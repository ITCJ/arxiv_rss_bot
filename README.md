# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-02-13 06:43:35 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Pretraining A Large Language Model using Distributed GPUs: A Memory-Efficient Decentralized Paradigm](https://arxiv.org/abs/2602.11543)

**Authors**: Jinrui Zhang, Chaodong Xiao, Aoqi Wu, Xindong Zhang, Lei Zhang  
**Category**: cs.CL  
**Published**: 2026-02-13  
**Score**: 13.5  
**Type**: new  
**ArXiv ID**: 2602.11543v1  

#### Abstract
Pretraining large language models (LLMs) typically requires centralized clusters with thousands of high-memory GPUs (e.g., H100/A100). Recent decentralized training methods reduce communication overhead by employing federated optimization; however, they still need to train the entire model on each n...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é¢„è®­ç»ƒä¸¥é‡ä¾èµ–äºé›†ä¸­å¼çš„é«˜æ€§èƒ½è®¡ç®—é›†ç¾¤ï¼Œé€šå¸¸éœ€è¦æ•°åƒå¼ é«˜æ˜¾å­˜GPUï¼ˆå¦‚H100/A100ï¼‰ä»¥åŠé«˜é€Ÿäº’è”ï¼ˆå¦‚RDMAï¼‰ã€‚è¿™ç§æ¶æ„å¯¹ç¡¬ä»¶èµ„æºè¦æ±‚æé«˜ï¼Œå¯¼è‡´å¤§å¤šæ•°ç ”ç©¶æœºæ„éš¾ä»¥å‚ä¸LLMç ”å‘ã€‚å°½ç®¡å·²æœ‰å»ä¸­å¿ƒåŒ–è®­ç»ƒæ–¹æ³•ï¼ˆå¦‚DiLiCoã€Photonï¼‰ï¼Œä½†å®ƒä»¬ä»éœ€åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šå­˜å‚¨å’Œæ›´æ–°**å®Œæ•´æ¨¡å‹å‚æ•°**ï¼Œå—é™äºå•ä¸ªGPUçš„å†…å­˜å®¹é‡ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šSPESï¼ˆSparse Expert Synchronizationï¼‰
æœ¬æ–‡æå‡ºäº†ä¸€ç§**å†…å­˜é«˜æ•ˆã€å»ä¸­å¿ƒåŒ–çš„MoE LLMé¢„è®­ç»ƒæ¡†æ¶â€”â€”SPES**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å°†Mixture-of-Expertsï¼ˆMoEï¼‰æ¨¡å‹ä¸­çš„**ä¸“å®¶ï¼ˆexpertsï¼‰åˆ†æ•£åˆ°ä¸åŒèŠ‚ç‚¹**è¿›è¡Œè®­ç»ƒã€‚
- æ¯ä¸ªèŠ‚ç‚¹ä»…è´Ÿè´£è®­ç»ƒè‡ªå·±åˆ†é…åˆ°çš„ä¸€ç»„ä¸“å®¶ï¼Œå…¶ä½™ä¸“å®¶ä¿æŒå†»ç»“çŠ¶æ€ã€‚
- èŠ‚ç‚¹é—´é€šè¿‡ç¨€ç–åŒæ­¥æœºåˆ¶äº¤æ¢å·²æ›´æ–°çš„ä¸“å®¶æƒé‡ï¼Œé¿å…ä¼ è¾“å…¨éƒ¨æ¨¡å‹å‚æ•°ã€‚

æ­¤å¤–ï¼Œä¸ºè§£å†³æ—©æœŸè®­ç»ƒé˜¶æ®µä¸“å®¶åˆ©ç”¨ç‡ä½ã€æ”¶æ•›æ…¢çš„é—®é¢˜ï¼Œä½œè€…å¼•å…¥äº†**expert-merging warm-upç­–ç•¥**ï¼š
- åœ¨è®­ç»ƒåˆæœŸå‘¨æœŸæ€§åœ°å°†ç›¸ä¼¼çš„ä¸“å®¶ä»¥åŠ æƒå¹³å‡æ–¹å¼åˆå¹¶ï¼Œä¿ƒè¿›è·¨èŠ‚ç‚¹çŸ¥è¯†å…±äº«ã€‚
- åˆå¹¶å¼ºåº¦éšè®­ç»ƒé€æ­¥è¡°å‡ï¼ŒåæœŸä¿ç•™ä¸“å®¶çš„ä¸“ä¸šåŒ–èƒ½åŠ›ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿé›†ä¸­å¼/DiLiCo | SPES |
|------|------------------|------|
| **æ¯èŠ‚ç‚¹æ˜¾å­˜å ç”¨** | é«˜ï¼ˆéœ€å­˜å…¨æ¨¡å‹+ä¼˜åŒ–å™¨çŠ¶æ€ï¼‰ | æ˜¾è‘—é™ä½ï¼ˆä»…ç»´æŠ¤å±€éƒ¨ä¸“å®¶ï¼‰ |
| **é€šä¿¡å¼€é”€** | é«˜é¢‘æ¬¡å…¨æ¨¡å‹åŒæ­¥ | ç¨€ç–åŒæ­¥ï¼Œä»…ä¼ æ›´æ–°éƒ¨åˆ† |
| **ç¡¬ä»¶é—¨æ§›** | å¿…é¡»ä½¿ç”¨é«˜æ˜¾å­˜GPUé›†ç¾¤ | å¯ç”¨æ™®é€š48GB GPUé€šè¿‡äº’è”ç½‘è¿æ¥è®­ç»ƒ |
| **å¯æ‰©å±•æ€§** | å—é™äºå¸¦å®½å’Œå†…å­˜ | æ›´é€‚åˆåœ°ç†åˆ†å¸ƒã€å¼‚æ„è®¾å¤‡ç¯å¢ƒ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **ä»é›¶è®­ç»ƒï¼ˆTraining from scratchï¼‰**ï¼š
  - `Ultra-FineWeb`ã€`SlimPajama`ï¼šé€šç”¨ç½‘é¡µæ–‡æœ¬
  - `arXiv`, `OpenWebMath`, `Algebraic Stack`, `peS2o`, `StarCoder`ï¼šç§‘å­¦ã€æ•°å­¦ã€ç¼–ç¨‹é¢†åŸŸæ•°æ®ï¼ˆæ¥è‡ªolmo-mix-1124ï¼‰
- **è¿ç§»è®­ç»ƒï¼ˆUpcyclingï¼‰**ï¼š
  - `Nemotron Pretraining Dataset`ï¼šé«˜è´¨é‡æ•°å­¦ã€ä»£ç ã€å¤šè¯­è¨€é—®ç­”æ•°æ®

æ‰€æœ‰æ•°æ®å‡ä¸ºå…¬å¼€å¯ç”¨ï¼Œç¡®ä¿å¤ç°æ€§å’Œç¤¾åŒºå¯è®¿é—®æ€§ã€‚

### å®éªŒè®¾ç½®
| æ¨¡å‹è§„æ¨¡ | èŠ‚ç‚¹æ•° | å•èŠ‚ç‚¹é…ç½® | æ€»è®­ç»ƒTokené‡ |
|--------|-------|-----------|-------------|
| 2B MoE | 16 | 1Ã—NVIDIA L40S (48GB) | 500B |
| 7B MoE | 4 | æ¯èŠ‚ç‚¹8Ã—A800 GPU (NVLinkäº’è”) | 500B |
| 9B MoE* | - | ç”±Qwen3-1.7B-Baseåˆå§‹åŒ– | 400B |

> *æ³¨ï¼š9Bæ¨¡å‹é‡‡ç”¨â€œupcyclingâ€æ–¹å¼ï¼Œå³ä»denseæ¨¡å‹æ‰©å±•è€Œæ¥ã€‚

### è¯„ä¼°æŒ‡æ ‡
ä½¿ç”¨ `lm-evaluation-harness` åº“è¿›è¡Œæ ‡å‡†è¯„æµ‹ï¼Œæ¶µç›–ä»¥ä¸‹åŸºå‡†ä»»åŠ¡ï¼š
- **å¸¸è¯†æ¨ç†**ï¼šARC(e/c), PIQA, SIQA, WinoGrande
- **é˜…è¯»ç†è§£**ï¼šBoolQ, OpenBookQA, LogiQA
- **ç»¼åˆçŸ¥è¯†**ï¼šMMLU, C-Eval

æŠ¥å‘Š0-shotæˆ–æ ‡å‡†åŒ–å‡†ç¡®ç‡ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Centralized Training**ï¼šä¼ ç»Ÿé›†ä¸­å¼è®­ç»ƒï¼ˆFSDP/ZeROç­‰ï¼‰
- **DiLiCo**ï¼šä»£è¡¨æ€§çš„å»ä¸­å¿ƒåŒ–é¢„è®­ç»ƒæ–¹æ³•ï¼ˆåŸºäºFedAvgï¼‰
- å…¶ä»–å¼€æºLLMï¼šå¦‚TinyLlama, Pythia, Qwenç³»åˆ—, MoE++ç­‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§Table 3ï¼‰
| æ–¹æ³• | å‚æ•°é‡ | è®­ç»ƒToken | ARC(e) | ARC(c) | PIQA | SciQ | BoolQ | Avg |
|-----|--------|------------|--------|--------|------|-------|--------|-----|
| SPES-2B | 0.8B/2.1B | 500B | 63.8 | 35.3 | 69.3 | 85.0 | 61.4 | â€” |
| SPES-7B | 1.6B/7B | 500B | 72.1 | 43.8 | 74.7 | 89.9 | 62.7 | â€” |
| SPES-9B* | 3.1B/9B | 400B | 81.5 | 57.3 | 78.9 | 95.3 | 77.3 | â€” |

> *æ³¨ï¼šå‰é¡¹ä¸ºæ¿€æ´»å‚æ•°é‡ï¼Œåé¡¹ä¸ºæ€»å‚æ•°é‡*

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”
#### å†…å­˜ä¸é€šä¿¡æ•ˆç‡ï¼ˆFig. 3ï¼‰
| æŒ‡æ ‡ | DiLiCo/Centralized | SPES | æ”¹è¿›å¹…åº¦ |
|------|--------------------|------|---------|
| **2Bæ¨¡å‹æ¯GPUæ˜¾å­˜** | >55GB | **35GB** | â†“36% |
| **7Bæ¨¡å‹ä¸Šè¡Œé€šä¿¡é‡/è½®** | 28.6 GB | **9.8 GB** | â†“65% |
| **2Bæ¨¡å‹é€šä¿¡æˆæœ¬** | åŸºå‡†å€¼ | â†“**33.3%** | æ˜¾è‘—é™ä½ |

> âœ… SPESå¯åœ¨16å°ç‹¬ç«‹çš„48GB GPUä¸Šå®Œæˆ2B MoEæ¨¡å‹è®­ç»ƒï¼Œè€Œä¼ ç»Ÿæ–¹æ³•æ— æ³•åœ¨æ­¤é…ç½®ä¸‹è¿è¡Œã€‚

#### æ€§èƒ½å¯¹æ¯”ï¼ˆTable 1ï¼‰
| æ–¹æ³• | å¹³å‡å¾—åˆ†ï¼ˆ8é¡¹ä»»åŠ¡ï¼‰ |
|------|------------------|
| Centralized | 49.7 |
| DiLiCo | 50.5 |
| **SPES** | **51.0** |

> ğŸ”º SPESä¸ä»…èµ„æºæ¶ˆè€—æ›´ä½ï¼Œä¸”åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¾¾åˆ°ç”šè‡³è¶…è¶Šé›†ä¸­å¼è®­ç»ƒçš„è¡¨ç°ã€‚

### æ¶ˆèå®éªŒç»“æœ
#### Expert-Merging Warm-Up æ•ˆæœï¼ˆTable 4ï¼‰
| æ–¹æ³• | å¹³å‡å¾—åˆ† | BoolQâ†‘ | SciQâ†‘ |
|------|----------|--------|-------|
| w/o merging | 50.5 | 58.0 | 75.9 |
| **w/ merging** | **51.3** | **60.4** | **77.8** |

> ğŸ’¡ åˆå¹¶ç­–ç•¥æ˜¾è‘—æå‡æ—©æœŸæ”¶æ•›é€Ÿåº¦å’Œæœ€ç»ˆæ€§èƒ½ï¼Œå°¤å…¶åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°æ›´ä¼˜ã€‚

#### ä¸åŒèŠ‚ç‚¹æ•°é‡çš„å½±å“ï¼ˆTable A5ï¼‰
| èŠ‚ç‚¹æ•° | å¹³å‡å¾—åˆ† |
|-------|----------|
| 2     | 50.6     |
| 4     | 49.7     |
| 8     | 49.5     |

> ğŸ“‰ éšç€èŠ‚ç‚¹å¢å¤šç•¥æœ‰ä¸‹é™ï¼Œä½†ä»ä¿æŒç«äº‰åŠ›ï¼Œè¡¨æ˜SPESå…·å¤‡è‰¯å¥½**æ¨ªå‘æ‰©å±•èƒ½åŠ›**ã€‚

#### åŒæ­¥é¢‘ç‡å½±å“ï¼ˆFig. A2ï¼‰
- å±€éƒ¨è®­ç»ƒæ­¥æ•° $H$ è¶Šå¤§ï¼ˆåŒæ­¥è¶Šå°‘ï¼‰ï¼Œæ€§èƒ½è¶Šå·®ã€‚
- æœ€ä½³å¹³è¡¡ç‚¹ä¸º $H=50$ï¼Œè¯´æ˜**é€‚åº¦é¢‘ç¹çš„åŒæ­¥æœ‰åŠ©äºç»´æŒä¸€è‡´æ€§**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **SPESå®ç°äº†çœŸæ­£æ„ä¹‰ä¸Šçš„ä½é—¨æ§›LLMé¢„è®­ç»ƒ**ï¼š
   - æˆåŠŸåœ¨16å—é€šè¿‡äº’è”ç½‘è¿æ¥çš„48GBæ¶ˆè´¹çº§GPUä¸Šå®Œæˆäº†2B MoEæ¨¡å‹çš„è®­ç»ƒã€‚
   - æ€§èƒ½åª²ç¾åŒç­‰ç®—åŠ›é¢„ç®—ä¸‹çš„é›†ä¸­å¼è®­ç»ƒæ–¹æ¡ˆã€‚

2. **MoEæ¶æ„å¤©ç„¶é€‚é…å»ä¸­å¿ƒåŒ–è®­ç»ƒ**ï¼š
   - ä¸“å®¶æ¨¡å—çš„ç‹¬ç«‹æ€§ä½¿å¾—å¯ä»¥è‡ªç„¶åˆ‡åˆ†è®­ç»ƒè´Ÿè½½ã€‚
   - ç»“åˆç¨€ç–åŒæ­¥æœºåˆ¶ï¼Œå¤§å¹…é™ä½é€šä¿¡å‹åŠ›ã€‚

3. **expert-merging warm-upæœ‰æ•ˆç¼“è§£ç¨€ç–è®­ç»ƒç¼ºé™·**ï¼š
   - æå‡äº†tokenåˆ©ç”¨ç‡å’Œä¸“å®¶æ³›åŒ–èƒ½åŠ›ã€‚
   - æ˜¯å®ç°å¿«é€Ÿæ”¶æ•›çš„å…³é”®è®¾è®¡ã€‚

4. **SPESå…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§**ï¼š
   - æˆåŠŸè®­ç»ƒ7Bä»å¤´å¼€å§‹æ¨¡å‹å’Œ9Bè¿ç§»æ¨¡å‹ã€‚
   - æ‰€æœ‰æ¨¡å‹å‡åŒ¹é…æˆ–ä¼˜äºåŒç±»é›†ä¸­å¼åŸºçº¿ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æœ€å¤§éªŒè¯è§„æ¨¡ä¸º9Bå‚æ•°ï¼Œå°šæœªéªŒè¯è¶…å¤§è§„æ¨¡ï¼ˆå¦‚>100Bï¼‰ä¸‹çš„è¡¨ç°ã€‚
- è®­ç»ƒæ—¶é—´è¾ƒé•¿ï¼Œå—é™äºå¼±ç½‘ç»œè¿æ¥ä¸‹çš„åŒæ­¥å»¶è¿Ÿã€‚
- æœªæ¢ç´¢å¤šæ¨¡æ€ä»»åŠ¡ä¸Šçš„é€‚ç”¨æ€§ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- éªŒè¯æ›´å¤§è§„æ¨¡æ¨¡å‹ï¼ˆ>10Bï¼‰å’Œæ›´é•¿è®­ç»ƒå‘¨æœŸä¸‹çš„ç¨³å®šæ€§ä¸æ€§èƒ½ã€‚
- æ¢ç´¢åœ¨**å¤šæ¨¡æ€æ¨¡å‹**ï¼ˆå¦‚vision-language modelsï¼‰ä¸­çš„åº”ç”¨ã€‚
- è¿›ä¸€æ­¥ä¼˜åŒ–åŒæ­¥åè®®ï¼Œæ”¯æŒåŠ¨æ€èŠ‚ç‚¹åŠ å…¥/é€€å‡ºï¼Œå¢å¼ºé²æ£’æ€§ã€‚
- ç»“åˆæ›´å…ˆè¿›çš„MoEè®¾è®¡ï¼ˆå¦‚zero-computation expertsï¼‰è¿›ä¸€æ­¥æå‡æ•ˆç‡ã€‚

---

> ğŸ”— **ä»£ç å¼€æºåœ°å€**ï¼š[https://github.com/zjr2000/SPES](https://github.com/zjr2000/SPES)  
> ğŸ“˜ **è®ºæ–‡é“¾æ¥**ï¼š[arXiv:2602.11543](https://arxiv.org/abs/2602.11543)

</details>

---

### 2. [Extending Puzzle for Mixture-of-Experts Reasoning Models with Application to GPT-OSS Acceleration](https://arxiv.org/abs/2602.11937)

**Authors**: Akhiad Bercovich, Nir Ailon, Vladimir Anisimov, Tomer Asida, Nave Assaf, Mohammad Dabbah, Ido Galil, Amnon Geifman, Yonatan Geifman, Izhak Golan, Roi Koren, Itay Levy, Zach Moshe, Pavlo Molchanov, Najeeb Nabwani, Mostofa Patwari, Omri Puny, Tomer Ronen, Itamar Schen, Elad Segal, Ido Shahaf, Oren Tropp, Ran Zilberstein, Ran El-Yaniv  
**Category**: cs.LG  
**Published**: 2026-02-13  
**Score**: 13.0  
**Type**: new  
**ArXiv ID**: 2602.11937v1  

#### Abstract
Reasoning-focused LLMs improve answer quality by generating longer reasoning traces, but the additional tokens dramatically increase serving cost, motivating inference optimization. We extend and apply Puzzle, a post-training neural architecture search (NAS) framework, to gpt-oss-120B to produce gpt...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šExtending Puzzle for Mixture-of-Experts Reasoning Models with Application to GPT-OSS Acceleration

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰åŸºäºæ¨ç†ï¼ˆreasoningï¼‰çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€šè¿‡ç”Ÿæˆæ›´é•¿çš„æ¨ç†é“¾ï¼ˆreasoning tracesï¼‰æ¥æå‡ç­”æ¡ˆè´¨é‡ï¼Œä½†è¿™æ˜¾è‘—å¢åŠ äº†æœåŠ¡æˆæœ¬ï¼ˆserving costï¼‰ã€‚ä¸»è¦åŸå› åœ¨äºï¼š
- è‡ªå›å½’è§£ç ä¸­ï¼Œ**self-attention çš„è®¡ç®—å¼€é”€éšåºåˆ—é•¿åº¦å¢é•¿è€Œå¢åŠ **ï¼›
- **KV Cache çš„å†…å­˜å ç”¨å’Œå¸¦å®½éœ€æ±‚éš token æ•°çº¿æ€§å¢é•¿**ï¼Œåœ¨é•¿ä¸Šä¸‹æ–‡ï¼ˆå¦‚ 128Kï¼‰åœºæ™¯ä¸‹æˆä¸ºç“¶é¢ˆï¼›
- æ¨ç†ä»»åŠ¡ä¸­çš„ token ç”Ÿæˆæ•°é‡å¯å˜ï¼Œä¼ ç»Ÿçš„ per-token ååé‡ï¼ˆtok/sï¼‰æˆ–å»¶è¿Ÿï¼ˆms/tokenï¼‰æ— æ³•å‡†ç¡®åæ˜ ç«¯åˆ°ç«¯æ•ˆç‡ã€‚

å› æ­¤ï¼Œå¦‚ä½•åœ¨ä¸ç‰ºç‰²æ¨ç†èƒ½åŠ›çš„å‰æä¸‹ï¼Œä¼˜åŒ–æ¨ç†å‹ MoE æ¨¡å‹çš„éƒ¨ç½²æ•ˆç‡ï¼Œæˆä¸ºä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æœ¬æ–‡æå‡ºå¯¹ **Puzzle** æ¡†æ¶è¿›è¡Œæ‰©å±•ï¼Œå¹¶åº”ç”¨äº `gpt-oss-120B` æ¨¡å‹ï¼Œæ„å»ºå‡ºè½»é‡åŒ–ã€é«˜æ€§èƒ½çš„è¡ç”Ÿæ¨¡å‹ `gpt-oss-puzzle-88B`ã€‚å…¶æ ¸å¿ƒæ˜¯**åè®­ç»ƒç¥ç»æ¶æ„æœç´¢ï¼ˆpost-training NASï¼‰**ï¼Œç»“åˆå¤šç§ä¼˜åŒ–æŠ€æœ¯ï¼š

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š
- âœ… **å¼‚æ„ MoE ä¸“å®¶å‰ªæï¼ˆHeterogeneous MoE Expert Pruningï¼‰**  
  åœ¨ MoE å±‚ä¸­æŒ‰å±‚åŠ¨æ€å†³å®šä¿ç•™çš„ä¸“å®¶æ•°é‡ï¼ˆ8â€“128ä¸ªï¼‰ï¼Œè€Œéç»Ÿä¸€å‹ç¼©ã€‚é€šè¿‡æ¿€æ´»ç›¸ä¼¼æ€§ï¼ˆactivation-based replace-1-block scoringï¼‰è¯„ä¼°æ¯å±‚é‡è¦æ€§ï¼Œå®ç°ç²¾ç»†åŒ–å‹ç¼©ã€‚

- âœ… **åŸºäºé•¿ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„çª—å£æ³¨æ„åŠ›æ›¿æ¢ï¼ˆLong-context-aware Window Attention Replacementï¼‰**  
  å°†éƒ¨åˆ†å…¨å±€æ³¨æ„åŠ›å±‚æ›¿æ¢ä¸º **Window Attention**ï¼ˆæ»‘åŠ¨çª—å£æ³¨æ„åŠ›ï¼‰ï¼Œä»¥é™ä½ KV Cache å ç”¨ã€‚ä¸åŒäºä¼ ç»Ÿå±€éƒ¨ä¿¡å·è¯„åˆ†ï¼Œæœ¬æ–‡ä½¿ç”¨ **AA-LCR åŸºå‡†åˆ†æ•°**ä½œä¸ºè¯„åˆ†ä¾æ®ï¼Œä¸“é—¨æ•æ‰å¯¹é•¿ç¨‹ä¾èµ–çš„å½±å“ã€‚

- âœ… **FP8 KV-Cache é‡åŒ– + æ ‡åº¦æ ¡å‡†ï¼ˆCalibrated Scalesï¼‰**  
  å¼•å…¥ FP8 é‡åŒ–å¹¶é‡‡ç”¨æœ€å¤§å€¼æ ‡å®šï¼ˆmax calibrationï¼‰ç”Ÿæˆ KV scalesï¼Œæœ‰æ•ˆç¼“è§£ç²¾åº¦æŸå¤±ï¼ŒåŒæ—¶å°† KV Cache å®¹é‡æå‡çº¦ 2Ã—ï¼ŒåŠ é€Ÿ attention æ¨¡å—ã€‚

- âœ… **å¼ºåŒ–å­¦ä¹ è®­ç»ƒåŒè·¯å¾„ç­–ç•¥ + æƒé‡å¹³å‡èåˆ**  
  è®­ç»ƒä¸¤ä¸ª RL ç­–ç•¥ï¼šä¸€ä¸ªä¸“æ³¨é«˜æ¨ç†åŠªåŠ›æ¨¡å¼ï¼ˆæå‡å‡†ç¡®æ€§ï¼‰ï¼Œå¦ä¸€ä¸ªå¹³è¡¡å„æ¨ç†ç­‰çº§ï¼ˆæ§åˆ¶ç”Ÿæˆé•¿åº¦ï¼‰ã€‚æœ€ç»ˆé€šè¿‡æƒé‡å¹³å‡åˆå¹¶ï¼Œå…¼é¡¾é«˜å‡†ç¡®æ€§å’Œå¯æ§çš„ç”Ÿæˆé•¿åº¦ã€‚

- âœ… **è¯·æ±‚çº§æ•ˆç‡è¯„ä¼°æŒ‡æ ‡ï¼ˆRequest-Level Efficiencyï¼‰**  
  æå‡º **ç›¸å¯¹è¯·æ±‚é€Ÿç‡ï¼ˆrelative request rateï¼‰ = æœ€å¤§ååé‡ / å¹³å‡ç”Ÿæˆ token æ•°**ï¼Œç»¼åˆè¡¡é‡é€Ÿåº¦ä¸æ¨ç†æˆæœ¬ï¼Œé¿å…â€œååé«˜ä½† trace é•¿â€å¯¼è‡´å®é™…æ•ˆç‡ä¸‹é™çš„è¯¯å¯¼ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿è¯´æ˜ |
|------|--------|
| **æ¶æ„çµæ´»æ€§** | æ”¯æŒå¼‚æ„ MoE å’Œæ··åˆæ³¨æ„åŠ›ç»“æ„ï¼Œä¼˜äºå›ºå®šç»“æ„å‹ç¼©æ–¹æ³• |
| **é•¿ä¸Šä¸‹æ–‡é€‚é…æ€§** | æ˜¾å¼ä¼˜åŒ– KV Cache å’Œé•¿ç¨‹å»ºæ¨¡èƒ½åŠ›ï¼Œé€‚åˆ agentic workflows |
| **ç«¯åˆ°ç«¯æ•ˆç‡å¯¼å‘** | ä¸ä»…çœ‹ per-token æ€§èƒ½ï¼Œæ›´å…³æ³¨è¯·æ±‚çº§åˆ«çš„æ€§ä»·æ¯” |
| **æ— éœ€é‡æ–°é¢„è®­ç»ƒ** | å…¨éƒ¨ä¼˜åŒ–åœ¨ post-training é˜¶æ®µå®Œæˆï¼ŒèŠ‚çœå¤§é‡ç®—åŠ› |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **LNPT-gpt-oss æ•°æ®é›†**ï¼šåŸºäº `nvidia/Llama-Nemotron-Post-Training-Dataset`ï¼Œç”± `gpt-oss-120B` åœ¨ high/medium reasoning effort ä¸‹ç”Ÿæˆå“åº”æ„æˆï¼Œç”¨äºï¼š
  - MoE ä¸“å®¶è´¡çŒ®è¯„åˆ†
  - Replace-1-block è¯„åˆ†
  - Knowledge Distillation
  - KV Quantization æ ‡åº¦æ ¡å‡†
- **AA-LCRï¼ˆArtificial Analysis Long-Context Reasoningï¼‰**ï¼šç”¨äºè¯„ä¼°æ³¨æ„åŠ›æ¨¡å—æ›¿æ¢å¯¹é•¿ä¸Šä¸‹æ–‡æ¨ç†èƒ½åŠ›çš„å½±å“ã€‚
- **å…¶ä»–åŸºå‡†æµ‹è¯•é›†**ï¼š
  - MMLU-Pro, GPQA-Diamond, HLE, AIME25, SciCode, IFBench, RULER-128K

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼š
  - ä¸»è¦ï¼š8Ã—NVIDIA H100 èŠ‚ç‚¹ï¼ˆ80GB HBM3ï¼‰
  - å¯¹æ¯”ï¼šå•å¼  H100 GPU
- **è¾“å…¥è¾“å‡ºé…ç½®**ï¼š
  - é•¿ä¸Šä¸‹æ–‡ï¼š64K/64Kï¼ˆ64K è¾“å…¥ + 64K è¾“å‡ºï¼‰
  - çŸ­ä¸Šä¸‹æ–‡ï¼š4K/4K
- **æ¨ç†å‚æ•°**ï¼ˆè§ Appendix Bï¼‰ï¼š
  - Temp=0.6, Top_p=0.95, Max new tokens=128K
  - ä½¿ç”¨ vLLM v0.11 è¿›è¡Œæ¨ç†è¯„æµ‹

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Per-token Throughput (tok/s)** | æ¯ç§’å¤„ç† token æ•°ï¼Œè¡¡é‡æ¶æ„æ•ˆç‡ |
| **Decode Latency (ITL, ms/token)** | å•ä¸ª token è§£ç å»¶è¿Ÿ |
| **Suite-Average Accuracy (%)** | å¤šé¡¹åŸºå‡†ä»»åŠ¡çš„å¹³å‡å‡†ç¡®ç‡ |
| **Generated Token Count (K)** | æ¯è¯·æ±‚å¹³å‡ç”Ÿæˆ token æ•° |
| **Effort Length Ratio** | é«˜/ä½æ¨ç†åŠªåŠ›ä¸‹çš„ç”Ÿæˆé•¿åº¦æ¯”ï¼Œè¡¡é‡å¯æ§æ€§ |
| **Relative Request Rate** | è¯·æ±‚çº§æ•ˆç‡ = æœ€å¤§åå / å¹³å‡ç”Ÿæˆ token æ•°ï¼Œå½’ä¸€åŒ–è‡³åŸºçº¿ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **gpt-oss-120B**ï¼ˆBF16 / FP8 KVï¼‰ï¼šåŸå§‹æ¨¡å‹ï¼Œä¸»è¦å¯¹æ¯”åŸºçº¿
- **HyperNova-60B**ï¼šç¬¬ä¸‰æ–¹å‹ç¼©ç‰ˆæœ¬ï¼ˆæ¥è‡ª Multiverse Computingï¼‰ï¼Œä¹ŸåŸºäº gpt-oss-120Bï¼Œæä¾›å¤–éƒ¨å¯¹ç…§

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆH100 èŠ‚ç‚¹ï¼‰

| åœºæ™¯ | æ¨¡å‹ | æœ€å¤§ååé‡ | Speedup |
|------|------|------------|---------|
| **4K/4K** | gpt-oss-120B | 29.6K tok/s | â€” |
| | gpt-oss-puzzle-88B | **36.1K tok/s** | **1.22Ã—** |
| **64K/64K** | gpt-oss-120B | 5.7K tok/s | â€” |
| | gpt-oss-puzzle-88B | **9.3K tok/s** | **1.63Ã—** |
| **å•å¡ 64K/64K** | gpt-oss-120B | 0.3K tok/s | â€” |
| | gpt-oss-puzzle-88B | **0.8K tok/s** | **2.82Ã—** |

> ğŸ’¡ åœ¨å•å¡åœºæ™¯ä¸‹ï¼Œç”±äºå†…å­˜é™åˆ¶æ›´ä¸¥é‡ï¼Œä¼˜åŒ–æ•ˆæœæ›´åŠ æ˜¾è‘—ã€‚

### å‡†ç¡®æ€§è¡¨ç°ï¼ˆsuite-average accuracy, KV FP8ï¼‰

| æ¨ç†ç­‰çº§ | gpt-oss-120B | gpt-oss-puzzle-88B | Retention |
|----------|---------------|---------------------|-----------|
| High | 58.19% | **58.67%** | 100.8% |
| Medium | 52.89% | **54.93%** | 103.9% |
| Low | 44.71% | **48.38%** | **108.2%** |

âœ… ç»“æœè¡¨æ˜ï¼šå°½ç®¡å‚æ•°é‡ä»…ä¸ºåŸæ¨¡å‹çš„ ~73%ï¼Œ`gpt-oss-puzzle-88B` åœ¨å¤šæ•°æ¨ç†ç­‰çº§ä¸Š**åŒ¹é…ç”šè‡³ç•¥å¾®è¶…è¶Š**åŸæ¨¡å‹ã€‚

### è¯·æ±‚çº§æ•ˆç‡ï¼ˆRelative Request Rateï¼‰

ä» Figure 1 å¯è§ï¼Œåœ¨æ•´ä¸ª **accuracy-speed frontier** ä¸Šï¼Œ`gpt-oss-puzzle-88B` å‡ä¼˜äº `gpt-oss-120B` å’Œ `HyperNova-60B`ï¼š
- åœ¨ä½æ¨ç†ç­‰çº§ä¸‹ï¼Œè¾¾åˆ°æœ€é«˜ **1.29Ã— çš„è¯·æ±‚çº§æ•ˆç‡å¢ç›Š**
- Effort Length Ratio ä¿æŒä¸æ•™å¸ˆæ¨¡å‹ç›¸è¿‘ï¼Œç¡®ä¿ç”¨æˆ·å¯é€šè¿‡è°ƒèŠ‚ effort æ§åˆ¶æˆæœ¬ä¸è´¨é‡

### ä¸å…¶ä»–å‹ç¼©æ¨¡å‹å¯¹æ¯”
- **HyperNova-60B** è™½ç„¶ per-token ååè¾ƒé«˜ï¼Œä½†ç”±äºç”Ÿæˆ trace æ›´é•¿ï¼Œ**è¯·æ±‚çº§æ•ˆç‡åè€Œè¢«æŠµæ¶ˆ**ï¼Œå°¤å…¶åœ¨é«˜æ¨ç†ç­‰çº§ä¸‹è¡¨ç°ä¸ä½³ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAppendix Cï¼‰

| æ³¨æ„åŠ›è¯„åˆ†æ–¹å¼ | MMLU-Pro â†‘ | GPQA â†‘ | AALCR â†‘ |
|----------------|------------|--------|---------|
| Activation-MSEï¼ˆå¸¸è§„ï¼‰ | 79.26 | 73.67 | 17.00 |
| **AALCR-basedï¼ˆæœ¬æ–‡ï¼‰** | **79.40** | **74.43** | **37.00** |

â¡ï¸ ä½¿ç”¨ **AA-LCR ä»»åŠ¡æ€§èƒ½ä¸‹é™ä½œä¸ºè¯„åˆ†ä¿¡å·**ï¼Œæ˜¾è‘—æå‡äº†é•¿ä¸Šä¸‹æ–‡æ¨ç†èƒ½åŠ›ä¿ç•™ï¼ŒéªŒè¯äº†é•¿ä¸Šä¸‹æ–‡æ„ŸçŸ¥è¯„åˆ†çš„æœ‰æ•ˆæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **Puzzle æ¡†æ¶å¯æˆåŠŸæ‰©å±•è‡³ MoE æ¶æ„å’Œå¤æ‚æ³¨æ„åŠ›æœºåˆ¶**ï¼Œæ”¯æŒå¼‚æ„å‰ªæä¸é€‰æ‹©æ€§ window attention æ›¿æ¢ã€‚
2. âœ… **FP8 KV Cache + calibrated scales å¯åœ¨å‡ ä¹æ— æŸç²¾åº¦å‰æä¸‹å‡åŠ KV å†…å­˜å ç”¨**ï¼Œæå¤§æå‡é•¿ä¸Šä¸‹æ–‡æœåŠ¡èƒ½åŠ›ã€‚
3. âœ… **è¯·æ±‚çº§æ•ˆç‡æŒ‡æ ‡æ¯” per-token ååæ›´èƒ½åæ˜ çœŸå®éƒ¨ç½²æ•ˆç›Š**ï¼Œåº”æˆä¸ºæ¨ç†æ¨¡å‹ä¼˜åŒ–çš„æ ¸å¿ƒç›®æ ‡ã€‚
4. âœ… **é€šè¿‡ RL åŒè·¯å¾„è®­ç»ƒ+èåˆç­–ç•¥ï¼Œå¯åœ¨ä¸å¢åŠ ç”Ÿæˆé•¿åº¦çš„å‰æä¸‹æ¢å¤å¹¶æå‡æ¨ç†å‡†ç¡®æ€§**ã€‚
5. âœ… `gpt-oss-puzzle-88B` åœ¨ **ååã€æ•ˆç‡ã€å‡†ç¡®æ€§ä¸‰æ–¹é¢å…¨é¢ä¼˜äºåŸºçº¿**ï¼Œè¯æ˜ post-training NAS æ˜¯é«˜æ•ˆéƒ¨ç½²çš„å¼ºå¤§å·¥å…·ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- ğŸ”¸ å½“å‰ Puzzle ä»ä¾èµ–â€œå•å—æ›¿æ¢â€è¿‘ä¼¼æ‰“åˆ†ï¼Œå¯èƒ½å¿½ç•¥æ¨¡å—é—´éçº¿æ€§äº¤äº’æ•ˆåº”ã€‚
- ğŸ”¸ å¯¹äºæç«¯é•¿ä¸Šä¸‹æ–‡ï¼ˆ>128Kï¼‰ï¼Œwindow attention çš„çª—å£å¤§å°éœ€è¿›ä¸€æ­¥è°ƒä¼˜ã€‚
- ğŸ”¸ æ‰€æœ‰ä¼˜åŒ–åŸºäºç‰¹å®šç¡¬ä»¶ï¼ˆH100ï¼‰ï¼Œè·¨è®¾å¤‡æ³›åŒ–èƒ½åŠ›æœ‰å¾…éªŒè¯ã€‚
- ğŸ”¸ å½“å‰æœªæ¢ç´¢ MoE router çš„å¾®è°ƒï¼Œå¯èƒ½å­˜åœ¨è¿›ä¸€æ­¥å‹ç¼©ç©ºé—´ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- ğŸ”„ å°† Puzzle åº”ç”¨äºæ›´å¤šæ–°å‹æ¶æ„ï¼ˆå¦‚ Mambaã€RetNetï¼‰
- ğŸ§© æ¢ç´¢è”åˆä¼˜åŒ– MoE routing ä¸ FFN ç»“æ„
- ğŸ“ˆ å¼€å‘æ›´ç²¾ç¡®çš„ long-range interaction è¯„ä¼°ä»£ç†ï¼ˆsurrogate metricï¼‰
- â˜ï¸ æ„å»ºè‡ªåŠ¨åŒ– Puzzle-as-a-Service æµæ°´çº¿ï¼Œæ”¯æŒç”¨æˆ·è‡ªå®šä¹‰çº¦æŸä¸‹çš„æ¨¡å‹å®šåˆ¶

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡é€šè¿‡æ‰©å±• Puzzle æ¡†æ¶ï¼Œé¦–æ¬¡å®ç°äº†å¯¹ MoE æ¨ç†æ¨¡å‹çš„ç³»ç»Ÿæ€§åè®­ç»ƒæ¶æ„æœç´¢ä¼˜åŒ–ï¼Œæ¨å‡ºäº† `gpt-oss-puzzle-88B`ï¼Œåœ¨ä¿æŒç”šè‡³æå‡æ¨ç†å‡†ç¡®æ€§çš„å‰æä¸‹ï¼Œå®ç°äº†é«˜è¾¾ **2.82Ã— çš„å•å¡ååæå‡** å’Œ **1.29Ã— çš„è¯·æ±‚çº§æ•ˆç‡å¢ç›Š**ï¼Œä¸ºé«˜æ•ˆéƒ¨ç½²å¤§å‹æ¨ç†æ¨¡å‹æä¾›äº†å®Œæ•´èŒƒå¼ã€‚

</details>

---

### 3. [T3D: Few-Step Diffusion Language Models via Trajectory Self-Distillation with Direct Discriminative Optimization](https://arxiv.org/abs/2602.12262)

**Authors**: Tunyu Zhang, Xinxi Zhang, Ligong Han, Haizhou Shi, Xiaoxiao He, Zhuowei Li, Hao Wang, Kai Xu, Akash Srivastava, Hao Wang, Vladimir Pavlovic, Dimitris N. Metaxas  
**Category**: cs.CL  
**Published**: 2026-02-13  
**Score**: 11.5  
**Type**: new  
**ArXiv ID**: 2602.12262v1  

#### Abstract
Diffusion large language models (DLLMs) have the potential to enable fast text generation by decoding multiple tokens in parallel. However, in practice, their inference efficiency is constrained by the need for many refinement steps, while aggressively reducing the number of steps leads to a substan...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠT3D: Few-Step Diffusion Language Models via Trajectory Self-Distillation with Direct Discriminative Optimizationã€‹æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
Diffusion Large Language Models (DLLMs) è™½ç„¶æ”¯æŒå¹¶è¡Œç”Ÿæˆå¤šä¸ª tokenï¼Œå…·å¤‡æ½œåœ¨çš„é«˜æ•ˆæ¨ç†èƒ½åŠ›ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­ä»éœ€å¤§é‡å»å™ªæ­¥éª¤ï¼ˆdenoising stepsï¼‰æ‰èƒ½ä¿è¯ç”Ÿæˆè´¨é‡ã€‚å½“å‡å°‘æ­¥æ•°ä»¥æå‡æ•ˆç‡æ—¶ï¼Œç”Ÿæˆè´¨é‡ä¼šæ˜¾è‘—ä¸‹é™ã€‚è¿™ä¸€**few-step decoding**ï¼ˆå°‘æ­¥è§£ç ï¼‰é—®é¢˜é™åˆ¶äº† DLLMs åœ¨ä½å»¶è¿Ÿåœºæ™¯ï¼ˆå¦‚å®æ—¶å†³ç­–ã€ç«¯ä¾§éƒ¨ç½²ï¼‰çš„åº”ç”¨ã€‚

æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•å­˜åœ¨ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼š
- **Mean-field approximation error**ï¼šç”±äºé‡‡ç”¨ token-factorized å‚æ•°åŒ–ï¼Œå¯¼è‡´åœ¨æ­¥æ•°å‹ç¼©ä¸‹å› å­åŒ–è¯¯å·®å¢å¤§ã€‚
- **Train-inference distribution mismatch**ï¼šè®­ç»ƒæ—¶ä½¿ç”¨éšæœºæ©ç ï¼Œè€Œæ¨ç†æ—¶ä½¿ç”¨åŸºäºç½®ä¿¡åº¦çš„ééšæœºè°ƒåº¦ç­–ç•¥ï¼Œå¯¼è‡´ä¸­é—´çŠ¶æ€åˆ†å¸ƒä¸ä¸€è‡´ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡º **T3D**ï¼ˆTrajectory Self-Distillation via DDOï¼‰ï¼Œä¸€ç§é€šè¿‡**è½¨è¿¹è‡ªè’¸é¦**ï¼ˆtrajectory self-distillationï¼‰ç»“åˆ**ç›´æ¥åˆ¤åˆ«ä¼˜åŒ–**ï¼ˆDirect Discriminative Optimization, DDOï¼‰æ¥æå‡å°‘æ­¥è§£ç æ€§èƒ½çš„æ–°æ¡†æ¶ã€‚å…¶ä¸‰å¤§æ ¸å¿ƒç»„ä»¶ä¸ºï¼š

1. **Trajectory Self-Distillationï¼ˆè½¨è¿¹è‡ªè’¸é¦ï¼‰**  
   åˆ©ç”¨é¢„è®­ç»ƒæ•™å¸ˆæ¨¡å‹åœ¨å…¶ç›®æ ‡è§£ç æµç¨‹ä¸‹çš„å®Œæ•´ç”Ÿæˆè½¨è¿¹ï¼ˆä»å…¨æ©ç åˆ°å¹²å‡€åºåˆ—çš„ä¸­é—´çŠ¶æ€åºåˆ—ï¼‰ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œè®­ç»ƒä¸€ä¸ªâ€œå­¦ç”Ÿâ€æ¨¡å‹ã€‚è¿™ä½¿å¾—å­¦ç”Ÿæ¨¡å‹åœ¨è®­ç»ƒé˜¶æ®µå°±æ¥è§¦åˆ°æ¨ç†æ—¶çš„çœŸå®ä¸­é—´çŠ¶æ€åˆ†å¸ƒï¼Œä»è€Œæ¶ˆé™¤ train-inference mismatchã€‚

2. **Direct Discriminative Optimization (DDO)**  
   å¼•å…¥ä¸€ç§ GAN å¯å‘å¼çš„åå‘ KLï¼ˆreverse-KLï¼‰é£æ ¼ç›®æ ‡å‡½æ•°ï¼Œæ›¿ä»£ä¼ ç»Ÿçš„å‰å‘ KLï¼ˆforward-KLï¼‰æŸå¤±ã€‚DDO é¼“åŠ±â€œæ¨¡å¼å¯»æ±‚â€ï¼ˆmode-seekingï¼‰è¡Œä¸ºï¼Œä½¿å­¦ç”Ÿæ›´å…³æ³¨é«˜æ¦‚ç‡çš„æ•™å¸ˆç”Ÿæˆè·¯å¾„ï¼Œé¿å…ä¼ ç»Ÿ mode-covering å¯¼è‡´çš„é¢„æµ‹å¹³æ»‘åŒ–é—®é¢˜ã€‚

3. **Path Consistency Regularizationï¼ˆè·¯å¾„ä¸€è‡´æ€§æ­£åˆ™åŒ–ï¼‰**  
   å¯¹æ—©æœŸè§£ç çš„ token èµ‹äºˆæ›´é«˜çš„æŸå¤±æƒé‡ï¼ˆ$w_i = \frac{B - \tau_i + 1}{B}$ï¼‰ï¼Œä»¥ç¼“è§£åœ¨å—çŠ¶å°‘æ­¥è§£ç ä¸­å› æ—©æœŸé”™è¯¯å¼•å‘çš„çº§è”è¯¯å·®ä¼ æ’­é—®é¢˜ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ— éœ€é¢å¤–æ ‡æ³¨æ•°æ®**ï¼šå®Œå…¨åŸºäºæ•™å¸ˆæ¨¡å‹è‡ªèº«ç”Ÿæˆçš„è½¨è¿¹è¿›è¡Œè‡ªè’¸é¦ï¼Œä¸ä¾èµ–çœŸå®æ•°æ®ã€‚
- **æ›´å¼ºçš„å¯¹é½èƒ½åŠ›**ï¼šç›¸æ¯”ä»…åŒ¹é…æœ€ç»ˆè¾“å‡ºçš„ä¼ ç»Ÿè’¸é¦æ–¹æ³•ï¼ŒT3D åœ¨æ•´ä¸ªç”Ÿæˆè½¨è¿¹ä¸Šè¿›è¡Œå¯¹é½ï¼Œæå‡äº†å¯¹å¤æ‚æ¨ç†è¿‡ç¨‹çš„å»ºæ¨¡èƒ½åŠ›ã€‚
- **æ›´ä¼˜çš„å°‘æ­¥æ€§èƒ½**ï¼šåœ¨æç´§çš„è§£ç é¢„ç®—ä¸‹ï¼ˆå¦‚æ¯å—ä»…1â€“2æ­¥ï¼‰ï¼ŒT3D æ˜¾è‘—ä¼˜äº ReDiã€dParallel ç­‰å¼ºåŸºçº¿ã€‚
- **ä¿ç•™å…¨æ­¥è§£ç èƒ½åŠ›**ï¼šå³ä½¿é’ˆå¯¹å°‘æ­¥ä»»åŠ¡è®­ç»ƒï¼ŒT3D ä»èƒ½ä¿æŒæ¥è¿‘åŸå§‹æ¨¡å‹çš„å…¨æ­¥æ‰©æ•£æ€§èƒ½ï¼Œé¿å…â€œé—å¿˜â€ç°è±¡ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
- **è®­ç»ƒæ•°æ®é›†**ï¼ˆç”¨äºè‡ªè’¸é¦ï¼‰ï¼š
  - æ•°å­¦æ¨ç†ï¼š`MATH` è®­ç»ƒé›†ï¼ˆHendrycks et al., 2021ï¼‰
  - ä»£ç ç”Ÿæˆï¼š`PrimeIntellect` æ•°æ®é›†ï¼ˆJaghouar et al., 2024ï¼‰
- **åŸºå‡†æµ‹è¯•æ•°æ®é›†**ï¼š
  - `GSM8K`ï¼šå°å­¦ç®—æœ¯æ–‡å­—é¢˜
  - `MATH500`ï¼šé«˜ä¸­åŠç«èµ›çº§åˆ«æ•°å­¦é¢˜
  - `MBPP`ï¼šPython ç¼–ç¨‹ä»»åŠ¡
  - `HumanEval`ï¼šä»£ç ç”Ÿæˆè¯„ä¼°

æ‰€æœ‰æ•°æ®å‡è¢«æˆªæ–­è‡³æœ€å¤§é•¿åº¦ 600 tokensã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹æ¶æ„**ï¼šåŸºäº **SDAR** ç³»åˆ—æ¨¡å‹ï¼ˆCheng et al., 2025ï¼‰ï¼Œé‡‡ç”¨å—å¼æ‰©æ•£ + å—é—´è‡ªå›å½’æœºåˆ¶ã€‚
  - ä½¿ç”¨ `SDAR-1.7B-Chat` å’Œ `SDAR-4B-Chat` ä¸¤ç§è§„æ¨¡ã€‚
- **è§£ç é…ç½®**ï¼š
  - Block Size âˆˆ {4, 8}
  - Tokens Per Step (TokPS) âˆˆ {2, 4} â†’ å¯¹åº”æ¯å—è§£ç æ­¥æ•°åˆ†åˆ«ä¸º 2/1 æˆ– 4/2 æ­¥
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - ä¸»è¦ï¼šå‡†ç¡®ç‡ï¼ˆAccuracyï¼‰åœ¨å„ benchmark ä¸Šçš„è¡¨ç°
  - è¾…åŠ©ï¼šååé‡ï¼ˆTPSï¼‰ã€å»¶è¿Ÿï¼ˆLatencyï¼‰ã€å¹³å‡è§£ç æ­¥æ•°ï¼ˆAvg Stepsï¼‰ç­‰åŠ¨æ€è§£ç æ•ˆç‡æŒ‡æ ‡

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç®€ä»‹ |
|------|------|
| **Original Model** | åŸå§‹é¢„è®­ç»ƒ SDAR æ¨¡å‹ |
| **SFT** | åœ¨çœŸå®æ•°æ®ä¸Šè¿›è¡Œç›‘ç£å¾®è°ƒï¼ˆSupervised Fine-Tuningï¼‰ |
| **ReDi** | Rectified Discrete Flowï¼Œæ ‡å‡†è‡ªè’¸é¦æ–¹æ³•ï¼ˆYoo et al., 2025ï¼‰ |
| **dParallel** | å­¦ä¹ å¹¶è¡Œè§£ç ç­–ç•¥çš„è’¸é¦æ–¹æ³•ï¼ˆChen et al., 2025ï¼‰ |
| **Naive TD** | æœ´ç´ è½¨è¿¹è’¸é¦ï¼ˆEqn. 5 ä¸­çš„ forward-KL ç‰ˆæœ¬ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

#### åœ¨ SDAR-1.7B-Chat ä¸Šï¼ˆTokPS=4, Block=4ï¼‰ï¼š
| æ–¹æ³• | MATH500 | GSM8K | MBPP | HumanEval | å¹³å‡æå‡ |
|------|--------|-------|------|-----------|----------|
| ReDi | 40.60 | 63.99 | 13.20 | 16.46 | â†“19.11% |
| dParallel | 43.40 | 68.23 | 22.20 | 24.39 | â†‘0.29% |
| **T3D (Ours)** | **47.00** | **70.96** | **27.20** | **30.49** | **â†‘7.59%** |

#### åœ¨ SDAR-4B-Chat ä¸Šï¼ˆTokPS=4, Block=8ï¼‰ï¼š
| æ–¹æ³• | MATH500 | GSM8K | MBPP | HumanEval | å¹³å‡æå‡ |
|------|--------|-------|------|-----------|----------|
| ReDi | 25.40 | 53.30 | 5.00 | 7.32 | â†‘0.65% |
| dParallel | 34.20 | 45.94 | 13.20 | 20.73 | â†‘39.05% |
| **T3D (Ours)** | **47.80** | **69.90** | **22.60** | **23.78** | **â†‘85.02%** |

> âœ… **ç»“è®º**ï¼šT3D åœ¨æ‰€æœ‰è®¾ç½®ä¸‹å‡å–å¾—æœ€ä½³æˆ–æ¬¡ä½³æ€§èƒ½ï¼Œå°¤å…¶åœ¨å¤§æ¨¡å‹å’Œé«˜å‹ç¼©æ¯”ä¸‹ä¼˜åŠ¿æ˜æ˜¾ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **å…¨é¢è¶…è¶Šç°æœ‰ self-distillation æ–¹æ³•**ï¼šåœ¨å››ç§ä¸åŒè§£ç é…ç½®ä¸‹ï¼ŒT3D å§‹ç»ˆä¼˜äº ReDiã€dParallel å’Œ Naive TDã€‚
- **æŠ—å‹èƒ½åŠ›å¼º**ï¼šéšç€ TokPS å¢åŠ ï¼ˆå³è§£ç æ­¥æ•°å‡å°‘ï¼‰ï¼Œå…¶ä»–æ–¹æ³•æ€§èƒ½æ€¥å‰§ä¸‹é™ï¼Œè€Œ T3D è¡¨ç°ç¨³å®šã€‚
- **åŠ¨æ€è§£ç å…¼å®¹æ€§å¥½**ï¼ˆè§ Table 3ï¼‰ï¼š
  - åœ¨åŠ¨æ€è§£ç ï¼ˆdynamic decodingï¼‰ä¸‹ï¼ŒT3D å®ç°æ›´é«˜å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½å¹³å‡è§£ç æ­¥æ•°å’Œå»¶è¿Ÿã€‚
  - ä¾‹å¦‚åœ¨ GSM8K ä¸Šï¼ŒT3D å‡†ç¡®ç‡è¾¾ **72.40%**ï¼ˆåŸæ¨¡å‹ 61.56%ï¼‰ï¼ŒåŒæ—¶ååé‡æå‡è‡³ **843.05 TPS**ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰æ˜¯å¦ä¿ç•™å…¨æ­¥è§£ç èƒ½åŠ›ï¼Ÿï¼ˆTable 2ï¼‰
| æ–¹æ³• | MATH500 (1.7B) | GSM8K (1.7B) | MATH500 (4B) | GSM8K (4B) |
|------|----------------|--------------|-------------|------------|
| ReDi | 47.00 | 73.77 | 50.40 | 82.03 |
| dParallel | 0.40 | 0.23 | 13.20 | 2.88 |
| **T3D (Ours)** | **56.80** | **78.01** | **70.00** | **89.31** |

> ğŸ” **å‘ç°**ï¼šT3D æˆåŠŸä¿ç•™äº†å…¨æ­¥æ‰©æ•£æ€§èƒ½ï¼Œå‡ ä¹æ— â€œé—å¿˜â€ï¼Œè€Œ ReDi å’Œ dParallel ä¸¥é‡é€€åŒ–ã€‚

#### ï¼ˆ2ï¼‰å„ç»„ä»¶ä½œç”¨åˆ†æï¼ˆTable 5â€“7ï¼‰
| ç»„ä»¶ç»„åˆ | MATH500 ACCï¼ˆFull-stepï¼‰ | Few-step æ€§èƒ½ |
|---------|----------------------------|---------------|
| Naive TD | 22.00 | ä¸­ç­‰ |
| Naive TD + Lpath | 58.00 | æå‡ç¨³å®šæ€§ |
| DDO + Random Tokens | 65.40 | æ˜¾è‘—æ”¹å–„ |
| **DDO + Lpath + Random (T3D)** | **69.00** | **æœ€ä¼˜** |

> ğŸ”¬ **å…³é”®å‘ç°**ï¼š
> - DDO å¯¹åˆå§‹åŒ–æ•æ„Ÿï¼Œéœ€é…åˆ random token æ··åˆè®­ç»ƒæ‰èƒ½ç¨³å®šã€‚
> - Path Consistency æ­£åˆ™åŒ–æœ‰æ•ˆæŠ‘åˆ¶æ—©æœŸé”™è¯¯ä¼ æ’­ã€‚
> - ä¸‰è€…ååŒä½œç”¨æ˜¯æˆåŠŸçš„å…³é”®ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **è½¨è¿¹è‡ªè’¸é¦å¯æœ‰æ•ˆè§£å†³ train-inference åˆ†å¸ƒåç§»é—®é¢˜**ï¼Œå¹¶é€šè¿‡ç›‘ç£å®Œæ•´ç”Ÿæˆè·¯å¾„æå‡å°‘æ­¥è§£ç é²æ£’æ€§ã€‚
2. **DDO çš„ reverse-KL ç‰¹æ€§æ›´é€‚åˆå¤šæ¨¡æ€å»å™ªåéªŒ**ï¼Œèƒ½å¼•å¯¼å­¦ç”Ÿèšç„¦äºé«˜è´¨é‡ç”Ÿæˆè·¯å¾„ï¼Œé¿å…é¢„æµ‹æ¨¡ç³Šã€‚
3. **T3D åœ¨æç«¯å°‘æ­¥æ¡ä»¶ä¸‹ä»èƒ½ç»´æŒé«˜ç”Ÿæˆè´¨é‡**ï¼Œå¤§å¹…ç¼©å°ä¸å…¨æ­¥è§£ç ä¹‹é—´çš„æ€§èƒ½å·®è·ã€‚
4. **è¯¥æ–¹æ³•å…·æœ‰è‰¯å¥½çš„æ³›åŒ–æ€§**ï¼Œä¸ä»…é€‚ç”¨äºé™æ€è§£ç ï¼Œåœ¨åŠ¨æ€è§£ç ä¸­ä¹Ÿè¡¨ç°å‡ºè‰²ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ–¹æ³•ä¾èµ–äºä¸€ä¸ªé«˜è´¨é‡çš„æ•™å¸ˆæ¨¡å‹ç”Ÿæˆè½¨è¿¹ï¼Œè‹¥æ•™å¸ˆæœ¬èº«å­˜åœ¨åå·®ï¼Œåˆ™å¯èƒ½è¢«ç»§æ‰¿ç”šè‡³æ”¾å¤§ã€‚
- DDO çš„è®­ç»ƒè¿‡ç¨‹å¯¹è¶…å‚æ•°ï¼ˆå¦‚æ­£åˆ™åŒ–ç³»æ•° $\lambda$ï¼‰è¾ƒä¸ºæ•æ„Ÿï¼Œéœ€è¦ä»”ç»†è°ƒå‚ï¼ˆæ–‡ä¸­è®¾ $\lambda=0.2$ æ•ˆæœæœ€ä½³ï¼‰ã€‚
- å°šæœªæ¢ç´¢å¦‚ä½•å°† T3D æ‰©å±•è‡³æ›´å¤§è§„æ¨¡æ¨¡å‹æˆ–å¤šæ¨¡æ€åœºæ™¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ **online distillation** æˆ– **self-play** æœºåˆ¶ï¼Œè®©æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸æ–­è¿­ä»£ä¼˜åŒ–è‡ªèº«è½¨è¿¹ã€‚
- ç»“åˆ **KV Cache** æŠ€æœ¯è¿›ä¸€æ­¥åŠ é€Ÿæ¨ç†ï¼ˆå¦‚ dKV-Cacheã€Fast-DLLMï¼‰ã€‚
- å°† T3D åº”ç”¨äº **text-to-image** æˆ– **speech generation** ç­‰ç¦»æ•£æ‰©æ•£æ¨¡å‹ä»»åŠ¡ã€‚
- ç ”ç©¶å¦‚ä½•åœ¨ **low-resource setting** ä¸‹å®ç°é«˜æ•ˆçš„ trajectory distillationã€‚

---

> ğŸŒŸ **æ€»ä½“è¯„ä»·**ï¼šT3D æ˜¯è¿ˆå‘å®ç”¨åŒ–å°‘æ­¥æ‰©æ•£è¯­è¨€æ¨¡å‹çš„é‡è¦ä¸€æ­¥ã€‚å®ƒé€šè¿‡ç®€å•è€Œæœ‰æ•ˆçš„è½¨è¿¹è’¸é¦ + åˆ¤åˆ«ä¼˜åŒ– + è·¯å¾„æ­£åˆ™åŒ–è®¾è®¡ï¼Œåœ¨ä¸ç‰ºç‰²å…¨æ­¥æ€§èƒ½çš„å‰æä¸‹æ˜¾è‘—æå‡äº†å°‘æ­¥ç”Ÿæˆè´¨é‡ï¼Œä¸ºé«˜æ•ˆæ–‡æœ¬ç”Ÿæˆæä¾›äº†æ–°çš„èŒƒå¼ã€‚  
> **å¼€æºåœ°å€**ï¼š[https://github.com/Tyrion58/T3D](https://github.com/Tyrion58/T3D)

</details>

---

### 4. [RL over Commodity Networks: Overcoming the Bandwidth Barrier with Lossless Sparse Deltas](https://arxiv.org/abs/2602.11456)

**Authors**: Chaoyi Ruan, Geng Luo, Xinyi Wan, Long Zhao, Qinghe Wang, Jiaan Zhu, Duling Xu, Guanbin Xu, Dehui Wei, Xiang Liu, Cheng Li, Haifeng Sun, Congcong Miao, Jialin Li  
**Category**: cs.DC  
**Published**: 2026-02-13  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2602.11456v1  

#### Abstract
LLM post-training with reinforcement learning (RL) requires frequent synchronization of large model parameters between the trainer and distributed rollout actors. High-throughput RL post-training therefore relies on dedicated RDMA HPC clusters, an infrastructure cost most organizations cannot absorb...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*RL over Commodity Networks: Overcoming the Bandwidth Barrier with Lossless Sparse Deltas*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¼ºåŒ–å­¦ä¹ ï¼ˆ**Reinforcement Learning, RL**ï¼‰åè®­ç»ƒä¾èµ–äºåœ¨ **Trainer** å’Œåˆ†å¸ƒå¼ **Rollout Actors** ä¹‹é—´é¢‘ç¹åŒæ­¥å¤§è§„æ¨¡æ¨¡å‹å‚æ•°ã€‚å½“å‰ä¸»æµç³»ç»Ÿä¾èµ–é«˜å¸¦å®½ã€ä½å»¶è¿Ÿçš„ **RDMA HPC é›†ç¾¤**ï¼Œè¿™ç±»åŸºç¡€è®¾æ–½æˆæœ¬é«˜æ˜‚ï¼Œå¤§å¤šæ•°å­¦æœ¯æœºæ„å’Œåˆåˆ›å…¬å¸éš¾ä»¥è´Ÿæ‹…ã€‚

ç„¶è€Œï¼Œä½¿ç”¨æ ‡å‡†ä»¥å¤ªç½‘å’Œå¹¿åŸŸç½‘ï¼ˆ**WAN**ï¼‰è¿æ¥çš„â€œæ¾æ•£è€¦åˆâ€GPU èµ„æºï¼ˆå¦‚è·¨äº‘ã€è·¨åŒºåŸŸã€è·¨æœºæ„ï¼‰è™½ç„¶ç»æµçµæ´»ï¼Œä½†å…¶æœ‰é™çš„å¸¦å®½ï¼ˆé€šå¸¸ä¸º 1-10 Gbpsï¼‰å¯¼è‡´å…¨æƒé‡å¹¿æ’­ï¼ˆfull-weight broadcastï¼‰è€—æ—¶æé•¿ï¼ˆä¾‹å¦‚ï¼Œä¸€ä¸ª 8B æ¨¡å‹ä¼ è¾“è¶…è¿‡ 100 ç§’ï¼‰ï¼Œè¿œè¶…ç”Ÿæˆæ—¶é—´ï¼Œé€ æˆ GPU åˆ©ç”¨ç‡æä½ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šSparrowRL
æœ¬æ–‡æå‡º **SparrowRL**ï¼Œä¸€ä¸ªä¸“ä¸ºå•†å“ç½‘ç»œï¼ˆcommodity networksï¼‰è®¾è®¡çš„é«˜æ€§èƒ½ RL è®­ç»ƒç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨ RL æ›´æ–°çš„**é«˜åº¦ç¨€ç–æ€§**ã€‚

#### å…³é”®åˆ›æ–°ç‚¹ï¼š
1. **Lossless Sparse Delta Checkpointsï¼ˆæ— æŸç¨€ç–å¢é‡æ£€æŸ¥ç‚¹ï¼‰**  
   - è§‚å¯Ÿåˆ° RL å¾®è°ƒä¸­æ¯æ­¥ä»…æœ‰çº¦ **1% çš„å‚æ•°å…ƒç´ å‘ç”Ÿå˜åŒ–**ã€‚
   - ä¸å†ä¼ è¾“å®Œæ•´æ¨¡å‹æƒé‡ï¼Œè€Œæ˜¯å°†æ›´æ–°è¡¨ç¤ºä¸º**ç¨€ç–å¢é‡ï¼ˆsparse deltaï¼‰**ï¼Œä»…åŒ…å«å˜åŒ–çš„å‚æ•°åŠå…¶ç²¾ç¡®ä½ç½®ã€‚
   - é‡‡ç”¨ **delta-encoded variable-length indexing** è¿›ä¸€æ­¥å‹ç¼©ç´¢å¼•å…ƒæ•°æ®ï¼Œå®ç°æ— æŸï¼ˆlosslessï¼‰ä¸”é«˜æ•ˆçš„å­˜å‚¨ä¸ä¼ è¾“ã€‚

2. **Streaming Delta Transfer Protocolï¼ˆæµå¼å¢é‡ä¼ è¾“åè®®ï¼‰**  
   - å°†ç¨€ç–å¢é‡åˆ†æ®µï¼Œé€šè¿‡å¤šè·¯å¹¶è¡Œ TCP æµè¿›è¡Œæ¡å¸¦åŒ–ï¼ˆstripingï¼‰ä¼ è¾“ï¼Œæé«˜é“¾è·¯åˆ©ç”¨ç‡ã€‚
   - å®ç° **cut-through forwarding**ï¼šåœ¨ Trainer å®Œæˆæ•´ä¸ªå¢é‡æå–å‰å°±å¼€å§‹ä¼ è¾“å·²ç¼–ç çš„æ®µï¼Œå®ç°æå–ä¸ä¼ è¾“çš„æµæ°´çº¿é‡å ã€‚
   - å¼•å…¥ **Relay-based fanout**ï¼šæ¯ä¸ªåŒºåŸŸæŒ‡å®šä¸€ä¸ª Relay èŠ‚ç‚¹æ¥æ”¶å¢é‡ï¼Œå¹¶åœ¨åŒºåŸŸå†…è½¬å‘ç»™å…¶ä»– Actorsï¼Œå‡å°‘è·¨åŒºåŸŸé€šä¿¡å¼€é”€ã€‚

3. **Heterogeneity-aware Scheduling & Lease-based Fault Tolerance**  
   - **å¼‚æ„æ„ŸçŸ¥è°ƒåº¦**ï¼šæ ¹æ®æ¯ä¸ª Actor çš„å®æ—¶ååé‡å’Œç½‘ç»œå¸¦å®½åŠ¨æ€åˆ†é…ä»»åŠ¡æ‰¹æ¬¡å¤§å°ï¼Œç¡®ä¿æ‰€æœ‰ Actor åœ¨ä¸€ä¸ªç­–ç•¥è¿­ä»£å‘¨æœŸå†…å®Œæˆã€‚
   - **åŸºäºç§Ÿçº¦çš„å®¹é”™**ï¼šä½¿ç”¨æ—¶é—´é™å®šçš„ç§Ÿçº¦ç®¡ç†ä»»åŠ¡ï¼Œè‡ªåŠ¨æ£€æµ‹å¤±è´¥èŠ‚ç‚¹å¹¶é‡æ–°åˆ†é…å·¥ä½œï¼Œé¿å…å…¨å±€é˜»å¡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ‰“ç ´å¯¹ RDMA çš„ä¾èµ–**ï¼šä½¿åœ¨ä½æˆæœ¬ã€è·¨äº‘ã€åœ°ç†åˆ†å¸ƒçš„ GPU èµ„æºä¸Šè¿›è¡Œé«˜æ•ˆ RL è®­ç»ƒæˆä¸ºå¯èƒ½ã€‚
- **ä¿æŒç²¾åº¦**ï¼šé‡‡ç”¨æ— æŸå‹ç¼©ï¼Œä¸è¿›è¡Œé‡åŒ–æˆ–ä¸¢å¼ƒä¿¡æ¯ï¼Œä¿è¯æ¨¡å‹æ›´æ–°çš„æ¯”ç‰¹çº§ç²¾ç¡®æ€§ï¼ˆbit-exactï¼‰ã€‚
- **é«˜ååä¸é«˜æ€§ä»·æ¯”**ï¼šæ˜¾è‘—é™ä½ä¼ è¾“è´Ÿè½½ï¼Œæå‡ç«¯åˆ°ç«¯ååé‡ï¼Œå¹¶å®ç°æ›´é«˜çš„ **tokens per dollar**ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **Hendrycks MATH**ï¼šæ•°å­¦æ¨ç†åŸºå‡†ã€‚
- **GSM8K**ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜æ•°æ®é›†ã€‚
- **DeepScaleR**ï¼šç”¨äºæ‰©å±• RL æ¨ç†èƒ½åŠ›çš„åŸºå‡†ã€‚

### æ¨¡å‹
- **Qwen3 ç³»åˆ—æ¨¡å‹**ï¼š4Bã€8Bã€14B å‚æ•°è§„æ¨¡ã€‚

### å®éªŒè®¾ç½®
- **éƒ¨ç½²ç¯å¢ƒ**ï¼šåœ°ç†åˆ†å¸ƒå¼ GPU éƒ¨ç½²ï¼Œè¦†ç›–åŒ—ç¾ã€æ¬§æ´²ã€äºšå¤ªç­‰åœ°åŒºã€‚
- **ç½‘ç»œæ¡ä»¶**ï¼šä½¿ç”¨è·¨äº‘ WAN é“¾æ¥ï¼Œå¸¦å®½åœ¨ 500 Mbps è‡³ 1 Gbps ä¹‹é—´æ³¢åŠ¨ã€‚
- **ç¡¬ä»¶é…ç½®**ï¼š
  - **Trainer**ï¼šåœ¨ç¾å›½ï¼Œä½¿ç”¨ H100 GPUã€‚
  - **Rollout Actors**ï¼šåˆ†å¸ƒåœ¨åŠ æ‹¿å¤§ç­‰åœ°ï¼Œä½¿ç”¨ A100 æˆ– L40 GPUã€‚
- **RL ç®—æ³•**ï¼šä½¿ç”¨ **GRPO** ç®—æ³•è¿›è¡Œè®­ç»ƒã€‚

### è¯„ä¼°æŒ‡æ ‡
- **Throughput**ï¼šç³»ç»Ÿæ¯ç§’å¤„ç†çš„ token æ•°é‡ï¼ˆtokens/sï¼‰ã€‚
- **Training Step Time**ï¼šå•ä¸ªä¼˜åŒ–å™¨æ­¥éª¤çš„å¢™é’Ÿæ—¶é—´ï¼ˆwall-clock timeï¼‰ã€‚
- **Tokens per Dollar (tokens/$)**ï¼šå•ä½æˆæœ¬ä¸‹çš„ååé‡ï¼Œè¡¡é‡æˆæœ¬æ•ˆç›Šã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
1. **Ideal-SingleDC**ï¼šç†æƒ³åŒ–çš„å•æ•°æ®ä¸­å¿ƒ RDMA åŸºçº¿ï¼ˆ800 Gbps RDMA + NVLinkï¼‰ï¼Œä½œä¸ºæ€§èƒ½ä¸Šé™ã€‚
2. **PrimeRL-Full**ï¼šåœ¨åœ°ç†åˆ†å¸ƒç¯å¢ƒä¸‹å¹¿æ’­å®Œæ•´æ¨¡å‹æƒé‡ã€‚
3. **PrimeRL-MultiStream**ï¼šåœ¨å¤šè·¯ TCP æµä¸Šä¼ è¾“å®Œæ•´æ¨¡å‹æƒé‡ï¼Œæå‡å¸¦å®½åˆ©ç”¨ç‡ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æ¨¡å‹ | æ–¹æ³• | ååé‡ (tokens/s) | æ­¥éª¤æ—¶é—´ (s) | Tokens/$ (Ã—10â¶) |
|------|------|-------------------|--------------|------------------|
| Qwen3-8B | SparrowRL | ~15.9k | ~12 | ~3.60 |
| Qwen3-8B | Ideal-SingleDC | ~16.5k | ~11 | ~2.99 |
| Qwen3-14B | SparrowRL | ~14.0k | ~15 | ~2.12 |
| Qwen3-14B | Ideal-SingleDC | ~14.8k | ~12 | ~1.33 |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ååé‡æå‡**ï¼š
  - ç›¸æ¯” **PrimeRL-Full**ï¼ŒSparrowRL åœ¨ Qwen3-4B ä¸Šæå‡ **2.4â€“3.7Ã—**ï¼Œåœ¨ Qwen3-14B ä¸Šæå‡ **7.7â€“9.5Ã—**ã€‚
- **æ­¥éª¤æ—¶é—´å¤§å¹…ç¼©çŸ­**ï¼š
  - PrimeRL-Full åœ¨ Qwen3-14B ä¸Šæ­¥éª¤æ—¶é—´è¶…è¿‡ **500 ç§’**ï¼Œè€Œ SparrowRL ä»…ä¸º **~15 ç§’**ã€‚
- **æ¥è¿‘ç†æƒ³æ€§èƒ½**ï¼š
  - SparrowRL çš„ååé‡è¾¾åˆ° Ideal-SingleDC çš„ **91.09%â€“98.69%**ï¼Œå³ä»…è½å **1.31%â€“8.91%**ã€‚
- **æˆæœ¬æ•ˆç‡ä¼˜åŠ¿æ˜¾è‘—**ï¼š
  - åœ¨ç›¸åŒååæ°´å¹³ä¸‹ï¼ŒSparrowRL çš„ **tokens per dollar** æ¯”ä¿ç•™çš„ RDMA é›†ç¾¤é«˜å‡º **1.21â€“1.59Ã—**ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **ç¨€ç–ç¼–ç ä¼˜åŒ–**ï¼š
  - ä½¿ç”¨ `uint8` delta ç¼–ç ç›¸æ¯” `int32/64`ï¼Œå°†æ¯æ­¥å¢é‡ä» **414 MB** å‹ç¼©è‡³ **202 MB**ï¼Œä¼ è¾“æ—¶é—´ä» **9.22s** é™è‡³ **4.71s**ã€‚
- **å¤šæµä¼ è¾“ï¼ˆMulti-Streamï¼‰**ï¼š
  - å¯ç”¨å¤šæµåï¼Œä¼ è¾“æ—¶é—´è¿›ä¸€æ­¥é™è‡³ **2.90s**ï¼Œæå‡é“¾è·¯åˆ©ç”¨ç‡ã€‚
- **Relay æœºåˆ¶**ï¼š
  - åœ¨åŠ æ‹¿å¤§-æ¾³å¤§åˆ©äºšéƒ¨ç½²ä¸­ï¼Œä½¿ç”¨ Relay ä½¿ååé‡æå‡ **4.4%â€“13.9%**ï¼Œå°¤å…¶åœ¨ DeepScaleR ä¸Šå¢ç›Šæ›´å¤§ã€‚
- **å¼‚æ„è°ƒåº¦**ï¼š
  - åœ¨æ··åˆ A100 + L40 çš„å¼‚æ„ç¯å¢ƒä¸­ï¼Œå¼‚æ„æ„ŸçŸ¥è°ƒåº¦ç›¸æ¯”å‡åŒ€åˆ†é…ï¼Œååé‡æå‡ **26.4%â€“35.5%**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **RL å‚æ•°æ›´æ–°å…·æœ‰é«˜åº¦ç¨€ç–æ€§**ï¼šæ¯æ­¥ä»…æœ‰çº¦ **1% çš„å‚æ•°å…ƒç´ å‘ç”Ÿå˜åŒ–**ï¼Œè¿™ä¸€ç‰¹æ€§æ˜¯ SparrowRL è®¾è®¡çš„åŸºç¡€ã€‚
2. **ç¨€ç–å¢é‡å¯æœ‰æ•ˆå…‹æœå¸¦å®½ç“¶é¢ˆ**ï¼šé€šè¿‡ä¼ è¾“ç¨€ç– delta è€Œéå®Œæ•´æƒé‡ï¼ŒSparrowRL å°†æ¯æ­¥ä¼ è¾“è´Ÿè½½å‡å°‘ **79Ã—**ï¼ˆQwen3-8Bï¼‰ã€‚
3. **å•†å“ç½‘ç»œä¸Šçš„ RL è®­ç»ƒæ˜¯å¯è¡Œçš„**ï¼šSparrowRL æˆåŠŸå¼¥åˆäº†å•†å“ç½‘ç»œä¸ç†æƒ³ RDMA é›†ç¾¤ä¹‹é—´çš„æ€§èƒ½å·®è·ï¼Œä½¿å…¶æ¥è¿‘ç†æƒ³æ€§èƒ½çš„ **91% ä»¥ä¸Š**ã€‚
4. **æˆæœ¬æ•ˆç›Šæ˜¾è‘—**ï¼šåˆ©ç”¨æŒ‰éœ€è·¨äº‘ GPUï¼ŒSparrowRL å®ç°äº†æ¯”ä¸“ç”¨ RDMA é›†ç¾¤ **æ›´é«˜æ€§ä»·æ¯”** çš„è®­ç»ƒæ–¹æ¡ˆã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–äº RL æ›´æ–°çš„ç¨€ç–æ€§**ï¼šè‹¥æœªæ¥ RL ç®—æ³•å¯¼è‡´æ›´å¯†é›†çš„æ›´æ–°ï¼Œç¨€ç–æ€§å‡è®¾å¯èƒ½ä¸å†æˆç«‹ã€‚
- **CPU å¼€é”€**ï¼šç¨€ç–å¢é‡çš„æå–å’Œç¼–ç å¸¦æ¥é¢å¤–çš„ CPU å¼€é”€ï¼Œè™½è¢«æ©ç›–ä½†ä»å­˜åœ¨ã€‚
- **ä¸­å¿ƒåŒ– Trainer æ¶æ„**ï¼šä»ä¾èµ–ä¸€ä¸ªé«˜æ€§èƒ½ Trainer èŠ‚ç‚¹ï¼Œæœªå®Œå…¨å»ä¸­å¿ƒåŒ–ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **ç»“åˆåˆ†å¸ƒå¼è®­ç»ƒæŠ€æœ¯**ï¼šå°† SparrowRL ä¸è·¨æ•°æ®ä¸­å¿ƒçš„æ¢¯åº¦èšåˆæ–¹æ³•ï¼ˆå¦‚ MASTã€Varunaï¼‰ç»“åˆï¼Œæ”¯æŒæ›´å¤§è§„æ¨¡çš„è®­ç»ƒã€‚
- **æ”¯æŒæ›´å¤š RL ç®—æ³•**ï¼šéªŒè¯ SparrowRL åœ¨å…¶ä»– RLHF ç®—æ³•ï¼ˆå¦‚ PPOã€DPO å˜ä½“ï¼‰ä¸Šçš„é€šç”¨æ€§ã€‚
- **å®Œå…¨å»ä¸­å¿ƒåŒ–æ¶æ„**ï¼šæ¢ç´¢æ— éœ€ä¸­å¿ƒ Trainer çš„å…¨å»ä¸­å¿ƒåŒ– RL è®­ç»ƒæ¡†æ¶ã€‚
- **åŠ¨æ€ç¨€ç–æ€§æ„ŸçŸ¥**ï¼šæ ¹æ®è®­ç»ƒé˜¶æ®µåŠ¨æ€è°ƒæ•´ç¨€ç–ç¼–ç ç­–ç•¥ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–æ€§èƒ½ã€‚

--- 

> **æ€»ç»“**ï¼šSparrowRL é€šè¿‡æ´å¯Ÿ RL æ›´æ–°çš„ç¨€ç–æ€§ï¼Œæå‡ºäº†ä¸€å¥—é¢å‘å•†å“ç½‘ç»œçš„é«˜æ•ˆ RL è®­ç»ƒç³»ç»Ÿï¼Œåœ¨ä¸ç‰ºç‰²ç²¾åº¦çš„å‰æä¸‹ï¼Œæ˜¾è‘—é™ä½äº†å¯¹é«˜å¸¦å®½ç½‘ç»œçš„ä¾èµ–ï¼Œä¸ºå­¦æœ¯ç•Œå’Œä¸­å°ä¼ä¸šæä¾›äº†è¿›è¡Œå‰æ²¿ LLM RL ç ”ç©¶çš„å®ç”¨è·¯å¾„ã€‚

</details>

---

### 5. [MAPLE: Modality-Aware Post-training and Learning Ecosystem](https://arxiv.org/abs/2602.11596)

**Authors**: Nikhil Verma, Minjung Kim, JooYoung Yoo, Kyung-Min Jin, Manasa Bharadwaj, Kevin Ferreira, Ko Keun Kim, Youngjoon Kim  
**Category**: cs.AI  
**Published**: 2026-02-13  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.11596v1  

#### Abstract
Multimodal language models now integrate text, audio, and video for unified reasoning. Yet existing RL post-training pipelines treat all input signals as equally relevant, ignoring which modalities each task actually requires. This modality-blind training inflates policy-gradient variance, slows con...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMAPLE: Modality-Aware Post-training and Learning Ecosystem

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜

å½“å‰çš„ **Multimodal Language Models (MLMs)** åœ¨è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åè®­ç»ƒæ—¶ï¼Œæ™®éé‡‡ç”¨â€œæ¨¡æ€ç›²â€ï¼ˆmodality-blindï¼‰ç­–ç•¥ï¼Œå³å‡è®¾æ‰€æœ‰è¾“å…¥æ¨¡æ€ï¼ˆå¦‚è§†é¢‘ã€éŸ³é¢‘ã€å­—å¹•ï¼‰å¯¹æ‰€æœ‰ä»»åŠ¡éƒ½åŒç­‰é‡è¦ã€‚è¿™ç§åšæ³•å¿½ç•¥äº†ç°å®åœºæ™¯ä¸­ä¸åŒä»»åŠ¡å®é™…ä¾èµ–çš„æ¨¡æ€ç»„åˆæ˜¯ä¸åŒçš„ã€‚ä¾‹å¦‚ï¼š

- æœ‰äº›é—®é¢˜ä»…éœ€è§†è§‰ï¼ˆVï¼‰å³å¯å›ç­”ï¼›
- æœ‰äº›éœ€è¦éŸ³è§†é¢‘ç»“åˆï¼ˆVAï¼‰ï¼›
- æœ‰äº›åˆ™å¿…é¡»ä¾èµ–å…¨éƒ¨ä¸‰ç§æ¨¡æ€ï¼ˆVASï¼‰ã€‚

è¿™ç§ç»Ÿä¸€å¤„ç†æ–¹å¼å¯¼è‡´ä»¥ä¸‹é—®é¢˜ï¼š

- **æ¢¯åº¦æ–¹å·®å¢å¤§**ï¼šæ··åˆå¼‚æ„æ¨¡æ€ç»„åˆä¼šå¼•å…¥ä¸åŒå¥–åŠ±å°ºåº¦å’Œå™ªå£°ç‰¹æ€§ï¼Œå¢åŠ  policy gradient çš„æ–¹å·®ã€‚
- **æ”¶æ•›é€Ÿåº¦æ…¢**ï¼šè®­ç»ƒä¸ç¨³å®šï¼Œä¼˜åŒ–æ•ˆç‡ä½ã€‚
- **é²æ£’æ€§å·®**ï¼šåœ¨æµ‹è¯•æ—¶é‡åˆ°ç¼ºå¤±æ¨¡æ€ï¼ˆmissing-at-testï¼‰æˆ–éƒ¨åˆ†è§‚æµ‹çš„æƒ…å†µæ—¶è¡¨ç°æ€¥å‰§ä¸‹é™ã€‚

---

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯

ä½œè€…æå‡ºäº† **MAPLE** â€”â€”ä¸€ä¸ªå®Œæ•´çš„ **æ¨¡æ€æ„ŸçŸ¥åè®­ç»ƒä¸å­¦ä¹ ç”Ÿæ€ç³»ç»Ÿ**ï¼ˆModality-Aware Post-training and Learning Ecosystemï¼‰ï¼ŒåŒ…å«ä¸‰å¤§æ ¸å¿ƒç»„ä»¶ï¼š

#### ï¼ˆ1ï¼‰MAPLE-benchï¼šé¦–ä¸ªæ˜¾å¼æ ‡æ³¨æœ€å°å¿…è¦æ¨¡æ€çš„åŸºå‡†

- æ•°æ®é›†è¦†ç›–ä¸ƒç§æ¨¡æ€ç»„åˆï¼š`{V, A, S, VA, VS, AS, VAS}`ã€‚
- æ¯ä¸ªæ ·æœ¬éƒ½å¸¦æœ‰ **Required Modality Tags (RMTs)**ï¼Œæ˜ç¡®æ ‡æ³¨è§£å†³è¯¥ä»»åŠ¡æ‰€éœ€çš„æœ€å°æ¨¡æ€å­é›†ã€‚
- æ”¯æŒä¸¤ç§ä»»åŠ¡ï¼š
  - **MAPLE-QA**ï¼šå¤šé¡¹é€‰æ‹©é¢˜é—®ç­”ï¼ˆåˆ¤åˆ«å¼ï¼‰
  - **MAPLE-Caption**ï¼šå¼€æ”¾å¼å¤šæ¨¡æ€æè¿°ç”Ÿæˆï¼ˆç”Ÿæˆå¼ï¼‰
- å¼•å…¥äº†åŠ¨æ€æ¨¡æ€æ‰°åŠ¨ç‰ˆæœ¬ **MAPLE-QA+**ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹åœ¨æ¨¡æ€å†—ä½™æˆ–ç¼ºå¤±ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

#### ï¼ˆ2ï¼‰MAPOï¼šæ¨¡æ€æ„ŸçŸ¥ç­–ç•¥ä¼˜åŒ–æ¡†æ¶ï¼ˆModality-Aware Policy Optimizationï¼‰

- æ ¸å¿ƒæ€æƒ³ï¼šæŒ‰ RMT å¯¹ batch è¿›è¡Œåˆ†å±‚ï¼ˆstratified batchingï¼‰ï¼Œå¹¶åœ¨æ¯ä¸ªå­ç»„å†…ç‹¬ç«‹å½’ä¸€åŒ–ä¼˜åŠ¿å‡½æ•°ï¼ˆadvantage normalizationï¼‰ã€‚
- æ•°å­¦ä¸Šè¯æ˜ï¼š  
  $$
  \text{Var}(g_{\text{MA}}) \leq \text{Var}(g_{\text{MU}})
  $$
  å³æ¨¡æ€æ„ŸçŸ¥è®­ç»ƒèƒ½æœ‰æ•ˆé™ä½æ¢¯åº¦æ–¹å·®ã€‚
- ä¼˜åŒ–è®¾è®¡å››è½´åˆ†æï¼š
  - **Loss aggregation**ï¼šæ¨è sample-level èšåˆä¼˜äº token-levelã€‚
  - **Clipping**ï¼šé‡‡ç”¨éå¯¹ç§°è£å‰ªï¼ˆasymmetric clipping, Îµâº=0.3, Îµâ»=0.2ï¼‰æå‡æ¢ç´¢ç¨³å®šæ€§ã€‚
  - **Sampling**ï¼šæ—©æœŸè¿‡æ»¤é›¶æ–¹å·®æ ·æœ¬æ˜¾è‘—åŠ é€Ÿè®­ç»ƒã€‚
  - **Curriculum learning**ï¼šä»å•æ¨¡æ€åˆ°å¤šæ¨¡æ€é€æ­¥è¿›é˜¶è®­ç»ƒã€‚

#### ï¼ˆ3ï¼‰è‡ªé€‚åº”è®­ç»ƒç­–ç•¥ï¼ˆAdaptive Trainingï¼‰

- **Adaptive weighting**ï¼šåŸºäºå†å² KL æ•£åº¦è¡¡é‡æ¯ç±» RMT çš„éš¾åº¦ï¼Œå¹¶åŠ¨æ€è°ƒæ•´å…¶æŸå¤±æƒé‡ï¼ˆ`adpw`ï¼‰ï¼Œä½¿éš¾ä»»åŠ¡è·å¾—æ›´å¤šæ›´æ–°å¹…åº¦ã€‚
- **Adaptive curriculum**ï¼šæ ¹æ® KL åŠ¨æ€è°ƒåº¦è®­ç»ƒé¡ºåºï¼Œä¼˜å…ˆè®­ç»ƒè¡¨ç°è¾ƒå·®çš„ä»»åŠ¡ï¼ˆ`adpcur`ï¼‰ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | MAPLE ä¼˜åŠ¿ |
|------|-----------|
| **å‡†ç¡®æ€§** | ç¼©å°äº† uni-/multi-modal å‡†ç¡®ç‡å·®è·è¾¾ **30.24%** |
| **æ”¶æ•›é€Ÿåº¦** | æ¯”å…¨ä¿¡å·è®­ç»ƒå¿« **3.18Ã—** |
| **è®­ç»ƒæ•ˆç‡** | æ›´ä½çš„ step-time å’Œæ›´é«˜çš„ wall-clock æ•ˆç‡ |
| **é²æ£’æ€§** | åœ¨æ¨¡æ€ç¼ºå¤±ã€å†—ä½™ç­‰çœŸå®åˆ†å¸ƒåç§»ä¸‹ä¿æŒç¨³å®šæ€§èƒ½ |
| **å¯æ‰©å±•æ€§** | ä¸ä¾èµ–é¢å¤– critic æˆ–è¾…åŠ©æ­£åˆ™é¡¹ï¼Œæ˜“äºéƒ¨ç½² |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†

| æ•°æ®é›† | ç±»å‹ | è§„æ¨¡ | ç‰¹ç‚¹ |
|-------|------|-----|------|
| **MAPLE-QA-train** | QA | 47,893 æ ·æœ¬ | æ¥è‡ª Daily-Omniï¼Œå¸¦ RMT æ ‡ç­¾ï¼Œ4 é€‰ 1 å¤šé¡¹é€‰æ‹© |
| **MAPLE-QA-eval** | QA | 5,001 æ ·æœ¬ | äººå·¥å®¡æ ¸ï¼Œè·¨ 68 ä¸ªè§†é¢‘ |
| **MAPLE-Caption-train** | Captioning | 5,120 æ ·æœ¬ | è‡ªåŠ¨ç”Ÿæˆ |
| **MAPLE-Caption-eval** | Captioning | 5,348 æ ·æœ¬ | äººå·¥æ ¡å‡†ï¼Œæ¯ RMT å‡è¡¡ä¸º 764 æ ·æœ¬ |
| **MAPLE-QA+** | æ‰°åŠ¨å¢å¼ºç‰ˆ | 137,313 æ€»æ ·æœ¬ | åŒ…å« exact/superset/deficit ä¸‰ç§æ¨¡æ€é…ç½®ï¼Œå¼•å…¥ â€œNoneâ€ é€‰é¡¹ä»¥æµ‹è¯• abstention èƒ½åŠ› |

---

### å®éªŒè®¾ç½®

- **æ¨¡å‹**ï¼šQwen2.5-Omni-3Bï¼ˆåŸç”Ÿæ”¯æŒæ–‡æœ¬ã€éŸ³é¢‘ã€è§†é¢‘è¾“å…¥ï¼‰
- **åºåˆ—é•¿åº¦**ï¼š10,240 tokensï¼ˆè¾“å…¥ 8,192 + è¾“å‡º 2,048ï¼‰
- **ä¼˜åŒ–å™¨**ï¼šAdamWï¼Œå­¦ä¹ ç‡ $2 \times 10^{-6}$ï¼Œbatch size 256ï¼ˆmini-batch 32ï¼‰
- **RL è®¾ç½®**ï¼š
  - ä½¿ç”¨ **veRL** åº“å®ç° GRPO
  - æ¯ä¸ª prompt ç”Ÿæˆ G=8 ä¸ªå“åº”ï¼ˆtemperature=1.0, top-p=1.0ï¼‰
  - æ—  KL æ­£åˆ™åŒ–ï¼Œä½¿ç”¨å¯¹ç§°è£å‰ªï¼ˆÂ±0.2ï¼‰ä½œä¸º baseline
- **ç¡¬ä»¶**ï¼š4Ã— NVIDIA H100-80GB

---

### è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | å®šä¹‰ | ç”¨é€” |
|------|------|------|
| **Pass@1 Accuracy** | 5 æ¬¡é‡‡æ ·ä¸­è‡³å°‘ä¸€æ¬¡æ­£ç¡®çš„æ¯”ä¾‹ | QA ä»»åŠ¡ä¸»æŒ‡æ ‡ |
| **LLM-as-Judge Score** | ä½¿ç”¨ GPT-4o å¯¹ç”Ÿæˆ caption æ‰“åˆ†ï¼Œç»¼åˆ missing/hallucination/fusion ä¸‰ä¸ªç»´åº¦ | Captioning ä¸»æŒ‡æ ‡ |
| **Modality Gap (%)** | Uni/Bi/Tri æ¨¡æ€ç»„ä¹‹é—´çš„å¹³å‡å‡†ç¡®ç‡å·®å¼‚ | è¡¡é‡æ¨¡æ€é—´ä¸å¹³è¡¡ç¨‹åº¦ |
| **Training Efficiency** | æ¯æ­¥è€—æ—¶ï¼ˆç§’/stepï¼‰ï¼Œå½’ä¸€åŒ– batch size | åæ˜ è®­ç»ƒæˆæœ¬ |
| **Fusion Gain** | å¤šæ¨¡æ€è¾“å‡ºä¼˜äºæœ€ä½³å•æ¨¡æ€çš„æ¯”ä¾‹ | è¡¡é‡çœŸæ­£èåˆèƒ½åŠ› |
| **Cross-tag Disparity Heatmap** | å„ RMT ä¹‹é—´æ€§èƒ½å·®å¼‚çš„çƒ­åŠ›å›¾ | å¯è§†åŒ–é²æ£’æ€§ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | æè¿° |
|------|------|
| **Zero-shot** | æœªç»åè®­ç»ƒçš„åŸå§‹æ¨¡å‹ |
| **MUPO**ï¼ˆModality-Unaware POï¼‰ | æ¥æ”¶å®Œæ•´ `(V, A, S)` è¾“å…¥ï¼Œæ··åˆæ‰€æœ‰æ¨¡æ€æ‰¹æ¬¡è®­ç»ƒï¼ˆæ ‡å‡† baselineï¼‰ |
| **MAPO**ï¼ˆæœ¬æ–‡æå‡ºï¼‰ | æŒ‰ RMT åˆ†å±‚è®­ç»ƒï¼Œä¿ç•™å„æ¨¡æ€ç»„åˆç»“æ„ |
| **MAPO + adpw/adpcur** | åŠ å…¥è‡ªé€‚åº”åŠ æƒä¸è¯¾ç¨‹è°ƒåº¦ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1â€“3ï¼‰

#### âœ… MAPLE-QA ç»“æœï¼ˆQwen2.5-Omni-3Bï¼‰

| æ–¹æ³• | å¹³å‡ Pass@1 | Modality Gap (%) | Step Time (s) |
|------|------------|------------------|---------------|
| Zero-shot | 39.38% | 8.72 | â€“ |
| MUPOï¼ˆbaselineï¼‰ | 58.58% | 2.27 | 523.28 |
| MAPOï¼ˆåŸºç¡€ï¼‰ | 58.68% | 2.11 | 389.11 |
| **Full-recipe (æœ€ä¼˜)** | **58.72%** | **1.74** | **164.72** |

> ğŸ’¡ **ç»“è®º**ï¼šå°½ç®¡ MAPO æ¥æ”¶æ›´å°‘æ¨¡æ€ä¿¡å·ï¼Œä»ç•¥ä¼˜äº MUPOï¼Œä¸”è®­ç»ƒé€Ÿåº¦å¿« **3.18Ã—**ï¼Œæ¨¡æ€å·®è·ç¼©å°è¿‘ 24%ã€‚

#### âœ… MAPLE-Caption ç»“æœ

| æ–¹æ³• | å¹³å‡ LLM-as-Judge | Fusion Gain |
|------|--------------------|-------------|
| MUPO | 67.67% | â€“ |
| MAPO | 73.88% | 18.19% |
| **MAPO + adpw + adpcur** | **74.00%** | **30.24%** |

> ğŸ’¡ **ç»“è®º**ï¼šè‡ªé€‚åº”ç­–ç•¥è¿›ä¸€æ­¥æå‡ç”Ÿæˆè´¨é‡ï¼Œå¤šæ¨¡æ€èåˆå¢ç›Šå¤§å¹…æå‡ã€‚

#### âœ… è‡ªé€‚åº”ç­–ç•¥æ¶ˆèå®éªŒï¼ˆTable 2 & 3ï¼‰

| é…ç½® | MAPLE-QA Avg | MAPLE-Caption Avg |
|------|--------------|------------------|
| MAPO | 58.68% | 73.88% |
| +adpw | 58.98% | 72.89% |
| +cur | 59.05% | 72.07% |
| **+adpw + adpcur** | **59.82%** | **74.00%** |

> ğŸ“Œ **å‘ç°**ï¼š
> - `adpw` æ˜¾è‘—æå‡ç¡¬ä»»åŠ¡ï¼ˆå¦‚ V, VAï¼‰è¡¨ç°ï¼Œç¼“è§£ scale imbalanceã€‚
> - `adpcur` æé«˜æ•´ä½“ä¸€è‡´æ€§ï¼Œå‡å°‘è·¨æ ‡ç­¾å·®å¼‚ï¼ˆè§ Fig. 4â€“5ï¼‰ã€‚

#### âœ… æ¶ˆèå®éªŒï¼šæ•°æ®å¢å¼ºä¸æ³›åŒ–èƒ½åŠ›ï¼ˆTable 4ï¼‰

| è®­ç»ƒæ•°æ® | å¹³å‡å‡†ç¡®ç‡ |
|---------|----------|
| MAPLE-QAï¼ˆexact onlyï¼‰ | 51.90% |
| **MAPLE-QA+**ï¼ˆexact/superset/deficitï¼‰ | **76.99%** |

> âœ… æ¨¡å‹ä¸ä»…èƒ½æ³›åŒ–åˆ°æœªè§è¿‡çš„æ¨¡æ€ç»„åˆï¼Œè¿˜èƒ½æ­£ç¡®åˆ¤æ–­ä½•æ—¶åº” abstainï¼ˆé€‰æ‹© â€œNoneâ€ï¼‰ï¼Œè¯´æ˜å…·å¤‡çœŸæ­£çš„ **modality-aware reasoning** èƒ½åŠ›ã€‚

#### âœ… æ¶ˆèå®éªŒï¼šContrastive Reward Weighting (CRW)

åº”ç”¨äº captioning ä»»åŠ¡ï¼Œé˜²æ­¢æ¨¡å¼åç¼©ï¼ˆmode collapseï¼‰ï¼š

| æŒ‡æ ‡ | w/o CRW | w/ CRW |
|------|--------|-------|
| Intra-group dispersion | 0.35 â†’ **0.36** | â†‘ å¤šæ ·æ€§ |
| Inter-group separation | 0.41 â†’ **0.46** | â†‘ åŒºåˆ†åº¦ |
| t-SNE å¯è§†åŒ– | ç°‡é‡å ä¸¥é‡ â†’ åˆ†å¸ƒæ›´åˆ†æ•£ï¼ˆFig. 16ï¼‰ | æœ‰æ•ˆç¼“è§£è¡¨ç¤ºåç¼© |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. **æ¨¡æ€åˆ†å±‚è®­ç»ƒè‡³å…³é‡è¦**ï¼š
   - å¿½è§†æ¨¡æ€ä¾èµ–å…³ç³»ä¼šå¯¼è‡´æ¢¯åº¦æ–¹å·®å¤§ã€æ”¶æ•›æ…¢ã€é²æ£’æ€§å·®ã€‚
   - MAPO é€šè¿‡ stratified batching å’Œ group-normalized advantages æ˜¾è‘—æ”¹å–„è¿™äº›é—®é¢˜ã€‚

2. **æœ€ä¼˜è®­ç»ƒé…æ–¹å·²ç¡®ç«‹**ï¼š
   - **Sample-level loss aggregation**
   - **Asymmetric clipping**
   - **Early zero-variance filtering**
   - **Curriculum learning by complexity**

3. **è‡ªé€‚åº”æœºåˆ¶è¿›ä¸€æ­¥çªç ´ç“¶é¢ˆ**ï¼š
   - `adpw` è§£å†³äº†â€œæ˜“ä»»åŠ¡ä¸»å¯¼â€çš„æ¢¯åº¦å€¾æ–œé—®é¢˜ã€‚
   - `adpcur` æ§åˆ¶æ›´æ–°æ—¶æœºï¼Œç¡®ä¿éš¾ä»»åŠ¡ä¸è¢«æ·¹æ²¡ã€‚

4. **çœŸæ­£å®ç°äº†æ¨¡æ€æ„ŸçŸ¥æ¨ç†**ï¼š
   - åœ¨ MAPLE-QA+ ä¸Šè¡¨ç°å‡ºè‰²ï¼Œèƒ½è¯†åˆ«ä¿¡æ¯ä¸è¶³å¹¶ä¸»åŠ¨ abstainã€‚
   - ä¸å†æ˜¯è®°å¿†æ¨¡æ€-æŸ¥è¯¢é…å¯¹ï¼Œè€Œæ˜¯å­¦ä¼šæ ¹æ®è¯æ®å¼ºåº¦åšå‡ºå†³ç­–ã€‚

5. **æ˜¾è‘—æå‡å¤šæ¨¡æ€èåˆèƒ½åŠ›**ï¼š
   - Fusion Gain ä» 18.19% æå‡è‡³ 30.24%ï¼Œè¡¨æ˜æ¨¡å‹çœŸæ­£å­¦ä¼šäº†æ•´åˆäº’è¡¥ä¿¡å·ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§

| å±€é™æ€§ | è¯´æ˜ |
|--------|------|
| **ä¾èµ–é«˜è´¨é‡ RMT æ ‡æ³¨** | å½“å‰ RMT ç”±äººå·¥æˆ–å¼ºæ¨¡å‹æ ‡æ³¨ï¼Œè‡ªåŠ¨åŒ–æ‰“æ ‡ä»æœ‰è¯¯å·®ï¼ˆæ–‡ä¸­æåˆ°çº¦ 74.2% éœ€äººå·¥ä¿®æ­£ï¼‰ã€‚ |
| **CRW ä»…é€‚ç”¨äºè¿ç»­å¥–åŠ±ä»»åŠ¡** | å¦‚ captioningï¼Œæ— æ³•ç›´æ¥ç”¨äºç¦»æ•£ QA ä»»åŠ¡ã€‚ |
| **æœªè€ƒè™‘å®æ—¶æ¨¡æ€ä¸¢åŒ…å»ºæ¨¡** | å½“å‰è®­ç»ƒå‡è®¾æ¨¡æ€å®Œå…¨å¯ç”¨æˆ–å®Œå…¨ç¼ºå¤±ï¼Œå°šæœªæ¨¡æ‹Ÿéƒ¨åˆ†é®æŒ¡ã€å»¶è¿Ÿç­‰å¤æ‚æƒ…å†µã€‚ |
| **è®¡ç®—å¼€é”€ç•¥æœ‰ä¸Šå‡** | å°½ç®¡æ€»æ—¶é—´ä¸‹é™ï¼Œä½†å› åˆ†ç»„ç®¡ç†å¢åŠ äº†è°ƒåº¦å¤æ‚åº¦ã€‚ |

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. **è‡ªåŠ¨ RMT æ¨ç†æœºåˆ¶**ï¼šè®©æ¨¡å‹è‡ªè¡Œæ¨æ–­æ‰€éœ€æ¨¡æ€ï¼Œè€Œéä¾èµ–å¤–éƒ¨æ ‡æ³¨ã€‚
2. **åœ¨çº¿æ¨¡æ€é€‰æ‹©ç­–ç•¥**ï¼šæ„å»ºè½»é‡çº§é—¨æ§æ¨¡å—ï¼Œåœ¨æ¨ç†æ—¶åŠ¨æ€å†³å®šæ¿€æ´»å“ªäº›æ¨¡æ€ã€‚
3. **é¢å‘è¾¹ç¼˜è®¾å¤‡çš„ç¨€ç–æ¿€æ´»è®­ç»ƒ**ï¼šç»“åˆ MBQ ç­‰é‡åŒ–æŠ€æœ¯ï¼Œæ‰“é€ é«˜æ•ˆèŠ‚èƒ½çš„å¤šæ¨¡æ€ agentã€‚
4. **æ‰©å±•è‡³æ›´å¤šæ¨¡æ€**ï¼šåŠ å…¥è§¦è§‰ã€ä½ç½®ã€ä¼ æ„Ÿå™¨ç­‰æ–°å‹è¾“å…¥é€šé“ã€‚
5. **å®‰å…¨ä¸å¯æ§æ€§ç ”ç©¶**ï¼šé˜²æ­¢æ¨¡å‹æ»¥ç”¨å†—ä½™æ¨¡æ€ç”Ÿæˆè¯¯å¯¼æ€§è¾“å‡ºã€‚

---

## æ€»ç»“

ğŸ“Œ **MAPLE æ˜¯é¦–ä¸ªå°†â€œæ¨¡æ€æ„ŸçŸ¥â€è´¯ç©¿äºæ•°æ®ã€ç®—æ³•ã€è®­ç»ƒå…¨æµç¨‹çš„ RL åè®­ç»ƒç”Ÿæ€ç³»ç»Ÿ**ã€‚å®ƒä¸ä»…æå‡äº†æ€§èƒ½ä¸æ•ˆç‡ï¼Œæ›´é‡è¦çš„æ˜¯å¢å¼ºäº†æ¨¡å‹åœ¨çœŸå®ä¸–ç•Œä¸­é¢å¯¹æ¨¡æ€ç¼ºå¤±ã€å†—ä½™ã€å¹²æ‰°æ—¶çš„ **é²æ£’æ€§å’Œå¯ä¿¡åº¦**ã€‚è¯¥å·¥ä½œæ­ç¤ºäº†ä¸€ä¸ªæ·±åˆ»æ´è§ï¼š

> **â€œä¸æ˜¯è¶Šå¤šæ¨¡æ€è¶Šå¥½ï¼Œè€Œæ˜¯è¦ç”¨å¯¹æ¨¡æ€ã€‚â€**

MAPLE ä¸ºä¸‹ä¸€ä»£ **production-ready multimodal agents** æä¾›äº†ä¸€å¥—å®Œæ•´ã€å®ç”¨ã€å¯å¤ç°çš„æŠ€æœ¯è“å›¾ã€‚

</details>

---

### 6. [TSR: Trajectory-Search Rollouts for Multi-Turn RL of LLM Agents](https://arxiv.org/abs/2602.11767)

**Authors**: Aladin Djuhera, Swanand Ravindra Kadhe, Farhan Ahmed, Holger Boche  
**Category**: cs.AI  
**Published**: 2026-02-13  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.11767v1  

#### Abstract
Advances in large language models (LLMs) are driving a shift toward using reinforcement learning (RL) to train agents from iterative, multi-turn interactions across tasks. However, multi-turn RL remains challenging as rewards are often sparse or delayed, and environments can be stochastic. In this r...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šTSR: Trajectory-Search Rollouts for Multi-Turn RL of LLM Agents**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å¤šè½®æ¬¡å¼ºåŒ–å­¦ä¹ ï¼ˆmulti-turn RLï¼‰åœ¨è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ™ºèƒ½ä½“æ—¶é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **ç¨€ç–æˆ–å»¶è¿Ÿå¥–åŠ±**ï¼ˆSparse/Delayed Rewardsï¼‰ï¼šè®¸å¤šä»»åŠ¡ä¸­ï¼Œåªæœ‰åœ¨ä»»åŠ¡å®Œæˆæ—¶æ‰è·å¾—æ­£å‘åé¦ˆï¼Œä¸­é—´æ­¥éª¤æ— æœ‰æ•ˆä¿¡å·ï¼Œå¯¼è‡´ç­–ç•¥æ¢¯åº¦ä¼°è®¡æ–¹å·®é«˜ã€‚
- **ä¸å¯é€†é™·é˜±**ï¼ˆIrreversible Trapsï¼‰ï¼šæ—©æœŸé”™è¯¯å¯èƒ½å¯¼è‡´çŠ¶æ€æ— æ³•æ¢å¤ï¼ˆå¦‚Sokobanä¸­å°†ç®±å­æ¨å…¥æ­»è§’ï¼‰ï¼Œåç»­åŠ¨ä½œæ— æ•ˆã€‚
- **æ¨¡å¼å´©æºƒ**ï¼ˆMode Collapse / Echo Trapï¼‰ï¼šç”±äºä½è´¨é‡rolloutå¯¼è‡´æ¢¯åº¦å‰§çƒˆæ³¢åŠ¨ï¼Œæ¨¡å‹æ€§èƒ½çªç„¶ä¸‹é™ã€‚
- **æ¢ç´¢ä¸åˆ©ç”¨å¤±è¡¡**ï¼šæœ´ç´ çš„éšæœºé‡‡æ ·éš¾ä»¥å¹³è¡¡é«˜è´¨é‡è½¨è¿¹ç”Ÿæˆä¸å¤šæ ·æ€§ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ï¼šTSR (Trajectory-Search Rollouts)**
TSR æ˜¯ä¸€ç§**è®­ç»ƒé˜¶æ®µçš„rolloutç”Ÿæˆæ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> å°†åŸæœ¬ç”¨äºæ¨ç†é˜¶æ®µçš„**test-time scaling**æŠ€æœ¯ï¼ˆå¦‚best-of-Nã€beam searchç­‰ï¼‰è¿ç§»è‡³**è®­ç»ƒé˜¶æ®µçš„rolloutç”Ÿæˆè¿‡ç¨‹**ï¼Œé€šè¿‡è½»é‡çº§æ ‘çŠ¶æœç´¢æ„å»ºæ›´é«˜è´¨é‡çš„è½¨è¿¹ã€‚

#### **å…³é”®æŠ€æœ¯æœºåˆ¶**
- åœ¨æ¯ä¸€è½®å†³ç­–ä¸­ï¼Œå¹¶éç›´æ¥ä»å½“å‰ç­–ç•¥ $\pi_\theta$ é‡‡æ ·å•ä¸€åŠ¨ä½œï¼Œè€Œæ˜¯ï¼š
  1. ç”Ÿæˆå€™é€‰åŠ¨ä½œé›†åˆï¼ˆcandidate action setï¼‰
  2. åˆ©ç”¨ä»»åŠ¡ç›¸å…³çš„è¯„åˆ†å‡½æ•° $S(\cdot)$ å¯¹åŠ¨ä½œæˆ–å‰ç¼€è¿›è¡Œæ‰“åˆ†
  3. åº”ç”¨æœç´¢ç­–ç•¥ï¼ˆå¦‚beam searchï¼‰é€‰æ‹©æœ€ä¼˜è·¯å¾„
- æ”¯æŒå¤šç§æœç´¢ç­–ç•¥ï¼š
  - **Best-of-N**ï¼šç‹¬ç«‹ç”ŸæˆNæ¡å®Œæ•´è½¨è¿¹ï¼Œé€‰æœ€é«˜å›æŠ¥çš„ä¸€æ¡
  - **Beam Search**ï¼šæ¯æ­¥ä¿ç•™Bä¸ªæœ€ä½³éƒ¨åˆ†è½¨è¿¹ï¼Œé€æ­¥æ‰©å±•
  - **Shallow Lookahead**ï¼šå‘å‰æ¨¡æ‹ŸDæ­¥ï¼Œè¯„ä¼°é•¿æœŸæ”¶ç›Šå†åšå†³ç­–

#### **è®¾è®¡ä¼˜åŠ¿**
- **Optimizer-Agnostic**ï¼šä¸æ”¹å˜åº•å±‚ä¼˜åŒ–ç›®æ ‡ï¼ˆå¦‚PPOã€GRPOï¼‰ï¼Œä»…æ›¿æ¢rolloutç”Ÿæˆæ–¹å¼ï¼Œå¯æ— ç¼é›†æˆåˆ°ç°æœ‰RLæ¡†æ¶ã€‚
- **æå‡rolloutè´¨é‡**ï¼šé¿å…â€œä¸å¹¸â€çš„ä½è´¨é‡è½¨è¿¹ä¸»å¯¼è®­ç»ƒä¿¡å·ã€‚
- **ç¨³å®šå­¦ä¹ åŠ¨æ€**ï¼šå‡å°‘æ¢¯åº¦æ–¹å·®ï¼Œé˜²æ­¢Echo Trapã€‚
- **æé«˜æ ·æœ¬æ•ˆç‡**ï¼šç”Ÿæˆçš„è½¨è¿¹æ›´å…·ä»£è¡¨æ€§ï¼ŒåŠ é€Ÿæ”¶æ•›ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹æ³• | å±€é™æ€§ | TSR çš„æ”¹è¿› |
|------|--------|------------|
| **Naive Rollout Sampling** | æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼Œå—éšæœºæ€§å½±å“å¤§ | å¼•å…¥æœç´¢æœºåˆ¶ä¸»åŠ¨æ¢ç´¢é«˜è´¨é‡è·¯å¾„ |
| **Instance Filtering** | åªç­›é€‰ä»»åŠ¡å®ä¾‹ï¼Œä¸ä¼˜åŒ–å•ä¸ªè½¨è¿¹å†…éƒ¨å†³ç­– | åŒæ—¶ä¼˜åŒ–**ä»»åŠ¡å¤šæ ·æ€§**ä¸**è½¨è¿¹è´¨é‡** |
| **Rejection Sampling (e.g., RAFT, GFPO)** | äº‹åè¿‡æ»¤ï¼Œæµªè´¹è®¡ç®—èµ„æº | äº‹å‰å¼•å¯¼ï¼Œé«˜æ•ˆç”Ÿæˆä¼˜è´¨è½¨è¿¹ |
| **Test-Time Search** | æ¨ç†å¼€é”€é«˜ï¼Œéƒ¨ç½²å»¶è¿Ÿå¤§ | å°†æœç´¢â€œè’¸é¦â€è¿›æ¨¡å‹æƒé‡ï¼Œ**è®­ç»ƒæ—¶èŠ±ä¸€æ¬¡é’±ï¼Œæ¨ç†æ—¶æ°¸ä¹…å—ç›Š** |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†ä¸ç¯å¢ƒ**
åœ¨ä¸‰ä¸ªå…·æœ‰ä»£è¡¨æ€§çš„å¤šè½®äº¤äº’ç¯å¢ƒä¸­è¿›è¡Œè¯„ä¼°ï¼š
| ç¯å¢ƒ | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **Sokoban** | ç¡®å®šæ€§é€»è¾‘è°œé¢˜ | å³æ—¶å¥–åŠ±ï¼Œéœ€é¿å…æ­»é”ï¼›æµ‹è¯•ç²¾ç¡®è§„åˆ’èƒ½åŠ› |
| **FrozenLake** | éšæœºå¯¼èˆªæ¸¸æˆ | åŠ¨ä½œæœ‰æ»‘åŠ¨å™ªå£°ï¼Œå¥–åŠ±æåº¦ç¨€ç–ï¼ˆä»…ç»ˆç‚¹+1ï¼‰ |
| **WebShop** | ç½‘é¡µè´­ç‰©ä»£ç† | é•¿å‘¨æœŸä»»åŠ¡ï¼ŒæˆåŠŸä¿¡å·å»¶è¿Ÿï¼Œéœ€è¯­ä¹‰ç†è§£ä¸é¡µé¢å¯¼èˆª |

### **å®éªŒè®¾ç½®**
- **æ¨¡å‹**ï¼šQwen2.5-0.5B å’Œ Qwen2.5-3Bï¼›WebShopä»…ç”¨3Bç‰ˆæœ¬
- **RLç®—æ³•**ï¼š
  - Sokoban ä½¿ç”¨ **PPO**
  - FrozenLake & WebShop ä½¿ç”¨ **GRPO**ï¼ˆæ›´é€‚åˆç¨€ç–å¥–åŠ±ï¼‰
- **è®­ç»ƒæµç¨‹**ï¼š
  - æ¯è½®é‡‡æ · P=16 ä¸ªä»»åŠ¡ç»„ï¼Œæ¯ç»„ç”Ÿæˆ L=16 æ¡è½¨è¿¹
  - æœ€å¤§å›åˆæ•° K=5
  - ä½¿ç”¨ **instance-level filtering**ï¼ˆä¿ç•™rewardæ ‡å‡†å·®æœ€é«˜çš„p=25%çš„ä»»åŠ¡ç»„ï¼‰ä½œä¸ºåŸºç¡€å¢å¼ºæ‰‹æ®µ
- **TSR å‚æ•°é…ç½®**ï¼š
  - **Best-of-N**: N=28 â†’ ä¿ç•™16æ¡
  - **Beam Search**: åˆ†æ”¯å› å­ M=4ï¼ŒæŸå®½ B=2
  - **Lookahead**: M=4, B=2, æ·±åº¦ D=2

### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Success Rate** | åœ¨å›ºå®šéªŒè¯é›†ï¼ˆ256 promptsï¼‰ä¸Šçš„ä»»åŠ¡å®Œæˆç‡ |
| **Average Response Length** | å¹³å‡ç”Ÿæˆtokenæ•°ï¼Œè¡¡é‡æ¨ç†ç®€æ´æ€§ |
| **Average Interaction Turns** | å®Œæˆä»»åŠ¡æ‰€éœ€çš„å¹³å‡äº¤äº’è½®æ¬¡ |
| **Rollout Entropy** | è¾“å‡ºç†µï¼Œåæ˜ æ¢ç´¢ç¨‹åº¦ |
| **Gradient Norm** | æ¢¯åº¦èŒƒæ•°ï¼Œç”¨äºæ£€æµ‹è®­ç»ƒç¨³å®šæ€§ï¼ˆæ˜¯å¦å‡ºç°å°–å³°ï¼‰ |
| **Wall-Clock Time** | æ€»è®­ç»ƒè€—æ—¶ï¼Œåˆ†æå®é™…å¼€é”€ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **Base Model**ï¼šä»…ç›‘ç£å¾®è°ƒåçš„åˆå§‹æ¨¡å‹
- **Instance Filtering**ï¼šå½“å‰ä¸»æµç¨³å®šè®­ç»ƒæ–¹æ³•ï¼Œä»…åšä»»åŠ¡ç­›é€‰
- **TSR variants**ï¼šBest-of-N, Beam Search, Shallow Lookahead

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæœ€ç»ˆæˆåŠŸç‡ï¼‰**

#### **è¡¨1ï¼šSokoban ä¸ FrozenLake ç»“æœ**
| æ–¹æ³• | Sokoban (0.5B) | Sokoban (3B) | FrozenLake (0.5B) | FrozenLake (3B) |
|------|----------------|--------------|-------------------|-----------------|
| Instance Filtering | 29.0% | 43.7% | 19.7% | 48.7% |
| TSR (Best-of-N) | 33.3% | 47.7% | 25.0% | 55.0% |
| TSR (Lookahead) | 36.1% | 49.5% | 27.8% | 57.0% |
| **TSR (Beam Search)** | **38.3%** | **52.3%** | **30.0%** | **60.7%** |

#### **è¡¨2ï¼šWebShop (Qwen2.5-3B) ç»“æœ**
| æ–¹æ³• | Success Rate | Resp. Len â†“ | Turns â†“ |
|------|-------------|-------------|---------|
| Base Model | 3.0% | 747 | 7.7 |
| Instance Filtering | 70.3% | 519 | 6.8 |
| TSR (Best-of-N) | 77.3% | 504 | 6.5 |
| TSR (Lookahead) | 82.3% | 475 | 6.1 |
| **TSR (Beam Search)** | **85.3%** | **453** | **5.8** |

> âœ… **æœ€å¤§ç»å¯¹å¢ç›Šè¾¾15%**ï¼ˆWebShopä¸Šä»70.3%â†’85.3%ï¼‰

---

### **ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ**
- åœ¨æ‰€æœ‰ä»»åŠ¡å’Œæ¨¡å‹è§„æ¨¡ä¸‹ï¼Œ**æ‰€æœ‰TSRå˜ä½“å‡æ˜¾è‘—ä¼˜äºInstance FilteringåŸºçº¿**ã€‚
- **Beam Search è¡¨ç°æœ€å¼º**ï¼Œå°¤å…¶åœ¨å¤æ‚é•¿å‘¨æœŸä»»åŠ¡ï¼ˆWebShopï¼‰ä¸Šé¢†å…ˆæ˜æ˜¾ã€‚
- **Lookahead æ¬¡ä¹‹**ï¼Œé€‚åˆç¡®å®šæ€§ç¯å¢ƒï¼ˆå¦‚Sokobanï¼‰ã€‚
- **Best-of-N æå‡æœ‰é™**ï¼Œå› å…¶ä»ä¾èµ–å®Œæ•´è½¨è¿¹ç”Ÿæˆåå†ç­›é€‰ï¼Œæ— æ³•çº æ­£ä¸­é€”é”™è¯¯ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### **(1) æœç´¢é¢„ç®—æ‰©å±•åˆ†æï¼ˆScaling Search Budgetï¼‰**
- å¢åŠ æŸå®½ **B ä»1åˆ°2** å¸¦æ¥æœ€å¤§æå‡ï¼ˆ+1.7% on Sokoban 3Bï¼‰
- ç»§ç»­å¢åŠ é‡‡æ ·æ•° Mï¼ˆä»2â†’6ï¼‰å¸¦æ¥**è¾¹é™…æ”¶ç›Šé€’å‡**
- è¡¨æ˜ï¼š**é€‚åº¦çš„æœç´¢å³å¯è·å¾—å¤§éƒ¨åˆ†æ”¶ç›Š**ï¼Œæ— éœ€è¿‡åº¦è®¡ç®—

#### **(2) ä¸æ›´å¤§æ¨¡å‹æ¯”è¾ƒï¼ˆTable 3ï¼‰**
| æ¨¡å‹ | Sokoban | FrozenLake |
|------|--------|-----------|
| GPT-4o (zero-shot) | 27.7% | 26.6% |
| Qwen2.5-72B (zero-shot) | 19.5% | 23.8% |
| **Qwen2.5-0.5B + TSR (Beam)** | **38.3%** | **30.0%** |

> ğŸ”¥ **0.5Bå°æ¨¡å‹ + TSR è¶…è¶Š GPT-4o å’Œ 72Bå·¨æ¨¡å‹ï¼**

#### **(3) æ¨ç†æ•ˆç‡æå‡**
- æ‰€æœ‰TSRæ–¹æ³•å‡ç”Ÿæˆ**æ›´çŸ­å“åº”**å’Œ**æ›´å°‘äº¤äº’è½®æ¬¡**
- Beam Search æœ€ä¼˜ï¼šå¹³å‡å‡å°‘ **~20% tokenæ•°** å’Œ **~20% turns**
- ç¤ºä¾‹æ˜¾ç¤ºï¼šTSR-beamèƒ½ç›´æ¥å‘½ä¸­æ­£ç¡®å•†å“å¹¶è´­ä¹°ï¼Œè€ŒåŸºçº¿åå¤å¾ªç¯ç‚¹å‡»è¿‡æ»¤å™¨

#### **(4) è®­ç»ƒç¨³å®šæ€§åˆ†æ**
- **æ¢¯åº¦èŒƒæ•°å¹³ç¨³æ— å°–å³°** â†’ æœªå‘ç”ŸEcho Trap
- **rollout entropyå¹³æ»‘ä¸‹é™** â†’ æ¢ç´¢-åˆ©ç”¨å¹³è¡¡è‰¯å¥½
- **æ”¶æ•›æ›´å¿«**ï¼šå¤šæ•°TSRæ–¹æ³•åœ¨æ›´å°‘è®­ç»ƒæ­¥å†…è¾¾åˆ°80%æ€§èƒ½

#### **(5) å®é™…è®­ç»ƒæ—¶é—´åˆ†æï¼ˆWall-Clock Timeï¼‰**
å°½ç®¡æ¯æ­¥è®¡ç®—æˆæœ¬æ›´é«˜ï¼Œä½†ç”±äº**æ”¶æ•›é€Ÿåº¦åŠ å¿«**ï¼Œ**æ€»è®­ç»ƒæ—¶é—´æ¥è¿‘ç”šè‡³ä¼˜äºåŸºçº¿**ï¼ˆè§App. F.3è¡¨æ ¼ï¼‰ã€‚  
ä¾‹å¦‚åœ¨WebShopä¸Šï¼ŒTSR(Beam)è™½è€—æ—¶æ›´é•¿ï¼ˆ14.94h vs 6.24hï¼‰ï¼Œä½†**æå‰35æ­¥æ”¶æ•›**ï¼Œå•ä½æ—¶é—´æ•ˆç‡æ›´é«˜ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. âœ… **è®­ç»ƒæ—¶å¼•å…¥è½»é‡æœç´¢å¯å¤§å¹…æå‡å¤šè½®RLæ€§èƒ½**ï¼šå³ä½¿åªå¢åŠ ä¸€æ¬¡æ€§çš„è®­ç»ƒè®¡ç®—ï¼Œä¹Ÿèƒ½æ¢æ¥æ˜¾è‘—çš„æ€§èƒ½å¢ç›Šï¼ˆæœ€é«˜+15%ï¼‰å’Œæ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚
2. âœ… **TSRæ˜¯é€šç”¨ä¸”æ¨¡å—åŒ–çš„æ’ä»¶å¼æ–¹æ³•**ï¼šå…¼å®¹PPO/GRPOç­‰å¤šç§optimizerï¼Œæ˜“äºé›†æˆè¿›ç°æœ‰æ¡†æ¶ï¼ˆå¦‚RAGENï¼‰ã€‚
3. âœ… **Beam Searchæ˜¯æœ€æœ‰æ•ˆçš„æœç´¢ç­–ç•¥**ï¼šå› å…¶èƒ½åœ¨æ¯ä¸€æ­¥ç»´æŒå¤šä¸ªå€™é€‰è·¯å¾„ï¼Œå…·å¤‡å®¹é”™èƒ½åŠ›å’Œé•¿æœŸè§„åˆ’æ½œåŠ›ã€‚
4. âœ… **å°æ¨¡å‹+TSRå¯è¶…è¶Šå¤§æ¨¡å‹**ï¼šè¯æ˜äº†**è®­ç»ƒæ•°æ®è´¨é‡ > æ¨¡å‹å‚æ•°é‡**çš„è¶‹åŠ¿ï¼Œåœ¨ç‰¹å®šä»»åŠ¡ä¸Šå®ç°â€œä»¥å·§èƒœåŠ›â€ã€‚
5. âœ… **ä¸ä»…ææ•ˆè¿˜æè´¨**ï¼šTSRä¸ä»…èƒ½æé«˜æˆåŠŸç‡ï¼Œè¿˜èƒ½è®©æ¨¡å‹å­¦ä¼šæ›´ç®€æ´é«˜æ•ˆçš„äº¤äº’è¡Œä¸ºï¼Œé™ä½æ¨ç†å»¶è¿Ÿã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–ä»»åŠ¡ç‰¹å®šè¯„åˆ†å‡½æ•°**ï¼ˆproxy scoreï¼‰ï¼šåœ¨WebShopå’ŒFrozenLakeä¸­éœ€äººå·¥è®¾è®¡å¯å‘å¼åˆ†æ•°ï¼ˆå¦‚è·ç¦»ç›®æ ‡æ›¼å“ˆé¡¿è·ç¦»ã€æ–‡æœ¬ç›¸ä¼¼åº¦ï¼‰ï¼Œå¯èƒ½ä¸å¤Ÿé²æ£’ã€‚
- **è®­ç»ƒè®¡ç®—æˆæœ¬ä¸Šå‡**ï¼šè™½ç„¶æ€»ä½“æ”¶æ•›å¿«ï¼Œä½†å•æ­¥rolloutç”Ÿæˆæ›´æ…¢ï¼Œå¯¹GPUèµ„æºè¦æ±‚æ›´é«˜ã€‚
- **æœç´¢æ·±åº¦å—é™**ï¼šshallow lookaheadå› è®¡ç®—é™åˆ¶åªèƒ½çœ‹å‡ æ­¥ï¼Œéš¾ä»¥åº”å¯¹æé•¿å‘¨æœŸä»»åŠ¡ã€‚
- **æœªå®Œå…¨è§£å†³æ¢ç´¢é—®é¢˜**ï¼šTSRä¾§é‡exploitationï¼Œéœ€é…åˆinstance filteringç­‰æœºåˆ¶ä¿éšœdiversityã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- è®¾è®¡**å¯å­¦ä¹ çš„è¯„åˆ†å‡½æ•°**ï¼ˆlearned scorerï¼‰æ›¿ä»£æ‰‹å·¥è§„åˆ™ï¼Œé€‚åº”æ›´å¤šä»»åŠ¡ã€‚
- æ¢ç´¢**è‡ªé€‚åº”æœç´¢é¢„ç®—åˆ†é…**ï¼šæ ¹æ®ä»»åŠ¡éš¾åº¦åŠ¨æ€è°ƒæ•´beam widthæˆ–lookahead depthã€‚
- ç»“åˆ**åˆ†å±‚RL**æˆ–**è®°å¿†æœºåˆ¶**ï¼Œæ”¯æŒè¶…é•¿å‘¨æœŸä»»åŠ¡ã€‚
- ç³»ç»Ÿç ”ç©¶TSRä¸å…¶ä»–å‰æ²¿æ–¹æ³•ï¼ˆå¦‚Process Reward Modeling, PRMï¼‰çš„ååŒæ•ˆåº”ã€‚
- å°†TSRåº”ç”¨äºçœŸå®ä¸–ç•Œå·¥å…·ä½¿ç”¨ï¼ˆtool-usingï¼‰ã€ä»£ç ç”Ÿæˆã€æœºå™¨äººæ§åˆ¶ç­‰åœºæ™¯ã€‚

---

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> **TSRé€šè¿‡å°†test-time scalingçš„æ€æƒ³å‰ç§»åˆ°è®­ç»ƒé˜¶æ®µçš„rolloutç”Ÿæˆç¯èŠ‚ï¼Œç”¨å°‘é‡é¢å¤–è®­ç»ƒè®¡ç®—æ¢å–æ˜¾è‘—çš„æ€§èƒ½æå‡ã€æ›´å¼ºçš„ç¨³å®šæ€§ä»¥åŠæ›´ä¼˜çš„æ¨ç†æ•ˆç‡ï¼Œæ˜¯ä¸€ç§ç®€å•ã€é€šç”¨ä¸”å¼ºå¤§çš„multi-turn RLå¢å¼ºèŒƒå¼ã€‚**

</details>

---

### 7. [Learn from Your Mistakes: Self-Correcting Masked Diffusion Models](https://arxiv.org/abs/2602.11590)

**Authors**: Yair Schiff, Omer Belhasin, Roy Uziel, Guanghan Wang, Marianne Arriola, Gilad Turok, Michael Elad, Volodymyr Kuleshov  
**Category**: cs.LG  
**Published**: 2026-02-13  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.11590v1  

#### Abstract
Masked diffusion models (MDMs) have emerged as a promising alternative to autoregressive models, enabling parallel token generation while achieving competitive performance. Despite these advantages, MDMs face a fundamental limitation: once tokens are unmasked, they remain fixed, leading to error acc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Learn from Your Mistakes: Self-Correcting Masked Diffusion Models*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
**Masked Diffusion Models (MDMs)** è™½ç„¶åœ¨ç¦»æ•£æ•°æ®ç”Ÿæˆä¸­è¡¨ç°å‡ºè‰²ï¼Œå…·å¤‡å¹¶è¡Œç”Ÿæˆèƒ½åŠ›ï¼Œä½†å­˜åœ¨ä¸€ä¸ªæ ¹æœ¬æ€§ç¼ºé™·ï¼š**ä¸€æ—¦æŸä¸ª token è¢«è§£ç ï¼ˆunmaskedï¼‰ï¼Œå…¶å€¼å°±å›ºå®šä¸å˜**ã€‚è¿™å¯¼è‡´æ—©æœŸç”Ÿæˆé”™è¯¯æ— æ³•è¢«ä¿®æ­£ï¼Œéšç€ç”Ÿæˆè¿‡ç¨‹æ¨è¿›ï¼Œé”™è¯¯ä¸æ–­ç´¯ç§¯ï¼Œæœ€ç»ˆå¯¼è‡´æ ·æœ¬è´¨é‡ä¸‹é™ï¼ˆdistributional driftï¼‰ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šProgressive Self-Correction (ProSeCo)
ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **Progressive Self-Correction (ProSeCo)** çš„æ–°æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- **å°†æ¨¡å‹è‡ªèº«çš„è¾“å‡ºè§†ä¸ºâ€œå¸¦å™ªå£°â€çš„æ•°æ®**ï¼Œå…¶ä¸­çš„é”™è¯¯å³ä¸ºä¸€ç§â€œcorruptionâ€ã€‚
- åœ¨è®­ç»ƒé˜¶æ®µï¼Œ**å¤ç”¨ MDM å»å™ªç½‘ç»œï¼ˆdenoiserï¼‰çš„è¾“å‡ºä½œä¸ºè¾“å…¥ï¼Œè®­ç»ƒåŒä¸€ä¸ªæ¨¡å‹å­¦ä¼šâ€œçº æ­£â€è¿™äº›æ½œåœ¨çš„é”™è¯¯**ã€‚
- åœ¨æ¨ç†é˜¶æ®µï¼Œ**åœ¨æ ‡å‡†çš„ unmasking æ­¥éª¤ä¹‹é—´æ’å…¥é¢å¤–çš„â€œcorrective refinementâ€æ­¥éª¤**ï¼Œå…è®¸æ¨¡å‹åŠ¨æ€ä¿®æ”¹å·²ç”Ÿæˆçš„ tokenã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **ç»Ÿä¸€çš„è®­ç»ƒç›®æ ‡**ï¼šé€šè¿‡ä¸€ä¸ªç®€å•çš„äº¤å‰ç†µï¼ˆcross-entropyï¼‰æŸå¤±é¡¹æ‰©å±•æ ‡å‡† MDM ç›®æ ‡å‡½æ•°ï¼Œå®ç°â€œå»å™ªâ€å’Œâ€œçº é”™â€èƒ½åŠ›çš„è”åˆè®­ç»ƒã€‚
- **æƒé‡å…±äº«ï¼ˆWeight Tyingï¼‰**ï¼šçº é”™å™¨ï¼ˆcorrectorï¼‰å’Œå»å™ªå™¨ï¼ˆdenoiserï¼‰å…±äº«åŒä¸€å¥—å‚æ•°ï¼Œæ— éœ€å¼•å…¥é¢å¤–çš„æ¨¡å‹ï¼ŒèŠ‚çœå†…å­˜ã€‚
- **çµæ´»çš„æ¨ç†æ§åˆ¶**ï¼šç”¨æˆ·å¯é€šè¿‡è°ƒæ•´ `corrector frequency` å’Œ `steps per loop` æ¥æƒè¡¡ç”Ÿæˆé€Ÿåº¦ä¸è´¨é‡ã€‚
- **æ˜¾è‘—æå‡æ•ˆç‡-è´¨é‡æƒè¡¡**ï¼šç›¸æ¯”æ ‡å‡† MDMï¼ŒProSeCo å¯å®ç° **2-3 å€æ›´å¿«çš„é‡‡æ ·é€Ÿåº¦**è€Œè´¨é‡ä¸é™ï¼Œæˆ–é€šè¿‡å¢åŠ è®¡ç®—é‡è¿›ä¸€æ­¥æå‡è´¨é‡ï¼ˆæœ€é«˜è¾¾ **~1.3x æ”¹è¿›**ï¼‰ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **æ•°å­¦ä¸ä»£ç ä»»åŠ¡**ï¼š
  - **rStar-Coder** å’Œ **OpenMathInstruct-2** ç”¨äºå¯¹ LLaDA-Base 8B æ¨¡å‹è¿›è¡Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ã€‚
  - è¯„æµ‹åŸºå‡†ï¼š**HumanEval**, **MBPP**ï¼ˆä»£ç ç”Ÿæˆï¼‰ï¼›**GSM8K**, **Minerva**ï¼ˆæ•°å­¦æ¨ç†ï¼‰ã€‚
- **å¼•å¯¼åˆ†å­è®¾è®¡**ï¼ˆGuided Molecule Designï¼‰ï¼š
  - **QM9** æ•°æ®é›†ï¼Œä½¿ç”¨ SMILES å­—ç¬¦ä¸²è¡¨ç¤ºåˆ†å­ã€‚
  - ä¼˜åŒ–ç›®æ ‡ï¼š**ç¯æ•°ï¼ˆring countï¼‰** å’Œ **è¯ç‰©ç›¸ä¼¼æ€§ï¼ˆQEDï¼‰**ã€‚
- **æ— æ¡ä»¶æ–‡æœ¬ç”Ÿæˆ**ï¼ˆUnconditional Text Generationï¼‰ï¼š
  - **OpenWebText (OWT)** æ•°æ®é›†ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹æ¶æ„**ï¼šåŸºäº LLaDA-Base 8B å’Œ DiT-style backboneã€‚
- **è®­ç»ƒ**ï¼šä½¿ç”¨ ProSeCo çš„æ‰©å±•ç›®æ ‡å‡½æ•°è¿›è¡Œè®­ç»ƒï¼ŒåŒ…å«æ ‡å‡† MDM æŸå¤±å’Œè‡ªçº é”™æŸå¤±ã€‚
- **é‡‡æ ·ç®—æ³•**ï¼šåœ¨æ ‡å‡† MDM é‡‡æ ·è¿‡ç¨‹ä¸­ï¼ŒæŒ‰è®¾å®šé¢‘ç‡ `w` æ’å…¥ `S` æ­¥çš„çº é”™å¾ªç¯ï¼ˆAlgorithm 3ï¼‰ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Pass@1 å‡†ç¡®ç‡**ï¼ˆHumanEval, MBPP, GSM8K, Minervaï¼‰ã€‚
  - **MAUVE**ï¼ˆè¡¡é‡ç”Ÿæˆæ–‡æœ¬ä¸äººç±»æ–‡æœ¬çš„åˆ†å¸ƒå·®è·ï¼‰ã€‚
  - **ç”Ÿæˆå›°æƒ‘åº¦ï¼ˆGen. PPLï¼‰** å’Œ **åºåˆ—ç†µï¼ˆEntropyï¼‰**ï¼ˆè¡¡é‡è´¨é‡å’Œå¤šæ ·æ€§ï¼‰ã€‚
  - **æœ‰æ•ˆæ ·æœ¬æ•°**ï¼ˆValid, Unique, Novelï¼‰åŠå…¶å¹³å‡å±æ€§å€¼ï¼ˆåˆ†å­è®¾è®¡ï¼‰ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Off-the-shelf æ¨¡å‹**ï¼šLlama3.1-Instruct, LLaDA1.5ã€‚
- **MDM åŸºçº¿**ï¼šLLaDA-Base, LLaDA-Instructã€‚
- **å¸¦çº é”™æœºåˆ¶çš„ MDM**ï¼šReMDM, PRISMã€‚
- **å…¶ä»–ç”ŸæˆèŒƒå¼**ï¼šAutoregressive (AR) æ¨¡å‹, Uniform Categorical Noise Diffusion (UDLM)ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”
åœ¨ **Table 1** ä¸­ï¼ŒProSeCo è¡¨ç°å…¨é¢é¢†å…ˆï¼š
- **ä»…ä½¿ç”¨ SFT è®­ç»ƒï¼ˆä¸å¯ç”¨é‡‡æ ·çº é”™ï¼‰**ï¼šProSeCo SFT å·²è¶…è¶Šæ‰€æœ‰åŸºçº¿ï¼ˆå¦‚ Vanilla SFT åœ¨ HumanEval ä¸Šä» 48.17 æå‡è‡³ 52.44ï¼‰ã€‚
- **ç»“åˆ ProSeCo é‡‡æ ·**ï¼šæ€§èƒ½å¤§å¹…æå‡ï¼Œåœ¨ HumanEval ä¸Šè¾¾åˆ° **62.20**ï¼ŒMBPP è¾¾åˆ° **50.20**ï¼ŒGSM8K è¾¾åˆ° **82.18**ï¼ŒMinerva è¾¾åˆ° **35.10**ï¼Œ**è¶…è¶ŠåŒè§„æ¨¡ AR æ¨¡å‹ï¼ˆLlama3.1-Instructï¼‰åœ¨ 3/4 ä»»åŠ¡ä¸Šçš„è¡¨ç°**ã€‚

### æ•ˆç‡-è´¨é‡æƒè¡¡åˆ†æï¼ˆFigure 3ï¼‰
- **Fast æ¨¡å¼**ï¼šé€šè¿‡å¢åŠ å¹¶è¡Œè§£ç ï¼Œå‡å°‘ unmasking æ­¥éª¤ï¼Œå¹¶è¾…ä»¥çº é”™ï¼Œå¯å®ç° **2-3 å€åŠ é€Ÿ**ï¼ˆNFEs æ˜¾è‘—é™ä½ï¼‰ä¸”ä¿æŒç”šè‡³è¶…è¿‡åŸºçº¿å‡†ç¡®ç‡ã€‚
- **Balanced æ¨¡å¼**ï¼šåœ¨é€‚åº¦å¢åŠ è®¡ç®—é‡ä¸‹ï¼Œè·å¾—æœ€ä½³æƒè¡¡ã€‚
- **Max æ¨¡å¼**ï¼šé€šè¿‡å¤§å¹…å¢åŠ æ¨ç†æ—¶è®¡ç®—é‡ï¼ˆinference-time compute scalingï¼‰ï¼Œå¯å°†æ€§èƒ½æ¨è‡³æœ€é«˜ï¼Œè¯æ˜äº† ProSeCo å…·å¤‡è‰¯å¥½çš„**å¯æ‰©å±•æ€§**ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **çº é”™é¢„ç®—é…ç½®**ï¼ˆAppendix C.3, Figure 8ï¼‰ï¼š
  - åœ¨é«˜å¹¶è¡Œåº¦ï¼ˆå¿«é€Ÿé‡‡æ ·ï¼‰åœºæ™¯ä¸‹ï¼Œéœ€è¦æ›´é¢‘ç¹çš„çº é”™ï¼ˆ`w â‰¥ T/16`ï¼‰æ¥æŠµæ¶ˆè´¨é‡ä¸‹é™ã€‚
  - å¯¹äºå›ºå®šçš„æ€»çº é”™æ­¥æ•°ï¼Œ**æ›´é¢‘ç¹ä½†æ›´çŸ­çš„çº é”™å¾ªç¯é€šå¸¸æ›´æœ‰æ•ˆ**ã€‚
- **å¹³è¡Œè§£ç çš„å¸•ç´¯æ‰˜å‰æ²¿**ï¼ˆFigure 4ï¼‰ï¼šæ ‡å‡† MDM éšç€å¹¶è¡Œåº¦å¢åŠ è´¨é‡æ€¥å‰§ä¸‹é™ï¼Œè€Œ ProSeCo èƒ½æœ‰æ•ˆæ¢å¤é”™è¯¯ï¼Œæ˜¾è‘—æ”¹å–„äº†å¹³è¡Œè§£ç ä¸è´¨é‡ä¹‹é—´çš„å¸•ç´¯æ‰˜å‰æ²¿ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **é”™è¯¯çº æ­£æ˜¯æå‡ MDM æ€§èƒ½çš„å…³é”®**ï¼šå…è®¸æ¨¡å‹åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­â€œè‡ªæˆ‘ä¿®æ­£â€å·²è¢«è¯æ˜æ˜¯è§£å†³é”™è¯¯ç´¯ç§¯é—®é¢˜çš„æœ‰æ•ˆé€”å¾„ã€‚
2. **ProSeCo æå¤§åœ°æ”¹è¿›äº†æ•ˆç‡-è´¨é‡æƒè¡¡**ï¼šå®ƒä¸ä»…èƒ½åœ¨æ›´å°‘çš„å‡½æ•°è°ƒç”¨ï¼ˆNFEsï¼‰ä¸‹è¾¾åˆ°æ›´é«˜æ€§èƒ½ï¼Œè¿˜èƒ½é€šè¿‡å¢åŠ æ¨ç†è®¡ç®—é‡æ¥æŒç»­æå‡è´¨é‡ï¼Œè¿™æ˜¯æ ‡å‡† MDM æ— æ³•åšåˆ°çš„ã€‚
3. **æ–¹æ³•é€šç”¨æ€§å¼º**ï¼šåœ¨æ¡ä»¶ç”Ÿæˆï¼ˆä»£ç ã€æ•°å­¦ï¼‰ã€å¼•å¯¼ç”Ÿæˆï¼ˆåˆ†å­è®¾è®¡ï¼‰å’Œæ— æ¡ä»¶ç”Ÿæˆï¼ˆæ–‡æœ¬ï¼‰ç­‰å¤šç§ä»»åŠ¡ä¸Šå‡å–å¾—ä¸€è‡´ä¸”æ˜¾è‘—çš„æå‡ã€‚

### å±€é™æ€§
- **è®­ç»ƒæˆæœ¬å¢åŠ **ï¼šç”±äºéœ€è¦é¢å¤–çš„å‰å‘ä¼ æ’­æ¥è®¡ç®—çº é”™æŸå¤±ï¼Œ**è®­ç»ƒæ—¶çš„è®¡ç®—å¼€é”€æœ‰æ‰€å¢åŠ **ï¼Œå°½ç®¡ä½œè€…è®¤ä¸ºè¿™ä¸€ä»£ä»·åœ¨ä¸‹æ¸¸ä»»åŠ¡æ”¶ç›Šé¢å‰æ˜¯å€¼å¾—çš„ã€‚
- **ä¾èµ– argmax é‡‡æ ·**ï¼šå½“å‰æ–¹æ³•ä¾èµ–äº argmax é‡‡æ ·æ¥æ„å»ºçº é”™è¾“å…¥ï¼Œå¯èƒ½é™åˆ¶äº†å…¶æ¢ç´¢èƒ½åŠ›ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **åˆ†ç¦»çº é”™ä¸å»å™ªæ¨¡å‹**ï¼šæ¢ç´¢è§£é™¤æƒé‡ç»‘å®šï¼ˆweight untyingï¼‰ï¼Œæˆ–ä¸ºçº é”™å’Œå»å™ªè®¾è®¡å®Œå…¨ç‹¬ç«‹çš„ç½‘ç»œéª¨å¹²ã€‚
- **æ›´å¤æ‚çš„çº é”™ç­–ç•¥**ï¼šå¼€å‘æ›´ sophisticated çš„æ–¹æ¡ˆæ¥è”åˆè°ƒåº¦çº é”™å’Œè§£ç æ­¥éª¤ï¼Œä¾‹å¦‚åŸºäºç½®ä¿¡åº¦çš„åŠ¨æ€å†³ç­–ã€‚
- **æ‰©å±•åˆ°å…¶ä»–æ¨¡æ€**ï¼šå°† ProSeCo æ¡†æ¶åº”ç”¨äºå›¾åƒã€éŸ³é¢‘ç­‰å…¶ä»–é¢†åŸŸçš„ç¦»æ•£æ‰©æ•£æ¨¡å‹ã€‚

</details>

---

### 8. [Improved state mixing in higher-order and block diagonal linear recurrent networks](https://arxiv.org/abs/2602.12021)

**Authors**: Igor Dubinin, Antonio Orvieto, Felix Effenberger  
**Category**: cs.LG  
**Published**: 2026-02-13  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.12021v1  

#### Abstract
Linear recurrent networks (LRNNs) and linear state space models (SSMs) promise computational and memory efficiency on long-sequence modeling tasks, yet their diagonal state transitions limit expressivity. Dense and nonlinear architectures (e.g., LSTMs) on the other hand are provably more expressive,...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šImproved State Mixing in Higher-order and Block Diagonal Linear Recurrent Networks**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
ç°ä»£ **Linear Recurrent Networks (LRNNs)** å’Œ **State Space Models (SSMs)** è™½ç„¶åœ¨é•¿åºåˆ—å»ºæ¨¡ä¸­å…·æœ‰è®¡ç®—å’Œå†…å­˜æ•ˆç‡ä¼˜åŠ¿ï¼Œä½†ç”±äºå…¶çŠ¶æ€è½¬ç§»çŸ©é˜µé€šå¸¸ä¸º**å¯¹è§’å½¢å¼**ï¼Œå¯¼è‡´è¡¨è¾¾èƒ½åŠ›å—é™ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå¯†é›†æˆ–éçº¿æ€§æ¶æ„ï¼ˆå¦‚ LSTMï¼‰è™½ç„¶è¡¨è¾¾åŠ›æ›´å¼ºï¼Œä½†è®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚

æœ¬æ–‡æ—¨åœ¨æ¢ç´¢å¦‚ä½•åœ¨ä¿æŒé«˜æ•ˆæ€§çš„å‰æä¸‹ï¼Œé€šè¿‡**æ›´ä¸°å¯Œçš„çŠ¶æ€æ··åˆæœºåˆ¶**æå‡ LRNNs çš„è¡¨è¾¾èƒ½åŠ›ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯**
ä½œè€…æå‡ºäº†ä¸¤ç§æ–°å‹ç»“æ„åŒ– LRNN æ¶æ„ï¼š

#### **(i) Higher-order Linear Recurrent Units (H-LRU)**
- å°†ä¼ ç»Ÿçš„ä¸€é˜¶é€’æ¨æ¨å¹¿åˆ° **m é˜¶é€’æ¨**ï¼Œå³å½“å‰çŠ¶æ€ç”±å‰ `m` ä¸ªéšè—çŠ¶æ€åŠ æƒç»„åˆè€Œæˆï¼š
  $$
  h_t = \sum_{i=1}^m a_{i,t} \odot h_{t-i} + a_{0,t} \odot v_t
  $$
- è¿™ç§é«˜é˜¶ç»“æ„å…è®¸æ¨¡å‹åœ¨æ—¶é—´ç»´åº¦ä¸Šè¿›è¡Œæ›´å¤æ‚çš„è®°å¿†æ•´åˆï¼Œå¢å¼ºäº†å¯¹é•¿æœŸä¾èµ–çš„å»ºæ¨¡èƒ½åŠ›ã€‚

#### **(ii) Block-Diagonal LRUs (BD-LRU)**
- åœ¨é€šé“ç»´åº¦ä¸Šå¼•å…¥**å—å¯¹è§’ç»“æ„**ï¼Œæ¯ä¸ªå—å†…å®ç°**å…¨è¿æ¥çš„çŠ¶æ€è½¬ç§»çŸ©é˜µ**ï¼Œä»è€Œæ”¯æŒå¯†é›†çš„é€šé“é—´ä¿¡æ¯æ··åˆã€‚
- æ¯ä¸ª block å†…éƒ¨æ˜¯ä¸€ä¸ª $m \times m$ çš„ç¨ å¯†çŸ©é˜µï¼Œä¸åŒ blocks ä¹‹é—´æ— äº¤äº’ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç‰¹æ€§ | H-LRU | BD-LRU |
|------|-------|--------|
| **è¡¨è¾¾èƒ½åŠ›å¢å¼ºæ–¹å¼** | æ—¶é—´ç»´åº¦ä¸Šçš„å¤šæ­¥å†å²æ··åˆ | é€šé“ç»´åº¦ä¸Šçš„å—å†…å¯†é›†æ··åˆ |
| **å‚æ•°æ•ˆç‡** | æ›´é«˜ï¼ˆå°¤å…¶åœ¨å‹ç¼©ä»»åŠ¡ä¸­ï¼‰ | è¾ƒä½ä½†æ€§èƒ½æ›´å¼º |
| **å¯æ‰©å±•æ€§** | æ”¯æŒ moderate window size æ‰©å±• | æ”¯æŒ moderate block size æ‰©å±• |
| **å®ç°æ•ˆç‡** | å¹³è¡Œæ‰«æï¼ˆparallel-scanï¼‰ä¿æŒé«˜æ•ˆ | åŒæ ·æ”¯æŒ parallel-scanï¼Œååé‡æ¥è¿‘å¯¹è§’æ¨¡å‹ |

æ­¤å¤–ï¼Œä½œè€…æå‡ºäº†ä¸€ç§**è”åˆé—¨æ§å½’ä¸€åŒ–ç­–ç•¥ï¼ˆper-row L1-normalizationï¼‰**ï¼Œç¡®ä¿è®­ç»ƒç¨³å®šæ€§ï¼Œå¹¶å…è®¸å®‰å…¨åœ°æ‰©å¤§ window/block sizeã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**

#### **åˆæˆä»»åŠ¡ï¼ˆSynthetic Tasksï¼‰**
åŸºäº MAD benchmark (Mechanistic Architecture Design)ï¼Œç”¨äºå¿«é€Ÿè¯„ä¼°æ¶æ„æ½œåŠ›ï¼š

1. **Compression Task**  
   - è¾“å…¥éšæœº token åºåˆ— â†’ ç¼–ç ä¸ºå•ä¸ªèšåˆ token â†’ è§£ç è¿˜åŸåŸåºåˆ—  
   - æµ‹è¯•æ¨¡å‹çš„ä¿¡æ¯å‹ç¼©ä¸é‡å»ºèƒ½åŠ›  

2. **Selective Copying Task**  
   - å¤åˆ¶ç‰¹å®šä½ç½®çš„ token åˆ°è¾“å‡ºï¼Œå¿½ç•¥å™ªå£°  
   - æµ‹è¯•é€‰æ‹©æ€§æ—¶åºé›†æˆèƒ½åŠ›  

3. **In-context Recall Task**  
   - ç»™å®š key-value å¯¹åºåˆ—ï¼Œæ ¹æ® query æ£€ç´¢å¯¹åº” value  
   - æµ‹è¯•ä¸Šä¸‹æ–‡å­¦ä¹ ä¸åŠ¨æ€æ£€ç´¢èƒ½åŠ›  

4. **Permutation Composition Tasks (S3â€“S5)**  
   - å­¦ä¹ ä»è¾“å…¥åºåˆ—åˆ°æ’åˆ—åè¾“å‡ºçš„æ˜ å°„ï¼ŒåŸºäºå¯¹ç§°ç¾¤ $S_n$  
   - æµ‹è¯•å¤æ‚ç»“æ„å½’çº³ä¸çŠ¶æ€è¿½è¸ªèƒ½åŠ›  

5. **Chomsky Hierarchy Tasks**  
   - åŒ…æ‹¬ Parityã€Cycle Navigationã€Modular Arithmeticï¼ˆå¸¦/ä¸å¸¦æ‹¬å·ï¼‰ç­‰  
   - æµ‹è¯•å½¢å¼è¯­è¨€å±‚çº§ä¸­çš„è®¡ç®—èƒ½åŠ›  

#### **çœŸå®è¯­è¨€å»ºæ¨¡ä»»åŠ¡**
- **FineWeb æ•°æ®é›†**  
  - ç”¨äºå¤§è§„æ¨¡è¯­è¨€å»ºæ¨¡å®éªŒï¼Œè¯„ä¼° perplexity å’Œ scaling behavior

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

| è®¾ç½®é¡¹ | æè¿° |
|--------|------|
| **æ¨¡å‹é…ç½®** | å•å±‚ç»“æ„ï¼Œæœ€å¤§éšè—ç»´åº¦ 6144ï¼›H-LRU window size $m \in [1,16]$ï¼ŒBD-LRU block size $m \in [1,16]$ |
| **ä¼˜åŒ–å™¨** | AdamWï¼Œcosine learning rate scheduleï¼Œåˆå§‹ LR âˆˆ {0.001, 0.0005, 0.0001} |
| **è¯„ä¼°æŒ‡æ ‡** | - åˆ†ç±»ä»»åŠ¡ï¼šå¹³å‡æµ‹è¯•å‡†ç¡®ç‡ï¼ˆaccuracyï¼‰<br>- è¯­è¨€å»ºæ¨¡ï¼šperplexity<br>- æ•ˆç‡ï¼šFLOPs / throughputï¼ˆtokens/secï¼‰ |
| **ç¡¬ä»¶å¹³å°** | NVIDIA A100/H100 GPUs |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **Diagonal LRNNs**: Mamba2, DeltaNet, DeltaProduct4
- **ç»å…¸ RNNs**: LSTM
- **å…¶ä»–ç»“æ„åŒ–æ¨¡å‹**: Deltanet (low-rank), Mamba (selective SSM)

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **è¡¨1ï¼šåˆæˆä»»åŠ¡ç»¼åˆè¡¨ç°ï¼ˆAccuracyï¼‰**
| Model | Recall | Copy | Compress | **Overall** |
|-------|--------|------|----------|------------|
| LSTM | 1.000 | 1.000 | 0.750 | **0.916** |
| Mamba2 | 1.000 | 0.807 | 0.720 | 0.842 |
| Deltanet | 1.000 | 0.892 | 0.782 | 0.892 |
| **BD-LRU m5 (ours)** | **1.000** | **0.985** | **0.782** | **0.922** âœ… |
| H-LRU m5 | 1.000 | 0.838 | 0.775 | 0.871 |

> âœ… **BD-LRU åœ¨æ€»ä½“æ€§èƒ½ä¸Šè¶…è¶Šæ‰€æœ‰ baselineï¼ŒåŒ…æ‹¬ LSTM**

---

#### **è¡¨2ï¼šPermutation Composition ä»»åŠ¡è¡¨ç°**
| Model | S3 (10k) | S4 (50k) | **S5 (100k)** |
|-------|-----------|-----------|----------------|
| LSTM | 1.000 | 1.000 | 1.000 |
| Mamba2 | 0.660 | 0.430 | 0.260 |
| Deltanet | 1.000 | 0.470 | 0.140 |
| **BD-LRU m5 (ours)** | **1.000** | **1.000** | **1.000** âœ… |

> âœ… **BD-LRU m5 ä»…ç”¨ ~200K å‚æ•°å³å¯å®Œç¾è§£å†³ S5 ä»»åŠ¡ï¼Œæ ·æœ¬æ•ˆç‡æé«˜**

---

#### **è¯­è¨€å»ºæ¨¡ï¼ˆFineWebï¼‰**
- **BD-LRU (m=4,8)** åœ¨ 210M å‚æ•°ä¸‹è¾¾åˆ°æœ€ä½ **perplexity**
- **H-LRU å‚æ•°æ•ˆç‡æ›´é«˜**ï¼Œä½†éœ€å¢å¤§ hidden dimension æ¥åŒ¹é…å‚æ•°é‡ï¼Œå¯¼è‡´è®¡ç®—å¼€é”€ä¸Šå‡
- **Moderate block size (m=2â€“8)** è¡¨ç°æœ€ä¼˜ï¼Œè¿‡å¤§ï¼ˆm=16ï¼‰åè€Œä¸‹é™

---

### **æ¶ˆèå®éªŒç»“æœ**

#### **å½’ä¸€åŒ–ç­–ç•¥çš„å½±å“ï¼ˆFig. 2ï¼‰**
- **L1-normalizationï¼ˆsoftmax/sigmoidï¼‰æ˜¾è‘—æå‡æ€§èƒ½**
- æ— å½’ä¸€åŒ–æˆ– ReLU å½’ä¸€åŒ–æ•ˆæœå·®
- å½’ä¸€åŒ–ä½¿æ¨¡å‹èƒ½ç¨³å®šæ‰©å±• window/block size

#### **Selectivity æ¶ˆèï¼ˆAppendix Fï¼‰**
- ç§»é™¤ selectivity åï¼Œåœ¨ selective copyingã€recall ç­‰ä»»åŠ¡ä¸Šæ€§èƒ½å´©æºƒ
- ä½†åœ¨ compression ä»»åŠ¡ä¸­ï¼Œnon-selective H-LRU ä»å¯é€šè¿‡å¤§ window size å®ç°è¾ƒå¥½å‹ç¼©ï¼Œæ˜¾ç¤ºå…¶å¼ºå½’çº³åç½®

#### **Block Size Scaling åˆ†æ**
- æ€§èƒ½éš block/window size å¢åŠ å…ˆå‡åé™ï¼Œ**æœ€ä½³å€¼é›†ä¸­åœ¨ m=3â€“5**
- è¿‡å¤§çš„ block size å¯¼è‡´è¿‡æ‹Ÿåˆæˆ–è®­ç»ƒä¸ç¨³å®š
- BD-LRU åœ¨ autoregressive ä»»åŠ¡ä¸­ scaling æ›´ä¼˜ï¼ŒH-LRU åœ¨ compression ä¸­æ›´é«˜æ•ˆ

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. âœ… **çŠ¶æ€æ··åˆç»“æ„æ¯”å•çº¯å¢åŠ å®½åº¦æ›´èƒ½å†³å®šè¡¨è¾¾èƒ½åŠ›**
   - ç»“æ„åŒ–çš„ state mixingï¼ˆæ—¶é—´æˆ–å¤šé€šé“ï¼‰æ˜¯æå‡ LRNN è¡¨è¾¾åŠ›çš„å…³é”®
   - å®½åº¦æ‰©å±•æ— æ³•å¼¥è¡¥ç»“æ„é™åˆ¶

2. âœ… **BD-LRU æ˜¯ç»¼åˆæ€§èƒ½æœ€å¼ºçš„æ¶æ„**
   - åœ¨ selective copyingã€permutationã€language modeling ä¸­å‡è¾¾åˆ° SOTA
   - å…·å¤‡å¼ºå¤§çš„ sample efficiency å’Œ parameter utilization

3. âœ… **H-LRU æ˜¯æœ€å‚æ•°é«˜æ•ˆçš„æ¶æ„**
   - åœ¨ compression ä»»åŠ¡ä¸­ä»¥æ›´å°‘å‚æ•°è¶…è¶Š Mamba å’Œ LSTM
   - é«˜é˜¶é€’æ¨æä¾›äº†ä¼˜ç§€çš„å‹ç¼©å…ˆéªŒ

4. âœ… **Moderate block/window sizes æœ€ä¼˜**
   - m=2â€“8 æä¾›æœ€ä½³ expressivity-efficiency trade-off
   - è¿‡å¤§åè€ŒæŸå®³æ€§èƒ½ï¼Œå°¤å…¶åœ¨å‹ç¼©ä»»åŠ¡ä¸­

5. âœ… **Parallel-scan å®ç°ç»´æŒé«˜åå**
   - å°½ç®¡ç†è®ºå¤æ‚åº¦ä¸Šå‡ï¼Œä½†åˆ©ç”¨ block-diagonal ç»“æ„å¯å°† parallel-scan å¤æ‚åº¦é™è‡³ $O(H m^3 \log T)$
   - å®é™…è¿è¡Œé€Ÿåº¦ä¸ diagonal LRNNs æ¥è¿‘

---

### **æ–¹æ³•çš„å±€é™æ€§**
1. **è®¡ç®—æ•ˆç‡éš batch size å¢åŠ ä¸‹é™è¾ƒå¿«**
   - ç›¸æ¯”é«˜åº¦ä¼˜åŒ–çš„ Mambaï¼Œæœ¬æ–¹æ³•åœ¨å¤§ batch ä¸‹ GPU åˆ©ç”¨ç‡è¾ƒä½
2. **æœªè¦†ç›–æ‰€æœ‰ gate parameterization ç©ºé—´**
   - å½“å‰ä»…æµ‹è¯•äº† softmax/sigmoid/ReLU ç­‰å¸¸è§å½¢å¼
3. **éš¾ä»¥å¤„ç†éœ€è¦éçº¿æ€§æ¨ç†çš„ä»»åŠ¡**
   - å¦‚å¸¦æ‹¬å·çš„ modular arithmetic ä»å…·æŒ‘æˆ˜ï¼Œè¡¨æ˜éçº¿æ€§å¯èƒ½ä»æ˜¯å¿…è¦ç»„ä»¶

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **è¿›ä¸€æ­¥ä¼˜åŒ–å®ç°ä»¥æå‡åå**
   - é’ˆå¯¹å¤§ batch å’Œé•¿åºåˆ—è¿›è¡Œ kernel çº§åˆ«è°ƒä¼˜
2. **æ¢ç´¢æ›´å¹¿æ³›çš„ gate è®¾è®¡ç©ºé—´**
   - å¼•å…¥åŠ¨æ€ç¨€ç–ã€æ¡ä»¶è·¯ç”±ç­‰æœºåˆ¶
3. **ç»“åˆå±€éƒ¨æ³¨æ„åŠ›æœºåˆ¶**
   - å¦‚ Griffin-style æ··åˆæ¶æ„ï¼Œå…¼é¡¾ long-range ä¸ local precision
4. **åº”ç”¨äºæ›´å¤§è§„æ¨¡çš„è¯­è¨€æ¨¡å‹è®­ç»ƒ**
   - éªŒè¯åœ¨ billion-scale setting ä¸‹çš„ scaling laws
5. **ç ”ç©¶æœ€ä¼˜ inductive bias çš„è‡ªåŠ¨æœç´¢**
   - è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„ block/window size å’Œç»“æ„é…ç½®

---

> ğŸ”š **æ€»ç»“**ï¼š  
> è¯¥è®ºæ–‡ç³»ç»Ÿæ€§åœ°æ¢ç´¢äº† LRNN ä¸­â€œ**ç»“æ„åŒ–çŠ¶æ€æ··åˆ**â€çš„è®¾è®¡ç©ºé—´ï¼Œæå‡ºäº† **H-LRU** ä¸ **BD-LRU** ä¸¤ç§æ–°æ¶æ„ï¼Œå¹¶è¯æ˜ï¼š**è¡¨è¾¾åŠ›ä¸ä»…å–å†³äºå®½åº¦ï¼Œæ›´å–å†³äºçŠ¶æ€æ··åˆçš„æ–¹å¼**ã€‚é€šè¿‡åˆç†çš„å½’ä¸€åŒ–ä¸ parallel-scan å®ç°ï¼Œè¿™äº›æ¨¡å‹åœ¨ä¿æŒæ•ˆç‡çš„åŒæ—¶å®ç°äº†åª²ç¾ç”šè‡³è¶…è¶Š LSTM å’Œ Mamba çš„æ€§èƒ½ï¼Œä¸ºæ„å»ºé«˜æ•ˆä¸”å¼ºå¤§çš„çº¿æ€§åºåˆ—æ¨¡å‹æä¾›äº†æ–°è·¯å¾„ã€‚

</details>

---

### 9. [Predicting LLM Output Length via Entropy-Guided Representations](https://arxiv.org/abs/2602.11812)

**Authors**: Huanyi Xie, Yubin Chen, Liangyu Wang, Lijie Hu, Di Wang  
**Category**: cs.AI  
**Published**: 2026-02-13  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.11812v1  

#### Abstract
The long-tailed distribution of sequence lengths in LLM serving and reinforcement learning (RL) sampling causes significant computational waste due to excessive padding in batched inference. Existing methods rely on auxiliary models for static length prediction, but they incur high overhead, general...

---

### 10. [RELATE: A Reinforcement Learning-Enhanced LLM Framework for Advertising Text Generation](https://arxiv.org/abs/2602.11780)

**Authors**: Jinfang Wang, Jiajie Liu, Jianwei Wu, Ziqin Luo, Zhen Chen, Chunlei Li, Biao Han, Tao Deng, Yi Li, Shuanglong Li, Lin Liu  
**Category**: cs.AI  
**Published**: 2026-02-13  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.11780v1  

#### Abstract
In online advertising, advertising text plays a critical role in attracting user engagement and driving advertiser value. Existing industrial systems typically follow a two-stage paradigm, where candidate texts are first generated and subsequently aligned with online performance metrics such as clic...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠRELATE: A Reinforcement Learning-Enhanced LLM Framework for Advertising Text Generationã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
åœ¨çº¿å¹¿å‘Šç³»ç»Ÿä¸­ï¼Œ**å¹¿å‘Šæ–‡æ¡ˆç”Ÿæˆ**ï¼ˆAdvertising Text Generationï¼‰é€šå¸¸é‡‡ç”¨â€œå…ˆç”Ÿæˆåå¯¹é½â€ï¼ˆgenerate-and-alignï¼‰çš„ä¸¤é˜¶æ®µèŒƒå¼ï¼š
- ç¬¬ä¸€é˜¶æ®µï¼šé€šè¿‡è§„åˆ™æˆ–ç”Ÿæˆæ¨¡å‹äº§ç”Ÿå€™é€‰æ–‡æ¡ˆï¼›
- ç¬¬äºŒé˜¶æ®µï¼šåˆ©ç”¨ç‚¹å‡»ç‡ï¼ˆCTRï¼‰ã€è½¬åŒ–ç‡ï¼ˆCVRï¼‰ç­‰åœ¨çº¿åé¦ˆä¿¡å·è¿›è¡Œæ’åºæˆ–ä¼˜åŒ–ã€‚

è¿™ç§åˆ†ç¦»æ–¹å¼å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **ç›®æ ‡ä¸ä¸€è‡´**ï¼ˆObjective Misalignmentï¼‰ï¼šç”Ÿæˆç›®æ ‡ï¼ˆå¦‚è¯­è¨€æµç•…æ€§ï¼‰ä¸ä¸šåŠ¡ç›®æ ‡ï¼ˆå¦‚CTCVRï¼‰è„±èŠ‚ï¼›
- **æ¼æ–—æ•ˆç‡ä½**ï¼ˆLow Funnel Efficiencyï¼‰ï¼šå¤§é‡å€™é€‰éœ€åç»­è¿‡æ»¤ï¼Œèµ„æºæµªè´¹ï¼›
- **å¤šæ ·æ€§ä¸è¶³**ï¼ˆDiversity Deficiencyï¼‰ï¼šæ¨¡å‹å®¹æ˜“é™·å…¥æ¨¡å¼åç¼©ï¼ˆmode collapseï¼‰ï¼Œå¯¼è‡´æ–‡æœ¬ç–²åŠ³ï¼ˆtext fatigueï¼‰ï¼›
- **çº¦æŸå¤„ç†å‰²è£‚**ï¼šåˆè§„æ€§ã€ç›¸å…³æ€§ç­‰è´¨é‡è¦æ±‚å¸¸ä»¥äº‹åè§„åˆ™å½¢å¼åŠ å…¥ï¼Œéš¾ä»¥ç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šRELATE æ¡†æ¶

**RELATE**ï¼ˆREinforcement learning-enhanced LLM framework for Advertising TExt generationï¼‰æ˜¯ä¸€ä¸ª**åŸºäºå¼ºåŒ–å­¦ä¹ çš„ç«¯åˆ°ç«¯å¤§è¯­è¨€æ¨¡å‹æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†å¹¿å‘Šæ–‡æ¡ˆç”Ÿæˆå»ºæ¨¡ä¸ºä¸€ä¸ª**å¸¦çº¦æŸçš„åºåˆ—ä¼˜åŒ–é—®é¢˜**ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ å®ç°ç»Ÿä¸€ä¼˜åŒ–ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š
1. **ç«¯åˆ°ç«¯çš„ç›®æ ‡å¯¹é½æœºåˆ¶**
   - å°† CTCVRã€åˆè§„æ€§ï¼ˆcomplianceï¼‰ã€å¤šæ ·æ€§ï¼ˆdiversityï¼‰ç­‰å¤šç»´ç›®æ ‡ç»Ÿä¸€å»ºæ¨¡ä¸º**å¤šç»´åº¦å¥–åŠ±å‡½æ•°**ï¼ˆmulti-dimensional rewardï¼‰ï¼Œç›´æ¥åµŒå…¥ç”Ÿæˆè¿‡ç¨‹ã€‚
   - é¿å…ä¼ ç»Ÿå¤šé˜¶æ®µæµç¨‹ä¸­çš„ç›®æ ‡æ¼‚ç§»å’Œæ€§èƒ½æŸå¤±ã€‚

2. **ç»Ÿä¸€çš„å¥–åŠ±å»ºæ¨¡æ¡†æ¶**
   - è®¾è®¡äº†ä¸‰ä¸ªå…³é”®å¥–åŠ±ç»„ä»¶ï¼š
     - **CTCVR Reward**ï¼šåŸºäºé¢„æµ‹çš„è½¬åŒ–ç‡æä¾›å•†ä¸šä»·å€¼å¯¼å‘ï¼›
     - **Quality Reward**ï¼šæ¶µç›–é•¿åº¦ã€æ ¼å¼ã€ç›¸å…³æ€§ã€æ­£ç¡®æ€§å’Œé£é™©æ§åˆ¶ï¼Œç¡®ä¿è¾“å‡ºå¯ç”¨ä¸”åˆè§„ï¼›
     - **Diversity Reward**ï¼šé€šè¿‡æƒ©ç½šé«˜é¢‘ n-gram æŠ‘åˆ¶æ¨¡æ¿åŒ–è¡¨è¾¾ï¼Œç¼“è§£æ–‡æœ¬ç–²åŠ³ã€‚

3. **ä»»åŠ¡å®šåˆ¶çš„ä¿¡ç”¨åˆ†é…æœºåˆ¶**ï¼ˆCredit Assignmentï¼‰
   - åŒºåˆ† **token-level** å’Œ **sentence-level** å¥–åŠ±ï¼š
     - Token-levelï¼ˆå¦‚é»‘åå•è¯ã€é«˜é¢‘çŸ­è¯­ï¼‰ï¼šå³æ—¶åé¦ˆï¼Œç²¾å‡†å½’å› ï¼›
     - Sentence-levelï¼ˆå¦‚CTCVRã€æ•´ä½“ç›¸å…³æ€§ï¼‰ï¼šå…¨å±€è¯„ä¼°ï¼Œæ‰¹é‡ç›¸å¯¹ä¼˜åŠ¿è®¡ç®—ã€‚
   - åœ¨ GRPOï¼ˆGeneralized Reward-based Policy Optimizationï¼‰åŸºç¡€ä¸Šå¼•å…¥ç»†ç²’åº¦ä¿¡ç”¨åˆ†é…ï¼Œæ˜¾è‘—æå‡è®­ç»ƒæ•ˆç‡å’Œæ”¶æ•›ç¨³å®šæ€§ã€‚

4. **å·¥ä¸šçº§å¯éƒ¨ç½²æ€§è®¾è®¡**
   - æ”¯æŒå¤§è§„æ¨¡ç”Ÿäº§ç¯å¢ƒä¸‹çš„ç¨³å®šè®­ç»ƒä¸æ¨ç†ï¼›
   - å·²åœ¨ç™¾åº¦çœŸå®å¹¿å‘Šå¹³å°ä¸Šçº¿ï¼ŒéªŒè¯äº†å®é™…æœ‰æ•ˆæ€§ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚SFT + åå¤„ç† / DPOï¼‰ | RELATE |
|------|-------------------------------|--------|
| æ¶æ„ | å¤šé˜¶æ®µï¼ˆç”Ÿæˆ + å¯¹é½ï¼‰ | ç«¯åˆ°ç«¯ä¸€ä½“åŒ– |
| ç›®æ ‡å¯¹é½ | é—´æ¥ä¾èµ–æ—¥å¿—ä¿¡å· | å¼ºåŒ–å­¦ä¹ ç›´æ¥ä¼˜åŒ–CTCVR |
| çº¦æŸæ•´åˆ | äº‹åè§„åˆ™è¿‡æ»¤ | å¥–åŠ±ä¸­è½¯çº¦æŸå»ºæ¨¡ |
| å¤šæ ·æ€§ | æ˜“å‡ºç°æ¨¡å¼åç¼© | æ˜¾å¼å¤šæ ·æ€§å¥–åŠ±æŠ‘åˆ¶é‡å¤ |
| è®­ç»ƒæ•ˆç‡ | å—é™äºå»¶è¿Ÿåé¦ˆ | ä¿¡ç”¨åˆ†é…ç¼“è§£ç¨€ç–å¥–åŠ± |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†
- ä½¿ç”¨ **ç™¾åº¦æœç´¢å¹¿å‘ŠçœŸå®æ•°æ®é›†**ï¼š
  - åŒ…å« **40ä¸‡æ¡çœŸå®æœç´¢å¹¿å‘Šæ ·æœ¬**ï¼›
  - è¾“å…¥åŒ…æ‹¬ç”¨æˆ·æŸ¥è¯¢ï¼ˆqueryï¼‰ã€ç«å“å…³é”®è¯ï¼ˆbidwordsï¼‰ã€è½åœ°é¡µå†…å®¹ç­‰ï¼›
  - åœºæ™¯èšç„¦äºä¿¡æ¯æµå¹¿å‘Šæ–‡æ¡ˆç”Ÿæˆï¼Œå¼ºè°ƒæ„å›¾åŒ¹é…ä¸è¯´æœåŠ›ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼š`Qwen3-8B`ï¼ˆcold-start åˆå§‹åŒ–ï¼‰ï¼›
- **è®­ç»ƒç¡¬ä»¶**ï¼š8 Ã— NVIDIA A800 GPUï¼Œä½¿ç”¨ DeepSpeed ZeRO Stage 2ï¼›
- **é‡‡æ ·ç­–ç•¥**ï¼šæ¯è½® rollout ç”Ÿæˆ `G=5` ä¸ªå€™é€‰æ–‡æ¡ˆç”¨äºç»„å†…æ¯”è¾ƒï¼›
- **æ‰¹é‡å¤§å°**ï¼šglobal batch size = 1440ï¼›
- **RLç®—æ³•**ï¼šåŸºäº **GRPO**ï¼ˆGeneralized Reward-based Policy Optimizationï¼‰ï¼›
- **ä¿¡ç”¨åˆ†é…æœºåˆ¶**ï¼šåŒºåˆ† token/sentence-level å¥–åŠ±ï¼Œå¹¶åˆ†åˆ«æ„å»ºä¼˜åŠ¿å‡½æ•°ã€‚

---

### ğŸ“ è¯„ä¼°æŒ‡æ ‡
ä»ä¸‰ä¸ªç»´åº¦ç»¼åˆè¯„ä¼°ï¼š

| ç±»åˆ« | æŒ‡æ ‡ | å®šä¹‰è¯´æ˜ |
|------|------|----------|
| **å•†ä¸šæ•ˆèƒ½** | `Î”CTCVR`ï¼ˆACTCVRï¼‰ | åœ¨çº¿ A/B æµ‹è¯•ä¸­ç›¸å¯¹äºåŸºçº¿çš„ CTCVR æå‡ç™¾åˆ†æ¯” |
| **åˆè§„æ€§** | `Compliance Rate` | é€šè¿‡å·¥ä¸šçº§é£æ§ç³»ç»Ÿå®¡æ ¸çš„æ¯”ä¾‹ |
| **å¤šæ ·æ€§** | `Diversity Score` | åŸºäºè®­ç»ƒæ—¶ç›¸åŒçš„å¤šæ ·æ€§å¥–åŠ±å‡½æ•°è®¡ç®—ï¼Œåæ˜ å¯¹é«˜é¢‘æ¨¡å¼çš„æŠ‘åˆ¶ç¨‹åº¦ |

æ­¤å¤–è¿˜è¿›è¡Œäº†ï¼š
- **äººå·¥è¯„æµ‹**ï¼ˆHuman Evaluationï¼‰ï¼šé‡‡ç”¨ GSBï¼ˆGood/Same/Badï¼‰é…å¯¹æ¯”è¾ƒæ³•ï¼Œè¯„ä¼°è¯­ä¹‰æ­£ç¡®æ€§å’Œè‡ªç„¶åº¦ï¼›
- **æ¡ˆä¾‹åˆ†æ**ï¼ˆCase Studyï¼‰ï¼šå±•ç¤ºå…¸å‹ query ä¸‹ç”Ÿæˆæ–‡æ¡ˆçš„è´¨é‡å·®å¼‚ã€‚

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿æ¨¡å‹ | æè¿° |
|---------|------|
| **NLG** | åŸºäºå†å²é«˜CTRå¹¿å‘Šæ•°æ®è®­ç»ƒçš„ä¼ ç»Ÿé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ |
| **Qwen-SFT** | åœ¨é¢†åŸŸå†…é«˜è´¨é‡å¹¿å‘Šæ•°æ®ä¸Šè¿›è¡Œç›‘ç£å¾®è°ƒï¼ˆSupervised Fine-Tuningï¼‰ï¼Œå¹¶åœ¨æ¨ç†æ—¶æ·»åŠ åå¤„ç†è§„åˆ™ä¿è¯åˆè§„æ€§ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ æ€§èƒ½å¯¹æ¯”ï¼ˆè§ Table 1ï¼‰

| æ¨¡å‹ | Compliance Rate | Diversity | Î”CTCVR (ACTCVR) |
|------|------------------|-----------|------------------|
| NLG | 73.00% | 0.75 | â€” |
| Qwen-SFT | 82.70% | 0.72 | +5.25% |
| **RELATE** | **93.98%** | **0.82** | **+9.19%** |

âœ… **å…³é”®å‘ç°**ï¼š
- RELATE åœ¨æ‰€æœ‰ç»´åº¦å‡æ˜¾è‘—ä¼˜äºä¸¤ä¸ªåŸºçº¿ï¼›
- ç›¸æ¯”å½“å‰çº¿ä¸Šæ¨¡å‹ï¼ˆQwen-SFTï¼‰ï¼ŒCTCVR æå‡è¾¾ **+9.19%**ï¼Œå…·æœ‰ç»Ÿè®¡æ˜¾è‘—æ€§ï¼›
- åˆè§„ç‡æå‡è¶… **11ä¸ªç™¾åˆ†ç‚¹**ï¼Œè¡¨æ˜æ›´å¼ºçš„é£é™©æ§åˆ¶èƒ½åŠ›ï¼›
- å¤šæ ·æ€§å¾—åˆ†æé«˜çº¦ **14%**ï¼Œæœ‰æ•ˆç¼“è§£æ–‡æœ¬ç–²åŠ³ã€‚

---

### ğŸ”¬ æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰

#### å®éªŒè®¾è®¡ï¼ˆTable 2 & Table 3ï¼‰
é€æ­¥å¢åŠ å¥–åŠ±é¡¹å¹¶æµ‹è¯•ä¸åŒä¿¡ç”¨åˆ†é…æœºåˆ¶çš„å½±å“ï¼š

| æ¨¡å‹ | Structural Quality | CTCVR | Diversity | Semantic Quality | Reward Granularity |
|------|--------------------|-------|-----------|------------------|---------------------|
| Model 1 | âˆš | Ã— | Ã— | Ã— | Sentence-level |
| Model 2 | âˆš | âˆš | Ã— | Ã— | Sentence-level |
| Model 3 | âˆš | âˆš | âˆš | Ã— | Sentence-level |
| Model 4 | âˆš | âˆš | âˆš | âˆš | Sentence-level |
| **RELATE** | âˆš | âˆš | âˆš | âˆš | **Token-level**ï¼ˆDiversity & Risk Controlï¼‰ |

#### å…³é”®è§‚å¯Ÿï¼ˆFigure 3 & Table 3ï¼‰ï¼š
1. **ä»…åŠ  CTCVRï¼ˆModel 2ï¼‰**ï¼š
   - CTCVR å¿«é€Ÿä¸Šå‡ï¼Œä½† **å¤šæ ·æ€§ä¸è¯­ä¹‰è´¨é‡æ˜æ˜¾ä¸‹é™** â†’ å­˜åœ¨ç›®æ ‡å†²çªã€‚
2. **åŠ å…¥å¤šæ ·æ€§å¥–åŠ±ï¼ˆModel 3ï¼‰**ï¼š
   - å¤šæ ·æ€§å›å‡ï¼Œä½† CTCVR å¢é•¿æ”¾ç¼“ â†’ è¡¨æ˜å¤šç›®æ ‡åè°ƒå›°éš¾ã€‚
3. **åŠ å…¥è¯­ä¹‰è´¨é‡å¥–åŠ±ï¼ˆModel 4ï¼‰**ï¼š
   - æ­£ç¡®æ€§ã€ç›¸å…³æ€§æå‡ï¼Œä½†æ•´ä½“æ€§èƒ½æå‡å—é™ã€‚
4. **å¼•å…¥ token-level ä¿¡ç”¨åˆ†é…ï¼ˆRELATEï¼‰**ï¼š
   - æ‰€æœ‰æŒ‡æ ‡åŒæ­¥æå‡ï¼Œå°¤å…¶ **Diversity è¾¾åˆ° 0.965**ï¼Œè¿œé«˜äºå…¶ä»–é…ç½®ï¼›
   - è¯æ˜ **ç»†ç²’åº¦ä¿¡ç”¨åˆ†é…èƒ½ç¼“è§£å¤šç›®æ ‡ç«äº‰**ï¼Œå®ç°ååŒä¼˜åŒ–ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º
1. **ç«¯åˆ°ç«¯å¼ºåŒ–å­¦ä¹ æ¡†æ¶ä¼˜äºä¼ ç»Ÿä¸¤é˜¶æ®µèŒƒå¼**ï¼š
   - RELATE æˆåŠŸå®ç°äº†ç”Ÿæˆä¸ä¸šåŠ¡ç›®æ ‡çš„ç›´æ¥å¯¹é½ï¼Œé¿å…äº†ç›®æ ‡é”™ä½é—®é¢˜ã€‚
2. **å¤šç»´åº¦å¥–åŠ±å»ºæ¨¡æœ‰æ•ˆå¹³è¡¡å•†ä¸šä»·å€¼ä¸å†…å®¹è´¨é‡**ï¼š
   - å°† CTCVRã€åˆè§„æ€§ã€å¤šæ ·æ€§ç»Ÿä¸€å»ºæ¨¡ä¸ºå¥–åŠ±ä¿¡å·ï¼Œä½¿æ¨¡å‹èƒ½åœ¨å¤æ‚çº¦æŸä¸‹ä»ä¿æŒé«˜æ€§èƒ½ã€‚
3. **ä¿¡ç”¨åˆ†é…æœºåˆ¶æ˜¯è§£å†³ç¨€ç–å¥–åŠ±çš„å…³é”®**ï¼š
   - åŒºåˆ† token/sentence-level å¥–åŠ±å¹¶å·®å¼‚åŒ–å½’å› ï¼Œå¤§å¹…æå‡è®­ç»ƒæ•ˆç‡ä¸æœ€ç»ˆæ€§èƒ½ã€‚
4. **å·²åœ¨çœŸå®å·¥ä¸šåœºæ™¯ä¸­éªŒè¯æœ‰æ•ˆæ€§**ï¼š
   - ä¸Šçº¿åå¸¦æ¥ **+9.19% CTCVR æå‡**ï¼ŒåŒæ—¶æå‡åˆè§„ç‡ä¸å¤šæ ·æ€§ï¼Œå…·å¤‡å¼ºå®ç”¨æ€§ã€‚

---

### âš ï¸ å±€é™æ€§
1. **ä¾èµ–é«˜è´¨é‡çš„ reward modeling**ï¼š
   - CTCVR é¢„æµ‹æ¨¡å‹çš„å‡†ç¡®æ€§ç›´æ¥å½±å“è®­ç»ƒæ•ˆæœï¼›
   - è‹¥ reward signal å­˜åœ¨å™ªå£°æˆ–åå·®ï¼Œå¯èƒ½å¯¼è‡´ç­–ç•¥è¯¯å¯¼ã€‚
2. **å¤šæ ·æ€§åº¦é‡ä»åè¡¨å±‚**ï¼š
   - å½“å‰ diversity reward åŸºäº n-gram é¢‘ç‡ï¼Œå°šæœªæ·±å…¥è¯­ä¹‰å±‚é¢ï¼ˆå¦‚ä¸»é¢˜åˆ†å¸ƒã€å¥å¼ç»“æ„ï¼‰ã€‚
3. **è®­ç»ƒæˆæœ¬è¾ƒé«˜**ï¼š
   - éœ€è¦å¤§é‡ GPU èµ„æºæ”¯æŒ rollout ä¸ group computationï¼Œä¸é€‚åˆå°è§„æ¨¡å›¢é˜Ÿå¤ç°ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ›´ä¸°å¯Œçš„å¥–åŠ±è®¾è®¡**ï¼š
   - æ¢ç´¢ **semantic diversity reward**ï¼ˆå¦‚åŸºäº embedding è·ç¦»ï¼‰ï¼›
   - å¼•å…¥ç”¨æˆ·é•¿æœŸç•™å­˜ã€å“ç‰Œè®¤çŸ¥ç­‰é•¿æ•ˆæŒ‡æ ‡ä½œä¸º rewardã€‚
2. **æ›´ç²¾ç»†çš„ä¿¡ç”¨åˆ†é…ç­–ç•¥**ï¼š
   - å¦‚ segment-level æˆ– clause-level å½’å› ï¼Œè¿›ä¸€æ­¥ç»†åŒ–è¡Œä¸ºè§£é‡Šã€‚
3. **è·¨æ¨¡æ€å¹¿å‘Šç”Ÿæˆæ‰©å±•**ï¼š
   - å°†æ¡†æ¶æ¨å¹¿è‡³å›¾æ–‡ã€è§†é¢‘å¹¿å‘Šè”åˆç”Ÿæˆåœºæ™¯ã€‚
4. **å†·å¯åŠ¨ä¸ä¸ªæ€§åŒ–é€‚é…**ï¼š
   - ç»“åˆ advertiser profile å®ç°å®šåˆ¶åŒ–åˆ›æ„ç”Ÿæˆã€‚

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> RELATE é€šè¿‡**å¼ºåŒ–å­¦ä¹  + å¤šç»´åº¦å¥–åŠ± + ç»†ç²’åº¦ä¿¡ç”¨åˆ†é…**ï¼Œé¦–æ¬¡å®ç°äº†å¹¿å‘Šæ–‡æ¡ˆç”Ÿæˆä¸­**å•†ä¸šç›®æ ‡ã€åˆè§„çº¦æŸä¸å¤šæ ·æ€§çš„ç«¯åˆ°ç«¯ååŒä¼˜åŒ–**ï¼Œåœ¨çœŸå®å·¥ä¸šç³»ç»Ÿä¸­å–å¾—æ˜¾è‘—æ€§èƒ½çªç ´ã€‚

</details>

---

### 11. [GAC-KAN: An Ultra-Lightweight GNSS Interference Classifier for GenAI-Powered Consumer Edge Devices](https://arxiv.org/abs/2602.11186)

**Authors**: Zhihan Zeng, Kaihe Wang, Zhongpei Zhang, Yue Xiu  
**Category**: cs.LG  
**Published**: 2026-02-13  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.11186v1  

#### Abstract
The integration of Generative AI (GenAI) into Consumer Electronics (CE)--from AI-powered assistants in wearables to generative planning in autonomous Uncrewed Aerial Vehicles (UAVs)--has revolutionized user experiences. However, these GenAI applications impose immense computational burdens on edge h...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šGAC-KAN: An Ultra-Lightweight GNSS Interference Classifier for GenAI-Powered Consumer Edge Devices

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
æœ¬è®ºæ–‡é’ˆå¯¹**ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆGenAIï¼‰é©±åŠ¨çš„æ¶ˆè´¹ç±»è¾¹ç¼˜è®¾å¤‡**åœ¨èµ„æºæåº¦å—é™èƒŒæ™¯ä¸‹ï¼Œé¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼š
- **æ•°æ®ç¨€ç¼ºæ€§**ï¼šçœŸå®ä¸–ç•Œä¸­çš„GNSSå¹²æ‰°ä¿¡å·éš¾ä»¥å¤§è§„æ¨¡é‡‡é›†ï¼Œå°¤å…¶ç¼ºä¹å¤šæ ·åŒ–çš„æ ‡æ³¨æ•°æ®ç”¨äºè®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚
- **è®¡ç®—èµ„æºå†²çª**ï¼šGenAIåº”ç”¨ï¼ˆå¦‚LLMã€æ‰©æ•£æ¨¡å‹ï¼‰æœ¬èº«å·²å ç”¨å¤§é‡NPUå’Œå†…å­˜èµ„æºï¼Œä¼ ç»Ÿé‡å‹DLæ¨¡å‹ï¼ˆå¦‚ResNetã€ViTï¼‰æ— æ³•ä¸å…¶å…±å­˜è¿è¡Œã€‚

å› æ­¤ï¼ŒäºŸéœ€ä¸€ç§**è¶…è½»é‡çº§ã€é«˜ç²¾åº¦ä¸”èƒ½â€œå¸¸é©»åå°â€è¿è¡Œ**çš„GNSSå¹²æ‰°åˆ†ç±»å™¨ï¼Œä»¥ä¿éšœPNTï¼ˆå®šä½ã€å¯¼èˆªä¸æˆæ—¶ï¼‰æœåŠ¡çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **GAC-KAN** çš„æ–°å‹æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒç”±ä¸¤éƒ¨åˆ†æ„æˆï¼š

#### ï¼ˆ1ï¼‰ç‰©ç†å¼•å¯¼çš„ç”Ÿæˆå¼ä»¿çœŸç­–ç•¥ï¼ˆPhysics-Guided Generative Simulationï¼‰
- åˆ©ç”¨ä¸¥æ ¼çš„æ•°å­¦å»ºæ¨¡åˆæˆå…­ç±»å…¸å‹å¹²æ‰°ä¿¡å·ï¼ˆSTJ, MTJ, LFM, Pulse, PBNJ, SCIï¼‰åŠå™ªå£°ç±»ã€‚
- å‚æ•°éšæœºåŒ–ç¡®ä¿å¤šæ ·æ€§ï¼Œæ¨¡æ‹ŸçœŸå®åœºæ™¯ä¸‹çš„åŠ¨æ€å˜åŒ–ï¼Œæœ‰æ•ˆç¼“è§£**real-world data scarcity**é—®é¢˜ã€‚

#### ï¼ˆ2ï¼‰è½»é‡åŒ–ç½‘ç»œæ¶æ„è®¾è®¡ï¼šMS-GAC + KAN Head
- **Multi-Scale Ghost-ACB-Coordinate (MS-GAC) Backbone**ï¼š
  - èåˆ **Asymmetric Convolution Blocks (ACB)** å’Œ **Ghost Modules**ï¼Œåœ¨è®­ç»ƒæ—¶å¢å¼ºæ„Ÿå—é‡ï¼Œåœ¨æ¨ç†æ—¶èåˆä¸ºæ ‡å‡†å·ç§¯æ ¸ï¼Œæ— é¢å¤–éƒ¨ç½²å¼€é”€ã€‚
  - å¼•å…¥ **Coordinate Attention (CA)** æ˜¾å¼æ•æ‰æ—¶é—´-é¢‘ç‡åŸŸçš„èƒ½é‡åˆ†å¸ƒç‰¹å¾ï¼Œæå‡å¯¹å±€éƒ¨å¹²æ‰°æ¨¡å¼çš„æ•æ„Ÿåº¦ã€‚
  - å¤šåˆ†æ”¯ç»“æ„æ”¯æŒå¤šå°ºåº¦ç‰¹å¾æå–ï¼Œé€‚åº”ä¸åŒå¸¦å®½ä¸æ—¶å˜ç‰¹æ€§çš„å¹²æ‰°ä¿¡å·ã€‚
- **Kolmogorov-Arnold Network (KAN) åˆ†ç±»å¤´**ï¼š
  - æ›¿ä»£ä¼ ç»Ÿçš„MLPåˆ†ç±»å¤´ï¼Œé‡‡ç”¨å¯å­¦ä¹ çš„**B-splineæ¿€æ´»å‡½æ•°**ä½œä¸ºè¾¹ä¸Šçš„éçº¿æ€§æ˜ å°„ã€‚
  - ç›¸æ¯”å›ºå®šæ¿€æ´»å‡½æ•°ï¼ˆå¦‚ReLUï¼‰ï¼Œå…·å¤‡æ›´å¼ºçš„éçº¿æ€§æ‹Ÿåˆèƒ½åŠ›ï¼ŒåŒæ—¶å‚æ•°æ›´ç¨€ç–ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | GAC-KANä¼˜åŠ¿ |
|------|-------------|
| **å‚æ•°é‡** | ä»… **0.13M parameters**ï¼Œçº¦ä¸ºViT-B/16çš„ **1/660** |
| **è®¡ç®—æ•ˆç‡** | **0.19 G FLOPs**ï¼Œæ˜¯æ‰€æœ‰å¯¹æ¯”æ¨¡å‹ä¸­æœ€ä½ |
| **å‡†ç¡®ç‡** | è¾¾åˆ° **98.0% OAï¼ˆOverall Accuracyï¼‰**ï¼Œä¼˜äºå½“å‰SOTA |
| **é€‚ç”¨åœºæ™¯** | å¯ä½œä¸ºâ€œalways-onâ€å®‰å…¨å®ˆæŠ¤è¿›ç¨‹ï¼Œä¸äº‰æŠ¢GenAIä¸»ä»»åŠ¡èµ„æº |
| **é²æ£’æ€§** | åœ¨ä½JNRï¼ˆ-20 dBï¼‰ç¯å¢ƒä¸‹ä»ä¿æŒçº¦80%å‡†ç¡®ç‡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†æ„å»º
- **è‡ªå»ºå¤§è§„æ¨¡åˆæˆæ•°æ®é›†**ï¼ˆæ— å…¬å¼€å¯ç”¨çœŸå®æ•°æ®é›†ï¼‰
- åŒ…å« **7ä¸ªç±»åˆ«**ï¼š
  - å•éŸ³å¹²æ‰°ï¼ˆSTJï¼‰
  - å¤šéŸ³å¹²æ‰°ï¼ˆMTJï¼‰
  - çº¿æ€§è°ƒé¢‘ï¼ˆLFM / Chirpï¼‰
  - è„‰å†²å¹²æ‰°ï¼ˆPulseï¼‰
  - éƒ¨åˆ†å¸¦å®½å™ªå£°å¹²æ‰°ï¼ˆPBNJï¼‰
  - æ­£å¼¦è°ƒé¢‘å¹²æ‰°ï¼ˆSCIï¼‰
  - æ— å¹²æ‰°ï¼ˆNone / Thermal Noiseï¼‰
- **JNRèŒƒå›´**ï¼šä» -25 dB åˆ° +10 dBï¼Œæ¯5 dBä¸€ä¸ªç­‰çº§
- æ¯ç±»æ¯JNRæ°´å¹³è¿›è¡Œ1000æ¬¡Monte Carloè¯•éªŒ â†’ æ€»æ ·æœ¬æ•°ï¼š**56,000**
- æ•°æ®åˆ’åˆ†ï¼šè®­ç»ƒé›†70%ï¼ŒéªŒè¯é›†15%ï¼Œæµ‹è¯•é›†15%

---

### ğŸ”§ ç‰¹å¾æå–ä¸é¢„å¤„ç†
- è¾“å…¥ä¿¡å·ç» **Short-Time Fourier Transform (STFT)** è½¬æ¢ä¸ºæ—¶é¢‘è°±å›¾ï¼š
  - Hannçª—é•¿åº¦ï¼š128
  - é‡å ç‡ï¼š92%
  - FFTç‚¹æ•°ï¼š4096
- è¾“å‡ºä¸ºå¯¹æ•°å¹…åº¦è°±ï¼Œå¹¶è¿›è¡Œgammaæ ¡æ­£ï¼ˆÎ³=0.9ï¼‰å¢å¼ºå¼±ä¿¡å·å¯è§æ€§
- æœ€ç»ˆä¼ªå½©è‰²åŒ–å¹¶è°ƒæ•´è‡³ **224Ã—224Ã—3 RGBå›¾åƒæ ¼å¼**ï¼Œé€‚é…CNNè¾“å…¥

---

### âš™ï¸ å®éªŒè®¾ç½®
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼šIntel i9-12900KF CPU, 64GB RAM, NVIDIA RTX 5060Ti (16GB)
- **è½¯ä»¶æ¡†æ¶**ï¼šPyTorch 2.x, CUDA 11.8, cuDNN
- **ä¼˜åŒ–å™¨**ï¼šAdamWï¼Œåˆå§‹å­¦ä¹ ç‡ $1\times10^{-3}$ï¼Œweight decay $1\times10^{-4}$
- **è®­ç»ƒç­–ç•¥**ï¼š
  - 200 epochs
  - å‰5è½®çº¿æ€§warmupï¼Œåç»­cosineé€€ç«
  - ä½¿ç”¨ **Mixup**ï¼ˆÎ±=1.0ï¼‰å’Œ **Label Smoothing**ï¼ˆÎµ=0.1ï¼‰æå‡æ³›åŒ–
- **æŸå¤±å‡½æ•°**ï¼š
  $$
  \mathcal{L}_{\text{total}} = \mathcal{L}_{\text{CE}} + \lambda \sum |\mathbf{c}_i|,\quad \lambda=10^{-5}
  $$
  å…¶ä¸­ $\mathbf{c}_i$ æ˜¯KANå±‚çš„splineç³»æ•°ï¼ŒL1æ­£åˆ™ä¿ƒè¿›ç¨€ç–æ€§

---

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **OA (Overall Accuracy)** | æ‰€æœ‰ç±»åˆ«å¹³å‡è¯†åˆ«å‡†ç¡®ç‡ |
| **Confusion Matrix** | å±•ç¤ºå„ç±»åˆ«é—´è¯¯åˆ¤æƒ…å†µ |
| **Params (M)** | æ¨¡å‹å‚æ•°æ•°é‡ï¼ˆç™¾ä¸‡çº§ï¼‰ |
| **FLOPs (G)** | å•æ¬¡å‰å‘ä¼ æ’­æµ®ç‚¹è¿ç®—é‡ï¼ˆåäº¿çº§ï¼‰ |
| **Inference Time (ms)** | GPUä¸Šå•æ ·æœ¬æ¨ç†å»¶è¿Ÿ |
| **JNR Robustness Curve** | ä¸åŒJNRæ¡ä»¶ä¸‹çš„åˆ†ç±»å‡†ç¡®ç‡è¶‹åŠ¿ |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Vision Transformer (ViT-B/16)**ï¼šå…¸å‹Transformeræ¶æ„ï¼Œå‚æ•°é‡å¤§
- **FA-CNN**ï¼šå¸¦é¢‘ç‡æ³¨æ„åŠ›çš„ä¼ ç»ŸCNN
- **RCNN**ï¼šå¾ªç¯å·ç§¯ç¥ç»ç½‘ç»œï¼Œé€‚åˆæ—¶åºå»ºæ¨¡
- **ST-MSFF-KAN**ï¼šè¿‘æœŸæå‡ºçš„è½»é‡KAN-basedæ–¹æ³•ï¼ˆSOTAä¹‹ä¸€ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ è¡¨æ ¼ï¼šæ€§èƒ½ç»¼åˆå¯¹æ¯”ï¼ˆTest Setï¼‰

| Model | OA (%) | Params (M) | FLOPs (G) | Time (ms) |
|-------|--------|------------|-----------|-----------|
| **GAC-KAN (Ours)** | **98.0** | **0.1289** | **0.1901** | 7.0140 |
| ST-MSFF-KAN | 96.8 | 0.2883 | 0.5026 | 3.0140 |
| ViT-B/16 | 95.2 | 85.8040 | 11.2855 | 6.6676 |
| FA-CNN | 93.8 | 57.0530 | 0.7102 | 0.8693 |
| RCNN | 91.8 | 13.1194 | 0.5547 | 0.3097 |

> âœ… **GAC-KANåœ¨å‡†ç¡®ç‡ç¬¬ä¸€çš„åŒæ—¶ï¼Œå‚æ•°é‡æœ€å°ã€è®¡ç®—æˆæœ¬æœ€ä½**

---

### ğŸ”¬ å…³é”®å®éªŒå‘ç°

#### ï¼ˆ1ï¼‰å“è¶Šçš„æ•´ä½“æ€§èƒ½
- **æœ€é«˜å‡†ç¡®ç‡ 98.0%**ï¼Œæ˜¾è‘—ä¼˜äºç¬¬äºŒå ST-MSFF-KANï¼ˆ96.8%ï¼‰ï¼Œé¢†å…ˆè¿‘1.2ä¸ªç™¾åˆ†ç‚¹ã€‚
- å°¤å…¶åœ¨å¤æ‚å¹²æ‰°ç±»å‹ï¼ˆå¦‚SCI vs PBNJï¼‰ä¹‹é—´å…·æœ‰è‰¯å¥½çš„åŒºåˆ†èƒ½åŠ›ã€‚

#### ï¼ˆ2ï¼‰æç«¯è½»é‡åŒ–ä¼˜åŠ¿
- å‚æ•°ä»…ä¸º **0.13M**ï¼Œç›¸è¾ƒViTå‡å°‘ **660å€**ï¼Œè¿œä½äºå…¶ä»–CNNæ¶æ„ã€‚
- å­˜å‚¨éœ€æ±‚æä½ï¼Œé€‚ç”¨äºOTAæ›´æ–°å’Œä½æˆæœ¬Flashå­˜å‚¨è®¾å¤‡ã€‚

#### ï¼ˆ3ï¼‰ä½JNRä¸‹çš„å¼ºé²æ£’æ€§
- å¦‚å›¾4æ‰€ç¤ºï¼Œåœ¨ **JNR = -20 dB** æç«¯å™ªå£°æ¡ä»¶ä¸‹ï¼š
  - GAC-KAN å‡†ç¡®ç‡ â‰ˆ **80%**
  - FA-CNN â‰ˆ 55%ï¼ŒRCNN â‰ˆ 50%
- å½’åŠŸäº **Coordinate Attentionæœºåˆ¶** å¯¹å¾®å¼±èƒ½é‡åŒºåŸŸçš„æœ‰æ•ˆèšç„¦ï¼Œä»¥åŠ **KANçš„çµæ´»å†³ç­–è¾¹ç•Œ**

#### ï¼ˆ4ï¼‰æ··æ·†çŸ©é˜µåˆ†æï¼ˆå›¾5ï¼‰
- å¯¹è§’çº¿é«˜åº¦é›†ä¸­ï¼Œè¡¨æ˜æ•´ä½“åˆ†ç±»ç²¾å‡†ã€‚
- ä¸»è¦è¯¯åˆ¤å‘ç”Ÿåœ¨ï¼š
  - **PBNJ è¢«è¯¯åˆ¤ä¸º Noneï¼ˆ87ä¾‹ï¼‰**ï¼šå› ä¸¤è€…åœ¨ä½JNRä¸‹é¢‘è°±ç›¸ä¼¼
  - **SCI è¢«è¯¯åˆ¤ä¸º PBNJ**ï¼šæ­£å¼¦è°ƒåˆ¶ç‰¹å¾è¢«å™ªå£°æ©ç›–
- ä½†ä»èƒ½æœ‰æ•ˆåŒºåˆ†å½¢æ€ç›¸è¿‘ä¿¡å·ï¼ˆå¦‚LChirp vs SCIï¼‰ï¼Œè¯æ˜MS-GACçš„æœ‰æ•ˆæ€§

#### ï¼ˆ5ï¼‰æ¶ˆèå®éªŒï¼ˆè™½æœªæ˜ç¡®åˆ—å‡ºè¡¨æ ¼ï¼Œæ–‡ä¸­éšå«éªŒè¯ï¼‰
- **ABlation by Design Components**ï¼š
  - ä½¿ç”¨ACBæå‡ä¸­å¿ƒéª¨æ¶å¼ºåº¦ â†’ æé«˜ç‰¹å¾è¡¨è¾¾åŠ›
  - Ghostæ¨¡å—æ˜¾è‘—é™ä½å†—ä½™ â†’ æ§åˆ¶å‚æ•°å¢é•¿
  - CAæœºåˆ¶æ˜¾å¼å»ºæ¨¡æ—¶ç©ºä¾èµ– â†’ æå‡ä½ä¿¡å™ªæ¯”è¡¨ç°
  - KANæ›¿ä»£MLP â†’ åœ¨æå°‘å‚æ•°ä¸‹å®ç°æ›´å¼ºéçº¿æ€§æ˜ å°„

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º
1. **GAC-KANå®ç°äº†ç²¾åº¦ä¸æ•ˆç‡çš„æœ€ä¼˜å¹³è¡¡**ï¼š
   - åœ¨ä»…æœ‰ **0.13Må‚æ•°** å’Œ **0.19G FLOPs** çš„ä»£ä»·ä¸‹è¾¾åˆ° **98.0%å‡†ç¡®ç‡**ï¼Œæ˜¯ç›®å‰æœ€é«˜æ•ˆçš„GNSSå¹²æ‰°åˆ†ç±»å™¨ä¹‹ä¸€ã€‚
   
2. **KANé¦–æ¬¡æˆåŠŸåº”ç”¨äºGNSSé¢†åŸŸ**ï¼š
   - éªŒè¯äº†åŸºäºå¯å­¦ä¹ spline activationçš„KANåœ¨ç´§å‡‘æ¨¡å‹ä¸­ä¼˜äºä¼ ç»ŸMLPï¼Œå°¤å…¶é€‚åˆè¾¹ç¼˜éƒ¨ç½²ã€‚

3. **ç”Ÿæˆå¼ä»¿çœŸå¯æœ‰æ•ˆè§£å†³data scarcityé—®é¢˜**ï¼š
   - ç‰©ç†å»ºæ¨¡+å‚æ•°éšæœºåŒ–ç”Ÿæˆçš„æ•°æ®è¶³å¤Ÿå¤šæ ·åŒ–ï¼Œä½¿æ¨¡å‹å…·å¤‡è‰¯å¥½æ³›åŒ–èƒ½åŠ›ã€‚

4. **â€œAlways-Onâ€å®‰å…¨æˆä¸ºå¯èƒ½**ï¼š
   - æä½çš„èµ„æºæ¶ˆè€—ä½¿å…¶å¯åœ¨GenAIè®¾å¤‡ä¸Šé•¿æœŸåå°è¿è¡Œï¼Œä¸å½±å“ä¸»AIä»»åŠ¡æ€§èƒ½ã€‚

---

### âš ï¸ å±€é™æ€§
- **å®Œå…¨ä¾èµ–åˆæˆæ•°æ®**ï¼šå°šæœªåœ¨çœŸå®GNSSæ¥æ”¶æœºå®æµ‹æ•°æ®ä¸ŠéªŒè¯ï¼Œå¯èƒ½å­˜åœ¨ä»¿çœŸ-ç°å®å·®è·ï¼ˆsim-to-real gapï¼‰ã€‚
- **æ¨ç†å»¶è¿Ÿç›¸å¯¹è¾ƒé«˜ï¼ˆ7msï¼‰**ï¼šè™½ç„¶æ»¡è¶³å¤šæ•°å®æ—¶ç³»ç»Ÿè¦æ±‚ï¼ˆ<100ms @10â€“50Hzï¼‰ï¼Œä½†å¯¹äºè¶…é«˜é¢‘æ§åˆ¶ç¯è·¯å¯èƒ½ç•¥æ…¢ã€‚
- **æœªè€ƒè™‘spoofingæ”»å‡»**ï¼šä»…èšç„¦äºjamming classificationï¼Œæœªæ¶µç›–æ¬ºéª—ä¿¡å·æ£€æµ‹ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³real-worldæ•°æ®è¿ç§»å­¦ä¹ **ï¼šç»“åˆå°‘é‡çœŸå®æ•°æ®è¿›è¡Œfine-tuningï¼Œç¼©å°ä»¿çœŸåå·®ã€‚
2. **é›†æˆspoofing detectionæ¨¡å—**ï¼šæ„å»ºç»Ÿä¸€çš„GNSSå¨èƒæ„ŸçŸ¥ç³»ç»Ÿï¼ˆanti-jamming + anti-spoofingï¼‰ã€‚
3. **éƒ¨ç½²åˆ°å®é™…SoCå¹³å°**ï¼šåœ¨æ‰‹æœºã€æ— äººæœºç­‰GenAI-nativeèŠ¯ç‰‡ä¸Šå®æµ‹åŠŸè€—ä¸èƒ½æ•ˆã€‚
4. **æ¢ç´¢KANä¸å…¶ä»–è½»é‡ç»“æ„ç»„åˆ**ï¼šå¦‚MobileNetã€EfficientNetç­‰ï¼Œè¿›ä¸€æ­¥å‹ç¼©æ¨¡å‹ã€‚
5. **æ”¯æŒfew-shot learningåœºæ™¯**ï¼šåº”å¯¹æ–°å‹æœªçŸ¥å¹²æ‰°ç±»å‹çš„å¿«é€Ÿé€‚åº”èƒ½åŠ›ã€‚

---

## æ€»ç»“

> **GAC-KAN æ˜¯é¢å‘ GenAI æ—¶ä»£çš„ä¸‹ä¸€ä»£ GNSS å®‰å…¨åŸºçŸ³**ã€‚å®ƒé€šè¿‡â€œç‰©ç†å¼•å¯¼ä»¿çœŸ + è½»é‡éª¨å¹² + KANåˆ†ç±»å¤´â€çš„ååŒè®¾è®¡ï¼Œåœ¨å‡ ä¹ä¸å ç”¨å®è´µç®—åŠ›çš„å‰æä¸‹ï¼Œæä¾›é«˜è¾¾98%çš„å¹²æ‰°è¯†åˆ«ç²¾åº¦ï¼ŒçœŸæ­£å®ç°äº†â€œ**æ°¸è¿œåœ¨çº¿ã€æ°¸ä¸å¦¥å**â€çš„å®‰å…¨æ„¿æ™¯ã€‚

</details>

---

### 12. [Robust Optimization Approach and Learning Based Hide-and-Seek Game for Resilient Network Design](https://arxiv.org/abs/2602.11854)

**Authors**: Mohammad Khosravi, Setareh Maghsudi  
**Category**: cs.LG  
**Published**: 2026-02-13  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.11854v1  

#### Abstract
We study the design of resilient and reliable communication networks in which a signal can be transferred only up to a limited distance before its quality falls below an acceptable threshold. When excessive signal degradation occurs, regeneration is required through regenerators installed at selecte...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

**è®ºæ–‡æ ‡é¢˜**ï¼š*Robust Optimization Approach and Learning Based Hide-and-Seek Game for Resilient Network Design*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

æœ¬æ–‡ç ”ç©¶çš„æ˜¯**Resilient Network Design**ï¼ˆå¼¹æ€§ç½‘ç»œè®¾è®¡ï¼‰ä¸­çš„**Regenerator Location Problem (RLP)**ã€‚è¯¥é—®é¢˜æ—¨åœ¨ä¸ºé€šä¿¡ç½‘ç»œï¼ˆå¦‚å…‰ç½‘ç»œã€å«æ˜Ÿç½‘ç»œï¼‰éƒ¨ç½²ä¿¡å·å†ç”Ÿå™¨ï¼ˆregeneratorsï¼‰ï¼Œä»¥å…‹æœä¿¡å·åœ¨é•¿è·ç¦»ä¼ è¾“ä¸­çš„è´¨é‡è¡°å‡ã€‚å…¶æ ¸å¿ƒæŒ‘æˆ˜åœ¨äºï¼š

- **ç‰©ç†é™åˆ¶**ï¼šä¿¡å·åªèƒ½åœ¨ä¸è¶…è¿‡æœ€å¤§è·ç¦» `d_max` çš„é“¾è·¯ä¸Šä¼ è¾“ï¼Œå¦åˆ™éœ€è¦é€šè¿‡ regenerator è¿›è¡Œå†ç”Ÿã€‚
- **ä¸ç¡®å®šæ€§**ï¼šç°å®ä¸–ç•Œä¸­ï¼Œ**ç½‘ç»œèŠ‚ç‚¹**çš„å®‰è£…æˆæœ¬å’Œ**ç½‘ç»œè¾¹**ï¼ˆé“¾è·¯ï¼‰çš„é•¿åº¦å‡å­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œè¿™äº›ä¸ç¡®å®šæ€§ä¼šéšæ—¶é—´åŠ¨æ€å˜åŒ–ã€‚

å› æ­¤ï¼Œç›®æ ‡æ˜¯è®¾è®¡ä¸€ä¸ª**é²æ£’ä¸”å¯é **çš„ç½‘ç»œï¼Œåœ¨æœ€åæƒ…å†µä¸‹ä¹Ÿèƒ½ä¿è¯å…¨ç½‘è¿é€šæ€§ï¼ŒåŒæ—¶æœ€å°åŒ–æ€»æˆæœ¬ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

1. **æ–°å‹ä¸ç¡®å®šæ€§å»ºæ¨¡**ï¼š
   - **Static Budgeted Uncertainty Set**ï¼šç”¨äºå»ºæ¨¡**èŠ‚ç‚¹å®‰è£…æˆæœ¬**çš„ä¸ç¡®å®šæ€§ï¼Œå…è®¸å¯¹æ‰‹åœ¨é¢„ç®—å†…å°†æœ€å¤š `I_v` ä¸ªèŠ‚ç‚¹çš„æˆæœ¬æå‡è‡³å…¶ä¸Šé™ã€‚
   - **Dynamic Budgeted Uncertainty Set**ï¼šè¿™æ˜¯æœ¬æ–‡æå‡ºçš„ä¸€ä¸ª**æ–°æ¦‚å¿µ**ï¼Œç”¨äºå»ºæ¨¡**è¾¹é•¿åº¦**çš„æ—¶å˜ä¸ç¡®å®šæ€§ã€‚å®ƒå‡è®¾é“¾è·¯çš„æœ‰æ•ˆé•¿åº¦ä¼šéšæ—¶é—´å‘¨æœŸæ€§æ³¢åŠ¨ï¼Œå¯¹æ‰‹å¯ä»¥åœ¨æ¯ä¸ªæ—¶é—´æ®µ `t` å†…é€‰æ‹©æœ€å¤š `I_e` æ¡è¾¹è¿›è¡Œå¹²æ‰°ã€‚

2. **å¤šèŒƒå¼æ±‚è§£æ¡†æ¶**ï¼š
   - **æ•°å­¦è§„åˆ’æ¨¡å‹**ï¼šæ„å»ºäº†é’ˆå¯¹é™æ€å’ŒåŠ¨æ€ä¸ç¡®å®šæ€§çš„æ··åˆæ•´æ•°è§„åˆ’ï¼ˆMIPï¼‰æ¨¡å‹ã€‚
   - **å¯æ‰©å±•çš„æ±‚è§£ç®—æ³•**ï¼šä¸ºè§£å†³å¤§è§„æ¨¡å®ä¾‹ï¼Œæå‡ºäº†ä¸‰ç§é«˜æ•ˆç®—æ³•ï¼š
     - **Column-and-Constraint Generation (CCG)**
     - **Benders Decomposition (BDC)**
     - **Iterative Robust Optimization (IRO)**
   - **å­¦ä¹ å‹åšå¼ˆæ¡†æ¶**ï¼šæå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„ **Learning-based Hide-and-Seek (HSL) Game**ï¼Œå°†é²æ£’ä¼˜åŒ–é—®é¢˜å»ºæ¨¡ä¸ºç½‘ç»œè§„åˆ’è€…ï¼ˆseekerï¼‰ä¸å¯¹æ‰‹ï¼ˆadversaryï¼‰ä¹‹é—´çš„é‡å¤åšå¼ˆï¼Œå¹¶é‡‡ç”¨æ¢¯åº¦æ›´æ–°è§„åˆ™è¿›è¡Œæ±‚è§£ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

- **æ›´è´´è¿‘ç°å®**ï¼šä¼ ç»Ÿçš„é²æ£’ä¼˜åŒ–é€šå¸¸åªè€ƒè™‘é™æ€ä¸ç¡®å®šæ€§ã€‚æœ¬æ–‡æå‡ºçš„ **dynamic budgeted uncertainty** æ›´å¥½åœ°æ•æ‰äº†å®é™…ç½‘ç»œä¸­ï¼ˆå¦‚æ¸©åº¦å˜åŒ–ã€æµé‡æ³¢åŠ¨ï¼‰å¯¼è‡´çš„æ—¶å˜é“¾è·¯è´¨é‡ã€‚
- **æ›´é«˜çš„æˆæœ¬æ•ˆç›Š**ï¼šé€šè¿‡æ˜¾å¼å»ºæ¨¡åŠ¨æ€ä¸ç¡®å®šæ€§ï¼Œæ‰€ææ–¹æ³•ï¼ˆç‰¹åˆ«æ˜¯ RDB å’Œ HSLï¼‰èƒ½å¤Ÿæ‰¾åˆ°æ¯”ä¼ ç»Ÿç¡®å®šæ€§æœ€åæƒ…å†µï¼ˆDWCï¼‰å’Œé™æ€é²æ£’ï¼ˆRSBï¼‰æ–¹æ³•**æˆæœ¬æ›´ä½**çš„è§£å†³æ–¹æ¡ˆã€‚
- **æ›´å¼ºçš„å¯æ‰©å±•æ€§**ï¼šCCGã€BDC ç­‰åˆ†è§£ç®—æ³•æ˜¾è‘—æå‡äº†æ±‚è§£å¤§è§„æ¨¡ç½‘ç»œå®ä¾‹çš„èƒ½åŠ›ï¼Œå…¶ä¸­ **CCG åœ¨æ•ˆç‡ä¸Šè¡¨ç°æœ€ä¼˜**ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

è®ºæ–‡æœªä½¿ç”¨å…¬å¼€çš„çœŸå®æ•°æ®é›†ï¼Œè€Œæ˜¯**è‡ªè¡Œç”Ÿæˆäº†åˆæˆæ•°æ®é›†**ï¼Œä»¥ç³»ç»Ÿæ€§åœ°è¯„ä¼°ä¸åŒå‚æ•°ä¸‹çš„æ€§èƒ½ã€‚

- **å›¾ç»“æ„**ï¼šç”Ÿæˆå…·æœ‰ `n` ä¸ªèŠ‚ç‚¹å’Œå¯†åº¦ `dens=0.3` çš„éšæœºæ— å‘å›¾ã€‚
- **å‚æ•°ç”Ÿæˆ**ï¼š
  - **è¾¹é•¿åº¦**ï¼šåä¹‰é•¿åº¦ `c_e` ä» `{350, ..., 600}` ä¸­å‡åŒ€éšæœºæŠ½å–ï¼›æœ€å¤§åå·® `d_e` ä» `{1, ..., 250}` ä¸­æŠ½å–ã€‚
  - **èŠ‚ç‚¹æˆæœ¬**ï¼šåä¹‰æˆæœ¬ `c_v` ä» `{250, ..., 300}` ä¸­æŠ½å–ï¼›æœ€å¤§åå·® `d_v` ä» `{1, ..., 50}` ä¸­æŠ½å–ã€‚
- **å›ºå®šå‚æ•°**ï¼š`d_max = 1000`ã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

è¿›è¡Œäº†å››ç»„å®éªŒï¼ˆExp-1 åˆ° Exp-4ï¼‰ï¼š

| å®éªŒ | ç½‘ç»œè§„æ¨¡ (`n`) | ä¸ç¡®å®šæ€§é¢„ç®— (`I_e`, `I_v`) | ç›®çš„ |
| :--- | :--- | :--- | :--- |
| **Exp-1** | 10 åˆ° 30 | å›ºå®š (`2, 2`) | å°è§„æ¨¡å®ä¾‹ï¼Œæ¯”è¾ƒ DWC, RSB, RDB |
| **Exp-2** | å›ºå®š (25) | å˜åŒ– (`{1,2}`, `{1,2,3}`) | åˆ†æé¢„ç®—å¯¹æ€§èƒ½çš„å½±å“ |
| **Exp-3** | 40 åˆ° 60 | å›ºå®š (`2, 2`) | å¤§è§„æ¨¡å®ä¾‹ï¼Œæµ‹è¯•å¯æ‰©å±•æ€§ |
| **Exp-4** | å›ºå®š (50) | å˜åŒ– (`{1,2}`, `{1,2,3}`) | å¤§è§„æ¨¡å®ä¾‹ï¼Œåˆ†æé¢„ç®—å½±å“ |

**è¯„ä¼°æŒ‡æ ‡**ï¼š
- **å¹³å‡æ€»æˆæœ¬ (Average Cost)**ï¼šè¡¡é‡è§£å†³æ–¹æ¡ˆçš„ç»æµæ€§ã€‚
- **è®¡ç®—æ—¶é—´ (Computational Time)**ï¼šè¡¡é‡ç®—æ³•æ•ˆç‡ã€‚
- **è¿­ä»£æ¬¡æ•° (Iterations)**ï¼šè¡¡é‡æ”¶æ•›é€Ÿåº¦ã€‚
- **æ€§èƒ½å¯¹æ¯”**ï¼šä½¿ç”¨ `R-DWC` å’Œ `R-RSB` è¡¨ç¤ºç›¸å¯¹äº DWC å’Œ RSB çš„æˆæœ¬é™ä½ç™¾åˆ†æ¯”ã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

- **DWC (Deterministic Worst-Case)**ï¼šæ‰€æœ‰å‚æ•°å–å…¶æœ€åå€¼ï¼ˆä¸Šç•Œï¼‰ï¼Œç„¶åæ±‚è§£ç¡®å®šæ€§é—®é¢˜ã€‚
- **RSB (Robust Static Budgeted)**ï¼šèŠ‚ç‚¹æˆæœ¬å’Œè¾¹é•¿åº¦å‡ä½¿ç”¨**é™æ€**é¢„ç®—ä¸ç¡®å®šæ€§é›†å»ºæ¨¡ã€‚
- **RDB (Robust Dynamic Budgeted)**ï¼šæœ¬æ–‡æå‡ºçš„åŸºå‡†æ¨¡å‹ï¼Œç»“åˆäº†é™æ€èŠ‚ç‚¹æˆæœ¬å’ŒåŠ¨æ€è¾¹é•¿åº¦ä¸ç¡®å®šæ€§ã€‚

æœ¬æ–‡æå‡ºçš„æ–¹æ³•ï¼ˆCCG, BDC, IRO, HSLï¼‰å‡ä¸ä¸Šè¿°åŸºçº¿è¿›è¡Œå¯¹æ¯”ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”ç»“æœ**

#### **å°è§„æ¨¡å®ä¾‹ (Exp-1 & Exp-2)**

- **æˆæœ¬ä¼˜åŠ¿**ï¼š
  - RDB ç›¸æ¯” DWC å’Œ RSB èƒ½å®ç° **4% åˆ° 11%** çš„æˆæœ¬é™ä½ï¼ˆè§ Table IIï¼‰ã€‚
  - å½“ `I_e=1` æ—¶ï¼ŒRDB çš„æˆæœ¬é™ä½é«˜è¾¾ **28%**ï¼ˆè§ Table IIIï¼‰ï¼Œè¡¨æ˜åœ¨å¯¹æ‰‹æ”»å‡»èƒ½åŠ›å—é™æ—¶ï¼ŒåŠ¨æ€å»ºæ¨¡çš„ä¼˜åŠ¿æ›´ä¸ºæ˜¾è‘—ã€‚
- **è®¡ç®—æ—¶é—´**ï¼š
  - RDB çš„æ±‚è§£æ—¶é—´æœ€é•¿ï¼Œå› ä¸ºå…¶å»ºæ¨¡æ›´å¤æ‚ã€‚
  - DWC å’Œ RSB æœ€å¿«ã€‚

#### **å¤§è§„æ¨¡å®ä¾‹ (Exp-3 & Exp-4)**

- **æˆæœ¬ä¼˜åŠ¿**ï¼š
  - åœ¨æ›´å¤§è§„æ¨¡ä¸‹ï¼ŒCCGã€BDCã€IROã€HSL ç­‰æ–¹æ³•ä»èƒ½è¿›ä¸€æ­¥é™ä½æœ€ç»ˆæˆæœ¬ï¼Œæœ€é«˜å¯è¾¾ **2.40%**ï¼ˆè§ Table IVï¼‰ã€‚
  - å½“ `I_e=1` æ—¶ï¼Œæˆæœ¬é™ä½é«˜è¾¾ **31%**ï¼ˆè§ Table Vï¼‰ã€‚
- **è®¡ç®—æ•ˆç‡ä¸å¯æ‰©å±•æ€§**ï¼š
  - **CCG æ˜¯æœ€å¿«çš„æ–¹æ³•**ï¼Œåœ¨è®¸å¤šæƒ…å†µä¸‹ç”šè‡³æ¯”æ±‚è§£ç¡®å®šæ€§é—®é¢˜ï¼ˆDWCï¼‰è¿˜å¿«ï¼ˆè§ Fig. 3 & 4ï¼‰ã€‚
  - æ”¶æ•›é€Ÿåº¦æ’åºï¼š**CCG â‰ˆ BDC > IRO > HSL**ã€‚CCG å’Œ BDC è¿­ä»£æ¬¡æ•°æœ€å°‘ã€‚
  - æ€§èƒ½æ›²çº¿ï¼ˆPerformance Profileï¼‰æ˜¾ç¤ºï¼ŒCCG åœ¨å¤§å¤šæ•°å®ä¾‹ä¸Šéƒ½èƒ½å¿«é€Ÿæ‰¾åˆ°é«˜è´¨é‡è§£ã€‚

### **æ¶ˆèå®éªŒç»“æœ**

è™½ç„¶æ²¡æœ‰æ˜ç¡®æ ‡æ³¨ä¸ºâ€œæ¶ˆèå®éªŒâ€ï¼Œä½†é€šè¿‡æ¯”è¾ƒä¸åŒè®¾ç½®ä¸‹çš„ç»“æœï¼Œå¯ä»¥å¾—å‡ºä»¥ä¸‹ç»“è®ºï¼š

- **åŠ¨æ€ä¸ç¡®å®šæ€§å»ºæ¨¡çš„ä»·å€¼**ï¼šRDB ç›¸æ¯” RSB çš„æ˜¾è‘—æˆæœ¬é™ä½è¯æ˜äº†å¼•å…¥ **dynamic budgeted uncertainty** çš„æœ‰æ•ˆæ€§ã€‚
- **ä¸åŒæ±‚è§£ç®—æ³•çš„æƒè¡¡**ï¼š
  - **CCG** åœ¨**é€Ÿåº¦å’Œæ•ˆç‡**ä¸Šæœ€ä¼˜ï¼Œé€‚åˆå¤§è§„æ¨¡åº”ç”¨ã€‚
  - **HSL** ä½œä¸ºä¸€ç§åŸºäºå­¦ä¹ çš„å¯å‘å¼æ–¹æ³•ï¼Œè™½ç„¶æ”¶æ•›è¾ƒæ…¢ï¼Œä½†æä¾›äº†ä¸€ç§æ¨¡æ‹Ÿå¯¹æŠ—æ€§äº¤äº’çš„æ–°é¢–è§†è§’ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **åŠ¨æ€ä¸ç¡®å®šæ€§è‡³å…³é‡è¦**ï¼šæ˜¾å¼åœ°å¯¹ç½‘ç»œé“¾è·¯çš„**æ—¶å˜ç‰¹æ€§**è¿›è¡Œå»ºæ¨¡ï¼ˆDynamic Budgeted Uncertaintyï¼‰èƒ½å¤Ÿæ˜¾è‘—æå‡ç½‘ç»œè®¾è®¡çš„é²æ£’æ€§å’Œæˆæœ¬æ•ˆç›Šï¼Œå°¤å…¶æ˜¯åœ¨å¯¹æ‰‹èµ„æºæœ‰é™çš„æƒ…å†µä¸‹ã€‚
2. **æ‰€ææ–¹æ³•é«˜æ•ˆä¸”å¯æ‰©å±•**ï¼šæå‡ºçš„ **CCG** å’Œ **Benders Decomposition** ç®—æ³•èƒ½å¤Ÿé«˜æ•ˆæ±‚è§£å¤§è§„æ¨¡ç½‘ç»œå®ä¾‹ï¼Œå…¶ä¸­ **CCG æ˜¯è®¡ç®—æ•ˆç‡æœ€é«˜çš„æ–¹æ³•**ã€‚
3. **å­¦ä¹ å‹åšå¼ˆæ¡†æ¶æœ‰æ•ˆ**ï¼š**Hide-and-Seek Game (HSL)** æˆåŠŸåœ°å°†å¤æ‚çš„é²æ£’ä¼˜åŒ–é—®é¢˜è½¬åŒ–ä¸ºä¸€ä¸ªå¯é€šè¿‡æ¢¯åº¦å­¦ä¹ æ±‚è§£çš„åšå¼ˆè¿‡ç¨‹ï¼ŒéªŒè¯äº†å…¶ä½œä¸ºæ›¿ä»£æ±‚è§£èŒƒå¼çš„æ½œåŠ›ã€‚
4. **ä¼ ç»Ÿæ–¹æ³•è¿‡äºä¿å®ˆ**ï¼šç¡®å®šæ€§æœ€åæƒ…å†µï¼ˆDWCï¼‰å’Œé™æ€é²æ£’ï¼ˆRSBï¼‰æ–¹æ³•ç”±äºæœªèƒ½å……åˆ†åˆ©ç”¨ä¸ç¡®å®šæ€§çš„æ—¶é—´åŠ¨æ€æ€§ï¼Œå¯¼è‡´äº†ä¸å¿…è¦çš„é«˜æˆæœ¬ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

- **è®¡ç®—å¤æ‚æ€§**ï¼šå°½ç®¡æœ‰é«˜æ•ˆçš„ç®—æ³•ï¼Œä½†æ ¸å¿ƒé—®é¢˜è¢«è¯æ˜æ˜¯ **NP-hard**ï¼Œå¯¹äºè¶…å¤§è§„æ¨¡ç½‘ç»œï¼Œè®¡ç®—è´Ÿæ‹…ä¾ç„¶å­˜åœ¨ã€‚
- **æ¨¡å‹å‡è®¾**ï¼šåŠ¨æ€é¢„ç®—ä¸ç¡®å®šæ€§é›†è™½ç„¶æ–°é¢–ï¼Œä½†ä»æ˜¯ä¸€ä¸ªç®€åŒ–æ¨¡å‹ï¼Œå¯èƒ½æ— æ³•å®Œå…¨æ•æ‰æ‰€æœ‰ç°å®ä¸–ç•Œçš„å¤æ‚åŠ¨æ€ã€‚
- **HSL çš„æ”¶æ•›æ€§**ï¼šå­¦ä¹ å‹æ–¹æ³•ä¾èµ–äºè¿­ä»£å’Œæ¢¯åº¦æ›´æ–°ï¼Œå…¶æ”¶æ•›åˆ°å…¨å±€æœ€ä¼˜çš„ç†è®ºä¿è¯å¯èƒ½ä¸å¦‚ç²¾ç¡®ç®—æ³•å¼ºã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **å¼€å‘å¯å‘å¼/å…ƒå¯å‘å¼ç®—æ³•**ï¼šä¸ºå›¾å˜æ¢å’Œå†ç”Ÿå™¨æ”¾ç½®ç»„ä»¶è®¾è®¡é«˜æ•ˆçš„å¯å‘å¼æ–¹æ³•ï¼Œä»¥è¿›ä¸€æ­¥æå‡å¯æ‰©å±•æ€§ã€‚
2. **æ¢ç´¢å…¶ä»–ä¸ç¡®å®šæ€§è¡¨ç¤º**ï¼šä¾‹å¦‚ï¼Œç ”ç©¶ **dynamic interval uncertainty** æˆ– **distributional uncertainty**ã€‚
3. **é›†æˆæ•…éšœä¸ç”Ÿå­˜æ€§çº¦æŸ**ï¼šå°†è¾¹æ•…éšœã€èŠ‚ç‚¹å¤±æ•ˆç­‰ç”Ÿå­˜æ€§ï¼ˆsurvivabilityï¼‰è¦æ±‚ç›´æ¥çº³å…¥æ¨¡å‹ã€‚
4. **åº”ç”¨äºä¸‹ä¸€ä»£ç½‘ç»œ**ï¼šå°†è¯¥æ¡†æ¶æ¨å¹¿åˆ° 6Gã€ç©ºå¤©åœ°ä¸€ä½“åŒ–ç½‘ç»œç­‰æ›´å¤æ‚çš„åœºæ™¯ä¸­ã€‚

</details>

---

### 13. [Pushing Forward Pareto Frontiers of Proactive Agents with Behavioral Agentic Optimization](https://arxiv.org/abs/2602.11351)

**Authors**: Yihang Yao, Zhepeng Cen, Haohong Lin, Shiqi Liu, Zuxin Liu, Jiacheng Zhu, Zhang-Wei Hong, Laixi Shi, Ding Zhao  
**Category**: cs.AI  
**Published**: 2026-02-13  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.11351v1  

#### Abstract
Proactive large language model (LLM) agents aim to actively plan, query, and interact over multiple turns, enabling efficient task completion beyond passive instruction following and making them essential for real-world, user-centric applications. Agentic reinforcement learning (RL) has recently eme...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šPushing Forward Pareto Frontiers of Proactive Agents with Behavioral Agentic Optimization

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
æœ¬æ–‡é’ˆå¯¹**Proactive LLM Agents**åœ¨å¤šè½®äº¤äº’ä»»åŠ¡ä¸­é¢ä¸´çš„æ ¸å¿ƒæŒ‘æˆ˜â€”â€”**ä»»åŠ¡æ€§èƒ½ä¸ç”¨æˆ·å‚ä¸åº¦ä¹‹é—´çš„æƒè¡¡ï¼ˆtrade-offï¼‰**ã€‚å…·ä½“è¡¨ç°ä¸ºï¼š
- è¢«åŠ¨å‹Agentæ— æ³•ä¸»åŠ¨è·å–ä¿¡æ¯ï¼Œéš¾ä»¥å‡†ç¡®ç†è§£ç”¨æˆ·æ„å›¾ï¼›
- è¿‡åº¦ä¾èµ–ç”¨æˆ·åé¦ˆçš„ä¸»åŠ¨å‹Agentè™½ç„¶èƒ½æå‡æœ€ç»ˆè¡¨ç°ï¼Œä½†é¢‘ç¹è¯·æ±‚ä¼šé™ä½ç”¨æˆ·ä½“éªŒå’Œæ»¡æ„åº¦ã€‚

è¯¥é—®é¢˜æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ª**å¤šç›®æ ‡ä¼˜åŒ–ï¼ˆMulti-Objective Optimization, MOOï¼‰é—®é¢˜**ï¼šæœ€å¤§åŒ–ä»»åŠ¡å®Œæˆè´¨é‡çš„åŒæ—¶æœ€å°åŒ–å¯¹ç”¨æˆ·çš„æ‰“æ‰°ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§æ–°çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼š**Behavioral Agentic Optimization (BAO)**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡**è¡Œä¸ºå¢å¼ºï¼ˆBehavior Enhancementï¼‰** å’Œ **è¡Œä¸ºæ­£åˆ™åŒ–ï¼ˆBehavior Regularizationï¼‰** æ¥ä¼˜åŒ–Agentçš„å¤šè½®æ¨ç†èƒ½åŠ›ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š
- **å°†Proactive Agentè®­ç»ƒå»ºæ¨¡ä¸ºMOOé—®é¢˜**ï¼Œå¹¶æ˜ç¡®è¯†åˆ«å‡ºParetoå‰æ²¿çš„å­˜åœ¨ã€‚
- å¼•å…¥ä¸¤ç±»å…³é”®çš„**multi-turn behaviors**ï¼š
  - **Retrospective Reasoning**ï¼ˆå›æº¯å¼æ¨ç†ï¼‰ï¼šåŸºäºå†å²ä¿¡æ¯è¿›è¡Œè®°å¿†ç®¡ç†å’Œå‡è®¾ä¿®æ­£ï¼ˆHypothesis Refinementï¼‰ï¼Œé¿å…é‡å¤æé—®ã€‚
  - **Prospective Planning**ï¼ˆå‰ç»æ€§è§„åˆ’ï¼‰ï¼šåŠ¨æ€è°ƒåº¦æŸ¥è¯¢ç­–ç•¥ï¼ˆDynamic Schedulingï¼‰å’Œæˆ˜ç•¥æ€§æé—®ï¼ˆStrategical Queryingï¼‰ï¼Œæé«˜æ¢ç´¢æ•ˆç‡ã€‚
- è®¾è®¡äº†ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹ï¼š
  1. **SFTé˜¶æ®µæ³¨å…¥è¡Œä¸ºæ¨¡å¼**ï¼šåˆ©ç”¨æ•™å¸ˆæ¨¡å‹ï¼ˆå¦‚GPT-4oï¼‰ç”Ÿæˆå¸¦æœ‰æŒ‡å®šè¡Œä¸ºç‰¹å¾çš„æ•°æ®ï¼›
  2. **RLé˜¶æ®µæ–½åŠ è¡Œä¸ºæ­£åˆ™åŒ–å¥–åŠ±**ï¼šé€šè¿‡turn-level reward shapingæŠ‘åˆ¶ä½æ•ˆè¡Œä¸ºï¼ˆå¦‚å†—ä½™æé—®ã€è¿‡åº¦æ€è€ƒï¼‰ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **ä¼˜äºä¼ ç»ŸRLæ–¹æ³•**ï¼ˆå¦‚UserRLï¼‰ï¼šåœ¨æ›´å°‘ç”¨æˆ·äº¤äº’ä¸‹è¾¾åˆ°æ›´é«˜ä»»åŠ¡æˆåŠŸç‡ã€‚
- **åª²ç¾ç”šè‡³è¶…è¶Šå•†ä¸šé—­æºæ¨¡å‹**ï¼ˆå¦‚GPT-4oã€Geminiç³»åˆ—ï¼‰ï¼šå°¤å…¶åœ¨Function-Gymç­‰å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°çªå‡ºã€‚
- **æœ‰æ•ˆç¼“è§£reward hackingé—®é¢˜**ï¼šç›¸æ¯”åŸºçº¿æ–¹æ³•ï¼Œåœ¨è·¨æ¨¡æ‹Ÿå™¨è¯„ä¼°æ—¶æ€§èƒ½ä¸‹é™æ›´å°ï¼Œè¯´æ˜æ³›åŒ–æ€§æ›´å¼ºã€‚
- **æ¨åŠ¨äº†Paretoå‰æ²¿å‰ç§»**ï¼šå®ç°äº†ä»»åŠ¡æ€§èƒ½ä¸ç”¨æˆ·è´Ÿæ‹…ä¹‹é—´æ›´å¥½çš„å¹³è¡¡ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
æ‰€æœ‰å®éªŒå‡åŸºäº **UserRL benchmark suite** ä¸­çš„ä¸‰ä¸ªä»»åŠ¡ï¼š
| ä»»åŠ¡ | æè¿° |
|------|------|
| **Function-Gym** | æ¨æ–­ä¸€ä¸ªæœªçŸ¥å››å˜é‡æ•°å­¦å‡½æ•°å½¢å¼ï¼Œé€šè¿‡è¾“å…¥è¾“å‡ºé‡‡æ ·æ¥æ¨æµ‹å‡½æ•°ç»“æ„ã€‚å®Œå…¨è§„åˆ™åŒ–åé¦ˆï¼Œæ— sim-to-real gapã€‚ |
| **Telepathy-Gym** | æ¨æµ‹éšè—å®ä½“ï¼Œé€šè¿‡å‘ç¯å¢ƒæé—®â€œYes/Noâ€é—®é¢˜é€æ­¥ç¼©å°èŒƒå›´ã€‚è®­ç»ƒç”¨Qwen3-8Bæ¨¡æ‹Ÿç”¨æˆ·ï¼Œæµ‹è¯•ç”¨GPT-4oï¼Œå­˜åœ¨åˆ†å¸ƒåç§»ã€‚ |
| **Turtle-Gym** | â€œé¾Ÿæ±¤æ¸¸æˆâ€ï¼Œéœ€ä»è¡¨é¢æ•…äº‹ä¸­æ¨ç†å‡ºéšè—è½¬æŠ˜ï¼ˆtwistï¼‰ã€‚ç»“åˆå™äº‹ç†è§£å’Œéšå–»è¯†åˆ«ï¼Œè®­ç»ƒä¸æµ‹è¯•é—´å­˜åœ¨æ˜¾è‘—sim-to-real gapã€‚ |

æ¯ä¸ªä»»åŠ¡æœ€å¤šå…è®¸ `T=15` è½®äº¤äº’ï¼ˆTurtle-Gymä¾‹å¤–ä¸º12è½®ï¼‰ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
#### æ¨¡å‹æ¶æ„
- åŸºç¡€æ¨¡å‹ï¼š**Qwen3ç³»åˆ—**ï¼ˆ1.7B å’Œ 4B å‚æ•°é‡ï¼‰
- æ•™å¸ˆæ¨¡å‹ï¼š**GPT-4o**

#### è®­ç»ƒæµç¨‹
1. **Behavior-Enhanced SFT**ï¼šæ„å»ºåŒ…å«Retrospective & Prospectiveè¡Œä¸ºçš„ç›‘ç£å¾®è°ƒæ•°æ®é›†ã€‚
2. **Behavior-Regularized RL**ï¼šé‡‡ç”¨GRPOç®—æ³•è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œå¹¶å¼•å…¥ä»¥ä¸‹æ­£åˆ™é¡¹ï¼š
   - **Information-Seeking Regularization**ï¼šæƒ©ç½šè¿ç»­æ— ä¿¡æ¯å¢ç›Šçš„ç”¨æˆ·äº¤äº’ã€‚
   - **Over-Thinking Regularization**ï¼šæƒ©ç½šå› tokenè€—å°½è€Œæœªå®Œæˆä»»åŠ¡çš„è½¨è¿¹ã€‚

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ | è¶Šé«˜è¶Šå¥½ï¼Ÿ |
|------|------|------------|
| **Pass@U-k** | åœ¨æœ€å¤šå…è®¸kæ¬¡ç”¨æˆ·äº¤äº’ï¼ˆAnsweråŠ¨ä½œï¼‰çš„æƒ…å†µä¸‹æˆåŠŸå®Œæˆä»»åŠ¡çš„æ¯”ä¾‹ | âœ… |
| **Score (R(T))** | æœªç»è°ƒæ•´çš„ç´¯ç§¯å¥–åŠ± | âœ… |
| **User Involvement Rate (UR)** | ç”¨æˆ·ç›¸å…³åŠ¨ä½œå æ¯” $ \mathbb{E}[U(T)/|T|] $ | âŒ |
| **Exploration Ratio** | å·¥å…·/ç¯å¢ƒäº¤äº’æ•° vs ç”¨æˆ·æäº¤ç­”æ¡ˆæ¬¡æ•° | âœ… |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»åˆ« | æ–¹æ³• |
|-------|--------|
| å•†ä¸šæ¨¡å‹ | GPT-4o, GPT-4o-mini, GPT-5-0807, Geminiç³»åˆ— |
| å¼€æºåŸå§‹æ¨¡å‹ | Qwen3-32B/14B/8B (Raw) |
| å¾®è°ƒåŸºçº¿ | **UserRL**ï¼ˆQian et al., 2025cï¼‰ |
| æ¶ˆèå˜ä½“ | BAO w/o BEï¼ˆæ— è¡Œä¸ºå¢å¼ºï¼‰ã€BAO w/o BRï¼ˆæ— è¡Œä¸ºæ­£åˆ™åŒ–ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ªTable 1ï¼‰

| æ–¹æ³• | Function-Gym Pass@U-1 | Pass@U-2 | Score | UR â†“ |
|------|------------------------|----------|-------|-------|
| **BAO-4B** | **0.2692** | **0.5354** | **0.6923** | **0.2148** |
| UserRL-4B | 0.2436 | 0.4103 | 0.5256 | 0.3758 |
| GPT-4o | 0.1282 | 0.1282 | 0.1410 | 0.2248 |
| GPT-5-0807 | 0.5000 | 0.6923 | 0.7436 | 0.1365 |

> æ³¨ï¼šBAO-4Båœ¨ä¿æŒè¾ƒä½URçš„åŒæ—¶ï¼ŒPass@U-2æ¥è¿‘GPT-5æ°´å¹³ï¼Œä¸”è¿œè¶…UserRLã€‚

| æ–¹æ³• | Turtle-Gym Pass@U-1 | Pass@U-2 | Score | UR â†“ |
|------|---------------------|----------|-------|-------|
| **BAO-4B** | **0.1063** | **0.1125** | **0.1125** | **0.2917** |
| UserRL-4B | 0.0417 | 0.0563 | 0.0594 | 0.7617 |

> BAOåœ¨æœ€éš¾çš„Turtle-Gymä¸Šä»æ˜¾è‘—ä¼˜äºUserRLï¼Œä¸”ç”¨æˆ·å‚ä¸ç‡å¤§å¹…é™ä½ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **BAOå…¨é¢è¶…è¶ŠUserRL**ï¼š
  - æ›´é«˜çš„Pass@U-1/2ï¼šè¡¨æ˜æ—©æœŸå³å¯åšå‡ºæ­£ç¡®åˆ¤æ–­ã€‚
  - æ›´ä½çš„URï¼šå‡å°‘å¯¹ç”¨æˆ·éªŒè¯çš„ä¾èµ–ã€‚
  - æ›´é«˜çš„æ¢ç´¢æ¯”ä¾‹ï¼ˆè§Figure 4ï¼‰ï¼šè¯´æ˜æ›´å–„äºåˆ©ç”¨å·¥å…·å’Œç¯å¢ƒäº¤äº’ã€‚
- **åª²ç¾ç”šè‡³è¶…è¶Šéƒ¨åˆ†å•†ä¸šæ¨¡å‹**ï¼š
  - åœ¨Function-Gymä¸Šï¼ŒBAO-4Bå¾—åˆ†è¶…è¿‡GPT-4oå’ŒGeminiç³»åˆ—ã€‚
  - åœ¨Turtle-Gymä¸Šè™½ä¸åŠGPT-5ï¼Œä½†ä¼˜äºå¤šæ•°é—­æºæ¨¡å‹ã€‚

### æ¶ˆèå®éªŒç»“æœ
#### è¡Œä¸ºç»„ä»¶æ¶ˆèï¼ˆTable 1 & Figure 6ï¼‰
| å˜ä½“ | å½±å“ |
|------|------|
| **BAO w/o BE** | Pass@U-kä¸‹é™ï¼ŒScoreé™ä½ â†’ è¯æ˜è¡Œä¸ºå¢å¼ºå¯¹æ€§èƒ½æå‡è‡³å…³é‡è¦ |
| **BAO w/o BR** | URæ€¥å‰§ä¸Šå‡è‡³0.8698ï¼ˆvs BAOçš„0.2917ï¼‰â†’ æ˜¾ç¤ºè¡Œä¸ºæ­£åˆ™åŒ–æœ‰æ•ˆæŠ‘åˆ¶å†—ä½™äº¤äº’ |

#### è¡Œä¸ºç±»å‹åˆ†æï¼ˆFigure 6ï¼‰
- **Retrospective Reasoning**ï¼šæå‡é•¿æœŸæ€§èƒ½ä¸Šé™ï¼ˆScoreâ†‘ï¼‰ï¼Œä½†ä¸æ˜¾è‘—æ”¹å–„é¦–æ¬¡æäº¤å‡†ç¡®ç‡ã€‚
- **Prospective Planning**ï¼šæ˜¾è‘—æå‡Pass@U-1ï¼Œå› å…¶æ”¯æŒæå‰è§„åˆ’ã€‚
- **äºŒè€…ç»“åˆ**ï¼šå®ç°æ—©æœŸå‡†ç¡®æ€§ä¸é•¿ç¨‹æ¨ç†èƒ½åŠ›çš„å‡è¡¡ã€‚

#### æ¢ç´¢å¤šæ ·æ€§åˆ†æï¼ˆFigures 7 & 8ï¼‰
- **Self-BLEU & Embedding Similarityæ›´ä½** â†’ BAOç”Ÿæˆçš„é—®é¢˜å’Œç­”æ¡ˆæ›´å…·å¤šæ ·æ€§ã€‚
- è¯´æ˜BAOèƒ½æ›´é«˜æ•ˆåœ°æ¢ç´¢ä¿¡æ¯ç©ºé—´ï¼Œé¿å…é™·å…¥æ— æ•ˆå¾ªç¯ã€‚

#### Reward Hackingåˆ†æï¼ˆFigure 9ï¼‰
- UserRLåœ¨è®­ç»ƒä¸­äº§ç”Ÿæ›´é•¿çš„å›ç­”ä»¥â€œæ¬ºéª—â€å¥–åŠ±æ¨¡å‹ï¼Œä½†åœ¨GPT-4oè¯„ä¼°æ—¶æ€§èƒ½éª¤é™ã€‚
- BAOè®­ç»ƒå“åº”é•¿åº¦é€‚ä¸­ï¼Œ**RTRï¼ˆReward Translation Rateï¼‰é«˜è¾¾0.575**ï¼ˆUserRLä»…0.154ï¼‰ï¼Œæ˜¾ç¤ºæ›´å¼ºé²æ£’æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Proactive Agentè®­ç»ƒæœ¬è´¨æ˜¯MOOé—®é¢˜**ï¼Œå¿…é¡»åŒæ—¶è€ƒè™‘ä»»åŠ¡æ€§èƒ½ä¸ç”¨æˆ·å‚ä¸æˆæœ¬ã€‚
2. **æ˜¾å¼å»ºæ¨¡multi-turn behaviors**ï¼ˆRetrospective Reasoning + Prospective Planningï¼‰å¯æ˜¾è‘—æå‡Agentçš„è‡ªä¸»æ¨ç†èƒ½åŠ›ã€‚
3. **BAOæˆåŠŸæ¨åŠ¨äº†Pareto Frontierå‰ç§»**ï¼šåœ¨åŒç­‰ç”¨æˆ·è´Ÿæ‹…ä¸‹è·å¾—æ›´é«˜æ€§èƒ½ï¼Œæˆ–åœ¨åŒç­‰æ€§èƒ½ä¸‹æ˜¾è‘—é™ä½å¹²æ‰°ã€‚
4. **è¡Œä¸ºæ­£åˆ™åŒ–æœºåˆ¶æœ‰æ•ˆé˜²æ­¢reward hacking**ï¼Œå¢å¼ºäº†æ¨¡å‹åœ¨çœŸå®åœºæ™¯ä¸­çš„å¯é æ€§ã€‚
5. **å¼€æ”¾æ¨¡å‹ç»BAOè®­ç»ƒåå¯åª²ç¾ç”šè‡³è¶…è¶Šéƒ¨åˆ†å•†ä¸šæ¨¡å‹**ï¼Œå±•ç¤ºäº†å¼€æºAgentçš„å·¨å¤§æ½œåŠ›ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰å·¥ä½œèšç„¦äº**çº¯è¯­è¨€Agent**ï¼Œå°šæœªæ‰©å±•åˆ°å¤šæ¨¡æ€åœºæ™¯ã€‚
- æ‰€æœ‰ä»»åŠ¡å‡åœ¨ä»¿çœŸç¯å¢ƒä¸­è¿›è¡Œï¼Œå®é™…éƒ¨ç½²ä¸­çš„å¤æ‚æ€§å’Œå®‰å…¨æ€§é£é™©æœªå……åˆ†éªŒè¯ã€‚
- å¯¹æ•™å¸ˆæ¨¡å‹ï¼ˆå¦‚GPT-4oï¼‰æœ‰ä¸€å®šä¾èµ–ï¼Œå¯èƒ½é™åˆ¶å®Œå…¨å»ä¸­å¿ƒåŒ–çš„è®­ç»ƒè·¯å¾„ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°†BAOæ¡†æ¶æ‹“å±•è‡³**Multimodal Agents**ï¼ˆè§†è§‰+è¯­è¨€+åŠ¨ä½œï¼‰ã€‚
- æ¢ç´¢æ›´è½»é‡çº§çš„è¡Œä¸ºæ³¨å…¥æ–¹å¼ï¼Œé™ä½å¯¹å¼ºTeacher Modelçš„ä¾èµ–ã€‚
- åœ¨çœŸå®äººæœºåä½œåœºæ™¯ä¸­æµ‹è¯•BAOè®­ç»ƒçš„Agentï¼Œç ”ç©¶å…¶ç¤¾ä¼šå½±å“ä¸ä¼¦ç†è¾¹ç•Œã€‚
- ç»“åˆ**User Preference Modeling**è¿›ä¸€æ­¥ä¸ªæ€§åŒ–Agentè¡Œä¸ºã€‚

---

> ğŸŒ **é¡¹ç›®ä¸»é¡µ**: [https://proactive-agentic-rl.github.io/](https://proactive-agentic-rl.github.io/)

</details>

---

### 14. [Credit Where It is Due: Cross-Modality Connectivity Drives Precise Reinforcement Learning for MLLM Reasoning](https://arxiv.org/abs/2602.11455)

**Authors**: Zhengbo Jiao, Shaobo Wang, Zifan Zhang, Wei Wang, Bing Zhao, Hu Wei, Linfeng Zhang  
**Category**: cs.AI  
**Published**: 2026-02-13  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.11455v1  

#### Abstract
Reinforcement Learning with Verifiable Rewards (RLVR) has significantly advanced the reasoning capabilities of Multimodal Large Language Models (MLLMs), yet how visual evidence is integrated during reasoning remains poorly understood. We explore multimodal RLVR through the lens of cross-modal attent...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**Credit Where It's Due: Cross-Modality Connectivity Drives Precise Reinforcement Learning for MLLM Reasoning**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³äº†ä»€ä¹ˆé—®é¢˜

å½“å‰çš„ **Reinforcement Learning with Verifiable Rewards (RLVR)** åœ¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰æ¨ç†ä»»åŠ¡ä¸­æ™®éå­˜åœ¨â€œ**å‡åŒ€ä¿¡ç”¨åˆ†é…**â€ï¼ˆuniform credit assignmentï¼‰çš„é—®é¢˜ã€‚å³åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ‰€æœ‰ç”Ÿæˆçš„æ–‡æœ¬ token è¢«åŒç­‰å¯¹å¾…ï¼Œæ— è®ºå…¶æ˜¯å¦çœŸæ­£ä¾èµ–è§†è§‰è¾“å…¥è¿›è¡Œæ¨ç†ã€‚

ç„¶è€Œï¼Œç ”ç©¶è¡¨æ˜ï¼ŒMLLMs åœ¨è§†è§‰æ¨ç†ä¸­å¸¸å‡ºç°â€œ**ä¼ªæ¨ç†**â€ç°è±¡â€”â€”å¤§é‡ token ä»…éµå¾ªè¯­è¨€æ¨¡å¼è€ŒæœªçœŸå®é”šå®šäºå›¾åƒå†…å®¹ã€‚è¿™å¯¼è‡´è®­ç»ƒä¿¡å·è¢«ç¨€é‡Šï¼Œå½±å“æ¨¡å‹å¯¹è§†è§‰è¯æ®çš„æœ‰æ•ˆåˆ©ç”¨ã€‚

---

### ğŸš€ æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯

ä½œè€…æå‡º **Anchor-Token Reinforcement Learning (AT-RL)**ï¼Œä¸€ç§è½»é‡çº§ã€å³æ’å³ç”¨çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> **å°†å¼ºåŒ–å­¦ä¹ çš„ä¿¡ç”¨ï¼ˆcreditï¼‰ç²¾å‡†åˆ†é…ç»™é‚£äº›çœŸæ­£è¿æ¥è§†è§‰ä¸è¯­è¨€çš„â€œæ„ŸçŸ¥é”šç‚¹â€ï¼ˆPerceptual Anchorsï¼‰**ã€‚

#### åˆ›æ–°æœºåˆ¶åŒ…æ‹¬ï¼š
- **å‘ç°æ„ŸçŸ¥é”šç‚¹**ï¼šé€šè¿‡åˆ†æè·¨æ¨¡æ€æ³¨æ„åŠ›ï¼ˆcross-modal attentionï¼‰æ‹“æ‰‘ç»“æ„ï¼Œè¯†åˆ«å‡ºçº¦ **15% çš„é«˜è¿é€šæ€§ token**ï¼Œè¿™äº› token æ„æˆâ€œæ„ŸçŸ¥é”šç‚¹â€ï¼Œè´Ÿè´£å°†æ¨ç†è¿‡ç¨‹é”šå®šåœ¨å›¾åƒä¸Šã€‚
- **å›¾èšç±»åˆ†ç»„**ï¼šæ„å»ºåŸºäºæ³¨æ„åŠ›ç›¸ä¼¼æ€§çš„ token å›¾ï¼Œå¹¶ä½¿ç”¨ METIS ç®—æ³•è¿›è¡Œè¯­ä¹‰èšç±»ï¼Œå½¢æˆå…·æœ‰åŠŸèƒ½ä¸€è‡´æ€§çš„æ¨ç†æ­¥éª¤å•å…ƒã€‚
- **è½¯åŠ æƒä¼˜åŠ¿è°ƒåˆ¶**ï¼šæ ¹æ®æ¯ä¸ª cluster çš„è·¨æ¨¡æ€è¿é€šå¯†åº¦ï¼ˆconnectivity densityï¼‰ï¼ŒåŠ¨æ€è°ƒæ•´å…¶å¯¹åº”çš„ advantage ä¿¡å·ï¼Œå®ç°ç»†ç²’åº¦çš„ credit assignmentã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç‰¹æ€§ | ä¼ ç»Ÿ RLVR æ–¹æ³•ï¼ˆå¦‚ GRPO, DAPOï¼‰ | AT-RL |
|------|-------------------------------|-------|
| Credit Assignment | å‡åŒ€å¹¿æ’­è‡³æ‰€æœ‰ token | é›†ä¸­äºé«˜è¿é€šæ€§ anchor tokens |
| è§†è§‰æ¥åœ°èƒ½åŠ› | å¼±ï¼Œæ˜“å—è¯­è¨€å…ˆéªŒå¹²æ‰° | æ˜¾è‘—å¢å¼ºï¼Œæå‡ grounding ç²¾åº¦ |
| æ¨¡å‹æ•ˆç‡ | æ— é¢å¤–å¼€é”€ | ä»…å¼•å…¥ **1.2%** é¢å¤–è®¡ç®—å¼€é”€ |
| å¯æ‰©å±•æ€§ | å›ºå®šç­–ç•¥ | æ”¯æŒä» 3B åˆ° 32B æ¨¡å‹ä¸€è‡´å¢ç›Š |
| æ³›åŒ–æ€§ | å¤šæ•°é™äºé™æ€å›¾åƒ | æˆåŠŸæ‰©å±•è‡³è§†é¢‘ç†è§£ä»»åŠ¡ |

æ­¤å¤–ï¼ŒAT-RL æ˜¯ **plug-and-play** çš„ï¼Œå¯æ— ç¼é›†æˆåˆ° GRPOã€DAPOã€GSPO ç­‰ä¸»æµ RLVR æ¡†æ¶ä¸­ï¼Œæ— éœ€ä¿®æ”¹ç½‘ç»œæ¶æ„æˆ–å¥–åŠ±è®¾è®¡ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†

| ç±»åˆ« | æ•°æ®é›† |
|------|--------|
| ä¸»è®­ç»ƒæ•°æ® | **ViRL-39K**ï¼ˆç”¨äº RL å¾®è°ƒï¼‰ |
| è·¨æ•°æ®é›†æ³›åŒ– | **Geometry-3K**, **GeoQA-8K** |
| æ•°å­¦æ¨ç†è¯„æµ‹ | **MathVista**, **MathVerse**, **MathVision**, **GeoQAtest**, **WeMath** |
| å¤šå­¦ç§‘ç†è§£ | **MMMU-Pro**, **MMMU_Val**, **EMMA_core** |
| å®é™…åœºæ™¯ | **MEGA** |
| å›¾è¡¨ç†è§£ | **ChartQAPro**, **ChartMimic** |
| è§†é¢‘ç†è§£ | **Video-R1**ï¼ˆå« VSI-Bench, VideoMMMU, MMVU å­é›†ï¼‰ |

---

### âš™ï¸ å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

- **æ¨¡å‹ç³»åˆ—**ï¼šQwen2.5-VL-3B / 7B / 32B / 72B-Instruct
- **è¯„ä¼°åè®®**ï¼š
  - ä½¿ç”¨ `Acc@1` æŒ‡æ ‡ï¼Œåœ¨æ¸©åº¦ `0.1` ä¸‹è¿›è¡Œé›¶æ ·æœ¬æµ‹è¯•ã€‚
  - æ‰€æœ‰æ–¹æ³•å‡é‡‡ç”¨ç»Ÿä¸€è¶…å‚æ•°é…ç½®ï¼Œè¿è¡Œäº 8Ã—NVIDIA A100 GPUã€‚
- **ç­”æ¡ˆæå–ç­–ç•¥**ï¼š
  - ä¼˜å…ˆæå– `\boxed{}` å†…å®¹ï¼›
  - è‹¥å¤±è´¥ï¼Œåˆ™é€šè¿‡å…¨æ–‡æœç´¢é€‰é¡¹å­—æ¯æˆ–æ•°å€¼ã€‚
- **éªŒè¯æ–¹å¼**ï¼šä½¿ç”¨ Qwen2.5-72B-Instruct ä½œä¸º LLM Judge è¿›è¡Œè¯­ä¹‰æ­£ç¡®æ€§åˆ¤æ–­ã€‚

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”

| åŸºçº¿ç±»åˆ« | æ–¹æ³•åˆ—è¡¨ |
|---------|----------|
| ç»Ÿä¸€ä¿¡ç”¨åˆ†é… | GRPO, DAPO, GSPO, SAPO |
| ç»†ç²’åº¦ä¿¡ç”¨åˆ†é… | StepGRPO, FT-RL, VPPO |
| å…¶ä»– | SFTï¼ˆç›‘ç£å¾®è°ƒï¼‰ã€Zero-shot |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 3ï¼‰

| æ–¹æ³• | MathVista | MathVerse | MMMU-Pro | MEGA | ChartQAPro |
|------|-----------|-----------|----------|------|------------|
| Qwen2.5-VL-32B (Zero-shot) | 75.7 | 49.3 | 48.5 | 48.9 | 43.4 |
| Qwen2.5-VL-32B + VPPO | 78.3 | 54.5 | 49.2 | 52.3 | 46.6 |
| **Qwen2.5-VL-32B + AT-RL (ours)** | **80.2** | **56.6** | **51.9** | **53.0** | **48.4** |
| Qwen2.5-VL-72B-Instruct (Zero-shot) | 77.8 | 57.2 | 51.6 | 49.6 | 47.2 |

> âœ… **äº®ç‚¹**ï¼š**32B æ¨¡å‹ + AT-RL è¶…è¶Šäº†æ›´å¤§çš„ 72B-Instruct æ¨¡å‹**ï¼Œå°¤å…¶åœ¨ MathVista ä¸Šè¾¾åˆ° **80.2**ï¼Œæ˜¾è‘—é¢†å…ˆã€‚

---

### ğŸ” ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœï¼ˆTable 1 & Table 3ï¼‰

- åœ¨ Qwen2.5-VL-7B ä¸Šï¼ŒSAPO + AT-RL ç›¸æ¯”åŸå§‹ SAPO æå‡é«˜è¾¾ **+8.24pp**ï¼ˆå¹³å‡æå‡ï¼‰ã€‚
- åœ¨å¤šä¸ªä»»åŠ¡ä¸Šï¼ŒAT-RL å‡ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼ŒåŒ…æ‹¬æœ€å…ˆè¿›çš„ VPPO å’Œ SAPOã€‚
- åœ¨è§†é¢‘ç†è§£ä»»åŠ¡ä¸­ï¼ˆTable 4ï¼‰ï¼š
  - è¾“å…¥ 64 å¸§æ—¶ï¼ŒAT-RL è¾¾åˆ° **56.8 å¹³å‡å‡†ç¡®ç‡**ï¼Œæ¯” T-GRPO é«˜å‡º **+5.1pp**ï¼Œæ¯”é›¶æ ·æœ¬é«˜å‡º **+9.4pp**ã€‚
  - åœ¨ VSI-Bench ä¸Šå¢ç›Šè¾¾ **+11.8pp**ï¼Œè¡¨æ˜å…¶èƒ½æœ‰æ•ˆæ•æ‰æ—¶é—´ç»´åº¦ä¸Šçš„å…³é”® anchor tokensã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰è½¯åŠ æƒ vs ç¡¬æˆªæ–­ï¼ˆTable 5ï¼‰
| æ–¹æ³• | MathVerse æå‡ï¼ˆÎ”ï¼‰ |
|------|------------------|
| Hard Truncation (top 15%) | +2.96pp |
| Random Weighting | -1.52pp |
| Reverse Weighting | -2.82pp |
| **AT-RL (Soft Weighting)** | **+5.65pp** |

> ç»“è®ºï¼š**è½¯åŠ æƒç­–ç•¥è¿œä¼˜äºç¡¬æ©ç æˆ–éšæœºé€‰æ‹©**ï¼Œè¯´æ˜ä¿ç•™ä½æƒé‡ token çš„æ¢¯åº¦æœ‰åŠ©äºç»´æŒè¯­è¨€è¿è´¯æ€§ã€‚

#### ï¼ˆ2ï¼‰åç½®æ ¡æ­£çš„é‡è¦æ€§ï¼ˆTable 6ï¼‰
| æ–¹æ³• | MathVerse |
|------|----------|
| AT-RL w/o Bias Correction | 34.20 |
| **AT-RL w/ Bias Correction** | **37.50** |

> å»é™¤æ³¨æ„åŠ›åå·®åæ€§èƒ½æ˜æ˜¾æå‡ï¼Œè¯æ˜ debiasing å¯¹è¯†åˆ«çœŸå®æ„ŸçŸ¥é”šç‚¹è‡³å…³é‡è¦ã€‚

#### ï¼ˆ3ï¼‰ç»„ä»¶æ¶ˆèï¼ˆTable 7ï¼‰
| é…ç½® | MathVerse â†‘ | MathVista â†‘ |
|------|-------------|------------|
| æ— åˆ†ç»„ï¼ˆRaw Attentionï¼‰ | +2.73 | +2.20 |
| ä»…æœ‰åˆ†ç»„ï¼ˆMETISï¼‰ | +3.56 | +3.20 |
| å®Œæ•´ AT-RLï¼ˆå« refine + expandï¼‰ | **+4.98** | **+4.50** |

> è¡¨æ˜ **è¯­ä¹‰åˆ†ç»„ + ç»“æ„ä¼˜åŒ–ï¼ˆdenoising & neighborhood expansionï¼‰å…±åŒè´¡çŒ®æœ€å¤§å¢ç›Š**ã€‚

#### ï¼ˆ4ï¼‰è®¡ç®—æ•ˆç‡åˆ†æ
- AT-RL æ¨¡å—ä»…å¢åŠ  **1.2%** çš„è®­ç»ƒè¿­ä»£å¼€é”€ã€‚
- å‰å‘ä¼ æ’­å  65.4%ï¼Œåå‘ä¼ æ’­å  33.5%ï¼Œå…¶ä½™ä¸º AT-RL å¤„ç†æµç¨‹ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **å­˜åœ¨æ„ŸçŸ¥é”šç‚¹ï¼ˆPerceptual Anchorsï¼‰**ï¼š
   - MLLM æ¨ç†é“¾ä¸­ä»…æœ‰çº¦ **15% çš„ token å±•ç°å‡ºå¼ºè·¨æ¨¡æ€è¿é€šæ€§**ï¼Œå®ƒä»¬å……å½“â€œç¯å¡”â€è§’è‰²ï¼Œå°†æ¨ç†é”šå®šäºå›¾åƒã€‚
   - é«˜è¿é€šæ€§ token å¤šä¸ºåŠ¨ä½œå¯¼å‘è¯ï¼ˆå¦‚ â€œcalculateâ€, â€œgivenâ€, â€œassumeâ€ï¼‰ï¼Œè€Œå¤§å¤šæ•° token ä»…ä¸ºè¯­è¨€è¿‡æ¸¡æœåŠ¡ã€‚

2. **ä¿¡ç”¨åº”å½’äºé”šç‚¹**ï¼š
   - RLVR ä¸­çš„ credit assignment åº”èšç„¦äºè¿™äº›æ„ŸçŸ¥é”šç‚¹ï¼Œè€Œéå¹³å‡åˆ†é…ã€‚
   - æ­£ç¡®æˆ–é”™è¯¯çš„ç­”æ¡ˆéƒ½ä¼šè®© anchor tokens æ‰¿æ‹…ä¸»è¦è´£ä»»ï¼Œå› æ­¤å¼ºåŒ–ä¿¡å·å¿…é¡»é›†ä¸­äºæ­¤ã€‚

3. **AT-RL æ˜¾è‘—æå‡æ€§èƒ½ä¸”é«˜æ•ˆ**ï¼š
   - åœ¨ä¸æ”¹å˜æ¨¡å‹ç»“æ„çš„å‰æä¸‹ï¼ŒAT-RL å®ç°äº†è·¨è§„æ¨¡ã€è·¨ä»»åŠ¡çš„ä¸€è‡´å¢ç›Šã€‚
   - **32B æ¨¡å‹è¶…è¶Š 72B åŸºçº¿**ï¼ŒéªŒè¯äº†â€œè´¨é‡èƒœäºæ•°é‡â€çš„æ¨ç†ä¼˜åŒ–è·¯å¾„ã€‚

4. **SFT ä¸ RL äº’è¡¥**ï¼š
   - RLï¼ˆå¦‚ AT-RLï¼‰æ“…é•¿ä¼˜åŒ–å·²æœ‰çŸ¥è¯†çš„è§†è§‰æ¥åœ°ï¼›
   - SFT/CPT æ›´é€‚åˆæ³¨å…¥æ–°çŸ¥è¯†ï¼›
   - äºŒè€…ç»“åˆæ‰èƒ½åŒæ—¶è§£å†³ **Knowledge Deployment Error (KDE)** å’Œ **Visual Perception Error (VPE)**ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

1. **æ— æ³•å¼¥è¡¥çŸ¥è¯†ç¼ºå¤±**ï¼š
   - å¦‚ Discussion 4 æ‰€è¿°ï¼ŒAT-RL ä¸æä¾›æ–°çš„é¢†åŸŸçŸ¥è¯†ï¼Œè‹¥æ¨¡å‹æœ¬èº«ç¼ºä¹ç›¸å…³æ¦‚å¿µï¼ˆå¦‚å‡ ä½•å®šç†ï¼‰ï¼Œä»ä¼šå¤±è´¥ã€‚

2. **ä¾èµ–é«˜è´¨é‡æ³¨æ„åŠ›ä¿¡å·**ï¼š
   - è‹¥åŸºç¡€æ¨¡å‹çš„ cross-modal attention æœ¬èº«ä¸å‡†ï¼ˆå¦‚æ—©æœŸå±‚æ··ä¹±ï¼‰ï¼Œåˆ™ anchor å®šä½å¯èƒ½å¤±æ•ˆã€‚

3. **èšç±»å‚æ•°æ•æ„Ÿæ€§**ï¼š
   - å°½ç®¡é»˜è®¤å‚æ•°è¡¨ç°ç¨³å®šï¼Œä½†åœ¨æç«¯çŸ­/é•¿åºåˆ—ä¸­éœ€è°ƒæ•´èšç±»æ•°é‡ $ K $ æˆ–é˜ˆå€¼ $ T_{sim} $ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **è”åˆè®­ç»ƒ SFT + AT-RL**ï¼š
   - è®¾è®¡ç«¯åˆ°ç«¯æ¡†æ¶ï¼ŒåŒæ­¥æ³¨å…¥çŸ¥è¯†å¹¶ä¼˜åŒ– groundingã€‚

2. **åŠ¨æ€è¯†åˆ« anchor ç±»å‹**ï¼š
   - åŒºåˆ†ä¸åŒç±»å‹çš„ anchorï¼ˆå¦‚ç©ºé—´å®šä½ã€æ•°å€¼è¯»å–ã€é€»è¾‘åˆ¤æ–­ï¼‰ï¼Œå®æ–½å·®å¼‚åŒ–å¼ºåŒ–ã€‚

3. **æ‰©å±•è‡³æ›´å¤šæ¨¡æ€**ï¼š
   - å°† AT-RL æ¨å¹¿è‡³éŸ³é¢‘ã€3D ç‚¹äº‘ç­‰å¤šæ¨¡æ€åœºæ™¯ï¼Œæ¢ç´¢é€šç”¨çš„è·¨æ¨¡æ€ anchoring æœºåˆ¶ã€‚

4. **åœ¨çº¿ anchor å‘ç°ä¸åé¦ˆ**ï¼š
   - æ„å»ºé—­ç¯ç³»ç»Ÿï¼Œåœ¨æ¨ç†è¿‡ç¨‹ä¸­å®æ—¶æ£€æµ‹ anchor å¹¶å¼•å¯¼æ¨¡å‹ä¿®æ­£è·¯å¾„ã€‚

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> **Reasoning quality is governed not by token quantity, but by the fidelity of cross-modal anchoring.**  
> â€”â€” çœŸæ­£å†³å®šæ¨ç†è´¨é‡çš„ä¸æ˜¯ token æ•°é‡ï¼Œè€Œæ˜¯è·¨æ¨¡æ€é”šå®šçš„ç²¾ç¡®æ€§ã€‚

</details>

---

### 15. [Few-Shot Design Optimization by Exploiting Auxiliary Information](https://arxiv.org/abs/2602.12112)

**Authors**: Arjun Mani, Carl Vondrick, Richard Zemel  
**Category**: cs.LG  
**Published**: 2026-02-13  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.12112v1  

#### Abstract
Many real-world design problems involve optimizing an expensive black-box function $f(x)$, such as hardware design or drug discovery. Bayesian Optimization has emerged as a sample-efficient framework for this problem. However, the basic setting considered by these methods is simplified compared to r...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šFew-Shot Design Optimization by Exploiting Auxiliary Information**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
è¯¥è®ºæ–‡é’ˆå¯¹ç°å®ä¸–ç•Œä¸­**æ˜‚è´µé»‘ç›’å‡½æ•°ä¼˜åŒ–**ï¼ˆexpensive black-box optimizationï¼‰çš„é—®é¢˜ï¼ŒæŒ‡å‡ºä¼ ç»Ÿ **Bayesian Optimization (BayesOpt)** å­˜åœ¨ä¸¤ä¸ªå…³é”®å±€é™ï¼š
1. **ä»…ä¾èµ–æ ‡é‡å¥–åŠ± $f(x)$**ï¼Œå¿½ç•¥äº†å®éªŒè¿‡ç¨‹ä¸­äº§ç”Ÿçš„ä¸°å¯Œè¾…åŠ©ä¿¡æ¯ï¼ˆå¦‚ä¼ æ„Ÿå™¨æ—¶åºã€å­¦ä¹ æ›²çº¿ç­‰ï¼‰ï¼›
2. **å•ä»»åŠ¡è®¾å®š**ï¼Œæ— æ³•åˆ©ç”¨å†å²ç›¸ä¼¼ä»»åŠ¡çš„çŸ¥è¯†è¿›è¡Œè¿ç§»ã€‚

ç°å®ä¸­è®¸å¤šè®¾è®¡ä»»åŠ¡ï¼ˆå¦‚æœºå™¨äººç¡¬ä»¶è®¾è®¡ã€è¯ç‰©å‘ç°ã€ç¥ç»ç½‘ç»œè¶…å‚è°ƒä¼˜ï¼‰ä¸ä»…äº§ç”Ÿé«˜ç»´ã€å¤šæ¨¡æ€çš„**è¾…åŠ©ä¿¡æ¯ $h(x)$**ï¼Œè¿˜å¾€å¾€å±äºåŒä¸€ä»»åŠ¡å®¶æ—ï¼Œå…·å¤‡å¯è¿ç§»çš„ç»éªŒã€‚å¦‚ä½•æœ‰æ•ˆåˆ©ç”¨è¿™äº›ä¿¡æ¯ä»¥å®ç°æ›´é«˜æ•ˆçš„å°‘æ ·æœ¬ï¼ˆfew-shotï¼‰ä¼˜åŒ–ï¼Œæ˜¯æœ¬æ–‡è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
ä½œè€…æå‡ºäº†ä¸€ç§**æ–°çš„ä¼˜åŒ–æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> **å°†è¾…åŠ©ä¿¡æ¯ $h(x)$ èå…¥ä¸Šä¸‹æ–‡ï¼ˆcontextï¼‰ï¼Œè®­ç»ƒä¸€ä¸ªç¥ç»æ¨¡å‹æ¥é¢„æµ‹æœªè§è®¾è®¡çš„æ€§èƒ½ $f(x)$ï¼Œä»è€Œä½œä¸º BayesOpt çš„ä»£ç†æ¨¡å‹ï¼ˆsurrogate modelï¼‰ã€‚**

å…·ä½“åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

- **æ–°é—®é¢˜è®¾å®š**ï¼šæ­£å¼å®šä¹‰äº†ä¸€ä¸ªåŒ…å«â€œè¾…åŠ©ä¿¡æ¯â€å’Œâ€œå¤šä»»åŠ¡å†å²â€çš„è®¾è®¡ä¼˜åŒ–æ–°èŒƒå¼ï¼Œå¼ºè°ƒæ¨¡å‹éœ€ä» $h(x)$ ä¸­å­¦ä¹ é€šç”¨è¡¨å¾ä»¥åŠ é€Ÿæ–°ä»»åŠ¡ä¼˜åŒ–ã€‚
- **åŸºäº Transformer çš„ç¥ç»è¿‡ç¨‹æ¶æ„**ï¼šé‡‡ç”¨ç±»ä¼¼ **Transformer Neural Processes** çš„ç»“æ„ï¼Œæ¨¡å‹æ¥å—ä¸€ä¸ªåŒ…å« $(x, f(x), h(x))$ çš„ few-shot ä¸Šä¸‹æ–‡é›†ï¼Œå¯¹ç›®æ ‡è®¾è®¡ $x$ é¢„æµ‹å…¶ $f(x)$ åˆ†å¸ƒã€‚
- **ç«¯åˆ°ç«¯å­¦ä¹ è¡¨å¾**ï¼šæ¨¡å‹ç›´æ¥å­¦ä¹ å¦‚ä½•ç¼–ç  $h(x)$ å¹¶ç”¨äºé¢„æµ‹ $f(x)$ï¼Œè€Œéå¼ºåˆ¶å»ºæ¨¡ $h(x)$ æœ¬èº«ï¼Œé¿å…äº†é«˜ç»´è¾“å‡ºå¸¦æ¥çš„è®­ç»ƒå›°éš¾ã€‚
- **æ— éœ€å¾®è°ƒçš„éƒ¨ç½²æ–¹å¼**ï¼šè®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹å†»ç»“ï¼Œåœ¨æ–°ä»»åŠ¡ä¸Šä»…é€šè¿‡æ›´æ–°ä¸Šä¸‹æ–‡å³å¯è¿›è¡Œæ¨ç†ï¼Œæ— éœ€é‡æ–°è®­ç»ƒï¼Œé€‚åˆå¿«é€Ÿéƒ¨ç½²ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| å¯¹æ¯”ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | æœ¬æ–‡æ–¹æ³• |
|---------|--------|--------|
| **æ˜¯å¦åˆ©ç”¨ $h(x)$** | å¦ï¼ˆæˆ–ç®€å•æ‹¼æ¥ï¼‰ | æ˜¯ï¼Œä¸”å­¦ä¹ å…¶è¯­ä¹‰è¡¨å¾ |
| **æ˜¯å¦æ”¯æŒå¤šä»»åŠ¡è¿ç§»** | å•ä»»åŠ¡æˆ–å¼±è¿ç§» | æ˜¾å¼åˆ©ç”¨ä»»åŠ¡å†å²è¿›è¡Œ few-shot è¿ç§» |
| **æ¨¡å‹çµæ´»æ€§** | GP å—é™äºæ ¸å‡½æ•°å‡è®¾ | ç¥ç»ç½‘ç»œå¯å­¦ä¹ å¤æ‚éçº¿æ€§å…³ç³» |
| **è®¡ç®—æ•ˆç‡** | GP æ¨ç†æ…¢ï¼Œéšæ•°æ®å¢é•¿ | Transformer æ¶æ„æ”¯æŒå¹¶è¡Œï¼Œæ¨ç†å¿« |
| **è¡¨ç¤ºèƒ½åŠ›** | éš¾ä»¥å¤„ç†é«˜ç»´å¼‚æ„ $h(x)$ | å¯çµæ´»ç¼–ç å›¾åƒã€åºåˆ—ç­‰å¤šç§å½¢å¼ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
è®ºæ–‡åœ¨ä¸¤ä¸ªæˆªç„¶ä¸åŒçš„é¢†åŸŸéªŒè¯æ–¹æ³•æœ‰æ•ˆæ€§ï¼š

#### **(1) æœºå™¨äººæŠ“æ‰‹è®¾è®¡ä»»åŠ¡ï¼ˆGripper Design Taskï¼‰**
- **è‡ªå»ºå¤§è§„æ¨¡åŸºå‡†æ•°æ®é›†**ï¼šåŸºäº **ShapeNet** ä¸­ 997 ä¸ªç‰©ä½“æ„å»ºã€‚
- **æ¯ä¸ªä»»åŠ¡**ï¼šä¸ºç‰¹å®šç‰©ä½“è®¾è®¡æœ€ä¼˜æŠ“æ‰‹å½¢çŠ¶ $x$ã€‚
- **$f(x)$**ï¼šæŠ“å–ç¨³å®šæ€§ï¼ˆæŠµæŠ—æ‰°åŠ¨åŠ›çš„æœ€å¤§ç‰›é¡¿æ•°ï¼Œæœ€é«˜çº¦ 6.0Nï¼‰ã€‚
- **$h(x)$**ï¼šæ¯æ¬¡ä»¿çœŸä¸­çš„**è§¦è§‰åé¦ˆ**ï¼ŒåŒ…æ‹¬ï¼š
  - å·¦å³å¤¹çˆªå†…è¡¨é¢çš„ 16Ã—16 è§¦è§‰å›¾ï¼ˆtactile mapsï¼‰
  - å…¶ä»–é¢çš„æ¥è§¦è¯»æ•°
  - ç³»ç»ŸçŠ¶æ€ï¼ˆå…³èŠ‚ä½ç½®ã€é€Ÿåº¦ã€æ–½åŠ åŠ›ç­‰ï¼‰
- **æ•°æ®è§„æ¨¡**ï¼šå…± **428ä¸‡æ¬¡** æŠ“æ‰‹è¯„ä¼°ï¼Œå¹³å‡æ¯ä¸ªç‰©ä½“ ~4300 ä¸ªè®¾è®¡ï¼Œæ˜¯å½“å‰æœ€å¤§çš„å¤šä»»åŠ¡ BayesOpt åŸºå‡†ä¹‹ä¸€ã€‚

#### **(2) ç¥ç»ç½‘ç»œè¶…å‚æ•°è°ƒä¼˜ä»»åŠ¡ï¼ˆHyperparameter Tuningï¼‰**
- **ä½¿ç”¨å…¬å¼€åŸºå‡† LCBench**ï¼š
  - åŒ…å« 35 ä¸ªåˆ†ç±»ä»»åŠ¡
  - æ¯ä¸ªä»»åŠ¡è¯„ä¼° 2000 ä¸ªè¶…å‚é…ç½®
- **$f(x)$**ï¼šæœ€ä½³éªŒè¯å‡†ç¡®ç‡
- **$h(x)$**ï¼šè®­ç»ƒå…¨è¿‡ç¨‹çš„**æ¯ epoch å­¦ä¹ æ›²çº¿**ï¼ŒåŒ…æ‹¬ï¼š
  - è®­ç»ƒ/éªŒè¯å‡†ç¡®ç‡
  - ç±»åˆ«å¹³è¡¡å‡†ç¡®ç‡
  - å­¦ä¹ ç‡å˜åŒ–ï¼ˆcosine annealingï¼‰

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **è®­ç»ƒé˜¶æ®µ**
- **æ¨¡å‹è¾“å…¥**ï¼šä¸Šä¸‹æ–‡é›† $C = \{(x_i, f(x_i), h(x_i))\}$ å’Œç›®æ ‡è®¾è®¡é›† $T_x$
- **ç›®æ ‡**ï¼šé¢„æµ‹ $P_\theta(f(T_x) | C, T_x)$
- **æŸå¤±å‡½æ•°**ï¼šè´Ÿå¯¹æ•°ä¼¼ç„¶ï¼ˆNLLï¼‰
- **é‡‡æ ·ç­–ç•¥**ï¼šä¸Šä¸‹æ–‡å¤§å°éšæœºé‡‡æ ·ï¼ˆGripper: 5â€“30, HP: 3â€“30ï¼‰ï¼Œç›®æ ‡é›†å›ºå®šä¸º 100

#### **ä¼˜åŒ–é˜¶æ®µï¼ˆBayesOpt Loopï¼‰**
- åˆå§‹ä¸Šä¸‹æ–‡ï¼š5 ä¸ªï¼ˆGripperï¼‰æˆ– 3 ä¸ªï¼ˆHPï¼‰éšæœºè®¾è®¡
- æ¯è½®é€‰æ‹©ä¸‹ä¸€ä¸ª $x_{t+1} = \arg\max_x \alpha(x, P_\theta(\cdot|C_t, x))$
- ä½¿ç”¨ **Probability of Improvement (PI)** ä½œä¸º acquisition function
- æ€»è¿­ä»£æ¬¡æ•°ï¼š30 æ¬¡

#### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Target MSE** | åœ¨ç›®æ ‡é›†ä¸Šçš„ $f(x)$ é¢„æµ‹å‡æ–¹è¯¯å·® |
| **Avg. Normalized Best $f(x)$** | å½’ä¸€åŒ–åçš„æœ€ä¼˜æ€§èƒ½éšè¿­ä»£çš„å˜åŒ– |
| **Average Regret** | å½“å‰æœ€ä¼˜ä¸å…¨å±€æœ€ä¼˜ä¹‹é—´çš„å·®è· |
| **Fraction Solved** | è¾¾åˆ°è¿‘ä¼¼æœ€ä¼˜ï¼ˆå¦‚ regret â‰¤ 0.5 æˆ– 0.01ï¼‰çš„ä»»åŠ¡æ¯”ä¾‹ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| åŸºçº¿ | æ˜¯å¦ç”¨ $h(x)$ | æ˜¯å¦å¤šä»»åŠ¡ | è¯´æ˜ |
|------|---------------|------------|------|
| **Ours w/o h** | âŒ | âœ… | æ¶ˆèç‰ˆæœ¬ï¼Œä»…ç”¨ $f(x)$ï¼Œå…¶ä½™ç»“æ„ç›¸åŒ |
| **DGP** | âŒ | âœ… | Deep Kernel GPï¼ŒSoTA å¤šä»»åŠ¡ BayesOpt æ–¹æ³• |
| **GP-H** | âœ… | âœ… | å¤šè¾“å‡º GPï¼Œè”åˆå»ºæ¨¡ $(E_\phi(h(x)), f(x))$ |
| **STGP** | âŒ | âŒ | å•ä»»åŠ¡ GPï¼Œä»…åœ¨æµ‹è¯•æ—¶æ‹Ÿåˆå½“å‰ä¸Šä¸‹æ–‡ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **(1) æŠ“æ‰‹è®¾è®¡ä»»åŠ¡ï¼ˆGripper Designï¼‰**
| æ–¹æ³• | æœ€ç»ˆå½’ä¸€åŒ–æ€§èƒ½ | 30æ­¥è§£å†³ç‡ï¼ˆregret â‰¤ 0.5ï¼‰ |
|------|----------------|----------------------------|
| **Ours (full)** | **~0.89** | **67.2%** |
| Ours w/o h | ~0.82 | 58.0% |
| DGP | ~0.80 | ~55% |
| GP-H | ~0.78 | ~50% |
| STGP | ~0.75 | ~45% |

- **é¢„æµ‹ MSE**ï¼šåœ¨ context size=5 æ—¶ï¼Œ**Ours MSE=170.9**ï¼Œè€Œ Ours w/o h=201.6ï¼Œè¡¨æ˜ $h(x)$ æ˜¾è‘—æå‡é¢„æµ‹ç²¾åº¦ã€‚
- **æ”¶æ•›é€Ÿåº¦**ï¼šOurs åœ¨å‰ 10 æ­¥å³æ˜¾è‘—é¢†å…ˆï¼Œè¯´æ˜èƒ½æ›´å¿«è¯†åˆ«é«˜è´¨é‡è®¾è®¡ã€‚

#### **(2) è¶…å‚è°ƒä¼˜ä»»åŠ¡ï¼ˆLCBenchï¼‰**
| æ–¹æ³• | 30æ­¥è§£å†³ç‡ï¼ˆwithin 0.01 of maxï¼‰ |
|------|----------------------------------|
| **Ours (full)** | **89.7%** |
| Ours w/o h | 82.1% |
| DGP | ~80% |
| GP-H | ~75% |
| STGP | ~70% |

- åœ¨è¾ƒå° contextï¼ˆå¦‚ 3â€“5ï¼‰ä¸‹ï¼ŒOurs çš„ä¼˜åŠ¿å°¤ä¸ºæ˜æ˜¾ï¼Œä½“ç°å…¶å¼ºå¤§çš„ few-shot å­¦ä¹ èƒ½åŠ›ã€‚
- GP-H è¡¨ç°ä¸ä½³ï¼Œè¯´æ˜ç®€å•åœ°å°† $h(x)$ æ‹¼æ¥è¿› GP å¹¶ä¸èƒ½æœ‰æ•ˆåˆ©ç”¨å…¶ä¿¡æ¯ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**
- **Ours vs. Ours w/o h**ï¼šåœ¨ä¸¤ä¸ªä»»åŠ¡ä¸Šå‡æœ‰æ˜¾è‘—å·®è·ï¼Œè¯æ˜ **$h(x)$ çš„ä»·å€¼ä¸å¯æ›¿ä»£**ã€‚
- **ä¸åŒ $h(x)$ ç¼–ç æ–¹å¼**ï¼šè®ºæ–‡å°è¯•äº†å¤šç§ç¼–ç å™¨ï¼ˆCNN for tactile, MLP for curvesï¼‰ï¼Œæœ€ç»ˆç»“æ„ç»è¿‡éªŒè¯æœ‰æ•ˆã€‚
- **ä¸Šä¸‹æ–‡å¤§å°å½±å“**ï¼šéšç€ context å¢å¤§ï¼Œæ‰€æœ‰æ–¹æ³•æ€§èƒ½ä¸Šå‡ï¼Œä½† **Ours åœ¨å° context ä¸‹ä¼˜åŠ¿æœ€å¤§**ï¼Œå‡¸æ˜¾å…¶ few-shot èƒ½åŠ›ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. âœ… **è¾…åŠ©ä¿¡æ¯ $h(x)$ è•´å«æ·±å±‚ä¼˜åŒ–ä¿¡å·**ï¼šä»…é  $f(x)$ å¾ˆéš¾åŒºåˆ†å¤±è´¥åŸå› ï¼Œè€Œ $h(x)$ï¼ˆå¦‚è§¦è§‰åˆ†å¸ƒã€å­¦ä¹ æ›²çº¿è¶‹åŠ¿ï¼‰æä¾›äº†â€œä¸ºä½•å¤±è´¥â€çš„çº¿ç´¢ï¼Œå¸®åŠ©æ¨¡å‹æ¨æ–­æ”¹è¿›æ–¹å‘ã€‚
2. âœ… **ç¥ç»æ¨¡å‹ä¼˜äº GP å¤„ç†é«˜ç»´ $h(x)$**ï¼šGP-H è¡¨ç°å·®ï¼Œè¯´æ˜ä¼ ç»Ÿ GP éš¾ä»¥å»ºæ¨¡å¤æ‚å¼‚æ„çš„è¾…åŠ©ä¿¡æ¯ï¼›è€Œç¥ç»ç½‘ç»œå¯é€šè¿‡ç«¯åˆ°ç«¯å­¦ä¹ æå–æœ‰ç”¨ç‰¹å¾ã€‚
3. âœ… **Few-shot é¢„æµ‹èƒ½åŠ›å¯è¿ç§»**ï¼šæ¨¡å‹åœ¨è®­ç»ƒæ—¶ä»æœªè§è¿‡æµ‹è¯•ä»»åŠ¡ï¼Œå´èƒ½åœ¨æå°‘é‡æ ·æœ¬ä¸‹å¿«é€Ÿå»ºç«‹å‡†ç¡®ä»£ç†æ¨¡å‹ï¼Œå®ç°é«˜æ•ˆä¼˜åŒ–ã€‚
4. âœ… **å‘ç°åˆ›é€ æ€§è®¾è®¡ç­–ç•¥**ï¼šæ¨¡å‹å­¦ä¼šåˆ©ç”¨ç‰©ä½“ç¼éš™ã€è–„ç»“æ„ç­‰è¿›è¡Œç¨³å®šæŠ“æ¡ï¼ˆè§ Fig. 8ï¼‰ï¼Œç”šè‡³é€šè¿‡åŠ¨æ€æ—‹è½¬è°ƒæ•´å§¿æ€ï¼ˆFig. 7ï¼‰ï¼Œè¿œè¶…äººç±»ç›´è§‰ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–ä»»åŠ¡åŒåˆ†å¸ƒå‡è®¾**ï¼šæµ‹è¯•ä»»åŠ¡éœ€æ¥è‡ªä¸è®­ç»ƒä»»åŠ¡ç›¸åŒçš„åˆ†å¸ƒï¼Œå¯¹ OOD ä»»åŠ¡æ³›åŒ–èƒ½åŠ›æœªçŸ¥ã€‚
- **ä¸æ”¯æŒä¸»åŠ¨é€‰æ‹© $h(x)$**ï¼šå½“å‰ $h(x)$ æ˜¯è¢«åŠ¨è§‚æµ‹çš„ï¼Œæœªè€ƒè™‘å¦‚ä½•è®¾è®¡å®éªŒä»¥è·å–æœ€æœ‰ä¿¡æ¯é‡çš„ $h(x)$ã€‚
- **é™æ€ä¸Šä¸‹æ–‡æœºåˆ¶**ï¼šæœªå¯¹ä¸Šä¸‹æ–‡è¿›è¡Œç­›é€‰æˆ–è®°å¿†å‹ç¼©ï¼Œå¯èƒ½å—å™ªå£°æ•°æ®å½±å“ã€‚
- **ç¦»æ•£æœç´¢ç©ºé—´ä¸ºä¸»**ï¼šè¿ç»­ç©ºé—´ä¼˜åŒ–éœ€ç»“åˆæ¢¯åº¦æ–¹æ³•ï¼Œå°šæœªæ·±å…¥æ¢ç´¢ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **é¢„è®­ç»ƒ + å¾®è°ƒ pipeline**ï¼šå…ˆç”¨è‡ªç›‘ç£ä»»åŠ¡ï¼ˆå¦‚é‡å»º $h(x)$ï¼‰é¢„è®­ç»ƒ $h(x)$ ç¼–ç å™¨ï¼Œå†ç”¨äºä¸‹æ¸¸é¢„æµ‹ã€‚
2. **OOD ä»»åŠ¡æ£€æµ‹ä¸å†·å¯åŠ¨èåˆ**ï¼šå½“æ¨¡å‹ä¸ç¡®å®šæ€§é«˜æ—¶ï¼Œåˆ‡æ¢è‡³åœ¨çº¿å­¦ä¹ æ¨¡å¼ï¼ˆå¦‚ STGPï¼‰è¿›è¡Œæ¢ç´¢ã€‚
3. **é•¿è§†ç•Œè§„åˆ’ï¼ˆLong-horizon Strategyï¼‰**ï¼šä¸å†å±€é™äºä¸€æ­¥æœ€ä¼˜ï¼Œè€Œæ˜¯é€‰æ‹©èƒ½æœ€å¤§åŒ–ä¿¡æ¯å¢ç›Šçš„è®¾è®¡ï¼Œä»¥æ›´å¥½ç†è§£ä»»åŠ¡ç»“æ„ã€‚
4. **æ‰©å±•æ›´å¤šæ¨¡æ€ $h(x)$**ï¼šå¦‚è¯­è¨€æè¿°ã€è§†é¢‘ã€åˆ†å­å›¾è°±ç­‰ï¼Œè¿›ä¸€æ­¥ä¸°å¯Œä¿¡æ¯æºã€‚

---

> **æ€»ç»“**ï¼šæœ¬æ–‡å¼€åˆ›æ€§åœ°å°† **auxiliary information** å¼•å…¥å¤šä»»åŠ¡è®¾è®¡ä¼˜åŒ–ï¼Œæå‡ºä¸€ç§åŸºäº **neural process + transformer** çš„ few-shot é¢„æµ‹æ¡†æ¶ï¼Œåœ¨ä¸¤ä¸ªæå…·æŒ‘æˆ˜æ€§çš„é¢†åŸŸå®ç°äº†æ˜¾è‘—è¶…è¶Š SoTA çš„æ€§èƒ½ï¼Œä¸º AI-driven ç§‘å­¦å‘ç°ä¸å·¥ç¨‹è®¾è®¡æä¾›äº†æ›´å¼ºå¤§ã€æ›´è´´è¿‘çœŸå®åœºæ™¯çš„å·¥å…·ã€‚

</details>

---

### 16. [Bi-Level Prompt Optimization for Multimodal LLM-as-a-Judge](https://arxiv.org/abs/2602.11340)

**Authors**: Bo Pan, Xuan Kan, Kaitai Zhang, Yan Yan, Shunwen Tan, Zihao He, Zixin Ding, Junjie Wu, Liang Zhao  
**Category**: cs.AI  
**Published**: 2026-02-13  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.11340v1  

#### Abstract
Large language models (LLMs) have become widely adopted as automated judges for evaluating AI-generated content. Despite their success, aligning LLM-based evaluations with human judgments remains challenging. While supervised fine-tuning on human-labeled data can improve alignment, it is costly and ...

---

### 17. [AgentLeak: A Full-Stack Benchmark for Privacy Leakage in Multi-Agent LLM Systems](https://arxiv.org/abs/2602.11510)

**Authors**: Faouzi El Yagoubi, Ranwa Al Mallah, Godwin Badu-Marfo  
**Category**: cs.AI  
**Published**: 2026-02-13  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.11510v1  

#### Abstract
Multi-agent Large Language Model (LLM) systems create privacy risks that current benchmarks cannot measure. When agents coordinate on tasks, sensitive data passes through inter-agent messages, shared memory, and tool arguments; pathways that output-only audits never inspect. We introduce AgentLeak, ...

---

### 18. [AlphaPROBE: Alpha Mining via Principled Retrieval and On-graph biased evolution](https://arxiv.org/abs/2602.11917)

**Authors**: Taian Guo, Haiyang Shen, Junyu Luo, Binqi Chen, Hongjun Ding, Jinsheng Huang, Luchen Liu, Yun Ma, Ming Zhang  
**Category**: cs.AI  
**Published**: 2026-02-13  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.11917v1  

#### Abstract
Extracting signals through alpha factor mining is a fundamental challenge in quantitative finance. Existing automated methods primarily follow two paradigms: Decoupled Factor Generation, which treats factor discovery as isolated events, and Iterative Factor Evolution, which focuses on local parent-c...

---

### 19. [Pedagogically-Inspired Data Synthesis for Language Model Knowledge Distillation](https://arxiv.org/abs/2602.12172)

**Authors**: Bowei He, Yankai Chen, Xiaokun Zhang, Linghe Kong, Philip S. Yu, Xue Liu, Chen Ma  
**Category**: cs.AI  
**Published**: 2026-02-13  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.12172v1  

#### Abstract
Knowledge distillation from Large Language Models (LLMs) to smaller models has emerged as a critical technique for deploying efficient AI systems. However, current methods for distillation via synthetic data lack pedagogical awareness, treating knowledge transfer as a one-off data synthesis and trai...

---

### 20. [Improving HPC Code Generation Capability of LLMs via Online Reinforcement Learning with Real-Machine Benchmark Rewards](https://arxiv.org/abs/2602.12049)

**Authors**: Ryo Mikasa, Shun-ichiro Hayashi, Daichi Mukunoki, Tetsuya Hoshino, Takahiro Katagiri  
**Category**: cs.LG  
**Published**: 2026-02-13  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.12049v1  

#### Abstract
Large language models (LLMs) have demonstrated strong code generation capabilities, yet the runtime performance of generated code is not guaranteed, and there have been few attempts to train LLMs using runtime performance as a reward in the HPC domain. We propose an online reinforcement learning app...

---

### 21. [AgentNoiseBench: Benchmarking Robustness of Tool-Using LLM Agents Under Noisy Condition](https://arxiv.org/abs/2602.11348)

**Authors**: Ruipeng Wang, Yuxin Chen, Yukai Wang, Chang Wu, Junfeng Fang, Xiaodong Cai, Qi Gu, Hui Su, An Zhang, Xiang Wang, Xunliang Cai, Tat-Seng Chua  
**Category**: cs.AI  
**Published**: 2026-02-13  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.11348v1  

#### Abstract
Recent advances in large language models have enabled LLM-based agents to achieve strong performance on a variety of benchmarks. However, their performance in real-world deployments often that observed on benchmark settings, especially in complex and imperfect environments. This discrepancy largely ...

---

### 22. [Gaia2: Benchmarking LLM Agents on Dynamic and Asynchronous Environments](https://arxiv.org/abs/2602.11964)

**Authors**: Romain Froger, Pierre Andrews, Matteo Bettini, Amar Budhiraja, Ricardo Silveira Cabral, Virginie Do, Emilien Garreau, Jean-Baptiste Gaya, Hugo Lauren\c{c}on, Maxime Lecanu, Kunal Malkan, Dheeraj Mekala, Pierre M\'enard, Gerard Moreno-Torres Bertran, Ulyana Piterbarg, Mikhail Plekhanov, Mathieu Rita, Andrey Rusakov, Vladislav Vorotilov, Mengjue Wang, Ian Yu, Amine Benhalloum, Gr\'egoire Mialon, Thomas Scialom  
**Category**: cs.AI  
**Published**: 2026-02-13  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.11964v1  

#### Abstract
We introduce Gaia2, a benchmark for evaluating large language model agents in realistic, asynchronous environments. Unlike prior static or synchronous evaluations, Gaia2 introduces scenarios where environments evolve independently of agent actions, requiring agents to operate under temporal constrai...

---

### 23. [Advancing AI Trustworthiness Through Patient Simulation: Risk Assessment of Conversational Agents for Antidepressant Selection](https://arxiv.org/abs/2602.11391)

**Authors**: Md Tanvir Rouf Shawon, Mohammad Sabik Irbaz, Hadeel R. A. Elyazori, Keerti Reddy Resapu, Yili Lin, Vladimir Franzuela Cardenas, Farrokh Alemi, Kevin Lybarger  
**Category**: cs.CL  
**Published**: 2026-02-13  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.11391v1  

#### Abstract
Objective: This paper introduces a patient simulator designed to enable scalable, automated evaluation of healthcare conversational agents. The simulator generates realistic, controllable patient interactions that systematically vary across medical, linguistic, and behavioral dimensions, allowing an...

---

### 24. [CADET: Context-Conditioned Ads CTR Prediction With a Decoder-Only Transformer](https://arxiv.org/abs/2602.11410)

**Authors**: David Pardoe, Neil Daftary, Miro Furtado, Aditya Aiyer, Yu Wang, Liuqing Li, Tao Song, Lars Hertel, Young Jin Yun, Senthil Radhakrishnan, Zhiwei Wang, Tommy Li, Khai Tran, Ananth Nagarajan, Ali Naqvi, Yue Zhang, Renpeng Fang, Avi Romascanu, Arjun Kulothungun, Deepak Kumar, Praneeth Boda, Fedor Borisyuk, Ruoyan Wang  
**Category**: cs.LG  
**Published**: 2026-02-13  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.11410v1  

#### Abstract
Click-through rate (CTR) prediction is fundamental to online advertising systems. While Deep Learning Recommendation Models (DLRMs) with explicit feature interactions have long dominated this domain, recent advances in generative recommenders have shown promising results in content recommendation. H...

---

### 25. [TimeSynth: A Framework for Uncovering Systematic Biases in Time Series Forecasting](https://arxiv.org/abs/2602.11413)

**Authors**: Md Rakibul Haque, Vishwa Goudar, Shireen Elhabian, Warren Woodrich Pettine  
**Category**: cs.LG  
**Published**: 2026-02-13  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.11413v1  

#### Abstract
Time series forecasting is a fundamental tool with wide ranging applications, yet recent debates question whether complex nonlinear architectures truly outperform simple linear models. Prior claims of dominance of the linear model often stem from benchmarks that lack diverse temporal dynamics and em...

---

### 26. [TUBO: A Tailored ML Framework for Reliable Network Traffic Forecasting](https://arxiv.org/abs/2602.11759)

**Authors**: Zhihang Yuan, Leyang Xue, Waleed Ahsan, Mahesh K. Marina  
**Category**: cs.LG  
**Published**: 2026-02-13  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.11759v1  

#### Abstract
Traffic forecasting based network operation optimization and management offers enormous promise but also presents significant challenges from traffic forecasting perspective. While deep learning models have proven to be relatively more effective than traditional statistical methods for time series f...

---

### 27. [Temperature as a Meta-Policy: Adaptive Temperature in LLM Reinforcement Learning](https://arxiv.org/abs/2602.11779)

**Authors**: Haoran Dang, Cuiling Lan, Hai Wan, Xibin Zhao, Yan Lu  
**Category**: cs.LG  
**Published**: 2026-02-13  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.11779v1  

#### Abstract
Temperature is a crucial hyperparameter in large language models (LLMs), controlling the trade-off between exploration and exploitation during text generation. High temperatures encourage diverse but noisy outputs, while low temperatures produce focused outputs but may cause premature convergence. Y...

---

### 28. [Latent Generative Solvers for Generalizable Long-Term Physics Simulation](https://arxiv.org/abs/2602.11229)

**Authors**: Zituo Chen, Haixu Wu, Sili Deng  
**Category**: cs.AI  
**Published**: 2026-02-13  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.11229v1  

#### Abstract
We study long-horizon surrogate simulation across heterogeneous PDE systems. We introduce Latent Generative Solvers (LGS), a two-stage framework that (i) maps diverse PDE states into a shared latent physics space with a pretrained VAE, and (ii) learns probabilistic latent dynamics with a Transformer...

---

### 29. [Benchmark Health Index: A Systematic Framework for Benchmarking the Benchmarks of LLMs](https://arxiv.org/abs/2602.11674)

**Authors**: Longyuan Zhu, Hairan Hua, Linlin Miao, Bing Zhao  
**Category**: cs.AI  
**Published**: 2026-02-13  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.11674v1  

#### Abstract
Large Language Models (LLMs) are advancing rapidly, yet the benchmarks used to measure this progress are becoming increasingly unreliable. Score inflation and selective reporting have eroded the authority of standard benchmarks, leaving the community uncertain about which evaluation results remain t...

---

### 30. [Text2GQL-Bench: A Text to Graph Query Language Benchmark [Experiment, Analysis & Benchmark]](https://arxiv.org/abs/2602.11745)

**Authors**: Songlin Lyu, Lujie Ban, Zihang Wu, Tianqi Luo, Jirong Liu, Chenhao Ma, Yuyu Luo, Nan Tang, Shipeng Qi, Heng Lin, Yongchao Liu, Chuntao Hong  
**Category**: cs.AI  
**Published**: 2026-02-13  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.11745v1  

#### Abstract
Graph models are fundamental to data analysis in domains rich with complex relationships. Text-to-Graph-Query-Language (Text-to-GQL) systems act as a translator, converting natural language into executable graph queries. This capability allows Large Language Models (LLMs) to directly analyze and man...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- kv cache, offload, State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
