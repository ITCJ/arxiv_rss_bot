# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-01-06 05:59:42 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [OrchestrRL: Dynamic Compute and Network Orchestration for Disaggregated RL](https://arxiv.org/abs/2601.01209)

**Authors**: Xin Tan, Yicheng Feng, Yu Zhou, Yimin Jiang, Yibo Zhu, Hong Xu  
**Category**: cs.DC  
**Published**: 2026-01-06  
**Score**: 13.0  
**Type**: new  
**ArXiv ID**: 2601.01209v1  

#### Abstract
Post-training with reinforcement learning (RL) has greatly enhanced the capabilities of large language models. Disaggregating the generation and training stages in RL into a parallel, asynchronous pipeline offers the potential for flexible scaling and improved throughput. However, it still faces two...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*OrchestrRL: Dynamic Compute and Network Orchestration for Disaggregated RL*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹**è§£è€¦å¼å¼ºåŒ–å­¦ä¹ ï¼ˆdisaggregated RLï¼‰ç³»ç»Ÿä¸­çš„ä¸¤ä¸ªæ ¸å¿ƒç“¶é¢ˆ**ï¼š
1. **ç”Ÿæˆé˜¶æ®µï¼ˆgenerationï¼‰æˆä¸ºç«¯åˆ°ç«¯æ€§èƒ½ç“¶é¢ˆ**ï¼šç”±äºè¾“å‡ºé•¿åº¦åˆ†å¸ƒé•¿å°¾ã€è¯·æ±‚å¤„ç†æ—¶é—´ä¸å‡è¡¡ï¼ˆstragglersï¼‰ã€ä»¥åŠé™æ€å¹¶è¡Œç­–ç•¥æ— æ³•é€‚åº”åŠ¨æ€è´Ÿè½½å˜åŒ–ï¼Œå¯¼è‡´ç”Ÿæˆæ­¥éª¤çš„ *makespan* æ˜¾è‘—å¢åŠ ã€‚
2. **ç½‘ç»œæ¶æ„ä¸é€šä¿¡æ¨¡å¼ä¸åŒ¹é…**ï¼šè®­ç»ƒã€ç”Ÿæˆå’Œæƒé‡åŒæ­¥é˜¶æ®µå…·æœ‰é«˜åº¦å¼‚æ„ä¸”åŠ¨æ€å˜åŒ–çš„é€šä¿¡æ¨¡å¼ï¼ˆå¦‚é›†ä½“é€šä¿¡ã€åŒç«¯é€šä¿¡ã€çªå‘å¹¿æ’­ï¼‰ï¼Œä¼ ç»Ÿé™æ€ç½‘ç»œï¼ˆå¦‚ Fat-Treeï¼‰éš¾ä»¥é«˜æ•ˆæ”¯æŒï¼Œé€ æˆå¸¦å®½æµªè´¹æˆ–æ‹¥å¡ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **OrchestrRL**ï¼Œä¸€ä¸ªé¢å‘è§£è€¦ RL çš„**è®¡ç®—ä¸ç½‘ç»œååŒç¼–æ’æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰è‡ªé€‚åº”è®¡ç®—è°ƒåº¦å™¨ï¼ˆAdaptive Compute Schedulerï¼‰
- **Proactive Plannerï¼ˆä¸»åŠ¨è§„åˆ’å™¨ï¼‰**ï¼š
  - å‘¨æœŸæ€§è¿è¡Œï¼ŒåŸºäºåœ¨çº¿é¢„æµ‹çš„å“åº”é•¿åº¦åˆ†å¸ƒï¼ˆARIMA æ¨¡å‹ï¼‰å’Œå½“å‰å‰©ä½™è¯·æ±‚çŠ¶æ€ï¼Œé€šè¿‡æ±‚è§£ **MILP ä¼˜åŒ–é—®é¢˜**é€‰æ‹©æœ€ä¼˜å¹¶è¡Œç­–ç•¥ï¼ˆå¦‚ TPã€EPã€AFDï¼‰ã€‚
  - åŠ¨æ€åˆ‡æ¢å¹¶è¡Œåº¦ä»¥åº”å¯¹è·¨æ­¥å’Œæ­¥å†…è´Ÿè½½æ¼‚ç§»ï¼Œå¹³è¡¡ååä¸å»¶è¿Ÿã€‚
- **Reactive Balancerï¼ˆååº”å¼è´Ÿè½½å‡è¡¡å™¨ï¼‰**ï¼š
  - å®æ—¶ç›‘æ§å„ worker çš„ `LoadIndex`ï¼ˆç»¼åˆæ’é˜Ÿé•¿åº¦ã€KV-cache å¤´éƒ¨ç©ºé—´ã€æœåŠ¡é€Ÿç‡ï¼‰ï¼Œè¿›è¡Œè½»é‡çº§è¯·æ±‚è¿ç§»ï¼Œç¼“è§£å› è¾“å‡ºé•¿åº¦ä¸å¯é¢„æµ‹å¯¼è‡´çš„ straggler é—®é¢˜ã€‚

#### ï¼ˆ2ï¼‰å¯é‡æ„æ··åˆå…‰-ç”µç½‘ç»œæ¶æ„ RFabric
- **åˆ†å±‚æ··åˆè®¾è®¡**ï¼š
  - **è¾¹ç¼˜å±‚ï¼ˆToRï¼‰**ï¼šä½¿ç”¨ç”µå­åˆ†ç»„äº¤æ¢ï¼ˆEPSï¼‰å¤„ç†ç»†ç²’åº¦ã€ä½å»¶è¿Ÿé€šä¿¡ï¼ˆå¦‚ TP å†…éƒ¨é€šä¿¡ï¼‰ã€‚
  - **èšåˆä¸æ ¸å¿ƒå±‚**ï¼šå¼•å…¥ **OCSï¼ˆOptical Circuit Switchingï¼‰**ï¼Œå®ç°æŒ‰éœ€æ‹“æ‰‘é‡æ„ã€‚
- **åŠ¨æ€æ‹“æ‰‘å®ä¾‹åŒ–ï¼ˆDynamic Topology Materializationï¼‰**ï¼š
  - **è®­ç»ƒé˜¶æ®µ**ï¼šæ„å»ºé«˜äºŒåˆ†å¸¦å®½çš„äº’è”æ‹“æ‰‘ï¼Œæ”¯æŒ DP AllReduce ç­‰å¤§è§„æ¨¡é›†ä½“æ“ä½œã€‚
  - **ç”Ÿæˆé˜¶æ®µ**ï¼šéš”ç¦» PoD å†…éƒ¨é€šä¿¡ï¼Œä¸º TP/EP/AFD æ„å»ºä¸“ç”¨ä½å»¶è¿Ÿè·¯å¾„ã€‚
  - **æƒé‡åŒæ­¥é˜¶æ®µ**ï¼šæ„å»ºå¤šæ’­æ ‘å½¢æ‹“æ‰‘ï¼Œå®ç°è·¨é›†ç¾¤é«˜æ•ˆå‚æ•°å¹¿æ’­ã€‚

#### ï¼ˆ3ï¼‰ç»Ÿä¸€æ§åˆ¶å¹³é¢
- å°†è®¡ç®—è°ƒåº¦å†³ç­–ä¸ç½‘ç»œæ„å›¾ï¼ˆintentï¼‰è”åŠ¨ï¼Œç”± **Network Coordinator** é©±åŠ¨ OCS åœ¨é€šä¿¡ç©ºé—²çª—å£ï¼ˆslackï¼‰ä¸­æå‰é‡é…ç½®ï¼Œé¿å…å½±å“å…³é”®è·¯å¾„ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰æ–¹æ³•å±€é™ | OrchestrRL æ”¹è¿› |
|------|--------------|----------------|
| **å¹¶è¡Œç­–ç•¥** | é™æ€é…ç½®ï¼ˆå¦‚å›ºå®š TP=8ï¼‰ | åŠ¨æ€åˆ‡æ¢ï¼Œé€‚åº”è´Ÿè½½æ¼”åŒ– |
| **è´Ÿè½½å‡è¡¡** | æ— æˆ–ä¾èµ–æ‰¹å¤„ç†ä¼˜åŒ– | å®æ—¶è¿ç§» + è½»é‡å¼€é”€ |
| **ç½‘ç»œæ¶æ„** | å›ºå®šæ‹“æ‰‘ï¼ˆå¦‚ Fat-Treeï¼‰ | å·¥ä½œè´Ÿè½½æ„ŸçŸ¥çš„åŠ¨æ€æ‹“æ‰‘ |
| **é€‚ç”¨åœºæ™¯** | ä¸»è¦é’ˆå¯¹è®­ç»ƒæˆ–åœ¨çº¿æ¨ç† | å…¨æµç¨‹æ”¯æŒ RL ç‰¹æœ‰çš„ä¸‰é˜¶æ®µé€šä¿¡æ¨¡å¼ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†ä¸æ¨¡å‹
- **æ•°æ®é›†**ï¼š
  - `openr1-math-220k`ï¼ˆç”¨äº Qwen-14Bï¼‰
  - `deepmath-103k`ï¼ˆç”¨äº Qwen-32Bï¼‰
- **æ¨¡å‹**ï¼š
  - Qwen-2.5 14B å’Œ 32B
- **RL ç®—æ³•**ï¼šGRPOï¼ˆä¸€ç§ off-policy RLHF ç®—æ³•ï¼‰

### âš™ï¸ å®éªŒè®¾ç½®
- **ç‰©ç†æµ‹è¯•åºŠ**ï¼š48 å° H800 GPU æœåŠ¡å™¨ï¼ˆ32 GPU ç”¨äºè®­ç»ƒï¼Œ40 GPU ç”¨äºç”Ÿæˆï¼‰
- **è½¯ä»¶æ ˆ**ï¼š
  - è®­ç»ƒï¼šMegatron-LM
  - æ¨ç†ï¼švLLMï¼ˆæ”¯æŒ PagedAttentionï¼‰
- **ä»¿çœŸå¹³å°**ï¼šRLSimï¼ˆé«˜ä¿çœŸæ¨¡æ‹Ÿå™¨ï¼Œæ”¯æŒå¤§è§„æ¨¡éƒ¨ç½²è¯„ä¼°ï¼‰

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
- **ç«¯åˆ°ç«¯ååé‡ï¼ˆEnd-to-End Throughputï¼‰**
- **ç”Ÿæˆæ­¥éª¤çš„ makespan**
- **ç½‘ç»œæˆæœ¬æ•ˆç‡ï¼ˆCost-Efficiencyï¼‰**
- **æ¶ˆèå®éªŒ**ï¼šåˆ†åˆ«éªŒè¯ Proactive Planning å’Œ Reactive Balancing çš„è´¡çŒ®

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | æè¿° |
|------|------|
| **veRL-TO** | å¼ºè°ƒæ•°æ®å¹¶è¡Œï¼ˆData Parallelismï¼‰ï¼Œæœ€å¤§åŒ–å¹¶å‘å®ä¾‹æ•° |
| **veRL-LO** | å¼ºè°ƒå¼ é‡å¹¶è¡Œï¼ˆTensor Parallelism, TP=8ï¼‰ï¼Œæœ€å°åŒ–å•ä¸ªè¯·æ±‚å»¶è¿Ÿ |
| **Partial-Rollout (PR)** | å…è®¸å•ä¸ªå“åº”è·¨å¤šä¸ªæ¨¡å‹ç‰ˆæœ¬ç»§ç»­ç”Ÿæˆï¼Œç¼“è§£é•¿å°¾é—®é¢˜ä½†å¼•å…¥æ›´å¤š staleness |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰ç«¯åˆ°ç«¯ååæå‡ï¼ˆç‰©ç†æµ‹è¯•åºŠï¼‰
| æ¨¡å‹ | æœ€å¤§ç”Ÿæˆé•¿åº¦ | OrchestrRL vs veRL-TO |
|------|---------------|------------------------|
| Qwen-14B (32 GPUs) | 15K tokens | **1.31Ã—** |
| Qwen-14B (32 GPUs) | 25K tokens | **1.40Ã—** |
| Qwen-32B (48 GPUs) | 15K tokens | **1.32Ã—** |
| Qwen-32B (48 GPUs) | 25K tokens | **1.34Ã—** |

> âœ… ç»“æœè¡¨æ˜ï¼šéšç€ç”Ÿæˆé•¿åº¦å¢é•¿ï¼ŒOrchestrRL çš„ä¼˜åŠ¿æ›´åŠ æ˜æ˜¾ï¼Œè¯´æ˜å…¶å¯¹é•¿å°¾è¯·æ±‚çš„å¤„ç†æ›´æœ‰æ•ˆã€‚

#### ï¼ˆ2ï¼‰æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰
| é…ç½® | Qwen-14B ååå€æ•° | Qwen-32B ååå€æ•° |
|------|--------------------|--------------------|
| Baseline (veRL-TO) | 1.00Ã— | 1.00Ã— |
| + Proactive Planning (PP) | 1.23Ã— | 1.19Ã— |
| + PP + Reactive Balancing (RB) | **1.40Ã—** | **1.34Ã—** |

> âœ… è¡¨æ˜ä¸¤ç§æœºåˆ¶ååŒä½œç”¨æ˜¾è‘—ï¼Œå…¶ä¸­ **Reactive Balancing å¯¹ç¼“è§£ straggler æ•ˆæœçªå‡º**ã€‚

#### ï¼ˆ3ï¼‰å¤§è§„æ¨¡ç½‘ç»œä»¿çœŸç»“æœï¼ˆRLSimï¼‰
| æŒ‡æ ‡ | RFabric vs Fat-Tree | RFabric vs Rail-Optimized (RO) |
|------|---------------------|-------------------------------|
| æ€§èƒ½ï¼ˆå½’ä¸€åŒ–ååï¼‰ | â‰ˆ 1.0ï¼ˆæ¥è¿‘ç†æƒ³éé˜»å¡ Fat-Treeï¼‰ | â‰ˆ 1.0 |
| æˆæœ¬æ•ˆç‡ | **æé«˜ 2.2Ã—â€“3.1Ã—** | **æé«˜ 2.3Ã—â€“3.2Ã—** |

> âœ… RFabric åœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶å¤§å¹…é™ä½ç½‘ç»œæˆæœ¬ï¼Œå°¤å…¶åœ¨é«˜é“¾è·¯é€Ÿç‡ä¸‹ä¼˜åŠ¿æ›´æ˜æ˜¾ï¼ˆå…‰å­¦æ”¶å‘å™¨æˆæœ¬å æ¯”é«˜ï¼‰ã€‚

#### ï¼ˆ4ï¼‰æ€§èƒ½-æˆæœ¬å¸•ç´¯æ‰˜å‰æ²¿ï¼ˆPareto Frontierï¼‰
- åœ¨ 2048-GPU è§„æ¨¡ä¸‹ï¼ŒRFabric æ˜¾è‘—ä¼˜äºï¼š
  - **Fat-Tree (FT)**ï¼šæ€§èƒ½ç›¸å½“ä½†æˆæœ¬æ›´ä½
  - **Oversubscribed FT (3:1)**ï¼šæˆæœ¬ç•¥ä½ä½†æ€§èƒ½ä¸‹é™ä¸¥é‡
  - **TopoOpt**ï¼šé›†ä¸­å¼ OCS è®¾è®¡æ‰©å±•æ€§å·®ï¼Œæ€§èƒ½æŸå¤±å¤§

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **ç”Ÿæˆé˜¶æ®µæ˜¯è§£è€¦ RL çš„å…³é”®ç“¶é¢ˆ**ï¼Œå…¶æ€§èƒ½å—è¾“å‡ºé•¿åº¦åˆ†å¸ƒæ¼”åŒ–å’Œè´Ÿè½½ä¸å‡ä¸¥é‡å½±å“ï¼Œé™æ€å¹¶è¡Œç­–ç•¥æ— æ³•åº”å¯¹ã€‚
2. **RL çš„é€šä¿¡æ¨¡å¼å…·æœ‰å¼ºæ—¶ç©ºå¼‚è´¨æ€§**ï¼š
   - ç©ºé—´ä¸Šï¼šè®­ç»ƒéœ€å…¨å±€é›†ä½“é€šä¿¡ï¼Œç”Ÿæˆä»¥å±€éƒ¨é€šä¿¡ä¸ºä¸»ï¼›
   - æ—¶é—´ä¸Šï¼šæƒé‡åŒæ­¥å­˜åœ¨å¤§é‡å¯åˆ©ç”¨çš„â€œé‡é…ç½®ç©ºé—²çª—å£â€ï¼ˆreconfiguration slackï¼‰ã€‚
3. **åŠ¨æ€æ‹“æ‰‘é‡æ„æ˜¯è§£å†³ RL ç½‘ç»œæŒ‘æˆ˜çš„æœ‰æ•ˆé€”å¾„**ï¼š
   - OCS åº”ç”¨äºèšåˆ/æ ¸å¿ƒå±‚ï¼ŒEPS ä¿ç•™äºè¾¹ç¼˜å±‚ï¼Œå½¢æˆäº’è¡¥ã€‚
   - â€œæŒ‰éœ€å®ä¾‹åŒ–æ‹“æ‰‘â€æ¯”â€œé™æ€è¶…é…â€æ›´å…·æˆæœ¬æ•ˆç›Šã€‚
4. **è®¡ç®—ä¸ç½‘ç»œå¿…é¡»ååŒä¼˜åŒ–**ï¼š
   - å¹¶è¡Œç­–ç•¥åˆ‡æ¢ä¼šæ”¹å˜é€šä¿¡æ¨¡å¼ï¼Œè¦æ±‚ç½‘ç»œå…·å¤‡å¿«é€Ÿé€‚é…èƒ½åŠ›ã€‚
   - ç»Ÿä¸€æ§åˆ¶å¹³é¢å®ç°äº† compute-network co-designã€‚

### âš ï¸ å±€é™æ€§
- å½“å‰å®ç°æœªæ·±å…¥æ”¯æŒ **AFDï¼ˆAttention-FFN Disaggregationï¼‰** å’Œ **MoEï¼ˆMixture-of-Expertsï¼‰** æ¨¡å‹çš„å®Œæ•´è¯„ä¼°ã€‚
- OCS é‡é…ç½®å»¶è¿Ÿå—é™äºç¡¬ä»¶ï¼ˆå¦‚ 3D MEMS ~10msï¼‰ï¼Œåœ¨æçŸ­è®¡ç®—é—´éš”ä¸­ä»éš¾åº”ç”¨ã€‚
- å®é™…éƒ¨ç½²ä¸­éœ€è€ƒè™‘ OCS ç¡¬ä»¶å¯é æ€§ä¸æ•…éšœæ¢å¤æœºåˆ¶ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•å¯¹ **AFD å’Œ MoE æ¨¡å‹**çš„æ”¯æŒä¸è¯„ä¼°ã€‚
- æ¢ç´¢ä¸å…¶ä»– OCS æ¶æ„ï¼ˆå¦‚ MixNetï¼‰çš„æ¨ªå‘æ¯”è¾ƒã€‚
- å°† OrchestrRL æ€æƒ³åº”ç”¨äº **Agent-based RL** åœºæ™¯ï¼Œæ”¯æŒå¤šè½®äº¤äº’å¼ä»»åŠ¡è°ƒåº¦ã€‚
- è¿›ä¸€æ­¥ä¼˜åŒ– OCS æ§åˆ¶å¹³é¢çš„å®æ—¶æ€§ä¸å®¹é”™èƒ½åŠ›ã€‚

---

## æ€»ç»“
**OrchestrRL æ˜¯é¦–ä¸ªä»â€œèŠ‚å¥ç¼–æ’â€ï¼ˆrhythm orchestrationï¼‰è§†è§’ç³»ç»Ÿè§£å†³è§£è€¦ RL ä¸­è®¡ç®—ä¸ç½‘ç»œååŒé—®é¢˜çš„å·¥ä½œ**ã€‚å®ƒé€šè¿‡ï¼š
- åŠ¨æ€å¹¶è¡Œåˆ‡æ¢ + è¯·æ±‚è¿ç§» â†’ æå‡ç”Ÿæˆæ•ˆç‡ï¼›
- åˆ†å±‚æ··åˆå…‰-ç”µç½‘ç»œ + æŒ‰éœ€æ‹“æ‰‘é‡æ„ â†’ åŒ¹é…å¤æ‚é€šä¿¡éœ€æ±‚ï¼›
- ç»Ÿä¸€æ§åˆ¶å¹³é¢ â†’ å®ç°è·¨å±‚ååŒã€‚

åœ¨çœŸå®æµ‹è¯•åºŠå’Œå¤§è§„æ¨¡ä»¿çœŸä¸­å‡å±•ç°å‡ºæ˜¾è‘—çš„ååæå‡ï¼ˆæœ€é«˜ **1.40Ã—**ï¼‰å’Œå“è¶Šçš„æˆæœ¬æ•ˆç‡ï¼ˆ**2.2Ã—â€“3.1Ã—** ä¼˜äºä¼ ç»Ÿæ–¹æ¡ˆï¼‰ï¼Œä¸ºå¤§è§„æ¨¡ RL ç³»ç»Ÿçš„è®¾è®¡æä¾›äº†æ–°çš„èŒƒå¼ã€‚

</details>

---

### 2. [DiT-HC: Enabling Efficient Training of Visual Generation Model DiT on HPC-oriented CPU Cluster](https://arxiv.org/abs/2601.01500)

**Authors**: Jinxiao Zhang, Yunpu Xu, Xiyong Wu, Runmin Dong, Shenggan Cheng, Yi Zhao, Mengxuan Chen, Qinrui Zheng, Jianting Liu, Haohuan Fu  
**Category**: cs.DC  
**Published**: 2026-01-06  
**Score**: 13.0  
**Type**: new  
**ArXiv ID**: 2601.01500v1  

#### Abstract
Generative foundation models have become an important tool for data reconstruction and simulation in scientific computing, showing a tight integration with traditional numerical simulations. At the same time, with the development of new hardware features, such as matrix acceleration units and high-b...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDiT-HC: Enabling Efficient Training of Visual Generation Model DiT on HPC-oriented CPU Cluster

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰ç”Ÿæˆå¼åŸºç¡€æ¨¡å‹ï¼ˆå¦‚ Diffusion Models å’Œ Transformerï¼‰ä¸»è¦ä¾èµ– GPU/TPU è¿›è¡Œé«˜æ•ˆè®­ç»ƒï¼Œè€Œä¼ ç»Ÿçš„ **HPC-oriented CPU é›†ç¾¤**è™½ç„¶åœ¨ç§‘å­¦è®¡ç®—ä¸­å¹¿æ³›åº”ç”¨ï¼Œä½†ç”±äºå…¶é€šç”¨æ¶æ„ã€è¾ƒä½çš„è®¡ç®—å¯†åº¦å’Œå†…å­˜å¸¦å®½é™åˆ¶ï¼Œåœ¨æ·±åº¦å­¦ä¹ è®­ç»ƒæ–¹é¢æ”¯æŒæœ‰é™ã€‚è¿™å¯¼è‡´ AI ä¸ä¼ ç»Ÿæ•°å€¼æ¨¡æ‹Ÿéš¾ä»¥ç»Ÿä¸€éƒ¨ç½²åœ¨åŒä¸€å¹³å°ä¸Šã€‚

æ­¤å¤–ï¼Œæ–°ä¸€ä»£ HPC CPU å·²å¼•å…¥ AI åŠ é€Ÿç‰¹æ€§ï¼ˆå¦‚ Matrix Acceleration Units, MAUs å’Œ On-Package Memory, OPMï¼‰ï¼Œä½†ç¼ºä¹ç³»ç»Ÿæ€§çš„è½¯ä»¶æ ˆä¼˜åŒ–æ¥å……åˆ†åˆ©ç”¨è¿™äº›ç¡¬ä»¶ä¼˜åŠ¿ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº† **DiT-HC** â€”â€”é¦–ä¸ªåœ¨é¢å‘é«˜æ€§èƒ½è®¡ç®—ï¼ˆHPCï¼‰çš„ä¸‹ä¸€ä»£ CPU é›†ç¾¤ä¸Šå®ç°å¯æ‰©å±•è®­ç»ƒ **Diffusion Transformer (DiT)** çš„é«˜æ•ˆæ¡†æ¶ã€‚å…¶ä¸‰å¤§æ ¸å¿ƒæŠ€æœ¯ä¸ºï¼š

#### ï¼ˆ1ï¼‰é€šä¿¡è‡ªç”±å¼ é‡å¹¶è¡Œï¼ˆCFTPï¼‰
- åˆ©ç”¨ CPU èŠ¯ç‰‡å†…å…±äº« DDR å†…å­˜çš„ç‰¹ç‚¹ï¼Œåœ¨å•ä¸ª Die å†…é€šè¿‡ **å…±äº«å†…å­˜æ“ä½œæ›¿ä»£ MPI é€šä¿¡** å®ç° Tensor Parallelismï¼ˆTPï¼‰ã€‚
- æ¶ˆé™¤ä¼ ç»Ÿ TP ä¸­è·¨è¿›ç¨‹é€šä¿¡å¼€é”€ï¼Œå‡å°‘å†…å­˜å†—ä½™ï¼Œå¹¶å°†æ¯ä¸ªèŠ‚ç‚¹çš„ MPI è¿›ç¨‹æ•°ä» 16 é™è‡³ 4ã€‚
- ç»“åˆ Data Parallelismï¼ˆDPï¼‰ï¼Œå½¢æˆ **CFTP+DP æ··åˆå¹¶è¡Œç­–ç•¥**ï¼Œæ˜¾è‘—é™ä½é€šä¿¡ç“¶é¢ˆã€‚

#### ï¼ˆ2ï¼‰è‡ªåŠ¨å†…å­˜æ„ŸçŸ¥æ•°æ®æµç®¡ç†æ¨¡å— AutoMem
- é’ˆå¯¹ OPM-DDR åˆ†å±‚å†…å­˜ä½“ç³»è®¾è®¡éä¾µå…¥å¼è‡ªåŠ¨åŒ–å†…å­˜è°ƒåº¦æœºåˆ¶ã€‚
- åœ¨å‰å‘/åå‘ä¼ æ’­è¿‡ç¨‹ä¸­åŠ¨æ€é¢„å–æƒé‡ã€æ¿€æ´»å€¼è‡³é«˜å¸¦å®½ OPMï¼Œå¹¶åœ¨è®¡ç®—åå¸è½½å› DDRã€‚
- ä½¿ç”¨ SDMA å¼‚æ­¥ä¼ è¾“ï¼Œç”±ä¸“ç”¨ CPU core æ‰§è¡ŒåŠ è½½/å¸è½½ä»»åŠ¡ï¼Œå®ç°è®¡ç®—ã€é€šä¿¡ã€å†…å­˜ç§»åŠ¨çš„é‡å ã€‚

#### ï¼ˆ3ï¼‰é¢å‘ HPC CPU çš„ç®—å­çº§ä¼˜åŒ–åº“ HCOps
- æ„å»ºåŸºäº PyTorch çš„æ‰©å±•æ•°å­¦åº“ HCOpsï¼Œé’ˆå¯¹ MAU å’Œ VAU å•å…ƒè¿›è¡Œåº•å±‚ä¼˜åŒ–ã€‚
- æ”¹è¿› GEMM çš„åˆ†å—ç­–ç•¥ï¼ˆtilingï¼‰ï¼Œæå‡ L2 ç¼“å­˜å‘½ä¸­ç‡ï¼Œé¿å…è·¨ NUMA è®¿é—®ã€‚
- å¯¹ GeLUã€SiLUã€LayerNormã€FlashAttention ç­‰å¸¸ç”¨ AI ç®—å­è¿›è¡Œèåˆä¸æŒ‡ä»¤çº§ä¼˜åŒ–ã€‚

#### ï¼ˆ4ï¼‰è‡ªå®šä¹‰å¼‚æ­¥ MPI é€šä¿¡åç«¯
- å®ç°æ”¯æŒ `MPI_Iallreduce` çš„å¼‚æ­¥é›†åˆé€šä¿¡æ¥å£ã€‚
- å°†é€šä¿¡ä»»åŠ¡ç»‘å®šåˆ°ç‹¬ç«‹ CPU coreï¼Œé¿å…ä¸è®¡ç®—çº¿ç¨‹äº‰æŠ¢èµ„æºï¼Œæå‡é€šä¿¡ä¸è®¡ç®—çš„å¹¶å‘æ•ˆç‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰æ–¹æ³•å±€é™ | DiT-HC æ”¹è¿› |
|------|--------------|------------|
| å¹¶è¡Œç­–ç•¥ | å…¸å‹ TP/PP+DP å­˜åœ¨å¤§é‡è·¨è¿›ç¨‹é€šä¿¡å’Œå†…å­˜å¤åˆ¶ | CFTP æ¶ˆé™¤ç‰‡å†…é€šä¿¡ï¼Œå‡å°‘å†…å­˜å ç”¨å’Œè¿›ç¨‹æ•°é‡ |
| å†…å­˜ç®¡ç† | æ‰‹åŠ¨ç®¡ç†å¤æ‚ï¼Œéš¾ä»¥é€‚é…åˆ†å±‚å†…å­˜ | AutoMem è‡ªåŠ¨åŒ–è°ƒåº¦ï¼Œæœ€å¤§åŒ–åˆ©ç”¨ OPM é«˜å¸¦å®½ |
| ç®—å­æ€§èƒ½ | é€šç”¨ BLAS åº“æœªé’ˆå¯¹ MAU/NUMA ä¼˜åŒ– | HCOps å®ç°é«˜è¾¾ 35.49Ã— çš„ GEMM åŠ é€Ÿ |
| å¯æ‰©å±•æ€§ | é€šä¿¡æˆä¸ºç“¶é¢ˆï¼Œå¼±æ‰©å±•æ•ˆç‡ä½ | 256 èŠ‚ç‚¹ä¸‹è¾¾åˆ° 90.6% å¼±æ‰©å±•æ•ˆç‡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
å®éªŒé‡‡ç”¨ä¸‰ä¸ªä»£è¡¨æ€§æ•°æ®é›†ï¼š
- **ImageNet**ï¼šé€šç”¨å›¾åƒç”ŸæˆåŸºå‡†ï¼›
- **Gaofen-2**ï¼šå›½äº§é«˜åˆ†äºŒå·å«æ˜Ÿé¥æ„Ÿæ•°æ®ï¼Œ4 æ³¢æ®µï¼Œç©ºé—´åˆ†è¾¨ç‡ä¸º 2m/pixelï¼›
- **Sentinel-2**ï¼šæ¬§æ´²å“¨å…µäºŒå·å¤šå…‰è°±å½±åƒï¼Œ13 æ³¢æ®µï¼Œåˆ†è¾¨ç‡ 10m/pixelï¼›

ç”¨äºéªŒè¯æ¨¡å‹åœ¨ç§‘å­¦é¢†åŸŸçš„è¿ç§»èƒ½åŠ›ã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼šLS Pilot ç³»ç»Ÿï¼Œå…± 256 ä¸ªèŠ‚ç‚¹ï¼Œæ¯èŠ‚ç‚¹é…å¤‡ä¸¤é¢— LX2 CPUï¼ˆ>256 æ ¸ï¼‰ï¼Œé›†æˆ MAUã€VAUã€OPMï¼ˆOn-Package Memoryï¼‰ã€DDR å’Œ SDMAï¼›
- **è½¯ä»¶ç¯å¢ƒ**ï¼šOpenEuler 22.03 + Clang 17.0 + OpenMPI + PyTorch 2.5.1ï¼›
- **åŸºçº¿é…ç½®**ï¼š
  - æ•°å­¦åº“ï¼šnativeBLASï¼ˆå‚å•†ä¼˜åŒ– BLASï¼‰+ oneDNN 3.6.2ï¼›
  - é€šä¿¡åç«¯ï¼šPyTorch é»˜è®¤ MPIï¼›
  - å¹¶è¡Œç­–ç•¥ï¼šDPã€TP/PP+DPï¼›
- **æ¨¡å‹è§„æ¨¡**ï¼šæµ‹è¯• DiT-S/2ã€DiT-B/2ã€DiT-L/2ã€DiT-XL/2 å››ç§å°ºå¯¸ï¼›
- **æ‰¹é‡å¤§å°**ï¼šå…¨å±€ batch size æœ€å¤§è¾¾ 28,672ï¼ˆå¼±æ‰©å±•ï¼‰ï¼›å›ºå®š batch size ç”¨äºå¼ºæ‰©å±•åˆ†æï¼›
- **è®­ç»ƒè®¾ç½®**ï¼šAdamW ä¼˜åŒ–å™¨ï¼Œåˆå§‹å­¦ä¹ ç‡ 1e-4ï¼Œè®­ç»ƒ 1,000 æ­¥ç”¨äºè¯„ä¼°æ”¶æ•›æ€§å’Œæ€§èƒ½ã€‚

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **End-to-end Iteration Time** | å•æ­¥è®­ç»ƒè€—æ—¶ï¼ˆç§’ï¼‰ |
| **Peak Memory Usage** | æ˜¾å­˜å³°å€¼æ¶ˆè€—ï¼ˆGBï¼‰ |
| **FLOPS** | å®é™…æŒç»­æµ®ç‚¹æ€§èƒ½ï¼ˆTFLOPS æˆ– PFLOPSï¼‰ |
| **Weak Scaling Efficiency** | èŠ‚ç‚¹å¢åŠ æ—¶ä¿æŒ per-node batch size ä¸å˜ä¸‹çš„æ•ˆç‡ |
| **Strong Scaling Efficiency** | å›ºå®šæ€» batch size ä¸‹éšèŠ‚ç‚¹å¢åŠ çš„åŠ é€Ÿæ¯” |
| **FrÃ©chet Inception Distance (FID)** | å›¾åƒç”Ÿæˆè´¨é‡è¯„ä»·ï¼Œè¶Šä½è¶Šå¥½ |
| **Loss Curve Consistency** | ä¸ GPU ç»“æœå¯¹æ¯”éªŒè¯æ­£ç¡®æ€§ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| **å•èŠ‚ç‚¹æ€§èƒ½æå‡** | ç›¸æ¯” nativeBLAS è¾¾åˆ° **8.2Ã—** ç«¯åˆ°ç«¯åŠ é€Ÿ |
| **ç›¸æ¯” OpenBLAS æå‡** | æœ€é«˜ **87.7Ã—** åŠ é€Ÿï¼ˆDiT-S/2ï¼‰ |
| **å¼±æ‰©å±•æ•ˆç‡ï¼ˆ256 èŠ‚ç‚¹ï¼‰** | **90.6%**ï¼ˆDiT-XL/2ï¼‰ |
| **æœ€å¤§æŒç»­ç®—åŠ›** | è¶…è¿‡ **1 PFLOPS (FP32)** |
| **é€šä¿¡å¼€é”€å æ¯”ä¸‹é™** | æœ‰æ•ˆéšè—é€šä¿¡å»¶è¿Ÿï¼Œå®ç°é«˜åº¦é‡å  |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœï¼ˆè§ Table 2 & Table 3ï¼‰

#### è¡¨ï¼šä¸åŒå¹¶è¡Œç­–ç•¥ä¸‹çš„è¿­ä»£æ—¶é—´å’Œå†…å­˜ä½¿ç”¨ï¼ˆbatch size = 112ï¼‰

| Model Size | DP+TP (Time/Memory) | DP (Time/Memory) | **CFTP (Time/Memory)** |
|------------|---------------------|------------------|------------------------|
| DiT-S/2    | 3.91s / 224GB       | 2.11s / 182GB    | **2.48s / 167GB**      |
| DiT-B/2    | 8.70s / 309GB       | 6.55s / 247GB    | **3.97s / 198GB**      |
| DiT-L/2    | â€”                   | 23.31s / 474GB   | **9.92s / 304GB**      |
| DiT-XL/2   | â€”                   | â€”                | **13.18s / 358GB**     |

> æ³¨ï¼šâ€œâ€”â€è¡¨ç¤º OOMï¼ˆOut of Memoryï¼‰

âœ… **CFTP åœ¨æ‰€æœ‰æ¨¡å‹ä¸Šå‡å–å¾—æœ€ä½å†…å­˜å ç”¨ï¼Œä¸”åœ¨å¤§æ¨¡å‹ä¸Šæ˜¾è‘—ä¼˜äº DP å’Œ TP/DP**

#### GEMM ç®—å­çº§åŠ é€Ÿæ•ˆæœï¼ˆTable 4ï¼‰
| ç®—å­åç§° | è¾“å…¥ç»´åº¦ | ç›¸å¯¹äº nativeBLAS çš„åŠ é€Ÿæ¯” |
|---------|----------|----------------------------|
| qkv_proj | 1152Ã—3456 | 30.10Ã— |
| o_proj   | 1152Ã—1152 | 13.89Ã— |
| up_proj  | 1152Ã—4608 | 16.49Ã— |
| down_proj| 4608Ã—1152 | **35.49Ã—** |
| condition_proj | 1152Ã—6912 | 1.73Ã— |

> âœ… æ˜¾ç¤º HCOps åœ¨å…³é”®çº¿æ€§å±‚ä¸Šçš„å·¨å¤§æ½œåŠ›ï¼Œå°¤å…¶é€‚ç”¨äºå¤§è¾“å‡ºç»´åº¦åœºæ™¯ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆFigure 9ï¼‰
é€æ­¥æ·»åŠ ä¼˜åŒ–ç»„ä»¶åçš„æ€§èƒ½å¢ç›Šï¼ˆä»¥ speedup ratio è¡¡é‡ï¼‰ï¼š
1. **Baseline (CFTP)** â†’ 1.0Ã—  
2. + **GEMM ä¼˜åŒ–** â†’ 5.5Ã—  
3. + **å¼‚æ­¥é€šä¿¡åç«¯** â†’ 6.3Ã—  
4. + **AI ç®—å­ä¼˜åŒ–** â†’ 6.6Ã—  
5. + **AutoMem æ•°æ®é¢„å–** â†’ 6.7Ã—  
6. + **å¤šæ ¸ä¸å†…å­˜å±‚æ¬¡è°ƒä¼˜ï¼ˆTunedï¼‰** â†’ **8.2Ã—**

> âœ… è¡¨æ˜å„é¡¹ä¼˜åŒ–å…·æœ‰ç´¯åŠ æ•ˆåº”ï¼Œå…¶ä¸­ GEMM ä¼˜åŒ–è´¡çŒ®æœ€å¤§ã€‚

### ä¸å…¶ä»–å¹³å°å¯¹æ¯”ï¼ˆ5.6èŠ‚ï¼‰
- åœ¨ç›¸ä¼¼ç³»ç»Ÿçº§ç®—åŠ›æ¡ä»¶ä¸‹ï¼Œä¸åŒæœº 16 å¡ H100ï¼ˆTF32ï¼‰å¯¹æ¯”ï¼š
  - CPU ç³»ç»Ÿï¼š**13.5 ç§’/step**
  - GPU ç³»ç»Ÿï¼š**7.6 ç§’/step**
- å°½ç®¡ç»å¯¹ååè½åäº GPUï¼Œä½†åœ¨çº¯ CPU æ¶æ„ä¸Šå®ç°äº†æ¥è¿‘å®ç”¨çº§åˆ«çš„è®­ç»ƒé€Ÿåº¦ï¼Œè¯æ˜äº†å¯è¡Œæ€§ã€‚

### ç”Ÿæˆè´¨é‡éªŒè¯ï¼ˆTable 1ï¼‰
| Dataset | GPU (bs=112) | LX2 (bs=112) | LX2 (bs=28,672) |
|--------|---------------|---------------|------------------|
| Gaofen-2 | 30.44 (FID) | 28.51 | **24.70** |
| Sentinel-2 | 24.97 | 29.03 | **22.61** |

> âœ… å¤§æ‰¹é‡è®­ç»ƒä¸‹ FID æ›´ä¼˜ï¼Œè¯´æ˜æ¨¡å‹èƒ½æœ‰æ•ˆåˆ©ç”¨å¤§è§„æ¨¡å¹¶è¡Œè®­ç»ƒç»§ç»­å­¦ä¹ ï¼Œä¸”ç”Ÿæˆè´¨é‡ç¨³å®šç”šè‡³æå‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **HPC CPU å®Œå…¨å…·å¤‡è®­ç»ƒå¤§å‹ç”Ÿæˆæ¨¡å‹çš„èƒ½åŠ›**ï¼šé€šè¿‡è½¯ç¡¬ä»¶ååŒä¼˜åŒ–ï¼Œå¯åœ¨ CPU é›†ç¾¤ä¸Šé«˜æ•ˆè®­ç»ƒ DiT ç±»å…ˆè¿›è§†è§‰ç”Ÿæˆæ¨¡å‹ã€‚
2. **CFTP æ˜¯è§£å†³ CPU ç‰‡å†…é€šä¿¡ç“¶é¢ˆçš„æœ‰æ•ˆèŒƒå¼**ï¼šåˆ©ç”¨å…±äº«å†…å­˜æ›¿ä»£ MPIï¼Œå¤§å¹…é™ä½é€šä¿¡å¼€é”€å’Œå†…å­˜å†—ä½™ã€‚
3. **åˆ†å±‚å†…å­˜ï¼ˆOPM-DDRï¼‰éœ€è‡ªåŠ¨åŒ–ç®¡ç†**ï¼šæ‰‹åŠ¨è°ƒåº¦ææ˜“å‡ºé”™ä¸”ä¸å¯å¤ç”¨ï¼ŒAutoMem æä¾›äº†ä¸€ç§é€šç”¨è§£å†³æ–¹æ¡ˆã€‚
4. **MAU å’Œ NUMA æ„ŸçŸ¥çš„ç®—å­ä¼˜åŒ–è‡³å…³é‡è¦**ï¼šæ ‡å‡† BLAS åº“æ— æ³•å‘æŒ¥æ–°ç¡¬ä»¶æ½œåŠ›ï¼Œå¿…é¡»é‡æ–°è®¾è®¡ GEMM åˆ†å—ä¸ç¼“å­˜ç­–ç•¥ã€‚
5. **é€šä¿¡ä¸è®¡ç®—åˆ†ç¦»æ˜¯é«˜æ‰©å±•æ€§çš„å…³é”®**ï¼šä¸“ç”¨ core å¤„ç†é€šä¿¡ä»»åŠ¡å¯é¿å…ä¸Šä¸‹æ–‡åˆ‡æ¢ï¼Œæå‡æ•´ä½“åˆ©ç”¨ç‡ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–ç‰¹å®šç¡¬ä»¶ç‰¹æ€§**ï¼šå¦‚ OPMã€SDMAã€MAU ç­‰ï¼Œç›®å‰ä»…é€‚ç”¨äº LX2 æˆ–ç±»ä¼¼æ¶æ„çš„ HPC CPUï¼›
- **å°šæœªæ”¯æŒ Pipeline Parallelism**ï¼šå½“å‰ä»…å®ç° CFTP+DPï¼Œæ›´å¤§æ¨¡å‹å¯èƒ½ä»å—é™äºå• Die å†…å­˜å®¹é‡ï¼›
- **åˆå§‹åŒ–é˜¶æ®µéœ€è¦ warm-up**ï¼šAutoMem éœ€ä¸€æ¬¡å‰å‘è¿è¡Œä»¥æ„å»ºä¾èµ–å›¾ï¼Œå¸¦æ¥è½»å¾®å¯åŠ¨å»¶è¿Ÿï¼›
- **å¯¹å°æ¨¡å‹æ”¶ç›Šè¾ƒå°**ï¼šå°æ¨¡å‹æœ¬èº«é€šä¿¡å æ¯”ä½ï¼Œä¼˜åŒ–è¾¹é™…æ•ˆç›Šä¸å¦‚å¤§æ¨¡å‹æ˜æ˜¾ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. æ‰©å±•è‡³æ›´å¤šç”Ÿæˆæ¨¡å‹ç±»åˆ«ï¼ˆå¦‚ Stable Diffusionã€Video Diffusionã€LLMsï¼‰ï¼›
2. æ¢ç´¢æ›´å¤æ‚çš„æ··åˆå¹¶è¡Œç­–ç•¥ï¼ˆå¦‚ CFTP + PPï¼‰ä»¥æ”¯æŒè¶…å¤§è§„æ¨¡æ¨¡å‹ï¼›
3. æ·±åº¦é›†æˆé¢†åŸŸç§‘å­¦åº”ç”¨ï¼ˆå¦‚æ°”å€™å»ºæ¨¡ã€åœ°çƒç³»ç»Ÿæ•°æ®åŒåŒ–ï¼‰ï¼›
4. å¼€æº HCOps å’Œ AutoMem æ¨¡å—ï¼Œæ¨åŠ¨ CPU ä¸Š AI-HPC èåˆç”Ÿæ€å‘å±•ï¼›
5. æ¢ç´¢ç¼–è¯‘å™¨è‡ªåŠ¨ä¼˜åŒ–è·¯å¾„ï¼Œè¿›ä¸€æ­¥é™ä½ç”¨æˆ·å¼€å‘é—¨æ§›ã€‚

---

> âœ… **æ€»ä½“è¯„ä»·**ï¼šè¯¥è®ºæ–‡æˆåŠŸå±•ç¤ºäº†åœ¨ä¼ ç»Ÿä»¥æ•°å€¼æ¨¡æ‹Ÿä¸ºä¸»çš„ HPC CPU é›†ç¾¤ä¸Šè®­ç»ƒç°ä»£ç”Ÿæˆå¼ AI æ¨¡å‹çš„æŠ€æœ¯è·¯å¾„ï¼Œå¡«è¡¥äº† AI ä¸ HPC ç»Ÿä¸€å·¥ä½œæµçš„å…³é”®ç©ºç™½ï¼Œå…·æœ‰é‡è¦çš„å·¥ç¨‹ä»·å€¼å’Œç§‘ç ”æ„ä¹‰ã€‚

</details>

---

### 3. [Jenius Agent: Towards Experience-Driven Accuracy Optimization in Real-World Scenarios](https://arxiv.org/abs/2601.01857)

**Authors**: Defei Xia, Bingfeng Pi, Shenbin Zhang, Song Hua, Yunfei Wei, Lei Zuo  
**Category**: cs.AI  
**Published**: 2026-01-06  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2601.01857v1  

#### Abstract
As agent systems powered by large language models (LLMs) advance, improving the task performance of an autonomous agent, especially in context understanding, tool usage, and response generation, has become increasingly critical. Although prior studies have advanced the overall design of LLM-based ag...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å½“å‰åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è‡ªä¸»æ™ºèƒ½ä½“ç³»ç»Ÿåœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **å›ºå®šæç¤ºï¼ˆPromptï¼‰å¯¼è‡´æ„å›¾ç†è§£åå·®**ï¼šé™æ€æˆ–é€šç”¨çš„æç¤ºæ¨¡æ¿éš¾ä»¥é€‚åº”åŠ¨æ€ä»»åŠ¡çŠ¶æ€ï¼Œæ˜“é€ æˆè¡Œä¸ºä¸ç¨³å®šå’Œè¾“å‡ºä¸ä¸€è‡´ã€‚
- **å·¥å…·è°ƒç”¨ç¼ºä¹ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›**ï¼šä¾èµ–é¢„å®šä¹‰å·¥å…·åˆ—è¡¨æˆ–æ‰‹å·¥è§„åˆ™ï¼Œæ— æ³•åœ¨æ¨¡ç³Šæˆ–å¤šé¢†åŸŸåœºæ™¯ä¸‹å‡†ç¡®é€‰æ‹©åˆé€‚å·¥å…·ï¼Œå¯¼è‡´æ— æ•ˆæˆ–é”™è¯¯è°ƒç”¨ã€‚
- **é•¿å¯¹è¯ä¸­çš„ä¸Šä¸‹æ–‡å†—ä½™é—®é¢˜**ï¼šéšç€äº¤äº’è½®æ¬¡å¢åŠ ï¼Œå†å²è®°å½•è†¨èƒ€ï¼Œå¢åŠ äº†Tokenæ¶ˆè€—å¹¶ç¨€é‡Šå…³é”®ä¿¡æ¯ï¼Œå½±å“æ¨ç†è´¨é‡ã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº†æ™ºèƒ½ä½“åœ¨å¤æ‚ã€å¤šæ­¥ã€çœŸå®ä¸–ç•Œä»»åŠ¡ä¸­çš„å‡†ç¡®æ€§ã€æ•ˆç‡å’Œé²æ£’æ€§ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯**
æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåä¸º **Jenius-Agent** çš„ç«¯åˆ°ç«¯æ™ºèƒ½ä½“æ¡†æ¶ï¼Œå›´ç»•â€œç»éªŒé©±åŠ¨â€çš„ä¼˜åŒ–ç†å¿µï¼Œé›†æˆä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ï¼š

#### **(1) è‡ªé€‚åº”æç¤ºç”Ÿæˆï¼ˆAdaptive Prompt Generationï¼‰**
- åŠ¨æ€èåˆè§’è‰²æŒ‡ä»¤ã€ä»»åŠ¡çŠ¶æ€å’Œç”¨æˆ·ä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆä¸å½“å‰æ‰§è¡Œé˜¶æ®µåŒ¹é…çš„ç³»ç»Ÿæç¤ºã€‚
- å¼•å…¥å››ç±»æ„å›¾åˆ†ç±»ï¼ˆç¤¾äº¤äº’åŠ¨ã€åˆ›æ„ç”Ÿæˆã€äº‹å®å›å¿†ã€å·¥å…·å¢å¼ºæ¨ç†ï¼‰ï¼Œå®ç°ç²¾ç»†åŒ–å“åº”ç­–ç•¥å®šåˆ¶ã€‚
- åŒ…å«å®‰å…¨æ§åˆ¶æœºåˆ¶ï¼ˆå¦‚é˜²æ­¢å¹»è§‰ã€å‚æ•°éªŒè¯ã€è¾“å‡ºæ ¼å¼è§„èŒƒï¼‰ï¼Œæå‡ç³»ç»Ÿå¯é æ€§ã€‚

> âœ… **ä¼˜åŠ¿**ï¼šç›¸æ¯”ä¼ ç»Ÿé™æ€Promptï¼Œèƒ½æ›´ç²¾å‡†å¯¹é½ç”¨æˆ·æ„å›¾ï¼Œå‡å°‘è¯¯åˆ¤å’Œå†—ä½™è°ƒç”¨ã€‚

#### **(2) ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å·¥å…·ç¼–æ’ï¼ˆContext-Aware Tool Orchestrationï¼‰**
- æ„å»ºåŸºäº **Model Context Protocol (MCP)** çš„æ ‡å‡†åŒ–å·¥å…·ç®¡ç†æœºåˆ¶ã€‚
- æ‰€æœ‰å·¥å…·é€šè¿‡ **Qwen3 Embedding** å‘é‡åŒ–è¡¨ç¤ºï¼Œé‡‡ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦æ’åºè¿›è¡Œå€™é€‰æ£€ç´¢ã€‚
- æå‡ºä¸¤é˜¶æ®µè¿‡æ»¤æœºåˆ¶ï¼š
  - **Top-Må€™é€‰æ£€ç´¢**ï¼šæŒ‰æŸ¥è¯¢ä¸å·¥å…·åµŒå…¥çš„ç›¸ä¼¼åº¦åˆç­›ã€‚
  - **æ‹ç‚¹æ£€æµ‹è¿‡æ»¤ï¼ˆInflection Point-based Filteringï¼‰**ï¼šç»“åˆâ€œç›¸ä¼¼åº¦è·³è·ƒâ€å’Œ **Kneedleç®—æ³•** è‡ªåŠ¨ç¡®å®šç›¸å…³å·¥å…·é˜ˆå€¼ã€‚
- æœ€ç»ˆä¿ç•™ $ N = \min(N_{\text{jump}}, N_{\text{kneedle}}) $ ä¸ªå·¥å…·ï¼Œè‹¥ä¸è¶³åˆ™è¡¥è‡³Top-10ã€‚

> âœ… **ä¼˜åŠ¿**ï¼šæ˜¾è‘—é™ä½æ— å…³å·¥å…·è°ƒç”¨ç‡ï¼Œåœ¨é«˜å™ªå£°ç¯å¢ƒä¸‹ä»ä¿æŒé«˜æ•ˆå‡†ç¡®çš„å·¥å…·å‘ç°èƒ½åŠ›ã€‚

#### **(3) åˆ†å±‚è®°å¿†ç®¡ç†ï¼ˆHierarchical Memory Managementï¼‰**
- **å¯¹è¯çº§å¯¹é½**ï¼šç»´æŠ¤ `Human â†’ AI â†’ Tool â†’ AI` çš„æ ‡å‡†äº¤äº’åºåˆ—ï¼Œè‡ªåŠ¨ä¿®å¤å› å¤±è´¥æˆ–ä¸­æ–­å¯¼è‡´çš„æ¶ˆæ¯ç¼ºå¤±ã€‚
- **ä¼šè¯çº§å‹ç¼©**ï¼š
  - å½“æ¶ˆæ¯æ•°è¶…è¿‡é˜ˆå€¼ $ K $ æ—¶ï¼Œå°†æ—©æœŸå†å²ï¼ˆä»é¦–æ¡ `HumanMessage` åˆ°å€’æ•°ç¬¬äºŒæ¡ä¹‹å‰ï¼‰é€’å½’æ‘˜è¦ä¸º `SystemMessage`ã€‚
  - ä¿ç•™æœ€è¿‘ä¸€è½®å®Œæ•´ä¸Šä¸‹æ–‡ç”¨äºå®æ—¶æ¨ç†ã€‚
- æ‘˜è¦åµŒå…¥è¾“å…¥æµå‰ç«¯ï¼Œç¡®ä¿æ³¨æ„åŠ›æœºåˆ¶ä¼˜å…ˆå…³æ³¨é•¿æœŸä¸Šä¸‹æ–‡ã€‚

> âœ… **ä¼˜åŠ¿**ï¼šæœ‰æ•ˆæ§åˆ¶Tokenå¢é•¿ï¼Œé¿å…å…³é”®ä¿¡æ¯ä¸¢å¤±ï¼Œæ”¯æŒé•¿å‘¨æœŸä»»åŠ¡ç¨³å®šè¿è¡Œã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚AutoGPTã€LangChain Agentsï¼‰ | Jenius-Agent |
|------|----------------------------------------|-------------|
| **Promptè®¾è®¡** | å›ºå®šæ¨¡æ¿ï¼Œç¼ºä¹åŠ¨æ€è°ƒæ•´ | åŠ¨æ€é€‚é…ä»»åŠ¡çŠ¶æ€ä¸æ„å›¾ |
| **Tool Selection** | é™æ€åˆ—è¡¨æˆ–ç¡¬ç¼–ç è§„åˆ™ | è¯­ä¹‰æ£€ç´¢ + æ‹ç‚¹è¿‡æ»¤ï¼Œè‡ªé€‚åº”ç­›é€‰ |
| **Memoryç®¡ç†** | çª—å£æˆªæ–­æˆ–ç®€å•æ±‡æ€» | åˆ†å±‚ç»“æ„åŒ–å‹ç¼©ï¼Œä¿ç•™åŠŸèƒ½è¿è´¯æ€§ |
| **åè®®å…¼å®¹æ€§** | å¤šä¸ºç§æœ‰æ¥å£ | æ”¯æŒMCPã€ACPç­‰å¼€æ”¾é€šä¿¡åè®® |
| **éƒ¨ç½²å®ç”¨æ€§** | å®éªŒæ€§è´¨å¼º | å·²ä¸Šçº¿ç”Ÿäº§ç¯å¢ƒï¼ˆ[jenius.cn](https://www.jenius.cn)ï¼‰ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**

#### **(1) APIGenï¼ˆå…¬å¼€åŸºå‡†ï¼‰**
- è§„æ¨¡ï¼š60Kæ ·æœ¬ï¼Œè¦†ç›–21ä¸ªç±»åˆ«ï¼ˆçº¦3.6K APIï¼‰
- ç‰¹ç‚¹ï¼šå•è½®äº¤äº’ï¼Œä»…æµ‹è¯•è‡ªç„¶è¯­è¨€åˆ°APIè°ƒç”¨çš„æ˜ å°„èƒ½åŠ›ã€‚
- æœ¬æ–‡æ”¹è¿›ï¼šæ¯æ¡æŸ¥è¯¢æ³¨å…¥100ä¸ªæ— å…³å·¥å…·ï¼Œæ¨¡æ‹Ÿé«˜å™ªå£°ç¯å¢ƒï¼Œè€ƒéªŒå·¥å…·æ£€ç´¢é²æ£’æ€§ã€‚

#### **(2) Jenius-benchï¼ˆæ–°æ„å»ºçš„çœŸå®ä¸–ç•Œå¤šè½®ä»»åŠ¡æ•°æ®é›†ï¼‰**
- è§„æ¨¡ï¼š850é«˜è´¨é‡äººå·¥æ ‡æ³¨æ ·æœ¬ï¼Œæ¶µç›–38ç±»å·¥å…·
- åº”ç”¨åœºæ™¯ï¼šæ—…è¡Œè§„åˆ’ã€ç¥¨åŠ¡é¢„è®¢ã€ç½‘é¡µç”Ÿæˆã€å­¦æœ¯æ£€ç´¢ç­‰
- ç‰¹ç‚¹ï¼š
  - å¤šè½®å¯¹è¯ï¼ŒåŒ…å«å®Œæ•´æ‰§è¡Œè½¨è¿¹ï¼ˆå·¥å…·è°ƒç”¨ã€å‚æ•°ã€è¿”å›ç»“æœã€å“åº”ï¼‰
  - å·¥å…·é™„å¸¦ä¸°å¯Œè¯­ä¹‰æè¿°ï¼ˆç›®çš„ã€å‰æã€ç¤ºä¾‹ï¼‰
  - è·¯å¾„ç»ä¸“å®¶å®¡æ ¸ï¼Œç¡®ä¿æ­£ç¡®æ€§å’Œä¸€è‡´æ€§
- å¯¹æ¯”APIGenæ›´å…·ç°å®æŒ‘æˆ˜æ€§ï¼ˆè§Table 1ï¼‰

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

#### **è¯„ä¼°æ¡†æ¶ä¸‰ç»´åº¦**
| ç»´åº¦ | æŒ‡æ ‡ä½“ç³» | å†…å®¹ |
|------|---------|------|
| **è¿‡ç¨‹ä¿çœŸåº¦** | **4T Metrics** | TCR, TFR, TIR, TPS |
| **è¾“å‡ºè´¨é‡** | **CRCFF Metrics** | Correctness, Relevance, Completeness, Fluency, Faithfulness |
| **è®¡ç®—æ•ˆç‡** | **Token Consumption** | è¾“å…¥/è¾“å‡ºTokenæ€»é‡ |

##### **4T Metrics å®šä¹‰**
- **TCR (Task Completion Rate)**ï¼šæ‰€æœ‰å¿…éœ€å·¥å…·ä»¥æ­£ç¡®é¡ºåºè°ƒç”¨çš„æ¯”ä¾‹ã€‚
- **TFR (Task Failure Rate)**ï¼šæ— æœ‰æ•ˆæ‰§è¡Œï¼ˆç©ºè°ƒç”¨æˆ–ç³»ç»Ÿé”™è¯¯ï¼‰çš„ä»»åŠ¡æ¯”ä¾‹ã€‚
- **TIR (Task Incompletion Rate)**ï¼šéƒ¨åˆ†å®Œæˆï¼ˆé—æ¼/é”™åº/æ— å…³è°ƒç”¨ï¼‰çš„æ¯”ä¾‹ã€‚
- **TPS (Task Performance Score)**ï¼šç»¼åˆè€ƒè™‘æ­£ç¡®ã€é”™è¯¯ã€é—æ¼å·¥å…·çš„åŠ æƒå¾—åˆ†ã€‚

##### **CRCFF Metrics**
ç”±Qwen-3å’ŒDeepSeekä½œä¸ºLLM evaluatoræ‰“åˆ†ï¼ˆ0â€“10åˆ†åˆ¶ï¼‰ï¼Œè¯„ä¼°å“åº”è¯­ä¹‰è´¨é‡ã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
æ„å»ºå››ä¸ªæ¸è¿›å¼å˜ä½“è¿›è¡Œæ¶ˆèç ”ç©¶ï¼š
| æ¨¡å‹ | æè¿° |
|------|------|
| **Base** | æ ‡å‡†ReActæ¶æ„ï¼Œæ— ä¼˜åŒ– |
| **B-P** | Base + Adaptive Prompt Generation |
| **B-PT** | B-P + Context-Aware Tool Orchestration |
| **Jenius** | B-PT + Hierarchical Memory Managementï¼ˆå®Œæ•´ç‰ˆï¼‰ |

æ‰€æœ‰æ¨¡å‹å…±äº«ç›¸åŒLLM backboneä¸æ¨ç†æµç¨‹ï¼Œä»…ç»„ä»¶ä¸åŒã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **(1) è¿‡ç¨‹ä¿çœŸåº¦ï¼ˆExecution Fidelityï¼‰**

##### **Table 2 & 3: åœ¨APIGenå’ŒJenius-benchä¸Šçš„4Tç»“æœ**

| Model | TCR (APIGen) | TCR (Jenius-bench) | TPS (Jenius-bench) |
|-------|--------------|---------------------|---------------------|
| Base  | 0.8150       | 0.5659              | 0.5968             |
| B-P   | 0.8275       | 0.7271 (**+28.5%**) | 0.7491             |
| B-PT  | 0.8375       | 0.7494 (**+32.5%**) | 0.7740             |
| Jenius| **0.8500**   | **0.7647 (+35%)**   | **0.7847**         |

> ğŸ” **åˆ†æ**ï¼š
> - åœ¨APIGenä¸Šå„æ¨¡å‹è¡¨ç°æ¥è¿‘ï¼Œè¯´æ˜è¯¥æ•°æ®é›†åå‘æ¨¡å¼åŒ¹é…ï¼Œéš¾ä»¥åŒºåˆ†é«˜çº§æ¨ç†èƒ½åŠ›ã€‚
> - åœ¨Jenius-benchä¸Šï¼Œæ¯ä¸€æ­¥ä¼˜åŒ–éƒ½å¸¦æ¥æ˜¾è‘—æå‡ï¼Œ**Jeniusæ¯”Baseæå‡çº¦35%çš„TCR**ï¼Œè¯æ˜å…¶åœ¨çœŸå®å¤æ‚ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

#### **(2) è¾“å‡ºè´¨é‡ï¼ˆCRCFFï¼‰â€”â€”ä»…åœ¨Jenius-benchä¸Šè¯„ä¼°**

| Model | Correctness (Qwen) | Fluency (Qwen) | Faithfulness (DeepSeek) |
|-------|--------------------|----------------|--------------------------|
| Base  | 0.6741             | 0.9294         | 0.8291                   |
| B-P   | 0.7259 (**+7.7%**) | 0.9563         | 0.8654                   |
| B-PT  | 0.7572 (**+12.3%**)| 0.9763         | 0.8652                   |
| Jenius| **0.7580**         | **0.9771**     | **0.8766**               |

> âœ… **ç»“è®º**ï¼šä¸‰é¡¹ä¼˜åŒ–ååŒä½œç”¨ï¼Œä½¿Correctnessæå‡è¶…12%ï¼ŒFluencyæ¥è¿‘æ»¡åˆ†ï¼ŒFaithfulnessç¨³æ­¥ä¸Šå‡ã€‚

#### **(3) Tokenæ¶ˆè€—åˆ†æï¼ˆFigure 6ï¼‰**

| æ•°æ®é›† | Base â†’ Jenius Token Reduction |
|--------|-------------------------------|
| APIGen | 9.96M â†’ 2.46M (**â†“75.2%**) |
| Jenius-bench | 9.27M â†’ 3.65M (**â†“60.6%**) |

> ğŸ’¡ **åŸå› åˆ†è§£**ï¼š
> - **Adaptive Prompt** å‡å°‘å†—ä½™æ¨ç†ï¼›
> - **Tool Orchestration** æŠ‘åˆ¶æ— æ•ˆè°ƒç”¨ï¼›
> - **Hierarchical Memory** å‹ç¼©å†å²è€Œä¸æŸå¤±è¯­ä¹‰ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**
- **B-P vs Base**ï¼šPromptä¼˜åŒ–å•ç‹¬å³å¯å¤§å¹…æå‡TCRï¼ˆ+16%ï¼‰å’ŒCorrectnessï¼ˆ+7.7%ï¼‰ï¼Œè¡¨æ˜æ„å›¾è¯†åˆ«ä¸åŠ¨æ€æç¤ºè‡³å…³é‡è¦ã€‚
- **B-PT vs B-P**ï¼šåŠ å…¥å·¥å…·ç¼–æ’åï¼ŒTIRä¸‹é™21%ï¼ŒTPSæå‡ï¼Œæ˜¾ç¤ºè¯­ä¹‰æ£€ç´¢æœ‰æ•ˆæŠ‘åˆ¶è¯¯è°ƒã€‚
- **Jenius vs B-PT**ï¼šå¼•å…¥è®°å¿†ç®¡ç†è¿›ä¸€æ­¥æå‡Faithfulnesså’Œç¨³å®šæ€§ï¼Œå°¤å…¶åœ¨é•¿ä»»åŠ¡ä¸­æ•ˆæœæ˜æ˜¾ã€‚

> ğŸ“Š æ€»ä½“è¶‹åŠ¿ï¼š**æ¯ä¸ªæ¨¡å—è´¡çŒ®äº’è¡¥ï¼Œè”åˆä½¿ç”¨è¾¾åˆ°æœ€ä¼˜æ€§èƒ½**ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **ç»éªŒé©±åŠ¨çš„è®¾è®¡ä¼˜äºé™æ€æ¶æ„**ï¼šé€šè¿‡åŠ¨æ€é€‚é…Promptã€å·¥å…·å’Œè®°å¿†ï¼ŒJenius-Agentåœ¨çœŸå®å¤æ‚ä»»åŠ¡ä¸­å®ç°äº†æ›´é«˜çš„ä»»åŠ¡å®Œæˆç‡å’Œè¾“å‡ºè´¨é‡ã€‚
2. **ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ˜¯å·¥å…·è°ƒç”¨çš„å…³é”®**ï¼šä¼ ç»Ÿçš„Top-Kæ£€ç´¢æ˜“å—å™ªå£°å¹²æ‰°ï¼Œè€Œç»“åˆæ‹ç‚¹æ£€æµ‹çš„åŠ¨æ€æˆªæ–­èƒ½æ›´å¥½å¹³è¡¡ç²¾åº¦ä¸è¦†ç›–ç‡ã€‚
3. **åˆ†å±‚è®°å¿†æœºåˆ¶å¯å…¼é¡¾æ•ˆç‡ä¸è¿è´¯æ€§**ï¼šç›¸æ¯”ç®€å•æˆªæ–­ï¼Œç»“æ„åŒ–æ‘˜è¦èƒ½ä¿ç•™è·¨è½®ä¾èµ–ï¼Œæ”¯æ’‘é•¿æœŸæ¨ç†ã€‚
4. **æ¨¡å—åŒ–è®¾è®¡ä¾¿äºå·¥ç¨‹è½åœ°**ï¼šJeniuså·²éƒ¨ç½²äºç”Ÿäº§ç¯å¢ƒï¼ˆé˜¿é‡Œäº‘+Kubernetesï¼‰ï¼Œæ”¯æŒå¯è§‚æµ‹æ€§ï¼ˆLangfuseï¼‰ã€å®‰å…¨é€šä¿¡ï¼ˆmTLSï¼‰å’ŒCI/CDè‡ªåŠ¨åŒ–ã€‚

---

### **å±€é™æ€§**
1. **è¯„ä¼°ä»åé‡åŠŸèƒ½æ€§æŒ‡æ ‡**ï¼šæœªå……åˆ†çº³å…¥ç”¨æˆ·ä½“éªŒã€å†³ç­–æˆæœ¬ã€å»¶è¿Ÿç­‰è¿è¥æŒ‡æ ‡ã€‚
2. **å­˜åœ¨å¤šç§åˆç†æ‰§è¡Œè·¯å¾„æœªè¢«å»ºæ¨¡**ï¼šç›®å‰TCRè¦æ±‚å®Œå…¨åŒ¹é…å‚è€ƒåºåˆ—ï¼Œå¯èƒ½æƒ©ç½šåˆæ³•ä½†ä¸åŒçš„è§£å†³æ–¹æ¡ˆã€‚
3. **å¯¹æç«¯é•¿ä»»åŠ¡çš„æ”¯æŒæœ‰é™**ï¼šå°½ç®¡æœ‰æ‘˜è¦æœºåˆ¶ï¼Œæé•¿å¯¹è¯ä»å¯èƒ½å¯¼è‡´è¯­ä¹‰æ¼‚ç§»ã€‚
4. **ä¾èµ–é«˜è´¨é‡å·¥å…·å…ƒæ•°æ®**ï¼šè‹¥MCPå·¥å…·æè¿°ä¸å®Œæ•´ï¼Œä¼šå½±å“è¯­ä¹‰æ£€ç´¢æ•ˆæœã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **æ›´çµæ´»çš„ç»“æœå¯¼å‘è¯„ä¼°**ï¼šå…è®¸å¤šç§æœ‰æ•ˆæ‰§è¡Œè·¯å¾„ï¼Œç»“åˆç”¨æˆ·æ»¡æ„åº¦åé¦ˆã€‚
2. **åŠ¨æ€æ¨¡å—é‡ç»„æœºåˆ¶**ï¼šæ ¹æ®ä»»åŠ¡å¤æ‚åº¦è‡ªåŠ¨å¯ç”¨/å…³é—­æŸäº›ä¼˜åŒ–æ¨¡å—ã€‚
3. **å¤šæ™ºèƒ½ä½“åä½œæ¡†æ¶**ï¼šæ¢ç´¢åˆ†å¸ƒå¼é—®é¢˜æ±‚è§£ä¸ä»»åŠ¡åˆ†å·¥ã€‚
4. **å¼ºåŒ–è§£é‡Šæ€§ä¸é€æ˜åº¦**ï¼šæä¾›ä¸­é—´æ¨ç†é“¾ã€å·¥å…·é€‰æ‹©ç†ç”±ï¼Œå¢å¼ºç”¨æˆ·ä¿¡ä»»ã€‚
5. **è‡ªé€‚åº”é‡è¯•ç­–ç•¥ä¼˜åŒ–**ï¼šåŸºäºé”™è¯¯ç±»å‹å’Œä¸Šä¸‹æ–‡åŠ¨æ€è°ƒæ•´é‡è¯•é€»è¾‘ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **Jenius-Agenté€šè¿‡è‡ªé€‚åº”Promptã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥å·¥å…·ç¼–æ’å’Œåˆ†å±‚è®°å¿†ä¸‰å¤§åˆ›æ–°ï¼Œåœ¨çœŸå®ä¸–ç•Œå¤šè½®ä»»åŠ¡ä¸­å®ç°äº†çº¦35%çš„ä»»åŠ¡å‡†ç¡®ç‡æå‡ï¼ŒåŒæ—¶é™ä½60%ä»¥ä¸ŠTokenæ¶ˆè€—ï¼Œä¸ºå¯æ‰©å±•ã€é²æ£’ã€åè®®å…¼å®¹çš„LLMæ™ºèƒ½ä½“æä¾›äº†å®ç”¨èŒƒæœ¬ã€‚**

</details>

---

### 4. [BigSUMO: A Scalable Framework for Big Data Traffic Analytics and Parallel Simulation](https://arxiv.org/abs/2601.02286)

**Authors**: Rahul Sengupta, Nooshin Yousefzadeh, Manav Sanghvi, Yash Ranjan, Anand Rangarajan, Sanjay Ranka, Yashaswi Karnati, Jeremy Dilmore, Tushar Patel, Ryan Casburn  
**Category**: cs.DC  
**Published**: 2026-01-06  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2601.02286v1  

#### Abstract
With growing urbanization worldwide, efficient management of traffic infrastructure is critical for transportation agencies and city planners. It is essential to have tools that help analyze large volumes of stored traffic data and make effective interventions. To address this need, we present ``Big...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šBigSUMO: A Scalable Framework for Big Data Traffic Analytics and Parallel Simulation

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
éšç€åŸå¸‚åŒ–è¿›ç¨‹åŠ å¿«ï¼Œäº¤é€šç®¡ç†éƒ¨é—¨äºŸéœ€é«˜æ•ˆå·¥å…·æ¥åˆ†ææµ·é‡äº¤é€šæ•°æ®ã€æ£€æµ‹å¼‚å¸¸äº‹ä»¶ï¼Œå¹¶è¯„ä¼°å¹²é¢„æªæ–½çš„æœ‰æ•ˆæ€§ã€‚ç„¶è€Œï¼Œç°æœ‰ç³»ç»Ÿå¾€å¾€å­˜åœ¨ä»¥ä¸‹ä¸è¶³ï¼š
- ç¼ºä¹ç«¯åˆ°ç«¯ï¼ˆend-to-endï¼‰çš„å¯æ‰©å±•æ¡†æ¶ï¼›
- å¤šæ•°ä¾èµ–ä¸“æœ‰è½¯ä»¶ï¼ˆå¦‚ VISSIMï¼‰ï¼Œæˆæœ¬é«˜ä¸”éš¾ä»¥éƒ¨ç½²ï¼›
- éš¾ä»¥åŒæ—¶èåˆå¤šæºå¼‚æ„æ•°æ®ï¼ˆå¦‚ ATSPM å’Œè½¨è¿¹æ•°æ®ï¼‰è¿›è¡Œæè¿°æ€§ä¸**prescriptive analytics**ï¼›
- ç¼ºå°‘å¯¹ç¨€ç– probe è½¨è¿¹æ•°æ®çš„æœ‰æ•ˆå¤„ç†æœºåˆ¶ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
æœ¬æ–‡æå‡º **BigSUMO** â€”â€” ä¸€ä¸ªå¼€æºã€å¯æ‰©å±•ã€æ¨¡å—åŒ–çš„ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œç”¨äºå¤§è§„æ¨¡äº¤é€šæ•°æ®åˆ†æä¸å¹¶è¡Œä»¿çœŸï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

1. **ç»Ÿä¸€çš„æ•°æ®å¤„ç†æµæ°´çº¿**  
   æ”¯æŒä» **ATSPM æ•°æ®**ï¼ˆloop detector å’Œä¿¡å·çŠ¶æ€ï¼‰å’Œ **ç¨€ç– probe è½¨è¿¹æ•°æ®** ä¸­æå–ä¿¡æ¯ï¼Œå®ç°åŸå¸‚çº§äº¤é€šçŠ¶æ€å»ºæ¨¡ã€‚

2. **åŸºäºç©ºé—´æ©ç çš„ç©ºé—´è¿‡æ»¤æœºåˆ¶ï¼ˆSpatial Masksï¼‰**  
   åˆ©ç”¨ GIS æ•°æ®è‡ªåŠ¨ç”Ÿæˆé“è·¯ç¼“å†²åŒºå’Œäº¤å‰å£åŒºåŸŸæ©ç ï¼Œè‡ªåŠ¨è£å‰ªæ— å…³è½¨è¿¹ï¼Œæå‡åˆ†æç²¾åº¦ä¸æ•ˆç‡ã€‚

3. **åŒé€šé“ä¸­æ–­æ£€æµ‹ç³»ç»Ÿï¼ˆInterruption Detectionï¼‰**  
   - åŸºäº ATSPM çš„å†å²æµé‡æ¨¡å¼æ¯”è¾ƒï¼›
   - åŸºäºè½¨è¿¹çš„å¼‚å¸¸å‘é‡æ£€æµ‹ï¼ˆä½¿ç”¨ ABOD ç®—æ³•ï¼‰ï¼›
   å®ç°äº’è¡¥å¼å¼‚å¸¸è¯†åˆ«ã€‚

4. **å¹¶è¡ŒåŒ– SUMO å¾®è§‚ä»¿çœŸæ¶æ„**  
   ä½¿ç”¨ Python `multiprocessing` å¹¶è¡Œè¿è¡Œæ•°ç™¾æ¬¡ SUMO æ¨¡æ‹Ÿï¼Œæ”¯æŒâ€œwhat-ifâ€åœºæ™¯æµ‹è¯•ï¼ˆå¦‚ä¿¡å·é…æ—¶ä¼˜åŒ–ï¼‰ï¼Œæ— éœ€å•†ä¸šè®¸å¯è¯ã€‚

5. **å¼€æ”¾æ€§å’Œå¯å¤ç°æ€§**  
   å…¨æµç¨‹åŸºäºå¼€æºç»„ä»¶ï¼ˆGeoPandas, MovingPandas, PyOD, SUMO, Jupyterï¼‰ï¼Œå¯åœ¨é€šç”¨äº‘å¹³å°éƒ¨ç½²ï¼Œé™ä½äº¤é€šæœºæ„ä½¿ç”¨é—¨æ§›ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ ReTime + VISSIMï¼‰ | BigSUMO |
|------|-------------------------------|--------|
| æˆæœ¬ | å•†ä¸šè½¯ä»¶æˆæƒè´¹ç”¨é«˜æ˜‚ | å®Œå…¨å¼€æºå…è´¹ |
| å¯æ‰©å±•æ€§ | å•æœºä¸²è¡Œæ¨¡æ‹Ÿè€—æ—¶é•¿ | æ”¯æŒå¹¶è¡Œæ¨¡æ‹Ÿï¼ˆ100+ åŒæ—¶è¿è¡Œï¼‰ |
| æ•°æ®èåˆèƒ½åŠ› | å¤šå±€é™äºå•ä¸€æ•°æ®æº | èåˆ ATSPM ä¸ probe è½¨è¿¹ |
| å¼‚å¸¸æ£€æµ‹ | å¤šä¸ºè§„åˆ™é©±åŠ¨æˆ–ç®€å•ç»Ÿè®¡ | ç»“åˆæœºå™¨å­¦ä¹ ï¼ˆABODï¼‰ä¸ä¸Šä¸‹æ–‡å½’ä¸€åŒ– |
| éƒ¨ç½²éš¾åº¦ | ä¾èµ–ç‰¹å®šç¯å¢ƒ | åŸºäº Python ç”Ÿæ€ï¼Œæ˜“äºéƒ¨ç½² |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†
1. **ATSPM æ•°æ®**  
   - æ¥æºï¼šFlorida Department of Transportation (FDOT)
   - å†…å®¹ï¼šæ„Ÿåº”çº¿åœˆè½¦è¾†è®¡æ•°ã€ç›¸ä½ä¿¡å·çŠ¶æ€ï¼ˆçº¢/ç»¿/é»„ï¼‰
   - æ—¶é—´èŒƒå›´ï¼š2024å¹´è¿ç»­ä¸¤ä¸ªæœˆ
   - ç²’åº¦ï¼šæ¯å‘¨æœŸï¼ˆcycle-levelï¼‰è®°å½•

2. **Probe è½¨è¿¹æ•°æ®**  
   - æ¥æºï¼šå•†ä¸šä¾›åº”å•†ï¼ˆéç½‘çº¦è½¦/å‡ºç§Ÿè½¦ï¼‰
   - åœ°ç†èŒƒå›´ï¼šç¾å›½ä½›ç½—é‡Œè¾¾å·ä¸‰ä¸ªå¿
   - è§„æ¨¡ï¼šæ¯æ—¥çº¦ 17,000â€“22,000 æ¡å”¯ä¸€è¡Œç¨‹
   - åˆ†è¾¨ç‡ï¼šæ—¶é—´é—´éš” 3 ç§’ï¼Œç©ºé—´ç²¾åº¦ ~1 ç±³
   - æ¸—é€ç‡ï¼š3%â€“7%ï¼Œä»£è¡¨å½“å‰ Connected Vehicle æ°´å¹³

3. **GIS æ•°æ®**  
   - æ¥æºï¼šFDOT SunStore æ•°æ®åº“
   - åŒ…æ‹¬ï¼šâ€œBasemap Route Roadsâ€ å’Œ â€œIntersectionsâ€ å›¾å±‚ï¼Œç”¨äºç”Ÿæˆ spatial masks

### âš™ï¸ å®éªŒè®¾ç½®
- **ç ”ç©¶åŒºåŸŸ**ï¼šå¤šä¸ªåŸå¸‚äº¤å‰å£åŠèµ°å»Šï¼ˆcorridorï¼‰ï¼Œé‡ç‚¹å…³æ³¨å·¥ä½œæ—¥ PM é«˜å³°æ—¶æ®µ
- **é¢„å¤„ç†æµç¨‹**ï¼š
  - è½¨è¿¹æ¸…æ´—ï¼šå‰”é™¤ç†„ç«çŠ¶æ€ã€çŸ­é€”æ—…ç¨‹ï¼ˆ<2minï¼‰ã€çŸ­è·ç¦»è½¨è¿¹ï¼ˆ<150mï¼‰
  - ä½¿ç”¨ GeoPandas/MovingPandas è¿›è¡Œè½¨è¿¹è£å‰ªä¸ç‰¹å¾æå–
- **ä¸­æ–­æ£€æµ‹æµç¨‹**ï¼š
  - ç‰¹å¾å‘é‡æ„å»ºï¼šæ¯æ¡è½¨è¿¹æå– `stopped time`, `avg speed`, `std speed`, `travel time`
  - å½’ä¸€åŒ–åè¾“å…¥ ABODï¼ˆAngle-Based Outlier Detectionï¼‰ç®—æ³•
  - å¯¹æ¯”åŒæœŸå‰ä¸€å‘¨ä¸ä¸¤å‘¨çš„å†å²è¡Œä¸ºä½œä¸ºâ€œæ­£å¸¸â€åŸºå‡†
- **SUMO ä»¿çœŸé…ç½®**ï¼š
  - Basemap æ„å»ºï¼šé€šè¿‡ NETEDIT æˆ– OpenStreetMap å¯¼å…¥
  - æµé‡æ ¡å‡†ï¼šç»“åˆ ATSPM è½¦è¾†æ•°ä¸è½¨è¿¹æ¨æ–­çš„ OD çŸ©é˜µï¼ˆturning movement probabilitiesï¼‰
  - é€Ÿåº¦æ ¡å‡†ï¼šåˆ©ç”¨è½¨è¿¹æœ€å¤§é€Ÿåº¦åˆ†å¸ƒè°ƒæ•´ SUMO çš„ `speedFactor`
  - ä¿¡å·æ§åˆ¶ï¼šåŸºäº NEMA ç›¸ä½é€»è¾‘ä¸å®é™…ä¿¡å·é…æ—¶è¡¨è®¾å®š

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
| ç±»åˆ« | æŒ‡æ ‡ |
|------|------|
| æè¿°æ€§åˆ†æ | Wait time åˆ†å¸ƒã€queue length æ¦‚ç‡ã€braking event çƒ­ç‚¹å›¾ã€turning movement OD çŸ©é˜µ |
| å¼‚å¸¸æ£€æµ‹ | Outlier å‘é‡å¯†åº¦ã€real-time interruption probability heatmap |
| ä»¿çœŸæ€§èƒ½ | Corridor travel timeã€average delayã€stopæ¬¡æ•°ã€throughput |
| æ•ˆç‡ | å•ä¸ªäº¤å‰å£å…¨æµç¨‹å¤„ç†æ—¶é—´ï¼ˆ~2â€“3åˆ†é’Ÿï¼‰ã€å¹¶è¡Œæ¨¡æ‹Ÿååé‡ |

### ğŸ”€ åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **ä¸­æ–­æ£€æµ‹**ï¼šä¸ä»…åŸºäº ATSPM çš„æ–¹æ³• [5] å¯¹æ¯”
- **ä»¿çœŸä¼˜åŒ–**ï¼šç±»æ¯” ReTimeï¼ˆåŸºäº VISSIM çš„å¹¶è¡Œä¼˜åŒ–å·¥å…·ï¼‰
- **æ¨¡å‹è®­ç»ƒæ•°æ®ç”Ÿæˆ**ï¼šä¸äººå·¥æ ‡æ³¨æˆ–å°è§„æ¨¡ä»¿çœŸæ•°æ®å¯¹æ¯”

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®
| æ¨¡å— | æ€§èƒ½è¡¨ç° |
|------|---------|
| **è½¨è¿¹é¢„å¤„ç† + åˆ†æ** | å•äº¤å‰å£å…¨æµç¨‹è€—æ—¶çº¦ **2â€“3åˆ†é’Ÿ**ï¼ˆCPU å¤šçº¿ç¨‹ï¼‰ |
| **ä¸­æ–­æ£€æµ‹** | æˆåŠŸè¯†åˆ«å‡º braking events é«˜å‘åŒºï¼ˆè§ Fig. 8ï¼‰ã€æ’é˜Ÿå¼‚å¸¸æ–¹å‘ï¼ˆEastbound/Southbound æ›´ä¸¥é‡ï¼‰ |
| **SUMO å¹¶è¡Œä»¿çœŸ** | åœ¨æ™®é€šäº‘æœåŠ¡å™¨ä¸Šå¯åŒæ—¶è¿è¡Œ **ä¸Šç™¾ä¸ªä»¿çœŸä»»åŠ¡**ï¼Œæ¯ä¸ª 1 å°æ—¶ä»¿çœŸè€—æ—¶ 3â€“6 åˆ†é’Ÿ |
| **ä¿¡å·ä¼˜åŒ–æ¡ˆä¾‹** | é€šè¿‡ grid search æ‰¾åˆ°æœ€ä¼˜ cycle length ä¸ green time ç»„åˆï¼Œä½¿ corridor travel time ä¸‹é™ **12â€“18%** |
| **é˜Ÿåˆ—é•¿åº¦ä¼°è®¡** | åˆ©ç”¨ stop point åˆ†å¸ƒæ‹Ÿåˆ queue length æ¦‚ç‡ï¼ˆFig. 7ï¼‰ï¼ŒEastbound æœ€å¤§å¯è¾¾ 150m |

### ğŸ” ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ
- **ç›¸æ¯”çº¯ ATSPM æ–¹æ³• [5]**ï¼š
  - è½¨è¿¹å¢å¼ºå‹ä¸­æ–­æ£€æµ‹èƒ½æ•æ‰æ›´ç»†ç²’åº¦çš„è¡Œä¸ºå¼‚å¸¸ï¼ˆå¦‚æ€¥åˆ¹ã€ç»•è¡Œï¼‰
  - ä½†ç›®å‰å›  probe æ•°æ®ç¨€ç–ï¼Œå¯é æ€§ä»ä½äº ATSPM æ–¹æ³•
- **ç›¸æ¯” ReTime + VISSIM**ï¼š
  - BigSUMO å®ç°ç±»ä¼¼åŠŸèƒ½ï¼ˆå‚æ•°æ‰«æ+ä¼˜åŒ–ï¼‰ï¼Œä½†æ— éœ€è®¸å¯è´¹
  - å¼€æºç‰¹æ€§å…è®¸æ·±åº¦å®šåˆ¶ä¸é›†æˆ ML æ¨¡å‹
- **åœ¨ prescriptive analytics ä¸Šçš„è¡¨ç°**ï¼š
  - æ”¯æŒå¿«é€ŸéªŒè¯å¤šç§ä¿¡å·ç­–ç•¥ç»„åˆï¼Œæ˜¾è‘—ç¼©çŸ­å†³ç­–å‘¨æœŸ
  - å¯è¾“å‡ºç¨³å¥æ€§åˆ†æï¼ˆrobustness under uncertaintyï¼‰

### ğŸ” æ¶ˆèå®éªŒï¼ˆéšå«åˆ†æï¼‰
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèå®éªŒè¡¨æ ¼ï¼Œä½†æ–‡ä¸­é€šè¿‡ä»¥ä¸‹æ–¹å¼ä½“ç°æ¨¡å—æœ‰æ•ˆæ€§ï¼š
- è‹¥ä¸ä½¿ç”¨ spatial masks â†’ è½¨è¿¹å™ªå£°å¢åŠ ï¼Œåˆ†æè¯¯å·®ä¸Šå‡
- è‹¥ä¸ç”¨è½¨è¿¹æ ¡å‡† speedFactor â†’ SUMO é»˜è®¤é™é€Ÿå¯¼è‡´ overspeeding è¡Œä¸ºç¼ºå¤±
- è‹¥ä»…ç”¨ ATSPM æ¨æ–­ OD â†’ turning movement ä¸å‡†ç¡®ï¼Œå½±å“ä»¿çœŸ realism

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **ç¨€ç– probe æ•°æ®ä»å…·é«˜ä»·å€¼**ï¼šå³ä½¿æ¸—é€ç‡ä»…ä¸º 3%-7%ï¼Œä¹Ÿèƒ½æœ‰æ•ˆæ”¯æŒ wait timeã€queue lengthã€braking behavior ç­‰å…³é”®æŒ‡æ ‡åˆ†æã€‚
2. **åŒæºæ•°æ®èåˆæå‡é²æ£’æ€§**ï¼šATSPM æä¾›ç¨³å®šå®è§‚æµé‡ï¼Œprobe æ•°æ®æä¾›å¾®è§‚è¡Œä¸ºç»†èŠ‚ï¼ŒäºŒè€…äº’è¡¥ã€‚
3. **å¼€æºå·¥å…·é“¾è¶³ä»¥æ”¯æ’‘åŸå¸‚çº§åˆ†æ**ï¼šSUMO + Python ç”Ÿæ€å¯æ›¿ä»£æ˜‚è´µå•†ä¸šè½¯ä»¶ï¼Œå®ç°é«˜æ€§èƒ½å¹¶è¡Œä»¿çœŸã€‚
4. **è‡ªåŠ¨åŒ– spatial masking æ˜¾è‘—æå‡æ•ˆç‡**ï¼šé¿å…æ‰‹åŠ¨æ ‡æ³¨ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡éƒ¨ç½²ã€‚
5. **BigSUMO å¯ä½œä¸ºæ•°å­—å­ªç”ŸåŸºç¡€å¹³å°**ï¼šå·²æˆåŠŸç”¨äºè®­ç»ƒ GNN æ¨¡å‹ï¼ˆå¦‚ [11][12][13]ï¼‰å’Œæ„å»º Digital Twin ç³»ç»Ÿï¼ˆMTDT/TGDTï¼‰ã€‚

### âš ï¸ å±€é™æ€§
1. **probe æ•°æ®ç¨€ç–æ€§é™åˆ¶**ï¼šä½é‡‡æ ·ç‡å¯èƒ½å¯¼è‡´æŸäº› rare eventsï¼ˆå¦‚ near-missï¼‰æ¼æ£€ã€‚
2. **è½¨è¿¹éšç§å¤„ç†å½±å“å®Œæ•´æ€§**ï¼šéƒ¨åˆ†è½¨è¿¹ç‚¹è¢«éšè—ï¼ˆå¦‚ä¸­é—´æ®µï¼‰ï¼Œå¯èƒ½æ‰­æ›²çœŸå®è¡Œé©¶è·¯å¾„ã€‚
3. **å½“å‰ä¸­æ–­æ£€æµ‹ä»¥ç¦»çº¿ä¸ºä¸»**ï¼šå°šæœªå®Œå…¨å®ç°å®æ—¶æµå¼å¤„ç†ã€‚
4. **SUMO æ ¡å‡†ä¾èµ–äººå·¥ç»éªŒ**ï¼šå°½ç®¡æµç¨‹æ ‡å‡†åŒ–ï¼Œä½†ä»éœ€ä¸€å®šé¢†åŸŸçŸ¥è¯†å®Œæˆ basemap é…ç½®ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æå‡å®æ—¶æ€§**ï¼šå¼•å…¥ streaming pipelineï¼ˆå¦‚ Kafka/Flinkï¼‰æ”¯æŒ near-real-time interruption detectionã€‚
2. **èåˆæ›´å¤šä¼ æ„Ÿå™¨æ¨¡æ€**ï¼šæ•´åˆè§†é¢‘ã€LiDARã€CV data æå‡æ„ŸçŸ¥ç²¾åº¦ã€‚
3. **è¿æ¥ V2X infrastructure**ï¼šéšç€ CV penetration rate ä¸Šå‡ï¼Œå°†è¿›ä¸€æ­¥å¢å¼ºè½¨è¿¹è´¨é‡ä¸åº”ç”¨æ½œåŠ›ã€‚
4. **è‡ªåŠ¨åŒ–å‚æ•°è°ƒä¼˜**ï¼šå¼•å…¥ Bayesian Optimization æˆ– RL æ›¿ä»£ grid searchï¼Œæé«˜ prescriptive analytics æ•ˆç‡ã€‚
5. **ä»£ç å¼€æºè®¡åˆ’**ï¼šé€æ­¥å‘å¸ƒå®Œæ•´ä»£ç è‡³ GitHubï¼ˆgithub.com/NSH2022/BigSUMOï¼‰ï¼Œæ¨åŠ¨ç¤¾åŒºå…±å»ºã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> BigSUMO æ˜¯ä¸€ä¸ªä½æˆæœ¬ã€å¯æ‰©å±•ã€å¼€æºçš„åŸå¸‚äº¤é€šåˆ†æä¸ä»¿çœŸæ¡†æ¶ï¼Œé€šè¿‡èåˆ ATSPM ä¸ probe æ•°æ®ï¼Œå®ç°äº†ä» descriptive åˆ° prescriptive analytics çš„é—­ç¯ï¼Œä¸ºæ™ºèƒ½äº¤é€šç³»ç»Ÿï¼ˆITSï¼‰å’Œæ•°å­—å­ªç”Ÿå»ºè®¾æä¾›äº†å¼ºå¤§å·¥å…·æ”¯æ’‘ã€‚

</details>

---

### 5. [Accelerating Decentralized Optimization via Overlapping Local Steps](https://arxiv.org/abs/2601.01493)

**Authors**: Yijie Zhou, Shi Pu  
**Category**: cs.LG  
**Published**: 2026-01-06  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2601.01493v1  

#### Abstract
Decentralized optimization has emerged as a critical paradigm for distributed learning, enabling scalable training while preserving data privacy through peer-to-peer collaboration. However, existing methods often suffer from communication bottlenecks due to frequent synchronization between nodes. We...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAccelerating Decentralized Optimization via Overlapping Local Steps

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨åˆ†å¸ƒå¼æœºå™¨å­¦ä¹ ä¸­ï¼Œ**é€šä¿¡å¼€é”€**æ˜¯åˆ¶çº¦è®­ç»ƒæ•ˆç‡çš„å…³é”®ç“¶é¢ˆã€‚ä¼ ç»Ÿçš„é›†ä¸­å¼æ–¹æ³•ä¾èµ–å‚æ•°æœåŠ¡å™¨è¿›è¡ŒåŒæ­¥ï¼Œå®¹æ˜“å½¢æˆå•ç‚¹æ•…éšœå’Œé€šä¿¡ç“¶é¢ˆï¼›è€Œå»ä¸­å¿ƒåŒ–ä¼˜åŒ–ï¼ˆDecentralized Optimization, DOï¼‰è™½ç„¶é¿å…äº†ä¸­å¿ƒåè°ƒï¼Œä½†ä»é¢ä¸´é¢‘ç¹é€šä¿¡å¯¼è‡´çš„èŠ‚ç‚¹ç­‰å¾…æ—¶é—´ï¼ˆnetwork idle timeï¼‰ã€‚ç°æœ‰æ–¹æ³•å¦‚ Local DSGD è™½é€šè¿‡å¢åŠ æœ¬åœ°æ›´æ–°æ­¥æ•°å‡å°‘é€šä¿¡é¢‘ç‡ï¼Œä½†æœªæœ‰æ•ˆåˆ©ç”¨è®¡ç®—ä¸é€šä¿¡ä¹‹é—´çš„é‡å æ½œåŠ›ã€‚

æ­¤å¤–ï¼Œè®¸å¤šå°è¯•å®ç° **computation-communication overlapping** çš„æ–¹æ³•å› ä½¿ç”¨è¿‡æ—¶ä¿¡æ¯ï¼ˆstale models/gradientsï¼‰å¼•å…¥åå·®ï¼Œå½±å“æ”¶æ•›æ€§ï¼Œå°¤å…¶åœ¨éå‡¸ç›®æ ‡ä¸‹è¡¨ç°æ›´å·®ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šOLDSGD
æœ¬æ–‡æå‡º **Overlapping Local Decentralized SGD (OLDSGD)**ï¼Œæ˜¯é¦–ä¸ªå°† **local updates** ä¸ **computation-communication overlapping** ç»“åˆçš„å»ä¸­å¿ƒåŒ–è®­ç»ƒç®—æ³•ã€‚

#### æ ¸å¿ƒè®¾è®¡æ€æƒ³ï¼š
- é‡‡ç”¨ **Combine-Then-Adapt (CTA)** æ›´æ–°æœºåˆ¶ï¼Œåœ¨æ‰§è¡Œæœ¬åœ°æ¢¯åº¦æ›´æ–°çš„åŒæ—¶å¼‚æ­¥æ¥æ”¶é‚»å±…æ¨¡å‹ã€‚
- åˆ©ç”¨ **è¿‡æ—¶çš„é‚»å±…æ¨¡å‹ï¼ˆstale modelsï¼‰** è¿›è¡Œå…±è¯†æ›´æ–°ï¼ˆconsensus updateï¼‰ï¼Œä»è€Œå…è®¸é€šä¿¡è¿‡ç¨‹å®Œå…¨ä¸è®¡ç®—è¿‡ç¨‹å¹¶è¡Œï¼Œ**å½»åº•æ©ç›–é€šä¿¡å»¶è¿Ÿ**ã€‚
- å…³é”®æ´å¯Ÿï¼šå°½ç®¡ä½¿ç”¨äº† stale modelsï¼Œä½†ç”±äº CTA è®¾è®¡å’ŒåŒéšæœºæ··åˆçŸ©é˜µ $W$ çš„æ€§è´¨ï¼Œå…¶**å¹³å‡æ¨¡å‹æ›´æ–°åŠ¨æ€ç­‰ä»·äºæ ‡å‡† SGD**ï¼Œå³ï¼š
  $$
  \bar{x}_t = \bar{x}_{t-1} - \alpha \frac{1}{n}\sum_{i=1}^n g_i^{t-1}
  $$
  å› æ­¤é¿å…äº†å› æ¢¯åº¦é™ˆæ—§å¯¼è‡´çš„â€œæ¢¯åº¦é”™é…â€é—®é¢˜ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿è¯´æ˜ |
|------|----------|
| **ç†è®ºä¿è¯** | æ”¶æ•›é€Ÿç‡ä¸ Local DSGD åœ¨éå‡¸è®¾å®šä¸‹ç›¸åŒï¼ˆ$O(\frac{1}{\sqrt{T}})$ï¼‰ï¼Œæ— é¢å¤–åå·®æˆ–é€€åŒ–ã€‚ |
| **è¿è¡Œæ—¶æ•ˆç‡** | æ¯è½®è¿­ä»£æ—¶é—´ä» $T + c$ï¼ˆä¸²è¡Œï¼‰é™ä½è‡³ $\max(T, c)$ï¼Œå½“ $T \geq c$ æ—¶å¯å®ç°**å®Œå…¨é€šä¿¡éšè—**ï¼Œæé€Ÿå¯è¾¾ 2 å€ä»¥ä¸Šã€‚ |
| **é€‚ç”¨æ€§å¹¿** | ä¸ä¾èµ–å…¨å±€å¹³å‡ï¼Œé€‚ç”¨äºä»»æ„ç½‘ç»œæ‹“æ‰‘ï¼ˆå¦‚ç¯å½¢ã€ç½‘æ ¼ç­‰ï¼‰ï¼Œè€Œ Overlap-Local-SGD ç­‰éœ€å…¨è¿æ¥æ‹“æ‰‘ã€‚ |
| **æ— éœ€è¡¥å¿æœºåˆ¶** | ä¸åŒäº CoCoD-SGDã€Delayed-SGD ç­‰éœ€è¦æ¢¯åº¦è£å‰ªã€è¯¯å·®æ ¡æ­£ç­‰å¤æ‚è¡¥å¿ç­–ç•¥ï¼ŒOLDSGD å¤©ç„¶æ— åã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†ä¸ä»»åŠ¡
å®éªŒæ¶µç›–è®¡ç®—æœºè§†è§‰ä¸è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼š
- **CIFAR-10** ä¸Šè®­ç»ƒï¼š
  - **VGG11**ï¼ˆ9 ä¸ª agentï¼‰
  - **ResNet18**ï¼ˆ9 ä¸ª agentï¼‰
- **WikiText-2** ä¸Šå¾®è°ƒï¼š
  - **GPT2-Small**ï¼ˆ8 ä¸ª agentï¼Œä»…æµ‹è¯•åŒæ„æ•°æ®åˆ†å¸ƒï¼‰

### å®éªŒè®¾ç½®
- **ç½‘ç»œæ‹“æ‰‘**ï¼šé»˜è®¤ä¸º undirected ring topologyã€‚
- **é€šä¿¡å»¶è¿Ÿå»ºæ¨¡**ï¼šè®¾æ¯æ¬¡å…±è¯†æ“ä½œè€—æ—¶ $c$ å•ä½æ—¶é—´ï¼Œæ¯æ­¥æ¢¯åº¦è®¡ç®—è€—æ—¶ 1 å•ä½æ—¶é—´ã€‚
- **æœ¬åœ°æ­¥æ•° $T$**ï¼šæµ‹è¯•èŒƒå›´ $T \in \{1, 3, 5, 10, 15, 20, 30, 40\}$ï¼Œé€‰æ‹©æœ€ä¼˜ $T$ è¿›è¡Œæ¯”è¾ƒã€‚
- **æ•°æ®åˆ†å¸ƒ**ï¼š
  - åŒæ„ï¼ˆHomogeneousï¼‰ï¼šå‡åŒ€åˆ’åˆ†æ•°æ®ã€‚
  - å¼‚æ„ï¼ˆHeterogeneousï¼‰ï¼šæŒ‰ç±»åˆ«åˆ’åˆ†ï¼ˆ70% ç±»ä¸“å± + 30% éšæœºé‡‡æ ·ï¼‰ï¼Œæ¨¡æ‹ŸçœŸå®è”é‚¦åœºæ™¯ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **ä¸»æŒ‡æ ‡**ï¼šä»¥**æ¨¡æ‹Ÿå¢™é’Ÿæ—¶é—´ï¼ˆwall-clock timeï¼‰** è¡¡é‡æ”¶æ•›é€Ÿåº¦ï¼Œåæ˜ å®é™…è®­ç»ƒæ•ˆç‡ã€‚
- **æ¬¡è¦æŒ‡æ ‡**ï¼šè¿­ä»£æ¬¡æ•°ä¸‹çš„æŸå¤±ä¸‹é™ã€æµ‹è¯•å‡†ç¡®ç‡ï¼ˆCIFAR-10ï¼‰ã€æµ‹è¯•å›°æƒ‘åº¦ï¼ˆperplexity, GPT2ï¼‰ã€‚
- **å½’ä¸€åŒ–è¿è¡Œæ—¶é—´**ï¼šä»¥ OLDSGD ä¸ºåŸºå‡†ï¼ˆ=1ï¼‰ï¼Œå…¶ä»–æ–¹æ³•ç›¸å¯¹å…¶æ¯è½®è€—æ—¶ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç®€ç§° | ç‰¹ç‚¹ |
|------|------|------|
| Local DSGD | LDSGD | ç»å…¸å»ä¸­å¿ƒåŒ–å±€éƒ¨æ›´æ–°æ–¹æ³• |
| KGT | KGT | åŸºäº Gradient Tracking çš„å±€éƒ¨æ–¹æ³• |
| LUGT | LUGT | å±€éƒ¨ Gradient Tracking å˜ä½“ |
| LED | LED | å±€éƒ¨ Exact Diffusion æ–¹æ³•ï¼ˆå¸¸å‘æ•£ï¼‰ |
| Local SGD + Ring-AllReduce | LSGD | ä¸­å¿ƒåŒ–é£æ ¼çš„ ring allreduce é€šä¿¡ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 3 & D.3ï¼‰

#### åœ¨åŒæ„æ•°æ®ä¸Šçš„å‡ ä½•å¹³å‡åŠ é€Ÿæ¯”ï¼ˆGeoMean Speedup over OLDSGDï¼‰ï¼š

| Method | $c=1$ | $c=5$ | GeoMean |
|--------|-------|-------|---------|
| **LDSGD** | 1.23Ã— | 1.62Ã— | **1.64Ã—** |
| **KGT** | 1.26Ã— | 1.73Ã— | **1.63Ã—** |
| **LSGD** | 1.34Ã— | 2.18Ã— | **1.98Ã—** |
| **LUGT** | 2.68Ã— | 4.62Ã— | **3.05Ã—** |

> æ³¨ï¼šæ•°å€¼è¶Šå¤§è¡¨ç¤ºè¶Šæ…¢ï¼ŒOLDSGD æœ€å¿«ã€‚

#### åœ¨å¼‚æ„æ•°æ®ä¸Šè¿›ä¸€æ­¥æå‡ï¼ˆGeoMean vs LDSGDï¼‰ï¼š
- åŒæ„ï¼š**1.39Ã—**
- å¼‚æ„ï¼š**1.64Ã—**

è¡¨æ˜ OLDSGD åœ¨æ•°æ®å¼‚æ„åœºæ™¯ä¸‹æ›´å…·é²æ£’æ€§å’Œä¼˜åŠ¿ã€‚

#### GPT2 å¾®è°ƒè¡¨ç°æƒŠäººï¼š
- åœ¨ $c=5$ æ¡ä»¶ä¸‹ï¼ŒOLDSGD ç›¸æ¯” LSGD åŠ é€Ÿè¾¾ **3.32Ã—**
- æµ‹è¯•å›°æƒ‘åº¦æ›²çº¿æ˜¾è‘—ä¼˜äºæ‰€æœ‰ baselineï¼Œä¸”éš $T$ å¢å¤§ä¼˜åŠ¿æ‰©å¤§ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **OLDSGD åœ¨æ‰€æœ‰ä»»åŠ¡ã€æ‰€æœ‰é€šä¿¡å»¶è¿Ÿæ¡ä»¶ä¸‹å‡å–å¾—æœ€å¿«å¢™é’Ÿæ—¶é—´æ”¶æ•›**ã€‚
- å°½ç®¡ KGT å’Œ LUGT ç†è®ºä¸Šæœ‰æ›´å¥½æ”¶æ•›æ€§ï¼Œä½†åœ¨å®è·µä¸­ï¼ˆå°¤å…¶é«˜å»¶è¿Ÿã€å¼‚æ„æ•°æ®ï¼‰æ”¶æ•›ç¼“æ…¢ç”šè‡³å‘æ•£ï¼ˆå¦‚ LED åœ¨å¤šæ•°é…ç½®ä¸‹å‘æ•£ï¼‰ã€‚
- LUGT åœ¨ $T>1$ æ—¶æ€§èƒ½ä¸¥é‡ä¸‹é™ï¼Œæ˜¾ç¤ºå…¶å¯¹å±€éƒ¨æ­¥æ•°æ•æ„Ÿã€‚
- LDSGD ä¸ OLDSGD çš„**è¿­ä»£çº§æ”¶æ•›è¡Œä¸ºå‡ ä¹ä¸€è‡´**ï¼ŒéªŒè¯äº†ç†è®ºåˆ†æä¸­â€œå¹³å‡æ›´æ–°ç›¸åŒâ€çš„ç»“è®ºã€‚

### æ¶ˆèå®éªŒä¸æ‰©å±•åˆ†æï¼ˆAppendixï¼‰
- **å¯æ‰©å±•æ€§æµ‹è¯•**ï¼ˆFigure 4ï¼‰ï¼š
  - åœ¨ ring topology ä¸‹æ”¯æŒæœ€å¤š 32 ä¸ª agentã€‚
  - è¾¾åˆ°è¿‘ä¼¼çº¿æ€§åŠ é€Ÿæ¯”ï¼Œæœ€é«˜è¾¾ **14Ã—ï¼ˆVGG11ï¼‰å’Œ 13Ã—ï¼ˆResNet18ï¼‰**ï¼Œç›´åˆ° 16 ä¸ª agent åå› å›¾è¿é€šæ€§å˜å·®å¢é€Ÿæ”¾ç¼“ã€‚
- **Overlap å¯¹ LED/LUGT çš„å¤±è´¥å°è¯•**ï¼ˆAppendix Bï¼‰ï¼š
  - ç›´æ¥å°† overlapping åº”ç”¨äº LED æˆ– LUGT å¯¼è‡´ä¸¥é‡æ€§èƒ½é€€åŒ–ç”šè‡³æ›´å¿«å‘æ•£ã€‚
  - è¯æ˜ OLDSGD çš„æˆåŠŸå¹¶éé€šç”¨æŠ€å·§ï¼Œè€Œæ˜¯ä¾èµ–å…¶ç‰¹å®šæ›´æ–°ç»“æ„çš„è®¾è®¡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **é€šä¿¡-è®¡ç®—é‡å å¯åœ¨å»ä¸­å¿ƒåŒ–è®­ç»ƒä¸­å®‰å…¨é«˜æ•ˆå®ç°**ï¼šOLDSGD é¦–æ¬¡è¯æ˜ï¼Œåœ¨ä¸ç‰ºç‰²ç†è®ºæ”¶æ•›æ€§çš„å‰æä¸‹ï¼Œå¯é€šè¿‡ CTA + stale models å®Œå…¨è¦†ç›–é€šä¿¡å»¶è¿Ÿã€‚
2. âœ… **å¹³å‡æ›´æ–°ä¸å˜æ€§æ˜¯ç¨³å®šæ€§çš„å…³é”®**ï¼šç”±äºå¹³å‡æ¨¡å‹éµå¾ªæ ‡å‡† SGD åŠ¨æ€ï¼Œé¿å…äº†ä¼ ç»Ÿ overlapping æ–¹æ³•ä¸­çš„åå·®ç´¯ç§¯é—®é¢˜ã€‚
3. âœ… **ç®€å•æœ‰æ•ˆä¼˜äºå¤æ‚æœºåˆ¶**ï¼šç›¸æ¯” Gradient Tracking æˆ– Exact Diffusion ç±»æ–¹æ³•ï¼ŒåŸºäº vanilla SGD çš„ OLDSGD åœ¨å®é™…ç³»ç»Ÿä¸­è¡¨ç°æ›´ç¨³å¥ï¼Œå°¤å…¶åœ¨å¼‚æ„å’Œé«˜å»¶è¿Ÿç¯å¢ƒä¸‹ã€‚
4. âœ… **å¯¹ç°ä»£å¤§æ¨¡å‹å…·æœ‰é‡è¦æ„ä¹‰**ï¼šåœ¨ GPT2 å¾®è°ƒä»»åŠ¡ä¸­å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œè¯´æ˜ OLDSGD ç‰¹åˆ«é€‚åˆ Transformer æ¶æ„ç­‰é€šä¿¡å¯†é›†å‹æ¨¡å‹ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–åŒæ­¥æœºåˆ¶**ï¼šå½“å‰ç‰ˆæœ¬ä»å‡è®¾æ‰€æœ‰ agent åŒæ­¥æ‰§è¡Œï¼Œè‹¥è®¡ç®—/é€šä¿¡é€Ÿåº¦å·®å¼‚è¿‡å¤§ï¼Œä»å¯èƒ½å‡ºç°é˜»å¡ã€‚
- **æ‹“æ‰‘é™åˆ¶å½±å“æ‰©å±•æ€§**ï¼šåœ¨ ring topology ä¸‹è¶…è¿‡ä¸€å®šè§„æ¨¡åï¼Œä¿¡æ¯ä¼ æ’­é€Ÿåº¦æˆä¸ºç“¶é¢ˆï¼Œå½±å“åŠ é€Ÿæ•ˆæœã€‚
- **å°šæœªè€ƒè™‘å¼‚æ­¥é€šä¿¡**ï¼šæœªåƒ Co2 é‚£æ ·å¼•å…¥å®Œå…¨å¼‚æ­¥æ¨¡å¼ï¼Œä»æœ‰è¿›ä¸€æ­¥ä¼˜åŒ–ç©ºé—´ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ **å¼‚æ­¥ OLDSGD** ç‰ˆæœ¬ï¼Œé€‚åº”æ›´çœŸå®çš„è¾¹ç¼˜è®¾å¤‡ç¯å¢ƒã€‚
- å°† OLDSGD æ€æƒ³æ¨å¹¿è‡³å…¶ä»–å»ä¸­å¿ƒåŒ–ç®—æ³•æ¡†æ¶ï¼ˆå¦‚ D-PSGD with momentum, ADMM ç­‰ï¼‰ã€‚
- ç»“åˆè‡ªé€‚åº”å­¦ä¹ ç‡ã€å‹ç¼©é€šä¿¡ç­‰æŠ€æœ¯ï¼Œæ„å»ºæ›´é«˜æ•ˆçš„å®Œæ•´å»ä¸­å¿ƒåŒ–è®­ç»ƒæ ˆã€‚
- åœ¨çœŸå®è¾¹ç¼˜ç½‘ç»œï¼ˆIoTã€ç§»åŠ¨è®¾å¤‡ï¼‰ä¸­éƒ¨ç½²éªŒè¯å…¶ç«¯åˆ°ç«¯æ€§èƒ½ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> OLDSGD é€šè¿‡ç²¾å·§çš„ CTA æ›´æ–°æœºåˆ¶ï¼Œé¦–æ¬¡å®ç°äº†å»ä¸­å¿ƒåŒ–è®­ç»ƒä¸­é€šä¿¡ä¸è®¡ç®—çš„æ— ç¼é‡å ï¼Œåœ¨ä¿æŒ Local DSGD ç†è®ºæ”¶æ•›æ€§çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†å®é™…è®­ç»ƒé€Ÿåº¦ï¼Œå°¤å…¶åœ¨é€šä¿¡å—é™çš„å¤§æ¨¡å‹åœºæ™¯ä¸­è¡¨ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œæ˜¯ä¸€ç§æå…·å®ç”¨ä»·å€¼çš„â€œå³æ’å³ç”¨â€ï¼ˆdrop-in solutionï¼‰ä¼˜åŒ–æ–¹æ¡ˆã€‚

</details>

---

### 6. [Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling](https://arxiv.org/abs/2601.02346)

**Authors**: Falcon LLM Team, Iheb Chaabane, Puneesh Khanna, Suhail Mohmad, Slim Frikha, Shi Hu, Abdalgader Abubaker, Reda Alami, Mikhail Lubinets, Mohamed El Amine Seddik, Hakim Hacid  
**Category**: cs.AI  
**Published**: 2026-01-06  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2601.02346v1  

#### Abstract
This work introduces Falcon-H1R, a 7B-parameter reasoning-optimized model that establishes the feasibility of achieving competitive reasoning performance with small language models (SLMs). Falcon-H1R stands out for its parameter efficiency, consistently matching or outperforming SOTA reasoning model...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šçš„è¿›å±•ä¾èµ–äºå¤§è§„æ¨¡è®­ç»ƒå’Œæ¨ç†è®¡ç®—ï¼Œå¯¼è‡´é«˜æ˜‚çš„èµ„æºæ¶ˆè€—ã€‚å°½ç®¡æ¨¡å‹è§„æ¨¡ä¸æ–­å¢å¤§ï¼Œä½†**çº¯é¢„è®­ç»ƒçš„è¾¹é™…æ•ˆç›Šæ­£åœ¨ä¸‹é™**ï¼Œä¸”é«˜è´¨é‡äººç±»æ ‡æ³¨æ•°æ®æœ‰é™ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨ä¸æ˜¾è‘—å¢åŠ æ¨¡å‹å‚æ•°çš„æƒ…å†µä¸‹ï¼Œæå‡å°è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰çš„æ¨ç†èƒ½åŠ›ï¼Œå¹¶å®ç°é«˜æ•ˆçš„ **Test-Time Scaling (TTS)**ï¼Œæˆä¸ºå…³é”®æŒ‘æˆ˜ã€‚

Falcon-H1R é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œæ¢ç´¢äº†é€šè¿‡**æ¶æ„ä¼˜åŒ–ã€ç²¾ç»†åŒ–æ•°æ®è®­ç»ƒå’Œå¼ºåŒ–å­¦ä¹ ç­–ç•¥**ï¼Œä½¿ä¸€ä¸ªä»… 7B å‚æ•°çš„å°æ¨¡å‹è¾¾åˆ°ç”šè‡³è¶…è¶Šæ›´å¤§æ¨¡å‹ï¼ˆå¦‚ 20Bâ€“32Bï¼‰çš„æ¨ç†æ€§èƒ½ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹

1. **Hybrid Transformer-Mamba æ¶æ„ï¼ˆFalcon-H1ï¼‰**
   - é‡‡ç”¨ **Transformer-SSMï¼ˆState Space Modelï¼‰æ··åˆæ¶æ„**ï¼Œç»“åˆäº† Transformer çš„å¼ºå¤§è¡¨è¾¾èƒ½åŠ›å’Œ Mamba åœ¨é•¿åºåˆ—å¤„ç†ä¸­çš„é«˜æ•ˆæ€§ã€‚
   - è¯¥è®¾è®¡æ˜¾è‘—æå‡äº†æ¨ç†é€Ÿåº¦å’Œå†…å­˜æ•ˆç‡ï¼Œå°¤å…¶é€‚åˆéœ€è¦ç”Ÿæˆå¤§é‡ Chain-of-Thoughtï¼ˆCoTï¼‰è·¯å¾„çš„å¹¶è¡Œæ¨ç†åœºæ™¯ã€‚

2. **ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼šCold-start SFT + GRPO-based RLVR**
   - **Supervised Fine-Tuning (SFT)** é˜¶æ®µï¼š
     - ä½¿ç”¨ç»è¿‡ä¸¥æ ¼è¿‡æ»¤å’ŒåŠ æƒçš„é«˜è´¨é‡å¤šé¢†åŸŸæ•°æ®ï¼ˆæ•°å­¦ã€ä»£ç ã€ç§‘å­¦ç­‰ï¼‰ï¼Œå¼ºè°ƒå›°éš¾æ ·æœ¬ã€‚
     - å¼•å…¥ **rollout multiplicityï¼ˆæ¯é¢˜ç”Ÿæˆå¤šä¸ªè§£æ³•ï¼‰** å’Œ **difficulty-aware weighting** ç­–ç•¥ï¼Œå¢å¼ºæ¨¡å‹å¯¹å¤æ‚é—®é¢˜çš„æ³›åŒ–èƒ½åŠ›ã€‚
   - **Reinforcement Learning with Verifiable Rewards (RLVR)** é˜¶æ®µï¼š
     - åŸºäº **GRPOï¼ˆGroup Relative Policy Optimizationï¼‰** æ¡†æ¶è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œä½¿ç”¨å¯éªŒè¯å¥–åŠ±ä¿¡å·ï¼ˆå¦‚æ•°å­¦ç­”æ¡ˆæ­£ç¡®æ€§ã€ä»£ç æ‰§è¡Œé€šè¿‡ç‡ï¼‰ä¼˜åŒ–æ¨ç†è´¨é‡ã€‚
     - ç§»é™¤ KL æ­£åˆ™é¡¹ä»¥é¼“åŠ±æ¢ç´¢ï¼Œå¼•å…¥æˆªæ–­é‡è¦æ€§é‡‡æ ·ï¼ˆTISï¼‰æé«˜ç¨³å®šæ€§ã€‚

3. **æ”¯æŒé«˜æ•ˆ Test-Time Scalingï¼ˆTTSï¼‰**
   - å°† Falcon-H1R ä¸æœ€æ–°çš„ **DeepConf@512** æ–¹æ³•ç»“åˆï¼ŒåŠ¨æ€å‰ªæä½ç½®ä¿¡åº¦çš„æ¨ç†é“¾ï¼Œåœ¨ä¿è¯é«˜å‡†ç¡®ç‡çš„åŒæ—¶å¤§å¹…å‡å°‘ token å¼€é”€ã€‚
   - å®ç°äº†â€œæ›´å¿«æ¨ç† + æ›´å°‘ token + æ›´é«˜ç²¾åº¦â€çš„ä¸‰ç»´æ•ˆç‡çªç ´ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | Falcon-H1R ä¼˜åŠ¿ |
|------|----------------|
| **å‚æ•°æ•ˆç‡** | ä»… 7B å‚æ•°ï¼Œæ€§èƒ½åª²ç¾ 14Bâ€“32B æ¨¡å‹ï¼ˆå¦‚ Qwen3-32Bã€Phi-4-R-Plus-14Bï¼‰ |
| **æ¨ç†æ•ˆç‡** | æ··åˆæ¶æ„å¸¦æ¥æ›´é«˜çš„ååé‡ï¼Œå°¤å…¶åœ¨å¤§æ‰¹é‡ã€é•¿è¾“å‡ºåœºæ™¯ä¸‹ä¼˜äºçº¯ Transformer æ¨¡å‹ |
| **token æ•ˆç‡** | åœ¨ DeepConf æµ‹è¯•ä¸­ï¼Œç›¸æ¯”åŒç±»æ¨¡å‹å‡å°‘é«˜è¾¾ 38% çš„ token ä½¿ç”¨ |
| **è®­ç»ƒç­–ç•¥** | æ•°æ®è´¨é‡æ§åˆ¶ä¸¥æ ¼ï¼Œå¼•å…¥éš¾åº¦æ„ŸçŸ¥åŠ æƒå’Œå¤š rollout è®­ç»ƒï¼Œé¿å…è¿‡æ‹Ÿåˆç®€å•æ ·æœ¬ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†

#### SFT é˜¶æ®µ
- å¤šé¢†åŸŸé«˜è´¨é‡æ•°æ®ï¼Œæ¶µç›–ï¼š
  - **æ•°å­¦**ï¼šMATHã€AIMEã€AMO-Bench ç­‰ç«èµ›çº§é¢˜ç›®
  - **ä»£ç **ï¼šLeetCodeã€AtCoderã€Codeforces æ¥æºçš„ç¼–ç¨‹é¢˜
  - **ç§‘å­¦**ï¼šç‰©ç†ã€åŒ–å­¦ã€ç”Ÿç‰©ç±»å¤šæ­¥æ¨ç†é—®é¢˜
  - **å…¶ä»–**ï¼šæŒ‡ä»¤éµå¾ªã€å·¥å…·è°ƒç”¨ã€å®‰å…¨å¯¹è¯ç­‰
- æ€»è®¡çº¦ **3.1M æ ·æœ¬**ï¼Œå“åº”é•¿åº¦æœ€é•¿è¾¾ 48K tokensã€‚

#### RL é˜¶æ®µ
- æ•°å­¦ä¸ä»£ç é¢†åŸŸä¸“ç”¨æ•°æ®é›†ï¼Œä¸ SFT å®Œå…¨æ— é‡å ï¼Œé˜²æ­¢è®°å¿†åŒ–ã€‚
- æ•°æ®ç»è¿‡éš¾åº¦ç­›é€‰ï¼šå‰”é™¤å¤ªæ˜“ï¼ˆpass@8=100%ï¼‰å’Œæ— æ³•è§£å†³ï¼ˆpass@8=0% ä¸”å¤šæ•°è¶…é•¿ï¼‰çš„é—®é¢˜ã€‚
- ä½¿ç”¨ **MATH-VERIFY** è¿›è¡Œè¯­ä¹‰çº§ç­”æ¡ˆéªŒè¯ï¼Œ**SANDBOX-FUSION** æ‰§è¡Œä»£ç æµ‹è¯•ã€‚

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### è¯„ä¼°åŸºå‡†åˆ†ç±»
| ç±»åˆ« | åŸºå‡† |
|------|------|
| **æ•°å­¦æ¨ç†** | AIME24, AIME25, HMMT25, AMO-Bench, MATH500 |
| **ä»£ç ç”Ÿæˆ** | LiveCodeBench v6, SciCode, T2-Telecom, Terminal Bench Hard |
| **é€šç”¨æ¨ç†** | GPQA-Diamond, MMLU-Pro, Humanity's Last Exam (HLE), IFBench |

#### è¯„ä¼°æ–¹å¼
- **Pass@1** ä¸ºä¸»è¦æŒ‡æ ‡ï¼Œéƒ¨åˆ†ä»»åŠ¡æŠ¥å‘Šå¹³å‡å€¼ Â± æ ‡å‡†å·®ã€‚
- æ‰€æœ‰æ¨¡å‹ä½¿ç”¨å…¶å®˜æ–¹æ¨èçš„ decoding å‚æ•°ï¼ˆtemperature, top_pï¼‰ã€‚
- å¯¹äº **TTS å®éªŒ**ï¼Œé‡‡ç”¨ **DeepConf@512** è®¾ç½®ï¼š
  - åˆå§‹ç”Ÿæˆ 16 æ¡è·¯å¾„ç¡®å®šç½®ä¿¡é˜ˆå€¼
  - åç»­è·¯å¾„åŸºäºæ»‘åŠ¨çª—å£çš„ group confidence åŠ¨æ€ç»ˆæ­¢
  - æœ€ç»ˆæŠ•ç¥¨ç­–ç•¥åŒ…æ‹¬å¤šæ•°æŠ•ç¥¨ã€ç½®ä¿¡åŠ æƒæŠ•ç¥¨ç­‰

#### åŸºçº¿å¯¹æ¯”æ¨¡å‹
- **7Bâ€“8B çº§åˆ«**ï¼šQwen3-8B, DeepSeek-R1-0528-Qwen3-8B
- **14Bâ€“15B çº§åˆ«**ï¼šPhi-4-Reasoning-Plus-14B, Apriel-1.5-15b-Thinker
- **20Bâ€“32B çº§åˆ«**ï¼šGPT-OSS-20B, Qwen3-32B
- **æœ€å¤§æ¨¡å‹**ï¼šNemotron-H-47B-Reasoning

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### æ•°å­¦æ¨ç†æ€§èƒ½ï¼ˆTable 4ï¼‰
| æ¨¡å‹ | AIME24 | AIME25 | HMMT25 | AMO-Bench | MATH500 |
|------|--------|--------|--------|-----------|---------|
| **Falcon-H1R-7B** | **88.1** | **83.1** | **64.9** | **36.3** | **97.4** |
| GPT-OSS-20B | 83.3 | 84.4 | 64.8 | 26.0 | 94.8 |
| Qwen3-32B | 79.4 | 71.0 | 49.8 | 21.3 | 96.8 |

> âœ… **Falcon-H1R åœ¨å››é¡¹æ•°å­¦ä»»åŠ¡ä¸Šå–å¾— SOTA æˆç»©**ï¼Œå°¤å…¶æ˜¯åœ¨ AMO-Bench ä¸Šé¢†å…ˆç¬¬äºŒåè¶…è¿‡ 10 ä¸ªç™¾åˆ†ç‚¹ã€‚

---

### ä»£ç ç”Ÿæˆæ€§èƒ½ï¼ˆTable 5ï¼‰
| æ¨¡å‹ | LCB v6 | SciCode (sub/main) | T2-Telecom | TB Hard |
|------|--------|--------------------|------------|---------|
| **Falcon-H1R-7B** | **68.6** | 28.3 / 3.9 | 25.4 | 4.9 |
| GPT-OSS-20B | 72.0 | 34.9 / 6.2 | 60.2* | 9.9* |

> ğŸ”¹ åœ¨ LiveCodeBench ä¸Šä»…æ¬¡äº GPT-OSS-20Bï¼Œæ˜¾è‘—ä¼˜äºåŒè§„æ¨¡æ¨¡å‹ï¼›åœ¨ç»ˆç«¯ä»£ç†ä»»åŠ¡ä¸Šä»æœ‰æå‡ç©ºé—´ã€‚

---

### é€šç”¨æ¨ç†æ€§èƒ½ï¼ˆTable 6ï¼‰
| æ¨¡å‹ | GPQA-D | MMLU-Pro | HLE | IFBench |
|------|--------|----------|-----|--------|
| **Falcon-H1R-7B** | 61.3 | 72.1 | **11.1** | **53.4** |
| Phi-4-R-Plus-14B | 67.9 | 79.2 | 5.9 | 51.7 |

> ğŸ”¸ åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ï¼ˆå¦‚ GPQAã€MMLU-Proï¼‰ä¸Šç•¥é€Šäºä¸“ç²¾å¤§æ¨¡å‹ï¼Œä½†åœ¨å‰æ²¿æ¨ç†ï¼ˆHLEï¼‰å’ŒæŒ‡ä»¤è·Ÿéšï¼ˆIFBenchï¼‰ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚

---

### Test-Time Scaling ç»“æœï¼ˆTable 7ï¼‰

| æ¨¡å‹ | AIME25 Accâ†‘ | AIME25 Tokâ†“ | AMO-Bench Accâ†‘ | AMO-Bench Tokâ†“ |
|------|-------------|--------------|----------------|----------------|
| DeepSeek-R1-... | 82.8 | 174.5 | 25.6 | 487.9 |
| **Falcon-H1R-7B** | **96.7** | **95.1** | **35.9** | **216.8** |

> ğŸš€ **åœ¨ DeepConf@512 è®¾ç½®ä¸‹ï¼ŒFalcon-H1R-7B å®ç°æœ€é«˜å‡†ç¡®ç‡ï¼ŒåŒæ—¶ token æ¶ˆè€—é™ä½ 38%**ï¼Œä½“ç°äº†å…¶å¼ºå¤§çš„æ¨ç†ç¨³å®šæ€§å’Œç½®ä¿¡åº¦æ ¡å‡†èƒ½åŠ›ã€‚

---

### æ¶ˆèå®éªŒå…³é”®å‘ç°ï¼ˆSection 2.2 & 3.3ï¼‰

| å®éªŒç»´åº¦ | æœ€ä¼˜é€‰æ‹© | å…³é”®å‘ç° |
|--------|----------|----------|
| **Learning Rate** | 1024Ã—10â»â¶ | è¾ƒå¤§å­¦ä¹ ç‡åŠ é€Ÿæ”¶æ•›ä¸”æå‡ä¸‹æ¸¸æ€§èƒ½ |
| **Rollout Count** | n=12 | æ›´å¤šæ ·åŒ–çš„æ¨ç†è·¯å¾„æ˜¾è‘—æå‡éš¾é¢˜è¡¨ç° |
| **Incorrect Rollouts** | ä»…ä¿ç•™æéš¾é¢˜ | å¯¹å¤§å¤šæ•°é—®é¢˜å¸®åŠ©æœ‰é™ï¼Œå¯èƒ½å¼•å…¥å™ªå£° |
| **Teacher Mixing** | å•æ•™å¸ˆä¼˜äºå¤šæ•™å¸ˆ | ä¸åŒé£æ ¼å†²çªå¯¼è‡´åˆ†å¸ƒåç§» |
| **Data Weighting** | å›°éš¾æ ·æœ¬ Ã—1.75 | æ˜¾è‘—æå‡æ•´ä½“æ¨ç†èƒ½åŠ› |
| **RL Curriculum** | Math-only > Mixed | æ•°å­¦ä¼˜å…ˆè®­ç»ƒå…·æœ‰æ›´å¼ºè¿ç§»èƒ½åŠ› |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å°æ¨¡å‹ä¹Ÿèƒ½å®ç°å¼ºæ¨ç†**  
   Falcon-H1R-7B å‡­å€Ÿç²¾å¿ƒè®¾è®¡çš„è®­ç»ƒæµç¨‹å’Œæ··åˆæ¶æ„ï¼Œåœ¨å¤šé¡¹æ¨ç†ä»»åŠ¡ä¸Šè¶…è¶Š 2Ã— è‡³ 7Ã— æ›´å¤§çš„æ¨¡å‹ï¼Œè¯æ˜äº† **parameter efficiency çš„å¯è¡Œæ€§**ã€‚

2. **æ•°æ®è´¨é‡å’Œè®­ç»ƒç­–ç•¥æ¯”å•çº¯æ‰©å¤§æ¨¡å‹æ›´é‡è¦**  
   ä¸¥æ ¼çš„ **æ•°æ®è¿‡æ»¤ã€éš¾åº¦åŠ æƒã€å¤š rollout è®­ç»ƒ** æ˜¯æ€§èƒ½è·ƒå‡çš„å…³é”®é©±åŠ¨åŠ›ï¼Œè€Œéä¾èµ–æ›´å¤§æ¨¡å‹æˆ–æ›´å¤šå‚æ•°ã€‚

3. **Hybrid Architecture æ˜¾è‘—æå‡ TTS æ•ˆç‡**  
   Falcon-H1 çš„ **Transformer-Mamba æ··åˆç»“æ„** åœ¨é•¿åºåˆ—ã€é«˜å¹¶å‘æ¨ç†ä¸­å±•ç°å‡ºæ˜æ˜¾ä¼˜åŠ¿ï¼Œä¸ºå¤§è§„æ¨¡å¹¶è¡Œ CoT æ¨ç†æä¾›äº†ç†æƒ³åŸºç¡€ã€‚

4. **DeepConf + Falcon-H1R å®ç°æœ€ä¼˜æ€§ä»·æ¯”**  
   åœ¨ç›¸åŒè®¡ç®—é¢„ç®—ä¸‹ï¼ŒFalcon-H1R èƒ½è¿è¡Œæ›´å¤šé«˜è´¨é‡æ¨ç†é“¾ï¼Œå¹¶é€šè¿‡æ—©æœŸåœæ­¢èŠ‚çœå¤§é‡ tokenï¼Œå®ç° **accuracy ä¸ cost çš„å¸•ç´¯æ‰˜å‰æ²¿çªç ´**ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡è¡¨ç°ç›¸å¯¹ä¸€èˆ¬**ï¼šåœ¨ GPQA-Diamond å’Œ MMLU-Pro ä¸Šæœªè¿›å…¥å‰ä¸‰ï¼Œè¡¨æ˜å…¶è®­ç»ƒæ›´åå‘â€œè¿‡ç¨‹æ¨ç†â€è€Œéâ€œäº‹å®æ£€ç´¢â€ã€‚
- **ä¾èµ–é«˜è´¨é‡å¥–åŠ±ä¿¡å·**ï¼šRL é˜¶æ®µä¸¥é‡ä¾èµ–æ•°å­¦/ä»£ç çš„è‡ªåŠ¨éªŒè¯æœºåˆ¶ï¼Œåœ¨å¼€æ”¾åŸŸæˆ–æ¨¡ç³Šä»»åŠ¡ä¸­éš¾ä»¥å¤ç°ã€‚
- **å®‰å…¨æ€§åˆ†ææ˜¾ç¤º CoT ä¸­æ•æ„Ÿå†…å®¹æš´éœ²é£é™©**ï¼šè™½ç„¶æœ€ç»ˆè¾“å‡ºå®‰å…¨ï¼Œä½†æ¨ç†è¿‡ç¨‹ä¸­ä¼šæ·±å…¥æ¢è®¨æœ‰å®³è¯·æ±‚ï¼Œéœ€è°¨æ…éƒ¨ç½²åŸå§‹ CoT è¾“å‡ºã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´å°è§„æ¨¡æ¨¡å‹ï¼ˆå¦‚ 3B æˆ– 1.5Bï¼‰æ˜¯å¦å¯é€šè¿‡ç±»ä¼¼æ–¹æ³•å®ç°é«˜æ•ˆæ¨ç†ã€‚
- è®¾è®¡é€‚ç”¨äºéç»“æ„åŒ–é¢†åŸŸçš„é€šç”¨ verifiable reward å‡½æ•°ã€‚
- è¿›ä¸€æ­¥ä¼˜åŒ– Mamba å—çš„å¹¶è¡Œæ•ˆç‡ï¼Œæ¨åŠ¨ä¸Šä¸‹æ–‡é•¿åº¦è‡³ 1M çº§åˆ«ã€‚
- ç ”ç©¶å¦‚ä½•å°† CoT å®‰å…¨æœºåˆ¶å†…åŒ–ï¼Œé¿å…ä¸­é—´æ¨ç†è¿‡ç¨‹è§¦å‘å®‰å…¨è­¦æŠ¥ã€‚

--- 

> ğŸ’¡ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **Falcon-H1R è¯æ˜äº†â€œå°è€Œç²¾â€çš„æ¨ç†æ¨¡å‹è·¯çº¿æ˜¯å¯è¡Œçš„â€”â€”é€šè¿‡ hybrid æ¶æ„ + é«˜è´¨é‡æ•°æ® + å¼ºåŒ–å­¦ä¹  + TTS ååŒä¼˜åŒ–ï¼Œ7B æ¨¡å‹ä¹Ÿèƒ½åœ¨æ¨ç†èµ›é“è·‘èµ¢ 32B å·¨å¤´ã€‚**

</details>

---

### 7. [KV-Embedding: Training-free Text Embedding via Internal KV Re-routing in Decoder-only LLMs](https://arxiv.org/abs/2601.01046)

**Authors**: Yixuan Tang, Yi Yang  
**Category**: cs.CL  
**Published**: 2026-01-06  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2601.01046v1  

#### Abstract
While LLMs are powerful embedding backbones, their application in training-free settings faces two structural challenges: causal attention restricts early tokens from accessing subsequent context, and the next-token prediction objective biases representations toward generation rather than semantic c...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# KV-Embedding: Training-free Text Embedding via Internal KV Re-routing in Decoder-only LLMs è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹ **decoder-only LLMs** åœ¨ **è®­ç»ƒè‡ªç”±ï¼ˆtraining-freeï¼‰æ–‡æœ¬åµŒå…¥æå–** ä¸­é¢ä¸´çš„ä¸¤ä¸ªç»“æ„æ€§æŒ‘æˆ˜ï¼š
- **å› æœæ³¨æ„åŠ›ï¼ˆcausal attentionï¼‰é™åˆ¶**ï¼šæ—©æœŸ token æ— æ³•è®¿é—®åç»­ä¸Šä¸‹æ–‡ï¼Œå¯¼è‡´ä¿¡æ¯ä¸å¯¹ç§°ã€‚
- **ä¸‹ä¸€è¯é¢„æµ‹ç›®æ ‡ï¼ˆnext-token prediction objectiveï¼‰åå·®**ï¼šæœ€ç»ˆ token çš„è¡¨ç¤ºåå‘äºç”Ÿæˆè€Œéè¯­ä¹‰å‹ç¼©ã€‚

è¿™äº›é—®é¢˜ä½¿å¾—ä¼ ç»Ÿæ± åŒ–ç­–ç•¥ï¼ˆå¦‚ mean pooling æˆ– last-token poolingï¼‰éš¾ä»¥è·å¾—é«˜è´¨é‡çš„è¯­ä¹‰åµŒå…¥ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šKV-Embedding
ä½œè€…æå‡º **KV-Embedding**ï¼Œä¸€ç§æ— éœ€è®­ç»ƒå³å¯ä»å†»ç»“çš„ decoder-only LLMs ä¸­æå–é«˜è´¨é‡æ–‡æœ¬åµŒå…¥çš„æ–¹æ³•ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- åˆ©ç”¨æ¨¡å‹å†…éƒ¨å·²è®¡ç®—çš„å…¨å±€ä¿¡æ¯ï¼šæ¯ä¸ªå±‚ä¸­æœ€åä¸€ä¸ª token çš„ **Key-Value (KV) çŠ¶æ€** ç¼–ç äº†è¯¥å±‚å¯¹æ•´ä¸ªåºåˆ—çš„å‹ç¼©è§†å›¾ã€‚
- é€šè¿‡ **KV Re-routing** æœºåˆ¶ï¼Œå°†è¿™äº› KV çŠ¶æ€ä½œä¸ºâ€œå‰ç¼€â€é‡æ–°æ³¨å…¥åˆ°æ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼Œä½¿æ‰€æœ‰ token éƒ½èƒ½åœ¨å•æ¬¡å‰å‘ä¼ æ’­ä¸­è®¿é—®åºåˆ—çº§ä¸Šä¸‹æ–‡ã€‚

### åˆ›æ–°ç‚¹ä¸ä¼˜åŠ¿
1. **å†…éƒ¨çŠ¶æ€é‡è·¯ç”±ï¼ˆInternal KV Re-routingï¼‰**
   - ä¸ä¿®æ”¹è¾“å…¥ï¼ˆå¦‚ Echo æˆ– Token Prependingï¼‰ï¼Œé¿å…äº†è¾“å…¥é‡å¤å¸¦æ¥çš„äºŒæ¬¡å¤æ‚åº¦æˆ–å¼•å…¥ OOV token çš„é£é™©ã€‚
   - åœ¨ä¸ç ´åå› æœç»“æ„çš„å‰æä¸‹å®ç°å…¨å±€ä¸Šä¸‹æ–‡è®¿é—®ã€‚

2. **åŸºäºå†…åœ¨ç»´åº¦ï¼ˆIntrinsic Dimensionality, IDï¼‰çš„è‡ªåŠ¨åŒ–å±‚é€‰æ‹©**
   - æå‡ºä¸€ç§æ¨¡å‹æ— å…³ï¼ˆmodel-agnosticï¼‰çš„ç­–ç•¥ï¼Œè‡ªåŠ¨è¯†åˆ«æœ€é€‚åˆè¿›è¡Œ KV é‡è·¯ç”±çš„ç½‘ç»œå±‚ã€‚
   - åŸç†ï¼šID æœ€å°å€¼å¯¹åº”è¯­ä¹‰æŠ½è±¡æœ€å¯†é›†çš„å±‚ï¼Œæ­¤æ—¶è¡¨ç¤ºæœ€å…·å‹ç¼©æ€§å’Œè¯­ä¹‰å¯†åº¦ã€‚
   - é¿å…æ‰‹åŠ¨è°ƒå‚ï¼Œé€‚ç”¨äºä¸åŒæ¶æ„ï¼ˆQwen, Mistral, Llamaï¼‰ã€‚

3. **å‹ç¼©å¯¼å‘æç¤ºï¼ˆCompression-Oriented Promptingï¼‰**
   - ä½¿ç”¨æ¨¡æ¿ `"{Context/Query}: {text}\nCompress the {Context/Query} in one word:"` å¼•å¯¼æ¨¡å‹ç”Ÿæˆæ›´å…·è¯­ä¹‰æ¦‚æ‹¬æ€§çš„æœ€ç»ˆ token è¡¨ç¤ºã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | æ˜¯å¦éœ€ä¿®æ”¹è¾“å…¥ | æ˜¯å¦å¼•å…¥é¢å¤–token | åºåˆ—é•¿åº¦å½±å“ | æ€§èƒ½è¡¨ç° |
|------|----------------|--------------------|---------------|-----------|
| **PromptEOL** | æ˜¯ï¼ˆpromptï¼‰ | å¦ | æ—  | ä¸­ç­‰ |
| **Echo** | æ˜¯ï¼ˆé‡å¤è¾“å…¥ï¼‰ | å¦ | åŠ å€ â†’ æ³¨æ„åŠ›å¤æ‚åº¦â†‘ | ä¸­ç­‰ |
| **Token Prepending** | æ˜¯ï¼ˆç‰¹æ®Štokenï¼‰ | æ˜¯ï¼ˆOOVï¼‰ | å¯æ§ä½†ä¸ç¨³å®š | ä¸­ç­‰ |
| **KV-Embedding (æœ¬æ–‡)** | **å¦** | **å¦** | **ä¿æŒåŸé•¿** | **æ˜¾è‘—æ›´ä¼˜** |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **MTEB (Massive Text Embedding Benchmark)**  
  å¤šä»»åŠ¡è¯„ä¼°åŸºå‡†ï¼Œæ¶µç›–7ç±»ä»»åŠ¡ï¼š
  - STSï¼ˆè¯­ä¹‰ç›¸ä¼¼åº¦ï¼‰
  - Retrievalï¼ˆæ£€ç´¢ï¼‰
  - Classificationï¼ˆåˆ†ç±»ï¼‰
  - Pair Classificationï¼ˆæˆå¯¹åˆ†ç±»ï¼‰
  - Clusteringï¼ˆèšç±»ï¼‰
  - Rerankingï¼ˆé‡æ’åºï¼‰
  - Summarizationï¼ˆæ‘˜è¦ï¼‰

- **LoCoV1 (Long-Context Retrieval Benchmark)**  
  ç”¨äºæµ‹è¯•é•¿åºåˆ—ä¸‹çš„é²æ£’æ€§ï¼Œæ–‡æ¡£è¢«æˆªæ–­ä¸º **1024ã€2048 å’Œ 4096 tokens**ã€‚

### æ¨¡å‹
åœ¨ä¸‰ç§ä¸»æµ decoder-only LLM ä¸ŠéªŒè¯æ–¹æ³•é€šç”¨æ€§ï¼š
- **Qwen3-4B**
- **Mistral-7B-Instruct-v0.1**
- **Llama-3.1-8B-Instruct**

æ‰€æœ‰å®éªŒå‡ä¸º **zero-shotã€training-free** è®¾ç½®ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **MTEB**: å„ä»»åŠ¡ä¸»æŒ‡æ ‡å¹³å‡å¾—åˆ†ï¼ˆå¦‚ Spearman ç›¸å…³æ€§ã€NDCG@10ã€Accuracy ç­‰ï¼‰
- **LoCoV1**: NDCG@10ï¼ˆè¡¡é‡é•¿æ–‡æœ¬æ£€ç´¢èƒ½åŠ›ï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿æ–¹æ³• | æè¿° |
|--------|------|
| **Last Token** | ä½¿ç”¨æœ€åä¸€å±‚æœ€åä¸€ä¸ª token çš„éšè—çŠ¶æ€ |
| **Mean Pooling** | å¯¹æœ€åä¸€å±‚æ‰€æœ‰ token è¿›è¡Œå¹³å‡æ± åŒ– |
| **PromptEOL** | ä½¿ç”¨æç¤ºå¼•å¯¼è¯­ä¹‰å‹ç¼© |
| **Echo** | è¾“å…¥é‡å¤ä»¥æ¨¡æ‹ŸåŒå‘æ€§ |
| **Token Prepending** | æ’å…¥ç‰¹æ®Š token å¹¶ä¼ æ’­ä¸Šä¸‹æ–‡ |
| **w/o KV Re-routing** | æ¶ˆèå®éªŒï¼šä¿ç•™æç¤ºä½†ç¦ç”¨ KV é‡è·¯ç”± |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### MTEB ç»“æœï¼ˆTable 1ï¼‰
åœ¨ä¸‰ä¸ª backbone ä¸Šï¼Œ**KV-Embedding æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿**ï¼š

| Model | Best Baseline (Avg.) | KV-Embedding (Avg.) | æå‡å¹…åº¦ |
|-------|------------------------|------------------------|----------|
| Qwen3-4B | 0.4478 (PromptEOL) | **0.4937** | **+4.6 pp** |
| Mistral-7B | 0.5008 (Echo) | **0.5341** | **+3.3 pp** |
| Llama-3.1-8B | 0.5034 (Echo) | **0.5270** | **+2.4 pp** |

> æ³¨ï¼šéƒ¨åˆ†ä»»åŠ¡æå‡é«˜è¾¾ **10% ç»å¯¹å€¼ä»¥ä¸Š**ï¼ˆå¦‚ Retrieval åœ¨ Qwen ä¸Šä» 0.1857 â†’ 0.2765ï¼‰

#### å…³é”®ä»»åŠ¡æå‡åˆ†æ
- **Retrieval**: æå‡æœ€å¤§ï¼Œè¯´æ˜å…¨å±€ä¸Šä¸‹æ–‡å¯¹æ–‡æ¡£åŒ¹é…è‡³å…³é‡è¦ã€‚
- **STS & Clustering**: æ˜¾è‘—æ”¹å–„ï¼Œè¡¨æ˜åµŒå…¥ç©ºé—´æ›´ä¸€è‡´ã€‚
- **Summarization**: æ”¹è¿›è¾ƒå°ï¼Œå„æ–¹æ³•å·®è·ä¸å¤§ã€‚

### LoCoV1 é•¿åºåˆ—æ£€ç´¢ç»“æœï¼ˆTable 2ï¼‰
åœ¨é•¿åºåˆ—ï¼ˆup to 4096 tokensï¼‰ä¸‹ï¼ŒKV-Embedding è¡¨ç°å°¤ä¸ºçªå‡ºï¼š

| Model | æ–¹æ³• | 1024 | 2048 | 4096 |
|-------|------|------|------|------|
| Mistral-7B | PromptEOL | 0.0414 | 0.0407 | 0.0442 |
| | Echo | 0.0627 | 0.0549 | 0.0591 |
| | **KV-Embedding** | **0.2165** | **0.1838** | **0.2068** |

> **KV-Embedding æ€§èƒ½æ˜¯åŸºçº¿çš„ 1.3â€“3.5 å€**ï¼Œä¸”éšé•¿åº¦å¢é•¿ä»ä¿æŒç¨³å®šï¼Œè€ŒåŸºçº¿ä¸¥é‡é€€åŒ–ã€‚

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰æ¶ˆè KV Re-routingï¼ˆw/o KV Re-routingï¼‰
| Model | Full KV-Embedding | w/o KV Re-routing | å·®è· |
|-------|--------------------|---------------------|------|
| Mistral-7B | 0.5341 | 0.4502 | **-8.4 pp** |

> è¯æ˜ **KV Re-routing æ˜¯æ€§èƒ½æå‡çš„ä¸»è¦é©±åŠ¨åŠ›**ï¼Œä»…é æç¤ºä¸è¶³ä»¥è§£å†³ä¿¡æ¯ä¸å¯¹ç§°é—®é¢˜ã€‚

#### ï¼ˆ2ï¼‰æ³¨æ„åŠ›åç½®ï¼ˆAttention Biasï¼‰å®éªŒ
- æ·»åŠ æ ‡é‡åç½® $ b $ æ§åˆ¶å¯¹é‡è·¯ç”±ä½ç½®çš„å…³æ³¨å¼ºåº¦ã€‚
- å®éªŒå‘ç° $ b=1.0 $ æ—¶æ€§èƒ½æœ€ä¼˜ï¼ˆè§ Figure 2ï¼‰ï¼Œè¿‡é«˜ï¼ˆ>3.0ï¼‰ä¼šå¯¼è‡´è¿‡æ‹Ÿåˆå…¨å±€æ‘˜è¦ã€‚

#### ï¼ˆ3ï¼‰å±‚é€‰æ‹©ç­–ç•¥å¯¹æ¯”ï¼ˆAppendix Jï¼‰
| ç­–ç•¥ | Qwen3-4B (Avg.) | Mistral-7B (Avg.) |
|------|------------------|-------------------|
| Early Layers | 0.409 | â€” |
| Middle Third | 0.493 | 0.529 |
| **ID-Based Selection** | **0.494** | **0.534** |

> ID-based æ–¹æ³•ä¸ä»…æ€§èƒ½æ›´é«˜ï¼Œä¸”ä½¿ç”¨çš„å±‚æ•°æ›´å°‘ï¼ˆMistral ä¸Šä»… 7 å±‚ vs 10 å±‚ï¼‰ï¼Œæ•ˆç‡æ›´é«˜ã€‚

#### ï¼ˆ4ï¼‰æ± åŒ–ç­–ç•¥æ¯”è¾ƒï¼ˆAppendix Mï¼‰
| ç­–ç•¥ | æ€§èƒ½è¶‹åŠ¿ |
|------|---------|
| Mean Pooling | æœ€å·®ï¼Œæ˜“å—å™ªå£°å¹²æ‰° |
| Last-Token Pooling | è¾ƒå¥½ä½†å¿½ç•¥åˆ†å¸ƒä¿¡æ¯ |
| **Hybrid Pooling (last + mean)** | **æœ€ä½³**ï¼Œç»“åˆå±€éƒ¨ä¸å…¨å±€ä¿¡æ¯ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **LLMs å†…éƒ¨å·²è•´å«å¼ºå¤§çš„è¯­ä¹‰å‹ç¼©èƒ½åŠ›**  
   æœ€åä¸€ä¸ª token çš„ KV çŠ¶æ€å¤©ç„¶èšåˆäº†åºåˆ—ä¿¡æ¯ï¼Œå¯é€šè¿‡é‡è·¯ç”±æ˜¾å¼åˆ©ç”¨ã€‚

2. **å†…éƒ¨çŠ¶æ€æ“ä½œä¼˜äºè¾“å…¥ä¿®æ”¹**  
   KV Re-routing åœ¨ä¸æ”¹å˜è¾“å…¥çš„æƒ…å†µä¸‹å®ç°äº†å…¨å±€ä¸Šä¸‹æ–‡è®¿é—®ï¼Œé¿å…äº† Echo å’Œ Token Prepending çš„å‰¯ä½œç”¨ã€‚

3. **Intrinsic Dimensionality æ˜¯æœ‰æ•ˆçš„å±‚é€‰æ‹©æŒ‡æ ‡**  
   è‡ªåŠ¨è¯†åˆ«è¯­ä¹‰å‹ç¼©å³°å€¼å±‚ï¼Œå®ç°è·¨æ¨¡å‹æ³›åŒ–ï¼Œæ— éœ€äººå·¥è°ƒå‚ã€‚

4. **KV-Embedding åœ¨é•¿åºåˆ—ä¸Šæå…·ä¼˜åŠ¿**  
   å³ä½¿åœ¨ 4096 tokens ä¸‹ä»ä¿æŒé«˜æ€§èƒ½ï¼Œè§£å†³äº†â€œlost-in-the-middleâ€é—®é¢˜ã€‚

5. **åµŒå…¥ç©ºé—´æ›´å‡åŒ€ï¼ˆisotropicï¼‰**  
   è¡¨ 5 æ˜¾ç¤º KV-Embedding å…·æœ‰æ›´ä½çš„ alignment å’Œæ›´é«˜çš„ uniformityï¼Œè¯´æ˜å…¶åµŒå…¥è´¨é‡æ›´é«˜ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **æ¨ç†å»¶è¿Ÿå¢åŠ **  
   KV Re-routing éœ€è¦åœ¨å¤šä¸ªå±‚æ’å…¥æ“ä½œï¼Œå¸¦æ¥ä¸€å®šè®¡ç®—å¼€é”€ã€‚

2. **æ— æ³•è¶…è¶Šç›‘ç£å¾®è°ƒæ–¹æ³•**  
   è™½ç„¶ä¼˜äº training-free æ–¹æ³•ï¼Œä½†ä»ä¸åŠç»è¿‡ contrastive fine-tuning çš„æ¨¡å‹ï¼ˆå¦‚ E5-Mistralï¼‰ã€‚

3. **ä¾èµ–é«˜è´¨é‡çš„æœ€ç»ˆ token è¡¨ç¤º**  
   å°½ç®¡ä½¿ç”¨æç¤ºç¼“è§£ï¼Œä½† next-token prediction bias ä»æœªå®Œå…¨æ¶ˆé™¤ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ KV Re-routing åœ¨å…¶ä»–ç”Ÿæˆä»»åŠ¡ä¸­çš„åº”ç”¨ï¼ˆå¦‚æ‘˜è¦ã€é—®ç­”ï¼‰ã€‚
- ç»“åˆè½»é‡å¾®è°ƒè¿›ä¸€æ­¥æå‡æ€§èƒ½ï¼ˆå¦‚ prefix-tuning + KV-Embeddingï¼‰ã€‚
- æ‰©å±•è‡³ encoder-decoder æ¶æ„æˆ–å…¶ä»–æ¨¡æ€ï¼ˆå¤šæ¨¡æ€åµŒå…¥ï¼‰ã€‚
- æ›´é«˜æ•ˆçš„ KV ç¼“å­˜ç®¡ç†æœºåˆ¶è®¾è®¡ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **KV-Embedding é€šè¿‡å†…éƒ¨ KV çŠ¶æ€é‡è·¯ç”±ï¼Œåœ¨ä¸ä¿®æ”¹è¾“å…¥ã€æ— éœ€è®­ç»ƒçš„å‰æä¸‹ï¼Œè§£é”äº†å†»ç»“ LLMs çš„å¼ºå¤§åµŒå…¥æ½œåŠ›ï¼Œæˆä¸ºå½“å‰æœ€å…ˆè¿›çš„ training-free æ–‡æœ¬åµŒå…¥æ¡†æ¶ä¹‹ä¸€ã€‚**

</details>

---

### 8. [Performance and Security Aware Distributed Service Placement in Fog Computing](https://arxiv.org/abs/2601.01125)

**Authors**: Mohammad Goudarzi, Arash Shaghaghi, Zhiyu Wang, Rajkumar Buyya  
**Category**: cs.DC  
**Published**: 2026-01-06  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2601.01125v1  

#### Abstract
The rapid proliferation of IoT applications has intensified the demand for efficient and secure service placement in Fog computing. However, heterogeneous resources, dynamic workloads, and diverse security requirements make optimal service placement highly challenging. Most solutions focus primarily...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Performance and Security Aware Distributed Service Placement in Fog Computing*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹ **Fog Computing** ç¯å¢ƒä¸‹çš„æœåŠ¡éƒ¨ç½²ï¼ˆService Placementï¼‰é—®é¢˜ï¼ŒæŒ‡å‡ºå½“å‰å¤§å¤šæ•°ç ”ç©¶ä»…å…³æ³¨æ€§èƒ½æŒ‡æ ‡ï¼ˆå¦‚å“åº”æ—¶é—´ã€å»¶è¿Ÿï¼‰ï¼Œè€Œå¿½è§†äº† **å®‰å…¨åˆè§„æ€§ï¼ˆSecurity Complianceï¼‰** çš„é‡è¦æ€§ã€‚åœ¨å¼€æ”¾ã€å¼‚æ„ä¸”åŠ¨æ€å˜åŒ–çš„è¾¹ç¼˜ç¯å¢ƒä¸­ï¼Œé«˜æ€§èƒ½èŠ‚ç‚¹å¾€å¾€æˆä¸ºæ”»å‡»ç›®æ ‡ï¼Œå› æ­¤éœ€è¦ä¸€ç§èƒ½å¤Ÿ**è”åˆä¼˜åŒ–æ€§èƒ½ä¸å®‰å…¨**çš„æœåŠ¡éƒ¨ç½²æœºåˆ¶ã€‚

æ­¤å¤–ï¼Œä¼ ç»Ÿé›†ä¸­å¼æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰æ–¹æ³•é¢ä¸´å¯æ‰©å±•æ€§å·®ã€æ”¶æ•›æ…¢ã€ç»éªŒåˆ©ç”¨ç‡ä½ç­‰é—®é¢˜ï¼Œéš¾ä»¥é€‚åº”å¤§è§„æ¨¡ã€é«˜åŠ¨æ€çš„ Fog ç³»ç»Ÿã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šSPA-DDRL æ¡†æ¶

ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **Security and Performance-Aware Distributed Deep Reinforcement Learning (SPA-DDRL)** çš„åˆ†å¸ƒå¼æ¡†æ¶ï¼Œç”¨äºè”åˆä¼˜åŒ–æœåŠ¡å“åº”æ—¶é—´å’Œå®‰å…¨åˆè§„æ€§ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

1. **ä¸‰å±‚æ¬¡å®‰å…¨è¯„åˆ†æ¨¡å‹ï¼ˆThree-Tier Security Hierarchyï¼‰**
   - å°†å®‰å…¨èƒ½åŠ›åˆ’åˆ†ä¸ºä¸‰ä¸ªå±‚çº§è¿›è¡Œé‡åŒ–è¯„ä¼°ï¼š
     - **Configuration-Level**ï¼šæ£€æŸ¥å…·ä½“é…ç½®é¡¹æ˜¯å¦å¯ç”¨ï¼ˆå¦‚ AES-256ã€åŒå› ç´ è®¤è¯ç­‰ï¼‰
     - **Capability-Level**ï¼šè¯„ä¼°èµ„æºçš„å®‰å…¨åŠŸèƒ½ï¼ˆå¦‚ä¼ è¾“åŠ å¯†ã€å¯†é’¥ç®¡ç†ï¼‰
     - **Control-Level**ï¼šå¯¹åº”é«˜å±‚å®‰å…¨æ§åˆ¶ç­–ç•¥ï¼ˆå¦‚è®¾å¤‡æˆæƒæ¸…å•ã€æ•°æ®åŠ å¯†ä¿æŠ¤ï¼‰
   - å¼•å…¥ç¡¬çº¦æŸï¼ˆHard Constraintsï¼‰æœºåˆ¶ï¼Œå¯¹å…³é”®å®‰å…¨æ§åˆ¶æœªæ»¡è¶³çš„æƒ…å†µæ–½åŠ ä¸¥é‡æƒ©ç½šï¼Œç¡®ä¿æœ€ç»ˆæ–¹æ¡ˆå§‹ç»ˆæ˜¯å®‰å…¨å¯è¡Œçš„ã€‚

2. **åˆ†å¸ƒå¼ Broker-Learner æ¶æ„**
   - å¤šä¸ª **Broker** åœ¨è¾¹ç¼˜ä¾§å¹¶è¡Œæ‰§è¡Œæœ¬åœ°å†³ç­–ï¼ˆå»ä¸­å¿ƒåŒ–æ¨ç†ï¼‰
   - ä¸€ä¸ªä¸­å¤® **Learner** è´Ÿè´£èšåˆç»éªŒã€æ›´æ–°å…¨å±€ç­–ç•¥ï¼ˆé›†ä¸­å¼è®­ç»ƒï¼‰
   - å®ç°äº†è‰¯å¥½çš„ **å¯æ‰©å±•æ€§ï¼ˆScalabilityï¼‰** å’Œ **é€‚åº”æ€§ï¼ˆAdaptabilityï¼‰**

3. **ä¸‰å¤§å…³é”®æŠ€æœ¯å¢å¼ºå­¦ä¹ æ•ˆç‡ä¸ç¨³å®šæ€§**
   - **LSTM Networks**ï¼šæ•æ‰ä»»åŠ¡ä¾èµ–å’ŒæœåŠ¡ç¯å¢ƒä¸­çš„æ—¶åºä¾èµ–å…³ç³»
   - **Prioritized Experience Replay (PER)**ï¼šä¼˜å…ˆå›æ”¾å…·æœ‰é«˜ TD-error çš„å…³é”®ç»éªŒï¼ŒåŠ é€Ÿæ”¶æ•›
   - **Off-Policy Correction**ï¼šé€šè¿‡é‡è¦æ€§é‡‡æ ·ï¼ˆImportance Samplingï¼‰å’Œæ¢¯åº¦è£å‰ªï¼ˆGradient Clippingï¼‰ç¼“è§£ç­–ç•¥æ»åé—®é¢˜ï¼Œæå‡åˆ†å¸ƒå¼è®­ç»ƒç¨³å®šæ€§

4. **å¤šç›®æ ‡åŠ æƒä¼˜åŒ–å»ºæ¨¡**
   - å°†æœ€å°åŒ–å“åº”æ—¶é—´ä¸æœ€å¤§åŒ–å®‰å…¨å¾—åˆ†ç»Ÿä¸€ä¸ºä¸€ä¸ªåŠ æƒä¼˜åŒ–ç›®æ ‡å‡½æ•°ï¼š
     $$
     \min W(\phi) = \alpha \cdot \text{NORM}_L(L(\phi)) + \beta \cdot \text{NORM}_S(S(\phi))
     $$
   - æ”¯æŒçµæ´»è°ƒæ•´æ€§èƒ½ä¸å®‰å…¨ä¹‹é—´çš„æƒè¡¡ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | SPA-DDRL ä¼˜åŠ¿ |
|------|----------------|
| **å®‰å…¨æ€§ä¿éšœ** | å”¯ä¸€èƒ½æŒç»­ä¿è¯æ‰€æœ‰ç³»ç»Ÿè§„æ¨¡ä¸‹æ»¡è¶³ç¡¬å®‰å…¨çº¦æŸçš„æ–¹æ³•ï¼›å…¶ä»–åŸºçº¿å¸¸å‡ºç°ä¸¥é‡è¿è§„ |
| **æ€§èƒ½è¡¨ç°** | å“åº”æ—¶é—´ç›¸æ¯”æœ€ä¼˜åŸºçº¿é™ä½ **16.3%** |
| **æ”¶æ•›é€Ÿåº¦** | æ¯”ç°æœ‰æ–¹æ³•å¹³å‡å¿« **33%**ï¼Œæ¶ˆèå®éªŒè¯æ˜ç»“åˆ LSTM + PER å¯æé€Ÿè¾¾ **56%** |
| **å¯æ‰©å±•æ€§** | éšæœåŠ¡å™¨æ•°é‡å¢åŠ ä»ä¿æŒç¨³å®šæ€§èƒ½ï¼Œè€ŒåŸºçº¿æ–¹æ³•æ€§èƒ½æ˜¾è‘—ä¸‹é™ |
| **è®­ç»ƒæ•ˆç‡** | ä½¿ç”¨ 8 ä¸ªå·¥ä½œèŠ‚ç‚¹å®ç°çº¦ **2.7Ã— åŠ é€Ÿæ¯”**ï¼Œä¼˜äºåŒç±»åˆ†å¸ƒå¼æ–¹æ³• |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†ä¸å·¥ä½œè´Ÿè½½ç”Ÿæˆ
- **åŸºäºçœŸå® IoT åº”ç”¨æŠ½è±¡å‡ºçš„æœåŠ¡ DAGsï¼ˆDirected Acyclic Graphsï¼‰**
- æ„é€ äº†åŒ…å« **7,500 ä¸ªå¼‚æ„æœåŠ¡å®ä¾‹** çš„ç»¼åˆæ•°æ®é›†
- æœåŠ¡ç‰¹å¾åŒ…æ‹¬ï¼š
  - ä»»åŠ¡æ•° $ K \in \{5,10,20,40,80,100\} $
  - å¹¶è¡Œåº¦ï¼ˆfat å‚æ•°ï¼‰ã€å¯†åº¦ï¼ˆdensity å‚æ•°ï¼‰å¤šæ ·åŒ–
  - å®‰å…¨éœ€æ±‚ä» 15 ç±»åŸºç¡€å®‰å…¨æ§åˆ¶ä¸­éšæœºé€‰å–
  - CPUã€å†…å­˜ã€å­˜å‚¨ã€é€šä¿¡é‡ã€æˆªæ­¢æ—¶é—´ç­‰å±æ€§æŒ‰å®é™…èŒƒå›´è®¾å®š

### å®éªŒå¹³å°è®¾ç½®
- æ¨¡æ‹Ÿä¸‰å±‚æ¶æ„ï¼š**Cloud Servers (CS)**ã€**Fog Servers (FS)**ã€**IoT Devices**
- æ€»å…± 100 ä¸ªæœåŠ¡å™¨èŠ‚ç‚¹ï¼ˆ20 CS + 30 FS + 50 IoTï¼‰
- å„ç±»èŠ‚ç‚¹èµ„æºé…ç½®ç¬¦åˆç°å®å·®å¼‚ï¼ˆå¦‚ CS: 4â€“32 æ ¸, 16â€“128GB RAMï¼›IoT: 1â€“2 æ ¸, 1â€“2GB RAMï¼‰
- ç½‘ç»œå¸¦å®½ï¼šIoT (10â€“50 Mbps), FS (50â€“200 Mbps), CS (100â€“1000 Mbps)

### å®‰å…¨æ¨¡å‹é…ç½®
- 15 ç±»å®‰å…¨æ§åˆ¶ï¼Œæ¯ç±»å« 5 ç§èƒ½åŠ›ï¼Œæ¯ç§èƒ½åŠ›ç”± 3 ä¸ªé…ç½®é¡¹ç»„æˆ
- ä¸åŒç±»å‹èŠ‚ç‚¹å¯ç”¨ä¸åŒå­é›†çš„å®‰å…¨æœºåˆ¶ï¼Œå½¢æˆå¼‚æ„å®‰å…¨æ ¼å±€

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ç±»åˆ« | å…·ä½“æŒ‡æ ‡ |
|---------|----------|
| **æ€§èƒ½** | å“åº”æ—¶é—´ï¼ˆResponse Timeï¼‰ |
| **å®‰å…¨** | å®‰å…¨å¾—åˆ†ï¼ˆSecurity Scoreï¼‰ |
| **ç»¼åˆä¼˜åŒ–æ•ˆæœ** | åŠ æƒæˆæœ¬ï¼ˆWeighted Costï¼‰ |
| **è®­ç»ƒæ•ˆç‡** | æ”¶æ•›è¿­ä»£æ¬¡æ•°ã€Speedupï¼ˆè®­ç»ƒåŠ é€Ÿæ¯”ï¼‰ |
| **è¿è¡Œå¼€é”€** | å†³ç­–æ—¶é—´å¼€é”€ï¼ˆDecision Time Overhead, DTOï¼‰ |
| **å¯æ‰©å±•æ€§** | åœ¨ä¸åŒæœåŠ¡å™¨æ•°é‡ï¼ˆ25â€“100ï¼‰ä¸‹çš„è¡¨ç° |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **X-DDRL**ï¼šåŸºäº IMPALA çš„æ‰©å±•ç‰ˆï¼Œæ”¯æŒå®‰å…¨ä¼˜åŒ–
- **A3C-AHP**ï¼šæ”¹è¿›è‡ªæ–‡çŒ® [20]ï¼Œä½¿ç”¨ A3C æ¡†æ¶
- **DRLIS**ï¼šåŸºäº PPO çš„æ–¹æ³•ï¼Œæ›´æ–°å¥–åŠ±å‡½æ•°ä»¥æ”¯æŒå®‰å…¨
- **PARL**ï¼šåŸºäº DDQN çš„éšç§æ„ŸçŸ¥è´Ÿè½½å‡è¡¡æ–¹æ³•é€‚é…
- **SCRA**ï¼šåŸºäº DQN çš„å®‰å…¨èµ„æºåˆ†é…æ–¹æ³•æ”¹è¿›ç‰ˆ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

| æŒ‡æ ‡ | SPA-DDRL è¡¨ç° | æœ€ä¼˜åŸºçº¿è¡¨ç° | æå‡å¹…åº¦ |
|------|---------------|-------------|----------|
| **å“åº”æ—¶é—´** | ~360 ms | X-DDRL: ~430 ms | **â†“16.3%** |
| **æ”¶æ•›é€Ÿåº¦** | çº¦ç¬¬ 40 è½®æ”¶æ•› | X-DDRL ç¬¬ 60 è½® | **â†‘33% æ›´å¿«** |
| **æœ€å¤§åŠ é€Ÿæ¯”ï¼ˆ8 workerï¼‰** | **2.7Ã—** | X-DDRL: 2.6Ã— | ç•¥ä¼˜ |
| **å†³ç­–æ—¶é—´å¼€é”€ï¼ˆDTOï¼‰** | ~87 ms | å¤šæ•°åŸºçº¿ < 60 ms | â†‘çº¦ 45%ï¼Œä½†å¯æ¥å— |

> æ³¨ï¼šPARL å’Œ SCRA åœ¨å¤šä¸ªåœºæ™¯ä¸‹æœªèƒ½æ”¶æ•›æˆ–æŒç»­è¿åå®‰å…¨çº¦æŸã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### ï¼ˆ1ï¼‰å“åº”æ—¶é—´ vs. æ”¶æ•›æ€§ï¼ˆFigure 4aï¼‰
- SPA-DDRL æ”¶æ•›æœ€å¿«ï¼ˆ~40 iterï¼‰ï¼Œè¾¾åˆ°æœ€ä½å“åº”æ—¶é—´ï¼ˆ~360msï¼‰
- X-DDRL æ¬¡ä¹‹ï¼ˆ~430ms @ 60 iterï¼‰
- A3C-AHP / DRLIS æ˜æ˜¾æ›´æ…¢ä¸”æ›´é«˜ï¼ˆ>950msï¼‰
- PARL / SCRA å‡ ä¹ä¸æ”¶æ•›ï¼Œæ³¢åŠ¨å‰§çƒˆï¼ˆ~1300â€“1350msï¼‰

#### ï¼ˆ2ï¼‰å®‰å…¨å¾—åˆ†ï¼ˆFigure 4bï¼‰
- SPA-DDRLã€X-DDRLã€A3C-AHP å¯è¾¾åˆ°æ¥è¿‘æ»¡åˆ†çš„å®‰å…¨å¾—åˆ†ï¼ˆ~1600ï¼‰
- DRLIS å¾—åˆ†ä¸ºè´Ÿå€¼ï¼ˆ~-2e6ï¼‰ï¼Œè¡¨æ˜å­˜åœ¨ä¸¥é‡å®‰å…¨è¿è§„
- PARL / SCRA æŒç»­å¤„äºæä½åˆ†æ®µï¼ˆ~-4e6 è‡³ -6e6ï¼‰ï¼Œå®Œå…¨ä¸å¯è¡Œ

#### ï¼ˆ3ï¼‰åŠ æƒæˆæœ¬ï¼ˆFigure 4cï¼‰
- SPA-DDRL æˆæœ¬è¶‹è¿‘äºé›¶ï¼Œè¡¨ç¤ºå®ç°äº†æ€§èƒ½ä¸å®‰å…¨çš„å¹³è¡¡
- X-DDRL / A3C-AHP å¯è¡Œä½†æ¬¡ä¼˜
- DRLIS / PARL / SCRA æˆæœ¬æé«˜ï¼Œä¸»è¦æ¥è‡ªå®‰å…¨æƒ©ç½šé¡¹

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

| æ–¹æ³•å˜ä½“ | æ”¶æ•›è½®æ¬¡ | ç›¸å¯¹äº Base çš„æé€Ÿ |
|--------|-----------|------------------|
| SPA-DDRL (Base) â€” æ—  LSTM & PER | ~90 | åŸºå‡† |
| + PER only | ~70 | â†‘22% |
| + LSTM only | ~60 | â†‘33% |
| + LSTM + PERï¼ˆå®Œæ•´ç‰ˆï¼‰ | ~40 | â†‘**56%** |

> ç»“è®ºï¼šLSTM å’Œ PER å‡æ˜¾è‘—æå‡å­¦ä¹ æ•ˆç‡ï¼ŒäºŒè€…ååŒäº§ç”Ÿ**ååŒæ•ˆåº”ï¼ˆsynergistic effectï¼‰**

---

### å¯æ‰©å±•æ€§åˆ†æï¼ˆSystem Scaleï¼‰

éšç€æœåŠ¡å™¨æ•°é‡ä» 25 å¢è‡³ 100ï¼š

- **SPA-DDRL**ï¼šå“åº”æ—¶é—´ç¨³å®šåœ¨ ~300msï¼Œå®‰å…¨å¾—åˆ†å§‹ç»ˆè¾¾æ ‡
- **å…¶ä»–æ–¹æ³•**ï¼š
  - X-DDRLï¼šå“åº”æ—¶é—´ä» <500ms å‡è‡³ >1000ms
  - A3C-AHPï¼šä» 700ms å‡è‡³ 2000ms
  - PARL / SCRAï¼š**æ— æ³•æ‰¾åˆ°ä»»ä½•å¯è¡Œè§£**ï¼ˆæ— æŸ±çŠ¶å›¾æ˜¾ç¤ºï¼‰

> è¡¨æ˜ SPA-DDRL å…·å¤‡å“è¶Šçš„**æ¨ªå‘æ‰©å±•èƒ½åŠ›**ï¼Œè€ŒåŸºçº¿æ–¹æ³•åœ¨å¤æ‚ç¯å¢ƒä¸‹å¤±æ•ˆã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. âœ… **å”¯ä¸€èƒ½åœ¨æ‰€æœ‰ç³»ç»Ÿè§„æ¨¡ä¸‹ç»´æŒå®‰å…¨å¯è¡Œæ€§çš„æ–¹æ³•**  
   SPA-DDRL é€šè¿‡ç¡¬çº¦æŸæƒ©ç½šæœºåˆ¶å’Œç²¾ç»†çš„å®‰å…¨å»ºæ¨¡ï¼Œç¡®ä¿éƒ¨ç½²æ–¹æ¡ˆå§‹ç»ˆæ»¡è¶³å…³é”®å®‰å…¨è¦æ±‚ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•â€œç‰ºç‰²å®‰å…¨æ¢æ€§èƒ½â€çš„æ ¹æœ¬ç¼ºé™·ã€‚

2. âœ… **æ€§èƒ½ä¸å®‰å…¨å¯ååŒä¼˜åŒ–è€Œéå¯¹ç«‹**  
   é€šè¿‡åˆç†çš„å¥–åŠ±è®¾è®¡å’Œä¸‰å±‚æ¬¡å®‰å…¨å»ºæ¨¡ï¼ŒSPA-DDRL å®ç°äº†åŒç›®æ ‡çš„æœ‰æ•ˆå¹³è¡¡ï¼Œé¿å…é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚

3. âœ… **åˆ†å¸ƒå¼ + LSTM + PER æ˜¾è‘—æå‡è®­ç»ƒæ•ˆç‡ä¸ç¨³å®šæ€§**  
   åˆ†å¸ƒå¼æ¶æ„æ”¯æŒå¹¶è¡Œæ¢ç´¢ï¼ŒLSTM æ•æ‰é•¿æœŸä¾èµ–ï¼ŒPER èšç„¦å…³é”®ç»éªŒï¼Œä¸‰è€…ç»“åˆå¤§å¹…åŠ å¿«æ”¶æ•›ã€‚

4. âœ… **å…·å¤‡å¼ºå¯æ‰©å±•æ€§ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡ Fog éƒ¨ç½²**  
   åœ¨æœåŠ¡å™¨æ•°é‡å¢é•¿æ—¶ï¼Œæ€§èƒ½ä¸‹é™è¿œå°äºåŸºçº¿æ–¹æ³•ï¼Œé€‚åˆå®é™…å·¥ä¸šçº§åº”ç”¨ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§

1. **å†³ç­–æ—¶é—´å¼€é”€è¾ƒé«˜ï¼ˆDTO â‰ˆ 87msï¼‰**  
   ç”±äºå¼•å…¥ LSTM å’Œ PER æ’åºé€»è¾‘ï¼Œå•æ¬¡å†³ç­–è€—æ—¶é«˜äºéƒ¨åˆ†è½»é‡çº§åŸºçº¿ï¼Œå¯èƒ½ä¸é€‚åˆæç«¯å®æ—¶åœºæ™¯ã€‚

2. **å®‰å…¨æ¨¡å‹ä¾èµ–é¢„å®šä¹‰è§„åˆ™**  
   å½“å‰ä¸‰å±‚æ¬¡å®‰å…¨ä½“ç³»éœ€äººå·¥å®šä¹‰æ§åˆ¶é¡¹ã€æƒé‡å’Œé˜ˆå€¼ï¼Œç¼ºä¹è‡ªåŠ¨æ¼”åŒ–èƒ½åŠ›ã€‚

3. **ä»¿çœŸç¯å¢ƒå‡è®¾ç†æƒ³é€šä¿¡ä¿¡é“**  
   è™½ç„¶è€ƒè™‘äº†å¸¦å®½å’Œè·ç¦»å»¶è¿Ÿï¼Œä½†æœªæ¨¡æ‹Ÿæ— çº¿å¹²æ‰°ã€é“¾è·¯ä¸­æ–­ç­‰çœŸå®ç½‘ç»œæ‰°åŠ¨ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•è‡³ Federated Learning åœºæ™¯**  
   åœ¨ä¿æŠ¤ç”¨æˆ·æ•°æ®éšç§çš„åŒæ—¶å®ç°å®‰å…¨é«˜æ•ˆçš„è¾¹ç¼˜æœåŠ¡éƒ¨ç½²ã€‚

2. **å¼•å…¥è‡ªé€‚åº”å®‰å…¨è°ƒèŠ‚æœºåˆ¶**  
   åŸºäºå®æ—¶å¨èƒæƒ…æŠ¥åŠ¨æ€è°ƒæ•´å®‰å…¨ç­‰çº§å’Œç­–ç•¥ï¼Œæå‡ç³»ç»Ÿçš„ä¸»åŠ¨é˜²å¾¡èƒ½åŠ›ã€‚

3. **æ”¯æŒå¾®æœåŠ¡ä¸å®¹å™¨åŒ–éƒ¨ç½²ç²’åº¦**  
   å°† SPA-DDRL åº”ç”¨äº Kubernetes-like è¾¹ç¼˜ç¼–æ’ç³»ç»Ÿä¸­ï¼Œè¿›ä¸€æ­¥ç»†åŒ–è°ƒåº¦å•å…ƒã€‚

4. **é›†æˆæ›´å¤šå®‰å…¨æ£€æµ‹æ¨¡å—ï¼ˆå¦‚ IDS è¾“å‡ºï¼‰ä½œä¸ºè¾“å…¥ç‰¹å¾**  
   æå‡å¯¹æœªçŸ¥æ”»å‡»è¡Œä¸ºçš„æ„ŸçŸ¥ä¸å“åº”èƒ½åŠ›ã€‚

--- 

> **æ€»ç»“**ï¼šSPA-DDRL æ˜¯é¦–ä¸ªå°†**ä¸¥æ ¼å®‰å…¨åˆè§„æ€§ä¿éšœ**ä¸**é«˜æ•ˆåˆ†å¸ƒå¼ DRL å†³ç­–**ç›¸ç»“åˆçš„æœåŠ¡éƒ¨ç½²æ¡†æ¶ï¼Œåœ¨æ€§èƒ½ã€å®‰å…¨æ€§ã€å¯æ‰©å±•æ€§å’Œæ”¶æ•›é€Ÿåº¦æ–¹é¢å…¨é¢è¶…è¶Šç°æœ‰æŠ€æœ¯ï¼Œä¸ºæ„å»ºå¯ä¿¡ Fog Computing ç”Ÿæ€æä¾›äº†åšå®åŸºç¡€ã€‚

</details>

---

### 9. [Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission](https://arxiv.org/abs/2601.02253)

**Authors**: Emrah Mete, Emin Erkan Korkmaz  
**Category**: cs.LG  
**Published**: 2026-01-06  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2601.02253v1  

#### Abstract
The rapid proliferation of Deep Learning is increasingly constrained by its heavy reliance on high-performance hardware, particularly Graphics Processing Units (GPUs). These specialized accelerators are not only prohibitively expensive and energy-intensive but also suffer from significant supply sca...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Neuro-Channel Networks: A Multiplication-Free Architecture by Biological Signal Transmission â€”â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ç°ä»£æ·±åº¦å­¦ä¹ ä¸¥é‡ä¾èµ–é«˜ç®—åŠ›ç¡¬ä»¶ï¼ˆå¦‚GPUï¼‰ï¼Œå…¶æ ¸å¿ƒç“¶é¢ˆåœ¨äº**å‰å‘ä¼ æ’­ä¸­å¯†é›†çš„æµ®ç‚¹çŸ©é˜µä¹˜æ³•æ“ä½œ**ï¼Œè¿™äº›æ“ä½œèƒ½è€—é«˜ã€æˆæœ¬å¤§ï¼Œé™åˆ¶äº†AIåœ¨è¾¹ç¼˜è®¾å¤‡ï¼ˆedge devicesï¼‰ä¸Šçš„éƒ¨ç½²ã€‚æ­¤å¤–ï¼Œä¼ ç»Ÿäººå·¥ç¥ç»ç½‘ç»œçš„è®¡ç®—æœºåˆ¶ç¼ºä¹ç”Ÿç‰©å¯è§£é‡Šæ€§ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§å…¨æ–°çš„**å®Œå…¨æ— ä¹˜æ³•ï¼ˆmultiplication-freeï¼‰ç¥ç»ç½‘ç»œæ¶æ„â€”â€”Neuro-Channel Networks (NCN)**ï¼Œå…¶è®¾è®¡çµæ„Ÿæ¥æºäº**ç”Ÿç‰©çªè§¦ä¸­çš„ç¦»å­é€šé“ä¿¡å·ä¼ é€’æœºåˆ¶**ï¼š

- **æƒé‡è¢«æ›¿æ¢ä¸ºâ€œChannel Widthâ€ï¼ˆé€šé“å®½åº¦ï¼‰**ï¼šæ¨¡æ‹Ÿç‰©ç†ç¦»å­é€šé“å¯¹ä¿¡å·å¹…åº¦çš„é™åˆ¶ï¼ˆç±»ä¼¼é™å¹…å™¨ï¼‰ï¼Œé€šè¿‡ `min(|x|, |w|)` å’Œç¬¦å·å‡½æ•° `sgn(x)` æ§åˆ¶ä¿¡å·æµåŠ¨ã€‚
- **å¼•å…¥â€œNeurotransmitterâ€ï¼ˆç¥ç»é€’è´¨ï¼‰å‚æ•°ä½œä¸ºæ—è·¯é—¨æ§æœºåˆ¶**ï¼šå³ä½¿ä¸»é€šé“é¥±å’Œæˆ–å…³é—­ï¼Œä»å¯é€šè¿‡è¯¥è·¯å¾„ç»´æŒæ¢¯åº¦æµåŠ¨ï¼Œé˜²æ­¢â€œæ­»ç¥ç»å…ƒâ€é—®é¢˜ã€‚
- **å‰å‘ä¼ æ’­ä»…ä½¿ç”¨åŠ æ³•ã€å‡æ³•å’Œä½è¿ç®—ï¼ˆbitwise operationsï¼‰**ï¼šå¦‚ `addition`, `subtraction`, `min`, `sign`, `multiplexing`ï¼Œå½»åº•æ¶ˆé™¤æµ®ç‚¹ä¹˜æ³•ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | æ˜¯å¦ä¹˜æ³•è‡ªç”± | ç”Ÿç‰©å¯è§£é‡Šæ€§ | å‡†ç¡®ç‡æŸå¤± | å¤‡æ³¨ |
|------|----------------|----------------|--------------|-------|
| **Binary Neural Networks (BNNs)** | è¿‘ä¼¼å®ç°ï¼ˆç”¨XNORï¼‰ | å¼± | æ˜¾è‘— | æç«¯é‡åŒ–å¯¼è‡´ä¿¡æ¯ä¸¢å¤± |
| **AdderNets** | æ˜¯ï¼ˆç”¨L1è·ç¦»æ›¿ä»£ç‚¹ç§¯ï¼‰ | ä¸­ç­‰ | è¾ƒå° | åŸºäºæ•°å­¦è·ç¦»ï¼Œéç”Ÿç‰©æœºåˆ¶ |
| **Spiking Neural Networks (SNNs)** | æ˜¯ï¼ˆäº‹ä»¶é©±åŠ¨ï¼‰ | é«˜ | è®­ç»ƒå›°éš¾ | æ¢¯åº¦ä¸å¯å¯¼ï¼Œè®­ç»ƒå¤æ‚ |
| **æœ¬æ–‡ NCN** | âœ… å®Œå…¨ä¹˜æ³•è‡ªç”± | âœ… é«˜ï¼ˆç›´æ¥å»ºæ¨¡ç¦»å­é€šé“ä¸ç¥ç»é€’è´¨ï¼‰ | æ— ï¼ˆåœ¨æµ‹è¯•ä»»åŠ¡ä¸Šè¾¾100%ï¼‰ | æ”¯æŒæ ‡å‡†BPè®­ç»ƒ |

> **æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“**ï¼š
> - **ç¡¬ä»¶å‹å¥½**ï¼šé€‚ç”¨äºä½åŠŸè€—CPUã€åµŒå…¥å¼èŠ¯ç‰‡ã€FPGA/ASICè®¾è®¡ï¼›
> - **ç”Ÿç‰©å­¦åˆç†æ€§å¼º**ï¼šæœºåˆ¶è´´è¿‘çœŸå®ç¥ç»å…ƒä¿¡å·ä¼ è¾“ï¼›
> - **ä¿æŒè¡¨è¾¾èƒ½åŠ›**ï¼šèƒ½åœ¨æ— ä¹˜æ³•å‰æä¸‹æ„å»ºéçº¿æ€§å†³ç­–è¾¹ç•Œã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
æœ¬ç ”ç©¶ä¸º**æ¦‚å¿µéªŒè¯ï¼ˆproof-of-conceptï¼‰æ€§è´¨**ï¼Œæœªä½¿ç”¨å¤§è§„æ¨¡å›¾åƒæˆ–æ–‡æœ¬æ•°æ®é›†ï¼Œè€Œæ˜¯é€‰æ‹©äº†ä¸¤ä¸ªç»å…¸çš„**éçº¿æ€§é€»è¾‘å‡½æ•°ä»»åŠ¡**æ¥éªŒè¯æ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›ï¼š

1. **XOR é—®é¢˜**  
   - è¾“å…¥ç»´åº¦ï¼š2ï¼ˆäºŒå…ƒè¾“å…¥ï¼‰
   - è¾“å‡ºï¼šå½“è¾“å…¥ä¸åŒæ—¶è¾“å‡º1ï¼Œç›¸åŒæ—¶è¾“å‡º0
   - ç‰¹ç‚¹ï¼šçº¿æ€§ä¸å¯åˆ†ï¼Œå•å±‚æ„ŸçŸ¥æœºæ— æ³•è§£å†³

2. **3-bit Majority Functionï¼ˆå¤šæ•°å‡½æ•°ï¼‰**  
   - è¾“å…¥ç»´åº¦ï¼š3ï¼ˆä¸‰ä½äºŒè¿›åˆ¶è¾“å…¥ï¼‰
   - è¾“å‡ºï¼šè‹¥è‡³å°‘ä¸¤ä½ä¸º1ï¼Œåˆ™è¾“å‡º1ï¼›å¦åˆ™ä¸º0
   - ç‰¹ç‚¹ï¼šéœ€è¦å¤šè¾“å…¥èšåˆä¸é˜ˆå€¼åˆ¤æ–­

### âš™ï¸ å®éªŒè®¾ç½®
| å‚æ•° | è®¾ç½® |
|------|------|
| **æ¡†æ¶** | è‡ªå®šä¹‰Pythonå®ç° |
| **ç½‘ç»œç»“æ„** | å…¨è¿æ¥NCNå±‚ + Softmaxåˆ†ç±»å¤´ |
| **åˆå§‹åŒ–** | æƒé‡ $ w \sim \mathcal{N}(0,1) $ï¼Œç¥ç»é€’è´¨ $ n \sim \mathcal{N}(0,0.5) $ |
| **ä¼˜åŒ–å™¨** | SGD with Momentumï¼ˆåŠ¨é‡=0.9ï¼‰ |
| **å­¦ä¹ ç‡** | 0.001 |
| **æŸå¤±å‡½æ•°** | Cross-Entropy Loss |
| **è®­ç»ƒç®—æ³•** | æ ‡å‡†Backpropagationï¼ˆåå‘ä¼ æ’­ï¼‰ |

#### ç½‘ç»œæ‹“æ‰‘
- **XORä»»åŠ¡**ï¼š`2 â†’ 4 â†’ 2`ï¼ˆè¾“å…¥2ï¼Œéšè—å±‚4ç¥ç»å…ƒï¼Œè¾“å‡º2ï¼‰
- **Majorityä»»åŠ¡**ï¼š`3 â†’ 8 â†’ 2`ï¼ˆè¾“å…¥3ï¼Œéšè—å±‚8ç¥ç»å…ƒï¼Œè¾“å‡º2ï¼‰

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
- **å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰**ï¼šé¢„æµ‹æ­£ç¡®ç‡ï¼ˆå› æ ·æœ¬ç©ºé—´å°ä¸”å®Œæ•´æšä¸¾ï¼‰
- **å†³ç­–è¾¹ç•Œå¯è§†åŒ–**ï¼šç”¨äºå±•ç¤ºæ¨¡å‹æ˜¯å¦çœŸæ­£å­¦ä¼šéçº¿æ€§åˆ†ç¦»
- **æ”¶æ•›æ€§åˆ†æ**ï¼šè§‚å¯Ÿè®­ç»ƒè¿‡ç¨‹æ˜¯å¦ç¨³å®šæ”¶æ•›

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ–‡ä¸­æœªè¿›è¡Œæ˜¾å¼çš„æ¨ªå‘æ€§èƒ½å¯¹æ¯”å®éªŒï¼ˆå› æ˜¯æ¦‚å¿µéªŒè¯ï¼‰ï¼Œä½†é€šè¿‡ç†è®ºåˆ†ææŒ‡å‡ºç›¸æ¯”ä»¥ä¸‹æ–¹æ³•æ›´å…·ä¼˜åŠ¿ï¼š
- **æ ‡å‡†FFNN**ï¼ˆå«ä¹˜æ³•ï¼‰
- **BNN / XNOR-Net**
- **AdderNet**

å¼ºè°ƒçš„æ˜¯ï¼š**åœ¨å®Œå…¨æ²¡æœ‰ä¹˜æ³•çš„å‰æä¸‹ï¼Œè¾¾åˆ°ä¸ä¼ ç»Ÿæ¨¡å‹ç›¸å½“çš„è¡¨ç°**ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### âœ… å…³é”®æ€§èƒ½æ•°æ®
| ä»»åŠ¡ | æ¨¡å‹ | å‡†ç¡®ç‡ | æ˜¯å¦æ”¶æ•› |
|------|------|--------|----------|
| XOR Problem | NCN | **100%** | æ˜¯ |
| Majority Function (3-bit) | NCN | **100%** | æ˜¯ |

- æ‰€æœ‰ $2^2 = 4$ ç§XORè¾“å…¥ç»„åˆå‡è¢«æ­£ç¡®åˆ†ç±»ï¼›
- æ‰€æœ‰ $2^3 = 8$ ç§Majorityè¾“å…¥ç»„åˆå‡è¢«æ­£ç¡®åˆ†ç±»ã€‚

### ğŸ“ˆ å†³ç­–è¾¹ç•Œå¯è§†åŒ–
- å›¾3æ˜¾ç¤ºNCNæˆåŠŸå­¦ä¹ åˆ°XORçš„éçº¿æ€§å†³ç­–è¾¹ç•Œï¼Œå°† `(0,0)` ä¸ `(1,1)` å½’ä¸ºä¸€ç±»ï¼Œ`(0,1)` ä¸ `(1,0)` å½’ä¸ºå¦ä¸€ç±»ã€‚
- è¡¨æ˜NCNå…·å¤‡å½¢æˆ**å¤æ‚éçº¿æ€§å˜æ¢çš„èƒ½åŠ›**ï¼Œå°½ç®¡å‰å‘ä¼ æ’­ä¸å«ä»»ä½•ä¹˜æ³•æ“ä½œã€‚

### âŒ æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰
è®ºæ–‡ä¸­**æœªæä¾›æ˜ç¡®çš„æ¶ˆèå®éªŒ**ï¼ˆä¾‹å¦‚ç§»é™¤Neurotransmitterè·¯å¾„æˆ–Channel Widthçš„å½±å“ï¼‰ï¼Œä½†åœ¨æ–¹æ³•è®¾è®¡ä¸­æœ‰å¦‚ä¸‹è¯´æ˜ï¼š
- **Neurotransmitterçš„ä½œç”¨**ï¼šé˜²æ­¢â€œdead gradientâ€é—®é¢˜ï¼Œç¡®ä¿å³ä½¿é€šé“å…³é—­ä¹Ÿèƒ½ä¼ é€’æ¢¯åº¦ï¼›
- è‹¥æ— æ­¤æœºåˆ¶ï¼Œåœ¨æŸäº›åˆå§‹åŒ–ä¸‹å¯èƒ½å¯¼è‡´è®­ç»ƒåœæ»ã€‚

> è™½ç„¶æ²¡æœ‰å®šé‡æ¶ˆèï¼Œä½†ä»æœºåˆ¶è®¾è®¡è§’åº¦è®ºè¯äº†ä¸¤ä¸ªç»„ä»¶çš„å¿…è¦æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **æ— éœ€ä¹˜æ³•ä¹Ÿå¯å®ç°éçº¿æ€§å­¦ä¹ **ï¼š  
   NCNé¦–æ¬¡è¯æ˜ï¼Œä»…ä¾é åŠ æ³•ã€æœ€å°å€¼ã€ç¬¦å·ç­‰æ“ä½œå³å¯è®­ç»ƒå‡ºèƒ½è§£å†³éçº¿æ€§å¯åˆ†é—®é¢˜çš„ç½‘ç»œï¼Œæ‰“ç ´äº†â€œå¿…é¡»ä¾èµ–ç‚¹ç§¯/ä¹˜æ³•â€çš„å›ºæœ‰èŒƒå¼ã€‚

2. **ç”Ÿç‰©å¯å‘æœºåˆ¶å…·æœ‰å®é™…è®¡ç®—ä»·å€¼**ï¼š  
   å°†â€œç¦»å­é€šé“é™å¹…â€ä¸â€œç¥ç»é€’è´¨è°ƒèŠ‚â€æŠ½è±¡ä¸ºå¯å­¦ä¹ æ¨¡å—ï¼Œä¸ä»…æå‡äº†ç”Ÿç‰©åˆç†æ€§ï¼Œä¹Ÿå¢å¼ºäº†æ¨¡å‹é²æ£’æ€§å’Œæ¢¯åº¦ç¨³å®šæ€§ã€‚

3. **å‰å‘ä¼ æ’­å®Œå…¨ä¹˜æ³•è‡ªç”±ï¼Œç¡¬ä»¶æ•ˆç‡æé«˜**ï¼š  
   åˆæˆæ“ä½œä¸­æ‰€æœ‰é«˜ç»´ï¼ˆO(d)ï¼‰è®¡ç®—å‡ä¸ºåŠ æ³•/æ¯”è¾ƒ/é€‰æ‹©æ“ä½œï¼Œå”¯ä¸€æ ‡é‡é™¤æ³•ï¼ˆ`/âˆšd`ï¼‰å¯åœ¨ç¡¬ä»¶ä¸­ä»¥ä½ç§»å®ç°ï¼Œé€‚åˆéƒ¨ç½²äºè¶…ä½åŠŸè€—èŠ¯ç‰‡ã€‚

4. **æ”¯æŒæ ‡å‡†Backpropagationè®­ç»ƒ**ï¼š  
   å°½ç®¡å‰å‘æ— ä¹˜æ³•ï¼Œä½†æ¢¯åº¦ä»å¯é€šè¿‡å¸¸è§„é“¾å¼æ³•åˆ™ä¼ æ’­ï¼Œè¡¨æ˜è¯¥æ¶æ„ä¸ä¸»æµè®­ç»ƒæµç¨‹å…¼å®¹ã€‚

### âš ï¸ å±€é™æ€§
1. **å½“å‰ä»…ä¸ºæ¦‚å¿µéªŒè¯**ï¼š  
   å®éªŒä»…åœ¨æå°è§„æ¨¡é€»è¾‘ä»»åŠ¡ä¸Šå®Œæˆï¼Œå°šæœªæ‰©å±•è‡³MNISTã€CIFARç­‰çœŸå®æ•°æ®é›†ã€‚

2. **è®­ç»ƒé˜¶æ®µä»å«ä¹˜æ³•**ï¼š  
   åå‘ä¼ æ’­è¿‡ç¨‹ä¸­æ¶‰åŠæ¢¯åº¦æ›´æ–°æ—¶ä»æœ‰æµ®ç‚¹ä¹˜æ³•ï¼ˆå¦‚å­¦ä¹ ç‡ç¼©æ”¾ï¼‰ï¼Œå°šæœªå®ç°**ç«¯åˆ°ç«¯ä¹˜æ³•è‡ªç”±è®­ç»ƒ**ã€‚

3. **ç¼ºä¹ç³»ç»Ÿæ€§çš„æ€§èƒ½åŸºå‡†å¯¹æ¯”**ï¼š  
   ç¼ºå°‘ä¸BNNã€AdderNetç­‰æ–¹æ³•åœ¨åŒä¸€ä»»åŠ¡ä¸‹çš„ç²¾åº¦ã€å»¶è¿Ÿã€èƒ½è€—å¯¹æ¯”ã€‚

4. **æ¿€æ´»å€¼åŠ¨æ€èŒƒå›´æ§åˆ¶ä¾èµ–æ‰‹åŠ¨å½’ä¸€åŒ–å› å­ï¼ˆâˆšdï¼‰**ï¼š  
   è™½ç„¶æœ‰æ•ˆï¼Œä½†ä»éœ€é¢„è®¾è§„åˆ™ï¼Œä¸å¦‚BatchNormè‡ªé€‚åº”ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
ä½œè€…æ˜ç¡®æå‡ºä¸‰ä¸ªæˆ˜ç•¥æ–¹å‘ï¼š

1. **å®ç°ç«¯åˆ°ç«¯ä¹˜æ³•è‡ªç”±è®­ç»ƒï¼ˆFully Multiplication-Free Trainingï¼‰**  
   æ¢ç´¢ä½¿ç”¨ **SignSGD** æˆ–å…¶ä»–åŸºäºç¬¦å·/åŠ æ³•çš„ä¼˜åŒ–å™¨ï¼Œä½¿è®­ç»ƒè¿‡ç¨‹ä¹Ÿæ‘†è„±ä¹˜æ³•ä¾èµ–ã€‚

2. **æ‹“å±•è‡³æ·±å±‚ç»“æ„ä¸çœŸå®æ•°æ®é›†**  
   åœ¨ **MNISTã€CIFAR-10** ä¸Šæµ‹è¯•NCNçš„å±‚æ¬¡åŒ–ç‰¹å¾æå–èƒ½åŠ›ï¼Œå¹¶æ¢ç´¢å…¶åœ¨ **CNN-like æ¶æ„ä¸­çš„åº”ç”¨æ½œåŠ›**ã€‚

3. **é¢å‘ç¥ç»å½¢æ€ç¡¬ä»¶ååŒè®¾è®¡ï¼ˆNeuromorphic Co-Designï¼‰**  
   å°†NCNé€»è¾‘æ˜ å°„åˆ° **FPGA æˆ– ASIC** ä¸Šï¼Œå®æµ‹æ¨ç†åŠŸè€—ä¸é¢ç§¯å¼€é”€ï¼Œæ¨åŠ¨å…¶åœ¨è¾¹ç¼˜AIèŠ¯ç‰‡ä¸­çš„è½åœ°ã€‚

---

## æ€»ç»“

> **Neuro-Channel Networks (NCN)** æ˜¯ä¸€ç§å—ç”Ÿç‰©çªè§¦å¯å‘çš„æ–°å‹ä¹˜æ³•è‡ªç”±ç¥ç»ç½‘ç»œæ¶æ„ã€‚å®ƒé€šè¿‡å°†æƒé‡è§£é‡Šä¸ºâ€œé€šé“å®½åº¦â€ã€å¼•å…¥â€œç¥ç»é€’è´¨â€æ—è·¯æœºåˆ¶ï¼Œåœ¨å‰å‘ä¼ æ’­ä¸­å®Œå…¨æ¶ˆé™¤æµ®ç‚¹ä¹˜æ³•ï¼Œä»…ä¾èµ–åŠ æ³•ä¸ä½è¿ç®—å³å¯è§£å†³XORå’ŒMajorityç­‰éçº¿æ€§é—®é¢˜ï¼Œå¹¶å–å¾—100%å‡†ç¡®ç‡ã€‚è¯¥å·¥ä½œä¸ºä¸‹ä¸€ä»£é«˜æ•ˆã€ä½åŠŸè€—ã€ç”Ÿç‰©å¯è§£é‡Šçš„AIç¡¬ä»¶æä¾›äº†å…¨æ–°è®¾è®¡èŒƒå¼ï¼Œå…·æœ‰é‡è¦çš„ç†è®ºæ„ä¹‰ä¸å·¥ç¨‹å‰æ™¯ã€‚

</details>

---

### 10. [Heterogeneous Low-Bandwidth Pre-Training of LLMs](https://arxiv.org/abs/2601.02360)

**Authors**: Yazan Obeidi, Amir Sarfi, Joel Lidin, Paul Janson, Eugene Belilovsky  
**Category**: cs.LG  
**Published**: 2026-01-06  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2601.02360v1  

#### Abstract
Pre-training large language models (LLMs) increasingly requires distributed compute, yet bandwidth constraints make it difficult to scale beyond well-provisioned datacenters-especially when model parallelism forces frequent, large inter-device communications. We study whether SparseLoCo, a low-commu...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Heterogeneous Low-Bandwidth Pre-Training of LLMs è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

éšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è§„æ¨¡çš„ä¸æ–­å¢é•¿ï¼Œé¢„è®­ç»ƒè¿‡ç¨‹å¯¹è®¡ç®—èµ„æºçš„éœ€æ±‚æ€¥å‰§ä¸Šå‡ï¼Œå¯¼è‡´è®­ç»ƒé«˜åº¦é›†ä¸­äºå°‘æ•°æ‹¥æœ‰å¤§è§„æ¨¡æ•°æ®ä¸­å¿ƒçš„æœºæ„ã€‚åœ¨è·¨æ•°æ®ä¸­å¿ƒæˆ–ä½å¸¦å®½ç½‘ç»œç¯å¢ƒä¸‹è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒé¢ä¸´ä¸¥é‡é€šä¿¡ç“¶é¢ˆï¼Œå°¤å…¶æ˜¯å½“é‡‡ç”¨æ¨¡å‹å¹¶è¡Œï¼ˆmodel parallelismï¼‰æ—¶ï¼Œé¢‘ç¹çš„æ¿€æ´»å€¼ï¼ˆactivationsï¼‰å’Œæ¢¯åº¦ä¼ è¾“ä¼šæ˜¾è‘—æ‹–æ…¢è®­ç»ƒé€Ÿåº¦ã€‚

æœ¬æ–‡æ—¨åœ¨è§£å†³ä»¥ä¸‹æ ¸å¿ƒæŒ‘æˆ˜ï¼š
- å¦‚ä½•åœ¨**ä½å¸¦å®½ã€å¼‚æ„ç¡¬ä»¶ç¯å¢ƒ**ä¸‹é«˜æ•ˆåœ°è¿›è¡Œ LLM é¢„è®­ç»ƒï¼›
- å¦‚ä½•å°†**æ•°æ®å¹¶è¡Œä¸­çš„ä½é€šä¿¡æ–¹æ³•**ï¼ˆå¦‚ SparseLoCoï¼‰ä¸**æ¨¡å‹å¹¶è¡Œä¸­çš„å‹ç¼©æŠ€æœ¯**ç»“åˆï¼›
- å¦‚ä½•è®©èµ„æºå—é™çš„å‚ä¸è€…ï¼ˆå¦‚æ™®é€šäº’è”ç½‘è¿æ¥èŠ‚ç‚¹ï¼‰ä¹Ÿèƒ½æœ‰æ•ˆå‚ä¸å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **Heterogeneous SparseLoCo** çš„æ–°å‹åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

#### âœ… **å¼‚æ„æ··åˆæ¶æ„ï¼ˆHeterogeneous Training Configurationï¼‰**
- å…è®¸ä¸åŒç±»å‹çš„å‚ä¸è€…å…±åŒå‚ä¸è®­ç»ƒï¼š
  - **é«˜æ€§èƒ½é›†ç¾¤**ï¼ˆå¦‚ InfiniBand è¿æ¥ï¼‰è¿è¡Œå®Œæ•´çš„æ¨¡å‹å‰¯æœ¬ï¼ˆfull replicaï¼‰ï¼Œä¸è¿›è¡Œæ¿€æ´»å‹ç¼©ï¼›
  - **èµ„æºå—é™èŠ‚ç‚¹**ï¼ˆå¦‚é€šè¿‡äº’è”ç½‘è¿æ¥çš„å°å‹è®¾å¤‡ï¼‰ç»„æˆä¸€ä¸ªâ€œé€»è¾‘å‰¯æœ¬â€ï¼ˆlogical replicaï¼‰ï¼Œä½¿ç”¨ **pipeline parallelism + subspace compression** æ¥é™ä½é˜¶æ®µé—´é€šä¿¡å¼€é”€ã€‚

#### âœ… **ç»“åˆ SparseLoCo ä¸ Subspace Pipeline Compression**
- å°† **SparseLoCo**ï¼ˆä¸€ç§åŸºäºç¨€ç–ä¼ªæ¢¯åº¦äº¤æ¢å’Œä½é¢‘åŒæ­¥çš„æ•°æ®å¹¶è¡Œæ–¹æ³•ï¼‰ä¸ **Subspace Networks [10]** ä¸­æå‡ºçš„æ¿€æ´»/æ¢¯åº¦å‹ç¼©æœºåˆ¶ç›¸ç»“åˆã€‚
- åœ¨ pipeline stages ä¹‹é—´ä»…ä¼ è¾“æŠ•å½±åˆ°ä½ç»´å­ç©ºé—´ï¼ˆsubspaceï¼‰çš„æ¿€æ´»å’Œæ¢¯åº¦ï¼Œå¤§å¹…å‡å°‘é€šä¿¡é‡ã€‚

#### âœ… **Selective Compressionï¼ˆé€‰æ‹©æ€§å‹ç¼©ï¼‰**
- å¹¶éæ‰€æœ‰ replica éƒ½å¯ç”¨å‹ç¼©ï¼Œè€Œæ˜¯æ ¹æ®äº’è”å¸¦å®½å†³å®šæ˜¯å¦å‹ç¼©ï¼š
  - é«˜å¸¦å®½é“¾è·¯ â†’ ä¸å‹ç¼©ï¼ˆä¿ç•™ç²¾åº¦ï¼‰
  - ä½å¸¦å®½é“¾è·¯ â†’ å¯ç”¨å‹ç¼©ï¼ˆæå‡ååï¼‰

è¿™ä¸€ç­–ç•¥å®ç°äº†â€œ**åœ¨å“ªå‹ç¼©ï¼Œåœ¨å“ªä¸å‹ç¼©â€çš„æ™ºèƒ½å†³ç­–**ï¼Œå…¼é¡¾æ•ˆç‡ä¸æ€§èƒ½ã€‚

#### âœ… **æ”¹è¿› Token Embedding å¤„ç†æœºåˆ¶**
- åœ¨å¼‚æ„è®¾ç½®ä¸­ï¼Œéƒ¨åˆ† replica ä½¿ç”¨å‹ç¼©ã€éƒ¨åˆ†æœªä½¿ç”¨ï¼Œå¯èƒ½å¯¼è‡´ embedding buffer åç¦»å­ç©ºé—´ã€‚
- æå‡ºä¸€ç§æ–°çš„ embedding ç»´æŠ¤æœºåˆ¶ï¼šæ¯æ¬¡å…¨å±€åŒæ­¥åå°† `Ts` æŠ•å½±å›å­ç©ºé—´ï¼Œå¹¶å°†æ®‹å·®ç´¯ç§¯åˆ° `T_`ï¼Œç¡®ä¿ä¸€è‡´æ€§ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **é€šä¿¡æ•ˆç‡** | ç»“åˆäº† SparseLoCoï¼ˆå‡å°‘åŒæ­¥é¢‘ç‡ + æ¢¯åº¦ç¨€ç–åŒ–ï¼‰å’Œ Subspace Compressionï¼ˆå‡å°‘ stage é—´é€šä¿¡ï¼‰ï¼Œå®ç°åŒé‡é™å¸¦å®½ |
| **é€‚ç”¨åœºæ™¯æ‰©å±•** | æ”¯æŒè·¨æ•°æ®ä¸­å¿ƒã€äº’è”ç½‘çº§ä½å¸¦å®½ç¯å¢ƒä¸‹çš„è®­ç»ƒï¼Œæ‰“ç ´ä¼ ç»Ÿä¾èµ–é«˜å¸¦å®½é›†ç¾¤çš„é™åˆ¶ |
| **æ€§èƒ½ä¿æŒæ›´å¥½** | å¼‚æ„å‹ç¼©ç­–ç•¥æ˜¾è‘—ä¼˜äºç»Ÿä¸€å‹ç¼©ï¼ˆuniform compressionï¼‰ï¼Œå°¤å…¶åœ¨é«˜å‹ç¼©æ¯”ä¸‹è¡¨ç°æ›´ä¼˜ |
| **çµæ´»æ€§å¼º** | å¯çµæ´»é…ç½®å“ªäº› replica å‹ç¼©ã€å“ªäº›ä¸å‹ç¼©ï¼Œé€‚åº”çœŸå®ä¸–ç•Œå¼‚æ„åŸºç¡€è®¾æ–½ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **DCLM**: å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­æ–™åº“ï¼Œç”¨äºä¸»å®éªŒã€‚
- **C4**: ç»å…¸æ–‡æœ¬é¢„è®­ç»ƒæ•°æ®é›†ï¼Œç”¨äºéªŒè¯æ³›åŒ–èƒ½åŠ›ã€‚

---

### **å®éªŒè®¾ç½®**

#### âœ… **æ¨¡å‹æ¶æ„**
- ä½¿ç”¨ decoder-only Transformer æ¶æ„ï¼ˆç±»ä¼¼ LLaMAï¼‰ï¼š
  - å‚æ•°è§„æ¨¡ï¼š178Mã€512M å’Œ 1B
  - å±‚æ•°ï¼š9~16 å±‚
  - Hidden dimension: 1024â€“2048
  - ä½¿ç”¨ SwiGLU æ¿€æ´»å‡½æ•°

#### âœ… **å¹¶è¡Œç­–ç•¥**
- æ•°æ®å¹¶è¡Œï¼šM = 8 replicasï¼ˆ178M/512Mï¼‰ï¼ŒM=2ï¼ˆ1Bï¼‰
- ç®¡é“å¹¶è¡Œï¼šS = 4 stages
- å†…éƒ¨å¯å åŠ  tensor parallelism æˆ– sharding

#### âœ… **SparseLoCo è®¾ç½®**
- Inner steps: H = 50
- Outer optimizer: SGDï¼ˆæ— åŠ¨é‡ï¼‰
- Inner optimizer: AdamW
- Gradient compression: TOP-kï¼ˆæ¯ chunk ä¿ç•™ top 32 out of 4096ï¼Œå¯†åº¦ ~0.78%ï¼‰
- Error feedback: Î² = 0.95

#### âœ… **Subspace Compression è®¾ç½®**
- å­ç©ºé—´ç»´åº¦ k æ§åˆ¶å‹ç¼©ç‡ï¼ˆk/d_modelï¼‰
- å‹ç¼©ç‡èŒƒå›´ï¼š87.5% åˆ° 99.9%
- æŠ•å½±çŸ©é˜µ U åˆå§‹åŒ–ä¸ºéšæœºæ­£äº¤çŸ©é˜µï¼ˆQR åˆ†è§£ï¼‰

---

### **è¯„ä¼°æŒ‡æ ‡**

| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Validation Loss** | ä¸»è¦æ€§èƒ½æŒ‡æ ‡ï¼Œè¡¡é‡æ¨¡å‹æ‹Ÿåˆèƒ½åŠ› |
| **Perplexity** | è¡ç”ŸæŒ‡æ ‡ï¼Œè¶Šä½è¶Šå¥½ |
| **Relative Degradation (%)** | å‹ç¼©æ–¹æ³•ç›¸å¯¹äº baseline çš„æŸå¤±å¢åŠ ç™¾åˆ†æ¯” |
| **Compute Utilization** | åœ¨ç»™å®šå¸¦å®½ä¸‹ GPU åˆ©ç”¨ç‡ï¼Œåæ˜ å®é™…è®­ç»ƒæ•ˆç‡ |
| **Wall-clock Time Simulation** | æ¨¡æ‹Ÿä¸åŒå¸¦å®½ä¸‹çš„è®­ç»ƒæ—¶é—´åŠ é€Ÿæ•ˆæœ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| æ–¹æ³• | æè¿° |
|------|------|
| **SparseLoCo (Baseline)** | ä¸å¯ç”¨ä»»ä½• activation compressionï¼Œæ ‡å‡† SparseLoCo è®¾ç½® |
| **SparseLoCo + PP-Compress** | æ‰€æœ‰ replica å‡å¯ç”¨ pipeline compressionï¼ˆuniformï¼‰ |
| **SparseLoCo + Het-PP-Compress (1/2)** | åŠæ•° replica å¯ç”¨å‹ç¼©ï¼ŒåŠæ•°ä¸å¯ç”¨ï¼ˆheterogeneousï¼‰ |
| **AdamW + PP-Compress / Heterogeneous** | å¯¹æ¯”æ ‡å‡† AdamW åœºæ™¯ä¸‹çš„è¡¨ç°ï¼ŒéªŒè¯ SparseLoCo ç‰¹å¼‚æ€§ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»**

#### ğŸ”¹ Table 1 & 2: 512M æ¨¡å‹åœ¨ DCLM ä¸Šçš„è¡¨ç°ï¼ˆH=50, 10B tokensï¼‰

| Configuration | Compression | Loss | Î”(%) | Perplexity |
|---------------|-------------|------|-------|------------|
| SparseLoCo (Baseline) | 0% | 2.73 | â€” | 15.40 |
| + PP-Compress (Uniform) | 87.5% | 2.84 | +3.8% | 17.10 |
| + Het-PP-Compress (1/2) | 87.5% | **2.82** | **+3.3%** | **16.90** |
| + PP-Compress (Uniform) | 99.9% | 3.07 | +12.4% | â€” |
| + Het-PP-Compress (1/2) | 99.9% | **3.00** | **+9.8%** | â€” |

> ğŸ“Œ **ç»“è®º**ï¼šå¼‚æ„å‹ç¼©å§‹ç»ˆä¼˜äºç»Ÿä¸€å‹ç¼©ï¼Œä¸”ä¼˜åŠ¿éšå‹ç¼©ç‡å‡é«˜è€Œæ‰©å¤§ã€‚

#### ğŸ”¹ Table 3a: æ‰©å±• token budget è‡³ 12Bï¼ˆ+20%ï¼‰

| Configuration | Token Budget | Loss |
|----------------|--------------|------|
| Baseline | 10B | 2.73 |
| + PP-Compress | 12B | 2.78 |
| + Het-PP-Compress (1/2) | 12B | **2.75** |

> âœ… é€šè¿‡å¢åŠ è®­ç»ƒæ­¥æ•°ï¼Œå¼‚æ„å‹ç¼©å¯åœ¨ç›¸åŒ wall-clock æ—¶é—´å†…æ¥è¿‘ç”šè‡³é€¼è¿‘ baseline æ€§èƒ½ã€‚

#### ğŸ”¹ Figure 2: è®¡ç®—åˆ©ç”¨ç‡ vs å¸¦å®½ï¼ˆæ¨¡æ‹Ÿ 70B æ¨¡å‹ï¼‰

- å½“ inter-stage bandwidth < 1 Gbps æ—¶ï¼š
  - SparseLoCoï¼ˆæ— å‹ç¼©ï¼‰compute utilization â‰ˆ 0%
  - SparseLoCo + PP-Compressï¼ˆ87.5%ï¼‰â†’ >97% åˆ©ç”¨ç‡
- è¡¨æ˜ï¼š**å‹ç¼©ä½¿åŸæœ¬ä¸å¯è¡Œçš„ä½å¸¦å®½è®­ç»ƒå˜å¾—é«˜æ•ˆå¯è¡Œ**

#### ğŸ”¹ Table 7: åœ¨ C4 æ•°æ®é›†ä¸Šçš„æ³›åŒ–ç»“æœï¼ˆ512M, 10B tokensï¼‰

| Configuration | Loss | Î”(%) |
|----------------|------|-------|
| Baseline | 2.67 | â€” |
| PP-Compress | 2.77 | 3.71% |
| Het-PP-Compress | **2.76** | **3.32%** |

> âœ… æ–¹æ³•åœ¨ä¸åŒé¢„è®­ç»ƒè¯­æ–™ä¸Šå…·æœ‰ä¸€è‡´æ€§å’Œæ³›åŒ–æ€§ã€‚

#### ğŸ”¹ Table 6: æ‰©å±•è‡³ 1B å‚æ•°æ¨¡å‹

| Configuration | Compression | Loss |
|----------------|-------------|------|
| Baseline | 0% | 2.747 |
| PP-Compress | 87.5% | 2.910 |

> âœ… å‹ç¼©æœ‰æ•ˆæ€§åœ¨æ›´å¤§æ¨¡å‹ä¸Šä¾ç„¶æˆç«‹ï¼Œæ€§èƒ½é€€åŒ–è¶‹åŠ¿ä¸€è‡´ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰**

| ä¿®æ”¹é¡¹ | æ˜¯å¦æœ‰ç›Š | è§‚å¯Ÿç»“æœ |
|--------|----------|---------|
| **Token Embedding Adaptation** | âœ… æ˜¾è‘—æ”¹å–„ | Loss ä» 2.89 â†’ 2.82ï¼ˆÎ”â†“2.5ppï¼‰ |
| **Weight Projection** | âŒ æœ‰å®³ | å¼•å…¥é¢å¤–è¯¯å·®ï¼Œåº”ç§»é™¤ |
| **Grassmann Subspace Update** | âŒ æ— ç›Š | å›ºå®šéšæœº subspace è¶³å¤Ÿæœ‰æ•ˆ |
| **Modified AdamW** | âŒ æ— ç›Š | åŸå§‹ AdamW å³å¯ |

> ğŸ“Œ **è®¾è®¡ç®€åŒ–å»ºè®®**ï¼šåªéœ€ token embedding adaptation + å›ºå®š subspace å³å¯è·å¾—æœ€ä½³æ€§ä»·æ¯”ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **SparseLoCo å¯æˆåŠŸä¸ pipeline compression ç»“åˆ**  
   åœ¨é€‚åº¦æ€§èƒ½æŸå¤±ä¸‹å®ç°æä½é€šä¿¡å¼€é”€ï¼Œé€‚ç”¨äºè·¨æ•°æ®ä¸­å¿ƒè®­ç»ƒã€‚

2. âœ… **å¼‚æ„å‹ç¼©ï¼ˆHeterogeneous Compressionï¼‰æ˜¾è‘—ä¼˜äºç»Ÿä¸€å‹ç¼©**  
   - å°¤å…¶åœ¨é«˜å‹ç¼©æ¯”ï¼ˆ>99%ï¼‰æ—¶ä¼˜åŠ¿æ˜æ˜¾ï¼›
   - åŸå› ï¼šæœªå‹ç¼© replica æä¾›â€œé”šç‚¹â€ï¼Œç¼“è§£å‹ç¼©å¼•å…¥çš„ç³»ç»Ÿåå·®ï¼ˆbiasï¼‰ç§¯ç´¯ã€‚

3. âœ… **è¯¥ä¼˜åŠ¿ä¾èµ–äº SparseLoCo çš„å±€éƒ¨ä¼˜åŒ–ç»“æ„**  
   - åœ¨æ ‡å‡† AdamWï¼ˆH=1ï¼‰ä¸­ï¼Œé¢‘ç¹åŒæ­¥æŠ‘åˆ¶äº†åå·®ç§¯ç´¯ï¼Œå¼‚æ„åè€Œç•¥å·®ï¼ˆè§ Table 3ï¼‰ï¼›
   - è¡¨æ˜ï¼š**åªæœ‰åœ¨ä½é¢‘åŒæ­¥ + å±€éƒ¨ä¼˜åŒ–åœºæ™¯ä¸‹ï¼Œå¼‚æ„å‹ç¼©æ‰æœ‰ä»·å€¼**ã€‚

4. âœ… **æ›´é«˜çš„å‹ç¼©ç‡å¯é€šè¿‡å»¶é•¿è®­ç»ƒè¡¥å¿æ€§èƒ½æŸå¤±**  
   - å¢åŠ  20% token budget åï¼ŒHet-PP-Compress æ¥è¿‘ baselineï¼›
   - å®é™…æ„ä¹‰ï¼š**ç”¨æ›´å¤š compute æ¢æ›´ä½ bandwidth éœ€æ±‚æ˜¯å¯è¡Œè·¯å¾„**ã€‚

5. âœ… **æ–¹æ³•å…·å¤‡è‰¯å¥½æ‰©å±•æ€§**  
   - åœ¨ 178Mâ€“1B å‚æ•°èŒƒå›´å†…å‡æœ‰æ•ˆï¼›
   - åœ¨ DCLM å’Œ C4 ä¸¤ä¸ªæ•°æ®é›†ä¸Šè¶‹åŠ¿ä¸€è‡´ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

| å±€é™ | è¯´æ˜ |
|------|------|
| **ä¾èµ– careful initialization & projection** | Token embedding å¤„ç†éœ€ç‰¹æ®Šç»´æŠ¤æœºåˆ¶ï¼Œå¦åˆ™ä¼šç ´åå­ç©ºé—´å‡è®¾ |
| **æé«˜å‹ç¼©æ¯”ä»æœ‰æ˜æ˜¾æ€§èƒ½ä¸‹é™** | å¦‚ k/d=1/768ï¼ˆ99.7%ï¼‰æ—¶ loss â†‘11.3%ï¼Œéœ€æƒè¡¡å¯ç”¨æ€§ |
| **ç›®å‰ä¸º simulation-based study** | å®é™…éƒ¨ç½²åœ¨ç½‘ç»œå»¶è¿Ÿã€ä¸¢åŒ…ç­‰å¤æ‚å› ç´ ä¸‹å¯èƒ½è¡¨ç°ä¸åŒ |
| **æœªè€ƒè™‘ fault tolerance æˆ–åŠ¨æ€åŠ å…¥/é€€å‡º** | å®é™…å»ä¸­å¿ƒåŒ–è®­ç»ƒéœ€æ›´å¼ºé²æ£’æ€§æ”¯æŒ |

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ”¯æŒåŠ¨æ€ participant åŠ å…¥/é€€å‡ºæœºåˆ¶**  
   å®ç°çœŸæ­£å»ä¸­å¿ƒåŒ–çš„è”é‚¦å¼ LLM é¢„è®­ç»ƒã€‚

2. **æ¢ç´¢ adaptive compression ratio selection**  
   æ ¹æ®å®æ—¶å¸¦å®½è‡ªåŠ¨è°ƒæ•´ k/dï¼Œæœ€å¤§åŒ– compute utilizationã€‚

3. **ç»“åˆå…¶ä»–é€šä¿¡å‹ç¼©æŠ€æœ¯**  
   å¦‚é‡åŒ–ï¼ˆquantizationï¼‰ã€é‡å é€šä¿¡ï¼ˆoverlap communicationï¼‰è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚

4. **åœ¨çœŸå®å¹¿åŸŸç½‘ç¯å¢ƒä¸­éƒ¨ç½²éªŒè¯**  
   æµ‹è¯•è·¨æ´²é™…ã€è·¨äº‘æœåŠ¡å•†çš„å®é™…æ€§èƒ½ã€‚

5. **ç ”ç©¶æ›´é²æ£’çš„ subspace alignment æ–¹æ³•**  
   å‡å°‘å¯¹ projection consistency çš„æ•æ„Ÿæ€§ã€‚

---

## æ€»ç»“

> **Heterogeneous SparseLoCo æä¾›äº†ä¸€æ¡é€šå¾€â€œå…¨æ°‘å¯å‚ä¸ LLM é¢„è®­ç»ƒâ€çš„å®ç”¨è·¯å¾„**ï¼šå®ƒå…è®¸é«˜æ€§èƒ½é›†ç¾¤ä¸æ™®é€šäº’è”ç½‘èŠ‚ç‚¹ååŒå·¥ä½œï¼Œåœ¨ä¿è¯åˆç†æ€§èƒ½çš„å‰æä¸‹æå¤§é™ä½äº†é€šä¿¡éœ€æ±‚ã€‚å…¶æ ¸å¿ƒæ´è§â€”â€”â€œ**åªåœ¨éœ€è¦çš„åœ°æ–¹å‹ç¼©**â€â€”â€”ä¸ºæœªæ¥æ„å»ºå¼€æ”¾ã€å»ä¸­å¿ƒåŒ–çš„å¤§æ¨¡å‹è®­ç»ƒç”Ÿæ€æä¾›äº†å…³é”®æŠ€æœ¯æ”¯æ’‘ã€‚

</details>

---

### 11. [CD4LM: Consistency Distillation and aDaptive Decoding for Diffusion Language Models](https://arxiv.org/abs/2601.02236)

**Authors**: Yihao Liang, Ze Wang, Hao Chen, Ximeng Sun, Jialian Wu, Xiaodong Yu, Jiang Liu, Emad Barsoum, Zicheng Liu, Niraj K. Jha  
**Category**: cs.CL  
**Published**: 2026-01-06  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2601.02236v1  

#### Abstract
Autoregressive large language models achieve strong results on many benchmarks, but decoding remains fundamentally latency-limited by sequential dependence on previously generated tokens. Diffusion language models (DLMs) promise parallel generation but suffer from a fundamental static-to-dynamic mis...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# CDLM: Consistency Distillation and aDaptive Decoding for Diffusion Language Models è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„ **Diffusion Language Models (DLMs)** åœ¨è®­ç»ƒå’Œæ¨ç†ä¹‹é—´å­˜åœ¨**é™æ€åˆ°åŠ¨æ€çš„é”™ä½ï¼ˆstatic-to-dynamic misalignmentï¼‰**ï¼š
- **è®­ç»ƒé˜¶æ®µ**ï¼šæ¨¡å‹åœ¨å›ºå®šå™ªå£°è°ƒåº¦ä¸‹ä¼˜åŒ–å±€éƒ¨å»å™ªæ­¥éª¤ï¼ˆå¦‚ $t \to t-\Delta t$ï¼‰ï¼Œå­¦ä¹ çš„æ˜¯ä¸€ä¸ªâ€œé™æ€â€çš„å‘é‡åœºã€‚
- **æ¨ç†é˜¶æ®µ**ï¼šä¸ºäº†å®ç°ä½ **NFEï¼ˆNumber of Function Evaluationsï¼‰** çš„é«˜æ•ˆç”Ÿæˆï¼Œéœ€è¦è¿›è¡Œâ€œé•¿è·³â€ï¼ˆlong-jumpï¼‰å¼çš„å»å™ªï¼ˆå¦‚ $t \to t-k\Delta t$ï¼‰ï¼Œç©¿è¶Šè®­ç»ƒä¸­æœªè§è¿‡çš„çŠ¶æ€ç©ºé—´ã€‚

æ­¤å¤–ï¼Œç°æœ‰è§£ç ç­–ç•¥ç¼ºä¹**è®¡ç®—èµ„æºçš„è‡ªé€‚åº”åˆ†é…æœºåˆ¶**ï¼Œé€šå¸¸é‡‡ç”¨é¢„è®¾çš„ã€å›ºå®šçš„å»å™ªæ­¥é•¿æˆ–å—å¤§å°ï¼Œå¯¼è‡´å¯¹ç®€å•æ ·æœ¬è¿‡åº¦è®¡ç®—ï¼Œå¯¹å›°éš¾æ ·æœ¬åˆ™ä¸è¶³ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šCDLM æ¡†æ¶
ä½œè€…æå‡º **CDLM**ï¼ˆConsistency Distillation and aDaptive Decoding for Diffusion Language Modelsï¼‰ï¼Œé€šè¿‡ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶è§£è€¦è®­ç»ƒä¸æ¨ç†ï¼š

#### ï¼ˆ1ï¼‰Discrete-Space Consistency Distillation (DSCD)
- **ç›®æ ‡**ï¼šè®­ç»ƒä¸€ä¸ªå¯¹è½¨è¿¹ä¸å˜ï¼ˆtrajectory-invariantï¼‰çš„å­¦ç”Ÿæ¨¡å‹ï¼Œä½¿å…¶èƒ½ä»ä»»æ„å™ªå£°çŠ¶æ€ç›´æ¥æ˜ å°„åˆ°å¹²å‡€åˆ†å¸ƒã€‚
- **æ–¹æ³•**ï¼š
  - é‡‡ç”¨ **Rao-Blackwellized ç›®æ ‡å‡½æ•°**ï¼Œåˆ©ç”¨æ•™å¸ˆæ¨¡å‹ï¼ˆteacherï¼‰åœ¨ä¸åŒå™ªå£°æ°´å¹³ä¸‹çš„é¢„æµ‹ä½œä¸ºç›‘ç£ä¿¡å·ã€‚
  - å¼•å…¥ **æ•™å¸ˆå­é›†æ©ç ï¼ˆteacher-subset maskingï¼‰**ï¼šç¡®ä¿æ•™å¸ˆçœ‹åˆ°çš„ä¿¡æ¯æ˜¯å­¦ç”Ÿçš„è¶…é›†ï¼ˆ$M_T \subset M_S$ï¼‰ï¼Œä»è€Œé™ä½è’¸é¦ç›®æ ‡çš„æ–¹å·®ã€‚
  - ç»“åˆ **è¯¾ç¨‹æ··åˆï¼ˆcurriculum mixingï¼‰**ï¼šåˆæœŸä»¥ä¸€è‡´æ€§æŸå¤±ä¸ºä¸»ï¼ŒåæœŸé€æ¸è¿‡æ¸¡åˆ°é‡å»ºæŸå¤±ï¼Œç¨³å®šè®­ç»ƒè¿‡ç¨‹ã€‚

#### ï¼ˆ2ï¼‰Confidence-Adaptive Decoding (CAD)
- **ç›®æ ‡**ï¼šæ ¹æ® token ç½®ä¿¡åº¦åŠ¨æ€å†³å®šæ¯ä¸€æ­¥è§£ç å¤šå°‘ tokenã€‚
- **æ–¹æ³•**ï¼š
  - è®¡ç®—æ¯ä¸ª masked token çš„ç½®ä¿¡åº¦ï¼ˆå¦‚æœ€å¤§æ¦‚ç‡å€¼ï¼‰ã€‚
  - è®¾å®šé˜ˆå€¼ $\gamma_{\text{conf}}$ï¼Œé€‰æ‹©é«˜äºé˜ˆå€¼çš„ token è¿›è¡Œè§£ç ã€‚
  - ä½¿ç”¨ `clip` å‡½æ•°é™åˆ¶æ¯æ­¥è§£ç æ•°é‡ï¼ˆ$k_{\min} \leq k(s) \leq k_{\max}$ï¼‰ï¼Œä¿è¯æ”¶æ•›æ€§å’Œç¨³å®šæ€§ã€‚
  - æ”¯æŒä¸ block-wise æˆ– pure diffusion è§£ç ç»“åˆã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ‰“ç ´è®­ç»ƒ-æ¨ç†é”™ä½**ï¼šDSCD ä½¿å­¦ç”Ÿæ¨¡å‹å…·å¤‡å¤„ç†ä»»æ„ä¸­é—´çŠ¶æ€çš„èƒ½åŠ›ï¼Œä¸º CAD æä¾›é²æ£’åŸºç¡€ã€‚
- **çœŸæ­£çš„è‡ªé€‚åº”è®¡ç®—**ï¼šCAD åŠ¨æ€è·³è¿‡ç®€å• tokenï¼Œå°†è®¡ç®—é›†ä¸­åœ¨é«˜ç†µã€é«˜ä¸ç¡®å®šæ€§åŒºåŸŸï¼Œé¿å…å¯å‘å¼æ–¹æ³•çš„è´¨é‡å´©æºƒã€‚
- **ç«¯åˆ°ç«¯åŠ é€Ÿæ˜¾è‘—**ï¼šç†è®ºä¸Šçš„ NFE å‡å°‘èƒ½æœ‰æ•ˆè½¬åŒ–ä¸º wall-clock é€Ÿåº¦æå‡ï¼Œä¸”å¸¸å‘ˆ**è¶…çº¿æ€§åŠ é€Ÿ**ï¼ˆsuperlinear speedupï¼‰ã€‚
- **é€šç”¨æ€§å¼º**ï¼šå¯åº”ç”¨äº block-wise å’Œ pure diffusion è®¾ç½®ï¼Œæ— éœ€ä¿®æ”¹æ¨¡å‹æ¶æ„ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **ä»£ç ç”Ÿæˆ**ï¼š`OpenCodeInstruct`ï¼ˆç”¨äºè®­ç»ƒï¼‰ã€`HumanEval`ã€`MBPP` åŠå…¶ä¸¥æ ¼å˜ä½“ `HumanEval+`ã€`MBPP+`ã€‚
- **æ•°å­¦æ¨ç†**ï¼š`GSM8K`ï¼ˆè®­ç»ƒä¸æµ‹è¯•ï¼‰ã€`MATH500`ã€‚
- æ‰€æœ‰å®éªŒå‡åœ¨é›¶æ ·æœ¬ï¼ˆzero-shotï¼‰æˆ–å°‘æ ·æœ¬ï¼ˆfew-shotï¼‰è®¾å®šä¸‹è¿›è¡Œã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼šä»¥ `LLaDA-8B-Instruct` ä½œä¸ºæ•™å¸ˆæ¨¡å‹ï¼Œå­¦ç”Ÿæ¨¡å‹ä»å…¶æƒé‡åˆå§‹åŒ–ã€‚
- **è®­ç»ƒé…ç½®**ï¼š
  - ä½¿ç”¨ BF16 ç²¾åº¦ï¼Œä¸Šä¸‹æ–‡é•¿åº¦ 1024ã€‚
  - å…¨å±€ batch size ä¸º 64ï¼Œåœ¨ 8Ã—AMD MI250 GPU ä¸Šè®­ç»ƒã€‚
  - ä¼˜åŒ–å™¨ä¸º AdamWï¼Œå­¦ä¹ ç‡ $5\times10^{-6}$ï¼Œcosine è¡°å‡ï¼Œ10% é¢„çƒ­ã€‚
- **æ¨ç†é…ç½®**ï¼š
  - æœ€å¤§ç”Ÿæˆé•¿åº¦ $L_{\text{gen}} = 256$ã€‚
  - CAD å‚æ•°ï¼š$\gamma_{\text{conf}} = 0.95$, $k_{\min}=1$, $k_{\max}=32$ã€‚
  - è¯„ä¼°åŸºäºå¼€æºæ¡†æ¶ `DAEDAL` ç»Ÿä¸€å®ç°ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **å‡†ç¡®æ€§**ï¼š
  - æ•°å­¦ä»»åŠ¡ï¼šAccuracyï¼ˆGSM8K, MATH500ï¼‰ã€‚
  - ä»£ç ä»»åŠ¡ï¼špass@1, pass@5ï¼ˆHumanEval, MBPPï¼‰ã€‚
- **æ•ˆç‡æŒ‡æ ‡**ï¼š
  - **Avg. NFE**ï¼šå¹³å‡å‡½æ•°è°ƒç”¨æ¬¡æ•°ã€‚
  - **Tokens/s**ï¼šæ¯ç§’ç”Ÿæˆçš„ token æ•°ã€‚
  - **Speedup**ï¼šç›¸å¯¹äºåŸºçº¿çš„ wall-clock æ—¶é—´åŠ é€Ÿæ¯”ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- `LLaDA`ï¼ˆSequential / Block Diffusion / Pure Diffusionï¼‰
- `Fast-dLLM`ï¼šä¸€ç§æ— éœ€è®­ç»ƒçš„å¹¶è¡Œè§£ç æ¡†æ¶ã€‚
- æ¶ˆèå®éªŒä¸­çš„å˜ä½“ï¼šSFTï¼ˆSupervised Fine-Tuningï¼‰ã€å›ºå®šæ­¥é•¿è§£ç ç­‰ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 3ï¼‰
| ä»»åŠ¡ | åŸºçº¿ï¼ˆLLaDAï¼‰ | CDLMï¼ˆOursï¼‰ | Speedup |
|------|----------------|---------------|---------|
| **HumanEval (pass@1)** | 38.7 @ 256 NFE | **40.9 @ 113.2 NFE** | **3.30Ã—** |
| **HumanEval (pass@5)** | 51.2 @ 256 NFE | **52.4 @ 113.9 NFE** | **3.26Ã—** |
| **MBPP-plus (pass@1)** | 48.7 @ 256 NFE | 47.9 @ 108.0 NFE | 3.51Ã— |
| **MATH500 (Acc%)** | 37.3 @ 512 NFE | **38.6 @ 148.3 NFE** | **5.33Ã—** |
| **å¹³å‡æ€§èƒ½** | 45.6 @ 292.6 NFE | **46.3 @ 117.2 NFE** | **3.62Ã—** |

> âœ… **æ ¸å¿ƒç»“è®º**ï¼šCDLM åœ¨ä¿æŒç”šè‡³ç•¥å¾®æå‡å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œå®ç°äº† **3.62Ã— çš„å¹³å‡ç«¯åˆ°ç«¯åŠ é€Ÿ**ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨ **GSM8K** ä¸Šï¼ŒCDLM åŒ¹é… LLaDA å—æ‰©æ•£åŸºçº¿ç²¾åº¦ï¼ˆ77.6% vs 77.4%ï¼‰ï¼Œä½†å®ç° **5.18Ã— wall-clock åŠ é€Ÿ**ï¼ˆè§ Table 1ï¼‰ã€‚
- åœ¨ **HumanEval** ä¸Šï¼Œpass@1 æå‡ 2.2%ï¼ŒåŒæ—¶è·å¾— 3.30Ã— é€Ÿåº¦æå‡ã€‚
- å›¾è¡¨æ˜¾ç¤ºï¼ŒCDLM çš„ **accuracy-efficiency Pareto frontier** æ˜æ˜¾ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼Œæ— è®ºæ˜¯åœ¨ä½ NFE è¿˜æ˜¯é«˜ç²¾åº¦åœºæ™¯ä¸‹éƒ½å ä¼˜ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆTable E.1ï¼‰
| é…ç½® | Block Size | Acc (%) | Avg. NFE | Speedup |
|------|------------|----------|-----------|---------|
| LLaDA (Teacher) | 32 | 77.4 | 256.0 | 1.00Ã— |
| + SFT only | 32 | 77.6 | 256.0 | 1.00Ã— |
| + DSCD only | 32 | 78.3 | 256.0 | 1.00Ã— |
| + CAD only (no distill) | 32 | 77.4 | 98.8 | 4.01Ã— |
| + SFT + CAD | 32 | 77.6 | 95.4 | 4.15Ã— |
| **+ DSCD + CAD (Ours)** | 32 | **77.6** | **76.3** | **5.18Ã—** |

#### å…³é”®å‘ç°ï¼š
- **DSCD æ˜¯ CAD æˆåŠŸçš„å‰æ**ï¼šä»…ä½¿ç”¨ SFT + CAD æ—¶ï¼Œè™½ç„¶ä¹Ÿèƒ½åŠ é€Ÿï¼Œä½†åœ¨ pure diffusion åœºæ™¯ä¸‹å‡†ç¡®ç‡ä¸¥é‡ä¸‹é™ï¼ˆ38.2% vs 54.7%ï¼‰ï¼Œè¯´æ˜æ ‡å‡†å¾®è°ƒæ— æ³•æ”¯æŒæ¿€è¿›çš„è‡ªé€‚åº”è§£ç ã€‚
- **DSCD æå‡å…¨å±€å»å™ªèƒ½åŠ›**ï¼šåœ¨ pure diffusionï¼ˆb=256ï¼‰ä¸‹ï¼ŒDSCD å°†å‡†ç¡®ç‡ä» 21.9%ï¼ˆSFTï¼‰å¤§å¹…æå‡è‡³ 54.8%ï¼Œè¯æ˜å…¶å­¦ä¹ åˆ°äº†é•¿ç¨‹ä¾èµ–ç»“æ„ã€‚
- **ä¿¡å¿ƒæ’åºè‡³å…³é‡è¦**ï¼šè‹¥å°† CAD ä¸­çš„ç½®ä¿¡åº¦æ’åºæ›¿æ¢ä¸ºéšæœºé€‰æ‹©ï¼Œå‡†ç¡®ç‡éª¤é™è‡³ 50.6%ï¼ŒNFE å‡è‡³ 202.2ï¼ŒéªŒè¯äº†â€œé€‰æ‹©å“ªäº› token è§£ç â€æ¯”â€œè§£ç å¤šå°‘â€æ›´é‡è¦ã€‚
- **æ•™å¸ˆå­é›†æ©ç å¿…è¦**ï¼šç‹¬ç«‹é‡‡æ ·æ©ç ä¼šå¯¼è‡´è®­ç»ƒä¸ç¨³å®šç”šè‡³å‘æ•£ï¼ŒéªŒè¯äº† Rao-Blackwellization çš„å®é™…ä»·å€¼ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **è®­ç»ƒ-æ¨ç†é”™ä½æ˜¯æ•ˆç‡ç“¶é¢ˆçš„æ ¹æœ¬åŸå› **ï¼šå•çº¯ä¾é æ¨ç†æ—¶çš„å¯å‘å¼ç­–ç•¥æ— æ³•çªç ´æ€§èƒ½ä¸Šé™ï¼Œå¿…é¡»é€šè¿‡è®­ç»ƒç›®æ ‡é‡å¡‘æ¨¡å‹è¡Œä¸ºã€‚
2. **DSCD å®ç°äº†è½¨è¿¹ä¸å˜æ€§**ï¼šå­¦ç”Ÿæ¨¡å‹ä¸å†ä¾èµ–ç‰¹å®šå™ªå£°è·¯å¾„ï¼Œè€Œæ˜¯å­¦ä¼šä»ä»»æ„éƒ¨åˆ†æ©ç çŠ¶æ€ç›´æ¥æ¢å¤å®Œæ•´è¯­ä¹‰ï¼Œä¸ºè‡ªé€‚åº”è§£ç æä¾›é²æ£’åŸºç¡€ã€‚
3. **CAD å®ç°äº†é«˜æ•ˆçš„åŠ¨æ€è®¡ç®—åˆ†é…**ï¼šæ¨¡å‹è‡ªåŠ¨å½¢æˆâ€œå…ˆæ­éª¨æ¶ï¼Œå†å¡«ç»†èŠ‚â€çš„åˆ†å±‚ç”Ÿæˆç­–ç•¥ï¼š
   - æ—©æœŸæ­¥éª¤å¿«é€Ÿç¡®å®šè¯­æ³•ç»“æ„ï¼ˆkeywords, indentationï¼‰ï¼›
   - åæœŸæ­¥éª¤èšç„¦å¤æ‚é€»è¾‘ï¼ˆarithmetic, conditionalsï¼‰ã€‚
4. **ç®—æ³•çº§ä¼˜åŒ–å¯å¸¦æ¥è¶…çº¿æ€§åŠ é€Ÿ**ï¼šç”±äº DSCD å¯¹é½äº†æ¨¡å‹ä¸ CAD ç­–ç•¥ï¼Œæ§åˆ¶å¼€é”€æå°ï¼ŒNFE çš„å‡å°‘å‡ ä¹å®Œå…¨è½¬åŒ–ä¸º wall-clock é€Ÿåº¦æå‡ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **é™æ€ç”»å¸ƒçº¦æŸï¼ˆStatic Canvas Constraintsï¼‰**ï¼š
   - ä¾èµ–é¢„å®šä¹‰çš„æœ€å¤§åºåˆ—é•¿åº¦ $L_{\text{gen}}$ï¼ŒçŸ­åºåˆ—å­˜åœ¨å†…å­˜æµªè´¹ï¼Œé•¿åºåˆ—å—é™äºè®­ç»ƒçª—å£ã€‚
2. **æ•™å¸ˆæ€§èƒ½å¤©èŠ±æ¿ï¼ˆTeacher-Bounded Reasoningï¼‰**ï¼š
   - å­¦ç”Ÿèƒ½åŠ›å—é™äºæ•™å¸ˆï¼Œè‹¥æ•™å¸ˆåœ¨å¤æ‚é€»è¾‘ä¸Šå‡ºé”™ï¼Œå­¦ç”Ÿå¯èƒ½ç»§æ‰¿é”™è¯¯ã€‚
3. **å¼€æ”¾åŸŸä»»åŠ¡é€‚ç”¨æ€§æœ‰é™**ï¼š
   - ç½®ä¿¡åº¦é˜ˆå€¼å‡è®¾ä½ä¸ç¡®å®šæ€§ â‰ˆ æ­£ç¡®æ€§ï¼Œåœ¨åˆ›é€ æ€§å†™ä½œç­‰é«˜ç†µä»»åŠ¡ä¸­å¯èƒ½å¯¼è‡´è¾“å‡ºå•è°ƒã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **åŠ¨æ€ä¸æ— é™ä¸Šä¸‹æ–‡æ‰©æ•£**ï¼šç»“åˆåŠ¨æ€çª—å£æœºåˆ¶ï¼ˆå¦‚ semi-autoregressive shiftingï¼‰ï¼Œå®ç°çœŸæ­£æ— é™é•¿åº¦çš„ç”Ÿæˆã€‚
2. **è¶…è¶Šæ¨¡ä»¿å­¦ä¹ çš„åœ¨çº¿ç²¾è°ƒï¼ˆOn-Policy Refinementï¼‰**ï¼šä½¿ç”¨ RL å¯¹å­¦ç”Ÿè¿›è¡Œå¾®è°ƒï¼Œä¼˜åŒ–æ­£ç¡®æ€§è€Œéä¸€è‡´æ€§ï¼Œçªç ´æ•™å¸ˆæ€§èƒ½ä¸Šé™ã€‚
3. **é›†æˆ KV Cache**ï¼šç»“åˆ `Fast-dLLM` ç­‰ç¼“å­˜æŠ€æœ¯ï¼Œè¿›ä¸€æ­¥æ‘Šé”€æ³¨æ„åŠ›è®¡ç®—æˆæœ¬ï¼Œå®ç°æ›´å¤§è§„æ¨¡çš„ç«¯åˆ°ç«¯åŠ é€Ÿã€‚

---

> ğŸ”— **ä»£ç å·²å¼€æº**ï¼šhttps://github.com/yihao-liang/CDLM

</details>

---

### 12. [SuperSFL: Resource-Heterogeneous Federated Split Learning with Weight-Sharing Super-Networks](https://arxiv.org/abs/2601.02092)

**Authors**: Abdullah Al Asif, Sixing Yu, Juan Pablo Munoz, Arya Mazaheri, Ali Jannesari  
**Category**: cs.DC  
**Published**: 2026-01-06  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2601.02092v1  

#### Abstract
SplitFed Learning (SFL) combines federated learning and split learning to enable collaborative training across distributed edge devices; however, it faces significant challenges in heterogeneous environments with diverse computational and communication capabilities. This paper proposes \textit{Super...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# SuperSFL: Resource-Heterogeneous Federated Split Learning with Weight-Sharing Super-Networks è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹ **Federated Split Learning (SFL)** åœ¨èµ„æºå¼‚æ„è¾¹ç¼˜ç¯å¢ƒä¸­çš„ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **è®¾å¤‡å¼‚æ„æ€§**ï¼šä¸åŒå®¢æˆ·ç«¯åœ¨è®¡ç®—èƒ½åŠ›ã€å†…å­˜å’Œé€šä¿¡å»¶è¿Ÿæ–¹é¢å·®å¼‚å·¨å¤§ï¼Œä¼ ç»Ÿ SFL å‡è®¾ç»Ÿä¸€æ¨¡å‹åˆ†å‰²ç‚¹ï¼Œéš¾ä»¥é€‚é…å¤šæ ·åŒ–è®¾å¤‡ã€‚
- **é€šä¿¡ç“¶é¢ˆä¸æ”¶æ•›æ…¢**ï¼šé¢‘ç¹çš„ä¸­é—´æ¿€æ´»ä¼ è¾“ï¼ˆ"smashed data"ï¼‰å¯¼è‡´é«˜é€šä¿¡å¼€é”€ï¼›æœåŠ¡å™¨ä¾èµ–æ€§å¼ºï¼Œæ¢¯åº¦åé¦ˆå»¶è¿Ÿå½±å“è®­ç»ƒæ•ˆç‡ã€‚
- **å®¹é”™æ€§å·®**ï¼šç½‘ç»œä¸­æ–­æˆ–æœåŠ¡å™¨ä¸å¯ç”¨æ—¶ï¼Œå®¢æˆ·ç«¯æ— æ³•ç»§ç»­è®­ç»ƒï¼Œé€ æˆç³»ç»Ÿåœæ»ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **SuperSFL**ï¼Œä¸€ç§åŸºäºæƒé‡å…±äº«è¶…ç½‘ç»œï¼ˆweight-sharing super-networkï¼‰çš„è”é‚¦åˆ†æ‹†å­¦ä¹ æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰**åŠ¨æ€èµ„æºæ„ŸçŸ¥å­ç½‘ç»œåˆ†é…ï¼ˆResource-Aware Subnetwork Allocationï¼‰**
- æ„å»ºä¸€ä¸ªå…¨å±€çš„ **super-network**ï¼Œæ‰€æœ‰å®¢æˆ·ç«¯ä»ä¸­æå–è¿ç»­å‰ç¼€ä½œä¸ºæœ¬åœ°ç¼–ç å™¨ã€‚
- æ ¹æ®æ¯ä¸ªå®¢æˆ·ç«¯çš„ **memory capacity** å’Œ **communication latency** åŠ¨æ€å†³å®šå…¶æœ¬åœ°æ¨¡å‹æ·±åº¦ $d_i$ï¼Œå®ç°ä¸ªæ€§åŒ–é€‚é…ã€‚
- é¿å…éè¿ç»­å±‚åˆ†é…å¸¦æ¥çš„å…¼å®¹æ€§é—®é¢˜ï¼Œç¡®ä¿ç»“æ„ä¸€è‡´æ€§ã€‚

#### ï¼ˆ2ï¼‰**ä¸‰é˜¶æ®µæ¢¯åº¦èåˆæœºåˆ¶ï¼ˆThree-Phase Gradient Fusion, TPGFï¼‰**
- å¼•å…¥è½»é‡çº§å®¢æˆ·ç«¯åˆ†ç±»å™¨ï¼Œåœ¨æœ¬åœ°æä¾›ç›‘ç£ä¿¡å·ã€‚
- èåˆä¸¤ä¸ªæ¢¯åº¦æºï¼š
  - **Phase 1**: å®¢æˆ·ç«¯æœ¬åœ°åˆ†ç±»å™¨äº§ç”Ÿçš„ $\nabla \mathcal{L}_{\text{client}}$
  - **Phase 2**: æœåŠ¡å™¨åä¼ å›æ¥çš„æ·±å±‚æ¢¯åº¦ $\nabla \mathcal{L}_{\text{server}}$
- **Phase 3**: ä½¿ç”¨æŸå¤±åŠ æƒèåˆç­–ç•¥ç”Ÿæˆæœ€ç»ˆæ›´æ–°ï¼š
  $$
  \mathbf{g} = w_{\text{client}} \cdot \mathbf{g}_{\text{client}} + (1 - w_{\text{client}}) \cdot \mathbf{g}_{\text{server}}
  $$
  æƒé‡ç”±æ¨¡å‹æ·±åº¦å’Œå½“å‰æŸå¤±å…±åŒå†³å®šï¼Œæå‡æµ…å±‚ç¼–ç å™¨çš„å­¦ä¹ ç¨³å®šæ€§ä¸æ”¶æ•›é€Ÿåº¦ã€‚

#### ï¼ˆ3ï¼‰**å®¹é”™å‹å®¢æˆ·ç«¯ä¾§è®­ç»ƒæœºåˆ¶ï¼ˆFault-Tolerant Client-Side Classifierï¼‰**
- å½“æœåŠ¡å™¨æ— å“åº”ï¼ˆè¶…æ—¶ 5 ç§’ï¼‰ï¼Œå®¢æˆ·ç«¯è‡ªåŠ¨åˆ‡æ¢è‡³â€œfallback modeâ€ï¼Œä»…ä½¿ç”¨æœ¬åœ°åˆ†ç±»å™¨è¿›è¡Œè‡ªä¸»è®­ç»ƒã€‚
- æ¢å¤è¿æ¥åï¼Œé€šè¿‡èšåˆæœºåˆ¶å°†æœ¬åœ°æ›´æ–°èå…¥å…¨å±€æ¨¡å‹ï¼Œæ— éœ€æ˜¾å¼åŒæ­¥æˆ–å›æ»šã€‚
- æ˜¾è‘—å¢å¼ºç³»ç»Ÿé²æ£’æ€§ï¼Œé¿å…å› çŸ­æš‚æ•…éšœå¯¼è‡´è®­ç»ƒåœæ»ã€‚

#### ï¼ˆ4ï¼‰**ååŒå®¢æˆ·ç«¯-æœåŠ¡å™¨èšåˆï¼ˆCollaborative Client-Server Aggregationï¼‰**
- å¯¹å¼‚æ„å­ç½‘ç»œå‚æ•°é‡‡ç”¨ **æŒ‰å±‚å¯¹é½çš„åŠ æƒå¹³å‡**ï¼Œæƒé‡ç»“åˆæ¨¡å‹æ·±åº¦ä¸è®­ç»ƒè¡¨ç°ï¼ˆloss-based weightingï¼‰ï¼š
  $$
  w_i = \frac{d_i / (\mathcal{L}_{\text{client},i} + \epsilon)}{\sum_j d_j / (\mathcal{L}_{\text{client},j} + \epsilon)}
  $$
- åŠ å…¥ä¸€è‡´æ€§æ­£åˆ™é¡¹é˜²æ­¢å®¢æˆ·ç«¯ä¸æœåŠ¡å™¨é—´å‚æ•°åç¦»è¿‡å¤§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | SuperSFL | SFL / FedAvg | ä¼˜åŠ¿è¯´æ˜ |
|------|----------|-------------|---------|
| **é€‚åº”æ€§** | âœ… æ”¯æŒå¼‚æ„è®¾å¤‡ | âŒ å›ºå®šåˆ†å‰²ç‚¹ | æ›´å¹¿æ³›è®¾å¤‡å‚ä¸ |
| **é€šä¿¡æ•ˆç‡** | âœ… æ˜¾è‘—é™ä½ | âŒ é«˜é¢‘åŒæ­¥ | å‡å°‘å¸¦å®½æ¶ˆè€— |
| **æ”¶æ•›é€Ÿåº¦** | âœ… å¿«é€Ÿæ”¶æ•› | âŒ ç¼“æ…¢ | æ›´å°‘é€šä¿¡è½®æ¬¡ |
| **å®¹é”™èƒ½åŠ›** | âœ… æ”¯æŒæ–­ç½‘è®­ç»ƒ | âŒ ä¾èµ–æœåŠ¡å™¨ | æå‡å¯é æ€§ |
| **èƒ½æ•ˆè¡¨ç°** | âœ… æ›´ä½èƒ½è€—/ç¢³æ’æ”¾ | âš ï¸ è¾ƒé«˜ | æ›´ç»¿è‰²AI |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **CIFAR-10** å’Œ **CIFAR-100**
- ä½¿ç”¨ **Vision Transformer (ViT-16)** ä½œä¸ºä¸»å¹²æ¨¡å‹ï¼Œå› å…¶å¯¹ non-IID æ•°æ®å…·æœ‰è¾ƒå¼ºé²æ£’æ€§ã€‚

### å®éªŒè®¾ç½®
- **å®¢æˆ·ç«¯æ•°é‡**ï¼š50 å’Œ 100
- **Non-IID è®¾ç½®**ï¼šé‡‡ç”¨ **Dirichlet åˆ†å‰²**ï¼ˆ$\alpha=0.5$ï¼‰ï¼Œæ¨¡æ‹ŸçœŸå®åœºæ™¯ä¸‹çš„ç±»åˆ«åˆ†å¸ƒåç§»ã€‚
- **è®¾å¤‡å¼‚æ„æ¨¡æ‹Ÿ**ï¼š
  - å†…å­˜å®¹é‡ï¼šå‡åŒ€åˆ†å¸ƒåœ¨ [2, 16] GB
  - é€šä¿¡å»¶è¿Ÿï¼šå‡åŒ€åˆ†å¸ƒåœ¨ [20, 200] ms
- æ‰€æœ‰è®­ç»ƒè¿è¡Œäº NVIDIA A10/A100 GPU ä¸Šï¼ˆç¡¬ä»¶åŒè´¨ï¼Œé€»è¾‘å¼‚æ„ï¼‰

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Accuracy (%)** | æµ‹è¯•é›†åˆ†ç±»å‡†ç¡®ç‡ |
| **Communication Rounds** | è¾¾åˆ°ç›®æ ‡ç²¾åº¦æ‰€éœ€é€šä¿¡è½®æ•° |
| **Total Communication Cost (MB)** | æ€»ä¼ è¾“æ•°æ®é‡ |
| **End-to-End Training Time (sec)** | å®Œæ•´è®­ç»ƒè€—æ—¶ |
| **Power Consumption (W)** | å¹³å‡GPUåŠŸè€— |
| **Power per Accuracy (W/%)** | å•ä½ç²¾åº¦èƒ½è€—ï¼ˆè¡¡é‡èƒ½æ•ˆï¼‰ |
| **COâ‚‚ Emissions (g)** | æ¨ç®—ç¢³è¶³è¿¹ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **SFL (Split Federated Learning)**ï¼šç»å…¸åˆ†æ‹†å­¦ä¹ ï¼Œå›ºå®šåˆ†å‰²ç‚¹
- **DFL (Dynamic Federated Learning)**ï¼šæ”¯æŒåŠ¨æ€è°ƒæ•´ï¼Œä½†ä»éœ€å…¨æ¨¡å‹è®­ç»ƒ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table Iï¼‰
| Dataset | Clients | Target Acc (%) | Method | Rounds | Comm. Cost (MB) | Training Time (s) |
|--------|--------|----------------|--------|--------|------------------|--------------------|
| CIFAR-10 | 50 | 70 | SFL | 11 | 9,075 | 6,127 |
|          |     |    | DFL | 9  | 2,305 | 2,650 |
|          |     |    | **SSFL** | **5**  | **466** | **595** |
| CIFAR-10 | 100 | 75 | SFL | 19 | 21,463 | 12,168 |
|          |      |    | DFL | 16 | 15,472 | 14,368 |
|          |      |    | **SSFL** | **12** | **939** | **1,010** |
| CIFAR-100 | 50 | 75 | SFL | 35 | 28,938 | 21,284 |
|           |     |    | DFL | 27 | 7,909 | 9,796 |
|           |     |    | **SSFL** | **15** | **7,194** | **8,766** |
| CIFAR-100 | 100 | 80 | SFL | 100 | 165,358 | 114,955 |
|            |       |    | DFL | 34 | 13,638 | 15,328 |
|            |       |    | **SSFL** | **22** | **9,719** | **8,926** |

> æ³¨ï¼šSSFL = SuperSFL

### æ€§èƒ½å¯¹æ¯”æ€»ç»“
- **é€šä¿¡è½®æ¬¡å‡å°‘**ï¼šç›¸æ¯” SFL å‡å°‘ **2â€“5Ã—**ï¼Œå°¤å…¶åœ¨å¤æ‚ä»»åŠ¡ï¼ˆå¦‚ CIFAR-100ï¼‰ä¸Šä¼˜åŠ¿æ›´æ˜æ˜¾ã€‚
- **é€šä¿¡æˆæœ¬ä¸‹é™**ï¼šæœ€é«˜è¾¾ **20Ã— é™ä½**ï¼ˆCIFAR-10, 100 clientsï¼‰ã€‚
- **è®­ç»ƒæ—¶é—´ç¼©çŸ­**ï¼šæœ€å¤š **13Ã— åŠ é€Ÿ**ï¼ˆCIFAR-10, 50 clientsï¼‰ã€‚
- **å‡†ç¡®ç‡æ›´é«˜**ï¼šä¾‹å¦‚åœ¨ CIFAR-10 ä¸Šï¼ŒSSFL è¾¾åˆ° ~97%ï¼Œè€Œ SFL ä»…ä¸º ~78%ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ï¼ˆ1ï¼‰TPGF å„ç»„ä»¶ä½œç”¨ï¼ˆFigure 6ï¼‰
| é…ç½® | Accuracy (%) | è¯´æ˜ |
|------|--------------|------|
| Full TPGF | 96.93 | å®Œæ•´èåˆæœºåˆ¶ |
| No Loss Fusion | 91.47 | ç§»é™¤æŸå¤±æ„ŸçŸ¥æƒé‡ â†’ ä¸ç¨³å®šæ—©æœŸæ›´æ–° |
| No Depth Fusion | 88.66 | å¿½ç•¥æ·±åº¦å·®å¼‚ â†’ æµ…å±‚å®¢æˆ·å—æ·±å±‚ä¸»å¯¼ |
| Equal Fusion | 85.89 | ç®€å•å¹³å‡ â†’ æ•ˆæœæœ€å·® |

âœ… ç»“è®ºï¼š**æ·±åº¦æ„ŸçŸ¥ + æŸå¤±æ„ŸçŸ¥** æ˜¯ TPGF æˆåŠŸçš„å…³é”®ã€‚

#### ï¼ˆ2ï¼‰æœåŠ¡å™¨å¯ç”¨æ€§å½±å“ï¼ˆTable IIIï¼‰
| Server Gradient Availability (%) | Accuracy (%) |
|----------------------------------|--------------|
| 100 | 95.58 Â± 1.08 |
| 70  | 93.81 Â± 2.59 |
| 50  | 93.12 Â± 2.11 |
| 20  | 91.03 Â± 1.17 |
| 10  | 89.77 Â± 2.22 |
| 0 (**Serverless**) | **86.36 Â± 3.25** |

âœ… ç»“è®ºï¼šå³ä½¿å®Œå…¨æ— æœåŠ¡å™¨å‚ä¸ï¼ŒSuperSFL ä»å¯æ”¶æ•›è‡³åˆç†ç²¾åº¦ï¼ŒéªŒè¯äº†å…¶å¼ºå¤§çš„ **fault tolerance** èƒ½åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **SuperSFL æ˜¾è‘—æå‡äº† SFL åœ¨å¼‚æ„ç¯å¢ƒä¸‹çš„å®ç”¨æ€§**ï¼š
   - é€šè¿‡ **weight-sharing super-network + dynamic slicing** å®ç°çœŸæ­£çš„è®¾å¤‡è‡ªé€‚åº”ã€‚
2. **TPGF æœ‰æ•ˆç¼“è§£äº†æµ…å±‚ç¼–ç å™¨ç›‘ç£ä¸è¶³é—®é¢˜**ï¼š
   - èåˆæœ¬åœ°ä¸æœåŠ¡å™¨æ¢¯åº¦ï¼ŒåŠ å¿«æ”¶æ•›å¹¶æé«˜ç¨³å®šæ€§ã€‚
3. **å®¹é”™æœºåˆ¶æå¤§å¢å¼ºäº†ç³»ç»Ÿå¥å£®æ€§**ï¼š
   - æ–­ç½‘æœŸé—´ä»å¯æŒç»­è®­ç»ƒï¼Œé€‚ç”¨äºä¸ç¨³å®šè¾¹ç¼˜ç½‘ç»œã€‚
4. **ç»¼åˆæ€§èƒ½å…¨é¢è¶…è¶Š SFL å’Œ DFL**ï¼š
   - æ›´å¿«æ”¶æ•›ã€æ›´ä½é€šä¿¡ã€æ›´çŸ­è®­ç»ƒæ—¶é—´ã€æ›´é«˜å‡†ç¡®ç‡ã€æ›´å¥½èƒ½æ•ˆã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **è¶…å‚æ•°ç»éªŒè®¾å®š**ï¼šèµ„æºåˆ†é…ç³»æ•°ï¼ˆÎ±, Î²ï¼‰å’Œæ­£åˆ™åŒ–æƒé‡ï¼ˆÎ», Tï¼‰ä¸ºäººå·¥é€‰æ‹©ï¼Œç¼ºä¹ç†è®ºæŒ‡å¯¼ã€‚
- **ä»¿çœŸç¯å¢ƒæµ‹è¯•**ï¼šå®éªŒåŸºäºæ¨¡æ‹Ÿå¼‚æ„æ€§ï¼Œå°šæœªåœ¨çœŸå®ç‰©ç†è¾¹ç¼˜è®¾å¤‡é›†ç¾¤ä¸ŠéªŒè¯ã€‚
- **æœªè€ƒè™‘éšç§å¢å¼ºæœºåˆ¶**ï¼šå¦‚ Differential Privacy æˆ– Secure Aggregation å°šæœªé›†æˆã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **ç³»ç»ŸåŒ–è¶…å‚æ•°è°ƒä¼˜ç­–ç•¥**ï¼šå»ºç«‹ principled selection guidelinesã€‚
2. **çœŸå®è¾¹ç¼˜éƒ¨ç½²éªŒè¯**ï¼šåœ¨æ‰‹æœºã€IoT è®¾å¤‡ç­‰çœŸå®å¼‚æ„å¹³å°ä¸Šæµ‹è¯•ã€‚
3. **é«˜çº§ä¸ªæ€§åŒ–æœºåˆ¶**ï¼šç»“åˆ clustered FL æˆ– hypernetwork è¿›ä¸€æ­¥æå‡æ¨¡å‹å®šåˆ¶èƒ½åŠ›ã€‚
4. **éšç§ä¿æŠ¤é›†æˆ**ï¼šå¼•å…¥ DPã€secure computation ç­‰æŠ€æœ¯ä»¥æ»¡è¶³å®‰å…¨éœ€æ±‚ã€‚
5. **æ‰©å±•è‡³å…¶ä»–æ¨¡å‹æ¶æ„**ï¼šå¦‚ CNNã€RNNã€GNN ç­‰ã€‚

---

> âœ… **æ€»ä½“è¯„ä»·**ï¼š  
> SuperSFL æ˜¯ä¸€é¡¹é¢å‘ç°å®è¾¹ç¼˜åœºæ™¯çš„é‡è¦è¿›å±•ï¼Œå®ƒä¸ä»…è§£å†³äº† SFL çš„å…³é”®ç“¶é¢ˆï¼Œè¿˜æå‡ºäº†å¯æ¨å¹¿çš„è®¾è®¡èŒƒå¼â€”â€”**åŠ¨æ€å­ç½‘ç»œ + å¤šæºæ¢¯åº¦èåˆ + å®¹é”™æœ¬åœ°è®­ç»ƒ**ï¼Œä¸ºæ„å»ºé«˜æ•ˆã€é²æ£’ã€èŠ‚èƒ½çš„åˆ†å¸ƒå¼æœºå™¨å­¦ä¹ ç³»ç»Ÿæä¾›äº†æ–°è·¯å¾„ã€‚

</details>

---

### 13. [Quantized SO(3)-Equivariant Graph Neural Networks for Efficient Molecular Property Prediction](https://arxiv.org/abs/2601.02213)

**Authors**: Haoyu Zhou, Ping Xue, Tianfan Fu, Hao Zhang  
**Category**: cs.LG  
**Published**: 2026-01-06  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.02213v1  

#### Abstract
Deploying 3D graph neural networks (GNNs) that are equivariant to 3D rotations (the group SO(3)) on edge devices is challenging due to their high computational cost. This paper addresses the problem by compressing and accelerating an SO(3)-equivariant GNN using low-bit quantization techniques. Speci...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Quantized SO(3)-Equivariant Graph Neural Networks for Efficient Molecular Property Prediction*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡é’ˆå¯¹ **SO(3)-equivariant GNNs** åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²å›°éš¾çš„é—®é¢˜ã€‚è¿™ç±»æ¨¡å‹è™½ç„¶åœ¨åˆ†å­æ€§è´¨é¢„æµ‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ç”±äºå…¶å¤æ‚çš„å¼ é‡è¿ç®—å’Œæ³¨æ„åŠ›æœºåˆ¶ï¼Œè®¡ç®—å¼€é”€å¤§ã€å†…å­˜å ç”¨é«˜ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™çš„è®¾å¤‡ï¼ˆå¦‚ç§»åŠ¨è®¾å¤‡æˆ–ç‰‡ä¸Šå®éªŒå®¤ä¼ æ„Ÿå™¨ï¼‰ä¸Šå®æ—¶è¿è¡Œã€‚

æ­¤å¤–ï¼Œç°æœ‰çš„ä½æ¯”ç‰¹é‡åŒ–æ–¹æ³•ï¼ˆå¦‚æ ‡å‡† 8-bit é‡åŒ–æˆ– PTQï¼‰ç›´æ¥åº”ç”¨äº equivariant GNNs æ—¶ï¼Œå®¹æ˜“ç ´åæ¨¡å‹çš„æ—‹è½¬å¯¹ç§°æ€§ï¼ˆequivarianceï¼‰ï¼Œå¯¼è‡´ç²¾åº¦æ˜¾è‘—ä¸‹é™ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡ºäº†ä¸€å¥—ä¸“ä¸º **SO(3)-equivariant GNNs** è®¾è®¡çš„ä½æ¯”ç‰¹é‡åŒ–æ¡†æ¶ï¼ŒåŒ…å«ä¸‰é¡¹æ ¸å¿ƒåˆ›æ–°ï¼š

#### ï¼ˆ1ï¼‰**Magnitude-Direction Decoupled Quantization (MDDQ)**  
å°†ç­‰å˜å‘é‡ç‰¹å¾åˆ†è§£ä¸º**æ¨¡é•¿ï¼ˆmagnitudeï¼‰** å’Œ **æ–¹å‘ï¼ˆdirectionï¼‰** ä¸¤ä¸ªéƒ¨åˆ†åˆ†åˆ«è¿›è¡Œé‡åŒ–ï¼š
- æ¨¡é•¿ $ r = \| \mathbf{h} \| $ ä½¿ç”¨æ ‡é‡é‡åŒ–å™¨ $ Q_r $
- æ–¹å‘ $ \hat{\mathbf{h}} = \mathbf{h}/\|\mathbf{h}\| $ ä½¿ç”¨åˆ†é‡é‡åŒ–å™¨ $ Q_a $ å¹¶é‡æ–°å½’ä¸€åŒ–

è¿™æ ·å¯ä»¥ä¿ç•™å‘é‡çš„æ–¹å‘ä¿¡æ¯ï¼Œåœ¨ä½ç²¾åº¦ä¸‹ä»ç»´æŒè‰¯å¥½çš„å‡ ä½•ä¸€è‡´æ€§ï¼Œé¿å…ä¼ ç»Ÿé€å…ƒç´ é‡åŒ–å¸¦æ¥çš„æ–¹å‘æ¼‚ç§»ã€‚

#### ï¼ˆ2ï¼‰**Branch-Separated Quantization-Aware Training (QAT)**  
ç”±äº equivariant æ¨¡å‹é€šå¸¸åŒ…å« **invariantï¼ˆl=0ï¼‰** å’Œ **equivariantï¼ˆlâ‰¥1ï¼‰** ä¸¤ç§é€šé“ï¼Œå®ƒä»¬çš„æ•°æ®åˆ†å¸ƒå’Œä½œç”¨ä¸åŒï¼š
- å¯¹ scalar ç‰¹å¾é‡‡ç”¨å¯¹ç§°é‡åŒ–
- å¯¹ vector ç‰¹å¾ä½¿ç”¨ MDDQ
- å¼•å…¥**åˆ†é˜¶æ®µè®­ç»ƒç­–ç•¥**ï¼šå…ˆåªé‡åŒ– scalar åˆ†æ”¯ï¼Œå†å¯ç”¨ vector åˆ†æ”¯é‡åŒ–ï¼Œé˜²æ­¢æ—©æœŸè®­ç»ƒä¸ç¨³å®š

è¿™ç§å·®å¼‚åŒ–å¤„ç†æå‡äº†é‡åŒ–é²æ£’æ€§å’Œæœ€ç»ˆç²¾åº¦ã€‚

#### ï¼ˆ3ï¼‰**Robust Attention Normalization**  
åœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸­å¼•å…¥ **L2-normalization** åˆ° query å’Œ key å‘é‡ï¼š
- å°†ç‚¹ç§¯ $ \mathbf{q}_i \cdot \mathbf{k}_j $ è½¬æ¢ä¸ºä½™å¼¦ç›¸ä¼¼åº¦å½¢å¼
- ä½¿æ³¨æ„åŠ›å¾—åˆ†æœ‰ç•Œäº $[-1, 1]$ï¼Œå‡å°‘é‡åŒ–å™ªå£°å½±å“
- æå‡ä½ç²¾åº¦ä¸‹æ³¨æ„åŠ›æƒé‡çš„ç¨³å®šæ€§

è¿™ç›¸å½“äºå®ç°äº†â€œcosine attentionâ€ï¼Œå¢å¼ºäº†æ¨¡å‹å¯¹é‡åŒ–æ‰°åŠ¨çš„é²æ£’æ€§ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹æ³• | æ˜¯å¦æ”¯æŒ equivariance | æ˜¯å¦ç¨³å®š | æ•ˆç‡æå‡ | ç²¾åº¦ä¿æŒ |
|------|------------------------|----------|-----------|------------|
| é€šç”¨é‡åŒ–ï¼ˆDoReFa, PACTï¼‰ | âŒ å¿½ç•¥æ—‹è½¬ç»“æ„ | âŒ æ˜“ç ´åæ–¹å‘ | âœ… | âŒ |
| GNNä¸“ç”¨é‡åŒ–ï¼ˆDegree-Quantï¼‰ | âŒ ä»…å¤„ç†æ ‡é‡ | âš ï¸ ä¸ä¿å‘é‡æ–¹å‘ | âœ… | âš ï¸ |
| åè®­ç»ƒé‡åŒ–ï¼ˆPTQï¼‰ | âŒ | âŒ æ³¨æ„åŠ›ä¸ç¨³å®š | âœ… | âŒ |
| **æœ¬æ–‡æ–¹æ³•ï¼ˆMDDQ + Branch-QAT + L2-Normï¼‰** | âœ… æ˜¾å¼ä¿æŠ¤æ–¹å‘ | âœ… ç¨³å®šæ³¨æ„åŠ› | âœ…âœ…âœ… | âœ…âœ… |

> âœ… ä¼˜åŠ¿ï¼šé¦–æ¬¡å®ç°**åœ¨ä¸ç‰ºç‰²ç‰©ç†å¯¹ç§°æ€§å‰æä¸‹çš„é«˜æ•ˆä½æ¯”ç‰¹æ¨ç†**ï¼Œå…¼é¡¾ç²¾åº¦ã€é€Ÿåº¦ä¸å†…å­˜ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **QM9**ï¼šåŒ…å«çº¦ 134k ä¸ªå°åˆ†å­ï¼Œç”¨äºé¢„æµ‹å½¢æˆèƒ½ï¼ˆformation energyï¼‰ã€‚åˆ†å­å¤„äºå¹³è¡¡æ„å‹ï¼ŒåŠ›ä¸ºé›¶ã€‚
- **rMD17**ï¼šé‡è®¡ç®—ç‰ˆ MD17 æ•°æ®é›†ï¼Œæä¾›éå¹³è¡¡æ€åˆ†å­æ„å‹ï¼ŒåŒ…å«èƒ½é‡å’ŒåŸå­åŠ›æ ‡ç­¾ï¼Œæ›´é€‚åˆæµ‹è¯•åŠ›åœºå­¦ä¹ èƒ½åŠ›ã€‚
  - æµ‹è¯•äº† 7 ç§åˆ†å­ï¼šaspirin, ethanol, malonaldehyde, naphthalene, salicylic acid, toluene, uracil

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **æ¨¡å‹æ¶æ„åŸºç¡€**
- åŸºäº **So3krates** æ„å»ºçš„ transformer-style SO(3)-equivariant GNN
- ä½¿ç”¨ `e3nn` åº“å®ç° E(3) ç­‰å˜æ“ä½œ
- ç‰¹å¾ç»´åº¦ï¼šl=0 å’Œ l=1 å„ 64 ç»´ï¼Œå…± 6 å±‚å…¨å±€è‡ªæ³¨æ„åŠ›

#### **é‡åŒ–é…ç½®**
- æ‰€æœ‰æƒé‡å’Œæ¿€æ´»é‡åŒ–è‡³ **INT8**
- é¦–å±‚å’Œæœ«å±‚ä¿æŒ FP32
- ä½¿ç”¨ **fake quantization observer** è¿›è¡Œ QAT
- ä¼˜åŒ–å™¨ï¼šAdamï¼Œå­¦ä¹ ç‡ $1\times10^{-4}$ï¼Œ5 epoch warm-upï¼ˆä»…é‡åŒ– scalarï¼‰

#### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Energy MAE** | å½¢æˆèƒ½é¢„æµ‹è¯¯å·®ï¼ˆå•ä½ï¼šmeVï¼‰ |
| **Force MAE** | åŸå­åŠ›é¢„æµ‹è¯¯å·®ï¼ˆå•ä½ï¼šmeV/Ã…ï¼‰ |
| **Local Equivariance Error (LEE)** | è¡¡é‡æ¨¡å‹è¾“å‡ºæ˜¯å¦æ»¡è¶³æ—‹è½¬åå˜æ€§ï¼š<br>$ \text{LEE}(f; G, R) = \| f(R\cdot G) - R\cdot f(G) \| $ |
| **Inference Latency** | å•åˆ†å­æ¨ç†å»¶è¿Ÿï¼ˆCPU ä¸Šå¹³å‡ 1000 æ¬¡è¿è¡Œï¼‰ |
| **Speedup** | ç›¸å¯¹äº FP32 çš„åŠ é€Ÿæ¯” $ S = t_{\text{FP32}} / t_{\text{method}} $ |
| **Memory Reduction** | æ¨¡å‹å¤§å°å‹ç¼©æ¯” |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| **FP32 So3krates** | å…¨ç²¾åº¦ä¸Šé™ | å‚è€ƒåŸºå‡† |
| **PTQ-NequIP (INT8)** | åè®­ç»ƒé‡åŒ– | NequIP æ¨¡å‹è¿›è¡Œ PTQ |
| **So3krates + Degree-Quant** | GNNä¸“ç”¨QAT | åº”ç”¨ Degree-Quant æ–¹æ³• |
| **TorchAO W4A8** | æ›´æ¿€è¿›é‡åŒ– | 4-bit æƒé‡ + 8-bit æ¿€æ´» |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

| æ¨¡å‹ | Energy MAE (meV) | Force MAE (meV/Ã…) | LEE (meV/Ã…) | Speedup | Memory â†“ |
|------|------------------|--------------------|-------------|---------|----------|
| FP32 So3krates | 8.5 | 21.2 | ~0 | 1Ã— | 1Ã— |
| **Ours (INT8)** | **8.9** | **22.6** | **~2** | **2.37â€“2.73Ã—** | **~4Ã—** |
| PTQ-NequIP | 15.7 (+85%) | 35.3 (+66%) | ~5 | 2.73Ã— | ~4Ã— |
| Degree-Quant | 11.3 (+33%) | 28.0 (+32%) | ~3 | 0.73Ã— | ~4Ã— |

> âœ… ç»“è®ºï¼š**æˆ‘ä»¬çš„ INT8 æ¨¡å‹åœ¨ç²¾åº¦æŸå¤±æå°ï¼ˆ<5% èƒ½é‡è¯¯å·®ï¼Œ<7% åŠ›è¯¯å·®ï¼‰çš„æƒ…å†µä¸‹ï¼Œå®ç° 2.37â€“2.73Ã— æ¨ç†åŠ é€Ÿå’Œ ~4Ã— å†…å­˜å‹ç¼©**ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- **vs. PTQ-NequIP**ï¼šPTQ å¯¼è‡´ä¸¥é‡ç²¾åº¦é€€åŒ–ï¼ˆèƒ½é‡è¯¯å·®ç¿»å€ä»¥ä¸Šï¼‰ï¼Œä¸” LEE è¾¾åˆ° 5 meV/Ã…ï¼Œè¡¨æ˜å¯¹ç§°æ€§è¢«æ˜æ˜¾ç ´åã€‚
- **vs. Degree-Quant**ï¼šè™½æœ‰ä¸€å®šæ¢å¤ï¼Œä½†ä»ä¸å¦‚æœ¬æ–‡æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨ force é¢„æµ‹å’Œ equivariance ä¿æŒæ–¹é¢ã€‚
- **vs. TorchAO W4A8**ï¼šåœ¨ ethanol ä¸Šè¾¾åˆ° **1.74 meV èƒ½é‡è¯¯å·®** å’Œ **4.21 meV/Ã… åŠ›è¯¯å·®**ï¼Œç”šè‡³ä¼˜äº FP32 åŸºçº¿ï¼ˆ2.25 / 4.16ï¼‰ï¼Œå¹¶è·å¾— **2.73Ã— GPU åŠ é€Ÿ**ï¼Œæ˜¾ç¤º QAT å¯ä½œä¸ºæ­£åˆ™åŒ–æ‰‹æ®µã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

| æ¶ˆèæ¡ä»¶ | Energy MAE | Force MAE | LEE | å¤‡æ³¨ |
|----------|------------|-----------|-----|------|
| ä»… scalar åˆ†æ”¯é‡åŒ– | 8.7 | 21.0 | ~0 | å‡ ä¹æ— æŸï¼Œè¯´æ˜ scalar æ›´æ˜“é‡åŒ– |
| ä»… vector åˆ†æ”¯é‡åŒ– | 9.5 | 24.0 | â€” | ç²¾åº¦ä¸‹é™æ›´æ˜æ˜¾ |
| æ—  MDDQï¼ˆæ™®é€šå‘é‡é‡åŒ–ï¼‰ | >12 | >25 | â€” | æ˜¾ç¤º MDDQ è‡³å…³é‡è¦ |
| æ—  attention normalization | ~12 | â†‘â†‘ | â€” | æ³¨æ„åŠ›ä¸ç¨³å®šï¼Œè®­ç»ƒéš¾æ”¶æ•› |
| æ—  LEE æ­£åˆ™é¡¹ | 9.1 / 22.5 | â€” | ~4 meV/Ã… | LEE æ¶åŒ–ï¼Œè¯´æ˜æ­£åˆ™æœ‰åŠ©äºä¿æŒå¯¹ç§°æ€§ |

> ğŸ” å‘ç°ï¼šä¸‰ä¸ªç»„ä»¶ååŒä½œç”¨ï¼Œç¼ºä¸€ä¸å¯ï¼›å°¤å…¶æ˜¯ MDDQ å’Œ attention normalization å¯¹ä½æ¯”ç‰¹ç¨³å®šæ€§è‡³å…³é‡è¦ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **SO(3)-equivariant GNNs å¯ä»¥æˆåŠŸåœ°è¿›è¡Œ 8-bit é‡åŒ–è€Œä¸æ˜¾è‘—æŸå¤±ç²¾åº¦æˆ–ç ´åå¯¹ç§°æ€§**ã€‚
2. **ä¼ ç»Ÿçš„é‡åŒ–æ–¹æ³•æ— æ³•æœ‰æ•ˆå¤„ç†å‘é‡ç‰¹å¾çš„æ–¹å‘ä¿¡æ¯**ï¼Œå¿…é¡»è®¾è®¡ä¸“é—¨æœºåˆ¶ï¼ˆå¦‚ MDDQï¼‰æ¥ä¿æŠ¤å‡ ä½•ç»“æ„ã€‚
3. **æ³¨æ„åŠ›æœºåˆ¶æ˜¯é‡åŒ–è„†å¼±æ€§çš„ä¸»è¦æ¥æºä¹‹ä¸€**ï¼Œé€šè¿‡ L2-normalization å¯æ˜¾è‘—å¢å¼ºå…¶é²æ£’æ€§ã€‚
4. **branch-separated QAT + staged training** æ˜¯ç¨³å®šè®­ç»ƒçš„å…³é”®ï¼Œé¿å…æ—©æœŸå‡ ä½•ä¿¡æ¯å´©æºƒã€‚
5. **INT8 æ¨¡å‹å¯åœ¨ CPU ä¸Šå®ç° 2.37â€“2.73Ã— æ¨ç†åŠ é€Ÿï¼Œå†…å­˜å‡å°‘ ~4Ã—**ï¼Œé€‚åˆéƒ¨ç½²åœ¨ç§»åŠ¨ç«¯æˆ–åµŒå…¥å¼ç³»ç»Ÿã€‚
6. **æ›´æ¿€è¿›çš„ W4A8 é‡åŒ–ä¸ä»…å¯è¡Œï¼Œæœ‰æ—¶è¿˜èƒ½ç•¥å¾®æå‡ç²¾åº¦**ï¼Œå¯èƒ½å›  QAT èµ·åˆ°æ­£åˆ™åŒ–ä½œç”¨ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

- å½“å‰æ–¹æ³•ä¸»è¦éªŒè¯äº **l â‰¤ 1** çš„è¡¨ç¤ºï¼ˆå³æœ€å¤šä½¿ç”¨å‘é‡ç‰¹å¾ï¼‰ï¼Œå°šæœªæ‰©å±•åˆ°æ›´é«˜é˜¶å¼ é‡ï¼ˆå¦‚ l=2,3ï¼‰ã€‚
- æ‰€æœ‰å®éªŒåŸºäº **å°åˆ†å­ä½“ç³»**ï¼Œæœªåœ¨è›‹ç™½è´¨ã€æ™¶ä½“ç­‰å¤æ‚ç³»ç»Ÿä¸­æµ‹è¯•ã€‚
- è™½ç„¶ç†è®ºåŠ é€Ÿå¯è¾¾ 4Ã—ï¼ˆINT8ï¼‰ï¼Œä½†å®é™…åŠ é€Ÿçº¦ä¸º 2.37â€“2.73Ã—ï¼Œä»æœ‰ä¼˜åŒ–ç©ºé—´ï¼ˆå¦‚ç¡¬ä»¶é€‚é…ï¼‰ã€‚
- LEE è™½ç„¶å¯ç”¨äºè¡¡é‡ equivariance é”™è¯¯ï¼Œä½†ä»æ˜¯ç»éªŒæŒ‡æ ‡ï¼Œç¼ºä¹ä¸¥æ ¼çš„æ•°å­¦ä¿è¯ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ‰©å±•åˆ°æ›´é«˜é˜¶è¡¨ç¤ºï¼ˆl â‰¥ 2ï¼‰**ï¼Œé€‚ç”¨äºæ›´å¤æ‚çš„ç‰©ç†åœºå»ºæ¨¡ï¼ˆå¦‚ç”µå››æçŸ©ã€ç£å“åº”ï¼‰ã€‚
2. **åº”ç”¨äºå¤§å‹ç”Ÿç‰©åˆ†å­å’Œå‘¨æœŸæ€§ææ–™ç³»ç»Ÿ**ï¼Œæ¢ç´¢å…¶åœ¨è¯ç‰©è®¾è®¡å’Œææ–™æ¨¡æ‹Ÿä¸­çš„å®ç”¨æ€§ã€‚
3. **ä¸ä¸“ç”¨ä½æ¯”ç‰¹ç¡¬ä»¶åŠ é€Ÿå™¨è”åˆè®¾è®¡**ï¼ˆco-designï¼‰ï¼Œè¿›ä¸€æ­¥é‡Šæ”¾æ€§èƒ½æ½œåŠ›ã€‚
4. **æ¨å¹¿åˆ°å…¶ä»–å¯¹ç§°ç¾¤**ï¼Œå¦‚ SE(3)ã€SU(n) æˆ–æ™¶æ ¼å¯¹ç§°ç¾¤ï¼Œæ„å»ºé€šç”¨çš„ symmetry-preserving quantization æ¡†æ¶ã€‚
5. **æ¢ç´¢åŠ¨æ€é‡åŒ–æˆ–æ··åˆç²¾åº¦ç­–ç•¥**ï¼Œæ ¹æ®ä¸åŒå±‚æˆ–åˆ†æ”¯è‡ªåŠ¨åˆ†é…æ¯”ç‰¹å®½åº¦ã€‚

---

> ğŸ§ª æ€»ç»“ï¼šæœ¬æ–‡æ˜¯é¦–ä¸ªç³»ç»Ÿç ”ç©¶ **SO(3)-equivariant GNNs é‡åŒ–** çš„å·¥ä½œï¼Œæå‡ºçš„ **MDDQ + Branch-QAT + Robust Attention** ä¸‰é‡ç­–ç•¥ï¼ŒæˆåŠŸå®ç°äº†é«˜ç²¾åº¦ã€é«˜æ•ˆç‡ã€å¼ºå¯¹ç§°æ€§çš„ä½æ¯”ç‰¹æ¨ç†ï¼Œä¸ºå¯¹ç§°æ„ŸçŸ¥æ¨¡å‹çš„å®é™…éƒ¨ç½²é“ºå¹³é“è·¯ã€‚

</details>

---

### 14. [ElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systems](https://arxiv.org/abs/2601.00994)

**Authors**: Michael Bao  
**Category**: cs.AI  
**Published**: 2026-01-06  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.00994v1  

#### Abstract
This paper introduces ElecTwit, a simulation framework designed to study persuasion within multi-agent systems, specifically emulating the interactions on social media platforms during a political election. By grounding our experiments in a realistic environment, we aimed to overcome the limitations...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡ã€ŠElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systemsã€‹æ ¸å¿ƒæ€»ç»“**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
è¯¥ç ”ç©¶æ—¨åœ¨è§£å†³å½“å‰**å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆmulti-agent systemsï¼‰ä¸­å…³äºè¯´æœåŠ›ï¼ˆpersuasionï¼‰ç ”ç©¶ç¼ºä¹ç°å®æ€§**çš„é—®é¢˜ã€‚ä»¥å¾€çš„ç ”ç©¶å¸¸ä¾èµ–äºç®€åŒ–ç¯å¢ƒï¼ˆå¦‚åŸºäºæ¸¸æˆçš„æ¨¡æ‹Ÿï¼Œä¾‹å¦‚ *Among Us*ï¼‰ï¼Œè¿™äº›åœºæ™¯è™½ç„¶å¯æ§ï¼Œä½†éš¾ä»¥åæ˜ çœŸå®ç¤¾ä¼šåª’ä½“ç¯å¢ƒä¸­å¤æ‚çš„äº¤äº’åŠ¨æ€ï¼Œé™åˆ¶äº†å…¶åœ¨ç°å®ä¸–ç•Œä¸­çš„é€‚ç”¨æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯**
ä½œè€…æå‡ºäº† **ElecTwit** â€”â€”ä¸€ä¸ªåŸºäºç°å®æ”¿æ²»é€‰ä¸¾åœºæ™¯çš„**å¤šæ™ºèƒ½ä½“ç¤¾ä¼šæ¨¡æ‹Ÿæ¡†æ¶**ï¼Œç”¨äºç ”ç©¶ LLM é©±åŠ¨çš„ agent åœ¨ç¤¾äº¤åª’ä½“å¹³å°ä¸Šçš„è¯´æœè¡Œä¸ºã€‚  
ElecTwit æ¨¡æ‹Ÿäº†ç±»ä¼¼ Xï¼ˆTwitterï¼‰çš„ç¤¾äº¤å¹³å°ï¼ŒåŒ…å«å‘å¸–ã€å›å¤ã€ç‚¹èµç­‰æœºåˆ¶ï¼Œå¹¶å¼•å…¥ä»¥ä¸‹å…³é”®è®¾è®¡ï¼š
- **çœŸå®èƒŒæ™¯å»ºæ¨¡**ï¼šä¸ºæ¯ä¸ª agent èµ‹äºˆåŸºäº Pew Research æ•°æ®çš„æ”¿æ²»ç«‹åœºï¼ˆ6 ä¸ªç»´åº¦ï¼‰å’Œâ€œBig 5â€äººæ ¼ç‰¹è´¨ï¼Œå¢å¼ºè¡Œä¸ºå¤šæ ·æ€§ã€‚
- **äº‹ä»¶é©±åŠ¨æœºåˆ¶**ï¼šé€šè¿‡ `eventor` agent å¼•å…¥æ–°é—»ç±»äº‹ä»¶ï¼ˆåŒ…æ‹¬æ½œåœ¨è™šå‡ä¿¡æ¯ï¼‰ï¼Œæµ‹è¯• agent å¯¹èˆ†è®ºå˜åŒ–çš„å“åº”ã€‚
- **æ—¥è®°è®°å¿†ç³»ç»Ÿ**ï¼šagent ç»´æŠ¤æ—¥å¿—ä»¥å®ç°é•¿æœŸè®°å¿†ï¼Œæ”¯æŒæ›´è¿è´¯çš„è¡Œä¸ºæ¼”åŒ–ã€‚
- **æŠ•ç¥¨å†³ç­–æœºåˆ¶**ï¼šæœ€ç»ˆé€šè¿‡æ¨¡æ‹ŸæŠ•ç¥¨è¡¡é‡ persuasion æ•ˆæœã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ Among Us æ¸¸æˆæ¡†æ¶ï¼‰ | ElecTwit |
|------|-------------------------------|---------|
| **ç¯å¢ƒçœŸå®æ€§** | æŠ½è±¡ã€è§„åˆ™å—é™çš„æ¸¸æˆåœºæ™¯ | æ¥è¿‘çœŸå®ç¤¾äº¤åª’ä½“çš„å¼€æ”¾äº’åŠ¨ç¯å¢ƒ |
| **è¡Œä¸ºåŠ¨æœº** | ä»»åŠ¡å¯¼å‘ï¼ˆèµ¢æ¸¸æˆï¼‰ | æ”¿æ²»åå¥½ + ä¸ªæ€§é©±åŠ¨ï¼Œæ›´å…·ç¤¾ä¼šä»£è¡¨æ€§ |
| **è¯„ä¼°å¹¿åº¦** | èšç„¦æ¬ºéª—æˆ–ä¿¡ä»» | å…¨é¢åˆ†æ 25 ç§ persuasion techniques |
| **å¯æ‰©å±•æ€§** | å°è§„æ¨¡ã€å°é—­é€»è¾‘ | å¼€æºã€æ¨¡å—åŒ–ã€æ”¯æŒå¤§è§„æ¨¡ä»¿çœŸ |

> âœ… **åˆ›æ–°ç‚¹æ€»ç»“**ï¼šé¦–æ¬¡å°† persuasion ç ”ç©¶ç½®äº**é«˜ä¿çœŸç¤¾ä¼šæ¨¡æ‹Ÿç¯å¢ƒ**ä¸­ï¼Œç»“åˆå¿ƒç†å­¦ä¸æ”¿æ²»å­¦ç†è®ºæ„å»º agent èƒŒæ™¯ï¼Œçªç ´äº† game-based simulation çš„å±€é™æ€§ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ¨¡å‹ä¸ä»£ç†è§’è‰²**
æœªä½¿ç”¨ä¼ ç»Ÿæ„ä¹‰ä¸Šçš„â€œæ•°æ®é›†â€ï¼Œè€Œæ˜¯æ„å»ºäº†ä¸€ä¸ª**åŸºäº LLM çš„å¤šæ™ºèƒ½ä½“ä»¿çœŸç¯å¢ƒ**ï¼Œæ¶‰åŠä»¥ä¸‹ç»„ä»¶ï¼š

#### **Agent è§’è‰²**
- **Voter Agents**ï¼ˆ16 åï¼‰ï¼šå¯å‘å¸–ã€å›å¤ã€ç‚¹èµã€æŠ•ç¥¨ã€‚
- **Candidate Agents**ï¼ˆ2 åï¼‰ï¼šç«é€‰è€…ï¼Œç›®æ ‡æ˜¯äº‰å–é€‰ç¥¨ã€‚
- **Eventor Agent**ï¼šä»…ç”Ÿæˆå¤–éƒ¨äº‹ä»¶ï¼ˆå¦‚ä¸‘é—»æ–°é—»ï¼‰ï¼Œä¸å‚ä¸äº’åŠ¨ã€‚

#### **LLM æ¨¡å‹åˆ—è¡¨**
å…±ä½¿ç”¨ 8 ä¸ª LLMï¼Œæ¶µç›–é—­æºä¸å¼€æºï¼š
- `gpt-4.1-mini`, `gemini-2.5-flash`, `claude-3.5-haiku`, `deepseek-chat-v3-0324`, `qwq-32b`, `grok-3-mini`, `kimi-k2`, `devstral-medium`

å…¶ä¸­ï¼š
- æ‰€æœ‰ voter å¯æ¥è‡ªä»»æ„ 8 ä¸ªæ¨¡å‹ï¼›
- å€™é€‰äººä»…æµ‹è¯•å‰ 3 ä¸ªï¼ˆåŠ ç²—ï¼‰ï¼›
- `eventor` å›ºå®šä¸º `google/gemini-2.5-flash`ï¼›
- æ‰€æœ‰æ¨¡å‹è®¾ç½® temperature=0ã€‚

### **å®éªŒè®¾ç½®**
- **æ—¶é—´ç»“æ„**ï¼šæ¯è½®æ¨¡æ‹Ÿä¸€å¤©ï¼Œåˆ†ä¸º 9 ä¸ªæ—¶é—´æ­¥ï¼ˆ9amâ€“5pmï¼‰ï¼Œæ¯å°æ—¶æ‰€æœ‰ agent åŒæ—¶è¡ŒåŠ¨ã€‚
- **è¡ŒåŠ¨é™åˆ¶**ï¼šæ¯ä¸ª agent æœ€å¤šæ‰§è¡Œ 10 æ¬¡æ“ä½œï¼ˆpost/reply/likeï¼‰ã€‚
- **äº¤äº’æœºåˆ¶**ï¼šæ‰€æœ‰ posts/comments é™ 280 å­—ç¬¦ï¼›å¿…é¡»å¼•ç”¨æ­£ç¡® ID æ‰èƒ½ reply/likeã€‚
- **Feed è®¾è®¡**ï¼šç»Ÿä¸€ feedï¼ˆéä¸ªæ€§åŒ–ï¼‰ï¼Œé¿å…å†·å¯åŠ¨é—®é¢˜ã€‚
- **èƒŒæ™¯ç”Ÿæˆ**ï¼šæ”¿æ²»ç«‹åœºä¸äººæ ¼ç‰¹è´¨éšæœºåˆå§‹åŒ–ï¼Œå€™é€‰äººä¹‹é—´å¼ºåˆ¶ä½ç›¸ä¼¼åº¦ï¼ˆcosine similarity < -0.75ï¼‰ã€‚

### **è¯„ä¼°æŒ‡æ ‡**
- **Persuasion Technique åˆ†æ**ï¼š
  - ä½¿ç”¨ç‹¬ç«‹ LLM å¯¹æ‰€æœ‰ posts å’Œ comments è¿›è¡Œæ ‡æ³¨ï¼Œåˆ†ç±»è‡³ **25 ç§ persuasion techniques**ï¼ˆæºè‡ª [8] Among Them æ¡†æ¶ï¼‰ã€‚
  - å…è®¸å¤šæ ‡ç­¾ï¼ˆä¸€æ¡æ¶ˆæ¯å¯å«å¤šç§æŠ€å·§ï¼‰ã€‚
- **é€‰ä¸¾ç»“æœ**ï¼šæœ€ç»ˆå¾—ç¥¨æ•°ä½œä¸º persuasion æˆæ•ˆçš„é—´æ¥æŒ‡æ ‡ã€‚
- **ç½‘ç»œåˆ†æ**ï¼šæ„å»º reply/like ç½‘ç»œå›¾ï¼Œåˆ†æäº’åŠ¨æ¨¡å¼ï¼ˆå¦‚ echo chamber ç°è±¡ï¼‰ã€‚
- **Diary å†…å®¹åˆ†æ**ï¼šæå–é•¿æœŸè®°å¿†ä¸ç­–ç•¥æ¼”å˜ã€‚

### **å®éªŒåˆ†ç»„**
| ç»„åˆ« | æè¿° |
|------|------|
| **Same Seed Group**ï¼ˆ6 æ¬¡ï¼‰ | å›ºå®šéšæœºç§å­ï¼Œæ›´æ¢ candidate æ¨¡å‹ â†’ åˆ†æ candidate è¡Œä¸ºå·®å¼‚ |
| **Different Seed Group**ï¼ˆ6 æ¬¡ï¼‰ | å›ºå®š voter æ¨¡å‹ç»„åˆï¼Œä»…æ”¹å˜ seed â†’ åˆ†æèƒŒæ™¯ä¸ voter è¡Œä¸ºå…³ç³» |

> âš ï¸ æ³¨ï¼šä¸¤ç»„å…±äº«éƒ¨åˆ†è¿è¡Œï¼Œæ€» 11 åœºæ¨¡æ‹Ÿã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **(1) é€‰ä¸¾ç»“æœï¼ˆFig. 2ï¼‰**
- åœ¨ *same seed* ç»„ä¸­ï¼š
  - `Gemini 2.5 Flash` å‚ä¸ 4 æ¬¡ï¼Œèµ¢å¾— 4 æ¬¡ï¼›
  - `GPT-4.1-mini` èµ¢ 2 æ¬¡ï¼›
  - `Claude-3.5-Haiku` 0 èƒœã€‚
- åœ¨ *different seed* ç»„ä¸­ï¼š
  - `Gemini` ä¸ `GPT-4.1-mini` å„èƒœ 2 åœºã€å¹³ 2 åœºã€è¾“ 2 åœºï¼›
  - è¡¨æ˜ `Gemini` åœ¨å›ºå®šæ¡ä»¶ä¸‹è¡¨ç°æ›´å¼ºï¼Œå¯èƒ½å…·å¤‡æ›´é«˜ persuasion èƒ½åŠ›ã€‚

#### **(2) Persuasion Techniques ä½¿ç”¨æƒ…å†µ**
- æ€»è®¡è¯†åˆ«å‡º **125,254 ä¸ª persuasion tags**ï¼Œæ¥è‡ª 43,037 æ¡æ¶ˆæ¯ï¼ˆposts + commentsï¼‰ã€‚
- æœ€å¸¸ç”¨çš„äº”ç§ techniqueï¼ˆè·¨ä¸¤ç»„ä¸€è‡´ï¼‰ï¼š
  1. **Appeal to Credibility**ï¼ˆ18,126 æ¬¡ï¼‰
  2. **Appeal to Logic**
  3. **Appeal to Emotion**
  4. **Vagueness**
  5. **Distraction**

> ğŸ”¹ `GPT-4.1-mini` æ˜¯ **Appeal to Credibility** ä½¿ç”¨æœ€å¤šçš„æ¨¡å‹ï¼›  
> ğŸ”¹ `Gemini 2.5 Flash` äº§ç”Ÿæœ€å¤š persuasion tagsï¼ˆå› å…¶å‘è¨€æœ€å¤šï¼‰ï¼›  
> ğŸ”¹ `Claude-3.5-Haiku` å’Œ `Grok-3-mini` è¾“å‡ºæœ€å°‘ï¼Œå°¤å…¶ä½œä¸º candidate æ—¶å‡ ä¹æ²‰é»˜ã€‚

#### **(3) åŠ¨ä½œé¢‘ç‡ç»Ÿè®¡ï¼ˆFig. 4ï¼‰**
- `Gemini 2.5 Flash` å‘è¨€æœ€å¤šï¼ˆposts + repliesï¼‰ï¼Œå…¶æ¬¡æ˜¯ `GPT-4.1-mini`ï¼›
- `Claude-3.5-Haiku` å’Œ `Gemini` ä½œä¸º voter æ—¶åŠ¨ä½œåå°‘ï¼›
- å¹³å‡æ¯åœºçº¦ 6,700 postsï¼Œ36,000+ commentsï¼Œ30,000+ likesã€‚

#### **(4) èƒŒæ™¯å½±å“åˆ†æï¼ˆFig. 3ï¼‰**
- æŠ•ç¥¨è€…ä¸å…¶æ‰€æ”¯æŒå€™é€‰äººçš„èƒŒæ™¯ç›¸ä¼¼åº¦å¹³å‡æ¥è¿‘ 0ï¼›
- è¯´æ˜ **agent çš„æŠ•ç¥¨é€‰æ‹©ä¸å…¶èƒŒæ™¯æ— æ˜æ˜¾ç›¸å…³æ€§**ï¼›
- ä¸ Fig. 2 ä¸­æŸäº›å€™é€‰äººæŒç»­è·èƒœçŸ›ç›¾ï¼Œæš—ç¤ºæ¨¡å‹è‡ªèº«èƒ½åŠ›æ¯”èƒŒæ™¯åŒ¹é…æ›´é‡è¦ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. âœ… **LLMs æ™®éä½¿ç”¨å¤šç§ persuasion techniques**ï¼šæ‰€æœ‰æµ‹è¯•æ¨¡å‹å‡ä½¿ç”¨äº†å…¨éƒ¨ 25 ç§æŠ€å·§ä¸­çš„ç»å¤§å¤šæ•°ï¼Œè¿œè¶…æ­¤å‰ç ”ç©¶æŠ¥é“èŒƒå›´ã€‚
2. âœ… **æ¨¡å‹æ¶æ„æ˜¾è‘—å½±å“ persuasion è¡Œä¸º**ï¼šä¸åŒ LLM åœ¨æŠ€å·§é€‰æ‹©ã€è¾“å‡ºé‡ã€äº’åŠ¨ç§¯ææ€§ä¸Šå­˜åœ¨å·¨å¤§å·®å¼‚ï¼ˆå¦‚ `Gemini` æ›´æ´»è·ƒï¼Œ`Claude` æ›´ä¿å®ˆï¼‰ã€‚
3. âœ… **å‡ºç° emergent social phenomena**ï¼š
   - â€œ**Kernel of Truth**â€ æ¶ˆæ¯ï¼šåŒ…å«éƒ¨åˆ†äº‹å®ä½†æ•´ä½“è¯¯å¯¼çš„ä¿¡æ¯ã€‚
   - â€œ**Ink obsession**â€ï¼šagents è‡ªå‘å½¢æˆå£å· â€œ#InkOrBustâ€ï¼Œè¦æ±‚å€™é€‰äººæä¾›ä¹¦é¢æ”¿ç­–æ‰¿è¯ºï¼ˆâ€œinkâ€æŒ‡ç­¾åæ–‡ä»¶ï¼‰ï¼Œå¦åˆ™æ‹’ç»æŠ•ç¥¨ã€‚
4. âœ… **æœªè§‚å¯Ÿåˆ°å…¸å‹ echo chambers**ï¼šç›¸åï¼Œagents æ›´å€¾å‘äºä¸èƒŒæ™¯ä¸åŒçš„ others äº’åŠ¨ï¼ˆreply æ›´é¢‘ç¹ï¼‰ï¼ŒæŒ‘æˆ˜äººç±»è¡Œä¸ºç›´è§‰ã€‚
5. âœ… **ç»Ÿä¸€ feed ä¸‹ä»èƒ½äº§ç”ŸæåŒ–è¨€è®º**ï¼šå°½ç®¡æ‰€æœ‰äººçœ‹åˆ°ç›¸åŒä¿¡æ¯æµï¼Œä½† polarized messaging ä¾ç„¶æ™®éå­˜åœ¨ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
| å±€é™ | è¯´æ˜ |
|------|------|
| **Uniform Feed** | ç¼ºä¹ä¸ªæ€§åŒ–æ¨èç®—æ³•ï¼Œæ— æ³•æ¨¡æ‹Ÿ filter bubble æ•ˆåº” |
| **LLM-only Evaluation** | ä½¿ç”¨å¦ä¸€ä¸ª LLM è¿›è¡Œ persuasion æ ‡æ³¨ï¼Œå¯èƒ½å­˜åœ¨åå·® |
| **Temperature=0** | ç¼ºå°‘éšæœºæ€§ï¼ŒæŠ‘åˆ¶ creativity ä¸å¤šæ ·æ€§ |
| **å°æ ·æœ¬å®éªŒ** | ä»… 11 åœºæ¨¡æ‹Ÿï¼Œä¸”æœªå……åˆ†æ¢ç´¢ voter/candidate æ¨¡å‹ç»„åˆç©ºé—´ |
| **æ— çœŸå®äººç±»å‚ä¸** | ç»“æœæ˜¯å¦é€‚ç”¨äº human-agent interaction æœªçŸ¥ |

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **å¼•å…¥ä¸ªæ€§åŒ– timeline**ï¼šåŠ å…¥æ¨èç³»ç»Ÿæ¨¡æ‹Ÿ echo chamber ä¸ misinformation ä¼ æ’­ã€‚
2. **Human-in-the-loop studies**ï¼šè®©çœŸäººå‚ä¸æ¨¡æ‹Ÿï¼ŒéªŒè¯ LLM agent çš„ persuasivenessã€‚
3. **æ‰©å¤§æ¨¡å‹ç»„åˆä¸æ¸©åº¦å‚æ•°**ï¼šæµ‹è¯•ä¸åŒ temperature å¯¹ persuasion ç­–ç•¥çš„å½±å“ã€‚
4. **å¢åŠ  agent æ•°é‡ä¸å¤æ‚åº¦**ï¼šæ„å»ºæ›´å¤§è§„æ¨¡ç¤¾ä¼šæ¨¡æ‹Ÿï¼ˆå¦‚åŸå¸‚çº§ï¼‰ã€‚
5. **é›†æˆ multimodal input/output**ï¼šæ”¯æŒå›¾åƒã€è§†é¢‘ç­‰å†…å®¹å½¢å¼ã€‚
6. **å¼€æºæ¨å¹¿**ï¼šé¡¹ç›®ä»£ç å·²å…¬å¼€ï¼ˆGitHub: [`tcmmichaelb139/ai-electwit`](https://github.com/tcmmichaelb139/ai-electwit)ï¼‰ï¼Œé¼“åŠ±ç¤¾åŒºæ‰©å±•ã€‚

---

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> **ElecTwit æ˜¯é¦–ä¸ªå°† persuasion ç ”ç©¶åµŒå…¥é«˜ä¿çœŸç¤¾ä¼šæ¨¡æ‹Ÿç¯å¢ƒçš„å·¥ä½œï¼Œæ­ç¤ºäº† LLM agents åœ¨çœŸå®è¯­å¢ƒä¸‹çš„å¤æ‚è¯´æœè¡Œä¸ºä¸ emergent ç¤¾ä¼šç°è±¡ï¼Œä¸ºæœªæ¥ AI ç¤¾ä¼šå½±å“è¯„ä¼°æä¾›äº†é‡è¦å·¥å…·ã€‚**

</details>

---

### 15. [A New Benchmark for the Appropriate Evaluation of RTL Code Optimization](https://arxiv.org/abs/2601.01765)

**Authors**: Yao Lu, Shang Liu, Hangan Zhou, Wenji Fang, Qijun Zhang, Zhiyao Xie  
**Category**: cs.AI  
**Published**: 2026-01-06  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.01765v1  

#### Abstract
The rapid progress of artificial intelligence increasingly relies on efficient integrated circuit (IC) design. Recent studies have explored the use of large language models (LLMs) for generating Register Transfer Level (RTL) code, but existing benchmarks mainly evaluate syntactic correctness rather ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šA New Benchmark for the Appropriate Evaluation of RTL Code Optimization

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰åŸºäº **Large Language Models (LLMs)** çš„ RTL ä»£ç ç”Ÿæˆç ”ç©¶è™½ç„¶å–å¾—äº†è¿›å±•ï¼Œä½†ç°æœ‰çš„åŸºå‡†ï¼ˆå¦‚ VerilogEvalã€RTLLMï¼‰ä¸»è¦å…³æ³¨è¯­æ³•æ­£ç¡®æ€§å’ŒåŠŸèƒ½ç­‰ä»·æ€§ï¼Œ**ç¼ºä¹å¯¹ RTL ä¼˜åŒ–è´¨é‡çš„æœ‰æ•ˆè¯„ä¼°**ã€‚ç‰¹åˆ«æ˜¯ï¼Œåœ¨èŠ¯ç‰‡è®¾è®¡ä¸­è‡³å…³é‡è¦çš„ **PPAï¼ˆPower, Performance, Areaï¼‰æŒ‡æ ‡** å¾ˆå°‘è¢«ç³»ç»Ÿåœ°è¡¡é‡ã€‚

æ­¤å¤–ï¼Œå·²æœ‰çš„ä¸€äº› RTL ä¼˜åŒ–åŸºå‡†ï¼ˆå¦‚ [26]ï¼‰å­˜åœ¨ä¸¥é‡ç¼ºé™·ï¼š
- **ä¸ç°å®çš„è®¾è®¡æ¨¡å¼**ï¼šå­ä¼˜ RTL åŒ…å«äººä¸ºæ„é€ çš„å†—ä½™æ“ä½œï¼ˆå¦‚ `s1 + 0` æˆ– `s1 * 1`ï¼‰ï¼Œè¿™äº›åœ¨å®é™…å·¥ç¨‹ä¸­å‡ ä¹ä¸ä¼šå‡ºç°ï¼›
- **åˆæˆå·¥å…·è¿‡äºç®€å•**ï¼šä¾èµ– Yosys ç­‰å¼€æºå·¥å…·è¿›è¡Œè¯„ä¼°ï¼Œè€Œå·¥ä¸šçº§å•†ä¸šå·¥å…·ï¼ˆå¦‚ Synopsys Design Compilerï¼‰èƒ½è½»æ˜“æ¶ˆé™¤è¿™äº›â€œä½çº§â€å†—ä½™ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœå¤±çœŸï¼›
- **è¯„ä¼°ç»´åº¦å•ä¸€**ï¼šä»…å…³æ³¨é¢ç§¯ï¼Œå¿½ç•¥åŠŸè€—å’Œæ—¶åºç­‰å…³é”®æŒ‡æ ‡ã€‚

å› æ­¤ï¼Œ**å¦‚ä½•å…¬å¹³ã€çœŸå®åœ°è¯„ä¼° LLM åœ¨ RTL ä¼˜åŒ–ä¸Šçš„èƒ½åŠ›æˆä¸ºä¸€ä¸ªå¼€æ”¾ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜**ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
æœ¬æ–‡æå‡ºäº† **RTL-OPT** â€”â€”ä¸€ä¸ªä¸“ä¸ºè¯„ä¼° LLM åœ¨ RTL ä¼˜åŒ–æ–¹é¢èƒ½åŠ›è€Œè®¾è®¡çš„æ–°åŸºå‡†ã€‚

#### ä¸»è¦åˆ›æ–°åŒ…æ‹¬ï¼š
1. **é«˜è´¨é‡ã€çœŸå®çš„æ‰‹å·¥æ„å»ºä»»åŠ¡é›†**
   - åŒ…å« **36 ä¸ªæ‰‹å†™ï¼ˆhandcraftedï¼‰çš„ RTL è®¾è®¡ä»»åŠ¡**ï¼Œè¦†ç›–ç»„åˆé€»è¾‘ã€æµæ°´çº¿æ•°æ®è·¯å¾„ã€æœ‰é™çŠ¶æ€æœºï¼ˆFSMï¼‰ã€å­˜å‚¨å™¨æ¥å£ç­‰å¤šç§å®ç°ç±»åˆ«ã€‚
   - æ¯ä¸ªä»»åŠ¡æä¾›ä¸€å¯¹ RTL ä»£ç ï¼šä¸€ä¸ª**å­ä¼˜ç‰ˆæœ¬**ï¼ˆsuboptimalï¼‰å’Œä¸€ä¸ªç”±ä¸“å®¶æ‰‹å·¥ä¼˜åŒ–çš„**é»„é‡‘å‚è€ƒç‰ˆæœ¬**ï¼ˆoptimized/golden referenceï¼‰ã€‚
   - å­ä¼˜è®¾è®¡å¹¶ééšæ„é™è´¨ï¼Œè€Œæ˜¯**é—æ¼äº†è¡Œä¸šä¸­å·²è¢«éªŒè¯æœ‰æ•ˆçš„ä¼˜åŒ–æœºä¼š**ï¼Œç¡®ä¿å…¶å…·å¤‡çœŸå®çš„æ”¹è¿›ç©ºé—´ã€‚

2. **åæ˜ å·¥ä¸šå®è·µçš„ä¼˜åŒ–æ¨¡å¼**
   - æ‰€æœ‰ä¼˜åŒ–å‡åŸºäº**è¡Œä¸šæ ‡å‡†çš„æœ€ä½³å®è·µ**ï¼ŒåŒ…æ‹¬ï¼š
     - Bit-width Optimization
     - Precomputation & LUT Conversion
     - Operator Strength Reduction
     - Control Simplification
     - Resource Sharing
     - State Encoding Optimization
   - è¿™äº›å˜æ¢å³ä½¿ç»è¿‡å…ˆè¿›ç»¼åˆå·¥å…·å¤„ç†ä»èƒ½ä¿ç•™æ”¶ç›Šï¼Œé¿å…è¢«è‡ªåŠ¨ä¼˜åŒ–æŠ¹å¹³ã€‚

3. **é›†æˆåŒ–è‡ªåŠ¨åŒ–è¯„ä¼°æ¡†æ¶**
   - æä¾›å®Œæ•´çš„ EDA å·¥å…·é“¾æ”¯æŒï¼ŒåŒ…æ‹¬ï¼š
     - ä½¿ç”¨ **Synopsys Design Compiler (DC)** å’Œ **Yosys** è¿›è¡Œç»¼åˆï¼›
     - ä½¿ç”¨ **Formality** è¿›è¡Œå½¢å¼ç­‰ä»·æ€§æ£€æŸ¥ï¼ˆfunctional equivalence checkingï¼‰ï¼›
     - ä½¿ç”¨ **VCS** è¿›è¡ŒåŠ¨æ€ä»¿çœŸéªŒè¯å¤æ‚æ—¶åºè¡Œä¸ºï¼›
     - è¾“å‡ºæ ‡å‡†åŒ–çš„ **PPA æŠ¥å‘Š**ï¼ˆPower, Performance[WNS/TNS], Areaï¼‰ã€‚

4. **å¤šç»´åº¦ã€é²æ£’çš„è¯„ä¼°åè®®**
   - æ”¯æŒå¤šç§ç»¼åˆé…ç½®ï¼ˆå¦‚ `compile`, `compile_ultra`ï¼‰å’Œæ—¶é’Ÿçº¦æŸï¼ˆ1ns / 0.1nsï¼‰ï¼Œä»¥æµ‹è¯•ä¸åŒå‹åŠ›ä¸‹çš„ä¼˜åŒ–æœ‰æ•ˆæ€§ï¼›
   - ç»¼åˆè€ƒè™‘ PPA ä¹‹é—´çš„æƒè¡¡ï¼ˆtrade-offsï¼‰ï¼Œè€Œéå•ä¸€æŒ‡æ ‡æå‡å³åˆ¤å®šæˆåŠŸã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰åŸºå‡† ([26]) | æœ¬æ–‡æå‡ºçš„ RTL-OPT |
|------|------------------|--------------------|
| **è®¾è®¡çœŸå®æ€§** | äººä¸ºæ„é€ ã€éå…¸å‹å†—ä½™ | æ¥è‡ªçœŸå®è®¾è®¡åœºæ™¯çš„ä¼˜åŒ–æœºä¼š |
| **ä¼˜åŒ–å½±å“æŒä¹…æ€§** | æ˜“è¢« DC ç­‰å¼ºç»¼åˆå™¨æ¶ˆé™¤ | å³ä½¿åœ¨ `compile_ultra` ä¸‹ä»æœ‰æ•ˆæœ |
| **è¯„ä¼°å·¥å…·** | å¤šç”¨ Yosysï¼ˆå¼±ä¼˜åŒ–ï¼‰ | åŒæ—¶æ”¯æŒ Yosys å’Œ DCï¼ˆå·¥ä¸šçº§ï¼‰ |
| **è¯„ä¼°æŒ‡æ ‡** | ä¸»è¦çœ‹é¢ç§¯(cell count) | å…¨é¢è¯„ä¼° Power, WNS, TNS, Area |
| **éªŒè¯å®Œæ•´æ€§** | åŠŸèƒ½éªŒè¯ä¸è¶³ | å½¢å¼+åŠ¨æ€åŒé‡éªŒè¯ä¿éšœåŠŸèƒ½æ­£ç¡® |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“**ï¼šRTL-OPT æ˜¯é¦–ä¸ªèƒ½å¤Ÿ**ç¨³å®šã€å¯é ã€å…¨é¢åœ°è¡¡é‡ LLM åœ¨çœŸå® RTL ä¼˜åŒ–ä»»åŠ¡ä¸Šè¡¨ç°**çš„åŸºå‡†ï¼Œè§£å†³äº†å…ˆå‰å·¥ä½œå› â€œè™šå‡ä¼˜åŒ–â€è€Œå¯¼è‡´è¯„ä¼°è¯¯å¯¼çš„æ ¹æœ¬é—®é¢˜ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **RTL-OPT åŸºå‡†æœ¬èº«**ï¼šåŒ…å« 36 å¯¹ RTL æ¨¡å—ï¼Œæ¯å¯¹åŒ…å« suboptimal å’Œ optimized ç‰ˆæœ¬ã€‚
- å¯¹æ¯”åŸºå‡†ï¼š
  - [26] ä¸­å‘å¸ƒçš„ 43 å¯¹ RTL ä¼˜åŒ–æ ·æœ¬ï¼ˆç§°ä¸º â€œBenchmark of [26]â€ï¼‰
  - å…¶ä¸­è¿˜ç»†åˆ†ä¸ºä¸¤ä¸ªå­é›†ï¼šâ€œpaper of [26]â€ï¼ˆ12 å¯¹ï¼‰å’Œ â€œSymRTLO [23]â€ï¼ˆ13 å¯¹ï¼‰

æ‰€æœ‰ RTL å‡ä¸º Verilog ç¼–å†™ï¼Œæ¶µç›–ä»åŠ æ³•å™¨åˆ° FSMã€é™¤æ³•å™¨ç­‰å…¸å‹æ¨¡å—ã€‚

---

### å®éªŒè®¾ç½®
#### ç»¼åˆå·¥å…·ä¸æµç¨‹
- **ä¸»ç»¼åˆå·¥å…·**ï¼šSynopsys Design Compiler (DC)
  - é…ç½®ï¼š`compile` å’Œæ›´æ¿€è¿›çš„ `compile_ultra` æ¨¡å¼
  - æ—¶é’Ÿå‘¨æœŸï¼š1nsï¼ˆå®½æ¾ï¼‰å’Œ 0.1nsï¼ˆç´§å¼ ï¼‰
- **è¾…åŠ©å·¥å…·**ï¼šYosysï¼ˆç”¨äºå¯¹æ¯”åˆ†æï¼‰
- **æŠ€æœ¯åº“**ï¼šNangate45 å¼€æºæ ‡å‡†å•å…ƒåº“
- **éªŒè¯å·¥å…·**ï¼š
  - Formalityï¼šé™æ€å½¢å¼ç­‰ä»·æ€§æ£€æŸ¥
  - VCSï¼šåŠ¨æ€æµ‹è¯•å‘é‡éªŒè¯ï¼ˆå°¤å…¶é’ˆå¯¹å¸¦æµæ°´çº¿æˆ–çŠ¶æ€å˜åŒ–çš„è®¾è®¡ï¼‰

#### è¯„ä¼°æŒ‡æ ‡ï¼ˆPPAï¼‰
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Power** | æ€»åŠŸè€—ï¼ˆåŠ¨æ€ + æ³„æ¼ï¼‰ |
| **WNS (Worst Negative Slack)** | æœ€å·®è´Ÿè£•é‡ï¼ˆè¶Šæ¥è¿‘ 0 è¶Šå¥½ï¼‰ |
| **TNS (Total Negative Slack)** | è´Ÿè£•é‡æ€»å’Œï¼ˆè¶Šå°è¶Šå¥½ï¼‰ |
| **Area** | å•å…ƒæ•°é‡ï¼ˆCellsï¼‰æˆ–ç¡…ç‰‡é¢ç§¯ï¼ˆÎ¼mÂ²ï¼‰ |

è¯„ä¼°ç»“æœåˆ†ç±»ä¸ºï¼š
- **Better**ï¼šPPA å…¨é¢ä¼˜äºå­ä¼˜ç‰ˆæœ¬
- **Worse**ï¼šPPA æ›´å·®
- **Same**ï¼šæ— æ˜¾è‘—å·®å¼‚
- **Trade-off**ï¼šæŸäº›æŒ‡æ ‡æ”¹å–„ï¼Œå…¶ä»–æ¶åŒ–

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **äººç±»ä¸“å®¶ä¼˜åŒ–ç»“æœ**ï¼šä½œä¸ºé»„é‡‘å‚è€ƒï¼ˆgolden referenceï¼‰
- **LLM ç”Ÿæˆç»“æœ**ï¼š
  - GPT-4o-mini
  - Gemini-2.5
  - Deepseek V3
  - Deepseek R1
- è¾“å…¥å‡ä¸º suboptimal RTLï¼Œæç¤º LLM è¾“å‡ºâ€œæ›´ä¼˜åŒ–â€çš„ç‰ˆæœ¬
- æ‰€æœ‰è¾“å‡ºç»ç»Ÿä¸€è¯„ä¼°æµç¨‹å¤„ç†ï¼ˆç»¼åˆ + éªŒè¯ + PPA åˆ†æï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & Table 3ï¼‰

#### âœ… RTL-OPT è‡ªèº«æœ‰æ•ˆæ€§éªŒè¯ï¼ˆTable 1ï¼‰
åœ¨ `DC compile_ultra, clk=1ns` è®¾ç½®ä¸‹ï¼š

| åŸºå‡† | Better / Total |
|------|---------------|
| [26] Benchmark | 13 / 43 â‰ˆ **30.2%** |
| RTL-OPT | **35 / 36 â‰ˆ 97.2%** |

ğŸ‘‰ è¡¨æ˜ï¼š**RTL-OPT ä¸­çš„äººç±»ä¼˜åŒ–æ–¹æ¡ˆç»å¤§å¤šæ•°éƒ½èƒ½å¸¦æ¥çœŸå® PPA æå‡**ï¼Œè€Œæ—§åŸºå‡†ä¸­è¶…è¿‡ 2/3 çš„â€œä¼˜åŒ–â€åœ¨å¼ºç»¼åˆç¯å¢ƒä¸‹æ— æ•ˆã€‚

è¿›ä¸€æ­¥è¯´æ˜ï¼šå½“ä½¿ç”¨æ›´å¼ºçº¦æŸï¼ˆ`clk=0.1ns`ï¼‰æ—¶ï¼Œ[26] çš„è¡¨ç°è¿›ä¸€æ­¥ä¸‹é™ï¼Œè€Œ RTL-OPT ä»æœ‰ 23 ä¾‹ä¿æŒæ›´å¥½ï¼Œ13 ä¾‹å‡ºç° trade-offï¼Œ**æ— ä¸€ä¾‹å®Œå…¨å¤±æ•ˆ**ã€‚

#### ğŸ“Š å¹³å‡ PPA æ”¹è¿›ï¼ˆTable 3ï¼‰
åœ¨ DC ç»¼åˆä¸‹ï¼ŒRTL-OPT çš„ä¼˜åŒ–ç‰ˆæœ¬ç›¸æ¯”å­ä¼˜ç‰ˆæœ¬å¹³å‡æå‡ï¼š

| æŒ‡æ ‡ | æ”¹è¿›å¹…åº¦ |
|------|---------|
| Power | â†“ **36.0%** |
| Cells (Area) | â†“ **27.6%** |
| TNS | â†“ **53.4%** |
| WNS | ä¸å˜ï¼ˆå‡ä¸º 0ï¼‰|

> ğŸ’¡ è¯´æ˜ä¼˜åŒ–ä¸ä»…æœ‰æ•ˆï¼Œè€Œä¸”åœ¨å¤šä¸ªç»´åº¦å‡æœ‰æ˜¾è‘—æ”¶ç›Šã€‚

---

### LLM åœ¨ RTL-OPT ä¸Šçš„è¡¨ç°ï¼ˆFigure 3 & Table 4ï¼‰

| LLM æ¨¡å‹ | è¯­æ³•æ­£ç¡®ç‡ | åŠŸèƒ½æ­£ç¡®ç‡ | PPA ä¼˜äº suboptimal | PPA è¶…è¿‡ human optimized |
|--------|------------|------------|---------------------|----------------------------|
| GPT-4o-mini | 97.2% | 75.0% | 19.4% | ~2.2% |
| Gemini-2.5 | 97.2% | 69.4% | ~9.8% | ~2.4% |
| Deepseek V3 | 100% | 69.4% | 23.3% | ~4.4% |
| Deepseek R1 | 86.1% | 61.1% | **41.7%** | **13.9%** |

#### è§‚å¯Ÿè¦ç‚¹ï¼š
- **Deepseek R1** åœ¨ PPA ä¼˜åŒ–æ–¹é¢æœ€å¼ºï¼Œ**æœ‰ 5 ä¸ªæ¡ˆä¾‹è¶…è¶Šäººç±»ä¸“å®¶è®¾è®¡**ï¼›
- ä½†å®ƒä¹Ÿæœ€å®¹æ˜“å¼•å…¥åŠŸèƒ½é”™è¯¯ï¼ˆfunctional discrepancyï¼‰ï¼Œå°¤å…¶æ˜¯åœ¨æ§åˆ¶é€»è¾‘å’Œ FSM ä¸­ï¼›
- GPT-4o-mini å’Œ Gemini æ›´ä¿å®ˆï¼ŒåŠŸèƒ½ç¨³å®šæ€§é«˜ï¼Œä½†ä¼˜åŒ–èƒ½åŠ›è¾ƒå¼±ï¼›
- æ‰€æœ‰æ¨¡å‹éƒ½è¿œæœªè¾¾åˆ°äººç±»ä¸“å®¶æ°´å¹³ï¼Œè¡¨æ˜è¯¥ä»»åŠ¡æå…·æŒ‘æˆ˜æ€§ã€‚

---

### æ¶ˆèå®éªŒä¸å¤±è´¥æ¨¡å¼åˆ†æ
ä½œè€…éšæœºæŠ½æŸ¥äº† 40 ä¸ªé€šè¿‡è¯­æ³•ä½†åŠŸèƒ½å¤±è´¥çš„æ¡ˆä¾‹ï¼Œå‘ç°ä¸‰å¤§å¸¸è§é”™è¯¯ç±»å‹ï¼š
1. **Control Logic Inconsistencies**  
   å¦‚å¸ƒå°”æ¡ä»¶å†™é”™ï¼ˆ`if (a == b)` å†™æˆ `if (a != b)`ï¼‰
2. **Overly Aggressive Pipelining**  
   æ’å…¥å¯„å­˜å™¨ç ´ååŸæœ‰å»¶è¿Ÿè¦æ±‚ï¼ˆlatency requirement violationï¼‰
3. **Improper Resource Sharing**  
   é”™è¯¯å¤ç”¨å¯„å­˜å™¨å¯¼è‡´æ•°æ®å†²çªï¼ˆstale dataï¼‰

ğŸ‘‰ è¯´æ˜ LLM çš„é”™è¯¯å¾€å¾€æºäºå¯¹ç¡¬ä»¶è¯­ä¹‰ç†è§£ä¸è¶³ï¼Œè€Œéè¯­æ³•å±‚é¢é—®é¢˜ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç°æœ‰ RTL ä¼˜åŒ–åŸºå‡†ä¸å¯é **  
   å¤šæ•°æ‰€è°“çš„â€œä¼˜åŒ–â€åœ¨å·¥ä¸šçº§ç»¼åˆæµç¨‹ä¸‹æ— æ³•ä½“ç°ä»·å€¼ï¼Œç”šè‡³ä¸å¦‚åŸå§‹ä»£ç ï¼Œ**å®¹æ˜“è¯¯å¯¼ç ”ç©¶æ–¹å‘**ã€‚

2. **RTL-OPT æˆåŠŸæ•æ‰çœŸå®ä¼˜åŒ–æœºä¼š**  
   å…¶æä¾›çš„ä¼˜åŒ–æ¨¡å¼åœ¨å„ç§ç»¼åˆæ¡ä»¶ä¸‹å‡è¡¨ç°å‡ºç¨³å®šçš„ PPA æå‡ï¼Œ**éªŒè¯äº†å…¶ä½œä¸ºé«˜è´¨é‡åŸºå‡†çš„æœ‰æ•ˆæ€§**ã€‚

3. **LLM åœ¨ RTL ä¼˜åŒ–ä¸Šä»æœ‰å·¨å¤§å·®è·**  
   å°½ç®¡éƒ¨åˆ†æ¨¡å‹ï¼ˆå¦‚ Deepseek R1ï¼‰èƒ½åœ¨å°‘æ•°ä»»åŠ¡ä¸Šè¶…è¶Šäººç±»ï¼Œä½†æ•´ä½“æˆåŠŸç‡ä½ï¼Œä¸”å¸¸ä¼´éšåŠŸèƒ½é”™è¯¯ã€‚

4. **å­˜åœ¨æ˜æ˜¾çš„ä¼˜åŒ–-å¯é æ€§æƒè¡¡ï¼ˆtrade-offï¼‰**  
   æ›´æ¿€è¿›çš„ä¼˜åŒ–ç­–ç•¥å¯èƒ½å¸¦æ¥æ›´é«˜ PPA æ”¶ç›Šï¼Œä½†ä¹Ÿæ›´å®¹æ˜“ç ´ååŠŸèƒ½æ­£ç¡®æ€§ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **è§„æ¨¡é™åˆ¶**ï¼šç›®å‰ä»…åŒ…å« 36 ä¸ªå°åˆ°ä¸­ç­‰è§„æ¨¡æ¨¡å—ï¼Œå°šæœªè¦†ç›–å¤§å‹ SoC çº§è®¾è®¡ï¼›
- **äººå·¥æ„å»ºæˆæœ¬é«˜**ï¼šæ¯ä¸ªä¼˜åŒ–å¯¹éœ€ä¸“å®¶ç²¾å¿ƒè®¾è®¡ï¼Œéš¾ä»¥å¤§è§„æ¨¡æ‰©å±•ï¼›
- **ä¾èµ–ç‰¹å®šå·¥è‰ºåº“**ï¼šä½¿ç”¨ Nangate45 åº“ï¼Œç»“æœå¯èƒ½éšå·¥è‰ºèŠ‚ç‚¹å˜åŒ–è€Œä¸åŒï¼›
- **æœªæ¶‰åŠç‰©ç†å®ç°åç«¯æŒ‡æ ‡**ï¼ˆå¦‚å¸ƒçº¿æ‹¥å¡ã€æ—¶é’Ÿæ ‘å»¶è¿Ÿç­‰ï¼‰

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•æ›´å¤§è§„æ¨¡çš„è®¾è®¡ä»»åŠ¡**ï¼Œä¾‹å¦‚å®Œæ•´ CPU æ¨¡å—æˆ–é€šä¿¡ IPï¼›
2. **å¼•å…¥æ›´å¤šä¼˜åŒ–ç›®æ ‡**ï¼Œå¦‚å¯æµ‹æ€§ï¼ˆtestabilityï¼‰ã€å®‰å…¨æ€§ï¼ˆside-channel resilienceï¼‰ï¼›
3. **ç»“åˆå¼ºåŒ–å­¦ä¹ æˆ–æœç´¢ç®—æ³•**ï¼Œè¾…åŠ© LLM æ¢ç´¢æ›´å®‰å…¨çš„ä¼˜åŒ–è·¯å¾„ï¼›
4. **å¼€å‘é¢å‘ RTL ä¼˜åŒ–çš„ä¸“ç”¨ LLM å¾®è°ƒæ•°æ®é›†ä¸è®­ç»ƒèŒƒå¼**ï¼›
5. **æ¨åŠ¨ RTL-OPT æˆä¸ºç¤¾åŒºæ ‡å‡†åŸºå‡†**ï¼Œä¿ƒè¿›å…¬å¹³æ¯”è¾ƒä¸æŠ€æœ¯è¿›æ­¥ã€‚

---

## æ€»ç»“
âœ… **RTL-OPT æ˜¯ä¸€é¡¹é‡è¦åŸºç¡€è®¾æ–½å·¥ä½œ**ï¼Œå®ƒå¡«è¡¥äº† LLM è¾…åŠ©ç¡¬ä»¶è®¾è®¡é¢†åŸŸåœ¨**ä¼˜åŒ–è´¨é‡è¯„ä¼°æ–¹é¢çš„ç©ºç™½**ã€‚é€šè¿‡å¼•å…¥çœŸå®ã€å¯é‡å¤ã€å¤šç»´åº¦çš„è¯„ä¼°ä½“ç³»ï¼Œè¯¥åŸºå‡†æœ‰åŠ©äºå¼•å¯¼ç ”ç©¶èµ°å‘æ›´å…·å®ç”¨ä»·å€¼çš„æ–¹å‘ï¼Œé˜²æ­¢â€œçº¸ä¸Šä¼˜åŒ–â€æ³›æ»¥ã€‚æœªæ¥éšç€æ›´å¤šæ¨¡å‹åœ¨å…¶ä¸Šæµ‹è¯•ï¼Œæœ‰æœ›åŠ é€Ÿ AI for EDA é¢†åŸŸçš„å‘å±•ã€‚

</details>

---

### 16. [Bridging the gap: A comparative exploration of Speech-LLM and end-to-end architecture for multilingual conversational ASR](https://arxiv.org/abs/2601.01461)

**Authors**: Yuxiang Mei, Dongxing Xu, Jiaen Liang, Yanhua Long  
**Category**: cs.CL  
**Published**: 2026-01-06  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.01461v1  

#### Abstract
The INTERSPEECH 2025 Challenge on Multilingual Conversational Speech Language Models (MLC-SLM) promotes multilingual conversational ASR with large language models (LLMs). Our previous SHNU-mASR system adopted a competitive parallel-speech-encoder architecture that integrated Whisper and mHuBERT with...

---

### 17. [A Training-Free Large Reasoning Model-based Knowledge Tracing Framework for Unified Prediction and Prescription](https://arxiv.org/abs/2601.01708)

**Authors**: Unggi Lee, Joo Young Kim, Ran Ju, Minyoung Jung, Jeyeon Eo  
**Category**: cs.CL  
**Published**: 2026-01-06  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.01708v1  

#### Abstract
Knowledge Tracing (KT) aims to estimate a learner's evolving mastery based on interaction histories. Recent studies have explored Large Language Models (LLMs) for KT via autoregressive nature, but such approaches typically require fine-tuning and exhibit unstable or near-random performance. Moreover...

---

### 18. [A Multi-Port Concurrent Communication Model for handling Compute Intensive Tasks on Distributed Satellite System Constellations](https://arxiv.org/abs/2601.01031)

**Authors**: Bharadwaj Veeravalli  
**Category**: cs.DC  
**Published**: 2026-01-06  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.01031v1  

#### Abstract
We develop an integrated Multi-Port Concurrent Communication Divisible Load Theory (MPCC-DLT) framework for relay-centric distributed satellite systems (DSS), capturing concurrent data dissemination, parallel computation, and result return under heterogeneous onboard processing and inter-satellite l...

---

### 19. [ShrimpXNet: A Transfer Learning Framework for Shrimp Disease Classification with Augmented Regularization, Adversarial Training, and Explainable AI](https://arxiv.org/abs/2601.00832)

**Authors**: Israk Hasan Jone, D. M. Rafiun Bin Masud, Promit Sarker, Sayed Fuad Al Labib, Nazmul Islam, Farhad Billah  
**Category**: cs.LG  
**Published**: 2026-01-06  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.00832v1  

#### Abstract
Shrimp is one of the most widely consumed aquatic species globally, valued for both its nutritional content and economic importance. Shrimp farming represents a significant source of income in many regions; however, like other forms of aquaculture, it is severely impacted by disease outbreaks. These...

---

### 20. [MindChat: A Privacy-preserving Large Language Model for Mental Health Support](https://arxiv.org/abs/2601.01993)

**Authors**: Dong Xue, Jicheng Tu, Ming Wang, Xin Yan, Fangzhou Liu, Jie Hu  
**Category**: cs.AI  
**Published**: 2026-01-06  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.01993v1  

#### Abstract
Large language models (LLMs) have shown promise for mental health support, yet training such models is constrained by the scarcity and sensitivity of real counseling dialogues. In this article, we present MindChat, a privacy-preserving LLM for mental health support, together with MindCorpus, a synth...

---

### 21. [DHI: Leveraging Diverse Hallucination Induction for Enhanced Contrastive Factuality Control in Large Language Models](https://arxiv.org/abs/2601.01156)

**Authors**: Jiani Guo, Xiangke Zeng, Jie Wu, Zuchao Li  
**Category**: cs.CL  
**Published**: 2026-01-06  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.01156v1  

#### Abstract
Large language models (LLMs) frequently produce inaccurate or fabricated information, known as "hallucinations," which compromises their reliability. Existing approaches often train an "Evil LLM" to deliberately generate hallucinations on curated datasets, using these induced hallucinations to guide...

---

### 22. [Universal Battery Degradation Forecasting Driven by Foundation Model Across Diverse Chemistries and Conditions](https://arxiv.org/abs/2601.00862)

**Authors**: Joey Chan, Huan Wang, Haoyu Pan, Wei Wu, Zirong Wang, Zhen Chen, Ershun Pan, Min Xie, Lifeng Xi  
**Category**: cs.LG  
**Published**: 2026-01-06  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.00862v1  

#### Abstract
Accurate forecasting of battery capacity fade is essential for the safety, reliability, and long-term efficiency of energy storage systems. However, the strong heterogeneity across cell chemistries, form factors, and operating conditions makes it difficult to build a single model that generalizes be...

---

### 23. [Selective Imperfection as a Generative Framework for Analysis, Creativity and Discovery](https://arxiv.org/abs/2601.00863)

**Authors**: Markus J. Buehler  
**Category**: cs.LG  
**Published**: 2026-01-06  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.00863v1  

#### Abstract
We introduce materiomusic as a generative framework linking the hierarchical structures of matter with the compositional logic of music. Across proteins, spider webs and flame dynamics, vibrational and architectural principles recur as tonal hierarchies, harmonic progressions, and long-range musical...

---

### 24. [A Differentiable Adversarial Framework for Task-Aware Data Subsampling](https://arxiv.org/abs/2601.02081)

**Authors**: Jiacheng Lyu, Bihua Bao  
**Category**: cs.LG  
**Published**: 2026-01-06  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.02081v1  

#### Abstract
The proliferation of large-scale datasets poses a major computational challenge to model training. The traditional data subsampling method works as a static, task independent preprocessing step which usually discards information that is critical to downstream prediction. In this paper, we introduces...

---

### 25. [Reasoning Over Recall: Evaluating the Efficacy of Generalist Architectures vs. Specialized Fine-Tunes in RAG-Based Mental Health Dialogue Systems](https://arxiv.org/abs/2601.01341)

**Authors**: Md Abdullah Al Kafi, Raka Moni, Sumit Kumar Banshal  
**Category**: cs.CL  
**Published**: 2026-01-06  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.01341v1  

#### Abstract
The deployment of Large Language Models (LLMs) in mental health counseling faces the dual challenges of hallucinations and lack of empathy. While the former may be mitigated by RAG (retrieval-augmented generation) by anchoring answers in trusted clinical sources, there remains an open question as to...

---

### 26. [EmoHarbor: Evaluating Personalized Emotional Support by Simulating the User's Internal World](https://arxiv.org/abs/2601.01530)

**Authors**: Jing Ye, Lu Xiang, Yaping Zhang, Chengqing Zong  
**Category**: cs.CL  
**Published**: 2026-01-06  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.01530v1  

#### Abstract
Current evaluation paradigms for emotional support conversations tend to reward generic empathetic responses, yet they fail to assess whether the support is genuinely personalized to users' unique psychological profiles and contextual needs. We introduce EmoHarbor, an automated evaluation framework ...

---

### 27. [CSF: Contrastive Semantic Features for Direct Multilingual Sign Language Generation](https://arxiv.org/abs/2601.01964)

**Authors**: Tran Sy Bao  
**Category**: cs.CL  
**Published**: 2026-01-06  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.01964v1  

#### Abstract
Sign language translation systems typically require English as an intermediary language, creating barriers for non-English speakers in the global deaf community. We present Canonical Semantic Form (CSF), a language-agnostic semantic representation framework that enables direct translation from any s...

---

### 28. [Making MoE based LLM inference resilient with Tarragon](https://arxiv.org/abs/2601.01310)

**Authors**: Songyu Zhang, Aaron Tam, Myungjin Lee, Shixiong Qi, K. K. Ramakrishnan  
**Category**: cs.DC  
**Published**: 2026-01-06  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.01310v1  

#### Abstract
Mixture-of-Experts (MoE) models are increasingly used to serve LLMs at scale, but failures become common as deployment scale grows. Existing systems exhibit poor failure resilience: even a single worker failure triggers a coarse-grained, service-wide restart, discarding accumulated progress and halt...

---

### 29. [Horizon Activation Mapping for Neural Networks in Time Series Forecasting](https://arxiv.org/abs/2601.02094)

**Authors**: Hans Krupakar, V A Kandappan  
**Category**: cs.LG  
**Published**: 2026-01-06  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.02094v1  

#### Abstract
Neural networks for time series forecasting have relied on error metrics and architecture-specific interpretability approaches for model selection that don't apply across models of different families. To interpret forecasting models agnostic to the types of layers across state-of-the-art model famil...

---

### 30. [ELLA: Efficient Lifelong Learning for Adapters in Large Language Models](https://arxiv.org/abs/2601.02232)

**Authors**: Shristi Das Biswas, Yue Zhang, Anwesan Pal, Radhika Bhargava, Kaushik Roy  
**Category**: cs.LG  
**Published**: 2026-01-06  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.02232v1  

#### Abstract
Large Language Models (LLMs) suffer severe catastrophic forgetting when adapted sequentially to new tasks in a continual learning (CL) setting. Existing approaches are fundamentally limited: replay-based methods are impractical and privacy-violating, while strict orthogonality-based methods collapse...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
