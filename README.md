# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-01-16 05:58:21 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [FaTRQ: Tiered Residual Quantization for LLM Vector Search in Far-Memory-Aware ANNS Systems](https://arxiv.org/abs/2601.09985)

**Authors**: Tianqi Zhang, Flavio Ponzina, Tajana Rosing  
**Category**: cs.LG  
**Published**: 2026-01-16  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2601.09985v1  

#### Abstract
Approximate Nearest-Neighbor Search (ANNS) is a key technique in retrieval-augmented generation (RAG), enabling rapid identification of the most relevant high-dimensional embeddings from massive vector databases. Modern ANNS engines accelerate this process using prebuilt indexes and store compressed...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFaTRQ: Tiered Residual Quantization for LLM Vector Search in Far-Memory-Aware ANNS Systems

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°ä»£ **Approximate Nearest-Neighbor Search (ANNS)** ç³»ç»Ÿåœ¨ **Retrieval-Augmented Generation (RAG)** ä¸­å¹¿æ³›åº”ç”¨ï¼Œç”¨äºä»å¤§è§„æ¨¡å‘é‡æ•°æ®åº“ä¸­å¿«é€Ÿæ£€ç´¢ç›¸å…³åµŒå…¥ã€‚ç„¶è€Œï¼Œå°½ç®¡å·²æœ‰ç´¢å¼•ç»“æ„ï¼ˆå¦‚ IVFã€CAGRAï¼‰å’Œå‘é‡é‡åŒ–æŠ€æœ¯ï¼ˆå¦‚ PQï¼‰å°†å‹ç¼©åçš„å‘é‡å­˜å‚¨åœ¨é«˜é€Ÿå†…å­˜ä¸­ä»¥åŠ é€Ÿæœç´¢ï¼Œ**ç¬¬äºŒé˜¶æ®µçš„ç²¾ç‚¼ï¼ˆrefinementï¼‰ä»éœ€ä»æ…¢é€Ÿå­˜å‚¨è®¾å¤‡ï¼ˆå¦‚ SSDï¼‰è¯»å–å…¨ç²¾åº¦å‘é‡**ã€‚

éšç€ç°ä»£æ–‡æœ¬å’Œå¤šæ¨¡æ€åµŒå…¥ç»´åº¦çš„å¢é•¿ï¼ˆå¦‚ 768â€“1536 ç»´ï¼‰ï¼Œè¿™ä¸€ç²¾ç‚¼é˜¶æ®µçš„ I/O å¼€é”€å·²æˆä¸ºæ•´ä¸ªæŸ¥è¯¢å»¶è¿Ÿçš„ä¸»è¦ç“¶é¢ˆâ€”â€”**è¶…è¿‡ 90% çš„æ—¶é—´æ¶ˆè€—åœ¨ä» SSD è¯»å–å…¨ç²¾åº¦å‘é‡ä¸Š**ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ ¸å¿ƒæ€è·¯
ä¸ºè§£å†³è¯¥é—®é¢˜ï¼Œä½œè€…æå‡º **FaTRQ**ï¼ˆ**Far-memory-aware Tiered Residual Quantization**ï¼‰ï¼Œä¸€ç§é¢å‘è¿œç«¯å†…å­˜ï¼ˆfar memoryï¼‰çš„æ¸è¿›å¼è·ç¦»ä¼°è®¡æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- **é¿å…ç›´æ¥è¯»å–å…¨ç²¾åº¦å‘é‡**ï¼Œè½¬è€Œé€šè¿‡åˆ†å±‚æ®‹å·®é‡åŒ–ï¼ˆTiered Residual Quantization, TRQï¼‰å°†åŸå§‹å‘é‡åˆ†è§£ä¸ºï¼š
  - **ç²—ç•¥é‡åŒ–ç ï¼ˆcoarse codeï¼‰** å­˜äº **fast memory**ï¼ˆå¦‚ DRAM/VRAMï¼‰
  - **ç´§å‡‘æ®‹å·®ç ï¼ˆresidual codesï¼‰** å­˜äº **far memory**ï¼ˆå¦‚ CXL å†…å­˜ã€SCMï¼‰
- åœ¨æŸ¥è¯¢æ—¶ï¼Œé‡‡ç”¨ **æ¸è¿›å¼è·ç¦»ä¼°è®¡ï¼ˆprogressive distance estimationï¼‰**ï¼š
  - åˆå§‹ä½¿ç”¨ç²—ç•¥è·ç¦»
  - é€æ­¥æµå¼åŠ è½½æ®‹å·®ç ï¼Œå¢é‡æ›´æ–°è·ç¦»
  - **ä¸€æ—¦å€™é€‰è€…å¯è¢«è¯æ˜ä¸åœ¨ top-k èŒƒå›´å†…ï¼Œåˆ™æå‰å‰ªæ**
- å¼•å…¥ **ä¸‰å€¼åŒ–æ®‹å·®ç¼–ç ï¼ˆternary residual encodingï¼‰**ï¼š
  - å°†æ®‹å·®æ–¹å‘ç¼–ç ä¸º {-1, 0, +1} çš„ç¨€ç–ä¸‰å…ƒå‘é‡
  - æ”¯æŒä¹˜æ³•è‡ªç”±çš„è·ç¦»è®¡ç®—ï¼ˆä»…éœ€åŠ å‡æ³•ï¼‰ï¼Œé™ä½è®¡ç®—å¼€é”€
- è®¾è®¡ä¸“ç”¨ç¡¬ä»¶åŠ é€Ÿå™¨ï¼ˆéƒ¨ç½²äº **CXL Type-2 è®¾å¤‡**ï¼‰å®ç°æœ¬åœ°ä½å»¶è¿Ÿç²¾ç‚¼ï¼Œå‡å°‘ä¸»æœº CPU å’Œå†…å­˜å¸¦å®½å‹åŠ›

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | FaTRQ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ cuVSã€FAISSï¼‰ |
|------|-------|-----------------------------|
| **ç²¾ç‚¼ I/O æˆæœ¬** | ä»…éœ€è¯»å–å‡ å­—èŠ‚çš„æ®‹å·®ç ï¼ˆCXL/far memoryï¼‰ | éœ€è¯»å–å®Œæ•´å…¨ç²¾åº¦å‘é‡ï¼ˆSSDï¼‰ |
| **å­˜å‚¨æ•ˆç‡** | æ®‹å·®ç é«˜åº¦å‹ç¼©ï¼ˆ~1.6 bits/dimï¼‰ | å…¨ç²¾åº¦å­˜å‚¨ï¼ˆ32 bits/dimï¼‰ |
| **è®¡ç®—æ¨¡å¼** | æ¸è¿›å¼ä¼°è®¡ + æ—©æœŸå‰ªæ | æ‰¹é‡é‡æ’åºæ‰€æœ‰å€™é€‰ |
| **ç¡¬ä»¶æ”¯æŒ** | å¯ç»“åˆ CXL åŠ é€Ÿå™¨å®ç°è¿‘å†…å­˜å¤„ç† | ä¾èµ–ä¸»æœº CPU è¿›è¡Œç²¾ç‚¼ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **Wiki dataset**ï¼š88M æ¡ SBERT å¤šè¯­è¨€å¥å­åµŒå…¥ï¼Œ768 ç»´ï¼Œå…± 251GB
- **LAION dataset**ï¼š100M æ¡ CLIP å›¾åƒ-æ–‡æœ¬åµŒå…¥ï¼ˆæ¥è‡ª LAION-5Bï¼‰ï¼Œ768 ç»´ï¼Œå…± 286GB
- æŸ¥è¯¢é›†ï¼šå„å« 10k æŸ¥è¯¢ï¼Œä½¿ç”¨ Euclidean è·ç¦»ä½œä¸ºç›¸ä¼¼åº¦åº¦é‡

### å®éªŒè®¾ç½®
- **å¹³å°æ¨¡æ‹Ÿ**ï¼š
  - GPU ç«¯ï¼šNVIDIA A10 GPUï¼ˆ24GB VRAMï¼‰ï¼Œè¿è¡Œ cuVS/FAISS çš„ç´¢å¼•éå†ä¸ç²—ç•¥æ‰“åˆ†
  - ä¸»æœº CPUï¼š40 çº¿ç¨‹ Intel Xeon Gold 6230ï¼Œ128GB DRAM
  - å­˜å‚¨ï¼š1TB SSDï¼ˆå»¶è¿Ÿ 45Î¼sï¼Œåå 1200K IOPSï¼‰
  - è¿œç«¯å†…å­˜ï¼šåŸºäº CXL çš„å­˜å‚¨ç±»å†…å­˜ï¼ˆlatency 271nsï¼Œbandwidth 22GB/sï¼‰ï¼Œä½¿ç”¨ Ramulator æ¨¡æ‹Ÿ
- **ç¡¬ä»¶è¯„ä¼°**ï¼šVerilog å®ç° CXL Type-2 åŠ é€Ÿå™¨ï¼Œåœ¨ ASAP7 å·¥è‰ºä¸‹ç»¼åˆï¼ˆ1GHzï¼‰

### è¯„ä¼°æŒ‡æ ‡
- **End-to-end throughput**ï¼ˆqueries/secï¼‰
- **Recall@10** at target levels (85%, 90%, 95%)
- **Refinement ratio**ï¼šå®é™…å‚ä¸æœ€ç»ˆæ’åºçš„å€™é€‰æ•°å æ¯”
- **Distance estimation distortion**ï¼ˆMSEï¼‰
- **Area & Power overhead** of accelerator

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **PQ-IVF-FAISS**ï¼šåŸºäº FAISS çš„ IVF+PQ ç´¢å¼•ï¼Œç²¾ç‚¼é˜¶æ®µä» SSD åŠ è½½å…¨ç²¾åº¦å‘é‡
- **PQ-CAGRA-cuVS**ï¼šåŸºäº cuVS çš„å›¾ç´¢å¼• CAGRA + PQï¼ŒåŒæ ·è¿›è¡Œ SSD å›è¯»ç²¾ç‚¼
- å¯¹æ¯”ç‰ˆæœ¬ï¼š
  - FaTRQ-IVF-SW / FaTRQ-CAGRA-SWï¼šè½¯ä»¶å®ç°ï¼Œæ®‹å·®ç å­˜äº CXL å†…å­˜
  - FaTRQ-IVF-HW / FaTRQ-CAGRA-HWï¼šç¡¬ä»¶åŠ é€Ÿç‰ˆæœ¬ï¼Œç²¾ç‚¼å¸è½½è‡³ CXL åŠ é€Ÿå™¨

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
#### âœ… ååæå‡ï¼ˆThroughput Speedupï¼‰
| æ–¹æ³• | Wiki-90 Recall | LAION-90 Recall |
|------|---------------|----------------|
| FaTRQ-IVF-HW | **9.4Ã—** vs IVF-FAISS | **3.1Ã—** vs IVF-FAISS |
| FaTRQ-CAGRA-HW | **4.9Ã—** vs CAGRA-cuVS | **2.6Ã—** vs CAGRA-cuVS |

> æ³¨ï¼šIVF æ›´ä¾èµ–å¤§é‡å€™é€‰é‡æ’åºï¼Œå› æ­¤ FaTRQ å¸¦æ¥çš„æ”¶ç›Šæ›´å¤§ï¼›CAGRA æœ¬èº«å‰ªææ›´å¼ºï¼Œæ”¹è¿›ç©ºé—´è¾ƒå°ã€‚

#### âœ… å­˜å‚¨æ•ˆç‡æå‡
- FaTRQ æ®‹å·®ç å­˜å‚¨å¼€é”€ï¼š
  - æ¯ä¸ª 768 ç»´å‘é‡ä»…éœ€ `(768 / 5) + 8 = 162 bytes`
    - 5 ä¸ªä¸‰å…ƒå€¼æ‰“åŒ…æˆ 1 å­—èŠ‚ â†’ å¹³å‡ 1.6 bits/dim
    - åŠ ä¸Šä¸¤ä¸ªé¢„è®¡ç®—æ ‡é‡ï¼ˆ`âŸ¨xc, Î´âŸ©`, `â€–Î´â€–`ï¼‰å…± 8 bytes
- å¯¹æ¯” 4-bit Scalar Quantization (SQ)ï¼š
  - éœ€è¦ 384 bytesï¼ˆ768 Ã— 0.5 bytesï¼‰
  - MSE ç›¸å½“ï¼ˆFaTRQ: 0.0159 vs SQ: 0.0134ï¼‰ï¼Œä½†å­˜å‚¨èŠ‚çœ **2.4Ã—**

#### âœ… ç²¾ç‚¼æµé‡å‰Šå‡
- åœ¨è¾¾åˆ°ç›¸åŒ Recall@10ï¼ˆ99%ï¼‰å‰æä¸‹ï¼š
  - åŸºçº¿éœ€è®¿é—® ~70 ä¸ªå…¨ç²¾åº¦å‘é‡
  - FaTRQ ä»…éœ€è®¿é—® ~25 ä¸ª â†’ **å‡å°‘ 2.8Ã— SSD I/O**
- å›¾ 8 æ˜¾ç¤ºï¼Œå³ä½¿åªå¯¹ top-30% çš„ FaTRQ æ’åºç»“æœæ‰§è¡Œå…¨ç²¾åº¦éªŒè¯ï¼Œä¹Ÿèƒ½æ˜¾è‘—ä¼˜äºæ—  FaTRQ çš„å®Œæ•´åˆ—è¡¨é‡æ’

#### âœ… è·ç¦»ä¼°è®¡å‡†ç¡®æ€§
- FaTRQ çš„è·ç¦»ä¼°è®¡ MSE ä»…ä¸º **0.0159**ï¼Œè¿œä½äº 3-bit SQ çš„ **0.258**
- å›¾ 7 æ˜¾ç¤º FaTRQ ç»“æœå‡ ä¹è´´åˆâ€œoracleâ€çº¿ï¼ˆå³ä½¿ç”¨å…¨ç²¾åº¦æ®‹å·®çš„ç†æƒ³æƒ…å†µï¼‰

#### âœ… ç¡¬ä»¶å¼€é”€æä½
- CXL åŠ é€Ÿå™¨æ€»é¢ç§¯ï¼š**0.729 mmÂ²**ï¼ŒåŠŸè€— **897 mW**
- FaTRQ è·ç¦»ä¼°è®¡æ¨¡å—å  29% é¢ç§¯ã€27% åŠŸè€—
- ç›¸æ¯”å®Œæ•´çš„ CXL æ§åˆ¶å™¨ï¼ˆå¦‚ Marvell Structera A2504ï¼Œå« 16 ä¸ª Neoverse V2 æ ¸å¿ƒï¼‰ï¼Œé¢ç§¯ä¸åŠŸè€—å¼€é”€åˆ†åˆ« < **1.8%** å’Œ **4%**

#### âœ… ç¦»çº¿è®­ç»ƒå¼€é”€å°
- æ„å»ºæ®‹å·®ç  + è®­ç»ƒè½»é‡æ ¡å‡†æ¨¡å‹ï¼šçº¦ **10 åˆ†é’Ÿ**
- ç›¸æ¯”æ„å»º CAGRA ç´¢å¼•æ‰€éœ€ ~3 å°æ—¶ï¼Œå¯å¿½ç•¥ä¸è®¡

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ANNS ç³»ç»Ÿçš„ç“¶é¢ˆå·²ä»è®¡ç®—è½¬å‘ I/O**ï¼šå°¤å…¶åœ¨é«˜ç»´åµŒå…¥åœºæ™¯ä¸‹ï¼Œ**SSD ä¸Šçš„å…¨ç²¾åº¦å‘é‡å›è¯»ä¸»å¯¼äº†æŸ¥è¯¢å»¶è¿Ÿ**ã€‚
2. **æ®‹å·®ä¿¡æ¯å¯ä»¥é«˜æ•ˆå‹ç¼©å¹¶ç”¨äºæ¸è¿›å¼è·ç¦»ä¼°è®¡**ï¼šåˆ©ç”¨æ®‹å·®è¿‘ä¼¼æ­£äº¤äºæŸ¥è¯¢åç§»çš„ç‰¹æ€§ï¼ŒFaTRQ å®ç°äº†é«˜ç²¾åº¦ã€ä½å¼€é”€çš„è·ç¦»ç»†åŒ–ã€‚
3. **ä¸‰å…ƒç¼–ç  + åˆ†å±‚å­˜å‚¨æ¶æ„å®ç°äº†æè‡´å‹ç¼©ä¸é«˜æ•ˆè®¡ç®—**ï¼šæ— éœ€é‡å»ºåŸå§‹å‘é‡å³å¯å®Œæˆé«˜è´¨é‡é‡æ’åºã€‚
4. **CXL Type-2 ç­‰è¿œç«¯å†…å­˜è®¾å¤‡éå¸¸é€‚åˆéƒ¨ç½²æ­¤ç±»è¿‘å†…å­˜ç²¾ç‚¼é€»è¾‘**ï¼šæ—¢èƒ½æä¾›å¤§å®¹é‡ï¼Œåˆå…·å¤‡ä¸€å®šè®¡ç®—èƒ½åŠ›ï¼Œå¤§å¹…å‡å°‘ä¸»æœºè´Ÿæ‹…ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“ç›®æ ‡ recall å¾ˆé«˜ï¼ˆå¦‚ 95%ï¼‰æ—¶ï¼Œç²—ç­›é€‰éš¾ä»¥æœ‰æ•ˆå‰ªæï¼Œå¯¼è‡´æ›´å¤šå€™é€‰è¿›å…¥ç²¾ç‚¼é˜¶æ®µï¼ŒFaTRQ çš„ä¼˜åŠ¿æœ‰æ‰€å‡å¼±ã€‚
- ä¾èµ–é¢„å…ˆæ„å»ºçš„æ®‹å·®ç å’Œæ ¡å‡†æ¨¡å‹ï¼Œå¯¹åŠ¨æ€æ›´æ–°çš„æ•°æ®é›†é€‚åº”æ€§æœ‰å¾…éªŒè¯ã€‚
- ç›®å‰è¯„ä¼°åŸºäºé™æ€åµŒå…¥æ•°æ®åº“ï¼Œæœªè€ƒè™‘å®æ—¶æ’å…¥æˆ–åˆ é™¤æ“ä½œçš„å½±å“ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•åˆ° **åŠ¨æ€å‘é‡æ•°æ®åº“** åœºæ™¯ï¼Œæ”¯æŒåœ¨çº¿å¢é‡ç¼–ç ä¸æ›´æ–°
- æ¢ç´¢æ›´å¤æ‚çš„ **multi-level residual quantization** ä»¥è¿›ä¸€æ­¥æé«˜ç²¾åº¦
- å°† FaTRQ ä¸ **Near-Data Processing (NDP)** æˆ– **Processing-In-Memory (PIM)** æ¶æ„ç»“åˆï¼Œå®ç°ç«¯åˆ°ç«¯è¿‘å†…å­˜ ANNS
- æ”¯æŒæ›´å¤šè·ç¦»åº¦é‡ï¼ˆå¦‚ cosine similarityï¼‰å’Œé‡åŒ–æ–¹æ¡ˆ

---

## æ€»ç»“
**FaTRQ æ˜¯é¦–ä¸ªæ˜ç¡®æå‡ºâ€œè¿œç«¯å†…å­˜æ„ŸçŸ¥â€çš„ ANNS ç²¾ç‚¼æ¡†æ¶**ï¼Œé€šè¿‡ **tiered residual quantization + ternary coding + progressive estimation** çš„ç»„åˆï¼ŒæˆåŠŸå°†æ˜‚è´µçš„ SSD å…¨ç²¾åº¦è¯»å–è½¬åŒ–ä¸ºé«˜æ•ˆçš„ CXL/far memory æµå¼æ®‹å·®è¯»å–ã€‚å…¶å®éªŒç»“æœæ˜¾ç¤ºï¼š
- **æœ€é«˜è¾¾ 9.4Ã— çš„ååæå‡**
- **2.4Ã— çš„å­˜å‚¨æ•ˆç‡å¢ç›Š**
- **ç¡¬ä»¶å¼€é”€æä½ï¼Œé€‚åˆé›†æˆè¿› CXL åŠ é€Ÿå™¨**

è¯¥å·¥ä½œä¸ºä¸‹ä¸€ä»£å¤§è§„æ¨¡å‘é‡æœç´¢ç³»ç»Ÿæä¾›äº†é‡è¦çš„è½¯ç¡¬ååŒè®¾è®¡èŒƒå¼ï¼Œå°¤å…¶é€‚ç”¨äº LLM-driven RAG åº”ç”¨ä¸­çš„é«˜æ€§èƒ½è¯­ä¹‰æ£€ç´¢éœ€æ±‚ã€‚

</details>

---

### 2. [TF3-RO-50M: Training Compact Romanian Language Models from Scratch on Synthetic Moral Microfiction](https://arxiv.org/abs/2601.10410)

**Authors**: Mihai Dan Nadas, Laura Diosan, Andreea Tomescu, Andrei Piscoran  
**Category**: cs.CL  
**Published**: 2026-01-16  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2601.10410v1  

#### Abstract
Recent advances in synthetic data generation have shown that compact language models can be trained effectively when the underlying corpus is structurally controlled and linguistically coherent. However, for morphologically rich and computationally under-resourced languages such as Romanian, there i...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTF3-RO-50M: Training Compact Romanian Language Models from Scratch on Synthetic Moral Microfiction

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**å½¢æ€ä¸°å¯Œä¸”è®¡ç®—èµ„æºç›¸å¯¹åŒ®ä¹çš„è¯­è¨€â€”â€”ç½—é©¬å°¼äºšè¯­ï¼ˆRomanianï¼‰**ï¼Œè§£å†³äº†ä»¥ä¸‹å…³é”®æŒ‘æˆ˜ï¼š
- **Tokenization Penalty**ï¼šé€šç”¨å¤šè¯­è¨€åˆ†è¯å™¨ï¼ˆå¦‚ multilingual BPEï¼‰åœ¨å¤„ç† Romanian æ—¶å¯¼è‡´ä¸¥é‡çš„å­è¯ç¢ç‰‡åŒ–ï¼Œæ˜¾è‘—å¢åŠ  token æ•°é‡ï¼ˆç›¸æ¯”è‹±æ–‡æ–‡æœ¬å¯é«˜å‡º 1.5â€“2Ã—ï¼‰ï¼Œé™ä½ä¸Šä¸‹æ–‡åˆ©ç”¨ç‡å¹¶å¢åŠ è®¡ç®—æˆæœ¬ã€‚
- **ç¼ºä¹ç«¯åˆ°ç«¯è®­ç»ƒæ¡†æ¶**ï¼šæ­¤å‰å°šæ— å…¬å¼€ã€å¯å¤ç°çš„å®Œæ•´æµç¨‹ï¼Œèƒ½å¤Ÿä»é›¶å¼€å§‹è®­ç»ƒåŸºäºåˆæˆæ•°æ®çš„ Romanian å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰ï¼Œæ¶µç›– tokenizer è®¾è®¡ã€é¢„è®­ç»ƒã€å‹ç¼©ã€è¯„ä¼°åŠæ–°æ•°æ®ç”Ÿæˆã€‚
- **æœ¬åœ°éƒ¨ç½²å›°éš¾**ï¼šç”±äºç¼ºä¹é«˜æ•ˆçš„å°å‹æ¨¡å‹ï¼ŒRomanian ç”¨æˆ·é¢ä¸´é«˜æ¨ç†å»¶è¿Ÿå’Œæœ‰é™çš„æœ¬åœ°éƒ¨ç½²èƒ½åŠ›ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
TF3-RO å¼•å…¥äº†ä¸€ä¸ª**å…¨åˆæˆã€ç«¯åˆ°ç«¯çš„ Romanian è¯­è¨€å»ºæ¨¡ç”Ÿæ€ç³»ç»Ÿï¼ˆpipelineï¼‰**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

| åˆ›æ–°æ¨¡å— | å†…å®¹ |
|--------|------|
| **Romanian-specific Tokenizer** | æ„å»ºäº†ä¸“ä¸º Romanian å½¢æ€ä¼˜åŒ–çš„ SentencePiece BPE å’Œ Unigram åˆ†è¯å™¨ï¼Œç‰¹åˆ«æ˜¯ 32k Unigram åœ¨å½¢æ€ä¿çœŸåº¦ä¸Šä¼˜äºé€šç”¨å¤šè¯­è¨€æ–¹æ¡ˆã€‚ |
| **ä»å¤´é¢„è®­ç»ƒï¼ˆfrom-scratch pretrainingï¼‰** | ä½¿ç”¨çº¦ 10 äº¿ä¸ª Romanian tokensï¼Œåœ¨ä¸€ä¸ª 51.65M å‚æ•°çš„ LLaMA-style Transformer ä¸Šè¿›è¡Œå®Œå…¨ä»å¤´è®­ç»ƒï¼Œä¸ä¾èµ–ä»»ä½•é¢„è®­ç»ƒæ£€æŸ¥ç‚¹ï¼ˆå¦‚ mBERT æˆ– XLM-Rï¼‰ã€‚ |
| **ç»“æ„åŒ–å‰ªææŒ‡å¯¼è’¸é¦ï¼ˆpruning-guided knowledge distillationï¼‰** | å…ˆé€šè¿‡ structured pruning æ¢ç´¢æœ€å°å¯è¡Œå®¹é‡ï¼Œå†ä»¥æ­¤æŒ‡å¯¼è®¾è®¡å­¦ç”Ÿæ¨¡å‹æ¶æ„ï¼Œå¹¶é‡‡ç”¨ logit-based KD è¿›è¡Œå‹ç¼©ï¼Œå¾—åˆ°ä»… 26.45M å‚æ•°çš„å­¦ç”Ÿæ¨¡å‹ã€‚ |
| **åˆæˆæ•°æ®å¼•æ“åå“ºè®­ç»ƒ** | ä½¿ç”¨è’¸é¦åçš„å­¦ç”Ÿæ¨¡å‹ä½œä¸ºç”Ÿæˆå™¨ï¼Œé€šè¿‡ç»„åˆæç¤ºï¼ˆcombinatorial promptingï¼‰æ¡†æ¶ç”Ÿæˆæ–°çš„ 300 ä¸‡æ¡ Romanian åŸç”Ÿé“å¾·å¯“è¨€ï¼ˆfablesï¼‰ï¼Œå½¢æˆé—­ç¯ã€‚ |
| **ç»¼åˆè¯„ä¼°å¥—ä»¶ï¼ˆcomprehensive evaluation suiteï¼‰** | é›†æˆå¤šç§è¯„ä¼°èŒƒå¼ï¼š<br>â€¢ **å†…åœ¨æŒ‡æ ‡**ï¼ˆPerplexity, CEï¼‰<br>â€¢ **è¯­æ³•æ¢é’ˆ**ï¼ˆmorphosyntactic agreementï¼‰<br>â€¢ **å®ä½“è¿è´¯æ€§åˆ†æ**ï¼ˆentropy-based entity coherenceï¼‰<br>â€¢ **è§„åˆ™è¯­æ³•æ£€æµ‹**ï¼ˆLanguageToolï¼‰<br>â€¢ **LLM-as-a-judge**ï¼ˆGemini 2.5 Flashï¼‰<br>â€¢ **å¤šæ ·æ€§/å¯è¯»æ€§æŒ‡æ ‡**ï¼ˆDistinct-n, Self-BLEU, Flesch Reading Easeï¼‰ |

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **è¯­è¨€é€‚é…æ€§å¼º**ï¼šç›¸æ¯”ç›´æ¥ä½¿ç”¨ multilingual tokenizer + è‹±æ–‡ä¸»å¯¼æ¶æ„çš„æ–¹æ³•ï¼ŒTF3-RO æ˜¾è‘—ç¼“è§£äº† Romanian çš„ token è†¨èƒ€é—®é¢˜ï¼Œæå‡ä¸Šä¸‹æ–‡æ•ˆç‡ã€‚
- **å…¨æµç¨‹å¯æ§ä¸å¯å¤ç°**ï¼šæ‰€æœ‰ç»„ä»¶ï¼ˆtokenizerã€æ¨¡å‹ã€æ•°æ®ç”Ÿæˆï¼‰å‡åŸºäºåŒä¸€å—æ§åˆæˆè¯­æ–™ï¼ˆTF2-ROï¼‰ï¼Œç¡®ä¿ä¸€è‡´æ€§ä¸å¯å¤ç°æ€§ã€‚
- **è½»é‡åŒ–ä¸éƒ¨ç½²å‹å¥½**ï¼šæœ€ç»ˆ 26.45M æ¨¡å‹æ”¯æŒ CPU/ç§»åŠ¨ç«¯éƒ¨ç½²ï¼Œé€‚åˆèµ„æºå—é™ç¯å¢ƒã€‚
- **é—­ç¯ç”Ÿæ€æ„å»º**ï¼šä¸ä»…è®­ç»ƒæ¨¡å‹ï¼Œè¿˜åˆ©ç”¨æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡æ–°æ•°æ®ï¼Œæ¨åŠ¨ Romanian NLP å‘å±•ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **ä¸»è®­ç»ƒæ•°æ®**ï¼š`TF2-RO`ï¼Œå³ TF1 è‹±æ–‡å¯“è¨€ç»é«˜è´¨é‡æœºå™¨ç¿»è¯‘å¾—åˆ°çš„ Romanian ç‰ˆæœ¬ï¼Œå…± **300 ä¸‡æ¡é“å¾·å¾®å°è¯´ï¼ˆmoral microfictionï¼‰**ï¼Œä¿ç•™åŸå§‹å…­æ§½å™äº‹ç»“æ„ï¼ˆcharacter, setting, challenge, resolution, moralï¼‰ã€‚
- **Tokenizer è®­ç»ƒæ•°æ®**ï¼šTF2-RO çš„ Romanian å­é›†ï¼Œä¿ç•™ diacriticsï¼Œä¸åšæ¿€è¿›å½’ä¸€åŒ–ã€‚
- **è¯„ä¼°æ•°æ®**ï¼š
  - æ–°æ„å»ºçš„ **100 æ¡ Romanian æ§åˆ¶ç”Ÿæˆæç¤ºé›†**ï¼Œç‹¬ç«‹äºè®­ç»ƒ/è’¸é¦æ•°æ®ï¼›
  - æ‰€æœ‰è¯„ä¼°æ•°æ®éµå¾ªç›¸åŒå™äº‹æ¨¡æ¿ï¼Œä¿è¯åˆ†å¸ƒä¸€è‡´æ€§ã€‚

### å®éªŒè®¾ç½®
| ç»„ä»¶ | è®¾ç½® |
|------|------|
| **Tokenizer** | BPE vs. Unigramï¼Œvocab size = 32kï¼Œdeterministic segmentation |
| **åºåˆ—æ‰“åŒ…** | Long-sequence packing into fixed 2,048-token blocksï¼Œå‡å°‘å¡«å……å¼€é”€ |
| **Teacher Model** | LLaMA-style Decoder-only Transformer<br>â€¢ 6 layers<br>â€¢ hidden size = 512<br>â€¢ MLP intermediate = 1365<br>â€¢ 8 attention heads (head dim = 64)<br>â€¢ RoPE positional embedding<br>â€¢ tied input/output embeddings<br>â€¢ total params = 51.65M |
| **Student Model** | åŸºäºå‰ªæåˆ†æè®¾è®¡ï¼š<br>â€¢ hidden size â†’ 384 (-25%)<br>â€¢ MLP intermediate â†’ 1024<br>â€¢ attention heads â†’ 6 (-25%)<br>â€¢ depth ä¸å˜<br>â€¢ total params = 26.45M |
| **Knowledge Distillation** | Loss = Î±Â·KL(p_T || p_S) + Î²Â·CE(y, p_S)ï¼Œå…¶ä¸­ Î±=1.0, Î²=0.1 |
| **Quantization Baselines** | Transformer-Q8, Transformer-Q6ï¼ˆpost-training quantizationï¼‰ |
| **Baseline Architecture** | å‚æ•°åŒ¹é…çš„ Mamba æ¨¡å‹ï¼ˆ50M paramsï¼‰ï¼Œç”¨äºå¯¹æ¯” SSM ä¸ Transformer åœ¨ Romanian ä¸‹çš„è¡¨ç° |

### è¯„ä¼°æŒ‡æ ‡
| ç±»åˆ« | æŒ‡æ ‡ |
|------|------|
| **Intrinsic** | Cross-Entropy (CE), Perplexity (PPL) |
| **Grammatical Accuracy** | Romanian-specific morphosyntactic agreement probesï¼ˆsubject-verb, noun-adjective ç­‰ï¼‰ |
| **Grammar Checking** | LanguageTool é”™è¯¯ç‡æ ‡å‡†åŒ–å¾—åˆ† |
| **Narrative Coherence** | Lemmatized entity entropyï¼ˆè¡¡é‡è§’è‰²ä½¿ç”¨å¹³è¡¡æ€§ï¼‰ |
| **Fluency & Coherence** | LLM-as-a-judgeï¼ˆGemini 2.5 Flashï¼‰è¯„åˆ†ï¼ˆ0â€“100ï¼‰ |
| **Diversity** | Self-BLEU, Distinct-1/2 |
| **Readability** | Romanian-calibrated Flesch Reading Ease |
| **Efficiency** | Tokens/sec throughputï¼ˆMLX backendï¼‰, model size (MB) |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æ¨¡å‹ | Params | PPL | Entity Coherence | LanguageTool Score | LLM Judge (Mean) | Throughput (tok/s) |
|------|-------|-----|------------------|--------------------|-------------------|---------------------|
| **Transformer (Teacher)** | 51.65M | ~2.43 | 0.88 | ~0.99 | ~4.19 | 159.5 |
| **Distilled Student** | 26.45M | â†‘ ~2.7 | 0.88 | ~0.97 | ~4.00 | â†‘ **257.7** |
| **Transformer-Q8** | 51.65M | ~2.44 | 0.88 | ~0.99 | ~4.18 | â†‘ 191.1 |
| **Transformer-Q6** | 51.65M | â†‘â†‘ 3.0+ | â†‘â†‘ **0.94** | â†“â†“ ~0.88 | â†“â†“ ~3.5 | â†‘ 199.1 |
| **Mamba (50M)** | 50M | ~2.5 | 0.88 | ~0.98 | ~4.0 | â†‘â†‘ **~300+** (estimated) |

> æ³¨ï¼šä»¥ä¸Šæ•°æ®æ¥è‡ª Figure 2 åŠæ­£æ–‡æè¿°ï¼Œéƒ¨åˆ†ä¸ºä¼°ç®—å€¼ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **vs. å¤§å‹æŒ‡ä»¤è°ƒä¼˜æ¨¡å‹ï¼ˆLLaMA-3 8B Instruct, GPT-4.1-mini ç­‰ï¼‰**ï¼š
  - å°½ç®¡å‚æ•°è§„æ¨¡å°ä¸¤ä¸ªæ•°é‡çº§ï¼ˆ51.65M vs >8Bï¼‰ï¼ŒTF3 Transformer åœ¨ LLM-as-a-judge è¯„ä¼°ä¸­ä»èƒ½è¾¾åˆ°è¿™äº›å¼ºåŸºçº¿çš„ **~90% è¡¨ç°æ°´å¹³**ï¼ˆå¹³å‡åˆ† 4.19 vs ~4.7ï¼‰ï¼Œè¡¨æ˜åˆæˆæ•°æ®è¶³ä»¥æ”¯æ’‘é«˜è´¨é‡ Romanian ç”Ÿæˆã€‚
- **vs. Mamba æ¶æ„**ï¼š
  - Transformer åœ¨ **å†…åœ¨å»ºæ¨¡è´¨é‡ï¼ˆPPLï¼‰å’Œè¯­æ³•æ­£ç¡®æ€§** ä¸Šç•¥ä¼˜ï¼›
  - Mamba åœ¨ **ååé‡** ä¸Šå…·æœ‰ä¼˜åŠ¿ï¼ˆå°¤å…¶åœ¨ MLX åç«¯ï¼‰ï¼Œä½† TF3 ä¸»ç®¡é“ä»ä»¥ Transformer ä¸ºä¸»ä»¥ä¿æŒæ¶æ„ä¸€è‡´æ€§ã€‚

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰Tokenizer æ•ˆç‡å¯¹æ¯”ï¼ˆTable 1ï¼‰
| Tokenizer | Avg Tokens/Sent. | Median |
|----------|------------------|--------|
| Romanian BPE (32k) | 304.89 | 304 |
| Romanian Unigram (32k) | **340.35** | **339** |

- **å‘ç°**ï¼šUnigram å¹¶æœªå‡å°‘ token æ•°ï¼Œåè€Œæ›´é•¿ï¼›ä½†å…¶ä¼˜åŠ¿åœ¨äº**å½¢æ€åˆ†å‰²æ›´åˆç†**ï¼ˆæ›´å¥½ä¿ç•™è¯å¹²å’Œå±ˆæŠ˜åç¼€ï¼‰ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§ä¸ç”Ÿæˆè´¨é‡ã€‚

#### ï¼ˆ2ï¼‰ç»“æ„åŒ–å‰ªæåˆ†æï¼ˆAppendix Aï¼‰
- æœ€å¤§å¯æ¥å—å‰ªæé…ç½®ï¼š**50% MLP neurons + 30% attention heads**ï¼Œå¯¹åº”æŸå¤±ä¸Šå‡ ~26â€“27%ã€‚
- æ­¤é…ç½®æˆä¸ºå­¦ç”Ÿæ¨¡å‹è®¾è®¡ä¾æ®ï¼Œé¿å…ç›²ç›®ç¼©å°å®½åº¦å¯¼è‡´å´©æºƒã€‚

#### ï¼ˆ3ï¼‰å‹ç¼©è·¯å¾„æ¯”è¾ƒï¼ˆFigure 2ï¼‰
- **Q8 é‡åŒ–**ï¼šå‡ ä¹æ— æŸï¼Œæ˜¯éƒ¨ç½²é¦–é€‰ï¼›
- **Q6 é‡åŒ–**ï¼šè™½ååé«˜ã€entity coherence é«˜ï¼ˆå› é‡å¤ç”Ÿæˆï¼‰ï¼Œä½†è¯­æ³•é”™è¯¯å¢å¤šï¼Œæµç•…åº¦ä¸‹é™ï¼›
- **è’¸é¦å­¦ç”Ÿæ¨¡å‹**ï¼šåœ¨å¤§å¹…å‡å‚ä¸‹ä¿æŒç¨³å®šå¥æ³•ç»“æ„ï¼Œé€‚åˆç”¨äºåç»­æ•°æ®ç”Ÿæˆä»»åŠ¡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **åˆæˆæ•°æ®è¶³ä»¥è®­ç»ƒé«˜è´¨é‡ Romanian SLM**ï¼šå³ä½¿å®Œå…¨åŸºäºæœºå™¨ç”Ÿæˆçš„ moral microfictionï¼Œä¹Ÿèƒ½è®© 51.65M Transformer å®ç°ç¨³å®šæ”¶æ•›ä¸è¯­æ³•è¿è´¯ç”Ÿæˆã€‚
2. âœ… **è¯­è¨€ç‰¹å®š tokenizer è‡³å…³é‡è¦**ï¼šè™½ç„¶ Romanian Unigram æœªå‡å°‘ token æ•°ï¼Œä½†å…¶**å½¢æ€ä¿çœŸåº¦æ›´é«˜**ï¼Œå¯¹ä¸‹æ¸¸å»ºæ¨¡è´¨é‡æœ‰ç§¯æå½±å“ã€‚
3. âœ… **ç»“æ„åŒ–å‰ªæå¯ç”¨äºæŒ‡å¯¼å­¦ç”Ÿæ¨¡å‹è®¾è®¡**ï¼šæ— éœ€å¤§é‡è¯•é”™ï¼Œå³å¯ç¡®å®šâ€œæœ€å°å¯è¡Œå®¹é‡â€ï¼Œä½¿çŸ¥è¯†è’¸é¦æ›´æœ‰é’ˆå¯¹æ€§ã€‚
4. âœ… **å‹ç¼©å¼•å…¥è´¨å˜è€Œéä»…é‡å˜**ï¼š
   - é‡åŒ–ï¼ˆQ8ï¼‰è¿‘ä¹æ— æŸï¼›
   - æ›´æ·±å‹ç¼©ï¼ˆQ6 / è’¸é¦ï¼‰ä¼šç‰ºç‰²è¡¨é¢æµç•…åº¦ï¼Œä½†å¯èƒ½å¢å¼ºæŸäº›å™äº‹ç»“æ„æ€§ï¼ˆå¦‚ entity coherenceï¼‰ã€‚
5. âœ… **å°å‹æ¨¡å‹å¯é€¼è¿‘å¤§å‹æŒ‡ä»¤æ¨¡å‹è¡¨ç°**ï¼šåœ¨å—æ§ä»»åŠ¡ä¸‹ï¼ŒTF3 æ¨¡å‹å¯è¾¾ LLaMA-3 8B Instruct ç­‰æ¨¡å‹çº¦ 90% çš„è¯„åˆ†ï¼Œæ€§ä»·æ¯”æé«˜ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- ğŸš« **é¢†åŸŸå—é™**ï¼šè®­ç»ƒæ•°æ®ä»…ä¸ºé“å¾·å¯“è¨€ï¼Œæ³›åŒ–è‡³æ–°é—»ã€ç§‘æŠ€ç­‰å…¶ä»–æ–‡ä½“çš„èƒ½åŠ›æœªçŸ¥ã€‚
- ğŸš« **ä¾èµ–åˆæˆæ•°æ®è´¨é‡**ï¼šè‹¥åˆå§‹ç”Ÿæˆå™¨å­˜åœ¨åè§æˆ–æ¨¡å¼å•ä¸€ï¼Œå°†è¢«æ”¾å¤§è‡³æ•´ä¸ª pipelineã€‚
- ğŸš« **ç¼ºä¹å¤§è§„æ¨¡äººå·¥è¯„ä¼°**ï¼šç›®å‰ä¾èµ– LLM-as-a-judge å’Œè‡ªåŠ¨æŒ‡æ ‡ï¼Œå¯èƒ½å­˜åœ¨åå·®ï¼ˆå¦‚ self-preference biasï¼‰ã€‚
- ğŸš« **æœªæ¢ç´¢è·¨è¯­è¨€è¿ç§»**ï¼šæœªå°è¯•å°† English TinyStories çš„çŸ¥è¯†è¿ç§»åˆ° Romanian æ¨¡å‹ä¸­ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- ğŸ” **ç”Ÿæˆæ›´å¤§ã€æ›´å¤šæ ·åŒ–çš„ Romanian åˆæˆè¯­æ–™**ï¼Œè¦†ç›–ä¸åŒä½“è£ä¸é£æ ¼ã€‚
- ğŸŒ **æ¢ç´¢ Romanian ä¸å…¶ä»–ç½—æ›¼è¯­æ—è¯­è¨€ï¼ˆå¦‚ Italian, Frenchï¼‰ä¹‹é—´çš„ cross-lingual transfer**ã€‚
- âš™ï¸ **ç ”ç©¶æ··åˆæ¶æ„**ï¼ˆhybrid attention + SSMï¼‰ï¼Œç»“åˆ Transformer çš„å»ºæ¨¡ç²¾åº¦ä¸ Mamba çš„æ¨ç†æ•ˆç‡ã€‚
- ğŸ“‰ **æ”¹è¿›å‰ªæä¸è’¸é¦æŠ€æœ¯**ï¼Œæ›´å¥½åœ°ä¿ç•™è¯­è¨€çš„**é£æ ¼ä¸°å¯Œæ€§ä¸è¡¨è¾¾å¤šæ ·æ€§**ã€‚
- ğŸ‘¥ **å¼•å…¥äººç±»è¯„ä¼°**ï¼Œå»ºç«‹æ›´å¯é çš„ Romanian æ–‡æœ¬ç”Ÿæˆè´¨é‡åŸºå‡†ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> TF3-RO æˆåŠŸéªŒè¯äº†â€œ**åˆæˆæ•°æ® + è¯­è¨€å®šåˆ¶ tokenizer + ç»“æ„æ„ŸçŸ¥å‹ç¼©**â€è¿™ä¸€èŒƒå¼ï¼Œå¯åœ¨èµ„æºæœ‰é™æ¡ä»¶ä¸‹é«˜æ•ˆæ„å»ºé«˜è´¨é‡ã€å¯éƒ¨ç½²çš„ Romanian å°å‹è¯­è¨€æ¨¡å‹ï¼Œå¹¶å½¢æˆâ€œ**è®­ç»ƒ â†’ å‹ç¼© â†’ ç”Ÿæˆæ–°æ•°æ®**â€çš„æ­£å‘å¾ªç¯ï¼Œä¸ºä½èµ„æºè¯­è¨€ NLP æä¾›äº†ä¸€æ¡æ¸…æ™°å¯è¡Œçš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 3. [CAFEDistill: Learning Personalized and Dynamic Models through Federated Early-Exit Network Distillation](https://arxiv.org/abs/2601.10015)

**Authors**: Boyi Liu, Zimu Zhou, Yongxin Tong  
**Category**: cs.LG  
**Published**: 2026-01-16  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.10015v1  

#### Abstract
Personalized Federated Learning (PFL) enables collaboratively model training on decentralized, heterogeneous data while tailoring them to each client's unique distribution. However, existing PFL methods produce static models with a fixed tradeoff between accuracy and efficiency, limiting their appli...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šCAFEDistill: Learning Personalized and Dynamic Models through Federated Early-Exit Network Distillation

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹ **Personalized Federated Learning (PFL)** é¢†åŸŸä¸­çš„ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼š
- **é™æ€æ¨¡å‹é™åˆ¶**ï¼šç°æœ‰ PFL æ–¹æ³•è®­ç»ƒå‡ºçš„æ¨¡å‹æ˜¯é™æ€çš„ï¼Œæ— æ³•åœ¨æ¨ç†æ—¶æ ¹æ®è¾“å…¥å¤æ‚åº¦åŠ¨æ€è°ƒæ•´è®¡ç®—æ·±åº¦ï¼Œéš¾ä»¥é€‚åº”èµ„æºæ³¢åŠ¨æˆ–å»¶è¿Ÿæ•æ„Ÿåœºæ™¯ã€‚
- **æ—©æœŸé€€å‡ºç½‘ç»œï¼ˆEarly-Exit Networks, EENsï¼‰åœ¨è”é‚¦å­¦ä¹ ä¸­çš„é›†æˆéš¾é¢˜**ï¼šå°† EENs å¼•å…¥ PFL ä¼šé¢ä¸´ä¸¤ç±»å†²çªï¼š
  - **å®¢æˆ·ç«¯å¼‚æ„æ€§ï¼ˆclient-wise heterogeneityï¼‰**ï¼šå„å®¢æˆ·ç«¯æ•°æ®åˆ†å¸ƒéç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆnon-IIDï¼‰ï¼Œå½±å“çŸ¥è¯†å…±äº«ã€‚
  - **æ·±åº¦é—´å¹²æ‰°ï¼ˆdepth-wise interferenceï¼‰**ï¼šæµ…å±‚ä¸æ·±å±‚å‡ºå£åœ¨è”åˆè®­ç»ƒä¸­äº§ç”Ÿåå‘ä¼ æ’­ä¿¡å·å†²çªã€‚

è¿™äº›é—®é¢˜å¯¼è‡´ç°æœ‰æ–¹æ³•ï¼ˆå¦‚å…ˆå…¨å±€è®­ç»ƒå†æœ¬åœ°å¾®è°ƒæµ…å±‚å‡ºå£ï¼‰æ€§èƒ½ä¸ä½³ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šCAFEDistill
ä½œè€…æå‡º **CAFEDistill** â€”â€” ä¸€ç§ **Conflict-Aware Federated Exit Distillation** æ¡†æ¶ï¼Œç”¨äºå®ç°ä¸ªæ€§åŒ–ä¸”åŠ¨æ€çš„è”é‚¦å­¦ä¹ ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
1. **é¦–æ¬¡å®ç° PFL-EEï¼ˆPersonalized Federated Learning of Early-Exit Networksï¼‰**
   - å°† PFL æ‰©å±•åˆ°æ”¯æŒåŠ¨æ€æ¨ç†çš„ EENsï¼Œä½¿æ¯ä¸ªå®¢æˆ·ç«¯æ‹¥æœ‰ä¸€ä¸ªå¯è‡ªé€‚åº”è·³è¿‡éƒ¨åˆ†è®¡ç®—çš„ä¸ªæ€§åŒ–æ¨¡å‹ã€‚

2. **è·¨å®¢æˆ·ç«¯çŸ¥è¯†è’¸é¦ï¼ˆCross-Client Knowledge Distillation, KDï¼‰æœºåˆ¶**
   - ä¸ä»…åˆ©ç”¨æœ¬åœ°æœ€åä¸€ä¸ªå‡ºå£ä½œä¸ºâ€œæ•™å¸ˆâ€ç›‘ç£æµ…å±‚å‡ºå£ï¼Œè¿˜å…è®¸**æ‰€æœ‰å®¢æˆ·ç«¯çš„æœ€ç»ˆå‡ºå£å…±åŒä½œä¸ºæ•™å¸ˆ**ï¼Œä¸ºä»»æ„å®¢æˆ·ç«¯çš„æµ…å±‚å‡ºå£æä¾›è’¸é¦ä¿¡å·ã€‚
   - è¿™ç§è·¨å®¢æˆ·ç«¯è’¸é¦èƒ½æœ‰æ•ˆç¼“è§£å±€éƒ¨æ•°æ®ç¨€ç–å¸¦æ¥çš„çŸ¥è¯†ä¸è¶³é—®é¢˜ã€‚

3. **æ¸è¿›å¼ã€ä»¥æ·±åº¦ä¼˜å…ˆçš„å­¦ç”Ÿé€‰æ‹©ç­–ç•¥ï¼ˆProgressive, Depth-Prioritized Student Coordinationï¼‰**
   - åœ¨è®­ç»ƒåˆæœŸåªæ¿€æ´»æœ€ç»ˆå‡ºå£ï¼ˆä½œä¸ºæ•™å¸ˆï¼‰ï¼›
   - éšç€è®­ç»ƒè¿›è¡Œï¼Œé€æ­¥å¼•å…¥æ›´æµ…çš„å‡ºå£ä½œä¸ºå­¦ç”Ÿï¼›
   - å‡å°‘å› åŒæ—¶ä¼˜åŒ–å¤šå‡ºå£è€Œå¯¼è‡´çš„æ¢¯åº¦å†²çªï¼Œæå‡ç¨³å®šæ€§ã€‚

4. **åŸºäºç›¸ä¼¼æ€§çš„æ•™å¸ˆåŒ¹é…ï¼ˆSimilarity-Aware Teacher Matchingï¼‰**
   - ä½¿ç”¨å®¢æˆ·ç«¯æ¨¡å‹æ¢¯åº¦ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦ä¼°è®¡æ•°æ®åˆ†å¸ƒç›¸ä¼¼æ€§ï¼›
   - åŠ¨æ€åˆ†é…ä¸åŒæ•™å¸ˆå‡ºå£çš„è’¸é¦æƒé‡ $k_i$ï¼Œé¿å…ä»å·®å¼‚å¤§çš„å®¢æˆ·ç«¯å¼•å…¥è´Ÿè¿ç§»ã€‚

5. **å»è€¦åˆçš„è·¨å®¢æˆ·ç«¯è’¸é¦ï¼ˆClient-Decoupled Cross-Client KDï¼‰**
   - åœ¨æœåŠ¡å™¨ç«¯èšåˆæ‰€æœ‰å®¢æˆ·ç«¯çš„æœ€ç»ˆå‡ºå£å½¢æˆä¸€ä¸ªâ€œè™šæ‹Ÿæ•™å¸ˆâ€ï¼›
   - å®¢æˆ·ç«¯åªéœ€æ¥æ”¶è¯¥èšåˆæ•™å¸ˆè¿›è¡Œæœ¬åœ°è’¸é¦ï¼›
   - å®ç°ä¸å…¨é‡è·¨å®¢æˆ·ç«¯ KD ç­‰æ•ˆçš„æ•ˆæœï¼Œä½†é€šä¿¡å¼€é”€ä¸æ ‡å‡† FedAvg ç›¸å½“ï¼ˆä»…ä¼ è¾“ backbone å’Œ aggregated teacherï¼‰ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **å‡†ç¡®æ€§** | æ˜¾è‘—ä¼˜äºå„ç±» PFL å’Œ GFL-EE åŸºçº¿ï¼Œåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå¹³å‡æå‡æœ€é«˜è¾¾ 21.29% |
| **æ¨ç†æ•ˆç‡** | æ”¯æŒ early-exitï¼Œæ˜¾è‘—é™ä½ MAC æ•°é‡ï¼ŒèŠ‚çœ 30.79%-46.86% æ¨ç†æˆæœ¬ |
| **é€šä¿¡æ•ˆç‡** | é€šä¿¡å¼€é”€ä»…æ¯” FedAvg é«˜çº¦ 0.45%ï¼Œè¿œä½äºç›´æ¥å®æ–½è·¨å®¢æˆ·ç«¯ KD çš„æ–¹æ¡ˆ |
| **é²æ£’æ€§** | èƒ½æœ‰æ•ˆåº”å¯¹é«˜åº¦ non-IID æ•°æ®ï¼ˆDir(Î±=0.1)ï¼‰ä¸‹çš„è®­ç»ƒæŒ‘æˆ˜ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **å›¾åƒåˆ†ç±»ä»»åŠ¡**ï¼š
  - CIFAR-10ï¼ˆ10ç±»ï¼‰
  - CIFAR-100ï¼ˆ100ç±»ï¼‰
  - TinyImageNetï¼ˆ200ç±»ï¼‰
- **æ–‡æœ¬åˆ†ç±»ä»»åŠ¡**ï¼š
  - AgNewsï¼ˆ4ç±»æ–°é—»ç±»åˆ«ï¼‰

æ•°æ®åˆ’åˆ†é‡‡ç”¨ **Dirichlet åˆ†å¸ƒï¼ˆDir(Î±)ï¼‰** æ§åˆ¶ non-IID ç¨‹åº¦ï¼Œæµ‹è¯•äº† Î± = 0.3 å’Œ Î± = 0.1 ä¸¤ç§æç«¯æƒ…å†µã€‚

---

### å®éªŒè®¾ç½®
| å‚æ•° | è®¾ç½® |
|------|------|
| å®¢æˆ·ç«¯æ•°é‡ | 100 |
| å‚ä¸ç‡ï¼ˆSample Rateï¼‰ | 10% æ¯è½® |
| é€šä¿¡è½®æ•° | 300ï¼ˆå›¾åƒï¼‰ï¼Œ100ï¼ˆæ–‡æœ¬ï¼‰ |
| æœ¬åœ°è®­ç»ƒè½®æ•°ï¼ˆLocal Epochsï¼‰ | 5ï¼ˆå›¾åƒï¼‰ï¼Œ1ï¼ˆæ–‡æœ¬ï¼‰ |
| æ¨¡å‹æ¶æ„ | ConvNetï¼ˆCIFAR-10ï¼‰ã€ResNet-18ï¼ˆCIFAR-100/TinyImageNetï¼‰ã€Transformerï¼ˆAgNewsï¼‰ |
| å‡ºå£æ•°é‡ | 3â€“4 ä¸ªä¸­é—´å‡ºå£ |
| ä¼˜åŒ–å™¨ | SGDï¼ˆmomentum=0.9, weight decay=1e-4, lr=0.1ï¼‰ |

---

### è¯„ä¼°æŒ‡æ ‡
1. **Accuracy**ï¼šæ ·æœ¬åœ¨ç»ˆæ­¢å‡ºå£å¤„çš„é¢„æµ‹å‡†ç¡®ç‡ã€‚
2. **Averaged Accuracy**ï¼šæ‰€æœ‰å‡ºå£å‡†ç¡®ç‡çš„å¹³å‡å€¼ã€‚
3. **Inference Efficiency**ï¼šæ¯æ ·æœ¬çš„ Multiply-Accumulate (MAC) æ“ä½œæ•°ï¼Œè¡¡é‡è®¡ç®—å¼€é”€ã€‚
4. **Accuracy-Efficiency Tradeoff**ï¼šåœ¨ä¸åŒ exit threshold ä¸‹ç»˜åˆ¶ accuracy vs. MAC æ›²çº¿ã€‚

---

### å¯¹æ¯”çš„åŸºçº¿æ–¹æ³•
#### ï¼ˆ1ï¼‰é€šç”¨è”é‚¦å­¦ä¹ ï¼ˆGFLï¼‰ä¸ PFL åŸºçº¿ï¼ˆæ‰©å±•è‡³ EENsï¼‰ï¼š
- **Local-EE**ï¼šå®Œå…¨æœ¬åœ°è®­ç»ƒ
- **FedAvg-EE**, **FedProx-EE**ï¼šç»å…¸ GFL æ–¹æ³•æ‰©å±•
- **FedPer-EE**, **FedRep-EE**, **FedBABU-EE**, **FedAMP-EE**, **pFedGraph-EE**, **FedRoD-EE**, **Ditto-EE**, **FedPAC-EE**ï¼šä»£è¡¨æ€§ PFL æ–¹æ³•æ‰©å±•

#### ï¼ˆ2ï¼‰ä¸“ä¸º EEN è®¾è®¡çš„ GFL-EE æ–¹æ³•ï¼š
- **ScaleFL**ï¼šåŸºäºæœ¬åœ° KD çš„èµ„æºé€‚é… FL
- **DepthFL**ï¼šåŒå‘ KD ä¸å¼‚æ„ä¼˜åŒ–å™¨

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰
| æ•°æ®é›† | æ–¹æ³• | Dir(0.3) å¹³å‡å‡†ç¡®ç‡ |
|--------|-------|---------------------|
| CIFAR-10 | CAFEDistill | **72.67Â±10.71** |
| CIFAR-100 | CAFEDistill | **50.41Â±5.47** |
| TinyImageNet | CAFEDistill | **36.27Â±10.86** |
| AgNews | CAFEDistill | **78.69Â±14.63** |

> âœ… åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šå‡å–å¾— **SOTA æ€§èƒ½**

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨ **CIFAR-100 (Dir(0.3))** ä¸Šï¼Œç›¸æ¯”æœ€å¼º PFL-EE åŸºçº¿ FedPAC-EEï¼ˆ47.45%ï¼‰ï¼ŒCAFEDistill è¾¾åˆ° **50.41%**ï¼Œæå‡ **+2.96pp**ã€‚
- åœ¨ **TinyImageNet (Dir(0.1))** ä¸Šï¼Œç›¸æ¯” FedPAC-EEï¼ˆ46.47%ï¼‰ï¼ŒCAFEDistill è¾¾åˆ° **48.22%**ï¼Œæå‡ **+1.75pp**ã€‚
- åœ¨ **AgNews** ä¸Šï¼Œè¶…è¶Šç¬¬äºŒå FedRoD-EEï¼ˆ77.24%ï¼‰è¾¾ **78.69%**ã€‚

æ›´é‡è¦çš„æ˜¯ï¼š
> ğŸ“‰ **æ¨ç†æˆæœ¬é™ä½ 30.79% â€“ 46.86%**

ä¾‹å¦‚åœ¨ CIFAR-100 ä¸Šï¼Œè¾¾åˆ°ç›¸åŒç²¾åº¦æ—¶ï¼ŒCAFEDistill æ‰€éœ€ MAC æ¯”å…¶ä»–æ–¹æ³•å°‘ **2.5â€“14.5%**ï¼›ç»™å®šç›¸åŒè®¡ç®—é¢„ç®—ï¼Œå…¶ç²¾åº¦é«˜å‡º **2.5â€“14.5%**ï¼ˆè§ Figure 7ï¼‰ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 4ï¼‰
éªŒè¯äº† CAFEDistill å„ç»„ä»¶çš„æœ‰æ•ˆæ€§ï¼ˆåœ¨ CIFAR-100 ä¸Šï¼‰ï¼š

| é…ç½® | Exit-1 | Exit-2 | Exit-3 | Exit-4 | ç»“è®º |
|------|--------|--------|--------|--------|------|
| æ—  KD | 36.29 | 37.92 | 41.45 | 41.88 | åŸºçº¿ |
| + Local KD | 36.45 | 38.10 | 38.31 | 37.51 | âŒ æµ…å±‚ç•¥å‡ï¼Œæ·±å±‚ä¸‹é™ â†’ å±€éƒ¨ KD æœ‰å®³ |
| + Cross-Client KD (TM) | 42.06 | 45.64 | 48.21 | 51.91 | âœ… å…¨é¢æå‡ï¼ˆ+5.77~10.03%ï¼‰ |
| + å­¦ç”Ÿé€‰æ‹© (SS) | **45.45** | **49.69** | **53.42** | **53.08** | âœ… å†æå‡ï¼ˆ+1.17~5.21%ï¼‰ |

ğŸ‘‰ è¡¨æ˜ï¼š**è·¨å®¢æˆ·ç«¯ KD + æ¸è¿›å¼è®­ç»ƒ** æ˜¯æˆåŠŸçš„å…³é”®ã€‚

æ­¤å¤–ï¼ŒTable 3 æ˜¾ç¤ºï¼šå¯¹ç°æœ‰ PFL-EE æ–¹æ³•æ·»åŠ  local KD åè€Œä¼šæŸå®³æ·±å±‚å‡ºå£æ€§èƒ½ï¼Œè¿›ä¸€æ­¥è¯´æ˜ä¼ ç»Ÿ KD ä¸é€‚ç”¨äºé«˜åº¦ non-IID åœºæ™¯ä¸‹çš„ PFL-EEã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **PFL ä¸ EEN å¯ä»¥æœ‰æ•ˆç»“åˆ**ï¼šCAFEDistill æˆåŠŸå®ç°äº†æ—¢èƒ½ä¸ªæ€§åŒ–åˆèƒ½åŠ¨æ€æ¨ç†çš„è”é‚¦å­¦ä¹ æ¡†æ¶ã€‚
2. âœ… **è·¨å®¢æˆ·ç«¯çŸ¥è¯†è’¸é¦è‡³å…³é‡è¦**ï¼šä»…ä¾èµ–æœ¬åœ° KD ä¼šå¯¼è‡´æ·±å±‚å‡ºå£é€€åŒ–ï¼Œå¿…é¡»å¼•å…¥è·¨å®¢æˆ·ç«¯çŸ¥è¯†èåˆã€‚
3. âœ… **æ¸è¿›å¼è®­ç»ƒç¼“è§£æ·±åº¦å¹²æ‰°**ï¼šé€šè¿‡ depth-prioritized åè°ƒæœºåˆ¶ï¼Œæ˜¾è‘—å‡å°‘å¤šå‡ºå£è”åˆè®­ç»ƒä¸­çš„å†²çªã€‚
4. âœ… **é«˜æ•ˆé€šä¿¡è®¾è®¡å¯è¡Œ**ï¼šæå‡ºçš„ client-decoupled formulation åœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹ï¼Œå°†é€šä¿¡å¼€é”€æ§åˆ¶åœ¨ FedAvg æ°´å¹³ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. å½“å‰å‡è®¾æ‰€æœ‰å®¢æˆ·ç«¯ä½¿ç”¨ç›¸åŒçš„ EEN æ¶æ„ï¼ˆç›¸åŒå±‚æ•°ã€ç›¸åŒå‡ºå£ä½ç½®ï¼‰ï¼Œæœªè€ƒè™‘è®¾å¤‡çº§å¼‚æ„æ€§ï¼ˆå¦‚å†…å­˜ã€ç®—åŠ›å·®å¼‚ï¼‰ã€‚
2. æ•™å¸ˆåŒ¹é…ä¾èµ–æ¢¯åº¦ç›¸ä¼¼æ€§ä»£ç†æ•°æ®åˆ†å¸ƒï¼Œå¯èƒ½åœ¨æŸäº›æç«¯åˆ†å¸ƒåç§»ä¸‹å¤±æ•ˆã€‚
3. å®éªŒä¸»è¦é›†ä¸­åœ¨å›¾åƒå’Œç®€å•æ–‡æœ¬ä»»åŠ¡ï¼Œå°šæœªéªŒè¯åœ¨å¤šæ¨¡æ€æˆ–åºåˆ—å»ºæ¨¡ç­‰å¤æ‚åœºæ™¯çš„è¡¨ç°ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **multi-modal scenarios**ï¼ˆå¦‚è§†è§‰-è¯­è¨€æ¨¡å‹ï¼‰
- æ”¯æŒ **client resource heterogeneity**ï¼Œå…è®¸ä¸åŒå®¢æˆ·ç«¯æ‹¥æœ‰ä¸åŒæ·±åº¦çš„ EEN
- æ¢ç´¢æ›´é«˜æ•ˆçš„ **exit policy learning**ï¼ˆå½“å‰ä½¿ç”¨å›ºå®šé˜ˆå€¼ confidence-based policyï¼‰
- ç»“åˆ **model compression** æˆ– **pruning** è¿›ä¸€æ­¥é™ä½éƒ¨ç½²æˆæœ¬

---

## æ€»ç»“
CAFEDistill æ˜¯é¦–ä¸ªå°† **Personalized Federated Learning** ä¸ **Early-Exit Networks** æˆåŠŸç»“åˆçš„å·¥ä½œï¼Œæå‡ºäº† **Conflict-Aware Federated Exit Distillation** æ¡†æ¶ï¼Œé€šè¿‡ **è·¨å®¢æˆ·ç«¯çŸ¥è¯†è’¸é¦ + æ¸è¿›å¼è®­ç»ƒ + å»è€¦åˆé€šä¿¡è®¾è®¡**ï¼Œåœ¨ä¿æŒä½é€šä¿¡å¼€é”€çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹å‡†ç¡®æ€§å’Œæ¨ç†æ•ˆç‡ã€‚å®éªŒè¯æ˜å…¶åœ¨å¤šç§ non-IID åœºæ™¯ä¸‹å…¨é¢è¶…è¶Š SOTA æ–¹æ³•ï¼Œä¸ºæ„å»ºé«˜æ•ˆã€çµæ´»ã€ä¸ªæ€§åŒ–çš„è¾¹ç¼˜æ™ºèƒ½ç³»ç»Ÿæä¾›äº†é‡è¦æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 4. [Efficient Content-based Recommendation Model Training via Noise-aware Coreset Selection](https://arxiv.org/abs/2601.10067)

**Authors**: Hung Vinh Tran, Tong Chen, Hechuan Wen, Quoc Viet Hung Nguyen, Bin Cui, Hongzhi Yin  
**Category**: cs.LG  
**Published**: 2026-01-16  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.10067v1  

#### Abstract
Content-based recommendation systems (CRSs) utilize content features to predict user-item interactions, serving as essential tools for helping users navigate information-rich web services. However, ensuring the effectiveness of CRSs requires large-scale and even continuous model training to accommod...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šEfficient Content-based Recommendation Model Training via Noise-aware Coreset Selection**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
- **è®­ç»ƒæ•ˆç‡ç“¶é¢ˆ**ï¼šå†…å®¹æ¨èç³»ç»Ÿï¼ˆCRSï¼‰ä¾èµ–å¤§è§„æ¨¡ç”¨æˆ·-ç‰©å“äº¤äº’æ—¥å¿—è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œå¯¼è‡´é«˜æ˜‚çš„è®¡ç®—æˆæœ¬ã€æ—¶é—´å¼€é”€å’Œç¢³è¶³è¿¹ã€‚
- **å™ªå£°æ ‡ç­¾å½±å“**ï¼šCRSå¹¿æ³›ä½¿ç”¨éšå¼åé¦ˆï¼ˆå¦‚ç‚¹å‡»ï¼‰ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œä½†è¿™ç±»æ•°æ®å­˜åœ¨å¤§é‡å™ªå£°ï¼ˆè¯¯ç‚¹ã€å¥½å¥‡ç‚¹å‡»ç­‰ï¼‰ï¼Œç›´æ¥å½±å“å°è§„æ¨¡ coreset çš„è´¨é‡ã€‚
- **ç°æœ‰ coreset æ–¹æ³•ä¸é€‚ç”¨**ï¼šä¼ ç»Ÿ coreset é€‰æ‹©æ–¹æ³•å‡è®¾æ•°æ®æ— å™ªå£°ï¼Œä¸”å¤šé’ˆå¯¹ååŒè¿‡æ»¤ä»»åŠ¡è®¾è®¡ï¼Œéš¾ä»¥ç›´æ¥åº”ç”¨äºå¤æ‚çš„åŸºäºå†…å®¹çš„æ¨èåœºæ™¯ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ï¼šNoise-aware Coreset Selection (NaCS)**
NaCS æ˜¯ä¸€ä¸ªä¸“ä¸ºå†…å®¹æ¨èç³»ç»Ÿè®¾è®¡çš„å™ªå£°æ„ŸçŸ¥ coreset é€‰æ‹©æ¡†æ¶ï¼ŒåŒ…å«ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š
1. **åŸºäºå­æ¨¡ä¼˜åŒ–çš„é«˜æ•ˆ coreset é€‰æ‹©**  
   - å°† coreset é€‰æ‹©å»ºæ¨¡ä¸ºå­æ¨¡ä¼˜åŒ–é—®é¢˜ï¼Œç›®æ ‡æ˜¯é€‰å‡ºèƒ½æœ€å¥½åœ°è¿‘ä¼¼å…¨é‡æ•°æ®æ¢¯åº¦çš„æ ·æœ¬å­é›†ã€‚
   - ä»…ä½¿ç”¨æœ€ç»ˆå±‚æ¢¯åº¦ï¼ˆfinal layer gradientï¼‰æ¥ä¼°è®¡æ¢¯åº¦å·®å¼‚ï¼Œæ˜¾è‘—é™ä½è®¡ç®—å¼€é”€ã€‚
   - é‡‡ç”¨ **stochastic greedy ç®—æ³•** å¹¶åœ¨ GPU ä¸Šå®ç°æ‰¹é‡å¹¶è¡Œå¤„ç†ï¼Œå¤§å¹…æå‡é€‰æ‹©æ•ˆç‡ã€‚

2. **æ¸è¿›å¼æ ‡ç­¾è‡ªä¿®æ­£ï¼ˆProgressive Label Self-Correctionï¼‰**  
   - åœ¨ coreset æ„å»ºè¿‡ç¨‹ä¸­ï¼Œåˆ©ç”¨å½“å‰æ¨¡å‹å¯¹æ•´ä¸ªæ•°æ®é›†çš„é¢„æµ‹ç»“æœï¼ŒåŠ¨æ€æ›´æ–°æ ·æœ¬æ ‡ç­¾ï¼ˆè½¯æ ‡ç­¾ï¼‰ï¼š
     $$
     y^* = (1 - \epsilon)y + \epsilon \hat{y}
     $$
     å…¶ä¸­ $\epsilon$ éšè®­ç»ƒè¿›ç¨‹å¢é•¿ï¼ˆâ€œå…¨å±€ä¿¡ä»»â€ï¼‰ä¸”ä¾èµ–äºæ¨¡å‹å¯¹è¯¥æ ·æœ¬çš„ç½®ä¿¡åº¦ï¼ˆâ€œå±€éƒ¨ä¿¡ä»»â€ç†µï¼‰ã€‚
   - å®ç°äº†åœ¨ä¸å¼•å…¥é¢å¤–æ ‡æ³¨çš„æƒ…å†µä¸‹é€æ­¥çº æ­£å™ªå£°æ ‡ç­¾ã€‚

3. **åŸºäºä¸ç¡®å®šæ€§çš„ coreset å»å™ªï¼ˆUncertainty-based Denoisingï¼‰**  
   - å¯¹åˆæ­¥æ„å»ºçš„ coreset åº”ç”¨ **Monte Carlo Dropout** è¿›è¡Œå¤šæ¬¡å‰å‘ä¼ æ’­ï¼Œä¼°è®¡æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹ä¸ç¡®å®šæ€§ã€‚
   - ç§»é™¤ä¸ç¡®å®šæ€§æœ€é«˜çš„æ ·æœ¬ï¼ˆå¦‚ top 10%ï¼‰ï¼Œè¿›ä¸€æ­¥æå‡ coreset è´¨é‡ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹é¢ | NaCS | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ CGMã€SVP-CFã€K-Centerï¼‰ |
|------|------|-----------------------------|
| **æ•°æ®è¡¨ç¤º** | ä½¿ç”¨åŸå§‹ç¨€ç–ç‰¹å¾ | CGM ä½¿ç”¨ç¨ å¯†åˆæˆç‰¹å¾ï¼Œè„±ç¦»ç°å® |
| **å™ªå£°é²æ£’æ€§** | æ˜¾å¼å»ºæ¨¡å¹¶çº æ­£å™ªå£°æ ‡ç­¾ | å‡è®¾æ•°æ®å¹²å‡€ï¼Œæ˜“å—å™ªå£°è¯¯å¯¼ |
| **è®¡ç®—æ•ˆç‡** | ä»…ç”¨æœ€ç»ˆå±‚æ¢¯åº¦ + æ‰¹é‡å¹¶è¡Œ | éœ€å…¨ç½‘ç»œåå‘ä¼ æ’­æˆ–åŒå±‚ä¼˜åŒ–ï¼Œå¼€é”€å¤§ |
| **å®ç”¨æ€§** | å¯æ‰©å±•è‡³ LLM-based æ¨èå™¨ | å¤šæ•°å±€é™äºä¼ ç»Ÿæ¨¡å‹ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **Criteo**ï¼šå¹¿å‘Šç‚¹å‡»é¢„æµ‹æ•°æ®é›†ï¼Œ4584ä¸‡æ¡è®°å½•ã€‚
- **Avazu**ï¼šç§»åŠ¨å¹¿å‘Šç‚¹å‡»æ•°æ®é›†ï¼Œ4043ä¸‡æ¡è®°å½•ã€‚
- **KDD Cup 2012**ï¼šå­¦æœ¯ç«èµ›æ•°æ®é›†ï¼Œ1.5äº¿æ¡è®°å½•ã€‚
- æ‰€æœ‰æ•°æ®é›†æŒ‰ 8:1:1 åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†ã€‚

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**
- **éª¨å¹²æ¨¡å‹**ï¼š
  - DeepFM
  - DCNv2
- **coreset è§„æ¨¡**ï¼š0.5%, 1%, 5%
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **AUC**ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰
  - **Log Loss**ï¼ˆè¶Šä½è¶Šå¥½ï¼‰
- **è®­ç»ƒé…ç½®**ï¼š
  - Adam ä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ 0.01ï¼Œbatch size 8192
  - Early stopping é˜²æ­¢è¿‡æ‹Ÿåˆ

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **Random** | éšæœºé‡‡æ · | æœ€ç®€å•åŸºçº¿ |
| **SVP-CF** | ä»£ç†æ¨¡å‹æ‰“åˆ† | ä½¿ç”¨ FM æ¨¡å‹è¯„åˆ†é€‰æ ·æœ¬ |
| **K-Center** | èšç±»ä¸­å¿ƒé€‰æ‹© | æœ€å°åŒ–æœ€å¤§è·ç¦» |
| **CGM** | æ•°æ®è’¸é¦ | æ¢¯åº¦åŒ¹é…ç”Ÿæˆåˆæˆæ•°æ® |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
- **ä»…ç”¨ 1% æ•°æ®å³å¯æ¢å¤ 93â€“95% å…¨é‡è®­ç»ƒæ€§èƒ½**ï¼š
  - Criteo @1%ï¼šAUC è¾¾åˆ° 0.7707ï¼ˆå…¨é‡ä¸º 0.8117ï¼‰ï¼Œæ¢å¤çº¦ **95%**
  - Avazu @1%ï¼šAUC è¾¾åˆ° 0.7365ï¼ˆå…¨é‡ä¸º 0.7891ï¼‰ï¼Œæ¢å¤çº¦ **93%**
  - KDD @1%ï¼šAUC è¾¾åˆ° 0.7441ï¼ˆå…¨é‡ä¸º 0.7995ï¼‰ï¼Œæ¢å¤çº¦ **93%**

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœï¼ˆTable 2ï¼‰**
- åœ¨æ‰€æœ‰æ•°æ®é›†å’Œæ¯”ä¾‹ä¸‹ï¼Œ**NaCS æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿æ–¹æ³•**ã€‚
- ä¼˜åŠ¿åœ¨å°è§„æ¨¡ coresetï¼ˆå¦‚ 0.5%ï¼‰æ—¶æ›´ä¸ºæ˜æ˜¾ã€‚
- CGM è¡¨ç°è¾ƒå·®ï¼Œå› å…¶ä½¿ç”¨ç¨ å¯†è¡¨ç¤ºä¸”è®­ç»ƒå¼€é”€å¤§ã€‚
- Random åœ¨æŸäº›æƒ…å†µä¸‹è¡¨ç°å°šå¯ï¼Œè¯´æ˜ coreset è´¨é‡é«˜åº¦ä¾èµ–é€‰æ‹©ç­–ç•¥ã€‚

### **æ¶ˆèå®éªŒç»“æœï¼ˆTable 3ï¼‰**
#### **(a) Coreset ç›®æ ‡å‡½æ•°æœ‰æ•ˆæ€§**
- â€œSet Coverâ€ å’Œ â€œRandomâ€ åœ¨å»å™ªåä»æœ‰æå‡ï¼Œä½† NaCS æ•ˆæœæœ€ä½³ï¼Œè¯æ˜å…¶å­æ¨¡ä¼˜åŒ–ç›®æ ‡æ›´ä¼˜ã€‚

#### **(b) æŸå¤±å‡½æ•°å¯¹æ¯”**
- ä½¿ç”¨ BCE æˆ– R-CE æŸå¤±æœ‰ä¸€å®šæ”¹è¿›ï¼Œä½† NaCS çš„æ¸è¿›æ ‡ç­¾ä¿®æ­£æ•ˆæœæœ€å¥½ã€‚
- T-CE è¡¨ç°å·®ï¼Œå¯èƒ½å› è¿‡åº¦æŠ‘åˆ¶æ­£æ ·æœ¬ã€‚

#### **(c) å»å™ªæ¨¡å—æœ‰æ•ˆæ€§**
- åŠ å…¥å»å™ªåæ€§èƒ½å…¨é¢æå‡ã€‚
- è‹¥ä½¿ç”¨å…¨é‡æ•°æ®è®­ç»ƒçš„æ¨¡å‹ä½œä¸ºâ€œå®Œç¾å»å™ªå™¨â€ï¼Œæ€§èƒ½å¯è¿›ä¸€æ­¥æå‡ï¼Œè¯´æ˜å½“å‰å»å™ªä»æœ‰ä¼˜åŒ–ç©ºé—´ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **å°è§„æ¨¡é«˜è´¨é‡ coreset å¯è¡Œ**ï¼šé€šè¿‡åˆç†é€‰æ‹©ä¸å»å™ªï¼Œ**1% æ•°æ®è¶³ä»¥æ”¯æ’‘æ¥è¿‘å…¨é‡è®­ç»ƒçš„æ¨èæ€§èƒ½**ã€‚
2. **å™ªå£°æ˜¯å° coreset çš„è‡´å‘½å› ç´ **ï¼šå¿½ç•¥å™ªå£°ä¼šå¯¼è‡´é€‰æ‹©åå·®ï¼ŒNaCS çš„ä¸¤é˜¶æ®µå»å™ªæœºåˆ¶æœ‰æ•ˆç¼“è§£è¯¥é—®é¢˜ã€‚
3. **æ¨¡å‹å¤æ‚åº¦éœ€ä¸æ•°æ®é¢„ç®—åŒ¹é…**ï¼šåœ¨æå°æ•°æ®ä¸‹ï¼ˆå¦‚ 1%ï¼‰ï¼Œç®€å•æ¨¡å‹ï¼ˆDeepFMï¼‰åè€Œä¼˜äºå¤æ‚æ¨¡å‹ï¼ˆDCNv2ï¼‰ï¼Œå› å…¶æ›´æŠ—è¿‡æ‹Ÿåˆã€‚
4. **NaCS å…·å¤‡è‰¯å¥½æ³›åŒ–èƒ½åŠ›**ï¼š
   - åœ¨æ–‡æœ¬æ¨èï¼ˆMIND + LLMï¼‰ä»»åŠ¡ä¸­ä»ä¼˜äºéšæœºé€‰æ‹©ã€‚
   - å¯æ— ç¼è¿ç§»è‡³ä¸åŒ backboneï¼ˆDeepFMã€DCNv2ã€FinalMLPï¼‰ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–æ¨¡å‹æ¢¯åº¦**ï¼šéœ€è¦è¿è¡Œå‰å‘/éƒ¨åˆ†åå‘ä¼ æ’­ï¼Œæ— æ³•å®Œå…¨é¿å…è®¡ç®—å¼€é”€ã€‚
- **å»å™ªè¿‡ç¨‹ä»å¯èƒ½å¼•å…¥åå·®**ï¼šæ¸è¿›ä¿®æ­£è‹¥åˆå§‹æ¨¡å‹é”™è¯¯ä¸¥é‡ï¼Œå¯èƒ½å¯¼è‡´é”™è¯¯ç´¯ç§¯ï¼ˆå°½ç®¡ early stopping ç¼“è§£äº†è¯¥é—®é¢˜ï¼‰ã€‚
- **è¶…å‚æ•°æ•æ„Ÿ**ï¼šå¦‚ `Nchoose`ï¼ˆé€‰æ‹©æ­¥æ•°ï¼‰ã€ç§»é™¤æ¯”ä¾‹ç­‰éœ€è°ƒä¼˜ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- å°† NaCS æ‰©å±•è‡³ **è”é‚¦å­¦ä¹ ** å’Œ **æµå¼æ¨è** åœºæ™¯ã€‚
- æ¢ç´¢æ›´å…ˆè¿›çš„ä¸ç¡®å®šæ€§é‡åŒ–æ–¹æ³•æ›¿ä»£ Monte Carlo Dropoutã€‚
- ç»“åˆä¸»åŠ¨å­¦ä¹ ï¼Œåœ¨çº¿è¿­ä»£ä¼˜åŒ– coresetã€‚
- æ”¯æŒå¤šä»»åŠ¡ä¸è·¨åŸŸæ¨èä¸­çš„ coreset æ„å»ºã€‚

---

> âœ… **ä»£ç å¼€æº**ï¼šä½œè€…å·²å°†æºç å…¬å¼€äº GitHubï¼š[https://github.com/chenxing1999/nacs](https://github.com/chenxing1999/nacs)

</details>

---

### 5. [Memo-SQL: Structured Decomposition and Experience-Driven Self-Correction for Training-Free NL2SQL](https://arxiv.org/abs/2601.10011)

**Authors**: Zerui Yang, Weichuan Wang, Yanwei Xu, Linqi Song, Yudai Matsuda, Wei Han, Bo Bai  
**Category**: cs.AI  
**Published**: 2026-01-16  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.10011v1  

#### Abstract
Existing NL2SQL systems face two critical limitations: (1) they rely on in-context learning with only correct examples, overlooking the rich signal in historical error-fix pairs that could guide more robust self-correction; and (2) test-time scaling approaches often decompose questions arbitrarily, ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMemo-SQL: Structured Decomposition and Experience-Driven Self-Correction for Training-Free NL2SQL

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰ NL2SQL ç³»ç»Ÿå­˜åœ¨ä¸‰å¤§å…³é”®å±€é™ï¼š
1. **ä¾èµ–é™æ€ in-context learning**ï¼šä»…ä½¿ç”¨æ­£ç¡®ç¤ºä¾‹è¿›è¡Œæç¤ºï¼Œå¿½ç•¥äº†å†å²é”™è¯¯-ä¿®æ­£å¯¹ï¼ˆerror-fix pairsï¼‰ä¸­è•´å«çš„ä¸°å¯Œä¿¡å·ï¼Œæ— æ³•æœ‰æ•ˆæŒ‡å¯¼æ¨¡å‹è‡ªæˆ‘ä¿®æ­£ã€‚
2. **Test-Time Scaling (TTS) æ–¹æ³•ç¼ºä¹å¤šæ ·æ€§**ï¼šå¤šæ•°åˆ†è§£ç­–ç•¥ç”± LLM è‡ªä¸»å†³å®šï¼Œå¯¼è‡´ä¸åŒè¿è¡Œé—´ç”Ÿæˆé«˜åº¦ç›¸ä¼¼ç”šè‡³ç›¸åŒçš„ SQL å€™é€‰ï¼Œå‰Šå¼±äº†é›†æˆï¼ˆensembleï¼‰æ•ˆæœã€‚
3. **å‡†ç¡®ç‡ä¸æ•ˆç‡çš„æƒè¡¡å›°å¢ƒ**ï¼šé«˜æ€§èƒ½æ–¹æ³•è®¡ç®—å¼€é”€å·¨å¤§ï¼Œè€Œè½»é‡çº§æ–¹æ¡ˆåˆ™ç‰ºç‰²è´¨é‡ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡º **Memo-SQL**ï¼Œä¸€ä¸ªæ— éœ€è®­ç»ƒçš„ NL2SQL æ¡†æ¶ï¼Œæ ¸å¿ƒåˆ›æ–°åœ¨äºä¸¤ä¸ªç®€å•ä½†æœ‰æ•ˆçš„æœºåˆ¶ï¼š

#### ï¼ˆ1ï¼‰Structured Decompositionï¼ˆç»“æ„åŒ–åˆ†è§£ï¼‰
æ‘’å¼ƒéšæœºæˆ– LLM è‡ªä¸»å†³å®šçš„åˆ†è§£æ–¹å¼ï¼Œå¼•å…¥ä¸‰ç§æ˜ç¡®çš„è¯­ä¹‰è½´å‘åˆ†è§£ç­–ç•¥ï¼Œä»¥æå‡æ¨ç†è·¯å¾„çš„å¤šæ ·æ€§ï¼š
- **Entity-wiseï¼ˆå®ä½“çº§ï¼‰**ï¼šæŒ‰æ•°æ®åº“ä¸­çš„è¡¨/å®ä½“åˆ’åˆ†å­é—®é¢˜ï¼ˆå¦‚å®¢æˆ·ã€è®¢å•ç­‰ï¼‰ï¼Œåˆ†åˆ«ç”Ÿæˆå±€éƒ¨æŸ¥è¯¢åé€šè¿‡å¤–é”®è¿æ¥ã€‚
- **Hierarchicalï¼ˆå±‚æ¬¡åŒ–ï¼‰**ï¼šå¤„ç†åµŒå¥—è¯­è¨€ç»“æ„ï¼ˆå¦‚â€œé«˜äºå¹³å‡å€¼â€ã€â€œä»æœªè®¢è´­è¿‡â€ï¼‰ï¼Œä»å†…å±‚èšåˆæ¡ä»¶å‘å¤–å±‚é€’å½’åˆ†è§£ï¼Œå¯¹åº” SQL ä¸­çš„ `NOT EXISTS` æˆ– `IN` å­å¥ã€‚
- **Atomic Sequentialï¼ˆåŸå­é¡ºåºï¼‰**ï¼šå°†é—®é¢˜æ‹†è§£ä¸ºä¸€ç³»åˆ—åŸå­å…³ç³»æ“ä½œï¼ˆé€‰æ‹©ã€æŠ•å½±ã€è¿æ¥ã€åˆ†ç»„ã€èšåˆï¼‰ï¼Œå®ç°ç»†ç²’åº¦é”™è¯¯å®šä½ã€‚

> è¿™ä¸‰ç§ç­–ç•¥å¹¶è¡Œæ‰§è¡Œï¼Œè‡ªç„¶å½¢æˆ **best-of-Nï¼ˆN=3ï¼‰** çš„å€™é€‰é€‰æ‹©æœºåˆ¶ã€‚

#### ï¼ˆ2ï¼‰Experience-Driven Self-Correctionï¼ˆç»éªŒé©±åŠ¨çš„è‡ªæˆ‘ä¿®æ­£ï¼‰
æ„å»ºä¸€ä¸ªåŠ¨æ€çš„ **error-correction memory**ï¼Œå­˜å‚¨å†å²ä¸Šçš„é”™è¯¯-ä¿®æ­£å¯¹ï¼ˆåŒ…æ‹¬é”™è¯¯ç±»å‹å’Œä¿®æ­£å»ºè®®ï¼‰ã€‚åœ¨æ¨ç†æ—¶ï¼š
- ä½¿ç”¨æ£€ç´¢å¢å¼ºï¼ˆretrieval-augmentedï¼‰æŠ€æœ¯ï¼ŒåŸºäºå½“å‰ç”Ÿæˆçš„ SQL ç»“æ„å’Œé—®é¢˜ï¼Œä»è®°å¿†åº“ä¸­å¬å›æœ€ç›¸å…³çš„é”™è¯¯ä¿®å¤æ¡ˆä¾‹ã€‚
- å°†è¿™äº›æ¡ˆä¾‹ä½œä¸ºä¸Šä¸‹æ–‡ç¤ºä¾‹æ³¨å…¥ promptï¼Œå¼•å¯¼æ¨¡å‹è¯†åˆ«å¹¶ä¿®æ­£æ½œåœ¨é”™è¯¯ã€‚

è¯¥æœºåˆ¶å®ç°äº†çœŸæ­£çš„â€œä»å¤±è´¥ä¸­å­¦ä¹ â€ï¼Œä¸”å®Œå…¨æ— éœ€ fine-tuning æˆ–å¤–éƒ¨ APIã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- âœ… **æ— éœ€è®­ç»ƒ**ï¼šçº¯ test-time scalingï¼Œé€‚ç”¨äºå¼€æº LLMã€‚
- âœ… **é«˜æ•ˆä¸”é«˜ç²¾åº¦**ï¼šåœ¨æ˜¾è‘—é™ä½è®¡ç®—èµ„æºæ¶ˆè€—çš„åŒæ—¶è¾¾åˆ° SOTA æ€§èƒ½ã€‚
- âœ… **å¯åŠ¨æ€æ›´æ–°**ï¼šæ”¯æŒå®æ—¶é›†æˆç”¨æˆ·åé¦ˆï¼ŒæŒç»­æ”¹è¿›ç³»ç»Ÿã€‚
- âœ… **å¼ºæ³›åŒ–èƒ½åŠ›**ï¼šè·¨æ•°æ®é›†è¿ç§»è¡¨ç°è‰¯å¥½ï¼Œå³ä½¿ä½¿ç”¨ BIRD æ„å»ºçš„è®°å¿†åº“ä¹Ÿèƒ½æå‡ Spider ä¸Šçš„è¡¨ç°ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | æè¿° |
|--------|------|
| **BIRD** | ä¸»è¦è¯„æµ‹åŸºå‡†ï¼ŒåŒ…å«å¤§è§„æ¨¡çœŸå®æ•°æ®åº“ï¼Œç”¨äºæ„å»º error-correction memory å’Œä¸»å®éªŒã€‚dev-new æ˜¯ç»è¿‡ä¿®æ­£çš„æ›´å¯é ç‰ˆæœ¬ã€‚ |
| **Spider** | ç»å…¸è·¨åŸŸ NL2SQL æ•°æ®é›†ï¼Œç”¨äºè¯„ä¼°è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ã€‚ |
| **CHESS-SDS** | BIRD dev çš„é«˜è´¨é‡å­é›†ï¼Œå¼ºè°ƒå¤æ‚æŸ¥è¯¢å’Œç²¾ç¡®æ¨¡å¼åŒ¹é…ï¼Œç”¨äºæ•ˆç‡è¯„ä¼°ã€‚ |

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹**ï¼šä¸»è¦ä½¿ç”¨ Qwen-Coder ç³»åˆ—ï¼ˆQwen2.5-Coder-32B, Qwen3-Coder-30B-A3Bï¼‰ï¼Œä¹Ÿæµ‹è¯•äº† DeepSeek-Coder-V2-Lite å’Œ Llama-3.1-8Bã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Execution Accuracy (EX%)**ï¼šç”Ÿæˆçš„ SQL æ‰§è¡Œç»“æœæ˜¯å¦ä¸é»„é‡‘ç­”æ¡ˆä¸€è‡´ã€‚
  - **Token æ•°é‡ / æŸ¥è¯¢**ï¼šè¡¡é‡è®¡ç®—æˆæœ¬ã€‚
  - **å“åº”æ—¶é—´ / æŸ¥è¯¢ï¼ˆç§’ï¼‰**ï¼šç«¯åˆ°ç«¯å»¶è¿Ÿã€‚
- **é‡å¤æ€§**ï¼šæ‰€æœ‰ç»“æœå–ä¸‰æ¬¡ç‹¬ç«‹è¿è¡Œçš„å¹³å‡å€¼ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»åˆ« | æ–¹æ³• |
|------|------|
| **è®­ç»ƒå…è´¹ + å¼€æº** | ROUTE, Alpha-SQL |
| **è®­ç»ƒå…è´¹ + é—­æº** | GPT-4, Gemini |
| **éœ€å¾®è°ƒ + å¼€æº** | SFT CodeS, XiYan-SQL@DDL |
| **å…¶ä»–ä¿®æ­£æ–¹æ³•** | DIN-SQLï¼ˆprompt engineeringï¼‰ã€Solid-SQLï¼ˆä»…ç”¨æ­£ç¡®ç¤ºä¾‹æ£€ç´¢ï¼‰ã€SHAREï¼ˆSFT å¾®è°ƒï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆBIRD dev-new é›†ï¼‰

| æ–¹æ³• | æ¨¡å‹ | EX (%) |
|------|------|-------|
| **Memo-SQL (ours)** | Qwen3-Coder-30B-A3B | **68.5** âœ… |
| Alpha-SQL | Qwen3-Coder-30B-A3B | 67.2 |
| ROUTE | Qwen3-Coder-30B-A3B | 65.2 |
| Distillery | Llama-3.1-405B | 59.2 |

> Memo-SQL åœ¨ **open, zero-fine-tuning** æ–¹æ³•ä¸­é¦–æ¬¡çªç ´ 68%ï¼Œæˆä¸ºæ–°çš„ SOTAã€‚

### ä¸å…¶ä»–æ–¹æ³•çš„å¯¹æ¯”ä¼˜åŠ¿

#### ï¼ˆ1ï¼‰æ•ˆç‡å¯¹æ¯”ï¼ˆCHESS-SDS æ•°æ®é›†ï¼‰
| æ–¹æ³• | æ¨¡å‹ | EX (%) | Tokens/Query | Time/Query (s) |
|------|------|--------|---------------|----------------|
| **Memo-SQL** | Qwen2.5-Coder-32B | 57.6 | **7,925** | **145** |
| Alpha-SQL | Qwen2.5-Coder-32B | 58.5 | 150,344 | 1,839 |
| **Memo-SQL** | Llama-3.1-8B | **52.1** | **16,563** | **135** |
| Alpha-SQL | Llama-3.1-8B | 49.6 | 244,775 | 135 |

- Memo-SQL åœ¨ Qwen ä¸Š **èŠ‚çœ 19 å€ token**ï¼Œé€Ÿåº¦æå‡ **12.7 å€**ï¼›
- åœ¨å°æ¨¡å‹ä¸Šä»ä¼˜äºå¤§æ¨¡å‹åŸºçº¿ï¼Œä¸”æ•ˆç‡è¿œè¶… Alpha-SQLï¼ˆtoken å‡å°‘ 14.8 å€ï¼‰ã€‚

#### ï¼ˆ2ï¼‰è·¨æ•°æ®é›†æ³›åŒ–ï¼ˆSpider devï¼‰
| æ–¹æ³• | EX (%) |
|------|--------|
| **Memo-SQL**ï¼ˆè®°å¿†åº“æ¥è‡ª BIRDï¼‰ | **86.5** |
| w/o SQL Correction | 85.8 |
| Alpha-SQL | 87.8 |
| ROUTE | 80.0 |

> å³ä½¿æœªè§è¿‡ Spider çš„äº¤äº’å†å²ï¼ŒMemo-SQL ä»å–å¾—æ¥è¿‘ SOTA çš„è¡¨ç°ï¼Œè¯æ˜å…¶ error-correction knowledge å…·æœ‰å¼ºè¿ç§»èƒ½åŠ›ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆBIRD dev-newï¼‰

| å˜ä½“ | EX (%) | Î” from Full |
|------|--------|------------|
| **Full Memo-SQL** | **68.5** | â€” |
| w/o Schema Linking | 67.7 | -0.8 |
| w/ Random Decomposition | 67.2 | -1.3 |
| w/o ReAct+Reflect | 67.3 | -1.2 |
| w/o Multi-Style Generation | 67.6 | -0.9 |
| **w/o SQL Refinement** | **66.4** | **-2.1** âœ… |
| + ICL in Final Gen | 67.1 | -1.4 |

> **æœ€å…³é”®çš„ç»„ä»¶æ˜¯ SQL Refinement æ¨¡å—**ï¼Œç§»é™¤åæ€§èƒ½ä¸‹é™æœ€å¤§ï¼ˆ-2.1%ï¼‰ï¼Œè¯´æ˜ error-aware è‡ªæˆ‘ä¿®æ­£æ˜¯æ ¸å¿ƒé©±åŠ¨åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç»“æ„åŒ–åˆ†è§£æ˜¾è‘—æå‡å¤šæ ·æ€§**ï¼šç›¸æ¯”éšæœºåˆ†è§£ï¼Œä¸‰ç§è¯­ä¹‰è½´å‘åˆ†è§£ç­–ç•¥èƒ½äº§ç”Ÿæ›´å¤šæ ·åŒ–çš„æ¨ç†è·¯å¾„ï¼Œå¢å¼ºé›†æˆé²æ£’æ€§ã€‚
2. **ä»é”™è¯¯ä¸­å­¦ä¹ æ¯”åªçœ‹æ­£ç¡®ç¤ºä¾‹æ›´æœ‰æ•ˆ**ï¼šå¼•å…¥ error-correction memory å¹¶ç»“åˆ retrieval-augmented promptingï¼Œä½¿æ¨¡å‹ä¸ä»…èƒ½â€œçŸ¥é“ä»€ä¹ˆæ˜¯å¯¹çš„â€ï¼Œè¿˜èƒ½â€œç†è§£é”™åœ¨å“ªä»¥åŠå¦‚ä½•æ”¹â€ã€‚
3. **æ— éœ€ fine-tuning ä¹Ÿèƒ½å®ç° SOTA**ï¼šMemo-SQL åœ¨å®Œå…¨ä¸æ›´æ–°å‚æ•°çš„å‰æä¸‹ï¼Œåœ¨ open, training-free èŒƒå¼ä¸‹è¾¾åˆ°æœ€é«˜æ‰§è¡Œå‡†ç¡®ç‡ã€‚
4. **é«˜æ•ˆä¸é«˜æ€§èƒ½å¯å…¼å¾—**ï¼šç›¸æ¯”ä¸»æµ TTS æ–¹æ³•ï¼ˆå¦‚ Alpha-SQLï¼‰ï¼ŒMemo-SQL è®¡ç®—å¼€é”€é™ä½ä¸€ä¸ªæ•°é‡çº§ä»¥ä¸Šï¼Œæ›´é€‚åˆå®é™…éƒ¨ç½²ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **é”™è¯¯è®°å¿†åº“ä¾èµ–åˆæˆé”™è¯¯è´¨é‡**ï¼šå½“å‰ memory æ¥æºäºæ¨¡å‹åœ¨ BIRD è®­ç»ƒé›†ä¸Šçš„é”™è¯¯ï¼Œè‹¥ä¸çœŸå®ç”¨æˆ·é”™è¯¯åˆ†å¸ƒä¸ç¬¦ï¼Œå¯èƒ½å½±å“ä¿®æ­£æ•ˆæœã€‚
2. **æ—©æœŸåˆ†è§£é”™è¯¯éš¾ä»¥çº æ­£**ï¼šå¦‚æœåˆå§‹åˆ†è§£å‡ºç°ä¸¥é‡åå·®ï¼ˆå¦‚æ­§ä¹‰é—®é¢˜ï¼‰ï¼Œåç»­è‡ªæˆ‘ä¿®æ­£å¯èƒ½æ— æ³•å®Œå…¨å¼¥è¡¥ã€‚
3. **ä»æœ‰ä¸€å®šå»¶è¿Ÿ**ï¼šå°½ç®¡æ¯” Alpha-SQL å¿«å¾—å¤šï¼Œä½†ç”±äºå¤šè½® LLM è°ƒç”¨å’Œ SQL æ‰§è¡Œï¼Œå¯¹äºäºšç§’çº§å“åº”è¦æ±‚çš„åœºæ™¯ï¼ˆå¦‚äº¤äº’å¼ä»ªè¡¨ç›˜ï¼‰ä»æ˜¾æ²‰é‡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ„å»ºåŸºäºçœŸå®ç”¨æˆ·åé¦ˆçš„åŠ¨æ€ error-correction memoryã€‚
- æ¢ç´¢æ›´è½»é‡çš„ self-correction æœºåˆ¶ï¼Œé€‚åº”ä½å»¶è¿Ÿåœºæ™¯ã€‚
- å°†æ¡†æ¶æ‰©å±•è‡³å…¶ä»–ç¨‹åºç”Ÿæˆä»»åŠ¡ï¼ˆå¦‚ Python ä»£ç ç”Ÿæˆï¼‰ã€‚
- å¼•å…¥ä¸»åŠ¨å­¦ä¹ æœºåˆ¶ï¼Œä¼˜å…ˆé‡‡é›†æœ€å…·ä¿¡æ¯é‡çš„é”™è¯¯æ ·æœ¬ä»¥ä¼˜åŒ– memory è´¨é‡ã€‚

---

> **æ€»ç»“**ï¼šMemo-SQL é€šè¿‡ **structured decomposition** å’Œ **experience-driven self-correction** ä¸¤å¤§è®¾è®¡ï¼Œåœ¨æ— éœ€è®­ç»ƒçš„å‰æä¸‹ï¼Œå®ç°äº†é«˜å‡†ç¡®ç‡ã€é«˜æ•ˆç‡ã€å¼ºæ³›åŒ–æ€§çš„ NL2SQL æ¨ç†æ¡†æ¶ï¼Œä¸ºæ„å»ºå¯æŒç»­è¿›åŒ–çš„å¼€æ”¾ BI ç³»ç»Ÿæä¾›äº†å®ç”¨èŒƒå¼ã€‚

</details>

---

### 6. [LLMdoctor: Token-Level Flow-Guided Preference Optimization for Efficient Test-Time Alignment of Large Language Models](https://arxiv.org/abs/2601.10416)

**Authors**: Tiesunlong Shen, Rui Mao, Jin Wang, Heming Sun, Jian Zhang, Xuejie Zhang, Erik Cambria  
**Category**: cs.AI  
**Published**: 2026-01-16  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.10416v1  

#### Abstract
Aligning Large Language Models (LLMs) with human preferences is critical, yet traditional fine-tuning methods are computationally expensive and inflexible. While test-time alignment offers a promising alternative, existing approaches often rely on distorted trajectory-level signals or inefficient sa...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLLMdoctor: Token-Level Flow-Guided Preference Optimization for Efficient Test-Time Alignment of Large Language Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹é½æ–¹æ³•ï¼ˆå¦‚ RLHFã€DPOï¼‰ä¾èµ–äºæ˜‚è´µçš„å…¨é‡å¾®è°ƒï¼ˆfull fine-tuningï¼‰ï¼Œè®¡ç®—æˆæœ¬é«˜ä¸”ç¼ºä¹çµæ´»æ€§ï¼Œéš¾ä»¥é€‚åº”å¤šæ ·æˆ–åŠ¨æ€å˜åŒ–çš„ç”¨æˆ·åå¥½ã€‚è€Œç°æœ‰çš„ **test-time alignment** æ–¹æ³•è™½ç„¶é¿å…äº†é‡æ–°è®­ç»ƒï¼Œä½†ä»å­˜åœ¨ä»¥ä¸‹æ ¹æœ¬ç¼ºé™·ï¼š
- **è½¨è¿¹çº§å¥–åŠ±ä¿¡å·ï¼ˆtrajectory-level rewardï¼‰** å¯¼è‡´ä¿¡ç”¨åˆ†é…ä¸ç²¾ç¡®ï¼Œæ— æ³•æ•æ‰å•ä¸ª token å¯¹åå¥½çš„è´¡çŒ®ï¼›
- **åºåˆ—æ¨¡ä»¿å¼å¥–åŠ±å»ºæ¨¡ï¼ˆsequence-mimicking rewardï¼‰** å­˜åœ¨â€œå¥–åŠ±é¢„ç®—â€æ‰­æ›²ï¼ˆreward-budget distortionï¼‰ï¼Œå³å¿…é¡»å°†ä¸€ä¸ªå…¨å±€å¥–åŠ±åˆ†æ‘Šåˆ°æ‰€æœ‰ token ä¸Šï¼Œå¯¼è‡´ä¸­æ€§ token è¢«é”™è¯¯èµ‹äºˆé«˜åˆ†ï¼›
- è¿™äº›æ–¹æ³•æœ€ç»ˆä¼šæ”¶æ•›åˆ°å°è§„æ¨¡å¥–åŠ±æ¨¡å‹çš„èƒ½åŠ›ä¸Šé™ï¼Œå½¢æˆ**æ€§èƒ½å¤©èŠ±æ¿æ•ˆåº”ï¼ˆceiling effectï¼‰**ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡º **LLMdoctor**ï¼Œä¸€ç§åŸºäºâ€œæ‚£è€…-åŒ»ç”Ÿâ€èŒƒå¼çš„é«˜æ•ˆ test-time alignment æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰Token-Level Reward Acquisitionï¼ˆç»†ç²’åº¦å¥–åŠ±è·å–ï¼‰
- ä¸ä¾èµ–å¤–éƒ¨å¥–åŠ±æ¨¡å‹ï¼Œè€Œæ˜¯é€šè¿‡å¯¹åŒä¸€å†»ç»“çš„â€œæ‚£è€… LLMâ€æ–½åŠ ä¸åŒè¡Œä¸ºæç¤ºï¼ˆpromptingï¼‰ï¼Œç”Ÿæˆæ­£å‘ï¼ˆhelpfulï¼‰å’Œè´Ÿå‘ï¼ˆlazy/unhelpfulï¼‰çš„è¡Œä¸ºå˜ä½“ï¼›
- é€šè¿‡å¯¹æ¯”è¿™ä¸¤ä¸ªå˜ä½“åœ¨ç›¸åŒä¸Šä¸‹æ–‡ä¸‹çš„ token çº§ log-likelihood å·®å¼‚ï¼Œæå–çœŸæ­£å…·æœ‰åˆ¤åˆ«åŠ›çš„ token çº§å¥–åŠ±ä¿¡å·ï¼›
- å¼•å…¥ç¨€ç–æ€§é˜ˆå€¼ï¼ˆsparsity thresholdï¼‰ï¼Œä»…å¯¹æ˜¾è‘—å½±å“åå¥½çš„ token åˆ†é…éé›¶å¥–åŠ±ï¼Œé¿å…å™ªå£°å¹²æ‰°ã€‚

#### ï¼ˆ2ï¼‰Token-Level Flow-Guided Preference Optimization (TFPO)
- å°† **Generative Flow Networks (GFlowNets)** çš„æµå®ˆæ’åŸç†å¼•å…¥ token åºåˆ—ç”Ÿæˆè¿‡ç¨‹ï¼›
- å®šä¹‰æ¯ä¸ªå‰ç¼€çŠ¶æ€ $ s_t $ çš„â€œæµâ€ä¸ºï¼š  
  $$
  F(s_t) = Q(s_t) \cdot V_d(s_t)
  $$
  å…¶ä¸­ $ Q(s_t) $ æ¥è‡ª token-level å¥–åŠ±ï¼Œ$ V_d(s_t) $ æ˜¯åŒ»ç”Ÿæ¨¡å‹å­¦ä¹ çš„ä»·å€¼å‡½æ•°ï¼›
- é€šè¿‡ **Subtrajectory Balance (SubTB)** ç›®æ ‡å¼ºåˆ¶æ‰€æœ‰å­è·¯å¾„æ»¡è¶³æµé‡å¹³è¡¡ï¼Œå®ç°ä»å±€éƒ¨åˆ°å…¨å±€çš„ä¸€è‡´æ€§ä¼˜åŒ–ï¼›
- è¯¥æœºåˆ¶å°†åå¥½ä¿¡å·ä» $ O(1) $ï¼ˆæ•´ä¸ªåºåˆ—ï¼‰æ‰©å±•åˆ° $ O(n) $ï¼ˆæ‰€æœ‰å­åºåˆ—ï¼‰ï¼Œæä¾›æ›´å¯†é›†ã€ä¸€è‡´çš„ç›‘ç£ä¿¡å·ã€‚

#### ï¼ˆ3ï¼‰çµæ´»é«˜æ•ˆçš„åœ¨çº¿å¯¹é½ï¼ˆOnline Alignmentï¼‰
- åœ¨æ¨ç†æ—¶ï¼Œè®­ç»ƒå¥½çš„â€œåŒ»ç”Ÿæ¨¡å‹â€ä½œä¸º flow-guided reward model åŠ¨æ€æŒ‡å¯¼â€œæ‚£è€…æ¨¡å‹â€çš„è§£ç è¿‡ç¨‹ï¼›
- æ”¯æŒå¤šç»´åº¦åå¥½æ§åˆ¶ï¼ˆå¦‚ helpfulness å’Œ harmlessnessï¼‰ï¼Œé€šè¿‡è°ƒæ•´ä¸åŒç»´åº¦çš„æƒé‡ $ \beta_i $ å®ç°å®æ—¶æƒè¡¡ï¼Œæ— éœ€é‡æ–°è®­ç»ƒã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | LLMdoctor | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ DPOã€GenARMï¼‰ |
|------|-----------|-----------------------------|
| **è®­ç»ƒæˆæœ¬** | ä»…éœ€è®­ç»ƒå°å‹ doctor æ¨¡å‹ | éœ€è¦å…¨é‡å¾®è°ƒå¤§æ¨¡å‹ |
| **çµæ´»æ€§** | æ¨ç†æ—¶å¯åŠ¨æ€è°ƒèŠ‚åå¥½æƒé‡ | å›ºå®šç­–ç•¥ï¼Œéœ€é‡æ–°è®­ç»ƒæ‰èƒ½æ”¹å˜ç›®æ ‡ |
| **ä¿¡ç”¨åˆ†é…ç²¾åº¦** | åŸºäºè¡Œä¸ºå·®å¼‚çš„ token çº§å¥–åŠ±ï¼Œç²¾å‡†å®šä½å…³é”® token | è½¨è¿¹çº§æˆ–å¼ºåˆ¶åˆ†æ‘Šçš„ token çº§å¥–åŠ±ï¼Œæ˜“å—å™ªå£°æ±¡æŸ“ |
| **å¤šæ ·æ€§ä¿æŒ** | TFPO å¤©ç„¶é˜²æ­¢æ¨¡å¼å´©æºƒï¼ˆmode collapseï¼‰ | å¥–åŠ±æœ€å¤§åŒ–å€¾å‘å¯¼è‡´è¾“å‡ºå•ä¸€åŒ– |
| **æ€§èƒ½ä¸Šé™** | ä¸å—é™äºå¥–åŠ±æ¨¡å‹èƒ½åŠ› | æ”¶æ•›è‡³å¥–åŠ±æ¨¡å‹çš„è´ªå©ªç­–ç•¥ï¼Œå­˜åœ¨ç†è®ºå¤©èŠ±æ¿ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **HH-RLHF**ï¼š112K è®­ç»ƒæ ·æœ¬ï¼Œç”¨äºé€šç”¨å¯¹é½è¯„ä¼°ï¼›
- **PKU-SafeRLHF-10K**ï¼šæ˜ç¡®æ ‡æ³¨ helpfulness å’Œ harmlessness çš„åŒç»´åå¥½æ•°æ®ï¼›
- **UltraFeedback**ï¼šå¤§è§„æ¨¡ AI åé¦ˆæ•°æ®ï¼Œç”¨äº weak-to-strong å®éªŒä¸­çš„å¥–åŠ±ä¿¡å·æå–ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
| è®¾ç½®é¡¹ | æè¿° |
|--------|------|
| **åŸºç¡€æ¨¡å‹** | LLaMA-7B-SFTã€Tulu2-7B/13B/70B-SFT |
| **Doctor æ¨¡å‹** | é€šå¸¸ä¸º 7B è§„æ¨¡çš„å°æ¨¡å‹ |
| **è®­ç»ƒæ–¹å¼** | ä½¿ç”¨ LoRA å¾®è°ƒ doctor æ¨¡å‹ |
| **è¯„ä¼°æ–¹å¼** | - **GPT-4o åˆ¤å®˜**ï¼šè¿›è¡Œæˆå¯¹æ¯”è¾ƒï¼ˆhead-to-headï¼‰ï¼ŒæŠ¥å‘Š Win/Tie/Lossï¼›<br>- **AlpacaEval 2**ï¼šè‡ªåŠ¨è¯„ä¼°æ¡†æ¶ï¼Œè®¡ç®—èƒœç‡ï¼ˆwin rateï¼‰ï¼›<br>- **é•¿åº¦æ§åˆ¶èƒœç‡ï¼ˆLength-Controlled Win Rateï¼‰**ï¼šæ¶ˆé™¤é•¿åº¦åå·®çš„å½±å“ã€‚ |
| **å…³é”®æŒ‡æ ‡** | - Win + Â½ Tie (%)<br>- å¤šç›®æ ‡å¸•ç´¯æ‰˜å‰æ²¿ï¼ˆPareto Frontierï¼‰<br>- ç”Ÿæˆå¤šæ ·æ€§ï¼ˆDistinct-4ï¼‰<br>- å¯¹é½ä¿¡å·å¼ºåº¦ï¼ˆValue Gapï¼‰ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»åˆ« | æ–¹æ³• |
|------|------|
| **æ ‡å‡†è§£ç ** | Greedy Search, Top-k, Top-p, Contrastive Search |
| **è®­ç»ƒæ—¶å¯¹é½** | DPO |
| **æµ‹è¯•æ—¶å¯¹é½** | ARGS, GenARM, CARDS, Transfer-Q, Naive RS |
| **å¤šç›®æ ‡å¯¹é½** | Reward Soups (RS), MORL, MOD |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 å’Œ Figure 4ï¼‰

#### ï¼ˆ1ï¼‰ä¸»å®éªŒç»“æœï¼ˆvs. DPOï¼‰
| æ–¹æ³• | Win + Â½ Tie (%) |
|------|------------------|
| **LLMdoctor (Ours)** | **61.00 Â± 0.30** âœ… |
| GenARM | 52.25 Â± 0.32 |
| CARDS | 41.55 Â± 0.23 |
| Transfer-Q | 33.37 Â± 0.22 |
| ARGS | 26.24 Â± 0.17 |

> **ç»“è®º**ï¼šLLMdoctor æ˜¾è‘—ä¼˜äºæ‰€æœ‰ test-time æ–¹æ³•ï¼Œå¹¶**è¶…è¶Šäº†éœ€è¦å…¨é‡å¾®è°ƒçš„ DPO**ã€‚

#### ï¼ˆ2ï¼‰å¼±å¼•å¯¼å¼ºå®éªŒï¼ˆWeak-to-Strong Guidanceï¼‰
| æ‚£è€…æ¨¡å‹è§„æ¨¡ | æ–¹æ³• | é•¿åº¦æ§åˆ¶èƒœç‡ï¼ˆLC Win Rateï¼‰ |
|--------------|------|-------------------------------|
| 70B | **LLMdoctor (7B doctor)** | **82.5%** âœ… |
| 70B | DPO (70B fine-tuned) | 82.0% âŒ |

> **ç»“è®º**ï¼šå³ä½¿ä½¿ç”¨ 7B çš„ doctor æ¨¡å‹ï¼Œä¹Ÿèƒ½æœ‰æ•ˆå¼•å¯¼ 70B çš„æ‚£è€…æ¨¡å‹ï¼Œ**æ€§èƒ½è¶…è¿‡å…¨é‡å¾®è°ƒçš„ DPO**ï¼ŒéªŒè¯äº† weak-to-strong çš„æœ‰æ•ˆæ€§ã€‚

#### ï¼ˆ3ï¼‰å¤šç»´åº¦åå¥½å¹³è¡¡ï¼ˆPareto Frontierï¼‰
- å¦‚å›¾ 3 æ‰€ç¤ºï¼ŒLLMdoctor åœ¨ helpfulness å’Œ harmlessness ä¹‹é—´å®ç°äº†**æœ€ä¼˜çš„æƒè¡¡æ›²çº¿**ï¼Œå…¨é¢ä¸»å¯¼å…¶ä»–æ–¹æ³•ï¼ˆåŒ…æ‹¬ RSã€MORL ç­‰ï¼‰ï¼›
- æ”¯æŒæ¨ç†æ—¶åŠ¨æ€è°ƒæ•´ $ \beta_h $ å’Œ $ \beta_s $ï¼Œæ— éœ€é‡æ–°è®­ç»ƒã€‚

#### ï¼ˆ4ï¼‰æ¶ˆèå®éªŒç»“æœï¼ˆTable 2 & Table 4ï¼‰
| æ¶ˆèå˜ä½“ | Win + Â½ Tie (%) | Diversity |
|----------|------------------|-----------|
| **å®Œæ•´ LLMdoctor** | **61.00** | **0.47** |
| w/o Subtrajectory Balance ($\mathcal{L}_{\text{SubTB}}$) | 53.15 â†“ | 0.34 â†“ |
| w/o Value Discrimination ($\mathcal{L}_{\text{value}}$) | 58.23 â†“ | 0.43 â†“ |
| w/o Reward Sparsity | 56.58 â†“ | 0.46 â†“ |
| w/o Flow-Guided Rewards | 52.76 â†“ | 0.25 â†“ |

> **ç»“è®º**ï¼šTFPO ä¸­çš„ flow consistency æ˜¯æå‡æ€§èƒ½å’Œå¤šæ ·æ€§çš„æ ¸å¿ƒæœºåˆ¶ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Token-level å¥–åŠ± + Flow-guided ä¼˜åŒ–æ˜¯é«˜æ•ˆ test-time alignment çš„å…³é”®è·¯å¾„**ï¼š
   - é€šè¿‡è¡Œä¸ºå˜ä½“æå– token çº§å¥–åŠ±ï¼Œé¿å…äº†å¤–éƒ¨å¥–åŠ±æ¨¡å‹çš„è¯¯å·®ä¼ æ’­ï¼›
   - TFPO æœºåˆ¶å®ç°äº†ä» token åˆ° subtrajectory å†åˆ°å®Œæ•´åºåˆ—çš„åå¥½ä¸€è‡´æ€§ä¼ æ’­ã€‚

2. **LLMdoctor åŒæ—¶æå‡äº†å¯¹é½æ€§èƒ½å’Œç”Ÿæˆå¤šæ ·æ€§**ï¼š
   - ä¼ ç»Ÿæ–¹æ³•å¾€å¾€åœ¨äºŒè€…ä¹‹é—´æƒè¡¡ï¼Œè€Œ LLMdoctor ç”±äºå…¶åˆ†å¸ƒåŒ¹é…ç‰¹æ€§ï¼ˆdistribution matchingï¼‰ï¼Œå¤©ç„¶é˜²æ­¢ mode collapseï¼ˆè§ Appendix C è¯æ˜ï¼‰ï¼›
   - å›¾ 6 æ˜¾ç¤ºå…¶åœ¨æ€§èƒ½-å¤šæ ·æ€§æƒè¡¡ä¸Šå…¨é¢é¢†å…ˆã€‚

3. **ä¿¡å·åŠ¨æ€åˆ†ææ­ç¤ºâ€œå‰ç»æ€§â€ä¼˜åŠ¿**ï¼š
   - å›¾ 5 æ˜¾ç¤ºï¼ŒLLMdoctor åœ¨ç”Ÿæˆæ—©æœŸå°±å…·å¤‡å¼ºçƒˆçš„å¯¹é½ä¿¡å·ï¼ˆhigh value gapï¼‰ï¼Œè¯´æ˜ TFPO æˆåŠŸå°†é•¿æœŸåå¥½ä¿¡æ¯æ³¨å…¥æ¯ä¸€æ­¥å†³ç­–ï¼›
   - è€Œ DPO å’Œ GenARM çš„ä¿¡å·éšæ—¶é—´é€æ­¥å¢å¼ºï¼Œç¼ºä¹â€œè¿œè§â€ã€‚

4. **ç†è®ºå¤©èŠ±æ¿æ•ˆåº”è¢«æ‰“ç ´**ï¼š
   - ä¼ ç»Ÿ reward-guided æ–¹æ³•å—é™äº reward model çš„èƒ½åŠ›ï¼ˆAppendix A è¯æ˜ï¼‰ï¼›
   - LLMdoctor é€šè¿‡ flow-guided æœºåˆ¶ç»•è¿‡æ­¤é™åˆ¶ï¼Œä½¿å¤§æ¨¡å‹èƒ½è¶…è¶Šå° reward model çš„è¡¨ç°ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡çš„è¡Œä¸ºæç¤ºè®¾è®¡**ï¼šPositive/Negative face çš„ prompt è®¾è®¡ç›´æ¥å½±å“ token-level å¥–åŠ±è´¨é‡ï¼›
- **å½“å‰ä»éœ€ç¦»çº¿è®­ç»ƒ doctor æ¨¡å‹**ï¼šè™½æ¯” full fine-tuning å¿«ï¼Œä½†å¹¶éå®Œå…¨å…è®­ç»ƒï¼›
- **å¤š doctor æ¨¡å‹é›†æˆå¯èƒ½å¢åŠ æ¨ç†å¤æ‚åº¦**ï¼šåœ¨å¤šç›®æ ‡åœºæ™¯ä¸‹éœ€ç®¡ç†å¤šä¸ª reward headsã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **å…¨è‡ªåŠ¨ prompt engineering for behavioral variants**ï¼šæ¢ç´¢å¦‚ä½•è‡ªåŠ¨ç”Ÿæˆæœ€ä¼˜çš„æ­£è´Ÿè¡Œä¸ºæç¤ºï¼›
- **Zero-shot doctor initialization**ï¼šå°è¯•æ— éœ€è®­ç»ƒå³å¯åˆå§‹åŒ– doctor æ¨¡å‹ï¼›
- **æ‰©å±•è‡³å¤šæ¨¡æ€å¯¹é½ä»»åŠ¡**ï¼šå°† TFPO æ¡†æ¶åº”ç”¨äºå›¾åƒã€éŸ³é¢‘ç­‰è·¨æ¨¡æ€ç”Ÿæˆï¼›
- **ç»“åˆ speculative decoding è¿›ä¸€æ­¥åŠ é€Ÿæ¨ç†**ï¼šæå‡ test-time alignment çš„æ•ˆç‡è¾¹ç•Œã€‚

--- 

> **æ€»ç»“**ï¼šLLMdoctor æå‡ºäº†ä¸€ç§å…¨æ–°çš„ test-time alignment èŒƒå¼ï¼Œé€šè¿‡ **token-level reward acquisition + flow-guided optimization** å®ç°äº†é«˜æ€§èƒ½ã€é«˜å¤šæ ·æ€§ã€é«˜çµæ´»æ€§çš„å¯¹é½æ•ˆæœï¼Œåœ¨å¤šä¸ªç»´åº¦ä¸Šè¶…è¶Šäº†åŒ…æ‹¬ DPO åœ¨å†…çš„ä¸»æµæ–¹æ³•ï¼Œä¸ºå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„å®æ—¶ä¸ªæ€§åŒ–å¯¹é½æä¾›äº†å®ç”¨ä¸”å¼ºå¤§çš„è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 7. [SPRInG: Continual LLM Personalization via Selective Parametric Adaptation and Retrieval-Interpolated Generation](https://arxiv.org/abs/2601.09974)

**Authors**: Seoyeon Kim, Jaehyung Kim  
**Category**: cs.AI  
**Published**: 2026-01-16  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.09974v1  

#### Abstract
Personalizing Large Language Models typically relies on static retrieval or one-time adaptation, assuming user preferences remain invariant over time. However, real-world interactions are dynamic, where user interests continuously evolve, posing a challenge for models to adapt to preference drift wi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSPRInG: Continual LLM Personalization via Selective Parametric Adaptation and Retrieval-Interpolated Generation

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰çš„ **Large Language Model (LLM)** ä¸ªæ€§åŒ–æ–¹æ³•é€šå¸¸ä¾èµ–é™æ€æ£€ç´¢ï¼ˆstatic retrievalï¼‰æˆ–ä¸€æ¬¡æ€§å‚æ•°é€‚é…ï¼ˆone-time adaptationï¼‰ï¼Œå‡è®¾ç”¨æˆ·åå¥½æ˜¯**æ—¶é—´ä¸å˜çš„**ã€‚ç„¶è€Œåœ¨çœŸå®åœºæ™¯ä¸­ï¼Œç”¨æˆ·çš„å…´è¶£ä¼šéšæ—¶é—´åŠ¨æ€æ¼”åŒ–ï¼ˆpreference driftï¼‰ï¼Œå¯¼è‡´æ¨¡å‹éš¾ä»¥æŒç»­é€‚åº”æ–°åå¥½ï¼ŒåŒæ—¶é¢ä¸´**ç¾éš¾æ€§é—å¿˜**ï¼ˆcatastrophic forgettingï¼‰çš„é£é™©ã€‚

æ ‡å‡†çš„ **Continual Learning (CL)** æ–¹æ³•åœ¨æ­¤ç±»ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œå› ä¸ºå®ƒä»¬å¯¹æ‰€æœ‰äº¤äº’æ•°æ®è¿›è¡Œæ— å·®åˆ«æ›´æ–°ï¼Œæ— æ³•åŒºåˆ†çœŸæ­£çš„åå¥½å˜åŒ–ä¸ä¸´æ—¶å™ªå£°ï¼ˆtransient contextsï¼‰ï¼Œä»è€Œå®¹æ˜“è¿‡æ‹ŸåˆäºçŸ­æœŸè¡Œä¸ºã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šSPRING
ä½œè€…æå‡º **SPRING**ï¼ˆSelective Parametric adaptation and Retrieval-Interpolated Generationï¼‰ï¼Œä¸€ç§æ–°å‹çš„**åŠå‚æ•°åŒ–æ¡†æ¶**ï¼ˆsemi-parametric frameworkï¼‰ï¼Œç”¨äºå®ç°é«˜æ•ˆçš„**æŒç»­æ€§ LLM ä¸ªæ€§åŒ–**ï¼ˆcontinual LLM personalizationï¼‰ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯åœ¨è®­ç»ƒå’Œæ¨ç†ä¸¤ä¸ªé˜¶æ®µè”åˆåˆ©ç”¨å‚æ•°åŒ–ä¸éå‚æ•°åŒ–æ–¹æ³•ï¼Œå„å¸å…¶èŒã€äº’è¡¥ååŒã€‚

#### åˆ›æ–°ç‚¹ï¼š
- **Drift-driven Selective Adaptationï¼ˆæ¼‚ç§»é©±åŠ¨çš„é€‰æ‹©æ€§é€‚é…ï¼‰**
  - åœ¨è®­ç»ƒé˜¶æ®µï¼Œè®¾è®¡äº†ä¸€ä¸ªåŸºäºä¼¼ç„¶åº¦çš„è¯„åˆ†å‡½æ•°ï¼ˆlikelihood-based scoring functionï¼‰ï¼Œè¯†åˆ«å…·æœ‰é«˜æ–°é¢–æ€§çš„äº¤äº’æ ·æœ¬ï¼ˆhigh-novelty interactionsï¼‰ã€‚
  - åªå¯¹è¿™äº›â€œæ¼‚ç§»ä¿¡å·â€æ˜æ˜¾çš„æ ·æœ¬æ›´æ–°ç”¨æˆ·ç‰¹å®šçš„ **LoRA adapter**ï¼Œé¿å…å™ªå£°å¹²æ‰°ã€‚
  - åŒæ—¶å°†éš¾ä»¥è¢«æ¨¡å‹å†…åŒ–çš„æ ·æœ¬ä¿ç•™åœ¨ä¸€ä¸ªæœ‰é™å®¹é‡çš„ **replay buffer** ä¸­ï¼Œä»¥ç¼“è§£é—å¿˜é—®é¢˜ã€‚

- **Selective Retrieval-Interpolated Generationï¼ˆé€‰æ‹©æ€§æ£€ç´¢-æ’å€¼ç”Ÿæˆï¼‰**
  - æ¨ç†é˜¶æ®µå¼•å…¥**ä¸¥æ ¼çš„ç›¸å…³æ€§é—¨æ§æœºåˆ¶**ï¼ˆrelevance gatingï¼‰ï¼Œè¿‡æ»¤æ‰ä¸ç›¸å…³çš„æ£€ç´¢å†å²ã€‚
  - å°†å‚æ•°åŒ–çŸ¥è¯†ï¼ˆæ¥è‡ª adapter çš„è¾“å‡º logitsï¼‰ä¸éå‚æ•°åŒ–çŸ¥è¯†ï¼ˆä» replay buffer æ£€ç´¢å¾—åˆ°çš„å†å²å“åº”ï¼‰é€šè¿‡ **logit interpolation** åŠ¨æ€èåˆï¼Œç”Ÿæˆæœ€ç»ˆå“åº”ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | SPRING | ä¼ ç»Ÿæ–¹æ³• |
|------|--------|----------|
| æ›´æ–°ç­–ç•¥ | é€‰æ‹©æ€§æ›´æ–°ï¼ˆä»…é«˜æ¼‚ç§»æ ·æœ¬ï¼‰ | å…¨é‡æ›´æ–°æˆ–å›ºå®šé€‚é…å™¨ |
| å™ªå£°é²æ£’æ€§ | å¼ºï¼ˆé€šè¿‡è´¨é‡é¡¹å’Œæ–°é¢–æ€§é¡¹åŒé‡ç­›é€‰ï¼‰ | å¼±ï¼ˆæ˜“å—å™ªå£°å½±å“ï¼‰ |
| é—å¿˜æ§åˆ¶ | æ˜¾å¼ä¿ç•™éš¾æ ·æœ¬åˆ° replay buffer | ä¾èµ–æ­£åˆ™åŒ–æˆ–å‡åŒ€å›æ”¾ |
| æ¨ç†çµæ´»æ€§ | å‚æ•°+éå‚æ•°åŒè·¯å¾„èåˆ | å•ä¸€è·¯å¾„ï¼ˆä»… adapter æˆ–ä»… RAGï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
åœ¨ **LongLaMP benchmark**ï¼ˆKumar et al., 2024ï¼‰ ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œè¯¥åŸºå‡†ä¸“æ³¨äºé•¿æ–‡æœ¬ä¸ªæ€§åŒ–ç”Ÿæˆä»»åŠ¡ï¼ŒåŒ…å«ä»¥ä¸‹ä¸¤ç±»ä»»åŠ¡ï¼š
- **Abstract Generation**ï¼ˆæ‘˜è¦ç”Ÿæˆï¼‰
- **Review Writing**ï¼ˆè¯„è®ºå†™ä½œï¼‰

æ¯ä¸ªä»»åŠ¡æŒ‰æ—¶é—´åˆ’åˆ†ä¸ºå¤šä¸ª periodï¼ˆå‘¨æœŸï¼‰ï¼Œæ¨¡æ‹Ÿç”¨æˆ·åå¥½çš„é€æ­¥æ¼”å˜è¿‡ç¨‹ã€‚

### å®éªŒè®¾ç½®
- **ä¸»å¹²æ¨¡å‹**ï¼šGemma-3-4B-IT
- **ä¼˜åŒ–å™¨**ï¼šAdamWï¼Œå­¦ä¹ ç‡ $1 \times 10^{-5}$ï¼Œweight decay = 0.01
- **è°ƒåº¦å™¨**ï¼šçº¿æ€§è¡°å‡ + 10% warmup
- **batch size**ï¼šæ¯è®¾å¤‡ 4
- **adapter ç±»å‹**ï¼šLoRAï¼ˆä½ç§©é€‚é…ï¼‰
- **replay buffer å®¹é‡**ï¼šå›ºå®šé¢„ç®— $N_{\text{max}}$
- **è¯„ä¼°é¢‘ç‡**ï¼šè·¨å¤šä¸ª time periods è¿›è¡ŒæŒç»­è¯„ä¼°

### è¯„ä¼°æŒ‡æ ‡
é‡‡ç”¨è‡ªåŠ¨è¯„ä»·æŒ‡æ ‡ï¼š
- **ROUGE-1**
- **ROUGE-L**

è¡¡é‡ç”Ÿæˆæ–‡æœ¬ä¸å‚è€ƒç­”æ¡ˆä¹‹é—´çš„ n-gram åŒ¹é…ç¨‹åº¦ï¼Œå°¤å…¶å…³æ³¨é•¿æ–‡æœ¬è¯­ä¹‰è¿è´¯æ€§ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
åŒ…æ‹¬ä»¥ä¸‹ä»£è¡¨æ€§æ–¹æ³•ï¼š
- **Standard RAG**ï¼šåŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆçš„ä¼ ç»Ÿéå‚æ•°æ–¹æ³•
- **CAMA**ï¼ˆKim et al., 2024ï¼‰ï¼šå½“å‰æœ€å…ˆè¿›çš„ Continual Learning æ–¹æ³•
- **Static Personalization**ï¼šåŸºäºåˆå§‹å†å²çš„ä¸€æ¬¡æ€§é€‚é…ï¼Œä¸å†æ›´æ–°
- **Full Fine-tuning / LoRA æ›´æ–°å…¨éƒ¨æ•°æ®**

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ªåŸæ–‡ Table å’Œæ­£æ–‡æè¿°ï¼‰

| æ–¹æ³• | Abstract Gen (ROUGE-L) | Review Writing (ROUGE-L) |
|------|-------------------------|----------------------------|
| **SPRING (Ours)** | **æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿** | **+18.12% vs RAG**, **+15.85% vs CAMA** |

å…·ä½“æå‡å¹…åº¦ï¼š
- åœ¨ **Review Writing** ä»»åŠ¡ä¸­ï¼Œç›¸æ¯”æœ€å¼ºçš„ CL æ–¹æ³• **CAMA**ï¼ŒSPRING åœ¨ ROUGE-L ä¸Šæå‡äº† **15.85%**ï¼›
- ç›¸æ¯”æ ‡å‡† **RAG** æ–¹æ³•ï¼Œæå‡è¾¾ **18.12%**ï¼›
- åœ¨ **Abstract Generation** ä»»åŠ¡ä¸­ä¹Ÿè¡¨ç°å‡ºä¸€è‡´ä¸”ç¨³å®šçš„é¢†å…ˆä¼˜åŠ¿ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ï¼ˆ1ï¼‰æ¼‚ç§»é©±åŠ¨è®­ç»ƒçš„æœ‰æ•ˆæ€§
- ç§»é™¤ drift-driven selection åï¼Œæ€§èƒ½ä¸‹é™ **12.35%**ï¼ˆä»¥ ROUGE-L è¡¡é‡ï¼‰ï¼ŒéªŒè¯äº†é€‰æ‹©æ€§æ›´æ–°çš„é‡è¦æ€§ã€‚

#### ï¼ˆ2ï¼‰Logit æ’å€¼æœºåˆ¶çš„ä½œç”¨
- å•ç‹¬ä½¿ç”¨å‚æ•°åŒ–è·¯å¾„ï¼ˆadapter onlyï¼‰æˆ–éå‚æ•°è·¯å¾„ï¼ˆRAG onlyï¼‰æ•ˆæœè¾ƒå·®ï¼›
- ä½¿ç”¨ logit interpolation èåˆä¸¤è€…åï¼Œæœ€å¤§æå‡å¯è¾¾ **22.58%**ï¼Œè¯æ˜åŒè·¯å¾„ååŒçš„æœ‰æ•ˆæ€§ã€‚

#### ï¼ˆ3ï¼‰Replay Buffer ä¿ç•™ç­–ç•¥æ¯”è¾ƒï¼ˆTable 4ï¼‰
| ç­–ç•¥ | Abstract Gen (ROUGE-1) | Review Writing (ROUGE-1) |
|------|------------------------|---------------------------|
| **Global Highest (Ours)** | **0.350** | **0.332** |
| Cluster Round | 0.346 | 0.331 |
| Cluster-wise | 0.345 | 0.332 |
| Random | 0.345 | 0.331 |

ç»“æœè¡¨æ˜ï¼Œâ€œå…¨å±€æœ€é«˜å¾—åˆ†ä¿ç•™â€ç­–ç•¥æœ€ä¼˜ï¼Œè¯´æ˜ä¼˜å…ˆä¿å­˜é«˜æ¼‚ç§»åˆ†æ ·æœ¬æœ€æœ‰æ•ˆã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **åå¥½æ¼‚ç§» â‰  æ‰€æœ‰æ–°æ•°æ®**ï¼šå¹¶éæ‰€æœ‰æ–°çš„ç”¨æˆ·äº¤äº’éƒ½å€¼å¾—å­¦ä¹ ï¼Œå¿…é¡»é€šè¿‡**æ–°é¢–æ€§+è¯­è¨€è´¨é‡**åŒé‡åˆ¤æ®ç­›é€‰çœŸæ­£æœ‰æ„ä¹‰çš„æ¼‚ç§»ä¿¡å·ã€‚
2. **å‚æ•°åŒ–ä¸éå‚æ•°åŒ–åº”åˆ†å·¥åä½œ**ï¼š
   - å‚æ•°è·¯å¾„ï¼ˆadapterï¼‰é€‚åˆå­¦ä¹ ç¨³å®šã€å¯æ³›åŒ–çš„åå¥½æ¨¡å¼ï¼›
   - éå‚æ•°è·¯å¾„ï¼ˆretrieval + replay bufferï¼‰æ›´é€‚åˆä¿ç•™å¤æ‚ã€ç¨€ç–ä½†å…³é”®çš„å†å²ç»†èŠ‚ã€‚
3. **logit-level fusion æ›´çµæ´»å¯æ§**ï¼šç›¸æ¯”äºæ‹¼æ¥ä¸Šä¸‹æ–‡çš„ RAGï¼Œlogit interpolation èƒ½æ›´ç²¾ç»†åœ°å¹³è¡¡å†…éƒ¨çŸ¥è¯†ä¸å¤–éƒ¨è¯æ®ã€‚
4. **replay buffer è®¾è®¡è‡³å…³é‡è¦**ï¼šåˆç†çš„ä¿ç•™ç­–ç•¥ï¼ˆå¦‚ global highestï¼‰èƒ½æ˜¾è‘—æå‡é•¿æœŸè®°å¿†æ•ˆç‡ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **æ¨ç†å»¶è¿Ÿå¢åŠ **ï¼š
   - æ¯ä¸ªè§£ç æ­¥éœ€æ‰§è¡Œä¸¤æ¬¡å‰å‘ä¼ æ’­ï¼ˆvanilla + RAGï¼‰ï¼Œå¸¦æ¥é¢å¤–è®¡ç®—å¼€é”€ã€‚
2. **æ¼‚ç§»æ£€æµ‹å¯èƒ½è¯¯åˆ¤**ï¼š
   - çªå‘è¯é¢˜åˆ‡æ¢ï¼ˆfalse driftï¼‰å¯èƒ½å¯¼è‡´é”™è¯¯æ›´æ–°ï¼Œå°½ç®¡é€šè¿‡é™åˆ¶æ›´æ–°æ¯”ä¾‹ï¼ˆä»… top p%ï¼‰æœ‰æ‰€ç¼“è§£ã€‚
3. **å¤§è§„æ¨¡ç”¨æˆ·éƒ¨ç½²æŒ‘æˆ˜**ï¼š
   - æ¯ä¸ªç”¨æˆ·ç»´æŠ¤ç‹¬ç«‹ adapter å’Œ bufferï¼Œå­˜å‚¨ä¸æœåŠ¡æˆæœ¬éšç”¨æˆ·æ•°å¢é•¿è€Œä¸Šå‡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **ä¼˜åŒ–æ¨ç†æ•ˆç‡**ï¼š
   - æ¢ç´¢è‡ªé€‚åº”æ’å€¼ç­–ç•¥ï¼Œä¾‹å¦‚å½“ä¸¤è·¯åˆ†å¸ƒå·®å¼‚è¾ƒå°æ—¶æå‰ç»ˆæ­¢ dual-path è§£ç ã€‚
2. **æ”¹è¿›æ£€ç´¢ä¸é—¨æ§æœºåˆ¶**ï¼š
   - å¼•å…¥ **dense retrieval** æˆ– **cross-encoder re-ranking** æå‡ç›¸å…³æ€§åˆ¤æ–­ç²¾åº¦ã€‚
3. **æ‰©å±•ç”¨æˆ·å…±äº«æ¶æ„**ï¼š
   - æ„å»º**å±‚æ¬¡åŒ–æˆ–å…±äº« adapter ç»“æ„**ï¼Œå¯¹ç›¸ä¼¼ç”¨æˆ·ç¾¤ä½“è¿›è¡Œèšç±»ï¼Œé™ä½å­˜å‚¨è´Ÿæ‹…å¹¶æ”¯æŒè·¨ç”¨æˆ·çŸ¥è¯†è¿ç§»ï¼ˆcross-user knowledge transferï¼‰ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> SPRING é€šè¿‡**é€‰æ‹©æ€§å‚æ•°æ›´æ–° + æ£€ç´¢-æ’å€¼ç”Ÿæˆ**ï¼Œå®ç°äº†å¯¹ç”¨æˆ·åå¥½æ¼”åŒ–çš„é«˜æ•ˆã€ç¨³å¥å»ºæ¨¡ï¼Œåœ¨ LongLaMP åŸºå‡†ä¸Šæ˜¾è‘—è¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œä¸ºç°å®ä¸–ç•Œä¸­çš„æŒç»­æ€§ LLM ä¸ªæ€§åŒ–æä¾›äº†å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 8. [NSR-Boost: A Neuro-Symbolic Residual Boosting Framework for Industrial Legacy Models](https://arxiv.org/abs/2601.10457)

**Authors**: Ziming Dai, Dabiao Ma, Jinle Tong, Mengyuan Han, Jian Yang, Haojun Fei  
**Category**: cs.AI  
**Published**: 2026-01-16  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.10457v1  

#### Abstract
Although the Gradient Boosted Decision Trees (GBDTs) dominate industrial tabular applications, upgrading legacy models in high-concurrency production environments still faces prohibitive retraining costs and systemic risks. To address this problem, we present NSR-Boost, a neuro-symbolic residual boo...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šNSR-Boost: A Neuro-Symbolic Residual Boosting Framework for Industrial Legacy Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨å·¥ä¸šçº§é«˜å¹¶å‘ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå°½ç®¡ **Gradient Boosted Decision Trees (GBDTs)** å¦‚ XGBoost å’Œ LightGBM åœ¨è¡¨æ ¼æ•°æ®å»ºæ¨¡ä¸­å æ®ä¸»å¯¼åœ°ä½ï¼Œä½†å¯¹å·²æœ‰éƒ¨ç½²çš„â€œé—ç•™æ¨¡å‹â€ï¼ˆlegacy modelï¼‰è¿›è¡Œå‡çº§é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼š
- **é«˜æ˜‚çš„é‡è®­ç»ƒæˆæœ¬**ï¼šå®Œå…¨æ›¿æ¢æ¨¡å‹æ¶æ„æˆ–å¼•å…¥å¤§è§„æ¨¡æ–°ç‰¹å¾éœ€é‡æ„æ•´ä¸ªå·¥ç¨‹æµæ°´çº¿ã€‚
- **ç³»ç»Ÿé£é™©**ï¼šä¼ä¸šä¼˜å…ˆè€ƒè™‘ç¨³å®šæ€§ï¼Œéš¾ä»¥æ¥å—å› æ¨¡å‹å˜æ›´å¸¦æ¥çš„æ½œåœ¨æ•…éšœã€‚

ç°æœ‰æ”¹è¿›æ–¹æ³•ï¼ˆå¦‚ TabNetã€OpenFEï¼‰é€šå¸¸è¦æ±‚ä¿®æ”¹è¾“å…¥ç‰¹å¾ç©ºé—´æˆ–æ›¿æ¢ä¸»å¹²æ¨¡å‹ï¼Œå¯¼è‡´éƒ¨ç½²é£é™©é«˜ã€ç»´æŠ¤æˆæœ¬å¤§ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡º **NSR-Boost**ï¼ˆNeuro-Symbolic Residual Boostingï¼‰ï¼Œä¸€ç§ä¸“ä¸ºå·¥ä¸šåœºæ™¯è®¾è®¡çš„**éä¾µå…¥å¼ç¥ç»ç¬¦å·æ®‹å·®å¢å¼ºæ¡†æ¶**ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å°†å·²æœ‰çš„ GBDT æ¨¡å‹è§†ä¸ºâ€œå†»ç»“æ¨¡å‹â€ï¼ˆfrozen modelï¼‰ï¼Œä¸ä¿®æ”¹å…¶å‚æ•°æˆ–ç»“æ„ã€‚
- ä»…é’ˆå¯¹æ¨¡å‹é¢„æµ‹å¤±è´¥çš„â€œå›°éš¾åŒºåŸŸâ€ï¼ˆhard regionsï¼‰ç”Ÿæˆå¯è§£é‡Šçš„ç¬¦å·ä¸“å®¶å‡½æ•°ï¼ˆSymbolic Expertsï¼‰è¿›è¡Œå±€éƒ¨ä¿®å¤ã€‚
- åˆ©ç”¨ **Large Language Model (LLM)** ä½œä¸º**ç¬¦å·ä»£ç ç”Ÿæˆå™¨**ï¼Œè€Œéé»‘ç›’é¢„æµ‹å™¨ï¼Œè¾“å‡ºå¯æ‰§è¡Œçš„ Python ä»£ç ã€‚

è¯¥æ¡†æ¶åŒ…å«ä¸‰ä¸ªé˜¶æ®µï¼š
1. **æ®‹å·®å¼•å¯¼çš„å›°éš¾åŒºåŸŸè¯†åˆ«**ï¼šé€šè¿‡ CART å†³ç­–æ ‘åˆ†ææ®‹å·®åˆ†å¸ƒï¼Œå®šä½éœ€è¦ä¼˜åŒ–çš„å­ç©ºé—´ã€‚
2. **åŒå±‚ä¼˜åŒ–çš„ä¸“å®¶ç”Ÿæˆ**ï¼š
   - å¤–å¾ªç¯ï¼šLLM åŸºäºä¸Šä¸‹æ–‡æç¤ºé€æ­¥æ¼”åŒ–ç¬¦å·ç»“æ„ï¼›
   - å†…å¾ªç¯ï¼šé‡‡ç”¨ **Bayesian Optimization** å¯¹ç”Ÿæˆå‡½æ•°çš„å‚æ•°è¿›è¡Œæ¢¯åº¦æ— å…³çš„ç²¾ç»†è°ƒä¼˜ã€‚
3. **ä¸Šä¸‹æ–‡æ„ŸçŸ¥èšåˆæœºåˆ¶**ï¼šè½»é‡çº§ XGBoost èšåˆå™¨åŠ¨æ€èåˆåŸå§‹æ¨¡å‹è¾“å‡ºä¸å¤šä¸ªç¬¦å·ä¸“å®¶ï¼Œå®ç°å®‰å…¨æå‡ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | NSR-Boost | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ OpenFE, TabNetï¼‰ |
|------|-----------|-----------------------------|
| **éä¾µå…¥æ€§** | âœ… ä¸æ”¹å˜åŸæ¨¡å‹ç»“æ„ä¸è¾“å…¥ç‰¹å¾ | âŒ éœ€é‡æ–°è®­ç»ƒæ¨¡å‹æˆ–ä¿®æ”¹ç‰¹å¾å·¥ç¨‹ |
| **æ¨ç†å»¶è¿Ÿ** | âœ… <1msï¼Œé€‚åˆé«˜å¹¶å‘çº¿ä¸ŠæœåŠ¡ | âŒ æ·±åº¦æ¨¡å‹ï¼ˆå¦‚ FT-Transformerï¼‰å»¶è¿Ÿè¾¾ 10â€“100ms |
| **å¯è§£é‡Šæ€§** | âœ… è¾“å‡ºæ˜¾å¼çš„ Python ç¬¦å·è¡¨è¾¾å¼ | âŒ é»‘ç®±æ¨¡å‹æˆ–éšå¼ç‰¹å¾ç»„åˆ |
| **éƒ¨ç½²å®‰å…¨æ€§** | âœ… å±€éƒ¨ä¿®å¤ï¼Œé¿å…å…¨å±€è¿‡æ‹Ÿåˆ | âŒ å…¨å±€æ›¿æ¢å¸¦æ¥ç³»ç»Ÿä¸ç¨³å®šé£é™© |
| **é€»è¾‘å»ºæ¨¡èƒ½åŠ›** | âœ… æ”¯æŒéçº¿æ€§ã€éå•è°ƒå…³ç³»ï¼ˆå¦‚é«˜æ–¯å‡½æ•°ï¼‰ | âŒ å¤šæ•°åŸºäºçº¿æ€§æˆ–ç®€å•äº¤äº’ |

æ­¤å¤–ï¼ŒNSR-Boost æ˜¯é¦–ä¸ªå°† LLM ç”¨äº**ç”Ÿæˆå¯éƒ¨ç½²ã€æ— éœ€åœ¨çº¿æ¨ç†çš„ç¬¦å·ä»£ç **æ¥å¢å¼ºå·¥ä¸šé—ç•™ç³»ç»Ÿçš„æ¡†æ¶ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒæ¶µç›–ä¸¤ç±»æ•°æ®ï¼š
- **6ä¸ªå…¬å¼€åŸºå‡†æ•°æ®é›†**ï¼ˆæ¥è‡ª OpenMLï¼‰ï¼š
  - `adult`, `bank-marketing`, `blood-transfusion`, `breast-w`, `credit-g`, `pc1`
  - è¦†ç›–é‡‘èã€åŒ»ç–—ç­‰é«˜é£é™©é¢†åŸŸï¼Œæ ·æœ¬é‡ä» 699 åˆ° 48,842 ä¸ç­‰ã€‚
- **1ä¸ªç§æœ‰çœŸå®ä¸šåŠ¡æ•°æ®é›†**ï¼ˆQfin Holdings æä¾›ï¼‰ï¼š
  - åä¸º `private-data`ï¼Œç”¨äºé‡‘èé£æ§ï¼›
  - ç‰¹å¾ç»´åº¦é«˜è¾¾ 200ï¼Œæ ·æœ¬é‡çº¦ 49.7ä¸‡ï¼Œå™ªå£°ä¸¥é‡ä¸”ç±»åˆ«ä¸å¹³è¡¡ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- æ•°æ®åˆ’åˆ†ï¼šç»Ÿä¸€é‡‡ç”¨ 80% è®­ç»ƒ / 20% æµ‹è¯•ï¼Œäº”æ¬¡éšæœºç§å­å¹³å‡ç»“æœã€‚
- è¯„ä¼°æŒ‡æ ‡ï¼š
  - å…¬å…±æ•°æ®é›†ï¼šAccuracy
  - ç§æœ‰æ•°æ®é›†ï¼šAUCï¼ˆå› ä¸¥é‡ç±»åˆ«ä¸å¹³è¡¡ï¼‰
- LLM åŸºåº§æ¨¡å‹ï¼š**Seed-OSS-36B-Instruct**
- ä¸“å®¶æ•°é‡ $ K = 4 $
- æ‰€æœ‰ LLM-based åŸºçº¿å‡é™åˆ¶æœ€å¤šè°ƒç”¨ 20 æ¬¡ APIï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | æ–¹æ³• |
|------|------|
| æ·±åº¦å­¦ä¹ æ¨¡å‹ | TabNet, FT-Transformer |
| è‡ªåŠ¨åŒ–ç‰¹å¾å·¥ç¨‹ | AutoFeat, OpenFE |
| LLM-based ç‰¹å¾å·¥ç¨‹ | CAAFE, FeatLLM, OCTree, LLM-FE |
| æ®‹å·®å­¦ä¹ åŸºçº¿ | Res-XGBoostï¼ˆç”¨æµ…å±‚ GBDT æ‹Ÿåˆæ®‹å·®ï¼‰ |

æ‰€æœ‰ç‰¹å¾å·¥ç¨‹æ–¹æ³•å‡ä»¥ XGBoost ä¸ºä¸‹æ¸¸åˆ†ç±»å™¨ï¼Œå¹¶è¿›è¡Œ 30 æ¬¡è´å¶æ–¯è¶…å‚æœç´¢ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰
| Dataset | Base(XGB) | NSR-Boost (Ours) | æœ€ä½³åŸºçº¿ |
|--------|------------|------------------|----------|
| adult | 0.873 | **0.875** | 0.874 (LLM-FE) |
| bank-marketing | 0.906 | **0.910** | 0.908 (FT-T.) |
| blood-transfusion | 0.742 | **0.820** | 0.805 (LLM-FE) |
| breast-w | 0.956 | **0.986** | 0.970 (LLM-FE) |
| credit-g | 0.751 | **0.815** | 0.784 (LLM-FE) |
| pc1 | 0.931 | **0.946** | 0.935 (LLM-FE) |
| private-data* | 0.688 | **0.694** | 0.666 (AutoFeat) |

- **å¹³å‡æ’åç¬¬ä¸€ï¼ˆMean Rank = 1.0ï¼‰**ï¼Œæ˜¾è‘—ä¼˜äºæ‰€æœ‰ SOTA æ–¹æ³•ã€‚
- åœ¨å°æ ·æœ¬æ•°æ®ï¼ˆå¦‚ `credit-g`, `blood-transfusion`ï¼‰ä¸Šæå‡å°¤ä¸ºæ˜æ˜¾ï¼ˆ+6.4% ~ +7.8%ï¼‰ã€‚
- åœ¨ç§æœ‰æ•°æ®é›†ä¸Šï¼Œ**å”¯ä¸€æœªå‡ºç°æ€§èƒ½é€€åŒ–çš„æ–¹æ³•**ï¼›è€Œ Res-XGBoost å› è¿‡æ‹Ÿåˆå™ªå£°å¯¼è‡´ AUC ä» 0.688 é™è‡³ 0.659ã€‚

---

### ä¸ä¸åŒä¸»å¹²æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼ˆFigure 2ï¼‰
NSR-Boost å¯æ— ç¼é€‚é…å¤šç§ GBDT ä¸»å¹²ï¼š
- åœ¨ `credit-g` ä¸Šï¼š
  - XGBoost â†’ +6.4%
  - LightGBM â†’ +4.3%
  - CatBoost â†’ +2.5%
- è¡¨æ˜å…¶æŒ–æ˜çš„æ˜¯æ•°æ®æœ¬èº«çš„é•¿å°¾æ¨¡å¼ï¼Œè€Œéç‰¹å®šæ¨¡å‹åå·®ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆFigure 4ï¼Œä»¥ credit-g ä¸ºä¾‹ï¼‰
| æ¶ˆèé…ç½® | å‡†ç¡®ç‡ |
|---------|--------|
| å®Œæ•´ NSR-Boost | **0.815** |
| w/o Bayesian Optimization | 0.766 (-4.9%) |
| w/o Context-Aware Aggregation | 0.773 |
| w/o Region Identification | 0.773 |
| w/o Statistical Prompting | 0.778 |
| w/o Feature Semantics | 0.778 |
| w/o Raw Feature Input | 0.783 |
| w/o Boundary Refinement | 0.793 |

**å…³é”®å‘ç°**ï¼š
- **Bayesian Optimization è‡³å…³é‡è¦**ï¼šLLM æ“…é•¿ç»“æ„ç”Ÿæˆï¼Œä½†æ— æ³•ç²¾ç¡®ç¡®å®šè¿ç»­å‚æ•°ã€‚
- **ä¸Šä¸‹æ–‡æ„ŸçŸ¥èšåˆä¸åŒºåŸŸè¯†åˆ«ç¼ºä¸€ä¸å¯**ï¼šå¦åˆ™æ˜“å¼•å‘å…¨ç©ºé—´å¼ºåˆ¶æ‹Ÿåˆå™ªå£°ã€‚
- å³ä½¿æœ€å¼±å˜ä½“ä»ä¼˜äºåŸå§‹ XGBoostï¼Œè¯æ˜æ¡†æ¶å…·æœ‰å†…åœ¨é²æ£’æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **NSR-Boost å®ç°äº†â€œå®‰å…¨è¿›åŒ–â€èŒƒå¼**ï¼š
   - åœ¨ä¸å¹²æ‰°ç°æœ‰ç³»ç»Ÿçš„æƒ…å†µä¸‹ï¼Œæœ‰æ•ˆæ•æ‰ä¼ ç»Ÿæ¨¡å‹å¿½ç•¥çš„**é•¿å°¾é£é™©**ã€‚
   - ç‰¹åˆ«é€‚ç”¨äºé‡‘èé£æ§ã€ä¿¡è´·è¯„åˆ†ç­‰é«˜ç¨³å®šæ€§è¦æ±‚åœºæ™¯ã€‚

2. **LLM åº”ä½œä¸ºâ€œç¨‹åºå‘˜â€è€Œéâ€œé¢„æµ‹å™¨â€ä½¿ç”¨**ï¼š
   - ç”Ÿæˆå¯æ‰§è¡Œä»£ç åå³å¯ä¸‹çº¿ LLMï¼Œæ¶ˆé™¤åœ¨çº¿æ¨ç†å¼€é”€ä¸ä¸ç¡®å®šæ€§ã€‚
   - ç»“åˆåé¦ˆæœºåˆ¶ï¼ˆNegative/Positive Constraintsï¼‰å¯æ˜¾è‘—å‡å°‘â€œå¹»è§‰â€ã€‚

3. **ç¬¦å·å›å½’ + æ•°å€¼ä¼˜åŒ–çš„è§£è€¦ç­–ç•¥æ›´é«˜æ•ˆ**ï¼š
   - å¤–å¾ªç¯ï¼ˆLLMï¼‰è´Ÿè´£é€»è¾‘æ„é€ ï¼Œå†…å¾ªç¯ï¼ˆBayesian Opt.ï¼‰è´Ÿè´£å‚æ•°ç²¾è°ƒã€‚
   - æˆåŠŸå…‹æœäº†ç¬¦å·å›å½’ä¸­ç»“æ„ä¸å‚æ•°è”åˆæœç´¢çš„ç»„åˆçˆ†ç‚¸éš¾é¢˜ã€‚

4. **å·¥ä¸šéƒ¨ç½²å¯è¡Œæ€§é«˜**ï¼š
   - æ¨ç†å»¶è¿Ÿ <1msï¼Œæ»¡è¶³æ¯«ç§’çº§å“åº”éœ€æ±‚ï¼ˆFigure 7ï¼‰ã€‚
   - åœ¨çº¿éƒ¨ç½²æµ‹è¯•ä¸­ï¼ŒAUC æå‡ 0.37%~1.17%ï¼Œåè´¦ç‡é™ä½ 0.15%~0.18%ï¼Œå¸¦æ¥å¯è§‚å•†ä¸šä»·å€¼ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡æ®‹å·®ä¿¡å·**ï¼šè‹¥åŸºç¡€æ¨¡å‹è¿‡äºå¼ºå¤§æˆ–æ®‹å·®æ— è§„å¾‹ï¼Œåˆ™éš¾æ‰¾åˆ°æœ‰æ•ˆâ€œå›°éš¾åŒºåŸŸâ€ã€‚
- **LLM è¯­ä¹‰ç†è§£ç“¶é¢ˆ**ï¼šè™½ç„¶è¯­æ³•æ­£ç¡®ç‡é«˜ï¼Œä½†â€œåˆå§‹ AUC å¤±è´¥â€å æ¯”è¶…è¿‡ 50%ï¼ˆFigure 11ï¼‰ï¼Œè¯´æ˜ LLM ç¼ºä¹çœŸæ­£çš„å› æœæ¨ç†èƒ½åŠ›ã€‚
- **å¹¶è¡Œé“¾æ•°å—é™äºè®¡ç®—èµ„æº**ï¼šæ¯ä¸ªä¸“å®¶é“¾éœ€ç‹¬ç«‹è¿è¡Œ Bayesian ä¼˜åŒ–ï¼Œå¢åŠ ç¡¬ä»¶è´Ÿæ‹…ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- å¼•å…¥ **meta-learning æˆ–å¼ºåŒ–å­¦ä¹ ** æ¥æŒ‡å¯¼ LLM æ›´é«˜æ•ˆåœ°æ¢ç´¢ç¬¦å·ç©ºé—´ã€‚
- æ„å»º **domain-specific concept library**ï¼ˆç±»ä¼¼ Grayeli et al. [6]ï¼‰ï¼Œæå‡ LLM åœ¨é‡‘èã€åŒ»ç–—ç­‰é¢†åŸŸçš„å…ˆéªŒçŸ¥è¯†ã€‚
- æ¢ç´¢ **multi-task symbolic experts**ï¼Œæ”¯æŒåŒæ—¶ä¿®å¤å¤šä¸ªä»»åŠ¡çš„æ®‹å·®ã€‚
- è¿›ä¸€æ­¥å‹ç¼©èšåˆå™¨å¤æ‚åº¦ï¼Œå®ç°å®Œå…¨æ— ç›‘ç£çš„åŠ¨æ€é—¨æ§æœºåˆ¶ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> NSR-Boost æå‡ºäº†ä¸€ç§**éä¾µå…¥ã€å¯è§£é‡Šã€ä½å»¶è¿Ÿ**çš„å·¥ä¸šæ¨¡å‹å¢å¼ºè·¯å¾„ï¼Œé€šè¿‡ LLM ç”Ÿæˆç¬¦å·ä¸“å®¶ + Bayesian å‚æ•°ä¼˜åŒ–ï¼Œåœ¨ä¿æŒç³»ç»Ÿç¨³å®šçš„åŒæ—¶å®ç°äº† SOTA æ€§èƒ½ï¼Œä¸ºå¤§è§„æ¨¡é—ç•™ç³»ç»Ÿçš„æŒç»­æ¼”è¿›æä¾›äº†å®ç”¨è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 9. [History Is Not Enough: An Adaptive Dataflow System for Financial Time-Series Synthesis](https://arxiv.org/abs/2601.10143)

**Authors**: Haochong Xia, Yao Long Teng, Regan Tan, Molei Qin, Xinrun Wang, Bo An  
**Category**: cs.AI  
**Published**: 2026-01-16  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.10143v1  

#### Abstract
In quantitative finance, the gap between training and real-world performance-driven by concept drift and distributional non-stationarity-remains a critical obstacle for building reliable data-driven systems. Models trained on static historical data often overfit, resulting in poor generalization in ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šHistory Is Not Enough: An Adaptive Dataflow System for Financial Time-Series Synthesis**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
é‡‘èæ—¶é—´åºåˆ—æ•°æ®å…·æœ‰å¼ºçƒˆçš„**æ¦‚å¿µæ¼‚ç§»ï¼ˆconcept driftï¼‰** å’Œ**åˆ†å¸ƒéå¹³ç¨³æ€§ï¼ˆdistributional non-stationarityï¼‰**ï¼Œå¯¼è‡´åŸºäºå†å²æ•°æ®è®­ç»ƒçš„æœºå™¨å­¦ä¹ æ¨¡å‹å®¹æ˜“è¿‡æ‹Ÿåˆï¼Œåœ¨çœŸå®å¸‚åœºç¯å¢ƒä¸­æ³›åŒ–èƒ½åŠ›å·®ã€‚ä¼ ç»Ÿé™æ€æ•°æ®å¢å¼ºæ–¹æ³•æ— æ³•åŠ¨æ€é€‚åº”å¸‚åœºå˜åŒ–ï¼Œç¼ºä¹åé¦ˆæœºåˆ¶æ¥æŒ‡å¯¼æ•°æ®ç”Ÿæˆã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯**
æœ¬æ–‡æå‡ºäº†ä¸€ç§**æ¼‚ç§»æ„ŸçŸ¥çš„è‡ªé€‚åº”æ•°æ®æµç³»ç»Ÿï¼ˆdrift-aware adaptive dataflow systemï¼‰**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯â€œ**History Is Not Enough**â€â€”â€”ä»…ä¾èµ–å†å²æ•°æ®ä¸è¶³ä»¥åº”å¯¹åŠ¨æ€å¸‚åœºï¼Œå¿…é¡»å¼•å…¥**å­¦ä¹ å¼•å¯¼çš„æ•°æ®åˆæˆä¸è°ƒåº¦æœºåˆ¶**ã€‚

è¯¥ç³»ç»ŸåŒ…å«ä¸¤å¤§æ ¸å¿ƒç»„ä»¶ï¼š
- **å‚æ•°åŒ–æ•°æ®æ“ä½œæ¨¡å— Mï¼ˆParameterized Data Manipulation Moduleï¼‰**  
  é›†æˆå¤šç§é‡‘èé¢†åŸŸç‰¹å®šçš„å¢å¼ºæ“ä½œï¼ŒåŒ…æ‹¬ï¼š
  - å•è‚¡å˜æ¢ï¼ˆå¦‚ Jitteringã€Scalingã€Magnitude Warpingã€Permutationã€STL Augmentationï¼‰
  - å¤šè‚¡æ··åˆï¼ˆå¦‚ Cut Mixã€Linear Mixã€Amplitude Mixï¼‰
  - æ•°æ®æ ¡å‡†ä¸æ’å€¼è¡¥å¿ï¼ˆå¦‚ Binary Mixï¼‰
  æ‰€æœ‰æ“ä½œå‡å—é‡‘èå…ˆéªŒçº¦æŸï¼ˆå¦‚ K-line ä¸€è‡´æ€§ã€åæ•´æ€§ã€éå¹³ç¨³æ€§ï¼‰ï¼Œç¡®ä¿ç”Ÿæˆæ•°æ®æ—¢å¤šæ ·åŒ–åˆç¬¦åˆç»æµé€»è¾‘ã€‚

- **å­¦ä¹ å¼•å¯¼çš„è§„åˆ’å™¨-è°ƒåº¦å™¨ï¼ˆLearning-Guided Planner-Schedulerï¼‰**
  é‡‡ç”¨**åŒå±‚ä¼˜åŒ–ï¼ˆbi-level optimizationï¼‰** æ¶æ„ï¼š
  - **Plannerï¼ˆgÎ¦ï¼‰**ï¼šåŸºäºä»»åŠ¡æ¨¡å‹çŠ¶æ€å’Œè¾“å…¥ç‰¹å¾ï¼Œè¾“å‡ºæœ€ä¼˜çš„å¢å¼ºç­–ç•¥ï¼ˆæ“ä½œé€‰æ‹©æ¦‚ç‡ `p` å’Œå¼ºåº¦ `Î»`ï¼‰ã€‚
  - **Scheduler**ï¼šæ ¹æ®éªŒè¯æŸå¤±å˜åŒ–åŠ¨æ€è°ƒæ•´è¢«å¢å¼ºæ•°æ®çš„æ¯”ä¾‹ `Î±`ï¼Œé˜²æ­¢è¿‡åº¦å¢å¼ºå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚
  æ•´ä¸ªç³»ç»Ÿå½¢æˆé—­ç¯åé¦ˆï¼Œå®ç°**è‡ªåŠ¨åŒ–çš„å·¥ä½œæµç®¡ç†ä¸è´¨é‡ç›‘æ§**ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹é¢ | ç°æœ‰æ–¹æ³•å±€é™ | æœ¬æ–‡ä¼˜åŠ¿ |
|------|---------------|----------|
| **æ•°æ®å¢å¼ºç­–ç•¥** | å›ºå®šç­–ç•¥ï¼ˆå¦‚ RandAugmentï¼‰ã€æ— åé¦ˆæœºåˆ¶ | è‡ªé€‚åº”ã€å¯å­¦ä¹ ã€æ¨¡å‹æ„ŸçŸ¥ |
| **è°ƒåº¦æœºåˆ¶** | å›ºå®šæ¯”ä¾‹å¢å¼º | åŠ¨æ€è°ƒèŠ‚å¢å¼ºæ¯”ä¾‹ï¼Œé˜²è¿‡æ‹Ÿåˆ |
| **é‡‘èä¿çœŸåº¦** | å¿½è§† K-line çº¦æŸã€ç ´åç›¸å…³æ€§ | æ˜¾å¼ç¼–ç é‡‘èçº¦æŸï¼Œä¿è¯ç°å®åˆç†æ€§ |
| **ç³»ç»Ÿæ¶æ„** | åˆ†ç¦»å¼å¤„ç† | ç»Ÿä¸€çš„å¯å¾®åˆ†æ¡†æ¶ï¼Œæ”¯æŒæº¯æºå›æ”¾ï¼ˆprovenance-aware replayï¼‰ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **Stocksï¼ˆæ—¥é¢‘ï¼‰**ï¼šé“ç¼æ–¯å·¥ä¸šå¹³å‡æŒ‡æ•°ï¼ˆDJIï¼‰27åªè‚¡ç¥¨ï¼Œ2000â€“2024å¹´ä»·æ ¼ä¸æŠ€æœ¯æŒ‡æ ‡ã€‚
- **Cryptoï¼ˆå°æ—¶é¢‘ï¼‰**ï¼šBTCã€ETHã€DOTã€LTC å››ç§åŠ å¯†è´§å¸ï¼Œ2023â€“2025å¹´ä»·æ ¼ä¸æŠ€æœ¯æŒ‡æ ‡ã€‚
- åˆ’åˆ†æ–¹å¼ï¼šæŒ‰æ—¶é—´é¡ºåºåˆ’åˆ†ä¸º Train / Valid / Test = 0.6 / 0.2 / 0.2ï¼Œé¿å…æ—¶é—´æ³„éœ²ã€‚

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

#### **ä»»åŠ¡æ¨¡å‹**
- **é¢„æµ‹ä»»åŠ¡**ï¼šGRUã€LSTMã€DLinearã€TCNã€Transformerï¼ˆé¢„æµ‹ä¸‹ä¸€æ—¥æ”¶ç›˜æ”¶ç›Šç‡ï¼‰
- **å¼ºåŒ–å­¦ä¹ äº¤æ˜“ä»»åŠ¡**ï¼šDQNã€PPOï¼ˆåœ¨å•èµ„äº§äº¤æ˜“ç¯å¢ƒä¸­å†³ç­–ä¹°å–ï¼‰

#### **è¯„ä¼°æŒ‡æ ‡**
| ä»»åŠ¡ç±»å‹ | ä¸»è¦æŒ‡æ ‡ |
|--------|---------|
| **é¢„æµ‹ä»»åŠ¡** | MSEã€MAEã€STDï¼ˆæµ‹è¯•é›†æŸå¤±æ ‡å‡†å·®ï¼Œè¡¡é‡é²æ£’æ€§ï¼‰ |
| **äº¤æ˜“ä»»åŠ¡** | Total Return (TR)ã€Sharpe Ratio (SR) |
| **æ•°æ®è´¨é‡è¯„ä¼°** | Discriminative Scoreï¼ˆåˆ†ç±»å™¨åŒºåˆ†çœŸå®/åˆæˆæ•°æ®çš„èƒ½åŠ›ï¼‰ã€Stylized Factsï¼ˆè‡ªç›¸å…³ã€æ æ†æ•ˆåº”ç­‰ï¼‰ |

#### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| æ–¹æ³• | æè¿° |
|------|------|
| **Original** | ä¸è¿›è¡Œä»»ä½•æ•°æ®å¢å¼º |
| **RandAugment** | éšæœºé€‰æ‹©å¢å¼ºæ“ä½œï¼Œå›ºå®šå¼ºåº¦ `Î»=1`ï¼Œæ¯”ä¾‹ `Î±=0.5` |
| **TrivialAugment** | éšæœºé€‰æ‹©æ“ä½œï¼Œéšæœºå¼ºåº¦ï¼Œå›ºå®šæ¯”ä¾‹ `Î±=0.5` |
| **AdaAug** | å­¦ä¹ ç±»/å®ä¾‹ç›¸å…³çš„å¢å¼ºç­–ç•¥ï¼Œä½†å›ºå®š `Î±=0.5`ï¼ˆæ— è°ƒåº¦å™¨ï¼‰ |
| **Ours w/o mixup** | ç§»é™¤å¤šè‚¡æ··åˆæ“ä½œçš„æ¶ˆèç‰ˆæœ¬ |
| **Ours** | å®Œæ•´æå‡ºçš„è‡ªé€‚åº”æ•°æ®æµç³»ç»Ÿ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **é¢„æµ‹ä»»åŠ¡ï¼ˆTable IIï¼‰**
åœ¨æ‰€æœ‰æ¨¡å‹ä¸Šï¼Œ**Ours æ–¹æ³•æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿**ï¼Œå°¤å…¶åœ¨ MSE å’Œ STD ä¸Šè¡¨ç°çªå‡ºï¼š

| æ¨¡å‹ | æ–¹æ³• | MSE â†“ | MAE â†“ | STD â†“ |
|------|------|-------|-------|-------|
| **GRU (Stocks)** | Original | 22.76Ã—10â»â´ | 3.388Ã—10â»Â² | 5.140Ã—10â»Â³ |
| | Ours | **13.14Ã—10â»â´** | **2.496Ã—10â»Â²** | **3.366Ã—10â»Â³** |
| **LSTM (Stocks)** | Original | 5.070Ã—10â»â´ | 1.578Ã—10â»Â² | 1.664Ã—10â»Â³ |
| | Ours | **4.253Ã—10â»â´** | **1.410Ã—10â»Â²** | **1.571Ã—10â»Â³** |
| **DLinear (Crypto)** | Original | 4.291Ã—10â»âµ | 4.428Ã—10â»Â³ | 6.339Ã—10â»Â³ |
| | Ours | **4.138Ã—10â»âµ** | **4.374Ã—10â»Â³** | **6.122Ã—10â»Â³** |

> âœ… **è¶‹åŠ¿**ï¼šæ›´å¼ºæ¨¡å‹ï¼ˆå¦‚ Transformerï¼‰åˆå§‹è¯¯å·®å°ï¼Œä½†å¼±æ¨¡å‹ï¼ˆå¦‚ DLinearï¼‰å¯¹å›ºå®šå¢å¼ºæ•æ„Ÿç”šè‡³é€€åŒ–ï¼›è€Œ **Ours åœ¨å„ç±»æ¨¡å‹ä¸Šå‡ç¨³å®šæå‡**ï¼Œä½“ç°**æ¨¡å‹æ— å…³æ€§ï¼ˆmodel-agnosticï¼‰ä¼˜åŠ¿**ã€‚

#### **å¼ºåŒ–å­¦ä¹ äº¤æ˜“ä»»åŠ¡ï¼ˆTable IIIï¼‰**
å³ä½¿å°† Planner è¿ç§»åˆ°ä¸åŒä»»åŠ¡ï¼ˆä»é¢„æµ‹è¿ç§»åˆ° RL äº¤æ˜“ï¼‰ï¼Œä»èƒ½æ˜¾è‘—æå‡æ”¶ç›Šä¸é£é™©æ§åˆ¶ï¼š

| æ–¹æ³• | è‚¡ç¥¨ | TR â†‘ | SR â†‘ |
|------|------|-----|-----|
| **DQN** | INTC | 35.99% | 16.80 |
| **DQN + Ours** | INTC | **33.35%** | **21.60** âœ… |
| **PPO** | INTC | 34.67% | 17.49 |
| **PPO + Ours** | INTC | **52.91%** âœ… | **23.45** âœ… |

> ğŸ” **å‘ç°**ï¼šè™½ç„¶éƒ¨åˆ†æƒ…å†µä¸‹æ€»å›æŠ¥ç•¥æœ‰ä¸‹é™ï¼Œä½† **Sharpe Ratio æ˜¾è‘—ä¸Šå‡**ï¼Œè¯´æ˜æ¨¡å‹å­¦ä¼šäº†æ›´ç¨³å¥çš„é£é™©æ§åˆ¶ç­–ç•¥ï¼ˆå¦‚æå‰å–å‡ºè§„é¿ä¸‹è·Œï¼‰ã€‚

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**
- **ç§»é™¤ Multi-Stock Mix-Up** â†’ æ€§èƒ½å…¨é¢ä¸‹é™ï¼Œè¡¨æ˜è·¨èµ„äº§ä¿¡æ¯èåˆæœ‰åŠ©äºæ•æ‰é€šç”¨å¸‚åœºåŠ¨æ€ã€‚
- **æ›¿æ¢ä¸ºå›ºå®šè°ƒåº¦ï¼ˆå¦‚ AdaAugï¼‰** â†’ æ€§èƒ½åŠ£äºå®Œæ•´ç³»ç»Ÿï¼Œè¯æ˜**åŠ¨æ€è°ƒåº¦çš„é‡è¦æ€§**ã€‚
- **å®Œå…¨ç§»é™¤ Planner å’Œ Scheduler**ï¼ˆå³ RandAugment/TrivialAugmentï¼‰â†’ å°¤å…¶å¯¹ TCN å’Œ Transformer å¯¼è‡´ä¸¥é‡é€€åŒ–ï¼Œè¯´æ˜**ç›²ç›®å¢å¼ºæœ‰å®³**ã€‚

> ğŸ“Š ç»“è®ºï¼š**Planner + Scheduler + Mix-up** ä¸‰è€…ååŒä½œç”¨ï¼Œç¼ºä¸€ä¸å¯ã€‚

### **æ•°æ®è´¨é‡è¯„ä¼°**
| æ–¹æ³• | Discriminative Score â†“ | ACF(ret) | ACF(abs ret) | Leverage Effect |
|------|------------------------|----------|--------------|------------------|
| **TimeGAN** | 48.2% - 50% = 48.2 | 0.0231 | 0.00987 | 0.0263 |
| **Diffusion-TS** | 42.4 - 50 = -7.6 â†’ 7.6 | 0.0361 | 0.0260 | 0.0220 |
| **Ours** | **14.1 - 50 = -35.9 â†’ 14.1** âœ… | **0.000133** âœ… | **0.000478** âœ… | **0.00224** âœ… |

> âœ… **ç»“è®º**ï¼šæœ¬æ–‡ç”Ÿæˆçš„æ•°æ®æœ€æ¥è¿‘çœŸå®åˆ†å¸ƒï¼Œä¸”å®Œç¾ä¿ç•™ä¸‰å¤§é‡‘èâ€œé£æ ¼åŒ–äº‹å®â€ï¼ˆstylized factsï¼‰ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **â€œHistory Is Not Enoughâ€**ï¼šé™æ€å†å²æ•°æ®ä¸è¶³ä»¥æ”¯æ’‘åŠ¨æ€é‡‘èå¸‚åœºå»ºæ¨¡ï¼Œå¿…é¡»å¼•å…¥**è‡ªé€‚åº”æ•°æ®åˆæˆæœºåˆ¶**ã€‚
2. **é—­ç¯åé¦ˆè‡³å…³é‡è¦**ï¼šé€šè¿‡éªŒè¯é›†åé¦ˆé©±åŠ¨ Planner æ›´æ–°ï¼Œä½¿æ•°æ®å¢å¼ºç­–ç•¥éšæ¨¡å‹å­¦ä¹ çŠ¶æ€æ¼”åŒ–ï¼Œæœ‰æ•ˆç¼“è§£æ¦‚å¿µæ¼‚ç§»ã€‚
3. **é‡‘èä¿çœŸä¼˜å…ˆ**ï¼šæ‰€æœ‰å¢å¼ºæ“ä½œå¿…é¡»éµå®ˆ K-line çº¦æŸã€åæ•´å…³ç³»ç­‰é‡‘èå…ˆéªŒï¼Œå¦åˆ™ä¼šç ´åæ•°æ®è¯­ä¹‰ã€‚
4. **è°ƒåº¦æœºåˆ¶å†³å®šæˆè´¥**ï¼šå›ºå®šæ¯”ä¾‹å¢å¼ºå¯èƒ½é€‚å¾—å…¶åï¼›**Overfitting-aware Scheduler** å¯åŠ¨æ€å¹³è¡¡å¤šæ ·æ€§ä¸ç¨³å®šæ€§ã€‚
5. **æ–¹æ³•å…·å¤‡è¿ç§»èƒ½åŠ›**ï¼šåœ¨é¢„æµ‹ä»»åŠ¡ä¸Šå­¦åˆ°çš„ Planner å¯è¿ç§»åˆ° RL äº¤æ˜“ä»»åŠ¡ï¼Œæå‡é£é™©è°ƒæ•´åæ”¶ç›Šã€‚

### **å±€é™æ€§**
- å½“å‰ç³»ç»Ÿå‡è®¾éªŒè¯é›†ä¸æœªæ¥æµ‹è¯•é›†åˆ†å¸ƒç›¸è¿‘ï¼ˆValidation-Test Proximityï¼‰ï¼Œè‹¥å¸‚åœºçªå˜ï¼ˆå¦‚é»‘å¤©é¹…äº‹ä»¶ï¼‰ï¼Œè¯¥å‡è®¾å¯èƒ½å¤±æ•ˆã€‚
- å¤šè‚¡æ··åˆä¾èµ–åæ•´æ£€éªŒï¼Œå¯¹ä½æµåŠ¨æ€§æˆ–æ–°å…´èµ„äº§å¯èƒ½ä¸é€‚ç”¨ã€‚
- Planner ä½¿ç”¨ Transformer æ¶æ„ï¼Œè®¡ç®—å¼€é”€è¾ƒå¤§ï¼Œå°šæœªéƒ¨ç½²äºé«˜é¢‘äº¤æ˜“åœºæ™¯ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- å¼•å…¥åœ¨çº¿å­¦ä¹ æœºåˆ¶ï¼Œå®ç°å®æ—¶æ•°æ®æµä¸‹çš„æŒç»­æ›´æ–°ã€‚
- æ¢ç´¢æ›´å¤æ‚çš„è·¨æ¨¡æ€å¢å¼ºï¼ˆå¦‚ç»“åˆæ–°é—»æƒ…ç»ªã€å®è§‚æŒ‡æ ‡ï¼‰ã€‚
- å°†æœ¬æ¡†æ¶æ‰©å±•è‡³å¤šèµ„äº§ç»„åˆä¼˜åŒ–ä¸é£é™©ç®¡ç†ä»»åŠ¡ã€‚
- å¼€å‘è½»é‡åŒ– Plannerï¼Œé€‚ç”¨äºè¾¹ç¼˜è®¾å¤‡æˆ–ä½å»¶è¿Ÿäº¤æ˜“ç³»ç»Ÿã€‚

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼šæœ¬æ–‡é¦–æ¬¡æ„å»ºäº†ä¸€ä¸ª**ç«¯åˆ°ç«¯å¯å¾®ã€å­¦ä¹ å¼•å¯¼ã€é‡‘èæ„ŸçŸ¥çš„è‡ªé€‚åº”æ•°æ®æµç³»ç»Ÿ**ï¼Œå®ç°äº†ä»â€œè¢«åŠ¨ä½¿ç”¨å†å²æ•°æ®â€åˆ°â€œä¸»åŠ¨æ¼”åŒ–æ•°æ®ç”Ÿæ€â€çš„èŒƒå¼è½¬å˜ï¼Œä¸ºæ„å»ºé²æ£’çš„é‡åŒ–é‡‘è AI æä¾›äº†æ–°åŸºç¡€è®¾æ–½ã€‚

</details>

---

### 10. [Unlocking Implicit Experience: Synthesizing Tool-Use Trajectories from Text](https://arxiv.org/abs/2601.10355)

**Authors**: Zhihao Xu, Rumei Li, Jiahuan Li, Rongxiang Weng, Jingang Wang, Xunliang Cai, Xiting Wang  
**Category**: cs.CL  
**Published**: 2026-01-16  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.10355v1  

#### Abstract
Enabling Large Language Models (LLMs) to effectively utilize tools in multi-turn interactions is essential for building capable autonomous agents. However, acquiring diverse and realistic multi-turn tool-use data remains a significant challenge. In this work, we propose a novel text-based paradigm. ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šUnlocking Implicit Experience: Synthesizing Tool-Use Trajectories from Text

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰è®­ç»ƒå…·å¤‡å¤šè½®äº¤äº’èƒ½åŠ›çš„è‡ªä¸»æ™ºèƒ½ä½“ï¼ˆautonomous agentsï¼‰é¢ä¸´ä¸€ä¸ªæ ¸å¿ƒç“¶é¢ˆï¼š**é«˜è´¨é‡ã€å¤šæ ·åŒ–çš„å¤šè½®å·¥å…·ä½¿ç”¨è½¨è¿¹ï¼ˆmulti-turn tool-use trajectoriesï¼‰æ•°æ®ç¨€ç¼º**ã€‚ç°æœ‰çš„æ•°æ®åˆæˆæ–¹æ³•å¤§å¤šä¾èµ–äºé¢„å®šä¹‰çš„APIé›†åˆï¼ˆpredefined APIsï¼‰ï¼Œé€šè¿‡æ¨¡æ‹Ÿç”¨æˆ·ä»»åŠ¡æ¥ç”Ÿæˆäº¤äº’æ•°æ®ã€‚è¿™ç§æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- å·¥å…·é›†çš„æ„å»ºæˆæœ¬é«˜ä¸”éš¾ä»¥è¦†ç›–çœŸå®ä¸–ç•Œçš„å¤šæ ·æ€§ï¼›
- ç”Ÿæˆçš„æ•°æ®å—é™äºé¢„è®¾å·¥å…·èŒƒå›´ï¼Œæ³›åŒ–èƒ½åŠ›å¼±ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§å…¨æ–°çš„ **â€œæ–‡æœ¬åˆ°è½¨è¿¹â€ï¼ˆText-to-Trajectoryï¼‰èŒƒå¼**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š  
> **ä»å¤§è§„æ¨¡éç»“æ„åŒ–æ–‡æœ¬è¯­æ–™ä¸­æå–éšå«çš„äººç±»å¤šæ­¥é—®é¢˜è§£å†³ç»éªŒï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºå¯ç”¨äºè®­ç»ƒæ™ºèƒ½ä½“çš„å¤šè½®å·¥å…·ä½¿ç”¨è½¨è¿¹ã€‚**

ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† **GEM**ï¼ˆGenerative Extraction from Multimodal textï¼‰æ•°æ®åˆæˆæµæ°´çº¿ï¼ŒåŒ…å«å››ä¸ªé˜¶æ®µï¼š
1. **ç›¸å…³æ€§è¿‡æ»¤ï¼ˆRelevance Filteringï¼‰**ï¼šç­›é€‰åŒ…å«å¤šæ­¥éª¤æµç¨‹çš„æ–‡æœ¬æ®µè½ï¼›
2. **å·¥ä½œæµä¸å·¥å…·æå–ï¼ˆWorkflow & Tool Extractionï¼‰**ï¼šä»æ–‡æœ¬ä¸­æŠ½å–å‡ºç»“æ„åŒ–çš„å·¥ä½œæµå’Œå¯æ“ä½œçš„å·¥å…·å®šä¹‰ï¼ˆç¬¦åˆOpenAIæ ¼å¼ï¼‰ï¼›
3. **è½¨è¿¹ç”Ÿæˆï¼ˆTrajectory Generationï¼‰**ï¼šåˆ©ç”¨å¤§æ¨¡å‹å°†æŠ½è±¡å·¥ä½œæµè½¬åŒ–ä¸ºå…·ä½“çš„ç”¨æˆ·-åŠ©æ‰‹å¤šè½®å¯¹è¯è½¨è¿¹ï¼›
4. **å¤æ‚åº¦ç²¾ç‚¼ï¼ˆComplexity Refinementï¼‰**ï¼šå¢å¼ºè½¨è¿¹çš„å¤æ‚æ€§å’ŒçœŸå®æ€§ï¼Œå¦‚å¼•å…¥æ­§ä¹‰è¯·æ±‚ã€é”™è¯¯æ¢å¤ç­‰æ¨¡å¼ã€‚

æ­¤å¤–ï¼Œä¸ºäº†é™ä½æ¨ç†å¼€é”€ï¼Œä½œè€…è¿›ä¸€æ­¥è®­ç»ƒäº†ä¸€ä¸ªè½»é‡çº§çš„ **Trajectory Synthesizer** æ¨¡å‹ï¼Œé€šè¿‡ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å°†æ•´ä¸ªå››é˜¶æ®µæµæ°´çº¿â€œè’¸é¦â€ä¸ºä¸€ä¸ªç«¯åˆ°ç«¯çš„é«˜æ•ˆç”Ÿæˆå™¨ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ— éœ€ä¾èµ–é¢„å®šä¹‰å·¥å…·é›†**ï¼šç›´æ¥ä»å¼€æ”¾åŸŸæ–‡æœ¬ä¸­æŒ–æ˜çœŸå®ä¸–ç•Œçš„é—®é¢˜è§£å†³é€»è¾‘ï¼›
- **æ•°æ®æ¥æºæ›´ä¸°å¯Œã€æ›´å…·çœŸå®æ€§**ï¼šåˆ©ç”¨å·²æœ‰çš„æµ·é‡æ–‡æœ¬ï¼ˆå¦‚ç½‘é¡µæ•™ç¨‹ã€æ“ä½œæ‰‹å†Œï¼‰ä½œä¸ºâ€œéšå¼ç»éªŒåº“â€ï¼›
- **æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›**ï¼šåœ¨æœªè§è¿‡çš„é¢†åŸŸä¹Ÿèƒ½è¡¨ç°å‡ºè‰²ï¼›
- **å¯æ‰©å±•æ€§å¼º**ï¼šéšç€æ–‡æœ¬è¯­æ–™å¢é•¿ï¼Œå¯æ— é™æ‰©å±•è®­ç»ƒæ•°æ®è§„æ¨¡ï¼›
- **æˆæœ¬æ›´ä½**ï¼šé€šè¿‡Trajectory Synthesizerå®ç°ä½æˆæœ¬ã€é«˜æ•ˆç‡çš„å¤§è§„æ¨¡æ•°æ®ç”Ÿæˆã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **åŸå§‹æ–‡æœ¬è¯­æ–™**ï¼š`Ultra-FineWeb`ï¼ˆç”¨äºè®­ç»ƒæ•°æ®åˆæˆï¼‰
- **å¤–éƒ¨éªŒè¯æº**ï¼š`Wikihow`ï¼ˆç”¨äºæµ‹è¯•æ–¹æ³•æ³›åŒ–æ€§ï¼‰
- **è¯„ä¼°åŸºå‡†**ï¼š
  - **BFCL V3 Multi-Turn**ï¼šè¯„ä¼°è·¨é¢†åŸŸçš„å‡½æ•°è°ƒç”¨èƒ½åŠ›ï¼Œåˆ†ä¸º Baseã€Miss Funcã€Miss Paramã€Long Context å››ç±»ä»»åŠ¡ï¼›
  - **T2-bench (Airline & Retail)**ï¼šè¯„ä¼°åœ¨ç‰¹å®šç°å®åœºæ™¯ä¸‹çš„åŒæ§ç¯å¢ƒï¼ˆdual-controlï¼‰ä¸‹æ™ºèƒ½ä½“è¡¨ç°ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹åŸºç¡€**ï¼šåŸºäº `Qwen3-8B` å’Œ `Qwen3-32B` è¿›è¡Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼›
- **è®­ç»ƒç»†èŠ‚**ï¼š
  - å­¦ä¹ ç‡ï¼š5e-6
  - Epochsï¼š2
  - Batch Sizeï¼š64
  - ä½¿ç”¨ `LLaMA-Factory` æ¡†æ¶è¿›è¡Œå…¨å‚æ•°å¾®è°ƒ
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **BFCL V3**ï¼šOverall Accuracyï¼ˆæ€»ä½“å‡†ç¡®ç‡ï¼‰
  - **T2-bench**ï¼š`Avg@4` å’Œ `Pass@4`

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å¯¹æ¯”äº†å¤šä¸ªä¸»æµå¼€æºå·¥å…·ä½¿ç”¨æ•°æ®é›†ï¼š
- **APIGEN-MT**
- **Simia-Tau**
- **MUA**
- **TOUCAN**

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå…¶ä¸­ **APIGEN-MT å’Œ Simia æ˜¯åœ¨ T-bench ç¯å¢ƒä¸­ç”Ÿæˆçš„ in-domain æ•°æ®**ï¼Œè€Œæœ¬æ–‡æ–¹æ³•ä½¿ç”¨çš„è®­ç»ƒæ•°æ®æ˜¯ **out-of-domain**ï¼ˆæ¥è‡ªé€šç”¨æ–‡æœ¬ï¼‰ï¼Œå› æ­¤æ›´å…·æŒ‘æˆ˜æ€§ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### åœ¨ BFCL V3 å¤šè½®åŸºå‡†ä¸Šçš„è¡¨ç°ï¼ˆTable 1ï¼‰

| æ¨¡å‹ | Overall Acc |
|------|-------------|
| GPT-4.1 | 38.88% |
| DeepSeek-V3.2-Exp | 37.38% |
| **Qwen3-32B-GEM** | **44.88%** âœ… |

ğŸ‘‰ **Qwen3-32B-GEM è¶…è¶Šäº†æ‰€æœ‰å¼€æºåŠéƒ¨åˆ†é—­æºå¤§æ¨¡å‹**ï¼Œç›¸æ¯”åŸºç¡€æ¨¡å‹æå‡è¾¾ **16.5ä¸ªç™¾åˆ†ç‚¹**ã€‚

#### åœ¨ T2-bench ä¸Šçš„è¡¨ç°ï¼ˆTable 5ï¼‰

| æ¨¡å‹ | Retail Pass@4 |
|------|----------------|
| APIGEN-MT | 74.56% |
| Simia | 73.68% |
| MUA | 80.70% |
| **Qwen3-32B-GEM** | **86.84%** âœ… |

ğŸ‘‰ å°½ç®¡è®­ç»ƒæ•°æ®å®Œå…¨ out-of-domainï¼Œ**Qwen3-32B-GEM åœ¨é›¶å”®é¢†åŸŸä»æ˜¾è‘—ä¼˜äºåŸºäº in-domain æ•°æ®è®­ç»ƒçš„æ¨¡å‹**ï¼Œå±•ç°å‡ºæå¼ºçš„è¿ç§»èƒ½åŠ›å’Œæ³›åŒ–æ€§ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨ BFCL ä¸Šï¼ŒQwen3-8B-GEM è¾¾åˆ° 30.25%ï¼Œè¿œè¶…åŒè§„æ¨¡åŸºçº¿ï¼ˆå¦‚ TOUCAN: 21.88%ï¼‰ï¼›
- åœ¨ T2-bench ä¸Šï¼Œå³ä½¿ä½¿ç”¨ 8B æ¨¡å‹ï¼ŒQwen3-8B-GEM ä¹Ÿè¾¾åˆ°äº†ä¸ in-domain è®­ç»ƒæ¨¡å‹ç›¸å½“ç”šè‡³æ›´ä¼˜çš„æ€§èƒ½ï¼ˆå¦‚åœ¨ Retail Pass@4 ä¸Šè¾¾åˆ° 75.44%ï¼Œè¶…è¿‡ APIGEN-MT çš„ 69.30%ï¼‰ï¼›
- è¡¨æ˜ï¼š**ä»æ–‡æœ¬ä¸­æå–çš„ç»éªŒå…·æœ‰å¼ºå¤§çš„è·¨åŸŸè¿ç§»æ½œåŠ›**ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ç§»é™¤ Refinement é˜¶æ®µçš„å½±å“ï¼ˆTable 6ï¼‰
- å¯¹ Qwen3-32Bï¼š
  - å®Œæ•´ GEMï¼š44.88%
  - w/o Refinementï¼š32.50%
  - â• **æå‡è¶…è¿‡ 12.38%**

#### ç§»é™¤ LLM-Based Checkï¼ˆå»å¹»è§‰æ£€æµ‹ï¼‰çš„å½±å“
- å¯¹ Qwen3-8Bï¼š
  - w/o Checkï¼š27.38%
  - å®Œæ•´ GEMï¼š30.25%
  - â• æå‡çº¦ 2.87%

ğŸ‘‰ è¯´æ˜ **Refinement å’Œ Hallucination Detection å¯¹æ•°æ®è´¨é‡è‡³å…³é‡è¦**ã€‚

### Trajectory Synthesizer æ€§èƒ½ï¼ˆTable 2ï¼‰
- ä½¿ç”¨ Ultrafineweb è®­ç»ƒçš„ Synthesizerï¼Œåœ¨ BFCL ä¸Šè¾¾åˆ° 28.38%ï¼Œæ¥è¿‘ä½¿ç”¨ GLM-4.6 ç”Ÿæˆæ•°æ®è®­ç»ƒçš„ç»“æœï¼ˆ30.25%ï¼‰ï¼›
- æ¨ç†å»¶è¿Ÿå’Œæˆæœ¬å¤§å¹…ä¸‹é™ï¼Œå®ç°äº† **é«˜è´¨é‡ä¸ä½æˆæœ¬çš„å¹³è¡¡**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **éç»“æ„åŒ–æ–‡æœ¬æ˜¯å®è´µçš„â€œéšå¼ç»éªŒâ€å®åº“**ï¼šå¤§é‡æ—¥å¸¸æ–‡æœ¬ï¼ˆå¦‚æ“ä½œæŒ‡å—ã€æ•™ç¨‹ï¼‰å¤©ç„¶è•´å«ä¸°å¯Œçš„å¤šæ­¥é—®é¢˜è§£å†³é€»è¾‘ï¼Œå¯è¢«æœ‰æ•ˆè½¬åŒ–ä¸º agent è®­ç»ƒæ•°æ®ã€‚
2. **GEM æµæ°´çº¿èƒ½ç”Ÿæˆé«˜åº¦å¤æ‚çš„è½¨è¿¹**ï¼š
   - å¹³å‡æ¯æ¡è½¨è¿¹åŒ…å« **8.6 ä¸ªä¸åŒå·¥å…·**ã€**46 è½®å¯¹è¯**ã€**16.3 æ¬¡å·¥å…·è°ƒç”¨**ï¼ˆè¿œé«˜äº TOUCANã€APIGEN-MTï¼‰ï¼›
   - æ”¯æŒå¤šç§çœŸå®äº¤äº’æ¨¡å¼ï¼šæ¾„æ¸…è¯·æ±‚ã€è§„åˆ™éµå®ˆã€é”™è¯¯æ¢å¤ã€å¤šè·³æ¨ç†ç­‰ï¼ˆè§ Figure 8ï¼‰ã€‚
3. **æ–‡æœ¬é©±åŠ¨çš„æ–¹æ³•å…·å¤‡å“è¶Šæ³›åŒ–èƒ½åŠ›**ï¼šå³ä½¿åœ¨å®Œå…¨ä¸åŒçš„é¢†åŸŸï¼ˆå¦‚èˆªç©ºã€é›¶å”®ï¼‰ï¼Œä¹Ÿèƒ½è¶…è¶ŠåŸºäº in-domain æ•°æ®è®­ç»ƒçš„æ¨¡å‹ã€‚
4. **Trajectory Synthesizer æˆåŠŸå®ç°äº†â€œè’¸é¦â€**ï¼šå°†å¤æ‚æµæ°´çº¿å‹ç¼©ä¸ºå•æ¨¡å‹ï¼Œä¿æŒè´¨é‡çš„åŒæ—¶æå¤§é™ä½æˆæœ¬ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- ä¾èµ–é«˜è´¨é‡çš„åŸå§‹æ–‡æœ¬è¾“å…¥ï¼Œè‹¥æ–‡æœ¬æè¿°æ¨¡ç³Šæˆ–ä¸å®Œæ•´ï¼Œåˆ™éš¾ä»¥æå–æœ‰æ•ˆå·¥ä½œæµï¼›
- å·¥å…·å®šä¹‰ä»éœ€äººå·¥è®¾è®¡ schema æˆ–ä¾èµ–å¼º teacher modelï¼ˆå¦‚ GLM-4.6ï¼‰ï¼Œè‡ªåŠ¨åŒ–ç¨‹åº¦æœ‰å¾…æé«˜ï¼›
- å½“å‰æ–¹æ³•ä¸»è¦é¢å‘æ–‡æœ¬ä¸­çš„â€œæ˜¾å¼æµç¨‹â€ï¼Œå¯¹éšå–»æ€§æˆ–éæ ‡å‡†åŒ–è¡¨è¾¾å¤„ç†æœ‰é™ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³å¤šæ¨¡æ€æ–‡æœ¬ï¼ˆå¦‚å›¾æ–‡ç»“åˆçš„æ“ä½œæŒ‡å—ï¼‰ï¼›
- æ„å»ºè‡ªåŠ¨åŒ–çš„å·¥å…·å‘ç°ä¸æ ‡å‡†åŒ–æœºåˆ¶ï¼›
- æ¢ç´¢å¦‚ä½•æ›´å¥½åœ°ä¿ç•™åŸå§‹æ–‡æœ¬ä¸­çš„ä¸Šä¸‹æ–‡çº¦æŸä¸ä¸šåŠ¡é€»è¾‘ï¼›
- å°†è¯¥èŒƒå¼åº”ç”¨äºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰é˜¶æ®µçš„ agent è®­ç»ƒã€‚

---

> âœ… **ä¸€å¥è¯æ€»ç»“**ï¼š  
> æœ¬è®ºæ–‡å¼€åˆ›æ€§åœ°æå‡ºä»çº¯æ–‡æœ¬ä¸­æå–â€œéšå¼ç»éªŒâ€ä»¥åˆæˆå¤šè½®å·¥å…·ä½¿ç”¨è½¨è¿¹çš„æ–°èŒƒå¼ï¼Œé€šè¿‡ GEM æµæ°´çº¿å’Œ Trajectory Synthesizer å®ç°äº†é«˜è´¨é‡ã€ä½æˆæœ¬ã€å¼ºæ³›åŒ–çš„ agent æ•°æ®ç”Ÿæˆï¼Œåœ¨å¤šä¸ª benchmark ä¸Šè¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œä¸ºæ„å»ºçœŸæ­£é€šç”¨çš„è‡ªä¸»æ™ºèƒ½ä½“æä¾›äº†æ–°è·¯å¾„ã€‚

</details>

---

### 11. [TimeSAE: Sparse Decoding for Faithful Explanations of Black-Box Time Series Models](https://arxiv.org/abs/2601.09776)

**Authors**: Khalid Oublal, Quentin Bouniot, Qi Gan, Stephan Cl\'emen\c{c}on, Zeynep Akata  
**Category**: cs.LG  
**Published**: 2026-01-16  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.09776v1  

#### Abstract
As black box models and pretrained models gain traction in time series applications, understanding and explaining their predictions becomes increasingly vital, especially in high-stakes domains where interpretability and trust are essential. However, most of the existing methods involve only in-dist...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šTimeSAE: Sparse Decoding for Faithful Explanations of Black-Box Time Series Models**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å½“å‰å¤§å¤šæ•°æ—¶é—´åºåˆ—æ¨¡å‹è§£é‡Šæ–¹æ³•å­˜åœ¨ä»¥ä¸‹å…³é”®ç¼ºé™·ï¼š
- **åˆ†å¸ƒå¤–æ³›åŒ–èƒ½åŠ›å·®ï¼ˆOut-of-Distribution Generalizationï¼‰**ï¼šç°æœ‰æ–¹æ³•ï¼ˆå¦‚LIMEã€Dynamaskç­‰ï¼‰åœ¨è®­ç»ƒåˆ†å¸ƒå†…è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨é¢å¯¹åˆ†å¸ƒå¤–ï¼ˆOODï¼‰æ ·æœ¬æ—¶ï¼Œè§£é‡Šè´¨é‡æ˜¾è‘—ä¸‹é™ã€‚
- **ç¼ºä¹å› æœæ€§ï¼ˆCausal Faithfulnessï¼‰**ï¼šå¤šæ•°æ–¹æ³•åŸºäºç›¸å…³æ€§è€Œéå› æœæ€§ç”Ÿæˆè§£é‡Šï¼Œæ— æ³•å‡†ç¡®åæ˜ æ¨¡å‹å†³ç­–çš„çœŸå®æ¨ç†è¿‡ç¨‹ã€‚
- **è§£é‡Šä¸å¿ å®ï¼ˆUnfaithful Explanationsï¼‰**ï¼šéƒ¨åˆ†æ–¹æ³•ç”Ÿæˆçš„è§£é‡Šå¯èƒ½ä¸åŸå§‹æ•°æ®åˆ†å¸ƒåç¦»ï¼Œå¯¼è‡´è§£é‡Šä¸å¯é ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯**
ä½œè€…æå‡ºäº† **TimeSAE**ï¼ˆTime Series Sparse Autoencoderï¼‰ï¼Œä¸€ä¸ªåŸºäºç¨€ç–è‡ªç¼–ç å™¨ï¼ˆSAEï¼‰çš„æ¡†æ¶ï¼Œç”¨äºå¯¹é»‘ç›’æ—¶é—´åºåˆ—æ¨¡å‹è¿›è¡Œå¯æ³›åŒ–çš„ã€å¿ å®çš„è§£é‡Šã€‚

#### **æ ¸å¿ƒåˆ›æ–°ç‚¹**ï¼š
1. **å¼•å…¥Sparse Autoencoderè¿›è¡Œæ¦‚å¿µå­¦ä¹ ï¼ˆConcept Learningï¼‰**  
   - ä½¿ç”¨SAEå°†æ—¶é—´åºåˆ—åˆ†è§£ä¸ºå¯è§£é‡Šçš„â€œæ¦‚å¿µâ€ï¼ˆconceptsï¼‰ï¼Œå¹¶é€šè¿‡JumpReLUæ¿€æ´»å‡½æ•°æå‡æ¦‚å¿µå­¦ä¹ çš„ç¨³å®šæ€§å’Œé‡å»ºä¿çœŸåº¦ã€‚
   - æ›¿ä»£ä¼ ç»Ÿæ©ç ï¼ˆmaskingï¼‰æ–¹æ³•ï¼Œç›´æ¥å­¦ä¹ ç«¯åˆ°ç«¯çš„æ¦‚å¿µè¡¨ç¤ºï¼Œé¿å…ç”ŸæˆOODæ ·æœ¬ã€‚

2. **é€šè¿‡åäº‹å®è§£é‡Šï¼ˆCounterfactual Explanationsï¼‰ä¿è¯å¿ å®æ€§ï¼ˆFaithfulnessï¼‰**  
   - å¼•å…¥**è¿‘ä¼¼åäº‹å®è§£é‡Šï¼ˆApproximated Counterfactual Explanationï¼‰**ï¼Œç»“åˆå¯¹æ¯”æŸå¤±ï¼ˆInfoNCEï¼‰è®­ç»ƒï¼Œç¡®ä¿å¹²é¢„åé¢„æµ‹å˜åŒ–ä¸çœŸå®å› æœæ•ˆåº”ä¸€è‡´ã€‚
   - ç†è®ºè¯æ˜ï¼šåœ¨è¯¯å·®æœ‰ç•Œæ¡ä»¶ä¸‹ï¼ŒTimeSAEèƒ½ä¿æŒå› æœæ•ˆåº”çš„æ’åºï¼ˆOrder Faithfulnessï¼‰ã€‚

3. **å¢å¼ºåˆ†å¸ƒå¤–æ³›åŒ–èƒ½åŠ›ï¼ˆGeneralization in OODï¼‰**  
   - æå‡º**ç»„åˆä¸€è‡´æ€§æŸå¤±ï¼ˆCompositional Consistency Loss, $L_{cc}$ï¼‰**ï¼Œé¼“åŠ±è§£ç å™¨åœ¨æœªè§çš„æ¦‚å¿µç»„åˆä¸Šä»èƒ½è¢«ç¼–ç å™¨æ­£ç¡®é€†æ˜ å°„ï¼Œä»è€Œæå‡OODåœºæ™¯ä¸‹çš„é²æ£’æ€§ã€‚

4. **å‘å¸ƒæ–°åŸºå‡†æ•°æ®é›† EliteLJ**  
   - åŒ…å«ç²¾è‹±è·³è¿œè¿åŠ¨å‘˜çš„éª¨éª¼å§¿æ€åºåˆ—åŠä¸“å®¶æ ‡æ³¨çš„å…³é”®é˜¶æ®µï¼ˆèµ·è·‘ã€èµ·è·³ã€é£è¡Œã€è½åœ°ï¼‰ï¼Œæ”¯æŒä½“è‚²åˆ†æä¸­çš„å¯è§£é‡Šæ€§ç ”ç©¶ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç‰¹æ€§ | TimeSAE | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚Dynamask, TimeX++ï¼‰ |
|------|--------|-------------------------------|
| æ˜¯å¦æ¨¡å‹æ— å…³ï¼ˆModel-Agnosticï¼‰ | âœ… æ˜¯ | âœ… å¤šæ•°æ˜¯ |
| æ˜¯å¦å¤„ç†OODæ ·æœ¬ | âœ… æ˜¾å¼å»ºæ¨¡ | âŒ å®¹æ˜“ç”ŸæˆOODæ ·æœ¬ |
| æ˜¯å¦å…·å¤‡å› æœæ€§ | âœ… åäº‹å®é©±åŠ¨ | âš ï¸ å¤šä¸ºç›¸å…³æ€§ |
| è§£é‡Šæ˜¯å¦å¿ å® | âœ… ç†è®º+å®è¯æ”¯æŒ | âš ï¸ éƒ¨åˆ†æ–¹æ³•å­˜åœ¨åå·® |
| æ¨ç†æ•ˆç‡ | âœ… å¿«é€Ÿï¼ˆ~4ms/å®ä¾‹ï¼‰ | âš ï¸ éƒ¨åˆ†éœ€å¤šæ¬¡å‰å‘ä¼ æ’­ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
å…±ä½¿ç”¨ **8ä¸ªæ•°æ®é›†**ï¼Œæ¶µç›–åˆæˆä¸çœŸå®ä¸–ç•Œåœºæ™¯ï¼š

| ç±»å‹ | æ•°æ®é›† | ä»»åŠ¡ | ç‰¹å¾ |
|------|-------|------|------|
| **åˆæˆæ•°æ®é›†** | FreqShapes, SeqComb-UV/MV, LowVar | åˆ†ç±» | å·²çŸ¥ground-truthè§£é‡Šä¿¡å· |
| **çœŸå®ä¸–ç•Œæ•°æ®é›†** | ECGï¼ˆå¿ƒç”µå›¾ï¼‰ | åˆ†ç±» | QRSåŒºé—´ä¸ºå…³é”®ç‰¹å¾ |
| | PAMï¼ˆäººä½“æ´»åŠ¨è¯†åˆ«ï¼‰ | åˆ†ç±» | å¤šå˜é‡ä¼ æ„Ÿå™¨æ•°æ® |
| | ETTh-1 / ETTh-2ï¼ˆç”µåŠ›è´Ÿè·ï¼‰ | å›å½’ | è·¨åŸŸOODæµ‹è¯•ï¼ˆETTh1â†’ETTh2ï¼‰ |
| | **EliteLJï¼ˆæœ¬æ–‡æå‡ºï¼‰** | å›å½’ | è·³è¿œåŠ¨ä½œéª¨éª¼åºåˆ—ï¼ˆ34ç»´Ã—50å¸§ï¼‰ |

---

### **å®éªŒè®¾ç½®**
- **é»‘ç›’æ¨¡å‹**ï¼šTransformerã€PatchTSã€DLinearï¼ˆè®­ç»ƒï¼‰ã€ä»¥åŠé¢„è®­ç»ƒå¤§æ¨¡å‹ **TimeGPT** å’Œ **Chronos**ã€‚
- **è¯„ä¼°æ–¹å¼**ï¼špost-hocè§£é‡Šï¼Œæ— éœ€è®¿é—®æ¨¡å‹å†…éƒ¨ç»“æ„ã€‚
- **è®­ç»ƒç›®æ ‡**ï¼šè”åˆä¼˜åŒ–å››é¡¹æŸå¤±ï¼š
  $$
  \mathcal{L}_{\text{TimeSAE}} = \mathcal{L}_{\text{SAE}} + \lambda_{\text{label-fidelity}} \cdot \mathcal{L}_{\text{label-fidelity}} + \omega \cdot \mathcal{L}_{cc} + \eta \cdot \mathcal{L}_{cf}
  $$

---

### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **AUPRC, AUP, AUR** | åŸºäºprecision-recallæ›²çº¿çš„ç»¼åˆæ€§èƒ½ï¼Œè¶Šé«˜è¶Šå¥½ |
| **Faithfulness ($F_x$)** | ç§»é™¤é‡è¦æ¦‚å¿µåé¢„æµ‹å˜åŒ–é‡ï¼Œè¶Šå¤§è¶Šå¿ å® |
| **KL, MMD** | è§£é‡Šæ ·æœ¬ä¸åŸåˆ†å¸ƒçš„è·ç¦»ï¼Œè¶Šå°è¶Šæ¥è¿‘ |
| **KDE** | è§£é‡Šæ ·æœ¬çš„å¯¹æ•°ä¼¼ç„¶ï¼Œè¶Šé«˜è¶Šåˆç† |
| **Spearmanç›¸å…³æ€§** | éªŒè¯ç†è®ºï¼š$F_x$ ä¸åäº‹å®è¯¯å·® $e_{cf}$ çš„è´Ÿç›¸å…³æ€§ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
å…±å¯¹æ¯” **11ç§SOTAæ–¹æ³•**ï¼š
- **æ¢¯åº¦ç±»**ï¼šIGï¼ˆIntegrated Gradientsï¼‰
- **æ‰°åŠ¨ç±»**ï¼šDynamask, WinIT, CoRTX
- **ä¿¡æ¯ç“¶é¢ˆç±»**ï¼šTimeX, TimeX++, CounTS
- **æœ€æ–°æ–¹æ³•**ï¼šStartGrad, TIMING, ORTE

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **è¡¨1ï¼šFaithfulness ($F_x$) å¯¹æ¯”ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰**
| Method | ECG | PAM | ETTh-1 | ETTh-2 | EliteLJ | Rank |
|--------|-----|-----|--------|--------|---------|------|
| IG | 0.92 | 0.89 | 1.00 | 0.95 | 0.91 | 9.0 |
| TimeX++ | 1.65 | 1.58 | 1.75 | 1.70 | 1.44 | 3.1 |
| **TimeSAE (Ours)** | **1.78** | **2.15** | **2.12** | **2.09** | **1.86** | **1.7** |

> âœ… åœ¨æ‰€æœ‰ä»»åŠ¡ä¸­å‡å–å¾—æœ€é«˜ $F_x$ï¼Œè¯´æ˜å…¶è§£é‡Šæœ€å…·å½±å“åŠ›ä¸”æœ€å¿ å®ã€‚

#### **å›¾2 & å›¾3ï¼šAUPRC æ€§èƒ½å¯¹æ¯”**
- TimeSAE åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Š **å…¨é¢ä¼˜äºæ‰€æœ‰åŸºçº¿æ–¹æ³•**ï¼Œå°¤å…¶åœ¨ ECG å’Œ PAM ä¸Šä¼˜åŠ¿æ˜æ˜¾ã€‚
- åœ¨ EliteLJ ä¸Šè¾¾åˆ° **0.866 AUPRC**ï¼Œæ˜¾è‘—é«˜äºç¬¬äºŒå TimeX++ï¼ˆ0.859ï¼‰ã€‚

#### **OOD æ³›åŒ–èƒ½åŠ›ï¼ˆè¡¨2ï¼‰**
| Setting | Method | AUPRC (ID) | AUPRC (OOD) | $\Delta$ AUPRC |
|--------|--------|------------|-------------|----------------|
| ETTh1 â†’ ETTh2 | TimeX++ | 0.714 | 0.622 | -0.092 |
| | **TimeSAE** | **0.741** | **0.641** | **-0.100** |

> å°½ç®¡ç»å¯¹å€¼ç•¥æœ‰ä¸‹é™ï¼Œä½†TimeSAEåœ¨OODä¸‹ä»ä¿æŒæœ€ä½³æ€§èƒ½ï¼Œä¸”KL/MMDæ›´ä½ï¼Œè¯´æ˜å…¶ç”Ÿæˆçš„è§£é‡Šæ›´ç¬¦åˆåŸå§‹åˆ†å¸ƒã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### **(1) ç»„ä»¶æœ‰æ•ˆæ€§ï¼ˆå›¾5bï¼‰**
- **ç§»é™¤ $L_{cf}$ï¼ˆåäº‹å®æŸå¤±ï¼‰**ï¼š$F_x$ ä¸‹é™çº¦15%ï¼ŒéªŒè¯äº†åäº‹å®ç›‘ç£å¯¹å¿ å®æ€§çš„å…³é”®ä½œç”¨ã€‚
- **ç§»é™¤ $L_{cc}$ï¼ˆç»„åˆä¸€è‡´æ€§ï¼‰**ï¼šåœ¨OODè®¾ç½®ä¸‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œè¯´æ˜å…¶å¯¹æ³›åŒ–è‡³å…³é‡è¦ã€‚
- **å®Œæ•´ç›®æ ‡å‡½æ•°æ•ˆæœæœ€ä½³**ï¼Œè¯æ˜å„æ¨¡å—ååŒå¢ç›Šã€‚

#### **(2) æ¿€æ´»å‡½æ•°å¯¹æ¯”ï¼ˆå›¾6ï¼‰**
- **JumpReLU vs TopK**ï¼š
  - JumpReLU åœ¨ç›¸åŒ $L_0$ ç¨€ç–åº¦ä¸‹é‡å»ºè¯¯å·®æ›´ä½ã€‚
  - TopK å­˜åœ¨â€œæ­»æ¦‚å¿µâ€é—®é¢˜ï¼ˆéƒ¨åˆ†æ¦‚å¿µå§‹ç»ˆä¸æ¿€æ´»ï¼‰ï¼Œè€ŒJumpReLUæ¿€æ´»æ›´å‡è¡¡ã€‚
  - JumpReLU æ›´é€‚åº”æ•°æ®åŠ¨æ€ï¼Œå‡å°‘è¶…å‚æ•°æ•æ„Ÿæ€§ã€‚

#### **(3) è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼ˆå›¾14ï¼‰**
- **ä¸€è‡´æ€§æƒé‡ $\omega$**ï¼šé€‚å½“å¢å¤§å¯æå‡è§£é‡Šç¨³å®šæ€§ï¼Œå°¤å…¶å¯¹å¤æ‚æ¨¡å‹ï¼ˆå¦‚iTransformerï¼‰æ›´æœ‰æ•ˆã€‚
- **å­—å…¸å¤§å° $r$**ï¼šæœ€ä¼˜å€¼é›†ä¸­åœ¨1.5â€“1.7ä¹‹é—´ï¼Œè¿‡å¤§åè€Œé™ä½æ€§èƒ½ï¼ˆè¿‡æ‹Ÿåˆ/å†—ä½™ï¼‰ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. âœ… **TimeSAE èƒ½ç”Ÿæˆæ›´å¿ å®ã€æ›´é²æ£’çš„æ—¶é—´åºåˆ—è§£é‡Š**ï¼Œå°¤å…¶åœ¨åˆ†å¸ƒå¤–åœºæ™¯ä¸‹è¡¨ç°ä¼˜è¶Šã€‚
2. âœ… **åäº‹å®ç›‘ç£ + ç»„åˆä¸€è‡´æ€§** æ˜¯æå‡è§£é‡Šè´¨é‡å’Œæ³›åŒ–èƒ½åŠ›çš„å…³é”®æœºåˆ¶ã€‚
3. âœ… **JumpReLU æ¿€æ´»å‡½æ•°æœ‰æ•ˆç¼“è§£â€œæ­»æ¦‚å¿µâ€é—®é¢˜**ï¼Œä¼˜äºä¼ ç»Ÿçš„TopKç¨€ç–åŒ–ç­–ç•¥ã€‚
4. âœ… **SAEå¯ç”¨äºè‡ªåŠ¨å‘ç°æ—¶é—´åºåˆ—ä¸­çš„è¯­ä¹‰æ¦‚å¿µ**ï¼Œæ— éœ€äººå·¥æ ‡æ³¨å³å¯å®ç°é«˜è´¨é‡è§£é‡Šã€‚
5. âœ… åœ¨çœŸå®ä½“è‚²æ•°æ®åˆ†æï¼ˆEliteLJï¼‰ä¸­ï¼ŒTimeSAEæˆåŠŸè¯†åˆ«å‡ºèµ·è·³ã€è…¾ç©ºç­‰å…³é”®é˜¶æ®µï¼Œå…·å¤‡å®é™…åº”ç”¨æ½œåŠ›ã€‚

---

### **å±€é™æ€§**
1. **ä¾èµ–è¶³å¤Ÿå¤§çš„è®­ç»ƒæ•°æ®**ï¼šåœ¨å°æ ·æœ¬æˆ–ç¨€ç¼ºé¢†åŸŸå¯èƒ½éš¾ä»¥å……åˆ†å­¦ä¹ æ¦‚å¿µå­—å…¸ã€‚
2. **å¯¹è¶…å‚æ•°è¾ƒæ•æ„Ÿ**ï¼šå¦‚ç¨€ç–ç³»æ•°ã€å­—å…¸å¤§å°ç­‰éœ€ä»”ç»†è°ƒå‚ã€‚
3. **è®¡ç®—å¼€é”€ç›¸å¯¹è¾ƒé«˜**ï¼šè™½æ¨ç†å¿«ï¼Œä½†è®­ç»ƒæ—¶é—´è¾ƒé•¿ï¼ˆçº¦1â€“2å°æ—¶ï¼‰ï¼Œä¸é€‚åˆæä½èµ„æºåœºæ™¯ã€‚
4. **å°šæœªæ¢ç´¢ç™½ç›’è§£é‡Š**ï¼šç›®å‰ä»…é€‚ç”¨äºpost-hocé»‘ç›’è§£é‡Šï¼Œæœªæ¶‰åŠæ¨¡å‹å†…éƒ¨å±‚çš„å¯è§£é‡Šæ€§ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **æ„å»ºåŸºäºæ¦‚å¿µçš„ç™½ç›’æ¨¡å‹**ï¼šåˆ©ç”¨TimeSAEå‘ç°çš„æ¦‚å¿µè®¾è®¡ ante-hoc å¯è§£é‡Šæ¨¡å‹ã€‚
2. **è·¨æ¨¡æ€å¯è§£é‡Šæ€§**ï¼šæ‰©å±•è‡³è§†é¢‘ã€éŸ³é¢‘ç­‰å¤šæ¨¡æ€æ—¶é—´åºåˆ—ã€‚
3. **è‡ªåŠ¨åŒ–è¶…å‚æ•°é€‰æ‹©**ï¼šå¼•å…¥NASæˆ–å…ƒå­¦ä¹ å‡å°‘äººå·¥è°ƒå‚è´Ÿæ‹…ã€‚
4. **åœ¨çº¿/æµå¼è§£é‡Š**ï¼šé€‚é…å®æ—¶æ—¶é—´åºåˆ—æµçš„å¢é‡è§£é‡Šéœ€æ±‚ã€‚
5. **æ›´å¤šçœŸå®åº”ç”¨åœºæ™¯**ï¼šå¦‚é‡‘èé£æ§ã€åŒ»ç–—é¢„è­¦ç³»ç»Ÿçš„å¯è§£é‡Šéƒ¨ç½²ã€‚

---

> ğŸ”— **ä»£ç ä¸æ•°æ®å¼€æºåœ°å€**ï¼š[https://anonymous.4open.science/w/TimeSAE-571D/](https://anonymous.4open.science/w/TimeSAE-571D/)  
> ğŸ“¦ åŒ…å«å®Œæ•´å®ç°ã€é¢„å¤„ç†è„šæœ¬ã€é¢„è®­ç»ƒæ¨¡å‹ä¸ **EliteLJ æ•°æ®é›†**ã€‚

</details>

---

### 12. [Discrete Feynman-Kac Correctors](https://arxiv.org/abs/2601.10403)

**Authors**: Mohsin Hasan, Viktor Ohanesian, Artem Gazizov, Yoshua Bengio, Al\'an Aspuru-Guzik, Roberto Bondesan, Marta Skreta, Kirill Neklyudov  
**Category**: cs.LG  
**Published**: 2026-01-16  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.10403v1  

#### Abstract
Discrete diffusion models have recently emerged as a promising alternative to the autoregressive approach for generating discrete sequences. Sample generation via gradual denoising or demasking processes allows them to capture hierarchical non-sequential interdependencies in the data. These custom p...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Discrete Feynman-Kac Correctors è®ºæ–‡æ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç¦»æ•£æ‰©æ•£æ¨¡å‹ï¼ˆDiscrete Diffusion Modelsï¼‰åœ¨ç”Ÿæˆç¦»æ•£åºåˆ—ï¼ˆå¦‚æ–‡æœ¬ã€è›‹ç™½è´¨åºåˆ—ï¼‰æ–¹é¢å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä½†å…¶æ¨ç†è¿‡ç¨‹ç¼ºä¹å¯¹ç”Ÿæˆæ ·æœ¬åˆ†å¸ƒçš„çµæ´»æ§åˆ¶ã€‚ä¼ ç»Ÿæ–¹æ³•é€šå¸¸ä¾èµ–äºè®­ç»ƒæ—¶å›ºå®šçš„æ¡ä»¶æˆ–åå¤„ç†ç­–ç•¥ï¼Œéš¾ä»¥åœ¨æ¨ç†é˜¶æ®µåŠ¨æ€è°ƒæ•´ç”Ÿæˆåˆ†å¸ƒï¼Œä¾‹å¦‚è¿›è¡Œæ¸©åº¦é€€ç«ï¼ˆannealingï¼‰ã€å¤šæ¨¡å‹è”åˆé‡‡æ ·ï¼ˆproduct of expertsï¼‰æˆ–ç»“åˆå¤–éƒ¨å¥–åŠ±å‡½æ•°ã€‚

æ­¤å¤–ï¼Œç°æœ‰åŸºäº Sequential Monte Carlo (SMC) çš„æ¨ç†æ—¶é—´æ§åˆ¶æ–¹æ³•ä¸»è¦é’ˆå¯¹è¿ç»­ç©ºé—´æ‰©æ•£æ¨¡å‹ï¼ˆå¦‚ Fokker-Planck æ–¹ç¨‹ï¼‰ï¼Œæ— æ³•ç›´æ¥åº”ç”¨äºæè¿°ç¦»æ•£çŠ¶æ€ç©ºé—´çš„è¿ç»­æ—¶é—´é©¬å°”å¯å¤«é“¾ï¼ˆCTMCï¼‰ã€‚

### æå‡ºçš„æ–°æ–¹æ³•
æœ¬æ–‡æå‡ºäº† **Discrete Feynman-Kac Correctors (DFKC)**ï¼Œä¸€ä¸ªç”¨äºåœ¨æ¨ç†é˜¶æ®µæ§åˆ¶ç¦»æ•£æ©ç æ‰©æ•£æ¨¡å‹ï¼ˆmasked diffusion modelsï¼‰ç”Ÿæˆåˆ†å¸ƒçš„ç†è®ºæ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ä¿®æ”¹æ‰©æ•£è¿‡ç¨‹çš„åå‘é€Ÿç‡çŸ©é˜µï¼ˆreverse-time rate matrixï¼‰å’Œå¼•å…¥æƒé‡æ›´æ–°è§„åˆ™ï¼Œä½¿å¾— SMC ç®—æ³•èƒ½å¤Ÿä»ä»¥ä¸‹ç›®æ ‡åˆ†å¸ƒä¸­æ— ååœ°é‡‡æ ·ï¼š

- **æ¸©åº¦é€€ç«åˆ†å¸ƒ**ï¼ˆTemperature-annealed distributionï¼‰: $p_{\text{anneal}}(x) \propto p(x)^\beta$
- **å¤šä¸ªæ¨¡å‹è¾¹ç¼˜åˆ†å¸ƒçš„ä¹˜ç§¯**ï¼ˆProduct of marginalsï¼‰: $p_{\text{prod}}(x) \propto \prod_k p_k(x)$
- **å‡ ä½•å¹³å‡åˆ†å¸ƒ**ï¼ˆGeometric averageï¼‰
- **å¥–åŠ±å€¾æ–œåˆ†å¸ƒ**ï¼ˆReward-tilted distributionï¼‰: $p_{\text{reward}}(x) \propto p(x)\exp(\beta r(x))$

DFKC çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†ç›®æ ‡åˆ†å¸ƒçš„æ¼”åŒ–æ–¹ç¨‹é‡æ–°è¡¨è¿°ä¸ºå¸¦æƒé‡é¡¹çš„ Forward Kolmogorov Equation (FKE)ï¼Œå¹¶åˆ©ç”¨ Feynman-Kac å…¬å¼æ¨å¯¼å‡ºç›¸åº”çš„ä¿®æ­£é€Ÿç‡çŸ©é˜µå’Œæƒé‡æ›´æ–°å‡½æ•°ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ— éœ€å†è®­ç»ƒæˆ–å¾®è°ƒ**ï¼šDFKC æ˜¯ä¸€ä¸ªçº¯ç²¹çš„æ¨ç†æ—¶ï¼ˆinference-timeï¼‰æ¡†æ¶ï¼Œå¯ä»¥ç›´æ¥ä½œç”¨äºå·²è®­ç»ƒå¥½çš„ç¦»æ•£æ‰©æ•£æ¨¡å‹ï¼Œæ— éœ€é¢å¤–è®­ç»ƒæˆæœ¬ã€‚
- **ç†è®ºä¸¥è°¨ä¸”é€šç”¨**ï¼šæ¡†æ¶å»ºç«‹åœ¨ CTMC å’Œ Feynman-Kac å…¬å¼çš„åšå®æ•°å­¦åŸºç¡€ä¸Šï¼Œé€‚ç”¨äºæ‰€æœ‰åŸºäºæ©ç çš„ç¦»æ•£æ‰©æ•£æ¨¡å‹ã€‚
- **çµæ´»æ€§é«˜**ï¼šæ”¯æŒå¤šç§åˆ†å¸ƒå˜æ¢ï¼ŒåŒ…æ‹¬é€€ç«ã€å¤šæ¨¡å‹èåˆå’Œå¥–åŠ±å¼•å¯¼ï¼Œåº”ç”¨åœºæ™¯å¹¿æ³›ã€‚
- **é«˜æ•ˆå®ç°**ï¼šæ‰€éœ€çš„ä¿®æ­£é€Ÿç‡çŸ©é˜µå’Œæƒé‡å‡½æ•°ä»…ä¾èµ–äºåŸå§‹æ¨¡å‹æä¾›çš„æ¦‚ç‡æ¯”ï¼ˆå¦‚ $p(j)/p(m)$ï¼‰ï¼Œè¿™äº›å€¼åœ¨æ ‡å‡†æ¨ç†è¿‡ç¨‹ä¸­å·²ä½œä¸ºç½‘ç»œè¾“å‡ºçš„ä¸€éƒ¨åˆ†è¢«è®¡ç®—ï¼Œå› æ­¤ DFKC çš„è®¡ç®—å¼€é”€æå°ã€‚
- **æ¸è¿‘æ— å**ï¼šé€šè¿‡ SMC çš„é‡é‡‡æ ·æœºåˆ¶ï¼ŒDFKC èƒ½å¤Ÿæ¸è¿‘åœ°ä»ç›®æ ‡åˆ†å¸ƒä¸­ç”Ÿæˆæ— åæ ·æœ¬ï¼Œä¼˜äºè®¸å¤šäº§ç”Ÿæœ‰åä¼°è®¡çš„å¯å‘å¼æ–¹æ³•ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
1. **Ising æ¨¡å‹**ï¼šåœ¨ $16\times16$ çš„äºŒç»´æ™¶æ ¼ä¸Šï¼Œä½¿ç”¨ Swendsen-Wang ç®—æ³•ç”Ÿæˆé…ç½®æ•°æ®ï¼Œç”¨äºè®­ç»ƒç¦»æ•£æ‰©æ•£æ¨¡å‹ä»¥å­¦ä¹ ç»å°”å…¹æ›¼åˆ†å¸ƒ $p_\beta(\sigma) \propto e^{-\beta H(\sigma)}$ã€‚
2. **ç¼–ç¨‹ä»»åŠ¡æ•°æ®é›†**ï¼š
   - **HumanEval**ï¼šè¯„ä¼°ä»£ç ç”Ÿæˆèƒ½åŠ›ã€‚
   - **MBPP**ï¼ˆMostly Basic Python Problemsï¼‰ï¼šè¯„ä¼°è§£å†³åŸºæœ¬ç¼–ç¨‹é—®é¢˜çš„èƒ½åŠ›ã€‚
3. **åˆæˆçº¿æ€§å›å½’æ•°æ®é›†**ï¼šç”¨äºâ€œæ‘Šé”€å­¦ä¹ â€ï¼ˆamortized learningï¼‰ä»»åŠ¡ï¼Œç”Ÿæˆå½¢å¦‚ $y = \theta_1 x + \theta_0 + \epsilon$ çš„æ•°æ®ç‚¹ï¼Œå…¶ä¸­ $\epsilon \sim \mathcal{N}(0, 0.1^2)$ã€‚
4. **è›‹ç™½è´¨åºåˆ—ç”Ÿæˆ**ï¼š
   - ä½¿ç”¨ **DPLM-650M** ä½œä¸ºåŸºç¡€ç¦»æ•£æ‰©æ•£æ¨¡å‹ã€‚
   - å¥–åŠ±æ¨¡å‹ï¼š
     - **ESM2-650M**ï¼šæä¾›åºåˆ—ä¼¼ç„¶å¥–åŠ±ï¼ˆpseudo log-likelihoodï¼‰ã€‚
     - **Fine-tuned DPLM-650M**ï¼šé¢„æµ‹åºåˆ—çš„çƒ­ç¨³å®šæ€§ï¼ˆthermostabilityï¼‰ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **é€šç”¨æµç¨‹**ï¼šæ‰€æœ‰å®éªŒå‡éµå¾ª Algorithm 1ï¼Œä½¿ç”¨ SMC è¿›è¡Œå¸¦æƒé‡çš„é‡‡æ ·å’Œé‡é‡‡æ ·ã€‚
- **Ising æ¨¡å‹**ï¼š
  - **æŒ‡æ ‡**ï¼šèƒ½é‡å’Œç£åŒ–å¼ºåº¦åˆ†å¸ƒçš„ 2-Wasserstein è·ç¦»ï¼ˆEnergy-W2, Magnetization-W2ï¼‰ï¼Œä»¥åŠè‡ªæ—‹ç›¸å…³å‡½æ•°çš„å‡æ–¹è¯¯å·®ï¼ˆCorrelation-MSEï¼‰ã€‚
  - **å¯¹æ¯”**ï¼šä¸ç›´æ¥åœ¨ç›®æ ‡æ¸©åº¦è®­ç»ƒçš„ç¦»æ•£æ‰©æ•£æ¨¡å‹ï¼ˆDDMï¼‰å’Œ LEAPS æ–¹æ³•æ¯”è¾ƒã€‚
- **è¯­è¨€æ¨¡å‹ä»»åŠ¡**ï¼š
  - **ä»£ç ç”Ÿæˆ**ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„ **LLaDA-8B-Instruct** æ¨¡å‹ï¼Œè¯„ä¼°ä¸åŒé‡‡æ ·æ–¹æ³•ä¸‹çš„ä»»åŠ¡å‡†ç¡®ç‡ã€‚
  - **æ‘Šé”€å­¦ä¹ **ï¼šè¯„ä¼°é¢„æµ‹å‚æ•°ä¸çœŸå®å‚æ•°ä¹‹é—´çš„å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ã€‚
- **è›‹ç™½è´¨åºåˆ—ç”Ÿæˆ**ï¼š
  - **æŒ‡æ ‡**ï¼š
    - **Reward**ï¼šESM2 å¯¹æ•°ä¼¼ç„¶æˆ–é¢„æµ‹çš„çƒ­ç¨³å®šæ€§ã€‚
    - **å¤šæ ·æ€§**ï¼ˆDiversityï¼‰ï¼šåºåˆ—å¤šæ ·æ€§ï¼ˆSeq. div.ï¼‰å’Œæœ€å¤§ç°‡æ¯”ä¾‹ï¼ˆMax. clusterï¼‰ã€‚
    - **ç»“æ„ç½®ä¿¡åº¦**ï¼ˆStructural confidenceï¼‰ï¼špLDDTã€pTM åˆ†æ•°åŠ pLDDT > 0.7 çš„æ¯”ä¾‹ã€‚
    - **æ–°é¢–æ€§**ï¼ˆNoveltyï¼‰ï¼šä¸ PDB æ•°æ®åº“çš„æœ€å¤§ TM-score åŠä½äº 0.5 çš„æ¯”ä¾‹ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Ising æ¨¡å‹**ï¼šDDMï¼ˆç›´æ¥è®­ç»ƒï¼‰ã€LEAPSã€‚
- **ä»£ç ç”Ÿæˆ**ï¼šBase Modelï¼ˆæ ‡å‡†é‡‡æ ·ï¼‰ã€Base Model Argmaxã€Naive Annealingï¼ˆæ— é‡é‡‡æ ·çš„é€€ç«ï¼‰ã€‚
- **è›‹ç™½è´¨ç”Ÿæˆ**ï¼š
  - **DG-Exact** (Nisonoff et al., 2024)ï¼šç­‰ä»·äº DFKC åœ¨å•æ ·æœ¬ï¼ˆæ— é‡é‡‡æ ·ï¼‰çš„æƒ…å†µã€‚
  - **FK Steering** (Singhal et al., 2025)ï¼šå¦ä¸€ç§åŸºäº SMC çš„æŒ‡å¯¼æ–¹æ³•ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”
#### Ising æ¨¡å‹é€€ç«
- åœ¨ $\beta=0.4$ æ—¶ï¼ŒDFKC çš„ Energy-W2 ä¸º `14.24Â±3.11`ï¼Œæ˜¾è‘—ä¼˜äºç›´æ¥è®­ç»ƒçš„ DDM (`69.38Â±4.25`)ã€‚
- DFKC èƒ½å¤Ÿåœ¨è®­ç»ƒæ¸©åº¦ ($\beta=0.3$) ä¹‹å¤–æœ‰æ•ˆé‡‡æ ·ï¼Œç”šè‡³è¶…è¿‡ä¸´ç•Œæ¸©åº¦ $\beta_{\text{crit}} \approx 0.4407$ï¼Œè€Œ LEAPS ç­‰æ–¹æ³•åœ¨æ­¤èŒƒå›´å¤–è¡¨ç°ä¸ä½³ã€‚

#### ä»£ç ç”Ÿæˆ
- åœ¨ **HumanEval** ä¸Šï¼ŒDFKC è¾¾åˆ° `33.78Â±0.97%` çš„å‡†ç¡®ç‡ï¼Œä¼˜äº Naive Annealing (`30.49Â±0.49%`) å’Œ Base Model Argmax (`30.74Â±0.76%`)ã€‚
- åœ¨ **MBPP** ä¸Šï¼ŒDFKC è¾¾åˆ° `31.00Â±0.40%`ï¼ŒåŒæ ·ä¼˜äºå…¶ä»–åŸºçº¿ã€‚
- ç»“æœè¡¨æ˜ï¼ŒDFKC ä¸­çš„ SMC é‡é‡‡æ ·æœºåˆ¶å¯¹äºæå‡æ€§èƒ½è‡³å…³é‡è¦ã€‚

#### æ‘Šé”€å­¦ä¹ 
- éšç€æç¤ºé•¿åº¦ï¼ˆæ•°æ®é‡ï¼‰å¢åŠ ï¼Œä¼ ç»Ÿçš„è”åˆæç¤ºï¼ˆjoint promptingï¼‰æ€§èƒ½æ€¥å‰§ä¸‹é™ã€‚
- DFKC çš„â€œä¹˜ç§¯â€å½¢å¼ï¼ˆproductï¼‰èƒ½ç¨³å®šä¿æŒé«˜æ€§èƒ½ï¼Œå¹¶ä¸”ä½¿ç”¨æ›´å¤š SMC æ ·æœ¬å¯ä»¥è¿›ä¸€æ­¥æå‡æ•ˆæœã€‚

#### è›‹ç™½è´¨åºåˆ—ç”Ÿæˆ
- **æ— æ¡ä»¶ç”Ÿæˆï¼ˆESM2 ä¼¼ç„¶å¥–åŠ±ï¼‰**ï¼š
  - DFKC çš„å¹³å‡å¥–åŠ±ä¸º `-1.6551Â±0.0952`ï¼Œæ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ (`-4.3266Â±0.3190`) å’Œ DG-Exact (`-1.8831Â±0.0979`)ã€‚
  - ä½¿ç”¨å¤šä¸ª SMC æ ·æœ¬çš„ DFKC æ˜æ˜¾ä¼˜äºå•æ ·æœ¬çš„ DG-Exactï¼Œè¯æ˜äº†é‡é‡‡æ ·çš„æœ‰æ•ˆæ€§ã€‚
- **çƒ­ç¨³å®šæ€§ä»»åŠ¡**ï¼š
  - DFKC åŒæ ·å–å¾—äº†æœ€ä½³çš„å¥–åŠ±åˆ†æ•° (`-0.5316Â±0.0153`)ã€‚
  - åœ¨ç»“æ„ç½®ä¿¡åº¦å’Œæ–°é¢–æ€§ç­‰æŒ‡æ ‡ä¸Šï¼ŒDFKC ä¸åŸºçº¿æ¨¡å‹ç›¸å½“ï¼Œè¡¨æ˜å…¶åœ¨ä¼˜åŒ–å¥–åŠ±çš„åŒæ—¶æœªç‰ºç‰²ç”Ÿæˆè´¨é‡ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **SMC æ ·æœ¬æ•°é‡**ï¼šåœ¨æ‘Šé”€å­¦ä¹ å’Œè›‹ç™½è´¨ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œå¢åŠ  SMC æ ·æœ¬æ•°ï¼ˆå¦‚ä» 1 åˆ° 5 æˆ– 8ï¼‰èƒ½æŒç»­æå‡æ€§èƒ½ï¼Œä½†æ”¶ç›Šå­˜åœ¨é¥±å’Œç‚¹ã€‚
- **é‡é‡‡æ ·çš„é‡è¦æ€§**ï¼šå°† DFKC ä¸â€œNaive Annealingâ€æˆ–â€œDG-Exactâ€å¯¹æ¯”ï¼Œæ˜ç¡®æ˜¾ç¤ºå‡º SMC é‡é‡‡æ ·æœºåˆ¶å¯¹äºè·å¾—é«˜è´¨é‡æ ·æœ¬çš„å…³é”®ä½œç”¨ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **DFKC æ˜¯ä¸€ä¸ªå¼ºå¤§ä¸”é€šç”¨çš„æ¨ç†æ—¶æ§åˆ¶æ¡†æ¶**ï¼šå®ƒæˆåŠŸåœ°å°† Feynman-Kac Correctors çš„æ€æƒ³æ‰©å±•åˆ°äº†ç¦»æ•£æ‰©æ•£æ¨¡å‹é¢†åŸŸï¼Œå¡«è¡¥äº†ç†è®ºç©ºç™½ã€‚
2. **æ— éœ€è®­ç»ƒå³å¯å®ç°åˆ†å¸ƒæ“æ§**ï¼šDFKC è¯æ˜äº†é€šè¿‡ç®€å•çš„æ•°å­¦å˜æ¢å’Œ SMC é‡é‡‡æ ·ï¼Œå°±èƒ½åœ¨ä¸æ”¹å˜æ¨¡å‹å‚æ•°çš„æƒ…å†µä¸‹ï¼Œçµæ´»åœ°æ§åˆ¶ç”Ÿæˆåˆ†å¸ƒã€‚
3. **é‡é‡‡æ ·æœºåˆ¶è‡³å…³é‡è¦**ï¼šå®éªŒä¸€è‡´è¡¨æ˜ï¼ŒDFKC ä¸­çš„ SMC é‡é‡‡æ ·æ­¥éª¤æ˜¯å…¶æ€§èƒ½è¶…è¶Šç®€å•å¯å‘å¼æ–¹æ³•ï¼ˆå¦‚ Naive Annealing, DG-Exactï¼‰çš„æ ¸å¿ƒåŸå› ã€‚
4. **åº”ç”¨å¹¿æ³›ä¸”æœ‰æ•ˆ**ï¼šDFKC åœ¨ç‰©ç†ç³»ç»Ÿé‡‡æ ·ï¼ˆIsingï¼‰ã€ä»£ç ç”Ÿæˆã€å‚æ•°æ¨æ–­å’Œè›‹ç™½è´¨è®¾è®¡ç­‰å¤šä¸ªæˆªç„¶ä¸åŒçš„ä»»åŠ¡ä¸Šéƒ½å±•ç°äº†å“è¶Šçš„æ€§èƒ½ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **è®¡ç®—å¼€é”€**ï¼šè™½ç„¶å•æ¬¡å‰å‘ä¼ æ’­é«˜æ•ˆï¼Œä½† SMC éœ€è¦ç»´æŠ¤å¤šä¸ªç²’å­ï¼ˆparticlesï¼‰ï¼Œå¢åŠ äº†å†…å­˜å’Œè®¡ç®—è´Ÿæ‹…ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¤§é‡æ ·æœ¬æ—¶ã€‚
- **å¥–åŠ±å‡½æ•°è¯„ä¼°æˆæœ¬**ï¼šåœ¨å¥–åŠ±å¼•å¯¼åœºæ™¯ä¸‹ï¼Œè®¡ç®—æ‰€æœ‰å¯èƒ½è½¬ç§»çš„å¥–åŠ±å€¼å¯èƒ½éå¸¸æ˜‚è´µï¼Œå°½ç®¡æ–‡ä¸­æå‡ºäº†ä¸€äº›è¿‘ä¼¼ç­–ç•¥ã€‚
- **ç†è®ºæ”¶æ•›æ€§**ï¼šè®ºæ–‡æä¾›äº†æ¡†æ¶çš„ç†è®ºæ­£ç¡®æ€§ï¼Œä½†å¯¹äºæœ‰é™ç²’å­æ•°ä¸‹çš„æ”¶æ•›é€Ÿåº¦å’Œåå·®åˆ†æå°šä¸å……åˆ†ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´é«˜æ•ˆçš„å¥–åŠ±è¯„ä¼°ç­–ç•¥ï¼Œä¾‹å¦‚åˆ©ç”¨å¥–åŠ±å·®å¼‚è€Œéç»å¯¹å€¼ã€‚
- å°† DFKC æ¡†æ¶æ‰©å±•åˆ°è¿ç»­-ç¦»æ•£æ··åˆæ¨¡å‹ã€‚
- ç ”ç©¶å¦‚ä½•å°† DFKC ä¸å¥–åŠ±å¾®è°ƒï¼ˆreward fine-tuningï¼‰ç­‰è®­ç»ƒé˜¶æ®µçš„æ–¹æ³•ç›¸ç»“åˆï¼Œä»¥è·å¾—æ›´å¼ºçš„æ§åˆ¶èƒ½åŠ›ã€‚
- è¿›ä¸€æ­¥ç ”ç©¶å’Œé‡åŒ– SMC ç²’å­æ•°ä¸ç”Ÿæˆè´¨é‡ä¹‹é—´çš„æƒè¡¡å…³ç³»ã€‚

</details>

---

### 13. [CS-GBA: A Critical Sample-based Gradient-guided Backdoor Attack for Offline Reinforcement Learning](https://arxiv.org/abs/2601.10407)

**Authors**: Yuanjie Zhao, Junnan Qiu, Yue Ding, Jie Li  
**Category**: cs.LG  
**Published**: 2026-01-16  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.10407v1  

#### Abstract
Offline Reinforcement Learning (RL) enables policy optimization from static datasets but is inherently vulnerable to backdoor attacks. Existing attack strategies typically struggle against safety-constrained algorithms (e.g., CQL) due to inefficient random poisoning and the use of easily detectable ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šCS-GBA: A Critical Sample-based Gradient-guided Backdoor Attack for Offline Reinforcement Learning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
Offline Reinforcement Learningï¼ˆOffline RLï¼‰ä¾èµ–é™æ€æ•°æ®é›†è¿›è¡Œç­–ç•¥å­¦ä¹ ï¼Œåœ¨å®é™…åº”ç”¨ä¸­å¸¸é¢ä¸´æ¥è‡ªç¬¬ä¸‰æ–¹æˆ–ä¼—åŒ…æ•°æ®æºçš„å®‰å…¨å¨èƒã€‚ç°æœ‰çš„**Backdoor Attack**ï¼ˆåé—¨æ”»å‡»ï¼‰æ–¹æ³•åœ¨é¢å¯¹å…·æœ‰ä¿å®ˆæœºåˆ¶ï¼ˆconservatism mechanismsï¼‰çš„å…ˆè¿›ç®—æ³•ï¼ˆå¦‚ CQLã€IQLã€BCQï¼‰æ—¶æ•ˆæœæœ‰é™ï¼Œä¸»è¦åŸå› æœ‰ä¸¤ç‚¹ï¼š
- **æ•ˆç‡ä½ä¸‹**ï¼šä¼ ç»ŸéšæœºæŠ•æ¯’ç­–ç•¥å°†æ”»å‡»é¢„ç®—æµªè´¹åœ¨å¯¹ä»·å€¼å‡½æ•°å½±å“è¾ƒå°çš„æ ·æœ¬ä¸Šï¼›
- **æ˜“è¢«æ£€æµ‹**ï¼šåŸºäºæç«¯å€¼æˆ– Out-of-Distributionï¼ˆOODï¼‰è§¦å‘å™¨çš„æ–¹æ³•å®¹æ˜“è¢«ä¿å®ˆæ­£åˆ™é¡¹ï¼ˆå¦‚ CQL çš„ Q å€¼æƒ©ç½šï¼‰è¯†åˆ«å¹¶æŠ‘åˆ¶ã€‚

å› æ­¤ï¼Œå¦‚ä½•åœ¨**ä½é¢„ç®—çº¦æŸä¸‹å®ç°é«˜éšè”½æ€§å’Œå¼ºç ´åæ€§**çš„åé—¨æ”»å‡»ï¼Œæ˜¯å½“å‰ Offline RL å®‰å…¨ç ”ç©¶ä¸­çš„å…³é”®æŒ‘æˆ˜ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šCS-GBA
æœ¬æ–‡æå‡º **CS-GBA**ï¼ˆCritical Sample-based Gradient-guided Backdoor Attackï¼‰ï¼Œä¸€ç§é¢å‘ Offline RL çš„é«˜æ•ˆä¸”éšè”½çš„åé—¨æ”»å‡»æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ä»¥ä¸‹ä¸‰éƒ¨åˆ†ï¼š

#### ï¼ˆ1ï¼‰åŸºäº TD Error çš„ Critical Sample Selectionï¼ˆå…³é”®æ ·æœ¬é€‰æ‹©ï¼‰
- **ç†è®ºä¾æ®**ï¼šTemporal Differenceï¼ˆTDï¼‰è¯¯å·®å¤§çš„æ ·æœ¬å¯¹ä»·å€¼å‡½æ•°æ›´æ–°è´¡çŒ®æ›´å¤§ï¼ˆPrioritized Experience Replay å¯å‘ï¼‰ã€‚
- **æ–¹æ³•**ï¼šé¢„è®­ç»ƒä¸€ä¸ªä»£ç† Q ç½‘ç»œï¼Œåœ¨å¹²å‡€æ•°æ®é›†ä¸Šè®¡ç®—æ¯ä¸ª transition çš„ |TD error|ï¼Œé€‰å–è¯¯å·®æœ€é«˜çš„å‰ 5% æ ·æœ¬ä½œä¸ºâ€œå…³é”®æ ·æœ¬â€è¿›è¡ŒæŠ•æ¯’ã€‚
- **ä¼˜åŠ¿**ï¼šæ˜¾è‘—æå‡æ”»å‡»æ•ˆç‡ï¼Œåœ¨ä»… 5% æŠ•æ¯’é¢„ç®—ä¸‹å³å¯å®ç°æœ‰æ•ˆæ”»å‡»ã€‚

#### ï¼ˆ2ï¼‰Correlation-Breaking Triggerï¼ˆæ‰“ç ´ç›¸å…³æ€§çš„è§¦å‘å™¨ï¼‰
- **è®¾è®¡åŠ¨æœº**ï¼šé¿å…ä½¿ç”¨ OOD è§¦å‘æ¨¡å¼ï¼Œé˜²æ­¢è¢«ä¿å®ˆç®—æ³•è¿‡æ»¤ã€‚
- **å®ç°æ–¹å¼**ï¼š
  - åˆ†æçŠ¶æ€ç‰¹å¾é—´çš„ Pearson ç›¸å…³çŸ©é˜µï¼Œé€‰æ‹©ä¸€ä¸ªä¸å…¶ä»–ç»´åº¦é«˜åº¦ç›¸å…³çš„ç‰¹å¾ $k$ï¼›
  - å°†è¯¥ç‰¹å¾å›ºå®šä¸ºå…¶åœ¨æ•´ä¸ªæ•°æ®é›†ä¸­ç¬¬ 95 ç™¾åˆ†ä½çš„å€¼ $v_{95\%}$ï¼Œè€Œä¿æŒå…¶ä»–ç›¸å…³ç‰¹å¾ä¸å˜ã€‚
- **æ•ˆæœ**ï¼šå•ä¸ªç‰¹å¾ä»åœ¨åˆæ³•èŒƒå›´å†…ï¼ˆè¾¹é™…åˆ†å¸ƒåˆè§„ï¼‰ï¼Œä½†ä¸å…¶ä½™ç‰¹å¾å½¢æˆâ€œä¸Šä¸‹æ–‡å†²çªâ€ï¼Œè½å…¥è”åˆåˆ†å¸ƒçš„ä½å¯†åº¦åŒºåŸŸï¼Œä»è€Œå®ç°**ç»Ÿè®¡éšè”½æ€§ä¸é€»è¾‘å¯åŒºåˆ†æ€§**çš„å¹³è¡¡ã€‚

#### ï¼ˆ3ï¼‰Gradient-Guided Action Generationï¼ˆæ¢¯åº¦å¼•å¯¼çš„åŠ¨ä½œç”Ÿæˆï¼‰
- **æ›¿ä»£ä¼ ç»Ÿæ ‡ç­¾ç¿»è½¬**ï¼šä¸å†ç®€å•åœ°åè½¬åŠ¨ä½œæˆ–èµ‹äºˆæœ€å¤§å¥–åŠ±ã€‚
- **æ–¹æ³•**ï¼š
  - åˆ©ç”¨é¢„è®­ç»ƒ Q ç½‘ç»œçš„æ¢¯åº¦ä¿¡æ¯ï¼Œä»åŸå§‹åŠ¨ä½œå‡ºå‘ï¼Œé€šè¿‡æŠ•å½±æ¢¯åº¦ä¸‹é™ï¼ˆProjected GDï¼‰æœç´¢ä½¿ $Q(s,a)$ æœ€å°åŒ–çš„å¯¹æŠ—åŠ¨ä½œï¼›
  - é™åˆ¶æ‰°åŠ¨å¹…åº¦ä»¥ç¡®ä¿æ–°åŠ¨ä½œä»å¤„äºè¡Œä¸ºç­–ç•¥æ”¯æŒåŸŸå†…ï¼ˆin-manifoldï¼‰ã€‚
- **æœ€ç»ˆæ„é€ **ï¼š$(s_{\text{trigger}}, a_{\text{worst}}, r_{\text{max}}, s')$ï¼Œå³â€œæœ€ååŠ¨ä½œ + é«˜å¥–åŠ±â€ç»„åˆï¼Œè¯±å¯¼ç­–ç•¥å­¦ä¹ é”™è¯¯æ˜ å°„ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ BAFFLEã€BadRLï¼‰ | CS-GBA |
|------|-------------------------------|--------|
| **æ ·æœ¬é€‰æ‹©** | éšæœºæˆ–åŸºäºé¢‘ç‡å¯å‘å¼ | åŸºäº TD error çš„å…³é”®æ ·æœ¬ä¼˜å…ˆçº§æ’åº |
| **è§¦å‘å™¨è®¾è®¡** | ä¸­ä½æ•°æ‰°åŠ¨ã€è§†è§‰å™ªå£°ç­‰ OOD æ¨¡å¼ | åˆ©ç”¨ 95th percentile æ‰“ç ´ç‰¹å¾ç›¸å…³æ€§ï¼Œä¿æŒ in-distribution |
| **æ¶æ„åŠ¨ä½œç”Ÿæˆ** | åŠ¨ä½œåè½¬ã€éšæœºæ›¿æ¢ | æ¢¯åº¦å¼•å¯¼æœç´¢æœ€å·® in-manifold åŠ¨ä½œ |
| **æ”»å‡»é¢„ç®—** | é€šå¸¸éœ€ 10% æˆ–æ›´é«˜ | ä»…éœ€ **5%** å³å¯å–å¾—æ›´å¼ºæ”»å‡»æ•ˆæœ |
| **é˜²å¾¡ç©¿é€èƒ½åŠ›** | æ˜“è¢« CQL/IQL/BCQ æŠ‘åˆ¶ | æˆåŠŸç»•è¿‡ OOD æ£€æµ‹æœºåˆ¶ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
åœ¨ **D4RL benchmark** ä¸Šè¿›è¡Œå®éªŒï¼Œé€‰ç”¨ä¸‰ä¸ª MuJoCo è¿ç»­æ§åˆ¶ä»»åŠ¡çš„ medium è´¨é‡æ•°æ®é›†ï¼š
- `walker2d-medium-v0`
- `halfcheetah-medium-v0`
- `hopper-medium-v0`

è¿™äº›æ•°æ®é›†åŒ…å«ä¸“å®¶ä¸æ¬¡ä¼˜è½¨è¿¹æ··åˆï¼Œæ›´è´´è¿‘çœŸå®åœºæ™¯ï¼Œé€‚åˆè¯„ä¼°åé—¨æ”»å‡»é²æ£’æ€§ã€‚

---

### å®éªŒè®¾ç½®

#### æ”»å‡»é…ç½®
- **æŠ•æ¯’é¢„ç®—**ï¼šCS-GBA ä½¿ç”¨ **5%**ï¼Œå¯¹æ¯”åŸºçº¿ BAFFLE ä½¿ç”¨ 10%
- **é»‘ç›’æ”»å‡»å‡è®¾**ï¼šæ”»å‡»è€…å¯è®¿é—®æ•°æ®é›†å¹¶ä¿®æ”¹çŠ¶æ€ã€åŠ¨ä½œã€å¥–åŠ±ï¼Œä½†æ— æ³•å¹²é¢„è®­ç»ƒè¿‡ç¨‹æˆ–ç¯å¢ƒåŠ¨æ€

#### å—å®³æ¨¡å‹ï¼ˆVictim Algorithmsï¼‰
æµ‹è¯•ä¸‰ç§ä¸»æµä¿å®ˆå‹ Offline RL ç®—æ³•ï¼š
- **CQL**ï¼ˆConservative Q-Learningï¼‰ï¼šé€šè¿‡ Q å€¼æ­£åˆ™æŠ‘åˆ¶ OOD åŠ¨ä½œ
- **IQL**ï¼ˆImplicit Q-Learningï¼‰ï¼šåŸºäº expectile å›å½’é¿å…æŸ¥è¯¢æœªè§åŠ¨ä½œ
- **BCQ**ï¼ˆBatch-Constrained Q-learningï¼‰ï¼šä½¿ç”¨ç”Ÿæˆæ¨¡å‹çº¦æŸåŠ¨ä½œç©ºé—´

#### åŸºçº¿æ–¹æ³•
- **BAFFLE**ï¼ˆGong et al., 2024ï¼‰ï¼šå½“å‰æœ€å…ˆè¿›çš„ Offline RL åé—¨æ”»å‡»æ–¹æ³•
  - éšæœºæŠ•æ¯’ï¼ˆ10% budgetï¼‰
  - ä¸­ä½æ•°è§¦å‘å™¨
  - åè½¬æŸå¤±åŠ¨ä½œç”Ÿæˆ

#### è§¦å‘æ¿€æ´»æ¨¡å¼ï¼ˆTesting Phaseï¼‰
ä¸¤ç§æµ‹è¯•æ¨¡å¼ç”¨äºè¯„ä¼°æ”»å‡»é²æ£’æ€§ï¼š
- **Distributed Modeï¼ˆç¨€ç–æ”»å‡»ï¼‰**ï¼šæ¯ N æ­¥è§¦å‘ä¸€æ¬¡ï¼ˆN âˆˆ {10, 20, 50}ï¼‰
- **Consecutive Modeï¼ˆçªå‘æ”»å‡»ï¼‰**ï¼šè¿ç»­è§¦å‘ L æ­¥ï¼ˆL âˆˆ {5, 10, 20}ï¼‰

#### è¯„ä¼°æŒ‡æ ‡
- **Clean Reward â†‘**ï¼šæ— è§¦å‘æ—¶çš„å¹³å‡ç´¯ç§¯å¥–åŠ± â†’ è¡¡é‡**éšè”½æ€§**
- **Attack Reward â†“**ï¼šè§¦å‘å­˜åœ¨æ—¶çš„å¹³å‡ç´¯ç§¯å¥–åŠ± â†’ è¡¡é‡**æ”»å‡»æœ‰æ•ˆæ€§**

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ‘˜è‡ª Tables 1â€“3ï¼‰

#### âœ… Walker2d-medium + CQLï¼ˆDistributed-10ï¼‰
| æ–¹æ³• | Clean Reward | Attack Reward |
|------|--------------|-------------|
| BAFFLE (10%) | 3402 | 1336 |
| **CS-GBA (5%)** | **3430** | **452** |

ğŸ‘‰ åœ¨æ›´ä½é¢„ç®—ä¸‹ï¼ŒCS-GBA å°†æ”»å‡»å¥–åŠ±é™ä½è¶…è¿‡ **66%**ï¼ŒåŒæ—¶ä¿æŒæ›´é«˜æ¸…æ´æ€§èƒ½ã€‚

#### âœ… HalfCheetah-medium + IQLï¼ˆDistributed-10ï¼‰
| æ–¹æ³• | Clean Reward | Attack Reward |
|------|--------------|-------------|
| BAFFLE | 4641 | 3367 |
| **CS-GBA** | **4672** | **2395** |

ğŸ‘‰ æ”»å‡»æ€§èƒ½æå‡è¿‘ 30%ï¼Œä¸”æ›´å…·éšè”½æ€§ã€‚

#### âœ… Hopper-medium + CQLï¼ˆDistributed-10ï¼‰
| æ–¹æ³• | Clean Reward | Attack Reward |
|------|--------------|-------------|
| BAFFLE | **951**ï¼ˆå´©æºƒï¼‰ | 29 |
| **CS-GBA** | **1941**ï¼ˆæ­£å¸¸æ°´å¹³ï¼‰ | **33** |

ğŸ‘‰ BAFFLE å¯¼è‡´æ¨¡å‹å´©æºƒï¼ˆclean æ€§èƒ½æš´è·Œï¼‰ï¼Œå±äºâ€œè¿‡åº¦ç ´åâ€ï¼›è€Œ CS-GBA å®ç°ç²¾å‡†åé—¨æ¤å…¥ï¼Œå…¼å…·é«˜éšè”½æ€§ä¸å¼ºç ´ååŠ›ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”æ€»ç»“
- åœ¨æ‰€æœ‰ä»»åŠ¡å’Œ victim ç®—æ³•ä¸Šï¼Œ**CS-GBA åœ¨ 5% é¢„ç®—ä¸‹å…¨é¢è¶…è¶Š BAFFLEï¼ˆ10% é¢„ç®—ï¼‰**
- ç‰¹åˆ«æ˜¯åœ¨æœ€éš¾é˜²å¾¡çš„ CQL å’Œæœ€ä¸ç¨³å®šç¯å¢ƒ Hopper ä¸Šï¼ŒCS-GBA å±•ç°å‡ºå‹å€’æ€§ä¼˜åŠ¿
- å¯¹ IQL å’Œ BCQ ä¹Ÿå®ç°äº†æ¥è¿‘éšæœºç­–ç•¥çš„æ€§èƒ½å‹åˆ¶ï¼ˆå¦‚ IQL on Walker2d: 141ï¼‰

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰æ ·æœ¬é€‰æ‹©ç­–ç•¥ï¼ˆRandom vs TD-Prioritizedï¼‰
| ç¯å¢ƒ | æ–¹æ³• | Attack Reward (Dist-10) |
|------|------|--------------------------|
| Walker2d | Random | 2972 |
| | **TD-Prioritized** | **452** |
| Hopper | Random | 1031 |
| | **TD-Prioritized** | **33** |

âœ… éªŒè¯äº†é«˜ TD error æ ·æœ¬æ˜¯â€œæ¢¯åº¦æ”¾å¤§å™¨â€ï¼Œç²¾å‡†å®šä½å¯æå¤§å¢å¼ºæ”»å‡»æ•ˆåŠ›ã€‚

#### ï¼ˆ2ï¼‰è§¦å‘å™¨è®¾è®¡ï¼ˆMedian vs Correlation-Breakingï¼‰
| ç¯å¢ƒ | æ–¹æ³• | Clean Reward | Attack Reward |
|------|------|---------------|----------------|
| Hopper | Median Trigger | 978ï¼ˆå´©æºƒï¼‰ | 32 |
| | **Correlation-Breaking** | **1941** | **33** |

âœ… Median å€¼ä½äºé«˜å¯†åº¦åŒºï¼Œå¯¼è‡´è¯¯è§¦å‘ï¼›è€Œ 95th percentile æ›´å…·åŒºåˆ†åº¦ä¸”ä¸å¹²æ‰°æ­£å¸¸æ¨ç†ã€‚

#### ï¼ˆ3ï¼‰åŠ¨ä½œç”Ÿæˆæœºåˆ¶ï¼ˆInverted Loss vs Gradient-Guidedï¼‰
| ç¯å¢ƒ | æ–¹æ³• | Clean Reward | Attack Reward |
|------|------|---------------|----------------|
| Walker2d | Inverted Loss | 3284 | 994 |
| | **Gradient-Guided** | **3430** | **452** |

âœ… æ¢¯åº¦å¼•å¯¼æ–¹æ³•èƒ½åœ¨ä¸å¼•èµ· OOD æƒ©ç½šçš„å‰æä¸‹æ‰¾åˆ°æœ€å…·ç ´åæ€§çš„ in-manifold åŠ¨ä½œã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Quality Over Quantity**ï¼šæ”»å‡»æˆåŠŸçš„å…³é”®ä¸åœ¨äºæŠ•æ¯’æ•°é‡ï¼Œè€Œåœ¨äº**ç²¾å‡†å®šä½é«˜å½±å“åŠ›æ ·æœ¬**ï¼ˆtop 5% TD error transitionsï¼‰ã€‚
2. **Conservative Defenses Are Fragile**ï¼šå°½ç®¡ CQL/IQL/BCQ èƒ½æœ‰æ•ˆæŠµå¾¡éšæœºå™ªå£°ï¼Œä½†åœ¨ç»“æ„æ€§ä¼˜åŒ–æ”»å‡»é¢å‰ä¾ç„¶è„†å¼±ã€‚
3. **Stealthiness and Effectiveness Can Coexist**ï¼šé€šè¿‡ correlation-breaking trigger å’Œ gradient-guided actionï¼Œå¯åœ¨ç»´æŒ clean performance çš„åŒæ—¶å®ç°è‡´å‘½æ”»å‡»ã€‚
4. **æœ€ä¼˜æ”»å‡»çª—å£å­˜åœ¨**ï¼šæ•æ„Ÿæ€§åˆ†æè¡¨æ˜ï¼Œ**Top 0â€“5% TD error æ ·æœ¬ + 5% é¢„ç®—**æ„æˆæœ€ä½³æƒè¡¡ç‚¹ï¼›ç›²ç›®å¢åŠ é¢„ç®—ä¼šå¯¼è‡´æ¨¡å‹å´©æºƒï¼Œç ´åéšè”½æ€§ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é¢„è®­ç»ƒä»£ç†æ¨¡å‹**ï¼šéœ€è¦å…ˆåœ¨ä¸€ä¸ªå¹²å‡€å‰¯æœ¬ä¸Šè®­ç»ƒ Q ç½‘ç»œæ¥ä¼°è®¡ TD errorï¼Œå¯èƒ½å¢åŠ æ”»å‡»æˆæœ¬ã€‚
- **ç‰¹å¾ç›¸å…³æ€§å‡è®¾**ï¼šcorrelation-breaking trigger ä¾èµ–äºçŠ¶æ€ç‰¹å¾é—´å­˜åœ¨è¾ƒå¼ºçº¿æ€§å…³ç³»ï¼Œè‹¥ç‰¹å¾ç‹¬ç«‹åˆ™éš¾ä»¥ç”Ÿæ•ˆã€‚
- **ç™½ç›’ç‰¹å¾ç»Ÿè®¡éœ€æ±‚**ï¼šéœ€è·å–å…¨å±€æ•°æ®åˆ†å¸ƒï¼ˆå¦‚ 95th percentileï¼‰ï¼Œåœ¨å®Œå…¨é»‘ç›’åœºæ™¯ä¸‹å¯èƒ½å—é™ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ— éœ€ä»£ç†æ¨¡å‹çš„åœ¨çº¿ TD error ä¼°è®¡æ–¹æ³•ï¼Œé™ä½æ”»å‡»é—¨æ§›ï¼›
- è®¾è®¡é€‚ç”¨äºé«˜ç»´å›¾åƒè¾“å…¥çš„éšå¼ correlation-breaking è§¦å‘æœºåˆ¶ï¼›
- å¼€å‘é’ˆå¯¹ CS-GBA çš„æ–°å‹é˜²å¾¡ç­–ç•¥ï¼Œä¾‹å¦‚åŸºäºå› æœæ¨ç†çš„å¼‚å¸¸æ£€æµ‹æˆ–é²æ£’ä»·å€¼å‡½æ•°æ­£åˆ™åŒ–ï¼›
- å°†ç±»ä¼¼æ€æƒ³åº”ç”¨äºå…¶ä»–å®‰å…¨æ•æ„Ÿé¢†åŸŸï¼Œå¦‚è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—å†³ç­–ç­‰ Offline RL åº”ç”¨åœºæ™¯ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> CS-GBA æ­ç¤ºäº† Offline RL å®‰å…¨çš„æ–°è¾¹ç•Œâ€”â€”é€šè¿‡**å…³é”®æ ·æœ¬èšç„¦ + åˆ†å¸ƒå†…è§¦å‘ + æ¢¯åº¦å¼•å¯¼åŠ¨ä½œ**ï¼Œå³ä½¿åœ¨ 5% æä½é¢„ç®—ä¸‹ä¹Ÿèƒ½ç©¿é€æœ€å¼ºä¿å®ˆé˜²å¾¡ï¼Œä¸ºæ„å»ºæ›´é²æ£’çš„ç¦»çº¿å¼ºåŒ–å­¦ä¹ ç³»ç»Ÿæ•²å“è­¦é’Ÿã€‚

</details>

---

### 14. [Improving Chain-of-Thought for Logical Reasoning via Attention-Aware Intervention](https://arxiv.org/abs/2601.09805)

**Authors**: Nguyen Minh Phuong, Dang Huu Tien, Naoya Inoue  
**Category**: cs.AI  
**Published**: 2026-01-16  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.09805v1  

#### Abstract
Modern logical reasoning with LLMs primarily relies on employing complex interactive frameworks that decompose the reasoning process into subtasks solved through carefully designed prompts or requiring external resources (e.g., symbolic solvers) to exploit their strong logical structures. While inte...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Improving Chain-of-Thought for Logical Reasoning via Attention-Aware Intervention è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°ä»£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨**é€»è¾‘æ¨ç†ä»»åŠ¡**ä¸Šé¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¤æ‚çš„ã€å¤šæ­¥çš„ã€åŸºäºè§„åˆ™çš„æ¨ç†æ—¶å®¹æ˜“å‡ºé”™ï¼Œä¾‹å¦‚ï¼š
- é”™è¯¯é€‰æ‹©æ¨ç†è§„åˆ™ï¼ˆrule selectionï¼‰
- æ— æ³•åˆ¤æ–­ä½•æ—¶ç»ˆæ­¢æ¨ç†è¿‡ç¨‹
- åœ¨é•¿é“¾æ¨ç†ä¸­å‡ºç°ä¿¡æ¯è¡°å‡ï¼ˆinformation decayï¼‰

ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–ä¸¤ç±»æ¡†æ¶ï¼š
1. **äº¤äº’å¼æ¡†æ¶**ï¼ˆInteractive frameworksï¼‰ï¼šå°†å¤æ‚æ¨ç†åˆ†è§£ä¸ºå¤šä¸ªå­ä»»åŠ¡ï¼ˆå¦‚è§„åˆ™é€‰æ‹©ã€å‰ææ¨å¯¼ç­‰ï¼‰ï¼Œä½†å¼•å…¥é¢å¤–çš„è®¡ç®—å¼€é”€å’Œç³»ç»Ÿå¤æ‚æ€§ã€‚
2. **æ··åˆæ–¹æ³•**ï¼ˆHybrid approachesï¼‰ï¼šç»“åˆå¤–éƒ¨ç¬¦å·æ±‚è§£å™¨ï¼ˆsymbolic solversï¼‰ï¼Œè™½ç„¶æ€§èƒ½å¼ºï¼Œä½†ä¾èµ–å¤–éƒ¨èµ„æºï¼Œé™åˆ¶äº†å¯æ‰©å±•æ€§å’Œç«¯åˆ°ç«¯è®­ç»ƒã€‚

è¿™äº›æ–¹æ³•æœªèƒ½ç›´æ¥è¯„ä¼°LLMsè‡ªèº«çš„**å†…åœ¨æ¨ç†èƒ½åŠ›**ï¼Œå³åœ¨å•æ¬¡å‰å‘ä¼ é€’ä¸­å®Œæˆå®Œæ•´æ¨ç†çš„èƒ½åŠ›ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§**éäº¤äº’å¼ã€ç«¯åˆ°ç«¯**çš„é€»è¾‘æ¨ç†å¢å¼ºæ¡†æ¶â€”â€”**Attention-Aware Intervention (AAI)**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- é€šè¿‡åœ¨**few-shot prompt**ä¸­æ³¨å…¥**ç¬¦å·åŒ–ç»“æ„ä¿¡æ¯**ï¼ˆå¦‚ `Rule1`, `=>`, `KB={}` ç­‰ï¼‰ï¼Œæ¿€æ´»ç‰¹å®šçš„ attention headsï¼Œä½¿å…¶è¡¨ç°å‡ºä¸é€»è¾‘æ“ä½œå¯¹é½çš„æ¨¡å¼ã€‚
- åŸºäºæ­¤è§‚å¯Ÿï¼Œè®¾è®¡ä¸€ç§**æ¨ç†æ—¶å¹²é¢„æœºåˆ¶**ï¼ˆinference-time interventionï¼‰ï¼ŒåŠ¨æ€é‡åŠ æƒï¼ˆreweightï¼‰é€‰å®š attention heads çš„æ³¨æ„åŠ›åˆ†æ•°ï¼Œä»¥å¼ºåŒ–æ¨¡å‹å¯¹å…³é”®è§„åˆ™çš„å…³æ³¨ï¼ŒæŠ‘åˆ¶æ— å…³å™ªå£°ã€‚

#### åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š
1. **é¦–æ¬¡æ­ç¤ºäº†ç»“æ„åŒ–æç¤ºå¦‚ä½•å½±å“LLMå†…éƒ¨æ³¨æ„åŠ›æœºåˆ¶**ï¼šå‘ç°æŸäº› attention heads å¯è¢«å½’ç±»ä¸ºä¸‰ç±»åŠŸèƒ½å‹å¤´ï¼š
   - **Anchor Heads**ï¼šè´Ÿè´£è®°å¿†ä¿¡æ¯ï¼ˆé«˜å¯¹è§’çº¿å¾—åˆ†ï¼‰
   - **Aggregation Heads**ï¼šæ•´åˆæ–°ç”Ÿæˆçš„å‰æå¹¶ä¼ æ’­ä¿¡æ¯ï¼ˆé«˜å‚ç›´å¾—åˆ†ï¼‰
   - **Copy Heads**ï¼šå¤åˆ¶ç”Ÿæˆçš„å‰æç”¨äºæ›´æ–°çŸ¥è¯†åº“ï¼ˆKBï¼‰æˆ–åŒ¹é…è§„åˆ™ï¼ˆçŸ­å¯¹è§’çº¿å¯¹é½ï¼‰
2. **æå‡º AAI å¹²é¢„æœºåˆ¶**ï¼šåŸºäºä¸Šè¿°åˆ†ç±»ï¼Œåœ¨æ¨ç†è¿‡ç¨‹ä¸­è‡ªé€‚åº”åœ°è°ƒæ•´ attention scoresï¼Œé€šè¿‡æ„é€ ä¸¤ä¸ªæ©ç çŸ©é˜µ $M_{\text{Ref}}$ å’Œ $M_{\text{NoRef}}$ æ¥åŠ å¼ºè§„åˆ™æ ‡è¯†ç¬¦ä¸å…¶å†…å®¹ä¹‹é—´çš„è¯­ä¹‰é“¾æ¥ã€‚
3. **å®Œå…¨éäº¤äº’ã€æ— éœ€å¤–éƒ¨ç»„ä»¶**ï¼šAAI æ˜¯ä¸€ä¸ªè½»é‡çº§ã€æ¨¡å‹æ— å…³çš„å¹²é¢„æ–¹æ³•ï¼Œä¸æ”¹å˜æ¨¡å‹å‚æ•°ï¼Œä»…åœ¨æ¨ç†æ—¶ä¿®æ”¹ attention åˆ†æ•°ï¼Œå› æ­¤**æ— é¢å¤–è®¡ç®—å¼€é”€**ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | AAI | äº¤äº’å¼æ¡†æ¶ | å¤–éƒ¨ç¬¦å·æ±‚è§£å™¨ |
|------|-----|------------|----------------|
| æ˜¯å¦éœ€è¦å¤–éƒ¨å·¥å…· | âŒ å¦ | âœ… æ˜¯ï¼ˆç¨‹åº/æ¨¡å—ï¼‰ | âœ… æ˜¯ï¼ˆå®šç†è¯æ˜å™¨ï¼‰ |
| æ˜¯å¦å¤šè½®äº¤äº’ | âŒ å•æ¬¡å‰å‘ | âœ… å¤šæ­¥è°ƒç”¨ | âœ… å¤šæ­¥è°ƒç”¨ |
| å¯è§£é‡Šæ€§ | âœ… é«˜ï¼ˆåŸºäº attention åˆ†æï¼‰ | âš ï¸ ä¸­ç­‰ | âš ï¸ è¾ƒä½ï¼ˆé»‘ç®±ï¼‰ |
| æ‰©å±•æ€§ | âœ… å¼ºï¼ˆé€‚ç”¨äºä»»æ„ decoder-only LLMï¼‰ | âš ï¸ å—é™äºæ¡†æ¶è®¾è®¡ | âŒ å¼±ï¼ˆä¾èµ–æ¥å£ï¼‰ |
| æ¨ç†æ•ˆç‡ | âœ… æé«˜ï¼ˆé›¶é¢å¤–å»¶è¿Ÿï¼‰ | âŒ ä½ï¼ˆå¤šæ¬¡è°ƒç”¨ï¼‰ | âŒ ä½ |

> âœ… AAI å®ç°äº†**é«˜æ€§èƒ½ã€é«˜å¯è§£é‡Šæ€§ã€ä½å¼€é”€ã€ç«¯åˆ°ç«¯æ¨ç†**çš„ç»Ÿä¸€ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒåœ¨äº”ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œï¼Œæ¶µç›–ä¸åŒç±»å‹çš„é€»è¾‘æ¨ç†ä»»åŠ¡ï¼š

| æ•°æ®é›† | ç±»å‹ | æ¨ç†éš¾åº¦ | æ ·æœ¬æ•° | è¯´æ˜ |
|--------|------|----------|--------|------|
| **ProofWriter** | å¤šè·³æ¼”ç»æ¨ç† | 5-hop | 600 | å¼€æ”¾ä¸–ç•Œå‡è®¾ï¼Œè¾“å‡º True/False/Uncertain |
| **ProntoQA** | å¤šè·³é€»è¾‘é—®ç­” | 5-hop | 500 | ç±»ä¼¼ ProofWriterï¼Œæ›´å…·æŒ‘æˆ˜æ€§ |
| **LogicalDeduction** | å®ä½“æ’åºæ¨ç† | 3/5/7å¯¹è±¡ | 300 | æ ¹æ®çº¦æŸæ¡ä»¶æ¨æ–­é¡ºåº |
| **FOLIO** | åŸºäºä¸€é˜¶é€»è¾‘çš„çœŸå®åœºæ™¯æ¨ç† | â€” | 204 | ç”±é¢†åŸŸä¸“å®¶æ„å»ºï¼Œå«ç°å®çŸ¥è¯† |
| **GSM8k** | æ•°å­¦åº”ç”¨é¢˜ | â€” | 1,319 | æµ‹è¯•æ³›åŒ–èƒ½åŠ› |

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### è¯„ä¼°æŒ‡æ ‡
- ä¸»è¦æŒ‡æ ‡ï¼š**Accuracy**ï¼ˆå‡†ç¡®ç‡ï¼‰
- æ‰€æœ‰ç»“æœå‡ä½¿ç”¨ **greedy decoding**ï¼ˆç¡®å®šæ€§è¾“å‡ºï¼‰ç¡®ä¿å¯å¤ç°ã€‚

#### æ¨¡å‹é€‰æ‹©
ä¸»è¦æµ‹è¯•ä»¥ä¸‹å¼€æº LLMsï¼š
- **Qwen-3** ç³»åˆ—ï¼š1.7B, 4B, 8B, 32B
- **OLMo-2**ï¼š32B
- **Phi-4**ï¼š14B

ç¡¬ä»¶ï¼šå•å¼  NVIDIA A40 GPUã€‚

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³•ç±»åˆ« | å…·ä½“æ–¹æ³• |
|---------|--------|
| **Closed-source Baseline** | GPT-4 + CoT |
| **Interactive + External Solver** | Logic-LM, DetermLR, SymbCoT |
| **Non-interactive Baseline** | Standard CoT, Symbolic-Aided CoT (Nguyen et al., 2025) |
| **Proposed Methods** | AAI + Symbolic-Aided CoT, AAI + Compact Symbolic-Aided CoT |

æ­¤å¤–è¿˜æå‡ºäº†ä¸€ä¸ªæ–°çš„è½»é‡æç¤ºæ¨¡æ¿ï¼š**Compact Symbolic-Aided CoT**ï¼Œç”¨äºéªŒè¯ AAI çš„é€šç”¨æ€§ã€‚

#### AAI è®¾ç½®
- **Main AAI Setting**ï¼šé€‰æ‹© $s_{\text{diagonal}} > 0.3$ çš„ anchor heads å’Œ copy heads è¿›è¡Œ reweightingã€‚
- **AAI_agg Setting**ï¼šé€‰æ‹© $s_{\text{vertical}} > 0.6$, $s_{\text{horizontal}}, s_{\text{diagonal}} < 0.3$ çš„ aggregation headsã€‚
- è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼šæµ‹è¯• binarization thresholdã€diagonal thresholdã€reweighting coefficient ($c$) å’Œ bias ($b$)ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 2ï¼‰

| æ–¹æ³• + LLM | ProofWriter | ProntoQA | LogicalDeduction | FOLIO | GSM8k |
|-----------|------------|----------|------------------|-------|-------|
| **Symbolic-Aided CoT (Qwen3-32B)** | 79.67 | 99.20 | 88.00 | 69.61 | â€” |
| **+AAI (ours)** | **82.50** (+2.83) | **99.40** | **89.67** (+1.67) | **71.09** | â€” |
| **Symbolic-Aided CoT (OLMo-2-32B)** | 65.00 | 92.60 | 51.33 | 64.22 | â€” |
| **+AAI (ours)** | **67.50** (+2.50) | **93.00** | **54.33** (+3.00) | 64.22 | â€” |
| **Symbolic-Aided CoT (Phi-4-14B)** | 76.33 | 99.40 | 91.67 | 70.59 | â€” |
| **+AAI (ours)** | 76.33 | 99.00 | **92.33** (+0.66) | **72.06** | â€” |

> ğŸ’¡ **å…³é”®æå‡é›†ä¸­åœ¨ ProofWriter å’Œ LogicalDeduction ä¸Š**ï¼Œæœ€å¤§æå‡è¾¾ **+2.83 Acc**ã€‚

---

### ä¸å…¶ä»– SOTA æ–¹æ³•çš„æ¯”è¾ƒ
- åœ¨ **Qwen3-32B** ä¸Šï¼Œ**AAI å·²è¾¾åˆ°ç”šè‡³è¶…è¿‡éƒ¨åˆ†ä½¿ç”¨ GPT-4 æˆ–å¤–éƒ¨ç¬¦å·æ±‚è§£å™¨çš„æ–¹æ³•**ï¼ˆå¦‚ Logic-LMã€DetermLRï¼‰ã€‚
- å°½ç®¡æœªè¶…è¶Šæœ€å¼ºçš„ **SymbCoT (99.6%)**ï¼Œä½† AAI æ˜¯**å”¯ä¸€æ— éœ€å¤–éƒ¨ç¨‹åºæˆ–äº¤äº’è°ƒç”¨**å³å¯æ¥è¿‘è¯¥æ€§èƒ½çš„æ–¹æ³•ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆè§ Figure 3ï¼‰

| é…ç½® | ProofWriter (Qwen3-32B) | LogicalDeduction (Qwen3-32B) |
|------|------------------------|-------------------------------|
| Symbolic-Aided CoT (Baseline) | 79.67 | 88.00 |
| + AAI (Full Head Selection) | 81.00 | 89.00 |
| + AAI (Aggregation Heads Only) | 81.50 | 88.67 |
| + AAI (Anchor/Copy Heads Only) | **82.50** | **89.67** |

> âœ… ç»“æœè¡¨æ˜ï¼š**é’ˆå¯¹ anchor å’Œ copy heads çš„å¹²é¢„æœ€æœ‰æ•ˆä¸”ç¨³å®š**ï¼Œè€Œå¹²é¢„ aggregation heads è™½æœ‰ä¸€å®šå¢ç›Šä½†å¯èƒ½å¯¼è‡´è¡Œä¸ºä¸ç¨³å®šã€‚

---

### è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼ˆFigure 5ï¼‰
- AAI å¯¹å¤§å¤šæ•°è¶…å‚æ•°ï¼ˆå¦‚ diagonal threshold, coefficientï¼‰å…·æœ‰è¾ƒå¼ºé²æ£’æ€§ã€‚
- å½“ä½¿ç”¨å›ºå®š biasï¼ˆ$c=0$ï¼‰æ—¶ï¼Œæ€§èƒ½å¯èƒ½ä¸‹é™ï¼Œå°¤å…¶åœ¨ **ProofWriter** ä¸Šï¼Œè¯´æ˜**è‡ªé€‚åº” reweighting æ›´ä¼˜**ã€‚

---

### è¯­ä¹‰è¡¨ç¤ºå¯è§†åŒ–ï¼ˆFigure 6ï¼‰
- ä½¿ç”¨ t-SNE å¯è§†åŒ–æœ€åä¸€å±‚éšè—çŠ¶æ€ï¼š
  - **Standard CoT**ï¼šèšç±»æ¾æ•£ï¼Œé”™è¯¯æ ·æœ¬åˆ†æ•£ã€‚
  - **Symbolic-Aided CoT**ï¼šå½¢æˆæ›´ç»†ç²’åº¦ç°‡ã€‚
  - **AAI**ï¼šç°‡æ›´ç´§å‡‘ã€åˆ†ç¦»æ›´æ¸…æ™° â†’ è¡¨æ˜ AAI å¢å¼ºäº†ç»“æ„åŒ–è¯­ä¹‰ç¼–ç èƒ½åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **ç»“æ„åŒ–æç¤ºèƒ½æ¿€æ´»ç‰¹å®š attention heads**ï¼šæ³¨å…¥ç¬¦å·ç»“æ„ï¼ˆå¦‚ `RuleX`, `=>`ï¼‰ä¼šè¯±å¯¼å‡ºä¸é€»è¾‘æ“ä½œå¯¹é½çš„ attention æ¨¡å¼ï¼ˆanchor, aggregation, copy headsï¼‰ã€‚
2. âœ… **AAI æ˜¾è‘—æå‡é€»è¾‘æ¨ç†æ€§èƒ½**ï¼šåœ¨å¤šç§æ¨¡å‹å’Œæ•°æ®é›†ä¸Šä¸€è‡´å¸¦æ¥ **+1~3% å‡†ç¡®ç‡æå‡**ï¼Œä¸”æ— é¢å¤–æ¨ç†å¼€é”€ã€‚
3. âœ… **anchor/copy heads æ˜¯å¹²é¢„çš„å…³é”®ç›®æ ‡**ï¼šå®ƒä»¬è´Ÿè´£ä¿¡æ¯å­˜å‚¨ä¸å¤åˆ¶ï¼Œå¹²é¢„è¿™äº›å¤´èƒ½æ›´å®‰å…¨æœ‰æ•ˆåœ°æ³¨å…¥å…ˆéªŒçŸ¥è¯†ã€‚
4. âœ… **AAI å…·æœ‰è‰¯å¥½æ³›åŒ–æ€§**ï¼šä¸ä»…é€‚ç”¨äºåŸå§‹ Symbolic-Aided CoTï¼Œä¹Ÿèƒ½æå‡æ–°è®¾è®¡çš„ **Compact Symbolic-Aided CoT** å’Œæ•°å­¦æ¨ç†ä»»åŠ¡ **GSM8k** çš„è¡¨ç°ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–åˆæˆæˆ–ä¸­å°è§„æ¨¡æ•°æ®é›†**ï¼šå½“å‰å®éªŒé›†ä¸­äºäººå·¥æ„é€ çš„é€»è¾‘ä»»åŠ¡ï¼ˆå¦‚ ProofWriterï¼‰ï¼Œå°šæœªåœ¨çœŸå®å¤æ‚åœºæ™¯ä¸­å……åˆ†éªŒè¯ã€‚
2. **ä¾èµ– self-attention æ¶æ„**ï¼šAAI åŸºäº attention åˆ†æï¼Œéš¾ä»¥è¿ç§»åˆ°é attention-based æ¨¡å‹ã€‚
3. **ä»å—é™äºåŸºç¡€ prompt è®¾è®¡**ï¼šAAI æ˜¯å¯¹å·²æœ‰ prompt çš„å¢å¼ºï¼Œè‹¥åŸå§‹ prompt æ— æ³•å¼•å¯¼æ­£ç¡®æ¨ç†è·¯å¾„ï¼Œåˆ™ AAI æ•ˆæœæœ‰é™ã€‚
4. **é”™è¯¯æ ¹æºæœªå®Œå…¨è§£å†³**ï¼šéƒ¨åˆ†å¤±è´¥æºäºåˆå§‹è§„åˆ™é€‰æ‹©é”™è¯¯æˆ–æœ€ç»ˆéªŒè¯é˜¶æ®µçš„ mismatchï¼ŒAAI æ— æ³•å®Œå…¨çº æ­£ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³å¸¸è¯†æ¨ç†ï¼ˆcommonsense reasoningï¼‰å’Œå…¶ä»–å¤šè·³æ¨ç†ä»»åŠ¡**ã€‚
2. **æ¢ç´¢è‡ªåŠ¨è¯†åˆ«å…³é”® attention heads çš„æ–¹æ³•**ï¼Œå‡å°‘äººå·¥åˆ†ææˆæœ¬ã€‚
3. **ç»“åˆè®­ç»ƒé˜¶æ®µå¹²é¢„**ï¼Œè¿›ä¸€æ­¥å›ºåŒ–æ¨ç†èƒ½åŠ›ã€‚
4. **åº”ç”¨äºæ›´å¤§è§„æ¨¡çœŸå®ä¸–ç•ŒçŸ¥è¯†åº“æ¨ç†ç³»ç»Ÿ**ï¼ŒéªŒè¯å®é™…éƒ¨ç½²ä»·å€¼ã€‚

---

## æ€»ç»“
æœ¬æ–‡æå‡ºçš„ **Attention-Aware Intervention (AAI)** æ˜¯ä¸€ç§é«˜æ•ˆã€å¯è§£é‡Šã€æ— é¢å¤–å¼€é”€çš„é€»è¾‘æ¨ç†å¢å¼ºæ–¹æ³•ã€‚å®ƒé€šè¿‡åˆ†æç»“æ„åŒ–æç¤ºä¸‹çš„ attention æ¨¡å¼ï¼Œè¯†åˆ«å‡ºæ‰¿æ‹…ä¸åŒé€»è¾‘åŠŸèƒ½çš„ attention headsï¼Œå¹¶åœ¨æ¨ç†æ—¶å¯¹å…¶è¿›è¡ŒåŠ¨æ€ reweightingï¼Œä»è€Œâ€œå¼•å¯¼â€æ¨¡å‹æ›´å¥½åœ°åˆ©ç”¨å…ˆéªŒçŸ¥è¯†è¿›è¡Œæ¨ç†ã€‚å®éªŒè¯æ˜ AAI åœ¨å¤šä¸ªåŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äº baselineï¼Œå¹¶é€¼è¿‘ç”šè‡³åª²ç¾ä¾èµ–å¤–éƒ¨å·¥å…·çš„å¤æ‚ç³»ç»Ÿï¼Œä¸ºæ„å»º**å¯ä¿¡èµ–ã€ç«¯åˆ°ç«¯ã€å¯åˆ†æçš„ç¥ç»ç¬¦å·æ¨ç†ç³»ç»Ÿ**æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 15. [M^4olGen: Multi-Agent, Multi-Stage Molecular Generation under Precise Multi-Property Constraints](https://arxiv.org/abs/2601.10131)

**Authors**: Yizhan Li, Florence Cloutier, Sifan Wu, Ali Parviz, Boris Knyazev, Yan Zhang, Glen Berseth, Bang Liu  
**Category**: cs.AI  
**Published**: 2026-01-16  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.10131v1  

#### Abstract
Generating molecules that satisfy precise numeric constraints over multiple physicochemical properties is critical and challenging. Although large language models (LLMs) are expressive, they struggle with precise multi-objective control and numeric reasoning without external structure and feedback. ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Mâ´olGen: Multi-Agent, Multi-Stage Molecular Generation under Precise Multi-Property Constraints  
**æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡è‡´åŠ›äºè§£å†³**åœ¨ç²¾ç¡®å¤šå±æ€§æ•°å€¼çº¦æŸä¸‹ç”Ÿæˆåˆ†å­**è¿™ä¸€å…³é”®æŒ‘æˆ˜ã€‚ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚LLMsæˆ–å›¾ç”Ÿæˆæ¨¡å‹ï¼‰åœ¨ä»¥ä¸‹æ–¹é¢å­˜åœ¨ä¸è¶³ï¼š
- éš¾ä»¥å®ç°å¯¹å¤šä¸ªç‰©ç†åŒ–å­¦æ€§è´¨ï¼ˆå¦‚QEDã€LogPã€MWã€HOMOã€LUMOï¼‰çš„åŒæ—¶**ç²¾ç¡®æ§åˆ¶**ï¼›
- ç¼ºä¹æœ‰æ•ˆçš„**æ•°å€¼æ¨ç†èƒ½åŠ›**ï¼Œæ— æ³•æ˜¾å¼æœ€å°åŒ–ç›®æ ‡å±æ€§è¯¯å·®ï¼›
- å•æ­¥ç”Ÿæˆç¼ºä¹å¯è§£é‡Šæ€§å’Œå¯æ§æ€§ã€‚

### ğŸ†• æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **Mâ´olGen** â€”â€” ä¸€ä¸ªä¸¤é˜¶æ®µã€åŸºäºç‰‡æ®µï¼ˆfragment-levelï¼‰ã€æ£€ç´¢å¢å¼ºçš„å¤šæ™ºèƒ½ä½“åˆ†å­ç”Ÿæˆæ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰**ä¸¤é˜¶æ®µååŒæ¶æ„**
- **Stage I: Prototype Generationï¼ˆåŸå‹ç”Ÿæˆï¼‰**
  - å¼•å…¥**å¤šæ™ºèƒ½ä½“æ¨ç†æœºåˆ¶**ï¼Œç»“åˆæ£€ç´¢ï¼ˆretrievalï¼‰ä¸é¢†åŸŸçŸ¥è¯†è¿›è¡Œé€æ­¥ç¼–è¾‘ã€‚
  - åˆ©ç”¨BRICSç‰‡æ®µåˆ†è§£å’ŒRDKitåé¦ˆï¼Œé€šè¿‡â€œæ£€ç´¢é”šå®šâ€ç­–ç•¥ç”Ÿæˆæ¥è¿‘å¯è¡ŒåŒºåŸŸçš„åˆå§‹åˆ†å­åŸå‹ã€‚
- **Stage II: GRPO-Based Optimizationï¼ˆä¼˜åŒ–ç²¾è°ƒï¼‰**
  - ä½¿ç”¨**Group Relative Policy Optimization (GRPO)** è®­ç»ƒä¸€ä¸ªç‰‡æ®µçº§ä¼˜åŒ–å™¨ï¼Œåœ¨å¯æ§çš„å¤šè·³ï¼ˆmulti-hopï¼‰ç¼–è¾‘ä¸­æ˜¾å¼æœ€å°åŒ–å±æ€§è¯¯å·®ã€‚
  - æ”¯æŒå¤æ‚åº¦è°ƒèŠ‚ï¼ˆhop budgetï¼‰ï¼Œé˜²æ­¢è¿‡åº¦åç¦»åŸå§‹ç»“æ„ã€‚

#### ï¼ˆ2ï¼‰**å¯æ§çš„å¤šè·³æ¨ç†æœºåˆ¶**
- æ„å»ºäº†ä¸€ä¸ªåŒ…å«117ä¸‡å¯¹å•æ­¥ç¼–è¾‘åˆ†å­çš„é‚»åŸŸå…³ç³»æ•°æ®é›†ï¼ˆneighbor relational datasetï¼‰ï¼Œæ”¯æŒé•¿é“¾ã€å¯è¿½è¸ªçš„æ¨ç†è·¯å¾„ã€‚
- å®ç°ä»â€œç²—ç•¥åŸå‹â€åˆ°â€œç²¾å‡†æ»¡è¶³â€çš„æ¸è¿›å¼ä¼˜åŒ–ï¼Œæå‡å¯æ§æ€§ä¸å¯è§£é‡Šæ€§ã€‚

#### ï¼ˆ3ï¼‰**å¤§è§„æ¨¡å…¬å¼€æ•°æ®é›†æ„å»º**
- å‘å¸ƒäº†ä¸€ä¸ªåŒ…å«çº¦ **295ä¸‡åˆ†å­** çš„BRICSç‰‡æ®µæ ‡æ³¨æ•°æ®é›†ï¼Œå¹¶æä¾›å…¶å±æ€§å˜åŒ–ï¼ˆâ–³propertyï¼‰ä¸ç¼–è¾‘æ“ä½œæ ‡ç­¾ã€‚
- æ•°æ®é›†æ¶µç›–QEDã€LogPã€MWã€HOMOã€LUMOç­‰å…³é”®å±æ€§ï¼Œå¯ç”¨äºè®­ç»ƒå…·å¤‡åŒ–å­¦æ¨ç†èƒ½åŠ›çš„æ¨¡å‹ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | Mâ´olGenä¼˜åŠ¿ |
|------|-------------|
| **ç²¾ç¡®æ§åˆ¶** | æ˜¾è‘—ä¼˜äºLLMså’Œå›¾æ¨¡å‹ï¼Œåœ¨QED/LogP/MWå’ŒHOMO/LUMOä»»åŠ¡ä¸Šå‡å–å¾—æœ€ä½è¯¯å·® |
| **å¯æ§æ€§** | å¤šè·³ç¼–è¾‘å…è®¸ç²¾ç»†è°ƒæ§ä¿®æ”¹ç¨‹åº¦ï¼Œé¿å…å‰§çƒˆç»“æ„çªå˜ |
| **å¯æ‰©å±•æ€§** | ä¸ä¾èµ–ç‰¹å®šç›®æ ‡é‡æ–°è®­ç»ƒï¼Œæ”¯æŒè·¨ç›®æ ‡æ³›åŒ– |
| **æ•ˆç‡** | GRPOè®­ç»ƒç¨³å®šé«˜æ•ˆï¼›æ¨ç†æˆæœ¬ä½äºé—ä¼ ç®—æ³•ï¼ˆGraph GAï¼‰è¿‘90% |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
- **ä¸»æ•°æ®é›†æ¥æº**ï¼šæ•´åˆZINCã€CHEMBL å’Œ MOSES æ•°æ®åº“ï¼Œç»å»é‡åå…±å¾— **2,945,596ä¸ªåˆ†å­**ã€‚
- **å±æ€§è®¡ç®—æ–¹å¼**ï¼š
  - QEDã€LogPã€MWï¼šä½¿ç”¨RDKitè®¡ç®—ï¼›
  - HOMO/LUMOï¼šä½¿ç”¨é¢„è®­ç»ƒçš„DimeNet++æ¨¡å‹é¢„æµ‹ã€‚
- **ç‰‡æ®µå¤„ç†**ï¼šé‡‡ç”¨BRICSè§„åˆ™å°†æ¯ä¸ªåˆ†å­åˆ†è§£ä¸ºåŒ–å­¦æœ‰æ„ä¹‰çš„å­ç»“æ„å•å…ƒã€‚
- **é‚»åŸŸæ•°æ®é›†æ„å»º**ï¼š
  - æ‰«ææ‰€æœ‰åˆ†å­å¯¹ï¼Œç­›é€‰ä»…å·®ä¸€ä¸ªç‰‡æ®µæ“ä½œï¼ˆadd/remove/replaceï¼‰çš„æœ‰æ•ˆé…å¯¹ï¼›
  - æœ€ç»ˆè·å¾— **~1.17Mä¸ªå•æ­¥ç¼–è¾‘å¯¹**ï¼Œå¹¶è®°å½•å±æ€§å˜åŒ–ï¼ˆâ–³QED, â–³LogP, â–³MWç­‰ï¼‰ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **ç›®æ ‡å±æ€§ç»„åˆ**ï¼š
  1. **Set 1**: QED, LogP, Molecular Weight (MW)
  2. **Set 2**: HOMO, LUMOï¼ˆç”µå­èƒ½çº§ï¼‰
- **é‡‡æ ·æ–¹å¼**ï¼šå‡åŒ€éšæœºæŠ½å–100ç»„ç›®æ ‡å€¼ï¼Œåœ¨æ¯ç»„ä¸Šè¿è¡Œ10æ¬¡ç‹¬ç«‹è¯•éªŒï¼ˆbest-of-10ï¼‰ã€‚
- **Hop Budget**ï¼šæµ‹è¯•1-hopã€2-hopã€3-hopä¼˜åŒ–æ•ˆæœã€‚

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ä¸ç”¨é€” |
|------|-----------|
| **MAE (Mean Absolute Error)** | å„å±æ€§å¹³å‡ç»å¯¹è¯¯å·®ï¼Œè¡¡é‡ç²¾åº¦ |
| **Normalized Total Error (NTE)** | å½’ä¸€åŒ–æ€»è¯¯å·®ï¼š<br>$$ \text{NTE} = |\Delta\text{QED}| + \frac{|\Delta\text{LogP}|}{10} + \frac{|\Delta\text{MW}|}{700} $$<br>ä¾¿äºå¤šç›®æ ‡æ¯”è¾ƒ |
| **Diversity** | åŸºäºECFP4æŒ‡çº¹çš„Tanimotoç›¸ä¼¼æ€§è®¡ç®—ï¼Œè¶Šé«˜è¡¨ç¤ºæ¢ç´¢è¶Šå¹¿ |
| **Uniqueness** | è¾“å‡ºä¸­å”¯ä¸€åˆ†å­çš„æ¯”ä¾‹ï¼ˆé€šè¿‡canonical SMILESåˆ¤æ–­ï¼‰ |
| **Validity** | RDKitå¯è§£æä¸”ä»·æ€åˆæ³•çš„åˆ†å­æ¯”ä¾‹ |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | æ–¹æ³•åˆ—è¡¨ |
|------|--------|
| **LLM-based** | GPT-4.1, GPT-4o, Gemini-Flash, Claude-3.5-haiku, SmileyLlama-8B, DrugAssist-7B |
| **Graph-based** | STGG+, Graph Genetic Algorithm (GA-500, GA-1000) |
| **ç‰¹åˆ«è¯´æ˜** | åœ¨HOMO/LUMOä»»åŠ¡ä¸­ï¼Œæ— LLMè¡¨ç°è‰¯å¥½ï¼Œæ•…ä»…ä¸Graph GAå¯¹æ¯” |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ªTable 1 & Table 2ï¼‰

#### âœ… Set 1: QED / LogP / MW ç»“æœï¼ˆTable 1ï¼‰
| æ–¹æ³• | QED err | LogP err | MW err | **NTE** |
|------|---------|----------|--------|--------|
| GPT-4.1 (best LLM) | 0.115 | 0.697 | 49.182 | 0.255 |
| STGG+ | 0.079 | 0.418 | 23.56 | 0.155 |
| **Mâ´olGen (3-hop, GPT-4o)** | **0.103** | **0.284** | **9.799** | **0.146** |
| **Mâ´olGen (3-hop, Qwen)** | 0.120 | 0.237 | 10.365 | 0.159 |

> ğŸ’¡ **å…³é”®æå‡**ï¼š
> - NTEæ¯”æœ€å¼ºLLMï¼ˆGPT-4.1ï¼‰é™ä½ **42.7%**
> - LogPè¯¯å·®ä¸‹é™ **59.1%**ï¼ˆ0.697 â†’ 0.284ï¼‰
> - MWè¯¯å·®ä¸‹é™ **80.0%**ï¼ˆvs. GPT-4.1ï¼‰

#### âœ… Set 2: HOMO / LUMO ç»“æœï¼ˆTable 2ï¼‰
| æ–¹æ³• | HOMO err (eV) | LUMO err (eV) | **Total Error (eV)** |
|------|----------------|----------------|---------------------|
| Graph GA-1000 | 0.251 | 0.353 | 0.604 |
| **Mâ´olGen (1-hop)** | 0.301 | 0.239 | **0.540** |
| **Mâ´olGen (2-hop)** | 0.112 | 0.115 | **0.227** |
| **Mâ´olGen (3-hop)** | **0.060** | **0.095** | **0.155** |

> ğŸ’¡ **å…³é”®æå‡**ï¼š
> - æ€»è¯¯å·®ä»…ä¸ºGraph GA-1000çš„ **25.7%**
> - 2-hopå³å®ç°è¶…è¿‡2å€æ”¹è¿›
> - åŒæ—¶ä¼˜åŒ–HOMOä¸LUMOï¼Œæœªå‡ºç°å•ä¸€è¿‡æ‹Ÿåˆ

#### âœ… æ•ˆç‡ä¼˜åŠ¿
- Mâ´olGenåœ¨è¾¾åˆ°æ›´ä¼˜æ€§èƒ½çš„åŒæ—¶ï¼Œ**æ¨ç†æ—¶é—´å‡å°‘è¿‘90%**ï¼Œå› ä¼˜åŒ–æˆæœ¬åœ¨è®­ç»ƒé˜¶æ®µæ‘Šé”€ã€‚

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœï¼ˆAblation Study, Table 3 & Figure 2ï¼‰

| æ–¹æ³• | QED err | LogP err | MW err | NTE |
|------|--------|---------|--------|-----|
| Stage I (no retrieval) | 0.111 | 0.970 | 68.555 | 0.307 |
| + Retrieval | 0.098 | 0.769 | 63.240 | 0.265 |
| + 1-hop | 0.130 | 0.423 | 10.404 | 0.187 |
| + 2-hop | 0.111 | 0.339 | 10.489 | 0.160 |
| + 3-hop | 0.103 | 0.284 | 9.799 | **0.146** |

> ğŸ” **æ¶ˆèå‘ç°**ï¼š
- **æ£€ç´¢æœºåˆ¶**ä½¿NTEä¸‹é™13.7%ï¼Œå°¤å…¶æ”¹å–„LogPå’ŒMWï¼›
- **å¼•å…¥GRPOä¼˜åŒ–å™¨**å¸¦æ¥æœ€å¤§æ”¶ç›Šï¼Œç‰¹åˆ«æ˜¯MWè¯¯å·®éª¤é™84.9%ï¼›
- éšç€hopæ•°å¢åŠ ï¼ŒNTEå•è°ƒä¸‹é™ï¼ˆ3-hopæœ€ä¼˜ï¼‰ï¼›
- å°½ç®¡1-hopæ—¶QEDç•¥æœ‰ä¸Šå‡ï¼Œä½†æœ€ç»ˆ3-hopæ¢å¤å¹¶è¶…è¶ŠåŸºå‡†ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º
1. **Mâ´olGenæ˜¾è‘—æå‡äº†å¤šå±æ€§ç²¾ç¡®æ§åˆ¶èƒ½åŠ›**ï¼Œåœ¨QED/LogP/MWå’ŒHOMO/LUMOä»»åŠ¡ä¸Šå…¨é¢è¶…è¶ŠLLMså’Œå›¾æ¨¡å‹ã€‚
2. **ä¸¤é˜¶æ®µè®¾è®¡è‡³å…³é‡è¦**ï¼š
   - Stage Iåˆ©ç”¨æ£€ç´¢ä¸å¤šæ™ºèƒ½ä½“åä½œå¿«é€Ÿå®šä½å¯è¡ŒåŒºåŸŸï¼›
   - Stage IIé€šè¿‡GRPOé©±åŠ¨çš„ç‰‡æ®µçº§ä¼˜åŒ–å®ç°ç»†ç²’åº¦è°ƒæ•´ã€‚
3. **GRPOé€‚ç”¨äºç¦»æ•£åŒ–å­¦åŠ¨ä½œç©ºé—´ä¼˜åŒ–**ï¼Œå…¶åŸºäºæ’åçš„å¥–åŠ±æœºåˆ¶ç¨³å®šæœ‰æ•ˆï¼Œæ— éœ€çœŸå®æ¼”ç¤ºæ•°æ®ã€‚
4. **å¤šè·³ç¼–è¾‘æœºåˆ¶æ”¯æŒå¯æ§ã€å¯è§£é‡Šçš„ä¼˜åŒ–è·¯å¾„**ï¼Œä¸ºè¯ç‰©è®¾è®¡ä¸­çš„â€œç†æ€§ä¿®é¥°â€æä¾›äº†è‡ªåŠ¨åŒ–å·¥å…·ã€‚
5. **æ‰€æ„å»ºçš„å¤§è§„æ¨¡ç‰‡æ®µ-å±æ€§æ•°æ®é›†æ˜¯é‡è¦å…¬å…±èµ„æº**ï¼Œæ¨åŠ¨å¯è§£é‡Šåˆ†å­AIå‘å±•ã€‚

### âš ï¸ å±€é™æ€§
- å½“å‰ä¾èµ–**è®¡ç®—å±æ€§ä¼°è®¡å™¨**ï¼ˆå¦‚RDKitã€DimeNet++ï¼‰ï¼Œå°šæœªéªŒè¯åœ¨çœŸå®å®éªŒæ•°æ®ä¸‹çš„è¡¨ç°ï¼›
- è¦†ç›–çš„å±æ€§é›†åˆæœ‰é™ï¼ˆä»…QEDã€LogPã€MWã€HOMOã€LUMOï¼‰ï¼›
- æ›´æ·±çš„hopè™½èƒ½ç»§ç»­ææ•ˆï¼Œä½†é¢ä¸´**è¾¹é™…æ”¶ç›Šé€’å‡ä¸è®¡ç®—å¼€é”€ä¸Šå‡**çš„æƒè¡¡ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³æ›´å¤šå®é™…åº”ç”¨åœºæ™¯ï¼ˆå¦‚ADMETã€æº¶è§£åº¦ã€æ¯’æ€§ç­‰ï¼‰ï¼›
- æ¥å…¥çœŸå®åˆæˆå¯è¡Œæ€§è¯„åˆ†ä¸å®éªŒå®¤åé¦ˆå½¢æˆé—­ç¯ï¼›
- æ¢ç´¢åŠ¨æ€hopé¢„ç®—è°ƒåº¦ä¸ Curriculum Learning ç­–ç•¥ï¼›
- å°†æ¡†æ¶è¿ç§»è‡³ææ–™ç§‘å­¦ï¼ˆå¦‚inorganic materialsï¼‰æˆ–å…¶ä»–ç»“æ„åŒ–è®¾è®¡ä»»åŠ¡ã€‚

---

> âœ… **ä¸€å¥è¯æ€»ç»“**ï¼š  
> Mâ´olGené€šè¿‡â€œæ£€ç´¢å¼•å¯¼åŸå‹ + GRPOé©±åŠ¨å¤šè·³ä¼˜åŒ–â€çš„åŒé˜¶æ®µèŒƒå¼ï¼Œé¦–æ¬¡å®ç°äº†åœ¨å¤šä¸ªç²¾ç¡®æ•°å€¼çº¦æŸä¸‹é«˜è´¨é‡ã€é«˜å¯æ§æ€§çš„åˆ†å­ç”Ÿæˆï¼Œä¸ºAIé©±åŠ¨çš„ç†æ€§è¯ç‰©è®¾è®¡æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 16. [Structure and Diversity Aware Context Bubble Construction for Enterprise Retrieval Augmented Systems](https://arxiv.org/abs/2601.10681)

**Authors**: Amir Khurshid, Abhishek Sehgal  
**Category**: cs.AI  
**Published**: 2026-01-16  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.10681v1  

#### Abstract
Large language model (LLM) contexts are typically constructed using retrieval-augmented generation (RAG), which involves ranking and selecting the top-k passages. The approach causes fragmentation in information graphs in document structures, over-retrieval, and duplication of content alongside insu...

---

### 17. [Distributed Linearly Separable Computation with Arbitrary Heterogeneous Data Assignment](https://arxiv.org/abs/2601.10177)

**Authors**: Ziting Zhang, Kai Wan, Minquan Cheng, Shuo Shao, Giuseppe Caire  
**Category**: cs.DC  
**Published**: 2026-01-16  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.10177v1  

#### Abstract
Distributed linearly separable computation is a fundamental problem in large-scale distributed systems, requiring the computation of linearly separable functions over different datasets across distributed workers. This paper studies a heterogeneous distributed linearly separable computation problem,...

---

### 18. [Kolmogorov Arnold Networks and Multi-Layer Perceptrons: A Paradigm Shift in Neural Modelling](https://arxiv.org/abs/2601.10563)

**Authors**: Aradhya Gaonkar, Nihal Jain, Vignesh Chougule, Nikhil Deshpande, Sneha Varur, Channabasappa Muttal  
**Category**: cs.LG  
**Published**: 2026-01-16  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.10563v1  

#### Abstract
The research undertakes a comprehensive comparative analysis of Kolmogorov-Arnold Networks (KAN) and Multi-Layer Perceptrons (MLP), highlighting their effectiveness in solving essential computational challenges like nonlinear function approximation, time-series prediction, and multivariate classific...

---

### 19. [Data-driven stochastic reduced-order modeling of parametrized dynamical systems](https://arxiv.org/abs/2601.10690)

**Authors**: Andrew F. Ilersich, Kevin Course, Prasanth B. Nair  
**Category**: cs.LG  
**Published**: 2026-01-16  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.10690v1  

#### Abstract
Modeling complex dynamical systems under varying conditions is computationally intensive, often rendering high-fidelity simulations intractable. Although reduced-order models (ROMs) offer a promising solution, current methods often struggle with stochastic dynamics and fail to quantify prediction un...

---

### 20. [Chinese Labor Law Large Language Model Benchmark](https://arxiv.org/abs/2601.09972)

**Authors**: Zixun Lan, Maochun Xu, Yifan Ren, Rui Wu, Jianghui Zhou, Xueyang Cheng, Jianan Ding Ding, Xinheng Wang, Mingmin Chi, Fei Ma  
**Category**: cs.AI  
**Published**: 2026-01-16  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.09972v1  

#### Abstract
Recent advances in large language models (LLMs) have led to substantial progress in domain-specific applications, particularly within the legal domain. However, general-purpose models such as GPT-4 often struggle with specialized subdomains that require precise legal knowledge, complex reasoning, an...

---

### 21. [FilDeep: Learning Large Deformations of Elastic-Plastic Solids with Multi-Fidelity Data](https://arxiv.org/abs/2601.10031)

**Authors**: Jianheng Tang, Shilong Tao, Zhe Feng, Haonan Sun, Menglu Wang, Zhanxing Zhu, Yunhuai Liu  
**Category**: cs.AI  
**Published**: 2026-01-16  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.10031v1  

#### Abstract
The scientific computation of large deformations in elastic-plastic solids is crucial in various manufacturing applications. Traditional numerical methods exhibit several inherent limitations, prompting Deep Learning (DL) as a promising alternative. The effectiveness of current DL techniques typical...

---

### 22. [From Single to Multi-Agent Reasoning: Advancing GeneGPT for Genomics QA](https://arxiv.org/abs/2601.10581)

**Authors**: Kimia Abedini, Farzad Shami, Gianmaria Silvello  
**Category**: cs.AI  
**Published**: 2026-01-16  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.10581v1  

#### Abstract
Comprehending genomic information is essential for biomedical research, yet extracting data from complex distributed databases remains challenging. Large language models (LLMs) offer potential for genomic Question Answering (QA) but face limitations due to restricted access to domain-specific databa...

---

### 23. [Credit C-GPT: A Domain-Specialized Large Language Model for Conversational Understanding in Vietnamese Debt Collection](https://arxiv.org/abs/2601.10167)

**Authors**: Nhung Nguyen Thi Hong, Cuong Nguyen Dang, Tri Le Ngoc  
**Category**: cs.CL  
**Published**: 2026-01-16  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.10167v1  

#### Abstract
Debt collection is a critical function within the banking, financial services, and insurance (BFSI) sector, relying heavily on large-scale human-to-human conversational interactions conducted primarily in Vietnamese contact centers. These conversations involve informal spoken language, emotional var...

---

### 24. [Measuring Affinity between Attention-Head Weight Subspaces via the Projection Kernel](https://arxiv.org/abs/2601.10266)

**Authors**: Hiroaki Yamagiwa, Yusuke Takase, Hidetoshi Shimodaira  
**Category**: cs.CL  
**Published**: 2026-01-16  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.10266v1  

#### Abstract
Understanding relationships between attention heads is essential for interpreting the internal structure of Transformers, yet existing metrics do not capture this structure well. We focus on the subspaces spanned by attention-head weight matrices and quantify head-to-head relationships using the Pro...

---

### 25. [Representation-Aware Unlearning via Activation Signatures: From Suppression to Knowledge-Signature Erasure](https://arxiv.org/abs/2601.10566)

**Authors**: Syed Naveed Mahmood, Md. Rezaur Rahman Bhuiyan, Tasfia Zaman, Jareen Tasneem Khondaker, Md. Sameer Sakib, Nazia Tasnim, Farig Sadeque  
**Category**: cs.CL  
**Published**: 2026-01-16  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.10566v1  

#### Abstract
Selective knowledge erasure from LLMs is critical for GDPR compliance and model safety, yet current unlearning methods conflate behavioral suppression with true knowledge removal, allowing latent capabilities to persist beneath surface-level refusals. In this work, we address this challenge by intro...

---

### 26. [Communication-Efficient Federated Learning by Exploiting Spatio-Temporal Correlations of Gradients](https://arxiv.org/abs/2601.10491)

**Authors**: Shenlong Zheng, Zhen Zhang, Yuhui Deng, Geyong Min, Lin Cui  
**Category**: cs.LG  
**Published**: 2026-01-16  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.10491v1  

#### Abstract
Communication overhead is a critical challenge in federated learning, particularly in bandwidth-constrained networks. Although many methods have been proposed to reduce communication overhead, most focus solely on compressing individual gradients, overlooking the temporal correlations among them. Pr...

---

### 27. [Single-Stage Huffman Encoder for ML Compression](https://arxiv.org/abs/2601.10673)

**Authors**: Aditya Agrawal, Albert Magyar, Hiteshwar Eswaraiah, Patrick Sheridan, Pradeep Janedula, Ravi Krishnan Venkatesan, Krishna Nair, Ravi Iyer  
**Category**: cs.LG  
**Published**: 2026-01-16  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.10673v1  

#### Abstract
Training and serving Large Language Models (LLMs) require partitioning data across multiple accelerators, where collective operations are frequently bottlenecked by network bandwidth. Lossless compression using Huffman codes is an effective way to alleviate the issue, however, its three-stage design...

---

### 28. [Communication-Efficient and Privacy-Adaptable Mechanism -- a Federated Learning Scheme with Convergence Analysis](https://arxiv.org/abs/2601.10701)

**Authors**: Chun Hei Michael Shiu, Chih Wei Ling  
**Category**: cs.LG  
**Published**: 2026-01-16  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.10701v1  

#### Abstract
Federated learning enables multiple parties to jointly train learning models without sharing their own underlying data, offering a practical pathway to privacy-preserving collaboration under data-governance constraints. Continued study of federated learning is essential to address key challenges in ...

---

### 29. [Beyond Rule-Based Workflows: An Information-Flow-Orchestrated Multi-Agents Paradigm via Agent-to-Agent Communication from CORAL](https://arxiv.org/abs/2601.09883)

**Authors**: Xinxing Ren, Quagmire Zang, Caelum Forder, Suman Deb, Ahsen Tahir, Roman J. Georgio, Peter Carroll, Zekun Guo  
**Category**: cs.AI  
**Published**: 2026-01-16  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.09883v1  

#### Abstract
Most existing Large Language Model (LLM)-based Multi-Agent Systems (MAS) rely on predefined workflows, where human engineers enumerate task states in advance and specify routing rules and contextual injections accordingly. Such workflow-driven designs are essentially rule-based decision trees, which...

---

### 30. [Structured Personality Control and Adaptation for LLM Agents](https://arxiv.org/abs/2601.10025)

**Authors**: Jinpeng Wang, Xinyu Jia, Wei Wei Heng, Yuquan Li, Binbin Shi, Qianlei Chen, Guannan Chen, Junxia Zhang, Yuyu Yin  
**Category**: cs.AI  
**Published**: 2026-01-16  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.10025v1  

#### Abstract
Large Language Models (LLMs) are increasingly shaping human-computer interaction (HCI), from personalized assistants to social simulations. Beyond language competence, researchers are exploring whether LLMs can exhibit human-like characteristics that influence engagement, decision-making, and percei...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- kv cache, offload, State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
