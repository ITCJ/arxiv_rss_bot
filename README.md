# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-01-09 05:58:50 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [FaST: Efficient and Effective Long-Horizon Forecasting for Large-Scale Spatial-Temporal Graphs via Mixture-of-Experts](https://arxiv.org/abs/2601.05174)

**Authors**: Yiji Zhao, Zihao Zhong, Ao Wang, Haomin Wen, Ming Jin, Yuxuan Liang, Huaiyu Wan, Hao Wu  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 13.0  
**Type**: new  
**ArXiv ID**: 2601.05174v1  

#### Abstract
Spatial-Temporal Graph (STG) forecasting on large-scale networks has garnered significant attention. However, existing models predominantly focus on short-horizon predictions and suffer from notorious computational costs and memory consumption when scaling to long-horizon predictions and large graph...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFaST: Efficient and Effective Long-Horizon Forecasting for Large-Scale Spatial-Temporal Graphs via Mixture-of-Experts

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„ **Spatial-Temporal Graph (STG)** é¢„æµ‹æ¨¡å‹åœ¨å¤„ç†**å¤§è§„æ¨¡å›¾**ï¼ˆæ•°åƒèŠ‚ç‚¹ï¼‰å’Œ**é•¿æ—¶åŸŸé¢„æµ‹**ï¼ˆå¦‚ä¸€å‘¨ã€672æ­¥ï¼‰æ—¶é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼š
- **è®¡ç®—å¤æ‚åº¦é«˜**ï¼šä¼ ç»Ÿ GNN å’Œ self-attention æ¨¡å—å…·æœ‰ $O(N^2)$ å’Œ $O(T^2)$ çš„ç©ºé—´-æ—¶é—´äº¤äº’å¤æ‚åº¦ï¼Œéš¾ä»¥æ‰©å±•ã€‚
- **ä¿¡æ¯å‹ç¼©å¯¼è‡´è¯­ä¹‰æŸå¤±**ï¼šä¸ºé™ä½å¤æ‚åº¦è€Œé‡‡ç”¨çš„æ—¶é—´åºåˆ—å‹ç¼©æ–¹æ³•ï¼ˆå¦‚çº¿æ€§æŠ•å½±ï¼‰å¾€å¾€é‡‡ç”¨â€œä¸€åˆ€åˆ‡â€ç­–ç•¥ï¼Œå¿½ç•¥äº†ä¸åŒèŠ‚ç‚¹å’Œæ—¶æ®µä¹‹é—´çš„**å¼‚è´¨æ€§**ï¼ˆheterogeneityï¼‰ï¼Œé€ æˆè¡¨ç¤ºåŒè´¨åŒ–å’Œç²¾åº¦ä¸‹é™ã€‚

### æå‡ºçš„æ–°æ–¹æ³•
ä½œè€…æå‡º **FaST**ï¼ˆFast long-horizon forecasting frameworkï¼‰ï¼Œä¸€ä¸ªåŸºäº **Mixture-of-Experts (MoE)** çš„é«˜æ•ˆä¸”æœ‰æ•ˆçš„é•¿æ—¶åŸŸå¤§è§„æ¨¡ STG é¢„æµ‹æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰å¼‚è´¨æ€§æ„ŸçŸ¥çš„ MoE æ—¶é—´å‹ç¼©è¾“å…¥æ¨¡å—ï¼ˆHeterogeneity-aware MoE-based Temporal Compressionï¼‰
- å°†å†å²æ—¶é—´åºåˆ—é€šè¿‡å¤šä¸ªå¯å­¦ä¹ çš„ä¸“å®¶ç½‘ç»œï¼ˆexpertsï¼‰è¿›è¡Œå‹ç¼©ï¼Œç”Ÿæˆä½ç»´ç¨ å¯†åµŒå…¥ã€‚
- å¼•å…¥ **Heterogeneity-Aware Router (HA-Router)**ï¼ŒåŠ¨æ€åœ°ä¸ºæ¯ä¸ªèŠ‚ç‚¹å’Œæ—¶é—´çª—å£é€‰æ‹©æœ€åˆé€‚çš„ä¸“å®¶è·¯å¾„ï¼Œä»è€Œä¿ç•™æ—¶ç©ºå¼‚è´¨æ€§ï¼Œé¿å…ä¿¡æ¯åŒè´¨åŒ–ã€‚

#### ï¼ˆ2ï¼‰è‡ªé€‚åº”å›¾ä»£ç†æ³¨æ„åŠ›æœºåˆ¶ï¼ˆAdaptive Graph Agent Attention, AGA-Attï¼‰
- å¼•å…¥å°‘é‡å¯å­¦ä¹ çš„ **agent tokens**ï¼ˆ$a \ll N$ï¼‰ä½œä¸ºä¸­ä»‹ï¼Œæ›¿ä»£å…¨å›¾èŠ‚ç‚¹é—´çš„ç›´æ¥äº¤äº’ã€‚
- é€šè¿‡ `Node-to-Agent` èšåˆå’Œ `Agent-to-Node` åˆ†å‘æœºåˆ¶ï¼Œå°†ç©ºé—´äº¤äº’å¤æ‚åº¦ä» $O(N^2)$ é™è‡³ $O(Na)$ï¼Œå®ç°çº¿æ€§æ‰©å±•ã€‚

#### ï¼ˆ3ï¼‰å¹¶è¡ŒåŒ– GLU-MoE æ¨¡å—
- åœ¨ç½‘ç»œä¸»å¹²ä¸­ç”¨ **GLU-based Experts** æ›¿ä»£ä¼ ç»Ÿçš„ FFN å±‚ã€‚
- è®¾è®¡é«˜æ•ˆçš„å¹¶è¡Œè®¡ç®—æœºåˆ¶ï¼Œå°†å¤šä¸ªä¸“å®¶çš„çº¿æ€§å˜æ¢åˆå¹¶ä¸ºå•å±‚æ“ä½œï¼Œæ˜¾è‘—æå‡è®¡ç®—æ•ˆç‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **çº¿æ€§å¤æ‚åº¦**ï¼šæ•´ä½“è®¡ç®—å’Œå†…å­˜å¤æ‚åº¦å¯¹èŠ‚ç‚¹æ•° $N$ å’Œæ—¶é—´æ­¥ $T$ å‡ä¸ºçº¿æ€§ï¼Œæ”¯æŒå¤§è§„æ¨¡å›¾å’Œé•¿æ—¶åŸŸé¢„æµ‹ã€‚
- **ä¿æŒè¡¨è¾¾èƒ½åŠ›**ï¼šé€šè¿‡ MoE å’Œ agent attention æœºåˆ¶ï¼Œåœ¨é™ä½å¤æ‚åº¦çš„åŒæ—¶ä¿ç•™äº†ä¸°å¯Œçš„æ—¶ç©ºä¾èµ–å»ºæ¨¡èƒ½åŠ›ã€‚
- **é«˜æ•ˆä¸”å‡†ç¡®**ï¼šåœ¨å¤šä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå®ç°äº†**æœ€ä¼˜é¢„æµ‹ç²¾åº¦**å’Œ**æœ€å¿«è®­ç»ƒ/æ¨ç†é€Ÿåº¦**ï¼Œå°¤å…¶åœ¨ 672 æ­¥é•¿æ—¶åŸŸä»»åŠ¡ä¸­è¡¨ç°çªå‡ºã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
ä½¿ç”¨ **LargeST** åŸºå‡†æ•°æ®é›†ï¼ŒåŒ…å«å››ä¸ªå¤§è§„æ¨¡äº¤é€šæµé‡å­é›†ï¼š

| æ•°æ®é›† | èŠ‚ç‚¹æ•° | æ—¶é—´ç²’åº¦ | æ—¶é—´è·¨åº¦ | æ ·æœ¬é‡ |
|--------|--------|----------|----------|--------|
| SD     | 716    | 15åˆ†é’Ÿ   | 2019å…¨å¹´ | ~25M   |
| GBA    | 2,352  | 15åˆ†é’Ÿ   | 2019å…¨å¹´ | ~82M   |
| GLA    | 3,834  | 15åˆ†é’Ÿ   | 2019å…¨å¹´ | ~134M  |
| CA     | 8,600  | 15åˆ†é’Ÿ   | 2019å…¨å¹´ | ~300M  |

æ•°æ®æŒ‰ 6:2:2 åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†ã€‚

### å®éªŒè®¾ç½®
- **ä»»åŠ¡**ï¼šåŸºäºè¿‡å» 96 ä¸ªæ—¶é—´æ­¥ï¼ˆ1å¤©ï¼‰é¢„æµ‹æœªæ¥ {48, 96, 192, 672} æ­¥ï¼ˆæœ€é•¿ä¸€å‘¨ï¼‰ã€‚
- **ç»Ÿä¸€æ¡†æ¶**ï¼šæ‰€æœ‰æ¨¡å‹åœ¨ **BasicTS** åŸºå‡†æ¡†æ¶ä¸‹å®ç°ï¼Œéšè—ç»´åº¦ç»Ÿä¸€ä¸º 64ã€‚
- **FaST é…ç½®**ï¼šå›ºå®šå‚æ•°ï¼ˆæ— éœ€è°ƒå‚ï¼‰â€”â€” #experts=8, #layers=3, #agents=32, #dim=64ã€‚
- **ç¡¬ä»¶**ï¼šNVIDIA RTX A6000 (48GB GPU)ï¼ŒAMD EPYC CPUã€‚

### è¯„ä¼°æŒ‡æ ‡
- **MAE**, **RMSE**, **MAPE**ï¼šè¶Šå°è¶Šå¥½ã€‚
- **RÂ²**ï¼šè¶Šå¤§è¶Šå¥½ã€‚

### åŸºçº¿æ–¹æ³•
åˆ†ä¸ºä¸¤ç±»ï¼š
- **æ—¶åºä¸­å¿ƒæ–¹æ³•**ï¼ˆTemporal-centricï¼‰ï¼š
  - DLinear, NHITS, CycleNet
- **æ—¶ç©ºä¸­å¿ƒæ–¹æ³•**ï¼ˆSpatial-Temporal-centricï¼‰ï¼š
  - DCRNN, STGCN, GWNet, SGP, STID, STDMAE, BigST, RPMixer, STPGNN, PatchSTG

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
åœ¨ **CA æ•°æ®é›†ï¼ˆ8,600èŠ‚ç‚¹ï¼Œ672æ­¥é¢„æµ‹ï¼‰** ä¸Šï¼ŒFaST è¡¨ç°å¦‚ä¸‹ï¼š
- **MAE**: 24.23
- **RMSE**: 45.09
- **MAPE**: 16.48%
- **RÂ²**: 0.9395

åœ¨æ‰€æœ‰æ•°æ®é›†å’Œé¢„æµ‹é•¿åº¦ä¸Šå‡å–å¾— **SOTA æ€§èƒ½**ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ç²¾åº¦ä¼˜åŠ¿**ï¼š
  - ç›¸æ¯”æœ€ä½³åŸºçº¿ï¼Œ**MAE é™ä½ 4.4%~18.4%**ï¼Œ**MAPE é™ä½æœ€å¤šè¾¾ 19.06%**ï¼ˆç”µåŠ›æ•°æ®é›†ï¼‰ã€‚
  - åœ¨çŸ­æ—¶é¢„æµ‹ï¼ˆ96â†’12ï¼‰ä¸Šä¹Ÿä¼˜äºæ‰€æœ‰åŸºçº¿ï¼ˆè§é™„å½• Table 6ï¼‰ã€‚
- **æ•ˆç‡ä¼˜åŠ¿**ï¼š
  - **è®­ç»ƒé€Ÿåº¦æ¯” SOTA å¿« 1.3Ã—~2.2Ã—**ã€‚
  - åœ¨ CA æ•°æ®é›†ä¸Šï¼ŒFaST è®­ç»ƒæ—¶é—´ä¸º **746ç§’/epoch**ï¼Œè€Œ BigST ä¸º 1,284ç§’/epochã€‚
  - å†…å­˜å¢é•¿æ›´å¹³ç¼“ï¼šä» 96â†’672 æ­¥ï¼ŒFaST å†…å­˜å¢é•¿ **102.7%**ï¼Œè¿œä½äº DLinear (487.3%) å’Œ NHITS (194.8%)ã€‚
- **å¯æ‰©å±•æ€§**ï¼š
  - å¤šä¸ªåŸºçº¿ï¼ˆå¦‚ STGCN, STPGNN, RPMixerï¼‰åœ¨ GLA æˆ– CA æ•°æ®é›†ä¸Šå‡ºç° **OOMï¼ˆå†…å­˜æº¢å‡ºï¼‰**ï¼Œæ— æ³•å®Œæˆè®­ç»ƒã€‚
  - FaST å¯ç¨³å®šè¿è¡Œäºæœ€å¤§è§„æ¨¡æ•°æ®é›†ï¼ˆCAï¼‰ã€‚

### æ¶ˆèå®éªŒç»“æœ
æ¶ˆèå®éªŒéªŒè¯äº†å„ç»„ä»¶çš„é‡è¦æ€§ï¼ˆè§ Figure 4ï¼‰ï¼š
- **w/ LinearInput**ï¼šç”¨çº¿æ€§å±‚æ›¿æ¢ MoE è¾“å…¥æ¨¡å—ï¼Œæ€§èƒ½æ˜¾è‘—ä¸‹é™ â†’ è¯æ˜ **MoE å‹ç¼©çš„æœ‰æ•ˆæ€§**ã€‚
- **w/o HA-MoE**ï¼šç§»é™¤ MoE æ¨¡å—ï¼Œæ€§èƒ½å¤§å¹…ä¸‹é™ï¼ˆå°¤å…¶åœ¨ GBA ä¸Šï¼‰â†’ è¯æ˜ **MoE æ˜¯æ ¸å¿ƒæ¨¡å—**ã€‚
- **w/o HA-Router**ï¼šç§»é™¤å¼‚è´¨æ€§æ„ŸçŸ¥è·¯ç”±ï¼Œæ€§èƒ½ä¸‹é™ â†’ è¯æ˜ **åŠ¨æ€è·¯ç”±å¯¹æ•æ‰å¼‚è´¨æ€§è‡³å…³é‡è¦**ã€‚
- **w/o AGA-Att**ï¼šç§»é™¤ä»£ç†æ³¨æ„åŠ›ï¼Œæ€§èƒ½æ˜¾è‘—ä¸‹é™ â†’ è¯æ˜ **AGA-Att å¯¹ç©ºé—´å»ºæ¨¡çš„å…³é”®ä½œç”¨**ã€‚

æ­¤å¤–ï¼Œ**GLU-Experts vs FFN-Experts** å®éªŒè¡¨æ˜ï¼š
- GLU ç‰ˆæœ¬åœ¨ç²¾åº¦ç›¸è¿‘çš„æƒ…å†µä¸‹ï¼Œ**è®­ç»ƒé€Ÿåº¦æå‡ 1.4Ã—**ï¼ŒéªŒè¯äº†å¹¶è¡ŒåŒ–è®¾è®¡çš„æœ‰æ•ˆæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **FaST æˆåŠŸå®ç°äº†å¤§è§„æ¨¡ã€é•¿æ—¶åŸŸ STG é¢„æµ‹çš„å¯è¡Œæ€§**ï¼šé¦–æ¬¡æ”¯æŒåœ¨æ•°åƒèŠ‚ç‚¹ä¸Šè¿›è¡Œé•¿è¾¾ä¸€å‘¨ï¼ˆ672æ­¥ï¼‰çš„é¢„æµ‹ã€‚
2. **å¼‚è´¨æ€§æ„ŸçŸ¥çš„ MoE è®¾è®¡æ˜¯å…³é”®**ï¼šé€šè¿‡ HA-Router åŠ¨æ€åˆ†é…ä¸“å®¶ï¼Œæœ‰æ•ˆç¼“è§£äº†å‹ç¼©å¸¦æ¥çš„ä¿¡æ¯æŸå¤±å’Œè¡¨ç¤ºåŒè´¨åŒ–é—®é¢˜ã€‚
3. **ä»£ç†æ³¨æ„åŠ›æœºåˆ¶æ˜¾è‘—é™ä½å¤æ‚åº¦**ï¼šAGA-Att å°†ç©ºé—´å¤æ‚åº¦é™è‡³çº¿æ€§ï¼ŒåŒæ—¶ä¿æŒäº†é•¿è·ç¦»ä¾èµ–å»ºæ¨¡èƒ½åŠ›ã€‚
4. **æ•ˆç‡ä¸ç²¾åº¦å…¼å¾—**ï¼šFaST ä¸ä»…ç²¾åº¦æœ€é«˜ï¼Œè€Œä¸”è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦æœ€å¿«ï¼Œå†…å­˜å ç”¨æ›´ä½ï¼Œå…·å¤‡å¼ºå®ç”¨æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ¨¡å‹é…ç½®ä¸ºå›ºå®šå‚æ•°ï¼ˆå¦‚ #experts=8ï¼‰ï¼Œæœªé’ˆå¯¹æ¯ä¸ªæ•°æ®é›†ç²¾ç»†è°ƒä¼˜ï¼Œå¯èƒ½å­˜åœ¨è¿›ä¸€æ­¥ä¼˜åŒ–ç©ºé—´ã€‚
- ä»£ç†æ³¨æ„åŠ›çš„æ•ˆæœä¾èµ–äºâ€œç©ºé—´å†—ä½™â€å‡è®¾ï¼ˆå³èŠ‚ç‚¹è¡Œä¸ºå­˜åœ¨å…±äº«æ¨¡å¼ï¼‰ï¼Œåœ¨é«˜åº¦å¼‚æ„çš„å›¾ä¸­å¯èƒ½éœ€å¢åŠ  agent æ•°é‡ä»¥è¡¥å¿ã€‚
- å®éªŒä¸»è¦é›†ä¸­åœ¨äº¤é€šå’Œç”µåŠ›æ•°æ®ï¼Œå…¶ä»–é¢†åŸŸï¼ˆå¦‚æ°”è±¡ã€ç¤¾äº¤ç½‘ç»œï¼‰çš„æ³›åŒ–èƒ½åŠ›æœ‰å¾…è¿›ä¸€æ­¥éªŒè¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢å°† **time series foundation models** ä¸ FaST ç»“åˆï¼Œè¿›ä¸€æ­¥æå‡æ¨¡å‹çš„é€šç”¨æ€§å’Œå¯è¿ç§»æ€§ã€‚
- æ‰©å±•è‡³æ›´å¤šåº”ç”¨åœºæ™¯ï¼Œå¦‚ç©ºæ°”è´¨é‡é¢„æµ‹ã€èƒ½æºè°ƒåº¦ã€åŸå¸‚äº‹ä»¶é¢„æµ‹ç­‰ã€‚
- è¿›ä¸€æ­¥ä¼˜åŒ– MoE è·¯ç”±æœºåˆ¶ï¼Œæ¢ç´¢æ›´ç»†ç²’åº¦çš„æ—¶ç©ºåŠ¨æ€è·¯ç”±ç­–ç•¥ã€‚

---

> **æºç åœ°å€**ï¼šhttps://github.com/yijizhao/FaST  
> **å‘è¡¨ä¿¡æ¯**ï¼šKDD'26, Jeju Island, Republic of Korea

</details>

---

### 2. [LinguaGame: A Linguistically Grounded Game-Theoretic Paradigm for Multi-Agent Dialogue Generation](https://arxiv.org/abs/2601.04516)

**Authors**: Yuxiao Ye, Yiming Zhang, Yiran Ma, Huiyuan Xie, Huining Zhu, Zhiyuan Liu  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2601.04516v1  

#### Abstract
Large Language Models (LLMs) have enabled Multi-Agent Systems (MASs) where agents interact through natural language to solve complex tasks or simulate multi-party dialogues. Recent work on LLM-based MASs has mainly focused on architecture design, such as role assignment and workflow orchestration. I...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šLinguaGame: A Linguistically Grounded Game-Theoretic Paradigm for Multi-Agent Dialogue Generation**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å½“å‰åŸºäº Large Language Models (LLMs) çš„ Multi-Agent Systems (MASs) å¤šé›†ä¸­äºæ¶æ„è®¾è®¡ï¼ˆå¦‚è§’è‰²åˆ†é…ã€æµç¨‹ç¼–æ’ï¼‰ï¼Œè€Œå¿½è§†äº†**å¤šæ™ºèƒ½ä½“å¯¹è¯ä¸­çš„äº¤äº’è¿‡ç¨‹æœ¬èº«**ã€‚ç‰¹åˆ«æ˜¯ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆæå‡æ™ºèƒ½ä½“åœ¨è‡ªç„¶è¯­è¨€äº¤æµä¸­çš„**æ²Ÿé€šæ•ˆç‡**â€”â€”å³å¦‚ä½•æ›´å‡†ç¡®ã€ç®€æ´åœ°ä¼ è¾¾æ„å›¾ã€‚

æ­¤å¤–ï¼Œå·²æœ‰ game-theoretic MAS æ–¹æ³•é€šå¸¸å°†åšå¼ˆæœºåˆ¶ä¸å…·ä½“ä»»åŠ¡ç›®æ ‡å¼ºè€¦åˆï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›å·®ï¼Œä¸”ä¾èµ–æ¨¡å‹é‡è®­ç»ƒæˆ–è¿­ä»£ç»éªŒç§¯ç´¯ï¼Œè®¡ç®—æˆæœ¬é«˜ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯**
æœ¬æ–‡æå‡ºäº† **LinguaGame**ï¼Œä¸€ç§åŸºäºè¯­è¨€å­¦åŸç†çš„ã€æ¸¸æˆç†è®ºé©±åŠ¨çš„å¤šæ™ºèƒ½ä½“å¯¹è¯ç”ŸæˆèŒƒå¼ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- å°†å¯¹è¯å»ºæ¨¡ä¸ºä¸€ä¸ª **signalling game**ï¼Œå…¶ä¸­å‘é€æ–¹ï¼ˆsenderï¼‰é€šè¿‡è¯­è¨€ä¿¡å·è¡¨è¾¾å…¶**communicative intent**ï¼ˆæ„å›¾ï¼‰å’Œ**strategy**ï¼ˆç­–ç•¥ï¼‰ï¼Œæ¥æ”¶æ–¹ï¼ˆreceiverï¼‰åˆ™æ¨æ–­è¿™äº›éšè—çŠ¶æ€ã€‚
- å¼•å…¥ä¸€ç§**æ— éœ€è®­ç»ƒçš„å‡è¡¡è¿‘ä¼¼ç®—æ³•**ï¼ˆtraining-free equilibrium approximation algorithmï¼‰ï¼Œåœ¨æ¨ç†é˜¶æ®µåŠ¨æ€è°ƒæ•´æ™ºèƒ½ä½“å†³ç­–ï¼Œä¼˜åŒ–æ²Ÿé€šæ•ˆæœã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | LinguaGame çš„ä¼˜åŠ¿ |
|------|------------------|
| **é€šç”¨æ€§** | åšå¼ˆè®¾è®¡åŸºäºè¯­è¨€å­¦ç†è®ºï¼ˆå¦‚ Speech Act Theoryï¼‰ï¼Œè€Œéä»»åŠ¡ç‰¹å®šç›®æ ‡ï¼Œå…·æœ‰æ›´å¼ºçš„è·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ã€‚ |
| **æ•ˆç‡** | æ¨ç†æ—¶å³å¯å®Œæˆå†³ç­–ä¼˜åŒ–ï¼Œæ— éœ€æ¨¡å‹å¾®è°ƒæˆ–åå¤äº¤äº’ç§¯ç´¯ç»éªŒï¼Œå®ç°â€œplug-and-playâ€é›†æˆã€‚ |
| **å¯è§£é‡Šæ€§** | æ˜¾å¼å»ºæ¨¡ intent å’Œ strategyï¼Œå¢å¼ºå¯¹è¯è¡Œä¸ºçš„è¯­ä¹‰å¯è§£é‡Šæ€§ã€‚ |
| **æœ‰æ•ˆæ€§** | åœ¨å¯¹æŠ—æ€§å¼€æ”¾å¯¹è¯åœºæ™¯ä¸­æ˜¾è‘—æå‡æ²Ÿé€šæ•ˆç‡ä¸å†…å®¹è´¨é‡ã€‚ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **Courtroom Proceedingsï¼ˆæ³•åº­å®¡ç†ï¼‰**ï¼šä»â€œä¸­å›½è£åˆ¤æ–‡ä¹¦ç½‘â€ï¼ˆChina Judgments Onlineï¼‰éšæœºé€‰å– 50 ä¸ªçœŸå®æ°‘äº‹æ¡ˆä»¶ï¼Œæå–å½“äº‹äººä¿¡æ¯ä¸æ¡ˆæƒ…ç®€ä»‹ä½œä¸ºè¾“å…¥ã€‚
- **Debatesï¼ˆè¾©è®ºï¼‰**ï¼šä» Quora Argumentation Mining æ•°æ®é›†ä¸­é€‰å– 50 ä¸ªäº‰è®®æ€§å‘½é¢˜ï¼ˆå¦‚â€œå •èƒåº”åˆæ³•åŒ–â€ï¼‰ï¼Œè¦†ç›–æ”¿æ²»ã€ç¤¾ä¼šã€ç§‘æŠ€ç­‰ 20 ä¸ªä¸»é¢˜ã€‚

### **å®éªŒè®¾ç½®**
- **åŸºç¡€ LLM**ï¼šQwen2.5-32Bã€‚
- **MAS æ¶æ„é…ç½®**ï¼š
  - æ³•åº­åœºæ™¯ï¼šæ¨¡æ‹Ÿä¸€å®¡ç¨‹åºï¼ŒåŒ…å«äº”ä¸ªé˜¶æ®µï¼ˆä¸¾è¯è´¨è¯ã€æ³•åº­è°ƒæŸ¥ã€æ³•åº­è¾©è®ºã€æœ€åé™ˆè¿°ã€å®£åˆ¤ï¼‰ï¼Œè§’è‰²ä¸ºæ³•å®˜ã€åŸå‘Šå¾‹å¸ˆã€è¢«å‘Šå¾‹å¸ˆã€‚
  - è¾©è®ºåœºæ™¯ï¼šæ­£ååŒæ–¹äº¤æ›¿å‘è¨€ï¼Œæ— å›ºå®šæµç¨‹ï¼Œç”± LLM åˆ¤æ–­æ˜¯å¦è‡ªç„¶æ”¶æ•›ã€‚
- **Hyperparameters**ï¼š
  - å€™é€‰ utterance æ•°é‡ï¼š3
  - æ„å›¾-ç­–ç•¥æƒé‡ $ w = 0.5 $
  - KL æ­£åˆ™åŒ–ç³»æ•° $ \lambda = 0.1 $
  - è¿­ä»£è½®æ•°ï¼š5000 è½®ç”¨äºå‡è¡¡é€¼è¿‘

### **è¯„ä¼°æŒ‡æ ‡**
é‡‡ç”¨åŒå±‚äººå·¥è¯„ä¼°ä½“ç³»ï¼ˆå…± 8 åç ”ç©¶ç”Ÿæ ‡æ³¨å‘˜ï¼Œæ³•å¾‹ä¸è¯­è¨€å­¦èƒŒæ™¯å„åŠï¼‰ï¼š

#### **Utterance-level Evaluation**
ä»…é’ˆå¯¹ LGMAS ä¸ LLM-based reranking åŸºçº¿ï¼š
- æ¯”è¾ƒâ€œåˆå§‹é¦–é€‰ utteranceâ€ä¸â€œgame-selected winning utteranceâ€çš„ä¼˜åŠ£ã€‚
- åˆ†ç±»ä¸º positive / neutral / negative alternationã€‚

#### **Dialogue-level Evaluation**
å¯¹æ‰€æœ‰ç³»ç»Ÿè¿›è¡Œäº”ç‚¹æå…‹ç‰¹é‡è¡¨è¯„åˆ†ï¼ˆLikert Scaleï¼‰ï¼š
| ç»´åº¦ | å­ç»´åº¦ | å®šä¹‰ |
|------|--------|------|
| **Linguistic form** | Clarity, Conciseness | è¯­æ³•æ­£ç¡®æ€§ã€ç»“æ„è¿è´¯æ€§ã€å†—ä½™ç¨‹åº¦ |
| **Content quality** | Argument, Tactic | è®ºç‚¹åˆç†æ€§ã€é€»è¾‘ä¸€è‡´æ€§ã€å›åº”é€‚åº”æ€§ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| ç³»ç»Ÿ | æè¿° |
|------|------|
| **SDMAS** | æ ‡å‡† MASï¼Œæ—  intent-strategy æˆ–åšå¼ˆæœºåˆ¶ |
| **ISMAS** | åŠ å…¥ intent-strategy æ¡ä»¶ç”Ÿæˆï¼ˆChain-of-Thought é£æ ¼ï¼‰ï¼Œä½†æ— åšå¼ˆæ¨ç† |
| **LGMAS** | å®Œæ•´ LinguaGame æ¡†æ¶ï¼ˆintent + strategy + game-theoretic selectionï¼‰ |
| **LLM-based reranking** | ä½¿ç”¨ Qwen2.5-32Bã€Llama-3.1-70Bã€DeepSeek-V3 å¯¹å€™é€‰ utterance è¿›è¡Œå•æ¬¡æ‰“åˆ†é‡æ’åº |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 1ï¼‰**

| ç³»ç»Ÿ | åœºæ™¯ | Clarity | Conciseness | Argument | Tactic | å¹³å‡å¾—åˆ† |
|------|------|---------|-------------|----------|--------|----------|
| SDMAS | Court | 4.10 | 3.55 | 3.18 | 3.28 | 3.53 |
| SDMAS | Debate | 4.15 | 3.62 | 3.27 | 3.39 | 3.61 |
| SDMAS | Overall | 4.13 | 3.59 | 3.23 | 3.34 | 3.57 |
| ISMAS | Court | 4.18 | 3.73 | 3.23 | 3.35 | 3.62 |
| ISMAS | Debate | 4.22 | 3.69 | 3.34 | 3.42 | 3.67 |
| ISMAS | Overall | 4.20 | 3.71 | 3.29 | 3.39 | 3.65 |
| **LGMAS** | **Court** | **4.36** | **4.12** | **3.83** | **3.96** | **4.07** |
| **LGMAS** | **Debate** | **4.42** | **4.19** | **3.92** | **4.05** | **4.15** |
| **LGMAS** | **Overall** | **4.39** | **4.16** | **3.88** | **4.01** | **4.11** |

> âœ… æ‰€æœ‰ç»´åº¦ä¸Š LGMAS å‡æ˜¾è‘—ä¼˜äº SDMAS å’Œ ISMASï¼ˆ$ p < 0.01 $ï¼ŒåŒå°¾é…å¯¹ t æ£€éªŒï¼‰

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- **LGMAS ç›¸æ¯” SDMAS**ï¼š
  - Clarity â†‘ 0.26
  - Conciseness â†‘ 0.57
  - Argument â†‘ 0.65
  - Tactic â†‘ 0.67
- **LGMAS ç›¸æ¯” ISMAS**ï¼š
  - è¡¨æ˜ä»…å¼•å…¥ intent-strategy conditioning ä¸è¶³ä»¥å¸¦æ¥å®è´¨æ€§æå‡ï¼Œå¿…é¡»ç»“åˆ game-theoretic reasoning æ‰èƒ½å®ç°å…¨é¢æ”¹è¿›ã€‚

### **æ¶ˆèå®éªŒç»“æœ**
- **ISMAS vs SDMAS**ï¼šä»…åœ¨æ„å›¾-ç­–ç•¥æ¡ä»¶ä¸‹ï¼Œconciseness æœ‰æ˜¾è‘—æå‡ï¼ˆ+0.12ï¼‰ï¼Œå…¶ä»–ç»´åº¦æ— æ˜¾è‘—å·®å¼‚ â†’ è¯´æ˜ intent-conditioning åªèƒ½ä¿ƒè¿›æ›´èšç„¦è¡¨è¾¾ï¼Œä½†æ— æ³•æå‡è®ºè¯è´¨é‡å’Œæˆ˜æœ¯è¿è´¯æ€§ã€‚
- **LGMAS vs ISMAS**ï¼šåœ¨ç›¸åŒ intent-strategy å…ˆéªŒä¸‹ï¼ŒLGMAS ä»å¤§å¹…é¢†å…ˆ â†’ æ”¹è¿›æ¥æºäºæ›´æœ‰æ•ˆçš„ **utterance selection**ï¼Œè€Œé intent/strategy é€‰æ‹©åå·®ã€‚

### **Utterance-level Evaluation ç»“æœï¼ˆTable 2ï¼‰**

| æ–¹æ³• | Positive (%) | Neutral (%) | Negative (%) | Altered Utterances |
|------|--------------|-------------|--------------|--------------------|
| **LGMAS** | **78.1%** | 12.4% | 9.5% | 1,366 |
| Qwen2.5 reranker | 44.0% | 38.4% | 17.6% | 318 |
| Llama-3.1 reranker | 36.7% | 40.8% | 22.5% | 1,503 |
| DeepSeek-V3 reranker | 51.2% | 14.6% | 34.2% | 972 |

> âœ… LinguaGame çš„ game-theoretic selection åœ¨å±€éƒ¨è¿è´¯æ€§å’Œé€‚å½“æ€§æ–¹é¢è¿œè¶…é€šç”¨ LLM é‡æ’åºæ–¹æ³•ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **å»ºæ¨¡å¯¹è¯ä¸º intent-strategy å±‚é¢çš„ signalling game èƒ½æ˜¾è‘—æå‡æ²Ÿé€šæ•ˆç‡**ï¼š
   - æ™ºèƒ½ä½“èƒ½ç”Ÿæˆæ›´æ¸…æ™°ã€ç®€æ´ã€é€»è¾‘ä¸€è‡´ä¸”å…·ç­–ç•¥å“åº”æ€§çš„å›å¤ã€‚
2. **LinguaGame çš„ä¼˜åŠ¿æ¥è‡ªâ€œæ›´ä¼˜çš„è¡¨è¾¾æ–¹å¼â€ï¼Œè€Œéâ€œæ›´å¥½çš„æ„å›¾é€‰æ‹©â€**ï¼š
   - ISMAS ä¸ LGMAS ä½¿ç”¨ç›¸åŒçš„ intent/strategy å…ˆéªŒï¼Œå·®è·æºäº utterance selection æœºåˆ¶ã€‚
3. **è®­ç»ƒ-free çš„å‡è¡¡é€¼è¿‘æœºåˆ¶é«˜æ•ˆå®ç”¨**ï¼š
   - æ— éœ€å¾®è°ƒæˆ–å¤šæ¬¡äº¤äº’ï¼Œåœ¨æ¨ç†æ—¶å³å¯å®Œæˆé«˜è´¨é‡å†³ç­–è°ƒæ•´ï¼Œé€‚åˆéƒ¨ç½²åœ¨å¤šæ ·åŒ– MAS åœºæ™¯ä¸­ã€‚
4. **è¯­è¨€å­¦é©±åŠ¨çš„è®¾è®¡å¢å¼ºäº†æ³›åŒ–æ½œåŠ›**ï¼š
   - åŸºäº Speech Act Theory å’Œ Argumentation Schemes è®¾è®¡ intent/strategy ä½“ç³»ï¼Œä½¿å…¶é€‚ç”¨äºä¸åŒé¢†åŸŸã€‚

### **å±€é™æ€§**
1. **ä»»åŠ¡ç›®æ ‡èŒƒå›´æœ‰é™**ï¼š
   - å½“å‰ç ”ç©¶èšç„¦äºå¯¹è¯è¿‡ç¨‹è´¨é‡ï¼ˆcommunication efficiencyï¼‰ï¼ŒæœªéªŒè¯å…¶å¯¹ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ï¼ˆå¦‚åˆ¤å†³å‡†ç¡®æ€§ã€è¾©è®ºèƒœè´Ÿï¼‰çš„å½±å“ã€‚
2. **è¯„ä¼°åŸŸå—é™ä¸”äººåŠ›æˆæœ¬é«˜**ï¼š
   - å®éªŒé›†ä¸­åœ¨æ³•åº­ä¸è¾©è®ºä¸¤ç±»å¯¹æŠ—æ€§åœºæ™¯ï¼›æ‰©å±•è‡³åä½œå‹ä»»åŠ¡ï¼ˆå¦‚è½¯ä»¶å¼€å‘ã€æ—¥å¸¸å¯¹è¯ï¼‰éœ€å¤§é‡äººå·¥è¯„ä¼°èµ„æºã€‚
3. **è´Ÿè´£ä»» AI è€ƒè™‘ä¸è¶³**ï¼š
   - ä¸å»ºè®®ç›´æ¥ç”¨äºç°å®æ³•å¾‹å†³ç­–ç³»ç»Ÿï¼Œéœ€è¿›ä¸€æ­¥è¯„ä¼°å…¬å¹³æ€§ã€åè§ã€é²æ£’æ€§ç­‰é—®é¢˜ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ¢ç´¢ LinguaGame åœ¨åä½œå‹ MAS ä¸­çš„åº”ç”¨ï¼ˆå¦‚ ChatDev ç±»ç³»ç»Ÿï¼‰ã€‚
- å°† intent-strategy æ¨ç†ä¸ä»»åŠ¡ç»©æ•ˆåé¦ˆç»“åˆï¼Œå½¢æˆé—­ç¯å­¦ä¹ æœºåˆ¶ã€‚
- å¼€å‘è‡ªåŠ¨åŒ–è¯„ä¼°æŒ‡æ ‡ä»¥æ›¿ä»£éƒ¨åˆ†äººå·¥è¯„ä»·ï¼Œé™ä½å®éªŒé—¨æ§›ã€‚
- æ‰©å±•è‡³å¤šæ¨¡æ€æˆ–å¤šè½®è°ˆåˆ¤ç­‰å¤æ‚äº¤äº’åœºæ™¯ã€‚

--- 

> **æ€»ç»“**ï¼šLinguaGame æå‡ºäº†ä¸€ç§æ–°é¢–çš„ã€è¯­è¨€å­¦åŸºç¡€çš„æ¸¸æˆç†è®ºæ¡†æ¶ï¼ŒæˆåŠŸå°† pragmatic communication å»ºæ¨¡ä¸º intent-strategy signalling gameï¼Œå¹¶é€šè¿‡ training-free equilibrium approximation å®ç°é«˜æ•ˆçš„æ¨ç†æ—¶ä¼˜åŒ–ã€‚å®éªŒè¯æ˜å…¶åœ¨æå‡å¤šæ™ºèƒ½ä½“å¯¹è¯çš„æ²Ÿé€šæ•ˆç‡æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œå…·å¤‡è‰¯å¥½çš„é€šç”¨æ€§ä¸å®ç”¨æ€§å‰æ™¯ã€‚

</details>

---

### 3. [RelayLLM: Efficient Reasoning via Collaborative Decoding](https://arxiv.org/abs/2601.05167)

**Authors**: Chengsong Huang, Tong Zheng, Langlin Huang, Jinyuan Li, Haolin Liu, Jiaxin Huang  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2601.05167v1  

#### Abstract
Large Language Models (LLMs) for complex reasoning is often hindered by high computational costs and latency, while resource-efficient Small Language Models (SLMs) typically lack the necessary reasoning capacity. Existing collaborative approaches, such as cascading or routing, operate at a coarse gr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# RelayLLM: Efficient Reasoning via Collaborative Decoding â€”â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶é«˜è®¡ç®—æˆæœ¬å’Œå»¶è¿Ÿé™åˆ¶äº†å®é™…éƒ¨ç½²ã€‚å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰è™½ç„¶é«˜æ•ˆï¼Œä½†åœ¨å¤æ‚æ¨ç†ä¸Šèƒ½åŠ›ä¸è¶³ã€‚ç°æœ‰çš„åä½œæ–¹æ³•ï¼ˆå¦‚ cascading æˆ– routingï¼‰é€šå¸¸ä»¥**æŸ¥è¯¢çº§åˆ«**ï¼ˆquery-levelï¼‰è¿›è¡Œå†³ç­–ï¼Œä¸€æ—¦åˆ¤å®šä»»åŠ¡å›°éš¾ï¼Œå°±å°†æ•´ä¸ªç”Ÿæˆä»»åŠ¡äº¤ç»™ LLMï¼Œå¯¼è‡´â€œ**å…¨æœ‰æˆ–å…¨æ— **â€ï¼ˆall-or-nothingï¼‰çš„ç²—ç²’åº¦è°ƒåº¦ï¼Œé€ æˆå¤§é‡ä¸å¿…è¦çš„è®¡ç®—å¼€é”€ã€‚

### âœ… æå‡ºçš„æ–°æ–¹æ³•ï¼šRelayLLM
ä½œè€…æå‡º **RelayLLM**ï¼Œä¸€ç§åŸºäº**token-level ååŒè§£ç **ï¼ˆtoken-level collaborative decodingï¼‰çš„æ–°å‹æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å°† LLM è§†ä¸ºä¸€ä¸ªå¯æŒ‰éœ€è°ƒç”¨çš„â€œå·¥å…·â€ï¼Œè€Œéå¤‡ç”¨ç”Ÿæˆå™¨ã€‚
- SLM ä½œä¸ºä¸»æ§åˆ¶å™¨ï¼Œåœ¨æ¨ç†è¿‡ç¨‹ä¸­è‡ªä¸»å†³å®šæ˜¯å¦ã€ä½•æ—¶ä»¥åŠè°ƒç”¨å¤šå°‘ä¸ª token çš„ LLM è¾“å‡ºã€‚
- å¼•å…¥ç‰¹æ®Šå‘½ä»¤ `<call>n</call>`ï¼Œå…è®¸ SLM åœ¨é‡åˆ°å…³é”®æ¨ç†æ­¥éª¤æ—¶æš‚åœè‡ªèº«ç”Ÿæˆï¼Œè¯·æ±‚ LLM ç”ŸæˆæŒ‡å®šæ•°é‡çš„ tokenï¼Œä¹‹åç»§ç»­æ¨ç†ã€‚

### âœ… ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ cascading/routingï¼‰ | RelayLLM |
|------|-------------------------------|----------|
| è°ƒåº¦ç²’åº¦ | Query-levelï¼ˆç²—ç²’åº¦ï¼‰ | **Token-level**ï¼ˆç»†ç²’åº¦ï¼‰ |
| æ§åˆ¶æœºåˆ¶ | å¤–éƒ¨è·¯ç”±å™¨æˆ–é™æ€è§„åˆ™ | **SLM è‡ªä¸»æ§åˆ¶**ï¼ˆactive controllerï¼‰ |
| æˆæœ¬æ•ˆç‡ | é«˜è°ƒç”¨ç‡ï¼Œæµªè´¹ä¸¥é‡ | **æä½ token è°ƒç”¨ç‡**ï¼ˆä»… 1.07%ï¼‰ |
| æ€§èƒ½æå‡ | æœ‰é™ | æ˜¾è‘—æå‡å‡†ç¡®ç‡ï¼ˆ+6.9% vs. random routerï¼‰ |
| æ— éœ€é¢å¤–æ§åˆ¶å™¨ | âŒ é€šå¸¸éœ€è¦ | âœ… **æ— é¢å¤–å‚æ•°æˆ–æ¨¡å—** |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
å®éªŒåœ¨å…­ä¸ªæ•°å­¦æ¨ç†åŸºå‡†ä¸Šè¿›è¡Œï¼š
- **Minerva**
- **MATH-500**
- **GSM8K**
- **Olympiad-Bench**
- **AIME-2024**
- **AIME-2025**

æ­¤å¤–è¿˜æµ‹è¯•äº†è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›ï¼š
- **Big-Bench Hard (BBEH)**
- **MMLU-Pro**
- **SuperGPQA**

è®­ç»ƒæ•°æ®æ¥è‡ª **DAPO dataset**ï¼ˆå¤§è§„æ¨¡å¼ºåŒ–å­¦ä¹ æ•°æ®é›†ï¼‰ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **å­¦ç”Ÿæ¨¡å‹ï¼ˆSLMï¼‰**ï¼š`Qwen3-0.6B`, `Qwen3-1.7B`
- **æ•™å¸ˆæ¨¡å‹ï¼ˆLLMï¼‰**ï¼š`Qwen3-8B`
- æ‰€æœ‰æ¨¡å‹æ¥è‡ªåŒä¸€æ—ï¼Œç¡®ä¿ tokenization å’Œé£æ ¼ä¸€è‡´æ€§ã€‚
- æ¨ç†æ¨¡å¼ï¼šnon-thinking modeï¼ˆç¦ç”¨å†…éƒ¨æ€ç»´é“¾ï¼‰
- è¯„ä¼°æ–¹å¼ï¼š
  - å¯¹ AIME æ•°æ®é›†ä½¿ç”¨ `avg@32`
  - å…¶ä»–ä½¿ç”¨ `pass@1`ï¼ˆgreedy decodingï¼‰
  - ä½¿ç”¨ **GPT-4o-mini** ä½œä¸ºè¯­ä¹‰è£åˆ¤åˆ¤æ–­è¾“å‡ºæ­£ç¡®æ€§

### ğŸ” è®­ç»ƒæ¡†æ¶ï¼šä¸¤é˜¶æ®µè®­ç»ƒ
1. **Supervised Warm-up**  
   - æ„é€ åˆæˆæ•°æ®ï¼Œéšæœºæ’å…¥ `<call>n</call>` å‘½ä»¤ï¼Œè®­ç»ƒ SLM å­¦ä¼šç”Ÿæˆåˆæ³•è°ƒç”¨æŒ‡ä»¤ã€‚
   - é˜²æ­¢åˆ†å¸ƒåç§»ï¼Œä¿è¯è®­ç»ƒä¸Šä¸‹æ–‡ä¸ SLM è‡ªèº«åˆ†å¸ƒä¸€è‡´ã€‚

2. **Reinforcement Learning with GRPO**  
   - ä½¿ç”¨ **Group Relative Policy Optimization (GRPO)** è¿›è¡Œç­–ç•¥ä¼˜åŒ–ã€‚
   - è®¾è®¡ **context-aware reward**ï¼Œç»“åˆä»»åŠ¡éš¾åº¦åŠ¨æ€è°ƒæ•´å¥–åŠ±ä¿¡å·ã€‚

### ğŸ¯ å¥–åŠ±è®¾è®¡ï¼ˆDifficulty-Aware Rewardï¼‰
å°†æ¯ä¸ª query åˆ†ä¸ºä¸‰ç±»åœºæ™¯å¹¶å·®å¼‚åŒ–å¥–åŠ±ï¼š
| åœºæ™¯ | æè¿° | å¥–åŠ±ç­–ç•¥ |
|------|------|--------|
| **Student-Solvable** | SLM å¯ç‹¬ç«‹è§£å†³ | ç‹¬ç«‹æˆåŠŸå¥–åŠ± +1.5ï¼Œé¼“åŠ±ä¸ä¾èµ– LLM |
| **Teacher-Dependent** | å¿…é¡»è°ƒç”¨ LLM æ‰èƒ½æ­£ç¡® | ä¸è°ƒç”¨ä¸”å¤±è´¥ â†’ æƒ©ç½š -1.0 |
| **Teacher-Unsolvable** | å³ä½¿è°ƒç”¨ä¹Ÿæ— æ³•è§£å†³ | è°ƒç”¨å°è¯•ç»™äºˆå°æ¢ç´¢å¥–åŠ± `r=p(y)` |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | ç±»å‹ | æ˜¯å¦éœ€è¦é¢å¤–æ§åˆ¶å™¨ |
|------|------|------------------|
| **Base Model** | åŸå§‹ SLM | âŒ |
| **GRPO** | å¼ºåŒ–å­¦ä¹ å¾®è°ƒ | âŒ |
| **CITER** | token-level routing æ–¹æ³• | âœ…ï¼ˆéœ€ MLP æ§åˆ¶å™¨ï¼‰ |
| **Random Router** | æŸ¥è¯¢çº§éšæœºè·¯ç”± | âŒ |
| **Perfect Router** | ç†æƒ³æŸ¥è¯¢çº§è·¯ç”±ï¼ˆoracleï¼‰ | âŒ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰

| æ–¹æ³• | å¹³å‡å‡†ç¡®ç‡ï¼ˆQwen3-1.7Bï¼‰ | Avg. Call Ratio |
|------|--------------------------|---------------|
| Base Model | 42.50% | â€” |
| GRPO | 44.06% | â€” |
| CITER | 46.81% | 1.34% |
| **RelayLLM (Simple-Reward)** | **49.30%** | **0.43%** |
| **RelayLLM (Difficulty-Aware)** | **49.52%** | **1.07%** |
| Qwen3-8Bï¼ˆæ•™å¸ˆæ¨¡å‹ï¼‰ | 54.12% | 100% |

> âœ… **RelayLLM å°†å¹³å‡å‡†ç¡®ç‡ä» 42.50% æå‡è‡³ 49.52%ï¼Œç¼©å°äº†çº¦ 60% çš„æ€§èƒ½å·®è·**ã€‚

### ğŸ” ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”
- ç›¸æ¯” **resource-equivalent Random Router**ï¼ŒRelayLLM å®ç° **+6.9% å‡†ç¡®ç‡æå‡**ã€‚
- åœ¨ä»…è°ƒç”¨ **1.07% çš„ token** çš„æƒ…å†µä¸‹ï¼Œè¾¾åˆ°æ¥è¿‘å¤§æ¨¡å‹ï¼ˆ54.12%ï¼‰çš„æ€§èƒ½ã€‚
- ç›¸æ¯” CITERï¼ˆtoken-level routingï¼‰ï¼Œ**å‡†ç¡®ç‡æ›´é«˜ä¸”æ— éœ€é¢å¤–æ§åˆ¶å™¨**ï¼Œæ›´é«˜æ•ˆã€‚

### ğŸ”§ æ¶ˆèå®éªŒç»“æœï¼ˆTable 3ï¼‰

| æ¶ˆèè®¾ç½® | å¹³å‡å‡†ç¡®ç‡ | Call Ratio |
|---------|------------|-----------|
| å®Œæ•´ RelayLLM | **49.52%** | **1.07%** |
| w/o Data Filteringï¼ˆä¸ç­›é€‰éš¾æ ·æœ¬ï¼‰ | 48.76% | **3.30%** â†‘ |
| w/o Independence Incentiveï¼ˆä¸é¼“åŠ±ç‹¬ç«‹ï¼‰ | 49.34% | **4.10%** â†‘ |
| w/o Exploration Rewardï¼ˆä¸é¼“åŠ±æ¢ç´¢ï¼‰ | **47.56%** â†“ | 0.65% |

> ğŸ’¡ ç»“è®ºï¼š
- **æ•°æ®è¿‡æ»¤**å¯é¿å…æ— æ•ˆè°ƒç”¨ï¼Œæ˜¾è‘—é™ä½æˆæœ¬ã€‚
- **é¼“åŠ±ç‹¬ç«‹æˆåŠŸ**é˜²æ­¢è¿‡åº¦ä¾èµ– LLMã€‚
- **æ¢ç´¢å¥–åŠ±**å¯¹å¤„ç†æç«¯éš¾é¢˜è‡³å…³é‡è¦ã€‚

### ğŸ”„ åŠ¨æ€é•¿åº¦ vs å›ºå®šé•¿åº¦è°ƒç”¨ï¼ˆTable 5 & 6ï¼‰
| æ–¹æ³• | å¹³å‡å‡†ç¡®ç‡ | Call Ratio |
|------|------------|-----------|
| Fixed-20 | 49.41% | 1.32% |
| Fixed-100 | 49.56% | 2.87% |
| Fixed-500 | 51.17% | 5.37% |
| **RelayLLMï¼ˆåŠ¨æ€é¢„æµ‹ï¼‰** | **49.52%** | **1.07%** âœ… |

> âœ… RelayLLM åœ¨ç²¾åº¦å‡ ä¹æŒå¹³çš„æƒ…å†µä¸‹ï¼Œ**è®¡ç®—æˆæœ¬ä»…ä¸º Fixed-100 çš„ ~37%**ï¼Œè¯æ˜å…¶â€œæŒ‰éœ€è°ƒç”¨â€ç­–ç•¥æä¸ºé«˜æ•ˆã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **ç»†ç²’åº¦åä½œä¼˜äºç²—ç²’åº¦è°ƒåº¦**  
   token-level åä½œèƒ½ç²¾å‡†è¯†åˆ«å…³é”®æ¨ç†èŠ‚ç‚¹ï¼Œæå¤§å‡å°‘å†—ä½™è®¡ç®—ã€‚

2. **SLM å¯å­¦ä¼šæˆ˜ç•¥æ€§æ±‚åŠ©è¡Œä¸º**  
   é€šè¿‡ GRPO + Difficulty-Aware Rewardï¼ŒSLM èƒ½è‡ªä¸»åˆ¤æ–­ä½•æ—¶è¯¥æ±‚åŠ©ã€ä½•æ—¶åº”ç‹¬ç«‹å®Œæˆã€‚

3. **æä½æˆæœ¬å®ç°é«˜æ€§èƒ½**  
   ä»…è°ƒç”¨ **1.07% çš„ LLM token**ï¼Œå³å¯å®ç°æ¥è¿‘å¤§æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œ**è®¡ç®—æˆæœ¬é™ä½ 98.2%**ã€‚

4. **å…·å¤‡è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›**  
   åœ¨æœªè§è¿‡çš„éæ•°å­¦ä»»åŠ¡ï¼ˆå¦‚ MMLU-Proï¼‰ä¸Šä»è¡¨ç°ä¼˜å¼‚ï¼Œè¯´æ˜å¸®åŠ©å¯»æ±‚è¡Œä¸ºå…·æœ‰é€šç”¨æ€§ã€‚

5. **å†…åœ¨æ¨ç†èƒ½åŠ›å¾—åˆ°å¢å¼º**  
   åœ¨â€œæ— æ•™å¸ˆâ€æµ‹è¯•ä¸­ï¼ˆç¦æ­¢è°ƒç”¨ LLMï¼‰ï¼ŒRelayLLM ä»ä¼˜äºåŸºçº¿ï¼Œè¡¨æ˜å…¶åœ¨è®­ç»ƒä¸­å†…åŒ–äº†éƒ¨åˆ†ä¸“å®¶æ¨ç†æ¨¡å¼ã€‚

### âš ï¸ å±€é™æ€§
- å½“å‰æ–¹æ³•ä¾èµ–äº LLM è¾“å‡ºè´¨é‡ï¼›è‹¥ LLM æœ¬èº«æ— æ³•è§£å†³é—®é¢˜ï¼ˆTeacher-Unsolvableï¼‰ï¼Œæ•ˆæœå—é™ã€‚
- å¥–åŠ±è®¾è®¡ä¾èµ–å¯éªŒè¯ä»»åŠ¡ï¼ˆå¦‚æ•°å­¦é¢˜ï¼‰ï¼Œéš¾ä»¥ç›´æ¥è¿ç§»åˆ°å¼€æ”¾ç”Ÿæˆä»»åŠ¡ã€‚
- è·¨æ¨¡å‹åˆ†å¸ƒå¯¹é½æ•æ„Ÿï¼šæ¢ç”¨ä¸åŒ LLM ä½œä¸ºæ•™å¸ˆå¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™ï¼ˆè§ Figure 3ï¼‰ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•åˆ°å¤šæ¨¡æ€æˆ–å¤šå·¥å…·ååŒåœºæ™¯ï¼ˆå¦‚ä»£ç æ‰§è¡Œã€æœç´¢ç­‰ï¼‰ã€‚
- æ¢ç´¢æ›´é€šç”¨çš„å¸®åŠ©ä¿¡å·å»ºæ¨¡æ–¹å¼ï¼Œé€‚ç”¨äºä¸å¯éªŒè¯ä»»åŠ¡ã€‚
- ç ”ç©¶å¦‚ä½•è®© SLM æ›´å¥½åœ°â€œå¸æ”¶â€ä¸“å®¶çŸ¥è¯†ï¼Œè¿›ä¸€æ­¥å‡å°‘å¯¹å¤–éƒ¨æ¨¡å‹çš„ä¾èµ–ã€‚
- æ¢ç´¢è‡ªé€‚åº”è°ƒç”¨é•¿åº¦çš„ç«¯åˆ°ç«¯å­¦ä¹ æœºåˆ¶ã€‚

---

## æ€»ç»“
**RelayLLM** æ˜¯ä¸€ç§æå…·æ½œåŠ›çš„é«˜æ•ˆæ¨ç†æ¡†æ¶ï¼Œå®ƒé€šè¿‡ **token-level ååŒè§£ç  + SLM ä¸»åŠ¨æ§åˆ¶ + éš¾åº¦æ„ŸçŸ¥å¼ºåŒ–å­¦ä¹ **ï¼Œå®ç°äº†â€œ**å°æ¨¡å‹ä¸»å¯¼ã€å¤§æ¨¡å‹è¾…åŠ©**â€çš„ç†æƒ³åä½œèŒƒå¼ã€‚å…¶ä¸ä»…å¤§å¹…æå‡äº† SLM çš„æ¨ç†èƒ½åŠ›ï¼Œè€Œä¸”ä»¥æä½ä»£ä»·é€¼è¿‘ LLM è¡¨ç°ï¼Œä¸ºèµ„æºå—é™ç¯å¢ƒä¸‹çš„æ™ºèƒ½ç³»ç»Ÿæä¾›äº†å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 4. [Safety-Utility Conflicts Are Not Global: Surgical Alignment via Head-Level Diagnosis](https://arxiv.org/abs/2601.04262)

**Authors**: Wang Cai, Yilin Wen, Jinchang Hou, Du Su, Guoqiu Wang, Zhonghou Lv, Chenfu Bao, Yunfang Wu  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2601.04262v1  

#### Abstract
Safety alignment in Large Language Models (LLMs) inherently presents a multi-objective optimization conflict, often accompanied by an unintended degradation of general capabilities. Existing mitigation strategies typically rely on global gradient geometry to resolve these conflicts, yet they overloo...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSafety-Utility Conflicts Are Not Global: Surgical Alignment via Head-Level Diagnosis

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è¿›è¡Œ **safety alignment**ï¼ˆå®‰å…¨å¯¹é½ï¼‰æ—¶ï¼Œå¸¸ä¼´éšç€â€œ**alignment tax**â€â€”â€”å³æ¨¡å‹é€šç”¨èƒ½åŠ›ï¼ˆå¦‚æ¨ç†ã€çŸ¥è¯†é—®ç­”ï¼‰çš„æ˜¾è‘—ä¸‹é™ã€‚ä¼ ç»Ÿæ–¹æ³•å°†æ­¤è§†ä¸ºå…¨å±€å¤šç›®æ ‡ä¼˜åŒ–ï¼ˆMOOï¼‰é—®é¢˜ï¼Œé€šè¿‡è°ƒæ•´æ¢¯åº¦æ–¹å‘ï¼ˆå¦‚ PCGradã€CAGradï¼‰æ¥ç¼“è§£å†²çªï¼Œä½†å¿½ç•¥äº† Transformer å†…éƒ¨çš„ **Modular Heterogeneity**ï¼ˆæ¨¡å—å¼‚è´¨æ€§ï¼‰ï¼Œå¯¼è‡´æ¬¡ä¼˜æƒè¡¡ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼š**CAST**ï¼ˆConflict-Aware Sparse Tuningï¼‰
CAST æ˜¯ä¸€ç§ç»“åˆ **head-level è¯Šæ–­** ä¸ **sparse fine-tuning** çš„æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å®‰å…¨-æ•ˆç”¨å†²çªå¹¶éå…¨å±€åˆ†å¸ƒï¼Œè€Œæ˜¯é›†ä¸­åœ¨å°‘æ•°ç‰¹å®šçš„ **attention heads** ä¸­ã€‚
- é€šè¿‡é¢„å¯¹é½é˜¶æ®µçš„ **head-level conflict diagnosis**ï¼Œè¯†åˆ«å‡ºè¿™äº›é«˜å†²çªå¤´ï¼Œå¹¶åœ¨è®­ç»ƒä¸­è·³è¿‡å®ƒä»¬ï¼Œä»è€Œå®ç°â€œå¤–ç§‘æ‰‹æœ¯å¼â€çš„ç²¾å‡†å¯¹é½ã€‚

#### æ–¹æ³•æµç¨‹ï¼š
1. **Head-Level Conflict Diagnosis**ï¼š
   - æ„å»ºä¸¤ä¸ªæŒ‡æ ‡ï¼š
     - **Optimization Conflict (O)**ï¼šè¡¡é‡å®‰å…¨ç›®æ ‡ä¸æ•ˆç”¨ç›®æ ‡æ¢¯åº¦æ–¹å‘çš„å¤¹è§’ï¼ˆcosine distanceï¼‰ã€‚
     - **Functional Sensitivity (S)**ï¼šé€šè¿‡é›¶æ ·æœ¬æ¶ˆèï¼ˆzero-shot ablationï¼‰è¡¡é‡æŸ head å¯¹é€šç”¨ä»»åŠ¡ vs. å®‰å…¨è¡Œä¸ºçš„é‡è¦æ€§ã€‚
   - åˆæˆç»Ÿä¸€çš„ **Conflict Score**ï¼š`C(h) = O(h) Â· S(h)`ï¼Œç”¨äºæ’åºæ‰€æœ‰ attention headsã€‚
2. **Sparse Tuning Strategy**ï¼š
   - å°† heads æŒ‰ `C(h)` åˆ†æ¡¶ï¼ˆå¦‚ Top-25% ä¸º Risky Zoneï¼ŒBottom-25% ä¸º Safe Zoneï¼‰ã€‚
   - åªæ›´æ–° Safe Zone çš„ headsï¼Œå†»ç»“å…¶ä½™å‚æ•°ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ Full SFT, PCGradï¼‰ | CAST |
|------|-------------------------------|------|
| æ›´æ–°ç²’åº¦ | å…¨å±€å‚æ•°æˆ–ä½ç§©å­ç©ºé—´ï¼ˆLoRAï¼‰ | **head-level ç²¾ç»†æ§åˆ¶** |
| å†²çªå¤„ç† | å‡ ä½•æŠ•å½±ï¼ˆå¿½ç•¥åŠŸèƒ½æ•æ„Ÿæ€§ï¼‰ | **ç»“åˆå‡ ä½• + åŠŸèƒ½æ•æ„Ÿæ€§** |
| å‚æ•°æ•ˆç‡ | é«˜å¼€é”€ï¼ˆå…¨é‡æˆ– LoRAï¼‰ | **ä»…æ›´æ–° 25% headsï¼Œé«˜æ•ˆä¸”å¯è§£é‡Š** |
| æ•ˆæœ | æ˜¾è‘—æŸå¤±é€šç”¨èƒ½åŠ› | **ä¿æŒå®‰å…¨æ€§èƒ½çš„åŒæ—¶æå¤§ä¿ç•™é€šç”¨èƒ½åŠ›** |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
| ç±»å‹ | æ•°æ®é›† | ç”¨é€” |
|------|--------|------|
| **è¯Šæ–­é˜¶æ®µï¼ˆpre-alignmentï¼‰** |  
| - `Dutil` | 500 ä¸ª MMLU æ ·æœ¬ | è¯„ä¼°é€šç”¨èƒ½åŠ›ä¾èµ– |
| - `Dsafe` | 500 ä¸ª WildJailbreak æ¶æ„æç¤º | è·å–æ‹’ç»è¡Œä¸ºæ¢¯åº¦ |
| **è®­ç»ƒé˜¶æ®µ** |  
| - `Dalign` | 10,000 ä¸ª WildJailbreak æ ·æœ¬ï¼ˆå¹³è¡¡å››ç±»ï¼švanilla/adversarial harmful/benignï¼‰ | å®‰å…¨å¾®è°ƒ |
| **è¯„ä¼°é˜¶æ®µ** |  
| - **Safety** | WildJailbreakï¼ˆæµ‹è¯•é›†ï¼‰ã€WildGuardã€DAN | é˜²å¾¡æˆåŠŸç‡ |
| - **Utility** | MMLUã€CSQAï¼ˆçŸ¥è¯†ï¼‰ï¼›GSM8Kã€MATHï¼ˆæ¨ç†ï¼‰ | å‡†ç¡®ç‡ |

### å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼šLlama-3.1-8B-Instructã€Qwen2.5-7B-Instructã€Mistral-7B-v0.2
- **å¾®è°ƒæ–¹å¼**ï¼šLoRAï¼ˆä»…ä½œç”¨äº `Wq` æŸ¥è¯¢æŠ•å½±çŸ©é˜µï¼Œç¡®ä¿ head-level attributionï¼‰
- **è¶…å‚æ•°**ï¼š
  - å­¦ä¹ ç‡ï¼š1e-4
  - è®­ç»ƒè½®æ•°ï¼š1
  - æ‰¹å¤§å°ï¼š8ï¼ˆæœ‰æ•ˆï¼‰
  - LoRA rank: 32
- **å¤šéšæœºç§å­**ï¼š{21, 42, 84}ï¼Œå–å¹³å‡å€¼ä»¥å¢å¼ºé²æ£’æ€§

### è¯„ä¼°æŒ‡æ ‡
- **Safety Performance**ï¼šDefense Success Rateï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰
- **Utility Performance**ï¼šMMLUã€CSQAã€GSM8Kã€MATH å‡†ç¡®ç‡
- **Trade-off Metrics**ï¼š
  - **Utility Cost Ratio (UCR)**ï¼šå•ä½å®‰å…¨å¢ç›Šå¸¦æ¥çš„æ•ˆç”¨æŸå¤±
    $$
    \text{UCR} = \max\left(0, \frac{U_b - U_a}{S_a - S_b + \epsilon}\right)
    $$
  - **MMLU-CR**ï¼šåŒä¸Šï¼Œä»…é’ˆå¯¹ MMLU
  - **è¶Šä½è¶Šå¥½**

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | æè¿° |
|------|------|
| **Full SFT** | å…¨é‡ LoRA å¾®è°ƒæ‰€æœ‰ attention heads |
| **Random-SFT (25%)** | éšæœºé€‰æ‹© 25% heads è¿›è¡Œ LoRA å¾®è°ƒ |
| **PCGrad (PCG)** | æ¢¯åº¦æŠ•å½±æ³•ç¼“è§£å¤šä»»åŠ¡å†²çª |
| **CAST-SFT / CAST-PCG** | åœ¨ Safe/Risky Zone ä¸Šåº”ç”¨ SFT æˆ– PCGrad |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & 2ï¼‰

#### âœ… åœ¨ Llama ä¸Šçš„è¡¨ç°ï¼ˆCAST-SFT Safe Zone vs Full SFTï¼‰
| æŒ‡æ ‡ | Full SFT | CAST-SFT (Safe) | æå‡ |
|------|----------|------------------|------|
| **MMLU** | 46.28 â†’ **55.73** | â†‘ +9.45 pp |
| **GSM8K** | 20.80 â†’ **77.20** | â†‘ +56.4 pp |
| **Safety (Avg)** | 90.61 | 92.62 | â‰ˆæŒå¹³ |
| **UCR** | â€” | **æ˜¾è‘—é™ä½** | æ›´é«˜æ•ˆçš„å®‰å…¨å¯¹é½ |

> **ç»“è®º**ï¼šä»…æ›´æ–° 25% çš„ä½å†²çªå¤´ï¼Œå³å¯æ¢å¤æ¥è¿‘ base model çš„é€šç”¨èƒ½åŠ›ï¼ŒåŒæ—¶è¾¾åˆ°ç”šè‡³è¶…è¿‡ full SFT çš„å®‰å…¨æ€§ã€‚

#### âœ… ä¸å…¶ä»–åŸºçº¿å¯¹æ¯”ï¼ˆå›¾ 3 & 4ï¼‰
- **Pareto Frontiers** æ˜¾ç¤ºï¼š
  - **CAST-SFT (Safe Zone)** åœ¨æ‰€æœ‰æ¨¡å‹ä¸Šå‡ä¸»å¯¼å‰æ²¿ã€‚
  - æ˜¾è‘—ä¼˜äº Full SFTã€Random-SFT å’Œ Risky Zone æ›´æ–°ã€‚
- **CAST + PCGrad** ç»„åˆè¿›ä¸€æ­¥æå‡æ€§èƒ½ï¼Œè¯´æ˜ç»“æ„é€‰æ‹©ä¸å‡ ä½•ä¼˜åŒ–å¯ååŒå¢æ•ˆã€‚

#### âœ… æ¶ˆèå®éªŒç»“æœï¼ˆAppendix Fï¼‰

##### ï¼ˆ1ï¼‰æŒ‡æ ‡å¿…è¦æ€§ï¼ˆTable 8ï¼‰
| æ–¹æ³• | Llama (MMLU-CR, Pearson r) | Qwen (MMLU-CR, r) |
|------|----------------------------|-------------------|
| O(h) only | -0.13 | 1.00 |
| S(h) only | 0.96 | -0.10 |
| **C(h) = OÂ·S** | **0.99** | **1.00** |

> **ç»“è®º**ï¼šå•ä¸€æŒ‡æ ‡å­˜åœ¨ç›²åŒºï¼Œå¿…é¡»è”åˆä¼˜åŒ–å†²çªä¸åŠŸèƒ½æ•æ„Ÿæ€§ã€‚

##### ï¼ˆ2ï¼‰ç¨€ç–æ¯”ä¾‹åˆ†æï¼ˆTable 9ï¼‰
- **Bottom-25% (Safe Zone)** è¾¾åˆ°æœ€ä¼˜æ•ˆç”¨ã€‚
- å¢åŠ è‡³ Bottom-50% åè€Œé™ä½æ€§èƒ½ï¼Œè¡¨æ˜â€œæ›´å¤šå‚æ•° â‰  æ›´å¥½â€ã€‚

##### ï¼ˆ3ï¼‰æ•°æ®æ•ˆç‡ï¼ˆTable 10ï¼‰
- å³ä½¿åªç”¨ **100 ä¸ª MMLU æ ·æœ¬**è¿›è¡Œè¯Šæ–­ï¼Œä»èƒ½å‡†ç¡®è¯†åˆ« Safe Zoneã€‚
- æ”¯æŒè½»é‡çº§éƒ¨ç½²ã€‚

##### ï¼ˆ4ï¼‰é¢†åŸŸè¿ç§»é—®é¢˜ï¼ˆTable 11ï¼‰
- è‹¥ç”¨ **GSM8K æ•°æ®è¯Šæ–­æ¨ç†ä»»åŠ¡**ï¼Œæœ€ä½³åŒºåŸŸä¸å†æ˜¯å°¾éƒ¨ï¼ˆB4ï¼‰ï¼Œè€Œæ˜¯ä¸­é—´æ¡¶ï¼ˆB2/B3ï¼‰ï¼Œå‘ˆç°â€œå€’ U å½¢â€ã€‚
- åŸå› ï¼šå•å¤´æ¶ˆèéš¾ä»¥æ•æ‰å¤æ‚æ¨ç†é“¾çš„ä¾èµ–å…³ç³»ï¼Œå¯¼è‡´æ•æ„Ÿæ€§ä½ä¼°ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **å®‰å…¨-æ•ˆç”¨å†²çªä¸æ˜¯å…¨å±€çš„**ï¼Œè€Œæ˜¯é›†ä¸­åœ¨å°‘æ•°ç‰¹å®š attention headsï¼ˆå°¤å…¶æ˜¯ä¸­æ·±å±‚ï¼‰ã€‚
2. âœ… **é€šç”¨èƒ½åŠ›é€€åŒ–ä¸»è¦æºäºå¯¹é«˜å†²çªå¤´çš„æ›´æ–°**ï¼Œè€Œéæ•´ä½“å¯¹é½è¿‡ç¨‹ã€‚
3. âœ… **CAST èƒ½æœ‰æ•ˆç»•è¿‡è¿™äº›ç“¶é¢ˆ**ï¼Œå®ç°â€œå®‰å…¨ä¸ç‰ºç‰²æ•ˆç”¨â€çš„å¯¹é½ã€‚
4. âœ… **Conflict Score C(h) å…·æœ‰å¼ºé¢„æµ‹åŠ›**ï¼š
   - ä¸ MMLU-CR çš„ Pearson r âˆˆ [0.73, 0.95]
   - æ”¯æŒäº‹å‰é£é™©è¯„ä¼°ï¼Œé¿å…ç›²ç›®è®­ç»ƒã€‚

### æ–¹æ³•çš„å±€é™æ€§ï¼ˆLimitationsï¼‰
1. **Structural Scope**ï¼š
   - å½“å‰ä»…å…³æ³¨ `Wq` æŠ•å½±çŸ©é˜µï¼Œæœªè¦†ç›– MLP å±‚ï¼ˆå å¤§éƒ¨åˆ†å‚æ•°ï¼‰ã€‚
2. **Static Diagnosis**ï¼š
   - å†²çªåœ°å›¾åŸºäºé¢„å¯¹é½çŠ¶æ€ï¼Œå‡è®¾å…¶ç¨³å®šï¼›é•¿æœŸå¾®è°ƒå¯èƒ½å¯¼è‡´â€œconflict driftâ€ã€‚
3. **Task Dependence**ï¼š
   - è¯Šæ–­ä¾èµ–æ ¡å‡†é›†ï¼ˆcalibration setï¼‰ï¼Œåœ¨ä»£ç ç”Ÿæˆã€åˆ›æ„å†™ä½œç­‰ç‰¹æ®Šé¢†åŸŸå¯èƒ½å¤±æ•ˆã€‚
4. **Single-Head Ablation çš„å±€é™æ€§**ï¼š
   - å¯¹å¤æ‚æ¨ç†ä»»åŠ¡æ•æ„Ÿæ€§ä¼°è®¡ä¸å‡†ï¼Œéœ€æ›´ç²¾ç»†çš„å¹²é¢„æœºåˆ¶ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è¯Šæ–­è‡³ **MLP å±‚** å’Œ **value/key projections**ã€‚
- è®¾è®¡ **åŠ¨æ€ conflict map**ï¼Œæ”¯æŒåœ¨çº¿æ›´æ–°ã€‚
- æ¢ç´¢ **multi-head ablation** æˆ– **causal tracing** æå‡æ•æ„Ÿæ€§ä¼°è®¡ç²¾åº¦ã€‚
- æ„å»º **domain-specific calibration sets**ï¼Œæå‡è·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ã€‚

---

## æ€»ç»“
è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªèŒƒå¼è½¬å˜ï¼šä»â€œå…¨å±€ä¼˜åŒ–â€è½¬å‘â€œç»“æ„æ„ŸçŸ¥çš„ç²¾å‡†å¹²é¢„â€ã€‚CAST ä¸ä»…æå‡äº† safety-utility trade-offï¼Œè¿˜æä¾›äº†å¯è§£é‡Šçš„è¯Šæ–­å·¥å…·ï¼Œä¸ºæœªæ¥ LLM alignment æä¾›äº†ä¸€æ¡é«˜æ•ˆã€å¯æ§çš„æ–°è·¯å¾„ã€‚

</details>

---

### 5. [Distributed Online Convex Optimization with Efficient Communication: Improved Algorithm and Lower bounds](https://arxiv.org/abs/2601.04907)

**Authors**: Sifan Yang, Wenhao Yang, Wei Jiang, Lijun Zhang  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2601.04907v1  

#### Abstract
We investigate distributed online convex optimization with compressed communication, where $n$ learners connected by a network collaboratively minimize a sequence of global loss functions using only local information and compressed data from neighbors. Prior work has established regret bounds of $O(...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDistributed Online Convex Optimization with Efficient Communication: Improved Algorithm and Lower bounds

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡ç ”ç©¶**åˆ†å¸ƒå¼åœ¨çº¿å‡¸ä¼˜åŒ–ï¼ˆD-OCOï¼‰ä¸­çš„å‹ç¼©é€šä¿¡é—®é¢˜**ï¼Œå³åœ¨å¤šä¸ªå­¦ä¹ è€…ï¼ˆlearnersï¼‰é€šè¿‡ç½‘ç»œåä½œæœ€å°åŒ–å…¨å±€æŸå¤±å‡½æ•°æ—¶ï¼Œå¦‚ä½•åœ¨ä»…ä½¿ç”¨æœ¬åœ°ä¿¡æ¯å’Œé‚»å±…çš„**å‹ç¼©æ•°æ®**è¿›è¡Œé€šä¿¡çš„å‰æä¸‹ï¼Œå®ç°é«˜æ•ˆçš„ä¼˜åŒ–ã€‚

ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ Tu et al., 2022 çš„ DC-DOGDï¼‰å­˜åœ¨ä»¥ä¸‹ç¼ºé™·ï¼š
- **Regret ä¸Šç•Œå¯¹å‹ç¼©è´¨é‡å› å­ `w` çš„ä¾èµ–è¿‡å¼º**ï¼šå…¶ Regret ä¸Šç•Œå…·æœ‰ `O(wâ»Â²)` ç”šè‡³ `O(wâ»â´)` çš„ä¾èµ–ï¼Œè¿™æ„å‘³ç€å½“å‹ç¼©ç‡è¾ƒé«˜ï¼ˆ`w < 1`ï¼‰æ—¶ï¼Œç†è®ºæ€§èƒ½ä¼šæ€¥å‰§ä¸‹é™ã€‚
- **å¯¹å­¦ä¹ è€…æ•°é‡ `n` çš„ä¾èµ–ä¸ç†æƒ³**ï¼šRegret ä¸Šç•Œä¸ `n` å‘ˆè¶…çº¿æ€§å…³ç³»ï¼Œä¸åˆ©äºå¤§è§„æ¨¡ç³»ç»Ÿã€‚
- **ç¼ºä¹ä¸‹ç•Œåˆ†æ**ï¼šæ­¤å‰çš„å·¥ä½œæ²¡æœ‰é’ˆå¯¹å‹ç¼©é€šä¿¡åœºæ™¯å»ºç«‹ Regret çš„ä¸‹ç•Œï¼Œæ— æ³•åˆ¤æ–­ç°æœ‰ä¸Šç•Œçš„ä¼˜åŠ£ã€‚

### æå‡ºçš„æ–°æ–¹æ³•å’Œæ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **Two-level Compressed Decentralized Online Gradient Descent (Top-DOGD)** çš„æ–°ç®—æ³•ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºä¸€ä¸ª**åŒå±‚é˜»å¡æ›´æ–°æ¡†æ¶ï¼ˆtwo-level blocking update frameworkï¼‰**ï¼Œè¯¥æ¡†æ¶æ•´åˆäº†ä¸¤ä¸ªå…³é”®æŠ€æœ¯ï¼š

1.  **åœ¨çº¿å‹ç¼© Gossip ç­–ç•¥ï¼ˆonline compressed gossip strategyï¼‰**ï¼š
    - åœ¨æ¯ä¸ªâ€œå—â€ï¼ˆblockï¼‰çš„å‰åŠéƒ¨åˆ†ï¼Œæ‰§è¡Œå¤šè½®ï¼ˆ`Lâ‚` è½®ï¼‰çš„å‹ç¼© Gossip é€šä¿¡ã€‚
    - è¿™èƒ½æ˜¾è‘—åŠ é€Ÿå­¦ä¹ è€…ä¹‹é—´å†³ç­–çš„ä¸€è‡´æ€§ï¼ˆconsensusï¼‰ï¼Œä»è€Œé™ä½**å…±è¯†è¯¯å·®ï¼ˆconsensus errorï¼‰** å’Œ**å‹ç¼©è¯¯å·®ï¼ˆcompression errorï¼‰**ã€‚

2.  **æŠ•å½±è¯¯å·®è¡¥å¿æ–¹æ¡ˆï¼ˆprojection error compensation schemeï¼‰**ï¼š
    - åœ¨æ¯ä¸ªâ€œå—â€çš„ååŠéƒ¨åˆ†ï¼Œé€’å½’åœ°å‹ç¼©å¹¶ä¼ è¾“ç”±æŠ•å½±æ“ä½œï¼ˆprojectionï¼‰å¼•å…¥çš„æ®‹å·®è¯¯å·®ã€‚
    - è¿™èƒ½æœ‰æ•ˆæ§åˆ¶**æŠ•å½±è¯¯å·®ï¼ˆprojection errorï¼‰**ï¼Œé¿å…å…¶å¯¼è‡´ Regret å¯¹ `n` çš„ä¸è‰¯ä¾èµ–ã€‚

**å…³é”®è®¾è®¡æ€æƒ³**ï¼šé€šè¿‡å°† `T` ä¸ªè¿­ä»£è½®æ¬¡åˆ’åˆ†ä¸ºå¤§å°ä¸º `L = Lâ‚ + Lâ‚‚` çš„â€œå—â€ï¼Œå¹¶åœ¨æ¯ä¸ªå—å†…æ‰§è¡Œ `Lâ‚` è½® Gossip å’Œ `Lâ‚‚` è½®è¯¯å·®è¡¥å¿ï¼Œæœ€ç»ˆåªåœ¨å—ç»“æŸæ—¶æ›´æ–°ä¸€æ¬¡å†³ç­–ã€‚è¿™æ ·ï¼Œè™½ç„¶å†…éƒ¨æœ‰å¤šè½®é€šä¿¡ï¼Œä½†ä»å¤–éƒ¨çœ‹æ¯è½®ä»åªæœ‰ä¸€æ¬¡é€šä¿¡ï¼Œæ»¡è¶³äº† D-OCO çš„çº¦æŸï¼ŒåŒæ—¶å®ç°äº†æ›´ä¼˜çš„è¯¯å·®æ§åˆ¶ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´ä¼˜çš„ Regret ä¸Šç•Œ**ï¼šTop-DOGD æ˜¾è‘—æ”¹è¿›äº† Regret ç•Œé™ã€‚
- **å»ºç«‹äº†é¦–ä¸ªä¸‹ç•Œ**ï¼šè®ºæ–‡é¦–æ¬¡ä¸ºè¯¥é—®é¢˜æä¾›äº† Regret ä¸‹ç•Œï¼Œè¯æ˜äº†å…¶ä¸Šç•Œçš„è¿‘ä¼¼æœ€ä¼˜æ€§ã€‚
- **ç†è®ºä¼˜åŠ¿æ˜æ˜¾**ï¼šå°¤å…¶åœ¨é«˜é€šä¿¡å‹ç¼©ç‡ï¼ˆå° `w`ï¼‰å’Œå¤§è§„æ¨¡ç½‘ç»œï¼ˆå¤§ `n`ï¼‰åœºæ™¯ä¸‹ï¼Œæ–°ç®—æ³•çš„ç†è®ºä¿è¯è¿œä¼˜äºä¹‹å‰çš„å·¥ä½œã€‚

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

éœ€è¦æŒ‡å‡ºçš„æ˜¯ï¼Œè¿™ç¯‡è®ºæ–‡æ˜¯ä¸€ç¯‡**ç†è®ºæ€§å¾ˆå¼ºçš„ç ”ç©¶è®ºæ–‡**ï¼Œå…¶æ ¸å¿ƒè´¡çŒ®æ˜¯ç®—æ³•è®¾è®¡å’Œç†è®ºåˆ†æï¼Œè€ŒéåŸºäºçœŸå®æ•°æ®é›†çš„å®éªŒéªŒè¯ã€‚å› æ­¤ï¼Œæ–‡ä¸­å¹¶æœªæŠ¥å‘Šä¼ ç»Ÿæ„ä¹‰ä¸Šçš„â€œå®éªŒç»“æœâ€ã€‚

### æ–¹æ³•å’Œè®¾ç½®
- **ç†è®ºåˆ†æä¸ºä¸»**ï¼šè®ºæ–‡é€šè¿‡ä¸¥æ ¼çš„æ•°å­¦æ¨å¯¼æ¥è¯æ˜å…¶æå‡ºçš„ Top-DOGD ç®—æ³•çš„ Regret ä¸Šç•Œï¼Œå¹¶æ„é€ ç‰¹å®šçš„å¯¹æŠ—æ€§åœºæ™¯æ¥è¯æ˜å…¶ä¸‹ç•Œã€‚
- **åˆ†æåœºæ™¯**ï¼šåˆ†ææ¶µç›–äº†ä¸¤ç§ä¸»è¦çš„åé¦ˆè®¾ç½®ï¼š
    1.  **å®Œæ•´ä¿¡æ¯åé¦ˆï¼ˆFull Information Feedbackï¼‰**ï¼šå­¦ä¹ è€…å¯ä»¥è·å–æŸå¤±å‡½æ•°çš„æ¢¯åº¦ã€‚
    2.  **Bandit åé¦ˆ**ï¼šå­¦ä¹ è€…åªèƒ½è§‚æµ‹åˆ°æŸå¤±å€¼ï¼Œæ— æ³•ç›´æ¥è·å¾—æ¢¯åº¦ã€‚æ­¤åœºæ™¯åˆç»†åˆ†ä¸ºï¼š
        -   **One-point Bandit Feedback**ï¼šæ¯è½®åªèƒ½æŸ¥è¯¢ä¸€ä¸ªç‚¹çš„æŸå¤±å€¼ã€‚
        -   **Two-point Bandit Feedback**ï¼šæ¯è½®å¯ä»¥æŸ¥è¯¢ä¸¤ä¸ªç‚¹çš„æŸå¤±å€¼ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼šæ ¸å¿ƒè¯„ä¼°æŒ‡æ ‡æ˜¯ **Regret**ï¼Œå®šä¹‰ä¸ºå­¦ä¹ è€…ç´¯è®¡æŸå¤±ä¸æœ€ä¼˜å›ºå®šå†³ç­–ç´¯è®¡æŸå¤±ä¹‹é—´çš„å·®è·ã€‚
- **åŸºçº¿æ–¹æ³•å¯¹æ¯”**ï¼šä¸»è¦ä¸ **Tu et al. (2022)** æå‡ºçš„ **DC-DOGD** æ–¹æ³•è¿›è¡Œç†è®ºä¸Šçš„å¯¹æ¯”ã€‚

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

ç”±äºæ˜¯ç†è®ºå·¥ä½œï¼Œè¿™é‡Œçš„â€œç»“æœâ€æŒ‡çš„æ˜¯**ç†è®ºæ€§èƒ½ç•Œé™**ã€‚

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆRegret ç•Œé™ï¼‰
ä¸‹è¡¨æ€»ç»“äº†æœ¬æ–‡ï¼ˆThis workï¼‰ä¸å…ˆå‰å·¥ä½œï¼ˆTu et al., 2022ï¼‰ä»¥åŠæœ¬æ–‡å»ºç«‹çš„ä¸‹ç•Œï¼ˆLower boundï¼‰çš„å¯¹æ¯”ã€‚å…¶ä¸­ `n` æ˜¯å­¦ä¹ è€…æ•°é‡ï¼Œ`p` æ˜¯é€šä¿¡çŸ©é˜µçš„è°±éš™ï¼ˆspectral gapï¼‰ï¼Œ`w âˆˆ (0,1]` æ˜¯å‹ç¼©è´¨é‡å› å­ï¼Œ`T` æ˜¯æ€»è½®æ•°ã€‚

#### è¡¨ 1ï¼šå®Œæ•´ä¿¡æ¯åé¦ˆä¸‹çš„ Regret ç•Œé™å¯¹æ¯”

| æ¥æº (Source) | æŸå¤±å‡½æ•° (Loss functions) | Regret ä¸Šç•Œ (Upper bounds) | Regret ä¸‹ç•Œ (Lower bounds) |
| :--- | :--- | :--- | :--- |
| Tu et al. (2022) | Convex | `O(max{wâ»Â²pâ»â´nÂ¹/Â², wâ»â´pâ»â¸} nâˆšT)` | - |
| Tu et al. (2022) | Strongly convex | `O(max{wâ»Â²pâ»â´nÂ¹/Â², wâ»â´pâ»â¸} n ln T)` | - |
| **This work** | **Convex** | **`O(wâ»Â¹/Â²pâ»Â¹n âˆš(ln n) âˆšT)`** | **`Î©(wâ»Â¹/Â²pâ»Â¹/â´nâˆšT)`** |
| **This work** | **Strongly convex** | **`O(wâ»Â¹pâ»Â²n ln n ln T)`** | **`Î©(wâ»Â¹pâ»Â¹/Â²n ln T)`** |

#### è¡¨ 2ï¼šBandit åé¦ˆä¸‹çš„ Regret ç•Œé™å¯¹æ¯”

| æ¥æº (Source) | è®¾ç½® (Settings) | Regret ä¸Šç•Œ (Upper bounds) |
| :--- | :--- | :--- |
| Tu et al. (2022) | Convex (1) | `O(max{wâ»Â¹pâ»Â²nÂ¹/â´, wâ»Â²pâ»â´} dÂ¹/Â²n TÂ³/â´)` |
| Tu et al. (2022) | Strongly convex (1) | `O(max{wâ»Â²/Â³pâ»â´/Â³nÂ¹/â¶, wâ»â´/Â³pâ»â¸/Â³} dÂ²/Â³n TÂ²/Â³(ln T)Â¹/Â³)` |
| **This work** | **Convex (1)** | **`O(wâ»Â¹/â´pâ»Â¹/Â²dÂ¹/Â²n (ln n)Â¹/â´ TÂ³/â´)`** |
| **This work** | **Strongly convex (1)** | **`O(wâ»Â¹/Â³pâ»Â²/Â³dÂ²/Â³n (ln n)Â¹/Â³ TÂ²/Â³(ln T)Â¹/Â³)`** |
| Tu et al. (2022) | Convex (2) | `O(max{wâ»Â²pâ»â´nÂ¹/Â², wâ»â´pâ»â¸} d n âˆšT)` |
| Tu et al. (2022) | Strongly convex (2) | `O(max{wâ»Â²pâ»â´nÂ¹/Â², wâ»â´pâ»â¸} dÂ² n ln T)` |
| **This work** | **Convex (2)** | **`O(wâ»Â¹/Â²pâ»Â¹ d n âˆš(ln n) âˆšT)`** |
| **This work** | **Strongly convex (2)** | **`O(wâ»Â¹pâ»Â² dÂ² n ln n ln T)`** |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **åœ¨æ‰€æœ‰åœºæ™¯ä¸‹ï¼Œæœ¬æ–‡æå‡ºçš„ Regret ä¸Šç•Œéƒ½æ˜¾è‘—ä¼˜äº Tu et al. (2022)**ã€‚
- æœ€å¤§çš„æ”¹è¿›ä½“ç°åœ¨å¯¹å‹ç¼©å› å­ `w` çš„ä¾èµ–ä¸Šï¼šä» `O(wâ»Â²)` æˆ– `O(wâ»â´)` æ”¹è¿›åˆ° `O(wâ»Â¹/Â²)` æˆ– `O(wâ»Â¹)`ï¼Œè¿™æ˜¯ä¸€ä¸ªè´¨çš„é£è·ƒã€‚
- åŒæ—¶ï¼Œå¯¹ `n` çš„ä¾èµ–ä¹Ÿå¾—åˆ°äº†æ”¹å–„ï¼ˆæ¶ˆé™¤äº† `max{}` ä¸­çš„ `nÂ¹/Â²` é¡¹ï¼‰ã€‚

### æ¶ˆèå®éªŒç»“æœ
è®ºæ–‡è¿›è¡Œäº†**ç†è®ºä¸Šçš„æ¶ˆèåˆ†æ**ï¼ˆablation analysisï¼‰ï¼Œè®ºè¯äº†æ‰€æä¸¤ä¸ªæŠ€æœ¯ç¼ºä¸€ä¸å¯ï¼š
- **è‹¥ `Lâ‚=1`**ï¼ˆå³ä¸ä½¿ç”¨å¤šæ­¥ Gossipï¼‰ï¼šç®—æ³•é€€åŒ–ä¸º DC-DOGD åŠ ä¸Šè¯¯å·®è¡¥å¿ï¼Œæ— æ³•æ”¹å–„ Regret ç•Œé™ã€‚
- **è‹¥ `Lâ‚‚=0`**ï¼ˆå³ä¸ä½¿ç”¨æŠ•å½±è¯¯å·®è¡¥å¿ï¼‰ï¼šRegret ç•Œé™ä¼šæ¶åŒ–ï¼Œä¾‹å¦‚å¯¹äºå‡¸å‡½æ•°å˜ä¸º `O(wâ»Â¹/Â²pâ»Â¹nâµ/â´ âˆš(ln n) âˆšT)`ï¼Œå¯¹ `n` çš„ä¾èµ–å˜å·®ã€‚

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1.  **æˆåŠŸæ”¹è¿›äº† Regret ç•Œé™**ï¼šé€šè¿‡ Top-DOGD ç®—æ³•ï¼Œå®ç°äº†å¯¹å‹ç¼©é€šä¿¡ D-OCO é—®é¢˜ Regret ç•Œé™çš„é‡å¤§çªç ´ï¼Œç‰¹åˆ«æ˜¯åœ¨ `w` å’Œ `n` çš„ä¾èµ–ä¸Šã€‚
2.  **å»ºç«‹äº†ç†è®ºæœ€ä¼˜æ€§çš„åŸºå‡†**ï¼šé¦–æ¬¡ä¸ºè¯¥é—®é¢˜æä¾›äº† Regret ä¸‹ç•Œï¼Œè¯æ˜äº†å…¶ä¸Šç•Œåœ¨ `w` å’Œ `T` ä¸Šæ˜¯è¿‘ä¹æœ€ä¼˜çš„ï¼ˆup to `p` å’Œ `polylog(n)` å› å­ï¼‰ã€‚
3.  **éªŒè¯äº†åŒå±‚æ¡†æ¶çš„æœ‰æ•ˆæ€§**ï¼šç†è®ºåˆ†æè¡¨æ˜ï¼Œ**åœ¨çº¿å‹ç¼© Gossip** å’Œ **æŠ•å½±è¯¯å·®è¡¥å¿** å¿…é¡»ååŒå·¥ä½œæ‰èƒ½è¾¾åˆ°æœ€ä½³æ•ˆæœã€‚
4.  **æ‰©å±•åˆ° Bandit åœºæ™¯åŒæ ·æœ‰æ•ˆ**ï¼šå°† Top-DOGD ä¸ç»å…¸æ¢¯åº¦ä¼°è®¡å™¨ç»“åˆï¼Œåœ¨ Bandit åé¦ˆåœºæ™¯ä¸‹ä¹Ÿå–å¾—äº†ä¼˜äºç°æœ‰å·¥ä½œçš„ Regret ç•Œé™ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ç¼ºä¹å®è¯éªŒè¯**ï¼šè®ºæ–‡å®Œå…¨åŸºäºç†è®ºåˆ†æï¼Œæ²¡æœ‰åœ¨çœŸå®æˆ–æ¨¡æ‹Ÿçš„æ•°æ®é›†ä¸Šè¿è¡Œç®—æ³•æ¥éªŒè¯å…¶å®é™…æ€§èƒ½ã€‚å…¶ä¼˜åŠ¿ç›®å‰ä»…å­˜åœ¨äºç†è®ºä¸Šã€‚
- **å¤æ‚æ€§å¢åŠ **ï¼šåŒå±‚é˜»å¡æ¡†æ¶å¢åŠ äº†ç®—æ³•çš„å®ç°å¤æ‚åº¦ï¼Œéœ€è¦ä»”ç»†è°ƒæ•´ `Lâ‚` å’Œ `Lâ‚‚` ç­‰å‚æ•°ã€‚
- **å‡è®¾æ¡ä»¶**ï¼šç†è®ºåˆ†æä¾èµ–äºæ ‡å‡†å‡è®¾ï¼Œå¦‚æ¢¯åº¦æœ‰ç•Œã€åŸŸæœ‰ç•Œç­‰ï¼Œè¿™äº›åœ¨æç«¯æƒ…å†µä¸‹å¯èƒ½ä¸æˆç«‹ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **è¿›è¡Œå¤§è§„æ¨¡ä»¿çœŸå®éªŒ**ï¼šåœ¨çœŸå®çš„åˆ†å¸ƒå¼ç¯å¢ƒä¸­å®ç° Top-DOGDï¼Œå¹¶ä¸åŸºçº¿æ–¹æ³•è¿›è¡Œç«¯åˆ°ç«¯çš„æ€§èƒ½æ¯”è¾ƒã€‚
- **æ¢ç´¢æ›´å®ç”¨çš„å‹ç¼©å™¨**ï¼šå°†ç†è®ºåº”ç”¨äºæ›´å…·ä½“çš„é‡åŒ–æˆ–ç¨€ç–åŒ–å‹ç¼©æ–¹æ¡ˆã€‚
- **æ”¾å®½å‡è®¾**ï¼šç ”ç©¶åœ¨éå¹³ç¨³ç¯å¢ƒã€å¼‚æ­¥é€šä¿¡æˆ–åŠ¨æ€ç½‘ç»œæ‹“æ‰‘ä¸‹çš„æ€§èƒ½ã€‚
- **åº”ç”¨äºå…·ä½“ä»»åŠ¡**ï¼šå°†è¯¥æ¡†æ¶ç”¨äºè§£å†³å…·ä½“çš„åˆ†å¸ƒå¼æœºå™¨å­¦ä¹ ä»»åŠ¡ï¼Œå¦‚è”é‚¦å­¦ä¹ ä¸­çš„åœ¨çº¿å­¦ä¹ ã€‚

</details>

---

### 6. [Aligning Text, Code, and Vision: A Multi-Objective Reinforcement Learning Framework for Text-to-Visualization](https://arxiv.org/abs/2601.04582)

**Authors**: Mizanur Rahman, Mohammed Saidul Islam, Md Tahmid Rahman Laskar, Shafiq Joty, Enamul Hoque  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.04582v1  

#### Abstract
Text-to-Visualization (Text2Vis) systems translate natural language queries over tabular data into concise answers and executable visualizations. While closed-source LLMs generate functional code, the resulting charts often lack semantic alignment and clarity, qualities that can only be assessed pos...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Aligning Text, Code, and Vision: A Multi-Objective Reinforcement Learning Framework for Text-to-Visualization*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰çš„ **Text-to-Visualization (Text2Vis)** ç³»ç»Ÿé¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **é—­æºæ¨¡å‹**ï¼ˆå¦‚ GPT-4oï¼‰è™½ç„¶èƒ½ç”Ÿæˆå¯æ‰§è¡Œä»£ç ï¼Œä½†ç”Ÿæˆçš„å›¾è¡¨å¸¸å­˜åœ¨è¯­ä¹‰ä¸ä¸€è‡´ã€è§†è§‰æ··ä¹±ç­‰é—®é¢˜ã€‚
- **å¼€æºæ¨¡å‹**ï¼ˆå°¤å…¶æ˜¯ 7Bâ€“14B è§„æ¨¡ï¼‰åœ¨ä»£ç å¯æ‰§è¡Œæ€§å’Œå¯è§†åŒ–è´¨é‡ä¸Šè¡¨ç°æ›´å·®ï¼Œå¸¸è¾“å‡ºè¯­æ³•é”™è¯¯æˆ–ä¸æŸ¥è¯¢æ„å›¾ä¸ç¬¦çš„å›¾è¡¨ã€‚
- ä¼ ç»Ÿçš„ **Supervised Fine-Tuning (SFT)** æ–¹æ³•ä»…ä¼˜åŒ– token-level æŸå¤±ï¼Œæ— æ³•æ•æ‰â€œæ‰§è¡Œååé¦ˆâ€ï¼ˆpost-execution feedbackï¼‰ï¼Œä¾‹å¦‚å›¾è¡¨çš„å¯è¯»æ€§ã€è¯­ä¹‰å¯¹é½ç­‰ã€‚

### æå‡ºçš„æ–°æ–¹æ³•
ä½œè€…æå‡º **RL-Text2Vis**ï¼Œæ˜¯é¦–ä¸ªä¸“ä¸º Text2Vis è®¾è®¡çš„ **å¼ºåŒ–å­¦ä¹ æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **åŸºäº GRPO çš„è®­ç»ƒæ¶æ„**ï¼šé‡‡ç”¨ **Group Relative Policy Optimization (GRPO)**ï¼Œæ— éœ€è®­ç»ƒä»·å€¼ç½‘ç»œï¼ˆcriticï¼‰ï¼Œé€šè¿‡ç»„å†…å¤šä¸ªè¾“å‡ºçš„ç›¸å¯¹ä¼˜åŠ¿è¿›è¡Œç­–ç•¥æ›´æ–°ï¼Œé«˜æ•ˆä¸”ç¨³å®šã€‚
- **å¤šç›®æ ‡å¥–åŠ±å‡½æ•°ï¼ˆmulti-objective rewardï¼‰**ï¼šè”åˆä¼˜åŒ–ä¸‰ä¸ªç»´åº¦ï¼š
  1. **æ–‡æœ¬å‡†ç¡®æ€§**ï¼ˆ`R_text`ï¼‰ï¼šç”Ÿæˆç­”æ¡ˆæ˜¯å¦ä¸çœŸå®ç­”æ¡ˆè¯­ä¹‰ä¸€è‡´ã€‚
  2. **ä»£ç æœ‰æ•ˆæ€§**ï¼ˆ`R_code`ï¼‰ï¼šä»£ç æ˜¯å¦å¯æ‰§è¡Œ + æ˜¯å¦ç¬¦åˆæŸ¥è¯¢æ„å›¾ã€‚
  3. **å¯è§†åŒ–è´¨é‡**ï¼ˆ`R_vis`ï¼‰ï¼šå›¾è¡¨æ˜¯å¦æ¸…æ™°ã€æ­£ç¡®ã€å¸ƒå±€åˆç†ã€‚
- **ç«¯åˆ°ç«¯æ•´åˆæ‰§è¡Œååé¦ˆ**ï¼šé¦–æ¬¡å°†ä»£ç æ‰§è¡Œã€å›¾è¡¨æ¸²æŸ“åçš„å¤šæ¨¡æ€åé¦ˆï¼ˆæ–‡æœ¬ã€ä»£ç ã€å›¾åƒï¼‰ç›´æ¥ç”¨äº RL è®­ç»ƒï¼Œå®ç°å¯¹å¯è§†åŒ–è´¨é‡çš„é—­ç¯ä¼˜åŒ–ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆSFT / Promptingï¼‰ | RL-Text2Vis |
|------|----------------------------|------------|
| å¯æ‰§è¡Œæ€§ | âœ… å¯æå‡ | âœ…âœ… æ˜¾è‘—æå‡ï¼ˆ78% â†’ 97%ï¼‰ |
| å›¾è¡¨è´¨é‡ | âŒ æ— æ³•ä¼˜åŒ– | âœ…âœ… æ˜¾è‘—æå‡ï¼ˆ+22% è¶…è¶Š GPT-4oï¼‰ |
| å¤šæ¨¡æ€åé¦ˆåˆ©ç”¨ | âŒ æ—  | âœ… æ”¯æŒæ–‡æœ¬ã€ä»£ç ã€å›¾åƒè”åˆè¯„ä¼° |
| éƒ¨ç½²å‹å¥½æ€§ | âœ… å¼€æºå¯ç”¨ | âœ…âœ… å¼€æº + é«˜æ€§èƒ½ + éšç§å®‰å…¨ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | ç±»å‹ | ç‰¹ç‚¹ |
|--------|------|------|
| **Text2Vis** | In-Domain | ä¸»è¦è®­ç»ƒä¸è¯„ä¼°é›†ï¼Œå«è‡ªç„¶è¯­è¨€æŸ¥è¯¢ã€è¡¨æ ¼æ•°æ®ã€å‚è€ƒç­”æ¡ˆä¸ä»£ç ï¼›åˆ†ä¸º `test1`ï¼ˆè®­ç»ƒç”¨ï¼‰å’Œ `test2`ï¼ˆè¯„ä¼°ç”¨ï¼Œ236 æ ·æœ¬ï¼‰ |
| **VIS-Eval** | Out-of-Domain | åŒ…å« 146 ä¸ªæ•°æ®åº“ã€2,524 æŸ¥è¯¢ï¼Œå¼ºè°ƒæ¨¡ç³Šæ˜ å°„ä¸å¤æ‚å¸ƒå±€ |
| **NVBench** | Out-of-Domain | è·¨é¢†åŸŸå¤§è§„æ¨¡æ•°æ®é›†ï¼ˆ105 domain, 7,247 ä»»åŠ¡ï¼‰ï¼Œæµ‹è¯•æ³›åŒ–èƒ½åŠ› |
| **PandasPlotBench** | Out-of-Domain | è¯„ä¼°ä» Pandas DataFrame ç”Ÿæˆç»˜å›¾ä»£ç çš„èƒ½åŠ›ï¼ˆ175 æ ·æœ¬ï¼‰ |

### å®éªŒè®¾ç½®
- **æ¨¡å‹åŸºç¡€**ï¼šåŸºäº **Qwen2.5-Instruct** ç³»åˆ—ï¼ˆ7B å’Œ 14Bï¼‰ï¼Œå¹¶éªŒè¯äº†åœ¨ **Llama-3.1-8B** ä¸Šçš„é€šç”¨æ€§ã€‚
- **è®­ç»ƒæ–¹å¼**ï¼šä½¿ç”¨ GRPO è¿›è¡Œ RL å¾®è°ƒï¼Œæ¯è½®ç”Ÿæˆ G=8 ä¸ªå€™é€‰è¾“å‡ºï¼Œè®¡ç®—ç»„å†…æ ‡å‡†åŒ–ä¼˜åŠ¿ã€‚
- **å¥–åŠ±æœºåˆ¶**ï¼š
  - ç¬¬ä¸€é˜¶æ®µï¼šæ ¼å¼å¥–åŠ±ï¼ˆå¿…é¡»è¿”å›åˆæ³• JSONï¼Œå« `answer` å’Œ `code` å­—æ®µï¼‰
  - ç¬¬äºŒé˜¶æ®µï¼šåŠ æƒç»„åˆå¥–åŠ± $ R = \alpha R_{\text{text}} + \beta R_{\text{code}} + \gamma R_{\text{vis}} $ï¼Œæœ€ä¼˜æƒé‡ä¸º (0.5, 0.25, 0.25)

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Answer Match (%)** | ç”Ÿæˆç­”æ¡ˆæ˜¯å¦ä¸çœŸå®ç­”æ¡ˆåŒ¹é…ï¼ˆå…è®¸è¿‘ä¼¼å€¼ã€ç¼©å†™ç­‰ï¼‰ |
| **Code Exec. Success (%)** | ç”Ÿæˆä»£ç èƒ½å¦æˆåŠŸè¿è¡Œï¼ˆMatplotlibï¼‰ |
| **Chart Readability** | å›¾è¡¨å¯è¯»æ€§è¯„åˆ†ï¼ˆ1â€“5 åˆ†ï¼ŒåŸºäºæ ‡ç­¾ã€é¢œè‰²ã€å­—ä½“ç­‰ï¼‰ |
| **Chart Correctness** | å›¾è¡¨æ˜¯å¦å‡†ç¡®åæ˜ æŸ¥è¯¢æ„å›¾å’Œæ•°æ®ï¼ˆ1â€“5 åˆ†ï¼‰ |
| **Final Pass Rate (%)** | åŒæ—¶æ»¡è¶³ï¼šä»£ç å¯æ‰§è¡Œã€ç­”æ¡ˆæ­£ç¡®ã€å¯è¯»æ€§ â‰¥3.5ã€æ­£ç¡®æ€§ â‰¥3.5 |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»åˆ« | åŸºçº¿æ¨¡å‹ |
|------|---------|
| **é—­æºé›¶æ ·æœ¬** | GPT-4o, Gemini 1.5 Flash, Gemini 2.0 Flash |
| **å¼€æºé›¶æ ·æœ¬** | Llama-3.1-8B, Mistral-7B, CodeLlama-7B/13B, Qwen2.5-7B/14B |
| **ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰** | Qwen2.5-7B-SFT, Qwen2.5-14B-SFT |
| **å…¶ä»– RL æ–¹æ³•** | PPO, DPOï¼ˆæœªä½¿ç”¨ï¼Œå› ç¼ºä¹åå¥½æ•°æ®ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆText2Vis åŸºå‡†ï¼‰

| Model | Code Exec. (%) | Answer Match (%) | Readability | Correctness | Final Pass (%) |
|-------|----------------|------------------|-------------|-------------|----------------|
| GPT-4o (Zero-Shot) | 87 | 39 | 3.32 | 3.30 | 30 |
| Qwen2.5-14B (Zero-Shot) | 78 | 29 | 3.12 | 2.94 | 14 |
| Qwen2.5-14B (SFT) | 87 | 36 | 3.42 | 3.28 | 18 |
| **RL-Text2Vis-14B** | **97** | **35** | **4.10** | **4.03** | **29** |

> âœ… **æ˜¾è‘—æå‡**ï¼š
> - å›¾è¡¨å¯è¯»æ€§ï¼š**+31%**ï¼ˆ3.12 â†’ 4.10ï¼‰
> - å›¾è¡¨æ­£ç¡®æ€§ï¼š**+37%**ï¼ˆ2.94 â†’ 4.03ï¼‰
> - ä»£ç æ‰§è¡ŒæˆåŠŸç‡ï¼š**+24%**ï¼ˆ78% â†’ 97%ï¼‰
> - ç›¸è¾ƒ GPT-4oï¼Œå›¾è¡¨è´¨é‡ **ç›¸å¯¹æå‡ 22%**

### Out-of-Domain æ³›åŒ–èƒ½åŠ›ï¼ˆNVBench ç¤ºä¾‹ï¼‰

| Model | Code Exec. (%) | Readability | Correctness |
|-------|----------------|-------------|-------------|
| Qwen2.5-7B (Zero-Shot) | 75 | 2.64 | 2.34 |
| Qwen2.5-7B (SFT) | 82 | 3.07 | 2.79 |
| **RL-Text2Vis-7B** | **93** | **3.47** | **3.28** |

> âœ… åœ¨è·¨åŸŸä»»åŠ¡ä¸­ä»ä¿æŒå¼ºåŠ²æ€§èƒ½ï¼Œè¯æ˜æ–¹æ³•å…·æœ‰å¼ºæ³›åŒ–æ€§ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

| é…ç½® | Code Exec. (%) | Answer Match (%) | Readability | Correctness | Final Pass (%) |
|------|----------------|------------------|-------------|-------------|----------------|
| Full (All Rewards) | 91 | 31 | 3.84 | 3.86 | 22 |
| - Format Reward | 87 | 25 | 3.38 | 3.25 | 17 |
| - Answer Reward | 89 | 24 | 3.79 | 3.82 | 19 |
| - Code & Visual Reward | 82 | 28 | 2.98 | 3.10 | 13 |
| Only Format Reward | 78 | 25 | 3.02 | 2.88 | 13 |

> ğŸ” ç»“è®ºï¼š
> - ç§»é™¤ä»»ä¸€å¥–åŠ±æ¨¡å—å‡å¯¼è‡´æ€§èƒ½ä¸‹é™
> - **å¤šç›®æ ‡è”åˆä¼˜åŒ–è‡³å…³é‡è¦**ï¼Œå•ç‹¬ä¾èµ–æŸä¸€ä¿¡å·æ— æ³•è¾¾åˆ°æœ€ä½³æ•ˆæœ
> - æ ¼å¼å¥–åŠ±è™½åŸºç¡€ï¼Œä½†å¯¹ç¨³å®šæ€§ä¸å¯æˆ–ç¼º

### å…¶ä»–åˆ†æ
- **äººç±»è¯„ä¼°ä¸€è‡´æ€§é«˜**ï¼šäººå·¥æ ‡æ³¨ä¸ GPT-4o è‡ªåŠ¨è¯„ä¼°çš„ç›¸å…³ç³»æ•°è¾¾ **r â‰ˆ 0.88â€“0.91**
- **é‡‡æ ·æ•°é‡å½±å“**ï¼šæ¯ prompt ç”Ÿæˆ 8 ä¸ªæ ·æœ¬ï¼ˆGen-8ï¼‰æ¯” 4 ä¸ªï¼ˆGen-4ï¼‰æ•ˆæœæ›´å¥½ï¼Œè¯´æ˜æ›´å¤šå€™é€‰æœ‰åŠ©äºç¨³å®š GRPO æ’åº
- **è·¨æ¶æ„æœ‰æ•ˆæ€§**ï¼šåœ¨ Llama-3.1-8B ä¸Šåº”ç”¨ RL-Text2Vis åŒæ ·å¸¦æ¥æ˜¾è‘—æå‡ï¼ŒéªŒè¯æ¡†æ¶é€šç”¨æ€§

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å¤šç›®æ ‡ RL æ˜¯æå‡ Text2Vis è´¨é‡çš„æœ‰æ•ˆè·¯å¾„**ï¼šç›¸æ¯” SFTï¼ŒRL èƒ½æœ‰æ•ˆåˆ©ç”¨æ‰§è¡Œååé¦ˆï¼Œæ˜¾è‘—æå‡å›¾è¡¨è´¨é‡å’Œè¯­ä¹‰å¯¹é½ã€‚
2. **GRPO æ˜¯è½»é‡é«˜æ•ˆçš„ RL ç®—æ³•é€‰æ‹©**ï¼šæ— éœ€ critic æ¨¡å‹ï¼Œé€‚åˆé•¿åºåˆ—ã€å¤šæ¨¡æ€ä»»åŠ¡ï¼Œåœ¨èµ„æºæ•ˆç‡å’Œæ€§èƒ½ä¹‹é—´å–å¾—è‰¯å¥½å¹³è¡¡ã€‚
3. **å¼€æºæ¨¡å‹å¯è¶…è¶Šé—­æºæ¨¡å‹**ï¼šRL-Text2Vis-14B åœ¨å›¾è¡¨å¯è¯»æ€§å’Œæ­£ç¡®æ€§ä¸Š **è¶…è¿‡ GPT-4o**ï¼ŒåŒæ—¶ä»£ç æ‰§è¡Œç‡æ›´é«˜ï¼ˆ97% vs 87%ï¼‰ã€‚
4. **æ–¹æ³•å…·å¤‡å¼ºæ³›åŒ–èƒ½åŠ›**ï¼šåœ¨ VIS-Evalã€NVBench ç­‰ out-of-domain æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œé€‚ç”¨äºå¤šæ ·åŒ–çš„å®é™…åœºæ™¯ã€‚

### å±€é™æ€§
1. **è®¡ç®—æˆæœ¬è¾ƒé«˜**ï¼š14B æ¨¡å‹è®­ç»ƒéœ€ 6Ã—H100 GPUï¼Œè€—æ—¶çº¦ 50 å°æ—¶ï¼Œå¯¹å°æœºæ„ä¸å‹å¥½ã€‚
2. **æœªæ¢ç´¢æ›´å¤§æ¨¡å‹**ï¼šå—é™äºç®—åŠ›ï¼Œæœªåœ¨ 32B æˆ– 72B æ¨¡å‹ä¸ŠéªŒè¯ï¼Œå¯èƒ½å­˜åœ¨è¿›ä¸€æ­¥æå‡ç©ºé—´ã€‚
3. **é¢†åŸŸé€‚åº”æ€§å¾…éªŒè¯**ï¼šåœ¨åŒ»ç–—ã€é‡‘èç­‰ä¸“ä¸šé¢†åŸŸçš„é²æ£’æ€§å°šæœªæµ‹è¯•ã€‚
4. **é™æ€å›¾è¡¨é™åˆ¶**ï¼šç›®å‰ä»…æ”¯æŒé™æ€å¯è§†åŒ–ï¼Œæœªæ¶‰åŠäº¤äº’å¼æˆ–å¤šè§†å›¾åˆ†æã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **äº¤äº’å¼å¯è§†åŒ–ç”Ÿæˆ**ï¼ˆInteractive Visï¼‰
- æ¢ç´¢ **æ›´é«˜æ•ˆçš„ RL æ¶æ„**ï¼ˆå¦‚è’¸é¦ + RLï¼‰
- å¼•å…¥ **ç”¨æˆ·åå¥½åé¦ˆæœºåˆ¶**ï¼Œå®ç°ä¸ªæ€§åŒ–å›¾è¡¨é£æ ¼å®šåˆ¶
- æ„å»º **ä¸“ç”¨å¥–åŠ±æ¨¡å‹**ï¼ˆReward Modelï¼‰æ›¿ä»£é€šç”¨ LLM/VLM åˆ¤æ–­å™¨
- åº”ç”¨äº **å¤šæ¨¡æ€æ•°æ®åˆ†æä»£ç†**ï¼ˆMultimodal Data Science Agentsï¼‰

---

> ğŸ“¢ **æ€»ç»“**ï¼š  
> RL-Text2Vis æˆåŠŸå°† **å¤šç›®æ ‡å¼ºåŒ–å­¦ä¹ ** å¼•å…¥ Text-to-Visualization é¢†åŸŸï¼Œé€šè¿‡ **GRPO + å¤šæ¨¡æ€å¥–åŠ±è®¾è®¡**ï¼Œå®ç°äº†å¯¹æ–‡æœ¬ã€ä»£ç ã€è§†è§‰ä¸‰é‡è´¨é‡çš„ååŒä¼˜åŒ–ã€‚å®éªŒè¯æ˜å…¶ä¸ä»…æ˜¾è‘—ä¼˜äºå„ç±»åŸºçº¿ï¼Œè¿˜èƒ½åœ¨ out-of-domain åœºæ™¯ä¸‹ç¨³å¥æ³›åŒ–ï¼Œä¸ºæ„å»ºé«˜è´¨é‡ã€å¯è§£é‡Šã€å¯éƒ¨ç½²çš„å¯è§†åŒ–ç³»ç»Ÿæä¾›äº†æ–°èŒƒå¼ã€‚

ğŸ”— é¡¹ç›®ä»£ç å·²å¼€æºï¼š[https://github.com/vis-nlp/RL-Text2Vis](https://github.com/vis-nlp/RL-Text2Vis)

</details>

---

### 7. [Learning Dynamics in RL Post-Training for Language Models](https://arxiv.org/abs/2601.04670)

**Authors**: Akiyoshi Tomihari  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.04670v1  

#### Abstract
Reinforcement learning (RL) post-training is a critical stage in modern language model development, playing a key role in improving alignment and reasoning ability. However, several phenomena remain poorly understood, including the reduction in output diversity. To gain a broader understanding of RL...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLearning Dynamics in RL Post-Training for Language Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡èšç„¦äº**å¼ºåŒ–å­¦ä¹ åè®­ç»ƒï¼ˆRL post-trainingï¼‰åœ¨è¯­è¨€æ¨¡å‹ä¸­çš„å­¦ä¹ åŠ¨æ€æœºåˆ¶å°šä¸æ˜ç¡®**çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯ä»¥ä¸‹ç°è±¡ç¼ºä¹ç†è®ºè§£é‡Šï¼š
- **è¾“å‡ºå¤šæ ·æ€§ä¸‹é™**ï¼šRL åè®­ç»ƒå¸¸å¯¼è‡´æ¨¡å‹è¾“å‡ºåˆ†å¸ƒæ›´åŠ é›†ä¸­ï¼Œé™ä½ç”Ÿæˆå¤šæ ·æ€§ã€‚
- **æ¨ç†èƒ½åŠ›æå‡æœ‰é™**ï¼šå°½ç®¡ RL èƒ½æé«˜å¥–åŠ±å¾—åˆ†ï¼Œä½†å¯èƒ½å¹¶æœªçœŸæ­£æ¿€å‘æ–°çš„æ¨ç†æ¨¡å¼ï¼Œè€Œæ˜¯å¯¹å·²æœ‰è¡Œä¸ºè¿›è¡ŒåŠ æƒæ”¾å¤§ï¼ˆ"amplify existing patterns"ï¼‰ã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº†å¯¹ RLHFï¼ˆReinforcement Learning from Human Feedbackï¼‰å’Œ RLVRï¼ˆReinforcement Learning with Verifiable Rewardsï¼‰æœºåˆ¶çš„ç†è§£ä¸ä¼˜åŒ–ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯

ä½œè€…æå‡ºäº†ä¸€ç§åŸºäº**ç»éªŒç¥ç»æ­£åˆ‡æ ¸ï¼ˆempirical Neural Tangent Kernel, NTKï¼‰** çš„åˆ†ææ¡†æ¶ï¼Œç”¨äºå½¢å¼åŒ– RL åè®­ç»ƒçš„å­¦ä¹ åŠ¨æ€ï¼Œå¹¶æ®æ­¤æå‡ºä¸€ç§æ–°çš„ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼š

#### ï¼ˆ1ï¼‰ç†è®ºåˆ†ææ¡†æ¶ï¼šNTK åˆ†è§£
å°† empirical NTK åˆ†è§£ä¸ºä¸¤ä¸ªç»„ä»¶ï¼š
- **Representation Component**ï¼ˆè¡¨ç¤ºåˆ†é‡ï¼‰ï¼šè¡¡é‡ç‰¹å¾å‘é‡ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚
- **Gradient Component**ï¼ˆæ¢¯åº¦åˆ†é‡ï¼‰ï¼šåŒ…å«åˆ†ç±»å™¨ $ W $ å’Œç‰¹å¾æ˜ å°„æ¢¯åº¦ï¼Œåæ˜ å‚æ•°æ›´æ–°çš„æ–¹å‘ã€‚

è¯¥åˆ†è§£æ­ç¤ºäº†ï¼š
- å½“ç‰¹å¾è¡¨ç¤ºé«˜åº¦ç›¸ä¼¼æ—¶ï¼ˆå¦‚è¡¨1æ‰€ç¤ºï¼Œcosine similarity å¹³å‡ > 0.6ï¼‰ï¼Œ**Representation Component ä¼šç³»ç»Ÿæ€§åœ°å¢å¼ºé«˜å¥–åŠ±æ ·æœ¬çš„æ¦‚ç‡ï¼Œå¯¼è‡´è¾“å‡ºåˆ†å¸ƒå°–é”åŒ–ï¼ˆå³ç½®ä¿¡åº¦ä¸Šå‡ã€å¤šæ ·æ€§ä¸‹é™ï¼‰**ã€‚
- å› æ­¤ï¼Œæœ‰æ•ˆçš„å­¦ä¹ ä¾èµ–äº **Gradient Component**ï¼Œè€Œå®ƒæ˜¾å¼ä¾èµ–äºåˆ†ç±»å™¨ $ W $ã€‚

#### ï¼ˆ2ï¼‰æ–°æ–¹æ³•ï¼šClassifier-First Reinforcement Learning (CF-RL)
å—ç›‘ç£å­¦ä¹ ä¸­â€œå…ˆçº¿æ€§æ¢æµ‹å†å¾®è°ƒâ€ï¼ˆLinear Probing then Fine-Tuning, LP-FTï¼‰å¯å‘ï¼Œæå‡º **CF-RL**ï¼š
- **ç¬¬ä¸€é˜¶æ®µ**ï¼šä»…æ›´æ–°åˆ†ç±»å™¨ï¼ˆclassifierï¼‰ï¼Œå†»ç»“å…¶ä½™æ‰€æœ‰å‚æ•°ï¼›
- **ç¬¬äºŒé˜¶æ®µ**ï¼šæ¢å¤æ ‡å‡† RL è®­ç»ƒï¼Œè”åˆä¼˜åŒ–å…¨éƒ¨å‚æ•°ã€‚

è¿™ä¸€è®¾è®¡æ—¨åœ¨æ—©æœŸå¿«é€Ÿå¡‘é€  Gradient Componentï¼Œä»è€Œæå‡åç»­ RL ä¼˜åŒ–æ•ˆç‡ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **ç†è®ºè§£é‡ŠåŠ›** | é¦–æ¬¡ä» NTK è§†è§’å½¢å¼åŒ– RL åè®­ç»ƒçš„å­¦ä¹ åŠ¨æ€ï¼Œè§£é‡Šäº†â€œä¸ºä½• RL ä¼šå¯¼è‡´è¾“å‡ºé›†ä¸­â€çš„æ ¹æœ¬åŸå› ã€‚ |
| **æ–¹æ³•ç®€æ´æœ‰æ•ˆ** | CF-RL ä¸å¼•å…¥é¢å¤–è¶…å‚æˆ–å¤æ‚æ¨¡å—ï¼Œä»…è°ƒæ•´è®­ç»ƒé¡ºåºå³å¯åŠ é€Ÿæ”¶æ•›ã€‚ |
| **æœºåˆ¶æ–°é¢–** | å‘ç° CF-RL çš„ä½œç”¨æœºåˆ¶ä¸åŒäº LP-FT â€”â€” å®ƒä¸æ˜¯é€šè¿‡æŠ‘åˆ¶ç‰¹å¾ç•¸å˜ï¼ˆfeature distortionï¼‰æˆ–æ”¾å¤§åˆ†ç±»å™¨èŒƒæ•°å®ç°çš„ï¼Œè€Œæ˜¯æ”¹å˜äº†åˆ†ç±»å™¨å¯¹ç»“æ„ç±» token çš„å“åº”ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **SFT é˜¶æ®µ**ï¼šä½¿ç”¨ `AlpacaFarm` è¿›è¡Œç›‘ç£å¾®è°ƒã€‚
- **RL é˜¶æ®µ**ï¼šä½¿ç”¨ `UltraFeedback` çš„äºŒå€¼åŒ–ç‰ˆæœ¬ä½œä¸ºåå¥½æ•°æ®é›†ï¼Œç»“åˆ ArmoRM ä½œä¸º ground-truth reward model æä¾›æ ‡é‡å¥–åŠ±ä¿¡å·ã€‚
- æ‰€æœ‰ prompt å’Œ response è¢«æˆªæ–­è‡³æœ€å¤š 512 tokensã€‚

### æ¨¡å‹æ¶æ„
- åŸºç¡€æ¨¡å‹ï¼šPythia-2.8B
- æ¶æ„ç»†èŠ‚ï¼šTransformer + çº¿æ€§ unembedding classifierï¼ˆå³è¾“å‡ºå±‚æƒé‡çŸ©é˜µ $ W $ï¼‰

### å®éªŒè®¾ç½®
- ä½¿ç”¨ **GRPO** æˆ– **RLOO** ä½œä¸º policy gradient ç®—æ³•ã€‚
- KL æ­£åˆ™ç³»æ•° $ \lambda = 0.05 $
- å­¦ä¹ ç‡ï¼šSFT ä¸º $1e^{-6}$ï¼ŒRL ä¸º $1e^{-7}$
- Batch sizeï¼šSFT ä¸º 32ï¼ŒRL ä¸º 16ï¼ˆå«æ¢¯åº¦ç´¯ç§¯ï¼‰
- è®­ç»ƒè½®æ•°ï¼šå„é˜¶æ®µå‡ä¸º 6 epochsï¼ˆCF-stage ä¸º 1 epochï¼‰

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **First-token entropy** | è¡¡é‡åˆå§‹ token åˆ†å¸ƒçš„é›†ä¸­ç¨‹åº¦ï¼Œè¶Šä½è¡¨ç¤ºå¤šæ ·æ€§è¶Šå·®ã€‚ |
| **Best-of-N reward** | é‡‡æ · N ä¸ªè¾“å‡ºå–æœ€é«˜ rewardï¼Œç”¨äºè¯„ä¼°æ¦‚ç‡é›†ä¸­æ˜¯å¦å¸¦æ¥æ€§èƒ½å¢ç›Šã€‚ |
| **Semantic & Style Diversity** | å¯¹å¤šä¸ªè¾“å‡ºåµŒå…¥åè®¡ç®—å¹³å‡ä½™å¼¦è·ç¦»ï¼Œè¡¡é‡è¯­ä¹‰å’Œé£æ ¼å¤šæ ·æ€§ã€‚ |
| **Parameter change norm** | å„æ¨¡å—å‚æ•°å˜åŒ–å¹…åº¦ï¼ˆå¦‚ classifier vs. transformer layersï¼‰ã€‚ |
| **Classifier update analysis** | åˆ†æåˆ†ç±»å™¨å„è¡Œï¼ˆå¯¹åº”æ¯ä¸ª tokenï¼‰çš„æ›´æ–°å¼ºåº¦ã€‚ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Standard RL**ï¼ˆGRPO / RLOOï¼‰ï¼šå¸¸è§„å…¨å‚æ•°å¾®è°ƒã€‚
- **CF-RL**ï¼ˆCF-GRPO / CF-RLOOï¼‰ï¼šæå‡ºçš„åˆ†ç±»å™¨ä¼˜å…ˆè®­ç»ƒç­–ç•¥ã€‚
- åŒæ—¶ä¸ **LP-FT** åœ¨ç›‘ç£å¾®è°ƒä¸­çš„æœºåˆ¶è¿›è¡Œç±»æ¯”ä¸åŒºåˆ†ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰RL å¯¼è‡´è¾“å‡ºæ›´é›†ä¸­ï¼ˆæ”¯æŒç†è®ºï¼‰
- å›¾2b æ˜¾ç¤ºï¼šéšç€ RL è®­ç»ƒè¿›è¡Œï¼Œ**first-token entropy å•è°ƒä¸‹é™**ï¼Œè¯´æ˜è¾“å‡ºåˆ†å¸ƒæŒç»­å°–é”åŒ–ã€‚
- è¡¨2 æ˜¾ç¤ºï¼šç»è¿‡ä¸€è½® RL åï¼Œ
  - é«˜å¥–åŠ±æ ·æœ¬çš„ first-token entropyï¼š**1.516 Â± 0.931**
  - ä½å¥–åŠ±æ ·æœ¬ï¼š**2.439 Â± 1.278**
  âœ è¡¨æ˜ RL ä¸»è¦åœ¨é«˜å¥–åŠ±æ ·æœ¬ä¸Šæå‡ç½®ä¿¡åº¦ã€‚

#### ï¼ˆ2ï¼‰CF-RL åŠ é€Ÿä¼˜åŒ–è¿‡ç¨‹
- å›¾4 æ˜¾ç¤ºï¼šCF-GRPO åœ¨ç¬¬1ä¸ª epoch å°±å®ç°äº†æ˜¾è‘— reward æå‡ï¼Œæ˜æ˜¾å¿«äºæ ‡å‡† GRPOã€‚
- å°½ç®¡ç¬¬ä¸€é˜¶æ®µï¼ˆä»…è®­ç»ƒ classifierï¼‰æœ¬èº« reward æå‡å¾ˆå°ï¼Œä½†ä¸ºåç»­é˜¶æ®µæä¾›äº†æ›´å¥½çš„èµ·ç‚¹ã€‚

#### ï¼ˆ3ï¼‰å¤šæ ·æ€§ä»£ä»·ç¡®è®¤
- å›¾3b æ˜¾ç¤ºï¼šæ— è®ºæ˜¯ semantic è¿˜æ˜¯ style diversityï¼Œåœ¨ RL è®­ç»ƒè¿‡ç¨‹ä¸­éƒ½**æŒç»­ä¸‹é™**ï¼ŒéªŒè¯äº†â€œä»¥ç‰ºç‰²å¤šæ ·æ€§æ¢å– reward æå‡â€çš„æƒè¡¡ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| æ–¹æ³• | Reward æ”¶æ•›é€Ÿåº¦ | è¾“å‡ºå¤šæ ·æ€§ | åˆ†ç±»å™¨å­¦ä¹ é€Ÿåº¦ |
|------|------------------|------------|----------------|
| Standard RL (GRPO/RLOO) | è¾ƒæ…¢ | å¿«é€Ÿä¸‹é™ | è¾ƒå¿«ï¼ˆä½†ä»æ…¢äºå…¶ä»–å±‚ï¼‰ |
| **CF-RL (CF-GRPO)** | **æ˜¾è‘—åŠ å¿«** | ç±»ä¼¼ä¸‹é™è¶‹åŠ¿ | **æœ€æ—©å‘ç”Ÿæ˜¾è‘—å˜åŒ–** |

---

### æ¶ˆèå®éªŒä¸æ·±å…¥åˆ†æ

#### ï¼ˆ1ï¼‰CF-RL æ˜¯å¦å‡å°‘ç‰¹å¾ç•¸å˜ï¼Ÿ âŒ å¦
- å›¾5 æ˜¾ç¤ºï¼šCF-RL ä¸æ ‡å‡† RL åœ¨ feature change å¹…åº¦ä¸Šçš„å·®å¼‚åˆ†å¸ƒä¸­å¿ƒæ¥è¿‘é›¶ã€‚
- ç»“è®ºï¼š**CF-RL çš„ä¼˜åŠ¿å¹¶éæ¥è‡ªæŠ‘åˆ¶ feature distortion**ï¼Œè¿™ä¸ LP-FT ä¸åŒã€‚

#### ï¼ˆ2ï¼‰CF-RL æ˜¯å¦å¢å¤§åˆ†ç±»å™¨èŒƒæ•°ï¼Ÿ âŒ å¦
- è¡¨ S.3 æ˜¾ç¤ºï¼šSFTã€GRPOã€CF-stageã€CF-GRPO çš„ classifier norm å‡ ä¹å®Œå…¨ä¸€è‡´ï¼ˆâ‰ˆ0.989ï¼‰ã€‚
- ç»“è®ºï¼š**æ€§èƒ½æå‡ä¸æ˜¯ç”±äº classifier scaling æ•ˆåº”**ã€‚

#### ï¼ˆ3ï¼‰åˆ†ç±»å™¨æ›´æ–°çš„ token çº§åˆ«åˆ†æ âœ… æ–°å‘ç°
- è¡¨3 æ˜¾ç¤ºï¼š
  - æ ‡å‡† GRPO ä¸»è¦å¢å¼º**å†…å®¹è¯**ï¼ˆå¦‚ bringing, Several, itï¼‰ã€‚
  - CF-stage å’Œ CF-GRPO åˆ™å¤§å¹…æ›´æ–°**ç»“æ„æ€§ token**ï¼Œä¾‹å¦‚ï¼š
    - `<endoftext>`, `\n`, `\x0c`, `Supplementary`, `Appendix`, `[Â·]`, `<U+FFFD>`
- ç»“è®ºï¼š**CF-RL ä½¿åˆ†ç±»å™¨æ›´å…³æ³¨æ–‡æ¡£ç»“æ„ã€æ ¼å¼æ§åˆ¶ç­‰å…ƒä¿¡æ¯**ï¼Œè¿™äº›ä¿¡æ¯å¯èƒ½æœ‰åŠ©äº reward å»ºæ¨¡å’Œç­–ç•¥å¼•å¯¼ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **RL åè®­ç»ƒå¢åŠ æ¨¡å‹ç½®ä¿¡åº¦çš„æ ¹æœ¬åŸå› æ˜¯ Representation Component çš„å±€é™æ€§**ï¼š
   - ç‰¹å¾ç©ºé—´é«˜åº¦å¯¹é½ï¼ˆhigh cosine similarityï¼‰å¯¼è‡´æ›´æ–°æ–¹å‘å—é™ï¼Œåªèƒ½å¼ºåŒ–å·²é€‰ tokenã€‚
2. **æœ‰æ•ˆçš„ RL å­¦ä¹ ä¾èµ–äº Gradient Componentï¼Œè€Œå…¶è´¨é‡ç”±åˆ†ç±»å™¨å†³å®š**ã€‚
3. **åˆ†ç±»å™¨æ˜¯ RL ä¼˜åŒ–ä¸­æœ€å…ˆå¿«é€Ÿå˜åŒ–çš„éƒ¨åˆ†**ï¼Œè¡¨æ˜å…¶åœ¨å­¦ä¹ åŠ¨æ€ä¸­èµ·ä¸»å¯¼ä½œç”¨ã€‚
4. **CF-RL å¯åŠ é€Ÿ RL æ”¶æ•›**ï¼Œä¸”å…¶æœºåˆ¶ç‹¬ç‰¹â€”â€”**é€šè¿‡æ—©æœŸè°ƒæ•´åˆ†ç±»å™¨å¯¹ç»“æ„ token çš„æ•æ„Ÿæ€§æ¥æ”¹å–„ Gradient Component**ï¼Œè€Œéå¤åˆ¶ LP-FT çš„æœºåˆ¶ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
| å±€é™ | è¯´æ˜ |
|------|------|
| **é€‚ç”¨èŒƒå›´å¾…éªŒè¯** | å½“å‰å®éªŒä»…åœ¨ Pythia-2.8B ä¸ŠéªŒè¯ï¼Œæ›´å¤§æ¨¡å‹ï¼ˆå¦‚ 7B+ï¼‰æˆ–ä¸åŒ reward ç»“æ„ä¸‹çš„æ•ˆæœéœ€è¿›ä¸€æ­¥ç ”ç©¶ã€‚ |
| **æœªè§£å†³å¤šæ ·æ€§æœ¬è´¨é—®é¢˜** | CF-RL åŠ é€Ÿä¼˜åŒ–ï¼Œä½†æœªç¼“è§£è¾“å‡ºå¤šæ ·æ€§ä¸‹é™çš„é—®é¢˜ã€‚ |
| **ä¾èµ–é«˜è´¨é‡ reward model** | ä½¿ç”¨ ArmoRM ä½œä¸º oracle rewardï¼Œå®é™…åº”ç”¨ä¸­ reward model åå·®ä¼šå½±å“ CF-RL æ•ˆæœã€‚ |
| **ç†è®ºå‡è®¾è¾ƒå¼º** | å¦‚ Proposition 2 å‡è®¾ç‰¹å¾å†…ç§¯éè´Ÿï¼Œåœ¨æç«¯æƒ…å†µä¸‹å¯èƒ½ä¸æˆç«‹ã€‚ |

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±• CF-RL è‡³å¤šé˜¶æ®µæˆ–å¤šä»»åŠ¡ RL å¾®è°ƒåœºæ™¯**ã€‚
2. **æ¢ç´¢å¦‚ä½•ä¿ç•™å¤šæ ·æ€§çš„åŒæ—¶æå‡ reward**ï¼Œä¾‹å¦‚ç»“åˆ deviation-weighted optimizationã€‚
3. **å°† NTK åŠ¨æ€åˆ†æåº”ç”¨äºå…¶ä»– RL ç®—æ³•**ï¼ˆå¦‚ DPOã€iDPOï¼‰ä»¥ç»Ÿä¸€ç†è§£ alignment æ–¹æ³•ã€‚
4. **è®¾è®¡å¯è§£é‡Šçš„ classifier interpretability å·¥å…·**ï¼Œè¿½è¸ªç»“æ„ token æƒé‡å˜åŒ–çš„æ„ä¹‰ã€‚
5. **ç ”ç©¶ CF-RL åœ¨ RLVRï¼ˆå¯éªŒè¯å¥–åŠ±ï¼‰ä»»åŠ¡ä¸­çš„æ¨ç†èƒ½åŠ›æ¿€å‘æ½œåŠ›**ã€‚

---

> âœ… **ä¸€å¥è¯æ€»ç»“**ï¼š  
> æœ¬è®ºæ–‡é¦–æ¬¡ä» NTK è§†è§’æ­ç¤ºäº† RL åè®­ç»ƒä¸­è¾“å‡ºé›†ä¸­åŒ–çš„åŠ¨å› ï¼Œå¹¶æå‡º **CF-RL** â€”â€” ä¸€ç§ç®€å•å´é«˜æ•ˆçš„ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡ä¼˜å…ˆæ›´æ–°åˆ†ç±»å™¨æ¥åŠ é€Ÿä¼˜åŒ–ï¼Œå…¶æœºåˆ¶ç‹¬ç«‹äºä¼ ç»Ÿçš„ LP-FT èŒƒå¼ï¼Œä¸ºç†è§£è¯­è¨€æ¨¡å‹å¯¹é½è®­ç»ƒæä¾›äº†æ–°è§†è§’ã€‚

</details>

---

### 8. [GPU-Accelerated INT8 Quantization for KV Cache Compression in Large Language Models](https://arxiv.org/abs/2601.04719)

**Authors**: Maanas Taneja, Purab Shingvi  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.04719v1  

#### Abstract
The key-value (KV) cache in large language models presents a significant memory bottleneck during inference, growing linearly with sequence length and often exceeding the memory footprint of model weights themselves. We implement and evaluate GPU-accelerated INT8 quantization for KV cache compressio...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šGPU-Accelerated INT8 Quantization for KV Cache Compression in Large Language Models

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨ç†è¿‡ç¨‹ä¸­é¢ä¸´æ˜¾è‘—çš„å†…å­˜ç“¶é¢ˆï¼Œå°¤å…¶æ˜¯ **Key-Value (KV) Cache** çš„å†…å­˜æ¶ˆè€—ã€‚éšç€åºåˆ—é•¿åº¦å¢é•¿ï¼ŒKV Cache çš„å¤§å°å‘ˆçº¿æ€§å¢åŠ ï¼Œåœ¨é•¿ä¸Šä¸‹æ–‡åœºæ™¯ä¸‹ï¼ˆå¦‚ 32Kã€128K tokensï¼‰ï¼Œå…¶å†…å­˜å ç”¨ç”šè‡³è¶…è¿‡æ¨¡å‹æƒé‡æœ¬èº«ï¼Œä¸¥é‡é™åˆ¶äº†æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ã€æ‰¹å¤„ç†å¤§å°ï¼Œå¹¶æé«˜äº†éƒ¨ç½²æˆæœ¬ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
æœ¬æ–‡æå‡ºå¹¶ç³»ç»Ÿè¯„ä¼°äº†ä¸€ç§ **GPU åŠ é€Ÿçš„ per-channel INT8 é‡åŒ–æ–¹æ¡ˆ**ï¼Œç”¨äºå‹ç¼© LLM æ¨ç†ä¸­çš„ KV Cacheï¼Œä¸»è¦è´¡çŒ®å¦‚ä¸‹ï¼š

- **é«˜æ•ˆå®ç°ä¸ä¼˜åŒ–**ï¼šè®¾è®¡å¹¶å®ç°äº†å››ç§ CUDA å†…æ ¸å˜ä½“ï¼ˆnaiveã€tiledã€coarsenedã€vectorizedï¼‰ï¼Œæ¢ç´¢ä¸åŒ GPU å¹¶è¡Œä¼˜åŒ–ç­–ç•¥å¯¹ KV Cache é‡åŒ–æ€§èƒ½çš„å½±å“ã€‚
- **ç»†ç²’åº¦é‡åŒ–ç­–ç•¥**ï¼šé‡‡ç”¨ **per-channel quantization**ï¼Œä¸ºæ¯ä¸ªæ³¨æ„åŠ›å¤´ç»´åº¦å•ç‹¬è®¡ç®— scale å› å­ï¼Œä»¥ä¿ç•™åŠ¨æ€èŒƒå›´å·®å¼‚è¾ƒå¤§çš„ç»´åº¦çš„ç²¾åº¦ã€‚
- **å…¨é¢çš„æ€§èƒ½-ç²¾åº¦åˆ†æ**ï¼šä¸ä»…æŠ¥å‘Šç«¯åˆ°ç«¯é€Ÿåº¦æå‡ï¼Œè¿˜æ·±å…¥åˆ†æäº†é‡å»ºè¯¯å·®ï¼ˆreconstruction errorï¼‰å’Œæ³¨æ„åŠ›åˆ†æ•°è¯¯å·®ï¼ˆattention score errorï¼‰ï¼Œæ­ç¤ºé‡åŒ–å¯¹ä¸‹æ¸¸è®¡ç®—çš„å®é™…å½±å“ã€‚
- **å®ç”¨æ€§å¼º**ï¼šå±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨çœŸå® LLM å·¥ä½œè´Ÿè½½ä¸‹çš„å¯è¡Œæ€§ï¼Œé‡åŒ–å¼€é”€ä»…ä¸º 6â€“58msï¼Œè¿œå°äºå®é™… attention è®¡ç®—æ—¶é—´ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰æ–¹æ³• | æœ¬æ–‡ä¼˜åŠ¿ |
|------|--------|---------|
| **FlashAttention** | é€šè¿‡ kernel fusion ä¼˜åŒ–è®¡ç®—ï¼Œä¸å‹ç¼©ç¼“å­˜ | å®ç° **4Ã— å†…å­˜å‹ç¼©**ï¼Œç›´æ¥ç¼“è§£å†…å­˜å‹åŠ› |
| **PagedAttention** | å‡å°‘å†…å­˜ç¢ç‰‡ï¼Œä»ä¿æŒ FP32 å­˜å‚¨ | åœ¨ç›¸åŒæœºåˆ¶åŸºç¡€ä¸Šå¯è¿›ä¸€æ­¥å åŠ é‡åŒ–èŠ‚çœå†…å­˜ |
| **LLM.int8()** | ä¸»è¦é’ˆå¯¹æƒé‡å’Œæ¿€æ´»é‡åŒ– | èšç„¦äº **KV Cache è¿™ä¸€ç‰¹å®šç“¶é¢ˆ**ï¼Œæä¾›ä¸“ç”¨ä¼˜åŒ– |
| **å…¶ä»–æç«¯é‡åŒ–ï¼ˆå¦‚ KIVI, KVQuantï¼‰** | æ¢ç´¢ 2-bit æˆ– sub-4-bit | æœ¬æ–‡æ–¹æ³•åœ¨ **ç²¾åº¦æŸå¤±æå°çš„å‰æä¸‹å®ç°ç®€å•é«˜æ•ˆ**ï¼Œæ›´é€‚åˆç”Ÿäº§éƒ¨ç½² |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›† / æµ‹è¯•é…ç½®
æœ¬ç ”ç©¶æœªä½¿ç”¨ä¼ ç»Ÿâ€œæ•°æ®é›†â€ï¼Œè€Œæ˜¯æ„å»ºäº†ä¸€ç³»åˆ— **åˆæˆçŸ©é˜µæµ‹è¯•ç”¨ä¾‹** æ¥æ¨¡æ‹ŸçœŸå®çš„ KV Cache åœºæ™¯ï¼Œè¦†ç›–ä»å°è§„æ¨¡åˆ°è¶…å¤§è§„æ¨¡çš„å·¥ä½œè´Ÿè½½ï¼š

| Test Case | Tokens (T) | Head Dim (D) | æè¿° |
|----------|------------|--------------|------|
| Small | 2,048 | 128 | æœ€å°æµ‹è¯• |
| Medium | 16,384 | 256 | å¼€å‘æµ‹è¯• |
| Large | 65,536 | 256 | æ‰©å±•ä¸Šä¸‹æ–‡ |
| Very Large | 131,072 | 256 | é•¿ä¸Šä¸‹æ–‡ |
| Realistic Small ~ V. Large | 131,072 | 1,024 ~ 8,192 | æ¨¡æ‹Ÿç°ä»£ LLM çš„çœŸå®å·¥ä½œè´Ÿè½½ï¼ˆé«˜è¾¾ 10 äº¿å…ƒç´ ï¼‰ |

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼š
  - GPU: NVIDIA Tesla T4 (16GB GDDR6)
  - CPU: 2Ã— Intel Xeon Gold 6148 (å…± 40 æ ¸)
  - CUDA ç‰ˆæœ¬: 12.0
- **å®ç°æ–¹å¼**ï¼š
  - CPU åŸºçº¿ï¼šC++ å®ç°ï¼Œä½œä¸ºæ­£ç¡®æ€§å’Œæ€§èƒ½åŸºå‡†
  - GPU å®ç°ï¼šå››ç§ CUDA kernelï¼ˆnaiveã€tiledã€coarsenedã€vectorizedï¼‰
- **é‡åŒ–æ–¹å¼**ï¼šPer-channel INT8 é‡åŒ–ï¼Œscale å®šä¹‰ä¸º $ s_d = \frac{\max_t |K_{t,d}|}{127} $

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ | ç›®çš„ |
|------|------|------|
| **Performance (Speedup)** | GPU kernel vs CPU baseline çš„è¿è¡Œæ—¶é—´æ¯” | è¡¡é‡åŠ é€Ÿæ•ˆæœ |
| **L2 Reconstruction Error** | åŸå§‹ FP32 çŸ©é˜µä¸åé‡åŒ–åçŸ©é˜µä¹‹é—´çš„ L2 è·ç¦» | è¯„ä¼°æ•°å€¼ä¿çœŸåº¦ |
| **Max Absolute Error** | æ‰€æœ‰å…ƒç´ ä¸­æœ€å¤§ç»å¯¹è¯¯å·® | åˆ†ææœ€åæƒ…å†µè¯¯å·®è¾¹ç•Œ |
| **Attention Score Error** | ä½¿ç”¨åŸå§‹ vs é‡æ„ Key å‘é‡è®¡ç®—çš„ attention dot product çš„å¹³å‡ç»å¯¹å·® | åˆ¤æ–­æ˜¯å¦å½±å“ä¸‹æ¸¸æ³¨æ„åŠ›æœºåˆ¶è¡Œä¸º |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **CPU Baseline**ï¼šä¸²è¡Œå®ç°ï¼Œç”¨äºè¡¡é‡ GPU åŠ é€Ÿæ¯”
- **å››ç§ GPU Kernel å˜ä½“ä¹‹é—´ç›¸äº’æ¯”è¾ƒ**ï¼ŒéªŒè¯ä¸åŒä¼˜åŒ–ç­–ç•¥çš„æœ‰æ•ˆæ€§

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **å†…å­˜å‹ç¼©ç‡** | **4Ã— reduction**ï¼ˆä» FP32 â†’ INT8ï¼‰ |
| **æœ€é«˜ GPU åŠ é€Ÿæ¯”** | **1,694Ã— speedup**ï¼ˆvectorized kernel åœ¨ 131K Ã— 8K è§„æ¨¡ä¸‹ï¼‰ |
| **æœ€å¤§æ‰§è¡Œæ—¶é—´ï¼ˆGPUï¼‰** | < 50msï¼ˆå³ä½¿å¤„ç† 10 äº¿å…ƒç´ ï¼‰ |
| **å…¸å‹é‡åŒ–å»¶è¿Ÿï¼ˆç°å®è´Ÿè½½ï¼‰** | **6 â€“ 58 ms**ï¼Œè¿œä½äº attention è®¡ç®—è€—æ—¶ |
| **CPU æœ€å¤§è€—æ—¶** | è¾¾ **79 ç§’**ï¼ˆåŒè§„æ¨¡ä»»åŠ¡ï¼‰ |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **Vectorized Kernel æ˜¾è‘—ä¼˜äºå…¶ä»–æ‰€æœ‰ç‰ˆæœ¬**ï¼š
  - åœ¨æœ€å¤§è´Ÿè½½ä¸Šæ¯” naive kernel å¿«æ•°å€
  - æ¯” CPU å¿«ä¸‰ä¸ªæ•°é‡çº§ï¼ˆè§ Figure 2ï¼‰
- **Tiled Kernel æœªå¸¦æ¥æ”¶ç›Š**ï¼š
  - å°½ç®¡ä½¿ç”¨ shared memory ç¼“å­˜ scalesï¼Œä½†ç”±äº scales æ•°ç»„è¾ƒå°ä¸”èƒ½é©»ç•™ L2 cacheï¼Œé¢å¤–åŒæ­¥å¼€é”€æŠµæ¶ˆäº†æ½œåœ¨å¥½å¤„ï¼Œæ€§èƒ½ä¸ naive kernel ç›¸å½“ç”šè‡³ç•¥å·®
- **Coarsened Kernel æå‡æœ‰é™**ï¼š
  - é€šè¿‡å‡å°‘çº¿ç¨‹æ•°ã€æé«˜ ILP è·å¾—å°å¹…æ”¹è¿›ï¼Œä½†åœ¨å¤§è´Ÿè½½ä¸‹å¢ç›Šè¶‹äºé¥±å’Œ

### æ¶ˆèå®éªŒç»“æœ
é€šè¿‡å¯¹å››ç§ kernel çš„æ¨ªå‘å¯¹æ¯”ï¼Œå¾—å‡ºä»¥ä¸‹å…³é”®å‘ç°ï¼ˆæœ¬è´¨æ˜¯æ¶ˆèåˆ†æï¼‰ï¼š

| ä¼˜åŒ–ç­–ç•¥ | æ˜¯å¦æœ‰æ•ˆ | åŸå›  |
|---------|----------|------|
| **Memory Coalescing** | âœ… æœ‰æ•ˆ | Naive kernel å·²å®ç°è‰¯å¥½åˆ—å‘åˆå¹¶è®¿é—® |
| **Shared Memory Tiling** | âŒ æ— æ•ˆ | æ— æ•°æ®å¤ç”¨ï¼ŒåŒæ­¥å¼€é”€ > ç¼“å­˜æ”¶ç›Š |
| **Thread Coarsening** | âš ï¸ æœ‰é™æœ‰æ•ˆ | å‡å°‘æŒ‡ä»¤å¼€é”€ï¼Œä½†å—é™äº memory-bound ç‰¹æ€§ |
| **Vectorization (float4/char4)** | âœ…âœ… æå…¶æœ‰æ•ˆ | å‡å°‘å†…å­˜äº‹åŠ¡æ•°è¾¾ 4Ã—ï¼Œç›´æ¥æå‡å¸¦å®½åˆ©ç”¨ç‡ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **INT8 é‡åŒ–æ˜¯ç¼“è§£ KV Cache å†…å­˜ç“¶é¢ˆçš„å®ç”¨æ–¹æ¡ˆ**ï¼š
   - å®ç° **4Ã— å†…å­˜å‹ç¼©**ï¼Œæ˜¾è‘—é™ä½æ˜¾å­˜å‹åŠ›ï¼Œæ”¯æŒæ›´é•¿ä¸Šä¸‹æ–‡å’Œæ›´å¤§ batch sizeã€‚
2. **GPU åŠ é€Ÿè‡³å…³é‡è¦**ï¼š
   - CPU ä¸Šé‡åŒ–å»¶è¿Ÿè¿‡é«˜ï¼ˆæ•°åç§’çº§ï¼‰ï¼Œæ— æ³•ç”¨äºå®æ—¶æ¨ç†ï¼›è€Œ GPU å®ç°å¯åœ¨ **æ¯«ç§’çº§å®Œæˆ**ï¼Œå¼€é”€å¯å¿½ç•¥ã€‚
3. **Vectorization æ˜¯æœ€ä¼˜ä¼˜åŒ–è·¯å¾„**ï¼š
   - KV Cache é‡åŒ–å±äºå…¸å‹çš„ **memory-bound** æ“ä½œï¼Œç®—æœ¯å¼ºåº¦ä½ï¼›
   - ä¸€æ—¦å®ç°å†…å­˜åˆå¹¶è®¿é—®ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–åº”èšç„¦äº **å‡å°‘å†…å­˜äº‹åŠ¡æ¬¡æ•°**ï¼Œè€Œéå¼•å…¥å¤æ‚åŒæ­¥æˆ–è°ƒåº¦ï¼›
   - **vectorized kernel åˆ©ç”¨ float4/char4 å‘é‡æŒ‡ä»¤ï¼Œæœ€å¤§åŒ–å¸¦å®½åˆ©ç”¨ç‡ï¼Œè¡¨ç°æœ€ä½³**ã€‚
4. **ç²¾åº¦æŸå¤±æå°**ï¼š
   - æœ€å¤§ç»å¯¹è¯¯å·®ç¨³å®šåœ¨ **0.00394**ï¼ˆç†è®ºä¸Šé™ä¸º 1/254 â‰ˆ 0.00394ï¼‰ï¼›
   - æ³¨æ„åŠ›åˆ†æ•°è¯¯å·®åœ¨æœ€å¤§ç»´åº¦ï¼ˆD=8192ï¼‰ä¸‹ä¹Ÿä»… **0.095**ï¼Œè¿œå°äº softmax å‰çš„æ•°å€¼èŒƒå›´ï¼Œä¸ä¼šæ˜¾è‘—æ”¹å˜ attention åˆ†å¸ƒã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä»…é™å• GPU å®ç°**ï¼šæœªè€ƒè™‘åˆ†å¸ƒå¼æˆ–å¤š GPU åœºæ™¯ä¸‹çš„æ‰©å±•æ€§ã€‚
- **æœªè¿›è¡Œç«¯åˆ°ç«¯ä»»åŠ¡è¯„ä¼°**ï¼šç¼ºä¹åœ¨å…·ä½“ä»»åŠ¡ï¼ˆå¦‚ QAã€generationï¼‰ä¸Šçš„ **perplexity æˆ– accuracy** æµ‹é‡ã€‚
- **å›ºå®š bit-widthï¼ˆINT8ï¼‰**ï¼šæœªæ¢ç´¢æ›´ä½æ¯”ç‰¹ï¼ˆå¦‚ INT4ã€INT2ï¼‰æˆ–æ··åˆç²¾åº¦ç­–ç•¥ã€‚
- **é™æ€ scale è®¡ç®—**ï¼šæœªé‡‡ç”¨åŠ¨æ€æˆ–è‡ªé€‚åº”é‡åŒ–ç­–ç•¥åº”å¯¹ outlier è¾“å…¥ã€‚
- **ä¾èµ–ç‰¹å®šæ•°æ®å¸ƒå±€**ï¼švectorized kernel è¦æ±‚ç»´åº¦ D å¯è¢« 4 æ•´é™¤ï¼Œéœ€é¢å¤–å¤„ç†è¾¹ç¼˜æƒ…å†µã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **é›†æˆè‡³ä¸»æµæ¨ç†æ¡†æ¶**ï¼š
   - å°† kernel é›†æˆè¿› **vLLMã€TensorRT-LLM æˆ– HuggingFace Transformers**ï¼Œè¿›è¡Œç«¯åˆ°ç«¯æ€§èƒ½è¯„æµ‹ã€‚
2. **æ¢ç´¢æ›´å…ˆè¿› GPU ä¼˜åŒ–æŠ€æœ¯**ï¼š
   - ä½¿ç”¨ warp-level primitivesï¼ˆå¦‚ `__shfl_down_sync`ï¼‰ä¼˜åŒ– scale reductionï¼›
   - è®¾è®¡ persistent kernel ä»¥æ‘Šé”€æµå¼æ¨ç†çš„å¯åŠ¨å¼€é”€ã€‚
3. **å°è¯•æ–°å‹æ•°å€¼æ ¼å¼**ï¼š
   - æ¢ç´¢åŸç”Ÿæ”¯æŒ **FP8** çš„æ–°æ¶æ„ï¼ˆå¦‚ Hopperï¼‰æ˜¯å¦èƒ½åœ¨ç²¾åº¦ä¸æ•ˆç‡é—´å–å¾—æ›´å¥½å¹³è¡¡ã€‚
4. **å¼€å±•å…¨é¢å‡†ç¡®æ€§è¯„ä¼°**ï¼š
   - åœ¨æ ‡å‡† benchmarkï¼ˆå¦‚ WikiTextã€LAMBADAï¼‰ä¸Šæµ‹é‡ **perplexity å˜åŒ–** å’Œç”Ÿæˆè´¨é‡é€€åŒ–ã€‚
5. **ç ”ç©¶æ··åˆä¸åŠ¨æ€é‡åŒ–ç­–ç•¥**ï¼š
   - å¯¹é‡è¦å±‚æˆ– token ä¿ç•™é«˜ç²¾åº¦ï¼Œå…¶ä½™éƒ¨åˆ†é‡åŒ–ï¼Œå®ç°ç²¾åº¦-æ•ˆç‡æƒè¡¡ã€‚

---

> ğŸ”— **ä»£ç å¼€æºåœ°å€**ï¼š[https://github.com/MaanasTaneja/cuda-kv-cache-compression](https://github.com/MaanasTaneja/cuda-kv-cache-compression)

</details>

---

### 9. [Approximate equivariance via projection-based regularisation](https://arxiv.org/abs/2601.05028)

**Authors**: Torben Berndt, Jan St\"uhmer  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.05028v1  

#### Abstract
Equivariance is a powerful inductive bias in neural networks, improving generalisation and physical consistency. Recently, however, non-equivariant models have regained attention, due to their better runtime performance and imperfect symmetries that might arise in real-world applications. This has m...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šApproximate equivariance via projection-based regularisation**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œ**equivariance**ï¼ˆç­‰å˜æ€§ï¼‰æ˜¯ä¸€ç§å¼ºå¤§çš„å½’çº³åç½®ï¼ˆinductive biasï¼‰ï¼Œèƒ½å¤Ÿæå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œç‰©ç†ä¸€è‡´æ€§ã€‚ç„¶è€Œï¼Œä¸¥æ ¼ç­‰å˜çš„æ¨¡å‹é€šå¸¸è®¡ç®—å¼€é”€å¤§ã€çµæ´»æ€§å·®ï¼Œä¸”ç°å®ä¸–ç•Œçš„æ•°æ®å¸¸å­˜åœ¨ä¸å®Œç¾çš„å¯¹ç§°æ€§ï¼ˆå¦‚å™ªå£°ã€éç†æƒ³å˜æ¢ï¼‰ã€‚å› æ­¤ï¼Œç ”ç©¶è€…å€¾å‘äºä½¿ç”¨**è¿‘ä¼¼ç­‰å˜æ¨¡å‹**ï¼ˆapproximately equivariant modelsï¼‰ï¼Œåœ¨ä¿ç•™å¯¹ç§°æ€§ä¼˜åŠ¿çš„åŒæ—¶é€‚åº”çœŸå®æ•°æ®åˆ†å¸ƒã€‚

ç°æœ‰æ–¹æ³•å¤šé‡‡ç”¨**åŸºäºæ ·æœ¬çš„æ­£åˆ™åŒ–**ï¼ˆsample-based regularisersï¼‰ï¼Œä¾‹å¦‚é€šè¿‡æ•°æ®å¢å¼ºï¼ˆdata augmentationï¼‰åœ¨è®­ç»ƒæ—¶éšæœºé‡‡æ ·ç¾¤å…ƒç´ å¹¶æ–½åŠ ç­‰å˜çº¦æŸã€‚è¿™ç±»æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **é«˜æ ·æœ¬å¤æ‚åº¦**ï¼ˆhigh sample complexityï¼‰ï¼Œå°¤å…¶å¯¹äºè¿ç»­ç¾¤ï¼ˆå¦‚ SO(3)ï¼‰ï¼›
- éœ€è¦é¢å¤–å‰å‘ä¼ æ’­ï¼Œå¢åŠ è®­ç»ƒæˆæœ¬ï¼›
- æ­£åˆ™åŒ–ä»…ä½œç”¨äºè¾“å…¥ç‚¹ï¼Œè€Œéæ¨¡å‹å‚æ•°æœ¬èº«ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•**
æœ¬æ–‡æå‡ºä¸€ç§å…¨æ–°çš„**åŸºäºæŠ•å½±çš„ç­‰å˜æ­£åˆ™åŒ–æ–¹æ³•**ï¼ˆprojection-based equivariance regularisationï¼‰ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- åˆ©ç”¨çº¿æ€§ç®—å­åœ¨**ç¾¤è¡¨ç¤ºä¸‹çš„æ­£äº¤åˆ†è§£**ï¼ˆorthogonal decompositionï¼‰ï¼Œå°†ä»»æ„çº¿æ€§å±‚ $ T $ åˆ†è§£ä¸ºç­‰å˜éƒ¨åˆ† $ P(T) $ å’Œéç­‰å˜éƒ¨åˆ† $ T - P(T) $ï¼›
- åœ¨è®­ç»ƒç›®æ ‡ä¸­ç›´æ¥æƒ©ç½šéç­‰å˜åˆ†é‡çš„èŒƒæ•° $ \|T - P(T)\| $ï¼Œä»è€Œåœ¨**ç®—å­å±‚é¢**ï¼ˆoperator levelï¼‰å®ç°å¯¹æ•´ä¸ªç¾¤è½¨é“ï¼ˆgroup orbitï¼‰çš„æ­£åˆ™åŒ–ã€‚

è¯¥æ–¹æ³•çš„å…³é”®å…¬å¼ä¸ºï¼š
$$
\mathcal{L} = \mathcal{L}_{\text{task}} + \lambda_G \|P(T)\| + \lambda_\perp \|T - P(T)\|
$$
å…¶ä¸­ $ P(T) $ æ˜¯ $ T $ åœ¨ç­‰å˜å­ç©ºé—´ä¸Šçš„æ­£äº¤æŠ•å½±ï¼ˆReynolds operatorï¼‰ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | æœ¬æ–‡æ–¹æ³•ï¼ˆProjection-basedï¼‰ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆSample-basedï¼‰ |
|------|-------------------------------|---------------------------|
| **æ­£åˆ™åŒ–ç²’åº¦** | ç®—å­çº§ï¼ˆå…¨å±€ï¼‰ | ç‚¹çº§ï¼ˆå±€éƒ¨ï¼‰ |
| **æ˜¯å¦ä¾èµ–æ•°æ®é‡‡æ ·** | å¦ | æ˜¯ï¼ˆéœ€é‡‡æ · group elementsï¼‰ |
| **è®¡ç®—æ•ˆç‡** | é«˜ï¼ˆå¯é—­å¼è®¡ç®—ï¼Œæ— é¢å¤–å‰å‘ï¼‰ | ä½ï¼ˆæ¯æ ·æœ¬éœ€å¤šæ¬¡å‰å‘ï¼‰ |
| **æ–¹å·®** | é›¶ä¼°è®¡æ–¹å·® | å­˜åœ¨é‡‡æ ·æ–¹å·® |
| **é€‚ç”¨äºè¿ç»­ç¾¤** | æ˜¯ï¼ˆå¯é€šè¿‡å‚…é‡Œå¶åŸŸé«˜æ•ˆè®¡ç®—ï¼‰ | å›°éš¾ï¼ˆéœ€å¤§é‡é‡‡æ ·ï¼‰ |

æ­¤å¤–ï¼Œä½œè€…æä¾›äº†åœ¨**ç©ºé—´åŸŸ**å’Œ**è°±åŸŸ**ï¼ˆFourier domainï¼‰é«˜æ•ˆè®¡ç®—æŠ•å½±çš„æ–¹æ³•ï¼Œç‰¹åˆ«é€‚åˆå¤„ç†è¿ç»­ç¾¤ï¼ˆå¦‚ SO(n)ï¼‰ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
1. **åˆæˆæ•°æ®é›†**ï¼š
   - **SO(2)ä¸å˜åˆ†ç±»ä»»åŠ¡**ï¼šäºŒç»´ç‚¹äº‘åˆ†ç±»ï¼Œå†…åœ†ä¸ºä¸€ç±»ï¼Œå¤–ç¯ä¸ºå¦ä¸€ç±»ï¼Œæµ‹è¯•æ¨¡å‹å­¦ä¹ æ—‹è½¬ä¸å˜æ€§çš„èƒ½åŠ›ã€‚
   - **çƒŸé›¾åŠ¨åŠ›å­¦é¢„æµ‹**ï¼ˆsmoke advection-diffusionï¼‰ï¼šä½¿ç”¨ PhiFlow ç”Ÿæˆ 64Ã—64 çƒŸé›¾æ‰©æ•£åºåˆ—ï¼Œæ¨¡æ‹Ÿå…·æœ‰**è¿‘ä¼¼å¯¹ç§°æ€§**çš„åŠ¨åŠ›ç³»ç»Ÿï¼ˆå¹³ç§»ã€æ—‹è½¬ã€ç¼©æ”¾ï¼‰ã€‚
2. **çœŸå®åŒ»å­¦å›¾åƒæ•°æ®é›†**ï¼š
   - **AAPM CT-MAR Grand Challenge**ï¼š14,000 å¼ å¸¦é‡‘å±ä¼ªå½±çš„å¤´éƒ¨å’Œèº«ä½“ CT åˆ‡ç‰‡ï¼Œç”¨äºé‡‘å±ä¼ªå½±å»é™¤ï¼ˆMetal Artifact Reduction, MARï¼‰ä»»åŠ¡ã€‚

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**
| ä»»åŠ¡ | æ¨¡å‹æ¶æ„ | è¯„ä¼°æŒ‡æ ‡ | è®¾ç½®è¯´æ˜ |
|------|----------|----------|----------|
| SO(2) Invariance | å¤æ•° MLP + åœ†è°å‡½æ•°åµŒå…¥ | å†³ç­–è¾¹ç•Œå¯è§†åŒ–ã€ç»éªŒç­‰å˜ç¼ºé™· $ \mathcal{E}_{\text{emp}}(T) $ | æ§åˆ¶ $ \lambda_G, \lambda_\perp $ è°ƒèŠ‚ç­‰å˜å¼ºåº¦ |
| åŠ¨åŠ›å­¦é¢„æµ‹ | Relaxed Group Conv / Steerable CNN | åƒç´ çº§ MSEï¼ˆFuture / Domain OODï¼‰ | æµ‹è¯•æœªæ¥æ—¶é—´æ­¥å’Œæœªè§ç©ºé—´åŒºåŸŸ |
| CT-MAR | ACDNet / DICDNet / OSCNet | PSNRã€SSIMã€ååé‡ã€å†…å­˜å ç”¨ | æ¯”è¾ƒå›ºå®š batch å’Œæœ€å¤§å¯è¡Œ batch ä¸‹çš„è¡¨ç° |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **Sample-based regulariser** (Bai et al., 2025)ï¼šåœ¨æŸå¤±ä¸­åŠ å…¥éšæœºæ—‹è½¬ä¸‹çš„ç­‰å˜è¯¯å·®é¡¹ã€‚
- **Residual Pathway Priors (RPP)** (Finzi et al., 2021)ï¼šä¸»å¹²ç½‘ç»œ + å°çš„ç­‰å˜æ®‹å·®è·¯å¾„ã€‚
- **Train-then-project**ï¼šå…ˆè®­ç»ƒéç­‰å˜æ¨¡å‹ï¼Œæµ‹è¯•æ—¶æŠ•å½±åˆ°ç­‰å˜å­ç©ºé—´ã€‚
- **Relaxed Group / Steerable CNNs** (Wang et al., 2022c)ï¼šæ”¾å®½æƒé‡å…±äº«æœºåˆ¶ã€‚
- **æ ‡å‡† CNN / ç­‰å˜ CNN** ä½œä¸ºä¸Šä¸‹ç•Œå‚è€ƒã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **(1) CT-MAR ä»»åŠ¡ï¼ˆè¡¨ 2ï¼‰**
ä»¥ **ACDNet + projection-based regulariser** ä¸ºä¾‹ï¼š
- **PSNR**: 42.68 dBï¼ˆä¼˜äº baseline 42.08ï¼Œä¼˜äº sample-based 40.02ï¼‰
- **SSIM**: 0.9620ï¼ˆæ¥è¿‘ sample-based çš„ 0.9623ï¼Œæ˜¾è‘—ä¼˜äº baseline 0.9559ï¼‰
- **è®­ç»ƒååé‡**ï¼ˆbatch size 12ï¼‰: 4.25 samples/GPU-sï¼ˆsample-based ä»…æ”¯æŒ batch=4ï¼Œåå 2.54ï¼‰
- **æ¨ç†ååé‡**: 4.99 samples/GPU-s
- **epoch æ—¶é—´**: 1202 ç§’ï¼ˆsample-based ä¸º 2011 ç§’ï¼‰

> âœ… **ç»“è®º**ï¼šæŠ•å½±æ³•åœ¨æ€§èƒ½ä¸ŠæŒå¹³æˆ–è¶…è¶Š sample-based æ–¹æ³•ï¼ŒåŒæ—¶è®­ç»ƒé€Ÿåº¦æå‡ **~40â€“60%**ã€‚

#### **(2) åŠ¨åŠ›å­¦é¢„æµ‹ä»»åŠ¡ï¼ˆè¡¨ 1ï¼‰**
åœ¨ **Rotation** å’Œ **Scaling** è®¾ç½®ä¸‹ï¼š
- **RGroup + Reg** åœ¨ Rotation-Future ä¸Š MSE è¾¾ **0.73Â±0.02**ï¼Œä¼˜äºåŸå§‹ RGroup (0.82Â±0.01) å’Œæ‰€æœ‰å…¶ä»– baselineã€‚
- **RSteer + Reg** åœ¨ Scaling-Domain ä¸Š MSE ä¸º **0.69Â±0.01**ï¼Œæ˜¾è‘—ä¼˜äº baseline (0.88Â±0.01)ã€‚

> âœ… **ç»“è®º**ï¼šæŠ•å½±æ­£åˆ™åŒ–èƒ½æœ‰æ•ˆæå‡åœ¨è¿‘ä¼¼å¯¹ç§°ç³»ç»Ÿä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚

#### **(3) SO(2) Invariance Toy Task**
- éšç€ $ \lambda_\perp $ å¢å¤§ï¼Œç»éªŒç­‰å˜ç¼ºé™· $ \mathcal{E}_{\text{emp}}(T) $ æ˜¾è‘—ä¸‹é™ï¼ˆä» $ 3.02e+01 $ é™è‡³ $ 1.53e-02 $ï¼‰ã€‚
- å³ä½¿æ•°æ®å¼•å…¥è§’åº¦æ‰°åŠ¨ï¼ˆangular waveï¼‰ï¼Œæ¨¡å‹ä»èƒ½â€œå°½å¯èƒ½ä¿æŒåœ†å½¢â€ï¼Œä»…åœ¨å¿…è¦å¤„åç¦»å¯¹ç§°æ€§ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### **(1) æ­£åˆ™åŒ–ç³»æ•°æ•æ„Ÿæ€§åˆ†æï¼ˆå›¾ 7, 8, 9ï¼‰**
- $ \lambda_\perp $ æ˜¯æ§åˆ¶ç­‰å˜æ€§çš„ä¸»è¦å› ç´ ï¼šå¢å¤§ $ \lambda_\perp $ æ˜¾è‘—é™ä½ç­‰å˜ç¼ºé™· $ \mathcal{E}(T) $ã€‚
- $ \lambda_G $ å½±å“è¾ƒå°ï¼›å½“ $ \lambda_\perp \ll \lambda_G $ æ—¶ï¼Œæ­£åˆ™åŒ–é€€åŒ–ä¸ºæ™®é€š L2 æ­£åˆ™åŒ–ã€‚
- åœ¨ MNIST/CIFAR åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œæ›´å¼ºçš„ç­‰å˜åå¥½ï¼ˆé«˜ $ \lambda_\perp $ï¼‰å¸¦æ¥æ›´é«˜å‡†ç¡®ç‡ã€‚

#### **(2) èŒƒæ•°é€‰æ‹©çš„å½±å“ï¼ˆè¡¨ 5ï¼‰**
æ¯”è¾ƒä¸åŒçŸ©é˜µèŒƒæ•°ï¼š
- **Frobenius norm**ï¼ˆé»˜è®¤ï¼‰è¡¨ç°ç¨³å®šï¼ŒPSNR â‰ˆ 38.48ï¼ŒSSIM â‰ˆ 0.9457ã€‚
- **Spectral norm** è®¡ç®—æ›´æ…¢ï¼ˆepoch +13%ï¼‰ï¼Œæ€§èƒ½æ— æå‡ã€‚
- **Infinity norm** å’Œ **(1,1)-norm** å¯¼è‡´æ˜æ˜¾æ€§èƒ½ä¸‹é™ï¼ˆPSNR < 36ï¼‰ï¼Œè¡¨æ˜è¿‡äºå¼ºè°ƒæå€¼ä¼šæ¬ æ‹Ÿåˆã€‚

> âœ… æœ€ç»ˆé€‰æ‹© **Frobenius norm** ä½œä¸ºé»˜è®¤é…ç½®ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **æŠ•å½±æ­£åˆ™åŒ–æ˜¯ä¸€ç§ç†è®ºä¸Šä¸¥è°¨ä¸”é«˜æ•ˆçš„è¿‘ä¼¼ç­‰å˜æ–¹æ³•**ï¼š
   - é€šè¿‡æ­£äº¤åˆ†è§£ç›´æ¥ä½œç”¨äºæ¨¡å‹æƒé‡ï¼Œé¿å…äº†æ ·æœ¬çº§æ­£åˆ™åŒ–çš„é«˜æ–¹å·®å’Œé«˜è®¡ç®—æˆæœ¬ã€‚
   - ç†è®ºä¸Šè¯æ˜äº† $ \|T - P(T)\| $ ä¸æœ€å¤§ç­‰å˜ç¼ºé™· $ \mathcal{E}(T) $ æˆå¸¸æ•°å€å…³ç³»ï¼ˆLemma 3.2ï¼‰ï¼Œæ­£åˆ™åŒ–æ•ˆæœæœ‰ä¿éšœã€‚

2. **åœ¨å¤šç§ä»»åŠ¡å’Œç¾¤ç»“æ„ä¸‹å‡ä¼˜äºç°æœ‰æ–¹æ³•**ï¼š
   - åœ¨è¿ç»­ç¾¤ï¼ˆSO(2)ï¼‰ã€ç¦»æ•£ç¾¤ï¼ˆC4ï¼‰ä¸Šå‡æœ‰æ•ˆã€‚
   - åœ¨åˆæˆå’ŒçœŸå®ä»»åŠ¡ä¸­ consistently æå‡æ€§èƒ½ï¼Œå°¤å…¶åœ¨ OOD æ³›åŒ–åœºæ™¯ã€‚

3. **æ˜¾è‘—æå‡è®­ç»ƒæ•ˆç‡**ï¼š
   - æ— éœ€é¢å¤–å‰å‘ä¼ æ’­ï¼Œæ”¯æŒæ›´å¤§ batch sizeã€‚
   - åœ¨ CT-MAR ä»»åŠ¡ä¸­ï¼Œååé‡æå‡ **42â€“61%**ï¼Œepoch æ—¶é—´å‡å°‘è¿‘ä¸€åŠã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **éœ€è¦ä¸ºæ¯ç§æ¶æ„å’Œç¾¤æ“ä½œé‡æ–°æ¨å¯¼æŠ•å½±å½¢å¼**ï¼Œé€šç”¨æ€§å—é™ã€‚
- å½“å‰å®éªŒé›†ä¸­åœ¨ç®€å•ç¾¤ï¼ˆå¦‚ SO(2), C4, translationï¼‰ï¼Œå°šæœªæ‰©å±•åˆ°å¤æ‚å¤åˆç¾¤ï¼ˆå¦‚ SE(3) çš„å­ç¾¤ç»„åˆï¼‰ã€‚
- å¯¹éçº¿æ€§å±‚çš„ç­‰å˜æ€§å»ºæ¨¡ä»ä¾èµ–ä¼ ç»Ÿæ–¹å¼ï¼ˆå¦‚ equivariant activationï¼‰ï¼Œæœªå®Œå…¨ç»Ÿä¸€æ¡†æ¶ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ‰©å±•è‡³æ›´å¤æ‚çš„ç¾¤ç»“æ„ï¼ˆå¦‚ material science ä¸­çš„æ™¶æ ¼å¯¹ç§°ç¾¤ï¼‰ã€‚
- æ¢ç´¢è‡ªåŠ¨æ¨å¯¼æŠ•å½±ç®—å­çš„æ–¹æ³•ï¼Œæå‡æ¡†æ¶é€šç”¨æ€§ã€‚
- ç»“åˆ spectral parameterizationï¼ˆå¦‚ eSENï¼‰è¿›ä¸€æ­¥ä¼˜åŒ–è®­ç»ƒæ•ˆç‡ã€‚

---

> **æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºçš„ **projection-based regularisation** æ˜¯ä¸€ç§**ç†è®ºæ‰å®ã€é«˜æ•ˆå®ç”¨**çš„è¿‘ä¼¼ç­‰å˜å­¦ä¹ æ¡†æ¶ï¼Œè§£å†³äº†ä¼ ç»Ÿ sample-based æ–¹æ³•çš„æ•ˆç‡ç“¶é¢ˆï¼Œåœ¨å¤šä¸ªä»»åŠ¡ä¸Šå®ç°äº†**æ€§èƒ½ä¸é€Ÿåº¦çš„åŒé‡æå‡**ï¼Œä¸ºå¤§è§„æ¨¡åº”ç”¨ç­‰å˜æ€§æä¾›äº†æ–°æ€è·¯ã€‚

</details>

---

### 10. [LLMs for Explainable Business Decision-Making: A Reinforcement Learning Fine-Tuning Approach](https://arxiv.org/abs/2601.04208)

**Authors**: Xiang Cheng, Wen Wang, Anindya Ghose  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.04208v1  

#### Abstract
Artificial Intelligence (AI) models increasingly drive high-stakes consumer interactions, yet their decision logic often remains opaque. Prevailing explainable AI techniques rely on post hoc numerical feature attributions, which fail to provide coherent narratives behind model decisions. Large langu...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLLMs for Explainable Business Decision-Making: A Reinforcement Learning Fine-Tuning Approach

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡é’ˆå¯¹é«˜é£é™©å•†ä¸šå†³ç­–ï¼ˆå¦‚è´·æ¬¾å®¡æ‰¹ï¼‰ä¸­äººå·¥æ™ºèƒ½æ¨¡å‹ç¼ºä¹å¯è§£é‡Šæ€§çš„æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºå½“å‰ä¸»æµçš„ **post hoc** å¯è§£é‡Šæ€§æ–¹æ³•ï¼ˆå¦‚ SHAPã€LIMEï¼‰å­˜åœ¨ä¸‰å¤§ç¼ºé™·ï¼š

1. **è§£é‡Šä¸å¿ å®ï¼ˆUnfaithfulï¼‰**ï¼šæ•°å€¼ç‰¹å¾å½’å› æ˜¯äº‹åè¿‘ä¼¼ï¼Œæ— æ³•çœŸå®åæ˜ æ¨¡å‹å†³ç­–é€»è¾‘ã€‚
2. **ç¼ºä¹å™äº‹èƒ½åŠ›ï¼ˆNon-narrativeï¼‰**ï¼šè¾“å‡ºä¸ºæ•°å­—æƒé‡ï¼Œè€Œéäººç±»å¯ç†è§£çš„è‡ªç„¶è¯­è¨€å™è¿°ã€‚
3. **å¤šå—ä¼—é€‚é…å›°éš¾**ï¼šåŒä¸€å†³ç­–éœ€é¢å‘ä¸“å®¶ï¼ˆå¦‚è´·æ¬¾å®˜ï¼‰å’Œæ¶ˆè´¹è€…æä¾›ä¸åŒé£æ ¼çš„è§£é‡Šï¼Œä½†ä¼ ç»Ÿæ–¹æ³•éš¾ä»¥åœ¨ä¸æ”¹å˜å†³ç­–è§„åˆ™çš„å‰æä¸‹å®ç°é£æ ¼è°ƒæ•´ã€‚

æ­¤å¤–ï¼Œä¾èµ–äººå·¥æ ‡æ³¨çš„é«˜è´¨é‡è§£é‡Šè¿›è¡Œç›‘ç£å¾®è°ƒæˆæœ¬é«˜æ˜‚ï¼Œé™åˆ¶äº†å¤§è§„æ¨¡éƒ¨ç½²ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡º **LEXMA**ï¼ˆLLM-based EXplanations for Multi-Audience decisionsï¼‰ï¼Œä¸€ä¸ªåŸºäº **Reinforcement Learning** çš„ä¸¤é˜¶æ®µå¾®è°ƒæ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### âœ… **1. å†³ç­–-è§£é‡Šè”åˆç”Ÿæˆæ¶æ„ï¼ˆJoint Reasoning â†’ Explanation â†’ Predictionï¼‰**
- å¼ºåˆ¶æ¨¡å‹å…ˆç”Ÿæˆå†…éƒ¨æ¨ç†é“¾ï¼ˆReasoningï¼‰ï¼Œå†æç‚¼å‡ºç®€æ´è§£é‡Šï¼ˆExplanationï¼‰ï¼Œæœ€ååšå‡ºé¢„æµ‹ï¼ˆPredictionï¼‰ã€‚
- é¢„æµ‹ç»“æœä¾èµ–äºè§£é‡Šå†…å®¹ï¼Œç¡®ä¿è§£é‡Šä¸å†³ç­–é€»è¾‘å¯¹é½ï¼ˆdecision-alignedï¼‰ï¼Œæå‡è§£é‡Šçš„**å¿ å®æ€§ï¼ˆfaithfulnessï¼‰**ã€‚

#### âœ… **2. åŒé€‚é…å™¨æ¶æ„ï¼ˆDual Adaptersï¼‰åˆ†ç¦»â€œæ­£ç¡®æ€§â€ä¸â€œè¯­æ°”â€**
- **ACC Adapter**ï¼ˆCorrectness Adapterï¼‰ï¼šè´Ÿè´£å­¦ä¹ å†³ç­–è¾¹ç•Œå’Œé£é™©å› ç´ ï¼Œç”¨äºæ‰€æœ‰å—ä¼—ã€‚
- **TONE Adapter**ï¼ˆTone Adapterï¼‰ï¼šä»…ç”¨äºæ¶ˆè´¹è€…åœºæ™¯ï¼Œè°ƒæ•´è¯­æ°”ï¼ˆå¦‚ç¤¼è²Œã€æ˜“è¯»æ€§ï¼‰ï¼Œä¸å½±å“å†³ç­–ã€‚
- å®ç°**å¤šå—ä¼—é€šä¿¡**ï¼šä¸“å®¶ç«¯æ¿€æ´» ACCï¼›æ¶ˆè´¹è€…ç«¯åŒæ—¶æ¿€æ´» ACC + TONEï¼Œä¿è¯å†³ç­–ä¸€è‡´æ€§ã€‚

#### âœ… **3. æ ‡ç­¾é«˜æ•ˆè®­ç»ƒï¼ˆLabel-Efficient Trainingï¼‰**
- **ç¬¬ä¸€é˜¶æ®µ**ï¼šä½¿ç”¨å¼ºå‚è€ƒæ¨¡å‹ï¼ˆGPT-5ï¼‰ç”Ÿæˆå¸¦åæ€ï¼ˆreflection-augmentedï¼‰çš„ç›‘ç£æ•°æ®ï¼Œæ— éœ€äººå·¥æ ‡æ³¨ã€‚
- **ç¬¬äºŒé˜¶æ®µ**ï¼šé‡‡ç”¨ **Group Relative Policy Optimization (GRPO)** è¿›è¡Œå¼ºåŒ–å­¦ä¹ å¾®è°ƒï¼š
  - GRPO-Step1ï¼šä¼˜åŒ– ACC Adapterï¼Œå¥–åŠ±ä¿¡å·ä»…ä¸º**å†³ç­–æ­£ç¡®æ€§**ã€‚
  - GRPO-Step2ï¼šä¼˜åŒ– TONE Adapterï¼Œå¥–åŠ±ä¿¡å·ä¸º**å¯è¯»æ€§ï¼ˆFlesch-Kincaid â‰¤ 8ï¼‰** å’Œ **ç¤¼è²Œæ€§ï¼ˆpoliteness densityï¼‰**ï¼Œå‡ä¸ºè§„åˆ™é©±åŠ¨ï¼Œæ— éœ€äººå·¥è¯„åˆ†ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆSHAP/LIMEï¼‰ | é€šç”¨ LLMï¼ˆå¦‚ GPT-5/Qwenï¼‰ | LEXMA |
|------|------------------------|----------------------------|-------|
| è§£é‡Šå½¢å¼ | æ•°å€¼å½’å›  | è‡ªç„¶è¯­è¨€ï¼Œä½†å¯èƒ½ä¸å¿ å® | å¿ å®ä¸”å™äº‹æ€§å¼º |
| å¤šå—ä¼—æ”¯æŒ | å¦ | é€šè¿‡æç¤ºè¯è°ƒæ•´ï¼Œä½†å¯èƒ½æ”¹å˜å†³ç­– | æ˜¯ï¼Œé€šè¿‡åŒé€‚é…å™¨è§£è€¦ |
| è®­ç»ƒæˆæœ¬ | ä½ï¼ˆpost hocï¼‰ | é«˜ï¼ˆéœ€å¤§é‡äººå·¥æ ‡æ³¨è§£é‡Šï¼‰ | ä½ï¼ˆæ— éœ€äººå·¥æ ‡æ³¨ï¼‰ |
| å†³ç­–å‡†ç¡®æ€§ | ä¾èµ–é»‘ç›’æ¨¡å‹ | é€šå¸¸ä½äºæ ‘æ¨¡å‹ | æ¥è¿‘ XGBoost æ°´å¹³ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **HMDA Loan Application Register**ï¼ˆHome Mortgage Disclosure Actï¼‰
  - æ¥æºï¼šç¾å›½æ¶ˆè´¹è€…é‡‘èä¿æŠ¤å±€ï¼ˆCFPBï¼‰å…¬å¼€æ•°æ®
  - æ—¶é—´èŒƒå›´ï¼š2024å¹´å­é›†ï¼ˆé¿å… LLM è®°å¿†é—®é¢˜ï¼‰
  - æ ·æœ¬é‡ï¼šè¶…ç™¾ä¸‡æ¡è´·æ¬¾ç”³è¯·è®°å½•
  - ç‰¹å¾ï¼šè´·æ¬¾é‡‘é¢ã€åˆ©ç‡ã€å€ºåŠ¡æ”¶å…¥æ¯”ï¼ˆDTIï¼‰ã€ä¿¡ç”¨è¯„åˆ†ç­‰ç»“æ„åŒ–æ•°æ®
  - æ ‡ç­¾ï¼š`Approve` / `Deny`ï¼ˆAction Taken = 1 æˆ– 3ï¼‰
  - é¢„å¤„ç†ï¼šå»é™¤å—ä¿æŠ¤å±æ€§ï¼ˆç§æ—ã€æ€§åˆ«ï¼‰ï¼Œæ„å»ºç±»åˆ«å¹³è¡¡è®­ç»ƒé›†ï¼ˆ50%/50%ï¼‰

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **æ¨¡å‹é€‰æ‹©**
- åŸºåº§æ¨¡å‹ï¼š**Qwen3-4B**
- å¯¹æ¯”æ¨¡å‹ï¼š
  - ä¼ ç»Ÿ MLï¼šXGBoostã€Neural Networkã€Logistic Regressionã€Gradient Boosting
  - LLM åŸºçº¿ï¼šåŸå§‹ Qwen3-4Bã€GPT-5ï¼ˆmedian reasoning intensityï¼‰

#### **å¾®è°ƒæµç¨‹ï¼ˆä¸‰é˜¶æ®µï¼‰**
1. **SFT**ï¼ˆSupervised Fine-Tuningï¼‰ï¼šä½¿ç”¨ GPT-5 ç”Ÿæˆå¸¦åæ€çš„æ•°æ®è¿›è¡Œç›‘ç£è®­ç»ƒ
2. **GRPO-Step1**ï¼šä¼˜åŒ– ACC Adapterï¼Œæå‡å†³ç­–å‡†ç¡®æ€§
3. **GRPO-Step2**ï¼šä¼˜åŒ– TONE Adapterï¼Œæå‡æ¶ˆè´¹è€…è§£é‡Šçš„å¯è¯»æ€§å’Œç¤¼è²Œæ€§

#### **è¯„ä¼°æŒ‡æ ‡**

| ç±»åˆ« | æŒ‡æ ‡ |
|------|------|
| **å†³ç­–æ­£ç¡®æ€§** | F1 Scoreã€Accuracyã€Precisionã€Recall |
| **ä¸“å®¶è§£é‡Šè´¨é‡** | äººå·¥è¯„ä¼°ï¼šRisk Relevanceã€Decision Appropriatenessã€Explainabilityï¼ˆLikert 1â€“5ï¼‰ |
| **æ¶ˆè´¹è€…è§£é‡Šè´¨é‡** | äººå·¥è¯„ä¼°ï¼šClarityã€Politenessã€Fairnessã€Actionabilityã€Trustworthinessã€Satisfactionï¼ˆLikert 1â€“5ï¼‰ |
| **è‡ªåŠ¨é£æ ¼è¯„ä¼°** | Flesch-Kincaid Grade Levelï¼ˆç›®æ ‡ â‰¤ 8ï¼‰ã€Politeness Density |

#### **äººç±»è¯„ä¼°è®¾ç½®**
- **ä¸“å®¶è¯„ä¼°**ï¼š3 åèµ„æ·±è´·æ¬¾å®˜ï¼Œè¯„ä¼° 30 å¯¹æ ·æœ¬
- **æ¶ˆè´¹è€…è¯„ä¼°**ï¼š110 å Prolific ç”¨æˆ·ï¼Œå®Œæˆ 536 å¯¹æ¯”è¾ƒä»»åŠ¡

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **å†³ç­–æ­£ç¡®æ€§ï¼ˆTest Setï¼‰**

| æ¨¡å‹ | Prompt | F1 | Accuracy |
|------|--------|-----|----------|
| **LEXMA (GRPO-Step1)** | Expert | **0.897** | **0.845** |
| **LEXMA (GRPO-Step2)** | Consumer | **0.893** | **0.825** |
| Raw Qwen3-4B | Expert | 0.723 | 0.627 |
| Raw Qwen3-4B | Consumer | 0.726 | 0.632 |
| GPT-5 | Expert | 0.730 | 0.639 |
| GPT-5 | Consumer | 0.771 | 0.679 |
| XGBoost | â€” | 0.917 | 0.875 |

> âœ… LEXMA æ˜¾è‘—ä¼˜äºæ‰€æœ‰ LLM åŸºçº¿ï¼Œæ¥è¿‘ XGBoost æ€§èƒ½ï¼Œè¿œè¶…åŸå§‹ Qwen å’Œ GPT-5ã€‚

---

#### **æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰**

| é˜¶æ®µ | F1 (Expert) | Accuracy (Expert) | è´¡çŒ® |
|------|------------|------------------|------|
| Raw Qwen | 0.723 | 0.627 | åŸºçº¿ |
| + SFT | 0.825 | 0.757 | +10.2 F1ï¼Œç»“æ„åŒ–è®­ç»ƒæœ‰æ•ˆ |
| + GRPO-Step1 | **0.897** | **0.845** | +7.2 F1ï¼ŒRL æ˜¾è‘—æå‡å‡†ç¡®æ€§ |
| + GRPO-Step2 | 0.902 | 0.851 | å‡ ä¹æ— æŸï¼ŒéªŒè¯**è¯­æ°”å¾®è°ƒä¸ç ´åå†³ç­–** |

> ğŸ” è¯´æ˜ GRPO-Step2 æˆåŠŸå®ç°äº†â€œåªæ”¹è¯­æ°”ï¼Œä¸åŠ¨å†³ç­–â€ã€‚

---

#### **è§£é‡Šè´¨é‡ï¼ˆäººå·¥è¯„ä¼°ï¼‰**

##### **ä¸“å®¶è§£é‡Šåå¥½**
- **80%** çš„æ¡ˆä¾‹ä¸­ï¼Œä¸“å®¶æ›´åå¥½ LEXMA ç”Ÿæˆçš„è§£é‡Šã€‚
- æ‰€æœ‰ç»´åº¦æ˜¾è‘—æå‡ï¼ˆp < 0.01ï¼‰ï¼š
  - **Risk Relevance**: 3.4 â†’ 4.4
  - **Decision Appropriateness**: 2.2 â†’ 3.9
  - **Explainability**: 2.4 â†’ 3.6

##### **æ¶ˆè´¹è€…è§£é‡Šåå¥½**
- **78%** çš„ç”¨æˆ·é€‰æ‹© LEXMA è§£é‡Šã€‚
- æ‰€æœ‰ç»´åº¦æ˜¾è‘—æå‡ï¼ˆp < 0.001ï¼‰ï¼š
  - **Clarity**: 3.835 â†’ 4.212
  - **Actionability**: 3.444 â†’ 4.052ï¼ˆ+17.6%ï¼‰
  - **Satisfaction**: 3.692 â†’ 4.447ï¼ˆ+20.5%ï¼‰
  - **Politeness**: 4.124 â†’ 4.586
  - **Trustworthiness**: 3.742 â†’ 4.139

---

#### **è‡ªåŠ¨é£æ ¼è¯„ä¼°ï¼ˆæ¶ˆè´¹è€…è§£é‡Šï¼‰**

| æ¨¡å‹ | Readability Grade (è¶Šä½è¶Šå¥½) | Politeness Density (è¶Šé«˜è¶Šå¥½) |
|------|-------------------------------|------------------------------|
| Raw Qwen | 6.866 | 0.223 |
| GRPO-Step1 | 9.374 â†‘ï¼ˆå˜å·®ï¼‰ | 0.169 â†“ï¼ˆå˜å·®ï¼‰ |
| **GRPO-Step2** | **5.952 â†“**ï¼ˆè¾¾æ ‡ï¼‰ | **0.223 â†‘**ï¼ˆæ¢å¤ï¼‰ |

> âœ… GRPO-Step2 æˆåŠŸå°†å¯è¯»æ€§æ¢å¤è‡³å°å­¦å…«å¹´çº§æ°´å¹³ä»¥ä¸‹ï¼ˆPlain Languageï¼‰ï¼Œå¹¶æå‡ç¤¼è²Œæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **LEXMA å®ç°äº†é«˜å‡†ç¡®ã€é«˜å¯è§£é‡Šã€å¤šå—ä¼—é€‚é…çš„ç»Ÿä¸€**ï¼š
   - å†³ç­–æ€§èƒ½æ¥è¿‘ XGBoostï¼Œè¿œè¶…åŸå§‹ LLMã€‚
   - ç”Ÿæˆçš„è§£é‡Šè¢«ä¸“å®¶è®¤ä¸ºæ›´**é£é™©èšç„¦**ï¼Œè¢«æ¶ˆè´¹è€…è®¤ä¸ºæ›´**æ¸…æ™°ã€ç¤¼è²Œã€å¯æ“ä½œ**ã€‚

2. **åŒé€‚é…å™¨è®¾è®¡æˆåŠŸè§£è€¦â€œå†³ç­–â€ä¸â€œè¯­æ°”â€**ï¼š
   - åœ¨ä¸æ”¹å˜å†³ç­–è§„åˆ™çš„å‰æä¸‹ï¼Œå®ç°äº†é¢å‘ä¸åŒå—ä¼—çš„ä¸ªæ€§åŒ–æ²Ÿé€šã€‚

3. **æ ‡ç­¾é«˜æ•ˆè®­ç»ƒå¯è¡Œ**ï¼š
   - æ— éœ€äººå·¥æ ‡æ³¨è§£é‡Šï¼Œä»…ç”¨å†³ç­–æ ‡ç­¾ + è§„åˆ™å¥–åŠ±å³å¯æå‡è§£é‡Šè´¨é‡ã€‚

4. **å¼ºåŒ–å­¦ä¹ å¯æå‡ LLM åœ¨è¡¨æ ¼æ•°æ®ä¸Šçš„è¡¨ç°**ï¼š
   - é€šè¿‡ GRPO ä¼˜åŒ–ï¼ŒQwen3-4B åœ¨ tabular æ•°æ®ä¸Šè¾¾åˆ°æ¥è¿‘æ ‘æ¨¡å‹çš„æ€§èƒ½ã€‚

---

### **å±€é™æ€§**

1. **æ•°æ®é™åˆ¶**ï¼šHMDA æ•°æ®ç¼ºå°‘è¯¦ç»†ä¿¡ç”¨å†å²å’Œè¿˜æ¬¾è¡Œä¸ºï¼Œå½±å“æ¨¡å‹ä¸Šé™ã€‚
2. **è¯„ä¼°è§„æ¨¡æœ‰é™**ï¼š
   - ä¸“å®¶è¯„ä¼°ä»… 3 äººï¼Œæ¶ˆè´¹è€…ä¸ºåœ¨çº¿é¢æ¿ï¼ŒéçœŸå®ç”¨æˆ·ã€‚
   - ç¼ºä¹çœŸå®ä¸šåŠ¡ç¯å¢ƒä¸­çš„ A/B æµ‹è¯•ã€‚
3. **è§£é‡Šå¿ å®æ€§æœªå®Œå…¨éªŒè¯**ï¼šè™½é€šè¿‡æ¶æ„è®¾è®¡å¢å¼ºå¿ å®æ€§ï¼Œä½†æœªä½¿ç”¨å¯¹æŠ—æµ‹è¯•æˆ–å› æœå¹²é¢„è¿›ä¸€æ­¥éªŒè¯ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ‰©å±•åˆ°å…¶ä»–é«˜é£é™©å†³ç­–åœºæ™¯**ï¼šå¦‚ä¿é™©æ ¸ä¿ã€åŒ»ç–—è¯Šæ–­ã€æ‹›è˜ç­›é€‰ã€‚
2. **å¼•å…¥å°æ ·æœ¬äººå·¥åé¦ˆ**ï¼šåœ¨å…³é”®é¢†åŸŸåŠ å…¥å°‘é‡äººç±»åå¥½æ•°æ®ï¼Œè¿›ä¸€æ­¥æå‡è§£é‡Šè´¨é‡ã€‚
3. **åŠ¨æ€é€‚é…æ›´å¤šå—ä¼—ç±»å‹**ï¼šå¦‚ç›‘ç®¡æœºæ„ã€è‘£äº‹ä¼šæˆå‘˜ç­‰ã€‚
4. **ç»“åˆ LLM-as-a-Judge è¿›è¡Œè‡ªåŠ¨è¯„ä¼°**ï¼šæ„å»ºæ›´å¤æ‚çš„ reward modelã€‚
5. **æ¢ç´¢å¤šæ¨¡æ€è§£é‡Š**ï¼šç»“åˆæ–‡æœ¬ã€å›¾è¡¨ã€å¯è§†åŒ–å¢å¼ºå¯è§£é‡Šæ€§ã€‚

---

> **æ€»ç»“**ï¼šLEXMA æä¾›äº†ä¸€ä¸ª**ç³»ç»ŸåŒ–ã€ä½æˆæœ¬ã€å¯æ‰©å±•**çš„ LLM å¾®è°ƒæ¡†æ¶ï¼Œæ¨åŠ¨äº† **Explainable AI** ä»â€œäº‹åå½’å› â€å‘â€œå†…ç”Ÿå™äº‹â€çš„èŒƒå¼è½¬å˜ï¼Œä¸ºé«˜é£é™©å•†ä¸šå†³ç­–çš„é€æ˜åŒ–éƒ¨ç½²æä¾›äº†å®ç”¨è·¯å¾„ã€‚

</details>

---

### 11. [ReEfBench: Quantifying the Reasoning Efficiency of LLMs](https://arxiv.org/abs/2601.03550)

**Authors**: Zhizhang Fu, Yuancheng Gu, Chenkai Hu, Hanmeng Liu, Yue Zhang  
**Category**: cs.AI  
**Published**: 2026-01-09  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.03550v1  

#### Abstract
Test-time scaling has enabled Large Language Models (LLMs) to tackle complex reasoning, yet the limitations of current Chain-of-Thought (CoT) evaluation obscures whether performance gains stem from genuine reasoning or mere verbosity. To address this, (1) we propose a novel neuro-symbolic framework ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# ReEfBench: Quantifying the Reasoning Efficiency of LLMs è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ¨ç†èƒ½åŠ›è¯„ä¼°ä¸»è¦ä¾èµ– **Chain-of-Thought (CoT)** èŒƒå¼ï¼Œä½†å­˜åœ¨ä»¥ä¸‹æ ¸å¿ƒé—®é¢˜ï¼š
- **è¯„ä¼°ä¸å……åˆ†**ï¼šç°æœ‰æ–¹æ³•éš¾ä»¥åŒºåˆ†â€œçœŸæ­£çš„é€»è¾‘æ¨ç†â€ä¸â€œå†—é•¿çš„æ–‡æœ¬ç”Ÿæˆâ€ï¼ˆå³â€œoverthinkingâ€ç°è±¡ï¼‰ã€‚
- **ç¼ºä¹è¿‡ç¨‹æ€§è¯„ä¼°**ï¼šå¤šæ•°è¯„ä¼°ä»…å…³æ³¨æœ€ç»ˆç­”æ¡ˆæ­£ç¡®æ€§ï¼Œå¿½ç•¥äº†æ¨ç†è·¯å¾„çš„è´¨é‡ã€æ•ˆç‡å’Œè®¤çŸ¥è¡Œä¸ºã€‚
- **è®­ç»ƒç­–ç•¥å†²çª**ï¼šæ··åˆé•¿çŸ­ CoT æ•°æ®å¯èƒ½å¯¼è‡´æ¨¡å‹ç­–ç•¥å¹²æ‰°ï¼Œå½±å“æ¨ç†ç¨³å®šæ€§ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡ºäº† **ReEfBench** â€”â€” ä¸€ä¸ªåŸºäº **neuro-symbolicï¼ˆç¥ç»ç¬¦å·ï¼‰æ¡†æ¶** çš„éä¾µå…¥å¼ã€è¿‡ç¨‹ä¸­å¿ƒåŒ–çš„æ¨ç†æ•ˆç‡é‡åŒ–è¯„ä¼°ä½“ç³»ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
1. **æ„å»ºå¯æ‰©å±•ã€å¯æ§çš„ First-Order Logic (FOL) æ¨ç†æ•°æ®é›†**
   - åŸºäº Modus Ponens åŠå…¶æ‰©å±•è§„åˆ™ï¼ˆåˆå–ã€æå–ï¼‰ï¼Œé€šè¿‡åå‘é“¾å¼ç”Ÿæˆæœºåˆ¶æ„é€ å¤šè·³é€»è¾‘æ¨ç†é—®é¢˜ã€‚
   - æ”¯æŒç²¾ç¡®æ§åˆ¶é€»è¾‘æ·±åº¦ï¼ˆLogical Depthï¼‰ã€å¼•å…¥å¹²æ‰°é¡¹ï¼ˆdistractorsï¼‰ï¼Œå®ç°éš¾åº¦å¯è°ƒã€é€»è¾‘å¯éªŒè¯ã€‚

2. **æå‡ºå…­ç»´è¯Šæ–­æ€§è¯„ä¼°æŒ‡æ ‡**
   - å°†æ¨ç†è¿‡ç¨‹åˆ†è§£ä¸ºå¤šä¸ªèŠ‚ç‚¹ï¼Œå¹¶å®šä¹‰å…­ä¸ªå¯è§£é‡Šçš„è¯Šæ–­ç»´åº¦ï¼š
     - **Logical Depth (Sld)**ï¼šè¾¾æˆçš„æœ‰æ•ˆæœ€å¤§é€»è¾‘æ·±åº¦ã€‚
     - **Cost (Scost)**ï¼šè®¡ç®—æ¶ˆè€—ï¼ˆtoken æ•°é‡ + planning/reflection æ­¥éª¤é¢‘ç‡ï¼‰ã€‚
     - **Exploration (Sexp)**ï¼šæ¢ç´¢åˆ°çš„ç‹¬ç‰¹ä¸”æ­£ç¡®çš„é€»è¾‘èŠ‚ç‚¹æ•°ã€‚
     - **Efficiency (Seff)**ï¼šæ¯å•ä½æˆæœ¬å¸¦æ¥çš„é€»è¾‘è¿›å±•ï¼ˆtoken æ•ˆç‡ + æœ‰æ•ˆè·¨åº¦ï¼‰ã€‚
     - **Coherence (Scoh)**ï¼šå…ƒè®¤çŸ¥æ­¥éª¤ï¼ˆplanning/reflectionï¼‰æ˜¯å¦å¸¦æ¥å®é™…é€»è¾‘æ¨è¿›ã€‚
     - **Redundancy (Sred)**ï¼šå¥å­çº§å’ŒèŠ‚ç‚¹çº§é‡å¤ç¨‹åº¦ã€‚

3. **æå‡ºå››ç±»è¡Œä¸ºåŸå‹åˆ†ç±»æ³•**
   - åŸºäº K-means èšç±»åœ¨ `Logical Depth` vs `Cost` å¹³é¢ä¸Šè¯†åˆ«å‡ºå››ç§å…¸å‹è¡Œä¸ºæ¨¡å¼ï¼š
     - **Effective Solver**ï¼ˆé«˜æ•ˆæ±‚è§£è€…ï¼‰
     - **Deep Wanderer**ï¼ˆæ·±æ€æ¼«æ¸¸è€…ï¼‰
     - **Hollow Mimic**ï¼ˆç©ºæ´æ¨¡ä»¿è€…ï¼‰
     - **Lazy Guesser**ï¼ˆæ‡’æƒ°çŒœæµ‹è€…ï¼‰

4. **éä¾µå…¥å¼è§£ææ¶æ„**
   - ä½¿ç”¨å°å‹ LLM ä½œä¸º parserï¼Œå°†è‡ªç„¶è¯­è¨€ CoT è¾“å‡ºè‡ªåŠ¨è½¬åŒ–ä¸ºå½¢å¼åŒ–é€»è¾‘èŠ‚ç‚¹ï¼Œå†ç”±ç¬¦å·ç³»ç»Ÿè¿›è¡ŒéªŒè¯ä¸åˆ†æï¼Œé¿å…å¼ºåˆ¶æ ¼å¼é™åˆ¶æ¨¡å‹è‡ªç”±è¡¨è¾¾ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | ReEfBench | å…¶ä»–æ–¹æ³•ï¼ˆå¦‚ ProntoQA, FOLIO, Roscoeï¼‰ |
|------|-----------|----------------------------------------|
| Scalable | âœ… | âŒ æˆ–éƒ¨åˆ†æ”¯æŒ |
| FOL å½¢å¼åŒ–åŸºç¡€ | âœ… | âœ… (FOLIO, ProntoQA) / âŒ |
| Logic-only è¯„ä¼° | âœ… | âŒï¼ˆå¸¸æ··æ‚çŸ¥è¯†ï¼‰ |
| Logical Depth å¯é‡åŒ– | âœ… | âŒ æˆ–å¼±æ”¯æŒ |
| è¡Œä¸ºè¿‡ç¨‹å¯åˆ†æï¼ˆBehProcï¼‰ | âœ… | âŒ |
| éä¾µå…¥å¼ï¼ˆNonIntrusiveï¼‰ | âœ… | âŒï¼ˆéœ€ç‰¹å®šè¾“å‡ºæ ¼å¼ï¼‰ |

> âœ… è¡¨ç¤ºæ”¯æŒï¼ŒâŒ è¡¨ç¤ºä¸æ”¯æŒæˆ–ç¼ºå¤±

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **è‡ªå»º FOL æ¨ç†æ•°æ®é›†**ï¼šè¦†ç›–å¤æ‚åº¦ç­‰çº§ C=3 åˆ° C=11ï¼Œæ¯ä¸ªç­‰çº§ 100 ä¸ªæ ·æœ¬ï¼Œå…± 900 ä¸ªæµ‹è¯•å®ä¾‹ã€‚
- æ¯ä¸ªæ ·æœ¬åŒ…å«ï¼š
  - å‰æï¼ˆPremisesï¼‰
  - ç»“è®ºï¼ˆConclusionï¼‰
  - é»„é‡‘æ¨ç†è·¯å¾„ï¼ˆGolden Solutionï¼‰
  - å¹²æ‰°å‰æï¼ˆC ä¸ªæ— å…³å‰æï¼‰
- é€»è¾‘è§„åˆ™åŸºäº **Modus Ponens + Conjunction/Disjunction Introduction/Elimination**

### å®éªŒè®¾ç½®
- **è¯„ä¼°å¯¹è±¡**ï¼š25 ä¸ªä¸»æµå¼€æºä¸é—­æº LLMsï¼ŒåŒ…æ‹¬ï¼š
  - é—­æºï¼šClaude-Opus/Sonnet-4.5 (.long/.short)
  - å¼€æºï¼šQwen3 ç³»åˆ—ï¼ˆ3Bâ€“235Bï¼‰ã€DeepSeek-R1ã€QwQ-32B ç­‰
- **Prompt è®¾è®¡**ï¼š
  ```text
  Please answer the question based on the given information...
  Please reason step by step, show your reasoning process and put your final answer in \boxed{}
  ```
- **API å‚æ•°**ï¼š
  - Temperature = 0
  - Max Tokens: 24kï¼ˆthinking æ¨¡å¼ï¼‰ï¼Œ8kï¼ˆæ™®é€šæ¨¡å¼ï¼‰

### è¯„ä¼°æµç¨‹ï¼ˆäº”é˜¶æ®µ Pipelineï¼‰
1. **Phase A**ï¼šæ•°æ®ç”Ÿæˆï¼ˆå¯æ§å¤æ‚åº¦ï¼‰
2. **Phase B**ï¼šç›®æ ‡ LLM ç”Ÿæˆå“åº”
3. **Phase C**ï¼šLLM Parser åˆ†è§£å“åº” â†’ é€»è¾‘èŠ‚ç‚¹ï¼ˆnormal/reflection, actual/planningï¼‰
4. **Phase D**ï¼šè§„åˆ™å¼•æ“è®¡ç®—èŠ‚ç‚¹å±æ€§ï¼ˆæ­£ç¡®æ€§ã€é€»è¾‘æ·±åº¦ã€æœ‰æ•ˆæ€§ï¼‰
5. **Phase E**ï¼šèšåˆå…­å¤§æŒ‡æ ‡å¹¶èšç±»åˆ†ç±»

### åŸºçº¿å¯¹æ¯”
- æ— ç›´æ¥ä¼ ç»Ÿ baselineï¼Œè€Œæ˜¯ä¸å·²æœ‰æ¡†æ¶æ¨ªå‘æ¯”è¾ƒï¼ˆè§ Table 1ï¼‰ã€‚
- ä¸»è¦å¯¹æ¯”ä¸åŒæ¨ç†èŒƒå¼çš„è¡Œä¸ºå·®å¼‚ï¼š
  - Long CoT vs Short CoT
  - Thinking Mode vs Instruct Mode
  - Distilled æ¨¡å‹ vs Teacher æ¨¡å‹
  - Mixed Training vs Pure Training

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆComplexity Level 11ï¼‰

| Model | Category | Sld | Scost | Seff | Depth (raw) | Token (k) |
|-------|----------|-----|--------|--------|-------------|------------|
| Qwen3-235B-thinking | DeepWanderer | 1.00 | 0.88 | 0.47 | 10.54 | 16.8 |
| Claude-Opus-4.5.long | EffectiveSolver | 0.97 | 0.37 | 0.60 | 10.27 | 3.5 |
| QwQ-32B | HollowMimic | 0.68 | 0.61 | 0.48 | 7.12 | 5.7 |
| Qwen2.5-32B-Instruct | LazyGuesser | 0.28 | 0.16 | 0.55 | 2.90 | 0.7 |

> æ³¨ï¼šSld å’Œ Scost å·²å½’ä¸€åŒ–è‡³ [0,1]

### å››ç±»è¡Œä¸ºåŸå‹ç‰¹å¾æ€»ç»“

| ç±»åˆ« | ç‰¹å¾æè¿° | ä»£è¡¨æ¨¡å‹ | æ ¸å¿ƒæŒ‡æ ‡è¡¨ç° |
|------|---------|--------|--------------|
| **Effective Solver** | é«˜æ•ˆç²¾å‡†æ¨ç† | Claude-Opus-4.5.long | é«˜ Sld, ä½ Scost, é«˜ Seff, ä½ Sred |
| **Deep Wanderer** | å…¨é¢æœç´¢ä½†å†—ä½™ | Qwen3-235B-thinking | æé«˜ Scost, é«˜ Sld, ä½ Seff, é«˜ Sexp, é«˜ Sred |
| **Hollow Mimic** | åŠªåŠ›ä½†æ— æ•ˆæ‰©å±• | QwQ-32B, DS-R1-Distill-Qwen-7B | ä¸­ç­‰ Scost, ä½ Sld, ä½ Sexp, é«˜ Sred |
| **Lazy Guesser** | æµ…å±‚å°è¯•å³æ”¾å¼ƒ | Qwen2.5-32B-Instruct | æœ€ä½ Scost, æœ€ä½ Sld, â€œè™šå‡â€é«˜ Seffï¼ˆå› çŸ­ï¼‰ |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨ç›¸åŒä»»åŠ¡ä¸‹ï¼Œ**Long CoT å¹¶ä¸æ€»æ˜¯ä¼˜äº Short CoT**ï¼š
  - å½“å‰å…ˆè¿› Short CoTï¼ˆå¦‚ Qwen3-235B-Instructï¼‰èƒ½è¾¾åˆ°æ¥è¿‘ Long CoT çš„é€»è¾‘æ·±åº¦ï¼ˆä»…å·® 1.6%ï¼‰ã€‚
  - ä¼˜åŠ¿åœ¨äºæ˜¾è‘—æ›´ä½çš„æˆæœ¬ï¼ˆtoken å‡å°‘çº¦ 75%ï¼‰ã€‚
- **Distillation å¤±è´¥**ï¼š
  - å°† Long CoT è¡Œä¸ºè’¸é¦åˆ°å°æ¨¡å‹ï¼ˆå¦‚ 4B/8Bï¼‰åï¼Œè™½èƒ½æ¨¡ä»¿ reflection/planning å½¢å¼ï¼Œä½†æ— æ³•æå‡é€»è¾‘æ·±åº¦ã€‚
  - å‡ºç°â€œ**Diluted Expansion**â€ï¼šå¢åŠ  token ä½†æœªæé«˜ Wï¼ˆWork = Logical Depthï¼‰ã€‚
- **Mixed Training å±å®³å¤§**ï¼š
  - åŒæ—¶è®­ç»ƒ Long å’Œ Short CoT æ•°æ®ä¼šå¯¼è‡´â€œ**Premature Saturation or Collapse**â€ã€‚
  - å¦‚ Qwen3-235B.longï¼ˆmixedï¼‰ç›¸æ¯” Qwen3-235B-thinkingï¼ˆpureï¼‰æ›´æ—©åœæ­¢æ‰©å±• tokenï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰Reflection çš„ä½œç”¨ï¼ˆTable 4ï¼‰
| Model | Logical Depth | Reflection % |
|-------|----------------|---------------|
| Claude-Opus-4.5.long | 10.3 | 0.7% |
| Qwen3-235B-Instruct | 10.0 | 1.8% |
| Qwen2.5-32B-Instruct | 2.9 | 0.0% |

â†’ æˆåŠŸæ¨¡å‹å³ä½¿åœ¨ short mode ä¸‹ä¹Ÿä¿æŒä¸€å®š reflection è¡Œä¸ºï¼›å¤±è´¥æ¨¡å‹å‡ ä¹æ—  reflectionã€‚

#### ï¼ˆ2ï¼‰æ¨¡å‹è§„æ¨¡å¯¹è’¸é¦çš„å½±å“ï¼ˆFigure 5 & 10ï¼‰
- **Qwen3-4B/8B**ï¼šç”Ÿæˆæ›´å¤š reflection/planning æ­¥éª¤ï¼Œä½†è´¨é‡éšè§„æ¨¡å‡å°è€Œä¸‹é™ â†’ æ— æ³•è½¬åŒ–ä¸ºæ›´é«˜é€»è¾‘æ·±åº¦ã€‚
- **Qwen3-14B**ï¼šå”¯ä¸€èƒ½åœ¨è¡Œä¸ºå’Œèƒ½åŠ›ä¸Šä¸ 32B teacher å¯¹é½çš„å°æ¨¡å‹ â†’ **14B æ˜¯ä¸´ç•Œå®¹é‡é˜ˆå€¼**ã€‚

#### ï¼ˆ3ï¼‰Long vs Short CoT æ€§èƒ½å¢ç›Šï¼ˆTable 3ï¼‰
| Model | Depth Î” (Long vs Short) |
|-------|--------------------------|
| QwQ-32B | +97.1% |
| Qwen3-235B-thinking vs Instruct | +1.6% |
| Claude-Opus-4.5.long vs short | +8.8% |

â†’ æ˜¾ç¤ºç°ä»£æ¨¡å‹ä¸­ Long CoT çš„è¾¹é™…æ”¶ç›Šæ€¥å‰§ä¸‹é™ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **æ·±åº¦æ¨ç† â‰  é•¿æ–‡æœ¬ç”Ÿæˆ**
   - Extended token generation ä¸æ˜¯ deep reasoning çš„å¿…è¦æ¡ä»¶ã€‚
   - é«˜æ•ˆæ¨¡å‹ï¼ˆå¦‚ Claude-Opus-4.5.longï¼‰å¯ä»¥ç”¨æå°‘ token è¾¾æˆé«˜é€»è¾‘æ·±åº¦ã€‚

2. âœ… **å­˜åœ¨ä¸¤ç§æˆåŠŸè·¯å¾„**
   - **High-P Strategy (Effective Solver)**ï¼šé«˜æ•ˆç‡ï¼Œç²¾å‡†æ¨å¯¼ã€‚
   - **High-t Strategy (Deep Wanderer)**ï¼šé«˜æˆæœ¬ï¼Œç©·ä¸¾æ¢ç´¢ã€‚
   - äºŒè€…éƒ½èƒ½æˆåŠŸï¼Œä½†å‰è€…æ›´å…·éƒ¨ç½²ä»·å€¼ã€‚

3. âœ… **ä¸¤ç±»å¤±è´¥æ¨¡å¼è¢«æ˜ç¡®è¯†åˆ«**
   - **Hollow Mimic**ï¼šå½¢å¼ä¸Šæœ‰ planning/reflectionï¼Œä½†æ— å®è´¨é€»è¾‘è¿›å±• â†’ â€œè¡¨æ¼”æ€§æ¨ç†â€
   - **Lazy Guesser**ï¼šé¢å¯¹é«˜å¤æ‚åº¦è¿…é€Ÿé¥±å’Œæˆ–å´©æºƒ â†’ ç¼ºä¹ç»´æŒæ¨ç†çŠ¶æ€çš„èƒ½åŠ›

4. âš ï¸ **æ··åˆè®­ç»ƒæœ‰å®³**
   - Mixing Long and Short CoT data ä¼šç ´å High-t ç­–ç•¥ï¼Œå¯¼è‡´ premature saturationã€‚
   - å·¥ä¸šç•Œå·²è½¬å‘ä¸“ç”¨ tuningï¼ˆå¦‚ Qwen2507 æ”¾å¼ƒ mixed trainingï¼‰ã€‚

5. âš ï¸ **è’¸é¦æ— æ³•å¤åˆ¶é€»è¾‘æ•ˆèƒ½**
   - å°æ¨¡å‹å¯ä»¥æ¨¡ä»¿è€å¸ˆçš„â€œè¡Œä¸ºé•¿åº¦â€ï¼Œä½†ç”±äºå†…åœ¨å®¹é‡ä¸è¶³ï¼Œæ— æ³•å¤ç°å…¶â€œé€»è¾‘æ•ˆåŠ›â€ã€‚
   - å­˜åœ¨æ˜æ˜¾çš„ **capacity bottleneck**ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **é¢†åŸŸå—é™**ï¼šä»…é€‚ç”¨äº FOL å¯è¡¨è¾¾çš„å°é—­ä¸–ç•Œæ¨ç†ï¼Œä¸é€‚ç”¨äºå¼€æ”¾åŸŸé—®ç­”æˆ–åˆ›é€ æ€§æ¨ç†ã€‚
2. **éä¾µå…¥å¼é™åˆ¶**ï¼šåªèƒ½åˆ†ææ˜¾å¼å†™å‡ºçš„å†…å®¹ï¼Œæ— æ³•æ•æ‰éšå«æ¨ç†æ­¥éª¤ã€‚
3. **è¾¹ç•Œæ¨¡ç³Š**ï¼šå››ç±»åŸå‹æ˜¯ç»Ÿè®¡è¶‹åŠ¿ï¼Œä¸ªä½“æ¨¡å‹å¯èƒ½è·¨ç±»åˆ«ï¼Œåˆ†ç±»å…·æœ‰è¿ç»­æ€§ã€‚
4. **ä¾èµ– parser è´¨é‡**ï¼šå°½ç®¡ parser åœ¨äººå·¥æ ‡æ³¨é›†ä¸Šè¾¾åˆ° 94.3% F1ï¼Œä»å¯èƒ½å­˜åœ¨è¯¯è§£æé£é™©ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³å…¶ä»–é€»è¾‘ç³»ç»Ÿï¼ˆå¦‚é«˜é˜¶é€»è¾‘ã€æ¨¡æ€é€»è¾‘ï¼‰
- å¼•å…¥åŠ¨æ€èµ„æºåˆ†é…æœºåˆ¶ç ”ç©¶ test-time scaling çš„ä¼˜åŒ–ç­–ç•¥
- æ¢ç´¢å¦‚ä½•è®­ç»ƒæ¨¡å‹å®ç° adaptive switching between High-P and High-t strategies
- æ„å»ºé¢å‘çœŸå®åœºæ™¯çš„æ•ˆç‡-å‡†ç¡®æ€§æƒè¡¡ benchmark

---

> ğŸ”— **é¡¹ç›®åœ°å€**ï¼šhttps://anonymous.4open.science/r/LoG-1AD8/  
> ğŸ“„ **è®ºæ–‡é“¾æ¥**ï¼šhttps://arxiv.org/abs/2601.03550

</details>

---

### 12. [Attribute-Aware Controlled Product Generation with LLMs for E-commerce](https://arxiv.org/abs/2601.04200)

**Authors**: Virginia Negri, V\'ictor Mart\'inez G\'omez, Sergio A. Balanya, Subburam Rajaram  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.04200v1  

#### Abstract
Product information extraction is crucial for e-commerce services, but obtaining high-quality labeled datasets remains challenging. We present a systematic approach for generating synthetic e-commerce product data using Large Language Models (LLMs), introducing a controlled modification framework wi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAttribute-Aware Controlled Product Generation with LLMs for E-commerce

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
- **ç”µå•†é¢†åŸŸé«˜è´¨é‡æ ‡æ³¨æ•°æ®ç¨€ç¼º**ï¼šçœŸå®ä¸–ç•Œä¸­çš„äº§å“ä¿¡æ¯å¸¸å­˜åœ¨å™ªå£°ã€ä¸ä¸€è‡´æˆ–ç¼ºå¤±ï¼Œæ‰‹åŠ¨æ ‡æ³¨æˆæœ¬é«˜æ˜‚ä¸”éš¾ä»¥è¦†ç›–å¤šæ ·åŒ–çš„è¡¨è¾¾æ–¹å¼ã€‚
- **ç°æœ‰åˆæˆæ•°æ®ç”Ÿæˆæ–¹æ³•å±€é™æ€§å¤§**ï¼šä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚è§„åˆ™å˜æ¢ã€back-translationï¼‰ç”Ÿæˆå¤šæ ·æ€§æœ‰é™ï¼Œéš¾ä»¥ä¿æŒè¯­ä¹‰è¿è´¯æ€§å’Œç»“æ„ä¸€è‡´æ€§ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§åŸºäº **Large Language Models (LLMs)** çš„ç³»ç»Ÿæ€§æ¡†æ¶ï¼Œç”¨äºç”Ÿæˆå¯æ§çš„åˆæˆç”µå•†äº§å“æ•°æ®ã€‚å…¶æ ¸å¿ƒæ˜¯ **ä¸‰ç±»å—æ§ä¿®æ”¹ç­–ç•¥**ï¼š
1. **Positive Example Generation (correct)**ï¼šæ­£ç¡®åæ˜ å±æ€§å€¼ï¼Œç¡®ä¿æ–‡æœ¬å­—æ®µä¸­æ‰€æœ‰æåŠå‡ä¸ç»“æ„åŒ–å±æ€§ä¸€è‡´ã€‚
2. **Negative Example Generation (incorrect)**ï¼šå¼•å…¥å—æ§çš„ä¸ä¸€è‡´æ€§ï¼ˆä¾‹å¦‚åœ¨æè¿°ä¸­æš—ç¤ºé”™è¯¯å±æ€§ï¼‰ï¼Œæ¨¡æ‹Ÿç°å®ä¸­çš„ä½è´¨é‡æ•°æ®ã€‚
3. **Incomplete Example Generation (unknown)**ï¼šç§»é™¤ç›®æ ‡å±æ€§çš„æ‰€æœ‰æåŠï¼Œæ¨¡æ‹Ÿä¿¡æ¯ç¼ºå¤±åœºæ™¯ã€‚

è¯¥æ¡†æ¶é€šè¿‡ **attribute-aware prompts** å’Œå¤šé˜¶æ®µéªŒè¯æœºåˆ¶ï¼ˆåŒ…æ‹¬ Value Provider LLM å’Œ Similarity LLMï¼‰ï¼Œå®ç°å¯¹ç”Ÿæˆå†…å®¹çš„ç²¾ç»†æ§åˆ¶ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **å®Œæ•´æ€§** | ç”Ÿæˆå®Œæ•´çš„äº§å“ä¿¡æ¯ï¼ˆtitle, description, bullet pointsï¼‰ï¼Œè€Œéå•ä¸€å­—æ®µ |
| **å¯æ§æ€§** | æ”¯æŒç²¾ç¡®æ§åˆ¶å±æ€§ä¿®æ”¹ç±»å‹ï¼ˆæ­£/è´Ÿ/æœªçŸ¥ï¼‰ï¼Œé€‚é…ä¸‹æ¸¸ä»»åŠ¡éœ€æ±‚ |
| **çœŸå®æ€§ä¸ä¸€è‡´æ€§** | åˆ©ç”¨LLMå¼ºå¤§çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ç»´æŒè·¨å­—æ®µä¸€è‡´æ€§ï¼Œå¹¶ä¿ç•™åŸå§‹æ–‡æœ¬ç»“æ„ |
| **å»å“ç‰ŒåŒ–ï¼ˆbrand anonymizationï¼‰** | è‡ªåŠ¨æ›¿æ¢çœŸå®å“ç‰Œä¸ºè™šæ„åç§°ï¼ˆå¦‚â€œBRANDâ€ â†’ â€œNeoTechâ€ï¼‰ï¼Œé˜²æ­¢åè§ä¼ æ’­ |
| **å¯æ‰©å±•æ€§ä¸å¤šè¯­è¨€æ”¯æŒ** | å¯å¿«é€Ÿåº”ç”¨äºæ–°ç±»åˆ«æˆ–å¸‚åœºï¼Œé€‚åº”ä¸åŒç”µå•†å¹³å°è¦æ±‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **MAVE dataset (Yang et al., 2022)**ï¼šå¤§è§„æ¨¡ç”µå•†å±æ€§æå–å…¬å¼€æ•°æ®é›†ï¼ŒåŒ…å«è¶…è¿‡ 220 ä¸‡äº§å“ï¼Œæ¶µç›– 1,257 ä¸ªç±»åˆ«å’Œ 662 ç§å±æ€§ã€‚
- å®éªŒé‡‡æ ·äº† **2,000 ä¸ªäº§å“**ï¼Œæ¥è‡ª top 200 ç±»åˆ«ï¼Œæ¯ä¸ªäº§å“éšæœºé€‰æ‹©ä¸€ä¸ªå±æ€§è¿›è¡Œä¿®æ”¹ã€‚

### å®éªŒè®¾ç½®
- **ç”Ÿæˆç­–ç•¥åˆ†å¸ƒ**ï¼š
  - æ­£ç¡®ä¿®æ”¹ï¼ˆcorrectï¼‰ï¼š50%
  - é”™è¯¯ç¤ºä¾‹ï¼ˆincorrectï¼‰ï¼š25%
  - å±æ€§ç¼ºå¤±ï¼ˆunknownï¼‰ï¼š25%
- **æ¨¡å‹å®ç°**ï¼š
  - ä¸»è¦ä½¿ç”¨ **Claude Haiku** ä½œä¸º Generation LLM å’Œ Value Provider LLM
  - ä½¿ç”¨ **sentence-transformers/all-MiniLM-L6-v2** ä½œä¸º Similarity LLM è¿›è¡Œè¯­ä¹‰åŒºåˆ†
- **prompt design å››è¦ç´ **ï¼š
  1. Role Definitionï¼ˆè§’è‰²å®šä¹‰ï¼‰
  2. Task Instructionsï¼ˆä»»åŠ¡æŒ‡ä»¤ï¼‰
  3. Product Contextï¼ˆäº§å“ä¸Šä¸‹æ–‡ï¼‰
  4. Output Formatï¼ˆè¾“å‡ºæ ¼å¼ï¼ŒJSONï¼‰

### è¯„ä¼°æŒ‡æ ‡
#### ï¼ˆ1ï¼‰äººå·¥è¯„ä¼°ï¼ˆHuman Evaluationï¼‰
ç”±ä¸‰ä½å…·å¤‡ç”µå•†èƒŒæ™¯çš„ä¸“å®¶ç‹¬ç«‹æ‰“åˆ†ï¼Œå…±è¯„ä¼° 2,000 æ¡æ ·æœ¬ï¼Œå…³æ³¨ä»¥ä¸‹ç»´åº¦ï¼š
- Attribute Value Qualityï¼ˆå±æ€§å€¼åˆç†æ€§ï¼‰
- Negative Example Coherenceï¼ˆè´Ÿé¢ä¾‹å­åˆç†æ€§ï¼‰
- Cross-field Consistencyï¼ˆè·¨å­—æ®µä¸€è‡´æ€§ï¼‰
- Brand Modification Successï¼ˆå“ç‰Œæ›¿æ¢æˆåŠŸç‡ï¼‰
- Content Preservationï¼ˆéç›®æ ‡å†…å®¹æ˜¯å¦è¢«æ„å¤–æ›´æ”¹ï¼‰
- Professional Writingï¼ˆæ•´ä½“è¯­è¨€è‡ªç„¶åº¦ï¼‰

æœ€ç»ˆé‡‡ç”¨å¤šæ•°æŠ•ç¥¨å†³å®šç»“æœã€‚

#### ï¼ˆ2ï¼‰ä¸‹æ¸¸ä»»åŠ¡è¯„ä¼°ï¼ˆDownstream Taskï¼‰
- **ä»»åŠ¡**ï¼šAttribute Value Extractionï¼ˆå±æ€§å€¼æŠ½å–ï¼‰
- **æ¨¡å‹**ï¼šFLAN-T5-base
- **è¾“å…¥å¤„ç†**ï¼šå°† title, description, features æ‹¼æ¥æˆ structured prompt
- **è®­ç»ƒé…ç½®**ï¼š
  - ä½¿ç”¨ ~800 æ¡ correct ç¤ºä¾‹è®­ç»ƒï¼ˆ80%ï¼‰å’ŒéªŒè¯ï¼ˆ20%ï¼‰
  - æµ‹è¯•é›†ä¸ºå‰©ä½™ ~1,000 æ¡äº§å“
  - å¯¹æ¯”å¤šç§æ•°æ®ç»„åˆé…ç½®

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| é…ç½® | æè¿° |
|------|------|
| Zero-shot | ä¸ä½¿ç”¨ä»»ä½•è®­ç»ƒæ•°æ®ï¼Œç›´æ¥æ¨ç† |
| Original-only | ä»…ä½¿ç”¨åŸå§‹çœŸå®æ•°æ®è®­ç»ƒ |
| Synthetic-only | ä»…ä½¿ç”¨åˆæˆæ•°æ®è®­ç»ƒ |
| Hybrid Configurations | æ··åˆä½¿ç”¨åŸå§‹ä¸åˆæˆæ•°æ®ï¼ˆ75/25, 50/50, 25/75ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### äººå·¥è¯„ä¼°ç»“æœï¼ˆN = 2,000ï¼‰
| æŒ‡æ ‡ | å¾—åˆ†ï¼ˆ%ï¼‰ |
|-------------------------------|--------|
| åˆæˆäº§å“è¯­è¨€è‡ªç„¶åº¦ï¼ˆReadabilityï¼‰ | **99.6%** |
| å±æ€§å€¼æœ‰æ•ˆç‡ï¼ˆValid Attribute Valuesï¼‰ | **96.5%** |
| å“ç‰ŒåŒ¿ååŒ–æˆåŠŸ | **95.8%** |
| è·¨å­—æ®µä¸€è‡´æ€§ï¼ˆCorrect ä¿®æ”¹ï¼‰ | **94.2%** |
| è·¨å­—æ®µä¸€è‡´æ€§ï¼ˆIncorrect ä¿®æ”¹ï¼‰ | **93.0%** |
| è·¨å­—æ®µä¸€è‡´æ€§ï¼ˆUnknown ä¿®æ”¹ï¼‰ | **88.3%** |
| æ— é¢å¤–å˜æ›´ï¼ˆContent Preservationï¼‰ | **88.8%** |

> âœ… è¡¨æ˜åˆæˆäº§å“è´¨é‡æé«˜ï¼Œæ¥è¿‘äººç±»æ’°å†™æ°´å¹³ã€‚

---

### ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ï¼ˆAttribute Extraction Accuracyï¼‰

| é…ç½® | Test Accuracy (%) |
|---------------------------------------------|------------------|
| Zero-shot Baseline | **13.40** |
| Original Data Only (100%) | **60.79** |
| Synthetic Data Only (100%) | **60.48** |
| Original 75% + Synthetic 25% | **68.82** â¬†ï¸ |
| Original 50% + Synthetic 50% | **66.11** |
| Original 25% + Synthetic 75% | **64.44** |

> ğŸ” å…³é”®å‘ç°ï¼š
> - **çº¯åˆæˆæ•°æ®è¡¨ç° â‰ˆ çœŸå®æ•°æ®**ï¼ˆ60.48% vs 60.79%ï¼‰ï¼Œè¯´æ˜åˆæˆæ•°æ®å…·æœ‰é«˜åº¦å¯ç”¨æ€§
> - **æ··åˆè®­ç»ƒæ˜¾è‘—æå‡æ€§èƒ½**ï¼Œæœ€ä¼˜è¾¾åˆ° **68.82%**ï¼Œä¼˜äºå•ç‹¬ä½¿ç”¨çœŸå®æˆ–åˆæˆæ•°æ®
> - éšç€åˆæˆæ¯”ä¾‹å¢åŠ ï¼Œæ€§èƒ½ç•¥æœ‰ä¸‹é™ï¼Œæç¤ºéœ€å¹³è¡¡æ•°æ®æ¥æº

---

### æ¶ˆèåˆ†æä¸è¯¯å·®åˆ†æï¼ˆError Analysisï¼‰
- æ‰‹åŠ¨å®¡æŸ¥ 441 æ¡â€œé¢„æµ‹é”™è¯¯â€çš„æ¡ˆä¾‹ï¼Œå‘ç°è®¸å¤šå®é™…ä¸º **è¯­ä¹‰æ­£ç¡®ä½†æ ¼å¼ä¸åŒ**ï¼Œå½’ç±»ä¸ºä¸ƒç§åˆç†å˜ä½“ï¼š
  1. Granularity differencesï¼ˆç²’åº¦å·®å¼‚ï¼Œå¦‚ "running" vs "running shoe"ï¼‰
  2. Morphological variationsï¼ˆå•å¤æ•°å˜åŒ–ï¼‰
  3. Multiple valid valuesï¼ˆå¤šä¸ªåˆæ³•æ ‡ç­¾ï¼‰
  4. Missing unitsï¼ˆç¼ºå°‘å•ä½ï¼‰
  5. Equivalent definitionsï¼ˆç­‰ä»·å®šä¹‰ï¼‰
  6. Contextual synonymsï¼ˆä¸Šä¸‹æ–‡åŒä¹‰è¯ï¼‰
  7. Format variationsï¼ˆå‘½åæ ¼å¼å·®å¼‚ï¼‰

> ğŸ’¡ è¿™è¡¨æ˜å½“å‰æ ‡æ³¨æ ‡å‡†æœ¬èº«å­˜åœ¨æ¨¡ç³Šæ€§ï¼Œè€Œæ¨¡å‹è¾“å‡ºæ›´å…·çµæ´»æ€§ï¼Œåè¡¬å‡ºçœŸå®æ•°æ®æ ‡æ³¨çš„ä¸€è‡´æ€§æŒ‘æˆ˜ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦ç»“è®º
1. **LLM å¯é«˜æ•ˆç”Ÿæˆé«˜è´¨é‡ã€å¯æ§çš„åˆæˆç”µå•†äº§å“æ•°æ®**ï¼Œåœ¨è¯­è¨€è‡ªç„¶åº¦ï¼ˆ99.6%ï¼‰ã€å±æ€§æœ‰æ•ˆæ€§ï¼ˆ96.5%ï¼‰æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚
2. **åˆæˆæ•°æ®åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­åª²ç¾çœŸå®æ•°æ®æ€§èƒ½**ï¼ˆ60.5% vs 60.8%ï¼‰ï¼Œæ˜¾è‘—è¶…è¶Šé›¶æ ·æœ¬åŸºçº¿ï¼ˆ13.4%ï¼‰ã€‚
3. **æ··åˆä½¿ç”¨åˆæˆä¸çœŸå®æ•°æ®å¯è¿›ä¸€æ­¥æå‡æ€§èƒ½è‡³ 68.8%**ï¼Œè¯æ˜äºŒè€…äº’è¡¥æ€§å¼ºã€‚
4. è¯¥æ¡†æ¶æ”¯æŒ **multi-lingualã€multi-categoryã€brand-anonymized** æ•°æ®ç”Ÿæˆï¼Œé€‚ç”¨äºä½èµ„æºåœºæ™¯ä¸‹çš„å¿«é€Ÿå†·å¯åŠ¨ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
| å±€é™ | å…·ä½“è¯´æ˜ |
|------|----------|
| ä¾èµ–è¾“å…¥æ•°æ®è´¨é‡ | è‹¥æºäº§å“æè¿°ç©ºæ´æˆ–å±æ€§å®šä¹‰ä¸æ¸…ï¼ˆå¦‚ `type="shoes"`ï¼‰ï¼Œä¼šå½±å“ç”Ÿæˆè´¨é‡ |
| å•å±æ€§ä¿®æ”¹é™åˆ¶ | å½“å‰ä»…æ”¯æŒä¸€æ¬¡ä¿®æ”¹ä¸€ä¸ªå±æ€§ï¼Œæœªè€ƒè™‘å¤šå±æ€§äº¤äº’å½±å“ |
| ç»“æ„åç¦»é£é™© | 4.2% çš„æ ·æœ¬å‡ºç°é‡å¤§éé¢„æœŸæ”¹åŠ¨ï¼Œå°¤å…¶å½“åŸå§‹æè¿°ä¸ºç©ºæ—¶ |
| åè§ä¼ é€’å¯èƒ½ | å°½ç®¡å“ç‰Œå·²åŒ¿åï¼Œä½†æºæ•°æ®ä¸­çš„å±æ€§åˆ†å¸ƒåå·®ä»å¯èƒ½å»¶ç»­ |
| è¯„ä¼°é›†ä¸­äº positive ç¤ºä¾‹ | negative å’Œ unknown ç¤ºä¾‹å°šæœªç”¨äºä¸‹æ¸¸ä»»åŠ¡å…¨é¢æµ‹è¯• |

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **å¢å¼ºå¤šå±æ€§è”åˆä¿®æ”¹èƒ½åŠ›**ï¼šç ”ç©¶å¤šä¸ªç›¸å…³å±æ€§ä¹‹é—´çš„ååŒå˜åŒ–ï¼ˆå¦‚ä»â€œvanillaâ€æ”¹ä¸ºâ€œchocolateâ€æ—¶è‡ªåŠ¨æ›´æ–°äº§åœ°ä¸ºâ€œSwitzerlandâ€ï¼‰ã€‚
2. **ç²¾ç»†åŒ–æ§åˆ¶å±æ€§ç²’åº¦ä¸åˆ†å¸ƒ**ï¼šé€šè¿‡ attribute-specific vocabularies æˆ– controlled decoding æŠ€æœ¯ç»Ÿä¸€å€¼çš„è¡¨è¾¾å±‚çº§ã€‚
3. **æ”¹è¿›æ··åˆè®­ç»ƒç­–ç•¥**ï¼šæ¢ç´¢æ›´ä¼˜çš„æ•°æ®èåˆæ–¹å¼ï¼Œç†è§£ synthetic ä¸ real data åœ¨ä¸åŒç±»å‹å±æ€§ä¸Šçš„äº’è¡¥æœºåˆ¶ã€‚
4. **åŠ å¼ºä¿®æ”¹çº¦æŸæœºåˆ¶**ï¼šå‡å°‘éç›®æ ‡å­—æ®µçš„æ„å¤–å˜æ›´ï¼Œæå‡ç”Ÿæˆç¨³å®šæ€§ã€‚
5. **æ‹“å±•åˆ°æ›´å¤šä¸‹æ¸¸ä»»åŠ¡**ï¼šå¦‚ product matchingã€recommendationã€QA ç­‰ï¼ŒéªŒè¯åˆæˆæ•°æ®æ³›åŒ–èƒ½åŠ›ã€‚
6. **å¼•å…¥æ›´å¼ºçš„ debiasing æœºåˆ¶**ï¼šä¸»åŠ¨æ£€æµ‹å¹¶ä¿®æ­£æ½œåœ¨çš„ç¤¾ä¼šæˆ–å•†ä¸šåè§ã€‚

---

> ğŸ“Œ **æ€»ä½“è¯„ä»·**ï¼šæœ¬æ–‡æä¾›äº†ä¸€ä¸ªå®ç”¨ã€å¯æ‰©å±•ã€é«˜è´¨é‡çš„åˆæˆç”µå•†æ•°æ®ç”Ÿæˆæ¡†æ¶ï¼Œåœ¨è§£å†³æ•°æ®ç¨€ç¼ºé—®é¢˜ä¸Šè¿ˆå‡ºé‡è¦ä¸€æ­¥ï¼Œå°¤å…¶é€‚åˆéœ€è¦å¿«é€Ÿæ„å»ºè®­ç»ƒé›†çš„æ–°å“ç±»æˆ–æ–°å¸‚åœºéƒ¨ç½²ã€‚

</details>

---

### 13. [AM$^3$Safety: Towards Data Efficient Alignment of Multi-modal Multi-turn Safety for MLLMs](https://arxiv.org/abs/2601.04736)

**Authors**: Han Zhu, Jiale Chen, Chengkun Cai, Shengjie Sun, Haoran Li, Yujin Zhou, Chi-Min Chan, Pengcheng Wen, Lei Li, Sirui Han, Yike Guo  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.04736v1  

#### Abstract
Multi-modal Large Language Models (MLLMs) are increasingly deployed in interactive applications. However, their safety vulnerabilities become pronounced in multi-turn multi-modal scenarios, where harmful intent can be gradually reconstructed across turns, and security protocols fade into oblivion as...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# AMÂ³Safety: Towards Data Efficient Alignment of Multi-modal Multi-turn Safety for MLLMs

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰å®‰å…¨å¯¹é½æ–¹æ³•ä¸»è¦é’ˆå¯¹å•è½®è§†è§‰é—®ç­”ï¼ˆVQAï¼‰ä»»åŠ¡è®¾è®¡ï¼Œä¸”é€šå¸¸ä¾èµ–æ˜‚è´µçš„äººå·¥åå¥½æ ‡æ³¨ã€‚è¿™äº›æ–¹æ³•åœ¨å¤šè½®å¤šæ¨¡æ€å¯¹è¯åœºæ™¯ä¸­æ•ˆæœæœ‰é™ï¼Œå› ä¸ºï¼š
- å¯¹è¯ä¸­çš„æœ‰å®³æ„å›¾å¯ä»¥é€šè¿‡å¤šè½®äº¤äº’é€æ­¥é‡æ„ï¼ˆmulti-turn intent reconstructionï¼‰
- éšç€å¯¹è¯è¿›è¡Œï¼Œå®‰å…¨åè®®å®¹æ˜“è¢«é—å¿˜
- ç¼ºä¹é«˜è´¨é‡çš„å¤šæ¨¡æ€å¯¹è¯å®‰å…¨æ•°æ®é›†
- æ‰‹åŠ¨æ ‡æ³¨æˆæœ¬é«˜æ˜‚

### æå‡ºçš„æ–°æ–¹æ³•å’Œæ€è·¯
æœ¬æ–‡æå‡ºäº† **AMÂ³Safety** æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¸Šè¿°æŒ‘æˆ˜ï¼š

#### ï¼ˆ1ï¼‰InterSafe-V æ•°æ®é›†
- æ„å»ºäº†ä¸€ä¸ªåŒ…å« **11,270 ä¸ªå¯¹è¯** å’Œ **500 ä¸ªä¸“é—¨è®¾è®¡çš„æ‹’ç»å‹ VQA æ ·æœ¬** çš„å¼€æºå¤šæ¨¡æ€å¯¹è¯å®‰å…¨è®­ç»ƒæ•°æ®é›†ã€‚
- æ•°æ®é€šè¿‡ **æ¨¡å‹é—´äº¤äº’ï¼ˆmodel-to-model interactionï¼‰** è‡ªåŠ¨ç”Ÿæˆï¼Œæ— éœ€äººå·¥æ ‡æ³¨ï¼Œæ˜¾è‘—é™ä½æ•°æ®æ„å»ºæˆæœ¬ã€‚
- é‡‡ç”¨ä¸‰æ­¥æ•°æ®æ„é€ æµç¨‹ï¼š
  1. **æœ‰å®³æ„å›¾åˆ†è§£ï¼ˆHarmful Intent Decompositionï¼‰**ï¼šå°†åŸå§‹æœ‰å®³æŸ¥è¯¢æ‹†åˆ†ä¸ºå¤šä¸ªç‹¬ç«‹ä½†ç»„åˆåä»å…·é£é™©çš„å­æŸ¥è¯¢ã€‚
  2. **å¯¹è¯æ¨¡æ‹Ÿå™¨ï¼ˆConversation Simulatorï¼‰**ï¼šåˆ©ç”¨ä¸¤ä¸ª MLLM è¿›è¡Œå¯¹æŠ—æ€§å¯¹è¯ç”Ÿæˆï¼ˆä¸€ä¸ªä½œä¸ºâ€œå®‰å…¨ä¸“å®¶â€è¯±å¯¼æ”»å‡»ï¼Œå¦ä¸€ä¸ªä½œä¸ºç›®æ ‡æ¨¡å‹å“åº”ï¼‰ã€‚
  3. **æ•°æ®æ¸…æ´—ï¼ˆData Cleaningï¼‰**ï¼šè¿‡æ»¤é«˜åº¦ç›¸ä¼¼å›¾åƒå’Œåç¦»ä¸»é¢˜çš„å¯¹è¯ï¼Œç¡®ä¿æ•°æ®è´¨é‡å’Œæ½œåœ¨é£é™©ã€‚

#### ï¼ˆ2ï¼‰AMÂ³Safety æ¡†æ¶
ç»“åˆå†·å¯åŠ¨æ‹’ç»å­¦ä¹ ä¸åŸºäº **Group Relative Policy Optimization (GRPO)** çš„å¾®è°ƒï¼Œå®ç°é«˜æ•ˆçš„å®‰å…¨å¯¹é½ï¼š
- **å†·å¯åŠ¨é˜¶æ®µï¼ˆCold-start Refusal Learningï¼‰**ï¼šå…ˆè®©æ¨¡å‹å­¦ä¼šä»¥åˆç†è§£é‡Šçš„æ–¹å¼æ‹’ç»æœ‰å®³è¯·æ±‚ï¼Œå»ºç«‹åŸºç¡€å®‰å…¨èƒ½åŠ›ã€‚
- **GRPO å¾®è°ƒé˜¶æ®µ**ï¼šå¼•å…¥ **turn-aware dual-objective reward function**ï¼ŒåŠ¨æ€æƒè¡¡æ¯ä¸€è½®çš„å®‰å…¨æ€§å’Œæœ‰ç”¨æ€§ï¼Œç¡®ä¿æ•´ä¸ªå¯¹è¯è¿‡ç¨‹çš„ä¸€è‡´æ€§è¡Œä¸ºã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ RLHF-V, Safe RLHF-V, MM-DPOï¼‰ | AMÂ³Safety |
|------|------------------------------------------|---------|
| æ•°æ®å½¢å¼ | å•è½® VQA | å¤šè½®å¤šæ¨¡æ€å¯¹è¯ |
| æ•°æ®æ¥æº | äººå·¥æ ‡æ³¨ä¸ºä¸» | æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆï¼Œæ— é¡»äººå·¥æ ‡æ³¨ |
| å®‰å…¨æœºåˆ¶ | é™æ€é˜²å¾¡ | åŠ¨æ€ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„ turn-aware æƒé‡æœºåˆ¶ |
| æˆæœ¬æ•ˆç‡ | é«˜æ ‡æ³¨æˆæœ¬ | æ•°æ®é«˜æ•ˆï¼Œä½æˆæœ¬ |
| å¯¹æŠ—å¤æ‚æ”»å‡»èƒ½åŠ› | å¼±ï¼ˆæ˜“è¢«è§’è‰²æ‰®æ¼”ç­‰ç»•è¿‡ï¼‰ | å¼ºï¼ˆæ”¯æŒæ¸è¿›å¼æ„å›¾é‡æ„æ”»å‡»æ¨¡æ‹Ÿï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | ç±»å‹ | è§„æ¨¡ | ç‰¹ç‚¹ |
|--------|------|------|------|
| **InterSafe-V** | è‡ªå»ºè®­ç»ƒé›† | 11,270 å¯¹è¯ + 500 æ‹’ç» VQA | æ¨¡å‹ç”Ÿæˆï¼Œå¤šè½®å¤šå›¾ï¼Œè¦†ç›– 20 ç±»å®‰å…¨é£é™© |
| **SafeMT** | åŸºå‡†æµ‹è¯•é›† | - | ä¸“ä¸ºå¤šè½®å¤šæ¨¡æ€å¯¹è¯å®‰å…¨è®¾è®¡ |
| **JailbreakV-mini** | åŸºå‡†æµ‹è¯•é›† | - | è¯„ä¼°å¯¹æŠ—æ€§è¶Šç‹±æ”»å‡»é²æ£’æ€§ |
| **MM-SafetyBench** | åŸºå‡†æµ‹è¯•é›† | - | å¤šæ¨¡æ€å®‰å…¨ç»¼åˆè¯„æµ‹ |
| **MMSafe-PO** | åŸºå‡†æµ‹è¯•é›† | - | åŒ…å«å°‘é‡å¯¹è¯æ ·æœ¬çš„å®‰å…¨è¯„æµ‹ |
| **MMDU / ConvBench** | é€šç”¨èƒ½åŠ›åŸºå‡† | - | è¯„ä¼°å¤šæ¨¡æ€å¯¹è¯ç†è§£ä¸è¿è´¯æ€§ |
| **ScienceQA / MathVista / Geometry3k / MathVerse** | æ¨ç†èƒ½åŠ›åŸºå‡† | - | æµ‹è¯•æ¨¡å‹é€»è¾‘æ¨ç†èƒ½åŠ›æ˜¯å¦å—æŸ |

### å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼š
  - Qwen2.5-VL-7B-Instruct
  - LLaVA-NeXT-7B
- **è®­ç»ƒé…ç½®**ï¼š
  - ä½¿ç”¨ 8Ã—H800 GPU
  - GRPO å¾®è°ƒä½¿ç”¨ 7,000 ä¸ªå¯¹è¯ï¼ˆå°‘äºå®Œæ•´æ•°æ®é›†ï¼‰ï¼Œè®­ç»ƒä¸è¶³ 15 è½®
  - Rollout æ•°é‡ï¼š8
  - Batch Sizeï¼š128
- **å¥–åŠ±æ¨¡å‹**ï¼šä½¿ç”¨ InternVL3-78B ä½œä¸ºè‡ªåŠ¨è¯„åˆ¤æ¨¡å‹ï¼ˆLLM-as-a-judgeï¼‰

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ | è¯´æ˜ |
|------|------|------|
| **Win Rate** | æ¥è‡ª Safe RLHF-V çš„ç›¸å¯¹èƒœç‡æŒ‡æ ‡ | ç»¼åˆè¡¡é‡ helpfulness ä¸ harmlessnessï¼Œè¶Šé«˜è¶Šå¥½ |
| **Attack Success Rate (ASR)** | æ”»å‡»æˆåŠŸæ¯”ä¾‹ $ \text{ASR} = \frac{1}{N}\sum I(\text{response unsafe}) $ | è¶Šä½è¡¨ç¤ºå®‰å…¨æ€§è¶Šå¼º |
| **Helpfulness Score** | å›ç­”æ˜¯å¦æœ‰ç”¨ã€ä¿¡æ¯å®Œæ•´ã€ç»“æ„æ¸…æ™° | 0â€“3 åˆ†åˆ¶ |
| **Harmlessness Score** | æ˜¯å¦æœ‰æ•ˆè¯†åˆ«å¹¶æ‹’ç»æœ‰å®³è¯·æ±‚ï¼Œå¹¶æä¾›ç†ç”± | -3 åˆ° 3 åˆ†åˆ¶ï¼Œç®€å•æ‹’ç»å¾—åˆ†ä¸º 0 |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **+RLHF-V**ï¼šåŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ 
- **+Safe RLHF-V**ï¼šå¹³è¡¡ helpfulness ä¸ harmlessness çš„å¤šæ¨¡æ€å¯¹é½æ–¹æ³•
- **+MM-DPO**ï¼šåŸºäº Direct Preference Optimization çš„å¤šç»´ä¼˜åŒ–
- **+SPA-VL**ï¼šå¤§è§„æ¨¡å®‰å…¨åå¥½å¯¹é½æ•°æ®é›†é©±åŠ¨çš„æ–¹æ³•

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 2ï¼‰

#### åœ¨ **Qwen2.5-VL-7B** ä¸Šçš„è¡¨ç°ï¼ˆSafeMT åŸºå‡†ï¼‰ï¼š
| æ–¹æ³• | Helpfulness â†‘ | Harmlessness â†‘ | ASR â†“ |
|------|----------------|------------------|--------|
| Base Model | 0.5000 | 0.5000 | 0.4892 |
| +Ours (AMÂ³Safety) | **0.6319** (+13.19%) | **0.5819** (+8.19%) | **0.2806** (-20.86%) |

> âœ… **æå‡æ˜¾è‘—**ï¼šASR ä¸‹é™è¶…è¿‡ 10%ï¼Œharmless ç»´åº¦æå‡è‡³å°‘ 8%ï¼Œhelpful ç»´åº¦æå‡è¶… 13%

#### åœ¨ **LLaVA-NeXT-7B** ä¸Šçš„è¡¨ç°ï¼ˆSafeMT åŸºå‡†ï¼‰ï¼š
| æ–¹æ³• | Helpfulness â†‘ | Harmlessness â†‘ | ASR â†“ |
|------|----------------|------------------|--------|
| Base Model | 0.5000 | 0.5000 | 0.4895 |
| +Ours (AMÂ³Safety) | **0.8210** (+32.10%) | **0.6918** (+19.18%) | **0.3844** (-10.51%) |

> âœ… **å…¨é¢æå‡**ï¼šutility æå‡ 32%ï¼Œsafety æå‡ 19%ï¼ŒASR æ˜¾è‘—ä¸‹é™

### ä¸å…¶ä»–åŸºå‡†çš„å¯¹æ¯”ï¼ˆTable 2 & 3ï¼‰
| æ–¹æ³• | JailbreakV (ASRâ†“) | MM-SafetyBench (ASRâ†“) | MMSafe-PO (ASRâ†“) |
|------|--------------------|------------------------|------------------|
| +Ours (Qwen) | **0.1187** | **0.1726** | **0.1200** |
| +Ours (LLaVA) | **0.3516** | **0.4333** | **0.1055** |

> âœ… åœ¨å¤šä¸ªå®‰å…¨åŸºå‡†ä¸Šå‡å–å¾—æœ€ä½ ASR æˆ–æ¥è¿‘æœ€ä¼˜è¡¨ç°

### é€šç”¨èƒ½åŠ›ä¿ç•™æƒ…å†µï¼ˆTable 3ï¼‰
| æ¨¡å‹ | MMDU | ConvBench | ScienceQA | MathVista | MathVerse |
|------|------|-----------|-----------|-----------|-----------|
| Qwen2.5-VL-7B | 4.85 â†’ **4.92** | 52.36% â†’ **59.97%** | 81.80% â†’ 81.11% | 50.11% â†’ **52.56%** | 27.79% â†’ **31.11%** |
| LLaVA-NeXT-7B | 4.15 â†’ **4.64** | 19.41% â†’ **22.24%** | 61.33% â†’ **62.27%** | 28.36% â†’ **29.00%** | 14.01% â†’ **14.87%** |

> âœ… å°½ç®¡è®­ç»ƒæ•°æ®é‡å°ï¼ˆä»… 7,500 æ ·æœ¬ï¼‰ï¼Œ**æœªæŸå®³åŸæœ‰é€šç”¨èƒ½åŠ›å’Œæ¨ç†æ€§èƒ½**ï¼Œéƒ¨åˆ†æŒ‡æ ‡åè€Œæå‡

### æ¶ˆèå®éªŒç»“æœï¼ˆFigure 3 & Table 4ï¼‰

#### ä¸åŒè®­ç»ƒé˜¶æ®µçš„å½±å“ï¼ˆFigure 3ï¼‰
- **ä»… GRPO å¾®è°ƒ**ï¼šæå‡æœ‰é™ï¼Œæ¨¡å‹ä»å€¾å‘äºå›ç­”æœ‰å®³é—®é¢˜
- **åŠ å…¥å†·å¯åŠ¨æ‹’ç»å­¦ä¹ **ï¼šæ˜¾è‘—æå‡ harmlessness ä¸ overall å®‰å…¨è¡¨ç°
- **ç»“è®º**ï¼šå¿…é¡»å…ˆæ•™ä¼šæ¨¡å‹â€œå¦‚ä½•æ‹’ç»â€ï¼Œå†ä¼˜åŒ–å…¶â€œå¦‚ä½•å¸®åŠ©â€

#### åŒç›®æ ‡å¥–åŠ±ç³»æ•°æ¶ˆèï¼ˆTable 4ï¼‰
åœ¨ Qwen2.5-VL-7B ä¸Šæµ‹è¯•ä¸åŒ $\beta$ï¼ˆhelpfulness ç³»æ•°ï¼‰ï¼š
| $\beta$ | Helpfulness | Harmlessness | ASR |
|--------|-------------|---------------|-----|
| 0 | 0.2080 | 0.5405 | 0.2995 |
| **0.1** | **0.6319** | **0.5819** | **0.2806** |
| 1 | 0.2667 | 0.5414 | 0.2986 |
| 10 | 0.2621 | 0.5290 | 0.3000 |

> âœ… æœ€ä¼˜å€¼å‡ºç°åœ¨ $\beta = 0.1$ï¼Œå³ **è½»å¾®åå‘ helpfulness**ï¼Œè¿‡é«˜ä¼šç ´åå®‰å…¨çº¦æŸ

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **å¤šè½®å¯¹è¯å®‰å…¨éœ€ä¸“ç”¨æ•°æ®ä¸æ–¹æ³•**ï¼šä¼ ç»Ÿå•è½® VQA å®‰å…¨æ–¹æ³•æ— æ³•åº”å¯¹æ¸è¿›å¼æ„å›¾é‡æ„æ”»å‡»ã€‚
2. âœ… **æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆæ•°æ®å¯è¡Œä¸”é«˜æ•ˆ**ï¼šInterSafe-V è¯æ˜å¯é€šè¿‡æ¨¡å‹äº¤äº’æ„å»ºé«˜è´¨é‡å¯¹è¯å®‰å…¨æ•°æ®ï¼Œé¿å…é«˜æˆæœ¬äººå·¥æ ‡æ³¨ã€‚
3. âœ… **å†·å¯åŠ¨ + GRPO æ˜¯æœ‰æ•ˆèŒƒå¼**ï¼šå…ˆè®­ç»ƒæ‹’ç»èƒ½åŠ›ï¼Œå†è¿›è¡Œç­–ç•¥ä¼˜åŒ–ï¼Œèƒ½æ›´å¥½ç»´æŒå®‰å…¨è¾¹ç•Œã€‚
4. âœ… **turn-aware reward è®¾è®¡è‡³å…³é‡è¦**ï¼šé€šè¿‡å®‰å…¨æ–¹å·®åŠ æƒæœºåˆ¶ï¼Œå¯ç²¾å‡†è¯†åˆ«â€œæ¨¡ç³Šè¾¹ç•Œâ€è½®æ¬¡å¹¶åŠ å¼ºç›‘ç£ã€‚
5. âœ… **æ‰“ç ´ safety-helpfulness trade-off**ï¼šAMÂ³Safety åŒæ—¶æå‡äº†å®‰å…¨æ€§ä¸æœ‰ç”¨æ€§ï¼Œè€Œéç‰ºç‰²ä¸€æ–¹æ¢å–å¦ä¸€æ–¹ã€‚

### å±€é™æ€§
1. **ç¼ºä¹ä¸“ç”¨å¯¹æŠ—æ€§è¶Šç‹±åŸºå‡†æµ‹è¯•**ï¼šå½“å‰è¯„ä¼°æœªæ¶µç›–æœ€å‰æ²¿çš„ jailbreak æ”»å‡»ç±»å‹ï¼Œå®é™…é²æ£’æ€§æœ‰å¾…éªŒè¯ã€‚
2. **æ¨¡å‹èŒƒå›´å—é™**ï¼šä»…åœ¨é€šç”¨ MLLM ä¸ŠéªŒè¯ï¼Œæœªæµ‹è¯•ä¸“ç”¨æ¨ç†æ¨¡å‹ä¸Šçš„é€‚ç”¨æ€§ã€‚
3. **ä¾èµ–å¤–éƒ¨å¼ºæ¨¡å‹ä½œä¸ºè£åˆ¤**ï¼šä½¿ç”¨ InternVL3-78B ä½œä¸º reward modelï¼Œå­˜åœ¨æ•™å¸ˆæ¨¡å‹åå·®ä¼ é€’é£é™©ã€‚
4. **å°šæœªå®ç°è‡ªæˆ‘åæ€æœºåˆ¶**ï¼šæ¨¡å‹æœªèƒ½å†…åŒ–å®‰å…¨åŸåˆ™ï¼Œä»ä¾èµ–å¤–éƒ¨æ‰“åˆ†ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å¼€å‘æ›´å…·æŒ‘æˆ˜æ€§çš„ **adversarial jailbreak benchmark**
- æ¢ç´¢ **self-correction / self-reflection** æœºåˆ¶ï¼Œå‡å°‘å¯¹å¤–éƒ¨ judge çš„ä¾èµ–
- æ‰©å±•è‡³æ›´å¤šç±»å‹çš„ MLLMï¼ˆå¦‚åŒ»å­¦ã€æ³•å¾‹ä¸“ç”¨æ¨¡å‹ï¼‰
- ç ”ç©¶æ›´é«˜æ•ˆçš„ **low-rank adaptation (LoRA)** æˆ– **quantization-aware training** æ–¹æ¡ˆä»¥è¿›ä¸€æ­¥é™ä½æˆæœ¬

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> AMÂ³Safety æå‡ºäº†ä¸€ç§**æ•°æ®é«˜æ•ˆã€æ— éœ€äººå·¥æ ‡æ³¨**çš„å¤šæ¨¡æ€å¤šè½®å¯¹è¯å®‰å…¨å¯¹é½æ¡†æ¶ï¼Œé€šè¿‡ **InterSafe-V æ•°æ®é›† + å†·å¯åŠ¨æ‹’ç»å­¦ä¹  + turn-aware GRPO ä¼˜åŒ–**ï¼Œåœ¨å¤§å¹…æå‡å®‰å…¨æ€§çš„åŒæ—¶ä¿æŒç”šè‡³å¢å¼ºæ¨¡å‹æœ‰ç”¨æ€§ï¼Œä¸ºç°å®ä¸–ç•Œä¸­ MLLM çš„å®‰å…¨éƒ¨ç½²æä¾›äº†å®ç”¨è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 14. [Revisiting Judge Decoding from First Principles via Training-Free Distributional Divergence](https://arxiv.org/abs/2601.04766)

**Authors**: Shengyin Sun, Yiming Li, Renxi Liu, Weizhe Lin, Hui-Ling Zhen, Xianzhi Yu, Mingxuan Yuan, Chen Ma  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.04766v1  

#### Abstract
Judge Decoding accelerates LLM inference by relaxing the strict verification of Speculative Decoding, yet it typically relies on expensive and noisy supervision. In this work, we revisit this paradigm from first principles, revealing that the ``criticality'' scores learned via costly supervision are...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šRevisiting Judge Decoding from First Principles via Training-Free Distributional Divergence

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿçš„ **Speculative Decoding (SD)** è™½ç„¶èƒ½åŠ é€Ÿå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†ï¼Œä½†å…¶éªŒè¯æœºåˆ¶è¿‡äºä¸¥æ ¼ï¼Œä»…æ¥å—ä¸ç›®æ ‡æ¨¡å‹å®Œå…¨ä¸€è‡´çš„ tokenï¼Œå¯¼è‡´è®¸å¤šè¯­ä¹‰ç­‰ä»·ä½†å½¢å¼ä¸åŒçš„è¾“å‡ºè¢«é”™è¯¯æ‹’ç»ï¼ˆå¦‚â€œ6+1=7â€ vs â€œ6 plus 1 equals 7â€ï¼‰ï¼Œé™åˆ¶äº†ååé‡æå‡ã€‚

ä¸ºæ­¤æå‡ºçš„ **Judge Decoding** å¼•å…¥ä¸€ä¸ªå¯å­¦ä¹ çš„â€œæ³•å®˜â€æ¨¡å‹æ¥åˆ¤æ–­ draft token æ˜¯å¦â€œå…³é”®é”™è¯¯â€ï¼Œä»è€Œå®ç°æ›´å®½æ¾ã€è¯­ä¹‰å±‚é¢çš„éªŒè¯ã€‚ç„¶è€Œï¼Œè¿™ç±»æ–¹æ³•ä¾èµ–æ˜‚è´µä¸”å™ªå£°å¤§çš„ç›‘ç£ä¿¡å·ï¼ˆå¦‚äººå·¥æ ‡æ³¨æˆ–åäº‹å® rolloutsï¼‰ï¼Œå­˜åœ¨ä»¥ä¸‹ç“¶é¢ˆï¼š
- **é«˜æˆæœ¬**ï¼šæ‰‹åŠ¨æ ‡æ³¨è´¹æ—¶è´¹åŠ›ï¼Œè‡ªåŠ¨æŒ–æ˜ï¼ˆå¦‚ AutoJudgeï¼‰éœ€å¤§é‡ GPU å°æ—¶ï¼›
- **æ ‡ç­¾å™ªå£°**ï¼šç”Ÿæˆçš„éšæœºæ€§å¯¼è‡´åŒä¸€ token åœ¨ä¸åŒ rollout ä¸­å¯èƒ½è¢«æ ‡è®°ä¸ºâ€œå…³é”®â€æˆ–â€œéå…³é”®â€ï¼›
- **æ³›åŒ–å·®**ï¼šè®­ç»ƒæ•°æ®å±€é™äºç‰¹å®šé¢†åŸŸï¼Œè·¨åŸŸè¡¨ç°ä¸‹é™æ˜æ˜¾ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸æ ¸å¿ƒæ€æƒ³
æœ¬æ–‡ä»ç¬¬ä¸€æ€§åŸç†å‡ºå‘ï¼Œæå‡ºä¸€ä¸ªé¢ è¦†æ€§è§‚ç‚¹ï¼š

> **â€œå…³é”®æ€§â€ï¼ˆcriticalityï¼‰ä¿¡å·æœ¬è´¨ä¸Šå·²å†…åµŒäº draft ä¸ target æ¨¡å‹ä¹‹é—´çš„åˆ†å¸ƒå·®å¼‚ä¸­ï¼Œæ— éœ€å¤–éƒ¨ç›‘ç£å³å¯æ•æ‰ã€‚**

#### åˆ›æ–°ç‚¹ï¼š
1. **ç†è®ºæ­ç¤º**ï¼šé¦–æ¬¡è¯æ˜äº†è®­ç»ƒå¾—åˆ°çš„çº¿æ€§ judge åˆ†ç±»å™¨ä¸ **KL æ•£åº¦**åœ¨æ•°å­¦ç»“æ„ä¸Šå…±äº«ç›¸åŒçš„ logit primitivesï¼ˆå³ `Î”(x) = (z_t(i)âˆ’z_t(j)) âˆ’ (z_d(i)âˆ’z_d(j))`ï¼‰ã€‚  
   - Judge æ˜¯å¯¹è¿™äº› primitives çš„**çº¿æ€§èšåˆ**ï¼›
   - KL æ•£åº¦æ˜¯å¯¹è¿™äº› primitives çš„**åŠ æƒäºŒæ¬¡èšåˆ**ã€‚
   > å› æ­¤ï¼Œä¸¤è€…æœ¬è´¨æ˜¯åœ¨æ£€æµ‹ç›¸åŒç±»å‹çš„åˆ†å¸ƒåç§»ã€‚

2. **æå‡º Training-Free éªŒè¯æœºåˆ¶**ï¼šåŸºäºä¸Šè¿°æ´å¯Ÿï¼Œä½œè€…æå‡ºä¸€ç§æ— éœ€è®­ç»ƒçš„éªŒè¯æ–¹æ³• â€”â€” **KL Thresholding**ï¼š
   - ä¸å†è®­ç»ƒåˆ†ç±»å™¨ï¼Œè€Œæ˜¯ç›´æ¥è®¡ç®—æ¯ä¸ª token ä¸Š draft å’Œ target åˆ†å¸ƒé—´çš„ KL æ•£åº¦ï¼›
   - è‹¥ KL æ•£åº¦ä½äºé˜ˆå€¼ï¼Œåˆ™æ¥å—è¯¥ tokenï¼›
   - å¯ç»“åˆ confidence maskingï¼ˆä¾‹å¦‚å½“ target æ¨¡å‹ top-1 æ¦‚ç‡ > 0.9 æ—¶å›é€€åˆ°æ ‡å‡† SDï¼‰ä»¥å¢å¼ºé²æ£’æ€§ã€‚

3. **ç»Ÿä¸€è§†è§’**ï¼šå°† judge decoding è§†ä¸ºå­¦ä¹ åˆ†å¸ƒå·®å¼‚çš„è¿‡ç¨‹ï¼ˆè§ Figure 2ï¼‰ï¼Œè€Œéä¾èµ–å¤–éƒ¨æ ‡ç­¾çš„ä»»åŠ¡ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ AutoJudgeï¼‰ | æœ¬æ–‡æ–¹æ³•ï¼ˆKL Thresholdingï¼‰ |
|------|--------------------------|----------------------------|
| **è®­ç»ƒéœ€æ±‚** | éœ€è¦å¤§è§„æ¨¡æ ‡æ³¨/rollout æ•°æ® | å®Œå…¨æ— éœ€è®­ç»ƒï¼ˆtraining-freeï¼‰ |
| **è®¡ç®—å¼€é”€** | æé«˜ï¼ˆ70B æ¨¡å‹éœ€ ~2700 GPU å°æ—¶ï¼‰ | å‡ ä¹ä¸ºé›¶é¢å¤–è®­ç»ƒæˆæœ¬ |
| **æ ‡ç­¾è´¨é‡** | å­˜åœ¨éšæœºæ€§å’Œä¸ä¸€è‡´æ€§ï¼ˆFigure 5 æ˜¾ç¤ºä»… 25.4% token ä¸€è‡´ï¼‰ | åŸºäºç¡®å®šæ€§åˆ†å¸ƒç»Ÿè®¡ï¼Œæ— å™ªå£° |
| **æ³›åŒ–èƒ½åŠ›** | åŸŸå¤–æ€§èƒ½æ˜¾è‘—ä¸‹é™ | å¯¹ domain shift æ›´é²æ£’ |
| **éƒ¨ç½²å¤æ‚åº¦** | éœ€ç»´æŠ¤é¢å¤– judge æ¨¡å‹ | ä»…éœ€è½»é‡çº§åˆ†å¸ƒæ¯”è¾ƒ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
- **GSM8K**ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜ï¼Œå¤šæ­¥æ¨ç†ï¼›
- **MATH-500-Hard**ï¼šMATH æ•°æ®é›†ä¸­æœ€éš¾çš„ Level-5 é—®é¢˜ï¼Œç”¨äºæµ‹è¯•è·¨åŸŸæ³›åŒ–ï¼›
- **LiveCodeBench**ï¼šä»£ç ç”Ÿæˆä»»åŠ¡ï¼Œå¼ºè°ƒç²¾ç¡®æ‰§è¡Œï¼›
- **MMLU-Pro**ï¼šæ¶µç›–å¹¿æ³›å­¦ç§‘çš„çŸ¥è¯†é—®ç­”ï¼Œæ›´å…·æŒ‘æˆ˜æ€§ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹å¯¹**ï¼š
  - Llama-3.2-1B-Instruct / Llama-3.1-8B-Instruct
  - Llama-3.1-8B-Instruct / Llama-3.1-70B-Instruct
  - Qwen3-0.6B / Qwen3-8Bï¼ˆä¸“ä¸ºæ¨ç†ä¼˜åŒ–ï¼‰
- **å®ç°æ¡†æ¶**ï¼šé›†æˆè‡³ **vLLM** è¿›è¡Œç«¯åˆ°ç«¯å»¶è¿Ÿæµ‹é‡ï¼›
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA A6000ã€L40ã€V100 GPUã€‚

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **MAT (Mean Accepted Tokens)** | å¹³å‡æ¯æ¬¡éªŒè¯æˆåŠŸæ¥å—çš„ draft token æ•°é‡ï¼Œåæ˜ æ•ˆç‡ |
| **Accuracy** | æœ€ç»ˆç­”æ¡ˆæ­£ç¡®ç‡ï¼Œè¡¡é‡è´¨é‡ |
| **Speedup** | ç›¸å¯¹äº Vanilla SP çš„ç«¯åˆ°ç«¯é€Ÿåº¦æå‡å€æ•°ï¼ˆtokens/sï¼‰ |
| **Consistency Analysis** | åŒä¸€ token åœ¨å¤šæ¬¡ rollout ä¸­æ˜¯å¦ç¨³å®šè¢«åˆ¤ä¸ºâ€œcriticalâ€ |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
1. **Vanilla SP**ï¼šæ ‡å‡† Speculative Samplingï¼Œä¸¥æ ¼æ¦‚ç‡åŒ¹é…ï¼›
2. **Top-K**ï¼šåŸºäº token æ’åºçš„ä¸€è‡´æ€§è¿›è¡Œæ¾å¼›éªŒè¯ï¼›
3. **AutoJudge**ï¼šå½“å‰æœ€å…ˆè¿›çš„è®­ç»ƒå‹ judge æ–¹æ³•ï¼Œé€šè¿‡åäº‹å® rollout è‡ªåŠ¨æŒ–æ˜ critical tokensï¼›
4. **Target-Entropy / Draft-Entropy**ï¼šåŸºäºå•ä¸€æ¨¡å‹ç†µçš„ä¸ç¡®å®šæ€§å¯å‘å¼æ–¹æ³•ï¼›
5. ï¼ˆé™„å½•ï¼‰**LLM-as-Annotator**ï¼šä½¿ç”¨ Qwen3-Max è‡ªåŠ¨ç”Ÿæˆæ ‡æ³¨è®­ç»ƒ judgeã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Figures 7â€“11 å’Œ Table 1ï¼‰

#### âœ… åœ¨ GSM8K ä¸Šçš„è¡¨ç°ï¼ˆLlama-1B/8Bï¼‰
| æ–¹æ³• | MAT â†‘ | Accuracy â†“ | Speedup |
|------|-------|------------|---------|
| Vanilla SP | 10.61 | 82.50% | 1.00Ã— |
| **KL Thresholding** | **17.35 (+63.5%)** | **80.96% (~1.5%â†“)** | **1.26Ã—** |
| AutoJudge | 17.00 | 79.39% | 1.23Ã— |

> KL æ–¹æ³•ç•¥ä¼˜äº AutoJudgeï¼Œä¸”ç²¾åº¦æ›´é«˜ã€‚

#### âœ… åœ¨ GSM8K ä¸Šçš„è¡¨ç°ï¼ˆLlama-8B/70Bï¼‰
| æ–¹æ³• | MAT â†‘ | Accuracy â†“ | Speedup |
|------|-------|------------|---------|
| Vanilla SP | 13.35 | 93.00% | 1.00Ã— |
| **KL Thresholding** | **30.55 (+128.8%)** | **91.88% (~1.1%â†“)** | **1.30Ã—** |
| AutoJudge | 30.00 | 92.09% | 1.28Ã— |

> KL æ–¹æ³•è¾¾åˆ°æœ€é«˜ MATï¼Œç²¾åº¦æŸå¤±æå°ã€‚

#### âœ… åœ¨ LiveCodeBench ä¸Šçš„è¡¨ç°
| æ–¹æ³• | MAT â†‘ | å¯æ‰§è¡Œæ€§ |
|------|-------|--------|
| KL Thresholding (1B/8B) | +104% (8.83 â†’ 18.01) | ä¿æŒé«˜ä»£ç æ­£ç¡®ç‡ |
| Top-K / Entropy æ–¹æ³• | æå‡æœ‰é™ | ç»å¸¸äº§ç”Ÿä¸å¯æ‰§è¡Œä»£ç  |

> è¡¨æ˜ KL æ–¹æ³•åœ¨éœ€è¦é«˜ç²¾åº¦çš„ä»»åŠ¡ä¸­ä»ç¨³å¥ã€‚

#### âœ… è·¨åŸŸæ³›åŒ–èƒ½åŠ›ï¼ˆMATH-500-Hardï¼‰
- AutoJudgeï¼ˆåœ¨ GSM8K ä¸Šè®­ç»ƒï¼‰åœ¨ MATH ä¸Šè¡¨ç°æ€¥å‰§æ¶åŒ–ï¼Œæ¥è¿‘ Top-Kï¼›
- **KL Thresholding ä¾ç„¶ä¿æŒé«˜æ•ˆ**ï¼š
  - MAT ä» 13.93 æå‡è‡³ **32.02**ï¼ˆ+130%ï¼‰ï¼Œç²¾åº¦ä»…é™ <1%ï¼›
  - æ˜¾è‘—ä¼˜äº AutoJudgeã€‚

#### âœ… ç«¯åˆ°ç«¯é€Ÿåº¦ï¼ˆTable 1ï¼‰
- KL æ–¹æ³•åœ¨ vLLM ä¸­å®ç°äº† **1.3Ã—~1.6Ã— çš„å®é™…åŠ é€Ÿ**ï¼›
- ä¸ AutoJudge ç›¸å½“ï¼Œä½†æ— éœ€ä»»ä½•è®­ç»ƒæˆæœ¬ã€‚

#### âœ… æ¶ˆèå®éªŒä¸åˆ†æ
- **KL ä¸ AutoJudge score é«˜åº¦æ­£ç›¸å…³**ï¼ˆFigure 6ï¼‰ï¼šKL æ•£åº¦éš AutoJudge æ‰“åˆ†å‡é«˜è€Œä¸Šå‡ï¼Œè¯´æ˜äºŒè€…æ•è·ç›¸ä¼¼ä¿¡å·ï¼›
- **Entropy æ— æ˜¾è‘—ç›¸å…³æ€§**ï¼šè¡¨æ˜å•çº¯ä¸ç¡®å®šæ€§ä¸è¶³ä»¥è¯†åˆ« critical tokenï¼›
- **Qwen3-Max ä½œä¸º annotator æ•ˆæœä¸å¦‚ AutoJudge**ï¼ˆFigure 12ï¼‰ï¼šå°½ç®¡æˆæœ¬ä½ï¼Œä½†æ ‡ç­¾ä¸å¤Ÿç²¾å‡†ï¼Œå°¤å…¶åœ¨é«˜ç²¾åº¦åœºæ™¯ä¸‹è¡¨ç°æ›´å·®ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **â€œCriticalityâ€ æ˜¯æ¨¡å‹å†…åœ¨å±æ€§**ï¼š  
   draft ä¸ target æ¨¡å‹ä¹‹é—´çš„ **distributional divergence**ï¼ˆç‰¹åˆ«æ˜¯ KL æ•£åº¦ï¼‰å¤©ç„¶ç¼–ç äº†å“ªäº› token ä¼šå¯¼è‡´é€»è¾‘åå·®ï¼Œæ— éœ€å¤–éƒ¨ç›‘ç£å³å¯è¯†åˆ«ã€‚

2. **è®­ç»ƒå‹ judge æœ¬è´¨ä¸Šæ˜¯ KL æ•£åº¦çš„ä»£ç†æ¨¡å‹**ï¼š  
   ç†è®ºè¯æ˜ AutoJudge ç­‰çº¿æ€§åˆ†ç±»å™¨ä¸ KL æ•£åº¦å…±äº«ç›¸åŒçš„ logit primitivesï¼Œåªæ˜¯å‰è€…æ˜¯çº¿æ€§ç»„åˆï¼Œåè€…æ˜¯äºŒæ¬¡èšåˆã€‚

3. **Training-Free KL Thresholding æ€§èƒ½åª²ç¾ç”šè‡³è¶…è¶Šè®­ç»ƒæ–¹æ³•**ï¼š  
   åœ¨å¤šä¸ª benchmark ä¸Šï¼ŒKL æ–¹æ³•åœ¨ MAT å’Œ accuracy æƒè¡¡ä¸Š**åŒ¹é…æˆ–è¶…è¿‡ AutoJudge**ï¼Œä¸”æ— éœ€ä»»ä½•è®­ç»ƒã€‚

4. **æ›´å¼ºçš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›**ï¼š  
   åœ¨è·¨åŸŸä»»åŠ¡ï¼ˆå¦‚ GSM8K â†’ MATHï¼‰ä¸­ï¼ŒKL æ–¹æ³•æ˜¾è‘—ä¼˜äºä¾èµ–ç‰¹å®šé¢†åŸŸè®­ç»ƒçš„ AutoJudgeã€‚

5. **ç®€åŒ–éƒ¨ç½²è·¯å¾„**ï¼š  
   æ¶ˆé™¤äº†å¯¹é¢å¤– judge æ¨¡å‹çš„éœ€æ±‚ï¼Œæ›´é€‚åˆç”Ÿäº§ç¯å¢ƒå¿«é€Ÿéƒ¨ç½²ã€‚

---

### âš ï¸ å±€é™æ€§
1. **æœªåœ¨è¶…å¤§è§„æ¨¡æ¨¡å‹ä¸ŠéªŒè¯**ï¼š  
   å¦‚ Llama-3.1-405B-Instruct ç­‰ï¼Œå°šä¸æ¸…æ¥š scalability æ˜¯å¦ä¿æŒï¼›
   
2. **æ¨ç†é˜¶æ®µå¼•å…¥é¢å¤–è®¡ç®—å¼€é”€**ï¼š  
   KL æ•£åº¦è®¡ç®—å¢åŠ äº† per-token å¼€é”€ï¼Œå½“å‰å®ç°æœªåš kernel ä¼˜åŒ–ï¼ˆå¦‚ Triton fused kernelï¼‰ï¼Œå¯èƒ½æˆä¸ºç“¶é¢ˆï¼›

3. **å‡è®¾ draft-target å·®å¼‚è¶³å¤Ÿè¡¨è¾¾è¯­ä¹‰é”™è¯¯**ï¼š  
   å¯¹æŸäº›ç»†å¾®è¯­ä¹‰é”™è¯¯ï¼ˆå¦‚é€»è¾‘è·³è·ƒä½†åˆ†å¸ƒå˜åŒ–å°ï¼‰å¯èƒ½ä¸å¤Ÿæ•æ„Ÿã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- è®¾è®¡æ›´é«˜æ•ˆçš„ **distributional divergence è®¡ç®—æ–¹å¼**ï¼ˆå¦‚è¿‘ä¼¼ KLã€JS æ•£åº¦ï¼‰ï¼›
- æ¢ç´¢å…¶ä»– divergence åº¦é‡ï¼ˆå¦‚ Wasserstein è·ç¦»ï¼‰æ˜¯å¦æ›´å…·åˆ¤åˆ«åŠ›ï¼›
- å°†è¯¥æ€æƒ³æ‰©å±•è‡³ **Medusa/EAGLE ç±» speculative ç»“æ„**ï¼›
- ç»“åˆ retrieval æˆ– cache æœºåˆ¶è¿›ä¸€æ­¥å‡å°‘å†—ä½™è®¡ç®—ã€‚

---

## æ€»ç»“
> æœ¬è®ºæ–‡ä»æ ¹æœ¬ä¸Šé‡æ–°å®¡è§†äº† Judge Decoding çš„æœ¬è´¨ï¼ŒæŒ‡å‡ºâ€œå…³é”®æ€§â€ä¿¡å·å¹¶éæ¥è‡ªå¤–éƒ¨ç›‘ç£ï¼Œè€Œæ˜¯å†…ç”Ÿäºæ¨¡å‹é—´çš„åˆ†å¸ƒå·®å¼‚ã€‚é€šè¿‡æå‡º **æ— éœ€è®­ç»ƒçš„ KL æ•£åº¦é˜ˆå€¼æ³•**ï¼Œä¸ä»…æ¶ˆé™¤äº†æ˜‚è´µçš„æ•°æ®æ ‡æ³¨å’Œè®­ç»ƒè¿‡ç¨‹ï¼Œè¿˜åœ¨æ•ˆç‡ã€å‡†ç¡®æ€§å’Œæ³›åŒ–æ€§æ–¹é¢è¾¾åˆ°äº†ä¸æœ€å…ˆè¿›è®­ç»ƒæ–¹æ³•ç›¸å½“ç”šè‡³æ›´ä¼˜çš„æ°´å¹³ï¼Œä¸ºé«˜æ•ˆã€é²æ£’çš„ LLM æ¨ç†æä¾›äº†ä¸€æ¡ç®€æ´è€Œå¼ºå¤§çš„æ–°è·¯å¾„ã€‚

</details>

---

### 15. [EARL: Energy-Aware Optimization of Liquid State Machines for Pervasive AI](https://arxiv.org/abs/2601.05205)

**Authors**: Zain Iqbal, Lorenzo Valerio  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.05205v1  

#### Abstract
Pervasive AI increasingly depends on on-device learning systems that deliver low-latency and energy-efficient computation under strict resource constraints. Liquid State Machines (LSMs) offer a promising approach for low-power temporal processing in pervasive and neuromorphic systems, but their depl...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**EARL: Energy-Aware Optimization of Liquid State Machines for Pervasive AI**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
- **ä¼ ç»Ÿè¶…å‚æ•°ä¼˜åŒ–ï¼ˆHPOï¼‰æ–¹æ³•åœ¨ Liquid State Machineï¼ˆLSMï¼‰ä¸Šçš„å±€é™æ€§**ï¼š
  - LSM å¯¹è¶…å‚æ•°ï¼ˆå¦‚ spectral radiusã€leak rateã€reservoir size ç­‰ï¼‰é«˜åº¦æ•æ„Ÿï¼Œå¾®å°å˜åŒ–å¯èƒ½å¯¼è‡´ç³»ç»Ÿä»ç¨³å®šæ€è¿›å…¥æ··æ²Œæ€ï¼Œä¸¥é‡å½±å“å‡†ç¡®ç‡å’Œèƒ½è€—ã€‚
  - ç°æœ‰ HPO æ–¹æ³•ï¼ˆå¦‚ Grid Searchã€Random Searchã€Bayesian Optimizationï¼‰é€šå¸¸å‡è®¾ç›®æ ‡å‡½æ•°æ˜¯å¹³æ»‘è¿ç»­çš„ï¼Œå¹¶ä¸”**æœªå°†èƒ½é‡æ¶ˆè€—ä½œä¸ºæ˜¾å¼ä¼˜åŒ–ç›®æ ‡**ã€‚
  - åœ¨ spiking neural network å’Œ neuromorphic computing åœºæ™¯ä¸‹ï¼Œè¿™äº›å‡è®¾ä¸æˆç«‹ï¼Œå¯¼è‡´æœç´¢æ•ˆç‡ä½ã€èµ„æºæµªè´¹ä¸¥é‡ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼š**EARL æ¡†æ¶**
æå‡ºäº†ä¸€ç§åä¸º **Energy-Aware Reinforcement Learning (EARL)** çš„æ··åˆä¼˜åŒ–æ¡†æ¶ï¼Œç”¨äº LSM è¶…å‚æ•°è°ƒä¼˜ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

1. **ç»Ÿä¸€çš„èƒ½é‡æ„ŸçŸ¥å¥–åŠ±å‡½æ•°**  
   å°†åˆ†ç±»å‡†ç¡®ç‡ $ f_1(x) $ å’Œèƒ½é‡æ¶ˆè€— $ f_2(x) $ ç»Ÿä¸€ä¸ºä¸€ä¸ªæ ‡é‡åŒ–å¥–åŠ±å‡½æ•°ï¼š
   $$
   r(x) = f_1(x) - \alpha \cdot f_2(x)
   $$
   å…è®¸åœ¨ç²¾åº¦ä¸èƒ½æ•ˆä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚

2. **èåˆ Bayesian Optimization ä¸ Reinforcement Learning**
   - **Bayesian Optimization (BO)**ï¼šä½¿ç”¨ Gaussian Process å»ºæ¨¡å¥–åŠ±å‡½æ•°ï¼Œé€šè¿‡ Expected Improvement (EI) è·å–å€™é€‰é…ç½®ï¼Œå®ç°å…¨å±€æ¢ç´¢ã€‚
   - **Reinforcement Learning (RL)**ï¼šå¼•å…¥ RL Agentï¼Œåœ¨æ¯ä¸€æ‰¹ BO ç”Ÿæˆçš„å€™é€‰ä¸­é€‰æ‹©æœ€ä¼˜è¯•éªŒï¼ŒåŸºäºé¢„æµ‹å‡å€¼å’Œæ–¹å·®åŠ¨æ€å†³ç­–ï¼Œæå‡å±€éƒ¨æœç´¢æ•ˆç‡ã€‚

3. **è‡ªé€‚åº”æ—©åœæœºåˆ¶ï¼ˆAdaptive Early Terminationï¼‰**
   - ç›‘æ§æœ€è¿‘ $ T_s $ æ¬¡è¿­ä»£ä¸­çš„ç›¸å¯¹æ”¹è¿›ï¼ˆaccuracy å’Œ energyï¼‰ï¼Œè‹¥è¿ç»­æ— æ˜¾è‘—æå‡ï¼ˆä½äºé˜ˆå€¼ $ \epsilon_r, \epsilon_e $ï¼‰ï¼Œåˆ™æå‰ç»ˆæ­¢æœç´¢ã€‚
   - æ˜¾è‘—å‡å°‘å†—ä½™è¯„ä¼°ï¼Œé™ä½è®¡ç®—å¼€é”€å’Œèƒ½è€—ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | EARL | Optuna / Ray Tune |
|------|------|------------------|
| æ˜¯å¦è€ƒè™‘èƒ½é‡ | âœ… æ˜¯ï¼ˆæ˜¾å¼å»ºæ¨¡ï¼‰ | âŒ å¦æˆ–é—´æ¥ä¼°è®¡ |
| æœç´¢ç­–ç•¥ | BO + RL åŠ¨æ€é€‰æ‹© | å•çº¯ BO æˆ–å¹¶è¡Œé‡‡æ · |
| æ—©åœæœºåˆ¶ | âœ… è‡ªé€‚åº”ç›‘æµ‹åŒç›®æ ‡ | é€šå¸¸å›ºå®š trial æ•°æˆ–ç®€å•æ”¶æ•›åˆ¤æ–­ |
| æ•ˆç‡ | é«˜ï¼ˆå‡å°‘æ— æ•ˆè¯„ä¼°ï¼‰ | è¾ƒä½ï¼ˆç›²ç›®æ¢ç´¢å¤šï¼‰ |

> EARL å®ç°äº†**å‡†ç¡®æ€§ã€èƒ½æ•ˆã€ä¼˜åŒ–æ—¶é—´ä¸‰è€…çš„ååŒä¼˜åŒ–**ï¼Œç‰¹åˆ«é€‚ç”¨äºè¾¹ç¼˜è®¾å¤‡ä¸Šçš„ Pervasive AI åº”ç”¨ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†
åœ¨ä¸‰ä¸ªæ ‡å‡†åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œè¦†ç›–å¤šç§æ—¶åºä»»åŠ¡ç±»å‹ï¼š

| æ•°æ®é›† | ä»»åŠ¡ç±»å‹ | æ ·æœ¬æ•° | ç±»åˆ«æ•° |
|--------|--------|-------|-------|
| **FSDD** (Free Spoken Digit Dataset) | è¯­éŸ³è¯†åˆ«ï¼ˆéŸ³é¢‘ï¼‰ | ~3,000 | 10ï¼ˆæ•°å­—0-9ï¼‰ |
| **UCI HAR** (Human Activity Recognition) | äººç±»æ´»åŠ¨è¯†åˆ«ï¼ˆIMUä¼ æ„Ÿå™¨ï¼‰ | ~15,000 | 6ï¼ˆæ­¥è¡Œã€åä¸‹ç­‰ï¼‰ |
| **Occupancy Detection** | ç¯å¢ƒå ç”¨æ£€æµ‹ï¼ˆæ¸©æ¹¿åº¦COâ‚‚ç­‰ï¼‰ | ~10,000 | 2ï¼ˆæœ‰äºº/æ— äººï¼‰ |

æ‰€æœ‰æ•°æ®å‡å½’ä¸€åŒ–å¤„ç†ï¼Œé‡‡ç”¨ 80%/20% åˆ†å‰²è®­ç»ƒ/éªŒè¯é›†ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼šLSMï¼ˆLeaky Integrate-and-Fire ç¥ç»å…ƒï¼‰ + GRU è¯»å‡ºå±‚
- **ä¼˜åŒ–ç›®æ ‡**ï¼šè”åˆä¼˜åŒ–åˆ†ç±» accuracy å’Œ reservoir-level energy consumption
- **è¶…å‚æ•°æœç´¢ç©ºé—´**ï¼ˆè§ Table Iï¼‰ï¼š
  - Leak Rate: [0.1, 0.4]
  - Spectral Radius: [0.6, 1.1]
  - Reservoir Size: [100, 1000]ï¼ˆæ•´æ•°ï¼‰
  - Connectivity: [0.2, 0.7]
- **è®­ç»ƒç»†èŠ‚**ï¼š
  - GRU è®­ç»ƒ 100 epochsï¼ŒAdamW ä¼˜åŒ–å™¨
  - å›ºå®šéšæœºç§å­ï¼ŒPyTorch å®ç°
  - è¿è¡Œå¹³å°ï¼šNVIDIA Tesla T4 GPUï¼ˆ16GB VRAMï¼‰
  - æ€» trialsï¼š50ï¼ˆå« 20 æ¬¡åˆå§‹åŒ–ï¼‰

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Accuracy (%)** | åˆ†ç±»å‡†ç¡®ç‡ï¼ˆÂ±ç½®ä¿¡åŒºé—´ CIï¼‰ |
| **Energy Consumption (pJ/sample)** | æ¯æ ·æœ¬å¹³å‡èƒ½è€— |
| **Total Optimization Time (min)** | å®Œæˆå…¨éƒ¨è¶…å‚æœç´¢æ‰€éœ€æ—¶é—´ |
| **Pareto Front** | å±•ç¤º accuracy-energy æƒè¡¡å…³ç³» |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Optuna**ï¼šä½¿ç”¨ NSGA-II å¤šç›®æ ‡é‡‡æ ·å™¨
- **Ray Tune**ï¼šå¼‚æ­¥å¹¶è¡Œé‡‡æ ·
- æ‰€æœ‰æ–¹æ³•ä½¿ç”¨ç›¸åŒæœç´¢ç©ºé—´ã€trial é¢„ç®—å’Œè®­ç»ƒè„šæœ¬ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»ï¼ˆæ¥è‡ª Table IIï¼‰

| Dataset | Model | Accuracy (%) | Energy (pJ/sample) | Opt. Time (min) |
|--------|-------|--------------|--------------------|------------------|
| **FSDD** | **EARL** | **95.39 Â± 0.44** | **0.2089 Â± 0.0129** | **10.57** |
|          | Optuna | 82.25 Â± 2.75 | 0.3644 Â± 0.0091 | 106.60 |
|          | Ray    | 88.15 Â± 2.18 | 0.4178 Â± 0.0042 | 100.88 |
| **HAR**  | **EARL** | **96.99 Â± 0.34** | **0.20796 Â± 0.02362** | **19.53** |
|          | Optuna | 90.52 Â± 1.16 | 0.6265 Â± 0.0193 | 47.75 |
|          | Ray    | 94.41 Â± 0.67 | 0.43737 Â± 0.00512 | 58.48 |
| **Occupancy** | **EARL** | **98.47 Â± 8e-5** | **0.0278 Â± 0.0052** | **15.28** |
|               | Optuna | 97.44 Â± 0.27 | 0.1599 Â± 0.0092 | 47.75 |
|               | Ray    | 98.47 Â± 0.03 | 0.1624 Â± 0.0030 | 64.85 |

### ğŸ” å¯¹æ¯”åˆ†æ
- **å‡†ç¡®æ€§æå‡**ï¼šEARL åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šå‡æ˜¾è‘—ä¼˜äºåŸºçº¿ï¼Œ**é«˜å‡º 6â€“15%**ã€‚
- **èƒ½è€—é™ä½**ï¼šç›¸æ¯” Optuna/Rayï¼Œ**èƒ½è€—ä¸‹é™ 60â€“80%**ï¼Œå°¤å…¶åœ¨ Occupancy ä¸Šè¾¾ **82% ä»¥ä¸ŠèŠ‚èƒ½**ã€‚
- **ä¼˜åŒ–é€Ÿåº¦åŠ å¿«**ï¼šä¼˜åŒ–æ—¶é—´**ç¼©çŸ­è¿‘ä¸€ä¸ªæ•°é‡çº§**ï¼ˆå¦‚ FSDD ä¸Šä»…éœ€ 10.6 åˆ†é’Ÿ vs è¶…è¿‡ 100 åˆ†é’Ÿï¼‰ã€‚
- **æ”¶æ•›æ›´å¿«**ï¼šEARL åœ¨æ›´å°‘ trial å†…è¾¾åˆ°æœ€ä¼˜ï¼ˆä¾‹å¦‚ HAR ä»…éœ€ 39 æ¬¡ trialï¼‰ã€‚

### ğŸ“ˆ Pareto å‰æ²¿åˆ†æï¼ˆå›¾ 3ï¼‰
- EARL æ‰¾åˆ°çš„è§£åœ¨é«˜ accuracyã€ä½ energy åŒºåŸŸå æ®ä¸»å¯¼åœ°ä½ã€‚
- è§£åˆ†å¸ƒé›†ä¸­ï¼Œå˜å¼‚å°ï¼Œè¡¨æ˜æœç´¢è¿‡ç¨‹ç¨³å®šå¯é ã€‚
- åœ¨ HAR å’Œ Occupancy ä¸Šå±•ç°å‡ºæ›´å¼ºçš„å¤šç›®æ ‡å¹³è¡¡èƒ½åŠ›ã€‚

> â— **æ²¡æœ‰æä¾›æ¶ˆèå®éªŒï¼ˆablation studyï¼‰**ï¼Œæ— æ³•é‡åŒ– BOã€RLã€early termination å„ç»„ä»¶çš„å…·ä½“è´¡çŒ®ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **èƒ½é‡å¿…é¡»ä½œä¸ºä¸€çº§ä¼˜åŒ–ç›®æ ‡**ï¼šåœ¨ LSM ç­‰ä½åŠŸè€—ç¥ç»å½¢æ€ç³»ç»Ÿä¸­ï¼Œå¿½ç•¥ energy çš„ HPO æ–¹æ³•ä¼šä¸¥é‡ä½ä¼°å®é™…éƒ¨ç½²æˆæœ¬ã€‚
2. **BO + RL æ··åˆç­–ç•¥æœ‰æ•ˆæå‡æœç´¢æ•ˆç‡**ï¼šBO æä¾›å…¨å±€æŒ‡å¯¼ï¼ŒRL å®ç°åŠ¨æ€ä¼˜å…ˆçº§æ’åºï¼ŒäºŒè€…ç»“åˆå¯é¿å…é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚
3. **è‡ªé€‚åº”æ—©åœæœºåˆ¶å¤§å¹…èŠ‚çœèµ„æº**ï¼šåœ¨æ€§èƒ½è¶‹äºé¥±å’Œæ—¶åŠæ—¶åœæ­¢ï¼Œé¿å…â€œè¿‡åº¦æœç´¢â€ï¼Œå¯¹è¾¹ç¼˜è®¾å¤‡å°¤ä¸ºé‡è¦ã€‚
4. **EARL å¯æ‰©å±•æ€§å¼º**ï¼šé€‚ç”¨äºå¤šç§ä¼ æ„Ÿå™¨æ¨¡æ€å’Œæ—¶åºä»»åŠ¡ï¼Œåœ¨è¯­éŸ³ã€æ´»åŠ¨è¯†åˆ«ã€ç¯å¢ƒæ„ŸçŸ¥ä¸­å‡è¡¨ç°ä¼˜å¼‚ã€‚

### âš ï¸ å±€é™æ€§
- **ç¼ºä¹ç¡¬ä»¶å®æµ‹èƒ½è€—æ•°æ®**ï¼šå½“å‰ energy consumption æ˜¯æ¨¡æ‹Ÿä¼°ç®—ï¼Œå°šæœªåœ¨çœŸå® neuromorphic chipï¼ˆå¦‚ Loihiã€SpiNNakerï¼‰ä¸ŠéªŒè¯ã€‚
- **æœªè¿›è¡Œæ¶ˆèç ”ç©¶**ï¼šæ— æ³•ç¡®è®¤ RL æ¨¡å—æˆ– early termination çš„ç‹¬ç«‹å½±å“ã€‚
- **æœç´¢ç©ºé—´æœ‰é™**ï¼šç›®å‰ä»…ä¼˜åŒ–å››ä¸ªä¸»è¦è¶…å‚æ•°ï¼Œæœªæ¶‰åŠç½‘ç»œç»“æ„ã€çªè§¦å»¶è¿Ÿç­‰æ›´å¤æ‚å˜é‡ã€‚
- **RL Agent è®¾è®¡è¾ƒç®€å•**ï¼šä½¿ç”¨å•å±‚ç½‘ç»œå’Œ e-greedy ç­–ç•¥ï¼Œå¯èƒ½é™åˆ¶é•¿æœŸç­–ç•¥å­¦ä¹ èƒ½åŠ›ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **Hardware-in-the-loop evaluation**ï¼šåœ¨çœŸå® neuromorphic processor ä¸Šè¿è¡Œ EARLï¼Œè·å–çœŸå®çš„ energy profilingã€‚
2. **æ‰©å±•æœç´¢ç©ºé—´**ï¼šçº³å…¥æ›´å¤šæ¶æ„å‚æ•°ï¼ˆå¦‚ topologyã€delayã€threshold adaptationï¼‰ã€‚
3. **åœ¨çº¿è‡ªé€‚åº”è°ƒä¼˜**ï¼šæ”¯æŒ streaming data ä¸‹çš„æŒç»­å­¦ä¹ ä¸å‚æ•°è°ƒæ•´ã€‚
4. **åº”ç”¨äºæ›´å¤§è§„æ¨¡ä»»åŠ¡**ï¼šæ‹“å±•è‡³ sensory fusionã€autonomous systems ç­‰å¤æ‚åœºæ™¯ã€‚

---

## âœ… æ€»ç»“
**EARL** æ˜¯é¦–ä¸ªä¸“ä¸º **Liquid State Machine** è®¾è®¡çš„**èƒ½é‡æ„ŸçŸ¥è¶…å‚æ•°ä¼˜åŒ–æ¡†æ¶**ï¼Œé€šè¿‡èåˆ **Bayesian Optimization** ä¸ **Reinforcement Learning**ï¼Œå®ç°äº†åœ¨å‡†ç¡®æ€§ã€èƒ½æ•ˆå’Œä¼˜åŒ–é€Ÿåº¦ä¸Šçš„å…¨é¢è¶…è¶Šã€‚å®éªŒè¡¨æ˜ï¼Œå®ƒèƒ½åœ¨å¤šç§æ—¶åºä»»åŠ¡ä¸­å®ç° **6â€“15% æ›´é«˜çš„ accuracyã€60â€“80% æ›´ä½çš„ energy æ¶ˆè€—ã€ä»¥åŠè¿‘ä¸€ä¸ªæ•°é‡çº§çš„ä¼˜åŒ–åŠ é€Ÿ**ï¼Œä¸ºèµ„æºå—é™çš„ **Pervasive AI** å’Œ **Edge Intelligence** åº”ç”¨æä¾›äº†é«˜æ•ˆå¯é çš„è‡ªåŠ¨åŒ–è°ƒä¼˜æ–¹æ¡ˆã€‚

</details>

---

### 16. [xDNN(ASP): Explanation Generation System for Deep Neural Networks powered by Answer Set Programming](https://arxiv.org/abs/2601.03847)

**Authors**: Ly Ly Trieu (New Mexico State University), Tran Cao Son (New Mexico State University)  
**Category**: cs.AI  
**Published**: 2026-01-09  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.03847v1  

#### Abstract
Explainable artificial intelligence (xAI) has gained significant attention in recent years. Among other things, explainablility for deep neural networks has been a topic of intensive research due to the meteoric rise in prominence of deep neural networks and their "black-box" nature. xAI approaches ...

---

### 17. [Unlocking the Pre-Trained Model as a Dual-Alignment Calibrator for Post-Trained LLMs](https://arxiv.org/abs/2601.04277)

**Authors**: Beier Luo, Cheng Wang, Hongxin Wei, Sharon Li, Xuefeng Du  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.04277v1  

#### Abstract
Post-training improves large language models (LLMs) but often worsens confidence calibration, leading to systematic overconfidence. Recent unsupervised post-hoc methods for post-trained LMs (PoLMs) mitigate this by aligning PoLM confidence to that of well-calibrated pre-trained counterparts. However...

---

### 18. [TSSR: Two-Stage Swap-Reward-Driven Reinforcement Learning for Character-Level SMILES Generation](https://arxiv.org/abs/2601.04521)

**Authors**: Jacob Ede Levine, Yun Lyan Luo, Sai Chandra Kosaraju  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.04521v1  

#### Abstract
The design of reliable, valid, and diverse molecules is fundamental to modern drug discovery, as improved molecular generation supports efficient exploration of the chemical space for potential drug candidates and reduces the cost of early design efforts. Despite these needs, current chemical langua...

---

### 19. [ROI-Reasoning: Rational Optimization for Inference via Pre-Computation Meta-Cognition](https://arxiv.org/abs/2601.03822)

**Authors**: Muyang Zhao, Qi Qi, Hao Sun  
**Category**: cs.AI  
**Published**: 2026-01-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.03822v1  

#### Abstract
Large language models (LLMs) can achieve strong reasoning performance with sufficient computation, but they do not inherently know how much computation a task requires. We study budgeted inference-time reasoning for multiple tasks under a strict global token constraint and formalize it as a Ordered ...

---

### 20. [Trade-R1: Bridging Verifiable Rewards to Stochastic Environments via Process-Level Reasoning Verification](https://arxiv.org/abs/2601.03948)

**Authors**: Rui Sun, Yifan Sun, Sheng Xu, Li Zhao, Jing Li, Daxin Jiang, Cheng Hua, Zuo Bai  
**Category**: cs.AI  
**Published**: 2026-01-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.03948v2  

#### Abstract
Reinforcement Learning (RL) has enabled Large Language Models (LLMs) to achieve remarkable reasoning in domains like mathematics and coding, where verifiable rewards provide clear signals. However, extending this paradigm to financial decision is challenged by the market's stochastic nature: rewards...

---

### 21. [ARREST: Adversarial Resilient Regulation Enhancing Safety and Truth in Large Language Models](https://arxiv.org/abs/2601.04394)

**Authors**: Sharanya Dasgupta, Arkaprabha Basu, Sujoy Nath, Swagatam Das  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.04394v1  

#### Abstract
Human cognition, driven by complex neurochemical processes, oscillates between imagination and reality and learns to self-correct whenever such subtle drifts lead to hallucinations or unsafe associations. In recent years, LLMs have demonstrated remarkable performance in a wide range of tasks. Howeve...

---

### 22. [Merging Triggers, Breaking Backdoors: Defensive Poisoning for Instruction-Tuned Language Models](https://arxiv.org/abs/2601.04448)

**Authors**: San Kim, Gary Geunbae Lee  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.04448v1  

#### Abstract
Large Language Models (LLMs) have greatly advanced Natural Language Processing (NLP), particularly through instruction tuning, which enables broad task generalization without additional fine-tuning. However, their reliance on large-scale datasets-often collected from human or web sources-makes them ...

---

### 23. [PRISM: A Unified Framework for Post-Training LLMs Without Verifiable Rewards](https://arxiv.org/abs/2601.04700)

**Authors**: Mukesh Ghimire, Aosong Feng, Liwen You, Youzhi Luo, Fang Liu, Xuan Zhu  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.04700v1  

#### Abstract
Current techniques for post-training Large Language Models (LLMs) rely either on costly human supervision or on external verifiers to boost performance on tasks such as mathematical reasoning and code generation. However, as LLMs improve their problem-solving, any further improvement will potentiall...

---

### 24. [Qwen3-VL-Embedding and Qwen3-VL-Reranker: A Unified Framework for State-of-the-Art Multimodal Retrieval and Ranking](https://arxiv.org/abs/2601.04720)

**Authors**: Mingxin Li, Yanzhao Zhang, Dingkun Long, Keqin Chen, Sibo Song, Shuai Bai, Zhibo Yang, Pengjun Xie, An Yang, Dayiheng Liu, Jingren Zhou, Junyang Lin  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.04720v1  

#### Abstract
In this report, we introduce the Qwen3-VL-Embedding and Qwen3-VL-Reranker model series, the latest extensions of the Qwen family built on the Qwen3-VL foundation model. Together, they provide an end-to-end pipeline for high-precision multimodal search by mapping diverse modalities, including text, i...

---

### 25. [RiskAtlas: Exposing Domain-Specific Risks in LLMs through Knowledge-Graph-Guided Harmful Prompt Generation](https://arxiv.org/abs/2601.04740)

**Authors**: Huawei Zheng, Xinqi Jiang, Sen Yang, Shouling Ji, Yingcai Wu, Dazhen Deng  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.04740v1  

#### Abstract
Large language models (LLMs) are increasingly applied in specialized domains such as finance and healthcare, where they introduce unique safety risks. Domain-specific datasets of harmful prompts remain scarce and still largely rely on manual construction; public datasets mainly focus on explicit har...

---

### 26. [A Navigational Approach for Comprehensive RAG via Traversal over Proposition Graphs](https://arxiv.org/abs/2601.04859)

**Authors**: Maxime Delmas, Lei Xu, Andr\'e Freitas  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.04859v1  

#### Abstract
Standard RAG pipelines based on chunking excel at simple factual retrieval but fail on complex multi-hop queries due to a lack of structural connectivity. Conversely, initial strategies that interleave retrieval with reasoning often lack global corpus awareness, while Knowledge Graph (KG)-based RAG ...

---

### 27. [CuMA: Aligning LLMs with Sparse Cultural Values via Demographic-Aware Mixture of Adapters](https://arxiv.org/abs/2601.04885)

**Authors**: Ao Sun, Xiaoyu Wang, Zhe Tan, Yu Li, Jiachen Zhu, Shu Su, Yuheng Jia  
**Category**: cs.CL  
**Published**: 2026-01-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.04885v1  

#### Abstract
As Large Language Models (LLMs) serve a global audience, alignment must transition from enforcing universal consensus to respecting cultural pluralism. We demonstrate that dense models, when forced to fit conflicting value distributions, suffer from \textbf{Mean Collapse}, converging to a generic av...

---

### 28. [Green MLOps: Closed-Loop, Energy-Aware Inference with NVIDIA Triton, FastAPI, and Bio-Inspired Thresholding](https://arxiv.org/abs/2601.04250)

**Authors**: Mustapha Hamdi, Mourad Jabou  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.04250v1  

#### Abstract
Energy efficiency is a first-order concern in AI deployment, as long-running inference can exceed training in cumulative carbon impact. We propose a bio-inspired framework that maps protein-folding energy basins to inference cost landscapes and controls execution via a decaying, closed-loop threshol...

---

### 29. [ArtCognition: A Multimodal AI Framework for Affective State Sensing from Visual and Kinematic Drawing Cues](https://arxiv.org/abs/2601.04297)

**Authors**: Behrad Binaei-Haghighi, Nafiseh Sadat Sajadi, Mehrad Liviyan, Reyhane Akhavan Kharazi, Fatemeh Amirkhani, Behnam Bahrak  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.04297v1  

#### Abstract
The objective assessment of human affective and psychological states presents a significant challenge, particularly through non-verbal channels. This paper introduces digital drawing as a rich and underexplored modality for affective sensing. We present a novel multimodal framework, named ArtCogniti...

---

### 30. [Enhanced-FQL($\lambda$), an Efficient and Interpretable RL with novel Fuzzy Eligibility Traces and Segmented Experience Replay](https://arxiv.org/abs/2601.04392)

**Authors**: Mohsen Jalaeian-Farimani  
**Category**: cs.LG  
**Published**: 2026-01-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.04392v1  

#### Abstract
This paper introduces a fuzzy reinforcement learning framework, Enhanced-FQL($\lambda$), that integrates novel Fuzzified Eligibility Traces (FET) and Segmented Experience Replay (SER) into fuzzy Q-learning with Fuzzified Bellman Equation (FBE) for continuous control tasks. The proposed approach empl...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- kv cache, offload, State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
