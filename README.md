# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-24 05:57:56 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge](https://arxiv.org/abs/2512.20276)

**Authors**: Yuntao Dai, Hang Gu, Teng Wang, Qianyu Cheng, Yifei Zheng, Zhiyong Qiu, Lei Gong, Wenqi Lou, Xuehai Zhou  
**Category**: cs.AI  
**Published**: 2025-12-24  
**Score**: 13.5  
**Type**: new  
**ArXiv ID**: 2512.20276v1  

#### Abstract
Vision-Language-Action (VLA) models have emerged as a unified paradigm for robotic perception and control, enabling emergent generalization and long-horizon task execution. However, their deployment in dynamic, real-world environments is severely hin dered by high inference latency. While smooth rob...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡ã€ŠActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edgeã€‹æ ¸å¿ƒæ€»ç»“**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
Vision-Language-Action (VLA) æ¨¡å‹åœ¨æœºå™¨äººæ„ŸçŸ¥ä¸æ§åˆ¶ä¸­å±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œé•¿è§†é‡ä»»åŠ¡æ‰§è¡Œæ½œåŠ›ï¼Œä½†å…¶åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„éƒ¨ç½²é¢ä¸´ä¸¥é‡çš„**é«˜æ¨ç†å»¶è¿Ÿç“¶é¢ˆ**ã€‚ç”±äºä¾èµ–è‡ªå›å½’è§£ç ï¼ˆautoregressive decodingï¼‰ï¼Œå½“å‰ VLA æ¨¡å‹åœ¨è¾¹ç¼˜ç¡¬ä»¶ä¸Šé€šå¸¸åªèƒ½è¾¾åˆ° 3â€“5 FPSï¼Œè¿œä½äºåŠ¨æ€äº¤äº’æ‰€éœ€çš„ 20â€“30 Hz æ§åˆ¶é¢‘ç‡ï¼Œå¯¼è‡´æœºå™¨äººååº”è¿Ÿç¼“ã€æ— æ³•å®æ—¶å“åº”ç¯å¢ƒå˜åŒ–ã€‚

æ­¤å¤–ï¼Œç°æœ‰ä¼˜åŒ–æ–¹æ³•å­˜åœ¨ä»¥ä¸‹å±€é™ï¼š
- **LLM æ¨ç†ç³»ç»Ÿ**ï¼ˆå¦‚ Continuous Batchingï¼‰é¢å‘å¤šç”¨æˆ·æœåŠ¡å™¨åœºæ™¯ï¼Œä¸é€‚ç”¨äºå•ç”¨æˆ·ä½å»¶è¿Ÿçš„æœºå™¨äººæ§åˆ¶ï¼›
- **è¾¹ç¼˜ç«¯ä¼˜åŒ–æŠ€æœ¯**ï¼ˆå¦‚é‡åŒ–ã€è’¸é¦ï¼‰è™½å‡å°æ¨¡å‹è§„æ¨¡ï¼Œä½†æœªæ”¹å˜è§£ç é˜¶æ®µå†…å­˜å—é™çš„æœ¬è´¨ï¼›
- **ç®—æ³•çº§åŠ é€Ÿæ–¹æ³•**ï¼ˆå¦‚å¹¶è¡Œè§£ç ã€æ‰©æ•£æ¨¡å‹ï¼‰å¸¸éœ€é‡æ–°è®­ç»ƒï¼Œå¯èƒ½å½±å“ç²¾åº¦æˆ–å¼•å…¥åŠ¨ä½œä¸è¿ç»­ç­‰é—®é¢˜ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯**
æœ¬æ–‡æå‡ºäº† **ActionFlow** â€”â€” ä¸€ç§ä¸“ä¸ºèµ„æºå—é™è¾¹ç¼˜å¹³å°è®¾è®¡çš„**ç³»ç»Ÿçº§æ¨ç†æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°† VLA çš„æ¨ç†è¿‡ç¨‹é‡æ„ä¸ºä¸€ä¸ªç”±â€œå¾®è¯·æ±‚â€ç»„æˆçš„å®æµæ°´çº¿ï¼Œå¹¶é€šè¿‡è·¨è¯·æ±‚è°ƒåº¦æå‡ç¡¬ä»¶åˆ©ç”¨ç‡ã€‚

#### **ä¸»è¦åˆ›æ–°ç‚¹ï¼š**
1. **Cross-Request Pipelining ç­–ç•¥**  
   å°†æ¯ä¸ª VLA è¯·æ±‚å†…éƒ¨çš„ `Prefill` å’Œå¤šä¸ª `Decode` é˜¶æ®µè§†ä¸ºä¸€ä¸ª K-stage å¾®è¯·æ±‚æµæ°´çº¿ã€‚ActionFlow åœ¨æ—¶é—´ç»´åº¦ä¸Šé‡å  K ä¸ªè¿ç»­è¯·æ±‚çš„æ“ä½œï¼šå°†å½“å‰å¸§çš„ `Prefill` ä¸å‰å‡ å¸§çš„ `Decode` æ‰¹é‡åˆå¹¶å¤„ç†ï¼Œä»è€Œæ¶ˆé™¤æµæ°´çº¿æ°”æ³¡ï¼Œæœ€å¤§åŒ– GPU åˆ©ç”¨ç‡ã€‚

2. **Cross-Request State Packed Forward ç®—å­**  
   è®¾è®¡äº†ä¸€ä¸ªèåˆç®—å­ï¼Œå°†å¤šä¸ªç‹¬ç«‹çš„å‘é‡çº§ Decode GEMV æ“ä½œæ‰“åŒ…æˆä¸€ä¸ªçŸ©é˜µçº§ GEMM æ“ä½œï¼Œæ˜¾è‘—æé«˜ç®—æœ¯å¼ºåº¦ï¼ˆarithmetic intensityï¼‰ï¼Œä½¿è®¡ç®—ä» memory-bound è½¬å‘ compute-boundã€‚

3. **Unified KV Ring Buffer**  
   å¼•å…¥ç»Ÿä¸€çš„ç¯å½¢ KV ç¼“å­˜ç»“æ„ï¼Œç‰©ç†ä¸Šè¿ç»­å­˜å‚¨æ‰€æœ‰æ´»è·ƒè¯·æ±‚çš„å†å² KV çŠ¶æ€ï¼Œé¿å…ä¼ ç»Ÿæ–¹æ³•ä¸­é¢‘ç¹çš„æ•°æ®æ‹·è´å’Œ CPU-GPU åŒæ­¥å¼€é”€ï¼Œæ”¯æŒé«˜æ•ˆçš„ Variable-Length Attentionï¼ˆVarlen-Attentionï¼‰æ“ä½œã€‚

4. **çº¯ç³»ç»Ÿçº§ä¼˜åŒ–ï¼Œæ— éœ€é‡è®­ç»ƒ**  
   ActionFlow å®Œå…¨åœ¨ç³»ç»Ÿå±‚é¢å®ç°åŠ é€Ÿï¼Œå¯¹åŸå§‹æ¨¡å‹å‚æ•°ã€æ¶æ„å’Œè®­ç»ƒæµç¨‹æ— ä»»ä½•ä¿®æ”¹ï¼Œæ­£äº¤äºé‡åŒ–ã€æ¨æµ‹è§£ç ç­‰å…¶ä»–ä¼˜åŒ–æ‰‹æ®µã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ActionFlow | ç°æœ‰æ–¹æ³• |
|------|-----------|---------|
| æ˜¯å¦éœ€è¦é‡è®­ç»ƒ | âŒ ä¸éœ€è¦ | âœ… å¤šæ•°éœ€è¦ï¼ˆå¦‚å¹¶è¡Œè§£ç ï¼‰ |
| æ˜¯å¦ä¾èµ–å¤–éƒ¨æ‰¹å¤„ç† | âŒ å•ç”¨æˆ·å†…æ„é€ æ‰¹å¤„ç† | âœ… ä¾èµ–å¤šç”¨æˆ·è¯·æ±‚ |
| æ˜¯å¦æ”¹å˜æ¨¡å‹ç»“æ„ | âŒ ä¿æŒåŸæ¨¡å‹ä¸å˜ | âœ… å¸¸éœ€ç»“æ„è°ƒæ•´ |
| å¯¹ Decode é˜¶æ®µæ•ˆç‡æå‡ | âœ… æ˜¾è‘—æå‡ï¼ˆç®—æœ¯å¼ºåº¦â†‘ï¼‰ | âš ï¸ æ”¹å–„æœ‰é™ |
| å¯éƒ¨ç½²æ€§ | âœ… è¾¹ç¼˜è®¾å¤‡å‹å¥½ | âš ï¸ å¤šä¸ºæ•°æ®ä¸­å¿ƒè®¾è®¡ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ¨¡å‹ä¸å¹³å°**
- **æ¨¡å‹**ï¼šOpenVLA-7Bï¼ˆä¸»æµå¼€æº VLA æ¨¡å‹ï¼‰
- **ç¡¬ä»¶å¹³å°**ï¼š
  - **NVIDIA Jetson AGX Orin (64GB)**ï¼šä»£è¡¨å…¸å‹åµŒå…¥å¼è¾¹ç¼˜è®¾å¤‡
  - **NVIDIA RTX 5090**ï¼šé«˜æ€§èƒ½è¾¹ç¼˜å·¥ä½œç«™ï¼ˆæ¨¡æ‹Ÿé«˜ç«¯è¾¹ç¼˜èŠ‚ç‚¹ï¼‰

### **è½¯ä»¶æ ˆ**
- PyTorch == 2.6.0
- Transformers == 4.49.0
- CUDA 12.6

### **è¯„ä¼°æŒ‡æ ‡**
- **FPSï¼ˆFrames Per Secondï¼‰**ï¼šæ ¸å¿ƒååé‡æŒ‡æ ‡ï¼Œè¡¡é‡æ¯ç§’å¯å®Œæˆçš„æ¨ç†å¸§æ•°ã€‚
- **End-to-End æ¨ç†å»¶è¿Ÿï¼ˆmsï¼‰**
- **Speedup**ï¼šç›¸å¯¹äº Baseline çš„åŠ é€Ÿæ¯”
- **Success Rate (%)**ï¼šåœ¨ LIBERO åŸºå‡†ä¸ŠéªŒè¯åŠŸèƒ½æ­£ç¡®æ€§ï¼Œç¡®ä¿æ— ç²¾åº¦æŸå¤±ã€‚

### **å¯¹æ¯”åŸºçº¿æ–¹æ³•**
| æ–¹æ³• | æè¿° |
|------|------|
| **Baseline** | æ ‡å‡†è‡ªå›å½’æ¨ç†ï¼Œæ— ç³»ç»Ÿçº§ä¼˜åŒ– |
| **Naive Pipe** | å®ç°äº†è·¨è¯·æ±‚æµæ°´çº¿ï¼Œä½†ä½¿ç”¨åŠ¨æ€ KV ç¼“å­˜æ‹¼æ¥å’Œ CPU åè°ƒæ‰¹å¤„ç†ï¼ˆæ— ç®—å­èåˆï¼‰ |
| **ActionFlow (Ours)** | å®Œæ•´å®ç° Cross-Request Pipelining + Packed Forward + Unified KV Ring Buffer |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **ç«¯åˆ°ç«¯æ€§èƒ½å¯¹æ¯”ï¼ˆTable 1ï¼‰**

| Method       | Platform      | FPS     | Latency (ms) | Speedup |
|--------------|---------------|---------|---------------|---------|
| Baseline     | AGX Orin      | 1.25    | 803           | 1.00x   |
| Naive Pipe   | AGX Orin      | 2.70    | 373           | 2.16x   |
| **ActionFlow** | **AGX Orin**  | **3.20**| **313**       | **2.56x** |
| Baseline     | RTX 5090      | 7.62    | 131           | 1.00x   |
| Naive Pipe   | RTX 5090      | 15.60   | 64            | 2.04x   |
| **ActionFlow** | **RTX 5090**  | **19.45**| **51**        | **2.55x** |

> âœ… **ç»“è®º**ï¼šActionFlow åœ¨ä¸¤ç§å¹³å°ä¸Šå‡å®ç°çº¦ **2.55x çš„ FPS æå‡**ï¼Œä¸”åŠ é€Ÿæ•ˆæœè·¨æ¶æ„ä¸€è‡´ã€‚

### **æ¶ˆèå®éªŒåˆ†æ**
- **Naive Pipe vs. ActionFlow**ï¼šè¯æ˜äº† **Kernel Fusion å’Œ Unified KV Ring Buffer çš„å…³é”®ä½œç”¨**ã€‚
  - åœ¨ AGX Orin ä¸Šå¸¦æ¥é¢å¤– **+18.5%** æ€§èƒ½å¢ç›Šï¼›
  - åœ¨ RTX 5090 ä¸Šå¸¦æ¥ **+24.7%** å¢ç›Šï¼›
- ä¸»è¦æ”¶ç›Šæ¥æºï¼š
  - æ¶ˆé™¤ CPU-GPU åŒæ­¥æ°”æ³¡ï¼›
  - å‡å°‘å†…å­˜åˆ†é…ä¸æ‹·è´å¼€é”€ï¼›
  - æé«˜ GEMM è®¡ç®—å¯†åº¦ã€‚

### **æ•æ„Ÿæ€§åˆ†æï¼ˆå›¾5ï¼‰**
- **ä¸åŒ Decode é•¿åº¦ K ä¸‹çš„è¡¨ç°**ï¼š
  - å½“ K=32ï¼ˆé•¿åŠ¨ä½œåºåˆ—ï¼‰æ—¶ï¼Œåœ¨ RTX 5090 ä¸Š Baseline æ€§èƒ½ä¸‹é™è‡³ 2.36 FPSï¼›
  - ActionFlow ä»ç»´æŒ 9.58 FPSï¼Œå®ç° **4.06Ã— åŠ é€Ÿ**ï¼›
  - åœ¨ AGX Orin ä¸Šæœ€é‡è´Ÿè½½ä¸‹è¾¾åˆ° **4.36Ã— åŠ é€Ÿ**ï¼ˆ1.31 vs. 0.30 FPSï¼‰ï¼›
- **å¯¹ Decode é•¿åº¦é²æ£’æ€§å¼º**ï¼š
  - Baseline éš K å¢åŠ æ€§èƒ½ä¸‹é™ 72%ï¼›
  - ActionFlow ä»…ä¸‹é™ 25%ï¼Œè¯´æ˜æœ‰æ•ˆæ‘Šå¹³äº†è‡ªå›å½’ä¸²è¡Œå¼€é”€ã€‚

### **åŠŸèƒ½æ­£ç¡®æ€§éªŒè¯ï¼ˆTable 2ï¼‰**

| Method       | Platform      | Spatial | Object | Goal | Long |
|--------------|---------------|--------|--------|------|------|
| OpenVLA      | RTX 5090      | 84.4%  | 73.8%  | 74.4%| 51.4%|
| ActionFlow   | RTX 5090      | 84.3%  | 71.2%  | 78.6%| 53.3%|
| ActionFlow   | AGX Orin      | 83.4%  | 68.8%  | 75.6%| 49.0%|

> âœ… **ç»“è®º**ï¼šActionFlow åœ¨æ‰€æœ‰ä»»åŠ¡ç±»åˆ«ä¸­æˆåŠŸç‡ä¸ Baseline åŸºæœ¬æŒå¹³ï¼Œæ³¢åŠ¨åœ¨ç»Ÿè®¡è¯¯å·®èŒƒå›´å†…ï¼Œ**éªŒè¯äº†å…¶åŠŸèƒ½æ— æŸæ€§ï¼ˆfunctionally losslessï¼‰**ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **VLA æ¨ç†ç“¶é¢ˆæœ¬è´¨åœ¨äº Decode é˜¶æ®µçš„ä½æ•ˆå†…å­˜è®¿é—®æ¨¡å¼**ï¼Œè€Œéå•çº¯è®¡ç®—èƒ½åŠ›ä¸è¶³ï¼›
2. **å³ä½¿åœ¨å•ç”¨æˆ·åœºæ™¯ä¸‹ï¼Œä¹Ÿèƒ½é€šè¿‡â€œè·¨è¯·æ±‚æµæ°´çº¿â€åˆ›é€ æœ‰æ•ˆçš„æ‰¹å¤„ç†æœºä¼š**ï¼Œçªç ´ä¼ ç»Ÿ batching çš„é™åˆ¶ï¼›
3. **ç³»ç»Ÿçº§ä¼˜åŒ–å¯åœ¨ä¸ä¿®æ”¹æ¨¡å‹çš„å‰æä¸‹å¤§å¹…åŠ é€Ÿ VLA æ¨ç†**ï¼Œä¸”ä¸é‡åŒ–ã€æ¨æµ‹è§£ç ç­‰æ­£äº¤ï¼›
4. **ActionFlow å°† OpenVLA-7B çš„æ¨ç†é€Ÿåº¦æå‡ 2.55Ã—ï¼Œä½¿å…¶é¦–æ¬¡æ¥è¿‘å®æ—¶æ§åˆ¶æ‰€éœ€é¢‘ç‡ï¼ˆ>3 FPS â†’ ~3.2 FPS on Orinï¼‰**ï¼Œä¸ºé€šç”¨å…·èº«æ™ºèƒ½ä½“åœ¨åŠ¨æ€ç¯å¢ƒä¸­éƒ¨ç½²é“ºå¹³é“è·¯ã€‚

### **å±€é™æ€§**
1. **åŠ é€Ÿæ•ˆæœä¾èµ–äºè¿ç»­è¯·æ±‚æµ**ï¼šè‹¥æœºå™¨äººæ§åˆ¶ä¸­æ–­æˆ–è¯·æ±‚ç¨€ç–ï¼Œæµæ°´çº¿éš¾ä»¥å¡«æ»¡ï¼Œæ€§èƒ½ä¼šå›è½ï¼›
2. **å›ºå®šåŠ¨ä½œé•¿åº¦å‡è®¾**ï¼šç›®å‰å‡è®¾æ¯ä¸ªè¯·æ±‚ç”Ÿæˆå›ºå®šé•¿åº¦çš„åŠ¨ä½œåºåˆ—ï¼ˆK æ­¥ï¼‰ï¼Œå¯¹å˜é•¿è¾“å‡ºæ”¯æŒè¾ƒå¼±ï¼›
3. **KV Ring Buffer å†…å­˜å¼€é”€**ï¼šéœ€ç»´æŠ¤ K ä¸ªå†å²è¯·æ±‚çš„ KV ç¼“å­˜ï¼Œå†…å­˜å ç”¨éš K çº¿æ€§å¢é•¿ï¼Œåœ¨æç«¯æƒ…å†µä¸‹å¯èƒ½æˆä¸ºç“¶é¢ˆï¼›
4. **å°šæœªé›†æˆæ›´é«˜çº§ä¼˜åŒ–**ï¼šå¦‚ Speculative Decoding æˆ– MOE è°ƒåº¦ï¼Œæœªæ¥å¯è¿›ä¸€æ­¥å åŠ ä¼˜åŒ–ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **æ”¯æŒå˜é•¿åŠ¨ä½œåºåˆ—çš„åŠ¨æ€æµæ°´çº¿è°ƒåº¦æœºåˆ¶**ï¼›
2. **ç»“åˆ Speculative Decoding æ„å»ºæ··åˆåŠ é€Ÿæ–¹æ¡ˆ**ï¼›
3. **æ‰©å±•è‡³å¤šæ¨¡æ€è¾“å…¥æµï¼ˆå¦‚è§†é¢‘ã€LiDARï¼‰çš„æŒç»­æ¨ç†åœºæ™¯**ï¼›
4. **åœ¨çœŸå®æœºå™¨äººå¹³å°ä¸Šè¿›è¡Œé—­ç¯æ§åˆ¶æµ‹è¯•**ï¼ŒéªŒè¯å®é™…æ“æ§ç¨³å®šæ€§ä¸å“åº”èƒ½åŠ›ï¼›
5. **æ¢ç´¢ä¸è½»é‡åŒ–æ¨¡å‹ï¼ˆå¦‚ TinyVLAã€BitVLAï¼‰çš„ååŒéƒ¨ç½²ç­–ç•¥**ã€‚

---

> ğŸ”— **é¡¹ç›®ä¸»é¡µ**ï¼šhttps://anonymous.4open.science/r/ActionFlow-1D47  
> ğŸ“„ **åŸæ–‡é“¾æ¥**ï¼š[arXiv:2512.20276](https://arxiv.org/abs/2512.20276)

</details>

---

### 2. [MoE-DiffuSeq: Enhancing Long-Document Diffusion Models with Sparse Attention and Mixture of Experts](https://arxiv.org/abs/2512.20604)

**Authors**: Alexandros Christoforos, Chadbourne Davis  
**Category**: cs.CL  
**Published**: 2025-12-24  
**Score**: 12.5  
**Type**: new  
**ArXiv ID**: 2512.20604v1  

#### Abstract
We present MoE-DiffuSeq, a mixture of experts based framework for enhancing diffusion models in long document generation. Existing diffusion based text generation models, such as DiffuSeq, suffer from high computational cost and memory overhead when applied to extended sequences. To address these ch...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# MoE-DiffuSeq è®ºæ–‡æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿæ‰©æ•£æ¨¡å‹ï¼ˆå¦‚ **DiffuSeq**ï¼‰åœ¨å¤„ç†é•¿æ–‡æœ¬ç”Ÿæˆä»»åŠ¡æ—¶é¢ä¸´ä¸¥é‡çš„**è®¡ç®—æ•ˆç‡ä½ä¸‹**å’Œ**å†…å­˜æ¶ˆè€—è¿‡é«˜**é—®é¢˜ï¼Œä¸»è¦æºäºæ ‡å‡† Transformer æ¶æ„ä¸­è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„ $O(n^2)$ æ—¶é—´å¤æ‚åº¦ã€‚æ­¤å¤–ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€šå¸¸å—é™äºè®­ç»ƒåºåˆ—é•¿åº¦ï¼ˆå¦‚ä¸è¶…è¿‡ 8,000 tokensï¼‰ï¼Œéš¾ä»¥æœ‰æ•ˆå»ºæ¨¡é•¿ä¸Šä¸‹æ–‡ä¾èµ–ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡º **MoE-DiffuSeq**ï¼Œä¸€ç§èåˆ **Mixture of Experts (MoE)** ä¸ **DiffuSeq** æ¡†æ¶ï¼Œå¹¶å¼•å…¥ **ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼ˆSparse Attentionï¼‰** å’Œ **è½¯å¸æ”¶æ€ï¼ˆsoft absorbing stateï¼‰** çš„æ–°å‹é•¿æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **MoE + Diffusion èåˆæ¶æ„**ï¼šé¦–æ¬¡å°† MoE åŠ¨æ€ä¸“å®¶é€‰æ‹©æœºåˆ¶é›†æˆåˆ°æ‰©æ•£è¯­è¨€æ¨¡å‹ä¸­ï¼Œå®ç°å¯¹ä¸åŒæ–‡æœ¬ç‰‡æ®µæŒ‰éœ€æ¿€æ´»æœ€ç›¸å…³ä¸“å®¶ï¼Œæå‡æ¨¡å‹å®¹é‡ä¸æ¨ç†æ•ˆç‡ã€‚
- **å®šåˆ¶åŒ–ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶**ï¼šé‡‡ç”¨ **Longformer-style æ»‘åŠ¨çª—å£æ³¨æ„åŠ›**ï¼Œå¹¶ç»“åˆ **è†¨èƒ€æ»‘çª—ï¼ˆDilated Sliding Windowï¼‰** æ‰©å±•æ„Ÿå—é‡ï¼Œåœ¨ä¸å¢åŠ è®¡ç®—è´Ÿæ‹…çš„å‰æä¸‹æ•æ‰é•¿è·ç¦»ä¾èµ–ã€‚
- **å…¨å±€æ³¨æ„åŠ›æœºåˆ¶**ï¼šä¸ºå…³é”® tokenï¼ˆå¦‚ `[CLS]`ï¼‰ä¿ç•™å…¨å±€æ³¨æ„åŠ›èƒ½åŠ›ï¼Œç¡®ä¿æ•´ä½“è¯­ä¹‰ä¸€è‡´æ€§ã€‚
- **ä¼˜åŒ–æ‰©æ•£è¿‡ç¨‹è®¾è®¡**ï¼š
  - å¼•å…¥ **è½¯å¸æ”¶æ€ï¼ˆsoft absorbing stateï¼‰** æ”¹è¿›ç¦»æ•£çŠ¶æ€å»ºæ¨¡ï¼›
  - ç»“åˆ **DPM-solver++** åŠ é€Ÿé‡‡æ ·è¿‡ç¨‹ï¼Œæ˜¾è‘—å‡å°‘æ‰€éœ€æ‰©æ•£æ­¥æ•°ï¼›
  - è®¾è®¡è”åˆå»å™ªç­–ç•¥ä¸æ­£åˆ™åŒ–æŸå¤±å‡½æ•°ä»¥æé«˜é‡å»ºç²¾åº¦ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿è¯´æ˜ |
|------|----------|
| **æ•ˆç‡** | æ˜¾è‘—é™ä½è®­ç»ƒå’Œæ¨ç†æ—¶é—´ï¼Œå°¤å…¶é€‚ç”¨äºè¶…é•¿åºåˆ—ï¼ˆscientific papers, code repos, dialoguesï¼‰ |
| **å¯æ‰©å±•æ€§** | MoE æ¶æ„æ”¯æŒæ›´å¤§å‚æ•°é‡è€Œæ— éœ€å…¨æ¿€æ´»ï¼Œé€‚åˆå¤§è§„æ¨¡éƒ¨ç½² |
| **è´¨é‡ä¿æŒ** | åœ¨æå‡é€Ÿåº¦çš„åŒæ—¶ï¼Œç»´æŒç”šè‡³è¶…è¶ŠåŸºçº¿æ¨¡å‹çš„æ–‡æœ¬è¿è´¯æ€§ã€è¯­ä¹‰å‡†ç¡®æ€§å’Œå¤šæ ·æ€§ |
| **çµæ´»æ€§** | ç¨€ç–æ³¨æ„åŠ› + MoE çš„ç»„åˆå¯åœ¨ä¸åŒä»»åŠ¡é—´çµæ´»è°ƒæ•´é…ç½® |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒæ¶µç›–å¤šä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é•¿æ–‡æœ¬ç”Ÿæˆåœºæ™¯ï¼š

| æ•°æ®é›† | ä»»åŠ¡ç±»å‹ | ç‰¹ç‚¹ |
|--------|---------|------|
| **Arxiv Abstract Dataset** | ç§‘å­¦æ–‡çŒ®æ‘˜è¦ç”Ÿæˆ | é•¿æ–‡æœ¬ã€é«˜æŠ€æœ¯æœ¯è¯­å¯†åº¦ |
| **HotpotQA** | å¤šè·³é—®ç­”ï¼ˆMulti-hop QAï¼‰ | éœ€è¦è·¨æ–‡æ¡£æ¨ç†ä¸ä¸Šä¸‹æ–‡æ•´åˆ |
| **Commonsense Conversation Dataset** | å¯¹è¯å“åº”ç”Ÿæˆ | æ³¨é‡å¸¸è¯†ç†è§£ä¸è‡ªç„¶è¡¨è¾¾ |
| **Quora Question Pairs (QQP)** | é—®å¥å¤è¿°è¯†åˆ« | æµ‹è¯•è¯­ä¹‰ç­‰ä»·åˆ¤æ–­èƒ½åŠ› |

### å®éªŒè®¾ç½®
- **æ¨¡å‹ç»“æ„**ï¼š
  - 12 å±‚ Transformerï¼Œæ¯å±‚ 12 ä¸ªæ³¨æ„åŠ›å¤´ï¼›
  - é›†æˆ Longformer ç¨€ç–æ³¨æ„åŠ› + MoE æ¨¡å—ï¼›
  - æ¯ä¸ª MoE å±‚å«å¤šä¸ªå‰é¦ˆç½‘ç»œä¸“å®¶ï¼Œç”±é—¨æ§å‡½æ•°åŠ¨æ€è·¯ç”±ã€‚
- **è®­ç»ƒç­–ç•¥**ï¼š
  - åˆ†é˜¶æ®µå¢å¤§çª—å£å¤§å°ä¸åºåˆ—é•¿åº¦ï¼›
  - ä½¿ç”¨ 2,048 æ­¥æ‰©æ•£è¿‡ç¨‹ï¼Œå™ªå£°è°ƒåº¦ä¸ºå¹³æ–¹æ ¹å½¢å¼ï¼›
  - ä¼˜åŒ–å™¨ä¸å­¦ä¹ ç‡æœªè¯¦è¿°ï¼Œä½†åœ¨ NVIDIA A100 GPU ä¸Šè¿è¡Œã€‚
- **é‡‡æ ·åŠ é€Ÿ**ï¼šé‡‡ç”¨ **DPM-solver++** å‡å°‘æ¨ç†é˜¶æ®µæ‰©æ•£æ­¥æ•°ã€‚

### è¯„ä¼°æŒ‡æ ‡
ç»¼åˆè¯„ä»·ç”Ÿæˆè´¨é‡ä¸è¯­ä¹‰å‡†ç¡®æ€§ï¼š

| æŒ‡æ ‡ | æè¿° |
|------|------|
| **BLEU** | è¡¡é‡ n-gram åŒ¹é…ç²¾åº¦ï¼Œåæ˜ ç”Ÿæˆæ–‡æœ¬ä¸å‚è€ƒæ–‡æœ¬çš„ç›¸ä¼¼åº¦ |
| **ROUGE (R1/R2/RL)** | åŸºäºå¬å›ç‡çš„ n-gram é‡å åº¦ï¼Œå¸¸ç”¨äºæ‘˜è¦ä»»åŠ¡ |
| **BERTScore** | åˆ©ç”¨ BERT ä¸Šä¸‹æ–‡åµŒå…¥è®¡ç®—è¯çº§è¯­ä¹‰ç›¸ä¼¼æ€§ï¼Œæ›´è´´è¿‘äººç±»åˆ¤æ–­ |
| **Accuracy** | åˆ†ç±»ä»»åŠ¡ï¼ˆå¦‚ QQPï¼‰ä¸­çš„é¢„æµ‹å‡†ç¡®ç‡ |
| **Inference Time / Novelty** | æ¨ç†å»¶è¿Ÿä¸ç”Ÿæˆæ–‡æœ¬æ–°é¢–æ€§ï¼ˆå¦‚ 2-gram noveltyï¼‰ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **DiffuSeq**ï¼šåŸºç¡€æ‰©æ•£è¯­è¨€æ¨¡å‹ï¼Œä½œä¸ºç›´æ¥å¯¹ç…§ï¼›
- **Longformer**ï¼šåŸºäºç¨€ç–æ³¨æ„åŠ›çš„ç»å…¸é•¿æ–‡æœ¬ç¼–ç å™¨ï¼›
- **GPT-4**ï¼šå½“å‰ä¸»æµå¤§æ¨¡å‹ï¼Œæä¾›é«˜æ€§èƒ½ä¸Šé™å‚è€ƒï¼›
- å…¶ä»–ç‰¹å®šä»»åŠ¡ä¸“ç”¨æ¨¡å‹ä¹Ÿå‚ä¸æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Tables 1â€“4ï¼‰

#### Arxiv Abstract Datasetï¼ˆROUGE æŒ‡æ ‡ï¼‰
| Model | R1 | R2 | RL |
|-------|----|----|-----|
| Longformer | 41.44 | 17.52 | 38.70 |
| DiffuSeq | 39.12 | 16.43 | 37.88 |
| **MoE-DiffuSeq** | **44.41** | **18.73** | **39.89** |

> âœ… åœ¨ç§‘å­¦æ‘˜è¦ç”Ÿæˆä¸Šå…¨é¢é¢†å…ˆï¼Œè¡¨æ˜æ›´å¼ºçš„è¯­è¨€ç»“æ„ç†è§£å’Œç»„ç»‡èƒ½åŠ›ã€‚

#### HotpotQAï¼ˆå¤šè·³é—®ç­”ï¼‰
| Model | Answer EM/F1 | Support EM/F1 |
|-------|---------------|----------------|
| Longformer | 71.21 / 82.42 | 65.11 / 89.50 |
| DiffuSeq | 70.91 / 81.43 | 64.60 / 88.51 |
| **MoE-DiffuSeq** | **72.88 / 85.42** | **66.69 / 90.40** |

> âœ… æ˜¾è‘—æå‡ç­”æ¡ˆä¸è¯æ®é“¾çš„åŒ¹é…å‡†ç¡®ç‡ï¼Œä½“ç°ä¼˜å¼‚çš„è·¨æ–‡æ¡£æ¨ç†èƒ½åŠ›ã€‚

#### Commonsense Conversation Dataset
| Model | BLEU | ROUGE-L | BERTScore |
|-------|------|---------|-----------|
| Longformer | 0.030 | 0.139 | 0.602 |
| DiffuSeq | 0.022 | 0.119 | 0.501 |
| **MoE-DiffuSeq** | **0.049** | **0.233** | **0.628** |

> âœ… ç”Ÿæˆæ›´å…·å¤šæ ·æ€§å’Œè¯­ä¹‰åˆç†æ€§çš„å¯¹è¯å›å¤ã€‚

#### QQPï¼ˆå¤è¿°è¯†åˆ«ï¼‰
| Model | Accuracy |
|-------|----------|
| Longformer | 92.3 |
| DiffuSeq | 91.7 |
| **MoE-DiffuSeq** | **95.3** |

> âœ… åœ¨è¯­ä¹‰ç­‰ä»·åˆ¤æ–­ä»»åŠ¡ä¸­è¡¨ç°æœ€ä½³ï¼Œè¯´æ˜å…¶èƒ½ç²¾å‡†æŠŠæ¡ç»†å¾®è¯­ä¹‰å·®å¼‚ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 5 & Figure 3ï¼‰

#### Ablation Study on Arxiv Dataset
| Configuration | BLEU/ROUGE/BERTScore |
|---------------|------------------------|
| Full Model (Sparse + 2048 steps + w=512) | 44.41 / 18.73 / 39.89 |
| No Sparse Attention | â†“ è‡³ 42.52 / 17.99 / 38.41 |
| Reduced Diffusion Steps (1024) | 43.11 / 18.03 / 39.26 |
| Increased Diffusion Steps (4096) | â€”â€”ï¼ˆè¾¹é™…æ”¶ç›Šé€’å‡ï¼‰ |
| Smaller Window (256) | å¾®é™ |
| Larger Window (1024) | æå‡æœ‰é™ |

> ğŸ” **å…³é”®å‘ç°**ï¼š
> - **ç¨€ç–æ³¨æ„åŠ›è‡³å…³é‡è¦**ï¼šç§»é™¤åæ€§èƒ½å¤§å¹…ä¸‹é™ï¼›
> - **æ›´å¤šæ‰©æ•£æ­¥æ•°æœ‰åŠ©äºè´¨é‡æå‡ï¼Œä½†å­˜åœ¨é¥±å’Œç‚¹**ï¼›
> - **çª—å£å¤§å°å½±å“è¾ƒå°**ï¼Œè¯´æ˜ç¨€ç–æœºåˆ¶æœ¬èº«å·²è¶³å¤Ÿé«˜æ•ˆã€‚

#### æ¨ç†æ•ˆç‡ä¸æ–°é¢–æ€§æƒè¡¡ï¼ˆFigure 3ï¼‰
- **MoE-DiffuSeq** åœ¨ **2-gram novelty** ä¸Šæ˜¾è‘—é«˜äº Longformer å’Œ DiffuSeqï¼›
- æ¨ç†æ—¶é—´ä»…ç•¥æ…¢äºæœ€å¿«çš„ Longformerï¼Œè¿œä¼˜äº DiffuSeqï¼›
- å®ç°äº†â€œ**é«˜è´¨é‡ + é«˜æ–°é¢–æ€§ + å¿«é€Ÿæ¨ç†**â€çš„è‰¯å¥½å¹³è¡¡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **MoE ä¸æ‰©æ•£æ¨¡å‹çš„ç»“åˆæ˜¯å¯è¡Œä¸”é«˜æ•ˆçš„**ï¼šMoE-DiffuSeq æˆåŠŸå°† MoE çš„åŠ¨æ€èµ„æºåˆ†é…ä¼˜åŠ¿å¼•å…¥æ‰©æ•£æ¡†æ¶ï¼Œè§£å†³äº†é•¿åºåˆ—ç”Ÿæˆä¸­çš„è®¡ç®—ç“¶é¢ˆã€‚
2. **ç¨€ç–æ³¨æ„åŠ›æ˜¯å¤„ç†é•¿æ–‡æœ¬çš„å…³é”®ç»„ä»¶**ï¼šé€šè¿‡å±€éƒ¨çª—å£ + è†¨èƒ€æœºåˆ¶ + å…¨å±€ token çš„æ··åˆè®¾è®¡ï¼Œå®ç°äº†é«˜æ•ˆä¸”æœ‰æ•ˆçš„ä¸Šä¸‹æ–‡å»ºæ¨¡ã€‚
3. **æ€§èƒ½å…¨é¢æå‡**ï¼šåœ¨å¤šä¸ª NLP ä»»åŠ¡ä¸­ï¼ŒMoE-DiffuSeq ä¸ä»…åœ¨ **ç”Ÿæˆè´¨é‡ï¼ˆROUGE, BERTScoreï¼‰** ä¸Šè¶…è¶ŠåŸºçº¿ï¼Œåœ¨ **æ¨ç†é€Ÿåº¦** å’Œ **æ–‡æœ¬æ–°é¢–æ€§** æ–¹é¢ä¹Ÿè¡¨ç°å‡ºè‰²ã€‚
4. **é€‚ç”¨äºå¤šç§é•¿æ–‡æœ¬åº”ç”¨åœºæ™¯**ï¼šåŒ…æ‹¬ç§‘ç ”å†™ä½œã€ä»£ç ç”Ÿæˆã€å¤æ‚å¯¹è¯ç³»ç»Ÿç­‰éœ€è¦æ·±åº¦ä¸Šä¸‹æ–‡ç†è§£çš„ä»»åŠ¡ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **å®ç°å¤æ‚åº¦è¾ƒé«˜**ï¼šåŒæ—¶é›†æˆ MoEã€ç¨€ç–æ³¨æ„åŠ›ã€æ‰©æ•£è¿‡ç¨‹å’Œ DPM-solver++ï¼Œå¢åŠ äº†å·¥ç¨‹å®ç°éš¾åº¦ï¼›
- **ç¡¬ä»¶éœ€æ±‚ä»é«˜**ï¼šå°½ç®¡ MoE æå‡äº†æ•ˆç‡ï¼Œä½†æ•´ä½“æ¨¡å‹è§„æ¨¡è¾ƒå¤§ï¼Œä¾èµ–é«˜æ€§èƒ½ GPUï¼ˆå¦‚ A100ï¼‰ï¼›
- **ç¼ºä¹å¤šæ¨¡æ€æ‰©å±•**ï¼šç›®å‰ä»…é™æ–‡æœ¬æ¨¡æ€ï¼Œå°šæœªæ¢ç´¢å›¾åƒã€éŸ³é¢‘ç­‰è·¨æ¨¡æ€ç”Ÿæˆï¼›
- **æ¶ˆèä¸å¤Ÿå……åˆ†**ï¼šæœªå•ç‹¬æµ‹è¯• MoE æ¨¡å—çš„å½±å“ï¼Œéš¾ä»¥å®Œå…¨è§£è€¦å„ç»„ä»¶è´¡çŒ®ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **æ‹“å±•è‡³å¤šæ¨¡æ€ç”Ÿæˆä»»åŠ¡**ï¼šç»“åˆè§†è§‰æˆ–è¯­éŸ³ä¿¡å·ï¼Œæ„å»ºè·¨æ¨¡æ€æ‰©æ•£ç”Ÿæˆç³»ç»Ÿï¼›
- **è¿›ä¸€æ­¥å‹ç¼©ä¸è’¸é¦**ï¼šç ”ç©¶è½»é‡åŒ–ç‰ˆæœ¬ä»¥ä¾¿åœ¨è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²ï¼›
- **æ¢ç´¢æ›´ä¼˜çš„ä¸“å®¶è·¯ç”±æœºåˆ¶**ï¼šå¦‚ Expert Choice Routing æˆ–è´Ÿè½½å‡è¡¡ç­–ç•¥ï¼›
- **åº”ç”¨äºçœŸå®ä¸–ç•Œé•¿æ–‡æ¡£ç”Ÿæˆåœºæ™¯**ï¼šå¦‚è‡ªåŠ¨æ’°å†™æŠ¥å‘Šã€æ³•å¾‹æ–‡ä¹¦ã€å°è¯´åˆ›ä½œç­‰ï¼›
- **å¢å¼ºå¯æ§æ€§ä¸ç¼–è¾‘èƒ½åŠ›**ï¼šå…è®¸ç”¨æˆ·å¹²é¢„ç”Ÿæˆè·¯å¾„æˆ–ä¿®æ”¹ä¸­é—´çŠ¶æ€ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **MoE-DiffuSeq é€šè¿‡èåˆ Mixture of Experts ä¸ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ˜¾è‘—æå‡äº†æ‰©æ•£è¯­è¨€æ¨¡å‹åœ¨é•¿æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­çš„æ•ˆç‡ä¸è´¨é‡ï¼Œä»£è¡¨äº†ä¸‹ä¸€ä»£é«˜æ•ˆã€å¯æ‰©å±•ç”Ÿæˆæ¨¡å‹çš„é‡è¦è¿›å±•ã€‚**

</details>

---

### 3. [SHIRO: Near-Optimal Communication Strategies for Distributed Sparse Matrix Multiplication](https://arxiv.org/abs/2512.20178)

**Authors**: Chen Zhuang, Lingqi Zhang, Benjamin Brock, Du Wu, Peng Chen, Toshio Endo, Satoshi Matsuoka, Mohamed Wahib  
**Category**: cs.DC  
**Published**: 2025-12-24  
**Score**: 11.5  
**Type**: new  
**ArXiv ID**: 2512.20178v1  

#### Abstract
Distributed Sparse Matrix-Matrix Multiplication (SpMM) is a fundamental operation in numerous high-performance computing and deep learning applications. The major performance bottleneck in distributed SpMM lies in the substantial communication overhead, which limits both performance and scalability....

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# SHIRO: Near-Optimal Communication Strategies for Distributed Sparse Matrix Multiplication è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

åˆ†å¸ƒå¼ç¨€ç–çŸ©é˜µä¹˜æ³•ï¼ˆ**Distributed SpMM**ï¼‰æ˜¯é«˜æ€§èƒ½è®¡ç®—å’Œæ·±åº¦å­¦ä¹ ï¼ˆå¦‚å›¾ç¥ç»ç½‘ç»œ GNNï¼‰ä¸­çš„æ ¸å¿ƒæ“ä½œï¼Œå…¶æ€§èƒ½ç“¶é¢ˆåœ¨äº**é€šä¿¡å¼€é”€è¿‡å¤§**ã€‚ç°æœ‰æ–¹æ³•åœ¨é€šä¿¡ç­–ç•¥ä¸Šå­˜åœ¨ä¸¤å¤§ä½æ•ˆé—®é¢˜ï¼š

1. **é€šä¿¡å†—ä½™**ï¼š  
   - **Sparsity-oblivious** æ–¹æ³•ï¼ˆå¦‚ CAGNETã€BCLï¼‰æ— è§†ç¨€ç–æ€§ï¼Œä¼ è¾“æ•´ä¸ªç¨ å¯†å—ï¼Œé€ æˆå¤§é‡æ— ç”¨æ•°æ®ä¼ è¾“ã€‚  
   - **Sparsity-aware** æ–¹æ³•ï¼ˆå¦‚ SPAã€CoLaï¼‰è™½æŒ‰åˆ—æˆ–è¡Œç´¢å¼•ä¼ è¾“æ‰€éœ€æ•°æ®ï¼Œä½†ä»ä»…åˆ©ç”¨å•ç»´åº¦ç¨€ç–ä¿¡æ¯ï¼Œæœªèƒ½å……åˆ†æŒ–æ˜ç¨€ç–æ¨¡å¼ã€‚

2. **å¿½ç•¥å±‚æ¬¡åŒ–ç½‘ç»œæ‹“æ‰‘**ï¼š  
   å¤šæ•°æ–¹æ³•å‡è®¾æ‰€æœ‰è¿›ç¨‹é—´é€šä¿¡ä»£ä»·ç›¸åŒï¼Œä½†åœ¨ç°ä»£ GPU é›†ç¾¤ä¸­ï¼ŒèŠ‚ç‚¹å†…ï¼ˆNVLinkï¼‰å¸¦å®½è¿œé«˜äºèŠ‚ç‚¹é—´ï¼ˆInfiniBandï¼‰ï¼Œå¯¼è‡´è·¨èŠ‚ç‚¹é‡å¤ä¼ è¾“ç›¸åŒæ•°æ®ï¼Œå½¢æˆç“¶é¢ˆã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡º **SHIRO** â€”â€” ä¸€ä¸ªé€šä¿¡é«˜æ•ˆçš„åˆ†å¸ƒå¼ SpMM æ¡†æ¶ï¼ŒåŒ…å«ä¸¤ä¸ªæ ¸å¿ƒä¼˜åŒ–ç­–ç•¥ï¼š

#### âœ… **(1) è”åˆè¡Œåˆ—ç¨€ç–æ„ŸçŸ¥é€šä¿¡ç­–ç•¥ï¼ˆJoint Row-Column Sparsity-Aware Communicationï¼‰**

- **æ ¸å¿ƒæ€æƒ³**ï¼šåŒæ—¶è€ƒè™‘ç¨€ç–çŸ©é˜µçš„**è¡Œç´¢å¼•**å’Œ**åˆ—ç´¢å¼•**ï¼Œä¸ºæ¯ä¸ªéé›¶å…ƒé€‰æ‹©æœ€ä¼˜é€šä¿¡æ–¹å¼ï¼š
  - **åˆ—åŸºç­–ç•¥ï¼ˆColumn-basedï¼‰**ï¼šè¿œç¨‹è¿›ç¨‹å‘é€æ‰€éœ€çš„ `B` è¡Œã€‚
  - **è¡ŒåŸºç­–ç•¥ï¼ˆRow-basedï¼‰**ï¼šè¿œç¨‹è¿›ç¨‹è®¡ç®—éƒ¨åˆ† `C` ç»“æœå¹¶è¿”å›ã€‚
- å°†é€šä¿¡æœ€å°åŒ–é—®é¢˜å»ºæ¨¡ä¸º **Minimum Weighted Set Cover Problem**ï¼Œè¿›ä¸€æ­¥è½¬åŒ–ä¸º **Minimum Weighted Vertex Cover on Bipartite Graph**ã€‚
- åˆ©ç”¨ **Max-Flow / Min-Cut** ç†è®ºï¼ˆé€šè¿‡ Dinicâ€™s Algorithmï¼‰æ±‚è§£æœ€ä¼˜é€šä¿¡æ–¹æ¡ˆï¼Œåœ¨å¤šé¡¹å¼æ—¶é—´å†…è·å¾—å…¨å±€æœ€ä¼˜è§£ã€‚

> ğŸ“Œ ä¼˜åŠ¿ï¼šç›¸æ¯”å•ä¸€ç»´åº¦ç­–ç•¥ï¼Œèƒ½æ˜¾è‘—å‡å°‘é€šä¿¡é‡ï¼Œå°¤å…¶åœ¨éé›¶å…ƒåˆ†å¸ƒå¤æ‚æ—¶æ•ˆæœæ›´æ˜æ˜¾ã€‚

#### âœ… **(2) å±‚æ¬¡åŒ–é€šä¿¡ç­–ç•¥ï¼ˆHierarchical Communication Strategyï¼‰**

- é’ˆå¯¹ GPU é›†ç¾¤çš„**ä¸¤å±‚ç½‘ç»œæ¶æ„**ï¼ˆèŠ‚ç‚¹å†…é«˜é€Ÿ + èŠ‚ç‚¹é—´ä½é€Ÿï¼‰è®¾è®¡ï¼š
  - **åˆ—åŸºé€šä¿¡ä¼˜åŒ–**ï¼šé‡‡ç”¨â€œæºç»„èšåˆ â†’ è·¨ç»„ä¼ è¾“ â†’ ç»„å†…åˆ†å‘â€ä¸‰æ­¥æ³•ï¼Œé¿å…åŒä¸€ `B` è¡Œè¢«å¤šæ¬¡è·¨èŠ‚ç‚¹ä¼ è¾“ã€‚
  - **è¡ŒåŸºé€šä¿¡ä¼˜åŒ–**ï¼šé‡‡ç”¨â€œç»„å†…é¢„èšåˆ â†’ è·¨ç»„ä¼ è¾“â€ä¸¤é˜¶æ®µï¼Œå°†å¤šä¸ªéƒ¨åˆ†ç»“æœå…ˆåœ¨æœ¬åœ°åˆå¹¶å†å‘é€ï¼Œå‡å°‘è·¨èŠ‚ç‚¹æµé‡ã€‚
- è®¾è®¡**é‡å è°ƒåº¦ç­–ç•¥ï¼ˆOverlapping Schedulingï¼‰**ï¼š
  - åˆ—åŸºé€šä¿¡ä½¿ç”¨è·¨èŠ‚ç‚¹é“¾è·¯æ—¶ï¼Œè¡ŒåŸºé€šä¿¡ä½¿ç”¨ç»„å†…é“¾è·¯ï¼Œåä¹‹äº¦ç„¶ã€‚
  - å®ç°åŒå±‚çº§é“¾è·¯çš„**å¹¶è¡Œé«˜æ•ˆåˆ©ç”¨**ï¼Œæå‡æ•´ä½“å¸¦å®½åˆ©ç”¨ç‡ã€‚

> ğŸ“Œ ä¼˜åŠ¿ï¼šæ˜¾è‘—é™ä½è·¨èŠ‚ç‚¹é€šä¿¡é‡ï¼Œç¼“è§£æ…¢é€Ÿé“¾è·¯ç“¶é¢ˆã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç‰¹æ€§ | SHIRO | CAGNET/BCL | SPA | CoLa |
|------|-------|------------|-----|------|
| Sparsity-aware | âœ… è”åˆè¡Œåˆ— | âŒ | âœ… åˆ—åŸº | âœ… åˆ—åŸº + å±‚æ¬¡ |
| Hierarchy-aware | âœ… åŒå‘ä¼˜åŒ– | âŒ | âŒ | âœ… ä»…åˆ—åŸº |
| å…¨å±€æœ€ä¼˜é€šä¿¡ | âœ… å›¾è®ºæ±‚è§£ | âŒ | âŒ å¯å‘å¼ | âŒ |
| é€šä¿¡ä½“ç§¯ | æœ€å° | æœ€å¤§ | ä¸­ç­‰ | è¾ƒå° |
| æ‰©å±•æ€§ | å¼ºï¼ˆè‡³128 GPUsï¼‰ | å¼± | ä¸­ç­‰ | ä¸­ç­‰ |

> SHIRO æ˜¯é¦–ä¸ª**è”åˆä¼˜åŒ–é€šä¿¡ç­–ç•¥ä¸ç½‘ç»œæ‹“æ‰‘**çš„ SpMM æ¡†æ¶ï¼Œå…¼å…·ç†è®ºæœ€ä¼˜æ€§ä¸å·¥ç¨‹å®ç”¨æ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

æ¥è‡ª **SuiteSparse Matrix Collection** çš„çœŸå®ä¸–ç•Œç¨€ç–çŸ©é˜µï¼Œæ¶µç›–ç¤¾äº¤ç½‘ç»œã€ç½‘é¡µå›¾ã€ç§‘å­¦è®¡ç®—ç­‰é¢†åŸŸï¼š

| æ•°æ®é›† | è§„æ¨¡ï¼ˆè¡Œ/åˆ—ï¼‰ | éé›¶å…ƒæ•°é‡ | å¯†åº¦ |
|--------|----------------|-------------|--------|
| `com-YT`, `soc-LJ`, `Orkut`, `Pokec` | ç™¾ä¸‡çº§ | æ•°åƒä¸‡ ~ 2.3äº¿ | ~1e-5 |
| `webbase-2001`, `GAP-web` | ä¸Šäº¿çº§ | è¶…10äº¿ | <1e-7 |
| `delaunay_n24`, `mawi_69M` | ä¸­å¤§å‹ | æ•°åƒä¸‡ ~ 1.4äº¿ | æç¨€ç– |

å…±13ä¸ªæ•°æ®é›†ï¼Œè¦†ç›–å¤šç§ç¨€ç–æ¨¡å¼ï¼ˆè¡Œåæ–œã€åˆ—åæ–œã€å‡åŒ€ã€æ··åˆï¼‰ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

- **ç¡¬ä»¶å¹³å°**ï¼šTSUBAME 4.0 è¶…ç®—ï¼Œæ¯èŠ‚ç‚¹ 4Ã—NVIDIA H100 GPUï¼ŒNVLink äº’è”ï¼ˆ450 GB/sï¼‰ï¼ŒèŠ‚ç‚¹é—´ InfiniBand NDR200ï¼ˆ200 Gbpsï¼‰ã€‚
- **å®ç°**ï¼š
  - å•èŠ‚ç‚¹ SpMM ä½¿ç”¨ PyTorch + cuSPARSEã€‚
  - å¤šèŠ‚ç‚¹é€šä¿¡åŸºäº PyTorch Distributed + NCCLã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **ç«¯åˆ°ç«¯è¿è¡Œæ—¶é—´ï¼ˆEnd-to-end Runtimeï¼‰**
  - **æ€»é€šä¿¡é‡ï¼ˆTotal Communication Volumeï¼‰**
  - **è·¨èŠ‚ç‚¹é€šä¿¡é‡ï¼ˆInter-node Trafficï¼‰**
  - **åŠ é€Ÿæ¯”ï¼ˆSpeedupï¼‰**
  - **å¼ºæ‰©å±•æ€§ï¼ˆStrong Scalingï¼‰**

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

é€‰å–å››ç±» SOTA åˆ†å¸ƒå¼ SpMM æ–¹æ³•ä½œä¸ºåŸºçº¿ï¼š

| åŸºçº¿ | åˆ†åŒºç­–ç•¥ | ç¨€ç–æ„ŸçŸ¥ | å±‚æ¬¡æ„ŸçŸ¥ | é€šä¿¡åç«¯ |
|------|----------|-----------|-----------|------------|
| **CAGNET** | 1.5D | âŒ | âŒ | NCCL |
| **SPA** | 1.5D | âœ…ï¼ˆåˆ—åŸºï¼‰ | âŒ | NCCL |
| **BCL** | 2D | âŒ | âŒ | NVSHMEM |
| **CoLa** | 1D | âœ…ï¼ˆåˆ—åŸºï¼‰ | âœ…ï¼ˆä»…åˆ—åŸºï¼‰ | NVSHMEM |

> æ‰€æœ‰æ–¹æ³•å‡æå–å…¶æ ¸å¿ƒ SpMM æ¨¡å—è¿›è¡Œå…¬å¹³æ¯”è¾ƒï¼Œç¦ç”¨å›¾é‡æ’åºã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

- åœ¨ **128 GPUs** ä¸Šï¼ŒSHIRO å®ç°ï¼š
  - **å‡ ä½•å¹³å‡åŠ é€Ÿæ¯”**è¾¾ï¼š
    - **221.5Ã—** vs CAGNET
    - **56.0Ã—** vs SPA
    - **23.4Ã—** vs BCL
    - **8.8Ã—** vs CoLa
  - æœ€é«˜é€šä¿¡é‡å‡å°‘ **96.3%**ï¼ˆåœ¨ `mawi` æ•°æ®é›†ä¸Šï¼‰ã€‚
  - è·¨èŠ‚ç‚¹é€šä¿¡é‡å‡å°‘æœ€é«˜è¾¾ **60%**ï¼ˆå¦‚ `com-LJ`, `Orkut`ï¼‰ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- **vs CAGNET/BCL**ï¼šç”±äºå®Œå…¨æ— è§†ç¨€ç–æ€§ï¼Œé€šä¿¡é‡å·¨å¤§ï¼ŒSHIRO åœ¨æ‰€æœ‰è§„æ¨¡ä¸‹å‡å¤§å¹…é¢†å…ˆï¼ˆ>50Ã—ï¼‰ã€‚
- **vs SPA**ï¼šè™½ä¸ºç¨€ç–æ„ŸçŸ¥ï¼Œä½†ä»…ç”¨åˆ—åŸºç­–ç•¥ï¼ŒSHIRO é€šè¿‡è”åˆä¼˜åŒ–è¿›ä¸€æ­¥å‡å°‘é€šä¿¡ï¼Œå¹³å‡æé€Ÿ **>50Ã—**ã€‚
- **vs CoLa**ï¼š
  - åœ¨ â‰¤4 GPUsï¼ˆå•èŠ‚ç‚¹å†…ï¼‰æ—¶ç•¥æ…¢ï¼ˆå›  CoLa æœ‰æ›´å¥½çš„è®¡ç®—-é€šä¿¡é‡å ï¼‰ã€‚
  - åœ¨ â‰¥8 GPUsï¼ˆè·¨èŠ‚ç‚¹ï¼‰åå…¨é¢åè¶…ï¼Œä¸”å·®è·éšè§„æ¨¡æ‰©å¤§è€Œå¢å¤§ï¼Œè¯æ˜å…¶å±‚æ¬¡åŒ–ä¼˜åŒ–çš„æœ‰æ•ˆæ€§ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### ğŸ”¹ **é€šä¿¡é‡å‡å°‘åˆ†æï¼ˆn=32 GPUs, N=64ï¼‰**

- **è”åˆè¡Œåˆ—ç­–ç•¥ vs åˆ—åŸºç­–ç•¥**ï¼š
  - å¹³å‡é€šä¿¡é‡å‡å°‘ **40â€“70%**ã€‚
  - åœ¨ `mawi` ä¸Šå‡å°‘ **96%**ï¼Œå¯¹åº”è¿è¡Œæ—¶é—´æé€Ÿè¿‘ **6Ã—**ã€‚
  - é€šä¿¡æ¨¡å¼æ›´å‡è¡¡ï¼Œæ¶ˆé™¤çƒ­ç‚¹é€šä¿¡å¯¹ï¼ˆè§ heatmap å¯¹æ¯”ï¼‰ã€‚

- **åŠ å…¥å±‚æ¬¡åŒ–ç­–ç•¥å**ï¼š
  - è·¨èŠ‚ç‚¹é€šä¿¡é‡è¿›ä¸€æ­¥å‡å°‘ **30â€“60%**ã€‚
  - åœ¨ `com-LJ`, `Orkut`, `sx-SO` ä¸Šæå‡æ˜¾è‘—ã€‚

#### ğŸ”¹ **é€æ­¥ä¼˜åŒ–æ€§èƒ½ï¼ˆAblation Studyï¼‰**

- ä»åˆ—åŸºç­–ç•¥ â†’ åŠ å…¥è”åˆä¼˜åŒ– â†’ åŠ å…¥å±‚æ¬¡åŒ–è°ƒåº¦ï¼š
  - æ¯ä¸€æ­¥éƒ½å¸¦æ¥æ˜¾è‘—æ€§èƒ½æå‡ã€‚
  - å”¯ä¸€ä¾‹å¤–æ˜¯ `del24`ï¼Œå› å…¶é€šä¿¡æåº¦ä¸å‡è¡¡ï¼Œå±‚æ¬¡åŒ–æ‹†åˆ†åè€Œé™ä½é“¾è·¯åˆ©ç”¨ç‡ã€‚

#### ğŸ”¹ **å¼ºæ‰©å±•æ€§æµ‹è¯•**

- æ‰€æœ‰åŸºçº¿åœ¨ >8 GPUs åæ€§èƒ½ä¸‹é™ï¼ˆé€šä¿¡ä¸»å¯¼ï¼‰ã€‚
- SHIRO åœ¨ **2â€“128 GPUs** ä¸ŠæŒç»­åŠ é€Ÿï¼Œè¡¨ç°å‡ºä¼˜å¼‚çš„å¯æ‰©å±•æ€§ã€‚
- åœ¨ `GAP-web`, `uk-2002`, `webbase` ç­‰å¤§è§„æ¨¡å›¾ä¸Šæ¥è¿‘ç†æƒ³æ‰©å±•æ•ˆç‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **è”åˆè¡Œåˆ—ç¨€ç–æ„ŸçŸ¥é€šä¿¡èƒ½æ˜¾è‘—å‡å°‘å†—ä½™**ï¼š
   - å•ç»´åº¦ä¼˜åŒ–ä»æœ‰å¤§é‡å†—ä½™ï¼Œè”åˆä¼˜åŒ–å¯é€¼è¿‘ç†è®ºä¸‹é™ã€‚
   - é€šä¿¡é‡å‡å°‘ç›´æ¥è½¬åŒ–ä¸ºæ€§èƒ½æå‡ï¼Œå°¤å…¶åœ¨æç¨€ç–çŸ©é˜µä¸Šã€‚

2. **å±‚æ¬¡åŒ–ç½‘ç»œå¿…é¡»æ˜¾å¼å»ºæ¨¡**ï¼š
   - å¿½è§†ç½‘ç»œå±‚çº§ä¼šå¯¼è‡´è·¨èŠ‚ç‚¹é‡å¤ä¼ è¾“ï¼Œæˆä¸ºæ‰©å±•ç“¶é¢ˆã€‚
   - é€šè¿‡æºç«¯èšåˆä¸ç›®æ ‡ç«¯åˆ†å‘ï¼Œå¯æœ‰æ•ˆå‡å°‘æ…¢é€Ÿé“¾è·¯è´Ÿè½½ã€‚

3. **äº’è¡¥è°ƒåº¦æœ€å¤§åŒ–å¸¦å®½åˆ©ç”¨ç‡**ï¼š
   - è¡ŒåŸºä¸åˆ—åŸºé€šä¿¡å¤©ç„¶äº’è¡¥ï¼ˆä¸€ä¸ªç”¨ç»„å†…é“¾è·¯ï¼Œä¸€ä¸ªç”¨ç»„é—´é“¾è·¯ï¼‰ã€‚
   - é‡å æ‰§è¡Œå¯å®ç°åŒé“¾è·¯å¹¶å‘ï¼Œæå‡æ•´ä½“ååã€‚

4. **SHIRO å…·å¤‡å¼ºæ‰©å±•æ€§**ï¼š
   - åœ¨ 128 H100 GPUs ä¸Šä»ä¿æŒè‰¯å¥½æ€§èƒ½ï¼Œè¿œè¶…ç°æœ‰æ–¹æ³•ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

- **é¢„å¤„ç†å¼€é”€**ï¼šæ„å»ºæµç½‘ç»œå¹¶æ±‚è§£æœ€å¤§æµéœ€ä¸€å®šæ—¶é—´ï¼Œå°½ç®¡å¯ç¦»çº¿å¤ç”¨ã€‚
- **æç«¯ä¸å‡è¡¡é€šä¿¡æ¨¡å¼ä¸‹å¯èƒ½é€€åŒ–**ï¼šå¦‚ `del24`ï¼Œå±‚æ¬¡åŒ–æ‹†åˆ†å¯èƒ½å¯¼è‡´é“¾è·¯åˆ©ç”¨ç‡ä¸‹é™ã€‚
- **å½“å‰å®ç°åŸºäº 1D è¡Œåˆ’åˆ†**ï¼Œè™½å¯æ¨å¹¿ï¼Œä½†æœªç³»ç»ŸéªŒè¯å…¶ä»–åˆ’åˆ†ç­–ç•¥ä¸‹çš„è¡¨ç°ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ”¯æŒåŠ¨æ€ç¨€ç–æ¨¡å¼**ï¼šåœ¨çº¿æ›´æ–°é€šä¿¡è®¡åˆ’ä»¥é€‚åº”å›¾ç»“æ„å˜åŒ–ï¼ˆå¦‚åŠ¨æ€ GNNï¼‰ã€‚
2. **ç»“åˆå›¾åˆ†åŒºæŠ€æœ¯**ï¼šä¸ hypergraph partitioning æˆ– Arrow Decomposition è”åˆä¼˜åŒ–ã€‚
3. **æ‰©å±•è‡³ SpGEMM**ï¼šåº”ç”¨äºç¨€ç–-ç¨€ç–çŸ©é˜µä¹˜æ³•ã€‚
4. **å¼‚æ„ç½‘ç»œé€‚é…**ï¼šæ”¯æŒæ›´å¤æ‚çš„å¤šå±‚çº§ç½‘ç»œæ‹“æ‰‘ï¼ˆå¦‚ CPU-GPU æ··åˆé›†ç¾¤ï¼‰ã€‚

---

> âœ… **æ€»ç»“**ï¼šSHIRO é€šè¿‡**è”åˆä¼˜åŒ–é€šä¿¡ç­–ç•¥ä¸ç½‘ç»œæ‹“æ‰‘**ï¼Œå®ç°äº†åˆ†å¸ƒå¼ SpMM çš„è¿‘æœ€ä¼˜é€šä¿¡æ•ˆç‡ï¼Œåœ¨çœŸå®æ•°æ®é›†å’Œå¤§è§„æ¨¡ GPU é›†ç¾¤ä¸Šå±•ç°å‡ºå“è¶Šæ€§èƒ½ä¸å¯æ‰©å±•æ€§ï¼Œä¸º GNN å’Œ HPC åº”ç”¨æä¾›äº†å¼ºæœ‰åŠ›çš„åº•å±‚æ”¯æ’‘ã€‚

</details>

---

### 4. [Multi-hop Reasoning via Early Knowledge Alignment](https://arxiv.org/abs/2512.20144)

**Authors**: Yuxin Wang, Shicheng Fang, Bo Wang, Qi Luo, Xuanjing Huang, Yining Zheng, Xipeng Qiu  
**Category**: cs.CL  
**Published**: 2025-12-24  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.20144v1  

#### Abstract
Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for Large Language Models (LLMs) to address knowledge-intensive queries requiring domain-specific or up-to-date information. To handle complex multi-hop questions that are challenging for single-step retrieval, iterative RAG app...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Multi-hop Reasoning via Early Knowledge Alignment*

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹ **Retrieval-Augmented Generation (RAG)** ç³»ç»Ÿåœ¨å¤„ç†å¤æ‚å¤šè·³æ¨ç†ï¼ˆmulti-hop reasoningï¼‰ä»»åŠ¡æ—¶å­˜åœ¨çš„â€œ**è®¡åˆ’å¤±è´¥**â€ï¼ˆplanning failureï¼‰é—®é¢˜ã€‚ç°æœ‰è¿­ä»£å¼ RAG æ–¹æ³•ï¼ˆå¦‚ Search-R1, Graph-R1ï¼‰é€šå¸¸åœ¨æœªæ¥è§¦æ£€ç´¢è¯­æ–™åº“çš„æƒ…å†µä¸‹ç›´æ¥å¯åŠ¨æ¨ç†è§„åˆ’ï¼ˆinitial thinkingï¼‰ï¼Œå¯¼è‡´ç”Ÿæˆè¯¯å¯¼æ€§çš„å‡è®¾æˆ–æ— æ•ˆçš„æ£€ç´¢è·¯å¾„ï¼Œä»è€Œå¼•å‘çº§è”é”™è¯¯ï¼ˆcascading errorsï¼‰ï¼Œé™ä½æ•´ä½“æ€§èƒ½ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šEarly Knowledge Alignment (EKA)
ä½œè€…æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ¨¡å—â€”â€”**Early Knowledge Alignment (EKA)**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> åœ¨ LLM å¼€å§‹é¦–æ¬¡æ¨ç†ï¼ˆthinkingï¼‰ä¹‹å‰ï¼Œå…ˆè¿›è¡Œä¸€æ¬¡**åˆå§‹æ£€ç´¢**ï¼ˆearly retrievalï¼‰ï¼Œå°†ç›¸å…³çŸ¥è¯†æ³¨å…¥æç¤ºï¼ˆpromptï¼‰ä¸­ï¼Œä½¿æ¨¡å‹åœ¨å…·å¤‡ä¸Šä¸‹æ–‡æ”¯æ’‘çš„å‰æä¸‹è¿›è¡Œåˆå§‹è§„åˆ’ã€‚

å…·ä½“æµç¨‹å¦‚ä¸‹ï¼š
1. ç»™å®šé—®é¢˜ $ q $ï¼Œé¦–å…ˆé€šè¿‡ retriever ä»çŸ¥è¯†åº“ $ D $ ä¸­æ£€ç´¢ top-k ç›¸å…³æ®µè½ $ P_0 = Retrieve(q, D, k) $ã€‚
2. å°† $ P_0 $ ä½œä¸ºâ€œæ—©æœŸçŸ¥è¯†â€åµŒå…¥åˆ°è¾“å…¥æç¤ºä¸­ã€‚
3. LLM åŸºäºè¯¥çŸ¥è¯†å¼€å§‹ç¬¬ä¸€è½® `<think>` æ¨ç†ï¼Œåç»­æŒ‰æ ‡å‡†è¿­ä»£æµç¨‹æ‰§è¡Œ `<query>` æˆ– `<answer>` åŠ¨ä½œã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- âœ… **æ›´å¼ºçš„æ¨ç†åŸºç¡€**ï¼šé¿å…äº†â€œæ— ä¾æ®çŒœæµ‹â€ï¼Œæå‡äº†åˆå§‹æ¨ç†çš„è´¨é‡ã€‚
- âœ… **å‡å°‘å†—ä½™æ¢ç´¢**ï¼šå¼•å¯¼æ¨¡å‹èšç„¦äºç›¸å…³çŸ¥è¯†å­é›†ï¼Œæå‡ RL è®­ç»ƒä¸­çš„æ¢ç´¢æ•ˆç‡ã€‚
- âœ… **æ— éœ€é¢å¤–è®­ç»ƒ**ï¼šEKA æ˜¯ä¸€ç§å³æ’å³ç”¨ï¼ˆplug-and-playï¼‰çš„æ¨ç†ç­–ç•¥ï¼Œé€‚ç”¨äºä»»ä½•è¿­ä»£ RAG æ¡†æ¶ï¼Œä¸”å¯ä½œä¸º **training-free inference strategy** åº”ç”¨äºå¤§æ¨¡å‹ã€‚
- âœ… **é€šç”¨æ€§å¼º**ï¼šåœ¨ä¸åŒ RL ç®—æ³•ï¼ˆPPO/GRPOï¼‰ã€ä¸åŒæ£€ç´¢æ¶æ„ï¼ˆchunk/graphï¼‰ã€ä¸åŒè§„æ¨¡æ¨¡å‹ä¸Šå‡æœ‰æ•ˆã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–å…­ä¸ªæ ‡å‡† RAG å¤šè·³é—®ç­”æ•°æ®é›†ï¼š
- **2WikiHop**
- **HotpotQA**
- **Musique**
- **Natural Questions (NQ)**
- **PopQA**
- **TriviaQA**

æ­¤å¤–ï¼Œåœ¨ Search-R1 è®¾ç½®ä¸­è¿˜åŠ å…¥äº† **Bamboogle** æ•°æ®é›†ã€‚

### å®éªŒè®¾ç½®
- **ä¸»å¹²æ–¹æ³•**ï¼šåŸºäºå¼ºåŒ–å­¦ä¹ çš„ä¸¤ç§ä¸»æµæ¡†æ¶
  - **Search-R1**ï¼ˆä½¿ç”¨ PPOï¼‰
  - **Graph-R1**ï¼ˆä½¿ç”¨ GRPOï¼‰
- **æ¨¡å‹è§„æ¨¡**ï¼šä¸»è¦ä½¿ç”¨ `Qwen2.5-7B-Instruct` å’Œ `Qwen2.5-14B-Instruct`ï¼Œå¹¶åœ¨é™„å½•ä¸­æµ‹è¯•äº†æ›´å¤§æ¨¡å‹ï¼ˆå¦‚ Qwen3ï¼‰ã€‚
- **æ£€ç´¢å™¨**ï¼š
  - Search-R1ï¼šE5
  - Graph-R1ï¼šåŸºäºè¶…å›¾çš„ bge-large-en-v1.5
- **è®­ç»ƒæ–¹å¼**ï¼šåœ¨éƒ¨åˆ†å®éªŒä¸­å¤ç°å¹¶æ¯”è¾ƒäº† SFTã€R1ã€R1-Searcher ç­‰åŸºçº¿ã€‚

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **EM** | Exact Matchï¼Œä¸¥æ ¼åŒ¹é…å‡†ç¡®ç‡ |
| **F1** | ç”Ÿæˆç­”æ¡ˆä¸çœŸå®ç­”æ¡ˆçš„è¯çº§åˆ« F1 åˆ†æ•° |
| **R-S (Retrieval Similarity)** | æ£€ç´¢åˆ°çš„å†…å®¹ä¸â€œé»„é‡‘ä¸Šä¸‹æ–‡â€çš„è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆcosine similarityï¼‰ï¼Œè¡¡é‡æ£€ç´¢è´¨é‡ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 2 & Table 4ï¼‰

#### åœ¨ Graph-R1 è®¾ç½®ä¸‹çš„å¹³å‡æ€§èƒ½æå‡ï¼ˆQwen2.5-7Bï¼‰ï¼š
| æ–¹æ³• | Avg. EM â†‘ | Avg. F1 â†‘ | R-S â†‘ |
|------|----------|----------|--------|
| Graph-R1 | 48.57 | 57.82 | 60.40 |
| **Graph-R1 + EKA** | **52.08** (+3.51) | **60.65** (+2.83) | **64.90** (+4.50) |

#### åœ¨ Search-R1 è®¾ç½®ä¸‹çš„å¹³å‡æ€§èƒ½æå‡ï¼ˆQwen2.5-7Bï¼‰ï¼š
| æ–¹æ³• | Avg. F1 â†‘ |
|------|----------|
| Search-R1 | 38.50 |
| **Search-R1 + EKA** | **44.80** (+6.30) |

> æ³¨ï¼šåœ¨æŸäº›å˜ä½“ï¼ˆå¦‚ Search-R1-PPOï¼‰ä¸Šæå‡é«˜è¾¾ **+11.64 F1**ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- EKA æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼ŒåŒ…æ‹¬ï¼š
  - é›¶æ ·æœ¬ç”Ÿæˆï¼ˆNaiveGenerationï¼‰
  - æ ‡å‡† RAGï¼ˆStandardRAGï¼‰
  - å›¾ç»“æ„æ–¹æ³•ï¼ˆGraphRAG, LightRAG, HyperGraphRAGï¼‰
  - å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼ˆR1, R1-Searcher, Search-R1ï¼‰
- å³ä½¿æ˜¯å½“å‰ SOTA æ–¹æ³•ï¼ˆå¦‚ Search-R1ï¼‰ï¼ŒåŠ å…¥ EKA åä»èƒ½è·å¾—æ˜¾è‘—å¢ç›Šã€‚

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰ç†µåˆ†æï¼ˆEntropy Analysisï¼‰
- å¦‚ **Figure 3** æ‰€ç¤ºï¼ŒEKA æ˜¾è‘—é™ä½äº† `<think>` å’Œ `<query>` æ­¥éª¤çš„ token ç†µã€‚
- è¡¨æ˜ EKA ä½¿æ¨¡å‹çš„æ¨ç†å’Œæ£€ç´¢è¡Œä¸ºæ›´åŠ ç¡®å®šå’Œé›†ä¸­ï¼Œå‡å°‘äº†æ— æ•ˆæ¢ç´¢ã€‚

#### ï¼ˆ2ï¼‰æ¨ç†æ­¥æ•°ï¼ˆTurnsï¼‰
- å¦‚ **Table 6** æ‰€ç¤ºï¼ŒEKA å¹³å‡å°†æ¨ç†è½®æ¬¡ä» **3.26** ç¼©çŸ­è‡³ **2.22**ã€‚
- æ›´çŸ­çš„æ¨ç†é“¾æ„å‘³ç€æ›´å°‘å™ªå£°ç§¯ç´¯å’Œæ›´é«˜æ•ˆç‡ã€‚

#### ï¼ˆ3ï¼‰æ³›åŒ–èƒ½åŠ›ï¼ˆGeneralizationï¼‰
- åœ¨è·¨æ•°æ®é›†è®­ç»ƒ-æµ‹è¯•åœºæ™¯ä¸‹ï¼ˆOODï¼‰ï¼ŒEKA ä¾ç„¶ä¿æŒç”šè‡³æå‡æ³›åŒ–æ€§èƒ½ï¼ˆè§ Table 7ï¼‰ã€‚
- åœ¨â€œå™ªå£°æ—©æœŸçŸ¥è¯†â€ï¼ˆEKA-wikiï¼‰å’Œâ€œä¸åŒ¹é…æ£€ç´¢å™¨â€ï¼ˆEKA-e5ï¼‰ç­‰é²æ£’æ€§æµ‹è¯•ä¸­ï¼ŒEKA ä»ä¼˜äºåŸºçº¿ï¼ˆTables 8 & 9ï¼‰ï¼Œè¯æ˜å…¶å¯¹æ£€ç´¢è´¨é‡å˜åŒ–å…·æœ‰é²æ£’æ€§ã€‚

#### ï¼ˆ4ï¼‰è®­ç»ƒå…è´¹æœ‰æ•ˆæ€§ï¼ˆTraining-free EKAï¼‰
- å¦‚ **Table 5** æ‰€ç¤ºï¼Œå³ä½¿ä¸å¯¹å¤§æ¨¡å‹ï¼ˆå¦‚ Qwen2.5-32B, Qwen3ï¼‰è¿›è¡Œå¾®è°ƒï¼Œä»…åœ¨æ¨ç†æ—¶å¼•å…¥ EKAï¼Œä¹Ÿèƒ½å¸¦æ¥ä¸€è‡´ä¸”æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚
- ä¾‹å¦‚ï¼Œåœ¨ Qwen3 ä¸Šï¼Œå°½ç®¡åŸæ¨¡å‹è¡¨ç°ä¸ä½³ï¼ŒEKA ä»èƒ½ç¨³å®šæåˆ†ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **æ—©æœŸçŸ¥è¯†å¯¹åˆå§‹è§„åˆ’è‡³å…³é‡è¦**ï¼šç¼ºä¹ä¸Šä¸‹æ–‡æ”¯æ’‘çš„â€œç›²ç›®æ€è€ƒâ€æ˜¯å¤šè·³ RAG æ€§èƒ½ç“¶é¢ˆçš„å…³é”®åŸå› ã€‚
2. âœ… **EKA æ˜¾è‘—æå‡æ€§èƒ½ä¸æ•ˆç‡**ï¼šé€šè¿‡æä¾› early knowledgeï¼ŒEKA æ”¹å–„äº†æ¨ç†èµ·ç‚¹ï¼Œå‡å°‘äº†é”™è¯¯ä¼ æ’­ï¼Œæé«˜äº†æ£€ç´¢ç²¾åº¦å’Œæœ€ç»ˆç­”æ¡ˆå‡†ç¡®æ€§ã€‚
3. âœ… **ä»â€œPlan-firstâ€åˆ°â€œAlign-firstâ€èŒƒå¼è½¬å˜**ï¼šè®ºæ–‡å€¡å¯¼å°† RAG è®¾è®¡é‡å¿ƒä»â€œå…ˆè®¡åˆ’å†æ£€ç´¢â€è½¬å‘â€œå…ˆå¯¹é½å†æ¨ç†â€ã€‚
4. âœ… **ç†µè§†è§’è§£é‡Šæœºåˆ¶**ï¼šEKA é™ä½äº† RL è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¢ç´¢ç†µï¼Œå®ç°äº†æ›´é«˜æ•ˆçš„æ¢ç´¢ç­–ç•¥ï¼ŒåŠ å¿«äº†æ”¶æ•›é€Ÿåº¦ã€‚
5. âœ… **é«˜åº¦é€šç”¨ä¸å¯æ‰©å±•**ï¼šEKA ä¸ä¾èµ–ç‰¹å®šæ¨¡å‹ã€æ£€ç´¢å™¨æˆ–è®­ç»ƒæ–¹å¼ï¼Œæ˜¯ä¸€ç§è½»é‡ã€çµæ´»ã€å¯æ‰©å±•çš„å¢å¼ºæ¨¡å—ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- â— **å°šæœªéªŒè¯äºæå¤æ‚åœºæ™¯**ï¼šå¦‚ Deepresearch ç­‰éœ€è¦æ·±åº¦ç½‘ç»œæœç´¢ã€é•¿æœŸè®°å¿†çš„ä»»åŠ¡ä¸­æ•ˆæœæœªçŸ¥ã€‚
- â— **ä¾èµ–åˆå§‹æ£€ç´¢è´¨é‡**ï¼šè™½ç„¶å¯¹å™ªå£°æœ‰ä¸€å®šé²æ£’æ€§ï¼Œä½†æç«¯ä½è´¨çš„ early retrieval å¯èƒ½å½±å“æ•ˆæœã€‚
- â— **å¯èƒ½å¢åŠ å»¶è¿Ÿ**ï¼šå¤šä¸€æ¬¡åˆå§‹æ£€ç´¢ä¼šç•¥å¾®å¢åŠ å“åº”æ—¶é—´ï¼ˆä½†åœ¨å¤šæ•°åœºæ™¯ä¸‹æ”¶ç›Šè¿œå¤§äºæˆæœ¬ï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ EKA åœ¨æ›´å¤æ‚çš„ agentic workflowsï¼ˆå¦‚è‡ªä¸»ç ”ç©¶ã€ç§‘å­¦å‘ç°ï¼‰ä¸­çš„åº”ç”¨ã€‚
- ç ”ç©¶å¦‚ä½•åŠ¨æ€é€‰æ‹© early knowledge çš„ç²’åº¦ï¼ˆå¦‚ entity vs. passage vs. graph pathï¼‰ã€‚
- ç»“åˆ EKA ä¸å…¶ä»–æ¨ç†ä¼˜åŒ–æŠ€æœ¯ï¼ˆå¦‚ self-reflection, verificationï¼‰æ„å»ºæ›´å¼ºå¤§çš„ RAG ç³»ç»Ÿã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬è®ºæ–‡æå‡ºçš„ **Early Knowledge Alignment (EKA)** é€šè¿‡åœ¨æ¨ç†å‰æ³¨å…¥åˆæ­¥æ£€ç´¢çŸ¥è¯†ï¼Œæœ‰æ•ˆè§£å†³äº†è¿­ä»£ RAG ä¸­å› â€œæ— ä¾æ®åˆå§‹æ€è€ƒâ€å¯¼è‡´çš„è®¡åˆ’å¤±è´¥é—®é¢˜ï¼Œåœ¨å¤šä¸ªæ•°æ®é›†å’Œæ¡†æ¶ä¸Šå®ç°äº†æ˜¾è‘—ä¸”ç¨³å¥çš„æ€§èƒ½æå‡ï¼Œæ˜¯ä¸€ç§ç®€å•ã€é«˜æ•ˆã€æ— éœ€è®­ç»ƒçš„é€šç”¨å¢å¼ºç­–ç•¥ã€‚

</details>

---

### 5. [EdgeFlex-Transformer: Transformer Inference for Edge Devices](https://arxiv.org/abs/2512.19741)

**Authors**: Shoaib Mohammad, Guanqun Song, Ting Zhu  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.19741v1  

#### Abstract
Deploying large-scale transformer models on edge devices presents significant challenges due to strict constraints on memory, compute, and latency. In this work, we propose a lightweight yet effective multi-stage optimization pipeline designed to compress and accelerate Vision Transformers (ViTs) fo...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡ã€ŠEdgeFlex-Transformer: Transformer Inference for Edge Devicesã€‹æ ¸å¿ƒæ€»ç»“**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
Vision Transformers (ViTs) åœ¨è¾¹ç¼˜è®¾å¤‡ï¼ˆå¦‚æ‰‹æœºã€åµŒå…¥å¼ä¼ æ„Ÿå™¨ï¼‰ä¸Šçš„éƒ¨ç½²é¢ä¸´ä¸¥é‡æŒ‘æˆ˜ï¼Œä¸»è¦å—é™äºï¼š
- **å†…å­˜é™åˆ¶**ï¼ˆé€šå¸¸ < 100MBï¼‰
- **è®¡ç®—èµ„æºæœ‰é™**
- **é«˜å»¶è¿Ÿä¸åŠŸè€—**
- ç°æœ‰å‹ç¼©æ–¹æ³•ï¼ˆå¦‚éç»“æ„åŒ–å‰ªæã€ä½æ¯”ç‰¹é‡åŒ–ï¼‰åœ¨ç¡¬ä»¶ä¸Šæ•ˆç‡ä½æˆ–å¯¼è‡´æ˜¾è‘—ç²¾åº¦ä¸‹é™ã€‚

è¯¥è®ºæ–‡æ—¨åœ¨å®ç°**æ— éœ€é‡è®­ç»ƒã€è½»é‡çº§ã€é«˜æ•ˆä¸”é€‚ç”¨äºå¤šç§è¾¹ç¼˜å¹³å°çš„ ViT æ¨ç†ä¼˜åŒ–æ–¹æ¡ˆ**ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯**
ä½œè€…æå‡ºäº† **EdgeFlex-Transformer** â€”â€”ä¸€ä¸ª**å¤šé˜¶æ®µã€æ¨¡å—åŒ–ã€æ— éœ€å¾®è°ƒçš„ä¼˜åŒ–æµæ°´çº¿**ï¼Œç»“åˆä»¥ä¸‹å…³é”®æŠ€æœ¯ï¼š

1. **Activation Profilingï¼ˆæ¿€æ´»åˆ†æï¼‰**  
   - åˆ©ç”¨å‰å‘ Hook æ”¶é›† MLP å±‚çš„æ¿€æ´»ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚å¹³å‡ç»å¯¹æ¿€æ´»å€¼ï¼‰ï¼Œè¯†åˆ«ä½é‡è¦æ€§é€šé“ã€‚

2. **Memory-Aware Structured Pruningï¼ˆå†…å­˜æ„ŸçŸ¥ç»“æ„åŒ–å‰ªæï¼‰**  
   - åŸºäºæ¿€æ´»å¼ºåº¦å¯¹ MLP è¾“å‡ºé€šé“è¿›è¡Œæ’åºï¼Œå‰ªé™¤æœ€ä¸æ´»è·ƒçš„é€šé“ï¼ˆä¾‹å¦‚æœ€ä½ 10%ï¼‰ï¼Œå‡å°‘ä¸­é—´ç‰¹å¾å›¾å†…å­˜å ç”¨ã€‚
   - ç»“æ„åŒ–å‰ªæç¡®ä¿å…¼å®¹ç°ä»£è¾¹ç¼˜åŠ é€Ÿå™¨ï¼ˆé¿å…éç»“æ„ç¨€ç–å¸¦æ¥çš„ç¡¬ä»¶æ‰§è¡Œç“¶é¢ˆï¼‰ã€‚

3. **Selective Mixed-Precision Executionï¼ˆé€‰æ‹©æ€§æ··åˆç²¾åº¦æ‰§è¡Œï¼‰**  
   - å°†éƒ¨åˆ†å­æ¨¡å—ï¼ˆå¦‚ MLP å—ï¼‰è½¬æ¢ä¸º FP16ï¼Œå…¶ä½™ä¿ç•™ FP32 ä»¥ä¿è¯æ•°å€¼ç¨³å®šæ€§ã€‚
   - ä½¿ç”¨ PyTorch çš„ Automatic Mixed Precision (AMP) å®ç°æ— ç¼æ¨ç†ã€‚

4. **Activation-Aware Quantization (AWQ)**  
   - å°†æƒé‡å’Œæ¿€æ´»é‡åŒ–è‡³ INT8ï¼Œåˆ©ç”¨æ¯é€šé“ç¼©æ”¾å› å­ï¼ˆper-channel scalingï¼‰ä¿æŠ¤æ•æ„Ÿé€šé“ã€‚
   - åŸºäºæ¿€æ´»åˆ†å¸ƒåŠ¨æ€è°ƒæ•´é‡åŒ–ç­–ç•¥ï¼Œæœ€å°åŒ–ç²¾åº¦æŸå¤±ã€‚

> âœ… **æ•´ä¸ªæµç¨‹æ— éœ€ä»»ä½• fine-tuning æˆ– retraining**ï¼Œé€‚åˆå¿«é€Ÿé€‚é…ä¸åŒ ViT éª¨å¹²ç½‘ç»œå’Œè¾¹ç¼˜è®¾å¤‡ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹æ³• | ç¼ºé™· | EdgeFlex çš„æ”¹è¿› |
|------|------|----------------|
| **Unstructured Pruning** | å¯¼è‡´ä¸è§„åˆ™ç¨€ç–ï¼Œéš¾ä»¥è¢«ç¡¬ä»¶åŠ é€Ÿ | ä½¿ç”¨**ç»“æ„åŒ–å‰ªæ**ï¼Œç¡¬ä»¶å‹å¥½ |
| **Naive Quantization** | æ˜“é€ æˆç²¾åº¦å¤§å¹…ä¸‹é™ | å¼•å…¥ **AWQ**ï¼ŒåŸºäºæ¿€æ´»æ•æ„Ÿåº¦ä¿æŠ¤å…³é”®é€šé“ |
| **Knowledge Distillation** | éœ€è¦å¤æ‚è®­ç»ƒæµç¨‹ï¼Œæ³›åŒ–æ€§å·® | **å®Œå…¨æ— è®­ç»ƒéœ€æ±‚**ï¼Œå³æ’å³ç”¨ |
| **NAS / AutoML** | æœç´¢æˆæœ¬æé«˜ï¼ˆæ•°ç™¾ GPU å°æ—¶ï¼‰ | **æ— éœ€æ¶æ„æœç´¢**ï¼Œè½»é‡å¯å¤ç”¨ |
| **é€šç”¨æ¨ç†æ¡†æ¶ï¼ˆå¦‚ FlexNNï¼‰** | å¯¹ Transformer å†…å­˜æ¨¡å¼æ”¯æŒä¸ä½³ | é’ˆå¯¹ ViT è®¾è®¡ï¼Œä¼˜åŒ–å†…å­˜è°ƒåº¦ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **CIFAR-10**ï¼šç”¨äºæ ¡å‡†ï¼ˆcalibrationï¼‰å’Œæµ‹è¯•ã€‚
- **æ ¡å‡†é›†**ï¼šä»…ä½¿ç”¨ 32 ä¸ªæ ·æœ¬è¿›è¡Œ activation profilingã€‚
- **æµ‹è¯•é›†**ï¼šå®Œæ•´ 10,000 ä¸ªæµ‹è¯•æ ·æœ¬ç”¨äºè¯„ä¼°æœ€ç»ˆæ€§èƒ½ã€‚

---

### **å®éªŒè®¾ç½®**
- **æ¨¡å‹æ¶æ„**ï¼šViT-Hugeï¼ˆ32 å±‚ï¼Œéšè—ç»´åº¦ 1280ï¼ŒMLP å¤§å° 5120ï¼Œæ€»å‚æ•°çº¦ 6.32 äº¿ï¼‰
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA A100 GPUï¼ˆOhio Supercomputing Center çš„ Ascend é›†ç¾¤ï¼‰ï¼Œå¯ç”¨å†…å­˜å‰–æ
- **æ‰¹å¤§å°ï¼ˆbatch sizeï¼‰**ï¼š32
- **å®ç°å·¥å…·**ï¼šPyTorch + Hugging Face Transformers åº“

---

### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Accuracy (%)** | åˆ†ç±»å‡†ç¡®ç‡ |
| **Average Batch Latency (s)** | å•æ‰¹æ¬¡å¹³å‡æ¨ç†å»¶è¿Ÿ |
| **Total Inference Time (s)** | æ‰€æœ‰ 10k æ ·æœ¬æ€»æ¨ç†æ—¶é—´ |
| **Peak Memory Usage (MB)** | æ¨ç†è¿‡ç¨‹ä¸­å³°å€¼å†…å­˜æ¶ˆè€— |

---

### **åŸºçº¿ä¸å˜ä½“å¯¹æ¯”**
å…±æ¯”è¾ƒå››ç§æ¨¡å‹å˜ä½“ï¼š
| å˜ä½“ | æè¿° |
|------|------|
| **Original FP32** | åŸå§‹æœªä¿®æ”¹çš„ ViT-Huge æ¨¡å‹ |
| **Pruned FP32** | ç»è¿‡ç»“æ„åŒ–å‰ªæåçš„ FP32 æ¨¡å‹ |
| **Pruned + FP16** | å‰ªæåå¯ç”¨æ··åˆç²¾åº¦ï¼ˆFP16ï¼‰ |
| **Pruned + AWQ** | å‰ªæååº”ç”¨ AWQ é‡åŒ–è‡³ INT8 |

> â—æ‰€æœ‰ä¼˜åŒ–å‡**ä¸æ¶‰åŠ fine-tuning**ï¼Œç›´æ¥åº”ç”¨äºé¢„è®­ç»ƒæ¨¡å‹ã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Fig. 3ï¼‰**

| Variant | Accuracy (%) | Avg Batch Latency (s) | Total Time (s) | Peak Memory (MB) |
|--------|---------------|------------------------|----------------|------------------|
| Original FP32 | 8.56 | 0.194 | 25.07 | 2613.45 |
| Pruned FP32 | 7.78 | 0.198 | 25.68 | ~2528 |
| Pruned + FP16 | **11.67** | **0.028** | **4.15** | **1356.10** |
| Pruned + AWQ | 11.28 | 0.199 | 25.79 | **623** |

> æ³¨ï¼šåŸå§‹ ViT-Huge åœ¨ CIFAR-10 ä¸Šæœªç» fine-tuning å‡†ç¡®ç‡è¾ƒä½å±æ­£å¸¸ç°è±¡ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- **å†…å­˜æ–¹é¢**ï¼š
  - Pruned + AWQ å®ç° **>76% çš„å³°å€¼å†…å­˜é™ä½**ï¼ˆä» 2613 â†’ 623 MBï¼‰
  - Pruned + FP16 å®ç° ~48% å†…å­˜ç¼©å‡
- **å»¶è¿Ÿæ–¹é¢**ï¼š
  - Pruned + FP16 è¾¾åˆ° **6.9Ã— åŠ é€Ÿ**ï¼ˆå¹³å‡å»¶è¿Ÿä» 0.194s â†’ 0.028sï¼‰
  - æ€»æ¨ç†æ—¶é—´ä» 25s+ ç¼©çŸ­è‡³ **4.15 ç§’**
- **ç²¾åº¦æ–¹é¢**ï¼š
  - æ‰€æœ‰ä¼˜åŒ–ç‰ˆæœ¬**ä¸ä»…æ²¡æœ‰æ‰ç‚¹ï¼Œåè€Œæå‡å‡†ç¡®ç‡**ï¼ˆå¯èƒ½å› å‰ªæå»é™¤äº†å™ªå£°é€šé“ï¼‰
  - Pruned + FP16 æœ€é«˜è¾¾ **11.67%**ï¼Œä¼˜äºåŸå§‹æ¨¡å‹

---

### **æ¶ˆèå®éªŒåˆ†æï¼ˆéšå«åœ¨ç»“æœä¸­ï¼‰**
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»å„é˜¶æ®µç»“æœå¯å¾—å‡ºï¼š
1. **ä»…å‰ªæ**ï¼ˆPruned FP32ï¼‰ï¼š
   - å†…å­˜ç•¥é™ï¼ˆ~3%ï¼‰ï¼Œå»¶è¿Ÿå‡ ä¹ä¸å˜ï¼Œå‡†ç¡®ç‡è½»å¾®ä¸‹é™ã€‚
   - è¡¨æ˜**å•ç‹¬å‰ªææ•ˆæœæœ‰é™**ã€‚
2. **å‰ªæ + FP16**ï¼š
   - å»¶è¿Ÿéª¤é™ 6.9Ã—ï¼Œå†…å­˜å‡åŠï¼Œå‡†ç¡®ç‡åå‡ã€‚
   - è¯´æ˜**æ··åˆç²¾åº¦æ˜¯åŠ é€Ÿçš„å…³é”®é©±åŠ¨å› ç´ **ã€‚
3. **å‰ªæ + AWQ**ï¼š
   - å†…å­˜é™è‡³ 623MBï¼ˆä»…ä¸ºåŸæ¨¡å‹ 24%ï¼‰ï¼Œé€‚åˆæç«¯èµ„æºå—é™åœºæ™¯ã€‚
   - è™½ç„¶å»¶è¿Ÿæœªæ”¹å–„ï¼ˆä»ä¸º ~0.2s/batchï¼‰ï¼Œä½†**å†…å­˜æ•ˆç‡æœ€ä¼˜**ã€‚

> ğŸ” å‘ç°ï¼š**â€œå‰ªæ + é‡åŒ–â€ æ›´é€‚åˆå†…å­˜å—é™åœºæ™¯ï¼Œâ€œå‰ªæ + FP16â€ æ›´é€‚åˆä½å»¶è¿Ÿéœ€æ±‚åœºæ™¯ã€‚**

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **æ— éœ€ fine-tuning çš„å‹ç¼©æ–¹æ¡ˆå¯è¡Œä¸”æœ‰æ•ˆ**ï¼šé€šè¿‡ activation-aware ç­–ç•¥ï¼Œå¯åœ¨ä¸é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹å®ç°é«˜è´¨é‡å‹ç¼©ã€‚
2. **ç»“æ„åŒ–å‰ªæ + AWQ æ˜¯å†…å­˜å‹ç¼©çš„æœ€ä½³ç»„åˆ**ï¼šPruned + AWQ å®ç° >76% å†…å­˜èŠ‚çœï¼Œé€‚ç”¨äº <1GB å†…å­˜çš„è¾¹ç¼˜è®¾å¤‡ã€‚
3. **æ··åˆç²¾åº¦ï¼ˆFP16ï¼‰å¸¦æ¥æœ€å¤§é€Ÿåº¦æ”¶ç›Š**ï¼šPruned + FP16 å®ç°è¶…è¿‡ 6Ã— æ¨ç†åŠ é€Ÿï¼Œé€‚åˆå®æ—¶åº”ç”¨ï¼ˆå¦‚ AR/è¯­éŸ³è½¬å½•ï¼‰ã€‚
4. **ä¼˜åŒ–é¡ºåºè‡³å…³é‡è¦**ï¼šå…ˆå‰ªæ â†’ å†æ··åˆç²¾åº¦/é‡åŒ–ï¼Œå½¢æˆæ¸è¿›å¼å‹ç¼©ï¼Œé¿å…è¯¯å·®ç´¯ç§¯ã€‚
5. **EdgeFlex å…·å¤‡è‰¯å¥½é€šç”¨æ€§å’Œæ¨¡å—æ€§**ï¼šå¯çµæ´»é›†æˆåˆ°å…¶ä»– ViT æ¶æ„æˆ–æ‰©å±•è‡³ NLP/Multimodal ä»»åŠ¡ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
1. **ä¾èµ– calibration æ•°æ®**ï¼šéœ€è¦å°‘é‡è¾“å…¥æ ·æœ¬æ¥æ”¶é›†æ¿€æ´»ç»Ÿè®¡ï¼Œè‹¥æ•°æ®åˆ†å¸ƒåç§»å¯èƒ½å¯¼è‡´å‰ªæä¸å‡†ã€‚
2. **å½“å‰æœªæ”¯æŒåŠ¨æ€ç¨€ç–æˆ– MoE æ¶æ„**ï¼šæ— æ³•å¤„ç†æ¡ä»¶æ‰§è¡Œè·¯å¾„ï¼ˆå¦‚ Mixture-of-Expertsï¼‰ã€‚
3. **æœªåœ¨çœŸå®è¾¹ç¼˜èŠ¯ç‰‡ä¸ŠéªŒè¯**ï¼šå®éªŒåŸºäº A100 GPUï¼Œå°šæœªåœ¨ç§»åŠ¨ SoCï¼ˆå¦‚ Snapdragonï¼‰æˆ– NPU ä¸Šæµ‹è¯•å®é™…èƒ½æ•ˆã€‚
4. **CIFAR-10 ä¸Šå‡†ç¡®ç‡æœ¬èº«åä½**ï¼šæœª fine-tune çš„ ViT-Huge ä¸é€‚åˆå°æ•°æ®é›†ï¼Œå½±å“ç»“æœè§£é‡ŠåŠ›ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘ï¼ˆä½œè€…æ˜ç¡®æå‡ºï¼‰**
1. **æ‰©å±•è‡³ Mixture-of-Experts (MoE) æ¶æ„**ï¼šç ”ç©¶å¦‚ä½•å¯¹ç¨€ç–æ¿€æ´»ä¸“å®¶å±‚è¿›è¡Œå‰ªæä¸é‡åŒ–ã€‚
2. **Task-Aware Pruning**ï¼šå¼•å…¥ä¸‹æ¸¸ä»»åŠ¡ä¿¡å·æŒ‡å¯¼å‰ªæå†³ç­–ï¼Œæå‡ç‰¹å®šä»»åŠ¡æ€§èƒ½ã€‚
3. **Layer-wise Dynamic Precision Control**ï¼šæŒ‰å±‚åŠ¨æ€é€‰æ‹© FP32/FP16/INT8ï¼Œè¿›ä¸€æ­¥å¹³è¡¡ç²¾åº¦ä¸æ•ˆç‡ã€‚
4. **ä¸å®æ—¶è°ƒåº¦ç³»ç»Ÿé›†æˆ**ï¼šå°† EdgeFlex ä¸è¾¹ç¼˜è¿è¡Œæ—¶ï¼ˆå¦‚ FlexNNï¼‰ç»“åˆï¼Œå®ç°ç«¯åˆ°ç«¯è‡ªé€‚åº”æ¨ç†ã€‚

---

## âœ… æ€»ç»“
**EdgeFlex-Transformer æä¾›äº†ä¸€ä¸ªå®ç”¨ã€é«˜æ•ˆã€æ— éœ€è®­ç»ƒçš„ ViT å‹ç¼©æ¡†æ¶**ï¼Œé€šè¿‡ **activation-aware pruning + mixed precision + AWQ** çš„ååŒä¼˜åŒ–ï¼Œåœ¨ä¿æŒç”šè‡³æå‡ accuracy çš„åŒæ—¶ï¼Œå®ç°äº†ï¼š
- **>76% å†…å­˜å‹ç¼©**
- **>6Ã— æ¨ç†åŠ é€Ÿ**
- å®Œå…¨å… retraining

ä¸ºå¤§è§„æ¨¡ Transformer æ¨¡å‹åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„éƒ¨ç½²æä¾›äº†**ä¸€æ¡åˆ‡å®å¯è¡Œçš„æŠ€æœ¯è·¯å¾„**ï¼Œå…·æœ‰è¾ƒå¼ºçš„å·¥ç¨‹è½åœ°æ½œåŠ›ã€‚

</details>

---

### 6. [MolAct: An Agentic RL Framework for Molecular Editing and Property Optimization](https://arxiv.org/abs/2512.20135)

**Authors**: Zhuo Yang, Yeyun chen, Jiaqing Xie, Ben Gao, Shuaike Shen, Wanhao Liu, Liujia Yang, Beilun Wang, Tianfan Fu, Yuqiang Li  
**Category**: cs.AI  
**Published**: 2025-12-24  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.20135v1  

#### Abstract
Molecular editing and optimization are multi-step problems that require iteratively improving properties while keeping molecules chemically valid and structurally similar. We frame both tasks as sequential, tool-guided decisions and introduce MolAct, an agentic reinforcement learning framework that ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# MolAct: An Agentic RL Framework for Molecular Editing and Property Optimization è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åˆ†å­ç¼–è¾‘ï¼ˆMolecular Editingï¼‰å’Œåˆ†å­ä¼˜åŒ–ï¼ˆMolecular Optimizationï¼‰æ˜¯è¯ç‰©è®¾è®¡ä¸­çš„æ ¸å¿ƒä»»åŠ¡ï¼Œä¼ ç»Ÿæ–¹æ³•é€šå¸¸é‡‡ç”¨å•æ­¥ç”Ÿæˆæˆ–é™æ€æŒ‡ä»¤å¾®è°ƒæ–¹å¼å¤„ç†ï¼Œå­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- ç¼ºä¹å¯¹**å¤šæ­¥å†³ç­–è¿‡ç¨‹**çš„å»ºæ¨¡ï¼›
- æ— æ³•æœ‰æ•ˆåˆ©ç”¨å¤–éƒ¨åŒ–å­¦å·¥å…·ï¼ˆå¦‚æœ‰æ•ˆæ€§æ£€æŸ¥ã€æ€§è´¨é¢„æµ‹ã€ç›¸ä¼¼æ€§è¯„ä¼°ï¼‰è¿›è¡Œåé¦ˆï¼›
- éš¾ä»¥ä¿è¯ç”Ÿæˆåˆ†å­çš„**åŒ–å­¦æœ‰æ•ˆæ€§**å’Œ**ç»“æ„ä¸€è‡´æ€§**ï¼ˆMurcko scaffold ä¿ç•™ï¼‰ï¼›
- åœ¨å¤æ‚ä¼˜åŒ–ç›®æ ‡ä¸‹è¡¨ç°ä¸ç¨³å®šã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
æœ¬æ–‡æå‡º **MolAct** â€”â€” ä¸€ç§åŸºäº **Agentic Reinforcement Learning (RL)** çš„æ¡†æ¶ï¼Œå°†åˆ†å­è®¾è®¡å½¢å¼åŒ–ä¸ºä¸€ä¸ª**å¤šè½®ã€å·¥å…·å¢å¼ºçš„æ™ºèƒ½ä½“å†³ç­–è¿‡ç¨‹**ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **é¦–æ¬¡å°†åˆ†å­è®¾è®¡å»ºæ¨¡ä¸º Agentic RL é—®é¢˜**ï¼šLLM æ™ºèƒ½ä½“é€šè¿‡â€œæ€è€ƒ â†’ è°ƒç”¨å·¥å…· â†’ è§‚å¯Ÿåé¦ˆ â†’ å†æ€è€ƒâ€çš„å¾ªç¯é€æ­¥ä¿®æ”¹åˆ†å­ã€‚
- **ä¸¤é˜¶æ®µè®­ç»ƒèŒƒå¼**ï¼š
  - **Stage 1ï¼ˆMolEditAgentï¼‰**ï¼šé¢„è®­ç»ƒé˜¶æ®µï¼Œå­¦ä¹ åŸºæœ¬ç¼–è¾‘æ“ä½œï¼ˆAdd/Delete/Substituteï¼‰ï¼Œå¼ºè°ƒåŒ–å­¦æœ‰æ•ˆæ€§å’Œç»“æ„ç›¸ä¼¼æ€§ï¼›
  - **Stage 2ï¼ˆMolOptAgentï¼‰**ï¼šç»§ç»­è®­ç»ƒé˜¶æ®µï¼Œåœ¨ Stage 1 åŸºç¡€ä¸Šå­¦ä¹ å±æ€§ä¼˜åŒ–ï¼ˆå¦‚ LogPã€solubilityï¼‰ï¼ŒåŒæ—¶ä¿æŒ scaffold ä¸€è‡´æ€§ã€‚
- **å·¥å…·é›†æˆæœºåˆ¶**ï¼šæ”¯æŒè°ƒç”¨å¤šç§åŒ–å­¦å·¥å…·ï¼ˆvalidity checker, similarity calculator, property oracleï¼‰ï¼Œå¹¶åˆ©ç”¨å…¶åé¦ˆæŒ‡å¯¼åç»­åŠ¨ä½œã€‚
- **Group-Relative Policy Optimization (GRPO)**ï¼šåœ¨å¤šä¸ªå¹¶è¡Œ rollout ä¸Šè¿›è¡Œç›¸å¯¹å¥–åŠ±å½’ä¸€åŒ–ï¼Œæå‡é•¿ç¨‹ä¿¡ç”¨åˆ†é…ç¨³å®šæ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | MolAct çš„ä¼˜åŠ¿ |
|------|----------------|
| **çµæ´»æ€§** | æ”¯æŒå¤šæ­¥äº¤äº’å¼ç¼–è¾‘ï¼Œé€‚åº”å¤šæ ·åŒ–ä»»åŠ¡ï¼›è€Œå¤šæ•° LLM æ–¹æ³•ä¸ºå•æ­¥ç”Ÿæˆ |
| **å¯é æ€§** | æ˜¾å¼å¼•å…¥å·¥å…·éªŒè¯ï¼Œæ˜¾è‘—æé«˜åˆ†å­æœ‰æ•ˆæ€§ï¼ˆ95â€“100%ï¼‰ |
| **å¯è§£é‡Šæ€§** | å†³ç­–è·¯å¾„é€æ˜ï¼Œæ¯ä¸€æ­¥éƒ½æœ‰å·¥å…·åé¦ˆæ”¯æ’‘ |
| **æ€§èƒ½è¡¨ç°** | åœ¨å¤šä¸ªåŸºå‡†ä»»åŠ¡ä¸­è¶…è¶Šå¼ºé—­æºæ¨¡å‹ï¼ˆå¦‚ Claude 3.7ã€Geminiï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä½¿ç”¨ **ChemCoTDatasets (Li et al., 2025)** æ„å»ºè®­ç»ƒæ•°æ®ï¼Œè¯¥æ•°æ®é›†åŒ…å«å¸¦é“¾å¼æ¨ç†æ ‡æ³¨çš„å¤šæ­¥åˆ†å­ä¿®æ”¹æ ·æœ¬ã€‚
- ç§»é™¤åŸå§‹ CoT æ¨ç†æ–‡æœ¬ï¼Œä»…æå–ï¼š
  - è¾“å…¥ï¼šæºåˆ†å­ SMILES + ç¼–è¾‘æŒ‡ä»¤ / ä¼˜åŒ–ç›®æ ‡
  - è¾“å‡ºï¼šç›®æ ‡åˆ†å­ SMILES
- æ‰€æœ‰åˆ†å­ç»è¿‡æ ‡å‡†åŒ–ï¼ˆcanonicalizationï¼‰å’Œæœ‰æ•ˆæ€§æ ¡éªŒã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹å®¶æ—**ï¼š
  - MolEditAgentï¼šç”¨äºåˆ†å­ç¼–è¾‘ä»»åŠ¡ï¼ŒåŸºäº Qwen-2.5-3B å’Œ Qwen-2.5-7Bï¼›
  - MolOptAgentï¼šç”± MolEditAgent åˆå§‹åŒ–åç»§ç»­è®­ç»ƒï¼Œç”¨äºä¼˜åŒ–ä»»åŠ¡ã€‚
- **äº¤äº’æœºåˆ¶**ï¼š
  - æœ€å¤§å›åˆæ•°ï¼ˆturn budgetï¼‰è®¾ä¸º 16ï¼›
  - æ¯ä¸ª prompt å¯åŠ¨ K æ¡å¹¶è¡Œ rolloutï¼Œä½¿ç”¨ GRPO è¿›è¡Œç­–ç•¥æ›´æ–°ï¼›
  - ä»…å¯¹ agent ç”Ÿæˆçš„ token è®¡ç®—æ¢¯åº¦ï¼Œå·¥å…·è¾“å‡ºä½œä¸ºä¸Šä¸‹æ–‡ä¸å‚ä¸åå‘ä¼ æ’­ã€‚
- **å·¥å…·æ¥å£**ï¼š
  - ç¼–è¾‘æ“ä½œï¼šadd/delete/substitute åŠŸèƒ½å›¢ï¼›
  - è¯„ä¼°å·¥å…·ï¼švalidity checkã€Tanimoto similarityã€property oracleï¼ˆLogP, solubility, QED, DRD2, JNK3, GSK3Î²ï¼‰ã€‚

### è¯„ä¼°æŒ‡æ ‡
| ä»»åŠ¡ç±»å‹ | ä¸»è¦æŒ‡æ ‡ |
|--------|---------|
| **åˆ†å­ç¼–è¾‘** | - Pass@1ï¼ˆæ˜¯å¦æ­£ç¡®å®Œæˆç¼–è¾‘ï¼‰<br>- Validityï¼ˆç”Ÿæˆåˆ†å­çš„æœ‰æ•ˆç‡ï¼‰ |
| **åˆ†å­ä¼˜åŒ–** | - â–³ï¼ˆå¹³å‡å±æ€§å¢ç›Šï¼Œæ­£å€¼æ›´å¥½ï¼‰<br>- SR%ï¼ˆSuccess Rateï¼Œå®ç°æ­£å‘æ”¹è¿›çš„æ¯”ä¾‹ï¼‰ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ¶µç›–ä¸¤ç±»ä¸»æµæ¨¡å‹ï¼š
- **W/ Thinking**ï¼šå…·å¤‡â€œæ€ç»´é“¾â€èƒ½åŠ›çš„é—­æºæˆ–å¼€æºæ¨¡å‹ï¼ˆå¦‚ Gemini-2.5-pro-think, Claude3.7-sonnet-thinkï¼‰
- **W/o Thinking**ï¼šæ— æ˜¾å¼æ¨ç†èƒ½åŠ›çš„æ ‡å‡†æŒ‡ä»¤å¾®è°ƒæ¨¡å‹ï¼ˆå¦‚ GPT-4o, Qwen2.5-7B-Instructï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### åˆ†å­ç¼–è¾‘ä»»åŠ¡ï¼ˆMolecular Editingï¼‰

#### å‡†ç¡®ç‡è¡¨ç°ï¼ˆTable 1ï¼‰
| æ¨¡å‹ | Add (%) | Delete (%) | Substitute (%) |
|------|--------|-----------|---------------|
| **MolEditAgent-7B** | **90.0** | **80.0** | **78.3** |
| Gemini-2.5-pro-think | 100.0 | 85.0 | 81.7 |
| Claude3.7-sonnet-think | 85.0 | 80.0 | 83.4 |
| GPT-4o | 80.0 | 80.0 | 65.0 |

- MolEditAgent-7B åœ¨ Add ä»»åŠ¡ä¸­ä»…æ¬¡äºæœ€å¼ºé—­æºæ¨¡å‹ï¼Œåœ¨ Delete å’Œ Sub ä¸Šä¼˜äºå¤§å¤šæ•° W/o Thinking æ¨¡å‹ã€‚
- MolEditAgent-3B è¡¨ç°è‰¯å¥½ï¼ˆAdd: 80.0%, Delete: 70.0%ï¼‰ï¼Œä½†åœ¨ Sub ä»»åŠ¡ä¸Šæ˜æ˜¾ä¸‹é™ï¼ˆ16.7%ï¼‰ï¼Œè¡¨æ˜å¤æ‚æ›¿æ¢éœ€è¦æ›´å¼ºæ¨ç†èƒ½åŠ›ã€‚

#### åŒ–å­¦æœ‰æ•ˆæ€§ï¼ˆTable 2ï¼‰
| æ¨¡å‹ | Add (%) | Delete (%) | Substitute (%) |
|------|--------|-----------|---------------|
| **MolEditAgent-7B** | **100.0** | **95.0** | **98.0** |
| Qwen2.5-7B-Instruct | 75.0 | 70.0 | 65.0 |
| **MolEditAgent-3B** | **95.0** | **80.0** | **71.7** |
| Qwen-2.5-3B-Instruct | 60.0 | 55.0 | 65.0 |

- MolAct æ˜¾è‘—æå‡äº†ç”Ÿæˆåˆ†å­çš„åŒ–å­¦æœ‰æ•ˆæ€§ï¼Œå°¤å…¶åœ¨ 7B æ¨¡å‹ä¸Šæ¥è¿‘å®Œç¾ï¼ˆ95â€“100%ï¼‰ã€‚

---

### åˆ†å­ä¼˜åŒ–ä»»åŠ¡ï¼ˆMolecular Optimizationï¼‰

#### æ€§èƒ½å¯¹æ¯”ï¼ˆTable 3ï¼‰
| æ¨¡å‹ | LogP â–³ (SR%) | Solubility â–³ (SR%) | DRD2 â–³ (SR%) | GSK3Î² â–³ (SR%) |
|------|-------------|--------------------|--------------|----------------|
| **MolOptAgent-7B** | **0.89 (92%)** | **1.42 (84%)** | 0.02 (38%) | **0.04 (36%)** |
| Gemini-2.5-pro-think | -0.28 (81%) | 1.91 (92%) | **0.35 (74%)** | 0.04 (68%) |
| Claude3.7-sonnet-think | 0.41 (81%) | 0.59 (77%) | 0.18 (66%) | 0.01 (57%) |
| DeepSeek-R1 | 0.36 (74%) | 1.48 (97%) | 0.10 (62%) | -0.02 (41%) |

- **LogP ä¼˜åŒ–**ï¼šMolOptAgent-7B å–å¾—æœ€é«˜å¢ç›Šï¼ˆâ–³=0.89ï¼‰å’ŒæˆåŠŸç‡ï¼ˆ92%ï¼‰ï¼Œå¤§å¹…é¢†å…ˆ Claude å’Œ Geminiï¼›
- **Solubility**ï¼šä»…æ¬¡äº Gemini å’Œ DeepSeek-R1ï¼Œä½†ä»å…·ç«äº‰åŠ›ï¼ˆâ–³=1.42, SR%=84%ï¼‰ï¼›
- **ç”Ÿç‰©æ´»æ€§ç›®æ ‡**ï¼šåœ¨ DRD2 å’Œ GSK3Î² ä¸Šå–å¾—æ­£å‘æ”¹è¿›ï¼Œä½†ä»æœ‰æå‡ç©ºé—´ï¼›
- **JNK3 å’Œ QED**ï¼šè¡¨ç°ä¸€èˆ¬ï¼ˆJNK3 â–³=-0.04ï¼‰ï¼Œè¯´æ˜æŸäº›ç‰¹å®šç›®æ ‡éœ€é¢†åŸŸå¢å¼ºã€‚

#### å°æ¨¡å‹è¡¨ç°
- MolOptAgent-3B æˆåŠŸç‡ä»…ä¸º 3â€“12%ï¼Œè¿œä½äº 7B ç‰ˆæœ¬ï¼Œæ˜¾ç¤ºå®¹é‡å¯¹æ‰§è¡Œèƒ½åŠ›è‡³å…³é‡è¦ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ä¸¤é˜¶æ®µè®­ç»ƒ vs å•é˜¶æ®µè®­ç»ƒï¼ˆTable 4ï¼‰
| æ¨¡å‹ | LogP SR% | Solubility SR% | QED SR% | DRD2 SR% |
|------|---------|----------------|--------|----------|
| Qwen-2.5-7B-Instructï¼ˆone-stageï¼‰ | 0% | 0% | 12% | 0% |
| **MolOptAgent-7Bï¼ˆtwo-stageï¼‰** | **92%** | **84%** | **35%** | **38%** |

- **å…³é”®å‘ç°**ï¼šå³ä½¿ä½¿ç”¨ç›¸åŒå·¥å…·å’Œ RL è®­ç»ƒï¼Œ**ç¼ºå°‘ç¼–è¾‘é¢„è®­ç»ƒçš„ä¸€é˜¶æ®µæ–¹æ³•å‡ ä¹å¤±è´¥**ï¼ˆSR% â‰ˆ 0%ï¼‰ï¼Œè¯æ˜ä¸¤é˜¶æ®µè®¾è®¡çš„å…³é”®ä½œç”¨ã€‚
- ç¼–è¾‘é¢„è®­ç»ƒå¸®åŠ©æ¨¡å‹å­¦ä¼šå¦‚ä½•åˆç†è°ƒç”¨å·¥å…·ã€ä½•æ—¶ç»ˆæ­¢ï¼Œä»è€Œå½¢æˆæœ‰æ•ˆçš„ç­–ç•¥æ‰§è¡Œèƒ½åŠ›ã€‚

#### æ¨¡å‹å®¹é‡ä¸å·¥å…·ä½¿ç”¨æ•ˆç‡åˆ†æ
- **å“åº”é•¿åº¦åˆ†æ**ï¼ˆFigures 5 & 6ï¼‰ï¼š
  - 3B æ¨¡å‹åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­å‡ºç°æç«¯å“åº”é•¿åº¦å³°å€¼ï¼ˆé«˜è¾¾ 5,000 tokensï¼‰ï¼Œåæ˜ æ¨ç†å†—ä½™ã€å·¥å…·è°ƒç”¨ä½æ•ˆï¼›
  - 7B æ¨¡å‹å“åº”æ›´çŸ­ä¸”ç¨³å®šï¼Œèƒ½åœ¨æœ‰é™å›åˆå†…é«˜æ•ˆæ‰§è¡Œç­–ç•¥ã€‚
- **ç»“è®º**ï¼šæ›´å¤§çš„æ¨¡å‹ä¸ä»…èƒ½å­¦åˆ°æ›´é«˜å¥–åŠ±ï¼Œè¿˜èƒ½æ›´å¯é åœ°**æ‰§è¡Œç­–ç•¥**ï¼Œä½“ç°â€œexecutabilityâ€é‡è¦æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **å¤šæ­¥ã€å·¥å…·å¢å¼ºçš„å†³ç­–æ¨¡å¼ä¼˜äºå•æ­¥ç”Ÿæˆ**ï¼šæ˜¾å¼å»ºæ¨¡ç¼–è¾‘è¿‡ç¨‹å¹¶é€šè¿‡å·¥å…·åé¦ˆè¿­ä»£ä¿®æ­£ï¼Œæ˜¾è‘—æå‡æœ‰æ•ˆæ€§å’ŒæˆåŠŸç‡ã€‚
2. âœ… **ä¸¤é˜¶æ®µè®­ç»ƒè‡³å…³é‡è¦**ï¼šå…ˆæŒæ¡åŸºç¡€ç¼–è¾‘æŠ€èƒ½ï¼Œå†è¿ç§»åˆ°å±æ€§ä¼˜åŒ–ï¼Œæ˜¯æˆåŠŸçš„å…³é”®ã€‚
3. âœ… **æ¨¡å‹å®¹é‡å½±å“ç­–ç•¥æ‰§è¡ŒåŠ›**ï¼šå°½ç®¡å°æ¨¡å‹ä¹Ÿèƒ½æ‹Ÿåˆå¥–åŠ±ä¿¡å·ï¼Œä½†éš¾ä»¥åœ¨é¢„ç®—å†…é«˜æ•ˆæ‰§è¡Œå·¥å…·åºåˆ—ã€‚
4. âœ… **é«˜æœ‰æ•ˆæ€§æºäºå·¥å…·é—­ç¯åé¦ˆ**ï¼šMolAct å®ç°äº† 95â€“100% çš„åŒ–å­¦æœ‰æ•ˆæ€§ï¼Œè§£å†³äº†ä¼ ç»Ÿç”Ÿæˆæ¨¡å‹å¸¸è§çš„â€œhallucinationâ€é—®é¢˜ã€‚
5. ğŸ“ˆ **MolAct-7B åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¶…è¶Šé—­æº Thinking æ¨¡å‹**ï¼Œå°¤å…¶æ˜¯åœ¨ LogP ä¼˜åŒ–æ–¹é¢è¡¨ç°çªå‡ºã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **å¯¹ç‰¹å®šç›®æ ‡æ³›åŒ–ä¸è¶³**ï¼šå¦‚ JNK3 å’Œ QED ä¼˜åŒ–æ•ˆæœä¸ä½³ï¼Œå¯èƒ½å› ç¼ºä¹ä¸“ç”¨çŸ¥è¯†æˆ–å·¥å…·ï¼›
2. **æœªè€ƒè™‘åˆæˆå¯è¡Œæ€§ï¼ˆsynthetic feasibilityï¼‰**ï¼šç”Ÿæˆçš„åˆ†å­è™½åœ¨è®¡ç®—ä¸Šæœ‰æ•ˆï¼Œä½†æœªå¿…æ˜“äºå®éªŒå®¤åˆæˆï¼›
3. **ä¾èµ–é«˜è´¨é‡å·¥å…·æ¥å£**ï¼šç³»ç»Ÿæ€§èƒ½å—é™äº property oracle å’Œ validity checker çš„å‡†ç¡®æ€§ï¼›
4. **å°æ¨¡å‹æ‰§è¡ŒåŠ›å¼±**ï¼š3B æ¨¡å‹å³ä¾¿æ¥å—ä¸¤é˜¶æ®µè®­ç»ƒï¼Œä»éš¾èƒœä»»å¤æ‚ä»»åŠ¡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **å¼•å…¥ååº”è·¯å¾„çº¦æŸ**ï¼šç»“åˆ retrosynthesis å·¥å…·ï¼Œç¡®ä¿ç”Ÿæˆåˆ†å­å…·æœ‰å¯è¡Œçš„åˆæˆè·¯çº¿ï¼›
2. **å¢å¼ºé”™è¯¯æ¢å¤æœºåˆ¶**ï¼šå½“å·¥å…·è¿”å›å¤±è´¥æ—¶ï¼Œè‡ªåŠ¨è°ƒæ•´ç­–ç•¥è€Œéé™·å…¥æ— æ•ˆå¾ªç¯ï¼›
3. **å¼€å‘é¢†åŸŸå®šåˆ¶åŒ–å·¥å…·é“¾**ï¼šé’ˆå¯¹ç‰¹å®šé¶ç‚¹ï¼ˆå¦‚ JNK3ï¼‰æ„å»ºä¸“ç”¨é¢„æµ‹å™¨æˆ–çŸ¥è¯†åº“ï¼›
4. **æ¢ç´¢æ›´é«˜çº§çš„è¯¾ç¨‹å­¦ä¹ **ï¼šè¶…è¶Šä¸¤é˜¶æ®µï¼Œè®¾è®¡æ¸è¿›å¼ä»»åŠ¡éš¾åº¦è°ƒåº¦ï¼›
5. **æ„å»º executability-aware è¯„ä¼°ä½“ç³»**ï¼šä¸ä»…çœ‹å¥–åŠ±é«˜ä½ï¼Œæ›´è¦è¡¡é‡ç­–ç•¥èƒ½å¦åœ¨é¢„ç®—å†…æˆåŠŸæ‰§è¡Œã€‚

---

> ğŸ”— **é¡¹ç›®èµ„æº**  
> GitHub: [https://github.com/little1d/MolAct](https://github.com/little1d/MolAct)  
> Hugging Face: [https://huggingface.co/collections/little1d/molact](https://huggingface.co/collections/little1d/molact)

</details>

---

### 7. [Field-Space Attention for Structure-Preserving Earth System Transformers](https://arxiv.org/abs/2512.20350)

**Authors**: Maximilian Witte, Johannes Meuer, \'Etienne Pl\'esiat, Christopher Kadow  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.20350v1  

#### Abstract
Accurate and physically consistent modeling of Earth system dynamics requires machine-learning architectures that operate directly on continuous geophysical fields and preserve their underlying geometric structure. Here we introduce Field-Space attention, a mechanism for Earth system Transformers th...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šField-Space Attention for Structure-Preserving Earth System Transformers

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

ä¼ ç»Ÿæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚ Vision Transformer å’Œ U-Netï¼‰åœ¨å¤„ç†åœ°çƒç³»ç»Ÿå»ºæ¨¡ä»»åŠ¡æ—¶å­˜åœ¨ä»¥ä¸‹å…³é”®é—®é¢˜ï¼š

- **æŠ½è±¡åŒ–è¡¨ç¤ºå¯¼è‡´ç‰©ç†ç»“æ„ä¸¢å¤±**ï¼šå¤§å¤šæ•°æ¨¡å‹å°†è¾“å…¥åœºï¼ˆå¦‚æ¸©åº¦ã€é£é€Ÿç­‰ï¼‰æ˜ å°„åˆ°é«˜ç»´**latent space**ä¸­è¿›è¡Œå¤„ç†ï¼Œä¸­é—´çŠ¶æ€ä¸å†æ˜¯å¯è§£é‡Šçš„ç‰©ç†åœºï¼Œç ´åäº†å‡ ä½•å’Œå®ˆæ’ç»“æ„ã€‚
- **ä¼˜åŒ–å›°éš¾ä¸è®­ç»ƒä¸ç¨³å®š**ï¼šç”±äºç¼ºä¹å¼ºå½’çº³åç½®ï¼ˆinductive biasï¼‰ï¼ŒVision Transformers åœ¨å°æ•°æ®æˆ–ä»å¤´è®­ç»ƒæ—¶æ”¶æ•›æ…¢ä¸”æ˜“å‡ºç°æŸå¤±éœ‡è¡ã€‚
- **åˆ†è¾¨ç‡å›ºå®šï¼Œéš¾ä»¥æ‰©å±•**ï¼šlatent space ä¸­çš„ token è¡¨ç¤ºé€šå¸¸ç»‘å®šç‰¹å®šç©ºé—´åˆ†è¾¨ç‡ï¼Œéš¾ä»¥åœ¨è®­ç»ƒåæå‡åˆ†è¾¨ç‡è€Œä¸ä¿®æ”¹æ¶æ„ã€‚
- **ç‰©ç†çº¦æŸéš¾ä»¥åµŒå…¥**ï¼šå®ˆæ’å¾‹ã€å°ºåº¦ä¸€è‡´æ€§ç­‰ç‰©ç†å…ˆéªŒåªèƒ½æ–½åŠ äºè¾“å‡ºç«¯ï¼Œæ— æ³•è´¯ç©¿æ•´ä¸ªç½‘ç»œå†…éƒ¨ã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº†æ¨¡å‹åœ¨ç§‘å­¦å»ºæ¨¡ä¸­çš„å¯é æ€§ã€å¯è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡º **Field-Space Attention** åŠå…¶æ„å»ºçš„ **Field-Space Transformer (FST)** æ¶æ„ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> **ä¸åœ¨ latent space ä¸­æ“ä½œï¼Œè€Œæ˜¯åœ¨ç‰©ç†ç©ºé—´ï¼ˆfield spaceï¼‰ä¸­ç›´æ¥å­¦ä¹ å¯¹è¿ç»­åœ°ç†ç‰©ç†åœºçš„ç»“æ„ä¿æŒå‹å˜å½¢ï¼ˆstructure-preserving deformationï¼‰ã€‚**

#### ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

- âœ… **Field-Space Attention æœºåˆ¶**ï¼š
  - æ³¨æ„åŠ›è®¡ç®—ä¸ä½œç”¨äº learned patch embeddingsï¼Œè€Œæ˜¯ä½œç”¨äºåŸå§‹ç‰©ç†åŸŸä¸Šçš„å¤šå°ºåº¦åœºåˆ†è§£ã€‚
  - æ‰€æœ‰ä¸­é—´çŠ¶æ€å§‹ç»ˆä¸ºçƒé¢ä¸Šçš„è¿ç»­åœºï¼Œå…·æœ‰æ˜ç¡®çš„ç‰©ç†æ„ä¹‰ã€‚

- âœ… **éå­¦ä¹ å‹å¤šå°ºåº¦åˆ†è§£ï¼ˆNon-learned Multi-Scale Decompositionï¼‰**ï¼š
  - åŸºäº HEALPix ç½‘æ ¼æ„å»ºå±‚æ¬¡åŒ–çš„ç²—ç»†ç½‘æ ¼ç»“æ„ï¼ˆzoom levelsï¼‰ã€‚
  - æ¯ä¸€å±‚è¡¨ç¤ºä¸ºâ€œç²—å°ºåº¦å‡å€¼ + ç»†å°ºåº¦æ®‹å·®â€ï¼Œæ®‹å·®å±€éƒ¨å‡å€¼ä¸ºé›¶ï¼Œç¡®ä¿è·¨å°ºåº¦å®ˆæ’ã€‚

- âœ… **ç»“æ„ä¿æŒæ›´æ–°ï¼ˆResidual Update in Field Spaceï¼‰**ï¼š
  - æ¯ä¸ª FSA block è¾“å‡ºä¸€ä¸ªæ®‹å·®æ›´æ–° $\Delta x_n$ï¼Œå¹¶æ‰§è¡Œ $x_{n+1} = x_n + \Delta x_n$ã€‚
  - æ•´ä¸ªè¿‡ç¨‹ä¿æŒåœºçš„å‡ ä½•ç»“æ„å’Œç‰©ç†ä¸€è‡´æ€§ã€‚

- âœ… **è”åˆå¤šå°ºåº¦ tokenization**ï¼š
  - ä¸åŒ zoom level çš„åœºè¢«ç»Ÿä¸€é‡æ’åˆ°å…±äº«çš„ token grid ä¸Šï¼Œå®ç°è·¨å°ºåº¦æ³¨æ„åŠ›äº¤äº’ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **å¯è§£é‡Šæ€§** | ä¸­é—´å±‚è¾“å‡ºæ˜¯çœŸå®çš„ç‰©ç†åœºï¼Œå¯ç”¨äºå¯è§†åŒ–åˆ†æï¼ˆè§ Fig. S1ï¼‰ |
| **ç¨³å®šæ€§ä¸æ”¶æ•›é€Ÿåº¦** | è®­ç»ƒæ›´ç¨³å®šï¼Œæ— æ˜æ˜¾ loss spikeï¼Œæ”¶æ•›æ›´å¿«ï¼ˆè§ Fig. S2ï¼‰ |
| **å‚æ•°æ•ˆç‡** | åœ¨æ˜¾è‘—æ›´å°‘å‚æ•°ä¸‹è¾¾åˆ°æ›´é«˜ç²¾åº¦ï¼ˆå¦‚ 15.5M vs 54.8Mï¼‰ |
| **ç‰©ç†ä¸€è‡´æ€§** | å°ºåº¦é—´å®ˆæ’æœºåˆ¶å†…ç½®äºè¡¨ç¤ºä¸­ï¼Œæ— éœ€åå¤„ç†å¼ºåˆ¶çº¦æŸ |
| **çµæ´»æ€§** | å›ºå®šåˆ†è§£å…è®¸åæœŸå¼•å…¥æ›´é«˜åˆ†è¾¨ç‡ï¼Œæ”¯æŒè¿ç§»ä¸æ‰©å±• |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **ERA5 å¤§æ°”å†åˆ†ææ•°æ®é›†**ï¼ˆECMWFï¼‰
- **ä»»åŠ¡**ï¼šå…¨çƒè¿‘åœ°è¡¨æ¸©åº¦è¶…åˆ†è¾¨ç‡ï¼ˆSuper-Resolution / Downscalingï¼‰
- **æ”¾å¤§å€æ•°**ï¼šÃ—1024ï¼ˆä½åˆ†è¾¨ç‡è¾“å…¥ â†’ é«˜åˆ†è¾¨ç‡è¾“å‡ºï¼‰
- **ç©ºé—´ç½‘æ ¼**ï¼šHEALPix çƒé¢ç¦»æ•£åŒ–ï¼Œæœ€é«˜ zoom level $z=8$ï¼ˆçº¦ 25 km åˆ†è¾¨ç‡ï¼‰

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

| é¡¹ç›® | è®¾ç½® |
|------|------|
| **è®­ç»ƒå‘¨æœŸ** | 100,000 iterations |
| **ç¡¬ä»¶** | 4 Ã— NVIDIA A100 GPU (80GB) |
| **æ··åˆç²¾åº¦** | bf16-mixedï¼ˆè®­ç»ƒï¼‰ï¼Œfull precisionï¼ˆéªŒè¯ï¼‰ |
| **ä¼˜åŒ–å™¨** | AdamW |
| **å­¦ä¹ ç‡** | $2 \times 10^{-4}$ï¼Œcosine è°ƒåº¦ + 2000 æ­¥ warmup |
| **Batch Size** | 16 |
| **Loss Function** | MSEï¼ˆMean Squared Errorï¼‰ |
| **è¯„ä¼°æŒ‡æ ‡** |  
- **RMSE**ï¼ˆRoot Mean Square Errorï¼Œä¸»æŒ‡æ ‡ï¼‰  
- **MAE**ï¼ˆMean Absolute Errorï¼Œæ—¶é—´åºåˆ—ç¨³å®šæ€§ï¼‰  
- **Latency-weighted RMSE**ï¼ˆç”¨äº U-Net å¯¹æ¯”ï¼‰ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| æ¨¡å‹ | æè¿° |
|------|------|
| **Vision Transformer (ViT)** | æ ‡å‡† ViTï¼Œpatch size=1024ï¼ˆå¯¹åº” $z=3$ï¼‰ï¼Œlearned patch embedding |
| **Multi-Scale ViT (MS-ViT)** | ä½¿ç”¨æœ¬æ–‡æå‡ºçš„ multi-scale tokenization çš„ ViT å˜ä½“ï¼ˆç”¨äºæ¶ˆèï¼‰ |
| **Transformer U-Net (Trans-U-Net)** | CNN ç¼–ç å™¨-è§£ç å™¨ + Transformer æ³¨æ„åŠ›æ¨¡å—ï¼Œå…¸å‹æ··åˆæ¶æ„ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 å’Œ Fig. 3ï¼‰**

| æ¨¡å‹ | å‚æ•°é‡ [M] | RMSE [K] |
|------|-----------|----------|
| **FST (ours, best)** | **15.5** | **0.847** âœ… |
| FST (overfitting) | 32.6 | 0.859 |
| ViT | 54.8 | 0.904 |
| MS-ViT | 54.8 | 0.865 |
| U-Net | 99.6 | 1.032 |

> ğŸ“Œ **ç»“è®º**ï¼šä»…ç”¨ **15.5M å‚æ•°** çš„ FST è¶…è¶Šäº†ä½¿ç”¨ **54.8M~99.6M å‚æ•°** çš„æ‰€æœ‰åŸºçº¿æ¨¡å‹ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- ğŸ”¹ **ä¼˜äº ViT å’Œ U-Net**ï¼š
  - RMSE é™ä½ **6.3% ~ 17.9%**
  - æ”¶æ•›é€Ÿåº¦å¿«ï¼Œè®­ç»ƒæ›²çº¿å¹³æ»‘ï¼ˆFig. S2 æ˜¾ç¤º ViT å‡ºç°å‰§çƒˆæ³¢åŠ¨ï¼‰
  - åœ¨ç›¸åŒå‚æ•°è§„æ¨¡ä¸‹ï¼ŒFST æ€§èƒ½è¿œè¶… ViT

- ğŸ”¹ **ä¼˜äº MS-ViT**ï¼š
  - å³ä½¿ MS-ViT ä½¿ç”¨äº†ç›¸åŒçš„ multi-scale tokenizationï¼Œå…¶æ€§èƒ½ä»ä½äº FSTï¼ˆ0.865 vs 0.847ï¼‰
  - è¡¨æ˜ **field-space æ“ä½œæœ¬èº«å¸¦æ¥äº†é¢å¤–å¢ç›Š**

- ğŸ”¹ **å‚æ•°æ•ˆç‡æé«˜**ï¼š
  - æœ€ä¼˜ FSTï¼ˆ15.5Mï¼‰å‚æ•°ä»…ä¸º ViTï¼ˆ54.8Mï¼‰çš„ **28%**ï¼Œå´å®ç°äº†æ›´ä½è¯¯å·®
  - å›¾ 3 æ˜¾ç¤º FST åœ¨æ‰€æœ‰å‚æ•°è§„æ¨¡ä¸‹éƒ½ä¼˜äºåŸºçº¿

---

### **æ¶ˆèå®éªŒç»“æœ**

#### ï¼ˆ1ï¼‰ä¸åŒ zoom level æ•°é‡çš„å½±å“ï¼ˆTable 2ï¼‰

| nz | Z levels | å‚æ•°é‡ [M] | RMSE [K] |
|----|--------|------------|----------|
| 1 | {8} | 3.8 | 1.653 |
| 2 | {3,8} | 3.8 | 0.945 |
| 3 | {3,4,8} | 3.8 | 0.934 |
| 4 | {3,4,5,8} | 3.8 | 0.913 |
| 5 | {3,4,5,6,8} | 4.1 | 0.908 |

> ğŸ“Œ **ç»“è®º**ï¼šå•å°ºåº¦ï¼ˆnz=1ï¼‰ä¸¥é‡å¤±è´¥ï¼›åŠ å…¥å¤šå°ºåº¦åæ€§èƒ½å¤§å¹…æå‡ï¼Œä¸”éšå°ºåº¦å¢åŠ é€æ¸é¥±å’Œã€‚

#### ï¼ˆ2ï¼‰multi-scale tokenization çš„ç‹¬ç«‹ä½œç”¨

- å°†æœ¬æ–‡çš„ multi-scale tokenization åº”ç”¨äºæ ‡å‡† ViT å¾—åˆ° **MS-ViT**
- ç»“æœæ˜¾ç¤ºï¼šMS-ViT æ¯”æ™®é€š ViT æ›´ç¨³å®šã€å‡†ç¡®
- è¯´æ˜ **multi-scale åˆ†è§£æœ¬èº«æœ‰åŠ©äºä¼˜åŒ–å’Œè¡¨è¾¾èƒ½åŠ›**

#### ï¼ˆ3ï¼‰single-scale æé™æƒ…å†µéªŒè¯

- å½“ $n_z=1$ æ—¶ï¼ŒFST é€€åŒ–ä¸ºå †å çš„ ViT å±‚
- å®éªŒè¡¨æ˜è¯¥é…ç½®æ— æ³•æœ‰æ•ˆæ”¶æ•›ï¼ˆFig. S3ï¼‰
- è¿›ä¸€æ­¥è¯æ˜ **å¤šå°ºåº¦ç»“æ„ + field-space æ“ä½œ** æ˜¯æˆåŠŸçš„å…³é”®

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **Field-Space æ“ä½œä¼˜äº Latent-Space æŠ½è±¡**ï¼š
   - ç›´æ¥åœ¨ç‰©ç†åœºç©ºé—´ä¸­å­¦ä¹ å˜å½¢ï¼Œèƒ½æ›´å¥½åœ°ä¿ç•™å‡ ä½•ç»“æ„å’Œç‰©ç†ä¸€è‡´æ€§ã€‚
   - ä¸­é—´çŠ¶æ€å¯è§£é‡Šï¼Œä¾¿äºè¯Šæ–­å’ŒåµŒå…¥ç§‘å­¦çº¦æŸã€‚

2. âœ… **å¤šå°ºåº¦åˆ†è§£æ˜¯å…³é”®å½’çº³åç½®**ï¼š
   - å›ºå®šçš„ã€åŸºäº HEALPix çš„ hierarchical decomposition æä¾›äº†å¤©ç„¶çš„å°ºåº¦åˆ†ç¦»æœºåˆ¶ã€‚
   - é›¶å‡å€¼æ®‹å·®è®¾è®¡å®ç°äº†è·¨å°ºåº¦å®ˆæ’ï¼Œå¢å¼ºäº†æ³›åŒ–èƒ½åŠ›ã€‚

3. âœ… **æ›´é«˜çš„å‚æ•°æ•ˆç‡ä¸è®­ç»ƒç¨³å®šæ€§**ï¼š
   - FST åœ¨æ›´å°æ¨¡å‹è§„æ¨¡ä¸‹å®ç°æ›´ä¼˜æ€§èƒ½ï¼Œé€‚åˆèµ„æºå—é™åœºæ™¯ã€‚
   - è®­ç»ƒè¿‡ç¨‹å¹³ç¨³ï¼Œé€‚åˆå¤§è§„æ¨¡ç§‘å­¦æ¨¡æ‹Ÿé›†æˆã€‚

4. âœ… **ä¸ç»å…¸æ•°å€¼æ–¹æ³•æœ‰æ·±åˆ»è”ç³»**ï¼š
   - ä¸ multigridã€finite-volumeã€LES ç­‰æ–¹æ³•å…±äº«è®¾è®¡ç†å¿µï¼ˆrestriction/prolongationã€subgrid modelingï¼‰ã€‚
   - æœ‰æœ›æˆä¸ºè¿æ¥ ML ä¸ä¼ ç»Ÿæ•°å€¼å»ºæ¨¡çš„æ¡¥æ¢ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

- âš ï¸ **å½“å‰ä»…éªŒè¯äºå•ä¸€ä»»åŠ¡**ï¼šå®éªŒé›†ä¸­åœ¨æ¸©åº¦è¶…åˆ†è¾¨ç‡ï¼Œå°šæœªå¹¿æ³›æµ‹è¯•äºå…¶ä»–å˜é‡ï¼ˆå¦‚é™æ°´ã€é£åœºï¼‰æˆ–å¤šä»»åŠ¡è”åˆå»ºæ¨¡ã€‚
- âš ï¸ **é«˜åˆ†è¾¨ç‡ä¸‹çš„å‚æ•°å¢é•¿é—®é¢˜**ï¼š
  - å½“å‰ attention åœ¨ coarse token grid ä¸Šæ“ä½œï¼Œä½†åœ¨æé«˜åˆ†è¾¨ç‡ä¸‹ dense projection å±‚å¯èƒ½å¯¼è‡´å‚æ•°çˆ†ç‚¸ã€‚
  - æ–‡ä¸­å»ºè®®å¯é€šè¿‡å±€éƒ¨æ³¨æ„åŠ›ï¼ˆlocal attentionï¼‰æˆ–æ®‹å·®å‹ç¼©ç¼“è§£ã€‚
- âš ï¸ **å°šæœªæ¢ç´¢å››ç»´æ—¶ç©ºå»ºæ¨¡**ï¼šè™½ç„¶æ–‡ä¸­æåˆ°å¯æ‰©å±•è‡³æ—¶ç©ºæ•°æ®ï¼Œä½†æœªå®é™…å®ç°ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

- ğŸ”® **æ„å»º Earth System Foundation Models**ï¼š
  - åˆ©ç”¨ FST ä½œä¸ºåŸºç¡€æ¨¡å—ï¼Œå‘å±•æ”¯æŒå¤šå˜é‡ã€å¤šæ¨¡æ€ã€æ—¶ç©ºé¢„æµ‹çš„é€šç”¨åœ°çƒç³»ç»Ÿæ¨¡å‹ã€‚
- ğŸ”® **ç»“åˆç”Ÿæˆå¼å»ºæ¨¡ï¼ˆå¦‚ Diffusion Modelsï¼‰**ï¼š
  - FST çš„é€æ­¥ refine ç‰¹æ€§ç±»ä¼¼ denoising diffusionï¼Œé€‚åˆç”¨äºæ°”å€™ç”Ÿæˆä»»åŠ¡ã€‚
- ğŸ”® **å¼•å…¥è‡ªé€‚åº” patch size æˆ–ç¨€ç– attention**ï¼š
  - å¦‚ Swin Transformer é£æ ¼çš„ shifted window attentionï¼Œä»¥åº”å¯¹åƒç±³çº§è¶…é«˜åˆ†è¾¨ç‡ã€‚
- ğŸ”® **é¢„è®­ç»ƒ-å¾®è°ƒèŒƒå¼æ¢ç´¢**ï¼š
  - åˆ©ç”¨éå­¦ä¹ åˆ†è§£ï¼Œå¯åœ¨é¢„è®­ç»ƒåæ’å…¥æ›´é«˜ zoom levelï¼Œå®ç°åˆ†è¾¨ç‡è¿ç§»ã€‚

---

## æ€»ç»“

> **Field-Space Transformer æå‡ºäº†ä¸€ç§å…¨æ–°çš„â€œä»¥åœºä¸ºä¸­å¿ƒâ€ï¼ˆfield-centricï¼‰å»ºæ¨¡èŒƒå¼**ï¼Œé€šè¿‡åœ¨ç‰©ç†ç©ºé—´è€Œé latent space ä¸­æ‰§è¡Œ attentionï¼Œå®ç°äº†**é«˜æ€§èƒ½ã€é«˜å¯è§£é‡Šæ€§ã€é«˜ç‰©ç†ä¸€è‡´æ€§çš„åœ°çƒç³»ç»Ÿå»ºæ¨¡**ã€‚å®ƒä¸ä»…åœ¨æ¸©åº¦è¶…åˆ†è¾¨ç‡ä»»åŠ¡ä¸Šè¶…è¶Šä¸»æµæ¶æ„ï¼Œæ›´ä¸ºä¸‹ä¸€ä»£ç§‘å­¦æœºå™¨å­¦ä¹ æä¾›äº†åšå®çš„åŸºç¡€ç»„ä»¶ã€‚

</details>

---

### 8. [Adaptive Financial Sentiment Analysis for NIFTY 50 via Instruction-Tuned LLMs , RAG and Reinforcement Learning Approaches](https://arxiv.org/abs/2512.20082)

**Authors**: Chaithra, Kamesh Kadimisetty, Biju R Mohan  
**Category**: cs.AI  
**Published**: 2025-12-24  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.20082v1  

#### Abstract
Financial sentiment analysis plays a crucial role in informing investment decisions, assessing market risk, and predicting stock price trends. Existing works in financial sentiment analysis have not considered the impact of stock prices or market feedback on sentiment analysis. In this paper, we pro...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAdaptive Financial Sentiment Analysis for NIFTY 50 via Instruction-Tuned LLMs, RAG and Reinforcement Learning Approaches

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿé‡‘èæƒ…æ„Ÿåˆ†ææ¨¡å‹å­˜åœ¨ä»¥ä¸‹å±€é™ï¼š
- **ç¼ºä¹å¸‚åœºåé¦ˆæœºåˆ¶**ï¼šå¤§å¤šæ•°æ¨¡å‹ä»…åŸºäºæ–‡æœ¬è¿›è¡Œé¢„æµ‹ï¼Œæœªè€ƒè™‘å®é™…è‚¡ç¥¨ä»·æ ¼å˜åŠ¨å¯¹æƒ…æ„Ÿåˆ¤æ–­çš„å½±å“ã€‚
- **ä¸Šä¸‹æ–‡ä¸è¶³**ï¼šæ–°é—»æ ‡é¢˜é€šå¸¸ç®€çŸ­ä¸”ç¼ºä¹èƒŒæ™¯ä¿¡æ¯ï¼Œå¯¼è‡´LLMsåœ¨ç†è§£æ—¶å®¹æ˜“å‡ºé”™ã€‚
- **é™æ€ä¿¡æ¯æºæƒé‡**ï¼šç°æœ‰æ–¹æ³•å¯¹ä¸åŒæ–°é—»æ¥æºé‡‡ç”¨å›ºå®šæƒé‡ï¼Œæ— æ³•åŠ¨æ€é€‚åº”å¸‚åœºå˜åŒ–ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§**è‡ªé€‚åº”é‡‘èæƒ…æ„Ÿåˆ†ææ¡†æ¶**ï¼Œç»“åˆ **Instruction-Tuned LLMsã€Retrieval-Augmented Generation (RAG)** å’Œ **Reinforcement Learning (PPO)**ï¼Œå®ç°å¸‚åœºæ„ŸçŸ¥çš„æƒ…æ„Ÿåˆ†ç±»ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

1. **Instruction-Tuned LLaMA 3.2 3B æ¨¡å‹å¾®è°ƒ**
   - åœ¨ SentiFin æ•°æ®é›†ä¸Šè¿›è¡ŒæŒ‡ä»¤å¾®è°ƒï¼Œä½¿ LLM æ›´å¥½åœ°ç†è§£å°åº¦è‚¡å¸‚è¯­å¢ƒä¸‹çš„é‡‘èæƒ…æ„Ÿã€‚

2. **åŠ¨æ€å¤šæº RAG ä¸Šä¸‹æ–‡å¢å¼º**
   - æ„å»ºä¸€ä¸ªåŸºäº cosine similarity çš„ RAG ç³»ç»Ÿï¼Œä»å¤šä¸ªå¯ä¿¡è´¢ç»åª’ä½“ä¸­æ£€ç´¢ç›¸å…³å†å²æ–°é—»ä½œä¸ºä¸Šä¸‹æ–‡ã€‚
   - å¼•å…¥**åŠ æƒç›¸ä¼¼åº¦è¯„åˆ†**ï¼Œç»“åˆæ–°é—»æ¥æºçš„å¯é æ€§æƒé‡ï¼Œæå‡ä¸Šä¸‹æ–‡è´¨é‡ã€‚

3. **å¸‚åœºåé¦ˆé©±åŠ¨çš„æºå¯ä¿¡åº¦æ›´æ–°æœºåˆ¶**
   - è®¾è®¡ä¸€ä¸ªåé¦ˆæ¨¡å—ï¼Œå°†æ¨¡å‹é¢„æµ‹æƒ…æ„Ÿä¸æ¬¡æ—¥è‚¡ä»·èµ°åŠ¿å¯¹æ¯”ã€‚
   - è‹¥é¢„æµ‹ä¸å®é™…å›æŠ¥ä¸€è‡´ï¼Œåˆ™å¢åŠ è¯¥æ–°é—»æºçš„æƒé‡ï¼›å¦åˆ™é™ä½æƒé‡ï¼ˆä½¿ç”¨æ¢¯åº¦å¼æ›´æ–°è§„åˆ™ï¼‰ã€‚

4. **åŸºäº PPO çš„å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–ç­–ç•¥**
   - å°†æºæƒé‡è°ƒæ•´å»ºæ¨¡ä¸º RL ä»»åŠ¡ï¼Œä½¿ç”¨ Proximal Policy Optimization (PPO) å­¦ä¹ é•¿æœŸæœ€ä¼˜çš„æºé€‰æ‹©ç­–ç•¥ã€‚
   - ç›¸æ¯”ç›´æ¥åé¦ˆæ›´æ–°æ›´ç¨³å®šï¼Œå…·å¤‡è·¨æ—¶é—´æ³›åŒ–èƒ½åŠ›ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| å¯¹æ¯”ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | æœ¬è®ºæ–‡æ–¹æ³• |
|--------|---------|-----------|
| ä¸Šä¸‹æ–‡è·å– | å•ä¸€æ¥æºæˆ–æ— ä¸Šä¸‹æ–‡ | å¤šæºåŠ¨æ€æ£€ç´¢ï¼ˆRAGï¼‰ |
| æ¥æºå¯ä¿¡åº¦ | é™æ€è®¾å®šæˆ–å¿½ç•¥ | åŠ¨æ€è°ƒæ•´ï¼ˆåé¦ˆ + PPOï¼‰ |
| å¸‚åœºå¯¹é½ | æ— æ˜¾å¼å¯¹é½æœºåˆ¶ | æ˜¾å¼åˆ©ç”¨ stock return è¿›è¡Œåé¦ˆ |
| æ³›åŒ–èƒ½åŠ› | å›ºå®šç­–ç•¥ | å¯éšæ—¶é—´æ¼”è¿›çš„å­¦ä¹ å‹ç­–ç•¥ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šç³»ç»Ÿä¸ä»…èƒ½æé«˜åˆ†ç±»å‡†ç¡®ç‡ï¼Œè¿˜èƒ½â€œå­¦ä¼šâ€ä¾èµ–é‚£äº›çœŸæ­£å½±å“å¸‚åœºçš„é«˜è´¨é‡ä¿¡æ¯æºï¼Œå¢å¼ºäº†æ¨¡å‹çš„å¸‚åœºæ•æ„Ÿæ€§å’Œé²æ£’æ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†

| æ•°æ®é›† | æè¿° |
|-------|------|
| **SentiFin Dataset** | ç”¨äº instruction tuning çš„è®­ç»ƒé›†ï¼ŒåŒ…å« 10,572 æ¡å°åº¦é‡‘èå¸‚åœºæ–°é—»æ ‡é¢˜ï¼Œä¸‰ç±»æ ‡ç­¾ï¼ˆpositive / neutral / negativeï¼‰ï¼ŒæŒ‰ 80:20 åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†ã€‚ |
| **NIFTY 50 æ–°é—»æ•°æ®é›†ï¼ˆè‡ªå»ºï¼‰** | æ”¶é›† 2024â€“2025 å¹´é—´ 8,000 æ¡ NIFTY 50 æˆåˆ†è‚¡ç›¸å…³æ–°é—»ï¼Œæ¥è‡ª Yahoo Financeã€MoneyControl ç­‰ä¸»æµå¹³å°ã€‚ç”¨äº RAG æ£€ç´¢å’Œæµ‹è¯•ã€‚ |
| **æµ‹è¯•é›†çœŸå®æ ‡ç­¾ç”Ÿæˆæ–¹å¼** | åŸºäºæ¬¡æ—¥æ”¶ç›Šç‡ç›¸å¯¹äº 30 æ—¥æ»šåŠ¨å‡å€¼å’Œæ ‡å‡†å·®å®šä¹‰ï¼š<br>- æ­£å‘ï¼šreturn > mean + std<br>- è´Ÿå‘ï¼šreturn < mean â€“ std<br>- ä¸­æ€§ï¼šå…¶ä½™æƒ…å†µ |

### âš™ï¸ å®éªŒè®¾ç½®

- **åŸºç¡€æ¨¡å‹**ï¼š`unsloth/Llama-3.2-3B-Instruct`ï¼Œä½¿ç”¨ QLoRA è¿›è¡Œé«˜æ•ˆå¾®è°ƒã€‚
- **RAG è®¾ç½®**ï¼š
  - ä½¿ç”¨ `all-MiniLM-L6-v2` ç¼–ç å¥å­å¹¶è®¡ç®— cosine similarityã€‚
  - æ£€ç´¢çª—å£ï¼šç›®æ ‡æ—¥æœŸå‰å 3 å¤©å†…çš„æ–°é—»ã€‚
  - Top-k æ£€ç´¢ + åŠ æƒæ’åºï¼ˆsource weight Ã— similarityï¼‰ã€‚
- **åé¦ˆæœºåˆ¶**ï¼š
  - å®šä¹‰ Â±0.5% ä¸ºä¸­æ€§åŒºé—´ï¼Œé¿å…è½»å¾®æ³¢åŠ¨å¹²æ‰°æƒé‡æ›´æ–°ã€‚
  - æƒé‡æ›´æ–°å…¬å¼ï¼š`W_new = clamp(W_old Â± Î±)`ï¼Œå…¶ä¸­ Î± = 1e-4ã€‚
- **PPO è®¾ç½®**ï¼š
  - çŠ¶æ€ï¼šå½“å‰ source weights + æŸ¥è¯¢ç‰¹å¾
  - åŠ¨ä½œï¼šè¾“å‡ºæ–°çš„ normalized source weight å‘é‡
  - å¥–åŠ±å‡½æ•°ï¼šé¢„æµ‹æ­£ç¡® +1ï¼Œé”™è¯¯ -1ï¼ˆå¯å¸¦ä¸­æ€§åŒºå‰ªè£ï¼‰
  - ä½¿ç”¨ Hugging Face TRL åº“å®ç° PPO è®­ç»ƒ

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡

- **Accuracy**ï¼šæ•´ä½“é¢„æµ‹å‡†ç¡®ç‡
- **Weighted F1-Score**ï¼šè€ƒè™‘ç±»åˆ«ä¸å¹³è¡¡çš„ç»¼åˆæŒ‡æ ‡
- **å¯¹æ¯”é…ç½®**ï¼š
  1. Fine-Tuned LLaMAï¼ˆæ— ä¸Šä¸‹æ–‡ï¼‰
  2. RAG + é™æ€æƒé‡ï¼ˆcosine similarityï¼‰
  3. RAG + å¸‚åœºåé¦ˆæ›´æ–°æƒé‡ï¼ˆWOC / cosineï¼‰
  4. RAG + PPO ä¼˜åŒ–æƒé‡
  5. åŠ å…¥å‰3å¤©ä»·æ ¼æè¿°ä½œä¸ºé¢å¤–ä¸Šä¸‹æ–‡ï¼ˆPrice Contextï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 4ï¼‰

| æ¨¡å‹å˜ä½“ | Accuracy | Weighted F1 |
|--------|----------|-------------|
| Fine-Tuned LLaMA 3.2 | 0.5520 | 0.5375 |
| RAG + Without Market Feedback | 0.6094 | 0.5722 |
| RAG + With Market Feedback (WOC) | **0.6153** | **0.5746** |
| RAG + PPO Optimized Weights | 0.6109 | 0.5733 |
| RAG + Price Context (WOC) | **0.6650** | 0.5674 |

> ğŸ’¡ æ³¨ï¼šåŠ å…¥ price context æ˜¾è‘—æå‡ accuracyï¼Œä½† F1 ä¸‹é™ â†’ æ¨¡å‹åå‘é¢„æµ‹ majority classï¼ˆneutralï¼‰ï¼Œå­˜åœ¨åå·®ã€‚

### ğŸ” ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”

| åŸºçº¿æ¨¡å‹ | Accuracy | F1 |
|--------|----------|-----|
| FinBERT | 0.4852 | 0.5027 |
| RoBERTa | 0.5800 | 0.5551 |
| **æœ¬æ–‡æœ€ä½³ï¼ˆRAG+WOCï¼‰** | **0.6153** | **0.5746** |

âœ… ç»“æœè¡¨æ˜ï¼šæœ¬æ–‡æ–¹æ³•æ˜¾è‘—ä¼˜äºé€šç”¨åŠé¢†åŸŸé¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚ FinBERTï¼‰ï¼Œè¯´æ˜**å¤šæºä¸Šä¸‹æ–‡ + åŠ¨æ€åé¦ˆæœºåˆ¶**çš„æœ‰æ•ˆæ€§ã€‚

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

- **ä»…ç”¨ LLaMA å¾®è°ƒ**ï¼šè¡¨ç°æœ€å¼±ï¼ˆAcc=0.5520ï¼‰ï¼Œè¯´æ˜ç¼ºä¹ä¸Šä¸‹æ–‡é™åˆ¶äº†æ€§èƒ½ã€‚
- **å¼•å…¥ RAGï¼ˆé™æ€æƒé‡ï¼‰**ï¼šAcc æå‡è‡³ 0.6094ï¼ŒéªŒè¯äº†å¤–éƒ¨ä¸Šä¸‹æ–‡çš„é‡è¦æ€§ã€‚
- **åŠ å…¥å¸‚åœºåé¦ˆï¼ˆWOCï¼‰**ï¼šè¿›ä¸€æ­¥æå‡åˆ° 0.6153ï¼Œè¯æ˜åŠ¨æ€æƒé‡èƒ½å¢å¼ºå¸‚åœºå¯¹é½ã€‚
- **PPO æ›¿ä»£åé¦ˆæ›´æ–°**ï¼šæ€§èƒ½ç•¥ä½ä½†æ›´ç¨³å®šï¼Œé€‚åˆé•¿æœŸéƒ¨ç½²ã€‚
- **åŠ å…¥ä»·æ ¼ä¸Šä¸‹æ–‡**ï¼šAcc è¾¾ 0.6650ï¼Œä½† F1 æœªæ”¹å–„ â†’ è¡¨æ˜ accuracy æå‡æºäºç±»åˆ«åç§»ï¼ŒéçœŸæ­£è¯­ä¹‰ç†è§£å¢å¼ºã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **Instruction tuning + RAG æ˜¯æœ‰æ•ˆç»„åˆ**  
   åœ¨é‡‘èé¢†åŸŸï¼Œå•çº¯ä¾èµ– LLM çš„ zero/few-shot èƒ½åŠ›ä¸è¶³ï¼Œéœ€é€šè¿‡ domain-specific å¾®è°ƒ + å¤–éƒ¨ä¸Šä¸‹æ–‡è¡¥å……æ‰èƒ½å‘æŒ¥æ½œåŠ›ã€‚

2. **å¸‚åœºåé¦ˆæ˜¾è‘—æå‡æ¨¡å‹å¯¹é½èƒ½åŠ›**  
   å°† stock return ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œå¯è®©æ¨¡å‹â€œæ„ŸçŸ¥â€å¸‚åœºååº”ï¼Œä»è€Œç­›é€‰æ›´æœ‰ä»·å€¼çš„ä¿¡æ¯æºã€‚

3. **PPO æä¾›æ›´ç¨³å¥çš„æƒé‡å­¦ä¹ æœºåˆ¶**  
   è™½ç„¶ç›´æ¥åé¦ˆæ›´æ–°ç®€å•æœ‰æ•ˆï¼Œä½†æ˜“å—çŸ­æœŸå™ªå£°å½±å“ï¼›PPO èƒ½å­¦ä¹ æ›´å…·æ³›åŒ–æ€§çš„ç­–ç•¥ï¼Œåœ¨æœªçŸ¥è‚¡ç¥¨æˆ–æ—¶é—´æ®µè¡¨ç°æ›´å¥½ã€‚

4. **Source Credibility å¯è¢«æ•°æ®é©±åŠ¨å­¦ä¹ **  
   å®éªŒæ˜¾ç¤ºï¼Œåˆå§‹é«˜æƒé‡åª’ä½“ï¼ˆå¦‚ Business Standardï¼‰æœ€ç»ˆè¢« PPO èµ‹äºˆé›¶æƒé‡ï¼Œè€Œ Moneycontrolã€Zee Business æˆä¸ºä¸»è¦ä¿¡æº â†’ è¯´æ˜â€œæƒå¨â‰ æœ‰ç”¨â€ï¼Œåº”ä»¥å®è¯æ•ˆæœä¸ºå‡†ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

- **é«˜åº¦ä¾èµ–å¤šæºæ–°é—»æ•°æ®**ï¼šè‹¥æŸäº›å…¬å¸æ–°é—»ç¨€ç–ï¼ŒRAG æ•ˆæœå—é™ã€‚
- **ä»·æ ¼ä¸Šä¸‹æ–‡æœªèƒ½æ”¹å–„ F1**ï¼šåŠ å…¥å†å²ä»·æ ¼æè¿°è™½æå‡ accuracyï¼Œä½†åŠ å‰§ç±»åˆ«ä¸å¹³è¡¡ï¼Œæœªè§£å†³ minority classï¼ˆpositive/negativeï¼‰è¯†åˆ«éš¾é¢˜ã€‚
- **æ ‡ç­¾åŸºäºä»·æ ¼å˜åŠ¨ï¼Œå¯èƒ½å­˜åœ¨å› æœæ··æ·†**ï¼šå¹¶éæ‰€æœ‰ä»·æ ¼æ³¢åŠ¨éƒ½ç”±æ–°é—»å¼•èµ·ï¼ŒåŸºæœ¬é¢æˆ–å…¶ä»–å®è§‚å› ç´ ä¹Ÿå¯èƒ½ä¸»å¯¼ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **èåˆåŸºæœ¬é¢æŒ‡æ ‡**ï¼ˆfundamental indicatorsï¼‰å¦‚ PE ratioã€EPSã€è¡Œä¸šè¶‹åŠ¿ç­‰ï¼Œå‡å°‘çº¯æƒ…ç»ªè¯¯åˆ¤ã€‚
2. **å¼•å…¥åŒè¡Œè‚¡ç¥¨ï¼ˆpeer stocksï¼‰ä¿¡æ¯**ï¼šåˆ©ç”¨åŒè¡Œä¸šä¼ä¸šçš„è”åŠ¨æ•ˆåº”è¾…åŠ©åˆ¤æ–­ã€‚
3. **æ¢ç´¢å¤šæ¨¡æ€è¾“å…¥**ï¼šæ•´åˆå›¾è¡¨ã€è´¢æŠ¥æ•°å­—ã€ç®¡ç†å±‚è¯­æ°”ç­‰éæ–‡æœ¬ä¿¡å·ã€‚
4. **æ‰©å±•è‡³å…¶ä»–å¸‚åœº**ï¼šéªŒè¯æ¡†æ¶åœ¨æ¬§ç¾ã€æ–°å…´å¸‚åœºçš„æ™®é€‚æ€§ã€‚
5. **åœ¨çº¿å­¦ä¹ æœºåˆ¶è®¾è®¡**ï¼šæ”¯æŒå®æ—¶å¢é‡æ›´æ–° source weights å’Œ LLM æ¨ç†ç­–ç•¥ã€‚

---

## æ€»ç»“

ğŸ“Œ æœ¬æ–‡æå‡ºäº†ä¸€ç§**å¸‚åœºæ„ŸçŸ¥ã€åé¦ˆé©±åŠ¨ã€å¯è‡ªé€‚åº”æ¼”åŒ–çš„é‡‘èæƒ…æ„Ÿåˆ†ææ¡†æ¶**ï¼Œé€šè¿‡ **Instruction-Tuned LLM + RAG + PPO** çš„ä¸‰é‡æ¶æ„ï¼Œåœ¨ NIFTY 50 æ•°æ®ä¸Šå®ç°äº†ä¼˜äºä¼ ç»Ÿæ–¹æ³•çš„æ€§èƒ½ã€‚å®ƒä¸ä»…æå‡äº†åˆ†ç±»ç²¾åº¦ï¼Œæ›´é‡è¦çš„æ˜¯å»ºç«‹äº†â€œæ¨¡å‹é¢„æµ‹â€”å¸‚åœºåé¦ˆâ€”ç­–ç•¥ä¼˜åŒ–â€çš„é—­ç¯ç³»ç»Ÿï¼Œä¸ºæ„å»ºæ™ºèƒ½æŠ•ç ”å·¥å…·æä¾›äº†å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 9. [HGAN-SDEs: Learning Neural Stochastic Differential Equations with Hermite-Guided Adversarial Training](https://arxiv.org/abs/2512.20272)

**Authors**: Yuanjian Xu, Yuan Shuai, Jianing Hao, Guang Zhang  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.20272v1  

#### Abstract
Neural Stochastic Differential Equations (Neural SDEs) provide a principled framework for modeling continuous-time stochastic processes and have been widely adopted in fields ranging from physics to finance. Recent advances suggest that Generative Adversarial Networks (GANs) offer a promising soluti...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# HGAN-SDEs: Learning Neural Stochastic Differential Equations with Hermite-Guided Adversarial Training â€”â€” è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
- **Neural SDEs çš„è®­ç»ƒéš¾é¢˜**ï¼šNeural Stochastic Differential Equations (Neural SDEs) è™½ç„¶èƒ½æœ‰æ•ˆå»ºæ¨¡è¿ç»­æ—¶é—´éšæœºè¿‡ç¨‹ï¼Œä½†ç”±äºå…¶è·¯å¾„åˆ†å¸ƒå¤æ‚ä¸”ä¼¼ç„¶å‡½æ•°éš¾ä»¥è®¡ç®—ï¼Œä¼ ç»ŸåŸºäºä¼¼ç„¶çš„æ–¹æ³•ä¸é€‚ç”¨ã€‚
- **ç°æœ‰ GAN æ–¹æ³•çš„ç“¶é¢ˆ**ï¼šå…ˆå‰ç ”ç©¶é‡‡ç”¨åŸºäº Neural Controlled Differential Equations (CDEs) çš„åˆ¤åˆ«å™¨è¿›è¡Œå¯¹æŠ—è®­ç»ƒï¼Œè™½å…·å¤‡å»ºæ¨¡æ—¶åºåŠ¨æ€çš„èƒ½åŠ›ï¼Œä½†å­˜åœ¨ï¼š
  - é«˜è®¡ç®—å¼€é”€
  - å¯¹æŠ—è®­ç»ƒä¸ç¨³å®š
  - æ‰©å±•æ€§å·®

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šHGAN-SDEs
ä½œè€…æå‡º **HGAN-SDEs**ï¼Œä¸€ç§åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰çš„æ–°æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š
- **ä½¿ç”¨ Neural Hermite Functions æ„é€ åˆ¤åˆ«å™¨**ï¼š
  - åˆ©ç”¨ Hermite å‡½æ•°ä½œä¸ºæ­£äº¤åŸºæ¥è¿‘ä¼¼ SDE çš„è½¬ç§»å¯†åº¦ï¼ˆtransition densityï¼‰
  - å°†åˆ¤åˆ«ä»»åŠ¡è½¬åŒ–ä¸ºå¯¹è·¯å¾„çº§åŠ¨æ€çš„æ¦‚ç‡åŒ¹é…é—®é¢˜
- **ç»“åˆ Neural SDE ä½œä¸ºç”Ÿæˆå™¨**ï¼š
  - ç”Ÿæˆå™¨ä¸ºæ ‡å‡†çš„ Neural SDE ç»“æ„ï¼Œä»å™ªå£° $ v \sim \mathcal{N}(0, I) $ æ˜ å°„åˆ°è½¨è¿¹ $ x(t) $
  - åˆ¤åˆ«å™¨é€šè¿‡ Hermite å±•å¼€è¯„ä¼°ç”Ÿæˆè½¨è¿¹æ˜¯å¦ç¬¦åˆçœŸå®æ•°æ®ç”Ÿæˆè¿‡ç¨‹ï¼ˆDGPï¼‰

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **è¡¨è¾¾èƒ½åŠ›** | Hermite å‡½æ•°æ„æˆå®Œå¤‡æ­£äº¤åŸºï¼ˆcomplete orthonormal basisï¼‰ï¼Œå…·æœ‰é€šç”¨é€¼è¿‘æ€§è´¨ï¼ˆuniversal approximationï¼‰ï¼Œå¯é€¼è¿‘ä»»æ„å¹³æ–¹å¯ç§¯å¯†åº¦å‡½æ•° |
| **ç¨³å®šæ€§æå‡** | æ­£äº¤æ€§å¸¦æ¥æ•°å€¼ç¨³å®šæ€§å’Œä¼˜åŒ–é²æ£’æ€§ï¼Œç¼“è§£ GAN è®­ç»ƒä¸­çš„æ¨¡å¼å´©æºƒå’Œæ¢¯åº¦çˆ†ç‚¸ |
| **æ•ˆç‡æ›´é«˜** | ç›¸æ¯” CDE-based åˆ¤åˆ«å™¨ï¼ŒHermite åˆ¤åˆ«å™¨å‚æ•°æ›´å°‘ã€å‰å‘ä¼ æ’­æ›´å¿«ï¼Œæ˜¾è‘—é™ä½è®­ç»ƒæ—¶é—´å’Œèµ„æºæ¶ˆè€— |
| **ç†è®ºä¿éšœå¼º** | æä¾›äº† Hermite å±•å¼€æ”¶æ•›æ€§çš„ç†è®ºè¯æ˜ï¼ˆTheorem 2ï¼‰ä»¥åŠåˆ¤åˆ«å™¨åˆ¤åˆ«åŠ›çš„æ•°å­¦ä¾æ®ï¼ˆTheorem 3ï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†

#### åˆæˆæ•°æ®é›†ï¼ˆSimulation Datasetsï¼‰
éµå¾ª Yacine Ait-Sahalia [30] è®¾è®¡å››ç±»ç»å…¸ SDE æ¨¡å‹ï¼š
| åç§° | SDE å½¢å¼ | åº”ç”¨èƒŒæ™¯ |
|------|--------|---------|
| **GBM** (Geometric Brownian Motion) | $ dX_t = \mu dt + \sigma dW_t $ | è‚¡ä»·å»ºæ¨¡ |
| **OU** (Ornstein-Uhlenbeck) | $ dX_t = \kappa(\alpha - X_t)dt + \sigma dW_t $ | å‡å€¼å›å½’è¿‡ç¨‹ |
| **CIR** (Cox-Ingersoll-Ross) | $ dX_t = \kappa(\theta - X_t)dt + \sigma\sqrt{X_t}dW_t $ | åˆ©ç‡/æ³¢åŠ¨ç‡å»ºæ¨¡ |
| **Polynomial Drift** | å¤šé¡¹å¼æ¼‚ç§»é¡¹ + éçº¿æ€§æ‰©æ•£ | å¤æ‚éçº¿æ€§ç³»ç»Ÿ |

æ¯ç»„æ•°æ®åŒ…å« 20,000 è®­ç»ƒæ ·æœ¬ + 6,000 æµ‹è¯•æ ·æœ¬ï¼Œè¾“å…¥ä¸ºå‰ 100 æ—¶é—´æ­¥ï¼Œé¢„æµ‹å 50 æ­¥ã€‚

#### çœŸå®ä¸–ç•Œæ•°æ®é›†
| åç§° | æè¿° |
|------|------|
| **Stock-AAL / Stock-ADBE** | 2017â€“2018 å¹´äº”åˆ†é¢‘è‚¡ç¥¨ä»·æ ¼ï¼ˆçº¦ 4.3 ä¸‡æ¡ï¼‰ï¼Œå«ç¼ºå¤±å€¼ï¼Œä½“ç°é‡‘èå¸‚åœºçš„éšæœºæ³¢åŠ¨ç‰¹æ€§ |
| **Traffic** | åŒ—äº¬å¸‚ 2022 å¹´äº¤é€šæµé‡è®°å½•ï¼ˆ21,600 æ¡ï¼‰ï¼Œäº”åˆ†é’Ÿç²’åº¦ï¼Œå‘¨æœŸæ€§å¼ºã€æ— ç¼ºå¤± |

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
ä½¿ç”¨å››ä¸ªäº’è¡¥æŒ‡æ ‡è¡¡é‡æ¨¡å‹æ€§èƒ½ï¼š
| æŒ‡æ ‡ | å…¨ç§° | å«ä¹‰ |
|------|-----|------|
| **MISE** | Mean Integrated Squared Error | è¡¡é‡æ•´ä½“è·¯å¾„æ‹Ÿåˆç²¾åº¦ï¼ˆè¶Šä½è¶Šå¥½ï¼‰ |
| **TD** | Tail Difference | è¯„ä¼°å°¾éƒ¨ï¼ˆ>5% åˆ†ä½æ•°ï¼‰ä¿çœŸåº¦ï¼Œåæ˜ æç«¯äº‹ä»¶å»ºæ¨¡èƒ½åŠ› |
| **MSE** | Mean Squared Error | ç‚¹å¯¹ç‚¹è¯¯å·®ï¼Œå…³æ³¨å±€éƒ¨å‡†ç¡®æ€§ |
| **MMD** | Maximum Mean Discrepancy | è¡¡é‡ç”Ÿæˆè½¨è¿¹ä¸çœŸå®è½¨è¿¹ä¹‹é—´çš„åˆ†å¸ƒå·®å¼‚ï¼ˆè¶Šå°è¶Šå¥½ï¼‰ |

---

### âš–ï¸ åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ¶µç›–ä¸»æµæ—¶é—´åºåˆ—ä¸ SDE å»ºæ¨¡èŒƒå¼ï¼š
| ç±»åˆ« | æ¨¡å‹ |
|------|------|
| **çº¿æ€§æ¨¡å‹** | DLinear |
| **å·ç§¯æ¨¡å‹** | MICN, TimesNet |
| **æ³¨æ„åŠ›æœºåˆ¶** | Transformer, Informer, Autoformer |
| **RNN æ¨¡å‹** | SegRNN |
| **çŠ¶æ€ç©ºé—´æ¨¡å‹** | Mamba |
| **SDE-based æ¨¡å‹** | Latent-SDEs, GAN-SDEs (CDE-based) |

æ‰€æœ‰æ¨¡å‹å…±äº«ç›¸åŒçš„ Neural SDE ç”Ÿæˆå™¨ç»“æ„ä»¥ç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½è¡¨ç°ï¼ˆè§ Table 1 & Table 3ï¼‰

#### åœ¨åˆæˆæ•°æ®ä¸Šçš„ç»“æœï¼ˆTable 1ï¼‰
| æ¨¡å‹ | GBM-MISE â†“ | OU-TD â†“ | CIR-MMD â†“ | PolyDrift-MSE â†“ |
|------|------------|----------|-----------|----------------|
| DLinear | 6.00 | 9.09 | 0.31 | 0.08 |
| Transformer | 0.74 | 0.70 | 1.44 | 0.02 |
| Latent-SDEs | 0.44 | 10.00 | 0.93 | 0.01 |
| GAN-SDEs (CDE) | 0.38 | 10.00 | 0.88 | 0.01 |
| **HGAN-SDEs** | **0.17** âœ… | **0.33** âœ… | **0.02** âœ… | **0.01** âœ… |

> âœ… **HGAN-SDEs åœ¨æ‰€æœ‰åˆæˆä»»åŠ¡ä¸Šå‡å–å¾—æœ€ä¼˜æˆ–æ¬¡ä¼˜ç»“æœï¼Œå°¤å…¶åœ¨å°¾éƒ¨å»ºæ¨¡ï¼ˆTDï¼‰å’Œåˆ†å¸ƒä¸€è‡´æ€§ï¼ˆMMDï¼‰æ–¹é¢å¤§å¹…é¢†å…ˆ**

#### åœ¨çœŸå®æ•°æ®ä¸Šçš„ç»“æœï¼ˆTable 3ï¼‰
| æ¨¡å‹ | Stock-AAL-MISE â†“ | Stock-ADBE-MSE â†“ | Traffic-MMD â†“ |
|------|------------------|------------------|---------------|
| Transformer | 59.80 | 4.86eâ»Â² | 1.00 |
| Latent-SDEs | 35.52 | 0.35eâ»Â² | 0.95 |
| GAN-SDEs | 38.00 | 0.38eâ»Â² | 0.97 |
| **HGAN-SDEs** | **2.89** âœ… | **0.08eâ»Â²** âœ… | **0.02** âœ… |

> âœ… **åœ¨é‡‘èå’Œäº¤é€šåœºæ™¯ä¸‹ï¼ŒHGAN-SDEs æ˜¾è‘—ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œå°¤å…¶æ˜¯åœ¨é«˜å™ªå£°ã€éå¹³ç¨³çš„é‡‘èå¸‚åœºä¸­è¡¨ç°å‡ºæå¼ºé²æ£’æ€§**

---

### ğŸ”¬ æ¶ˆèå®éªŒä¸è¿›ä¸€æ­¥æ¢ç´¢

#### ï¼ˆ1ï¼‰Hermite å‡½æ•°é¡¹æ•°çš„å½±å“ï¼ˆFigure 2ï¼‰
- å½“ Hermite é¡¹æ•°ä» 1 å¢åŠ åˆ° 3ï½4 æ—¶ï¼ŒMISE å¿«é€Ÿä¸‹é™ï¼›
- è¶…è¿‡ 4 é¡¹åæ€§èƒ½è¶‹äºé¥±å’Œç”šè‡³è½»å¾®ä¸‹é™ï¼›
- **ç»“è®º**ï¼šä»…éœ€ 3â€“4 ä¸ª Hermite é¡¹å³å¯å®ç°é«˜æ•ˆä¸”ç¨³å®šçš„å»ºæ¨¡ï¼Œæ— éœ€é«˜é˜¶å±•å¼€ã€‚

#### ï¼ˆ2ï¼‰è®¡ç®—æ•ˆç‡å¯¹æ¯”ï¼ˆTable 4ï¼‰
| æ¨¡å‹ | GPU-hours | MISE â†“ |
|------|-----------|--------|
| LSTM åˆ¤åˆ«å™¨ | 6.5 | 1.12 |
| MLP åˆ¤åˆ«å™¨ | 4.8 | 0.95 |
| GAN-SDEs (CDE) | 10.0 | 0.11 |
| **HGAN-SDEs (Hermite)** | **1.2** âœ… | **0.04** âœ… |

> âœ… **HGAN-SDEs ä¸ä»…æ€§èƒ½æœ€ä½³ï¼Œè€Œä¸”è®­ç»ƒæˆæœ¬æœ€ä½ï¼Œä»…ä¸º CDE æ–¹æ³•çš„ 1/8**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Hermite å‡½æ•°æ˜¯å»ºæ¨¡ SDE è·¯å¾„åˆ†å¸ƒçš„ç†æƒ³å·¥å…·**ï¼š
   - å…¶æ­£äº¤æ€§å’Œå®Œå¤‡æ€§ä½¿å¾—å¯†åº¦ä¼°è®¡ç¨³å®šä¸”é«˜æ•ˆ
   - å¯è§£æåœ°å…³è” Fokker-Planck æ–¹ç¨‹ä¸ç¨³æ€è§£
2. **HGAN-SDEs å®ç°äº†ç²¾åº¦ä¸æ•ˆç‡çš„åŒé‡çªç ´**ï¼š
   - åœ¨å¤šç§ SDE åŠ¨æ€ç³»ç»Ÿä¸­è¾¾åˆ° SOTA æ€§èƒ½
   - æ”¶æ•›é€Ÿåº¦å¿«ã€èµ„æºæ¶ˆè€—ä½ï¼Œé€‚åˆå¤§è§„æ¨¡éƒ¨ç½²
3. **å¯¹æŠ—è®­ç»ƒç¨³å®šæ€§æ˜¾è‘—å¢å¼º**ï¼š
   - ç›¸æ¯” CDE-based GAN-SDEs æ›´å°‘å‡ºç°è®­ç»ƒå´©æºƒ
   - å³ä½¿åœ¨é«˜åº¦éšæœºçš„çœŸå®é‡‘èæ•°æ®ä¸­ä¹Ÿèƒ½ä¿æŒç¨³å¥è¾“å‡º

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–å¹³ç¨³å‡è®¾**ï¼šå½“å‰ Hermite å±•å¼€ä¸»è¦é’ˆå¯¹ç¨³æ€ï¼ˆstationaryï¼‰è¿‡æ¸¡å¯†åº¦æ¨å¯¼ï¼Œåœ¨å¿«é€Ÿå˜åŒ–æˆ–éå¹³ç¨³ç³»ç»Ÿä¸­å¯èƒ½éœ€è¦æ‰©å±•
- **å›ºå®šåŸºå‡½æ•°ç»“æ„**ï¼šè™½ç„¶ Hermite æ˜¯é€šç”¨åŸºåº•ï¼Œä½†åœ¨ç‰¹å®šé¢†åŸŸï¼ˆå¦‚è·³è·ƒæ‰©æ•£è¿‡ç¨‹ï¼‰å¯èƒ½ä¸å¦‚è‡ªé€‚åº”åŸºå‡½æ•°çµæ´»
- **ä»…é€‚ç”¨äºä¸€ç»´æˆ–ä½ç»´ç³»ç»Ÿ**ï¼šé«˜ç»´ SDE ä¸­ Hermite åŸºçš„æ•°é‡å‘ˆæŒ‡æ•°å¢é•¿ï¼Œé¢ä¸´â€œç»´åº¦ç¾éš¾â€

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ¨å¹¿è‡³å¤šç»´ SDE ç³»ç»Ÿ**ï¼šè®¾è®¡å¼ é‡åŒ–æˆ–ç¨€ç–åŒ–çš„å¤šå˜é‡ Hermite å±•å¼€
2. **å¼•å…¥å¯å­¦ä¹ åŸºå‡½æ•°**ï¼šå°† Hermite å‚æ•°ä¹Ÿçº³å…¥ç«¯åˆ°ç«¯è®­ç»ƒï¼Œæå‡é€‚åº”æ€§
3. **èåˆç‰©ç†å…ˆéªŒ**ï¼šç»“åˆé¢†åŸŸçŸ¥è¯†ï¼ˆå¦‚å¸‚åœºå¾®è§‚ç»“æ„ï¼‰æ„å»ºçº¦æŸå‹ Hermite æ‰©å±•
4. **åº”ç”¨äºæ›´å¤šå®é™…åœºæ™¯**ï¼šå¦‚é«˜é¢‘äº¤æ˜“å»ºæ¨¡ã€æ°”å€™æ¨¡æ‹Ÿã€ç”Ÿç‰©åŠ¨åŠ›å­¦ç­‰

---

## âœ… æ€»ç»“
**HGAN-SDEs** æ˜¯ä¸€ä¸ªå…¼å…·ç†è®ºä¸¥è°¨æ€§ä¸å·¥ç¨‹å®ç”¨æ€§çš„æ–°å‹ GAN æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥ **Neural Hermite Functions** ä½œä¸ºåˆ¤åˆ«å™¨ï¼ŒæˆåŠŸè§£å†³äº† Neural SDEs åœ¨å¯¹æŠ—è®­ç»ƒä¸­çš„ç¨³å®šæ€§ä¸æ•ˆç‡ç“¶é¢ˆã€‚å®éªŒè¡¨æ˜è¯¥æ–¹æ³•åœ¨åˆæˆä¸çœŸå®æ•°æ®ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰ SOTA æ¨¡å‹ï¼Œå°¤å…¶åœ¨é‡‘èç­‰é«˜å™ªå£°ã€å¼ºéšæœºç¯å¢ƒä¸­å±•ç°å‡ºå“è¶Šçš„å»ºæ¨¡èƒ½åŠ›å’Œé²æ£’æ€§ï¼Œä¸ºè¿ç»­æ—¶é—´éšæœºç³»ç»Ÿçš„æ·±åº¦å­¦ä¹ å»ºæ¨¡æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 10. [Scaling Reinforcement Learning for Content Moderation with Large Language Models](https://arxiv.org/abs/2512.20061)

**Authors**: Hamed Firooz, Rui Liu, Yuchen Lu, Zhenyu Hou, Fangzhou Xiong, Xiaoyang Zhang, Changshu Jian, Zhicheng Zhu, Jiayuan Ma, Jacob Tao, Chaitali Gupta, Xiaochang Peng, Shike Mei, Hang Cui, Yang Qin, Shuo Tang, Jason Gaedtke, Arpit Mittal  
**Category**: cs.AI  
**Published**: 2025-12-24  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.20061v1  

#### Abstract
Content moderation at scale remains one of the most pressing challenges in today's digital ecosystem, where billions of user- and AI-generated artifacts must be continuously evaluated for policy violations. Although recent advances in large language models (LLMs) have demonstrated strong potential f...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Scaling Reinforcement Learning for Content Moderation with Large Language Models*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡èšç„¦äº**å¤§è§„æ¨¡å†…å®¹å®¡æ ¸ï¼ˆcontent moderationï¼‰ä¸­çš„æ ¸å¿ƒæŒ‘æˆ˜**ï¼šåœ¨æ ‡ç­¾ç¨€ç–ã€æ”¿ç­–å®šä¹‰åŠ¨æ€å˜åŒ–ã€ä¸”éœ€è¦å¤æ‚æ¨ç†çš„ç°å®åœºæ™¯ä¸­ï¼Œå¦‚ä½•é«˜æ•ˆè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä»¥å®ç°ä¸“å®¶çº§å‡†ç¡®åº¦ã€‚ä¼ ç»Ÿæ–¹æ³•å¦‚ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å—é™äºæ ‡æ³¨æˆæœ¬é«˜ã€æ³›åŒ–èƒ½åŠ›å¼±ï¼Œéš¾ä»¥åº”å¯¹ç»†å¾®è¯­ä¹‰åˆ¤æ–­å’Œå¤šæ¡ä»¶ç­–ç•¥é€»è¾‘ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…ç³»ç»Ÿæ€§åœ°æ¢ç´¢äº†**å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning, RLï¼‰åœ¨å·¥ä¸šçº§å†…å®¹å®¡æ ¸ä¸­çš„å¯æ‰©å±•æ€§**ï¼Œæå‡ºäº†ä¸€å¥—å®Œæ•´çš„RLè®­ç»ƒæ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **å¤šç»´åº¦å¥–åŠ±å¡‘é€ ï¼ˆReward Shapingï¼‰**ï¼šç»“åˆå››ç§å¥–åŠ±ä¿¡å·æ„å»ºå¤åˆç›®æ ‡å‡½æ•°ï¼š
  - `R_acc`ï¼šæœ€ç»ˆé¢„æµ‹å‡†ç¡®æ€§ï¼ˆverifiable rewardï¼‰
  - `R_fmt`ï¼šè¾“å‡ºæ ¼å¼ä¸€è‡´æ€§
  - `R_len`ï¼šé¼“åŠ±åˆç†æ¨ç†é•¿åº¦ï¼Œé˜²æ­¢â€œé•¿åº¦åç¼©â€
  - `R_rub`ï¼šåŸºäºè¯„åˆ†æ ‡å‡†ï¼ˆrubric-basedï¼‰çš„LLM-as-judgeå¥–åŠ±ï¼Œè¯„ä¼°æ¨ç†é“¾çš„è´¨é‡ï¼ˆå¦‚äº‹å®æ€§ã€å¿ å®åº¦ï¼‰

- **å¯¹æŠ—RLå¸¸è§å¤±è´¥æ¨¡å¼çš„æœ‰æ•ˆç­–ç•¥**ï¼š
  - ä½¿ç”¨**è’™ç‰¹å¡æ´›é‡‡æ ·ï¼ˆMonte-Carlo samplingï¼‰** ç¼“è§£åŒå³°æ¦‚ç‡åˆ†å¸ƒé—®é¢˜ï¼Œæå‡ç½®ä¿¡åº¦æ ¡å‡†ã€‚
  - å¼•å…¥**åæ€æç¤ºï¼ˆReflection-aided Promptingï¼‰**ï¼Œè®©æ¨¡å‹å…ˆç”Ÿæˆåˆæ­¥åˆ¤æ–­ï¼Œå†é€šè¿‡å­æ ‡ç­¾è¿›è¡Œè¯æ®å›é¡¾ï¼Œæœ€åè¾“å‡ºæœ€ç»ˆå†³ç­–ï¼Œæ”¹å–„å¾—åˆ†ç¨³å®šæ€§ã€‚
  - é‡‡ç”¨**åºåˆ—çº§å¥–åŠ±å½’ä¸€åŒ–ï¼ˆsequence-level normalizationï¼‰** é¿å…å› å“åº”é•¿åº¦å·®å¼‚å¯¼è‡´çš„ä¼˜åŒ–åå·®ã€‚

- **æ•°æ®æ•ˆç‡ä¼˜åŒ–æœºåˆ¶â€”â€”Disagreement Filtering**ï¼š
  åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹å¯¹åŒä¸€è¾“å…¥å¤šæ¬¡é‡‡æ ·ï¼Œè¯†åˆ«â€œåˆ†æ­§æ ·æœ¬â€ï¼ˆdisagreement examplesï¼‰ï¼Œå³ä¸åŒæ¨ç†è·¯å¾„äº§ç”Ÿä¸ä¸€è‡´é¢„æµ‹çš„æ ·æœ¬ã€‚è¿™ç±»æ ·æœ¬è¢«è®¤ä¸ºå…·æœ‰æ›´é«˜å­¦ä¹ ä»·å€¼ï¼Œä»…ç”¨å°‘é‡æ­¤ç±»æ•°æ®å³å¯è¾¾åˆ°ç”šè‡³è¶…è¶Šå…¨é‡è®­ç»ƒæ•ˆæœã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æé«˜çš„æ•°æ®æ•ˆç‡**ï¼šç›¸æ¯”SFTï¼ŒRLæ–¹æ³•å®ç°äº† **10Ã—â€“100Ã— çš„æ•°æ®æ•ˆç‡æå‡**ï¼Œå°¤å…¶é€‚ç”¨äºä¸“å®¶æ ‡æ³¨ç¨€ç¼ºçš„åœºæ™¯ã€‚
- **æ›´å¼ºçš„å¤æ‚æ¨ç†èƒ½åŠ›**ï¼šåœ¨éœ€å¤šå±‚æ¬¡æ”¿ç­–è§£è¯»çš„ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºSFTã€‚
- **æ›´ç¨³å®šçš„è®­ç»ƒè¿‡ç¨‹**ï¼šé€šè¿‡ç»¼åˆå¥–åŠ±è®¾è®¡æœ‰æ•ˆç¼“è§£äº†reward hackingã€length collapseç­‰é—®é¢˜ã€‚
- **å¯é¢„æµ‹çš„æ‰©å±•è¡Œä¸º**ï¼šRLè¡¨ç°å‡ºsigmoid-like scalingè§„å¾‹ï¼Œä¸ºèµ„æºåˆ†é…æä¾›å®ç”¨æŒ‡å¯¼ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
å®éªŒåŸºäº **Meta Platforms, Inc. çš„ä¸‰ä¸ªçœŸå®ç”Ÿäº§ç¯å¢ƒä¸­çš„å†…å®¹å®¡æ ¸ä»»åŠ¡ï¼ˆTask1, Task2, Task3ï¼‰**ï¼Œå‡æ¥è‡ªå®é™…ç”¨æˆ·/AIç”Ÿæˆå†…å®¹ï¼Œæ¶‰åŠæ”¿ç­–è¿è§„åˆ†ç±»ï¼ˆbinary classificationï¼‰ï¼Œä¾‹å¦‚ä»‡æ¨è¨€è®ºã€è™šå‡ä¿¡æ¯ç­‰ã€‚æ‰€æœ‰ä»»åŠ¡å‡ä½¿ç”¨é«˜è´¨é‡äººå·¥æ ‡æ³¨ä½œä¸ºground truthã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼šä¸»è¦ä½¿ç”¨ Qwen2.5-VL-7B å’Œ Qwen-3-8B ç­‰å¼€æºLLMã€‚
- **RLç®—æ³•**ï¼šé‡‡ç”¨ **Group Relative Policy Optimization (GRPO)**ï¼Œç›¸è¾ƒäºPPOæ— éœ€æ˜¾å¼å€¼å‡½æ•°ï¼Œè®¡ç®—æ›´é«˜æ•ˆä¸”é€‚åˆåˆ†å¸ƒå¼è®­ç»ƒã€‚
- **è®­ç»ƒæ¡†æ¶å¯¹æ¯”**ï¼šæ¯”è¾ƒäº† HuggingFace TRL ä¸ **VeRL**ï¼ˆHybridFlowé©±åŠ¨ï¼‰ï¼Œç»“æœæ˜¾ç¤ºVeRLååé‡æœ€é«˜è¾¾2.5Ã—ä¼˜åŠ¿ã€‚
- **è¾“å…¥å½¢å¼**ï¼šå°†ä»»åŠ¡å»ºæ¨¡ä¸ºæ¡ä»¶åˆ†ç±»é—®é¢˜ï¼Œpromptç»“æ„åŒ…å«æŒ‡ä»¤ã€æ”¿ç­–æè¿°ã€å†…å®¹åŠç»“æ„åŒ–è¾“å‡ºè¦æ±‚ï¼ˆJSONæ ¼å¼ï¼‰ã€‚
- **è¾“å‡ºç»“æ„**ï¼šæ¨¡å‹è¾“å‡ºåŒ…å«æ¨ç†é“¾ï¼ˆreasoning traceï¼‰ã€é¢„æµ‹æ ‡ç­¾ `y âˆˆ {0,1}` åŠå…¶å¯¹åº”æ¦‚ç‡ `p`ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **PRAUC**ï¼ˆPrecision-Recall AUCï¼‰ï¼šè¡¡é‡æ•´ä½“åˆ†ç±»æ€§èƒ½ã€‚
- **R@P90**ï¼šåœ¨ä¿è¯Precision â‰¥ 90%æ—¶çš„Recallï¼Œåæ˜ é«˜ç²¾åº¦çº¦æŸä¸‹çš„å¬å›èƒ½åŠ›ã€‚
- **F1 Score**ï¼šå¹³è¡¡ç²¾ç¡®ç‡ä¸å¬å›ç‡ã€‚
- **Faithfulness & Factuality**ï¼šé€šè¿‡LLM-as-judgeï¼ˆGemini-2.5-Proï¼‰å’ŒHHEMæ¨¡å‹è¯„ä¼°æ¨ç†å¿ å®æ€§å’Œäº‹å®æ€§ã€‚
- **Throughput (tokens/s/GPU)**ï¼šç”¨äºè¯„ä¼°è®­ç»ƒæ•ˆç‡ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **SFT-COT**ï¼šåŸºäºæ€ç»´é“¾ï¼ˆChain-of-Thoughtï¼‰çš„ç›‘ç£å¾®è°ƒã€‚
- **Zero-shot SFT / RL**ï¼šæ— ç›‘ç£æˆ–å°æ ·æœ¬åˆå§‹åŒ–ä¸‹çš„è¡¨ç°ã€‚
- **SFT â†’ RL**ï¼šä¸¤é˜¶æ®µè®­ç»ƒï¼ˆå…ˆSFTåRLï¼‰ã€‚
- **RL-Only**ï¼šç›´æ¥åœ¨åŸºç¡€æ¨¡å‹ä¸Šåº”ç”¨RLã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æ–¹æ³• | æ•°æ®è§„æ¨¡ | æ€§èƒ½è¡¨ç° |
|------|----------|---------|
| **RL-Only** | æ•°ç™¾æ ·æœ¬ | åŒ¹é…ç”šè‡³è¶…è¿‡æ•°ä¸‡æ ·æœ¬è®­ç»ƒçš„SFTæ¨¡å‹ |
| **SFT â†’ RL** | åƒçº§æ ·æœ¬ + RL | R@P90 æå‡5â€“15ä¸ªç™¾åˆ†ç‚¹ |
| **Disagreement Filtering + RL** | ä»…61ä¸ªâ€œåˆ†æ­§æ ·æœ¬â€ | F1 â‰ˆ 0.88ï¼Œæ¥è¿‘å…¨é‡æ•°æ®è®­ç»ƒçš„SFTæ¨¡å‹ |

#### è¡¨ï¼šTask1 ä¸Šä¸åŒå¥–åŠ±é…ç½®çš„æ€§èƒ½å¯¹æ¯”ï¼ˆQwen-38Bï¼‰
| Reward Setup | Recall | Precision | F1 |
|-------------|--------|-----------|-----|
| R_acc + R_fmt (Baseline) | 0.58 | 0.43 | 0.49 |
| + R_len | 0.61 | 0.41 | 0.49 |
| + R_rub (å®Œæ•´å¥–åŠ±) | **0.71** | **0.54** | **0.61** |

> âœ… æ·»åŠ  `R_rub` åF1æå‡ **12%**ï¼Œè¡¨æ˜rubric-based rewardå¯¹è´¨é‡æå‡è‡³å…³é‡è¦ã€‚

#### è¡¨ï¼šä¸åŒrolloutæ•°é‡ä¸‹çš„æ€§èƒ½ï¼ˆTask2ï¼‰
| Rollouts (N) | R@P90 |
|--------------|-------|
| 8            | 0.53  |
| 32           | 0.63  |
| 64           | 0.62  |
| 128          | 0.64  |

> ğŸ“ˆ æ€§èƒ½åœ¨N=32é™„è¿‘è¶‹äºé¥±å’Œï¼Œä½“ç°**è¾¹é™…æ”¶ç›Šé€’å‡**ã€‚

#### æ¶ˆèå®éªŒå…³é”®å‘ç°
- **Monte Carlo Sampling**ï¼šå½“N=4ã€T=1.0æ—¶æ€§èƒ½è¾¾åˆ°å¹³å°æœŸï¼Œè¿›ä¸€æ­¥å¢åŠ rolloutsæ”¶ç›Šæœ‰é™ã€‚
- **Sampling Temperature**ï¼šæœ€ä¼˜æ¸©åº¦åŒºé—´ä¸º **0.7â€“1.0**ï¼›é«˜äº1.0ä¼šå¯¼è‡´è§£æé”™è¯¯å¢å¤šã€‚
- **Effective Batch Size**ï¼šä»128å¢è‡³1024æ—¶ï¼ŒTask1çš„R@P90ä»0.18è·ƒå‡è‡³0.81ï¼›è¶…è¿‡2048ååŸºæœ¬é¥±å’Œã€‚
- **Disagreement Filtering**ï¼šå»é™¤â€œå›°éš¾æ ·æœ¬â€åè€Œæå‡æ€§èƒ½ï¼Œè¯´æ˜å™ªå£°æ ‡ç­¾å¯èƒ½å¹²æ‰°RLä¼˜åŒ–ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **RLå±•ç°å‡ºsigmoid-like scaling behavior**ï¼š
   - éšç€è®­ç»ƒæ•°æ®ã€rolloutæ•°é‡ã€ä¼˜åŒ–æ­¥æ•°å¢åŠ ï¼Œæ€§èƒ½å¹³æ»‘ä¸Šå‡å¹¶é€æ¸é¥±å’Œï¼Œä¸ºå·¥ä¸šéƒ¨ç½²æä¾›äº†å¯é¢„æµ‹çš„æ‰©å±•è“å›¾ã€‚

2. **RLåœ¨æ•°æ®æ•ˆç‡æ–¹é¢è¿œè¶…SFT**ï¼š
   - åœ¨æ•°ç™¾æ ·æœ¬ä¸‹å³å¯åŒ¹æ•Œæ•°ä¸‡æ ·æœ¬çš„SFTæ¨¡å‹ï¼Œ**å®ç°10Ã—â€“100Ã—çš„æ•°æ®æ•ˆç‡å¢ç›Š**ï¼Œç‰¹åˆ«é€‚åˆæ ‡æ³¨æˆæœ¬é«˜æ˜‚çš„å†…å®¹å®¡æ ¸é¢†åŸŸã€‚

3. **å¥–åŠ±è®¾è®¡å†³å®šæˆè´¥**ï¼š
   - å•çº¯ä¾èµ–accuracy rewardæ˜“å¼•å‘reward hackingå’Œlength collapseï¼›
   - å¼•å…¥`R_rub`ï¼ˆrubric-basedï¼‰å’Œ`R_len`èƒ½æ˜¾è‘—æå‡æ¨ç†è´¨é‡å’Œæ¨¡å‹é²æ£’æ€§ã€‚

4. **RLæœ¬è´¨æ˜¯response selectorè€Œécapability enhancer**ï¼š
   - åˆ†æè¡¨æ˜ï¼ŒRLæ›´å¤šæ˜¯æé«˜äº†ä»å¤šä¸ªå€™é€‰ç”Ÿæˆä¸­é€‰å‡ºæ­£ç¡®ç­”æ¡ˆçš„æ¦‚ç‡ï¼ˆpass@Nï¼‰ï¼Œè€Œéæ ¹æœ¬å¢å¼ºæ¨ç†èƒ½åŠ›ã€‚

5. **Disagreement Filteringæå¤§æå‡æ ·æœ¬æ•ˆç‡**ï¼š
   - ä»…ä½¿ç”¨â€œæ¨¡å‹å†…éƒ¨å­˜åœ¨åˆ†æ­§â€çš„æ ·æœ¬è¿›è¡Œè®­ç»ƒï¼Œå¯åœ¨æå°æ•°æ®é‡ä¸‹å®ç°é«˜æ€§èƒ½ï¼Œæ˜¯æœªæ¥ä½èµ„æºRLçš„é‡è¦æ–¹å‘ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡judgment infrastructure**ï¼š`R_rub`ä¾èµ–LLM-as-judgeæˆ–äººå·¥è¯„åˆ†ï¼Œå¢åŠ äº†ç³»ç»Ÿå¤æ‚æ€§å’Œå»¶è¿Ÿã€‚
- **å¯¹hard examplesæ•æ„Ÿ**ï¼šæŸäº›æç«¯éš¾ä¾‹å¯èƒ½å¯¼è‡´ä¸ç¨³å®šæ›´æ–°ï¼Œéœ€è°¨æ…è¿‡æ»¤ã€‚
- **compute overheadè¾ƒé«˜**ï¼šå°½ç®¡VeRLæå‡äº†ååï¼Œä½†MC samplingå’Œå¤šrolloutä»å¸¦æ¥æ¨ç†å¼€é”€ã€‚
- **æ— æ³•å®Œå…¨è§£å†³å¹»è§‰é—®é¢˜**ï¼šè™½ç„¶rubric rewardæœ‰åŠ©äºæ§åˆ¶ï¼Œä½†faithfulnessä¸factualityä¹‹é—´ä»å­˜åœ¨æƒè¡¡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢è‡ªåŠ¨åŒ–rubricç”Ÿæˆä¸è½»é‡åŒ–judgeæ¨¡å‹ï¼Œé™ä½rewardæˆæœ¬ã€‚
- å°†è¯¥æ¡†æ¶æ‰©å±•è‡³å¤šæ¨¡æ€å†…å®¹å®¡æ ¸ï¼ˆtext+image/videoï¼‰ã€‚
- ç»“åˆåœ¨çº¿å­¦ä¹ æœºåˆ¶ï¼Œé€‚åº”å¿«é€Ÿæ¼”åŒ–çš„æ”¿ç­–å®šä¹‰ã€‚
- è¿›ä¸€æ­¥ç ”ç©¶RLæ˜¯å¦çœŸæ­£å¢å¼ºäº†æ¨¡å‹çš„å†…åœ¨æ¨ç†èƒ½åŠ›ï¼Œè¿˜æ˜¯ä»…ä¼˜åŒ–äº†è¾“å‡ºé€‰æ‹©ç­–ç•¥ã€‚

--- 

> ğŸ”š **æ€»ç»“**ï¼šæœ¬è®ºæ–‡é¦–æ¬¡ç³»ç»ŸéªŒè¯äº†**å¼ºåŒ–å­¦ä¹ åœ¨å·¥ä¸šçº§å†…å®¹å®¡æ ¸ä¸­çš„è§„æ¨¡åŒ–å¯è¡Œæ€§**ï¼Œä¸ä»…å±•ç¤ºäº†å…¶å“è¶Šçš„æ•°æ®æ•ˆç‡å’Œæ¨ç†èƒ½åŠ›ï¼Œè¿˜æå‡ºäº†å¤šé¡¹ç¨³å®šè®­ç»ƒçš„å…³é”®æŠ€æœ¯ï¼ˆå¦‚rubric rewardã€reflection promptingã€disagreement filteringï¼‰ï¼Œä¸ºæ„å»ºä¸‹ä¸€ä»£æ™ºèƒ½å®¡æ ¸ç³»ç»Ÿæä¾›äº†åšå®çš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 11. [FastMPS: Revisit Data Parallel in Large-scale Matrix Product State Sampling](https://arxiv.org/abs/2512.20064)

**Authors**: Yaojian Chen, Si-Qiu Gong, Lin Gan, Yanfei Liu, An Yang, Yinuo Wang, Chao-yang Lu, Guangwen Yang  
**Category**: cs.DC  
**Published**: 2025-12-24  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.20064v1  

#### Abstract
Matrix Product State (MPS) is a versatile tensor network representation widely applied in quantum physics, quantum chemistry, and machine learning, etc. MPS sampling serves as a critical fundamental operation in these fields. As the problems become more complex, the scale of MPS is rapidly increasin...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFastMPS: Revisit Data Parallel in Large-scale Matrix Product State Sampling

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿ **Matrix Product State (MPS)** é‡‡æ ·åœ¨å¤§è§„æ¨¡åœºæ™¯ä¸‹é¢ä¸´ä¸¥é‡ç“¶é¢ˆï¼š
- **Data Parallelism** å—é™äºå†…å­˜å’Œé«˜ I/O å¼€é”€ï¼Œå½“ MPS å¼ é‡è¿‡å¤§æ— æ³•å…¨éƒ¨æ”¾å…¥æ˜¾å­˜æ—¶ï¼Œé¢‘ç¹çš„ç£ç›˜äº¤æ¢å¯¼è‡´æ€§èƒ½æ€¥å‰§ä¸‹é™ã€‚
- **Model Parallelism** è™½èƒ½å¤„ç†å¤§å°ºåº¦ MPSï¼Œä½†è¦æ±‚è¿›ç¨‹æ•°ä¸¥æ ¼ç­‰äºç«™ç‚¹æ•°ï¼ˆ$M$ï¼‰ï¼Œç¼ºä¹å¯æ‰©å±•æ€§ï¼Œä¸”å­˜åœ¨å¯åŠ¨å»¶è¿Ÿã€è´Ÿè½½ä¸å‡å’Œé€šä¿¡å¼€é”€é«˜ç­‰é—®é¢˜ã€‚

éšç€é‡å­å®éªŒï¼ˆå¦‚ Gaussian Boson Samplingï¼‰è§„æ¨¡æ‰©å¤§ï¼ˆç«™ç‚¹ $M \sim 8000$ï¼Œbond ç»´åº¦ $\chi \sim 10^4$ï¼Œæ ·æœ¬æ•° $N \sim 10^7$ï¼‰ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥é«˜æ•ˆæ”¯æŒã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æœ¬æ–‡æå‡º **FastMPS** â€”â€” ä¸€ç§å¤šçº§å¹¶è¡Œæ¡†æ¶ï¼Œé‡æ–°æ¿€æ´»å¤§è§„æ¨¡ MPS é‡‡æ ·çš„ **Data Parallelism**ï¼Œå…¶æ ¸å¿ƒè®¾è®¡ä¸ºï¼š

#### ï¼ˆ1ï¼‰**Multi-level Parallel Framework**
- **Task-level Data Parallelism**ï¼šå°†ç‹¬ç«‹æ ·æœ¬åˆ†å¸ƒåœ¨å¤šä¸ªè¿›ç¨‹ç»„ä¸­ï¼Œå®ç°è·¨æ ·æœ¬å¹¶è¡Œã€‚
- **Tensor-level Tensor Parallelism**ï¼šæ²¿ bond ç»´åº¦å¯¹ MPS å¼ é‡è¿›è¡Œåˆ‡åˆ†ï¼Œåœ¨ç»„å†…é‡‡ç”¨å¼ é‡å¹¶è¡ŒåŠ é€Ÿå•ä¸ªæ ·æœ¬è®¡ç®—ã€‚
- æ”¯æŒçµæ´»çš„è¿›ç¨‹é…ç½®ï¼ˆä¸å†ç»‘å®š $p = M$ï¼‰ï¼Œæ˜¾è‘—æå‡å¯æ‰©å±•æ€§å’Œèµ„æºåˆ©ç”¨ç‡ã€‚

#### ï¼ˆ2ï¼‰**Adaptive Mixed Precision Strategy**
- åœ¨ä¿æŒæ•°å€¼ç¨³å®šæ€§çš„å‰æä¸‹ï¼Œä½¿ç”¨ **TF32** è¿›è¡Œè®¡ç®—ï¼Œå¹¶é€šè¿‡ **sample-wise åŠ¨æ€ç¼©æ”¾** é˜²æ­¢ä¸‹æº¢ã€‚
- å­˜å‚¨é‡‡ç”¨ **FP16** å‹ç¼© MPS å¼ é‡ï¼Œå‡å°‘ I/O å’Œé€šä¿¡å¼€é”€ã€‚
- åˆ©ç”¨ Tensor Core åŠ é€Ÿ GEMM æ“ä½œï¼Œå¤§å¹…æå‡è®¡ç®—ååã€‚

#### ï¼ˆ3ï¼‰**Customized Kernels & Dynamic Bond Dimension**
- é’ˆå¯¹ GBS ä¸­çš„ displacement operator è®¾è®¡è¿‘ä¼¼ç®—æ³•ï¼ˆåŸºäº Zassenhaus å…¬å¼åˆ†è§£ï¼‰ï¼Œå°†çŸ©é˜µæŒ‡æ•°è¿ç®—å¤æ‚åº¦å¤§å¹…é™ä½ã€‚
- å¼•å…¥ **dynamic bond dimension**ï¼Œæ ¹æ® entanglement åˆ†å¸ƒåŠ¨æ€è°ƒæ•´å„ç«™ç‚¹çš„ $\chi$ï¼Œé¿å…è¾¹ç¼˜åŒºåŸŸå†—ä½™è®¡ç®—ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ [19]ï¼‰ | FastMPS |
|------|---------------------|---------|
| å¯æ‰©å±•æ€§ | å›ºå®š $p = M$ï¼Œä¸å¯æ‰©å±• | æ”¯æŒä»»æ„è¿›ç¨‹æ•°ï¼Œå¼ºå¼±æ‰©å±•æ€§ä¼˜å¼‚ |
| å†…å­˜ä¸ I/O | é«˜é¢‘ç£ç›˜è¯»å–ï¼ŒI/O å¯†é›† | å‹ç¼© + é‡å ä¼˜åŒ–ï¼Œç¼“è§£ I/O å‹åŠ› |
| æ•°å€¼æ•ˆç‡ | å¤šæ•°ä½¿ç”¨ FP64ï¼Œæ€§èƒ½å—é™ | è‡ªé€‚åº”æ··åˆç²¾åº¦ï¼Œé‡Šæ”¾ Tensor Core æ€§èƒ½ |
| é€šä¿¡æ¨¡å¼ | Pipeline å¼ç‚¹å¯¹ç‚¹é€šä¿¡ï¼Œå¯åŠ¨å»¶è¿Ÿé«˜ | æ•°æ®å¹¶è¡Œ + é›†ä½“é€šä¿¡ï¼Œæ˜“äºé‡å  |
| çµæ´»æ€§ | ä»…é€‚ç”¨äºç‰¹å®šç¡¬ä»¶é…ç½® | è·¨å¹³å°å…¼å®¹ï¼ˆCPU/GPU/Sunway/Tianheï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- ä¸»è¦åŸºå‡†ä»»åŠ¡ï¼š**Gaussian Boson Sampling (GBS)**ï¼ŒåŒ…æ‹¬ï¼š
  - **Jiuzhang ç³»åˆ—**ï¼ˆä¸­å›½ç§‘å¤§å…‰é‡å­è®¡ç®—æœºï¼‰
  - **Borealis**ï¼ˆXanadu å…‰å­èŠ¯ç‰‡ï¼‰
  - è‡ªå®šä¹‰å¤§è§„æ¨¡æ¨¡æ‹Ÿæ•°æ®ï¼š**8176-site GBS**ï¼Œå« 16.54 ä¸ªå®é™…å‹ç¼©å…‰å­ï¼ˆactual squeezed photonsï¼‰

è¿™äº›æ•°æ®å…·æœ‰æ ‡å‡†åŒ–è¾“å…¥ã€çœŸå®ç‰©ç†èƒŒæ™¯ï¼Œé€‚åˆä½œä¸ºé«˜æ€§èƒ½ä»¿çœŸåŸºå‡†ã€‚

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### ç¡¬ä»¶å¹³å°
- **GPU æµ‹è¯•**ï¼šå•å¡ A100ï¼ˆ40GBï¼‰ï¼ŒNVLink è¿æ¥å¤šå¡
- **CPU æµ‹è¯•**ï¼šIntel Xeon Gold 6230R @ 2.10GHz
- **è¶…ç®—å¹³å°**ï¼š
  - **Tianhe-3**ï¼šæœ€å¤š 15 èŠ‚ç‚¹ï¼ˆ375 æ ¸ï¼‰
  - **Sunway TaihuLight**ï¼šæœ€å¤š 500 è¿›ç¨‹ï¼ˆ32500 æ ¸ï¼‰

#### å‚æ•°è®¾ç½®
- ç‰©ç†ç»´åº¦ $d = 3$ æˆ– $4$
- bond dimension $\chi = 10^3 \sim 10^4$
- æ ·æœ¬æ€»æ•° $N = 10^5 \sim 10^7$
- micro batch size $N_2 = 10^3 \sim 2\times10^4$

#### è¯„ä¼°æŒ‡æ ‡
- **è¿è¡Œæ—¶é—´ï¼ˆTime-to-solutionï¼‰**
- **åŠ é€Ÿæ¯”ï¼ˆSpeedupï¼‰**
- **å¼º/å¼±æ‰©å±•æ•ˆç‡ï¼ˆStrong/Weak Scaling Efficiencyï¼‰**
- **æˆªæ–­è¯¯å·®ï¼ˆTruncation Errorï¼‰**
- **ç›¸å…³å‡½æ•°ä¸€è‡´æ€§éªŒè¯ï¼ˆ1st/2nd-order Correlationï¼‰**

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **[19]**ï¼šå½“å‰æœ€å…ˆè¿›çš„ MPS-based GBS æ¨¡æ‹Ÿå™¨ï¼Œé‡‡ç”¨ model parallelism + pipeline è®¾è®¡
- å¯¹æ¯”æ–¹å¼ï¼š
  - ç›¸åŒå‚æ•°ä¸‹çš„ç«¯åˆ°ç«¯è¿è¡Œæ—¶é—´
  - å•ä½èµ„æºä¸‹çš„æ€§èƒ½ï¼ˆå¦‚æ¯ GPU æ—¶é—´ï¼‰
  - æ‰©å±•èƒ½åŠ›ï¼ˆæœ€å¤§æ”¯æŒè§„æ¨¡ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- æˆåŠŸå®ç°äº† **8176-siteã€$\chi=10^4$** çš„ GBS æ¨¡æ‹Ÿï¼Œè¿œè¶…æ­¤å‰ state-of-the-artï¼ˆçº¦ 288-siteï¼‰ã€‚
- åœ¨å•å¼  A100 GPU ä¸Šå®Œæˆ 10 million æ ·æœ¬ç”Ÿæˆä»…éœ€ **çº¦ 14 å°æ—¶**ï¼ˆBorealis-288 åœºæ™¯ï¼‰ï¼Œæ˜¯ç›®å‰æœ€å¿«å®ç°ã€‚
- ä½¿ç”¨ 8 å— A100 GPU å®Œæˆ Jiuzhang2 çš„ 10M æ ·æœ¬é‡‡æ ·è€—æ—¶ **38.57 åˆ†é’Ÿ**ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœï¼ˆTable 2 & 3ï¼‰

| GBS å®ä¾‹ | [19] æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰ | Fast-MPS-8 æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰ | åŠ é€Ÿæ¯” |
|--------|------------------|------------------------|-------|
| Jiuzhang2 | 62ï¼ˆä½¿ç”¨ 144 GPUsï¼‰ | 38.57ï¼ˆä½¿ç”¨ 8 GPUsï¼‰ | **>10Ã—**ï¼ˆæŒ‰ç­‰æ•ˆèµ„æºä¼°ç®—ï¼‰ |
| B-M288 | 62ï¼ˆä½¿ç”¨ 288 GPUsï¼‰ | 247.43ï¼ˆä½¿ç”¨ 8 GPUsï¼‰ | **~10.6Ã—**ï¼ˆå‡è®¾ 95% å¹¶è¡Œæ•ˆç‡ï¼‰ |

> æ³¨ï¼šFast-MPS ç”¨æ›´å°‘ GPU è¾¾åˆ°æ›´å¿«é€Ÿåº¦ï¼Œä½“ç°æé«˜èµ„æºåˆ©ç”¨ç‡ã€‚

#### CPU å¯¹æ¯”ï¼ˆTable 3ï¼‰
| å®ä¾‹ | [19] æ—¶é—´ | Fast-MPS æ—¶é—´ | åŠ é€Ÿæ¯” |
|------|----------|---------------|--------|
| Jiuzhang2-P65-1 | 17.72h | 1.76h | **10.06Ã—** |
| B-M288 | 36.44h | 4.504h | **8.09Ã—** |

---

### æ¶ˆèå®éªŒç»“æœï¼ˆFigure 11ï¼‰
åœ¨ A100 ä¸Šå¯¹ä¸‰å¤§ä¼˜åŒ–è¿›è¡Œæ¶ˆèæµ‹è¯•ï¼ˆå›ºå®š $d=4,\chi=10^4$, 40ä¸‡æ ·æœ¬ï¼‰ï¼š

| ä¼˜åŒ–é¡¹ | ç§»é™¤åæ€§èƒ½ä¸‹é™å€æ•° | è´¡çŒ®åŠ é€Ÿæ¯” |
|--------|--------------------|------------|
| Dynamic Bond Dimension | ä¸‹é™ 2.6Ã— | **~2.6Ã—** |
| Optimized expm | ä¸‹é™ 1.9Ã— | **~1.9Ã—** |
| Adaptive Mixed Precision | ä¸‹é™ 5.1Ã— | **~5.1Ã—** |

> ç»“æœè¡¨æ˜ï¼š**æ··åˆç²¾åº¦è´¡çŒ®æœ€å¤§**ï¼Œè¯´æ˜æ•°å€¼ç¨³å®šæ€§è®¾è®¡è‡³å…³é‡è¦ï¼›ä¸‰é¡¹ä¼˜åŒ–å‘ˆä¹˜æ³•æ•ˆåº”ï¼Œå…±åŒå¸¦æ¥æ€»ä½“ >10Ã— æå‡ã€‚

---

### æ‰©å±•æ€§è¡¨ç°ï¼ˆFigure 12ï¼‰
- **Weak Scaling**ï¼šæ ·æœ¬éšè¿›ç¨‹çº¿æ€§å¢é•¿ï¼Œæ•ˆç‡ >95%
- **Strong Scaling**ï¼šæ€»æ ·æœ¬å›ºå®šï¼ŒåŠ é€Ÿæ¥è¿‘ç†æƒ³æ›²çº¿ï¼Œæ•ˆç‡ >95%
- æ”¯æŒä¸Šåƒè¿›ç¨‹æ‰©å±•ï¼Œåœ¨ Sunway ä¸Šå®ç°å…¨ 8176-site è§„æ¨¡ä»¿çœŸ

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Data Parallelism å¯åœ¨å¤§è§„æ¨¡ MPS ä¸­å¤æ´»**ï¼šé€šè¿‡å‹ç¼©ã€é‡å å’Œ tensor parallelism ååŒï¼Œè§£å†³äº†ä¼ ç»Ÿ data parallel çš„ I/O å’Œå†…å­˜ç“¶é¢ˆã€‚
2. **æ··åˆç²¾åº¦å¯è¡Œä¸”å¿…è¦**ï¼šé€šè¿‡ sample-wise ç¼©æ”¾æœºåˆ¶ï¼Œå¯åœ¨æ•°åƒç«™ç‚¹ä¸Šå®‰å…¨ä½¿ç”¨ TF32ï¼Œå……åˆ†å‘æŒ¥ Tensor Core æ€§èƒ½ã€‚
3. **dynamic bond dimension æ˜¾è‘—é™ä½è®¡ç®—å¤æ‚åº¦**ï¼šTable 1 æ˜¾ç¤ºè®¡ç®—æ­¥éª¤å‡å°‘è¾¾ **80%**ï¼Œå°¤å…¶åœ¨ä½çº ç¼ åŒºåŸŸæ•ˆæœæ˜æ˜¾ã€‚
4. **FastMPS å®ç°å‰æ‰€æœªæœ‰çš„æ¨¡æ‹Ÿè§„æ¨¡**ï¼šé¦–æ¬¡å®ç° **8176-siteã€$\chi=10^4$** çš„ GBS æ¨¡æ‹Ÿï¼Œæ¨åŠ¨ç»å…¸æ¨¡æ‹Ÿè¾¹ç•Œã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ä»ä¾èµ–é«˜è´¨é‡ MPS è¡¨ç¤º**ï¼šè‹¥åŸå§‹é‡å­æ€æ— æ³•è¢« MPS é«˜æ•ˆè¡¨ç¤ºï¼ˆå¦‚é«˜åº¦çº ç¼ æ€ï¼‰ï¼Œåˆ™æœ¬æ–¹æ³•ä¸é€‚ç”¨ã€‚
2. **é€šä¿¡æ•æ„Ÿ**ï¼štensor parallelism ä¸­ ReduceScatter å¯¹å¸¦å®½æ•æ„Ÿï¼Œåœ¨ PCIe ç­‰ä½å¸¦å®½è¿æ¥ä¸‹æ€§èƒ½ä¸‹é™æ˜æ˜¾ã€‚
3. **æš‚æœªæ”¯æŒ FP16/BF16 å…¨æµç¨‹**ï¼šå›  ComplexHalf æ”¯æŒä¸è¶³åŠæ ·æœ¬å†…åŠ¨æ€èŒƒå›´è¿‡å¤§ï¼Œå°šæœªå…¨é¢å¯ç”¨åŠç²¾åº¦è®­ç»ƒçº§æ ¼å¼ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ¢ç´¢ä¸ AI æ¨ç†ç³»ç»Ÿçš„å…±é€šæ€§**ï¼šå°† MPS è§†ä¸ºâ€œç‰©ç†ç¥ç»ç½‘ç»œâ€ï¼Œå€Ÿé‰´ Transformer æ¨ç†ä¸­çš„ continuous batchingã€KV Cache ç­‰æŠ€æœ¯ã€‚
2. **å¼‚æ„è®¡ç®—èåˆ**ï¼šç»“åˆ CPU + GPU + ASIC æ¶æ„ï¼Œè¿›ä¸€æ­¥æå‡èƒ½æ•ˆæ¯”ã€‚
3. **è‡ªåŠ¨å¹¶è¡Œç­–ç•¥é€‰æ‹©å™¨**ï¼šåŸºäºç¡¬ä»¶æ‹“æ‰‘è‡ªåŠ¨åˆ¤æ–­ä½¿ç”¨ single-site vs double-site tensor parallelismã€‚
4. **æ‹“å±•è‡³å…¶ä»– tensor network åº”ç”¨**ï¼šå¦‚ PEPSã€MERAã€QUICKER ç­‰æ›´å¤æ‚çš„ç½‘ç»œç»“æ„ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> FastMPS é€šè¿‡åˆ›æ–°çš„å¤šçº§å¹¶è¡Œæ¶æ„ä¸æ··åˆç²¾åº¦ç­–ç•¥ï¼ŒæˆåŠŸå°† data parallelism é‡æ–°å¸¦å›å¤§è§„æ¨¡ MPS é‡‡æ ·é¢†åŸŸï¼Œåœ¨ GBS ç­‰å…³é”®åº”ç”¨ä¸­å®ç° **>10Ã— æ€§èƒ½æå‡**ï¼Œå¹¶çªç ´æ€§åœ°æ”¯æŒ **8176-site** è§„æ¨¡ä»¿çœŸï¼Œä¸ºé‡å­ä¼˜åŠ¿éªŒè¯æä¾›äº†å¼ºå¤§çš„ç»å…¸å·¥å…·ã€‚

</details>

---

### 12. [OpComm: A Reinforcement Learning Framework for Adaptive Buffer Control in Warehouse Volume Forecasting](https://arxiv.org/abs/2512.19738)

**Authors**: Wilson Fung, Lu Guo, Drake Hilliard, Alessandro Casadei, Raj Ratan, Sreyoshi Bhaduri, Adi Surve, Nikhil Agarwal, Rohit Malshe, Pavan Mullapudi, Hungjen Wang, Saurabh Doodhwala, Ankush Pole, Arkajit Rakshit  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.19738v1  

#### Abstract
Accurate forecasting of package volumes at delivery stations is critical for last-mile logistics, where errors lead to inefficient resource allocation, higher costs, and delivery delays. We propose OpComm, a forecasting and decision-support framework that combines supervised learning with reinforcem...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*OpComm: A Reinforcement Learning Framework for Adaptive Buffer Control in Warehouse Volume Forecasting*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**æœ€åä¸€å…¬é‡Œç‰©æµä¸­åŒ…è£¹é‡é¢„æµ‹ä¸å‡†å¯¼è‡´èµ„æºåˆ†é…ä½æ•ˆã€æˆæœ¬ä¸Šå‡å’Œäº¤ä»˜å»¶è¿Ÿ**çš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨ä»“åº“é…é€ç«™ç‚¹ï¼ˆdelivery stationsï¼‰å±‚é¢çš„**ç¼“å†²åŒºç®¡ç†ï¼ˆbuffer controlï¼‰å†³ç­–ä¸ç§‘å­¦**çš„æŒ‘æˆ˜ã€‚ä¼ ç»Ÿæ–¹æ³•ä¾èµ–äººå·¥ç»éªŒæˆ–å¯å‘å¼è§„åˆ™ï¼Œéš¾ä»¥é€‚åº”ç«™ç‚¹é—´çš„å¼‚è´¨æ€§å’Œéœ€æ±‚æ³¢åŠ¨ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº† **OpComm** â€”â€” ä¸€ä¸ªèåˆç›‘ç£å­¦ä¹ ã€å¼ºåŒ–å­¦ä¹ ä¸ç”Ÿæˆå¼AIçš„**è‡ªé€‚åº”ç¼“å†²æ§åˆ¶æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **å°†ç¼“å†²åŒºå†³ç­–å»ºæ¨¡ä¸ºä¸Šä¸‹æ–‡å¼ºåŒ–å­¦ä¹ ï¼ˆcontextual reinforcement learningï¼‰é—®é¢˜**ï¼šä»¥ LightGBM é¢„æµ‹çš„éœ€æ±‚ä½œä¸ºçŠ¶æ€è¾“å…¥ï¼Œç”± PPOï¼ˆProximal Policy Optimizationï¼‰æ™ºèƒ½ä½“é€‰æ‹©æœ€ä¼˜ç¼“å†²ç­‰çº§ã€‚
- **è®¾è®¡éå¯¹ç§°å¥–åŠ±å‡½æ•°ï¼ˆasymmetric reward functionï¼‰**ï¼šå¯¹â€œç¼“å†²ä¸è¶³â€ï¼ˆunder-bufferingï¼‰æ–½åŠ æ¯”â€œç¼“å†²è¿‡åº¦â€æ›´é‡çš„æƒ©ç½šï¼ˆÎ± > Î²ï¼‰ï¼Œåæ˜ ç°å®ä¸­æœªæ»¡è¶³éœ€æ±‚å¸¦æ¥çš„æ›´é«˜è¿è¥é£é™©ã€‚
- **å¼•å…¥è’™ç‰¹å¡æ´›æ›´æ–°æœºåˆ¶å®ç°ç­–ç•¥æŒç»­é€‚åº”**ï¼šé€šè¿‡å®é™…ç«™ç‚¹åé¦ˆè¿›è¡Œç­–ç•¥è¿­ä»£ï¼Œå¢å¼ºåœ¨éå¹³ç¨³ç¯å¢ƒä¸­çš„é²æ£’æ€§ã€‚
- **é›†æˆç”Ÿæˆå¼AIè§£é‡Šæ¨¡å—æå‡å¯è§£é‡Šæ€§ä¸å†³ç­–æ”¯æŒèƒ½åŠ›**ï¼šåˆ©ç”¨ SHAP ç‰¹å¾å½’å› ç”Ÿæˆé«˜ç®¡çº§æ‘˜è¦å’Œæƒ…æ™¯åˆ†æï¼Œå¸®åŠ©è¿è¥äººå‘˜ç†è§£æ¨¡å‹å†³ç­–é€»è¾‘ï¼Œä¿ƒè¿›è½åœ°é‡‡çº³ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **è¶…è¶Šçº¯é¢„æµ‹æ¨¡å‹**ï¼šä¸ä»…æä¾›é¢„æµ‹ï¼Œè¿˜è¾“å‡ºå¯æ‰§è¡Œçš„ç¼“å†²å»ºè®®ï¼Œå½¢æˆç«¯åˆ°ç«¯å†³ç­–æ”¯æŒç³»ç»Ÿã€‚
- **ä¼˜äºä¼ ç»ŸRLæ–¹æ³•**ï¼šé‡‡ç”¨ PPO è€Œé DQN æˆ– TRPOï¼Œåœ¨ç¦»æ•£åŠ¨ä½œç©ºé—´ä¸‹å…¼å…·ç¨³å®šæ€§ä¸æ•ˆç‡ã€‚
- **å…¼é¡¾å‡†ç¡®æ€§ä¸å®ç”¨æ€§**ï¼šç»“åˆ LightGBM çš„é«˜ç²¾åº¦é¢„æµ‹ä¸ RL çš„åŠ¨æ€ä¼˜åŒ–ï¼Œå¹¶é€šè¿‡ç”Ÿæˆå¼AIæ¡¥æ¥æŠ€æœ¯ä¸ä¸šåŠ¡ä¹‹é—´çš„é¸¿æ²Ÿã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- å®éªŒåŸºäº **åŒ—ç¾åœ°åŒºè¶…è¿‡400ä¸ªä»“åº“é…é€ç«™ç‚¹çš„å†å²è¿è¥æ•°æ®**ã€‚
- æ•°æ®åŒ…å«æ—¶é—´åºåˆ—ç‰¹å¾ï¼ˆå¦‚å‘¨æœŸæ€§ã€å­£èŠ‚æ€§ï¼‰ã€æ»åæŒ‡æ ‡ï¼ˆå†å²éœ€æ±‚æ³¢åŠ¨ã€å®¹é‡åˆ©ç”¨ç‡ï¼‰ä»¥åŠç«™ç‚¹ç‰¹å®šæ“ä½œçº¦æŸã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼š
  - **LightGBM å›å½’æ¨¡å‹**ç”¨äºç”Ÿæˆå„ç«™ç‚¹çš„åŒ…è£¹é‡é¢„æµ‹ï¼Œä½œä¸º PPO æ™ºèƒ½ä½“çš„çŠ¶æ€è¾“å…¥ã€‚
  - **PPO æ™ºèƒ½ä½“**ä»é¢„å®šä¹‰çš„ç¦»æ•£ç¼“å†²ç­‰çº§é›†åˆ {bâ‚, bâ‚‚, ..., bk} ä¸­é€‰æ‹©åŠ¨ä½œã€‚
  - å¥–åŠ±å‡½æ•°å®šä¹‰å¦‚ä¸‹ï¼š
    $$
    r_t = -\alpha \cdot \max(0, D_t - \hat{D}_t - b_t) + \beta \cdot \max(0, b_t + \hat{D}_t - D_t)
    $$
    å…¶ä¸­ Î± > Î²ï¼Œå¼ºè°ƒé¿å… under-bufferingã€‚
- **è®­ç»ƒæ–¹å¼**ï¼šé‡‡ç”¨ **Monte Carlo rollouts** è®¡ç®—ç»éªŒå›æŠ¥ï¼Œæ— éœ€æ˜¾å¼å»ºæ¨¡éœ€æ±‚åŠ¨æ€ï¼Œé€‚ç”¨äºéå¹³ç¨³ç¯å¢ƒã€‚
- **å¯è§£é‡Šæ€§æ¨¡å—**ï¼šåŸºäº SHAP å€¼é©±åŠ¨ç”Ÿæˆå¼AIç”Ÿæˆè‡ªç„¶è¯­è¨€æŠ¥å‘Šã€‚

### è¯„ä¼°æŒ‡æ ‡
- **WAPEï¼ˆWeighted Absolute Percentage Errorï¼‰**ï¼šè¡¡é‡é¢„æµ‹å‡†ç¡®æ€§ã€‚
- **WAPE æ ‡å‡†å·®**ï¼šè¯„ä¼°è·¨ç«™ç‚¹ç¨³å®šæ€§ã€‚
- **Under-buffering å’Œ Over-buffering ç™¾åˆ†æ¯”**ï¼šè¡¡é‡ç¼“å†²ç­–ç•¥çš„é£é™©è¡¨ç°ã€‚
- å¯¹æ¯”äººå·¥é¢„æµ‹ï¼ˆmanual forecastingï¼‰ä½œä¸ºåŸºçº¿ã€‚

### åŸºçº¿æ–¹æ³•
- **Manual Forecasting**ï¼šå½“å‰è¡Œä¸šå¸¸ç”¨çš„äººå·¥/å¯å‘å¼é¢„æµ‹ä¸ç¼“å†²è®¾å®šæ–¹æ³•ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| åŒºåŸŸ       | æ–¹æ³•      | WAPE (%) | Under-buffering (%) | Over-buffering (%) |
|------------|-----------|----------|----------------------|---------------------|
| North-East | Manual    | 4.95     | 18.3                 | 12.5                |
|            | OpComm    | **3.85** | **10.2**             | 15.1                |
| Mid-West   | Manual    | 5.12     | 20.1                 | 13.0                |
|            | OpComm    | **3.90** | **11.0**             | 14.2                |
| South      | Manual    | 4.88     | 16.7                 | 11.9                |
|            | OpComm    | **3.70** | **9.5**              | 13.5                |
| West       | Manual    | 4.99     | 17.9                 | 12.7                |
|            | OpComm    | **3.80** | **10.0**             | 14.0                |

### æ€»ä½“å¯¹æ¯”ç»“æœ
- **WAPE å¹³å‡ä¸‹é™ 21.65%**ï¼ˆä» 4.95% â†’ 3.85%ï¼‰ã€‚
- åœ¨ **93.7% çš„ç«™ç‚¹ä¸Šæå‡äº†é¢„æµ‹å‡†ç¡®ç‡**ã€‚
- **æ˜¾è‘—é™ä½ under-buffering å‘ç”Ÿç‡**ï¼ˆå¹³å‡é™å¹…çº¦ 8 ä¸ªç™¾åˆ†ç‚¹ï¼‰ï¼Œè¡¨æ˜ç­–ç•¥æ›´å…·ä¿å®ˆæ€§å’Œé£é™©è§„é¿ç‰¹æ€§ã€‚
- å°½ç®¡ over-buffering ç•¥æœ‰ä¸Šå‡ï¼Œä½†æ•´ä½“èµ„æºæµªè´¹ä»£ä»·ä½äºç¼ºè´§é£é™©ï¼Œç¬¦åˆè®¾è®¡ç›®æ ‡ã€‚

> âš ï¸ æ³¨ï¼šæ–‡ä¸­æœªæåŠæ¶ˆèå®éªŒï¼ˆablation studyï¼‰ï¼Œå› æ­¤æ— æ³•æä¾›ç›¸å…³ç»“æœã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
- **OpComm æ˜¾è‘—ä¼˜äºäººå·¥é¢„æµ‹æ–¹æ³•**ï¼Œåœ¨å¤šä¸ªåœ°ç†åŒºåŸŸå‡è¡¨ç°å‡ºæ›´é«˜çš„é¢„æµ‹ç²¾åº¦å’Œæ›´ä½çš„æ“ä½œé£é™©ã€‚
- å¼•å…¥ **PPO ä¸éå¯¹ç§°å¥–åŠ±æœºåˆ¶** å¯æœ‰æ•ˆå¼•å¯¼æ™ºèƒ½ä½“å­¦ä¹ åå‘å®‰å…¨çš„ç¼“å†²ç­–ç•¥ï¼Œå¥‘åˆç°å®ç‰©æµåœºæ™¯çš„æˆæœ¬ä¸å¯¹ç§°æ€§ã€‚
- **ç”Ÿæˆå¼AIè§£é‡Šå±‚å¢å¼ºäº†ç³»ç»Ÿçš„é€æ˜åº¦ä¸å¯ä¿¡åº¦**ï¼Œæœ‰åŠ©äºæ¨åŠ¨ç®—æ³•åœ¨è¿è¥ç®¡ç†ä¸­çš„å®é™…éƒ¨ç½²ã€‚
- æ•´ä½“æ¡†æ¶å±•ç¤ºäº†å¦‚ä½•å°† **ç»Ÿè®¡å»ºæ¨¡ã€å¼ºåŒ–å­¦ä¹ æ§åˆ¶ä¸äººæœºååŒå†³ç­–æ”¯æŒ** æœ‰æœºç»“åˆï¼Œè§£å†³é«˜é£é™©è¿è¥ç¯å¢ƒä¸‹çš„å¤æ‚å†³ç­–é—®é¢˜ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- æœªéªŒè¯å…¶ä»– policy optimization ç®—æ³•ï¼ˆå¦‚ SACã€A2Cï¼‰çš„è¡¨ç°å·®å¼‚ã€‚
- åŠ¨ä½œç©ºé—´ä¸ºç¦»æ•£å‹ç¼“å†²ç­‰çº§ï¼Œå¯èƒ½é™åˆ¶ç»†ç²’åº¦è°ƒæ§èƒ½åŠ›ã€‚
- ç¼ºä¹è·¨ç«™ç‚¹ååŒä¼˜åŒ–æœºåˆ¶ï¼Œç›®å‰ä¸ºå•ç«™ç‹¬ç«‹å†³ç­–ã€‚
- æœªè¿›è¡Œä¸¥æ ¼çš„ç”¨æˆ·ç ”ç©¶æ¥è¯„ä¼°ç”Ÿæˆå¼AIæ¨¡å—çš„å®é™…å¯ç”¨æ€§ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ **meta-learning** ç”¨äºåŠ¨æ€ç‰¹å¾è¡¨ç¤ºï¼Œæå‡è·¨ç«™ç‚¹æ³›åŒ–èƒ½åŠ›ã€‚
- ç ”ç©¶ **æ›¿ä»£æ€§çš„ç­–ç•¥ä¼˜åŒ–ç®—æ³•**ï¼Œè¿›ä¸€æ­¥æé«˜å­¦ä¹ æ•ˆç‡ä¸ç¨³å®šæ€§ã€‚
- æ‰©å±•è‡³ **ç½‘ç»œå±‚çº§åè°ƒæ§åˆ¶**ï¼Œå®ç°å¤šç«™ç‚¹è”åˆè°ƒåº¦ä¸èµ„æºè°ƒé…ã€‚
- å¼€å±• **å¯è§£é‡Šæ€§æ–¹æ³•çš„å½¢å¼åŒ–è¯„ä¼°**ï¼Œé‡åŒ–ç”Ÿæˆå¼AIå¯¹å†³ç­–è´¨é‡çš„å½±å“ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> OpComm æˆåŠŸåœ°å°† LightGBM é¢„æµ‹ã€PPO å¼ºåŒ–å­¦ä¹ ä¸ç”Ÿæˆå¼AIè§£é‡Šç›¸ç»“åˆï¼Œæ„å»ºäº†ä¸€ä¸ªé«˜æ•ˆã€ç¨³å¥ä¸”å¯è§£é‡Šçš„ä»“å‚¨ä½“ç§¯é¢„æµ‹ä¸ç¼“å†²æ§åˆ¶æ¡†æ¶ï¼Œåœ¨çœŸå®ç‰©æµåœºæ™¯ä¸­å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ä¸å†³ç­–æ”¯æŒä»·å€¼ã€‚

</details>

---

### 13. [Learning to Design City-scale Transit Routes](https://arxiv.org/abs/2512.19767)

**Authors**: Bibek Poudel, Weizi Li  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.19767v1  

#### Abstract
Designing efficient transit route networks is an NP-hard problem with exponentially large solution spaces that traditionally relies on manual planning processes. We present an end-to-end reinforcement learning (RL) framework based on graph attention networks for sequential transit network constructi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Learning to Design City-scale Transit Routes*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹**Transit Route Network Design Problem (TRNDP)**ï¼Œå³åŸå¸‚å…¬äº¤çº¿è·¯ç½‘ç»œè®¾è®¡é—®é¢˜ã€‚è¯¥é—®é¢˜æ˜¯ **NP-hard** çš„ç»„åˆä¼˜åŒ–é—®é¢˜ï¼Œå…·æœ‰æŒ‡æ•°çº§åºå¤§çš„è§£ç©ºé—´ï¼Œä¼ ç»Ÿä¸Šä¾èµ–äººå·¥è§„åˆ’ï¼Œæ•ˆç‡ä½ä¸”éš¾ä»¥è¾¾åˆ°å…¨å±€æœ€ä¼˜ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
1. **ç«¯åˆ°ç«¯å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼ˆEnd-to-End RL Frameworkï¼‰**  
   é¦–æ¬¡æå‡ºä¸€ä¸ªå®Œæ•´çš„ã€åŸºäº **Graph Attention Networks (GAT)** å’Œ **Proximal Policy Optimization (PPO)** çš„ç«¯åˆ°ç«¯ RL æ¡†æ¶ï¼Œç”¨äº**é¡ºåºæ„å»ºåŸå¸‚å°ºåº¦çš„å…¬äº¤ç½‘ç»œ**ã€‚

2. **ä¸¤å±‚çº§å¥–åŠ±æœºåˆ¶ï¼ˆTwo-Level Reward Structureï¼‰**  
   ä¸ºè§£å†³é•¿å‘¨æœŸå†³ç­–ä¸­çš„**ç¨€ç–å¥–åŠ±ï¼ˆsparse rewardï¼‰ä¸ä¿¡ç”¨åˆ†é…ï¼ˆcredit assignmentï¼‰éš¾é¢˜**ï¼Œå¼•å…¥ï¼š
   - **å¢é‡æ‹“æ‰‘åé¦ˆï¼ˆIncremental Topological Feedbackï¼‰**ï¼šåœ¨æ¯ä¸€æ­¥æ‰©å±•è·¯çº¿æ—¶æä¾›è½»é‡çº§å¥–åŠ±ï¼ˆå¦‚éœ€æ±‚è¦†ç›–ã€é¿å…é‡å ï¼‰ï¼›
   - **ä»¿çœŸç»ˆç«¯å¥–åŠ±ï¼ˆSimulation-Based Terminal Rewardsï¼‰**ï¼šåœ¨å®Œæ•´ç½‘ç»œç”Ÿæˆåé€šè¿‡äº¤é€šæ¨¡æ‹Ÿå™¨è·å–çœŸå®æ€§èƒ½åé¦ˆï¼ˆå¦‚æœåŠ¡ç‡ã€ç­‰å¾…æ—¶é—´ç­‰ï¼‰ã€‚

3. **å¯æ‰©å±•çš„å›¾æ³¨æ„åŠ›ç­–ç•¥æ¶æ„ï¼ˆScalable Graph Attention Policyï¼‰**  
   è®¾è®¡äº†ä¸€ä¸ªå‚æ•°æ•°é‡ä¸è¾“å…¥ç½‘ç»œè§„æ¨¡æ— å…³çš„ç­–ç•¥ç½‘ç»œï¼Œä½¿å…¶å…·å¤‡è‰¯å¥½çš„**è·¨åŸå¸‚è¿ç§»æ½œåŠ›**ã€‚

4. **å‘å¸ƒçœŸå®ä¸–ç•Œæ•°æ®é›†ï¼ˆReal-World Datasetï¼‰**  
   æ„å»ºå¹¶å…¬å¼€å‘å¸ƒäº†æ¥è‡ªç¾å›½å°ç¬¬å®‰çº³å·å¸ƒå¢æ˜é¡¿ï¼ˆBloomingtonï¼‰çš„çœŸå®æ•°æ®é›†ï¼ŒåŒ…å«ï¼š
   - å‡†ç¡®çš„é“è·¯æ‹“æ‰‘ï¼ˆ143èŠ‚ç‚¹ï¼Œ243æ¡è¾¹ï¼‰
   - åŸºäºäººå£æ™®æŸ¥çš„ Origin-Destination (OD) éœ€æ±‚çŸ©é˜µ
   - å½“å‰è¿è¥çš„16æ¡å…¬äº¤çº¿è·¯ GTFS æ•°æ®

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | æœ¬è®ºæ–‡æ–¹æ³• |
|------|--------|-----------|
| æ–¹æ³•ç±»å‹ | æ‰‹å·¥å¯å‘å¼ / å…ƒå¯å‘ç®—æ³•ï¼ˆGA, SAï¼‰ | ç«¯åˆ°ç«¯æ·±åº¦å¼ºåŒ–å­¦ä¹  |
| å¥–åŠ±æœºåˆ¶ | ä»…æœ€ç»ˆè¯„ä¼°ï¼ˆç¨€ç–åé¦ˆï¼‰ | ä¸¤çº§å¥–åŠ±ï¼ˆä¸­é—´+ç»ˆç«¯ï¼‰ï¼Œç¼“è§£ä¿¡ç”¨å»¶è¿Ÿ |
| æ•°æ®åŸºç¡€ | åˆæˆç½‘ç»œï¼ˆå¦‚ Mandl ç½‘ç»œï¼‰ | çœŸå®åŸå¸‚æ‹“æ‰‘ + çœŸå® OD éœ€æ±‚ |
| å¯æ‰©å±•æ€§ | å›ºå®šç®—å­ï¼Œéœ€è°ƒå‚ | å›¾ç¥ç»ç½‘ç»œï¼Œå‚æ•°ç‹¬ç«‹äºåŸå¸‚å¤§å° |
| æ€§èƒ½è¡¨ç° | å±€éƒ¨æœ€ä¼˜ï¼Œéš¾ä»¥å¹³è¡¡å¤šç›®æ ‡ | è‡ªåŠ¨å­¦ä¹ æƒè¡¡ä¹˜å®¢ä¸è¿è¥å•†åˆ©ç›Š |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†
- **åç§°**ï¼šBloomington Transit Datasetï¼ˆä½œè€…è‡ªå»ºï¼‰
- **æ¥æº**ï¼š
  - è·¯ç½‘ï¼šTIGER/Line Shapefilesï¼ˆU.S. Census Bureauï¼‰
  - OD éœ€æ±‚ï¼šLEHD LODES æ•°æ®ï¼ˆ2022å¹´é€šå‹¤æµï¼Œç»1.5å€éé€šå‹¤æµé‡æ”¾å¤§ï¼‰
  - å…¬äº¤çº¿è·¯ï¼šBloomington Transit GTFS å¼€æ”¾æ•°æ®
- **è§„æ¨¡**ï¼š143ä¸ªèŠ‚ç‚¹ï¼Œ243æ¡åŒå‘è¾¹ï¼Œçº¦5,738ä¸ªODå¯¹
- **ç‰¹ç‚¹**ï¼šé¦–æ¬¡å°†çœŸå®é“è·¯æ‹“æ‰‘ã€çœŸå®å‡ºè¡Œéœ€æ±‚ä¸å®é™…å…¬äº¤ç³»ç»Ÿç»“åˆç”¨äº TRNDP ç ”ç©¶

### âš™ï¸ å®éªŒè®¾ç½®
- **ç¯å¢ƒæ¨¡æ‹Ÿå™¨**ï¼šUXsimï¼ˆè½»é‡çº§ä¸­è§‚äº¤é€šä»¿çœŸå™¨ï¼ŒåŸºäºè¿åŠ¨æ³¢ç†è®ºï¼‰
- **è®­ç»ƒè¿‡ç¨‹**ï¼š
  - æ¯ episode è®¾è®¡ 16 æ¡çº¿è·¯ï¼Œæ¯æ¡æœ€å¤š 14 ä¸ªèŠ‚ç‚¹
  - ä½¿ç”¨ PPO ç®—æ³•è®­ç»ƒï¼Œå…± 2000 episodes
  - åŠ¨ä½œç©ºé—´é‡‡ç”¨ **action masking** æŠ€æœ¯é™åˆ¶æ— æ•ˆé€‰æ‹©
- **é¢‘ç‡è®¾å®š**ï¼šä½¿ç”¨ **æœ€å¤§è´Ÿè½½åŸåˆ™ï¼ˆmax-load principleï¼‰** åœ¨è·¯çº¿è®¾è®¡å®Œæˆåç¡®å®šå‘è½¦é¢‘ç‡ï¼Œé¿å…é¢‘ç‡å¹²æ‰°å­¦ä¹ ä¿¡å·

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡ï¼ˆPassenger & Operator Orientedï¼‰
| ç±»åˆ« | æŒ‡æ ‡ | å®šä¹‰ |
|------|------|------|
| **ä¹˜å®¢ä¾§** | Service Rate (%) | æˆåŠŸä¸Šè½¦ä¹˜å®¢å æ€»éœ€æ±‚æ¯”ä¾‹ |
| | Wait Time (min) | å¹³å‡å€™è½¦æ—¶é—´ |
| | Transfer Rate (%) | å®Œæˆæ—…ç¨‹ä¸­éœ€è¦æ¢ä¹˜çš„æ¯”ä¾‹ |
| | Travel Time (min) | æ€»è¡Œç¨‹æ—¶é—´ï¼ˆå«ç­‰å¾…+è½¦å†…ï¼‰ |
| **è¿è¥ä¾§** | Route Efficiency (pax/km) | æ¯å…¬é‡Œçº¿è·¯æœåŠ¡çš„ä¹˜å®¢æ•° |
| | Fleet Size | æ‰€éœ€å…¬äº¤è½¦æ€»æ•° |
| | Bus Utilization (%) | è½¦è¾†å¹³å‡è½½å®¢ç‡ |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿æ–¹æ³• | æè¿° |
|--------|------|
| **Real-world** | å½“å‰å¸ƒå¢æ˜é¡¿å®é™…è¿è¡Œçš„å…¬äº¤ç½‘ç»œï¼ˆäººå·¥è®¾è®¡ï¼‰ |
| **Random Walk** | æ¯æ­¥éšæœºé€‰æ‹©å¯è¡Œé‚»å±…èŠ‚ç‚¹ |
| **Greedy Demand Coverage** | æ¯æ­¥é€‰æ‹©èƒ½å¸¦æ¥æœ€å¤§æ–°å¢éœ€æ±‚è¿æ¥çš„èŠ‚ç‚¹ |
| **Greedy Shortest Path** | æ¯æ­¥é€‰æ‹©æœ€è¿‘çš„å¯è¡ŒèŠ‚ç‚¹ï¼ˆæœ€å°è·ç¦»ä¼˜å…ˆï¼‰ |

æ­¤å¤–è¿˜æµ‹è¯•äº†ä¸¤ç§åˆå§‹åŒ–æ–¹å¼ï¼š
- **Transit Center Start**ï¼šæ‰€æœ‰çº¿è·¯ä»äº¤é€šæ¢çº½å‡ºå‘ï¼ˆåŒ¹é…ç°å®æƒ…å†µï¼‰
- **Random Start**ï¼šé¦–ç«™éšæœºé€‰å–

ä»¥åŠä¸¤ç§å‡ºè¡Œæ¨¡å¼å æ¯”ï¼ˆmodal splitï¼‰ï¼š
- `Î± = 0.3`ï¼šæ··åˆå‡ºè¡Œï¼ˆ30%ä½¿ç”¨å…¬äº¤ï¼‰
- `Î± = 1.0`ï¼šå…¨å…¬äº¤å‡ºè¡Œï¼ˆé«˜é‡‡ç”¨åœºæ™¯ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ `Î± = 1.0`, Transit Center åˆå§‹åŒ–ä¸ºä¾‹ï¼‰

| æŒ‡æ ‡ | Real-world | RL (Ours) | æå‡å¹…åº¦ |
|------|------------|----------|---------|
| **Service Rate (%)** | 58.20% | **73.10%** | â†‘ **25.6%** |
| **Wait Time (min)** | 15.87 | **10.96** | â†“ **30.9%** |
| **Travel Time (min)** | 52.85 | 53.04 | â‰ˆæŒå¹³ï¼ˆ+0.4%ï¼‰ |
| **Route Efficiency (pax/km)** | 62.74 | **72.06** | â†‘ **14.9%** |
| **Bus Utilization (%)** | 32.15% | **38.89%** | â†‘ **21.0%** |
| **Fleet Size** | 281 | 281 | ç›¸åŒ |

> âœ… åœ¨é«˜å…¬äº¤é‡‡ç”¨ç‡ä¸‹ï¼ŒRL è®¾è®¡æ˜¾è‘—ä¼˜äºç°å®ç½‘ç»œï¼Œåœ¨æœåŠ¡ç‡ã€ç­‰å¾…æ—¶é—´å’Œåˆ©ç”¨ç‡æ–¹é¢å‡æœ‰å¤§å¹…æå‡ã€‚

### ğŸ” æ··åˆæ¨¡å¼ä¸‹çš„è¡¨ç°ï¼ˆ`Î± = 0.3`, Random Initializationï¼‰

| å¯¹æ¯”é¡¹ | ç»“æœ |
|-------|------|
| vs. **Demand Coverage Heuristic** | Route Efficiency æå‡ **68.8%** |
| vs. **Shortest Path Heuristic** | Travel Time é™ä½ **5.9%** |
| vs. Real-world Network | Service Rate â†‘6.9%ï¼ŒWait Time â†“27.3% |

> âœ… å³ä½¿åœ¨æ›´å¤æ‚ã€æ— å…ˆéªŒèµ·ç‚¹çš„æƒ…å†µä¸‹ï¼ŒRL ä»èƒ½å‘ç°ä¼˜äºå„ç±»å¯å‘å¼çš„æƒè¡¡æ–¹æ¡ˆã€‚

### ğŸ“Š å›¾å½¢åŒ–åˆ†æå‘ç°
- RL è®¾è®¡çš„ç½‘ç»œï¼š
  - è¦†ç›–æ›´å¤šè¾¹ç¼˜åŒºåŸŸï¼ˆæ–°å¢27ä¸ªèŠ‚ç‚¹æœåŠ¡ï¼‰
  - æ›´å°‘é‡å¤çº¿è·¯ï¼ˆä»…39æ¡è¾¹è¢«å¤šçº¿å…±äº« vs. ç°å®47æ¡ï¼‰
  - åˆ†å¸ƒæ›´å‡åŒ€ï¼ˆ19.7%èŠ‚ç‚¹è¢«â‰¥3æ¡çº¿æœåŠ¡ vs. ç°å®22.8%ï¼‰
- è¡¨æ˜ RL å­¦ä¼šäº†**å‡å°‘å†—ä½™ã€æ‰©å¤§è¦†ç›–èŒƒå›´ã€æå‡èµ„æºåˆ©ç”¨æ•ˆç‡**

### âŒ æ½œåœ¨ä»£ä»·
- Transfer Rate ç•¥æœ‰ä¸Šå‡ï¼ˆ+0.8~6.1ä¸ªç™¾åˆ†ç‚¹ï¼‰ï¼Œè¯´æ˜æ›´å¤šä¹˜å®¢éœ€æ¢ä¹˜
- ä½†åœ¨ `Î±=0.3` ä¸‹ Route Efficiency ç•¥ä½ï¼ˆå› å¢åŠ è½¦è¾†åè°ƒæˆæœ¬ï¼‰

> å°½ç®¡æ¢ä¹˜å¢å¤šï¼Œä½†æ€»æ—…è¡Œæ—¶é—´å‡ ä¹ä¸å˜ï¼Œè¡¨æ˜ç³»ç»Ÿå®ç°äº†æœ‰æ•ˆçš„æ¢ä¹˜è¡”æ¥ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º
1. **ç«¯åˆ°ç«¯ RL å¯æœ‰æ•ˆè§£å†³å¤§è§„æ¨¡ TRNDP**  
   åœ¨çœŸå®åŸå¸‚å°ºåº¦ä¸Šï¼ŒRL èƒ½è‡ªåŠ¨å­¦ä¹ é«˜è´¨é‡çš„å…¬äº¤ç½‘ç»œè®¾è®¡ç­–ç•¥ï¼Œè¶…è¶Šäººç±»ä¸“å®¶è®¾è®¡å’Œä¼ ç»Ÿå¯å‘å¼æ–¹æ³•ã€‚

2. **ä¸¤å±‚çº§å¥–åŠ±æœºåˆ¶è‡³å…³é‡è¦**  
   ä¸­é—´æ‹“æ‰‘å¥–åŠ±å¸®åŠ©å¼•å¯¼æ¢ç´¢æ–¹å‘ï¼Œç»ˆç«¯ä»¿çœŸå¥–åŠ±ç¡®ä¿æœ€ç»ˆæ€§èƒ½å¯ä¿¡ï¼ŒäºŒè€…ç»“åˆæ˜¾è‘—æå‡äº†å­¦ä¹ æ•ˆç‡ä¸ç¨³å®šæ€§ã€‚

3. **RL èƒ½å®ç°æ›´ä¼˜çš„å¤šç›®æ ‡æƒè¡¡**  
   åœ¨ä¹˜å®¢ä½“éªŒï¼ˆæœåŠ¡ç‡ã€ç­‰å¾…æ—¶é—´ï¼‰ä¸è¿è¥å•†æ•ˆç‡ï¼ˆè½¦è¾†åˆ©ç”¨ç‡ã€çº¿è·¯æ•ˆç‡ï¼‰ä¹‹é—´æ‰¾åˆ°æ›´å¥½å¹³è¡¡ï¼Œå°¤å…¶åœ¨é«˜å…¬äº¤åˆ†æ‹…ç‡åœºæ™¯ä¸‹ä¼˜åŠ¿æ˜æ˜¾ã€‚

4. **çœŸå®æ•°æ®é©±åŠ¨çš„è®¾è®¡æ›´å…·å®ç”¨æ€§**  
   åŸºäºçœŸå®è·¯ç½‘ä¸éœ€æ±‚çš„è®¾è®¡æ›´èƒ½åæ˜ ç°å®äº¤é€šåŠ¨æ€ï¼Œä¸ºæœªæ¥æ™ºèƒ½äº¤é€šç³»ç»Ÿæä¾›äº†å¯é éªŒè¯å¹³å°ã€‚

### âš ï¸ å±€é™æ€§
1. **é™æ€éœ€æ±‚å‡è®¾**ï¼šå½“å‰æ¨¡å‹åŸºäºå›ºå®šé«˜å³°å°æ—¶éœ€æ±‚ï¼Œæœªè€ƒè™‘æ—¶é—´å˜åŒ–æˆ–éšæœºæ³¢åŠ¨ã€‚
2. **å•åŸå¸‚éªŒè¯**ï¼šç›®å‰ä»…åœ¨å¸ƒå¢æ˜é¡¿è¿™ä¸€ä¸­ç­‰åŸå¸‚æµ‹è¯•ï¼Œå°šæœªæ¨å¹¿è‡³æ›´å¤§æˆ–æ›´å¤æ‚çš„åŸå¸‚ã€‚
3. **å¿½ç•¥åŠ¨æ€è°ƒåº¦ç»†èŠ‚**ï¼šå¦‚å®æ—¶å»¶è¯¯ã€ä¿¡å·æ§åˆ¶ã€ç«™ç‚¹å®¹é‡ç­‰æœªçº³å…¥å»ºæ¨¡ã€‚
4. **è®¡ç®—å¼€é”€è¾ƒé«˜**ï¼šè®­ç»ƒè€—æ—¶çº¦48å°æ—¶ï¼ˆRTX 4090 + i9 CPUï¼‰ï¼Œé™åˆ¶å¿«é€Ÿè¿­ä»£ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. æ‰©å±•è‡³å¤šä¸ªåŸå¸‚ï¼Œå¹¶é›†æˆåŠ¨æ€ OD ä¼°è®¡ä¸æ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å—ã€‚
2. å¼•å…¥ **multi-agent RL** æˆ– **hierarchical RL** å¤„ç†çº¿è·¯ååŒä¸é¢‘ç‡è”åˆä¼˜åŒ–ã€‚
3. æ¢ç´¢ä¸ **mixed traffic dynamics**ï¼ˆè‡ªåŠ¨é©¾é©¶ã€å…±äº«å‡ºè¡Œï¼‰çš„èåˆè®¾è®¡ã€‚
4. ç»“åˆ **digital twin** æŠ€æœ¯è¿›è¡Œåœ¨çº¿æŒç»­ä¼˜åŒ–ä¸æ”¿ç­–æ¨æ¼”ã€‚
5. å¼€å‘è½»é‡åŒ–æ¨ç†ç‰ˆæœ¬ï¼Œæ”¯æŒåŸå¸‚è§„åˆ’è€…çš„äº¤äº’å¼è¾…åŠ©è®¾è®¡å·¥å…·ã€‚

---

## ğŸ’¡ æ€»ç»“
è¯¥è®ºæ–‡æˆåŠŸå±•ç¤ºäº† **deep reinforcement learning + graph attention + real-world data + traffic simulation** çš„å¼ºå¤§ç»„åˆï¼Œä¸ºåŸå¸‚å…¬å…±äº¤é€šç½‘ç»œè®¾è®¡æä¾›äº†å…¨æ–°çš„è‡ªåŠ¨åŒ–èŒƒå¼ã€‚å…¶å‘å¸ƒçš„æ•°æ®é›†å’Œä»£ç ä¹Ÿä¸ºåç»­ç ”ç©¶å¥ å®šäº†åšå®åŸºç¡€ï¼Œæ ‡å¿—ç€åŸå¸‚äº¤é€šè§„åˆ’æ­£ä»â€œç»éªŒé©±åŠ¨â€è¿ˆå‘â€œæ•°æ®ä¸AIé©±åŠ¨â€çš„æ–°æ—¶ä»£ã€‚

</details>

---

### 14. [A DeepSeek-Powered AI System for Automated Chest Radiograph Interpretation in Clinical Practice](https://arxiv.org/abs/2512.20344)

**Authors**: Yaowei Bai, Ruiheng Zhang, Yu Lei, Xuhua Duan, Jingfeng Yao, Shuguang Ju, Chaoyang Wang, Wei Yao, Yiwan Guo, Guilin Zhang, Chao Wan, Qian Yuan, Lei Chen, Wenjuan Tang, Biqiang Zhu, Xinggang Wang, Tao Sun, Wei Zhou, Dacheng Tao, Yongchao Xu, Chuansheng Zheng, Huangxuan Zhao, Bo Du  
**Category**: cs.AI  
**Published**: 2025-12-24  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.20344v1  

#### Abstract
A global shortage of radiologists has been exacerbated by the significant volume of chest X-ray workloads, particularly in primary care. Although multimodal large language models show promise, existing evaluations predominantly rely on automated metrics or retrospective analyses, lacking rigorous pr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šA DeepSeek-Powered AI System for Automated Chest Radiograph Interpretation in Clinical Practice

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
- **å…¨çƒæ”¾å°„ç§‘åŒ»ç”ŸçŸ­ç¼º**ï¼Œå°¤å…¶æ˜¯åœ¨åŸºå±‚åŒ»ç–—ä¸­ï¼Œèƒ¸ç‰‡ï¼ˆCXRï¼‰è§£è¯»è´Ÿæ‹…å·¨å¤§ã€‚
- ç°æœ‰åŸºäºAIçš„CXRæŠ¥å‘Šç”Ÿæˆç³»ç»Ÿå¤šä¾èµ–è‡ªåŠ¨åŒ–æŒ‡æ ‡æˆ–å›é¡¾æ€§åˆ†æï¼Œç¼ºä¹**å‰ç»æ€§ä¸´åºŠéªŒè¯**ï¼Œéš¾ä»¥è¯æ˜å…¶çœŸå®ä¸–ç•Œä¸­çš„ä¸´åºŠä»·å€¼ã€‚
- å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆå¦‚ChatGPT 4oï¼‰è™½å…·æ½œåŠ›ï¼Œä½†å­˜åœ¨éƒ¨ç½²æˆæœ¬é«˜ã€æœ¯è¯­ä¸è§„èŒƒã€éšç§é£é™©ç­‰é—®é¢˜ã€‚

### ğŸ†• æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
- å¼€å‘äº† **Janus-Pro-CXR**ï¼šä¸€ä¸ªåŸºäºDeepSeekå¼€æºå¤šæ¨¡æ€å¤§æ¨¡å‹Janus-Proï¼ˆ1Bå‚æ•°ï¼‰çš„è½»é‡çº§ã€ä¸“ç”¨äºCXRçš„AIç³»ç»Ÿã€‚
- é‡‡ç”¨**å¤§-å°æ¨¡å‹ååŒæ¡†æ¶**ï¼š
  - åˆ©ç”¨ä¸“å®¶åˆ†ç±»æ¨¡å‹æ³¨å…¥è¯Šæ–­ç»“æœï¼›
  - ç»Ÿä¸€æ¨¡å‹æ•´åˆå¤šæ¨¡æ€ä¸´åºŠæ•°æ®ï¼›
  - æ˜¾å¼å»ºæ¨¡å½±åƒé˜…è¯»é€»è¾‘ã€‚
- é€šè¿‡ä¸‰é˜¶æ®µç›‘ç£å¾®è°ƒï¼ˆsupervised fine-tuningï¼‰ï¼Œåœ¨MIMIC-CXRã€CheXpert Pluså’Œä¸­å›½å¤šä¸­å¿ƒCXR-27æ•°æ®é›†ä¸Šå®Œæˆè®­ç»ƒã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | Janus-Pro-CXRä¼˜åŠ¿ |
|------|-------------------|
| **æ€§èƒ½è¡¨ç°** | åœ¨è‡ªåŠ¨æŠ¥å‘Šç”ŸæˆæŒ‡æ ‡ä¸Šè¶…è¶Šæ›´å¤§è§„æ¨¡æ¨¡å‹ï¼ˆå¦‚ChatGPT 4o, 200Bï¼‰ |
| **éƒ¨ç½²å¯è¡Œæ€§** | ä»…éœ€GeForce RTX 4060å³å¯å®ç°1â€“2ç§’æ¨ç†å»¶è¿Ÿï¼Œé€‚åˆèµ„æºå—é™ç¯å¢ƒ |
| **ä¸´åºŠå®ç”¨æ€§** | é¦–æ¬¡è¿›è¡Œå¤šä¸­å¿ƒå‰ç»æ€§è¯•éªŒï¼ˆNCT07117266ï¼‰ï¼ŒéªŒè¯AIè¾…åŠ©å¯¹å®é™…å·¥ä½œæµçš„å½±å“ |
| **å¼€æ”¾æ€§** | æ¨¡å‹æ¶æ„ä¸ä»£ç å°†å¼€æºï¼ˆGitHub: https://github.com/ZrH42/Janus-Pro-CXRï¼‰ï¼Œä¿ƒè¿›ä¸´åºŠè½¬åŒ– |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | æè¿° |
|--------|------|
| **MIMIC-CXR** | å…¬å¼€èƒ¸éƒ¨Xå…‰æ•°æ®åº“ï¼Œå«å¸¦è‡ªç”±æ–‡æœ¬æŠ¥å‘Šçš„å›¾åƒï¼›ç”¨äºå‰ä¸¤é˜¶æ®µå¾®è°ƒåŠæµ‹è¯•ï¼ˆn=2,365ï¼‰ |
| **CheXpert Plus** | æ‰©å±•ç‰ˆCheXpertï¼Œå¢åŠ äººå£ç»Ÿè®¡å­¦ä¿¡æ¯å’Œæ–‡æœ¬æŠ¥å‘Šï¼›ç”¨äºå‰æœŸè®­ç»ƒ |
| **CXR-27** | æ¥è‡ªä¸­å›½27å®¶åŒ»é™¢çš„å¤šä¸­å¿ƒå›é¡¾æ€§æ•°æ®é›†ï¼ˆn=12,396ï¼‰ï¼Œç”¨äºæœ€ç»ˆå¾®è°ƒä¸è¯„ä¼° |
| **Prospective Cohort** | æ¥è‡ª3å®¶ä¸­å›½åŒ»é™¢çš„å‰ç»æ€§é˜Ÿåˆ—ï¼ˆn=296æ‚£è€…ï¼‰ï¼Œç”¨äºçœŸå®åœºæ™¯ä¸‹AIåä½œç ”ç©¶ |

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹ç»“æ„**ï¼šä»¥Janus-Proï¼ˆ1Bï¼‰ä¸ºåŸºç¡€ï¼Œå…¨å‚æ•°å¾®è°ƒã€‚
- **è®­ç»ƒæµç¨‹**ï¼š
  1. ç¬¬ä¸€é˜¶æ®µï¼šMIMIC-CXR + CheXpert Plus â†’ åŸºç¡€è¯Šæ–­èƒ½åŠ›
  2. ç¬¬äºŒé˜¶æ®µï¼šCXR-27 â†’ é€‚åº”æœ¬åœ°å†™ä½œé£æ ¼ä¸æ•°æ®åˆ†å¸ƒ
- **éƒ¨ç½²æ–¹å¼**ï¼šç‹¬ç«‹äºPACSç³»ç»Ÿï¼Œé€šè¿‡å±€åŸŸç½‘æ¥æ”¶å›¾åƒä¸ç—…å²ï¼Œè¿”å›æŠ¥å‘Šä¾›åŒ»ç”Ÿç¼–è¾‘ã€‚

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡

#### è‡ªåŠ¨åŒ–è¯„ä¼°ï¼ˆRetrospectiveï¼‰
- **RadGraph F1**ï¼šåŒ»å­¦å®ä½“å…³ç³»æŠ½å–å‡†ç¡®ç‡
- **Micro/Macro F1-5 & F1-14**ï¼šTop 5å¸¸è§ç–¾ç—…ä¸å…¨éƒ¨14ç±»ç–¾ç—…çš„è¯†åˆ«ç²¾åº¦
- **AUC**ï¼šå…­é¡¹å…³é”®å½±åƒå‘ç°çš„åˆ†ç±»æ€§èƒ½
- **Cohen's Kappa**ï¼šä¸å‚è€ƒæ ‡å‡†çš„ä¸€è‡´æ€§

#### ä¸»è§‚è¯„ä¼°ï¼ˆProspective & Retrospectiveï¼‰
- **Report Quality Score**ï¼šäº”ç‚¹è¯„åˆ†åˆ¶ï¼ˆLikert scaleï¼‰
- **Pairwise Preference Test**ï¼šä¸“å®¶ç›²é€‰æ›´ä¼˜æŠ¥å‘Š
- **RADPEER Agreement Score**ï¼šè¡¡é‡æŠ¥å‘Šå·®å¼‚çš„ä¸´åºŠæ„ä¹‰
- **Reading Time**ï¼šä»é˜…ç‰‡åˆ°å®ŒæˆæŠ¥å‘Šçš„æ—¶é—´ï¼ˆç§’ï¼‰

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
| å¯¹æ¯”å¯¹è±¡ | ç±»å‹ |
|---------|------|
| **Janus-Pro (1B)** | åŸå§‹åŸºç¡€æ¨¡å‹ï¼ˆæœªå¾®è°ƒï¼‰ |
| **ChatGPT 4o (200B)** | å•†ä¸šé€šç”¨å¤šæ¨¡æ€å¤§æ¨¡å‹ |
| **MAIRA-2**, **CheXagent** | å…¶ä»–CXRä¸“ç”¨æ¨¡å‹ï¼ˆå› ä¸å¯å¤ç°æœªå‚ä¸å‰ç»å®éªŒï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰è‡ªåŠ¨åŒ–æŠ¥å‘Šç”Ÿæˆæ€§èƒ½ï¼ˆCXR-27æµ‹è¯•é›†ï¼‰
| æŒ‡æ ‡ | Janus-Pro-CXR |
|------|---------------|
| **RadGraph F1** | **58.6**ï¼ˆæ‰€æœ‰æ¨¡å‹ä¸­æ’åç¬¬ä¸€ï¼‰ |
| **Micro F1-5** | 63.4ï¼ˆMIMIC-CXRæµ‹è¯•é›†ç¬¬ä¸€ï¼‰ |
| **Macro F1-5** | 55.1ï¼ˆMIMIC-CXRæµ‹è¯•é›†ç¬¬ä¸€ï¼‰ |
| **Micro F1-14** | 59.9ï¼ˆç¬¬äºŒåï¼‰ |
| **Macro F1-14** | 42.3ï¼ˆç¬¬äºŒåï¼‰ |

> æ³¨ï¼šæ˜¾è‘—ä¼˜äºJanus-Proå’ŒChatGPT 4oï¼Œåœ¨ç½•è§ç—…è¯†åˆ«ä¸Šä¹Ÿè¡¨ç°å‡ºè‰¯å¥½å¹³è¡¡æ€§ã€‚

#### ï¼ˆ2ï¼‰å…³é”®å½±åƒå‘ç°æ£€æµ‹æ€§èƒ½ï¼ˆAUCï¼‰
| å‘ç° | AUC |
|------|-----|
| Support Devices | 0.931 |
| Pleural Effusion | 0.931 |
| Pneumothorax | 0.921 |
| Lung Opacity | >0.8 |
| Consolidation | >0.8 |
| Cardiomegaly | >0.8 |

âœ… **å…­é¡¹å…³é”®å‘ç°AUCå‡ > 0.8**ï¼Œæ˜¾ç¤ºå¼ºå¤§è¯Šæ–­èƒ½åŠ›ã€‚

#### ï¼ˆ3ï¼‰å‰ç»æ€§ä¸´åºŠåä½œç»“æœï¼ˆn=296ï¼‰
| æŒ‡æ ‡ | æ ‡å‡†ç»„ï¼ˆStandard Careï¼‰ | AIè¾…åŠ©ç»„ï¼ˆAI-Assistedï¼‰ | På€¼ |
|------|--------------------------|--------------------------|-----|
| **Report Quality Score** | 4.12 Â± 0.80 | **4.36 Â± 0.50** | <0.001 |
| **Agreement Score (RADPEER)** | 4.14 Â± 0.84 | **4.30 Â± 0.57** | <0.001 |
| **Reading Time (ç§’)** | 147.6 Â± 51.1 | **120.6 Â± 45.6** | <0.001 |
| **æ—¶é—´å‡å°‘** | â€” | **27.0ç§’ï¼ˆâ†“18.3%ï¼‰** | â€” |
| **å¤æ‚ç—…ä¾‹æ—¶é—´èŠ‚çœ**ï¼ˆâ‰¥3ä¸ªå‘ç°ï¼‰ | â€” | â†“32.5ç§’ï¼ˆâ†“16.4%ï¼‰ | <0.001 |

> ğŸ’¡ è‹¥æ¯æ—¥è¯»200å¼ èƒ¸ç‰‡ï¼Œå¯èŠ‚çœçº¦90åˆ†é’Ÿï¼Œå¯ç”¨äºç–‘éš¾ç—…ä¾‹åˆ†ææˆ–ç¼“è§£è§†è§‰ç–²åŠ³ã€‚

#### ï¼ˆ4ï¼‰åå¥½æµ‹è¯•ç»“æœ
- **AIç‹¬ç«‹ç”Ÿæˆ vs å‘è¡¨æŠ¥å‘Š**ï¼š30.4%è¢«â‰¥3ä½ä¸“å®¶åçˆ±
- **AIè¾…åŠ©æŠ¥å‘Š vs æ ‡å‡†æŠ¥å‘Š**ï¼š**54.3%è¢«â‰¥3ä½ä¸“å®¶åçˆ±**

#### ï¼ˆ5ï¼‰å¤šå›¾è¾“å…¥èƒ½åŠ›éªŒè¯
| åœºæ™¯ | æŠ¥å‘Šè´¨é‡è¯„åˆ† |
|------|--------------|
| å†å²èƒ¸ç‰‡å¯¹æ¯” | 3.19 Â± 1.22 |
| PA+LateralåŒè§†å›¾ | **3.42 Â± 1.02** |
| ä»…PAè§†å›¾ï¼ˆå¯¹ç…§ï¼‰ | 3.23 Â± 1.06ï¼ˆP<0.001ï¼‰ |

âœ… è¡¨æ˜åŒæ—¶è¾“å…¥æ­£ä¾§ä½å›¾åƒèƒ½æ˜¾è‘—æå‡æŠ¥å‘Šè´¨é‡ã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
- **Janus-Pro-CXR-Zero**ï¼ˆä»…ç”¨MIMIC+CheXpertå¾®è°ƒï¼‰ï¼š
  - åœ¨CXR-27æµ‹è¯•é›†ä¸­å¤šæ•°æŒ‡æ ‡æ’åç¬¬äºŒï¼Œè¯´æ˜åŠ å…¥CXR-27æ•°æ®åæ€§èƒ½è¿›ä¸€æ­¥æå‡ã€‚
- **è½»é‡åŒ–è®¾è®¡æœ‰æ•ˆæ€§**ï¼š
  - å°½ç®¡ä»…ä¸º1Bå‚æ•°ï¼Œæ€§èƒ½è¶…è¿‡æ›´å¤§æ¨¡å‹ï¼ˆå¦‚3Bã€7Bç”šè‡³200Bçš„ChatGPT 4oï¼‰ï¼Œè¡¨æ˜é¢†åŸŸä¼˜åŒ–æ¯”å•çº¯æ‰©å‚æ›´é‡è¦ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Janus-Pro-CXRæ˜¯é¦–ä¸ªç»è¿‡å¤šä¸­å¿ƒå‰ç»æ€§éªŒè¯çš„CXRæŠ¥å‘Šç”ŸæˆAIç³»ç»Ÿ**ï¼Œè¯å®å…¶åœ¨çœŸå®ä¸´åºŠç¯å¢ƒä¸­æœ‰æ•ˆæå‡æŠ¥å‘Šè´¨é‡å’Œå·¥ä½œæ•ˆç‡ã€‚
2. è½»é‡çº§ï¼ˆ1Bå‚æ•°ï¼‰è®¾è®¡å®ç°äº†é«˜æ€§èƒ½ä¸ä½éƒ¨ç½²é—¨æ§›çš„ç»Ÿä¸€ï¼Œç‰¹åˆ«é€‚ç”¨äºåŸºå±‚åŒ»ç–—æœºæ„ã€‚
3. AIè¾…åŠ©æ˜¾è‘—æé«˜åˆçº§æ”¾å°„ç§‘åŒ»ç”Ÿçš„è¡¨ç°ï¼š
   - æŠ¥å‘Šè´¨é‡â†‘0.25åˆ†ï¼ˆP<0.001ï¼‰
   - é˜…ç‰‡æ—¶é—´â†“18.3%
   - æ›´å—ä¸“å®¶é’çï¼ˆ54.3%èƒœå‡ºï¼‰
4. ç³»ç»Ÿå…·å¤‡è‰¯å¥½çš„å¤šå›¾å¤„ç†èƒ½åŠ›ï¼ˆå†å²å›¾åƒã€æ­£ä¾§ä½ï¼‰ï¼Œæ”¯æŒåŠ¨æ€å˜åŒ–åˆ†æã€‚
5. **è‚ºç‚è¯Šæ–­é˜³æ€§ç‡æå‡**ï¼šAIç»„ä¸º52.4%ï¼Œå¯¹ç…§ç»„ä¸º36.1%ï¼ˆP<0.001ï¼‰ï¼Œæç¤ºAIå¢å¼ºäº†åŒ»ç”Ÿå†³ç­–ä¿¡å¿ƒã€‚

### âš ï¸ å±€é™æ€§
1. **å¯¹ç»†å¾®æˆ–å¤æ‚å¾è±¡è¯†åˆ«èƒ½åŠ›æœ‰é™**ï¼šå¦‚è‚ºæ°´è‚¿ã€èƒ¸è†œå¢åšç­‰ä»éœ€æ”¹è¿›ã€‚
2. **çºµå‘å†å²å›¾åƒæ•´åˆåŠŸèƒ½å°šæœªå®Œå…¨å‰ç»æ€§éªŒè¯**ï¼šå› é•¿æœŸéšè®¿æ•°æ®ç§¯ç´¯å‘¨æœŸé•¿ã€‚
3. **å‚è€ƒæ ‡å‡†éâ€œé‡‘æ ‡å‡†â€**ï¼šä¾èµ–å·²å‘è¡¨æŠ¥å‘Šï¼Œå¯èƒ½å­˜åœ¨ä¸ªä½“åˆ¤æ–­åå·®ã€‚
4. **æœªä¸å…¶ä»–ä¸“ç”¨æ¨¡å‹ï¼ˆå¦‚MAIRA-2ã€CheXagentï¼‰ç›´æ¥æ¯”è¾ƒ**ï¼šå› å…¶ä¸å¼€æºæˆ–ç¡¬ä»¶è¦æ±‚è¿‡é«˜ã€‚
5. å½“å‰æ¨¡å¼ä¸ºâ€œAIç”Ÿæˆâ†’åŒ»ç”Ÿä¿®æ”¹â€ï¼Œå°šä¸èƒ½æ›¿ä»£äººå·¥å®¡æ ¸ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹å¯¹**ç»†å¾®ç—…å˜**çš„è¯†åˆ«èƒ½åŠ›ã€‚
2. æ¨è¿›**çºµå‘å›¾åƒåºåˆ—åˆ†æ**çš„å‰ç»æ€§éªŒè¯ã€‚
3. æ¢ç´¢æ›´é«˜çº§çš„äººæœºäº¤äº’æ¨¡å¼ï¼š
   - æ”¯æŒåŒå‘å®æ—¶å¯¹è¯ï¼ˆç±»ä¼¼èµ„æ·±ä¼šè¯Šä¸“å®¶ï¼‰
   - ä¸»åŠ¨æç¤ºæ½œåœ¨æ¼è¯Šæˆ–è¯¯è¯Š
4. æ„å»º**AIåˆç¨¿â†’ä¸Šçº§åŒ»å¸ˆç»ˆå®¡**çš„å·¥ä½œæµï¼Œè¿›ä¸€æ­¥å‹ç¼©æŠ¥å‘Šå‡ºå…·æ—¶é—´ã€‚
5. å°†è¯¥æ¡†æ¶æ‰©å±•è‡³å…¶ä»–å½±åƒæ¨¡æ€ï¼ˆCTã€MRIã€Ultrasoundï¼‰ï¼Œæ‰“é€ é€šç”¨åŒ»å­¦å½±åƒAIåŠ©æ‰‹ã€‚

---

## æ€»ç»“

> **Janus-Pro-CXRä¸ä»…æ˜¯æŠ€æœ¯çªç ´ï¼Œæ›´æ˜¯è¿ˆå‘â€œæ•°å­—åŒäº‹â€ï¼ˆdigital colleagueï¼‰çš„é‡è¦ä¸€æ­¥**ã€‚å®ƒé€šè¿‡è½»é‡åŒ–æ¶æ„ã€é¢†åŸŸä¼˜åŒ–å’Œä¸¥æ ¼çš„å‰ç»æ€§éªŒè¯ï¼Œå±•ç¤ºäº†AIåœ¨çœŸå®ä¸´åºŠåœºæ™¯ä¸­æå‡æ•ˆç‡ã€ä¿éšœè´¨é‡çš„å·¨å¤§æ½œåŠ›ï¼Œå°¤å…¶ä¸ºèµ„æºåŒ®ä¹åœ°åŒºæä¾›äº†å¯è¡Œè§£å†³æ–¹æ¡ˆã€‚å…¶å¼€æºç­–ç•¥ä¹Ÿå°†æ¨åŠ¨æ•´ä¸ªAIè¾…åŠ©æ”¾å°„å­¦é¢†åŸŸçš„é€æ˜åŒ–ä¸æ™®åŠåŒ–è¿›ç¨‹ã€‚

</details>

---

### 15. [SpidR: Learning Fast and Stable Linguistic Units for Spoken Language Models Without Supervision](https://arxiv.org/abs/2512.20308)

**Authors**: Maxime Poli, Mahi Luthra, Youssef Benchekroun, Yosuke Higuchi, Martin Gleize, Jiayi Shen, Robin Algayres, Yu-An Chung, Mido Assran, Juan Pino, Emmanuel Dupoux  
**Category**: cs.CL  
**Published**: 2025-12-24  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.20308v1  

#### Abstract
The parallel advances in language modeling and speech representation learning have raised the prospect of learning language directly from speech without textual intermediates. This requires extracting semantic representations directly from speech. Our contributions are threefold. First, we introduce...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSpidR: Learning Fast and Stable Linguistic Units for Spoken Language Models Without Supervision

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰çš„ **Spoken Language Model (SLM)** ä¸»è¦ä¾èµ–äºä»æ–‡æœ¬ä¸­é—´è¡¨ç¤ºï¼ˆå¦‚ASRè¾“å‡ºï¼‰è¿›è¡Œè®­ç»ƒï¼Œè€Œç†æƒ³çš„ç›®æ ‡æ˜¯ç›´æ¥ä»åŸå§‹è¯­éŸ³ä¿¡å·ä¸­å­¦ä¹ è¯­è¨€æ¨¡å‹ï¼Œå³â€œæ— ç›‘ç£å£è¯­å»ºæ¨¡â€ï¼ˆtextless spoken language modelingï¼‰ã€‚ç„¶è€Œï¼Œç°æœ‰çš„è‡ªç›‘ç£è¯­éŸ³è¡¨ç¤ºæ¨¡å‹ï¼ˆå¦‚ wav2vec 2.0ã€HuBERTï¼‰æå–çš„ç¦»æ•£è¯­éŸ³å•å…ƒï¼ˆspeech unitsï¼‰å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- å•å…ƒä¸ç¨³å®šï¼Œæ˜“å‘ç”Ÿ **codebook collapse**ï¼ˆç æœ¬åç¼©ï¼‰ï¼Œå¯¼è‡´èšç±»è´¨é‡ä¸‹é™ï¼›
- ç¼ºä¹å¯¹ **éŸ³ç´ ä¿¡æ¯** çš„ç¨³å®šç¼–ç èƒ½åŠ›ï¼Œéš¾ä»¥æ”¯æŒé«˜è´¨é‡çš„è¯­è¨€å»ºæ¨¡ï¼›
- é¢„è®­ç»ƒè€—æ—¶é•¿ï¼ˆå¦‚ HuBERT éœ€è¦ä¸€å‘¨ä»¥ä¸Šï¼‰ï¼Œé™åˆ¶äº†å¿«é€Ÿè¿­ä»£å’Œç ”ç©¶æ¢ç´¢ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šSpidR
ä½œè€…æå‡º **SpidR**ï¼ˆ**S**elf-distilled **P**redictive **R**epresentationsï¼‰ï¼Œä¸€ç§æ–°å‹çš„è‡ªç›‘ç£è¯­éŸ³è¡¨ç¤ºå­¦ä¹ æ¡†æ¶ï¼Œä¸“ä¸ºé«˜æ•ˆä¸”ç¨³å®šçš„ **spoken language modeling** è®¾è®¡ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
1. **æ”¹è¿›çš„ self-distillation + online clustering æ¶æ„**
   - å»¶ç»­ DinoSR çš„æ€æƒ³ï¼Œé‡‡ç”¨ **teacher-student æ¡†æ¶** å’Œ **æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆEMAï¼‰** æ›´æ–° teacherã€‚
   - å…³é”®æ”¹è¿›ï¼š**å­¦ç”Ÿç½‘ç»œçš„æ¯ä¸€å±‚ä¸­é—´è¡¨ç¤º**ï¼ˆintermediate layerï¼‰ç”¨äºé¢„æµ‹ **å¯¹åº”æ•™å¸ˆå±‚çš„ç æœ¬åˆ†é…**ï¼Œè€Œéä»…ç”¨æœ€åä¸€å±‚é¢„æµ‹æ‰€æœ‰å±‚ç›®æ ‡ã€‚
     > è¿™å¢å¼ºäº†å±‚çº§å¯¹é½ï¼Œæå‡äº†è®­ç»ƒç¨³å®šæ€§ï¼Œé˜²æ­¢ codebook collapseã€‚

2. **æ›´ç¨³å®šçš„è®­ç»ƒç›®æ ‡è®¾è®¡**
   - å¼•å…¥ **å¹³æ»‘çš„ EMA è¡°å‡è°ƒåº¦å™¨**ï¼ˆdecay scheduleï¼‰ï¼š`Î²(t) = 1 - (1-Î²â‚€)exp(-t/T)`ï¼Œé¿å…ä¼ ç»Ÿå›ºå®šå€¼å¸¦æ¥çš„ä¼˜åŒ–æ»åã€‚
   - ç§»é™¤æ³¨æ„åŠ›æ¨¡å—ä¸­çš„åç½®é¡¹ï¼ˆbias in Q/K/V projectionsï¼‰ï¼Œé˜²æ­¢è®­ç»ƒè¿‡ç¨‹ä¸­æ¢¯åº¦çˆ†ç‚¸ã€‚

3. **é«˜æ•ˆçš„çº¯ PyTorch å®ç°**
   - å¼€å‘äº†ä¸€ä¸ªè½»é‡çº§ã€åŸºäºåŸç”Ÿ PyTorch çš„ä»£ç åº“ï¼Œå…¼å®¹ `torch.compile`ï¼Œæ˜¾è‘—æå‡è®­ç»ƒååã€‚
   - æ”¯æŒåœ¨ **16å— A100 GPU ä¸Šä»…éœ€1å¤©å®Œæˆé¢„è®­ç»ƒ**ï¼ˆç›¸æ¯” HuBERT çš„62å°æ—¶ã€DinoSR çš„180å°æ—¶å¤§å¹…æé€Ÿï¼‰ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | SpidR vs. HuBERT/DinoSR |
|------|------------------------|
| **è®­ç»ƒé€Ÿåº¦** | å¿«è¾¾ **5â€“18å€**ï¼Œå•æ—¥å¯å®Œæˆé¢„è®­ç»ƒ |
| **è®­ç»ƒç¨³å®šæ€§** | æ˜¾è‘—å‡å°‘ codebook collapseï¼Œç æœ¬å¤šæ ·æ€§æ›´é«˜ |
| **ä¸‹æ¸¸ SLM æ€§èƒ½** | åœ¨ sWUGGYã€sBLIMPã€tSC ç­‰ä»»åŠ¡ä¸Šå…¨é¢è¶…è¶ŠåŸºçº¿ |
| **å·¥ç¨‹å‹å¥½æ€§** | å•é˜¶æ®µè®­ç»ƒï¼Œæ— éœ€å¤šè½®èšç±»ä¸æ ‡ç­¾ç”Ÿæˆ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **é¢„è®­ç»ƒæ•°æ®**ï¼šLibriSpeech 960 å°æ—¶éŸ³é¢‘ï¼ˆtrain-clean-100/360 + train-other-500ï¼‰
- **ä¸‹æ¸¸è¯­è¨€æ¨¡å‹è®­ç»ƒæ•°æ®**ï¼šLibri-Light çš„ 6k å­é›†ï¼ˆçº¦6000å°æ—¶æœªæ ‡æ³¨è¯­éŸ³ï¼‰
- **è¯„ä¼°æ•°æ®**ï¼šLibriSpeech dev-clean/dev-otherï¼Œç”¨äº ABXã€MAPã€SLM è¯„ä¼°

### æ¨¡å‹æ¶æ„
- **ç‰¹å¾æŠ½å–å™¨**ï¼š7å±‚å·ç§¯ï¼Œä¸‹é‡‡æ ·è‡³ 50Hzï¼ˆæ¯å¸§20msï¼‰
- **Transformer ç»“æ„**ï¼šBASE è§„æ¨¡ï¼ŒL=12 å±‚ï¼Œd=768 ç»´ï¼Œ12 å¤´æ³¨æ„åŠ›
- **ç æœ¬è®¾ç½®**ï¼šK=8 ä¸ªä¸­é—´å±‚å‚ä¸é¢„æµ‹ï¼Œæ¯ä¸ªå±‚ V=256 ä¸ªç å­—ï¼ˆcodewordsï¼‰

### è¯„ä¼°æŒ‡æ ‡

#### ï¼ˆ1ï¼‰è¿ç»­è¡¨ç¤ºè´¨é‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **ABX discriminability** | è¡¡é‡ triphone ä¸­å¤®éŸ³ç´ çš„åŒºåˆ†èƒ½åŠ›ï¼Œåˆ† within-speaker å’Œ across-speaker |
| **MAP words** | åŸºäºè¯çº§åˆ«çš„æ£€ç´¢å‡†ç¡®ç‡ï¼Œè¡¡é‡è¯çº§è¯­ä¹‰èšç±»è´¨é‡ |

#### ï¼ˆ2ï¼‰ç¦»æ•£å•å…ƒè´¨é‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **ABX (discrete)** | å¯¹ one-hot ç æœ¬åˆ†é…è®¡ç®— ABX é”™è¯¯ç‡ |
| **PNMI**ï¼ˆPhone Normalized Mutual Informationï¼‰ | è¡¡é‡ç¦»æ•£å•å…ƒä¸çœŸå®éŸ³ç´ æ ‡ç­¾ä¹‹é—´çš„äº’ä¿¡æ¯ï¼Œè¶Šé«˜è¶Šå¥½ |

#### ï¼ˆ3ï¼‰ä¸‹æ¸¸ SLM é›¶æ ·æœ¬æ€§èƒ½
| ä»»åŠ¡ | æè¿° |
|------|------|
| **sWUGGY** | åˆ¤æ–­çœŸè¯ vs. ä¼ªè¯ï¼ˆå¦‚ brick vs. blickï¼‰çš„æ¦‚ç‡é«˜ä½ |
| **sBLIMP** | åˆ¤æ–­è¯­æ³•æ­£ç¡®å¥ vs. é”™è¯¯å¥çš„æ¦‚ç‡ |
| **tSC**ï¼ˆtopic-based Story Clozeï¼‰ | åˆ¤æ–­æ•…äº‹ç»“å°¾æ˜¯å¦è¿è´¯ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **wav2vec 2.0**
- **HuBERT**
- **WavLM BASE**
- **DinoSR**ï¼ˆåŸç‰ˆåŠä½œè€…å¤ç°ï¼‰
- æ‰€æœ‰æ¨¡å‹ç»Ÿä¸€ä½¿ç”¨ç›¸åŒ batch sizeï¼ˆ63åˆ†é’ŸéŸ³é¢‘ï¼‰ã€OPT-125M ä½œä¸º SLM è§£ç å™¨

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ï¼ˆ1ï¼‰è¯­éŸ³è¡¨ç¤ºè´¨é‡ï¼ˆè¡¨2ï¼‰
åœ¨è¿ç»­è¡¨ç¤ºå±‚é¢ï¼ŒSpidR åœ¨ ABX å’Œ MAP æŒ‡æ ‡ä¸Šå‡ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼š

| Model | ABX (within) â†“ | ABX (across) â†“ | MAP words â†‘ |
|-------|----------------|---------------|-------------|
| wav2vec 2.0 | 4.47 | 5.25 | 44.81 |
| HuBERT | 3.38 | 4.01 | 46.07 |
| DinoSR | 4.05 | 4.72 | 63.02 |
| **SpidR** | **3.32** | **3.66** | **66.50** |

âœ… SpidR åœ¨éŸ³ç´ åˆ¤åˆ«æ€§å’Œè¯çº§æ£€ç´¢ä¸Šå‡è¾¾åˆ°æœ€ä¼˜ã€‚

---

### ï¼ˆ2ï¼‰ç¦»æ•£å•å…ƒè´¨é‡ä¸ SLM æ€§èƒ½ï¼ˆè¡¨3ï¼‰

| Model | Units | ABX â†“ | PNMI â†‘ | sWUGGY (all) â†‘ | sBLIMP â†‘ | tSC â†‘ |
|-------|-------|--------|--------|----------------|----------|--------|
| HuBERT | K-means | 7.32 | 0.637 | 65.50 | 55.60 | 68.75 |
| WavLM BASE | K-means | 7.01 | 0.667 | 69.74 | 56.60 | 70.35 |
| DinoSR | Codebook | 7.92 | 0.620 | 60.10 | 57.04 | 69.44 |
| **SpidR** | **K-means** | **7.20** | **0.636** | **71.89** | **59.48** | **70.46** |

âœ… SpidR åœ¨æ‰€æœ‰ä¸‰é¡¹ SLM ä»»åŠ¡ä¸Šå‡å–å¾—æœ€ä½³æ€§èƒ½ï¼Œå°¤å…¶åœ¨ **sWUGGY** ä¸Šé¢†å…ˆæ˜æ˜¾ã€‚

> æ³¨ï¼šå³ä½¿ä½¿ç”¨ codebook predictionï¼ˆé K-meansï¼‰ï¼ŒSpidR ä»ä¼˜äºå¤šæ•°åŸºçº¿ã€‚

---

### ï¼ˆ3ï¼‰æ•°æ®æ‰©å±•æ€§åˆ†æï¼ˆå›¾3ï¼‰
- åœ¨ä¸åŒè®­ç»ƒæ•°æ®é‡ï¼ˆ600h / 6k / 60kï¼‰ä¸‹ï¼ŒSpidR å§‹ç»ˆä¼˜äº HuBERTã€‚
- è™½ç„¶æ–œç‡ç›¸ä¼¼ï¼ˆscaling lawä¸€è‡´ï¼‰ï¼Œä½† SpidR å…·æœ‰æ’å®šæ€§èƒ½ä¼˜åŠ¿ã€‚
- æ–‡æœ¬åŸºçº¿ï¼ˆBPEï¼‰ä»æ˜¾è‘—ä¼˜äºæ‰€æœ‰è¯­éŸ³æ¨¡å‹ï¼Œè¯´æ˜å½“å‰ SLM ä»æœ‰æå‡ç©ºé—´ã€‚

---

### ï¼ˆ4ï¼‰æ¶ˆèå®éªŒï¼ˆè¡¨9 & å›¾2ï¼‰

| å˜ä½“ | ABX â†“ | MAP â†‘ | PNMI â†‘ |
|------|------|------|--------|
| DinoSR (reimpl.) | 5.91 | 42.55 | 0.614 |
| + Headsï¼ˆä¸­é—´å±‚é¢„æµ‹ï¼‰ | 4.22 | 63.39 | 0.610 |
| + Exp. EMAï¼ˆå¹³æ»‘è¡°å‡ï¼‰ | 5.86 | 51.85 | 0.609 |
| **å®Œæ•´ SpidR** | **3.92** | **60.88** | **0.602** |

âœ… **ä¸­é—´å±‚é¢„æµ‹å¤´ï¼ˆHeadsï¼‰** æ˜¯æ€§èƒ½æå‡çš„å…³é”®ï¼›å¹³æ»‘ EMA æœ‰åŠ©äºè®­ç»ƒç¨³å®šã€‚

æ­¤å¤–ï¼Œå›¾2æ˜¾ç¤ºï¼š
- DinoSR å‡ºç°æ˜æ˜¾çš„ **prediction perplexity ä¸‹é™ â†’ codebook collapse**
- SpidR çš„ perplexity æ›´å¹³ç¨³ï¼Œç æœ¬åˆ©ç”¨ç‡é«˜ï¼Œè®­ç»ƒæ›´ç¨³å®š

---

### ï¼ˆ5ï¼‰é¢„è®­ç»ƒæ•ˆç‡ï¼ˆè¡¨5ï¼‰
| Model | Pretraining Time | GPU Hours |
|-------|------------------|-----------|
| HuBERT | 62 hrs | 1984 |
| DinoSR (åŸç‰ˆ) | 180 hrs | 2880 |
| **SpidR (æœ¬æ–‡)** | **23 hrs** | **369** |

âœ… SpidR åœ¨ç›¸åŒç¡¬ä»¶ä¸‹å°†è®­ç»ƒæ—¶é—´ç¼©çŸ­è‡³ **ä¸åˆ°ä¸€å¤©**ï¼Œå¹¶å¼€æºä»£ç ä¸ checkpointã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **å±‚çº§å¯¹é½çš„ self-distillation æ˜¾è‘—æå‡è®­ç»ƒç¨³å®šæ€§**ï¼Œæœ‰æ•ˆç¼“è§£ codebook collapseã€‚
2. âœ… **éŸ³ç´ å¯è®¿é—®æ€§ï¼ˆphonetic accessibilityï¼‰å¼ºçš„è¡¨ç¤ºæ›´åˆ©äº SLM**ï¼ŒABX/PNMI æ˜¯å¯é çš„ä»£ç†æŒ‡æ ‡ã€‚
3. âœ… **SpidR åœ¨å¤šä¸ªé›¶æ ·æœ¬ SLM ä»»åŠ¡ä¸Šè¶…è¶Š wav2vec 2.0ã€HuBERTã€DinoSR å’Œ WavLM**ã€‚
4. âœ… **é«˜æ•ˆå®ç°æå¤§åŠ é€Ÿç ”ç©¶å‘¨æœŸ**ï¼Œä¸ºå¤šè¯­è¨€ã€ä½èµ„æºåœºæ™¯ä¸‹çš„ SLM ç ”ç©¶æä¾›åŸºç¡€ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ SpidR ä¸»è¦ä¼˜åŒ– **è¯­è¨€å†…å®¹å»ºæ¨¡**ï¼Œç‰ºç‰²äº†éƒ¨åˆ† **å£°å­¦ç»†èŠ‚** å’Œ **è¯´è¯äººä¿¡æ¯**ã€‚
- æœªå®ç°å®Œå…¨è§£è€¦çš„è¡¨ç¤ºï¼ˆå¦‚ prosodyã€speakerã€emotion åˆ†ç¦»ï¼‰ã€‚
- åœ¨ **ASR å¾®è°ƒä»»åŠ¡ä¸Šè¡¨ç°ä¸å¦‚ DinoSR æˆ– data2vec**ï¼ˆè§è¡¨10-11ï¼‰ï¼Œè¯´æ˜å…¶è¡¨ç¤ºåå‘ SLM è€Œéé€šç”¨è¯­éŸ³ä»»åŠ¡ã€‚

> â€œBetter performance on SLM does not imply better performance on ASR.â€  
> â€”â€” è¡¨æ˜ä¸åŒä»»åŠ¡éœ€è¦ä¸åŒçš„è¡¨ç¤ºåå¥½ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ„å»ºå¤šç²’åº¦ã€è§£è€¦çš„è¯­éŸ³è¡¨ç¤ºç³»ç»Ÿ**ï¼šåŒæ—¶å»ºæ¨¡è¯­è¨€ã€éŸµå¾‹ã€æƒ…æ„Ÿã€è¯´è¯äººç­‰ç»´åº¦ã€‚
2. **æ‰©å±•åˆ°å¤šè¯­è¨€å’Œä½èµ„æºè¯­è¨€**ï¼šåˆ©ç”¨ SpidR çš„é«˜æ•ˆæ€§è®­ç»ƒè·¨è¯­è¨€ SLMã€‚
3. **æ¢ç´¢æ›´å¤§è§„æ¨¡æ¨¡å‹ä¸ç”Ÿæ€åŒ–è¯­éŸ³å­¦ä¹ **ï¼šä» audiobook å‘çœŸå®å¯¹è¯ã€å™ªå£°ç¯å¢ƒæ‰©å±•ã€‚
4. **è®¾è®¡ä¸“é—¨é¢å‘ SLM çš„ benchmark å’Œè¯„ä¼°ä½“ç³»**ï¼Œæ¨åŠ¨ textless NLP å‘å±•ã€‚

---

> ğŸ”— **å¼€æºä¿¡æ¯**ï¼š  
> ä»£ç ä¸æ¨¡å‹å·²å¼€æºï¼š[https://github.com/facebookresearch/spidr](https://github.com/facebookresearch/spidr)

</details>

---

### 16. [Can LLMs Predict Their Own Failures? Self-Awareness via Internal Circuits](https://arxiv.org/abs/2512.20578)

**Authors**: Amirhosein Ghasemabadi, Di Niu  
**Category**: cs.CL  
**Published**: 2025-12-24  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.20578v1  

#### Abstract
Large language models (LLMs) generate fluent and complex outputs but often fail to recognize their own mistakes and hallucinations. Existing approaches typically rely on external judges, multi-sample consistency, or text-based self-critique, which incur additional compute or correlate weakly with tr...

---

### 17. [An Adaptive Distributed Stencil Abstraction for GPUs](https://arxiv.org/abs/2512.19851)

**Authors**: Aditya Bhosale, Laxmikant Kale  
**Category**: cs.DC  
**Published**: 2025-12-24  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.19851v1  

#### Abstract
The scientific computing ecosystem in Python is largely confined to single-node parallelism, creating a gap between high-level prototyping in NumPy and high-performance execution on modern supercomputers. The increasing prevalence of hardware accelerators and the need for energy efficiency have made...

---

### 18. [WOC: Dual-Path Weighted Object Consensus Made Efficient](https://arxiv.org/abs/2512.20485)

**Authors**: Tanisha Fonseca, Gengrui Zhang  
**Category**: cs.DC  
**Published**: 2025-12-24  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.20485v1  

#### Abstract
Modern distributed systems face a critical challenge: existing consensus protocols optimize for either node heterogeneity or workload independence, but not both. For example, Cabinet leverages weighted quorums to handle node heterogeneity but serializes all operations through a global leader, limiti...

---

### 19. [Scaling Point-based Differentiable Rendering for Large-scale Reconstruction](https://arxiv.org/abs/2512.20017)

**Authors**: Hexu Zhao, Xiaoteng Liu, Xiwen Min, Jianhao Huang, Youming Deng, Yanfei Li, Ang Li, Jinyang Li, Aurojit Panda  
**Category**: cs.DC  
**Published**: 2025-12-24  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.20017v1  

#### Abstract
Point-based Differentiable Rendering (PBDR) enables high-fidelity 3D scene reconstruction, but scaling PBDR to high-resolution and large scenes requires efficient distributed training systems. Existing systems are tightly coupled to a specific PBDR method. And they suffer from severe communication o...

---

### 20. [Predictive-LoRA: A Proactive and Fragmentation-Aware Serverless Inference System for LLMs](https://arxiv.org/abs/2512.20210)

**Authors**: Yinan Ni, Xiao Yang, Yuqi Tang, Zhimin Qiu, Chen Wang, Tingzhou Yuan  
**Category**: cs.DC  
**Published**: 2025-12-24  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.20210v1  

#### Abstract
The serverless computing paradigm offers compelling advantages for deploying Large Language Model (LLM) inference services, including elastic scaling and pay-per-use billing. However, serving multiple fine-tuned LLMs via Low-Rank Adaptation (LoRA) in serverless environments faces critical challenges...

---

### 21. [Resilient Packet Forwarding: A Reinforcement Learning Approach to Routing in Gaussian Interconnected Networks with Clustered Faults](https://arxiv.org/abs/2512.20394)

**Authors**: Mohammad Walid Charrwi, Zaid Hussain  
**Category**: cs.DC  
**Published**: 2025-12-24  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.20394v1  

#### Abstract
As Network-on-Chip (NoC) and Wireless Sensor Network architectures continue to scale, the topology of the underlying network becomes a critical factor in performance. Gaussian Interconnected Networks based on the arithmetic of Gaussian integers, offer attractive properties regarding diameter and sym...

---

### 22. [End-to-End Data Quality-Driven Framework for Machine Learning in Production Environment](https://arxiv.org/abs/2512.19723)

**Authors**: Firas Bayram, Bestoun S. Ahmed, Erik Hallin  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.19723v1  

#### Abstract
This paper introduces a novel end-to-end framework that efficiently integrates data quality assessment with machine learning (ML) model operations in real-time production environments. While existing approaches treat data quality assessment and ML systems as isolated processes, our framework address...

---

### 23. [Exploring Deep-to-Shallow Transformable Neural Networks for Intelligent Embedded Systems](https://arxiv.org/abs/2512.19731)

**Authors**: Xiangzhong Luo, Weichen Liu  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.19731v1  

#### Abstract
Thanks to the evolving network depth, convolutional neural networks (CNNs) have achieved remarkable success across various embedded scenarios, paving the way for ubiquitous embedded intelligence. Despite its promise, the evolving network depth comes at the cost of degraded hardware efficiency. In co...

---

### 24. [Case Prompting to Mitigate Large Language Model Bias for ICU Mortality Prediction](https://arxiv.org/abs/2512.19735)

**Authors**: Gangxiong Zhang, Yongchao Long  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.19735v1  

#### Abstract
Accurate mortality risk prediction for intensive care unit (ICU) patients is essential for clinical decision-making. Although large language models (LLMs) show promise in predicting outcomes from structured medical data, their predictions may exhibit demographic biases related to sex, age, and race,...

---

### 25. [DeepBridge: A Unified and Production-Ready Framework for Multi-Dimensional Machine Learning Validation](https://arxiv.org/abs/2512.19744)

**Authors**: Gustavo Coelho Haase, Paulo Henrique Dourado da Silva  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.19744v1  

#### Abstract
We present DeepBridge, an 80K-line Python library that unifies multi-dimensional validation, automatic compliance verification, knowledge distillation, and synthetic data generation. DeepBridge offers: (i) 5 validation suites (fairness with 15 metrics, robustness with weakness detection, uncertainty...

---

### 26. [Offline Safe Policy Optimization From Heterogeneous Feedback](https://arxiv.org/abs/2512.20173)

**Authors**: Ze Gong, Pradeep Varakantham, Akshat Kumar  
**Category**: cs.AI  
**Published**: 2025-12-24  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.20173v1  

#### Abstract
Offline Preference-based Reinforcement Learning (PbRL) learns rewards and policies aligned with human preferences without the need for extensive reward engineering and direct interaction with human annotators. However, ensuring safety remains a critical challenge across many domains and tasks. Previ...

---

### 27. [LongVideoAgent: Multi-Agent Reasoning with Long Videos](https://arxiv.org/abs/2512.20618)

**Authors**: Runtao Liu, Ziyi Liu, Jiaqi Tang, Yue Ma, Renjie Pi, Jipeng Zhang, Qifeng Chen  
**Category**: cs.AI  
**Published**: 2025-12-24  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.20618v1  

#### Abstract
Recent advances in multimodal LLMs and systems that use tools for long-video QA point to the promise of reasoning over hour-long episodes. However, many methods still compress content into lossy summaries or rely on limited toolsets, weakening temporal grounding and missing fine-grained cues. We pro...

---

### 28. [Hard Negative Sample-Augmented DPO Post-Training for Small Language Models](https://arxiv.org/abs/2512.19728)

**Authors**: Haocheng Lu, Minjun Zhu, Henry Yu  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.19728v1  

#### Abstract
Large language models (LLMs) continue to struggle with mathematical reasoning, and common post-training pipelines often reduce each generated solution to a binary outcome: correct or incorrect. This perspective is limiting in practice, as failures in chain-of-thought (CoT) reasoning are frequently s...

---

### 29. [Spatio-Temporal Graph Neural Networks for Dairy Farm Sustainability Forecasting and Counterfactual Policy Analysis](https://arxiv.org/abs/2512.19970)

**Authors**: Surya Jayakumar, Kieran Sullivan, John McLaughlin, Christine O'Meara, Indrakshi Dey  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.19970v1  

#### Abstract
This study introduces a novel data-driven framework and the first-ever county-scale application of Spatio-Temporal Graph Neural Networks (STGNN) to forecast composite sustainability indices from herd-level operational records. The methodology employs a novel, end-to-end pipeline utilizing a Variatio...

---

### 30. [Saddle-to-Saddle Dynamics Explains A Simplicity Bias Across Neural Network Architectures](https://arxiv.org/abs/2512.20607)

**Authors**: Yedi Zhang, Andrew Saxe, Peter E. Latham  
**Category**: cs.LG  
**Published**: 2025-12-24  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.20607v1  

#### Abstract
Neural networks trained with gradient descent often learn solutions of increasing complexity over time, a phenomenon known as simplicity bias. Despite being widely observed across architectures, existing theoretical treatments lack a unifying framework. We present a theoretical framework that explai...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
