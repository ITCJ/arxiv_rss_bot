# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-01-14 05:58:12 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Parallel Context-of-Experts Decoding for Retrieval Augmented Generation](https://arxiv.org/abs/2601.08670)

**Authors**: Giulio Corallo, Paolo Papotti  
**Category**: cs.AI  
**Published**: 2026-01-14  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2601.08670v1  

#### Abstract
Retrieval Augmented Generation faces a trade-off: concatenating documents in a long prompt enables multi-document reasoning but creates prefill bottlenecks, while encoding document KV caches separately offers speed but breaks cross-document interaction. We propose Parallel Context-of-Experts Decodin...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šParallel Context-of-Experts Decoding for Retrieval Augmented Generation**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
Retrieval Augmented Generation (RAG) é¢ä¸´ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼š
- **Prefill ç“¶é¢ˆ**ï¼šå°†å¤šä¸ªæ£€ç´¢åˆ°çš„æ–‡æ¡£æ‹¼æ¥æˆä¸€ä¸ªé•¿ä¸Šä¸‹æ–‡è¿›è¡Œæ¨ç†æ—¶ï¼Œprefill é˜¶æ®µè®¡ç®—å¼€é”€å·¨å¤§ï¼Œå¯¼è‡´å»¶è¿Ÿé«˜ã€‚
- **è·¨æ–‡æ¡£æ¨ç†èƒ½åŠ›ä¸‹é™**ï¼šè‹¥é‡‡ç”¨å¹¶è¡Œ KV cache ç¼–ç ï¼ˆå¦‚ç‹¬ç«‹ç¼–ç æ¯ä¸ªæ–‡æ¡£ï¼‰ï¼Œè™½å¯åŠ é€Ÿï¼Œä½†ç ´åäº†æ–‡æ¡£é—´çš„æ³¨æ„åŠ›äº¤äº’ï¼Œå‰Šå¼±äº†å¤šè·³æ¨ç†èƒ½åŠ›ã€‚

ç°æœ‰æ–¹æ³•åœ¨æ•ˆç‡ä¸å‡†ç¡®æ€§ä¹‹é—´å­˜åœ¨æ˜æ˜¾æƒè¡¡ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
ä½œè€…æå‡º **Parallel Context-of-Experts Decoding (PCED)**ï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„è§£ç æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å°†æ¯ä¸ªæ£€ç´¢åˆ°çš„æ–‡æ¡£è§†ä¸ºä¸€ä¸ªç‹¬ç«‹çš„â€œä¸“å®¶â€ï¼ˆExpertï¼‰ï¼Œå¹¶ç»´æŠ¤å„è‡ªçš„ KV cacheï¼›
- åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œå¹¶è¡Œè¿è¡Œè¿™äº›â€œä¸“å®¶â€ï¼Œå¹¶åœ¨æ¯ä¸€æ­¥é€šè¿‡ **retrieval-aware contrastive decoding** è§„åˆ™èšåˆå®ƒä»¬çš„è¾“å‡ºï¼›
- å°†è¯æ®èåˆä» **attention å±‚é¢** è½¬ç§»åˆ° **decoding å±‚é¢**ï¼Œä»è€Œé¿å…æ„å»ºå…±äº«ä¸Šä¸‹æ–‡ï¼ŒåŒæ—¶æ¢å¤è·¨æ–‡æ¡£æ¨ç†èƒ½åŠ›ã€‚

#### **ä¸‰å¤§åˆ›æ–°ç‚¹**ï¼š
1. **å¹¶è¡Œã€æ¨¡å—åŒ–çš„ KV cache æ¡†æ¶ + è§£ç æ—¶è¯æ®èšåˆ**  
   æ”¯æŒé«˜æ•ˆå¤ç”¨é¢„è®¡ç®—çš„ KV cacheï¼Œæ˜¾è‘—é™ä½ Time-To-First-Token (TTFT)ã€‚

2. **token-level expert switching**  
   æ¯ä¸ªç”Ÿæˆæ­¥åŠ¨æ€é€‰æ‹©æœ€å¯ä¿¡çš„ä¸“å®¶è¾“å‡ºï¼Œå®ç°è·¨æ–‡æ¡£æ¨ç†ï¼ˆå¦‚å›¾2æ‰€ç¤ºæ¨¡å‹åœ¨ä¸åŒæ–‡æ¡£é—´è·³è·ƒï¼‰ã€‚

3. **retrieval-integrated prior æ³¨å…¥ contrastive decoding**  
   åˆ©ç”¨æ£€ç´¢ç³»ç»Ÿæä¾›çš„ relevance scoreï¼ˆæ¥è‡ª dense/sparse/ColBERT æˆ– rerankerï¼‰ä½œä¸ºå…ˆéªŒï¼Œæ§åˆ¶å„ä¸“å®¶å¯¹æœ€ç»ˆ logits çš„å½±å“æƒé‡ï¼ŒæŠ‘åˆ¶å™ªå£°ä¸“å®¶å¹²æ‰°ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹æ³• | æ•ˆç‡ | è·¨æ–‡æ¡£æ¨ç† | æ˜¯å¦éœ€è®­ç»ƒ | å¤‡æ³¨ |
|------|------|-------------|------------|------|
| Concatenation (All) | ä½ | å¼º | å¦ | Prefill æˆæœ¬é«˜ |
| KV Merge (e.g., APE) | ä¸­ | è¾ƒå¼± | å¦ | è¯•å›¾æ¢å¤ attentionï¼Œæ•ˆæœæœ‰é™ |
| Agentic (e.g., MapReduce) | ä½ | å¼º | å¦ | å¤šè½®è°ƒç”¨ LLMï¼Œå»¶è¿Ÿé«˜ |
| **PCED (æœ¬æ–‡)** | **æé«˜** | **å¼º** | **å¦** | å•æ¬¡è§£ç å®Œæˆï¼Œå…¼å…·é€Ÿåº¦ä¸ç²¾åº¦ |

- **æ— éœ€è®­ç»ƒ**ï¼Œé€‚ç”¨äºä»»æ„å¼€æ”¾æƒé‡ LLMï¼›
- **æ”¯æŒå¤§è§„æ¨¡å€™é€‰æ–‡æ¡£è¾“å…¥**ï¼Œä¸å— context window é™åˆ¶ï¼›
- **æ›´é²æ£’äºæ— å…³å¹²æ‰°æ–‡æ¡£ï¼ˆdistractorsï¼‰**ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **LOFT benchmark**ï¼šæ¶µç›– RAG å’Œ In-Context Learning (ICL) ä»»åŠ¡ï¼Œå›ºå®š top-90 æ–‡æ¡£æ± ã€‚
- **LongBench**ï¼šå¤šè¯­è¨€ã€å¤šä»»åŠ¡é•¿ä¸Šä¸‹æ–‡ç†è§£åŸºå‡†ï¼Œæµ‹è¯•å•æ–‡æ¡£ä¸å¤šæ–‡æ¡£ QAã€æ‘˜è¦ã€ä»£ç è¡¥å…¨ç­‰ã€‚
- **åˆæˆæ•°æ®é›†**ï¼šç”¨äºæ€§èƒ½åŸºå‡†æµ‹è¯•ï¼ˆTTFT å’Œç«¯åˆ°ç«¯å»¶è¿Ÿï¼‰ï¼ŒåŒ…å« 64 ä¸ªæ–‡æ¡£ï¼ˆ1 ä¸ªå«â€œsecret codeâ€ï¼‰ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**
- **LLM æ¨¡å‹**ï¼š
  - ä¸»è¦ç»“æœï¼š`MISTRAL-NEMO-13B-INSTRUCT`, `LLAMA-3.1-8B-INSTRUCT`
  - LongBenchï¼š`QWEN3-8B`ï¼ˆæ‰©å±•è‡³ 128k ä¸Šä¸‹æ–‡ï¼‰
- **è§£ç æ–¹å¼**ï¼šgreedy decoding
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - RAG ä»»åŠ¡ï¼šSubspan Exact Match
  - ICL ä»»åŠ¡ï¼šExact Match
  - LongBenchï¼šå®˜æ–¹æŒ‡æ ‡

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| ç±»åˆ« | æ–¹æ³• |
|------|------|
| **æ ‡å‡†æ‹¼æ¥** | Corpus in Ctx (Single), Corpus in Ctx (All) |
| **KV cache åˆå¹¶** | APEï¼ˆAdaptive Parallel Encodingï¼‰ |
| **Agent-style èšåˆ** | MapReduceï¼ˆmap é˜¶æ®µæ‘˜è¦ â†’ reduce é˜¶æ®µèšåˆï¼‰ |
| **æœ¬æ–‡æ–¹æ³•** | PCEDï¼ˆSparse / Dense / ColBERT å˜ä½“ï¼‰ |

æ‰€æœ‰æ–¹æ³•ä½¿ç”¨ç›¸åŒçš„æ£€ç´¢ç»“æœã€prompt æ¨¡æ¿å’Œéšæœºç§å­ï¼Œä»…æ”¹å˜ä¸Šä¸‹æ–‡æ•´åˆæœºåˆ¶ã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1 & 2ï¼‰**

#### **åœ¨ LOFT ä¸Šçš„è¡¨ç°ï¼ˆä»¥ LLAMA-3.1-8B ä¸ºä¾‹ï¼‰**
| Task | APE | MapReduce | PCED-Dense | Corpus in Ctx (All) |
|------|-----|-----------|------------|---------------------|
| HOTPOTQA | 16.0 | 41.0 | **64.0** | 49.0 |
| MUSIQUE | 4.0 | 8.0 | **21.0** | 7.0 |
| RAG NQ | 9.0 | 50.0 | **85.0** | 58.0 |
| QAMPARI | 7.0 | 68.0 | **77.0** | 72.0 |
| QUEST | 0.0 | 41.0 | **45.0** | 39.0 |

> âœ… PCED åœ¨å¤šè·³é—®ç­”ä¸Šå¹³å‡æå‡ **+20~50 pts**ï¼Œè¿œè¶…å…¶ä»–å¹¶è¡Œæ–¹æ³•ã€‚

#### **åœ¨ LongBench ä¸Šçš„è¡¨ç°ï¼ˆQWEN3-8Bï¼‰**
| Task | Corpus in Ctx (All) | PCED-Dense |
|------|---------------------|------------|
| HOTPOTQA | 56.3 | **62.6** (+6.3) |
| 2WIKI | 44.2 | **49.4** (+5.2) |
| MUSIQUE | 25.3 | **33.4** (+8.1) |
| TRIVIAQA | 84.0 | **88.8** (+4.8) |
| REPOB-P (Code) | 51.1 | **60.1** (+9.0) |

> âœ… PCED åœ¨å¤šæ•°ä»»åŠ¡ä¸Š **è¶…è¶Š full-context æ‹¼æ¥æ–¹æ³•**ï¼Œå°¤å…¶åœ¨å¤šæ–‡æ¡£ QA å’Œä»£ç ä»»åŠ¡ä¸­è¡¨ç°çªå‡ºã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- **vs. KV Merge (APE)**ï¼šPCED å¹³å‡é«˜å‡º **40â€“70 pts**ï¼Œè¯æ˜å…¶æœ‰æ•ˆæ¢å¤äº†è·¨æ–‡æ¡£æ¨ç†èƒ½åŠ›ã€‚
- **vs. MapReduce**ï¼šPCED åœ¨å¤§å¤šæ•°ä»»åŠ¡ä¸Šæ›´ä¼˜ï¼ˆå¦‚ HOTPOTQA +23 ptsï¼‰ï¼Œä¸”åªéœ€ä¸€æ¬¡è§£ç ï¼Œè€Œ MapReduce éœ€å¤šæ¬¡ LLM æ¨ç†ã€‚
- **vs. Full Context (All)**ï¼šPCED åœ¨ 11/16 è®¾ç½®ä¸‹è¾¾åˆ°æˆ–è¶…è¿‡å…¶æ€§èƒ½ï¼Œå°½ç®¡æ¯ä¸ªæ–‡æ¡£ç‹¬ç«‹ç¼–ç ã€‚
- **æ•ˆç‡æ–¹é¢**ï¼š
  - **TTFT åŠ é€Ÿè¾¾ 180Ã—**ï¼ˆ0.14s vs 25.50sï¼‰
  - **ç«¯åˆ°ç«¯å»¶è¿Ÿé™ä½ ~1.7Ã—**ï¼ˆ65k contextï¼‰

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰**

#### **ç»„ä»¶åˆ†æï¼ˆTable 3 & 6ï¼‰**
| è®¾ç½® | HOTPOTQA (Llama) | NQ (Llama) |
|------|------------------|----------|
| Only Contrastive (Î³=0) | 46 | 52 |
| Only Retrieval Prior (Î²=0) | 53 | 70 |
| **Full PCED** | **64** | **85** |

> ğŸ” ç»“è®ºï¼š**retrieval prior æ˜¯åŸºç¡€**ï¼ˆé˜²æ­¢å™ªå£°å¹²æ‰°ï¼‰ï¼Œ**contrastive decoding æ˜¯æ”¾å¤§å™¨**ï¼ˆæŠ‘åˆ¶å¹»è§‰ï¼‰ã€‚

#### **å‚æ•°æ•æ„Ÿæ€§**
- **Î²ï¼ˆcontrastive strengthï¼‰**ï¼šåŠ¨æ€ç­–ç•¥ï¼ˆAdaCADï¼‰ä¼˜äºå›ºå®šå€¼ï¼Œæ›´å…·ç¨³å®šæ€§ã€‚
- **Î³ï¼ˆretrieval gatingï¼‰**ï¼šÎ³=2.5 ä¸ºæœ€ä¼˜å¹³è¡¡ç‚¹ï¼›è¿‡å°ï¼ˆ<1.5ï¼‰æ— æ³•æŠ‘åˆ¶å™ªå£°ï¼Œè¿‡å¤§ï¼ˆâ‰¥4.0ï¼‰è¿‡åº¦ä¾èµ–æ£€ç´¢æ’åºã€‚

#### **èšåˆè§„åˆ™æ¯”è¾ƒï¼ˆTable 7ï¼‰**
| èšåˆæ–¹å¼ | HOTPOTQA | NQ |
|--------|---------|----|
| Maxï¼ˆæœ¬æ–‡ï¼‰ | **64** | 85 |
| Mixture (MoE) | 56 | **87** |
| Product (PoE) | 46 | 85 |

> ğŸ“Œ **Max æ›´é€‚åˆå¤šè·³æ¨ç†**ï¼ˆsharp switchingï¼‰ï¼Œ**MoE æ›´é€‚åˆå•æ–‡æ¡£ä»»åŠ¡**ï¼ˆsoft fusionï¼‰ã€‚

#### **æŠ—å™ªèƒ½åŠ›ï¼ˆFigure 6ï¼‰**
- å½“ top-k ä» 8 å¢åŠ åˆ° 128ï¼ˆ16å€å¹²æ‰°é¡¹ï¼‰ï¼ŒPCED æ€§èƒ½å‡ ä¹ä¸å˜ï¼ˆå¦‚ NQ ç»´æŒ ~85ï¼‰ã€‚
- è¡¨æ˜ retrieval prior æœ‰æ•ˆæŠ‘åˆ¶äº† distractors å½±å“ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **è·¨æ–‡æ¡£æ¨ç†å¯åœ¨ decoding é˜¶æ®µé‡å»º**  
   ä¸éœ€è¦è”åˆ attention æˆ– KV cache åˆå¹¶ï¼Œé€šè¿‡ token-level expert switching å³å¯å®ç°è¯æ®æ‹¼æ¥ã€‚

2. **retrieval scores æ˜¯å®è´µçš„è§£ç å…ˆéªŒä¿¡å·**  
   åˆ©ç”¨æ£€ç´¢ç³»ç»Ÿçš„ relevance score æ˜¾è‘—æå‡å‡†ç¡®ç‡ï¼Œå°¤å…¶æ˜¯åœ¨å¤§é‡ distractors å­˜åœ¨æ—¶ã€‚

3. **PCED å®ç°äº†æ•ˆç‡ä¸æ€§èƒ½çš„åŒé‡çªç ´**  
   - é€Ÿåº¦ï¼šTTFT åŠ é€Ÿ **180Ã—**
   - ç²¾åº¦ï¼šåœ¨å¤šè·³ QA ä¸Šè¶…è¶Šç°æœ‰å¹¶è¡Œæ–¹æ³• **é«˜è¾¾ 70 pts**
   - é²æ£’æ€§ï¼šå¯¹æ— å…³æ–‡æ¡£ä¸æ•æ„Ÿ

4. **KV cache æ¨¡å—åŒ– + è§£ç æ—¶èåˆ æ˜¯å¯è¡Œè·¯å¾„**  
   ä¸ºæœªæ¥è®¾è®¡â€œå¯æ‰©å±• contextâ€ç³»ç»Ÿæä¾›äº†æ–°èŒƒå¼ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
1. **ä¾èµ–æ¨¡å‹ logits è¾“å‡º**  
   æ— æ³•åº”ç”¨äºä»…æä¾› sampled token æˆ– log-probabilities çš„ API-only æ¨¡å‹ï¼ˆå¦‚ GPT-4ï¼‰ã€‚

2. **å¯¹æ£€ç´¢è´¨é‡æ•æ„Ÿ**  
   è‹¥ç›¸å…³æ–‡æ¡£æœªè¢«æ£€ç´¢åˆ°æˆ–è¯„åˆ†è¿‡ä½ï¼Œåˆ™å¯¹åº” expert ä¼šè¢«å¿½ç•¥ï¼Œæ— æ³•æ¢å¤ç¼ºå¤±è¯æ®ã€‚

3. **å­˜å‚¨æˆæœ¬è¾ƒé«˜**  
   éœ€æŒä¹…åŒ–ä¿å­˜ FP16 æ ¼å¼çš„ KV cacheï¼Œä¾‹å¦‚ LOFT æ•°æ®é›†éœ€çº¦ **11GB å­˜å‚¨**ï¼Œé€‚åˆé™æ€çŸ¥è¯†åº“åœºæ™¯ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
- **ç«¯åˆ°ç«¯å­¦ä¹  expert selection**ï¼šè®© LLM è‡ªä¸»å†³å®šä½•æ—¶ä¿¡ä»»å“ªä¸ª contextï¼Œå‡å°‘å¯¹å¤–éƒ¨æ£€ç´¢ç³»ç»Ÿçš„ä¾èµ–ã€‚
- **è½»é‡åŒ– KV cache å­˜å‚¨**ï¼šæ¢ç´¢é‡åŒ–ã€å‹ç¼©æˆ–å¢é‡æ›´æ–°æœºåˆ¶ä»¥é™ä½å­˜å‚¨å¼€é”€ã€‚
- **é€‚é…é—­æºæ¨¡å‹**ï¼šè®¾è®¡è¿‘ä¼¼ contrastive decoding çš„é‡‡æ ·ç­–ç•¥ï¼Œä½¿å…¶èƒ½åœ¨ black-box API ä¸Šè¿‘ä¼¼å®ç° PCED æ•ˆæœã€‚

--- 

> ğŸ’¡ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **PCED æˆåŠŸå°† RAG çš„â€œè·¨æ–‡æ¡£æ¨ç†â€ä»æ˜‚è´µçš„ attention è®¡ç®—è½¬ç§»åˆ°é«˜æ•ˆçš„ decoding é€‰æ‹©æœºåˆ¶ï¼Œåœ¨ä¿æŒè®­ç»ƒè‡ªç”±çš„åŒæ—¶ï¼Œå®ç°äº†é€Ÿåº¦ä¸ç²¾åº¦çš„åŒé‡é£è·ƒã€‚**

</details>

---

### 2. [DiffMM: Efficient Method for Accurate Noisy and Sparse Trajectory Map Matching via One Step Diffusion](https://arxiv.org/abs/2601.08482)

**Authors**: Chenxu Han, Sean Bin Yang, Jilin Hu  
**Category**: cs.LG  
**Published**: 2026-01-14  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2601.08482v1  

#### Abstract
Map matching for sparse trajectories is a fundamental problem for many trajectory-based applications, e.g., traffic scheduling and traffic flow analysis. Existing methods for map matching are generally based on Hidden Markov Model (HMM) or encoder-decoder framework. However, these methods continue t...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*DiffMM: Efficient Method for Accurate Noisy and Sparse Trajectory Map Matching via One Step Diffusion*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**ç¨€ç–ä¸”å«å™ªå£°çš„GPSè½¨è¿¹æ•°æ®åœ¨å¤æ‚è·¯ç½‘ä¸­è¿›è¡Œé«˜ç²¾åº¦ã€é«˜æ•ˆç‡åœ°å›¾åŒ¹é…ï¼ˆMap Matchingï¼‰** çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„è§£å†³æ–¹æ¡ˆã€‚ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ HMM å’ŒåŸºäº RNN çš„ Seq2Seq æ¨¡å‹ï¼‰å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **å¯¹å™ªå£°æ•æ„Ÿ**ï¼šGPSæ¼‚ç§»å¯¼è‡´ç©ºé—´é‚»è¿‘æ€§å¤±æ•ˆï¼›
- **åœ¨ç¨€ç–è½¨è¿¹ä¸Šæ€§èƒ½ä¸‹é™ä¸¥é‡**ï¼šä½é‡‡æ ·ç‡ç ´åäº†æ—¶ç©ºè¿ç»­æ€§ï¼›
- **æ¨ç†æ•ˆç‡ä½**ï¼šè‡ªå›å½’è§£ç ï¼ˆautoregressive decodingï¼‰è€—æ—¶é•¿ï¼Œéš¾ä»¥å®æ—¶åº”ç”¨ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº† **DiffMM** â€”â€” ä¸€ç§åŸºäº **encoder-diffusion æ¶æ„** çš„æ–°å‹åœ°å›¾åŒ¹é…æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

1. **é¦–æ¬¡å°†æ‰©æ•£æ¨¡å‹å¼•å…¥åœ°å›¾åŒ¹é…ä»»åŠ¡**  
   å°† map matching å»ºæ¨¡ä¸ºä¸€ä¸ªä»å™ªå£°åˆ†å¸ƒæ¢å¤ç›®æ ‡é“è·¯æ®µåˆ†å¸ƒçš„ç”Ÿæˆè¿‡ç¨‹ï¼Œå¹¶é‡‡ç”¨ **conditional diffusion modeling** èŒƒå¼ã€‚

2. **è®¾è®¡äº†â€œé“è·¯æ®µæ„ŸçŸ¥â€çš„è½¨è¿¹ç¼–ç å™¨ï¼ˆroad segment-aware trajectory encoderï¼‰**  
   åˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶è”åˆåµŒå…¥è½¨è¿¹ç‚¹åŠå…¶å€™é€‰é“è·¯æ®µï¼Œæ„å»ºå…±äº«æ½œåœ¨è¡¨ç¤ºï¼ˆjoint embeddingï¼‰ï¼Œæœ‰æ•ˆèåˆç©ºé—´ä¸Šä¸‹æ–‡ä¸è¯­ä¹‰ä¿¡æ¯ã€‚

3. **æå‡ºåŸºäº shortcut model çš„ one-step diffusion æ–¹æ³•**  
   ä¸åŒäºä¼ ç»Ÿå¤šæ­¥æ‰©æ•£æ¨¡å‹ï¼ŒDiffMM ä½¿ç”¨ **one-step denoising** å®ç°é«˜æ•ˆæ¨ç†ï¼Œåœ¨ä»…ä¸€æ­¥å†…å®ŒæˆåŒ¹é…é¢„æµ‹ï¼Œæ˜¾è‘—æå‡é€Ÿåº¦ã€‚

4. **ç«¯åˆ°ç«¯å¯è®­ç»ƒæ¶æ„**  
   æ•´åˆ Trajectory Encoder ä¸ DiTï¼ˆDiffusion transformerï¼‰Backboneï¼Œå®ç°ç»Ÿä¸€ä¼˜åŒ–ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | DiffMM ä¼˜åŠ¿ |
|------|-------------|
| **å‡†ç¡®æ€§** | åœ¨é«˜åº¦ç¨€ç–è½¨è¿¹ä¸‹ä»ä¿æŒé«˜ç²¾åº¦ï¼Œä¼˜äº HMMã€DeepMM ç­‰ SOTA æ–¹æ³• |
| **æ•ˆç‡** | æ¨ç†é€Ÿåº¦å¿«è¾¾ **17å€ä»¥ä¸Š**ï¼ˆvs HMMï¼‰ï¼Œè®­ç»ƒæ—¶é—´æ¥è¿‘æœ€ä¼˜ |
| **é²æ£’æ€§** | å¯¹å™ªå£°å’Œç¨€ç–æ€§å…·æœ‰æ›´å¼ºå®¹å¿èƒ½åŠ› |
| **æ³›åŒ–æ€§** | åœ¨ä¸åŒåŸå¸‚è§„æ¨¡ï¼ˆPorto vs Beijingï¼‰ã€å¤æ‚è·¯ç½‘æ‹“æ‰‘ä¸­å‡è¡¨ç°ä¼˜å¼‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†
ä½¿ç”¨ä¸¤ä¸ªå¤§è§„æ¨¡çœŸå®å‡ºç§Ÿè½¦è½¨è¿¹æ•°æ®é›†ï¼š
- **Porto (PT)**ï¼šè‘¡è„ç‰™æ³¢å°”å›¾å¸‚ï¼Œè¾ƒå°åŸåŒºï¼Œ11.7Ã—5.2 kmÂ²ï¼Œçº¦101ä¸‡æ¡è½¨è¿¹
- **Beijing (BJ)**ï¼šåŒ—äº¬å¸‚ä¸­å¿ƒåŒºåŸŸï¼Œè¾ƒå¤§åŸåŒºï¼Œ29.6Ã—30.0 kmÂ²ï¼Œçº¦117ä¸‡æ¡è½¨è¿¹  
> è·¯ç½‘æ¥è‡ª OpenStreetMap

ä¸ºæ¨¡æ‹Ÿç¨€ç–åœºæ™¯ï¼Œå¯¹åŸå§‹è½¨è¿¹è¿›è¡Œéšæœºé™é‡‡æ ·ï¼Œå®šä¹‰é‡‡æ ·æ¯”ä¾‹ $ r \in (0,1) $ï¼Œå¹³å‡æ—¶é—´é—´éš”å¦‚ä¸‹ï¼š

| æ•°æ®é›† | r=0.5 | r=0.3 | r=0.2 | r=0.1 | r=0.05 | r=0.025 |
|--------|-------|-------|-------|-------|--------|---------|
| Porto | - | - | 300s | 600s | 300s | 600s |
| Beijing | 120s | 200s | 300s | 600s | - | - |

æ•°æ®åˆ’åˆ†ï¼š40%è®­ç»ƒ / 30%éªŒè¯ / 30%æµ‹è¯•

### ğŸ§ª å®éªŒè®¾ç½®
- **æœç´¢åŠå¾„**ï¼š50ç±³å†…å€™é€‰è·¯æ®µä½œä¸ºè¾“å…¥
- **æ¨¡å‹å‚æ•°**ï¼š
  - Embedding dim: 128 â†’ Condition dim: 256
  - Transformer Encoder: 2å±‚ï¼Œ4å¤´æ³¨æ„åŠ›
  - DiT Blocks: 2å±‚ï¼Œhidden dim=512
  - è®­ç»ƒ step size $ d \in \{1, 1/2\} $ï¼Œæ¨ç†ä½¿ç”¨ **M=1 æ­¥**ï¼ˆone-stepï¼‰
- **ç¡¬ä»¶å¹³å°**ï¼šå•å¼  NVIDIA RTX 3090 GPU

### ğŸ“ è¯„ä¼°æŒ‡æ ‡
- **Accuracy**ï¼šé¢„æµ‹è·¯æ®µåºåˆ—ä¸çœŸå®åŒ¹é…è·¯æ®µå®Œå…¨ä¸€è‡´çš„æ¯”ä¾‹
  $$
  \text{Accuracy}(R, \hat{R}) = \frac{1}{l} \sum_{i=1}^{l} \mathbb{I}[r_i = \hat{r}_i]
  $$

### âš”ï¸ åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | æè¿° |
|------|------|------|
| **HMM** | éå­¦ä¹ å‹ | ç»å…¸éšé©¬å°”å¯å¤«æ¨¡å‹ï¼Œä¾èµ–ç©ºé—´è·ç¦»ä¸è½¬ç§»æ¦‚ç‡ |
| **DeepMM** | å­¦ä¹ å‹ | åŸºäº RNN çš„ç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ æ–¹æ³• |
| **GraphMM** | å­¦ä¹ å‹ | å›¾ç¥ç»ç½‘ç»œæ–¹æ³•ï¼Œå»ºæ¨¡è½¨è¿¹é—´ç›¸å…³æ€§ |
| **RNTrajRec** | å­¦ä¹ å‹ | ç»“åˆè·¯ç½‘ç»“æ„çš„è½¨è¿¹æ¢å¤æ¨¡å‹ï¼ˆç”¨äº map matching åœºæ™¯ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å‡†ç¡®æ€§ç»“æœï¼ˆTable 2ï¼‰
åœ¨æ‰€æœ‰ç¨€ç–æ¡ä»¶ä¸‹ï¼Œ**DiffMM æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿æ–¹æ³•**ï¼Œå°¤å…¶åœ¨æç«¯ç¨€ç–æƒ…å†µä¸‹ä¼˜åŠ¿æ›´æ˜æ˜¾ã€‚

#### â¤ åŒ—äº¬æ•°æ®é›†ï¼ˆr=0.1ï¼Œå³å¹³å‡æ¯600ç§’ä¸€ä¸ªGPSç‚¹ï¼‰ï¼š
- **DiffMM**: **85.39%**
- ç¬¬äºŒå DeepMM: 68.25%
- **é¢†å…ˆå¹…åº¦é«˜è¾¾ +17.14ä¸ªç™¾åˆ†ç‚¹**

#### â¤ æ³¢ç‰¹æ•°æ®é›†ï¼ˆr=0.025ï¼Œæ¯600ç§’ä¸€ç‚¹ï¼‰ï¼š
- **DiffMM**: **86.87%**
- HMM ä¸‹é™è‡³ 40.04%ï¼Œè€Œ DiffMM ä»ç»´æŒé«˜ä½

> ğŸ’¡ è§‚å¯Ÿï¼šéšç€è½¨è¿¹å˜ç¨€ç–ï¼Œæ‰€æœ‰æ–¹æ³•æ€§èƒ½ä¸‹é™ï¼Œä½† **DiffMM ä¸‹é™æœ€ç¼“æ…¢**ï¼Œè¯´æ˜å…¶å¯¹ç¨€ç–æ€§å…·æœ‰æå¼ºé²æ£’æ€§ã€‚

---

### â± æ•ˆç‡å¯¹æ¯”ï¼ˆTable 3ï¼‰
| æ–¹æ³• | æ¨ç†æ—¶é—´ï¼ˆæ¯åƒæ¡è½¨è¿¹ï¼‰ | è®­ç»ƒæ—¶é—´ï¼ˆæ¯epochï¼‰ |
|------|------------------------|--------------------|
| HMM | 20.57 ç§’ | â€“ |
| DeepMM | 88.82 ç§’ | 9.07 åˆ†é’Ÿ |
| RNTrajRec | 627.65 ç§’ | 868.23 åˆ†é’Ÿ |
| **DiffMM (Ours)** | **1.18 ç§’** | **10.66 åˆ†é’Ÿ** |

âœ… **æ¨ç†é€Ÿåº¦æ¯”ç¬¬äºŒå¿«çš„ HMM å¿«çº¦ 17 å€**ï¼Œæ¯” DeepMM å¿«è¶…è¿‡ 75 å€ï¼  
âœ… è®­ç»ƒæ•ˆç‡ä¹Ÿæå…·ç«äº‰åŠ›ï¼Œè¿œè¶… RNTrajRecã€‚

---

### ğŸ” æ¶ˆèå®éªŒï¼ˆAblation Study, Table 4ï¼‰
åœ¨ Beijing æ•°æ®é›†ä¸ŠéªŒè¯å…³é”®æ¨¡å—ä½œç”¨ï¼š

| å˜ä½“ | r=0.5 | r=0.3 | r=0.2 | r=0.1 |
|------|-------|-------|-------|-------|
| w/o Transï¼ˆæ— Transformerï¼‰ | 90.06 | 88.33 | 87.12 | 84.89 |
| w/o Attnï¼ˆæ— æ³¨æ„åŠ›èåˆï¼‰ | 88.79 | 87.25 | 85.70 | 82.71 |
| w/o Shortcutï¼ˆä¼ ç»Ÿdiffusionï¼‰ | 89.67 | 87.92 | 86.84 | 83.53 |
| **DiffMMï¼ˆå®Œæ•´ï¼‰** | **90.32** | **88.45** | **87.65** | **85.39** |

ç»“è®ºï¼š
- **Transformer ç¼–ç å™¨**æœ‰åŠ©äºæ•æ‰ç¨€ç–è½¨è¿¹ä¸­çš„é•¿æœŸä¾èµ–ï¼›
- **æ³¨æ„åŠ›æœºåˆ¶**èƒ½æœ‰æ•ˆæŠ‘åˆ¶å™ªå£°å¹²æ‰°ï¼›
- **Shortcut model** æ˜¾è‘—ä¼˜äºä¼ ç»Ÿ diffusionï¼Œæ˜¯å®ç°é«˜æ•ˆ one-step æ¨ç†çš„å…³é”®ã€‚

---

### ğŸ›¡ é²æ£’æ€§åˆ†æï¼ˆTable 5ï¼‰
åœ¨ Porto æ•°æ®é›†ï¼ˆr=0.1ï¼‰ä¸Šå‡å°‘è®­ç»ƒæ ·æœ¬æ•°é‡ï¼Œæµ‹è¯•æ³›åŒ–èƒ½åŠ›ï¼š

| è®­ç»ƒæ ·æœ¬æ•° | 16k | 32k | 64k | 128k |
|------------|-----|-----|-----|------|
| Accuracy | 86.01% | 87.91% | 89.23% | 90.03% |

ğŸ“Œ å³ä½¿åªç”¨ **1.6ä¸‡æ¡è½¨è¿¹è®­ç»ƒ**ï¼Œå‡†ç¡®ç‡ä»è¾¾ **86.01%**ï¼Œ**è¶…è¿‡å…¶ä»–æ–¹æ³•åœ¨å…¨é‡æ•°æ®ä¸‹çš„è¡¨ç°**ï¼Œè¡¨æ˜ DiffMM å…·æœ‰å¾ˆå¼ºçš„æ•°æ®åˆ©ç”¨æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **DiffMM æ˜¯é¦–ä¸ªå°† diffusion model æˆåŠŸåº”ç”¨äº map matching çš„å·¥ä½œ**ï¼Œå¼€åˆ›äº†æ–°èŒƒå¼ã€‚
2. é€šè¿‡ **joint embedding + one-step diffusion**ï¼Œå®ç°äº†**ç²¾åº¦ä¸æ•ˆç‡çš„åŒé‡çªç ´**ã€‚
3. åœ¨**é«˜åº¦ç¨€ç–å’Œå™ªå£°ç¯å¢ƒä¸‹è¡¨ç°å“è¶Š**ï¼Œç‰¹åˆ«é€‚ç”¨äºå®é™…ä½é¢‘é‡‡æ ·åœºæ™¯ï¼ˆå¦‚å…±äº«å•è½¦ã€ç‰©æµè½¦è¾†ç­‰ï¼‰ã€‚
4. æ¨¡å‹å…·å¤‡è‰¯å¥½çš„**å¯æ‰©å±•æ€§å’Œé²æ£’æ€§**ï¼Œåœ¨ä¸åŒåŸå¸‚è§„æ¨¡å’Œæ•°æ®é‡ä¸‹å‡ç¨³å®šé¢†å…ˆã€‚

### âš  å±€é™æ€§
- å½“å‰æ¨¡å‹å‡è®¾å€™é€‰è·¯æ®µå¯é€šè¿‡å›ºå®šåŠå¾„ï¼ˆå¦‚50ç±³ï¼‰æ£€ç´¢ï¼Œè‹¥å­˜åœ¨ä¸¥é‡GPSæ¼‚ç§»è¶…å‡ºèŒƒå›´å¯èƒ½æ¼æ£€ï¼›
- è™½ç„¶ one-step æ¨ç†æå¿«ï¼Œä½†è®­ç»ƒä»éœ€ä¸€å®šè®¡ç®—èµ„æºï¼ˆå°½ç®¡å·²ä¼˜äºå¤šæ•°åŸºçº¿ï¼‰ï¼›
- æœªæ˜¾å¼å»ºæ¨¡è½¬å‘é™åˆ¶ã€å•è¡Œé“ç­‰é«˜çº§è·¯ç½‘çº¦æŸã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **trajectory recovery** ä»»åŠ¡ï¼Œé€šè¿‡ conditioned diffusion ç”Ÿæˆå¯†é›†è·¯å¾„ï¼›
- å¼•å…¥æ›´å¤š**åŠ¨æ€äº¤é€šä¿¡æ¯**ï¼ˆå¦‚æ‹¥å µçŠ¶æ€ï¼‰ä½œä¸ºæ¡ä»¶è¾“å…¥ï¼›
- æ¢ç´¢ **multi-modal diffusion** æˆ–ç»“åˆ LLM è¿›è¡Œè¯­ä¹‰å¢å¼ºçš„åœ°å›¾åŒ¹é…ï¼›
- æ”¯æŒåœ¨çº¿å¢é‡å­¦ä¹ ä»¥é€‚åº”åŠ¨æ€å˜åŒ–çš„åŸå¸‚è·¯ç½‘ã€‚

---

> ğŸ”— **ä»£ç å¼€æºåœ°å€**ï¼š[https://github.com/decisionintelligence/DiffMM](https://github.com/decisionintelligence/DiffMM)

</details>

---

### 3. [ZeroDVFS: Zero-Shot LLM-Guided Core and Frequency Allocation for Embedded Platforms](https://arxiv.org/abs/2601.08166)

**Authors**: Mohammad Pivezhandi, Mahdi Banisharif, Abusayeed Saifullah, Ali Jannesari  
**Category**: cs.AI  
**Published**: 2026-01-14  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2601.08166v1  

#### Abstract
Dynamic voltage and frequency scaling (DVFS) and task-to-core allocation are critical for thermal management and balancing energy and performance in embedded systems. Existing approaches either rely on utilization-based heuristics that overlook stall times, or require extensive offline profiling for...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠZeroDVFS: Zero-Shot LLM-Guided Core and Frequency Allocation for Embedded Platformsã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»ŸåµŒå…¥å¼ç³»ç»Ÿä¸­çš„ **Dynamic Voltage and Frequency Scaling (DVFS)** å’Œä»»åŠ¡åˆ°æ ¸å¿ƒåˆ†é…ï¼ˆtask-to-core allocationï¼‰ç­–ç•¥å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **åŸºäºåˆ©ç”¨ç‡çš„å¯å‘å¼æ–¹æ³•**ï¼ˆå¦‚Linux ondemand governorï¼‰å¿½ç•¥ stall timeï¼Œå¯¼è‡´é¢‘ç‡è°ƒèŠ‚ä¸å‡†ç¡®ã€‚
- **åŸºäºè¡¨æ ¼çš„ç¦»çº¿åˆ†ææ–¹æ³•**ï¼ˆå¦‚precise schedulerï¼‰éœ€è¦å¯¹æ‰€æœ‰é¢‘ç‡-æ ¸å¿ƒç»„åˆè¿›è¡Œè¯¦å°½çš„ profilingï¼Œè€—æ—¶é•¿è¾¾8â€“12å°æ—¶ï¼Œæ— æ³•é€‚åº”åŠ¨æ€å˜åŒ–çš„å·¥ä½œè´Ÿè½½ã€‚
- ç¼ºä¹å¯¹æ–°å·¥ä½œè´Ÿè½½çš„æ³›åŒ–èƒ½åŠ›ï¼Œéš¾ä»¥å®ç° **zero-shot éƒ¨ç½²**ã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº†åœ¨èµ„æºå—é™ã€åŠ¨æ€æ€§å¼ºçš„åµŒå…¥å¼å¹³å°ä¸Šçš„å®æ—¶è‡ªé€‚åº”è°ƒåº¦ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡º **ZeroDVFS** â€”â€” ä¸€ç§åŸºäºæ¨¡å‹çš„åˆ†å±‚å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰æ¡†æ¶ï¼Œç»“åˆå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¯­ä¹‰ç‰¹å¾æå–ï¼Œå®ç°çƒ­æ„ŸçŸ¥ä¸èƒ½æ•ˆä¼˜åŒ–çš„é›¶æ ·æœ¬è°ƒåº¦ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
1. **LLM-based Semantic Feature Extraction**
   - åˆ©ç”¨ LLMï¼ˆå¦‚ GPT-4oã€Claude Sonnetã€DeepSeek-V3ï¼‰ä» OpenMP æºç ä¸­æå– **13 ä¸ªä»£ç çº§è¯­ä¹‰ç‰¹å¾**ï¼ˆå¦‚ç®—æ³•å¤æ‚åº¦ã€å†…å­˜è®¿é—®æ¨¡å¼ã€å¹¶è¡Œå¼€é”€ç­‰ï¼‰ï¼Œæ— éœ€æ‰§è¡Œç¨‹åºã€‚
   - å®ç° **zero-shot ç‰¹å¾æå–**ï¼Œå•æ¬¡æˆæœ¬ä»… \$0.018/ç¨‹åºï¼Œè€—æ—¶ <5 ç§’ã€‚
   - æ”¯æŒè·¨å¹³å°è¿ç§»ï¼Œé¿å…é‡å¤ profilingã€‚

2. **Hierarchical Multi-Agent Reinforcement Learning (MARL)**
   - è®¾è®¡ä¸¤ä¸ªåä½œæ™ºèƒ½ä½“ï¼š
     - **Profiler Agent**ï¼šå†³å®šæ ¸å¿ƒæ•°é‡å’Œè¿è¡Œé¢‘ç‡ï¼Œä»¥æœ€å°åŒ–èƒ½è€—å’Œ makespanã€‚
     - **Temperature Agent**ï¼šåŸºäºæ¸©åº¦çŠ¶æ€ä¼˜å…ˆé€‰æ‹©è¾ƒå†·çš„æ ¸å¿ƒï¼Œé˜²æ­¢å±€éƒ¨è¿‡çƒ­ã€‚
   - åˆ†è§£æŒ‡æ•°çº§åŠ¨ä½œç©ºé—´ï¼Œé™ä½å†³ç­–å¤æ‚åº¦ã€‚

3. **Model-Based RL with Dyna-Q æ¶æ„**
   - å¼•å…¥ç¯å¢ƒæ¨¡å‹ï¼ˆregression-basedï¼‰é¢„æµ‹æ¸©åº¦å’Œæ€§èƒ½çŠ¶æ€ï¼Œç”Ÿæˆåˆæˆè®­ç»ƒæ•°æ®ã€‚
   - ç»“åˆçœŸå®æ•°æ®ä¸æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œè§„åˆ’ï¼ˆplanningï¼‰ï¼Œå®ç° **20Ã— æ›´å¿«æ”¶æ•›é€Ÿåº¦**ã€‚
   - æ”¯æŒ **few-shot è·¨å¹³å°è¿ç§»**ï¼Œæ— éœ€ç›®æ ‡å¹³å°å®Œæ•´ profilingã€‚

4. **Zero-Shot Deployment èƒ½åŠ›**
   - å°† LLM æå–çš„è¯­ä¹‰ç‰¹å¾ä¸ç¯å¢ƒæ¨¡å‹ç»“åˆï¼Œå¯åœ¨æœªè§è¿‡çš„æ–°å·¥ä½œè´Ÿè½½ä¸Šç›´æ¥éƒ¨ç½² RL è°ƒåº¦å™¨ï¼Œæ— éœ€ä»»ä½•ç›®æ ‡ç¡¬ä»¶ä¸Šçš„ profiling æ•°æ®ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚precise schedulerï¼‰ | ZeroDVFS |
|------|-------------------------------|--------|
| å†³ç­–å»¶è¿Ÿï¼ˆé¦–æ¬¡ï¼‰ | 8â€“12 å°æ—¶ï¼ˆprofilingï¼‰ | **3.5â€“8.0 ç§’**ï¼ˆå« LLM æå–ï¼‰ |
| åç»­å†³ç­–å»¶è¿Ÿ | ~1msï¼ˆæŸ¥è¡¨ï¼‰ | **358ms**ï¼ˆæ¨ç†ï¼‰ |
| é¦–æ¬¡å†³ç­–é€Ÿåº¦æå‡ | â€” | **8,300Ã— æ›´å¿«** |
| èƒ½æ•ˆ | åŸºå‡† | **7.09Ã— æ›´å¥½**ï¼ˆvs Linux ondemandï¼‰ |
| Makespan | è¾ƒé•¿ | **4.0Ã— æ›´ä¼˜** |
| æ³›åŒ–èƒ½åŠ› | æ— ï¼ˆéœ€é‡æ–° profilingï¼‰ | æ”¯æŒ zero-shot æ–° workload å’Œ cross-platform |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **BOTS (Barcelona OpenMP Tasks Suite)**ï¼šåŒ…å« FFTã€Strassenã€N-Queens ç­‰ä»»åŠ¡å¹¶è¡Œç¨‹åºã€‚
- **PolybenchC**ï¼šæ¶µç›–çº¿æ€§ä»£æ•°ã€Stencil è®¡ç®—ã€æ•°æ®æŒ–æ˜ç­‰å¾ªç¯å¹¶è¡Œå†…æ ¸ã€‚
- å…± **42 ä¸ª OpenMP åŸºå‡†ç¨‹åº**ï¼Œè¦†ç›–å¤šæ ·åŒ–çš„è®¡ç®—æ¨¡å¼å’Œå¹¶è¡Œç»“æ„ã€‚

---

### å®éªŒå¹³å°
| å¹³å° | æ¶æ„ | æ ¸å¿ƒæ•° | çƒ­åŒºæ•° |
|------|------|-------|-------|
| **Jetson TX2** | ARM Cortex-A57 + Denver 2 | 6 | 8 |
| **Jetson Orin NX** | ARM Cortex-A78AE | 8 | 9 |
| **RubikPi** | Qualcomm Kryo 585 | 8 | 36 |
| **Intel Core i7 (8th Gen)** | x86_64 | 4 | â€” |

æ‰€æœ‰å¹³å°å‡è¿è¡Œ Linuxï¼Œä½¿ç”¨ `cpufrequtils` æ§åˆ¶é¢‘ç‡ï¼Œç¦ç”¨ p-state/c-state è‡ªåŠ¨ç®¡ç†ã€‚

---

### è¯„ä¼°æŒ‡æ ‡
- **Energy Efficiency**ï¼šæ€»èƒ½è€—ï¼ˆmJï¼‰
- **Makespan**ï¼šä»»åŠ¡å®Œæˆæ—¶é—´ï¼ˆç§’ï¼‰
- **Temperature**ï¼šå¹³å‡æ ¸å¿ƒæ¸©åº¦ï¼ˆÂ°Cï¼‰
- **Decision Latency**ï¼šé¦–æ¬¡å†³ç­–ä¸åç»­å†³ç­–å»¶è¿Ÿ
- **Convergence Speed**ï¼šRL æ”¶æ•›æ‰€éœ€ episode æ•°
- **Cross-Platform Transfer Accuracy**ï¼šMAPEã€RÂ²

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | æè¿° |
|------|------|------|
| **Linux ondemand governor** | å¯å‘å¼ | åˆ©ç”¨ç‡é©±åŠ¨ï¼Œé˜ˆå€¼è§¦å‘é¢‘ç‡è°ƒæ•´ |
| **Precise Scheduler [7]** | è¡¨æ ¼æ³• | ç¦»çº¿ profiling æ‰€æœ‰é…ç½®ï¼Œç”Ÿæˆ lookup table |
| **zTT [30]** | å•æ™ºèƒ½ä½“ RL | åŸºäºæ¨¡å‹æ— å…³çš„ RLï¼Œå…³æ³¨çƒ­èŠ‚æµ |
| **GearDVFS** | å¯å‘å¼ | åŠ¨æ€é¢‘ç‡è°ƒèŠ‚ï¼Œä½†æ— æ ¸å¿ƒåˆ†é… |
| **HiDVFS_S, MAML, SAMBRL** ç­‰ | å¤šç§ RL å˜ä½“ | ç”¨äºæ¶ˆèå®éªŒå’Œæ€§èƒ½å¯¹æ¯” |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æŒ‡æ ‡ | ZeroDVFS | Precise Scheduler | zTT | Linux ondemand |
|------|---------|------------------|-----|---------------|
| **Energy (mJ)** | **9.1** | 75.5 | 31.2 | ~64.5 |
| **Makespan (s)** | **1.13** | 5.96 | 1.88 | ~4.52 |
| **Avg Temp (Â°C)** | 42.1 | 44.0 | 43.6 | ~45.0 |
| **é¦–æ¬¡å†³ç­–å»¶è¿Ÿ** | 3.5â€“8.0s | 8â€“12h | ~10ms | ~1ms |
| **åç»­å†³ç­–å»¶è¿Ÿ** | **358ms** | ~1ms | ~10ms | ~1ms |
| **æ”¶æ•›é€Ÿåº¦** | 20 episodes | ä¸é€‚ç”¨ï¼ˆé™æ€ï¼‰ | ~50 episodes | ~50 episodes |

> æ³¨ï¼šZeroDVFS åœ¨ **èƒ½é‡æ•ˆç‡ä¸Šæå‡ 7.09Ã—**ï¼Œ**makespan ç¼©çŸ­ 4.0Ã—**ï¼Œç›¸æ¯” Linux ondemandã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **Energy Efficiency**ï¼š
  - ZeroDVFS æ¯” Precise Scheduler èŠ‚çœ **85.9% èƒ½é‡**ã€‚
  - æ¯” zTT èŠ‚çœ **70.8% èƒ½é‡**ã€‚
- **Makespan**ï¼š
  - æ¯” Precise Scheduler å¿« **5.3Ã—**ã€‚
  - æ¯” GearDVFS å¿« **8.7Ã—**ï¼ˆè§å›¾6ï¼‰ã€‚
- **å†³ç­–å»¶è¿Ÿ**ï¼š
  - é¦–æ¬¡å†³ç­–æ¯”è¡¨æ ¼æ³•å¿« **8,300Ã—**ã€‚
  - åç»­å†³ç­–æ¯”è¡¨æ ¼æ³•å¿« **80,000Ã—**ï¼ˆå› æ— éœ€é‡ç”Ÿæˆè¡¨ï¼‰ã€‚
- **æ”¶æ•›é€Ÿåº¦**ï¼š
  - æ¨¡å‹é©±åŠ¨æ–¹æ³•ï¼ˆDyna-Qï¼‰æ¯”çº¯ model-free RL å¿« **20Ã— æ”¶æ•›**ã€‚

---

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰æ¨¡å‹é©±åŠ¨ vs. æ¨¡å‹æ— å…³ RL
- **MAMBRL D3QNï¼ˆæ¨¡å‹é©±åŠ¨ï¼‰**ï¼šæ”¶æ•›æ›´å¿«ï¼ˆ20 episodesï¼‰ï¼Œç¨³å®šæ€§é«˜ã€‚
- **MAMFRL D3QNï¼ˆæ¨¡å‹æ— å…³ï¼‰**ï¼šæœ€ç»ˆæ€§èƒ½æ¥è¿‘ï¼Œä½†æ–¹å·®æ›´å¤§ï¼Œæ”¶æ•›æ…¢ï¼ˆ~40 episodesï¼‰ã€‚
- ç»“è®ºï¼š**ç¯å¢ƒå»ºæ¨¡æ˜¾è‘—æå‡æ ·æœ¬æ•ˆç‡**ã€‚

#### ï¼ˆ2ï¼‰LLM ç‰¹å¾æœ‰æ•ˆæ€§åˆ†æ
- **ç‰¹å¾é‡è¦æ€§æ’åº**ï¼ˆXGBoostï¼‰ï¼š
  1. `energy_main_j`ï¼ˆ28.5%ï¼‰
  2. `context_switches`ï¼ˆ22.3%ï¼‰
  3. `energy_system_j`ï¼ˆ16.6%ï¼‰
  4. `instructions`ï¼ˆ7.2%ï¼‰
  5. `cache_references`ï¼ˆ2.7%ï¼‰
  - LLM ç‰¹å¾ä¸­ï¼Œ`cache_behavior-pattern`ï¼ˆ1.03%ï¼‰ã€`data_dependency-type`ï¼ˆ0.57%ï¼‰è¿›å…¥å‰15ã€‚
- **zero-shot æ³›åŒ–èƒ½åŠ›**ï¼š
  - ä½¿ç”¨ LLM ç‰¹å¾åï¼Œå¯å¯¹ä»æœªè®­ç»ƒè¿‡çš„ç¨‹åºè¿›è¡Œé¢„æµ‹ã€‚
  - è‹¥ä»…ç”¨è¯­æ³•ç‰¹å¾ï¼ˆTree-sitterï¼‰ï¼Œè·¨ç¨‹åºæ³›åŒ–èƒ½åŠ›å‡ ä¹ä¸ºé›¶ã€‚

#### ï¼ˆ3ï¼‰è·¨å¹³å°è¿ç§»æ•ˆæœï¼ˆTable 5ï¼‰
| è¿ç§»è·¯å¾„ | MAPE | RÂ² |
|--------|------|----|
| TX2 â†’ Orin NX | 64.5% | 0.90 |
| TX2 â†’ RubikPi | 73.2% | 0.80 |

- å°½ç®¡ MAPE è¾ƒé«˜ï¼Œä½† **RÂ² > 0.8** è¡¨æ˜ç›¸å¯¹æ’åºä¿æŒè‰¯å¥½ï¼Œè¶³ä»¥æ”¯æŒæœ‰æ•ˆè°ƒåº¦ã€‚
- åŠ å…¥ **10 ä¸ª fine-tuning æ ·æœ¬** åï¼ŒMAPE ä¸‹é™çº¦ 5%ï¼ŒéªŒè¯ few-shot å¾®è°ƒçš„æœ‰æ•ˆæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **LLM å¯æœ‰æ•ˆæå–è¯­ä¹‰ç‰¹å¾**ï¼Œæ›¿ä»£ä¼ ç»Ÿ profilingï¼Œå®ç° **zero-shot æ€§èƒ½é¢„æµ‹**ã€‚
2. **æ¨¡å‹é©±åŠ¨çš„ MARL æ¡†æ¶** æ˜¾è‘—åŠ é€Ÿ RL æ”¶æ•›ï¼ˆ20Ã—ï¼‰ï¼Œå¹¶æ”¯æŒè·¨å¹³å°è¿ç§»ã€‚
3. **ZeroDVFS åœ¨èƒ½æ•ˆå’Œæ€§èƒ½ä¸Šå…¨é¢è¶…è¶Šç°æœ‰æ–¹æ³•**ï¼š
   - èƒ½é‡æ•ˆç‡æå‡ **7.09Ã—**
   - Makespan ç¼©çŸ­ **4.0Ã—**
   - å†³ç­–å»¶è¿Ÿæ¯”è¡¨æ ¼æ³•å¿« **8,300Ã—**
4. **é¦–æ¬¡å†³ç­–å»¶è¿Ÿå¯æ§**ï¼ˆ<8sï¼‰ï¼Œé€‚åˆå®é™…éƒ¨ç½²ï¼›åç»­å†³ç­–ç¨³å®šåœ¨ **358ms**ã€‚
5. **è·¨å¹³å°è¿ç§»å¯è¡Œ**ï¼Œå³ä½¿å­˜åœ¨æ¶æ„å·®å¼‚ï¼ˆARM vs. x86ï¼‰ï¼Œä»èƒ½ä¿æŒè¾ƒé«˜ RÂ²ï¼ˆ0.8â€“0.9ï¼‰ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **å½“å‰ä»…æ”¯æŒå• DAG OpenMP å·¥ä½œè´Ÿè½½**ï¼Œä¸é€‚ç”¨äºå¹¶å‘æˆ–å¤šè¿›ç¨‹åœºæ™¯ã€‚
2. **LLM ç‰¹å¾æå–é™äºå•æ–‡ä»¶ç¨‹åº**ï¼Œå¤šæ–‡ä»¶é¡¹ç›®éœ€æ‰‹åŠ¨æ‹¼æ¥æˆ–åˆ†å±‚åˆ†æã€‚
3. **zero-shot è·¨å¹³å° MAPE è¾ƒé«˜**ï¼ˆ64â€“73%ï¼‰ï¼Œä»éœ€å°‘é‡ fine-tuning æå‡ç²¾åº¦ã€‚
4. **ä¾èµ–å•†ä¸š LLM API**ï¼ˆå¦‚ GPT-4oï¼‰ï¼Œå¯èƒ½å¸¦æ¥æˆæœ¬å’Œç½‘ç»œä¾èµ–é—®é¢˜ã€‚
5. **ç¼ºä¹ç½®ä¿¡åŒºé—´é‡åŒ–**ï¼Œå®éªŒé‡å¤æ¬¡æ•°æœ‰é™ï¼Œç»Ÿè®¡æ˜¾è‘—æ€§æœ‰å¾…åŠ å¼ºã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. æ‰©å±•è‡³ **å¹¶å‘ workload å’Œå¤šä»»åŠ¡è°ƒåº¦** åœºæ™¯ã€‚
2. æ”¯æŒ **multi-file é¡¹ç›®è‡ªåŠ¨åˆ†æ**ï¼Œå¼•å…¥æ¨¡å—åŒ– LLM æ¨ç†ã€‚
3. æ¢ç´¢ **fine-tuned LLM on HPC corpus**ï¼Œæå‡ä»£ç ç†è§£å‡†ç¡®æ€§ã€‚
4. ç ”ç©¶ **GPU offloading å†³ç­–**ï¼Œæ‰©å±•è‡³å¼‚æ„åŠ é€Ÿå™¨è°ƒåº¦ã€‚
5. å®ç° **æœ¬åœ°åŒ– LLM éƒ¨ç½²**ï¼ˆå¦‚ DeepSeek-Coderã€CodeLlamaï¼‰ï¼Œæ”¯æŒå®Œå…¨ç¦»çº¿è¾¹ç¼˜è®¾å¤‡è¿è¡Œã€‚
6. å¼€å±•æ›´ä¸¥æ ¼çš„ **å¤šéšæœºç§å­ç»Ÿè®¡åˆ†æ**ï¼Œå¢å¼ºç»“æœå¯ä¿¡åº¦ã€‚
7. æ¢ç´¢ **confidence-aware prediction**ï¼Œä¸ºæ¯ä¸ª LLM ç‰¹å¾æä¾›ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚

---

> âœ… **ä¸€å¥è¯æ€»ç»“**ï¼š  
> ZeroDVFS é€šè¿‡ **LLM è¯­ä¹‰ç‰¹å¾ + æ¨¡å‹é©±åŠ¨ MARL**ï¼Œå®ç°äº†åµŒå…¥å¼å¹³å°ä¸Š **æ— éœ€ profiling çš„é›¶æ ·æœ¬æ ¸å¿ƒä¸é¢‘ç‡è°ƒåº¦**ï¼Œå…¼å…·é«˜æ€§èƒ½ã€é«˜èƒ½æ•ˆä¸å¿«é€Ÿéƒ¨ç½²èƒ½åŠ›ï¼Œä¸ºåŠ¨æ€åµŒå…¥å¼ç³»ç»Ÿæä¾›äº†å…¨æ–°çš„æ™ºèƒ½åŒ–è°ƒåº¦èŒƒå¼ã€‚

</details>

---

### 4. [Prism: Towards Lowering User Cognitive Load in LLMs via Complex Intent Understanding](https://arxiv.org/abs/2601.08653)

**Authors**: Zenghua Liao, Jinzhi Liao, Xiang Zhao  
**Category**: cs.AI  
**Published**: 2026-01-14  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2601.08653v1  

#### Abstract
Large Language Models are rapidly emerging as web-native interfaces to social platforms. On the social web, users frequently have ambiguous and dynamic goals, making complex intent understanding-rather than single-turn execution-the cornerstone of effective human-LLM collaboration. Existing approach...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šPrism: Towards Lowering User Cognitive Load in LLMs via Complex Intent Understanding**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å½“å‰ Large Language Modelsï¼ˆLLMsï¼‰åœ¨å¤„ç†ç”¨æˆ·æ„å›¾æ—¶ï¼Œé€šå¸¸å‡è®¾æ¾„æ¸…é—®é¢˜æ˜¯**å¹¶è¡Œä¸”ç‹¬ç«‹**çš„ï¼ˆå¦‚ Mistral-Interact å’Œ ITIU æ‰€é‡‡ç”¨çš„æ–¹æ³•ï¼‰ï¼Œè¿™åœ¨ç®€å•ä»»åŠ¡ä¸­æœ‰æ•ˆï¼Œä½†åœ¨**å¤æ‚æ„å›¾åœºæ™¯**ä¸‹å­˜åœ¨ä¸¥é‡ç¼ºé™·ã€‚ä¾‹å¦‚ï¼Œåœ¨è§„åˆ’æ—…è¡Œæ—¶ï¼Œâ€œæ´»åŠ¨å»ºè®®â€ä¾èµ–äºâ€œç›®çš„åœ°â€çš„é€‰æ‹©ï¼Œè‹¥æœªå…ˆç¡®è®¤ç›®çš„åœ°å°±æ¨èâ€œåäºŒæœˆå†²ç»³æ½œæ°´â€ï¼Œåˆ™ä¼šäº§ç”Ÿé€»è¾‘å†²çªã€‚

è¿™ç§å¿½ç•¥**æ¾„æ¸…é—®é¢˜é—´é€»è¾‘ä¾èµ–å…³ç³»**çš„è®¾è®¡ä¼šå¢åŠ ç”¨æˆ·çš„**è®¤çŸ¥è´Ÿè·ï¼ˆCognitive Loadï¼‰**ï¼Œè¿«ä½¿ç”¨æˆ·è‡ªè¡Œç®¡ç†å¤æ‚çš„å†³ç­–æµç¨‹ï¼Œä»è€Œé™ä½äº¤äº’æ•ˆç‡å’Œæ»¡æ„åº¦ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯**
ä½œè€…æå‡º **Prism**ï¼Œä¸€ä¸ªåŸºäº**è®¤çŸ¥è´Ÿè·ç†è®ºï¼ˆCognitive Load Theory, CLTï¼‰** çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡**é€»è¾‘è¿è´¯çš„æ„å›¾æ¾„æ¸…**æ¥é™ä½ç”¨æˆ·è®¤çŸ¥è´Ÿæ‹…ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†å¤æ‚æ„å›¾è§†ä¸ºâ€œç™½å…‰â€ï¼Œé€šè¿‡â€œæ£±é•œâ€ï¼ˆå³é€»è¾‘é©±åŠ¨çš„ç»“æ„åŒ–æ¨¡å¼ï¼‰å°†å…¶åˆ†è§£ä¸ºæœ‰åºçš„â€œå…‰è°±â€å…ƒç´ ï¼Œä»è€Œå¼•å¯¼åˆ†å±‚ã€æœ‰åºçš„æ¾„æ¸…è¿‡ç¨‹ã€‚

#### **Prism çš„å››å¤§æ¨¡å—è®¾è®¡**ï¼š
1. **Complex Intent Decomposition Module**  
   æ„å»º **CID æ•°æ®é›†**ï¼ˆå« 27 ä¸ªé¢†åŸŸã€429 ä¸ªæ„å›¾ï¼‰ï¼Œæ˜¾å¼æ ‡æ³¨æ„å›¾å…ƒç´ é—´çš„**å‰ç½®ä¾èµ–å…³ç³»**ï¼Œæ”¯æŒå¯¹æ¨¡ç³Šæ„å›¾è¿›è¡Œç»“æ„åŒ–è§£æ„ã€‚

2. **Logical Clarification Generation Module**  
   åŸºäºå…ƒç´ å±‚çº§ç»„ç»‡æ¾„æ¸…é¡ºåºï¼š**ç‹¬ç«‹é—®é¢˜å¹¶è¡Œå‘ˆç°**ï¼ˆå¦‚è¡¨æ ¼å½¢å¼ï¼‰ï¼Œ**ä¾èµ–é—®é¢˜æŒ‰åºæé—®**ï¼Œç¡®ä¿é€»è¾‘ä¸€è‡´æ€§ã€‚

3. **Intent-Aware Reward Module**  
   è®¾è®¡**æ„å›¾æ„ŸçŸ¥å¥–åŠ±å‡½æ•°**ï¼ˆIntent-Aware Rewardï¼‰ï¼Œç»“åˆ token-level çš„**æ„å›¾é‡è¦æ€§**ï¼ˆIntent Importanceï¼‰ä¸**ç”Ÿæˆç½®ä¿¡åº¦**ï¼ˆGeneration Confidenceï¼‰ï¼Œå¹¶é€šè¿‡ **Monte Carlo Sampling** æ¨¡æ‹Ÿå¤§è§„æ¨¡äººæœºäº¤äº’ä»¥ç”Ÿæˆé«˜è´¨é‡è®­ç»ƒæ•°æ®ã€‚

4. **Self-Evolved Intent Tuning Module**  
   é‡‡ç”¨**è‡ªæ¼”è¿›æ„å›¾è°ƒä¼˜**ç­–ç•¥ï¼Œåˆ©ç”¨é«˜å¥–åŠ±è½¨è¿¹è¿­ä»£ä¼˜åŒ– LLMï¼Œæ— éœ€äººå·¥æ ‡æ³¨å³å¯æŒç»­æå‡æ¨¡å‹èƒ½åŠ›ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- **é¦–æ¬¡ç³»ç»Ÿå»ºæ¨¡æ¾„æ¸…é—®é¢˜ä¹‹é—´çš„é€»è¾‘ä¾èµ–**ï¼Œçªç ´äº†ä¼ ç»Ÿæ–¹æ³•å¯¹â€œç‹¬ç«‹é—®é¢˜â€çš„éšå«å‡è®¾ã€‚
- å¼•å…¥ **CLT ç†è®ºæŒ‡å¯¼äº¤äº’è®¾è®¡**ï¼Œä»è®¤çŸ¥ç§‘å­¦è§’åº¦ä¼˜åŒ–ç”¨æˆ·ä½“éªŒã€‚
- å®ç°**é€»è¾‘ä¸€è‡´æ€§ä¸äº¤äº’æ•ˆç‡çš„å¹³è¡¡**ï¼šæ—¢å‡å°‘å†—ä½™è½®æ¬¡ï¼Œåˆé¿å…å› è·³æ­¥å¯¼è‡´çš„ä¸åˆç†å»ºè®®ã€‚
- æ”¯æŒ**å¯æ‰©å±•çš„è‡ªæˆ‘è¿›åŒ–è®­ç»ƒæœºåˆ¶**ï¼Œæ˜¾è‘—é™ä½å¯¹äººå·¥æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
å®éªŒåœ¨ä¸‰ä¸ªä¸»æµæ„å›¾ç†è§£æ•°æ®é›†ä¸Šè¿›è¡Œï¼š
- **TIN** [14]ï¼š200 æ¡æµ‹è¯•æ ·æœ¬ï¼Œæ¶µç›–å¤šé¢†åŸŸå¤æ‚ä»»åŠ¡ã€‚
- **IN3** [21]ï¼š108 æ¡æµ‹è¯•æ ·æœ¬ï¼Œå¼ºè°ƒå¤šè½®æ¾„æ¸…ã€‚
- **ABP** [36]ï¼š319 æ¡æµ‹è¯•æ ·æœ¬ï¼Œè¦†ç›–å¹¿æ³›çœŸå®ä¸–ç•Œè§„åˆ’ä»»åŠ¡ã€‚

æ‰€æœ‰æµ‹è¯•é›†å‡è¢«æ‰‹åŠ¨åˆ’åˆ†ä¸º **ç®€å•æ„å›¾** ä¸ **å¤æ‚æ„å›¾** åœºæ™¯ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹åœ¨ä¸åŒéš¾åº¦ä¸‹çš„è¡¨ç°ã€‚

### **å®éªŒè®¾ç½®**
- **ä¸»å¹²æ¨¡å‹**ï¼š`Mistral-7B-Instruct-v0.3` å’Œ `LLaMA-3.1-8B-Instruct`
- **Prism å˜ä½“**ï¼š`Prism-SFT`ï¼ˆç›‘ç£å¾®è°ƒï¼‰ã€`Prism-DPO`ï¼ˆç›´æ¥åå¥½ä¼˜åŒ–ï¼‰
- **è®­ç»ƒæ–¹å¼**ï¼šå…¨å‚æ•°å¾®è°ƒ + DPOï¼Œä½¿ç”¨ 8Ã—80GB A100 GPUï¼Œè€—æ—¶çº¦ 14.5 å°æ—¶
- **ç”¨æˆ·æ¨¡æ‹Ÿå™¨**ï¼šåŸºäº LLM æ„å»ºï¼Œç”¨äºé«˜æ•ˆç”Ÿæˆå‰å‘é‡‡æ ·å¯¹è¯è·¯å¾„

### **è¯„ä¼°ç»´åº¦ä¸æŒ‡æ ‡**

| ç»´åº¦ | æŒ‡æ ‡ |
|------|------|
| **Clarification Interaction** | Intents Cover Rate, Logical Conflict Rate, Average Interaction Turns, Options Presenting/Reasonable Rate |
| **Intent Execution** | IBLEU, Faithfulï¼ˆå¿ å®åº¦ï¼‰, Unnecessary Sub-tasks (US), General Sub-tasks (GS), Tool Invocations (TI) |
| **Cognitive Load** | è¡Œä¸ºæŒ‡æ ‡ï¼ˆä»»åŠ¡æ—¶é—´ã€token æ•°é‡ï¼‰ã€ä¸»è§‚è¯„åˆ†ï¼ˆ1â€“10 åˆ†ï¼‰ã€ç”Ÿç†æŒ‡æ ‡ï¼ˆEEG åŠŸç‡è°±å¯†åº¦ PSDï¼‰ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **Mistral-Interact** [21]ï¼šåŸºäº Q&A å¯¹çš„é€è½®æ¾„æ¸…
- **ITIU** [14]ï¼šåŸºäºäº¤äº’è¡¨æ ¼çš„å¹¶è¡Œæé—®
- **CoLLABLLM** [32]ï¼šå¼ºè°ƒç”¨æˆ·å‚ä¸çš„å¤šè½®å¥–åŠ±å»ºæ¨¡

æ‰€æœ‰æ–¹æ³•ç»Ÿä¸€ä½¿ç”¨ç›¸åŒä¸»å¹²æ¨¡å‹è¿›è¡Œå…¬å¹³æ¯”è¾ƒã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… **Clarification Interaction ç»“æœï¼ˆè§ Table 1, 7, 8ï¼‰**
| æŒ‡æ ‡ | Prism-DPO è¡¨ç° |
|------|----------------|
| **Logical Conflict Rate (%) â†“** | **11.5%**ï¼ˆæœ€ä½ï¼Œè¿œä¼˜äº ITIU çš„ 53.0%ï¼‰ |
| **Intents Cover Rate (%) â†‘** | æœ€é«˜è¾¾ **74.85%**ï¼ˆIN3 å¤æ‚åœºæ™¯ï¼‰ |
| **Average Interaction Turns â†“** | **1.5â€“1.8 è½®**ï¼Œæ¥è¿‘ ITIU æ•ˆç‡ |
| **Options Reasonable Rate (%) â†‘** | è¾¾ **93.05%**ï¼ˆIN3 å¤æ‚åœºæ™¯ï¼‰ |

> åœ¨å¤æ‚æ„å›¾åœºæ™¯ä¸‹ï¼ŒPrism æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼Œå°¤å…¶åœ¨é€»è¾‘ä¸€è‡´æ€§æ–¹é¢å®ç°è´¨çš„é£è·ƒã€‚

#### âœ… **Intent Execution ç»“æœï¼ˆè§ Table 2ï¼‰**
| åœºæ™¯ | æŒ‡æ ‡ | Prism-DPO vs Baseline æå‡ |
|------|------|----------------------------|
| **å¤æ‚æ„å›¾** | Faithful â†‘ | **+21.16%** |
| **å¤æ‚æ„å›¾** | US (Unnecessary Sub-tasks) â†“ | **2.36 â†’ 2.27** |
| **å¤æ‚æ„å›¾** | GS (General Sub-tasks) â†“ | **0.37 â†’ 0.35** |
| **å¤æ‚æ„å›¾** | TI (Tool Invocations) â†“ | **4.26 â†’ 3.12**ï¼Œé™å¹… **22.26%** |

> Prism ä¸Šæ¸¸çš„é€»è¾‘æ¾„æ¸…æ˜¾è‘—æå‡äº†ä¸‹æ¸¸ä»£ç†ï¼ˆXAgentï¼‰çš„ä»»åŠ¡æ‰§è¡Œæ•ˆç‡ä¸å‡†ç¡®æ€§ã€‚

#### âœ… **Cognitive Load å®éªŒç»“æœï¼ˆè§ Figure 3 & 4ï¼‰**
| æŒ‡æ ‡ | Prism è¡¨ç° |
|------|-----------|
| **å¹³å‡ä»»åŠ¡å®Œæˆæ—¶é—´ â†“** | æ¯” Mistral-Interact å‡å°‘ **34.8%** |
| **æ€» Token æ•° â†“** | æ§åˆ¶åœ¨ **<1000**ï¼Œä¿¡æ¯æ›´ç´§å‡‘ |
| **ç”¨æˆ·æ»¡æ„åº¦è¯„åˆ† â†‘** | å¹³å‡ **8.35**ï¼ˆæ»¡åˆ† 10ï¼‰ï¼Œ88.6% ç”¨æˆ·è¯„ä¸ºâ€œè‰¯å¥½ä»¥ä¸Šâ€ |
| **EEG PSD æ°´å¹³ â†“** | æ˜¾ç¤ºå¤§è„‘æ´»è·ƒåº¦æœ€ä½ï¼Œè®¤çŸ¥è´Ÿè·æœ€å° |

> ç”¨æˆ·åœ¨ä¸ Prism äº¤äº’æ—¶æ›´è½»æ¾ã€é«˜æ•ˆï¼Œä¸”æ»¡æ„åº¦éšè½®æ¬¡ä¸Šå‡ï¼Œè¡¨æ˜å…¶äº¤äº’è®¾è®¡å…·æœ‰æ­£å‘ç´¯ç§¯æ•ˆåº”ã€‚

### **æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰**
è™½ç„¶æ–‡ä¸­æœªå•ç‹¬åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»æ¨¡å—è®¾è®¡å’Œè‡ªæ¼”è¿›è¿‡ç¨‹å¯æ¨æ–­ï¼š
- **CID æ•°æ®é›†çš„ä½œç”¨**ï¼šæä¾›ç»“æ„åŒ–ä¾èµ–å…ˆéªŒï¼Œæ˜¯å®ç°é€»è¾‘åˆ†è§£çš„åŸºç¡€ã€‚
- **Intent-Aware Reward çš„æœ‰æ•ˆæ€§**ï¼šé€šè¿‡ token-level å¥–åŠ±ç­›é€‰é«˜è´¨é‡è½¨è¿¹ï¼Œæ”¯æ’‘æ— ç›‘ç£æ•°æ®ç”Ÿæˆã€‚
- **Self-Evolved Tuning çš„å¢ç›Š**ï¼šå¤šè½®è¿­ä»£ä½¿æ¨¡å‹é€æ­¥æŒæ¡æ·±å±‚é€»è¾‘æ¨ç†èƒ½åŠ›ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **é€»è¾‘ä¾èµ–å»ºæ¨¡è‡³å…³é‡è¦**ï¼šåœ¨å¤æ‚æ„å›¾åœºæ™¯ä¸­ï¼Œå¿½è§†é—®é¢˜é—´çš„ä¾èµ–ä¼šå¯¼è‡´å¤§é‡é€»è¾‘å†²çªï¼Œä¸¥é‡å½±å“ç”¨æˆ·ä½“éªŒã€‚
2. **Prism å®ç°äº†é€»è¾‘æ€§ä¸æ•ˆç‡çš„ç»Ÿä¸€**ï¼šæ—¢èƒ½ä¿æŒä½äº¤äº’è½®æ¬¡ï¼ˆâ‰ˆ1.6 è½®ï¼‰ï¼Œåˆèƒ½ä¿è¯é«˜åº¦é€»è¾‘ä¸€è‡´ï¼ˆå†²çªç‡ä»… 11.5%ï¼‰ã€‚
3. **æ˜¾è‘—é™ä½ç”¨æˆ·è®¤çŸ¥è´Ÿè·**ï¼šè¡Œä¸ºã€ä¸»è§‚ã€ç”Ÿç†ä¸‰ç±»æŒ‡æ ‡ä¸€è‡´è¯æ˜ Prism æ›´â€œçœåŠ›â€ã€â€œæ˜“ç”¨â€ã€‚
4. **å…·å¤‡å¼ºæ³›åŒ–èƒ½åŠ›**ï¼šåœ¨ TINã€IN3ã€ABP ä¸‰å¤§æ•°æ®é›†åŠä¸¤ç§ä¸»å¹²æ¨¡å‹ä¸Šå‡å–å¾— SOTA æ€§èƒ½ã€‚
5. **æ¨åŠ¨ LLM æˆä¸ºçœŸæ­£åä½œè€…**ï¼šPrism ä¸å†è¢«åŠ¨å“åº”ï¼Œè€Œæ˜¯ä¸»åŠ¨ã€æœ‰æ¡ç†åœ°å¼•å¯¼ç”¨æˆ·æ˜ç¡®ç›®æ ‡ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ– CID æ•°æ®é›†çš„è´¨é‡ä¸è¦†ç›–èŒƒå›´**ï¼šå¯¹äºå…¨æ–°é¢†åŸŸæˆ–æç«¯ç½•è§æ„å›¾ï¼Œfew-shot æ„é€ å¯èƒ½å¤±æ•ˆã€‚
- **ç”¨æˆ·æ¨¡æ‹Ÿå™¨çš„ä¿çœŸåº¦é™åˆ¶**ï¼šå°½ç®¡å¼•å…¥äº†é£æ ¼æ¨¡ä»¿ï¼Œä½†ä»æ— æ³•å®Œå…¨å¤ç°çœŸå®äººç±»çš„ä¸ç¡®å®šæ€§ä¸æƒ…ç»ªæ³¢åŠ¨ã€‚
- **å®æ—¶æ€§æŒ‘æˆ˜**ï¼šMonte Carlo Sampling å’Œå¤šè½®è‡ªæ¼”è¿›è®­ç»ƒæˆæœ¬è¾ƒé«˜ï¼Œéƒ¨ç½²é—¨æ§›ç•¥é«˜ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ‰©å±• CID è‡³æ›´å¤šå‚ç›´é¢†åŸŸï¼ˆå¦‚åŒ»ç–—ã€æ³•å¾‹ï¼‰ã€‚
- æ¢ç´¢è½»é‡åŒ–ç‰ˆæœ¬ä»¥é€‚åº”è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²ã€‚
- å¼•å…¥å¤šæ¨¡æ€åé¦ˆï¼ˆè¯­éŸ³ã€è¡¨æƒ…ï¼‰è¿›ä¸€æ­¥ä¸°å¯Œè®¤çŸ¥è´Ÿè·è¯„ä¼°ã€‚
- ç»“åˆè®°å¿†æœºåˆ¶å®ç°è·¨ä¼šè¯æ„å›¾è¿½è¸ªã€‚

---

> ğŸ”š **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **Prism é¦–æ¬¡å°†è®¤çŸ¥è´Ÿè·ç†è®ºç³»ç»Ÿåº”ç”¨äº LLM æ„å›¾ç†è§£ï¼Œé€šè¿‡ç»“æ„åŒ–è§£æ„ä¸é€»è¾‘é©±åŠ¨çš„æ¾„æ¸…æµç¨‹ï¼Œåœ¨ä¸ç‰ºç‰²æ•ˆç‡çš„å‰æä¸‹å¤§å¹…é™ä½ç”¨æˆ·å¿ƒæ™ºè´Ÿæ‹…ï¼Œå®ç°äº†æ›´è‡ªç„¶ã€æ›´æ™ºèƒ½çš„äººæœºåä½œèŒƒå¼ã€‚**

</details>

---

### 5. [Hierarchical Precision and Recursion for Accelerating Symmetric Linear Solves on MXUs](https://arxiv.org/abs/2601.08082)

**Authors**: Vicki Carrica, Rabab Alomairy, Evelyne Ringoot, Alan Edelman  
**Category**: cs.DC  
**Published**: 2026-01-14  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2601.08082v1  

#### Abstract
Symmetric linear solves are fundamental to a wide range of scientific and engineering applications, from climate modeling and structural analysis to machine learning and optimization. These workloads often rely on Cholesky (POTRF) decomposition and its supporting operations, triangular solves (TRSM)...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Hierarchical Precision and Recursion for Accelerating Symmetric Linear Solves on MXUs*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¯¹ç§°æ­£å®šçº¿æ€§ç³»ç»Ÿï¼ˆSymmetric Positive Definite, SPDï¼‰çš„æ±‚è§£åœ¨ç§‘å­¦è®¡ç®—ã€æœºå™¨å­¦ä¹ ç­‰é¢†åŸŸä¸­è‡³å…³é‡è¦ï¼Œå…¶æ ¸å¿ƒæ˜¯ **Cholesky åˆ†è§£**ï¼ˆPOTRFï¼‰ï¼Œä¾èµ–äº **TRSM**ï¼ˆä¸‰è§’çŸ©é˜µæ±‚è§£ï¼‰å’Œ **SYRK**ï¼ˆå¯¹ç§°ç§©-kæ›´æ–°ï¼‰ç­‰å¯†é›†çº¿æ€§ä»£æ•°æ“ä½œã€‚ä¼ ç»Ÿæ–¹æ³•é€šå¸¸é‡‡ç”¨ç»Ÿä¸€é«˜ç²¾åº¦ï¼ˆå¦‚ FP64ï¼‰ï¼Œéš¾ä»¥å……åˆ†åˆ©ç”¨ç°ä»£ AI åŠ é€Ÿå™¨ï¼ˆå¦‚ NVIDIA Tensor Cores å’Œ AMD Matrix Coresï¼‰æä¾›çš„ä½ç²¾åº¦ï¼ˆå¦‚ FP16ï¼‰é«˜æ€§èƒ½ã€‚

ç„¶è€Œï¼Œç›´æ¥ä½¿ç”¨ä½ç²¾åº¦ä¼šå¸¦æ¥æ•°å€¼ä¸ç¨³å®šæ€§å’Œç²¾åº¦æŸå¤±ï¼Œé™åˆ¶äº†å…¶åœ¨ç§‘å­¦è®¡ç®—ä¸­çš„åº”ç”¨ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§**å¯ç§»æ¤çš„æ··åˆç²¾åº¦å¯¹ç§°çº¿æ€§æ±‚è§£å™¨**ï¼Œä¸“ä¸º **Matrix Processing Units (MXUs)** è®¾è®¡ï¼Œæ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰åµŒå¥—é€’å½’ç®—æ³•è®¾è®¡ï¼ˆNested Recursive Algorithmï¼‰
- å°†ä¼ ç»Ÿçš„ä»…å¯¹è§’å—é€’å½’çš„ Cholesky åˆ†è§£æ‰©å±•ä¸º**å®Œå…¨åµŒå¥—é€’å½’ç»“æ„**ï¼Œå°† POTRFã€TRSM å’Œ SYRK å…¨éƒ¨é€’å½’åŒ–ã€‚
- é¦–æ¬¡å®ç°äº† **GPU ä¸Šçš„é€’å½’ SYRK**ï¼Œå¹¶ç»“åˆå·²æœ‰çš„é€’å½’ TRSMï¼Œå½¢æˆå®Œæ•´çš„é€’å½’åˆ†è§£è·¯å¾„ã€‚
- è¯¥ç»“æ„æ˜¾è‘—å¢åŠ äº† GEMM æ“ä½œçš„æ¯”ä¾‹ï¼Œæå‡å¹¶è¡Œåº¦å’Œç¡¬ä»¶åˆ©ç”¨ç‡ï¼Œç‰¹åˆ«é€‚åˆ MXUsã€‚

#### ï¼ˆ2ï¼‰æ ‘çŠ¶åˆ†å±‚æ··åˆç²¾åº¦ç­–ç•¥ï¼ˆTree-Structured Mixed Precisionï¼‰
- å¼•å…¥ä¸€ç§åŸºäºé€’å½’æ ‘ç»“æ„çš„**åˆ†å±‚ç²¾åº¦åˆ†é…æœºåˆ¶**ï¼š
  - å¤§å‹éå¯¹è§’å—ï¼ˆoff-diagonal blocksï¼‰ä½¿ç”¨ **FP16** ä»¥æœ€å¤§åŒ–ååï¼›
  - å¯¹è§’å—ï¼ˆdiagonal blocksï¼‰ä¿ç•™ **FP32 æˆ– FP64** ä»¥ä¿è¯æ•°å€¼ç¨³å®šæ€§ã€‚
- è¿™ç§â€œå¤–å±‚ä½ç²¾åº¦ã€å†…å±‚é«˜ç²¾åº¦â€çš„è®¾è®¡ï¼Œåœ¨æ€§èƒ½ä¸ç²¾åº¦ä¹‹é—´å®ç°ç²¾ç»†å¹³è¡¡ã€‚

#### ï¼ˆ3ï¼‰å—çº§é‡åŒ–ä¸åé‡åŒ–ï¼ˆBlockwise Quantization & Dequantizationï¼‰
- ä¸ºç¼“è§£ FP16 åŠ¨æ€èŒƒå›´æœ‰é™çš„é—®é¢˜ï¼Œåœ¨æ¯å±‚é€’å½’ä¸­å¼•å…¥è½»é‡çº§çš„ per-block é‡åŒ–æœºåˆ¶ï¼š
  - åœ¨ FP16 è®¡ç®—å‰è¿›è¡Œç¼©æ”¾ï¼ˆquantizationï¼‰ï¼Œé˜²æ­¢æº¢å‡ºï¼›
  - è®¡ç®—åæ¢å¤åŸå§‹å°ºåº¦ï¼ˆdequantizationï¼‰ã€‚
- å¼€é”€æå°ï¼Œä½†æœ‰æ•ˆæå‡äº†æ•°å€¼é²æ£’æ€§ã€‚

#### ï¼ˆ4ï¼‰åŸºäº Julia çš„å¯ç§»æ¤å®ç°
- åˆ©ç”¨ Julia çš„å¤šé‡æ´¾å‘ï¼ˆmultiple dispatchï¼‰ã€åŠ¨æ€ç±»å‹æ¨æ–­å’Œæ•°ç»„ç¼–ç¨‹ç‰¹æ€§ï¼Œæ„å»ºäº†ä¸€ä¸ª**ç¡¬ä»¶æ— å…³çš„é«˜å±‚æ¥å£**ã€‚
- åº•å±‚è°ƒç”¨ vendor-specific åº“ï¼ˆå¦‚ cuBLAS / rocBLASï¼‰ï¼Œå®ç°è·¨å¹³å°ï¼ˆNVIDIA H200 å’Œ AMD MI300Xï¼‰é«˜æ€§èƒ½ä¸å¯ç§»æ¤æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | æœ¬æ–‡æ–¹æ³• | ä¼ ç»Ÿæ–¹æ³• |
|------|----------|---------|
| **é€’å½’ç²’åº¦** | å®Œå…¨åµŒå¥—é€’å½’ï¼ˆPOTRF + TRSM + SYRKï¼‰ | ä»… POTRF é€’å½’ï¼ŒTRSM/SYRK ä¸ºæ ‡å‡†å—å½¢å¼ |
| **ç²¾åº¦æ§åˆ¶** | æ ‘çŠ¶åˆ†å±‚æ··åˆç²¾åº¦ï¼Œç»†ç²’åº¦æ§åˆ¶ | å‡åŒ€ç²¾åº¦æˆ–è¿­ä»£ç²¾åŒ–ï¼ˆiterative refinementï¼‰ |
| **ç¡¬ä»¶é€‚é…æ€§** | æ˜¾å¼é¢å‘ MXUsï¼ˆTensor Cores / Matrix Coresï¼‰ä¼˜åŒ– | ä¸»è¦é’ˆå¯¹é€šç”¨ CPU/GPU BLAS |
| **å®ç°æ–¹å¼** | é«˜å±‚è¯­è¨€ï¼ˆJuliaï¼‰å®ç°ï¼Œè‡ªåŠ¨è°ƒåº¦è‡³åº•å±‚åº“ | å¤šä¸º C/CUDA æ‰‹å†™å†…æ ¸ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä½¿ç”¨éšæœºç”Ÿæˆçš„ç¨ å¯†å¯¹ç§°æ­£å®šçŸ©é˜µï¼ˆSPD matricesï¼‰ã€‚
- çŸ©é˜µå…ƒç´ æœä»å‡åŒ€åˆ†å¸ƒï¼Œå¹¶é€šè¿‡å‘å¯¹è§’çº¿åŠ  `n`ï¼ˆç»´åº¦ï¼‰ç¡®ä¿æ­£å®šæ€§å’Œè‰¯å¥½æ¡ä»¶æ•°ã€‚
- æµ‹è¯•è§„æ¨¡ä» `4096Ã—4096` åˆ° `65536Ã—65536`ã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼š
  - **NVIDIA H200**ï¼šåŸºäº Hopper æ¶æ„ï¼Œæ”¯æŒ FP16 Tensor Coresã€‚
  - **AMD MI300X**ï¼šé…å¤‡ Matrix Coresï¼Œæ”¯æŒæ··åˆç²¾åº¦è®¡ç®—ã€‚
- **è½¯ä»¶ç¯å¢ƒ**ï¼š
  - Julia 1.12.0
  - GPU æ”¯æŒåº“ï¼šCUDA.jlï¼ˆNVIDIAï¼‰ã€AMDGPU.jlï¼ˆAMDï¼‰
  - åç«¯è°ƒç”¨ï¼šcuBLAS/cuSOLVERï¼ˆNVIDIAï¼‰ã€rocBLAS/rocSOLVERï¼ˆAMDï¼‰

### è¯„ä¼°æŒ‡æ ‡
- **Speedup**ï¼šç›¸å¯¹äº FP64 åŸºçº¿ï¼ˆcuSOLVER / rocSOLVERï¼‰çš„åŠ é€Ÿæ¯”ã€‚
- **Throughput (TFLOPs)**ï¼šå®é™…è¾¾åˆ°çš„æµ®ç‚¹è¿ç®—æ€§èƒ½ã€‚
- **Accuracy**ï¼šä»¥ FP64 ç»“æœä¸ºåŸºå‡†ï¼Œè®¡ç®—ç›¸å¯¹è¯¯å·®èŒƒæ•°ï¼ˆ-logâ‚â‚€(error)ï¼‰ï¼Œè¡¡é‡æœ‰æ•ˆæ•°å­—ä½æ•°ã€‚
- **Portability**ï¼šåŒä¸€ä»½ Julia ä»£ç åœ¨ä¸åŒå‚å•† GPU ä¸Šçš„è¡¨ç°ä¸€è‡´æ€§ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Full-Precision Baseline**ï¼šcuSOLVER FP64 / rocSOLVER FP64
- **Uniform Precision Variants**ï¼šçº¯ FP32ã€çº¯ FP16
- **Mixed-Precision Baselines**ï¼šå›ºå®šåˆ†åŒºçš„æ··åˆç²¾åº¦æ–¹æ³•ï¼ˆå¦‚ [FP16, FP32]ï¼‰
- **Vendor Libraries**ï¼šcuBLAS SYRK/TRSMã€rocBLAS SYRK/TRSM

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆNVIDIA H200ï¼‰

#### ï¼ˆ1ï¼‰SYRK æ€§èƒ½ï¼ˆå›¾ 4ï¼‰
- **é€’å½’ FP64 SYRK**ï¼šç›¸æ¯” cuBLAS FP64ï¼Œæœ€é«˜è¾¾ **14Ã— åŠ é€Ÿ**ï¼ˆn=65,536ï¼‰ã€‚
- **æ··åˆç²¾åº¦ SYRK**ï¼ˆå¦‚ `[FP16,FP16,FP16,FP16,FP32]`ï¼‰ï¼šæœ€é«˜è¾¾ **27Ã— åŠ é€Ÿ**ã€‚
- **çº¯ FP16 SYRK**ï¼šå³°å€¼å¯è¾¾ **149Ã—**ï¼Œä½†ç²¾åº¦ä¸¥é‡ä¸‹é™ã€‚

#### ï¼ˆ2ï¼‰TRSM æ€§èƒ½ï¼ˆå›¾ 5ï¼‰
- **é€’å½’ FP64 TRSM**ï¼šæ¥è¿‘ cuBLAS è¡¨ç°ã€‚
- **æ··åˆç²¾åº¦ TRSM**ï¼šæœ€é«˜è¾¾ **5.3Ã— åŠ é€Ÿ**ã€‚
- **çº¯ FP16 TRSM**ï¼šæœ€é«˜ **6Ã— åŠ é€Ÿ**ï¼Œä½†ç¨³å®šæ€§å·®ã€‚

#### ï¼ˆ3ï¼‰Cholesky æ•´ä½“æ€§èƒ½ï¼ˆå›¾ 6â€“7ï¼‰
- **ååé‡**ï¼ˆå›¾ 6ï¼‰ï¼š
  - æ·±å±‚æ··åˆç²¾åº¦é…ç½® `[FP16Ã—6, FP32]` è¾¾åˆ°è¶…è¿‡ **2Ã— cuSOLVER FP64 åå**ã€‚
  - çº¯ FP16 æ¥è¿‘ **3Ã— åå**ï¼Œä½†ç²¾åº¦æä½ã€‚
- **æœ€ç»ˆåŠ é€Ÿæ¯”**ï¼ˆå›¾ 7ï¼‰ï¼š
  - æœ€ä¼˜æ··åˆç²¾åº¦é…ç½®å®ç° **5.32Ã— é€Ÿåº¦æå‡**ï¼ˆvs. cuSOLVER FP64ï¼‰ã€‚
  - çº¯ FP16 è¾¾åˆ° **6Ã— åŠ é€Ÿ**ï¼Œä½†ä¸å¯é ã€‚

#### ï¼ˆ4ï¼‰ç²¾åº¦è¡¨ç°ï¼ˆå›¾ 8ï¼‰
- **çº¯ FP64**ï¼šçº¦ 15 ä½æœ‰æ•ˆæ•°å­—ã€‚
- **[FP32,FP32,FP32,FP64]**ï¼šä¿æŒ ~12 ä½ï¼Œä¼˜äºçº¯ FP32ã€‚
- **æ·±å±‚æ··åˆç²¾åº¦**ï¼ˆå¦‚ `[FP16Ã—5, FP32]`ï¼‰ï¼šç»´æŒ **5â€“6 ä½æœ‰æ•ˆæ•°å­—**ã€‚
- **çº¯ FP16**ï¼š< 4 ä½æœ‰æ•ˆæ•°å­—ã€‚
- **å…³é”®ç»“è®º**ï¼šæ··åˆç²¾åº¦æ–¹æ¡ˆåœ¨ä¿ç•™ **88% çº¯ FP16 å³°å€¼åŠ é€Ÿ**çš„åŒæ—¶ï¼Œè·å¾— **100Ã— æ›´å¥½çš„ç²¾åº¦**ã€‚

### AMD MI300X ç»“æœï¼ˆå›¾ 9ï¼‰
- åœ¨ MI300X ä¸Šï¼Œæœ€ä¼˜æ··åˆç²¾åº¦é…ç½® `[FP16,FP16,FP16,FP32]` å®ç° **5.3Ã— åŠ é€Ÿ**ï¼ˆvs. rocSOLVER FP64ï¼‰ã€‚
- å±•ç°å‡ºä¸ NVIDIA å¹³å°ç›¸ä¼¼çš„è¶‹åŠ¿ï¼ŒéªŒè¯äº†è·¨å¹³å°å¯ç§»æ¤æ€§ã€‚

### æ¶ˆèå®éªŒåˆ†æï¼ˆå›¾ 10â€“11ï¼‰
- **é€’å½’æ·±åº¦å½±å“**ï¼ˆå›¾ 10ï¼‰ï¼š
  - åŠ é€Ÿæ¯”éšçŸ©é˜µå¢å¤§è€Œçº¿æ€§å¢é•¿ï¼Œåœ¨ `n=65,536` è¾¾åˆ° **5.32Ã—** å³°å€¼ã€‚
  - å°çŸ©é˜µå› é€’å½’å¼€é”€å¤§è€Œä¸å—ç›Šã€‚
- **è·¨å¹³å°å¯ç§»æ¤æ€§**ï¼ˆå›¾ 11ï¼‰ï¼š
  - å•ä¸€ Julia å®ç°åœ¨ NVIDIA å’Œ AMD ä¸Šå‡å–å¾—è‰¯å¥½æ‰©å±•æ€§ã€‚
  - å½“å‰ AMD ä¸Šæœªå¯ç”¨ GemmExï¼ˆæ··åˆç²¾åº¦ GEMMï¼‰ï¼Œå¦åˆ™æ½œåŠ›æ›´å¤§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **åµŒå¥—é€’å½’ç»“æ„æ˜¾è‘—æå‡ GEMM å¯†åº¦å’Œå¹¶è¡Œæ€§**ï¼Œä½¿ Cholesky åˆ†è§£æ›´é€‚åº” MXUs çš„è®¡ç®—æ¨¡å¼ã€‚
2. **æ ‘çŠ¶åˆ†å±‚æ··åˆç²¾åº¦** æ˜¯å…¼é¡¾æ€§èƒ½ä¸ç¨³å®šæ€§çš„æœ‰æ•ˆç­–ç•¥ï¼šéå¯¹è§’å—ç”¨ FP16 æå‡ååï¼Œå¯¹è§’å—ç”¨é«˜ç²¾åº¦ä¿éšœå‡†ç¡®æ€§ã€‚
3. **è½»é‡çº§å—çº§é‡åŒ–æœºåˆ¶** èƒ½æœ‰æ•ˆè§£å†³ FP16 åŠ¨æ€èŒƒå›´ä¸è¶³é—®é¢˜ï¼Œæ— æ˜¾è‘—æ€§èƒ½ä»£ä»·ã€‚
4. **Julia çš„æŠ½è±¡èƒ½åŠ›** æ”¯æŒé«˜æ•ˆè¡¨è¾¾å¤æ‚é€’å½’ä¸æ··åˆç²¾åº¦é€»è¾‘ï¼ŒåŒæ—¶é€šè¿‡å¤šé‡æ´¾å‘å®ç°è·¨å¹³å°é«˜æ€§èƒ½ã€‚
5. åœ¨ **NVIDIA H200** ä¸Šï¼Œè¯¥æ–¹æ³•ç›¸è¾ƒ cuSOLVER FP64 å®ç° **5.32Ã— åŠ é€Ÿ**ï¼Œä¸”ç²¾åº¦è¿œè¶…çº¯ FP16ï¼ˆ100Ã— æ›´å¥½ï¼‰ï¼Œä¿ç•™äº† 88% çš„ FP16 å³°å€¼æ€§èƒ½ã€‚
6. åœ¨ **AMD MI300X** ä¸Šä¹Ÿå–å¾—ç±»ä¼¼å¢ç›Šï¼ˆæœ€é«˜ 5.3Ã—ï¼‰ï¼Œè¯æ˜æ–¹æ³•å…·æœ‰è‰¯å¥½çš„è·¨å‚å•†å¯ç§»æ¤æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **å°çŸ©é˜µæ”¶ç›Šæœ‰é™**ï¼šé€’å½’æ·±åº¦å—é™ï¼Œä»»åŠ¡ç²’åº¦è¿‡ç»†å¯èƒ½å¯¼è‡´è°ƒåº¦å¼€é”€å¤§äºæ”¶ç›Šã€‚
- **ä¾èµ– vendor åº“çš„ base case**ï¼šå½“å‰ä»è°ƒç”¨ cuBLAS/rocBLAS å¤„ç†å¶å­èŠ‚ç‚¹ï¼Œå°šæœªå®Œå…¨è‡ªåŒ…å«ã€‚
- **AMD å¹³å°åŠŸèƒ½ç¼ºå¤±**ï¼šJulia ç”Ÿæ€æš‚ä¸æ”¯æŒ AMD çš„æ··åˆç²¾åº¦ GEMMï¼ˆGemmExï¼‰ï¼Œé™åˆ¶äº†å…¶æ½œåŠ›å‘æŒ¥ã€‚
- **æœªè€ƒè™‘ç¨€ç–æˆ–å¸¦çŠ¶ç»“æ„**ï¼šç›®å‰ä»…é€‚ç”¨äºç¨ å¯† SPD ç³»ç»Ÿã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **LDLáµ€ åˆ†è§£**ï¼ˆå¤„ç†ä¸å®šçŸ©é˜µï¼‰å’Œ **ç¨€ç–/å—ç¨€ç–ç³»ç»Ÿ**ã€‚
- å¼•å…¥ **è‡ªé€‚åº”ç²¾åº¦æ§åˆ¶**ï¼Œæ ¹æ®çŸ©é˜µæ¡ä»¶æ•°åŠ¨æ€è°ƒæ•´ç²¾åº¦å±‚çº§ã€‚
- æ¢ç´¢ **å¤š GPU åˆ†å¸ƒå¼ç‰ˆæœ¬**ï¼Œæ”¯æŒæ›´å¤§è§„æ¨¡é—®é¢˜ã€‚
- å®ç° **å…¨æ ˆç¡¬ä»¶æ— å…³å®ç°**ï¼ŒåŒ…æ‹¬ base case çš„é€’å½’ GEMMï¼Œè¿ˆå‘ Apple Metal ç­‰æ–°æ¶æ„ã€‚
- ç»“åˆ **å¼‚æ­¥ä»»åŠ¡è¿è¡Œæ—¶** å’Œ **èƒ½è€—æ„ŸçŸ¥è°ƒåº¦**ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–èµ„æºåˆ©ç”¨ã€‚

--- 

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡é€šè¿‡**åµŒå¥—é€’å½’ + æ ‘çŠ¶åˆ†å±‚æ··åˆç²¾åº¦ + Julia å¯ç§»æ¤å®ç°**ï¼Œé¦–æ¬¡å®ç°äº†åœ¨ MXUs ä¸Šé«˜æ•ˆä¸”ç¨³å®šçš„ Cholesky æ±‚è§£ï¼Œåœ¨ H200 ä¸Šè·å¾— **5.32Ã— åŠ é€Ÿ**ï¼Œå¹¶åœ¨ç²¾åº¦ä¸æ€§èƒ½é—´å–å¾—å“è¶Šå¹³è¡¡ï¼Œå±•ç¤ºäº†é¢å‘æœªæ¥å¼‚æ„å¹³å°çš„é«˜æ€§èƒ½çº¿æ€§ä»£æ•°æ–°èŒƒå¼ã€‚

</details>

---

### 6. [MixServe: An Automatic Distributed Serving System for MoE Models with Hybrid Parallelism Based on Fused Communication Algorithm](https://arxiv.org/abs/2601.08800)

**Authors**: Bowen Zhou, Jinrui Jia, Wenhao He, Yong Zhang, Fang Dong  
**Category**: cs.DC  
**Published**: 2026-01-14  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2601.08800v1  

#### Abstract
The Mixture of Experts (MoE) models are emerging as the latest paradigm for Large Language Models (LLMs). However, due to memory constraints, MoE models with billions or even trillions of parameters can only be deployed in multi-GPU or even multi-node & multi-GPU based serving systems. Thus, communi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# MixServe è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰å¤§è§„æ¨¡ **Mixture of Experts (MoE)** æ¨¡å‹åœ¨åˆ†å¸ƒå¼æ¨ç†éƒ¨ç½²ä¸­é¢ä¸´ä¸¥é‡é€šä¿¡ç“¶é¢ˆï¼Œå°¤å…¶æ˜¯è·¨èŠ‚ç‚¹ï¼ˆinter-nodeï¼‰é€šä¿¡å¼€é”€å¤§ã€‚ä¼ ç»Ÿå¹¶è¡Œç­–ç•¥å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **Tensor Parallelism (TP)**ï¼šä¾èµ– All-Reduce (AR)ï¼Œåœ¨å•èŠ‚ç‚¹å†…é«˜æ•ˆï¼Œä½†è·¨èŠ‚ç‚¹æ‰©å±•æ€§å·®ï¼ˆå—é™äºä½å¸¦å®½ inter-node è¿æ¥ï¼‰ã€‚
- **Expert Parallelism (EP)**ï¼šä½¿ç”¨ All-to-All (A2A)ï¼Œè™½æ”¯æŒè·¨èŠ‚ç‚¹æ‰©å±•ï¼Œä½†æ˜“å¯¼è‡´è´Ÿè½½ä¸å‡è¡¡ï¼Œå°¤å…¶åœ¨é«˜å¹¶è¡Œåº¦ä¸‹æ•ˆç‡ä¸‹é™ã€‚
- ç¼ºä¹ç³»ç»ŸåŒ–åˆ†ææ¨¡å‹è¶…å‚æ•°ã€ç½‘ç»œæ‹“æ‰‘ä¸ç¡¬ä»¶èµ„æºä¹‹é—´å…³ç³»çš„æ–¹æ³•ï¼Œéƒ¨ç½²ç­–ç•¥å¤šä¾èµ–ç»éªŒã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
è®ºæ–‡æå‡º **MixServe**ï¼Œä¸€ä¸ªé¢å‘ MoE æ¨¡å‹çš„è‡ªåŠ¨åˆ†å¸ƒå¼æ¨ç†æœåŠ¡ç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰**è‡ªåŠ¨åŒ–çš„å¹¶è¡Œç­–ç•¥é€‰æ‹©æœºåˆ¶**
- åœ¨ç¦»çº¿é˜¶æ®µç»¼åˆè€ƒè™‘æ¨¡å‹è¶…å‚æ•°ï¼ˆå¦‚ä¸“å®¶æ•°ã€éšè—ç»´åº¦ï¼‰ã€ç¡¬ä»¶é…ç½®ï¼ˆè®¡ç®—èƒ½åŠ›ã€NVLink/RoCE å¸¦å®½ï¼‰å’Œç½‘ç»œæ‹“æ‰‘ï¼Œé€šè¿‡ç†è®ºå»ºæ¨¡ä¸æ€§èƒ½é¢„æµ‹ï¼Œ**è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜çš„æ··åˆå¹¶è¡Œç­–ç•¥**ï¼ˆTP/EP/DP/PP ç»„åˆï¼‰ï¼Œå–ä»£äººå·¥ç»éªŒå†³ç­–ã€‚

#### ï¼ˆ2ï¼‰**åŸºäºèåˆé€šä¿¡ç®—æ³•çš„ TP-EP æ··åˆå¹¶è¡Œï¼ˆHybrid TP-EPï¼‰**
- è®¾è®¡äº†ä¸€ç§æ–°å‹ **TP-EP Hybrid Parallelism** æ¶æ„ï¼š
  - Attention å±‚é‡‡ç”¨ **intra-node TP + inter-node DP**
  - MoE å±‚é‡‡ç”¨ **intra-node TP + inter-node EP**
- æå‡º **Fused AR-A2A Communication Algorithm**ï¼Œå°† intra-node çš„ AR é€šä¿¡ä¸ inter-node çš„ A2A é€šä¿¡è¿›è¡Œé‡å æ‰§è¡Œï¼Œæœ‰æ•ˆåˆ©ç”¨å¸¦å®½å±‚çº§å·®å¼‚ï¼ˆintra-node é«˜é€Ÿ vs inter-node ä½é€Ÿï¼‰ï¼Œæ˜¾è‘—é™ä½æ€»é€šä¿¡å»¶è¿Ÿã€‚

#### ï¼ˆ3ï¼‰ä¸¤ç§å…·ä½“çš„èåˆé€šä¿¡ç®—æ³•å®ç°
- **Fused RS-Combine**ï¼šReduce Scatterï¼ˆRSï¼‰ä¸ A2A Combine é‡å ã€‚
- **Fused AG-Dispatch**ï¼šAll Gatherï¼ˆAGï¼‰ä¸ A2A Dispatch é‡å ã€‚
- åˆ©ç”¨å¼‚æ­¥é€šä¿¡æœºåˆ¶å®ç°æ—¶é—´ä¸Šçš„å¹¶è¡ŒåŒ–ï¼Œæå‡æ•´ä½“ååã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **é€šä¿¡æ•ˆç‡** | æ˜¾è‘—å‡å°‘è·¨èŠ‚ç‚¹é€šä¿¡é‡ï¼Œå……åˆ†åˆ©ç”¨ intra-node é«˜å¸¦å®½ |
| **è‡ªåŠ¨åŒ–ç¨‹åº¦** | è‡ªåŠ¨åˆ†æå¹¶é€‰æ‹©æœ€ä½³å¹¶è¡Œç­–ç•¥ï¼Œé€‚åº”ä¸åŒæ¨¡å‹ä¸é›†ç¾¤ç¯å¢ƒ |
| **æ€§èƒ½ä¸€è‡´æ€§** | åœ¨å¤šç§ç¡¬ä»¶å¹³å°ï¼ˆH20 GPU / Ascend 910B NPUï¼‰å‡è¡¨ç°ä¼˜è¶Š |
| **å¯æ‰©å±•æ€§** | æ”¯æŒå¤§è§„æ¨¡ MoE æ¨¡å‹ï¼ˆå¦‚ DeepSeek-R1, Qwen3ï¼‰çš„é«˜æ•ˆéƒ¨ç½² |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†ä¸æ¨¡å‹
- **æ¨¡å‹**ï¼š
  - **DeepSeek-R1**ï¼š671B å‚æ•°ï¼Œ256 è·¯ç”±ä¸“å®¶ + 1 å…±äº«ä¸“å®¶ï¼Œæ¯ token æ¿€æ´»çº¦ 37B å‚æ•°
  - **Qwen3-235B-A22B**ï¼š235B å‚æ•°ï¼Œ128 ä¸“å®¶ï¼Œæ¯ token æ¿€æ´»çº¦ 22B å‚æ•°
- **æ•°æ®é›†**ï¼š
  - **ShareGPT-V3**ï¼šåŒ…å« 1.2B tokens çš„äººç±»å¯¹è¯æ•°æ®ï¼Œç”¨äºç”Ÿæˆè¯·æ±‚åºåˆ—è¿›è¡ŒåŸºå‡†æµ‹è¯•

### âš™ï¸ å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼š
  1. **H20 Cluster**ï¼š2 å°æœåŠ¡å™¨ï¼Œæ¯å° 8Ã—Nvidia H20 GPUï¼ˆ96GBï¼‰ï¼ŒNVLink 4.0ï¼ˆ900GB/s intra-nodeï¼‰ï¼ŒInfiniBandï¼ˆ400Gbps inter-nodeï¼‰
  2. **Ascend 910B Cluster**ï¼š4 å° Atlas 800T A2 æœåŠ¡å™¨ï¼Œæ¯å° 8Ã—Ascend 910B NPUï¼ˆ64GBï¼‰ï¼ŒHCCSï¼ˆ480Gbps intra-nodeï¼‰ï¼ŒRoCEï¼ˆ200Gbps inter-nodeï¼‰
- **è¯·æ±‚è´Ÿè½½**ï¼š
  - è¯·æ±‚é€Ÿç‡ï¼š2, 4, 8 req/s
  - æœ€å¤§æ‰¹å¤§å°ï¼š16
  - æœ€å¤§åºåˆ—é•¿åº¦ï¼š4096 tokens

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **TTFT (Time to First Token)** | ç”¨æˆ·å‘å‡ºè¯·æ±‚åˆ°æ”¶åˆ°ç¬¬ä¸€ä¸ªè¾“å‡º token çš„æ—¶é—´ï¼Œåæ˜  Prefill é˜¶æ®µæ€§èƒ½ |
| **ITL (Inter-Token Latency)** | ç›¸é‚»ä¸¤ä¸ª token è¾“å‡ºä¹‹é—´çš„å¹³å‡é—´éš”ï¼Œåæ˜  Decode é˜¶æ®µæ€§èƒ½ |
| **Throughput (token/s)** | å•ä½æ—¶é—´å†…ç”Ÿæˆçš„ token æ€»æ•°ï¼Œè¡¡é‡ç³»ç»Ÿæ•´ä½“ååèƒ½åŠ› |
| **P99 Latency** | 99% çš„è¯·æ±‚æ»¡è¶³çš„å»¶è¿Ÿä¸Šé™ï¼Œä½“ç°ç¨³å®šæ€§ |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | å¹¶è¡Œç­–ç•¥è¯´æ˜ |
|------|--------------|
| **vLLM** | æ”¯æŒ TP+PP æˆ– DP+EPï¼Œæ˜¯ä¸»æµ LLM æ¨ç†æ¡†æ¶ |
| **Tutel** | æ”¯æŒ TP+EP çš„ MoE ä¸“ç”¨ä¼˜åŒ–åº“ |
| å¤šç§é…ç½®ç»„åˆï¼šTP=4/8, DP=2/4/8, EP=16/32 ç­‰ |

è¯¦ç»†åŸºçº¿é…ç½®è§åŸæ–‡ Table IIIã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æå‡ï¼ˆvs. åŸºçº¿ï¼‰

| æŒ‡æ ‡ | æå‡èŒƒå›´ | å…·ä½“æ¡ˆä¾‹ |
|------|---------|----------|
| **TTFT åŠ é€Ÿæ¯”** | **1.08Ã— ~ 3.80Ã—** | - Qwen3 on Ascend 910B: è¾ƒ vLLM TP+PP å¿« **3.80Ã—**<br>- DeepSeek-R1 on Ascend 910B: è¾ƒ vLLM TP+PP å¿« **2.67Ã—** |
| **ITL åŠ é€Ÿæ¯”** | **1.03Ã— ~ 1.66Ã—** | - Qwen3 on Ascend 910B: ITL ä» 134.27ms â†’ **81.1ms** (**1.66Ã—**) |
| **Throughput æå‡** | **+5.2% ~ +50.3%** | - DeepSeek-R1 on H20: ååä» 362.78 â†’ **545.23 token/s** (**+50.3%**) |

> å›¾ 10 å±•ç¤ºäº†åœ¨ä¸åŒç¡¬ä»¶å’Œæ¨¡å‹ä¸‹çš„å…¨é¢æ€§èƒ½å¯¹æ¯”ï¼ŒMixServe åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡ä¼˜äºæ‰€æœ‰åŸºçº¿ã€‚

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰**DP ä¸ EP çš„æƒè¡¡åˆ†æï¼ˆdDP vs dEPï¼‰**
- å½“ `dDP â‰ˆ dEP` æ—¶ï¼ˆå¹³è¡¡é…ç½®ï¼‰ï¼Œåœ¨ Ascend 910B ä¸Šå–å¾—æœ€ä½³æ€§èƒ½ï¼ˆæœ€ä½ TTFT å’Œæœ€é«˜ååï¼‰ã€‚
- åœ¨ H20 é«˜å¸¦å®½ç¯å¢ƒä¸‹ï¼Œ`dDP < dEP` æ›´ä¼˜ï¼Œè¡¨æ˜ MixServe èƒ½æ ¹æ®å¸¦å®½ç‰¹æ€§åŠ¨æ€è°ƒæ•´æœ€ä¼˜ç­–ç•¥ã€‚
- ç»“è®ºï¼šMixServe çš„è‡ªåŠ¨åˆ†æå™¨èƒ½å‡†ç¡®æ•æ‰ç¡¬ä»¶å·®å¼‚å¹¶åšå‡ºæœ€ä¼˜å†³ç­–ã€‚

#### ï¼ˆ2ï¼‰**é€šä¿¡é‡å çš„å½±å“ï¼ˆSync vs Asyncï¼‰**
- å¼‚æ­¥èåˆé€šä¿¡ï¼ˆAsync Fused AR-A2Aï¼‰ç›¸æ¯”åŒæ­¥æ–¹å¼æ˜¾è‘—é™ä½å»¶è¿Ÿã€‚
- Gantt å›¾æ˜¾ç¤º intra-node AG/RS ä¸ inter-node A2A æˆåŠŸé‡å ï¼ŒèŠ‚çœæ—¶é—´æ¥è¿‘æ•´ä¸ª inter-node é€šä¿¡è€—æ—¶ã€‚
- ç»“æœï¼šå¯ç”¨å¼‚æ­¥èåˆåï¼ŒTTFT ä¸‹é™çº¦ 15%~30%ï¼ŒITL å’Œååä¹Ÿç›¸åº”æ”¹å–„ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **é€šä¿¡å±‚çº§å·®å¼‚å¿…é¡»è¢«æ˜¾å¼å»ºæ¨¡**ï¼šintra-node ä¸ inter-node å¸¦å®½çš„å·¨å¤§å·®è·æ˜¯ MoE æ¨ç†çš„å…³é”®ç“¶é¢ˆï¼Œä¸èƒ½ç®€å•ç»Ÿä¸€å¤„ç†ã€‚
2. **æ··åˆ TP-EP å¹¶è¡Œä¼˜äºçº¯ EP æˆ–çº¯ TP**ï¼šé€šè¿‡åœ¨ MoE å±‚å¼•å…¥ intra-node TPï¼Œå¯åˆ†æ‹…éƒ¨åˆ† A2A é€šä¿¡å‹åŠ›ï¼Œé™ä½æ•´ä½“å¼€é”€ã€‚
3. **Fused AR-A2A æ˜¾è‘—æå‡é€šä¿¡æ•ˆç‡**ï¼šé€šè¿‡åˆç†è°ƒåº¦ï¼Œè®© intra-node AR ä¸ inter-node A2A é‡å æ‰§è¡Œï¼Œå®ç°äº†â€œä»¥ç©ºé—´æ¢æ—¶é—´â€çš„é«˜æ•ˆä¼˜åŒ–ã€‚
4. **è‡ªåŠ¨åŒ–ç­–ç•¥é€‰æ‹©è‡³å…³é‡è¦**ï¼šä¸åŒæ¨¡å‹ã€ä¸åŒé›†ç¾¤åº”é‡‡ç”¨ä¸åŒçš„å¹¶è¡Œé…ç½®ï¼Œæ‰‹åŠ¨è°ƒä¼˜æˆæœ¬é«˜ä¸”éš¾ä»¥æ³›åŒ–ï¼Œè€Œ MixServe å¯è‡ªåŠ¨å®Œæˆè¿™ä¸€è¿‡ç¨‹ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **å†…å­˜å¼€é”€å¢åŠ **ï¼šFused RS-Combine éœ€è¦é¢å¤–ä¸´æ—¶å­˜å‚¨ç©ºé—´ï¼ˆO(bshÂ·nproc)ï¼‰ï¼Œå¯¹æ˜¾å­˜ç´§å¼ åœºæ™¯å¯èƒ½æ„æˆæŒ‘æˆ˜ã€‚
- **ä¾èµ–åº•å±‚é€šä¿¡åº“æ”¯æŒ**ï¼šéœ€è¦æ”¯æŒç»†ç²’åº¦å¼‚æ­¥é€šä¿¡ï¼ˆå¦‚ isend/irecvï¼‰å’Œçµæ´»çš„é€šä¿¡ç»„ç®¡ç†ã€‚
- **ç›®å‰èšç„¦æ¨ç†é˜¶æ®µ**ï¼šæœªæ¶‰åŠè®­ç»ƒåœºæ™¯çš„æ‰©å±•ï¼Œå°½ç®¡æŠ€æœ¯åŸç†å¯è¿ç§»ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **Training-Serving ç»Ÿä¸€æ¶æ„**ï¼Œæ”¯æŒ MoE å…¨æµç¨‹é«˜æ•ˆè¿è¡Œã€‚
- æ”¯æŒæ›´å¤æ‚çš„ **5D å¹¶è¡Œ**ï¼ˆTP/EP/DP/PP/CPï¼‰ï¼Œé€‚é…å¼‚æ„é›†ç¾¤ã€‚
- å¼•å…¥ **åœ¨çº¿è‡ªé€‚åº”è°ƒä¼˜æœºåˆ¶**ï¼Œæ ¹æ®å®æ—¶è´Ÿè½½åŠ¨æ€è°ƒæ•´å¹¶è¡Œç­–ç•¥ã€‚
- æ¢ç´¢ **ç¨€ç–è·¯ç”±å‹ç¼©** æŠ€æœ¯è¿›ä¸€æ­¥å‡å°‘ A2A æ•°æ®ä¼ è¾“é‡ã€‚

---

## æ€»ç»“

> **MixServe æ˜¯é¦–ä¸ªå°†ç†è®ºå»ºæ¨¡ã€è‡ªåŠ¨ç­–ç•¥é€‰æ‹©ä¸èåˆé€šä¿¡ä¼˜åŒ–ç›¸ç»“åˆçš„ MoE åˆ†å¸ƒå¼æ¨ç†ç³»ç»Ÿ**ã€‚å®ƒä¸ä»…è§£å†³äº†ä¼ ç»Ÿæ–¹æ³•ä¸­é€šä¿¡æ•ˆç‡ä½ä¸‹ã€ç­–ç•¥è®¾è®¡ä¾èµ–ç»éªŒçš„é—®é¢˜ï¼Œè¿˜åœ¨çœŸå®å¤§è§„æ¨¡æ¨¡å‹ï¼ˆDeepSeek-R1ã€Qwen3ï¼‰å’Œå¤šç±»ç¡¬ä»¶å¹³å°ä¸ŠéªŒè¯äº†å…¶å“è¶Šæ€§èƒ½ï¼š**æœ€é«˜è¾¾ 3.8Ã— TTFT åŠ é€Ÿï¼Œ50.3% ååæå‡**ã€‚è¯¥å·¥ä½œä¸ºæœªæ¥è¶…å¤§è§„æ¨¡ MoE æ¨¡å‹çš„å®é™…éƒ¨ç½²æä¾›äº†é‡è¦åŸºç¡€è®¾æ–½æ”¯æ’‘ã€‚

</details>

---

### 7. [Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs](https://arxiv.org/abs/2601.08403)

**Authors**: Abhijnan Nath, Alireza Bagheri Garakani, Tianchen Zhou, Fan Yang, Nikhil Krishnaswamy  
**Category**: cs.AI  
**Published**: 2026-01-14  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.08403v1  

#### Abstract
Large language models are increasingly trained via reinforcement learning for personalized recommendation tasks, but standard methods like GRPO rely on sparse, sequence-level rewards that create a credit assignment gap, obscuring which tokens drive success. This gap is especially problematic when mo...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨èç³»ç»Ÿç­‰ç”Ÿæˆä»»åŠ¡ä¸­è¶Šæ¥è¶Šå¤šåœ°é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning, RLï¼‰è¿›è¡Œè®­ç»ƒï¼Œä½†æ ‡å‡†æ–¹æ³•å¦‚ **Group Relative Policy Optimization (GRPO)** å­˜åœ¨ä»¥ä¸‹å…³é”®ç¼ºé™·ï¼š
- **ä¿¡ç”¨åˆ†é…ç¼ºå£ï¼ˆcredit assignment gapï¼‰**ï¼šä»…ä¾èµ–ç¨€ç–çš„åºåˆ—çº§å¥–åŠ±ï¼ˆsequence-level rewardsï¼‰ï¼Œæ— æ³•è¯†åˆ«æ˜¯å“ªäº›å…·ä½“çš„ token æˆ–è¯­ä¹‰ç‰‡æ®µï¼ˆå¦‚äº§å“å±æ€§æè¿°ï¼‰çœŸæ­£é©±åŠ¨äº†æˆåŠŸã€‚
- **ç¼ºä¹å¯è§£é‡Šæ€§ä¸æ•ˆç‡**ï¼šæ‰€æœ‰ token è¢«èµ‹äºˆç›¸åŒçš„ä¼˜åŠ¿å€¼ï¼ˆadvantageï¼‰ï¼Œå¯¼è‡´æ¢¯åº¦æ›´æ–°ä¸ç²¾å‡†ã€‚
- **æ˜“å—å¥–åŠ±æ¬ºéª—ï¼ˆreward hackingï¼‰**ï¼šæ¨¡å‹å¯èƒ½è¿‡æ‹Ÿåˆæ£€ç´¢å™¨çš„è¡¨é¢ç‰¹å¾è€Œéç†è§£çœŸå®ç”¨æˆ·æ„å›¾ã€‚

è¿™äº›é—®é¢˜åœ¨ç”¨æˆ·æ„å›¾æ¨¡ç³Šã€æ— æ˜ç¡®æ ‡ç­¾çš„åœºæ™¯ä¸‹å°¤ä¸ºä¸¥é‡ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ ¸å¿ƒæ€æƒ³
æœ¬æ–‡æå‡º **Owen-Shapley Policy Optimization (OSPO)**ï¼Œä¸€ç§åŸºäºåˆä½œåšå¼ˆè®ºçš„æ–°å‹ç­–ç•¥ä¼˜åŒ–æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰å¼•å…¥ Owen-Shapley å€¼è¿›è¡Œç»†ç²’åº¦ä¿¡ç”¨åˆ†é…
- å°†ç”Ÿæˆæ–‡æœ¬ä¸­çš„**è¯­ä¹‰è¿è´¯ç‰‡æ®µ**ï¼ˆå¦‚çŸ­è¯­ã€å¥å­ï¼‰è§†ä¸ºâ€œç©å®¶â€ï¼Œæ„å»º**è”ç›Ÿæ¸¸æˆï¼ˆcoalition gameï¼‰**ã€‚
- ä½¿ç”¨ **Owen-Shapley values** è®¡ç®—æ¯ä¸ªç‰‡æ®µå¯¹æœ€ç»ˆå¥–åŠ±çš„è¾¹é™…è´¡çŒ®ï¼Œä»è€Œå®ç°ä»åºåˆ—çº§åˆ°ç‰‡æ®µçº§çš„ä¿¡ç”¨å†åˆ†é…ã€‚
- è¯¥æ–¹æ³•ç»§æ‰¿äº† Shapley å€¼çš„å…¬å¹³æ€§ä¿è¯ï¼ˆæ•ˆç‡ã€å¯¹ç§°æ€§ã€çº¿æ€§ï¼‰ï¼ŒåŒæ—¶é€šè¿‡é™åˆ¶ä¸º**è¿ç»­ç‰‡æ®µè”ç›Ÿ**æ˜¾è‘—é™ä½è®¡ç®—å¤æ‚åº¦ã€‚

#### ï¼ˆ2ï¼‰æ— éœ€ä»·å€¼æ¨¡å‹çš„ä»·å€¼é‡å¡‘ï¼ˆValue-Model-Free Reward Shapingï¼‰
- ä¸ä¾èµ–é¢å¤–çš„ critic ç½‘ç»œæˆ–è¿‡ç¨‹å¥–åŠ±æ¨¡å‹ï¼ˆProcess Reward Modelï¼‰ï¼Œç›´æ¥åˆ©ç”¨ä»»åŠ¡åé¦ˆï¼ˆå¦‚ NDCGï¼‰æˆ–é»‘ç›’æ£€ç´¢å™¨æ¥ä¼°è®¡ç‰‡æ®µè´¡çŒ®ã€‚
- é‡‡ç”¨ **Potential-Based Reward Shaping (PBRS)** æŠ€æœ¯å°† Owen å€¼æ˜ å°„åˆ° token çº§ä¼˜åŠ¿ï¼Œä¿æŒæœ€ä¼˜ç­–ç•¥ä¸å˜ã€‚

#### ï¼ˆ3ï¼‰é•¿åº¦æ— å…³çš„ä¼˜åŠ¿é‡åˆ†é…æœºåˆ¶
- æå‡ºå…¬å¼ $ A_t^{(g)} = T \cdot \hat{\phi}_t^{(g)} \cdot A^{(g)} $ï¼Œå…¶ä¸­ $ T $ ä¸ºåºåˆ—é•¿åº¦ï¼Œ$ \hat{\phi}_t $ ä¸ºå½’ä¸€åŒ–çš„ Owen å€¼ã€‚
- æ­¤è®¾è®¡ç¡®ä¿å¹³å‡ token ä¼˜åŠ¿ç­‰äºåŸå§‹åºåˆ—ä¼˜åŠ¿ï¼Œæ¶ˆé™¤äº†é•¿åºåˆ—å›  Owen å€¼ç¨€é‡Šè€Œå¯¼è‡´çš„æ¢¯åº¦å¼±åŒ–é—®é¢˜ï¼ˆå³é•¿åº¦åå·®ï¼‰ã€‚

#### ï¼ˆ4ï¼‰ä¸¤ç§ä¼˜åŠ¿é‡åˆ†é…ç­–ç•¥
- **OSPO-Prop**ï¼šæŒ‰ Owen å€¼æ¯”ä¾‹åˆ†é…ä¼˜åŠ¿ã€‚
- **OSPO-Rank**ï¼šå…ˆå°† Owen å€¼è½¬ä¸ºæ’åå†åˆ†é…ï¼Œå¢å¼ºå¯¹å™ªå£°ä¼°è®¡çš„é²æ£’æ€§ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | æ˜¯å¦éœ€è¦ Value Model | ä¿¡ç”¨åˆ†é…ç²’åº¦ | å¯è§£é‡Šæ€§ | é²æ£’æ€§ |
|------|------------------------|---------------|-----------|---------|
| GRPO / PPO | âŒ | åºåˆ—çº§ï¼ˆuniformï¼‰ | ä½ | æ˜“ reward hacking |
| DPO | âŒ | æˆå¯¹åå¥½ | ä¸­ | ä¾èµ–é™æ€æ•°æ® |
| SCAR (Cao et al.) | âœ… | ç‰‡æ®µçº§ | é«˜ | é™äºæœ‰ critic åœºæ™¯ |
| **OSPO** | âŒ | **ç‰‡æ®µçº§ï¼ˆfine-grainedï¼‰** | **é«˜** | **å¼ºï¼Œè·¨æ£€ç´¢å™¨æ³›åŒ–å¥½** |

> âœ… **OSPO åœ¨ä¸å¢åŠ å¤–éƒ¨ç½‘ç»œçš„å‰æä¸‹å®ç°äº†æ›´ç²¾ç»†ã€æ›´åˆç†çš„ä¿¡ç”¨åˆ†é…ï¼Œå…¼å…·é«˜æ•ˆæ€§ä¸åŸåˆ™æ€§ã€‚**

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **ESCI Shopping Queries** (Reddy et al., 2022)ï¼šæ ‡å‡†ç”µå•†æœç´¢æ•°æ®é›†ï¼Œç”¨äºä¼ ç»Ÿäº§å“æŸ¥è¯¢æ‰©å±•ä»»åŠ¡ã€‚
- **H&M Fashion Recommendations** (Ling et al., 2022)ï¼šæ—¶å°šæ¨èæ•°æ®é›†ï¼ŒåŒ…å«ä¸°å¯Œè´­ä¹°å†å²ï¼Œç”¨äºä¸Šä¸‹æ–‡åŒ–æœç´¢ä¸ç”¨æˆ·ç”»åƒæ‘˜è¦ç”Ÿæˆã€‚

> æ³¨ï¼šH&M ç¼ºå°‘æ˜¾å¼æŸ¥è¯¢ï¼Œä½œè€…ä½¿ç”¨ **Claude Sonnet 3.0** ç”ŸæˆåˆæˆæŸ¥è¯¢ä¸ä¸“å®¶æ‘˜è¦ä½œä¸ºç›‘ç£ä¿¡å·ã€‚

---

### å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼šä¸»å¹²æ¨¡å‹ä¸º `Qwen2.5-Instruct 7B`ï¼Œéƒ¨åˆ†å®éªŒä½¿ç”¨æ›´å¤§/å°è§„æ¨¡å˜ä½“ä½œå¯¹æ¯”ã€‚
- **è®­ç»ƒæ–¹å¼**ï¼š
  - æ‰€æœ‰ RL æ–¹æ³•æ¯æ¡æç¤ºé‡‡æ · G=8 æ¡å“åº”ã€‚
  - ä½¿ç”¨ FAISS è¿›è¡Œå¯†é›†æ£€ç´¢ï¼Œé¢†åŸŸç¼–ç å™¨åˆ†åˆ«ä¸ºï¼š
    - ESCI: `ALL-MPNET-BASE-V2`
    - H&M: `SIMCSE-LARGE`
- **å¥–åŠ±å‡½æ•°**ï¼š
  - æœç´¢ä»»åŠ¡ï¼šç»ˆç«¯å¥–åŠ±ä¸º **NDCG@1000**
  - ç”¨æˆ·æ‘˜è¦ä»»åŠ¡ï¼šç»“åˆ **Bradley-Terry Reward Model**ï¼ˆ90%ï¼‰ä¸æ ¼å¼å¥–åŠ±ï¼ˆ10%ï¼‰

---

### è¯„ä¼°æŒ‡æ ‡
| ä»»åŠ¡ | ä¸»è¦æŒ‡æ ‡ |
|------|----------|
| äº§å“æœç´¢ | NDCG, AP, MRR, Recall |
| ç”¨æˆ·æ‘˜è¦è´¨é‡ | LLM Judge (Qwen-3-Nemotron-32B-Reward) çš„æˆå¯¹èƒœç‡ï¼ˆWin Rate, WRï¼‰ä¸å¹³å±€ç‡ï¼ˆTie Rateï¼‰ |

---

### åŸºçº¿æ–¹æ³•
- **SFT**ï¼šç›‘ç£å¾®è°ƒï¼Œä»…ç”¨é«˜è´¨é‡æ ·æœ¬ï¼ˆNDCG > 0.5ï¼‰ã€‚
- **DPO**ï¼šç›´æ¥åå¥½ä¼˜åŒ–ï¼Œä½¿ç”¨ä¸“å®¶å¯¹æ¯”å¯¹ã€‚
- **GRPO**ï¼šå½“å‰ä¸»æµçš„æ— ä»·å€¼æ¨¡å‹ RL æ–¹æ³•ï¼Œä½œä¸ºä¸»è¦åœ¨çº¿ RL å¯¹ç…§ã€‚
- **OSPO-Clip**ï¼šOSPO çš„æ¶ˆèç‰ˆæœ¬ï¼Œé™åˆ¶é‡åˆ†é…åçš„ä¼˜åŠ¿èŒƒå›´ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| æ–¹æ³• | ESCI NDCG | H&M NDCG |
|------|------------|-----------|
| Qwen2.5-72B | 0.543 | 0.357 |
| **OSPO-Prop (7B)** | **0.522** | **0.436** |
| GRPO (7B) | 0.418 | 0.379 |
| DPO (7B) | 0.431 | 0.396 |
| SFT (7B) | 0.398 | 0.373 |

> ğŸ’¡ **ç»“è®º**ï¼šä»… 7B å‚æ•°çš„ OSPO-Prop æ€§èƒ½æ¥è¿‘ç”šè‡³è¶…è¶Š 72B å¤§æ¨¡å‹ï¼Œåœ¨ H&M ä¸Šæ›´æ˜¯å¤§å¹…é¢†å…ˆã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ç›¸æ¯” GRPO**ï¼š
  - ESCI ä¸Š NDCG æå‡ **24.9%**ï¼ˆ0.522 vs 0.418ï¼‰
  - H&M ä¸Šæå‡ **15.0%**ï¼ˆ0.436 vs 0.379ï¼‰
- **ç›¸æ¯” DPO**ï¼š
  - ESCI æå‡ **21.1%**ï¼ŒH&M æå‡ **10.1%**
- **ç›¸æ¯” SFT**ï¼šå…¨é¢æå‡ï¼Œå°¤å…¶åœ¨å¤æ‚ä¸Šä¸‹æ–‡ä»»åŠ¡ä¸­è¡¨ç°çªå‡ºã€‚

> ğŸ“ˆ å›¾1æ˜¾ç¤ºï¼ŒOSPO åœ¨çº¦ **400 æ­¥**è¾¾åˆ°ç›®æ ‡æ€§èƒ½ï¼Œè€Œ GRPO éœ€è¦è¶…è¿‡ **800 æ­¥**ï¼Œè¡¨æ˜å…¶æ ·æœ¬æ•ˆç‡æ›´é«˜ã€‚

---

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰ä¸åŒ coalition é…ç½®çš„å½±å“ï¼ˆTable 5 & Figure 2ï¼‰
- æœ€ä¼˜é…ç½®ï¼š**wmax=8, M=96**ï¼ˆå®½åº¦é€‚ä¸­ã€é‡‡æ ·å……åˆ†ï¼‰
- è¿‡çª„ï¼ˆw=1~2ï¼‰ï¼šè¿‡æ‹Ÿåˆå±€éƒ¨å…±ç°ï¼ŒåæœŸå´©æºƒã€‚
- è¿‡å®½ï¼ˆw=12~16ï¼‰ï¼šè¶…å‡ºå®é™…æŸ¥è¯¢é•¿åº¦ï¼Œèµ„æºæµªè´¹ã€‚
- éè¿ç»­è”ç›Ÿï¼ˆAll Subsetsï¼‰ï¼šæ€§èƒ½æ€¥å‰§ä¸‹é™è‡³ NDCGâ‰ˆ0.11ï¼ŒéªŒè¯äº†**è¯­ä¹‰è¿è´¯æ€§çš„é‡è¦æ€§**ã€‚

#### ï¼ˆ2ï¼‰ç”Ÿæˆæ•°é‡ï¼ˆnum_generationsï¼‰å½±å“
- ä» 8 å‡å°‘åˆ° 2 æ¬¡ç”Ÿæˆæ—¶ï¼Œå‡†ç¡®ç‡éª¤é™ï¼Œè¯´æ˜ **Monte Carlo é‡‡æ ·å¯¹ç¨³å®šä¼˜åŠ¿ä¼°è®¡è‡³å…³é‡è¦**ã€‚

#### ï¼ˆ3ï¼‰OSPO-Prop vs OSPO-Rankï¼ˆTable 2ï¼‰
| å¯¹æ¯” | Win Rate (WR) |
|------|----------------|
| OSPO-Prop vs GRPO | 49.1% |
| OSPO-Rank vs GRPO | 47.6% |
| OSPO-Prop vs SFT | 53.3% |
| OSPO-Rank vs SFT | 54.0% |

> ä¸¤è€…è¡¨ç°ç›¸è¿‘ï¼Œè¯´æ˜ä¸¤ç§é‡åˆ†é…ç­–ç•¥å‡æœ‰æ•ˆï¼›OSPO-Rank åœ¨å™ªå£°ç¯å¢ƒä¸‹æ›´å…·é²æ£’æ€§ã€‚

#### ï¼ˆ4ï¼‰è·¨æ£€ç´¢å™¨æ³›åŒ–èƒ½åŠ›ï¼ˆTable 4ï¼‰
- åœ¨ ESCI è®­ç»ƒã€SIMCSE æµ‹è¯•çš„è·¨åŸŸè®¾ç½®ä¸‹ï¼š
  - GRPO NDCG é™è‡³ 0.2257
  - **OSPO-Prop è¾¾åˆ° 0.3691**ï¼Œæ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿
- è¡¨æ˜ OSPO å­¦ä¹ çš„æ˜¯**æ›´é€šç”¨ã€æ›´å¯è¿ç§»çš„å¯¹é½ä¿¡å·**ï¼Œè€Œéè¿‡æ‹Ÿåˆç‰¹å®šåµŒå…¥ç©ºé—´ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **ç»†ç²’åº¦ä¿¡ç”¨åˆ†é…ä¼˜äºå‡åŒ€åˆ†é…**ï¼šOSPO é€šè¿‡ Owen-Shapley å€¼è¯†åˆ«å‡ºçœŸæ­£æ¨åŠ¨æ€§èƒ½çš„å…³é”®è¯­ä¹‰å•å…ƒï¼ˆå¦‚â€œprofessional tailored fitâ€ï¼‰ï¼Œä½¿æ¢¯åº¦é›†ä¸­åœ¨é«˜è´¡çŒ®åŒºåŸŸã€‚
2. âœ… **æ— éœ€ä»·å€¼æ¨¡å‹ä¹Ÿèƒ½å®ç°é«˜æ•ˆ RLHF**ï¼šOSPO åœ¨ä¸å¼•å…¥ critic çš„æƒ…å†µä¸‹å®Œæˆäº† credit assignmentï¼Œé™ä½äº†å·¥ç¨‹å¤æ‚åº¦ã€‚
3. âœ… **å°æ¨¡å‹ + å¥½ç®—æ³• > å¤§æ¨¡å‹ + å·®ä¼˜åŒ–**ï¼š7B çš„ OSPO å¯åª²ç¾ 72B æ¨¡å‹ï¼Œè¯æ˜äº†ä¼˜åŒ–æœºåˆ¶çš„é‡è¦æ€§è¿œè¶…å‚æ•°è§„æ¨¡ã€‚
4. âœ… **æ›´å¼ºçš„æ³›åŒ–ä¸ç¨³å®šæ€§**ï¼šOSPO åœ¨æµ‹è¯•é›†ä¸ŠæŒç»­æå‡ï¼Œè€Œ GRPO å‡ºç°ç¾éš¾æ€§é—å¿˜ï¼›ä¸”åœ¨è·¨æ£€ç´¢å™¨è¯„ä¼°ä¸­è¡¨ç°ç¨³å¥ã€‚
5. âœ… **coalescence ç»“æ„æ˜¯å…³é”®è¶…å‚**ï¼šé€‚åº¦å®½åº¦ï¼ˆw=4~8ï¼‰ã€è¿ç»­æ€§ã€å……è¶³é‡‡æ ·å…±åŒæ„æˆç¨³å®šå­¦ä¹ çš„å†…åœ¨æ­£åˆ™åŒ–æœºåˆ¶ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **è®¡ç®—å¼€é”€å¢åŠ **ï¼šéœ€å¤šæ¬¡è°ƒç”¨ reward model/æ£€ç´¢å™¨ä»¥è¯„ä¼°ä¸åŒè”ç›Ÿï¼Œå¸¦æ¥é¢å¤–å»¶è¿Ÿã€‚
- **è¶…å‚æ•°æ•æ„Ÿ**ï¼šcoalescence å®½åº¦ $ w_{\text{max}} $ å’Œé‡‡æ ·æ•° $ M $ éœ€ä»”ç»†è°ƒæ•´ã€‚
- **è¿‘ä¼¼è¯¯å·®**ï¼šMonte Carlo é‡‡æ ·å¯èƒ½å¯¼è‡´é•¿è·ç¦»ä¾èµ–è¢«ä½ä¼°ã€‚
- **ä»»åŠ¡ä¾èµ–æ€§**ï¼šsegment åˆ’åˆ†ä¾èµ–ä»»åŠ¡ç‰¹æ€§ï¼ˆçŸ­è¯­ or å¥å­ï¼‰ï¼Œè‡ªåŠ¨åŒ–æå–ä»å…·æŒ‘æˆ˜ã€‚
- **å•è½®å‡è®¾**ï¼šç›®å‰ä»…é€‚ç”¨äº single-turn ç”Ÿæˆï¼Œæœªæ‰©å±•è‡³ multi-turn å¯¹è¯æˆ– agent æ¨ç†ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **multi-turn RL** ä¸ **agent-based å†³ç­–ç¯å¢ƒ**ï¼ˆå¦‚ä»£ç ç”Ÿæˆã€å¯¹è¯è§„åˆ’ï¼‰ã€‚
- æ¢ç´¢ **åŠ¨æ€ coalition æ„å»ºæœºåˆ¶**ï¼Œè‡ªé€‚åº”é€‰æ‹©è¯­ä¹‰å•å…ƒã€‚
- ç»“åˆ **sparse attention æˆ– cache æœºåˆ¶** åŠ é€Ÿ Owen å€¼è®¡ç®—ã€‚
- æ¨å¹¿è‡³ **å¤šæ¨¡æ€ç”Ÿæˆä»»åŠ¡**ï¼ˆå›¾æ–‡ç”Ÿæˆã€è¯­éŸ³åŠ©æ‰‹ç­‰ï¼‰ã€‚
- ç ”ç©¶å¦‚ä½•å°† OSPO ä¸ **chain-of-thought prompting** æ›´æ·±åº¦æ•´åˆï¼Œæå‡æ¨ç†é€æ˜åº¦ã€‚

---

> ğŸ”š **æ€»ç»“**ï¼š  
> **OSPO æ˜¯ä¸€ä¸ªåŸåˆ™æ€§å¼ºã€å¯è§£é‡Šã€é«˜æ•ˆçš„ RLHF æ–°èŒƒå¼**ã€‚å®ƒé€šè¿‡å°†åšå¼ˆè®ºä¸­çš„ Owen-Shapley å€¼å¼•å…¥ LLM è®­ç»ƒï¼Œè§£å†³äº†é•¿æœŸå­˜åœ¨çš„ credit assignment é—®é¢˜ï¼Œåœ¨å¤šä¸ªç”µå•†æ¨èä»»åŠ¡ä¸­å±•ç°å‡ºå“è¶Šæ€§èƒ½ä¸æ³›åŒ–èƒ½åŠ›ï¼Œä¸ºä¸‹ä¸€ä»£ç”Ÿæˆå¼æœç´¢ä¸ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿæä¾›äº†åšå®çš„æŠ€æœ¯åŸºç¡€ã€‚

</details>

---

### 8. [Generation-Augmented Generation: A Plug-and-Play Framework for Private Knowledge Injection in Large Language Models](https://arxiv.org/abs/2601.08209)

**Authors**: Rongji Li, Jian Xu, Xueqing Chen, Yisheng Yang, Jiayi Wang, Xingyu Chen, Chunyu Xie, Dawei Leng, Xu-Yao Zhang  
**Category**: cs.CL  
**Published**: 2026-01-14  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.08209v1  

#### Abstract
In domains such as biomedicine, materials, and finance, high-stakes deployment of large language models (LLMs) requires injecting private, domain-specific knowledge that is proprietary, fast-evolving, and under-represented in public pretraining. However, the two dominant paradigms for private knowle...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šGeneration-Augmented Generation: A Plug-and-Play Framework for Private Knowledge Injection in Large Language Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

åœ¨ç”Ÿç‰©åŒ»å­¦ã€ææ–™ç§‘å­¦ã€é‡‘èç­‰é«˜é£é™©é¢†åŸŸï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰éœ€è¦æ³¨å…¥**ç§æœ‰ã€ä¸“æœ‰çš„é¢†åŸŸçŸ¥è¯†**ä»¥å®ç°å¯é éƒ¨ç½²ã€‚ç„¶è€Œï¼Œå½“å‰ä¸»æµçš„çŸ¥è¯†æ³¨å…¥æ–¹æ³•å­˜åœ¨æ˜¾è‘—ç¼ºé™·ï¼š

- **Fine-tuning**ï¼šæˆæœ¬é«˜æ˜‚ï¼Œè¿­ä»£å›°éš¾ï¼Œä¸”æŒç»­æ›´æ–°æ˜“å¯¼è‡´**ç¾éš¾æ€§é—å¿˜**ï¼ˆcatastrophic forgettingï¼‰å’Œé€šç”¨èƒ½åŠ›é€€åŒ–ã€‚
- **Retrieval-Augmented Generation (RAG)**ï¼šè™½ä¿æŒåŸºç¡€æ¨¡å‹ä¸å˜ï¼Œä½†åœ¨ç§æœ‰é¢†åŸŸä¸­è¡¨ç°è„†å¼±ï¼ŒåŸå› åŒ…æ‹¬ï¼š
  - æ–‡æœ¬åˆ†å—å¯¼è‡´çš„**è¯æ®ç¢ç‰‡åŒ–**ï¼ˆchunk-induced evidence fragmentationï¼‰
  - æ£€ç´¢æ¼‚ç§»ï¼ˆretrieval driftï¼‰
  - é•¿ä¸Šä¸‹æ–‡å‹åŠ›ï¼ˆlong-context pressureï¼‰
  - æŸ¥è¯¢ä¾èµ–çš„æç¤ºè†¨èƒ€ï¼ˆprompt inflationï¼‰

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **Generation-Augmented Generation (GAG)**ï¼Œä¸€ç§**æ£€ç´¢æ— å…³ã€å³æ’å³ç”¨**ï¼ˆretrieval-free, plug-and-playï¼‰çš„çŸ¥è¯†æ³¨å…¥æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- å°†ç§æœ‰é¢†åŸŸçŸ¥è¯†è§†ä¸ºä¸€ç§â€œä¸“å®¶æ¨¡æ€â€ï¼ˆexpert modalityï¼‰ï¼Œé€šè¿‡ä¸€ä¸ª**ç´§å‡‘çš„è¡¨ç¤ºå±‚æ¥å£**ï¼ˆrepresentation-level interfaceï¼‰å¯¹é½åˆ°å†»ç»“çš„åŸºç¡€æ¨¡å‹ï¼ˆfrozen base modelï¼‰ä¸­ã€‚
- ä¸ä¾èµ–äºæ–‡æœ¬åºåˆ—åŒ–çš„æ£€ç´¢è¿‡ç¨‹ï¼Œè€Œæ˜¯é€šè¿‡ä¸€ä¸ª**å•è¿ç»­ token æ³¨å…¥**ï¼ˆone-token injectionï¼‰æœºåˆ¶ï¼Œåœ¨ä¸ä¿®æ”¹åŸºç¡€æ¨¡å‹å‚æ•°çš„å‰æä¸‹æ³¨å…¥é¢†åŸŸçŸ¥è¯†ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç‰¹æ€§ | Fine-tuning | RAG | GAG |
|------|-----------|-----|-----|
| æ˜¯å¦ä¿®æ”¹åŸºç¡€æ¨¡å‹ | âœ… æ˜¯ | âŒ å¦ | âŒ å¦ |
| è¿­ä»£æˆæœ¬ | é«˜ | ä¸­ | ä½ |
| ä¸Šä¸‹æ–‡å‹åŠ› | æ—  | é«˜ï¼ˆé•¿ä¸Šä¸‹æ–‡ï¼‰ | æä½ï¼ˆå›ºå®šé¢„ç®—ï¼‰ |
| æ¨¡å—åŒ–æ‰©å±• | å›°éš¾ | å¯è¡Œä½†å¤æ‚ | âœ… å³æ’å³ç”¨ |
| é€‰æ‹©æ€§æ¿€æ´»å¯é æ€§ | ä½ | ä¸­ | âœ… é«˜ï¼ˆæ¥è¿‘Oracleï¼‰ |
| æŠ—æ£€ç´¢é”™è¯¯èƒ½åŠ› | å¼º | å¼± | âœ… å¼º |

GAG çš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºå®ç°äº†**å¸¸é‡é¢„ç®—ã€æ¨¡å—åŒ–ã€å¯æ‰©å±•ä¸”å¯é çš„ç§æœ‰çŸ¥è¯†æ³¨å…¥**ï¼Œé¿å…äº† prompt-time çš„è¯æ®åºåˆ—åŒ–ï¼ŒåŒæ—¶æ”¯æŒå¤šé¢†åŸŸç»„åˆã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **é€šç”¨é¢†åŸŸ QA åŸºå‡†**ï¼ˆ6ä¸ªå…¬å¼€æ•°æ®é›†ï¼‰ï¼š
  - FreebaseQA, HotpotQA, Natural Questions, TriviaQA, WebQuestions, PopQA
  - ç”¨äºè¯„ä¼°æ¨¡å‹åœ¨å¼€æ”¾åŸŸä»»åŠ¡ä¸­çš„é€šç”¨èƒ½åŠ›æ˜¯å¦å—æŸã€‚

- **ç§æœ‰é¢†åŸŸ QA åŸºå‡†**ï¼ˆ2ä¸ªç§‘å­¦é¢†åŸŸï¼‰ï¼š
  - **Immunology Adjuvant**ï¼ˆå…ç–«ä½å‰‚ï¼‰ï¼šæ¥è‡ªåŒ¿åç ”ç©¶ (Anonymous, 2025b)
  - **Catalytic Materials**ï¼ˆå‚¬åŒ–ææ–™ï¼‰ï¼šæ¥è‡ª Catalystbench (Anonymous, 2025a)
  - é…å¥—ç§æœ‰æ–‡çŒ®åº“ï¼šåˆ†åˆ«åŒ…å« 813 å’Œ 986 ç¯‡è®ºæ–‡ã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

- **åŸºç¡€æ¨¡å‹**ï¼š`Qwen3-8B`ï¼ˆå†»ç»“ï¼‰
- **é¢†åŸŸä¸“å®¶æ¨¡å‹**ï¼š`Qwen3-1.7B`
- **æŠ•å½±å™¨**ï¼ˆProjectorï¼‰ï¼šè½»é‡çº§ä¸¤å±‚ MLPï¼Œå°†ä¸“å®¶æ¨¡å‹è¾“å‡ºæ˜ å°„åˆ°åŸºç¡€æ¨¡å‹åµŒå…¥ç©ºé—´ã€‚
- **è·¯ç”±æœºåˆ¶**ï¼šPrototype Plug-and-Play Routing (PPR)ï¼ŒåŸºäºå†»ç»“ç¼–ç å™¨å’ŒåŸå‹èšç±»å®ç°æ— éœ€è®­ç»ƒçš„é€‰æ‹©æ€§æ¿€æ´»ã€‚

#### **è¯„ä¼°æŒ‡æ ‡**

| ç±»å‹ | æŒ‡æ ‡ | è¯´æ˜ |
|------|------|------|
| é€šç”¨é¢†åŸŸ | **Exact Match (EM)** | å­—ç¬¦ä¸²ç²¾ç¡®åŒ¹é…ï¼Œè¡¡é‡äº‹å®æ­£ç¡®æ€§ |
| ç§æœ‰é¢†åŸŸ | **BERTScore (with SciBERT)** | åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œæ›´é€‚åˆè‡ªç”±å½¢å¼ç­”æ¡ˆçš„æŠ€æœ¯é¢†åŸŸ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿ | æè¿° |
|------|------|
| **Base-Model-Only** | ä»…ä½¿ç”¨ `Qwen3-8B`ï¼Œæ— ä»»ä½•å¤–éƒ¨çŸ¥è¯† |
| **RAG** | ä½¿ç”¨ ColBERTv2 æ£€ç´¢ top-k æ–‡æ¡£å¹¶æ‹¼æ¥è‡³ prompt |
| **xRAG** | æç«¯å‹ç¼©ç‰ˆ RAGï¼Œä»…ä¿ç•™ 1 ä¸ª token çš„æ£€ç´¢æ‘˜è¦ |
| **EGC** (Expert-Generated Context) | é¢†åŸŸä¸“å®¶æ¨¡å‹ç”ŸæˆèƒŒæ™¯æ–‡æœ¬å¹¶è¿½åŠ è‡³ prompt |

æ‰€æœ‰æ–¹æ³•å‡åœ¨**å†»ç»“åŸºç¡€æ¨¡å‹**å‰æä¸‹è¿›è¡Œæ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

| æ–¹æ³• | Adjuvant (BERTScore) | Materials (BERTScore) | é€šç”¨å¹³å‡ (EM) | æ³¨å…¥ token æ•° |
|------|------------------------|-------------------------|----------------|----------------|
| Base-Model-Only | 56.12 | 60.01 | 42.16 | 0 |
| RAG | 59.97 (+6.86%) | 62.13 (+3.53%) | â€” | 375.17 |
| xRAG | 59.12 (+5.35%) | 62.24 (+3.72%) | â€” | 1 |
| EGC (Adjuvant) | 64.07 (+14.17%) | 58.60 (-2.35%) | â†“ æ˜¾è‘—ä¸‹é™ | 148.48 |
| EGC (Materials) | 54.22 (-3.39%) | 66.47 (+10.76%) | â†“ æ˜¾è‘—ä¸‹é™ | 165.21 |
| **GAG (Gen+Adj)** | **69.16 (+23.24%)** | 61.41 (+0.57%) | 42.31 (+0.36%) | **1** |
| **GAG (Gen+Adj+Mat)** | **69.17 (+23.25%)** | **71.36 (+18.91%)** | 42.35 (+0.45%) | **1** |

> âœ… GAG åœ¨ä¸¤ä¸ªç§æœ‰é¢†åŸŸåˆ†åˆ«æå‡ **15.34%** å’Œ **14.86%** ç›¸å¯¹äºå¼º RAG åŸºçº¿ï¼Œå¹¶**ç»´æŒé€šç”¨èƒ½åŠ›ä¸é€€åŒ–**ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- **RAG/xRAG**ï¼šæå‡æœ‰é™ï¼Œè¡¨æ˜**æ£€ç´¢è´¨é‡æ˜¯ç“¶é¢ˆ**ï¼Œè€Œéä¸Šä¸‹æ–‡é•¿åº¦ã€‚
- **EGC**ï¼šè™½ç„¶åœ¨åŒ¹é…é¢†åŸŸæœ‰æ•ˆï¼Œä½†ä¼šä¸¥é‡æŸå®³é€šç”¨èƒ½åŠ›ï¼Œä¸”è·¨é¢†åŸŸæ³›åŒ–å·®ã€‚
- **GAG**ï¼šé€šè¿‡**è¡¨ç¤ºå±‚å¯¹é½**ï¼ˆrepresentation-level alignmentï¼‰å®ç°é«˜ä¿¡å™ªæ¯”æ³¨å…¥ï¼Œé¿å…äº†æ–‡æœ¬ç«äº‰å’Œæ³¨æ„åŠ›ç¨€é‡Šã€‚

### **æ¶ˆèå®éªŒç»“æœ**

#### **(1) è·¯ç”±å‡†ç¡®æ€§ï¼ˆPPRï¼‰**

| è·¯ç”±é…ç½® | å¾®å¹³å‡å‡†ç¡®ç‡ (Micro acc.) | Gen | Adj | Mat |
|----------|----------------------------|-----|-----|-----|
| PPR (2 routes) | 99.78% | 99.65% | 99.91% | â€” |
| PPR (3 routes) | 99.55% | 99.65% | 99.38% | 99.69% |

âœ… è¡¨æ˜ PPR å®ç°äº†**æ¥è¿‘ Oracle çš„é€‰æ‹©æ€§æ¿€æ´»ç²¾åº¦**ï¼Œæ”¯æŒå¢é‡å¼å¤šé¢†åŸŸæ‰©å±•ã€‚

#### **(2) ä¸“å®¶æ¨¡å‹è¯»å‡ºå±‚æ¶ˆèï¼ˆReadout Layer Ablationï¼‰**

| è¯»å‡ºå±‚ | BERTScore | Î” ç›¸å¯¹æœ€ä¼˜ |
|--------|------------|-------------|
| L2-4 (default) | 69.72 | 0.00 |
| L2-2 | 69.20 | -0.52 |
| L2-8 | 69.38 | -0.34 |
| L2-24 | 58.42 | -11.30 |

âœ… æœ€ä¼˜è¯»å‡ºå±‚ä¸ºå€’æ•°ç¬¬4å±‚ï¼ˆL2-4ï¼‰ï¼Œè¡¨æ˜**è¯­ä¹‰æ•´åˆå……åˆ†ä½†æœªè¿‡åº¦ä¸“ä¸šåŒ–**çš„è¡¨ç¤ºæœ€é€‚åˆè¿ç§»ã€‚

#### **(3) ä¸¤é˜¶æ®µè®­ç»ƒæ¶ˆè**

| å˜ä½“ | æ˜¯å¦ Stage I | æ˜¯å¦ Stage II | BERTScore |
|------|--------------|---------------|------------|
| w/o Stage I | âŒ | âœ… | 57.14 |
| w/o Stage II | âœ… | âŒ | 55.64 |
| Full GAG | âœ… | âœ… | **69.72** |

âœ… ä¸¤ä¸ªé˜¶æ®µç¼ºä¸€ä¸å¯ï¼š
- Stage Iï¼šèµ‹äºˆä¸“å®¶æ¨¡å‹é¢†åŸŸçŸ¥è¯†
- Stage IIï¼šå¯¹é½è¡¨ç¤ºç©ºé—´ï¼Œå®ç°æœ‰æ•ˆæ³¨å…¥

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **GAG æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•**ï¼šåœ¨ç§æœ‰ç§‘å­¦ QA ä¸Šè¶…è¶Š RAG è¶…è¿‡ 15%ï¼ŒåŒæ—¶ä¿æŒé€šç”¨èƒ½åŠ›ç¨³å®šã€‚
2. **è¡¨ç¤ºå±‚æ³¨å…¥ä¼˜äºæ–‡æœ¬çº§æ³¨å…¥**ï¼šé¿å…äº† RAG çš„æ£€ç´¢è„†å¼±æ€§å’Œ EGC çš„æ³¨æ„åŠ›å¹²æ‰°ã€‚
3. **PPR å®ç°é«˜ç²¾åº¦å³æ’å³ç”¨è·¯ç”±**ï¼šæ— éœ€è®­ç»ƒå³å¯å®ç°è¿‘ Oracle çš„é€‰æ‹©æ€§æ¿€æ´»ï¼Œæ”¯æŒå¤šé¢†åŸŸåŠ¨æ€æ‰©å±•ã€‚
4. **å¸¸é‡é¢„ç®—æ¥å£æ›´å¯é¢„æµ‹**ï¼šå• token æ³¨å…¥ä½¿æ¨ç†è¡Œä¸ºä¸å—æ£€ç´¢æ·±åº¦æˆ–ä¸Šä¸‹æ–‡è†¨èƒ€å½±å“ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

1. **å•é¢†åŸŸå‡è®¾é™åˆ¶**ï¼šé»˜è®¤æ¯ä¸ªæŸ¥è¯¢åªå±äºä¸€ä¸ªé¢†åŸŸï¼Œéš¾ä»¥å¤„ç†**è·¨é¢†åŸŸå¤åˆé—®é¢˜**ã€‚
2. **æ•°å€¼ç²¾ç¡®æ€§æŒ‘æˆ˜**ï¼šç”±äºä¸ç›´æ¥å¤åˆ¶åŸæ–‡ï¼Œå¯èƒ½åœ¨éœ€è¦ç²¾ç¡®æ•°å­—/å•ä½çš„ä»»åŠ¡ä¸Šç•¥æœ‰åå·®ï¼ˆå¦‚ nm vs Î¼mï¼‰ã€‚
3. **ä¾èµ–é«˜è´¨é‡ä¸“å®¶æ¨¡å‹**ï¼šè‹¥é¢†åŸŸä¸“å®¶æ¨¡å‹æœ¬èº«èƒ½åŠ›ä¸è¶³ï¼Œæ³¨å…¥æ•ˆæœå—é™ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **å¤šé¢†åŸŸè”åˆæ³¨å…¥æœºåˆ¶**ï¼šæ¢ç´¢æ¦‚ç‡æ€§æˆ–å¤šè·¯æ³¨å…¥ï¼Œæ”¯æŒè·¨é¢†åŸŸçŸ¥è¯†èåˆã€‚
2. **åå¤„ç†æ•°å€¼æ ¡æ­£æ¨¡å—**ï¼šå¼•å…¥è½»é‡çº§éªŒè¯å™¨æå‡æ•°å€¼ä¿çœŸåº¦ã€‚
3. **æ›´é«˜æ•ˆçš„æŠ•å½±å™¨è®¾è®¡**ï¼šæ¢ç´¢æ›´å°å‚æ•°é‡æˆ–é›¶æ ·æœ¬å¯¹é½ç­–ç•¥ã€‚
4. **æ‰©å±•è‡³å¤šæ¨¡æ€ç§æœ‰çŸ¥è¯†æ³¨å…¥**ï¼šå¦‚ç»“åˆå›¾åƒã€å›¾è°±ç­‰éæ–‡æœ¬ç§æœ‰æ•°æ®æºã€‚

---

> **æ€»ç»“**ï¼šGAG æä¾›äº†ä¸€æ¡**æ¨¡å—åŒ–ã€å¯æ‰©å±•ã€æ²»ç†å‹å¥½**çš„ç§æœ‰çŸ¥è¯†æ³¨å…¥è·¯å¾„ï¼Œä¸º LLM åœ¨ä¼ä¸šçº§ã€ç§‘ç ”çº§åœºæ™¯ä¸­çš„å®‰å…¨ã€é«˜æ•ˆéƒ¨ç½²æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 9. [Silence the Judge: Reinforcement Learning with Self-Verifier via Latent Geometric Clustering](https://arxiv.org/abs/2601.08427)

**Authors**: Nonghai Zhang, Weitao Ma, Zhanyu Ma, Jun Xu, Jiuchong Gao, Jinghua Hao, Renqing He, Jingwen Xu  
**Category**: cs.CL  
**Published**: 2026-01-14  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.08427v1  

#### Abstract
Group Relative Policy Optimization (GRPO) significantly enhances the reasoning performance of Large Language Models (LLMs). However, this success heavily relies on expensive external verifiers or human rules. Such dependency not only leads to significant computational costs and training latency, but...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSilence the Judge: Reinforcement Learning with Self-Verifier via Latent Geometric Clustering

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰åŸºäºå¼ºåŒ–å­¦ä¹ çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†èƒ½åŠ›æå‡æ–¹æ³•ï¼ˆå¦‚ **GRPO**ï¼‰ä¸¥é‡ä¾èµ–æ˜‚è´µçš„å¤–éƒ¨éªŒè¯å™¨ï¼ˆexternal verifiersï¼‰ï¼Œä¾‹å¦‚äººå·¥è§„åˆ™æˆ–å¦ä¸€ä¸ª LLMï¼ˆå¦‚ GPT-4oï¼‰ä½œä¸ºâ€œJudgeâ€æ¥æä¾›å¥–åŠ±ä¿¡å·ã€‚è¿™ç§ä¾èµ–å¸¦æ¥äº†ä»¥ä¸‹é—®é¢˜ï¼š
- **é«˜è®¡ç®—æˆæœ¬ä¸è®­ç»ƒå»¶è¿Ÿ**ï¼šè°ƒç”¨å¤–éƒ¨ LLM éœ€è¦é¢å¤–æ¨ç†å¼€é”€ã€‚
- **ç¨€ç–ä¸”ç¦»æ•£çš„å¥–åŠ±ä¿¡å·**ï¼šé€šå¸¸ä¸ºäºŒå…ƒåé¦ˆï¼ˆ0/1ï¼‰ï¼Œç¼ºä¹å¯¹æ¨ç†è¿‡ç¨‹ç»†å¾®å·®å¼‚çš„æŒ‡å¯¼ã€‚
- **éªŒè¯å™¨åå·®ä¸ä¸ä¸€è‡´æ€§**ï¼šå¤–éƒ¨ Judge å¯èƒ½è¯„åˆ†ä¸å‡†æˆ–å­˜åœ¨åè§ï¼Œå½±å“è®­ç»ƒç¨³å®šæ€§ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡º **Latent-GRPO**ï¼Œä¸€ç§æ— éœ€å¤–éƒ¨ç›‘ç£çš„è‡ªéªŒè¯å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- **ä»æ½œç©ºé—´å‡ ä½•ç»“æ„ä¸­æå–å†…åœ¨å¥–åŠ±ä¿¡å·**ï¼šå‘ç°æ­£ç¡®æ¨ç†è·¯å¾„åœ¨ç»ˆç«¯ token çš„ `last hidden state` ä¸Šå½¢æˆå¯†é›†èšç±»ï¼Œè€Œé”™è¯¯è·¯å¾„åˆ™è¡¨ç°ä¸ºç¦»ç¾¤ç‚¹ã€‚
- å¼•å…¥ **Iterative Robust Centroid Estimation (IRCE)** ç®—æ³•ï¼š
  - å¯¹ç»ˆç«¯éšè—çŠ¶æ€è¿›è¡Œçƒé¢å½’ä¸€åŒ–ï¼ˆspherical projectionï¼‰ï¼Œæ¶ˆé™¤å¹…åº¦æ³¢åŠ¨ã€‚
  - è¿­ä»£åŠ æƒèšåˆï¼ŒåŠ¨æ€ä¼°è®¡ä¸€ä¸ªé²æ£’çš„â€œçœŸç›¸è´¨å¿ƒâ€ï¼ˆtruth centroidï¼‰ã€‚
  - å°†æ¯ä¸ªè½¨è¿¹åˆ°è¯¥è´¨å¿ƒçš„è·ç¦»å®šä¹‰ä¸ºè¿ç»­ã€ç¨ å¯†çš„å¥–åŠ±å€¼ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ•ˆç‡** | æ¶ˆé™¤å¤–éƒ¨éªŒè¯å™¨è°ƒç”¨ï¼Œè®­ç»ƒé€Ÿåº¦æå‡ **2Ã—ä»¥ä¸Š**ã€‚ |
| **å¥–åŠ±è´¨é‡** | æä¾›**ç¨ å¯†ã€è¿ç»­**çš„å¥–åŠ±ä¿¡å·ï¼Œä¼˜äºä¼ ç»Ÿçš„äºŒå…ƒå¥–åŠ±ï¼Œä¼˜åŒ–æ›´å¹³æ»‘ã€‚ |
| **ç¨³å®šæ€§** | é¿å…å¤–éƒ¨ Judge çš„å™ªå£°ä¸ä¸ä¸€è‡´ï¼Œé˜²æ­¢æ¨¡å‹å´©æºƒï¼ˆmodel collapseï¼‰ã€‚ |
| **é€šç”¨æ€§** | ä¸ä¾èµ–ä»»åŠ¡ç‰¹å®šè§„åˆ™ï¼Œé€‚ç”¨äºå¼€æ”¾åŸŸå¤æ‚æ¨ç†ä»»åŠ¡ã€‚ |
| **å¯æ‰©å±•æ€§** | å¥–åŠ±è®¡ç®—ä»…åŸºäºå·²æœ‰çš„å‰å‘ä¼ æ’­éšè—çŠ¶æ€ï¼Œæ— é¢å¤–æ¨ç†å¼€é”€ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | æè¿° |
|--------|------|
| **GSM8K** | å°å­¦æ•°å­¦åº”ç”¨é¢˜ï¼Œæµ‹è¯•åŸºç¡€å¤šæ­¥æ¨ç†èƒ½åŠ›ã€‚ |
| **MATH** | é«˜ä¸­åŠç«èµ›çº§æ•°å­¦é¢˜ï¼ŒæŒ‘æˆ˜é«˜çº§æ•°å­¦æ¨ç†ã€‚ |
| **Open-Platypus** | å¤šæºæ··åˆæŒ‡ä»¤æ•°æ®é›†ï¼Œæ¶µç›–ç‰©ç†ã€é€»è¾‘ã€æ•°å­¦ç­‰å¤šæ ·åŒ–æ¨ç†ä»»åŠ¡ã€‚ |

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹è§„æ¨¡**ï¼šåœ¨ **Qwen3-0.6B, 1.7B, 4B** ä¸‰ä¸ªå°ºåº¦ä¸ŠéªŒè¯ã€‚
- **ç¡¬ä»¶é…ç½®**ï¼šå• GPUï¼Œä½¿ç”¨ bfloat16 æ··åˆç²¾åº¦è®­ç»ƒã€‚
- **GRPO è®¾ç½®**ï¼šæ¯ç»„ç”Ÿæˆ 8 æ¡è½¨è¿¹ï¼ˆG=8ï¼‰ï¼Œbatch size=1ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Task Accuracy**ï¼šå„æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡ã€‚
  - **Training Time per Epoch**ï¼šè¡¡é‡è®­ç»ƒæ•ˆç‡ï¼ˆå•ä½ï¼šåˆ†é’Ÿï¼‰ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **LLM-as-Judge** | ä½¿ç”¨ GPT-4o å¯¹è¾“å‡ºæ–‡æœ¬æ‰“åˆ†ï¼Œè·å¾—äºŒå…ƒå¥–åŠ±ï¼ˆ0/1ï¼‰ã€‚ |
| **Rule-based Verification** | ä½¿ç”¨ SymPy ç¬¦å·è®¡ç®—æˆ–æ²™ç®±æ‰§è¡ŒéªŒè¯ç­”æ¡ˆï¼Œæä¾›ç²¾ç¡®ä½†ç¨€ç–çš„å¥–åŠ±ã€‚ |
| **Latent-GRPO (Ours)** | æå‡ºçš„æ–¹æ³•ï¼ŒåŸºäºæ½œç©ºé—´å‡ ä½•èšç±»ç”Ÿæˆå†…åœ¨å¥–åŠ±ã€‚ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

#### åœ¨ **GSM8K** ä¸Šçš„è¡¨ç°ï¼ˆQwen3-4Bï¼‰
| æ–¹æ³• | å‡†ç¡®ç‡ | æ¯è½®è®­ç»ƒæ—¶é—´ |
|------|--------|--------------|
| LLM-as-Judge | 79.87% | 651.45 min |
| **Latent-GRPO (Ours)** | **82.34%** | **658.21 min** |
- âœ… **å‡†ç¡®ç‡æ›´é«˜**ï¼ˆ+2.47%ï¼‰
- â±ï¸ è™½ç„¶æ—¶é—´ç•¥é•¿ï¼Œä½†å®é™…å› æ¶ˆé™¤äº†å¤–éƒ¨è°ƒç”¨ç“¶é¢ˆï¼Œåœ¨çœŸå®éƒ¨ç½²ä¸­æ›´å¿«ã€‚

> æ³¨ï¼šè¡¨ä¸­æ˜¾ç¤º Latent-GRPO æ—¶é—´ç¨é«˜ï¼Œæ˜¯å› ä¸ºæ¨¡æ‹Ÿäº† LLM-as-Judge çš„ QPS é™åˆ¶ï¼ˆ2 queries/secï¼‰ï¼Œè‹¥è€ƒè™‘æ’é˜Ÿç­‰å¾…ï¼ŒLatent-GRPO å®é™…å¿« **2.14Ã—**ã€‚

#### åœ¨ **MATH** ä¸Šçš„è¡¨ç°ï¼ˆQwen3-1.7Bï¼‰
| æ–¹æ³• | å‡†ç¡®ç‡ | æ¯è½®è®­ç»ƒæ—¶é—´ |
|------|--------|--------------|
| LLM-as-Judge | 65.77% | 1608.34 min |
| **Latent-GRPO (Ours)** | **78.51%** | **811.51 min** |
- âœ… **å‡†ç¡®ç‡å¤§å¹…æå‡**ï¼ˆ+12.74%ï¼‰
- â±ï¸ **è®­ç»ƒé€Ÿåº¦å¿«è¿‘ 2Ã—**ï¼ˆ1.98Ã— speedupï¼‰

#### åœ¨ **Open-Platypus** ä¸Šçš„è¡¨ç°ï¼ˆQwen3-4Bï¼‰
| æ–¹æ³• | å‡†ç¡®ç‡ | æ¯è½®è®­ç»ƒæ—¶é—´ |
|------|--------|--------------|
| LLM-as-Judge | 65.21% | 3522.18 min |
| **Latent-GRPO (Ours)** | **78.06%** | **1632.52 min** |
- âœ… **å‡†ç¡®ç‡æå‡å·¨å¤§**ï¼ˆ+12.85%ï¼‰
- â±ï¸ **è®­ç»ƒé€Ÿåº¦æå‡è¶…è¿‡ 2Ã—**ï¼ˆ2.16Ã— speedupï¼‰

> ğŸ’¡ ç»“è®ºï¼šLatent-GRPO åœ¨å¤æ‚ã€å¤šæ ·åŒ–çš„æ¨ç†ä»»åŠ¡ä¸Šä¼˜åŠ¿å°¤ä¸ºæ˜¾è‘—ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰éšè—çŠ¶æ€æå–æ–¹å¼å¯¹æ¯”ï¼ˆTable 2ï¼‰
| æ–¹æ³• | Qwen3-0.6B Acc | Qwen3-1.7B Acc | Qwen3-4B Acc |
|------|----------------|----------------|-------------|
| Mean Pooling | 58.74% | 71.05% | 79.45% |
| Weighted Mean | 57.12% | 69.88% | 78.12% |
| **Last Token (Ours)** | **61.25%** | **73.88%** | **82.34%** |

âœ… **ç»“è®º**ï¼šä½¿ç”¨ç»ˆç«¯ token çš„éšè—çŠ¶æ€æ•ˆæœæœ€ä½³ï¼Œè¯´æ˜æœ€ç»ˆè¯­ä¹‰å·²æ±‡èšäºæœ€åä¸€ä¸ªè¡¨ç¤ºä¸­ã€‚

#### ï¼ˆ2ï¼‰è´¨å¿ƒä¼°è®¡ç®—æ³•å¯¹æ¯”ï¼ˆTable 3ï¼‰
| æ–¹æ³• | Qwen3-0.6B Acc | Qwen3-1.7B Acc | Qwen3-4B Acc | æ—¶é—´ |
|------|----------------|----------------|-------------|------|
| Mean Pool | 57.12% | 68.45% | 77.89% | å¿« |
| K-Means | 58.85% | 70.12% | 79.23% | è¾ƒæ…¢ |
| Eigen Centrality | 59.43% | 71.56% | 80.56% | æ…¢ |
| **IRCE (Ours)** | **61.25%** | **73.88%** | **82.34%** | **æœ€å¿«** |

âœ… **ç»“è®º**ï¼šIRCE åœ¨å‡†ç¡®æ€§ä¸æ•ˆç‡ä¹‹é—´è¾¾åˆ°æœ€ä¼˜å¹³è¡¡ï¼Œå°¤å…¶é€‚åˆå®æ—¶è®­ç»ƒåœºæ™¯ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **æ½œç©ºé—´å…·æœ‰å¼ºå‡ ä½•ä¸€è‡´æ€§**ï¼šæ­£ç¡®çš„æ¨ç†è½¨è¿¹åœ¨ `last hidden state` ä¸Šé«˜åº¦èšé›†ï¼Œé”™è¯¯è½¨è¿¹åˆ†æ•£ï¼Œå½¢æˆâ€œå…±è¯†æ ¸å¿ƒ + ç¦»ç¾¤ç‚¹â€ç»“æ„ï¼ˆè§ Figure 2 & 5ï¼‰ã€‚
2. âœ… **æ½œç©ºé—´å¯ä½œä¸ºéšå¼éªŒè¯å™¨**ï¼šæ— éœ€å¤–éƒ¨æ¨¡å‹æˆ–è§„åˆ™ï¼Œå³å¯é€šè¿‡å‡ ä½•è·ç¦»åˆ¤æ–­æ¨ç†è´¨é‡ã€‚
3. âœ… **ç¨ å¯†å¥–åŠ±ä¼˜äºç¨€ç–å¥–åŠ±**ï¼šè¿ç»­å¥–åŠ±ä¿¡å·æä¾›äº†æ›´ä¸°å¯Œçš„æ¢¯åº¦ä¿¡æ¯ï¼ŒåŠ é€Ÿæ”¶æ•›å¹¶æå‡æœ€ç»ˆæ€§èƒ½ã€‚
4. âœ… **æ–¹æ³•å…·å¤‡è‰¯å¥½æ³›åŒ–æ€§**ï¼š
   - åœ¨ä¸åŒæ¨¡å‹å®¶æ—ï¼ˆQwen å’Œ **Llama3.2-3B**ï¼‰ä¸Šå‡æœ‰æ•ˆï¼ˆTable 5ï¼‰ã€‚
   - åœ¨æœªè§è¿‡çš„ä»»åŠ¡ï¼ˆMMLU, AIME, BBHï¼‰ä¸Šä¿æŒç”šè‡³è¶…è¶ŠåŸºçº¿æ€§èƒ½ï¼ˆTable 4ï¼‰ï¼Œè¡¨æ˜æœªå‘ç”Ÿè¿‡æ‹Ÿåˆã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. â— å½“å‰æ–¹æ³•ä¸»è¦åœ¨ **â‰¤8B å‚æ•°æ¨¡å‹** ä¸ŠéªŒè¯ï¼Œè¶…å¤§è§„æ¨¡æ¨¡å‹ï¼ˆå¦‚ 70B+ï¼‰çš„æ•ˆæœå°šå¾…æ¢ç´¢ã€‚
2. â— å¯¹**å¼€æ”¾å¼ç”Ÿæˆä»»åŠ¡**ï¼ˆå¦‚åˆ›æ„å†™ä½œï¼‰çš„é€‚ç”¨æ€§æœªçŸ¥ã€‚
3. â— ç¼ºä¹ä¸¥æ ¼çš„**æ•°å­¦ç†è®ºæ¡†æ¶**è§£é‡Šä¸ºä½•æ½œç©ºé—´ä¼šè‡ªç„¶å½¢æˆè¯­ä¹‰èšç±»ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ Latent-GRPO åœ¨æ›´å¤§æ¨¡å‹å’Œå¼€æ”¾ç”Ÿæˆä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚
- æ„å»ºå½¢å¼åŒ–çš„**æ½œç©ºé—´èšç±»ç†è®ºæ¨¡å‹**ã€‚
- ç ”ç©¶å°† IRCE å¥–åŠ±ä¸ç¦»çº¿å¯¹é½æ–¹æ³•ï¼ˆå¦‚ **DPO**ï¼‰ç»“åˆï¼Œæ„å»ºæ›´ç¨³å®šçš„è‡ªç›‘ç£å¯¹é½èŒƒå¼ã€‚

---

> ğŸ”š **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **Latent-GRPO æˆåŠŸâ€œæ²‰é»˜äº†æ³•å®˜â€ï¼ˆSilence the Judgeï¼‰ï¼Œè®© LLM å­¦ä¼šè‡ªæˆ‘è¯„åˆ¤â€”â€”é€šè¿‡æŒ–æ˜è‡ªèº«æ½œç©ºé—´çš„å‡ ä½•ç»“æ„ï¼Œå®ç°äº†é«˜æ•ˆã€ç¨³å®šã€æ— éœ€å¤–éƒ¨ä¾èµ–çš„å¼ºåŒ–å­¦ä¹ æ–°èŒƒå¼ã€‚**

</details>

---

### 10. [Get away with less: Need of source side data curation to build parallel corpus for low resource Machine Translation](https://arxiv.org/abs/2601.08629)

**Authors**: Saumitra Yadav, Manish Shrivastava  
**Category**: cs.CL  
**Published**: 2026-01-14  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.08629v1  

#### Abstract
Data curation is a critical yet under-researched step in the machine translation training paradigm. To train translation systems, data acquisition relies primarily on human translations and digital parallel sources or, to a limited degree, synthetic generation. But, for low-resource languages, human...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šGet away with less: Need of source side data curation to build parallel corpus for low resource Machine Translation

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**ä½èµ„æºæœºå™¨ç¿»è¯‘**ï¼ˆLow Resource Machine Translationï¼‰ä¸­ä¸€ä¸ªè¢«å¿½è§†çš„å…³é”®ç¯èŠ‚â€”â€”**æ•°æ®æ•´ç†**ï¼ˆdata curationï¼‰ã€‚åœ¨ä½èµ„æºè¯­è¨€åœºæ™¯ä¸‹ï¼Œè·å–é«˜è´¨é‡çš„å¹³è¡Œè¯­æ–™æˆæœ¬é«˜æ˜‚ï¼Œè€Œç°æœ‰çš„å¤§è§„æ¨¡ç½‘ç»œçˆ¬å–è¯­æ–™ï¼ˆå¦‚ OSCARã€Samanantarï¼‰å¾€å¾€åŒ…å«å¤§é‡ç®€å•æˆ–å†—ä½™å¥å­ï¼Œå¯¼è‡´è®­ç»ƒæ•ˆç‡ä½ä¸‹ã€‚ä¼ ç»Ÿåšæ³•æ˜¯â€œè¶Šå¤šè¶Šå¥½â€ï¼Œä½†æœ¬æ–‡æŒ‡å‡ºï¼Œè¿™ç§ç­–ç•¥å¹¶ä¸é«˜æ•ˆã€‚

### æå‡ºçš„æ–°æ–¹æ³•å’Œæ–°æ€è·¯
ä½œè€…æå‡ºäº†åä¸º **LALITA**ï¼ˆLexical And Linguistically Informed Text Analysisï¼‰çš„æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š

- **æå‡º LALITA Score**ï¼šä¸€ç§åŸºäºæºè¯­è¨€ï¼ˆsource sideï¼‰å¥å­å¤æ‚åº¦çš„é‡åŒ–è¯„åˆ†æœºåˆ¶ã€‚è¯¥åˆ†æ•°é€šè¿‡æå–å¥å­çš„**ç»Ÿè®¡ç‰¹å¾**ï¼ˆå¦‚å›°æƒ‘åº¦ï¼‰ã€**è¯æ±‡ç‰¹å¾**ï¼ˆå¦‚é•¿åº¦ï¼‰ã€**è¯­è¨€å­¦ç‰¹å¾**ï¼ˆå¦‚ä¾å­˜å…³ç³»ã€è¯æ€§æ ‡æ³¨ã€å½¢æ€ç‰¹å¾ç­‰ï¼‰ï¼Œç»ç”± **PCA**ï¼ˆä¸»æˆåˆ†åˆ†æï¼‰é™ç»´åï¼Œå°†ç¬¬ä¸€ä¸»æˆåˆ†ï¼ˆPCA1ï¼‰å®šä¹‰ä¸º LALITA Scoreã€‚å¾—åˆ†è¶Šé«˜ï¼Œè¡¨ç¤ºå¥å­ç»“æ„è¶Šå¤æ‚ã€‚
- **å¤æ‚å¥ä¼˜å…ˆé€‰æ‹©ç­–ç•¥**ï¼šä¸»å¼ åœ¨æœ‰é™çš„äººå·¥ç¿»è¯‘é¢„ç®—ä¸‹ï¼Œåº”ä¼˜å…ˆé€‰æ‹©**ç»“æ„æ›´å¤æ‚çš„æºè¯­è¨€å¥å­**è¿›è¡Œç¿»è¯‘ï¼Œä»¥æœ€å¤§åŒ–æ¯ä¸ªç¿»è¯‘å¯¹çš„å­¦ä¹ ä¿¡å·ã€‚
- **ä¸»åŠ¨å¼æ•°æ®æ•´ç†**ï¼šä¸åŒäºä¼ ç»Ÿçš„â€œäº‹åè¿‡æ»¤â€ï¼ˆreactive filteringï¼‰ï¼ŒLALITA æ˜¯ä¸€ç§â€œäº‹å‰ç­›é€‰â€ï¼ˆproactive selectionï¼‰ç­–ç•¥ï¼Œä»æºå¤´ä¸Šä¼˜åŒ–å¹³è¡Œè¯­æ–™çš„æ„å»ºè¿‡ç¨‹ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ•ˆç‡æ›´é«˜**ï¼šç›¸æ¯”éšæœºé‡‡æ ·æˆ–æŒ‰åŸå§‹æ¯”ä¾‹é‡‡æ ·çš„åŸºçº¿ï¼ŒLALITA èƒ½ç”¨æ›´å°‘çš„æ•°æ®è¾¾åˆ°ç›¸åŒç”šè‡³æ›´å¥½çš„ç¿»è¯‘è´¨é‡ã€‚
- **é€šç”¨æ€§å¼º**ï¼šä¸ä»…é€‚ç”¨äºä½èµ„æºè¯­è¨€ï¼Œåœ¨é«˜èµ„æºè¯­è¨€å¯¹ï¼ˆå¦‚è‹±è¯­-å¾·è¯­ï¼‰ä¸Šä¹Ÿè¡¨ç°å‡ºè‰²ã€‚
- **æŒ‡å¯¼æ•°æ®å¢å¼º**ï¼šå¯ç”¨äºæŒ‡å¯¼åˆæˆæ•°æ®ï¼ˆsynthetic dataï¼‰çš„ç”Ÿæˆä¸é€‰æ‹©ï¼Œç¡®ä¿å¢å¼ºæ•°æ®åŒæ ·å…·æœ‰é«˜å­¦ä¹ ä»·å€¼ã€‚
- **å‡å°‘è®­ç»ƒæˆæœ¬**ï¼šæ˜¾è‘—é™ä½æ‰€éœ€è®­ç»ƒæ•°æ®é‡ï¼Œä»è€ŒèŠ‚çœè®¡ç®—èµ„æºå’Œç¯å¢ƒæˆæœ¬ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **ä¸»å®éªŒæ•°æ®é›†**ï¼š**Samanantar è‹±å°åŒè¯­æ–‡æœ¬**ï¼ˆEnglish-Hindi bitextï¼‰ï¼Œç»è¿‡æ¸…æ´—åå¾—åˆ°çº¦ 185 ä¸‡å¯¹å¹³è¡Œå¥å¯¹ï¼ˆFiltered Parallel Sentences, FPSï¼‰ã€‚
- **å…¶ä»–ä½èµ„æºè¯­è¨€å¯¹**ï¼š
  - è‹±è¯­-å¥¥é‡Œäºšè¯­ï¼ˆEnglish-Odiaï¼‰
  - è‹±è¯­-å°¼æ³Šå°”è¯­ï¼ˆEnglish-Nepaliï¼‰
  - è‹±è¯­-æŒªå¨å°¼è¯ºæ–¯å…‹è¯­ï¼ˆEnglish-Norwegian Nynorskï¼‰
- **é«˜èµ„æºè¯­è¨€å¯¹**ï¼š**è‹±è¯­-å¾·è¯­**ï¼ˆEnglish-Germanï¼‰ï¼Œä½¿ç”¨ WMT24 æ•°æ®é›†ä¸­çš„ 2000 ä¸‡å¥å¯¹ã€‚
- **æµ‹è¯•é›†**ï¼šç»Ÿä¸€ä½¿ç”¨ **FLORES** æµ‹è¯•é›†è¿›è¡Œè¯„ä¼°ã€‚
- **å•è¯­æ•°æ®**ï¼šç”¨äºå›è¯‘ï¼ˆback-translationï¼‰ç”Ÿæˆåˆæˆæ•°æ®ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹æ¶æ„**ï¼šæ ‡å‡† **Transformer** æ¨¡å‹ã€‚
- **åˆ†è¯**ï¼šä½¿ç”¨ **Byte-Pair Encoding (BPE)**ï¼Œåˆå¹¶æ“ä½œæ•°ä¸º 16,000ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š**CHRF++** åˆ†æ•°ï¼ˆSacrebleu å·¥å…·åŒ…è®¡ç®—ï¼‰ã€‚
- **æ•°æ®è§„æ¨¡æ¨¡æ‹Ÿ**ï¼šåœ¨ 50K åˆ° 800K å¥å¯¹çš„ä¸åŒæ•°æ®è§„æ¨¡ä¸‹è¿›è¡Œå®éªŒï¼Œæ¨¡æ‹Ÿä½èµ„æºåœºæ™¯ã€‚
- **èšç±»æ–¹æ³•**ï¼šä½¿ç”¨ **Fisher-Jenks ç®—æ³•** å°†å¥å­æŒ‰ LALITA Score åˆ†ä¸º 4 ä¸ªç°‡ï¼ˆCluster 0â€“3ï¼‰ï¼Œå…¶ä¸­ Cluster 3 åŒ…å«æœ€å¤æ‚çš„å¥å­ã€‚
- **é…ç½®ç­–ç•¥**ï¼šé‡‡ç”¨ `<a,b,c,d>` å½¢å¼çš„é…ç½®ï¼Œè¡¨ç¤ºä»å››ä¸ªç°‡ä¸­åˆ†åˆ«é€‰å– a%ã€b%ã€c%ã€d% çš„å¥å­ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **RS**ï¼ˆRandomly Sampledï¼‰ï¼šä»å®Œæ•´è¯­æ–™ä¸­éšæœºæŠ½å–æŒ‡å®šæ•°é‡çš„å¥å¯¹ã€‚
- **baselineP**ï¼ˆProportionalï¼‰ï¼šæŒ‰åŸå§‹è¯­æ–™ä¸­å„ç°‡çš„æ¯”ä¾‹è¿›è¡Œé‡‡æ ·ã€‚
- **Full Dataset**ï¼šä½¿ç”¨å…¨éƒ¨æ¸…æ´—åçš„è¯­æ–™ï¼ˆå¦‚ 1.8M æˆ– 20M å¥å¯¹ï¼‰ä½œä¸ºæ€§èƒ½ä¸Šé™å‚è€ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| è¯­è¨€å¯¹ | åŸºçº¿ç³»ç»Ÿæœ€ä½³æ€§èƒ½ (CHRF++) | LALITA æœ€ä½³æ€§èƒ½ (CHRF++) | æ€§èƒ½æå‡ | æ‰€éœ€æ•°æ®é‡ | æ•°æ®ç¼©å‡æ¯”ä¾‹ |
|--------|--------------------------|-------------------------|----------|------------|--------------|
| **English-Hindi** | 51.63 (baselineP) | **53.84** | +2.21 | 800K | **â†“ 56%** (vs 1.8M) |
| **English-Odia** | 41.57 | **46.64** | +5.07 | 800K | **â†“ 86%** (vs 5.79M) |
| **English-Nepali** | 43.86 | **46.88** | +3.02 | 800K | **â†“ 51%** (vs 1.63M) |
| **English-Nynorsk** | 55.53 | **56.69** | +1.16 | 800K | **â†“ 36%** (vs 1.24M) |
| **English-German** | 51.87 | **58.24** | **+6.37** | 8M | **â†“ 60%** (vs 20M) |

> æ³¨ï¼šLALITA åœ¨è‹±è¯­-å¾·è¯­ä»»åŠ¡ä¸­ï¼Œä»…ç”¨ 800 ä¸‡å¥å¯¹å°±è¶…è¿‡äº†ä½¿ç”¨ 2000 ä¸‡å¥å¯¹çš„å…¨é‡æ¨¡å‹ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨æ‰€æœ‰è¯­è¨€å¯¹å’Œæ•°æ®è§„æ¨¡ä¸‹ï¼Œ**ä»¥ Cluster 3ï¼ˆå¤æ‚å¥ï¼‰ä¸ºä¸»çš„é…ç½®**ï¼ˆå¦‚ `0_0_0_100`ã€`0_20_20_60`ï¼‰å‡æ˜¾è‘—ä¼˜äº **RS** å’Œ **baselineP**ã€‚
- å³ä½¿åªä½¿ç”¨ 800K å¤æ‚å¥è®­ç»ƒçš„è‹±å°æ¨¡å‹ï¼Œå…¶æ€§èƒ½ä¹Ÿä¸ä½¿ç”¨ 1.8M å…¨é‡æ•°æ®çš„æ¨¡å‹ç›¸å½“ï¼Œä¸”**æ€» token æ•°å‡å°‘äº†çº¦ 64%**ã€‚
- åœ¨é«˜èµ„æºçš„è‹±å¾·ä»»åŠ¡ä¸­ï¼ŒLALITA ä¸ä»…å°†æ•°æ®éœ€æ±‚å‡å°‘ 60%ï¼Œè¿˜å®ç°äº† **+4.32 CHRF++** çš„ç»å¯¹æå‡ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **å•ä¸€ç‰¹å¾ vs LALITA Score**ï¼šä»…åŸºäº**æœ€é•¿å¥å­**æˆ–**æœ€å¤šåŠ¨è¯**çš„é€‰æ‹©ç­–ç•¥ï¼Œæ€§èƒ½è¿œä½äº LALITA Scoreã€‚ä¾‹å¦‚åœ¨ 800K è‹±å°æ•°æ®ä¸Šï¼ŒLALITA è¾¾åˆ° 53.84ï¼Œè€ŒåŸºäºæœ€é•¿å¥çš„ç­–ç•¥ä»…ä¸º 50.72ã€‚
- **åˆæˆæ•°æ®é€‰æ‹©**ï¼šå½“ä½¿ç”¨å•ä¸€ç‰¹å¾é€‰æ‹©åˆæˆæ•°æ®æ—¶ï¼Œæ€§èƒ½ä¸‹é™æ˜æ˜¾ï¼›è€Œä½¿ç”¨ LALITA Score é€‰æ‹©ï¼Œåˆ™èƒ½æœ‰æ•ˆæå‡æ€§èƒ½ã€‚
- **ç»“è®º**ï¼šLALITA Score çš„ä¼˜åŠ¿æ¥è‡ªäºå…¶**å¤šç»´åº¦è¯­è¨€å­¦ç‰¹å¾çš„ç»¼åˆè€ƒé‡**ï¼Œè€Œéä¾èµ–å•ä¸€å¯å‘å¼è§„åˆ™ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å¤æ‚å¥è•´å«æ›´å¼ºçš„å­¦ä¹ ä¿¡å·**ï¼šç»“æ„å¤æ‚çš„å¥å­èƒ½å¸®åŠ© MT æ¨¡å‹æ›´å¥½åœ°å­¦ä¹ å¥æ³•å’Œè¯­ä¹‰è§„å¾‹ï¼Œå³ä½¿æ•°é‡è¾ƒå°‘ä¹Ÿèƒ½å¸¦æ¥æ›´é«˜çš„æ€§èƒ½å¢ç›Šã€‚
2. **â€œå°‘å³æ˜¯å¤šâ€**ï¼šé€šè¿‡æ™ºèƒ½ç­›é€‰ï¼Œå¯ä»¥ç”¨**ä¸åˆ°ä¸€åŠçš„æ•°æ®é‡**å®ç°åŒç­‰ç”šè‡³æ›´ä¼˜çš„ç¿»è¯‘è´¨é‡ï¼Œå°¤å…¶åœ¨ä½èµ„æºåœºæ™¯ä¸‹æ•ˆæœæ˜¾è‘—ã€‚
3. **LALITA Score å…·æœ‰è·¨è¯­è¨€é€šç”¨æ€§**ï¼šè¯¥æ–¹æ³•åœ¨å°åº¦è¯­ç³»ï¼ˆHindi, Odia, Nepaliï¼‰ã€åŒ—æ¬§è¯­è¨€ï¼ˆNorwegian Nynorskï¼‰åŠé«˜èµ„æºè¯­è¨€ï¼ˆGermanï¼‰ä¸Šå‡æœ‰æ•ˆï¼Œè¡¨æ˜å…¶æ•æ‰çš„è¯­è¨€å¤æ‚åº¦å…·æœ‰æ™®é€‚æ€§ã€‚
4. **æ•°æ®æ•´ç†åº”å‰ç½®**ï¼šä¸å…¶äº‹åæ¸…æ´—å™ªå£°ï¼Œä¸å¦‚åœ¨æ•°æ®æ„å»ºé˜¶æ®µå°±ä¸»åŠ¨é€‰æ‹©é«˜ä»·å€¼æ ·æœ¬ï¼Œè¿™æ˜¯æ›´é«˜æ•ˆçš„ç­–ç•¥ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–æºè¯­è¨€è§£æå·¥å…·**ï¼šLALITA éœ€è¦é«˜è´¨é‡çš„æºè¯­è¨€å¥æ³•åˆ†æå™¨ï¼ˆå¦‚ Trankitï¼‰ï¼Œå¯¹äºçœŸæ­£ä½èµ„æºä¸”ç¼ºä¹ NLP å·¥å…·çš„è¯­è¨€å­˜åœ¨â€œå†·å¯åŠ¨â€é—®é¢˜ã€‚
- **è®¡ç®—æˆæœ¬é«˜**ï¼šæ¢ç´¢æœ€ä¼˜é…ç½®éœ€è¦å¤§é‡å®éªŒï¼Œè®¡ç®—å¼€é”€è¾ƒå¤§ã€‚
- **å±€é™äºå¥å­çº§åˆ«**ï¼šæœªè€ƒè™‘ç¯‡ç« çº§çš„è¿è´¯æ€§å’ŒæŒ‡ä»£æ¶ˆè§£ç­‰é«˜çº§è¯­è¨€ç°è±¡ã€‚
- **æœªä½¿ç”¨å¥å‘é‡**ï¼šå½“å‰ç‰ˆæœ¬æœªå¼•å…¥ LASERã€LaBSE ç­‰è¯­ä¹‰åµŒå…¥ä½œä¸ºç‰¹å¾ï¼Œå¯èƒ½é—æ¼éƒ¨åˆ†è¯­ä¹‰å¤æ‚åº¦ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **æé«˜æœç´¢æ•ˆç‡**ï¼šå¼€å‘æ›´é«˜æ•ˆçš„ç®—æ³•æ¥å¯»æ‰¾æœ€ä¼˜æ•°æ®é…ç½®ã€‚
- **æ‰©å±•è‡³å¤šè¯­è¨€å’Œéè‹±è¯­æºè¯­è¨€**ï¼šå°† LALITA æ¨å¹¿åˆ°æ›´å¤šè¯­è¨€ç»„åˆï¼Œå°¤å…¶æ˜¯éè‹±è¯­ä½œä¸ºæºè¯­è¨€çš„åœºæ™¯ã€‚
- **ç»“åˆè¯­ä¹‰ä¸ç¡®å®šæ€§**ï¼šå°† LALITA Score ä¸è¯­ä¹‰ä¸ç¡®å®šæ€§é‡‡æ ·ç»“åˆï¼Œæ„å»ºæ›´å…¨é¢çš„æ•°æ®å¢å¼ºç®¡é“ã€‚
- **åº”ç”¨äºè¯¾ç¨‹å­¦ä¹ **ï¼ˆCurriculum Learningï¼‰ï¼šæŒ‰ LALITA Score ä»æ˜“åˆ°éš¾åœ°ç»„ç»‡è®­ç»ƒæ•°æ®ï¼Œæ¨¡æ‹Ÿäººç±»å­¦ä¹ è¿‡ç¨‹ã€‚
- **æ•´åˆç¯‡ç« ä¿¡æ¯**ï¼šæ‰©å±•æ¡†æ¶ä»¥æ•æ‰è·¨å¥å­çš„è¯­ç¯‡å¤æ‚åº¦ã€‚
- **ç”¨äºå¤§æ¨¡å‹é¢„è®­ç»ƒ**ï¼šå°† LALITA Score åº”ç”¨äº LLM ç¬¬äºŒé˜¶æ®µè®­ç»ƒï¼Œæå‡é¢„è®­ç»ƒæ•°æ®è´¨é‡ã€‚

---

> **æ€»ç»“**ï¼šLALITA æä¾›äº†ä¸€ç§**ä»¥è¯­è¨€å­¦å¤æ‚åº¦ä¸ºå¯¼å‘çš„æ•°æ®æ•´ç†èŒƒå¼**ï¼Œè¯æ˜äº†åœ¨æœºå™¨ç¿»è¯‘ä¸­ï¼Œâ€œ**è´¨é‡èƒœäºæ•°é‡**â€ã€‚å®ƒä¸ä»…é™ä½äº†ä½èµ„æº MT çš„é—¨æ§›ï¼Œä¹Ÿä¸ºé«˜èµ„æºåœºæ™¯ä¸‹çš„é«˜æ•ˆè®­ç»ƒæä¾›äº†æ–°æ€è·¯ï¼Œå…·æœ‰é‡è¦çš„ç†è®ºå’Œåº”ç”¨ä»·å€¼ã€‚

</details>

---

### 11. [Where to Split? A Pareto-Front Analysis of DNN Partitioning for Edge Inference](https://arxiv.org/abs/2601.08025)

**Authors**: Adiba Masud, Nicholas Foley, Pragathi Durga Rajarajan, Palden Lama  
**Category**: cs.DC  
**Published**: 2026-01-14  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.08025v1  

#### Abstract
The deployment of deep neural networks (DNNs) on resource-constrained edge devices is frequently hindered by their significant computational and memory requirements. While partitioning and distributing a DNN across multiple devices is a well-established strategy to mitigate this challenge, prior res...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Where to Split? A Pareto-Front Analysis of DNN Partitioning for Edge Inference*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰é¢ä¸´è®¡ç®—å’Œå†…å­˜èµ„æºå—é™çš„æŒ‘æˆ˜ã€‚è™½ç„¶æ¨¡å‹åˆ†å‰²ï¼ˆDNN partitioningï¼‰æ˜¯ä¸€ç§å¸¸è§ç­–ç•¥ï¼Œä½†**ç°æœ‰ç ”ç©¶å¤§å¤šèšç„¦äºå•ç›®æ ‡ä¼˜åŒ–**ï¼ˆå¦‚æœ€å°åŒ–å»¶è¿Ÿæˆ–æœ€å¤§åŒ–ååé‡ï¼‰ï¼Œå¿½ç•¥äº†ç°å®åœºæ™¯ä¸­**å»¶è¿Ÿä¸ååé‡ä¹‹é—´çš„å¤æ‚æƒè¡¡å…³ç³»**ï¼Œå°¤å…¶æ˜¯åœ¨ç½‘ç»œæ¡ä»¶å¤šå˜çš„è¾¹ç¼˜ç¯å¢ƒä¸­ã€‚

### âœ… æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºå°† DNN åˆ†å‰²å»ºæ¨¡ä¸ºä¸€ä¸ª**å¤šç›®æ ‡ä¼˜åŒ–é—®é¢˜**ï¼Œå¹¶å¼•å…¥ **ParetoPipe** â€”â€” ä¸€ä¸ªå¼€æºæ¡†æ¶ï¼Œåˆ©ç”¨ **Pareto Front åˆ†æ** æ¥ç³»ç»Ÿè¯†åˆ«æœ€ä¼˜çš„æ¨¡å‹åˆ†å‰²ç­–ç•¥ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š
- **é¦–æ¬¡ç³»ç»Ÿæ€§åœ°åº”ç”¨ Pareto Front åˆ†æ** åˆ°è¾¹ç¼˜æ¨ç†ä¸­çš„ DNN åˆ†å‰²é—®é¢˜ï¼Œæ­ç¤ºäº†å»¶è¿Ÿä¸ååé‡ä¹‹é—´çš„çœŸå®æƒè¡¡è¾¹ç•Œã€‚
- è®¾è®¡å¹¶å®ç°äº† **ParetoPipe æ¡†æ¶**ï¼Œæ”¯æŒçµæ´»çš„åˆ†å¸ƒå¼æ¨ç†å®éªŒï¼Œå…·å¤‡åŒé€šä¿¡åç«¯ï¼ˆPyTorch RPC å’Œè‡ªå®šä¹‰è½»é‡çº§ TCP Socket å®ç°ï¼‰ã€‚
- å¼ºè°ƒ **block-level profiling** çš„é‡è¦æ€§ï¼ŒæŒ‡å‡ºä¸åŒæ¨¡å‹å—çš„è®¡ç®—æˆæœ¬å·®å¼‚æ˜¾è‘—ï¼Œå½±å“æœ€ä½³åˆ†å‰²ç‚¹çš„é€‰æ‹©ã€‚
- æ¢ç´¢äº†**ç½‘ç»œå»¶è¿Ÿä¸å¸¦å®½å¯¹ Pareto Frontier çš„å½±å“**ï¼ŒéªŒè¯äº†ç½‘ç»œæ˜¯è¾¹ç¼˜éƒ¨ç½²ä¸­çš„ä¸€ç­‰æ€§èƒ½ç“¶é¢ˆã€‚

### âœ… ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰æ–¹æ³• | æœ¬å·¥ä½œï¼ˆParetoPipeï¼‰ |
|------|--------|------------------|
| ä¼˜åŒ–ç›®æ ‡ | å•ç›®æ ‡ï¼ˆä»…å»¶è¿Ÿæˆ–ååï¼‰ | å¤šç›®æ ‡è”åˆåˆ†æï¼ˆå»¶è¿Ÿ vs ååï¼‰ |
| åˆ†ææ–¹å¼ | å¯»æ‰¾â€œæœ€ä¼˜â€å•ä¸€è§£ | æ„å»ºå®Œæ•´çš„ Pareto Frontierï¼Œæä¾›å†³ç­–ç©ºé—´ |
| ç½‘ç»œæ„ŸçŸ¥ | å¿½è§†æˆ–ç®€åŒ–ç½‘ç»œå˜åŒ– | æ˜¾å¼æ¨¡æ‹Ÿé«˜å»¶è¿Ÿ/ä½å¸¦å®½åœºæ™¯ï¼Œåˆ†æé²æ£’æ€§ |
| å·¥å…·æ”¯æŒ | å°é—­æˆ–ä¸“ç”¨ç³»ç»Ÿ | å¼€æºã€å¯æ‰©å±•ã€æ”¯æŒå¤šç§ backend |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šParetoPipe ä¸ä»…æ˜¯ä¸€ä¸ªå·¥å…·é“¾ï¼Œæ›´æ˜¯ä¸€ç§æ–°çš„åˆ†æèŒƒå¼ï¼Œå¸®åŠ©å¼€å‘è€…ç†è§£â€œæ²¡æœ‰ç»å¯¹æœ€ä¼˜â€çš„ç°å®ï¼Œå¹¶åŸºäºå®é™…éœ€æ±‚é€‰æ‹©åˆé€‚çš„åˆ†å‰²ç­–ç•¥ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“¦ æ•°æ®é›†ä¸æ¨¡å‹
- **æ•°æ®é›†**ï¼šä½¿ç”¨ **CIFAR-10** è¿›è¡Œå¾®è°ƒï¼ˆfine-tuningï¼‰ï¼Œé€‚é…è¾“å…¥å°ºå¯¸ï¼ˆ32Ã—32ï¼‰ï¼›åŸå§‹æƒé‡æ¥è‡ª ImageNet é¢„è®­ç»ƒã€‚
- **æµ‹è¯•çš„ DNN æ¨¡å‹**ï¼ˆå…±6ä¸ªï¼‰ï¼š
  - MobileNetV2
  - ResNet18
  - InceptionV3
  - ResNet50
  - AlexNet
  - VGG16  
  > è¦†ç›–ä»è½»é‡åˆ°é‡å‹ã€ä¸åŒæ¶æ„ç±»å‹çš„ CNN æ¨¡å‹ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼š
  - è¾¹ç¼˜èŠ‚ç‚¹ï¼šä¸¤ä¸ª Raspberry Pi 4Bï¼ˆ4æ ¸ CPUï¼Œ4GB RAMï¼‰
  - è¾¹ç¼˜æœåŠ¡å™¨ï¼šé…å¤‡ NVIDIA RTX 4090 GPUã€32æ ¸ CPUã€124GB å†…å­˜
  - ç½‘ç»œï¼šæœ‰çº¿ä»¥å¤ªç½‘ LANï¼ŒåŸºç¡€ RTT ~0.2â€“0.4ms
- **ç½‘ç»œæ¨¡æ‹Ÿ**ï¼šä½¿ç”¨ `tc` å·¥å…·æ³¨å…¥ **200ms å»¶è¿Ÿ + 5 Mbit/s å¸¦å®½é™åˆ¶**ï¼Œæ¨¡æ‹Ÿæ‹¥å¡ Wi-Fi åœºæ™¯ã€‚
- **éƒ¨ç½²æ¨¡å¼**ï¼š
  - **Pi-to-Pi**ï¼šä¸¤éƒ¨åˆ†å‡è¿è¡Œåœ¨æ ‘è“æ´¾ä¸Š
  - **Pi-to-GPU**ï¼šç¬¬ä¸€æ®µåœ¨ Pi ä¸Šæ‰§è¡Œï¼Œç¬¬äºŒæ®µå¸è½½è‡³ GPU æœåŠ¡å™¨

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **End-to-end Latency** | æ¯ batch çš„å®Œæ•´æ¨ç†è€—æ—¶ï¼ˆç§’ï¼‰ |
| **Throughput** | æ¯ç§’å¤„ç†å›¾åƒæ•°ï¼ˆimgs/sï¼‰ |
| **CPU Utilization** | ä½¿ç”¨ `psutil` ç›‘æ§å„è®¾å¤‡èµ„æºå ç”¨ |
| **Memory Usage** | æ¨¡å‹åˆ†åŒºå†…å­˜æ¶ˆè€— |
| **Network Overhead** | ä¸­é—´å¼ é‡ä¼ è¾“æ—¶é—´ |

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **é€šä¿¡åç«¯å¯¹æ¯”**ï¼š
  - **PyTorch RPC + TensorPipe**ï¼ˆæ ‡å‡†åˆ†å¸ƒå¼æ–¹æ¡ˆï¼‰
  - **Custom TCP Socket Implementation**ï¼ˆæœ¬æ–‡è½»é‡å®ç°ï¼‰
- **åˆ†å‰²ç­–ç•¥**ï¼šåœ¨æ¯ä¸ªæ¨¡å‹çš„ block è¾¹ç•Œå¤„è¿›è¡Œç©·ä¸¾åˆ†å‰²ï¼ˆexhaustive searchï¼‰ï¼Œç”Ÿæˆæ‰€æœ‰å¯èƒ½é…ç½®ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆåŸºäº Custom Backendï¼‰

#### ï¼ˆ1ï¼‰Pareto Frontier åˆ†æç»“æœï¼ˆFig. 3 & 4ï¼‰
- åœ¨ **Pi-to-Pi** è®¾ç½®ä¸‹ï¼š
  - è½»é‡æ¨¡å‹ï¼ˆå¦‚ MobileNetV2ï¼‰å¯é€šè¿‡éå¯¹ç§°åˆ†å‰²è·å¾—æ›´é«˜ååã€‚
  - ä¾‹å¦‚ï¼šMobileNetV2 æœ€ä½³ååå‡ºç°åœ¨ **P3**ï¼ˆå‰3å—ç•™æœ¬åœ°ï¼Œå…¶ä½™18å—é€è¿œç«¯ï¼‰ã€‚
  - å±‚æ¬¡åˆ†å¸ƒå‡åŒ€çš„æ¨¡å‹ï¼ˆå¦‚ AlexNetã€VGG16ï¼‰é€‚åˆå¯¹ç§°åˆ†å‰²ã€‚
- åœ¨ **Pi-to-GPU** è®¾ç½®ä¸‹ï¼š
  - å‡ ä¹æ‰€æœ‰æ¨¡å‹çš„æœ€ä½³ç­–ç•¥éƒ½æ˜¯**å°½æ—©å¸è½½**ï¼ˆearly offloadingï¼‰ï¼Œå› ä¸º GPU åŠ é€Ÿæ•ˆæœæ˜æ˜¾ã€‚
  - å¦‚ MobileNetV2 æœ€ä¼˜åˆ†å‰²ç‚¹ä¸º **P1**ï¼ˆä»…ç¬¬1å—åœ¨ Pi æ‰§è¡Œï¼Œå…¶ä½™20å—åœ¨ GPUï¼‰ã€‚

#### ï¼ˆ2ï¼‰ç½‘ç»œæ¶åŒ–ä¸‹çš„æ€§èƒ½é€€åŒ–ï¼ˆFig. 5 & 6ï¼‰
- å½“å¼•å…¥ **200ms å»¶è¿Ÿ + 5 Mbps å¸¦å®½**ï¼š
  - æ‰€æœ‰æ¨¡å‹çš„ Pareto Frontier æ˜æ˜¾å³ç§»ï¼ˆå»¶è¿Ÿä¸Šå‡ï¼‰ã€ä¸‹ç§»ï¼ˆååä¸‹é™ï¼‰ã€‚
  - **GPU çš„ç®—åŠ›ä¼˜åŠ¿è¢«é€šä¿¡å¼€é”€æ·¹æ²¡**ï¼šå³ä½¿ GPU æ‰§è¡Œæå¿«ï¼Œä»éœ€é•¿æ—¶é—´ç­‰å¾…ä¸­é—´æ•°æ®åˆ°è¾¾ã€‚
  - åŸå…ˆæœ€ä¼˜çš„ early offloading ç­–ç•¥ï¼ˆå¦‚ P1ï¼‰å˜å¾—æœ€å·®ï¼Œå› å…¶äº§ç”Ÿæœ€å¤§é€šä¿¡é‡ã€‚
  - æ–°çš„ Pareto æœ€ä¼˜ç‚¹å€¾å‘äº**ä¿ç•™æ›´å¤šè®¡ç®—åœ¨åˆå§‹è®¾å¤‡**ï¼Œå‡å°‘ä¼ è¾“æ•°æ®é‡ã€‚

#### ï¼ˆ3ï¼‰é€šä¿¡åç«¯å¯¹æ¯”ï¼ˆFig. 7ï¼‰
| æŒ‡æ ‡ | PyTorch RPCï¼ˆP15ï¼‰ | Custom Socketï¼ˆP3ï¼‰ | æå‡å¹…åº¦ |
|------|--------------------|---------------------|----------|
| Throughput | 5.1 img/s | **7.8 img/s** | â†‘ **53%** |
| End-to-end Latency | 1.58s | **0.37s** | â†“ **76%** |
| RPC Coordination Overhead | æ˜¾è‘—å­˜åœ¨ | å®Œå…¨æ¶ˆé™¤ | â€” |

> ğŸ’¡ è‡ªå®šä¹‰é€šä¿¡åç«¯å¤§å¹…é™ä½å¼€é”€ï¼Œå°¤å…¶é€‚ç”¨äºèµ„æºå—é™è¾¹ç¼˜ç¯å¢ƒã€‚

#### ï¼ˆ4ï¼‰èµ„æºåˆ©ç”¨ç‡åˆ†æï¼ˆTable II & IIIï¼‰
- é«˜ååé…ç½®é€šå¸¸å¯¼è‡´**åŒè®¾å¤‡é«˜ CPU åˆ©ç”¨ç‡**ï¼ˆæ¥è¿‘ 350%+ï¼Œè¡¨æ˜å¤šæ ¸é¥±å’Œï¼‰ã€‚
- ä½å»¶è¿Ÿé…ç½®å¸¸å‡ºç°**è´Ÿè½½ä¸å‡è¡¡**ï¼ˆå¦‚ Pi1 é«˜è´Ÿè½½ï¼ŒPi2 ç©ºé—²ï¼‰ã€‚
- Pi-to-GPU åœºæ™¯ä¸­ï¼ŒGPU åˆ©ç”¨ç‡æ™®éå¾ˆä½ï¼ˆ<4%ï¼‰ï¼Œè¯´æ˜å…¶å¤§éƒ¨åˆ†æ—¶é—´å¤„äºç­‰å¾…çŠ¶æ€ï¼ˆå—åˆ¶äºç½‘ç»œï¼‰ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **å»¶è¿Ÿä¸ååå­˜åœ¨æœ¬è´¨æƒè¡¡**ï¼šä¸å­˜åœ¨å•ä¸€â€œæœ€ä¼˜â€åˆ†å‰²ç‚¹ï¼Œåº”é€šè¿‡ Pareto Front è¿›è¡Œç³»ç»Ÿåˆ†æã€‚
2. **ç½‘ç»œæ˜¯è¾¹ç¼˜æ¨ç†çš„å…³é”®ç“¶é¢ˆ**ï¼šåœ¨çœŸå®ç½‘ç»œæ¡ä»¶ä¸‹ï¼Œé€šä¿¡å¼€é”€å¯èƒ½å®Œå…¨æŠµæ¶ˆå¼ºå¤§çš„æœ¬åœ°ç®—åŠ›ï¼ˆå¦‚ GPUï¼‰å¸¦æ¥çš„æ”¶ç›Šã€‚
3. **æœ€ä¼˜åˆ†å‰²ç‚¹éšç½‘ç»œåŠ¨æ€å˜åŒ–**ï¼š
   - ç†æƒ³ç½‘ç»œ â†’ å°½æ—©å¸è½½ï¼ˆoffload earlyï¼‰
   - æ¶åŠ£ç½‘ç»œ â†’ æœ¬åœ°å¤šç®—ã€å°‘ä¼ æ•°æ®
4. **block-level profiling è‡³å…³é‡è¦**ï¼šä¸åŒ block çš„è®¡ç®—å¯†åº¦å·®å¼‚å¤§ï¼Œç›´æ¥å½±å“åˆ†å‰²æ•ˆç‡ã€‚
5. **PyTorch RPC å­˜åœ¨æ˜¾è‘—è¿è¡Œæ—¶å¼€é”€**ï¼šå¯¹äºè¾¹ç¼˜åœºæ™¯ï¼Œè½»é‡çº§é€šä¿¡åè®®æ›´å…·ä¼˜åŠ¿ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä»…æ”¯æŒ **two-stage pipeline**ï¼ˆä¸¤ç«¯æµæ°´çº¿ï¼‰ï¼Œæœªæ¢ç´¢æ›´å¤æ‚çš„å¤šè®¾å¤‡æ‹“æ‰‘ã€‚
- æ‰€æœ‰å®éªŒåŸºäº **CNN æ¨¡å‹**ï¼Œæœªæ¶µç›– Transformer ç­‰æ–°å…´æ¶æ„ã€‚
- åˆ†å‰²ç²’åº¦ä¸º **block çº§åˆ«**ï¼Œæœªæ·±å…¥åˆ° layer æˆ– tensor çº§ç»†ç²’åº¦åˆ’åˆ†ã€‚
- ç¼ºä¹èƒ½é‡æ•ˆç‡ï¼ˆenergy consumptionï¼‰ä½œä¸ºä¼˜åŒ–ç›®æ ‡ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. å¼€å‘ **adaptive partitioning algorithm**ï¼šæ ¹æ®å®æ—¶ç½‘ç»œçŠ¶å†µåŠ¨æ€è°ƒæ•´åˆ†å‰²ç‚¹ã€‚
2. å¼•å…¥ **energy efficiency** ä½œä¸ºç¬¬ä¸‰ç»´ä¼˜åŒ–ç›®æ ‡ï¼Œæ„å»ºä¸‰ç»´ Pareto Frontã€‚
3. æ”¯æŒ **multi-device pipelines** å’Œ **hybrid partitioning**ï¼ˆç»“åˆ tensor/pipeline å¹¶è¡Œï¼‰ã€‚
4. æ‰©å±•è‡³ **Transformer-based models**ï¼ˆå¦‚ BERTã€ViTï¼‰çš„è¾¹ç¼˜æ¨ç†ä¼˜åŒ–ã€‚
5. é›†æˆ **model compression** æŠ€æœ¯ï¼ˆå¦‚é‡åŒ–ã€å‰ªæï¼‰ä¸åˆ†å‰²ååŒè®¾è®¡ã€‚

---

## æ€»ç»“
è¯¥è®ºæ–‡é€šè¿‡ **ParetoPipe æ¡†æ¶** å’Œç³»ç»Ÿçš„å®éªŒåˆ†æï¼Œæ­ç¤ºäº†è¾¹ç¼˜ç¯å¢ƒä¸‹ DNN åˆ†å‰²çš„å¤æ‚æƒè¡¡æœ¬è´¨ã€‚å®ƒä¸ä»…æä¾›äº†å®ç”¨å·¥å…·ï¼Œæ›´é‡è¦çš„æ˜¯å€¡å¯¼äº†ä¸€ç§**ä»å•ç›®æ ‡ä¼˜åŒ–è½¬å‘å¤šç›®æ ‡æƒè¡¡åˆ†æ**çš„æ–°è§†è§’ï¼Œå¼ºè°ƒ**ç½‘ç»œæ„ŸçŸ¥**å’Œ**å®é™…éƒ¨ç½²æ¡ä»¶çš„é‡è¦æ€§**ï¼Œä¸ºæœªæ¥è¾¹ç¼˜ AI ç³»ç»Ÿçš„è®¾è®¡æä¾›äº†åšå®çš„åŸºç¡€å’ŒæŒ‡å¯¼åŸåˆ™ã€‚

</details>

---

### 12. [Forecast Aware Deep Reinforcement Learning for Efficient Electricity Load Scheduling in Dairy Farms](https://arxiv.org/abs/2601.08052)

**Authors**: Nawazish Alia, Rachael Shawb, Karl Mason  
**Category**: cs.AI  
**Published**: 2026-01-14  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.08052v1  

#### Abstract
Dairy farming is an energy intensive sector that relies heavily on grid electricity. With increasing renewable energy integration, sustainable energy management has become essential for reducing grid dependence and supporting the United Nations Sustainable Development Goal 7 on affordable and clean ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬ç ”ç©¶é’ˆå¯¹ç°ä»£å¥¶ç‰›åœºä¸­é«˜èƒ½è€—æ“ä½œï¼ˆå¦‚ç”µæ± å‚¨èƒ½å’Œçƒ­æ°´åŠ çƒ­ï¼‰åœ¨åŠ¨æ€ç”µä»·å’Œå¯å†ç”Ÿèƒ½æºé—´æ­‡æ€§ä¾›åº”ä¸‹çš„ç”µåŠ›è´Ÿè·è°ƒåº¦æŒ‘æˆ˜ã€‚ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning, RLï¼‰æ–¹æ³•é€šå¸¸å‡è®¾å¯¹æœªæ¥ä»·æ ¼æˆ–å‘ç”µé‡æœ‰å®Œå…¨å…ˆéªŒçŸ¥è¯†ï¼Œè¿™åœ¨ç°å®ç¯å¢ƒä¸­ä¸åˆ‡å®é™…ï¼›åŒæ—¶ï¼Œæ ‡å‡†çš„ **Proximal Policy Optimization (PPO)** ç®—æ³•ä¾èµ–å›ºå®šçš„è£å‰ªé˜ˆå€¼æˆ–KLæ•£åº¦é™åˆ¶ï¼Œåœ¨ç”µä»·æ³¢åŠ¨å‰§çƒˆæ—¶å®¹æ˜“å¯¼è‡´è®­ç»ƒä¸ç¨³å®šã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
è¯¥è®ºæ–‡æå‡ºäº†ä¸¤ä¸ªåŸºäº **PPO** çš„æ”¹è¿›æ¡†æ¶ï¼š

- **Forecast-Aware PPO (F-PPO)**  
  å°†çŸ­æœŸéœ€æ±‚ä¸å¯å†ç”Ÿèƒ½æºç”Ÿæˆé¢„æµ‹ä¿¡å·æ•´åˆè¿›æ™ºèƒ½ä½“çš„è§‚æµ‹ç©ºé—´ã€‚é€šè¿‡â€œå°æ—¶-æœˆâ€æ®‹å·®æ ¡å‡†ï¼ˆHour-of-Day and Month-based Residual Calibrationï¼‰æŠ€æœ¯ç”Ÿæˆç»“æ„åŒ–é¢„æµ‹è¾“å…¥ï¼Œä½¿ç­–ç•¥èƒ½å¤Ÿå‰ç»æ€§åœ°åšå‡ºå†³ç­–ï¼Œè€Œéä»…ååº”å¼å“åº”å½“å‰çŠ¶æ€ã€‚

- **PID-KL PPO**  
  å¼•å…¥ä¸€ä¸ª **Proportional-Integral-Derivative (PID) æ§åˆ¶å™¨** æ¥åŠ¨æ€è°ƒèŠ‚KLæ•£åº¦æƒ©ç½šç³»æ•° $ c_{KL} $ï¼Œä»è€Œå®ç°è‡ªé€‚åº”çš„ä¿¡ä»»åŒºåŸŸæ§åˆ¶ã€‚è¿™ç§æ–¹æ³•èƒ½æ ¹æ®æ¯æ¬¡æ›´æ–°åç­–ç•¥å˜åŒ–çš„ç¨‹åº¦è‡ªåŠ¨è°ƒæ•´æ›´æ–°æ­¥é•¿ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§ï¼Œå‡å°‘å¯¹è¶…å‚æ•°è°ƒä¼˜çš„ä¾èµ–ã€‚

æ­¤å¤–ï¼Œæ¨¡å‹ç»“åˆäº†GRUç½‘ç»œå¯¹é¢„æµ‹åºåˆ—è¿›è¡Œç¼–ç ï¼Œå¹¶åµŒå…¥äº†çœŸå®è¿è¡Œçº¦æŸï¼ˆå¦‚ç”µæ± SOCè¾¹ç•Œã€çƒ­æ°´å™¨æ¯æ—¥è¿è¡Œæ—¶é—´è¦æ±‚ï¼‰ï¼Œç¡®ä¿è°ƒåº¦æ–¹æ¡ˆå…·å¤‡å®é™…å¯è¡Œæ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´è´´è¿‘ç°å®åœºæ™¯**ï¼šæ‘’å¼ƒäº†å¯¹æœªæ¥ç”µä»·/å‘ç”µé‡å…¨çŸ¥çš„å‡è®¾ï¼Œé‡‡ç”¨å¯è§£é‡Šä¸”ç¡®å®šæ€§çš„é¢„æµ‹æœºåˆ¶ã€‚
- **æ›´å¼ºçš„è®­ç»ƒç¨³å®šæ€§**ï¼šPID-KLæœºåˆ¶æ˜¾è‘—é™ä½äº†å¥–åŠ±æ³¢åŠ¨å¸¦æ¥çš„ç­–ç•¥éœ‡è¡ï¼Œæ”¶æ•›æ›²çº¿æ›´åŠ å¹³æ»‘ã€‚
- **æ›´é«˜çš„æˆæœ¬æ•ˆç›Šä¸å¯é æ€§**ï¼šç›¸æ¯”æ ‡å‡†PPOã€DQNã€SACç­‰åŸºçº¿ç®—æ³•ï¼Œåœ¨é™ä½ç”µè´¹ã€å‰Šå‡å³°å€¼è´Ÿè½½å’Œæé«˜ç”¨æˆ·æ»¡æ„åº¦æ–¹é¢è¡¨ç°æ›´ä¼˜ã€‚
- **é›¶çº¦æŸè¿å**ï¼šæ‰€æœ‰F-PPOå˜ä½“å‡å®ç°äº†é›¶è¿è§„ï¼ˆæ— è¿‡å……/è¿‡æ”¾ã€æ— è¿è¡Œæ—¶é—´ä¸è¶³ï¼‰ï¼Œè€Œéƒ¨åˆ†åŸºçº¿å­˜åœ¨æ˜æ˜¾è¿åã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **ç”µæ± è°ƒåº¦ä»»åŠ¡**ï¼šä½¿ç”¨èŠ¬å…°VTTæä¾›çš„å…¬å¼€å¥¶ç‰›åœºç”¨ç”µæ•°æ®ï¼ˆå¹´æ€»è€—ç”µé‡çº¦261 MWï¼‰ï¼Œç»“åˆNREL SAMæ¨¡æ‹Ÿçš„20kWå…‰ä¼ç³»ç»Ÿå‘ç”µæ•°æ®åŠèµ«å°”è¾›åŸºç”µåŠ›ä¾›åº”å•†çš„åŠ¨æ€ç”µä»·ã€‚
- **çƒ­æ°´å™¨è°ƒåº¦ä»»åŠ¡**ï¼šé‡‡ç”¨çˆ±å°”å…°å¥¶ç‰›åœºçš„ç ”ç©¶æ•°æ®é›†ï¼ŒåŒ…å«è®¾å¤‡çº§æ‹†åˆ†ç”¨ç”µä¿¡æ¯ï¼ˆæ¥è‡ª200å¤´è§„æ¨¡å†œåœºï¼‰ã€20kWå…‰ä¼æ•°æ®ï¼ˆSAMç”Ÿæˆï¼‰ä»¥åŠElectric Irelandçš„æ—¶é—´åˆ†æ®µç”µä»·ï¼ˆTime-of-Use Tariffsï¼‰ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **ç¯å¢ƒå»ºæ¨¡ä¸ºMarkov Decision Process (MDP)**ï¼š
  - **ç”µæ± è°ƒåº¦**ï¼šçŠ¶æ€åŒ…æ‹¬æ—¶é—´ã€SOCã€è´Ÿè½½åŠŸç‡ã€å…‰ä¼è¾“å‡ºï¼›åŠ¨ä½œä¸ºå……ç”µ/æ”¾ç”µ/ç©ºé—²ï¼›å¥–åŠ±å‡½æ•°ç»¼åˆè€ƒè™‘ç”µç½‘è´­ç”µæˆæœ¬ä¸ç”µæ± å¥åº·æƒ©ç½šã€‚
  - **çƒ­æ°´å™¨è°ƒåº¦**ï¼šçŠ¶æ€æ‰©å±•è‡³ç”µä»·ã€èƒŒæ™¯è´Ÿè½½ã€å‡€åŠŸè€—ã€è®¾å¤‡åŠŸè€—ã€å‰©ä½™éœ€è¿è¡Œæ—¶é—´ç­‰ï¼›åŠ¨ä½œä¸ºON/OFFï¼›å¥–åŠ±ç”±æˆæœ¬é¡¹ä¸ä»»åŠ¡å®Œæˆåº¦å…±åŒæ„æˆã€‚
- **è®­ç»ƒé…ç½®**ï¼š
  - æ‰€æœ‰ç®—æ³•è®­ç»ƒ100ä¸‡æ—¶é—´æ­¥ï¼ˆtimestepsï¼‰
  - ä½¿ç”¨CleanRLæ¡†æ¶ä¿è¯å¤ç°æ€§å’Œä¸€è‡´æ€§
  - è¶…å‚æ•°è§æ–‡ä¸­Table 1 & Table 2

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **æ°´ heater è°ƒåº¦å¯¹æ¯”ç®—æ³•**ï¼š
  - **Standard PPO**
  - **Deep Q-Network (DQN)**
  - **Soft Actor-Critic (SAC)**
- **ç”µæ± è°ƒåº¦å¯¹æ¯”ç®—æ³•**ï¼š
  - **Q-learning**
  - **Rule-based ç­–ç•¥**

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»ï¼ˆæ¥è‡ªTable 3ä¸æ­£æ–‡ï¼‰

| ç®—æ³• | æ€»ç”µè´¹ (â‚¬) | è¾ƒæ ‡å‡†PPOé™å¹… | è¿è§„å¤©æ•° |
|------|-----------|----------------|----------|
| DQN | 16,418 | +4.3% â†‘ | 60å¤©underuse |
| Standard PPO | 15,744 | â€” | 0 |
| Forecast-Aware PPO (F-PPO) | 15,635 | â†“0.7% | 0 |
| F-PPO (dropout=0.15) | 15,582 | â†“1.0% | 17å¤©underuse |
| PID-KL PPO | 15,624 | â†“0.8% | ~1å¤©underuse |
| Discrete SAC | 15,773 | â†‘0.2% â†‘ | 0 |

> æ³¨ï¼šâ€œâ†“â€è¡¨ç¤ºæ›´ä½ï¼ˆæ›´å¥½ï¼‰ï¼Œâ€œâ†‘â€è¡¨ç¤ºæ›´é«˜ï¼ˆæ›´å·®ï¼‰

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ç›¸å¯¹äºDQN**ï¼š
  - F-PPOå®ç° **4.76% çš„ç”µè´¹èŠ‚çœ**
  - å¹³å‡æ¯æ—¥å³°å€¼éœ€æ±‚é™ä½ **13.75%**
  - ç”¨æˆ·æ»¡æ„åº¦ä»80%æå‡è‡³99%
  - ç»Ÿè®¡æ£€éªŒï¼ˆWilcoxon signed-rank testï¼‰æ˜¾ç¤ºæ‰€æœ‰å·®å¼‚å‡æ˜¾è‘—ï¼ˆp=0.0019**ï¼‰

- **ç›¸å¯¹äºæ ‡å‡†PPO**ï¼š
  - F-PPOè¿›ä¸€æ­¥é™ä½ç”µè´¹ **~1%**
  - PID-KL PPOè™½æœ€ç»ˆæˆæœ¬ç›¸è¿‘ï¼Œä½†è¡¨ç°å‡ºæ›´ç¨³å®šçš„è®­ç»ƒè¿‡ç¨‹ï¼ˆæ–¹å·®æ›´å°ï¼Œæ”¶æ•›æ›´å¿«ï¼‰

- **ç”µæ± è°ƒåº¦ç»“æœ**ï¼š
  - PPOç›¸è¾ƒæ— ç”µæ± åœºæ™¯å‡å°‘ **13.11% çš„ç”µç½‘è¿›å£ç”µé‡**
  - æ¯”Q-learningå’Œrule-basedæ–¹æ³•åˆ†åˆ«å¤šèŠ‚çœ **1.62% å’Œ 2.56%** çš„ç”µç½‘ä¾èµ–

### æ¶ˆèå®éªŒç»“æœ
- **é¢„æµ‹æ¨¡å—æœ‰æ•ˆæ€§**ï¼šå¼•å…¥forecast blockï¼ˆå«ä¸­ä½æ•°æˆ–ç™¾åˆ†ä½åŒºé—´ï¼‰åï¼ŒF-PPOç›¸æ¯”æ ‡å‡†PPOå–å¾—ç¨³å®šæˆæœ¬ä¸‹é™ï¼ˆçº¦1%ï¼‰ï¼Œè¯æ˜é¢„æµ‹ä¿¡æ¯æœ‰åŠ©äºæå‰è§„åˆ’ã€‚
- **GRUç¼–ç å™¨ä½œç”¨**ï¼šGRUæˆåŠŸæ•æ‰é¢„æµ‹ä¿¡å·ä¸­çš„æ—¶é—´ä¾èµ–å…³ç³»ï¼Œæ”¯æŒä¸»åŠ¨è°ƒåº¦ã€‚
- **PID-KLæœºåˆ¶ä¼˜åŠ¿**ï¼šå°½ç®¡æœ€ç»ˆæ€§èƒ½æ¥è¿‘F-PPOï¼Œä½†å…¶è®­ç»ƒè¿‡ç¨‹æ›´ä¸ºå¹³ç¨³ï¼Œrewardæ›²çº¿æ³¢åŠ¨æ›´å°ï¼ˆè§Figure 10ï¼‰ï¼Œè¯´æ˜å…¶å¢å¼ºäº†é²æ£’æ€§ã€‚
- **Dropoutè°ƒå‚å½±å“**ï¼šå°†GRU dropoutä»0.10å¢è‡³0.15å¯è¿›ä¸€æ­¥é™ä½æˆæœ¬ï¼ˆè¾¾1.5%ï¼‰ï¼Œä½†å¸¦æ¥æ›´å¤šunderuseå¤©æ•°ï¼ˆ17å¤©ï¼‰ï¼Œè¡¨æ˜å­˜åœ¨**æˆæœ¬ä¼˜åŒ–ä¸çº¦æŸæ»¡è¶³ä¹‹é—´çš„æƒè¡¡**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **é¢„æµ‹æ„ŸçŸ¥å‹PPOæ˜¾è‘—ä¼˜äºä¼ ç»ŸRLæ–¹æ³•**ï¼šF-PPOé€šè¿‡èåˆçŸ­æœŸé¢„æµ‹ä¿¡æ¯ï¼Œèƒ½å¤Ÿåœ¨ç”µä»·ä½è°·æœŸå’Œå…‰ä¼å‘ç”µé«˜å³°æœŸä¸»åŠ¨å®‰æ’ç”¨ç”µï¼Œæœ‰æ•ˆé™ä½è¿è¥æˆæœ¬å¹¶å‰Šå³°å¡«è°·ã€‚
2. **PID-KLæœºåˆ¶æå¤§æå‡äº†è®­ç»ƒç¨³å®šæ€§**ï¼šé¢å¯¹ç”µä»·å‰§çƒˆæ³¢åŠ¨ï¼Œä¼ ç»Ÿçš„å›ºå®šKLé˜ˆå€¼éš¾ä»¥ç»´æŒç¨³å®šå­¦ä¹ ï¼Œè€ŒPIDæ§åˆ¶å™¨å¯æ ¹æ®å®é™…KLåå·®åŠ¨æ€è°ƒèŠ‚æƒ©ç½šå¼ºåº¦ï¼Œé¿å…ç­–ç•¥çªå˜ã€‚
3. **æ‰€ææ–¹æ³•å…¼å…·é«˜æ€§èƒ½ä¸é«˜å¯é æ€§**ï¼šåœ¨å¤šä¸ªçœŸå®æ•°æ®é›†ä¸ŠéªŒè¯ï¼Œæ–°æ–¹æ³•ä¸ä»…å®ç°äº†ç»æµæ€§æœ€ä¼˜ï¼Œè¿˜ä¸¥æ ¼éµå®ˆè®¾å¤‡è¿è¡Œçº¦æŸï¼Œé€‚ç”¨äºå®é™…éƒ¨ç½²ã€‚
4. **æ°´ heater æ˜¯å…³é”®å¯è°ƒåº¦è´Ÿè·**ï¼šåˆç†è°ƒåº¦è¿™ä¸€é«˜èƒ½è€—è®¾å¤‡å¯æ˜¾è‘—æ”¹å–„æ•´ä½“èƒ½æ•ˆï¼Œå°¤å…¶åœ¨å¤å­£å…‰ä¼å……è¶³æ—¶æ®µæ•ˆæœçªå‡ºã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **é¢„æµ‹æ¨¡å‹è¾ƒç®€å•**ï¼šç›®å‰é‡‡ç”¨çš„æ˜¯seasonal-naiveåŠ æ®‹å·®å¸¦çš„æ–¹æ³•ï¼Œè™½å…·å¯è§£é‡Šæ€§ï¼Œä½†åœ¨æç«¯å¤©æ°”æˆ–çªå‘äº‹ä»¶ä¸‹å¯èƒ½å¤±æ•ˆã€‚
- **å•æ™ºèƒ½ä½“æ¶æ„**ï¼šå½“å‰ä¸ºå•ä¸€agentæ§åˆ¶å•ä¸€è®¾å¤‡ï¼Œæœªè€ƒè™‘å¤šè®¾å¤‡ååŒä¼˜åŒ–é—®é¢˜ã€‚
- **ç¦»æ•£åŠ¨ä½œç©ºé—´é™åˆ¶**ï¼šä»…æ”¯æŒON/OFFæˆ–Charge/Discharge/Idleç­‰æœ‰é™åŠ¨ä½œï¼Œæ— æ³•ç²¾ç»†è°ƒæ§åŠŸç‡æ°´å¹³ã€‚
- **æœªè€ƒè™‘è®¾å¤‡è€åŒ–ä¸ç»´æŠ¤æˆæœ¬**ï¼šè™½ç„¶åŠ å…¥äº†SOCè¾¹ç•Œä¿æŠ¤ï¼Œä½†æœªæ˜¾å¼å»ºæ¨¡é•¿æœŸé€€åŒ–æ•ˆåº”ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ **Multi-Agent Reinforcement Learning (MARL)** æ¶æ„ä»¥åè°ƒå¤šä¸ªç”¨ç”µè®¾å¤‡ï¼ˆå¦‚æŒ¤å¥¶æœºã€å†·å´ç³»ç»Ÿã€æ°´æ³µç­‰ï¼‰ã€‚
- é›†æˆæ›´å¤šç±»å‹çš„å¯å†ç”Ÿèƒ½æºï¼ˆå¦‚é£èƒ½ã€æ²¼æ°”ï¼‰åŠå…¶è”åˆè°ƒåº¦ç­–ç•¥ã€‚
- åº”ç”¨ **Evolutionary Reinforcement Learning** æå‡è®­ç»ƒé²æ£’æ€§ä¸æ³›åŒ–èƒ½åŠ›ã€‚
- å¼€å‘åœ¨çº¿è‡ªé€‚åº”é¢„æµ‹æ¨¡å—ï¼Œæ›¿ä»£é™æ€æ®‹å·®æ ¡å‡†æ–¹æ³•ï¼Œå¢å¼ºåº”å¯¹ä¸ç¡®å®šæ€§èƒ½åŠ›ã€‚
- åœ¨çœŸå®å†œåœºç¯å¢ƒä¸­è¿›è¡Œå®åœ°éƒ¨ç½²ä¸é•¿æœŸè¿è¡Œæµ‹è¯•ã€‚

--- 

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§èåˆçŸ­æœŸé¢„æµ‹ä¸è‡ªé€‚åº”KLæ§åˆ¶çš„ **Forecast-Aware Deep Reinforcement Learning** æ¡†æ¶ï¼Œåœ¨çœŸå®å¥¶ç‰›åœºè´Ÿè·è°ƒåº¦ä»»åŠ¡ä¸­å®ç°äº†æ›´ä½æˆæœ¬ã€æ›´é«˜ç¨³å®šæ€§å’Œæ›´å¼ºå®ç”¨æ€§çš„èƒ½æºç®¡ç†è§£å†³æ–¹æ¡ˆï¼Œæ¨åŠ¨å†œä¸šé¢†åŸŸå‘å¯æŒç»­æ™ºèƒ½åŒ–è¿ˆè¿›ã€‚

</details>

---

### 13. [Attention Projection Mixing and Exogenous Anchors](https://arxiv.org/abs/2601.08131)

**Authors**: Jonathan Su  
**Category**: cs.CL  
**Published**: 2026-01-14  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.08131v1  

#### Abstract
Transformers that reuse early-layer attention projections as residuals face a fundamental tension: the first layer must simultaneously serve as a stable reference for all deeper layers and as an effective computational block. To resolve this, we propose ExoFormer, which learns dedicated exogenous an...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Attention Projection Mixing and Exogenous Anchors*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
Transformer æ¨¡å‹ä¸­ï¼Œ**ç¬¬ä¸€å±‚æ³¨æ„åŠ›æŠ•å½±**è¢«åŒæ—¶ç”¨ä½œä¸¤ä¸ªè§’è‰²ï¼š
1. **å¯é‡ç”¨çš„é”šç‚¹ï¼ˆReusable Anchorï¼‰**ï¼šä¸ºæ‰€æœ‰æ·±å±‚æä¾›ç¨³å®šçš„å‚è€ƒè¡¨ç¤ºï¼›
2. **è®¡ç®—å—ï¼ˆComputational Blockï¼‰**ï¼šè¿›è¡Œç‰¹å¾å˜æ¢ä»¥æ”¯æŒé€å±‚æŠ½è±¡ã€‚

è¿™ç§åŒé‡è§’è‰²å¯¼è‡´â€œ**ç¬¬ä¸€å±‚å¼ åŠ›ï¼ˆFirst-Layer Tensionï¼‰**â€â€”â€”æ—¢è¦ä¿æŒç¨³å®šä¸å˜ä»¥ä¾›å¤ç”¨ï¼Œåˆè¦çµæ´»å˜åŒ–ä»¥æ”¯æŒè®¡ç®—ï¼ŒäºŒè€…æœ¬è´¨ä¸Šå­˜åœ¨å†²çªï¼Œé™åˆ¶äº†æ¨¡å‹æ€§èƒ½ã€‚

æ­¤å¤–ï¼Œå°½ç®¡å·²æœ‰å·¥ä½œï¼ˆå¦‚ ResFormerï¼‰å°è¯•é€šè¿‡æ®‹å·®è¿æ¥ä¿ç•™æ—©æœŸä¿¡æ¯ï¼ˆå¦‚ä»…å¯¹ `V` æŠ•å½±ï¼‰ï¼Œä½†æœªç³»ç»Ÿæ¢ç´¢å¯¹ **Queriesã€Keysã€Gate Logits** ç­‰å…¶ä»–æ³¨æ„åŠ›è·¯å¾„çš„è·¨å±‚æ··åˆï¼Œä¸”ç¼ºä¹ç»Ÿä¸€æ¡†æ¶ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

#### ï¼ˆ1ï¼‰ç»Ÿä¸€çš„å½’ä¸€åŒ–æ··åˆæ¡†æ¶ï¼ˆNormalized Unified Mixingï¼‰
æå‡º **NuResFormer**ï¼Œä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œåœ¨æ‰€æœ‰æ³¨æ„åŠ›è·¯å¾„ï¼ˆ`Q`, `K`, `V`, `G`ï¼‰ä¸Šå®ç°è·¨å±‚æ··åˆï¼š
- å¼•å…¥å¯å­¦ä¹ çš„æ··åˆç³»æ•°ï¼ˆ`Î»â‚`, `Î»â‚‚`ï¼‰ï¼Œæ§åˆ¶å½“å‰å±‚æŠ•å½±ä¸æ—©æœŸé”šç‚¹ä¹‹é—´çš„åŠ æƒèåˆï¼›
- åœ¨æ··åˆå‰å¯¹é”šç‚¹æºåº”ç”¨ **RMSNorm**ï¼Œè§£å†³åˆ†å¸ƒä¸åŒ¹é…é—®é¢˜ï¼Œæå‡ç¨³å®šæ€§ä¸æ•ˆæœã€‚

#### ï¼ˆ2ï¼‰ExoFormerï¼šå¤–ç”Ÿé”šç‚¹è§£è€¦æ¶æ„
æå‡º **ExoFormer**ï¼Œæ ¸å¿ƒåˆ›æ–°æ˜¯å°†â€œé”šç‚¹â€è§’è‰²ä»ç¬¬ä¸€å±‚ä¸­å‰¥ç¦»ï¼š
- é”šç‚¹ä¸å†æ¥è‡ªç¬¬ä¸€å±‚è¾“å‡ºï¼Œè€Œæ˜¯ç”±è¾“å…¥åµŒå…¥ç»**ç‹¬ç«‹çš„å¤–éƒ¨æŠ•å½±æ¨¡å—**ç”Ÿæˆï¼ˆå³ *exogenous anchor*ï¼‰ï¼›
- è¿™ç§**è§£è€¦è®¾è®¡**å…è®¸ï¼š
  - å¤–éƒ¨é”šç‚¹ä¸“æ³¨äºä¿ç•™ token èº«ä»½ä¿¡æ¯ï¼ˆidentity preservationï¼‰ï¼›
  - å†…éƒ¨å±‚ä¸“æ³¨äºæ¸è¿›å¼è®¡ç®—ä¼˜åŒ–ï¼ˆcomputational refinementï¼‰ã€‚

#### ï¼ˆ3ï¼‰åŠ¨æ€æ··åˆæ¨¡å—ï¼ˆDynamic Mixing, DMï¼‰
å— MUDDFormer å¯å‘ï¼Œå¼•å…¥ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„åŠ¨æ€æ··åˆæœºåˆ¶ï¼š
- ä½¿ç”¨å°å‹ MLP æ ¹æ®å½“å‰å±‚è¾“å…¥ç”Ÿæˆè°ƒåˆ¶å› å­ï¼Œå®æ—¶è°ƒæ•´æ··åˆæƒé‡ï¼›
- å®ç°æ›´çµæ´»ã€è‡ªé€‚åº”çš„ä¿¡æ¯å¤ç”¨ç­–ç•¥ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **æ€§èƒ½æå‡** | æ‰€æœ‰ ExoFormer å˜ä½“å‡ä¼˜äºå¯¹åº”çš„å†…éƒ¨é”šç‚¹ç‰ˆæœ¬ï¼ˆNuResFormerï¼‰ï¼Œåœ¨ä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®ç‡å’Œå›°æƒ‘åº¦ï¼ˆPPLï¼‰ä¸Šå…¨é¢é¢†å…ˆã€‚ |
| **æ•°æ®æ•ˆç‡** | Dynamic ExoFormer ä»…ç”¨ **1.84Ã— æ›´å°‘çš„è®­ç»ƒ token** å³å¯è¾¾åˆ°åŸºçº¿éªŒè¯æŸå¤±ï¼Œæ˜¾è‘—æå‡è®­ç»ƒæ•ˆç‡ã€‚ |
| **æ³¨æ„åŠ›è¡Œä¸ºä¼˜åŒ–** | ç›¸æ¯”æ ‡å‡† Gated Attentionï¼ŒExoFormer å°† **attention sink å‡å°‘ 2Ã—**ï¼Œé¿å…è¿‡åº¦å‹ç¼©å¸¦æ¥çš„ä¿¡æ¯ä¸¢å¤±ã€‚ |
| **ç†è®ºè§£é‡ŠåŠ›å¼º** | æå‡ºâ€œ**Offloading Hypothesis**â€ï¼Œåˆç†è§£é‡Šä¸ºä½•æ¨¡å‹åœ¨å‡ºç°è¡¨å¾åç¼©ï¼ˆrepresentation collapseï¼‰çš„æƒ…å†µä¸‹ä»èƒ½å–å¾—æ›´é«˜æ€§èƒ½ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **é¢„è®­ç»ƒæ•°æ®**ï¼šFineWeb-Edu å­é›†ï¼ˆ10B tokensï¼‰ï¼Œç¬¦åˆ Chinchilla ç¼©æ”¾å®šå¾‹ï¼›
- **è¯„ä¼°åŸºå‡†**ï¼š6 ä¸ªå¤šé¡¹é€‰æ‹©é¢˜ä»»åŠ¡ï¼š
  - ARC-C, ARC-E
  - HellaSwag
  - OpenBookQA (OBQA)
  - PIQA
  - Winogrande

### å®éªŒè®¾ç½®
- **æ¨¡å‹è§„æ¨¡**ï¼šçº¦ 450M å‚æ•°ï¼ˆBase: 454M, ExoFormer: 457Mï¼‰ï¼›
- **åºåˆ—é•¿åº¦**ï¼š2048ï¼›
- **æ‰¹é‡å¤§å°**ï¼š262,144 tokensï¼›
- **ä¼˜åŒ–å™¨**ï¼šMuonï¼ˆä¸»å‚æ•°ï¼‰ + AdamWï¼ˆ1D å‚æ•°ï¼‰ï¼Œå¯ç”¨ cautious weight decayï¼›
- **ç²¾åº¦**ï¼šBF16ï¼Œä½¿ç”¨ FlashAttention åŠ é€Ÿï¼›
- **è®­ç»ƒé¢„ç®—**ï¼š10B tokensã€‚

### è¯„ä¼°æŒ‡æ ‡
- **ä¸‹æ¸¸æ€§èƒ½**ï¼šå¹³å‡å‡†ç¡®ç‡ï¼ˆAvg. Acc %ï¼‰ï¼›
- **è¯­è¨€å»ºæ¨¡èƒ½åŠ›**ï¼šéªŒè¯é›†å›°æƒ‘åº¦ï¼ˆPPLï¼‰ï¼›
- **åˆ†ææŒ‡æ ‡**ï¼š
  - Attention entropy
  - Token è¡¨ç¤ºç›¸ä¼¼æ€§ï¼ˆcosine similarityï¼‰
  - ä¸»æˆåˆ†æ ¸å¿ƒç‰¹å¾æ•°ï¼ˆPCA Core Featuresï¼Œè¡¡é‡å†…åœ¨ç»´åº¦ï¼‰
  - Attention sink å¼ºåº¦

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ¨¡å‹ | ç‰¹ç‚¹ |
|------|------|
| Base Transformer | åŸå§‹æ¶æ„ |
| Gated Attention | å¼•å…¥é—¨æ§æœºåˆ¶è°ƒèŠ‚ attention è¾“å‡º |
| ResFormer | ä»…å¯¹ `Vâ‚` æ·»åŠ æ®‹å·®è¿æ¥ |
| Naive Combination | Gated Attention + ResFormer ç›´æ¥ç»„åˆ |
| NuResFormer | ç»Ÿä¸€æ¡†æ¶ + ç¬¬ä¸€å±‚ä½œä¸ºå†…éƒ¨é”šç‚¹ |
| ExoFormer | ç»Ÿä¸€æ¡†æ¶ + å¤–éƒ¨é”šç‚¹ï¼ˆæœ¬æ–‡æå‡ºï¼‰ |
| Dynamic ExoFormer | ExoFormer + åŠ¨æ€æ··åˆæ¨¡å— |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1 & A3ï¼‰

| æ¨¡å‹ | Avg. Acc (%) | PPL | å‚æ•°é‡ (M) |
|------|--------------|-----|-----------|
| Base Transformer | 48.14 | 14.79 | 454 |
| Gated Attention | 48.80 | 14.64 | 453 |
| ResFormer | 49.65 | 14.32 | 454 |
| NuResFormer (E) | 49.68 | 14.15 | 453 |
| **ExoFormer (E)** | **49.85** | **14.13** | 457 |
| **Dynamic ExoFormer** | **50.27** | **14.09** | 457 |

> âœ… **Dynamic ExoFormer è¾¾åˆ°æœ€é«˜å‡†ç¡®ç‡ï¼ˆ50.27%ï¼‰å’Œæœ€ä½å›°æƒ‘åº¦ï¼ˆ14.09ï¼‰**

---

### ä¸åŸºçº¿å¯¹æ¯”ç»“æœ

- **ç›¸æ¯” ResFormer**ï¼š
  - å‡†ç¡®ç‡ â†‘ 0.62 ptsï¼ˆDynamic ExoFormer vs ResFormerï¼‰
  - PPL â†“ 0.23
- **ç›¸æ¯” NuResFormer**ï¼š
  - æ‰€æœ‰ ExoFormer å˜ä½“å‡ä¼˜äºå¯¹åº” NuResFormerï¼Œè¯æ˜**å¤–ç”Ÿé”šç‚¹ä¼˜äºå†…ç”Ÿé”šç‚¹**
- **æ•°æ®æ•ˆç‡**ï¼š
  - Dynamic ExoFormer ç”¨ **1.84Ã— æ›´å°‘çš„æ•°æ®**å³å¯åŒ¹é…åŸºçº¿éªŒè¯æŸå¤±
- **Attention Sink æŠ‘åˆ¶**ï¼ˆTable 2ï¼‰ï¼š
  - Baseline: 0.2572
  - Gated Attention: 0.0091
  - **ExoFormer: 0.0041**, **Dynamic ExoFormer: 0.0073**
  - â†’ **å‡å°‘è¶…è¿‡ 2Ã—**

---

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰æ˜¯å¦å½’ä¸€åŒ–é”šç‚¹ï¼Ÿ
- è‹¥ä¸å¯¹é”šç‚¹åš RMSNormï¼ˆ`no norm`ï¼‰ï¼Œåˆ™ anchor pathway è¢«ä¸¥é‡æŠ‘åˆ¶ï¼ˆè¿‘é›¶ç³»æ•°æ¯”ä¾‹ä¸‰å€äºå½’ä¸€åŒ–ç‰ˆæœ¬ï¼‰ï¼Œè¯´æ˜ **RMSNorm å¯¹ç¨³å®šæ··åˆè‡³å…³é‡è¦**ã€‚

#### ï¼ˆ2ï¼‰æ··åˆç²’åº¦ï¼ˆGranularityï¼‰çš„å½±å“ï¼ˆAppendix Bï¼‰
| æ¨¡å‹ | æœ€ä½³ç²’åº¦ | ç»“æœ |
|------|----------|------|
| NuResFormer | Scalar (S) | æœ€é«˜ä¸‹æ¸¸å‡†ç¡®ç‡ï¼ˆ49.83%ï¼‰ |
| ExoFormer | Elementwise (E) | æœ€ä½³ç»¼åˆè¡¨ç°ï¼ˆ49.85%, PPL=14.13ï¼‰ |

â†’ è¡¨æ˜ **ExoFormer å› è§£è€¦æ›´å¹²å‡€ï¼Œèƒ½æ›´å¥½åˆ©ç”¨ç»†ç²’åº¦æ§åˆ¶**

#### ï¼ˆ3ï¼‰ä¸åŒè·¯å¾„æ®‹å·®çš„æœ‰æ•ˆæ€§**
- **Q/K æ®‹å·®ä¸ç¨³å®š** â†’ éœ€é…åˆ QKNorm æ‰å¯è®­ç»ƒï¼›
- **åŠ ä¸Š RMSNorm åˆ°æ®‹å·®æºåæ€§èƒ½è¿›ä¸€æ­¥æå‡**ï¼›
- **Gating Logits æ®‹å·®å¤©ç„¶ç¨³å®š**ï¼ˆå› ç» sigmoid å‹ç¼©ï¼‰ï¼Œæ— éœ€é¢å¤–å½’ä¸€åŒ–ä¹Ÿå¯æœ‰æ•ˆèåˆã€‚

#### ï¼ˆ4ï¼‰åŠ¨æ€æ··åˆ vs é™æ€æ··åˆ**
- Dynamic ExoFormer åœ¨é€šé“å’Œå±‚é—´å±•ç°å‡ºæ›´å‡åŒ€çš„æ··åˆç³»æ•°åˆ†å¸ƒï¼ˆå›¾3dï¼‰ï¼Œè¡¨æ˜å…¶å…·å¤‡æ›´å¼ºçš„ä¸Šä¸‹æ–‡é€‚åº”èƒ½åŠ›ï¼›
- åœ¨è·¯ç”±ï¼ˆQ/Kï¼‰å’Œé€‰æ‹©ï¼ˆGï¼‰ç»„ä»¶ä¸Šå°¤å…¶å—ç›Šã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

#### âœ… **ExoFormer æ˜¾è‘—ä¼˜äºå†…éƒ¨é”šç‚¹æ¶æ„**
- è§£è€¦â€œé”šç‚¹â€ä¸â€œè®¡ç®—â€è§’è‰²å¸¦æ¥æŒç»­æ”¶ç›Šï¼›
- å³ä½¿å‚æ•°ç•¥æœ‰å¢åŠ ï¼ˆ+3Mï¼‰ï¼Œä¹Ÿèƒ½åœ¨ç›¸åŒå®½åº¦/æ·±åº¦ä¸‹å®ç° SOTA æ€§èƒ½ã€‚

#### âœ… **è¡¨å¾åç¼© â‰  æ€§èƒ½ä¸‹é™ â€”â€” Offloading Hypothesis**
è¿™æ˜¯æœ¬æ–‡æœ€åç›´è§‰ä¹Ÿæœ€é‡è¦çš„å‘ç°ï¼š
- ExoFormer å±‚å†… token è¡¨ç¤ºé«˜åº¦ç›¸ä¼¼ï¼ˆå›¾2eï¼Œé«˜è¾¾ 95%ï¼‰ï¼Œå†…åœ¨ç»´åº¦æä½ï¼ˆ~738 vs baseline 839ï¼‰ï¼›
- ä½†æ€§èƒ½åè€Œæœ€å¥½ã€‚

ä¸ºæ­¤æå‡º **Offloading Hypothesis**ï¼š
> å¤–éƒ¨é”šç‚¹æ‰¿æ‹…äº†â€œèº«ä»½ä¿ç•™â€çš„èŒè´£ï¼Œä½¿å¾—ä¸»å¹²ç½‘ç»œå¯ä»¥å®Œå…¨ä¸“æ³¨äºâ€œä¿¡å·æçº¯â€å’Œâ€œé€æ­¥æ¨ç†â€ã€‚æ‰€è°“çš„â€œåç¼©â€å®é™…ä¸Šæ˜¯**ä¸»åŠ¨ä¸¢å¼ƒå†—ä½™é™æ€ä¿¡æ¯çš„è¿‡ç¨‹**ï¼Œæ˜¯ä¸€ç§åŠŸèƒ½ä¸“ä¸šåŒ–è€Œéé€€åŒ–ã€‚

#### âœ… **ExoFormer æ”¹å˜äº†ä¿¡æ¯å¤„ç†æµç¨‹**
- æ ‡å‡† Transformer éµå¾ª Mix â†’ Compress â†’ Refine ä¸‰é˜¶æ®µï¼›
- ExoFormer æå‰è¿›å…¥å¹¶é•¿æœŸåœç•™åœ¨ **Refinement é˜¶æ®µ**ï¼ˆå æ€»å±‚æ•° 2/3ï¼‰ï¼Œè·³è¿‡å‰§çƒˆå‹ç¼©ï¼›
- å¾—ç›Šäºé—¨æ§å’Œæ®‹å·®æ··åˆæä¾›çš„åˆ†å¸ƒå¼è¿‡æ»¤æœºåˆ¶ï¼Œæ— éœ€ä¾èµ– attention sinkã€‚

---

### æ–¹æ³•çš„å±€é™æ€§ï¼ˆSection 6ï¼‰

1. **å®éªŒè§„æ¨¡æœ‰é™**ï¼šä»…åœ¨ ~450M å‚æ•°ã€10B tokens ä¸ŠéªŒè¯ï¼Œå¯èƒ½æ— æ³•æ¨å¹¿è‡³æ›´å¤§æ¨¡å‹æˆ–æ›´é•¿è®­ç»ƒï¼›
2. **è¶…å‚æœç´¢ä¸è¶³**ï¼šæœªç³»ç»Ÿæ¢ç´¢æ··åˆç³»æ•°åˆå§‹åŒ–ç­–ç•¥ï¼›
3. **è¯„ä¼°èŒƒå›´å—é™**ï¼šé›†ä¸­åœ¨å¤šé¡¹é€‰æ‹©ä»»åŠ¡ï¼Œç¼ºä¹å¯¹é•¿æ–‡æœ¬ç”Ÿæˆã€ä¸Šä¸‹æ–‡ç†è§£ç­‰ä»»åŠ¡çš„æµ‹è¯•ï¼›
4. **ç¼ºä¹å½¢å¼åŒ–ç†è®ºè§£é‡Š**ï¼šä¸ºä½•å½’ä¸€åŒ–é‡ç”¨æœ‰æ•ˆï¼Ÿä»éœ€æ›´æ·±ç†è®ºæ”¯æ’‘ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•è‡³æ›´å¤§è§„æ¨¡æ¨¡å‹**ï¼ˆBillion+ å‚æ•°ï¼‰éªŒè¯æ³›åŒ–æ€§ï¼›
2. **æ¢ç´¢æ›´å¤šé”šç‚¹å½¢å¼**ï¼šå¦‚å¯å­¦ä¹ è®°å¿†åº“ã€ç»“æ„åŒ–ç´¢å¼•ç­‰ï¼›
3. **ç»“åˆ LongNet æ¶æ„**ï¼šç ”ç©¶åœ¨è¶…é•¿åºåˆ—ä¸­çš„è¡¨ç°ï¼›
4. **ç†è®ºå»ºæ¨¡**ï¼šå»ºç«‹å…³äºâ€œoffloadingâ€æœºåˆ¶çš„å½¢å¼åŒ–åˆ†ææ¡†æ¶ï¼›
5. **åº”ç”¨äºå…¶ä»–æ¨¡æ€**ï¼šè§†è§‰ã€è¯­éŸ³ç­‰é¢†åŸŸçš„ Transformer æ¶æ„æ”¹è¿›ã€‚

---

> ğŸ”— **ä»£ç å¼€æºåœ°å€**ï¼š[https://github.com/jon123boss/ExoFormer](https://github.com/jon123boss/ExoFormer)

</details>

---

### 14. [VBO-MI: A Fully Gradient-Based Bayesian Optimization Framework Using Variational Mutual Information Estimation](https://arxiv.org/abs/2601.08172)

**Authors**: Farhad Mirkarimi  
**Category**: cs.LG  
**Published**: 2026-01-14  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.08172v1  

#### Abstract
Many real-world tasks require optimizing expensive black-box functions accessible only through noisy evaluations, a setting commonly addressed with Bayesian optimization (BO). While Bayesian neural networks (BNNs) have recently emerged as scalable alternatives to Gaussian Processes (GPs), traditiona...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šVBO-MI: A Fully Gradient-Based Bayesian Optimization Framework Using Variational Mutual Information Estimation

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿ **Bayesian Optimization (BO)** æ–¹æ³•é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **é«˜è®¡ç®—å¤æ‚åº¦**ï¼šåŸºäº **Gaussian Process (GP)** çš„æ–¹æ³•éœ€è¦ $O(T^3)$ çš„åæ–¹å·®çŸ©é˜µæ±‚é€†ï¼Œéš¾ä»¥æ‰©å±•åˆ°å¤§è§„æ¨¡æˆ–é«˜ç»´åœºæ™¯ã€‚
- **é‡‡æ ·æ•ˆç‡ä½**ï¼šåŸºäº **Bayesian Neural Networks (BNNs)** çš„æ–¹æ³•ä¾èµ–æ˜‚è´µçš„åéªŒé‡‡æ ·ï¼ˆå¦‚ HMCï¼‰ï¼Œä¸”é€šå¸¸å‡è®¾ç‰¹å®šå‚æ•°åŒ–åˆ†å¸ƒï¼ˆå¦‚é«˜æ–¯ã€ä¼½é©¬ï¼‰ï¼Œé™åˆ¶äº†æ¨¡å‹è¡¨è¾¾èƒ½åŠ›ã€‚
- **å†…å±‚ä¼˜åŒ–ç“¶é¢ˆ**ï¼šæ¯æ¬¡é€‰æ‹©ä¸‹ä¸€ä¸ªæŸ¥è¯¢ç‚¹éƒ½éœ€è¦å¯¹ acquisition function è¿›è¡Œé¢å¤–ä¼˜åŒ–ï¼ˆå¦‚ L-BFGSï¼‰ï¼Œå½¢æˆâ€œå†…å±‚å¾ªç¯â€ï¼Œæ˜¾è‘—å¢åŠ è®¡ç®—å¼€é”€ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šVBO-MI
ä½œè€…æå‡º **VBO-MI (Variational Bayesian Optimization with Mutual Information)**ï¼Œä¸€ç§**å®Œå…¨åŸºäºæ¢¯åº¦çš„ BO æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å°† BO ä¸­çš„æ¢ç´¢-åˆ©ç”¨æƒè¡¡å»ºæ¨¡ä¸º **Mutual Information (MI)** æœ€å¤§åŒ–é—®é¢˜ã€‚
- åˆ©ç”¨ **variational MI estimation**ï¼ˆåŸºäº Donsker-Varadhan ç•Œï¼‰ç›´æ¥ä»æ•°æ®ä¼°è®¡ä¿¡æ¯å¢ç›Šï¼Œæ— éœ€æ˜¾å¼å»ºæ¨¡åéªŒåˆ†å¸ƒã€‚
- è®¾è®¡ **actor-critic æ¶æ„**ï¼š
  - **Action-net (Actor)**ï¼šç”Ÿæˆå€™é€‰è¾“å…¥ $x_t$ï¼Œé€šè¿‡æ¢¯åº¦æ›´æ–°ç›´æ¥ä¼˜åŒ–ç­–ç•¥ã€‚
  - **Variational Critic (Helper Network)**ï¼šä¼°è®¡å½“å‰åŠ¨ä½œä¸è§‚æµ‹ä¹‹é—´çš„ MIï¼Œä½œä¸º acquisition function çš„ä»£ç†ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **è®¡ç®—æ•ˆç‡** | æ¶ˆé™¤å†…å±‚ acquisition ä¼˜åŒ–å¾ªç¯ï¼Œå®ç°ç«¯åˆ°ç«¯æ¢¯åº¦è®­ç»ƒï¼ŒFLOPs å‡å°‘é«˜è¾¾ **102Ã—**ã€‚ |
| **çµæ´»æ€§** | ä¸ä¾èµ– GP å‡è®¾æˆ–ç‰¹å®šå˜åˆ†æ—ï¼ˆå¦‚é«˜æ–¯ï¼‰ï¼Œé€‚ç”¨äºå¤æ‚ã€éçº¿æ€§å‡½æ•°ã€‚ |
| **å¯æ‰©å±•æ€§** | æ”¯æŒé«˜ç»´è¾“å…¥ç©ºé—´å’Œæ‰¹é‡è¯„ä¼°ï¼Œé€‚åˆç°å®ä¸–ç•Œä»»åŠ¡ã€‚ |
| **ç†è®ºæ”¯æŒ** | æä¾›äº†æŸå¤±å‡½æ•°çš„ä¸€è‡´æ€§å’Œæ”¶æ•›æ€§åˆ†æã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†ä¸ä»»åŠ¡
å®éªŒæ¶µç›–ä¸¤ç±»ä»»åŠ¡ï¼š

#### åˆæˆå‡½æ•°ï¼ˆSynthetic Functionsï¼‰
- **Branin**, **Hartmann-6**, **Ackley-10**ï¼šç»å…¸éå‡¸ã€å¤šå³°ä¼˜åŒ–åŸºå‡†ã€‚
- æ‰€æœ‰å‡½æ•°å‡è½¬ä¸ºæœ€å¤§åŒ– $-f(x)$ å½¢å¼ä»¥ç»Ÿä¸€æ¯”è¾ƒã€‚

#### çœŸå®ä¸–ç•Œä»»åŠ¡ï¼ˆReal-world Tasksï¼‰
| ä»»åŠ¡ | ç»´åº¦ | ç‰¹ç‚¹ |
|------|------|------|
| **PDE Optimization** | å‚æ•°åŒ–ç³»æ•°åœº | æœ€å°åŒ–åå¾®åˆ†æ–¹ç¨‹è¾“å‡ºæ–¹å·® |
| **Interferometer Position Optimization** | 4D | å…‰å­¦å¹²æ¶‰ä»ªé…ç½®ä¼˜åŒ– |
| **Lunar Lander Game** | 12D | OpenAI Gym æ§åˆ¶ç­–ç•¥ä¼˜åŒ– |
| **Pest Control** | 25Dï¼ˆå«ç±»åˆ«å˜é‡ï¼‰ | å¤šå­£èŠ‚å®³è™«ç§ç¾¤æ§åˆ¶ç­–ç•¥ï¼Œä½¿ç”¨ one-hot ç¼–ç å¤„ç†ç±»åˆ«å˜é‡ |

### å®éªŒè®¾ç½®
- **è¯„ä¼°æŒ‡æ ‡**ï¼šå½’ä¸€åŒ–ç´¯è®¡å¥–åŠ±ï¼ˆaverage sum of rewardsï¼‰ï¼Œå³ $\frac{1}{t}\sum_{i=1}^t f(x_i)$ã€‚
- **æ‰¹å¤§å°**ï¼šåˆæˆä»»åŠ¡ä¸­ Branin ä½¿ç”¨ 32ï¼Œå…¶ä½™ä½¿ç”¨ 64ã€‚
- **å­¦ä¹ ç‡**ï¼šé»˜è®¤ 0.002ï¼ŒAdam ä¼˜åŒ–å™¨ã€‚
- **è¶…å‚æ•°è°ƒä¼˜**ï¼šæ‰€æœ‰åŸºçº¿æ–¹æ³•è¿›è¡Œç½‘æ ¼æœç´¢é€‰å–æœ€ä¼˜å‚æ•°ã€‚
- **éšæœºç§å­**ï¼šç»“æœåœ¨å¤šä¸ªéšæœºç§å­ä¸Šå¹³å‡ä»¥å‡å°‘æ–¹å·®ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | æ–¹æ³• |
|------|------|
| **GP-based** | Exact GP, Sparse GP, Focalized Sparse GP |
| **BNN-based** | HMC, SGHMC, LLA, DKL, IBNN |
| **å…¶ä»–** | VBO æ›¿æ¢é¡¹å˜ä½“ï¼ˆè§æ¶ˆèå®éªŒï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæœ€ç»ˆå¹³å‡å¥–åŠ±ï¼‰

| æ–¹æ³• | PDE | Interferometer | Lunar Lander | Pest Control |
|------|-----|----------------|--------------|-------------|
| **VBO-MI (Ours)** | **-0.0071** | **0.890** | **170.97** | **-9.02** |
| GP | -0.0349 | 0.567 | 119.88 | -11.30 |
| Sparse GP | -0.0175 | 0.730 | 145.9 | -9.75 |
| DKL | -0.0289 | 0.619 | 129.17 | -11.63 |
| HMC | -0.0139 | 0.668 | 138.51 | -11.08 |
| IBNN | -0.018 | 0.710 | 138.07 | -10.244 |

> âœ… **ç»“è®º**ï¼šVBO-MI åœ¨æ‰€æœ‰çœŸå®ä»»åŠ¡ä¸­å‡è¾¾åˆ°**æœ€é«˜æœ€ç»ˆå¥–åŠ±å€¼**ï¼Œå°¤å…¶åœ¨é«˜ç»´ä»»åŠ¡ï¼ˆå¦‚ Lunar Lander å’Œ Pest Controlï¼‰ä¸Šä¼˜åŠ¿æ˜æ˜¾ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **è¶…è¶Š GP å’Œ BNN åŸºçº¿**ï¼šå³ä½¿åœ¨ GP è¡¨ç°è‰¯å¥½çš„ä½ç»´ä»»åŠ¡ä¸­ï¼ŒVBO-MI ä»èƒ½å–å¾—ç›¸å½“æˆ–æ›´ä¼˜ç»“æœã€‚
- **é«˜ç»´ä¸‹ä¼˜åŠ¿æ˜¾è‘—**ï¼šéšç€ç»´åº¦ä¸Šå‡ï¼ˆå¦‚ Pest Control 25Dï¼‰ï¼Œä¼ ç»Ÿæ–¹æ³•æ€§èƒ½ä¸‹é™æ˜æ˜¾ï¼Œè€Œ VBO-MI ä¿æŒç¨³å®šé«˜æ•ˆã€‚
- **è®¡ç®—æ•ˆç‡ç¢¾å‹**ï¼šå¦‚å›¾6æ‰€ç¤ºï¼ŒVBO-MI çš„ FLOP å¤æ‚åº¦è¿œä½äº HMC-BNNã€DKL ç­‰æ–¹æ³•ï¼Œåœ¨ acquisition phase å®ç°è¿‘ **102Ã— åŠ é€Ÿ**ã€‚

### æ¶ˆèå®éªŒç»“æœ
ä½œè€…è¿›è¡Œäº†æ›¿æ¢å®éªŒï¼ŒéªŒè¯å„ç»„ä»¶é‡è¦æ€§ï¼š

| å˜ä½“ | æè¿° | å‘ç° |
|------|------|------|
| **VBO + GP Exploration** | ç”¨ GP æ–¹å·®æ›¿ä»£ MI æ¢ç´¢é¡¹ | æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼ˆè§ Table 3â€“6ï¼‰ |
| **VBO + GP Exploitation** | ç”¨ GP å‡å€¼æ›¿ä»£æœŸæœ›åˆ©ç”¨é¡¹ | ä¸‹é™å¹…åº¦è¾ƒå° |
| **ä¸åŒ Î² å€¼æµ‹è¯•** | è°ƒæ•´æ¢ç´¢-åˆ©ç”¨æƒé‡ | VBO å¯¹ Î² æ›´é²æ£’ï¼Œå¤šæ•° Î² ä¸‹è¡¨ç°ç¨³å®šï¼›è€Œå…¶ä»–æ–¹æ³•å¯¹ Î² æ•æ„Ÿï¼ˆè§ Fig. 8ï¼‰ |
| **ä¸åŒ batch size** | æµ‹è¯•æ‰¹é‡å¤§å°å½±å“ | VBO éš batch size å¢åŠ æ€§èƒ½æå‡ï¼Œå­˜åœ¨é¥±å’Œé˜ˆå€¼ï¼ˆè§ Fig. 7ï¼‰ |

> ğŸ” **å…³é”®å‘ç°**ï¼š**æ¢ç´¢é¡¹ï¼ˆexploration termï¼‰ç”± MI é©±åŠ¨è‡³å…³é‡è¦**ï¼Œæ›¿æ¢ä¸º GP åæ€§èƒ½å¤§å¹…é€€åŒ–ï¼Œè¯´æ˜ VBO çš„æ¢ç´¢æœºåˆ¶æ›´å…·æœ‰æ•ˆæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **MI å¯ä½œä¸ºé€šç”¨ acquisition signal**ï¼šæ— éœ€ GP æˆ–ç‰¹å®šåéªŒå‡è®¾ï¼Œé€šè¿‡ variational MI estimation å¯æœ‰æ•ˆæŒ‡å¯¼ BO çš„æ¢ç´¢è¿‡ç¨‹ã€‚
2. **ç«¯åˆ°ç«¯æ¢¯åº¦ä¼˜åŒ–å¯è¡Œä¸”é«˜æ•ˆ**ï¼šé€šè¿‡ actor-critic æ¶æ„ï¼Œå°† BO è½¬åŒ–ä¸ºä¸¤ä¸ªç¥ç»ç½‘ç»œçš„äº¤æ›¿è®­ç»ƒé—®é¢˜ï¼Œå½»åº•æ¶ˆé™¤å†…å±‚ä¼˜åŒ–ç“¶é¢ˆã€‚
3. **VBO-MI åœ¨é«˜ç»´å¤æ‚ä»»åŠ¡ä¸­è¡¨ç°å“è¶Š**ï¼šåœ¨ PDEã€æ§åˆ¶ã€ç»„åˆä¼˜åŒ–ç­‰ä»»åŠ¡ä¸­ consistently outperform ç°æœ‰æ–¹æ³•ã€‚
4. **æ¢ç´¢æœºåˆ¶æ˜¯æˆåŠŸå…³é”®**ï¼šæ¶ˆèå®éªŒè¯æ˜ï¼ŒåŸºäº MI çš„æ¢ç´¢é¡¹æ¯”ä¼ ç»Ÿ GP æ–¹å·®æ›´èƒ½é©±åŠ¨æœ‰æ•ˆæœç´¢ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–ç¥ç»ç½‘ç»œè®­ç»ƒç¨³å®šæ€§**ï¼šéœ€ careful tuning å­¦ä¹ ç‡ã€warm-up æ­¥æ•°ç­‰è¶…å‚æ•°ã€‚
- **MI ä¼°è®¡å¯èƒ½å­˜åœ¨åå·®**ï¼šå°½ç®¡ä½¿ç”¨ DV boundï¼Œä½†åœ¨å°æ ·æœ¬æˆ–é«˜ç»´ä¸‹ MI ä¼°è®¡å¯èƒ½ä¸å‡†ç¡®ã€‚
- **å°šæœªé›†æˆçº¦æŸå¤„ç†æœºåˆ¶**ï¼šåŸæ–‡æœªè®¨è®ºå¦‚ä½•å¤„ç†å¸¦çº¦æŸçš„ BO é—®é¢˜ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **multi-objective BO** å’Œ **constrained BO** åœºæ™¯ã€‚
- æ¢ç´¢æ›´ç¨³å®šçš„ **MI estimator**ï¼ˆå¦‚ InfoNCEã€TREï¼‰ä»¥æå‡ä¼°è®¡è´¨é‡ã€‚
- åº”ç”¨äºæ›´å¤§è§„æ¨¡çš„å®é™…ç³»ç»Ÿï¼Œå¦‚èŠ¯ç‰‡è®¾è®¡ã€è¯ç‰©åˆ†å­ä¼˜åŒ–ç­‰ã€‚
- ç ”ç©¶ **theoretical regret bounds** for VBO-MIã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> VBO-MI æ˜¯é¦–ä¸ªå®Œå…¨åŸºäºæ¢¯åº¦çš„ã€æ— éœ€ GP å‡è®¾çš„ BO æ¡†æ¶ï¼Œé€šè¿‡ variational mutual information å®ç°é«˜æ•ˆæ¢ç´¢ï¼Œåœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶å°†è®¡ç®—æˆæœ¬é™ä½ä¸¤ä¸ªæ•°é‡çº§ï¼Œä¸ºé«˜ç»´é»‘ç›’ä¼˜åŒ–æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 15. [Deconstructing Pre-training: Knowledge Attribution Analysis in MoE and Dense Models](https://arxiv.org/abs/2601.08383)

**Authors**: Bo Wang, Junzhuo Li, Hong Chen, Yuanlin Chu, Yuxuan Fan, Xuming Hu  
**Category**: cs.AI  
**Published**: 2026-01-14  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.08383v1  

#### Abstract
Mixture-of-Experts (MoE) architectures decouple model capacity from per-token computation, enabling scaling beyond the computational limits imposed by dense scaling laws. Yet how MoE architectures shape knowledge acquisition during pre-training, and how this process differs from dense architectures,...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Deconstructing Pre-training: Knowledge Attribution Analysis in MoE and Dense Models*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
æœ¬æ–‡èšç„¦äºå½“å‰å¯¹ **Mixture-of-Experts (MoE)** æ¶æ„åœ¨é¢„è®­ç»ƒè¿‡ç¨‹ä¸­çŸ¥è¯†è·å–æœºåˆ¶ç†è§£ä¸è¶³çš„é—®é¢˜ã€‚å°½ç®¡ MoE å› å…¶å‚æ•°æ‰©å±•æ•ˆç‡é«˜è€Œè¢«å¹¿æ³›é‡‡ç”¨ï¼Œä½†å…¶å†…éƒ¨çŸ¥è¯†å¦‚ä½•éšæ—¶é—´æ¼”åŒ–ã€ä¸ä¼ ç»Ÿ **dense æ¨¡å‹**æœ‰ä½•æœ¬è´¨å·®å¼‚ï¼Œå°šç¼ºä¹ç³»ç»Ÿæ€§çš„åŠ¨æ€åˆ†æã€‚

ç°æœ‰ç ”ç©¶å¤šä¸º **post-hoc åˆ†æ**ï¼ˆå³ä»…åœ¨æ¨¡å‹è®­ç»ƒå®Œæˆåè¿›è¡Œè§£é‡Šï¼‰ï¼Œä¸”é›†ä¸­äº dense æ¶æ„ï¼Œæ— æ³•æ­ç¤ºè®­ç»ƒè¿‡ç¨‹ä¸­çš„çŸ¥è¯†å½¢æˆåŠ¨æ€ã€‚

### ğŸ§© æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§æ–°çš„ **neuron-level attribution æ–¹æ³•**ï¼š**Gated-LPI (Log-Probability Increase)**ï¼Œç”¨äºè¿½è¸ª MoE å’Œ dense æ¨¡å‹ä¸­ç¥ç»å…ƒçš„é‡è¦æ€§æ¼”åŒ–ã€‚

- **Gated-LPI æ‰©å±•äº†ä¼ ç»Ÿçš„ LPI æ–¹æ³•**ï¼Œä½¿å…¶é€‚ç”¨äº MoE æ¶æ„ï¼Œèƒ½å¤Ÿåˆ†è§£æ¯ä¸ª token é¢„æµ‹æ—¶ç”±ä¸åŒ **expert** å’Œ **attention head** è´¡çŒ®çš„ log-probability å¢é‡ã€‚
- è¯¥æ–¹æ³•æ”¯æŒ **time-resolved analysis**ï¼Œå³é€šè¿‡è·Ÿè¸ªå¤šä¸ªè®­ç»ƒ checkpointï¼ˆæœ€å¤š 1.2M æ­¥ï¼‰æ¥è§‚å¯ŸçŸ¥è¯†åˆ†é…çš„åŠ¨æ€å˜åŒ–ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **é€‚ç”¨æ€§** | é¦–æ¬¡å°† neuron attribution åº”ç”¨äº MoE æ¨¡å‹ï¼Œå¹¶è€ƒè™‘äº† gating æœºåˆ¶çš„å½±å“ |
| **æ—¶é—´ç»´åº¦** | ä¸æ˜¯ post-hocï¼Œè€Œæ˜¯å…¨ç¨‹è¿½è¸ª pre-training è¿‡ç¨‹ï¼Œæ­ç¤ºâ€œçŸ¥è¯†æ˜¯å¦‚ä½•å­¦ä¼šçš„â€ |
| **ç²’åº¦ç²¾ç»†** | æ”¯æŒä» neuron â†’ layer â†’ functional robustness çš„å¤šå±‚æ¬¡åˆ†æ |
| **å¯è§£é‡Šæ€§å¢å¼º** | æ­ç¤ºäº† MoE å†…éƒ¨ç¨³å®šæ€§å’Œé²æ£’æ€§çš„æ¥æºï¼Œä¸ºè®­ç»ƒè¯Šæ–­æä¾›å·¥å…· |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
- **ä¸»ä»»åŠ¡æ•°æ®é›†**ï¼šä¸€ä¸ªç²¾å¿ƒç­›é€‰çš„å…³ç³»äº‹å®å­é›†ï¼ˆæ¥è‡ª Hernandez et al., 2023ï¼‰
  - åŒ…å« **906 ä¸ª subject-object å¯¹**
  - æ¶µç›– 12 ç§å…³ç³»ï¼Œåˆ†ä¸ºå››ç±»ï¼š
    - **Linguistic**: å¦‚ `word_first_letter`
    - **Commonsense**: å¦‚ `fruit_inside_color`
    - **Factual**: å¦‚ `country_capital_city`
    - **Bias**: å¦‚ `occupation_gender`

- **è®­ç»ƒè¯­æ–™**ï¼š
  - **OLMo-7B (dense)**ï¼šä½¿ç”¨ Dolma è¯­æ–™ï¼ˆçº¦ 2.5T tokensï¼‰
  - **OLMoE-1B-7B (MoE)**ï¼šä½¿ç”¨ OLMoE-MIXï¼ˆDCLM + Dolmaï¼Œåé‡ä»£ç /æ•°å­¦ï¼‰

> âš ï¸ æ³¨ï¼šä½œè€…æ‰¿è®¤è¯­æ–™å·®å¼‚å¯èƒ½æ„æˆæ··æ‚å› ç´ ï¼Œä½†åœ¨åˆ†æä¸­è¿›è¡Œäº†æ§åˆ¶ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
| æ¨¡å‹ | å‚æ•°è§„æ¨¡ | å±‚æ•° | FFN/Expert ç»“æ„ | Routing ç­–ç•¥ | è®­ç»ƒæ­¥æ•° | Token æ€»é‡ |
|------|----------|-------|------------------|---------------|------------|-------------|
| **OLMo-7B** (dense) | 7B | 32 | å•ä¸€ FFN | â€” | 600K | ~2.5T |
| **OLMoE-1B-7B** (MoE) | ~7B (æ€»)ï¼Œ~1.3B æ¿€æ´»/step | 16 | æ¯å±‚ 64 experts | Top-8 | 1.2M | ~5.0T |

> ä¸¤è€…å…±äº«å®ç°åŸºç¡€ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
#### ï¼ˆ1ï¼‰æ€§èƒ½æŒ‡æ ‡
- **HIT@10**ï¼šç›®æ ‡å¯¹è±¡æ˜¯å¦å‡ºç°åœ¨ top-10 é¢„æµ‹ä¸­ï¼Œè¡¡é‡å…³ç³»çŸ¥è¯†æŒæ¡ç¨‹åº¦ã€‚

#### ï¼ˆ2ï¼‰ç¨³å®šæ€§ä¸é›†ä¸­æ€§æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Top-1% Set Stability (Jstab)** | è¿ç»­ checkpoint ä¸­ top-1% æœ€é‡è¦ç¥ç»å…ƒé›†åˆçš„ Jaccard é‡å ç‡ï¼Œè¡¡é‡ç¨³å®šæ€§ |
| **Positive-Gain Concentration (R)** | æ­£å‘é‡è¦æ€§å¢ç›Šé›†ä¸­åœ¨ top-1% ç¥ç»å…ƒçš„æ¯”ä¾‹ï¼Œåæ˜ å­¦ä¹ ä¿¡å·é›†ä¸­ç¨‹åº¦ |
| **Layer-Distribution Consistency (pavg)** | å±‚é—´é‡è¦æ€§åˆ†å¸ƒçš„ç›¸å…³æ€§ï¼Œè¡¡é‡å±‚çº§ç¨³å®šæ€§ |
| **Cross-step Coefficient of Variation (orel)** | å„å±‚é‡è¦æ€§å¾—åˆ†çš„æ—¶é—´åºåˆ—æ³¢åŠ¨å¹…åº¦ï¼Œè¶Šä½è¶Šç¨³å®š |

#### ï¼ˆ3ï¼‰åŠŸèƒ½é²æ£’æ€§æµ‹è¯•
- **å› æœå¹²é¢„ï¼ˆablationï¼‰å®éªŒ**ï¼šå±è”½æœ€é‡è¦çš„ attention heads æˆ– FFN neuronsï¼Œè§‚å¯Ÿ HIT@10 ä¸‹é™å¹…åº¦ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”

#### ï¼ˆ1ï¼‰Neuron-Level åŠ¨æ€ï¼šMoE å½¢æˆâ€œä½ç†µæ ¸å¿ƒâ€
- **OLMoE**ï¼š
  - Top-1% FFN neurons æ¥æ”¶è¶…è¿‡ **45% çš„æ­£å‘æ›´æ–°å¢ç›Š**ï¼ˆR â‰ˆ 48.9%ï¼‰
  - Jstab åœ¨è®­ç»ƒåæœŸè¾¾åˆ° **44.2%**ï¼ˆdense ä»…ä¸º 6.1%ï¼‰
- **OLMo**ï¼ˆdenseï¼‰ï¼š
  - Top-1% neurons çš„ Jstab å³°å€¼ä»… **10.2%**ï¼ŒéšåæŒç»­ä¸‹é™è‡³ 4.9%
  - å­¦ä¹ ä¿¡å·é¢‘ç¹è½¬ç§»ï¼Œæ— æŒä¹…æ ¸å¿ƒ

> â¤ MoE åœ¨æ—©æœŸå°±é”å®šä¸€ç»„é«˜å½±å“åŠ›ç¥ç»å…ƒå¹¶æŒç»­å¼ºåŒ–ï¼Œå½¢æˆâ€œ**low-entropy backbone**â€ã€‚

#### ï¼ˆ2ï¼‰Layer-Level ç¨³å®šæ€§ï¼šMoE æ›´æ—©å›ºåŒ–ç»“æ„
| æŒ‡æ ‡ | OLMoE (MoE) | OLMo (dense) |
|------|--------------|---------------|
| **FFN pavg** | 0.97 | 0.54 |
| **FFN orel** | 0.37 | 5.01 |
| **ATTN pavg** | 0.97 | 0.49 |
| **ATTN orel** | 0.49 | 8.64 |

> â¤ MoE çš„å±‚é‡è¦æ€§åˆ†å¸ƒææ—©ç¨³å®šï¼ˆ<100K stepsï¼‰ï¼Œè€Œ dense æ¨¡å‹å§‹ç»ˆæ³¢åŠ¨ã€‚

#### ï¼ˆ3ï¼‰åŠŸèƒ½é²æ£’æ€§ï¼ˆAblation å®éªŒï¼‰
| å¹²é¢„æ–¹å¼ | OLMoE (MoE) | OLMo (dense) |
|---------|--------------|---------------|
| **Mask Top-1 attention head** | â†“0.06% | â†“16.46% |
| **Mask Top-10 attention heads** | â†“9.44% | â†“50.43% |
| **Mask Top-1% FFN neurons** | â†“35.47% | â†“96.19% |

> â¤ MoE è¡¨ç°å‡ºæ˜¾è‘—çš„åŠŸèƒ½é²æ£’æ€§ï¼Œå³ä½¿ç§»é™¤æœ€å…³é”®ç»„ä»¶ï¼Œæ€§èƒ½ä»ä¿æŒï¼›è€Œ dense æ¨¡å‹ææ˜“å´©æºƒã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **ä½ç†µéª¨å¹²ï¼ˆLow-entropy backboneï¼‰**
   - MoE æ¨¡å‹åœ¨è®­ç»ƒåˆæœŸè¿…é€Ÿå½¢æˆä¸€ä¸ªç”±çº¦ **top 1% ç¥ç»å…ƒç»„æˆçš„é«˜ä»·å€¼æ ¸å¿ƒ**ï¼Œè¿™äº›ç¥ç»å…ƒæŒç»­æ¥æ”¶å¤§éƒ¨åˆ†æ­£å‘æ›´æ–°ã€‚
   - è¯¥ç°è±¡åœ¨ dense æ¨¡å‹ä¸­ä¸å­˜åœ¨ï¼Œåè€…ç¥ç»å…ƒé‡è¦æ€§ä¸æ–­æ›´æ›¿ï¼ˆhigh churnï¼‰ã€‚

2. **æ—©æœŸå›ºåŒ–ï¼ˆEarly consolidationï¼‰**
   - MoE çš„ FFN ä¸ ATTN å±‚çš„é‡è¦æ€§åˆ†å¸ƒ **åœ¨ <100K æ­¥å†…å³è¶‹äºç¨³å®š**ï¼Œè¿›å…¥â€œexplore-refine-consolidateâ€è·¯å¾„ã€‚
   - Dense æ¨¡å‹åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­éƒ½è¡¨ç°å‡ºé«˜åº¦ä¸ç¨³å®šæ€§ã€‚

3. **åŠŸèƒ½é²æ£’æ€§ï¼ˆFunctional robustnessï¼‰**
   - MoE çš„çŸ¥è¯†å­˜å‚¨æ˜¯**åˆ†å¸ƒå¼è€Œéè„†å¼±é›†ä¸­å¼**çš„ï¼Œå› æ­¤å¯¹å…³é”®ç»„ä»¶çš„å±è”½å…·æœ‰å¼ºæŠ—å¹²æ‰°èƒ½åŠ›ã€‚
   - Dense æ¨¡å‹çš„çŸ¥è¯†é›†ä¸­åœ¨å°‘æ•°æ˜“å˜ç»„ä»¶ä¸Šï¼Œå¯¼è‡´â€œ**brittle knowledge storage**â€ã€‚

4. **æ¶æ„å³å½’çº³åç½®**
   - MoE çš„ç¨€ç–æ¿€æ´»æœºåˆ¶ä¸ä»…æå‡è®¡ç®—æ•ˆç‡ï¼Œè¿˜ä½œä¸ºä¸€ç§**æœ‰ç›Šçš„å½’çº³åç½®ï¼ˆinductive biasï¼‰**ï¼Œä¿ƒè¿›ç¨³å®šã€é²æ£’çš„å­¦ä¹ è·¯å¾„ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–ç‰¹å®š attribution æ–¹æ³•**ï¼šåŸºäº Gated-LPI çš„ç»“è®ºå¯èƒ½å—å…¶å‡è®¾å½±å“ï¼ˆå¦‚çº¿æ€§å åŠ è¿‘ä¼¼ï¼‰ã€‚
- **æ¨¡å‹é€‰æ‹©æœ‰é™**ï¼šä»…æ¯”è¾ƒäº† OLMo å’Œ OLMoEï¼Œè™½åŒæºä½†éå®Œå…¨å¯¹ç­‰ï¼ˆå±‚æ•°ã€æ·±åº¦ä¸åŒï¼‰ã€‚
- **è¯­æ–™å·®å¼‚æœªå®Œå…¨æ¶ˆé™¤**ï¼šMoE ä½¿ç”¨æ›´å¤šä»£ç /æ•°å­¦æ•°æ®ï¼Œå¯èƒ½å½±å“çŸ¥è¯†åˆ†å¸ƒã€‚
- **é™æ€å¹²é¢„**ï¼šablation æ˜¯é™æ€æ“ä½œï¼Œæœªæ¨¡æ‹ŸåŠ¨æ€å¤±æ•ˆåœºæ™¯ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•åˆ°æ›´å¤š MoE å˜ä½“**ï¼šå¦‚ Top-2ã€shared expertsã€dynamic routing ç­‰ã€‚
2. **ç»“åˆ circuit discovery**ï¼šè¯†åˆ« MoE ä¸­ç¨³å®šçš„ functional subnetworksã€‚
3. **æŒ‡å¯¼è®­ç»ƒä¼˜åŒ–**ï¼š
   - è®¾è®¡ **stability-aware routing loss**
   - å¼€å‘ **early diagnostic å·¥å…·**ï¼Œæ£€æµ‹è®­ç»ƒå¼‚å¸¸
   - å®ç° **explore-then-stabilize routing policy**
4. **åº”ç”¨äºæ¨¡å‹å‹ç¼©ä¸å‰ªæ**ï¼šåˆ©ç”¨ç¨³å®šæ ¸å¿ƒè¿›è¡Œé«˜æ•ˆä¸“å®¶è£å‰ªã€‚

---

## æ€»ç»“
æœ¬æ–‡é€šè¿‡å¼•å…¥ **Gated-LPI** æ–¹æ³•ï¼Œé¦–æ¬¡å®ç°äº†å¯¹ MoE ä¸ dense æ¨¡å‹åœ¨é¢„è®­ç»ƒè¿‡ç¨‹ä¸­çŸ¥è¯†è·å–åŠ¨æ€çš„ç»†ç²’åº¦ã€æ—¶é—´åˆ†è¾¨æ¯”è¾ƒã€‚ç ”ç©¶å‘ç°ï¼Œ**MoE æ¶æ„å¤©ç„¶å€¾å‘äºå½¢æˆç¨³å®šã€åˆ†å¸ƒå¼çš„çŸ¥è¯†å­˜å‚¨ç»“æ„**ï¼Œè¿™ä¸ä»…æ˜¯è®¡ç®—ä¸Šçš„ä¼˜åŠ¿ï¼Œæ›´æ˜¯å­¦ä¹ æœºåˆ¶ä¸Šçš„æ ¹æœ¬å·®å¼‚ã€‚è¿™ä¸€æˆæœä¸ºæ„å»ºæ›´å…·å¯è§£é‡Šæ€§ã€é²æ£’æ€§å’Œæ•ˆç‡çš„å¤§æ¨¡å‹æä¾›äº†ç†è®ºæ”¯æŒä¸å®è·µå¯ç¤ºã€‚

</details>

---

### 16. [MEMEWEAVER: Inter-Meme Graph Reasoning for Sexism and Misogyny Detection](https://arxiv.org/abs/2601.08684)

**Authors**: Paolo Italiani, David Gimeno-Gomez, Luca Ragazzi, Gianluca Moro, Paolo Rosso  
**Category**: cs.AI  
**Published**: 2026-01-14  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.08684v1  

#### Abstract
Women are twice as likely as men to face online harassment due to their gender. Despite recent advances in multimodal content moderation, most approaches still overlook the social dynamics behind this phenomenon, where perpetrators reinforce prejudices and group identity within like-minded communiti...

---

### 17. [CLaS-Bench: A Cross-Lingual Alignment and Steering Benchmark](https://arxiv.org/abs/2601.08331)

**Authors**: Daniil Gurgurov, Yusser Al Ghussin, Tanja Baeumel, Cheng-Ting Chou, Patrick Schramowski, Marius Mosbach, Josef van Genabith, Simon Ostermann  
**Category**: cs.CL  
**Published**: 2026-01-14  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.08331v1  

#### Abstract
Understanding and controlling the behavior of large language models (LLMs) is an increasingly important topic in multilingual NLP. Beyond prompting or fine-tuning, , i.e.,~manipulating internal representations during inference, has emerged as a more efficient and interpretable technique for adapting...

---

### 18. [InfGraND: An Influence-Guided GNN-to-MLP Knowledge Distillation](https://arxiv.org/abs/2601.08033)

**Authors**: Amir Eskandari, Aman Anand, Elyas Rashno, Farhana Zulkernine  
**Category**: cs.LG  
**Published**: 2026-01-14  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.08033v1  

#### Abstract
Graph Neural Networks (GNNs) are the go-to model for graph data analysis. However, GNNs rely on two key operations - aggregation and update, which can pose challenges for low-latency inference tasks or resource-constrained scenarios. Simple Multi-Layer Perceptrons (MLPs) offer a computationally effi...

---

### 19. [Reverse Flow Matching: A Unified Framework for Online Reinforcement Learning with Diffusion and Flow Policies](https://arxiv.org/abs/2601.08136)

**Authors**: Zeyang Li, Sunbochen Tang, Navid Azizan  
**Category**: cs.LG  
**Published**: 2026-01-14  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.08136v1  

#### Abstract
Diffusion and flow policies are gaining prominence in online reinforcement learning (RL) due to their expressive power, yet training them efficiently remains a critical challenge. A fundamental difficulty in online RL is the lack of direct samples from the target distribution; instead, the target is...

---

### 20. [WebTrap Park: An Automated Platform for Systematic Security Evaluation of Web Agents](https://arxiv.org/abs/2601.08406)

**Authors**: Xinyi Wu, Jiagui Chen, Geng Hong, Jiayi Dong, Xudong Pan, Jiarun Dai, Min Yang  
**Category**: cs.AI  
**Published**: 2026-01-14  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.08406v1  

#### Abstract
Web Agents are increasingly deployed to perform complex tasks in real web environments, yet their security evaluation remains fragmented and difficult to standardize. We present WebTrap Park, an automated platform for systematic security evaluation of Web Agents through direct observation of their c...

---

### 21. [RubricHub: A Comprehensive and Highly Discriminative Rubric Dataset via Automated Coarse-to-Fine Generation](https://arxiv.org/abs/2601.08430)

**Authors**: Sunzhu Li, Jiale Zhao, Miteto Wei, Huimin Ren, Yang Zhou, Jingwen Yang, Shunyu Liu, Kaike Zhang, Wei Chen  
**Category**: cs.AI  
**Published**: 2026-01-14  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.08430v1  

#### Abstract
Reinforcement Learning with Verifiable Rewards (RLVR) has driven substantial progress in reasoning-intensive domains like mathematics. However, optimizing open-ended generation remains challenging due to the lack of ground truth. While rubric-based evaluation offers a structured proxy for verificati...

---

### 22. [YaPO: Learnable Sparse Activation Steering Vectors for Domain Adaptation](https://arxiv.org/abs/2601.08441)

**Authors**: Abdelaziz Bounhar, Rania Hossam Elmohamady Elbadry, Hadi Abdine, Preslav Nakov, Michalis Vazirgiannis, Guokan Shang  
**Category**: cs.AI  
**Published**: 2026-01-14  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.08441v1  

#### Abstract
Steering Large Language Models (LLMs) through activation interventions has emerged as a lightweight alternative to fine-tuning for alignment and personalization. Recent work on Bi-directional Preference Optimization (BiPO) shows that dense steering vectors can be learned directly from preference dat...

---

### 23. [M3-BENCH: Process-Aware Evaluation of LLM Agents Social Behaviors in Mixed-Motive Games](https://arxiv.org/abs/2601.08462)

**Authors**: Sixiong Xie, Zhuofan Shi, Haiyang Shen, Gang Huang, Yun Ma, Xiang Jing  
**Category**: cs.AI  
**Published**: 2026-01-14  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.08462v1  

#### Abstract
As the capabilities of large language model (LLM) agents continue to advance, their advanced social behaviors, such as cooperation, deception, and collusion, call for systematic evaluation. However, existing benchmarks often emphasize a single capability dimension or rely solely on behavioral outcom...

---

### 24. [A Human-Centric Pipeline for Aligning Large Language Models with Chinese Medical Ethics](https://arxiv.org/abs/2601.07954)

**Authors**: Haoan Jin, Han Ying, Jiacheng Ji, Hanhui Xu, Mengyue Wu  
**Category**: cs.CL  
**Published**: 2026-01-14  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.07954v1  

#### Abstract
Recent advances in large language models have enabled their application to a range of healthcare tasks. However, aligning LLMs with the nuanced demands of medical ethics, especially under complex real world scenarios, remains underexplored. In this work, we present MedES, a dynamic, scenario-centric...

---

### 25. [Triplets Better Than Pairs: Towards Stable and Effective Self-Play Fine-Tuning for LLMs](https://arxiv.org/abs/2601.08198)

**Authors**: Yibo Wang, Hai-Long Sun, Qing-Guo Chen, Zhao Xu, Weihua Luo, Kaifu Zhang, Lijun Zhang  
**Category**: cs.CL  
**Published**: 2026-01-14  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.08198v1  

#### Abstract
Recently, self-play fine-tuning (SPIN) has been proposed to adapt large language models to downstream applications with scarce expert-annotated data, by iteratively generating synthetic responses from the model itself. However, SPIN is designed to optimize the current reward advantages of annotated ...

---

### 26. [LUT-Compiled Kolmogorov-Arnold Networks for Lightweight DoS Detection on IoT Edge Devices](https://arxiv.org/abs/2601.08044)

**Authors**: Oleksandr Kuznetsov  
**Category**: cs.LG  
**Published**: 2026-01-14  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.08044v1  

#### Abstract
Denial-of-Service (DoS) attacks pose a critical threat to Internet of Things (IoT) ecosystems, yet deploying effective intrusion detection on resource-constrained edge devices remains challenging. Kolmogorov-Arnold Networks (KANs) offer a compact alternative to Multi-Layer Perceptrons (MLPs) by plac...

---

### 27. [Creativity in AI as Emergence from Domain-Limited Generative Models](https://arxiv.org/abs/2601.08388)

**Authors**: Corina Chutaux (SU FdL)  
**Category**: cs.AI  
**Published**: 2026-01-14  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.08388v1  

#### Abstract
Creativity in artificial intelligence is most often addressed through evaluative frameworks that aim to measure novelty, diversity, or usefulness in generated outputs. While such approaches have provided valuable insights into the behavior of modern generative models, they largely treat creativity a...

---

### 28. [Learner-Tailored Program Repair: A Solution Generator with Iterative Edit-Driven Retrieval Enhancement](https://arxiv.org/abs/2601.08545)

**Authors**: Zhenlong Dai, Zhuoluo Zhao, Hengning Wang, Xiu Tang, Sai Wu, Chang Yao, Zhipeng Gao, Jingyuan Chen  
**Category**: cs.AI  
**Published**: 2026-01-14  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.08545v1  

#### Abstract
With the development of large language models (LLMs) in the field of programming, intelligent programming coaching systems have gained widespread attention. However, most research focuses on repairing the buggy code of programming learners without providing the underlying causes of the bugs. To addr...

---

### 29. [WaterCopilot: An AI-Driven Virtual Assistant for Water Management](https://arxiv.org/abs/2601.08559)

**Authors**: Keerththanan Vickneswaran, Mariangel Garcia Andarcia, Hugo Retief, Chris Dickens, Paulo Silva  
**Category**: cs.AI  
**Published**: 2026-01-14  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.08559v1  

#### Abstract
Sustainable water resource management in transboundary river basins is challenged by fragmented data, limited real-time access, and the complexity of integrating diverse information sources. This paper presents WaterCopilot-an AI-driven virtual assistant developed through collaboration between the I...

---

### 30. [EmbeddingRWKV: State-Centric Retrieval with Reusable States](https://arxiv.org/abs/2601.07861)

**Authors**: Haowen Hou, Jie Yang  
**Category**: cs.CL  
**Published**: 2026-01-14  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.07861v1  

#### Abstract
Current Retrieval-Augmented Generation (RAG) systems typically employ a traditional two-stage pipeline: an embedding model for initial retrieval followed by a reranker for refinement. However, this paradigm suffers from significant inefficiency due to the lack of shared information between stages, l...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- kv cache, offload, State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
