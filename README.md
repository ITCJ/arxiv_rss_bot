# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-02-16 06:47:54 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [FlashSchNet: Fast and Accurate Coarse-Grained Neural Network Molecular Dynamics](https://arxiv.org/abs/2602.13140)

**Authors**: Pingzhi Li, Hongxuan Li, Zirui Liu, Xingcheng Lin, Tianlong Chen  
**Category**: cs.LG  
**Published**: 2026-02-16  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2602.13140v1  

#### Abstract
Graph neural network (GNN) potentials such as SchNet improve the accuracy and transferability of molecular dynamics (MD) simulation by learning many-body interactions, but remain slower than classical force fields due to fragmented kernels and memory-bound pipelines that underutilize GPUs. We show t...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*FlashSchNet: Fast and Accurate Coarse-Grained Neural Network Molecular Dynamics*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»ŸåŸºäº **Graph Neural Network (GNN)** çš„åˆ†å­åŠ¨åŠ›å­¦ï¼ˆMDï¼‰åŠ¿èƒ½æ¨¡å‹ï¼ˆå¦‚ SchNetã€CGSchNetï¼‰è™½ç„¶åœ¨å‡†ç¡®æ€§å’Œå¯è¿ç§»æ€§ä¸Šä¼˜äºç»å…¸åŠ›åœºï¼ˆå¦‚ MARTINIï¼‰ï¼Œä½†ç”±äºå…¶è®¡ç®—æµç¨‹ä¸­å­˜åœ¨å¤§é‡å†…å­˜è®¿é—®ç“¶é¢ˆï¼ˆmemory-boundï¼‰ï¼Œå¯¼è‡´å®é™…æ¨¡æ‹Ÿé€Ÿåº¦è¿œæ…¢äºç»å…¸åŠ›åœºã€‚å°¤å…¶æ˜¯åœ¨ GPU ä¸Šè¿è¡Œæ—¶ï¼Œé¢‘ç¹çš„ä¸­é—´å¼ é‡å†™å…¥é«˜å¸¦å®½å†…å­˜ï¼ˆHBMï¼‰ã€ç¢ç‰‡åŒ–çš„ kernel è°ƒç”¨ä»¥åŠ scatter-add æ“ä½œä¸­çš„åŸå­å†²çªä¸¥é‡é™åˆ¶äº†ååé‡ã€‚

è¯¥è®ºæ–‡æŒ‡å‡ºï¼š**GNN-MD çš„ç“¶é¢ˆä¸æ˜¯ FLOPs ä¸è¶³ï¼Œè€Œæ˜¯ IO æ•ˆç‡ä½ä¸‹** â€”â€” å³ GPU HBM ä¸ç‰‡ä¸Š SRAM ä¹‹é—´çš„æ•°æ®ç§»åŠ¨æœªè¢«ä¼˜åŒ–ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **FlashSchNet**ï¼Œä¸€ç§ **IO-aware** çš„é«˜æ•ˆ SchNet é£æ ¼ GNN-MD æ¡†æ¶ï¼Œé€šè¿‡ç®—æ³•-ç³»ç»ŸååŒè®¾è®¡å‡å°‘å†…å­˜æµé‡å¹¶æå‡ç¡¬ä»¶åˆ©ç”¨ç‡ã€‚å…¶å››å¤§æ ¸å¿ƒæŠ€æœ¯ä¸ºï¼š

1. **Flash radial basis**  
   å°†æˆå¯¹è·ç¦»è®¡ç®—ã€Gaussian basis å±•å¼€å’Œ cosine cutoff åŒ…ç»œèåˆä¸ºä¸€ä¸ª **tiled pass**ï¼Œæ¯ä¸ªè·ç¦»åªè®¡ç®—ä¸€æ¬¡å¹¶åœ¨ç‰‡ä¸Šå¤ç”¨äºæ‰€æœ‰åŸºå‡½æ•°ï¼Œé¿å…å¤šæ¬¡å†™å› HBMã€‚

2. **Flash message passing**  
   èåˆ cutoff æ©ç ã€é‚»å±… gatherã€æ»¤æ³¢å™¨ä¹˜æ³•å’Œ reduction æ“ä½œåˆ°å•ä¸ª kernel ä¸­ï¼Œ**æ¶ˆé™¤è¾¹çº§å¼ é‡ï¼ˆedge tensorsï¼‰åœ¨ HBM ä¸­çš„ç‰©åŒ–ï¼ˆmaterializationï¼‰**ã€‚

3. **Flash aggregation**  
   å°†ä¼ ç»Ÿçš„ scatter-add èšåˆé‡æ„ä¸ºåŸºäº **CSRï¼ˆCompressed Sparse Rowï¼‰çš„åˆ†æ®µ reduceï¼ˆsegmented reduceï¼‰**ï¼Œå°†åŸå­æ›´æ–°æ¬¡æ•°ä» $O(E \times D)$ é™è‡³ $O(N \times D)$ï¼Œå®ç°æ— ç«äº‰ï¼ˆcontention-freeï¼‰ç´¯ç§¯ã€‚

4. **Channel-wise 16-bit quantization (W16A16)**  
   åˆ©ç”¨ SchNet ä¸­ MLP æƒé‡é€šé“é—´åŠ¨æ€èŒƒå›´ä½çš„ç‰¹ç‚¹ï¼Œé‡‡ç”¨é€é€šé“é‡åŒ–ç­–ç•¥ï¼Œåœ¨å‡ ä¹ä¸æŸå¤±ç²¾åº¦çš„å‰æä¸‹åŠ é€Ÿ MLP è®¡ç®—å¹¶é™ä½å†…å­˜å¸¦å®½éœ€æ±‚ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ˜¾è‘—æé€Ÿ**ï¼šç›¸æ¯” CGSchNet åŸºçº¿å®ç° **6.5Ã— çš„ç«¯åˆ°ç«¯åŠ é€Ÿ**ã€‚
- **å¤§å¹…é™è€—**ï¼šå³°å€¼å†…å­˜å ç”¨å‡å°‘ **80%**ï¼ˆä¾‹å¦‚ä» 92GB â†’ 18GBï¼‰ã€‚
- **è¶…è¶Šç»å…¸åŠ›åœº**ï¼šé¦–æ¬¡ä½¿ SchNet ç±» GNN åŠ¿èƒ½è¾¾åˆ°ç”šè‡³è¶…è¿‡ç»å…¸ç²—ç²’åŒ–åŠ›åœºï¼ˆå¦‚ MARTINIï¼‰çš„é€Ÿåº¦ï¼ˆè¾¾ 1000 ns/dayï¼‰ï¼ŒåŒæ—¶ä¿æŒ MLFF çš„é«˜ç²¾åº¦ä¸å¯è¿ç§»æ€§ã€‚
- **æ”¯æŒæ›´å¤§è§„æ¨¡æ¨¡æ‹Ÿ**ï¼šæ›´ä½å†…å­˜ä½¿å¾—å¯åœ¨å•å¡ä¸Šè¿è¡Œæ›´å¤šå¹¶è¡Œå‰¯æœ¬ï¼ˆreplicasï¼‰ï¼Œåˆ©äºå¢å¼ºé‡‡æ ·ç­‰ä»»åŠ¡ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
ä½¿ç”¨äº”ä¸ªå¿«é€ŸæŠ˜å è›‹ç™½ä½œä¸ºæµ‹è¯•ä½“ç³»ï¼Œå‡é‡‡ç”¨ **coarse-grained (CG)** è¡¨ç¤ºï¼ˆæ¯ä¸ªæ°¨åŸºé…¸æ®‹åŸºç”¨ä¸€ä¸ª bead è¡¨ç¤ºï¼‰ï¼š
- Chignolin (CLN, 10 residues)
- TRPcage (2JOF, 20 residues)
- Homeodomain (1ENH, 54 residues, å« 269 beads)
- Villin (1YRF, 35 residues)
- Alpha3D (2A3D, 73 residues)

è¿™äº›ä½“ç³»æ¥è‡ª Charron et al. (2025) çš„åŸºå‡†å¥—ä»¶ã€‚

---

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼šå•å— NVIDIA RTX PRO 6000 GPU
- **æ¨¡æ‹Ÿå‚æ•°**ï¼š
  - Langevin åŠ¨åŠ›å­¦ï¼Œæ¸©åº¦ 300K
  - æ—¶é—´æ­¥é•¿ 4 fs
  - å¹¶è¡Œè¿è¡Œ 64 ä¸ª replicas
- **è¯„ä¼°å‘¨æœŸ**ï¼šæ¯ MD æ­¥æµ‹é‡ throughput å’Œ peak memory usage

---

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Throughput** | `timestepÂ·mol/s`ï¼Œå³æ¯ç§’å®Œæˆçš„æ¨¡æ‹Ÿæ­¥æ•° Ã— åˆ†å­æ•°é‡ï¼ˆè·¨æ‰€æœ‰ replicas æ€»å’Œï¼‰ |
| **Peak Memory** | GPU æœ€å¤§æ˜¾å­˜å ç”¨ï¼ˆGBï¼‰ |
| **Structural Fidelity** | ä½¿ç”¨ä»¥ä¸‹ä¸‰ä¸ªæŒ‡æ ‡éªŒè¯ç‰©ç†ä¿çœŸåº¦ï¼š<br>â€¢ **Ca RMSD**ï¼šä¸»é“¾ç¢³åŸå­ä¸å‚è€ƒç»“æ„çš„å‡æ–¹æ ¹åå·®<br>â€¢ **Q (Fraction of Native Contacts)**ï¼šåŸç”Ÿæ¥è§¦æ¯”ä¾‹<br>â€¢ **GDT-TS**ï¼šå…¨å±€è·ç¦»æµ‹è¯•æ€»åˆ†ï¼Œè¡¡é‡æ‹“æ‰‘ç›¸ä¼¼æ€§ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **CGSchNet (FP32)** | MLFF åŸºçº¿ | å½“å‰æœ€å…ˆè¿›çš„ coarse-grained GNN åŠ¿èƒ½æ¨¡å‹ï¼Œä½œä¸ºæ€§èƒ½ä¸ç²¾åº¦åŸºå‡† |
| **MARTINI** | ç»å…¸åŠ›åœº | å¹¿æ³›ä½¿ç”¨çš„ coarse-grained ç»éªŒåŠ›åœºï¼Œé€Ÿåº¦å¿«ä½†è¿‘ä¼¼ç¨‹åº¦é«˜ |
| **All-Atom Simulation** | å‚è€ƒæ ‡å‡† | åŸå­çº§æ¨¡æ‹Ÿç»“æœç”¨äºè¯„ä¼°ç»“æ„å‡†ç¡®æ€§ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ 1ENH è›‹ç™½ä¸ºä¾‹ï¼‰
| æŒ‡æ ‡ | FlashSchNet | CGSchNet | MARTINI |
|------|------------|----------|---------|
| **Throughput** | ~3000 timestepÂ·mol/s (**â‰ˆ1000 ns/day**) | ~477 timestepÂ·mol/s | ~2250 timestepÂ·mol/s |
| **Speedup vs CGSchNet** | **6.5Ã—** | â€” | â€” |
| **Peak Memory** | **18.0 GB** | 92.5 GB | 34.9 GB |
| **Memory Reduction** | **>80%** | â€” | â€” |

> âœ… FlashSchNet åœ¨é€Ÿåº¦ä¸Šä¸ä»…å¤§å¹…è¶…è¶Š CGSchNetï¼Œè¿˜ **é¦–æ¬¡è¶…è¿‡äº† MARTINI**ï¼Œå®ç°äº†â€œå…¼å…·é«˜é€Ÿä¸é«˜ç²¾åº¦â€çš„çªç ´ã€‚

---

### ä¸å…¶ä»–ç³»ç»Ÿçš„æ¯”è¾ƒï¼ˆè§ Table 3ï¼‰
| Protein | FlashSchNet Speed (timestepÂ·mol/s) | CGSchNet Speed | Speedup |
|--------|------------------------------------|----------------|---------|
| Chignolin | 5222 | 3578 | ~1.5Ã— |
| TRPcage | 4938 | 1729 | ~2.8Ã— |
| Villin | 3912 | 1056 | ~3.7Ã— |
| Alpha3D | 2610 | 288 | **~9Ã—** |

> âš¡ï¸ æ›´å¤æ‚çš„ç³»ç»Ÿä¸­åŠ é€Ÿæ¯”æ›´é«˜ï¼Œè¡¨æ˜ FlashSchNet åœ¨å¤§è§„æ¨¡åœºæ™¯ä¸‹ä¼˜åŠ¿æ›´æ˜æ˜¾ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰å¯¹åŠ¨æ€å›¾æ‹“æ‰‘çš„é²æ£’æ€§
- åœ¨ 1ENH çš„æ‹‰ä¼¸æ¨¡æ‹Ÿä¸­ï¼Œéšç€è›‹ç™½è´¨å±•å¼€ï¼Œé‚»æ¥å›¾å˜å¾—ç¨ å¯†ä¸”éå¯¹è§’åŒ–ã€‚
- **CGSchNet ååé‡éšå›¾å¯†åº¦ä¸Šå‡è€Œæ˜¾è‘—ä¸‹é™**ï¼ˆscatter contention åŠ å‰§ï¼‰ã€‚
- **FlashSchNet ä¿æŒç¨³å®šååé‡**ï¼Œå¾—ç›Šäº CSR åˆ†æ®µ reduce çš„æ— ç«äº‰ç‰¹æ€§ã€‚
- æ‰¹å¤§å°è¶Šå¤§ï¼ˆ64 replicasï¼‰ï¼Œå·®è·è¶Šæ˜æ˜¾ï¼ˆæœ€é«˜è¾¾ 6.5Ã—ï¼‰ã€‚

#### ï¼ˆ2ï¼‰æ‰¹å¤§å°æ‰©å±•èƒ½åŠ›
- FlashSchNet å¯æ‰©å±•è‡³ **3â€“10Ã— æ›´å¤§çš„ batch size** æ‰å‡ºç° OOMï¼ˆOut-of-Memoryï¼‰ã€‚
  - å¦‚ Chignolin æ”¯æŒé«˜è¾¾ 2048 replicasï¼ŒAlpha3D è¾¾ 256 replicasã€‚
- CGSchNet åœ¨è¾ƒå° batch ä¸‹å³å› æ˜¾å­˜ä¸è¶³å¤±è´¥ã€‚
- æ˜¾å­˜èŠ‚çœä¸»è¦æ¥è‡ªï¼š**æ¶ˆé™¤ Bã€Wã€M ç­‰è¾¹çº§ä¸­é—´å¼ é‡çš„ HBM å­˜å‚¨**ã€‚

#### ï¼ˆ3ï¼‰é‡åŒ–å½±å“
- é‡‡ç”¨ **channel-wise W16A16** åï¼ŒMLP è®¡ç®—æ˜ å°„è‡³ Tensor Coresï¼Œååè¿›ä¸€æ­¥æå‡ã€‚
- ç²¾åº¦åˆ†ææ˜¾ç¤ºï¼š**GDT-TS ä¸ Largest Q ä¸ FP32 åŸºçº¿å·®å¼‚æå°ï¼ˆ<0.04ï¼‰**ï¼Œè¯æ˜é‡åŒ–å‡ ä¹æ— æŸã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **GNN-MD çš„æ€§èƒ½ç“¶é¢ˆæœ¬è´¨æ˜¯ IO è€Œéè®¡ç®—**ï¼šå°½ç®¡åä¹‰ FLOPs ä¸é«˜ï¼Œä½†é¢‘ç¹çš„ HBM è®¿é—®ä½¿å…¶æˆä¸ºå¼º memory-bound åº”ç”¨ã€‚
2. **IO-aware è®¾è®¡å¯å¸¦æ¥æ•°é‡çº§æ”¹è¿›**ï¼šé€šè¿‡èåˆ kernelã€æ¶ˆé™¤ä¸­é—´å­˜å‚¨ã€é‡æ„èšåˆæ–¹å¼ï¼Œå¯åœ¨ä¸ç‰ºç‰²ç²¾åº¦çš„æƒ…å†µä¸‹å¤§å¹…æå‡æ•ˆç‡ã€‚
3. **FlashSchNet æ˜¯é¦–ä¸ªåœ¨ wall-clock efficiency ä¸Šè¶…è¶Šç»å…¸åŠ›åœºçš„ SchNet é£æ ¼æ¨¡å‹**ï¼Œå®ç°äº†â€œå‡†ç¡® â‰  æ…¢â€çš„èŒƒå¼è½¬å˜ã€‚
4. **ä½é€šé“åŠ¨æ€èŒƒå›´é€‚åˆè½»é‡çº§é‡åŒ–**ï¼šSchNet ä¸­çš„ filter MLP å¤©ç„¶å…·å¤‡é€šé“ç¨€ç–æ€§ï¼Œæ”¯æŒé«˜æ•ˆ W16A16 è€Œä¸å½±å“è¾“å‡ºè´¨é‡ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- ç›®å‰ä»…é’ˆå¯¹ **coarse-grained** è›‹ç™½è´¨ç³»ç»Ÿè¿›è¡Œä¼˜åŒ–ï¼Œå°šæœªéªŒè¯äºå…¨åŸå­ï¼ˆall-atomï¼‰æˆ–å¤æ‚æº¶å‰‚ç¯å¢ƒã€‚
- ä¾èµ–å®šåˆ¶ CUDA kernel å®ç°ï¼Œç›®å‰éœ€ç‰¹å®šå·¥ç¨‹æŠ•å…¥ï¼Œé€šç”¨æ€§å—é™äºæ¡†æ¶æ”¯æŒï¼ˆå¦‚ PyTorch å¯¹ CSR aggregation æ”¯æŒè¾ƒå¼±ï¼‰ã€‚
- bucket sort æ„å»º grouped layout å¼•å…¥é¢å¤–å¼€é”€ï¼Œè™½æ€»ä½“å¯æ§ï¼Œä½†åœ¨æçŸ­æ—¶é—´æ­¥ä¸‹å¯èƒ½å½±å“æ•ˆç‡ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† FlashSchNet æ€è·¯æ¨å¹¿è‡³å…¶ä»– GNN æ¶æ„ï¼ˆå¦‚ NequIPã€MACEï¼‰åŠå…¨åŸå­æ¨¡æ‹Ÿã€‚
- å¼€å‘è‡ªåŠ¨ä»£ç ç”Ÿæˆå·¥å…·ï¼Œå°† IO-aware æ¨¡å¼å°è£…è¿›ä¸»æµ ML æ¡†æ¶ï¼ˆå¦‚ PyTorch Geometricã€JAX-MDï¼‰ã€‚
- ç»“åˆæ›´é«˜æ•ˆçš„ neighbor list æ›´æ–°æœºåˆ¶ï¼Œè¿›ä¸€æ­¥é™ä½åŠ¨æ€å›¾é‡æ„æˆæœ¬ã€‚
- æ¢ç´¢åœ¨å¤š GPU åœºæ™¯ä¸‹çš„åˆ†å¸ƒå¼æ‰©å±•æ–¹æ¡ˆï¼Œæ”¯æŒè¶…å¤§ä½“ç³»æ¨¡æ‹Ÿã€‚

---

> ğŸ”— **å¼€æºåœ°å€**ï¼š[https://github.com/UNITES-Lab/flash-molecular-dynamics](https://github.com/UNITES-Lab/flash-molecular-dynamics)

</details>

---

### 2. [Synthetic Interaction Data for Scalable Personalization in Large Language Models](https://arxiv.org/abs/2602.12394)

**Authors**: Yuchen Ma, Yue Huang, Wenjie Wang, Xiaonan Luo, Xiangliang Zhang, Stefan Feuerriegel  
**Category**: cs.LG  
**Published**: 2026-02-16  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2602.12394v1  

#### Abstract
Personalized prompting offers large opportunities for deploying large language models (LLMs) to diverse users, yet existing prompt optimization methods primarily focus on task-level optimization while largely overlooking user-specific preferences and latent constraints of individual users. This gap ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¸ªæ€§åŒ–å¯¹é½ï¼ˆpersonalized alignmentï¼‰æ–¹é¢é¢ä¸´ä¸¤å¤§ç“¶é¢ˆï¼š
1. **æ•°æ®ç¼ºå£ï¼ˆData Gapï¼‰**ï¼šç¼ºä¹é«˜è´¨é‡ã€éšç§å®‰å…¨çš„å¤šè½®ç”¨æˆ·-LLMäº¤äº’æ•°æ®ï¼Œéš¾ä»¥æ•æ‰çœŸå®ç”¨æˆ·çš„åŠ¨æ€åå¥½ã€‚
2. **æ–¹æ³•å±€é™ï¼ˆMethod Limitationï¼‰**ï¼šç°æœ‰æ–¹æ³•å¤šä¾èµ–é™æ€åå¥½å»ºæ¨¡ã€æ¨¡å‹å‚æ•°å¾®è°ƒæˆ–å°é—­æºæ¨¡å‹ä¸å¯è®¿é—®çš„é—®é¢˜ï¼Œé™åˆ¶äº†å¯æ‰©å±•æ€§å’Œå®ç”¨æ€§ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æœ¬æ–‡æå‡ºä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œç³»ç»Ÿæ€§è§£å†³ä¸Šè¿°é—®é¢˜ï¼š

#### **â‘  PERSONAGYMï¼šé«˜ä¿çœŸåˆæˆæ•°æ®ç”Ÿæˆæ¡†æ¶**
- å°†ä¸ªæ€§åŒ–å»ºæ¨¡ä¸º**åŠ¨æ€è¿‡ç¨‹**è€Œéé™æ€è§’è‰²è®¾å®šï¼ˆstatic personaï¼‰ï¼Œé€šè¿‡ä¸€ä¸ªåŸºäºLLMçš„**ä»£ç†ç³»ç»Ÿ**ï¼ˆagentic LLM systemï¼‰æ¨¡æ‹ŸçœŸå®ç”¨æˆ·è¡Œä¸ºã€‚
- åŒ…å«ä¸‰ä¸ªLLMä»£ç†ï¼š
  - **User Agent**ï¼šæ¨¡æ‹Ÿç”¨æˆ·æé—®ä¸åé¦ˆã€‚
  - **Assistant Agent**ï¼šæ¨¡æ‹ŸLLMå“åº”ã€‚
  - **Distractor Agent**ï¼šæ³¨å…¥è¯­ä¹‰æ„ŸçŸ¥å™ªå£°ï¼ˆsemantic-aware noiseï¼‰ï¼Œå¢å¼ºç°å®æ€§ã€‚
- æ”¯æŒ**éƒ¨åˆ†å¯è§‚æµ‹æ€§**ï¼ˆpartial observabilityï¼‰å’Œ**å¤šè½®äº¤äº’è½¨è¿¹ç”Ÿæˆ**ï¼Œæ›´è´´è¿‘çœŸå®åœºæ™¯ã€‚

#### **â‘¡ PERSONAATLAS æ•°æ®é›†**
- åŸºäº PERSONAGYM ç”Ÿæˆçš„å¤§è§„æ¨¡ã€é«˜è´¨é‡ã€å¤šæ ·åŒ–çš„**å¤šè½®ä¸ªæ€§åŒ–äº¤äº’æ•°æ®é›†**ã€‚
- åŒ…å«çº¦ 2,000 ä¸ªåˆæˆ persona å’Œè¶…è¿‡ 10,000 åœºå¯¹è¯ï¼Œè¦†ç›–å¤šç§ä»»åŠ¡é¢†åŸŸï¼ˆå¦‚å†™ä½œã€ç¼–ç ã€è§„åˆ’ç­‰ï¼‰ã€‚

#### **â‘¢ PPOptï¼šå¯æ‰©å±•çš„ä¸ªæ€§åŒ–æç¤ºä¼˜åŒ–æ¡†æ¶**
- æå‡º **Personalized Prompt Optimization (PPOpt)**ï¼Œä¸€ç§**æ¨¡å‹æ— å…³**ï¼ˆmodel-agnosticï¼‰ã€æ— éœ€ä¿®æ”¹éƒ¨ç½²æ¨¡å‹å‚æ•°çš„é»‘ç›’æç¤ºä¼˜åŒ–æ–¹æ³•ã€‚
- é‡‡ç”¨ **reason-then-optimize èŒƒå¼**ï¼š
  1. å…ˆä»å†å²äº¤äº’ä¸­æ¨ç†å‡ºæ˜¾å¼çš„ç”¨æˆ·ç”»åƒï¼ˆuser profileï¼‰ï¼›
  2. å†åŸºäºè¯¥ç”»åƒé‡å†™å½“å‰æç¤ºï¼ˆprompt rewritingï¼‰ã€‚
- é¿å…â€œå¥–åŠ±é»‘å®¢â€ï¼ˆreward hackingï¼‰å’Œæ·å¾„å­¦ä¹ ï¼ˆshortcut learningï¼‰ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | PPOpt (æœ¬æ–‡) | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ PAD, CoPe, LaMP ç­‰ï¼‰ |
|------|-------------|-------------------------------|
| **å¹²é¢„å±‚çº§** | Prompt-levelï¼ˆéä¾µå…¥å¼ï¼‰ | Memory/Parameter/Decoding-levelï¼ˆéœ€è®¿é—®å†…éƒ¨çŠ¶æ€ï¼‰ |
| **é—­æºå…¼å®¹æ€§** | âœ… æ”¯æŒ | âŒ å¤šæ•°ä¸æ”¯æŒ |
| **æ•°æ®å¯æ‰©å±•æ€§** | âœ… é«˜ï¼ˆåŸºäºåˆæˆæ•°æ®ï¼‰ | âŒ ä¾èµ–çœŸå®ç”¨æˆ·æ•°æ®ï¼Œç¨€ç¼ºä¸”æ•æ„Ÿ |
| **å™ªå£°å»ºæ¨¡** | âœ… æ˜¾å¼å»ºæ¨¡è¯­ä¹‰å™ªå£° | âš ï¸ å¤šå¿½ç•¥æˆ–ç®€åŒ– |
| **äº¤äº’åŠ¨æ€æ€§** | âœ… å¤šè½®åŠ¨æ€åå¥½æ¼”åŒ– | âš ï¸ å¤šä¸ºå•è½®æˆ–é™æ€åå¥½ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
#### **åˆæˆè®­ç»ƒä¸æµ‹è¯•æ•°æ®**
- **PERSONAATLAS**ï¼šæœ¬æ–‡æå‡ºçš„åˆæˆæ•°æ®é›†ï¼Œç”¨äºè®­ç»ƒ PPOptã€‚
- æ„å»ºæ–¹å¼ï¼š
  - ç§å­æŸ¥è¯¢æ¥è‡ªå¤šä¸ªå…¬å¼€æ•°æ®é›†æ··åˆï¼š
    - `ultrachat_200k`, `OpenR1-Math-220k`ï¼ˆå¤šè½®å¯¹è¯ï¼‰
    - `CodeFeedback`, `Mol-Instructions`ï¼ˆä»£ç ä¸ç§‘å­¦ï¼‰
    - `MMLU`, `ai2_arc`ï¼ˆå¸¸è¯†é—®ç­”ï¼‰
    - `Alpaca-cleaned`, `TruthfulQA` ç­‰
- **çœŸå®ä¸–ç•Œæµ‹è¯•é›†**ï¼šé€šè¿‡äººç±»ä¸“å®¶ç¼–è¾‘åˆæˆè½¨è¿¹æ„å»ºï¼Œç¡®ä¿é«˜ä¿çœŸåº¦ã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**
#### **è¯„ä¼°æ–¹å¼**
- åœ¨ä¸¤ç§ç¯å¢ƒä¸‹è¿›è¡Œè¯„ä¼°ï¼š
  1. åˆæˆåŸºå‡†ï¼ˆsynthetic benchmarksï¼‰
  2. çœŸå®ä¸–ç•Œæµ‹è¯•é›†ï¼ˆreal-world test setï¼‰

#### **è¯„ä¼°æŒ‡æ ‡ï¼ˆç”± LLM-as-a-Judge åˆ¤æ–­ï¼‰**
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Personalization Score** | è¡¡é‡è¾“å‡ºæ˜¯å¦ç¬¦åˆç”¨æˆ·åå¥½ï¼ˆè¯­æ°”ã€æ ¼å¼ã€é£æ ¼ç­‰ï¼‰ï¼ŒèŒƒå›´ 1â€“10 |
| **Task Completion Score** | è¡¡é‡ä»»åŠ¡å®Œæˆè´¨é‡ï¼ˆæ­£ç¡®æ€§ã€å®Œæ•´æ€§ï¼‰ï¼ŒèŒƒå›´ 1â€“10 |

#### **éƒ¨ç½²æ¨¡å‹**
- ä½¿ç”¨å¤šä¸ªä¸»æµ LLM è¿›è¡Œæµ‹è¯•ï¼ŒåŒ…æ‹¬ï¼š
  - `Llama-3-8b-instruct`, `Qwen3-8b`, `GPT-oss-20b`
  - éƒ¨ç½²æ—¶æ¨¡å‹å†»ç»“ï¼Œä»…ä¼˜åŒ–è¾“å…¥ promptã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| åŸºçº¿æ–¹æ³• | ç±»å‹ | æè¿° |
|--------|------|------|
| **Vanilla Prompt** | åŸºçº¿ | åŸå§‹ç”¨æˆ·æŸ¥è¯¢ï¼Œæ— ä»»ä½•ä¼˜åŒ– |
| **History-augmented Prompting (Concat)** | ä¸Šä¸‹æ–‡æ‹¼æ¥ | å°†å†å²å¯¹è¯ç›´æ¥æ‹¼æ¥åˆ°å½“å‰æŸ¥è¯¢ |
| **Persona-based Query Rewriting** | è§’è‰²é‡å†™ | ä»å†å²æ¨æ–­ persona å¹¶é™„åŠ åˆ°æŸ¥è¯¢ |
| **Preference-based Few-shot ICL** | å°‘æ ·æœ¬ç¤ºä¾‹ | æ„é€ åå¥½ç›¸å…³çš„ in-context ç¤ºä¾‹ |
| **Controller-guided Prompting** | æ§åˆ¶å™¨å¼•å¯¼ | ä½¿ç”¨è¾…åŠ©æ§åˆ¶å™¨æ¨¡å‹æ”¹å†™æŸ¥è¯¢ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **è¡¨6 & è¡¨9ï¼šç»¼åˆæ€§èƒ½è¡¨ç°**
| æ–¹æ³• | Personalization Score â†‘ | Task Completion Score â†‘ |
|------|--------------------------|-------------------------|
| **Vanilla** | 5.41 | 8.48 |
| **PPOpt (ours)** | **7.20** (+1.79, +33.09%) | **8.26** (-0.22, -2.59%) |

> æ³¨ï¼šç»“æœåŸºäº `Llama-3.3-70b-instruct` éƒ¨ç½²æ¨¡å‹ã€‚

#### **çœŸå®ä¸–ç•Œæµ‹è¯•é›†è¡¨ç°ï¼ˆTable 9ï¼‰**
| æ–¹æ³• | Personalization | Task Completion |
|------|------------------|------------------|
| Vanilla | 5.49 | 8.09 |
| PPOpt | **7.20** (+1.71) | 8.05 (-0.04) |

âœ… **ç»“è®º**ï¼šPPOpt åœ¨çœŸå®åœºæ™¯ä¸‹ä»æ˜¾è‘—æå‡ä¸ªæ€§åŒ–è´¨é‡ï¼Œä¸”å‡ ä¹ä¸å½±å“ä»»åŠ¡å®Œæˆèƒ½åŠ›ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœï¼ˆTable 7ï¼‰**
| æ–¹æ³• | Personalization Gain | Task Completion Drop |
|------|-----------------------|------------------------|
| History-augmented | +1.53 | -0.59 |
| Persona-based Rewriting | +0.81 | -1.06 |
| Preference-based ICL | +1.45 | -0.54 |
| Controller-guided | +1.26 | -0.54 |
| **PPOpt (ours)** | **+1.79** | **-0.22** |

ğŸ“Œ **ä¼˜åŠ¿æ˜æ˜¾**ï¼šPPOpt ä¸ä»…å¸¦æ¥æœ€å¤§ä¸ªæ€§åŒ–å¢ç›Šï¼Œè¿˜æœ€å°åŒ–äº†å¯¹ä»»åŠ¡æ€§èƒ½çš„è´Ÿé¢å½±å“ã€‚

### **æ¶ˆèå®éªŒç»“æœï¼ˆFigure 3ï¼‰**
æ¯”è¾ƒä¸åŒè®­ç»ƒé˜¶æ®µçš„å½±å“ï¼š
| è®¾ç½® | Personalization Score |
|------|------------------------|
| SFT only | ~6.7â€“7.0 |
| RL w/o Profile Inference Reward | ä¸ç¨³å®šï¼Œéƒ¨åˆ†ä¸‹é™ |
| **Full PPOpt (SFT + RL + Profile Reward)** | **~7.2â€“7.35** âœ… |

ğŸ” **å‘ç°**ï¼š
- SFT æä¾›è‰¯å¥½å†·å¯åŠ¨ï¼ˆcold-start priorï¼‰ã€‚
- åŠ å…¥ profile inference reward å¯¹ç¨³å®šå¼ºåŒ–å­¦ä¹ è‡³å…³é‡è¦ï¼Œé˜²æ­¢ä¼˜åŒ–åç¦»çœŸå®åå¥½ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. âœ… **åˆæˆæ•°æ®å¯ç”¨äºé«˜è´¨é‡ä¸ªæ€§åŒ–è®­ç»ƒ**ï¼šPERSONAGYM èƒ½ç”Ÿæˆè¶³å¤Ÿé€¼çœŸçš„å¤šè½®äº¤äº’æ•°æ®ï¼Œæ”¯æ’‘ä¸‹æ¸¸ä¸ªæ€§åŒ–ä¼˜åŒ–ã€‚
2. âœ… **reason-then-optimize èŒƒå¼æœ‰æ•ˆ**ï¼šå…ˆæ¨ç†ç”¨æˆ·ç”»åƒå†ä¼˜åŒ–æç¤ºï¼Œèƒ½é¿å… reward hackingï¼Œæé«˜é²æ£’æ€§ã€‚
3. âœ… **PPOpt æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•**ï¼šåœ¨ personalization ä¸Šå¹³å‡æå‡ **33%**ï¼ŒåŒæ—¶ä¿æŒ task performance å‡ ä¹ä¸å˜ã€‚
4. âœ… **è·¨æ¨¡å‹æ³›åŒ–èƒ½åŠ›å¼º**ï¼šæ— è®ºä½¿ç”¨ä½•ç§ optimizer æˆ–éƒ¨ç½²æ¨¡å‹ï¼ŒPPOpt å‡ä¸€è‡´æœ‰æ•ˆã€‚
5. âœ… **å¯¹ç¨€ç–å’Œå™ªå£°ä¿¡å·é²æ£’**ï¼šå³ä½¿ç”¨æˆ·åé¦ˆæ¨¡ç³Šã€ä¸ä¸€è‡´æˆ–ç¼ºå¤±ï¼ŒPPOpt ä»èƒ½æ¢å¤æ½œåœ¨åå¥½ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
1. ğŸš« **ä¾èµ–é«˜è´¨é‡åˆæˆæµç¨‹**ï¼šè‹¥ PERSONAGYM çš„ä»£ç†æ¨¡æ‹Ÿå¤±çœŸï¼Œå¯èƒ½å¯¼è‡´é”™è¯¯åå¥½ä¼ æ’­ã€‚
2. ğŸš« **æ— æ³•å¤„ç†æç«¯åˆ†å¸ƒå¤–ç”¨æˆ·**ï¼šå¯¹äºå®Œå…¨æœªè§çš„ persona ç±»å‹ï¼Œæ³›åŒ–èƒ½åŠ›å—é™ã€‚
3. ğŸš« **è®¡ç®—æˆæœ¬è¾ƒé«˜**ï¼šç”Ÿæˆ PERSONAATLAS å•æ¡å¯¹è¯å¹³å‡æ¶ˆè€—çº¦ 17.7k tokensï¼ˆä»¥ GPT-5.2 è®¡çº¦ä¸º \$0.25ï¼‰ã€‚
4. ğŸš« **ä»ä¸º offline ä¼˜åŒ–**ï¼šæœªå®ç°åœ¨çº¿æŒç»­å­¦ä¹ ï¼ˆonline adaptationï¼‰ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. ğŸ”® **å¼•å…¥åœ¨çº¿è‡ªé€‚åº”æœºåˆ¶**ï¼šç»“åˆ online feedback å®ç°æŒç»­æ›´æ–°ç”¨æˆ·ç”»åƒã€‚
2. ğŸ” **é™ä½åˆæˆæˆæœ¬**ï¼šæ¢ç´¢è½»é‡åŒ–ä»£ç†æˆ–è’¸é¦ç­–ç•¥å‡å°‘ token å¼€é”€ã€‚
3. ğŸ§  **èåˆè®°å¿†æœºåˆ¶**ï¼šå°†é•¿æœŸç”¨æˆ·è®°å¿†æ•´åˆè¿› prompt optimizerã€‚
4. ğŸŒ **è·¨å¹³å°è¿ç§»**ï¼šç ”ç©¶åœ¨ä¸åŒ LLM é—´å…±äº« prompt optimizer çš„å¯è¡Œæ€§ã€‚
5. ğŸ” **åŠ å¼ºéšç§ä¿éšœ**ï¼šè¿›ä¸€æ­¥ç ”ç©¶å¦‚ä½•åœ¨åˆæˆä¸­æ¶ˆé™¤èº«ä»½å¯è¯†åˆ«ä¿¡æ¯ï¼ˆPIIï¼‰é£é™©ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬è®ºæ–‡é€šè¿‡ **PERSONAGYM + PERSONAATLAS + PPOpt** ä¸‰ä½ä¸€ä½“æ–¹æ¡ˆï¼Œé¦–æ¬¡å®ç°äº†**åŸºäºé«˜ä¿çœŸåˆæˆæ•°æ®çš„å¯æ‰©å±•ã€æ¨¡å‹æ— å…³ã€å¤šè½®åŠ¨æ€ä¸ªæ€§åŒ–æç¤ºä¼˜åŒ–**ï¼Œä¸º LLM ä¸ªæ€§åŒ–è½åœ°æä¾›äº†å®ç”¨ä¸”é«˜æ•ˆçš„è·¯å¾„ã€‚

</details>

---

### 3. [Scaling Web Agent Training through Automatic Data Generation and Fine-grained Evaluation](https://arxiv.org/abs/2602.12544)

**Authors**: Lajanugen Logeswaran, Jaekyeom Kim, Sungryull Sohn, Creighton Glasscock, Honglak Lee  
**Category**: cs.AI  
**Published**: 2026-02-16  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.12544v1  

#### Abstract
We present a scalable pipeline for automatically generating high-quality training data for web agents. In particular, a major challenge in identifying high-quality training instances is trajectory evaluation - quantifying how much progress was made towards task completion. We introduce a novel const...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šScaling Web Agent Training through Automatic Data Generation and Fine-grained Evaluation

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰ **Web Agent** çš„è®­ç»ƒé¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼š
- **é«˜è´¨é‡è®­ç»ƒæ•°æ®ç¨€ç¼º**ï¼šçœŸå®ä¸–ç•Œä¸­å¤æ‚çš„ç½‘é¡µäº¤äº’è½¨è¿¹éš¾ä»¥å¤§è§„æ¨¡è·å–ã€‚
- **è½¨è¿¹è¯„ä¼°å›°éš¾**ï¼šä¼ ç»Ÿè¯„ä¼°æ–¹å¼ï¼ˆå¦‚ LLM-as-Judgeï¼‰åœ¨å¤šçº¦æŸã€é•¿å‘¨æœŸä»»åŠ¡ä¸­è¡¨ç°ä¸å¯é ï¼Œæ— æ³•å‡†ç¡®è¡¡é‡éƒ¨åˆ†æˆåŠŸï¼ˆpartial successï¼‰çš„è½¨è¿¹ä»·å€¼ã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº†å°æ¨¡å‹ï¼ˆsmall language modelsï¼‰åœ¨å¤æ‚ Web ä»»åŠ¡ä¸Šçš„èƒ½åŠ›æå‡ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

#### ï¼ˆ1ï¼‰**è‡ªåŠ¨åŒ–çš„é«˜è´¨é‡è½¨è¿¹ç”Ÿæˆä¸è’¸é¦æµæ°´çº¿ï¼ˆAutomatic Data Generation Pipelineï¼‰**
- åˆ©ç”¨å…¬å¼€çš„ **LLMï¼ˆå¦‚ LLaMA 3.1 405Bï¼‰ä½œä¸º Teacher Agent**ï¼Œé€šè¿‡ few-shot prompting åœ¨çœŸå®ç½‘ç«™ä¸Šè‡ªåŠ¨ç”Ÿæˆå¤§é‡ agent è½¨è¿¹ã€‚
- æ”¯æŒå¤æ‚ç°å®ä»»åŠ¡ï¼ˆå¦‚æ—…è¡Œé¢„è®¢ï¼‰ï¼Œæ¶µç›–å¤šä¸ªç½‘ç«™å’Œå¤šæ ·åŒ–ä»»åŠ¡ç±»å‹ã€‚

#### ï¼ˆ2ï¼‰**åŸºäºçº¦æŸçš„ç»†ç²’åº¦è¯„ä¼°æ¡†æ¶ï¼ˆConstraint-Based Evaluation Frameworkï¼‰**
- å°†ä»»åŠ¡æ‹†è§£ä¸ºä¸€ç»„æ˜ç¡®çš„ **constraints**ï¼ˆå¦‚ `location`, `start_date`, `ski-in/ski-out access` ç­‰ï¼‰ã€‚
- å¼•å…¥ **Constraint Satisfaction Rate (CSR)**ï¼šå¯¹æ¯ä¸ª constraint è¿›è¡ŒäºŒå…ƒåˆ¤æ–­ï¼ˆæ˜¯å¦æ»¡è¶³ï¼‰ï¼Œå¹¶å–å¹³å‡å€¼ä½œä¸ºè¯„ä¼°åˆ†æ•°ã€‚
- å®šä¹‰ **Task Success Rate (SR)**ï¼šä»…å½“æ‰€æœ‰ constraints éƒ½æ»¡è¶³æ—¶æ‰è®°ä¸ºæˆåŠŸï¼ˆå³ CSR=1ï¼‰ã€‚

> ğŸ’¡ ä¼˜åŠ¿ï¼šç›¸æ¯”ä¼ ç»Ÿçš„â€œå…¨æœ‰æˆ–å…¨æ— â€SR æŒ‡æ ‡ï¼ŒCSR æä¾›æ›´ç»†ç²’åº¦ã€å¯è§£é‡Šã€é²æ£’çš„åé¦ˆä¿¡å·ã€‚

#### ï¼ˆ3ï¼‰**åˆ©ç”¨éƒ¨åˆ†æˆåŠŸè½¨è¿¹è¿›è¡Œæ•°æ®å¢å¼º**
- å³ä½¿æœ€ç»ˆæœªå®Œæˆä»»åŠ¡ï¼Œåªè¦æŸä¸€æ­¥è¾¾åˆ°äº†æœ€é«˜ CSRï¼Œå°±æå–è¯¥å‰ç¼€ä½œä¸ºæœ‰æ•ˆè®­ç»ƒæ ·æœ¬ã€‚
- ç»“åˆ **hindsight re-labeling** æŠ€æœ¯ï¼Œå°†éƒ¨åˆ†æˆåŠŸçš„ä»»åŠ¡é‡æ–°å®šä¹‰ä¸ºå…¶å®é™…è¾¾æˆçš„ç›®æ ‡ï¼Œä»è€Œè½¬åŒ–ä¸ºåˆæ³•çš„è®­ç»ƒå®ä¾‹ã€‚

#### ï¼ˆ4ï¼‰æå‡ºæ–°åŸºå‡† **BookingArena**
- åŒ…å«æ¥è‡ª **20 ä¸ªæµè¡Œé¢„è®¢ç±»ç½‘ç«™** çš„ **120 ä¸ªå¤æ‚ç»“æ„åŒ–ä»»åŠ¡**ï¼ˆæ¯ç«™ 6 ä¸ªä»»åŠ¡ï¼‰ã€‚
- æŒ‰éš¾åº¦åˆ†ä¸º easy / medium / hardï¼Œå¹³å‡çº¦æŸæ•°åˆ†åˆ«ä¸º 3.95 / 5.45 / 7.30ã€‚
- æ‰€æœ‰ä»»åŠ¡å‡å¯åœ¨çº¿æ‰§è¡Œï¼Œå¹¶é™„å¸¦è„šæœ¬è‡ªåŠ¨æ›´æ–°è¿‡æœŸæ—¥æœŸä»¥ä¿æŒæœ‰æ•ˆæ€§ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | æœ¬æ–‡æ–¹æ³• | ä¼ ç»Ÿæ–¹æ³• |
|------|--------|---------|
| æ•°æ®ç”Ÿæˆ | å…¨è‡ªåŠ¨ã€å¯æ‰©å±•ã€è¦†ç›–çœŸå®ç½‘ç«™ | ä¾èµ–äººå·¥æ ‡æ³¨æˆ–é™æ€æ•°æ®é›† |
| è½¨è¿¹è¯„ä¼° | ç»†ç²’åº¦ã€å®¢è§‚ã€æ”¯æŒ partial progress | äºŒå€¼åŒ–ã€ä¸»è§‚æ€§å¼ºã€æ˜“å—å¹»è§‰å½±å“ |
| å¯ç”¨æ•°æ®é‡ | æ˜¾è‘—å¢åŠ ï¼ˆåˆ©ç”¨éƒ¨åˆ†æˆåŠŸè½¨è¿¹ï¼‰ | ä»…é™å®Œå…¨æˆåŠŸè½¨è¿¹ï¼ˆç¨€å°‘ï¼‰ |
| æ¨¡å‹è§„æ¨¡ | æˆåŠŸè®­ç»ƒ **24B å‚æ•°çš„å°æ¨¡å‹** | å¤šä¾èµ–è¶…å¤§é—­æºæ¨¡å‹ï¼ˆå¦‚ 405Bï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†

#### ï¼ˆ1ï¼‰**BookingArenaï¼ˆæœ¬æ–‡æå‡ºçš„æ–°åŸºå‡†ï¼‰**
- **20 ä¸ªçœŸå®é¢„è®¢ç½‘ç«™**ï¼ˆè§ Figure 9ï¼‰ï¼šåŒ…æ‹¬ `booking.com`, `airbnb.com`, `google flights`, `vrbo.com` ç­‰ã€‚
- **120 ä¸ªä»»åŠ¡**ï¼Œåˆ†å¸ƒäºä¸åŒéš¾åº¦ç­‰çº§ã€‚
- å¼ºè°ƒ **multi-constraint**, **long-horizon**, **real-world usability**ã€‚

#### ï¼ˆ2ï¼‰**WebVoyagerï¼ˆå¤–éƒ¨å¯¹æ¯”åŸºå‡†ï¼‰**
- æ¥è‡ª 15 ä¸ªç½‘ç«™çš„ 643 ä¸ªä»»åŠ¡ï¼Œåé‡æœç´¢ç±»æ“ä½œã€‚
- æ’é™¤ 55 ä¸ªå·²å¤±æ•ˆä»»åŠ¡ï¼Œå…¶ä½™æ—¶é—´ç›¸å…³ä»»åŠ¡è¢«è‡ªåŠ¨æ›´æ–°è‡³æœªæ¥æ—¥æœŸã€‚

#### ï¼ˆ3ï¼‰è‡ªå»ºè®­ç»ƒæ•°æ®é›†
- ä½¿ç”¨ **LLaMA 3 70B å’Œ LLaMA 3.1 405B Instruct** ç”Ÿæˆçº¦ **150k æ¡è½¨è¿¹**ï¼ˆå…± ~1M æ­¥éª¤ï¼‰ã€‚
- ç»è¿‡çº¦æŸè¯„ä¼°åä¿ç•™ï¼š
  - ~16k å®Œå…¨æˆåŠŸè½¨è¿¹ï¼ˆSR=1ï¼‰
  - ~65k éƒ¨åˆ†å¯ç”¨è½¨è¿¹ â†’ æå–ä¸º **300k åŠ¨ä½œæ­¥éª¤** çš„é«˜è´¨é‡è®­ç»ƒé›†ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®

#### æ¨¡å‹æ¶æ„
- **Student Model**: **Mistral 3 Small 24B**ï¼ˆå‚æ•°é‡è¿œå°äº teacherï¼‰
- **Fine-tuning æ–¹æ³•**: ä½¿ç”¨ **LoRA** å¾®è°ƒ `q_proj` å’Œ `v_proj` å±‚
- å­¦ä¹ ç‡ï¼š1e-4ï¼Œcosine schedulerï¼Œbatch size=16

#### è‡ªåŠ¨è¯„ä¼°æµç¨‹
1. ä½¿ç”¨ **LLaMA 3.3 70B** å’Œ **Gemma 3 27B** ä½œä¸º evaluator è¿›è¡Œ constraint-based è¯„åˆ†
2. å¯¹ä¸¤ä¸ª evaluator è¾“å‡ºå–äº¤é›†ä»¥å‡å°‘å™ªå£°
3. æœ€ç»ˆæ¨¡å‹è¯„ä¼°ä½¿ç”¨ **GPT-4oï¼ˆè§†è§‰è¾“å…¥ï¼‰**ï¼Œé¿å…æ•°æ®æ„å»ºåå·®

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **SR (Task Success Rate)** | æ‰€æœ‰ constraints å‡æ»¡è¶³çš„æ¯”ä¾‹ |
| **CSR (Constraint Satisfaction Rate)** | å¹³å‡æ¯ä¸ª constraint è¢«æ»¡è¶³çš„æ¯”ä¾‹ï¼ˆæ›´ç»†ç²’åº¦ï¼‰ |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”

| åŸºçº¿æ¨¡å‹ | ç±»å‹ | ç‰¹ç‚¹ |
|--------|-----|------|
| **UI-TARS** | å¼€æº VLM Agent | åŸºäº GUI çš„åŸç”Ÿäº¤äº’ |
| **Claude Computer Use (Anthropic)** | å•†ä¸šé—­æºç³»ç»Ÿ | Pixel-based æ§åˆ¶ |
| **Operator (OpenAI)** | å•†ä¸šé—­æºç³»ç»Ÿ | é«˜çº§è‡ªåŠ¨åŒ–ä»£ç† |
| **Browser Use** | å¼€æº Set-of-Marks Agent | æ•°å­—æ ‡è®°å¯ç‚¹å‡»å…ƒç´  |
| **Qwen 2.5 72B / LLaMA few-shot** | å¤§æ¨¡å‹é›¶æ ·æœ¬ | ä¸ç»å¾®è°ƒç›´æ¥æ¨ç† |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆBookingArena ä¸Šçš„ç»“æœï¼‰

| æ–¹æ³• | Avg. SR (%) | Avg. CSR (%) |
|------|-------------|--------------|
| **Ours (Mistral 24B)** | **29.9** | **60.2** |
| Operator | 33.0 | **68.7** |
| UI-TARS | 26.7 | 53.6 |
| Claude CU | 16.8 | 48.7 |
| Browser Use | 18.8 | 45.3 |

> âœ… **æˆ‘ä»¬çš„ 24B æ¨¡å‹åœ¨ SR ä¸Šä¼˜äºé™¤ Operator å¤–çš„æ‰€æœ‰åŸºçº¿ï¼Œåœ¨ CSR ä¸Šä»…æ¬¡äº Operator**

#### ğŸ† ç½‘ç«™çº§åˆ«äº®ç‚¹è¡¨ç°ï¼š
- **Booking.com**: æˆ‘ä»¬çš„ CSR è¾¾ **89.2%**ï¼ˆæœ€é«˜ï¼‰
- **Vrbo**: SR=66.7%, CSR=88.4%
- **Orbitz**: SR=80.0%, CSR=80.0%

> ğŸ’¬ å°½ç®¡æ•´ä½“ SR ä¸é«˜ï¼ˆå› ä»»åŠ¡æéš¾ï¼‰ï¼Œä½† CSR è¡¨æ˜æˆ‘ä»¬èƒ½æ˜¾è‘—æ¨è¿›ä»»åŠ¡è¿›åº¦ã€‚

---

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

| æ¨¡å‹é…ç½® | SR (%) | CSR (%) | è¯´æ˜ |
|--------|-------|--------|------|
| Mistral 24B (success only) | 25.0 | 55.0 | ä»…ç”¨å®Œå…¨æˆåŠŸè½¨è¿¹ |
| Mistral 24B (all trajectories) | 29.4 | 57.2 | åŒ…å«å¤±è´¥è½¨è¿¹ |
| **Mistral 24B (partial success)** | **29.9** | **60.2** | âœ… æœ€ä½³ç­–ç•¥ â€”â€” åˆ©ç”¨éƒ¨åˆ†æˆåŠŸè½¨è¿¹ |
| Mistral 24B (full finetune) | â€“ | 58.7 | LoRA æ›´ä¼˜ï¼Œfull finetune æ˜“è¿‡æ‹Ÿåˆ |
| LLaMA 405B (few-shot) | 22.5 | 52.4 | æ›´å¤§çš„ teacher æ¨¡å‹ä»ä¸å¦‚è’¸é¦åçš„å°æ¨¡å‹ |

> âœ… **å…³é”®å‘ç°**ï¼š  
> - **å­¦ä¹ éƒ¨åˆ†æˆåŠŸè½¨è¿¹ > ä»…å­¦ä¹ å®Œå…¨æˆåŠŸè½¨è¿¹**
> - **LoRA > Full Finetuning**ï¼šæ›´é€‚åˆæ­¤åœºæ™¯ä¸‹çš„çŸ¥è¯†è¿ç§»
> - **å°æ¨¡å‹ç»é«˜è´¨é‡æ•°æ®è’¸é¦åå¯è¶…è¶Šæ›´å¤§ teacher æ¨¡å‹**

---

### ğŸŒ WebVoyager ä¸Šçš„è¡¨ç°

| æ–¹æ³• | Overall SR (%) |
|------|----------------|
| Wilbur (Lutz et al.) | 52.6 |
| GPT-4V (reported) | 57.1 |
| **Ours (Mistral 24B)** | **64.5** |

> âœ… åœ¨å¤šä¸ªé¢†åŸŸå¤§å¹…é¢†å…ˆï¼Œå°¤å…¶åœ¨ **Booking (+11.1%)** å’Œ **Google Flights (+15.1%)** ä¸Šè¡¨ç°çªå‡ºã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **ç»†ç²’åº¦è¯„ä¼°ï¼ˆCSRï¼‰æ˜¯æ¨åŠ¨ Web Agent å‘å±•çš„å…³é”®**
   - æä¾›æ¯” SR æ›´ä¸°å¯Œã€å¯é çš„ä»»åŠ¡è¿›å±•ä¿¡å·ã€‚
   - æ”¯æŒè¯†åˆ«å’Œåˆ©ç”¨ **partial trajectories**ï¼Œæå¤§æ‰©å±•å¯ç”¨è®­ç»ƒæ•°æ®ã€‚

2. **é«˜è´¨é‡æ•°æ®è’¸é¦èƒ½è®©å°æ¨¡å‹è¶…è¶Šå¤§æ¨¡å‹**
   - æˆ‘ä»¬çš„ **24B Mistral æ¨¡å‹** åœ¨å¤šæ•°æŒ‡æ ‡ä¸Šè¶…è¿‡ **405B LLaMA teacher** å’Œå¤šä¸ªå•†ä¸šç³»ç»Ÿï¼ˆå¦‚ Claudeã€Browser Useï¼‰ã€‚

3. **BookingArena æ˜¯ä¸€ä¸ªæ›´å…·æŒ‘æˆ˜æ€§å’Œç°å®æ„ä¹‰çš„æµ‹è¯•å¹³å°**
   - æ­ç¤ºäº†å½“å‰ä¸»æµæ–¹æ³•åœ¨å¤æ‚å¤šçº¦æŸä»»åŠ¡ä¸­çš„å±€é™æ€§ã€‚
   - æœ‰æœ›æˆä¸ºæœªæ¥ Web Agent ç ”ç©¶çš„æ ‡å‡† benchmarkã€‚

4. **URL æ˜¯æ¯” action history æ›´å¯é çš„è¯„ä¼°ä¾æ®**
   - å®éªŒè¯æ˜æä¾› action history ä¼šå¯¼è‡´ evaluator â€œå¹»è§‰â€ï¼Œè¯¯åˆ¤åŠ¨ä½œæ‰§è¡Œæ•ˆæœã€‚
   - è€Œ URL ä¸­ç¼–ç çš„ä¿¡æ¯ï¼ˆå¦‚æ—¥æœŸã€åœ°ç‚¹ï¼‰èƒ½æä¾›å®¢è§‚è¯æ®ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

1. **ä¾èµ– LLM æå– constraints çš„å‡†ç¡®æ€§**
   - è‹¥ constraint extraction å‡ºé”™ï¼Œä¼šå½±å“åç»­è¯„ä¼°è´¨é‡ã€‚
   - å½“å‰æœªå¯¹ constraint æå–è¿‡ç¨‹åšè¯¯å·®åˆ†æã€‚

2. **å°šæœªæ”¯æŒ multimodal observations**
   - å½“å‰ pipeline ä¸»è¦åŸºäº accessibility tree å’Œæ–‡æœ¬ URLï¼Œæœªå……åˆ†åˆ©ç”¨å›¾åƒè¯­ä¹‰ã€‚

3. **å±€é™äºè‹±æ–‡ç½‘ç«™å’Œé¢„è®¢ç±»ä»»åŠ¡**
   - æ³›åŒ–åˆ°å…¶ä»–è¯­è¨€ã€å¹³å°ï¼ˆå¦‚ç§»åŠ¨ç«¯ Appï¼‰ã€ä»»åŠ¡ç±»å‹ï¼ˆå¦‚ç¤¾äº¤ç½‘ç»œæ“ä½œï¼‰å°šéœ€æ‹“å±•ã€‚

4. **evaluation ä»ä¾èµ– LLM/VLM judge**
   - è™½ç„¶è®¾è®¡äº†æ›´ç³»ç»Ÿçš„æ¡†æ¶ï¼Œä½†ä»æœªå®Œå…¨æ‘†è„±å¯¹ black-box judge çš„ä¾èµ–ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•è‡³å¤šæ¨¡æ€è§‚å¯Ÿç©ºé—´**
   - æ•´åˆ screenshotã€DOMã€è¯­éŸ³ç­‰å¤šæºä¿¡æ¯è¿›è¡Œè”åˆå»ºæ¨¡ã€‚

2. **æ„å»ºé€šç”¨ constraint extractor**
   - è®¾è®¡ä¸“ç”¨æ¨¡å—è‡ªåŠ¨ã€å‡†ç¡®åœ°ä»è‡ªç„¶è¯­è¨€ä»»åŠ¡æè¿°ä¸­æŠ½å– structured constraintsã€‚

3. **åº”ç”¨äºæ›´å¤šé¢†åŸŸå’Œå¹³å°**
   - å¦‚ç”µå•†è´­ç‰©ã€é“¶è¡ŒæœåŠ¡ã€æ”¿åºœäº‹åŠ¡åŠç†ç­‰ real-world workflowsã€‚

4. **æ¢ç´¢ online learning æœºåˆ¶**
   - ç»“åˆç”¨æˆ·åé¦ˆæŒç»­ä¼˜åŒ– agent è¡Œä¸ºä¸è¯„ä¼°æ ‡å‡†ã€‚

5. **å¼€æºæ•°æ®é›†ä¸ benchmark**
   - æ¨åŠ¨ç¤¾åŒºå…±å»ºå¼€æ”¾ã€é€æ˜ã€å¯å¤ç°çš„ Web Agent ç ”ç©¶ç”Ÿæ€ã€‚

---

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> æœ¬æ–‡é€šè¿‡ **è‡ªåŠ¨æ•°æ®ç”Ÿæˆ + åŸºäº constraint çš„ç»†ç²’åº¦è¯„ä¼°**ï¼Œå®ç°äº†é«˜æ•ˆè®­ç»ƒé«˜æ€§èƒ½å°è§„æ¨¡ Web Agentï¼Œåœ¨æ–°æå‡ºçš„ **BookingArena** å’Œç°æœ‰ **WebVoyager** åŸºå‡†ä¸Šå‡å–å¾— SOTA è¡¨ç°ï¼Œè¯æ˜äº†â€œå¥½æ•°æ® + å¥½è¯„ä¼°â€æ¯”â€œå¤§æ¨¡å‹ + é»‘ç›’åˆ¤æ–­â€æ›´å…·æ½œåŠ›ã€‚

</details>

---

### 4. [Think Fast and Slow: Step-Level Cognitive Depth Adaptation for LLM Agents](https://arxiv.org/abs/2602.12662)

**Authors**: Ruihan Yang, Fanghua Ye, Xiang We, Ruoqing Zhao, Kang Luo, Xinbo Xu, Bo Zhao, Ruotian Ma, Shanyi Wang, Zhaopeng Tu, Xiaolong Li, Deqing Yang,  Linus  
**Category**: cs.AI  
**Published**: 2026-02-16  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.12662v1  

#### Abstract
Large language models (LLMs) are increasingly deployed as autonomous agents for multi-turn decision-making tasks. However, current agents typically rely on fixed cognitive patterns: non-thinking models generate immediate responses, while thinking models engage in deep reasoning uniformly. This rigid...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šThink Fast and Slow: Step-Level Cognitive Depth Adaptation for LLM Agents**

---

## 1. **è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å½“å‰çš„ LLM Agents åœ¨æ‰§è¡Œå¤šè½®å†³ç­–ä»»åŠ¡æ—¶é€šå¸¸é‡‡ç”¨**å›ºå®šçš„è®¤çŸ¥æ¨¡å¼**ï¼ˆfixed cognitive patternsï¼‰ï¼š
- **éæ€è€ƒæ¨¡å‹**ï¼ˆnon-thinking modelsï¼‰åœ¨æ¯ä¸€æ­¥éƒ½è¿›è¡Œç›´è§‰ååº”ï¼Œç¼ºä¹æ·±åº¦æ¨ç†èƒ½åŠ›ï¼›
- **æ€è€ƒæ¨¡å‹**ï¼ˆthinking modelsï¼‰åˆ™åœ¨æ•´ä¸ªè½¨è¿¹ä¸­å§‹ç»ˆè¿›è¡Œæ·±åº¦é“¾å¼æ¨ç†ï¼ˆå¦‚ DeepSeek-R1ï¼‰ï¼Œå¯¼è‡´åœ¨ç®€å•æ­¥éª¤ä¸Šæµªè´¹å¤§é‡è®¡ç®—èµ„æºã€‚

è¿™ç§â€œè®¤çŸ¥åƒµåŒ–â€ï¼ˆcognitive rigidityï¼‰åœ¨é•¿è§†é‡ï¼ˆlong-horizonï¼‰ã€å¼‚æ„æ­¥çº§å¤æ‚åº¦çš„ä»»åŠ¡ä¸­æ•ˆç‡ä½ä¸‹ã€‚ä¾‹å¦‚ï¼Œåœ¨æ¢ç´¢æˆ¿é—´ååªéœ€â€œgo to bathroomâ€çš„ä¾‹è¡Œæ“ä½œå´ä»è¿›è¡Œå¤æ‚è§„åˆ’ï¼Œé€ æˆ**token æµªè´¹ä¸å“åº”å»¶è¿Ÿ**ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æœ¬æ–‡æå‡º **CoGROUTER** æ¡†æ¶ï¼Œå®ç° LLM Agent åœ¨æ¯ä¸€æ­¥åŠ¨æ€è°ƒæ•´å…¶**è®¤çŸ¥æ·±åº¦**ï¼ˆcognitive depthï¼‰ï¼Œçµæ„Ÿæ¥æºäºäººç±»è®¤çŸ¥ç†è®º **ACT-R**ï¼ˆAdaptive Control of Thought-Rationalï¼‰ã€‚

#### **æ ¸å¿ƒè®¾è®¡**
- å®šä¹‰å››ä¸ªå±‚çº§çš„è®¤çŸ¥æ°´å¹³ï¼ˆCognitive Levelsï¼‰ï¼š
  - **L1: Instinctive Response**ï¼ˆç›´è§‰ååº”ï¼‰â€”â€”æ— æ˜¾å¼æ¨ç†ï¼Œç›´æ¥è¾“å‡ºåŠ¨ä½œã€‚
  - **L2: Situational Awareness**ï¼ˆæƒ…å¢ƒæ„ŸçŸ¥ï¼‰â€”â€”åˆ†æå½“å‰çŠ¶æ€ä¸å¯ç”¨åŠ¨ä½œã€‚
  - **L3: Experience Integration**ï¼ˆç»éªŒæ•´åˆï¼‰â€”â€”å›é¡¾å†å²è¡Œä¸ºå¹¶åæ€ã€‚
  - **L4: Strategic Planning**ï¼ˆæˆ˜ç•¥è§„åˆ’ï¼‰â€”â€”æ¨¡æ‹Ÿå¤šä¸ªå€™é€‰åŠ¨ä½œçš„æœªæ¥å½±å“ã€‚

- ä¸¤é˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼š
  1. **Cognition-aware Supervised Fine-tuning (CoSFT)**  
     æ„å»ºå¹³è¡¡æ ‡æ³¨æ•°æ®é›†ï¼Œä½¿æ¨¡å‹æŒæ¡å„å±‚çº§ç¨³å®šçš„è¡Œä¸ºæ¨¡å¼ï¼Œé˜²æ­¢åç»­ RL ä¸­çš„æ ¼å¼å´©æºƒï¼ˆformat collapseï¼‰ã€‚
  2. **Cognition-aware Policy Optimization (CoPO)**  
     æ–°å‹å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œé€šè¿‡**ç½®ä¿¡åº¦æ„ŸçŸ¥ä¼˜åŠ¿é‡åŠ æƒ**ï¼ˆconfidence-aware advantage reweightingï¼‰å®ç°ç»†ç²’åº¦çš„æ­¥çº§ä¿¡ç”¨åˆ†é…ã€‚

#### **å…³é”®æ´å¯Ÿ**
> â€œåˆé€‚çš„è®¤çŸ¥æ·±åº¦åº”æœ€å¤§åŒ–åŠ¨ä½œé¢„æµ‹çš„ç½®ä¿¡åº¦ã€‚â€  
å³ï¼šå½“ä¸€ä¸ªè®¤çŸ¥å±‚çº§èƒ½æ›´è‡ªä¿¡åœ°å¼•å¯¼å‡ºæ­£ç¡®åŠ¨ä½œæ—¶ï¼Œå®ƒå°±æ˜¯è¯¥æ­¥æ›´ä¼˜çš„é€‰æ‹©ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | CoGROUTER vs. ç°æœ‰æ–¹æ³• |
|------|------------------------|
| **çµæ´»æ€§** | è¶…è¶ŠäºŒå…ƒåˆ‡æ¢ï¼ˆå¦‚ AdaptThinkï¼‰ï¼Œæ”¯æŒå››å±‚è¿ç»­é€‚åº” |
| **æ•ˆç‡** | æ˜¾è‘—å‡å°‘ token ä½¿ç”¨é‡ï¼ˆæœ€é«˜èŠ‚çœ 62%ï¼‰ |
| **æ€§èƒ½** | è¾¾åˆ° SOTA æˆåŠŸç‡ï¼Œè¿œè¶… GPT-4oã€GRPO ç­‰å‰æ²¿æ¨¡å‹ |
| **æœºåˆ¶åˆ›æ–°** | é¦–æ¬¡å®ç°åŸºäº**åŠ¨ä½œé¢„æµ‹ç½®ä¿¡åº¦**çš„æ­¥çº§ä¿¡ç”¨åˆ†é… |

---

## 2. **æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **ALFWorld**ï¼šåŸºäº TextWorld çš„å…·èº«ç¯å¢ƒï¼ŒåŒ…å«å…­ç±»å®¶åº­ä»»åŠ¡ï¼ˆPick & Place, Clean & Place ç­‰ï¼‰ï¼Œæœ€å¤§æ­¥æ•°ä¸º 30ã€‚
- **ScienceWorld**ï¼šé¢å‘å°å­¦ç§‘å­¦è¯¾ç¨‹çš„æ–‡æœ¬ç¯å¢ƒï¼Œæ¶µç›– 30 ç§ç§‘å­¦æ¨ç†ä»»åŠ¡ï¼ˆå¦‚ä½¿ç”¨æ¸©åº¦è®¡æµ‹é‡ç‰©è´¨ï¼‰ã€‚æŒ‰ oracle è·¯å¾„é•¿åº¦åˆ†ä¸ºçŸ­ï¼ˆSï¼‰ã€ä¸­ï¼ˆMï¼‰ã€é•¿ï¼ˆLï¼‰ä¸‰ç±»ä»»åŠ¡ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

| è®¾ç½®é¡¹ | æè¿° |
|-------|------|
| **Base Models** | `Qwen2.5-7B` å’Œ `Llama3.1-8B` |
| **è®­ç»ƒæ–¹å¼** | ä¸¤é˜¶æ®µï¼š<br>1. CoSFTï¼ˆç›‘ç£å¾®è°ƒï¼‰<br>2. CoPOï¼ˆå¼ºåŒ–å­¦ä¹ ä¼˜åŒ–ï¼‰ |
| **è¯„ä¼°æ–¹å¼** | åœ¨æµ‹è¯•é›†ä¸Šè¿è¡Œ 200 æ¬¡æ¨¡æ‹Ÿ |
| **è¯„ä¼°æŒ‡æ ‡** | - **Success Rate (SR)**ï¼ˆæˆåŠŸç‡ï¼‰<br>- **Average Score**ï¼ˆä»… ScienceWorldï¼‰<br>- **#Tokens**ï¼ˆå¹³å‡æ¯ä»»åŠ¡è¾“å‡º token æ•°ï¼Œè¡¡é‡æ•ˆç‡ï¼‰ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

#### **Prompt-based æ–¹æ³•**
- **ReAct**ï¼šæ ‡å‡†çš„â€œThought: ... Action: ...â€æ ¼å¼ã€‚
- **Reflexion**ï¼šå¤±è´¥åè‡ªæˆ‘åæ€å¹¶æ”¹è¿›ç­–ç•¥ã€‚

#### **Training-based æ–¹æ³•**
- **SFT / ETO**ï¼šç¦»çº¿ç›‘ç£è®­ç»ƒã€‚
- **GRPO / GiGPO**ï¼šåŸºäºç»„çš„å¼ºåŒ–å­¦ä¹ ï¼Œä¸åŒºåˆ†æ­¥çº§è®¤çŸ¥éœ€æ±‚ã€‚
- **AdaptThink**ï¼šäºŒå…ƒæ€ç»´å¼€å…³ï¼ˆthink vs. non-thinkï¼‰ã€‚

#### **å‰æ²¿å¤§æ¨¡å‹**
- GPT-4o, DeepSeek-R1, OpenAI-o3, Gemini-2.5-Pro ç­‰ã€‚

---

## 3. **ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ Qwen2.5-7B ä¸ºä¾‹ï¼‰**

| æ–¹æ³• | å¹³å‡æˆåŠŸç‡ (SR%) | å¹³å‡ Token æ•° |
|------|------------------|---------------|
| **CoGROUTER (Ours)** | **82.3%** | **1641.4** |
| GPT-4o | 42.0% | 935.4 |
| OpenAI-o3 | 64.0% | 4737.5 |
| GRPO | 68.3% | 4367.3 |
| GiGPO | 67.5% | 3779.2 |
| AdaptThink | 63.0% | 1343.2 |

> âœ… **CoGROUTER æ¯” GPT-4o é«˜ +40.3%ï¼Œæ¯” GRPO é«˜ +14.0% æˆåŠŸç‡ï¼ŒåŒæ—¶èŠ‚çœ 62% tokenã€‚**

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

#### **å›ºå®šæ¨¡å¼ vs. è‡ªé€‚åº”**
- **L1-only æ¨¡å‹**ï¼šæˆåŠŸç‡ä¸º 76.5%ï¼Œæé«˜æ•ˆä½†æ— æ³•å¤„ç†å¤æ‚æ­¥éª¤ã€‚
- **L4-only æ¨¡å‹**ï¼šæˆåŠŸç‡ä¸º 86.5%ï¼Œä½†æ¶ˆè€—é«˜è¾¾ 4640.98 tokensï¼ˆæ˜¯ CoGROUTER çš„ 2.7 å€ï¼‰ã€‚
- **FreeFormï¼ˆæ— ç»“æ„æ¨ç†ï¼‰**ï¼š81.5% SR @ 4068.88 tokensï¼Œè¯´æ˜é»˜è®¤å€¾å‘æ·±æ€ã€‚

> â¡ï¸ ç»“è®ºï¼šå•ä¸€è®¤çŸ¥æ¨¡å¼æ— æ³•å…¼é¡¾æ€§èƒ½ä¸æ•ˆç‡ï¼Œ**è‡ªé€‚åº”æ‰æ˜¯æœ€ä¼˜è§£**ã€‚

#### **RL æ–¹æ³•æ¯”è¾ƒï¼ˆå›¾ 3 & å›¾ 4ï¼‰**
- **GRPO/GiGPO**ï¼šå¿«é€Ÿåç¼©è‡³ L4 å ä¸»å¯¼ï¼ˆ>75% æ­¥éª¤ä½¿ç”¨ L4ï¼‰ï¼Œå³ä½¿åœ¨ç®€å•æ­¥éª¤ä¹Ÿè¿‡åº¦æ€è€ƒã€‚
- **CoPO**ï¼šä¿æŒå¤šæ ·åŒ–åˆ†å¸ƒï¼š
  - ALFWorld ä¸Šï¼šL1 å  55.0%ï¼ŒL4 ä»…å  12.3%
  - ScienceWorld ä¸Šï¼šéšä»»åŠ¡è¿›å±•ï¼ŒL1 ä» 48.5% å‡è‡³ 94.8%

> âœ… CoPO å®ç°çœŸæ­£çš„**æƒ…å¢ƒæ„ŸçŸ¥å¼è®¤çŸ¥è°ƒåº¦**ã€‚

#### **æ”¶æ•›é€Ÿåº¦**
- CoPO åœ¨ **100 æ­¥å†…è¾¾åˆ° 90% æˆåŠŸç‡**ï¼ˆALFWorldï¼‰ï¼Œè€Œ GRPO åœ¨ 150 æ­¥åä»…è¾¾ 83.3%ã€‚
- æ”¶æ•›æ›´å¿«ï¼Œå¾—ç›Šäºæ›´ç²¾ç»†çš„æ­¥çº§ä¿¡ç”¨ä¿¡å·ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**

| å˜ä½“ | SR (%) | #Tokens | åˆ†æ |
|------|--------|---------|------|
| **CoPO (Ours)** | 82.3 | 1641.4 | åŸºå‡† |
| w/ Max Probs | 79.5 | 2167.5 | å±€éƒ¨å³°å€¼è¯¯å¯¼ï¼Œæ€§èƒ½ä¸‹é™ |
| w/ Min Probs | 67.5 | 2063.6 | å•ä¸ªä½æ¦‚ç‡ token ä¸»å¯¼ï¼Œä¸ç¨³å®š |
| w/ Entropy | 70.0 | 1873.9 | è¡¡é‡æ•´ä½“ä¸ç¡®å®šæ€§ï¼Œä¸åæ˜ åŠ¨ä½œä¸€è‡´æ€§ |
| w/o Cold Start | 75.3 | 3123.4 | ç¼ºä¹ SFT åˆå§‹åŒ–ï¼Œæ ¼å¼å´©æºƒä¸¥é‡ |
| w/ CoSFTexpert | 74.5 | 3627.2 | ç»§æ‰¿ä¸“å®¶åå¥½ï¼ˆåçˆ± L3ï¼‰ï¼Œä¸§å¤±é€‚åº”æ€§ |
| w/ Corr & Incorr | 74.5 | 1565.7 | å¯¹å¤±è´¥è½¨è¿¹ä¹ŸåŠ æƒï¼Œè¯±å¯¼æ¨¡å‹è§„é¿ä¿¡å¿ƒ |

> ğŸ” **éªŒè¯äº†ä¸¤ä¸ªå…³é”®è®¾è®¡ï¼š**
> 1. ä½¿ç”¨å¹³å‡å¯¹æ•°æ¦‚ç‡ä½œä¸ºç½®ä¿¡åº¦æŒ‡æ ‡æœ€æœ‰æ•ˆï¼›
> 2. å¿…é¡»ä»å¹³è¡¡åˆå§‹åŒ–å¼€å§‹ï¼Œå¹¶åªå¯¹æˆåŠŸè½¨è¿¹è¿›è¡Œé‡åŠ æƒã€‚

---

## 4. **å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **è®¤çŸ¥åƒµåŒ–æ˜¯å½“å‰ Agent çš„æ ¹æœ¬ç“¶é¢ˆ**  
   å›ºå®šæ€è€ƒæˆ–éæ€è€ƒæ¨¡å¼å‡æ— æ³•åº”å¯¹ä»»åŠ¡å†…éƒ¨çš„æ­¥çº§å¼‚è´¨æ€§ã€‚

2. **äººç±»å¯å‘çš„è®¤çŸ¥åˆ†å±‚æ˜¯å¯è¡Œè·¯å¾„**  
   åŸºäº ACT-R ç†è®ºåˆ’åˆ† L1â€“L4 å±‚çº§ï¼Œç¬¦åˆä»»åŠ¡æ¼”è¿›è§„å¾‹ï¼š
   - åˆå§‹é˜¶æ®µå¤šç”¨ L4ï¼ˆæˆ˜ç•¥è§„åˆ’ï¼‰
   - ä¸­æœŸæ¢ç´¢ç”¨ L2/L3ï¼ˆæƒ…å¢ƒæ„ŸçŸ¥ + ç»éªŒæ•´åˆï¼‰
   - åæœŸæ‰§è¡Œå›å½’ L1ï¼ˆæœ¬èƒ½ååº”ï¼‰

3. **CoPO å®ç°äº†é«˜æ•ˆçš„æ­¥çº§ä¿¡ç”¨åˆ†é…**  
   é€šè¿‡â€œå“ªä¸ªè®¤çŸ¥å±‚çº§è®©æˆ‘æ›´ç¡®ä¿¡åšå‡ºæ­£ç¡®åŠ¨ä½œï¼Ÿâ€è¿™ä¸€åŸåˆ™ï¼Œé¿å…äº†ä¼ ç»Ÿ RL æ–¹æ³•å‘ L4 çš„åç¼©ã€‚

4. **è‡ªé€‚åº”æ˜¾è‘—æå‡æ€§èƒ½ä¸æ•ˆç‡**  
   ä¸ä»…è¶…è¶Šæ‰€æœ‰ baselineï¼Œè¿˜å®ç°äº†**æ›´é«˜æ€§èƒ½ + æ›´å°‘èµ„æºæ¶ˆè€—**çš„å¸•ç´¯æ‰˜ä¼˜åŠ¿ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–ç»“æ„åŒ–è¾“å‡ºæ ¼å¼**ï¼šå¿…é¡»ä½¿ç”¨ `<level>`, `<think>`, `<action>` æ ‡ç­¾ï¼Œå¯èƒ½é™åˆ¶æ³›åŒ–ã€‚
- **CoSFT æ•°æ®æ„å»ºæˆæœ¬é«˜**ï¼šéœ€äººå·¥æ ‡æ³¨æˆ– GPT-4o ç”Ÿæˆå¸¦å±‚çº§æ ‡ç­¾çš„è½¨è¿¹ã€‚
- **ä»…é€‚ç”¨äºç¨€ç–å¥–åŠ±ä»»åŠ¡**ï¼šå¯†é›†å¥–åŠ±åœºæ™¯ä¸‹ä¼˜åŠ¿å¯èƒ½å‡å¼±ã€‚
- **æœªæ¢ç´¢æ›´å¤šå±‚çº§æˆ–è¿ç»­ç©ºé—´**ï¼šç›®å‰ä¸ºç¦»æ•£å››çº§ï¼Œæœªæ¥å¯å°è¯•è½¯è·¯ç”±æˆ–ç¥ç»æ§åˆ¶å™¨ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **æ‰©å±•è®¤çŸ¥å±‚çº§æ•°é‡ä¸ç±»å‹**  
   æ¢ç´¢æ›´ç»†ç²’åº¦æˆ–ä»»åŠ¡ç‰¹å®šçš„è®¤çŸ¥æ¨¡å—ã€‚
   
2. **å®ç°ç«¯åˆ°ç«¯çš„è®¤çŸ¥è·¯ç”±æœºåˆ¶**  
   æ›¿ä»£æ˜¾å¼æ ‡ç­¾ï¼Œè®©æ¨¡å‹è‡ªä¸»å†³å®šä½•æ—¶è¿›å…¥ä½•ç§æ€ç»´æ¨¡å¼ã€‚

3. **åº”ç”¨äºçœŸå®ä¸–ç•Œäº¤äº’ä»»åŠ¡**  
   å¦‚æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ã€è½¯ä»¶å·¥ç¨‹ä»£ç†ç­‰ã€‚

4. **ç ”ç©¶è®¤çŸ¥æ¼”åŒ–æœºåˆ¶**  
   å…è®¸æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­**è‡ªåŠ¨ç”Ÿæˆæ–°çš„è®¤çŸ¥å±‚çº§**ï¼Œå½¢æˆâ€œè‡ªæˆ‘è¿›åŒ–â€çš„æ™ºèƒ½ä½“ã€‚

5. **ç»“åˆè®°å¿†ç³»ç»Ÿä¸å…ƒè®¤çŸ¥ç›‘æ§**  
   å¼•å…¥â€œæˆ‘æ˜¯å¦åº”è¯¥æ¢ä¸€ç§æ€ç»´æ–¹å¼ï¼Ÿâ€çš„å…ƒçº§åˆ«åˆ¤æ–­ã€‚

---

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> **CoGROUTER æ˜¯é¦–ä¸ªå®ç°â€œå¿«æ…¢åŒç³»ç»Ÿâ€ååŒçš„ LLM Agent æ¡†æ¶ï¼Œè®©æ¨¡å‹å­¦ä¼šâ€œä»€ä¹ˆæ—¶å€™è¯¥æ·±æ€ï¼Œä»€ä¹ˆæ—¶å€™è¯¥ç›´è§‰â€ï¼Œåœ¨æ€§èƒ½ä¸æ•ˆç‡ä¹‹é—´å–å¾—å‰æ‰€æœªæœ‰çš„å¹³è¡¡ã€‚**

</details>

---

### 5. [Multi-Dimensional Visual Data Recovery: Scale-Aware Tensor Modeling and Accelerated Randomized Computation](https://arxiv.org/abs/2602.12982)

**Authors**: Wenjin Qin, Hailin Wang, Jiangjun Peng, Jianjun Wang, Tingwen Huang  
**Category**: cs.LG  
**Published**: 2026-02-16  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.12982v1  

#### Abstract
The recently proposed fully-connected tensor network (FCTN) decomposition has demonstrated significant advantages in correlation characterization and transpositional invariance, and has achieved notable achievements in multi-dimensional data processing and analysis. However, existing multi-dimension...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMulti-Dimensional Visual Data Recovery: Scale-Aware Tensor Modeling and Accelerated Randomized Computation

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹**å¤§è§„æ¨¡å¤šç»´è§†è§‰æ•°æ®æ¢å¤**ä¸­å­˜åœ¨çš„ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼š
- **å»ºæ¨¡èƒ½åŠ›ä¸è¶³**ï¼šç°æœ‰åŸºäº FCTN åˆ†è§£çš„æ–¹æ³•éš¾ä»¥åŒæ—¶æœ‰æ•ˆæ•æ‰æ•°æ®çš„å…¨å±€ä½ç§©æ€§ï¼ˆGlobal Low-Rankness, Lï¼‰å’Œå±€éƒ¨å¹³æ»‘æ€§ï¼ˆLocal Smoothness, Sï¼‰ã€‚
- **è®¡ç®—æ•ˆç‡ä½ä¸‹**ï¼šå¤„ç†é«˜é˜¶å¤§å°ºåº¦å¼ é‡æ—¶ï¼Œä¼ ç»Ÿ FCTN æ–¹æ³•é¢ä¸´é«˜æ˜‚çš„ SVD å’Œ ALS è®¡ç®—å¼€é”€ï¼Œéš¾ä»¥æ‰©å±•åˆ°å®é™…åº”ç”¨ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
1. **FCTN-GNTCTV æ­£åˆ™åŒ–å™¨ï¼ˆFCTN-based Generalized Nonconvex Tensor Correlated Total Variationï¼‰**
   - åœ¨ FCTN åˆ†è§£æ¡†æ¶ä¸‹ï¼Œæå‡ºä¸€ç§æ–°å‹éå‡¸æ¢¯åº¦åŸŸæ­£åˆ™åŒ–æ–¹æ³•ï¼Œé€šè¿‡åœ¨æ¢¯åº¦å¼ é‡ä¸Šæ–½åŠ  FCTN æ ¸èŒƒæ•°ï¼Œ**è”åˆç¼–ç å…¨å±€ä½ç§©æ€§å’Œå±€éƒ¨è¿ç»­æ€§**ã€‚
   - å¼•å…¥**éå‡¸å‡½æ•°**ï¼ˆå¦‚ MCPã€SCAD ç­‰ï¼‰å¢å¼ºå¯¹ä½ç§©ç»“æ„çš„è¯±å¯¼èƒ½åŠ›ã€‚

2. **é²æ£’å¯æ‰©å±•çš„æ•°æ®æ¢å¤æ¨¡å‹**
   - æ„å»ºäº†ä»**éé‡åŒ–è§‚æµ‹åˆ°ç²—ç²’åº¦é‡åŒ–è§‚æµ‹**çš„ç»Ÿä¸€å»ºæ¨¡æ¡†æ¶ï¼Œæå‡æ¨¡å‹åœ¨çœŸå®ç³»ç»Ÿä¸­çš„é€‚ç”¨æ€§ï¼ˆè€ƒè™‘å­˜å‚¨ã€å¸¦å®½é™åˆ¶ä¸‹çš„é‡åŒ–å½±å“ï¼‰ã€‚

3. **åŠ é€Ÿçš„éšæœºå‹ç¼©ç®—æ³•ï¼ˆAccelerated Randomized Compressionï¼‰**
   - åŸºäºæ•°å€¼çº¿æ€§ä»£æ•°ä¸­çš„ sketching æŠ€æœ¯ï¼Œè®¾è®¡äº†ä¸¤ç§é«˜æ•ˆçš„éšæœºå‹ç¼©ç®—æ³•ï¼š
     - **Fixed-Rank Randomized Algorithm**ï¼šç»™å®šç›®æ ‡ç§©è¿›è¡Œå¿«é€Ÿå‹ç¼©ã€‚
     - **Fixed-Accuracy Randomized Algorithm**ï¼šè‡ªé€‚åº”ç¡®å®šç§©ä»¥æ»¡è¶³ç²¾åº¦è¦æ±‚ã€‚
   - è¿™äº›ç®—æ³•ä½œä¸ºæ•´ä¸ªæ¢å¤æ¡†æ¶çš„**è®¡ç®—åŠ é€Ÿæ ¸å¿ƒ**ï¼Œæ˜¾è‘—é™ä½é«˜é˜¶å¼ é‡å¤„ç†çš„å¤æ‚åº¦ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **å»ºæ¨¡èƒ½åŠ›** | åŒæ—¶å»ºæ¨¡ L+S ç»“æ„ï¼Œä¼˜äºä»…ä¾èµ–ä½ç§©æ€§çš„æ–¹æ³•ï¼ˆå¦‚ TRNNMã€HTNNï¼‰æˆ–ä»…å¹³æ»‘æ€§æ–¹æ³•ã€‚ |
| **è®¡ç®—æ•ˆç‡** | éšæœºå‹ç¼©ç­–ç•¥ä½¿è¿è¡Œæ—¶é—´å¹³å‡å‡å°‘çº¦ **88%**ï¼Œç›¸æ¯”ç¡®å®šæ€§ç‰ˆæœ¬å®ç° **9Ã— å¹³å‡åŠ é€Ÿ**ï¼Œä¸ªåˆ«æ¡ˆä¾‹è¾¾ **20Ã— åŠ é€Ÿ**ã€‚ |
| **æ¢å¤ç²¾åº¦** | åœ¨æä½é‡‡æ ·ç‡ï¼ˆå¦‚ 0.1%ï¼‰ä¸‹ä»èƒ½ä¿æŒè‰¯å¥½è§†è§‰è´¨é‡ï¼Œå®šé‡æŒ‡æ ‡ï¼ˆMPSNRã€MSSIMï¼‰æ˜¾è‘—ä¼˜äºå¤šæ•°åŸºçº¿æ–¹æ³•ã€‚ |
| **æ³›åŒ–èƒ½åŠ›** | æ”¯æŒé‡åŒ–è§‚æµ‹åœºæ™¯ï¼Œåœ¨ä¸åŒå™ªå£°æ°´å¹³å’Œé‡åŒ–åˆ†è¾¨ç‡ä¸‹è¡¨ç°ç¨³å¥ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒæ¶µç›–å¤šç§çœŸå®ä¸–ç•Œçš„å¤§è§„æ¨¡å¤šç»´è§†è§‰æ•°æ®ï¼š
- **Color Images (CIs)**ï¼šMaastricht-Bassin, Wildpark ç­‰ï¼ˆ~3000Ã—4000Ã—3ï¼‰
- **Color Videos (CVs)**ï¼šRush-hour, Johnny ç­‰ï¼ˆ720Ã—1280Ã—3Ã—50ï¼‰
- **Multi-Temporal Remote Sensing Images (MRSIs)**ï¼šSPOT-53, Landsat-7 ç­‰ï¼ˆ1000Ã—1000Ã—4Ã—13ï¼‰
- **Hyperspectral Videos (HVs)**ï¼šMain5, Oranges1 ç­‰ï¼ˆ240Ã—240Ã—33Ã—31ï¼‰
- **Face Datasets**ï¼šExtended YaleFace Bï¼ˆ192Ã—168Ã—64Ã—38ï¼‰ã€UWA Hyperspectral Faceï¼ˆ256Ã—256Ã—30Ã—33ï¼‰
- **Cardiac MRIs**ï¼šsol-yxzt-part 1/2/8/30ï¼ˆ256Ã—256Ã—14Ã—20ï¼‰

æ‰€æœ‰åŸå§‹å¼ é‡å‡è¿›è¡Œäº†å½’ä¸€åŒ–å¤„ç†ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **ä»»åŠ¡ç±»å‹**ï¼š
  - å¼ é‡è¡¥å…¨ï¼ˆLRTCï¼‰
  - é²æ£’å¼ é‡è¡¥å…¨ï¼ˆRTCï¼‰
  - é‡åŒ–å¼ é‡æ¢å¤ï¼ˆQuantized Tensor Recoveryï¼‰
- **é‡‡æ ·ç‡ï¼ˆSRï¼‰**ï¼š0.1%, 0.3%, 0.5%, 1%, 3%, 5%
- **å™ªå£°è®¾ç½®**ï¼š
  - åŠ æ€§é«˜æ–¯å™ªå£°ï¼ˆSNR = 2dB / 3dBï¼‰
  - ç¨€ç–è„‰å†²å™ªå£°ï¼ˆNR = 0.1 / 0.5ï¼‰
  - é‡åŒ–å™ªå£°ï¼ˆUniform Scalar Quantizationï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **MPSNR**ï¼ˆMean Peak Signal-to-Noise Ratioï¼‰
  - **MSSIM**ï¼ˆMean Structural Similarity Indexï¼‰
  - **MRSE**ï¼ˆMean Relative Squared Errorï¼‰
  - **MTime**ï¼ˆMean CPU Time in secondsï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»åˆ« | å¯¹æ¯”æ–¹æ³• |
|------|--------|
| **åŸºäº TR/FCTN çš„æ–¹æ³•** | TRNNM, FCTN-NNM, FCTN-TC, FCTNFR |
| **åŸºäº T-SVD çš„æ–¹æ³•** | HTNN, WSTNN, METNN, OTNN, GTNN-HOC, t-e-LogDet |
| **å…¶ä»–å…ˆè¿›æ–¹æ³•** | TCTV-TC, MTTD, EMLCP-LRTC |
| **é²æ£’è¡¥å…¨æ–¹æ³•** | TTNN, TSPK, TTLRR, LNOP, NRTRM, HWTNN, HWTSN, R-HWTSN, BCNRTC |

æå‡ºçš„éšæœºåŠ é€Ÿç‰ˆæœ¬å‘½åä¸º **R1-FCTN-GNTC/GNRTC** å’Œ **R2-FCTN-GNTC/GNRTC**ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»£è¡¨æ€§ç»“æœæ‘˜å½•ï¼‰

#### è¡¨æ ¼ Iï¼šFace æ•°æ®é›†ä¸Šçš„å¼ é‡è¡¥å…¨ï¼ˆSR=1%ï¼‰
| æ–¹æ³• | MPSNR â†‘ | MSSIM â†‘ | MRSE â†“ | MTime â†“ |
|------|---------|---------|--------|---------|
| **R1-FCTN-GNTC** | **36.49** | **0.915** | **0.066** | 8086 |
| FCTN-TC | 34.04 | 0.889 | 0.099 | 34371 |
| TCTV-TC | 34.05 | 0.889 | 0.099 | 17020 |
| HTNN | 29.82 | 0.752 | 0.150 | 3502 |

> âœ… **MPSNR æå‡ ~2.5 dBï¼Œè¿è¡Œæ—¶é—´ä»…ä¸º FCTN-TC çš„ 23.5%**

#### è¡¨æ ¼ IIï¼šMRI æ•°æ®é›†ä¸Šçš„å¼ é‡è¡¥å…¨ï¼ˆSR=1%ï¼‰
| æ–¹æ³• | MPSNR â†‘ | MSSIM â†‘ | MRSE â†“ | MTime â†“ |
|------|---------|---------|--------|---------|
| **R2-FCTN-GNTC** | **32.06** | **0.858** | **0.239** | 2730 |
| FCTN-TC | 25.51 | 0.638 | 0.486 | 4574 |
| TCTV-TC | 29.24 | 0.838 | 0.322 | 8224 |
| WSTNN | 27.35 | 0.640 | 0.391 | 1703 |

> âœ… **MPSNR æå‡è¿‘ 7 dBï¼Œä¸”é€Ÿåº¦æ›´å¿«**

#### è¡¨æ ¼ IVï¼šMRSI ä¸Šçš„é²æ£’å¼ é‡è¡¥å…¨ï¼ˆSR=0.2, NR=1/3ï¼‰
| æ–¹æ³• | MPSNR â†‘ | MRSE â†“ | MTime â†“ |
|------|---------|--------|---------|
| **R1-FCTN-GNRTC** | **28.89** | **0.1386** | 3150.63 |
| FCTN-GNRTC (deterministic) | 28.41 | 0.1510 | 15397.15 |
| TCTV-RTC | 28.51 | 0.1643 | 4111.31 |

> âœ… **ç²¾åº¦æ›´é«˜ï¼ˆ+0.38 dBï¼‰ï¼Œé€Ÿåº¦æå‡çº¦ 4.9Ã—**

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **æ¢å¤è´¨é‡æ–¹é¢**ï¼š
  - åœ¨å‡ ä¹æ‰€æœ‰æ•°æ®é›†å’Œé‡‡æ ·ç‡ä¸‹ï¼Œæ‰€ææ–¹æ³•åœ¨ **MPSNR å’Œ MSSIM ä¸Šå–å¾—æœ€ä¼˜æˆ–æ¬¡ä¼˜ç»“æœ**ã€‚
  - ç‰¹åˆ«æ˜¯åœ¨ **æä½é‡‡æ ·ç‡ï¼ˆ<1%ï¼‰** ä¸‹ï¼Œä»èƒ½è¾ƒå¥½ä¿ç•™çº¹ç†ã€è¾¹ç¼˜å’Œé¢œè‰²ä¿¡æ¯ï¼Œè€Œå…¶ä»–æ–¹æ³•å‡ºç°ä¸¥é‡æ¨¡ç³Šæˆ–ä¼ªå½±ã€‚
- **è®¡ç®—æ•ˆç‡æ–¹é¢**ï¼š
  - éšæœºåŒ–ç‰ˆæœ¬ç›¸æ¯”ç¡®å®šæ€§ç‰ˆæœ¬å¹³å‡æé€Ÿ **9å€**ï¼Œæœ€é«˜å¯è¾¾ **20å€**ã€‚
  - åœ¨ MRSI æ¢å¤ä»»åŠ¡ä¸­ï¼Œéšæœºç‰ˆæœ¬æ¯”åŸç‰ˆå¿« **5~7å€**ï¼›åœ¨ CV ä»»åŠ¡ä¸­å¿« **~2.5å€**ã€‚
- **å¯è§†åŒ–æ•ˆæœ**ï¼š
  - å›¾ 1â€“6 æ˜¾ç¤ºï¼Œæœ¬æ–‡æ–¹æ³•åœ¨é¢éƒ¨ç»†èŠ‚ã€è¿åŠ¨ç»“æ„ã€é¥æ„Ÿåœ°ç‰©è¾¹ç•Œç­‰æ–¹é¢é‡å»ºæ›´æ¸…æ™°è‡ªç„¶ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆéšå«åˆ†æï¼‰
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»ä»¥ä¸‹å‡ ç‚¹å¯æ¨æ–­æ¨¡å—æœ‰æ•ˆæ€§ï¼š
- **å¼•å…¥ L+S æ­£åˆ™åŒ–**ï¼šç›¸æ¯”ä»…ç”¨ä½ç§©æ­£åˆ™çš„æ–¹æ³•ï¼ˆå¦‚ HTNNã€WSTNNï¼‰ï¼Œåœ¨ç›¸åŒæ¡ä»¶ä¸‹è·å¾—æ›´é«˜çš„ MPSNR å’Œæ›´ä½³è§†è§‰æ•ˆæœã€‚
- **éšæœºå‹ç¼©æœºåˆ¶**ï¼šå›¾ 3 æ˜¾ç¤ºï¼Œåœ¨å‡ ä¹ä¸æŸå¤± PSNR çš„å‰æä¸‹ï¼ŒCPU æ—¶é—´å¤§å¹…ä¸‹é™ï¼ŒéªŒè¯äº†å…¶é«˜æ•ˆæ€§ã€‚
- **é‡åŒ–å»ºæ¨¡èƒ½åŠ›**ï¼šå›¾ 7 å±•ç¤ºäº†åœ¨ä¸åŒé‡åŒ–æ­¥é•¿ Î´ ä¸‹çš„æ€§èƒ½å˜åŒ–è¶‹åŠ¿ï¼Œè¯æ˜æ¨¡å‹å¯¹é‡åŒ–å™ªå£°å…·æœ‰åˆç†é²æ£’æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **FCTN-GNTCTV èƒ½æœ‰æ•ˆè”åˆå»ºæ¨¡ L+S å…ˆéªŒ**ï¼Œæ˜¾è‘—æå‡å¤šç»´è§†è§‰æ•°æ®çš„æ¢å¤è´¨é‡ï¼Œå°¤å…¶é€‚ç”¨äºå…·æœ‰å¼ºå†—ä½™å’Œè¿ç»­æ€§çš„å›¾åƒ/è§†é¢‘æ•°æ®ã€‚
2. **éšæœº sketching æŠ€æœ¯æ˜¯è§£å†³å¤§è§„æ¨¡å¼ é‡è®¡ç®—ç“¶é¢ˆçš„æœ‰æ•ˆé€”å¾„**ï¼Œå¯åœ¨å‡ ä¹æ— ç²¾åº¦æŸå¤±çš„æƒ…å†µä¸‹å®ç°æ•°é‡çº§çš„é€Ÿåº¦æå‡ã€‚
3. **å°†æ¨¡å‹ä»éé‡åŒ–æ¨å¹¿è‡³é‡åŒ–è§‚æµ‹**å¢å¼ºäº†å®ç”¨æ€§ï¼Œä¸ºéƒ¨ç½²äºèµ„æºå—é™è®¾å¤‡æä¾›äº†ç†è®ºæ”¯æŒã€‚
4. æ‰€ææ¡†æ¶åœ¨å¤šç§çœŸå®æ•°æ®é›†ä¸Šå®ç°äº†**ç²¾åº¦ä¸æ•ˆç‡çš„åŒé‡é¢†å…ˆ**ï¼ŒéªŒè¯äº†å…¶é€šç”¨æ€§å’Œä¼˜è¶Šæ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **å‚æ•°æ•æ„Ÿæ€§**ï¼šéå‡¸å‡½æ•°é€‰æ‹©ã€æ­£åˆ™åŒ–å‚æ•° Î»â‚ã€Î»â‚‚ã€é‡åŒ–æ­¥é•¿ Î´ ç­‰éœ€æ‰‹åŠ¨è°ƒå‚ï¼Œç¼ºä¹è‡ªåŠ¨è°ƒèŠ‚æœºåˆ¶ã€‚
- **ç¡¬ä»¶ä¾èµ–**ï¼šå°½ç®¡å·²åŠ é€Ÿï¼Œä½†åœ¨è¶…å¤§è§„æ¨¡å¼ é‡ï¼ˆå¦‚ 10KÃ—10KÃ—100ï¼‰ä¸Šä»å¯èƒ½å—é™äºå†…å­˜å¸¦å®½ã€‚
- **ç†è®ºä¿è¯æœ‰é™**ï¼šè™½ç„¶ç»™å‡ºäº†è¯¯å·®ä¸Šç•Œå’Œæ”¶æ•›æ€§åˆ†æï¼Œä½†å¯¹éå‡¸ä¼˜åŒ–éƒ¨åˆ†çš„å…¨å±€æœ€ä¼˜æ€§ç¼ºä¹ä¸¥æ ¼è¯æ˜ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† **Tensor æ–¹æ³• + Quantization + Randomized Sketching + Deep Learning** ç›¸ç»“åˆï¼Œæ¢ç´¢æ›´å¿«é€Ÿã€è‡ªé€‚åº”çš„ç«¯åˆ°ç«¯æ¢å¤ç½‘ç»œã€‚
- ç ”ç©¶é¢å‘è¾¹ç¼˜è®¡ç®—çš„è½»é‡åŒ–å¼ é‡æ¢å¤æ¶æ„ï¼Œè¿›ä¸€æ­¥é™ä½åŠŸè€—ä¸å»¶è¿Ÿã€‚
- æ¢ç´¢åŠ¨æ€é‡‡æ ·ç­–ç•¥ä¸ä¸»åŠ¨å­¦ä¹ æœºåˆ¶ï¼Œæå‡æä½é‡‡æ ·æ¡ä»¶ä¸‹çš„æ¢å¤èƒ½åŠ›ã€‚

--- 

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡ºäº†ä¸€ç§**å…¼å…·é«˜ç²¾åº¦ä¸é«˜æ•ˆç‡**çš„å¤§è§„æ¨¡å¤šç»´è§†è§‰æ•°æ®æ¢å¤æ¡†æ¶ï¼Œé€šè¿‡**å°ºåº¦æ„ŸçŸ¥çš„å¼ é‡å»ºæ¨¡**ä¸**åŠ é€Ÿçš„éšæœºè®¡ç®—**ï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•åœ¨å»ºæ¨¡èƒ½åŠ›å’Œè®¡ç®—æˆæœ¬ä¹‹é—´çš„æƒè¡¡éš¾é¢˜ï¼Œåœ¨å¤šä¸ªçœŸå®åœºæ™¯ä¸­å±•ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚

</details>

---

### 6. [Wireless TokenCom: RL-Based Tokenizer Agreement for Multi-User Wireless Token Communications](https://arxiv.org/abs/2602.12338)

**Authors**: Farshad Zeinali, Mahdi Boloursaz Mashhadi, Dusit Niyato, Rahim Tafazolli  
**Category**: cs.LG  
**Published**: 2026-02-16  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.12338v1  

#### Abstract
Token Communications (TokenCom) has recently emerged as an effective new paradigm, where tokens are the unified units of multimodal communications and computations, enabling efficient digital semantic- and goal-oriented communications in future wireless networks. To establish a shared semantic laten...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Wireless TokenCom: RL-Based Tokenizer Agreement for Multi-User Wireless Token Communications*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹**å¤šç”¨æˆ·æ— çº¿ Token Communicationsï¼ˆTokenComï¼‰ç³»ç»Ÿä¸­çš„ Tokenizer Agreementï¼ˆTAï¼‰é—®é¢˜**æå‡ºè§£å†³æ–¹æ¡ˆã€‚åœ¨ TokenCom ä¸­ï¼Œå‘é€ç«¯å’Œæ¥æ”¶ç«¯éœ€å°±ç»Ÿä¸€çš„ tokenizer æ¨¡å‹å’Œ codebook è¾¾æˆä¸€è‡´ï¼Œä»¥å»ºç«‹å…±äº«çš„è¯­ä¹‰éšç©ºé—´ï¼ˆsemantic latent spaceï¼‰ã€‚ç„¶è€Œï¼Œåœ¨åŠ¨æ€å˜åŒ–çš„å¤šç”¨æˆ·æ— çº¿ç¯å¢ƒä¸­ï¼Œå¦‚ä½•è‡ªé€‚åº”åœ°é€‰æ‹©æœ€ä¼˜ tokenizerï¼Œå¹¶è”åˆä¼˜åŒ–å­ä¿¡é“åˆ†é…ã€æ³¢æŸæˆå½¢ï¼ˆbeamformingï¼‰å’Œèµ„æºåˆ†é…ï¼Œæ˜¯ä¸€ä¸ªé«˜åº¦å¤æ‚çš„æ··åˆæ•´æ•°éå‡¸ä¼˜åŒ–é—®é¢˜ã€‚

ä¼ ç»Ÿä¼˜åŒ–æ–¹æ³•å› è®¡ç®—å¤æ‚åº¦é«˜ã€éš¾ä»¥åº”å¯¹åŠ¨æ€ç¯å¢ƒè€Œå—é™ï¼Œä¸”ç°æœ‰åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„ç ”ç©¶å¤šé›†ä¸­äºå•ç”¨æˆ·ã€å°æ¨¡å‹çš„è¯­ä¹‰é€šä¿¡ï¼ˆSemComï¼‰ï¼Œæœªè€ƒè™‘ TokenCom æ‰€éœ€çš„**è‡ªé€‚åº” tokenizer åå•†æœºåˆ¶**ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
1. **é¦–æ¬¡ç ”ç©¶å¤šç”¨æˆ·æ— çº¿è§†é¢‘ TokenCom åœºæ™¯ä¸‹çš„è‡ªé€‚åº” TA é—®é¢˜**  
   - æ˜ç¡®å»ºæ¨¡äº†è”åˆ **Tokenizer Agreementï¼ˆTAï¼‰ã€å­ä¿¡é“åˆ†é…ã€æ³¢æŸæˆå½¢ä¸èµ„æºåˆ†é…** çš„æ··åˆæ•´æ•°éå‡¸ä¼˜åŒ–é—®é¢˜ã€‚

2. **æå‡ºä¸€ç§æ–°å‹æ··åˆå¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼šHybrid DQN-DDPG**
   - **DQN åˆ†æ”¯**ï¼šå¤„ç†ç¦»æ•£åŠ¨ä½œç©ºé—´ï¼Œç”¨äºè”åˆå†³ç­– tokenizer é€‰æ‹©å’Œå­ä¿¡é“ï¼ˆRBï¼‰åˆ†é…ã€‚
   - **DDPG åˆ†æ”¯**ï¼šå¤„ç†è¿ç»­åŠ¨ä½œç©ºé—´ï¼Œç”Ÿæˆæ³¢æŸæˆå½¢å‘é‡ $ \mathbf{w}[l] $ã€‚
   - é€šè¿‡åŒç»éªŒå›æ”¾ç¼“å†²åŒºï¼ˆreplay bufferï¼‰ç‹¬ç«‹è®­ç»ƒä¸¤ä¸ªä»£ç†ï¼Œå®ç°å¯¹æ··åˆåŠ¨ä½œç©ºé—´çš„æœ‰æ•ˆå­¦ä¹ ã€‚

3. **è®¾è®¡ç«¯åˆ°ç«¯çš„ Markov å†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰å»ºæ¨¡**
   - çŠ¶æ€ç©ºé—´åŒ…å«ä¿¡é“çŠ¶æ€ã€åŠŸç‡ã€å‹ç¼©ç‡ç­‰ï¼›
   - å¥–åŠ±å‡½æ•°åŸºäºç³»ç»Ÿæ•ˆç”¨å‡½æ•°ï¼ˆsystem utilityï¼‰ï¼Œå¹¶å¼•å…¥çº¦æŸè¿åæƒ©ç½šé¡¹ï¼Œæå‡å¯è¡Œæ€§ã€‚

4. **æ”¯æŒå¯æ‰©å±•çš„å¤šç”¨æˆ·åœºæ™¯**
   - è™½ç„¶ç®—æ³•å¤æ‚åº¦éšç”¨æˆ·æ•°ã€å¤©çº¿æ•°å¢åŠ è€Œä¸Šå‡ï¼Œä½†å‡è®¾åŸºç«™å…·å¤‡è¶³å¤Ÿç®—åŠ›æ”¯æ’‘å¤§è§„æ¨¡éƒ¨ç½²ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | æœ¬å·¥ä½œä¼˜åŠ¿ |
|------|-----------|
| **é—®é¢˜å»ºæ¨¡** | é¦–æ¬¡å°† TA å¼•å…¥å¤šç”¨æˆ·æ— çº¿ TokenComï¼Œå¡«è¡¥äº† LAM/MLLM é©±åŠ¨é€šä¿¡ä¸­è‡ªé€‚åº” tokenizer é€‰æ‹©çš„ç ”ç©¶ç©ºç™½ |
| **æ–¹æ³•è®¾è®¡** | Hybrid DQN-DDPG å¯é«˜æ•ˆå¤„ç†æ··åˆç¦»æ•£-è¿ç»­åŠ¨ä½œç©ºé—´ï¼Œä¼˜äºçº¯ DDPG å¯¹ç¦»æ•£å˜é‡çš„ä½æ•ˆç¼–ç  |
| **é€‚åº”æ€§** | æ”¯æŒåŠ¨æ€ä¿¡é“æ¡ä»¶ä¸å¼‚æ„ç”¨æˆ·éœ€æ±‚ï¼Œå®ç°ä¸ªæ€§åŒ– tokenizer åŒ¹é… |
| **æ€§èƒ½è¡¨ç°** | åœ¨è¯­ä¹‰è´¨é‡ã€èµ„æºæ•ˆç‡ã€è§†é¢‘æµç•…æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ¡ˆ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- ä½¿ç”¨ **DAVIS è§†é¢‘æ•°æ®é›†** è¿›è¡Œè¯„ä¼°ã€‚
- è§†é¢‘å¸§ç‡ $ p = 24 $ fpsã€‚
- åˆ†è¾¨ç‡èŒƒå›´ä» 360p åˆ° 1080pï¼ˆ1920Ã—1080ï¼‰ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
| å‚æ•° | è®¾ç½®å€¼ |
|------|--------|
| åŸºç«™å¤©çº¿æ•° $ N $ | 32 / 64 |
| ç”¨æˆ·æ•° $ U $ | 4 / 16 |
| å­è½½æ³¢å¸¦å®½ $ B $ | 30 kHzï¼ˆç¬¦åˆ 5G NR æ ‡å‡†ï¼‰ |
| èµ„æºå—æ•°é‡ $ R $ | 16 |
| æ¯ä¸ªæ—¶éš™æœ€å¤šæœåŠ¡ç”¨æˆ·æ•° $ K $ | 2 |
| æ€»å‘å°„åŠŸç‡ $ P_{\text{BS}} $ | 30 dBm |
| æœ€å°æ•°æ®é€Ÿç‡è¦æ±‚ $ R_{\min} $ | 1 Mbps |
| ä»¿çœŸè½®æ¬¡ | 500 episodes |
| æ¯è½®æ­¥æ•° | 100 steps |

#### Tokenizer é…ç½®ï¼ˆå…± 4 ç§é¢„è®­ç»ƒæ¨¡å‹ï¼‰
| Tokenizer Model | bpp | PSNR â†‘ | SSIM â†‘ | rFVD â†“ |
|------------------|-----|--------|--------|--------|
| Cosmos-0.1-DV8Ã—16Ã—16 | 0.008 | 25.09 | 0.714 | 241.52 |
| Cosmos-0.1-DV4Ã—8Ã—8 | 0.063 | 28.81 | 0.818 | 37.36 |
| HEVC medium | 0.084 | 33.21 | 0.856 | 25.16 |
| BSQ-VAE | 0.127 | 38.41 | 0.920 | 10.057 |

> æ³¨ï¼šä¸åŒ tokenizer æä¾›ä¸åŒçš„ rate-distortion/perception æƒè¡¡ã€‚

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
1. **è§†é¢‘å†»ç»“ç‡ï¼ˆFreezing Rate, %ï¼‰**  
   - å®šä¹‰ä¸ºï¼šå½“ç”¨æˆ·å®é™…ä¼ è¾“é€Ÿç‡ä½äºå…¶ tokenizer æ‰€éœ€ç ç‡æ—¶å‘ç”Ÿçš„â€œå¡é¡¿â€äº‹ä»¶æ¯”ä¾‹ã€‚
2. **å¹³å‡ PSNRï¼ˆPeak Signal-to-Noise Ratioï¼‰**  
   - è¡¡é‡è§†é¢‘é‡å»ºè´¨é‡ã€‚
3. **ç³»ç»Ÿæ•ˆç”¨ï¼ˆSystem Utilityï¼‰**  
   - ç»¼åˆè€ƒè™‘è¯­ä¹‰è´¨é‡å’Œèµ„æºæ¶ˆè€—ï¼š$ U_t = \sum_i (\alpha q_i - \beta R_i^{\text{sum}}) $

---

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
1. **DDPG-TA**ï¼šä½¿ç”¨æ ‡å‡† DDPG å¤„ç†æ‰€æœ‰åŠ¨ä½œï¼ˆåŒ…æ‹¬ç¦»æ•£ tokenizer é€‰æ‹©ï¼‰ï¼Œè¾“å‡ºç»ç¦»æ•£åŒ–ã€‚
2. **Agnostic-TA**ï¼šæ‰€æœ‰ç”¨æˆ·å¼ºåˆ¶ä½¿ç”¨ç›¸åŒ tokenizerï¼Œå¿½ç•¥ä¿¡é“å¼‚è´¨æ€§ã€‚
3. **Fixed-TA**ï¼šå›ºå®šä½¿ç”¨æŸä¸€ tokenizerï¼Œæ— è‡ªé€‚åº”èƒ½åŠ›ã€‚
4. **Conventionalï¼ˆH.265ï¼‰**ï¼šä¼ ç»Ÿæ•°å­—é€šä¿¡åŸºå‡†ï¼Œé‡‡ç”¨ H.265 ç¼–ç  + DQN-DDPG èµ„æºè°ƒåº¦ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

#### âœ… è§†é¢‘å†»ç»“ç‡é™ä½
- åœ¨ $ U=16 $ã€1080p é«˜æ¸…è§†é¢‘ä¸‹ï¼š
  - **ç›¸æ¯” H.265 åŸºçº¿ï¼Œå†»ç»“ç‡ä¸‹é™çº¦ 68%**ã€‚
  - Proposed-TA å†»ç»“ç‡ç¨³å®šåœ¨è¾ƒä½æ°´å¹³ï¼ˆ<10%ï¼‰ï¼Œè€Œ Fixed-TA å’Œ Agnostic-TA å‡ºç°æ˜æ˜¾æ³¢åŠ¨ã€‚

#### âœ… PSNR æå‡æ˜¾è‘—
- åœ¨ $ U=4, N=64 $ æ¡ä»¶ä¸‹ï¼š
  - Proposed-TA å¹³å‡ PSNR æ¯” H.265 åŸºçº¿é«˜å‡ºçº¦ **10 dB**ã€‚
- éšç€ç”¨æˆ·æ•°å¢åŠ ï¼ˆ4â†’16ï¼‰ï¼ŒPSNR ä¸‹é™è¶‹åŠ¿å¹³ç¼“ï¼Œæ˜¾ç¤ºè‰¯å¥½å¯æ‰©å±•æ€§ã€‚

#### âœ… åŠ¨æ€é€‚åº”èƒ½åŠ›å¼º
- éšç€åŸºç«™å‘å°„åŠŸç‡æå‡ï¼Œæ‰€æœ‰æ–¹æ³• PSNR ä¸Šå‡ï¼Œä½† Proposed-TA å¢é•¿æœ€å¿«ï¼Œè¡¨æ˜å…¶èƒ½æ›´æœ‰æ•ˆåˆ©ç”¨å¯Œä½™èµ„æºæå‡è¯­ä¹‰è´¨é‡ã€‚

---

### ğŸ†š ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœï¼ˆç»¼åˆï¼‰

| æ–¹æ³• | å†»ç»“ç‡ | PSNR | è‡ªé€‚åº”æ€§ | èµ„æºæ•ˆç‡ |
|------|--------|------|----------|----------|
| **Proposed-TA (DQN-DDPG)** | âœ… æœ€ä½ï¼ˆâ†“68% vs H.265ï¼‰ | âœ… æœ€é«˜ï¼ˆ+~10dB vs H.265ï¼‰ | âœ… å¼º | âœ… é«˜ |
| DDPG-TA | âŒ è¾ƒé«˜ï¼ˆç¦»æ•£åŠ¨ä½œå¤„ç†å·®ï¼‰ | âŒ æ¬¡ä¼˜ | âš ï¸ ä¸€èˆ¬ | âš ï¸ ä¸€èˆ¬ |
| Agnostic-TA | âŒ é«˜ï¼ˆæ— æ³•åŒ¹é…å¼‚æ„ä¿¡é“ï¼‰ | âŒ ä¸­ç­‰ | âŒ å¼± | âŒ ä½ |
| Fixed-TA | âŒ æé«˜ä¸”æŒ¯è¡ | âŒ å›ºå®šï¼ˆä¿å®ˆç­–ç•¥ï¼‰ | âŒ æ—  | âŒ ä½ |
| Conventional (H.265) | âŒ é«˜ | âŒ æœ€ä½ | âŒ æ— è¯­ä¹‰é€‚é… | âŒ ä½ |

> å›¾1(a)-(d) æ˜¾ç¤º Proposed-TA åœ¨è®­ç»ƒåˆæœŸå¿«é€Ÿæ”¶æ•›ï¼ŒåæœŸä¿æŒç¨³å®šé«˜æ€§èƒ½ã€‚

---

### ğŸ” æ¶ˆèå®éªŒåˆ†æï¼ˆéšå«äºå¯¹æ¯”ä¸­ï¼‰
è™½ç„¶æ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºâ€œablation studyâ€ç« èŠ‚ï¼Œä½†ä»ä»¥ä¸‹å¯¹æ¯”å¯æ¨æ–­å…³é”®ç»„ä»¶ä½œç”¨ï¼š

| ç»„ä»¶ | å½±å“åˆ†æ |
|------|---------|
| **Hybrid DQN-DDPG æ¶æ„** | æ˜¾è‘—ä¼˜äº DDPG-TA â†’ è¯´æ˜åˆ†ç¦»å¤„ç†ç¦»æ•£/è¿ç»­åŠ¨ä½œæ›´é«˜æ•ˆ |
| **è‡ªé€‚åº” TA æœºåˆ¶** | æ˜¾è‘—ä¼˜äº Fixed/Agnostic-TA â†’ è¯æ˜ TA å¯¹æ€§èƒ½è‡³å…³é‡è¦ |
| **è”åˆä¼˜åŒ–è®¾è®¡** | æ•´ä½“æ•ˆç”¨æœ€å¤§åŒ– â†’ è¡¨æ˜èµ„æºåˆ†é…ä¸ TA ååŒå¢ç›Šæ˜æ˜¾ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Tokenizer Agreement æ˜¯ TokenCom æˆåŠŸçš„å…³é”®å‰æ**ï¼Œå¿…é¡»æ ¹æ®ä¿¡é“çŠ¶æ€å’Œç”¨æˆ·éœ€æ±‚åŠ¨æ€åå•†ã€‚
2. **Hybrid DQN-DDPG æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆè§£å†³æ··åˆåŠ¨ä½œç©ºé—´ä¸‹çš„è”åˆä¼˜åŒ–é—®é¢˜**ï¼Œåœ¨å¤šç”¨æˆ·åœºæ™¯ä¸­è¡¨ç°å‡ºè‰²ã€‚
3. **TokenCom æ˜¾è‘—ä¼˜äºä¼ ç»Ÿ H.265 æ•°å­—é€šä¿¡**ï¼š
   - åœ¨ç›¸åŒèµ„æºä¸‹æä¾›æ›´é«˜è¯­ä¹‰è´¨é‡ï¼ˆâ†‘PSNRï¼‰ï¼›
   - å¤§å¹…å‡å°‘è§†é¢‘å†»ç»“äº‹ä»¶ï¼ˆâ†“68%ï¼‰ï¼›
   - æ›´å¥½åœ°å¹³è¡¡èµ„æºå¼€é”€ä¸æ„ŸçŸ¥è´¨é‡ã€‚
4. **ç³»ç»Ÿå…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§å’Œé²æ£’æ€§**ï¼Œå³ä½¿ç”¨æˆ·æ•°ç¿»å››å€ï¼ˆ4â†’16ï¼‰ï¼Œæ€§èƒ½ä¸‹é™æœ‰é™ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–é¢„è®­ç»ƒ tokenizer åº“çš„å­˜åœ¨**  
   - å‡è®¾ BS å’Œç”¨æˆ·å‡å·²é¢„è£…æˆ–ç¼“å­˜å…¼å®¹çš„ tokenizer/de-tokenizer å¯¹ï¼Œç°å®ä¸­å¯èƒ½é¢ä¸´å­˜å‚¨ä¸æ›´æ–°æŒ‘æˆ˜ã€‚
2. **é›†ä¸­å¼æ¶æ„é™åˆ¶è¾¹ç¼˜éƒ¨ç½²**  
   - æ‰€æœ‰å†³ç­–ç”± BS å®Œæˆï¼Œå¯¹åŸºç«™ç®—åŠ›è¦æ±‚é«˜ï¼Œä¸åˆ©äºè¶…å¤§è§„æ¨¡ç½‘ç»œæˆ–å»ä¸­å¿ƒåŒ–åœºæ™¯ã€‚
3. **æœªè€ƒè™‘æ¨¡å‹æ¨ç†å»¶è¿Ÿä¸èƒ½è€—**  
   - å½“å‰æ•ˆç”¨å‡½æ•°æœªåŒ…å«è§£ç ç«¯è®¡ç®—æˆæœ¬ï¼Œæœªæ¥éœ€çº³å…¥ç«¯ä¾§è®¾å¤‡èƒ½åŠ›çº¦æŸã€‚
4. **ä»…éªŒè¯è§†é¢‘æ¨¡æ€**  
   - å°½ç®¡ä½œè€…æŒ‡å‡ºæ¡†æ¶å¯æ‰©å±•è‡³å›¾åƒã€éŸ³é¢‘ç­‰ï¼Œä½†å®éªŒä»…é™è§†é¢‘ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **åˆ†å¸ƒå¼ TA æœºåˆ¶è®¾è®¡**  
   - æ¢ç´¢è”é‚¦å­¦ä¹ æˆ–å…±è¯†åè®®å®ç°å»ä¸­å¿ƒåŒ–çš„ tokenizer åå•†ã€‚
2. **è·¨æ¨¡æ€ TokenCom æ‰©å±•**  
   - æ”¯æŒæ–‡æœ¬ã€å›¾åƒã€è¯­éŸ³ç­‰å¤šæ¨¡æ€ä¿¡å·çš„ç»Ÿä¸€ token ä¼ è¾“ã€‚
3. **è½»é‡åŒ– tokenizer è®¾è®¡**  
   - å¼€å‘é€‚ç”¨äºç§»åŠ¨ç»ˆç«¯çš„å°å‹ tokenizer æ¨¡å‹ï¼Œé™ä½éƒ¨ç½²é—¨æ§›ã€‚
4. **ç«¯åˆ°ç«¯è”åˆè®­ç»ƒ tokenizer ä¸é€šä¿¡ç­–ç•¥**  
   - å½“å‰ tokenizer å›ºå®šï¼Œæœªæ¥å¯æ¢ç´¢ joint optimization of tokenizer å’Œæ— çº¿ç­–ç•¥ã€‚
5. **çœŸå®ä¿¡é“ä¸ç¡¬ä»¶å¹³å°éªŒè¯**  
   - åœ¨ testbed æˆ– real-world channel traces ä¸Šè¿›ä¸€æ­¥éªŒè¯æ³›åŒ–èƒ½åŠ›ã€‚

---

## æ€»ç»“
è¯¥è®ºæ–‡å¼€åˆ›æ€§åœ°æå‡ºäº†é¢å‘å¤šç”¨æˆ·æ— çº¿ TokenCom çš„è‡ªé€‚åº” **Tokenizer Agreement** æ¡†æ¶ï¼Œç»“åˆ **Hybrid DQN-DDPG** å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œå®ç°äº†è¯­ä¹‰è´¨é‡ä¸èµ„æºæ•ˆç‡çš„ååŒä¼˜åŒ–ã€‚å®éªŒè¯æ˜å…¶åœ¨ **PSNRã€å†»ç»“ç‡ã€å¯æ‰©å±•æ€§** ç­‰æ–¹é¢å…¨é¢è¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œä¸ºä¸‹ä¸€ä»£ AI é©±åŠ¨çš„è¯­ä¹‰é€šä¿¡ç³»ç»Ÿæä¾›äº†é‡è¦æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 7. [Dual-Granularity Contrastive Reward via Generated Episodic Guidance for Efficient Embodied RL](https://arxiv.org/abs/2602.12636)

**Authors**: Xin Liu, Yixuan Li, Yuhui Chen, Yuxing Qin, Haoran Li, Dongbin Zhao  
**Category**: cs.LG  
**Published**: 2026-02-16  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.12636v1  

#### Abstract
Designing suitable rewards poses a significant challenge in reinforcement learning (RL), especially for embodied manipulation. Trajectory success rewards are suitable for human judges or model fitting, but the sparsity severely limits RL sample efficiency. While recent methods have effectively impro...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**Dual-Granularity Contrastive Reward via Generated Episodic Guidance for Efficient Embodied RL**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³äº†ä»€ä¹ˆé—®é¢˜

åœ¨ **Embodied RL**ï¼ˆå…·èº«å¼ºåŒ–å­¦ä¹ ï¼‰ä¸­ï¼Œè®¾è®¡æœ‰æ•ˆçš„å¥–åŠ±å‡½æ•°æ˜¯æ ¸å¿ƒæŒ‘æˆ˜ä¹‹ä¸€ã€‚ä¼ ç»Ÿæ–¹æ³•é¢ä¸´ä»¥ä¸‹ç“¶é¢ˆï¼š

- **Sparse success rewards**ï¼ˆç¨€ç–æˆåŠŸå¥–åŠ±ï¼‰è™½ç„¶æ˜“äºå®šä¹‰ï¼Œä½†ä¸¥é‡é™åˆ¶äº† RL çš„æ ·æœ¬æ•ˆç‡ã€‚
- ç°æœ‰çš„ **dense reward** è®¾è®¡æ–¹æ³•ä¾èµ–å¤§é‡é«˜è´¨é‡ä¸“å®¶æ¼”ç¤ºï¼ˆexpert demonstrationsï¼‰æˆ–äººå·¥æ ‡æ³¨æ•°æ®ï¼Œæˆæœ¬é«˜æ˜‚ä¸”éš¾ä»¥æ‰©å±•ã€‚

æœ¬æ–‡æ—¨åœ¨è§£å†³ï¼š**å¦‚ä½•åœ¨æå°‘ä¸“å®¶è§†é¢‘ã€æ— éœ€äººå·¥æ ‡æ³¨çš„å‰æä¸‹ï¼Œå®ç°é«˜æ•ˆçš„ dense reward è®¾è®¡ï¼Œä»è€Œæå‡ RL çš„æ ·æœ¬æ•ˆç‡å’Œç­–ç•¥æ”¶æ•›èƒ½åŠ›ï¼Ÿ**

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šDEGï¼ˆDual-granularity contrastive reward via generated Episodic Guidanceï¼‰

æå‡ºäº†ä¸€ç§å…¨æ–°çš„æ¡†æ¶ **DEG**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

1. **åˆ©ç”¨å¤§æ¨¡å‹å…ˆéªŒçŸ¥è¯†ç”Ÿæˆ episodic guidance**  
   - ä½¿ç”¨ä¸€ä¸ªå¼€æºçš„ **video generation model**ï¼ˆå¦‚ Wan2.1-I2V-14Bï¼‰ï¼Œä»…ç”¨ **3â€“5ä¸ªä¸“å®¶è§†é¢‘** è¿›è¡Œå¾®è°ƒï¼ˆvia LoRAï¼‰ï¼Œä½¿å…¶é€‚åº”ç›®æ ‡ä»»åŠ¡çš„åŠ¨åŠ›å­¦ç‰¹æ€§ã€‚
   - åœ¨æ¯ä¸ª RL episode ä¸­ï¼Œè¯¥æ¨¡å‹æ ¹æ®å½“å‰åˆå§‹çŠ¶æ€ç”Ÿæˆä¸€æ¡ä¸“å±çš„ **task guidance video**ï¼Œä½œä¸ºæ™ºèƒ½ä½“çš„å­¦ä¹ ç›®æ ‡ã€‚

2. **æ„å»ºåŒç²’åº¦å¯¹æ¯”å¥–åŠ±ï¼ˆDual-granularity contrastive rewardï¼‰**
   - åœ¨è‡ªç›‘ç£çš„ latent space ä¸­ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ å¯¹é½çœŸå®è§‚æµ‹ä¸ç”Ÿæˆè§†é¢‘ã€‚
   - å¥–åŠ±åˆ†ä¸ºä¸¤ä¸ªå±‚æ¬¡ï¼š
     - **Coarse-grained exploration reward**ï¼šé¼“åŠ±ç²—ç•¥åœ°æŒ‰é¡ºåºæ¨¡ä»¿æŒ‡å¯¼è§†é¢‘çš„åŠ¨ä½œè½¨è¿¹ï¼Œæå‡æ¢ç´¢æ•ˆç‡ã€‚
     - **Fine-grained matching reward**ï¼šå¯¹ç²¾ç¡®åŒ¹é…å…³é”®å¸§ï¼ˆå¦‚æŠ“å–ã€æ—‹è½¬ç­‰ç²¾ç»†æ“ä½œï¼‰ç»™äºˆé«˜å¥–åŠ±ï¼Œç¡®ä¿åŠ¨ä½œç²¾åº¦ã€‚

3. **å®Œå…¨æ— éœ€äººå·¥æ ‡æ³¨æˆ–å¯†é›†ç›‘ç£**
   - æ•´ä¸ªæµç¨‹ä¸ä¾èµ–äººå·¥è®¾è®¡çš„ reward å‡½æ•°ã€è¯­è¨€æè¿°æˆ–å¤šè§†è§’ä¸“å®¶æ•°æ®ã€‚

---

### â­ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | DEG | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ TeViR, RoboCLIP, VIPERï¼‰ |
|------|-----|-------------------------------|
| æ•°æ®éœ€æ±‚ | ä»…éœ€ **3â€“5 å•è§†è§’ä¸“å®¶è§†é¢‘** | éœ€è¦æ•°åç”šè‡³ä¸Šç™¾è§†é¢‘ + å¤šè§†è§’ |
| æ˜¯å¦éœ€è¦äººå·¥æ ‡æ³¨ | âŒ ä¸éœ€è¦ | âœ… å¤šæ•°éœ€è¦è¯­è¨€æŒ‡ä»¤æˆ–çŠ¶æ€æ ‡ç­¾ |
| å¥–åŠ±å¯†åº¦ | è‡ªåŠ¨ç”Ÿæˆ dense reward | ä¾èµ–é¢„è®­ç»ƒ reward model æˆ–æ‰‹å·¥è®¾è®¡ |
| æ³›åŒ–èƒ½åŠ› | åˆ©ç”¨ç”Ÿæˆæ¨¡å‹é€‚åº”å¤šæ ·åŒ–åˆå§‹çŠ¶æ€ | å¤šåŸºäºå›ºå®šè½¨è¿¹æˆ–é™æ€ç›®æ ‡ |
| æ ·æœ¬æ•ˆç‡ | æ˜¾è‘—æ›´é«˜ï¼ˆè§å®éªŒï¼‰ | å—é™äºç¨€ç–åé¦ˆæˆ–å™ªå£°å¥–åŠ± |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿**ï¼šä»¥æä½çš„æ•°æ®æˆæœ¬å®ç°äº†åª²ç¾ç”šè‡³è¶…è¶Šäººç±»ä¸“å®¶è®¾è®¡ dense reward çš„æ€§èƒ½ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†

- **Simulation Tasks**ï¼šæ¥è‡ª **MetaWorld** çš„ **16 ä¸ª manipulation ä»»åŠ¡**ï¼ŒåŒ…æ‹¬ï¼š
  - `drawer-open`, `plate-slide`, `hammer`, `assembly`, `door-close` ç­‰ã€‚
  - è¦†ç›–äº†æœºæ¢°è‡‚æ“ä½œä¸­çš„æ¨ã€æ‹‰ã€æ—‹è½¬ã€å †å ç­‰å¤šç§å¤æ‚äº¤äº’ã€‚
- **Real-world Tasks**ï¼šåœ¨ç‰©ç† **Franka æœºæ¢°è‡‚** ä¸Šè¿›è¡Œä¸¤ä¸ªé•¿ç¨‹ä»»åŠ¡ï¼š
  - `pick banana`ï¼šä»éšæœºä½ç½®æŠ“å–é¦™è•‰å¹¶æ”¾å…¥ç›˜å­ã€‚
  - `stack cube`ï¼šå°†å°çº¢æ–¹å—å †å åˆ°å¤§æœ¨å—ä¸Šã€‚

---

### ğŸ”§ å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

| è®¾ç½®é¡¹ | å†…å®¹ |
|-------|------|
| **Backbone RL Algorithm** | DrQv2ï¼ˆsimï¼‰ã€HIL-SERLï¼ˆreal-worldï¼‰ |
| **è®­ç»ƒæ­¥æ•°** | Sim: 500k stepsï¼›Real: æœ€å¤š 25k steps |
| **è¯„ä¼°æŒ‡æ ‡** | - æˆåŠŸç‡ï¼ˆsuccess rateï¼‰<br>- å­¦ä¹ æ›²çº¿ï¼ˆtraining curveï¼‰<br>- å¹²é¢„æ¬¡æ•°ï¼ˆintervention stepsï¼Œreal-worldï¼‰ |
| **DEG è¾“å…¥** | ä»… 3â€“5 æ¡ä¸“å®¶è§†é¢‘ï¼ˆæ— æ ‡æ³¨ï¼‰ |
| **Reward ç±»å‹å¯¹æ¯”** | - Sparse success reward<br>- Expert-designed dense reward<br>- DEGï¼ˆç‹¬ç«‹ä½¿ç”¨ï¼‰<br>- DEG+ï¼ˆç»“åˆ sparse rewardï¼‰ |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”

| åŸºçº¿æ–¹æ³• | ç®€ä»‹ |
|--------|------|
| **TeViR** | åŸºäºæ–‡æœ¬åˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¤šè§†è§’è½¨è¿¹ä½œä¸ºå¥–åŠ±ï¼Œéœ€ 60+ è§†é¢‘ + ä¸‰æ‘„åƒå¤´è§†è§’ |
| **Diffusion Reward** | ä½¿ç”¨æ¡ä»¶è§†é¢‘æ‰©æ•£æ¨¡å‹å»ºæ¨¡ä¸“å®¶åˆ†å¸ƒï¼Œä¾èµ–å¤§é‡ä¸“å®¶æ•°æ® |
| **VIPER** | åˆ©ç”¨è§†é¢‘é¢„æµ‹æ¨¡å‹çš„ likelihood ä½œä¸º reward |
| **RoboCLIP** | ä½¿ç”¨ VLM å°†è§‚å¯Ÿä¸è¯­è¨€æè¿°å¯¹æ¯”æ‰“åˆ† |
| **Success Sparse Reward** | ç¯å¢ƒåŸç”Ÿçš„äºŒå€¼æˆåŠŸä¿¡å· |
| **Expert Dense Reward** | McLean et al. (2025) æ‰‹å·¥è®¾è®¡çš„ dense rewardï¼Œä¸ºå½“å‰æœ€ä¼˜åŸºå‡† |

> æ³¨ï¼šéƒ¨åˆ†åŸºçº¿ç»“æœå¼•ç”¨è‡ªåŸå§‹è®ºæ–‡ï¼ˆå› æœªå¼€æºå®ç°ï¼‰ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰åœ¨ **12 ä¸ª reward-free ä»»åŠ¡** ä¸Šçš„è¡¨ç°ï¼ˆFig. 3ï¼‰
- DEG åœ¨ **10/12 ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºæ‰€æœ‰ baseline**ã€‚
- ä»…åœ¨ `door-close` å’Œ `drawer-close` ä¸Šä¸ TeViR æ¥è¿‘ã€‚
- **æ ·æœ¬æ•ˆç‡è¿œè¶…å…¶ä»–æ–¹æ³•**ï¼šåœ¨ç›¸åŒæ­¥æ•°ä¸‹è¾¾åˆ°æ›´é«˜æˆåŠŸç‡ã€‚

#### ï¼ˆ2ï¼‰ç»“åˆ sparse reward çš„è¡¨ç°ï¼ˆDEG+ï¼ŒFig. 4ï¼‰
- åœ¨å…¨éƒ¨ **16 ä¸ª MetaWorld ä»»åŠ¡** ä¸Šï¼š
  - DEG+ **åŒ¹é…ç”šè‡³è¶…è¶Š expert dense reward** çš„æœ€ç»ˆæ€§èƒ½ã€‚
  - åœ¨å¤šä¸ªä»»åŠ¡ï¼ˆå¦‚ `assembly`, `hammer`, `drawer-open`ï¼‰ä¸Š **æ˜æ˜¾èƒœå‡º**ã€‚
- ç¤ºä¾‹åˆ†æï¼šåœ¨ `drawer-open` ä¸­ï¼Œexpert reward å› åªå…³æ³¨å¤¹çˆªä¸æŠŠæ‰‹è·ç¦»ï¼Œæ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼ˆä»å¤–ä¾§æ¨ï¼‰ï¼›è€Œ DEG èƒ½å­¦ä¼šæ­£ç¡®æŠ¬å‡å¤¹çˆªã€ä»å†…ä¾§é’©ä½æŠŠæ‰‹å†æ‹‰å¼€ã€‚

#### ï¼ˆ3ï¼‰çœŸå®ä¸–ç•Œä»»åŠ¡è¡¨ç°ï¼ˆFig. 5ï¼‰
- åœ¨ `pick banana` å’Œ `stack cube` ä¸Šï¼š
  - DEG+ æ˜¾è‘—ä¼˜äºä»…ç”¨ sparse rewardã€‚
  - æ”¶æ•›æ›´å¿«ï¼Œå¹²é¢„é¢‘ç‡æ›´ä½ã€‚
  - è¡¨æ˜ DEG åœ¨ç°å®ç¯å¢ƒä¸­åŒæ ·æœ‰æ•ˆï¼Œä¸”èƒ½ä¸ human-in-the-loop RL å…¼å®¹ã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ï¼ˆ1ï¼‰åŒç²’åº¦å¥–åŠ±çš„æœ‰æ•ˆæ€§ï¼ˆFig. 6 & Fig. 8ï¼‰
- ç§»é™¤ coarse-grained reward â†’ ç¼ºä¹å…¨å±€è½¨è¿¹å¼•å¯¼ï¼Œå­¦ä¹ ç¼“æ…¢ã€‚
- ç§»é™¤ fine-grained reward â†’ èƒ½æŠ“å–ä½†æ— æ³•å®Œæˆç²¾ç»†æ“ä½œï¼ˆå¦‚å‡†ç¡®æ’å…¥ï¼‰ã€‚
- **ä¸¤è€…ç»“åˆæ‰èƒ½å®ç°é«˜æ•ˆä¸”ç²¾å‡†çš„ä»»åŠ¡å®Œæˆ**ã€‚

#### ï¼ˆ2ï¼‰Policy æ„å›¾å¯è§†åŒ–ï¼ˆFig. 9ï¼‰
- **Only coarse**ï¼šå­¦ä¼šå¤§è‡´è¿åŠ¨è·¯å¾„ï¼Œä½†æ— æ³•ç²¾ç¡®äº¤äº’ã€‚
- **Only fine**ï¼šèƒ½æ¥è§¦ç›®æ ‡ï¼Œä½†ç¼ºä¹é¡ºåºæ¨¡ä»¿ï¼Œè¡Œä¸ºæ··ä¹±ã€‚
- **Dual-granularity**ï¼šå…¼å…·æµç•…è½¨è¿¹ä¸ç²¾ç¡®æ“ä½œï¼Œé¡ºåˆ©å®Œæˆä»»åŠ¡ã€‚

#### ï¼ˆ3ï¼‰Encoder å¯¹æ¯”åˆ†æï¼ˆFig. 7 & 10â€“11ï¼‰
- ä½¿ç”¨é¢„è®­ç»ƒ DINOv3 ç¼–ç å™¨ï¼š
  - å¯¹ç”Ÿæˆå™ªå£°æ•æ„Ÿï¼Œè¯­ä¹‰å¯¹é½å·®ã€‚
  - æ— æ³•åŒºåˆ†ä¸åŒæ—¶é—´é—´éš”çš„å¸§å·®å¼‚ï¼Œä¸é€‚åˆ reward è®¾è®¡ã€‚
- ä½¿ç”¨ DEG è‡ªç ”çš„ contrastive encoderï¼š
  - æ›´å¥½å¯¹é½è¯­ä¹‰ä¸€è‡´å¸§ï¼ŒåŒºåˆ†è¯­ä¹‰ä¸åŒå¸§ã€‚
  - èƒ½å°†è¯­ä¹‰è·ç¦»æ˜ å°„ä¸º latent similarity å·®å¼‚ï¼Œæ”¯æŒé˜ˆå€¼è®¾è®¡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **DEG å¯åœ¨æä½æ•°æ®æˆæœ¬ä¸‹å®ç°é«˜æ•ˆ RL**
   - ä»…éœ€ **3â€“5 æ¡ä¸“å®¶è§†é¢‘**ï¼Œæ— éœ€ä»»ä½•äººå·¥æ ‡æ³¨ï¼Œå³å¯ç”Ÿæˆé«˜è´¨é‡ dense rewardã€‚
   - åœ¨æ¨¡æ‹Ÿå’ŒçœŸå®ä¸–ç•Œå‡éªŒè¯å…¶æœ‰æ•ˆæ€§ã€‚

2. **ç”Ÿæˆå¼ episodic guidance æ˜¯å¯è¡Œä¸”å¼ºå¤§çš„å¼•å¯¼æœºåˆ¶**
   - å¾®è°ƒåçš„ video generation model èƒ½æ³›åŒ–åˆ°å¤šæ ·åˆå§‹çŠ¶æ€ï¼Œæä¾›ä¸ªæ€§åŒ– episode guidanceã€‚
   - ç”Ÿæˆè§†é¢‘è™½å«å™ªå£°ï¼Œä½†é€šè¿‡ contrastive learning å¯æœ‰æ•ˆå¯¹é½çœŸå®è§‚æµ‹ã€‚

3. **åŒç²’åº¦å¥–åŠ±æœºåˆ¶å¹³è¡¡äº†æ¢ç´¢ä¸ç²¾åº¦**
   - Coarse reward æä¾›å®è§‚å¼•å¯¼ï¼Œæå‡æ ·æœ¬æ•ˆç‡ï¼›
   - Fine reward å¼ºåŒ–ç»†èŠ‚äº¤äº’ï¼Œé¿å…å±€éƒ¨æœ€ä¼˜ï¼›
   - äºŒè€…ååŒä½œç”¨ï¼Œå®ç°â€œä»ç²—åˆ°ç²¾â€çš„ç­–ç•¥è¿›åŒ–ã€‚

4. **DEG å¯ç‹¬ç«‹å¼•å¯¼ RL æ”¶æ•›ï¼Œä¹Ÿå¯å¢å¼º sparse reward**
   - åœ¨ reward-free åœºæ™¯ä¸‹è¡¨ç° SOTAï¼›
   - ç»“åˆ sparse reward åæ€§èƒ½åª²ç¾ç”šè‡³è¶…è¶Š expert-designed dense rewardã€‚

---

### âš ï¸ å±€é™æ€§

- **è§†é¢‘ç”Ÿæˆé€Ÿåº¦æ…¢**ï¼šå½“å‰ video generation model æ¨ç†å»¶è¿Ÿè¾ƒé«˜ï¼Œå½±å“å®æ—¶æ€§ã€‚
- **åˆ†è¾¨ç‡æ•æ„Ÿ**ï¼šé™ä½åˆ†è¾¨ç‡åŠ é€Ÿç”Ÿæˆå¯èƒ½å¯¼è‡´æ¨¡å‹å´©æºƒï¼ˆå› è®­ç»ƒæ•°æ®é«˜ä¿çœŸï¼‰ã€‚
- **é¢†åŸŸè¿ç§»èƒ½åŠ›å¾…éªŒè¯**ï¼šç›®å‰é›†ä¸­åœ¨æœºæ¢°è‡‚ manipulationï¼Œæ˜¯å¦é€‚ç”¨äºå¯¼èˆªã€äººå½¢æœºå™¨äººç­‰è¿˜éœ€ç ”ç©¶ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **åŠ é€Ÿè§†é¢‘ç”Ÿæˆ**ï¼šæ¢ç´¢è½»é‡åŒ– video foundation models æˆ–è’¸é¦æŠ€æœ¯ã€‚
2. **è·¨ä»»åŠ¡æ³›åŒ–**ï¼šç ”ç©¶ single video generator æ”¯æŒ multiple tasks çš„å¯èƒ½æ€§ã€‚
3. **ä¸ VLAï¼ˆVision-Language-Actionï¼‰ç»“åˆ**ï¼šå¼•å…¥è¯­è¨€ prompt å¢å¼ºä»»åŠ¡ç†è§£ã€‚
4. **åœ¨çº¿è‡ªé€‚åº”ç”Ÿæˆ**ï¼šè®© guidance video éšç­–ç•¥æ”¹è¿›åŠ¨æ€è°ƒæ•´ï¼Œå½¢æˆé—­ç¯ä¼˜åŒ–ã€‚

---

## æ€»ç»“

> **DEG å¼€è¾Ÿäº†ä¸€æ¡â€œä»¥ç”Ÿæˆæ¨¡å‹ä¸ºå¯¼å¸ˆâ€çš„æ–°å‹ RL èŒƒå¼**ï¼š  
> å®ƒåˆ©ç”¨å¤§æ¨¡å‹çš„å…ˆéªŒçŸ¥è¯†ï¼Œå°†å°‘é‡ä¸“å®¶è§†é¢‘è½¬åŒ–ä¸º episode-specific çš„è§†è§‰æŒ‡å¯¼ï¼Œå¹¶é€šè¿‡åŒç²’åº¦å¯¹æ¯”å¥–åŠ±é©±åŠ¨æ™ºèƒ½ä½“é«˜æ•ˆå­¦ä¹ ã€‚  
> è¯¥æ–¹æ³•åœ¨æ•°æ®æ•ˆç‡ã€æ€§èƒ½è¡¨ç°å’Œå®ç”¨æ€§æ–¹é¢å‡å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä¸ºæœªæ¥ä½ç›‘ç£ã€é«˜æ•ˆç‡çš„å…·èº«æ™ºèƒ½å‘å±•æä¾›äº†é‡è¦æ€è·¯ã€‚

</details>

---

### 8. [ADEPT: RL-Aligned Agentic Decoding of Emotion via Evidence Probing Tools -- From Consensus Learning to Ambiguity-Driven Emotion Reasoning](https://arxiv.org/abs/2602.12714)

**Authors**: Esther Sun, Bo-Hao Su, Abinay Reddy Naini, Shinji Watanabe, Carlos Busso  
**Category**: cs.LG  
**Published**: 2026-02-16  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.12714v1  

#### Abstract
Speech Large Language Models (SLLMs) enable high-level emotion reasoning but often produce ungrounded, text-biased judgments without verifiable acoustic evidence. In contrast, self-supervised speech encoders such as WavLM provide strong acoustic representations yet remain opaque discriminative model...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# ADEPT: RL-Aligned Agentic Decoding of Emotion via Evidence Probing Tools â€”â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰ **Speech Emotion Recognition (SER)** é¢ä¸´ä¸¤å¤§æ ¸å¿ƒæŒ‘æˆ˜ï¼š

- **ä¿¡å·-è¯­ä¹‰é¸¿æ²Ÿ**ï¼ˆSignal-Semantics Gapï¼‰ï¼š
  - **SSL æ¨¡å‹**ï¼ˆå¦‚ WavLMï¼‰è™½èƒ½æå–å¼ºå£°å­¦è¡¨å¾ï¼Œä½†ä½œä¸ºé»‘ç®±åˆ¤åˆ«æ¨¡å‹ï¼Œç¼ºä¹å¯è§£é‡Šæ€§ã€‚
  - **Multimodal Large Language Models (MLLMs)** è™½å…·å¤‡é«˜çº§æ¨ç†èƒ½åŠ›ï¼Œä½†å…¶æƒ…æ„Ÿåˆ¤æ–­å¸¸åŸºäºæ–‡æœ¬åè§ï¼Œç¼ºä¹å¯¹**å¯éªŒè¯å£°å­¦è¯æ®**çš„ä¾èµ–ï¼Œæ˜“äº§ç”Ÿâ€œå¹»è§‰â€ã€‚

- **å…±è¯†æ‚–è®º**ï¼ˆConsensus Paradoxï¼‰ï¼š
  - ä¼ ç»Ÿ SER å¤šé‡‡ç”¨å¤šæ•°æŠ•ç¥¨ï¼ˆplurality/majority votingï¼‰ç”Ÿæˆå•ä¸€æ ‡ç­¾ï¼Œå°†æ ‡æ³¨è€…åˆ†æ­§è§†ä¸ºâ€œå™ªå£°â€è€Œä¸¢å¼ƒã€‚
  - è¿™ç§åšæ³•å¿½ç•¥äº†äººç±»æƒ…æ„Ÿçš„**å¤æ‚æ€§ä¸å…±ç°æ€§**ï¼ˆcomplexity and co-occurrenceï¼‰ï¼Œå¯¼è‡´æ¨¡å‹æ— æ³•æ•æ‰æ¬¡è¦æƒ…ç»ªï¼ˆminor emotionsï¼‰å’Œæ¨¡ç³ŠçŠ¶æ€ï¼ˆå¦‚ä¸­ç«‹ä¸­çš„ç„¦è™‘ï¼‰ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡º **ADEPT**ï¼ˆAgentic Decoding of Emotion via Probing Toolsï¼‰æ¡†æ¶ï¼Œå®ç°ä»**å…±è¯†å­¦ä¹ **åˆ°**æ­§ä¹‰é©±åŠ¨çš„æƒ…æ„Ÿæ¨ç†**ï¼ˆAmbiguity-Driven Emotion Reasoningï¼‰çš„èŒƒå¼è½¬å˜ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š

1. **å¤šè½®æ™ºèƒ½ä½“æ¨ç†æ¡†æ¶**ï¼ˆAgentic, Multi-turn Inquiryï¼‰
   - å°† SER é‡æ„ä¸ºä¸€ä¸ªä¸‰é˜¶æ®µçš„**ä¸»åŠ¨æ¢ç©¶è¿‡ç¨‹**ï¼Œè€Œéå•æ¬¡é¢„æµ‹ï¼š
     - **Phase 1: Global Perception**ï¼ˆé«˜å¬å›å‡è®¾åˆå§‹åŒ–ï¼‰
     - **Phase 2: Evidence Verification**ï¼ˆè‡ªé€‚åº”è¯æ®æ”¶é›†ï¼‰
     - **Phase 3: Decision Synthesis**ï¼ˆè¯æ®å°é—­å¼è£å†³ï¼‰
   - MLLM è¢«è½¬åŒ–ä¸ºä¸€ä¸ª**æ™ºèƒ½ä½“**ï¼ˆagentï¼‰ï¼Œç»´æŠ¤å¹¶æ›´æ–°å€™é€‰æƒ…ç»ªé›†åˆï¼Œé€šè¿‡è°ƒç”¨å·¥å…·ä¸»åŠ¨æŸ¥è¯¢è¯æ®ã€‚

2. **ç»“æ„åŒ–æ¢é’ˆå·¥å…·åŒ…**ï¼ˆStructured Evidence Probing Toolkitï¼‰
   - å®šä¹‰äº†å››ä¸ªå¯å®¡è®¡çš„å·¥å…·å®¶æ—ï¼Œç¡®ä¿æ‰€æœ‰æ¨ç†åŸºäº**æ˜¾å¼ä¿¡æ¯æ£€ç´¢**ï¼ˆExplicit Information Retrieval, EIRï¼‰ï¼š
     - **Structural Prior Tool**ï¼šåŸºäºå…±ç°ç»Ÿè®¡è¿›è¡Œé«˜æ•ˆé¢„ç®—åˆ†é…ä¸å›æº¯ã€‚
     - **Semantic Probing Tool**ï¼šåŸºäº Scherer çš„ CPM æ¨¡å‹ï¼ŒéªŒè¯æ–‡æœ¬ä¸­çš„ appraisal å› å­ï¼ˆå¦‚çªå‘æ€§ã€æ§åˆ¶æ„Ÿï¼‰ã€‚
     - **Acoustic Probing Tool**ï¼šè¾“å‡ºå¯è§£é‡Šçš„å£°å­¦ binï¼ˆå¦‚ High Pitch, Volatile Energyï¼‰ï¼Œæ¡¥æ¥æ•°å€¼-è¯­ä¹‰é¸¿æ²Ÿã€‚
     - **Refinement Tool**ï¼šæ”¯æŒåŒå‘é‡æŸ¥ï¼ˆreplay audio / re-check semanticsï¼‰ï¼Œè§£å†³è·¨æ¨¡æ€å†²çªï¼ˆå¦‚è®½åˆºï¼‰ã€‚

3. **æ­§ä¹‰é©±åŠ¨çš„å­¦ä¹ èŒƒå¼**
   - **ä¸ä¸¢å¼ƒå°‘æ•°æ ‡æ³¨**ï¼Œè€Œæ˜¯å°†å…¶ä½œä¸º**æ¬¡è¦æƒ…ç»ª**ï¼ˆminor emotionsï¼‰çš„ç›‘ç£ä¿¡å·ã€‚
   - åœ¨æ ‡ç­¾æ„å»ºä¸­ä¿ç•™**å¹³å±€æƒ…å†µ**ï¼ˆtieï¼‰ï¼Œå…è®¸å¤šä¸ªä¸»æƒ…ç»ªå­˜åœ¨ï¼ŒçœŸå®åæ˜ æƒ…æ„Ÿå¤æ‚æ€§ã€‚

4. **å¼ºåŒ–å­¦ä¹ å¯¹é½ä¼˜åŒ–**ï¼ˆRL-Aligned Optimizationï¼‰
   - é‡‡ç”¨ **Group Relative Policy Optimization (GRPO)** ç»“åˆ **Evidence Trust Gate**ã€‚
   - è¯¥æœºåˆ¶å°†å·¥å…·ä½¿ç”¨è¡Œä¸ºä¸é¢„æµ‹è´¨é‡æ˜¾å¼è€¦åˆï¼Œé˜²æ­¢â€œå¥–åŠ±ä½œå¼Šâ€ï¼ˆreward hackingï¼‰ï¼Œç¡®ä¿å·¥å…·è°ƒç”¨æ˜¯ä¸ºè·å–**ä¿¡æ¯é‡å¤§ä¸”å¯é **çš„è¯æ®ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | ADEPT |
|------|--------|-------|
| **æ¨ç†æ–¹å¼** | å•æ¬¡åˆ†ç±» / åè§è§£é‡Š | å¤šè½®ä¸»åŠ¨æ¢ç©¶ï¼Œè¯æ®é©±åŠ¨ |
| **è¯æ®åŸºç¡€** | é»‘ç®±ç‰¹å¾ / æ–‡æœ¬ç”Ÿæˆ | å¯å®¡è®¡çš„å£°å­¦ä¸è¯­ä¹‰è¯æ® |
| **æ ‡ç­¾å¤„ç†** | ä¸¢å¼ƒåˆ†æ­§ï¼Œå¼ºåˆ¶å…±è¯† | åˆ©ç”¨åˆ†æ­§ï¼Œå»ºæ¨¡å…±ç° |
| **å¯è§£é‡Šæ€§** | ä½ï¼ˆpost-hoc explanationï¼‰ | é«˜ï¼ˆaudit trail, causal traceabilityï¼‰ |
| **é²æ£’æ€§** | æ˜“å—æ–‡æœ¬åè§å½±å“ | å¹³è¡¡è¯­ä¹‰ä¸å£°å­¦ä¿¡å· |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **MSP-Podcast Corpus V2.0**ï¼ˆä¸»å®éªŒï¼‰ï¼š
  - è‡ªç„¶ä¸»ä¹‰æ’­å®¢è¯­éŸ³ï¼Œéè¡¨æ¼”æ€§æƒ…æ„Ÿã€‚
  - æ¯æ®µéŸ³é¢‘è‡³å°‘æœ‰ 5 åæ ‡æ³¨è€…ï¼Œæä¾›ä¸°å¯Œçš„æ ‡æ³¨åˆ†æ­§ã€‚
  - ä½¿ç”¨å…¶ 8 ç±»ä¸»æƒ…ç»ªæ ‡ç­¾ï¼ˆAnger, Sadness, Happiness, Surprise, Fear, Disgust, Contempt, Neutralï¼‰ã€‚
- **IEMOCAP**ï¼ˆé›¶æ ·æœ¬æ³›åŒ–æµ‹è¯•ï¼‰ï¼š
  - ç”¨äºè¯„ä¼°è·¨åŸŸé²æ£’æ€§ï¼Œåœ¨æœªå¾®è°ƒçš„æƒ…å†µä¸‹è¿›è¡Œä¸¥æ ¼é›¶æ ·æœ¬æµ‹è¯•ã€‚

### å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼š`Qwen-3-Omni`ï¼ˆå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼‰ã€‚
- **è®­ç»ƒæ–¹æ³•**ï¼šä½¿ç”¨ GRPO è¿›è¡Œå¼ºåŒ–å­¦ä¹ åè®­ç»ƒï¼ˆpost-trainingï¼‰ï¼Œé‡‡æ · 8 æ¡è½¨è¿¹ï¼ˆK=8ï¼‰æ¯æç¤ºã€‚
- **è®­ç»ƒæ•°æ®é‡**ï¼š169K æ ·æœ¬ï¼Œ2 ä¸ª epochã€‚

### è¯„ä¼°æŒ‡æ ‡
1. **Primary-label fidelity**ï¼ˆä¸»æƒ…ç»ªå‡†ç¡®æ€§ï¼‰ï¼š
   - `P-MacroF1`ï¼šä¸»æƒ…ç»ªä¸¥æ ¼åŒ¹é…çš„å®å¹³å‡ F1ã€‚
   - `Soft Recall`ï¼šå®½æ¾åŒ¹é…ï¼Œåªè¦é¢„æµ‹åŒ…å«çœŸå®ä¸»æƒ…ç»ªå³è®¡æ•°ã€‚
2. **Set-level ambiguity decoding**ï¼ˆé›†åˆçº§æ­§ä¹‰è§£ç ï¼‰ï¼š
   - `Set Recall`ï¼šé¢„æµ‹é›†åˆä¸çœŸå®é›†åˆï¼ˆä¸»+æ¬¡ï¼‰çš„äº¤é›†è¦†ç›–ç‡ã€‚
   - `Jaccard Index`ï¼ˆIoUï¼‰ï¼šé¢„æµ‹ä¸çœŸå®æ ‡ç­¾é›†çš„ Jaccard ç›¸ä¼¼åº¦ï¼Œæƒ©ç½šè¿‡é¢„æµ‹ã€‚
3. **Calibration**ï¼ˆæ ¡å‡†æ€§ï¼‰ï¼š
   - `Average Cardinality`ï¼šå¹³å‡é¢„æµ‹æ ‡ç­¾æ•°é‡ï¼Œç›‘æµ‹æ¨¡å‹æ˜¯å¦è¿‡åº¦ä¿å®ˆæˆ–æ¿€è¿›ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»åˆ« | åŸºçº¿æ–¹æ³• |
|------|----------|
| **SSL åˆ†ç±»å™¨**ï¼ˆä»…ä¸»æƒ…ç»ªï¼‰ | HuBERT, wav2vec2.0, WavLM (frozen/fine-tuned) |
| **ç”Ÿæˆå¼ SLLM/MLLM**ï¼ˆä¸»+æ¬¡ï¼‰ | SALMONN, Qwen-2-Audio, BLSP-Emo |
| **æ¶ˆèå˜ä½“** | Qwen-3-Omni (no tools), ADEPT (w/o GRPO) |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### åœ¨ MSP-Podcast ä¸Šçš„ä¸»è¦ç»“æœï¼ˆTest1ï¼‰

| Method | P-MacroF1 â†‘ | Soft R â†‘ | Set R â†‘ | Jaccard â†‘ | Avg Size |
|--------|-------------|----------|---------|-----------|----------|
| **WavLM (fine-tuned)** | 0.3640 | â€” | â€” | â€” | â€” |
| **BLSP-Emo** | 0.2915 | 0.6740 | 0.5320 | 0.4280 | 2.08 |
| **Qwen-3-Omni (no tools)** | 0.2358 | 0.6003 | 0.4923 | 0.3890 | 2.02 |
| **ADEPT (w/o GRPO)** | 0.3571 | 0.7032 | 0.5748 | 0.4450 | 2.15 |
| **ADEPT + GRPO (Ours)** | **0.4224** | **0.7874** | **0.6192** | **0.4751** | 2.21 |

#### å…³é”®å‘ç°ï¼š
- ADEPT + GRPO åœ¨ **P-MacroF1** ä¸Šè¶…è¶Šæœ€å¼º SSL åŸºçº¿ï¼ˆWavLM-ftï¼‰**+5.84 ä¸ªç™¾åˆ†ç‚¹**ã€‚
- åœ¨ **Set Recall** å’Œ **Jaccard** ä¸Šæ˜¾è‘—ä¼˜äºæ‰€æœ‰ç”Ÿæˆå¼åŸºçº¿ï¼Œè¯æ˜å…¶åœ¨æ¢å¤å…±ç°æƒ…ç»ªä¸Šçš„å¼ºå¤§èƒ½åŠ›ã€‚
- å·¥å…·åè®®ï¼ˆADEPTï¼‰æœ¬èº«å¸¦æ¥å·¨å¤§æå‡ï¼ˆvs. no toolsï¼‰ï¼ŒGRPO è¿›ä¸€æ­¥å¢å¼ºæ€§èƒ½ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

| Variant | Set R | Soft R | Jaccard | P-F1 |
|--------|-------|--------|---------|------|
| **ADEPT (Full)** | 61.92 | 78.74 | 47.51 | 42.24 |
| w/o Prior | 58.17 | 74.58 | 44.63 | 39.07 |
| w/o Semantic | 60.06 | 75.93 | 42.31 | 33.86 |
| w/o Acoustic | 59.08 | 75.21 | 41.28 | 34.52 |
| w/o Replay | 60.47 | 77.06 | 46.18 | 40.44 |
| w/o Trust Gate | 60.73 | 77.82 | 44.96 | 40.63 |

#### æ¶ˆèåˆ†æï¼š
- **ç§»é™¤ Acoustic Tools** å¯¹ Jaccard å½±å“æœ€å¤§ï¼Œè¡¨æ˜å±€éƒ¨å£°å­¦è¯æ®å¯¹æ­§ä¹‰è§£æè‡³å…³é‡è¦ã€‚
- **ç§»é™¤ Semantic Tools** å¯¹ P-MacroF1 å½±å“æœ€å¤§ï¼Œè¯´æ˜æ–‡æœ¬éªŒè¯å¯¹ä¸»æƒ…ç»ªåˆ¤åˆ«å…³é”®ã€‚
- **ç§»é™¤ Trust Gate** å¯¼è‡´ Jaccard ä¸‹é™ï¼ŒéªŒè¯å…¶æœ‰æ•ˆé˜²æ­¢æ— æ•ˆå·¥å…·è°ƒç”¨ã€‚

### é›¶æ ·æœ¬æ³›åŒ–ï¼ˆIEMOCAPï¼‰

| Method | Acc â†‘ | Soft R â†‘ | Set R â†‘ | Jaccard â†‘ |
|--------|-------|----------|---------|-----------|
| **BLSP-Emo** (supervised) | 76.13 | 80.51 | 52.30 | 48.90 |
| **Qwen-3-Omni** | 42.37 | 51.12 | 35.24 | 31.08 |
| **ADEPT + GRPO (Ours)** | 54.83 | 67.42 | **54.80** | 43.15 |

#### å‘ç°ï¼š
- å°½ç®¡æ˜¯é›¶æ ·æœ¬ï¼ŒADEPT åœ¨ **Set Recall** ä¸Š**è¶…è¿‡å…¨ç›‘ç£ SOTA**ï¼ˆ54.80 vs. 52.30ï¼‰ï¼Œè¯æ˜å…¶å¼ºå¤§çš„æ­§ä¹‰æ„ŸçŸ¥ä¸è·¨åŸŸæ³›åŒ–èƒ½åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æ­§ä¹‰æ˜¯ä¿¡æ¯ï¼Œä¸æ˜¯å™ªå£°**ï¼šå°†æ ‡æ³¨è€…åˆ†æ­§ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œèƒ½æ˜¾è‘—æå‡å¯¹**å…±ç°æƒ…ç»ª**çš„å»ºæ¨¡èƒ½åŠ›ã€‚
2. **ä¸»åŠ¨æ¢ç©¶ä¼˜äºè¢«åŠ¨åˆ†ç±»**ï¼šé€šè¿‡å·¥å…·è°ƒç”¨è¿›è¡Œ**æ˜¾å¼ä¿¡æ¯æ£€ç´¢**ï¼ˆEIRï¼‰ï¼Œä½¿æ¨¡å‹æ¨ç†è¿‡ç¨‹å¯å®¡è®¡ã€å¯è¿½æº¯ã€‚
3. **å·¥å…·ååŒå¢æ•ˆ**ï¼šSemanticã€Acousticã€Priorã€Refinement å·¥å…·äº’è¡¥ï¼Œç¼ºä¸€ä¸å¯ã€‚
4. **GRPO + Trust Gate æœ‰æ•ˆå¯¹é½è¡Œä¸º**ï¼šç¡®ä¿å·¥å…·ä½¿ç”¨æœåŠ¡äºæé«˜é¢„æµ‹è´¨é‡ï¼Œè€Œéç›²ç›®è°ƒç”¨ã€‚
5. **è®¡ç®—èµ„æºæŒ‰éœ€åˆ†é…**ï¼šå·¥å…·è°ƒç”¨æ¬¡æ•°éšæ ‡æ³¨æ­§ä¹‰åº¦å¢åŠ ï¼ˆé«˜æ­§ä¹‰æ ·æœ¬è°ƒç”¨æ›´å¤šå·¥å…·ï¼‰ï¼Œä½“ç°æ™ºèƒ½èµ„æºè°ƒåº¦ã€‚

### å±€é™æ€§
- **è®¡ç®—å¼€é”€è¾ƒå¤§**ï¼šå¤šè½®å·¥å…·è°ƒç”¨æ˜¾è‘—å¢åŠ æ¨ç†å»¶è¿Ÿï¼Œä¸é€‚åˆå®æ—¶åº”ç”¨ã€‚
- **ä¾èµ–é«˜è´¨é‡å¯¹é½**ï¼šAcoustic Tools ä¾èµ– forced alignmentï¼Œå¯¹é½é”™è¯¯å¯èƒ½ä¼ æ’­ã€‚
- **å·¥å…·è®¾è®¡ä¾èµ–å…ˆéªŒçŸ¥è¯†**ï¼šæ¢é’ˆå·¥å…·çš„è®¾è®¡åŸºäºå¿ƒç†å­¦ç†è®ºï¼ˆå¦‚ CPMï¼‰ï¼Œé€šç”¨æ€§å—é™ã€‚
- **æ•°æ®é›†é™åˆ¶**ï¼šMSP-Podcast è™½å¤§ï¼Œä½†ä»ä»¥è‹±è¯­ä¸ºä¸»ï¼Œå¤šè¯­è¨€æ³›åŒ–å¾…éªŒè¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³æ›´ä¸°å¯Œçš„æƒ…ç»ªæ ‡ç­¾ä½“ç³»ï¼ˆå¦‚ secondary emotionsï¼‰ã€‚
- æ¢ç´¢è½»é‡åŒ–å·¥å…·è°ƒç”¨ç­–ç•¥ï¼Œé™ä½æ¨ç†æˆæœ¬ã€‚
- å°† ADEPT æ¡†æ¶åº”ç”¨äºå…¶ä»–å¤šæ¨¡æ€ç†è§£ä»»åŠ¡ï¼ˆå¦‚æ„å›¾è¯†åˆ«ã€å¿ƒç†å¥åº·è¯„ä¼°ï¼‰ã€‚
- ç ”ç©¶å¦‚ä½•è®©æ¨¡å‹è‡ªä¸»å‘ç°å’Œå®šä¹‰æ–°çš„æ¢é’ˆå·¥å…·ï¼ˆmeta-tool learningï¼‰ã€‚

--- 

> **æ€»ç»“**ï¼šADEPT æˆåŠŸåœ°å°† SER ä»â€œé™æ€åˆ†ç±»â€è½¬å˜ä¸ºâ€œåŠ¨æ€ã€å¯å®¡è®¡çš„ç§‘å­¦æ¢ç©¶â€ï¼Œé€šè¿‡**æ™ºèƒ½ä½“æ¶æ„ + ç»“æ„åŒ–å·¥å…· + æ­§ä¹‰åˆ©ç”¨ + å¼ºåŒ–å­¦ä¹ å¯¹é½**ï¼Œå®ç°äº†æ›´é«˜å‡†ç¡®ç‡ã€æ›´å¼ºè§£é‡Šæ€§ä¸æ›´å¥½æ³›åŒ–æ€§çš„ç»Ÿä¸€ï¼Œä¸ºå¯ä¿¡çš„ Affective Computing æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 9. [Formalizing the Sampling Design Space of Diffusion-Based Generative Models via Adaptive Solvers and Wasserstein-Bounded Timesteps](https://arxiv.org/abs/2602.12624)

**Authors**: Sangwoo Jo, Sungjoon Choi  
**Category**: cs.LG  
**Published**: 2026-02-16  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.12624v1  

#### Abstract
Diffusion-based generative models have achieved remarkable performance across various domains, yet their practical deployment is often limited by high sampling costs. While prior work focuses on training objectives or individual solvers, the holistic design of sampling, specifically solver selection...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Formalizing the Sampling Design Space of Diffusion-Based Generative Models via Adaptive Solvers and Wasserstein-Bounded Timesteps*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
æ‰©æ•£ç”Ÿæˆæ¨¡å‹ï¼ˆDiffusion-based Generative Modelsï¼‰åœ¨å›¾åƒã€è§†é¢‘å’Œ3Då†…å®¹ç”Ÿæˆä¸­å–å¾—äº†å“è¶Šæ€§èƒ½ï¼Œä½†å…¶**é«˜é‡‡æ ·æˆæœ¬**ï¼ˆå³é«˜ Number of Function Evaluations, NFEï¼‰ä¸¥é‡é™åˆ¶äº†å®é™…éƒ¨ç½²ã€‚ç°æœ‰æ–¹æ³•å¤šä¾èµ–é™æ€å¯å‘å¼ç­–ç•¥ï¼ˆå¦‚å›ºå®šæ­¥é•¿è°ƒåº¦å’Œç»Ÿä¸€æ±‚è§£å™¨ï¼‰ï¼Œå¿½ç•¥äº†æ‰©æ•£è½¨è¿¹åœ¨ä¸åŒå™ªå£°é˜¶æ®µçš„å‡ ä½•ç‰¹æ€§å·®å¼‚ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº† **SDM (Sampling Design via Adaptive Solvers and Wasserstein-Bounded Timesteps)**ï¼Œä¸€ä¸ªæ— éœ€é‡æ–°è®­ç»ƒçš„é‡‡æ ·æ¡†æ¶ï¼Œä»å‡ ä½•è§†è§’å½¢å¼åŒ–äº†æ‰©æ•£æ¨¡å‹çš„é‡‡æ ·è®¾è®¡ç©ºé—´ï¼ŒåŒ…å«ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š

- **è‡ªé€‚åº” ODE æ±‚è§£å™¨ï¼ˆAdaptive ODE Solversï¼‰**  
  åŸºäºå¯¹ Probability Flow ODEï¼ˆPF-ODEï¼‰æ›²ç‡çš„ç†è®ºåˆ†æï¼Œæå‡ºåŠ¨æ€åˆ†é…æ±‚è§£å™¨ï¼šåœ¨æ—©æœŸé«˜å™ªå£°é˜¶æ®µä½¿ç”¨é«˜æ•ˆçš„ä½é˜¶æ±‚è§£å™¨ï¼ˆå¦‚ Eulerï¼‰ï¼Œåœ¨æ¥è¿‘æ•°æ®æµå½¢æ—¶åˆ‡æ¢åˆ°é«˜é˜¶æ±‚è§£å™¨ï¼ˆå¦‚ Heunï¼‰ã€‚è¯¥ç­–ç•¥ç”±ä¸€ä¸ªåŸºäºå‘é‡åœºå˜åŒ–çš„ç¼“å­˜æ›²ç‡ä¼°è®¡ $K_{\text{rel}}(i)$ é©±åŠ¨ï¼Œé¿å…é¢å¤– NFE å¼€é”€ã€‚

- **Wasserstein æœ‰ç•Œè‡ªé€‚åº”æ—¶é—´æ­¥è°ƒåº¦ï¼ˆWasserstein-Bounded Adaptive Schedulingï¼‰**  
  å¼•å…¥ä¸€ç§æ–°çš„ä¼˜åŒ–æ¡†æ¶ï¼Œé€šè¿‡æ§åˆ¶æ¯ä¸€æ­¥çš„å±€éƒ¨ **Wasserstein è·ç¦»**è¯¯å·®æ¥æ¨å¯¼è‡ªé€‚åº”æ—¶é—´æ­¥ã€‚å…·ä½“åœ°ï¼Œæ¨å¯¼å‡ºæœ€å¤§å…è®¸æ­¥é•¿ $\Delta t \leq \sqrt{\frac{2\eta}{S_t}}$ï¼Œå…¶ä¸­ $S_t$ æ˜¯é€Ÿåº¦åœºçš„å˜åŒ–ä¸Šç•Œï¼Œ$\eta$ æ˜¯å¯è°ƒè¯¯å·®å®¹å¿åº¦ã€‚æ­¤å¤–ï¼Œæå‡º **N-step resampling** ç®—æ³•ï¼Œåœ¨å›ºå®š NFE ä¸‹å®ç°æœ€ä¼˜è·¯å¾„é‡é‡‡æ ·ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ— éœ€å†è®­ç»ƒ**ï¼šå®Œå…¨é€‚ç”¨äºé¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚ EDMã€Stable Diffusionï¼‰ï¼Œä¸ä¿®æ”¹æ¨¡å‹æ¶æ„æˆ–å‚æ•°ã€‚
- **å‡ ä½•æ„ŸçŸ¥**ï¼šé¦–æ¬¡å°†æ‰©æ•£è½¨è¿¹çš„éçº¿æ€§å’Œåˆšæ€§å˜åŒ–çº³å…¥é‡‡æ ·è®¾è®¡ï¼Œå®ç°â€œæŒ‰éœ€ç²¾åº¦â€ã€‚
- **ç³»ç»Ÿæ€§ä¼˜åŒ–**ï¼šç»Ÿä¸€äº†æ±‚è§£å™¨é€‰æ‹©ä¸æ—¶é—´æ­¥è°ƒåº¦çš„è®¾è®¡ç©ºé—´ï¼ŒäºŒè€…å¯ç‹¬ç«‹ä¼˜åŒ–å¹¶äº’è¡¥æå‡ã€‚
- **é«˜æ•ˆä¸”çµæ´»**ï¼šåœ¨æ›´å°‘ NFE ä¸‹è¾¾åˆ°æ›´é«˜æ ·æœ¬è´¨é‡ï¼Œå¹¶æ”¯æŒé€šè¿‡è¶…å‚æ•°ï¼ˆå¦‚ $\eta$, $T_k$ï¼‰çµæ´»æƒè¡¡è´¨é‡ä¸æ•ˆç‡ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **CIFAR-10**ï¼ˆ32Ã—32ï¼‰
- **FFHQ**ï¼ˆ64Ã—64ï¼‰
- **AFHQv2**ï¼ˆ64Ã—64ï¼‰
- **ImageNet**ï¼ˆ64Ã—64ï¼‰

æ‰€æœ‰å®éªŒå‡åŸºäºé¢„è®­ç»ƒçš„ **EDM æ¨¡å‹**ï¼ˆKarras et al., 2022ï¼‰ï¼Œæ¶µç›– VP å’Œ VE å‚æ•°åŒ–ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **FID (FrÃ©chet Inception Distance)**ï¼šè¡¡é‡ç”Ÿæˆæ ·æœ¬çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚
  - **NFE (Number of Function Evaluations)**ï¼šè¡¡é‡é‡‡æ ·æ•ˆç‡ã€‚
- **é‡‡æ ·å™¨é…ç½®**ï¼š
  - å¯¹æ¯” Eulerã€Heun åŠ SDM è‡ªé€‚åº”æ±‚è§£å™¨ã€‚
  - æ—¶é—´æ­¥è°ƒåº¦åŒ…æ‹¬ï¼šEDM (p=7)ã€COS (Williams et al., 2024)ã€SDM è‡ªé€‚åº”è°ƒåº¦ã€‚
- **æ¶ˆèç ”ç©¶**ï¼šå¯¹é˜ˆå€¼ $T_k$ã€è°ƒåº¦å‡½æ•° $A(t)$ï¼ˆstep/linear/cosineï¼‰ã€è¯¯å·®å®¹å¿å‚æ•° $\eta_{\min}, \eta_{\max}, p$ å’Œ resampling å‚æ•° $q$ è¿›è¡Œç½‘æ ¼æœç´¢ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **EDM (p=7)**ï¼šæ ‡å‡†å¤šé¡¹å¼å™ªå£°è°ƒåº¦ã€‚
- **COS (Corrector Optimized Schedules)**ï¼šåŸºäº score-based ä¼˜åŒ–çš„æ—¶é—´æ­¥ã€‚
- æ‰€æœ‰æ–¹æ³•å‡åœ¨ç›¸åŒé¢„è®­ç»ƒæ¨¡å‹ä¸Šæµ‹è¯•ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 å’Œ Abstractï¼‰
| æ•°æ®é›†       | æ–¹æ³•               | å‚æ•°åŒ– | FID    | NFE  |
|------------|--------------------|--------|--------|------|
| CIFAR-10   | **SDM (Adaptive Solver)** | VP     | **1.93** | 32   |
| FFHQ       | **SDM (Adaptive Scheduling)** | VP     | **2.41** | 79   |
| AFHQv2     | **SDM (Adaptive Solver)** | VP     | **1.98** | 66   |

> æ³¨ï¼šè¿™äº›ç»“æœå‡ä¸º state-of-the-artï¼Œä¸”éƒ¨åˆ†ä¼˜äºåŸºçº¿çš„åŒæ—¶é™ä½äº† NFEã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨ **Euler æ±‚è§£å™¨ + è‡ªé€‚åº”è°ƒåº¦** ä¸‹ï¼ŒFID æ˜¾è‘—ä¸‹é™ï¼š
  - CIFAR-10 (VP): 7.61 (EDM) â†’ **6.18** (SDM)ï¼Œâ†“18.7%
  - FFHQ (VP): 4.59 â†’ **4.16**
- åœ¨ **Heun æ±‚è§£å™¨** ä¸Šï¼ŒSDM è°ƒåº¦ä»èƒ½è¿›ä¸€æ­¥æå‡è´¨é‡æˆ–ä¿æŒç«äº‰åŠ›ã€‚
- **SDM è‡ªé€‚åº”æ±‚è§£å™¨ï¼ˆä»…ç”¨ Euler/Heun åˆ‡æ¢ï¼‰** å·²è¶…è¶Š EDM + Heun åŸºçº¿ï¼ŒåŒæ—¶é™ä½çº¦ 15â€“20% NFEã€‚
- **ç»„åˆä½¿ç”¨è‡ªé€‚åº”æ±‚è§£å™¨ + è‡ªé€‚åº”è°ƒåº¦** è¾¾åˆ°æœ€ä½³æ€§èƒ½ï¼Œä¾‹å¦‚ AFHQv2 ä¸Š FID è¾¾ **1.97 (VP)** / **1.99 (VE)**ã€‚

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰é˜ˆå€¼ $T_k$ çš„å½±å“ï¼ˆFigure 4ï¼‰
- å­˜åœ¨ä¸€ä¸ªæœ€ä¼˜ $T_k$ å¹³è¡¡è´¨é‡ä¸æ•ˆç‡ï¼›è¿‡å¤§åˆ™è¿‡æ—©å¯ç”¨é«˜é˜¶æ±‚è§£å™¨ï¼Œæµªè´¹è®¡ç®—ï¼›è¿‡å°åˆ™æŸå¤±ç²¾åº¦ã€‚
- æœ€ä¼˜å€¼å› æ•°æ®é›†è€Œå¼‚ï¼ˆå¦‚ CIFAR-10: $2\times10^{-4}$ï¼ŒAFHQv2: $1\times10^{-3}$ï¼‰ã€‚

#### ï¼ˆ2ï¼‰è°ƒåº¦å‡½æ•° $A(t)$ çš„é€‰æ‹©ï¼ˆTable 5ï¼‰
- **Step schedule** è¡¨ç°æœ€å¥½ï¼ŒFID æœ€ä½ä¸” NFE < 2ï¼ˆå¹³å‡æ¯æ¬¡æ›´æ–°ä¸åˆ°ä¸¤æ¬¡ç½‘ç»œè°ƒç”¨ï¼‰ã€‚
- Linear/Cosine è°ƒåº¦è™½å¹³æ»‘ä½†éœ€è¦å›ºå®š NFE=2ï¼Œæ•ˆç‡æ›´ä½ã€‚

#### ï¼ˆ3ï¼‰è¯¯å·®å®¹å¿ä¸ resampling å‚æ•°
- CIFAR-10 å¯¹ $\eta_{\min}, \eta_{\max}, p, q$ æ•æ„Ÿï¼Œéœ€ç²¾ç»†è°ƒå‚ã€‚
- å…¶ä»–æ•°æ®é›†é²æ£’æ€§å¼ºï¼Œé‡‡ç”¨ç»Ÿä¸€è®¾ç½®å³å¯è·å¾—è‰¯å¥½è¡¨ç°ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **æ‰©æ•£è½¨è¿¹å…·æœ‰æ˜¾è‘—çš„å‡ ä½•éå‡åŒ€æ€§**ï¼šæ—©æœŸé«˜å™ªå£°é˜¶æ®µè¿‘ä¹çº¿æ€§ï¼Œé€‚åˆä½é˜¶æ±‚è§£å™¨ï¼›åæœŸæ¥è¿‘æ•°æ®æµå½¢æ—¶æ›²ç‡æ€¥å‰§ä¸Šå‡ï¼Œéœ€é«˜é˜¶æ±‚è§£å™¨ã€‚
2. **é™æ€è°ƒåº¦æ˜¯æ¬¡ä¼˜çš„**ï¼šEDM ç­‰å¯å‘å¼è°ƒåº¦åœ¨ä¸­é—´é˜¶æ®µæµªè´¹è¯¯å·®é¢„ç®—ï¼Œè€Œ SDM å°†æ›´å¤šå®¹é”™ç©ºé—´åˆ†é…ç»™æ—©æœŸå¹³æ»‘é˜¶æ®µï¼ŒåæœŸæ”¶ç´§æ§åˆ¶ï¼Œä»è€Œæ›´é«˜æ•ˆåˆ©ç”¨ NFEã€‚
3. **è‡ªé€‚åº”æ±‚è§£å™¨ä¸è‡ªé€‚åº”è°ƒåº¦æ˜¯æ­£äº¤ä¸”äº’è¡¥çš„**ï¼šä¸¤è€…å¯ç‹¬ç«‹åº”ç”¨ï¼Œè”åˆä½¿ç”¨å¸¦æ¥å åŠ å¢ç›Šã€‚
4. **æ— éœ€è®­ç»ƒå³å¯çªç ´æ€§èƒ½è¾¹ç•Œ**ï¼šSDM åœ¨å¤šä¸ª benchmark ä¸Šå®ç°äº†æ— éœ€å¾®è°ƒçš„ SOTA æ€§èƒ½ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- æ›²ç‡ä¼°è®¡ä¾èµ–ç¼“å­˜æœºåˆ¶ï¼Œå¯èƒ½åœ¨æç«¯éçº¿æ€§åŒºåŸŸç•¥æœ‰å»¶è¿Ÿã€‚
- å½“å‰å®ç°ä¸»è¦é’ˆå¯¹ç¡®å®šæ€§ ODE é‡‡æ ·ï¼Œæœªç›´æ¥æ‰©å±•è‡³ SDE æˆ–éšæœºé‡‡æ ·è·¯å¾„ã€‚
- è¶…å‚æ•°ï¼ˆå°¤å…¶æ˜¯ $\eta$ å’Œ $T_k$ï¼‰éœ€æ ¹æ®ä»»åŠ¡è°ƒæ•´ï¼Œå°šæœªå®Œå…¨è‡ªåŠ¨åŒ–ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† SDM æ¡†æ¶æ¨å¹¿è‡³ **Rectified Flow**ã€**Consistency Models** ç­‰æ–°å‹ç”ŸæˆèŒƒå¼ã€‚
- æ¢ç´¢ **å…¨è‡ªåŠ¨è¶…å‚æ•°è°ƒèŠ‚æœºåˆ¶**ï¼ˆå¦‚åŸºäºåœ¨çº¿è¯¯å·®ä¼°è®¡ï¼‰ã€‚
- ç»“åˆ **distillation** æˆ– **knowledge transfer** æŠ€æœ¯ï¼Œæ„å»ºç«¯åˆ°ç«¯é«˜æ•ˆæ¨ç† pipelineã€‚
- æ‰©å±•è‡³ **é«˜åˆ†è¾¨ç‡ç”Ÿæˆ**ï¼ˆå¦‚ 1024Ã—1024ï¼‰å’Œ **è·¨æ¨¡æ€ç”Ÿæˆä»»åŠ¡**ï¼ˆå¦‚ text-to-videoï¼‰ã€‚

---

> âœ… **ä»£ç å¼€æºåœ°å€**ï¼šhttps://github.com/aiimaginglab/sdm  
> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼šSDM é€šè¿‡å‡ ä½•æ„ŸçŸ¥çš„è‡ªé€‚åº”æ±‚è§£å™¨ä¸ Wasserstein æœ‰ç•Œæ—¶é—´æ­¥è°ƒåº¦ï¼Œä¸ºé¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹æä¾›äº†æ— éœ€è®­ç»ƒå³å¯æå‡é‡‡æ ·æ•ˆç‡ä¸è´¨é‡çš„æ–°èŒƒå¼ã€‚

</details>

---

### 10. [Mixture of Predefined Experts: Maximizing Data Usage on Vertical Federated Learning](https://arxiv.org/abs/2602.12708)

**Authors**: Jon Irureta, Gorka Azkune, Jon Imaz, Aizea Lojo, Javier Fernandez-Marques  
**Category**: cs.LG  
**Published**: 2026-02-16  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.12708v1  

#### Abstract
Vertical Federated Learning (VFL) has emerged as a critical paradigm for collaborative model training in privacy-sensitive domains such as finance and healthcare. However, most existing VFL frameworks rely on the idealized assumption of full sample alignment across participants, a premise that rarel...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**Mixture of Predefined Experts: Maximizing Data Usage on Vertical Federated Learning**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹ **Vertical Federated Learning (VFL)** ä¸­ä¸¤ä¸ªå…³é”®ç°å®æŒ‘æˆ˜ï¼š
- **æ ·æœ¬ä¸å®Œå…¨å¯¹é½ï¼ˆSample Misalignmentï¼‰**ï¼šçœŸå®åœºæ™¯ä¸­ï¼Œä¸åŒå‚ä¸æ–¹çš„æ•°æ®IDäº¤é›†ç¨€ç–ï¼ˆå¦‚è·¨åŒ»é™¢æ‚£è€…é‡å å°‘ï¼‰ï¼Œä¼ ç»ŸVFLæ–¹æ³•å› ä¾èµ–â€œå…¨æ ·æœ¬å¯¹é½â€å‡è®¾è€Œæ€§èƒ½ä¸¥é‡ä¸‹é™ã€‚
- **é€šä¿¡å¼€é”€å¤§ä¸é²æ£’æ€§å·®**ï¼šç°æœ‰æ–¹æ³•éœ€å¤šè½®é€šä¿¡è¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒï¼Œä¸”éš¾ä»¥æŠµå¾¡æ¶æ„æˆ–å™ªå£°å‚ä¸è€…çš„å½±å“ï¼ŒåŒæ—¶ç¼ºä¹å¯è§£é‡Šæ€§ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šSplit-MoPE
æå‡º **Split-MoPE**ï¼Œä¸€ç§ç»“åˆ **Split Learning** ä¸æ–°å‹ **Mixture of Predefined Experts (MoPE)** æ¶æ„çš„VFLæ¡†æ¶ã€‚

#### åˆ›æ–°æ€è·¯ï¼š
- **MoPE æ›¿ä»£æ ‡å‡† MoE**ï¼š
  - ä¼ ç»Ÿ MoE åŠ¨æ€å­¦ä¹ è·¯ç”±ï¼ˆroutingï¼‰ï¼Œä¸“å®¶æŒ‰æ•°æ®æ¨¡å¼è‡ªé€‚åº”åˆ†å·¥ã€‚
  - **MoPE é¢„å®šä¹‰ä¸“å®¶èŒè´£**ï¼šæ¯ä¸ªä¸“å®¶ä¸“é—¨å¤„ç†ä¸€ç§ç‰¹å®šçš„ **æ•°æ®å¯¹é½ç»„åˆ**ï¼ˆç”± `P(K)` å®šä¹‰ï¼‰ï¼Œå³ä¸åŒçš„ç‰¹å¾å¯ç”¨æ€§æ¨¡å¼ï¼ˆå¦‚ä»…ä¸»åŠ¨æ–¹ã€ä¸»è¢«åŠ¨å‡æœ‰ç­‰ï¼‰ã€‚
- **Split Learning + å†»ç»“é¢„è®­ç»ƒç¼–ç å™¨**ï¼š
  - è¢«åŠ¨æ–¹ä½¿ç”¨ **é¢„è®­ç»ƒä¸”å†»ç»“çš„ backbone**ï¼ˆå¦‚ DINOv2ã€Qwen3-Embeddingï¼‰æå–ç‰¹å¾ã€‚
  - ä»…ä¼ è¾“ä¸€æ¬¡åµŒå…¥ï¼ˆembeddingï¼‰ï¼Œå®ç° **å•è½®é€šä¿¡è®­ç»ƒ**ï¼Œæå¤§é™ä½é€šä¿¡æˆæœ¬ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ä¼˜åŠ¿ç»´åº¦ | å…·ä½“è¡¨ç° |
|--------|---------|
| **æ•°æ®åˆ©ç”¨ç‡** | æœ€å¤§åŒ–åˆ©ç”¨éå¯¹é½æ ·æœ¬ï¼Œæ”¯æŒè®­ç»ƒä¸æ¨ç†é˜¶æ®µçš„ä¸å®Œæ•´æ•°æ® |
| **é€šä¿¡æ•ˆç‡** | å•è½®é€šä¿¡ï¼Œé€šä¿¡é‡å‡å°‘è¾¾ **200Ã—**ï¼ˆç›¸æ¯”å¤šè½®ç«¯åˆ°ç«¯è®­ç»ƒï¼‰ |
| **é²æ£’æ€§** | å¯¹å™ªå£°/æ¶æ„å‚ä¸è€…å…·æœ‰å¤©ç„¶æŠµæŠ—åŠ›ï¼Œæ€§èƒ½é€€åŒ–æœ€å¤šé™ä½ **25Ã—** |
| **å¯è§£é‡Šæ€§** | æä¾› **per-sample è´¡çŒ®åº¦é‡åŒ–**ï¼Œæ˜ç¡®å„å‚ä¸è€…å¯¹é¢„æµ‹çš„è´¡çŒ® |
| **æ— éœ€é¢å¤–è¶…å‚æ•°** | ç›¸æ¯” APC-VFLã€VFedTrans ç­‰ï¼Œä¸º **hyperparameter-free** è®¾è®¡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†
åœ¨ä¸‰ç§æ•°æ®é›†ä¸ŠéªŒè¯ï¼Œæ¶µç›–è§†è§‰ä¸è¡¨æ ¼æ¨¡æ€ï¼š
- **CIFAR-10 / CIFAR-100**ï¼šå›¾åƒåˆ†ç±»ä»»åŠ¡ï¼Œé€šè¿‡åˆ‡åˆ†å›¾åƒå—æ¨¡æ‹Ÿå¤šæ–¹ç‰¹å¾åˆ†å‰²ã€‚
- **Breast Cancer Wisconsin**ï¼šè¡¨æ ¼æ•°æ®ï¼Œç›´æ¥æŒ‰åˆ—åˆ†é…ç»™ä¸åŒå‚ä¸è€…ã€‚

> æ³¨ï¼šæ‰€æœ‰æ•°æ®é›†å‡éåŸç”ŸVFLæ ¼å¼ï¼Œéœ€äººå·¥å‚ç›´åˆ‡åˆ†ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **æ ·æœ¬ç¼ºå¤±æœºåˆ¶**ï¼šé‡‡ç”¨ **MCARï¼ˆMissing Completely at Randomï¼‰**ï¼Œå¼•å…¥å‚æ•° `pmiss` æ§åˆ¶è¢«åŠ¨æ–¹æ•°æ®ç¼ºå¤±æ¦‚ç‡ï¼ˆ0=å®Œå…¨å¯¹é½ï¼Œ1=ä»…ä¸»åŠ¨æ–¹å¯è§ï¼‰ã€‚
- **å‚ä¸è€…æ•°é‡**ï¼šä¸»è¦æµ‹è¯• **ä¸¤æ–¹åä½œ** åœºæ™¯ï¼ˆç¬¦åˆVFLå¸¸è§è®¾å®šï¼‰ã€‚
- **é¢„è®­ç»ƒç¼–ç å™¨**ï¼š
  - å›¾åƒï¼šDINOv2ï¼ˆViT-S/B/Lï¼‰
  - è¡¨æ ¼ï¼šå°†è¡Œè½¬ä¸ºæ–‡æœ¬ `"feat1:val1|feat2:val2"`ï¼Œä½¿ç”¨ **Qwen3-Embedding** æ¨¡å‹ç”Ÿæˆå‘é‡ã€‚

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
- **å›¾åƒæ•°æ®**ï¼šæµ‹è¯•å‡†ç¡®ç‡ï¼ˆAccuracy %ï¼‰
- **è¡¨æ ¼æ•°æ®**ï¼šF1 Scoreï¼ˆÃ—100ï¼‰
- æ‰€æœ‰ç»“æœæŠ¥å‘Š **ä¸‰è½®å®éªŒçš„å‡å€¼Â±æ ‡å‡†å·®**

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **SplitNN*** | æ”¹è¿›åŸºçº¿ | ä½¿ç”¨å†»ç»“é¢„è®­ç»ƒç¼–ç å™¨çš„ SplitNN |
| **LASER*** | å½“å‰ SOTA | æ”¹è¿›ç‰ˆ LASERï¼ŒåŒæ ·ä½¿ç”¨å†»ç»“ç¼–ç å™¨ |
| **Local Model** | ä¸‹ç•ŒåŸºå‡† | ä»…ä½¿ç”¨ä¸»åŠ¨æ–¹æœ¬åœ°ç‰¹å¾è®­ç»ƒçš„æ¨¡å‹ |

> æ³¨ï¼šå¸¦ `*` è¡¨ç¤ºä½œè€…å¤ç°å¹¶æ”¹è¿›çš„ç‰ˆæœ¬ï¼Œä»¥å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 2ï¼‰

#### åœ¨ **CIFAR-100** ä¸Šçš„è¡¨ç°ï¼ˆAccuracy %ï¼‰
| æ–¹æ³• \ `pmiss` | 0.0 | 0.1 | 0.7 |
|----------------|-----|-----|-----|
| Local          | â€”   | â€”   | 73.48 |
| SplitNN*       | 81.53 | 81.12 | 72.56 |
| LASER*         | 82.26 | 79.83 | 72.55 |
| **MoPE**       | **81.78** | **80.50** | **73.27** âœ… |

> MoPE åœ¨é«˜ç¼ºå¤±ç‡ä¸‹ä»ä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œä¸”å§‹ç»ˆ **ä¸ä½äº Local æ¨¡å‹**ã€‚

#### åœ¨ **Breast Cancer Wisconsin** ä¸Šçš„è¡¨ç°ï¼ˆF1 Score Ã—100ï¼‰
| æ–¹æ³• \ `pmiss` | 0.0 | 0.1 | 0.7 |
|----------------|-----|-----|-----|
| Local          | â€”   | â€”   | 86.36 |
| SplitNN*       | 93.37 | 93.37 | 82.86 |
| LASER*         | 86.69 | 84.90 | 86.19 |
| **MoPE**       | **94.15** | **93.30** | **87.68** âœ… |

> åœ¨ `pmiss=0.7` æ—¶ï¼ŒMoPE æ¯” SplitNN* é«˜å‡ºè¿‘ **5 ä¸ªç™¾åˆ†ç‚¹**ï¼Œæ˜¾è‘—æå‡ã€‚

### ğŸ” ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”æ€»ç»“
- **å¯¹é½åœºæ™¯ï¼ˆ`pmiss=0`ï¼‰**ï¼šMoPE æ€§èƒ½ä¸ SplitNN*/LASER* ç›¸å½“ï¼Œè¾¾åˆ° SOTA æ°´å¹³ã€‚
- **é«˜ç¼ºå¤±åœºæ™¯ï¼ˆ`pmiss > 0.5`ï¼‰**ï¼šMoPE æ˜¾è‘—é¢†å…ˆï¼Œå°¤å…¶åœ¨è¡¨æ ¼æ•°æ®ä¸Šä¼˜åŠ¿æ˜æ˜¾ã€‚
- **æç«¯ç¼ºå¤±ï¼ˆ`pmiss â†’ 1`ï¼‰**ï¼šMoPE æ€§èƒ½è¶‹è¿‘äº Local æ¨¡å‹ï¼Œæ»¡è¶³ **Local Robustness** è¦æ±‚ï¼Œè€Œå…¶ä»–æ–¹æ³•å¯èƒ½ä½äº Localã€‚

### ğŸ§ª æ¶ˆèå®éªŒä¸å…³é”®åˆ†æ

#### ï¼ˆ1ï¼‰å†»ç»“é¢„è®­ç»ƒç¼–ç å™¨çš„æœ‰æ•ˆæ€§ï¼ˆTable 1ï¼‰
| æ–¹æ³• | CIFAR-100 (`pmiss=0`) |
|------|-----------------------|
| LASER (end-to-end) | 59.98 |
| **LASER*** (frozen) | **95.42** âœ… |
| SplitNN (end-to-end) | 47.55 |
| **SplitNN*** (frozen) | **95.61** âœ… |

> ç»“è®ºï¼š**å†»ç»“é¢„è®­ç»ƒç¼–ç å™¨ + å•è½®é€šä¿¡** ä¸ä»…å¤§å¹…é™ä½é€šä¿¡æˆæœ¬ï¼Œåè€Œæ˜¾è‘—æå‡æ€§èƒ½ï¼Œæ‰“ç ´â€œå¿…é¡»å¾®è°ƒâ€çš„å›ºæœ‰è®¤çŸ¥ã€‚

#### ï¼ˆ2ï¼‰å¯¹æŠ—å™ªå£°/æ¶æ„å‚ä¸è€…çš„é²æ£’æ€§ï¼ˆTable 3ï¼‰
åœ¨æ·»åŠ å™ªå£°å‚ä¸è€…ï¼ˆembedding ~ N(0,100)ï¼‰åï¼Œæ€§èƒ½ä¸‹é™ï¼ˆÎ”â†“ï¼‰è¶Šå°è¶Šå¥½ï¼š

| æ–¹æ³• \ å™ªå£°æ•° | 1 noisy (CIFAR-10) | 5 noisy (CIFAR-10) |
|--------------|--------------------|--------------------|
| SplitNN*     | 3.05               | 5.92               |
| LASER*       | 3.76               | 22.31              |
| **MoPE**     | **0.35** âœ…        | **3.53** âœ…        |

> MoPE åœ¨å¤šæ•°æƒ…å†µä¸‹æ€§èƒ½ä¸‹é™æœ€å°ï¼Œ**æœ€å¤šå‡å°‘ 25Ã— çš„é€€åŒ–**ï¼Œè¡¨ç°å‡ºæå¼ºé²æ£’æ€§ã€‚

#### ï¼ˆ3ï¼‰è·¯ç”±æƒé‡åˆ†æï¼ˆTable 4ï¼‰
- MoPE çš„ **router èƒ½æœ‰æ•ˆè¯†åˆ«å™ªå£°è¾“å…¥**ï¼Œå°†å…¶å¯¹åº”ä¸“å®¶çš„æƒé‡é™è‡³æ¥è¿‘ 0ã€‚
- å¯å®ç° **per-sample è´¡çŒ®åº¦åˆ†æ**ï¼Œæ”¯æŒå…¬å¹³æ¿€åŠ±æœºåˆ¶è®¾è®¡ã€‚

#### ï¼ˆ4ï¼‰æ›´å¤§ç¼–ç å™¨å¸¦æ¥æ›´å¼ºé²æ£’æ€§ï¼ˆTable 5ï¼‰
| ç¼–ç å™¨ | CIFAR-10 (`pmiss=0â†’0.7`) Î”â†“ | BCW (`pmiss=0â†’0.7`) Î”â†“ |
|--------|-------------------------------|--------------------------|
| ViT-S (21M) | -3.65 pts | -11.17 pts |
| ViT-L (300M) | -2.07 pts | -2.67 pts âœ… |

> æ›´å¤§çš„é¢„è®­ç»ƒæ¨¡å‹ä¸ä»…æ€§èƒ½æ›´é«˜ï¼Œ**å¯¹æ•°æ®ç¼ºå¤±ä¹Ÿæ›´é²æ£’**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **MoPE æ¶æ„èƒ½æœ‰æ•ˆåº”å¯¹æ ·æœ¬ä¸å¯¹é½é—®é¢˜**ï¼Œåœ¨å„ç§ `pmiss` ä¸‹å‡ä¼˜äºç°æœ‰ SOTA æ–¹æ³•ã€‚
2. **å†»ç»“é¢„è®­ç»ƒç¼–ç å™¨ + å•è½®é€šä¿¡** æ˜¯é«˜æ•ˆä¸”é«˜æ€§èƒ½çš„VFLèŒƒå¼ï¼Œé¢ è¦†ä¼ ç»Ÿç«¯åˆ°ç«¯è®­ç»ƒé€»è¾‘ã€‚
3. **MoPE å¤©ç„¶å…·å¤‡é²æ£’æ€§ä¸å¯è§£é‡Šæ€§**ï¼š
   - Router è‡ªåŠ¨æŠ‘åˆ¶å™ªå£°è¾“å…¥å½±å“ã€‚
   - å¯é‡åŒ–æ¯ä¸ªå‚ä¸æ–¹çš„è´¡çŒ®ï¼Œå¢å¼ºä¿¡ä»»ä¸å…¬å¹³æ€§ã€‚
4. **æ›´å¤§çš„é¢„è®­ç»ƒç¼–ç å™¨ä¸ä»…èƒ½ææ€§èƒ½ï¼Œè¿˜èƒ½å¢å¼ºå¯¹ç¼ºå¤±æ•°æ®çš„å®¹å¿åº¦**ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- å½“å‰å®éªŒé›†ä¸­åœ¨ **ä¸¤æ–¹åä½œ**ï¼Œæ‰©å±•åˆ°æ›´å¤šå‚ä¸æ–¹æ—¶ï¼Œ`P(K)` ç»„åˆæ•°æŒ‡æ•°å¢é•¿ï¼Œå¯èƒ½å¯¼è‡´ä¸“å®¶æ•°é‡è¿‡å¤šã€‚
- MoPE çš„ **expert æ•°é‡ç”±æ•°æ®å¯¹é½æ¨¡å¼å†³å®š**ï¼Œåœ¨æç«¯ç¨€ç–åœºæ™¯ä¸‹å¯èƒ½é¢ä¸´è®¡ç®—æˆ–å†…å­˜å‹åŠ›ã€‚
- è·¯ç”±æœºåˆ¶åœ¨å™ªå£°æ¯”ä¾‹æé«˜æ—¶å¯èƒ½å‡ºç°æ¬¡ä¼˜åŠ æƒï¼ˆå¦‚ç­‰æƒåˆ†é…æœ‰æ•ˆä¸“å®¶ï¼‰ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. æ¢ç´¢ **æ›´é«˜æ•ˆçš„ MoPE è®­ç»ƒç­–ç•¥**ï¼Œå¦‚ä¸“å®¶å…±äº«ã€ç¨€ç–æ¿€æ´»ç­‰ã€‚
2. å°† Split-MoPE åº”ç”¨äº **å¼‚æ„å¤šæ¨¡æ€è”é‚¦å­¦ä¹ **ï¼ˆå¦‚å›¾åƒ+æ–‡æœ¬+è¡¨æ ¼ï¼‰ï¼Œç ”ç©¶è·¯ç”±å¦‚ä½•æƒè¡¡ä¸åŒæ¨¡æ€ä»·å€¼ã€‚
3. è®¾è®¡ **åŠ¨æ€ä¸“å®¶å‰ªææˆ–åˆå¹¶æœºåˆ¶**ï¼Œä»¥åº”å¯¹å¤§è§„æ¨¡å‚ä¸è€…åœºæ™¯ã€‚
4. æ¢ç´¢åœ¨ **Horizontal FL æˆ– Hybrid FL** ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> **Split-MoPE** é€šè¿‡ **é¢„å®šä¹‰ä¸“å®¶ + å†»ç»“ç¼–ç å™¨ + å•è½®é€šä¿¡**ï¼Œå®ç°äº†é«˜æ•ˆã€é²æ£’ã€å¯è§£é‡Šçš„ VFL æ–°èŒƒå¼ï¼Œåœ¨æ ·æœ¬ä¸å…¨å¯¹é½çš„çœŸå®åœºæ™¯ä¸­æ˜¾è‘—è¶…è¶Šç°æœ‰æ–¹æ³•ã€‚

</details>

---

### 11. [WebClipper: Efficient Evolution of Web Agents with Graph-based Trajectory Pruning](https://arxiv.org/abs/2602.12852)

**Authors**: Junjie Wang, Zequn Xie, Dan Yang, Jie Feng, Yue Shen, Duolin Sun, Meixiu Long, Yihan Jiao, Zhehao Tan, Jian Wang, Peng Wei, Jinjie Gu  
**Category**: cs.AI  
**Published**: 2026-02-16  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.12852v1  

#### Abstract
Deep Research systems based on web agents have shown strong potential in solving complex information-seeking tasks, yet their search efficiency remains underexplored. We observe that many state-of-the-art open-source web agents rely on long tool-call trajectories with cyclic reasoning loops and expl...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šWebClipper: Efficient Evolution of Web Agents with Graph-based Trajectory Pruning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰åŸºäº **web agent** çš„ Deep Research ç³»ç»Ÿåœ¨å¤æ‚ä¿¡æ¯æ£€ç´¢ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†æ™®éå­˜åœ¨**æœç´¢æ•ˆç‡ä½ä¸‹**çš„é—®é¢˜ã€‚è®¸å¤šå¼€æº web agent ä¾èµ–å†—é•¿çš„å·¥å…·è°ƒç”¨è½¨è¿¹ï¼ˆtool-call trajectoriesï¼‰ï¼Œå­˜åœ¨ä»¥ä¸‹ä½æ•ˆæ¨¡å¼ï¼š
- **å¾ªç¯æ¨ç†ï¼ˆcyclic reasoning loopsï¼‰**ï¼šåå¤éªŒè¯å·²è·å–çš„ä¿¡æ¯ã€‚
- **æ— æ•ˆåˆ†æ”¯æ¢ç´¢ï¼ˆunproductive branchesï¼‰**ï¼šåç¦»æ­£ç¡®è§£è·¯å¾„ï¼Œé™·å…¥æ— å…³ç»†èŠ‚ã€‚

è¿™äº›è¡Œä¸ºå¯¼è‡´å·¥å…·è°ƒç”¨è½®æ¬¡ï¼ˆtool-call roundsï¼‰å’Œä¸Šä¸‹æ–‡é•¿åº¦æ¿€å¢ï¼Œæ˜¾è‘—å¢åŠ æ¨ç†å»¶è¿Ÿå’Œæˆæœ¬ï¼ˆå¦‚ Google Searchã€Jina Reader ç­‰å•†ä¸šå·¥å…·è´¹ç”¨é«˜æ˜‚ï¼‰ï¼Œå½±å“å®é™…ç”¨æˆ·ä½“éªŒã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
ä½œè€…æå‡º **WebClipper**ï¼Œä¸€ç§é€šè¿‡**åŸºäºå›¾çš„è½¨è¿¹å‰ªæï¼ˆgraph-based trajectory pruningï¼‰** æ¥é«˜æ•ˆæ¼”è¿› web agent çš„æ¡†æ¶ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°† agent çš„æœç´¢è¿‡ç¨‹å»ºæ¨¡ä¸º**çŠ¶æ€å›¾ï¼ˆstate graphï¼‰**ï¼Œå¹¶å°†è½¨è¿¹ä¼˜åŒ–å½¢å¼åŒ–ä¸º**æœ€å°å¿…è¦æœ‰å‘æ— ç¯å›¾ï¼ˆMinimum-necessary DAG, MNDAGï¼‰æŒ–æ˜é—®é¢˜**ã€‚

#### WebClipper æ¡†æ¶åŒ…å«å››ä¸ªå…³é”®æ­¥éª¤ï¼š
1. **Trajectory to State-Graph Transformation**  
   å°†åŸå§‹è½¨è¿¹è½¬æ¢ä¸ºçŠ¶æ€å›¾ï¼Œå…¶ä¸­èŠ‚ç‚¹åˆ†ä¸ºä¸¤ç±»ï¼š
   - **Action Nodes**ï¼šè¡¨ç¤º agent çš„æ€è€ƒä¸åŠ¨ä½œï¼ˆå¦‚ `SEARCH`, `VISIT`, `PYTHON`, `ANSWER`ï¼‰ã€‚
   - **Information Nodes**ï¼šè¡¨ç¤ºä»ç¯å¢ƒä¸­è·å¾—çš„åŸå­ä¿¡æ¯ï¼ˆå¦‚æŸ¥è¯¢ã€ç½‘é¡µå†…å®¹ã€è®¡ç®—ç»“æœï¼‰ã€‚
   è¾¹è¡¨ç¤ºåŠ¨ä½œä¸ä¿¡æ¯ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚

2. **Pruning via MNDAG**  
   åœ¨çŠ¶æ€å›¾ä¸Šè¿è¡Œæœ€çŸ­è·¯å¾„ç®—æ³•ï¼ˆDijkstra-styleï¼‰å¹¶è¿›è¡Œåå‘é—­åŒ…éå†ï¼Œæå–è¿æ¥åˆå§‹æŸ¥è¯¢èŠ‚ç‚¹ï¼ˆIoï¼‰åˆ°æœ€ç»ˆç­”æ¡ˆèŠ‚ç‚¹ï¼ˆAâ‚œï¼‰çš„**æœ€å°å¿…è¦å­å›¾ï¼ˆMNDAGï¼‰**ï¼Œä»è€Œç§»é™¤æ‰€æœ‰ä¸è´¡çŒ®äºæœ€ç»ˆç­”æ¡ˆçš„å†—ä½™æ­¥éª¤ã€‚

3. **Coherence-aware Thought Rewriting**  
   å¯¹å‰ªæåçš„è½¨è¿¹è¿›è¡Œè¯­ä¹‰è¿è´¯æ€§é‡å†™ï¼Œç¡®ä¿ ReAct é£æ ¼çš„â€œè§‚å¯Ÿ-æ€è€ƒ-è¡ŒåŠ¨â€å¾ªç¯é€»è¾‘è¿ç»­ã€‚é‡‡ç”¨ä¸¤ç§ç­–ç•¥ï¼š
   - **Context-aware selective rewriting**ï¼šä»…é‡å†™å› å‰ªæè€Œæ–­å¼€é€»è¾‘é“¾çš„æ€è€ƒã€‚
   - **Perplexity-based selection**ï¼šç”± base model è‡ªèº«é€‰æ‹©å›°æƒ‘åº¦ï¼ˆPPLï¼‰æœ€ä½çš„é‡å†™ç‰ˆæœ¬ï¼Œä»¥ä¿æŒæ¨ç†é£æ ¼ä¸€è‡´æ€§ã€‚

4. **Agent Evolution via Hybrid Training**  
   åŸºäºå‰ªæåçš„é«˜è´¨é‡è½¨è¿¹å¯¹åŸ agent è¿›è¡Œæ¼”åŒ–è®­ç»ƒï¼Œæå‡ºä¸¤ç§ç­–ç•¥ï¼š
   - **Efficiency-oriented evolution**ï¼šä»…åœ¨å‰ªæè½¨è¿¹ä¸Šå¾®è°ƒï¼Œæœ€å¤§åŒ–æ•ˆç‡ã€‚
   - **Hybrid evolution**ï¼šæ··åˆä½¿ç”¨å‰ªæè½¨è¿¹ä¸æœªå‰ªæä½†é«˜éš¾åº¦çš„è½¨è¿¹ï¼Œå¹³è¡¡æ•ˆç‡ä¸å‡†ç¡®æ€§ã€‚

æ­¤å¤–ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªæ–°çš„ç»¼åˆè¯„ä¼°æŒ‡æ ‡ **F-AE Score**ï¼Œç”¨äºè¡¡é‡æ¨¡å‹åœ¨**å‡†ç¡®æ€§ï¼ˆAccuracyï¼‰ä¸æ•ˆç‡ï¼ˆEfficiencyï¼‰ä¹‹é—´çš„å¹³è¡¡èƒ½åŠ›**ï¼Œå®šä¹‰å¦‚ä¸‹ï¼š

$$
\text{F-AE} = 2 \times \frac{\text{Acc} \times (1 - \frac{\text{Rounds}}{\text{Max\_Rounds}})}{\text{Acc} + (1 - \frac{\text{Rounds}}{\text{Max\_Rounds}})}
$$

è¯¥æŒ‡æ ‡å€Ÿé‰´ F1-score æ€æƒ³ï¼Œä½¿ç”¨è°ƒå’Œå¹³å‡æ•°é¿å…å•ä¸€ç»´åº¦è¢«è¿‡åº¦ä¼˜åŒ–ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | ç¼ºé™· | WebClipper çš„ä¼˜åŠ¿ |
|------|------|------------------|
| **Prompt Control**ï¼ˆæç¤ºå·¥ç¨‹æ§åˆ¶ï¼‰ | æ•ˆæœæœ‰é™ï¼Œéš¾ä»¥çº¦æŸå¤æ‚è¡Œä¸º | æ˜¾è‘—å‡å°‘å·¥å…·è°ƒç”¨ä¸”ä¸ç‰ºç‰²å‡†ç¡®ç‡ |
| **Coarse Prune**ï¼ˆç²—ç²’åº¦å‰ªæï¼‰ | å•ä¸€ LLM åˆ¤æ–­æ˜“å‡ºé”™ï¼Œå¯¼è‡´æ€§èƒ½å¤§å¹…ä¸‹é™ | å›¾ç»“æ„åˆ†ææ›´ç²¾ç»†å¯é ï¼Œä¿ç•™å…³é”®è·¯å¾„ |
| **ç›´æ¥æ‰©å¤§ context å’Œ depth**ï¼ˆå¦‚ Tongyi-DeepResearchï¼‰ | æˆæœ¬é«˜ã€æ•ˆç‡ä½ | åœ¨ä¿æŒç”šè‡³æå‡å‡†ç¡®ç‡çš„åŒæ—¶é™ä½çº¦ 20% å·¥å…·è°ƒç”¨ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
å®éªŒåœ¨å››ä¸ªä¸»æµ web agent benchmark ä¸Šè¿›è¡Œï¼š
- **xbench-deepsearch**ï¼šæ·±åº¦ç ”ç©¶ç±»ä»»åŠ¡åŸºå‡†ã€‚
- **Browsecomp**ï¼šæµè§ˆä»£ç†æŒ‘æˆ˜æ€§åŸºå‡†ã€‚
- **GAIA**ï¼šé€šç”¨ AI åŠ©æ‰‹ç»¼åˆèƒ½åŠ›è¯„æµ‹é›†ï¼ˆä½¿ç”¨ dev set ä¸­çš„ 103 ä¸ªçº¯æ–‡æœ¬æ ·æœ¬ï¼‰ã€‚
- **HLE**ï¼ˆHumanity's Last Examï¼‰ï¼šé«˜éš¾åº¦å¤šè·³æ¨ç†ä»»åŠ¡ï¼ˆä½¿ç”¨ 500 ä¸ªçº¯æ–‡æœ¬å­é›†ï¼‰ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Accuracy (Acc)** | ä½¿ç”¨ `o3-mini` ä½œä¸º LLM-as-Judge åˆ¤å®šå›ç­”æ˜¯å¦æ­£ç¡® |
| **Tool-call Rounds â†“** | æ¨ç†è¿‡ç¨‹ä¸­ä½¿ç”¨çš„å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼ˆè¶Šå°‘è¶Šå¥½ï¼‰ |
| **Token Consumption â†“** | æ¨ç†é˜¶æ®µæ€» token æ•°é‡ï¼ˆè¶Šå°‘è¶Šå¥½ï¼‰ |
| **F-AE Score â†‘** | æ–°æå‡ºçš„ç»¼åˆæŒ‡æ ‡ï¼Œå¹³è¡¡ accuracy ä¸ efficiency |

> Max_Rounds è®¾ä¸º 100ï¼Œç¬¦åˆ Deep Research ç±»ç³»ç»Ÿçš„å…¸å‹ä¸Šé™ã€‚

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Closed-source Systems**ï¼š
  - OpenAI o3
  - OpenAI DeepResearch
  - Claude-4-Sonnet
- **Open-source Agents**ï¼š
  - Kimi-K2-Instruct-0905
  - DeepSeek-R1-671B
  - Qwen3-235B-A22B-Instruct-2507
  - WebExplorer
  - Tongyi-DeepResearchï¼ˆåŸºç¡€æ¨¡å‹ï¼‰
- **Pruning Baselines**ï¼ˆæœ¬æ–‡è®¾è®¡ï¼‰ï¼š
  - **Prompt Control**ï¼šåœ¨ç³»ç»Ÿæç¤ºä¸­åŠ å…¥â€œé¿å…é‡å¤æ“ä½œâ€ç­‰æŒ‡ä»¤ã€‚
  - **Coarse Prune**ï¼šç”¨ Qwen3 ç›´æ¥è¯†åˆ«å¹¶åˆ é™¤å†—ä½™å¯¹è¯è½®æ¬¡åè¿›è¡Œ SFTã€‚

#### å®ç°ç»†èŠ‚
- **Base Agent**: Tongyi-DeepResearch (30B-A3B)
- **Extractor & Rewriter**: Qwen3-235B-A22B-Instruct-2507
- **Training Platform**: 32 Ã— H800 GPUs
- **Learning Rate**: 5e-6ï¼Œcosine decay
- **Web Tools**: Serper APIï¼ˆæœç´¢ï¼‰ã€Jina Readerï¼ˆURL è§£æï¼‰
- **æ¯æ¨¡å‹è¿è¡Œä¸‰æ¬¡å–å¹³å‡å€¼**ï¼Œé™ä½æ–¹å·®ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| æ–¹æ³• | xbench-deepsearch (Acc/F-AE/Rounds) | Browsecomp (Acc/F-AE/Rounds) | GAIA (Acc/F-AE/Rounds) | HLE (Acc/F-AE/Rounds) |
|------|-------------------------------|--------------------------|--------------------|------------------|
| **Tongyi-DeepResearch** | 0.713 / 0.779 / 14.26 | 0.410 / 0.385 / 63.70 | 0.682 / 0.733 / 20.56 | 0.358 / 0.487 / 23.92 |
| **WebClipper (Eff)** | **0.713** / **0.792** / **10.81** | **0.427** / **0.431** / **56.50** | **0.684** / **0.760** / **14.44** | 0.353 / 0.492 / 18.60 |
| **WebClipper (Hybrid)** | **0.733** / **0.797** / 12.57 | **0.467** / **0.428** / 60.42 | **0.695** / 0.744 / 19.92 | **0.361** / **0.495** / 21.07 |

> âœ… **åŠ ç²—** è¡¨ç¤ºä¼˜äºåŸºçº¿ï¼›â†‘ è¶Šé«˜è¶Šå¥½ï¼Œâ†“ è¶Šä½è¶Šå¥½ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ç›¸æ¯” Tongyi-DeepResearch åŸºçº¿**ï¼š
  - **å·¥å…·è°ƒç”¨è½®æ¬¡å¹³å‡å‡å°‘çº¦ 20%**ï¼ˆæœ€é«˜è¾¾ 30%ï¼Œå°¤å…¶åœ¨ GAIA ä¸Šï¼‰ã€‚
  - **token æ¶ˆè€—é™ä½çº¦ 19.4%**ã€‚
  - **å‡†ç¡®ç‡æŒå¹³æˆ–æå‡**ï¼ˆHybrid ç‰ˆæœ¬å¹³å‡æå‡ 4.8%ï¼‰ã€‚
  - **F-AE Score å…¨é¢é¢†å…ˆ**ï¼Œè¯æ˜å…¶åœ¨ accuracy-efficiency trade-off ä¸Šè¡¨ç°æœ€ä¼˜ã€‚

- **ç›¸æ¯”å…¶ä»–å‰ªææ–¹æ³•**ï¼š
  - **Prompt Control**ï¼šä»…ç•¥å¾®å‡å°‘è½®æ¬¡ï¼ˆ12.50 vs 14.26ï¼‰ï¼Œä½†å‡†ç¡®ç‡ä¸‹é™æ˜æ˜¾ï¼ˆ0.676 vs 0.713ï¼‰ã€‚
  - **Coarse Prune**ï¼šè™½èƒ½å‡å°‘è½®æ¬¡ï¼ˆ8.85ï¼‰ï¼Œä½†å‡†ç¡®ç‡ä¸¥é‡å—æŸï¼ˆ0.603ï¼‰ï¼Œè¯´æ˜ç²—ç²’åº¦å‰ªæä¸å¯é ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ï¼ˆ1ï¼‰ç»„ä»¶æœ‰æ•ˆæ€§ï¼ˆFigure 4ï¼‰
| å˜ä½“ | æè¿° | å½±å“ |
|------|------|------|
| **w/o GP**ï¼ˆæ— å›¾å‰ªæï¼‰ | æ›¿æ¢ä¸º Coarse Prune | å‡†ç¡®ç‡æ˜¾è‘—ä¸‹é™ â†’ å›¾ç»“æ„åˆ†æè‡³å…³é‡è¦ |
| **w/o PPL-S**ï¼ˆæ— å›°æƒ‘åº¦ç­›é€‰ï¼‰ | ä¸åš PPL é€‰æ‹© | æ€§èƒ½ä¸‹é™ â†’ PPL æœ‰åŠ©äºä¿æŒæ¨ç†é£æ ¼ä¸€è‡´ |
| **w/o CSR**ï¼ˆæ— ä¸Šä¸‹æ–‡æ„ŸçŸ¥é‡å†™ï¼‰ | æ— æ¡ä»¶é‡å†™æ‰€æœ‰æ€è€ƒ | **ç¾éš¾æ€§å´©æºƒ** â†’ è¯­ä¹‰è¿è´¯æ€§å¿…é¡»ä¿éšœ |

> ç»“è®ºï¼šä¸‰ä¸ªæ¨¡å—å‡ä¸å¯æˆ–ç¼ºï¼Œå°¤å…¶æ˜¯ **coherence-aware rewriting** æ˜¯æˆåŠŸçš„å…³é”®ã€‚

#### ï¼ˆ2ï¼‰è®­ç»ƒç­–ç•¥æ¯”è¾ƒï¼ˆTable 2ï¼‰
| ç­–ç•¥ | Acc | Rounds | F-AE |
|------|-----|--------|------|
| **Unpruned-Distill** | æœ€é«˜ï¼ˆ0.746ï¼‰ | æœ€é«˜ï¼ˆ17.13ï¼‰ | ä¸­ç­‰ï¼ˆ0.785ï¼‰ |
| **WebClipper (Eff)** | æŒå¹³ï¼ˆ0.713ï¼‰ | æœ€ä½ï¼ˆ10.81ï¼‰ | æœ€é«˜ï¼ˆ0.792ï¼‰ |
| **WebClipper (Hybrid)** | æ›´é«˜ï¼ˆ0.733ï¼‰ | åˆç†ï¼ˆ12.57ï¼‰ | **æœ€é«˜ï¼ˆ0.797ï¼‰** |

> **Hybrid ç­–ç•¥å®ç°äº†æœ€ä½³æƒè¡¡**ï¼šæ—¢æå‡äº† accuracyï¼Œåˆæ§åˆ¶äº† roundsï¼Œé€‚åˆå®é™…éƒ¨ç½²ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **web agent å­˜åœ¨å¤§é‡å¯å‰ªæçš„å†—ä½™è¡Œä¸º**ï¼Œå¦‚å¾ªç¯éªŒè¯ã€è¿‡åº¦æ¢ç´¢æ— å…³ä¿¡æ¯ã€‚
2. **å°†è½¨è¿¹å»ºæ¨¡ä¸ºçŠ¶æ€å›¾å¹¶æŒ–æ˜ MNDAG æ˜¯æœ‰æ•ˆçš„å‰ªææ–¹å¼**ï¼Œèƒ½ç²¾å‡†è¯†åˆ«å¹¶å»é™¤å†—ä½™æ­¥éª¤ã€‚
3. **åŸºäºå‰ªæè½¨è¿¹ç»§ç»­è®­ç»ƒå¯ä½¿ agent å‘æ›´é«˜æ•ˆçš„æœç´¢æ¨¡å¼æ¼”åŒ–**ï¼Œå®ç°â€œè¿›åŒ–â€è€Œéé‡å»ºã€‚
4. **F-AE Score æ˜¯ä¸€ä¸ªåˆç†ä¸”å®ç”¨çš„ç»¼åˆè¯„ä»·æŒ‡æ ‡**ï¼Œæœ‰æ•ˆé˜²æ­¢åªè¿½æ±‚ accuracy æˆ– efficiency çš„æç«¯å€¾å‘ã€‚
5. **WebClipper åœ¨å¤šä¸ª benchmark ä¸Šå®ç°äº†æ•ˆç‡ä¸å‡†ç¡®æ€§çš„åŒé‡æå‡**ï¼Œå°¤å…¶åœ¨ GAIA ä¸Š tool-call å‡å°‘è¿‘ 30%ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ– base model çš„åˆå§‹èƒ½åŠ›**ï¼šè‹¥ base model æœ¬èº«è§„åˆ’èƒ½åŠ›å¼±ï¼Œå‰ªæåªèƒ½åœ¨å…¶å†…éƒ¨å»å†—ï¼Œæ— æ³•æ ¹æœ¬æ”¹è¿›ç­–ç•¥ã€‚
2. **æ³›åŒ–æ€§å—é™**ï¼šç›®å‰ä»…é’ˆå¯¹ search/browse/code æ‰§è¡Œç±»å·¥å…·ï¼Œå°šæœªæ‰©å±•è‡³å¤šæ¨¡æ€ã€æ•°æ®åº“æŸ¥è¯¢ã€API è°ƒç”¨ç­‰æ–°å‹ action spaceã€‚
3. **å›¾æ„å»ºä¾èµ– LLM extractor**ï¼šå­˜åœ¨ä¸€å®šçš„ä¸ç¨³å®šæ€§ï¼Œéœ€é€šè¿‡å¤šæ¬¡é‡‡æ ·+å¤šæ•°æŠ•ç¥¨ç¼“è§£ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **ç»“åˆå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æˆ–åœ¨çº¿å­¦ä¹ æœºåˆ¶**ï¼Œè®© agent ä¸»åŠ¨å‘ç°æ–°çš„é«˜æ•ˆè·¯å¾„ï¼Œè¶…è¶Šå·²æœ‰è½¨è¿¹çš„é™åˆ¶ã€‚
2. **æ‰©å±•å›¾æ¡†æ¶ä»¥æ”¯æŒå¤šæ ·åŒ–å·¥å…·ç±»å‹**ï¼Œæ„å»ºé€‚ç”¨äºæ›´å¹¿æ³›åº”ç”¨åœºæ™¯çš„é€šç”¨ agent å‹ç¼©æ¡†æ¶ã€‚
3. **æ¢ç´¢è‡ªåŠ¨åŒ–çš„ MNDAG æ„å»ºæ–¹æ³•**ï¼Œå‡å°‘å¯¹ LLM extractor çš„ä¾èµ–ï¼Œæé«˜é²æ£’æ€§å’Œå¯æ‰©å±•æ€§ã€‚

</details>

---

### 12. [Discovering Semantic Latent Structures in Psychological Scales: A Response-Free Pathway to Efficient Simplification](https://arxiv.org/abs/2602.12575)

**Authors**: Bo Wang, Yuxuan Zhang, Yueqin Hu, Hanchao Hou, Kaiping Peng, Shiguang Ni  
**Category**: cs.CL  
**Published**: 2026-02-16  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.12575v1  

#### Abstract
Psychological scale refinement traditionally relies on response-based methods such as factor analysis, item response theory, and network psychometrics to optimize item composition. Although rigorous, these approaches require large samples and may be constrained by data availability and cross-cultura...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDiscovering Semantic Latent Structures in Psychological Scales: A Response-Free Pathway to Efficient Simplification

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
ä¼ ç»Ÿå¿ƒç†é‡è¡¨ç®€åŒ–ï¼ˆscale simplificationï¼‰ä¾èµ–äº**response-based methods**ï¼ˆå¦‚ CFAã€EFAã€IRTã€network psychometricsï¼‰ï¼Œè¿™äº›æ–¹æ³•éœ€è¦å¤§é‡è¢«è¯•æ•°æ®ï¼Œå­˜åœ¨ä»¥ä¸‹ç“¶é¢ˆï¼š
- æ•°æ®è·å–æˆæœ¬é«˜ï¼Œå°¤å…¶åœ¨è·¨æ–‡åŒ–é€‚é…ã€æ—©æœŸå¼€å‘é˜¶æ®µï¼›
- æ˜“å—æ ·æœ¬åå·®ã€æµ‹é‡æƒ…å¢ƒå½±å“ï¼Œå¤ç°æ€§å·®ï¼›
- å¿½è§†äº†**itemæ–‡æœ¬æœ¬èº«è•´å«çš„è¯­ä¹‰ç»“æ„ä¿¡æ¯**ã€‚

è¯¥ç ”ç©¶æå‡ºï¼š**é‡è¡¨é¡¹ç›®çš„è¯­è¨€è¡¨è¾¾æœ¬èº«å°±ç¼–ç äº†æ½œåœ¨æ„å¿µçš„ç»„ç»‡ç»“æ„**ï¼Œå¯ä»¥åœ¨æ— ååº”æ•°æ®çš„å‰æä¸‹ï¼Œé€šè¿‡è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯æŒ–æ˜è¿™ç§â€œè¯­ä¹‰æ½œç»“æ„â€ï¼ˆsemantic latent structureï¼‰ï¼Œä¸ºé«˜æ•ˆã€ç†è®ºä¸€è‡´çš„é‡è¡¨ç®€åŒ–æä¾›æ–°è·¯å¾„ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æå‡ºäº†ä¸€ç§**å“åº”æ— å…³**ï¼ˆresponse-freeï¼‰ã€åŸºäºä¸»é¢˜å»ºæ¨¡çš„é‡è¡¨ç®€åŒ–æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæµç¨‹å¦‚ä¸‹ï¼š

1. **Encoding & Dimensionality Reduction**  
   ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯¹æ¯ä¸ªé¡¹ç›®ç”Ÿæˆ**contextual sentence embeddings**ï¼Œå¹¶ç”¨ UMAP è¿›è¡Œé™ç»´ã€‚

2. **Density-Based Clustering**  
   é‡‡ç”¨ **HDBSCAN** å¯¹åµŒå…¥å‘é‡è¿›è¡Œèšç±»ï¼Œè‡ªåŠ¨å‘ç°è¯­ä¹‰ç°‡ï¼ˆæ— éœ€é¢„è®¾å› å­æ•°ï¼‰ã€‚

3. **Topic Modeling**  
   åœ¨æ¯ä¸ªèšç±»å†…ï¼Œç»“åˆæ–‡æœ¬è¯é¢‘åˆ†æï¼ˆc-TF-IDFï¼‰ï¼Œæå–ä»£è¡¨æ€§å…³é”®è¯ï¼Œå½¢æˆå¯è§£é‡Šçš„â€œè¯­ä¹‰å› å­â€ï¼ˆsemantic factorsï¼‰ã€‚

4. **Hierarchical Merging & Representative Item Selection**  
   å°†è¯­ä¹‰ç›¸è¿‘çš„ç°‡åˆå¹¶ï¼Œå¹¶åŸºäº**è¯­ä¹‰éš¶å±æ¦‚ç‡**ï¼ˆmembership probabilityï¼‰é€‰æ‹©æœ€å…·ä»£è¡¨æ€§çš„é¡¹ç›®ä½œä¸ºç®€åŒ–ç‰ˆé‡è¡¨æ¡ç›®ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆCTT/FA/IRT/EGAï¼‰ | æœ¬æ–‡æ–¹æ³• |
|------|----------------------------|--------|
| æ˜¯å¦éœ€è¦ response data | âœ… æ˜¯ | âŒ å¦ |
| æ˜¯å¦å¯è§£é‡Š | é«˜ï¼ˆå› å­è½½è·ç­‰ï¼‰ | é«˜ï¼ˆè¯­ä¹‰ä¸»é¢˜+å…³é”®è¯ï¼‰ |
| æ˜¯å¦éœ€é¢„è®¾ç»´åº¦æ•° | é€šå¸¸éœ€è¦ | ä¸éœ€è¦ï¼ˆå¯†åº¦èšç±»è‡ªåŠ¨ç¡®å®šï¼‰ |
| æ˜¯å¦åˆ©ç”¨ item æ–‡æœ¬ä¿¡æ¯ | é—´æ¥ï¼ˆä»…ä½œæ ‡ç­¾ï¼‰ | ç›´æ¥ï¼ˆæ ¸å¿ƒè¾“å…¥ï¼‰ |
| é€‚ç”¨é˜¶æ®µ | åæœŸéªŒè¯ | æ—©æœŸè®¾è®¡ã€è·¨æ–‡åŒ–è¿ç§» |

> âœ… **æ ¸å¿ƒåˆ›æ–°**ï¼šé¦–æ¬¡å°†**è¯­ä¹‰æ½œç»“æ„**å½¢å¼åŒ–ä¸ºä¸€ä¸ªå¯æ“ä½œã€å¯æ£€éªŒçš„â€œå‰æµ‹é‡ç»“æ„â€ï¼ˆpre-structureï¼‰ï¼Œä¸º scale construction æä¾›é€æ˜ã€å¯å®¡è®¡çš„å‰ç«¯å·¥å…·ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
åœ¨ä¸‰ä¸ªå¹¿æ³›ä½¿ç”¨çš„å¿ƒç†é‡è¡¨ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œè¦†ç›–ä¸åŒæ„å¿µé¢†åŸŸå’Œè¯­è¨€ï¼š

| Scale | æ„å¿µé¢†åŸŸ | æ¡ç›®æ•° | å› å­æ•° | æ•°æ®æ¥æº | è¢«è¯•æ•° |
|-------|--------|--------|--------|----------|--------|
| **DASS** | Negative affect | 42 | 3 (Depression, Anxiety, Stress) | OpenPsychometrics.org | 39,775 |
| **IPIP** | Personality traits | 50 | 5 (Big Five) | OpenPsychometrics.org | 1,015,341* |
| **EPOCH-CN** | Well-being | 20 | 5 (Engagement, Perseverance, etc.) | Zeng et al. (2019) | 17,854 |

> *æ³¨ï¼šIPIP æ•°æ®ç”¨äºè¯„ä¼°æ—¶éšæœºæŠ½å– 20,000 ä¸ªæœ‰æ•ˆæ ·æœ¬ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### æ–¹æ³•è®ºè¯„ä¼°ï¼ˆMethodological Evidenceï¼‰
- **Alignment with theoretical factors**ï¼šä½¿ç”¨ **Adjusted Rand Index (ARI)** è¡¡é‡è¯­ä¹‰èšç±»ä¸ç†è®ºå› å­çš„ä¸€è‡´æ€§ã€‚
- **Information fidelity**ï¼š
  - å­é‡è¡¨ç›¸å…³çŸ©é˜µçš„ **Frobenius similarity**ï¼ˆè¡¡é‡ç»“æ„ä¿ç•™ç¨‹åº¦ï¼‰ï¼›
  - å…¨é‡è¡¨ä¸ç®€åŒ–ç‰ˆå­é‡è¡¨å¾—åˆ†çš„ **cross-form correlation**ï¼ˆæ”¶æ•›æ•ˆåº¦ï¼‰ã€‚

#### å¿ƒç†è®¡é‡å­¦è¯„ä¼°ï¼ˆPsychometric Evidenceï¼‰
- **ç»“æ„æ•ˆåº¦**ï¼šé€šè¿‡ **CFA** æ£€éªŒç®€åŒ–ç‰ˆæ˜¯å¦ä¿æŒåŸå¤šå› å­ç»“æ„ï¼ˆCFI, TLI, RMSEAï¼‰ã€‚
- **å†…éƒ¨ä¸€è‡´æ€§**ï¼šè®¡ç®— **Cronbachâ€™s Î±** å’Œ **corrected item-total correlation (CITC)**ã€‚
- **å¯è§†åŒ–**ï¼šä½¿ç”¨ **t-SNE** å¯è§†åŒ–è¯­ä¹‰ç©ºé—´ï¼Œå±•ç¤ºèšç±»ä¸å› å­å¯¹åº”å…³ç³»ã€‚

#### å‚æ•°è®¾ç½®
- **Embedding Model**: `qwen3-embedding-4b`ï¼ˆå¼€æº LLMï¼‰
- **Dimension Reduction**: UMAP (`n_neighbors=3`, `n_components=5`)
- **Clustering**: HDBSCAN (`min_cluster_size=2`, `min_samples=1`)
- **Topic Modeling**: BERTopicï¼ˆè‡ªåŠ¨æå–å…³é”®è¯ï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æœªç›´æ¥ä¸å•ä¸€åŸºçº¿å¯¹æ¯”ï¼Œè€Œæ˜¯ä»æ–¹æ³•è®ºç±»åˆ«ä¸Šå®šä½è‡ªèº«ä¼˜åŠ¿ï¼š

| æ–¹æ³•ç±»åˆ« | æ˜¯å¦éœ€è¦å“åº”æ•°æ® | å¯è§£é‡Šæ€§ | æ˜¯å¦å‡è®¾å›ºå®šç»´åº¦ |
|--------|------------------|---------|----------------|
| CTT/FA/IRT | âœ… | é«˜ | æ˜¯ |
| EGA | âœ… | ä¸­é«˜ | å¦ |
| Supervised ML | âœ… | ä½ | æ˜¯ |
| Fixed-K èšç±» | âŒ | ä¸­ | æ˜¯ |
| **æœ¬æ–‡æ–¹æ³•** | âŒ | **é«˜** | **å¦ï¼ˆå¯é€‰ï¼‰** |

> âœ… æœ¬æ–‡æ–¹æ³•æ˜¯å”¯ä¸€åŒæ—¶æ»¡è¶³â€œæ— å“åº”æ•°æ® + é«˜å¯è§£é‡Šæ€§ + è‡ªåŠ¨ç¡®å®šç»´åº¦â€çš„æ¡†æ¶ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰è¯­ä¹‰èšç±»ä¸ç†è®ºå› å­é«˜åº¦ä¸€è‡´
| Scale | ARI | ä¸»å¯¼å› å­åŒ¹é…ç‡ |
|-------|-----|---------------|
| DASS | 0.745 | 92.9% |
| IPIP | 0.855 | 96.0% |
| EPOCH-CN | **1.000** | 100% |

> è¡¨æ˜è¯­ä¹‰ç»“æ„èƒ½æœ‰æ•ˆæ¢å¤å·²çŸ¥æ„å¿µç»“æ„ï¼Œå°¤å…¶åœ¨è¯­ä¹‰è¾¹ç•Œæ¸…æ™°çš„é‡è¡¨ï¼ˆå¦‚ EPOCHï¼‰è¡¨ç°æä½³ã€‚

#### ï¼ˆ2ï¼‰ç®€åŒ–åé‡è¡¨ä¿æŒè‰¯å¥½å¿ƒç†è®¡é‡æ€§è´¨
| Scale | åŸæ¡ç›®æ•° | ç®€åŒ–åæ¡ç›®æ•° | å‡å°‘æ¯”ä¾‹ | æ€» Cronbachâ€™s Î± | CFA æ‹Ÿåˆï¼ˆCFI/TLI/RMSEAï¼‰ |
|-------|--------|------------|----------|----------------|-----------------------------|
| DASS | 42 | 12 | **71.4%** | 0.899 | 0.956 / 0.943 / 0.064 |
| IPIP | 50 | 20 | **60.0%** | 0.705 | 0.860 / 0.833 / 0.059 |
| EPOCH-CN | 20 | 10 | **50.0%** | 0.875 | 0.983 / 0.970 / 0.041 |

> âœ… æ‰€æœ‰ç®€åŒ–ç‰ˆå‡ä¼˜äºå•å› å­æ¨¡å‹ï¼Œä¸” CFI > 0.85ï¼Œè¡¨æ˜å¤šç»´ç»“æ„å¾—ä»¥ä¿ç•™ã€‚

#### ï¼ˆ3ï¼‰ç»“æ„ä¿¡æ¯é«˜åº¦ä¿ç•™
- **å­é‡è¡¨ç›¸å…³çŸ©é˜µç›¸ä¼¼åº¦**ï¼ˆNormalized Frobenius similarityï¼‰ï¼š
  - DASS: 0.889
  - IPIP: 0.872
  - EPOCH: 0.861
- **å…¨é‡è¡¨ vs ç®€åŒ–ç‰ˆå­é‡è¡¨å¾—åˆ†ç›¸å…³æ€§**ï¼ˆå¯¹è§’çº¿ï¼‰ï¼š
  - DASS: r â‰ˆ 0.92â€“0.95
  - IPIP: r â‰ˆ 0.87â€“0.93
  - EPOCH: r â‰ˆ 0.91â€“0.95

> è¡¨æ˜ç®€åŒ–ç‰ˆä¸ä»…ä¿ç•™å†…éƒ¨ç»“æ„ï¼Œè¿˜èƒ½å‡†ç¡®åæ˜ åŸå§‹æ„å¿µæ°´å¹³ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
è™½ç„¶æ²¡æœ‰ç›´æ¥è¿è¡Œå…¶ä»–æ–¹æ³•ï¼Œä½†ä½œè€…æŒ‡å‡ºï¼š
- ç›¸æ¯” **fixed-K clustering**ï¼ˆå¦‚ K-meansï¼‰ï¼Œæœ¬æ–‡æ–¹æ³•æ— éœ€é¢„è®¾ Kï¼Œé¿å…è¿‡åˆ†å‰²æˆ–æ¬ åˆ†å‰²ï¼›
- ç›¸æ¯” **supervised ML**ï¼ˆå¦‚ SVMã€Random Forestï¼‰ï¼Œæœ¬æ–‡æ–¹æ³•æ›´å…·ç†è®ºé€æ˜æ€§ï¼Œä¸ä¾èµ–é¢„æµ‹ç›®æ ‡ï¼›
- ç›¸æ¯” **response-based methods**ï¼Œæœ¬æ–‡å¯åœ¨æ— æ•°æ®æ—¶å¿«é€Ÿç”Ÿæˆå€™é€‰çŸ­è¡¨ï¼Œé™ä½å¼€å‘æˆæœ¬ã€‚

### æ¶ˆèå®éªŒç»“æœ
è¿›è¡Œäº†**å‚æ•°æ•æ„Ÿæ€§åˆ†æ**ï¼Œè€ƒå¯Ÿå…³é”®å‚æ•°å¯¹ç»“æœç¨³å®šæ€§çš„å½±å“ï¼š

#### ï¼ˆ1ï¼‰æ¯ä¸»é¢˜ä¿ç•™æ¡ç›®æ•°çš„å½±å“ï¼ˆIPIPï¼‰
| æ¯ä¸»é¢˜æ¡ç›®æ•° | CFI | TLI |
|-------------|-----|-----|
| 3 | 0.857 | 0.812 |
| **4** | **0.860** | **0.833** |
| 5 | 0.808 | 0.782 |
| 6 | 0.821 | 0.803 |
| â‰¥7 | â†“ ä¸‹é™ |

> âœ… ä¿ç•™ **3â€“4 æ¡ç›®/å› å­**å³å¯è·å¾—æœ€ä¼˜æ‹Ÿåˆï¼Œæ›´å¤šæ¡ç›®åè€Œå› å¼•å…¥è¾¹ç¼˜è¯­ä¹‰è€Œé™ä½ç»“æ„æ¸…æ™°åº¦ã€‚

#### ï¼ˆ2ï¼‰ä¸»é¢˜æ•°è®¾ç½®çš„å½±å“
- å½“è®¾å®š `topics=5`ï¼ˆä¸çœŸå®å› å­æ•°ä¸€è‡´ï¼‰æ—¶ï¼ŒCFA æ‹Ÿåˆæœ€ä½³ï¼ˆCFI=0.875ï¼‰ï¼›
- `nr_topics='auto'` ä¹Ÿèƒ½è¾¾åˆ°æ¥è¿‘æœ€ä¼˜æ•ˆæœï¼ˆCFI=0.857ï¼‰ï¼›
- è‹¥è®¾ä¸º 4ï¼Œå› é”™è¯¯åˆ†ç¦» OPN é¡¹ç›®å¯¼è‡´æ‹Ÿåˆä¸‹é™ã€‚

#### ï¼ˆ3ï¼‰å‚æ•°æ‰°åŠ¨ä¸‹çš„ç¨³å®šæ€§ï¼ˆJaccard Similarityï¼‰
| Scale | å¹³å‡ Jaccard | æœ€ä½ Jaccard |
|-------|--------------|-------------|
| DASS | ~0.50 | 0.20 |
| IPIP | ~0.45 | 0.25 |
| EPOCH | 0.429ï¼ˆç¨³å®šï¼‰ | 0.429 |

> è¡¨æ˜æ ¸å¿ƒä»£è¡¨é¡¹ç›®å…·æœ‰è¾ƒé«˜ç¨³å®šæ€§ï¼Œå°¤å…¶åœ¨è¯­ä¹‰æ¸…æ™°çš„é‡è¡¨ä¸­ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **è¯­ä¹‰æ½œç»“æ„æ˜¯çœŸå®å­˜åœ¨çš„**ï¼šä»…ä» item æ–‡æœ¬å³å¯æ¢å¤å‡ºä¸ç†è®ºå› å­é«˜åº¦ä¸€è‡´çš„è¯­ä¹‰èšç±»ï¼ˆARI è¾¾ 0.75â€“1.00ï¼‰ã€‚
2. âœ… **é«˜æ•ˆç®€åŒ–å¯è¡Œ**ï¼šå¹³å‡å‡å°‘ **60.5%** æ¡ç›®åï¼Œä»èƒ½ä¿æŒè‰¯å¥½çš„ç»“æ„æ•ˆåº¦ä¸å†…éƒ¨ä¸€è‡´æ€§ã€‚
3. âœ… **ç»“æ„ä¿¡æ¯å¾—ä»¥ä¿ç•™**ï¼šç®€åŒ–ç‰ˆä¸ä»…è¿˜åŸå› å­ç»“æ„ï¼Œè¿˜ä¿ç•™äº†å› å­é—´ç›¸å…³æ¨¡å¼ä¸å…¨é‡è¡¨å¾—åˆ†çš„é«˜åº¦ä¸€è‡´æ€§ã€‚
4. âœ… **æ–¹æ³•ç¨³å¥ä¸”å¯è§£é‡Šæ€§å¼º**ï¼šé€šè¿‡å…³é”®è¯ã€éš¶å±æ¦‚ç‡ã€å¯è§†åŒ–ç­‰æ–¹å¼ï¼Œä½¿ç®€åŒ–è¿‡ç¨‹é€æ˜å¯å®¡è®¡ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–è¯­è¨€è¡¨ç¤ºè´¨é‡**ï¼šä¸åŒ embedding model æˆ–è¯­è¨€å¯èƒ½å½±å“ç»“æœï¼›ç›®å‰ä»…éªŒè¯äº†ä¸­è‹±æ–‡ç‰ˆæœ¬ã€‚
2. **è¯­ä¹‰ â‰  æµ‹é‡ç­‰ä»·æ€§**ï¼šè¯­ä¹‰ç›¸è¿‘çš„é¡¹ç›®å¯èƒ½åœ¨éš¾åº¦ã€æç«¯æ€§ã€ååº”å€¾å‘ä¸Šä¸åŒã€‚
3. **åå‘è®¡åˆ†é¢˜éœ€é¢„å¤„ç†**ï¼šéœ€æ‰‹åŠ¨ç»Ÿä¸€è¡¨è¿°æ–¹å‘ï¼Œå¦åˆ™æ˜“å½¢æˆâ€œæ–¹æ³•èšç±»â€ã€‚
4. **è¶…å‚æ•°é€‰æ‹©ä»æœ‰è‡ªç”±åº¦**ï¼šå°½ç®¡æ¨èé»˜è®¤å€¼ï¼Œä½†å‚æ•°å˜åŒ–ä¼šå½±å“æœ€ç»ˆç»“æœï¼Œéœ€æŠ¥å‘Šå¹¶åšç¨³å®šæ€§æ£€æŸ¥ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **è·¨è¯­è¨€ä¸è·¨æ–‡åŒ–æ³›åŒ–ç ”ç©¶**ï¼šç³»ç»Ÿæ¯”è¾ƒå¤šè¯­è¨€é‡è¡¨çš„è¯­ä¹‰ç»“æ„ä¸€è‡´æ€§ï¼Œç»“åˆ measurement invariance åˆ†æã€‚
2. **äººæœºååŒç®€åŒ–æµç¨‹**ï¼šæ„å»ºâ€œç®—æ³•åˆç­› + ä¸“å®¶å®¡æ ¸ + æ•°æ®éªŒè¯â€çš„ä¸‰é˜¶æ®µ workflowã€‚
3. **ä¸ response-based æ–¹æ³•èåˆ**ï¼šæ¢ç´¢ semantic selection ä¸ IRT/EGA çš„è”åˆä¼˜åŒ–ç­–ç•¥ã€‚
4. **å¼€æ”¾å·¥å…·ç”Ÿæ€å»ºè®¾**ï¼šæ¨å¹¿ **One-Click Psychological Scale Simplification Tool**ï¼Œæ”¯æŒéç¼–ç¨‹ç”¨æˆ·ä½¿ç”¨ã€‚

---

> ğŸ¯ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡ºäº†ä¸€ç§**æ— éœ€è¢«è¯•æ•°æ®**çš„å¿ƒç†é‡è¡¨ç®€åŒ–æ–°èŒƒå¼ï¼Œé€šè¿‡æŒ–æ˜ item æ–‡æœ¬ä¸­çš„**è¯­ä¹‰æ½œç»“æ„**ï¼Œå®ç°äº†é«˜æ•ˆã€å¯è§£é‡Šã€ç†è®ºä¸€è‡´çš„çŸ­è¡¨æ„å»ºï¼Œä¸ºå¿ƒç†æµ‹é‡å­¦æä¾›äº†å¼ºå¤§çš„å‰ç«¯è®¾è®¡å·¥å…·ã€‚

</details>

---

### 13. [Closing the Loop: A Control-Theoretic Framework for Provably Stable Time Series Forecasting with LLMs](https://arxiv.org/abs/2602.12756)

**Authors**: Xingyu Zhang, Hanyun Du, Zeen Song, Jianqi Zhang, Changwen Zheng, Wenwen Qiang  
**Category**: cs.LG  
**Published**: 2026-02-16  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.12756v1  

#### Abstract
Large Language Models (LLMs) have recently shown exceptional potential in time series forecasting, leveraging their inherent sequential reasoning capabilities to model complex temporal dynamics. However, existing approaches typically employ a naive autoregressive generation strategy. We identify a c...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šClosing the Loop: A Control-Theoretic Framework for Provably Stable Time Series Forecasting with LLMs**

---

## 1. **è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### âœ… **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡é’ˆå¯¹å½“å‰åŸºäº **Large Language Models (LLMs)** çš„æ—¶é—´åºåˆ—é¢„æµ‹ï¼ˆTime Series Forecasting, TSFï¼‰ä¸­å­˜åœ¨çš„ä¸€ä¸ª**ç»“æ„æ€§ç¼ºé™·**ï¼š**Error Accumulationï¼ˆè¯¯å·®ç´¯ç§¯ï¼‰**ã€‚

- å½“å‰ä¸»æµçš„ LLM-based TSF æ–¹æ³•é‡‡ç”¨ **autoregressive generation**ï¼ˆè‡ªå›å½’ç”Ÿæˆï¼‰ç­–ç•¥ï¼Œåœ¨æ¨ç†é˜¶æ®µæ¨¡å‹é€’å½’åœ°å°†è‡ªå·±ç”Ÿæˆçš„è¾“å‡ºä½œä¸ºä¸‹ä¸€æ­¥è¾“å…¥ã€‚
- è¿™ç§â€œå¼€ç¯â€ï¼ˆopen-loopï¼‰æ¨¡å¼å¯¼è‡´æ—©æœŸå¾®å°çš„é¢„æµ‹åå·®åœ¨åç»­æ­¥éª¤ä¸­ä¸æ–­è¢«æ”¾å¤§ï¼Œå½¢æˆâ€œé›ªçƒæ•ˆåº”â€ï¼ˆsnowball effectï¼‰ï¼Œæœ€ç»ˆé€ æˆé¢„æµ‹è½¨è¿¹ä¸¥é‡åç¦»çœŸå®æ•°æ®æµå½¢ï¼Œå°¤å…¶åœ¨**é•¿æ—¶åŸŸé¢„æµ‹**ï¼ˆlong-horizon forecastingï¼‰ä¸­è¡¨ç°å°¤ä¸ºæ˜æ˜¾ã€‚
- æ­¤ç°è±¡æºäºè®­ç»ƒï¼ˆteacher forcingï¼‰ä¸æ¨ç†ï¼ˆfree-runningï¼‰ä¹‹é—´çš„åˆ†å¸ƒä¸ä¸€è‡´ï¼Œå³ **Exposure Bias**ã€‚

---

### ğŸš€ **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡ºäº†ä¸€ç§å…¨æ–°çš„æ¡†æ¶ â€”â€” **F-LLM (Feedback-driven LLM)**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†ä¼ ç»Ÿçš„å¼€ç¯é¢„æµ‹è¿‡ç¨‹é‡æ„ä¸ºä¸€ä¸ª**é—­ç¯æ§åˆ¶ï¼ˆclosed-loop controlï¼‰ç³»ç»Ÿ**ï¼Œå€Ÿé‰´ç»å…¸**æ§åˆ¶ç†è®º**ï¼ˆcontrol theoryï¼‰ä¸­çš„åé¦ˆæœºåˆ¶æ¥ä¸»åŠ¨æŠ‘åˆ¶è¯¯å·®ä¼ æ’­ã€‚

#### ä¸»è¦ç»„ä»¶åŒ…æ‹¬ï¼š

1. **Dynamical Plantï¼ˆåŠ¨æ€ç³»ç»Ÿä¸»ä½“ï¼‰**  
   - å³å†»ç»“çš„ LLM é¢„æµ‹å™¨ï¼Œè´Ÿè´£ç”ŸæˆåŸå§‹é¢„æµ‹å€¼ã€‚
   
2. **State Observerï¼ˆçŠ¶æ€è§‚æµ‹å™¨ï¼‰**  
   - ä¸€ä¸ªè½»é‡çº§çš„ **Residual Estimator**ï¼Œç”¨äºä¼°è®¡å½“å‰æ­¥çš„é¢„æµ‹æ®‹å·®ï¼ˆå³è¯¯å·®ï¼‰ï¼Œå› ä¸ºçœŸå®è¯¯å·®åœ¨æ¨ç†æ—¶ä¸å¯è§ï¼ˆæ—  ground truthï¼‰ã€‚
   
3. **Feedback Controllerï¼ˆåé¦ˆæ§åˆ¶å™¨ï¼‰**  
   - å°†ä¼°è®¡çš„æ®‹å·®æ³¨å…¥åˆ°ä¸‹ä¸€æ—¶åˆ»çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œå¯¹é¢„æµ‹è¿›è¡Œå®æ—¶æ ¡æ­£ï¼Œå®ç°â€œ**in-loop correction**â€ã€‚

æ­¤å¤–ï¼Œä¸ºäº†ä¿è¯ç³»ç»Ÿçš„ç¨³å®šæ€§ï¼Œä½œè€…å¼•å…¥äº† **Local Lipschitz Constraint** æ¥çº¦æŸ LLM è¾“å‡ºå¯¹è¾“å…¥æ‰°åŠ¨çš„æ•æ„Ÿåº¦ï¼Œç¡®ä¿å…¶å¤„äºå¯è¢«çº¿æ€§åé¦ˆæ§åˆ¶çš„èŒƒå›´å†…ã€‚

---

### ğŸ” **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | F-LLM | ä¼ ç»Ÿ LLM4TS æ–¹æ³•ï¼ˆå¦‚ AutoTimesã€Time-LLMï¼‰ |
|------|-------|----------------------------------------|
| **æ¨ç†æœºåˆ¶** | é—­ç¯åé¦ˆï¼ˆclosed-loopï¼‰ | å¼€ç¯è‡ªå›å½’ï¼ˆopen-loopï¼‰ |
| **è¯¯å·®å¤„ç†** | ä¸»åŠ¨çº æ­£ï¼ˆactive error rejectionï¼‰ | è¢«åŠ¨ä¼ æ’­ï¼ˆerror accumulationï¼‰ |
| **ç†è®ºä¿éšœ** | æä¾› **uniformly bounded error** çš„æ•°å­¦è¯æ˜ | ç¼ºä¹ç¨³å®šæ€§ç†è®ºåˆ†æ |
| **æ¨¡å—è®¾è®¡** | å¯æ’æ‹”å¼è½»é‡åé¦ˆæ¨¡å—ï¼ˆæ— éœ€ä¿®æ”¹ LLM æƒé‡ï¼‰ | é€šå¸¸éœ€è°ƒæ•´ LLM æˆ–æ·»åŠ é¢å¤–å‚æ•° |
| **é›¶æ ·æœ¬èƒ½åŠ›ä¿ç•™** | æ”¯æŒ zero-shot è·¨åŸŸè¿ç§»ä¸”æ€§èƒ½æ›´ä¼˜ | é›¶æ ·æœ¬æ€§èƒ½å­˜åœ¨æ¼‚ç§»é£é™© |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿**ï¼š**åœ¨ä¸é‡æ–°è®­ç»ƒ LLM çš„å‰æä¸‹ï¼Œé€šè¿‡å¢åŠ ä¸€ä¸ªæè½»é‡çš„åé¦ˆæ¨¡å—ï¼Œæ˜¾è‘—æå‡é•¿æœŸé¢„æµ‹ç¨³å®šæ€§ï¼Œå¹¶æä¾›ç†è®ºä¸Šçš„è¯¯å·®æœ‰ç•Œä¿è¯ã€‚**

---

## 2. **æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### ğŸ“Š **ä½¿ç”¨çš„æ•°æ®é›†**

å…±ä½¿ç”¨ **7 ä¸ªçœŸå®ä¸–ç•Œå¤šå˜é‡æ—¶é—´åºåˆ—æ•°æ®é›†**ï¼Œæ¶µç›–å¤šä¸ªé¢†åŸŸï¼š

| æ•°æ®é›† | ç±»å‹ | å˜é‡æ•° (Dim) | æ—¶é—´åˆ†è¾¨ç‡ | åº”ç”¨åœºæ™¯ |
|--------|------|-------------|------------|----------|
| **ETTh1/ETTh2**, **ETTm1/ETTm2** | å¤šå˜é‡ | 7 | å°æ—¶ / 15åˆ†é’Ÿ | ç”µåŠ›è´Ÿè·ä¸å˜å‹å™¨æ²¹æ¸© |
| **ECL** | å¤šå˜é‡ | 321 | å°æ—¶ | å®¶åº­ç”¨ç”µæ¶ˆè€— |
| **Traffic** | å¤šå˜é‡ | 862 | å°æ—¶ | é«˜é€Ÿå…¬è·¯å æœ‰ç‡ |
| **Weather** | å¤šå˜é‡ | 21 | 10åˆ†é’Ÿ | æ°”è±¡æ•°æ® |
| **M4** | å•å˜é‡ | 1 | å¤šç§é¢‘ç‡ | å•†ä¸šç»æµé¢„æµ‹ç«èµ›æ•°æ® |
| **M3** | å•å˜é‡ | 1 | å¤šç§é¢‘ç‡ | æ—¶é—´åºåˆ—é¢„æµ‹åŸºå‡† |

> æ‰€æœ‰æ•°æ®æŒ‰æ—¶é—´é¡ºåºåˆ’åˆ† train/validation/testï¼Œé˜²æ­¢æ•°æ®æ³„éœ²ã€‚

---

### âš™ï¸ **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

- **é¢„æµ‹é•¿åº¦ï¼ˆHorizonï¼‰**ï¼š{96, 192, 336, 720}
- **å›çœ‹çª—å£ï¼ˆLookback Lengthï¼‰**ï¼šå›ºå®šä¸º 672ï¼ˆé™¤ M3/M4 æŒ‰ä¸¤å€ horizon è®¾ç½®ï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **MSE**ï¼ˆMean Squared Errorï¼‰
  - **MAE**ï¼ˆMean Absolute Errorï¼‰
  - **SMAPE**ï¼ˆSymmetric Mean Absolute Percentage Errorï¼Œç”¨äº zero-shot å®éªŒï¼‰

- **æ¨¡å‹æ¶æ„åŸºç¡€**ï¼š
  - ä½¿ç”¨ **LLaMA-2-7B** ä½œä¸ºå†»ç»“ backboneã€‚
  - æ·»åŠ  patch-based embedding å’Œ inverse projection å±‚ã€‚
  - Residual Estimator ä¸ºå•å±‚çº¿æ€§ç½‘ç»œã€‚

- **è®­ç»ƒç­–ç•¥**ï¼šä¸¤é˜¶æ®µè¯¾ç¨‹å­¦ä¹ ï¼ˆCurriculum Learningï¼‰
  1. **Stage 1**: å›ºå®šæ®‹å·®ä¼°è®¡å™¨ï¼Œä»…è®­ç»ƒæŠ•å½±å±‚ + æ–½åŠ  Local Lipschitz æ­£åˆ™åŒ–ã€‚
  2. **Stage 2**: å†»ç»“æŠ•å½±å±‚ï¼Œè®­ç»ƒæ®‹å·®ä¼°è®¡å™¨ä»¥æ‹Ÿåˆå†å²è¯¯å·®æ¨¡å¼ã€‚

---

### ğŸ†š **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

#### åŒ…æ‹¬ä»¥ä¸‹å‡ ç±»ä»£è¡¨æ€§æ–¹æ³•ï¼š

| ç±»åˆ« | æ–¹æ³• |
|------|------|
| **é LLM æ·±åº¦æ¨¡å‹** | PatchTST, DLinear, FEDformer, TimesNet, iTransformer, TimeMixer++, SimpleTM |
| **LLM-based TSF** | AutoTimes, Time-LLM, FPT, UniTime, LVICL |
| **å…¶ä»–** | Informer, Reformer, NSformer |

> å¤§éƒ¨åˆ†ç»“æœæ¥è‡ª [149]ï¼ˆAutoTimesï¼‰å’Œ [167]ï¼ˆLVICLï¼‰çš„å…¬å¼€æŠ¥å‘Šã€‚

---

## 3. **ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### ğŸ“ˆ **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 1 & Table 8ï¼‰**

åœ¨ **å¹³å‡ MSE/MAE** ä¸Šï¼ŒF-LLM åœ¨å¤šæ•°æ•°æ®é›†ä¸Šå–å¾—æœ€ä¼˜è¡¨ç°ï¼š

| Dataset | F-LLM (MSE) | Best Baseline (MSE) | æå‡å¹…åº¦ |
|--------|-------------|---------------------|---------|
| ETTh1 | **0.376** | 0.389 (AutoTimes) | â†“ **3.3%** |
| ETTh2 | **0.317** | 0.326 (LVICL) | â†“ **2.8%** |
| ETTm1 | **0.319** | 0.328 (LVICL) | â†“ **2.7%** |
| ETTm2 | **0.234** | 0.239 (LVICL) | â†“ **2.1%** |
| ECL | **0.148** | 0.158 (LVICL) | â†“ **6.3%** |
| Weather | **0.215** | 0.222 (LVICL) | â†“ **3.1%** |
| Traffic | **0.364** | 0.370 (LVICL) | â†“ **1.6%** |

> âœ… æ€»ä½“æ¥çœ‹ï¼ŒF-LLM åœ¨æœ€å…·æŒ‘æˆ˜æ€§çš„é•¿æ—¶åŸŸä»»åŠ¡ä¸­å¹³å‡é™ä½ MSE è¾¾ **5.6%**ã€‚

---

### ğŸ” **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- F-LLM æ˜¾è‘—ä¼˜äºæ‰€æœ‰å¯¹æ¯”æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨ **ECL å’Œ ETTh ç³»åˆ—**ç­‰å¤æ‚å¤šå˜é‡åœºæ™¯ä¸­ã€‚
- ç›¸æ¯”æœ€å¼ºçš„ LLM4TS æ–¹æ³•ï¼ˆå¦‚ AutoTimesã€LVICLï¼‰ï¼ŒF-LLM ä¸ä»…æ€§èƒ½æ›´å¥½ï¼Œè€Œä¸”å…·å¤‡æ›´å¼ºçš„**è½¨è¿¹ä¸€è‡´æ€§**ï¼ˆtrajectory alignmentï¼‰ï¼Œé¿å…äº†æ˜æ˜¾çš„æ¼‚ç§»ã€‚
- åœ¨é LLM æ–¹æ³•ä¸­ï¼Œä¹Ÿå…¨é¢è¶…è¶Š DLinearã€PatchTST ç­‰å…ˆè¿›æ¨¡å‹ã€‚

---

### ğŸ”§ **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Study, Table 3ï¼‰**

éªŒè¯äº†å„æ¨¡å—çš„æœ‰æ•ˆæ€§ï¼ˆåœ¨ ETTh1 å’Œ Weather ä¸Šï¼‰ï¼š

| æ¨¡å‹å˜ä½“ | ETTh1 (Pred-720, MSE) | Weather (Pred-720, MSE) |
|--------|------------------------|--------------------------|
| F-LLM (Full) | **0.395** | **0.305** |
| w/o Feedback | 0.417 (+5.6%) | 0.320 (+4.9%) |
| w/o LLM (MLP æ›¿ä»£) | 0.438 (+10.9%) | 0.324 (+6.2%) |

> ç»“è®ºï¼š
> - ç§»é™¤ **feedback æ¨¡å—** å¯¼è‡´æ€§èƒ½ä¸‹é™æ˜æ˜¾ï¼Œè¯´æ˜è¯¯å·®æ ¡æ­£æœºåˆ¶è‡³å…³é‡è¦ã€‚
> - ç§»é™¤ **LLM** åæ€§èƒ½å¤§å¹…ä¸‹æ»‘ï¼Œè¡¨æ˜ LLM çš„å¼ºæ³›åŒ–èƒ½åŠ›ä»æ˜¯åŸºç¡€ã€‚
> - äºŒè€…ç»“åˆæ‰èƒ½å‘æŒ¥æœ€å¤§æ•ˆèƒ½ã€‚

---

### ğŸ”„ **é€šç”¨æ€§ä¸é²æ£’æ€§åˆ†æ**

- **è·¨ LLM backbone æ³›åŒ–æ€§æµ‹è¯•**ï¼ˆTable 4ï¼‰ï¼š
  - åœ¨ GPT-2ã€OPT-6.7Bã€LLaMA-7B ä¸Šå‡èƒ½ç¨³å®šææ•ˆã€‚
  - è¡¨æ˜ F-LLM æ˜¯ **model-agnostic** çš„ï¼Œé€‚ç”¨äºä»»æ„ decoder-only LLMã€‚

- **è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æ**ï¼ˆFigure 4ï¼‰ï¼š
  - å¯¹ lookback length å’Œ patch length å…·æœ‰è‰¯å¥½é²æ£’æ€§ã€‚
  - æ€§èƒ½å¢ç›Šä¸æ˜¯ç”±ç‰¹å®š tokenization è®¾è®¡å¸¦æ¥çš„ã€‚

- **æ•ˆç‡åˆ†æ**ï¼ˆFigure 5ï¼‰ï¼š
  - ä»…å¼•å…¥ <5% çš„é¢å¤–æ¨ç†å¼€é”€ã€‚
  - å¯è®­ç»ƒå‚æ•°æå°‘ï¼ˆä¸»è¦é›†ä¸­åœ¨ projection layers å’Œ residual estimatorï¼‰ï¼Œè¿œä½äº LoRA å¾®è°ƒæ–¹æ¡ˆã€‚

- **ä¸ LoRA å¯¹æ¯”**ï¼ˆTable 6ï¼‰ï¼š
  - LoRA å¾®è°ƒå¸¦æ¥ä¸€å®šæ”¹è¿›ï¼Œä½†ä¸å¦‚ F-LLM æ˜¾è‘—ã€‚
  - ç‰¹åˆ«æ˜¯åœ¨é•¿å‘¨æœŸé¢„æµ‹ä¸­ï¼ŒF-LLM çš„ä¼˜åŠ¿æ›´åŠ çªå‡ºã€‚

---

## 4. **å…³é”®ç»“è®ºå’Œå‘ç°**

### âœ… **ä¸»è¦å‘ç°**

1. **ç†è®ºå±‚é¢**ï¼š
   - é¦–æ¬¡ä»**æ§åˆ¶ç†è®ºè§†è§’**å½¢å¼åŒ–åˆ†æäº† LLM è‡ªå›å½’é¢„æµ‹ä¸­çš„è¯¯å·®ä¼ æ’­æœºåˆ¶ã€‚
   - è¯æ˜æ ‡å‡† open-loop æ¨ç†ä¼šå¯¼è‡´ **exponential error growth**ï¼ˆæŒ‡æ•°çº§è¯¯å·®å¢é•¿ï¼‰ã€‚
   - æå‡ºå¹¶è¯æ˜ï¼šé€šè¿‡å¼•å…¥ feedback æ§åˆ¶ï¼Œå¯åœ¨æ»¡è¶³å±€éƒ¨ Lipschitz æ¡ä»¶ä¸‹å®ç° **uniformly bounded error**ï¼ˆä¸€è‡´æœ‰ç•Œè¯¯å·®ï¼‰ï¼Œä¸º LLM é¢„æµ‹æä¾›äº†**å¯è¯æ˜çš„ç¨³å®šæ€§ä¿éšœ**ã€‚

2. **æ–¹æ³•å±‚é¢**ï¼š
   - æå‡º **F-LLM** æ¡†æ¶ï¼Œé¦–æ¬¡å°†åŠ¨æ€è¯¯å·®æ ¡æ­£æœºåˆ¶åº”ç”¨äº LLM-based TSFã€‚
   - æ„å»ºäº†ä¸€ä¸ªâ€œPlant-Observer-Controllerâ€é—­ç¯ç»“æ„ï¼Œå®ç°äº† in-loop error correctionã€‚
   - é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥æœ‰æ•ˆè§£è€¦è¡¨ç¤ºå­¦ä¹ ä¸æ§åˆ¶å­¦ä¹ ã€‚

3. **å®éªŒå±‚é¢**ï¼š
   - åœ¨å¤šä¸ªçœŸå®æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äº SOTA æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨é•¿æ—¶åŸŸé¢„æµ‹ä¸­ã€‚
   - ä¿æŒäº† LLM çš„ **zero-shot generalization** èƒ½åŠ›ï¼Œåœ¨è·¨åŸŸè¿ç§»ä»»åŠ¡ä¸­åŒæ ·é¢†å…ˆï¼ˆTable 2ï¼‰ã€‚
   - æ¨¡å—è½»é‡ã€é«˜æ•ˆã€å³æ’å³ç”¨ï¼Œé€‚åˆéƒ¨ç½²äºå·²æœ‰ LLM æ¨ç†æµç¨‹ä¸­ã€‚

---

### âš ï¸ **å±€é™æ€§**

- **ä¾èµ–é«˜è´¨é‡çš„å†å²è¯¯å·®æ¨¡å¼**ï¼šResidual Estimator çš„æ•ˆæœå—é™äºè®­ç»ƒé˜¶æ®µèƒ½å¦æ•æ‰åˆ°ç³»ç»Ÿæ€§åå·®ã€‚
- **Local Lipschitz Constraint çš„å®ç°æ–¹å¼è¾ƒç®€å•**ï¼šç›®å‰ä»…åœ¨ projection head ä¸Šæ–½åŠ æ­£åˆ™é¡¹ï¼Œæœªæ·±å…¥ä¼˜åŒ–æ•´ä¸ª LLM çš„åŠ¨åŠ›å­¦ç‰¹æ€§ã€‚
- **å°šæœªæ¢ç´¢å¤šæ¨¡æ€åé¦ˆæˆ–å…¶ä»– observer ç»“æ„**ï¼šå½“å‰ observer ä»…ä¸ºçº¿æ€§ä¼°è®¡å™¨ï¼Œå¯èƒ½é™åˆ¶è¡¨è¾¾èƒ½åŠ›ã€‚

---

### ğŸ”® **æœªæ¥å·¥ä½œæ–¹å‘**

1. è®¾è®¡æ›´å¤æ‚çš„ **nonlinear observers** æˆ–å¼•å…¥ attention æœºåˆ¶å¢å¼ºæ®‹å·®å»ºæ¨¡èƒ½åŠ›ã€‚
2. å°† F-LLM æ‹“å±•è‡³ **probabilistic forecasting** åœºæ™¯ï¼Œæ”¯æŒä¸ç¡®å®šæ€§é‡åŒ–ã€‚
3. æ¢ç´¢ä¸å…¶ä»– LLM adapterï¼ˆå¦‚ LoRAã€Adapterï¼‰è”åˆä½¿ç”¨ï¼Œè¿›ä¸€æ­¥é‡Šæ”¾æ½œåŠ›ã€‚
4. å°†è¯¥æ§åˆ¶æ¡†æ¶æ¨å¹¿è‡³å…¶ä»–åºåˆ—ç”Ÿæˆä»»åŠ¡ï¼ˆå¦‚è§†é¢‘é¢„æµ‹ã€è¯­éŸ³åˆæˆï¼‰ä¸­è§£å†³ exposure bias é—®é¢˜ã€‚

---

## âœ… **æ€»ç»“ä¸€å¥è¯**

> æœ¬æ–‡å¼€åˆ›æ€§åœ°å°†**æ§åˆ¶ç†è®º**å¼•å…¥ LLM æ—¶é—´åºåˆ—é¢„æµ‹ï¼Œæå‡º **F-LLM** æ¡†æ¶ï¼Œé€šè¿‡æ„å»ºé—­ç¯åé¦ˆç³»ç»Ÿï¼Œä¸ä»…å®è¯æ˜¾è‘—ç¼“è§£äº†è¯¯å·®ç´¯ç§¯é—®é¢˜ï¼Œè¿˜é¦–æ¬¡ä¸º LLM é¢„æµ‹æä¾›äº†**å¯è¯æ˜çš„ç¨³å®šæ€§ç†è®ºä¿éšœ**ï¼Œå…¼å…·é«˜æ€§èƒ½ã€é«˜æ•ˆç‡ä¸å¼ºæ³›åŒ–èƒ½åŠ›ã€‚

</details>

---

### 14. [Eventizing Traditionally Opaque Binary Neural Networks as 1-safe Petri net Models](https://arxiv.org/abs/2602.13128)

**Authors**: Mohamed Tarraf, Alex Chan, Alex Yakovlev, Rishad Shafik  
**Category**: cs.LG  
**Published**: 2026-02-16  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.13128v1  

#### Abstract
Binary Neural Networks (BNNs) offer a low-complexity and energy-efficient alternative to traditional full-precision neural networks by constraining their weights and activations to binary values. However, their discrete, highly non-linear behavior makes them difficult to explain, validate and formal...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šEventizing Traditionally Opaque Binary Neural Networks as 1-safe Petri net Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
Binary Neural Networks (BNNs) è™½ç„¶åœ¨èƒ½æ•ˆå’Œè®¡ç®—æ•ˆç‡ä¸Šå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œä½†ç”±äºå…¶**ç¦»æ•£åŒ–ã€é«˜åº¦éçº¿æ€§çš„è¡Œä¸º**ï¼Œå¯¼è‡´æ¨¡å‹å†…éƒ¨å†³ç­–è¿‡ç¨‹ä¸é€æ˜ï¼ˆopaqueï¼‰ï¼Œéš¾ä»¥è¿›è¡Œè§£é‡Šã€éªŒè¯å’Œå½¢å¼åŒ–åˆ†æã€‚è¿™é™åˆ¶äº†å…¶åœ¨å®‰å…¨å…³é”®é¢†åŸŸï¼ˆå¦‚å«æ˜Ÿæ§åˆ¶ã€åŒ»ç–—ç›‘æµ‹ï¼‰çš„åº”ç”¨ã€‚

ä¼ ç»Ÿå¯è§£é‡Šæ€§æ–¹æ³•ï¼ˆå¦‚ SHAPã€LIMEï¼‰ä»…æä¾›äº‹åç›¸å…³æ€§è¿‘ä¼¼ï¼Œè€Œå½¢å¼åŒ–éªŒè¯æ–¹æ³•ï¼ˆå¦‚ SMTã€å‡¸æ¾å¼›ï¼‰éš¾ä»¥æ•æ‰ BNN ä¸­ç»†ç²’åº¦çš„äº‹ä»¶ä¾èµ–å…³ç³»ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº **Petri Net (PN)** çš„æ¡†æ¶ï¼Œå°† BNN çš„æ¨ç†å’Œè®­ç»ƒè¿‡ç¨‹â€œ**äº‹ä»¶åŒ–**â€ï¼ˆeventizingï¼‰ï¼Œå³å»ºæ¨¡ä¸ºç”±å› æœé©±åŠ¨çš„å¹¶å‘äº‹ä»¶ç³»ç»Ÿã€‚å…·ä½“åˆ›æ–°åŒ…æ‹¬ï¼š

- å°† BNN çš„æ ¸å¿ƒæ“ä½œï¼ˆæ¿€æ´»å‡½æ•°ã€æ¢¯åº¦è®¡ç®—ã€æƒé‡æ›´æ–°ç­‰ï¼‰åˆ†è§£ä¸ºæ¨¡å—åŒ–çš„ PN æ®µï¼ˆblueprint-like PN segmentsï¼‰ã€‚
- æ„å»ºå®Œæ•´çš„ç³»ç»Ÿçº§ PN æ¨¡å‹ï¼Œæ˜¾å¼åˆ»ç”» BNN å†…éƒ¨çš„**å› æœå…³ç³»ã€å¹¶å‘æ€§ã€çŠ¶æ€æ¼”åŒ–å’Œæ§åˆ¶æµé¡ºåº**ã€‚
- ä½¿ç”¨ **Workcraft** å·¥å…·é“¾å®ç° PN çš„æ„å»ºã€ä»¿çœŸä¸è‡ªåŠ¨åŒ–éªŒè¯ï¼ˆé€šè¿‡ Mpsat å’Œ Petrify åç«¯ï¼‰ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³• | æœ¬è®ºæ–‡æ–¹æ³• |
|------|--------|-----------|
| å¯è§£é‡Šæ€§ | é»‘ç›’è¿‘ä¼¼ï¼ˆpost-hocï¼‰ | ç™½ç›’æœºåˆ¶è§£é‡Šï¼ˆmechanistic viewï¼‰ |
| å½¢å¼åŒ–èƒ½åŠ› | éš¾ä»¥å¤„ç†ç¦»æ•£éçº¿æ€§ | æ”¯æŒå½¢å¼åŒ–éªŒè¯ï¼ˆ1-safeness, deadlock-freeness ç­‰ï¼‰ |
| å› æœå»ºæ¨¡ | ç¼ºä¹æ˜¾å¼å› æœç»“æ„ | æ˜¾å¼å»ºæ¨¡äº‹ä»¶é—´çš„å› æœä¾èµ– |
| éªŒè¯ç²’åº¦ | æ•´ä½“è¾“å‡ºéªŒè¯ä¸ºä¸» | æ”¯æŒäº‹ä»¶çº§ï¼ˆevent-by-eventï¼‰çš„è¡Œä¸ºéªŒè¯ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿**ï¼šé¦–æ¬¡å®ç°äº†å¯¹ BNN æ¨ç†ä¸è®­ç»ƒå…¨è¿‡ç¨‹çš„å½¢å¼åŒ–ã€å¯éªŒè¯ã€äº‹ä»¶é©±åŠ¨å»ºæ¨¡ï¼Œä½¿åŸæœ¬â€œé»‘ç›’â€çš„ BNN æˆä¸º**é€æ˜ä¸”å¯éªŒè¯çš„äº‹ä»¶ç³»ç»Ÿ**ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- ä¸»è¦ç”¨äºè¯´æ˜æ€§ç¤ºä¾‹çš„æ˜¯ä¸€ä¸ªç®€å•çš„ **2-input XOR æ•°æ®é›†**ï¼š  
  `{00 â†’ -1, 01 â†’ 1, 10 â†’ 1, 11 â†’ -1}`  
  è¯¥æ•°æ®é›†ç”¨äºæ¼”ç¤ºæ•´ä¸ª PN æ¨¡å‹çš„æ„å»ºä¸è¿è¡Œæµç¨‹ã€‚
- åœ¨æ‰©å±•å¤æ‚åº¦åˆ†æä¸­ï¼Œä¼°ç®—äº†ä»¥ä¸‹çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„æ¨¡å‹è§„æ¨¡ï¼š
  - **KWS6**ï¼ˆKeyword Spottingï¼‰
  - **CIFAR2**
  - **MNIST**

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
#### å®éªŒå¹³å°
- ä½¿ç”¨ **Workcraft** å·¥å…·è¿›è¡Œ PN å»ºæ¨¡ã€äº¤äº’å¼ä»¿çœŸä¸è‡ªåŠ¨éªŒè¯ã€‚
- åç«¯å·¥å…·ï¼š**Petrify**ï¼ˆé€»è¾‘ç»¼åˆï¼‰ã€**Mpsat**ï¼ˆéªŒè¯ä¸åä¾‹ç”Ÿæˆï¼‰ã€‚

#### è¯„ä¼°ç»´åº¦
| ç±»åˆ« | å…·ä½“æŒ‡æ ‡ |
|------|---------|
| **ç»“æ„æ€§è´¨éªŒè¯** | 1-safenessï¼ˆå®‰å…¨æ€§ï¼‰ã€deadlock-freenessï¼ˆæ— æ­»é”ï¼‰ã€mutual exclusionï¼ˆäº’æ–¥ï¼‰ã€reachabilityï¼ˆå¯è¾¾æ€§ï¼‰ |
| **è¡Œä¸ºæ­£ç¡®æ€§** | ä¸å‚è€ƒè½¯ä»¶å®ç°çš„ BNN è¾“å‡ºè½¨è¿¹å¯¹æ¯”ï¼ˆloss, prediction, gradientsï¼‰ |
| **æ¨¡å‹è§„æ¨¡ä¸å¤æ‚åº¦** | Placesã€Transitionsã€Arcs æ•°é‡ç»Ÿè®¡ï¼›æ€»æ¨¡å‹å¤§å°ï¼ˆTotal Sizeï¼‰ |
| **å¯æ‰©å±•æ€§åˆ†æ** | ä¸åŒç½‘ç»œç»“æ„ï¼ˆè¾“å…¥/éšè—/è¾“å‡ºç¥ç»å…ƒæ•°ï¼‰ä¸‹çš„ç»„åˆçˆ†ç‚¸è¶‹åŠ¿ |

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **å‚è€ƒ BNN å®ç°**ï¼šä¸€ä¸ªæ ‡å‡†çš„ Python å®ç°çš„ BNNï¼Œä½¿ç”¨ç›¸åŒçš„æ¶æ„ï¼ˆ2 è¾“å…¥å±‚ã€2 éšè—å±‚ã€1 è¾“å‡ºå±‚ï¼‰ã€Hinge Lossã€SGD ä¼˜åŒ–å™¨ã€å­¦ä¹ ç‡ 0.6ã€‚
- å¯¹æ¯”æ–¹å¼ï¼šé€æ“ä½œè®°å½•ä¸­é—´å€¼ï¼ˆæƒé‡ã€æ¿€æ´»ã€æŸå¤±ã€æ¢¯åº¦ç­‰ï¼‰ï¼Œå¹¶ä¸ PN æ¨¡å‹ä¸­çš„ metric instrument è¾“å‡ºè¿›è¡Œæ¯”å¯¹ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰æ¨¡å‹è§„æ¨¡ï¼ˆè§ Table IIï¼‰
| ç»„ä»¶ | Places | Transitions | Arcs | Total Size |
|------|--------|------------|------|------------|
| å•ä¸ªéšè—ç¥ç»å…ƒ | 238 | 409 | 3,109 | 3,756 |
| æƒé‡æ›´æ–°ï¼ˆæœ€å¤æ‚éƒ¨åˆ†ï¼‰ | 1,256 | 1,912 | 10,642 | 13,810 |
| å®Œæ•´ BNN-PN æ¨¡å‹ | **8,243** | **12,598** | **71,370** | **92,211** |

> âš ï¸ æƒé‡æ›´æ–°æ˜¯æœ€å¤§ç“¶é¢ˆï¼Œå æ€»è§„æ¨¡çš„ ~15%ï¼Œå› å…¶æ¶‰åŠ IEEE-754 æµ®ç‚¹è¿ç®—çš„å®Œæ•´å»ºæ¨¡ã€‚

#### ï¼ˆ2ï¼‰ä¸åŒæ•°æ®é›†çš„ä¼°è®¡å¤æ‚åº¦ï¼ˆTable IIIï¼‰
| Dataset | Total Size (Ã—10â¹) |
|--------|------------------|
| KWS6 (largest config) | ~3.0 Ã— 10â¹ |
| CIFAR2 (largest config) | ~6.8 Ã— 10â¹ |
| MNIST (largest config) | ~5.4 Ã— 10â¹ |

> è¡¨æ˜å­˜åœ¨æ˜æ˜¾çš„**ç»„åˆçˆ†ç‚¸**é—®é¢˜ï¼Œå°¤å…¶åœ¨å…¨è¿æ¥å±‚ä¸­éšç¥ç»å…ƒæ•°é‡å‘ˆå¹³æ–¹å¢é•¿ã€‚

#### ï¼ˆ3ï¼‰è¡Œä¸ºéªŒè¯ç»“æœ
- **å½¢å¼åŒ–éªŒè¯ç»“æœ**ï¼ˆTable Iï¼‰ï¼š
  - æ‰€æœ‰æ®µã€ç»„ä»¶å’Œç³»ç»Ÿçº§æ¨¡å‹å‡é€šè¿‡ï¼š
    - **1-safeness**ï¼ˆæ¯ä¸ª place æœ€å¤šä¸€ä¸ª tokenï¼‰
    - **Deadlock-freeness**
    - **Causal sequencing æ­£ç¡®æ€§**ï¼ˆå¦‚ï¼šé¢„æµ‹ â†’ æŸå¤± â†’ æ¢¯åº¦ â†’ æ›´æ–°ï¼‰
    - **Progressiveness**ï¼ˆå¾ªç¯å¤„ç†æ‰€æœ‰æ•°æ®ç‚¹ï¼‰
  - ä»…éƒ¨åˆ†ä¸å¯é€†ï¼ˆpartial irreversibilityï¼‰ï¼Œå› è®­ç»ƒè¿‡ç¨‹ä¸­æƒé‡æŒç»­æ¼”åŒ–ã€‚

- **ä¸å‚è€ƒ BNN çš„è¡Œä¸ºå¯¹æ¯”**ï¼ˆFig. 19ï¼‰ï¼š
  - åˆå§‹é˜¶æ®µï¼ˆå‰ 3 ä¸ª epochï¼‰ï¼šPN æ¨¡å‹ä¸å‚è€ƒæ¨¡å‹ loss è½¨è¿¹å‡ ä¹ä¸€è‡´ã€‚
  - ç¬¬ 3â€“15 epochï¼šå‡ºç°è½»å¾®åå·®ï¼Œå¯èƒ½æºäºæµ®ç‚¹èˆå…¥æˆ–éšæœºåˆå§‹åŒ–å·®å¼‚ã€‚
  - 15 epoch åï¼šPN æ¨¡å‹ loss ç¼“æ…¢ä¸‹é™ï¼Œæœ€ç»ˆåœ¨ 100 epoch æ—¶è¾¾åˆ°æ¯”å‚è€ƒæ¨¡å‹ä½çº¦ **10% çš„ loss**ã€‚
  - ç»“è®ºï¼š**PN æ¨¡å‹åŠŸèƒ½æ­£ç¡®ï¼Œä¸”è¡¨ç°å‡ºç›¸ä¼¼ç”šè‡³ç•¥ä¼˜çš„å­¦ä¹ åŠ¨æ€**ã€‚

#### ï¼ˆ4ï¼‰æ¶ˆèå®éªŒï¼ˆéšå«ï¼‰
è™½ç„¶æœªæ˜ç¡®å‘½åâ€œablation studyâ€ï¼Œä½†æ–‡ä¸­é€šè¿‡åˆ†å±‚éªŒè¯ä½“ç°äº†æ¨¡å—åŒ–è®¾è®¡çš„æœ‰æ•ˆæ€§ï¼š
- å„ PN æ®µç‹¬ç«‹éªŒè¯é€šè¿‡ â†’ ç»„åˆæˆç»„ä»¶ä»æ»¡è¶³æ€§è´¨ â†’ ç³»ç»Ÿçº§é›†æˆåä¾ç„¶å®‰å…¨å¯é ã€‚
- ç‰¹åˆ«åœ°ï¼Œå¼•å…¥ **arbitration places** å’Œ **proxy places** æœ‰æ•ˆç®¡ç†äº†å¹¶å‘ä¸å¯è§†åŒ–å¤æ‚åº¦ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **BNN å¯è¢«å®Œå…¨äº‹ä»¶åŒ–å»ºæ¨¡ä¸º 1-safe Petri Net**ï¼Œå…¶æ¨ç†ä¸è®­ç»ƒè¿‡ç¨‹å¯ä»¥è¢«åˆ†è§£ä¸ºå…·æœ‰æ˜ç¡®å› æœç»“æ„çš„äº‹ä»¶åºåˆ—ã€‚
2. âœ… æ‰€æå‡ºçš„ PN æ¨¡å‹èƒ½å¤Ÿé€šè¿‡ä¸¥æ ¼çš„**å½¢å¼åŒ–éªŒè¯**ï¼Œç¡®ä¿å®‰å…¨æ€§ã€æ— æ­»é”æ€§å’Œæ­£ç¡®çš„å› æœé¡ºåºã€‚
3. âœ… ä¸å‚è€ƒ BNN çš„è¡Œä¸ºé«˜åº¦ä¸€è‡´ï¼Œè¯æ˜äº†è¯¥å»ºæ¨¡æ–¹æ³•çš„**åŠŸèƒ½ä¿çœŸåº¦**ã€‚
4. ğŸ” å­˜åœ¨**ç»„åˆçˆ†ç‚¸**é—®é¢˜ï¼Œå°¤å…¶æ˜¯æµ®ç‚¹æƒé‡æ›´æ–°éƒ¨åˆ†å¯¼è‡´æ¨¡å‹è§„æ¨¡æ€¥å‰§ä¸Šå‡ã€‚
5. ğŸ”„ æ¨¡å‹æ”¯æŒ**äº‹ä»¶çº§ä»¿çœŸä¸è°ƒè¯•**ï¼Œå¯ç”¨äºè¿½è¸ªæ•…éšœä¼ æ’­è·¯å¾„ã€ç†è§£æ¢¯åº¦æµåŠ¨æœºåˆ¶ã€‚

### æ–¹æ³•çš„å±€é™æ€§
| å±€é™æ€§ | è¯´æ˜ |
|-------|------|
| **å¯æ‰©å±•æ€§å·®** | å½“å‰æ¨¡å‹ä¸ºå…¨å±•å¼€å¼ï¼ˆfully instantiatedï¼‰ï¼Œæ— æ³•ç›´æ¥åº”ç”¨äºå¤§å‹ç½‘ç»œï¼ˆå¦‚ ResNetï¼‰ã€‚ |
| **æµ®ç‚¹å»ºæ¨¡å¼€é”€å¤§** | IEEE-754 è¿ç®—å»ºæ¨¡æå…¶å¤æ‚ï¼Œæ˜¯ä¸»è¦æ€§èƒ½ç“¶é¢ˆã€‚ |
| **ç¼ºä¹å‚æ•°å…±äº«æœºåˆ¶** | å½“å‰ PN æ®µæœªå®ç°æ¨¡æ¿å¤ç”¨ï¼Œç›¸åŒæ“ä½œéœ€é‡å¤å»ºæ¨¡ã€‚ |
| **ä»…æ”¯æŒ SGD** | æ›´å¤æ‚çš„ä¼˜åŒ–å™¨ï¼ˆå¦‚ Adamï¼‰å› æ¶‰åŠåŠ¨é‡å˜é‡å°šæœªæ”¯æŒã€‚ |
| **æš‚æ— åç½®é¡¹å»ºæ¨¡** | å½“å‰æ¨¡å‹çœç•¥äº† bias termsã€‚ |

### æœªæ¥å·¥ä½œæ–¹å‘
1. **å¢å¼ºæ¨¡å‹é€šç”¨æ€§**ï¼š
   - å¼•å…¥ **bias terms**
   - æ”¯æŒæ›´å¤š activation functionsã€loss functions å’Œ optimizersï¼ˆå¦‚ Adamï¼‰
2. **æå‡è‡ªåŠ¨åŒ–ç¨‹åº¦**ï¼š
   - å¼€å‘ **Workcraft æ’ä»¶**ï¼Œå…è®¸ç”¨æˆ·è¾“å…¥ç½‘ç»œæ¶æ„è‡ªåŠ¨ç”Ÿæˆ PN æ¨¡å‹
3. **ä¼˜åŒ–è¡¨ç¤ºä¸æ€§èƒ½**ï¼š
   - æ¢ç´¢æ›´é«˜æ•ˆçš„æ•°æ®ç»“æ„åŠ é€Ÿ PN ä»¿çœŸ
   - å¼•å…¥ **templatingã€parameter sharing å’Œ hierarchical reuse** ä»¥ç¼“è§£ç»„åˆçˆ†ç‚¸
4. **å‘ç¡¬ä»¶æ˜ å°„å»¶ä¼¸**ï¼š
   - åˆ©ç”¨ PN çš„å¼‚æ­¥ç‰¹æ€§ç”Ÿæˆä½åŠŸè€—å¼‚æ­¥ç”µè·¯æ§åˆ¶å™¨
   - åº”ç”¨äºåµŒå…¥å¼ AI èŠ¯ç‰‡çš„å¯ä¿¡è®¾è®¡æµç¨‹

---

## æ€»ç»“

> æœ¬æ–‡æˆåŠŸå°†ä¼ ç»Ÿçš„â€œé»‘ç›’â€BNN è½¬åŒ–ä¸º**é€æ˜ã€å¯éªŒè¯ã€äº‹ä»¶é©±åŠ¨çš„ 1-safe Petri Net æ¨¡å‹**ï¼Œå¡«è¡¥äº†æœºå™¨å­¦ä¹ æ¨¡å‹ä¸å½¢å¼åŒ–æ–¹æ³•ä¹‹é—´çš„é¸¿æ²Ÿã€‚å°½ç®¡é¢ä¸´å¯æ‰©å±•æ€§æŒ‘æˆ˜ï¼Œä½†å®ƒä¸ºæ„å»º**é«˜å¯ä¿¡ã€å¯è§£é‡Šã€å®‰å…¨å…³é”®å‹ AI ç³»ç»Ÿ**æä¾›äº†å…¨æ–°çš„ç†è®ºåŸºç¡€ä¸å·¥ç¨‹è·¯å¾„ã€‚

</details>

---

### 15. [Regularized Meta-Learning for Improved Generalization](https://arxiv.org/abs/2602.12469)

**Authors**: Noor Islam S. Mohammad, Md Muntaqim Meherab  
**Category**: cs.LG  
**Published**: 2026-02-16  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.12469v1  

#### Abstract
Deep ensemble methods often improve predictive performance, yet they suffer from three practical limitations: redundancy among base models that inflates computational cost and degrades conditioning, unstable weighting under multicollinearity, and overfitting in meta-learning pipelines. We propose a ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šRegularized Meta-Learning for Improved Generalization**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
è¯¥è®ºæ–‡é’ˆå¯¹**æ·±åº¦é›†æˆå­¦ä¹ **ï¼ˆdeep ensemblesï¼‰åœ¨å®é™…åº”ç”¨ä¸­çš„ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **å†—ä½™æ€§**ï¼ˆRedundancyï¼‰ï¼šå¤§é‡åŸºç¡€æ¨¡å‹ä¹‹é—´å­˜åœ¨é«˜åº¦ç›¸å…³æ€§ï¼Œå¯¼è‡´è®¡ç®—æˆæœ¬å¢åŠ ã€æ¡ä»¶æ•°æ¶åŒ–ï¼›
- **ä¸ç¨³å®šæ€§**ï¼ˆInstabilityï¼‰ï¼šå¤šé‡å…±çº¿æ€§ï¼ˆmulticollinearityï¼‰å¯¼è‡´å…ƒå­¦ä¹ æƒé‡ä¼°è®¡ä¸ç¨³å®šï¼›
- **è¿‡æ‹Ÿåˆé£é™©**ï¼ˆOverfittingï¼‰ï¼šé«˜ç»´é¢„æµ‹ç©ºé—´ä¸‹ï¼Œå…ƒå­¦ä¹ å™¨å®¹æ˜“åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¿‡æ‹Ÿåˆã€‚

è¿™äº›é—®é¢˜ä½¿å¾—ä¼ ç»Ÿ stacking æ–¹æ³•åœ¨å¤§è§„æ¨¡æ¨¡å‹æ± ä¸­è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨ AutoML å’Œç”Ÿäº§éƒ¨ç½²åœºæ™¯ä¸­ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
ä½œè€…æå‡ºäº†ä¸€ç§**æ­£åˆ™åŒ–å…ƒå­¦ä¹ æ¡†æ¶**ï¼ˆRegularized Meta-Learning Frameworkï¼‰ï¼ŒåŒ…å«å››ä¸ªé˜¶æ®µçš„æµæ°´çº¿ï¼š

1. **å†—ä½™æŠ•å½±**ï¼ˆRedundancy Projectionï¼‰  
   - ä½¿ç”¨å¤šæŒ‡æ ‡å»é‡ç­–ç•¥ï¼ˆmulti-metric de-duplicationï¼‰ï¼ŒåŸºäº `T_corr=0.95` çš„ç›¸å…³æ€§å’Œ `T_mse` çš„è¯¯å·®é˜ˆå€¼ç§»é™¤è¿‘ä¼¼å…±çº¿çš„é¢„æµ‹å˜é‡ï¼›
   - æ˜¾è‘—é™ä½å…ƒè®¾è®¡çŸ©é˜µçš„æœ‰æ•ˆæ¡ä»¶æ•°ï¼ˆeffective condition numberï¼‰ã€‚

2. **ç»Ÿè®¡å…ƒç‰¹å¾å¢å¼º**ï¼ˆStatistical Meta-Feature Augmentationï¼‰  
   - æ„é€ é›†æˆç»Ÿè®¡é‡ä½œä¸ºæ–°ç‰¹å¾ï¼Œå¦‚ï¼š
     - `ensemble_mean`, `ensemble_std`, `median`, `range`
     - äº¤äº’é¡¹ï¼ˆinteraction termsï¼‰å¦‚ `mean * std`
   - æ•è·åŸå§‹é¢„æµ‹åˆ—æ— æ³•è¡¨è¾¾çš„é«˜é˜¶ç»“æ„ä¿¡æ¯ã€‚

3. **äº¤å‰éªŒè¯çš„æ­£åˆ™åŒ–å…ƒå­¦ä¹ **ï¼ˆCross-Validated Regularized Meta-Learningï¼‰  
   - ä½¿ç”¨ Ridgeã€Lasso å’Œ ElasticNet è¿›è¡Œå…ƒæ¨¡å‹è®­ç»ƒï¼›
   - å†…å±‚åµŒå¥—äº¤å‰éªŒè¯é€‰æ‹©è¶…å‚æ•°ï¼Œç¡®ä¿æƒ©ç½šä¸å˜æ€§ï¼ˆpenalty invarianceï¼‰ã€‚

4. **é€†RMSEèåˆ**ï¼ˆInverse-RMSE Blendingï¼‰  
   - å¯¹å¤šä¸ªæ­£åˆ™åŒ–å…ƒæ¨¡å‹ï¼ˆRidge/Lasso/ElasticNetï¼‰çš„ç»“æœè¿›è¡ŒåŠ æƒèåˆï¼›
   - æƒé‡ä¸ºå„æ¨¡å‹ OOF RMSE çš„å€’æ•°å¹³æ–¹ï¼Œæå‡é²æ£’æ€§å¹¶å‡å°‘æ­£åˆ™å™¨é€‰æ‹©å¸¦æ¥çš„æ–¹å·®ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ€§èƒ½** | è¶…è¶Šç®€å•å¹³å‡ã€æ ‡å‡† Ridge stackingï¼Œä¸è´ªå©ªçˆ¬å±±æ³•ï¼ˆgreedy hill climbingï¼‰ç›¸å½“ç”šè‡³ç•¥ä¼˜ |
| **æ•ˆç‡** | è¿è¡Œæ—¶é—´ä»…ä¸º hill climbing çš„ **1/4**ï¼ˆæé€Ÿ 4Ã—ï¼‰ï¼Œé€‚åˆç”Ÿäº§éƒ¨ç½² |
| **ç¨³å®šæ€§** | æ˜¾è‘—æ”¹å–„æ¡ä»¶æ•°ï¼ˆâ†“53.7%ï¼‰ï¼Œé™ä½ä¼°è®¡æ–¹å·®ï¼Œæé«˜è·¨æŠ˜ä¸€è‡´æ€§ |
| **å¯è§£é‡Šæ€§** | çº¿æ€§å…ƒæ¨¡å‹ä¿ç•™å¯è§£é‡Šæ€§ï¼Œä¼˜äºç¥ç»ç½‘ç»œå…ƒå­¦ä¹ å™¨ |
| **æ‰©å±•æ€§** | æ”¯æŒå¤§è§„æ¨¡æ¨¡å‹æ± ï¼Œåœ¨ AutoML åœºæ™¯ä¸­æ›´å…·å®ç”¨æ€§ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **Playground Series S6E1 å›å½’ä»»åŠ¡**
  - æ ·æœ¬æ•°ï¼š`N_train = 100,000`
  - ç›®æ ‡èŒƒå›´ï¼š`[0, 100]`
  - æ•°æ®æ··åˆåˆæˆä¸çœŸå®åˆ†å¸ƒï¼Œæ”¯æŒé²æ£’æ€§åˆ†æ
- **ç¼©æ”¾å®éªŒ**ï¼šä½¿ç”¨åˆ†å±‚é‡‡æ ·çš„å­é›† `{0.1, 0.25, 0.5, 0.75} Ã— N_train`

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **åŸºç¡€æ¨¡å‹æ± ï¼ˆBase Model Poolï¼‰**
- æ€»è®¡ `K = 72` ä¸ªå¼‚æ„æ¨¡å‹
- åŒ…æ‹¬äº”ç±»ç®—æ³•ï¼š
  - Gradient Boostingï¼ˆXGBoost, LightGBMï¼‰
  - Neural Networks
  - Linear Models
  - Tree Ensembles
  - Kernel Methods
- ä½¿ç”¨ **10æŠ˜åˆ†å±‚äº¤å‰éªŒè¯** æ„å»ºæ— æ³„æ¼çš„ OOF é¢„æµ‹çŸ©é˜µ

#### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | è¯´æ˜ |
|------|------|
| **RMSE** | ä¸»è¦æŒ‡æ ‡ï¼ˆè¶Šä½è¶Šå¥½ï¼‰ |
| MAE | å¹³å‡ç»å¯¹è¯¯å·® |
| RÂ² | å†³å®šç³»æ•° |
| Pearson Correlation | é¢„æµ‹ä¸çœŸå®å€¼çš„ç›¸å…³æ€§ |
| **ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ** | æˆå¯¹åŒå°¾ t æ£€éªŒ + Bonferroni æ ¡æ­£ï¼ˆÎ±=0.001ï¼‰ |
| **ç½®ä¿¡åŒºé—´** | 1,000 æ¬¡ bootstrap é‡é‡‡æ ·å¾—åˆ° 95% CI |

#### **å¤ç°æ€§ä¿éšœ**
- æ‰€æœ‰å®éªŒå›ºå®šéšæœºç§å­ `seed=42`
- è¶…å‚æ•°æœç´¢ç½‘æ ¼æ˜ç¡®åˆ—å‡ºï¼ˆå¦‚ Ridge: Î» âˆˆ [10â»Â³, 10], 50 ä¸ªå€¼ï¼‰

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| åŸºçº¿æ–¹æ³• | æè¿° |
|---------|------|
| **Best Single Model** | è¡¨ç°æœ€å¥½çš„å•ä¸ªæ¨¡å‹ |
| **Simple Average (All)** | æ‰€æœ‰æ¨¡å‹ç­‰æƒå¹³å‡ |
| **Weighted Average (Performance)** | æŒ‰ 1/RMSE åŠ æƒå¹³å‡ |
| **Vanilla Stacking (OLS / Ridge)** | æ™®é€šçº¿æ€§/å²­å›å½’ stacking |
| **Greedy Hill Climbing** | è´ªå©ªå‰å‘é€‰æ‹©ä¼˜åŒ–æƒé‡ |
| **Neural Meta-Learner (MLP)** | æµ…å±‚ MLP å…ƒå­¦ä¹ å™¨ç”¨äºæ¯”è¾ƒ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 1ï¼‰**

| æ–¹æ³• | RMSE (OOF) | Î”RMSE vs Hill Climbing | #Models | Runtime (s) |
|------|-----------|------------------------|--------|-------------|
| Best Single Model | 9.247 | +0.665 | 1 | â€” |
| Simple Average | 8.894 | +0.312 | 45 | 3.2 |
| Weighted Average | 8.756 | +0.174 | 45 | 12.7 |
| Vanilla Ridge Stacking | 8.627 | +0.045 | 45 | 189.3 |
| **Greedy Hill Climbing** | **8.603** | â€” | **28** | **2,841.6** |
| **Proposed Full Pipeline** | **8.582** | **-0.021** | **37** | **712.8** |

> âœ… **ç»“è®º**ï¼šæå‡ºçš„å®Œæ•´æµç¨‹è¾¾åˆ° **RMSE = 8.582**ï¼Œç›¸å¯¹ hill climbing æå‡ 0.24%ï¼Œè™½æœªè¾¾ç»Ÿè®¡æ˜¾è‘—ï¼ˆp=0.639ï¼‰ï¼Œä½†åœ¨æ›´å¤§æ¨¡å‹é›†åˆä¸‹å®ç°æ›´é«˜æ•ˆè¿è¡Œã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- ç›¸æ¯” **ç®€å•å¹³å‡**ï¼šRMSE â†“3.51% ï¼ˆ8.894 â†’ 8.582ï¼‰
- ç›¸æ¯” **æœ€ä½³å•æ¨¡å‹**ï¼šRMSE â†“7.19%
- ç›¸æ¯” **æ ‡å‡† Ridge stacking**ï¼šRMSE â†“0.52%
- ç›¸æ¯” **greedy hill climbing**ï¼š
  - æ€§èƒ½ç›¸è¿‘ï¼ˆ+0.021 RMSE æ›´ä¼˜ï¼‰
  - æ¨¡å‹ä¿ç•™æ›´å¤šï¼ˆ37 vs 28ï¼‰
  - **è¿è¡Œé€Ÿåº¦å¿« 4 å€**ï¼ˆ712.8s vs 2,841.6sï¼‰

> ğŸ“ˆ å›¾ 2 æ˜¾ç¤ºè¯¥æ–¹æ³•ä½äº **accuracy-runtime Pareto frontier ä¸Šæ¸¸**ï¼Œæ˜¯éƒ¨ç½²å‹å¥½çš„é€‰æ‹©ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Study, Table 3ï¼‰**

é€æ­¥æ·»åŠ ç»„ä»¶çš„ç´¯è®¡æ•ˆæœï¼ˆä»¥ Ridge stacking ä¸ºåŸºå‡†ï¼‰ï¼š

| é˜¶æ®µ | RMSE ä¸‹é™ | è´¡çŒ®æ¯”ä¾‹ |
|------|----------|--------|
| åŸºçº¿ï¼ˆä»… Ridgeï¼‰ | 7.183 | â€” |
| + å¤šæŒ‡æ ‡å»é‡ | -0.089 | -1.24% |
| + æ–¹å·®å‰ªæ | -0.038 | -0.53% |
| + ç»Ÿè®¡èšåˆç‰¹å¾ | **-0.135** | **-1.88%** |
| + äº¤äº’ç‰¹å¾ | -0.048 | -0.67% |
| + å…ƒé›†æˆèåˆ | -0.131 | -1.82% |
| **æ€»è®¡æ”¹è¿›** | **â†“0.441 RMSE** | **â†“6.13%** |

> ğŸ” **å‘ç°**ï¼š
> - **ç»Ÿè®¡èšåˆç‰¹å¾**è´¡çŒ®æœ€å¤§ï¼Œè¯´æ˜å…ƒç‰¹å¾å·¥ç¨‹è‡³å…³é‡è¦ï¼›
> - **å†—ä½™æŠ•å½±**å¸¦æ¥æœ€ç¨³å®šå¢ç›Šï¼ŒéªŒè¯å…¶å¯¹æ¡ä»¶æ•°çš„æ”¹å–„ä½œç”¨ï¼›
> - å„æ¨¡å—å‘ˆ**ç´¯è¿›å¼æ”¹è¿›**ï¼Œè¯æ˜æ¡†æ¶è®¾è®¡åˆç†æ€§ã€‚

---

### **å…¶ä»–é‡è¦å®éªŒå‘ç°**

#### **å†—ä½™æŠ•å½±æ•ˆæœï¼ˆTable 2 & Figure 3ï¼‰**
- åˆå§‹æ¨¡å‹æ± ï¼š45 ä¸ª â†’ æŠ•å½±åä¿ç•™ 37 ä¸ªï¼ˆå‹ç¼©ç‡ 48.6%ï¼‰
- ç›¸å…³æ€§ > 0.95 ä¸”æ€§èƒ½è¾ƒå·®çš„æ¨¡å‹è¢«ç§»é™¤ï¼ˆå¹³å‡ Î”RMSE = +0.105ï¼‰
- æ¡ä»¶æ•°ä» **Îº â‰ˆ 847 â†’ Îº â‰ˆ 392**ï¼ˆâ†“53.7%ï¼‰ï¼Œæ˜¾è‘—æå‡æ•°å€¼ç¨³å®šæ€§

#### **æ­£åˆ™åŒ–è·¯å¾„åˆ†æï¼ˆFigure 4ï¼‰**
- Ridge åœ¨å®½ Î» èŒƒå›´å†…è¡¨ç°ç¨³å®šï¼ˆÎ» âˆˆ [0.6, 1.5]ï¼‰
- Lasso å®ç° 68% ç¨€ç–æ€§ï¼Œæƒé‡æ¥è¿‘é›¶ä½†ä»ä¿æŒç²¾åº¦
- ElasticNet æä¾›ç¨€ç–æ€§ä¸ç¨³å®šæ€§ä¹‹é—´çš„å¹³è¡¡

#### **è®¡ç®—æ•ˆç‡ï¼ˆTable 5ï¼‰**
- å°½ç®¡å†—ä½™æŠ•å½±å¤æ‚åº¦ä¸º O(KÂ²N)ï¼Œä½†ç”±äº K_eff å‡å°ï¼Œä¸‹æ¸¸ä»»åŠ¡åŠ é€Ÿæ˜æ˜¾
- æœ€ç»ˆæ¨ç†æˆæœ¬ä¸º O(K_eff)ï¼Œæ¯æ ·æœ¬å¼€é”€ä½ï¼Œåˆ©äºçº¿ä¸ŠæœåŠ¡

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **å†—ä½™æ§åˆ¶æ˜¯å…³é”®**ï¼šé€šè¿‡ correlation + MSE åŒé˜ˆå€¼å»é‡ï¼Œæœ‰æ•ˆç¼“è§£å¤šé‡å…±çº¿æ€§ï¼Œæå‡ meta-learning çš„ conditioningã€‚
2. **ç»Ÿè®¡å…ƒç‰¹å¾æå…·ä»·å€¼**ï¼šé›†æˆå‡å€¼ã€æ ‡å‡†å·®ã€äº¤äº’é¡¹ç­‰èƒ½æ•æ‰é«˜é˜¶æ¨¡å¼ï¼Œæ˜¾è‘—ä¼˜äºä»…ç”¨åŸå§‹é¢„æµ‹åˆ—ã€‚
3. **æ­£åˆ™åŒ– + èåˆæå‡ç¨³å®šæ€§**ï¼šRidge/Lasso/ElasticNet ç»“æœç›¸è¿‘ï¼Œèåˆåè¿›ä¸€æ­¥é™ä½æ–¹å·®ã€‚
4. **æ•ˆç‡-ç²¾åº¦æƒè¡¡ä¼˜è¶Š**ï¼šåœ¨æ¥è¿‘æœ€ä¼˜æ€§èƒ½çš„åŒæ—¶ï¼Œå¤§å¹…ç¼©çŸ­è®­ç»ƒæ—¶é—´ï¼Œæ›´é€‚åˆç”Ÿäº§ç¯å¢ƒã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
1. **ä¾èµ–åŸºç¡€æ¨¡å‹å¤šæ ·æ€§**ï¼šè‹¥æ‰€æœ‰æ¨¡å‹é«˜åº¦ç›¸ä¼¼ï¼Œå†—ä½™æŠ•å½±å¯èƒ½è¿‡åº¦å‹ç¼©ï¼›
2. **å†—ä½™æŠ•å½±å¤æ‚åº¦é«˜**ï¼šO(KÂ²N) ä¸é€‚ç”¨äºè¶…å¤§è§„æ¨¡æ¨¡å‹æ± ï¼ˆå¦‚ K > 1000ï¼‰ï¼Œéœ€å¼•å…¥è¿‘ä¼¼ç›¸ä¼¼æœç´¢ï¼›
3. **å¯¹åˆ†å¸ƒåç§»æ•æ„Ÿ**ï¼šå°šæœªç³»ç»Ÿæµ‹è¯•ä¸¥é‡åˆ†å¸ƒæ¼‚ç§»ä¸‹çš„è¡¨ç°ï¼›
4. **å½“å‰èšç„¦å›å½’ä»»åŠ¡**ï¼šåˆ†ç±»ä»»åŠ¡éœ€å¼•å…¥æ ¡å‡†æœºåˆ¶ï¼ˆcalibration-aware extensionï¼‰ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **è‡ªé€‚åº”æ­£åˆ™åŒ–è°ƒåº¦**ï¼šå¼€å‘ç›¸å…³æ€§æ„ŸçŸ¥çš„åŠ¨æ€æ­£åˆ™åŒ–ç­–ç•¥ï¼›
2. **ä¸ç¡®å®šæ€§é‡åŒ–**ï¼šç»“åˆ conformal prediction æˆ– Bayesian meta-learning æä¾›ç½®ä¿¡åŒºé—´ï¼›
3. **å¤šä»»åŠ¡/å¤šåŸŸæ‰©å±•**ï¼šæ¨å¹¿è‡³ multi-task å’Œ domain-adaptive ensemble settingï¼›
4. **åœ¨çº¿éå¹³ç¨³æµå¤„ç†**ï¼šæ”¯æŒ streaming data ä¸­çš„åŠ¨æ€æ¨¡å‹æ›´æ–°ä¸èåˆï¼›
5. **å¼€æºå®ç°æ¨åŠ¨è½åœ°**ï¼šå‘å¸ƒå¯å¤ç°ã€é¢å‘éƒ¨ç½²çš„ä»£ç åº“ï¼Œä¿ƒè¿›å·¥ä¸šç•Œé‡‡çº³ã€‚

---

> âœ… **æ€»ä½“è¯„ä»·**ï¼šæœ¬æ–‡æå‡ºçš„ **regularized meta-learning** æ¡†æ¶ä¸ºé«˜ç»´é›†æˆç³»ç»Ÿæä¾›äº†ä¸€ä¸ª**ç¨³å®šã€é«˜æ•ˆã€å¯è§£é‡Šä¸”æ˜“äºéƒ¨ç½²**çš„ stacking è§£å†³æ–¹æ¡ˆï¼Œåœ¨ MLSysï¼ˆæœºå™¨å­¦ä¹ ç³»ç»Ÿï¼‰åœºæ™¯ä¸­å…·æœ‰é‡è¦å®è·µæ„ä¹‰ã€‚

</details>

---

### 16. [Multi-Agent Model-Based Reinforcement Learning with Joint State-Action Learned Embeddings](https://arxiv.org/abs/2602.12520)

**Authors**: Zhizun Wang, David Meger  
**Category**: cs.LG  
**Published**: 2026-02-16  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.12520v1  

#### Abstract
Learning to coordinate many agents in partially observable and highly dynamic environments requires both informative representations and data-efficient training. To address this challenge, we present a novel model-based multi-agent reinforcement learning framework that unifies joint state-action rep...

---

### 17. [Flow-Factory: A Unified Framework for Reinforcement Learning in Flow-Matching Models](https://arxiv.org/abs/2602.12529)

**Authors**: Bowen Ping, Chengyou Jia, Minnan Luo, Hangwei Qian, Ivor Tsang  
**Category**: cs.LG  
**Published**: 2026-02-16  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.12529v1  

#### Abstract
Reinforcement learning has emerged as a promising paradigm for aligning diffusion and flow-matching models with human preferences, yet practitioners face fragmented codebases, model-specific implementations, and engineering complexity. We introduce Flow-Factory, a unified framework that decouples al...

---

### 18. [Efficient Personalized Federated PCA with Manifold Optimization for IoT Anomaly Detection](https://arxiv.org/abs/2602.12622)

**Authors**: Xianchao Xiu, Chenyi Huang, Wei Zhang, Wanquan Liu  
**Category**: cs.LG  
**Published**: 2026-02-16  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.12622v1  

#### Abstract
Internet of things (IoT) networks face increasing security threats due to their distributed nature and resource constraints. Although federated learning (FL) has gained prominence as a privacy-preserving framework for distributed IoT environments, current federated principal component analysis (PCA)...

---

### 19. [Resource-Efficient Gesture Recognition through Convexified Attention](https://arxiv.org/abs/2602.13030)

**Authors**: Daniel Schwartz, Dario Salvucci, Yusuf Osmanlioglu, Richard Vallett, Genevieve Dion, Ali Shokoufandeh  
**Category**: cs.LG  
**Published**: 2026-02-16  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.13030v1  

#### Abstract
Wearable e-textile interfaces require gesture recognition capabilities but face severe constraints in power consumption, computational capacity, and form factor that make traditional deep learning impractical. While lightweight architectures like MobileNet improve efficiency, they still demand thous...

---

### 20. [Can I Have Your Order? Monte-Carlo Tree Search for Slot Filling Ordering in Diffusion Language Models](https://arxiv.org/abs/2602.12586)

**Authors**: Joshua Ong Jun Leang, Yu Zhao, Mihaela C\u{a}t\u{a}lina Stoian, Wenda Li, Shay B. Cohen, Eleonora Giunchiglia  
**Category**: cs.AI  
**Published**: 2026-02-16  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.12586v1  

#### Abstract
While plan-and-infill decoding in Masked Diffusion Models (MDMs) shows promise for mathematical and code reasoning, performance remains highly sensitive to slot infilling order, often yielding substantial output variance. We introduce McDiffuSE, a framework that formulates slot selection as decision...

---

### 21. [Adaptive Structured Pruning of Convolutional Neural Networks for Time Series Classification](https://arxiv.org/abs/2602.12744)

**Authors**: Javidan Abdullayev, Maxime Devanne, Cyril Meyer, Ali Ismail-Fawaz, Jonathan Weber, Germain Forestier  
**Category**: cs.LG  
**Published**: 2026-02-16  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.12744v1  

#### Abstract
Deep learning models for Time Series Classification (TSC) have achieved strong predictive performance but their high computational and memory requirements often limit deployment on resource-constrained devices. While structured pruning can address these issues by removing redundant filters, existing...

---

### 22. [Uncertainty in Federated Granger Causality: From Origins to Systemic Consequences](https://arxiv.org/abs/2602.13004)

**Authors**: Ayush Mohanty, Nazal Mohamed, Nagi Gebraeel  
**Category**: cs.LG  
**Published**: 2026-02-16  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.13004v1  

#### Abstract
Granger Causality (GC) provides a rigorous framework for learning causal structures from time-series data. Recent federated variants of GC have targeted distributed infrastructure applications (e.g., smart grids) with distributed clients that generate high-dimensional data bound by data-sovereignty ...

---

### 23. [BrowseComp-$V^3$: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents](https://arxiv.org/abs/2602.12876)

**Authors**: Huanyao Zhang, Jiepeng Zhou, Bo Li, Bowen Zhou, Yanzhe Dan, Haishan Lu, Zhiyong Cao, Jiaoyang Chen, Yuqian Han, Zinan Sheng, Zhengwei Tao, Hao Liang, Jialong Wu, Yang Shi, Yuanpeng He, Jiaye Lin, Qintong Zhang, Guochen Yan, Runhao Zhao, Zhengpin Li, Xiaohan Yu, Lang Mei, Chong Chen, Wentao Zhang, Bin Cui  
**Category**: cs.AI  
**Published**: 2026-02-16  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.12876v1  

#### Abstract
Multimodal large language models (MLLMs), equipped with increasingly advanced planning and tool-use capabilities, are evolving into autonomous agents capable of performing multimodal web browsing and deep search in open-world environments. However, existing benchmarks for multimodal browsing remain ...

---

### 24. [A Theoretical Analysis of Mamba's Training Dynamics: Filtering Relevant Features for Generalization in State Space Models](https://arxiv.org/abs/2602.12499)

**Authors**: Mugunthan Shandirasegaran, Hongkang Li, Songyang Zhang, Meng Wang, Shuai Zhang  
**Category**: cs.LG  
**Published**: 2026-02-16  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.12499v1  

#### Abstract
The recent empirical success of Mamba and other selective state space models (SSMs) has renewed interest in non-attention architectures for sequence modeling, yet their theoretical foundations remain underexplored. We present a first-step analysis of generalization and learning dynamics for a simpli...

---

### 25. [RelBench v2: A Large-Scale Benchmark and Repository for Relational Data](https://arxiv.org/abs/2602.12606)

**Authors**: Justin Gu, Rishabh Ranjan, Charilaos Kanatsoulis, Haiming Tang, Martin Jurkovic, Valter Hudovernik, Mark Znidar, Pranshu Chaturvedi, Parth Shroff, Fengyu Li, Jure Leskovec  
**Category**: cs.LG  
**Published**: 2026-02-16  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.12606v1  

#### Abstract
Relational deep learning (RDL) has emerged as a powerful paradigm for learning directly on relational databases by modeling entities and their relationships across multiple interconnected tables. As this paradigm evolves toward larger models and relational foundation models, scalable and realistic b...

---

### 26. [Physics-Informed Laplace Neural Operator for Solving Partial Differential Equations](https://arxiv.org/abs/2602.12706)

**Authors**: Heechang Kim, Qianying Cao, Hyomin Shin, Seungchul Lee, George Em Karniadakis, Minseok Choi  
**Category**: cs.LG  
**Published**: 2026-02-16  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.12706v1  

#### Abstract
Neural operators have emerged as fast surrogate solvers for parametric partial differential equations (PDEs). However, purely data-driven models often require extensive training data and can generalize poorly, especially in small-data regimes and under unseen (out-of-distribution) input functions th...

---

### 27. [R-Diverse: Mitigating Diversity Illusion in Self-Play LLM Training](https://arxiv.org/abs/2602.13103)

**Authors**: Gengsheng Li, Jinghan He, Shijie Wang, Dan Zhang, Ruiqi Liu, Renrui Zhang, Zijun Yao, Junfeng Fang, Haiyun Guo, Jinqiao Wang  
**Category**: cs.LG  
**Published**: 2026-02-16  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.13103v1  

#### Abstract
Self-play bootstraps LLM reasoning through an iterative Challenger-Solver loop: the Challenger is trained to generate questions that target the Solver's capabilities, and the Solver is optimized on the generated data to expand its reasoning skills. However, existing frameworks like R-Zero often exhi...

---

### 28. [ProbeLLM: Automating Principled Diagnosis of LLM Failures](https://arxiv.org/abs/2602.12966)

**Authors**: Yue Huang, Zhengzhe Jiang, Yuchen Ma, Yu Jiang, Xiangqi Wang, Yujun Zhou, Yuexing Hao, Kehan Guo, Pin-Yu Chen, Stefan Feuerriegel, Xiangliang Zhang  
**Category**: cs.CL  
**Published**: 2026-02-16  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.12966v1  

#### Abstract
Understanding how and why large language models (LLMs) fail is becoming a central challenge as models rapidly evolve and static evaluations fall behind. While automated probing has been enabled by dynamic test generation, existing approaches often discover isolated failure cases, lack principled con...

---

### 29. [SciAgentGym: Benchmarking Multi-Step Scientific Tool-use in LLM Agents](https://arxiv.org/abs/2602.12984)

**Authors**: Yujiong Shen, Yajie Yang, Zhiheng Xi, Binze Hu, Huayu Sha, Jiazheng Zhang, Qiyuan Peng, Junlin Shang, Jixuan Huang, Yutao Fan, Jingqi Tong, Shihan Dou, Ming Zhang, Lei Bai, Zhenfei Yin, Tao Gui, Xingjun Ma, Qi Zhang, Xuanjing Huang, Yu-Gang Jiang  
**Category**: cs.CL  
**Published**: 2026-02-16  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.12984v1  

#### Abstract
Scientific reasoning inherently demands integrating sophisticated toolkits to navigate domain-specific knowledge. Yet, current benchmarks largely overlook agents' ability to orchestrate tools for such rigorous workflows. To bridge this gap, we introduce SciAgentGym, a scalable interactive environmen...

---

### 30. [Order Matters in Retrosynthesis: Structure-aware Generation via Reaction-Center-Guided Discrete Flow Matching](https://arxiv.org/abs/2602.13136)

**Authors**: Chenguang Wang, Zihan Zhou, Lei Bai, Tianshu Yu  
**Category**: cs.LG  
**Published**: 2026-02-16  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.13136v1  

#### Abstract
Template-free retrosynthesis methods treat the task as black-box sequence generation, limiting learning efficiency, while semi-template approaches rely on rigid reaction libraries that constrain generalization. We address this gap with a key insight: atom ordering in neural representations matters. ...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- kv cache, offload, State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
