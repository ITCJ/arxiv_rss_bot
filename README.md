# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-02-03 06:34:57 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Out of the Memory Barrier: A Highly Memory Efficient Training System for LLMs with Million-Token Contexts](https://arxiv.org/abs/2602.02108)

**Authors**: Wenhao Li, Daohai Yu, Gen Luo, Yuxin Zhang, Fei Chao, Rongrong Ji, Yifan Wu, Jiaxin Liu, Ziyang Gong, Zimu Liao  
**Category**: cs.CL  
**Published**: 2026-02-03  
**Score**: 19.0  
**Type**: new  
**ArXiv ID**: 2602.02108v1  

#### Abstract
Training Large Language Models (LLMs) on long contexts is severely constrained by prohibitive GPU memory overhead, not training time. The primary culprits are the activations, whose memory footprints scale linearly with sequence length. We introduce OOMB, a highly memory-efficient training system th...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**Out of the Memory Barrier: A Highly Memory Efficient Training System for LLMs with Million-Token Contexts**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
è®­ç»ƒå…·æœ‰ç™¾ä¸‡çº§ Token ä¸Šä¸‹æ–‡çš„ **Large Language Models (LLMs)** é¢ä¸´ä¸¥é‡çš„ **GPU å†…å­˜ç“¶é¢ˆ**ï¼Œå°¤å…¶æ˜¯æ¿€æ´»å€¼ï¼ˆactivationsï¼‰å’Œ KV Cache çš„å†…å­˜å ç”¨éšåºåˆ—é•¿åº¦çº¿æ€§å¢é•¿ï¼Œå¯¼è‡´å•å¡éš¾ä»¥å¤„ç†é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ã€‚ä¼ ç»Ÿæ–¹æ³•å¦‚ ZeRO3ã€Tensor Parallelism è™½å¯æ‰©å±•ï¼Œä½†ä¾èµ–å¤§è§„æ¨¡é›†ç¾¤ï¼Œæˆæœ¬é«˜æ˜‚ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼š**OOMB**
ä½œè€…æå‡º **OOMB**ï¼ˆOut Of the Memory Barrierï¼‰ï¼Œä¸€ä¸ªé«˜åº¦å†…å­˜é«˜æ•ˆçš„ LLM è®­ç»ƒç³»ç»Ÿï¼Œä¸“ä¸ºè¶…é•¿ä¸Šä¸‹æ–‡ï¼ˆç™¾ä¸‡ Token çº§åˆ«ï¼‰è®¾è®¡ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
- **Chunk-Recurrent Training Framework**  
  å°†é•¿åºåˆ—åˆ†å—ï¼ˆchunkï¼‰å¤„ç†ï¼Œå‰å‘ä¼ æ’­åç«‹å³ä¸¢å¼ƒä¸­é—´æ¿€æ´»å€¼ï¼Œåå‘ä¼ æ’­æ—¶æŒ‰éœ€é‡æ–°è®¡ç®—ï¼ˆon-the-fly activation recomputationï¼‰ã€‚è¯¥ç­–ç•¥ä½¿ **activation memory footprint ç»´æŒåœ¨ O(1)**ï¼Œä¸éšä¸Šä¸‹æ–‡é•¿åº¦å¢é•¿ã€‚

- **Paged KV Cache & Gradient Management**  
  å— PagedAttention å¯å‘ï¼Œå¼•å…¥åˆ†é¡µæœºåˆ¶ç®¡ç†ä¸æ–­å¢é•¿çš„ KV Cache å’Œå…¶æ¢¯åº¦ï¼Œé¿å…é¢‘ç¹å†…å­˜æ‹·è´ä¸ç¢ç‰‡åŒ–ï¼Œæå‡å†…å­˜åˆ©ç”¨ç‡ã€‚

- **Asynchronous CPU Offloading**  
  å¼‚æ­¥åœ°å°† KV Cache å’Œæ¢¯åº¦å¸è½½åˆ° CPU å†…å­˜ä¸­ï¼Œå¹¶é€šè¿‡ä¸“ç”¨ CUDA stream å’Œ DMA éšè—ä¼ è¾“å»¶è¿Ÿï¼Œæœ‰æ•ˆç¼“è§£æ˜¾å­˜å‹åŠ›ã€‚

- **Page-Level Sparse Attention**  
  æ”¯æŒé¡µç²’åº¦ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼ˆå¦‚ Top-K é¡µé¢æ£€ç´¢ï¼‰ï¼Œæ˜¾è‘—é™ä½æ³¨æ„åŠ›è®¡ç®—å¤æ‚åº¦å’Œé€šä¿¡å¼€é”€ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹æ€§èƒ½ã€‚

> å››å¤§ç»„ä»¶ååŒä½œç”¨ï¼Œå½¢æˆé—­ç¯ä¼˜åŒ–ä½“ç³»ï¼Œä»æ ¹æœ¬ä¸Šçªç ´äº†é•¿ä¸Šä¸‹æ–‡è®­ç»ƒçš„å†…å­˜å¢™ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | æ˜¾å­˜å¢é•¿è¶‹åŠ¿ | æ˜¯å¦æ”¯æŒå•å¡è®­ç»ƒ | æœ€å¤§ä¸Šä¸‹æ–‡ | æ‰€éœ€ç¡¬ä»¶è§„æ¨¡ |
|------|---------------|------------------|-------------|----------------|
| Parallel Training | O(N) | âŒï¼ˆçŸ­åºåˆ—å¯è¡Œï¼‰ | ~32Kâ€“128K | å•å¡ |
| Context Parallelism (e.g., Ring Attention) | O(N/P) | âœ…ï¼ˆå¤šå¡ï¼‰ | 256Kâ€“4M | å¤šGPUé›†ç¾¤ |
| **OOMB (æœ¬å·¥ä½œ)** | **~O(1)** | âœ… | **4M+** | **å•å¼  H200 GPU** |

- **èµ„æºæ•ˆç‡é£è·ƒ**ï¼šå®ç°å•å¡è®­ç»ƒ 400 ä¸‡ Token ä¸Šä¸‹æ–‡ï¼Œè€ŒåŒç±»æ–¹æ³•éœ€æ•°ç™¾ GPU é›†ç¾¤ã€‚
- **å†…å­˜å¢é•¿æä½**ï¼šæ¯å¢åŠ  10K tokensï¼Œç«¯åˆ°ç«¯è®­ç»ƒå†…å­˜ä»…å¢åŠ çº¦ **10MB**ï¼ˆå¯¹ Qwen2.5-7Bï¼‰ã€‚
- **æ— éœ€ä¸“ç”¨é«˜å¸¦å®½ç½‘ç»œ**ï¼šç›¸æ¯” Context Parallelism å¯¹ NCCL/IB çš„å¼ºä¾èµ–ï¼ŒOOMB æ›´é€‚åˆé€šç”¨éƒ¨ç½²ç¯å¢ƒã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- ä¸»è¦ä½¿ç”¨ **arXiv dataset**ï¼ˆç»æ¸…æ´—å»é‡åçš„ç§‘å­¦æ–‡çŒ®è¯­æ–™ï¼‰
- æ„é€ è¶…é•¿åºåˆ—æ–¹å¼ï¼šå°†å¤šä¸ªæ ·æœ¬æ‹¼æ¥æˆæŒ‡å®šé•¿åº¦ï¼ˆå¦‚ 256K, 1M, 4M tokensï¼‰

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼š`Qwen2.5-7B`ï¼ˆ70äº¿å‚æ•°åŸºç¡€æ¨¡å‹ï¼‰
- **ç¡¬ä»¶å¹³å°**ï¼šå•å¼ æˆ–å››å¼  NVIDIA H200 GPUï¼ˆéƒ¨åˆ†å¯¹æ¯”å®éªŒä½¿ç”¨ A100/TPUï¼‰
- **ç²¾åº¦**ï¼šbfloat16
- **ä¼˜åŒ–å™¨**ï¼šAdam (`lr=5e-5`, `betas=(0.9, 0.98)`ï¼‰
- **Batch Size**ï¼šæ¯å¡ batch size = 1ï¼Œä»¥éš”ç¦»åºåˆ—é•¿åº¦å½±å“
- **Page Size**ï¼šKV Cache åˆ†é¡µå¤§å°è®¾ä¸º 128 tokens

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Peak GPU Memory Usage** | å•æ¬¡è¿­ä»£å³°å€¼æ˜¾å­˜å ç”¨ï¼ˆMB/GBï¼‰ |
| **Per-iteration Latency** | å•æ­¥è®­ç»ƒè€—æ—¶ï¼ˆç§’ï¼‰ |
| **Throughput (tokens/sec)** | æ¯è®¾å¤‡æ¯ç§’å¤„ç† token æ•°é‡ |
| **Gradient Approximation Error (L2 Norm)** | ç¨€ç–æ³¨æ„åŠ›å¸¦æ¥çš„æ¢¯åº¦è¿‘ä¼¼è¯¯å·® |
| **Training Loss Curve** | ä¸åŒé…ç½®ä¸‹çš„æ”¶æ•›è¡Œä¸º |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|--------|------|------|
| **Standard Parallel Training + FlashAttention + Gradient Checkpointing** | å…¨å¹¶è¡Œè®­ç»ƒ | å½“å‰ä¸»æµé«˜æ•ˆå®ç°ï¼Œä½†ä»å—æ˜¾å­˜é™åˆ¶ |
| **Ring Flash Attention (RFA)** | Context Parallelism ä»£è¡¨ | åˆ†å¸ƒå¼åˆ‡åˆ†ä¸Šä¸‹æ–‡ï¼Œé€šä¿¡å¼€é”€å¤§ |
| **SeCO (Li et al., 2025)** | Chunk-wise æ–¹æ³•å…ˆé©± | ç¼ºä¹åº•å±‚ä¼˜åŒ–ï¼Œæ‰©å±•æ€§å·® |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 2 & Figure 8ï¼‰

#### âœ… å†…å­˜æ•ˆç‡æƒŠäºº
- å¯¹äº **Qwen2.5-7B** æ¨¡å‹ï¼š
  - æ¯å¢åŠ  **10K tokens ä¸Šä¸‹æ–‡**ï¼Œç«¯åˆ°ç«¯è®­ç»ƒå†…å­˜ä»…å¢åŠ  **çº¦ 10MB**
  - åœ¨ **4M-token ä¸Šä¸‹æ–‡** ä¸‹ä»å¯åœ¨ **å•å¼  H200 GPU** ä¸Šè¿è¡Œ
  - ä½¿ç”¨ç¨€ç–æ³¨æ„åŠ›æ—¶ï¼Œ**å³°å€¼æ˜¾å­˜å‡ ä¹æ’å®š**ï¼ˆ~33â€“38 GBï¼‰ï¼Œä¸å—ä¸Šä¸‹æ–‡é•¿åº¦å½±å“

#### â±ï¸ æ¨ç†ä¸è®­ç»ƒé€Ÿåº¦ä¼˜åŠ¿
| ä¸Šä¸‹æ–‡é•¿åº¦ | æ–¹æ³• | ååé‡ (tokens/sec/device) |
|----------|------|----------------------------|
| 64K | RFA (16Ã—TPUv4) | 49 |
| 64K | OOMB + Dense Attn (1Ã—H200) | **936.22** |
| 64K | OOMB + Sparse Attn (1Ã—H200) | **1560.38** âœ… |
| 256K | RFA (8Ã—A100) | 50 |
| 256K | OOMB + Sparse Attn (1Ã—H200) | **1301.60** âœ… |

> OOMB åœ¨ **å•ä½è®¾å¤‡ååé‡ä¸Šè¿œè¶… Context Parallelism æ–¹æ¡ˆ**ï¼Œä¸”æ— éœ€å¤šå¡åŒæ­¥ã€‚

#### ğŸ“ˆ å¯æ‰©å±•æ€§éªŒè¯ï¼ˆFigure 8ï¼‰
- æˆåŠŸåœ¨ **8 million tokens** ä¸Šä¸‹æ–‡é•¿åº¦ä¸‹å®Œæˆè®­ç»ƒ
- ä½¿ç”¨ç¨€ç–æ³¨æ„åŠ›æ—¶ï¼Œè®­ç»ƒæ—¶é—´å‘ˆè¿‘ä¼¼çº¿æ€§å¢é•¿ï¼Œå…·å¤‡è‰¯å¥½å¯æ‰©å±•æ€§

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰Chunk Size å½±å“ï¼ˆFigure 9ï¼‰
- å¢å¤§ chunk sizeï¼ˆå¦‚ä» 512 åˆ° 4096ï¼‰å¯æå‡ç¡¬ä»¶åˆ©ç”¨ç‡å’Œåå
- ä½†æ”¶ç›Šé€’å‡ï¼Œè¶…è¿‡ 4096 åæ€§èƒ½æå‡æœ‰é™
- æ¨èé»˜è®¤å€¼ï¼š**4096 tokens/chunk**

#### ï¼ˆ2ï¼‰CPU Offloading å¼€å¯å‰åå¯¹æ¯”
- å¼€å¯å¼‚æ­¥å¸è½½åï¼Œæ˜¾å­˜å³°å€¼ä¸‹é™ **è¶…è¿‡ 50%**
- æ—¶é—´å¼€é”€å¢åŠ  <5%ï¼Œè¢«è®¡ç®—å®Œå…¨æ©ç›–ï¼ˆlatency hiding æˆåŠŸï¼‰

#### ï¼ˆ3ï¼‰Sparse Attention Retrieval Budget å½±å“
- ä½¿ç”¨ `4K+8192`ï¼ˆlocal + top-kï¼‰é¢„ç®—å³å¯é€¼è¿‘ dense attention æ€§èƒ½
- æ›´å¤§çš„ budgetï¼ˆå¦‚ 32768ï¼‰å¸¦æ¥è¾¹é™…æ”¶ç›Šé€’å‡
- æ¢¯åº¦è¿‘ä¼¼è¯¯å·®ï¼ˆL2 normï¼‰åœ¨åˆç†èŒƒå›´å†…ï¼ˆè§ Figure 7ï¼‰

#### ï¼ˆ4ï¼‰ä¸åŒ Attention ç±»å‹å¯¹æ¯”ï¼ˆTable 2ï¼‰
| é…ç½® | æ˜¾å­˜å¢é•¿é€Ÿç‡ | ç›¸å¯¹åŸºçº¿å‡å°‘å€æ•° |
|------|--------------|------------------|
| Baseline (FlashAttn + ckpt) | å¿«é€Ÿä¸Šå‡ â†’ OOM at 128K | â€” |
| OOMB w/o offload | ç¼“æ…¢ä¸Šå‡ | â†“ >5Ã— |
| OOMB w/ offload | å‡ ä¹å¹³å¦ | â†“ >10Ã— |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **æ¿€æ´»å†…å­˜ä¸å†æ˜¯ç“¶é¢ˆ**ï¼šé€šè¿‡ chunk-recurrent + activation recomputationï¼Œå®ç°äº† **O(1) æ¿€æ´»å†…å­˜å ç”¨**ã€‚
2. **KV Cache æˆä¸ºæ–°ç“¶é¢ˆ**ï¼šå¿…é¡»ç»“åˆåˆ†é¡µç®¡ç†ã€å¼‚æ­¥å¸è½½ä¸ç¨€ç–æ³¨æ„åŠ›æ‰èƒ½å½»åº•è§£å†³ã€‚
3. **å››å¤§æŠ€æœ¯æ·±åº¦è€¦åˆã€ç¼ºä¸€ä¸å¯**ï¼š
   - Chunk-wise training â†’ è§¦å‘åç»­æ‰€æœ‰ä¼˜åŒ–
   - Paged KV Cache â†’ æ”¯æŒåŠ¨æ€å¢é•¿ä¸é«˜æ•ˆè®¿é—®
   - Sparse Attention â†’ é™ä½è®¡ç®—ä¸é€šä¿¡è´Ÿè½½
   - Async Offloading â†’ å®ç°æ˜¾å­˜æº¢å‡ºæ§åˆ¶
4. **å•å¡ç™¾ä¸‡ Token è®­ç»ƒæˆä¸ºç°å®**ï¼šOOMB ä½¿å¾—åŸæœ¬éœ€è¦æ•°ç™¾ GPU é›†ç¾¤çš„ä»»åŠ¡å¯åœ¨ **å•å¼  H200 ä¸Šå®Œæˆ**ï¼Œæå¤§é™ä½é—¨æ§›ã€‚

### âš ï¸ å±€é™æ€§
1. **ä¸²è¡Œå¤„ç†å¼•å…¥å»¶è¿Ÿ**ï¼šchunk-wise åºåˆ—å¤„ç†ç‰ºç‰²äº†ä¸€å®šå¹¶è¡Œæ€§ï¼Œåœ¨é«˜åååœºæ™¯å¯èƒ½å—é™ã€‚
2. **ç¨€ç–æ³¨æ„åŠ›æ˜¯è¿‘ä¼¼æ–¹æ³•**ï¼šè™½ç„¶å®éªŒè¯æ˜æœ‰æ•ˆï¼Œä½†åœ¨æŸäº›éœ€è¦å…¨å±€å¯†é›†äº¤äº’çš„ä»»åŠ¡ä¸­å¯èƒ½å­˜åœ¨æ€§èƒ½æŸå¤±ã€‚
3. **ä¾èµ– CPU-GPU å¸¦å®½**ï¼šå¼‚æ­¥å¸è½½æ•ˆç‡å— PCIe/NVLink å¸¦å®½åˆ¶çº¦ï¼Œåœ¨ä½ç«¯å¹³å°ä¸Šæ•ˆæœæ‰“æŠ˜ã€‚
4. **å°šæœªæ¢ç´¢æ›´å¤æ‚çš„ç¨€ç–æ¨¡å¼**ï¼šå½“å‰é‡‡ç”¨ Top-K æ£€ç´¢ï¼Œæœªæ¥å¯é›†æˆæ›´æ™ºèƒ½çš„ routing æˆ– MoE-style attentionã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ **åŠ¨æ€ chunk size è°ƒåº¦ç­–ç•¥**ï¼Œé€‚åº”ä¸åŒè¾“å…¥åˆ†å¸ƒ
- ç»“åˆ **MoE æ¶æ„** è¿›ä¸€æ­¥æå‡é•¿ä¸Šä¸‹æ–‡ä¸‹çš„è®¡ç®—æ•ˆç‡
- è®¾è®¡ **å­¦ä¹ å¼ç¨€ç– attention è·¯ç”±æœºåˆ¶**ï¼Œè¶…è¶Šå¯å‘å¼ Top-K
- å°† OOMB æ‰©å±•è‡³ **å¤šæ¨¡æ€é•¿åºåˆ—å»ºæ¨¡**ï¼ˆå¦‚è§†é¢‘ã€åŸºå› ç»„ç­‰ï¼‰

---

## ğŸ’¡ æ€»ç»“ä¸€å¥è¯
> **OOMB é€šè¿‡â€œåˆ†å—è®­ç»ƒ + åˆ†é¡µ KV + å¼‚æ­¥å¸è½½ + ç¨€ç–æ³¨æ„åŠ›â€å››ä½ä¸€ä½“æ¶æ„ï¼Œé¦–æ¬¡å®ç°äº†åœ¨å•å¼  GPU ä¸Šé«˜æ•ˆè®­ç»ƒç™¾ä¸‡ä¹ƒè‡³åƒä¸‡ Token ä¸Šä¸‹æ–‡çš„ LLMï¼Œæ‰“ç ´äº†ä¼ ç»Ÿè®­ç»ƒç³»ç»Ÿçš„å†…å­˜å£å’ï¼Œæ¨åŠ¨é•¿ä¸Šä¸‹æ–‡æ¨¡å‹èµ°å‘æ™®æƒ åŒ–ä¸å¯æŒç»­å‘å±•ã€‚**

ğŸ”— **å¼€æºåœ°å€**ï¼š[Github Repository](https://github.com/anonymous)ï¼ˆåŸæ–‡æä¾›åŒ¿åé“¾æ¥ï¼‰

</details>

---

### 2. [Scalable Generative Game Engine: Breaking the Resolution Wall via Hardware-Algorithm Co-Design](https://arxiv.org/abs/2602.00608)

**Authors**: Wei Zeng, Xuchen Li, Ruili Feng, Zhen Liu, Fengwei An, Jian Zhao  
**Category**: cs.AI  
**Published**: 2026-02-03  
**Score**: 14.0  
**Type**: new  
**ArXiv ID**: 2602.00608v1  

#### Abstract
Real-time generative game engines represent a paradigm shift in interactive simulation, promising to replace traditional graphics pipelines with neural world models. However, existing approaches are fundamentally constrained by the ``Memory Wall,'' restricting practical deployments to low resolution...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šScalable Generative Game Engine: Breaking the Resolution Wall via Hardware-Algorithm Co-Design

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
ä¼ ç»Ÿæ¸¸æˆå¼•æ“ä¾èµ–æ˜¾å¼çš„ç‰©ç†è§„åˆ™å’Œå…‰æ …åŒ–æ¸²æŸ“æµç¨‹ï¼Œè€Œ**ç”Ÿæˆå¼æ¸¸æˆå¼•æ“**ï¼ˆGenerative Game Engineï¼‰é€šè¿‡ç¥ç»ä¸–ç•Œæ¨¡å‹ï¼ˆNeural World Modelsï¼‰ç›´æ¥ä»åƒç´ æˆ–æ½œåœ¨ç©ºé—´ç”Ÿæˆæ¸¸æˆç”»é¢ï¼Œå®ç°â€œç”Ÿæˆå³æ¨¡æ‹Ÿâ€ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å—é™äºâ€œ**Memory Wall**â€â€”â€”é«˜åˆ†è¾¨ç‡ç”Ÿæˆéœ€è¦å¤§é‡å†…å­˜å¸¦å®½ï¼Œå¯¼è‡´æ¨ç†å»¶è¿Ÿæé«˜ï¼ˆå¸¸è¶…è¿‡50â€“100msï¼‰ï¼Œæ— æ³•æ»¡è¶³å®æ—¶äº¤äº’éœ€æ±‚ï¼ˆå¦‚60 FPSéœ€â‰¤16.6msï¼‰ã€‚å°¤å…¶åœ¨æ ‡å‡†æ¸…æ™°åº¦ï¼ˆ720Ã—480ï¼‰ä¸‹ï¼Œç°æœ‰ç³»ç»Ÿä»…èƒ½æ”¯æŒæä½åˆ†è¾¨ç‡ï¼ˆå¦‚64Ã—64ï¼‰ï¼Œä¸¥é‡é™åˆ¶äº†å®é™…åº”ç”¨ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§**å¯æ‰©å±•çš„ç¡¬ä»¶-ç®—æ³•ååŒè®¾è®¡æ¡†æ¶**ï¼ˆHardware-Algorithm Co-Designï¼‰ï¼Œä»¥çªç ´ç”Ÿæˆå¼æ¸¸æˆå¼•æ“çš„åˆ†è¾¨ç‡ç“¶é¢ˆã€‚å…¶ä¸‰å¤§æ ¸å¿ƒåˆ›æ–°ä¸ºï¼š

1. **å¼‚æ„è®¡ç®—æ¶æ„ä¸èµ„æºåˆ†é…ç­–ç•¥**  
   å°†è®¡ç®—å¯†é›†å‹çš„ **World Model**ï¼ˆåŸºäº DiTï¼‰ä¸å†…å­˜å¯†é›†å‹çš„ **Decoder**ï¼ˆåŸºäº VAEï¼‰è§£è€¦ï¼Œå¹¶åœ¨AIåŠ é€Ÿå™¨é›†ç¾¤ä¸­é‡‡ç”¨ä¸åŒçš„å¹¶è¡Œç­–ç•¥ï¼š
   - DiT ä½¿ç”¨ **Sequence Parallelism**ï¼ˆUlyssesï¼‰
   - VAE ä½¿ç”¨ **Spatial Parallelism**
   å¹¶é€šè¿‡ç†è®ºå»ºæ¨¡æ¨å¯¼å‡ºæœ€ä¼˜è®¾å¤‡åˆ†é…æ¯”ä¾‹ï¼ˆ5:3ï¼‰ï¼Œæœ€å¤§åŒ–ååé‡ã€‚

2. **å†…å­˜ä¸­å¿ƒåŒ–çš„ç®—å­èåˆä¼˜åŒ–**ï¼ˆMemory-Centric Operator Fusionï¼‰
   åˆ©ç”¨ç°ä»£AIèŠ¯ç‰‡çš„æ˜¾å¼å†…å­˜å±‚æ¬¡ï¼ˆå¦‚SRAMï¼‰ï¼Œå¯¹è®¡ç®—å›¾è¿›è¡Œé‡æ„ï¼š
   - åœ¨VAEä¸­å®æ–½**å‚ç›´èåˆ**ï¼ˆVertical Fusionï¼‰ï¼šå°† `Upsample â†’ Conv2d â†’ GroupNorm â†’ SiLU` èåˆä¸ºå•ä¸ªæ ¸å‡½æ•°ï¼Œå‡å°‘75%çš„HBMè®¿é—®ã€‚
   - åœ¨DiTä¸­å®æ–½**æ°´å¹³èåˆ**ï¼ˆHorizontal Fusionï¼‰ï¼šåˆå¹¶AdaLNä¸­çš„å¤šä¸ªå°çŸ©é˜µä¹˜æ³•ï¼Œæå‡è®¡ç®—å¯†åº¦è‡³ç†è®ºå³°å€¼çš„85%ä»¥ä¸Šã€‚

3. **æµå½¢æ„ŸçŸ¥çš„æ½œåœ¨å¤–æ¨æœºåˆ¶**ï¼ˆManifold-Aware Latent Extrapolationï¼‰
   åˆ©ç”¨è¿ç»­å¸§ä¹‹é—´çš„æ—¶åºå†—ä½™ï¼Œåœ¨åŠ¨ä½œç¨³å®šæ—¶è·³è¿‡éƒ¨åˆ†DiTè®¡ç®—ï¼Œä½¿ç”¨çº¿æ€§å¤–æ¨é¢„æµ‹ä¸‹ä¸€å¸§æ½œå˜é‡ $ z_{t+1} \approx z_t + \Delta t \cdot v_t $ï¼Œä»è€Œé™ä½å¹³å‡è®¡ç®—è´Ÿè½½ã€‚

æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†**æ¨æµ‹æ€§åŠ¨ä½œé¢„å–**ï¼ˆSpeculative Action Prefetchingï¼‰ï¼Œåˆ©ç”¨è½»é‡çº§LSTMé¢„æµ‹ç”¨æˆ·è¾“å…¥ï¼Œå‘½ä¸­ç‡è¾¾93%ï¼Œæ˜¾è‘—é™ä½æ„ŸçŸ¥å»¶è¿Ÿã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **é¦–æ¬¡å®ç°åœ¨720Ã—480åˆ†è¾¨ç‡ä¸‹çš„å®æ—¶ç”Ÿæˆ**ï¼Œç›¸æ¯”åŸºçº¿ï¼ˆå¦‚Diamondçš„64Ã—64ï¼‰æå‡çº¦50å€åƒç´ ååã€‚
- é€šè¿‡**ä½“ç³»ç»“æ„çº§ååŒè®¾è®¡**è€Œéå•çº¯ç®—æ³•ä¼˜åŒ–ï¼Œä»æ ¹æœ¬ä¸Šç¼“è§£Memory Wallé—®é¢˜ã€‚
- å®ç°äº†**é«˜ä¿çœŸä¸ä½å»¶è¿Ÿçš„ç»Ÿä¸€**ï¼š26.4 FPS @ 720Ã—480ï¼Œæ„ŸçŸ¥å»¶è¿Ÿä»…2.7msï¼Œè¿œä½äºäººç±»æ„ŸçŸ¥é˜ˆå€¼ã€‚
- æ”¯æŒé€»è¾‘ä¸€è‡´æ€§ï¼ˆ100%è®­ç»ƒåˆ†å¸ƒå†…æ­£ç¡®æ€§ï¼‰ï¼Œä¼˜äºçº¯ç¼“å­˜æˆ–å‰ªæç±»æ–¹æ³•ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
è®ºæ–‡æ„å»ºäº†ä¸¤ä¸ªåŸºå‡†æµ‹è¯•ç¯å¢ƒï¼Œè¦†ç›–è¿ç»­ä¸ç¦»æ•£æ§åˆ¶åœºæ™¯ï¼š

1. **Matrix**ï¼ˆContinuous Domainï¼‰  
   - é«˜ä¿çœŸ3Dèµ›è½¦æ¨¡æ‹Ÿå™¨ï¼Œåˆ†è¾¨ç‡ä¸º **720Ã—480**
   - å¼ºè°ƒè¿ç»­åŠ¨åŠ›å­¦ã€æ‘©æ“¦åŠ›ã€åŠ¨é‡ç­‰éšå¼ç‰©ç†è§„å¾‹çš„å­¦ä¹ 
   - ç”¨äºè¯„ä¼°æ§åˆ¶æ•æ„Ÿæ€§å’Œè§†è§‰è¿è´¯æ€§

2. **Playable Game Generation (PGG)**ï¼ˆDiscrete Domainï¼‰  
   - 2Då¹³å°è·³è·ƒæ¸¸æˆï¼Œåˆ†è¾¨ç‡ä¸º **256Ã—256**
   - å¼ºè°ƒå¸ƒå°”é€»è¾‘ã€ç¢°æ’æ£€æµ‹ã€çŠ¶æ€è½¬ç§»çš„ç²¾ç¡®æ€§
   - ç”¨äºè¯„ä¼°é€»è¾‘ä¸€è‡´æ€§å’Œç¦»æ•£è¡Œä¸ºå»ºæ¨¡èƒ½åŠ›

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### ç¡¬ä»¶å¹³å°
- **8å— Huawei Ascend 910C NPU** ç»„æˆé›†ç¾¤
- å•å¡æ€§èƒ½ï¼š752 TFLOPS FP16ï¼Œ64GB HBM
- é«˜é€Ÿäº’è”ï¼šHCCSç¯å½¢æ‹“æ‰‘ï¼Œå¸¦å®½30 GB/s
- æ§åˆ¶å¹³é¢ï¼šåŒè·¯Intel Xeon Platinum CPU + Rayåˆ†å¸ƒå¼è°ƒåº¦æ¡†æ¶

#### è½¯ä»¶æ ˆ
- CANN 8.0, PyTorch 2.5.1, xfuserï¼ˆæ”¯æŒUlysseså¹¶è¡Œï¼‰

#### è¯„ä¼°æŒ‡æ ‡
| ç±»åˆ« | æŒ‡æ ‡ | æè¿° |
|------|------|------|
| **æ€§èƒ½** | FPS, Motion-to-Photon Latency (M2P) | è¡¡é‡ç”Ÿæˆé€Ÿåº¦ä¸å“åº”å»¶è¿Ÿ |
| **è´¨é‡** | FID, PSNR, SSIM, LPIPS | è§†è§‰ä¿çœŸåº¦ï¼ˆè¶Šä½è¶Šå¥½ / è¶Šé«˜è¶Šå¥½ï¼‰ |
| **ç‰©ç†æœ‰æ•ˆæ€§** | Control Sensitivity Analysis (CSA) | è¿ç»­åŸŸä¸­è½¬å‘è¾“å…¥ä¸åèˆªç‡çš„ç›¸å…³æ€§ |
| **é€»è¾‘ä¸€è‡´æ€§** | Discrete Logic Boundary (DLB) Score | ç¦»æ•£åŸŸä¸­æ— æ•ˆçŠ¶æ€è½¬ç§»çš„æ¯”ä¾‹ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | ç¡¬ä»¶ | åˆ†è¾¨ç‡ | FPS | å¤‡æ³¨ |
|------|------|--------|-----|------|
| **Diamond** [6] | RTX 3090 | 64Ã—64 | 10.0 | æ‰©æ•£æ¨¡å‹ç”¨äºCS:GO |
| **GameNGen** [4] | TPU v5 | 320Ã—240 | >20 | Googleæå‡ºçš„ç”Ÿæˆå¼å¼•æ“ |
| **PGG Baseline** | RTX 5090 | 256Ã—256 | 29.9 | å¼€æº2Då¹³å°æ¸¸æˆç”Ÿæˆæ¨¡å‹ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| åœºæ™¯ | åˆ†è¾¨ç‡ | FPS | æ„ŸçŸ¥å»¶è¿Ÿï¼ˆM2Pï¼‰ | FID | LPIPS |
|------|--------|-----|------------------|-----|-------|
| **Ours (Matrix)** | 720Ã—480 | **26.4** | **2.7ms** | 42.3 | 0.087 |
| **Ours (PGG)** | 256Ã—256 | **48.3** | â€” | **28.5** | **0.052** |

> æ³¨ï¼šæ„ŸçŸ¥å»¶è¿Ÿç»æ¨æµ‹æ€§é¢„å–åæ‘Šé”€è‡³2.7msï¼ŒåŸå§‹ç«¯åˆ°ç«¯å»¶è¿Ÿä¸º38msã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨**è¿ç»­3Dé¢†åŸŸ**ï¼ˆMatrixï¼‰ï¼š
  - è¾¾åˆ° **26.4 FPS @ 720Ã—480**ï¼Œç›¸è¾ƒDiamondï¼ˆ64Ã—64, 10 FPSï¼‰å®ç°**50å€åƒç´ ååæå‡**
  - FIDä»89.5ï¼ˆDiamondï¼‰é™è‡³42.3ï¼Œæ˜¾ç¤ºæ›´å¼ºçš„è§†è§‰çœŸå®æ„Ÿ
- åœ¨**ç¦»æ•£2Dé¢†åŸŸ**ï¼ˆPGGï¼‰ï¼š
  - å•å¡å³è¾¾ **48.3 FPS**ï¼Œè¶…è¶ŠRTX 5090ä¸Šçš„PGGåŸºçº¿ï¼ˆ29.9 FPSï¼‰
  - DLBå¾—åˆ†ä¸º **100.0%**ï¼ˆæ— è¿è§„çŠ¶æ€è½¬ç§»ï¼‰ï¼Œæ˜¾è‘—ä¼˜äºéæ—¶åºæ³¨æ„åŠ›åŸºçº¿ï¼ˆ85.3%ï¼‰

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
| é˜¶æ®µ | æ¶æ„ | FPS | Speedup |
|------|------|-----|---------|
| Baselineï¼ˆé¡ºåºæ‰§è¡Œï¼‰ | å•å¡ | 2.1 | 1.0x |
| + Operator Fusion | å•å¡ | 4.5 | 2.1x |
| + Ulysses (3:5) | 3 DiT + 5 VAE | 16.6 | 7.9x |
| + Optimal Ratio (5:3) | 5 DiT + 3 VAE | 19.4 | 9.2x |
| + Latent Extrapolation | 5:3 | 26.4 | 12.6x |
| + Speculative Prefetch | 5:3 | 26.4ï¼ˆ2.7mså»¶è¿Ÿï¼‰ | 12.6x |

> å¦‚å›¾7æ‰€ç¤ºï¼Œå„é˜¶æ®µä¼˜åŒ–ç´¯è®¡å¸¦æ¥ **12.6å€çš„ç³»ç»Ÿçº§æ€§èƒ½æå‡**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **â€œMemory Wallâ€æ˜¯é«˜åˆ†è¾¨ç‡ç”Ÿæˆå¼æ¸¸æˆçš„æ ¸å¿ƒç“¶é¢ˆ**ï¼Œä»…é è½¯ä»¶ä¼˜åŒ–æ— æ³•è§£å†³ï¼›å¿…é¡»é€šè¿‡**ç¡¬ä»¶-ç®—æ³•ååŒè®¾è®¡**æ¥æ‰“ç ´ã€‚
2. **å¼‚æ„å¹¶è¡Œç­–ç•¥**ï¼ˆcompute-bound vs memory-boundï¼‰èƒ½å¤Ÿæœ‰æ•ˆå¹³è¡¡ç³»ç»Ÿè´Ÿè½½ï¼Œ5:3çš„DiT:VAEèµ„æºé…ç½®è¢«è¯æ˜æ˜¯æœ€ä¼˜è§£ã€‚
3. **æ˜¾å¼å†…å­˜ç®¡ç†**ï¼ˆå¦‚SRAMèåˆï¼‰æ¯”é€šç”¨GPUçš„ç¼“å­˜æœºåˆ¶æ›´é«˜æ•ˆï¼Œå¯å‡å°‘é«˜è¾¾75%çš„HBMæµé‡ã€‚
4. **æ—¶é—´å†—ä½™å¯è¢«å®‰å…¨åˆ©ç”¨**ï¼šManifold-Aware Latent Extrapolationå¯åœ¨ä¿æŒè§†è§‰è¿è´¯çš„åŒæ—¶è·³è¿‡35%çš„DiTè®¡ç®—ã€‚
5. **ç”Ÿæˆå¼å¼•æ“å¯å­¦ä¹ éšå¼ç‰©ç†è§„å¾‹**ï¼šåœ¨Matrixä¸­è§‚å¯Ÿåˆ°â€œæ¶Œç°æƒ¯æ€§â€ç°è±¡ï¼Œè¡¨æ˜æ¨¡å‹å·²å†…éƒ¨åŒ–åŠ¨é‡å®ˆæ’ç­‰ç‰©ç†ç‰¹æ€§ã€‚
6. **é€»è¾‘ä¸€è‡´æ€§å¯åœ¨è®­ç»ƒåˆ†å¸ƒå†…ä¸¥æ ¼ä¿è¯**ï¼šPGGä»»åŠ¡ä¸­å®ç°100% DLBå¾—åˆ†ï¼ŒéªŒè¯äº†ç³»ç»Ÿçš„å¯é æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–å¤§è§„æ¨¡åŠ é€Ÿå™¨é›†ç¾¤**ï¼šå½“å‰æ–¹æ¡ˆé€‚ç”¨äºäº‘æ¸¸æˆåœºæ™¯ï¼Œéš¾ä»¥éƒ¨ç½²äºè¾¹ç¼˜è®¾å¤‡æˆ–æ¶ˆè´¹çº§PCã€‚
2. **Out-of-Distributionï¼ˆOODï¼‰è¡Œä¸ºå¤„ç†ä¸è¶³**ï¼šé¢å¯¹æœªè§è¿‡çš„åŠ¨ä½œç»„åˆå¯èƒ½å‡ºç°â€œå¹»è§‰â€ï¼ˆå¦‚ç©¿å¢™ï¼‰ï¼Œéœ€é¢å¤–çº¦æŸæœºåˆ¶ã€‚
3. **èµ„æºåˆ†é…ä¾èµ–æ¨¡å‹è¶…å‚**ï¼šæœ€ä¼˜5:3æ¯”ä¾‹åŸºäºç‰¹å®šAttention Headæ•°é‡ï¼Œæ¢æ¨¡å‹éœ€é‡æ–°è°ƒä¼˜ã€‚
4. **ä»å­˜åœ¨P99å°¾å»¶è¿Ÿé—®é¢˜**ï¼šçªå˜åœºæ™¯ä¸‹æ¢å¤éœ€å®Œæ•´é‡ç”Ÿæˆï¼Œå¯èƒ½å¯¼è‡´è½»å¾®å¡é¡¿ï¼ˆä½†å¯é€šè¿‡Change Blindnessæ•ˆåº”æ©ç›–ï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **å¼€å‘æ··åˆç¥ç»-ç¬¦å·å¼•æ“**ï¼ˆHybrid Neuro-Symbolic Engineï¼‰  
   å¼•å…¥è½»é‡çº§å¯å¾®åˆ†ç¬¦å·é€»è¾‘å±‚ä½œä¸ºâ€œæ¸¸æˆè§„åˆ™ç›‘ç£å™¨â€ï¼Œå¼ºåˆ¶æ‰§è¡Œå…³é”®è§„åˆ™ï¼ˆå¦‚ç¢°æ’è¾¹ç•Œï¼‰ã€‚

2. **æ¢ç´¢å¤šæ¨¡æ€æ§åˆ¶æ¥å£**  
   åˆ©ç”¨Transformerçš„è·¨æ¨¡æ€èƒ½åŠ›ï¼Œæ”¯æŒè‡ªç„¶è¯­è¨€æˆ–è¯­éŸ³æŒ‡ä»¤ç›´æ¥é©±åŠ¨æ¸¸æˆä¸–ç•Œã€‚

3. **æ¨åŠ¨æœ¬åœ°åŒ–éƒ¨ç½²**  
   ç ”ç©¶æç«¯é‡åŒ–æŠ€æœ¯ï¼ˆå¦‚4-bitæƒé‡ + æ¿€æ´»æ„ŸçŸ¥å¹³æ»‘ï¼‰ï¼Œä½¿é«˜ä¿çœŸç”Ÿæˆå¼•æ“å¯åœ¨é…å¤‡NPUçš„æ¶ˆè´¹çº§è®¾å¤‡ä¸Šè¿è¡Œã€‚

4. **è·¨å¹³å°é€šç”¨åŒ–**  
   å°†å½“å‰Ascendä¸“ç”¨ä¼˜åŒ–è¿ç§»è‡³CUDA/NVLinkç”Ÿæ€ï¼ˆå¦‚H100é›†ç¾¤ï¼‰ï¼Œå¹¶é€šè¿‡OpenAI Tritonç­‰ç¼–è¯‘å™¨å®ç°è·¨å‚å•†å…¼å®¹ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬å·¥ä½œè¯æ˜ï¼Œé€šè¿‡**ç¡¬ä»¶-ç®—æ³•ååŒè®¾è®¡**ï¼Œå°¤å…¶æ˜¯**å¼‚æ„å¹¶è¡Œã€å†…å­˜èåˆä¸æ½œåœ¨ç©ºé—´å¤–æ¨**ï¼Œå¯ä»¥çªç ´ç”Ÿæˆå¼æ¸¸æˆå¼•æ“çš„â€œåˆ†è¾¨ç‡å¢™â€ï¼Œé¦–æ¬¡å®ç°åœ¨720Ã—480åˆ†è¾¨ç‡ä¸‹çš„å®æ—¶ã€é«˜ä¿çœŸã€é€»è¾‘ä¸€è‡´çš„æ¸¸æˆç”Ÿæˆï¼Œæ ‡å¿—ç€å‘â€œå…¨ç¥ç»åŒ–æ¸¸æˆå¼•æ“â€çš„é‡è¦è¿ˆè¿›ã€‚

</details>

---

### 3. [STILL: Selecting Tokens for Intra-Layer Hybrid Attention to Linearize LLMs](https://arxiv.org/abs/2602.02180)

**Authors**: Weikang Meng, Liangyu Huo, Yadan Luo, Jiawen Guan, Jingyi Zhang, Yingjian Li, Zheng Zhang  
**Category**: cs.LG  
**Published**: 2026-02-03  
**Score**: 13.5  
**Type**: new  
**ArXiv ID**: 2602.02180v1  

#### Abstract
Linearizing pretrained large language models (LLMs) primarily relies on intra-layer hybrid attention mechanisms to alleviate the quadratic complexity of standard softmax attention. Existing methods perform token routing based on sliding-window partitions, resulting in position-based selection and fa...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**STILL: Selecting Tokens for Intra-Layer Hybrid Attention to Linearize LLMs**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰å¯¹é¢„è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œçº¿æ€§åŒ–ï¼ˆlinearizationï¼‰ä»¥é™ä½ **Softmax Attention** çš„ $O(N^2)$ å¤æ‚åº¦æ—¶ï¼Œä¸»æµæ–¹æ³•é‡‡ç”¨ **intra-layer hybrid attention**ï¼ˆå±‚å†…æ··åˆæ³¨æ„åŠ›ï¼‰ï¼Œå³éƒ¨åˆ† token ä½¿ç”¨ Softmax Attention (SA)ï¼Œå…¶ä½™ä½¿ç”¨ Linear Attention (LA)ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å­˜åœ¨ä¸¤å¤§ç¼ºé™·ï¼š

1. **Token è·¯ç”±æœºåˆ¶ä¾èµ–ä½ç½®æ»‘çª—ï¼ˆposition-based sliding windowï¼‰**  
   å¦‚ LoLCATs å’Œ Liger å°†å›ºå®šçª—å£å†…çš„ token åˆ†é…ç»™ SAï¼Œå¿½ç•¥å…¶è¯­ä¹‰é‡è¦æ€§ï¼Œå¯¼è‡´å…³é”®è¿œè·ç¦» token è¢«é”™è¯¯åœ°é€å…¥ LAï¼ŒæŸå®³é•¿ç¨‹å»ºæ¨¡èƒ½åŠ›ã€‚

2. **Linear Attention å¼•å…¥ Learnable Feature Map å¯¼è‡´åˆ†å¸ƒåç§»ï¼ˆdistribution shiftï¼‰**  
   ç‰¹åˆ«æ˜¯é€šè¿‡ MLP å˜æ¢ç‰¹å¾ä¼šç ´åé¢„è®­ç»ƒæ¨¡å‹ä¸­çš„ **norm-aware** ç‰¹æ€§ï¼ˆå³å‘é‡æ¨¡é•¿å½±å“æ³¨æ„åŠ›å¼ºåº¦ï¼‰ï¼Œä»è€Œæ‰­æ›²åŸå§‹è¡¨ç¤ºå‡ ä½•ç»“æ„ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šSTILL
ä½œè€…æå‡º **STILL**ï¼ˆSelecting Tokens for Intra-Layer Hybrid Attention to Linearize LLMsï¼‰ï¼Œä¸€ç§é«˜æ•ˆä¸”å¿ å®äºé¢„è®­ç»ƒçŸ¥è¯†çš„çº¿æ€§åŒ–æ¡†æ¶ï¼ŒåŒ…å«ä¸‰å¤§æ ¸å¿ƒåˆ›æ–°ï¼š

#### ï¼ˆ1ï¼‰**Self-Saliency Score**ï¼šåŸºäºå†…å®¹çš„ Token é€‰æ‹©æœºåˆ¶
- åˆ©ç”¨å±€éƒ¨æ»‘çª—å†…è®¡ç®—çš„æ³¨æ„åŠ›åˆ†å¸ƒå·®å¼‚ï¼ˆå«å¯¹è§’é¡¹ vs ä¸å«å¯¹è§’é¡¹ï¼‰å®šä¹‰æ¯ä¸ª token çš„ **Self-Saliency Score**ã€‚
- è¯¥åˆ†æ•°èƒ½æœ‰æ•ˆåæ˜  token åœ¨å…¨å±€ä¸Šä¸‹æ–‡ä¸­çš„é‡è¦æ€§ï¼Œå®ç°â€œå±€éƒ¨è®¡ç®—ï¼Œå…¨å±€ä¸€è‡´â€çš„ token é€‰æ‹©ã€‚
- é«˜åˆ† token è¢«é€‰å…¥ SA åˆ†æ”¯ï¼Œå…¶ä½™é€å…¥ LAï¼Œçªç ´ä¼ ç»Ÿæ»‘çª—çš„ä½ç½®é™åˆ¶ã€‚

> ğŸ” å›¾ 3 æ˜¾ç¤ºå±€éƒ¨å¾—åˆ†ä¸å…¨å±€å¾—åˆ†é«˜åº¦ä¸€è‡´ï¼›å›¾ 4 æ˜¾ç¤ºè¢«é€‰ä¸­çš„ token å¤šä¸ºå¦å®šè¯ï¼ˆnot, neverï¼‰ã€æƒ…æ€åŠ¨è¯ï¼ˆmay, willï¼‰ç­‰é«˜è¯­ä¹‰ä½œç”¨è¯ã€‚

#### ï¼ˆ2ï¼‰**Norm-Preserved Feature Map (NP-Map)**ï¼šä¿ç•™é¢„è®­ç»ƒ norm ç»“æ„
- è®¾è®¡æ–°çš„å¯å­¦ä¹ ç‰¹å¾æ˜ å°„æœºåˆ¶ï¼Œåœ¨ MLP å˜æ¢åé‡æ–°æ³¨å…¥åŸå§‹è¾“å…¥çš„ normï¼ˆæ¨¡é•¿ï¼‰ã€‚
- å½¢å¼ä¸ºï¼š  
  $$
  \phi_{\text{NP}}(x) = [\text{softmax}(f(x)/\|f(x)\| \cdot \|x\|), \text{softmax}(-f(x)/\|f(x)\| \cdot \|x\|)]
  $$
- ä¿è¯ Linear Attention çš„ kernel ä»ä½œç”¨åœ¨ç¬¦åˆé¢„è®­ç»ƒåˆ†å¸ƒçš„ç‰¹å¾ä¸Šï¼Œé¿å… norm distortionã€‚

#### ï¼ˆ3ï¼‰**Chunk-wise Delayed Selection**ï¼šæå‡ç¡¬ä»¶æ•ˆç‡
- å°†åºåˆ—åˆ’åˆ†ä¸º chunkï¼Œåœ¨æ¯ä¸ª chunk å®Œæˆåå†ç»Ÿä¸€æ‰§è¡Œ token é€‰æ‹©ï¼ˆTop-Kï¼‰ï¼Œè€Œéé€ token å†³ç­–ã€‚
- æ”¯æŒè®­ç»ƒä¸æ¨ç†ç»Ÿä¸€æ¶æ„ä¸‹çš„å¹¶è¡ŒåŒ–å¤„ç†ï¼Œæ˜¾è‘—æå‡ååé‡ã€‚

---

### âš–ï¸ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ LoLCATs/Ligerï¼‰ | STILL |
|------|-------------------------------|-------|
| Token è·¯ç”± | å›ºå®šæ»‘çª— â†’ ä½ç½®åç½® | Self-Saliency Score â†’ å†…å®¹æ„ŸçŸ¥ |
| Norm ä¸€è‡´æ€§ | MLP æ‰­æ›²é¢„è®­ç»ƒ norm | NP-Map æ˜¾å¼ä¿ç•™ norm |
| æ•ˆç‡è®¾è®¡ | é€ token è·¯ç”± â†’ å¹¶è¡Œå·® | Chunk-wise å»¶è¿Ÿé€‰æ‹© â†’ é«˜å¹¶è¡Œ |
| æ€§èƒ½æ¢å¤ | é•¿æ–‡æœ¬ä»»åŠ¡ä¸¥é‡é€€åŒ– | æ¥è¿‘ç”šè‡³è¶…è¶ŠåŸæ¨¡å‹ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **Commonsense & General Reasoning**ï¼š  
  PIQA, ARC-Easy, ARC-Challenge, HellaSwag, WinoGrande, MMLUï¼ˆ5-shotï¼‰
- **Long-context Benchmarks**ï¼š  
  - **RULER**ï¼šå•é’ˆæ£€ç´¢ï¼ˆS-NIAHï¼‰ã€å¤šé”®/æŸ¥è¯¢/å€¼æ£€ç´¢ï¼ˆMK/MQ/MVï¼‰ã€é—®ç­”ï¼ˆHQA/SQAï¼‰ã€å˜é‡è¿½è¸ªï¼ˆVTï¼‰ç­‰ï¼Œæœ€é•¿è¾¾ 4K tokensã€‚
  - **BABILong**ï¼šbAbI ä»»åŠ¡æ‰©å±•è‡³é•¿ä¸Šä¸‹æ–‡ï¼Œæµ‹è¯•è·¨è¿œè·ç¦»è¯æ®æ•´åˆèƒ½åŠ›ï¼ˆQA1â€“QA5ï¼‰ï¼Œé•¿åº¦ä» 0K åˆ° 4Kã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **Teacher Models**ï¼šLlama 3 8B / Llama 3.1 8B / Mistral 7B / Llama 3.2 1B&3B
- **è®­ç»ƒç­–ç•¥**ï¼ˆä¸¤é˜¶æ®µï¼‰ï¼š
  1. **Attention Transfer**ï¼šå†»ç»“æ•™å¸ˆæ¨¡å‹ï¼Œæœ€å°åŒ– MSE æŸå¤±å¯¹é½æ³¨æ„åŠ›å›¾ã€‚
  2. **Low-rank Linearization**ï¼šä½¿ç”¨ LoRA å¾®è°ƒ Query/Key/Value æŠ•å½±åŠé—¨æ§å‚æ•°ã€‚
- **è®­ç»ƒæ•°æ®**ï¼šCleaned Alpacaï¼ˆ20M tokensï¼Œseq len=1024ï¼‰
- **è¯„ä¼°æ–¹å¼**ï¼šzero-shot æˆ–æ ‡å‡† few-shotï¼ˆå¦‚ MMLU 5-shotï¼‰ï¼Œä½¿ç”¨ `lm-evaluation-harness`ã€‚

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | æ–¹æ³• |
|------|------|
| **Full Transformer** | Llama 3/3.1 ç³»åˆ— |
| **Subquadratic from scratch** | Mamba, Mamba2, RWKV-6, Hawk, Griffin |
| **Inter-layer Hybrid** | StripedHyena, Zamba, RecurrentGemma |
| **Linearized from LLM** | LoLCATs, Liger-GLA, Hedgehog-LoLCATs, SUPRA |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| æ¨¡å‹ | MMLU (5-shot) | Avg. (w/ MMLU) | è®­ç»ƒ Tokens (B) |
|------|----------------|----------------|------------------|
| Llama 3.1 8B (åŸæ¨¡å‹) | 68.0 | 74.2 | 15000+ |
| Liger-GLA | 46.9 | 68.3 | 0.02 |
| **STILL (Ours)** | **61.3** | **72.5** | **0.04** |

> âœ… STILL ä»…ç”¨ **0.04B è®­ç»ƒ tokens**ï¼ˆç›¸æ¯”åŸæ¨¡å‹ <1/300,000ï¼‰ï¼Œå¹³å‡æ€§èƒ½æ¥è¿‘åŸæ¨¡å‹ï¼Œå¹¶å¤§å¹…ä¼˜äºå…¶ä»–çº¿æ€§åŒ–æ–¹æ³•ã€‚

---

### ğŸ” é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡è¡¨ç°ï¼ˆTable 2 & 3ï¼‰

#### **RULER - S-NIAH-1 @ 4K context**
| æ–¹æ³• | å‡†ç¡®ç‡ |
|------|--------|
| LoLCATs (512 cache) | 8.8 |
| Liger-GLA | 0.0 |
| **STILL (256~512 cache)** | **86.2** |
| Full Attention | 100 |

> ğŸ’¡ STILL åœ¨æå°ç¼“å­˜ä¸‹å®ç° **86.2% çš„ç›¸å¯¹æ€§èƒ½æ¢å¤**ï¼Œè¿œè¶…åŸºçº¿ã€‚

#### **Extended RULER @ 4K context (Avg.)**
| æ–¹æ³• | å¹³å‡å¾—åˆ† |
|------|----------|
| LoLCATs | 7.2 |
| Liger-GLA | 2.1 |
| **STILL** | **47.9** |

> è¡¨æ˜ STILL åœ¨å¤æ‚è®°å¿†ä¸çŠ¶æ€è·Ÿè¸ªä»»åŠ¡ä¸­å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

---

### ğŸ§ª BABILong @ 4K contextï¼ˆQA5ï¼‰
| æ–¹æ³• | å‡†ç¡®ç‡ |
|------|--------|
| SWA / LoLCATs | 6 |
| **STILL** | **24** |

> åœ¨éœ€è¦è¿œè·ç¦»æ¨ç†çš„ä»»åŠ¡ä¸Šï¼ŒSTILL å®ç° **4å€æå‡**ã€‚

---

### ğŸ”¬ æ¶ˆèå®éªŒï¼ˆAblation Study, Table 6ï¼‰
åœ¨ BABILongï¼ˆ1Kï¼‰ä¸Šçš„æ¨¡å—æ¶ˆèï¼š

| ç»„ä»¶ç§»é™¤ | å‡†ç¡®ç‡ | ä¸‹é™å¹…åº¦ |
|---------|--------|-----------|
| å®Œæ•´ STILL | 27.5 | â€” |
| ç§»é™¤ Gate | 21.7 | -5.8 |
| ç§»é™¤ NP-Map | 22.4 | -4.9 |
| ç§»é™¤ä¸¤è€… | 19.2 | -8.3 |
| å†ç§»é™¤ Self-Saliency | 12.5 | -15.0 |

> â— ç»“æœè¡¨æ˜ï¼š**Self-Saliency Score æ˜¯æœ€å…³é”®ç»„ä»¶**ï¼Œä¸‰è€…ååŒå¢æ•ˆã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Token é‡è¦æ€§å¯é€šè¿‡å±€éƒ¨ä¿¡æ¯å¯é ä¼°è®¡**  
   Self-Saliency Score å®ç°äº†â€œå±€éƒ¨è®¡ç®— â†’ å…¨å±€æœ‰æ•ˆâ€çš„ token é€‰æ‹©ï¼Œæ‰“ç ´äº†æ»‘çª—é™åˆ¶ã€‚

2. **Norm preservation å¯¹æ€§èƒ½æ¢å¤è‡³å…³é‡è¦**  
   é¢„è®­ç»ƒæ¨¡å‹çš„ â€œnorm-awareâ€ æ³¨æ„åŠ›æœºåˆ¶å¿…é¡»è¢«ä¿ç•™ï¼Œå¦åˆ™å³ä½¿å½¢å¼ä¸Šæ¨¡ä»¿ softmaxï¼Œå®é™…è¡Œä¸ºå·²åç§»ã€‚

3. **é«˜æ•ˆçº¿æ€§åŒ–æ— éœ€å¤§è§„æ¨¡å†è®­ç»ƒ**  
   STILL ä»…éœ€ **0.04B tokens** å¾®è°ƒå³å¯å®Œæˆé«˜è´¨é‡çº¿æ€§åŒ–ï¼Œè®­ç»ƒæˆæœ¬æä½ã€‚

4. **é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›å¯è¢«æœ‰æ•ˆæ¢å¤**  
   åœ¨ RULER å’Œ BABILong ä¸Šï¼ŒSTILL æ˜¾è‘—ä¼˜äºç°æœ‰çº¿æ€§åŒ–æ–¹æ³•ï¼Œè¯æ˜å…¶çœŸæ­£è§£å†³äº†é•¿ç¨‹ä¾èµ–å»ºæ¨¡éš¾é¢˜ã€‚

---

### âš ï¸ å±€é™æ€§
- å½“å‰æ–¹æ³•ä»ä¾èµ–ä¸€å®šæ•°é‡çš„ Softmax Attentionï¼ˆçº¦æ•°ç™¾ tokenï¼‰ï¼Œå°šæœªå®Œå…¨æ¶ˆé™¤äºŒæ¬¡é¡¹ã€‚
- Self-Saliency Score çš„ç†è®ºè§£é‡Šå°šä¸å……åˆ†ï¼Œä¸ºä½•å±€éƒ¨æ•æ„Ÿæ€§èƒ½é¢„æµ‹å…¨å±€é‡è¦æ€§æœ‰å¾…è¿›ä¸€æ­¥åˆ†æã€‚
- Chunk-wise è®¾è®¡å¯èƒ½å¼•å…¥è½»å¾®å»¶è¿Ÿï¼Œåœ¨æç«¯ä½å»¶è¿Ÿåœºæ™¯ä¸­éœ€æƒè¡¡ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´è½»é‡åŒ–çš„ saliency ä¼°è®¡å™¨ï¼Œå‡å°‘é¢å¤–è®¡ç®—å¼€é”€ã€‚
- å°† STILL æ‰©å±•åˆ° encoder-decoder æ¶æ„æˆ–å¤šæ¨¡æ€æ¨¡å‹ã€‚
- ç»“åˆåŠ¨æ€ç¨€ç–åŒ–æˆ– early exiting è¿›ä¸€æ­¥å‹ç¼©è®¡ç®—ã€‚
- æ¢ç´¢ saliency ä¸è¯­è¨€å­¦ç»“æ„ï¼ˆå¦‚å¥æ³•ã€é€»è¾‘ä½œç”¨è¯ï¼‰ä¹‹é—´çš„å…³è”ã€‚

---

## âœ… æ€»ç»“
**STILL** æ˜¯é¦–ä¸ªå°† **content-aware token selection** ä¸ **norm-preserving linear attention** ç»“åˆçš„ LLM çº¿æ€§åŒ–æ¡†æ¶ã€‚å®ƒä¸ä»…åœ¨ commonsense å’Œ reasoning ä»»åŠ¡ä¸Šé€¼è¿‘åŸæ¨¡å‹æ€§èƒ½ï¼Œæ›´åœ¨é•¿ä¸Šä¸‹æ–‡ç†è§£ä»»åŠ¡ä¸Šå®ç°äº†çªç ´æ€§è¿›å±•ï¼Œæœ€é«˜æ¢å¤ **86.2% çš„ full-attention æ€§èƒ½**ï¼ŒåŒæ—¶å¸¦æ¥ **45% å†…å­˜ä¸‹é™** å’Œ **28% è§£ç åŠ é€Ÿ**ã€‚è¯¥å·¥ä½œä¸ºé«˜æ•ˆéƒ¨ç½²è¶…é•¿ä¸Šä¸‹æ–‡ LLM æä¾›äº†ä¸€æ¡å®ç”¨ä¸”é«˜æ€§èƒ½çš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 4. [Focus-dLLM: Accelerating Long-Context Diffusion LLM Inference via Confidence-Guided Context Focusing](https://arxiv.org/abs/2602.02159)

**Authors**: Lingkun Long, Yushi Huang, Shihao Bai, Ruihao Gong, Jun Zhang, Ao Zhou, Jianlei Yang  
**Category**: cs.CL  
**Published**: 2026-02-03  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2602.02159v1  

#### Abstract
Diffusion Large Language Models (dLLMs) deliver strong long-context processing capability in a non-autoregressive decoding paradigm. However, the considerable computational cost of bidirectional full attention limits the inference efficiency. Although sparse attention is promising, existing methods ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡ã€ŠFocus-dLLM: Accelerating Long-Context Diffusion LLM Inference via Confidence-Guided Context Focusingã€‹æ€»ç»“**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
Diffusion Large Language Models (dLLMs) è™½ç„¶åœ¨éè‡ªå›å½’è§£ç èŒƒå¼ä¸‹å±•ç°å‡ºå¼ºå¤§çš„é•¿ä¸Šä¸‹æ–‡å¤„ç†èƒ½åŠ›ï¼Œä½†ç”±äºå…¶**åŒå‘å…¨æ³¨æ„åŠ›æœºåˆ¶**ï¼Œæ¨ç†è¿‡ç¨‹è®¡ç®—å¼€é”€å·¨å¤§ï¼Œå°¤å…¶åœ¨é•¿ä¸Šä¸‹æ–‡ï¼ˆå¦‚ 32K tokensï¼‰åœºæ™¯ä¸‹æ•ˆç‡æä½ã€‚ç°æœ‰çš„åŠ é€Ÿæ–¹æ³•å­˜åœ¨ä»¥ä¸‹ä¸è¶³ï¼š
- **Approximated KV cache**ï¼šè™½èƒ½å¤ç”¨ç¼“å­˜çŠ¶æ€ï¼Œä½†ä»éœ€å¯¹å®Œæ•´ä¸Šä¸‹æ–‡è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—ã€‚
- **Sparse attention**ï¼šä¾èµ–å½“å‰å·²è§£ç  token æ¥ä¼°è®¡é‡è¦æ€§ï¼Œä½†åœ¨ dLLM ä¸­ï¼Œå¾…è§£ç ä½ç½®ï¼ˆunmaskedï¼‰æ˜¯åŠ¨æ€ä¸”æœªçŸ¥çš„ï¼Œå¯¼è‡´é¢„æµ‹ä¸å‡†ç¡®ã€‚

å› æ­¤ï¼Œå¦‚ä½•**å‡†ç¡®é¢„æµ‹å³å°†è¢«è§£ç çš„ä½ç½®å¹¶é«˜æ•ˆå‰ªæå†—ä½™æ³¨æ„åŠ›è®¡ç®—**ï¼Œæˆä¸ºæå‡ dLLM æ¨ç†æ•ˆç‡çš„å…³é”®æŒ‘æˆ˜ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æœ¬æ–‡æå‡º **Focus-dLLM**ï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„ã€åŸºäºç½®ä¿¡åº¦å¼•å¯¼çš„ä¸Šä¸‹æ–‡èšç„¦æ¡†æ¶ï¼Œç”¨äºåŠ é€Ÿé•¿ä¸Šä¸‹æ–‡ dLLM æ¨ç†ã€‚å…¶æ ¸å¿ƒæ€æƒ³åŒ…æ‹¬ï¼š

#### **(1) è¿‡å»ç½®ä¿¡åº¦å¼•å¯¼æŒ‡ç¤ºå™¨ (Past Confidence-Guided Indicator)**
- å‘ç°ï¼šç›¸é‚»å»å™ªæ­¥ä¸­ token çš„ç½®ä¿¡åº¦ï¼ˆconfidence scoreï¼‰å…·æœ‰å¼ºæ­£ç›¸å…³æ€§ï¼Œå‰ä¸€æ­¥é«˜ç½®ä¿¡åº¦çš„ token å¾ˆå¯èƒ½åœ¨ä¸‹ä¸€æ­¥è¢«è§£ç ã€‚
- æ–¹æ³•ï¼šåˆ©ç”¨ç¬¬ $t-1$ æ­¥çš„ç½®ä¿¡åº¦é¢„æµ‹ç¬¬ $t$ æ­¥å°†è¢«è§£ç çš„ä½ç½®ï¼Œå¹¶é€šè¿‡çª—å£æ‰©å±•ä¿ç•™å±€éƒ¨è¯­ä¹‰è¿è´¯æ€§ï¼Œå½¢æˆæ´»è·ƒæŸ¥è¯¢é›†ï¼ˆ`Q_active`ï¼‰ã€‚

#### **(2) Sink-Aware åŠ¨æ€å‰ªæç­–ç•¥**
- å‘ç°ï¼šdLLM ä¸­å­˜åœ¨â€œ**attention sinks**â€â€”â€”å¯¹ç”Ÿæˆè´¨é‡è‡³å…³é‡è¦çš„å…³é”® tokenï¼Œä¸”è¿™äº› sink åœ¨ä¸åŒå±‚ä¹‹é—´è¡¨ç°å‡ºæ˜¾è‘—çš„è·¨å±‚ä¸€è‡´æ€§ï¼ˆcross-layer consistencyï¼‰ã€‚
- æ–¹æ³•ï¼š
  - åœ¨æµ…å±‚ï¼ˆdense layersï¼‰è¯†åˆ« attention sinks å¹¶åœ¨æ•´ä¸ªæ·±å±‚ä¸­å¤ç”¨å…¶ä½ç½®ï¼Œé¿å…é‡å¤æ£€æµ‹ã€‚
  - å¯¹ prompt åˆ†å—ï¼ŒåŸºäº relevance score åŠ¨æ€é€‰æ‹©æœ€ç›¸å…³çš„ block å‚ä¸æ³¨æ„åŠ›è®¡ç®—ã€‚
  - æœ€ç»ˆä»…å¯¹ `active queries` å’Œ `selected key-value pairs` æ‰§è¡Œç¨€ç–æ³¨æ„åŠ›ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç‰¹æ€§ | Focus-dLLM | Fast-dLLM | Sparse-dLLM | SparseD |
|------|------------|-----------|--------------|----------|
| æ˜¯å¦éœ€è¦è®­ç»ƒ | âŒ å¦ | âŒ å¦ | âŒ å¦ | âŒ å¦ |
| æ˜¯å¦é¢„æµ‹ unmasked ä½ç½® | âœ… é«˜ç²¾åº¦é¢„æµ‹ | âŒ æ—  | âš ï¸ ç²—ç²’åº¦ä¼°è®¡ | âŒ ä¸é€‚ç”¨ |
| æ˜¯å¦ä¿ç•™ attention sinks | âœ… æ˜¾å¼è¯†åˆ«å¹¶ä¿ç•™ | âŒ å¿½ç•¥ | âŒ å¿½ç•¥ | âŒ å¿½ç•¥ |
| æ˜¯å¦è·¨å±‚å…±äº« sink | âœ… æ˜¯ | âŒ å¦ | âŒ å¦ | âŒ å¦ |
| åŠ é€Ÿæ¯”ï¼ˆ32Kï¼‰ | **29.6Ã—** | ~14Ã— | ~12Ã— | ~1.5Ã— |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼š  
> - æ›´ç²¾å‡†åœ°å®šä½å…³é”® tokenï¼Œå‡å°‘è¯¯å‰ªé£é™©ï¼›
> - åˆ©ç”¨è·¨å±‚ sink ä¸€è‡´æ€§é™ä½é‡å¤è®¡ç®—ï¼›
> - å®ç°**æ— æŸç”šè‡³æ›´ä¼˜æ€§èƒ½ä¸‹çš„è¶…é«˜åŠ é€Ÿæ¯”**ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ¨¡å‹**
- **UltraLLaDA** (He et al., 2025)ï¼šæ”¯æŒè¶…é•¿ä¸Šä¸‹æ–‡ï¼ˆè¾¾ 128Kï¼‰çš„ dLLMã€‚
- **Dream-7B-Instruct** (Ye et al., 2025)ï¼šåŸºäºæ‰©æ•£æœºåˆ¶çš„æŒ‡ä»¤å¾®è°ƒæ¨¡å‹ã€‚

### **æ•°æ®é›†**
- **LongBench** (Bai et al., 2024)ï¼šå¤šä»»åŠ¡ã€åŒè¯­ã€é•¿ä¸Šä¸‹æ–‡ç†è§£åŸºå‡†ï¼Œæ¶µç›–ï¼š
  - å•æ–‡æ¡£é—®ç­”ï¼ˆQasperï¼‰
  - å¤šæ–‡æ¡£é—®ç­”ï¼ˆHotpotQA, 2WikiMQAï¼‰
  - æ‘˜è¦ç”Ÿæˆï¼ˆGovReport, MultiNewsï¼‰
  - å°‘æ ·æœ¬å­¦ä¹ ï¼ˆTRECï¼‰
  - åˆæˆä»»åŠ¡ï¼ˆPassageRetrievalï¼‰
  - ä»£ç è¡¥å…¨ï¼ˆRepoBench-Pï¼‰

### **è¯„ä¼°æŒ‡æ ‡**
| ç±»å‹ | æŒ‡æ ‡ |
|------|------|
| å‡†ç¡®ç‡ | F1, Rouge-L, Accuracy, Edit Sim |
| æ•ˆç‡ | Throughput (tokens/s)ï¼ŒSpeedup Ã— |
| ç»¼åˆè¡¨ç° | Average Score on LongBench |

### **å®éªŒè®¾ç½®**
- ä¸Šä¸‹æ–‡é•¿åº¦ï¼š8K â†’ 32Kï¼ˆä»¥ 1K = 1024 tokensï¼‰
- ç”Ÿæˆé•¿åº¦ä¸æ­¥æ•°å›ºå®šä¸º 256
- æ‰€æœ‰æ–¹æ³•ç»Ÿä¸€é‡‡ç”¨ semi-autoregressive remasking ç­–ç•¥ï¼ˆblock size = 32ï¼‰
- ä½¿ç”¨ NVIDIA H200 GPUï¼ŒåŸºäº OpenCompass å¹³å°è¯„æµ‹

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| æ–¹æ³• | ç±»å‹ | æ ¸å¿ƒæœºåˆ¶ |
|------|------|---------|
| **Vanilla** | åŸå§‹æ¨ç† | å…¨æ³¨æ„åŠ›ï¼Œæ— ä¼˜åŒ– |
| **Fast-dLLM** | KV Cache | å—çº§è¿‘ä¼¼ KV ç¼“å­˜å¤ç”¨ |
| **Sparse-dLLM** | Sparse Attention | åŠ¨æ€ç¼“å­˜é©±é€ï¼Œç²—ç²’åº¦é‡è¦æ€§ä¼°è®¡ |
| **SparseD** | Sparse Attention | é¢„å®šä¹‰ç¨€ç–æ¨¡å¼é‡ç”¨ï¼Œæ—©æœŸå…¨æ³¨æ„ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **(1) å‡†ç¡®ç‡è¡¨ç°ï¼ˆLongBench å¹³å‡å¾—åˆ†ï¼‰**

| æ–¹æ³• | UltraLLaDA | Dream-7B-Instruct |
|------|------------|------------------|
| Vanilla | 44.90 | 43.03 |
| Fast-dLLM | 44.74 | 42.75 |
| Sparse-dLLM | 44.86 | 42.78 |
| SparseD | 44.70 | **43.59** |
| **Focus-dLLM** | **45.14** âœ… | 42.82 |

> ğŸ” **å‘ç°**ï¼š
> - åœ¨ UltraLLaDA ä¸Šï¼ŒFocus-dLLM **è¶…è¶Šæ‰€æœ‰åŸºçº¿**ï¼Œç”šè‡³ä¼˜äº Vanillaï¼›
> - åœ¨ Dream-7B ä¸Šç•¥ä½äº SparseDï¼Œä½†æ¢æ¥äº†æ›´é«˜çš„æ¨ç†é€Ÿåº¦ã€‚

#### **(2) æ¨ç†æ•ˆç‡ï¼ˆååé‡ Speedupï¼‰**

| æ–¹æ³• | Context Length | Speedup vs Vanilla |
|------|----------------|--------------------|
| Focus-dLLM | 8K | 9.4Ã— |
| Focus-dLLM | 16K | ~18Ã— |
| Focus-dLLM | **32K** | **29.6Ã—** âœ… |
| Fast-dLLM | 32K | ~14.3Ã— |
| Sparse-dLLM | 32K | ~12.2Ã— |
| SparseD | 32K | ~1.5Ã— |

> ğŸ“ˆ **è¶‹åŠ¿**ï¼šéšç€ä¸Šä¸‹æ–‡å¢é•¿ï¼Œå†—ä½™è®¡ç®—åŠ å‰§ï¼ŒFocus-dLLM çš„å‰ªæä¼˜åŠ¿æ„ˆå‘æ˜æ˜¾ã€‚

#### **(3) Niah ä»»åŠ¡ï¼ˆneedle-in-a-haystackï¼‰æ£€ç´¢èƒ½åŠ›**
- åœ¨ UltraLLaDA ä¸Šæµ‹è¯• 32K ä¸Šä¸‹æ–‡ä¸­æŸ¥æ‰¾ç‰¹å®šä¿¡æ¯ã€‚
- **Focus-dLLM è¡¨ç°æœ€ä¼˜**ï¼Œå°¤å…¶åœ¨æ·±å±‚ç½‘ç»œä¸­è¶…è¿‡ Vanillaï¼Œè¯æ˜å…¶æœ‰æ•ˆä¿ç•™äº†å…³é”®ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### **è¡¨ 2ï¼šç»„ä»¶æ¶ˆèï¼ˆUltraLLaDA, 16Kï¼‰**

| æ–¹æ³• | Avg. Score | Throughput (tokens/s) |
|------|-----------|------------------------|
| Fast-dLLM | 44.74 | 11.03 |
| + PCGIï¼ˆç½®ä¿¡åº¦å¼•å¯¼ï¼‰ | 44.23 (-0.51) | 11.37 (+0.34) |
| + SA Sparse Attnï¼ˆsink-aware å‰ªæï¼‰ | 44.84 (+0.10) | **17.68 (+6.65)** |
| **Focus-dLLMï¼ˆå®Œæ•´ï¼‰** | **45.14 (+0.40)** | **17.71 (+6.68)** |

> âœ… **ç»“è®º**ï¼š
> - Sink-aware å‰ªææ˜¯æ€§èƒ½æå‡ä¸»å› ï¼›
> - ç»“åˆ PCGI åå¯å®ç°æ›´ç²¾ç¡®çš„æŸ¥è¯¢é€‰æ‹©ï¼Œè¿›ä¸€æ­¥æå‡å‡†ç¡®ç‡ä¸æ•ˆç‡ã€‚

#### **è¡¨ 3ï¼šattention sinks çš„å½±å“ï¼ˆDream-7Bï¼‰**
| è®¾ç½® | Avg. Score |
|------|-----------|
| w/o attention sinks | 41.47 |
| **w/ attention sinks** | **42.82 (+1.35)** âœ… |

> ğŸ’¡ æ˜¾å¼ä¿ç•™ attention sinks æ˜¾è‘—æå‡å¤šä»»åŠ¡è¡¨ç°ã€‚

#### **å›¾ 7ï¼šè¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æ**
- **sparsity ratio Î± â†‘**ï¼šä¿ç•™æ›´å¤š context â†’ æ€§èƒ½å…ˆå‡åé™ï¼ˆè¿‡å¤šæ— å…³ token å¼•å…¥å™ªå£°ï¼‰
- **prediction expansion factor p â†‘**ï¼šå¬å›ç‡æé«˜ â†’ æ€§èƒ½ç¨³æ­¥ä¸Šå‡
- **window size w**ï¼šé€‚ä¸­æœ€ä½³ï¼ˆå¤ªå°ä¸¢å¤±ä¸Šä¸‹æ–‡ï¼Œå¤ªå¤§å¼•å…¥å™ªå£°ï¼‰
- **dense layer æ•°é‡**ï¼šéå•è°ƒå˜åŒ–ï¼Œè¡¨æ˜ sink ç¨³å®šæ€§éšæ·±åº¦æ¼”åŒ–

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **Token confidence å…·æœ‰æ—¶é—´è¿ç»­æ€§**ï¼šå‰ä¸€æ­¥é«˜ç½®ä¿¡åº¦ token ææœ‰å¯èƒ½åœ¨ä¸‹ä¸€æ­¥è¢«è§£ç ï¼Œå¯ç”¨äºç²¾å‡†é¢„æµ‹ unmasked ä½ç½®ã€‚
2. **Attention sinks å­˜åœ¨è·¨å±‚ä¸€è‡´æ€§**ï¼šå¯åœ¨ä¸­é—´å±‚è¯†åˆ«å¹¶åœ¨æ·±å±‚å¤ç”¨ï¼Œå¤§å¹…å‡å°‘é‡å¤è®¡ç®—ã€‚
3. **ç»“åˆç½®ä¿¡åº¦å¼•å¯¼ä¸ sink-aware å‰ªæ**ï¼Œå¯åœ¨å‡ ä¹æ— æŸç”šè‡³å¢ç›Šçš„æƒ…å†µä¸‹å®ç°é«˜è¾¾ **29.6Ã— çš„æ¨ç†åŠ é€Ÿ**ï¼ˆ32K contextï¼‰ã€‚
4. Focus-dLLM åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¾¾åˆ° **SOTA çº§åˆ«çš„ accuracy-efficiency trade-off**ï¼Œæ„å»ºäº†æ›´å¼ºçš„ Pareto frontierã€‚

---

### **å±€é™æ€§**
1. **ç›®å‰ä»…é€‚ç”¨äºæ–‡æœ¬ä»»åŠ¡**ï¼šå°šæœªæ‹“å±•åˆ° multimodal reasoning åœºæ™¯ã€‚
2. **è¶…å‚æ•°æ‰‹åŠ¨é…ç½®**ï¼šæœªå®ç°å®Œå…¨è‡ªé€‚åº”è°ƒèŠ‚ï¼Œå¯èƒ½åœ¨ä¸åŒ domain ä¸‹éæœ€ä¼˜ã€‚
3. **ä¾èµ– semi-autoregressive remasking ç­–ç•¥**ï¼šå¯¹å…¶ä»–è°ƒåº¦ç­–ç•¥çš„æ³›åŒ–æ€§æœ‰å¾…éªŒè¯ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **æ‰©å±•è‡³å¤šæ¨¡æ€ dLLM**ï¼šæ¢ç´¢è§†è§‰-è¯­è¨€è”åˆæ¨ç†ä¸­çš„ context focusingã€‚
2. **å¼€å‘è‡ªé€‚åº”å‚æ•°è°ƒæ•´æœºåˆ¶**ï¼šæ ¹æ®è¾“å…¥åŠ¨æ€ä¼˜åŒ– `p`, `Î±`, `ldense` ç­‰è¶…å‚æ•°ã€‚
3. **ç»“åˆç¡¬ä»¶ä¼˜åŒ–**ï¼šè®¾è®¡ä¸“ç”¨ kernel æ”¯æŒæ›´é«˜æ•ˆçš„ç¨€ç–æ³¨æ„åŠ›æ‰§è¡Œï¼ˆå¦‚ Triton + FlashAttention ååŒï¼‰ã€‚
4. **ç†è®ºåˆ†æ confidence dynamics ä¸ sink formation æœºåˆ¶**ï¼šä¸ºæ›´é€šç”¨çš„æ¨ç†åŠ é€Ÿæä¾›æŒ‡å¯¼ã€‚

---

> ğŸ”— **å¼€æºåœ°å€**ï¼šhttps://github.com/Longxmas/Focus-dLLM  
> ğŸ“„ **è®ºæ–‡é“¾æ¥**ï¼šhttps://arxiv.org/abs/2602.02159

</details>

---

### 5. [Grappa: Gradient-Only Communication for Scalable Graph Neural Network Training](https://arxiv.org/abs/2602.01872)

**Authors**: Chongyang Xu, Christoph Siebenbrunner, Laurent Bindschaedler  
**Category**: cs.DC  
**Published**: 2026-02-03  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2602.01872v1  

#### Abstract
Cross-partition edges dominate the cost of distributed GNN training: fetching remote features and activations per iteration overwhelms the network as graphs deepen and partition counts grow. Grappa is a distributed GNN training framework that enforces gradient-only communication: during each iterati...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šGrappa: Gradient-Only Communication for Scalable Graph Neural Network Training

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åˆ†å¸ƒå¼å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰è®­ç»ƒé¢ä¸´ä¸¥é‡çš„**é€šä¿¡ç“¶é¢ˆ**ã€‚å½“å›¾è¢«åˆ†åŒºåï¼Œè·¨åˆ†åŒºè¾¹ï¼ˆcross-partition edgesï¼‰åœ¨å‰å‘ä¼ æ’­ä¸­éœ€è¦é¢‘ç¹è·å–è¿œç¨‹èŠ‚ç‚¹çš„ç‰¹å¾å’Œæ¿€æ´»å€¼ï¼Œå¯¼è‡´ç½‘ç»œæµé‡æ¿€å¢ï¼Œå°¤å…¶åœ¨æ¨¡å‹åŠ æ·±æˆ–åˆ†åŒºæ•°å¢åŠ æ—¶ï¼Œè¯¥é—®é¢˜æˆä¸ºè®­ç»ƒæ•ˆç‡çš„ä¸»å¯¼æˆæœ¬ã€‚

ç°æœ‰è§£å†³æ–¹æ¡ˆå¦‚é«˜æ€§èƒ½äº’è¿ï¼ˆNVLink/RDMAï¼‰ã€ç¼“å­˜æœºåˆ¶æˆ–é«˜è´¨é‡å›¾åˆ’åˆ†ï¼ˆå¦‚METISï¼‰å­˜åœ¨éƒ¨ç½²æˆæœ¬é«˜ã€å†…å­˜å‹åŠ›å¤§æˆ–é¢„å¤„ç†å¼€é”€é«˜ç­‰é—®é¢˜ï¼Œæ— æ³•ä»æ ¹æœ¬ä¸Šè§£å†³é€šä¿¡ç“¶é¢ˆã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
Grappa æå‡ºäº†ä¸€ç§å…¨æ–°çš„åˆ†å¸ƒå¼ GNN è®­ç»ƒæ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ˜¯ **Gradient-Only Communicationï¼ˆæ¢¯åº¦ä»…é€šä¿¡ï¼‰** èŒƒå¼ï¼Œå…·ä½“åŒ…å«ä»¥ä¸‹ä¸‰ä¸ªå…³é”®æŠ€æœ¯ï¼š

1. **éš”ç¦»è®­ç»ƒï¼ˆIsolated Trainingï¼‰**  
   æ¯ä¸ªè®­ç»ƒè¿­ä»£ä¸­ï¼Œå„åˆ†åŒºç‹¬ç«‹è®­ç»ƒï¼Œ**å®Œå…¨ä¸äº¤æ¢ä»»ä½•ç‰¹å¾æˆ–æ¿€æ´»å€¼**ï¼Œä»…åœ¨å…¨å±€æ›´æ–°é˜¶æ®µåŒæ­¥æ¢¯åº¦ã€‚è¿™å½»åº•æ¶ˆé™¤äº†è·¨åˆ†åŒºé‚»å±…é€šä¿¡å¼€é”€ã€‚

2. **åŠ¨æ€é‡åˆ†åŒºï¼ˆDynamic Repartitioningï¼‰**  
   åœ¨å¤šä¸ª epoch ç»„æˆçš„â€œè¶…çº§ epochâ€ï¼ˆsuper-epochï¼‰ä¹‹é—´ï¼Œå¯¹å›¾è¿›è¡Œé‡æ–°åˆ†åŒºã€‚é€šè¿‡å‘¨æœŸæ€§åœ°æ”¹å˜åˆ†åŒºå¸ƒå±€ï¼Œç¡®ä¿æ¯ä¸ªèŠ‚ç‚¹æœ€ç»ˆèƒ½æ¥è§¦åˆ°å…¶æ‰€æœ‰é‚»å±…ï¼Œä»è€Œæ¢å¤å…¨å±€ä¿¡æ¯è¦†ç›–ã€‚

3. **è¦†ç›–ç‡æ ¡æ­£çš„æ¢¯åº¦èšåˆï¼ˆCoverage-Corrected Gradient Aggregationï¼‰**  
   ç”±äºéš”ç¦»è®­ç»ƒå¼•å…¥äº†é‡‡æ ·åå·®ï¼ŒGrappa æå‡ºä¸€ç§åŸºäºé‡è¦æ€§é‡‡æ ·çš„è½»é‡çº§æ¢¯åº¦åŠ æƒæœºåˆ¶ï¼š
   - **ç†è®ºä¿è¯**ï¼šæå‡ºäº†ä¸€ä¸ªæ¸è¿‘æ— åçš„èŠ‚ç‚¹çº§ä¼°è®¡å™¨ï¼Œå¹¶è¯æ˜å…¶æ­£ç¡®æ€§ã€‚
   - **å®ç”¨å®ç°**ï¼šè®¾è®¡äº†ä¸€ä¸ªæ‰¹çº§åˆ«ï¼ˆbatch-levelï¼‰çš„æ ¡æ­£å› å­ï¼Œæœ€å°åŒ–ä¸ç†æƒ³ä¼°è®¡çš„å‡æ–¹è¯¯å·®ï¼Œå…¼å®¹ PyTorch ç­‰ä¸»æµæ¡†æ¶ã€‚
   - **ç¨³å®šæ€§å¢å¼º**ï¼šå¼•å…¥åŸºäºâ€œé‡é‡‡æ ·æœŸæœ›â€çš„æ”¶ç¼©ï¼ˆshrinkageï¼‰ç‰ˆæœ¬ $c_{\text{resampling}}$ï¼Œè¿›ä¸€æ­¥æå‡è®­ç»ƒç¨³å®šæ€§ã€‚

æ­¤å¤–ï¼ŒGrappa æ”¯æŒ **phase-parallel æ‰§è¡Œæ¨¡å¼**ï¼Œå…è®¸åœ¨å•å°æœºå™¨ä¸Šé¡ºåºè®­ç»ƒä¸åŒåˆ†åŒºï¼Œä»¥æ—¶é—´æ¢å®¹é‡ï¼Œæ”¯æŒè¶…å¤§è§„æ¨¡å›¾çš„è®­ç»ƒã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æè‡´é€šä¿¡ä¼˜åŒ–**ï¼šæ¶ˆé™¤ç‰¹å¾/æ¿€æ´»é€šä¿¡ï¼Œä»…ä¿ç•™æ¢¯åº¦åŒæ­¥ï¼Œé€šä¿¡é‡å¤§å¹…é™ä½ã€‚
- **æ¨¡å‹æ— å…³æ€§ï¼ˆmodel-agnosticï¼‰**ï¼šé€‚ç”¨äºå„ç§ GNN æ¶æ„ï¼ˆGCN, GAT, GraphSAGE ç­‰ï¼‰ï¼Œè€Œå¦‚ Cluster-GCN ä»…é™ GCNã€‚
- **æ— éœ€ç‰¹æ®Šç¡¬ä»¶**ï¼šä¸ä¾èµ– NVLink æˆ– RDMA ç­‰é«˜å¸¦å®½äº’è¿ã€‚
- **å†…å­˜å‹å¥½**ï¼šä¸ä¾èµ–å¤æ‚çš„ç¼“å­˜æœºåˆ¶ï¼Œå‡å°‘ HBM/DRAM å‹åŠ›ã€‚
- **å¯æ‰©å±•æ€§å¼º**ï¼šæ”¯æŒ phase-parallel æ¨¡å¼ï¼Œåœ¨å•æœºä¸Šè®­ç»ƒä¸‡äº¿è¾¹è§„æ¨¡çš„å›¾ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
å®éªŒä½¿ç”¨äº†çœŸå®ä¸–ç•Œå’Œåˆæˆä¸¤ç±»æ•°æ®é›†ï¼š

| æ•°æ®é›† | ç±»å‹ | èŠ‚ç‚¹æ•° | è¾¹æ•° | ç‰¹å¾ç»´åº¦ |
|--------|------|--------|------|----------|
| OGBN-ArXiv | å¼•ç”¨ç½‘ç»œ | 0.16M | 1.11M | 128 |
| Reddit | ç¤¾äº¤ç½‘ç»œ | 0.22M | 109.30M | 602 |
| OGBN-Products | å•†å“å›¾ | 2.34M | 58.99M | 100 |
| OGBN-Papers100M | å­¦æœ¯ç½‘ç»œ | 105.92M | 1.51B | 128 |
| RMAT-X | åˆæˆå›¾ï¼ˆå¹‚å¾‹åˆ†å¸ƒï¼‰ | $2^X$ | $2^{X+4}$ | 128 |

å…¶ä¸­ RMAT-36 åŒ…å«çº¦ **1.1 ä¸‡äº¿æ¡è¾¹**ï¼Œç”¨äºéªŒè¯æç«¯è§„æ¨¡ä¸‹çš„å¯è¡Œæ€§ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼š
  - åˆ†å¸ƒå¼é›†ç¾¤ï¼š8 å°æœºå™¨ï¼Œæ¯å° 2Ã—V100 GPUï¼Œé€šè¿‡ 10Gb/s ç½‘ç»œè¿æ¥ã€‚
  - å•èŠ‚ç‚¹é«˜æ€§èƒ½ï¼š1 å°æœºå™¨ï¼Œ8Ã—H100 GPUï¼Œå…¨ NVLink äº’è”ã€‚
- **æ¨¡å‹**ï¼šGraphSAGE (Sage-k), GCN-k, GAT-kï¼ˆk=2,3,4 å±‚ï¼‰ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **ç³»ç»Ÿçº§**ï¼šå¹³å‡ epoch æ—¶é—´ï¼ˆruntimeï¼‰ã€ååé‡ã€å¯æ‰©å±•æ€§ã€‚
  - **æ¨¡å‹çº§**ï¼šæµ‹è¯•å‡†ç¡®ç‡ï¼ˆtest accuracyï¼‰ã€‚
  - **å®¹é‡**ï¼šèƒ½å¦è®­ç»ƒè¶…å‡ºå•æœºå†…å­˜çš„å¤§å›¾ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **DGL**ï¼šä¸»æµåˆ†å¸ƒå¼ GNN æ¡†æ¶ï¼Œæ”¯æŒéšæœºå’Œ METIS åˆ’åˆ†ã€‚
- **MGG**ï¼šå•èŠ‚ç‚¹å…¨å›¾è®­ç»ƒç³»ç»Ÿï¼Œåˆ©ç”¨ NVLink ä¼˜åŒ–ï¼Œä»£è¡¨å•æœºæ€§èƒ½ä¸Šé™ã€‚
- **Cluster-GCN**ï¼šåŸºäºèšç±»é¢„è®¡ç®—æ‰¹æ¬¡çš„ä½é€šä¿¡é‡‡æ ·æ–¹æ³•ï¼Œä½†ä»…æ”¯æŒ GCNã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- **è®­ç»ƒé€Ÿåº¦**ï¼šGrappa å¹³å‡æ¯” DGL å¿« **4Ã—**ï¼Œæœ€é«˜å¯è¾¾ **13Ã—** åŠ é€Ÿã€‚
- **å¯æ‰©å±•æ€§**ï¼šåœ¨ 64 ä¸ªåˆ†åŒºä¸‹ä»ä¿æŒè¿‘ä¹çº¿æ€§æ‰©å±•ã€‚
- **è¶…å¤§è§„æ¨¡è®­ç»ƒ**ï¼šåœ¨å•å° V100 æœºå™¨ä¸Šï¼Œä»¥ phase-parallel æ¨¡å¼å®Œæˆ **RMAT-36ï¼ˆ1.1 ä¸‡äº¿è¾¹ï¼‰** ä¸Š Sage-3 æ¨¡å‹çš„ä¸€ä¸ª epoch ä»…éœ€ **3.6 å°æ—¶**ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
#### ä¸ DGL å¯¹æ¯”ï¼ˆTable 3ï¼‰
- **é€Ÿåº¦ä¼˜åŠ¿**ï¼šåœ¨æ‰€æœ‰æ¨¡å‹å’Œæ•°æ®é›†ä¸Šï¼ŒGrappa çš„ epoch æ—¶é—´æ˜¾è‘—ä½äº DGLï¼ˆRandom å’Œ METISï¼‰ã€‚
  - ä¾‹å¦‚ï¼Œåœ¨ OGBN-Pa ä¸Šè®­ç»ƒ GCN-2ï¼ŒGrappa ä¸º 3.8sï¼Œè€Œ DGL-Metis éœ€ 9.1sã€‚
- **å‡†ç¡®æ€§ä¼˜åŠ¿**ï¼šå°¤å…¶åœ¨æ·±å±‚æ¨¡å‹ä¸Šè¡¨ç°æ›´ä¼˜ã€‚
  - **å¹³å‡æµ‹è¯•å‡†ç¡®ç‡**ï¼šGrappa ä¸º **67.68%**ï¼ŒDGL ä¸º **61.22%**ã€‚
  - **æ·±å±‚æ¨¡å‹è¡¨ç°**ï¼š
    | æ¨¡å‹æ·±åº¦ | Grappa å‡†ç¡®ç‡ | DGL å‡†ç¡®ç‡ |
    |----------|----------------|-------------|
    | 2-layer  | ~69%           | ~69%        |
    | 3-layer  | ~67%           | ~63%        |
    | 4-layer  | ~67%           | ~51%        |
  - Grappa çš„éš”ç¦»è®­ç»ƒå…·æœ‰ç±»ä¼¼ **dropout** çš„æ­£åˆ™åŒ–æ•ˆæœï¼Œæœ‰æ•ˆç¼“è§£äº†æ·±å±‚æ¨¡å‹çš„è¿‡æ‹Ÿåˆé—®é¢˜ã€‚

#### ä¸ Cluster-GCN å¯¹æ¯”ï¼ˆTable 5ï¼‰
- **é€Ÿåº¦**ï¼šCluster-GCN çš„ epoch æ—¶é—´çº¦ä¸º Grappa çš„ä¸€åŠï¼ˆ1.2s vs 2.6s on OGBN-Prï¼‰ã€‚
- **å‡†ç¡®æ€§**ï¼šGrappa æµ‹è¯•å‡†ç¡®ç‡æ›´é«˜ï¼ˆ**76.63%** vs 73.90%ï¼‰ã€‚
- **æ€»è€—æ—¶**ï¼šè€ƒè™‘é¢„å¤„ç†æ—¶é—´ï¼ˆCluster-GCN éœ€ 881s èšç±»ï¼‰ï¼ŒGrappa æ€»æ—¶é—´æ›´çŸ­ï¼ˆ1425s vs 1481sï¼‰ã€‚
- **é€šç”¨æ€§**ï¼šGrappa æ”¯æŒæ‰€æœ‰ GNN æ¨¡å‹ï¼Œè€Œ Cluster-GCN ä»…é™ GCNã€‚

#### ä¸ MGG å¯¹æ¯”ï¼ˆTable 6ï¼‰
- **å°å›¾**ï¼šMGG åˆ©ç”¨ NVLink åœ¨å°å›¾ä¸Šæ›´å¿«ï¼ˆå¦‚ Reddit ä¸Š 0.2s vs 0.4sï¼‰ã€‚
- **å¤§å›¾**ï¼šMGG å› æ˜¾å­˜ä¸è¶³åœ¨ OGBN-Pa ä¸Šå´©æºƒï¼ˆ2/4 GPUï¼‰ï¼Œè€Œ Grappa æˆåŠŸè¿è¡Œï¼ˆ5.7s @2 GPUï¼‰ã€‚
- **ç»“è®º**ï¼šGrappa åœ¨æ˜¾å­˜å—é™åœºæ™¯ä¸‹æ›´å…·ä¼˜åŠ¿ï¼Œä¸”å…¶åˆ†å¸ƒå¼æ¶æ„å¤©ç„¶æ”¯æŒå¤šèŠ‚ç‚¹æ‰©å±•ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 7ï¼‰
åœ¨ Reddit æ•°æ®é›†ä¸Šå¯¹ Grappa çš„å…³é”®ç»„ä»¶è¿›è¡Œæ¶ˆèï¼š

| æ–¹æ³• | æè¿° | æµ‹è¯•å‡†ç¡®ç‡ï¼ˆGCN-3ï¼‰ |
|------|------|---------------------|
| **Grappa** | å®Œæ•´æ–¹æ³• | **0.9326** |
| Grappa-UW | ç§»é™¤è¦†ç›–ç‡æ ¡æ­£ | 0.8284 |
| Grappa-FP | å›ºå®šåˆ†åŒºï¼ˆä¸é‡åˆ†åŒºï¼‰ | 0.8464 |
| Grappa-50S | 50% è¿œç¨‹é‡‡æ ·ï¼ˆééš”ç¦»ï¼‰ | 0.6593 |

- **å‘ç°**ï¼šç§»é™¤ä»»ä¸€ç»„ä»¶éƒ½ä¼šå¯¼è‡´å‡†ç¡®ç‡ä¸‹é™ï¼Œè¯æ˜ **åŠ¨æ€é‡åˆ†åŒº** å’Œ **è¦†ç›–ç‡æ ¡æ­£** å‡è‡³å…³é‡è¦ã€‚
- **åç›´è§‰å‘ç°**ï¼šå³ä½¿å…è®¸è®¿é—®è¿œç¨‹èŠ‚ç‚¹ï¼ˆGrappa-50Sï¼‰ï¼Œå…¶å‡†ç¡®ç‡ä»è¿œä½äºå®Œæ•´ Grappaï¼Œè¯´æ˜ **éš”ç¦»è®­ç»ƒ + æ ¡æ­£æœºåˆ¶** çš„ç»„åˆä¼˜äºç›´æ¥è®¿é—®ï¼Œå¯èƒ½å¾—ç›Šäºæ›´å¼ºçš„æ­£åˆ™åŒ–æ•ˆæœã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **é€šä¿¡æ˜¯ç“¶é¢ˆ**ï¼šè·¨åˆ†åŒºé‚»å±…é€šä¿¡æ˜¯åˆ†å¸ƒå¼ GNN è®­ç»ƒçš„ä¸»è¦å¼€é”€ï¼Œè€Œéè®¡ç®—ã€‚
2. **éš”ç¦»è®­ç»ƒå¯è¡Œ**ï¼šé€šè¿‡ **åŠ¨æ€é‡åˆ†åŒº + è¦†ç›–ç‡æ ¡æ­£**ï¼Œå¯ä»¥åœ¨å®Œå…¨æ¶ˆé™¤ç‰¹å¾é€šä¿¡çš„å‰æä¸‹ï¼Œç»´æŒç”šè‡³æå‡æ¨¡å‹ç²¾åº¦ã€‚
3. **æ­£åˆ™åŒ–æ•ˆåº”**ï¼šéš”ç¦»è®­ç»ƒç±»ä¼¼äºè¾“å…¥å±‚ dropoutï¼Œç‰¹åˆ«æœ‰åˆ©äºæ·±å±‚ GNN æ¨¡å‹ï¼Œå‡è½»è¿‡æ‹Ÿåˆã€‚
4. **é«˜æ•ˆæ‰©å±•**ï¼šGrappa å®ç°äº†è¿‘ä¹çº¿æ€§çš„æ°´å¹³æ‰©å±•ï¼Œå¹¶èƒ½é€šè¿‡ phase-parallel æ¨¡å¼çªç ´å•æœºå†…å­˜é™åˆ¶ã€‚
5. **é€šç”¨æ€§å¼º**ï¼šæ–¹æ³•ä¸ä¾èµ–ç‰¹å®šæ¨¡å‹ã€ç¡¬ä»¶æˆ–ç¼“å­˜ç­–ç•¥ï¼Œå…·æœ‰å¹¿æ³›é€‚ç”¨æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **é‡åˆ†åŒºå¼€é”€**ï¼šè™½ç„¶å®éªŒè¯æ˜å¼€é”€è¾ƒä½ï¼ˆ<12% è®­ç»ƒæ—¶é—´ï¼‰ï¼Œä½†åœ¨æé«˜é¢‘ç‡åˆ‡æ¢åˆ†åŒºæ—¶å¯èƒ½å½±å“æ•ˆç‡ã€‚
- **æ”¶æ•›é€Ÿåº¦**ï¼šå°½ç®¡ epoch æ—¶é—´çŸ­ï¼Œä½†å¯èƒ½éœ€è¦æ›´å¤š epoch æ”¶æ•›ï¼ˆæ–‡ä¸­æœªæ˜ç¡®æ¯”è¾ƒæ€»æ”¶æ•›æ—¶é—´ï¼‰ã€‚
- **ç†è®ºå‡è®¾**ï¼šæ¸è¿‘æ— åæ€§ä¾èµ–äºé•¿æœŸæ­£è¦†ç›–æ¦‚ç‡ï¼Œå®é™…ä¸­è¶…çº§ epoch æ•°æœ‰é™ï¼Œå¯èƒ½å­˜åœ¨æ®‹ä½™åå·®ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- è®¾è®¡æ›´æ™ºèƒ½çš„ **åˆ†åŒºåˆ‡æ¢å¯å‘å¼ç­–ç•¥**ï¼ˆå½“å‰ä½¿ç”¨ç®€å•è½®è½¬ï¼‰ã€‚
- æ¢ç´¢ **è‡ªé€‚åº”é‡åˆ†åŒºé¢‘ç‡**ï¼Œæ ¹æ®æ¨¡å‹æ”¶æ•›çŠ¶æ€åŠ¨æ€è°ƒæ•´ã€‚
- å°† Grappa çš„æ€æƒ³åº”ç”¨äº **Federated GNN** åœºæ™¯ï¼Œç»“åˆéšç§ä¿æŠ¤ä¸é«˜æ•ˆé€šä¿¡ã€‚
- è¿›ä¸€æ­¥ä¼˜åŒ– **phase-parallel æ¨¡å¼** ä¸‹çš„èµ„æºè°ƒåº¦ä¸ I/O æ•ˆç‡ã€‚

> **æ€»ç»“**ï¼šGrappa é€šè¿‡é¢ è¦†æ€§çš„ **gradient-only communication** èŒƒå¼ï¼Œä»æ ¹æœ¬ä¸Šè§£å†³äº†åˆ†å¸ƒå¼ GNN è®­ç»ƒçš„é€šä¿¡ç“¶é¢ˆï¼Œå®ç°äº†é€Ÿåº¦ã€ç²¾åº¦å’Œå¯æ‰©å±•æ€§çš„å…¨é¢è¶…è¶Šï¼Œä¸ºè¶…å¤§è§„æ¨¡å›¾å­¦ä¹ æä¾›äº†æ–°çš„å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 6. [Dynamic Expert Sharing: Decoupling Memory from Parallelism in Mixture-of-Experts Diffusion LLMs](https://arxiv.org/abs/2602.00879)

**Authors**: Hao Mark Chen, Zhiwen Mo, Royson Lee, Qianzhou Wang, Da Li, Shell Xu Hu, Wayne Luk, Timothy Hospedales, Hongxiang Fan  
**Category**: cs.LG  
**Published**: 2026-02-03  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2602.00879v1  

#### Abstract
Among parallel decoding paradigms, diffusion large language models (dLLMs) have emerged as a promising candidate that balances generation quality and throughput. However, their integration with Mixture-of-Experts (MoE) architectures is constrained by an expert explosion: as the number of tokens gene...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šDynamic Expert Sharing: Decoupling Memory from Parallelism in Mixture-of-Experts Diffusion LLMs**

---

## 1. **è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### âœ… **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
- **â€œExpert Explosionâ€ç“¶é¢ˆ**ï¼šåœ¨ Mixture-of-Experts (MoE) æ¶æ„çš„ diffusion large language models (dLLMs) ä¸­ï¼Œéšç€å¹¶è¡Œè§£ç çš„ token æ•°é‡å¢åŠ ï¼Œæ¯ä¸ª token ç‹¬ç«‹è·¯ç”±å¯¼è‡´æ¿€æ´»çš„**å”¯ä¸€ä¸“å®¶æ•°é‡è¿‘ä¹çº¿æ€§å¢é•¿**ï¼Œå¼•å‘ä¸¥é‡çš„ **HBMï¼ˆHigh Bandwidth Memoryï¼‰åˆ° SRAM çš„å†…å­˜æµé‡å¼€é”€**ã€‚
- è¿™ä½¿å¾—æ¨¡å‹æ¨ç†è¿›å…¥ **memory-bound regime**ï¼ŒæŠµæ¶ˆäº† MoE å’Œå¹¶è¡Œè§£ç å¸¦æ¥çš„è®¡ç®—æ•ˆç‡ä¼˜åŠ¿ã€‚

### ğŸš€ **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æå‡º **Dynamic Expert Sharing (DES)**ï¼Œä¸€ç§å…¨æ–°çš„ MoE ä¼˜åŒ–èŒƒå¼ï¼š
- å°†ä¼˜åŒ–ç›®æ ‡ä» **token-centric pruning** è½¬å‘ **sequence-level coreset selection**ã€‚
- åœ¨ä¸€ä¸ªå¹¶è¡Œè§£ç å—å†…ï¼Œé€šè¿‡è·¨ token å…±è¯†åŠ¨æ€é€‰æ‹©ä¸€ä¸ª**ç´§å‡‘ä¸”é«˜å®ç”¨æ€§çš„ä¸“å®¶å­é›†ï¼ˆcoresetï¼‰**ï¼Œä¾›æ‰€æœ‰ token å…±äº«ä½¿ç”¨ã€‚

#### ä¸¤ç§æ ¸å¿ƒç­–ç•¥ï¼š
1. **DES-Seq (Intra-Sequence Sharing)**  
   - å¯¹ block å†…æ¯ä¸ª token çš„ Top-k ä¸“å®¶å–å¹¶é›†ï¼Œå½¢æˆå…±äº« coresetã€‚
   - ç®€å•æœ‰æ•ˆï¼Œæ”¯æŒå‘é‡åŒ–æ‰§è¡Œã€‚

2. **DES-Vote (Saliency-Aware Voting)**  
   - å¼•å…¥åŸºäº router æƒé‡çš„åŠ æƒæŠ•ç¥¨æœºåˆ¶ï¼Œèšåˆæ‰€æœ‰ token çš„è·¯ç”±å¾—åˆ†ã€‚
   - é«˜ saliency çš„ä¸“å®¶æ›´å¯èƒ½è¢«é€‰ä¸­ï¼Œå®ç°å¯¹è¯­ä¹‰å¤æ‚åº¦çš„æ•´ä½“å“åº”ã€‚

> ğŸ’¡ **æ ¸å¿ƒæ€æƒ³**ï¼šåˆ©ç”¨å¹¶è¡Œ token ä¹‹é—´çš„è¯­ä¹‰ç›¸å…³æ€§ï¼Œæœ€å¤§åŒ–ä¸“å®¶å¤ç”¨ï¼Œä»è€Œ**è§£è€¦å†…å­˜å¼€é”€ä¸å¹¶è¡Œåº¦ï¼ˆdegree of parallelismï¼‰**ã€‚

### âš–ï¸ **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹æ³• | å±€é™æ€§ | DES çš„æ”¹è¿› |
|------|--------|------------|
| **Vanilla MoE** | æ¯ä¸ª token ç‹¬ç«‹è·¯ç”± â†’ ä¸“å®¶çˆ†ç‚¸ | æ˜¾è‘—å‡å°‘å”¯ä¸€æ¿€æ´»ä¸“å®¶æ•° |
| **Expert Pruning / Merging** | é™æ€å‹ç¼©ï¼Œä¸å¯é€†æŸå¤±å®¹é‡ | åŠ¨æ€ã€æ— æŸï¼ˆæ— éœ€é‡æ–°è®­ç»ƒï¼‰ |
| **Expert Skipping (e.g., NAEE, MC-MoE)** | ä»…å‡å°‘ per-token FLOPsï¼Œä¸è§£å†³å…¨å±€ HBM æµé‡ | é™ä½æ•´ä½“ HBM æ•°æ®åŠ è½½é‡ |
| **OEA (Batch-level sharing)** | é€‚ç”¨äº AR æ‰¹å¤„ç†ï¼Œæœªé’ˆå¯¹ dLLM è®¾è®¡ | ä¸“ä¸º block-wise å¹¶è¡Œè§£ç è®¾è®¡ |

---

## 2. **æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### ğŸ“š **ä½¿ç”¨çš„æ•°æ®é›†**
å››ä¸ªéœ€è¦é•¿æ–‡æœ¬ç”Ÿæˆå’Œå¤šæ ·åŒ–æ¨ç†èƒ½åŠ›çš„åŸºå‡†ï¼š
- **HumanEval**ï¼šä»£ç ç”Ÿæˆä»»åŠ¡
- **MBPP**ï¼šPython ç¼–ç¨‹ä»»åŠ¡
- **GSM8K**ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜
- **MATH500**ï¼šé«˜ç­‰æ•°å­¦é—®é¢˜

> æ‰€æœ‰ç»“æœä¸ºå¤šä¸ª benchmark ä¸Šçš„å¹³å‡å€¼æˆ–åˆ†åˆ«æŠ¥å‘Šã€‚

### âš™ï¸ **å®éªŒè®¾ç½®**
- **æ¨¡å‹**ï¼š
  - `LLaDA2.0-Mini` (16B, MoE)
  - `LLaDA-MoE-7B` (7B, MoE)
- **ç¡¬ä»¶å¹³å°**ï¼š
  - NVIDIA B200 GPU + Intel Xeon 6960P CPU
  - CUDA 13.1ï¼ŒNsight Systems ç”¨äºæ€§èƒ½å‰–æ
- **æ¡†æ¶**ï¼š
  - ä½¿ç”¨ `dInfer` æ¡†æ¶ + `Fast-dLLM` KV cache æ–¹æ³•
  - Block length = 32 tokensï¼ˆå« 16 prefix + 16 suffixï¼‰
- **å‚æ•°æ§åˆ¶**ï¼š
  - DES-Voteï¼šé€šè¿‡ budget factor $ \beta $ æ§åˆ¶ coreset å¤§å° $ M_{\text{core}} = \beta \times M $
  - DES-Seqï¼šé€šè¿‡å±€éƒ¨é€‰æ‹©æ•° $ k $ æ§åˆ¶

### ğŸ¯ **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Unique Activated Experts (T)** | æ¯å±‚å¹³å‡æ¿€æ´»çš„å”¯ä¸€ä¸“å®¶æ•°é‡ |
| **Relative Accuracy (R.Acc %)** | ç›¸å¯¹äº vanilla æ¨¡å‹çš„å‡†ç¡®ç‡ç™¾åˆ†æ¯” |
| **MoE Kernel Latency (ms)** | MoE å±‚å‰å‘ä¼ æ’­å»¶è¿Ÿ |
| **End-to-End GPU Kernel Time** | æ•´ä½“ GPU æ¨ç†è€—æ—¶ |
| **Memory Footprint (GB)** | æ¿€æ´»å‚æ•°çš„å†…å­˜å ç”¨ |
| **Cosine Similarity (s)** | ä¸åŸå§‹è·¯ç”±æ¨¡å¼çš„ç›¸ä¼¼åº¦ï¼ˆä¿çœŸåº¦ï¼‰ |

### ğŸ” **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **Vanilla**ï¼šæ ‡å‡† MoE è·¯ç”±
- **Top-K (k=4)**ï¼šç›´æ¥å‡å°‘ K å€¼ä»¥é™ä½æµé‡
- **NAEE**ï¼šåŸºäºç´¯ç§¯æ¦‚ç‡è·³è¿‡ä½åˆ†ä¸“å®¶
- **MC-MoE**ï¼šä¿ç•™é‡è¦ token çš„ä¸“å®¶
- æ‰€æœ‰ baseline å‡é€‚é…è‡³ dLLM è®¾ç½®ï¼Œä»…æ¯”è¾ƒåŠ¨æ€åˆ†é…ç­–ç•¥

---

## 3. **ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### ğŸ“Š **å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»ï¼ˆæ¥è‡ª Table 1ï¼‰**

| æ–¹æ³• | Avg. T â†“ | Mem. (GB) â†“ | R.Acc (%) â†‘ | æ¨¡å‹ |
|------|---------|------------|-------------|-------|
| **Vanilla** | 84 | 0.98 | 100.0 | LLaDA2.0-Mini |
| **DES-Vote (Î²=0.15)** | **38** | **0.45** | **99.5** | |
| **DES-Seq (k=3)** | 45 | 0.53 | 97.2 | |
| **NAEE / MC-MoE** | ~65 | ~0.76 | ~46.6 | |
| â€” | â€” | â€” | â€” | â€” |
| **Vanilla** | 59 | 0.35 | 100.0 | LLaDA-MoE-7B |
| **DES-Vote (Î²=0.6)** | **38** | **0.22** | **97.6** | |
| **DES-Seq (k=3)** | 42 | 0.25 | 96.9 | |

> âœ… **DES-Vote åœ¨ LLaDA2.0-Mini ä¸Šå®ç°ï¼š**
- **å”¯ä¸€ä¸“å®¶å‡å°‘ 55%**ï¼ˆ84 â†’ 38ï¼‰
- **å†…å­˜å ç”¨ä¸‹é™ 54%**ï¼ˆ0.98GB â†’ 0.45GBï¼‰
- **ä¿æŒ 99.5% çš„åŸå§‹ç²¾åº¦**

### â±ï¸ **æ•ˆç‡æå‡ï¼ˆFigure 5ï¼‰**
- **MoE Kernel Latency ä¸‹é™æœ€å¤šè¾¾ 38.0%**ï¼ˆLLaDA2.0-Miniï¼‰
- **æ€»ç«¯åˆ°ç«¯ GPU æ—¶é—´å‡å°‘ 8.2%â€“14.3%**
- ä¸»è¦æ”¶ç›Šæ¥è‡ªç¼“è§£ HBM è®¿é—®ç“¶é¢ˆ

### ğŸ” **è‡ªå®šä¹‰èåˆæ ¸å‡½æ•°åŠ é€Ÿï¼ˆFigure 6ï¼‰**
- å¼€å‘äº†èåˆ 12 ä¸ªæ“ä½œï¼ˆsoftmax, top-k, reductionï¼‰çš„å®šåˆ¶ GPU kernel
- **Coreset selection é˜¶æ®µé€Ÿåº¦æå‡ 6Ã—**

### ğŸ”¬ **æ¶ˆèå®éªŒç»“æœ**

#### ï¼ˆ1ï¼‰**Coreset Size å½±å“ï¼ˆFigure 7aï¼‰**
- å‡†ç¡®ç‡éš coreset å¢å¤§è€Œä¸Šå‡
- **DES-Vote åœ¨ç›¸åŒå¤§å°ä¸‹å§‹ç»ˆä¼˜äº DES-Seq**
- å¯é…ç½®æå° coresetï¼ˆå¦‚ Î²=0.1ï¼‰ï¼Œçªç ´ DES-Seq â€œæ¯ token è‡³å°‘ä¸€ä¸“å®¶â€çš„é™åˆ¶
- æŸäº›æƒ…å†µä¸‹å‡ºç°æ­£å¢ç›Šï¼ˆ>100% R.Accï¼‰ï¼Œæ¨æµ‹å› å™ªå£°ä¸“å®¶è¢«å‰ªæäº§ç”Ÿæ­£åˆ™åŒ–æ•ˆåº”

#### ï¼ˆ2ï¼‰**Block Size é²æ£’æ€§ï¼ˆFigure 7bï¼‰**
- DES-Vote åœ¨ block size ä» 8 åˆ° 64 æ—¶ï¼Œå‡†ç¡®ç‡æ³¢åŠ¨æå°
- **æ¿€æ´»ä¸“å®¶æ•°åŸºæœ¬æ’å®š**ï¼ŒçœŸæ­£å®ç°äº†â€œå†…å­˜å¼€é”€ä¸å¹¶è¡Œåº¦è§£è€¦â€
- Vanilla æ–¹æ³•éš block å¢å¤§ä¸“å®¶æ•°æ€¥å‰§ä¸Šå‡

#### ï¼ˆ3ï¼‰**Per-Token Computation å½±å“ï¼ˆFigure 8ï¼‰**
- å›ºå®šå”¯ä¸€ä¸“å®¶æ•°ï¼ˆå¦‚ 38ï¼‰ï¼Œä½†æ”¹å˜ per-token K å€¼ï¼ˆ8 vs 4ï¼‰
- K=8 æ›´ä¼˜ â†’ è¡¨æ˜ **ä» coreset ä¸­ re-activate åŸæœ¬é top-K çš„ä¸“å®¶ä»èƒ½ç»´æŒæ€§èƒ½**

#### ï¼ˆ4ï¼‰**ä¸“å®¶åˆ©ç”¨ç‡åˆ†æï¼ˆFigure 9ï¼‰**
- **Cosine similarity â‰¥ 0.98** â†’ è·¯ç”±æ¨¡å¼é«˜åº¦ä¿çœŸ
- DES-Vote çš„ hit åˆ†å¸ƒæ›´é›†ä¸­ï¼ˆsharp curveï¼‰ï¼ŒæŠ‘åˆ¶é•¿å°¾ï¼Œè¿›ä¸€æ­¥èŠ‚çœå†…å­˜

---

## 4. **å…³é”®ç»“è®ºå’Œå‘ç°**

### âœ… **ä¸»è¦å‘ç°**
1. **â€œExpert Explosionâ€æ˜¯ dLLM + MoE çš„å…³é”®ç“¶é¢ˆ**ï¼Œå…¶æœ¬è´¨æ˜¯å†…å­˜æµé‡è€Œéè®¡ç®—å‹åŠ›ã€‚
2. **å¹¶è¡Œ token å­˜åœ¨æ˜¾è‘—ä¸“å®¶éœ€æ±‚é‡å **ï¼Œå¯é€šè¿‡åºåˆ—çº§å…±è¯†å®ç°é«˜æ•ˆå…±äº«ã€‚
3. **DES ç‰¹åˆ«æ˜¯ DES-Vote èƒ½ä»¥ <1% ç²¾åº¦æŸå¤±æ¢å– >55% å”¯ä¸€ä¸“å®¶å‡å°‘å’Œè¿‘ 40% å»¶è¿Ÿä¸‹é™**ã€‚
4. **DES æˆåŠŸå°† HBM æµé‡ä¸å¹¶è¡Œåº¦è§£è€¦**ï¼Œä½¿å¼€å‘è€…å¯è‡ªç”±è°ƒæ•´ block size è€Œä¸å—å†…å­˜å¸¦å®½åˆ¶çº¦ã€‚

### âš ï¸ **æ–¹æ³•çš„å±€é™æ€§**
- å½“å‰ä¾èµ–äº router logits çš„å¯èšåˆæ€§ï¼Œåœ¨æç«¯å¼‚æ„ä»»åŠ¡æ··åˆåœºæ™¯ä¸­å¯èƒ½å¤±æ•ˆã€‚
- æç«¯å‹ç¼©ï¼ˆå¦‚ Î² < 0.1ï¼‰å¯èƒ½å¯¼è‡´æ€§èƒ½ä¸ç¨³å®šï¼Œéœ€è°¨æ…è°ƒå‚ã€‚
- å®šåˆ¶ kernel å¢åŠ éƒ¨ç½²å¤æ‚æ€§ï¼Œå°šæœªé›†æˆè¿›ä¸»æµæ¨ç†æ¡†æ¶ï¼ˆå¦‚ vLLM, TensorRT-LLMï¼‰ã€‚

### ğŸ”® **æœªæ¥å·¥ä½œæ–¹å‘**
- æ¢ç´¢ **adaptive Î² æ§åˆ¶æœºåˆ¶**ï¼Œæ ¹æ®è¾“å…¥å¤æ‚åº¦åŠ¨æ€è°ƒèŠ‚ coreset å¤§å°ã€‚
- å°† DES æ‰©å±•è‡³ **multimodal MoE models**ï¼ˆå¦‚ MoE-VLMsï¼‰ã€‚
- ç»“åˆ **expert prefetching** ä¸ DESï¼Œè¿›ä¸€æ­¥éšè—å†…å­˜å»¶è¿Ÿã€‚
- ç ”ç©¶ **sequence-level expert routing çš„å¯å­¦ä¹ æœºåˆ¶**ï¼Œæ›¿ä»£å¯å‘å¼æŠ•ç¥¨ã€‚

---

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> **DES é€šè¿‡ sequence-level coreset selection å®ç°äº† MoE dLLMs ä¸­ memory ä¸ parallelism çš„è§£è€¦ï¼Œåœ¨å‡ ä¹æ— æŸç²¾åº¦çš„å‰æä¸‹å¤§å¹…é™ä½å†…å­˜æµé‡å’Œå»¶è¿Ÿï¼Œä¸ºé«˜ååå¹¶è¡Œç”Ÿæˆæä¾›äº†æ–°è·¯å¾„ã€‚**

</details>

---

### 7. [Hard Constraints Meet Soft Generation: Guaranteed Feasibility for LLM-based Combinatorial Optimization](https://arxiv.org/abs/2602.01090)

**Authors**: Yang Liu, Chuan Zhou, Yancheng Chen, Shuai Zhang, Xixun Lin, Xiaoqing Wang  
**Category**: cs.AI  
**Published**: 2026-02-03  
**Score**: 11.5  
**Type**: new  
**ArXiv ID**: 2602.01090v1  

#### Abstract
Large language models (LLMs) have emerged as promising general-purpose solvers for combinatorial optimization (CO), yet they fundamentally lack mechanisms to guarantee solution feasibility which is critical for real-world deployment. In this work, we introduce FALCON, a framework that ensures 100\% ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šHard Constraints Meet Soft Generation: Guaranteed Feasibility for LLM-based Combinatorial Optimization

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç»„åˆä¼˜åŒ–ï¼ˆCombinatorial Optimization, COï¼‰ä»»åŠ¡ä¸­å±•ç°å‡ºå¼ºå¤§çš„æ¨¡å¼è¯†åˆ«å’Œåºåˆ—ç”Ÿæˆèƒ½åŠ›ï¼Œä½†å…¶æœ¬è´¨æ˜¯**æ— çº¦æŸçš„ç”Ÿæˆæ¨¡å‹**ï¼Œæ— æ³•ä¿è¯è¾“å‡ºæ»¡è¶³ç¡¬æ€§çº¦æŸæ¡ä»¶ï¼ˆå¦‚å®¹é‡é™åˆ¶ã€è·¯å¾„è¿é€šæ€§ã€ç‹¬ç«‹é›†éé‚»æ¥ç­‰ï¼‰ã€‚è¿™å¯¼è‡´ç°æœ‰LLM-based COæ±‚è§£å™¨çš„å¯è¡Œæ€§ï¼ˆFeasibilityï¼‰è¿œä½äº100%ï¼Œä¸¥é‡åˆ¶çº¦å…¶åœ¨ç‰©æµã€åˆ¶é€ ã€åº”æ€¥è°ƒåº¦ç­‰å®‰å…¨æ•æ„Ÿåœºæ™¯çš„å®é™…éƒ¨ç½²ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡º **FALCON**ï¼ˆFeasibility-Aware Language-based Combinatorial Optimization with Adaptive Inferenceï¼‰ï¼Œé¦–ä¸ªèƒ½æä¾›**100%å¯è¡Œæ€§ä¿è¯**çš„LLM-based COæ¡†æ¶ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†â€œå¯è¡Œæ€§â€åˆ†è§£ä¸ºä¸¤ä¸ªå±‚æ¬¡ï¼Œå¹¶é€šè¿‡ä¸‰ä¸ªååŒç»„ä»¶å®ç°ï¼š

1. **Grammar-Constrained Decoding**  
   åˆ©ç”¨é—®é¢˜ç‰¹å®šçš„ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•ï¼ˆContext-Free Grammar, CFGï¼‰çº¦æŸè§£ç å¤´éƒ¨ï¼Œç¡®ä¿è¾“å‡ºæ ¼å¼æ­£ç¡®ï¼ˆå¦‚æ‹¬å·åŒ¹é…ã€ç´¢å¼•æœ‰æ•ˆï¼‰ï¼Œè§£å†³**è¯­æ³•æœ‰æ•ˆæ€§**é—®é¢˜ã€‚

2. **Feasibility Repair Layer**  
   è®¾è®¡é—®é¢˜ç›¸å…³çš„ä¿®å¤ç®—å­ï¼ˆRepair Operatorï¼‰ï¼Œå°†ä»»ä½•è¿åè¯­ä¹‰çº¦æŸçš„è§£è½¬æ¢ä¸ºå¯è¡Œè§£ã€‚è¯¥ç®—å­æ»¡è¶³ä¸‰å¤§æ€§è´¨ï¼š
   - **å¯è¡Œæ€§**ï¼ˆFeasibilityï¼‰ï¼šè¾“å‡ºå¿…ä¸ºå¯è¡Œè§£ï¼›
   - **å¹‚ç­‰æ€§**ï¼ˆIdempotenceï¼‰ï¼šè¾“å…¥å·²å¯è¡Œåˆ™ä¸ä¿®æ”¹ï¼›
   - **æœ‰ç•Œå±€éƒ¨æ€§**ï¼ˆBounded Localityï¼‰ï¼šä¿®æ”¹å¹…åº¦ä¸çº¦æŸè¿åç¨‹åº¦æˆæ­£æ¯”ã€‚

3. **Adaptive Best-of-N Sampling**  
   åŠ¨æ€è°ƒæ•´é‡‡æ ·æ•°é‡ï¼šåŸºäºå¤šä¸ªæ ·æœ¬çš„ä¸€è‡´æ€§ï¼ˆConsistencyï¼‰ä¼°è®¡å®ä¾‹éš¾åº¦ï¼Œåœ¨ç®€å•å®ä¾‹ä¸Šæ—©åœä»¥èŠ‚çœè®¡ç®—ï¼Œåœ¨å›°éš¾å®ä¾‹ä¸Šå¢åŠ æ¢ç´¢ã€‚

æ­¤å¤–ï¼Œè®­ç»ƒé˜¶æ®µå¼•å…¥ **BOPO**ï¼ˆBest-anchored Objective-guided Preference Optimizationï¼‰ï¼š
- æ„é€ åå¥½å¯¹æ—¶ä»¥å½“å‰æ‰¹æ¬¡ä¸­çš„æœ€ä¼˜å¯è¡Œè§£ä¸ºé”šç‚¹ï¼ˆBest-anchoredï¼‰ï¼›
- æŸå¤±å‡½æ•°ä¸­æŒ‰ç›®æ ‡å€¼å·®è·åŠ æƒï¼ˆObjective-guided weightingï¼‰ï¼Œä½¿å·®è·æ›´å¤§çš„åŠ£è´¨è§£æä¾›æ›´å¼ºçš„å­¦ä¹ ä¿¡å·ï¼›
- å®ç°æ— éœ€äººå·¥æ ‡æ³¨çš„å¯†é›†ç›‘ç£ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰æ–¹æ³• | FALCON |
|------|--------|--------|
| å¯è¡Œæ€§ä¿è¯ | è½¯çº¦æŸæ¿€åŠ±ï¼Œä¸å¯æ§ï¼ˆé€šå¸¸<100%ï¼‰ | **ç†è®ºå¯è¯çš„100%å¯è¡Œæ€§** |
| è§£è´¨é‡ | æ˜“å› æ‹’ç»é‡‡æ ·ä¸¢å¤±é«˜è´¨é‡ä½†ä¸å¯è¡Œè§£ | ä¿®å¤æœºåˆ¶ä¿ç•™å¤§éƒ¨åˆ†ç»“æ„ï¼Œè´¨é‡æŸå¤±å¯æ§ |
| æ¨ç†æ•ˆç‡ | å›ºå®šé‡‡æ ·æ•°ï¼Œèµ„æºåˆ†é…ä¸å‡ | è‡ªé€‚åº”é‡‡æ ·ï¼Œå¹³å‡å‡å°‘58%è®¡ç®—é‡ |
| è®­ç»ƒæ•ˆç‡ | Reward shapingç¨€ç–ï¼ŒGRPOæ¢¯åº¦è¢«ä¸»å¯¼æ ·æœ¬å„æ–­ | BOPOæä¾›æ›´å¯†é›†ã€å‡è¡¡çš„æ¢¯åº¦æ›´æ–° |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
åœ¨**ä¸ƒä¸ªNP-hard COé—®é¢˜**ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œè¦†ç›–ä¸‰å¤§é¢†åŸŸï¼š

| é—®é¢˜ç±»åˆ« | å…·ä½“é—®é¢˜ | è§„æ¨¡ | åˆ†å¸ƒ | å‚è€ƒæ±‚è§£å™¨ |
|---------|--------|------|------|------------|
| Routing | TSP, CVRP, OP | 10â€“100èŠ‚ç‚¹ | Uniform, GM | LKH-3, COMPASS |
| Graph | MIS, MVC | 50â€“500èŠ‚ç‚¹ | ER, BA | Gurobi |
| Scheduling | PFSP, JSSP | 10â€“100ä½œä¸š / 6â€“30ä½œä¸š | Taillard | QIG, OR-Tools |

æ‰€æœ‰è®­ç»ƒé›†å‡ä¸ºåˆæˆæ•°æ®ï¼ˆå…±50ä¸‡å®ä¾‹ï¼‰ï¼Œæµ‹è¯•é›†å„100ä¸ªå®ä¾‹ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### ä¸»è¦æŒ‡æ ‡
- **Feasibility (%)**ï¼šç”Ÿæˆè§£æ»¡è¶³æ‰€æœ‰çº¦æŸçš„æ¯”ä¾‹ã€‚
- **Optimality Gap (%)**ï¼šç›¸å¯¹äºå‚è€ƒæ±‚è§£å™¨ï¼ˆå¦‚LKHã€Gurobiï¼‰çš„ç›¸å¯¹ç›®æ ‡å€¼å·®è·ã€‚
- **Inference Time (s)**ï¼šæ¯å®ä¾‹å¹³å‡æ¨ç†æ—¶é—´ã€‚

#### æ¨ç†é…ç½®
- `N_min=8`, `N_max=64`, ç½®ä¿¡é˜ˆå€¼ `T=0.85`ï¼Œæ¸©åº¦ `T=0.7`
- è‡ªé€‚åº”é‡‡æ ·åŸºäºè´å¶æ–¯ç½®ä¿¡åº¦æå‰ç»ˆæ­¢ã€‚

#### è®­ç»ƒæµç¨‹
1. **SFTé˜¶æ®µ**ï¼šåœ¨ä¸“å®¶è§£ä¸Šå¾®è°ƒï¼ˆå¦‚LKHç”Ÿæˆçš„TSPè§£ï¼‰ï¼›
2. **BOPOé˜¶æ®µ**ï¼šä»å½“å‰ç­–ç•¥é‡‡æ ·K=8ä¸ªè§£ï¼Œæ„å»ºåå¥½å¯¹å¹¶ä¼˜åŒ–BOPOæŸå¤±ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
åˆ†ä¸ºå››ç±»ï¼š

| ç±»å‹ | ä»£è¡¨æ–¹æ³• |
|------|--------|
| é›¶æ ·æœ¬é€šç”¨LLM | GPT-4o, Claude-3.5, Llama-3.3-70B |
| æ¨ç†å¢å¼ºLLM | GPT-o1, DeepSeek-R1 |
| LLMä¼˜åŒ–æ–¹æ³• | OPRO, LMEA, PHP, SGE |
| ç¥ç»COæ±‚è§£å™¨ | SFT Only, GRPO, LLMCoSolver |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ªTable 2ï¼‰

| æ–¹æ³• | å¹³å‡å¯è¡Œæ€§ (%) | å¹³å‡æœ€ä¼˜æ€§å·®è· (%) | å¹³å‡è€—æ—¶ (s) |
|------|----------------|--------------------|--------------|
| GPT-4o | ~40 | ~30â€“100 | 4â€“5 |
| LLMCoSolver (N=8) | 94â€“100 | 1.07â€“10.94 | 9.8 |
| **FALCON (Adaptive)** | **100** | **0.92â€“6.98** | **6.3** |

- **FALCONåœ¨æ‰€æœ‰7ä¸ªé—®é¢˜ä¸Šå‡è¾¾åˆ°100%å¯è¡Œæ€§**ï¼Œé¦–æ¬¡å®ç°ç†è®ºå¯è¯çš„å®Œå…¨å¯è¡Œæ€§ã€‚
- åœ¨æœ€ä¼˜æ€§å·®è·ä¸Šï¼Œ**5/7é—®é¢˜å–å¾—æœ€ä½³ç»“æœ**ï¼Œå…¶ä½™æ¥è¿‘æœ€ä¼˜ã€‚
- è‡ªé€‚åº”é‡‡æ ·ä¸‹ä»…éœ€å¹³å‡ **26.7æ¬¡é‡‡æ ·**ï¼ˆå›ºå®šN=64éœ€64æ¬¡ï¼‰ï¼ŒèŠ‚çœçº¦58%è®¡ç®—ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### âœ… å¯¹æ¯”é›¶æ ·æœ¬LLM
- å¯è¡Œæ€§æå‡å·¨å¤§ï¼šå¦‚TSPä»39% â†’ 100%ï¼ŒCVRPä»6% â†’ 100%
- æœ€ä¼˜æ€§å·®è·æ˜¾è‘—ç¼©å°ï¼šå¦‚TSPä»33.79% â†’ 0.92%

#### âœ… å¯¹æ¯”ç¥ç»COæ±‚è§£å™¨
- **ä¼˜äºGRPOå’ŒLLMCoSolver**ï¼šå°½ç®¡åè€…ä¹Ÿä½¿ç”¨å¼ºåŒ–å­¦ä¹ ï¼Œä½†FALCONé€šè¿‡BOPO+Repairå®ç°äº†æ›´é«˜é²æ£’æ€§å’Œæ›´ä½gapã€‚
- ä¾‹å¦‚åœ¨TSPä¸Šï¼ŒFALCON(N=8)çš„gapä¸º0.95%ï¼Œä¼˜äºLLMCoSolverçš„1.07%ã€‚

#### âœ… å¯¹æ¯”ç»å…¸å¯å‘å¼ç®—æ³•ï¼ˆTable 3ï¼‰
| æ–¹æ³• | TSPå¤§å®ä¾‹gap | CVRPå¤§å®ä¾‹gap | PFSPå¤§å®ä¾‹gap |
|------|-------------|---------------|----------------|
| Nearest Neighbor | 26.19% | 22.07% | â€” |
| ACO | 36.69% | 29.49% | â€” |
| OR-Tools | 3.59% | 8.84% | â€” |
| **FALCON (Adaptive)** | **1.08%** | **6.05%** | **1.21%** |

â†’ FALCONå…¨é¢è¶…è¶Šä¼ ç»Ÿå¯å‘å¼ï¼Œå°¤å…¶åœ¨å¤§è§„æ¨¡å®ä¾‹ä¸Šä¼˜åŠ¿æ˜æ˜¾ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 4ï¼‰

| é…ç½® | TSPå¯è¡Œæ€§ | TSP Gap | CVRPå¯è¡Œæ€§ | CVRP Gap |
|------|----------|--------|-----------|---------|
| FALCON (Full) | 100% | 0.92 | 100% | 3.52 |
| w/o Grammar | 100% | 0.95 | 100% | 3.67 |
| **w/o Repair** | **94%** | 0.89 | **85%** | 3.41 |
| w/o Adaptive | 100% | 0.91 | 100% | 3.48 |
| **w/o BOPO** | 100% | **1.85** | 100% | **5.89** |
| SFT Only | 89% | 2.30 | 59% | 6.02 |

- **ç§»é™¤Repairå±‚**ï¼šå¯è¡Œæ€§éª¤é™ï¼Œè¯æ˜å…¶å¯¹100%ä¿è¯è‡³å…³é‡è¦ã€‚
- **ç§»é™¤BOPO**ï¼šgapç¿»å€ä»¥ä¸Šï¼Œè¯´æ˜å…¶åœ¨æå‡è§£è´¨é‡ä¸Šçš„å…³é”®ä½œç”¨ã€‚
- **ç§»é™¤Grammar**ï¼šå½±å“è¾ƒå°ï¼Œè¡¨æ˜è¯­æ³•é”™è¯¯è¾ƒå°‘ï¼Œä½†ä»æœ‰åŠ©äºå‡è½»repairè´Ÿæ‹…ã€‚
- **ç§»é™¤Adaptive**ï¼šè´¨é‡ç•¥ä¼˜ä½†è€—æ—¶å¤šè¿‘ä¸€å€ï¼ŒéªŒè¯è‡ªé€‚åº”é‡‡æ ·çš„é«˜æ•ˆæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **å¯è¡Œæ€§å¯ä»¥è¢«ä¸¥æ ¼ä¿è¯**ï¼šé€šè¿‡â€œè¯­æ³•çº¦æŸ + è¯­ä¹‰ä¿®å¤â€çš„åˆ†å±‚æ¶æ„ï¼Œå¯åœ¨ä¸ç‰ºç‰²è¡¨è¾¾åŠ›çš„å‰æä¸‹å®ç°100%å¯è¡Œæ€§ã€‚
2. **ä¿®å¤ä¸ä¸€å®šæŸå®³è´¨é‡**ï¼šç”±äºBOPOè®­ç»ƒå‡ºçš„æ¨¡å‹æœ¬èº«é«˜åº¦å¯è¡Œï¼ˆä¿®å¤ç‡ä»…2.8â€“18.5%ï¼‰ï¼Œä¸”ä¿®å¤å…·æœ‰å±€éƒ¨æ€§ï¼Œå› æ­¤æ•´ä½“è´¨é‡æŸå¤±æå°ï¼Œç”šè‡³æœ‰æ—¶èƒ½å»é™¤å†—ä½™èŠ‚ç‚¹è€Œæ”¹å–„è§£ã€‚
3. **è‡ªé€‚åº”é‡‡æ ·æ˜¾è‘—ææ•ˆ**ï¼šåŸºäºä¸€è‡´æ€§ï¼ˆConsistencyï¼‰çš„éš¾åº¦ä¼°è®¡èƒ½å‡†ç¡®åŒºåˆ†æ˜“/éš¾å®ä¾‹ï¼Œå®ç°â€œç®€å•é¢˜å¿«ç­”ï¼Œéš¾é¢˜æ·±æ€â€ï¼Œå¹³å‡èŠ‚çœè¶…ä¸€åŠè®¡ç®—èµ„æºã€‚
4. **BOPOä¼˜äºGRPO**ï¼šåœ¨ç›¸åŒèµ·ç‚¹å’Œé¢„ç®—ä¸‹ï¼ŒBOPOåœ¨æ‰€æœ‰é—®é¢˜ä¸Šéƒ½å–å¾—æ›´ä½çš„æœ€ä¼˜æ€§å·®è·å’Œæ›´é«˜çš„å¯è¡Œæ€§ï¼ˆå›¾2ï¼‰ï¼Œå°¤å…¶åœ¨å¼ºçº¦æŸé—®é¢˜ï¼ˆå¦‚CVRPã€MISï¼‰ä¸Šä¼˜åŠ¿æ›´å¤§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¿®å¤å¯èƒ½å¼•å…¥åå·®**ï¼šè™½ç„¶ç†è®ºä¸Šä¿®å¤æ˜¯å±€éƒ¨çš„ï¼Œä½†åœ¨æç«¯æƒ…å†µä¸‹ä»å¯èƒ½å¯¼è‡´æ¬¡ä¼˜è§£ã€‚
- **ä¾èµ–è‰¯å¥½åˆå§‹åˆ†å¸ƒ**ï¼šè‹¥SFTé˜¶æ®µæœªèƒ½æŒæ¡åŸºæœ¬æ±‚è§£æ¨¡å¼ï¼Œåç»­BOPOå’Œrepairéš¾ä»¥å¼¥è¡¥ã€‚
- **æ–‡æ³•è®¾è®¡éœ€äººå·¥å‚ä¸**ï¼šæ¯ä¸ªæ–°é—®é¢˜éœ€è¦å®šåˆ¶CFGï¼Œè™½æ¨¡å—åŒ–ä½†ä¸å¤Ÿå…¨è‡ªåŠ¨ã€‚
- **æœªå¤„ç†åŠ¨æ€æˆ–éšæœºCOé—®é¢˜**ï¼šç›®å‰å‡è®¾é—®é¢˜æ˜¯é™æ€ç¡®å®šæ€§çš„ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°†FALCONæ‰©å±•è‡³**éšæœºè§„åˆ’**ï¼ˆStochastic Programmingï¼‰å’Œ**åœ¨çº¿ä¼˜åŒ–**ï¼ˆOnline Optimizationï¼‰åœºæ™¯ã€‚
- æ¢ç´¢**è‡ªåŠ¨æ–‡æ³•ç”Ÿæˆ**æŠ€æœ¯ï¼Œé™ä½äººå·¥è®¾è®¡æˆæœ¬ã€‚
- ç»“åˆ**å½¢å¼éªŒè¯å·¥å…·**å¯¹ä¿®å¤è¿‡ç¨‹è¿›è¡Œç«¯åˆ°ç«¯éªŒè¯ã€‚
- ç ”ç©¶**å¤šç›®æ ‡ä¼˜åŒ–ä¸‹çš„åå¥½å»ºæ¨¡**ï¼Œæ”¯æŒParetoå‰æ²¿æ¢ç´¢ã€‚
- æ¢ç´¢å°†FALCONåº”ç”¨äºå·¥ä¸šçº§çœŸå®ä¸–ç•ŒCOç³»ç»Ÿï¼ˆå¦‚åŸå¸‚äº¤é€šè°ƒåº¦ã€èŠ¯ç‰‡å¸ƒçº¿ç­‰ï¼‰ã€‚

---

> **ä¸€å¥è¯æ€»ç»“**ï¼šFALCONé¦–æ¬¡å®ç°äº†LLM-basedç»„åˆä¼˜åŒ–çš„**100%å¯è¡Œæ€§ä¿è¯**ï¼Œé€šè¿‡â€œè¯­æ³•çº¦æŸ+è¯­ä¹‰ä¿®å¤+è‡ªé€‚åº”é‡‡æ ·â€ä¸‰å±‚æœºåˆ¶ï¼Œåœ¨ä¿æŒé«˜è§£è´¨é‡çš„åŒæ—¶ï¼Œä¸ºLLMèµ°å‘ç°å®ä¸–ç•Œé«˜å¯é æ€§åº”ç”¨é“ºå¹³äº†é“è·¯ã€‚

</details>

---

### 8. [LRAgent: Efficient KV Cache Sharing for Multi-LoRA LLM Agents](https://arxiv.org/abs/2602.01053)

**Authors**: Hyesung Jeon, Hyeongju Ha, Jae-Joon Kim  
**Category**: cs.LG  
**Published**: 2026-02-03  
**Score**: 11.5  
**Type**: new  
**ArXiv ID**: 2602.01053v1  

#### Abstract
Role specialization in multi-LLM agent systems is often realized via multi-LoRA, where agents share a pretrained backbone and differ only through lightweight adapters. Despite sharing base model weights, each agent independently builds and stores its own KV cache for the same long, tool-augmented tr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLRAgent: Efficient KV Cache Sharing for Multi-LoRA LLM Agents

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨å¤š **LLM Agent** ç³»ç»Ÿä¸­ï¼Œè§’è‰²ä¸“ä¸šåŒ–é€šå¸¸é€šè¿‡ **multi-LoRA** å®ç°ï¼Œå³å¤šä¸ªä»£ç†å…±äº«ä¸€ä¸ªé¢„è®­ç»ƒä¸»å¹²æ¨¡å‹ï¼Œå¹¶é€šè¿‡è½»é‡çº§é€‚é…å™¨ï¼ˆLoRAï¼‰å®ç°è§’è‰²å·®å¼‚åŒ–ã€‚ç„¶è€Œï¼Œå°½ç®¡å…±äº«äº†ä¸»å¹²æƒé‡ï¼Œæ¯ä¸ªä»£ç†ä»éœ€ç‹¬ç«‹æ„å»ºå’Œå­˜å‚¨å…¶ **KV Cache**ï¼Œå¯¼è‡´åœ¨é•¿è½¨è¿¹ï¼ˆlong trajectoriesï¼‰åœºæ™¯ä¸‹äº§ç”Ÿæ˜¾è‘—çš„å†…å­˜å’Œè®¡ç®—å¼€é”€ã€‚

ç°æœ‰ **KV Cache å…±äº«** æ–¹æ³•å¤§å¤šå¿½ç•¥äº† multi-LoRA æ¶æ„çš„ç‰¹æ€§ï¼Œæœªèƒ½æœ‰æ•ˆåˆ©ç”¨å…¶æ½œåœ¨çš„å…±äº«æœºä¼šã€‚

### æå‡ºçš„æ–°æ–¹æ³•å’Œæ–°æ€è·¯
æœ¬æ–‡æå‡ºäº† **LRAgent**ï¼Œä¸€ç§ä¸“ä¸º multi-LoRA ä»£ç†ç³»ç»Ÿè®¾è®¡çš„é«˜æ•ˆ KV Cache å…±äº«æ¡†æ¶ã€‚å…¶æ ¸å¿ƒæ€æƒ³åŸºäºä»¥ä¸‹å…³é”®è§‚å¯Ÿï¼š

> åœ¨ç›¸åŒä¸Šä¸‹æ–‡ä¸‹ï¼Œä¸åŒä»£ç†ä¹‹é—´çš„ KV Cache å·®å¼‚ä¸»è¦ç”± **LoRA é€‚é…å™¨è¾“å‡º** å¼•èµ·ï¼Œè€Œæ¥è‡ªå…±äº«é¢„è®­ç»ƒä¸»å¹²çš„æ¿€æ´»åˆ™é«˜åº¦ç›¸ä¼¼ã€‚

åŸºäºæ­¤ï¼ŒLRAgent å°† KV Cache åˆ†è§£ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼š
1.  **Base Cache**ï¼šç”±é¢„è®­ç»ƒä¸»å¹²æƒé‡ï¼ˆ`Wâ‚€`ï¼‰ç”Ÿæˆï¼Œå¯åœ¨æ‰€æœ‰ä»£ç†é—´**å…±äº«**ã€‚
2.  **Adapter Output (LR Cache)**ï¼šç”± LoRA æƒé‡ï¼ˆ`Î”W = AB`ï¼‰ç”Ÿæˆï¼Œå…·æœ‰**ä½ç§©**ï¼ˆlow-rankï¼‰ç‰¹æ€§ã€‚

å…·ä½“æ–¹æ¡ˆåŒ…æ‹¬ï¼š
- **BaseShared**ï¼šä»…å…±äº« `Base Cache`ï¼Œå¹¶ä»¥ä½ç§©å½¢å¼ï¼ˆå³ä¸­é—´æ¿€æ´» `XA`ï¼‰å­˜å‚¨æ¯ä¸ªä»£ç†çš„ `LR Cache`ï¼Œé¿å…äº†å…¨ç»´åº¦å­˜å‚¨ã€‚
- **BaseLRShared**ï¼šè¿›ä¸€æ­¥åˆ©ç”¨ **shared-A multi-LoRA** æ¶æ„ï¼ˆå³æ‰€æœ‰ä»»åŠ¡å…±äº«åŒä¸€ä¸ª `A` çŸ©é˜µï¼‰ï¼Œä½¿å¾— `LR Cache` æœ¬èº«ä¹Ÿå¯ä»¥è¢«æ‰€æœ‰ä»£ç†å…±äº«ï¼Œä»è€Œå®ç°äº† `Base Cache` å’Œ `LR Cache` çš„åŒé‡å…±äº«ã€‚

ä¸ºäº†é™ä½è¿è¡Œæ—¶é‡æ„ `Adapter Output` çš„å¼€é”€ï¼Œä½œè€…è®¾è®¡äº† **Flash-LoRA-Attention** å†…æ ¸ã€‚è¯¥å†…æ ¸é€šè¿‡é‡æ–°æ’åºæ³¨æ„åŠ›è®¡ç®—ï¼Œå°† `(PV_lr)B` æ›¿ä»£ `P(V_lrB)`ï¼Œé¿å…äº†å°†ä½ç§©ç¼“å­˜æ˜¾å¼åœ°æ‰©å±•åˆ°å…¨ç»´åº¦ï¼Œä»è€Œå°†è®¡ç®—å¼€é”€ä» `O(L * d_out)` é™ä½åˆ° `O(L * r)`ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´é«˜çš„æ•ˆç‡**ï¼šç›¸æ¯”éå…±äº«æ–¹æ¡ˆï¼Œæ˜¾è‘—é™ä½äº†å†…å­˜å ç”¨å’Œæ¨ç†å»¶è¿Ÿã€‚
- **æ›´å¥½çš„å‡†ç¡®æ€§**ï¼šç›¸æ¯”ç›´æ¥å…±äº«æ•´ä¸ª KV Cache æˆ–é€‰æ‹©æ€§é‡è®¡ç®—çš„æ–¹æ³•ï¼ˆå¦‚ DroidSpeakï¼‰ï¼ŒLRAgent æ›´å¥½åœ°ä¿ç•™äº†ç”± LoRA é€‚é…å™¨å¸¦æ¥çš„å…³é”®è§’è‰²ç‰¹å®šä¿¡æ¯ï¼Œå› æ­¤å‡†ç¡®ç‡ä¸‹é™æ›´å°ã€‚
- **æ¶æ„å…¼å®¹æ€§**ï¼šæ˜¯é¦–ä¸ªä¸“é—¨ä¸º multi-LoRA æ¶æ„è®¾è®¡çš„ KV Cache å…±äº«æ–¹æ¡ˆï¼Œèƒ½ä¸ç°æœ‰çš„ PEFT æŠ€æœ¯æ— ç¼é›†æˆã€‚

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **HotpotQA**ï¼šä¸€ä¸ªå¤šè·³é—®ç­”æ•°æ®é›†ï¼Œéœ€è¦å¤–éƒ¨çŸ¥è¯†å’Œå¤šæ­¥æ¨ç†ã€‚
- **ScienceQA**ï¼šä¸€ä¸ªç§‘å­¦é¢†åŸŸçš„å¤šæ¨¡æ€é—®ç­”æ•°æ®é›†ï¼ŒåŒæ ·éœ€è¦å¤šæ­¥æ¨ç†ã€‚
- å®éªŒä½¿ç”¨äº† 2.5k HotpotQA å’Œ 2.0k ScienceQA çš„æµ‹è¯•é›†ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹**ï¼šåœ¨ `LLaMA-3.1-8B-Instruct` å’Œ `Ministral-8B-Instruct` ä¸Šè¿›è¡Œå¾®è°ƒå’Œè¯„ä¼°ã€‚
- **ä»£ç†è§’è‰²**ï¼šéµå¾ª AutoAct è®¾ç½®ï¼Œå®šä¹‰äº†ä¸‰ç§è§’è‰²ï¼š
  - **Plan Agent**ï¼šè´Ÿè´£æ¨ç†å’Œé€‰æ‹©å·¥å…·ã€‚
  - **Action Agent**ï¼šè´Ÿè´£æ‰§è¡Œå·¥å…·è°ƒç”¨ã€‚
  - **Reflect Agent**ï¼šè´Ÿè´£å®¡æŸ¥å’Œå†³å®šæ˜¯å¦ç»ˆæ­¢ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Benchmark Accuracy (%)**ï¼šåœ¨ HotpotQA å’Œ ScienceQA ä¸Šçš„æœ€ç»ˆç­”æ¡ˆå‡†ç¡®ç‡ã€‚
  - **System Throughput (tokens/s)**ï¼šç³»ç»Ÿæ€»å¤„ç†åºåˆ—é•¿åº¦é™¤ä»¥ç«¯åˆ°ç«¯å»¶è¿Ÿã€‚
  - **Time-to-First-Token (TTFT)**ï¼šæ‰€æœ‰ä»£ç†æ­¥éª¤çš„ Prefill å»¶è¿Ÿä¹‹å’Œã€‚
  - **Memory Usage (GB)**ï¼šå³°å€¼å†…å­˜æ¶ˆè€—ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Non-Shared**ï¼šé»˜è®¤åŸºçº¿ï¼Œæ¯ä¸ªä»£ç†ç»´æŠ¤è‡ªå·±çš„å®Œæ•´ KV Cacheã€‚
- **FullShared**ï¼šæœ€ç†æƒ³çš„å…±äº«åŸºçº¿ï¼Œæ‰€æœ‰ä»£ç†å®Œå…¨å…±äº«æ•´ä¸ª KV Cacheï¼ˆæ— é‡è®¡ç®—ï¼‰ã€‚
- **DroidSpeak**ï¼šä¸€ç§é€‰æ‹©æ€§é‡è®¡ç®—æ–¹æ³•ï¼Œå¯¹æ¨¡å‹ä¸­æœ€æ•æ„Ÿçš„ 33% å±‚è¿›è¡Œé‡è®¡ç®—ã€‚

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”
1.  **å‡†ç¡®æ€§ (Accuracy)**ï¼š
    - **BaseShared** å’Œ **BaseLRShared** çš„å‡†ç¡®ç‡éå¸¸æ¥è¿‘ `Non-Shared` åŸºçº¿ã€‚
    - åœ¨ `LLaMA-3.1-8B` ä¸Šï¼Œ`BaseShared` çš„å¹³å‡å‡†ç¡®ç‡æŸå¤±ä»…ä¸º **-0.28%**ï¼Œ`BaseLRShared` ä¸º **-0.97%**ã€‚
    - ç›¸æ¯”ä¹‹ä¸‹ï¼Œ`FullShared` å’Œ `DroidSpeak` çš„å‡†ç¡®ç‡æŸå¤±æ›´å¤§ï¼Œåˆ†åˆ«è¾¾åˆ° **-2.48%** å’Œ **-2.12%**ã€‚
    - è¿™è¡¨æ˜ LRAgent èƒ½åœ¨å…±äº«çš„åŒæ—¶æ›´å¥½åœ°ä¿ç•™è§’è‰²ç‰¹å®šè¡Œä¸ºã€‚

2.  **ååé‡ (Throughput)**ï¼š
    - `BaseLRShared` çš„ååé‡è¡¨ç°æœ€ä½³ï¼Œæ¥è¿‘ `FullShared` çš„ä¸Šé™ã€‚
    - åœ¨æœ€é•¿åºåˆ—ï¼ˆ66.4k tokensï¼‰ä¸Šï¼Œ`BaseLRShared` è¾¾åˆ°äº† `Non-Shared` çš„ **2.46å€** ååé‡å¢ç›Šã€‚
    - `BaseShared` ä¹Ÿè¾¾åˆ°äº† **1.42å€** çš„å¢ç›Šã€‚
    - `DroidSpeak` çš„å¢ç›Šçº¦ä¸º **1.36å€**ï¼Œä¸ `BaseShared` ç›¸å½“ã€‚

3.  **é¦–ä»¤ç‰Œå»¶è¿Ÿ (TTFT)**ï¼š
    - `BaseLRShared` åœ¨å‡å°‘ TTFT æ–¹é¢æ•ˆæœæœ€ä¸ºæ˜¾è‘—ï¼Œæœ€é«˜å¯å®ç° **4.44å€** çš„é™ä½ï¼Œå‡ ä¹ä¸ `FullShared` æŒå¹³ã€‚
    - `BaseShared` æœ€é«˜å¯å®ç° **1.63å€** çš„é™ä½ã€‚

4.  **å†…å­˜ä½¿ç”¨ (Memory Usage)**ï¼š
    - `BaseShared` å’Œ `BaseLRShared` å°† KV Cache å†…å­˜å‡å°‘äº†è¿‘ **1/3**ï¼Œä¸ `FullShared` å’Œ `DroidSpeak` å¤„äºåŒä¸€æ°´å¹³ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **Rank Ablation**ï¼šå®éªŒäº†ä¸åŒçš„ LoRA ç§©ï¼ˆr=4, 8, 16, 32ï¼‰ã€‚ç»“æœæ˜¾ç¤ºï¼Œåœ¨ `r=8` æ—¶å·²èƒ½è¾¾åˆ°è¾ƒå¥½çš„æ€§èƒ½ï¼Œæ›´é«˜çš„ç§©å¹¶æœªå¸¦æ¥æ˜æ˜¾æå‡ï¼Œå› æ­¤é€‰æ‹© `r=8` ä½œä¸ºå¹³è¡¡ç‚¹ã€‚
- **LoRA åº”ç”¨ä½ç½®**ï¼šæ¯”è¾ƒäº†ä»…åœ¨ `qv`ï¼ˆquery, valueï¼‰æŠ•å½±ä¸Šåº”ç”¨ LoRA ä¸åœ¨ `qkvo`ï¼ˆquery, key, value, outputï¼‰ä¸Šåº”ç”¨çš„å˜ä½“ã€‚ç»“æœè¡¨æ˜ï¼Œ`qv` è®¾ç½®åœ¨å‡†ç¡®ç‡å’Œæ•ˆç‡ä¸Šéƒ½æ›´å…·ä¼˜åŠ¿ï¼Œè¿™ä¹Ÿæ˜¯æœ¬æ–‡é‡‡ç”¨çš„è®¾ç½®ã€‚

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1.  **åˆ†è§£å¼å…±äº«ä¼˜äºå…¨é‡å…±äº«**ï¼šç›´æ¥å…±äº«å®Œæ•´çš„ KV Cache (`FullShared`) ä¼šå› å¿½ç•¥ LoRA é€‚é…å™¨çš„å·®å¼‚è€Œå¯¼è‡´æ˜¾è‘—çš„å‡†ç¡®ç‡ä¸‹é™ã€‚LRAgent é€šè¿‡åˆ†ç¦» `Base Cache` å’Œ `LR Cache`ï¼Œå®ç°äº†â€œç²¾å‡†å…±äº«â€ï¼Œåœ¨ä¿è¯æ•ˆç‡çš„åŒæ—¶æœ€å¤§é™åº¦åœ°ä¿ç•™äº†æ¨¡å‹æ€§èƒ½ã€‚
2.  **ä½ç§©ç‰¹æ€§æ˜¯å…³é”®**ï¼šåˆ©ç”¨ LoRA é€‚é…å™¨è¾“å‡ºå›ºæœ‰çš„ä½ç§©ç‰¹æ€§æ¥å‹ç¼©å­˜å‚¨å’Œä¼˜åŒ–è®¡ç®—ï¼Œæ˜¯å®ç°é«˜æ•ˆæ€§çš„æ ¸å¿ƒæŠ€æœ¯ã€‚
3.  **shared-A æ¶æ„æ½œåŠ›å·¨å¤§**ï¼š`BaseLRShared` è¯æ˜äº†å½“ multi-LoRA ç³»ç»Ÿé‡‡ç”¨ shared-A è®¾è®¡æ—¶ï¼Œå¯ä»¥å®ç° KV Cache å’Œ LR Cache çš„åŒé‡å…±äº«ï¼Œä»è€Œåœ¨è®¡ç®—æ•ˆç‡ä¸Šå–å¾—è´¨çš„é£è·ƒï¼Œå…¶ TTFT å‡ ä¹ä¸ç†è®ºæœ€ä¼˜çš„ `FullShared` ç›¸å½“ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ– shared-A æ¶æ„**ï¼š`BaseLRShared` çš„æœ€å¤§ä¼˜åŠ¿ä¾èµ–äº multi-LoRA ç³»ç»Ÿé‡‡ç”¨äº† shared-A çš„è®­ç»ƒæ–¹å¼ï¼Œè¿™å¯èƒ½ä¸é€‚ç”¨äºæ‰€æœ‰åœºæ™¯ã€‚
- **é¢å¤–çš„è®¡ç®—å¼€é”€**ï¼šè™½ç„¶ `Flash-LoRA-Attention` æå¤§é™ä½äº†å¼€é”€ï¼Œä½†è¿è¡Œæ—¶é‡æ„ `Adapter Output` ä»ç„¶å¼•å…¥äº†é¢å¤–çš„è®¡ç®—ï¼Œå°¤å…¶æ˜¯åœ¨ç”Ÿæˆé˜¶æ®µã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´é«˜æ•ˆçš„ä½ç§©ç¼“å­˜ç®¡ç†ç­–ç•¥ã€‚
- å°† LRAgent çš„æ€æƒ³æ‰©å±•åˆ°å…¶ä»–å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æ–¹æ³•ï¼Œå¦‚ AdaLoRA æˆ– PiSSAã€‚
- ç ”ç©¶å¦‚ä½•åœ¨ä¸ç‰ºç‰²å‡†ç¡®ç‡çš„å‰æä¸‹ï¼Œè¿›ä¸€æ­¥ç®€åŒ–æˆ–è‡ªåŠ¨åŒ– `shared-A` çš„è®­ç»ƒè¿‡ç¨‹ã€‚

</details>

---

### 9. [SNIP: An Adaptive Mixed Precision Framework for Subbyte Large Language Model Training](https://arxiv.org/abs/2602.01410)

**Authors**: Yunjie Pan, Yongyi Yang, Hanmei Yang, Scott Mahlke  
**Category**: cs.LG  
**Published**: 2026-02-03  
**Score**: 11.5  
**Type**: new  
**ArXiv ID**: 2602.01410v1  

#### Abstract
Training large language models (LLMs) efficiently while preserving model quality poses significant challenges, particularly with subbyte precision supported by state-of-the-art GPUs. Current mixed-precision training approaches either apply uniform precision to all GEMM operations or rely on heuristi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSNIP: An Adaptive Mixed Precision Framework for Subbyte Large Language Model Training

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰çš„å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è®­ç»ƒä¾èµ– **Mixed Precision Training**ï¼ˆå¦‚ FP8ã€FP4ï¼‰æ¥é™ä½è®¡ç®—æˆæœ¬ï¼Œä½†ä¸»æµæ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **Uniform Precision**ï¼šå¯¹æ‰€æœ‰å±‚é‡‡ç”¨ç›¸åŒç²¾åº¦ï¼ˆå¦‚å…¨ç”¨ FP8 æˆ– FP4ï¼‰ï¼Œå¿½ç•¥äº†ä¸åŒå±‚å¯¹ç²¾åº¦çš„æ•æ„Ÿæ€§å·®å¼‚ï¼Œå¯¼è‡´æ•ˆç‡æœªè¾¾æœ€ä¼˜ã€‚
- **Heuristic-based æ–¹æ³•**ï¼šåŸºäºå±€éƒ¨æŒ‡æ ‡ï¼ˆå¦‚ KL æ•£åº¦ã€ç»å¯¹è¯¯å·®ï¼‰é€‰æ‹©ç²¾åº¦ï¼Œæ— æ³•æ•æ‰è®­ç»ƒè¿‡ç¨‹ä¸­çš„å…¨å±€åŠ¨æ€ï¼ˆå¦‚æ¢¯åº¦ä¼ æ’­ã€æƒé‡æ›´æ–°åå·®ï¼‰ï¼Œå®¹æ˜“å¯¼è‡´æ”¶æ•›ä¸ç¨³å®šæˆ–è´¨é‡ä¸‹é™ã€‚
- **ç¼ºä¹ç³»ç»Ÿæ€§ä¼˜åŒ–**ï¼šç¼ºå°‘ä¸€ä¸ªèƒ½è”åˆè€ƒè™‘å‰å‘å’Œåå‘ä¼ æ’­ä¸­é‡åŒ–å½±å“ï¼Œå¹¶åœ¨æ»¡è¶³æ•ˆç‡ç›®æ ‡ä¸‹æœ€å°åŒ–è´¨é‡æŸå¤±çš„æ¡†æ¶ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡º **SNIP**ï¼ˆ**S**ystematic **N**eural **I**nteger-programming-based **P**recision selectionï¼‰ï¼Œä¸€ç§é¢å‘ LLM é¢„è®­ç»ƒçš„ç»†ç²’åº¦è‡ªé€‚åº”æ··åˆç²¾åº¦æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **åŒç»´åº¦è´¨é‡æŸå¤±åº¦é‡**ï¼š
  - **Loss Divergence**ï¼šè¡¡é‡å‰å‘ä¼ æ’­ä¸­å› é‡åŒ–å¯¼è‡´çš„è®­ç»ƒæŸå¤±å¢åŠ ã€‚
  - **Weight Divergence**ï¼šè¡¡é‡åå‘ä¼ æ’­ä¸­å› æ¢¯åº¦é‡åŒ–è¯¯å·®ç´¯ç§¯å¯¼è‡´çš„æƒé‡æ›´æ–°åå·®ã€‚
  è¿™ä¸¤ä¸ªæŒ‡æ ‡å…±åŒé‡åŒ–äº†é‡åŒ–å¯¹è®­ç»ƒç¨³å®šæ€§å’Œæœ€ç»ˆæ¨¡å‹è´¨é‡çš„å½±å“ã€‚

- **åŸºäº ILP çš„å…¨å±€ä¼˜åŒ–ç­–ç•¥**ï¼š
  å°†æ¯å±‚çš„ç²¾åº¦é€‰æ‹©å»ºæ¨¡ä¸ºä¸€ä¸ª **Integer Linear Programming**ï¼ˆILPï¼‰é—®é¢˜ï¼š
  - **ç›®æ ‡å‡½æ•°**ï¼šæœ€å°åŒ–æ€»è´¨é‡æŸå¤±ï¼ˆåŠ æƒçš„ Loss Divergence å’Œ Weight Divergenceï¼‰ã€‚
  - **çº¦æŸæ¡ä»¶**ï¼šæ»¡è¶³ç»™å®šçš„æ•ˆç‡ç›®æ ‡ï¼ˆå¦‚ FP4 FLOPs å æ¯”ï¼‰ã€‚
  è¯¥æ–¹æ³•å®ç°äº†å…¨å±€æœ€ä¼˜çš„å±‚é—´ç²¾åº¦åˆ†é…ï¼Œè€Œéå±€éƒ¨å¯å‘å¼å†³ç­–ã€‚

- **å®ç”¨çš„å¼‚æ­¥é›†æˆç³»ç»Ÿ**ï¼š
  SNIP åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å‘¨æœŸæ€§åœ°æ”¶é›†ç»Ÿè®¡ä¿¡æ¯ã€åˆ†æå‘æ•£åº¦ã€æ±‚è§£ ILP å¹¶æ›´æ–°ç²¾åº¦ç­–ç•¥ï¼Œæ•´ä¸ªè¿‡ç¨‹å¼‚æ­¥è¿›è¡Œï¼Œä¸ä¸­æ–­ä¸»è®­ç»ƒæµç¨‹ï¼Œå…·å¤‡è‰¯å¥½çš„å·¥ç¨‹å¯é›†æˆæ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´ä¼˜çš„ Pareto å‰æ²¿**ï¼šåœ¨ä¿æŒæ¥è¿‘ BF16 æ¨¡å‹å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œå®ç°é«˜è¾¾ 80% çš„ FLOPs èŠ‚çœï¼Œæ˜¾è‘—ä¼˜äºå‡åŒ€ç²¾åº¦å’Œå„ç±»å¯å‘å¼æ–¹æ³•ã€‚
- **æ›´å¼ºçš„ç¨³å®šæ€§**ï¼šé€šè¿‡åŒæ—¶è€ƒè™‘å‰å‘å’Œåå‘çš„é‡åŒ–å½±å“ï¼Œé¿å…äº†ä»…å…³æ³¨å±€éƒ¨è¯¯å·®å¯¼è‡´çš„è®­ç»ƒå´©æºƒã€‚
- **æ›´é«˜çš„é€šç”¨æ€§å’Œé€‚åº”æ€§**ï¼šæ”¯æŒä¸åŒæ¨¡å‹å¤§å°ï¼ˆ1B åˆ° 70Bï¼‰ã€ä¸åŒè®­ç»ƒé˜¶æ®µï¼Œå¹¶å¯æ‰©å±•è‡³æ–°çš„é‡åŒ–æ ¼å¼ï¼ˆå¦‚ FP4ã€FP8ï¼‰ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
- **TinyLlama 1B**ï¼šä½¿ç”¨ SlimPajama å’Œ StarcoderData æ•°æ®é›†çš„çº¦ 1% å­é›†ã€‚
- **OpenLlama 3B / 7B**ï¼šä½¿ç”¨ RedPajama æ•°æ®é›†çš„çº¦ 1% å­é›†ã€‚
- **70B LLaMA-style æ¨¡å‹**ï¼šä½¿ç”¨å†…éƒ¨å·¥ä¸šæ•°æ®é›†ã€‚

> æ³¨ï¼šç”±äºå®éªŒåŸºäºä¸­é—´æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒï¼Œå› æ­¤ä½¿ç”¨åŸå§‹æ•°æ®é›†çš„å°æ¯”ä¾‹é‡‡æ ·å³å¯ä¿è¯è®­ç»ƒæ•ˆæœã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹**ï¼šTinyLlama 1Bã€OpenLlama 3Bã€OpenLlama 7B å’Œä¸€ä¸ª 70B çš„ LLaMA é£æ ¼ç¨ å¯†æ¨¡å‹ã€‚
- **é‡åŒ–æ¨¡æ‹Ÿ**ï¼šç”±äºç¼ºä¹åŸç”Ÿæ”¯æŒ FP4/FP8 çš„ç¡¬ä»¶ï¼Œé‡‡ç”¨ **fake quantization** æ¨¡æ‹Ÿï¼Œæ”¯æŒ FP4 (E2M1) å’Œ FP8 (E4M3) æ ¼å¼ã€‚
- **é‡åŒ–ç²’åº¦**ï¼šè¾“å…¥æ¿€æ´»å’Œæ¢¯åº¦é‡‡ç”¨ 1x128 **tilewise** é‡åŒ–ï¼Œæƒé‡é‡‡ç”¨ 128x128 **blockwise** é‡åŒ–ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **æ•ˆç‡**ï¼šFP4 FLOPs å æ¯”ï¼ˆä½œä¸ºç«¯åˆ°ç«¯åŠ é€Ÿçš„ä»£ç†æŒ‡æ ‡ï¼‰ã€‚
  - **å‡†ç¡®æ€§**ï¼šä½¿ç”¨ `lm-evaluation-harness` æµ‹è¯•å¤šä¸ªåŸºå‡†ï¼š
    - **å¸¸è¯†æ¨ç†**ï¼šARC-c, ARC-e
    - **ç»¼åˆèƒ½åŠ›**ï¼šMMLU
    - **å¸¸è¯†ç†è§£**ï¼šBoolQ, HellaSwag, OBQA, PIQA, WinoGrande
  - **è®­ç»ƒç¨³å®šæ€§**ï¼šè®­ç»ƒæŸå¤±æ›²çº¿ã€ç›¸å¯¹æŸå¤±å·®ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Uniform Precision**ï¼šBF16ã€FP8ã€FP4ã€‚
- **Empirical Coarse-grained**ï¼š
  - `E-layer-id`ï¼šå¤´å°¾å±‚ç”¨é«˜ç²¾åº¦ï¼ˆFP8ï¼‰ï¼Œä¸­é—´å±‚ç”¨ä½ç²¾åº¦ï¼ˆFP4ï¼‰ã€‚
  - `E-layer-type`ï¼šæ•æ„Ÿå±‚ç±»å‹ï¼ˆå¦‚ MLP ä¸­çš„ Gate/Up å±‚ï¼‰ç”¨ FP8ï¼Œå…¶ä½™ç”¨ FP4ã€‚
- **Fine-grained Heuristic**ï¼š
  - `min-abs-err`ï¼šé€‰æ‹©ä½¿ç»å¯¹é‡åŒ–è¯¯å·®æœ€å°çš„å±‚ç”¨ FP4ã€‚
  - `min-rel-err`ï¼šé€‰æ‹©ä½¿ç›¸å¯¹é‡åŒ–è¯¯å·®æœ€å°çš„å±‚ç”¨ FP4ã€‚
- **Random**ï¼šéšæœºåˆ†é… FP4/FP8ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- åœ¨ **TinyLlama 1B** ä¸Šï¼ŒSNIP åœ¨ **80% FP4 FLOPs** çš„æ•ˆç‡é¢„ç®—ä¸‹ï¼Œå¹³å‡æµ‹è¯•å‡†ç¡®ç‡ä»èƒ½è¾¾åˆ° **44.27**ï¼Œå‡ ä¹ä¸ BF16 åŸºçº¿ï¼ˆ44.22ï¼‰æŒå¹³ã€‚
- åœ¨ **70B æ¨¡å‹** ä¸Šï¼ŒSNIP åœ¨ 50% FP4 FLOPs ä¸‹ï¼Œç›¸å¯¹ BF16 çš„è®­ç»ƒæŸå¤±å·®æå°ï¼Œä¸”åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¡¨ç°ç¨³å®šï¼Œè€Œ FP4 å…¨é‡è®­ç»ƒåˆ™å‡ºç°æ˜æ˜¾å‘æ•£ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **å…¨é¢è¶…è¶Šå¯å‘å¼æ–¹æ³•**ï¼š
  - åœ¨ **Table 1** ä¸­ï¼ŒSNIP åœ¨æ‰€æœ‰ FP4 FLOPs æ¯”ä¾‹ï¼ˆ25%, 50%, 75%ï¼‰ä¸‹å‡å–å¾—æœ€é«˜å¹³å‡åˆ†ï¼Œæ˜¾è‘—ä¼˜äº `min-abs-err`ã€`min-rel-err` åŠå„ç±»éšæœºæ–¹æ³•ã€‚
  - ä¾‹å¦‚ï¼Œåœ¨ 75% FP4 FLOPs æ—¶ï¼ŒSNIP å¹³å‡åˆ†ä¸º 44.21ï¼Œè€Œ `min-abs-err` ä»…ä¸º 33.53ã€‚
- **ä¼˜äºç»éªŒæ€§ç²—ç²’åº¦æ–¹æ³•**ï¼š
  - `E-layer-id` å’Œ `E-layer-type` åœ¨ä½æ•ˆç‡é¢„ç®—ä¸‹å°šå¯ï¼Œä½†åœ¨é«˜é¢„ç®—ï¼ˆå¦‚ 50%ï¼‰ä¸‹æ€§èƒ½è¿…é€Ÿä¸‹é™ï¼Œè€Œ SNIP ä»èƒ½ä¿æŒé«˜è´¨é‡ã€‚
- **è®­ç»ƒç¨³å®šæ€§æœ€ä½³**ï¼š
  - **Figure 8** æ˜¾ç¤ºï¼Œåœ¨ 75% FP4 FLOPs ä¸‹ï¼ŒSNIP çš„è®­ç»ƒæŸå¤±æ›²çº¿ä¸ BF16 å‡ ä¹é‡åˆï¼Œè€Œå…¶ä»–æ–¹æ³•ï¼ˆå¦‚ `random`ï¼‰è¿…é€Ÿå‘æ•£ã€‚
  - **Figure 9** æ˜¾ç¤ºï¼Œ70B æ¨¡å‹ä¸Š SNIP çš„ç›¸å¯¹æŸå¤±å·®è¿œä½äºå…¶ä»–æ–¹æ³•ï¼Œè¯æ˜å…¶åœ¨å¤§æ¨¡å‹ä¸Šçš„ç¨³å®šæ€§ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **è´¨é‡æŸå¤±åº¦é‡çš„æœ‰æ•ˆæ€§éªŒè¯**ï¼š
  - **Figure 13** æ˜¾ç¤ºï¼ŒSNIP ä¼°è®¡çš„æ¯å±‚é‡åŒ–æŸå¤±ä¸çœŸå®æµ‹é‡å€¼é«˜åº¦ä¸€è‡´ï¼Œè¯æ˜äº†å…¶è¯¯å·®ä¼ æ’­ä¼°è®¡æ–¹æ³•çš„å¯é æ€§ã€‚
- **åŠ¨æ€è°ƒæ•´çš„å¿…è¦æ€§**ï¼š
  - **Figure 11** æ˜¾ç¤ºï¼ŒSNIP åœ¨ä¸åŒè®­ç»ƒé˜¶æ®µï¼ˆ5k åˆ° 240k æ­¥ï¼‰ä¼šé€‰æ‹©ä¸åŒçš„å±‚ä½¿ç”¨é«˜ç²¾åº¦ï¼Œè¡¨æ˜å±‚çš„é‡è¦æ€§æ˜¯åŠ¨æ€å˜åŒ–çš„ï¼Œé™æ€ç­–ç•¥æ¬¡ä¼˜ã€‚
- **Pipeline Parallelism é›†æˆæ•ˆæœ**ï¼š
  - **Figure 12** å±•ç¤ºäº† SNIP åœ¨æµæ°´çº¿å¹¶è¡Œä¸‹çš„æ—¶é—´çº¿ï¼Œè¯æ˜å…¶èƒ½æœ‰æ•ˆå¹³è¡¡å„é˜¶æ®µçš„è®¡ç®—è´Ÿè½½ï¼Œé¿å…ç“¶é¢ˆã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **é‡åŒ–å½±å“éœ€å…¨å±€å»ºæ¨¡**ï¼šä»…é å±€éƒ¨è¯¯å·®ï¼ˆå¦‚ abs/rel errorï¼‰æ— æ³•å‡†ç¡®é¢„æµ‹é‡åŒ–å¯¹ LLM è®­ç»ƒè´¨é‡çš„å½±å“ï¼Œå¿…é¡»è”åˆè€ƒè™‘å‰å‘çš„ **Loss Divergence** å’Œåå‘çš„ **Weight Divergence**ã€‚
2. **å±‚é—´æ•æ„Ÿæ€§å·®å¼‚æ˜¾è‘—**ï¼šä¸åŒå±‚ï¼ˆå°¤å…¶æ˜¯ MLP ä¸­çš„ Down å±‚ã€Attention ä¸­çš„ V å±‚ï¼‰å¯¹ä½ç²¾åº¦æ›´æ•æ„Ÿï¼Œéœ€è¦æ›´é«˜ç²¾åº¦ä¿æŠ¤ã€‚
3. **SNIP å®ç°é«˜æ•ˆä¸é«˜è´¨é‡çš„å¹³è¡¡**ï¼šé€šè¿‡ ILP ä¼˜åŒ–ï¼ŒSNIP èƒ½åœ¨é«˜è¾¾ 80% FP4 FLOPs çš„æƒ…å†µä¸‹ï¼Œå°†æ¨¡å‹è´¨é‡æŸå¤±é™è‡³æœ€ä½ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚
4. **æ–¹æ³•å…·æœ‰å¼ºé²æ£’æ€§å’Œå¯æ‰©å±•æ€§**ï¼šåœ¨ 1B åˆ° 70B ä¸åŒè§„æ¨¡æ¨¡å‹å’Œå¤šä¸ªè®­ç»ƒé˜¶æ®µä¸Šå‡è¡¨ç°å‡ºè‰²ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **è®¡ç®—å¼€é”€**ï¼šè™½ç„¶å¼‚æ­¥æ‰§è¡Œï¼Œä½†æ”¶é›†ç»Ÿè®¡å’Œæ±‚è§£ ILP ä»å¼•å…¥é¢å¤–å¼€é”€ï¼ˆçº¦æ¯ 100k æ­¥ä¸€æ¬¡ï¼Œè€—æ—¶ ~25 åˆ†é’Ÿï¼‰ã€‚
- **ä¾èµ–å‡é‡åŒ–æ¨¡æ‹Ÿ**ï¼šå®éªŒåŸºäºè½¯ä»¶æ¨¡æ‹Ÿï¼Œå®é™…ç¡¬ä»¶éƒ¨ç½²æ—¶å¯èƒ½å—ç‰¹å®šæ¶æ„é™åˆ¶ï¼ˆå¦‚å†…å­˜å¸¦å®½ã€ç¨€ç– GEMM æ”¯æŒï¼‰ã€‚
- **æœªç›´æ¥ä¼˜åŒ–ç«¯åˆ°ç«¯å»¶è¿Ÿ**ï¼šä»¥ FP4 FLOPs æ¯”ä¾‹ä½œä¸ºæ•ˆç‡æŒ‡æ ‡ï¼Œè€Œéå®æµ‹è®­ç»ƒæ—¶é—´ï¼Œæœªæ¥éœ€ç»“åˆçœŸå®ç¡¬ä»¶éªŒè¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **æ‰©å±•è‡³æ›´å¤šé‡åŒ–æ ¼å¼**ï¼šå°† INT4ã€INT8 ç­‰æ•´æ•°é‡åŒ–çº³å…¥ ILP é€‰é¡¹ã€‚
- **æ¢ç´¢åœ¨çº¿å­¦ä¹ æ›¿ä»£ ILP**ï¼šç ”ç©¶æ›´è½»é‡çº§çš„åœ¨çº¿ä¼˜åŒ–å™¨æ›¿ä»£è€—æ—¶çš„ ILP æ±‚è§£ã€‚
- **ç»“åˆé€šä¿¡ä¼˜åŒ–**ï¼šå°†ä½ç²¾åº¦æ‰©å±•è‡³ Reduce-Scatter ç­‰é€šä¿¡æ“ä½œï¼Œè¿›ä¸€æ­¥é™ä½é€šä¿¡å¼€é”€ã€‚
- **åº”ç”¨äºå¾®è°ƒå’Œå¤šæ¨¡æ€æ¨¡å‹**ï¼šéªŒè¯ SNIP åœ¨ PEFTï¼ˆå¦‚ LoRAï¼‰å’Œè§†è§‰-è¯­è¨€æ¨¡å‹ä¸­çš„æœ‰æ•ˆæ€§ã€‚

</details>

---

### 10. [Position: Agentic Evolution is the Path to Evolving LLMs](https://arxiv.org/abs/2602.00359)

**Authors**: Minhua Lin, Hanqing Lu, Zhan Shi, Bing He, Rui Mao, Zhiwei Zhang, Zongyu Wu, Xianfeng Tang, Hui Liu, Zhenwei Dai, Xiang Zhang, Suhang Wang, Benoit Dumoulin, Jian Pei  
**Category**: cs.AI  
**Published**: 2026-02-03  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2602.00359v1  

#### Abstract
As Large Language Models (LLMs) move from curated training sets into open-ended real-world environments, a fundamental limitation emerges: static training cannot keep pace with continual deployment environment change. Scaling training-time and inference-time compute improves static capability but do...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠPosition: Agentic Evolution is the Path to Evolving LLMsã€‹æ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰çš„ **Large Language Models (LLMs)** åœ¨ä»é™æ€è®­ç»ƒç¯å¢ƒéƒ¨ç½²åˆ°å¼€æ”¾ã€åŠ¨æ€çš„çœŸå®ä¸–ç•Œæ—¶é¢ä¸´ä¸€ä¸ªæ ¹æœ¬æ€§æŒ‘æˆ˜ï¼š**train-deploy gap**ï¼ˆè®­ç»ƒ-éƒ¨ç½²ç¯å¢ƒå·®å¼‚ï¼‰ã€‚  
- é™æ€æ¨¡å‹æ— æ³•åº”å¯¹æ— é™å¤šå˜çš„ç°å®åœºæ™¯ï¼ˆå¦‚APIå˜æ›´ã€æ ¼å¼è¿ç§»ã€éšç§çº¦æŸï¼‰ã€‚
- ç°æœ‰çš„é€‚åº”æ–¹æ³•ï¼ˆå¦‚åœ¨çº¿å¾®è°ƒæˆ–è®°å¿†ç§¯ç´¯ï¼‰å­˜åœ¨ä¸¥é‡ç¼ºé™·ï¼š
  - **Parametric Fine-tuning**ï¼šæ˜“å¯¼è‡´ **catastrophic forgetting**ï¼ˆç¾éš¾æ€§é—å¿˜ï¼‰ï¼Œä¸”æ›´æ–°ä¸é€æ˜ã€éš¾æ²»ç†ã€‚
  - **Heuristic Memory Accumulation**ï¼šå¯¼è‡´ **context saturation**ï¼ˆä¸Šä¸‹æ–‡é¥±å’Œï¼‰ï¼Œæ”¹è¿›æ”¶ç›Šé€’å‡ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æå‡º **Agentic Evolutionï¼ˆä»£ç†å¼è¿›åŒ–ï¼‰** èŒƒå¼ï¼Œå¹¶æ„å»ºé€šç”¨æ¡†æ¶ **A-Evolve**ã€‚

#### æ ¸å¿ƒæ€æƒ³
å°† LLM ç³»ç»Ÿçš„éƒ¨ç½²æœŸæ”¹è¿›è§†ä¸ºä¸€ä¸ªç”±â€œ**Evolver Agent**â€é©±åŠ¨çš„ã€ç›®æ ‡å¯¼å‘çš„ä¼˜åŒ–è¿‡ç¨‹ï¼Œè€Œéå›ºå®šæµæ°´çº¿ã€‚  
è¯¥ Evolver Agent æ˜¯ä¸€ä¸ªè‡ªä¸»å†³ç­–ä½“ï¼Œè´Ÿè´£ï¼š
- è¯Šæ–­å¤±è´¥åŸå› 
- å†³å®šä½•æ—¶æ›´æ–°
- ç”Ÿæˆå¯éªŒè¯çš„æ¨¡å—åŒ–æ”¹è¿›

#### ä¸‰å¤§åŸåˆ™ï¼ˆThree Principlesï¼‰
| åŸåˆ™ | è¯´æ˜ |
|------|------|
| **Goal-Oriented Principle** | æ˜ç¡®â€œ**what to change**â€ï¼šä¸»åŠ¨å½’å› å¤±è´¥ï¼Œå®šä½éœ€ä¿®æ”¹çš„å…·ä½“ç»„ä»¶ï¼ˆå¦‚å·¥å…·ã€schemaï¼‰ï¼Œå®ç°å› æœçº§ä¿®å¤ã€‚ |
| **Autonomy Principle** | æ˜ç¡®â€œ**when to change**â€ï¼šè‡ªä¸»åˆ¤æ–­æ˜¯å¦è§¦å‘æ›´æ–°ï¼Œé¿å…ç›²ç›®æˆ–é¢‘ç¹ä¿®æ”¹ï¼Œæå‡ç¨³å®šæ€§ã€‚ |
| **Compositional Principle** | æ˜ç¡®â€œ**how to change**â€ï¼šé€šè¿‡ç»“æ„åŒ–ã€æ¨¡å—åŒ–çš„ artifactï¼ˆå¦‚å·¥å…·ã€æµ‹è¯•ã€æŠ€èƒ½ï¼‰è¿›è¡Œæ›´æ–°ï¼Œæ”¯æŒå¤ç”¨ä¸éªŒè¯ã€‚ |

#### æ¡†æ¶è®¾è®¡ï¼šA-Evolve
- **Persistent Artifact State $T_s$**ï¼šåŒ…å«ä¸‰ç±»å¯ç¼–è¾‘èµ„äº§ï¼š
  - **Knowledge Registry (K)**ï¼šç»“æ„åŒ–çŸ¥è¯†ï¼ˆå¦‚APIæ–‡æ¡£ã€æµç¨‹è§„èŒƒï¼‰
  - **Tool Registry (T)**ï¼šå¯æ‰§è¡Œå‡½æ•°ï¼ˆå¸¦ç­¾åä¸æµ‹è¯•ï¼‰
  - **Validation Registry (V)**ï¼šéªŒè¯æœºåˆ¶ï¼ˆå•å…ƒæµ‹è¯•ã€å›å½’æ£€æŸ¥ï¼‰
- **Solve-Evolve Control Loop**ï¼š
  - **Solve Phase**ï¼šä½¿ç”¨å½“å‰ç­–ç•¥å®Œæˆä»»åŠ¡ã€‚
  - **Evolve Phase**ï¼šEvolver åˆ†æå†å²è½¨è¿¹ï¼Œæå‡ºå¹¶éªŒè¯å€™é€‰æ›´æ–°ã€‚
- **Evolver Agent ç»“æ„**ï¼š
  - `Diagnose` â†’ `Plan` â†’ `Update` â†’ `Verify`

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | Agentic Evolution |
|------|--------|-------------------|
| æ›´æ–°å¯¹è±¡ | æƒé‡ $\theta$ æˆ–åŸå§‹æ–‡æœ¬è®°å¿† | å¯è§£é‡Šã€å¯å®¡è®¡çš„ç»“æ„åŒ– artifact |
| æ›´æ–°æœºåˆ¶ | å›ºå®šè§„åˆ™ï¼ˆæ¢¯åº¦ä¸‹é™ / è¿½åŠ æ£€ç´¢ï¼‰ | è‡ªä¸»å†³ç­– + éªŒè¯é—¨æ§ï¼ˆcommit decisionï¼‰ |
| å¯æ‰©å±•æ€§ | æ”¶ç›Šå¿«é€Ÿé¥±å’Œ | æ”¯æŒæŒç»­æ”¹è¿›ï¼ˆamortization of reasoningï¼‰ |
| å®‰å…¨æ€§ | éš¾ä»¥æ§åˆ¶ï¼Œé£é™©é«˜ | é€šè¿‡ `V` æ³¨å†Œè¡¨å®ç°å¼ºæ²»ç† |
| æ•°æ®éšç§ | éœ€é›†ä¸­å›ä¼ æ•°æ® | æ”¯æŒæœ¬åœ°åŒ–ã€å»ä¸­å¿ƒåŒ–è¿›åŒ– |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **AppWorld** (Trivedi et al., 2024)ï¼šä¸€ä¸ªç”¨äºè¯„æµ‹äº¤äº’å¼ç¼–ç æ™ºèƒ½ä½“çš„åŸºå‡†å¹³å°ã€‚
  - åŒ…å« 9 ä¸ªæ—¥å¸¸åº”ç”¨ï¼ˆå¦‚ Amazonã€Spotifyã€Venmoï¼‰å’Œ 457 ä¸ª APIã€‚
  - æ¨¡æ‹Ÿçº¦ 100 åè™šæ„ç”¨æˆ·çš„æ•°å­—æ´»åŠ¨ï¼Œæ”¯æŒå¤æ‚ä»»åŠ¡ã€‚
  - ä»»åŠ¡éœ€è·¨å¤šä¸ªåº”ç”¨è°ƒç”¨ APIï¼Œå¹³å‡æ¯ä¸ªä»»åŠ¡ä½¿ç”¨ 9.5 ä¸ª APIã€‚
  - åˆ’åˆ†ï¼š
    - 50 ä¸ªä»»åŠ¡ç”¨äºè¿›åŒ–è®­ç»ƒï¼ˆtraining splitï¼‰
    - 50 ä¸ªä»»åŠ¡ç”¨äºæµ‹è¯•è¯„ä¼°ï¼ˆtest-normal splitï¼‰

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **å›ºå®šè®¡ç®—é¢„ç®—**ï¼š
  - `C_solve`ï¼šæ¯ä»»åŠ¡æœ€å¤§ tool calls / steps / tokensï¼ˆè§£é¢˜é˜¶æ®µï¼‰
  - `C_evolve`ï¼šæ¯ episode æœ€å¤§ tokens å’Œ tool invocationsï¼ˆè¿›åŒ–é˜¶æ®µï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Task Goal Completion (TGC)**ï¼šä»»åŠ¡å®Œå…¨æˆåŠŸçš„æ¯”ä¾‹ï¼ˆæ‰€æœ‰å•å…ƒæµ‹è¯•é€šè¿‡ï¼‰ã€‚
  - **Average Passed Tests (APT)**ï¼šå¹³å‡æ¯é¡¹ä»»åŠ¡é€šè¿‡çš„å•å…ƒæµ‹è¯•æ¯”ä¾‹ï¼Œè¡¡é‡æ¸è¿›å¼è¿›æ­¥ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | æè¿° |
|------|------|------|
| **Vanilla** | æ— è¿›åŒ– | ä¸è¿›è¡Œä»»ä½•æŒä¹…åŒ–æ›´æ–°ï¼Œç›´æ¥æ¨ç† |
| **APE** (Zhou et al., 2022) | éå‚æ•°å¯å‘å¼ | åŸºäºæœç´¢çš„ prompt è¿›åŒ–ï¼Œé€‰æ‹©å¾—åˆ†é«˜çš„æŒ‡ä»¤ |
| **AWM** (Wang et al., 2024) | éå‚æ•°å¯å‘å¼ | ä»å†å²è½¨è¿¹ä¸­æå–å¯å¤ç”¨çš„å·¥ä½œæµä½œä¸ºè®°å¿† |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 1ï¼‰

| Method | Claude Haiku 4.5 (TGC/APT) | Gemini 3 Flash (TGC/APT) |
|--------|----------------------------|--------------------------|
| Vanilla | 32 / 51.16 | 56 / 80.45 |
| APE | 30 / 56.00 | 52 / 84.00 |
| AWM | 46 / 65.76 | 52 / 87.75 |
| **A-Evolve** | **64 / 84.31** | **82 / 92.05** |

> âœ… **ç»“è®º**ï¼šA-Evolve åœ¨æ‰€æœ‰ solver backbone ä¸Šå‡æ˜¾è‘—ä¼˜äºåŸºçº¿ï¼Œå°¤å…¶åœ¨å°æ¨¡å‹ä¸Šæå‡å·¨å¤§ï¼ˆHaiku 4.5 çš„ TGC ä» 32% æå‡è‡³ 64%ï¼‰ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **èƒ½åŠ›æ”¾å¤§å™¨æ•ˆåº”**ï¼šA-Evolve èƒ½å°†å¼± solverï¼ˆå¦‚ Haiku 4.5ï¼‰çš„èƒ½åŠ›æå‡è‡³æ¥è¿‘ç”šè‡³è¶…è¿‡æ›´å¼ºçš„ vanilla æ¨¡å‹ï¼ˆå¦‚ Sonnet 4ï¼‰ã€‚
- **ç¼©å°å®¹é‡å·®è·**ï¼šä¾‹å¦‚ï¼ŒA-Evolve + Haiku 4.5ï¼ˆ64% TGCï¼‰ > Vanilla + Sonnet 4ï¼ˆ42% TGCï¼‰ã€‚
- **é«˜æ•ˆæ€§**ï¼šå³ä½¿æå°çš„è¿›åŒ–æ­¥æ•°ï¼ˆå¦‚ 1 stepï¼‰ï¼Œä¹Ÿèƒ½å¸¦æ¥æ˜¾è‘—å¢ç›Šã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆFig. 3 & C.2ï¼‰
ç§»é™¤ A-Evolve ä¸­ä»»ä¸€ç»„ä»¶å‡å¯¼è‡´æ€§èƒ½ä¸‹é™ï¼š

| å˜ä½“ | æ€§èƒ½å½±å“ | å¤±è´¥æ¨¡å¼ |
|------|--------|--------|
| **A-Evolve/D**ï¼ˆæ— è¯Šæ–­ï¼‰ | æ˜¾è‘—ä¸‹é™ | ç›²ç›®ä¿®è¡¥ï¼Œä»…æ©ç›–é”™è¯¯è€Œéæ ¹æ²» |
| **A-Evolve/A**ï¼ˆæ— åˆ†æå·¥å…·ï¼‰ | ä¸‹é™ | ä¾èµ–å•æ¬¡è½¨è¿¹æ¨æ–­ï¼Œé”™è¿‡ç³»ç»Ÿæ€§æ¨¡å¼ |
| **A-Evolve/P**ï¼ˆæ— è§„åˆ’ï¼‰ | ä¸‹é™ | ç¼–è¾‘ä¸åè°ƒï¼Œå¦‚æ”¹å·¥å…·æœªåŒæ­¥æ”¹ schema |
| **A-Evolve/V**ï¼ˆæ— éªŒè¯ï¼‰ | **ä¸‹é™æœ€å¤š** | æäº¤æœ‰ç¼ºé™· artifactï¼ˆå¦‚è¯­æ³•é”™è¯¯å·¥å…·ï¼‰ï¼Œæ±¡æŸ“ä¸Šä¸‹æ–‡ï¼Œå¼•å‘å›å½’ |

> ğŸ” **å…³é”®å‘ç°**ï¼š**Verification æ˜¯ç¨³å®šæ€§çš„å…³é”®ä¿éšœ**ï¼›å®Œæ•´é—­ç¯ä¸å¯åˆ†å‰²ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **Agentic Evolution æ˜¯å¿…è¦èŒƒå¼**ï¼š
   - ä¼ ç»Ÿé™æ€ä¼˜åŒ–æ— æ³•åº”å¯¹å¼€æ”¾ä¸–ç•Œçš„æŒç»­å˜åŒ–ã€‚
   - å°†è¿›åŒ–æœ¬èº«å»ºæ¨¡ä¸º **goal-directed agent** æ˜¯å®ç°å¯æŒç»­é€‚åº”çš„å…³é”®ã€‚

2. **è¿›åŒ–å¯è§„æ¨¡åŒ–ï¼ˆEvolution-Scaling Hypothesisï¼‰**ï¼š
   - æå‡ºå‡è®¾ï¼š**é€‚åº”èƒ½åŠ›éš evolution-time compute å•è°ƒå¢é•¿**ã€‚
   - å®éªŒè¯æ˜ï¼šå¢åŠ è¿›åŒ–æ­¥æ•°æˆ–ä½¿ç”¨æ›´å¤§ evolverï¼ˆå¦‚ Opus > Sonnet > Haikuï¼‰ï¼Œæ€§èƒ½æŒç»­æå‡ï¼Œè€Œ AWM å¿«é€Ÿé¥±å’Œã€‚

3. **ç»“æ„åŒ– artifact çš„ä»·å€¼**ï¼š
   - å°†æ¨ç†æˆæœå›ºåŒ–ä¸º **toolã€skillã€test** ç­‰æ¨¡å—ï¼Œå®ç° **amortization of expensive reasoning**ã€‚
   - ç›¸æ¯”äºå­˜å‚¨åŸå§‹æ–‡æœ¬è®°å¿†ï¼Œæ›´é«˜æ•ˆã€å¯å¤ç”¨ã€å¯æ²»ç†ã€‚

4. **æœ¬åœ°åŒ–è¿›åŒ–çš„ç¤¾ä¼šä»·å€¼**ï¼š
   - æ”¯æŒåœ¨è®¾å¤‡ç«¯æˆ–ç§æœ‰ç¯å¢ƒä¸­ç‹¬ç«‹è¿›åŒ–ï¼Œæ— éœ€ä¸Šä¼ æ•æ„Ÿæ•°æ®ï¼Œå¢å¼º **privacy ä¸ data sovereignty**ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **è®¡ç®—å¼€é”€è¾ƒé«˜**ï¼šç»´æŠ¤ Evolver Agent éœ€é¢å¤– compute resourceï¼ŒçŸ­æœŸæ•ˆç‡ä½äºç®€å•å¯å‘å¼ã€‚
- **å¯¹ Evolver èƒ½åŠ›ä¾èµ–å¼º**ï¼šå°æ¨¡å‹ä½œä¸º evolver æ—¶è¯Šæ–­è´¨é‡å·®ï¼ŒéªŒè¯å¤±è´¥ç‡é«˜ï¼ˆè§ Table 3ï¼‰ã€‚
- **å½“å‰æ¡†æ¶ä»ä¸º centralized**ï¼šè™½æ”¯æŒæœ¬åœ°è¿›åŒ–ï¼Œä½†æœªæ¢è®¨å¤š agent ååŒè¿›åŒ–çš„åˆ†å¸ƒå¼æ¶æ„ã€‚
- **éªŒè¯æœºåˆ¶ä¾èµ–äººå·¥å®šä¹‰**ï¼šV registry ä¸­çš„æµ‹è¯•éœ€é¢„å…ˆç¼–å†™ï¼Œè‡ªåŠ¨åŒ–ç”Ÿæˆä»æ˜¯æŒ‘æˆ˜ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **Benchmark Development**ï¼š
   - æ„å»ºæ›´èƒ½ä½“ç° train-deploy gap çš„éå¹³ç¨³ç¯å¢ƒåŸºå‡†ï¼Œè¯„ä¼° artifact çš„æŒä¹…æ€§å’Œå¤ç”¨æ€§ã€‚

2. **Framework Optimization**ï¼š
   - æ”¹è¿› diagnosisã€planningã€verification æ¨¡å—ï¼Œæé«˜ compute åˆ©ç”¨æ•ˆç‡ï¼Œé€¼è¿‘ compute-optimal frontierã€‚

3. **ç†è®ºå»ºæ¨¡**ï¼š
   - å½¢å¼åŒ– agentic evolution ä¸ºç»„åˆç¨‹åºç©ºé—´ä¸Šçš„ä¼˜åŒ–é—®é¢˜ã€‚
   - å»ºç«‹ä¸éä»£ç†æ–¹æ³•çš„åˆ†ç¦»ç•Œé™ï¼ˆseparation resultsï¼‰ã€‚
   - æ¨å¯¼é•¿æœŸé€‚åº”çš„ regret boundsã€‚

4. **å®‰å…¨ä¸å¯¹é½æœºåˆ¶æ·±åŒ–**ï¼š
   - è®¾è®¡æ›´é²æ£’çš„ validation gatesï¼ˆå¦‚å½¢å¼åŒ–éªŒè¯ã€äººç±»åé¦ˆé›†æˆï¼‰ã€‚
   - é˜²æ­¢ capability drift ä¸ç›®æ ‡é”™ä½ï¼ˆmisalignmentï¼‰ã€‚

> ğŸ“Œ **æœ€ç»ˆè®ºæ–­**ï¼šAgentic Evolution ä¸æ˜¯å¯é€‰é¡¹ï¼Œè€Œæ˜¯ LLM ç³»ç»Ÿèµ°å‘çœŸå®ä¸–ç•Œéƒ¨ç½²çš„ **å¿…ç„¶è·¯å¾„**ã€‚å®ƒæ ‡å¿—ç€ AI ç³»ç»Ÿä»â€œé™æ€æ¨ç†æœºâ€å‘â€œæŒç»­å­¦ä¹ ä½“â€çš„èŒƒå¼è·ƒè¿ã€‚

</details>

---

### 11. [Lyapunov Stability-Aware Stackelberg Game for Low-Altitude Economy: A Control-Oriented Pruning-Based DRL Approach](https://arxiv.org/abs/2602.01131)

**Authors**: Yue Zhong, Jiawen Kang, Yongju Tong, Hong-Ning Dai, Dong In Kim, Abbas Jamalipour, Shengli Xie  
**Category**: cs.AI  
**Published**: 2026-02-03  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2602.01131v1  

#### Abstract
With the rapid expansion of the low-altitude economy, Unmanned Aerial Vehicles (UAVs) serve as pivotal aerial base stations supporting diverse services from users, ranging from latency-sensitive critical missions to bandwidth-intensive data streaming. However, the efficacy of such heterogeneous netw...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Lyapunov Stability-Aware Stackelberg Game for Low-Altitude Economy: A Control-Oriented Pruning-Based DRL Approach*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹**ä½ç©ºç»æµ**ï¼ˆLow-Altitude Economy, LAEï¼‰ä¸­æ— äººæœº**ï¼ˆUAVï¼‰**ä½œä¸ºç©ºä¸­åŸºç«™æ—¶é¢ä¸´çš„èµ„æºåˆ†é…ä¸ç‰©ç†æ§åˆ¶ç¨³å®šæ€§ä¹‹é—´çš„çŸ›ç›¾é—®é¢˜ã€‚ä¼ ç»Ÿç½‘ç»œè®¾è®¡é€šå¸¸ä»¥ååé‡ä¸ºä¸­å¿ƒï¼Œå¿½ç•¥äº†é€šä¿¡å»¶è¿Ÿå¯¹æ§åˆ¶ç¯è·¯ç¨³å®šæ€§çš„ç›´æ¥å½±å“ï¼Œå°¤å…¶åœ¨ç¾ååº”æ€¥ç­‰å®‰å…¨å…³é”®ä»»åŠ¡ä¸­å¯èƒ½å¯¼è‡´ç³»ç»Ÿå¤±ç¨³ç”šè‡³ä»»åŠ¡å¤±è´¥ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
1. **æ„å»ºäº† Sensing-Communication-Computing-Control (SCÂ³) é—­ç¯æ¡†æ¶**  
   é¦–æ¬¡å°† Sensingã€Communicationã€Computing å’Œ Control å››ä¸ªç¯èŠ‚ç»Ÿä¸€å»ºæ¨¡ä¸ºä¸€ä¸ªé—­ç¯ç³»ç»Ÿï¼Œæ˜ç¡®åˆ»ç”»äº†é€šä¿¡èµ„æºæ³¢åŠ¨å¦‚ä½•é€šè¿‡ç«¯åˆ°ç«¯å»¶è¿Ÿå½±å“æ§åˆ¶ç³»ç»Ÿçš„å®æ—¶å“åº”ä¸ç‰©ç†ç¨³å®šæ€§ã€‚

2. **å¼•å…¥ Lyapunov ç¨³å®šæ€§ç†è®ºè¿›è¡Œæ§åˆ¶-é€šä¿¡ååŒè®¾è®¡**  
   åˆ©ç”¨ **Lyapunov stability theory** å°†æŠ½è±¡çš„ç‰©ç†æ§åˆ¶ç¨³å®šæ€§è¦æ±‚è½¬åŒ–ä¸ºå¯é‡åŒ–çš„é€šä¿¡å»¶è¿Ÿè¾¹ç•Œï¼ˆ`T_budget`ï¼‰ï¼Œå®ç°äº†ä»â€œæ§åˆ¶éœ€æ±‚â€åˆ°â€œé€šä¿¡çº¦æŸâ€çš„ç†è®ºæ˜ å°„ï¼Œä¸ºèµ„æºåˆ†é…æä¾›äº†ä¸¥æ ¼çš„æ•°å­¦åŸºç¡€ã€‚

3. **æå‡ºåŸºäº Stackelberg åšå¼ˆçš„èµ„æºåˆ†é…æœºåˆ¶**  
   æ„å»ºäº†ä¸€ä¸ªåˆ†å±‚åšå¼ˆæ¨¡å‹ï¼š
   - **UAV ä½œä¸ºé¢†å¯¼è€…**ï¼ˆLeaderï¼‰åŠ¨æ€å®šä»·å¸¦å®½èµ„æºï¼›
   - **ç”¨æˆ·ä½œä¸ºè·Ÿéšè€…**ï¼ˆFollowerï¼‰æ ¹æ®ä»·æ ¼å’ŒæœåŠ¡ç´§è¿«æ€§ä¼˜åŒ–å¸¦å®½è¯·æ±‚ã€‚
   è¯¥æœºåˆ¶é€šè¿‡æ¿€åŠ±ç›¸å®¹çš„æ–¹å¼å®ç°è´Ÿè½½å‡è¡¡ï¼Œå¹¶ä¿éšœç³»ç»Ÿåœ¨åŠ¨æ€ç¯å¢ƒä¸‹çš„ç¨³å®šæ€§ã€‚

4. **è®¾è®¡è½»é‡çº§çš„ Pruning-based PPO ç®—æ³•**  
   é’ˆå¯¹æ ‡å‡† **Deep Reinforcement Learning (DRL)** åœ¨èƒ½é‡å—é™è¾¹ç¼˜å¹³å°ä¸Šçš„é«˜è®¡ç®—å¼€é”€é—®é¢˜ï¼Œæå‡ºä¸€ç§ç»“åˆ**åŠ¨æ€ç»“æ„åŒ–å‰ªæ**ï¼ˆdynamic structured pruningï¼‰çš„ **Proximal Policy Optimization (PPO)** ç®—æ³•ï¼Œæ˜¾è‘—å‹ç¼©ç¥ç»ç½‘ç»œè§„æ¨¡ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å»é™¤å†—ä½™ç¥ç»å…ƒï¼Œé™ä½æ¨ç†å»¶è¿Ÿä¸èƒ½è€—ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | æœ¬æ–‡æ–¹æ³• | ç°æœ‰æ–¹æ³• |
|------|----------|---------|
| **ç³»ç»Ÿè§†è§’** | æ§åˆ¶-é€šä¿¡è”åˆè®¾è®¡ï¼ˆSCÂ³é—­ç¯ï¼‰ | ä»…å…³æ³¨é€šä¿¡æ€§èƒ½ï¼ˆå¦‚ååé‡ã€AoIï¼‰ |
| **ç¨³å®šæ€§ä¿éšœ** | æ˜¾å¼å»ºæ¨¡å¹¶ä¿è¯ Lyapunov æ„ä¹‰ä¸‹çš„æ¸è¿‘ç¨³å®š | å¿½ç•¥æˆ–å¼±åŒ–ç‰©ç†æ§åˆ¶ç¨³å®šæ€§ |
| **æ¿€åŠ±æœºåˆ¶** | å®šä»·ç­–ç•¥ç”±ç¨³å®šæ€§çŠ¶æ€é©±åŠ¨ï¼ˆLyapunov-drivenï¼‰ | ä»…åŸºäºèµ„æºç¨€ç¼ºæ€§æˆ–ç»æµæ•ˆç”¨ |
| **ç®—æ³•æ•ˆç‡** | åŠ¨æ€å‰ªæå®ç°è½»é‡åŒ– DRLï¼Œé€‚åˆæœºè½½éƒ¨ç½² | ä½¿ç”¨å…¨è¿æ¥é‡å‹ç½‘ç»œï¼Œéš¾ä»¥éƒ¨ç½²äº UAV |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### å®éªŒåœºæ™¯ä¸ä»¿çœŸè®¾ç½®
- **åœºæ™¯è®¾å®š**ï¼šç¾ååº”æ€¥é€šä¿¡æ¢å¤åœºæ™¯ï¼Œåœ°é¢åŸºç¡€è®¾æ–½ç˜«ç—ªï¼Œå¤šæ¶ UAV ä½œä¸ºç©ºä¸­åŸºç«™æœåŠ¡å¹¸å­˜è€…ï¼ˆusersï¼‰ã€‚
- **ç”¨æˆ·ç±»å‹**ï¼šåŒ…å«ç´§æ€¥å‹ï¼ˆçŸ­åŒ…ã€è¶…ä½å»¶è¿Ÿã€é«˜å¯é æ€§ï¼‰ä¸éç´§æ€¥å‹ï¼ˆå¤§è½½è·ã€è¿ç»­ä¼ è¾“ï¼‰ä¸¤ç±»ä¸šåŠ¡ã€‚
- **UAV æ•°é‡**ï¼š3â€“12 æ¶ï¼›**ç”¨æˆ·æ•°é‡**ï¼š5â€“20 åã€‚
- **ä¿¡é“æ¨¡å‹**ï¼šé‡‡ç”¨è‡ªç”±ç©ºé—´è·¯å¾„æŸè€—æ¨¡å‹ï¼Œè€ƒè™‘è·ç¦»ç›¸å…³çš„ `SNR` å˜åŒ–ã€‚
- **æ§åˆ¶æ¨¡å‹**ï¼šUAV è·Ÿè¸ªç”¨æˆ·ä½ç½®ï¼Œå»ºæ¨¡ä¸ºå¸¦æœ‰è¾“å…¥å»¶è¿Ÿçš„çº¿æ€§éšæœºå¾®åˆ†æ–¹ç¨‹ï¼Œä½¿ç”¨ç¦»æ•£åŒ–çŠ¶æ€æ›´æ–°ã€‚

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Test Reward** | UAV çš„å¹³å‡æ•ˆç”¨ï¼ˆæ”¶ç›Šå‡å»æˆæœ¬ï¼‰ï¼Œåæ˜ æ•´ä½“ç³»ç»Ÿæ€§èƒ½ |
| **Stackelberg Equilibrium æ”¶æ•›æ€§** | å®šä»·ä¸å¸¦å®½è¯·æ±‚æ˜¯å¦æ”¶æ•›è‡³çº³ä»€å‡è¡¡ |
| **End-to-End Latency** (`T_total`) | åŒ…æ‹¬ Sensingã€Communicationã€Computingã€Control å››éƒ¨åˆ†å»¶è¿Ÿ |
| **Control Loop Stability** | æ˜¯å¦æ»¡è¶³ Lyapunov æ¡ä»¶ `E[V(x_{k+1})] â‰¤ ÏV(x_k) + Tr(PQ)` |
| **Inference Latency / Model Size** | å‰ªæå‰åæ¨¡å‹å‚æ•°é‡ä¸æ¨ç†æ—¶é—´å¯¹æ¯” |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
1. **Standard PPO**ï¼šæœªå‰ªæçš„æ ‡å‡†å¤šæ™ºèƒ½ä½“ PPO ç®—æ³•
2. **Greedy Algorithm**ï¼šUAV å›ºå®šé«˜ä»·æˆ–æŒ‰è´Ÿè½½è°ƒæ•´ä»·æ ¼ï¼Œç”¨æˆ·è´ªå¿ƒç”³è¯·å¸¦å®½
3. **Random Algorithm**ï¼šéšæœºå®šä»·ä¸å¸¦å®½è¯·æ±‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- **å¥–åŠ±æå‡**ï¼šæå‡ºçš„ **Pruning-based PPO** åœ¨ 500 è½®è¿­ä»£åè¾¾åˆ°çº¦ **8.0** çš„æµ‹è¯•å¥–åŠ±ï¼Œä¼˜äºæ ‡å‡† PPOï¼ˆ~7.6ï¼‰ã€è´ªå©ªç®—æ³•ï¼ˆ~4.5ï¼‰å’Œéšæœºç­–ç•¥ï¼ˆ~2.3ï¼‰ã€‚
- **æ”¶æ•›é€Ÿåº¦æ›´å¿«**ï¼šPruning-based PPO åœ¨çº¦ 300 è½®å†…å®Œæˆæ”¶æ•›ï¼Œä¸”æœ€ç»ˆæ€§èƒ½æ›´é«˜ï¼Œè¡¨æ˜å‰ªæèµ·åˆ°äº†æ­£åˆ™åŒ–ä½œç”¨ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚
- **æ¨¡å‹å‹ç¼©æ•ˆæœæ˜¾è‘—**ï¼š
  - æœ€ç»ˆæ¨¡å‹å‚æ•°å‡å°‘è¶…è¿‡ **50%**ï¼ˆå…·ä½“æ•°å€¼æœªç»™å‡ºï¼Œä½†ä»ç»“æ„æ¨æ–­ï¼‰ï¼›
  - æ¨ç†å»¶è¿Ÿå¤§å¹…ä¸‹é™ï¼Œé€‚ç”¨äºæœºè½½å®æ—¶å†³ç­–ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| æ–¹æ³• | å¹³å‡ Test Reward | æ˜¯å¦ä¿éšœç¨³å®šæ€§ | æ˜¯å¦æ”¶æ•› | é€‚ç”¨æ€§ |
|------|------------------|----------------|----------|--------|
| Pruning-based PPO | âœ… **8.0**ï¼ˆæœ€é«˜ï¼‰ | âœ… æ˜¯ | âœ… å¿«é€Ÿæ”¶æ•› | âœ… é€‚åˆè¾¹ç¼˜éƒ¨ç½² |
| Standard PPO | ~7.6 | âœ… æ˜¯ | âœ… æ”¶æ•›è¾ƒæ…¢ | âŒ è®¡ç®—å¼€é”€å¤§ |
| Greedy | ~4.5 | âŒ å¦ï¼ˆå¸¸è¿åå»¶è¿Ÿçº¦æŸï¼‰ | â­• å±€éƒ¨éœ‡è¡ | â­• ç®€å•ä½†ä¸å¯é  |
| Random | ~2.3 | âŒ å¦ | âŒ ä¸æ”¶æ•› | âŒ æ— å®é™…æ„ä¹‰ |

> å›¾ 3 å’Œå›¾ 6 æ˜¾ç¤ºï¼Œæ— è®ºç”¨æˆ·æ•°æˆ– UAV æ•°å˜åŒ–ï¼Œæ‰€ææ–¹æ³•å§‹ç»ˆå–å¾—æœ€ä¼˜ rewardï¼ŒéªŒè¯å…¶é²æ£’æ€§å’Œå¯æ‰©å±•æ€§ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
- **å‰ªæèµ·å§‹è½®æ¬¡**ï¼ˆpruning start epoch, `tâ‚€`ï¼‰çš„å½±å“ï¼ˆè§å›¾ 4ï¼‰ï¼š
  - `tâ‚€ = 50`ï¼ˆæ—©å‰ªæï¼‰â†’ æœ€ä¼˜æ€§èƒ½ï¼ˆreward â‰ˆ 8.2ï¼‰
  - `tâ‚€ = 200`ï¼ˆä¸­å‰ªæï¼‰â†’ æ€§èƒ½æœ€å·®ï¼ˆå¹²æ‰°å­¦ä¹ è¿‡ç¨‹ï¼‰
  - `tâ‚€ = 300`ï¼ˆæ™šå‰ªæï¼‰â†’ æ¬¡ä¼˜ï¼ˆä¿ç•™åˆæœŸå¯†é›†æ¢ç´¢èƒ½åŠ›ï¼‰
- **ç»“è®º**ï¼š**æ—©æœŸç»“æ„å¹²é¢„æ›´æœ‰åˆ©äºå½¢æˆç¨€ç–è€Œé«˜æ•ˆçš„ç­–ç•¥**ï¼Œå…¼å…·æ­£åˆ™åŒ–ä¸å‹ç¼©ä¼˜åŠ¿ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æ§åˆ¶ç¨³å®šæ€§å¯é€šè¿‡é€šä¿¡èµ„æºè°ƒæ§æ¥ä¿éšœ**ï¼šé€šè¿‡ Lyapunov åˆ†æå¯¼å‡ºçš„å»¶è¿Ÿè¾¹ç•Œå¯æœ‰æ•ˆæŒ‡å¯¼èµ„æºåˆ†é…ï¼Œç¡®ä¿ç‰©ç†ç³»ç»Ÿç¨³å®šã€‚
2. **Stackelberg åšå¼ˆæ˜¯å®ç°æ¿€åŠ±å…¼å®¹çš„æœ‰æ•ˆå·¥å…·**ï¼šUAV å®šä»·æœºåˆ¶èƒ½è‡ªç„¶å¼•å¯¼ç”¨æˆ·è¡Œä¸ºï¼Œå®ç°ç¨³å®šä¸æ•ˆç”¨çš„å¹³è¡¡ã€‚
3. **ç»“æ„åŒ–å‰ªæä¸ä»…å‹ç¼©æ¨¡å‹ï¼Œè¿˜èƒ½æå‡æ³›åŒ–èƒ½åŠ›**ï¼šåŠ¨æ€å‰ªæç›¸å½“äºä¸€ç§æ­£åˆ™åŒ–ï¼Œå¸®åŠ© agent æ›´å¿«èšç„¦å…³é”®ç‰¹å¾ï¼Œé¿å…é™·å…¥å±€éƒ¨å™ªå£°ã€‚
4. **æ‰€ææ¡†æ¶å¯åœ¨åŠ¨æ€è´Ÿè½½ä¸‹å¿«é€Ÿé€¼è¿‘ Stackelberg å‡è¡¡**ï¼šå³ä½¿åœ¨ç”¨æˆ·æ•°é‡å‰§çƒˆæ³¢åŠ¨çš„æƒ…å†µä¸‹ï¼Œç³»ç»Ÿä»èƒ½ç»´æŒé«˜æ•ˆè¿è¡Œã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **å‡è®¾çº¿æ€§æ§åˆ¶æ¨¡å‹**ï¼šå®é™… UAV åŠ¨åŠ›å­¦å¯èƒ½é«˜åº¦éçº¿æ€§ï¼Œå½“å‰ Lyapunov åˆ†æåŸºäº LTI è¿‘ä¼¼ï¼Œé€‚ç”¨èŒƒå›´æœ‰é™ã€‚
2. **é›†ä¸­å¼è®­ç»ƒã€åˆ†å¸ƒå¼æ‰§è¡Œ**ï¼ˆCTDEï¼‰ä¾èµ–å…¨å±€ä¿¡æ¯æ”¶é›†ç”¨äºè®­ç»ƒï¼Œå¯èƒ½å­˜åœ¨éšç§ä¸é€šä¿¡ç“¶é¢ˆã€‚
3. **æœªè€ƒè™‘å¤šè·³ä¸­ç»§æˆ–é›†ç¾¤åä½œ**ï¼šå½“å‰æ¨¡å‹èšç„¦å•è·³ A2G é“¾è·¯ï¼Œå¤æ‚æ‹“æ‰‘ä¸‹çš„æ‰©å±•æ€§æœ‰å¾…éªŒè¯ã€‚
4. **ä»¿çœŸç¯å¢ƒç†æƒ³åŒ–**ï¼šæœªæ¨¡æ‹Ÿæç«¯å¤©æ°”ã€å¼ºå¹²æ‰°æˆ–å¤šæºå¼‚æ„æ•°æ®æµç­‰ç°å®æŒ‘æˆ˜ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **ç ”ç©¶æ—¶å˜èƒ½é‡ä¸å¸¦å®½è”åˆæ³¢åŠ¨ä¸‹çš„å¤åˆå»¶è¿Ÿå»ºæ¨¡**ï¼›
2. **æ·±åŒ–åŒå‘æ§åˆ¶-é€šä¿¡ååŒæœºåˆ¶**ï¼Œä¾‹å¦‚å°†æ§åˆ¶è¯¯å·®åé¦ˆç”¨äºåŠ¨æ€è°ƒåˆ¶é€šä¿¡è°ƒåº¦ï¼›
3. **æ‹“å±•è‡³ multi-leader multi-follower Stackelberg æ¸¸æˆ**ï¼Œæ”¯æŒ UAV ååŒç«äº‰ï¼›
4. **é›†æˆè¯­ä¹‰é€šä¿¡æˆ–ç”Ÿæˆå¼ AI æŠ€æœ¯**ï¼Œè¿›ä¸€æ­¥é™ä½å…³é”®ä¿¡æ¯ä¼ è¾“å¼€é”€ã€‚

---

> âœ… **æ€»ä½“è¯„ä»·**ï¼šæœ¬æ–‡æˆåŠŸæ‰“é€šäº† **control theory** ä¸ **network resource management** çš„å£å’ï¼Œæå‡ºäº†é¦–ä¸ª **Lyapunov stability-aware** çš„ **DRL-based resource allocation** æ¡†æ¶ï¼Œå¹¶é€šè¿‡ **pruning-based lightweight learning** å®ç°äº†ç†è®ºä¸å·¥ç¨‹è½åœ°çš„åŒé‡çªç ´ï¼Œå¯¹æ„å»ºå¯é ã€æ™ºèƒ½çš„ä½ç©ºç»æµç”Ÿæ€ç³»ç»Ÿå…·æœ‰é‡è¦æ„ä¹‰ã€‚

</details>

---

### 12. [HyLRA: Hybrid Layer Reuse Attention for Efficient Long-Context Inference](https://arxiv.org/abs/2602.00777)

**Authors**: Xuan Ai, Qingqing Yang, Peng Wang, Lei Deng, Lin Zhang, Renhai Chen, Gong Zhang  
**Category**: cs.CL  
**Published**: 2026-02-03  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2602.00777v1  

#### Abstract
Long-context inference in Large Language Models (LLMs) is bottlenecked by the quadratic computation complexity of attention and the substantial memory footprint of Key-Value (KV) caches. While existing sparse attention mechanisms attempt to mitigate this by exploiting inherent sparsity, they often r...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šHyLRA: Hybrid Layer Reuse Attention for Efficient Long-Context Inference**

---

## 1. **è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### âœ… **è§£å†³çš„é—®é¢˜**
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é•¿ä¸Šä¸‹æ–‡æ¨ç†ä¸­é¢ä¸´ä¸¤ä¸ªæ ¸å¿ƒç“¶é¢ˆï¼š
- **Attention çš„äºŒæ¬¡è®¡ç®—å¤æ‚åº¦**ï¼šéšç€åºåˆ—é•¿åº¦å¢é•¿ï¼Œself-attention çš„è®¡ç®—å¼€é”€å‘ˆ $O(n^2)$ å¢é•¿ã€‚
- **KV Cache çš„å†…å­˜å‹åŠ›**ï¼šKey-Value ç¼“å­˜éšä¸Šä¸‹æ–‡çº¿æ€§å¢é•¿ï¼Œå¯¼è‡´é«˜å†…å­˜å ç”¨å’Œå¸¦å®½ç“¶é¢ˆã€‚

ç°æœ‰ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼ˆå¦‚å›ºå®šçª—å£ã€æ¿€è¿›ç¼“å­˜æ·˜æ±°ï¼‰å¾€å¾€åœ¨æ•ˆç‡ä¸å‡†ç¡®æ€§ä¹‹é—´éš¾ä»¥å¹³è¡¡ï¼Œä¸”å¤šæ•°æ–¹æ³•å¯¹æ‰€æœ‰å±‚é‡‡ç”¨ç»Ÿä¸€ç­–ç•¥ï¼Œå¿½ç•¥äº†ä¸åŒç½‘ç»œæ·±åº¦ä¸Šçš„ç»“æ„å¼‚è´¨æ€§ã€‚

---

### ğŸš€ **æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯**
ä½œè€…æå‡º **HyLRAï¼ˆHybrid Layer Reuse Attentionï¼‰**ï¼Œä¸€ç§åŸºäº**å±‚é—´ç›¸ä¼¼æ€§åˆ†æ**çš„æ··åˆæ³¨æ„åŠ›æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ¥è‡ªä¸¤ä¸ªå…³é”®è§‚å¯Ÿï¼š

#### ğŸ” **ä¸¤å¤§æ´å¯Ÿï¼ˆInsightsï¼‰**
1. **Intra-layer Sensitivityï¼ˆå±‚å†…æ•æ„Ÿæ€§ï¼‰**  
   - ä¸åŒ Transformer å±‚å¯¹ç¨€ç–åŒ–è¯¯å·®çš„å®¹å¿åº¦å·®å¼‚æ˜¾è‘—ï¼š
     - **æ•æ„Ÿå±‚ï¼ˆSensitive Layersï¼‰**ï¼šæ—©æœŸæˆ–å…³é”®å±‚å¯¹ç‰¹å¾æ‰°åŠ¨é«˜åº¦æ•æ„Ÿï¼Œéœ€ä¿ç•™ full attention ä»¥é˜²æ­¢ä¿¡æ¯å¤±çœŸã€‚
     - **å®¹å¿å±‚ï¼ˆTolerant Layersï¼‰**ï¼šæ·±å±‚å¯¹ top-k è¿‘ä¼¼é²æ£’æ€§å¼ºï¼Œå¯å®‰å…¨ä½¿ç”¨ç¨€ç–æ³¨æ„åŠ›ã€‚

2. **Inter-layer Similarityï¼ˆå±‚é—´ç›¸ä¼¼æ€§ï¼‰**  
   - ç›¸é‚»å±‚ä¹‹é—´çš„ top-k é«˜æ³¨æ„åŠ› token å…·æœ‰é«˜åº¦é‡å ï¼ˆå°¤å…¶åœ¨æ·±å±‚ï¼‰ï¼Œè¡¨æ˜å¯ä»¥è·¨å±‚å¤ç”¨é‡è¦ token çš„ç´¢å¼•ã€‚

#### ğŸ’¡ **HyLRA çš„è®¾è®¡**
ç»“åˆä¸Šè¿°ä¸¤ç‚¹ï¼ŒHyLRA æå‡ºä¸€ä¸ª**æ··åˆç­–ç•¥**ï¼š
- åœ¨**æ•æ„Ÿå±‚**æ‰§è¡Œæ ‡å‡† full attentionï¼Œå¹¶æå– top-k indicesï¼›
- åœ¨**å®¹å¿å±‚**ç›´æ¥**å¤ç”¨å‰ä¸€å±‚çš„ top-k indices**ï¼Œè·³è¿‡é‡å¤çš„é‡è¦æ€§è¯„åˆ†ä¸æ’åºè¿‡ç¨‹ï¼Œä»è€Œè§„é¿äºŒæ¬¡è®¡ç®—ã€‚

è¯¥ç­–ç•¥é€šè¿‡ **offline åŠ¨æ€è§„åˆ’ï¼ˆDynamic Programmingï¼‰** æ±‚è§£æœ€ä¼˜å±‚é…ç½®è·¯å¾„ï¼Œåœ¨æœ€å°åŒ– full attention è°ƒç”¨æ¬¡æ•°çš„åŒæ—¶æœ€å¤§åŒ–ç´¯è®¡ç›¸ä¼¼åº¦ã€‚

---

### â­ **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹é¢ | HyLRA | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ Jump3ã€H2Oã€StreamingLLMï¼‰ |
|------|-------|-------------------------------|
| **ç²¾åº¦ä¿æŒ** | æ›´ä¼˜ï¼Œä»… <1% å‡†ç¡®ç‡ä¸‹é™ | æ˜“å› æ¿€è¿›å‰ªææˆ–å›ºå®šæ¨¡å¼ä¸¢å¤±å…³é”®ä¿¡æ¯ |
| **æ•ˆç‡æå‡** | æ˜¾è‘—å‡å°‘å†—ä½™è®¡ç®—ï¼ˆé¿å…æ¯å±‚é‡æ–°é€‰ tokenï¼‰ | å¤šæ•°ä»éœ€æ¯å±‚ç‹¬ç«‹æ‰“åˆ†/æ’åºï¼Œå®é™…åŠ é€Ÿæœ‰é™ |
| **çµæ´»æ€§** | è‡ªé€‚åº”å†³å®šå“ªäº›å±‚ full / reuse | å¤šä¸ºé™æ€è§„åˆ™ï¼ˆå¦‚æ¯éš”3å±‚åˆ·æ–°ï¼‰ |
| **å…¼å®¹æ€§** | æ”¯æŒ token-level å’Œ block-level sparsityï¼Œé€‚é…ç¡¬ä»¶ä¼˜åŒ– | å¤šå±€é™äºç‰¹å®šå®ç° |

> âœ… **æœ¬è´¨ä¼˜åŠ¿**ï¼šå°†â€œç¨€ç–æ³¨æ„åŠ›â€ä»**é€å±‚ç‹¬ç«‹å†³ç­–**è½¬å˜ä¸º**è·¨å±‚ååŒè°ƒåº¦**ï¼Œå®ç°äº†æ›´é«˜æ•ˆçš„è®¡ç®—èµ„æºåˆ†é…ã€‚

---

## 2. **æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### ğŸ“š **ä½¿ç”¨çš„æ•°æ®é›†**
- **LongBench v2**ï¼šç»¼åˆæ€§é•¿ä¸Šä¸‹æ–‡è¯„æµ‹åŸºå‡†ï¼Œæ¶µç›–å…­ç±»ä»»åŠ¡ï¼š
  - Single-document QA
  - Multi-document QA
  - Long-dialogue History Understanding
  - Long Structured Data Understanding
  - Long In-context Learning
  - Code Repository Understanding
- ä¸Šä¸‹æ–‡é•¿åº¦è¦†ç›– **short (~8K)** åˆ° **long (~60K tokens)**ï¼Œæµ‹è¯•æ¨¡å‹åœ¨å¤šæ ·åœºæ™¯ä¸‹çš„è¡¨ç°ã€‚

---

### ğŸ§ª **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

#### âœ… æ¨¡å‹
- **DeepSeek-R1**ï¼šé«˜æ€§èƒ½æ¨ç†å¯¼å‘æ¨¡å‹
- **QWQ-32B-W8A8**ï¼šé‡åŒ–ç‰ˆæœ¬ï¼ˆ8-bit weights & activationsï¼‰ï¼Œç”¨äºéªŒè¯å†…å­˜å—é™ç¯å¢ƒä¸‹çš„æœ‰æ•ˆæ€§

#### âœ… ç¡¬ä»¶å¹³å°
- 8å—åŠ é€Ÿå™¨è®¾å¤‡ï¼Œå…± 768GB HBM3 å†…å­˜ï¼ˆ96GB/deviceï¼‰

#### âœ… åŸºçº¿æ–¹æ³•ï¼ˆBaselinesï¼‰
| æ–¹æ³• | æè¿° |
|------|------|
| **Full Attention** | æ ‡å‡† dense attentionï¼Œä½œä¸ºæ€§èƒ½ä¸Šé™ |
| **Jump3** | é™æ€ç‰ˆ HyLRA å˜ä½“ï¼Œæ¯3å±‚æ‰§è¡Œä¸€æ¬¡ full attentionï¼Œå…¶ä½™å¤ç”¨ç´¢å¼• |

> æ³¨ï¼šJump3 æ˜¯ HyLRA çš„ç®€åŒ–å¯¹ç…§ï¼Œç”¨äºéªŒè¯åŠ¨æ€è§„åˆ’ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚

#### âœ… è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Performance Score** | LongBench v2 ä¸Šçš„ä»»åŠ¡å‡†ç¡®ç‡ï¼ˆOverall / Easy / Hard / ä¸åŒ context length åˆ†æ®µï¼‰ |
| **Efficiency Metrics** | 
| - AVG_TTFT | Average Time To First Token |
| - Generation Throughput | ç”Ÿæˆé˜¶æ®µååé‡ï¼ˆtokens/sï¼‰ |
| - Overall Throughput | ç«¯åˆ°ç«¯ååé‡ |
| - Speedup | ç›¸å¯¹äº Full Attention çš„åŠ é€Ÿæ¯” |

---

## 3. **ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### ğŸ“Š **å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»**

#### âœ… è¡¨æ ¼ 1 & 2ï¼šLongBench v2 æ€§èƒ½å¯¹æ¯”ï¼ˆéƒ¨åˆ†æ‘˜è¦ï¼‰

| Model | Method | Overall | Easy | Hard | Short | Medium | Long |
|-------|--------|--------|------|------|-------|--------|------|
| DeepSeek-R1 | Full | 44.33 | 48.44 | 41.80 | 48.89 | 40.00 | 45.37 |
| DeepSeek-R1 | Jump3 | 42.54 | 43.75 | 41.80 | 50.00 | 39.07 | 37.04 |
| DeepSeek-R1 | **HyLRA** | **46.32** | **49.48** | **44.37** | **52.78** | **43.72** | **40.74** |

> ğŸ’¡ **ç»“è®º**ï¼š
- HyLRA **ä¸ä»…ä¼˜äºæ‰€æœ‰ sparse baselineï¼ˆJump3ï¼‰**
- ç”šè‡³åœ¨å¤šä¸ªå­ä»»åŠ¡ä¸Š**è¶…è¿‡ full attention**ï¼Œè¯´æ˜å…¶èƒ½æœ‰æ•ˆè¿‡æ»¤å™ªå£°å¹¶èšç„¦å…³é”®ä¸Šä¸‹æ–‡ã€‚

#### âœ… è¡¨æ ¼ 3ï¼šæ•ˆç‡å¯¹æ¯”ï¼ˆSequence Length ä» 8K â†’ 60Kï¼‰

| Seq Len | Method | TTFT (ms) | Gen Throughput | Overall Throughput | Speedup |
|--------|--------|-----------|----------------|--------------------|---------|
| 8K     | Full      | 16.81 | 1225 | 11033 | 1.00 |
|        | Jump3     | 15.27 | 1229 | 11068 | 1.15 |
|        | **HyLRA** | **14.85** | **1145** | **10309** | **1.06** |
| 60K    | Full      | 57.69 | 177 | 2835 | 1.00 |
|        | Jump3     | 53.98 | 273 | 4730 | 1.54 |
|        | **HyLRA** | **56.62** | **258** | **4128** | **1.45** |

> ğŸ”º **è¶‹åŠ¿å‘ç°**ï¼š
- éšç€ sequence length å¢åŠ ï¼ŒHyLRA çš„ speedup æŒç»­ä¸Šå‡ï¼ˆæœ€é«˜è¾¾ **1.45Ã— æ•´ä½“åŠ é€Ÿ**ï¼‰
- å°½ç®¡ TTFT æ¥è¿‘ full attentionï¼Œä½†åœ¨é•¿åºåˆ—ä¸‹ç”Ÿæˆååå¤§å¹…æå‡ï¼Œä½“ç°å…¶å¯¹ KV cache æ‰«æçš„ä¼˜åŒ–æ•ˆæœã€‚

---

### ğŸ” **æ¶ˆèå®éªŒä¸åˆ†æï¼ˆéšå«äºä¸»å®éªŒä¸­ï¼‰**
è™½ç„¶æœªå•ç‹¬åˆ—å‡º ablation studyï¼Œä½†ä»ä»¥ä¸‹æ–¹é¢å¯çœ‹å‡ºè®¾è®¡æœ‰æ•ˆæ€§ï¼š
- **Jump3 vs HyLRA**ï¼šè¯æ˜äº†**åŠ¨æ€è§„åˆ’æ±‚è§£æœ€ä¼˜è·¯å¾„**ä¼˜äºå›ºå®šè·³è·ƒç­–ç•¥ï¼›
- **reuse å±‚æ•°æ¯”ä¾‹æ§åˆ¶**ï¼šé€šè¿‡ similarity threshold æ§åˆ¶ full/reuse æ¯”ä¾‹ï¼ŒéªŒè¯äº† trade-off å¯è°ƒï¼›
- **block-level adaptation**ï¼šæ”¯æŒ block-wise sparsityï¼ˆå¦‚ QUESTï¼‰ï¼Œæ˜¾ç¤ºç³»ç»Ÿçº§å…¼å®¹æ€§ã€‚

---

## 4. **å…³é”®ç»“è®ºå’Œå‘ç°**

### âœ… **ä¸»è¦å‘ç°**
1. **Transformer å±‚å­˜åœ¨æ˜¾è‘—çš„ heterogeneity**ï¼š
   - å¹¶éæ‰€æœ‰å±‚éƒ½é€‚åˆç¨€ç–åŒ–ï¼›**æ•æ„Ÿå±‚å¿…é¡»ä¿ç•™ full attention**ã€‚
2. **ç›¸é‚»å±‚ attention pattern é«˜åº¦ç¨³å®š**ï¼š
   - top-k tokens åœ¨è¿ç»­å±‚é—´é«˜åº¦é‡åˆï¼Œä¸º index reuse æä¾›ç†è®ºåŸºç¡€ã€‚
3. **HyLRA å®ç°å¸•ç´¯æ‰˜å‰æ²¿çªç ´**ï¼š
   - åœ¨ accuracy å‡ ä¹æ— æŸï¼ˆ<1% ä¸‹é™ï¼‰å‰æä¸‹ï¼Œè·å¾—é«˜è¾¾ **1.45Ã— æ¨ç†åŠ é€Ÿ**ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰ sparse attention æ–¹æ³•ã€‚
4. **é€‚ç”¨äºé‡åŒ–æ¨¡å‹ä¸é•¿åºåˆ—åœºæ™¯**ï¼š
   - åœ¨ QWQ-32B-W8A8 ä¸ŠåŒæ ·æœ‰æ•ˆï¼Œå…·å¤‡éƒ¨ç½²æ½œåŠ›ã€‚

---

### âš ï¸ **å±€é™æ€§**
1. **ä¾èµ– offline profiling**ï¼š
   - éœ€è¦é¢„å…ˆè¿è¡Œ full attention è·å– attention similarity matrixï¼Œå¢åŠ éƒ¨ç½²å‰æˆæœ¬ã€‚
2. **å‡è®¾ attention pattern ç¨³å®šæ€§**ï¼š
   - å¯¹è¾“å…¥å˜åŒ–å‰§çƒˆçš„ä»»åŠ¡ï¼ˆå¦‚è·³è·ƒå¼å¯¹è¯ï¼‰å¯èƒ½å½±å“ reuse å‡†ç¡®æ€§ã€‚
3. **æœªå¤„ç† encoder-decoder æ¶æ„**ï¼š
   - å½“å‰å·¥ä½œèšç„¦ decoder-only æ¨¡å‹ï¼ˆå¦‚ Llamaã€Qwenï¼‰ï¼Œå°šæœªæ‰©å±•è‡³ T5 ç±»ç»“æ„ã€‚

---

### ğŸ”® **æœªæ¥å·¥ä½œæ–¹å‘**
1. **Online Adaptation Mechanism**ï¼š
   - è®¾è®¡è½»é‡çº§ online profilerï¼Œå®æ—¶è°ƒæ•´ reuse policyï¼Œé€‚åº”åŠ¨æ€è¾“å…¥ã€‚
2. **Cross-model Generalization**ï¼š
   - æ¢ç´¢æ˜¯å¦å¯åœ¨ä¸€ä¸ªæ¨¡å‹ä¸Šå­¦å¾—çš„ policy è¿ç§»åˆ°å…¶ä»–æ¶æ„ã€‚
3. **Integration with Other KV Cache Compression Techniques**ï¼š
   - ç»“åˆ PyramidInferã€ShadowKV ç­‰æ–¹æ³•è¿›ä¸€æ­¥å‹ç¼©å†…å­˜ã€‚
4. **Support for Training & Fine-tuning**ï¼š
   - å°† HyLRA æ€æƒ³å¼•å…¥è®­ç»ƒé˜¶æ®µï¼Œæ¢ç´¢ç¨€ç–åŒ–çš„ç«¯åˆ°ç«¯å­¦ä¹ ã€‚

---

## âœ… **æ€»ç»“ä¸€å¥è¯**
> **HyLRA é€šè¿‡æ­ç¤º LLM ä¸­ attention çš„å±‚é—´å¼‚è´¨æ€§ä¸ç¨³å®šæ€§ï¼Œæå‡ºäº†ä¸€ç§â€œæ•æ„Ÿå±‚å…¨ç®— + å®¹å¿å±‚ç´¢å¼•å¤ç”¨â€çš„æ··åˆç­–ç•¥ï¼Œåˆ©ç”¨åŠ¨æ€è§„åˆ’æ±‚è§£æœ€ä¼˜æ‰§è¡Œè·¯å¾„ï¼Œåœ¨å‡ ä¹ä¸æŸå¤±ç²¾åº¦çš„å‰æä¸‹å®ç°é«˜è¾¾ 1.45Ã— çš„é•¿ä¸Šä¸‹æ–‡æ¨ç†åŠ é€Ÿï¼Œæ˜¯å½“å‰æœ€é«˜æ•ˆçš„ sparse attention æ¡†æ¶ä¹‹ä¸€ã€‚**

ğŸ”— å¼€æºåœ°å€ï¼š[/r/unified-cache-management-CF80/](https://github.com/r/unified-cache-management-CF80/)

</details>

---

### 13. [Prism: Efficient Test-Time Scaling via Hierarchical Search and Self-Verification for Discrete Diffusion Language Models](https://arxiv.org/abs/2602.01842)

**Authors**: Jinbin Bai, Yixuan Li, Yuchen Zhu, Yi Xin, Qingyu Shi, Aosong Feng, Xiaohong Liu, Molei Tao, Jianru Xue, Xiangtai Li, Ming-Hsuan Yang  
**Category**: cs.LG  
**Published**: 2026-02-03  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2602.01842v1  

#### Abstract
Inference-time compute has re-emerged as a practical way to improve LLM reasoning. Most test-time scaling (TTS) algorithms rely on autoregressive decoding, which is ill-suited to discrete diffusion language models (dLLMs) due to their parallel decoding over the entire sequence. As a result, developi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šPRISM: Efficient Test-Time Scaling via Hierarchical Search and Self-Verification for Discrete Diffusion Language Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
- **ç¦»æ•£æ‰©æ•£è¯­è¨€æ¨¡å‹**ï¼ˆdLLMsï¼‰åœ¨æ¨ç†æ—¶éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨é¢å¤–è®¡ç®—èµ„æºè¿›è¡Œ**æµ‹è¯•æ—¶æ‰©å±•**ï¼ˆTest-Time Scaling, TTSï¼‰ï¼Œå› ä¸ºå…¶å¹¶è¡Œå»å™ªæœºåˆ¶ä¸ä¼ ç»Ÿçš„è‡ªå›å½’ï¼ˆARï¼‰è§£ç ä¸å…¼å®¹ã€‚
- ç°æœ‰çš„ TTS æ–¹æ³•ï¼ˆå¦‚ Best-of-Nã€Tree Searchï¼‰ä¾èµ–äºå¤–éƒ¨éªŒè¯å™¨æˆ–åºåˆ—ç”Ÿæˆç»“æ„ï¼Œæ— æ³•ç›´æ¥åº”ç”¨äº dLLMsã€‚
- ç®€å•åœ°å¯¹ dLLMs æ‰§è¡Œ Best-of-N æœç´¢ä¼šå¯¼è‡´é«˜æ˜‚çš„**å‡½æ•°è°ƒç”¨æ¬¡æ•°**ï¼ˆNumber of Function Evaluations, NFEï¼‰ï¼Œæ•ˆç‡ä½ä¸‹ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
ä½œè€…æå‡º **PRISM**ï¼ˆPruning, Remasking, and Integrated Self-verification Methodï¼‰ï¼Œä¸€ä¸ªä¸“ä¸º dLLMs è®¾è®¡çš„é«˜æ•ˆ TTS æ¡†æ¶ï¼ŒåŒ…å«ä¸‰å¤§æ ¸å¿ƒç»„ä»¶ï¼š

#### ï¼ˆ1ï¼‰åˆ†å±‚è½¨è¿¹æœç´¢**ï¼ˆHierarchical Trajectory Search, HTSï¼‰
- å°†æ•´ä¸ªå»å™ªè¿‡ç¨‹åˆ’åˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼š
  - **éšæœºæ¢ç´¢**ï¼ˆStochastic Explorationï¼‰ï¼šåˆæœŸä¿æŒå®½è½¨è¿¹æ± ï¼ˆN æ¡è·¯å¾„ï¼‰ï¼Œä¸è¿›è¡Œå‰ªæã€‚
  - **æ¸è¿›ç¨€ç–åŒ–**ï¼ˆProgressive Thinningï¼‰ï¼šåœ¨ä¸­å‰æœŸæ ¹æ®**è‡ªéªŒè¯åé¦ˆ**ï¼ˆSVFï¼‰åŠ¨æ€å‰ªæä½è´¨é‡è½¨è¿¹ï¼Œå¹¶é€šè¿‡å±€éƒ¨é‡æ©ç åˆ†æ”¯ä¿ç•™å¤šæ ·æ€§ã€‚
  - **æœ€ç»ˆç²¾ç‚¼**ï¼ˆFinal Refinementï¼‰ï¼šä»…å¯¹å°‘é‡é«˜è´¨é‡è½¨è¿¹ï¼ˆK æ¡ï¼‰å®Œæˆå‰©ä½™å»å™ªæ­¥éª¤ã€‚
- è½¨è¿¹æ•°é‡éšæ—¶é—´å‘ˆå‡ ä½•è¡°å‡ï¼Œæ˜¾è‘—é™ä½æ€» NFEã€‚

#### ï¼ˆ2ï¼‰å±€éƒ¨åˆ†æ”¯ä¸éƒ¨åˆ†é‡æ©ç **ï¼ˆLocal Branching with Partial Remaskingï¼‰
- åœ¨é«˜åˆ†è½¨è¿¹ä¸Šé€‰æ‹©**ä½ç½®ä¿¡åº¦ token** è¿›è¡Œé‡æ–°æ©ç ï¼Œä¿ç•™â€œé€»è¾‘éª¨æ¶â€ï¼ˆhigh-confidence logic skeletonï¼‰ã€‚
- ä»è¿™äº›éƒ¨åˆ†é‡æ©ç çš„çŠ¶æ€ç»§ç»­å»å™ªï¼Œå®ç°**å¤šæ ·åŒ–å®ç°æ–¹æ¡ˆæ¢ç´¢**ï¼Œé¿å…å®Œå…¨é‡å¯å¯¼è‡´çš„ä¿¡æ¯ä¸¢å¤±ã€‚

#### ï¼ˆ3ï¼‰è‡ªéªŒè¯åé¦ˆ**ï¼ˆSelf-Verified Feedback, SVFï¼‰
- åˆ©ç”¨**åŒä¸€ dLLM è‡ªèº«**ä½œä¸ºè½»é‡çº§äºŒåˆ†ç±»éªŒè¯å™¨ï¼Œåˆ¤æ–­ä¸­é—´ç”Ÿæˆæ˜¯å¦å¯èƒ½æ­£ç¡®ã€‚
- é€šè¿‡è®¾è®¡ç‰¹å®šçš„ Yes/No æé—®æ¨¡æ¿ï¼ˆè§é™„å½• Cï¼‰ï¼Œè®©æ¨¡å‹è¾“å‡º `Yes` æˆ– `No`ï¼Œå¹¶å°†å…¶æ¦‚ç‡ä½œä¸ºè¯„åˆ†ä¾æ®ã€‚
- é¿å…å¼•å…¥é¢å¤–çš„å¤–éƒ¨å¥–åŠ±æ¨¡å‹ï¼ˆExternal Verifierï¼‰ï¼ŒèŠ‚çœæ˜¾å­˜å’Œç³»ç»Ÿå¤æ‚åº¦ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | PRISM | Best-of-N | å¤–éƒ¨éªŒè¯æ–¹æ³• |
|------|-------|----------|-------------|
| **è®¡ç®—æ•ˆç‡** | âœ… è¿‘ä¼¼çº¿æ€§å¢é•¿ $O(N + KT)$ | âŒ äºŒæ¬¡å¢é•¿ $O(NT)$ | âŒ æ›´é«˜ï¼ˆéœ€é¢å¤–å‰å‘ä¼ æ’­ï¼‰ |
| **å†…å­˜å¼€é”€** | âœ… æ— é¢å¤–æ¨¡å‹ | âœ… åŒå·¦ | âŒ éœ€åŠ è½½ç‹¬ç«‹éªŒè¯æ¨¡å‹ |
| **é€‚é…æ€§** | âœ… ä¸“ä¸º dLLMs è®¾è®¡ | âš ï¸ å¯ç”¨ä½†ä½æ•ˆ | âŒ ä¸é€‚ç”¨äºéƒ¨åˆ†æ©ç çŠ¶æ€ |
| **æ§åˆ¶ä¿¡å·æ¥æº** | âœ… å†…ç”Ÿ SVF | âŒ æ— æ’åºèƒ½åŠ› | âœ… å¤–éƒ¨ PRM/ORM |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
æ¶µç›–æ•°å­¦æ¨ç†ä¸ä»£ç ç”Ÿæˆä¸¤å¤§ä»»åŠ¡ï¼š

| ç±»åˆ« | æ•°æ®é›† | æè¿° |
|------|--------|------|
| **æ•°å­¦æ¨ç†** | GSM8K | å°å­¦æ°´å¹³æ•°å­¦åº”ç”¨é¢˜ï¼Œéœ€å¤šæ­¥ç¬¦å·æ¨ç† |
|             | MATH-500 | 500 é“ç«èµ›çº§æ•°å­¦éš¾é¢˜ |
| **ä»£ç ç”Ÿæˆ** | HumanEval | Docstring åˆ° Python å‡½æ•°çš„ç”Ÿæˆä»»åŠ¡ |
|             | MBPP | æ—¥å¸¸ç¼–ç¨‹ä»»åŠ¡ï¼Œå«è‡ªç„¶è¯­è¨€æè¿°ä¸å•å…ƒæµ‹è¯• |

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹**ï¼šLLaDA-8B-Instructã€Dream-7B-Instructã€LLaDA-2.0-mini
- **è¯„ä¼°æ–¹å¼**ï¼šZero-shot è®¾ç½®ä¸‹è¯„ä¼°
- **ä¸»æŒ‡æ ‡**ï¼š
  - æ•°å­¦ä»»åŠ¡ï¼šAccuracy
  - ä»£ç ä»»åŠ¡ï¼šPass@1
- **è®¡ç®—æˆæœ¬åº¦é‡**ï¼š
  - **NFE**ï¼ˆNumber of Function Evaluationsï¼‰ï¼šè¡¡é‡å»å™ªæ­¥éª¤æ€»æ•°
  - **SVF Calls**ï¼šè‡ªéªŒè¯è°ƒç”¨æ¬¡æ•°ï¼ˆå•ç‹¬ç»Ÿè®¡ï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | æè¿° |
|------|------|
| **N=1** | å•æ¬¡é‡‡æ ·ï¼ŒåŸºç¡€æ€§èƒ½åŸºå‡† |
| **Best-of-N**ï¼ˆN=4,8,16ï¼‰ | å¹¶è¡Œç”Ÿæˆ N æ¡ç‹¬ç«‹è½¨è¿¹ï¼Œé€šè¿‡å¤šæ•°æŠ•ç¥¨é€‰æ‹©æœ€ä¼˜ç»“æœ |
| **ReMDM**ï¼ˆWang et al., 2025ï¼‰ | å½“å‰æœ€å…ˆè¿›çš„ dLLM æ¨ç†ä¼˜åŒ–æ–¹æ³•ï¼Œåœ¨ TruthfulQA ä¸Šæ¯”è¾ƒ |
| **å¤–éƒ¨éªŒè¯å™¨**ï¼ˆQwen ç³»åˆ—ï¼‰ | ä½¿ç”¨å¤–éƒ¨ LLM ä½œä¸ºéªŒè¯å™¨ï¼Œä¸ SVF å¯¹æ¯”æ•ˆæœä¸èµ„æºæ¶ˆè€— |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ LLaDA-8B-Instruct ä¸ºä¾‹ï¼‰

| æ–¹æ³• | GSM8K | NFE | MATH-500 | NFE | HumanEval | NFE | MBPP | NFE |
|------|--------|-----|-----------|-----|------------|-----|--------|-----|
| N=1 | 67.58% | 256 | 26.40% | 256 | 54.88% | 512 | 21.80% | 512 |
| Best-of-16 | 87.50% | 4096 | 38.00% | 4096 | 82.32% | 8192 | 35.20% | 8192 |
| **PRISM (K=8)** | **85.30%** | **1048** | **42.80%** | **1304** | **79.27%** | **2480** | **38.20%** | **2576** |

> âœ… **ç»“è®º**ï¼šPRISM åœ¨ä»…ä½¿ç”¨çº¦ **1/4 çš„ NFE** ä¸‹ï¼Œè¾¾åˆ°ç”šè‡³è¶…è¿‡ Best-of-16 çš„æ€§èƒ½ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **æ•ˆç‡æå‡æ˜¾è‘—**ï¼š
  - åœ¨ GSM8K ä¸Šï¼ŒPRISM è¾¾åˆ° 85.30% å‡†ç¡®ç‡ä»…éœ€ 1048 NFEï¼Œè€Œ Best-of-16 éœ€è¦ 4096 NFE â†’ **æé€Ÿè¶… 4Ã—**
  - åœ¨ MATH-500 å’Œ MBPP ä¸Šï¼ŒPRISM å¸¸ä»¥ä¸åˆ°ä¸‰åˆ†ä¹‹ä¸€çš„é¢„ç®—åŒ¹é…æˆ–è¶…è¶Š Best-of-16
- **æ€§èƒ½æ›´å¼º**ï¼š
  - PRISM åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå®ç°äº†**ç»å¯¹æ€§èƒ½çªç ´**ï¼Œä¾‹å¦‚åœ¨ MATH-500 ä¸Šè¾¾åˆ° 42.80%ï¼Œä¼˜äº Best-of-16 çš„ 38.00%
- **æ¶ˆèå®éªŒæ”¯æŒè®¾è®¡æœ‰æ•ˆæ€§**ï¼ˆè¯¦è§ Appendix Bï¼‰ï¼š
  - æœ€ä½³å‰ªæçª—å£ä¸º `[0.1â€“0.6]T`ï¼Œå¤ªæ—©æˆ–å¤ªæ™šå‰ªæå‡æŸå®³æ€§èƒ½
  - ä¸­ç­‰è¡°å‡é€Ÿç‡ `d=1.8` è¡¨ç°æœ€ä½³
  - å­˜æ´»è½¨è¿¹æ•° `S=4` å’Œç›®æ ‡å®½åº¦ `K=8` æä¾›æœ€ä½³æƒè¡¡
  - å‰ªæé—´éš” `i=3` æ•ˆæœæœ€å¥½ï¼Œè¿‡äºé¢‘ç¹ä¼šè¿‡æ—©ä¸¢å¼ƒæ½œåœ¨å¥½è·¯å¾„

### ä¸å…¶ä»– TTS æ–¹æ³•æ¯”è¾ƒ
| æ–¹æ³• | æ€§èƒ½å¢ç›Š | NFE å¼€é”€ | æ˜¯å¦å¼€æº |
|------|---------|----------|----------|
| MEDAL (Huang et al., 2025b) | ~1.4Ã— runtime, +1.4pp | æœªå…¬å¼€ç»†èŠ‚ | âŒ |
| RFG (Chen et al., 2025) | ~9.2% avg gain | ~2Ã— NFE | âŒ |
| **PRISM** | **>10% avg gain** | **~2Ã— NFE** | âœ… å¼€æº |

### ä¸å¤–éƒ¨éªŒè¯å™¨å¯¹æ¯”ï¼ˆTable 3ï¼‰
| éªŒè¯å™¨ | GSM8K Pass@1 | å‚æ•°é‡ | æ˜¯å¦é¢å¤–åŠ è½½ |
|--------|---------------|--------|--------------|
| SVF (Ours) | 85.30% | 8B | âŒï¼ˆå¤ç”¨åŸæ¨¡å‹ï¼‰ |
| Qwen-7B | 84.39% | 15B | âœ… |
| Qwen2-7B | 85.98% | 15B | âœ… |
| Qwen3-8B | 87.35% | 16B | âœ… |

> ğŸ” **å‘ç°**ï¼šè™½ç„¶æ›´å¤§å¤–éƒ¨éªŒè¯å™¨ç•¥ä¼˜ï¼Œä½†éœ€é¢å¤–éƒ¨ç½²ä¸”å ç”¨æ›´å¤šæ˜¾å­˜ï¼ˆå¸¸è¶…å‡º 40GB A100 å®¹é‡ï¼‰ã€‚**SVF åœ¨é›¶é¢å¤–å‚æ•°ä¸‹å®ç°æ¥è¿‘æœ€ä¼˜æ€§èƒ½**ï¼Œæå…·å®ç”¨æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **dLLMs å®Œå…¨å¯ä»¥å—ç›Šäºé«˜æ•ˆçš„ TTS**ï¼Œä½†éœ€è¦ä¸“é—¨è®¾è®¡çš„æœç´¢ç­–ç•¥ã€‚
2. **HTS æ¶æ„å°†è®¡ç®—é›†ä¸­åœ¨â€œé€»è¾‘å½¢æˆæœŸâ€**ï¼ˆearly-to-mid denoising windowï¼‰ï¼Œå¤§å¹…æå‡æ•ˆç‡ã€‚
3. **SVF æ˜¯ä¸€ç§ä½æˆæœ¬ã€é«˜æ•ˆç›Šçš„å†…ç”ŸéªŒè¯æœºåˆ¶**ï¼Œæ— éœ€å¤–éƒ¨æ¨¡å‹å³å¯æä¾›å¯é çš„æ’åºä¿¡å·ã€‚
4. **å±€éƒ¨é‡æ©ç åˆ†æ”¯æœ‰æ•ˆç»´æŒå¤šæ ·æ€§**ï¼Œé˜²æ­¢å› å‰ªæå¯¼è‡´çš„æ¨¡å¼åç¼©ã€‚
5. **PRISM å®ç°äº†è¿‘çº¿æ€§çš„è®¡ç®—æ‰©å±•æ€§**ï¼š$C_{HTS} \sim O(N + KT)$ï¼Œè¿œä¼˜äºä¼ ç»Ÿ $O(NT)$ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡ prompt è®¾è®¡**ï¼šSVF çš„æ•ˆæœé«˜åº¦ä¾èµ–äºéªŒè¯æç¤ºè¯çš„è´¨é‡ã€‚
- **å¯¹å‰ªæç­–ç•¥æ•æ„Ÿ**ï¼šè‹¥å‰ªæçª—å£è®¾ç½®ä¸å½“ï¼Œå¯èƒ½å¯¼è‡´æ—©æœŸè¯¯åˆ ä¼˜è´¨è·¯å¾„ã€‚
- **å½“å‰ä»…é€‚ç”¨äº block-wise dLLMs**ï¼šå¯¹äºå…¨åºåˆ—å¹¶è¡Œå»å™ªæ¨¡å‹éœ€è¿›ä¸€æ­¥é€‚é…ã€‚
- **SVF å¯èƒ½å­˜åœ¨è¿‡åº¦è‡ªä¿¡é£é™©**ï¼šåœ¨åˆ†å¸ƒå¤–è¾“å…¥ä¸Šå¯èƒ½å‡ºç°é”™è¯¯è‡ªä¿¡åˆ¤æ–­ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† PRISM æ‰©å±•è‡³å›¾åƒã€éŸ³é¢‘ç­‰å¤šæ¨¡æ€æ‰©æ•£æ¨¡å‹ã€‚
- æ¢ç´¢æ›´æ™ºèƒ½çš„åŠ¨æ€å‰ªæè°ƒåº¦å™¨ï¼ˆå¦‚åŸºäºä¸ç¡®å®šæ€§ä¼°è®¡è‡ªåŠ¨è°ƒæ•´çª—å£ï¼‰ã€‚
- ç»“åˆè®­ç»ƒæ—¶å¾®è°ƒï¼Œä½¿æ¨¡å‹æ›´é€‚åº” SVF åˆ¤æ–­ä»»åŠ¡ã€‚
- ç ”ç©¶å¦‚ä½•å°† PRISM åº”ç”¨äºé•¿æ–‡æœ¬ç”Ÿæˆä¸è§„åˆ’ä»»åŠ¡ã€‚

---

> ğŸ“¦ **ä»£ç å·²å¼€æº**ï¼šhttps://github.com/viiika/Prism  
> ğŸ“… **é¢„å°æœ¬å‘å¸ƒæ—¥æœŸ**ï¼šJanuary 30, 2026

</details>

---

### 14. [EvoOpt-LLM: Evolving industrial optimization models with large language models](https://arxiv.org/abs/2602.01082)

**Authors**: Yiliu He, Tianle Li, Binghao Ji, Zhiyuan Liu, Di Huang  
**Category**: cs.AI  
**Published**: 2026-02-03  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.01082v1  

#### Abstract
Optimization modeling via mixed-integer linear programming (MILP) is fundamental to industrial planning and scheduling, yet translating natural-language requirements into solver-executable models and maintaining them under evolving business rules remains highly expertise-intensive. While large langu...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡ã€ŠEvoOpt-LLM: Evolving industrial optimization models with large language modelsã€‹æ ¸å¿ƒæ€»ç»“**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å·¥ä¸šçº§ä¼˜åŒ–å»ºæ¨¡ï¼ˆå¦‚MILPï¼‰åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **æ¨¡å‹æ„å»ºé—¨æ§›é«˜**ï¼šå°†è‡ªç„¶è¯­è¨€æè¿°çš„éœ€æ±‚è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„æ•°å­¦è§„åˆ’æ¨¡å‹ä¾èµ–å¤§é‡ä¸“å®¶ç»éªŒã€‚
- **æ¨¡å‹éš¾ä»¥åŠ¨æ€æ¼”åŒ–**ï¼šä¸šåŠ¡è§„åˆ™é¢‘ç¹å˜åŒ–æ—¶ï¼Œä¼ ç»Ÿæ–¹æ³•éœ€ä»å¤´é‡å»ºæ¨¡å‹ï¼Œæˆæœ¬é«˜æ˜‚ä¸”æ˜“å‡ºé”™ã€‚
- **æ¨¡å‹è§„æ¨¡å¤§å¯¼è‡´æ±‚è§£æ•ˆç‡ä½**ï¼šå¤§è§„æ¨¡MILPåŒ…å«æˆåƒä¸Šä¸‡å˜é‡ï¼Œæ±‚è§£è€—æ—¶é•¿ï¼Œä¼ ç»ŸpresolveæŠ€æœ¯å¯¹éšå«ä¸šåŠ¡é€»è¾‘è¯†åˆ«èƒ½åŠ›æœ‰é™ã€‚

ç°æœ‰LLMæ–¹æ³•å¤šèšç„¦äºä¸€æ¬¡æ€§ç”Ÿæˆç®€åŒ–æ¨¡å‹ï¼Œç¼ºä¹å¯¹**å…¨ç”Ÿå‘½å‘¨æœŸç®¡ç†**çš„æ”¯æŒï¼Œå°¤å…¶åœ¨solver-levelæœ‰æ•ˆæ€§ã€åŠ¨æ€æ›´æ–°èƒ½åŠ›å’Œå¯æ‰©å±•æ€§æ–¹é¢è¡¨ç°ä¸è¶³ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯**
ä½œè€…æå‡ºäº† **EvoOpt-LLM** â€”â€”ä¸€ä¸ªåŸºäºLLMçš„ç»Ÿä¸€æ¡†æ¶ï¼Œæ”¯æŒå·¥ä¸šä¼˜åŒ–æ¨¡å‹çš„**å…¨ç”Ÿå‘½å‘¨æœŸè‡ªåŠ¨åŒ–ç®¡ç†**ï¼Œæ¶µç›–ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ï¼š

| æ¨¡å— | åŠŸèƒ½ |
|------|------|
| **Automated Modeling** | å°†è‡ªç„¶è¯­è¨€éœ€æ±‚è‡ªåŠ¨è½¬æ¢ä¸ºå¯æ‰§è¡Œçš„MILPä»£ç  |
| **Constraint Injection** | åœ¨å·²æœ‰å¯æ‰§è¡Œæ¨¡å‹ä¸­åŠ¨æ€æ³¨å…¥æ–°çš„ä¸šåŠ¡çº¦æŸï¼ˆå¦‚äººåŠ›é™åˆ¶ã€åˆ†æ‰¹äº¤ä»˜ç­‰ï¼‰ï¼Œä¿æŒåŸç›®æ ‡å‡½æ•°ä¸å˜ |
| **End-to-End Variable Pruning** | åŸºäºå†å²æ•°æ®é¢„æµ‹å¹¶å›ºå®šå†—ä½™å˜é‡ä¸ºé›¶ï¼Œå®ç°æ¨¡å‹å‹ç¼©ä»¥æå‡æ±‚è§£æ•ˆç‡ |

è¯¥æ¡†æ¶åŸºäº **7Bå‚æ•°çš„openPangu-Embedded-7B** æ¨¡å‹ï¼Œå¹¶é€šè¿‡ **LoRA** è¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒï¼Œä»…éœ€å°‘é‡æ ‡æ³¨æ ·æœ¬å³å¯è·å¾—é¢†åŸŸä¸“ä¸šåŒ–èƒ½åŠ›ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | EvoOpt-LLMä¼˜åŠ¿ |
|------|----------------|
| **ä»»åŠ¡å®Œæ•´æ€§** | è¦†ç›–å»ºæ¨¡â†’æ¼”åŒ–â†’åŠ é€Ÿå…¨è¿‡ç¨‹ï¼Œè€Œéå•ä¸€ç”Ÿæˆä»»åŠ¡ |
| **æ•°æ®æ•ˆç‡** | ä»…ç”¨3,000æ ·æœ¬å³è¾¾é«˜æ€§èƒ½ï¼›å…³é”®çªç ´å‡ºç°åœ¨<1,500æ ·æœ¬é˜¶æ®µ |
| **solverå…¼å®¹æ€§** | è¾“å‡ºæ¨¡å‹å…·å¤‡é«˜executabilityï¼ˆ65.9%ï¼‰ï¼Œè¿œè¶…é€šç”¨LLMç›´æ¥ç”Ÿæˆç»“æœ |
| **åŠ¨æ€é€‚åº”æ€§** | æ”¯æŒLP-levelçš„ç»“æ„åŒ–ç¼–è¾‘ï¼Œå…è®¸å¢é‡å¼æ¨¡å‹æ¼”è¿› |
| **è®¡ç®—æ•ˆç‡å¢ç›Š** | å˜é‡å‰ªæF1è¾¾~0.56ï¼ˆä»…400æ ·æœ¬è®­ç»ƒï¼‰ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿpresolveæ— æ³•æ•æ‰çš„æ•°æ®é©±åŠ¨æ¨¡å¼ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **Automated Modelingæ¨¡å—**ï¼š  
  æ„å»ºäº†ä¸€ä¸ªåŒ…å«3,000ä¸ªæ ·æœ¬çš„fine-tuningæ•°æ®é›†ï¼Œè¦†ç›–å¤šç§ORé—®é¢˜ç±»å‹ï¼š
  | ç±»å‹ | å æ¯” |
  |-----|------|
  | Mixed Integer Linear Programming | 33% |
  | Linear Programming | 22% |
  | Network Optimization | 12% |
  | Scheduling Optimization | 9% |
  | å…¶ä»–ï¼ˆStochastic, Nonlinearç­‰ï¼‰ | 24% |

- **Constraint Injectionæ¨¡å—**ï¼š  
  åŸºäºä¸€ä¸ªåŸºå‡†ä¾›åº”é“¾ä¼˜åŒ–LPæ–‡ä»¶ï¼Œéšæœºé‡‡æ ·å‚æ•°ï¼ˆå¦‚setupæ—¶é—´ã€äººåŠ›ä¸Šé™ã€æ‰¹é‡å•ä½ç­‰ï¼‰ï¼Œè‡ªåŠ¨ç”Ÿæˆâ€œåŸå§‹LP + è‡ªç„¶è¯­è¨€çº¦æŸ â†’ æ‰©å±•åLPâ€çš„é…å¯¹æ•°æ®ã€‚

- **Variable Pruningæ¨¡å—**ï¼š  
  åˆ©ç”¨çœŸå®å·¥ä¸šè°ƒåº¦è®°å½•æ„å»ºå°è§„æ¨¡ç­‰ä»·å®ä¾‹ï¼Œç»“åˆå›¾ç®—æ³•ä¸ä¼˜åŒ–æ±‚è§£å™¨ç”Ÿæˆé«˜è´¨é‡å‰ªææ ‡ç­¾ï¼ˆå³å“ªäº›å˜é‡æ’ä¸º0ï¼‰ã€‚

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

#### **ç¡¬ä»¶ç¯å¢ƒ**
- å››å¼ åä¸ºAscend 910B NPUï¼Œæ¯å¼ 64GB HBMå†…å­˜
- æ”¯æŒé•¿ä¸Šä¸‹æ–‡è¾“å…¥å¤„ç†ï¼ˆé€‚ç”¨äºæ•°ç™¾è‡³æ•°åƒè¡ŒLPæ–‡ä»¶ï¼‰

#### **è½¯ä»¶æ ˆ**
- CANN 8.1.rc1, PyTorch 2.5.1 + torch_npu, Transformers 4.53.2, vLLM-Ascend
- ä½¿ç”¨LoRAè¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒï¼Œåˆ†åˆ«è®­ç»ƒä¸‰ä¸ªä»»åŠ¡ä¸“ç”¨adapter

#### **è¯„ä¼°æŒ‡æ ‡**

| æ¨¡å— | ä¸»è¦æŒ‡æ ‡ |
|------|----------|
| **Automated Modeling** | Generation Rate, Executability Rate, Accuracy Rate |
| **Constraint Injection** | ç»“æ„ä¸€è‡´æ€§ã€æ˜¯å¦ä¿ç•™åŸç›®æ ‡ã€æ–°çº¦æŸæ­£ç¡®æ€§ï¼ˆäººå·¥+è‡ªåŠ¨éªŒè¯ï¼‰ |
| **Variable Pruning** | Precision, Recall, F1 Scoreï¼ˆé’ˆå¯¹å¯å®‰å…¨ç½®é›¶çš„å˜é‡ï¼‰ |

#### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
æ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºå¤šä¸ªå¤–éƒ¨åŸºçº¿ï¼Œè€Œæ˜¯ä»¥å†…ç½®å¯¹ç…§ä¸ºä¸»ï¼š
- **Base Modelï¼ˆæœªå¾®è°ƒï¼‰ vs. LoRA-finetuned Model**ï¼šç”¨äºéªŒè¯å¾®è°ƒæ•ˆæœ
- **ä¸åŒæ•°æ®é‡ä¸‹çš„æ€§èƒ½æ›²çº¿**ï¼šå±•ç¤ºæ•°æ®æ•ˆç‡
- **ä¸ä¼ ç»Ÿpresolveå¯¹æ¯”**ï¼šå¼ºè°ƒå…¶æ— æ³•åˆ©ç”¨å†å²è¡Œä¸ºæ¨¡å¼è¿›è¡Œæ™ºèƒ½å‰ªæ

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… **Automated Modeling æ€§èƒ½**
| æŒ‡æ ‡ | æ•°å€¼ï¼ˆ3,000æ ·æœ¬ï¼‰ | æ•°æ®æ•ˆç‡è¡¨ç° |
|------|--------------------|-------------|
| **Generation Rate** | **91%** | è¡¨ç¤ºå‡ ä¹æ€»èƒ½è¾“å‡ºå®Œæ•´ä»£ç  |
| **Executability Rate** | **65.9%** | ç”Ÿæˆä»£ç å¯é€šè¿‡è¯­æ³•è§£æå¹¶è¢«CPLEX/Gurobiæ‰§è¡Œ |
| **Semantic Accuracy** | **26.37%** | è§£å‡ºæœ€ä¼˜è§£ä¸”ä¸æ ‡å‡†æ¨¡å‹ä¸€è‡´çš„æ¯”ä¾‹ |

> âš¡ **é‡è¦å‘ç°**ï¼šå½“è®­ç»ƒæ ·æœ¬å°‘äº1,500æ—¶å·²å‡ºç°**è´¨å˜è·ƒè¿**â€”â€”executabilityä»2.4%é£™å‡è‡³38.2%ï¼Œè¡¨æ˜LoRAæé€‚åˆä½èµ„æºåœºæ™¯ä¸‹çš„ORçŸ¥è¯†æ³¨å…¥ã€‚

---

#### âœ… **Constraint Injection æ•ˆæœ**
- å¾®è°ƒåçš„æ¨¡å‹èƒ½å‡†ç¡®è¯†åˆ«æ–°å¢çº¦æŸè¯­ä¹‰ï¼ˆå¦‚â€œæ¯ä¸ªç­æ¬¡æœ€å¤š10äººä¸Šç­â€ï¼‰
- æ­£ç¡®å¼•å…¥è¾…åŠ©å˜é‡ï¼ˆå¦‚`ym,t`: æœºå™¨måœ¨tæ—¶æ®µè¿è¡Œï¼‰ã€å‚æ•°ï¼ˆ`Rt`: tæ—¶æ®µå¯ç”¨äººåŠ›ï¼‰
- æ·»åŠ å½¢å¼è§„èŒƒçš„çº¿æ€§çº¦æŸï¼ˆå¦‚ `âˆ‘m rmÂ·ym,t â‰¤ Rt`ï¼‰
- å®Œå…¨ä¿ç•™åŸæœ‰ç›®æ ‡å‡½æ•°ä¸çº¦æŸç»“æ„ï¼Œæ— ç ´åæ€§ä¿®æ”¹
- ç›¸æ¯”æœªå¾®è°ƒæ¨¡å‹ï¼ˆä»…è¾“å‡ºæ¦‚å¿µæ€§æè¿°ï¼Œä¸å¯æ‰§è¡Œï¼‰ï¼Œfine-tunedç‰ˆæœ¬è¾“å‡º**solver-readyæ¨¡æ¿**

---

#### âœ… **Variable Pruning æ€§èƒ½**
| æŒ‡æ ‡ | æ•°å€¼ï¼ˆ400æ ·æœ¬è®­ç»ƒï¼‰ |
|------|----------------------|
| **Peak F1 Score** | **~0.56** |
| **æœ€ä½³é€‚ç”¨èŒƒå›´** | ~350â€“400è¡ŒLPæ–‡ä»¶ |
| **Precision & Recallè¶‹åŠ¿** | éšæ–‡ä»¶å¢å¤§è€Œä¸‹é™ |

> ğŸ” åœ¨ä¸­ç­‰è§„æ¨¡LPä¸Šè¡¨ç°å‡ºæœ‰æ„ä¹‰çš„å‰ªæèƒ½åŠ›ï¼Œå°½ç®¡F1æœªè¿‡åŠï¼Œä½†åœ¨ä»…æœ‰400æ ·æœ¬ä¸‹å·²ä¼˜äºçº¯è§„åˆ™æ–¹æ³•å¯¹å¤æ‚äº¤äº’å†—ä½™çš„è¯†åˆ«ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**
è™½æœªè®¾ç‹¬ç«‹æ¶ˆèç« èŠ‚ï¼Œä½†ä»¥ä¸‹åˆ†æå…·æœ‰æ¶ˆèæ€§è´¨ï¼š
- **æ•°æ®é‡å½±å“åˆ†æ**ï¼ˆFig. 2ï¼‰ï¼šè¯æ˜æ€§èƒ½éšæ•°æ®å¢åŠ å•è°ƒä¸Šå‡ï¼Œä¸”å­˜åœ¨ä¸´ç•Œç‚¹ï¼ˆ~1,200â€“1,500æ ·æœ¬ï¼‰
- **ä¸Šä¸‹æ–‡é•¿åº¦å½±å“**ï¼ˆFig. 5ï¼‰ï¼šæ˜¾ç¤ºå½“å‰æ¨¡å‹åœ¨è¶…è¿‡~450è¡Œåæ€§èƒ½éª¤é™ï¼Œæ­ç¤º**context windowé™åˆ¶**æ˜¯ä¸»è¦ç“¶é¢ˆ
- **post-processingä¿®å¤æœºåˆ¶ä½œç”¨**ï¼šè½»é‡çº§è§„åˆ™ä¿®å¤æå‡äº†executabilityï¼Œè¯´æ˜ç«¯åˆ°ç«¯ç”Ÿæˆä»éœ€è¾…åŠ©æ ¡æ­£

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **LoRAå¾®è°ƒå¯åœ¨æä½æ•°æ®é‡ä¸‹èµ‹äºˆLLMå¼ºå¤§çš„ORå»ºæ¨¡èƒ½åŠ›**ï¼Œå°¤å…¶åœ¨<1,500æ ·æœ¬æ—¶å³å®ç°ä»â€œä¸å¯æ‰§è¡Œâ€åˆ°â€œéƒ¨åˆ†å¯ç”¨â€çš„è·¨è¶Šã€‚
2. **ä¼˜åŒ–æ¨¡å‹åº”è¢«è§†ä¸ºå¯ç¼–è¾‘å¯¹è±¡**ï¼ŒEvoOpt-LLMé¦–æ¬¡ç³»ç»Ÿå®ç°äº†åŸºäºè‡ªç„¶è¯­è¨€æŒ‡ä»¤çš„LP-levelç»“æ„åŒ–ç¼–è¾‘ï¼ˆconstraint injectionï¼‰ï¼Œæ”¯æŒå·¥ä¸šç³»ç»Ÿçš„æ•æ·è¿­ä»£ã€‚
3. **å˜é‡å‰ªæå¯ä½œä¸ºæ•°æ®é©±åŠ¨çš„é¢„å¤„ç†æ­¥éª¤**ï¼Œè¶…è¶Šä¼ ç»ŸåŸºäºä»£æ•°è§„åˆ™çš„presolveï¼Œæ•æ‰ç”±å†å²è¿è¥å½¢æˆçš„éšæ€§ä¸šåŠ¡è§„å¾‹ã€‚
4. **ä¸‰æ¨¡å—å½¢æˆé—­ç¯å·¥ä½œæµ**ï¼šå…ˆè‡ªåŠ¨ç”Ÿæˆbaselineæ¨¡å‹ â†’ åŠ¨æ€æ³¨å…¥æ–°è§„åˆ™ â†’ å‰ªæåŠ é€Ÿæ±‚è§£ï¼Œæ„æˆé¢å‘å·¥ä¸šéƒ¨ç½²çš„å®Œæ•´pipelineã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
| å±€é™ | æè¿° |
|------|------|
| **ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶** | å½“å‰æœ€å¤§åºåˆ—é•¿åº¦åˆ¶çº¦äº†å¯¹è¶…å¤§è§„æ¨¡LPï¼ˆ>1,500è¡Œï¼‰çš„æœ‰æ•ˆå¤„ç†ï¼ŒF1è¶‹è¿‘äº0 |
| **æ³›åŒ–èƒ½åŠ›å—é™** | å¯¹å®Œå…¨æ–°é¢–çš„é—®é¢˜ç»“æ„æˆ–æç«¯å¤æ‚çš„è€¦åˆçº¦æŸä»éš¾ä»¥ä¿è¯æ­£ç¡®æ€§ |
| **è¯­ä¹‰å‡†ç¡®æ€§åä½** | å°½ç®¡executabilityè¾¾65.9%ï¼Œä½†semantic accuracyä»…26.37%ï¼Œè¯´æ˜ç”Ÿæˆæ¨¡å‹å¯èƒ½â€œè·‘å¾—é€šä½†ä¸å¯¹â€ |
| **ä¾èµ–é«˜è´¨é‡æ ‡æ³¨æ•°æ®** | å°¤å…¶variable pruningéœ€å€ŸåŠ©æ±‚è§£å™¨ç”Ÿæˆæ ‡ç­¾ï¼Œæˆæœ¬è¾ƒé«˜ |

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **å‘å±•å±‚æ¬¡åŒ–å‰ªæç­–ç•¥ï¼ˆHierarchical Pruningï¼‰**ï¼šå°†å¤§æ¨¡å‹åˆ†è§£ä¸ºå­ç»“æ„é€çº§å‰ªæï¼Œç¼“è§£å•æ¬¡æ¨ç†å‹åŠ›ã€‚
2. **å¢å¼ºé•¿ä¸Šä¸‹æ–‡å»ºæ¨¡èƒ½åŠ›**ï¼šæ¢ç´¢æ›´é€‚åˆå¤„ç†æ•°åƒè¡Œæ•°å­¦è¡¨è¾¾å¼çš„æ¶æ„æˆ–è®­ç»ƒèŒƒå¼ã€‚
3. **æ‰©å¤§è®­ç»ƒæ•°æ®å¤šæ ·æ€§**ï¼šçº³å…¥æ›´å¤šè¡Œä¸šã€æ›´å¤§è§„æ¨¡çš„çœŸå®MILPæ¡ˆä¾‹ï¼Œæå‡é²æ£’æ€§ã€‚
4. **èåˆsolveråé¦ˆæœºåˆ¶**ï¼šå¼•å…¥test-time RLæˆ–self-refinementæœºåˆ¶ï¼Œè®©æ¨¡å‹æ ¹æ®æ±‚è§£å¤±è´¥åå‘è°ƒæ•´æ¨¡å‹ç”Ÿæˆã€‚
5. **æ„å»ºç«¯åˆ°ç«¯LLMâ€“SolverååŒç³»ç»Ÿ**ï¼šä½¿LLMä¸ä»…å‰ç½®å»ºæ¨¡ï¼Œä¹Ÿèƒ½åœ¨æ±‚è§£è¿‡ç¨‹ä¸­æä¾›å¯å‘å¼å¼•å¯¼ã€‚

---

> ğŸ’¡ **æ€»ä½“è¯„ä»·**ï¼š  
> EvoOpt-LLMä¸æ˜¯è¦å–ä»£ä¼ ç»Ÿoptimization solverï¼Œè€Œæ˜¯å°†å…¶å‰ç½®çš„**å»ºæ¨¡ã€ç»´æŠ¤ã€ç®€åŒ–ç¯èŠ‚æ™ºèƒ½åŒ–**ã€‚å®ƒæ ‡å¿—ç€LLMåœ¨ORé¢†åŸŸçš„åº”ç”¨ä»â€œç©å…·çº§demoâ€è¿ˆå‘â€œå·¥ä¸šçº§å·¥å…·é“¾â€çš„å…³é”®ä¸€æ­¥ï¼Œä¸ºæ„å»º**è‡ªè¿›åŒ–çš„ä¼ä¸šå†³ç­–ç³»ç»Ÿ**æä¾›äº†å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 15. [Harvest: Opportunistic Peer-to-Peer GPU Caching for LLM Inference](https://arxiv.org/abs/2602.00328)

**Authors**: Nikhil Gopal, Kostis Kaffes  
**Category**: cs.LG  
**Published**: 2026-02-03  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.00328v1  

#### Abstract
Large Language Model (LLM) inference is increasingly constrained by GPU memory capacity rather than compute throughput, driven by growing model sizes and the linear growth of the key-value (KV) cache during autoregressive decoding. Existing approaches mitigate memory pressure by offloading model sta...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Harvest: Opportunistic Peer-to-Peer GPU Caching for LLM Inference*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†è¿‡ç¨‹ä¸­ï¼Œ**GPU å†…å­˜å®¹é‡**å·²æˆä¸ºä¸»è¦ç“¶é¢ˆï¼Œè€Œéè®¡ç®—ååé‡ã€‚éšç€æ¨¡å‹è§„æ¨¡æ‰©å¤§ä»¥åŠè‡ªå›å½’è§£ç ä¸­ Key-Value (KV) ç¼“å­˜çš„çº¿æ€§å¢é•¿ï¼Œå•ä¸ª GPU çš„é«˜å¸¦å®½å†…å­˜ï¼ˆHBMï¼‰å¸¸å¸¸ä¸è¶³ä»¥å®¹çº³æ¨¡å‹æƒé‡ã€KV cache å’Œè¿è¡Œæ—¶å…ƒæ•°æ®ã€‚

ç°æœ‰è§£å†³æ–¹æ¡ˆå¦‚å°†çŠ¶æ€å¸è½½åˆ°ä¸»æœº DRAMï¼ˆé€šè¿‡ PCIeï¼‰ï¼Œè™½ç„¶èƒ½ç¼“è§£å†…å­˜å‹åŠ›ï¼Œä½†å—é™äº PCIe å¸¦å®½ï¼Œå¯¼è‡´æ˜¾è‘—å»¶è¿Ÿï¼›è€Œå¤š GPU åˆ†ç‰‡åˆ™å¢åŠ ç¡¬ä»¶æˆæœ¬å’Œé€šä¿¡å¼€é”€ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡º **Harvest** â€”â€” ä¸€ç§**æœºä¼šä¸»ä¹‰çš„ peer-to-peer GPU ç¼“å­˜ç®¡ç†æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- å°†æœåŠ¡å™¨å†…å…¶ä»–ç©ºé—² GPU ä¸Šçš„ HBM è§†ä¸ºä¸€ä¸ª**ä¸´æ—¶ç¼“å­˜å±‚ï¼ˆtransient cache tierï¼‰**ï¼›
- åˆ©ç”¨é«˜é€Ÿ **NVLink** è¿›è¡Œ GPU é—´æ•°æ®ä¼ è¾“ï¼Œæ›¿ä»£ä½é€Ÿ PCIeï¼›
- ç¼“å­˜å¯¹è±¡å¯è¢«åŠ¨æ€å›æ”¶ï¼ˆrevokedï¼‰ï¼Œç³»ç»Ÿè®¾è®¡ä¸Šä¸ä¾èµ–è¯¥ç¼“å­˜å±‚çš„æŒä¹…æ€§ï¼Œç¡®ä¿æ­£ç¡®æ€§ã€‚

#### ä¸»è¦è´¡çŒ®ï¼š
1. **æå‡ºäº†ä¸€ç§æ–°çš„ placement model**ï¼šå°†è¿œç¨‹ GPU å†…å­˜æš´éœ²ä¸ºå¯åŠ¨æ€åˆ©ç”¨çš„ç¼“å­˜å±‚çº§ã€‚
2. **æ„å»ºäº†ä¸€ä¸ªè‡ªé€‚åº”è¿è¡Œæ—¶ç³»ç»Ÿï¼ˆHarvest Runtimeï¼‰**ï¼šæ— éœ€ä¿®æ”¹æ¨¡å‹ä»£ç å³å¯å®ç°å¯¹ç¼“å­˜åˆ†é…ã€è¿ç§»å’Œæ’¤é”€çš„è‡ªåŠ¨ç®¡ç†ã€‚
3. **å®è¯éªŒè¯äº† peer-memory caching åœ¨ LLM æ¨ç†ä¸­çš„æœ‰æ•ˆæ€§**ï¼šåœ¨ MoE æ¨¡å‹ä¸“å®¶æƒé‡å’Œ KV cache ä¸¤ä¸ªå…¸å‹åœºæ™¯ä¸­è¿›è¡Œäº†è¯„ä¼°ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ CPU offloadï¼‰ | Harvest |
|------|--------------------------|--------|
| æ•°æ®è·¯å¾„ | PCIeï¼ˆ~12â€“32 GB/sï¼‰ | NVLinkï¼ˆå¯è¾¾æ•°ç™¾ GB/sï¼‰ |
| å»¶è¿Ÿ | é«˜ï¼ˆå— PCIe å¸¦å®½é™åˆ¶ï¼‰ | æ˜¾è‘—é™ä½ï¼ˆæœ€é«˜è¾¾ 10Ã—ï¼‰ |
| æ­£ç¡®æ€§ä¿éšœ | ä¾èµ–ä¸»æœº DRAM | ä¸ä¾èµ– peer ç¼“å­˜ï¼Œä¿ç•™ fallback è·¯å¾„ |
| æˆæœ¬ | æ— éœ€é¢å¤–ç¡¬ä»¶ | å……åˆ†åˆ©ç”¨å·²æœ‰é—²ç½® GPU èµ„æº |
| åŠ¨æ€é€‚åº”æ€§ | å¼± | æ”¯æŒåŠ¨æ€å†…å­˜å¯ç”¨æ€§å˜åŒ– |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†ä¸æ¨¡å‹
- **MoE æ¨¡å‹**ï¼š
  - `Mixtral-8x7B-Instruct-v0.1`ï¼ˆMistral AIï¼‰
  - `Qwen2-MoE`ï¼ˆAlibabaï¼‰
  - `Phi-3.5-MoE-instruct` å’Œ `Phi-tiny-MoE-instruct`ï¼ˆMicrosoftï¼‰
- **KV Cache æµ‹è¯•æ¨¡å‹**ï¼š
  - `DeepSeekV3`
  - `Mistral-Large-3-675B-Base-2512`
  - `Kimi-K2-Instruct-0905`

æµ‹è¯• prompts æ¥æºäº **MTBench æ•°æ®é›†**ï¼Œç”¨äºæ¨¡æ‹ŸçœŸå®å¯¹è¯è´Ÿè½½ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼šMicrosoft Azure NC80adis H100 v5 VM
  - 2 Ã— NVIDIA H100 GPUs
  - 12 Ã— NVLink linksï¼ˆæä¾›é«˜å¸¦å®½ P2P äº’è”ï¼‰
  - PCIe 5.0ï¼ˆç”¨äº CPU â†” GPU é€šä¿¡ï¼‰
- **è½¯ä»¶åŸºç¡€**ï¼š
  - MoE å®éªŒåŸºäº **MoE-Lightning** æ¡†æ¶ + CGOPipe æ‰§è¡Œæµæ°´çº¿
  - KV Cache å®éªŒé›†æˆè‡³ **vLLM** ç³»ç»Ÿï¼Œæ‰©å±•å…¶ KV ç®¡ç†æ¨¡å—

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Throughput (tokens/sec)** | å•ä½æ—¶é—´å†…ç”Ÿæˆçš„ token æ•°é‡ï¼Œè¡¡é‡ç«¯åˆ°ç«¯æ¨ç†æ•ˆç‡ |
| **Transfer Latency (ms)** | KV cache æˆ–ä¸“å®¶æƒé‡ä»è¿œç«¯åŠ è½½çš„æ—¶é—´ |
| **Speedup vs CPU Offload** | ç›¸å¯¹äºä¼ ç»Ÿ CPU å¸è½½æ–¹æ¡ˆçš„åŠ é€Ÿæ¯” |
| **Cache Hit Rate / Revocation Impact** | ç¼“å­˜å‘½ä¸­ç‡åŠå¤±æ•ˆåå›é€€æœºåˆ¶çš„å½±å“ |

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **CPU Offload (Baseline)**ï¼šå°†ä¸“å®¶æƒé‡æˆ– KV cache å­˜å‚¨åœ¨ host DRAMï¼ŒæŒ‰éœ€é€šè¿‡ PCIe åŠ è½½
- **No Offload**ï¼šå…¨éƒ¨é©»ç•™æœ¬åœ° HBMï¼ˆä»…é€‚ç”¨äºå°æ¨¡å‹ï¼‰
- **Harvest (Ours)**ï¼šä½¿ç”¨ peer GPU HBM ä½œä¸ºä¸­é—´ç¼“å­˜å±‚ï¼Œé€šè¿‡ NVLink åŠ è½½

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

#### âœ… MoE ä¸“å®¶æƒé‡å¸è½½ç»“æœï¼ˆå›¾5 & å›¾6ï¼‰
| æ¨¡å‹ | ååæå‡ï¼ˆvs CPUï¼‰ | æœ€å¤§åŠ é€Ÿæ¯” |
|------|--------------------|-----------|
| Mixtral-8x7B | ~55% | 1.55Ã— |
| Qwen2-MoE | ~48% | 1.48Ã— |
| Phi-3.5-MoE | **~110%** | **2.1Ã—** |

> **è¯´æ˜**ï¼šPhi-3.5-MoE è¡¨ç°æœ€ä¼˜ï¼Œå› å…¶å…·æœ‰æ›´å°‘çš„ä¸“å®¶æ•°å’Œæ›´é«˜çš„æ—¶é—´å±€éƒ¨æ€§ï¼ˆtemporal localityï¼‰ï¼Œä½¿å¾—ç¼“å­˜å¤ç”¨ç‡æ›´é«˜ã€‚

- å½“ **50% ä¸“å®¶è¢«å¼ºåˆ¶å¸è½½**æ—¶ï¼ŒHarvest å¹³å‡å¸¦æ¥ **1.5â€“2.0Ã— çš„ååæå‡**ã€‚
- éšç€å¸è½½æ¯”ä¾‹ä¸Šå‡ï¼ˆ0% â†’ 100%ï¼‰ï¼ŒCPU å¸è½½æ€§èƒ½æ€¥å‰§ä¸‹é™ï¼Œè€Œ Harvest å‡ ä¹ä¿æŒç¨³å®šï¼š
  - å¦‚ Qwen2-MoEï¼šCPU æ–¹æ¡ˆä» ~975 â†’ 810 tokens/sï¼›Harvest ç»´æŒåœ¨ ~975 tokens/sã€‚

#### âœ… KV Cache å¸è½½ç»“æœï¼ˆå›¾7ï¼‰
| æ¨¡å‹ | KV æ¡ç›®æ•°é‡ | Transfer Latency Speedup (GPU vs CPU) |
|------|------------|---------------------------------------|
| Kimi-K2 | 100 â†’ 8000 entries | **5.42Ã— â†’ 5.68Ã—** |
| Mistral-Large-3 | 100 â†’ 8000 entries | **3.0Ã— â†’ 5.65Ã—** |
| DeepSeekV3 | ä¸­ç­‰è§„æ¨¡ | ~4â€“5Ã— |

> éšç€åºåˆ—é•¿åº¦å¢åŠ ï¼ŒKV cache å¤§å°å¢é•¿ï¼ŒPCIe æˆä¸ºä¸¥é‡ç“¶é¢ˆï¼Œè€Œ NVLink çš„ä¼˜åŠ¿æ„ˆå‘æ˜æ˜¾ã€‚

---

### ğŸ” æ¶ˆèå®éªŒåˆ†æï¼ˆæ–‡ä¸­éšå«ï¼‰
å°½ç®¡æœªæ˜ç¡®åˆ—å‡ºâ€œablation studyâ€ç« èŠ‚ï¼Œä½†ä»ä»¥ä¸‹è§‚å¯Ÿå¯æ¨æ–­å…³é”®å› ç´ å½±å“ï¼š

| å› ç´  | å‘ç° |
|------|------|
| **Temporal Locality** | å¯¹ç¼“å­˜æ”¶ç›Šå½±å“å·¨å¤§ã€‚ä¸“å®¶é‡ç”¨ç‡é«˜çš„æ¨¡å‹ï¼ˆå¦‚ Phi-3.5-MoEï¼‰å¢ç›Šæ›´å¤§ |
| **Working Set Churn** | ä¸“å®¶æ¿€æ´»æ¨¡å¼è¶Šåˆ†æ•£ï¼ˆå¦‚ Qwen2-MoEï¼‰ï¼Œç¼“å­˜æ•ˆæœç•¥å¼±ä½†ä»æ˜¾è‘— |
| **Peer Memory Availability** | åªè¦æœ‰éƒ¨åˆ† GPU å­˜åœ¨ç©ºé—²å†…å­˜ï¼ˆè§å›¾2ï¼šçº¦68%æœºå™¨ä½¿ç”¨ â‰¤20% GPUå†…å­˜ï¼‰ï¼Œå³å¯æœ‰æ•ˆå¯ç”¨ Harvest |
| **Revocation Handling** | å›è°ƒæœºåˆ¶èƒ½å¹³æ»‘å¤„ç†ç¼“å­˜å¤±æ•ˆï¼Œfallback è‡³ host DRAM ä¸å¼•å‘å´©æºƒæˆ–é”™è¯¯ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **å¤§é‡ç”Ÿäº§ç¯å¢ƒä¸­å­˜åœ¨ GPU å†…å­˜ç¢ç‰‡åŒ–ç°è±¡**ï¼šå¦‚ Alibaba é›†ç¾¤æ•°æ®æ˜¾ç¤ºï¼Œè¶…è¿‡ **68% çš„èŠ‚ç‚¹ GPU å†…å­˜åˆ©ç”¨ç‡ä½äº 20%**ï¼Œè¡¨æ˜å­˜åœ¨å¯è§‚çš„â€œå†…å­˜ Slackâ€å¯ä¾›åˆ©ç”¨ã€‚
2. **NVLink æä¾›è¶³å¤Ÿé«˜çš„å¸¦å®½å’Œä½å»¶è¿Ÿ**ï¼šç›¸æ¯” PCIeï¼ŒGPUâ†’GPU ä¼ è¾“å»¶è¿Ÿé™ä½ **7.5Ã— åˆ° 9.5Ã—**ï¼Œä½¿å…¶æˆä¸ºç†æƒ³çš„ä¸­é—´ç¼“å­˜é€šé“ã€‚
3. **Harvest æ˜¾è‘—æå‡äº† LLM æ¨ç†åå**ï¼š
   - MoE åœºæ™¯ä¸‹ï¼š**æå‡ 1.5â€“2.0Ã— åå**
   - KV Cache åœºæ™¯ä¸‹ï¼š**å‡å°‘æœ€å¤š 5.68Ã— çš„ reload å»¶è¿Ÿ**
4. **ç¼“å­˜çš„â€œéæƒå¨æ€§â€è®¾è®¡æ˜¯å…³é”®**ï¼šå…è®¸ç¼“å­˜ä¸¢å¤±å¹¶é‡å»ºï¼ˆlossy cachingï¼‰æˆ– fallback åˆ° host DRAMï¼Œä½¿ç³»ç»Ÿæ—¢èƒ½äº«å—é«˜æ€§èƒ½åˆèƒ½ä¿è¯æ­£ç¡®æ€§ã€‚

### âš ï¸ å±€é™æ€§
1. **å®éªŒè§„æ¨¡æœ‰é™**ï¼šç›®å‰ä»…åœ¨åŒ GPU NVLink ç³»ç»Ÿä¸ŠéªŒè¯ï¼Œå°šæœªæµ‹è¯•å¤§è§„æ¨¡ NVSwitch æ¶æ„ä¸‹çš„è¡¨ç°ã€‚
2. **æœªè€ƒè™‘ NVLink æ‹¥å¡æƒ…å†µ**ï¼šå½“å¤šä¸ªä»»åŠ¡å¹¶å‘ä½¿ç”¨ NVLinkï¼ˆå¦‚æ¨¡å‹å¹¶è¡Œè®­ç»ƒï¼‰ï¼Œå¯èƒ½å½±å“ Harvest çš„å®é™…å¸¦å®½ã€‚
3. **ç¼ºä¹é€šç”¨é¡µé¢æ›¿æ¢ç­–ç•¥ä¼˜åŒ–**ï¼šå½“å‰é‡‡ç”¨ç®€å• best-fit åˆ†é…ç­–ç•¥ï¼Œæœªé’ˆå¯¹ä¸åŒ workload è‡ªé€‚åº”è°ƒæ•´æ›¿æ¢ç®—æ³•ã€‚
4. **æ‹“æ‰‘æ„ŸçŸ¥ä¸è¶³**ï¼šæœªç»“åˆç‰©ç†è¿æ¥æ‹“æ‰‘è¿›è¡Œ placement ä¼˜åŒ–ï¼Œå¯èƒ½å¯¼è‡´è·¨ switch é€šä¿¡å¼€é”€ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³ NUMA-style å…±äº«å†…å­˜æ± æ¶æ„**ï¼š
   - å°†æ•´ä¸ªé›†ç¾¤ GPU å†…å­˜è§†ä¸ºéå‡åŒ€å…±äº«èµ„æºæ± ï¼ˆlocal HBM, peer HBM, host DRAM, CXL memoryï¼‰
   - å®ç°åŸºäºè®¿é—®ä»£ä»·çš„æ™ºèƒ½ placement ä¸ migration
2. **æ”¯æŒ JIT ç¼–è¯‘ä¼˜åŒ–**ï¼š
   - æ¢ç´¢ JAX ç­‰æ”¯æŒåŠ¨æ€å†…å­˜çš„æ¡†æ¶ï¼Œä»¥æ¢å¤å› åŠ¨æ€ offloading å¤±å»çš„ CUDA Graphs ä¼˜åŒ–
3. **å¼€å‘è‡ªé€‚åº”é¡µé¢æ›¿æ¢ç­–ç•¥**ï¼š
   - åŸºäº profiling æ•°æ®å­¦ä¹ çƒ­ç‚¹å—
   - è®¾è®¡æ»‘åŠ¨çª—å£æœºåˆ¶åŠ¨æ€åˆ‡æ¢æ›¿æ¢ç­–ç•¥ï¼ˆLRU/LFU/Hawkeye-likeï¼‰
4. **å¢å¼ºæ‹“æ‰‘ä¸å¹²æ‰°æ„ŸçŸ¥èƒ½åŠ›**ï¼š
   - ç»“åˆ NVLink æ‹“æ‰‘ä¿¡æ¯æœ€å°åŒ–ä¼ è¾“è·ç¦»
   - å¼•å…¥å¸¦å®½é¢„ç®—æ§åˆ¶é¿å…ä¸å…¶ä»– tenant å†²çª
5. **æ¢ç´¢è·¨æœºæŸœï¼ˆrack-scaleï¼‰Harvesting**ï¼š
   - åˆ©ç”¨ NVIDIA NVSwitch æ”¯æŒçš„ 72-GPU å…¨è¿æ¥æ‹“æ‰‘è¿›ä¸€æ­¥æ”¾å¤§ç¼“å­˜æ± å®¹é‡

---

## æ€»ç»“
> **Harvest é€šè¿‡å°†é—²ç½® peer GPU HBM è½¬åŒ–ä¸ºé«˜æ€§èƒ½ä¸´æ—¶ç¼“å­˜å±‚ï¼Œåœ¨ä¸å½±å“æ­£ç¡®æ€§çš„å‰æä¸‹ï¼Œæ˜¾è‘—ç¼“è§£äº† LLM æ¨ç†ä¸­çš„å†…å­˜ç“¶é¢ˆã€‚å…¶å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ MoE å’Œ KV cache å¸è½½åœºæ™¯ä¸­å‡å¯å®ç°é«˜è¾¾ 2Ã— çš„ååæå‡å’Œè¿‘ 10Ã— çš„å»¶è¿Ÿé™ä½ï¼Œå±•ç¤ºäº†â€œæœºä¼šä¸»ä¹‰ç¼“å­˜â€åœ¨ç°ä»£ AI åŸºç¡€è®¾æ–½ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚**

</details>

---

### 16. [AREAL-DTA: Dynamic Tree Attention for Efficient Reinforcement Learning of Large Language Models](https://arxiv.org/abs/2602.00482)

**Authors**: Jiarui Zhang, Yuchen Yang, Ran Yan, Zhiyu Mei, Liyuan Zhang, Daifeng Li, Wei Fu, Jiaxuan Gao, Shusheng Xu, Yi Wu, Binhang Yuan  
**Category**: cs.LG  
**Published**: 2026-02-03  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.00482v1  

#### Abstract
Reinforcement learning (RL) based post-training for large language models (LLMs) is computationally expensive, as it generates many rollout sequences that could frequently share long token prefixes. Existing RL frameworks usually process these sequences independently, repeatedly recomputing identica...

---

### 17. [Multi-Fidelity Physics-Informed Neural Networks with Bayesian Uncertainty Quantification and Adaptive Residual Learning for Efficient Solution of Parametric Partial Differential Equations](https://arxiv.org/abs/2602.01176)

**Authors**: Olaf Yunus Laitinen Imanov  
**Category**: cs.LG  
**Published**: 2026-02-03  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.01176v1  

#### Abstract
Physics-informed neural networks (PINNs) have emerged as a powerful paradigm for solving partial differential equations (PDEs) by embedding physical laws directly into neural network training. However, solving high-fidelity PDEs remains computationally prohibitive, particularly for parametric system...

---

### 18. [Grad2Reward: From Sparse Judgment to Dense Rewards for Improving Open-Ended LLM Reasoning](https://arxiv.org/abs/2602.01791)

**Authors**: Zheng Zhang, Ao Lu, Yuanhao Zeng, Ziwei Shan, Jinjin Guo, Lufei Li, Yexin Li, Kan Ren  
**Category**: cs.LG  
**Published**: 2026-02-03  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.01791v1  

#### Abstract
Reinforcement Learning with Verifiable Rewards (RLVR) has catalyzed significant breakthroughs in complex LLM reasoning within verifiable domains, such as mathematics and programming. Recent efforts have sought to extend this paradigm to open-ended tasks by employing LLMs-as-a-Judge to provide sequen...

---

### 19. [Reasoning and Tool-use Compete in Agentic RL:From Quantifying Interference to Disentangled Tuning](https://arxiv.org/abs/2602.00994)

**Authors**: Yu Li, Mingyang Yi, Xiuyu Li, Ju Fan, Fuxin Jiang, Binbin Chen, Peng Li, Jie Song, Tieying Zhang  
**Category**: cs.AI  
**Published**: 2026-02-03  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.00994v1  

#### Abstract
Agentic Reinforcement Learning (ARL) focuses on training large language models (LLMs) to interleave reasoning with external tool execution to solve complex tasks. Most existing ARL methods train a single shared model parameters to support both reasoning and tool use behaviors, implicitly assuming th...

---

### 20. [PROBE: Co-Balancing Computation and Communication in MoE Inference via Real-Time Predictive Prefetching](https://arxiv.org/abs/2602.00509)

**Authors**: Qianchao Zhu, Xucheng Ye, Yuliang Liu, Haodong Ouyang, Chengru Song  
**Category**: cs.DC  
**Published**: 2026-02-03  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.00509v1  

#### Abstract
Mixture-of-Experts models have become a dominant architecture for scaling Large Language Models by activating only a sparse subset of experts per token. However, latency-critical MoE inference faces a fundamental tension: while expert parallelism improves memory efficiency, it also amplifies executi...

---

### 21. [sVIRGO: A Scalable Virtual Tree Hierarchical Framework for Distributed Systems](https://arxiv.org/abs/2602.02438)

**Authors**: Lican Huang  
**Category**: cs.DC  
**Published**: 2026-02-03  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.02438v1  

#### Abstract
We propose sVIRGO, a scalable virtual tree hierarchical framework for large-scale distributed systems. sVIRGO constructs virtual hierarchical trees directly on physical nodes, allowing each node to assume multiple hierarchical roles without overlay networks. The hierarchy preserves locality and is o...

---

### 22. [Generation Order and Parallel Decoding in Masked Diffusion Models: An Information-Theoretic Perspective](https://arxiv.org/abs/2602.00286)

**Authors**: Shaorong Zhang, Longxuan Yu, Rob Brekelmans, Luhan Tang, Salman Asif, Greg Ver Steeg  
**Category**: cs.LG  
**Published**: 2026-02-03  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.00286v1  

#### Abstract
Masked Diffusion Models (MDMs) significantly accelerate inference by trading off sequential determinism. However, the theoretical mechanisms governing generation order and the risks inherent in parallelization remain under-explored. In this work, we provide a unified information-theoretic framework ...

---

### 23. [MiTA Attention: Efficient Fast-Weight Scaling via a Mixture of Top-$k$ Activations](https://arxiv.org/abs/2602.01219)

**Authors**: Qishuai Wen, Zhiyuan Huang, Xianghan Meng, Wei He, Chun-Guang Li  
**Category**: cs.LG  
**Published**: 2026-02-03  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.01219v1  

#### Abstract
The attention operator in Transformers can be viewed as a two-layer fast-weight MLP, whose weights are dynamically instantiated from input tokens and whose width equals sequence length $N$. As the context extends, the expressive capacity of such an $N$-width MLP increases, but scaling its fast weigh...

---

### 24. [Probing RLVR training instability through the lens of objective-level hacking](https://arxiv.org/abs/2602.01103)

**Authors**: Yiming Dong, Kun Fu, Haoyu Li, Xinyuan Zhu, Yurou Liu, Lijing Shao, Jieping Ye, Zheng Wang  
**Category**: cs.AI  
**Published**: 2026-02-03  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.01103v1  

#### Abstract
Prolonged reinforcement learning with verifiable rewards (RLVR) has been shown to drive continuous improvements in the reasoning capabilities of large language models, but the training is often prone to instabilities, especially in Mixture-of-Experts (MoE) architectures. Training instability severel...

---

### 25. [A State-Transition Framework for Efficient LLM Reasoning](https://arxiv.org/abs/2602.01198)

**Authors**: Liang Zhang, Yu Zhao, Longyue Wang, Tianqi Shi, Weihua Luo, Kaifu Zhang, Jinsong Su  
**Category**: cs.AI  
**Published**: 2026-02-03  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.01198v1  

#### Abstract
While Long Chain-of-Thought (CoT) reasoning significantly improves Large Language Models (LLMs) performance on complex reasoning tasks, the substantial computational and memory costs of generating long CoT sequences limit their efficiency and practicality. Existing studies usually enhance the reason...

---

### 26. [WorldCup Sampling for Multi-bit LLM Watermarking](https://arxiv.org/abs/2602.01752)

**Authors**: Yidan Wang, Yubing Ren, Yanan Cao, Li Guo  
**Category**: cs.CL  
**Published**: 2026-02-03  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.01752v1  

#### Abstract
As large language models (LLMs) generate increasingly human-like text, watermarking offers a promising solution for reliable attribution beyond mere detection. While multi-bit watermarking enables richer provenance encoding, existing methods largely extend zero-bit schemes through seed-driven steeri...

---

### 27. [Low-latency Federated LLM Fine-tuning Over Wireless Networks](https://arxiv.org/abs/2602.01024)

**Authors**: Zhiwen Pang, Kang Wei, Long Shi, Zhe Wang, Jun Li, Feng Shu  
**Category**: cs.DC  
**Published**: 2026-02-03  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.01024v1  

#### Abstract
Recently, federated large language models (LLMs) have drawn significant attention thanks to coupled capabilities of LLMs and federated learning (FL) that address privacy concerns in collaborative fine-tuning. However, due to large-scale parameters of LLMs, existing federated LLM fine-tuning framewor...

---

### 28. [Hierarchical Federated Learning with SignSGD: A Highly Communication-Efficient Approach](https://arxiv.org/abs/2602.02355)

**Authors**: Amirreza Kazemi, Seyed Mohammad Azimi-Abarghouyi, Gabor Fodor, Carlo Fischione  
**Category**: cs.DC  
**Published**: 2026-02-03  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.02355v1  

#### Abstract
Hierarchical federated learning (HFL) has emerged as a key architecture for large-scale wireless and Internet of Things systems, where devices communicate with nearby edge servers before reaching the cloud. In these environments, uplink bandwidth and latency impose strict communication limits, there...

---

### 29. [ELLMPEG: An Edge-based Agentic LLM Video Processing Tool](https://arxiv.org/abs/2602.00028)

**Authors**: Zoha Azimi, Reza Farahani, Radu Prodan, Christian Timmerer  
**Category**: cs.LG  
**Published**: 2026-02-03  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.00028v1  

#### Abstract
Large language models (LLMs), the foundation of generative AI systems like ChatGPT, are transforming many fields and applications, including multimedia, enabling more advanced content generation, analysis, and interaction. However, cloud-based LLM deployments face three key limitations: high computa...

---

### 30. [SFMP: Fine-Grained, Hardware-Friendly and Search-Free Mixed-Precision Quantization for Large Language Models](https://arxiv.org/abs/2602.01027)

**Authors**: Xin Nie, Haicheng Zhang, Liang Dong, Beining Feng, Jinhong Weng, Guiling Sun  
**Category**: cs.LG  
**Published**: 2026-02-03  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.01027v1  

#### Abstract
Mixed-precision quantization is a promising approach for compressing large language models under tight memory budgets. However, existing mixed-precision methods typically suffer from one of two limitations: they either rely on expensive discrete optimization to determine precision allocation, or int...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- kv cache, offload, State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
