# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-01-08 05:57:54 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Implicit Graph, Explicit Retrieval: Towards Efficient and Interpretable Long-horizon Memory for Large Language Models](https://arxiv.org/abs/2601.03417)

**Authors**: Xin Zhang, Kailai Yang, Hao Li, Chenyue Li, Qiyu Wei, Sophia Ananiadou  
**Category**: cs.CL  
**Published**: 2026-01-08  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2601.03417v1  

#### Abstract
Long-horizon applications increasingly require large language models (LLMs) to answer queries when relevant evidence is sparse and dispersed across very long contexts. Existing memory systems largely follow two paradigms: explicit structured memories offer interpretability but often become brittle u...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šImplicit Graph, Explicit Retrieval: Towards Efficient and Interpretable Long-horizon Memory for Large Language Models**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
åœ¨é•¿ä¸Šä¸‹æ–‡ï¼ˆlong-horizonï¼‰åœºæ™¯ä¸­ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰éœ€è¦ä»åˆ†æ•£ä¸”ç¨€ç–çš„è¯æ®ä¸­è¿›è¡Œæ¨ç†ã€‚ç°æœ‰çš„è®°å¿†ç³»ç»Ÿå­˜åœ¨ä¸¤å¤§èŒƒå¼ï¼š
- **æ˜¾å¼ç»“æ„åŒ–è®°å¿†**ï¼ˆExplicit Structured Memoryï¼‰ï¼šå¦‚å›¾ç»“æ„è®°å¿†ï¼Œå…·æœ‰è‰¯å¥½çš„å¯è§£é‡Šæ€§ï¼Œä½†åœ¨é•¿è€Œå˜ˆæ‚çš„ä¸Šä¸‹æ–‡ä¸­å®¹æ˜“å› ç»“æ„æ„å»ºé”™è¯¯å’Œæ£€ç´¢ä¸ç¨³å®šè€Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚
- **éšå¼æ½œåœ¨è®°å¿†**ï¼ˆLatent Memoryï¼‰ï¼šå°†ä¿¡æ¯å­˜å‚¨åœ¨è¿ç»­çš„æ½œåœ¨ç©ºé—´ä¸­ï¼Œæ•ˆç‡é«˜ä¸”ç¨³å®šï¼Œä½†ç¼ºä¹å¯è§£é‡Šæ€§ï¼Œéš¾ä»¥è¿½è¸ªæ¨ç†è¿‡ç¨‹ã€‚

æœ¬æ–‡æŒ‡å‡ºï¼Œåœ¨é•¿ä¸Šä¸‹æ–‡é—®ç­”ä»»åŠ¡ä¸­ï¼Œæ˜¾å¼æ–¹æ³•å¾€å¾€è¡¨ç°ä¸ä½³ç”šè‡³å´©æºƒï¼Œè€Œéšå¼æ–¹æ³•è™½ç¨³å®šå´â€œé»‘ç®±â€ï¼Œé™åˆ¶äº†å…¶åœ¨éœ€è¦é€æ˜å†³ç­–çš„åº”ç”¨ä¸­çš„ä½¿ç”¨ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ï¼šLATENTGRAPHMEM**
ä½œè€…æå‡ºäº† **LATENTGRAPHMEM**ï¼Œä¸€ç§ç»“åˆäº†ä¸¤ç§èŒƒå¼ä¼˜åŠ¿çš„è®°å¿†æ¡†æ¶ï¼š
- **éšå¼å›¾å­˜å‚¨**ï¼ˆImplicit Graph Storageï¼‰ï¼šåœ¨æ½œåœ¨ç©ºé—´ä¸­æ„å»ºå’Œç»´æŠ¤ä¸€ä¸ªå›¾ç»“æ„è®°å¿†ï¼Œç¡®ä¿é«˜æ•ˆæ€§å’Œç¨³å®šæ€§ã€‚
- **æ˜¾å¼å­å›¾æ£€ç´¢**ï¼ˆExplicit Subgraph Retrievalï¼‰ï¼šåœ¨æ¨ç†æ—¶ä»…å°†ä¸æŸ¥è¯¢ç›¸å…³çš„ç´§å‡‘å­å›¾æ˜¾å¼æå–å‡ºæ¥ï¼Œä¾›ä¸‹æ¸¸LLMè¿›è¡Œæ¨ç†å’Œäººç±»å®¡æŸ¥ã€‚

è¯¥æ–¹æ³•é€šè¿‡ä¸‰ä¸ªé˜¶æ®µå®ç°ï¼š
1. **è¿œç¨‹ç›‘ç£çš„å…¨å›¾æ„å»º**ï¼ˆStage Iï¼‰ï¼šåˆ©ç”¨å†»ç»“çš„reasoneræä¾›ç›‘ç£ä¿¡å·ï¼Œè®­ç»ƒå›¾æ„å»ºå™¨ï¼ˆGraph Builderï¼‰ä»é•¿æ–‡æ¡£æµå¼æ„å»ºç¬¦å·å›¾ã€‚
2. **è¿œç¨‹ç›‘ç£çš„æ½œåœ¨å­å›¾æ£€ç´¢**ï¼ˆStage IIï¼‰ï¼šå°†è¾¹æ˜ å°„ä¸ºæ½œåœ¨åµŒå…¥ï¼Œåœ¨æ½œåœ¨ç©ºé—´ä¸­è®­ç»ƒå­å›¾æ£€ç´¢å™¨ï¼ˆSubgraph Retrieverï¼‰ï¼ŒæŒ‰é¢„ç®—é€‰æ‹©æœ€ç›¸å…³è¾¹ã€‚
3. **è”åˆå¾®è°ƒ**ï¼ˆStage IIIï¼‰ï¼šè”åˆä¼˜åŒ–Builderå’ŒRetrieverï¼Œå¢å¼ºäºŒè€…ååŒèƒ½åŠ›ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- âœ… **å…¼é¡¾æ•ˆç‡ä¸å¯è§£é‡Šæ€§**ï¼šé¿å…äº†æ˜¾å¼æ–¹æ³•åœ¨é•¿ä¸Šä¸‹æ–‡ä¸‹çš„ä¸ç¨³å®šæ€§ï¼ŒåŒæ—¶å…‹æœäº†çº¯éšå¼æ–¹æ³•ä¸å¯è§çš„é—®é¢˜ã€‚
- âœ… **å‚æ•°é«˜æ•ˆé€‚åº”**ï¼šä½¿ç”¨LoRAç­‰è½»é‡é€‚é…æŠ€æœ¯ï¼Œå¯åœ¨å°è§„æ¨¡æ¨¡å‹ä¸Šè®­ç»ƒåè¿ç§»åˆ°æ›´å¤§è§„æ¨¡çš„reasonerã€‚
- âœ… **çµæ´»æ‰©å±•æ€§**ï¼šæ”¯æŒä¸åŒè§„æ¨¡çš„å†»ç»“reasonerï¼ˆ1.5B~8Bï¼‰ï¼Œæ— éœ€é‡æ–°è®­ç»ƒè®°å¿†æ¨¡å—ã€‚
- âœ… **å›ºå®šæ£€ç´¢é¢„ç®—æ§åˆ¶**ï¼šä¿è¯æ¨ç†å¼€é”€å¯æ§ï¼Œé¿å…éšä¸Šä¸‹æ–‡å¢é•¿è€Œçˆ†ç‚¸ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
#### **è®­ç»ƒæ•°æ®é›†**ï¼ˆå…±20,800å®ä¾‹ï¼‰
- **TriviaQA**ï¼šå¼€æ”¾åŸŸé—®ç­”ï¼Œä¸Šä¸‹æ–‡é•¿ä¸”å¼‚æ„ï¼Œé€‚åˆè®­ç»ƒè·¨ç‰‡æ®µä¿¡æ¯èšåˆèƒ½åŠ›ã€‚
- **QASPER**ï¼šåŸºäºå®Œæ•´ç§‘ç ”è®ºæ–‡çš„é—®ç­”ï¼Œéœ€è·¨ç« èŠ‚æ•´åˆä¿¡æ¯ã€‚
- **QuALITY**ï¼šå¤šé€‰é¢˜å½¢å¼ï¼Œå¼ºè°ƒå¯¹é•¿ç¯‡æ–‡ç« çš„æ•´ä½“ç†è§£ã€‚

#### **è¯„ä¼°æ•°æ®é›†**ï¼ˆå…±2,600æµ‹è¯•å®ä¾‹æ··åˆï¼‰
- **HotpotQA**ï¼šå¤šè·³æ¨ç†ï¼Œè¦æ±‚è·¨å¤šä¸ªå®ä½“æˆ–æ–‡æ¡£æ¨ç†ã€‚
- **NarrativeQA**ï¼šå™äº‹å‹é•¿æ–‡æœ¬ç†è§£ï¼Œç­”æ¡ˆæŠ½è±¡åº¦é«˜ã€‚
- **WikiHop**ï¼šè·¨ç»´åŸºç™¾ç§‘æ¡ç›®çš„å¤šè·³é€»è¾‘æ¨ç†ã€‚

> æ‰€æœ‰è¯„ä¼°æ•°æ®å‡æœªå‚ä¸è®­ç»ƒï¼Œç¡®ä¿å…¬å¹³æ€§ã€‚

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**
- **Reasoner**ï¼šå†»ç»“çš„é¢„è®­ç»ƒLLMï¼Œåˆ†åˆ«ä½¿ç”¨ `Qwen2.5-1.5B`ã€`SmolLM3-3B` å’Œ `Qwen3-8B`ã€‚
- **Memory Modules**ï¼šBuilder å’Œ Retriever ä½¿ç”¨ `Qwen2.5-1.5B-Instruct` + LoRA å¾®è°ƒï¼Œå…¶ä½™éƒ¨åˆ†å†»ç»“ã€‚
- **å›¾å®¹é‡é™åˆ¶**ï¼šæ¯chunkæœ€å¤šæå–32ä¸ªä¸‰å…ƒç»„ï¼Œå…¨å±€å›¾æœ€å¤§è¾¹æ•° $ M = 150 $ã€‚
- **æ£€ç´¢é¢„ç®—**ï¼šæœ€å¤šè¿”å› $ k = 30 $ æ¡è¾¹æ„æˆçš„å­å›¾ã€‚
- **è¾“å…¥å¤„ç†**ï¼šæ–‡æ¡£åˆ‡åˆ†ä¸º1024 tokençš„é‡å å—ï¼ˆoverlap=128ï¼‰ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Accuracy (Acc)**ï¼šç²¾ç¡®åŒ¹é…å‡†ç¡®ç‡ã€‚
  - **ROUGE-L**ï¼šè¡¡é‡ç”Ÿæˆç­”æ¡ˆä¸å‚è€ƒç­”æ¡ˆçš„æœ€é•¿å…¬å…±å­åºåˆ—ç›¸ä¼¼åº¦ã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| ç±»å‹ | æ–¹æ³• | ç®€ä»‹ |
|------|------|------|
| **Reasoner-only** | â€”â€” | ç›´æ¥ç”¨å®Œæ•´ä¸Šä¸‹æ–‡æ¨ç†ï¼Œæ— å¤–éƒ¨è®°å¿† |
| **RAG** | â€”â€” | åŸºäºembeddingç›¸ä¼¼åº¦æ£€ç´¢top-kæ–‡æœ¬å—æ‹¼æ¥ |
| **æ˜¾å¼å›¾è®°å¿†** | THEANINE, PREMem, Mem0/Mem0g, A-Mem | æ„å»ºæ˜¾å¼å›¾ç»“æ„å¹¶æ£€ç´¢ |
| **éšå¼æ½œåœ¨è®°å¿†** | MemGen | ç”Ÿæˆè½¯å‘é‡ä½œä¸ºæ½œåœ¨çº¿ç´¢ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆå¹³å‡ Accuracy / ROUGE-Lï¼‰**
| æ–¹æ³• | Qwen2.5-1.5B | SmolLM3-3B | Qwen3-8B | å¹³å‡ Accâ†‘ |
|------|--------------|------------|----------|-----------|
| Reasoner-only | 52.11 / 34.63 | 50.70 / 37.83 | 54.74 / 52.61 | 52.52 |
| MemGen (Latent) | 44.03 / 48.11 | 49.58 / 47.87 | 54.56 / 58.42 | 49.39 |
| A-Mem (Explicit) | 24.78 / 42.37 | 29.44 / 48.54 | 18.89 / 39.68 | 24.37 |
| PREMem (Explicit) | 23.40 / 23.73 | 45.81 / 31.63 | 43.30 / 30.36 | 37.50 |
| THEANINE (Explicit) | 10.63 / 6.22 | 24.47 / 13.71 | 20.91 / 10.54 | 18.67 |
| Mem0 (Explicit) | 25.52 / 19.82 | 15.88 / 11.53 | 17.74 / 12.00 | 19.71 |
| RAG | 6.87 / 21.19 | 7.89 / 36.29 | 16.43 / 43.74 | 10.40 |
| **LATENTGRAPHMEM (Ours)** | **56.08 / 38.61** | **58.64 / 44.16** | **63.34 / 49.73** | **59.35** |

> âœ… åœ¨æ‰€æœ‰reasonerè§„æ¨¡ä¸‹ï¼ŒLATENTGRAPHMEMå‡å–å¾—**æœ€é«˜å¹³å‡å‡†ç¡®ç‡**ï¼Œæ˜¾è‘—ä¼˜äºå„ç±»åŸºçº¿ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- ç›¸æ¯”æœ€å¼ºæ˜¾å¼æ–¹æ³•ï¼ˆPREMemï¼‰ï¼Œå¹³å‡æå‡çº¦ **21.85%**ï¼ˆ59.35 vs. 37.50ï¼‰ã€‚
- æ˜¾å¼æ–¹æ³•åœ¨ **NarrativeQA** ä¸Šæ™®éå´©æºƒï¼ˆå¦‚THEANINEä»…å¾—2.25% Accï¼‰ï¼Œè€ŒLATENTGRAPHMEMä¿æŒç¨³å¥ã€‚
- å°½ç®¡MemGenåœ¨æŸäº›ROUGE-Lä¸Šç•¥ä¼˜ï¼Œä½†åœ¨**å¤šè·³æ¨ç†ä»»åŠ¡ï¼ˆHotpotQAï¼‰ä¸Šå‡†ç¡®ç‡æ›´ä½**ï¼Œè¯´æ˜å…¶æ¨ç†è¿‡ç¨‹ä¸å¯é ã€‚
- LATENTGRAPHMEMèƒ½ç”¨**å•ä¸€1.5B Builderé€‚é…ä¸åŒè§„æ¨¡reasoner**ï¼Œè€ŒMemGenéœ€åŒè§„æ¨¡è®­ç»ƒæ‰èƒ½å¯¹é½æ½œåœ¨ç©ºé—´ã€‚

### **æ¶ˆèå®éªŒç»“æœ**
#### **å›¾ç»“æ„ä¸æ£€ç´¢ç­–ç•¥æ¶ˆèï¼ˆFigure 3ï¼‰**
| å˜ä½“ | æè¿° | æ€§èƒ½è¶‹åŠ¿ |
|------|------|---------|
| **No Subgraph (Full Graph Only)** | ä¸åšå­å›¾æ£€ç´¢ï¼Œç›´æ¥ä¼ æ•´ä¸ªå›¾ç»™reasoner | âŒ æ€§èƒ½ä¸‹é™ï¼Œå› å™ªå£°å¼•å…¥è¿‡å¤š |
| **No Subgraph Retriever (BFS Heuristic)** | ç”¨BFSä»£æ›¿å­¦ä¹ å¼æ£€ç´¢å™¨ | âŒ å¼•å…¥å¤§é‡æ— å…³è¾¹ï¼Œæ•ˆæœå·® |
| **Fully Explicit (No Latent Structure)** | å®Œå…¨ä¾èµ–æ˜¾å¼å›¾æ„å»ºä¸æ£€ç´¢ | âš ï¸ è™½ä¼˜äºæœ´ç´ æ£€ç´¢ï¼Œä½†ä»ä½äºLATENTGRAPHMEM |

> ç»“è®ºï¼š**å­¦ä¹ å¼çš„æ½œåœ¨ç©ºé—´æ£€ç´¢ + æ˜¾å¼å­å›¾æš´éœ²** æ˜¯å…³é”®è®¾è®¡ã€‚

#### **å›¾å®¹é‡ $ M $ å½±å“ï¼ˆFigure 4ï¼‰**
- **WikiHop**ï¼šéšç€ $ M $ å¢å¤§æŒç»­å—ç›Š â†’ éœ€è¦æ›´å¹¿çš„çŸ¥è¯†è¦†ç›–ã€‚
- **HotpotQA & NarrativeQA**ï¼šè¶…è¿‡ $ M=150 $ åæ€§èƒ½é¥±å’Œç”šè‡³ä¸‹é™ â†’ æ›´æ³¨é‡ç²¾å‡†è€Œéå¹¿åº¦ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **æ˜¾å¼å›¾è®°å¿†åœ¨é•¿ä¸Šä¸‹æ–‡ä¸­ä¸ç¨³å®š**ï¼šç»“æ„æå–å’Œæ£€ç´¢æ˜“å—å™ªå£°å¹²æ‰°ï¼Œå¯¼è‡´ç«¯åˆ°ç«¯æ€§èƒ½å´©æºƒã€‚
2. **éšå¼è®°å¿†è™½ç¨³å®šä½†ç¼ºä¹å¯è§£é‡Šæ€§**ï¼šæ— æ³•éªŒè¯ä¸­é—´æ¨ç†ä¾æ®ï¼Œä¸åˆ©äºè°ƒè¯•å’Œå¯ä¿¡AIã€‚
3. **LATENTGRAPHMEMå®ç°äº†æœ€ä½³å¹³è¡¡**ï¼š
   - åˆ©ç”¨æ½œåœ¨ç©ºé—´ä¿éšœ**ç¨³å®šæ€§ä¸æ•ˆç‡**ï¼›
   - é€šè¿‡æ˜¾å¼å­å›¾è¾“å‡ºå®ç°**å¯è§£é‡Šæ€§ä¸å¯æ§æ€§**ï¼›
   - æ”¯æŒè·¨è§„æ¨¡reasonerè¿ç§»ï¼Œå…·å¤‡è‰¯å¥½**æ³›åŒ–æ€§**ã€‚
4. **å›ºå®šæ£€ç´¢é¢„ç®—è‡³å…³é‡è¦**ï¼šé˜²æ­¢æ¨ç†æˆæœ¬éšä¸Šä¸‹æ–‡çº¿æ€§å¢é•¿ï¼Œä¿éšœå®é™…éƒ¨ç½²å¯è¡Œæ€§ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- å›¾æ„å»ºè´¨é‡é«˜åº¦ä¾èµ–Extractorå’ŒMerge/Filteræ¨¡å—çš„è®¾è®¡ã€‚
- å›ºå®šå®¹é‡ $ M $ å’Œé¢„ç®— $ k $ å¯èƒ½åœ¨ä¸åŒä»»åŠ¡é—´éœ€æ‰‹åŠ¨è°ƒæ•´ï¼Œç¼ºä¹è‡ªé€‚åº”æœºåˆ¶ã€‚
- å½“å‰ä»…é€‚ç”¨äºæ–‡æœ¬è¾“å…¥å’ŒQAä»»åŠ¡ï¼Œå°šæœªæ‹“å±•è‡³å¤šæ¨¡æ€æˆ–äº¤äº’å¼æ¨ç†åœºæ™¯ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ¢ç´¢åŠ¨æ€å›¾å®¹é‡æ§åˆ¶ä¸è‡ªé€‚åº”æ£€ç´¢é¢„ç®—ã€‚
- å°†æ¡†æ¶æ‰©å±•è‡³å¤šæ¨¡æ€è®°å¿†ç³»ç»Ÿï¼ˆå¦‚å›¾åƒ+æ–‡æœ¬ï¼‰ã€‚
- åº”ç”¨äºAgenté•¿æœŸè§„åˆ’ã€å¯¹è¯ç³»ç»Ÿç­‰å¤æ‚æ¨ç†åœºæ™¯ã€‚
- å¼•å…¥å¼ºåŒ–å­¦ä¹ æˆ–å…¶ä»–æœºåˆ¶è¿›ä¸€æ­¥ä¼˜åŒ–Builder-Retrieveråä½œã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> LATENTGRAPHMEM æå‡ºäº†ä¸€ç§â€œ**éšå¼å­˜ã€æ˜¾å¼å–**â€çš„æ–°å‹è®°å¿†æ¶æ„ï¼Œåœ¨ä¿æŒé«˜æ•ˆç¨³å®šçš„åŒæ—¶å®ç°äº†å¯è§£é‡Šçš„é•¿ç¨‹æ¨ç†ï¼Œä¸ºä¸‹ä¸€ä»£LLMè®°å¿†ç³»ç»Ÿæä¾›äº†å®ç”¨ä¸”å¯æ‰©å±•çš„è®¾è®¡èŒƒå¼ã€‚

</details>

---

### 2. [Robust Physics Discovery from Highly Corrupted Data: A PINN Framework Applied to the Nonlinear Schr\"odinger Equation](https://arxiv.org/abs/2601.04176)

**Authors**: Pietro de Oliveira Esteves  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2601.04176v1  

#### Abstract
We demonstrate a deep learning framework capable of recovering physical parameters from the Nonlinear Schrodinger Equation (NLSE) under severe noise conditions. By integrating Physics-Informed Neural Networks (PINNs) with automatic differentiation, we achieve reconstruction of the nonlinear coeffici...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Robust Physics Discovery from Highly Corrupted Data: A PINN Framework Applied to the Nonlinear SchrÃ¶dinger Equation*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
è¯¥ç ”ç©¶é’ˆå¯¹**åœ¨é«˜å™ªå£°ã€ç¨€ç–è§‚æµ‹æ¡ä»¶ä¸‹ä»å®éªŒæ•°æ®ä¸­æ¢å¤éçº¿æ€§ç‰©ç†ç³»ç»Ÿå‚æ•°**è¿™ä¸€æŒ‘æˆ˜æ€§é€†é—®é¢˜å±•å¼€ã€‚å…·ä½“èšç„¦äº**éçº¿æ€§è–›å®šè°”æ–¹ç¨‹ï¼ˆNLSEï¼‰ä¸­çš„éçº¿æ€§ç³»æ•° $\beta$ çš„è¯†åˆ«ä»»åŠ¡**ï¼Œå…¶ä¸­è¾“å…¥æ•°æ®å…·æœ‰ä»¥ä¸‹ç°å®ç‰¹å¾ï¼š
- é«˜è¾¾ **20% çš„åŠ æ€§é«˜æ–¯å™ªå£°**
- æ•°æ®æåº¦ç¨€ç–ï¼ˆä»… 100â€“1000 ä¸ªéšæœºé‡‡æ ·ç‚¹ï¼‰
- ç¼ºä¹å…ˆéªŒçŸ¥è¯†ï¼ˆ$\beta$ åˆå§‹åŒ–ä¸º 0.0ï¼‰

ä¼ ç»Ÿæ•°å€¼æ–¹æ³•ï¼ˆå¦‚æœ‰é™å·®åˆ† + ä¼˜åŒ–ï¼‰åœ¨æ­¤ç±»å™ªå£°ç¯å¢ƒä¸‹å› **æ•°å€¼å¾®åˆ†æ”¾å¤§è¯¯å·®**è€Œå¤±æ•ˆã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§åŸºäº **Physics-Informed Neural Networks (PINNs)** çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºä»é«˜åº¦æ±¡æŸ“çš„æ•°æ®ä¸­ç¨³å¥åœ°å‘ç°ç‰©ç†è§„å¾‹å’Œå‚æ•°ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š
- **å°†ç‰©ç†æ­£åˆ™åŒ–ä½œä¸ºâ€œå»å™ªæ»¤æ³¢å™¨â€**ï¼šé€šè¿‡å°† NLSE çš„æ®‹å·®é¡¹åµŒå…¥æŸå¤±å‡½æ•°ï¼ŒPINN èƒ½å¤Ÿæœ‰æ•ˆåŒºåˆ†ä¿¡å·ä¸å™ªå£°ï¼Œå®ç°å¯¹çœŸå®åŠ¨åŠ›å­¦çš„é‡å»ºã€‚
- **å®Œå…¨æ— ååˆå§‹åŒ–**ï¼šå¾…è¯†åˆ«å‚æ•° $\beta$ åˆå§‹åŒ–ä¸º 0.0ï¼Œä¸ä¾èµ–ä»»ä½•å…ˆéªŒä¼°è®¡ï¼ŒéªŒè¯äº†æ–¹æ³•çš„çº¯æ•°æ®é©±åŠ¨æ€§å’Œé²æ£’æ€§ã€‚
- **è‡ªåŠ¨å¾®åˆ†é¿å…æ•°å€¼è¯¯å·®**ï¼šåˆ©ç”¨ PyTorch çš„è‡ªåŠ¨å¾®åˆ†æœºåˆ¶è®¡ç®—ç²¾ç¡®çš„ç©ºé—´/æ—¶é—´å¯¼æ•°ï¼Œè§„é¿äº†ä¼ ç»Ÿæ–¹æ³•ä¸­å› æœ‰é™å·®åˆ†å¯¼è‡´çš„å™ªå£°æ”¾å¤§é—®é¢˜ã€‚
- **è½»é‡çº§æ¶æ„ä¸å¯è®¿é—®æ€§è®¾è®¡**ï¼šæ•´ä¸ªæµç¨‹å¯åœ¨ Google Colab ä¸Šçš„ NVIDIA Tesla T4 GPU ä¸Šè¿è¡Œï¼Œæ€»è€—æ—¶çº¦ 80 åˆ†é’Ÿï¼Œæå‡äº†ç§‘å­¦ç¤¾åŒºçš„å¯å¤ç°æ€§ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ FD + L-BFGSï¼‰ | æœ¬æ–‡ PINN æ–¹æ³• |
|------|----------------------------|----------------|
| å™ªå£°é²æ£’æ€§ | å·®ï¼ˆå™ªå£°è¢«å¾®åˆ†æ”¾å¤§ï¼‰ | å¼ºï¼ˆç‰©ç†çº¦æŸæŠ‘åˆ¶è¿‡æ‹Ÿåˆï¼‰ |
| æ•°æ®éœ€æ±‚ | éœ€å¯†é›†ã€è§„åˆ™ç½‘æ ¼ | æ”¯æŒç¨€ç–ã€éšæœºé‡‡æ ·æ•°æ® |
| æ­£åˆ™åŒ–è°ƒå‚ | æ‰‹åŠ¨è°ƒæ•´ Tikhonov å‚æ•° | ç‰©ç†æ–¹ç¨‹å¤©ç„¶æä¾›éšå¼æ­£åˆ™åŒ– |
| å¯æ‰©å±•æ€§ | å¯¹ä¸è§„åˆ™å‡ ä½•é€‚åº”å·® | æ˜“æ¨å¹¿è‡³å¤æ‚åŸŸ |

> âœ… ç»“è®ºï¼šPINNs åœ¨é«˜å™ªå£°ã€ä½æ•°æ®åœºæ™¯ä¸‹æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå°¤å…¶é€‚ç”¨äºå®éªŒæ¡ä»¶å—é™çš„å®é™…ç‰©ç†ç³»ç»Ÿå»ºæ¨¡ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†ç”Ÿæˆ
- **æ§åˆ¶æ–¹ç¨‹**ï¼šä¸€ç»´éçº¿æ€§è–›å®šè°”æ–¹ç¨‹ï¼ˆNLSEï¼‰ï¼Œå½¢å¼å¦‚ä¸‹ï¼š
  $$
  i\psi_t + 0.5\psi_{xx} + \beta|\psi|^2\psi = 0
  $$
- **çœŸè§£æ¥æº**ï¼šè§£æå­¤å­è§£ï¼ˆsoliton solutionï¼‰ï¼Œå®šä¹‰åœ¨ç©ºé—´åŸŸ $x \in [-5,5]$ å’Œæ—¶é—´åŸŸ $t \in [0, \pi/2]$ã€‚
- **è®­ç»ƒæ•°æ®**ï¼š
  - ä»çœŸå®è§£ä¸­éšæœºæŠ½å– $N_u \in [100, 1000]$ ä¸ªç‚¹ä½œä¸ºè§‚æµ‹æ•°æ®ã€‚
  - æ·»åŠ  **20% åŠ æ€§é«˜æ–¯å™ªå£°**ï¼ˆä¿¡å™ªæ¯” ~5:1ï¼‰ã€‚
  - è¾“å…¥ä»…ä¸º $(x_i, t_i)$ åŠå…¶å¸¦å™ªçš„ $u(x_i,t_i), v(x_i,t_i)$ï¼ˆå®éƒ¨ä¸è™šéƒ¨åˆ†è§£ï¼‰ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®
| é¡¹ç›® | è®¾ç½®è¯¦æƒ… |
|------|----------|
| **ç½‘ç»œç»“æ„** | Fully Connected DNNï¼š<br>â€¢ è¾“å…¥å±‚ï¼š2 neurons ($x, t$)<br>â€¢ éšè—å±‚ï¼š4 å±‚ Ã— 50 ç¥ç»å…ƒ<br>â€¢ æ¿€æ´»å‡½æ•°ï¼štanh<br>â€¢ è¾“å‡ºå±‚ï¼š2 neurons ($u, v$) |
| **å¯è®­ç»ƒå‚æ•°** | çº¦ 10,000ï¼›$\beta$ ä½œä¸ºå¯å­¦ä¹ æ ‡é‡å˜é‡ |
| **ä¼˜åŒ–å™¨** | Adam ($\text{lr}=10^{-3}$)ï¼Œä¼˜äº L-BFGS åœ¨å™ªå£°ç¯å¢ƒä¸‹çš„ç¨³å®šæ€§ |
| **é…ç‚¹æ•°é‡** | $N_f = 20,000$ ä¸ª collocation pointsï¼Œé‡‡ç”¨æ‹‰ä¸è¶…ç«‹æ–¹é‡‡æ ·ï¼ˆLHSï¼‰è¦†ç›–æ—¶ç©ºåŸŸ |
| **æŸå¤±å‡½æ•°** | å¤åˆæŸå¤±ï¼š
  $$
  \mathcal{L} = \lambda_{\text{data}} \mathcal{L}_{\text{data}} + \lambda_{\text{physics}} \mathcal{L}_{\text{physics}},\quad \lambda_{\text{data}} = \lambda_{\text{physics}} = 1.0
  $$
  - $\mathcal{L}_{\text{data}}$: MSE on noisy observations
  - $\mathcal{L}_{\text{physics}}$: PDE residual via automatic differentiation |
| **è®­ç»ƒé…ç½®** | 10,000 epochsï¼Œæ—©åœåˆ¤æ–­æ”¶æ•›ï¼›ä½¿ç”¨å›ºå®šéšæœºç§å­ä¿è¯å¯å¤ç° |

---

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
- **ç›¸å¯¹è¯¯å·®ï¼ˆRelative Errorï¼‰**ï¼š
  $$
  \text{Error}_\beta = \frac{|\beta_{\text{true}} - \beta_{\text{learned}}|}{\beta_{\text{true}}} \times 100\%
  $$
- **ç»Ÿè®¡å¯é æ€§**ï¼šå¤šæ¬¡ç‹¬ç«‹è¿è¡Œçš„æ ‡å‡†å·®ï¼ˆstd. dev.ï¼‰
- **è®¡ç®—æ•ˆç‡**ï¼šå•æ¬¡è®­ç»ƒæ—¶é—´å’Œæ€»æµç¨‹è€—æ—¶
- **å¯è§†åŒ–åˆ†æ**ï¼šæ—¶ç©ºè¯¯å·®çƒ­å›¾ã€é¢„æµ‹ vs. çœŸå€¼æ›²çº¿ã€æŸå¤±æ¼”åŒ–æ›²çº¿

---

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ–‡ä¸­è™½æœªç›´æ¥è¿è¡Œä¼ ç»Ÿæ–¹æ³•ï¼Œä½†å¼•ç”¨æ–‡çŒ®æŒ‡å‡ºï¼š
- **Finite Difference + Optimization (e.g., L-BFGS-B with Tikhonov)**ï¼š
  - æ•°å€¼å¾®åˆ†ä¼šæ”¾å¤§å™ªå£°ï¼ˆè¯¯å·® $\propto e_{\text{noise}} / h^2$ï¼‰
  - éœ€è¦ç²¾ç»†è°ƒèŠ‚æ­£åˆ™åŒ–å‚æ•°
  - ä¸é€‚åˆä¸è§„åˆ™é‡‡æ ·æ•°æ®
- æ–‡çŒ®æ”¯æŒ [4][5] è¡¨æ˜æ­¤ç±»æ–¹æ³•åœ¨ >10% å™ªå£°ä¸‹é€šå¸¸å¤±è´¥ã€‚

> å› æ­¤ï¼Œä½œè€…å¼ºè°ƒ PINN åœ¨è¯¥ä»»åŠ¡ä¸Šçš„**æ ¹æœ¬ä¼˜åŠ¿åœ¨äºé¿å…æ˜¾å¼æ•°å€¼å¾®åˆ†**ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®

#### âœ… ä¸åŒ $\beta$ ä¸‹çš„å‚æ•°è¯†åˆ«ç²¾åº¦ï¼ˆ$N_u = 500$, 20% å™ªå£°ï¼‰

| çœŸå® $\beta$ | ç›¸å¯¹è¯¯å·® (%) | æ ‡å‡†å·® (%) | è®­ç»ƒæ—¶é—´ (min) |
|-------------|---------------|------------|----------------|
| 0.5         | 0.71 Â± 0.15   | å¾ˆå°       | 11.2 Â± 1.3     |
| **1.0**     | **0.16 Â± 0.05** | æå°       | 10.8 Â± 0.9     |
| 2.0         | 0.33 Â± 0.10   | å°         | 12.1 Â± 1.5     |

> âœ”ï¸ æœ€ä½³è¡¨ç°ï¼šå½“ $\beta=1.0$ æ—¶ï¼Œå¹³å‡è¯¯å·® **< 0.2%**ï¼Œæ ‡å‡†å·® < 0.15%ï¼Œè¡¨ç°å‡ºæå¼ºçš„ä¸€è‡´æ€§å’Œé²æ£’æ€§ã€‚

---

#### âœ… æ•°æ®ç¨€ç–æ€§æ•æ„Ÿæ€§æµ‹è¯•ï¼ˆ$\beta=1.0$, 20% å™ªå£°ï¼‰

| æ•°æ®ç‚¹æ•° $N_u$ | ç›¸å¯¹è¯¯å·® (%) | æ ‡å‡†å·® (%) |
|----------------|---------------|------------|
| 100            | 1.47          | 1.10       |
| 250            | 1.59          | 1.49       |
| **500**        | **0.36**      | **0.52**   |
| 1000           | 0.80          | 0.79       |

> ğŸ” å‘ç°ï¼š
> - **500 æ˜¯æœ€ä¼˜å¹³è¡¡ç‚¹**ï¼šè¯¯å·®æœ€ä½ä¸”æ–¹å·®æœ€å°ã€‚
> - è¶…è¿‡ 1000 ç‚¹åè€Œè¯¯å·®ä¸Šå‡ â†’ å¯èƒ½å‡ºç°å¯¹å™ªå£°çš„è¿‡æ‹Ÿåˆã€‚
> - å³ä½¿åªæœ‰ 100 ä¸ªç‚¹ï¼Œè¯¯å·®ä»ä½äº 2%ï¼Œä½“ç° PINN çš„**æé«˜æ•°æ®æ•ˆç‡**ã€‚

---

#### âœ… æŸå¤±åŠ¨æ€ä¸æ¨¡å‹è¡Œä¸º
- **Data Loss**ï¼šå¿«é€Ÿä¸‹é™åè¶‹äºå¹³ç¨³ï¼Œæœªè¶‹è¿‘é›¶ â†’ æˆåŠŸé¿å…å¯¹å™ªå£°è¿‡æ‹Ÿåˆã€‚
- **Physics Loss**ï¼šæŒç»­ä¸‹é™ï¼Œè¯´æ˜æ¨¡å‹é€æ­¥æ»¡è¶³ NLSE çº¦æŸã€‚
- **å‚æ•°å­¦ä¹ è½¨è¿¹**ï¼šä» $\beta=0.0$ å¼€å§‹ï¼Œåœ¨å‰ 1000 epoch å†…è¿…é€Ÿé€¼è¿‘çœŸå®å€¼ï¼Œæ”¶æ•›ç¨³å®šæ— éœ‡è¡ã€‚

---

#### âœ… æ—¶ç©ºé‡å»ºè´¨é‡
- Figure 2 æ˜¾ç¤ºç»å¯¹è¯¯å·®çƒ­å›¾ï¼š
  - æ•´ä½“è¯¯å·® < 2% å³°å€¼æŒ¯å¹…
  - è¾¹ç•ŒåŒºåŸŸç•¥é«˜ï¼ˆå¸¸è§äº DNN è¿‘ä¼¼ï¼‰
  - å­¤å­æ ¸å¿ƒåŒºåŸŸé‡å»ºæä¸ºå‡†ç¡®
- Figure 4 æ˜¾ç¤ºä¸åŒæ—¶é—´åˆ‡ç‰‡ä¸Šï¼ŒPINN é¢„æµ‹ï¼ˆçº¢è‰²å®çº¿ï¼‰ä¸çœŸå®è§£ï¼ˆé»‘è‰²è™šçº¿ï¼‰å‡ ä¹é‡åˆï¼Œè¡¨æ˜å…·å¤‡è‰¯å¥½çš„å¤–æ¨èƒ½åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **PINNs å…·å¤‡å¼ºå¤§çš„æŠ—å™ªèƒ½åŠ›**ï¼šå³ä½¿åœ¨ **20% é«˜æ–¯å™ªå£°**å¹²æ‰°ä¸‹ï¼Œä»èƒ½ä»¥ **< 0.2% çš„ç›¸å¯¹è¯¯å·®**æ¢å¤éçº¿æ€§ç³»æ•° $\beta$ã€‚
2. **ç‰©ç†æ­£åˆ™åŒ–å³ä¸ºä¸€ç§éšå¼æ»¤æ³¢æœºåˆ¶**ï¼šPDE æ®‹å·®çº¦æŸæœ‰æ•ˆåˆ†ç¦»ä¿¡å·ä¸å™ªå£°ï¼Œé˜²æ­¢æ¨¡å‹è¿‡åº¦æ‹Ÿåˆè§‚æµ‹è¯¯å·®ã€‚
3. **é«˜åº¦æ•°æ®é«˜æ•ˆ**ï¼šä»…éœ€ **500 ä¸ªéšæœºé‡‡æ ·ç‚¹**å³å¯å®ç°äºšç™¾åˆ†ä¹‹ä¸€ç²¾åº¦ï¼Œè¿œå°‘äºä¼ ç»Ÿæ–¹æ³•æ‰€éœ€å¯†åº¦ã€‚
4. **è®¡ç®—å¯åŠæ€§å¼º**ï¼šå®Œæ•´æµç¨‹å¯åœ¨å…è´¹äº‘èµ„æºï¼ˆGoogle Colab + Tesla T4ï¼‰ä¸Šå®Œæˆï¼Œæ€»è€—æ—¶çº¦ **80 åˆ†é’Ÿ**ï¼Œä¿ƒè¿›ç§‘ç ”æ™®åŠã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
1. **ç»´åº¦é™åˆ¶**ï¼šå½“å‰ä»…é€‚ç”¨äº 1D NLSEï¼›å‘ 2D/3D æ‰©å±•é¢ä¸´è®¡ç®—æˆæœ¬å‰§å¢ï¼ˆ$O(N^d)$ é…ç‚¹å¢é•¿ï¼‰ã€‚
2. **å™ªå£°å‡è®¾ç†æƒ³åŒ–**ï¼šä»…è€ƒè™‘åŠ æ€§ç™½é«˜æ–¯å™ªå£°ï¼›å®é™…å®éªŒå¯èƒ½å­˜åœ¨éé«˜æ–¯å¼‚å¸¸å€¼ã€ç³»ç»Ÿåå·®æˆ–ç›¸å…³å™ªå£°ç»“æ„ã€‚
3. **å•ä¸€å‚æ•°è¯†åˆ«**ï¼šç›®å‰åªè¯†åˆ« $\beta$ï¼›åŒæ—¶ä¼°è®¡è‰²æ•£ç³»æ•°ä¸éçº¿æ€§ç³»æ•°æ›´å…·æŒ‘æˆ˜æ€§ï¼Œå­˜åœ¨å‚æ•°è€¦åˆé—®é¢˜ã€‚
4. **æŸå¤±æƒé‡å›ºå®š**ï¼šé‡‡ç”¨ç­‰æƒç­–ç•¥ï¼ˆ$\lambda_{\text{data}} = \lambda_{\text{physics}} = 1.0$ï¼‰ï¼Œå¯èƒ½éæœ€ä¼˜ï¼›è‡ªé€‚åº”åŠ æƒ [9] æˆ–å¯è¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚
5. **æ—¶é—´å¤–æ¨æœªéªŒè¯**ï¼šè®­ç»ƒåŒºé—´ä¸º $t \in [0, \pi/2]$ï¼Œæœªæµ‹è¯•é•¿æœŸæ¼”åŒ–å¤–æ¨èƒ½åŠ›ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ¨å¹¿è‡³ **é«˜ç»´ç³»ç»Ÿ**ï¼ˆå¦‚ 2D/3D NLSEã€Gross-Pitaevskii æ–¹ç¨‹ï¼‰
- å®ç° **å¤šå‚æ•°è”åˆåæ¼”**ï¼ˆdispersion + nonlinearityï¼‰
- åº”ç”¨äºçœŸå®å®éªŒæ•°æ®ï¼ˆå¦‚å…‰çº¤é€šä¿¡ã€å†·åŸå­ç³»ç»Ÿï¼‰
- å¼•å…¥ **è‡ªé€‚åº”æŸå¤±åŠ æƒç­–ç•¥**ï¼ˆå¦‚ [9] ä¸­æ¢¯åº¦å¹³è¡¡æ³•ï¼‰
- æ¢ç´¢ **å·ç§¯æˆ–æ³¨æ„åŠ›ç»“æ„** æå‡ç©ºé—´å»ºæ¨¡æ•ˆç‡
- æµ‹è¯• **é•¿æ—¶é—´å¤–æ¨èƒ½åŠ›** ä¸èƒ½é‡å®ˆæ’æ€§è´¨ä¿æŒæƒ…å†µ

---

## ğŸ’¡ æ€»ç»“
æœ¬è®ºæ–‡æˆåŠŸå±•ç¤ºäº† **PINN åœ¨æç«¯å™ªå£°å’Œç¨€ç–æ•°æ®æ¡ä»¶ä¸‹è¿›è¡Œç‰©ç†å‘ç°çš„å¼ºå¤§æ½œåŠ›**ã€‚å®ƒä¸ä»…å®ç°äº†å¯¹ NLSE ä¸­éçº¿æ€§å‚æ•° $\beta$ çš„é«˜ç²¾åº¦è¯†åˆ«ï¼ˆè¯¯å·® < 0.2%ï¼‰ï¼Œè¿˜æ­ç¤ºäº†ç‰©ç†ä¿¡æ¯æ­£åˆ™åŒ–ä½œä¸ºä¸€ç§**å†…åœ¨å»å™ªæœºåˆ¶**çš„æœ‰æ•ˆæ€§ã€‚è¯¥æ–¹æ³•ä¸ºå¤„ç†ç°å®ä¸­â€œè„æ•°æ®â€çš„ç§‘å­¦æœºå™¨å­¦ä¹ æä¾›äº†å¯è¡Œè·¯å¾„ï¼Œå¹¶å› å…¶å¼€æºå®ç°å’Œä½ç¡¬ä»¶é—¨æ§›ï¼Œæœ‰æœ›æ¨åŠ¨ PINN åœ¨æ›´å¤šç‰©ç†é¢†åŸŸçš„åº”ç”¨è½åœ°ã€‚

> ğŸ”— **ä»£ç åœ°å€**ï¼š[https://github.com/p-esteves/pinn-nlse-2026](https://github.com/p-esteves/pinn-nlse-2026) ï¼ˆMIT è®¸å¯è¯ï¼‰

</details>

---

### 3. [From Bits to Chips: An LLM-based Hardware-Aware Quantization Agent for Streamlined Deployment of LLMs](https://arxiv.org/abs/2601.03484)

**Authors**: Kaiyuan Deng, Hangyu Zheng, Minghai Qing, Kunxiong Zhu, Gen Li, Yang Xiao, Lan Emily Zhang, Linke Guo, Bo Hui, Yanzhi Wang, Geng Yuan, Gagan Agrawal, Wei Niu, Xiaolong Ma  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2601.03484v1  

#### Abstract
Deploying models, especially large language models (LLMs), is becoming increasingly attractive to a broader user base, including those without specialized expertise. However, due to the resource constraints of certain hardware, maintaining high accuracy with larger model while meeting the hardware r...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# From Bits to Chips: An LLM-based Hardware-Aware Quantization Agent for Streamlined Deployment of LLMs â€”â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šçš„éƒ¨ç½²é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼š
- **é«˜ç²¾åº¦è¦æ±‚**ï¼šé‡åŒ–åéœ€ä¿æŒæ¨¡å‹æ€§èƒ½ä¸æ˜¾è‘—ä¸‹é™ã€‚
- **ç¡¬ä»¶å…¼å®¹æ€§ä¸æ•ˆç‡**ï¼šä¸åŒç¡¬ä»¶å¹³å°ï¼ˆå¦‚GPUã€ç§»åŠ¨SoCï¼‰å¯¹é‡åŒ–ç­–ç•¥å“åº”å·®å¼‚å¤§ï¼Œæ‰‹åŠ¨è°ƒä¼˜è€—æ—¶ä¸”æ˜“æ¬¡ä¼˜ã€‚

æ­¤å¤–ï¼Œä¼ ç»Ÿè¶…å‚æ•°ä¼˜åŒ–æ–¹æ³•ï¼ˆå¦‚éšæœºæœç´¢ã€è´å¶æ–¯ä¼˜åŒ–ï¼‰åœ¨é«˜ç»´ç©ºé—´ä¸­æ•ˆç‡ä½ï¼Œè€Œç¼–è¯‘å™¨é©±åŠ¨çš„æ–¹æ³•ä¾èµ–é¢„è®¾è§„åˆ™ï¼Œéš¾ä»¥é€‚åº”å¤æ‚å¤šå˜çš„LLMéƒ¨ç½²åœºæ™¯ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šHAQAï¼ˆHardware-Aware Quantization Agentï¼‰
æœ¬æ–‡æå‡º **HAQA** â€”â€” ä¸€ç§åŸºäº **Large Language Model (LLM)** çš„è‡ªåŠ¨åŒ–æ¡†æ¶ï¼Œç”¨äºè”åˆä¼˜åŒ–ï¼š
- **é‡åŒ–æ¨¡å‹å¾®è°ƒé˜¶æ®µ** çš„è¶…å‚æ•°ï¼ˆå¦‚ `learning_rate`, `batch_size`, `LoRA` å‚æ•°ç­‰ï¼‰
- **ç¡¬ä»¶éƒ¨ç½²é˜¶æ®µ** çš„æ‰§è¡Œé…ç½®ï¼ˆå¦‚ CUDA kernel çš„ `blockdim`, `griddim`, å†…å­˜å¸ƒå±€ã€tiling ç­–ç•¥ç­‰ï¼‰

è¯¥ä»£ç†é€šè¿‡ **é™æ€æç¤ºï¼ˆStatic Promptï¼‰ + åŠ¨æ€åé¦ˆï¼ˆDynamic Promptï¼‰** æ„å»ºé—­ç¯ä¼˜åŒ–æµç¨‹ï¼Œå¹¶å¼•å…¥ **ReAct** èŒƒå¼å®ç°â€œæ€è€ƒ-è¡ŒåŠ¨-è§‚å¯Ÿâ€è¿­ä»£æœºåˆ¶ï¼Œæå‡å†³ç­–ç¨³å®šæ€§ä¸å¯è§£é‡Šæ€§ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | HAQA |
|------|--------|-------|
| **ä¼˜åŒ–èŒƒå›´** | ä»…å¾®è°ƒ æˆ– ä»…éƒ¨ç½² | âœ… è”åˆä¼˜åŒ–å¾®è°ƒ + éƒ¨ç½² |
| **ä¸“å®¶ä¾èµ–** | é«˜åº¦ä¾èµ–äººå·¥ç»éªŒ | âœ… è‡ªåŠ¨åŒ–ï¼Œé™ä½éä¸“å®¶é—¨æ§› |
| **æœç´¢æ•ˆç‡** | ç½‘æ ¼/éšæœºæœç´¢ä½æ•ˆï¼›è´å¶æ–¯ä¼˜åŒ–è®¡ç®—å¼€é”€å¤§ | âœ… LLMæ¨ç†å¼•å¯¼ï¼Œå¿«é€Ÿæ”¶æ•› |
| **ç¡¬ä»¶æ„ŸçŸ¥èƒ½åŠ›** | ç¼ºä¹æ·±å±‚ç¡¬ä»¶åˆ†æ | âœ… å¯è¯†åˆ«åç›´è§‰é…ç½®ï¼ˆå¦‚ INT8 > INT4ï¼‰ |
| **é€šç”¨æ€§ä¸é€‚åº”æ€§** | ç‰¹å®šäºæŸç±»æ¨¡å‹æˆ–ç¡¬ä»¶ | âœ… æ”¯æŒå¤šç§æ¨¡å‹ï¼ˆResNet, LLaMAç³»åˆ—ï¼‰å’Œå¹³å°ï¼ˆA6000, OnePlus 11ï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†ä¸æ¨¡å‹
| ç±»å‹ | æ•°æ®é›† | æ¨¡å‹ |
|------|--------|------|
| å›¾åƒåˆ†ç±» | CIFAR-10, ImageNet2012 | ResNet20, ResNet32, ResNet50 |
| å¤§è¯­è¨€æ¨¡å‹ | Alpaca | LLaMA2-7B, LLaMA2-13B, LLaMA3.2-3B, LLaMA3-8B |

é‡åŒ–æŠ€æœ¯ï¼š
- **DoReFa-QAT**ï¼ˆç”¨äºResNetï¼‰
- **QLoRA**ï¼ˆç”¨äºLLaMAç³»åˆ—ï¼Œæ”¯æŒ INT4/INT8 é‡åŒ–ï¼‰

### âš™ï¸ å®éªŒè®¾ç½®
#### å¾®è°ƒä»»åŠ¡
- ä½¿ç”¨ **ChatGPT-4 (GPT-4-0613)** ä½œä¸º LLM Agent
- æœ€å¤§ä¼˜åŒ–è½®æ•°ï¼š10è½®
- æœç´¢ç©ºé—´åŒ…å«å­¦ä¹ ç‡ã€æ‰¹é‡å¤§å°ã€æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ã€LoRA rank/alpha ç­‰ï¼ˆè¯¦è§ Appendix Dï¼‰

#### éƒ¨ç½²ä»»åŠ¡
- åŸºäº `llama.cpp` æ¡†æ¶è¿›è¡Œç«¯åˆ°ç«¯æ¨ç†æµ‹è¯•
- æµ‹è¯•å¹³å°ï¼š
  - **æœåŠ¡å™¨çº§ GPU**ï¼šNVIDIA A6000ï¼ˆ48GBæ˜¾å­˜ï¼ŒCUDA 12.3ï¼‰
  - **ç§»åŠ¨ç«¯ SoC**ï¼šOnePlus 11ï¼ˆSnapdragon 8 Gen 2 + Adreno 740 GPUï¼‰
- è¾“å…¥åºåˆ—é•¿åº¦ï¼š128ï¼Œè¾“å‡º token æ•°ï¼š256
- ä¸»è¦æŒ‡æ ‡ï¼š**Token Generation Speed (tokens/s)**, **Latency (Î¼s)**

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| ç±»åˆ« | æŒ‡æ ‡ |
|------|------|
| å‡†ç¡®æ€§ | Accuracy (%) on downstream tasks (BoolQ, RTE, Winograde, ARC, Hellaswag, MathQA ç­‰) |
| æ¨ç†æ•ˆç‡ | Latency (Î¼s), Throughput (tokens/s), Speed-up vs baseline |
| å†…å­˜çº¦æŸ | æ˜¯å¦æ»¡è¶³æŒ‡å®šå†…å­˜é™åˆ¶ï¼ˆå¦‚ 10GBï¼‰ |
| æ”¶æ•›æ€§ | Accuracy éšè¿­ä»£è½®æ¬¡çš„å˜åŒ–æ›²çº¿ï¼ˆè§ Figure 4ï¼‰ |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **Default** | å…¨ç²¾åº¦æ¨¡å‹æ¨èçš„é»˜è®¤è¶…å‚ |
| **Human** | äººç±»ä¸“å®¶æ‰‹åŠ¨è°ƒå‚å¹³å‡ç»“æœ |
| **Local Search / Random Search** | å±€éƒ¨/éšæœºæœç´¢ |
| **Bayesian Optimization** | è´å¶æ–¯ä¼˜åŒ–ï¼ˆSurrogate Modelï¼‰ |
| **NSGA-II** | å¤šç›®æ ‡è¿›åŒ–ç®—æ³• |
| **llama.cpp (Default)** | åŸå§‹éƒ¨ç½²åŸºå‡†ï¼ˆæ— ä¼˜åŒ–ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### âœ… å‡†ç¡®æ€§æå‡ï¼ˆTable 1 & Table 2ï¼‰
| æ¨¡å‹ | é‡åŒ–æ–¹å¼ | HAQA å‡†ç¡®ç‡ | æœ€ä½³åŸºçº¿ï¼ˆHumanï¼‰ | æå‡å¹…åº¦ |
|------|----------|-------------|------------------|---------|
| ResNet20 (w4a4) | INT4 | **88.38%** | 87.17% | +1.21pp |
| ResNet32 (w4a4) | INT4 | **90.02%** | 88.90% | +1.12pp |
| LLaMA2-7B (INT4) | INT4 | **63.11% (avg)** | 62.04% | +1.07pp |
| LLaMA2-13B (INT4) | INT4 | **65.57% (avg)** | 63.96% | +1.61pp |
| LLaMA3-8B (INT4) | INT4 | **67.87% (avg)** | 66.60% | +1.27pp |

> æ³¨ï¼šåœ¨æä½æ¯”ç‰¹ï¼ˆå¦‚ w2a2ï¼‰ä¸‹ï¼ŒHAQA æ˜¯å”¯ä¸€èƒ½ç¨³å®šæ”¶æ•›å¹¶å–å¾—è¾ƒå¥½æ€§èƒ½çš„æ–¹æ³•ã€‚

#### âš¡ æ¨ç†åŠ é€Ÿæ•ˆæœï¼ˆFigure 5 & Table 3ï¼‰
| å¹³å° | æ¨¡å‹ | é‡åŒ– | é»˜è®¤åå (tokens/s) | HAQA åå | åŠ é€Ÿæ¯” |
|------|------|--------|--------------------|------------|--------|
| A6000 GPU | LLaMA2-7B | INT4 | ~4.0 | ~6.0 | **~1.5Ã—** |
| A6000 GPU | LLaMA3-8B | INT8 | ~3.5 | ~5.0 | **~1.4Ã—** |

| Kernel | è¾“å…¥å°ºå¯¸ | é»˜è®¤å»¶è¿Ÿ (Î¼s) | HAQA ä¼˜åŒ–å | åŠ é€Ÿæ¯” |
|--------|-----------|----------------|--------------|--------|
| Softmax | [1024,64,32] | 51.70 | 27.96 | **1.85Ã—** |
| SiLU    | [11008,64,1] | 10.44 | 4.51  | **2.31Ã—** |
| MatMul  | [2048,128,2048] | 63.20 | 38.85 | **1.63Ã—** |

> åœ¨å…³é”®è®¡ç®— kernel ä¸Šå®ç°äº† **1.1Ã— ~ 2.3Ã— çš„å»¶è¿Ÿé™ä½**

#### ğŸ’¡ åç›´è§‰ä½†æœ‰æ•ˆçš„ç¡¬ä»¶è‡ªé€‚åº”ç­–ç•¥ï¼ˆSection 4.4ï¼‰
åœ¨ **OnePlus 11ï¼ˆAdreno 740 GPUï¼‰** ä¸Šï¼š
- å°½ç®¡ INT4 ç†è®ºä¸Šæ›´é«˜æ•ˆï¼Œä½†å®é™…è¡¨ç°ä¸å¦‚ INT8
- åŸå› ï¼šAdreno 740 **ä¸åŸç”Ÿæ”¯æŒ INT4**ï¼Œéœ€é€šè¿‡ INT8 æ¨¡æ‹Ÿ + é¢å¤–ä½æ“ä½œé‡å»ºå€¼ â†’ å¼•å…¥é¢å¤–å¼€é”€
- HAQA æ­£ç¡®è¯†åˆ«æ­¤ç°è±¡ï¼Œæ¨èä½¿ç”¨ **INT8**ï¼Œå®æµ‹æ€§èƒ½ä¼˜äº INT4

| æ¨¡å‹ | FP16 | INT8 | INT4 |
|------|------|------|------|
| openllama-3B | 5.11 | **5.25** | 4.95 |
| tinylama-1.1B | 11.17 | **11.23** | 10.43 |

> è¡¨æ˜ HAQA èƒ½è‡ªåŠ¨å‘ç°å¹¶åˆ©ç”¨ç¡¬ä»¶ç‰¹æ€§ï¼Œé¿å…â€œç†è®ºæœ€ä¼˜ â‰  å®é™…æœ€ä¼˜â€çš„é™·é˜±

#### ğŸ“‰ æ”¶æ•›é€Ÿåº¦ä¼˜åŠ¿ï¼ˆFigure 4ï¼‰
- HAQA åœ¨ **æ›´å°‘è½®æ¬¡å†…è¾¾åˆ°æ›´é«˜å‡†ç¡®ç‡**
- ç›¸æ¯”å…¶ä»–æ–¹æ³•ï¼ˆå¦‚ Bayesian, Randomï¼‰ï¼Œå…¶ä¼˜åŒ–è·¯å¾„æ›´å…·æ–¹å‘æ€§å’Œç¨³å®šæ€§
- åˆ©ç”¨å†å²åé¦ˆé¿å…é‡å¤æ— æ•ˆå°è¯•ï¼Œæå‡æœç´¢æ•ˆç‡

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **HAQA æ˜¾è‘—æå‡äº†é‡åŒ–æ¨¡å‹çš„å‡†ç¡®æ€§ä¸æ¨ç†æ•ˆç‡**  
   - åœ¨å¤šä¸ª LLM å’Œ CNN æ¨¡å‹ä¸Šå‡è¶…è¶Šäººå·¥è°ƒä¼˜å’Œå…¶ä»–è‡ªåŠ¨åŒ–æ–¹æ³•ã€‚
   - åœ¨ INT4 æé™é‡åŒ–ä¸‹ä»èƒ½ç»´æŒé«˜æ€§èƒ½ï¼Œç¼©å°ä¸ FP16 çš„å·®è·ã€‚

2. **å®ç°äº†è·¨é˜¶æ®µè”åˆä¼˜åŒ–ï¼ˆfine-tuning + deploymentï¼‰**  
   - é¦–æ¬¡å°† LLM Agent åº”ç”¨äºä»è®­ç»ƒåˆ°éƒ¨ç½²çš„å®Œæ•´é“¾æ¡ã€‚
   - é€šè¿‡ååŒè°ƒå‚å®ç°â€œsynergistic optimizationâ€ï¼Œè€Œéå­¤ç«‹ä¼˜åŒ–å„æ¨¡å—ã€‚

3. **å…·å¤‡å¼ºå¤§çš„ç¡¬ä»¶æ„ŸçŸ¥ä¸è‡ªé€‚åº”èƒ½åŠ›**  
   - èƒ½åˆ†æç¡¬ä»¶æ¶æ„ç»†èŠ‚ï¼ˆå¦‚æ˜¯å¦æ”¯æŒç‰¹å®šæŒ‡ä»¤é›†ã€memory bandwidthï¼‰åšå‡ºåˆç†åˆ¤æ–­ã€‚
   - æˆåŠŸæ­ç¤ºå¹¶éªŒè¯äº†â€œINT8 æ¯” INT4 æ›´å¿«â€è¿™ç±»åç›´è§‰ç°è±¡ã€‚

4. **ç”¨æˆ·å‹å¥½æ€§å¼ºï¼Œæ˜“äºé›†æˆä¸å¤ç°**  
   - æä¾›æ ‡å‡†åŒ– prompt è®¾è®¡æ¨¡æ¿ï¼ˆAppendix Eï¼‰
   - æ§åˆ¶å†å²é•¿åº¦é˜²æ­¢è¶…å‡ºä¸Šä¸‹æ–‡çª—å£
   - æ€»æˆæœ¬ä½å»‰ï¼šçº¦ **$5** å®Œæˆä¸¤ä¸ªæ¨¡å‹çš„å…¨æµç¨‹ä¼˜åŒ–ï¼ˆAPI è°ƒç”¨è´¹ç”¨ï¼‰

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–å¤–éƒ¨ LLM API**ï¼ˆå¦‚ GPT-4ï¼‰ï¼Œå­˜åœ¨å»¶è¿Ÿã€æˆæœ¬å’Œéšç§é¡¾è™‘
- å½“å‰æœªæ”¯æŒå®Œå…¨æœ¬åœ°åŒ–éƒ¨ç½²çš„è½»é‡çº§ LLM Agent
- å¯¹ prompt engineering æ•æ„Ÿï¼Œéœ€ç²¾å¿ƒè®¾è®¡é™æ€æç¤ºä»¥ä¿è¯ç¨³å®šæ€§
- å®éªŒä¸»è¦é›†ä¸­äº NVIDIA å’Œé«˜é€šå¹³å°ï¼Œå°šæœªè¦†ç›–æ›´å¤šå¼‚æ„ç¡¬ä»¶ï¼ˆå¦‚ Apple Silicon, Ascendï¼‰

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- å¼€å‘ **å¼€æºå°å‹ LLM Agent** æ›¿ä»£é—­æºå¤§æ¨¡å‹ï¼Œå®ç°å»ä¸­å¿ƒåŒ–ä¼˜åŒ–
- æ‰©å±•è‡³ **å¤šæ¨¡æ€æ¨¡å‹** å’Œ **è¾¹ç¼˜é›†ç¾¤ååŒéƒ¨ç½²**
- å¼•å…¥ **å¼ºåŒ–å­¦ä¹  + LLM** æ··åˆæ¶æ„ï¼Œè¿›ä¸€æ­¥æå‡æ¢ç´¢æ•ˆç‡
- æ„å»ºç»Ÿä¸€çš„ **AI éƒ¨ç½²æ™ºèƒ½ä½“ç”Ÿæ€**ï¼Œæ”¯æŒè‡ªåŠ¨è¯Šæ–­ã€ä¿®å¤ä¸è¿ç§»

---

## æ€»ç»“
> **HAQA æ˜¯é¦–ä¸ªå°† LLM Agent æˆåŠŸåº”ç”¨äºé‡åŒ–æ¨¡å‹å¾®è°ƒä¸ç¡¬ä»¶éƒ¨ç½²è”åˆä¼˜åŒ–çš„å·¥ä½œ**ã€‚å®ƒä¸ä»…æ˜¾è‘—æå‡äº†æ¨¡å‹ç²¾åº¦ä¸æ¨ç†é€Ÿåº¦ï¼Œæ›´é‡è¦çš„æ˜¯é™ä½äº† AI éƒ¨ç½²çš„æŠ€æœ¯é—¨æ§›ï¼Œä½¿éä¸“å®¶ä¹Ÿèƒ½è½»æ¾å®Œæˆå¤æ‚çš„æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿä»»åŠ¡ã€‚å…¶â€œç¡¬ä»¶æ„ŸçŸ¥ + åç›´è§‰æ´å¯Ÿâ€çš„èƒ½åŠ›å±•ç¤ºäº† LLM åœ¨ç³»ç»Ÿçº§ä¼˜åŒ–ä¸­çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºæœªæ¥æ„å»ºå…¨è‡ªåŠ¨åŒ–çš„ AI å·¥ç¨‹æµæ°´çº¿å¥ å®šäº†åŸºç¡€ã€‚

</details>

---

### 4. [LUT-KAN: Segment-wise LUT Quantization for Fast KAN Inference](https://arxiv.org/abs/2601.03332)

**Authors**: Oleksandr Kuznetsov  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.03332v1  

#### Abstract
Kolmogorov--Arnold Networks (KAN) replace scalar weights by learnable univariate functions, often implemented with B-splines. This design can be accurate and interpretable, but it makes inference expensive on CPU because each layer requires many spline evaluations. Standard quantization toolchains a...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# LUT-KAN: Segment-wise LUT Quantization for Fast KAN Inference â€”â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

Kolmogorov-Arnold Networks (KAN) é€šè¿‡å°†ä¼ ç»Ÿç¥ç»ç½‘ç»œä¸­çš„æ ‡é‡æƒé‡æ›¿æ¢ä¸ºå¯å­¦ä¹ çš„ä¸€å…ƒå‡½æ•°ï¼ˆé€šå¸¸ç”¨ B-splines å®ç°ï¼‰ï¼Œåœ¨ä¿æŒæ¨¡å‹ç´§å‡‘æ€§å’Œé«˜é¢„æµ‹ç²¾åº¦çš„åŒæ—¶æä¾›äº†è‰¯å¥½çš„**å¯è§£é‡Šæ€§**ã€‚ç„¶è€Œï¼Œè¿™ç§è®¾è®¡å¸¦æ¥äº†æ˜¾è‘—çš„æ¨ç†å¼€é”€ï¼Œå°¤å…¶æ˜¯åœ¨ CPU ä¸Šï¼š

- **è®¡ç®—ç“¶é¢ˆ**ï¼šæ¯ä¸ª KAN å±‚éœ€è¦å¯¹å¤§é‡ B-spline å‡½æ•°è¿›è¡Œé‡å¤æ±‚å€¼ï¼Œæ¶‰åŠæŸ¥æ‰¾èŠ‚ç‚¹åŒºé—´ã€é€’å½’è®¡ç®—åŸºå‡½æ•°ç­‰æ“ä½œï¼Œå¯¼è‡´æ¨ç†å»¶è¿Ÿé«˜ã€‚
- **é‡åŒ–å›°éš¾**ï¼šæ ‡å‡†çš„é‡åŒ–å·¥å…·é“¾ï¼ˆå¦‚ INT8 GEMMï¼‰é’ˆå¯¹çŸ©é˜µä¹˜æ³•ä¼˜åŒ–ï¼Œè€Œ KAN çš„æ ¸å¿ƒè¿ç®—æ˜¯å‡½æ•°æ±‚å€¼è€ŒéçŸ©é˜µè¿ç®—ï¼Œéš¾ä»¥ç›´æ¥åº”ç”¨ã€‚
- **éƒ¨ç½²ä¸ç¡®å®šæ€§**ï¼šç¼ºä¹æ˜ç¡®çš„ **Out-of-Bounds (OOB)** è¡Œä¸ºå®šä¹‰ï¼Œä¸åŒå®ç°å¯èƒ½äº§ç”Ÿä¸ä¸€è‡´çš„ç»“æœã€‚

å› æ­¤ï¼Œå¦‚ä½•åœ¨ä¿è¯ç²¾åº¦çš„å‰æä¸‹ï¼Œå®ç°**å¿«é€Ÿã€å¯ç§»æ¤ã€è¯­ä¹‰ä¸€è‡´çš„ CPU æ¨ç†**æˆä¸º KAN éƒ¨ç½²çš„å…³é”®æŒ‘æˆ˜ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **LUT-KAN**ï¼Œä¸€ç§é¢å‘ PyKAN é£æ ¼ KAN å±‚çš„**åˆ†æ®µæŸ¥æ‰¾è¡¨ï¼ˆsegment-wise LUTï¼‰ç¼–è¯‘ä¸é‡åŒ–æ–¹æ³•**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³åŒ…æ‹¬ï¼š

1. **Segment-wise LUT ç¼–è¯‘**  
   å°†æ¯æ¡è¾¹ä¸Šçš„å¯å­¦ä¹ ä¸€å…ƒå‡½æ•° $\phi_i(x)$ åœ¨æ¯ä¸ª knot segment å†…é¢„è®¡ç®—å¹¶å­˜å‚¨ä¸º LUTï¼Œä½¿ç”¨çº¿æ€§æ’å€¼æ¢å¤è¿ç»­è¾“å‡ºã€‚LUT åˆ†è¾¨ç‡ç”±æ¯æ®µé‡‡æ ·ç‚¹æ•° $L$ æ§åˆ¶ã€‚

2. **Affine int8/uint8 é‡åŒ–**  
   å¯¹æ¯ä¸ª segment çš„ LUT å€¼é‡‡ç”¨ä»¿å°„é‡åŒ–ï¼š
   - **å¯¹ç§°é‡åŒ–ï¼ˆsymmetric int8ï¼‰**ï¼šèŒƒå›´ [-127, 127]ï¼Œé›¶ä¸­å¿ƒåŒ–
   - **éå¯¹ç§°é‡åŒ–ï¼ˆasymmetric uint8ï¼‰**ï¼šèŒƒå›´ [0, 255]ï¼Œæ”¯æŒåç§»
   ç»Ÿä¸€åé‡åŒ–å…¬å¼ç¡®ä¿æ¨ç†ä¸€è‡´æ€§ã€‚

3. **æ˜¾å¼çš„ OOB è¯­ä¹‰å¥‘çº¦ï¼ˆExplicit OOB Contractï¼‰**  
   æ˜ç¡®å®šä¹‰ä¸¤ä¸ªæ­£äº¤ç»´åº¦çš„è¡Œä¸ºï¼š
   - **Boundary Mode**ï¼š`half_open` vs `closed`ï¼Œå†³å®šåŸŸå†…/å¤–åˆ¤å®š
   - **OOB Policy**ï¼š`clip_x`ï¼ˆè¾“å…¥é¥±å’Œï¼‰ vs `zero_spline`ï¼ˆä»…æŠ‘åˆ¶æ ·æ¡åˆ†æ”¯ï¼‰
   è¿™äº›é…ç½®è¢«å›ºåŒ–åœ¨ LUT artifact ä¸­ï¼Œç¡®ä¿è·¨å¹³å°è¡Œä¸ºä¸€è‡´ã€‚

4. **â€œè¯šå®åŸºçº¿â€è¯„ä¼°æ–¹æ³•è®ºï¼ˆHonest Baseline Methodologyï¼‰**  
   ä¸ºé¿å…æ··æ·†â€œè¡¨ç¤ºå½¢å¼æ”¹è¿›â€ä¸â€œåç«¯ä¼˜åŒ–â€ï¼Œä½œè€…æå‡ºå…¬å¹³æ¯”è¾ƒï¼š
   - åœ¨ç›¸åŒåç«¯ä¸‹å¯¹æ¯”ï¼š**NumPy B-spline vs NumPy LUT**
   - æˆ– **Numba B-spline vs Numba LUT**
   ä»è€Œåˆ†ç¦»å‡ºçœŸæ­£çš„â€œLUT vs æ ·æ¡â€å¸¦æ¥çš„åŠ é€Ÿæ•ˆæœã€‚

5. **è½»é‡çº§å¯éƒ¨ç½² artifact**  
   è¾“å‡ºä¸ºå‹ç¼© NPZ æ–‡ä»¶ + JSON æ¸…å•ï¼Œå¯åœ¨æ—  PyTorch å’Œæ ·æ¡åº“ä¾èµ–çš„æƒ…å†µä¸‹åŠ è½½æ‰§è¡Œï¼Œé€‚åˆè¾¹ç¼˜éƒ¨ç½²ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | LUT-KAN çš„ä¼˜åŠ¿ |
|------|----------------|
| **é€Ÿåº¦** | ç›¸æ¯”åŸå§‹ B-spline æ±‚å€¼ï¼Œåœ¨ç›¸åŒåç«¯ä¸‹å®ç° **10â€“14Ã— åŠ é€Ÿ**ï¼ˆNumPy/Numbaï¼‰ |
| **ç²¾åº¦ä¿ç•™** | åœ¨ $L=64$ ä¸‹ï¼Œä¸‹æ¸¸ä»»åŠ¡ F1 åˆ†æ•°ä¸‹é™ < 0.0002ï¼Œå‡ ä¹æ— æŸ |
| **å¯å¤ç°æ€§ä¸ä¸€è‡´æ€§** | æ˜¾å¼ OOB è¯­ä¹‰ + å›ºå®šç‰ˆæœ¬ä»£ç å‘å¸ƒï¼ˆGitHub tag v1.0.0ï¼‰ï¼Œç¡®ä¿ç»“æœå¯å¤ç° |
| **å·¥ç¨‹å®ç”¨æ€§** | artifact è½»é‡ã€ç‹¬ç«‹äºè®­ç»ƒæ¡†æ¶ï¼Œä¾¿äºé›†æˆåˆ°ç”Ÿäº§ç³»ç»Ÿ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

1. **æ§åˆ¶å®éªŒï¼ˆControlled Sweepsï¼‰**  
   - ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„ KAN å±‚ï¼ˆè¾“å…¥ dim=10, è¾“å‡º dim=8, grid=8, degree=3ï¼‰
   - è¾“å…¥åˆ†å¸ƒï¼šæ ‡å‡†æ­£æ€åˆ†å¸ƒè£å‰ªè‡³ knot domain
   - ç›®çš„ï¼šæ§åˆ¶å˜é‡ç ”ç©¶ LUT å‚æ•°å½±å“

2. **çœŸå®æ¡ˆä¾‹ç ”ç©¶ï¼ˆCase Studyï¼‰**  
   - **CICIDS2017 æ•°æ®é›†**ï¼šç”¨äº DoS æ”»å‡»æ£€æµ‹ï¼ˆBENIGN vs DoS Hulkï¼‰
   - ç‰¹å¾æ•°é‡ï¼š78
   - æµ‹è¯•é›†å¤§å°ï¼š69,523 æ ·æœ¬
   - æ¨¡å‹ç»“æ„ï¼š[78 â†’ 32 â†’ 16 â†’ 1]ï¼Œå…± 3,024 æ¡è¾¹

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **LUT æ„é€ å‚æ•°**
- åˆ†è¾¨ç‡ $L \in \{16, 32, 64, 128\}$
- é‡åŒ–æ–¹æ¡ˆï¼šsymmetric int8 / asymmetric uint8
- æ’å€¼æ–¹å¼ï¼šlinear
- è¾¹ç•Œæ¨¡å¼ï¼šclosed / half_open
- OOB ç­–ç•¥ï¼šclip_x / zero_spline
- å€¼è¡¨ç¤ºï¼š`value_repr = spline_component`ï¼ˆæ¨èï¼‰

#### **è¯„ä¼°æŒ‡æ ‡**

| ç±»åˆ« | æŒ‡æ ‡ |
|------|------|
| **å‡†ç¡®æ€§** | MAEï¼ˆin-range / OOBï¼‰ã€MaxAbs Errorã€åˆ†ç±» Accuracy/Precision/Recall/F1 |
| **é€Ÿåº¦** | Steady-state latency (ms/iter, ms/sample)ï¼ŒSpeedupï¼ˆç›¸å¯¹åŒåç«¯ B-splineï¼‰ |
| **å†…å­˜** | LUT artifact å¤§å°ï¼ˆbytesï¼‰ã€LUT/float_model_ratio |
| **é²æ£’æ€§** | OOB è§¦å‘ç‡ï¼ˆOOB_any_fracï¼‰ã€OOB å­é›†è¯¯å·®åˆ†æ |

#### **é‡å¤æ€§ä¿éšœ**
- æ‰€æœ‰å®éªŒè¿è¡Œ 5 æ¬¡ï¼ˆseeds 0â€“4ï¼‰
- æŠ¥å‘Šå‡å€¼ Â± æ ‡å‡†å·®ï¼ˆmeanÂ±stdï¼‰
- å…¬å¼€å®Œæ•´å®éªŒè„šæœ¬ä¸å›ºå®šç‰ˆæœ¬ä»£ç 

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

- **ä¸å…¬å¹³åŸºçº¿ï¼ˆStack-levelï¼‰**ï¼šPyTorch float B-spline vs NumPy/Numba LUTï¼ˆæ··åˆäº†åç«¯å·®å¼‚ï¼‰
- **è¯šå®åŸºçº¿ï¼ˆHonest Baselineï¼‰**ï¼š
  - NumPy B-spline vs NumPy LUT
  - Numba B-spline vs Numba LUT
- å¼ºè°ƒåªåŸºäºâ€œè¯šå®åŸºçº¿â€å¾—å‡ºè¡¨ç¤ºå½¢å¼çš„åŠ é€Ÿæ”¶ç›Š

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… **ç²¾åº¦è¡¨ç°ï¼ˆ$L=64$ï¼‰**
| è®¾ç½® | MAE (in-range) | MaxAbs (in-range) |
|------|----------------|--------------------|
| symmetric int8 | $1.59 \times 10^{-4}$ | $8.02 \times 10^{-4}$ |
| asymmetric uint8 | $1.58 \times 10^{-4}$ | $8.33 \times 10^{-4}$ |

- è¯¯å·®éš $L$ å¢å¤§å‘ˆ $O(1/L)$ è¡°å‡ï¼Œç¬¦åˆçº¿æ€§æ’å€¼ç†è®ºé¢„æœŸ
- ä¸¤ç§é‡åŒ–æ–¹æ¡ˆç²¾åº¦å‡ ä¹æ— å·®åˆ«

#### âœ… **æ¨ç†é€Ÿåº¦ï¼ˆè¯šå®åŸºçº¿ï¼‰**
| åç«¯ | å¹³å‡ Speedup (vs B-spline) |
|------|----------------------------|
| **NumPy** | **12.3Ã— Â± 1.2Ã—** |
| **Numba** | **10.5Ã— Â± 0.6Ã—** |

> ç¤ºä¾‹ï¼ˆNumbaï¼‰ï¼š
> - B-spline: ~6.25 ms/iter
> - LUT: ~0.60 ms/iter â†’ **~10.4Ã— åŠ é€Ÿ**

- LUT æ€§èƒ½ç¨³å®šï¼Œä¸å— $L$ å½±å“ï¼ˆå†…å­˜ç»‘å®šï¼Œéè®¡ç®—ç»‘å®šï¼‰

#### âœ… **å†…å­˜å¼€é”€**
| $L$ | LUT / Float Model Ratio |
|-----|--------------------------|
| 16 | 3.07Ã— |
| 32 | 5.51Ã— |
| **64** | **10.40Ã—** |
| 128 | 20.18Ã— |

- ä¸»è¦å¼€é”€æ¥è‡ª `q_table`ï¼ˆå  73â€“88%ï¼‰
- åœ¨ $L=64$ æ—¶çº¦ä¸º **10Ã— å†…å­˜ä»£ä»·**

#### âœ… **çœŸå®ä»»åŠ¡æ€§èƒ½ï¼ˆDoS æ£€æµ‹ï¼‰**
| æŒ‡æ ‡ | Float Model | LUT (NumPy/Numba) | å·®å¼‚ |
|------|-------------|--------------------|-------|
| **F1 Score** | 0.9900 | 0.9898 | â†“0.0002 |
| **Accuracy** | 0.9899 | 0.9898 | â†“0.0001 |
| **Latency (ms/sample)** | 0.8850 | 0.0596 (NumPy) / 0.0138 (Numba) | **â†“12Ã— / â†“64Ã—** |

- **Steady-state åŠ é€Ÿ**ï¼š
  - NumPy LUT vs PyTorch float: **14.9Ã—**
  - Numba LUT vs PyTorch float: **64.4Ã—**
- **è¯šå®åŸºçº¿åŠ é€Ÿ**ï¼ˆæ›´ä¿å®ˆï¼‰ï¼š
  - NumPy LUT vs NumPy B-spline: **~12Ã—**
  - Numba LUT vs Numba B-spline: **~10Ã—**

#### âœ… **æ¶ˆèå®éªŒç»“æœ**

##### ï¼ˆ1ï¼‰OOB é²æ£’æ€§çŸ©é˜µï¼ˆ$L=64$, symmetric int8ï¼‰

| Boundary | OOB Policy | OOB frac | MAE (OOB) | MaxAbs (OOB) |
|---------|------------|----------|-----------|--------------|
| closed | clip_x | 0.000 | N/A | N/A |
| half_open | clip_x | 0.101 | 0.000312 | 0.000661 |
| half_open | zero_spline | 0.101 | 0.0245 | **0.0892** |

- `half_open + zero_spline` å¯¼è‡´ä¸¥é‡ OOB é”™è¯¯ï¼ˆå› è¾¹ç•Œå¤„å‡½æ•°å€¼çªå˜ï¼‰
- æ¨èï¼šè‹¥è¾“å…¥ä¼šè¢«è£å‰ªï¼Œåˆ™ä½¿ç”¨ `closed` + `clip_x`

##### ï¼ˆ2ï¼‰é‡åŒ–æ–¹æ¡ˆå¯¹æ¯”ï¼ˆ$L=64$ï¼‰
- symmetric int8 ä¸ asymmetric uint8 åœ¨æµ‹è¯•åœºæ™¯ä¸‹ç²¾åº¦å‡ ä¹ä¸€è‡´
- éå¯¹ç§°é‡åŒ–æ›´é€‚åˆéé›¶å‡å€¼åˆ†å¸ƒï¼›å¯¹ç§°æ›´ç®€å•ï¼ˆæ— éœ€å­˜å‚¨åç§»ï¼‰

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **LUT-KAN æ˜¾è‘—æå‡ KAN æ¨ç†é€Ÿåº¦**  
   åœ¨ç›¸åŒåç«¯ä¼˜åŒ–æ¡ä»¶ä¸‹ï¼Œå®ç° **10â€“14Ã— çš„ CPU æ¨ç†åŠ é€Ÿ**ï¼Œä¸”åŠ é€Ÿæºäºè¡¨ç¤ºå½¢å¼æœ¬èº«ï¼ˆéå‘é‡åŒ–/JIT æ•ˆåº”ï¼‰ã€‚

2. **ç²¾åº¦æŸå¤±æå°**  
   åœ¨ $L=64$ ä¸‹ï¼Œå‡½æ•°é€¼è¿‘ MAE ~$1.6 \times 10^{-4}$ï¼ŒçœŸå®ä»»åŠ¡ F1 ä¸‹é™ < 0.0002ï¼Œæ»¡è¶³å¤§å¤šæ•°åº”ç”¨åœºæ™¯éœ€æ±‚ã€‚

3. **å†…å­˜å¼€é”€å¯æ§**  
   å†…å­˜å¢é•¿çº¦ 10Ã—ï¼ˆ$L=64$ï¼‰ï¼Œä¸»è¦ç”±é‡åŒ–è¡¨ä¸»å¯¼ï¼Œå¯é€šè¿‡é™ä½ $L$ æˆ–å‚æ•°å‹ç¼©è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚

4. **OOB è¯­ä¹‰è‡³å…³é‡è¦**  
   ä¸åŒ boundary mode ä¸ oob_policy ç»„åˆä¼šå¯¼è‡´æ˜¾è‘—ä¸åŒçš„ OOB è¡Œä¸ºã€‚å¿…é¡»å°†å…¶ä½œä¸ºæ¨¡å‹éƒ¨ç½²å¥‘çº¦çš„ä¸€éƒ¨åˆ†æ˜ç¡®å®šä¹‰ã€‚

5. **â€œè¯šå®åŸºçº¿â€æ–¹æ³•è®ºæœ‰æ•ˆæ­ç¤ºçœŸå®æ”¶ç›Š**  
   è‹¥ä¸æ§åˆ¶åç«¯ä¸€è‡´æ€§ï¼Œå®¹æ˜“å¤¸å¤§ LUT çš„ä¼˜åŠ¿ï¼›æœ¬æ–‡æ–¹æ³•æå‡äº†è¯„ä¼°å¯ä¿¡åº¦ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

| å±€é™æ€§ | è¯´æ˜ |
|--------|------|
| **å†…å­˜å¼€é”€å¤§** | Dense å±‚è¾¹æ•°å¤šæ—¶ï¼ŒLUT artifact å¯èƒ½è¿‡å¤§ï¼ˆé¦–å±‚å  82.5%ï¼‰ |
| **é™æ€ç¼–è¯‘** | æ¨¡å‹æ›´æ–°éœ€é‡æ–°ç¼–è¯‘ LUTï¼Œä¸æ”¯æŒåœ¨çº¿å¾®è°ƒ |
| **æœªå®Œå…¨æ•´æ•°é‡åŒ–** | åé‡åŒ–ã€ç´¯åŠ ä»ä½¿ç”¨ float32ï¼Œæœªå®ç°ç«¯åˆ°ç«¯ integer pipeline |
| **æ ¡å‡†æ•æ„Ÿæ€§** | é‡åŒ–èŒƒå›´ä¾èµ–æ ¡å‡†æ•°æ®åˆ†å¸ƒï¼Œè‹¥éƒ¨ç½²æ•°æ®åç§»å¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™ |
| **å•ç²¾åº¦å‚æ•°å­˜å‚¨** | scale/y_min ä½¿ç”¨ float32ï¼Œå¯ç”¨ float126 å‹ç¼©ä½†å¯èƒ½å¼•å…¥æ•°å€¼è¯¯å·® |

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **ç¨€ç– LUT è¡¨ç¤º**ï¼šç»“åˆ edge pruning æˆ–ä½ç§©åˆ†è§£å‡å°‘ dense å±‚å†…å­˜å ç”¨
2. **è‡ªé€‚åº”åˆ†è¾¨ç‡ LUT**ï¼šæ ¹æ®å‡½æ•°å¤æ‚åº¦åŠ¨æ€è°ƒæ•´å„ segment çš„ $L$
3. **å…¨æ•´æ•°æ¨ç†æµæ°´çº¿**ï¼šæ¢ç´¢ int8 ç´¯åŠ ä¸å®šç‚¹è¿ç®—æ”¯æŒ
4. **åŠ¨æ€é‡åŒ–ä¸åœ¨çº¿ç¼–è¯‘**ï¼šæ”¯æŒè½»é‡çº§æ¨¡å‹æ›´æ–°åçš„è‡ªåŠ¨ LUT ç”Ÿæˆ
5. **ç¡¬ä»¶ååŒè®¾è®¡**ï¼šé’ˆå¯¹ LUT-KAN è®¾è®¡ä¸“ç”¨è¾¹ç¼˜æ¨ç†èŠ¯ç‰‡æˆ– FPGA å®ç°

---

> ğŸ”— **ä»£ç ä¸å¤ç°**  
> æ‰€æœ‰ä»£ç ã€å®éªŒè„šæœ¬ã€artifact å‡å·²å¼€æºï¼Œå¸¦å›ºå®š release tagï¼ˆv1.0.0ï¼‰ï¼š
> - LUT-KAN æ¡†æ¶ï¼š[https://github.com/KuznetsovKarazin/lut-kan](https://github.com/KuznetsovKarazin/lut-kan)
> - DoS æ£€æµ‹æ¡ˆä¾‹ï¼š[https://github.com/KuznetsovKarazin/kan-dos-detection](https://github.com/KuznetsovKarazin/kan-dos-detection)

</details>

---

### 5. [ReEfBench: Quantifying the Reasoning Efficiency of LLMs](https://arxiv.org/abs/2601.03550)

**Authors**: Zhizhang Fu, Yuancheng Gu, Chenkai Hu, Hanmeng Liu, Yue Zhang  
**Category**: cs.AI  
**Published**: 2026-01-08  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.03550v1  

#### Abstract
Test-time scaling has enabled Large Language Models (LLMs) to tackle complex reasoning, yet the limitations of current Chain-of-Thought (CoT) evaluation obscures whether performance gains stem from genuine reasoning or mere verbosity. To address this, (1) we propose a novel neuro-symbolic framework ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# ReEfBench: Quantifying the Reasoning Efficiency of LLMs è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¨ç†èƒ½åŠ›çš„è¯„ä¼°ä¸»è¦ä¾èµ– **Chain-of-Thought (CoT)** è¾“å‡ºé•¿åº¦æˆ–æœ€ç»ˆç­”æ¡ˆå‡†ç¡®æ€§ï¼Œå­˜åœ¨ä»¥ä¸‹ç¼ºé™·ï¼š
- **æ— æ³•åŒºåˆ†â€œçœŸå®æ¨ç†â€ä¸â€œå†—ä½™ç”Ÿæˆâ€**ï¼šæ¨¡å‹å¯èƒ½é€šè¿‡â€œè¿‡åº¦æ€è€ƒâ€ï¼ˆoverthinkingï¼‰ç”Ÿæˆå¤§é‡æ— æ„ä¹‰çš„ä¸­é—´æ­¥éª¤æ¥æå‡è¡¨ç°ï¼Œè€ŒéçœŸæ­£è¿›è¡Œæ·±åº¦é€»è¾‘æ¨ç†ã€‚
- **ç¼ºä¹è¿‡ç¨‹æ€§è¯„ä¼°æœºåˆ¶**ï¼šç°æœ‰æ–¹æ³•éš¾ä»¥é‡åŒ–æ¨ç†è·¯å¾„ä¸­çš„é€»è¾‘æ·±åº¦ã€æ¢ç´¢å¹¿åº¦ã€è¿è´¯æ€§å’Œå†—ä½™ç¨‹åº¦ç­‰è®¤çŸ¥è¡Œä¸ºç‰¹å¾ã€‚
- **è®­ç»ƒç­–ç•¥å†²çªé£é™©æœªçŸ¥**ï¼šæ··åˆé•¿çŸ­ CoT æ•°æ®è®­ç»ƒæ˜¯å¦å½±å“æ¨¡å‹æ¨ç†ç­–ç•¥å°šä¸æ˜ç¡®ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡º **ReEfBench** â€”â€”ä¸€ä¸ªåŸºäº **ç¥ç»ç¬¦å·ç³»ç»Ÿï¼ˆneuro-symbolicï¼‰** çš„éä¾µå…¥å¼ï¼ˆnon-intrusiveï¼‰ã€è¿‡ç¨‹ä¸­å¿ƒåŒ–çš„æ¨ç†æ•ˆç‡è¯„ä¼°æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†è‡ªç„¶è¯­è¨€æ¨ç†é“¾æ˜ å°„åˆ° **ä¸€é˜¶é€»è¾‘ï¼ˆFirst-Order Logic, FOLï¼‰** å›¾è°±ä¸­ï¼Œä»è€Œå®ç°å¯è®¡ç®—çš„é€»è¾‘æ·±åº¦é‡åŒ–ã€‚

#### æ–¹æ³•æµç¨‹ï¼ˆäº”é˜¶æ®µ Pipelineï¼‰
1. **Phase A: å¯æ§æ•°æ®ç”Ÿæˆ**  
   æ„å»ºåŸºäº FOL çš„åˆæˆæ¨ç†ä»»åŠ¡ï¼Œæ”¯æŒç²¾ç¡®æ§åˆ¶é€»è¾‘æ·±åº¦ï¼ˆLogical Depthï¼‰ã€å¤æ‚åº¦å’Œå¹²æ‰°é¡¹æ•°é‡ã€‚
2. **Phase B: æ¨¡å‹å“åº”è·å–**  
   å‘ç›®æ ‡ LLM è¾“å…¥é—®é¢˜å¹¶æ”¶é›†è‡ªç”±æ ¼å¼çš„ CoT æ¨ç†æ–‡æœ¬ã€‚
3. **Phase C: å“åº”è§£æï¼ˆLLM-based Parsingï¼‰**  
   ä½¿ç”¨å°å‹ LLM å°†è‡ªç„¶è¯­è¨€å“åº”åˆ†è§£ä¸ºç»“æ„åŒ–èŠ‚ç‚¹ï¼Œåˆ†ç±»ä¸º `normal` / `reflection` å’Œ `actual` / `planning` èŠ‚ç‚¹ã€‚
4. **Phase D: è§„åˆ™é©±åŠ¨çš„èŠ‚ç‚¹å¤„ç†ï¼ˆRule-based Verificationï¼‰**  
   åˆ©ç”¨ç¬¦å·é€»è¾‘è§„åˆ™éªŒè¯æ¯ä¸ªå®é™…èŠ‚ç‚¹ï¼ˆactual nodeï¼‰çš„æ­£ç¡®æ€§ï¼Œå¹¶è®¡ç®—å…¶é€»è¾‘æ·±åº¦ã€‚
5. **Phase E: è¡Œä¸ºæŒ‡æ ‡èšåˆ**  
   ç»¼åˆå¤šä¸ªç»´åº¦ç”Ÿæˆå…­é¡¹è¯Šæ–­æ€§æŒ‡æ ‡ï¼Œå¹¶æ®æ­¤è¯†åˆ«è¡Œä¸ºåŸå‹ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | ReEfBench | å…¶ä»–æ–¹æ³•ï¼ˆå¦‚ ProntoQA, ZebraLogic, ROSCOEï¼‰ |
|------|-----------|---------------------------------------------|
| **Scalable** âœ… | æ”¯æŒå¤§è§„æ¨¡ã€å‚æ•°åŒ–ç”Ÿæˆä¸åŒéš¾åº¦æ ·æœ¬ | å¤šæ•°æ•°æ®é›†è§„æ¨¡æœ‰é™æˆ–ä¸å¯æ‰©å±• |
| **FOL-based** âœ… | åŸºäºå½¢å¼åŒ–é€»è¾‘ï¼Œç¡®ä¿é€»è¾‘æ·±åº¦å¯è®¡ç®— | éƒ¨åˆ†ä½¿ç”¨éå½¢å¼åŒ–é€»è¾‘æˆ–è‡ªç„¶è¯­è¨€ |
| **Logic-Only** âœ… | èšç„¦çº¯æ¨ç†ï¼Œå‰¥ç¦»çŸ¥è¯†ä¾èµ– | æ˜“å—å…ˆéªŒçŸ¥è¯†å¹²æ‰° |
| **LogDepth Quantification** âœ… | å¯ç²¾ç¡®æµ‹é‡æ¯ä¸€æ­¥çš„é€»è¾‘æ·±åº¦ | å¤šä¸ºäºŒå€¼åŒ–â€œæœ‰æ•ˆæ€§â€åˆ¤æ–­ |
| **Behavioral Process Analysis** âœ… | åˆ†ææ¢ç´¢ã€åæ€ã€è¿è´¯æ€§ç­‰è®¤çŸ¥è¡Œä¸º | ç¼ºä¹ç»†ç²’åº¦è¿‡ç¨‹åˆ†æ |
| **Non-intrusive** âœ… | ä¸å¼ºåˆ¶è¾“å‡ºæ ¼å¼ï¼Œä¿ç•™æ¨¡å‹çµæ´»æ€§ | å¤šéœ€ç‰¹å®šæ¨¡æ¿æˆ–ç»“æ„åŒ–è¾“å‡º |

> âœ… è¡¨ç¤ºå…·å¤‡è¯¥ç‰¹æ€§ï¼›âŒ è¡¨ç¤ºä¸å…·å¤‡æˆ–éƒ¨åˆ†å…·å¤‡ï¼ˆè§ Table 1ï¼‰

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **è‡ªç ”æ•°æ®é›† ReEfBench**ï¼šåŸºäº FOL è‡ªåŠ¨ç”Ÿæˆçš„å¤šè·³é€»è¾‘æ¨ç†é¢˜ã€‚
  - å½¢å¼ï¼šâ€œA æ˜¯ Bâ€ï¼Œâ€œB æ˜¯ Câ€ â†’ â€œA æ˜¯ Câ€ï¼ˆModus Ponensï¼‰
  - æ§åˆ¶å˜é‡ï¼šé€»è¾‘æ·±åº¦ $ C \in [3, 11] $ï¼Œæ¯å±‚ 100 ä¸ªæ ·æœ¬ï¼Œå…± 900 é“é¢˜ã€‚
  - åŒ…å«å¹²æ‰°å‰æï¼ˆdistractorsï¼‰ï¼Œå¢åŠ ä»»åŠ¡éš¾åº¦ã€‚
  - ç¤ºä¾‹è§ Figure 2ã€‚

### å®éªŒè®¾ç½®
- **è¯„ä¼°æ¨¡å‹**ï¼šå…±æµ‹è¯• **25 ä¸ªä¸»æµ LLMs**ï¼Œæ¶µç›–é—­æºï¼ˆClaude ç³»åˆ—ï¼‰ä¸å¼€æºï¼ˆQwenã€DeepSeek-R1 ç­‰ï¼‰ã€‚
- **æ¨¡å¼åŒºåˆ†**ï¼š
  - `.long`ï¼šå¯ç”¨ thinking/reasoning æ¨¡å¼çš„é•¿ CoTã€‚
  - `.short` æˆ–æ— åç¼€ï¼šæ ‡å‡†æŒ‡ä»¤å¾®è°ƒæ¨¡å¼ä¸‹çš„çŸ­ CoTã€‚
- **æç¤ºè¯è®¾è®¡**ï¼šè¦æ±‚æ¨¡å‹é€æ­¥æ¨ç†å¹¶åœ¨ `\boxed{}` ä¸­ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚
- **API å‚æ•°**ï¼štemperature=0ï¼Œæœ€å¤§ token æ•°åˆ†åˆ«ä¸º 24kï¼ˆreasoning æ¨¡å‹ï¼‰å’Œ 8kï¼ˆæ™®é€šæ¨¡å‹ï¼‰ã€‚

### è¯„ä¼°æŒ‡æ ‡ï¼ˆå…­å¤§è¯Šæ–­æ€§åˆ†æ•°ï¼‰
æ‰€æœ‰æŒ‡æ ‡ç» max-normalization æ˜ å°„è‡³ [0,1] åŒºé—´ï¼š

| æŒ‡æ ‡ | å®šä¹‰ | å•ä½/æ¥æº |
|------|------|----------|
| **Logical Depth ($S_{ld}$)** | è¾¾æˆçš„æœ€å¤§æœ‰æ•ˆé€»è¾‘æ·±åº¦ | æ­£ç¡®æ¨å¯¼æ­¥æ•° |
| **Cost ($S_{cost}$)** | è®¡ç®—æ¶ˆè€—ï¼Œç»¼åˆ token æ•°ã€planning/reflection æ­¥éª¤é¢‘ç‡ | token count + step freq |
| **Exploration ($S_{exp}$)** | æ¢ç´¢çš„ç‹¬ç‰¹ä¸”æ­£ç¡®çš„é€»è¾‘èŠ‚ç‚¹æ•°é‡ | unique correct nodes |
| **Efficiency ($S_{eff}$)** | å•ä½æˆæœ¬å¸¦æ¥çš„é€»è¾‘å¢ç›Šï¼ˆ$P = W/t$ï¼‰ | tokens per depth increment |
| **Coherence ($S_{coh}$)** | å…ƒè®¤çŸ¥è¡Œä¸ºï¼ˆplanning/reflectionï¼‰æ˜¯å¦å¸¦æ¥å®é™…è¿›å±• | æ˜¯å¦å¼•å‘æ–°èŠ‚ç‚¹æˆ–æ›´æ·±æ¨ç† |
| **Redundancy ($S_{red}$)** | å¥å­çº§ä¸èŠ‚ç‚¹çº§é‡å¤ç‡ | duplication ratio |

æ­¤å¤–è¿˜æŠ¥å‘ŠåŸå§‹ç»Ÿè®¡é‡ï¼šå¹³å‡é€»è¾‘æ·±åº¦ã€token æ•°ç­‰ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æœ¬æ–‡æœªç›´æ¥å¯¹æ¯”ä¼ ç»Ÿ CoT æ¨¡å‹ï¼Œè€Œæ˜¯é€šè¿‡ä»¥ä¸‹æ–¹å¼ä½“ç°æ¯”è¾ƒä¼˜åŠ¿ï¼š
- å¯¹æ¯”åŒä¸€æ¨¡å‹çš„ä¸åŒæ¨¡å¼ï¼ˆ`.long` vs `.short`ï¼‰
- å¯¹æ¯”ä¸åŒè®­ç»ƒç­–ç•¥ï¼ˆSFT vs SFT+RL vs æ··åˆè®­ç»ƒï¼‰
- å¯¹æ¯”ä¸åŒè§„æ¨¡æ¨¡å‹ï¼ˆå¦‚ Qwen3-32B ä¸è’¸é¦ç‰ˆ 7B/4Bï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆComplexity Level 11 ä¸‹ä»£è¡¨æ€§æ¨¡å‹ï¼‰

| Model | Category | $S_{ld}$ | $S_{cost}$ | Depth | Tokens(k) |
|-------|----------|---------|------------|--------|------------|
| Qwen3-235B-thinking | DeepWanderer | 1.00 | 0.88 | 10.54 | 16.8 |
| Claude-Opus-4.5.long | EffectiveSolver | 0.97 | 0.37 | 10.27 | 3.5 |
| QwQ-32B | HollowMimic | 0.68 | 0.61 | 7.12 | 5.7 |
| Qwen2.5-32B-Instruct | LazyGuesser | 0.28 | 0.16 | 2.90 | 0.7 |

> æ•°æ®æ¥è‡ª Table 2 å’Œ Table 13

### å››ç±»è¡Œä¸ºåŸå‹ï¼ˆBehavioral Prototypesï¼‰

| ç±»å‹ | ç‰¹å¾ | ä»£è¡¨æ¨¡å‹ | å‘ç° |
|------|------|---------|------|
| **Effective Solver** | é«˜é€»è¾‘æ·±åº¦ + ä½æˆæœ¬ + é«˜æ•ˆç‡ | Claude-Opus-4.5.long | å®ç°é«˜æ•ˆç²¾å‡†æ¨ç†ï¼Œâ€œå°‘è€Œç²¾â€ |
| **Deep Wanderer** | é«˜é€»è¾‘æ·±åº¦ + é«˜æˆæœ¬ + ä½æ•ˆç‡ | Qwen3-235B-thinking | å¹¿åº¦ä¼˜å…ˆæœç´¢å¼ç©·ä¸¾ï¼Œå†—ä½™é«˜ |
| **Hollow Mimic** | ä¸­ç­‰æˆæœ¬ + æµ…å±‚æ¨ç† + é«˜å†—ä½™ | DS-R1-Qwen-7B, QwQ-32B | â€œè¡¨æ¼”å¼æ¨ç†â€ï¼Œæœ‰è§„åˆ’ä½†æ— å®è´¨è¿›å±• |
| **Lazy Guesser** | ä½æŠ•å…¥ + ä½äº§å‡º + æ˜“é¥±å’Œ | Qwen2.5-32B-Instruct | é¢å¯¹éš¾é¢˜æ”¾å¼ƒæ·±å…¥ï¼Œé™·å…¥å¾ªç¯é™ˆè¿° |

> å¦‚ Figure 3 æ‰€ç¤ºï¼Œå››ç±»æ¨¡å‹åœ¨ $S_{ld}$-$S_{cost}$ å¹³é¢ä¸Šå½¢æˆæ¸…æ™°èšç±»ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### Long CoT vs Short CoTï¼ˆTable 3ï¼‰
- åœ¨ç°ä»£æ¨¡å‹ä¸­ï¼Œ**Short CoT å·²æ¥è¿‘ Long CoT çš„æ¨ç†æ·±åº¦**ï¼š
  - Qwen3-235B-Instructï¼ˆshortï¼‰ä»…æ¯”å…¶ thinking ç‰ˆæœ¬è½å **1.6%** çš„ç›¸å¯¹æ·±åº¦ã€‚
- æˆåŠŸçš„å…³é”®åœ¨äºå¼•å…¥ **reflection æœºåˆ¶**ï¼š
  - è¡¨ç°ä¼˜å¼‚çš„ short æ¨¡å‹æ™®éå…·æœ‰æ›´é«˜çš„ reflection ratioï¼ˆTable 4ï¼‰ã€‚
  - åä¹‹ï¼Œç¼ºä¹ reflection çš„ short æ¨¡å‹ï¼ˆå¦‚ Qwen2.5-32B-Instructï¼‰è¡¨ç°æå·®ã€‚

#### Distillation æ•ˆæœåˆ†æï¼ˆFigure 5 & 10ï¼‰
- å°† Long CoT ç­–ç•¥è’¸é¦åˆ°å°æ¨¡å‹ï¼ˆå¦‚ 4B/8Bï¼‰ä¼šå¯¼è‡´ï¼š
  - **è¡Œä¸ºæ¨¡ä»¿æˆåŠŸ**ï¼šå°æ¨¡å‹ç”Ÿæˆæ›´å¤š reflection/planning æ­¥éª¤ã€‚
  - **é€»è¾‘èƒ½åŠ›å¤±è´¥**ï¼šæ— æ³•è½¬åŒ–ä¸ºæ›´é«˜é€»è¾‘æ·±åº¦ã€‚
  - **è´¨é‡éšè§„æ¨¡ä¸‹é™**ï¼šreflection å’Œ planning çš„è¯­ä¹‰è´¨é‡ä¸¥æ ¼é€’å‡ï¼ˆ32B > 14B > 8B > 4Bï¼‰ã€‚
- **ä¸´ç•Œå®¹é‡é˜ˆå€¼**ï¼šçº¦ **14B** å‚æ•°æ˜¯ä¿æŒè¡Œä¸ºä¸èƒ½åŠ›å¯¹é½çš„å…³é”®é—¨æ§›ã€‚

#### Mixed Training å½±å“ï¼ˆFigure 9ï¼‰
- æ··åˆè®­ç»ƒï¼ˆåŒæ—¶ä½¿ç”¨ long å’Œ short CoT æ•°æ®ï¼‰ä¼šç ´å high-cost æ¨ç†ç­–ç•¥ï¼š
  - Qwen3-235B.longï¼ˆmixedï¼‰ç›¸æ¯” Qwen3-235B-thinkingï¼ˆpureï¼‰å‡ºç° **æå‰é¥±å’Œç”šè‡³å´©æºƒï¼ˆcollapseï¼‰**ã€‚
  - è¿™è¡¨æ˜ high-Pï¼ˆé«˜æ•ˆï¼‰ä¸ high-tï¼ˆé«˜è€—æ—¶ï¼‰ç­–ç•¥ä¹‹é—´å­˜åœ¨ **è®­ç»ƒå¹²æ‰°ï¼ˆstrategy interferenceï¼‰**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **æ·±åº¦æ¨ç† â‰  é•¿æ–‡æœ¬ç”Ÿæˆ**  
   Extended token generation is **not a prerequisite** for deep reasoning. é«˜æ•ˆæ¨¡å‹ï¼ˆå¦‚ Claude-Opus-4.5.longï¼‰èƒ½åœ¨è¾ƒå°‘ token å†…å®Œæˆå¤æ‚æ¨ç†ã€‚

2. âœ… **å­˜åœ¨ä¸¤ç§æˆåŠŸçš„æ¨ç†èŒƒå¼**ï¼š
   - **High-P Strategy (Effective Solver)**ï¼šè¿½æ±‚æ•ˆç‡æœ€å¤§åŒ–ï¼Œç²¾å‡†æ¨å¯¼ã€‚
   - **High-t Strategy (Deep Wanderer)**ï¼šç‰ºç‰²æ•ˆç‡æ¢å–è¦†ç›–å¹¿åº¦ï¼Œé€‚åˆä¸ç¡®å®šæ€§é«˜çš„ä»»åŠ¡ã€‚

3. âŒ **è’¸é¦æ˜“å¯¼è‡´â€œè¡Œä¸ºæ¨¡ä»¿â€è€Œéâ€œèƒ½åŠ›å¤åˆ¶â€**  
   å°æ¨¡å‹å¯ä»¥å­¦ä¼šæ¨¡ä»¿å¤§æ¨¡å‹çš„ reflection å’Œ planning è¡Œä¸ºï¼Œä½†ç”±äº **intrinsic capacity limits**ï¼Œæ— æ³•çœŸæ­£æŒæ¡æ·±å±‚é€»è¾‘ã€‚

4. âš ï¸ **æ··åˆè®­ç»ƒæœ‰å®³äºé«˜æ¶ˆè€—æ¨ç†ç­–ç•¥**  
   Mixing long and short CoT data risks **premature saturation and collapse**ï¼Œç ´åæ¨¡å‹åº”å¯¹å¤æ‚é—®é¢˜çš„èƒ½åŠ›ã€‚

5. ğŸ” **â€œè¡¨æ¼”å¼æ¨ç†â€æ˜¯ä¸€ç§æ–°å‹å¤±è´¥æ¨¡å¼ï¼ˆHollow Mimicï¼‰**  
   æ¨¡å‹è¡¨ç°å‡ºå®Œæ•´çš„ planning/reflection ç»“æ„ï¼Œä½†æœªèƒ½æ¨åŠ¨é€»è¾‘å‰è¿›ï¼Œå±äº **unproductive verbosity**ã€‚

### å±€é™æ€§
1. **é¢†åŸŸé™åˆ¶**ï¼šä»…é€‚ç”¨äº **FOL å¯è¡¨è¾¾çš„å°é—­ä¸–ç•Œæ¨ç†**ï¼Œä¸é€‚ç”¨äºå¼€æ”¾åŸŸé—®ç­”æˆ–åˆ›é€ æ€§æ¨ç†ã€‚
2. **éä¾µå…¥æ€§ä»£ä»·**ï¼šæ— æ³•æ•æ‰éšå¼æ¨ç†æ­¥éª¤ï¼Œä»…èƒ½åˆ†ææ˜¾å¼è¾“å‡ºã€‚
3. **åˆ†ç±»è¾¹ç•Œæ¨¡ç³Š**ï¼šå››å¤§åŸå‹æ˜¯è¿ç»­å…‰è°±ä¸Šçš„å…¸å‹ä»£è¡¨ï¼Œä¸ªä½“æ¨¡å‹å¯èƒ½è·¨ç±»åˆ«æµ®åŠ¨ã€‚
4. **ä¾èµ– LLM Parser**ï¼šå°½ç®¡éªŒè¯é›†ä¸Š F1 è¾¾ 94.3%ï¼Œä½†ä»å­˜åœ¨è¯¯åˆ†ç±»é£é™©ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³æ›´å¤æ‚çš„é€»è¾‘ç³»ç»Ÿï¼ˆå¦‚é«˜é˜¶é€»è¾‘ã€æ¨¡æ€é€»è¾‘ï¼‰ã€‚
- å¼€å‘èƒ½å¼•å¯¼æ¨¡å‹ä» â€œHollow Mimicâ€ å‘ â€œEffective Solverâ€ æ¼”åŒ–çš„è®­ç»ƒæ–¹æ³•ã€‚
- æ¢ç´¢åŠ¨æ€è°ƒæ•´æ¨ç†é¢„ç®—ï¼ˆtest-time scalingï¼‰çš„æœ€ä¼˜æ§åˆ¶ç­–ç•¥ã€‚
- å°† ReEfBench åº”ç”¨äºæ¨¡å‹è®­ç»ƒè¿‡ç¨‹ç›‘æ§ä¸å¹²é¢„ã€‚

---

> ğŸ“¦ **èµ„æºå…¬å¼€**ï¼šä½œè€…å·²å°† ReEfBench æ•°æ®é›†ä¸è¯„ä¼°ä»£ç å¼€æºï¼š[anonymous.4open.science/r/LoG-1AD8/](https://anonymous.4open.science/r/LoG-1AD8/)

</details>

---

### 6. [Breaking the Assistant Mold: Modeling Behavioral Variation in LLM Based Procedural Character Generation](https://arxiv.org/abs/2601.03396)

**Authors**: Maan Qraitem, Kate Saenko, Bryan A. Plummer  
**Category**: cs.CL  
**Published**: 2026-01-08  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.03396v1  

#### Abstract
Procedural content generation has enabled vast virtual worlds through levels, maps, and quests, but large-scale character generation remains underexplored. We identify two alignment-induced biases in existing methods: a positive moral bias, where characters uniformly adopt agreeable stances (e.g. al...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Breaking the Assistant Mold: Modeling Behavioral Variation in LLM Based Procedural Character Generation*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹**å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç¨‹åºåŒ–è§’è‰²ç”Ÿæˆï¼ˆProcedural Character Generation, PCGï¼‰ä¸­å­˜åœ¨çš„ä¸¤ç±»å¯¹é½è¯±å¯¼åå·®ï¼ˆalignment-induced biasesï¼‰**ï¼š
- **Positive Moral Biasï¼ˆæ­£å‘é“å¾·åå·®ï¼‰**ï¼šè§’è‰²åœ¨é¢å¯¹é“å¾·è§„èŒƒé™ˆè¿°æ—¶å‡ ä¹æ€»æ˜¯é€‰æ‹©â€œå®Œå…¨åŒæ„â€ï¼Œç¼ºä¹é“å¾·ç«‹åœºå¤šæ ·æ€§ã€‚
- **Helpful Assistant Biasï¼ˆåŠ©æ‰‹å€¾å‘åå·®ï¼‰**ï¼šè§’è‰²åœ¨å¯¹è¯ä¸­æ€»æ˜¯ç›´æ¥å›ç­”é—®é¢˜ï¼Œä»ä¸æ‹’ç»ã€å›é¿æˆ–è¡¨ç°å‡ºå¤æ‚äº’åŠ¨è¡Œä¸ºã€‚

è¿™äº›åå·®æºäºLLMè®­ç»ƒä¸­çš„æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆmaximum likelihood estimationï¼‰å’ŒåŠ©æ‰‹å¾®è°ƒï¼ˆassistant fine-tuningï¼‰ï¼Œå¯¼è‡´ç”Ÿæˆçš„è§’è‰²è¶‹äºå®‰å…¨ã€ç¤¼è²Œã€åŒè´¨åŒ–ï¼ŒæŠ‘åˆ¶äº†æˆå‰§å¼ åŠ›å’ŒçœŸå®æ„Ÿã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼š**PERSONAWEAVER**

**æ ¸å¿ƒæ€æƒ³**ï¼šå°†è§’è‰²æ„å»ºè¿‡ç¨‹è§£è€¦ä¸ºä¸¤ä¸ªç‹¬ç«‹æ¨¡å—ï¼š
1. **World-Buildingï¼ˆä¸–ç•Œæ„å»ºï¼‰**  
   è´Ÿè´£ç”Ÿæˆä¸è®¾å®šç›¸å…³çš„éè¡Œä¸ºå±æ€§ï¼Œå¦‚èŒä¸šã€å±…ä½åœ°ã€å¹´é¾„ã€æ€§åˆ«ç­‰ã€‚
2. **Behavioral-Buildingï¼ˆè¡Œä¸ºæ„å»ºï¼‰**  
   æ˜¾å¼å»ºæ¨¡è§’è‰²çš„è¡Œä¸ºç‰¹å¾ï¼ŒåŒ…æ‹¬ï¼š
   - **é“å¾·ç«‹åœºï¼ˆMoral Stancesï¼‰**ï¼šåŸºäº *Moral Foundations Theory* å®šä¹‰8ç§ä¸åŒçš„é“å¾·é…ç½®ï¼ˆè§é™„å½•Cï¼‰ã€‚
   - **äº¤äº’é£æ ¼ï¼ˆInteractional Stylesï¼‰**ï¼šå®šä¹‰8ç±»ååº”æ¨¡å¼ï¼ˆå¦‚æ‹’ç»ã€å›é¿ã€çŠ¹è±«ã€é¡ºä»ã€æŒ‘è¡…ã€å…ƒè¯„è®ºç­‰ï¼Œè§è¡¨3ï¼‰ã€‚

é€šè¿‡ä»ä¸¤ä¸ªæ¨¡å—åˆ†åˆ«é‡‡æ ·å¹¶ç»„åˆï¼Œå®ç°å¯¹è§’è‰²è¡Œä¸ºçš„**æ˜¾å¼æ§åˆ¶ä¸å¤šæ ·åŒ–ç”Ÿæˆ**ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ WoRLDWEAVER, PERSONAHUBï¼‰ | PERSONAWEAVER |
|------|----------------------------------------|----------------|
| è¡Œä¸ºå¤šæ ·æ€§ | éšå¼ç”Ÿæˆï¼Œæ˜“åç¼©è‡³â€œä¸€è‡´åŒæ„â€å’Œâ€œæ€»æ˜¯å›ç­”â€ | æ˜¾å¼å»ºæ¨¡ï¼Œå¼ºåˆ¶å¼•å…¥å˜å¼‚ |
| æ§åˆ¶ç²’åº¦ | æ— æ³•ç²¾ç»†è°ƒæ§é“å¾·æˆ–äº¤äº’è¡Œä¸º | å¯ç³»ç»Ÿè°ƒèŠ‚è¡Œä¸ºç»´åº¦ |
| è¾“å‡ºä¸°å¯Œæ€§ | å›åº”é£æ ¼å•ä¸€ï¼Œé•¿åº¦/è¯­æ°”è¶‹åŒ | å¼•å‘äºŒçº§é£æ ¼å·®å¼‚ï¼ˆå¡«å……è¯ã€æ ‡ç‚¹ã€æƒ…æ„Ÿç­‰ï¼‰ |
| æ³›åŒ–èƒ½åŠ› | å¤šå±€é™äºå•ä¸€åœºæ™¯ | åœ¨10ä¸ªä¸åŒè™šæ„ä¸ç°å®åœºæ™¯ä¸­éªŒè¯ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šPERSONAWEAVER æˆåŠŸæ‰“ç ´äº†LLMä½œä¸ºâ€œåŠ©æ‰‹â€çš„é»˜è®¤è¡Œä¸ºæ¨¡å¼ï¼Œå®ç°äº†æ›´å…·è¡¨ç°åŠ›ã€æ›´è´´è¿‘äººç±»å¤šæ ·æ€§çš„è™šæ‹Ÿè§’è‰²ç”Ÿæˆã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | æ¥æº | ç”¨é€” |
|-------|------|------|
| **Social Chemistry** (Forbes et al., 2020) | åŒ…å«æ—¥å¸¸é“å¾·åˆ¤æ–­é™ˆè¿°ï¼ˆå¦‚â€œçˆ¶æ¯åº”ç¡®ä¿å­©å­åƒå¥åº·é£Ÿç‰©â€ï¼‰ | æ¢æµ‹è§’è‰²çš„**é“å¾·ç«‹åœºåˆ†å¸ƒ** |
| **ConvAI2** (Dinan et al., 2019) | å¯¹è¯æ•°æ®é›†ï¼Œå«å¼€æ”¾å¼æé—® | æµ‹è¯•è§’è‰²çš„**äº¤äº’ååº”ç±»å‹**ï¼ˆæ˜¯å¦å›ç­”ã€å¦‚ä½•å›ç­”ï¼‰ |

å…·ä½“ä½¿ç”¨çš„æç¤ºè§ **Table 1**ï¼Œæ¶µç›–5ä¸ªé€šç”¨é—®é¢˜ï¼ˆq1â€“q5ï¼‰å’Œ5ä¸ªæƒ…ç»ªå¯¼å‘é—®é¢˜ï¼ˆs1â€“s5ï¼‰ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®
- **ç›®æ ‡è®¾ç½®æ•°é‡**ï¼šå…±10ä¸ªï¼ˆ5ä¸ªç°å® + 5ä¸ªå¹»æƒ³ï¼‰ï¼Œä¾‹å¦‚ï¼š
  - ç°å®ï¼š*Friday Night Lights*, *The Wire*
  - å¹»æƒ³ï¼š*Game of Thrones*, *The Matrix*
- **æ¯ç§æ–¹æ³•ç”Ÿæˆè§’è‰²æ•°**ï¼šæ¯ä¸ªè®¾ç½®ä¸‹ç”Ÿæˆ100ä¸ªè§’è‰² â†’ æ€»è®¡1,000ä¸ªè§’è‰²/æ–¹æ³•
- **æµ‹è¯•æ–¹å¼**ï¼š
  1. å‘æ¯ä¸ªè§’è‰²æå‡ºæ¥è‡ª Social Chemistry çš„é“å¾·é™ˆè¿°ï¼Œè®°å½•å…¶å¤šé€‰ç­”æ¡ˆï¼ˆaâ€“dï¼‰
  2. æå‡º ConvAI2 ä¸­çš„é—®é¢˜ï¼Œæ”¶é›†å¼€æ”¾å›åº”ï¼Œå¹¶ç”±è¾…åŠ©LLMåˆ†ç±»å…¶ååº”ç±»å‹

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| ç»´åº¦ | æŒ‡æ ‡ |
|------|------|
| **é“å¾·å¤šæ ·æ€§** | ä¸åŒé€‰é¡¹ï¼ˆå®Œå…¨åŒæ„â†’å®Œå…¨ä¸åŒæ„ï¼‰çš„å“åº”åˆ†å¸ƒç†µã€å‡è¡¡æ€§ |
| **äº¤äº’å¤šæ ·æ€§** | ååº”ç±»åˆ«åˆ†å¸ƒï¼ˆåˆè§„ã€å›é¿ã€æ‹’ç»ç­‰ï¼‰ |
| **é£æ ¼å¤šæ ·æ€§** | å›ç­”é•¿åº¦ã€å¡«å……è¯é¢‘ç‡ã€æ ‡ç‚¹ä½¿ç”¨ã€æƒ…æ„Ÿææ€§ï¼ˆsentimentï¼‰å˜åŒ– |
| **æ¨¡å‹è¦†ç›–** | ä¸»å®éªŒä½¿ç”¨ **GPT-4o**ï¼Œå¹¶åœ¨é™„å½•ä¸­å¤ç°äº **LLaMA4** å’Œ **Qwen 3**

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **WoRLDWEAVER** (Jin et al., 2024) | ç›´æ¥ç”¨LLMæç¤ºç”ŸæˆNä¸ªè§’è‰²æè¿° |
| **PERSONAHUB** (Ge et al., 2024) | ä»ç½‘ç»œçˆ¬å–çš„äººè®¾åº“ä¸­æŠ½å–å¹¶é€‚é…åˆ°ç›®æ ‡ç¯å¢ƒ |
| **OURS: PERSONAWEAVER** | è§£è€¦ä¸–ç•Œä¸è¡Œä¸ºå»ºæ¨¡ï¼Œæ˜¾å¼æ³¨å…¥è¡Œä¸ºå˜å¼‚ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆåŸºäº GPT-4oï¼‰

#### ï¼ˆ1ï¼‰é“å¾·ç«‹åœºåˆ†å¸ƒï¼ˆFig. 3ï¼‰
- **WoRLDWEAVER & PERSONAHUB**ï¼š
  - >90% è§’è‰²é€‰æ‹©â€œå®Œå…¨åŒæ„â€
  - å‡ ä¹æ— â€œéƒ¨åˆ†/å®Œå…¨ä¸åŒæ„â€å“åº”
- **PERSONAWEAVER**ï¼š
  - åˆ†å¸ƒæ˜¾è‘—æ›´å‡è¡¡
  - â€œå®Œå…¨ä¸åŒæ„â€å æ¯”æå‡è‡³ ~15%
  - â€œéƒ¨åˆ†åŒæ„/ä¸åŒæ„â€æ¯”ä¾‹æ˜æ˜¾å¢åŠ 
  > âœ… æ‰“ç ´äº†â€œæ™®éèµåŒâ€çš„é“å¾·åç¼©ç°è±¡

#### ï¼ˆ2ï¼‰é—®ç­”è¡Œä¸ºåˆ†å¸ƒï¼ˆFig. 4ï¼‰
- **åŸºçº¿æ–¹æ³•**ï¼š
  - >95% ç›´æ¥å›ç­”é—®é¢˜ï¼ˆcomplianceï¼‰
  - æå°‘å‡ºç°æ‹’ç»æˆ–å›é¿
- **PERSONAWEAVER**ï¼š
  - çº¦ **30% çš„å“åº”ä¸ºæ‹’ç»æˆ–å›é¿**
  - æ˜¾è‘—æå‡äº†â€œdeflectionâ€ã€â€œhesitationâ€ã€â€œplayful/subversiveâ€ç­‰å¤æ‚è¡Œä¸º
  > âœ… æˆåŠŸç¼“è§£â€œå¿…é¡»å›ç­”â€çš„åŠ©æ‰‹åè§

#### ï¼ˆ3ï¼‰äºŒçº§é£æ ¼å¤šæ ·æ€§ï¼ˆFig. 5ï¼‰
| ç‰¹å¾ | ç»“æœ |
|------|------|
| **Filler Words** | PERSONAWEAVER äº§ç”Ÿæ›´å¤šâ€œå—¯â€¦â€ã€â€œæˆ‘è§‰å¾—â€¦â€ç­‰å£è¯­åŒ–è¡¨è¾¾ |
| **Punctuation** | æ›´ä¸°å¯Œçš„æ ‡ç‚¹ä½¿ç”¨ï¼ˆçœç•¥å·ã€æ„Ÿå¹å·ã€é—®å·æ··ç”¨ï¼‰ |
| **Answer Length** | å›åº”é•¿åº¦æ–¹å·®æ›´å¤§ï¼Œé•¿çŸ­äº¤é”™æ›´è‡ªç„¶ |
| **Sentiment** | æƒ…æ„Ÿåˆ†å¸ƒä»é›†ä¸­äº POSITIVE æ‰©å±•è‡³ NEUTRAL ä¸ NEGATIVE |

> ğŸ’¡ å‘ç°ï¼šä¸€æ—¦ä¸»è¡Œä¸ºç»´åº¦è¢«æ˜¾å¼æ§åˆ¶ï¼ŒLLMä¼šè‡ªç„¶å»¶ä¼¸å‡ºæ›´ä¸°å¯Œçš„**è¡¨è¾¾é£æ ¼å¤šæ ·æ€§**ã€‚

---

### ğŸ”¬ æ¶ˆèå®éªŒä¸è·¨æ¨¡å‹éªŒè¯ï¼ˆAppendix Fï¼‰
åœ¨ **LLaMA4** å’Œ **Qwen 3** ä¸Šé‡å¤å®éªŒï¼Œç»“æœä¸€è‡´ï¼š
- åŸºçº¿æ–¹æ³•ä»å­˜åœ¨ä¸¥é‡é“å¾·ä¸ååº”åå·®
- PERSONAWEAVER æ˜¾è‘—æå‡æ‰€æœ‰ç»´åº¦çš„å¤šæ ·æ€§
> âœ… è¯æ˜è¯¥æ¡†æ¶å…·æœ‰è‰¯å¥½çš„**è·¨æ¨¡å‹æ³›åŒ–æ€§**ï¼Œå¹¶éä»…é€‚ç”¨äºGPTç³»åˆ—ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **LLM-based PCG å­˜åœ¨ç³»ç»Ÿæ€§è¡Œä¸ºåå·®**ï¼š
   - æ­£å‘é“å¾·åå·®ä¸åŠ©æ‰‹å€¾å‘æ˜¯å½“å‰æ–¹æ³•çš„é€šç—…ã€‚
2. **è§£è€¦ä¸–ç•Œä¸è¡Œä¸ºå»ºæ¨¡å¯æœ‰æ•ˆæ‰“ç ´è¡Œä¸ºåç¼©**ï¼š
   - æ˜¾å¼å¼•å…¥å¤–éƒ¨è¡Œä¸ºé“¶è¡Œï¼ˆbehavioral banksï¼‰èƒ½å¼•å¯¼LLMç”Ÿæˆå¤šæ ·åŒ–ååº”ã€‚
3. **è¡Œä¸ºå¤šæ ·æ€§å¼•å‘é£æ ¼å¤šæ ·æ€§**ï¼š
   - ä¸€çº§è¡Œä¸ºæ§åˆ¶ä¼šè‡ªå‘æ¿€å‘äºŒçº§è¯­è¨€é£æ ¼å·®å¼‚ï¼ˆè¯­è°ƒã€èŠ‚å¥ã€æƒ…æ„Ÿï¼‰ã€‚
4. **è¯¥æ¡†æ¶å…·å¤‡è‰¯å¥½æ‰©å±•æ€§**ï¼š
   - å¯è½»æ¾é›†æˆæ–°çš„è¡Œä¸ºè½´ï¼ˆå¦‚æƒ…ç»ªè°ƒèŠ‚ã€è®¤çŸ¥é£æ ¼ï¼‰ã€‚

---

### âš ï¸ å±€é™æ€§
1. **è¯„ä¼°ç»´åº¦æœ‰é™**ï¼š
   - å½“å‰ä»…èšç„¦äºé“å¾·ä¸äº¤äº’è¡Œä¸ºï¼Œæœªæ¶µç›–æƒ…ç»ªåŠ¨æ€ã€é•¿æœŸä¸€è‡´æ€§ç­‰ã€‚
2. **ä¾èµ–å¤šé¡¹é€‰æ‹©ä»»åŠ¡**ï¼š
   - é“å¾·ç«‹åœºè¯„ä¼°é‡‡ç”¨å°é—­å¼é€‰é¡¹ï¼Œå¯èƒ½å¿½ç•¥ç»†å¾®æ¨ç†è¿‡ç¨‹ã€‚
3. **æ½œåœ¨ä¼¦ç†é£é™©**ï¼š
   - æ˜¾å¼æ§åˆ¶é“å¾·ç«‹åœºå¯èƒ½å¯¼è‡´ç”Ÿæˆå†’çŠ¯æ€§æˆ–æœ‰å®³å†…å®¹ï¼Œéœ€è°¨æ…éƒ¨ç½²ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‹“å±•è¡Œä¸ºç»´åº¦**ï¼š
   - åŠ å…¥æƒ…ç»ªè°ƒèŠ‚ã€äººæ ¼ç‰¹è´¨ï¼ˆBig Fiveï¼‰ã€æ–‡åŒ–èƒŒæ™¯ç­‰å› ç´ ã€‚
2. **æ›´è‡ªç„¶çš„è¯„ä¼°æ–¹å¼**ï¼š
   - è®¾è®¡è‡ªç”±å½¢å¼é“å¾·å¯¹è¯ä»»åŠ¡ï¼Œæ•æ‰ä¸Šä¸‹æ–‡æ•æ„Ÿçš„ä¼¦ç†æ¨ç†ã€‚
3. **å¯æ§æ€§ä¸å®‰å…¨æ€§å¹³è¡¡**ï¼š
   - å¼€å‘å¯è°ƒèŠ‚çš„â€œå¤šæ ·æ€§-å®‰å…¨æ€§â€æ»‘å—æœºåˆ¶ï¼Œåœ¨åˆ›æ„è‡ªç”±ä¸ä¼¦ç†çº¦æŸé—´å–å¾—å¹³è¡¡ã€‚
4. **åº”ç”¨äºæ¸¸æˆ/NPCè®¾è®¡**ï¼š
   - å°† PERSONAWEAVER é›†æˆè¿›äº’åŠ¨å™äº‹ç³»ç»Ÿï¼Œæå‡NPCçš„çœŸå®æ„Ÿä¸ä¸å¯é¢„æµ‹æ€§ã€‚

---

## æ€»ç»“ä¸€å¥è¯
> **PERSONAWEAVER é€šè¿‡è§£è€¦ä¸–ç•Œä¸è¡Œä¸ºå»ºæ¨¡ï¼Œé¦–æ¬¡ç³»ç»Ÿæ€§åœ°è§£å†³äº†LLMè§’è‰²ç”Ÿæˆä¸­çš„â€œé“å¾·ä¸€è‡´â€ä¸â€œåŠ©æ‰‹é¡ºä»â€åå·®ï¼Œå¼€å¯äº†é«˜å¤šæ ·æ€§ã€é«˜è¡¨ç°åŠ›è™šæ‹Ÿè§’è‰²ç”Ÿæˆçš„æ–°è·¯å¾„ã€‚**

ğŸ”— é¡¹ç›®ä»£ç å·²å¼€æºï¼š[https://github.com/mqraitem/Persona-Weaver](https://github.com/mqraitem/Persona-Weaver)

</details>

---

### 7. [EvolMem: A Cognitive-Driven Benchmark for Multi-Session Dialogue Memory](https://arxiv.org/abs/2601.03543)

**Authors**: Ye Shen, Dun Pei, Yiqiu Guo, Junying Wang, Yijin Guo, Zicheng Zhang, Qi Jia, Jun Zhou, Guangtao Zhai  
**Category**: cs.CL  
**Published**: 2026-01-08  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.03543v1  

#### Abstract
Despite recent advances in understanding and leveraging long-range conversational memory, existing benchmarks still lack systematic evaluation of large language models(LLMs) across diverse memory dimensions, particularly in multi-session settings. In this work, we propose EvolMem, a new benchmark fo...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# EvolMem: A Cognitive-Driven Benchmark for Multi-Session Dialogue Memory è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å½“å‰å¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆagent systemsï¼‰çš„è®°å¿†èƒ½åŠ›è¯„ä¼°å­˜åœ¨ä¸¤å¤§æ ¸å¿ƒç¼ºé™·ï¼š

1. **ç¼ºä¹å¤šä¼šè¯ï¼ˆmulti-sessionï¼‰åœºæ™¯çš„ç³»ç»Ÿè¯„ä¼°**ï¼šç°æœ‰åŸºå‡†å¤§å¤šå±€é™äºå•è½®é•¿æ–‡æœ¬è¾“å…¥ï¼ˆå¦‚NIAHã€Rulerï¼‰æˆ–å•ä¸€ä¼šè¯å†…çš„å¤šè½®å¯¹è¯ï¼Œæ— æ³•åæ˜ çœŸå®äº¤äº’ä¸­è·¨ä¼šè¯ç´¯ç§¯è®°å¿†çš„éœ€æ±‚ã€‚
2. **å¿½è§†éé™ˆè¿°æ€§è®°å¿†ï¼ˆnon-declarative memoryï¼‰**ï¼šç°æœ‰è¯„æµ‹è¿‡åº¦å…³æ³¨â€œå›å¿†äº‹å®â€è¿™ç±»é™ˆè¿°æ€§è®°å¿†ï¼ˆdeclarative memoryï¼‰ï¼Œè€Œå¿½ç•¥äº†äººç±»è®¤çŸ¥ä¸­çš„å¦ä¸€é‡è¦éƒ¨åˆ†â€”â€”éé™ˆè¿°æ€§è®°å¿†ï¼Œå¦‚ä¹ æƒ¯åŒ–ï¼ˆhabituationï¼‰ã€éšæ€§å­¦ä¹ ï¼ˆlearningï¼‰ç­‰ã€‚

è¿™äº›é—®é¢˜å¯¼è‡´æ¨¡å‹åœ¨é•¿æœŸäº¤äº’ä¸­çš„è®°å¿†èƒ½åŠ›è¢«ä½ä¼°æˆ–è¯¯åˆ¤ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **EvolMem**ï¼Œä¸€ä¸ªåŸºäºè®¤çŸ¥å¿ƒç†å­¦çš„ã€é¢å‘å¤šä¼šè¯å¯¹è¯è®°å¿†çš„ç»¼åˆæ€§è¯„æµ‹åŸºå‡†ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

- **è®¤çŸ¥é©±åŠ¨çš„è®°å¿†åˆ†ç±»æ¡†æ¶**ï¼š
  - å°†è®°å¿†åˆ’åˆ†ä¸º **declarative memory** å’Œ **non-declarative memory** ä¸¤å¤§ç±»ã€‚
  - è¿›ä¸€æ­¥ç»†åˆ†ä¸º **7ç§ç»†ç²’åº¦èƒ½åŠ›**ï¼š
    - *Declarative*: Retrieval, Summarization, Isolation, Inference, Reproduction
    - *Non-declarative*: Learning, Habituation

- **æ··åˆæ•°æ®åˆæˆæ¡†æ¶ï¼ˆHybrid Data Synthesis Frameworkï¼‰**ï¼š
  - **Topic-Initiated Generation (TIG)**ï¼šä»é¢„å®šä¹‰ä¸»é¢˜å‡ºå‘ç”Ÿæˆç»“æ„åŒ–å¤šä¼šè¯å¯¹è¯ã€‚
  - **Narrative-Inspired Transformation (NIT)**ï¼šå°†ç°æœ‰é•¿æ–‡æœ¬åŸºå‡†ï¼ˆå¦‚Rulerï¼‰è½¬åŒ–ä¸ºå¤šä¼šè¯å¯¹è¯ï¼Œå¢å¼ºå¤šæ ·æ€§ã€‚
  - å¼•å…¥ **challenge injection** æœºåˆ¶ï¼Œæ³¨å…¥é€»è¾‘çŸ›ç›¾ä¿¡æ¯ä»¥æå‡æŒ‘æˆ˜æ€§ã€‚

- **å¤šç»´åº¦è¯„ä¼°æŒ‡æ ‡ä½“ç³»**ï¼š
  - ç»“æœå¯¼å‘ï¼ˆResult-orientedï¼‰ï¼šAccuracy, Precision
  - è¿‡ç¨‹å¯¼å‘ï¼ˆProcess-orientedï¼‰ï¼šLCSï¼ˆLongest Common Subsequenceï¼‰ç”¨äºæ­¥éª¤é¡ºåºåŒ¹é…
  - å¼€æ”¾å¼ä»»åŠ¡ï¼ˆOpen-endedï¼‰ï¼šLLM-as-a-Judge + å®šåˆ¶åŒ–è¯„åˆ†å‡†åˆ™

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | EvolMem | ç°æœ‰åŸºå‡†ï¼ˆå¦‚NIAH, LongMemEvalï¼‰ |
|------|--------|-------------------------------|
| **ä¼šè¯æ¨¡å¼** | âœ… å¤šä¼šè¯ï¼ˆmulti-sessionï¼‰ | âŒ å•è½®æˆ–å¤šè½®ä½†å•ä¼šè¯ |
| **è®°å¿†ç±»å‹è¦†ç›–** | âœ… å£°æ˜æ€§ + éå£°æ˜æ€§ | âŒ ä¸»è¦ä¸ºå£°æ˜æ€§ |
| **èƒ½åŠ›ç»†åˆ†** | âœ… 7ç§ç»†ç²’åº¦èƒ½åŠ› | âŒ èƒ½åŠ›åˆ’åˆ†ç²—ç•¥ |
| **è¯„ä¼°æ–¹å¼** | âœ… å¤šæ ·åŒ–æŒ‡æ ‡ï¼ˆç»“æœ/è¿‡ç¨‹/ä¸»è§‚ï¼‰ | âŒ å¤šä¸ºç²¾ç¡®åŒ¹é… |
| **æ•°æ®å¤šæ ·æ€§** | âœ… æ··åˆç”Ÿæˆ + ä¸»é¢˜æ§åˆ¶ | âŒ æ•°æ®æ¥æºå•ä¸€ |

> âœ… è¡¨ç¤ºæ”¯æŒï¼ŒâŒ è¡¨ç¤ºä¸æ”¯æŒæˆ–å¼±æ”¯æŒ

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **EvolMem è‡ªå»ºæ•°æ®é›†**ï¼š
  - åŒ…å« **1,600 æ¡å¤šä¼šè¯å¯¹è¯**
  - å¹³å‡æ¯æ¡å¯¹è¯æœ‰ **6.82 ä¸ªä¼šè¯ï¼ˆsessionï¼‰** å’Œ **29.49 è½®ï¼ˆturnsï¼‰**
  - æ•°æ®æ¥æºï¼š
    - **Topic-Initiated Generation (TIG)**ï¼šåŸºäº10ä¸ªç±»åˆ«ã€50ä¸ªå…·ä½“è¯é¢˜ç”Ÿæˆï¼ˆå¦‚å†™ä½œã€è¾…å¯¼ã€èŒä¸šå‘å±•ç­‰ï¼‰
    - **Narrative-Inspired Transformation (NIT)**ï¼šä» **Ruler** åŸºå‡†ä¸­çš„ **Variable Tracking (VT)** å­é›†è½¬åŒ–è€Œæ¥

### **å®éªŒè®¾ç½®**

- **è¯„ä¼°å¯¹è±¡**ï¼š
  - **7ä¸ªå‰æ²¿LLMs**ï¼š
    - Gemini-3-Pro, GPT-5.1, MiniMax-M2, Mistral-Large, DeepSeek-V3.2, Kimi-K2, Llama-4-Maverick
  - **4ä¸ªAgent Memory Systems**ï¼ˆä»¥DeepSeek-V3.2ä¸ºåº•åº§ï¼‰ï¼š
    - Structure-Augmented RAG ç±»ï¼šMem0, HippoRAG
    - Agentic Memory ç±»ï¼šMemoryOS, A-MEM

- **è¯„ä¼°æŒ‡æ ‡åˆ†ç±»**ï¼š
  - **Result-Oriented**ï¼šAccuracy, Precision
  - **Process-Oriented**ï¼šLCSï¼ˆç”¨äºReproductionå’ŒLearningä»»åŠ¡ï¼‰
  - **Open-Ended**ï¼šLLM-as-a-Judge + åŠ æƒè¯„åˆ†å‡†åˆ™

- **è¯„ä¼°æµç¨‹æ ‡å‡†åŒ–**ï¼š
  - æ‰€æœ‰Agentç³»ç»Ÿç»Ÿä¸€ä½¿ç”¨ DeepSeek-V3.2 ä½œä¸ºbackbone LLM
  - ç»Ÿä¸€embeddingæ¨¡å‹ï¼ˆall-MiniLM-L6-v2ï¼‰
  - å›ºå®šè¶…å‚æ•°ï¼ˆå¦‚æ£€ç´¢top-kã€memoryå®¹é‡ç­‰ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§Table 2ï¼‰**

| Model | Overall Score | Declarative Avg | Non-declarative Avg |
|-------|---------------|------------------|----------------------|
| **Gemini-3-Pro** | **67.47%** | 69.16% | 65.77% |
| GPT-5.1 | 52.82% | 72.81% | 32.83% |
| MiniMax-M2 | 52.39% | 71.02% | 33.76% |
| Mistral-Large | 52.35% | 71.44% | 33.26% |
| DeepSeek-V3.2 | 52.18% | 66.94% | 37.41% |
| Llama-4-Maverick | 37.53% | 49.92% | 25.13% |

> âš ï¸ æ³¨æ„ï¼šå°½ç®¡GPT-5.1åœ¨å£°æ˜æ€§è®°å¿†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨**Habituation**ä¸Šä»…å¾— **14.79%**ï¼Œè¿œä½äºGemini-3-Proçš„ **84.16%**

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

#### **LLM vs. Agent Systemsï¼ˆTable 3ï¼‰**

| Agent System | Overall Score | vs. Base Model (DeepSeek-V3.2) |
|--------------|----------------|-------------------------------|
| MemoryOS     | 48.66%         | < 52.18%                      |
| A-MEM        | 44.54%         | < 52.18%                      |
| Mem0         | 42.44%         | < 52.18%                      |
| HippoRAG     | 33.11%         | < 52.18%                      |

> ğŸ”´ **æ‰€æœ‰Agentç³»ç»Ÿå‡æœªè¶…è¶Šå…¶åº•åº§LLMï¼ˆDeepSeek-V3.2ï¼‰çš„æ•´ä½“æ€§èƒ½**ï¼Œè¯´æ˜å½“å‰è®°å¿†æœºåˆ¶è®¾è®¡æœªèƒ½æœ‰æ•ˆæå‡è®°å¿†èƒ½åŠ›ã€‚

#### **æ•ˆç‡å¯¹æ¯”ï¼ˆTable 4ï¼‰**

| Agent System | Generation Speed (s/sample) |
|--------------|------------------------------|
| Mem0         | 30.17                        |
| HippoRAG     | 92.76                        |
| MemoryOS     | 183.24                       |
| A-MEM        | **492.60**                   |

> â±ï¸ A-MEM çš„å»¶è¿Ÿæ˜¯ Mem0 çš„ **16.3å€**ï¼Œè¡¨æ˜agentic memoryæœºåˆ¶å¸¦æ¥æ˜¾è‘—æ•ˆç‡ç“¶é¢ˆã€‚

---

### **æ¶ˆèå®éªŒä¸æ•æ„Ÿæ€§åˆ†æ**

- **LLMç”Ÿæˆå™¨æ•æ„Ÿæ€§æµ‹è¯•**ï¼ˆFig. 3ï¼‰ï¼š
  - ä½¿ç”¨ä¸åŒLLMï¼ˆDeepSeek, GPT-4.1, Grokï¼‰ç”Ÿæˆè®­ç»ƒæ•°æ®æ—¶ï¼Œæ¨¡å‹æ’åç›¸å…³æ€§å·®å¼‚æ˜¾è‘—ã€‚
  - DeepSeekç”Ÿæˆçš„æ•°æ®ä¸å…¶ä»–é«˜åº¦ä¸€è‡´ï¼ˆSpearman Ï=0.90ï¼‰ï¼Œè€ŒGPT-4.1ç›¸å…³æ€§æä½ï¼ˆÏ=0.05ï¼‰ã€‚
  - âœ æ”¯æŒä½¿ç”¨**å¤šLLMååŒç”Ÿæˆ**ä»¥æé«˜æ•°æ®å¤šæ ·æ€§å’Œè¯„ä¼°å…¬å¹³æ€§ã€‚

- **å¤æ‚åº¦æ¼”åŒ–å®éªŒ**ï¼ˆFig. 4ï¼‰ï¼š
  - éšç€ä¼šè¯æ•°å¢åŠ ï¼ŒDeepSeek-V3.2æ€§èƒ½æŒç»­ä¸‹é™ã€‚
  - âœ è¯æ˜EvolMemå…·å¤‡**å¯æ‰©å±•éš¾åº¦æ¼”åŒ–èƒ½åŠ›**ï¼Œé€‚åˆé•¿æœŸè¿½è¸ªæ¨¡å‹è¿›æ­¥ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **No LLM is universally superior**ï¼š
   - æ²¡æœ‰ä»»ä½•ä¸€ä¸ªLLMåœ¨æ‰€æœ‰è®°å¿†ç»´åº¦ä¸Šéƒ½é¢†å…ˆã€‚
   - ä¾‹å¦‚ï¼šGeminiæ“…é•¿Inferenceå’ŒHabituationï¼Œä½†Retrievalè¾ƒå¼±ï¼›Mistralæ“…é•¿Retrievalä½†Inferenceå·®ã€‚

2. **Non-declarative memory is severely underdeveloped**ï¼š
   - æ‰€æœ‰æ¨¡å‹åœ¨ **Habituation** ä¸Šè¡¨ç°æœ€å·®ï¼ˆå¹³å‡ä»…29.13%ï¼‰ï¼Œä¸”æ–¹å·®æå¤§ï¼ˆæ ‡å‡†å·®24.57%ï¼‰ã€‚
   - è¡¨æ˜å½“å‰è®­ç»ƒèŒƒå¼ä¸¥é‡å¿½è§†é•¿æœŸè¡Œä¸ºä¸€è‡´æ€§å»ºæ¨¡ã€‚

3. **Agent memory mechanisms do not help â€” often hurt**ï¼š
   - æ‰€æœ‰Agentç³»ç»Ÿ**æœªèƒ½è¶…è¶Šå…¶åº•åº§LLM**ï¼Œç”šè‡³åœ¨å¤šæ•°ä»»åŠ¡ä¸Šæ›´å·®ã€‚
   - ç‰¹åˆ«æ˜¯åœ¨ **non-declarative memory** ä¸Šæ€§èƒ½æ€¥å‰§ä¸‹é™ï¼ˆå¦‚A-MEMåœ¨Habituationä¸Šä»…9.37%ï¼‰ã€‚

4. **Efficiency is a major bottleneck**ï¼š
   - Agentic memoryç³»ç»Ÿï¼ˆå¦‚A-MEMï¼‰å¼•å…¥å·¨å¤§æ¨ç†å»¶è¿Ÿï¼Œä¸é€‚åˆå®æ—¶åº”ç”¨ã€‚

5. **Memory is distinct from general capabilities**ï¼š
   - EvolMemå¾—åˆ†ä¸Codeï¼ˆÏ=0.75ï¼‰ã€Reasoningï¼ˆÏ=0.71ï¼‰å¼ºç›¸å…³ï¼Œä½†ä¸Knowledgeï¼ˆÏ=0.18ï¼‰å‡ ä¹æ— å…³ã€‚
   - âœ è¯´æ˜è¯¥åŸºå‡†æµ‹çš„æ˜¯**ä¸Šä¸‹æ–‡ç†è§£ä¸è®°å¿†åˆ©ç”¨èƒ½åŠ›**ï¼Œè€Œéé™æ€çŸ¥è¯†å‚¨å¤‡ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

- **ä¾èµ–LLMç”Ÿæˆæ•°æ®**ï¼šè™½ç»äººå·¥éªŒè¯ï¼ˆæœ‰æ•ˆæ€§95.33%ï¼‰ï¼Œä½†ä»å¯èƒ½å­˜åœ¨å¹»è§‰æˆ–åå·®ã€‚
- **éå£°æ˜æ€§ä»»åŠ¡éš¾ä»¥å®Œå…¨å®¢è§‚è¯„ä¼°**ï¼šå¦‚Habituationä¾èµ–LLM-as-a-Judgeï¼Œä¸»è§‚æ€§å¼ºã€‚
- **å°šæœªè¦†ç›–æ‰€æœ‰éå£°æ˜æ€§è®°å¿†ç±»å‹**ï¼šå¦‚æƒ…æ„Ÿè®°å¿†ã€ç¨‹åºæ€§æŠ€èƒ½ç­‰æœªçº³å…¥ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **è”åˆä¼˜åŒ–Agentçš„æœ‰æ•ˆæ€§ä¸æ•ˆç‡**ï¼šæ¢ç´¢è½»é‡çº§ã€é«˜å“åº”é€Ÿåº¦çš„è®°å¿†æ¶æ„ã€‚
2. **æå‡non-declarative memoryå»ºæ¨¡èƒ½åŠ›**ï¼šè®¾è®¡ä¸“é—¨é’ˆå¯¹habituationå’Œimplicit learningçš„è®­ç»ƒç›®æ ‡ã€‚
3. **åŠ¨æ€æ¼”åŒ–åŸºå‡†**ï¼šæ„å»ºéšæ—¶é—´è‡ªåŠ¨å‡çº§éš¾åº¦çš„â€œæ´»â€åŸºå‡†ï¼ˆliving benchmarkï¼‰ã€‚
4. **äººæœºååŒè¯„ä¼°**ï¼šå¼•å…¥æ›´å¤šäººç±»æ ‡æ³¨ä»¥æ ¡å‡†LLM-as-a-Judgeçš„åè§ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **EvolMemæ­ç¤ºäº†ä¸€ä¸ªå…³é”®ç°å®â€”â€”å½“å‰LLMså’ŒAgentç³»ç»Ÿåœ¨è·¨ä¼šè¯ã€éšæ€§è®°å¿†ä»»åŠ¡ä¸Šä»æä¸ºè„†å¼±ï¼Œè€Œç°æœ‰çš„â€œè®°å¿†å¢å¼ºâ€æœºåˆ¶å¹¶æœªçœŸæ­£è§£å†³é—®é¢˜ï¼Œåè€Œå¸¦æ¥äº†æ•ˆç‡ä»£ä»·ã€‚**

</details>

---

### 8. [LLM-MC-Affect: LLM-Based Monte Carlo Modeling of Affective Trajectories and Latent Ambiguity for Interpersonal Dynamic Insight](https://arxiv.org/abs/2601.03645)

**Authors**: Yu-Zheng Lin, Bono Po-Jen Shih, John Paul Martin Encinas, Elizabeth Victoria Abraham Achom, Karan Himanshu Patel, Jesus Horacio Pacheco, Sicong Shao, Jyotikrishna Dass, Soheil Salehi, Pratik Satam  
**Category**: cs.CL  
**Published**: 2026-01-08  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.03645v1  

#### Abstract
Emotional coordination is a core property of human interaction that shapes how relational meaning is constructed in real time. While text-based affect inference has become increasingly feasible, prior approaches often treat sentiment as a deterministic point estimate for individual speakers, failing...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLLM-MC-Affect: LLM-Based Monte Carlo Modeling of Affective Trajectories and Latent Ambiguity for Interpersonal Dynamic Insight

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»ŸåŸºäºæ–‡æœ¬çš„æƒ…æ„Ÿåˆ†ææ–¹æ³•é€šå¸¸å°†æƒ…æ„Ÿè§†ä¸º**ç¡®å®šæ€§çš„ç‚¹ä¼°è®¡**ï¼ˆdeterministic point estimateï¼‰ï¼Œå¿½ç•¥äº†ä»¥ä¸‹å…³é”®å› ç´ ï¼š
- **ä¸»è§‚æ€§å’Œæ„ŸçŸ¥æ¨¡ç³Šæ€§**ï¼ˆperceptual ambiguityï¼‰ï¼šåŒä¸€å¥è¯å¯èƒ½è¢«ä¸åŒäººè§£è¯»ä¸ºä¸åŒæƒ…ç»ªã€‚
- **åŠ¨æ€è€¦åˆæ€§**ï¼ˆsequential couplingï¼‰ï¼šäººé™…äº’åŠ¨ä¸­çš„æƒ…æ„Ÿæ˜¯ç›¸äº’å½±å“ã€æ—¶åºå…³è”çš„ï¼Œè€Œéå­¤ç«‹å­˜åœ¨ã€‚

è¿™äº›ç®€åŒ–é™åˆ¶äº†å¯¹çœŸå®ç¤¾äº¤äº’åŠ¨ä¸­æƒ…æ„Ÿåè°ƒï¼ˆemotional coordinationï¼‰çš„æ·±å…¥ç†è§£ï¼Œå°¤å…¶æ˜¯åœ¨æ•™è‚²ç­‰éœ€è¦ç²¾ç»†æƒ…æ„Ÿäº¤äº’çš„åœºæ™¯ä¸­ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **LLM-MC-Affect** â€”â€” ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è’™ç‰¹å¡æ´›ï¼ˆMonte Carloï¼‰æƒ…æ„Ÿå»ºæ¨¡æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³åŒ…æ‹¬ï¼š

- **å°†æƒ…æ„Ÿå»ºæ¨¡ä¸ºè¿ç»­æ½œåœ¨æ¦‚ç‡åˆ†å¸ƒ**  
  ä¸å†è¾“å‡ºå•ä¸€æƒ…æ„Ÿæ ‡ç­¾ï¼Œè€Œæ˜¯é€šè¿‡å¤šæ¬¡éšæœºé‡‡æ ·ï¼ˆstochastic decodingï¼‰æ„å»ºä¸€ä¸ª**æ½œè—æƒ…æ„Ÿåˆ†å¸ƒ** $ p(e|u) $ï¼Œä»è€Œæ•æ‰æƒ…æ„Ÿçš„ä¸­å¿ƒè¶‹åŠ¿ï¼ˆå‡å€¼ï¼‰å’Œä¸ç¡®å®šæ€§ï¼ˆæ–¹å·®ï¼‰ã€‚

- **åˆ©ç”¨LLMçš„éšæœºè§£ç è¿›è¡ŒMonte Carloä¼°è®¡**  
  åœ¨éé›¶æ¸©åº¦ä¸‹å¯¹åŒä¸€è¯è¯­æ‰§è¡Œ $ K $ æ¬¡ç‹¬ç«‹æ¨ç†ï¼Œå¾—åˆ°å¤šä¸ªæƒ…æ„Ÿè¯„åˆ†ï¼Œè§†ä½œä»éšå«æƒ…æ„Ÿåˆ†å¸ƒä¸­æŠ½å–çš„æ ·æœ¬ï¼Œè¿›è€Œä¼°ç®—å‡å€¼ä¸æ–¹å·®ã€‚

- **æ„å»ºä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„æƒ…æ„Ÿè½¨è¿¹**ï¼ˆuncertainty-aware affective trajectoriesï¼‰  
  å°†æ¯è½®å¯¹è¯çš„æƒ…æ„Ÿå‡å€¼ä¸²è”æˆæ—¶é—´åºåˆ—è½¨è¿¹ï¼Œå¹¶ç”¨æ–¹å·®è¡¨ç¤ºâ€œæƒ…æ„Ÿæ¨¡ç³Šåº¦â€ï¼Œå®ç°å¯¹ä¸ªä½“æƒ…æ„Ÿæ¼”å˜çš„é«˜ä¿çœŸåˆ»ç”»ã€‚

- **å¼•å…¥äººé™…åŠ¨æ€åˆ†æå±‚**  
  åŸºäºæ•™å¸ˆä¸å­¦ç”Ÿçš„æƒ…æ„Ÿè½¨è¿¹ï¼Œè®¡ç®—ï¼š
  - **å½’ä¸€åŒ–äº¤å‰ç›¸å…³å‡½æ•°**ï¼ˆNormalized Cross-Correlation Function, NCCFï¼‰
  - **æœ€ä¼˜æ»å**ï¼ˆOptimal Lag $ L^* $ï¼‰ä»¥è¯†åˆ«è°ä¸»å¯¼æƒ…æ„ŸæµåŠ¨
  - **æ–œç‡è¶‹åŠ¿æŒ‡æ ‡**ï¼ˆslope-based trendï¼‰åæ˜ é•¿æœŸæƒ…æ„Ÿå‘å±•
  å¹¶ç»“åˆä¸‰è€…å½¢æˆå¯è§£é‡Šçš„äº’åŠ¨æ¨¡å¼åˆ†ç±»ï¼ˆå¦‚æœ‰æ•ˆæ”¯æ¶ã€å…±äº«ç–²åŠ³ç­‰ï¼‰ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | LLM-MC-Affect |
|------|--------|---------------|
| æƒ…æ„Ÿè¡¨ç¤º | ç¡®å®šæ€§æ ‡ç­¾ï¼ˆå¦‚æ­£é¢/è´Ÿé¢ï¼‰ | è¿ç»­æ¦‚ç‡åˆ†å¸ƒï¼ˆå«å‡å€¼ä¸æ–¹å·®ï¼‰ |
| ä¸»è§‚æ€§å¤„ç† | å¿½ç•¥æˆ–å¹³å‡æ‰å·®å¼‚ | æ˜¾å¼é‡åŒ–â€œæƒ…æ„Ÿæ¨¡ç³Šæ€§â€ |
| åŠ¨æ€å»ºæ¨¡ | é™æ€é€å¥åˆ¤æ–­ | æ„å»ºçºµå‘æƒ…æ„Ÿè½¨è¿¹ |
| äººé™…è€¦åˆåˆ†æ | ç¼ºä¹ç³»ç»Ÿå»ºæ¨¡ | æ”¯æŒæ»åã€ç›¸å…³æ€§ã€è¶‹åŠ¿è”åˆåˆ†æ |
| å¯æ‰©å±•æ€§ | ä¾èµ–äººå·¥æ ‡æ³¨æˆ–ç”Ÿç‰©ä¼ æ„Ÿå™¨ | å®Œå…¨åŸºäºæ–‡æœ¬ï¼Œæ— éœ€å¾®è°ƒï¼ˆzero-shotï¼‰ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡è‡ªç„¶å¯¹è¯ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **Google's Education Dialogue Dataset**ï¼ˆShani et al., 2024ï¼‰  
  åŒ…å«å¤šè½®æ¨¡æ‹Ÿçš„æ•™å­¦å¯¹è¯ï¼Œæ¶µç›–å¤šä¸ªä¸»é¢˜ï¼ˆå¦‚â€œThe Cold Warâ€, â€œPersonificationâ€ç­‰ï¼‰ã€‚  
  æ•°æ®ä¸º**ä»¿çœŸç”Ÿæˆ**ï¼Œä¾¿äºæ§åˆ¶å­¦ç”Ÿ/æ•™å¸ˆçš„äººè®¾åå¥½ä¸ååº”æœºåˆ¶ï¼Œé¿å…çœŸå®è¯¾å ‚æ•°æ®çš„ä¼¦ç†ä¸éšç§é—®é¢˜ã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹é€‰æ‹©**ï¼š
  - å•†ä¸šé—­æºæ¨¡å‹ï¼š`GPT-4.1`, `GPT-3.5-Turbo`
  - å¼€æºæ¨¡å‹ï¼š`Llama 3.3 70B`, `Gemma 3 4B`, `Phi-4 14B`, `GPT-OSS 120B`

- **è§£ç å‚æ•°**ï¼š
  - æ¸©åº¦ $ T \in [0.1, 1.0] $ï¼Œç”¨äºæ§åˆ¶ç”Ÿæˆå¤šæ ·æ€§
  - æ¯ä¸ªutteranceæ‰§è¡Œ $ K=20 $ æ¬¡Monte Carloé‡‡æ ·

- **ç»Ÿä¸€å¿ƒç†æµ‹é‡æç¤º**ï¼ˆpsychometric prompt, `pemo`ï¼‰ï¼š
  - å¼•å¯¼LLMä½œä¸ºå¿ƒç†å­¦å®¶è¿›è¡Œæƒ…æ„Ÿæ‰“åˆ†
  - è¾“å‡ºèŒƒå›´ï¼š0ï¼ˆæœ€ç§¯æï¼‰åˆ°5ï¼ˆæœ€æ¶ˆæï¼‰ï¼Œæ­¥é•¿0.5
  - ä¸­æ€§å€¼ä¸º2.5
  - è¦æ±‚è€ƒè™‘ä¸Šä¸‹æ–‡è¿ç»­æ€§ä¸æƒ…æ„Ÿæ¼”åŒ–

- **åå¤„ç†**ï¼š
  - å¯¹åŸå§‹å¾—åˆ†è¿›è¡Œææ€§æ˜ å°„è‡³ $[-1, 1]$ åŒºé—´ï¼Œä¾¿äºåç»­åˆ†æ
  - æ–¹å·®åŒæ­¥ç¼©æ”¾ä»¥ä¿æŒå•ä½ä¸€è‡´æ€§

### è¯„ä¼°æŒ‡æ ‡
- **æƒ…æ„Ÿè½¨è¿¹ç¨³å®šæ€§**ï¼šåœ¨ä¸åŒæ¸©åº¦ä¸‹çš„å‡å€¼æ³¢åŠ¨æƒ…å†µ
- **æƒ…æ„Ÿæ¨¡ç³Šæ€§é‡åŒ–**ï¼šMonte Carloé‡‡æ ·çš„æ–¹å·®å¤§å°
- **è·¨æ¨¡å‹ä¸€è‡´æ€§æ¯”è¾ƒ**ï¼šä¸åŒLLMç”Ÿæˆè½¨è¿¹çš„å½¢æ€å·®å¼‚
- **äººé™…åŠ¨æ€æŒ‡æ ‡**ï¼š
  - æœ€ä¼˜æ»å $ L^* $
  - æœ€å¤§äº¤å‰ç›¸å…³ç³»æ•° $ R_{rs}(L^*) $
  - è½¨è¿¹æ–œç‡ $ \beta_T, \beta_S $

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æœ¬æ–‡æœªç›´æ¥å¯¹æ¯”ä¼ ç»ŸNLPæƒ…æ„Ÿåˆ†ç±»å™¨ï¼ˆå¦‚BERT-based classifiersï¼‰ï¼Œè€Œæ˜¯å¼ºè°ƒä¸ä»¥ä¸‹ä¸¤ç±»å·¥ä½œçš„åŒºåˆ«ï¼š
- **ä¼ ç»Ÿç¡®å®šæ€§æƒ…æ„Ÿåˆ†æç®¡é“**ï¼ˆå¦‚Liu et al., 2023a; Gao et al., 2022ï¼‰
- **ä¾èµ–ç”Ÿç‰©ä¿¡å·çš„æƒ…æ„ŸåŒæ­¥ç ”ç©¶**ï¼ˆå¦‚Qi et al., 2024; Bevilacqua et al., 2019ï¼‰

LLM-MC-Affectçš„ä¼˜åŠ¿åœ¨äº**ä»…ç”¨æ–‡æœ¬å³å¯å®ç°ç±»ä¼¼ç”šè‡³æ›´ä¸°å¯Œçš„åŠ¨æ€æ´å¯Ÿ**ï¼Œä¸”æ›´å…·å¯éƒ¨ç½²æ€§ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ä¸å‘ç°

#### ï¼ˆ1ï¼‰æƒ…æ„Ÿåˆ†å¸ƒå»ºæ¨¡çš„æœ‰æ•ˆæ€§
- å›¾2aæ˜¾ç¤ºï¼Œåœ¨ä½æ¸©åº¦ï¼ˆ$T=0.1$ï¼‰æ—¶ï¼ŒLLMå¯¹æŸäº›è¯­å¥äº§ç”Ÿ**åŒå³°åˆ†å¸ƒ**ï¼ˆbimodal perceptionï¼‰ï¼Œè¡¨æ˜å­˜åœ¨å¤šç§åˆç†çš„æƒ…æ„Ÿè§£è¯»ã€‚
- éšç€æ¸©åº¦å‡é«˜ï¼Œåˆ†å¸ƒè¶‹äºå¹³æ»‘ï¼Œæ–¹å·®å¢åŠ ï¼Œæ­ç¤ºäº†è¯­è¨€è¡¨è¾¾çš„å†…åœ¨æ­§ä¹‰ã€‚
- **æ–¹å·®è¢«æˆåŠŸç”¨ä½œâ€œæƒ…æ„Ÿæ¨¡ç³Šæ€§â€çš„ä»£ç†æŒ‡æ ‡**ã€‚

#### ï¼ˆ2ï¼‰æƒ…æ„Ÿè½¨è¿¹çš„é²æ£’æ€§
- å°½ç®¡æ¸©åº¦å˜åŒ–æ˜¾è‘—å½±å“é‡‡æ ·æ–¹å·®ï¼ˆå¦‚Utterance 6çš„ $\sigma^2$ ä»0.010å‡è‡³0.024ï¼‰ï¼Œä½†**å‡å€¼æƒ…æ„ŸçŠ¶æ€æå…¶ç¨³å®š**ï¼ˆæ³¢åŠ¨èŒƒå›´ï¼š-0.11 ~ -0.26ï¼‰ã€‚
- å›¾2bæ˜¾ç¤ºæ‰€æœ‰æ¸©åº¦ä¸‹çš„æ•™å¸ˆæƒ…æ„Ÿè½¨è¿¹é«˜åº¦ä¸€è‡´ï¼ŒéªŒè¯äº†MCä¼°è®¡çš„å¯é æ€§ã€‚

#### ï¼ˆ3ï¼‰è·¨æ¨¡å‹è¡Œä¸ºå·®å¼‚
| æ¨¡å‹ | è¡¨ç°ç‰¹ç‚¹ |
|------|---------|
| `GPT-4.1` | æƒ…æ„Ÿåˆ†è¾¨ç‡æœ€é«˜ï¼Œèƒ½å‡†ç¡®æ•æ‰æ—©æœŸè´Ÿé¢æƒ…ç»ªå¹¶å»ºæ¨¡å›å‡è¿‡ç¨‹ |
| `GPT-3.5-Turbo` | ç»“æ„ç›¸ä¼¼ä½†ä¸ç¡®å®šæ€§æ›´å¤§ï¼ˆuncertainty bandæ›´å®½ï¼‰ |
| `Llama 3.3 70B` | **æç«¯æ­£å‘åè§**ï¼Œå®Œå…¨å¿½ç•¥åˆæœŸè´Ÿé¢æƒ…ç»ªï¼ˆalignment for harmlessnessæ‰€è‡´ï¼‰ |
| `GPT-OSS 120B`, `Gemma 3 4B`, `Phi-4 14B` | æ™®éè¡¨ç°å‡ºä¿å®ˆä¼°è®¡å€¾å‘ï¼Œä½ä¼°æƒ…æ„Ÿè½¬æŠ˜ç‚¹ |

> âœ… **ç»“è®º**ï¼šå¹¶éæ‰€æœ‰LLMéƒ½é€‚åˆé«˜ä¿çœŸæƒ…æ„Ÿæƒ…ç»ªå»ºæ¨¡ï¼›`GPT-4.1`è¡¨ç°æœ€ä¼˜ã€‚

#### ï¼ˆ4ï¼‰äººé™…åŠ¨æ€åˆ†æç»“æœï¼ˆæ¡ˆä¾‹ç ”ç©¶ï¼‰
ä½¿ç”¨`GPT-4.1` ($T=0.7$) åˆ†æå¤šä¸ªæ•™å­¦å¯¹è¯ï¼Œå¾—å‡ºå¦‚ä¸‹å…¸å‹æ¨¡å¼ï¼š

| å¯¹è¯ä¸»é¢˜ | $L^*$ | $R_{rs}(L^*)$ | $\beta_T$ | $\beta_S$ | è§£é‡Š |
|--------|-------|----------------|-----------|-----------|------|
| **Personification** | +1 | 0.999 | +0.162 | +0.253 | **Effective Scaffolding**ï¼ˆæ•™å¸ˆå¼•é¢†çš„æ­£å‘æ„ŸæŸ“ï¼‰ |
| **The Respiratory System** | +3 | 1.000 | +0.065 | +0.166 | åŒä¸Š |
| **Achilles** | +1 | 0.886 | +0.071 | +0.057 | åŒä¸Š |
| **The Cold War** | 0 | 0.991 | -0.177 | -0.136 | **Shared Fatigue**ï¼ˆåŒæ­¥åŠ¨æœºè¡°é€€ï¼‰ |
| **World War 2** | -2 | 1.000 | -0.124 | -0.267 | **Feedback Burnout**ï¼ˆå­¦ç”Ÿé©±åŠ¨çš„å…±åŒä¸‹æ»‘ï¼‰ |

è¿™äº›æ¨¡å¼ä¸é¢„è®¾çš„å­¦ç”Ÿ/æ•™å¸ˆäººè®¾é«˜åº¦å»åˆï¼Œè¯æ˜äº†è¯¥æ–¹æ³•çš„**è§£é‡ŠåŠ›å¼ºã€ç¬¦åˆç›´è§‰**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æƒ…æ„Ÿä¸åº”è¢«è§†ä¸ºç¡®å®šæ€§æ ‡ç­¾**ï¼Œè€Œåº”å»ºæ¨¡ä¸ºå¸¦æœ‰ä¸ç¡®å®šæ€§çš„æ½œåœ¨åˆ†å¸ƒã€‚
2. **LLMçš„éšæœºè§£ç å¯ç”¨äºè¿‘ä¼¼äººç±»æƒ…æ„Ÿåˆ¤æ–­çš„ä¸»è§‚å˜å¼‚æ€§**ï¼Œæ— éœ€æ˜‚è´µçš„äººå·¥æ ‡æ³¨ã€‚
3. **é€šè¿‡Monte Carloé‡‡æ ·è·å¾—çš„æƒ…æ„Ÿè½¨è¿¹å…·æœ‰è‰¯å¥½çš„ç¨³å®šæ€§ä¸è§£é‡Šæ€§**ï¼Œå³ä½¿åœ¨é«˜éšæœºæ€§æ¡ä»¶ä¸‹ä¹Ÿèƒ½ä¿ç•™æ ¸å¿ƒæƒ…æ„Ÿä¿¡å·ã€‚
4. **ç»“åˆcross-correlationã€lagå’ŒslopeæŒ‡æ ‡ï¼Œå¯ä»¥ç³»ç»Ÿè¯†åˆ«å‡ºå¤šç§å¯è§£é‡Šçš„äººé™…äº’åŠ¨æ¨¡å¼**ï¼Œå¦‚æœ‰æ•ˆæ”¯æ¶ã€åé¦ˆå€¦æ€ ã€åŠ¨æ€è¡¥å¿ç­‰ã€‚
5. **ä¸åŒLLMåœ¨æƒ…æ„Ÿèƒ½åŠ›ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚**ï¼Œ`GPT-4.1`åœ¨åˆ†è¾¨ç‡å’ŒçœŸå®æ€§æ–¹é¢ä¼˜äºå…¶ä»–æ¨¡å‹ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **æ–¹å·®è§£é‡Šçš„æ¨¡ç³Šæ€§**ï¼šMonte Carloæ–¹å·®å¯èƒ½æ··æ‚äº†å¤šç§ä¸ç¡®å®šæ€§æ¥æºï¼ˆepistemic vs. aleatoricï¼‰ï¼Œä¸èƒ½å®Œå…¨ç­‰åŒäºäººç±»æ„ŸçŸ¥çš„â€œæ¨¡ç³Šæ€§â€ã€‚
2. **ç›¸å…³ä¸ç­‰äºå› æœ**ï¼šäº¤å‰ç›¸å…³åªèƒ½åæ˜ é¡ºåºå¯¹é½ï¼Œæ— æ³•æ¨æ–­å› æœå½±å“ã€‚
3. **çŸ­å¯¹è¯é™åˆ¶ç»Ÿè®¡ç¨³å¥æ€§**ï¼šå½“å‰åˆ†æåŸºäºè¾ƒçŸ­å¯¹è¯ï¼Œé•¿ç¨‹åŠ¨æ€éœ€é‡‡ç”¨æ»‘åŠ¨çª—å£æˆ–åˆ†å±‚å»ºæ¨¡ã€‚
4. **è®¡ç®—æˆæœ¬è¾ƒé«˜**ï¼šæ¯æ¬¡æƒ…æ„Ÿè¯„ä¼°éœ€è¿è¡Œ $K=20$ æ¬¡LLMæ¨ç†ï¼Œä¸é€‚åˆå®æ—¶åº”ç”¨ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢è½»é‡çº§ã€ä»»åŠ¡ä¸“ç”¨çš„**æƒ…æ„Ÿæ•æ„Ÿå‹LLM**ï¼ˆaffect-sensitive LLMsï¼‰ä»¥æå‡æ•ˆç‡ã€‚
- å‘å±•**æ»‘åŠ¨çª—å£æˆ–å¤šå°ºåº¦åˆ†ææŠ€æœ¯**ï¼Œé€‚åº”æ›´é•¿å¯¹è¯ã€‚
- å°†æ¡†æ¶æ‹“å±•è‡³æ›´å¤šé¢†åŸŸï¼ˆå¦‚å¿ƒç†å’¨è¯¢ã€å®¢æˆ·æœåŠ¡ã€å›¢é˜Ÿåä½œï¼‰ã€‚
- ç»“åˆå°‘é‡äººå·¥æ ‡æ³¨è¿›è¡Œ**ä¸ç¡®å®šæ€§æ ¡å‡†**ï¼Œå¢å¼ºæ–¹å·®çš„å¯è§£é‡Šæ€§ã€‚

---

> ğŸ” **æ€»ä½“è¯„ä»·**ï¼š  
> LLM-MC-Affect æ˜¯ä¸€é¡¹å°†**æ¦‚ç‡å»ºæ¨¡æ€æƒ³**ä¸**LLMéšæœºæ€§**å·§å¦™ç»“åˆçš„å·¥ä½œï¼Œçªç ´äº†ä¼ ç»Ÿæƒ…æ„Ÿåˆ†æçš„é™æ€èŒƒå¼ï¼Œä¸ºç†è§£å¤æ‚ç¤¾ä¼šäº’åŠ¨æä¾›äº†æ–°çš„å·¥å…·è·¯å¾„ã€‚å®ƒä¸ä»…é€‚ç”¨äºæ•™è‚²åœºæ™¯ï¼Œä¹Ÿä¸ºæ›´å¹¿æ³›çš„**computational social science** å’Œ **affect-aware AI systems** æä¾›äº†å¯æ‰©å±•çš„æŠ€æœ¯åŸºç¡€ã€‚

</details>

---

### 9. [Rethinking Recurrent Neural Networks for Time Series Forecasting: A Reinforced Recurrent Encoder with Prediction-Oriented Proximal Policy Optimization](https://arxiv.org/abs/2601.03683)

**Authors**: Xin Lai, Shiming Deng, Lu Yu, Yumin Lai, Shenghao Qiao, Xinze Zhang  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.03683v1  

#### Abstract
Time series forecasting plays a crucial role in contemporary engineering information systems for supporting decision-making across various industries, where Recurrent Neural Networks (RNNs) have been widely adopted due to their capability in modeling sequential data. Conventional RNN-based predictor...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šRethinking Recurrent Neural Networks for Time Series Forecasting

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿçš„åŸºäº **Recurrent Neural Networks (RNNs)** çš„æ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹é€šå¸¸é‡‡ç”¨ **encoder-only** æ¶æ„ï¼Œé€šè¿‡æ»‘åŠ¨å†å²çª—å£è¿›è¡Œå¤šæ­¥é¢„æµ‹ã€‚ç„¶è€Œï¼Œè¿™ç±»æ–¹æ³•å­˜åœ¨ä»¥ä¸‹å±€é™æ€§ï¼š
- å°†æ‰€æœ‰æ—¶é—´æ­¥å’Œéšè—çŠ¶æ€è§†ä¸ºåŒç­‰é‡è¦ï¼Œå¿½ç•¥äº†å®ƒä»¬å¯¹é¢„æµ‹çš„ä¸åŒè´¡çŒ®ï¼›
- ç¼ºä¹åŠ¨æ€é€‚åº”æœºåˆ¶ï¼Œéš¾ä»¥æ•æ‰æ—¶å˜çš„æ—¶é—´ä¾èµ–æ¨¡å¼ï¼›
- å›ºå®šçš„è¾“å…¥é€‰æ‹©ã€éšè—è¿æ¥å’Œè¾“å‡ºç›®æ ‡ç­–ç•¥é™åˆ¶äº†æ¨¡å‹çš„çµæ´»æ€§ã€‚

è¿™äº›å› ç´ å¯¼è‡´æ¨¡å‹åœ¨å¤æ‚éå¹³ç¨³æ—¶é—´åºåˆ—ä¸Šçš„è¡¨ç°ä¸ä½³ã€‚

### æå‡ºçš„æ–°æ–¹æ³•
ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åä¸º **Reinforced Recurrent Encoder with Prediction-oriented Proximal Policy Optimization (RRE-PPO4Pred)** çš„æ–°æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰Reinforced Recurrent Encoder (RRE)
å°† RNN ç¼–ç å™¨çš„å†…éƒ¨é€‚åº”è¿‡ç¨‹å»ºæ¨¡ä¸ºä¸€ä¸ª **Markov Decision Process (MDP)**ï¼Œæ„å»ºäº†ä¸€ä¸ªç»Ÿä¸€çš„å†³ç­–ç¯å¢ƒï¼Œèƒ½å¤ŸåŒæ—¶å­¦ä¹ ä¸‰ç§å…³é”®æ“ä½œï¼š
- **Input Feature Selection**ï¼šå†³å®šæ¯ä¸ªæ—¶é—´æ­¥æ˜¯å¦ä½¿ç”¨å½“å‰è¾“å…¥ï¼›
- **Hidden Skip Connection**ï¼šåŠ¨æ€é€‰æ‹©è·³è¿‡å¤šå°‘æ­¥ä»¥å»ºç«‹é•¿è·ç¦»è®°å¿†è¿æ¥ï¼›
- **Output Target Selection**ï¼šå†³å®šæ˜¯å¦å°†æŸä¸€æ­¥çš„è¾“å‡ºçº³å…¥è®­ç»ƒæŸå¤±ã€‚

è¯¥æ¡†æ¶é€‚ç”¨äºå„ç§ RNN å˜ä½“ï¼ˆå¦‚ LSTM, GRU, xLSTM ç­‰ï¼‰ï¼Œå…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§ã€‚

#### ï¼ˆ2ï¼‰Prediction-oriented Proximal Policy Optimization (PPO4Pred)
ä¸€ç§æ”¹è¿›çš„ **PPO** ç®—æ³•ï¼Œä¸“ä¸ºé¢„æµ‹ä»»åŠ¡è®¾è®¡ï¼ŒåŒ…å«ä¸¤ä¸ªå…³é”®æ”¹è¿›ï¼š
- **Transformer-based Agent**ï¼šåˆ©ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶å¢å¼ºä»£ç†å¯¹æ—¶é—´ä¾èµ–æ€§çš„å»ºæ¨¡èƒ½åŠ›ï¼›
- **Dynamic Transition Sampling (DTS)**ï¼šå¼•å…¥ä¼˜å…ˆçº§é‡‡æ ·ç­–ç•¥ï¼Œèšç„¦äºé«˜è¯¯å·®æˆ–é«˜ä¸ç¡®å®šæ€§æ ·æœ¬ï¼Œæå‡è®­ç»ƒæ•ˆç‡ã€‚

#### ï¼ˆ3ï¼‰Co-evolutionary Optimization Paradigm
æå‡ºäº†ä¸€ç§å¼‚æ­¥ååŒè¿›åŒ–ä¼˜åŒ–èŒƒå¼ï¼Œäº¤æ›¿æ›´æ–° RNN é¢„æµ‹å™¨å’Œå¼ºåŒ–å­¦ä¹ ä»£ç†ï¼Œå®ç°ä¸¤è€…çš„è”åˆæ¼”åŒ–ï¼Œä»è€Œæå‡æ•´ä½“é¢„æµ‹èƒ½åŠ›å’Œé€‚åº”æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´å¼ºçš„é€‚åº”æ€§**ï¼šé€šè¿‡åŠ¨æ€å†³ç­–æœºåˆ¶ï¼Œæ¨¡å‹èƒ½æ ¹æ®ä¸åŒè¾“å…¥æ¨¡å¼è‡ªé€‚åº”è°ƒæ•´æ¶æ„ï¼›
- **æ›´é«˜çš„é¢„æµ‹ç²¾åº¦**ï¼šåœ¨å¤šä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿ RNN å’Œéƒ¨åˆ† Transformer æ¨¡å‹ï¼›
- **æ›´ä¼˜çš„ç¨³å®šæ€§**ï¼šæ¶ˆé™¤äº† Seq2Seq ä¸­çš„è¯¯å·®ç´¯ç§¯å’Œæš´éœ²åå·®é—®é¢˜ï¼›
- **ç«¯åˆ°ç«¯å¯è®­ç»ƒ**ï¼šä¸‰ä¸ªç»„ä»¶ï¼ˆè¾“å…¥ã€éšè—ã€è¾“å‡ºï¼‰è¢«ç»Ÿä¸€åœ¨ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ æ¡†æ¶ä¸‹è”åˆä¼˜åŒ–ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒåœ¨äº”ä¸ªçœŸå®ä¸–ç•Œçš„å…¬å¼€åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œï¼Œæ¶µç›–äº¤é€šã€ç”µåŠ›ã€æ°”å€™ç­‰å¤šä¸ªé¢†åŸŸï¼š

| æ•°æ®é›† | é‡‡æ ·é¢‘ç‡ | æ—¶é—´æ­¥æ•° | å˜é‡æ•° $D_{in}$ | è¾“å…¥é•¿åº¦ $T$ | é¢„æµ‹èŒƒå›´ $H$ |
|--------|----------|-----------|------------------|---------------|----------------|
| **Traffic** | 1å°æ—¶ | 17,544 | 862 | 96 | [24, 48, 96] |
| **Electricity** | 1å°æ—¶ | 26,304 | 321 | 96 | [24, 48, 96] |
| **ETTh** | 1å°æ—¶ | 17,420 | 7 | 96 | [24, 48, 96] |
| **Weather** | 10åˆ†é’Ÿ | 52,696 | 21 | 96 | [24, 48, 96] |
| **ILI** | 1å‘¨ | 966 | 7 | 48 | [12, 24, 48] |

### å®éªŒè®¾ç½®
- æ‰€æœ‰æ•°æ®æŒ‰ 7:1:2 åˆ’åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ï¼›
- ä½¿ç”¨ **Min-Max** å½’ä¸€åŒ–ï¼›
- è¯„ä¼°æŒ‡æ ‡ï¼š**MSE** å’Œ **MAE**ï¼›
- æ¯ä¸ªå®éªŒè¿è¡Œ 10 æ¬¡å–å¹³å‡å€¼ï¼›
- GPUï¼šNVIDIA RTX A4500ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å…±æ¯”è¾ƒäº†å…­ç±»åŸºçº¿æ–¹æ³•ï¼š

| ç±»åˆ« | æ–¹æ³• | æè¿° |
|------|------|------|
| å›ºå®šç­–ç•¥ | `Naive-all`, `Naive-last` | ä½¿ç”¨æ‰€æœ‰æˆ–ä»…æœ€åä¸€æ­¥è¾“å‡ºä½œä¸ºç›‘ç£ä¿¡å· |
| å›ºå®šè·³è·ƒ | `DilatedRNN` | å›ºå®šé—´éš”çš„éšè—çŠ¶æ€è·³è·ƒè¿æ¥ |
| å¯å‘å¼æœç´¢ | `EBPSO` | åŸºäºç²’å­ç¾¤ä¼˜åŒ–çš„è¾“å…¥ç‰¹å¾é€‰æ‹© |
| å¼ºåŒ–å­¦ä¹  | `LSTMjump` | ä½¿ç”¨ PG å­¦ä¹ è¾“å…¥è·³è¿‡ç­–ç•¥ |
| å¼ºåŒ–å­¦ä¹  | `PGLSTM` | ä½¿ç”¨ PG å­¦ä¹ éšè—çŠ¶æ€è·³è·ƒ |
| Transformer | `iTransformer`, `PatchTST` | å½“å‰æœ€å…ˆè¿›çš„ Transformer æ¨¡å‹ |

æ­¤å¤–ï¼Œè¿˜è¿›è¡Œäº†ä¸ä¸åŒ RNN ä¸»å¹²ç½‘ç»œï¼ˆRNN, GRU, LSTM, xLSTM ç­‰ï¼‰çš„ç»„åˆå®éªŒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ ETTh æ•°æ®é›†ä¸ºä¾‹ï¼‰
| æ–¹æ³• | H=24 (MSE) | H=48 (MSE) | H=96 (MSE) |
|------|------------|------------|------------|
| iTransformer | 0.3540 | 0.3790 | 0.3921 |
| PatchTST | 0.3195 | 0.3477 | 0.3746 |
| xLSTM (Naive-all) | 0.5620 | 0.5962 | 0.6755 |
| **xLSTM + RRE-PPO4Pred** | **0.3075** | **0.3378** | **0.3607** |

> âœ… åœ¨æ‰€æœ‰é¢„æµ‹èŒƒå›´å†…å‡ä¼˜äºæœ€å…ˆè¿›çš„ Transformer æ¨¡å‹ï¼

### ä¸å…¶ä»– RNN åŸºçº¿çš„æ•´ä½“å¯¹æ¯”ï¼ˆå¹³å‡ MSE æ”¹è¿›ï¼‰
| å¯¹æ¯”ç±»åˆ« | å¹³å‡ MSE æ”¹è¿›å¹…åº¦ |
|---------|--------------------|
| vs. `Naive-all/last`, `DilatedRNN` | **23.7% ~ 53.08%** |
| vs. `EBPSO`ï¼ˆå¯å‘å¼ï¼‰ | **23.21% ~ 28.36%** |
| vs. `LSTMjump`, `PGLSTM`ï¼ˆRLï¼‰ | **19.04% ~ 27.80%** |

> ğŸ“Š å›¾è¡¨æ˜¾ç¤º RRE-PPO4Pred åœ¨æ‰€æœ‰æ•°æ®é›†å’Œé¢„æµ‹èŒƒå›´ä¸‹å‡å–å¾—æœ€ä½³æ€§èƒ½ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
é€šè¿‡é€æ­¥ç§»é™¤ç»„ä»¶éªŒè¯å„æ¨¡å—æœ‰æ•ˆæ€§ï¼š

| æ¶ˆèå˜ä½“ | MSE æ”¹è¿›ç‡ï¼ˆvs. TA-PSOï¼‰ | MAE æ”¹è¿›ç‡ï¼ˆvs. TA-PSOï¼‰ |
|----------|--------------------------|----------------------------|
| `TA-PSO`ï¼ˆPSOä¼˜åŒ–ä¸‰å…ƒåŠ¨ä½œï¼‰ | â€” | â€” |
| `RRE-PG`ï¼ˆPolicy Gradientï¼‰ | +7.14% ~ 13.38% | +9.01% ~ 11.78% |
| `RRE-DQN`ï¼ˆDeep Q-Networkï¼‰ | +5.08% ~ 10.81% | +6.98% ~ 10.80% |
| `RRE-PPO`ï¼ˆæ ‡å‡†PPOï¼‰ | +5.79% ~ 8.95% | +5.45% ~ 7.30% |
| **RRE-PPO4Predï¼ˆå®Œæ•´æ–¹æ³•ï¼‰** | **+24.99% ~ 37.01%** | **+24.69% ~ 31.25%** |

> ğŸ” ç»“è®ºï¼š
> - æ‰€æœ‰ RL æ–¹æ³•å‡ä¼˜äºå¯å‘å¼æœç´¢ï¼ˆPSOï¼‰ï¼›
> - PPO è¡¨ç°ä¼˜äº PG å’Œ DQNï¼›
> - åŠ å…¥ **Transformer-based Agent** å’Œ **DTS** åæ€§èƒ½è¿›ä¸€æ­¥æå‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **RNN ä»æœ‰å·¨å¤§æ½œåŠ›**ï¼šé€šè¿‡åˆç†çš„ç»“æ„ä¼˜åŒ–ï¼ŒRNN æ¨¡å‹å¯ä»¥è¶…è¶Šå½“å‰ä¸»æµçš„ Transformer æ¨¡å‹ï¼›
2. **åŠ¨æ€å†³ç­–æœºåˆ¶è‡³å…³é‡è¦**ï¼šç»Ÿä¸€ä¼˜åŒ–è¾“å…¥ã€éšè—å’Œè¾“å‡ºç­–ç•¥æ˜¾è‘—æå‡äº†æ¨¡å‹é€‚åº”æ€§å’Œé¢„æµ‹ç²¾åº¦ï¼›
3. **å¼ºåŒ–å­¦ä¹ æ˜¯æœ‰æ•ˆå·¥å…·**ï¼šå°† RNN æ¶æ„æœç´¢å»ºæ¨¡ä¸º MDP æ˜¯å¯è¡Œä¸”é«˜æ•ˆçš„ï¼›
4. **ååŒè¿›åŒ–èŒƒå¼æœ‰æ•ˆæ”¶æ•›**ï¼šä»£ç†ä¸é¢„æµ‹å™¨çš„äº¤æ›¿è®­ç»ƒå®ç°äº†ç¨³å®šä¸”æŒç»­çš„æ€§èƒ½æå‡ï¼›
5. **è¯¯å·®åˆ†å¸ƒæ›´é›†ä¸­**ï¼šRRE-PPO4Pred çš„é¢„æµ‹é”™è¯¯æ–¹å·®æ›´å°ï¼Œé²æ£’æ€§æ›´å¼ºã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **è®¡ç®—å¼€é”€è¾ƒå¤§**ï¼šç›¸æ¯”æ™®é€š RNNï¼Œè®­ç»ƒæ—¶é—´å’Œå‚æ•°é‡æœ‰æ‰€å¢åŠ ï¼ˆçº¦ 6â€“10 å€ï¼‰ï¼›
- **æ¨ç†é˜¶æ®µä»éœ€ä»£ç†å‚ä¸**ï¼šæ¯æ¬¡é¢„æµ‹éƒ½éœ€è¦è°ƒç”¨ç­–ç•¥ç½‘ç»œï¼Œå¢åŠ äº†éƒ¨ç½²å¤æ‚åº¦ï¼›
- **è¶…å‚æ•°æ•æ„Ÿ**ï¼šå¦‚ skip window size $K$ éœ€è¦ä»”ç»†è°ƒèŠ‚ï¼ˆæ–‡ä¸­å»ºè®® $K=8\sim10$ï¼‰ï¼›
- **ç›®å‰ä»…ç”¨äºé¢„æµ‹**ï¼šå°šæœªæ‰©å±•åˆ°ç”Ÿæˆã€å¼‚å¸¸æ£€æµ‹ç­‰å…¶ä»–ä»»åŠ¡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´é«˜æ•ˆçš„ä»£ç†æ¶æ„ï¼ˆå¦‚è½»é‡åŒ– Transformer æˆ–çŸ¥è¯†è’¸é¦ï¼‰ï¼›
- ç ”ç©¶è¿ç§»å­¦ä¹ æœºåˆ¶ï¼Œä½¿ä»£ç†å¯åœ¨ä¸åŒæ•°æ®é›†é—´å¤ç”¨ï¼›
- å°†è¯¥æ¡†æ¶åº”ç”¨äºå…¶ä»–åºåˆ—å»ºæ¨¡ä»»åŠ¡ï¼ˆå¦‚ NLPã€è¯­éŸ³è¯†åˆ«ï¼‰ï¼›
- å¼€å‘æ— éœ€åœ¨çº¿å†³ç­–çš„â€œå›ºåŒ–â€ç‰ˆæœ¬ï¼Œä¾¿äºè¾¹ç¼˜è®¾å¤‡éƒ¨ç½²ã€‚

---

> ğŸ’¡ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡ºçš„ **RRE-PPO4Pred** æ¡†æ¶é€šè¿‡å°† RNN ç¼–ç å™¨é‡æ„ä¸ºä¸€ä¸ªå¯å­¦ä¹ çš„å¼ºåŒ–å­¦ä¹ ç¯å¢ƒï¼Œå®ç°äº†å¯¹è¾“å…¥ã€éšè—å’Œè¾“å‡ºç­–ç•¥çš„è”åˆåŠ¨æ€ä¼˜åŒ–ï¼Œåœ¨å¤šä¸ªçœŸå®æ•°æ®é›†ä¸Šä¸ä»…å¤§å¹…è¶…è¶Šä¼ ç»Ÿ RNN æ–¹æ³•ï¼Œç”šè‡³è¶…è¿‡äº†å…ˆè¿›çš„ Transformer æ¨¡å‹ï¼Œé‡æ–°ç¡®ç«‹äº† RNN åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„ç«äº‰åŠ›ã€‚

</details>

---

### 10. [EDCO: Dynamic Curriculum Orchestration for Domain-specific Large Language Model Fine-tuning](https://arxiv.org/abs/2601.03725)

**Authors**: Jing-Cheng Pang, Liu Sun, Chang Zhou, Xian Tang, Haichuan Ma, Kun Jiang, Jianlong Wang, Kai Zhang, Sijie Wu, Haoran Cai, Chenwei Wu, Xubin Li, Xin Chen  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.03725v1  

#### Abstract
Domain-specific large language models (LLMs), typically developed by fine-tuning a pre-trained general-purpose LLM on specialized datasets, represent a significant advancement in applied AI. A common strategy in LLM fine-tuning is curriculum learning, which pre-orders training samples based on metri...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# EDCO: Dynamic Curriculum Orchestration for Domain-specific Large Language Model Fine-tuning â€”â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
- **é™æ€è¯¾ç¨‹å­¦ä¹ ï¼ˆStatic Curriculum Learningï¼‰çš„å±€é™æ€§**ï¼šä¼ ç»Ÿ LLM å¾®è°ƒé€šå¸¸é‡‡ç”¨éšæœºé‡‡æ ·æˆ–åŸºäºå¯å‘å¼éš¾åº¦æ’åºï¼ˆå¦‚é•¿åº¦ã€ç­”æ¡ˆå¤æ‚åº¦ã€å›°æƒ‘åº¦ PPLï¼‰çš„å›ºå®šè®­ç»ƒé¡ºåºï¼Œæ— æ³•é€‚åº”æ¨¡å‹åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­èƒ½åŠ›çš„åŠ¨æ€å˜åŒ–ã€‚
- **ç†µåå¡Œï¼ˆEntropy Collapseï¼‰é—®é¢˜**ï¼šå°¤å…¶åœ¨å¼ºåŒ–å­¦ä¹ å¾®è°ƒï¼ˆRLFTï¼‰ä¸­ï¼Œæ¨¡å‹æ¨ç†ç†µè¿…é€Ÿä¸‹é™ï¼Œå¯¼è‡´è¿‡æ—©æ”¶æ•›ã€æ¢ç´¢ä¸è¶³ï¼Œé™åˆ¶äº†é•¿æœŸæ€§èƒ½æå‡ã€‚
- **é¢†åŸŸæ•°æ®ç¨€ç¼ºä¸”æ˜‚è´µ**ï¼šé«˜è´¨é‡é¢†åŸŸæ•°æ®æœ‰é™ï¼Œå› æ­¤éœ€è¦æœ€å¤§åŒ–æ¯ä¸€æ­¥è®­ç»ƒçš„æœ‰æ•ˆæ€§ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šEDCOï¼ˆEntropy-based Dynamic Curriculum Orchestrationï¼‰
EDCO æ˜¯ä¸€ç§åŸºäº**æ¨ç†ç†µï¼ˆinference entropyï¼‰**çš„åŠ¨æ€è¯¾ç¨‹ç¼–æ’æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- **æŒç»­è¯†åˆ«æœ€å…·æŒ‘æˆ˜æ€§çš„æ ·æœ¬**ï¼šé€šè¿‡ä¼°è®¡æ¯ä¸ªæ ·æœ¬çš„æ¨ç†ç†µï¼Œä¼˜å…ˆé€‰æ‹©ä½¿æ¨¡å‹æœ€ä¸ç¡®å®šçš„æ ·æœ¬è¿›è¡Œè®­ç»ƒã€‚
- **æ„å»ºâ€œåå‘è¯¾ç¨‹â€ï¼ˆReverse Curriculumï¼‰**ï¼šä¸åŒäºä¼ ç»Ÿçš„â€œç”±æ˜“åˆ°éš¾â€ï¼ŒEDCO ä¸»å¼ ä»é«˜ç†µï¼ˆéš¾ï¼‰æ ·æœ¬å¼€å§‹å¹¶åŠ¨æ€è°ƒæ•´ï¼Œç¡®ä¿æ¨¡å‹å§‹ç»ˆå¤„äºå­¦ä¹ å‰æ²¿ã€‚

#### ä¸‰å¤§æ ¸å¿ƒæŠ€æœ¯ç»„ä»¶ï¼š
1. **é«˜æ•ˆç†µä¼°è®¡æ¨¡å—ï¼ˆEfficient Entropy Estimatorï¼‰**
   - å¼•å…¥ **Quick-Answer Prompting (QAP)**ï¼šå¼•å¯¼æ¨¡å‹å¿«é€Ÿè¾“å‡ºç­”æ¡ˆè€Œéé•¿é“¾æ¨ç†ï¼Œä½¿å‰ç¼€ token æ›´èƒ½åæ˜ è¯­ä¹‰ä¸ç¡®å®šæ€§ã€‚
   - æå‡º **Prefix Entropy Approximation**ï¼šä»…ç”¨è¾“å‡ºåºåˆ—å‰ $L$ ä¸ª tokenï¼ˆå¦‚ 50â€“128ï¼‰ä¼°ç®—å…¨åºåˆ—ç†µï¼Œæ˜¾è‘—é™ä½è®¡ç®—å¼€é”€ã€‚

2. **ç†µé©±åŠ¨çš„åŠ¨æ€è¯¾ç¨‹ç”Ÿæˆå™¨ï¼ˆEntropy-based Curriculum Generatorï¼‰**
   - åœ¨æ¯ä¸ªè®­ç»ƒé˜¶æ®µé‡æ–°è¯„ä¼°æ‰€æœ‰æœªå……åˆ†æŒæ¡æ ·æœ¬çš„æ¨ç†ç†µã€‚
   - åŠ¨æ€é€‰å–ç†µå€¼æœ€é«˜çš„ Top-$N$ æ ·æœ¬ç»„æˆä¸‹ä¸€é˜¶æ®µè®­ç»ƒé›†ã€‚

3. **å…¼å®¹å¤šç§å¾®è°ƒèŒƒå¼çš„ LLM è®­ç»ƒå™¨**
   - æ”¯æŒ Supervised Fine-Tuning (SFT) å’Œ Reinforcement Learning Fine-Tuning (RLFT)ï¼Œå‡å¯å—ç›Šäºé«˜ç†µæ ·æœ¬å¸¦æ¥çš„æŒç»­æ¢ç´¢ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| å¯¹æ¯”ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ RS, Length, AC, PPLï¼‰ | EDCO |
|--------|-------------------------------|------|
| è¯¾ç¨‹ç­–ç•¥ | é™æ€é¢„è®¾ï¼Œä¸å¯å˜ | åŠ¨æ€æ›´æ–°ï¼Œéšæ¨¡å‹çŠ¶æ€æ¼”åŒ– |
| æ ·æœ¬é€‰æ‹©ä¾æ® | å¯å‘å¼æŒ‡æ ‡ï¼ˆé•¿åº¦ã€ç­”æ¡ˆå¥æ•°ã€PPLï¼‰ | æ¨¡å‹å®æ—¶æ¨ç†ç†µï¼ˆæ›´è´´è¿‘å­¦ä¹ éœ€æ±‚ï¼‰ |
| æ¢ç´¢ç»´æŒèƒ½åŠ› | æ˜“å‘ç”Ÿç†µåå¡Œï¼Œå°¤å…¶åœ¨ RLFT ä¸­ | ä¸»åŠ¨ç»´æŒé«˜ç†µç¯å¢ƒï¼Œå»¶ç¼“åå¡Œ |
| é€šç”¨æ€§ | å¤šä¸ºä»»åŠ¡ç‰¹å®šè®¾è®¡ | è·¨é¢†åŸŸã€è·¨æ¨¡å‹ï¼ˆQwen/Llamaï¼‰ã€è·¨èŒƒå¼ï¼ˆSFT/RLFTï¼‰æœ‰æ•ˆ |
| æ•ˆç‡ | æ— é¢å¤–å¼€é”€ | å¼•å…¥å¯æ¥å—çš„è®¡ç®—å¼€é”€ï¼ˆ+10% wall-clockï¼‰ï¼Œä½†å¸¦æ¥æ˜¾è‘—æ€§èƒ½å¢ç›Š |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–å››ä¸ªä¸“ä¸šé¢†åŸŸï¼ŒéªŒè¯æ³›åŒ–èƒ½åŠ›ï¼š

| æ•°æ®é›† | é¢†åŸŸ | æè¿° |
|-------|------|------|
| **Wireless Communication** | æ— çº¿é€šä¿¡ | è‡ªå»ºæ•°æ®é›†ï¼Œ12K QA å¯¹ï¼Œæ¥è‡ªäº§å“æ–‡æ¡£å’ŒæŠ€æœ¯æ–¹æ¡ˆï¼Œæ¶µç›– 5G/Wi-Fi/GTP åè®®ç­‰ |
| **Datacom** | æ•°æ®é€šä¿¡ | è‡ªå»ºæ•°æ®é›†ï¼Œ12K QA å¯¹ï¼Œæ¶‰åŠè·¯ç”±å™¨ã€äº¤æ¢æœºã€Segment VXLANã€BGP EVPN ç­‰ç½‘ç»œæŠ€æœ¯ |
| **MedQA (Jin et al., 2021)** | åŒ»å­¦ | æ¥è‡ªç¾å›½åŒ»å¸ˆæ‰§ç…§è€ƒè¯•çš„å¤šé€‰é¢˜ï¼Œå«ä¸´åºŠæ¡ˆä¾‹æè¿°ï¼Œæµ‹è¯•åŒ»å­¦çŸ¥è¯†ä¸å¤šè·³æ¨ç† |
| **JEC-QA (Zhong et al., 2020)** | æ³•å¾‹ | ä¸­å›½å¸æ³•è€ƒè¯•é¢˜åº“ï¼ŒåŒ…å«å•é€‰ä¸å¤šé€‰é¢˜ï¼Œéœ€æ³•å¾‹æ¡æ–‡ç†è§£ä¸æ¡ˆä¾‹åˆ†æ |

> æ‰€æœ‰ä»»åŠ¡å‡ä¿ç•™ 230 é“é«˜éš¾åº¦é¢˜ç›®ä½œä¸ºæµ‹è¯•é›†ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼š
  - Qwen3-4B
  - Llama3.2-3B
- **å¾®è°ƒæ–¹å¼**ï¼š
  - **SFT**ï¼šæœ€å°åŒ–äº¤å‰ç†µæŸå¤±
  - **RLFT**ï¼šä½¿ç”¨ GRPO ç®—æ³•ä¼˜åŒ–å¥–åŠ±ä¿¡å·ï¼ˆDeepseek-V3 è‡ªåŠ¨ç”ŸæˆéªŒè¯ / è§„åˆ™-based å¥–åŠ±ï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Answer Accuracy**ï¼šæœ€ç»ˆç­”æ¡ˆåŒ¹é…æ­£ç¡®ç‡ï¼ˆä¸»è¦æŒ‡æ ‡ï¼‰
  - **Inference Entropy**ï¼šç”¨äºåˆ†æè®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¢ç´¢è¡Œä¸º
  - **Wall-clock Time / Per-sample Estimation Time**ï¼šè¡¡é‡æ•ˆç‡

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | æ–¹æ³• | è¯´æ˜ |
|-----|------|------|
| **æ— è¯¾ç¨‹** | Random Sampling (RS) | æ ‡å‡†éšæœºé‡‡æ · |
| **é™æ€è¯¾ç¨‹** | Length, AC, PPL | åˆ†åˆ«æŒ‰è¾“å…¥é•¿åº¦ã€ç­”æ¡ˆå¥å­æ•°ã€åˆå§‹æ¨¡å‹å›°æƒ‘åº¦æ’åº |
| **åŠ¨æ€è¯¾ç¨‹** | SEC, Dynamic-PPL | SEC ä½¿ç”¨ bandit å­¦ä¹ ç­–ç•¥ï¼›Dynamic-PPL å®šæœŸæ›´æ–° PPL æ’åº |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### ï¼ˆ1ï¼‰é€šä¿¡é¢†åŸŸï¼ˆQwen3-4Bï¼‰â€”â€” RLFT è®¾ç½®ä¸‹è¡¨ç°

| æ–¹æ³• | Wireless Acc (%) | Datacom Acc (%) |
|------|------------------|-----------------|
| No Training | 35.22 | 40.00 |
| RS | 34.35 | 40.43 |
| PPL | 33.91 | 44.78 |
| **EDCO** | **38.70** | **46.96** |

> âœ… EDCO åœ¨ä¸¤ä¸ªé¢†åŸŸå‡å–å¾—æœ€é«˜ç²¾åº¦ï¼Œåœ¨ Datacom ä¸Šæ¯”æœ€å¼ºé™æ€åŸºçº¿ï¼ˆPPLï¼‰æå‡ **+2.18%**

#### ï¼ˆ2ï¼‰é€šä¿¡é¢†åŸŸï¼ˆQwen3-4Bï¼‰â€”â€” SFT è®¾ç½®ä¸‹è¡¨ç°

| æ–¹æ³• | Wireless Acc (%) | Datacom Acc (%) |
|------|------------------|-----------------|
| RS | 31.7 | 33.0 |
| PPL | 32.0 | 33.0 |
| **EDCO** | **33.7** | **36.3** |

> âœ… åœ¨ SFT ä¸‹ä»æ˜¾è‘—ä¼˜äºå„ç±»åŸºçº¿ï¼Œå°¤å…¶é¿å…äº†æŸäº›é™æ€è¯¾ç¨‹ï¼ˆå¦‚ ACï¼‰å¯¼è‡´æ€§èƒ½é€€åŒ–çš„é—®é¢˜

#### ï¼ˆ3ï¼‰è·¨é¢†åŸŸè¿ç§»æ•ˆæœï¼ˆLlama3.2-3Bï¼‰

| Dataset | RS | PPL | EDCO |
|--------|----|-----|-------|
| MedQA | 32.9 | 24.6 | **36.7** |
| JEC-QA | 16.2 | 12.4 | **17.4** |

> âœ… EDCO åœ¨åŒ»å­¦ä¸æ³•å¾‹é¢†åŸŸä¹Ÿå…¨é¢è¶…è¶ŠåŸºçº¿ï¼Œè¯æ˜å…¶**è·¨é¢†åŸŸæ™®é€‚æ€§**

#### ï¼ˆ4ï¼‰ä¸å…ˆè¿›åŠ¨æ€åŸºçº¿æ¯”è¾ƒï¼ˆDatacom + Qwen3-4Bï¼‰

| æ–¹æ³• | Accuracy (%) |
|------|--------------|
| RS | 40.43 |
| SEC (bandit-based) | 34.78 |
| Dynamic-PPL | 41.30 |
| **EDCO** | **47.00** |

> âœ… EDCO æ˜¾è‘—ä¼˜äºä¸¤ç§åŠ¨æ€è¯¾ç¨‹æ–¹æ³•ï¼Œè¡¨æ˜â€œåŸºäºæ¨ç†ç†µâ€çš„é€‰æ‹©æœºåˆ¶ä¼˜äºâ€œåŸºäº bandit å†³ç­–â€æˆ–â€œå®šæœŸæ›´æ–° PPLâ€

---

### ğŸ” æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰ç†µä¼°è®¡å‡†ç¡®æ€§ï¼ˆPrefix vs Full-sequenceï¼‰
- ä½¿ç”¨ 128-token å‰ç¼€ä¼°ç®—çš„ç†µä¸å®Œæ•´åºåˆ—ç†µä¹‹é—´çš„ **Pearson ç›¸å…³ç³»æ•°è¾¾ 0.63**
- è¡¨æ˜å‰ç¼€ç†µå¯ä½œä¸ºå¯é ä»£ç†ä¿¡å·

#### ï¼ˆ2ï¼‰è®¡ç®—æ•ˆç‡æå‡
| æ–¹æ³• | å•è¿›ç¨‹è€—æ—¶ (ç§’/æ ·æœ¬) | å¹¶è¡Œï¼ˆ8 NPUï¼‰è€—æ—¶ |
|------|--------------------|------------------|
| Full-sequence | 2.24 | 0.24 |
| **Prefix-based (Ours)** | **0.37** | **0.04** |

> â±ï¸ **è®¡ç®—æ—¶é—´å‡å°‘ 83.5%**ï¼Œä½¿å¾—åŠ¨æ€è¯¾ç¨‹æˆä¸ºå®ç”¨å¯è¡Œçš„æŠ€æœ¯

#### ï¼ˆ3ï¼‰å‰ç¼€é•¿åº¦å½±å“ï¼ˆAblation on $L$ï¼‰
- å½“ prefix length â‰¥ 50 æ—¶ï¼Œç†µè¶‹åŠ¿è¶‹äºç¨³å®š
- æ¨èé»˜è®¤é…ç½®ï¼š**50â€“128 tokens**

#### ï¼ˆ4ï¼‰Quick-Answer Prompting (QAP) çš„ä½œç”¨
- ç§»é™¤ QAP åï¼Œprefix ä¸ full-sequence ç†µçš„ç›¸å…³æ€§ä» **0.63 é™è‡³ 0.32**
- è¯æ˜ QAP å¯¹æå‡ç†µä¼°è®¡è´¨é‡è‡³å…³é‡è¦

#### ï¼ˆ5ï¼‰æ˜¯å¦åº”é¿å…æœ€é«˜ç†µæ ·æœ¬ï¼Ÿï¼ˆModerate-entropy Window å®éªŒï¼‰
- å°è¯•é€‰æ‹©ä¸­ç­‰ç†µåŒºé—´ï¼ˆTop 5â€“11.67%ï¼‰è€Œéæœ€é«˜ç†µï¼ˆTop 0â€“6.67%ï¼‰
- ç»“æœæ˜¾ç¤ºï¼š**æœ€é«˜ç†µç­–ç•¥å¾—åˆ†æ›´é«˜ï¼ˆ46.96 vs 44.78ï¼‰**
- ç»“è®ºï¼šé«˜ç†µæ ·æœ¬å¹¶éå™ªå£°æˆ– OOD é”™è¯¯ï¼Œè€Œæ˜¯çœŸæ­£å…·æœ‰ä¿¡æ¯é‡çš„å­¦ä¹ éš¾ç‚¹

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **æ¨ç†ç†µæ˜¯æœ‰æ•ˆçš„è¯¾ç¨‹ä¿¡å·**ï¼š
   - ç»´æŒé«˜æ¨ç†ç†µæœ‰åŠ©äºé˜²æ­¢æ¨¡å‹è¿‡æ—©æ”¶æ•›ï¼Œä¿ƒè¿›æŒç»­æ¢ç´¢ï¼Œå°¤å…¶æ˜¯åœ¨ RLFT åœºæ™¯ä¸­ã€‚
2. **åŠ¨æ€è¯¾ç¨‹ä¼˜äºé™æ€è¯¾ç¨‹**ï¼š
   - å›ºå®šé¡ºåºï¼ˆå¦‚ easy-to-hardï¼‰å¯èƒ½é€‚å¾—å…¶åï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸“ä¸šé¢†åŸŸä¸­ï¼Œâ€œçŸ­â€ä¸ç­‰äºâ€œç®€å•â€ã€‚
3. **EDCO å…·å¤‡å¼ºæ³›åŒ–èƒ½åŠ›**ï¼š
   - åœ¨é€šä¿¡ã€åŒ»å­¦ã€æ³•å¾‹ç­‰å¤šä¸ªé¢†åŸŸï¼Œä»¥åŠ Qwen å’Œ Llama ä¸åŒæ¶æ„ä¸Šå‡ä¸€è‡´æœ‰æ•ˆã€‚
4. **é«˜æ•ˆç†µä¼°ç®—æ˜¯å¯è¡Œçš„**ï¼š
   - ç»“åˆ QAP ä¸ prefix approximation å¯å®ç°é«˜ç²¾åº¦ã€ä½å»¶è¿Ÿçš„åœ¨çº¿ç†µä¼°è®¡ï¼Œæ”¯æŒè¿‘å®æ—¶è¯¾ç¨‹æ›´æ–°ã€‚

### âš ï¸ å±€é™æ€§
1. **å‘¨æœŸæ€§è®¡ç®—å¼€é”€ä»å­˜åœ¨**ï¼š
   - å°½ç®¡å·²å¤§å¹…ä¼˜åŒ–ï¼Œä½†ä»å¼•å…¥çº¦ 10% çš„ wall-clock æ—¶é—´å¢é•¿ï¼Œå¯¹è¶…å¤§è§„æ¨¡æ•°æ®é›†å¯èƒ½æ„æˆè´Ÿæ‹…ã€‚
2. **å›ºå®šæ›´æ–°é—´éš”ä¸å¤Ÿæ™ºèƒ½**ï¼š
   - å½“å‰é‡‡ç”¨å›ºå®šè®­ç»ƒæ­¥æ•°è§¦å‘è¯¾ç¨‹æ›´æ–°ï¼Œæœªæ¥å¯è€ƒè™‘åŸºäºç†µå˜åŒ–ç‡æˆ–æ€§èƒ½å¹³å°æœŸè‡ªé€‚åº”è°ƒåº¦ã€‚
3. **ä¾èµ–é«˜è´¨é‡é¢„å¤„ç†æ•°æ®**ï¼š
   - æ–¹æ³•å‡è®¾æ•°æ®å·²æ¸…æ´—ï¼Œè‹¥å­˜åœ¨å¤§é‡æ­§ä¹‰æˆ–é”™è¯¯æ ·æœ¬ï¼Œé«˜ç†µå¯èƒ½åæ˜ çš„æ˜¯å™ªéŸ³è€ŒéæŒ‘æˆ˜ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **è½»é‡åŒ–ç†µé¢„æµ‹æœºåˆ¶**ï¼š
   - è®¾è®¡æ— éœ€å®Œæ•´å‰å‘ä¼ æ’­å³å¯é¢„æµ‹æ ·æœ¬ç†µçš„å°å‹è¾…åŠ©ç½‘ç»œæˆ–å…ƒå­¦ä¹ å™¨ã€‚
2. **è‡ªé€‚åº”è¯¾ç¨‹è°ƒåº¦å™¨**ï¼š
   - å¼•å…¥ç›‘æ§æœºåˆ¶ï¼Œåœ¨æ£€æµ‹åˆ°ç†µéª¤é™æˆ–æ€§èƒ½åœæ»æ—¶è‡ªåŠ¨è§¦å‘è¯¾ç¨‹é‡ç»„ã€‚
3. **æ‰©å±•è‡³æ›´å¤šé¢†åŸŸä¸ä½èµ„æºè¯­è¨€**ï¼š
   - éªŒè¯ EDCO åœ¨ç§‘å­¦ã€é‡‘èã€å°è¯­ç§ç­‰åœºæ™¯ä¸‹çš„æœ‰æ•ˆæ€§ã€‚
4. **ç»“åˆä¸»åŠ¨å­¦ä¹ ï¼ˆActive Learningï¼‰**ï¼š
   - å°† EDCO ä¸æ•°æ®æ ‡æ³¨æµç¨‹æ•´åˆï¼Œå½¢æˆé—­ç¯çš„â€œå­¦ä¹ -é€‰æ‹©-æ ‡æ³¨â€ç³»ç»Ÿã€‚

---

## æ€»ç»“

ğŸ“Œ **EDCO æå‡ºäº†ä¸€ç§å…¨æ–°çš„è§†è§’ï¼šå°†â€œæœ€éš¾çš„æ ·æœ¬â€è§†ä¸ºæœ€æœ‰ä»·å€¼çš„å­¦ä¹ ææ–™ï¼Œå¹¶é€šè¿‡åŠ¨æ€è¯¾ç¨‹æœºåˆ¶è®©æ¨¡å‹å§‹ç»ˆä¿æŒåœ¨è®¤çŸ¥è¾¹ç¼˜ã€‚**

å®ƒä¸ä»…è§£å†³äº†ä¼ ç»Ÿè¯¾ç¨‹å­¦ä¹ åƒµåŒ–çš„é—®é¢˜ï¼Œè¿˜ä¸ºç¼“è§£ RLFT ä¸­çš„ç†µåå¡Œæä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚å…¶å®éªŒå……åˆ†ã€è®¾è®¡ä¸¥è°¨ï¼Œåœ¨å¤šä¸ªçœŸå®é¢†åŸŸä»»åŠ¡ä¸­å±•ç°å‡ºç¨³å®šä¸”æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œæ˜¯ä¸€é¡¹å…¼å…·ç†è®ºæ·±åº¦ä¸å·¥ç¨‹å®ç”¨æ€§çš„åˆ›æ–°å·¥ä½œã€‚

</details>

---

### 11. [Quantum vs. Classical Machine Learning: A Benchmark Study for Financial Prediction](https://arxiv.org/abs/2601.03802)

**Authors**: Rehan Ahmad, Muhammad Kashif, Nouhaila Innan, Muhammad Shafique  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.03802v1  

#### Abstract
In this paper, we present a reproducible benchmarking framework that systematically compares QML models with architecture-matched classical counterparts across three financial tasks: (i) directional return prediction on U.S. and Turkish equities, (ii) live-trading simulation with Quantum LSTMs versu...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# ã€ŠQuantum vs. Classical Machine Learning: A Benchmark Study for Financial Predictionã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰é‡å­æœºå™¨å­¦ä¹ ï¼ˆQMLï¼‰åœ¨é‡‘èé¢„æµ‹é¢†åŸŸçš„ç ”ç©¶å­˜åœ¨ä»¥ä¸‹å…³é”®é—®é¢˜ï¼š
- **ç‰¹å¾è¡¨è¾¾ä¸è¶³**ï¼šå¤šæ•°QMLç ”ç©¶ä»…ä½¿ç”¨ç®€å•æˆ–å•ä¸€è‚¡ç¥¨çš„å†å²ä»·æ ¼ï¼Œç¼ºä¹æŠ€æœ¯æŒ‡æ ‡ã€è·¨èµ„äº§ä¿¡å·ç­‰ä¸°å¯Œç‰¹å¾ã€‚
- **åŸºçº¿ä¸åŒ¹é…**ï¼šå¸¸å°†æµ…å±‚QNNä¸æ·±å±‚LSTMç­‰ç»“æ„å·®å¼‚å·¨å¤§çš„ç»å…¸æ¨¡å‹å¯¹æ¯”ï¼Œå¯¼è‡´ä¸å…¬å¹³æ¯”è¾ƒã€‚
- **è¯„ä¼°æŒ‡æ ‡ä¸è´´åˆå®é™…**ï¼šå¤šä¾èµ–RMSEã€MAEç­‰ç»Ÿè®¡è¯¯å·®æŒ‡æ ‡ï¼Œè€Œéäº¤æ˜“ç›¸å…³çš„é£é™©è°ƒæ•´æ”¶ç›Šï¼ˆå¦‚Sharpe Ratioï¼‰æˆ–æ³¢åŠ¨ç‡ä¸“ç”¨æŒ‡æ ‡ï¼ˆå¦‚QLIKEï¼‰ã€‚
- **ä»»åŠ¡è¦†ç›–ä¸å…¨**ï¼šç¼ºä¹å¯¹æ–¹å‘æ€§åˆ†ç±»ã€å®æ—¶äº¤æ˜“æ¨¡æ‹Ÿã€æ³¢åŠ¨ç‡é¢„æµ‹ç­‰æ ¸å¿ƒé‡‘èä»»åŠ¡çš„ç³»ç»Ÿæ€§åŸºå‡†æµ‹è¯•ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºä¸€ä¸ª**å¯å¤ç°ã€æ ‡å‡†åŒ–çš„åŸºå‡†æ¡†æ¶**ï¼ˆreproducible benchmarking frameworkï¼‰ï¼Œç”¨äºå…¬å¹³ã€ç³»ç»Ÿåœ°æ¯”è¾ƒQMLä¸ç»å…¸MLåœ¨é‡‘èé¢„æµ‹ä¸­çš„è¡¨ç°ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **æ¶æ„åŒ¹é…å¯¹æ¯”**ï¼ˆArchitecture-matched comparisonï¼‰  
  å¯¹æ¯ç±»QMLæ¨¡å‹ï¼ˆQNN, QLSTM, QSVRï¼‰å‡è®¾è®¡å‚æ•°é‡ã€å½’çº³åç½®ç›¸è¿‘çš„ç»å…¸å¯¹åº”æ¨¡å‹ï¼ˆANN, LSTM, SVRï¼‰ï¼Œç¡®ä¿æ¯”è¾ƒèšç„¦äºâ€œé‡å­ vs ç»å…¸â€è€Œéâ€œç»“æ„å·®å¼‚â€ã€‚

- **ç»Ÿä¸€çš„ä»»åŠ¡è®¾è®¡ä¸è¯„ä¼°ä½“ç³»**  
  è¦†ç›–ä¸‰å¤§æ ¸å¿ƒé‡‘èä»»åŠ¡ï¼š
  - **Directional Return Prediction**ï¼ˆæ–¹å‘æ€§å›æŠ¥é¢„æµ‹ï¼‰
  - **Live Trading Simulation**ï¼ˆå®ç›˜äº¤æ˜“æ¨¡æ‹Ÿï¼‰
  - **Realized Volatility Forecasting**ï¼ˆå·²å®ç°æ³¢åŠ¨ç‡é¢„æµ‹ï¼‰

- **çœŸå®é‡‘èä»·å€¼å¯¼å‘çš„è¯„ä¼°**  
  å¼•å…¥äº¤æ˜“æˆæœ¬ã€é£é™©è°ƒæ•´æ”¶ç›Šï¼ˆSharpe/Sortinoï¼‰ã€æœ€å¤§å›æ’¤ï¼ˆMaxDDï¼‰ç­‰ç»æµæŒ‡æ ‡ï¼Œè¯„ä¼°æ¨¡å‹çš„å®é™…ç›ˆåˆ©èƒ½åŠ›ï¼Œè€Œä¸ä»…æ˜¯é¢„æµ‹å‡†ç¡®ç‡ã€‚

- **å¤šå¸‚åœºã€å¤šç»´åº¦ç‰¹å¾æµ‹è¯•**  
  åœ¨ç¾å›½ï¼ˆæˆç†Ÿå¸‚åœºï¼‰å’ŒåœŸè€³å…¶ï¼ˆæ–°å…´å¸‚åœºï¼‰è‚¡ç¥¨ä¸Šè¿›è¡Œå®éªŒï¼Œæ¶µç›–ä½ç»´ï¼ˆ3-Dï¼‰ã€ä¸­ç»´ï¼ˆ7-Dï¼‰ã€é«˜ç»´ï¼ˆ64-Dï¼‰ä¸‰ç§ç‰¹å¾ç©ºé—´ï¼Œæ£€éªŒæ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´å…¬å¹³**ï¼šé€šè¿‡å‚æ•°åŒ¹é…ã€ç›¸åŒæ•°æ®åˆ’åˆ†ã€ç»Ÿä¸€è¯„ä¼°åè®®ï¼Œé¿å…äº†ä»¥å¾€ç ”ç©¶ä¸­çš„åå·®ã€‚
- **æ›´å…¨é¢**ï¼šé¦–æ¬¡åœ¨åŒä¸€æ¡†æ¶ä¸‹ç³»ç»Ÿè¯„ä¼°QMLåœ¨ä¸‰å¤§é‡‘èä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚
- **æ›´å…·å®è·µæ„ä¹‰**ï¼šä»â€œé¢„æµ‹ç²¾åº¦â€è½¬å‘â€œç»æµä»·å€¼â€ï¼Œè´´è¿‘çœŸå®æŠ•èµ„å†³ç­–æµç¨‹ã€‚
- **å¯å¤ç°æ€§å¼º**ï¼šå¼€æºä»£ç ä¸è¯¦ç»†è¶…å‚æœç´¢ç©ºé—´ï¼Œä¾¿äºåç»­ç ”ç©¶å¤ç°ä¸æ‰©å±•ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
| ä»»åŠ¡ | æ•°æ®æ¥æº | å…·ä½“èµ„äº§ |
|------|----------|---------|
| **Directional Classification** | Yahoo Finance API | - **ç¾å›½å¸‚åœº**ï¼šS&P 500ã€AAPLã€BAã€GILDã€DVNã€LNC<br>- **åœŸè€³å…¶å¸‚åœº**ï¼šKCHOL.ISã€GARAN.ISã€TUPRS.ISã€ULKER.ISã€TCELL.IS |
| **Live Trading Simulation** | Yahoo Finance API | S&P 500æŒ‡æ•°ï¼ˆ2008â€“2024ï¼‰ï¼Œåˆ’åˆ†ä¸ºå››ä¸ªå†å²é˜¶æ®µï¼š<br>- F1: å…¨çƒé‡‘èå±æœº (2008â€“2009)<br>- F2: ç–«æƒ…å‰ (2018â€“2019)<br>- F3: ç–«æƒ…å†²å‡»ä¸å¤è‹ (2020â€“2021)<br>- F4: åç–«æƒ…æ—¶ä»£ (2022â€“2024) |
| **Volatility Forecasting** | Yahoo Finance API | S&P 500ã€AAPLã€KCHOLã€GARAN |

### ç‰¹å¾å·¥ç¨‹
- **æ–¹å‘æ€§åˆ†ç±»**ï¼š
  - ä½ç»´ï¼ˆ3-Dï¼‰ï¼šRSIã€Stochastic Oscillatorç­‰æŠ€æœ¯æŒ‡æ ‡ï¼ˆåœŸè€³å…¶è‚¡ï¼‰
  - ä¸­ç»´ï¼ˆ7-Dï¼‰ï¼šå…­å¤§å…¨çƒè‚¡æŒ‡æ»åæ”¶ç›Šï¼ˆé¢„æµ‹S&P 500æ–¹å‘ï¼‰
  - é«˜ç»´ï¼ˆ64-Dï¼‰ï¼šä¸ªè‚¡è¿‡å»8æ—¥æ”¶ç›Š + 8å¤§æŒ‡æ•°è¿‡å»7æ—¥æ”¶ç›Š
- **å®æ—¶äº¤æ˜“**ï¼šMACDã€RSIã€å‰ä¸€æ—¥æ”¶ç›Šç‡ç­‰4ç»´æ—¶åºç‰¹å¾ï¼Œæ„å»º10å¤©æ»‘åŠ¨çª—å£ã€‚
- **æ³¢åŠ¨ç‡é¢„æµ‹**ï¼šè¿‡å»pæ—¥æ”¶ç›Šç‡ + è¿‡å»qæ—¥å·²å®ç°æ–¹å·®ï¼Œç›®æ ‡ä¸ºæœªæ¥5æ—¥å·²å®ç°æ–¹å·®ï¼ˆ5-day realized varianceï¼‰ã€‚

### è¯„ä¼°æŒ‡æ ‡
| ä»»åŠ¡ | ä¸»è¦è¯„ä¼°æŒ‡æ ‡ |
|------|-------------|
| **Directional Classification** | Accuracy, AUC, Precision, Recall |
| **Live Trading Simulation** | Annualized Return (ARC), Annualized Standard Deviation (ASD), Sharpe Ratio, Sortino Ratio, Max Drawdown |
| **Volatility Forecasting** | QLIKEï¼ˆä¸»æŒ‡æ ‡ï¼‰ã€MSEã€RÂ²ã€Directional Accuracy (DirAcc)ã€Diebold-Mariano Test (DM-p) |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| QMLæ¨¡å‹ | ç»å…¸åŸºçº¿æ¨¡å‹ | åŒ¹é…åŸåˆ™ |
|--------|------------|---------|
| QNN | ANN | å‚æ•°é‡ç›¸è¿‘ï¼Œç»“æ„å¯¹é½ï¼ˆå¦‚Hybrid-SQ QNN vs æµ…å±‚ANNï¼‰ |
| QLSTM | LSTM | éšè—çŠ¶æ€å¤§å°ã€å±‚æ•°ã€æ€»å‚æ•°é‡åŒ¹é… |
| QSVR | SVR (Linear, Poly, RBF) + GARCH(1,1) | ä½¿ç”¨é¢„è®¡ç®—æ ¸çŸ©é˜µï¼Œä¿æŒä¼˜åŒ–æµç¨‹ä¸€è‡´ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### (1) Directional Return Prediction
| èµ„äº§ | æ¨¡å‹ | Accuracy â†‘ | AUC â†‘ | ç›¸å¯¹æå‡ |
|------|------|-----------|-------|---------|
| **AAPL** | QNN (Hybrid-SQ) | **0.606** | **0.635** | +3.4pp Acc, +3.8 AUC vs ANN |
| **KCHOL** | QNN (Hybrid-MQ) | **0.7106** | **0.7968** | +4.9 AUC, +3.6pp Acc vs ANN |
| **S&P 500** | ANN | 0.7289 | 0.7657 | ç•¥ä¼˜äºQNNï¼ˆHybrid-SQ: 0.7221, 0.7498ï¼‰ |

> âœ… **å…³é”®å‘ç°**ï¼šåœ¨é«˜ç»´ç‰¹å¾ä¸‹ï¼ˆå¦‚AAPLï¼‰ï¼ŒQNNæ˜¾è‘—è¶…è¶Šå‚æ•°åŒ¹é…çš„ANNï¼›åœ¨ä¸­ç»´ç‰¹å¾ï¼ˆS&P 500è·¨èµ„äº§è¾“å…¥ï¼‰ä¸­ï¼ŒANNä»ç•¥ä¼˜ï¼Œä½†QNNå¬å›ç‡æ›´é«˜ã€‚

### (2) Live Trading Simulation (S&P 500)
| å¸‚åœºé˜¶æ®µ | æ¨¡å‹ | Sharpe Ratio â†‘ | Annualized Return â†‘ | ç»“æœå¯¹æ¯” |
|--------|------|----------------|---------------------|----------|
| **F1: é‡‘èå±æœº (2008â€“2009)** | QLSTM | **0.3865** | **+5.96%** | æ˜¾è‘—ä¼˜äºLSTM (-1.67%, SR=-0.0477) |
| **F2: ç–«æƒ…å‰ (2018â€“2019)** | QLSTM | **1.2585** | **+11.03%** | å¤§å¹…ä¼˜äºLSTM (SR=0.4966, ARC=7.45%) |
| **F3: ç–«æƒ…æœŸ (2020â€“2021)** | LSTM | 0.8947 | 21.02% | QLSTM SRæ›´ä½ï¼ˆ0.7659ï¼‰ï¼Œä½†Sortinoæ›´é«˜ |
| **F4: åç–«æƒ… (2022â€“2024)** | LSTM | **1.5228** | **35.16%** | QLSTMä¸¥é‡å¤±æ•ˆï¼ˆARC=-15.15%, SR=-0.6936ï¼‰ |

> âœ… **å…³é”®å‘ç°**ï¼šQLSTMåœ¨ä¸¤ä¸ªé«˜æ³¢åŠ¨æ—¶æœŸï¼ˆF1ã€F2ï¼‰è¡¨ç°å‡ºæ›´å¼ºçš„é£é™©è°ƒæ•´æ”¶ç›Šï¼Œä½†åœ¨F4é˜¶æ®µå› é˜ˆå€¼æ ¡å‡†å¤±è´¥è€Œå´©æºƒï¼Œæ˜¾ç¤ºå…¶å¯¹å¸‚åœºçŠ¶æ€æ•æ„Ÿã€‚

### (3) Volatility Forecasting
| èµ„äº§ | æœ€ä½³æ¨¡å‹ | QLIKE â†“ | vs RBF SVR | vs Linear/Poly SVR |
|------|---------|--------|-----------|------------------|
| **KCHOL** | **QSVR (Angle Encoding)** | **-6.4352** | **èƒœå‡º** | æ˜¾è‘—ä¼˜äº |
| **S&P 500** | SVR (RBF) | -8.3277 | QSVRæ¬¡ä¹‹ (-8.2937) | QSVRä¼˜äºçº¿æ€§/å¤šé¡¹å¼ |
| **AAPL** | SVR (RBF) | -7.4101 | QSVRæ¥è¿‘ (-7.3888) | QSVRä¼˜äºçº¿æ€§/å¤šé¡¹å¼ |

> âœ… **å…³é”®å‘ç°**ï¼š
> - QSVRåœ¨KCHOLä¸Šå–å¾—æœ€ä½QLIKEï¼Œä¼˜äºæ‰€æœ‰ç»å…¸æ¨¡å‹ã€‚
> - åœ¨S&P 500å’ŒAAPLä¸Šï¼ŒQSVRæ€§èƒ½æ¥è¿‘æœ€ä¼˜RBF-SVRï¼Œæ˜æ˜¾ä¼˜äºçº¿æ€§å’Œå¤šé¡¹å¼æ ¸ã€‚
> - æ–¹å‘æ€§å‡†ç¡®ç‡ï¼ˆDirAccï¼‰æ–¹é¢ï¼ŒQSVRæ™®éè¾¾åˆ°0.60å·¦å³ï¼Œä¸æœ€ä½³æ¨¡å‹ç›¸å½“ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **QNNæ¶æ„åˆ†æ**ï¼š
  - **Hybridç»“æ„**ï¼ˆå«ç»å…¸é¢„å¤„ç†ï¼‰åœ¨é«˜ç»´ç‰¹å¾ä¸‹è¡¨ç°æ›´å¥½ã€‚
  - **Multi-Qubit Readout (MQR)** æå‡æ·±åº¦ç”µè·¯çš„è¡¨ç°ï¼Œå°¤å…¶åœ¨å¤æ‚äº¤äº’å»ºæ¨¡ä¸­ã€‚
  - **Amplitude Encoding** åœ¨d=32æ—¶è¡¨ç°è‰¯å¥½ï¼Œä½†d=64æ—¶å› æ•°å€¼ä¸ç¨³å®šå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚
- **QLSTMæ•æ„Ÿæ€§**ï¼š
  - æ€§èƒ½é«˜åº¦ä¾èµ–**é˜ˆå€¼é€‰æ‹©**ï¼ˆT_long, T_shortï¼‰ï¼Œåœ¨F4é˜¶æ®µæœ€ä¼˜é˜ˆå€¼æœªèƒ½è¿ç§»ï¼Œå¯¼è‡´äºæŸã€‚
  - è¡¨æ˜QMLæ¨¡å‹çš„**åˆ†æ•°æ ¡å‡†**ï¼ˆscore calibrationï¼‰å¯èƒ½ä¸å¦‚ç»å…¸æ¨¡å‹ç¨³å®šã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **QMLåœ¨ç‰¹å®šæ¡ä»¶ä¸‹å¯è¶…è¶Šç»å…¸æ¨¡å‹**ï¼š
   - åœ¨**é«˜ç»´ç‰¹å¾ç©ºé—´**ï¼ˆå¦‚64-Dï¼‰ä¸­ï¼ŒHybrid QNNåœ¨æ–¹å‘æ€§é¢„æµ‹ä¸Šæ˜¾è‘—ä¼˜äºå‚æ•°åŒ¹é…çš„ANNã€‚
   - åœ¨**é«˜æ³¢åŠ¨å¸‚åœºç¯å¢ƒ**ï¼ˆå¦‚é‡‘èå±æœºï¼‰ä¸­ï¼ŒQLSTMèƒ½äº§ç”Ÿæ›´é«˜çš„é£é™©è°ƒæ•´æ”¶ç›Šã€‚
   - åœ¨**æ³¢åŠ¨ç‡é¢„æµ‹**ä»»åŠ¡ä¸­ï¼ŒQSVRåœ¨éƒ¨åˆ†èµ„äº§ï¼ˆå¦‚KCHOLï¼‰ä¸Šè¾¾åˆ°æœ€ä¼˜QLIKEï¼Œä¸”æ™®éä¼˜äºçº¿æ€§/å¤šé¡¹å¼SVRã€‚

2. âš ï¸ **ç»å…¸æ¨¡å‹åœ¨ä¸­ç­‰å¤æ‚åº¦ä»»åŠ¡ä¸­ä»å…·ä¼˜åŠ¿**ï¼š
   - åœ¨ä¸­ç»´è·¨èµ„äº§ç‰¹å¾ï¼ˆ7-Dï¼‰é¢„æµ‹S&P 500æ–¹å‘æ—¶ï¼ŒANNç•¥ä¼˜äºQNNã€‚
   - RBFæ ¸SVRä»æ˜¯æ³¢åŠ¨ç‡é¢„æµ‹çš„å¼ºåŸºçº¿ï¼ŒQSVRå°šæœªå…¨é¢è¶…è¶Šã€‚

3. ğŸ” **æ¨¡å‹è®¾è®¡è‡³å…³é‡è¦**ï¼š
   - **Hybridæ¶æ„**ï¼ˆç»å…¸+é‡å­æ··åˆï¼‰åœ¨å½“å‰NISQè®¾å¤‡ä¸‹æ›´å…·å®ç”¨æ€§ã€‚
   - **Amplitude Encoding**è™½ç†è®ºä¸Šé«˜æ•ˆï¼Œä½†å®è·µä¸­æ˜“å—æ•°å€¼è¯¯å·®å½±å“ã€‚
   - **è¯»å‡ºç­–ç•¥**ï¼ˆSingle vs Multi-Qubit Readoutï¼‰å’Œ**ç”µè·¯æ·±åº¦**æ˜¯å½±å“æ€§èƒ½çš„å…³é”®è¶…å‚ã€‚

4. ğŸ’¡ **QMLçš„ä»·å€¼ä¸ä»…åœ¨äºç²¾åº¦ï¼Œæ›´åœ¨äºæ¨¡å¼æ•æ‰æ–¹å¼ä¸åŒ**ï¼š
   - QNNå¸¸ä»¥ç¨ä½å‡†ç¡®ç‡ä¸ºä»£ä»·æ¢å–æ›´é«˜**Recall**ï¼Œé€‚åˆä¸æ„¿é”™è¿‡ä¸Šæ¶¨è¡Œæƒ…çš„ç­–ç•¥ã€‚
   - QSVRè™½ç»å¯¹æ‹Ÿåˆä¸å¦‚RBF-SVRï¼Œä½†**æ–¹å‘æ€§åˆ¤æ–­èƒ½åŠ›å¼º**ï¼Œé€‚åˆè¶‹åŠ¿è·Ÿè¸ªã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **å…¨éƒ¨åŸºäºæ¨¡æ‹Ÿå™¨è¿è¡Œ**ï¼šæœªåœ¨çœŸå®é‡å­ç¡¬ä»¶ä¸Šéƒ¨ç½²ï¼Œå¿½ç•¥å™ªå£°ä¸é€€ç›¸å¹²å½±å“ã€‚
- **ç‰¹å¾ç»´åº¦å—é™**ï¼šå°½ç®¡ä½¿ç”¨Amplitude Encodingï¼Œä½†ä»æ— æ³•å¤„ç†æ•°ç™¾ç»´ä»¥ä¸Šç‰¹å¾ã€‚
- **è®­ç»ƒæˆæœ¬é«˜æ˜‚**ï¼šQSVRéœ€è®¡ç®—O(NÂ²)è§„æ¨¡çš„æ ¸çŸ©é˜µï¼Œéš¾ä»¥æ‰©å±•åˆ°å¤§è§„æ¨¡æ•°æ®é›†ã€‚
- **æ³›åŒ–èƒ½åŠ›å¾…éªŒè¯**ï¼šåœ¨F4é˜¶æ®µQLSTMè¡¨ç°å´©æºƒï¼Œæç¤ºQMLæ¨¡å‹å¯èƒ½å¯¹å¸‚åœº regime æ›´æ•æ„Ÿã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢**å™ªå£°é²æ£’çš„QMLè®­ç»ƒç­–ç•¥**ï¼ˆnoise-resilient trainingï¼‰ä»¥é€‚åº”çœŸå®ç¡¬ä»¶ã€‚
- è®¾è®¡**è½»é‡åŒ–é‡å­ç”µè·¯**ï¼Œé™ä½å¯¹qubitæ•°é‡ä¸ç”µè·¯æ·±åº¦çš„ä¾èµ–ã€‚
- æ„å»º**åŠ¨æ€é˜ˆå€¼æ ¡å‡†æœºåˆ¶**ï¼Œæå‡QLSTMåœ¨ä¸åŒå¸‚åœºçŠ¶æ€ä¸‹çš„ç¨³å®šæ€§ã€‚
- æ‰©å±•è‡³æ›´å¤šé‡‘èä»»åŠ¡ï¼Œå¦‚**ç»„åˆä¼˜åŒ–**ï¼ˆportfolio optimizationï¼‰ã€**ä¿¡ç”¨è¯„åˆ†**ï¼ˆcredit scoringï¼‰ã€**æ¬ºè¯ˆæ£€æµ‹**ç­‰ã€‚
- å¼€å‘**ç«¯åˆ°ç«¯å¯å¾®åˆ†çš„é‡å­-ç»å…¸æ··åˆæ¨¡å‹**ï¼Œæ”¯æŒæ¢¯åº¦åå‘ä¼ æ’­ä¸è”åˆä¼˜åŒ–ã€‚

---

> **æ€»ç»“**ï¼šè¯¥è®ºæ–‡é¦–æ¬¡æä¾›äº†QMLä¸ç»å…¸MLåœ¨é‡‘èé¢„æµ‹ä¸­çš„**ç³»ç»Ÿæ€§ã€æ ‡å‡†åŒ–ã€å¯å¤ç°çš„åŸºå‡†æ¡†æ¶**ã€‚ç»“æœæ˜¾ç¤ºï¼Œ**å½“å‰ä¸€ä»£QMLæ¨¡å‹åœ¨ç‰¹å®šåœºæ™¯ä¸‹å·²å±•ç°å‡ºå®ç”¨æ½œåŠ›**ï¼Œå°¤å…¶æ˜¯åœ¨é«˜ç»´éçº¿æ€§å»ºæ¨¡ä¸é«˜æ³¢åŠ¨ç¯å¢ƒä¸‹çš„é£é™©æ§åˆ¶æ–¹é¢ã€‚ç„¶è€Œï¼Œç»å…¸æ–¹æ³•åœ¨å¤šæ•°å¸¸è§„ä»»åŠ¡ä¸­ä»å ä¼˜ã€‚æœªæ¥QMLçš„å‘å±•åº”èšç„¦äº**æ··åˆæ¶æ„è®¾è®¡ã€å™ªå£°é²æ£’æ€§æå‡ä¸çœŸå®åœºæ™¯éƒ¨ç½²**ï¼Œè€Œéå•çº¯è¿½æ±‚â€œé‡å­ä¼˜è¶Šæ€§â€ã€‚

</details>

---

### 12. [Feature-Aware One-Shot Federated Learning via Hierarchical Token Sequences](https://arxiv.org/abs/2601.03882)

**Authors**: Shudong Liu, Hanwen Zhang, Xiuling Wang, Yuesheng Zhu, Guibo Luo  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.03882v1  

#### Abstract
One-shot federated learning (OSFL) reduces the communication cost and privacy risks of iterative federated learning by constructing a global model with a single round of communication. However, most existing methods struggle to achieve robust performance on real-world domains such as medical imaging...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Feature-Aware One-Shot Federated Learning via Hierarchical Token Sequences è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹**One-Shot Federated Learning (OSFL)** åœ¨å®é™…åº”ç”¨ä¸­çš„ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼š
- **éç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆnon-IIDï¼‰æ•°æ®ä¸‹çš„æ€§èƒ½ä¸‹é™**ï¼šå°¤å…¶æ˜¯åœ¨åŒ»ç–—å›¾åƒç­‰çœŸå®åœºæ™¯ä¸­ï¼Œå®¢æˆ·ç«¯é—´çš„æ•°æ®åˆ†å¸ƒå·®å¼‚å¤§ï¼Œå¯¼è‡´å…¨å±€æ¨¡å‹æ³›åŒ–èƒ½åŠ›å·®ã€‚
- **é€šä¿¡æ•ˆç‡ä¸éšç§é£é™©ä¹‹é—´çš„æƒè¡¡**ï¼šä¼ ç»Ÿè¿­ä»£å¼è”é‚¦å­¦ä¹ é€šä¿¡å¼€é”€å¤§ï¼Œè€Œç°æœ‰ OSFL æ–¹æ³•åœ¨ç”Ÿæˆä»£ç†æ•°æ®æ—¶å­˜åœ¨è®¡ç®—å¤æ‚åº¦é«˜ã€éšç§æ³„éœ²é£é™©æˆ–å»ºæ¨¡ä¸å‡†ç¡®ç­‰é—®é¢˜ã€‚

æ­¤å¤–ï¼Œç°æœ‰åŸºäºç‰¹å¾ç»Ÿè®¡çš„æ–¹æ³•ï¼ˆå¦‚ FedPFTã€FedCGSï¼‰å—é™äºé¢„è®­ç»ƒç¼–ç å™¨å¯¹ç‰¹å®šé¢†åŸŸæ•°æ®çš„é€‚åº”æ€§ä¸è¶³ï¼Œä¸”éš¾ä»¥æ•æ‰å¤šå°ºåº¦ç»†èŠ‚ï¼ˆå°¤å…¶åœ¨é«˜åˆ†è¾¨ç‡åŒ»å­¦å½±åƒä¸­ï¼‰ï¼Œå½±å“æ€§èƒ½ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šFALCON æ¡†æ¶

ä½œè€…æå‡º **FALCON**ï¼ˆ**Feature-Aware One-shot Learning via Hierarchical Token Sequences**ï¼‰ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ç»“åˆ**åˆ†å±‚ token åºåˆ—ç”Ÿæˆ**ä¸**çŸ¥è¯†è’¸é¦å¼•å¯¼çš„å…¨å±€è®­ç»ƒ**ï¼Œæå‡ OSFL åœ¨ non-IID å›¾åƒæ•°æ®ä¸Šçš„æœ‰æ•ˆæ€§ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š
1. **Hierarchical Scale Encoding (HSE)**  
   - åˆ©ç”¨é¢„è®­ç»ƒè§†è§‰ç¼–ç å™¨ï¼ˆå¦‚ DINOv2ï¼‰ï¼Œé€šè¿‡åŒè·¯å¾„æå–å›¾åƒçš„**å…¨å±€è¯­ä¹‰ä¿¡æ¯**ï¼ˆä½åˆ†è¾¨ç‡å…¨å›¾è§†å›¾ï¼‰å’Œ**å±€éƒ¨é«˜åˆ†è¾¨ç‡åŒºåŸŸç»†èŠ‚**ï¼ˆæ»‘åŠ¨çª—å£åˆ‡ç‰‡ï¼‰ã€‚
   - æ„å»ºå…·æœ‰å¤šå°ºåº¦è¯­ä¹‰çš„**å±‚æ¬¡åŒ– token åºåˆ—**ï¼Œå¢å¼ºç¼–ç å™¨å¯¹è·¨åŸŸæ•°æ®çš„é€‚åº”æ€§ï¼Œæ— éœ€æœ¬åœ°å¾®è°ƒã€‚

2. **Multi-Scale Autoregressive (M-AR) Transformer Generator**  
   - è®¾è®¡ä¸€ä¸ªå¸¦æœ‰å—çŠ¶å› æœæ©ç ï¼ˆblock-wise causal maskï¼‰çš„ Transformer ç»“æ„ï¼Œä»¥è‡ªå›å½’æ–¹å¼å»ºæ¨¡ token åºåˆ—çš„åˆ†å¸ƒã€‚
   - å¼•å…¥æ¡ä»¶é«˜æ–¯æ··åˆæ¨¡å‹ï¼ˆGMMï¼‰å¯¹ä¸åŒå±‚çº§ token è¿›è¡Œæ¦‚ç‡å»ºæ¨¡ï¼Œå®ç°æ›´ç²¾ç¡®çš„åˆæˆåºåˆ—ç”Ÿæˆã€‚

3. **Distillation-Guided Global Training**  
   - å®¢æˆ·ç«¯ä¸Šä¼ **åˆæˆ token åºåˆ—** + **æœ¬åœ°åˆ†ç±»å™¨**ã€‚
   - æœåŠ¡å™¨ç«¯åˆ©ç”¨æ‰€æœ‰æœ¬åœ°åˆ†ç±»å™¨ä½œä¸ºâ€œæ•™å¸ˆâ€ï¼Œé€šè¿‡ **Knowledge Distillation** æŒ‡å¯¼å…¨å±€åˆ†ç±»å™¨è®­ç»ƒï¼Œé™ä½å¯¹ç”Ÿæˆæ•°æ®è´¨é‡çš„ä¾èµ–ï¼Œæé«˜é²æ£’æ€§ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | FALCON çš„ä¼˜åŠ¿ |
|------|----------------|
| **æ€§èƒ½** | æ˜¾è‘—ä¼˜äºä¸»æµ OSFL åŸºçº¿ï¼Œåœ¨å¤šç§ non-IID åœºæ™¯ä¸‹å¹³å‡å‡†ç¡®ç‡æå‡ **9.58%** |
| **æ•ˆç‡** | åˆæˆæ ·æœ¬ç”Ÿæˆä»…éœ€ **0.46 GFLOPs/sample**ï¼Œæ¯”æ‰©æ•£æ¨¡å‹ï¼ˆå¦‚ FedLMGï¼‰å¿«å››ä¸ªæ•°é‡çº§ |
| **éšç§ä¿æŠ¤** | åˆæˆ token éš¾ä»¥é‡æ„åŸå§‹å›¾åƒï¼Œæœ‰æ•ˆæŠµå¾¡é‡å»ºæ”»å‡»ï¼ˆreconstruction attackï¼‰ |
| **é€‚ç”¨æ€§** | æ”¯æŒåŒ»ç–—ä¸è‡ªç„¶å›¾åƒï¼Œé€‚ç”¨äºç‰¹å¾ non-IID å’Œæ ‡ç­¾ non-IID å¤šç§åœºæ™¯ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒæ¶µç›– **6 ä¸ªæ•°æ®é›†**ï¼Œè¦†ç›–è‡ªç„¶å›¾åƒä¸åŒ»å­¦å›¾åƒï¼Œåˆ†ä¸ºä¸¤ç±» non-IID è®¾ç½®ï¼š

| æ•°æ®é›† | ç±»å‹ | non-IID ç±»å‹ | ç±»åˆ«æ•° | å®¢æˆ·ç«¯æ•° |
|--------|------|--------------|--------|----------|
| Tuberculosis | åŒ»ç–— | ç‰¹å¾ non-IID | 2 | 3 |
| PACS | è‡ªç„¶ | ç‰¹å¾ non-IID | 7 | 4 |
| OfficeHome | è‡ªç„¶ | ç‰¹å¾ non-IID | 65 | 4 |
| PMRAM | åŒ»ç–— | æ ‡ç­¾ non-IID | 4 | 5 |
| Pneumonia | åŒ»ç–— | æ ‡ç­¾ non-IID | 2 | 5 |
| Tiny-ImageNet | è‡ªç„¶ | æ ‡ç­¾ non-IID | 200 | 5 |

> æ³¨ï¼šæ ‡ç­¾ non-IID é€šè¿‡ Dirichlet åˆ†å¸ƒåˆ’åˆ†æ ‡ç­¾åˆ†å¸ƒæ¨¡æ‹Ÿï¼ˆÎ± âˆˆ {0.1, 0.3, 0.5}ï¼‰

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **ä¸»ä»»åŠ¡**ï¼šå›¾åƒåˆ†ç±»
- **è¯„ä¼°æŒ‡æ ‡**ï¼šæµ‹è¯•é›† **Accuracy (%)**
- **é¢„è®­ç»ƒç¼–ç å™¨**ï¼šDINOv2-base
- **HSE å‚æ•°**ï¼šæ»‘åŠ¨çª—å£å¤§å°ä¸æ­¥é•¿å‡ä¸º 224ï¼Œè¾“å…¥å°ºå¯¸ç»Ÿä¸€ä¸º 448Ã—448
- **ç”Ÿæˆå™¨æ¶æ„**ï¼š4 å±‚ Transformerï¼Œéšè—ç»´åº¦ 768ï¼Œ16 å¤´æ³¨æ„åŠ›ï¼ŒGMM ç»„ä»¶æ•° K=20
- **è®­ç»ƒé…ç½®**ï¼š
  - æœ¬åœ°åˆ†ç±»å™¨ & å…¨å±€åˆ†ç±»å™¨ï¼šAdamï¼Œlr=5e-4ï¼Œbatch_size=256ï¼Œ60 epochs
  - è’¸é¦æ¸©åº¦ T=4ï¼Œå¹³è¡¡ç³»æ•° Î±=0.5

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | å…³é”®æŠ€æœ¯ |
|------|------|---------|
| **FedAvg** | è¿­ä»£å¼ FL | å¤šè½®é€šä¿¡èšåˆ |
| **DENSE** | æ•°æ®æ— å…³è’¸é¦ | çŸ¥è¯†è’¸é¦ + åˆæˆæ ·æœ¬ |
| **FedLMG** | ç”Ÿæˆæ¨¡å‹ | æ‰©æ•£æ¨¡å‹ç”Ÿæˆå›¾åƒ |
| **FedPFT** | ç‰¹å¾åˆ†å¸ƒå»ºæ¨¡ | GMM å»ºæ¨¡ç‰¹å¾åˆ†å¸ƒ |
| **FedCGS** | ç‰¹å¾ç»Ÿè®¡ | é«˜æ–¯æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 2ï¼‰
FALCON åœ¨æ‰€æœ‰è®¾ç½®ä¸‹å‡å–å¾—æœ€ä¼˜æˆ–æ¬¡ä¼˜è¡¨ç°ï¼Œ**å¹³å‡å‡†ç¡®ç‡è¾¾åˆ° 85.92%**ï¼Œæ˜¾è‘—è¶…è¶Šæœ€å¼º OSFL åŸºçº¿ **FedCGS (76.34%)** å’Œ **FedPFT (73.61%)**ã€‚

#### æ€§èƒ½æå‡äº®ç‚¹ï¼š
- **Tuberculosisï¼ˆåŒ»ç–—ç‰¹å¾ non-IIDï¼‰**ï¼šFALCON è¾¾åˆ° **87.20%**ï¼Œæ¯”ç¬¬äºŒå¥½çš„ FedCGSï¼ˆ53.50%ï¼‰é«˜å‡º **33.7%**ã€‚
- **PMRAMï¼ˆåŒ»ç–—æ ‡ç­¾ non-IIDï¼‰**ï¼šåœ¨ Î±=0.1 æœ€æç«¯å¼‚æ„æƒ…å†µä¸‹ä»ä¿æŒ **83.33%** å‡†ç¡®ç‡ï¼Œè¿œè¶… DENSEï¼ˆ26.93%ï¼‰ã€FedLMGï¼ˆ36.99%ï¼‰ã€‚
- **Tiny-ImageNetï¼ˆå¤§è§„æ¨¡æ ‡ç­¾ non-IIDï¼‰**ï¼šFALCON è¾¾åˆ° ~81.5%ï¼Œè€Œ FedCGS è¡¨ç°ä¼˜å¼‚ï¼ˆ~81.5%ï¼‰ï¼Œä½† FALCON æ›´ç¨³å®šã€‚

> âœ… **æ€»ä½“å¹³å‡æå‡ï¼šç›¸æ¯”æœ€ä½³ OSFL åŸºçº¿æå‡ 9.58%**

---

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 3ï¼‰

| å˜ä½“ | å¹³å‡å‡†ç¡®ç‡ (%) | ç›¸æ¯”å®Œæ•´ç‰ˆä¸‹é™ |
|------|----------------|---------------|
| **Full (FALCON)** | **85.92** | â€” |
| w/o HSEï¼ˆæ— åˆ†å±‚ç¼–ç ï¼‰ | 82.32 | â†“3.60 |
| w/o KDï¼ˆæ— çŸ¥è¯†è’¸é¦ï¼‰ | 82.82 | â†“3.10 |
| ARï¼ˆæ™®é€šè‡ªå›å½’ï¼‰ | 81.47 | â†“4.45 |
| NARï¼ˆéè‡ªå›å½’ï¼‰ | 82.99 | â†“2.93 |

#### å‘ç°ï¼š
- **HSE è´¡çŒ®æœ€å¤§**ï¼šç‰¹åˆ«æ˜¯åœ¨åŒ»ç–—æ•°æ®ä¸Šï¼ˆTuberculosis +3.57%ï¼ŒPneumonia +4.73%ï¼‰ï¼Œè¯´æ˜å¤šå°ºåº¦ç¼–ç å¯¹ç»†ç²’åº¦è¯†åˆ«è‡³å…³é‡è¦ã€‚
- **çŸ¥è¯†è’¸é¦å…³é”®ä½œç”¨**ï¼šå¼¥è¡¥ç”Ÿæˆæ•°æ®åå·®ï¼Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚
- **M-AR ä¼˜äº AR/NAR**ï¼šéªŒè¯äº†å»ºæ¨¡ token é—´ä¾èµ–å…³ç³»çš„é‡è¦æ€§ã€‚

---

### åˆ†å¸ƒé€¼è¿‘èƒ½åŠ›åˆ†æï¼ˆTable 4ï¼‰
ä½¿ç”¨ **Maximum Mean Discrepancy (MMD)** è¡¡é‡ç”Ÿæˆ token ä¸çœŸå® token åˆ†å¸ƒçš„è·ç¦»ï¼š

| æ–¹æ³• | Tuberculosis | PACS | OfficeHome |
|------|--------------|------|-----------|
| M-AR (FALCON) | **0.003227** | **0.002047** | **0.000905** |
| AR | 0.003868 | 0.002457 | 0.001079 |
| NAR | 0.003868 | 0.002151 | 0.000849 |

â†’ M-AR åœ¨å¤šæ•°æ•°æ®é›†ä¸Šè¾¾åˆ°æœ€ä½ MMDï¼Œè¡¨æ˜å…¶èƒ½æ›´å¥½æ‹ŸåˆçœŸå® token åˆ†å¸ƒã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **HSE æ˜¾è‘—æå‡é¢†åŸŸé€‚åº”æ€§**ï¼šæ— éœ€å¾®è°ƒå³å¯ä»åŸå§‹å›¾åƒä¸­æå–å¤šå°ºåº¦è¯­ä¹‰ï¼Œåœ¨åŒ»ç–—å›¾åƒä¸­å°¤ä¸ºæœ‰æ•ˆã€‚
2. âœ… **M-AR Transformer é«˜æ•ˆå»ºæ¨¡ token åˆ†å¸ƒ**ï¼šç›¸æ¯”æ‰©æ•£æ¨¡å‹ç­‰ heavy-weight ç”Ÿæˆå™¨ï¼Œè®¡ç®—æˆæœ¬æä½ï¼ˆ0.46 GFLOPs/sampleï¼‰ï¼Œé€‚åˆè¾¹ç¼˜éƒ¨ç½²ã€‚
3. âœ… **çŸ¥è¯†è’¸é¦ç¼“è§£ç”Ÿæˆåå·®**ï¼šå³ä½¿ç”Ÿæˆæ•°æ®ä¸å®Œç¾ï¼Œä¹Ÿèƒ½é€šè¿‡æœ¬åœ°åˆ†ç±»å™¨çŸ¥è¯†èåˆè·å¾—é«˜æ€§èƒ½å…¨å±€æ¨¡å‹ã€‚
4. âœ… **å¼ºéšç§ä¿æŠ¤èƒ½åŠ›**ï¼šé‡å»ºæ”»å‡»æ˜¾ç¤ºï¼Œä»**åˆæˆ token** æ— æ³•æ¢å¤å¯è¯†åˆ«å›¾åƒï¼ˆSSIM < 0.16ï¼‰ï¼Œè€ŒçœŸå® token å¯éƒ¨åˆ†è¿˜åŸï¼ˆSSIM > 0.8ï¼‰ã€‚
5. âœ… **é€šä¿¡çµæ´»**ï¼šå®¢æˆ·ç«¯å¯é€‰æ‹©ä¸Šä¼ ç”Ÿæˆå™¨æ¨¡å‹æˆ–åˆæˆ token åºåˆ—ï¼Œæ ¹æ®æ•°æ®é‡åŠ¨æ€ä¼˜åŒ–é€šä¿¡å¼€é”€ï¼ˆä¸Šé™çº¦ 166.86 MBï¼‰ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–é«˜è´¨é‡é¢„è®­ç»ƒç¼–ç å™¨**ï¼šè‹¥é¢„è®­ç»ƒåŸŸä¸ç›®æ ‡åŸŸå·®è·è¿‡å¤§ï¼ˆå¦‚é¥æ„Ÿ â†’ åŒ»ç–—ï¼‰ï¼ŒHSE æ•ˆæœå¯èƒ½å—é™ã€‚
2. **ç”Ÿæˆå™¨ä»éœ€ä¸€å®šè®­ç»ƒèµ„æº**ï¼šè™½ç„¶æ¨ç†é«˜æ•ˆï¼Œä½†æ¯ä¸ªå®¢æˆ·ç«¯éœ€è®­ç»ƒ M-AR Generatorï¼Œå¯¹æä½èµ„æºè®¾å¤‡ä»æœ‰è´Ÿæ‹…ã€‚
3. **æœªæ”¯æŒä¸ªæ€§åŒ–æ¨¡å‹**ï¼šå½“å‰æ¡†æ¶èšç„¦å…¨å±€æ¨¡å‹æ„å»ºï¼Œæœªæ¢è®¨ä¸ªæ€§åŒ–é€‚é…ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. æ¢ç´¢æ›´é«˜æ•ˆçš„ç¼–ç ç­–ç•¥ï¼Œè¿›ä¸€æ­¥æå‡è·¨åŸŸè¿ç§»èƒ½åŠ›ï¼›
2. è®¾è®¡è½»é‡åŒ–ç”Ÿæˆå™¨ç»“æ„ï¼Œé™ä½å®¢æˆ·ç«¯è®­ç»ƒæˆæœ¬ï¼›
3. å°† FALCON æ‰©å±•è‡³å…¶ä»–ä»»åŠ¡ï¼ˆå¦‚åˆ†å‰²ã€æ£€æµ‹ï¼‰ï¼›
4. ç ”ç©¶æ›´å¼ºå¤§çš„ç”Ÿæˆå»ºæ¨¡èŒƒå¼ï¼ˆå¦‚ latent autoregressive modelingï¼‰ä»¥æå‡è¡¨è¾¾åŠ›ï¼›
5. åŠ å¼ºç†è®ºåˆ†æï¼Œç†è§£ HSE ä¸ KD å¦‚ä½•ååŒæ”¹å–„ non-IID æ³›åŒ–ã€‚

---

> ğŸ”— **ä»£ç åœ°å€**ï¼š[https://github.com/LMIAPC/FALCON](https://github.com/LMIAPC/FALCON)

</details>

---

### 13. [xDNN(ASP): Explanation Generation System for Deep Neural Networks powered by Answer Set Programming](https://arxiv.org/abs/2601.03847)

**Authors**: Ly Ly Trieu (New Mexico State University), Tran Cao Son (New Mexico State University)  
**Category**: cs.AI  
**Published**: 2026-01-08  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.03847v1  

#### Abstract
Explainable artificial intelligence (xAI) has gained significant attention in recent years. Among other things, explainablility for deep neural networks has been a topic of intensive research due to the meteoric rise in prominence of deep neural networks and their "black-box" nature. xAI approaches ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šxDNN(ASP): Explanation Generation System for Deep Neural Networks powered by Answer Set Programming

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰å› å…¶â€œé»‘ç®±â€ç‰¹æ€§è€Œç¼ºä¹å¯è§£é‡Šæ€§ï¼Œè¿™åœ¨åŒ»ç–—ã€ç½‘ç»œå®‰å…¨ç­‰é«˜é£é™©é¢†åŸŸå°¤ä¸ºå…³é”®ã€‚ç°æœ‰çš„è§£é‡Šæ€§äººå·¥æ™ºèƒ½ï¼ˆxAIï¼‰æ–¹æ³•å¤§å¤šå…³æ³¨è¾“å…¥-è¾“å‡ºå…³ç³»ï¼ˆå¦‚SHAPã€LIMEï¼‰ï¼Œå¿½è§†äº†æ¨¡å‹å†…éƒ¨ç»“æ„ï¼ˆå°¤å…¶æ˜¯éšè—å±‚ï¼‰å¯¹é¢„æµ‹çš„å½±å“ã€‚æ­¤å¤–ï¼Œè®¸å¤šè§„åˆ™æå–æ–¹æ³•æ— æ³•æä¾›å…¨å±€è§£é‡Šæˆ–ä¾èµ–é¢å¤–æ ‡æ³¨æ•°æ®ã€‚

æœ¬æ–‡æ—¨åœ¨è§£å†³ä»¥ä¸‹ä¸‰ä¸ªæ ¸å¿ƒé—®é¢˜ï¼š
- **ä¸ºä»€ä¹ˆ**æŸä¸ªè¾“å‡ºè¢«ç”Ÿæˆï¼Ÿ
- å“ªäº›**ç‰¹å¾**å‚ä¸äº†å†³ç­–è¿‡ç¨‹ï¼Ÿ
- éšè—å±‚ä¹‹é—´çš„**äº¤äº’æœºåˆ¶**æ˜¯æ€æ ·çš„ï¼Ÿ

### æå‡ºçš„æ–°æ–¹æ³•æˆ–æ–°æ€è·¯
ä½œè€…æå‡ºäº† **xDNN(ASP)** â€”â€”ä¸€ç§åŸºäº **Answer Set Programming (ASP)** çš„å…¨å±€è§£é‡Šç”Ÿæˆç³»ç»Ÿï¼Œå±äº**åˆ†è§£å¼ï¼ˆdecompositionalï¼‰xAI** æ–¹æ³•ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†è®­ç»ƒå¥½çš„DNNæ¨¡å‹åŠå…¶è®­ç»ƒæ•°æ®è½¬åŒ–ä¸ºä¸€ä¸ªé€»è¾‘ç¨‹åº $\Pi(M)$ï¼Œä½¿å¾—è¯¥ç¨‹åºçš„ **answer sets** ä¸DNNçš„è¾“å…¥-è¾“å‡ºè¡Œä¸ºä¸€ä¸€å¯¹åº”ã€‚

#### åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š
- **é¦–æ¬¡å°†DNNè½¬æ¢ä¸ºASPé€»è¾‘ç¨‹åº**ï¼šåˆ©ç”¨C5.0å†³ç­–æ ‘ç®—æ³•é€å±‚æå–è§„åˆ™ï¼Œå¹¶æ„å»ºå…·æœ‰è¯­ä¹‰ä¸€è‡´æ€§çš„é€»è¾‘ç¨‹åºã€‚
- **åˆ†å±‚è§„åˆ™æ„é€ æœºåˆ¶**ï¼š
  - **Top-level rules**ï¼šè¿æ¥æœ€åä¸€å±‚éšè—èŠ‚ç‚¹åˆ°è¾“å‡ºç±»ï¼›
  - **Intermediate rules**ï¼šæè¿°éšè—å±‚ä¹‹é—´èŠ‚ç‚¹çš„å…³ç³»ï¼›
  - **Bottom-level rules**ï¼šä»åŸå§‹è¾“å…¥ç‰¹å¾æ¨å¯¼ç¬¬ä¸€å±‚éšè—èŠ‚ç‚¹çš„çŠ¶æ€ã€‚
- **æ”¯æŒå¯¹éšè—èŠ‚ç‚¹å½±å“çš„é‡åŒ–åˆ†æ**ï¼šæå‡ºâ€œimpact scoreâ€æ¥è¡¡é‡æ¯ä¸ªéšè—èŠ‚ç‚¹çš„é‡è¦æ€§ï¼Œå¯ç”¨äºç½‘ç»œç®€åŒ–è®¾è®¡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | å±€é™æ€§ | xDNN(ASP) çš„ä¼˜åŠ¿ |
|------|--------|------------------|
| **SHAP/LIME** | ä»…æä¾›å±€éƒ¨ã€ç»Ÿè®¡æ€§è§£é‡Šï¼Œå¿½ç•¥ç½‘ç»œç»“æ„ | æä¾›**å…¨å±€ã€ç»“æ„æ€§è§£é‡Š**ï¼Œæ­ç¤ºå†…éƒ¨æœºåˆ¶ |
| **ECLAIRE / DeepRED** | ä»…ç”Ÿæˆä»è¾“å…¥åˆ°è¾“å‡ºçš„IF-THENè§„åˆ™ï¼Œä¸å»ºæ¨¡éšè—å±‚é—´å…³ç³» | æ˜¾å¼å»ºæ¨¡**éšè—å±‚é—´çš„ä¾èµ–å…³ç³»**ï¼Œæ”¯æŒæ›´ç»†ç²’åº¦åˆ†æ |
| **Pedagogical æ–¹æ³•** | å¿½è§†ç½‘ç»œç»“æ„ï¼Œè§†ä¸ºé»‘ç›’ | å±äº**decompositional** ç±»å‹ï¼Œä¿ç•™å¹¶è§£æç½‘ç»œç»“æ„ |
| **éœ€æ˜ å°„ç½‘ç»œçš„æ–¹æ³•ï¼ˆå¦‚[11]ï¼‰** | éœ€è¦ä¸“å®¶æ ‡æ³¨ä¸­é—´æ¦‚å¿µ | ä¸éœ€è¦é¢å¤–æ ‡æ³¨ï¼Œç«¯åˆ°ç«¯è‡ªåŠ¨æå– |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒé‡‡ç”¨ä¸¤ä¸ªåˆæˆæ•°æ®é›†è¿›è¡ŒéªŒè¯ï¼š

1. **XOR Dataset**
   - æ ·æœ¬æ•°ï¼š1000
   - ç‰¹å¾ç»´åº¦ï¼š10ï¼ˆä»…å‰ä¸¤ä¸ªç‰¹å¾ $x_1, x_2$ æœ‰æ•ˆï¼‰
   - è¾“å‡ºæ ‡ç­¾ï¼š$y = \text{round}(x_1) \oplus \text{round}(x_2)$
   - ç›®æ ‡ï¼šè¯„ä¼°é¢„æµ‹å‡†ç¡®æ€§ã€ä¸€è‡´æ€§åŠç‰¹å¾é‡è¦æ€§è¯†åˆ«èƒ½åŠ›

2. **Modified-XOR Dataset**
   - åœ¨XORåŸºç¡€ä¸Šä¿®æ”¹ï¼š$y = (\text{round}(x_1) \oplus \text{round}(x_2)) + \text{round}(x_3)$
   - ä¸‰ä¸ªç‰¹å¾ï¼ˆ$x_1, x_2, x_3$ï¼‰ç›¸å…³ï¼Œæ›´å…·å¤æ‚æ€§
   - ç›®æ ‡ï¼šç ”ç©¶éšè—èŠ‚ç‚¹çš„å½±å“ï¼Œæ¢ç´¢ç½‘ç»œæ¶æ„ä¼˜åŒ–æ½œåŠ›

### å®éªŒè®¾ç½®
- **DNNç»“æ„**ï¼š
  - è¾“å…¥å±‚ï¼š10èŠ‚ç‚¹ï¼ˆå¯¹åº”10ç»´ç‰¹å¾ï¼‰
  - è¾“å‡ºå±‚ï¼š1èŠ‚ç‚¹ï¼ˆäºŒåˆ†ç±»ï¼‰
  - éšè—å±‚æ•°é‡ï¼š1å±‚æˆ–å¤šå±‚
  - éšè—èŠ‚ç‚¹æ•°é‡ï¼š{8, 16, 32, 64, 128}
  - æ¿€æ´»å‡½æ•°ï¼štanh / relu / elu
  - è®­ç»ƒå‚æ•°ï¼šepochs âˆˆ {50,100,150,200}, batch_size âˆˆ {16,32}

- **xDNN(ASP)æµç¨‹**ï¼š
  1. è®­ç»ƒDNNæ¨¡å‹ $M$
  2. ä½¿ç”¨C5.0åœ¨å„å±‚æ¿€æ´»å€¼ä¸Šè®­ç»ƒåˆ†ç±»å™¨ï¼Œç”ŸæˆIF-THENè§„åˆ™
  3. å°†è§„åˆ™ç¼–ç ä¸ºASPé€»è¾‘ç¨‹åº $\Pi(M)$
  4. åˆ©ç”¨ASPæ±‚è§£å™¨æ¨ç†å¹¶è¯„ä¼°è§£é‡Šæ€§èƒ½

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Accuracy of $\Pi(M)$** | $\Pi(M)$ åœ¨æµ‹è¯•é›†ä¸Šçš„é¢„æµ‹å‡†ç¡®ç‡ |
| **Fidelity** | $\Pi(M)$ å‡†ç¡®ç‡ä¸åŸDNNæ¨¡å‹ $M$ å‡†ç¡®ç‡çš„ä¸€è‡´ç¨‹åº¦ï¼Œåæ˜ è§„åˆ™ä¿çœŸåº¦ |
| **Feature Importance** | ç‰¹å¾ $x_i$ åœ¨æ‰€æœ‰è§„åˆ™ä¸­å‡ºç°æ¬¡æ•°å æ¯”ï¼Œç”¨äºè¯†åˆ«å…³é”®è¾“å…¥ |
| **Impact Score of Hidden Node** | èŠ‚ç‚¹ä½œä¸ºè§„åˆ™å¤´ï¼ˆè¢«å½±å“ï¼‰å’Œè§„åˆ™ä½“ï¼ˆå½±å“ä»–äººï¼‰çš„é¢‘æ¬¡ä¹˜ç§¯ï¼Œè¡¡é‡å…¶åœ¨ç½‘ç»œä¸­çš„å½±å“åŠ› |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **ECLAIRE**ï¼šå½“å‰æœ€ä¼˜çš„decompositionalè§„åˆ™æå–æ–¹æ³•
- **DeepRED**, **REM-D**ï¼šå…¶ä»–ä»£è¡¨æ€§åˆ†è§£å¼æ–¹æ³•
- **Wekaå†³ç­–æ ‘ï¼ˆC5.0ï¼‰**ï¼šä½œä¸ºéDNNåŸºçº¿ï¼Œç”¨äºæ¯”è¾ƒä¼ ç»Ÿå¯è§£é‡Šæ¨¡å‹æ€§èƒ½
- **SHAP**ï¼šè™½æœªç›´æ¥æ¯”è¾ƒè§„åˆ™æå–æ•ˆæœï¼Œä½†ç”¨äºéªŒè¯ç‰¹å¾é‡è¦æ€§ä¸€è‡´æ€§

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆXOR æ•°æ®é›†ï¼‰

#### è¡¨1ï¼šä¸åŒè®¾è®¡ä¸‹DNNä¸$\Pi(M)$çš„å‡†ç¡®ç‡å¯¹æ¯”ï¼ˆTable 3ï¼‰
| è®¾è®¡ | éšè—èŠ‚ç‚¹ | Epochs | Batch Size | DNN Accuracy (%) | $\Pi(M)$ Accuracy (%) |
|------|----------|--------|------------|------------------|------------------------|
| 1    | 128      | 200    | 32         | 96.3             | **94.0**               |
| 2    | 128      | 150    | 32         | 95.2             | **94.0**               |
| 3    | 64       | 200    | 16         | 96.2             | 93.8                   |
| 4    | 128      | 150    | 16         | 95.5             | 93.2                   |
| 5    | 32       | 200    | 16         | 95.1             | 92.6                   |

- **xDNN(ASP)** å¹³å‡è§„åˆ™æå–å‡†ç¡®ç‡è¾¾ **~93%**
- æ˜¾è‘—ä¼˜äºECLAIREï¼ˆ91.8 Â± 2.6%ï¼‰ä¸”æ³¢åŠ¨æ›´å°

#### å›¾2 & å›¾3ï¼šFidelity åˆ†æ
- æ‰€æœ‰ç‚¹é è¿‘å¯¹è§’çº¿ â†’ é«˜ä¿çœŸåº¦
- xDNN(ASP) åœ¨å¤šä¸ªè®¾è®¡ä¸­è¡¨ç°ç¨³å®šï¼Œ**fidelity æ¥è¿‘1.0**
- ECLAIRE åœ¨æŸäº›foldä¸­ä¸‹é™è‡³65%ï¼Œè¡¨ç°å‡ºæ˜æ˜¾ä¸ç¨³å®šæ€§

#### ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆå›¾4ï¼‰
- æå–çš„è§„åˆ™ä¸­ï¼Œåªæœ‰ $x_1$ å’Œ $x_2$ è¢«é¢‘ç¹ä½¿ç”¨ï¼ˆ>35%ï¼‰
- å…¶ä»–æ— å…³ç‰¹å¾å‡ ä¹æœªå‡ºç°åœ¨è§„åˆ™ä¸­
- ä¸çœŸå®æ•°æ®ç”Ÿæˆæœºåˆ¶å®Œå…¨ä¸€è‡´ï¼Œè¯´æ˜èƒ½æ­£ç¡®è¯†åˆ«**çœŸæ­£é‡è¦çš„ç‰¹å¾**

---

### Modified-XOR å®éªŒç»“æœï¼ˆè¡¨4ï¼‰

#### è¡¨2ï¼šModified-XOR ä¸Šçš„è¡¨ç°ï¼ˆTable 4ï¼‰
| è®¾è®¡ | éšè—èŠ‚ç‚¹ | Epochs | Batch Size | DNN Accuracy (%) | $\Pi(M)$ Accuracy (%) |
|------|----------|--------|------------|------------------|------------------------|
| 1    | 128      | 200    | 16         | 91.9             | 83.4                   |
| 2    | 16       | 200    | 16         | 90.8             | 82.6                   |
| 3    | 64       | 200    | 16         | 92.3             | 82.4                   |
| 4    | 32       | 200    | 32         | 90.3             | 80.7                   |
| 5 (special) | **10** | 200 | 16       | **92.1**         | **82.8**               |

- å³ä½¿åªç”¨ **10ä¸ªéšè—èŠ‚ç‚¹**ï¼ˆè¿œå°‘äºå¸¸è§„128ï¼‰ï¼Œä»ä¿æŒæœ€é«˜å‡†ç¡®ç‡
- æ”¯æŒé€šè¿‡ **impact score** å‘ç°å†—ä½™èŠ‚ç‚¹ï¼Œå®ç°ç½‘ç»œå‹ç¼©

#### å›¾5ï¼šéšè—èŠ‚ç‚¹å½±å“åˆ†æ
- åªæœ‰å°‘æ•°éšè—èŠ‚ç‚¹å…·æœ‰é«˜ **impact score**
- å¤§éƒ¨åˆ†èŠ‚ç‚¹è´¡çŒ®æä½ï¼Œè¡¨æ˜å­˜åœ¨æ˜¾è‘—å†—ä½™
- å¯æ®æ­¤æŒ‡å¯¼ç½‘ç»œç²¾ç®€è®¾è®¡ï¼ˆpruning æˆ– architecture searchï¼‰

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **xDNN(ASP) æˆåŠŸå°†DNNè½¬åŒ–ä¸ºé«˜ä¿çœŸçš„ASPé€»è¾‘ç¨‹åº**ï¼Œ$\Pi(M)$ èƒ½ä»¥ >92% å‡†ç¡®ç‡å¤ç°åŸæ¨¡å‹è¡Œä¸ºã€‚
2. âœ… æå–çš„è§„åˆ™ä¸ä»…èƒ½è§£é‡Šâ€œ**è¾“å…¥â†’è¾“å‡º**â€ï¼Œè¿˜èƒ½æ­ç¤ºâ€œ**è¾“å…¥â†’éšè—å±‚â†’è¾“å‡º**â€çš„å®Œæ•´æ¨ç†é“¾ã€‚
3. âœ… **ç‰¹å¾é‡è¦æ€§è¯†åˆ«å‡†ç¡®**ï¼šä»…å…³é”®ç‰¹å¾è¢«é¢‘ç¹ä½¿ç”¨ï¼Œä¸ground truthä¸€è‡´ã€‚
4. âœ… **éšè—èŠ‚ç‚¹å½±å“å¯é‡åŒ–**ï¼šé€šè¿‡ impact score å¯è¯†åˆ«æ ¸å¿ƒèŠ‚ç‚¹ï¼Œæ”¯æŒç½‘ç»œç»“æ„ä¼˜åŒ–ã€‚
5. âœ… ç›¸æ¯”ECLAIREç­‰æ–¹æ³•ï¼ŒxDNN(ASP) åœ¨**ä¿çœŸåº¦å’Œç¨³å®šæ€§**æ–¹é¢è¡¨ç°æ›´ä¼˜ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ç¨‹åºè§„æ¨¡éšç½‘ç»œå¢é•¿çº¿æ€§ä¸Šå‡**ï¼šå¯¹äºå¤§å‹DNNï¼ˆå¦‚CNNã€Transformerï¼‰ï¼Œç”Ÿæˆçš„ASPç¨‹åºå¯èƒ½è¿‡äºåºå¤§ï¼Œéš¾ä»¥äººå·¥é˜…è¯»æˆ–å¯è§†åŒ–ã€‚
- **ä¾èµ–C5.0è¿›è¡Œè§„åˆ™æå–**ï¼šC5.0æœ¬èº«é€‚ç”¨äºè¡¨æ ¼å‹æ•°æ®ï¼Œåœ¨å¤„ç†å›¾åƒã€æ–‡æœ¬ç­‰éç»“æ„åŒ–è¾“å…¥æ—¶å—é™ã€‚
- **ç›®å‰ä»…é€‚ç”¨äºå…¨è¿æ¥ç½‘ç»œ**ï¼šå°šæœªæ‰©å±•åˆ°å·ç§¯å±‚ã€æ³¨æ„åŠ›æœºåˆ¶ç­‰å¤æ‚ç»“æ„ã€‚
- **è®¡ç®—å¼€é”€è¾ƒé«˜**ï¼šå¤šè½®C5.0è°ƒç”¨å’ŒASPç¼–ç å¸¦æ¥ä¸€å®šæ—¶é—´æˆæœ¬ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **é™ä½è®¡ç®—æˆæœ¬**ï¼šç ”ç©¶æŒ‰ç»„ï¼ˆgroup-wiseï¼‰è€Œéå•ä¸ªèŠ‚ç‚¹åˆ†æéšè—å±‚å½±å“ã€‚
2. **æ‰©å±•è‡³ä¸“ç”¨æ¶æ„**ï¼šæ¢ç´¢å¦‚ä½•åº”ç”¨äº **Convolutional Neural Networks (CNNs)** æˆ– **Graph Neural Networks (GNNs)**ã€‚
3. **ç»“åˆç¬¦å·æ¨ç†å¢å¼ºè§£é‡Šèƒ½åŠ›**ï¼šåˆ©ç”¨ASPçš„å¼ºå¤§è¡¨è¾¾åŠ›ç”Ÿæˆåäº‹å®è§£é‡Šï¼ˆcounterfactual explanationsï¼‰æˆ–å› æœè·¯å¾„ã€‚
4. **è‡ªåŠ¨åŒ–ç½‘ç»œå‰ªæå·¥å…·**ï¼šåŸºäº impact score å¼€å‘DNNå‹ç¼©æ¡†æ¶ï¼Œæå‡éƒ¨ç½²æ•ˆç‡ã€‚
5. **æ”¯æŒéæ•°å€¼è¾“å…¥**ï¼šæ”¹è¿›bottom-levelè§„åˆ™ç”Ÿæˆæ–¹å¼ï¼Œé€‚é…ç±»åˆ«å‹ã€æ–‡æœ¬å‹ç‰¹å¾ã€‚

---

> **æ€»ç»“**ï¼š  
> xDNN(ASP) æ˜¯é¦–ä¸ªå°†DNNè½¬åŒ–ä¸ºASPé€»è¾‘ç¨‹åºçš„è§£é‡Šç³»ç»Ÿï¼Œä¸ä»…å®ç°äº†é«˜ä¿çœŸçš„å…¨å±€è§£é‡Šï¼Œè¿˜å¼€åˆ›æ€§åœ°æä¾›äº†å¯¹éšè—å±‚ç»“æ„çš„ç†è§£èƒ½åŠ›ã€‚å…¶å®éªŒç»“æœè¯æ˜äº†å…¶åœ¨å‡†ç¡®æ€§ã€ç¨³å®šæ€§å’Œå¯è§£é‡Šæ·±åº¦æ–¹é¢çš„ä¼˜è¶Šæ€§ï¼Œä¸ºæ„å»ºå¯ä¿¡ã€é€æ˜çš„æ·±åº¦å­¦ä¹ ç³»ç»Ÿæä¾›äº†æœ‰åŠ›å·¥å…·ã€‚

</details>

---

### 14. [DiffCoT: Diffusion-styled Chain-of-Thought Reasoning in LLMs](https://arxiv.org/abs/2601.03559)

**Authors**: Shidong Cao, Hongzhan Lin, Yuxuan Gu, Ziyang Luo, Jing Ma  
**Category**: cs.CL  
**Published**: 2026-01-08  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.03559v1  

#### Abstract
Chain-of-Thought (CoT) reasoning improves multi-step mathematical problem solving in large language models but remains vulnerable to exposure bias and error accumulation, as early mistakes propagate irreversibly through autoregressive decoding. In this work, we propose DiffCoT, a diffusion-styled Co...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šDIFFCoT: Diffusion-styled Chain-of-Thought Reasoning in LLMs**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
ä¼ ç»Ÿçš„ **Chain-of-Thought (CoT)** æ¨ç†åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­å­˜åœ¨ä¸¤ä¸ªå…³é”®ç¼ºé™·ï¼š
- **æš´éœ²åå·®ï¼ˆExposure Biasï¼‰**ï¼šè®­ç»ƒæ—¶ä½¿ç”¨æ­£ç¡®çš„å‰ç¼€ï¼ˆteacher-forcingï¼‰ï¼Œè€Œæ¨ç†æ—¶å¯èƒ½åŸºäºé”™è¯¯çš„ä¸­é—´æ­¥éª¤ç»§ç»­ç”Ÿæˆï¼Œå¯¼è‡´è¯¯å·®ä¼ æ’­ã€‚
- **è¯¯å·®ç´¯ç§¯ï¼ˆError Accumulationï¼‰**ï¼šæ—©æœŸæ¨ç†æ­¥éª¤ä¸­çš„é”™è¯¯ä¼šä¸å¯é€†åœ°å½±å“åç»­æ­¥éª¤ï¼Œæœ€ç»ˆå¯¼è‡´é”™è¯¯ç­”æ¡ˆã€‚

ç°æœ‰æ–¹æ³•å¦‚ **Preference Optimization (PO)** å’Œ **Tree of Thoughts (ToT)** è™½èƒ½éƒ¨åˆ†ç¼“è§£è¯¥é—®é¢˜ï¼Œä½†ä»å—é™äºä¸¥æ ¼çš„è‡ªå›å½’ã€å‰å‘ç”Ÿæˆæ¨¡å¼ï¼Œç¼ºä¹å¯¹å·²ç”Ÿæˆæ­¥éª¤çš„å…¨å±€ä¿®æ­£èƒ½åŠ›ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ï¼šDIFFCoT**
ä½œè€…æå‡ºäº† **DIFFCoT**ï¼Œä¸€ç§å°† **æ‰©æ•£æ¨¡å‹ï¼ˆDiffusion Modelï¼‰æ€æƒ³èå…¥ CoT æ¨ç†** çš„æ–°æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### âœ… **1. å°† CoT é‡æ„ä¸ºè¿­ä»£å»å™ªè¿‡ç¨‹**
- ä¸å†å°†æ¨ç†è§†ä¸ºå•å‘ã€ä¸å¯ä¿®æ”¹çš„ç”Ÿæˆæµç¨‹ï¼Œè€Œæ˜¯å°†å…¶å»ºæ¨¡ä¸ºä¸€ä¸ªä»â€œå™ªå£°æ¨ç†é“¾â€é€æ­¥ä¿®å¤ä¸ºâ€œå¹²å‡€æ¨ç†é“¾â€çš„ **è¿­ä»£å»å™ªè¿‡ç¨‹**ã€‚
- å…è®¸æ¨¡å‹åœ¨ç”Ÿæˆåç»­æ­¥éª¤çš„åŒæ—¶ï¼Œå›æº¯å¹¶ä¿®æ­£å…ˆå‰çš„é”™è¯¯æ­¥éª¤ã€‚

#### âœ… **2. å¼•å…¥æ»‘åŠ¨çª—å£æœºåˆ¶ï¼ˆSliding-Window Mechanismï¼‰**
- åœ¨ä¸€ä¸ªå¤§å°ä¸º `m` çš„æ»‘åŠ¨çª—å£å†…ï¼ŒåŒæ—¶è¿›è¡Œï¼š
  - **å»å™ª**ï¼šå¯¹çª—å£å†…çš„å†å²æ­¥éª¤è¿›è¡Œä¼˜åŒ–ï¼ˆé™ä½å™ªå£°ï¼‰
  - **ç”Ÿæˆ**ï¼šé¢„æµ‹ä¸‹ä¸€ä¸ªé«˜å™ªå£°çŠ¶æ€çš„æ¨ç†æ­¥éª¤
- ä¿æŒäº† token-level çš„è‡ªå›å½’ç‰¹æ€§ï¼Œä¾¿äºä¸ç°æœ‰ LLM æ¶æ„å…¼å®¹ã€‚

#### âœ… **3. è®¾è®¡å› æœæ‰©æ•£å™ªå£°è°ƒåº¦ï¼ˆCausal Diffusion Noise Scheduleï¼‰**
- ä¼ ç»Ÿæ‰©æ•£æ¨¡å‹æ˜¯éå› æœçš„ï¼Œè€Œ CoT å¿…é¡»ä¿æŒæ—¶é—´é¡ºåºã€‚
- DIFFCoT æå‡ºä¸€ç§ **step-dependent å™ªå£°è°ƒåº¦ç­–ç•¥**ï¼šè¶Šé åçš„æ¨ç†æ­¥éª¤ï¼Œåœ¨åˆå§‹é˜¶æ®µè¢«æ³¨å…¥æ›´å¼ºçš„å™ªå£°ï¼Œä»è€Œå¼ºåˆ¶æ¨¡å‹å°Šé‡å› æœä¾èµ–å…³ç³»ã€‚

#### âœ… **4. ç»Ÿä¸€ç”Ÿæˆä¸ä¿®æ­£**
- åœ¨åŒä¸€æ¡†æ¶ä¸‹å®ç° **forward generation** ä¸ **retrospective correction**ï¼Œé¿å…é¢å¤–å¼•å…¥æœç´¢æˆ–éªŒè¯æ¨¡å—å¸¦æ¥çš„è®¡ç®—å¼€é”€ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹æ³• | æ˜¯å¦æ”¯æŒä¿®æ­£ | æ˜¯å¦ç¼“è§£æš´éœ²åå·® | æ˜¯å¦ä¿æŒè‡ªå›å½’ | è®¡ç®—æ•ˆç‡ |
|------|----------------|--------------------|------------------|-----------|
| Standard CoT | âŒ | âŒ | âœ… | é«˜ |
| ToT / MCTS | âœ…ï¼ˆé€šè¿‡æœç´¢ï¼‰ | âš ï¸æœ‰é™ | âœ… | ä½ï¼ˆé«˜æ¨ç†æˆæœ¬ï¼‰ |
| Step-DPO / Full-Step-DPO | âŒ | âš ï¸å±€éƒ¨ç¼“è§£ | âœ… | ä¸­ |
| **DIFFCoT** | âœ…ï¼ˆåŠ¨æ€ä¿®æ­£ï¼‰ | âœ… | âœ… | ä¸­ï¼ˆå¯å¾®è°ƒï¼‰ |

> DIFFCoT åœ¨ä¸ç‰ºç‰²æ¨ç†æ•ˆç‡çš„å‰æä¸‹ï¼Œå®ç°äº†å¯¹ä¸­é—´æ­¥éª¤çš„çµæ´»ä¿®æ­£ï¼Œæ˜¾è‘—æå‡äº†é²æ£’æ€§å’Œçº é”™èƒ½åŠ›ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
åœ¨ä¸‰ä¸ªä¸»æµæ•°å­¦æ¨ç†åŸºå‡†ä¸Šè¿›è¡Œè¯„ä¼°ï¼š
- **GSM8K**ï¼šå°å­¦çº§æ•°å­¦åº”ç”¨é¢˜ï¼Œå¼ºè°ƒå¤šæ­¥é€»è¾‘æ¨ç†ã€‚
- **SVAMP**ï¼šè¯­ä¹‰å˜åŒ–çš„åº”ç”¨é¢˜ï¼Œæµ‹è¯•æ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚
- **MATH**ï¼šé«˜ä¸­è‡³ç«èµ›çº§åˆ«æ•°å­¦é¢˜ï¼Œåˆ†ä¸ºäº”ä¸ªéš¾åº¦ç­‰çº§ï¼ˆL1â€“L5ï¼‰ã€‚

> æ‰€æœ‰æ•°æ®é›†å‡é‡‡æ · 300 æµ‹è¯•æ ·æœ¬ç”¨äºå…¬å¹³æ¯”è¾ƒã€‚

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**
- **æ¨¡å‹éª¨å¹²ï¼ˆBackbone Modelsï¼‰**ï¼š
  - Llama3-8B
  - Qwen3-8B
  - Qwen3-4B
- **è®­ç»ƒæ–¹å¼**ï¼š
  - ä½¿ç”¨ **Low-Rank Adaptation (LoRA)** è¿›è¡Œé«˜æ•ˆå¾®è°ƒ
  - é‡‡ç”¨ **Direct Preference Optimization (DPO)** æŸå¤±å‡½æ•°ï¼ˆÎ²=0.4ï¼‰
  - è®­ç»ƒ 3 è½®ï¼Œå­¦ä¹ ç‡ 1e-5ï¼Œbatch size=32
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **å‡†ç¡®ç‡ï¼ˆAccuracy %ï¼‰**ï¼šæœ€ç»ˆç­”æ¡ˆæ˜¯å¦æ­£ç¡®
  - **ä¿®æ­£æˆåŠŸç‡ï¼ˆCorrection Success Rateï¼‰**ï¼šåœ¨äººä¸ºæ³¨å…¥å™ªå£°å‰ç¼€åä»èƒ½å¾—å‡ºæ­£ç¡®ç­”æ¡ˆçš„æ¯”ä¾‹

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| åŸºçº¿æ–¹æ³• | ç®€ä»‹ |
|---------|------|
| **CoT** | æ ‡å‡†æ€ç»´é“¾æç¤ºï¼Œè´ªå©ªè§£ç  |
| **ToT** | Tree of Thoughtsï¼ŒåŸºäºæ ‘æœç´¢æ¢ç´¢å¤šæ¡è·¯å¾„ |
| **TS-SFT** | å¯¹ ToT ç”Ÿæˆçš„è·¯å¾„åšç›‘ç£å¾®è°ƒ |
| **CPO** | Chain of Preference Optimizationï¼ŒåŸºäºåå¥½ä¼˜åŒ–ä¸­é—´æ­¥éª¤ |
| **Step-DPO** | åœ¨é”™è¯¯æ­¥éª¤ä¸Šæ„å»ºåå¥½å¯¹è¿›è¡Œä¼˜åŒ– |
| **Full-Step-DPO** | å¯¹æ•´ä¸ªæ¨ç†è½¨è¿¹è¿›è¡Œå…¨å±€åå¥½ä¼˜åŒ– |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰**

| æ–¹æ³• | GSM8K | SVAMP | MATH-L1 | MATH-L2 | MATH-L3 | MATH-L4 | MATH-L5 |
|------|-------|--------|----------|----------|----------|----------|----------|
| CoT | 37.2 | 49.6 | 31.3 | 18.4 | 12.5 | 5.9 | 1.9 |
| ToT | 37.7 | 48.8 | 33.8 | 19.3 | 13.7 | 7.6 | 3.1 |
| CPO | 36.1 | 48.6 | 32.0 | 17.6 | 13.7 | 7.6 | 3.1 |
| Step-DPO | 38.1 | 48.4 | 32.0 | 17.6 | 13.7 | 7.6 | 3.1 |
| Full-Step-DPO | 39.6 | 50.4 | 34.3 | 19.5 | 14.2 | 8.0 | 3.3 |
| **DIFFCoT** | **65.5** | **83.5** | **62.0** | **39.2** | **26.1** | **15.0** | **5.4** |

> âœ… **DIFFCoT åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šå¤§å¹…è¶…è¶Šç°æœ‰æ–¹æ³•**ï¼Œå°¤å…¶åœ¨å¤æ‚ä»»åŠ¡ï¼ˆå¦‚ MATH-L5ï¼‰ä¸Šæå‡æ˜æ˜¾ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- åœ¨ **GSM8K** ä¸Šï¼ŒDIFFCoT è¾¾åˆ° **65.5%** å‡†ç¡®ç‡ï¼Œæ¯”ç¬¬äºŒå Full-Step-DPOï¼ˆ39.6%ï¼‰é«˜å‡ºè¿‘ **26 ä¸ªç™¾åˆ†ç‚¹**ã€‚
- åœ¨ **SVAMP** ä¸Šè¾¾åˆ° **83.5%**ï¼Œè¿œè¶…åŸºçº¿ï¼ˆ~50%ï¼‰ã€‚
- åœ¨æœ€éš¾çš„ **MATH-L5** ä¸Šï¼ŒDIFFCoT å¾—åˆ† **5.4%**ï¼Œæ˜¯å”¯ä¸€è¶…è¿‡ 5% çš„æ–¹æ³•ï¼Œæ˜¾ç¤ºå…¶å¤„ç†é«˜éš¾åº¦é•¿é“¾æ¨ç†çš„èƒ½åŠ›ã€‚

> ç»“è®ºï¼šDIFFCoT æ˜¾è‘—ä¼˜äºæ‰€æœ‰ SoTA PO æ–¹æ³•ï¼Œä¸”åœ¨ä¸åŒè§„æ¨¡æ¨¡å‹ï¼ˆ8B vs 4Bï¼‰ä¸Šå‡è¡¨ç°ç¨³å®šã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**

| æ¨¡å‹å˜ä½“ | GSM8K â†“ | SVAMP â†“ | è¯´æ˜ |
|---------|--------|--------|------|
| DIFFCoTï¼ˆå®Œæ•´ç‰ˆï¼‰ | 65.5 | 83.5 | â€” |
| - window size=1 | 61.1 | 80.7 | é€€åŒ–ä¸ºçº¯ AR æ¨¡å¼ï¼Œå¤±å»ä¿®æ­£èƒ½åŠ› |
| - window size=K | 60.1 | 82.7 | å…¨åºåˆ—å»å™ªç ´åå› æœç»“æ„ |
| - ç§»é™¤å› æœå™ªå£° | 60.8 | 80.2 | æ€§èƒ½ä¸‹é™ï¼Œè¯æ˜å› æœå™ªå£°è°ƒåº¦æœ‰æ•ˆ |

> ğŸ” å‘ç°ï¼š**ä¸­ç­‰å¤§å°çš„æ»‘åŠ¨çª—å£ï¼ˆéæç«¯å€¼ï¼‰æœ€ä¼˜**ï¼Œå¹³è¡¡äº†â€œå› æœè¿è´¯æ€§â€ä¸â€œçº é”™èƒ½åŠ›â€ã€‚

æ­¤å¤–ï¼Œåœ¨ **é”™è¯¯æ³¨å…¥å®éªŒï¼ˆError Accumulation Analysisï¼‰** ä¸­ï¼š
- å½“æ¨ç†ä¸­é€”æ³¨å…¥å™ªå£°æ—¶ï¼ŒDIFFCoT çš„ **ä¿®æ­£æˆåŠŸç‡å§‹ç»ˆé«˜äº Full-Step-DPO**ï¼Œå°¤å…¶æ˜¯åœ¨é«˜å™ªå£°å¼ºåº¦ï¼ˆÏ‰=0.4ï¼‰ä¸‹ä¼˜åŠ¿æ›´æ˜æ˜¾ã€‚
- è¡¨æ˜ DIFFCoT èƒ½æœ‰æ•ˆä»è¯­ä¹‰æ¼‚ç§»ä¸­æ¢å¤ï¼Œå…·å¤‡æ›´å¼ºçš„é²æ£’æ€§ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **CoT æ¨ç†ä¸åº”æ˜¯â€œä¸€æ¬¡æ€§â€è¿‡ç¨‹**ï¼šå…è®¸æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€ä¿®æ­£æ—©æœŸé”™è¯¯ï¼Œå¯ä»¥æ˜¾è‘—æå‡æœ€ç»ˆå‡†ç¡®æ€§ã€‚
2. **æ‰©æ•£æœºåˆ¶é€‚åˆå»ºæ¨¡æ¨ç†çº é”™**ï¼šå°†æ¨ç†é“¾è§†ä¸ºå¯è¿­ä»£ä¼˜åŒ–çš„å¯¹è±¡ï¼Œæ¯”é™æ€ç”Ÿæˆæ›´å…·é²æ£’æ€§ã€‚
3. **å› æœç»“æ„å¿…é¡»ä¿ç•™**ï¼šç›´æ¥å¥—ç”¨å›¾åƒæ‰©æ•£æ¨¡å‹ä¼šå¯¼è‡´æ¨ç†æ··ä¹±ï¼›é€šè¿‡è®¾è®¡å› æœæ„ŸçŸ¥çš„å™ªå£°è°ƒåº¦ï¼Œå¯åœ¨ä¿æŒé€»è¾‘é¡ºåºçš„åŒæ—¶å®ç°å»å™ªã€‚
4. **DIFFCoT å¯æ— ç¼é›†æˆåˆ°ç°ä»£ LLM**ï¼šæ— éœ€æ”¹å˜æ¶æ„ï¼Œä»…éœ€å¾®è°ƒå³å¯è·å¾—å·¨å¤§æ”¶ç›Šï¼Œå…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
1. **Off-policy æ•°æ®æ”¶é›†å¸¦æ¥åˆ†å¸ƒåç§»é£é™©**ï¼š
   - åå¥½æ•°æ®ç”± MCTS æ”¶é›†ï¼Œè€Œç›®æ ‡æ¨¡å‹ä¸åŒï¼Œå¯èƒ½å¯¼è‡´è®­ç»ƒä¸ç¨³å®šã€‚
2. **æ‰“ç ´å±€éƒ¨é©¬å°”å¯å¤«æ€§è´¨**ï¼š
   - å›æº¯ä¿®æ”¹å†å²æ­¥éª¤å¢åŠ äº†ç”Ÿæˆä¸ç¡®å®šæ€§ï¼Œéœ€è¦æ›´å¤šè®­ç»ƒæ•°æ®æ‰èƒ½æ”¶æ•›ã€‚
3. **è®­ç»ƒæˆæœ¬è¾ƒé«˜**ï¼š
   - ç›¸æ¯”æ ‡å‡† DPOï¼Œéœ€è¦æ„é€ å¤šå€™é€‰è½¨è¿¹å’Œå™ªå£°ç‰ˆæœ¬ï¼Œæ•°æ®å‡†å¤‡æ›´å¤æ‚ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ¢ç´¢å°† **Reinforcement Learning** ä¸æ‰©æ•£å»å™ªè¿‡ç¨‹ç»“åˆï¼Œè¿›ä¸€æ­¥ä¼˜åŒ– denoising dynamicsã€‚
- æ‰©å±•åˆ°æ›´å¤šæ¨ç†é¢†åŸŸï¼Œå¦‚ç¬¦å·æ¨ç†ã€ç¨‹åºåˆæˆã€ç§‘å­¦é—®ç­”ç­‰ã€‚
- ç ”ç©¶æ›´é«˜æ•ˆçš„åœ¨çº¿å»å™ªç­–ç•¥ï¼Œå‡å°‘æ¨ç†å»¶è¿Ÿã€‚

---

> ğŸ’¡ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **DIFFCoT é€šè¿‡å¼•å…¥æ‰©æ•£å¼çš„è¿­ä»£å»å™ªæœºåˆ¶ï¼Œé¦–æ¬¡å®ç°äº† CoT æ¨ç†ä¸­â€œè¾¹æƒ³è¾¹æ”¹â€çš„èƒ½åŠ›ï¼Œåœ¨ä¸ç‰ºç‰²è‡ªå›å½’æ•ˆç‡çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº† LLM å¤šæ­¥æ¨ç†çš„é²æ£’æ€§ä¸å‡†ç¡®æ€§ã€‚**

</details>

---

### 15. [Decide Then Retrieve: A Training-Free Framework with Uncertainty-Guided Triggering and Dual-Path Retrieval](https://arxiv.org/abs/2601.03908)

**Authors**: Wang Chen, Guanqiang Qi, Weikang Li, Yang Li, Deguo Xia, Jizhou Huang  
**Category**: cs.CL  
**Published**: 2026-01-08  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.03908v1  

#### Abstract
Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating external knowledge, but existing approaches indiscriminately trigger retrieval and rely on single-path evidence construction, often introducing noise and limiting performance gains. In this work, we propose D...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šDecide Then Retrieve: A Training-Free Framework with Uncertainty-Guided Triggering and Dual-Path Retrieval**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

ä¼ ç»Ÿçš„ **Retrieval-Augmented Generation (RAG)** å­˜åœ¨ä¸¤ä¸ªå…³é”®ç¼ºé™·ï¼š

1. **æ— å·®åˆ«è§¦å‘æ£€ç´¢ï¼ˆIndiscriminate Retrieval Triggeringï¼‰**  
   æ‰€æœ‰æŸ¥è¯¢éƒ½å¼ºåˆ¶è§¦å‘æ£€ç´¢ï¼Œå³ä½¿ç®€å•é—®é¢˜æœ¬å¯ç”± LLM çš„å‚æ•°åŒ–çŸ¥è¯†ç›´æ¥å›ç­”ï¼Œå¯¼è‡´å¼•å…¥æ— å…³å™ªå£°ï¼Œé™ä½ç”Ÿæˆè´¨é‡ã€‚

2. **å•è·¯å¾„è¯æ®æ„å»ºè„†å¼±ï¼ˆSingle-Path Evidence Constructionï¼‰**  
   å¯¹äºç¨€ç–æˆ–æ¨¡ç³ŠæŸ¥è¯¢ï¼ˆsparse queriesï¼‰ï¼Œä»…ä¾èµ–åŸå§‹æŸ¥è¯¢è¿›è¡Œæ£€ç´¢ï¼Œè¯­ä¹‰ä¿¡å·ä¸è¶³ï¼Œå®¹æ˜“å¬å›ä½ç›¸å…³æ€§æ–‡æ¡£ï¼Œå½±å“ç­”æ¡ˆå‡†ç¡®æ€§ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **Decide Then Retrieve (DTR)** â€”â€” ä¸€ç§æ— éœ€è®­ç»ƒã€æ¨¡å‹æ— å…³ï¼ˆmodel-agnosticï¼‰çš„ RAG æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†æ£€ç´¢è§†ä¸ºä¸€ä¸ª**æ¡ä»¶åŒ–ã€è‡ªé€‚åº”çš„è¿‡ç¨‹**ï¼ŒåŒ…å«ä¸¤å¤§åˆ›æ–°æœºåˆ¶ï¼š

#### **(1) Uncertainty-Guided Triggering (UGT)**  
åˆ©ç”¨ LLM è‡ªèº«ç”Ÿæˆè¿‡ç¨‹ä¸­çš„ **generation uncertainty**ï¼ˆå½’ä¸€åŒ–çš„è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼‰æ¥åˆ¤æ–­æ˜¯å¦éœ€è¦è§¦å‘æ£€ç´¢ï¼š
- è‹¥ä¸ç¡®å®šæ€§ä½ï¼ˆæ¨¡å‹è‡ªä¿¡ï¼‰ï¼Œåˆ™è·³è¿‡æ£€ç´¢ï¼Œé¿å…å™ªå£°ï¼›
- è‹¥ä¸ç¡®å®šæ€§é«˜ï¼Œåˆ™æ¿€æ´»æ£€ç´¢ï¼Œå€ŸåŠ©å¤–éƒ¨çŸ¥è¯†æå‡å‡†ç¡®æ€§ã€‚

#### **(2) Dual-Path Retrieval with Adaptive Information Selection (DPR-AIS)**  
é’ˆå¯¹ç¨€ç–æŸ¥è¯¢ï¼Œæå‡ºåŒè·¯å¾„æ£€ç´¢æœºåˆ¶ï¼š
- åŒæ—¶åŸºäº **åŸå§‹æŸ¥è¯¢ï¼ˆqueryï¼‰** å’Œ **LLM ç”Ÿæˆçš„ä¼ªä¸Šä¸‹æ–‡ï¼ˆpseudo-contextï¼‰** è¿›è¡Œç‹¬ç«‹æ£€ç´¢ï¼›
- é€šè¿‡ **Adaptive Information Selection (AIS)** æœºåˆ¶èåˆä¸¤è·¯ç»“æœï¼Œé€‰æ‹©åœ¨ä¸¤ä¸ªè§†è§’ä¸‹å‡ç›¸å…³çš„æ–‡æ¡£ï¼›
- åˆ©ç”¨å‡ ä½•è§’åº¦ï¼ˆcos(Î¸â‚ + Î¸â‚‚)ï¼‰å»ºæ¨¡è”åˆç›¸å…³æ€§ï¼Œå¢å¼ºé²æ£’æ€§ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | DTR çš„ä¼˜åŠ¿ |
|------|-----------|
| **æ— éœ€è®­ç»ƒ** | ä¸ä¾èµ–é¢å¤–åˆ†ç±»å™¨æˆ–å¾®è°ƒï¼Œå¯å³æ’å³ç”¨åˆ°ç°æœ‰ RAG ç³»ç»Ÿ |
| **å‡å°‘å™ªå£°** | UGT é¿å…å¯¹ç®€å•é—®é¢˜è¿›è¡Œä¸å¿…è¦çš„æ£€ç´¢ |
| **æå‡å¬å›è´¨é‡** | DPR-AIS æ˜¾è‘—æ”¹å–„ç¨€ç–æŸ¥è¯¢ä¸‹çš„æ£€ç´¢ç›¸å…³æ€§ |
| **é€šç”¨æ€§å¼º** | åœ¨ä¸åŒæ¨¡å‹è§„æ¨¡ï¼ˆ7B / 72Bï¼‰ã€ä¸åŒ retrieverï¼ˆbge / e5ï¼‰ã€å¤šç§æ•°æ®é›†ä¸Šè¡¨ç°ç¨³å®š |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**

åœ¨äº”ä¸ªå¼€æ”¾åŸŸ QA æ•°æ®é›†ä¸Šè¿›è¡Œè¯„ä¼°ï¼š

| æ•°æ®é›† | ç±»å‹ | æ–‡æ¡£æ•°é‡ |
|--------|------|----------|
| **NaturalQA** | å¼€æ”¾åŸŸé—®ç­” | 21M |
| **WebQuestions** | çŸ¥è¯†åº“é—®ç­” | 21M |
| **SQuAD** | æŠ½å–å¼é—®ç­” | 21M |
| **TriviaQA** | å¤šæ ·åŒ–é—®ç­” | 21M |
| **HotpotQA** | å¤šè·³æ¨ç† | 5M |

æ£€ç´¢è¯­æ–™ä¸ºè‹±æ–‡ç»´åŸºç™¾ç§‘ï¼ˆ21M åˆ†å—ï¼‰æˆ– HotpotQA è‡ªå¸¦è¯­æ–™ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

- **ç”Ÿæˆæ¨¡å‹**ï¼šQwen2.5-7B-Instruct å’Œ Qwen2.5-72B-Instruct
- **æ£€ç´¢å™¨**ï¼šbge-large-en-v1.5 å’Œ e5
- **æ£€ç´¢æ·±åº¦**ï¼štop-3 æˆ– top-5
- **è§£ç ç­–ç•¥**ï¼štemperature = 0.0ï¼ˆç¡®å®šæ€§è¾“å‡ºï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Exact Match (EM)**ï¼šé¢„æµ‹ç­”æ¡ˆä¸ä»»ä¸€æ ‡å‡†ç­”æ¡ˆå®Œå…¨åŒ¹é…çš„æ¯”ä¾‹
  - **F1 Score**ï¼štoken çº§åˆ«çš„é‡å åˆ†æ•°ï¼Œæ›´å®½å®¹

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿æ–¹æ³• | ç®€è¦è¯´æ˜ |
|---------|--------|
| **No Retrieval** | ä»…ä½¿ç”¨ LLM å‚æ•°çŸ¥è¯†ç”Ÿæˆç­”æ¡ˆ |
| **Standard RAG** | æ ‡å‡† RAGï¼Œæ‰€æœ‰æŸ¥è¯¢å‡è§¦å‘æ£€ç´¢ |
| **LLM Judge** | ä½¿ç”¨ LLM åˆ¤æ–­æ˜¯å¦éœ€è¦æ£€ç´¢ï¼ˆå¦‚â€œæ˜¯å¦éœ€è¦å¤–éƒ¨ä¿¡æ¯ï¼Ÿâ€ï¼‰ |
| **HyDE** | ä½¿ç”¨ LLM ç”Ÿæˆå‡è®¾æ–‡æ¡£ç”¨äºæ£€ç´¢ |
| **Q2D** | å°†åŸå§‹æŸ¥è¯¢ä¸ä¼ªæ–‡æ¡£æ‹¼æ¥åæ£€ç´¢ |
| **CoT** | å…ˆç”Ÿæˆæ¨ç†é“¾ï¼Œå†ç»“åˆæŸ¥è¯¢è¿›è¡Œæ£€ç´¢ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 2 & Table 7ï¼‰**

åœ¨ **Qwen2.5-7B-Instruct + bge** è®¾ç½®ä¸‹ï¼ŒDTR ç›¸æ¯” Standard RAG æ˜¾è‘—æå‡ï¼š

| æ–¹æ³• | Average EM | Average F1 |
|------|------------|------------|
| Standard RAG | 35.81 | 45.81 |
| **DTR (u=0.001)** | **37.87** (+2.06) | **48.08** (+2.27) |

åœ¨æ›´å¤§æ¨¡å‹ **Qwen2.5-72B-Instruct** ä¸Šï¼š
| æ–¹æ³• | Average EM | Average F1 |
|------|------------|------------|
| Standard RAG | 38.83 | 50.73 |
| **DTR (u=0.005)** | **40.46** (+1.63) | **52.14** (+1.41) |

ä½¿ç”¨ **e5 retriever** æ—¶ï¼ŒDTR ä»ä¼˜äº Standard RAGï¼š
- å¹³å‡ EM æå‡ **1.56**ï¼ˆä» 36.86 â†’ 38.42ï¼‰
- å¹³å‡ F1 æå‡ **1.68**ï¼ˆä» 47.18 â†’ 48.86ï¼‰

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- DTR åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šå‡è¾¾åˆ° **æœ€ä½³æˆ–æ¬¡ä½³æ€§èƒ½**ï¼›
- æ˜æ˜¾ä¼˜äº HyDEã€Q2Dã€CoT ç­‰ query expansion æ–¹æ³•ï¼›
- ç›¸æ¯” LLM Judgeï¼š
  - å°æ¨¡å‹ç‰ˆï¼ˆ7Bï¼‰å‡ ä¹ä¸è§¦å‘æ£€ç´¢ï¼Œæ€§èƒ½æ¥è¿‘ No Retrievalï¼›
  - å¤§æ¨¡å‹ç‰ˆï¼ˆ72Bï¼‰é¢‘ç¹è§¦å‘ä½†ä»ä¸å¦‚ DTRï¼›
- è¡¨æ˜ **åŸºäº uncertainty çš„åŠ¨æ€å†³ç­–ä¼˜äºå¯å‘å¼åˆ¤æ–­**ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆTable 3ï¼‰**

éªŒè¯å„ç»„ä»¶è´¡çŒ®ï¼ˆä»¥ 7B æ¨¡å‹ä¸ºä¾‹ï¼‰ï¼š

| æ–¹æ³•å˜ä½“ | Average EM | Average F1 | ç›¸æ¯”å®Œæ•´ DTR ä¸‹é™ |
|--------|------------|------------|------------------|
| **DTR (å®Œæ•´)** | 37.87 | 48.08 | â€” |
| w/o UGT | 37.84 | 48.13 | åŸºæœ¬æŒå¹³ï¼ˆç•¥ä¼˜ï¼‰ |
| w/o DPR | 35.98 | 45.86 | â†“1.89 EM / â†“2.22 F1 |
| w/o AIS (1q+2p) | 31.15 | 40.32 | â†“6.72 EM / â†“7.76 F1 |

> âœ… **ç»“è®º**ï¼šDPR å’Œ AIS æ˜¯æ ¸å¿ƒç»„ä»¶ï¼›UGT è™½éæ˜¾è‘—å¢ç›Šï¼Œä½†èƒ½æœ‰æ•ˆå‡å°‘ä¸å¿…è¦æ£€ç´¢ï¼ˆè§ Trigger Ratioï¼‰ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**

1. **Generation uncertainty æ˜¯æœ‰æ•ˆçš„æ£€ç´¢è§¦å‘ä¿¡å·**  
   - ä¸ç¡®å®šæ€§è¶Šä½ï¼Œparametric accuracy è¶Šé«˜ï¼›
   - å¼ºåˆ¶æ£€ç´¢åè€Œå¯èƒ½å› å™ªå£°é™ä½å‡†ç¡®ç‡ï¼›
   - DTR å¯åŠ¨æ€å¹³è¡¡â€œä½•æ—¶æ£€ç´¢â€ã€‚

2. **Dual-Path Retrieval æ˜¾è‘—æå‡ç¨€ç–æŸ¥è¯¢çš„å¬å›è´¨é‡**  
   - æŸ¥è¯¢ä¸ GT æ–‡æ¡£ç›¸ä¼¼åº¦å¸¸ä½äº 0.8ï¼ˆFig. 7ï¼‰ï¼›
   - ä¼ªä¸Šä¸‹æ–‡å¯å¼¥è¡¥è¯­ä¹‰é¸¿æ²Ÿï¼Œå…¶åˆ†å¸ƒæ›´æ¥è¿‘ GT æ–‡æ¡£ï¼ˆFig. 9â€“10ï¼‰ï¼›
   - DPR åœ¨ HotpotQA ä¸Š Recall@3 è¾¾ **62.7%**ï¼Œé«˜äº Standard RAGï¼ˆ61.9%ï¼‰ã€‚

3. **Adaptive Information Selection è‡³å…³é‡è¦**  
   - å›ºå®šæ¯”ä¾‹èåˆï¼ˆå¦‚ 1q+2pï¼‰æ€§èƒ½å¤§å¹…ä¸‹é™ï¼›
   - åŠ¨æ€åŠ æƒé€‰æ‹©èƒ½æ›´å¥½è¿‡æ»¤å™ªå£°ã€‚

4. **DTR å…·æœ‰è‰¯å¥½çš„æ³›åŒ–æ€§å’Œé²æ£’æ€§**  
   - åœ¨ä¸åŒæ¨¡å‹è§„æ¨¡ã€ä¸åŒ retrieverã€ä¸åŒæ£€ç´¢æ·±åº¦ä¸‹å‡ä¸€è‡´ä¼˜äº baselineã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **ä¾èµ– uncertainty ä¼°è®¡çš„è´¨é‡**  
   - ä¸åŒ decoding ç­–ç•¥æˆ–æ¨¡å‹å®¶æ—å¯èƒ½å¯¼è‡´ uncertainty åˆ†å¸ƒå˜åŒ–ï¼›
   - å½“å‰åŸºäº token-level NLLï¼Œå¯èƒ½ä¸å¤Ÿç¨³å®šã€‚

2. **å¢åŠ æ¨ç†å»¶è¿Ÿ**  
   - ç”Ÿæˆ pseudo-context å¢åŠ ä¸€æ¬¡å‰å‘æ¨ç†ï¼›
   - åŒè·¯å¾„æ£€ç´¢éœ€ä¸¤æ¬¡ç‹¬ç«‹æ£€ç´¢æ“ä½œã€‚

3. **æ€§èƒ½ä»å—é™äºæ£€ç´¢è¯­æ–™å’Œ embedding è´¨é‡**  
   - è‹¥ corpus ä¸å…¨æˆ– embedding ä¸å‡†ï¼ŒDPR æ•ˆæœå—é™ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

- æ¢ç´¢æ›´é«˜æ•ˆçš„ uncertainty ä¼°è®¡æ–¹å¼ï¼ˆå¦‚ logits varianceï¼‰ï¼›
- ç»“åˆ reranker è¿›ä¸€æ­¥ä¼˜åŒ–æ–‡æ¡£é€‰æ‹©ï¼›
- å°† DTR æ‰©å±•è‡³å¤šæ¨¡æ€ RAG åœºæ™¯ï¼›
- ç ”ç©¶å¦‚ä½•åœ¨ agent æˆ–æœç´¢ç³»ç»Ÿä¸­åŠ¨æ€é›†æˆ DTR å†³ç­–æœºåˆ¶ã€‚

---

> ğŸ”— **ä»£ç ä¸æ•°æ®**ï¼šhttps://github.com/ChenWangHKU/DTR

</details>

---

### 16. [Bridging the Discrete-Continuous Gap: Unified Multimodal Generation via Coupled Manifold Discrete Absorbing Diffusion](https://arxiv.org/abs/2601.04056)

**Authors**: Yuanfeng Xu, Yuhao Chen, Liang Lin, Guangrun Wang  
**Category**: cs.CL  
**Published**: 2026-01-08  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.04056v1  

#### Abstract
The bifurcation of generative modeling into autoregressive approaches for discrete data (text) and diffusion approaches for continuous data (images) hinders the development of truly unified multimodal systems. While Masked Language Models (MLMs) offer efficient bidirectional context, they traditiona...

---

### 17. [Weather-Aware Transformer for Real-Time Route Optimization in Drone-as-a-Service Operations](https://arxiv.org/abs/2601.03376)

**Authors**: Kamal Mohamed, Lillian Wassim, Ali Hamdi, Khaled Shaban  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.03376v1  

#### Abstract
This paper presents a novel framework to accelerate route prediction in Drone-as-a-Service operations through weather-aware deep learning models. While classical path-planning algorithms, such as A* and Dijkstra, provide optimal solutions, their computational complexity limits real-time applicabilit...

---

### 18. [ROI-Reasoning: Rational Optimization for Inference via Pre-Computation Meta-Cognition](https://arxiv.org/abs/2601.03822)

**Authors**: Muyang Zhao, Qi Qi, Hao Sun  
**Category**: cs.AI  
**Published**: 2026-01-08  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.03822v1  

#### Abstract
Large language models (LLMs) can achieve strong reasoning performance with sufficient computation, but they do not inherently know how much computation a task requires. We study budgeted inference-time reasoning for multiple tasks under a strict global token constraint and formalize it as a Ordered ...

---

### 19. [Trade-R1: Bridging Verifiable Rewards to Stochastic Environments via Process-Level Reasoning Verification](https://arxiv.org/abs/2601.03948)

**Authors**: Rui Sun, Yifan Sun, Sheng Xu, Li Zhao, Jing Li, Daxin Jiang, Chen Hua, Zuo Bai  
**Category**: cs.AI  
**Published**: 2026-01-08  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.03948v1  

#### Abstract
Reinforcement Learning (RL) has enabled Large Language Models (LLMs) to achieve remarkable reasoning in domains like mathematics and coding, where verifiable rewards provide clear signals. However, extending this paradigm to financial decision is challenged by the market's stochastic nature: rewards...

---

### 20. [Atlas: Orchestrating Heterogeneous Models and Tools for Multi-Domain Complex Reasoning](https://arxiv.org/abs/2601.03872)

**Authors**: Jinyang Wu, Guocheng Zhai, Ruihan Jin, Jiahao Yuan, Yuhao Shen, Shuai Zhang, Zhengqi Wen, Jianhua Tao  
**Category**: cs.CL  
**Published**: 2026-01-08  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.03872v1  

#### Abstract
The integration of large language models (LLMs) with external tools has significantly expanded the capabilities of AI agents. However, as the diversity of both LLMs and tools increases, selecting the optimal model-tool combination becomes a high-dimensional optimization challenge. Existing approache...

---

### 21. [SIGMA: Scalable Spectral Insights for LLM Collapse](https://arxiv.org/abs/2601.03385)

**Authors**: Yi Gu, Lingyou Pang, Xiangkun Ye, Tianyu Wang, Jianyu Lin, Carey E. Priebe, Alexander Aue  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.03385v1  

#### Abstract
The rapid adoption of synthetic data for training Large Language Models (LLMs) has introduced the technical challenge of "model collapse"-a degenerative process where recursive training on model-generated content leads to a contraction of distributional variance and representational quality. While t...

---

### 22. [Sensor to Pixels: Decentralized Swarm Gathering via Image-Based Reinforcement Learning](https://arxiv.org/abs/2601.03413)

**Authors**: Yigal Koifman, Eran Iceland, Erez Koifman, Ariel Barel, Alfred M. Bruckstein  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.03413v1  

#### Abstract
This study highlights the potential of image-based reinforcement learning methods for addressing swarm-related tasks. In multi-agent reinforcement learning, effective policy learning depends on how agents sense, interpret, and process inputs. Traditional approaches often rely on handcrafted feature ...

---

### 23. [LinkD: AutoRegressive Diffusion Model for Mechanical Linkage Synthesis](https://arxiv.org/abs/2601.04054)

**Authors**: Yayati Jadhav, Amir Barati Farimani  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.04054v1  

#### Abstract
Designing mechanical linkages to achieve target end-effector trajectories presents a fundamental challenge due to the intricate coupling between continuous node placements, discrete topological configurations, and nonlinear kinematic constraints. The highly nonlinear motion-to-configuration relation...

---

### 24. [Digital Red Queen: Adversarial Program Evolution in Core War with LLMs](https://arxiv.org/abs/2601.03335)

**Authors**: Akarsh Kumar, Ryan Bahlous-Boldi, Prafull Sharma, Phillip Isola, Sebastian Risi, Yujin Tang, David Ha  
**Category**: cs.AI  
**Published**: 2026-01-08  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.03335v1  

#### Abstract
Large language models (LLMs) are increasingly being used to evolve solutions to problems in many domains, in a process inspired by biological evolution. However, unlike biological evolution, most LLM-evolution frameworks are formulated as static optimization problems, overlooking the open-ended adve...

---

### 25. [Evolving Programmatic Skill Networks](https://arxiv.org/abs/2601.03509)

**Authors**: Haochen Shi, Xingdi Yuan, Bang Liu  
**Category**: cs.AI  
**Published**: 2026-01-08  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.03509v1  

#### Abstract
We study continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills. We introduce the Programmatic Skill Network (PSN), a framework in which skills are executable symbolic programs forming a compositional...

---

### 26. [eTracer: Towards Traceable Text Generation via Claim-Level Grounding](https://arxiv.org/abs/2601.03669)

**Authors**: Bohao Chu, Qianli Wang, Hendrik Damm, Hui Wang, Ula Muhabbek, Elisabeth Livingstone, Christoph M. Friedrich, Norbert Fuhr  
**Category**: cs.CL  
**Published**: 2026-01-08  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.03669v1  

#### Abstract
How can system-generated responses be efficiently verified, especially in the high-stakes biomedical domain? To address this challenge, we introduce eTracer, a plug-and-play framework that enables traceable text generation by grounding claims against contextual evidence. Through post-hoc grounding, ...

---

### 27. [What Does Loss Optimization Actually Teach, If Anything? Knowledge Dynamics in Continual Pre-training of LLMs](https://arxiv.org/abs/2601.03858)

**Authors**: Seyed Mahed Mousavi, Simone Alghisi, Giuseppe Riccardi  
**Category**: cs.CL  
**Published**: 2026-01-08  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.03858v1  

#### Abstract
Continual Pre-Training (CPT) is widely used for acquiring and updating factual knowledge in LLMs. This practice treats loss as a proxy for knowledge learning, while offering no grounding into how it changes during training. We study CPT as a knowledge learning process rather than a solely optimizati...

---

### 28. [Evaluating Small Decoder-Only Language Models for Grammar Correction and Text Simplification](https://arxiv.org/abs/2601.03874)

**Authors**: Anthony Lamelas  
**Category**: cs.CL  
**Published**: 2026-01-08  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.03874v1  

#### Abstract
Large language models have become extremely popular recently due to their ability to achieve strong performance on a variety of tasks, such as text generation and rewriting, but their size and computation cost make them difficult to access, deploy, and secure in many settings. This paper investigate...

---

### 29. [Modular Prompt Optimization: Optimizing Structured Prompts with Section-Local Textual Gradients](https://arxiv.org/abs/2601.04055)

**Authors**: Prith Sharma, Austin Z. Henley  
**Category**: cs.CL  
**Published**: 2026-01-08  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.04055v1  

#### Abstract
Prompt quality plays a central role in controlling the behavior, reliability, and reasoning performance of large language models (LLMs), particularly for smaller open-source instruction-tuned models that depend heavily on explicit structure. While recent work has explored automatic prompt optimizati...

---

### 30. [Variational Inference, Entropy, and Orthogonality: A Unified Theory of Mixture-of-Experts](https://arxiv.org/abs/2601.03577)

**Authors**: Ye Su, Yong Liu  
**Category**: cs.LG  
**Published**: 2026-01-08  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.03577v1  

#### Abstract
Mixture-of-Experts models enable large language models to scale efficiently, as they only activate a subset of experts for each input. Their core mechanisms, Top-k routing and auxiliary load balancing, remain heuristic, however, lacking a cohesive theoretical underpinning to support them. To this en...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- kv cache, offload, State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
