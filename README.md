# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-18 05:57:44 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Multiscale Aggregated Hierarchical Attention (MAHA): A Game Theoretic and Optimization Driven Approach to Efficient Contextual Modeling in Large Language Models](https://arxiv.org/abs/2512.14925)

**Authors**: Caner Erden  
**Category**: cs.CL  
**Published**: 2025-12-18  
**Score**: 12.5  
**Type**: new  
**ArXiv ID**: 2512.14925v1  

#### Abstract
The quadratic computational complexity of MultiHead SelfAttention (MHSA) remains a fundamental bottleneck in scaling Large Language Models (LLMs) for longcontext tasks. While sparse and linearized attention mechanisms attempt to mitigate this, they often compromise the representation of global depen...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMultiscale Aggregated Hierarchical Attention (MAHA)

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
- **æ ‡å‡† Multi-Head Self-Attention (MHSA)** å­˜åœ¨ **äºŒæ¬¡è®¡ç®—å¤æ‚åº¦** $O(n^2)$ï¼Œä¸¥é‡é™åˆ¶äº† Large Language Models (LLMs) åœ¨é•¿åºåˆ—ä»»åŠ¡ä¸­çš„æ‰©å±•èƒ½åŠ›ã€‚
- ç°æœ‰ç¨€ç–æ³¨æ„åŠ›ï¼ˆå¦‚ Longformerã€BigBirdï¼‰æˆ–çº¿æ€§åŒ–æ–¹æ³•ï¼ˆå¦‚ Performerï¼‰è™½ç„¶é™ä½äº†è®¡ç®—å¼€é”€ï¼Œä½†å¾€å¾€ç‰ºç‰²äº†å¯¹å…¨å±€ä¾èµ–å…³ç³»çš„å»ºæ¨¡èƒ½åŠ›ï¼Œæˆ–æ— æ³•æœ‰æ•ˆæ•æ‰å¤šå°ºåº¦è¯­ä¹‰ç²’åº¦ã€‚

### ğŸ†• æå‡ºçš„æ–°æ–¹æ³•ï¼šMAHA
æå‡º **Multiscale Aggregated Hierarchical Attention (MAHA)**ï¼Œä¸€ç§åŸºäº**åˆ†å±‚åˆ†è§£**ä¸**æ•°å­¦ä¼˜åŒ–é©±åŠ¨èšåˆ**çš„æ–°å‹æ³¨æ„åŠ›æ¶æ„æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰å¤šå°ºåº¦åˆ†å±‚åˆ†è§£ï¼ˆMultiscale Decompositionï¼‰
- å°†è¾“å…¥åºåˆ—é€šè¿‡å¯å­¦ä¹ çš„ä¸‹é‡‡æ ·æ“ä½œï¼ˆstrided convolution æˆ– adaptive poolingï¼‰åŠ¨æ€åˆ’åˆ†ä¸ºå¤šä¸ªå±‚çº§ï¼ˆscalesï¼‰ï¼Œå½¢æˆé‡‘å­—å¡”ç»“æ„ã€‚
- ä¸åŒå±‚çº§åˆ†åˆ«æ•è·ä¸åŒæŠ½è±¡çº§åˆ«çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼šç»†ç²’åº¦ï¼ˆå±€éƒ¨è¯­æ³•ï¼‰ã€ä¸­ç­‰ç²’åº¦ï¼ˆå­å¥çº§ï¼‰ã€ç²—ç²’åº¦ï¼ˆæ–‡æ¡£ä¸»é¢˜ï¼‰ã€‚

#### ï¼ˆ2ï¼‰ä¼˜åŒ–é©±åŠ¨çš„èšåˆæœºåˆ¶ï¼ˆOptimization-Driven Aggregationï¼‰
- å¼•å…¥ä¸¤ç§ç†è®ºä¸¥è°¨çš„èšåˆç­–ç•¥ï¼Œæ›¿ä»£ä¼ ç»ŸåŠ æƒå¹³å‡ç­‰å¯å‘å¼èåˆæ–¹å¼ï¼š
  - **å‡¸ä¼˜åŒ–ï¼ˆConvex Optimization, COï¼‰**ï¼šå°†å¤šå°ºåº¦è¾“å‡ºèåˆå»ºæ¨¡ä¸ºå¸¦çº¦æŸçš„ä¼˜åŒ–é—®é¢˜ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–é‡æ„è¯¯å·®å¹¶é¼“åŠ±ç¨€ç–é€‰æ‹©é‡è¦å°ºåº¦ã€‚
  - **åšå¼ˆè®ºçº³ä»€å‡è¡¡ï¼ˆNash Equilibrium, NEï¼‰**ï¼šå°†å„å°ºåº¦è§†ä¸ºâ€œç©å®¶â€ï¼Œç«äº‰å½±å“æœ€ç»ˆè¡¨ç¤ºï¼›èšåˆæƒé‡ç”±éåˆä½œåšå¼ˆçš„çº³ä»€å‡è¡¡å†³å®šï¼Œç¡®ä¿æ— å•ä¸€å°ºåº¦å¯é€šè¿‡å•æ–¹é¢æ”¹å˜æå‡è‡ªèº«æ•ˆç”¨ã€‚

#### ï¼ˆ3ï¼‰æ··åˆç¨€ç–å·ç§¯ä¸»å¹²è®¾è®¡
- é›†æˆ **dilated convolution** æ•æ‰å±€éƒ¨ä¸Šä¸‹æ–‡ï¼›
- ä½¿ç”¨è·¨å°ºåº¦é—¨æ§ï¼ˆcross-scale gatingï¼‰å¢å¼ºå±‚çº§é—´ä¿¡æ¯æµåŠ¨ï¼›
- æ•´ä½“ä½œä¸º Transformer ä¸­ MHSA å±‚çš„å³æ’å³ç”¨æ›¿ä»£æ–¹æ¡ˆã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | MAHA | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ Sparse Attention / Hierarchical Attentionï¼‰ |
|------|------|--------------------------------------------------------|
| **è®¡ç®—æ•ˆç‡** | è¿‘çº¿æ€§å¤æ‚åº¦ $O(n)$ï¼Œæ˜¾è‘—é™ä½ FLOPs å’Œå†…å­˜å ç”¨ | å¤šæ•°ä»å­˜åœ¨å±€éƒ¨äºŒæ¬¡é¡¹æˆ–å›ºå®šæ¨¡å¼ç“¶é¢ˆ |
| **ä¸Šä¸‹æ–‡å»ºæ¨¡** | æ˜¾å¼ä¿ç•™å¤šå°ºåº¦è¯­ä¹‰ï¼Œå…¼é¡¾å±€éƒ¨ç»†èŠ‚ä¸å…¨å±€ä¸€è‡´æ€§ | èšåˆæ–¹å¼ç®€å•ï¼Œæ˜“å¯¼è‡´ä¿¡æ¯ç¨€é‡Š |
| **ç†è®ºåŸºç¡€** | åŸºäºå‡¸ä¼˜åŒ–æˆ–åšå¼ˆè®ºï¼Œæä¾›æœ€ä¼˜æ€§ä¿è¯ | å¤šä¸ºç»éªŒæ€§è®¾è®¡ï¼Œç¼ºä¹ç†è®ºæ”¯æ’‘ |
| **çµæ´»æ€§** | å¯é€‚é…å¤šç§ Transformer æ¶æ„ï¼Œå…¼å®¹ç°æœ‰è®­ç»ƒæµç¨‹ | å¾€å¾€éœ€ç‰¹å®šç»“æ„è°ƒæ•´ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–å››ç±»å…¸å‹ NLP ä»»åŠ¡ï¼Œæ¶µç›–é•¿çŸ­ä¸Šä¸‹æ–‡åœºæ™¯ï¼š

| ä»»åŠ¡ | æ•°æ®é›† | ç‰¹ç‚¹ |
|------|-------|------|
| æ–‡æœ¬åˆ†ç±» | **GLUE**ï¼ˆMNLI, SST-2ï¼‰ | æ ‡å‡†ç†è§£ä»»åŠ¡ï¼Œæµ‹è¯•é€šç”¨è¡¨å¾èƒ½åŠ› |
| é•¿è·ç¦»ä¾èµ–å»ºæ¨¡ | **PG-19**ï¼ˆ>4k tokensï¼‰ | è¶…é•¿æ–‡æœ¬è¯­è¨€å»ºæ¨¡ï¼Œè€ƒéªŒè¿œè·ä¾èµ–æ•æ‰ |
| æœºå™¨ç¿»è¯‘ | **WMT14 En-De** | åºåˆ—åˆ°åºåˆ—ç”Ÿæˆä»»åŠ¡ |
| é—®ç­”ç³»ç»Ÿ | **SQuAD v2.0** | ä¸Šä¸‹æ–‡é˜…è¯»ç†è§£ï¼Œè¦æ±‚ç²¾å‡†å®šä½ |

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼š12å±‚ Transformerï¼Œéšè—ç»´åº¦ 768ï¼Œ12 ä¸ª attention head
- **è®­ç»ƒå‚æ•°**ï¼š
  - Batch Sizeï¼š32ï¼ˆåˆ†ç±»/QAï¼‰ï¼Œ16ï¼ˆç¿»è¯‘ï¼‰
  - å­¦ä¹ ç‡ï¼š$5 \times 10^{-5}$ï¼Œwarmup 10k æ­¥
- **åºåˆ—é•¿åº¦**ï¼š
  - åˆ†ç±»/é—®ç­”ï¼š512
  - PG-19ï¼ˆé•¿æ–‡æœ¬ï¼‰ï¼š4096
- **MAHA å‚æ•°é…ç½®**ï¼š
  - å±‚æ•° $L=4$ï¼ˆtoken æ•°åˆ†åˆ«ä¸º 32, 64, 128, 256ï¼‰
  - ä¸‹é‡‡æ ·æ ¸å¤§å° kernel=3
  - èšåˆæ­£åˆ™åŒ–ç³»æ•° $\lambda=0.1$

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿æ¨¡å‹ | ç±»å‹ |
|--------|------|
| Standard MHA (Vaswani et al., 2017) | å…¨æ³¨æ„åŠ›åŸºå‡† |
| Longformer (Beltagy et al., 2020) | å±€éƒ¨+å…¨å±€ç¨€ç–æ³¨æ„åŠ› |
| BigBird (Zaheer et al., 2020) | å±€éƒ¨+éšæœº+å…¨å±€ç¨€ç– |
| Reformer (Kitaev et al., 2020) | LSH-based æ³¨æ„åŠ› |
| Performer (Choromanski et al., 2020) | æ ¸å‡½æ•°è¿‘ä¼¼çº¿æ€§æ³¨æ„åŠ› |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰

| Model | MNLI (Acc) | SST-2 (Acc) | PG-19 (PPLâ†“) | WMT (BLEU) | SQuAD (F1) | Memory (GB)â†“ | Throughput (seq/s)â†‘ |
|-------|------------|-------------|---------------|------------|------------|----------------|------------------------|
| Standard MHA | 86.2 | 93.5 | 24.3 | 28.7 | 88.4 | 15.2 | 42 |
| Longformer | 85.7 | 92.8 | 23.8 | 27.9 | 87.6 | 9.1 | 58 |
| BigBird | 85.9 | 93.1 | 23.5 | 28.1 | 87.9 | 10.3 | 53 |
| Reformer | 84.3 | 91.7 | 25.6 | 26.4 | 85.2 | 7.8 | 62 |
| Performer | 85.1 | 92.4 | 24.9 | 27.3 | 86.7 | 8.5 | 67 |
| **MAHA** | **86.0** | **93.3** | **23.1** | **28.5** | **88.2** | **2.5** | **71** |

> æ³¨ï¼šMemory å’Œ Throughput ä¸­ MHA/MAHA ä¸ºæœ¬åœ° GPU æµ‹é‡å€¼ï¼Œå…¶ä½™æ¥è‡ªåŸè®ºæ–‡ã€‚

### ğŸ” æ€§èƒ½åˆ†æè¦ç‚¹
- **ç²¾åº¦è¡¨ç°**ï¼šMAHA åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šå‡è¾¾åˆ°ä¸æ ‡å‡† MHA ç›¸å½“ç”šè‡³æ›´ä¼˜çš„æ€§èƒ½ï¼ˆå°¤å…¶åœ¨ PG-19 ä¸Š PPL æœ€ä½ä¸º **23.1**ï¼‰ã€‚
- **å†…å­˜æ•ˆç‡**ï¼šç›¸æ¯”æ ‡å‡† MHA å†…å­˜ä» 15.2GB é™è‡³ **2.5GB**ï¼Œå‡å°‘çº¦ **83.5%**ã€‚
- **ååé‡**ï¼šæ¨ç†é€Ÿåº¦è¾¾ **71 seq/s**ï¼Œé«˜äºæ‰€æœ‰åŸºçº¿ï¼Œé€‚åˆé«˜å¹¶å‘éƒ¨ç½²ã€‚
- **FLOPs åˆ†æ**ï¼ˆå›¾3ï¼‰ï¼š
  - åœ¨ $n=4096$ æ—¶ï¼š
    - Standard MHAï¼š~16.8M FLOPs
    - MAHAï¼š~3.2M FLOPs â†’ **é™ä½ 81%**
  - éšåºåˆ—å¢é•¿ï¼Œä¼˜åŠ¿å‘ˆæŒ‡æ•°æ‰©å¤§ã€‚

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰èšåˆç­–ç•¥æ¯”è¾ƒï¼ˆTable 2ï¼‰
| æ–¹æ³• | MNLI (Acc) | Memory (GB) | è®­ç»ƒé€Ÿåº¦ |
|------|------------|--------------|----------|
| COï¼ˆå‡¸ä¼˜åŒ–ï¼‰ | 86.0 | 6.7 | 1.0x |
| NEï¼ˆçº³ä»€å‡è¡¡ï¼‰ | 85.8 | 6.9 | 0.9x |
| å¹³å‡èåˆï¼ˆBaselineï¼‰ | 85.2 | 7.2 | 1.1x |

- **å‘ç°**ï¼šCO ä¸ NE å‡ä¼˜äºç®€å•å¹³å‡ï¼Œä¸” CO æ›´é«˜æ•ˆï¼›NE æ”¶æ•›åæŸå¤±æ›´ä½ï¼ˆå›¾4ï¼‰ï¼Œè¡¨æ˜åšå¼ˆæœºåˆ¶å¯èƒ½æ‰¾åˆ°æ›´é²æ£’çš„å¹³è¡¡ç‚¹ã€‚

#### ï¼ˆ2ï¼‰å±‚çº§æ•°é‡å½±å“ï¼ˆå›¾5ï¼‰
- $L=4$ æ—¶æ€§èƒ½æœ€ä½³ï¼ˆMNLI 86.0ï¼‰
- $L=2$ï¼šç²’åº¦è¿‡ç²—ï¼Œä¸¢å¤±ç»†èŠ‚ â†’ å‡†ç¡®ç‡ä¸‹é™è‡³ 84.5%
- $L=6$ï¼šè¿‡åº¦ä¸‹é‡‡æ ·å¼•å…¥å™ªå£° â†’ æ€§èƒ½é€€åŒ–è‡³ 84.8%

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **MAHA æˆåŠŸå°†æ³¨æ„åŠ›å¤æ‚åº¦ä» $O(n^2)$ é™è‡³è¿‘çº¿æ€§ $O(n)$**ï¼Œåœ¨ä¿æŒç”šè‡³æå‡æ€§èƒ½çš„åŒæ—¶å¤§å¹…æé«˜å¯æ‰©å±•æ€§ã€‚
2. **ä¼˜åŒ–é©±åŠ¨çš„èšåˆæœºåˆ¶ï¼ˆCO/NEï¼‰ä¼˜äºä¼ ç»ŸåŠ æƒå¹³å‡**ï¼Œæä¾›äº†æ›´å¼ºçš„ç†è®ºä¿éšœå’ŒåŠ¨æ€é€‚åº”èƒ½åŠ›ã€‚
3. **å¤šå°ºåº¦æ³¨æ„åŠ›å¯è§†åŒ–æ˜¾ç¤ºæ˜ç¡®åˆ†å·¥**ï¼š
   - ç»†å°ºåº¦å…³æ³¨å±€éƒ¨è¯­æ³•ï¼ˆå¯¹è§’å¯†é›†ï¼‰
   - ä¸­å°ºåº¦å½¢æˆå—çŠ¶ç»“æ„ï¼ˆå¥å­å†…èšåˆï¼‰
   - ç²—å°ºåº¦å‡ºç°å‚ç›´æ¡å¸¦ï¼ˆå…³é”®è¯å…¨å±€è¿½è¸ªï¼‰
4. **é€‚ç”¨äºé•¿ä¸Šä¸‹æ–‡å»ºæ¨¡èŒƒç•´**ï¼ˆå¦‚ä¹¦ç±ã€ç§‘å­¦æ–‡çŒ®ã€ä»£ç ï¼‰ï¼Œæ˜¯ä¸‹ä¸€ä»£ LLM çš„æœ‰åŠ›å€™é€‰æ¶æ„ã€‚

### âš ï¸ å±€é™æ€§
- éœ€è°ƒå‚è¾ƒå¤šï¼ˆå¦‚å±‚çº§æ•° $L$ã€å‹ç¼©æ¯” $r$ï¼‰ï¼Œå¯èƒ½éœ€é¢†åŸŸå®šåˆ¶ã€‚
- NE èšåˆè®­ç»ƒå¼€é”€ç•¥é«˜ï¼ˆè¿­ä»£æ±‚è§£ï¼‰ï¼Œä¸å¦‚ CO å¿«é€Ÿé—­å¼è§£ã€‚
- å‡è®¾è¯­è¨€å…·æœ‰å¤©ç„¶å±‚æ¬¡ç»“æ„ï¼Œåœ¨é«˜åº¦éç»„åˆæ€§æˆ–è·³è·ƒå¼•ç”¨æ–‡æœ¬ä¸­å¯èƒ½å—é™ï¼ˆLiu et al., 2021ï¼‰ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³å…¶ä»–æ¨¡æ€ï¼ˆComputer Visionã€Speech Processingï¼‰ï¼Œåˆ©ç”¨å…¶å¤©ç„¶å¤šåˆ†è¾¨ç‡ç‰¹æ€§ã€‚
- æ¢ç´¢è”é‚¦å­¦ä¹ åœºæ™¯ä¸‹çš„åˆ†å¸ƒå¼ä¼˜åŒ–èšåˆã€‚
- ç»“åˆ MAHA çš„å¯è§£é‡Šæ€§æ½œåŠ›ï¼Œå¼€å‘é€æ˜å†³ç­–è·¯å¾„åˆ†æå·¥å…·ã€‚
- å¼€æºå®ç°å·²å‘å¸ƒï¼š[GitHub](https://github.com/can-ererden/MAHA-Project)ï¼ŒDOI: `10.5281/zenodo.17936753`

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> MAHA é€šè¿‡**åˆ†å±‚åˆ†è§£ + ä¼˜åŒ–èšåˆ**ï¼Œå®ç°äº†**é«˜æ•ˆã€å¯æ‰©å±•ã€ç†è®ºä¸¥è°¨**çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œåœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹å°†è®¡ç®—æˆæœ¬é™ä½ 80% ä»¥ä¸Šï¼Œä¸ºæ„å»ºä¸‹ä¸€ä»£é•¿ä¸Šä¸‹æ–‡ Large Language Models æä¾›äº†åšå®çš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 2. [DEER: Draft with Diffusion, Verify with Autoregressive Models](https://arxiv.org/abs/2512.15176)

**Authors**: Zicong Cheng, Guo-Wei Yang, Jia Li, Zhijie Deng, Meng-Hao Guo, Shi-Min Hu  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2512.15176v1  

#### Abstract
Efficiency, as a critical practical challenge for LLM-driven agentic and reasoning systems, is increasingly constrained by the inherent latency of autoregressive (AR) decoding. Speculative decoding mitigates this cost through a draft-verify scheme, yet existing approaches rely on AR draft models (a....

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDEER: Draft with Diffusion, Verify with Autoregressive Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„ **speculative decoding** æ–¹æ³•æ™®éä¾èµ–äº **autoregressive (AR) drafters** æ¥ç”Ÿæˆå€™é€‰åºåˆ—ï¼Œä½†è¿™ç±»æ–¹æ³•å­˜åœ¨ä¸¤ä¸ªæ ¹æœ¬æ€§ç“¶é¢ˆï¼š
1. **é€æ­¥ä¸ç¡®å®šæ€§ç´¯ç§¯ï¼ˆstep-wise uncertainty accumulationï¼‰**ï¼šç”±äº AR æ¨¡å‹æ˜¯é€ token ç”Ÿæˆçš„ï¼Œæ—©æœŸé¢„æµ‹è¯¯å·®ä¼šé€šè¿‡å·¦åˆ°å³çš„ä¾èµ–å…³ç³»ä¸æ–­ä¼ æ’­å’Œæ”¾å¤§ï¼Œå¯¼è‡´ä¸ç›®æ ‡æ¨¡å‹çš„ä¿¡ä»»é€æ¸â€œå´©æºƒâ€ï¼ˆgradual collapse of trustï¼‰ï¼Œä»è€Œé™åˆ¶äº†å¯æ¥å—çš„ draft é•¿åº¦ã€‚
2. **å›ºæœ‰çš„ä¸²è¡Œè§£ç æ•ˆç‡ä½ä¸‹**ï¼šAR drafters å¿…é¡»é¡ºåºç”Ÿæˆ tokenï¼Œæ— æ³•å¹¶è¡ŒåŒ–ï¼Œåˆ¶çº¦äº†æ•´ä½“åŠ é€Ÿæ½œåŠ›ã€‚

è¿™ä¸¤ä¸ªå› ç´ å…±åŒå¯¼è‡´ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ EAGLE-3ï¼‰çš„å®é™…åŠ é€Ÿæ•ˆæœæœ‰é™ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡º **DEER** â€”â€” ä¸€ç§å…¨æ–°çš„ speculative decoding æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> **ç”¨ diffusion LLM (dLLM) ä½œä¸º drafter è¿›è¡Œå¹¶è¡Œèµ·è‰ï¼Œç”¨ AR æ¨¡å‹è¿›è¡ŒéªŒè¯ï¼ˆdraft with diffusion, verify with autoregressive modelsï¼‰**

#### ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

- âœ… **é¦–æ¬¡å®Œå…¨åŸºäºç¦»æ•£ç©ºé—´ dLLM çš„ speculative decoding æ¡†æ¶**  
  DEER æ˜¯é¦–ä¸ªä»…ä½¿ç”¨ **discrete-space diffusion LLM** ä½œä¸º drafter çš„æ¡†æ¶ï¼Œæ— éœ€è¾…åŠ© AR æ¨¡å‹æˆ–æ··åˆæ¶æ„ï¼Œé¿å…äº† AR drafters çš„ä¸²è¡Œä¾èµ–ã€‚

- âœ… **æå‡º Diffusion-to-AR (D2A) å¯¹é½è®­ç»ƒç®¡é“**  
  ä¸ºè§£å†³æ ‡å‡† dLLM åœ¨ prefix-conditioned ç»­å†™ä»»åŠ¡ä¸­åˆ†å¸ƒä¸åŒ¹é…çš„é—®é¢˜ï¼Œè®¾è®¡äº†ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼š
  1. **Stage I: AR-Style Continuation Distillation**  
     ä½¿ç”¨æˆªæ–­çš„æ•™å¸ˆç­”æ¡ˆ + `[SEP]` æ ‡è®°è¿›è¡Œè’¸é¦è®­ç»ƒï¼Œä½¿ dLLM å­¦ä¹ ä»ç»™å®šå‰ç¼€ç”Ÿæˆåç¼€çš„èƒ½åŠ›ã€‚
  2. **Stage II: Scribe Refinement**  
     é‡‡ç”¨æŒ‡æ•°è¡°å‡åŠ æƒçš„ suffix masking ç­–ç•¥ï¼Œåœ¨é è¿‘éªŒè¯è¾¹ç•Œçš„åŒºåŸŸå¢å¼ºå±€éƒ¨å‡†ç¡®æ€§ï¼Œæå‡ token çº§ç¨³å®šæ€§ã€‚

- âœ… **å®ç°å•æ­¥é•¿å—ç”Ÿæˆï¼ˆone-step block draftingï¼‰**  
  åˆ©ç”¨ dLLM çš„å…¨å±€å»å™ªèƒ½åŠ›ï¼Œä¸€æ¬¡æ€§ç”Ÿæˆé•¿è¾¾æ•°åä¸ª token çš„å®Œæ•´åç¼€å—ï¼Œå½»åº•æ¶ˆé™¤ left-to-right ä¾èµ–ã€‚

- âœ… **å‘ç°â€œå¯é å—å†ç”Ÿâ€ï¼ˆreliable block regenerationï¼‰æ–°èƒ½åŠ›**  
  è®­ç»ƒåçš„ dLLM èƒ½å¤Ÿåå¤æ¥å—éƒ¨åˆ†æ©ç çš„åç¼€å¹¶è¿è´¯åœ°é‡å»ºå®ƒä»¬ï¼Œå±•ç°å‡ºè¶…è¶Šä¼ ç»Ÿç”Ÿæˆæ¨¡å¼çš„çµæ´»æ€§ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | DEER | EAGLE-3 / å…¶ä»– AR-based æ–¹æ³• |
|------|------|-----------------------------|
| **ç”Ÿæˆæœºåˆ¶** | å¹¶è¡Œå»å™ªï¼Œæ•´å—ç”Ÿæˆ | ä¸²è¡Œè‡ªå›å½’ç”Ÿæˆ |
| **é”™è¯¯ä¼ æ’­** | æ— é€æ­¥ç´¯ç§¯ï¼ˆproposal ç‹¬ç«‹äºå†å² draftï¼‰ | æ˜æ˜¾ç´¯ç§¯ï¼Œè¶Šå¾€åè¶Šä¸ç¨³å®š |
| **æœ€å¤§æ¥å—é•¿åº¦** | é«˜è¾¾ **32 tokens** | é€šå¸¸ä¸è¶…è¿‡ **8â€“10 tokens** |
| **é€Ÿåº¦æå‡** | æœ€é«˜ **5.54Ã—** | æœ€é«˜çº¦ **2.41Ã—** |
| **è®­ç»ƒæˆæœ¬** | æ›´ä½ï¼ˆè§ Table 8ï¼‰ | æ›´é«˜ï¼Œä¸”åœ¨å¤§æ¨¡å‹ä¸Šæ˜“ OOM |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†

#### ä»£ç ç”Ÿæˆä»»åŠ¡ï¼š
- **HumanEval**, **MBPP**, **LiveCodeBench**, **CodeAlpacaPy**ï¼ˆPython å­é›†ï¼‰
- è®­ç»ƒæ•°æ®ï¼š**OpenCodeInstruct**

#### æ•°å­¦æ¨ç†ä»»åŠ¡ï¼š
- **GSM8K**, **Math500**, **Minerva Math**
- è®­ç»ƒæ•°æ®ï¼š**UltraChat**, **ShareGPT**

---

### å®éªŒè®¾ç½®

- **åŸºç¡€æ¨¡å‹ç³»åˆ—**ï¼šQwen3-4B, Qwen3-8B, Qwen3-14B, Qwen3-30B-A3B
- **dLLM drafter æ¶æ„**ï¼š
  - ä»£ç ä»»åŠ¡ï¼šåŸºäº Open-dLLM ä¿®æ”¹çš„ 0.5B å‚æ•° discrete dLLM
  - æ•°å­¦ä»»åŠ¡ï¼šå°† Qwen2.5-0.5B-Instruct æ”¹é€ ä¸º diffusion æ¨¡å‹åå¾®è°ƒ
- **æ¸©åº¦è®¾ç½®**ï¼šä¸»å®éªŒä½¿ç”¨ `temperature=0` å’Œ `temperature=0.6`
- **ç¡¬ä»¶å¹³å°**ï¼š8Ã—NVIDIA A100 (80GB)

---

### è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Speedup Ratio** | ç›¸å¯¹äºæ ‡å‡† AR è§£ç çš„ç«¯åˆ°ç«¯æ¨ç†é€Ÿåº¦æå‡å€æ•° |
| **Average Acceptance Length (T)** | æ¯æ¬¡ draft-verify å¾ªç¯ä¸­å¹³å‡è¢«æ¥å—çš„ token æ•°é‡ï¼Œåæ˜ æœ‰æ•ˆå¹¶è¡Œåº¦ |
| **Maximum Accepted Length** | å•æ¬¡æˆåŠŸæ¥å—çš„æœ€é•¿ draft é•¿åº¦ |

> æ³¨ï¼šç”±äº DEER ä½¿ç”¨ rejection sampling ä¿è¯è¾“å‡ºåˆ†å¸ƒä¸€è‡´æ€§ï¼Œå› æ­¤æ‰€æœ‰æ–¹æ³•å‡ä¿æŒåŸå§‹æ¨¡å‹ç²¾åº¦ä¸å˜ï¼Œæ•…ä¸æŠ¥å‘Š accuracy ç±»æŒ‡æ ‡ã€‚

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **EAGLE-3**ï¼šå½“å‰æœ€å…ˆè¿›çš„ AR-based speculative decoding æ–¹æ³•
- **Medusa**, **Hydra**ï¼šåŸºäºæ ‘ç»“æ„é¢„æµ‹çš„ AR drafters
- **Lookahead**, **DiffuSpec**ï¼šè½»é‡çº§ heuristic æˆ– n-gram åŒ¹é…æ–¹æ³•ï¼ˆæ–‡ä¸­ç®€è¦æåŠï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ Qwen3-30B-A3B, temp=0 ä¸ºä¾‹ï¼‰

| æ–¹æ³• | Speedup | T (Avg. Acceptance Length) |
|------|---------|----------------------------|
| **DEER** | **5.54Ã—** | **6.58** |
| EAGLE-3 | 2.41Ã— | 3.21 |

> åœ¨ HumanEval ä¸Šï¼ŒDEER å®ç°äº† **è¶…è¿‡ 2 å€çš„é€Ÿåº¦ä¼˜åŠ¿**ã€‚

---

### ä¸å…¶ä»–æ¨¡å‹è§„æ¨¡çš„å…¨é¢æ¯”è¾ƒï¼ˆTable 1 & 2ï¼‰

| æ¨¡å‹ | æ–¹æ³• | Speedup | T |
|------|------|--------|----|
| Qwen3-30B-A3B | DEER | **5.54Ã—** | **6.58** |
| | EAGLE-3 | 2.41Ã— | 3.21 |
| Qwen3-14B | DEER | 3.50Ã— | 5.00 |
| | EAGLE-3 | 1.91Ã— | 2.61 |
| Qwen3-8B | DEER | 3.30Ã— | 5.00 |
| | EAGLE-3 | 2.65Ã— | 3.87 |

âœ… **è¶‹åŠ¿ä¸€è‡´**ï¼šDEER åœ¨æ‰€æœ‰æ¨¡å‹å°ºåº¦ä¸‹å‡æ˜¾è‘—ä¼˜äº EAGLE-3ï¼Œä¸”éšç€æ¨¡å‹å¢å¤§ä¼˜åŠ¿æ›´æ˜æ˜¾ã€‚

---

### æœ€å¤§æ¥å—é•¿åº¦å¯¹æ¯”ï¼ˆTable 4ï¼‰

| æ¨¡å‹ | EAGLE-3 | **DEER** |
|------|--------|----------|
| Qwen3-4B | 8 | **32** |
| Qwen3-8B | 8 | **32** |
| Qwen3-14B | 8 | **32** |
| Qwen3-30B-A3B | 7 | **32** |

â¡ï¸ DEER å¯ç¨³å®šæ¥å—é•¿è¾¾ **32 tokens** çš„è‰æ¡ˆï¼Œè€Œ EAGLE-3 æœ€å¤šåªèƒ½æ¥å— 7â€“8 ä¸ªï¼Œå·®è·å·¨å¤§ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### Stage IIï¼ˆScribe Refinementï¼‰çš„å½±å“ï¼ˆTable 3ï¼‰

| Benchmark | w/o Refinement | **w/ Refinement** | Î” |
|----------|----------------|--------------------|----|
| MBPP | 4.74 | **4.87** | +0.13 |
| CodeAlpacaPy | 3.47 | **4.04** | +0.57 |
| HumanEval | 5.38 | **6.58** | **+1.20** |
| LiveCodeBench | 3.87 | **5.03** | **+1.16** |

ğŸ”¹ ç»“æœè¡¨æ˜ï¼šStage II æ˜¾è‘—æå‡äº†ç»­å†™è´¨é‡ï¼Œå°¤å…¶å¯¹å¤æ‚ä»»åŠ¡ï¼ˆå¦‚ HumanEvalï¼‰æ”¹å–„æœ€å¤§ã€‚

#### è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼ˆFigure 6ï¼‰
- æŒ‡æ•°åŠ æƒç³»æ•° Î± è¿‡å¤§ä¼šå¯¼è‡´è®­ç»ƒä¸ç¨³å®šï¼ˆå¦‚ Î±=1.05 æ—¶å‘æ•£ï¼‰
- åˆç†èŒƒå›´å†…ï¼ˆå¦‚ Î±=1.01~1.02ï¼‰å¯ç¨³å®šä¼˜åŒ–ï¼Œè¯´æ˜è¯¥æ¨¡å—éœ€ç²¾ç»†è°ƒå‚

---

### æ‰¹å¤„ç†æ‰©å±•æ€§æµ‹è¯•ï¼ˆTable 5ï¼‰

| Batch Size | AR Baseline (tokens/s) | **DEER** (tokens/s) | åŠ é€Ÿæ¯” |
|------------|------------------------|---------------------|-------|
| 2 | 34.03 | 82.97 | ~2.4Ã— |
| 8 | 38.35 | 159.87 | **~4.2Ã—** |
| 16 | 49.76 | 175.66 | ~3.5Ã— |

âœ… DEER åœ¨æ‰¹å¤„ç†åœºæ™¯ä¸‹è¡¨ç°å‡ºè‰¯å¥½çš„å¯æ‰©å±•æ€§ï¼Œå°¤å…¶åœ¨ä¸­ç­‰ batch size ä¸‹åŠ é€Ÿæ˜¾è‘—ã€‚

---

### æ•°å­¦æ¨ç†ä»»åŠ¡è¡¨ç°ï¼ˆTable 6ï¼‰

| Benchmark | EAGLE-3 (Speedup/T) | **DEER** (Speedup/**T**) |
|----------|---------------------|---------------------------|
| Math500 | Ã—1.89 / 2.04 | **Ã—2.12 / 2.45** |
| GSM8K | Ã—1.92 / 2.43 | **Ã—2.23 / 2.70** |
| Minerva Math | Ã—1.91 / 2.07 | **Ã—2.02 / 2.31** |
| **Mean** | **Ã—1.91 / 2.18** | **Ã—2.12 / 2.47** |

ğŸ”¸ å³ä½¿æ•°å­¦ä»»åŠ¡ä¸Šçš„ dLLM å°šæœªå……åˆ†æ”¶æ•›ï¼ŒDEER ä»èƒ½æä¾›ç¨³å®šåŠ é€Ÿï¼Œè¯æ˜å…¶é²æ£’æ€§å¼ºã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. âœ… **dLLM ä½œä¸º drafter å¯ä»æ ¹æœ¬ä¸Šç¼“è§£ AR drafters çš„ä¸ç¡®å®šæ€§ç´¯ç§¯é—®é¢˜**  
   ç”±äº dLLM æ˜¯ block-wise å¹¶è¡Œç”Ÿæˆï¼Œæ¯ä¸ªä½ç½®çš„ proposal ä¸ä¾èµ–äºä¹‹å‰çš„ draft tokenï¼Œå› æ­¤ä¸ä¼šæ”¾å¤§è‡ªèº«é”™è¯¯ã€‚

2. âœ… **DEER å®ç°äº†å‰æ‰€æœªæœ‰çš„é•¿å—æ¥å—èƒ½åŠ›ï¼ˆup to 32 tokensï¼‰**  
   è¿œè¶…ç°æœ‰æ–¹æ³•ï¼ˆâ‰¤10 tokensï¼‰ï¼Œè¿™æ˜¯å®ç°é«˜å€åŠ é€Ÿçš„å…³é”®ã€‚

3. âœ… **æå‡ºçš„ D2A å¯¹é½è®­ç»ƒç­–ç•¥æœ‰æ•ˆè§£å†³äº†åˆ†å¸ƒé”™é…é—®é¢˜**  
   ç‰¹åˆ«æ˜¯ Stage II çš„æŒ‡æ•°åŠ æƒæŸå¤±æ˜¾è‘—æå‡äº†è¾¹ç•ŒåŒºåŸŸçš„ç»­å†™ç¨³å®šæ€§ã€‚

4. âœ… **DEER å…·å¤‡è‰¯å¥½æ³›åŒ–æ€§å’Œé²æ£’æ€§**  
   åœ¨ä¸åŒæ¨¡å‹è§„æ¨¡ã€ä»»åŠ¡ç±»å‹ï¼ˆä»£ç  & æ•°å­¦ï¼‰ã€batch size ä¸‹å‡è¡¨ç°ä¼˜å¼‚ã€‚

5. ğŸ”® **æ­ç¤ºäº† dLLM çš„â€œå¯é å—å†ç”Ÿâ€æ–°èƒ½åŠ›**  
   è¡¨æ˜ç»è¿‡ç‰¹å®šè®­ç»ƒçš„ dLLM å¯ä»¥æ”¯æŒçµæ´»çš„å±€éƒ¨ç¼–è¾‘ä¸æ‰©å±•ï¼Œå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§

- âš ï¸ **ç¼ºä¹æˆç†Ÿçš„ dLLM æ¨ç†æ¡†æ¶æ”¯æŒ**  
  å½“å‰ä¸»æµç³»ç»Ÿï¼ˆå¦‚ vLLM, SGLangï¼‰å°šä¸æ”¯æŒ dLLM çš„ KV cacheï¼Œå½±å“æ‰¹å¤„ç†æ•ˆç‡ï¼ˆä½œè€…å·²åœ¨é™„å½• F ä¸­æŒ‡å‡º Fast-dLLM å’Œ dInfer æ­£åœ¨æ¨è¿›æ­¤æ–¹å‘ï¼‰ã€‚

- âš ï¸ **Stage II è®­ç»ƒå¯¹è¶…å‚æ•°è¾ƒæ•æ„Ÿ**  
  æŒ‡æ•°æƒé‡ç³»æ•° Î± éœ€è°¨æ…é€‰æ‹©ï¼Œå¦åˆ™å¯èƒ½å¯¼è‡´è®­ç»ƒä¸ç¨³å®šã€‚

- âš ï¸ **dLLM è‡ªèº«è®­ç»ƒå°šæœªå®Œå…¨æˆç†Ÿ**  
  ç›¸æ¯” AR æ¨¡å‹ï¼ŒdLLM çš„é¢„è®­ç»ƒå’Œå¾®è°ƒç”Ÿæ€ä»åœ¨å‘å±•ä¸­ï¼Œå¯èƒ½é™åˆ¶å…¶ standalone æ€§èƒ½ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. ğŸ”„ **æ¢ç´¢æ›´é«˜æ•ˆçš„ dLLM æ¶æ„ä¸è®­ç»ƒèŒƒå¼**ï¼Œè¿›ä¸€æ­¥ç¼©å°ä¸ AR æ¨¡å‹çš„è´¨é‡å·®è·ã€‚
2. ğŸ’¡ **å¼€å‘æ”¯æŒ dLLM KV cache çš„é€šç”¨æ¨ç†å¼•æ“**ï¼Œé‡Šæ”¾å…¶åœ¨ batch inference ä¸­çš„å…¨éƒ¨æ½œåŠ›ã€‚
3. ğŸ§© **å°† DEER æ‰©å±•è‡³æ›´å¤šæ¨¡æ€**ï¼ˆå¦‚å›¾åƒã€è¯­éŸ³ï¼‰ï¼Œåˆ©ç”¨ diffusion æ¨¡å‹çš„è·¨æ¨¡æ€ä¼˜åŠ¿ã€‚
4. ğŸ¤– **ç»“åˆ agentic workflows**ï¼Œåˆ©ç”¨é•¿å— drafting æå‡å¤æ‚ä»»åŠ¡ä¸­çš„è§„åˆ’ä¸æ‰§è¡Œæ•ˆç‡ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **DEER é€šè¿‡å¼•å…¥ diffusion LLM ä½œä¸ºå¹¶è¡Œ drafterï¼Œå¹¶è®¾è®¡é’ˆå¯¹æ€§çš„å¯¹é½è®­ç»ƒç­–ç•¥ï¼ŒæˆåŠŸçªç ´äº†ä¼ ç»Ÿ speculative decoding çš„ä¸²è¡Œç“¶é¢ˆï¼Œåœ¨å¤šé¡¹ä»»åŠ¡ä¸Šå®ç°äº†é«˜è¾¾ 5.54Ã— çš„åŠ é€Ÿï¼Œæ˜¯è¿ˆå‘é«˜æ•ˆ LLM æ¨ç†çš„é‡è¦ä¸€æ­¥ã€‚**

</details>

---

### 3. [Meta Hierarchical Reinforcement Learning for Scalable Resource Management in O-RAN](https://arxiv.org/abs/2512.13715)

**Authors**: Fatemeh Lotfi, Fatemeh Afghah  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.13715v1  

#### Abstract
The increasing complexity of modern applications demands wireless networks capable of real time adaptability and efficient resource management. The Open Radio Access Network (O-RAN) architecture, with its RAN Intelligent Controller (RIC) modules, has emerged as a pivotal solution for dynamic resourc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMeta-Hierarchical Reinforcement Learning for Scalable Resource Management in O-RAN

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ç°ä»£æ— çº¿ç½‘ç»œï¼ˆå°¤å…¶æ˜¯åŸºäº **O-RAN** æ¶æ„ï¼‰é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **åŠ¨æ€æ€§å’Œä¸å¯é¢„æµ‹æ€§**ï¼šç”¨æˆ·éœ€æ±‚ã€æµé‡æ¨¡å¼å’Œç½‘ç»œæ¡ä»¶é«˜åº¦å˜åŒ–ï¼Œå¯¼è‡´ä¼ ç»Ÿèµ„æºç®¡ç†ç­–ç•¥éš¾ä»¥é€‚åº”ã€‚
- **å¤šåˆ‡ç‰‡å¼‚æ„æœåŠ¡éœ€æ±‚**ï¼šeMBBã€URLLC å’Œ mMTC ç­‰ä¸åŒ **Network Slicing** ç±»å‹å…·æœ‰å·®å¼‚å·¨å¤§çš„ QoS è¦æ±‚ï¼ˆå¦‚é«˜ååã€ä½å»¶è¿Ÿã€æµ·é‡è¿æ¥ï¼‰ï¼Œåè°ƒéš¾åº¦å¤§ã€‚
- **å®æ—¶æ€§ä¸å¯æ‰©å±•æ€§çŸ›ç›¾**ï¼šåœ¨å¤§è§„æ¨¡åˆ†å¸ƒå¼ç¯å¢ƒä¸­å®ç°å¿«é€Ÿè‡ªé€‚åº”çš„åŒæ—¶ä¿æŒç³»ç»Ÿç¨³å®šæ€§ä¸å†³ç­–ç²’åº¦ã€‚

ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ä¼ ç»Ÿ DRL æˆ– Federated Learningï¼‰å¾€å¾€ç¼ºä¹å¯¹çªå‘åœºæ™¯çš„å¿«é€Ÿå“åº”èƒ½åŠ›ï¼Œä¸”åœ¨éå¹³ç¨³ç¯å¢ƒä¸‹çš„æ³›åŒ–æ€§èƒ½è¾ƒå·®ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

æœ¬æ–‡æå‡ºäº†ä¸€ç§ **è‡ªé€‚åº” Meta-Hierarchical Reinforcement Learning (Meta-HRL)** æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰**åˆ†å±‚æ§åˆ¶æ¶æ„ï¼ˆHierarchical Controlï¼‰**
- **é«˜å±‚æ§åˆ¶å™¨ï¼ˆHigh-level Controllerï¼‰**ï¼šè´Ÿè´£è·¨åˆ‡ç‰‡çš„èµ„æºåˆ†é…ï¼ˆInter-slice Resource Allocationï¼‰ï¼Œä½œä¸ºå…¨å±€è°ƒåº¦å™¨ã€‚
- **åº•å±‚ä»£ç†ï¼ˆLow-level Agentsï¼‰**ï¼šéƒ¨ç½²äºæ¯ä¸ª **DU** ä¸Šï¼Œæ‰§è¡Œå„åˆ‡ç‰‡å†…çš„ç”¨æˆ·çº§èµ„æºå—ï¼ˆRBï¼‰è°ƒåº¦ï¼ˆIntra-slice Schedulingï¼‰ã€‚
- åˆ†è§£å¤æ‚ä»»åŠ¡ä¸ºä¸¤çº§å­é—®é¢˜ï¼Œæå‡å­¦ä¹ æ•ˆç‡ä¸å¯æ‰©å±•æ€§ã€‚

#### ï¼ˆ2ï¼‰**åŸºäº MAML çš„å…ƒå­¦ä¹ æœºåˆ¶ï¼ˆMeta-Learning Inspired by MAMLï¼‰**
- å¼•å…¥ **Model-Agnostic Meta-Learning (MAML)** æ€æƒ³ï¼Œä½¿æ¨¡å‹èƒ½ä»å†å²ä»»åŠ¡ä¸­â€œå­¦ä¼šå¦‚ä½•å­¦ä¹ â€ï¼Œä»è€Œåœ¨æ–°ä»»åŠ¡æˆ–æ–° DU æ¥å…¥æ—¶å®ç° **few-shot å¿«é€Ÿé€‚åº”**ã€‚
- å°†æ¯ä¸ª DU è§†ä¸ºä¸€ä¸ªç‹¬ç«‹çš„å­¦ä¹ ä»»åŠ¡ï¼ˆtaskï¼‰ï¼Œé€šè¿‡ meta-training å­¦ä¹ é€šç”¨åˆå§‹åŒ–å‚æ•°ï¼Œåœ¨æ–°ç¯å¢ƒä¸‹ä»…éœ€å°‘é‡æ ·æœ¬å³å¯ fine-tuneã€‚

#### ï¼ˆ3ï¼‰**è‡ªé€‚åº”åŠ æƒå…ƒæ›´æ–°æœºåˆ¶ï¼ˆAdaptive Variance-Weighted Meta Updateï¼‰**
- åˆ›æ–°åœ°ä½¿ç”¨ **Temporal Difference Error (TD-error) æ–¹å·®** æ¥è¡¡é‡ä»»åŠ¡å¤æ‚åº¦ï¼Œå¹¶æ®æ­¤åŠ¨æ€è°ƒæ•´å„ä¸ªä»»åŠ¡åœ¨ meta-gradient æ›´æ–°ä¸­çš„æƒé‡ï¼š
  $$
  w_g = \text{Softmin}(\sigma^2_{\text{TD},g})
  $$
- é«˜æ–¹å·®ä»»åŠ¡ï¼ˆå³æ›´å¤æ‚ã€æ³¢åŠ¨æ›´å¤§çš„ç½‘ç»œçŠ¶æ€ï¼‰è·å¾—æ›´é«˜ä¼˜å…ˆçº§ï¼Œç¡®ä¿æ¨¡å‹èšç„¦äºæœ€å…·æŒ‘æˆ˜æ€§çš„åœºæ™¯ã€‚

#### ï¼ˆ4ï¼‰**ç†è®ºä¿éšœä¸å®é™…éƒ¨ç½²å…¼å®¹æ€§**
- æä¾›äº† **æ”¶æ•›æ€§åˆ†æ** å’Œ **regret bound** è¯æ˜ï¼Œè¡¨æ˜è¯¥æ¡†æ¶å…·å¤‡ **sublinear æ”¶æ•›é€Ÿåº¦** å’Œç¨³å®šçš„å­¦ä¹ è¡Œä¸ºã€‚
- è®¾è®¡ç¬¦åˆ O-RAN æ¶æ„æ ‡å‡†ï¼Œå¯åœ¨ Near-RT RIC ä¸­ä»¥ xApp å½¢å¼éƒ¨ç½²ï¼Œæ”¯æŒåˆ†å¸ƒå¼ã€ä½å¼€é”€é€šä¿¡ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **é€‚åº”é€Ÿåº¦** | ç›¸æ¯” baseline RL å’Œ meta-RL æ–¹æ³•ï¼Œ**å¿«è¾¾ 40% æ›´å¿«é€‚åº”** æ–°ä»»åŠ¡ |
| **æ€§èƒ½è¡¨ç°** | åœ¨ç»¼åˆç½‘ç»œç®¡ç†æ•ˆç‡ä¸Šæå‡ **19.8%** |
| **é²æ£’æ€§** | å¯¹çƒ­ç‚¹åŒºåŸŸã€çªå‘æµé‡ç­‰ corner cases è¡¨ç°å‡ºæ›´å¼ºéŸ§æ€§ |
| **å…¬å¹³æ€§ä¸æœåŠ¡è´¨é‡** | æ˜¾è‘—æ”¹å–„ **Jainâ€™s Fairness Index**ï¼ˆä» 0.91 â†’ 0.96ï¼‰ï¼Œé™ä½å¹³å‡å»¶è¿Ÿ 9.2% |
| **å¯æ‰©å±•æ€§** | æ”¯æŒå¤§è§„æ¨¡ DU æ‰©å±•ï¼Œè®­ç»ƒæˆæœ¬å¢é•¿å‘ˆ **äºšçº¿æ€§è¶‹åŠ¿** |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†ä¸ä»¿çœŸç¯å¢ƒ
- **æ— çœŸå®æ•°æ®é›†**ï¼Œé‡‡ç”¨ **è‡ªå®šä¹‰ O-RAN ä»¿çœŸå¹³å°** è¿›è¡Œå®éªŒã€‚
- æ¨¡æ‹ŸåŒ…å«å¤šä¸ª DUã€CUã€RU çš„ O-RAN ç½‘ç»œæ‹“æ‰‘ï¼Œæ”¯æŒä¸‰ç§å…¸å‹åˆ‡ç‰‡ï¼š
  - **eMBB**ï¼ˆå¢å¼ºç§»åŠ¨å®½å¸¦ï¼‰
  - **URLLC**ï¼ˆè¶…å¯é ä½æ—¶å»¶é€šä¿¡ï¼‰
  - **mMTC**ï¼ˆæµ·é‡æœºå™¨ç±»é€šä¿¡ï¼‰

---

### âš™ï¸ å®éªŒè®¾ç½®

| å‚æ•° | è®¾ç½®å€¼ |
|------|--------|
| å­è½½æ³¢é—´éš” | 15 kHz |
| å•ä¸ª DU å¸¦å®½ | 20 MHz |
| RB æ•°é‡ / DU | 100 |
| ç”¨æˆ·æ•° / DU | 30 |
| åˆ†å¸ƒå¼å•å…ƒæ•°é‡ï¼ˆNgï¼‰ | 7ï¼ˆåŸºå‡†ï¼‰ã€æœ€é«˜æ‰©å±•è‡³ 30 |
| æ€»ç”¨æˆ·æ•° | æœ€é«˜è¾¾ 200 |
| ç§»åŠ¨é€Ÿåº¦ | 10â€“20 m/s |
| å­¦ä¹ ç®—æ³• | DDPGï¼ˆActor-Critic æ¶æ„ï¼‰ |
| ç½‘ç»œç»“æ„ | ä¸‰å±‚å…¨è¿æ¥ç¥ç»ç½‘ç»œï¼ˆ256, 512, 512ï¼‰ |
| ä¼˜åŒ–å™¨ | Adam (lr = 1e-4) |
| æŠ˜æ‰£å› å­ Î³ | 0.99 |

> æ‰€æœ‰ç»“æœå‡ç»è¿‡å¤šæ¬¡è¿è¡Œå–å¹³å‡ï¼Œä¿è¯ç»Ÿè®¡å¯é æ€§ã€‚

---

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ç±»åˆ« | å…·ä½“æŒ‡æ ‡ |
|---------|----------|
| **æ€§èƒ½æŒ‡æ ‡** | - ç´¯ç§¯å¥–åŠ±ï¼ˆCumulative Rewardï¼‰<br>- ååé‡ï¼ˆThroughputï¼‰<br>- å»¶è¿Ÿï¼ˆLatencyï¼‰ |
| **æœåŠ¡è´¨é‡ï¼ˆQoSï¼‰** | - Slice-specific KPIï¼š<br>â€ƒâ€¢ eMBB: å¹³å‡åå<br>â€ƒâ€¢ mMTC: UE å¯†åº¦æ”¯æŒ + åååŠ æƒ<br>â€ƒâ€¢ URLLC: æœ€å¤§ä¼ è¾“å»¶è¿Ÿ |
| **ç”¨æˆ·ä½“éªŒï¼ˆQoEï¼‰** | - ç”¨æˆ·çº§åå CDF åˆ†å¸ƒ |
| **é€‚åº”èƒ½åŠ›** | - ä¸åŒ shot æ•°ä¸‹çš„é€‚åº”æ€§èƒ½ï¼ˆ0-shot, 5-shot, 30-shotï¼‰ |
| **å¯æ‰©å±•æ€§** | - éš DU å’Œ UE æ•°é‡å¢åŠ çš„æ”¶æ•›è¿­ä»£æ¬¡æ•°ä¸å½’ä¸€åŒ–å¥–åŠ±å˜åŒ– |
| **å…¬å¹³æ€§ä¸é²æ£’æ€§** | - Jainâ€™s Fairness Index<br>- çªå‘æµé‡ä¸‹æ€§èƒ½ä¸‹é™å¹…åº¦ |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **DRL**ï¼šä»é›¶å¼€å§‹è®­ç»ƒçš„æ ‡å‡† Deep Reinforcement Learning
- **Transfer Learning (TL)**ï¼šå°†å·²æœ‰ agent çš„çŸ¥è¯†è¿ç§»åˆ°æ–°ä»»åŠ¡
- **Multi-Task Learning (MTL)**ï¼šåŒæ—¶å­¦ä¹ å¤šä¸ªä»»åŠ¡
- **MAML-RL / MAML-HRL**ï¼šæ ‡å‡†å…ƒå¼ºåŒ–å­¦ä¹ åŠå…¶åˆ†å±‚ç‰ˆæœ¬ï¼ˆéè‡ªé€‚åº”ï¼‰
- **Uniform-Meta**ï¼šç­‰æƒ meta-updateï¼ˆç”¨äºæ¶ˆèå®éªŒï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **ç½‘ç»œç®¡ç†æ•ˆç‡æå‡** | ç›¸æ¯” baseline æå‡ **19.8%**ï¼ˆæœ€ç»ˆ return å€¼ï¼‰ |
| **ç´¯ç§¯å¥–åŠ±æå‡** | è¾ƒå…¶ä»–æ–¹æ³•é«˜å‡º **73%**ï¼Œè¾ƒ MAML-HRL æå‡ **4%** |
| **é€‚åº”é€Ÿåº¦æå‡** | è¾¾åˆ°ç›¸åŒæ€§èƒ½æ‰€éœ€ adaptation shots å‡å°‘ **çº¦ 40%** |
| **å¹³å‡å»¶è¿Ÿé™ä½** | ç›¸æ¯” uniform weighting ä¸‹é™ **9.2%** |
| **å…¬å¹³æ€§æå‡** | Jainâ€™s Fairness ä» 0.91 æå‡è‡³ **0.96** |
| **æŠ—çªå‘èƒ½åŠ›** | åœ¨ 50% æµé‡æ¿€å¢æƒ…å†µä¸‹ï¼Œæ€§èƒ½é€€åŒ– < **5%** |

---

### ğŸ“Š ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### ï¼ˆ1ï¼‰**å›¾4 & å›¾5ï¼šç´¯ç§¯å¥–åŠ±æ¯”è¾ƒ**
- **Adaptive MAML-HRL** åœ¨æ‰€æœ‰é˜¶æ®µå‡æ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚
- **DRL** åˆå§‹å­¦ä¹ æ…¢ï¼Œæ”¶æ•›å·®ï¼›**TL/MTL** è¡¨ç°ä¸­ç­‰ä½†æ³›åŒ–æœ‰é™ã€‚
- è‡ªé€‚åº”åŠ æƒæœºåˆ¶å¸¦æ¥æ˜æ˜¾å¢ç›Šã€‚

#### ï¼ˆ2ï¼‰**å›¾6 & å›¾7ï¼šQoS ä¸ç”¨æˆ·åå CDF**
- åœ¨æ‰€æœ‰ä¸‰ç§åˆ‡ç‰‡ä¸­ï¼Œæ‰€ææ–¹æ³•å‡è¾¾åˆ°æœ€ä¼˜ QoSï¼š
  - **eMBB**ï¼šæ›´é«˜åå
  - **mMTC**ï¼šæ›´å¥½æ”¯æŒé«˜å¯†åº¦è®¾å¤‡æ¥å…¥
  - **URLLC**ï¼šæ›´ä½æœ€å¤§å»¶è¿Ÿ
- ç”¨æˆ·åååˆ†å¸ƒæ›´é›†ä¸­ï¼Œè¯´æ˜æœåŠ¡ä¸€è‡´æ€§æ›´å¼ºã€‚

#### ï¼ˆ3ï¼‰**å›¾8ï¼šé€‚åº”æ€§èƒ½éš shot æ•°å˜åŒ–**
- åœ¨ 0-shot åœºæ™¯ä¸‹å·²ä¼˜äºå¤šæ•° baselineï¼Œä½“ç°å¼ºå¤§å…ˆéªŒçŸ¥è¯†è¿ç§»èƒ½åŠ›ã€‚
- éš shot æ•°å¢åŠ ï¼Œæ€§èƒ½è¿…é€Ÿä¸Šå‡ï¼Œå°¤å…¶åœ¨ **mMTC åˆ‡ç‰‡**ä¸­è¡¨ç°çªå‡ºã€‚

#### ï¼ˆ4ï¼‰**å›¾9ï¼šè·¨æ–°ä»»åŠ¡çš„ QoS æ³›åŒ–èƒ½åŠ›**
- åœ¨ä¸‰ä¸ªå…¨æ–°ä»»åŠ¡ä¸­ï¼ŒAdaptive MAML-HRL å§‹ç»ˆä¿æŒé¢†å…ˆï¼ŒéªŒè¯å…¶å¼ºæ³›åŒ–æ€§ã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

| æ–¹æ³• | å½’ä¸€åŒ–å¥–åŠ± | æ”¶æ•›æ‰€éœ€ shots |
|------|------------|----------------|
| Uniform-Metaï¼ˆç­‰æƒï¼‰ | 0.78 | 28 |
| Static-Varï¼ˆé™æ€æ–¹å·®åŠ æƒï¼‰ | 0.81 | 22 |
| **Adaptive-Varï¼ˆæœ¬æ–‡æ–¹æ³•ï¼‰** | **0.84** | **17** |

> âœ… ç»“è®ºï¼š**åŠ¨æ€æ–¹å·®åŠ æƒæœºåˆ¶è´¡çŒ®çº¦ 3% çš„æ€§èƒ½å¢ç›Šå’Œ 40% çš„åŠ é€Ÿæ•ˆæœ**

æ­¤å¤–ï¼Œè¯¥æœºåˆ¶è¿˜å¸¦æ¥ï¼š
- å»¶è¿Ÿå‡å°‘ 9.2%
- å…¬å¹³æ€§æå‡ï¼ˆJainâ€™s Index â†‘ï¼‰
- æŠ—çªå‘æµé‡èƒ½åŠ›å¢å¼ºï¼ˆ<5% æ€§èƒ½ä¸‹é™ï¼‰

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Meta-HRL æ˜¯è§£å†³ O-RAN åŠ¨æ€èµ„æºç®¡ç†çš„æœ‰æ•ˆèŒƒå¼**ï¼š
   - åˆ†å±‚ç»“æ„ + å…ƒå­¦ä¹ ç»“åˆï¼Œå…¼é¡¾å…¨å±€åè°ƒä¸æœ¬åœ°çµæ´»æ€§ã€‚
2. **è‡ªé€‚åº”åŠ æƒæœºåˆ¶æ˜¾è‘—æå‡å­¦ä¹ æ•ˆç‡ä¸é²æ£’æ€§**ï¼š
   - TD-error æ–¹å·®ä½œä¸ºä»»åŠ¡å¤æ‚åº¦æŒ‡æ ‡æœ‰æ•ˆå¼•å¯¼ meta-updateã€‚
3. **æ–¹æ³•å…·å¤‡è‰¯å¥½çš„å¯æ‰©å±•æ€§ä¸å·¥ç¨‹å¯è¡Œæ€§**ï¼š
   - åœ¨å¤šè¾¾ 30 ä¸ª DU å’Œ 200 ç”¨æˆ·çš„å¤§è§„æ¨¡åœºæ™¯ä¸‹ä»ä¿æŒç¨³å®šæ€§èƒ½ã€‚
   - å‚æ•°äº¤æ¢å¼€é”€å°ï¼ˆä»…ä¼ é€’ actor/critic weightsï¼‰ï¼Œæ»¡è¶³ Near-RT RIC æ—¶å»¶è¦æ±‚ï¼ˆ<10msï¼‰ã€‚
4. **ç†è®ºåˆ†ææ”¯æ’‘å®è·µè¡¨ç°**ï¼š
   - è¯æ˜äº†ä¸¤å±‚çº§å­¦ä¹ ç³»ç»Ÿçš„ **sublinear convergence** ä¸ **bounded regret**ï¼Œå¢å¼ºäº†å¯ä¿¡åº¦ã€‚

---

### âš ï¸ å±€é™æ€§
1. **ä¾èµ–ä»¿çœŸç¯å¢ƒ**ï¼š
   - å½“å‰å®éªŒåŸºäºæ¨¡æ‹Ÿå™¨ï¼Œå°šæœªåœ¨çœŸå® O-RAN testbed ä¸ŠéªŒè¯ï¼ˆå—é™äºç¡¬ä»¶è§„æ¨¡ï¼‰ã€‚
2. **è®¡ç®—å¼€é”€è¾ƒé«˜**ï¼š
   - è™½ç„¶é€šä¿¡å¼€é”€ä½ï¼Œä½† meta-training é˜¶æ®µéœ€è¦å¤§é‡å¹¶è¡Œä»»åŠ¡é‡‡æ ·ï¼Œè®­ç»ƒæ—¶é—´è¾ƒé•¿ã€‚
3. **æœªè€ƒè™‘è·¨å±‚å¹²æ‰°æˆ–å¤šè·³è·¯ç”±**ï¼š
   - å½“å‰æ¨¡å‹èšç„¦äºå•è·³ RAN å†…éƒ¨èµ„æºè°ƒåº¦ï¼Œæœªæ¶‰åŠ backhaul/midhaul æˆ– multi-hop åœºæ™¯ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **Hardware-in-the-loop éªŒè¯**ï¼š
   - åœ¨å¼€æºå¹³å°ï¼ˆå¦‚ OAIã€srsRANï¼‰ä¸Šéƒ¨ç½² xApp å½¢å¼çš„ meta-controllerã€‚
2. **é€šä¿¡é«˜æ•ˆçš„å…ƒå‚æ•°æ›´æ–°æœºåˆ¶**ï¼š
   - æ¢ç´¢å‹ç¼©ã€é‡åŒ–æˆ–ç¨€ç–åŒ–æŠ€æœ¯è¿›ä¸€æ­¥é™ä½ meta-parameter åŒæ­¥å¼€é”€ã€‚
3. **æ‰©å±•è‡³ 6G å¤šç»´åœºæ™¯**ï¼š
   - æ”¯æŒ UAV-assisted networksã€multi-hop routingã€è·¨åŸŸååŒç­‰æ›´å¤æ‚æ¶æ„ã€‚
4. **å¼•å…¥ä¸ç¡®å®šæ€§å»ºæ¨¡**ï¼š
   - ç»“åˆ Bayesian RL æˆ– ensemble methods åº”å¯¹æ›´æç«¯çš„éå¹³ç¨³ç¯å¢ƒã€‚

---

## æ€»ç»“

æœ¬æ–‡æå‡ºçš„ **Adaptive Meta-HRL** æ¡†æ¶æ˜¯é¦–ä¸ªå°† **MAML é£æ ¼å…ƒå­¦ä¹ ** ä¸ **Hierarchical RL** æ·±åº¦èåˆç”¨äº O-RAN èµ„æºç®¡ç†çš„å·¥ä½œã€‚å®ƒä¸ä»…åœ¨æ€§èƒ½ä¸Šè¶…è¶Šç°æœ‰æ–¹æ³•è¿‘ **20%**ï¼Œè¿˜åœ¨ **é€‚åº”é€Ÿåº¦ã€å…¬å¹³æ€§ã€å¯æ‰©å±•æ€§** ç­‰æ–¹é¢å±•ç°å‡ºå…¨é¢ä¼˜åŠ¿ï¼Œå¹¶æä¾›äº†åšå®çš„ç†è®ºæ”¯æ’‘ã€‚è¯¥ç ”ç©¶ä¸ºä¸‹ä¸€ä»£æ™ºèƒ½æ— çº¿ç½‘ç»œçš„è‡ªåŠ¨åŒ–è¿ç»´å¥ å®šäº†é‡è¦åŸºç¡€ã€‚

</details>

---

### 4. [Sparse Multi-Modal Transformer with Masking for Alzheimer's Disease Classification](https://arxiv.org/abs/2512.14491)

**Authors**: Cheng-Han Lu, Pei-Hsuan Tsai  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.14491v1  

#### Abstract
Transformer-based multi-modal intelligent systems often suffer from high computational and energy costs due to dense self-attention, limiting their scalability under resource constraints. This paper presents SMMT, a sparse multi-modal transformer architecture designed to improve efficiency and robus...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹åŸºäº **Transformer** çš„å¤šæ¨¡æ€æ™ºèƒ½ç³»ç»Ÿåœ¨é˜¿å°”èŒ¨æµ·é»˜ç—…ï¼ˆAlzheimer's Disease, ADï¼‰åˆ†ç±»ä»»åŠ¡ä¸­é¢ä¸´çš„ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼š
- **é«˜è®¡ç®—ä¸èƒ½è€—æˆæœ¬**ï¼šä¼ ç»Ÿå¤šæ¨¡æ€ Transformer æ¨¡å‹ä¾èµ–å¯†é›†è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆdense self-attentionï¼‰ï¼Œå¯¼è‡´æ—¶é—´å¤æ‚åº¦ä¸º $O(n^2)$ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹éƒ¨ç½²ã€‚
- **å¯¹ä¸å®Œæ•´è¾“å…¥æ•æ„Ÿ**ï¼šä¸´åºŠæ•°æ®å¸¸å­˜åœ¨ç¼ºå¤±æ¨¡æ€ï¼ˆå¦‚ç¼ºå°‘ MRI æˆ–åŸºå› ä¿¡æ¯ï¼‰ï¼Œè€Œç°æœ‰æ¨¡å‹ç¼ºä¹æ˜¾å¼æœºåˆ¶åº”å¯¹è¿™ä¸€ç°å®é—®é¢˜ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
ä½œè€…æå‡º **SMMTï¼ˆSparse Multi-Modal Transformer with Maskingï¼‰**ï¼Œä¸€ç§ä»ç³»ç»Ÿå±‚é¢è®¾è®¡çš„é«˜æ•ˆã€é²æ£’çš„å¤šæ¨¡æ€ Transformer æ¶æ„ï¼Œå…¶ä¸¤å¤§æ ¸å¿ƒåˆ›æ–°ä¸ºï¼š

- **Cluster-based Sparse Attentionï¼ˆåŸºäºèšç±»çš„ç¨€ç–æ³¨æ„åŠ›ï¼‰**  
  å¼•å…¥ K-Means èšç±»å°† token åˆ†ç»„ï¼Œåœ¨æ¯ä¸ªç°‡å†…è¿›è¡Œå±€éƒ¨æ³¨æ„åŠ›è®¡ç®—ï¼Œå°†è®¡ç®—å¤æ‚åº¦ä» $O(n^2)$ é™ä½è‡³ $O(n \log n)$ï¼Œæ˜¾è‘—æå‡è®­ç»ƒæ•ˆç‡ã€‚

- **Modality-wise Maskingï¼ˆæ¨¡æ€çº§æ©ç å­¦ä¹ ï¼‰**  
  åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éšæœºä¸¢å¼ƒæŸä¸€æ¨¡æ€çš„ç‰¹å¾è¡¨ç¤ºï¼ˆæ¨¡æ‹Ÿç¼ºå¤±åœºæ™¯ï¼‰ï¼Œå¢å¼ºæ¨¡å‹å¯¹ä¸å®Œæ•´è¾“å…¥çš„æ³›åŒ–èƒ½åŠ›ï¼Œæé«˜ä¸´åºŠå®ç”¨æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
ç›¸æ¯”å½“å‰æœ€å…ˆè¿›çš„ **3MTï¼ˆCascaded Multi-Modal Mixing Transformerï¼‰** å’Œå…¶ä»–åŸºçº¿æ¨¡å‹ï¼ŒSMMT å…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š
- æ˜¾è‘—é™ä½è®­ç»ƒæ—¶é—´å’Œå†…å­˜å ç”¨ï¼›
- å¤§å¹…å‡å°‘èƒ½æºæ¶ˆè€—å’Œç¢³æ’æ”¾ï¼›
- åœ¨å…¨é‡å’Œå°æ ·æœ¬æ•°æ®ä¸‹å‡ä¿æŒä¼˜è¶Šæ€§èƒ½ï¼›
- æ›´å¼ºçš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼Œå°¤å…¶é€‚ç”¨äºçœŸå®ä¸–ç•Œä¸­æ¨¡æ€ç¼ºå¤±çš„åœºæ™¯ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
å®éªŒåŸºäº **ADNI-1 å’Œ ADNI-2** æ•°æ®é›†ï¼Œä»…ä¿ç•™ç¡®è¯Šä¸º ADï¼ˆAlzheimerâ€™s Diseaseï¼‰æˆ– CNï¼ˆCognitively Normalï¼‰çš„ä¸ªä½“ï¼Œæ’é™¤ MCIï¼ˆè½»åº¦è®¤çŸ¥éšœç¢ï¼‰ä»¥é¿å…ç±»åˆ«ä¸å¹³è¡¡ã€‚æœ€ç»ˆå…±ä½¿ç”¨ **12,680 å¼  T1-weighted 2D MRI åˆ‡ç‰‡**ï¼Œå¹¶ä¸ç»“æ„åŒ–ä¸´åºŠå…ƒæ•°æ®å¯¹é½ã€‚

ä½¿ç”¨çš„æ¨¡æ€åŒ…æ‹¬ï¼š
- **Imaging**ï¼šMRI å›¾åƒï¼ˆç» MNI152 é…å‡†ã€å½’ä¸€åŒ–ä¸º 256Ã—256ï¼‰
- **Numerical Clinical Scores**ï¼šMMSEã€CDRã€FAQã€Age
- **Categorical Data**ï¼šAPOE genotypeã€Sex

### å®éªŒè®¾ç½®
- **æ¡†æ¶**ï¼šPyTorch
- **ç¡¬ä»¶**ï¼šNVIDIA GeForce RTX 3060 GPUï¼ˆ12GBï¼‰
- **è®­ç»ƒå‚æ•°**ï¼š
  - Epochs: 50ï¼ˆäº”æŠ˜äº¤å‰éªŒè¯å…± 250 epochsï¼‰
  - Batch Size: 8
  - Optimizer: Adam ($\text{lr} = 1\times10^{-3}$)
  - Latent Dimension: 512
  - Masking Ratio: $r = 0.3$

### è¯„ä¼°æŒ‡æ ‡

#### ï¼ˆ1ï¼‰åˆ†ç±»æ€§èƒ½æŒ‡æ ‡
- Accuracyï¼ˆå‡†ç¡®ç‡ï¼‰
- Precisionï¼ˆç²¾ç¡®ç‡ï¼‰
- Recall / Sensitivityï¼ˆå¬å›ç‡ / çµæ•åº¦ï¼‰
- F1-score
- Specificityï¼ˆç‰¹å¼‚æ€§ï¼‰
- AUCï¼ˆROC æ›²çº¿ä¸‹é¢ç§¯ï¼‰

#### ï¼ˆ2ï¼‰è®¡ç®—å¯æŒç»­æ€§æŒ‡æ ‡ï¼ˆé€šè¿‡ CodeCarbon å·¥å…·ç›‘æµ‹ï¼‰
- æ€»èƒ½é‡æ¶ˆè€—ï¼ˆkWhï¼‰ï¼šæ¶µç›– CPUã€GPUã€RAM
- COâ‚‚ æ’æ”¾é‡ï¼ˆkgCOâ‚‚ï¼‰ï¼šåŸºäºå°æ¹¾ç”µç½‘ç¢³å¼ºåº¦ï¼ˆ0.502 kgCOâ‚‚/kWhï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ¨¡å‹ | ç±»å‹ |
|------|------|
| **3MT [8]** | å½“å‰ SOTA å¤šæ¨¡æ€ Transformerï¼ˆçº§è”è·¨æ¨¡æ€æ³¨æ„åŠ›ï¼‰ |
| **ADDFformer [20]** | åŸºäº Transformer çš„å•æ¨¡æ€ MRI æ¨¡å‹ |
| **FusionNet [21]** | é€šç”¨å¤šæ¨¡æ€èåˆç½‘ç»œï¼ˆæ— æ³¨æ„åŠ›æœºåˆ¶ï¼‰ |
| **CNN-only [22]** | å•æ¨¡æ€ CNNï¼ˆå¦‚ VGG16ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆ100% æ•°æ®ï¼‰

| æ¨¡å‹ | Accuracy (%) | Sensitivity (%) | Specificity (%) | AUC |
|------|--------------|------------------|------------------|-----|
| **SMMT (Ours)** | **97.05** | **96.31** | **97.58** | **0.986** |
| 3MT [8] | 90.28 | 93.64 | 93.81 | 0.965 |
| ADDFformer [20] | 88.20 | 91.87 | 91.53 | 0.948 |
| FusionNet [21] | 94.28 | 91.01 | 93.24 | 0.956 |
| CNN-only [22] | 80.24 | 78.45 | 80.22 | 0.852 |

> âœ… SMMT åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡è¾¾åˆ°æœ€ä¼˜ï¼Œå°¤å…¶åœ¨ AUC ä¸Šè¡¨ç°çªå‡ºï¼Œè¡¨æ˜å…¶å…·æœ‰ä¼˜ç§€çš„åˆ¤åˆ«èƒ½åŠ›å’Œä¸´åºŠå¯é æ€§ã€‚

### å°æ ·æœ¬åœºæ™¯ä¸‹çš„é²æ£’æ€§ï¼ˆä½æ•°æ® regimeï¼‰

| æ•°æ®æ¯”ä¾‹ | SMMT (Ours) | 3MT [8] |
|---------|-------------|--------|
| 20%     | **84.96%**  | 78.92% |
| 40%     | **86.52%**  | 82.17% |
| 60%     | **91.28%**  | 86.25% |

> ğŸ” SMMT åœ¨æå°æ ·æœ¬æ¡ä»¶ä¸‹ä»èƒ½ç»´æŒè¾ƒé«˜ç²¾åº¦ï¼Œå±•ç°å‡ºå“è¶Šçš„æ•°æ®æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚

### è®­ç»ƒæ•ˆç‡ä¸èƒ½è€—å¯¹æ¯”

| ç»„ä»¶ | 3MT (Baseline) | SMMT (Ours) | å‡å°‘å¹…åº¦ |
|------|----------------|------------|----------|
| **GPU Energy** | 0.283977 kWh | 0.159642 kWh | â†“ **43.8%** |
| **CPU Energy** | 0.108489 kWh | 0.071179 kWh | â†“ 34.4% |
| **RAM Energy** | 0.051035 kWh | 0.033485 kWh | â†“ 34.4% |
| **Total Energy** | **0.443501 kWh** | **0.264306 kWh** | â†“ **40.4%** |
| **COâ‚‚ Emissions** | 0.2226 kg | 0.1327 kg | â†“ **40.3%** |

> ğŸ’¡ èƒ½è€—é™ä½è¿‘ä¸€åŠï¼Œç­‰æ•ˆèŠ‚çœçº¦â€œä¸ºæ™ºèƒ½æ‰‹æœºå……ç”µ18æ¬¡â€æˆ–â€œç‚¹äº®60ç“¦ç¯æ³¡è¶…30å°æ—¶â€ï¼Œä½“ç°æ˜¾è‘—çš„ç¯å¢ƒå¯æŒç»­ä¼˜åŠ¿ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

| é…ç½® | 100% Accuracy / Time(min) | 20% Accuracy |
|------|----------------------------|-------------|
| 3MT (Baseline) | 90.28 / 133 | 78.92 |
| w/o Sparse Attention | 91.35 / 147 | 84.85 |
| w/o Masking | 95.42 / 108 | 80.85 |
| **SMMT (Full)** | **97.05 / 112** | **84.96** |

#### å‘ç°ï¼š
- ç§»é™¤ **Sparse Attention** å¯¼è‡´è®­ç»ƒæ—¶é—´å¤§å¹…å¢åŠ ï¼ˆâ†‘34 minï¼‰ï¼Œè¯´æ˜å…¶æœ‰æ•ˆæå‡æ•ˆç‡ï¼›
- ç§»é™¤ **Masking** åå°æ ·æœ¬æ€§èƒ½æ˜æ˜¾ä¸‹é™ï¼ˆâ†“4.11%ï¼‰ï¼ŒéªŒè¯å…¶æ­£åˆ™åŒ–ä¸é²æ£’æ€§ä½œç”¨ï¼›
- ä¸¤è€…ç»“åˆå®ç°æœ€ä½³å¹³è¡¡ï¼š**é«˜æ•ˆ + é«˜æ€§èƒ½ + å¼ºæ³›åŒ–**

æ­¤å¤–ï¼Œæ©ç æ¯”ç‡ $r$ çš„æ¶ˆèæ˜¾ç¤ºï¼š**å½“ $r=0.3$ æ—¶æ€§èƒ½è¾¾åˆ°å³°å€¼**ï¼Œè¿‡é«˜ï¼ˆ>0.6ï¼‰ä¼šç ´åå…³é”®ä¿¡æ¯ï¼Œå½±å“æ”¶æ•›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **SMMT åœ¨ä¿æŒç”šè‡³è¶…è¶Š SOTA æ€§èƒ½çš„åŒæ—¶ï¼Œå®ç°äº†æ˜¾è‘—çš„æ•ˆç‡æå‡**ï¼š
   - å‡†ç¡®ç‡è¾¾ **97.05%**ï¼ˆAD vs. CNï¼‰
   - å°æ ·æœ¬ï¼ˆ20%ï¼‰ä¸‹ä»è¾¾ **84.96%**
   - è®­ç»ƒèƒ½è€—é™ä½ **40.4%**

2. **ç¨€ç–æ³¨æ„åŠ›ä¸ä»…æ˜¯åŠ é€Ÿæ‰‹æ®µï¼Œä¹Ÿå…·å¤‡éšå¼æ­£åˆ™åŒ–æ•ˆæœ**ï¼š
   - é™åˆ¶ token é—´æ— æ•ˆäº¤äº’ï¼ŒæŠ‘åˆ¶è¿‡æ‹Ÿåˆï¼Œåè€Œæœ‰åŠ©äºæå‡æ³›åŒ–èƒ½åŠ›ã€‚

3. **æ¨¡æ€çº§æ©ç æ˜¯æå‡é²æ£’æ€§çš„å…³é”®è®¾è®¡**ï¼š
   - æ¨¡æ‹ŸçœŸå®ä¸´åºŠä¸­çš„æ¨¡æ€ç¼ºå¤±ï¼Œä½¿æ¨¡å‹æ›´å…·å®ç”¨ä»·å€¼ã€‚

4. **SMMT ç‰¹åˆ«é€‚åˆèµ„æºå—é™ã€æ•°æ®ç¨€ç¼ºçš„çœŸå®åŒ»ç–—åœºæ™¯**ï¼š
   - å…¼é¡¾é«˜æ€§èƒ½ã€ä½èƒ½è€—ã€é«˜é²æ£’æ€§ï¼Œç¬¦åˆâ€œç»¿è‰² AIâ€ä¸â€œå¯æ‰©å±•æ™ºèƒ½ç³»ç»Ÿâ€çš„å‘å±•æ–¹å‘ã€‚

### å±€é™æ€§
- å½“å‰ç ”ç©¶èšç„¦äº **äºŒåˆ†ç±»ä»»åŠ¡ï¼ˆAD vs. CNï¼‰**ï¼ŒæœªåŒ…å« MCIï¼ˆè½»åº¦è®¤çŸ¥éšœç¢ï¼‰é˜¶æ®µï¼›
- MCI æ ·æœ¬è¾ƒå°‘ä¸”æ˜“å¼•å‘ç±»åˆ«ä¸å¹³è¡¡ï¼Œé™åˆ¶äº†æ›´ç»†ç²’åº¦ç–¾ç—…è¿›å±•å»ºæ¨¡ï¼›
- æ‰€æœ‰å®éªŒåŸºäºå•ä¸€ç¡¬ä»¶å¹³å°ï¼ˆRTX 3060ï¼‰ï¼Œå°šæœªåœ¨è¾¹ç¼˜è®¾å¤‡æˆ–å¤šä¸­å¿ƒå¼‚æ„ç¯å¢ƒä¸­éªŒè¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. æ‰©å±•è‡³ **ä¸‰åˆ†ç±»æˆ–å¤šé˜¶æ®µé¢„æµ‹ä»»åŠ¡**ï¼ˆCN â†’ MCI â†’ ADï¼‰ï¼Œæ”¯æŒçºµå‘å»ºæ¨¡ï¼ˆlongitudinal modelingï¼‰ï¼›
2. è®¾è®¡ **adaptive modality selection** æœºåˆ¶ï¼Œåœ¨æ¨ç†æ—¶åŠ¨æ€å¤„ç†å¯å˜æ¨¡æ€è¾“å…¥ï¼›
3. åœ¨æ›´å¤§è§„æ¨¡ã€æ›´å¤šæ ·åŒ–çš„ä¸´åºŠæ•°æ®é›†ä¸ŠéªŒè¯æ³›åŒ–èƒ½åŠ›ï¼›
4. æ¢ç´¢ SMMT åœ¨ **Human Digital Twin** æˆ–è¿œç¨‹å¥åº·ç›‘æµ‹ç³»ç»Ÿä¸­çš„é›†æˆåº”ç”¨ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> SMMT æ˜¯ä¸€ä¸ªé¢å‘å®é™…ä¸´åºŠéœ€æ±‚çš„é«˜æ•ˆã€é²æ£’ã€ç¯ä¿çš„å¤šæ¨¡æ€ Transformer æ¶æ„ï¼Œåœ¨ AD åˆ†ç±»ä»»åŠ¡ä¸­å®ç°äº†æ€§èƒ½ã€æ•ˆç‡ä¸å¯æŒç»­æ€§çš„ç»Ÿä¸€ï¼Œä¸ºèµ„æºå—é™ç¯å¢ƒä¸‹çš„åŒ»å­¦ AI éƒ¨ç½²æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 5. [Dynamic Rebatching for Efficient Early-Exit Inference with DREX](https://arxiv.org/abs/2512.15705)

**Authors**: Xuting Liu, Daniel Alexander, Siva Kesava Reddy Kakarla, Behnaz Arzani, Vincent Liu  
**Category**: cs.DC  
**Published**: 2025-12-18  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.15705v1  

#### Abstract
Early-Exit (EE) is a Large Language Model (LLM) architecture that accelerates inference by allowing easier tokens to be generated using only a subset of the model's layers. However, traditional batching frameworks are ill-suited for EE LLMs, as not all requests in a batch may be ready to exit at the...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šDynamic Rebatching for Efficient Early-Exit Inference with DREX**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
ä¼ ç»Ÿ **Early-Exit (EE)** æ¨ç†æ¶æ„è™½èƒ½é€šè¿‡è®©â€œç®€å•â€tokenæå‰é€€å‡ºæ·±å±‚ç½‘ç»œæ¥èŠ‚çœè®¡ç®—èµ„æºï¼Œä½†åœ¨**æ‰¹å¤„ç†ï¼ˆbatchingï¼‰åœºæ™¯ä¸‹å­˜åœ¨ä¸¥é‡æŒ‘æˆ˜**ï¼š
- **Split Decision é—®é¢˜**ï¼šä¸€ä¸ª batch ä¸­éƒ¨åˆ†è¯·æ±‚æ»¡è¶³æ—©é€€æ¡ä»¶ï¼Œå¦ä¸€äº›ä¸æ»¡è¶³ï¼Œå¯¼è‡´æ— æ³•ç»Ÿä¸€å†³ç­–ã€‚
- **Grouped Exit æ”¿ç­–çš„ç¼ºé™·**ï¼š
  - *Consensus*ï¼šæ‰€æœ‰è¯·æ±‚éƒ½éœ€åŒæ„æ‰é€€å‡º â†’ å¯¼è‡´å¤§é‡ **involuntary stays**ï¼ˆæœ¬å¯æ—©é€€å´è¢«è¿«ç»§ç»­ï¼‰ï¼Œæµªè´¹ EE æœºä¼šã€‚
  - *Greedy/Majority*ï¼šå°‘æ•°æˆ–å¤šæ•°åŒæ„å³å…¨ä½“é€€å‡º â†’ å¯¼è‡´ **involuntary exits**ï¼ˆæœ¬åº”ç»§ç»­å´è¢«è¿«é€€å‡ºï¼‰ï¼Œä¸¥é‡æŸå®³è¾“å‡ºè´¨é‡ã€‚
- **Missing KV Cache é—®é¢˜**ï¼šæ—©é€€ token è·³è¿‡äº†æ·±å±‚ï¼Œå…¶ KV Cache åœ¨åç»­è§£ç ä¸­ç¼ºå¤±ï¼Œå½±å“è‡ªå›å½’æ¨ç†ã€‚

è¿™äº›é—®é¢˜ä½¿å¾— EE åœ¨å®é™…éƒ¨ç½²ä¸­éš¾ä»¥å…¼é¡¾**é«˜ååé‡**ä¸**é«˜è´¨é‡è¾“å‡º**ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
è®ºæ–‡æå‡º **DREX**ï¼Œé¦–ä¸ªæ”¯æŒé«˜æ•ˆæ‰¹å¤„ç† EE æ¨ç†çš„æœåŠ¡ç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒæ˜¯ **Dynamic Rebatchingï¼ˆåŠ¨æ€é‡æ‰¹å¤„ç†ï¼‰** æ¶æ„ï¼Œå¹¶é…å¥—ä¸¤å¤§ä¼˜åŒ–ï¼š

#### **1. Dynamic Rebatching**
- ä¸å¼ºåˆ¶æ•´ä¸ª batch ç»Ÿä¸€å†³ç­–ã€‚
- å½“å‡ºç° split decision æ—¶ï¼š
  - æ»¡è¶³æ¡ä»¶çš„è¯·æ±‚ç«‹å³æ—©é€€å¹¶ç”Ÿæˆ tokenã€‚
  - æœªæ»¡è¶³çš„è¯·æ±‚æš‚å­˜äº **é€»è¾‘ç¼“å†²åŒºï¼ˆlogical bufferï¼‰**ã€‚
  - ç¼“å†²åŒºç§¯ç´¯è¶³å¤Ÿè¯·æ±‚åï¼Œé‡æ–°ç»„æˆæ–° batch è¿›å…¥æ·±å±‚ã€‚
- å®ç°**æ¯ä¸ªè¯·æ±‚ç‹¬ç«‹å†³ç­–**ï¼Œå®Œå…¨é¿å… involuntary exitsã€‚

#### **2. ä¸¤é¡¹å…³é”®æŠ€æœ¯ä¼˜åŒ–**
- **Copy-Free Rebatching Buffer**ï¼š
  - åˆ©ç”¨ç°ä»£æ³¨æ„åŠ›å†…æ ¸ï¼ˆå¦‚ FlashAttentionï¼‰çš„ `cache_batch_idx` APIï¼Œé€šè¿‡è™šæ‹Ÿå¼ é‡ç´¢å¼•å®ç°**é›¶ç‰©ç†æ•°æ®ç§»åŠ¨**çš„é‡æ‰¹å¤„ç†ã€‚
  - å¼€é”€æä½ï¼ˆåœ¨ Llama-EE-70B ä¸Š < 6% å•æ¬¡è¿­ä»£æ—¶é—´ï¼‰ã€‚
- **Memory-Efficient State-Copying**ï¼š
  - é’ˆå¯¹è·³è¿‡å±‚çš„ KV Cache ç¼ºå¤±é—®é¢˜ï¼Œé‡‡ç”¨**è™šæ‹Ÿå†…å­˜æ˜ å°„**ï¼ˆvirtual memory mappingï¼‰å…±äº«æœ€åä¸€å±‚çš„ KV Cache ç‰©ç†å—ã€‚
  - é¿å…ç‰©ç†å¤åˆ¶ï¼Œæ¶ˆé™¤å†…å­˜å†—ä½™ã€‚

#### **3. æ€§èƒ½ä¿éšœæœºåˆ¶**
- **Adaptive Rebatching Threshold (ART)**ï¼š
  - åˆ†ææ€§é¢„æµ‹ rebatching æ˜¯å¦ç›ˆåˆ©ï¼ˆæ”¶ç›Š > å¼€é”€ï¼‰ã€‚
  - è‹¥æ—©é€€æ¯”ä¾‹å¤ªå°ï¼Œå¼€é”€å¤§äºæ”¶ç›Šï¼Œåˆ™æ”¾å¼ƒ rebatchingã€‚
- **SLA-Aware Forced Flushing**ï¼š
  - è‹¥ç¼“å†²åŒºä¸­è¯·æ±‚æ¥è¿‘ SLA æˆªæ­¢æ—¶é—´ï¼Œåˆ™å¼ºåˆ¶åˆ·æ–°ï¼Œé˜²æ­¢å»¶è¿Ÿè¶…æ ‡ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹æ³• | ååé‡ | è¾“å‡ºè´¨é‡ | Involuntary Exits | Involuntary Stays |
|------|--------|----------|-------------------|-------------------|
| **Consensus** | ä½ | é«˜ | 0 | é«˜ |
| **Greedy** | é«˜ | æä½ | æé«˜ | 0 |
| **Latency-Only (Apparate)** | ä½ | é«˜ | 0 | é«˜ |
| **DREX (æœ¬æ–‡)** | **é«˜** | **é«˜** | **0** | **ä½** |

- **å”¯ä¸€åŒæ—¶å®ç°é«˜ååä¸é«˜è´¨é‡çš„æ–¹æ³•**ã€‚
- **å®Œå…¨æ¶ˆé™¤ involuntary exits**ï¼Œä¿è¯ EE æ¨¡å‹è®¾è®¡çš„è¾“å‡ºè´¨é‡ã€‚
- **æ˜¾è‘—é™ä½ KV Cache å†—ä½™**ï¼Œæœ€é«˜å‡å°‘ 18.3% CUDA å†…å­˜ä½¿ç”¨ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ¨¡å‹ä¸æ•°æ®é›†**
- **æ¨¡å‹**ï¼š
  - `Llama-EE-13B`, `Llama-EE-70B`, `Qwen-EE-14B`
  - EE é…ç½®ï¼šSoftmax ç½®ä¿¡åº¦åˆ†ç±»å™¨ + å¯é…ç½®çš„ exit ramp å±‚ä¸é˜ˆå€¼ï¼ˆè§ Table 3ï¼‰
- **æ•°æ®é›†**ï¼š
  - **CNN/Daily Mail** æ–‡æœ¬æ‘˜è¦ä»»åŠ¡ï¼ˆæ¥è‡ª HELM benchmarkï¼‰
  - è¿‡æ»¤æ–‡ç« é•¿åº¦ < 2048 tokensï¼Œå…± 2160 æ¡æ ·æœ¬
- **ç¡¬ä»¶**ï¼š
  - A100 (80GB) ç”¨äº 13B/14B æ¨¡å‹
  - H200 (141GB) ç”¨äº 70B æ¨¡å‹

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

#### **è¯„ä¼°æŒ‡æ ‡**
| ç±»åˆ« | æŒ‡æ ‡ | å®šä¹‰ |
|------|------|------|
| **Performance** | Throughput | æ¯ç§’ç”Ÿæˆçš„ output token æ•° |
|               | RCT (Request Completion Time) | è¯·æ±‚ä»è°ƒåº¦åˆ°å®Œæˆçš„æ—¶é—´ |
| **Quality** | P95 Confidence Score | æ—©é€€ token çš„ç½®ä¿¡åº¦ç¬¬95ç™¾åˆ†ä½ï¼Œåæ˜ è¾“å‡ºè´¨é‡ |
|           | BERT Score | ç”Ÿæˆæ‘˜è¦ä¸å‚è€ƒæ‘˜è¦çš„è¯­ä¹‰ç›¸ä¼¼åº¦ |
| **EE Stats** | EE Proportion | æ—©é€€ token å æ¯” |
|            | Involuntary Exit (%) | å¼ºåˆ¶æ—©é€€çš„ token æ¯”ä¾‹ |
|            | Involuntary Stay (%) | å¼ºåˆ¶ç»§ç»­çš„ token æ¯”ä¾‹ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **Latency-Only**ï¼šæ—©é€€ä½†ä»åœ¨ batch ä¸­ç»§ç»­è®¡ç®—ï¼ˆApparateï¼‰
- **Consensus**ï¼šå…¨ batch åŒæ„æ‰é€€å‡º
- **Majority**ï¼šå¤šæ•°æŠ•ç¥¨å†³å®š
- **Greedy**ï¼šä»»ä¸€è¯·æ±‚æƒ³é€€å‡ºåˆ™å…¨ batch é€€å‡º
- **Non-EE**ï¼šæ— æ—©é€€åŸºçº¿

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
- **ååæå‡**ï¼šç›¸æ¯” Non-EE åŸºçº¿ï¼ŒDREX æå‡ **2â€“12%** ååé‡ã€‚
- **P95 Confidence Score**ï¼šä¸ Non-EE å’Œ Conservative åŸºçº¿æŒå¹³æˆ–æ›´ä¼˜ï¼Œ**è¿œé«˜äº Greedy**ï¼ˆGreedy ä»…ä¸º 0.03ï¼‰ã€‚
- **BERT Score**ï¼šä¸ Conservative æ–¹æ³•ç›¸è¿‘ï¼Œç•¥ä½äºï¼ˆå› æ›´å¤šæ—©é€€ï¼‰ï¼Œä½†ä¼˜äº Greedyã€‚
- **Involuntary Exits**ï¼š**DREX å®Œå…¨ä¸º 0%**ï¼Œè€Œ Greedy é«˜è¾¾ 25.9â€“35.1%ã€‚
- **KV Cache å†…å­˜èŠ‚çœ**ï¼šç›¸æ¯” EE-LLM çš„ state-copyingï¼ŒDREX å‡å°‘ **5.7% å¹³å‡ / 18.3% æœ€å¤§** CUDA å†…å­˜æ“ä½œã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
| æ–¹æ³• | åå | P95 Confidence | Involuntary Exit |
|------|------|----------------|------------------|
| **Greedy** | æœ€é«˜ | æä½ (0.03) | æé«˜ (~35%) |
| **Consensus** | æœ€ä½ | é«˜ | 0% |
| **DREX** | **ç¬¬äºŒé«˜ï¼ˆ+2â€“12% vs Non-EEï¼‰** | **é«˜ï¼ˆâ‰ˆ0.8ï¼‰** | **0%** |

- **DREX æ˜¯å”¯ä¸€åœ¨ååä¸è´¨é‡ä¹‹é—´å–å¾—å¹³è¡¡çš„æ–¹æ³•**ã€‚
- åœ¨ 2-exit é…ç½®ä¸‹ï¼ŒDREX æ¯” Greedy ååç•¥ä½ï¼Œä½† **BERT Score é«˜å‡º 11%**ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**
#### **Adaptive Rebatching Threshold (ART) çš„å½±å“**
- æ‰‹åŠ¨è®¾ç½® rebatching é˜ˆå€¼ï¼ŒéªŒè¯ DREX åŠ¨æ€è®¡ç®—çš„ ART æœ€ä¼˜ã€‚
- ç»“æœï¼ˆTable 5ï¼‰ï¼š
  - å¯¹ Llama-EE-13Bï¼Œæœ€ä¼˜ ART = 3 â†’ åå **127.35 t/s**
  - å›ºå®š ART=0ï¼ˆæ€»æ˜¯ rebatchï¼‰â†’ ååä»… 116.80 t/s
  - **æå‡ 9%**ï¼Œè¯æ˜é¿å…ä¸ç›ˆåˆ© rebatching è‡³å…³é‡è¦ã€‚

#### **SLA-Aware Scheduling çš„æ•ˆæœ**
- åœ¨é«˜ SLA å‹åŠ›ä¸‹ï¼ŒDREX è‡ªåŠ¨åˆ‡æ¢è‡³ç±»ä¼¼ Consensus è¡Œä¸ºï¼Œä¼˜å…ˆä¿éšœå»¶è¿Ÿã€‚
- åœ¨ä½å‹åŠ›ä¸‹ï¼Œä¼˜å…ˆååï¼Œå¹³å‡ RCT æå‡ 1.4Ã—ï¼ŒP95 RCT æå‡ 3Ã—ã€‚
- **SLA-aware è°ƒåº¦ä½¿å¹³å‡ RCT æ”¹å–„æœ€å¤š 58.4%**ï¼Œå®ç°åŠ¨æ€æƒè¡¡ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **Dynamic Rebatching æ˜¯å®ç°é«˜æ•ˆ EE æ¨ç†çš„å…³é”®**ï¼š
   - å…è®¸ per-request ç‹¬ç«‹å†³ç­–ï¼Œæœ€å¤§åŒ– EE æœºä¼šã€‚
   - ç»“åˆ copy-free buffer ä¸ virtual state-copyingï¼Œå¼€é”€æä½ã€‚
2. **DREX å®ç°äº†ååä¸è´¨é‡çš„å¸•ç´¯æ‰˜å‰æ²¿**ï¼š
   - ååæ˜¾è‘—é«˜äº Conservative æ–¹æ³•ï¼Œè´¨é‡è¿œé«˜äº Greedyã€‚
   - **é¦–æ¬¡å®ç° zero involuntary exits**ï¼Œç¡®ä¿ EE æ¨¡å‹çš„å¯é æ€§ã€‚
3. **Adaptive æœºåˆ¶è‡³å…³é‡è¦**ï¼š
   - ART é¿å…æ— æ•ˆ rebatchingï¼Œæå‡åå 9%ã€‚
   - SLA-aware flushing å®ç°åŠ¨æ€å»¶è¿Ÿ-ååæƒè¡¡ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–ç°ä»£æ³¨æ„åŠ›å†…æ ¸æ”¯æŒ**ï¼ˆå¦‚ FlashAttention çš„ `cache_batch_idx`ï¼‰ï¼Œå¯èƒ½é™åˆ¶åœ¨æ—§æ¡†æ¶ä¸Šçš„éƒ¨ç½²ã€‚
- **å¯¹æç«¯è´Ÿè½½æ•æ„Ÿ**ï¼šè‹¥ç³»ç»ŸæŒç»­é«˜è´Ÿè½½ä¸”æ—  split decisionï¼Œç¼“å†²åŒºå¯èƒ½ starveï¼ˆä½†æ¦‚ç‡ä½ï¼‰ã€‚
- **å½“å‰å‡è®¾ EE ramp å‡†ç¡®**ï¼Œæœªè”åˆä¼˜åŒ– EE å†³ç­–æœ¬èº«ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
- å°† DREX ä¸ **speculative decoding** æˆ– **Mixture-of-Depths** ç­‰åŠ¨æ€è®¡ç®—æŠ€æœ¯ç»“åˆã€‚
- æ¢ç´¢ **å¤š exit ramp çš„ååŒè°ƒåº¦**ã€‚
- è”åˆä¼˜åŒ– **EE å†³ç­–ç®—æ³•** ä¸ **æœåŠ¡è°ƒåº¦ç­–ç•¥**ï¼Œè¿›ä¸€æ­¥æå‡ç«¯åˆ°ç«¯æ•ˆç‡ã€‚
- æ‰©å±•è‡³ **vision-language models** æˆ– **encoder-decoder æ¶æ„**ã€‚

---

> **æ€»ç»“**ï¼šDREX æ˜¯é¦–ä¸ªå°† Early-Exit LLM ä»ç†è®ºæ¨å‘å®ç”¨çš„æ¨ç†ç³»ç»Ÿï¼Œé€šè¿‡ **Dynamic Rebatching + Copy-Free Buffer + Virtual State-Copying**ï¼Œå®ç°äº†**é«˜ååã€é«˜è´¨é‡ã€é›¶å¼ºåˆ¶é€€å‡º**çš„ EE æ¨ç†ï¼Œä¸ºå¤§è§„æ¨¡éƒ¨ç½² EE æ¨¡å‹æä¾›äº†åšå®åŸºç¡€ã€‚

</details>

---

### 6. [Bits for Privacy: Evaluating Post-Training Quantization via Membership Inference](https://arxiv.org/abs/2512.15335)

**Authors**: Chenxiang Zhang, Tongxi Qu, Zhong Li, Tian Zhang, Jun Pang, Sjouke Mauw  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.15335v1  

#### Abstract
Deep neural networks are widely deployed with quantization techniques to reduce memory and computational costs by lowering the numerical precision of their parameters. While quantization alters model parameters and their outputs, existing privacy analyses primarily focus on full-precision models, le...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Bits for Privacy: Evaluating Post-Training Quantization via Membership Inference*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
æœ¬æ–‡ç³»ç»Ÿåœ°ç ”ç©¶äº†**Post-Training Quantization (PTQ)** å¯¹æ¨¡å‹éšç§çš„å½±å“ï¼Œå¡«è¡¥äº†å½“å‰ç ”ç©¶ä¸­å¯¹ä½ç²¾åº¦é‡åŒ–æ¨¡å‹éšç§åˆ†æçš„ç©ºç™½ã€‚å°½ç®¡é‡åŒ–è¢«å¹¿æ³›ç”¨äºæå‡æ¨ç†æ•ˆç‡ï¼Œä½†å…¶å¯¹éšç§æ³„éœ²ï¼ˆå°¤å…¶æ˜¯é€šè¿‡ **Membership Inference Attacks, MIAs**ï¼‰çš„å½±å“å°šä¸æ˜ç¡®ã€‚

ç°æœ‰ç ”ç©¶å¤šé›†ä¸­äºå…¨ç²¾åº¦æ¨¡å‹æˆ–è®­ç»ƒé˜¶æ®µå¼•å…¥é‡åŒ–çš„ QAT æ–¹æ³•ï¼Œè€Œæœ¬æ–‡é¦–æ¬¡èšç„¦äº**æ— éœ€å†è®­ç»ƒçš„ PTQ æ–¹æ³•åœ¨ä¸åŒæ¯”ç‰¹å®½åº¦ä¸‹çš„éšç§-æ•ˆç”¨æƒè¡¡**ã€‚

---

### âœ… æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯

- **é¦–æ¬¡ç³»ç»Ÿè¯„ä¼° PTQ åœ¨å¤šä¸ªå…ˆè¿›ç®—æ³•ï¼ˆAdaRoundã€BRECQã€OBCï¼‰ä¸‹çš„éšç§è¡¨ç°**ï¼Œä½¿ç”¨æœ€å…ˆè¿›çš„ **LiRA (Likelihood Ratio Attack)** æ”»å‡»æ¡†æ¶è¿›è¡Œè¯„ä¼°ã€‚
- å¼•å…¥å¹¶é€‚é… **1.58-bit é‡åŒ–**ï¼ˆå¯¹åº” ternary æƒé‡ {-1,0,1}ï¼‰åˆ° PTQ æ¡†æ¶ä¸­ï¼Œæ¢ç´¢æç«¯ä½æ¯”ç‰¹ä¸‹çš„éšç§ä¿æŠ¤æ½œåŠ›ã€‚
- æå‡º **â€œè§£è€¦é‡åŒ–â€ï¼ˆdecoupled quantizationï¼‰** æ€è·¯ï¼šå°†æœ€åä¸€å±‚ä»¥æ›´é«˜ç²¾åº¦ï¼ˆå¦‚ 8-bitï¼‰ä¿ç•™ï¼Œå…¶ä½™å±‚ä¿æŒæä½æ¯”ç‰¹ï¼ˆå¦‚ 1.58-bitï¼‰ï¼Œå®ç°å¯¹éšç§-æ•ˆç”¨æƒè¡¡çš„ç»†ç²’åº¦æ§åˆ¶ã€‚

---

### âœ… ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **å®ç”¨æ€§** | PTQ ä¸éœ€è¦é‡æ–°è®­ç»ƒï¼Œé€‚ç”¨äºå®é™…éƒ¨ç½²åœºæ™¯ï¼›ç›¸æ¯” DP-SGD ç­‰éšç§ä¿æŠ¤æŠ€æœ¯ï¼Œæ— é¢å¤–è®­ç»ƒæˆæœ¬ã€‚ |
| **æ–°é¢–æ€§** | é¦–æ¬¡æ­ç¤º PTQ æœ¬èº«å¯ä½œä¸ºä¸€ç§è½»é‡çº§éšç§é˜²å¾¡æœºåˆ¶ï¼Œå°¤å…¶åœ¨ä½æ¯”ç‰¹ä¸‹æ˜¾è‘—é™ä½ MIA æˆåŠŸç‡ã€‚ |
| **çµæ´»æ€§** | é€šè¿‡è°ƒèŠ‚é‡åŒ–æ¯”ç‰¹æ•°ï¼ˆbit-widthï¼‰å’Œé‡‡ç”¨è§£è€¦ç­–ç•¥ï¼Œå¯åœ¨ç²¾åº¦æŸå¤±å¯æ§çš„å‰æä¸‹çµæ´»è°ƒæ•´éšç§æ°´å¹³ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **CIFAR-10**ï¼š10 ç±»å›¾åƒåˆ†ç±»ä»»åŠ¡ï¼Œ32Ã—32 å½©è‰²å›¾åƒã€‚
- **CIFAR-100**ï¼š100 ç±»æ›´å¤æ‚å›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚
- **TinyImageNet**ï¼š200 ç±»ï¼Œ64Ã—64 å›¾åƒï¼Œæ›´å…·æŒ‘æˆ˜æ€§ã€‚

> æ‰€æœ‰æ•°æ®é›†å‡ä¸º MIA ç ”ç©¶ä¸­çš„æ ‡å‡†åŸºå‡†ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®

| ç»„ä»¶ | è®¾ç½®è¯´æ˜ |
|------|----------|
| **ä¸»å¹²æ¨¡å‹** | ResNet18ï¼ˆé»˜è®¤ï¼‰ï¼Œéƒ¨åˆ†å®éªŒæ‰©å±•è‡³ ResNet50 å’Œ DenseNet121 |
| **é‡åŒ–æ–¹æ³•** | ä¸‰ç§ä¸»æµ PTQï¼š<br>â€¢ **AdaRound**<br>â€¢ **BRECQ**<br>â€¢ **OBC** |
| **é‡åŒ–çº§åˆ«** | 32-bitï¼ˆå…¨ç²¾åº¦ï¼‰ã€4-bitã€2-bitã€**1.58-bit**ï¼ˆternaryï¼‰ |
| **é‡åŒ–æ–¹å¼** | ä»…å¯¹æƒé‡è¿›è¡Œ per-channel asymmetric weight quantizationï¼Œæ¿€æ´»å‡½æ•°ä¿æŒ full-precision |
| **æ ¡å‡†æ•°æ®** | ä½¿ç”¨ 1024 ä¸ªæ¥è‡ªè®­ç»ƒé›†çš„æ ·æœ¬è¿›è¡Œæ ¡å‡†ï¼Œé¿å…æ•°æ®æ³„éœ² |
| **æ”»å‡»æ–¹æ³•** | **LiRA**ï¼ˆLikelihood Ratio Attackï¼‰<br>â€¢ Online æ”»å‡»ï¼ˆæ›´å¼ºï¼‰<br>â€¢ Offline æ”»å‡»ï¼ˆå« fixed variance æ¨¡å¼ï¼‰<br>â€¢ å…±è®­ç»ƒ 64 ä¸ª shadow models |
| **è¯„ä¼°æŒ‡æ ‡** | â€¢ **Utility**: Test Accuracy<br>â€¢ **Privacy**: TPR@0.1%FPRï¼ˆæ›´æ•æ„Ÿåæ˜ çœŸå®å¨èƒï¼‰<br>â€¢ Log-AUROCï¼ˆè¾…åŠ©å‚è€ƒï¼‰ |

---

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Full-precision model (32-bit)**ï¼šä½œä¸ºåŸºå‡†ï¼Œè¡¡é‡é‡åŒ–å¸¦æ¥çš„å½±å“ã€‚
- ä¸åŒæ¯”ç‰¹å®½åº¦çš„ PTQ æ¨¡å‹ä¹‹é—´æ¨ªå‘æ¯”è¾ƒï¼ˆ4-bit vs 2-bit vs 1.58-bitï¼‰ã€‚
- åŒä¸€é‡åŒ–æ–¹æ³•åœ¨ä¸åŒæ•°æ®é›†å’Œæ¶æ„ä¸Šçš„æ³›åŒ–èƒ½åŠ›éªŒè¯ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### ï¼ˆ1ï¼‰**1.58-bit é‡åŒ–æ•ˆæœï¼ˆCIFAR-100 ä¸Šï¼‰**

| æ–¹æ³• | ç²¾åº¦ï¼ˆ%ï¼‰ | TPR@0.1%FPR (Online) | ç›¸æ¯” Full-Precision ä¸‹é™å¹…åº¦ |
|------|-----------|------------------------|-------------------------------|
| Full-precision | 70.22 | 0.3765 | â€” |
| AdaRound 1.58-bit | 62.35 | **0.0031** | â†“99.2% |
| BRECQ 1.58-bit | 67.61 | 0.0045 | â†“98.8% |
| OBC 1.58-bit | 64.34 | 0.0052 | â†“98.6% |
| Sign Quantization (1-bit) | ~1.0 | â€” | å¤±è´¥ï¼ˆæ¥è¿‘éšæœºçŒœæµ‹ï¼‰ |

> âœ… ç»“è®ºï¼š**1.58-bit é‡åŒ–å¤§å¹…é™ä½ MIA æˆåŠŸç‡ï¼ˆä¸€ä¸ªæ•°é‡çº§ï¼‰ï¼ŒåŒæ—¶ä»ä¿ç•™è¾ƒé«˜å¯ç”¨æ€§**ã€‚

---

#### ï¼ˆ2ï¼‰**ä¸åŒæ¯”ç‰¹å®½åº¦çš„æ•´ä½“è¶‹åŠ¿ï¼ˆè§ Fig. 2 & Fig. 3ï¼‰**

| æ¯”ç‰¹æ•° | å‡†ç¡®ç‡å˜åŒ– | éšç§æ³„éœ²ï¼ˆTPRï¼‰ |
|-------|------------|------------------|
| **4-bit** | æ¥è¿‘ full-precisionï¼ˆ<1% å·®å¼‚ï¼‰ | éšç§æ³„éœ²æ°´å¹³ç›¸ä¼¼ç”šè‡³ç•¥é«˜ |
| **2-bit** | è½»å¾®ä¸‹é™ï¼ˆ~0.5â€“1%ï¼‰ | æ˜æ˜¾å‡å°‘ TPRï¼ˆçº¦ 50â€“70% é™ä½ï¼‰ |
| **1.58-bit** | æ˜¾è‘—ä¸‹é™ï¼ˆ~20â€“25% ç»å¯¹å€¼ï¼‰ | æå¤§æŠ‘åˆ¶ MIAï¼ˆTPR â†“99%ï¼‰ |

> ğŸ”º æ³¨æ„ï¼šTinyImageNet ä¸Š 1.58-bit å¯¼è‡´ä¸¥é‡ç²¾åº¦é€€åŒ–ï¼ˆAdaRound ä» 58% â†’ 33%ï¼‰ï¼Œéœ€è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚

---

#### ï¼ˆ3ï¼‰**æ¶ˆèå®éªŒç»“æœ**

##### âœ… è§£è€¦é‡åŒ–ï¼ˆDecoupled Quantizationï¼‰
- å°†æœ€åä¸€å±‚è®¾ä¸º 8-bitï¼Œå…¶ä½™ä¸º 1.58-bit æˆ– 2-bitã€‚
- **ç»“æœï¼ˆTinyImageNetï¼‰**ï¼š
  - AdaRound 1.58-bit + 8-bit last layerï¼šç²¾åº¦æ¢å¤è‡³ä»…æ¯” full-precision ä½ **5.6%**ï¼ˆåŸä¸º 26%ï¼‰ã€‚
  - åŒæ—¶ TPR@0.1%FPR ä»è¿œä½äº full-precision å’Œ 2-bit æ¨¡å‹ã€‚
- **æ„ä¹‰**ï¼šå®ç°äº†**é«˜ç²¾åº¦ä¸å¼ºéšç§ä¿æŠ¤çš„å¹³è¡¡**ï¼Œæä¾›å®ç”¨éƒ¨ç½²æ–¹æ¡ˆã€‚

##### âœ… ä¸åŒæ¨¡å‹æ¶æ„éªŒè¯ï¼ˆFig. 5ï¼‰
- åœ¨ ResNet18ã€ResNet50ã€DenseNet121 ä¸Šä½¿ç”¨ OBC è¿›è¡Œé‡åŒ–ã€‚
- æ‰€æœ‰æ¶æ„å‡è¡¨ç°å‡ºä¸€è‡´è¶‹åŠ¿ï¼š**æ›´ä½æ¯”ç‰¹ â‡’ æ›´ä½ç²¾åº¦ + æ›´ä½éšç§æ³„éœ²**ã€‚
- è¡¨æ˜ç»“è®ºå…·æœ‰è‰¯å¥½çš„**è·¨æ¶æ„æ³›åŒ–æ€§**ã€‚

##### âœ… 1.58-bit æ¨¡å‹çš„æ–¹å·®åˆ†æï¼ˆFig. 6ï¼‰
- BRECQ åœ¨ CIFAR-100 ä¸Šå‡ºç°ä¸¤ä¸ªé›†ç¾¤ï¼šä¸€éƒ¨åˆ†æ¨¡å‹ç²¾åº¦é«˜ä¸”éšç§å¥½ï¼Œå¦ä¸€éƒ¨åˆ†éšç§å·®ã€‚
- è¯´æ˜æŸäº› PTQ æ–¹æ³•ï¼ˆå¦‚ BRECQï¼‰å­˜åœ¨**è®­ç»ƒè¿‡ç¨‹ä¸­çš„ä¸ç¨³å®šæ€§**ï¼Œå¯¼è‡´éšç§è¡Œä¸ºæ³¢åŠ¨ã€‚
- æé†’å®è·µè€…éœ€å¤šæ¬¡è¿è¡Œä»¥è¯„ä¼°é²æ£’æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **ä½æ¯”ç‰¹ PTQ å¯æœ‰æ•ˆç¼“è§£ Membership Inference Attack**ï¼š
   - ç‰¹åˆ«æ˜¯ **1.58-bit é‡åŒ–**èƒ½å°† TPR@0.1%FPR é™ä½ **è¶…è¿‡ 99%**ï¼Œæ˜¾è‘—ä¼˜äº full-precision æ¨¡å‹ã€‚
   - è¿™è¡¨æ˜é‡åŒ–æœ¬èº«å¯è§†ä¸ºä¸€ç§éšå¼çš„å™ªå£°æ³¨å…¥æœºåˆ¶ï¼Œå‰Šå¼±æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®çš„è®°å¿†ã€‚

2. **å­˜åœ¨æ˜æ˜¾çš„ privacy-utility trade-off**ï¼š
   - 4-bit é‡åŒ–å‡ ä¹ä¸å½±å“ accuracy å’Œ privacyï¼›
   - 2-bit å¼€å§‹æ˜¾ç° trade-offï¼›
   - 1.58-bit å®ç°æœ€å¼ºéšç§ä¿æŠ¤ï¼Œä½†ä»£ä»·æ˜¯è¾ƒå¤§ accuracy æŸå¤±ã€‚

3. **è§£è€¦é‡åŒ–æ˜¯ä¸€ç§æœ‰æ•ˆçš„è°ƒæ§æ‰‹æ®µ**ï¼š
   - ä¿ç•™æœ€åä¸€å±‚é«˜ç²¾åº¦å¯åœ¨**å‡ ä¹ä¸ç‰ºç‰²éšç§çš„å‰æä¸‹æ˜¾è‘—æ¢å¤ accuracy**ï¼Œç‰¹åˆ«é€‚åˆé«˜è¦æ±‚ä»»åŠ¡ã€‚

4. **ç»“æœå…·æœ‰è·¨æ•°æ®é›†ä¸è·¨æ¶æ„çš„ä¸€è‡´æ€§**ï¼š
   - åœ¨ CIFAR-10ã€CIFAR-100ã€TinyImageNet åŠå¤šç§ DNN æ¶æ„ä¸Šå‡æˆç«‹ï¼Œå¢å¼ºäº†ç»“è®ºå¯ä¿¡åº¦ã€‚

5. **æ”»å‡»å¼ºåº¦å½±å“è¯„ä¼°ç»“æœ**ï¼š
   - LiRA Online æ”»å‡»æ›´éš¾é˜²å¾¡ï¼Œè€Œ Offline æ”»å‡»åœ¨ä½æ¯”ç‰¹ä¸‹æ˜“è¢«å®Œå…¨æŠ‘åˆ¶ï¼Œå¼ºè°ƒåº”ä½¿ç”¨å¼º baseline è¯„ä¼°éšç§ã€‚

---

### âš ï¸ å±€é™æ€§

| å±€é™ | è¯´æ˜ |
|------|------|
| **ä»…é™è§†è§‰é¢†åŸŸ** | å®éªŒåŸºäºå›¾åƒåˆ†ç±»ä»»åŠ¡ï¼ŒæœªéªŒè¯ NLP æˆ– graph æ¨¡å‹ä¸­çš„æœ‰æ•ˆæ€§ã€‚ |
| **ç¼ºä¹ç†è®ºè§£é‡Š** | å½“å‰ä¸ºç»éªŒæ€§å‘ç°ï¼Œå°šæœªå»ºç«‹é‡åŒ–æ¯”ç‰¹ä¸éšç§æ³„éœ²ä¹‹é—´çš„å½¢å¼åŒ–å…³ç³»ï¼ˆå¦‚åŸºäºä¿¡æ¯è®ºï¼‰ã€‚ |
| **ä¾èµ– shadow model å‡è®¾** | LiRA æ”»å‡»éœ€æ„å»º shadow modelsï¼Œåœ¨ç°å®ä¸­å¯èƒ½éš¾ä»¥å®Œå…¨å¤ç°ã€‚ |
| **æœªè€ƒè™‘ activation quantization** | ä»…é‡åŒ– weightsï¼Œè‹¥åŒæ—¶é‡åŒ– activations å¯èƒ½è¿›ä¸€æ­¥å½±å“éšç§-æ•ˆç”¨å¹³è¡¡ã€‚ |

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•è‡³å…¶ä»–æ¨¡æ€**ï¼šå°†ç ”ç©¶æ¨å¹¿åˆ°è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€å›¾ç¥ç»ç½‘ç»œç­‰é¢†åŸŸã€‚
2. **ç»“åˆå…¶ä»–éšç§æŠ€æœ¯**ï¼šæ¢ç´¢ PTQ ä¸ Differential Privacyã€Federated Learning ç­‰ç»“åˆçš„ååŒæ•ˆåº”ã€‚
3. **ç†è®ºå»ºæ¨¡**ï¼šå»ºç«‹é‡åŒ–å™ªå£°ä¸ä¿¡æ¯æ³„æ¼ä¹‹é—´çš„æ•°å­¦è”ç³»ï¼ŒæŒ‡å¯¼æœ€ä¼˜ bit-width é€‰æ‹©ã€‚
4. **è‡ªåŠ¨åŒ–è°ƒå‚**ï¼šè®¾è®¡ç®—æ³•è‡ªåŠ¨æœç´¢æœ€ä½³é‡åŒ–é…ç½®ï¼ˆå¦‚æ¯å±‚ bit æ•°ï¼‰ï¼Œå®ç°ä¸ªæ€§åŒ– privacy-utility å¹³è¡¡ã€‚
5. **ç ”ç©¶ scaling law ä¸‹çš„è¡Œä¸º**ï¼šæ¢ç©¶å¤§æ¨¡å‹åœ¨ä¸åŒè§„æ¨¡ä¸‹ PTQ å¯¹ MIA çš„å½±å“æ˜¯å¦éµå¾ªç‰¹å®šè§„å¾‹ã€‚

---

## âœ… æ€»ç»“

è¯¥è®ºæ–‡é¦–æ¬¡ç³»ç»Ÿæ­ç¤ºäº† **Post-Training Quantization** åœ¨éšç§ä¿æŠ¤æ–¹é¢çš„æ½œåŠ›ï¼Œè¯æ˜**æä½æ¯”ç‰¹é‡åŒ–ï¼ˆå¦‚ 1.58-bitï¼‰å¯æ˜¾è‘—é™ä½ Membership Inference Attack çš„æˆåŠŸç‡**ï¼Œä¸ºé«˜æ•ˆä¸”ç§æœ‰çš„æœºå™¨å­¦ä¹ éƒ¨ç½²æä¾›äº†æ–°çš„è§†è§’ã€‚é€šè¿‡å¼•å…¥è§£è€¦é‡åŒ–ç­‰ç­–ç•¥ï¼Œèƒ½å¤Ÿåœ¨å®ç”¨æ€§ä¸å®‰å…¨æ€§ä¹‹é—´å–å¾—è‰¯å¥½å¹³è¡¡ï¼Œå…·æœ‰é‡è¦çš„å·¥ç¨‹æŒ‡å¯¼ä»·å€¼ã€‚

</details>

---

### 7. [FlowBind: Efficient Any-to-Any Generation with Bidirectional Flows](https://arxiv.org/abs/2512.15420)

**Authors**: Yeonwoo Cha, Semin Kim, Jinhyeon Kwon, Seunghoon Hong  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2512.15420v1  

#### Abstract
Any-to-any generation seeks to translate between arbitrary subsets of modalities, enabling flexible cross-modal synthesis. Despite recent success, existing flow-based approaches are challenged by their inefficiency, as they require large-scale datasets often with restrictive pairing constraints, inc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# FlowBind: Efficient Any-to-Any Generation with Bidirectional Flows â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ç°æœ‰çš„ **flow-based any-to-any generation** æ–¹æ³•é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **æ•°æ®ä¾èµ–æ€§å¼º**ï¼šå¤šæ•°æ–¹æ³•éœ€è¦å®Œå…¨é…å¯¹çš„å¤šæ¨¡æ€æ•°æ®ï¼ˆå¦‚æ–‡æœ¬-å›¾åƒ-éŸ³é¢‘ä¸‰å…ƒç»„ï¼‰ï¼Œè¿™ç±»æ•°æ®ç¨€ç¼ºä¸”æ˜‚è´µã€‚
- **è®¡ç®—æˆæœ¬é«˜**ï¼šå»ºæ¨¡è”åˆåˆ†å¸ƒå¯¼è‡´è®¡ç®—å¤æ‚åº¦éšæ¨¡æ€æ•°å¹³æ–¹å¢é•¿ï¼Œè®­ç»ƒæ•ˆç‡ä½ã€‚
- **è®­ç»ƒæµç¨‹å¤æ‚**ï¼šæ™®éé‡‡ç”¨å¤šé˜¶æ®µè®­ç»ƒï¼ˆå¦‚å…ˆå¯¹é½å†ç”Ÿæˆï¼‰ï¼Œæµç¨‹ç¹çã€éš¾ä»¥ä¼˜åŒ–ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šFlowBind
FlowBind æ˜¯ä¸€ç§ç®€æ´é«˜æ•ˆçš„ **flow-based any-to-any generation æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å¼•å…¥ä¸€ä¸ª**å¯å­¦ä¹ çš„å…±äº«æ½œåœ¨ç©ºé—´ï¼ˆlearnable shared latentï¼‰**ï¼Œä½œä¸ºæ‰€æœ‰æ¨¡æ€ä¹‹é—´çš„â€œè¯­ä¹‰é”šç‚¹â€ã€‚
- æ¯ä¸ªæ¨¡æ€é€šè¿‡ä¸€ä¸ª**æ¨¡æ€ç‰¹å®šçš„å¯é€†æµï¼ˆinvertible flowï¼‰** è¿æ¥åˆ°è¯¥å…±äº«æ½œåœ¨ç©ºé—´ã€‚
- æ‰€æœ‰ç»„ä»¶åœ¨**å•ä¸€ flow matching ç›®æ ‡å‡½æ•°ä¸‹ç«¯åˆ°ç«¯è”åˆè®­ç»ƒ**ï¼Œæ— éœ€å¤šé˜¶æ®µæµç¨‹ã€‚

### ğŸ” åˆ›æ–°ç‚¹ä¸ä¼˜åŠ¿
| ç‰¹æ€§ | FlowBind | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ CoDi, OmniFlowï¼‰ |
|------|---------|-----------------------------|
| **è®­ç»ƒæ–¹å¼** | å•ä¸€ç›®æ ‡ã€ç«¯åˆ°ç«¯è”åˆè®­ç»ƒ | å¤šé˜¶æ®µè®­ç»ƒï¼ˆå¯¹é½ + ç”Ÿæˆï¼‰ |
| **æ•°æ®è¦æ±‚** | æ”¯æŒä»»æ„éƒ¨åˆ†é…å¯¹æ•°æ®ï¼ˆpartial pairingï¼‰ | éœ€è¦å…¨é…å¯¹æˆ–ä»¥æ–‡æœ¬ä¸ºé”šç‚¹çš„æ•°æ® |
| **è®¡ç®—æ•ˆç‡** | å‚æ•°æ›´å°‘ã€è®¡ç®—å¼€é”€æ›´ä½ | é«˜ç»´è”åˆå»ºæ¨¡ï¼Œè®¡ç®—æ˜‚è´µ |
| **çµæ´»æ€§** | è‡ªç„¶æ”¯æŒä»»æ„å­é›†è¾“å…¥â†’ä»»æ„å­é›†è¾“å‡º | å—é™äºå›ºå®šæ¶æ„è®¾è®¡ |

> ğŸ’¡ **å…³é”®æ´å¯Ÿ**ï¼šé€šè¿‡å°†å¤šæ¨¡æ€äº¤äº’è§£è€¦ä¸ºâ€œå„æ¨¡æ€ â†” å…±äº«æ½œå˜é‡â€çš„ç‹¬ç«‹æµï¼Œå®ç°äº†é«˜æ•ˆã€çµæ´»ä¸”å¯æ‰©å±•çš„ any-to-any ç”Ÿæˆã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
FlowBind åœ¨ **text, image, audio** ä¸‰ç§æ¨¡æ€ä¸Šè¿›è¡ŒéªŒè¯ï¼Œä½¿ç”¨ä»¥ä¸‹é…å¯¹æ•°æ®é›†ï¼ˆæ— ä¸‰å…ƒç»„ï¼‰ï¼š
- **Text-Image**: LAION-COCO (242K), Flickr-30k (30K)
- **Text-Audio**: AudioCaps v2 (91K)
- **Audio-Image**: VGGSound (184K)

> âš ï¸ ä¸ä½¿ç”¨ triplet æ•°æ®ï¼Œä½“ç°å…¶å¯¹éƒ¨åˆ†é…å¯¹æ•°æ®çš„å¼ºå¤§åˆ©ç”¨èƒ½åŠ›ã€‚

### ğŸ§ª å®éªŒè®¾ç½®
- **æ¨¡å‹è§„æ¨¡**ï¼šæ€»è®­ç»ƒå‚æ•°ä»… **568M**ï¼ˆè¿œå°äº CoDi çš„ 4.3B å’Œ OmniFlow çš„ 3.2Bï¼‰
- **è®­ç»ƒèµ„æº**ï¼šçº¦ **48 GPU-hours**ï¼ˆH100ï¼‰ï¼Œçº¦ä¸º OmniFlow çš„ 1/10
- **æ¨ç†æœºåˆ¶**ï¼š
  - ç¼–ç ï¼šè¾“å…¥æ¨¡æ€é€šè¿‡åå‘ ODE æ˜ å°„è‡³å…±äº«æ½œå˜é‡ $ z^* $
  - è§£ç ï¼šä» $ z^* $ å‡ºå‘ï¼Œç”¨ç›®æ ‡æ¨¡æ€çš„æ­£å‘ ODE ç”Ÿæˆè¾“å‡º
  - å¤šæºè¾“å…¥æ—¶ï¼Œå„æ¨¡æ€æ½œå˜é‡å–å¹³å‡

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
#### ï¼ˆ1ï¼‰ç”Ÿæˆè´¨é‡ï¼ˆFidelityï¼‰
- å›¾åƒï¼š**FID**
- éŸ³é¢‘ï¼š**FAD**
- æ–‡æœ¬ï¼š**CIDEr**

#### ï¼ˆ2ï¼‰è·¨æ¨¡æ€å¯¹é½ï¼ˆAlignmentï¼‰
- æ–‡æœ¬-å›¾åƒï¼š**CLIP Score**
- æ–‡æœ¬-éŸ³é¢‘ï¼š**CLAP Score**
- å›¾åƒ-éŸ³é¢‘ï¼š**AIS (Audio-Image Similarity)**

#### ï¼ˆ3ï¼‰ä»»åŠ¡ç±»å‹
- **One-to-One**ï¼š6 ç§ä¸¤ä¸¤è½¬æ¢ï¼ˆTâ†’I, Iâ†’T, Tâ†’A, Aâ†’T, Iâ†’A, Aâ†’Iï¼‰
- **Many-to-One / One-to-Many**ï¼šå®šé‡ + å®šæ€§åˆ†æ
- **Zero-shot æ³›åŒ–**ï¼šæ–°å¢ 3D point cloud æ¨¡æ€æµ‹è¯•æ³›åŒ–èƒ½åŠ›

### ğŸ†š åŸºçº¿æ–¹æ³•
- **Specialists**ï¼šSD3-Medium, FLUX.1, LLaVA-NeXT, TangoFlux, Qwen2-Audio ç­‰å•ä»»åŠ¡ä¸“å®¶æ¨¡å‹
- **Generalists**ï¼š
  - **CoDi**ï¼šåŸºäºæ–‡æœ¬åµŒå…¥å¯¹é½çš„å¤šæ¨¡æ€æ¡†æ¶
  - **OmniFlow**ï¼šè”åˆé€Ÿåº¦åœºå»ºæ¨¡çš„ flow-based any-to-any æ–¹æ³•

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ One-to-One ç”Ÿæˆæ€§èƒ½ï¼ˆè¡¨ 2 & è¡¨ 3ï¼‰

| æŒ‡æ ‡ | FlowBind vs. CoDi/OmniFlow |
|------|----------------------------|
| **ç”Ÿæˆè´¨é‡ï¼ˆFID/FAD/CIDErï¼‰** | åœ¨å…¨éƒ¨ 6 é¡¹ä»»åŠ¡ä¸­å–å¾—**æœ€ä½³è´¨é‡æŒ‡æ ‡** |
| **è·¨æ¨¡æ€å¯¹é½ï¼ˆCLIP/CLAP/AISï¼‰** | åœ¨ 6 é¡¹ä¸­æœ‰ 4 é¡¹ä¼˜äºåŸºçº¿ï¼Œå°¤å…¶åœ¨éæ–‡æœ¬ä»»åŠ¡ï¼ˆå¦‚ Iâ†’A, Aâ†’Iï¼‰è¡¨ç°çªå‡º |

> ğŸ”¥ **äº®ç‚¹**ï¼šåœ¨ **image-audio äº’ç”Ÿä»»åŠ¡** ä¸Šæ˜¾è‘—è¶…è¶Š specialist æ¨¡å‹ï¼Œè¯´æ˜å…±äº«æ½œç©ºé—´èƒ½æœ‰æ•ˆæ•æ‰éè¯­è¨€æ¨¡æ€é—´çš„æ·±å±‚å…³è”ã€‚

### ğŸ“Š Many-to-Many ç”Ÿæˆï¼ˆè¡¨ 4 & è¡¨ 5ï¼‰
æ„å»ºåˆæˆ triplet æ•°æ®é›†ç”¨äºè¯„ä¼°ï¼š

| è®¾ç½® | FlowBind è¡¨ç° |
|------|---------------|
| **(I+A)â†’T, (T+A)â†’I, (T+I)â†’A**ï¼ˆMany-to-Oneï¼‰ | åœ¨æ‰€æœ‰å¯¹é½æŒ‡æ ‡ä¸Š**å…¨é¢é¢†å…ˆ**ï¼Œå°¤å…¶åœ¨ (T+I)â†’A ä¸­ CLAP è¾¾ **28.13**ï¼ˆCoDi: 4.85ï¼‰ |
| **Tâ†’(I+A), Iâ†’(T+A), Aâ†’(T+I)**ï¼ˆOne-to-Manyï¼‰ | å¯¹é½åˆ†æ•°æ›´é«˜ï¼Œè¡¨æ˜èƒ½æ›´å¥½ä¿ç•™å¤šæ¨¡æ€æ¡ä»¶ä¿¡æ¯ |

> âœ… FlowBind æ›´å°‘å‡ºç°â€œå¿½ç•¥æŸä¸€è¾“å…¥æ¨¡æ€â€çš„é—®é¢˜ï¼Œæ˜¾ç¤ºæ›´å¼ºçš„**å¤šæ¡ä»¶èåˆèƒ½åŠ›**ã€‚

### ğŸ” æ¶ˆèå®éªŒä¸åˆ†æï¼ˆå…³é”®å‘ç°ï¼‰

#### ï¼ˆ1ï¼‰å…±äº«æ½œç©ºé—´çš„æœ‰æ•ˆæ€§ï¼ˆè¡¨ 6ï¼‰
- å¯¹æ¯”â€œå›ºå®šæ–‡æœ¬é”šâ€ vs â€œå¯å­¦ä¹ å…±äº«æ½œå˜é‡â€
- å³ä½¿ä¸ä½¿ç”¨ image-audio pair è®­ç»ƒï¼ŒFlowBind å˜ä½“ä»ä¼˜äº text-anchoring æ–¹æ³•
- ç»“è®ºï¼š**learnable shared latent æ›´æœ‰åˆ©äºè·¨æ¨¡æ€å¯¹é½**

#### ï¼ˆ2ï¼‰å…±äº«æ½œç©ºé—´çš„è¯­ä¹‰ä¸€è‡´æ€§ï¼ˆè¡¨ 7ï¼‰
ä½¿ç”¨ **CKNNA** åº¦é‡è¡¡é‡æ½œç©ºé—´å¯¹é½ç¨‹åº¦ï¼š
| æ¨¡æ€å¯¹ | Per-modality Latent | Shared Latent |
|--------|---------------------|--------------|
| T-A    | 0.1965              | **0.2872**   |
| A-I    | 0.1343              | **0.3026**   |

> è¡¨æ˜å…±äº«æ½œç©ºé—´å…·æœ‰æ›´å¼ºçš„è·¨æ¨¡æ€è¯­ä¹‰å¯¹é½èƒ½åŠ›ã€‚

#### ï¼ˆ3ï¼‰æ’å€¼å¯è§†åŒ–ï¼ˆå›¾ 3ï¼‰
- åœ¨å…±äº«æ½œç©ºé—´ä¸­è¿›è¡Œçº¿æ€§æ’å€¼ï¼Œè§£ç åå›¾åƒ/æ–‡æœ¬å‘ˆç°å¹³æ»‘è¯­ä¹‰è¿‡æ¸¡
- è¯æ˜è¯¥ç©ºé—´å…·å¤‡è‰¯å¥½çš„**è¿ç»­æ€§å’Œè¯­ä¹‰ç»“æ„æ€§**

#### ï¼ˆ4ï¼‰å†²çªæ¡ä»¶é²æ£’æ€§ï¼ˆå›¾ 4ï¼‰
- åœ¨è¯­ä¹‰å†²çªçš„ {text + audio} â†’ image ä»»åŠ¡ä¸­ï¼ŒFlowBind èƒ½åŒæ—¶åæ˜ ä¸¤ç§ä¿¡å·ï¼Œè€Œéé€€åŒ–ä¸ºå•ä¸€æ¨¡æ€ä¸»å¯¼
- å½’å› äºå…±äº«æ½œç©ºé—´çš„ç»“æ„åŒ–è¡¨ç¤ºèƒ½åŠ›

#### ï¼ˆ5ï¼‰æ‰©å±•è‡³ 3D Point Cloudï¼ˆå›¾ 6â€“7ï¼‰
- æ–°å¢æ¨¡æ€åªéœ€æ·»åŠ å¯¹åº” drift networkï¼Œå‚æ•°å¢é•¿è¿‘ä¼¼çº¿æ€§
- æˆåŠŸå®ç° **text â†’ point cloud** å’Œ **point cloud â†’ text** çš„ zero-shot è·¨æ¨¡æ€ç”Ÿæˆ
- å±•ç¤ºäº†å‡ºè‰²çš„**å¯æ‰©å±•æ€§ä¸æ³›åŒ–èƒ½åŠ›**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º
1. **FlowBind å®ç°äº†çœŸæ­£çµæ´»çš„ any-to-any generation**ï¼š
   - æ”¯æŒä»»æ„è¾“å…¥/è¾“å‡ºæ¨¡æ€ç»„åˆ
   - æ— éœ€å…¨é…å¯¹æ•°æ®ï¼Œè®­ç»ƒæ›´å®ç”¨

2. **æ•ˆç‡æ˜¾è‘—æå‡**ï¼š
   - å‚æ•°é‡ä»…ä¸º OmniFlow çš„ **1/6**
   - è®­ç»ƒæ—¶é—´ç¼©çŸ­ **10 å€**
   - æ¨ç†è¿‡ç¨‹ç®€å•é«˜æ•ˆï¼ˆä»…éœ€ ODE æ­£åå‘ç§¯åˆ†ï¼‰

3. **æ€§èƒ½åª²ç¾ç”šè‡³è¶…è¶Šå¤§æ¨¡å‹**ï¼š
   - åœ¨ one-to-one å’Œ many-to-many ä»»åŠ¡ä¸­å‡è¾¾åˆ° SOTA æˆ–æ¥è¿‘ SOTA æ°´å¹³
   - å°¤å…¶åœ¨éæ–‡æœ¬æ¨¡æ€é—´è½¬æ¢ï¼ˆå¦‚ audio-imageï¼‰è¡¨ç°å‡ºè‰²

4. **å…±äº«æ½œç©ºé—´æ˜¯æˆåŠŸçš„å…³é”®**ï¼š
   - å­¦ä¹ åˆ°ä¸€ä¸ªé«˜åº¦å¯¹é½ã€è¯­ä¹‰ä¸°å¯Œçš„å…±äº«è¡¨ç¤º
   - é€šè¿‡æœ€å°åŒ– conditional variance å®ç°ç¨³å®šè®­ç»ƒ

### âš ï¸ å±€é™æ€§
- å½“å‰ä¾èµ–é¢„è®­ç»ƒ encoder-decoderï¼ˆå¦‚ CLIP, CLAP, EmbeddingGemmaï¼‰ï¼Œæœªç«¯åˆ°ç«¯è®­ç»ƒæ•´ä¸ª pipeline
- å¯¹æç«¯è¯­ä¹‰å†²çªæˆ–å¤šæ¨¡æ€çŸ›ç›¾çš„å¤„ç†ä»æœ‰æ”¹è¿›ç©ºé—´
- å°šæœªåœ¨å¤§è§„æ¨¡çœŸå®ä¸–ç•Œå¤æ‚åœºæ™¯ä¸­éƒ¨ç½²éªŒè¯

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢åŠ¨æ€åŠ æƒèšåˆæœºåˆ¶æ›¿ä»£ç®€å•çš„ latent averaging
- æ‰©å±•è‡³æ›´å¤šæ¨¡æ€ï¼ˆå¦‚è§†é¢‘ã€3D meshã€è§¦è§‰ç­‰ï¼‰
- ç»“åˆ diffusion transformer æ¶æ„è¿›ä¸€æ­¥æå‡ç”Ÿæˆè´¨é‡
- æ¢ç´¢åœ¨ä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚æœºå™¨äººæ§åˆ¶ã€è·¨æ¨¡æ€æ£€ç´¢ï¼‰ä¸­çš„åº”ç”¨

---

## æ€»ç»“
FlowBind æå‡ºäº†ä¸€ç§**ç®€æ´ã€é«˜æ•ˆã€å¯æ‰©å±•**çš„ any-to-any ç”ŸæˆèŒƒå¼ã€‚å®ƒé€šè¿‡å¼•å…¥ **learnable shared latent + bidirectional invertible flows** çš„æ¶æ„ï¼Œåœ¨å¤§å¹…é™ä½æ•°æ®ä¸è®¡ç®—éœ€æ±‚çš„åŒæ—¶ï¼Œå®ç°äº†å¼ºå¤§çš„è·¨æ¨¡æ€ç”Ÿæˆèƒ½åŠ›ã€‚å®éªŒè¯æ˜å…¶ä¸ä»…åœ¨æ ‡å‡†ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¿˜èƒ½è‡ªç„¶æ”¯æŒå¤æ‚å¤šæ¨¡æ€è¾“å…¥è¾“å‡ºï¼Œå¹¶å…·å¤‡è‰¯å¥½çš„é›¶æ ·æœ¬æ³›åŒ–æ½œåŠ›ï¼Œä¸ºæ„å»ºé€šç”¨å¤šæ¨¡æ€ç”Ÿæˆæ¨¡å‹æä¾›äº†æ–°æ€è·¯ã€‚

> ğŸŒ é¡¹ç›®ä¸»é¡µï¼š[https://yeonwoo378.github.io/official_flowbind](https://yeonwoo378.github.io/official_flowbind)

</details>

---

### 8. [LLMQ: Efficient Lower-Precision Pretraining for Consumer GPUs](https://arxiv.org/abs/2512.15306)

**Authors**: Erik Schultheis, Dan Alistarh  
**Category**: cs.DC  
**Published**: 2025-12-18  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.15306v1  

#### Abstract
We present LLMQ, an end-to-end CUDA/C++ implementation for medium-sized language-model training, e.g. 3B to 32B parameters, on affordable, commodity GPUs. These devices are characterized by low memory availability and slow communication compared to datacentre-grade GPUs. Consequently, we showcase a ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLLMQ: Efficient Lower-Precision Pretraining for Consumer GPUs

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

LLMQ é’ˆå¯¹**æ¶ˆè´¹çº§ GPUï¼ˆå¦‚æ¸¸æˆæ˜¾å¡ï¼‰åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é¢„è®­ç»ƒä¸­é¢ä¸´çš„å†…å­˜å—é™ã€é€šä¿¡å¸¦å®½ä½**çš„é—®é¢˜ã€‚è¿™ç±»è®¾å¤‡è™½ç„¶æ€§ä»·æ¯”é«˜ï¼ˆFLOPs/dollarï¼‰ï¼Œä½†ç”±äºæ˜¾å­˜å°ï¼ˆå¦‚ 16â€“24GBï¼‰ã€ç¼ºä¹é«˜æ•ˆçš„ GPU é—´ç›´æ¥é€šä¿¡ï¼ˆå¦‚ NVLinkï¼‰ï¼Œéš¾ä»¥æ”¯æŒ 3Bâ€“32B å‚æ•°è§„æ¨¡çš„å®Œæ•´è®­ç»ƒæµç¨‹ã€‚

ä¼ ç»Ÿæ•°æ®ä¸­å¿ƒçº§ç³»ç»Ÿï¼ˆå¦‚åŸºäº H100 æˆ– L40S çš„é›†ç¾¤ï¼‰è™½èƒ½èƒœä»»ï¼Œä½†æˆæœ¬é«˜æ˜‚ä¸”éœ€å°†æ•°æ®ä¸Šä¼ è‡³äº‘ç«¯ï¼Œå­˜åœ¨éšç§ä¸è´¹ç”¨é—®é¢˜ã€‚LLMQ çš„ç›®æ ‡æ˜¯å®ç°**åœ¨å•èŠ‚ç‚¹ã€å¤šå—æ¶ˆè´¹çº§ GPU ä¸Šé«˜æ•ˆå®Œæˆä¸­ç­‰è§„æ¨¡ LLM çš„ç«¯åˆ°ç«¯é¢„è®­ç»ƒä¸å¾®è°ƒ**ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

LLMQ æ˜¯ä¸€ä¸ª**å®Œå…¨ç”¨ C++ å’Œ CUDA ç¼–å†™çš„ç«¯åˆ°ç«¯è®­ç»ƒæ¡†æ¶**ï¼Œä¸“ä¸ºæ¶ˆè´¹çº§ç¡¬ä»¶ä¼˜åŒ–ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

1. **FP8 + åŠ¨æ€å¼ é‡çº§ç¼©æ”¾ï¼ˆDynamic Tensor-Level Scalingï¼‰**
   - æ”¯æŒ Adaï¼ˆRTX 40xxï¼‰å’Œ Blackwellï¼ˆRTX 50xxï¼‰æ¶æ„ä¸Šçš„åŸç”Ÿ FP8 è®­ç»ƒã€‚
   - ä½¿ç”¨ **abs-max scaling** åœ¨å‰å‘ä¼ æ’­æ—¶è¿›è¡Œå³æ—¶é‡åŒ–ï¼Œä¿è¯æ— æº¢å‡ºï¼Œé€‚ç”¨äºç»Ÿè®¡å˜åŒ–å‰§çƒˆçš„å°æ‰¹é‡åœºæ™¯ã€‚
   - ä¸»è¦çŸ©é˜µè¿ç®—ï¼ˆmatmulï¼‰ä½¿ç”¨ FP8ï¼Œéçº¿æ€§å±‚ã€SDPAã€Embedding/LM-head ç­‰ä¿ç•™ BF16 ä»¥ä¿æŒæ•°å€¼ç¨³å®šæ€§ã€‚

2. **å¤šå±‚æ¬¡å†…å­˜ä¼˜åŒ–ç­–ç•¥ç»„åˆ**
   - **é€‰æ‹©æ€§é‡è®¡ç®—ï¼ˆSelective Recomputationï¼‰**ï¼šä»ä»…é‡ç®— SwiGLU/RMSNorm åˆ°æ•´ Transformer Block é‡ç®—ï¼Œçµæ´»åº”å¯¹ä¸åŒæ˜¾å­˜å®¹é‡ã€‚
   - **CPU Offloading**ï¼š
     - å°† optimizer statesï¼ˆm/vï¼‰ã€ä¸»å‚æ•°ï¼ˆmaster weightsï¼‰ã€æ®‹å·®ï¼ˆresidualsï¼‰ã€ç”šè‡³æ¢¯åº¦ç¼“å†²åŒº offload è‡³ä¸»æœºå†…å­˜ã€‚
     - åœ¨å•å¼  16GB RTX 5060Ti ä¸ŠæˆåŠŸè®­ç»ƒ 7B æ¨¡å‹ã€‚
   - **Chunking æŠ€æœ¯**ï¼šå¯¹ logits å’Œ FlashAttention çš„ workspace è¿›è¡Œåˆ†å—å¤„ç†ï¼Œé¿å…å› å¤§ batch å¯¼è‡´å†…å­˜çˆ†ç‚¸ã€‚

3. **åŸºäº cudaMemcpy çš„é€šä¿¡åç«¯**
   - é’ˆå¯¹æ¶ˆè´¹çº§ GPU æ— æ³•é€šè¿‡ PCIe ç›´æ¥ P2P é€šä¿¡çš„é—®é¢˜ï¼Œæå‡ºåˆ©ç”¨ **GPU Copy Engine** å®ç°é«˜æ•ˆçš„ Reduce-Scatter å’Œ All-Gatherã€‚
   - ç›¸æ¯” NCCLï¼Œåœ¨ RTX 4090 å¤šå¡ç³»ç»Ÿä¸Šæ˜¾è‘—æå‡ PCIe å¸¦å®½åˆ©ç”¨ç‡ï¼Œé‡Šæ”¾ SM èµ„æºç”¨äºè®¡ç®—ã€‚

4. **æƒé‡ç¼“å­˜äºä¸»æœºå†…å­˜ï¼ˆWeight Caching on Hostï¼‰**
   - åˆ©ç”¨â€œå¿…é¡»ç»è¿‡ CPU ä¸­è½¬â€çš„åŠ£åŠ¿å˜ä¼˜åŠ¿ï¼šå°†åˆ†ç‰‡æƒé‡æš‚å­˜äºä¸»æœºå†…å­˜ï¼Œåç»­å‰å‘ä¼ æ’­å¯å¤ç”¨ï¼Œå‡å°‘é‡å¤ä¼ è¾“ã€‚

5. **ç¡®å®šæ€§å†…æ ¸ä¸æ’åºä¼˜åŒ–**
   - æ‰€æœ‰ kernel å‡ä¸º bitwise-deterministicï¼Œç¡®ä¿å¯å¤ç°æ€§ã€‚
   - Embedding å±‚åå‘ä¼ æ’­é‡‡ç”¨ CPU æ’åº + åˆ†åŒºï¼Œé¿å…å¤§è§„æ¨¡åŸå­æ“ä½œå¸¦æ¥çš„ä¸­é—´ buffer å¼€é”€ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | LLMQ ä¼˜åŠ¿ |
|------|-----------|
| **ç¡¬ä»¶é€‚é…æ€§** | å¯è¿è¡Œäº RTX 30/40/50 ç³»åˆ—æ¶ˆè´¹å¡ï¼Œæ— éœ€æ•°æ®ä¸­å¿ƒçº§ç¡¬ä»¶ |
| **è®­ç»ƒæ•ˆç‡** | åœ¨ 4Ã—RTX 4090 ä¸Šè®­ç»ƒ 32B æ¨¡å‹è¾¾åˆ° **51% Model FLOPs Utilization (MFU)**ï¼Œè¶…è¿‡ L40S çš„ 29% MFU |
| **å†…å­˜æ•ˆç‡** | å•å¡ 16GB å¯è®­ 7B æ¨¡å‹ï¼ˆ70% MFUï¼‰ï¼Œè¿œè¶…åŒç±»æ¡†æ¶é™åˆ¶ |
| **é€šä¿¡æ•ˆç‡** | è‡ªç ” memcpy-based collectives æ˜¾è‘—ä¼˜äº NCCL åœ¨æ¶ˆè´¹çº§å¹³å°çš„è¡¨ç° |
| **ç²¾åº¦å…¼å®¹æ€§** | æ”¯æŒæ··åˆ BF16-FP8 è®­ç»ƒï¼Œå…¼é¡¾é€Ÿåº¦ä¸ç²¾åº¦ï¼Œä¸”ä¸å¼•å…¥ç®—æ³•è¿‘ä¼¼ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **ClimbMix**ï¼šç”¨äº 1.5B å‚æ•° Qwen é£æ ¼æ¨¡å‹çš„é¢„è®­ç»ƒï¼Œretokenized å¹¶ subsampled è‡³ 10B~30B tokensã€‚
- **GSM8K**ï¼šæ•°å­¦æ¨ç†ä»»åŠ¡ï¼Œç”¨äºè¯„ä¼° LLama2-7B å’Œ Qwen2.5-14B çš„å¾®è°ƒæ•ˆæœã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **ç¡¬ä»¶é…ç½®**
- å•å¡ï¼šRTX 5060Ti (16GB), RTX 4090 (24GB)
- å¤šå¡ï¼š4Ã—RTX 4090, 4Ã—L40S, DGX Sparkï¼ˆBlackwell æ¶æ„ï¼Œç»Ÿä¸€å†…å­˜ï¼‰
- å¯¹æ¯”å¯¹è±¡ï¼šLLama-Factoryï¼ˆä¸»æµå¼€æºå¾®è°ƒæ¡†æ¶ï¼‰

#### **è®­ç»ƒè®¾ç½®**
- å›ºå®šæ¯ step æ€» token æ•°ä¸º 500kï¼ˆmicro-batch Ã— seq_len Ã— accum_stepï¼‰
- åºåˆ—é•¿åº¦ï¼š2048ï¼ˆLLama2ï¼‰ï¼Œ512ï¼ˆQwenï¼‰
- ä¼˜åŒ–å™¨ï¼šAdamWï¼ˆFP8/BF16ï¼‰ï¼Œä½¿ç”¨ stochastic rounding
- å­¦ä¹ ç‡è°ƒåº¦ï¼šçº¿æ€§è¡°å‡ + warmup

#### **è¯„ä¼°æŒ‡æ ‡**
- **Tokens Per Second (TPS)**ï¼šååé‡
- **Model FLOPs Utilization (MFU)**ï¼šå®é™… FLOPs / ç†è®ºå³°å€¼ FLOPsï¼Œåæ˜ ç¡¬ä»¶åˆ©ç”¨ç‡
- **Speed-up (Sp)**ï¼šFP8 ç›¸è¾ƒ BF16 çš„åŠ é€Ÿæ¯”
- **ä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®ç‡**ï¼šGSM8K ä¸Šçš„ few-shot/zero-shot è¡¨ç°

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **LLama-Factory (LF)**ï¼šä½œä¸ºä¸»æµå¼€æºæ¡†æ¶ä»£è¡¨ï¼Œä½¿ç”¨ ZeRO-2/3 + DeepSpeed Offloadã€‚
- **NCCL-based collectives**ï¼šæ ‡å‡†é€šä¿¡åº“ vs LLMQ è‡ªç ” memcpy æ–¹æ¡ˆã€‚
- **BF16 baseline**ï¼šéªŒè¯ FP8 æ˜¯å¦å¸¦æ¥çœŸå®æ”¶ç›Šã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **å•å¡æ€§èƒ½ï¼ˆTable 1ï¼‰**

| æ¨¡å‹å¤§å° | è®¾å¤‡ | ç²¾åº¦ | TPS | MFU |
|--------|------|-----|-----|-----|
| 7B | RTX 5060Ti | FP8 | 1.4k | **70%** |
| 7B | RTX 4090 | FP8 | 4.3k | 61% |
| 14B | RTX 4090 | FP8 | 2.0k | 55% |

> âœ… å³ä½¿åœ¨ **16GB æ˜¾å­˜çš„ RTX 5060Ti** ä¸Šä¹Ÿèƒ½å®ç° **7B æ¨¡å‹è®­ç»ƒï¼ŒMFU è¾¾ 70%**ï¼Œæå…·çªç ´æ€§ã€‚

#### **å¤šå¡æ€§èƒ½ï¼ˆTable 2ï¼‰**

| æ¨¡å‹å¤§å° | è®¾å¤‡ | ç²¾åº¦ | TPS | MFU |
|--------|------|-----|-----|-----|
| 14B | 4Ã—RTX 4090 | FP8 | 7.8k | **54%** |
| 32B | 4Ã—RTX 4090 | FP8 | **3.4k** | **51%** |
| 32B | 4Ã—L40S | BF16 | 3.0k | 40% |

> âœ… **4Ã—RTX 4090 çš„ MFU æ˜¾è‘—é«˜äºæ›´è´µçš„ 4Ã—L40S**ï¼ˆ51% vs 29%ï¼‰ï¼Œè¯´æ˜æ¶ˆè´¹çº§ç¡¬ä»¶ç»ä¼˜åŒ–åæ›´å…·æ€§ä»·æ¯”ã€‚

#### **FP8 åŠ é€Ÿæ•ˆæœï¼ˆSpeed-up Spï¼‰**

- å¯¹äº 7B+ æ¨¡å‹ï¼ŒFP8 ç›¸æ¯” BF16 å¯å¸¦æ¥ **~50â€“59% çš„ååæå‡**ã€‚
- å°æ¨¡å‹åŠ é€Ÿæœ‰é™ï¼ˆ<30%ï¼‰ï¼Œå› é GEMM æ“ä½œå æ¯”é«˜ã€‚

#### **memcpy vs NCCL é€šä¿¡æ•ˆç‡ï¼ˆTable 5ï¼‰**

| è®¾å¤‡ | æ–¹æ³• | 14B æ¨¡å‹ TPSï¼ˆFP8ï¼‰ |
|------|------|------------------|
| 4Ã—RTX 4090 | NCCL | 4.3k |
| 4Ã—RTX 4090 | memcpy (full) | **7.8k** (**+81%**) |
| 4Ã—L40S | NCCL | 9.5k |
| 4Ã—L40S | memcpy (full) | 9.9k |

> âœ… **memcpy-based collectives åœ¨æ¶ˆè´¹çº§å¹³å°è‡³å…³é‡è¦**ï¼Œå‡ ä¹ç¿»å€æ€§èƒ½ï¼›ä½†åœ¨ä¸“ä¸šå¡ä¸Šå¢ç›Šè¾ƒå°ã€‚

#### **ä¸ LLama-Factory å¯¹æ¯”**

| æ¨¡å‹ | è®¾å¤‡ | LLMQ TPS | LF TPS | åŠ é€Ÿæ¯” |
|------|------|---------|--------|-------|
| 1.5B | 4Ã—4090 | 71k | 41k | ~1.7Ã— |
| 14B | 4Ã—4090 | 7.8k | 2.6k | **~3Ã—** |

> âœ… åœ¨å¤§è§„æ¨¡ä¸‹ LLMQ æ˜æ˜¾é¢†å…ˆï¼Œå°¤å…¶å½“éœ€è¦ offloading æ—¶ï¼ŒLLMQ æ›´é«˜æ•ˆã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

- **Offloading å±‚çº§å½±å“**ï¼šé€æ­¥ offload `m/v` â†’ `master weights` â†’ `residuals` â†’ `gradients`ï¼Œå¯åœ¨ 16GB æ˜¾å­˜ä¸‹å°† micro-batch ä» 2 æå‡è‡³ 16ã€‚
- **Recompute ç­–ç•¥**ï¼šå…¨ block é‡ç®— + offloading æ˜¯è®­ç»ƒ 7B çš„å¿…è¦æ¡ä»¶ã€‚
- **Chunking å¿…è¦æ€§**ï¼šæœª chunking æ—¶ 3B æ¨¡å‹æœ€å¤§ batch ä»…ä¸º 10ï¼Œchunking åå¯è¾¾ 24ã€‚
- **FP8 æ•°å€¼ç¨³å®šæ€§**ï¼š
  - E4M3ï¼ˆ4 exponent, 3 mantissaï¼‰è¡¨ç°æ¥è¿‘ BF16ï¼›
  - E5M2 åœ¨åå‘ä¼ æ’­ä¸­ç”¨äºæ¿€æ´»æ¢¯åº¦æ—¶ç•¥æœ‰æ€§èƒ½ä¸‹é™ï¼ŒæŒ‘æˆ˜ä¼ ç»Ÿæ¨èã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **æ¶ˆè´¹çº§ GPU å®Œå…¨å¯ä»¥èƒœä»»ä¸­ç­‰è§„æ¨¡ LLM è®­ç»ƒ**ï¼Œåªè¦ç³»ç»Ÿå±‚é¢å……åˆ†ä¼˜åŒ–å†…å­˜ä¸é€šä¿¡ã€‚
2. **FP8 è®­ç»ƒåœ¨å¤§æ¨¡å‹ä¸Šå¯å¸¦æ¥çº¦ 50% çš„ååæå‡**ï¼Œä¸”ç²¾åº¦æŸå¤±æå°ï¼ˆGSM8K å¾®è°ƒç»“æœç›¸å½“ï¼‰ã€‚
3. **memcpy-based collectives æ¯” NCCL æ›´é€‚åˆæ—  P2P æ”¯æŒçš„æ¶ˆè´¹çº§å¹³å°**ï¼Œèƒ½æœ‰æ•ˆéšè—é€šä¿¡å»¶è¿Ÿã€‚
4. **LLMQ åœ¨ MFU ä¸Šè¶…è¶Šä¸“ä¸šçº§ L40S GPU**ï¼Œè¯æ˜å…¶ä¼˜åŒ–æœ‰æ•ˆæ€§ã€‚
5. **å•å¼  16GB æ˜¾å¡è®­ç»ƒ 7B æ¨¡å‹æˆä¸ºç°å®**ï¼Œæå¤§é™ä½æœ¬åœ°è®­ç»ƒé—¨æ§›ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **ä¾èµ–ç»Ÿä¸€å†…å­˜æ¶æ„çš„æ½œåŠ›å°šæœªå®Œå…¨é‡Šæ”¾**ï¼šDGX Spark è™½æœ‰ 128GB ç»Ÿä¸€å†…å­˜ï¼Œä½†å†…å­˜å¸¦å®½è¾ƒä½ï¼ˆ300 GB/sï¼‰ï¼Œå¯¼è‡´ MFU ä¸åŠé¢„æœŸã€‚
2. **FP8 é•¿æœŸè®­ç»ƒç¨³å®šæ€§ä»å¾…éªŒè¯**ï¼šè®ºæ–‡æŒ‡å‡ºä½ç²¾åº¦å¯èƒ½åœ¨è¶…é•¿è®­ç»ƒï¼ˆ>Chinchilla æœ€ä¼˜æ¯”ä¾‹ï¼‰ä¸‹å¤±æ•ˆï¼Œå½“å‰ä¸»è¦ç”¨äºçŸ­å‘¨æœŸå¾®è°ƒæˆ–ä¸­ç­‰é•¿åº¦é¢„è®­ç»ƒã€‚
3. **æœªæ¶‰åŠ MoE æˆ–æç«¯é•¿åºåˆ—è®­ç»ƒ**ï¼šç›®å‰èšç„¦ dense æ¨¡å‹ä¸å¸¸è§„ä¸Šä¸‹æ–‡é•¿åº¦ã€‚
4. **NVMe offloading æœªå®ç°**ï¼šè™½ç„¶ç†è®ºä¸Šå¯è¡Œï¼Œä½†ä½œè€…è®¤ä¸ºä¼šç ´åè®¡ç®—éšè—é€šä¿¡çš„å¹³è¡¡ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ‰©å±•è‡³æ›´å¤šä½æ¯”ç‰¹æ ¼å¼**ï¼ˆå¦‚ INT8ã€FP6ã€1-bitï¼‰ä»¥è¿›ä¸€æ­¥å‹ç¼© optimizer statesã€‚
2. **é›†æˆ Parameter-Efficient Fine-Tuning (PEFT)** æ–¹æ³•ï¼ˆå¦‚ LoRAï¼‰ï¼Œä¸ç°æœ‰ offloading ååŒã€‚
3. **æ”¯æŒè·¨èŠ‚ç‚¹åˆ†å¸ƒå¼è®­ç»ƒ**ï¼Œç»“åˆå½“å‰å•èŠ‚ç‚¹é«˜æ•ˆé€šä¿¡å‘æ›´å¤§è§„æ¨¡æ‰©å±•ã€‚
4. **æ¢ç´¢ Blackwell æ¶æ„ä¸­çš„ç¡¬ä»¶ scaling æ”¯æŒ**ï¼Œæ¶ˆé™¤è½¯ä»¶ emulate å¼€é”€ã€‚
5. **è‡ªåŠ¨åŒ–é…ç½®æœç´¢**ï¼šæ ¹æ®ä¸åŒç¡¬ä»¶è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ recompute/offload/batch ç­–ç•¥ã€‚

---

> ğŸ”— **ä»£ç å¼€æºåœ°å€**ï¼š[https://github.com/IST-DASLab/llmq](https://github.com/IST-DASLab/llmq)

</details>

---

### 9. [Dual-Density Inference for Efficient Language Model Reasoning](https://arxiv.org/abs/2512.15358)

**Authors**: Zhengyi Zhao, Shubo Zhang, Yuxi Zhang, Huimin Wang, Binyang Li, Kam-Fai Wong  
**Category**: cs.CL  
**Published**: 2025-12-18  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.15358v1  

#### Abstract
Large Language Models (LLMs) have shown impressive capabilities in complex reasoning tasks. However, current approaches employ uniform language density for both intermediate reasoning and final answers, leading to computational inefficiency. Our observation found that reasoning process serves a comp...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠDual-Density Inference for Efficient Language Model Reasoningã€‹æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è¿›è¡Œå¤æ‚æ¨ç†ä»»åŠ¡æ—¶ï¼Œæ™®éé‡‡ç”¨ **Chain-of-Thought (CoT)** ç­‰æ–¹æ³•ï¼Œå…¶æ¨ç†è¿‡ç¨‹å’Œæœ€ç»ˆç­”æ¡ˆå‡ä½¿ç”¨ç›¸åŒçš„è‡ªç„¶è¯­è¨€ï¼ˆNatural Language, NLï¼‰ã€‚è¿™ç§åšæ³•å­˜åœ¨**è¡¨å¾é”™é…ï¼ˆrepresentational mismatchï¼‰**ï¼š
- **ä¸­é—´æ¨ç†**æ˜¯æ¨¡å‹å†…éƒ¨çš„è®¡ç®—è¿‡ç¨‹ï¼Œåº”è¿½æ±‚é«˜ä¿¡æ¯å¯†åº¦ã€ä½å†—ä½™ï¼›
- **æœ€ç»ˆå›ç­”**æ˜¯é¢å‘ç”¨æˆ·çš„æ²Ÿé€šè¾“å‡ºï¼Œéœ€å…·å¤‡å¯è¯»æ€§å’Œè§£é‡Šæ€§ã€‚

ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å°†ä¸¤è€…æ··ç”¨ï¼Œå¯¼è‡´å¤§é‡è®¡ç®—èµ„æºè¢«æµªè´¹åœ¨ç”Ÿæˆå†—ä½™çš„â€œè¯­æ³•ç³–â€ä¸Šï¼Œé€ æˆä¸¥é‡çš„**è®¡ç®—æ•ˆç‡ä½ä¸‹**ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡º **Denser: Dual-density Inference**ï¼Œä¸€ç§æ–°å‹çš„åŒå¯†åº¦æ¨ç†æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> **åˆ†ç¦»æ¨ç†ï¼ˆreasoningï¼‰ä¸å›ç­”ï¼ˆansweringï¼‰çš„è¯­è¨€å¯†åº¦**ã€‚

å…·ä½“å®ç°é€šè¿‡ä¸‰ä¸ªæ¨¡å—ï¼š
1. **Query Analysis Module**ï¼šåˆ†æè¾“å…¥é—®é¢˜ï¼Œè¯†åˆ«å…¶æ‰€å±é¢†åŸŸï¼ˆæ•°å­¦ã€é€»è¾‘ã€ä»£ç ç­‰ï¼‰ï¼Œå¹¶ç¡®å®šç›¸åº”çš„å‹ç¼©ç­–ç•¥ã€‚
2. **High-density Reasoning Module**ï¼šåœ¨ä¸­é—´æ¨ç†é˜¶æ®µï¼Œä½¿ç”¨**é«˜åº¦å‹ç¼©ã€ç¬¦å·åŒ–å¼º**çš„è¯­è¨€ï¼ˆå¦‚æ•°å­¦å…¬å¼ã€é€»è¾‘ç¬¦å·ã€ä¼ªä»£ç ï¼‰è¿›è¡Œé«˜æ•ˆè®¡ç®—ã€‚
3. **Low-density Answering Module**ï¼šåœ¨æ¨ç†å®Œæˆåï¼Œå°†å‹ç¼©çš„æ¨ç†è·¯å¾„**è§£å‹**ä¸ºäººç±»å¯è¯»çš„è‡ªç„¶è¯­è¨€è§£é‡Šã€‚

è¯¥æ–¹æ³•ä»ä¿¡æ¯è®ºè§’åº¦ä¼˜åŒ–äº†æ¨ç†é“¾çš„ä¿¡æ¯å¯†åº¦ï¼Œå®ç°äº†â€œå¯¹å†…é«˜æ•ˆï¼Œå¯¹å¤–å‹å¥½â€ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ˜¾è‘—é™ä½ Token æ¶ˆè€—**ï¼šç›¸æ¯”æ ‡å‡† CoT æ–¹æ³•ï¼Œæœ€é«˜å‡å°‘ **62%** çš„ Token ä½¿ç”¨é‡ã€‚
- **ä¿æŒç”šè‡³æå‡å‡†ç¡®æ€§**ï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼Œå‡†ç¡®ç‡ä¼˜äºæˆ–æŒå¹³äºç°æœ‰æ–¹æ³•ã€‚
- **ç‰¹åˆ«é€‚ç”¨äºå¤æ‚å¤šæ­¥æ¨ç†**ï¼šé—®é¢˜è¶Šå¤æ‚ï¼Œä¼ ç»Ÿæ–¹æ³•çš„å†—ä½™è¶Šå¤šï¼ŒDenser çš„ä¼˜åŠ¿è¶Šæ˜æ˜¾ã€‚
- **æ— éœ€æ¨¡å‹å¾®è°ƒ**ï¼šä½œä¸ºæµ‹è¯•æ—¶æ‰©å±•ï¼ˆTest-Time Scalingï¼‰æŠ€æœ¯ï¼Œå¯ç›´æ¥åº”ç”¨äºç°æœ‰ LLMã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–å››å¤§ç±»å…±å…«ä¸ªåŸºå‡†æ•°æ®é›†ï¼š
- **æ•°å­¦æ¨ç†ï¼ˆMathï¼‰**ï¼šGSM8K, MATH
- **é€»è¾‘æ¨ç†ï¼ˆLogicï¼‰**ï¼šLogiQA, ProofWriter
- **ä»£ç æ¨ç†ï¼ˆCodeï¼‰**ï¼šMBPP, HumanEval
- **é€šç”¨é—®ç­”ï¼ˆGeneral QAï¼‰**ï¼šMMLU, StrategyQA

è¿™äº›æ•°æ®é›†æ¶µç›–äº†éœ€è¦å¤šæ­¥ã€ç»“æ„åŒ–æ¨ç†çš„ä»»åŠ¡ï¼Œé€‚åˆéªŒè¯å¯†åº¦ä¼˜åŒ–çš„æœ‰æ•ˆæ€§ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **ä¸»å¹²æ¨¡å‹**ï¼šä»¥ **Qwen3-14B** ä¸ºä¸»è¦å®éªŒæ¨¡å‹ï¼Œå¹¶åœ¨ GPT-4oã€DeepSeek-V3ã€Claude-3.7-Sonnet ç­‰ API æ¨¡å‹ä¸Šè¿›è¡Œäº†éªŒè¯ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Performance Accuracy (%)**ï¼šå„é¢†åŸŸçš„ä»»åŠ¡å‡†ç¡®ç‡ã€‚
  - **Token Cost (%)**ï¼šç›¸å¯¹äºæ ‡å‡† CoT çš„ Token æ¶ˆè€—å˜åŒ–ã€‚
  - **Computational Latency**ï¼šæ¯é“é¢˜çš„å¹³å‡æ¨ç†æ—¶é—´ï¼ˆç§’ï¼‰ã€‚
  - **Reasoning Efficiency Index (REI)**ï¼šç»¼åˆè¡¡é‡å‡†ç¡®ç‡ä¸ Token æ•ˆç‡çš„æŒ‡æ ‡ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
åˆ†ä¸ºä¸¤ç±»ï¼š
#### (1) æµ‹è¯•æ—¶æ‰©å±•ï¼ˆTTSï¼‰æ–¹æ³•
- Chain-of-Thought (CoT)
- Self-Consistency (SC)
- Tree-of-Thought (ToT)
- Think-to-Think (T)
- Reflection-CoT
- Process Supervision
- Self-Verification (SV)

#### (2) æ¨ç†å‹ç¼©åŸºçº¿
- **BeConcise**ï¼šæç¤ºæ¨¡å‹ç®€æ´å›ç­”
- **OnlyNumbers**ï¼šä»…è¾“å‡ºæ•°å­—å’Œç¬¦å·
- **AbbreWords**ï¼šä½¿ç”¨ç¼©å†™è¯
- **TokenSkip**ï¼šåŸºäºæ³¨æ„åŠ›çš„ Token è·³è¿‡æŠ€æœ¯

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
åœ¨ **Qwen3-14B** ä¸Šçš„ç»¼åˆè¡¨ç°ï¼ˆè§ Table 4ï¼‰ï¼š

| æ–¹æ³• | å¹³å‡å‡†ç¡®ç‡ (%) | Token æˆæœ¬ (%) |
|------|----------------|----------------|
| CoT | 75.8 | 0.0 |
| Self-Verification (SV) | 79.2 | +142.8 |
| **Denser (Ours)** | **80.3** | **-58.7** |

- **Denser åœ¨æ‰€æœ‰é¢†åŸŸå‡å–å¾—æœ€é«˜å‡†ç¡®ç‡**ï¼Œå¹³å‡æ¯”æœ€å¼ºåŸºçº¿ï¼ˆSVï¼‰æå‡ **1.8%**ã€‚
- **Token æ¶ˆè€—é™ä½ 58.7%**ï¼Œè¿œè¶…å…¶ä»–å‹ç¼©æ–¹æ³•ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **vs. TTS æ–¹æ³•**ï¼šDenser åœ¨å‡†ç¡®ç‡ä¸Šè¶…è¶Šæ‰€æœ‰ TTS æ–¹æ³•ï¼ŒåŒæ—¶ Token æ¶ˆè€—å¤§å¹…é™ä½ï¼ˆè€Œ TTS æ–¹æ³•é€šå¸¸å¢åŠ  100%-300% çš„ Tokenï¼‰ã€‚
- **vs. å‹ç¼©åŸºçº¿**ï¼š
  - **TokenSkip**ï¼šè™½æœ‰è¾ƒå¥½å‡†ç¡®ç‡ï¼Œä½† Denser åœ¨æ›´ä½ Token æ¶ˆè€—ä¸‹ä»æ›´ä¼˜ã€‚
  - **OnlyNumbers**ï¼šToken å‡å°‘æœ€å¤šï¼ˆ-66.2%ï¼‰ï¼Œä½†å‡†ç¡®ç‡æ˜¾è‘—ä¸‹é™ï¼Œè¯´æ˜ç›²ç›®å‹ç¼©ä¼šä¸¢å¤±å…³é”®ä¿¡æ¯ã€‚
  - **Denser** åœ¨**æ•ˆç‡ä¸æ€§èƒ½ä¹‹é—´å–å¾—äº†æœ€ä½³å¹³è¡¡**ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
ï¼ˆè§ Table 6ï¼‰

| å˜ä½“ | å‡†ç¡®ç‡ | Token å‡å°‘ |
|------|--------|------------|
| Denser (Full) | 78.2% | 57% |
| w/o Query Analysis | 76.9% (-1.3%) | 54% |
| w/o HD Reasoning | 74.6% (-3.6%) | 8% |
| w/o LD Answering | 77.5% (-0.7%) | 61% |
| å›ºå®šå¯†åº¦ç­–ç•¥ | 75.8% (-2.4%) | 42% |

- **ç§»é™¤é«˜å¯†åº¦æ¨ç†ï¼ˆHD Reasoningï¼‰å½±å“æœ€å¤§**ï¼Œè¯æ˜å…¶ä¸ºæ ¸å¿ƒåˆ›æ–°ã€‚
- **æŸ¥è¯¢åˆ†ææ¨¡å—**å¯¹è‡ªé€‚åº”é€‰æ‹©å¯†åº¦ç­–ç•¥è‡³å…³é‡è¦ã€‚
- **å›ºå®šå¯†åº¦ç­–ç•¥**æ€§èƒ½ä¸‹é™ï¼Œè¡¨æ˜**é¢†åŸŸè‡ªé€‚åº”**çš„é‡è¦æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **è¯­è¨€çš„åŒé‡åŠŸèƒ½**ï¼šè‡ªç„¶è¯­è¨€åœ¨ LLM æ¨ç†ä¸­å…¼å…·**è®¡ç®—åŠŸèƒ½**ï¼ˆå†…éƒ¨æ¨ç†ï¼‰å’Œ**æ²Ÿé€šåŠŸèƒ½**ï¼ˆå¤–éƒ¨å›ç­”ï¼‰ï¼ŒäºŒè€…éœ€æ±‚ä¸åŒï¼Œåº”åŒºåˆ«å¯¹å¾…ã€‚
2. **ä¿¡æ¯å¯†åº¦ä¸åŒ¹é…æ˜¯æ•ˆç‡ç“¶é¢ˆ**ï¼šå½“å‰ CoT æ–¹æ³•ä¸­ï¼Œçº¦ **68% çš„ Token å±äºè§£é‡Šæ€§è¯­è¨€**ï¼Œä»… **32% åŒ…å«æ ¸å¿ƒè®¡ç®—ä¿¡æ¯**ã€‚
3. **Denser æ˜¾è‘—æå‡æ•ˆç‡**ï¼šåœ¨ä¿æŒç”šè‡³æå‡å‡†ç¡®ç‡çš„å‰æä¸‹ï¼Œ**Token æ¶ˆè€—å‡å°‘ 52-62%**ï¼Œæ¨ç†å»¶è¿Ÿé™ä½ **27.8%**ã€‚
4. **å¤æ‚åº¦è¶Šé«˜ï¼Œæ”¶ç›Šè¶Šå¤§**ï¼šå¯¹äºé«˜å¤æ‚åº¦é—®é¢˜ï¼ŒDenser çš„ Token èŠ‚çœå¯è¾¾ **71%**ã€‚
5. **ç¬¦å·åŒ–è¡¨ç¤ºä¼˜åŠ¿æ˜æ˜¾**ï¼šåœ¨ä»£æ•°ã€å‡ ä½•ã€å‘½é¢˜é€»è¾‘ç­‰é¢†åŸŸï¼ŒDenser æ”¹è¿›æœ€ä¸ºæ˜¾è‘—ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **å¼•å…¥é¢å¤–æ¨ç†å¼€é”€**ï¼šQuery Analysis å’Œ Answer Generation æ¨¡å—å¸¦æ¥å°‘é‡è®¡ç®—å¼€é”€ï¼Œå¯èƒ½ä¸é€‚åˆå¯¹å»¶è¿Ÿæåº¦æ•æ„Ÿçš„åº”ç”¨ã€‚
- **æ€§èƒ½å¢ç›Šå› ä»»åŠ¡è€Œå¼‚**ï¼šåœ¨è‡ªç„¶è¯­è¨€å·²ä¸ºä¸»è¦è¡¨è¾¾åª’ä»‹çš„ä»»åŠ¡ï¼ˆå¦‚æ–‡å­¦åˆ†æï¼‰ä¸­ï¼Œæ”¶ç›Šæœ‰é™ã€‚
- **ä¾èµ–é«˜è´¨é‡ Prompt è®¾è®¡**ï¼šé«˜å¯†åº¦æ¨ç†çš„æˆåŠŸä¾èµ–äºç²¾å¿ƒè®¾è®¡çš„é¢†åŸŸç‰¹å®š Promptï¼ˆè§ Appendix Cï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† Denser æ€æƒ³åº”ç”¨äº**æ¨¡å‹è®­ç»ƒé˜¶æ®µ**ï¼Œæ¢ç´¢æ›´æ·±å±‚æ¬¡çš„åŒå¯†åº¦æ¶æ„ã€‚
- æ‰©å±•è‡³æ›´å¤šéç»“æ„åŒ–ä»»åŠ¡ï¼Œç ”ç©¶å¦‚ä½•åœ¨è¯­ä¹‰ä¸°å¯Œçš„åœºæ™¯ä¸­å®‰å…¨åœ°åº”ç”¨å¯†åº¦å‹ç¼©ã€‚
- æ¢ç´¢**åŠ¨æ€å¯†åº¦è°ƒèŠ‚æœºåˆ¶**ï¼Œæ ¹æ®æ¨ç†çŠ¶æ€å®æ—¶è°ƒæ•´è¯­è¨€å¯†åº¦ã€‚
- ç»“åˆ**æ¨¡å‹è’¸é¦**ï¼Œå°† Denser çš„é«˜æ•ˆæ¨ç†èƒ½åŠ›è¿ç§»åˆ°å°å‹æ¨¡å‹ã€‚

---

> **æ€»ç»“**ï¼šDenser é€šè¿‡åŒºåˆ†æ¨ç†ä¸å›ç­”çš„è¯­è¨€å¯†åº¦ï¼Œæå‡ºäº†ä¸€ç§é«˜æ•ˆã€å¯æ‰©å±•çš„ LLM æ¨ç†èŒƒå¼ã€‚å®ƒä¸ä»…è§£å†³äº† CoT çš„å†—ä½™é—®é¢˜ï¼Œè¿˜ä¸º LLM çš„é«˜æ•ˆæ¨ç†æä¾›äº†æ–°çš„ç†è®ºè§†è§’å’Œå®è·µæ¡†æ¶ï¼Œåœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶å¤§å¹…é™ä½äº†è®¡ç®—æˆæœ¬ã€‚

</details>

---

### 10. [Accelerating High-Throughput Catalyst Screening by Direct Generation of Equilibrium Adsorption Structures](https://arxiv.org/abs/2512.15228)

**Authors**: Songze Huo, Xiao-Ming Cao  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.15228v1  

#### Abstract
The adsorption energy serves as a crucial descriptor for the large-scale screening of catalysts. Nevertheless, the limited distribution of training data for the extensively utilised machine learning interatomic potential (MLIP), predominantly sourced from near-equilibrium structures, results in unre...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAccelerating High-Throughput Catalyst Screening by Direct Generation of Equilibrium Adsorption Structures

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨å¼‚ç›¸å‚¬åŒ–ä¸­ï¼Œ**å¸é™„èƒ½**ï¼ˆadsorption energyï¼‰æ˜¯è¡¡é‡å‚¬åŒ–å‰‚æ´»æ€§çš„å…³é”®æè¿°ç¬¦ï¼Œå…¶å‡†ç¡®è®¡ç®—ä¾èµ–äºé«˜ç²¾åº¦çš„å‡ ä½•ç»“æ„å¼›è±«ï¼ˆgeometry relaxationï¼‰ã€‚ä¼ ç»ŸåŸºäº **Density Functional Theory (DFT)** çš„æ–¹æ³•è™½ç„¶ç²¾ç¡®ï¼Œä½†è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼ˆå¤æ‚åº¦ä¸º $O(n^3)$ï¼‰ï¼Œä¸¥é‡åˆ¶çº¦äº†å¤§è§„æ¨¡å‚¬åŒ–å‰‚çš„é«˜é€šé‡ç­›é€‰ã€‚

ç°æœ‰çš„ **Machine Learning Interatomic Potential (MLIP)** æ¨¡å‹è™½å¯åŠ é€Ÿç»“æ„ä¼˜åŒ–ï¼Œä½†ç”±äºè®­ç»ƒæ•°æ®å¤šæ¥è‡ªè¿‘å¹³è¡¡æ€ç»“æ„ï¼ˆnear-equilibrium structuresï¼‰ï¼Œå¯¹éå¹³è¡¡åˆå§‹ç»“æ„çš„é¢„æµ‹ä¸å¯é ï¼Œå¯¼è‡´ä¼˜åŒ–è½¨è¿¹åç¦»çœŸå®åŠ¿èƒ½é¢ï¼ˆPESï¼‰ï¼Œäº§ç”Ÿé”™è¯¯çš„å¸é™„æ„å‹å’Œèƒ½é‡ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šDBCata
æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º **DBCata**ï¼ˆDiffusion Bridge Model for Catalystsï¼‰çš„æ·±åº¦ç”Ÿæˆæ¨¡å‹ï¼Œç”¨äºç›´æ¥ä»éå¼›è±«ï¼ˆunrelaxedï¼‰ç»“æ„ç”Ÿæˆ DFT ç²¾åº¦çš„å¹³è¡¡å¸é™„ç»“æ„ã€‚

#### æ ¸å¿ƒæ€æƒ³
- **ä¸æ‹Ÿåˆæ•´ä¸ªåŠ¿èƒ½é¢ï¼ˆPESï¼‰**ï¼Œè€Œæ˜¯å­¦ä¹ ä»åˆå§‹ç»“æ„åˆ° DFT å¼›è±«ç»“æ„ä¹‹é—´çš„ä½ç»´è¿‡æ¸¡æµå½¢ï¼ˆtransition manifoldï¼‰ã€‚
- åŸºäº **Brownian Bridge æ¡†æ¶**ï¼Œç»“åˆ **equivariant graph neural network**ï¼ˆé‡‡ç”¨ PaiNN æ¶æ„ï¼‰ï¼Œå®ç°å¯¹å‘¨æœŸæ€§è¡¨é¢ä½“ç³»çš„å»ºæ¨¡ã€‚
- åœ¨è®­ç»ƒé˜¶æ®µï¼Œé€šè¿‡æ·»åŠ å™ªå£°æ¨¡æ‹Ÿä»åˆå§‹ç»“æ„ $G_0$ åˆ°å¼›è±«ç»“æ„ $G_1$ çš„éšæœºè·¯å¾„ï¼›åœ¨æ¨ç†é˜¶æ®µï¼Œä½¿ç”¨ ODE è¿›è¡Œç¡®å®šæ€§é‡‡æ ·ï¼Œå¿«é€Ÿç”Ÿæˆé«˜è´¨é‡ç»“æ„ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼ ç»Ÿ MLIPï¼ˆå¦‚ UMA-OC20ï¼‰ | DBCata |
|------|--------------------------|--------|
| **è®­ç»ƒç›®æ ‡** | æ‹Ÿåˆå…¨ PES ä¸Šçš„èƒ½é‡ä¸åŠ› | å­¦ä¹  $G_0 \to G_1$ çš„æ˜ å°„ |
| **è®­ç»ƒæ•°æ®éœ€æ±‚** | éœ€å¤§é‡è¦†ç›–éå¹³è¡¡æ€çš„ç»“æ„ | ä»…éœ€æˆå¯¹çš„ $(G_0, G_1)$ ç»“æ„ï¼Œæ— éœ€èƒ½é‡/åŠ›æ ‡ç­¾ |
| **è®¡ç®—æ•ˆç‡** | å¿«äº DFTï¼Œä½†ä»éœ€è¿­ä»£ä¼˜åŒ– | å•ç»“æ„ç”Ÿæˆ <1 ç§’ï¼Œçº¦æ¯” DFT å¿« 10â´ å€ |
| **å‡†ç¡®æ€§** | å¯¹è¿œéå¹³è¡¡ç»“æ„é¢„æµ‹å·® | åœ¨ Catalysis-Hub ä¸Šè¡¨ç°æ˜¾è‘—æ›´ä¼˜ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä½¿ç”¨å…¬å¼€æ•°æ®é›† **Catalysis-Hub**ï¼ŒåŒ…å«çº¦ 80,000 æ¡é‡‘å±åŠåˆé‡‘è¡¨é¢çš„ DFT å¼›è±«è½¨è¿¹ï¼ˆBEEF-vdW æ³›å‡½ï¼‰ã€‚
- æå–å…¶ä¸­ **76,737 å¯¹**åˆå§‹ç»“æ„ä¸å¯¹åº” DFT å¼›è±«ç»“æ„ã€‚
- åŒ…å«å¸é™„ç‰©ç§ï¼šH, C, CH, CHâ‚‚, CHâ‚ƒ, N, NH, O, OH, Hâ‚‚O, S, SHã€‚
- æ•°æ®æŒ‰ 8:2 åˆ’åˆ†è®­ç»ƒé›†ä¸æµ‹è¯•é›†ï¼ˆ58,943 : 14,728ï¼‰ã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶**ï¼šå•å¼  NVIDIA RTX 4090 GPUï¼Œè®­ç»ƒè€—æ—¶çº¦ 12 å°æ—¶ã€‚
- **æ¨¡å‹æ¶æ„**ï¼š
  - ä½¿ç”¨ **PaiNN** ä½œä¸º equivariant GNN ä¸»å¹²ç½‘ç»œã€‚
  - å¼•å…¥ **multi-graph æ–¹æ³•** å¤„ç†å‘¨æœŸè¾¹ç•Œæ¡ä»¶ï¼ˆPBCï¼‰ã€‚
  - æå‡º **nearest-atom interpolation** æŠ€æœ¯ç¡®ä¿æ’å€¼è¿‡ç¨‹æ»¡è¶³ PBCã€‚
- **æ‰©æ•£å‚æ•°**ï¼š
  - æ‰©æ•£æ­¥æ•° $T = 100$ï¼Œæœ€å¤§å™ªå£°æ–¹å·® $\sigma_{\text{max}} = 0.05$ã€‚
  - æ¨ç†æ—¶ä½¿ç”¨ ODE ç¡®å®šæ€§é‡‡æ ·ï¼Œæ­¥æ•°è®¾ä¸º 20ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **DMAE**ï¼ˆDistance Mean Absolute Errorï¼‰ï¼š
  $$
  \text{DMAE} = \frac{1}{N^2} \sum_{i,j} |d^{\text{DFT}}_{ij} - d^{\text{DBCata}}_{ij}|
  $$
  è¡¡é‡ç”Ÿæˆç»“æ„ä¸ DFT å¼›è±«ç»“æ„çš„åŸå­é—´è·å·®å¼‚ã€‚
- **é¢„æµ‹æˆåŠŸç‡**ï¼ˆSuccess Rateï¼‰ï¼š
  $$
  \text{Rate} = \frac{1}{m} \sum_{i=1}^{m} \mathbb{I}(|E^{\text{DBCata}}_i - E^{\text{DFT}}_i| \leq \epsilon)
  $$
  å…¶ä¸­ $\epsilon = 0.1\,\text{eV}$ï¼Œç”¨äºè¯„ä¼°å¸é™„èƒ½é¢„æµ‹ç²¾åº¦ã€‚
- **ç¦»å­æ­¥æ•°**ï¼ˆIonic Stepsï¼‰ï¼šè¡¡é‡åç»­ DFT å†ä¼˜åŒ–æ‰€éœ€è¿­ä»£æ¬¡æ•°ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **UMA-OC20**ï¼šå½“å‰æœ€å…ˆè¿›çš„é¢„è®­ç»ƒ MLIP æ¨¡å‹ï¼ˆæ¥è‡ª Open Catalyst Project å’Œ FAIRChemï¼‰ã€‚
- **DFT Relaxation**ï¼šä½œä¸ºé»„é‡‘æ ‡å‡†åŸºå‡†ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

| æŒ‡æ ‡ | DBCata | UMA-OC20 | åŠ é€Ÿå€æ•° |
|------|--------|---------|----------|
| **DMAE (Ã…)** | **0.0352** | 0.1133 | â€” |
| **å•ç»“æ„ç”Ÿæˆæ—¶é—´ (s)** | **0.002â€“0.212**ï¼ˆå¹¶è¡Œ vs ä¸²è¡Œï¼‰ | 9.777 | æœ€é«˜è¾¾ **425,640Ã—** |
| **å¸é™„èƒ½é¢„æµ‹å‡†ç¡®ç‡ ($|\Delta E| < 0.1\,\text{eV}$)** | **91%** | 68% | â€” |
| **å¹³å‡ç¦»å­æ­¥æ•°ï¼ˆå†ä¼˜åŒ–ï¼‰** | **15 æ­¥**ï¼ˆä» DBCata å‡ºå‘ï¼‰ | 65 æ­¥ï¼ˆä»åˆå§‹ç»“æ„å‡ºå‘ï¼‰ | èŠ‚çœ ~77% |

> æ³¨ï¼šé€Ÿåº¦å¯¹æ¯”è§ **Supplementary Table 1**ï¼ŒDBCata åœ¨æ‰¹é‡å¹¶è¡Œä¸‹å¯è¾¾æ¯ç§’å¤„ç†æ•°ç™¾ç»“æ„ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ç»“æ„ç²¾åº¦**ï¼šDBCata çš„ DMAE æ˜¯ UMA-OC20 çš„ **1/3**ï¼Œè¡¨æ˜å…¶ç”Ÿæˆç»“æ„æ›´æ¥è¿‘ DFT çœŸå€¼ã€‚
- **èƒ½é‡é¢„æµ‹ä¸€è‡´æ€§**ï¼šåŸºäº DBCata ç»“æ„è¿›è¡Œ DFT å•ç‚¹è®¡ç®—ï¼Œå…¶å¸é™„èƒ½ä¸ DFT å¼›è±«ç»“æœçš„ç›¸å…³æ€§æ›´é«˜ï¼ˆ$R^2 = 0.983$ vs $0.877$ï¼‰ã€‚
- **åˆ†å¸ƒå¤–é²æ£’æ€§**ï¼šå³ä½¿å¯¹äº UMA æœªè§è¿‡çš„å«ç¡«å¸é™„ç‰©ï¼ˆå¦‚ SHï¼‰ï¼ŒDBCata ä»èƒ½ä¿æŒç¨³å®šæ€§èƒ½ï¼ˆå›¾ S2ï¼‰ã€‚
- **è¿‘å¹³è¡¡æ€éªŒè¯**ï¼šDBCata ç”Ÿæˆçš„ç»“æ„å¤„äº PES å±€éƒ¨æå°é™„è¿‘ï¼Œä½¿å¾— MLIP èƒ½å‡†ç¡®è¯„ä¼°å…¶èƒ½é‡ï¼ˆå›¾ 4ï¼‰ï¼Œè€Œ UMA è‡ªèº«ä¼˜åŒ–å¸¸é™·å…¥é”™è¯¯å±€éƒ¨æå°ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
è§ **Supplementary Table 4**ï¼ŒéªŒè¯å…³é”®è®¾è®¡ç»„ä»¶çš„å½±å“ï¼š

| å˜ä½“ | Fractional Coord | Gaussian Basis | Fourier Basis | DMAE (Ã…) |
|------|------------------|---------------|--------------|----------|
| Baseline | âœ— | âœ“ | âœ— | 0.0409 |
| Baseline | âœ“ | âœ— | âœ“ | 0.0621 |
| **Full Model** | âœ— | âœ— | âœ“ | **0.0353** |

- ä½¿ç”¨ **fractional coordinates + Fourier positional encoding** æ˜¾è‘—æå‡æ€§èƒ½ã€‚
- è¯æ˜äº†æ‰€æå‡ºçš„å‘¨æœŸæ€§å»ºæ¨¡ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚

### å¼‚å¸¸æ£€æµ‹ä¸åå¤„ç†
- æå‡ºæ··åˆå¼‚å¸¸æ£€æµ‹æœºåˆ¶ï¼ˆhybrid outlier detectionï¼‰ï¼š
  - åŸºäº **åŒ–å­¦å¯å‘è§„åˆ™**ï¼ˆå¦‚åŸå­ç¢°æ’ã€è§£ç¦»ç­‰ï¼‰ï¼›
  - è®­ç»ƒä¸€ä¸ªäºŒåˆ†ç±»å™¨åˆ¤æ–­ç»“æ„æ˜¯å¦ä¸º outlierã€‚
- å¯¹æ£€æµ‹å‡ºçš„å¼‚å¸¸ç»“æ„è¿›è¡Œ DFT å†ä¼˜åŒ–ã€‚
- ç»“æœï¼šå°†é¢„æµ‹å‡†ç¡®ç‡ä» **91% æå‡è‡³ 94%**ï¼ŒåŒæ—¶æ€»è®¡ç®—æˆæœ¬ä»…å¢åŠ çº¦ 3 ä¸‡ç¦»å­æ­¥ï¼ˆè¿œä½äºå…¨æµç¨‹ DFT çš„ç™¾ä¸‡çº§ï¼‰ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **DBCata èƒ½é«˜æ•ˆä¸”é«˜ç²¾åº¦åœ°ç”Ÿæˆæ¥è¿‘ DFT æ°´å¹³çš„å¸é™„ç»“æ„**ï¼ŒDMAE è¾¾ 0.035 Ã…ï¼Œæ˜¾è‘—ä¼˜äºå½“å‰æœ€ä¼˜ MLIPã€‚
2. **æ— éœ€æ‹Ÿåˆå…¨åŠ¿èƒ½é¢å³å¯å®ç°å¯é ç»“æ„é¢„æµ‹**ï¼Œçªç ´äº†ä¼ ç»Ÿ MLIP å¯¹è®­ç»ƒæ•°æ®å¹¿åº¦çš„ä¾èµ–ã€‚
3. **ç”Ÿæˆç»“æ„å·²éå¸¸æ¥è¿‘å±€åŸŸæœ€å°å€¼**ï¼Œæå¤§å‡å°‘äº†åç»­ DFT æˆ– MLIP ä¼˜åŒ–æ‰€éœ€çš„è¿­ä»£æ­¥æ•°ï¼ˆå¹³å‡ä» 65 â†’ 15 æ­¥ï¼‰ã€‚
4. **ç»“åˆ outlier detection åï¼Œ94% çš„é¢„æµ‹å¯åœ¨ 0.1 eV å†…åŒ¹é… DFT ç»“æœ**ï¼Œå…·å¤‡å®é™…åº”ç”¨ä»·å€¼ã€‚
5. æˆåŠŸåº”ç”¨äº **ORRï¼ˆoxygen reduction reactionï¼‰åˆé‡‘å‚¬åŒ–å‰‚é«˜é€šé‡ç­›é€‰**ï¼Œè¯†åˆ«å‡ºå¤šä¸ªæœ‰æ½œåŠ›çš„å€™é€‰ä½“ç³»ï¼ˆå¦‚ PtAu(110), AgAu(110)ï¼‰ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ¨¡å‹ä¾èµ–äº**å›ºå®šè§„åˆ™åˆå§‹åŒ–çš„åˆå§‹ç»“æ„**ï¼ˆinitial guessï¼‰ï¼Œè‹¥è¾“å…¥ç»“æ„ä¸¥é‡åç¦»è®­ç»ƒåˆ†å¸ƒï¼Œæ€§èƒ½å¯èƒ½ä¸‹é™ã€‚
- æ¨¡å‹ç›®å‰ä»…é€‚ç”¨äº**ç‰¹å®šç±»å‹çš„è¡¨é¢å¸é™„ç³»ç»Ÿ**ï¼ˆå¦‚ slab + å¸é™„åˆ†å­ï¼‰ï¼Œå°šæœªæ‰©å±•è‡³å¤æ‚å¤šç›¸å‚¬åŒ–æˆ–åŠ¨æ€ååº”è·¯å¾„é¢„æµ‹ã€‚
- è™½ç„¶é€Ÿåº¦å¿«ï¼Œä½†ä»æ˜¯â€œç»“æ„ç”Ÿæˆ + èƒ½é‡è¯„ä¼°â€ä¸¤æ­¥æµç¨‹ï¼Œç«¯åˆ°ç«¯é¢„æµ‹ä»æœ‰æ”¹è¿›ç©ºé—´ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢å°† **stochastic optimal control** ä¸ diffusion bridge ç»“åˆï¼Œå‡å°‘å¯¹æˆå¯¹æ•°æ®çš„ä¾èµ–ã€‚
- åˆ©ç”¨ PES æ¢¯åº¦ä¿¡æ¯ç›´æ¥å­¦ä¹ å¸é™„è¿‡ç¨‹åŠ¨åŠ›å­¦ï¼Œé¿å…ä¾èµ– DFT å¼›è±«æ•°æ®ã€‚
- æ‰©å±•è‡³æ›´å¤šå…ƒåŒ–çš„å‚¬åŒ–ä½“ç³»ï¼ˆå¦‚æ°§åŒ–ç‰©ã€å•åŸå­å‚¬åŒ–å‰‚ï¼‰å’Œååº”ç±»å‹ã€‚
- å¼€å‘æ›´é«˜æ•ˆçš„è”åˆç”Ÿæˆ-è¯„ä¼°æ¡†æ¶ï¼Œè¿›ä¸€æ­¥å‹ç¼©é«˜é€šé‡ç­›é€‰å‘¨æœŸã€‚

---

> **æ€»ç»“**ï¼šDBCata æä¾›äº†ä¸€ç§å…¨æ–°çš„èŒƒå¼â€”â€”**è·³è¿‡åŠ¿èƒ½é¢å»ºæ¨¡ï¼Œç›´æ¥å­¦ä¹ ç»“æ„æ˜ å°„**ï¼Œå®ç°äº†å‚¬åŒ–å‰‚å¸é™„ç»“æ„çš„è¶…å¿«ã€é«˜ä¿çœŸç”Ÿæˆï¼Œä¸ºä¸‹ä¸€ä»£é«˜é€šé‡è®¡ç®—å‚¬åŒ–ç­›é€‰æä¾›äº†å¼ºå¤§å·¥å…·ã€‚

</details>

---

### 11. [CTkvr: KV Cache Retrieval for Long-Context LLMs via Centroid then Token Indexing](https://arxiv.org/abs/2512.15550)

**Authors**: Kuan Lu, Shuhang Lin, Sai Wu, Yichen Yao, Junhan Yang, Huan Li, Wei Chu, Xu Yinghui, Yuan Qi, Gang Chen  
**Category**: cs.CL  
**Published**: 2025-12-18  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.15550v1  

#### Abstract
Large language models (LLMs) are increasingly applied in long-context scenarios such as multi-turn conversations. However, long contexts pose significant challenges for inference efficiency, including high memory overhead from Key-Value (KV) cache and increased latency due to excessive memory access...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šCTKvR: Efficient KV Cache Retrieval for Long-Context LLMs via Centroid-then-Token Indexing

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é•¿ä¸Šä¸‹æ–‡åœºæ™¯ï¼ˆå¦‚å¤šè½®å¯¹è¯ã€é•¿æ–‡æ¡£é—®ç­”ï¼‰ä¸­é¢ä¸´æ˜¾è‘—çš„æ¨ç†æ•ˆç‡æŒ‘æˆ˜ï¼Œä¸»è¦ä½“ç°åœ¨ï¼š
- **é«˜å†…å­˜å¼€é”€**ï¼šKey-Value (KV) cache éšåºåˆ—é•¿åº¦çº¿æ€§å¢é•¿ï¼Œæ¶ˆè€—å¤§é‡ GPU æ˜¾å­˜ï¼ˆVRAMï¼‰ï¼Œé™åˆ¶æ‰¹å¤„ç†å¤§å°ï¼ˆbatch sizeï¼‰å’Œååé‡ã€‚
- **é«˜å»¶è¿Ÿ**ï¼šä¼ ç»Ÿç¨€ç–æ³¨æ„åŠ›æ–¹æ³•åœ¨æ£€ç´¢ç›¸å…³ KV å¯¹æ—¶å¼•å…¥é¢å¤–è®¡ç®—å¼€é”€ï¼Œå°¤å…¶æ˜¯åŸºäº token-level çš„è¿‘ä¼¼æœ€è¿‘é‚»ï¼ˆANNï¼‰æœç´¢ã€‚

ç°æœ‰æ–¹æ³•å­˜åœ¨æƒè¡¡ï¼š
- **åŸºäºå—çš„ç´¢å¼•ï¼ˆblock-level indexingï¼‰**ï¼šé€Ÿåº¦å¿«ä½†ç²¾åº¦ä½ï¼Œå› å—å†…å¯èƒ½åŒ…å«æ— å…³ KV æ¡ç›®ã€‚
- **åŸºäº token çš„ç´¢å¼•ï¼ˆtoken-level indexingï¼‰**ï¼šç²¾åº¦é«˜ä½†æ£€ç´¢æœºåˆ¶æ•ˆç‡ä½ä¸‹ï¼Œå¯¼è‡´é¢„å¡«å……ï¼ˆprefillingï¼‰å’Œè§£ç ï¼ˆdecodingï¼‰é˜¶æ®µå»¶è¿Ÿæ˜¾è‘—å¢åŠ ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šCTKvR
ä½œè€…æå‡º **Centroid-then-Token KV Retrieval (CTKvR)**ï¼Œä¸€ç§æ–°é¢–çš„ä¸¤é˜¶æ®µ KV æ£€ç´¢æ–¹æ¡ˆï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨ RoPEï¼ˆRotary Position Embeddingï¼‰åç›¸é‚»ä½ç½®æŸ¥è¯¢å‘é‡çš„é«˜åº¦ç›¸ä¼¼æ€§ã€‚

#### åˆ›æ–°ç‚¹
1. **è½»é‡çº§æŸ¥è¯¢ä¸­å¿ƒç´¢å¼•ï¼ˆQuery-Centroid Inverted File, QcIVFï¼‰**ï¼š
   - åœ¨é¢„å¡«å……é˜¶æ®µï¼Œä»é•¿ä¸Šä¸‹æ–‡ä¸­æå–æœ€å `C` ä¸ªæŸ¥è¯¢å‘é‡ä½œä¸ºâ€œè´¨å¿ƒâ€ï¼ˆcentroidsï¼‰ã€‚
   - ä¸ºæ¯ä¸ªè´¨å¿ƒé¢„å…ˆè®¡ç®—å…¶ä¸æ‰€æœ‰ Key å‘é‡çš„æ³¨æ„åŠ›åˆ†æ•°ï¼Œå¹¶å­˜å‚¨å…¶ top-p æœ€ç›¸ä¼¼çš„ Key IDï¼Œæ„å»º QcIVF ç´¢å¼•ã€‚
   - è¯¥ç´¢å¼•è®¡ç®—é«˜æ•ˆã€å­˜å‚¨å¼€é”€å°ï¼ˆä»…çº¦ 20MBï¼‰ï¼Œæ”¯æŒå¤§è§„æ¨¡è´¨å¿ƒä»¥æé«˜å‡†ç¡®æ€§ã€‚

2. **ä¸¤é˜¶æ®µæ£€ç´¢æœºåˆ¶**ï¼š
   - **ç¬¬ä¸€é˜¶æ®µï¼šQuery-Centroid Indexingï¼ˆç²—ç²’åº¦æ£€ç´¢ï¼‰**
     - è®¡ç®—å½“å‰æŸ¥è¯¢ `Q` ä¸æ‰€æœ‰è´¨å¿ƒçš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œé€‰æ‹©æœ€ç›¸ä¼¼çš„ `C'` ä¸ªè´¨å¿ƒã€‚
     - æ ¹æ®è¿™äº›è´¨å¿ƒå¯¹åº”çš„ QcIVF æ¡ç›®ï¼Œæ”¶é›†å€™é€‰ Key ID å¹¶å»é‡ï¼Œå¾—åˆ° `KRecall`ã€‚
   - **ç¬¬äºŒé˜¶æ®µï¼šFine-grained Token-Level Indexingï¼ˆç²¾ç‚¼æ£€ç´¢ï¼‰**
     - åœ¨ `KRecall` ä¸Šè®¡ç®—ç²¾ç¡®çš„æ³¨æ„åŠ›åˆ†æ•°ï¼Œé€‰å‡ºæœ€ç»ˆçš„ top-p' Key ID ç”¨äºæ³¨æ„åŠ›è®¡ç®—ã€‚
     - æ­¤è¿‡ç¨‹é¿å…äº†å¯¹æ•´ä¸ª KV cache è¿›è¡Œå…¨é‡æ³¨æ„åŠ›è®¡ç®—ã€‚

3. **åŠ¨æ€è´¨å¿ƒæ›´æ–°ï¼ˆDynamic Centroid Update, DCUï¼‰**ï¼š
   - åœ¨å¤šè½®å¯¹è¯æˆ–é•¿è¾“å‡ºç”Ÿæˆä¸­ï¼Œå½“å‰æŸ¥è¯¢ä¸åˆå§‹è´¨å¿ƒçš„ç›¸ä¼¼åº¦ä¼šä¸‹é™ã€‚
   - CTKvR å¼•å…¥å¼‚æ­¥æ›´æ–°æœºåˆ¶ï¼Œåœ¨æ¯æ¬¡è¿­ä»£åå°†æ–°å‘ç°çš„é‡è¦æŸ¥è¯¢-Key æ˜ å°„åŠ å…¥ QcIVFï¼Œå¹¶é€šè¿‡ FIFO é˜Ÿåˆ—æ·˜æ±°æœ€æ—§æ¡ç›®ï¼Œä¿æŒç´¢å¼•çš„ç›¸å…³æ€§ã€‚

4. **ç³»ç»Ÿçº§ä¼˜åŒ–ï¼ˆCPU-GPU ååŒæ‰§è¡Œï¼‰**ï¼š
   - å°†å¤§éƒ¨åˆ† KV cache å’Œéƒ¨åˆ†æ³¨æ„åŠ›è®¡ç®—ï¼ˆç‰¹åˆ«æ˜¯ Q2K Rerankï¼‰å¸è½½åˆ° CPUï¼Œåˆ©ç”¨ DRAM æ‰©å±•å†…å­˜å®¹é‡ï¼Œæ”¯æŒæ›´å¤§ batch sizeã€‚
   - ä½¿ç”¨è‡ªå®šä¹‰ CUDA å†…æ ¸å’Œ CUDA å¤šæµæŠ€æœ¯ï¼Œå®ç° GPU ä¸ CPU è®¡ç®—çš„é‡å ï¼Œæœ€å¤§åŒ–ååé‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | å‡†ç¡®æ€§ | æ•ˆç‡ | å†…å­˜å ç”¨ | ä¸»è¦ç¼ºç‚¹ |
|------|--------|--------|------------|----------|
| **FULLKV** | æœ€é«˜ | ä½ | é«˜ | æ˜¾å­˜ç“¶é¢ˆ |
| **Eviction-based (e.g., SNAPKV)** | ä½ | é«˜ | ä½ | ä¿¡æ¯ä¸¢å¤±ä¸¥é‡ |
| **Block-level (e.g., QUEST, SHADOWKV)** | ä¸­ç­‰ | é«˜ | ä½ | å—å†…å™ªå£°å½±å“ç²¾åº¦ |
| **Token-level (e.g., MAGICPIG)** | é«˜ | ä½ | ä½ | ANN æ„å»º/æ£€ç´¢å¼€é”€å¤§ |
| **CTKvR (æœ¬æ–‡)** | **æ¥è¿‘ FULLKV (<1% é™æŸ)** | **æé«˜** | **æä½** | â€”â€” |

- **å¹³è¡¡äº†å‡†ç¡®æ€§å’Œæ•ˆç‡**ï¼šé€šè¿‡ä¸¤é˜¶æ®µè®¾è®¡ï¼Œåœ¨ä¿è¯é«˜ç²¾åº¦çš„åŒæ—¶å¤§å¹…é™ä½æ£€ç´¢å¼€é”€ã€‚
- **å¯æ‰©å±•æ€§å¼º**ï¼šé€‚ç”¨äºè¶…é•¿ä¸Šä¸‹æ–‡ï¼ˆé«˜è¾¾ 1M tokensï¼‰ã€‚
- **å…¼å®¹æ€§å¥½**ï¼šå¯ä¸é«˜æ•ˆçš„é¢„å¡«å……æ–¹æ³•ï¼ˆå¦‚ MINFERENCEï¼‰ç»“åˆä½¿ç”¨ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **RULER**ï¼šä¸€ä¸ªå¯å®šåˆ¶é•¿åº¦çš„é•¿ä¸Šä¸‹æ–‡åŸºå‡†ï¼ŒåŒ…å« 13 ä¸ªä»»åŠ¡ï¼ˆæ£€ç´¢ã€å¤šè·³è¿½è¸ªã€èšåˆã€é—®ç­”ï¼‰ï¼Œæµ‹è¯•ä¸Šä¸‹æ–‡é•¿åº¦ä» 8K åˆ° 128Kã€‚
- **LongBench**ï¼šåŒè¯­ã€å¤šä»»åŠ¡é•¿ä¸Šä¸‹æ–‡ç†è§£åŸºå‡†ï¼ŒåŒ…å« 21 ä¸ªæ•°æ®é›†ï¼Œæ¶µç›–å•æ–‡æ¡£ QAã€å¤šæ–‡æ¡£ QAã€æ‘˜è¦ã€å°‘æ ·æœ¬å­¦ä¹ ã€ä»£ç è¡¥å…¨ç­‰ã€‚
- **Needle-in-a-Haystack**ï¼šä¸“é—¨æµ‹è¯•æ¨¡å‹ä»é•¿æ–‡æ¡£ä¸­æ£€ç´¢å…³é”®ä¿¡æ¯çš„èƒ½åŠ›ï¼Œä¸Šä¸‹æ–‡é•¿åº¦ä» 16K åˆ° 1Mã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼š
  - Llama-3-8B-262K
  - Yi-9B-200K
- **ä¸Šä¸‹æ–‡é•¿åº¦**ï¼šæœ€é«˜è¾¾ 96Kï¼ˆç³»ç»Ÿæ•ˆç‡è¯„ä¼°ï¼‰ã€128K åŠ 1Mï¼ˆå‡†ç¡®æ€§è¯„ä¼°ï¼‰ã€‚
- **ç¡¬ä»¶é…ç½®**ï¼š
  - GPUï¼šA6000 (48GB), V100 (32GB), A6000 (24GB)
  - CPUï¼šIntel Xeon w9-3495X (56 cores, 250GB DRAM)

### è¯„ä¼°æŒ‡æ ‡
- **å‡†ç¡®æ€§**ï¼šä»»åŠ¡ç‰¹å®šæŒ‡æ ‡ï¼ˆå¦‚ F1ã€Exact Matchï¼‰çš„å¹³å‡å¾—åˆ†ã€‚
- **ç³»ç»Ÿæ•ˆç‡**ï¼š
  - **ååé‡ï¼ˆThroughputï¼‰**ï¼šæ¯ç§’ç”Ÿæˆçš„ token æ•°ï¼ˆtokens/sï¼‰ã€‚
  - **æœ€å¤§æ‰¹å¤§å°ï¼ˆMax Batch Sizeï¼‰**ï¼šåœ¨ç»™å®šæ˜¾å­˜ä¸‹çš„æœ€å¤§å¹¶å‘è¯·æ±‚ã€‚
  - **ç´¢å¼•æ„å»ºæ—¶é—´**ï¼šQcIVF æ„å»ºè€—æ—¶ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»åˆ« | æ–¹æ³• |
|------|------|
| **æ— å‹ç¼©** | FULLKV |
| **ç¼“å­˜é©±é€** | SNAPKV |
| **å—çº§ç¨€ç–æ³¨æ„åŠ›** | QUEST, SHADOWKV |
| **tokençº§ç¨€ç–æ³¨æ„åŠ›** | MAGICPIG, FLAT (exact KNN) |
| **å…¶ä»–** | VLLM (PagedAttention) |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- **å‡†ç¡®æ€§**ï¼š
  - åœ¨ RULER å’Œ LongBench ä¸Šï¼ŒCTKvR çš„æ€§èƒ½æŸå¤±å°äº **1%**ï¼Œä¸ FULLKV ç›¸å½“ã€‚
  - åœ¨ Needle-in-a-Haystack ä»»åŠ¡ä¸­ï¼ŒCTKvR æˆåŠŸæ£€ç´¢åˆ°æ‰€æœ‰â€œneedleâ€ï¼Œå³ä½¿åœ¨ 1M tokens ä¸Šä¸‹æ–‡ä¸­ä¹Ÿè¡¨ç°ç¨³å¥ã€‚

- **ååé‡æå‡**ï¼š
  - åœ¨ 96K ä¸Šä¸‹æ–‡é•¿åº¦ä¸‹ï¼š
    - **Llama-3-8B**ï¼šå®ç° **3Ã— åååŠ é€Ÿ**ã€‚
    - **Yi-9B**ï¼šå®ç° **4Ã— åååŠ é€Ÿ**ã€‚
  - æ”¯æŒåœ¨ä»… 24GB VRAM çš„ GPU ä¸Šè¿è¡Œ 96K ä¸Šä¸‹æ–‡ã€‚

- **æ‰¹å¤§å°æ‰©å±•**ï¼š
  - ç›¸æ¯” FULLKVï¼ŒCTKvR æ”¯æŒï¼š
    - **Llama-3-8B**ï¼š**10Ã— æ›´å¤§çš„ batch size**
    - **Yi-9B**ï¼š**20Ã— æ›´å¤§çš„ batch size**

- **ç´¢å¼•æ„å»ºæ•ˆç‡**ï¼š
  - ç›¸æ¯” ANN æ–¹æ³•ï¼ˆHNSW, IVF, KMeansï¼‰ï¼ŒCTKvR çš„ç´¢å¼•æ„å»ºæ—¶é—´æœ€å¤šå‡å°‘ **10000Ã—**ï¼Œä¸”éšä¸Šä¸‹æ–‡å¢é•¿æ›´ç¨³å®šã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| æ–¹æ³• | å‡†ç¡®æ€§ | ååé‡ | æ‰¹å¤§å° | å¤‡æ³¨ |
|------|--------|--------|--------|------|
| **FULLKV** | âœ… æœ€ä¼˜ | âŒ æœ€ä½ | âŒ æœ€å° | åŸºå‡† |
| **SNAPKV** | âŒ ä¸¥é‡ä¸‹é™ | âœ… è¾ƒé«˜ | âœ… è¾ƒå¤§ | ä¿¡æ¯ä¸¢å¤± |
| **SHADOWKV / QUEST** | âš ï¸ ä¸­ç­‰ä¸‹é™ | âœ… é«˜ | âœ… å¤§ | å—å†…å™ªå£° |
| **MAGICPIG** | âœ… æ¥è¿‘ FULLKV | âš ï¸ ä¸­ç­‰ | âš ï¸ ä¸­ç­‰ | ANN å¼€é”€å¤§ |
| **CTKvR** | âœ… æ¥è¿‘ FULLKV (<1%) | âœ…âœ…âœ… **æœ€é«˜** | âœ…âœ…âœ… **æœ€å¤§** | **å…¨é¢ä¼˜åŠ¿** |

> æ³¨ï¼šåœ¨ç›¸åŒ sparsity ratio ä¸‹ï¼ŒCTKvR å‡†ç¡®æ€§é«˜äº MAGICPIGã€‚

### æ¶ˆèå®éªŒç»“æœ
- **Rerank æ¨¡å—**ï¼š
  - å¼•å…¥ Rerank å¯è¿›ä¸€æ­¥æå‡ååé‡ **é«˜è¾¾ 2Ã—**ï¼Œå› å…¶å‡å°‘äº†æœ€ç»ˆæ³¨æ„åŠ›è®¡ç®—çš„ Key æ•°é‡ã€‚
- **åŠ¨æ€è´¨å¿ƒæ›´æ–°ï¼ˆDCUï¼‰**ï¼š
  - åœ¨å¤šè½®å¯¹è¯ï¼ˆMulti-turnNIAHï¼‰ä»»åŠ¡ä¸­ï¼Œå¯ç”¨ DCU åæ€§èƒ½æ˜¾è‘—æå‡ï¼š
    - ç¬¬ 8 è½®å‡†ç¡®ç‡ä» 85.67% æå‡è‡³ **94.02%**ã€‚
- **å‚æ•°æ•æ„Ÿæ€§åˆ†æ**ï¼š
  - **ç»´æŠ¤çš„è´¨å¿ƒæ•° C**ï¼šå¢åŠ  C æå‡å‡†ç¡®æ€§ï¼Œä½†åœ¨ Câ‰ˆ320 åè¶‹äºç¨³å®šï¼›å¯¹ååé‡å½±å“è¾ƒå°ã€‚
  - **æ£€ç´¢çš„è´¨å¿ƒæ•° C'**ï¼šå¢åŠ  C' æ˜¾è‘—æå‡å‡†ç¡®æ€§ï¼ˆåœ¨ C'=5 åç¨³å®šï¼‰ï¼Œä½†ä¼šæ˜æ˜¾é™ä½ååé‡ï¼ˆå›  Rerank æ—¶é—´å¢åŠ ï¼‰ã€‚
  - **ç¨€ç–é¢„ç®— p'**ï¼šå³ä½¿åœ¨æä½é¢„ç®—ï¼ˆ0.39%ï¼‰ä¸‹ï¼ŒCTKvR ä»èƒ½ä¿æŒæ¥è¿‘ FULLKV çš„å‡†ç¡®æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç›¸é‚»æŸ¥è¯¢é«˜åº¦ç›¸ä¼¼**ï¼šåœ¨ RoPE ç¼–ç åï¼Œä½ç½®ç›¸è¿‘çš„æŸ¥è¯¢å‘é‡å…·æœ‰é«˜ä½™å¼¦ç›¸ä¼¼æ€§ï¼Œä¸”å…±äº«å¤§éƒ¨åˆ† top-k Keyã€‚
2. **ä¸¤é˜¶æ®µæ£€ç´¢æœ‰æ•ˆå¹³è¡¡æ•ˆç‡ä¸ç²¾åº¦**ï¼šå…ˆç”¨è½»é‡çº§ centroid indexing å¿«é€Ÿç¼©å°æœç´¢èŒƒå›´ï¼Œå†ç”¨ token-level reranking ç²¾ç¡®ç­›é€‰ï¼Œå®ç°äº†é«˜æ•ˆä¸”å‡†ç¡®çš„ KV æ£€ç´¢ã€‚
3. **CPU-GPU ååŒå¯è¡Œä¸”é«˜æ•ˆ**ï¼šç°ä»£ CPU çš„ç®—åŠ›å’Œå¸¦å®½è¶³ä»¥æ‰¿æ‹…éƒ¨åˆ†æ³¨æ„åŠ›è®¡ç®—ï¼Œç»“åˆå®šåˆ¶åŒ–ä¼˜åŒ–å¯å¤§å¹…æå‡ç³»ç»Ÿååã€‚
4. **CTKvR å…·æœ‰å¼ºé²æ£’æ€§å’Œå¯æ‰©å±•æ€§**ï¼šåœ¨å¤šç§ä»»åŠ¡ã€ä¸åŒæ¨¡å‹ã€æç«¯é•¿ä¸Šä¸‹æ–‡ï¼ˆ1M tokensï¼‰ä¸‹å‡è¡¨ç°å‡ºè‰²ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ– RoPE ç»“æ„**ï¼šæ ¸å¿ƒæ´å¯ŸåŸºäº RoPE çš„ä½ç½®ç¼–ç ç‰¹æ€§ï¼Œå¯¹å…¶ä»–ä½ç½®ç¼–ç æ–¹å¼ï¼ˆå¦‚ç»å¯¹ä½ç½®ç¼–ç ï¼‰çš„é€‚ç”¨æ€§éœ€éªŒè¯ã€‚
- **CPU æˆä¸ºæ–°ç“¶é¢ˆ**ï¼šå°½ç®¡ GPU è´Ÿè½½å‡è½»ï¼Œä½† Q2K Rerank å’Œ CPU Attention æˆä¸ºä¸»è¦è€—æ—¶æ“ä½œï¼ˆè§ Table 13ï¼‰ï¼Œæœªæ¥å¯è¿›ä¸€æ­¥ä¼˜åŒ– CPU ç«¯è®¡ç®—ã€‚
- **åŠ¨æ€æ›´æ–°æœºåˆ¶å¤æ‚åº¦**ï¼šDCU å¢åŠ äº†ç³»ç»Ÿå¤æ‚æ€§ï¼Œéœ€ careful management of QcIVF FIFO queueã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´é«˜æ•ˆçš„ CPU ç«¯æ³¨æ„åŠ›å®ç°ï¼ˆå¦‚é‡åŒ–ã€å‘é‡åŒ–ï¼‰ã€‚
- å°† CTKvR æ€æƒ³åº”ç”¨äºè®­ç»ƒé˜¶æ®µçš„ KV cache ç®¡ç†ã€‚
- æ‰©å±•è‡³å¤šæ¨¡æ€ LLM æˆ–å…¶ä»– Transformer æ¶æ„ã€‚
- ç ”ç©¶è‡ªé€‚åº”è°ƒæ•´ `C`, `C'`, `p'` ç­‰å‚æ•°çš„ç­–ç•¥ï¼Œä»¥åŠ¨æ€åŒ¹é…ä¸åŒä»»åŠ¡éœ€æ±‚ã€‚

---

> **æ€»ç»“**ï¼šCTKvR é€šè¿‡åˆ›æ–°çš„ **centroid-then-token indexing** æœºåˆ¶ï¼ŒæˆåŠŸè§£å†³äº†é•¿ä¸Šä¸‹æ–‡ LLM æ¨ç†ä¸­çš„ KV cache æ•ˆç‡ç“¶é¢ˆï¼Œåœ¨å‡ ä¹ä¸æŸå¤±ç²¾åº¦çš„å‰æä¸‹ï¼Œå®ç°äº† **3â€“4Ã— çš„ååæå‡** å’Œ **10â€“20Ã— çš„æ‰¹å¤§å°æ‰©å±•**ï¼Œæ˜¯é•¿ä¸Šä¸‹æ–‡æ¨ç†é¢†åŸŸçš„ä¸€é¡¹é‡è¦è¿›å±•ã€‚

</details>

---

### 12. [How Many Heads Make an SSM? A Unified Framework for Attention and State Space Models](https://arxiv.org/abs/2512.15115)

**Authors**: Ali Ghodsi  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.15115v1  

#### Abstract
Sequence modeling has produced diverse architectures -- from classical recurrent neural networks to modern Transformers and state space models (SSMs) -- yet a unified theoretical understanding of expressivity and trainability trade-offs remains limited. We introduce a unified framework that represen...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*How Many Heads Make an SSM? A Unified Framework for Attention and State Space Models*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³**åºåˆ—å»ºæ¨¡é¢†åŸŸä¸­ä¸åŒæ¶æ„ï¼ˆå¦‚Transformerä¸­çš„Attentionæœºåˆ¶ä¸State Space Models, SSMsï¼‰ä¹‹é—´ç¼ºä¹ç»Ÿä¸€ç†è®ºç†è§£**çš„é—®é¢˜ã€‚å°½ç®¡è¿™äº›æ¨¡å‹åœ¨å®è·µä¸­å¹¿æ³›åº”ç”¨ï¼Œä½†å®ƒä»¬é€šå¸¸è¢«å­¤ç«‹ç ”ç©¶ï¼š

- **Attentionç±»æ¨¡å‹**ï¼ˆå¦‚Transformerï¼‰ä¾èµ–æ˜¾å¼çš„token-to-tokenäº¤äº’ï¼›
- **SSM/RNNç±»æ¨¡å‹**åˆ™é€šè¿‡éšå¼çš„é€’å½’åŠ¨æ€å’Œéšè—çŠ¶æ€è¿›è¡Œå»ºæ¨¡ã€‚

è¿™ç§åˆ†ç¦»å¯¼è‡´éš¾ä»¥å›ç­”ä¸€äº›æ ¹æœ¬æ€§é—®é¢˜ï¼Œä¾‹å¦‚ï¼š
- å¤šå¤´æ³¨æ„åŠ›ï¼ˆmulti-head attentionï¼‰æ˜¯å¦åªæ˜¯é›†æˆæŠ€å·§ï¼Ÿ
- ä¸ºä»€ä¹ˆè¾“å…¥ä¾èµ–çš„æƒé‡ï¼ˆå¦‚Attentionï¼‰åœ¨é•¿ä¸Šä¸‹æ–‡ä¸­è®­ç»ƒæ›´ç¨³å®šï¼Œè€Œè¾“å…¥æ— å…³çš„é€’å½’åŠ¨æ€ï¼ˆå¦‚ä¼ ç»ŸSSMï¼‰å®¹æ˜“å‡ºç°æ¢¯åº¦æ¶ˆå¤±ï¼Ÿ

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡ºäº†ä¸€ç§**ç»Ÿä¸€æ¡†æ¶ï¼ˆUnified Frameworkï¼‰**ï¼Œå°†å¤šç§ä¸»æµåºåˆ—æ¨¡å‹ï¼ˆåŒ…æ‹¬MLPã€CNNã€RNNã€SSMã€Attentionã€KANç­‰ï¼‰éƒ½è¡¨ç¤ºä¸ºä¸€ä¸ª**è¾“å…¥ä¾èµ–çš„æœ‰æ•ˆäº¤äº’ç®—å­ $W(X)$** çš„ä¸åŒå®ç°æ–¹å¼ã€‚

åœ¨æ­¤æ¡†æ¶ä¸‹ï¼Œæ‰€æœ‰æ¨¡å‹éƒ½å¯ä»¥å†™æˆå¦‚ä¸‹å½¢å¼ï¼š
$$
\mathbf{y}_i = \sum_{j=1}^n W_{ij}(X) \mathbf{x}_j
$$
å…¶ä¸­ $W_{ij}(X) \in \mathbb{R}^{p \times d}$ æ˜¯ä»è¾“å…¥ $\mathbf{x}_j$ åˆ°è¾“å‡º $\mathbf{y}_i$ çš„æœ‰æ•ˆçº¿æ€§æ˜ å°„ï¼Œä¸”ä¾èµ–äºæ•´ä¸ªè¾“å…¥åºåˆ— $X$ã€‚

åŸºäºæ­¤ï¼Œä½œè€…åŒºåˆ†äº†ä¸¤ç±»æ„é€ æ¨¡å¼ï¼š

#### ï¼ˆ1ï¼‰**Unified Factorized Frameworkï¼ˆæ˜¾å¼äº¤äº’ï¼‰**
- æƒé‡åˆ†è§£ä¸ºæ ‡é‡å¾—åˆ†ä¸å…±äº«å€¼çŸ©é˜µçš„ä¹˜ç§¯ï¼š  
  $$
  W_{ij}(X) = f_o(\mathbf{x}_i, \mathbf{x}_j) \cdot V
  $$
- åŒ…æ‹¬ï¼šSoftmax Attentionã€Linear Attentionã€KANã€CNNã€MLPã€‚
- ç‰¹ç‚¹æ˜¯â€œ**scalar-factorized interaction**â€ï¼Œå³æ‰€æœ‰äº¤äº’æ“ä½œéƒ½æ˜¯å¯¹åŒä¸€ä¸ªçŸ©é˜µ $V$ è¿›è¡ŒåŠ æƒã€‚

#### ï¼ˆ2ï¼‰**Structured Dynamicsï¼ˆéšå¼åŠ¨æ€ï¼‰**
- æƒé‡ç”±æ½œåœ¨åŠ¨åŠ›ç³»ç»Ÿç”Ÿæˆï¼Œå¦‚çº¿æ€§SSMï¼š
  $$
  W_{ij} = C A^{i-j-1} B \quad (\text{for } j < i)
  $$
- åŒ…æ‹¬ï¼šS4ã€Mambaç­‰ã€‚
- å¯ä»¥ç”Ÿæˆéç§©ä¸€ï¼ˆnon-rank-oneï¼‰çš„æ“ä½œï¼Œå…·æœ‰æ›´é«˜çš„ä»£æ•°è¡¨è¾¾èƒ½åŠ›ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **ç†è®ºç»Ÿä¸€æ€§** | é¦–æ¬¡å°†Attentionä¸SSMç½®äºåŒä¸€æ•°å­¦æ¡†æ¶ä¸‹ï¼Œæ­ç¤ºå…¶æœ¬è´¨å·®å¼‚ä¸è”ç³»ã€‚ |
| **å¯è§£é‡Šæ€§å¢å¼º** | æ˜ç¡®æŒ‡å‡ºmulti-head attentionä¸æ˜¯ç®€å•ensembleï¼Œè€Œæ˜¯ä¸ºäº†æå‡â€œinteraction rankâ€ä»¥åŒ¹é…é«˜ç»´åŠ¨æ€ç³»ç»Ÿã€‚ |
| **æŒ‡å¯¼æ¶æ„è®¾è®¡** | æ­ç¤ºäº†**è¡¨è¾¾åŠ›ï¼ˆexpressivityï¼‰ä¸å¯è®­ç»ƒæ€§ï¼ˆtrainabilityï¼‰ä¹‹é—´çš„æ ¹æœ¬æƒè¡¡**ï¼Œä¸ºæ··åˆæ¶æ„ï¼ˆå¦‚Jambaï¼‰æä¾›ç†è®ºæ”¯æŒã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

è®ºæ–‡æœªä½¿ç”¨çœŸå®ä¸–ç•Œè‡ªç„¶è¯­è¨€æˆ–è§†è§‰æ•°æ®é›†ï¼Œè€Œæ˜¯é‡‡ç”¨**åˆæˆä»»åŠ¡ï¼ˆsynthetic tasksï¼‰** æ¥éªŒè¯ç†è®ºé¢„æµ‹ï¼š

- **ç³»ç»Ÿè¯†åˆ«ä»»åŠ¡ï¼ˆSystem Identificationï¼‰**ï¼šç”¨ä¸€ä¸ªâ€œæ•™å¸ˆâ€SSMç”Ÿæˆç›®æ ‡è¾“å‡ºï¼Œè®­ç»ƒâ€œå­¦ç”Ÿâ€Attentionæ¨¡å‹å»æ‹Ÿåˆå®ƒã€‚
- **æ¢¯åº¦æµåˆ†æä»»åŠ¡**ï¼šæµ‹é‡æ¨¡å‹å¯¹è¿œè·ç¦»è¾“å…¥å˜åŒ–çš„æ•æ„Ÿåº¦ï¼ˆå³Jacobiansï¼‰ï¼Œç”¨äºéªŒè¯æ¢¯åº¦ä¼ æ’­æ€§è´¨ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### âœ… å®éªŒä¸€ï¼šInteraction Rank Gapï¼ˆå®šç†4.4éªŒè¯ï¼‰

- **æ•™å¸ˆæ¨¡å‹ï¼ˆTeacherï¼‰**ï¼šæ„é€ ä¸€ä¸ªçº¿æ€§SSMï¼Œå…¶è„‰å†²å“åº”çŸ©é˜µ $\{W(\tau)\}$ å¼ æˆ $k$ ç»´å­ç©ºé—´ï¼ˆæ§åˆ¶$k=2,4,8$ï¼‰ã€‚
- **å­¦ç”Ÿæ¨¡å‹ï¼ˆStudentï¼‰**ï¼šmulti-head linear attention æ¨¡å‹ï¼Œheadæ•° $H \in \{1,\dots,9\}$ï¼Œå¸¦å¯å­¦ä¹ ä½ç½®ç¼–ç ã€‚
- **ç›®æ ‡**ï¼šæœ€å°åŒ–å­¦ç”Ÿè¾“å‡ºä¸æ•™å¸ˆè¾“å‡ºä¹‹é—´çš„MSEã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼šæµ‹è¯•é›†ä¸Šçš„å‡æ–¹è¯¯å·®ï¼ˆTest MSEï¼‰ã€‚

#### âœ… å®éªŒäºŒï¼šGradient Flow Dynamicsï¼ˆå®šç†5.1éªŒè¯ï¼‰

- å¯¹æ¯”ä¸¤ä¸ªæ¨¡å‹ï¼š
  - å›ºå®šå‚æ•°çš„çº¿æ€§SSMï¼ˆstableï¼Œ$\|A\|_2 < 1$ï¼‰
  - å¤šå¤´Attentionæ¨¡å‹ï¼ˆæ ‡å‡†åˆå§‹åŒ–ï¼‰
- æµ‹é‡æ™šæœŸè¾“å‡º $\mathbf{y}_T$ å¯¹ç¬¬ä¸€ä¸ªè¾“å…¥ $\mathbf{x}_1$ çš„é›…å¯æ¯”èŒƒæ•°ï¼š$\left\|\frac{\partial \mathbf{y}_T}{\partial \mathbf{x}_1}\right\|$
- åºåˆ—é•¿åº¦ $T$ ä»25åˆ°200å˜åŒ–ï¼Œåœ¨åŠå¯¹æ•°åæ ‡ä¸‹ç»˜å›¾ã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| æ¨¡å‹ | ç±»å‹ | æ˜¯å¦ä½œä¸ºBaseline |
|------|------|------------------|
| Linear SSM (e.g., S4-style) | Structured Dynamics | âœ… æ˜¯ï¼ˆç”¨äºæ¢¯åº¦è¡°å‡å®éªŒï¼‰ |
| Multi-head Linear Attention | Factorized Model | âœ… æ˜¯ï¼ˆç”¨äºrank-capacityå®éªŒï¼‰ |
| Single-head Attention | Factorized Model | âŒ å¦ï¼ˆä½œä¸ºç†è®ºä¸‹ç•Œï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### âœ… å®éªŒä¸€ï¼šInteraction Rank Gapï¼ˆå›¾3ï¼‰

| ç»“æœ | æ•°æ®/è§‚å¯Ÿ |
|------|----------|
| **å½“ $H < k$ æ—¶ï¼Œtest MSE å¾ˆé«˜** | è¡¨æ˜æ¨¡å‹æ— æ³•å……åˆ†è¡¨è¾¾ $k$ ç»´äº¤äº’ç©ºé—´ |
| **å½“ $H \geq k$ æ—¶ï¼Œerroræ˜¾è‘—ä¸‹é™å¹¶è¶‹äºç¨³å®šä½å€¼** | æ”¯æŒå®šç†4.4ä¸­â€œå¿…è¦ä¸”å……åˆ†â€çš„ç»“è®º |
| **ä¾‹å¦‚ $k=8$ æ—¶ï¼Œåªæœ‰å½“ $H \geq 8$ æ‰è¿›å…¥ä½è¯¯å·®åŒº** | æ˜¾ç¤ºhead countç›´æ¥å†³å®šè¡¨è¾¾ä¸Šé™ |
| **SVDè°±æ˜¾ç¤ºçº¦4ä¸ªä¸»å¯¼å¥‡å¼‚å€¼ï¼ˆå½“ $k=4, H=4$ï¼‰** | è¡¨æ˜headsç¡®å®å­¦åˆ°äº†ç›®æ ‡äº¤äº’å­ç©ºé—´çš„åŸº |

> ğŸ” **å…³é”®å‘ç°**ï¼šmulti-head attentionçš„headæ•°é‡ $H$ å¿…é¡»è‡³å°‘ç­‰äºSSMçš„interaction rank $k$ æ‰èƒ½ç²¾ç¡®è¡¨ç¤ºè¯¥åŠ¨æ€ç³»ç»Ÿã€‚

---

### âœ… å®éªŒäºŒï¼šGradient Flow Dynamicsï¼ˆå›¾4ï¼‰

| æ¨¡å‹ | æ¢¯åº¦è¡°å‡è¶‹åŠ¿ | é•¿ç¨‹æ•æ„Ÿæ€§ |
|------|--------------|------------|
| **Linear SSM** | æŒ‡æ•°çº§è¡°å‡ï¼ˆçº¢çº¿ï¼‰ | éšè·ç¦»è¿…é€Ÿå‡å¼± |
| **Multi-head Attention** | ç¼“æ…¢è¡°å‡ï¼ˆè“çº¿ï¼‰ï¼Œä¿æŒè¾ƒé«˜æ°´å¹³ | å³ä½¿åœ¨ $T=200$ ä»ä¿ç•™è¾ƒå¼ºä¿¡å· |

> ğŸ” **å…³é”®å‘ç°**ï¼šAttentionæä¾›äº†â€œgradient highwayâ€â€”â€”ä¸€ç§ä¸éšè·ç¦»è¡°å‡çš„çŸ­è·¯å¾„ï¼Œæœ‰åŠ©äºç¼“è§£é•¿æœŸä¾èµ–è®­ç»ƒéš¾é¢˜ã€‚

---

### âœ… æ¶ˆèå®éªŒï¼ˆéšå«åœ¨ç†è®ºè¯æ˜ä¸­ï¼‰

è™½ç„¶æ²¡æœ‰ç‹¬ç«‹ç« èŠ‚å‘½åâ€œablationâ€ï¼Œä½†ä»¥ä¸‹æ„æˆå®è´¨æ¶ˆèï¼š

- **å•å¤´ vs å¤šå¤´ Attention**ï¼šå•å¤´æ— æ³•è·¨è¶ŠInteraction Rank Gapï¼Œå¤šå¤´å¯ä»¥ï¼›
- **é™æ€ vs åŠ¨æ€æƒé‡**ï¼šä»…åŠ¨æ€æƒé‡ï¼ˆå¦‚Attentionï¼‰æ‰èƒ½å®ç°distance-independentæ¢¯åº¦ï¼›
- **æœ‰æ— Positional Encoding**ï¼šæ·»åŠ PEåèƒ½æ›´å¥½æ‹Ÿåˆlagç»“æ„ï¼Œè¯´æ˜ä½ç½®ä¿¡æ¯çš„é‡è¦æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ğŸ§  **ä¸»è¦å‘ç°**

1. **Interaction Rank Gap å®šç†ï¼ˆTheorem 4.2ï¼‰**
   - å•å¤´factorizedæ¨¡å‹ï¼ˆå¦‚single-head attentionï¼‰åªèƒ½ç”Ÿæˆæ‰€æœ‰äº¤äº’ç®—å­éƒ½åœ¨ä¸€ä¸ªå›ºå®šçŸ©é˜µ $V$ çš„æ ‡é‡å€æ•°æ–¹å‘ä¸Šã€‚
   - è€Œçº¿æ€§SSMçš„è„‰å†²å“åº”çŸ©é˜µå¯èƒ½å¼ æˆé«˜ç»´ç©ºé—´ï¼ˆå¦‚æ—‹è½¬çŸ©é˜µä¾‹å­ï¼‰ï¼Œå› æ­¤**å•å¤´Attentionæ— æ³•ä¸€è‡´é€¼è¿‘è¿™ç±»ç³»ç»Ÿ**ã€‚

2. **Multi-head Equivalence å®šç†ï¼ˆTheorem 4.4ï¼‰**
   - è¦ç²¾ç¡®è¡¨ç¤ºä¸€ä¸ªinteraction rankä¸º $k$ çš„çº¿æ€§SSMï¼Œmulti-head attentionå¿…é¡»æ»¡è¶³ï¼š
     $$
     H \geq k
     $$
   - å¹¶ä¸”å½“ $H \geq k$ æ—¶ï¼Œå­˜åœ¨å‚æ•°é…ç½®ä½¿å¾—æ¨¡å‹èƒ½å®Œå…¨å¤ç°SSMè¡Œä¸ºã€‚
   - â‡’ **Head count æ§åˆ¶ interaction subspace çš„ç»´åº¦ä¸Šé™**ã€‚

3. **Gradient Highway å®šç†ï¼ˆTheorem 5.1ï¼‰**
   - åœ¨ç¨³å®šçº¿æ€§SSMä¸­ï¼Œè¾“å…¥-è¾“å‡ºJacobiçŸ©é˜µèŒƒæ•°éšè·ç¦»æŒ‡æ•°è¡°å‡ï¼ˆ$\propto \|A\|^{T}$ï¼‰ï¼›
   - è€ŒAttentionæœºåˆ¶å­˜åœ¨è¾“å…¥åºåˆ—ä½¿å¾—æ¢¯åº¦èŒƒæ•°**ä¸è·ç¦»æ— å…³**ï¼Œå½¢æˆâ€œtopological shortcutâ€ã€‚

4. **æ ¹æœ¬æƒè¡¡ï¼ˆTrade-offï¼‰**
   - **SSMç±»æ¨¡å‹**ï¼šé«˜è¡¨è¾¾åŠ›ï¼ˆhigh interaction rankï¼‰ï¼Œä½†æ¢¯åº¦æ˜“è¡°å‡ï¼ˆhard to trainï¼‰ï¼›
   - **Attentionç±»æ¨¡å‹**ï¼šä½ç§©é™åˆ¶ï¼ˆlow interaction rank per headï¼‰ï¼Œä½†æ¢¯åº¦ä¼ æ’­å¼ºï¼ˆeasy to trainï¼‰ï¼›
   - â‡’ **Hybridæ¶æ„ï¼ˆå¦‚Jambaï¼‰æ˜¯å¯¹æ­¤trade-offçš„å·¥ç¨‹å›åº”**ã€‚

---

### âš ï¸ **æ–¹æ³•çš„å±€é™æ€§**

| å±€é™ | è¯´æ˜ |
|------|------|
| **ä»…é€‚ç”¨äºçº¿æ€§æˆ–å±€éƒ¨çº¿æ€§æ¨¡å‹** | éçº¿æ€§RNNçš„Jacobianså¤æ‚ï¼Œå½“å‰åˆ†æä¸»è¦é’ˆå¯¹çº¿æ€§SSMå’Œlinear attention |
| **åˆæˆå®éªŒä¸ºä¸»** | å°šæœªåœ¨å¤§è§„æ¨¡è¯­è¨€å»ºæ¨¡ä»»åŠ¡ä¸ŠéªŒè¯ç†è®ºé¢„æµ‹ |
| **feature dimensionå¯èƒ½å¾ˆå¤§** | æ„é€ æ€§è¯æ˜ä¸­éœ€è¦ $r=O(n)$ çš„ç‰¹å¾ç»´åº¦ï¼Œå®é™…åº”ç”¨éœ€è¿›ä¸€æ­¥å‹ç¼© |
| **æœªæ¶µç›–éå› æœ/åŒå‘åœºæ™¯** | åˆ†æé›†ä¸­åœ¨causal settingï¼Œæ‰©å±•éœ€è°ƒæ•´ |

---

### ğŸ”® **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ¨å¹¿åˆ°éçº¿æ€§åŠ¨æ€ç³»ç»Ÿ**ï¼šç ”ç©¶éçº¿æ€§SSMæˆ–RNNçš„interaction rankå®šä¹‰ã€‚
2. **è®¾è®¡æœ€ä¼˜headåˆ†é…ç­–ç•¥**ï¼šå¦‚ä½•æ ¹æ®ä»»åŠ¡è‡ªåŠ¨é€‰æ‹© $H$ æˆ–åŠ¨æ€åˆ†é…headsã€‚
3. **ç»“åˆHiPPO/S4å‚æ•°åŒ–**ï¼šåˆ©ç”¨é¢‘åŸŸç»“æ„é™ä½feature dimensionè‡³ $O(m)$ã€‚
4. **åº”ç”¨äºå®é™…æ¨¡å‹å‹ç¼©ä¸è’¸é¦**ï¼šç”¨SSMä½œä¸ºâ€œteacherâ€æŒ‡å¯¼è½»é‡Attentionâ€œstudentâ€ã€‚
5. **æ¢ç´¢å…¶ä»–factorizationå½¢å¼**ï¼šè¶…è¶Šæ ‡é‡å› å­åŒ–ï¼ˆscalar factorizationï¼‰ï¼Œå¼•å…¥çŸ©é˜µå› å­åŒ–æå‡æ•ˆç‡ã€‚

---

## æ€»ç»“

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œæ­ç¤ºäº†Attentionä¸SSMçš„æœ¬è´¨åŒºåˆ«åœ¨äº**interaction rank**ä¸**gradient propagationç‰¹æ€§**ï¼Œå¹¶è¯æ˜ï¼š**multi-head attentionä¸­çš„headæ•°é‡ $H$ å¿…é¡»ä¸å°‘äºSSMçš„interaction rank $k$ æ‰èƒ½å®Œæ•´è¡¨è¾¾å…¶åŠ¨æ€ï¼›è€ŒAttentionå‡­å€Ÿâ€œgradient highwayâ€åœ¨é•¿ç¨‹ä¾èµ–è®­ç»ƒä¸­æ›´å…·ä¼˜åŠ¿**ã€‚

è¿™ä¸€ç†è®ºä¸ºç°ä»£åºåˆ—æ¨¡å‹çš„è®¾è®¡ï¼ˆå°¤å…¶æ˜¯hybridæ¶æ„å¦‚Jambaï¼‰æä¾›äº†åšå®çš„æ•°å­¦åŸºç¡€ã€‚

</details>

---

### 13. [Metanetworks as Regulatory Operators: Learning to Edit for Requirement Compliance](https://arxiv.org/abs/2512.15469)

**Authors**: Ioannis Kalogeropoulos, Giorgos Bouritsas, Yannis Panagakis  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.15469v1  

#### Abstract
As machine learning models are increasingly deployed in high-stakes settings, e.g. as decision support systems in various societal sectors or in critical infrastructure, designers and auditors are facing the need to ensure that models satisfy a wider variety of requirements (e.g. compliance with reg...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Metanetworks as Regulatory Operators: Learning to Edit for Requirement Compliance*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
éšç€æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨é«˜é£é™©åœºæ™¯ï¼ˆå¦‚å†³ç­–æ”¯æŒç³»ç»Ÿã€å…³é”®åŸºç¡€è®¾æ–½ï¼‰ä¸­çš„å¹¿æ³›åº”ç”¨ï¼Œç¡®ä¿æ¨¡å‹æ»¡è¶³**å¤šæ ·åŒ–è¦æ±‚**ï¼ˆå¦‚æ³•è§„åˆè§„ã€å…¬å¹³æ€§ã€è®¡ç®—æ•ˆç‡ç­‰ï¼‰å˜å¾—è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿæ–¹æ³•é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **Post-processing** æ–¹æ³•å¸¸æŸå®³æ¨¡å‹æ€§èƒ½ï¼›
- **Fine-tuning æˆ–é‡æ–°è®­ç»ƒ** æˆæœ¬é«˜æ˜‚ä¸”å¯èƒ½å› æ•°æ®éšç§æˆ–çŸ¥è¯†äº§æƒé™åˆ¶è€Œä¸å¯è¡Œï¼›
- æ–°è¦æ±‚å¾€å¾€åœ¨æ¨¡å‹éƒ¨ç½²åæ‰å‡ºç°ï¼Œå¯¼è‡´â€œè®­ç»ƒ-éœ€æ±‚â€æ—¶é—´é”™é…ã€‚

æœ¬æ–‡æå‡ºçš„æ ¸å¿ƒé—®é¢˜æ˜¯ï¼š  
> **èƒ½å¦åœ¨ä¸ç‰ºç‰²æ¨¡å‹æ•ˆç”¨çš„å‰æä¸‹ï¼Œé«˜æ•ˆåœ°ç¼–è¾‘æ¨¡å‹ä»¥æ»¡è¶³æ–°è¦æ±‚ï¼Ÿ**

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡ºä¸€ç§**ç»Ÿä¸€çš„ã€åŸºäºå­¦ä¹ çš„ç¥ç»ç½‘ç»œç¼–è¾‘æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å°†æ¨¡å‹ç¼–è¾‘å»ºæ¨¡ä¸ºä¸€ä¸ª**å¤šç›®æ ‡ä¼˜åŒ–é—®é¢˜**ï¼Œç›®æ ‡å‡½æ•°åŒ…æ‹¬ï¼š
  - **Preservation Objective**ï¼šä¿æŒåŸå§‹æ¨¡å‹è¡Œä¸ºä¸å˜ï¼ˆé€šè¿‡ JSD è¡¡é‡è¾“å‡ºå·®å¼‚ï¼‰ï¼›
  - **Requirement Objective**ï¼šæ»¡è¶³ç‰¹å®šåˆè§„è¦æ±‚ï¼ˆå¦‚æ•°æ®æœ€å°åŒ–ã€å…¬å¹³æ€§ã€ç¨€ç–æ€§ï¼‰ã€‚
- å¼•å…¥ **Graph Metanetwork** ä½œä¸ºâ€œå¯å­¦ä¹ çš„ç¼–è¾‘å™¨â€ï¼Œç›´æ¥ä»åŸå§‹æ¨¡å‹å‚æ•°é¢„æµ‹ç¼–è¾‘åçš„å‚æ•°ã€‚
- ç¼–è¾‘è¿‡ç¨‹ä»…éœ€ä¸€æ¬¡å‰å‘æ¨ç†ï¼ˆsingle inference stepï¼‰ï¼Œå®ç°**å¿«é€Ÿã€çµæ´»çš„æ¨¡å‹ä¿®æ”¹**ã€‚

è¯¥æ–¹æ³•çš„å…³é”®åˆ›æ–°åœ¨äºï¼š
- **ç»Ÿä¸€æ¡†æ¶**ï¼šå°†ä¸åŒç±»å‹çš„åˆè§„è¦æ±‚å½¢å¼åŒ–ä¸ºæ•°å­¦ç›®æ ‡ï¼Œé€‚ç”¨äºå¤šç§ä»»åŠ¡ï¼›
- **æ•°æ®é©±åŠ¨ç¼–è¾‘**ï¼šåˆ©ç”¨å¤§é‡å·²è®­ç»ƒæ¨¡å‹ï¼ˆNN populationsï¼‰è®­ç»ƒ metanetworkï¼Œä½¿å…¶å­¦ä¼šâ€œå¦‚ä½•ç¼–è¾‘â€ï¼›
- **æ— éœ€å†è®­ç»ƒ**ï¼šé¿å…äº†è€—æ—¶çš„ fine-tuning æˆ– retrainingï¼›
- **ç™½ç›’è®¿é—®ä¸‹çš„é€šç”¨å·¥å…·**ï¼šå¯è¢«è®¾è®¡è€…æˆ–å®¡è®¡å‘˜ç”¨äºå¿«é€Ÿåˆè§„è°ƒæ•´ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆPost-processing / Retrainingï¼‰ | æœ¬æ–‡æ–¹æ³•ï¼ˆMetanetwork-based Editingï¼‰ |
|------|----------------------------------------|----------------------------------------|
| æ—¶é—´æ•ˆç‡ | é«˜å»¶è¿Ÿï¼ˆåˆ†é’Ÿåˆ°å°æ—¶çº§ï¼‰ | **æ¯«ç§’çº§ç¼–è¾‘**ï¼ˆå•æ¬¡æ¨ç†ï¼‰ |
| æ€§èƒ½ä¿ç•™ | å¸¸æ˜¾è‘—ä¸‹é™ | æ›´å¥½åœ°å¹³è¡¡**åŠŸèƒ½ä¿ç•™ä¸è¦æ±‚æ»¡è¶³** |
| å¯æ‰©å±•æ€§ | æ¯ä¸ªæ¨¡å‹ç‹¬ç«‹å¤„ç† | ä¸€ä¸ª metanetwork å¯ç¼–è¾‘åŒä»»åŠ¡åˆ†å¸ƒä¸‹çš„ä»»æ„æ¨¡å‹ |
| çµæ´»æ€§ | éœ€ä¸ºæ¯ç§éœ€æ±‚å®šåˆ¶æµç¨‹ | æ”¯æŒå¤šä»»åŠ¡ç»„åˆï¼ˆå¦‚å…ˆå»åå†å‰ªæï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **UCI Adult** å’Œ **Bank Marketing** æ•°æ®é›†ï¼Œå‡ä¸ºçœŸå®ä¸–ç•Œçš„è¡¨æ ¼æ•°æ® benchmarkï¼›
- æ„å»ºä¸¤ä¸ªå¤§è§„æ¨¡çš„ **NN populationsï¼ˆDmï¼‰**ï¼šå„åŒ…å«çº¦ 12,000 ä¸ª MLP æ¨¡å‹ï¼Œè¦†ç›–ä¸åŒæ¶æ„ã€è¶…å‚æ•°å’Œè®­ç»ƒé˜¶æ®µï¼›
- æ•°æ®åˆ†å¸ƒè®°ä¸º $ p_d $ï¼Œæ¨¡å‹å‚æ•°åˆ†å¸ƒè®°ä¸º $ p_m $ã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹ç±»å‹**ï¼šMLPï¼ˆå…¨è¿æ¥å‰é¦ˆç½‘ç»œï¼‰ï¼›
- **Metanetwork æ¶æ„**ï¼šåŸºäº **Graph Metanetwork**ï¼ˆLim et al., 2024ï¼‰ï¼Œå¯¹å‚æ•°ç©ºé—´çš„ç½®æ¢å¯¹ç§°æ€§ï¼ˆpermutation symmetryï¼‰ä¿æŒç­‰å˜æ€§ï¼›
- **è®­ç»ƒæ–¹å¼**ï¼šæ— ç›‘ç£å­¦ä¹ ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–åŠ æƒæŸå¤±ï¼š
  $$
  \mathcal{L} = \mathbb{E}_{(G,\theta)\sim p_m} \left[ \text{JSD}(f_{\theta}, f_{\hat{\theta}}) + \lambda \cdot r(\hat{G}, \hat{\theta}) \right]
  $$
  å…¶ä¸­ $\lambda$ æ§åˆ¶ä¸¤ä¸ªç›®æ ‡ä¹‹é—´çš„æƒè¡¡ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **X-axis**ï¼šå¹³å‡ requirement objectiveï¼ˆè¶Šä½è¶Šå¥½ï¼‰
  - æ•°æ®æœ€å°åŒ–ï¼šæ¿€æ´»ç‰¹å¾æ¯”ä¾‹
  - å…¬å¹³æ€§ï¼šEqualized Odds Difference (EOD)
  - å‰ªæï¼šå‰©ä½™æƒé‡æ¯”ä¾‹
- **Y-axis**ï¼šå¹³å‡ JSDï¼ˆè¶Šä½è¡¨ç¤ºåŠŸèƒ½åç¦»è¶Šå°ï¼‰
- ç»˜åˆ¶ **Pareto front** æ›²çº¿ï¼Œå±•ç¤ºæ€§èƒ½ä¸åˆè§„æ€§çš„æƒè¡¡å…³ç³»ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ä»»åŠ¡ | åŸºçº¿æ–¹æ³• |
|------|---------|
| **æ•°æ®æœ€å°åŒ–** | Feature Selection (FS), FS & Retrain (çŸ¥è¯†è’¸é¦) |
| **å…¬å¹³æ€§æå‡** | ThresholdOpt, RejectOption, CalEqOdds, FairCls |
| **æƒé‡å‰ªæ** | Random, Magnitude, Grad Importance, SNIP, Lottery Ticket |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”ç»“æœ

#### ï¼ˆ1ï¼‰æ•°æ®æœ€å°åŒ–ï¼ˆData Minimizationï¼‰
- åœ¨ Adult å’Œ Bank æ•°æ®é›†ä¸Šï¼Œ**GMN** æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼›
- åœ¨é«˜æ©ç ç‡ï¼ˆå³ä¿ç•™æ›´å°‘ç‰¹å¾ï¼‰æ—¶ä¼˜åŠ¿æ›´å¤§ï¼Œè¯´æ˜ metanetwork èƒ½æœ‰æ•ˆè¡¥å¿ä¿¡æ¯ç¼ºå¤±ï¼›
- **FS (GMN)**ï¼ˆä»…é¢„æµ‹ maskï¼‰ä¹Ÿä¼˜äºä¼ ç»Ÿ FSï¼Œè¡¨æ˜å‚æ•°æ„ŸçŸ¥çš„ mask æ›´ä¼˜ã€‚

> âœ… å›¾1æ˜¾ç¤ºï¼šGMN åœ¨ç›¸åŒ JSD ä¸‹èƒ½å±è”½æ›´å¤šç‰¹å¾ï¼Œæˆ–åœ¨ç›¸åŒå±è”½æ¯”ä¾‹ä¸‹é€ æˆæ›´å°çš„åŠŸèƒ½æ¼‚ç§»ã€‚

#### ï¼ˆ2ï¼‰åå·®ç¼“è§£ï¼ˆBias Mitigationï¼‰
- GMN åœ¨æ•´ä¸ª Pareto front ä¸Šå…¨é¢è¶…è¶Š ThresholdOptã€RejectOption ç­‰ç»å…¸ post-processing æ–¹æ³•ï¼›
- è¾¾åˆ°æ›´ä½çš„ EOD åŒæ—¶ä¿æŒæ›´å°çš„ JSDï¼›
- ä¼ ç»Ÿæ–¹æ³•å—é™äºç¡¬çº¦æŸï¼ˆå¦‚ Equalized Oddsï¼‰ï¼Œåªèƒ½äº§ç”Ÿå•ä¸€è§£ï¼›è€Œ GMN æä¾›è¿ç»­æƒè¡¡æ›²çº¿ã€‚

> âœ… å›¾2æ˜¾ç¤ºï¼šGMN å®ç°äº† **EOD < 0.01** ä¸” JSD â‰ˆ 0.005ï¼Œè¿œè¶…åŸºçº¿ã€‚

#### ï¼ˆ3ï¼‰æƒé‡å‰ªæï¼ˆWeight Pruningï¼‰
- **GMN-Prune & Edit** åœ¨é«˜ç¨€ç–åº¦ä¸‹è¡¨ç°å°¤ä¸ºå‡ºè‰²ï¼›
- å³ä½¿åªè¿›è¡Œå‰ªæï¼ˆGMN-Pruneï¼‰ï¼Œä¹Ÿä¼˜äº Randomã€Magnitudeã€Grad Importanceï¼›
- ç»“åˆå‚æ•°ç¼–è¾‘åï¼Œåœ¨ç›¸åŒç¨€ç–åº¦ä¸‹æ˜¾è‘—é™ä½ JSDã€‚

> âœ… å›¾3æ˜¾ç¤ºï¼šå½“å‰©ä½™æƒé‡æ¯”ä¾‹ä¸º 0.2 æ—¶ï¼ŒGMN-Prune & Edit çš„ JSD æ¯” SNIP ä½çº¦ 50%ã€‚

### æ—¶é—´æ•ˆç‡å¯¹æ¯”ï¼ˆTable 1ï¼‰
| æ–¹æ³• | å¹³å‡ç¼–è¾‘æ—¶é—´ï¼ˆç§’ï¼‰ |
|------|------------------|
| FS & Retrain | 32.35 |
| RejectOption | 4.36 |
| SNIP | 0.41 |
| **GMN (æœ¬æ–‡)** | **0.03** |

> âš¡ GMN æ¯”å¤§å¤šæ•°åŸºçº¿å¿« **1â€“1000 å€**ï¼Œä»…ç•¥æ…¢äºæœ€ç®€å•çš„éšæœºå‰ªæã€‚

### æ¶ˆèå®éªŒç»“æœ
- **è®­ç»ƒæ ·æœ¬æ•ˆç‡åˆ†æ**ï¼ˆå›¾4ï¼‰ï¼š
  - å³ä½¿ç”¨ **10% çš„è®­ç»ƒæ•°æ®**ï¼ŒGMN ä»ä¼˜äºå¤šæ•°åŸºçº¿ï¼›
  - ä½¿ç”¨ **25% æ•°æ®** å³å¯æ¥è¿‘æœ€ä¼˜æ€§èƒ½ï¼›
  - 50% ä»¥ä¸Šæå‡æœ‰é™ï¼Œè¡¨æ˜ metanetwork å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

- **ç»„åˆå¤šä¸ª metanetwork**ï¼ˆAppendix A.7ï¼‰ï¼š
  - å°†åˆ†åˆ«è®­ç»ƒçš„æ•°æ®æœ€å°åŒ–ï¼ˆS_dmï¼‰å’Œå‰ªæï¼ˆS_prï¼‰metanetwork ç»„åˆï¼š$ \mathcal{S} = \mathcal{S}_{pr} \circ \mathcal{S}_{dm} $
  - ç»„åˆåçš„ metanetwork ä¾ç„¶ä¸»å¯¼ Pareto frontï¼Œè¯æ˜å…¶**æ¨¡å—åŒ–ä¸å¯ç»„åˆæ€§**ï¼›
  - è¡¨æ˜å•ä¸ªç¼–è¾‘ä¸ä¼šç ´ååç»­ç¼–è¾‘æ‰€éœ€çš„å‚æ•°åˆ†å¸ƒå‡è®¾ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **Metanetwork å¯ä½œä¸ºé«˜æ•ˆçš„â€œåˆè§„æ“ä½œç¬¦â€**ï¼šèƒ½å¤Ÿåœ¨éƒ¨ç½²åå¿«é€Ÿã€ä½æˆæœ¬åœ°ä½¿æ¨¡å‹æ»¡è¶³æ–°è¦æ±‚ã€‚
2. âœ… **å­¦ä¹ åˆ°çš„ç¼–è¾‘ä¼˜äºæ‰‹å·¥è§„åˆ™æˆ–ä¼˜åŒ–æ–¹æ³•**ï¼šåœ¨æ€§èƒ½ä¿ç•™ä¸è¦æ±‚æ»¡è¶³ä¹‹é—´å–å¾—æ›´å¥½æƒè¡¡ã€‚
3. âœ… **ç¼–è¾‘è¿‡ç¨‹é«˜åº¦é«˜æ•ˆ**ï¼šå•æ¬¡æ¨ç†å³å¯å®Œæˆï¼Œé€‚åˆå®æ—¶æˆ–æ‰¹é‡åˆè§„å®¡è®¡ã€‚
4. âœ… **æ¡†æ¶å…·æœ‰é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§**ï¼šåŒä¸€èŒƒå¼å¯ç”¨äºæ•°æ®æœ€å°åŒ–ã€å…¬å¹³æ€§ã€å‰ªæç­‰å¤šç§ä»»åŠ¡ã€‚
5. âœ… **æ”¯æŒå¤šç›®æ ‡ç»„åˆç¼–è¾‘**ï¼šä¸åŒ metanetwork å¯ä¸²è”ä½¿ç”¨ï¼Œæ„å»ºå¤æ‚åˆè§„æµæ°´çº¿ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- â— å½“å‰ä»…é€‚ç”¨äº **åŒä»»åŠ¡åˆ†å¸ƒå†…çš„ MLP æ¨¡å‹**ï¼Œéš¾ä»¥è·¨ä»»åŠ¡è¿ç§»ï¼›
- â— éœ€è¦é¢„å…ˆæ”¶é›†å¤§é‡è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆ$ p_m $ï¼‰æ¥è®­ç»ƒ metanetworkï¼›
- â— ç›®å‰æœªéªŒè¯åœ¨å¤æ‚æ¶æ„ï¼ˆå¦‚ CNNã€Transformerï¼‰ä¸Šçš„æœ‰æ•ˆæ€§ï¼›
- â— å®Œå…¨è‡ªåŠ¨åŒ–ç¼–è¾‘å­˜åœ¨é£é™©ï¼Œ**ä»éœ€äººç±»ä¸“å®¶å‚ä¸æœ€ç»ˆå†³ç­–**ï¼ˆå¼ºè°ƒ human oversightï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **å¤šä»»åŠ¡å¯å­¦ä¹ ç¼–è¾‘å™¨**ï¼ˆmulti-task learnable editorï¼‰ï¼Œæ”¯æŒè·¨ä»»åŠ¡æ³›åŒ–ï¼›
- æ¢ç´¢ **é»‘ç›’æ¡ä»¶ä¸‹çš„ç¼–è¾‘æ–¹æ³•**ï¼ˆå½“å‰ä¾èµ–ç™½ç›’å‚æ•°è®¿é—®ï¼‰ï¼›
- å°† metanetwork åº”ç”¨äºæ›´å¤æ‚çš„æ¨¡å‹æ¶æ„ï¼ˆå¦‚ Vision Transformerã€LLMsï¼‰ï¼›
- å¼€å‘é¢å‘ç›‘ç®¡æœºæ„çš„ **è‡ªåŠ¨åŒ– AI å®¡è®¡å·¥å…·é“¾**ï¼Œé›†æˆæ­¤ç±» learned editorï¼›
- è¿›ä¸€æ­¥ç ”ç©¶ metanetwork çš„**å¯è§£é‡Šæ€§ä¸å®‰å…¨æ€§**ï¼Œé˜²æ­¢æ¶æ„ç¼–è¾‘ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå¼€åˆ›æ€§çš„â€œ**å­¦ä¼šç¼–è¾‘**â€ï¼ˆLearning to Editï¼‰èŒƒå¼ï¼Œåˆ©ç”¨ **Graph Metanetwork** å®ç°å¯¹ç¥ç»ç½‘ç»œçš„å¿«é€Ÿã€çµæ´»ã€é«˜æ€§èƒ½çš„åˆè§„æ€§ä¿®æ”¹ï¼Œä¸º AI ç›‘ç®¡ä¸å¯æŒç»­éƒ¨ç½²æä¾›äº†å¼ºæœ‰åŠ›çš„å·¥å…·åŸºç¡€ã€‚

</details>

---

### 14. [Multi-Modal Semantic Communication](https://arxiv.org/abs/2512.15691)

**Authors**: Matin Mortaheb, Erciyes Karakaya, Sennur Ulukus  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.15691v1  

#### Abstract
Semantic communication aims to transmit information most relevant to a task rather than raw data, offering significant gains in communication efficiency for applications such as telepresence, augmented reality, and remote sensing. Recent transformer-based approaches have used self-attention maps to ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠMulti-Modal Semantic Communicationã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»ŸåŸºäºè§†è§‰è‡ªæ³¨æ„åŠ›ï¼ˆself-attentionï¼‰çš„è¯­ä¹‰é€šä¿¡æ–¹æ³•åœ¨å¤æ‚åœºæ™¯ä¸­å­˜åœ¨ä»¥ä¸‹å±€é™ï¼š
- åœ¨å¤šç‰©ä½“ã€èƒŒæ™¯æ‚ä¹±æˆ–è¯­ä¹‰æ¨¡ç³Šçš„å›¾åƒä¸­ï¼Œ**è‡ªæ³¨æ„åŠ›æœºåˆ¶éš¾ä»¥å‡†ç¡®è¯†åˆ«ä»»åŠ¡ç›¸å…³çš„è¯­ä¹‰åŒºåŸŸ**ï¼Œå®¹æ˜“èšç„¦äºè§†è§‰æ˜¾è‘—ä½†è¯­ä¹‰æ— å…³çš„å†…å®¹ï¼›
- å½“é€šä¿¡ç›®æ ‡æ”¹å˜æ—¶ï¼ˆå¦‚ä»åˆ†ç±»å˜ä¸ºæ£€æµ‹ï¼‰ï¼Œéœ€é‡æ–°è®­ç»ƒæ•´ä¸ªæ¨¡å‹ï¼Œ**ç¼ºä¹çµæ´»æ€§å’Œå®æ—¶é€‚åº”èƒ½åŠ›**ï¼›
- ç¼ºä¹å¯¹ç”¨æˆ·æ„å›¾çš„æ˜¾å¼å»ºæ¨¡ï¼Œå¯¼è‡´ä¼ è¾“å†…å®¹ä¸å®é™…éœ€æ±‚è„±èŠ‚ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§**Multi-Modal Semantic Communicationï¼ˆMMSCï¼‰æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

1. **å¼•å…¥æ–‡æœ¬æŸ¥è¯¢ä½œä¸ºå¼•å¯¼ä¿¡å·**  
   åˆ©ç”¨ç”¨æˆ·æä¾›çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼ˆtext-based user queryï¼‰æ¥æŒ‡å¯¼å›¾åƒä¸­å…³é”®åŒºåŸŸçš„é€‰æ‹©ï¼Œå®ç°â€œä»»åŠ¡é©±åŠ¨â€çš„è¯­ä¹‰æå–ã€‚

2. **è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶ï¼ˆCross-Modal Attentionï¼‰**  
   èåˆè§†è§‰ç‰¹å¾ï¼ˆæ¥è‡ªCLIP-Visionï¼‰ä¸è¯­è¨€åµŒå…¥ï¼ˆæ¥è‡ªCLIP-Textï¼‰ï¼Œé€šè¿‡äº¤å‰æ³¨æ„åŠ›è®¡ç®—æ¯ä¸ªå›¾åƒå—ç›¸å¯¹äºæŸ¥è¯¢çš„**è½¯ç›¸å…³æ€§åˆ†æ•°ï¼ˆsoft relevance scoresï¼‰**ï¼Œè€Œéç¡¬åˆ†å‰²æ©ç ã€‚

3. **åŠ¨æ€åˆ†è¾¨ç‡ç¼–ç ç­–ç•¥**  
   æ ¹æ®é€šé“å¸¦å®½å’Œè¯­ä¹‰é‡è¦æ€§è¯„åˆ†ï¼Œå°†å›¾åƒåˆ’åˆ†ä¸ºpatchï¼Œå¹¶åˆ†é…ä¸åŒåˆ†è¾¨ç‡ç­‰çº§è¿›è¡Œç¼–ç ã€‚é«˜ç›¸å…³æ€§patchä»¥æ›´é«˜æ¯”ç‰¹ç‡ä¼ è¾“ï¼Œä½ç›¸å…³æ€§åˆ™å‹ç¼©æ›´ç”šï¼Œæ€»ç ç‡åŒ¹é…ä¿¡é“å®¹é‡ã€‚

4. **æ— éœ€å¾®è°ƒå³å¯é€‚åº”æ–°ä»»åŠ¡**  
   æ¨¡å‹åœ¨æ¨ç†é˜¶æ®µç›´æ¥å¤„ç†ä»»æ„è‡ªç”±å½¢å¼çš„æ–‡æœ¬æŸ¥è¯¢ï¼Œæ— éœ€ä¸ºæ¯ä¸ªæ–°ä»»åŠ¡é‡æ–°è®­ç»ƒæˆ–å¾®è°ƒï¼Œæå¤§æå‡å®ç”¨æ€§ä¸æ³›åŒ–èƒ½åŠ›ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | æœ¬æ–‡ MMSC | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ ViT-SC [6]ï¼‰ |
|------|-----------|--------------------------|
| è¾“å…¥æ¨¡æ€ | å›¾åƒ + æ–‡æœ¬æŸ¥è¯¢ï¼ˆåŒæ¨¡æ€ï¼‰ | ä»…å›¾åƒï¼ˆå•æ¨¡æ€ï¼‰ |
| æ³¨æ„åŠ›æœºåˆ¶ | Cross-Modal Attentionï¼ˆå›¾æ–‡èåˆï¼‰ | Self-Attentionï¼ˆä»…è§†è§‰å†…å»ºï¼‰ |
| è¯­ä¹‰ä¼˜å…ˆçº§æ§åˆ¶ | ç”¨æˆ·æŸ¥è¯¢é©±åŠ¨ï¼Œå¯å˜ä»»åŠ¡ | å›ºå®šä»»åŠ¡ï¼Œä¾èµ–é¢„è®­ç»ƒç›®æ ‡ |
| çµæ´»æ€§ | æ”¯æŒå¼€æ”¾è¯æ±‡ã€è‡ªç„¶è¯­è¨€æŸ¥è¯¢ | éœ€é‡æ–°è®­ç»ƒæ‰èƒ½åˆ‡æ¢ä»»åŠ¡ |
| è¾“å‡ºè¡¨ç¤º | Soft relevance mapï¼ˆè¿ç»­å€¼ï¼‰ | Hard attention / binary mask |
| å¸¦å®½åˆ©ç”¨æ•ˆç‡ | æ›´ä¼˜çš„ä»»åŠ¡ç›¸å…³ä¿çœŸåº¦ | æ˜“å¿½ç•¥éæ˜¾è‘—ä½†è¯­ä¹‰é‡è¦çš„å¯¹è±¡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- ä½¿ç”¨ **COCO validation set** çš„ä¸€ä¸ªå­é›†ï¼Œå…± **200å¼ å›¾åƒ**ã€‚
- æ‰€æœ‰å›¾åƒç»Ÿä¸€è°ƒæ•´ä¸º **320Ã—480 åˆ†è¾¨ç‡**ã€‚
- æ„é€ ä¸¤ç±»ç”¨æˆ·æŸ¥è¯¢ï¼š
  1. å•ä¸ªæ ‡æ³¨å¯¹è±¡ç±»åˆ«ï¼ˆå¦‚ "cat"ï¼‰
  2. åŒå¯¹è±¡ç»„åˆæŸ¥è¯¢ï¼ˆå¦‚ "cat and keyboard"ï¼‰
- æä¾›å¯¹åº”çš„çœŸå®åˆ†å‰²æ©ç ï¼ˆground truth maskï¼‰ç”¨äºè¯„ä¼°è¯­ä¹‰ä¸€è‡´æ€§ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **Patchåˆ’åˆ†**ï¼šå›¾åƒåˆ‡åˆ†ä¸º 8Ã—8 çš„éé‡å å— â†’ å…± 2400 ä¸ª patchã€‚
- **åˆ†è¾¨ç‡å±‚çº§ï¼ˆL=5ï¼‰**ï¼š
  - L=0: ä¸ä¼ è¾“ï¼ˆ0å­—èŠ‚ï¼‰
  - L=12, 24, 48: å‹ç¼©ç¼–ç 
  - L=192: åŸå§‹patchæ— æŸä¼ è¾“ï¼ˆ3Ã—8Ã—8=192å­—èŠ‚ï¼‰
- **æ€»å¸¦å®½èŒƒå›´**ï¼š0 ~ 2400Ã—192 â‰ˆ 460,800 å­—èŠ‚
- **è¯­ä¹‰æå–æ¨¡å—**ï¼šåŸºäº **MAFT+ [8]** æ¡†æ¶æ”¹è¿›ï¼Œä½¿ç”¨ **ConvNeXt-Large** ç‰ˆæœ¬çš„ OpenCLIPã€‚
- **Embeddingç»´åº¦**ï¼šd = 1024
- **Mask Proposalæ•°é‡**ï¼šN = 100ï¼ˆclass-agnosticï¼‰

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
é‡‡ç”¨ä¸‰ç§äº’è¡¥æŒ‡æ ‡è¡¡é‡é‡å»ºå›¾åƒæ˜¯å¦ä¿ç•™äº†ä¸ç”¨æˆ·æŸ¥è¯¢ç›¸å…³çš„è¯­ä¹‰ä¿¡æ¯ï¼š

1. **Masked MSE**  
   åœ¨ ground truth åˆ†å‰²åŒºåŸŸå†…è®¡ç®—åŸå§‹å›¾åƒä¸é‡å»ºå›¾åƒä¹‹é—´çš„å‡æ–¹è¯¯å·®ï¼Œåæ˜ å…³é”®åŒºåŸŸçš„ä¿çœŸåº¦ã€‚

2. **L1 Distance of Informativeness Scores (Sinf)**  
   æ¯”è¾ƒåŸå§‹å›¾åƒå’Œé‡å»ºå›¾åƒåˆ†åˆ«ä¸åŒä¸€æ–‡æœ¬æŸ¥è¯¢ç”Ÿæˆçš„ `Sinf` åœ°å›¾ä¹‹é—´çš„ L1 è·ç¦»ï¼Œè¡¡é‡è¯­ä¹‰ç»“æ„çš„ä¸€è‡´æ€§ã€‚

3. **CLIP Relevancy Score**  
   ä½¿ç”¨ CLIP-V å’Œ CLIP-T åˆ†åˆ«ç¼–ç å›¾åƒå’Œæ–‡æœ¬ï¼Œè®¡ç®—åµŒå…¥å‘é‡çš„ç‚¹ç§¯å¾—åˆ†ï¼Œè¯„ä¼°å›¾æ–‡è¯­ä¹‰å¯¹é½ç¨‹åº¦ã€‚

### ğŸ” åŸºçº¿æ–¹æ³•
- **ViT-SC [6]**ï¼šåŸºäºVision Transformerçš„è‡ªæ³¨æ„åŠ›è¯­ä¹‰é€šä¿¡ç³»ç»Ÿï¼Œä»…ä½¿ç”¨å›¾åƒè¾“å…¥ï¼Œä¸æ¥å—æ–‡æœ¬æŸ¥è¯¢ã€‚
- å¯¹æ¯”æ¡ä»¶ï¼šå…±äº«ç›¸åŒçš„ encoder-decoder ç»“æ„ä¸å¤šåˆ†è¾¨ç‡æ§åˆ¶ç®—æ³•ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½è¡¨ç°ï¼ˆè§ Fig. 4â€“6ï¼‰

#### ï¼ˆ1ï¼‰Masked MSEï¼ˆè¶Šä½è¶Šå¥½ï¼‰
- åœ¨æ‰€æœ‰å¸¦å®½æ°´å¹³ä¸‹ï¼Œ**MMSC å‡æ˜¾è‘—ä½äº ViT-SC**ã€‚
- ä¾‹å¦‚ï¼Œåœ¨çº¦ 200,000 Bytes æ—¶ï¼ŒMMSC çš„ masked MSE çº¦ä¸º **0.015**ï¼Œè€Œ ViT-SC æ¥è¿‘ **0.03**ã€‚
- è¡¨æ˜ MMSC æ›´å¥½åœ°ä¿ç•™äº†æŸ¥è¯¢ç›¸å…³åŒºåŸŸçš„ç»†èŠ‚ã€‚

> âœ… **ç»“è®º**ï¼šå¼•å…¥æ–‡æœ¬å¼•å¯¼èƒ½æœ‰æ•ˆæå‡å…³é”®åŒºåŸŸçš„é‡å»ºè´¨é‡ã€‚

#### ï¼ˆ2ï¼‰L1 Distance of Sinf Mapsï¼ˆè¶Šå°è¶Šå¥½ï¼‰
- MMSC çš„ `Sinf` å·®å¼‚å§‹ç»ˆå°äº ViT-SCï¼Œå°¤å…¶åœ¨ä¸­ä½å¸¦å®½åŒºé—´ä¼˜åŠ¿æ˜æ˜¾ã€‚
- æœ€å¤§å·®è·å‡ºç°åœ¨ ~100K Bytes å¤„ï¼ŒMMSC æ¯” ViT-SC ä½çº¦ **40%**ã€‚
- è¯´æ˜ MMSC æ›´å¥½åœ°ç»´æŒäº†åŸå§‹å›¾åƒçš„è¯­ä¹‰é‡è¦æ€§åˆ†å¸ƒã€‚

> âœ… **ç»“è®º**ï¼šè·¨æ¨¡æ€æ³¨æ„åŠ›ä½¿è¯­ä¹‰ç»“æ„åœ¨å‹ç¼©åä»ä¿æŒç¨³å®šã€‚

#### ï¼ˆ3ï¼‰CLIP Relevancy Scoreï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰
- MMSC åœ¨ä¸­ç­‰å¸¦å®½èŒƒå›´å†…ï¼ˆ~100Kâ€“300K Bytesï¼‰å–å¾—æœ€é«˜åˆ†ï¼ˆå³°å€¼è¾¾ **0.198**ï¼‰ï¼Œä¼˜äº ViT-SCï¼ˆæœ€é«˜çº¦ **0.185**ï¼‰ã€‚
- é«˜å¸¦å®½æ—¶ MMSC å¾—åˆ†ç•¥æœ‰ä¸‹é™ï¼Œæ¨æµ‹å› ä¼ è¾“è¿‡å¤šæ— å…³åŒºåŸŸç¨€é‡Šäº†è¯­ä¹‰ç„¦ç‚¹ã€‚

> âœ… **ç»“è®º**ï¼šMMSC å®ç°æ›´å¼ºçš„å›¾æ–‡è¯­ä¹‰å¯¹é½ï¼Œç‰¹åˆ«æ˜¯åœ¨èµ„æºå—é™æ¡ä»¶ä¸‹æ›´å…·ä¼˜åŠ¿ã€‚

### ğŸ” å®šæ€§åˆ†æï¼ˆFig. 3 ç¤ºä¾‹ï¼‰
- æŸ¥è¯¢ï¼šâ€œCat and Keyboardâ€
- **MMSC** æˆåŠŸé‡å»ºçŒ«å’Œé”®ç›˜ä¸¤ä¸ªå¯¹è±¡ï¼Œä¸”ä¸¤è€…å‡æ¸…æ™°å¯è§ï¼›
- **ViT-SC** ä¸»è¦å…³æ³¨çŒ«ï¼ˆæœ€æ˜¾è‘—å¯¹è±¡ï¼‰ï¼Œé”®ç›˜å‡ ä¹æœªè¢«æ¢å¤ï¼›
- è¿›ä¸€æ­¥éªŒè¯äº†**çº¯è§†è§‰æ³¨æ„åŠ›æ˜“å¿½ç•¥æ¬¡è¦ä½†è¯­ä¹‰é‡è¦çš„ç›®æ ‡**ï¼Œè€Œå¤šæ¨¡æ€å¼•å¯¼å¯å…‹æœæ­¤ç¼ºé™·ã€‚

> âŒ **æ¶ˆèå®éªŒç¼ºå¤±è¯´æ˜**ï¼šæ–‡ä¸­æœªæä¾›æ˜ç¡®çš„ ablation studyï¼ˆå¦‚ç§»é™¤CDTã€æ›¿æ¢CLIPç­‰ï¼‰ï¼Œä½†å¼ºè°ƒäº†è®¾è®¡é€‰æ‹©çš„åˆç†æ€§ï¼ˆå¦‚è½¯è¯„åˆ† vs ç¡¬æ©ç ã€æ¡ä»¶åŒ–æ–‡æœ¬åµŒå…¥ç­‰ï¼‰ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **æ–‡æœ¬æŸ¥è¯¢å¯æœ‰æ•ˆå¼•å¯¼è¯­ä¹‰é€šä¿¡**  
   å¼•å…¥è‡ªç„¶è¯­è¨€æŒ‡ä»¤æ˜¾è‘—æå‡äº†ç³»ç»Ÿå¯¹ç”¨æˆ·æ„å›¾çš„ç†è§£èƒ½åŠ›ï¼Œä½¿å¾—ä¼ è¾“å†…å®¹æ›´åŠ â€œç›®æ ‡å¯¼å‘â€ã€‚

2. **è·¨æ¨¡æ€æ³¨æ„åŠ›ä¼˜äºè‡ªæ³¨æ„åŠ›**  
   åœ¨å¤æ‚åœºæ™¯ä¸­ï¼Œä»…é è§†è§‰è‡ªæ³¨æ„åŠ›æ— æ³•å¯é æ•æ‰ä»»åŠ¡ç›¸å…³åŒºåŸŸï¼›ç»“åˆè¯­è¨€å…ˆéªŒçš„ cross-modal attention èƒ½æ›´ç²¾å‡†å®šä½è¯­ä¹‰é‡è¦å†…å®¹ã€‚

3. **è½¯ç›¸å…³æ€§è¯„åˆ†æ”¯æŒçµæ´»ç¼–ç å†³ç­–**  
   ä½¿ç”¨ continuous relevance scores è€Œé binary masksï¼Œå…è®¸ç²¾ç»†åŒ–æ§åˆ¶å„patchçš„ç¼–ç è´¨é‡ï¼Œæ›´é€‚åˆå¸¦å®½å—é™ç¯å¢ƒä¸‹çš„èµ„æºåˆ†é…ã€‚

4. **æ— éœ€é‡è®­ç»ƒå³å¯æ”¯æŒå¤šæ ·åŒ–ä»»åŠ¡**  
   ç³»ç»Ÿå¯åœ¨æ¨ç†æ—¶åŠ¨æ€å“åº”ä»»æ„æ–‡æœ¬å‘½ä»¤ï¼Œé€‚ç”¨äºè¿œç¨‹ç›‘æ§ã€ARå¯¼èˆªç­‰éœ€è¦å¿«é€Ÿä»»åŠ¡åˆ‡æ¢çš„åº”ç”¨åœºæ™¯ã€‚

### âš ï¸ å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡é¢„è®­ç»ƒæ¨¡å‹**ï¼šæ€§èƒ½é«˜åº¦ä¾èµ– CLIP ç­‰å¤§è§„æ¨¡è§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œéƒ¨ç½²æˆæœ¬è¾ƒé«˜ï¼›
- **æœªè€ƒè™‘å»¶è¿Ÿä¸å®æ—¶æ€§**ï¼šå½“å‰æ¡†æ¶ä¾§é‡å‹ç¼©æ•ˆç‡ï¼Œå°šæœªè®¨è®ºç«¯åˆ°ç«¯ä¼ è¾“å»¶è¿Ÿæˆ–è§†é¢‘æµæ‰©å±•ï¼›
- **ç¼ºä¹çœŸå®ä¿¡é“å™ªå£°å»ºæ¨¡**ï¼šå®éªŒå‡è®¾ç†æƒ³å¸¦å®½é™åˆ¶ï¼ŒæœªåŠ å…¥ AWGN æˆ–è¡°è½ä¿¡é“å½±å“ï¼›
- **ç¼ºå°‘æ¶ˆèç ”ç©¶**ï¼šæœªèƒ½é‡åŒ–å„ç»„ä»¶ï¼ˆå¦‚ CDTã€Mask Proposal æ•°é‡ï¼‰çš„å…·ä½“è´¡çŒ®ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **video semantic communication**ï¼Œæ”¯æŒæ—¶åºè¯­ä¹‰ä¸€è‡´æ€§å»ºæ¨¡ï¼›
- æ¢ç´¢ **joint source-channel coding with feedback**ï¼Œå®ç°è‡ªé€‚åº”ç ç‡è°ƒèŠ‚ï¼›
- å¼•å…¥ **lightweight multimodal backbones**ï¼Œé™ä½è®¡ç®—å¼€é”€ä»¥é€‚é…è¾¹ç¼˜è®¾å¤‡ï¼›
- ç ”ç©¶ **interactive querying** æœºåˆ¶ï¼Œæ”¯æŒç”¨æˆ·åœ¨æ¥æ”¶ç«¯åé¦ˆå¹¶è°ƒæ•´é‡å»ºé‡ç‚¹ã€‚

---

## æ€»ç»“
è¯¥è®ºæ–‡æå‡ºçš„ **Multi-Modal Semantic Communication (MMSC)** æ¡†æ¶é¦–æ¬¡å°†**æ–‡æœ¬æŸ¥è¯¢ä¸è·¨æ¨¡æ€æ³¨æ„åŠ›**å¼•å…¥è¯­ä¹‰é€šä¿¡é¢†åŸŸï¼Œå®ç°äº†çœŸæ­£æ„ä¹‰ä¸Šçš„â€œæŒ‰éœ€ä¼ è¾“â€ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§æŒ‡æ ‡ä¸Šå…¨é¢è¶…è¶Šä»…ä¾èµ–è§†è§‰è‡ªæ³¨æ„åŠ›çš„åŸºçº¿ï¼ˆViT-SCï¼‰ï¼Œå°¤å…¶åœ¨å¤æ‚åœºæ™¯å’Œå¸¦å®½å—é™æ¡ä»¶ä¸‹å±•ç°å‡ºå“è¶Šçš„è¯­ä¹‰ä¿çœŸèƒ½åŠ›å’Œä»»åŠ¡é€‚åº”æ€§ï¼Œä¸ºä¸‹ä¸€ä»£æ™ºèƒ½é€šä¿¡ç³»ç»Ÿæä¾›äº†é‡è¦èŒƒå¼ã€‚

</details>

---

### 15. [ValuePilot: A Two-Phase Framework for Value-Driven Decision-Making](https://arxiv.org/abs/2512.13716)

**Authors**: Yitong Luo, Ziang Chen, Hou Hei Lam, Jiayu zhan, Junqi Wang, Zhenliang Zhang, Xue Feng  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.13716v1  

#### Abstract
Personalized decision-making is essential for human-AI interaction, enabling AI agents to act in alignment with individual users' value preferences. As AI systems expand into real-world applications, adapting to personalized values beyond task completion or collective alignment has become a critical...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šValuePilot: A Two-Phase Framework for Value-Driven Decision-Making**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
ä¼ ç»ŸAIå†³ç­–ç³»ç»Ÿå¤šåŸºäº**ä»»åŠ¡å¯¼å‘èŒƒå¼**ï¼ˆtask-oriented paradigmsï¼‰ï¼Œä¾èµ–å¤–éƒ¨å¥–åŠ±ä¿¡å·è¿›è¡Œä¼˜åŒ–ï¼Œç¼ºä¹å¯¹ä¸ªä½“ç”¨æˆ·å†…åœ¨**ä»·å€¼åå¥½**ï¼ˆvalue preferencesï¼‰çš„ç†è§£ä¸å»ºæ¨¡ã€‚è¿™å¯¼è‡´AIè¡Œä¸ºéš¾ä»¥é€‚åº”ä¸ªæ€§åŒ–éœ€æ±‚ï¼Œå°¤å…¶åœ¨é¢å¯¹æœªè§è¿‡çš„æ–°åœºæ™¯æ—¶æ³›åŒ–èƒ½åŠ›å·®ã€‚

æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•å¦‚**Reinforcement Learning from Human Feedback (RLHF)** å’Œ **Direct Preference Optimization (DPO)** è™½èƒ½å¯¹é½äººç±»ä»·å€¼è§‚ï¼Œä½†é€šå¸¸ä¾èµ–ç¾¤ä½“åé¦ˆï¼Œå¿½è§†ä¸ªä½“å·®å¼‚ï¼›è€Œè§„åˆ’æ¨¡å‹å¦‚ **AutoPlan** æˆ– **ReAct** åˆ™å…³æ³¨æ•ˆç‡è€Œéå†…åœ¨ä»·å€¼é©±åŠ¨ã€‚

å› æ­¤ï¼Œæœ¬æ–‡æ—¨åœ¨è§£å†³ä»¥ä¸‹ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼š
- å¦‚ä½•è¯†åˆ«ç‰¹å®šæƒ…å¢ƒä¸‹ç›¸å…³çš„**ä»·å€¼ç»´åº¦**ï¼ˆvalue dimensionsï¼‰
- å¦‚ä½•é€‰æ‹©ä¸ç”¨æˆ·ä¸ªæ€§åŒ–ä»·å€¼åå¥½ä¸€è‡´çš„è¡ŒåŠ¨ï¼Œå¹¶å¤„ç†å¤šä¸ªä»·å€¼ä¹‹é—´çš„æƒè¡¡

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
ä½œè€…æå‡º **ValuePilot**ï¼Œä¸€ä¸ªä¸¤é˜¶æ®µæ¡†æ¶ï¼Œç”¨äºå®ç°**ä»¥ä»·å€¼ä¸ºå¯¼å‘çš„ä¸ªæ€§åŒ–å†³ç­–**ï¼ˆvalue-driven personalized decision-makingï¼‰ã€‚è¯¥æ¡†æ¶ç”±ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶æ„æˆï¼š

#### **(1) Dataset Generation Toolkit (DGT)**
- åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ„å»ºäº†ä¸€ä¸ªè‡ªåŠ¨åŒ–ç”Ÿæˆæµç¨‹ï¼Œç”¨äºåˆ›å»ºå¸¦æœ‰**ç»†ç²’åº¦ä»·å€¼æ ‡æ³¨**çš„å†³ç­–åœºæ™¯æ•°æ®é›†ã€‚
- åŒ…å«ä¸‰ä¸ªé˜¶æ®µï¼š
  - **Prompt Construction and Scenario Generation**ï¼šç»™å®šä¸€ç»„ç›®æ ‡ä»·å€¼ç»´åº¦ï¼ˆå¦‚ curiosity, safetyï¼‰ï¼Œé€šè¿‡æ¨¡å—åŒ–æç¤ºå¼•å¯¼ GPT-4 ç”Ÿæˆå¤šæ™ºèƒ½ä½“å®¶åº­åœºæ™¯ã€‚
  - **Action Generation and Value Scoring**ï¼šä¸ºæ¯ä¸ªåœºæ™¯ç”Ÿæˆå€™é€‰åŠ¨ä½œï¼Œå¹¶ç”¨ [-1, +1] è¿ç»­åˆ†æ•°æ ‡æ³¨å…¶åœ¨å„ä»·å€¼ç»´åº¦ä¸Šçš„å¯¹é½ç¨‹åº¦ï¼ˆæ¥è¿‘ +1 è¡¨ç¤ºå¼ºçƒˆæ”¯æŒï¼Œ-1 è¡¨ç¤ºè¿èƒŒï¼‰ã€‚
  - **Automatic Filtering via Re-evaluation**ï¼šä½¿ç”¨å¦ä¸€è½® LLM æ¨ç†éªŒè¯ç”Ÿæˆæ ·æœ¬çš„ä»·å€¼ä¸€è‡´æ€§ï¼Œå‰”é™¤ä¸åŒ¹é…é¡¹ã€‚

#### **(2) Decision-Making Module (DMM)**
- å°†å†³ç­–å»ºæ¨¡ä¸º**å¤šå‡†åˆ™å†³ç­–é—®é¢˜**ï¼ˆMulti-Criteria Decision-Making, MCDMï¼‰ï¼Œç»“åˆå®¢è§‚ä»·å€¼è¯„ä¼°ä¸ä¸»è§‚ç”¨æˆ·åå¥½ã€‚
- åŒ…æ‹¬ä¸¤ä¸ªå­æ¨¡å—ï¼š
  - **Value Assessment Network**ï¼šé‡‡ç”¨ T5 ç¼–ç å™¨å°†åœºæ™¯å’ŒåŠ¨ä½œæ–‡æœ¬ç¼–ç ï¼Œè¾“å‡ºæ¯ä¸ªåŠ¨ä½œåœ¨å„ä¸ªä»·å€¼ç»´åº¦ä¸Šçš„å®¢è§‚å¾—åˆ†ã€‚
  - **Action Selection Module**ï¼š
    - å¼•å…¥**æƒ…å¢ƒåŒ–è¯„åˆ†æœºåˆ¶**ï¼ˆContextualized Scoringï¼‰ï¼Œèåˆç”¨æˆ·çš„åå¥½å‘é‡ $ \mathbf{p} $ ä¸æ¨¡å‹é¢„æµ‹çš„åŠ¨ä½œä»·å€¼å¾—åˆ†ã€‚
    - ä½¿ç”¨ **PROMETHEE æ–¹æ³•** è¿›è¡Œæ’åºï¼Œè®¡ç®—å‡€ä¼˜åŠ¿æµï¼ˆnet outranking flowï¼‰ï¼Œç”Ÿæˆå¯è§£é‡Šçš„è¡ŒåŠ¨ä¼˜å…ˆçº§åˆ—è¡¨ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ValuePilot çš„ä¼˜åŠ¿ |
|------|------------------|
| **ä¸ªæ€§åŒ–å»ºæ¨¡** | æ˜¾å¼å»ºæ¨¡ç”¨æˆ·çš„ä»·å€¼åå¥½å‘é‡ï¼Œæ”¯æŒä¸ªä½“åŒ–å†³ç­– |
| **å¯è§£é‡Šæ€§** | è¾“å‡ºåŸºäºä»·å€¼ç»´åº¦çš„è¯„åˆ†ä¸æ’åºé€»è¾‘ï¼Œä¼˜äºé»‘ç®±å¼ LLM å†³ç­– |
| **æ³›åŒ–èƒ½åŠ›** | åœ¨æœªè§åœºæ™¯ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¯´æ˜å…¶å­¦ä¹ åˆ°äº†ç¨³å®šçš„ä»·å€¼ä¿¡å·è€Œéè¡¨é¢æ¨¡å¼ |
| **ç³»ç»Ÿæ€§æ•°æ®æ„å»º** | DGT æä¾›é«˜è´¨é‡ã€ç»“æ„åŒ–çš„ä»·å€¼æ ‡æ³¨æ•°æ®é›†ï¼Œå¡«è¡¥äº†è¯¥é¢†åŸŸèµ„æºç©ºç™½ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **è‡ªå»ºæ•°æ®é›†**ï¼šé€šè¿‡ DGT æ„å»ºï¼Œå…±åŒ…å«ï¼š
  - **11,938 ä¸ªåœºæ™¯**
  - **100,255 ä¸ªå€™é€‰åŠ¨ä½œ**
- æ•°æ®é›†è¦†ç›–å…­ä¸ªæ ¸å¿ƒä»·å€¼ç»´åº¦ï¼š
  - `Curiosity`, `Energy`, `Security`ï¼ˆåŸæ–‡ä¸­ä¸º Safetyï¼‰, `Happiness`, `Intimacy`, `Fairness`
- åœºæ™¯è®¾è®¡ä¸º**å®¶åº­ç¯å¢ƒä¸­çš„æ—¥å¸¸äº’åŠ¨**ï¼Œå¼ºè°ƒå¤šæ™ºèƒ½ä½“åä½œä¸å†²çªã€‚
- æ•°æ®ç»è¿‡è‡ªåŠ¨è¿‡æ»¤ + å››äººå›¢é˜Ÿäººå·¥å®¡æ ¸ï¼Œç¡®ä¿çœŸå®æ€§ä¸ä»·å€¼ä¸€è‡´æ€§ã€‚

> æ³¨ï¼šæ–‡ä¸­æŒ‡å‡ºå½“å‰å…¬å¼€æ•°æ®é›†ï¼ˆå¦‚ ALFWorld, InterCode, WVS, Moral Storiesï¼‰å‡æ— æ³•æ»¡è¶³ä»·å€¼é©±åŠ¨å†³ç­–è®­ç»ƒéœ€æ±‚ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **å®éªŒä¸€ï¼šValue Recognitionï¼ˆä»·å€¼è¯†åˆ«èƒ½åŠ›ï¼‰**
- **ä»»åŠ¡**ï¼šåˆ¤æ–­æ¨¡å‹èƒ½å¦å‡†ç¡®è¯†åˆ«åœºæ™¯ä¸­åŠ¨ä½œå¯¹åº”çš„ä»·å€¼å¾—åˆ†ã€‚
- **åŸºçº¿æ¨¡å‹**ï¼š
  - `Llama-3.5-70b`, `Llama-3.5-405b`, `Mixtral-8x22b`, `Gemini-1.5-flash`
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Average Accuracy (AvgAcc)** @ é˜ˆå€¼ $ t=0.2 $ å’Œ $ t=0.05 $
  - **Mean Absolute Error (MAE)**

#### **å®éªŒäºŒï¼šValue-driven Decision-makingï¼ˆå†³ç­–å¯¹é½èƒ½åŠ›ï¼‰**
- **ä»»åŠ¡**ï¼šé¢„æµ‹äººç±»å—è¯•è€…åœ¨ç»™å®šä»·å€¼åå¥½çš„æƒ…å†µä¸‹ä¼šå¦‚ä½•æ’åºå€™é€‰åŠ¨ä½œã€‚
- **å‚ä¸äººæ•°**ï¼š40 åäººç±»è¢«è¯•
- **æµç¨‹**ï¼š
  1. å—è¯•è€…å…ˆå¡«å†™å…­ç»´ä»·å€¼é‡è¦æ€§è¯„åˆ†ï¼ˆ0~1ï¼‰
  2. å®Œæˆ 11 ä¸ªæ­£å¼å†³ç­–é¢˜ç›®çš„åŠ¨ä½œæ’åº
  3. æ”¶é›†æ¯ä¸ªäººçš„â€œçœŸå®â€åå¥½å‘é‡ + åŠ¨ä½œæ’åä½œä¸º ground truth
- **åŸºçº¿æ¨¡å‹**ï¼š
  - `Llama-3.1-70b`, `DeepSeek-R1`, `Claude-Sonnet-4`, `Gemini-2.5-flash`, `Kimi-K2`, `GPT-4o-mini`, `GPT-5`
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Order-Sensitive Similarity (OS-Sim)**ï¼šåŸºäºå‰ç¼€äº¤é›†çš„åºåˆ—ç›¸ä¼¼åº¦ï¼Œæ›´é‡è§†é«˜ä¼˜å…ˆçº§åŠ¨ä½œçš„ä¸€è‡´æ€§ã€‚
  - **First-Action Accuracy (First-Acc)**ï¼šæ¨¡å‹æ’åç¬¬ä¸€çš„åŠ¨ä½œæ˜¯å¦ä¸äººç±»é€‰æ‹©ä¸€è‡´ã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… **ä»·å€¼è¯†åˆ«ä»»åŠ¡ç»“æœï¼ˆTable 1ï¼‰**
| Model | AvgAcc (%) @ t=0.2 | AvgAcc (%) @ t=0.05 | MAE |
|-------|--------------------|---------------------|-----|
| Llama-3.5-70b | 40.90 | 17.74 | 0.30 |
| Mixtral-8x22b | 42.71 | 18.39 | 0.29 |
| Gemini-1.5-flash | 51.61 | 25.64 | 0.24 |
| **Value Assessment Network (Ours)** | **66.70** | **40.00** | **0.19** |

> â¤ ç›¸æ¯”æœ€å¼ºåŸºçº¿ï¼ˆGeminiï¼‰ï¼Œæå‡ **15.09 pp**ï¼ˆ@t=0.2ï¼‰ï¼ŒMAE ä¸‹é™ **36.7%**

---

#### âœ… **å†³ç­–å¯¹é½ä»»åŠ¡ç»“æœï¼ˆFigure 2ï¼‰**
| Model | OS-Sim (%) | First-Acc (%) |
|-------|------------|---------------|
| GPT-5 | 69.23 Â± 0.71 | 38.01 Â± 3.81 |
| **DMM (Ours)** | **73.16 Â± 0.43** | **46.14 Â± 4.09** |

> â¤ åœ¨ **OS-Sim** ä¸Šæå‡ **+3.93 pp**ï¼Œåœ¨ **First-Acc** ä¸Šæå‡ **+8.13 pp**ï¼Œæ˜¾è‘—ä¼˜äºæ‰€æœ‰ä¸»æµ LLMã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Study, Table 2ï¼‰**

| æ¨¡å‹å˜ä½“ | OS-Sim (%) | First-Acc (%) |
|--------|-----------|--------------|
| Only Actionï¼ˆä»…åŠ¨ä½œï¼‰ | 60.23 | 32.27 |
| w/o Preferenceï¼ˆæ— åå¥½ï¼‰ | 61.07 | 31.82 |
| w/o Subjectiveï¼ˆæ— ä¸»è§‚è°ƒæ•´ï¼‰ | 68.93 | 43.45 |
| w/o Scenarioï¼ˆæ— è§†æƒ…å¢ƒï¼‰ | 69.99 | 43.64 |
| **DMM (Full)** | **73.16** | **46.14** |

> â¤ æ‰€æœ‰ç»„ä»¶å‡æœ‰è´¡çŒ®ï¼Œå°¤å…¶æ˜¯å¼•å…¥**ç”¨æˆ·åå¥½**å’Œ**æƒ…å¢ƒè°ƒèŠ‚**åæ€§èƒ½å¤§å¹…æå‡ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **ä»·å€¼é©±åŠ¨å†³ç­–æ˜¯å¯è¡Œä¸”æœ‰æ•ˆçš„è·¯å¾„**  
   æ˜¾å¼å»ºæ¨¡äººç±»åŸºæœ¬ä»·å€¼ç»´åº¦ï¼ˆå¦‚ Schwartzâ€™s theoryï¼‰å¹¶ç»“åˆä¸ªæ€§åŒ–åå¥½ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡AIåœ¨å¤æ‚æƒ…å¢ƒä¸‹çš„å†³ç­–è´¨é‡ã€‚

2. **ValuePilot å…·å¤‡å¼ºæ³›åŒ–èƒ½åŠ›**  
   åœ¨æœªè§åœºæ™¯ä¸Šä»èƒ½ä¼˜äºå¤§å‹ LLMï¼Œè¡¨æ˜å…¶å­¦åˆ°çš„æ˜¯ç¨³å®šçš„â€œä»·å€¼-è¡Œä¸ºâ€æ˜ å°„å…³ç³»ï¼Œè€Œéè®°å¿†è®­ç»ƒæ•°æ®ã€‚

3. **å¯è§£é‡Šæ€§ä¸å¯æ§æ€§å¼º**  
   é€šè¿‡ PROMETHEE æ–¹æ³•ç”Ÿæˆçš„æ’åºå…·æœ‰æ˜ç¡®çš„æ•°å­¦ä¾æ®ï¼Œä¾¿äºåˆ†æä¸ºä½•æŸä¸ªåŠ¨ä½œè¢«ä¼˜å…ˆæ¨èã€‚

4. **DGT æ˜¯é«˜è´¨é‡æ•°æ®ç”Ÿäº§çš„æœ‰æ•ˆå·¥å…·**  
   ç»“åˆ LLM è‡ªåŠ¨ç”Ÿæˆ + è‡ªåŠ¨/äººå·¥åŒé‡è¿‡æ»¤ï¼Œå¯è§„æ¨¡åŒ–ç”Ÿäº§å¸¦ä»·å€¼æ ‡æ³¨çš„å†³ç­–æ•°æ®ï¼Œæ¨åŠ¨è¯¥æ–¹å‘ç ”ç©¶ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§ï¼ˆF Limitationsï¼‰**
- å½“å‰ä»·å€¼è¡¨ç¤ºè¾ƒä¸ºç®€åŒ–ï¼Œæœªæ•æ‰äººç±»ä»·å€¼çš„**å±‚æ¬¡æ€§ã€åŠ¨æ€æ€§å’Œè¯­å¢ƒä¾èµ–æ€§**ã€‚
- ç”¨æˆ·åå¥½é‡‡é›†ä¾èµ–ç›´æ¥æ‰“åˆ†ï¼ˆdirect rating scalesï¼‰ï¼Œå¯èƒ½ä¸å¦‚å¿ƒç†æµ‹é‡å­¦æ–¹æ³•ç²¾ç¡®ã€‚
- æ¡†æ¶æœ¬èº«ä¾§é‡å·¥ç¨‹é›†æˆï¼Œæœªæ·±å…¥æ¢ç´¢æ›´å…ˆè¿›çš„ä»·å€¼å­¦ä¹ æˆ–åå¥½æ¨æ–­ç®—æ³•ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ‰©å±•æ›´å¤šä»·å€¼ç»´åº¦ï¼ˆå¦‚ responsibility, ambitionï¼‰ä»¥è¦†ç›–æ›´å¹¿æ³›çš„ç¤¾ä¼šè¡Œä¸ºã€‚
- æ¢ç´¢éæ˜¾å¼æ–¹å¼ï¼ˆå¦‚å¯¹è¯äº¤äº’ï¼‰è‡ªåŠ¨æ¨æ–­ç”¨æˆ·ä»·å€¼åå¥½ã€‚
- å°† ValuePilot åº”ç”¨äºçœŸå®ä¸–ç•Œåœºæ™¯ï¼Œå¦‚æ™ºèƒ½å®¶å±…åŠ©æ‰‹ã€æ•™è‚²æœºå™¨äººç­‰ã€‚
- ç ”ç©¶è·¨æ–‡åŒ–èƒŒæ™¯ä¸‹çš„ä»·å€¼å»ºæ¨¡å·®å¼‚ã€‚

---

> ğŸ’¡ **æ€»ä½“è¯„ä»·**ï¼š  
> ValuePilot æå‡ºäº†ä¸€æ¡é€šå¾€**å¯è§£é‡Šã€ä¸ªæ€§åŒ–ã€ç¤¾ä¼šå¯¹é½ AI** çš„æ¸…æ™°å·¥ç¨‹è·¯å¾„ã€‚å®ƒä¸ä»…å±•ç¤ºäº†ä»·å€¼é©±åŠ¨å†³ç­–çš„æœ‰æ•ˆæ€§ï¼Œè¿˜æä¾›äº†å¯å¤ç°çš„æ•°æ®ç”Ÿæˆä¸å»ºæ¨¡èŒƒå¼ï¼Œä¸ºåç»­ç ”ç©¶å¥ å®šäº†åšå®åŸºç¡€ã€‚

</details>

---

### 16. [Distillation-Guided Structural Transfer for Continual Learning Beyond Sparse Distributed Memory](https://arxiv.org/abs/2512.15267)

**Authors**: Huiyan Xue, Xuming Ran, Yaxin Li, Qi Xu, Enhui Li, Yi Xu, Qiang Zhang  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.15267v1  

#### Abstract
Sparse neural systems are gaining traction for efficient continual learning due to their modularity and low interference. Architectures such as Sparse Distributed Memory Multi-Layer Perceptrons (SDMLP) construct task-specific subnetworks via Top-K activation and have shown resilience against catastr...

---

### 17. [AI-Powered Annotation Pipelines for Stabilizing Large Language Models: A Human-AI Synergy Approach](https://arxiv.org/abs/2512.13714)

**Authors**: Gangesh Pathak, Prasanna Kumar  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.13714v1  

#### Abstract
LLM implementations are failing in highly regulated industries owing to instability issues, inconsistent reasoning, hallucinations and performance variability, especially in workflows. These reliability issues restrict safe use of LLM in areas that need the precision of facts and consistent behavior...

---

### 18. [PortAgent: LLM-driven Vehicle Dispatching Agent for Port Terminals](https://arxiv.org/abs/2512.14417)

**Authors**: Jia Hu, Junqi Li, Weimeng Lin, Peng Jia, Yuxiong Ji, Jintao Lai  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.14417v1  

#### Abstract
Vehicle Dispatching Systems (VDSs) are critical to the operational efficiency of Automated Container Terminals (ACTs). However, their widespread commercialization is hindered due to their low transferability across diverse terminals. This transferability challenge stems from three limitations: high ...

---

### 19. [EMFusion: Conditional Diffusion Framework for Trustworthy Frequency Selective EMF Forecasting in Wireless Networks](https://arxiv.org/abs/2512.15067)

**Authors**: Zijiang Yan, Yixiang Huang, Jianhua Pei, Hina Tabassum, Luca Chiaraviglio  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.15067v1  

#### Abstract
The rapid growth in wireless infrastructure has increased the need to accurately estimate and forecast electromagnetic field (EMF) levels to ensure ongoing compliance, assess potential health impacts, and support efficient network planning. While existing studies rely on univariate forecasting of wi...

---

### 20. [SigMA: Path Signatures and Multi-head Attention for Learning Parameters in fBm-driven SDEs](https://arxiv.org/abs/2512.15088)

**Authors**: Xianglin Wu, Chiheb Ben Hammouda, Cornelis W. Oosterlee  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.15088v1  

#### Abstract
Stochastic differential equations (SDEs) driven by fractional Brownian motion (fBm) are increasingly used to model systems with rough dynamics and long-range dependence, such as those arising in quantitative finance and reliability engineering. However, these processes are non-Markovian and lack a s...

---

### 21. [RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees](https://arxiv.org/abs/2512.14069)

**Authors**: Junjie Ma, Jinlong Li  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.14069v1  

#### Abstract
Inference with modern Large Language Models (LLMs) is expensive and slow, and speculative sampling has emerged as an effective solution to this problem, however, the number of the calls to the draft model for generating candidate tokens in speculative sampling is a preset hyperparameter, lacking fle...

---

### 22. [How a Bit Becomes a Story: Semantic Steering via Differentiable Fault Injection](https://arxiv.org/abs/2512.14715)

**Authors**: Zafaryab Haider, Md Hafizur Rahman, Shane Moeykens, Vijay Devabhaktuni, Prabuddha Chakraborty  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.14715v1  

#### Abstract
Hard-to-detect hardware bit flips, from either malicious circuitry or bugs, have already been shown to make transformers vulnerable in non-generative tasks. This work, for the first time, investigates how low-level, bitwise perturbations (fault injection) to the weights of a large language model (LL...

---

### 23. [Deep Learning and Elicitability for McKean-Vlasov FBSDEs With Common Noise](https://arxiv.org/abs/2512.14967)

**Authors**: Felipe J. P. Antunes, Yuri F. Saporito, Sebastian Jaimungal  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.14967v1  

#### Abstract
We present a novel numerical method for solving McKean-Vlasov forward-backward stochastic differential equations (MV-FBSDEs) with common noise, combining Picard iterations, elicitability and deep learning. The key innovation involves elicitability to derive a path-wise loss function, enabling effici...

---

### 24. [A Regime-Aware Fusion Framework for Time Series Classification](https://arxiv.org/abs/2512.15378)

**Authors**: Honey Singh Chauhan, Zahraa S. Abdallah  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.15378v1  

#### Abstract
Kernel-based methods such as Rocket are among the most effective default approaches for univariate time series classification (TSC), yet they do not perform equally well across all datasets. We revisit the long-standing intuition that different representations capture complementary structure and sho...

---

### 25. [Blind Radio Mapping via Spatially Regularized Bayesian Trajectory Inference](https://arxiv.org/abs/2512.13701)

**Authors**: Zheng Xing, Junting Chen  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.13701v1  

#### Abstract
Radio maps enable intelligent wireless applications by capturing the spatial distribution of channel characteristics. However, conventional construction methods demand extensive location-labeled data, which are costly and impractical in many real-world scenarios. This paper presents a blind radio ma...

---

### 26. [Compressed Causal Reasoning: Quantization and GraphRAG Effects on Interventional and Counterfactual Accuracy](https://arxiv.org/abs/2512.13725)

**Authors**: Steve Nwaiwu, Nipat Jongsawat, Anucha Tungkasthan  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.13725v1  

#### Abstract
Causal reasoning in Large Language Models spanning association, intervention, and counterfactual inference is essential for reliable decision making in high stakes settings. As deployment shifts toward edge and resource constrained environments, quantized models such as INT8 and NF4 are becoming sta...

---

### 27. [OpenDataArena: A Fair and Open Arena for Benchmarking Post-Training Dataset Value](https://arxiv.org/abs/2512.14051)

**Authors**: Mengzhang Cai, Xin Gao, Yu Li, Honglin Lin, Zheng Liu, Zhuoshi Pan, Qizhi Pei, Xiaoran Shang, Mengyuan Sun, Zinan Tang, Xiaoyang Wang, Zhanping Zhong, Yun Zhu, Dahua Lin, Conghui He, Lijun Wu  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.14051v1  

#### Abstract
The rapid evolution of Large Language Models (LLMs) is predicated on the quality and diversity of post-training datasets. However, a critical dichotomy persists: while models are rigorously benchmarked, the data fueling them remains a black box--characterized by opaque composition, uncertain provena...

---

### 28. [Grammar Search for Multi-Agent Systems](https://arxiv.org/abs/2512.14079)

**Authors**: Mayank Singh, Vikas Yadav, Shiva Krishna Reddy Malay, Shravan Nayak, Sai Rajeswar, Sathwik Tejaswi Madhusudhan, Eduardo Blanco  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.14079v1  

#### Abstract
Automatic search for Multi-Agent Systems has recently emerged as a key focus in agentic AI research. Several prior approaches have relied on LLM-based free-form search over the code space. In this work, we propose a more structured framework that explores the same space through a fixed set of simple...

---

### 29. [Adversarial versification in portuguese as a jailbreak operator in LLMs](https://arxiv.org/abs/2512.15353)

**Authors**: Joao Queiroz  
**Category**: cs.CL  
**Published**: 2025-12-18  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.15353v1  

#### Abstract
Recent evidence shows that the versification of prompts constitutes a highly effective adversarial mechanism against aligned LLMs. The study 'Adversarial poetry as a universal single-turn jailbreak mechanism in large language models' demonstrates that instructions routinely refused in prose become e...

---

### 30. [Is GPT-OSS All You Need? Benchmarking Large Language Models for Financial Intelligence and the Surprising Efficiency Paradox](https://arxiv.org/abs/2512.14717)

**Authors**: Ziqian Bi, Danyang Zhang, Junhao Song, Chiung-Yi Tseng  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.14717v1  

#### Abstract
The rapid adoption of large language models in financial services necessitates rigorous evaluation frameworks to assess their performance, efficiency, and practical applicability. This paper conducts a comprehensive evaluation of the GPT-OSS model family alongside contemporary LLMs across ten divers...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
