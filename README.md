# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-01-28 06:00:53 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [DART: Diffusion-Inspired Speculative Decoding for Fast LLM Inference](https://arxiv.org/abs/2601.19278)

**Authors**: Fuliang Liu, Xue Li, Ketai Zhao, Yinxi Gao, Ziyan Zhou, Zhonghui Zhang, Zhibin Wang, Wanchun Dou, Sheng Zhong, Chen Tian  
**Category**: cs.CL  
**Published**: 2026-01-28  
**Score**: 12.5  
**Type**: new  
**ArXiv ID**: 2601.19278v1  

#### Abstract
Speculative decoding is an effective and lossless approach for accelerating LLM inference. However, existing widely adopted model-based draft designs, such as EAGLE3, improve accuracy at the cost of multi-step autoregressive inference, resulting in high drafting latency and ultimately rendering the ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# DART: Diffusion-Inspired Speculative Decoding for Fast LLM Inference â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ç°æœ‰çš„ **Speculative Decoding** æ–¹æ³•åœ¨åŠ é€Ÿå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†æ—¶é¢ä¸´ä¸¤å¤§ç“¶é¢ˆï¼š
- **é«˜ drafting latency**ï¼šä¸»æµåŸºäºæ¨¡å‹çš„ draftersï¼ˆå¦‚ EAGLE3ï¼‰è™½ç„¶æé«˜äº†é¢„æµ‹å‡†ç¡®ç‡ï¼ˆTï¼‰ï¼Œä½†å…¶è‡ªå›å½’ï¼ˆautoregressiveï¼‰ç”Ÿæˆæ–¹å¼å¯¼è‡´ drafting é˜¶æ®µæœ¬èº«æˆä¸ºæ€§èƒ½ç“¶é¢ˆï¼Œå æ€»æ¨ç†æ—¶é—´çš„ 20%-40%ã€‚
- **æ•ˆç‡ä¸å‡†ç¡®æ€§æƒè¡¡å¤±è¡¡**ï¼šéè‡ªå›å½’æ–¹æ³•ï¼ˆå¦‚ Lookaheadã€N-gramï¼‰è™½å»¶è¿Ÿä½ï¼Œä½†æ¥å—é•¿åº¦ï¼ˆTï¼‰è¿‡å°ï¼›è€Œç›´æ¥é‡‡ç”¨ **diffusion-based LLMs (dLLMs)** ä½œä¸º drafter å­˜åœ¨æ¶æ„ä¸åŒ¹é…ï¼ˆåŒå‘ vs å› æœï¼‰ã€å‚æ•°é‡å¤§ã€tokenizer ä¸å…¼å®¹ç­‰é—®é¢˜ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šDART
æå‡º **DART**ï¼ˆDiffusion-Inspired Speculative Decodingï¼‰ï¼Œä¸€ç§å—æ‰©æ•£æ¨¡å‹å¯å‘ã€ä¸“ä¸º speculative decoding å®šåˆ¶çš„å¹¶è¡Œèµ·è‰æ¡†æ¶ï¼Œæ ¸å¿ƒæ€æƒ³å¦‚ä¸‹ï¼š

#### åˆ›æ–°ç‚¹ 1ï¼šè½»é‡çº§å¹¶è¡Œèµ·è‰æœºåˆ¶ï¼ˆLightweight Diffusion-Inspired Parallel Draftingï¼‰
- **çµæ„Ÿæ¥æº**ï¼šå€Ÿé‰´ dLLMs çš„â€œå¤šä½ç½®å¹¶è¡Œé¢„æµ‹â€èƒ½åŠ›ï¼Œä½†æ‘’å¼ƒå…¶è¿­ä»£å»å™ªå’ŒåŒå‘å»ºæ¨¡ã€‚
- **å®ç°æ–¹å¼**ï¼š
  - åœ¨å•æ¬¡å‰å‘ä¼ æ’­ä¸­ï¼Œåˆ©ç”¨ç›®æ ‡æ¨¡å‹çš„éšè—çŠ¶æ€ï¼ˆhidden statesï¼‰ï¼Œé€šè¿‡ä¸€ä¸ªè½»é‡åŒ–çš„å®šåˆ¶ **Transformer decoder layer** å¹¶è¡Œé¢„æµ‹å¤šä¸ªæœªæ¥ä½ç½®çš„ logitsã€‚
  - å¼•å…¥ **Shifted Logits Prediction**ï¼šæ¯ä¸ªä½ç½®è¾“å‡ºçš„ logit å¯¹åº”çš„æ˜¯â€œä¸‹ä¸€ä¸ª tokenâ€çš„é¢„æµ‹ï¼Œæ˜¾è‘—æå‡é¦–ä¸ª draft token çš„å‡†ç¡®ç‡ã€‚
- **ä¼˜åŠ¿**ï¼š
  - å½»åº•æ¶ˆé™¤ draft model ä¸­çš„è‡ªå›å½’ rolloutã€‚
  - drafting forward å»¶è¿Ÿä¸ draft length æ— å…³ï¼Œä»…éœ€ä¸€æ¬¡è½»é‡å‰å‘ã€‚

#### åˆ›æ–°ç‚¹ 2ï¼šåŸºäº N-gram çš„è¿ç»­æ€§æ„ŸçŸ¥æ ‘å‰ªæï¼ˆContinuity-Aware Tree Pruningï¼‰
- **æŒ‘æˆ˜**ï¼šå¹¶è¡Œ logits é¢„æµ‹éšå«æŒ‡æ•°çº§ç»„åˆç©ºé—´ï¼Œç›´æ¥éªŒè¯ä¸å¯è¡Œã€‚
- **è§£å†³æ–¹æ¡ˆ**ï¼š
  - å°† N-gram æ¨¡å‹ç”¨ä½œ **è¯­ä¹‰è¿ç»­æ€§çº¦æŸå™¨**ï¼Œè€Œéç‹¬ç«‹é¢„æµ‹å™¨ã€‚
  - è®¾è®¡é«˜æ•ˆå‰ªæç®—æ³•ï¼Œåœ¨æ¯ä¸€æ­¥ç»“åˆ logit å¾—åˆ†ä¸ N-gram è¿ç»­æ€§å¾—åˆ†ï¼Œæ„å»ºé«˜è´¨é‡ draft token treeã€‚
- **ä¼˜åŠ¿**ï¼š
  - ä¿ç•™é«˜æ¦‚ç‡ä¸”è¯­ä¹‰è¿è´¯çš„å€™é€‰è·¯å¾„ã€‚
  - æ˜¾è‘—æé«˜å¹³å‡æ¥å—é•¿åº¦ $T$ï¼ŒåŒæ—¶ä¿æŒä½å»¶è¿Ÿã€‚

#### åˆ›æ–°ç‚¹ 3ï¼šä¸ç›®æ ‡æ¨¡å‹ç´§è€¦åˆè®¾è®¡
- DART ä¸æ˜¯ç‹¬ç«‹æ¨¡å‹ï¼Œè€Œæ˜¯å¤ç”¨ç›®æ ‡æ¨¡å‹çš„ hidden states å’Œ embedding å±‚ï¼Œä»…æ·»åŠ å°‘é‡å¯è®­ç»ƒå‚æ•°ï¼ˆFC layer + decoder layer + LM headï¼‰ã€‚
- æå¤§é™ä½éƒ¨ç½²å¤æ‚æ€§å’Œè®¡ç®—å¼€é”€ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | æ˜¯å¦è‡ªå›å½’ | Drafting Latency | å‡†ç¡®æ€§ï¼ˆTï¼‰ | å®é™…åŠ é€Ÿæ¯” |
|------|------------|------------------|-------------|------------|
| SPS / Vanilla | æ˜¯ | é«˜ | ä¸­ç­‰ | ä½ |
| Medusa / Hydra | å¦ï¼ˆéƒ¨åˆ†ï¼‰ | ä¸­ | ä¸­é«˜ | ä¸­ |
| EAGLE3 | æ˜¯ï¼ˆè½»é‡å±‚ï¼‰ | ä¸­é«˜ | é«˜ | è¾ƒé«˜ |
| Lookahead / PLD | å¦ | æä½ | ä½ | æœ‰é™ |
| **DART** | **å¦** | **æä½** | **é«˜** | **æœ€é«˜** |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿**ï¼šåœ¨ä¿æŒé«˜ $T$ çš„åŒæ—¶ï¼Œå°† drafting latency å‹ç¼©è‡³æè‡´ï¼Œå®ç°ç«¯åˆ°ç«¯æœ€å¤§åŠ é€Ÿã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
æ¶µç›–å¤šç§ä»»åŠ¡ç±»å‹ï¼Œç”¨äºå…¨é¢è¯„ä¼°ï¼š
- **æŒ‡ä»¤è·Ÿéš**ï¼šAlpaca
- **æ•°å­¦æ¨ç†**ï¼šMath500
- **ä»£ç ç”Ÿæˆ**ï¼šHumanEval, CodeAlpaca, LiveCodeBench, MBPP
- **å¤šè½®å¯¹è¯è´¨é‡**ï¼šMT-Bench

è®­ç»ƒæ•°æ®æ¥è‡ª ShareGPT å’Œ UltraChatï¼ˆç»æ¸…æ´—åçº¦ 280K ç¤ºä¾‹ï¼‰ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼š
  - ä¸»è¦ï¼š8Ã—NVIDIA H20-3e GPUï¼ˆ141GBæ˜¾å­˜ï¼‰
  - è¡¥å……æµ‹è¯•ï¼šNVIDIA A100-40G GPU
- **ç›®æ ‡æ¨¡å‹**ï¼š
  - Qwen3 ç³»åˆ—ï¼šQwen3-1.7B, 4B, 8B, 14B, 32B
  - LLaMA2-Chat-7Bï¼ˆç”¨äºè·¨æ–¹æ³•å¯¹æ¯”ï¼‰
- **Batch Size**ï¼šé»˜è®¤ä¸º 1ï¼Œé¢å¤–æµ‹è¯•æ›´å¤§ batchï¼ˆ2â€“64ï¼‰
- **Draft Length**ï¼šç»Ÿä¸€è®¾ä¸º 8ï¼ˆDART å’Œ EAGLE3ï¼‰ï¼ŒSPS ä½¿ç”¨ 5
- **æ¸©åº¦è®¾ç½®**ï¼šT=0 å’Œ T=1 ä¸‹å‡æµ‹è¯•

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Throughput (Speedup)** | ç›¸å¯¹äºæ ‡å‡†è‡ªå›å½’è§£ç çš„ç«¯åˆ°ç«¯ wall-clock time åŠ é€Ÿæ¯” |
| **Average Acceptance Length (T)** | æ¯è½® draft-verify å‘¨æœŸä¸­è¢«æ¥å—çš„ token æ•°é‡ï¼Œåæ˜  draft è´¨é‡ |
| **Drafting Latency** | draft model å‰å‘ + tree search æ‰€è€—æ—¶é—´ï¼ˆmsï¼‰ï¼Œä½“ç°å¼€é”€ |
| **Verification Latency** | target model éªŒè¯ draft token tree çš„æ—¶é—´ |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **SPS**ï¼ˆStandard Speculative Samplingï¼‰ï¼šä½¿ç”¨å°å‹åŒæ—æ¨¡å‹ï¼ˆå¦‚ Qwen3-1.7Bï¼‰ä½œä¸º drafter
- **EAGLE3**ï¼šå½“å‰æœ€ä¼˜çš„åŸºäºç‰¹å¾å¾®è°ƒçš„è‡ªå›å½’ drafter
- **Medusa**, **Hydra**, **Lookahead**, **PLD**ï¼šå…¶ä»–ä»£è¡¨æ€§ speculative decoding æ–¹æ³•
- **æœªæ¯”è¾ƒ**ï¼šDiffuSpec / SpecDiffï¼ˆé—­æºæ— æ³•å¤ç°ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

#### âœ… ç«¯åˆ°ç«¯åŠ é€Ÿæ¯”ï¼ˆSpeedupï¼‰
- DART åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå®ç° **2.03Ã— ~ 3.44Ã—** çš„å®é™…åŠ é€Ÿã€‚
- å¹³å‡æ¯” EAGLE3 å¿« **30%**ã€‚
- åœ¨ä»£ç ç›¸å…³ä»»åŠ¡ï¼ˆå¦‚ CodeAlpacaï¼‰ä¸­è¡¨ç°å°¤ä¸ºçªå‡ºï¼Œå¯¹ Qwen3-14B æé€Ÿè¾¾ **65%** è¶…è¶Š EAGLE3ã€‚

#### âœ… å¹³å‡æ¥å—é•¿åº¦ $T$
- DART çš„ $T$ ä¸ EAGLE3 å¤„äºåŒä¸€æ°´å¹³ï¼ˆç›¸å·® < 0.2ï¼‰ï¼Œä¾‹å¦‚ï¼š
  - Qwen3-14B ä¸Šï¼šEAGLE3 â‰ˆ 3.48ï¼ŒDART â‰ˆ 3.67
- è¡¨æ˜ DART åœ¨å¤§å¹…é™ä½ drafting å¼€é”€çš„åŒæ—¶ï¼Œæœªç‰ºç‰² draft è´¨é‡ã€‚

#### âœ… Drafting Latency æè‡´å‹ç¼©
- å¦‚å›¾ 5 æ‰€ç¤ºï¼Œåœ¨ Qwen3-14B æ¨ç†ä¸­ï¼š
  - **DART drafting forward**: **1.5ms**
  - **EAGLE3 drafting forward**: **10.2ms** â†’ DART å¿« **6.8Ã—**
  - **SPS drafting forward**: **80.0ms** â†’ DART å¿« **53.3Ã—**
- Tree pruning é¢å¤–è€—æ—¶çº¦ 2msï¼Œä»è¿œä½äº EAGLE3 çš„æ ‘æœç´¢æˆæœ¬ã€‚

#### âœ… æ›´å¤§ batch size ä¸‹çš„è¡¨ç°
- éšç€ batch size å¢å¤§ï¼Œæ‰€æœ‰æ–¹æ³•çš„åŠ é€Ÿæ¯”ä¸‹é™ï¼ˆå› ç³»ç»Ÿæ›´ compute-boundï¼‰ã€‚
- ä½†åœ¨æ‰€æœ‰é…ç½®ä¸‹ï¼Œ**DART å§‹ç»ˆä¼˜äº EAGLE3**ï¼Œä¾‹å¦‚åœ¨ Qwen3-4B ä¸Šï¼š
  - batch=2: DART 2.16Ã— vs EAGLE3 1.84Ã—
  - batch=64: DART 1.45Ã— vs EAGLE3 1.22Ã—

#### âœ… è·¨ç¡¬ä»¶å¹³å°éªŒè¯ï¼ˆA100ï¼‰
- åœ¨ A100 ä¸Šæµ‹è¯•è¡¨æ˜ï¼ŒDART ä¾ç„¶ç¨³å®šé¢†å…ˆ EAGLE3 çº¦ **30%**ï¼Œè¯æ˜å…¶è®¾è®¡å…·æœ‰è‰¯å¥½çš„ **hardware-agnostic æ€§èƒ½**ã€‚

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœ

| å®éªŒé¡¹ | å‘ç° |
|--------|------|
| **N-gram Pruning** | ç§»é™¤ N-gram å $T$ æ˜¾è‘—ä¸‹é™ï¼ˆå¦‚ HumanEval ä» 3.63 â†’ 3.13ï¼‰ï¼Œè¯´æ˜å…¶å¯¹ç»´æŒè¯­ä¹‰è¿è´¯æ€§å’Œæé«˜æ¥å—ç‡è‡³å…³é‡è¦ã€‚ |
| **Shifted Logits Prediction** | ç›¸æ¯” unshiftedï¼Œshifted æ–¹æ¡ˆä½¿ç¬¬ä¸€ä¸ªä½ç½®çš„ hit@1 å‡†ç¡®ç‡ä» 57.7% æå‡è‡³ **71.1%**ï¼ˆâ†‘13.4%ï¼‰ï¼Œåç»­ä½ç½®ä¹Ÿæœ‰ç¨³å®šå¢ç›Šã€‚ |
| **Annealed KL Objective ($\gamma=0.6$)** | $\gamma=0.6$ æ—¶è¾¾åˆ°æœ€ä½³å¹³è¡¡ï¼šæ—©æœŸä½ç½®ç²¾åº¦é«˜ï¼Œæ•´ä½“ $T=3.63$ æœ€ä¼˜ï¼›$\gamma=1.0$ï¼ˆæ— é€€ç«ï¼‰æ—¶ $T=3.48$ï¼Œæ€§èƒ½ä¸‹é™ã€‚ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **å¹¶è¡Œ drafting + ç»“æ„åŒ–å‰ªæ æ˜¯å¯è¡Œä¸”é«˜æ•ˆçš„æ›¿ä»£è·¯å¾„**  
   DART æˆåŠŸå°† diffusion-style å¹¶è¡Œç”Ÿæˆå¼•å…¥ speculative decodingï¼Œå¹¶é€šè¿‡å®šåˆ¶åŒ–è®¾è®¡è§£å†³äº†æ¶æ„ä¸åŒ¹é…é—®é¢˜ã€‚

2. **æœ€å°åŒ– drafting overhead æ¯”å•çº¯è¿½æ±‚é«˜ $T$ æ›´é‡è¦**  
   å³ä½¿ $T$ ç•¥ä½äº EAGLE3ï¼ŒDART å‡­å€Ÿæä½çš„ drafting latency å®ç°äº†æ›´é«˜çš„ç«¯åˆ°ç«¯ååé‡ï¼Œæ­ç¤ºäº†æ–°çš„ä¼˜åŒ–èŒƒå¼ã€‚

3. **N-gram åº”ä½œä¸º continuity constraint è€Œé predictor**  
   å°† N-gram ç”¨äºå‰ªæè€Œéç‹¬ç«‹ç”Ÿæˆï¼Œæ—¢èƒ½ä¿è¯è¯­ä¹‰åˆç†ï¼Œåˆä¸ç ´åæ¨¡å‹ä¸»å¯¼çš„åˆ†å¸ƒæ‹Ÿåˆèƒ½åŠ›ã€‚

4. **DART å…·å¤‡è‰¯å¥½æ³›åŒ–æ€§**  
   åœ¨ä¸åŒæ¨¡å‹è§„æ¨¡ï¼ˆ1.7Bâ€“32Bï¼‰ã€ä¸åŒä»»åŠ¡ç±»å‹ã€ä¸åŒç¡¬ä»¶å¹³å°ï¼ˆH20, A100ï¼‰ä¸Šå‡è¡¨ç°å‡ºä¸€è‡´ä¼˜è¶Šæ€§ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–ç›®æ ‡æ¨¡å‹ hidden states**ï¼šéœ€ä¸ç‰¹å®šç›®æ ‡æ¨¡å‹ç´§å¯†é›†æˆï¼Œè¿ç§»æ€§å—é™ã€‚
- **N-gram å†…å­˜å ç”¨è¾ƒé«˜**ï¼šçº¦ 100GB CPU RAMï¼Œè™½å¯æ¥å—ä½†å¯¹èµ„æºç´§å¼ ç¯å¢ƒæ„æˆå‹åŠ›ã€‚
- **è®­ç»ƒå¤æ‚åº¦å¢åŠ **ï¼šéœ€ä¸“é—¨è®­ç»ƒ draft modelï¼Œç›¸æ¯” heuristic æ–¹æ³•é—¨æ§›æ›´é«˜ã€‚
- **ç›®å‰ä»…æ”¯æŒ greedy decoding**ï¼šæœªæ¢ç´¢ temperature sampling æˆ– top-k ç­‰éšæœºé‡‡æ ·åœºæ™¯ä¸‹çš„ç¨³å®šæ€§ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ”¯æŒæ›´å¤šé‡‡æ ·ç­–ç•¥ï¼ˆå¦‚ nucleus samplingï¼‰ä¸‹çš„ speculative decodingã€‚
- æ¢ç´¢æ›´ç´§å‡‘çš„ continuity model æ›¿ä»£å¤§å‹ N-gram trieã€‚
- æ‰©å±•è‡³ MoE æ¨¡å‹æˆ–é•¿ä¸Šä¸‹æ–‡åœºæ™¯ä¸­çš„é«˜æ•ˆ draftingã€‚
- è‡ªåŠ¨åŒ– draft length ä¸ pruning å‚æ•°çš„åŠ¨æ€è°ƒæ•´æœºåˆ¶ã€‚

---

> ğŸ’¡ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **DART é‡æ–°å®šä¹‰äº† speculative decoding çš„è®¾è®¡å“²å­¦â€”â€”ä¸æ˜¯â€œæ›´å¿«åœ°è‡ªå›å½’â€ï¼Œè€Œæ˜¯â€œç”¨å› æœå¹¶è¡Œé¢„æµ‹ + ç»“æ„åŒ–å‰ªæâ€æ‰“ç ´ drafting ç“¶é¢ˆï¼Œåœ¨å‡ ä¹ä¸æŸå¤±å‡†ç¡®æ€§çš„å‰æä¸‹ï¼Œå°† drafting latency å‹ç¼©ä¸€ä¸ªæ•°é‡çº§ä»¥ä¸Šï¼Œä»è€Œå®ç°å‰æ‰€æœªæœ‰çš„ç«¯åˆ°ç«¯åŠ é€Ÿæ•ˆæœã€‚**

</details>

---

### 2. [Length-Adaptive Interest Network for Balancing Long and Short Sequence Modeling in CTR Prediction](https://arxiv.org/abs/2601.19142)

**Authors**: Zhicheng Zhang, Zhaocheng Du, Jieming Zhu, Jiwei Tang, Fengyuan Lu, Wang Jiaheng, Song-Li Wu, Qianhui Zhu, Jingyu Li, Hai-Tao Zheng, Zhenhua Dong  
**Category**: cs.AI  
**Published**: 2026-01-28  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2601.19142v1  

#### Abstract
User behavior sequences in modern recommendation systems exhibit significant length heterogeneity, ranging from sparse short-term interactions to rich long-term histories. While longer sequences provide more context, we observe that increasing the maximum input sequence length in existing CTR models...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**Length-Adaptive Interest Network for Balancing Long and Short Sequence Modeling in CTR Prediction**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ç°ä»£æ¨èç³»ç»Ÿä¸­çš„ç”¨æˆ·è¡Œä¸ºåºåˆ—å­˜åœ¨æ˜¾è‘—çš„**é•¿åº¦å¼‚è´¨æ€§**ï¼ˆlength heterogeneityï¼‰ï¼š  
- é•¿åºåˆ—ç”¨æˆ·æ‹¥æœ‰ä¸°å¯Œçš„å†å²äº¤äº’ï¼ˆå¦‚æ•°ç™¾æ¬¡ç‚¹å‡»ï¼‰ï¼Œå¯æä¾›ä¸°å¯Œä¸Šä¸‹æ–‡ï¼›  
- çŸ­åºåˆ—ç”¨æˆ·ï¼ˆå¦‚æ–°ç”¨æˆ·æˆ–ä½æ´»è·ƒç”¨æˆ·ï¼‰ä»…æœ‰å°‘é‡è¡Œä¸ºï¼Œå»ºæ¨¡å›°éš¾ã€‚

ç„¶è€Œï¼Œä½œè€…å‘ç°ä¸€ä¸ªåç›´è§‰ç°è±¡ï¼š**å½“å¢åŠ æœ€å¤§è¾“å…¥åºåˆ—é•¿åº¦æ—¶ï¼Œç°æœ‰ CTR æ¨¡å‹å¯¹é•¿åºåˆ—ç”¨æˆ·çš„æ€§èƒ½æå‡ï¼Œå´å¯¼è‡´çŸ­åºåˆ—ç”¨æˆ·æ€§èƒ½ä¸‹é™**ã€‚è¿™ç§â€œ**é•¿åº¦ä¸å¹³è¡¡**â€ï¼ˆlength imbalanceï¼‰é—®é¢˜æºäºï¼š
- **Attention Polarization**ï¼šsoftmax æ³¨æ„åŠ›åœ¨é•¿åºåˆ—ä¸­è¶‹äºé›†ä¸­äºå°‘æ•°æ˜¾è‘—é¡¹ï¼Œåœ¨çŸ­åºåˆ—ä¸­åˆ™è¿‡åº¦æ”¾å¤§å™ªå£°ï¼›
- **Length Signal Deficiency**ï¼šç°æœ‰æ¨¡å‹æœªæ˜¾å¼åˆ©ç”¨åºåˆ—é•¿åº¦ä½œä¸ºç”¨æˆ·çŠ¶æ€çš„å…ˆéªŒä¿¡å·ã€‚

æ­¤å¤–ï¼Œè®­ç»ƒæ•°æ®åˆ†å¸ƒä¹ŸåŠ å‰§äº†è¿™ä¸€é—®é¢˜ï¼š**é•¿åºåˆ—ç”¨æˆ·è™½ç„¶æ•°é‡å°‘ï¼Œä½†è´¡çŒ®äº†å¤§éƒ¨åˆ†è®­ç»ƒæ ·æœ¬**ï¼Œå¯¼è‡´æ¨¡å‹éšå¼åå‘ä¼˜åŒ–ä»–ä»¬ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šLAINï¼ˆLength-Adaptive Interest Networkï¼‰

æå‡ºä¸€ç§è½»é‡çº§ã€å³æ’å³ç”¨çš„æ¡†æ¶ **LAIN**ï¼Œé€šè¿‡å°†**åºåˆ—é•¿åº¦ä½œä¸ºæ¡ä»¶ä¿¡å·**ï¼ŒåŠ¨æ€è°ƒæ•´å…´è¶£æå–ä¸æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ç°å¯¹ä¸åŒé•¿åº¦åºåˆ—çš„è‡ªé€‚åº”å»ºæ¨¡ã€‚

#### æ ¸å¿ƒç»„ä»¶ï¼š
1. **Spectral Length Encoder (SLE)**  
   - å°†åŸå§‹é•¿åº¦ $ L $ æ˜ å°„ä¸ºè¿ç»­åµŒå…¥è¡¨ç¤º $ h_{\text{len}} $ï¼Œé‡‡ç”¨å¯å­¦ä¹ çš„å‚…é‡Œå¶åŸºï¼ˆFourier basisï¼‰è¿›è¡Œç¼–ç ï¼Œé¿å…ç¦»æ•£åŒ–æŸå¤±ï¼Œæ•æ‰é•¿åº¦çš„ç»†ç²’åº¦è¯­ä¹‰ã€‚

2. **Length-Conditioned Prompting (LCP)**  
   - åŸºäº $ h_{\text{len}} $ ç”Ÿæˆè½¯æç¤º tokenï¼Œå¹¶å‰ç½®åˆ°é•¿çŸ­åºåˆ—çš„è¡Œä¸ºåºåˆ—ä¸­ï¼Œå‘æ¨¡å‹æ³¨å…¥å…¨å±€é•¿åº¦ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¼•å¯¼å…¶é‡‡ç”¨åˆé€‚çš„å½’çº³åç½®ã€‚

3. **Length-Modulated Attention (LMA)**  
   - åŠ¨æ€è°ƒèŠ‚æ³¨æ„åŠ›é”åº¦ï¼š
     - **Query-Key Conditioning**ï¼šå°†é•¿åº¦åµŒå…¥æ‹¼æ¥åˆ° query å’Œ key ä¸­ï¼›
     - **Temperature Scaling**ï¼šæ ¹æ®é•¿åº¦è‡ªé€‚åº”è°ƒæ•´ softmax æ¸©åº¦ $ T $ï¼ŒçŸ­åºåˆ—æ—¶å¢å¤§æ¸©åº¦ä»¥å¹³æ»‘æ³¨æ„åŠ›åˆ†å¸ƒï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | LAIN çš„ä¼˜åŠ¿ |
|------|-------------|
| **é€šç”¨æ€§** | å¯æ— ç¼é›†æˆåˆ°ä¸»æµ CTR æ¨¡å‹ï¼ˆDINã€DIENã€SIMã€SDIMã€TWIN ç­‰ï¼‰ä¸­ï¼Œæ— éœ€æ¶æ„é‡æ„ |
| **å…¬å¹³æ€§** | æ˜¾è‘—æå‡çŸ­åºåˆ—ç”¨æˆ·é¢„æµ‹ç²¾åº¦ï¼Œç¼“è§£å› æ•°æ®åˆ†å¸ƒä¸å‡é€ æˆçš„æ¨¡å‹åè§ |
| **æ•ˆç‡** | å¼•å…¥å‚æ•° <1.5%ï¼Œæ¨ç†å¼€é”€ä»…å¢åŠ çº¦ 2.3%ï¼Œé€‚åˆå·¥ä¸šéƒ¨ç½² |
| **ç†è®ºåŠ¨æœºå¼º** | æ˜ç¡®è¯Šæ–­å‡º attention polarization ä¸ length signal deficiency ä¸¤å¤§é—®é¢˜ï¼Œå¹¶é’ˆå¯¹æ€§è®¾è®¡è§£å†³æ–¹æ¡ˆ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†
åœ¨ä¸‰ä¸ªçœŸå®ä¸–ç•Œçš„å¤§è§„æ¨¡å…¬å¼€ CTR æ•°æ®é›†ä¸ŠéªŒè¯æ–¹æ³•æœ‰æ•ˆæ€§ï¼š

| æ•°æ®é›† | ç”¨æˆ·æ•° | ç‰©å“æ•° | äº¤äº’æ•° | å¹³å‡åºåˆ—é•¿åº¦ | åœºæ™¯ |
|--------|--------|--------|--------|---------------|------|
| **EBNeRD-small** | 18,828 | 20,739 | 5.5M | 147 | æ–°é—»æ¨è |
| **KuaiVideo** | 10,000 | 3.2M | 4.7M | 278 | çŸ­è§†é¢‘æ¨è |
| **MicroVideo1.7M** | 10,951 | 1.7M | 4.3M | 148 | å¾®è§†é¢‘æ¨è |

æ‰€æœ‰æ•°æ®é›†å‡å‘ˆç°æ˜æ˜¾çš„**é•¿å°¾åˆ†å¸ƒ**ï¼šå¤šæ•°ç”¨æˆ·è¡Œä¸ºç¨€ç–ï¼Œå°‘æ•°ç”¨æˆ·è¡Œä¸ºå¯†é›†ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®
- **æœ€å¤§åºåˆ—é•¿åº¦**ï¼šç»Ÿä¸€è®¾ä¸º 1000ï¼Œä»¥æ”¯æŒé•¿åºåˆ—å»ºæ¨¡ï¼›
- **ç‰¹å¾ç»´åº¦**ï¼šembedding dim = 64ï¼›
- **ä¼˜åŒ–å™¨**ï¼šAdamï¼Œlr = 0.001ï¼Œæ—©åœåŸºäºéªŒè¯é›† AUCï¼›
- **Head ç»“æ„**ï¼šMLP + ReLU + Dropout(0.2)ï¼›
- **LAIN å‚æ•°é…ç½®**ï¼š
  - Fourier dimension $ d_f = 32 $
  - MLP hidden dim = 512
  - Prompt token æ•°é‡ $ k = 4 $

---

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **AUC** | è¡¡é‡æ•´ä½“æ’åºèƒ½åŠ›ï¼Œè¶Šé«˜è¶Šå¥½ |
| **GAUC** | åˆ†ç”¨æˆ·è®¡ç®— AUC åå¹³å‡ï¼Œå‡å°‘é«˜é¢‘ç”¨æˆ·ä¸»å¯¼å½±å“ |
| **LogLoss** | è¡¡é‡æ¦‚ç‡æ ¡å‡†è´¨é‡ï¼Œè¶Šä½è¶Šå¥½ |
| **åˆ†ç»„è¯„ä¼°** | æŒ‰åºåˆ—é•¿åº¦åˆ’åˆ† bucketï¼ˆ<100, 100â€“200, â‰¥200ï¼‰ï¼Œåˆ†æå„ç¾¤ä½“è¡¨ç° |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
é€‰æ‹©äº”ç±»ä»£è¡¨æ€§ CTR æ¨¡å‹ä½œä¸º backbone è¿›è¡Œå¢å¼ºæ¯”è¾ƒï¼š
1. **DIN**ï¼šåŸºäº target-aware attention çš„åŸºç¡€æ¨¡å‹
2. **DIEN**ï¼šå¼•å…¥ GRU å»ºæ¨¡å…´è¶£æ¼”åŒ–
3. **SIM**ï¼šä¸¤é˜¶æ®µæ¶æ„ï¼ˆGSU + ESUï¼‰å¤„ç†é•¿åºåˆ—
4. **SDIM**ï¼šå¤šå¤´æ³¨æ„åŠ›å¢å¼ºç‰ˆ SIM
5. **TWIN**ï¼šåŒå¡”ç»“æ„å»ºæ¨¡è¶…é•¿åºåˆ—

æ‰€æœ‰åŸºçº¿å‡ä½¿ç”¨ç›¸åŒç‰¹å¾å·¥ç¨‹ä¸è¶…å‚è®¾ç½®ï¼Œåœ¨ **FuxiCTR** æ¡†æ¶ä¸‹å¤ç°ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ æ•´ä½“æ€§èƒ½æå‡ï¼ˆTable 3ï¼‰
LAIN åœ¨æ‰€æœ‰ backbone å’Œæ•°æ®é›†ä¸Šå‡å¸¦æ¥ä¸€è‡´å¢ç›Šï¼š

| æ¨¡å‹ | æœ€å¤§ AUC æå‡ | æœ€å¤§ LogLoss ä¸‹é™ |
|------|----------------|--------------------|
| TWIN + LAIN | **+1.15%** | **-1.63%** |
| DIN + LAIN | +1.07% | -0.92% |
| DIEN + LAIN | +0.27% | -2.25% |

> ğŸ’¡ æ³¨ï¼šDIEN è™½ç„¶ AUC æå‡è¾ƒå°ï¼Œä½†åœ¨ KuaiVideo ä¸Š LogLoss æ”¹å–„æœ€æ˜æ˜¾ï¼ˆ-2.25%ï¼‰ï¼Œè¯´æ˜å…¶åœ¨æ¦‚ç‡æ ¡å‡†æ–¹é¢ä¹Ÿæœ‰ä¼˜åŠ¿ã€‚

---

### ğŸ¯ é•¿çŸ­åºåˆ—ç”¨æˆ·åˆ†åˆ«è¯„ä¼°ï¼ˆTable 4ï¼‰
ä»¥ TWIN ä¸ºä¾‹ï¼Œåœ¨ MicroVideo1.7M ä¸ŠæŒ‰é•¿åº¦åˆ†ç»„çš„ç»“æœæ˜¾ç¤ºï¼š

| åºåˆ—é•¿åº¦ | AUC æå‡ | LogLoss ä¸‹é™ |
|---------|----------|--------------|
| **<100ï¼ˆçŸ­åºåˆ—ï¼‰** | **+1.08%** | **-2.17%** |
| 100â€“200ï¼ˆä¸­ç­‰ï¼‰ | +0.50% | -1.26% |
| â‰¥200ï¼ˆé•¿åºåˆ—ï¼‰ | +1.58% | -1.74% |

ğŸ‘‰ **å…³é”®å‘ç°**ï¼šLAIN ä¸ä»…æ²¡æœ‰ç‰ºç‰²é•¿åºåˆ—æ€§èƒ½ï¼Œåè€ŒåŒæ—¶æå‡äº†ä¸¤ç±»ç”¨æˆ·çš„å»ºæ¨¡æ•ˆæœï¼Œå®ç°äº†çœŸæ­£çš„â€œå¹³è¡¡â€ã€‚

---

### ğŸ”¬ æ³¨æ„åŠ›æåŒ–ç¼“è§£åˆ†æï¼ˆTable 5ï¼‰
ä½¿ç”¨ Gini ç³»æ•°è¡¡é‡æ³¨æ„åŠ›åˆ†å¸ƒçš„é›†ä¸­ç¨‹åº¦ï¼ˆè¶Šä½è¶Šå‡åŒ€ï¼‰ï¼š

| æ¨¡å‹é…ç½® | çŸ­åºåˆ— Gini | ä¸­åºåˆ— Gini | é•¿åºåˆ— Gini |
|----------|------------|------------|------------|
| Baseline (L=1000) | 0.346 | 0.351 | 0.352 |
| **LAIN** | **0.318** | **0.322** | **0.321** |

âœ… LAIN å°†æ³¨æ„åŠ›æåŒ–ç¨‹åº¦é™ä½çº¦ **33.3%~50.6%**ï¼Œå°¤å…¶æ”¹å–„äº†çŸ­åºåˆ—ä¸‹çš„æ³¨æ„åŠ›å¡Œç¼©é—®é¢˜ã€‚

---

### ğŸ” æ¶ˆèå®éªŒï¼ˆAblation Study, Table 6ï¼‰
åœ¨ TWIN ä¸Šç§»é™¤å„æ¨¡å—çš„å½±å“ï¼š

| å˜ä½“ | AUC | Î”AUC |
|------|-----|-------|
| **LAIN (Full)** | **0.7233** | â€” |
| w/o LCP | 0.7228 | -0.05% |
| w/o Query-Key Conditioning | 0.7195 | -0.38% |
| w/o Temperature Scaling | 0.7212 | -0.21% |
| w/o LMA | 0.7189 | **-0.44%** |
| w/o Short-term Branch | 0.7226 | -0.07% |

ğŸ“Œ **ç»“è®º**ï¼š
- **LMA æ˜¯æœ€å…³é”®çš„ç»„ä»¶**ï¼Œå°¤å…¶æ˜¯ query-key conditioning ä¸ temperature scaling ååŒä½œç”¨ï¼›
- ç§»é™¤ short-term åˆ†æ”¯ä»é€ æˆè½»å¾®ä¸‹é™ï¼Œè¡¨æ˜ LAIN å¯¹çŸ­åºåˆ—å»ºæ¨¡å…·æœ‰ç‹¬ç«‹ä»·å€¼ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **é•¿åº¦ä¸æ˜¯è¢«åŠ¨ç»Ÿè®¡é‡ï¼Œè€Œæ˜¯ä¸»åŠ¨å»ºæ¨¡ä¿¡å·**ï¼šåºåˆ—é•¿åº¦åæ˜ äº†ç”¨æˆ·çš„æ´»è·ƒåº¦ã€å…´è¶£ç¨³å®šæ€§ä¸å†…å®¹å¤šæ ·æ€§ï¼Œåº”è¢«æ˜¾å¼å»ºæ¨¡ã€‚
2. **æ ‡å‡† CTR æ¨¡å‹å­˜åœ¨â€œé•¿åº¦è¯±å¯¼åå·®â€**ï¼ˆlength-induced biasï¼‰ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­é•¿åºåˆ—æ ·æœ¬ä¸»å¯¼æ¢¯åº¦æ›´æ–°ï¼ŒæŸå®³çŸ­åºåˆ—æ³›åŒ–ã€‚
3. **LAIN æˆåŠŸè§£è€¦äº†é•¿çŸ­åºåˆ—çš„ä¼˜åŒ–å†²çª**ï¼šé€šè¿‡æ¡ä»¶åŒ– prompt ä¸ attention è°ƒåˆ¶ï¼Œä½¿å…±äº«æ¨¡å‹èƒ½æ ¹æ®ä¸åŒé•¿åº¦åŠ¨æ€è°ƒæ•´è¡Œä¸ºç­–ç•¥ã€‚
4. **æ–¹æ³•å…·å¤‡å¼ºé²æ£’æ€§å’Œæ™®é€‚æ€§**ï¼šåœ¨å¤šç§ backbone å’Œæ•°æ®é›†ä¸Šç¨³å®šæœ‰æ•ˆï¼Œä¸”å¯¹è¶…å‚æ•°ä¸æ•æ„Ÿï¼ˆè§ Figure 4ï¼‰ã€‚

---

### âš ï¸ å±€é™æ€§
1. **ä¾èµ–é¢„å®šä¹‰çš„æœ€å¤§åºåˆ—é•¿åº¦**ï¼šè™½ç„¶ LAIN ç¼–ç çš„æ˜¯å®é™…é•¿åº¦ $ L $ï¼Œä½† truncation æˆ– padding ç­–ç•¥å¯èƒ½å½±å“æ€§èƒ½è¾¹ç•Œï¼›
2. **æœªè€ƒè™‘å…¶ä»–ç”¨æˆ·çŠ¶æ€ä¿¡å·è”åˆå»ºæ¨¡**ï¼šå¦‚æ³¨å†Œæ—¶é—´ã€è®¾å¤‡ç±»å‹ã€åœ°ç†ä½ç½®ç­‰ï¼Œæœªæ¥å¯æ¢ç´¢å¤šä¿¡å·è”åˆ conditioningï¼›
3. **ç›®å‰ä»…ç”¨äº CTR é¢„æµ‹ä»»åŠ¡**ï¼šæ˜¯å¦é€‚ç”¨äº CVRã€CTR/CVR è”åˆå»ºæ¨¡ç­‰è¿˜éœ€è¿›ä¸€æ­¥éªŒè¯ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³å¤šä»»åŠ¡æ¨èåœºæ™¯**ï¼šå°† LAIN æ€è·¯åº”ç”¨äºå¤šç›®æ ‡å­¦ä¹ ï¼ˆmulti-task learningï¼‰ä¸­ï¼Œå®ç°è·¨ä»»åŠ¡çš„é•¿åº¦è‡ªé€‚åº”ï¼›
2. **ç»“åˆç”¨æˆ·ç”Ÿå‘½å‘¨æœŸå»ºæ¨¡**ï¼šå°†é•¿åº¦è§†ä¸ºç”¨æˆ·æˆé•¿é˜¶æ®µçš„ä»£ç†å˜é‡ï¼Œæ„å»ºåŠ¨æ€æ¼”åŒ–æ¨¡å‹ï¼›
3. **æ¢ç´¢æ›´å¤æ‚çš„é•¿åº¦æ„ŸçŸ¥æ¶æ„**ï¼šä¾‹å¦‚åŸºäº length çš„å­ç½‘ç»œè·¯ç”±ï¼ˆroutingï¼‰ã€adapter æ’å…¥ä½ç½®è‡ªé€‚åº”ç­‰ï¼›
4. **åº”ç”¨äºå†·å¯åŠ¨ä¸å…¬å¹³æ€§ç ”ç©¶**ï¼šä½œä¸ºç¼“è§£æ¨èç³»ç»Ÿåè§çš„ä¸€ç§é€šç”¨å·¥å…·ï¼Œæ¨åŠ¨æ›´å…¬å¹³çš„ä¸ªæ€§åŒ–æœåŠ¡ã€‚

---

> âœ… **æ€»ä½“è¯„ä»·**ï¼š  
> LAIN æ˜¯ä¸€é¡¹å…¼å…·**ç†è®ºæ´å¯ŸåŠ›**ä¸**å·¥ç¨‹å®ç”¨æ€§**çš„å·¥ä½œã€‚å®ƒæ­ç¤ºäº†ä¸€ä¸ªé•¿æœŸè¢«å¿½è§†çš„â€œé•¿åº¦å¤±è¡¡â€é—®é¢˜ï¼Œå¹¶æå‡ºäº†ç®€æ´é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚è¯¥æ–¹æ³•æœ‰æœ›æˆä¸ºå·¥ä¸šçº§æ¨èç³»ç»Ÿçš„æ ‡å‡†ç»„ä»¶ä¹‹ä¸€ã€‚

</details>

---

### 3. [GPCR-Filter: a deep learning framework for efficient and precise GPCR modulator discovery](https://arxiv.org/abs/2601.19149)

**Authors**: Jingjie Ning, Xiangzhen Shen, Li Hou, Shiyi Shen, Jiahao Yang, Junrui Li, Hong Shan, Sanan Wu, Sihan Gao, Huaqiang Eric Xu, Xinheng He  
**Category**: cs.LG  
**Published**: 2026-01-28  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2601.19149v1  

#### Abstract
G protein-coupled receptors (GPCRs) govern diverse physiological processes and are central to modern pharmacology. Yet discovering GPCR modulators remains challenging because receptor activation often arises from complex allosteric effects rather than direct binding affinity, and conventional assays...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šGPCR-Filter: a deep learning framework for efficient and precise GPCR modulator discovery

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
Gè›‹ç™½å¶è”å—ä½“ï¼ˆGPCRsï¼‰æ˜¯ç°ä»£è¯ç‰©ç ”å‘ä¸­æœ€é‡è¦çš„é¶ç‚¹å®¶æ—ä¹‹ä¸€ï¼ˆçº¦36% FDAæ‰¹å‡†è¯ç‰©ä½œç”¨äºGPCRsï¼‰ï¼Œä½†å…¶**åŠŸèƒ½è°ƒæ§æœºåˆ¶å¤æ‚**ï¼Œå¸¸æ¶‰åŠåˆ«æ„æ•ˆåº”ï¼ˆallosteric effectsï¼‰ï¼Œå¯¼è‡´ä¼ ç»ŸåŸºäºç»“åˆäº²å’ŒåŠ›çš„è™šæ‹Ÿç­›é€‰æ–¹æ³•éš¾ä»¥å‡†ç¡®é¢„æµ‹åŠŸèƒ½æ€§è°ƒèŠ‚å‰‚ï¼ˆmodulatorsï¼‰ã€‚æ­¤å¤–ï¼Œå®éªŒéªŒè¯æˆæœ¬é«˜ã€é€šé‡ä½ï¼Œé™åˆ¶äº†æ–°é…ä½“çš„å‘ç°ã€‚

ç°æœ‰AIæ¨¡å‹å¦‚TransformerCPIã€ConPLexç­‰è™½å¯ç”¨äºåŒ–åˆç‰©-è›‹ç™½ç›¸äº’ä½œç”¨ï¼ˆDTIï¼‰é¢„æµ‹ï¼Œä½†**ç¼ºä¹å¯¹GPCRç‰¹å¼‚æ€§åºåˆ—-åŠŸèƒ½å…³ç³»çš„æ•æ„Ÿæ€§**ï¼Œåœ¨è·¨é¶ç‚¹ï¼ˆinter-targetï¼‰æˆ–æ–°åŒ–å­¦éª¨æ¶ä¸Šçš„æ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
ä½œè€…æå‡º **GPCR-Filter** â€”â€”ä¸€ä¸ªä¸“ä¸ºGPCRè°ƒèŠ‚å‰‚å‘ç°è®¾è®¡çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå…·æœ‰ä»¥ä¸‹åˆ›æ–°ï¼š

1. **é¢†åŸŸä¸“ç”¨å»ºæ¨¡æ¶æ„**  
   é’ˆå¯¹GPCRç”Ÿç‰©å­¦ç‰¹æ€§å®šåˆ¶æ¨¡å‹ç»“æ„ï¼Œæ•´åˆï¼š
   - **ESM-3**ï¼šå…ˆè¿›çš„è›‹ç™½è´¨è¯­è¨€æ¨¡å‹ï¼Œç”¨äºæå–é«˜ä¿çœŸåº¦çš„GPCRåºåˆ—åµŒå…¥ï¼›
   - **å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰**ï¼šç¼–ç é…ä½“åˆ†å­å›¾ç»“æ„ï¼›
   - **æ³¨æ„åŠ›èåˆæœºåˆ¶ï¼ˆattention-based fusionï¼‰**ï¼šé€šè¿‡ligand-to-protein cross-attentionåŠ¨æ€æ•æ‰å—ä½“-é…ä½“ä¹‹é—´çš„åŠŸèƒ½å…³è”ï¼Œè¶…è¶Šç®€å•â€œç»“åˆâ€é¢„æµ‹ï¼Œå®ç°â€œåŠŸèƒ½è°ƒèŠ‚æ½œåŠ›â€çš„æ¨æ–­ã€‚

2. **é«˜è´¨é‡ã€å¤§è§„æ¨¡å®éªŒéªŒè¯æ•°æ®é›†æ„å»º**  
   æ„å»ºäº†ä¸€ä¸ªåŒ…å« **91,396ä¸ªç»å®éªŒéªŒè¯çš„äººæºGPCR-é…ä½“å¯¹** çš„é«˜è´¨é‡æ•°æ®é›†ï¼Œæ¥æºäºGPCRdbå’ŒGtoPdbæ•°æ®åº“ï¼Œå¹¶ç»Ÿä¸€æ˜ å°„è‡³UniProtåºåˆ—å’Œæ ‡å‡†SMILESæ ¼å¼ã€‚

3. **å¯è§£é‡Šæ€§å¼ºçš„è®¾è®¡**  
   åˆ©ç”¨cross-attentionæƒé‡åˆ†æå…³é”®æ®‹åŸºï¼Œå‘ç°æ¨¡å‹å…³æ³¨åŒºåŸŸä¸æ™¶ä½“ç»“æ„ä¸­çš„é…ä½“ç»“åˆå£è¢‹é«˜åº¦é‡åˆï¼Œæ”¯æŒå…¶ç”Ÿç‰©å­¦åˆç†æ€§ã€‚

4. **ä½œä¸ºè™šæ‹Ÿç­›é€‰æµç¨‹ä¸­çš„é«˜æ•ˆè¿‡æ»¤å™¨**  
   GPCR-Filterä¸å–ä»£ç»“æ„å¯¹æ¥ï¼Œè€Œæ˜¯ä½œä¸ºåç»­ç²¾ç­›æ­¥éª¤ï¼Œåœ¨ä»…è¾“å…¥GPCRåºåˆ—å’ŒSMILESçš„æƒ…å†µä¸‹è¿›ä¸€æ­¥æå‡å‘½ä¸­ç‡ï¼ˆhit rateï¼‰ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | GPCR-Filter | ä¼ ç»ŸDTIæ¨¡å‹ï¼ˆå¦‚ConPLex, TransformerCPI2.0ï¼‰ |
|------|-------------|------------------------------------------|
| **ä»»åŠ¡ç›®æ ‡** | åŠŸèƒ½æ€§è°ƒèŠ‚å‰‚è¯†åˆ«ï¼ˆfunctional modulationï¼‰ | é€šç”¨ç»“åˆé¢„æµ‹ï¼ˆbinding likelihoodï¼‰ |
| **æ³›åŒ–èƒ½åŠ›** | å¼ºå¤§çš„è·¨é¶ç‚¹ï¼ˆinter-targetï¼‰æ³›åŒ–èƒ½åŠ› | åœ¨æœªè§å—ä½“ä¸Šè¡¨ç°å·®ç”šè‡³ä½äºéšæœº |
| **è¾“å…¥ä¾èµ–** | æ— éœ€ä¸‰ç»´ç»“æ„ï¼Œä»…éœ€åºåˆ— + SMILES | åŒæ ·è¾“å…¥ï¼Œä½†æœªé’ˆå¯¹GPCRä¼˜åŒ– |
| **æ€§èƒ½è¡¨ç°** | æ˜¾è‘—ä¼˜äºåŸºçº¿ï¼Œå°¤å…¶åœ¨æŒ‘æˆ˜æ€§åœºæ™¯ä¸‹ | æ€§èƒ½å¹³åº¸ï¼Œæ˜“è¿‡æ‹Ÿåˆ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†
- **æ¥æº**ï¼šæ•´åˆè‡ª [GPCRdb](https://gpcrdb.org/) å’Œ [Guide to Pharmacology (GtoPdb)](https://www.guidetopharmacology.org/)
- **è§„æ¨¡**ï¼š
  - 91,396 æ¡å®éªŒéªŒè¯çš„ human GPCRâ€“ligand interaction è®°å½•
  - è¦†ç›– **527ä¸ªç‹¬ç‰¹GPCRs**
  - åŒ…å« **72,177ä¸ªä¸åŒé…ä½“ï¼ˆcanonical SMILESï¼‰**
- **è´Ÿæ ·æœ¬æ„é€ **ï¼š
  - æ‰€æœ‰å¯èƒ½ç»„åˆä¸­å»é™¤å·²çŸ¥é˜³æ€§å¯¹
  - é‡‡ç”¨ **1:1 æ­£è´Ÿé‡‡æ ·ç­–ç•¥**ï¼Œç¡®ä¿ç±»åˆ«å¹³è¡¡
  - ä¸åŒsplitç‹¬ç«‹é‡‡æ ·ä»¥é¿å…ä¿¡æ¯æ³„éœ²

---

### âš™ï¸ å®éªŒè®¾ç½®ä¸è¯„ä¼°åè®®
é‡‡ç”¨ä¸‰ç§é€’è¿›éš¾åº¦çš„æ•°æ®åˆ’åˆ†æ–¹å¼ï¼Œç³»ç»Ÿè¯„ä¼°æ¨¡å‹æ³›åŒ–èƒ½åŠ›ï¼š

| è®¾ç½® | æè¿° | æŒ‘æˆ˜æ€§ |
|------|------|--------|
| **Random Split** | éšæœºåˆ’åˆ†æ‰€æœ‰GPCRâ€“ligandå¯¹ï¼ˆè®­ç»ƒ/éªŒè¯/æµ‹è¯• = 80/10/10ï¼‰ | æœ€ä½ï¼Œè¡¡é‡in-distributionæ€§èƒ½ |
| **Intra-target Split** | æ¯ä¸ªGPCRå‡ºç°åœ¨æ‰€æœ‰é›†åˆä¸­ï¼Œä½†å…¶é…ä½“äº’æ–¥åˆ’åˆ† | ä¸­ç­‰ï¼Œæµ‹è¯•å¯¹åŒä¸€é¶ç‚¹çš„æ–°é…ä½“æ³›åŒ– |
| **Inter-target Split** | å°†GPCRåˆ†ä¸ºè®­ç»ƒé›†ï¼ˆ90%ï¼‰ä¸ä¿ç•™é›†ï¼ˆ10%ï¼‰ï¼Œæµ‹è¯•é›†ä»…æ¥è‡ªæœªè§è¿‡çš„GPCRs | æœ€é«˜ï¼Œæµ‹è¯•è·¨é¶ç‚¹è¿ç§»èƒ½åŠ› |

> æ³¨ï¼šæ‰€æœ‰æ¨¡å‹å‡ä½¿ç”¨ç›¸åŒçš„è¾“å…¥ï¼ˆGPCRæ°¨åŸºé…¸åºåˆ— + é…ä½“SMILESï¼‰ï¼Œå…¬å¹³æ¯”è¾ƒã€‚

---

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
- **AUC**ï¼ˆROCæ›²çº¿ä¸‹é¢ç§¯ï¼‰
- **AP**ï¼ˆAverage Precisionï¼Œæ›´é€‚ç”¨äºä¸å¹³è¡¡æ•°æ®ï¼‰
- **Accuracy (ACC)** å’Œ **Precision**
- æ‰€æœ‰é˜ˆå€¼ç›¸å…³æŒ‡æ ‡ä½¿ç”¨å›ºå®šæ¦‚ç‡é˜ˆå€¼ `0.5`

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
ä¸ä¸¤ä¸ªæœ€å…ˆè¿›çš„åºåˆ—çº§DTIæ¨¡å‹è¿›è¡Œå¯¹æ¯”ï¼š
1. **ConPLex**ï¼šåŸºäºå¯¹æ¯”å­¦ä¹ çš„è›‹ç™½è¯­è¨€æ¨¡å‹æ¡†æ¶
2. **TransformerCPI2.0**ï¼šç»“åˆTAPE-BERTä¸GNNçš„ç«¯åˆ°ç«¯æ¨¡å‹

> æ‰€æœ‰æ–¹æ³•ä½¿ç”¨ç›¸åŒçš„æ•°æ®é¢„å¤„ç†ã€è¶…å‚æ•°è°ƒä¼˜ç­–ç•¥åŠè¯„ä¼°åè®®ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰

| Method | Random AUC (%) | Intra-target AUC (%) | Inter-target AUC (%) |
|--------|----------------|-----------------------|------------------------|
| ConPLex | 53.03 | 52.89 | **44.91** âŒï¼ˆ<50%ï¼Œå¯èƒ½è¿‡æ‹Ÿåˆï¼‰ |
| TransformerCPI2.0 | 65.94 | 62.02 | 66.31 |
| **GPCR-Filter** | **99.02** | **97.98** | **80.35** âœ… |

> âœ… GPCR-Filteråœ¨æ‰€æœ‰ä¸‰é¡¹ä»»åŠ¡ä¸­æ˜¾è‘—é¢†å…ˆï¼Œå°¤å…¶åœ¨æœ€å…·æŒ‘æˆ˜æ€§çš„ **inter-target split** ä¸Šæ¯”ç¬¬äºŒåé«˜å‡º **14ä¸ªç™¾åˆ†ç‚¹ä»¥ä¸Š**ã€‚

#### å…¶ä»–å…³é”®æŒ‡æ ‡ï¼ˆInter-targetï¼‰ï¼š
- **AP**: 70.99% vs. 58.50%ï¼ˆTransformerCPI2.0ï¼‰
- **Precision**: 75.93% vs. 53.35%
- **ACC**: 74.57%

è¡¨æ˜è¯¥æ¨¡å‹ä¸ä»…èƒ½åŒºåˆ†æ­£è´Ÿæ ·æœ¬ï¼Œè¿˜èƒ½åœ¨å®Œå…¨é™Œç”Ÿçš„GPCRsä¸Šä¿æŒé«˜ç²¾åº¦é¢„æµ‹ã€‚

---

### ğŸ”¬ å¯è§£é‡Šæ€§åˆ†æç»“æœ
é€šè¿‡å¯¹cross-attentionæƒé‡å¯è§†åŒ–ï¼Œç ”ç©¶æ¨¡å‹æ˜¯å¦çœŸæ­£å­¦åˆ°ç»“åˆä½ç‚¹æ¨¡å¼ï¼š

- åˆ†æä¸¤ä¸ªæ–°è§£æçš„å¤åˆç‰©ç»“æ„ï¼ˆPDB: 9bsb, DRD2ï¼›9jcl, purinergic receptorï¼‰
- å®šä¹‰â€œæ™¶ä½“å­¦ç»“åˆå£è¢‹â€ä¸ºè·ç¦»é…ä½“é‡åŸå­ <5Ã… çš„æ®‹åŸº
- æŠ¥å‘ŠTop-20é«˜æ³¨æ„åŠ›æ®‹åŸºä¸­æœ‰å¤šå°‘è½åœ¨çœŸå®ç»“åˆå£è¢‹å†…ï¼ˆPocket hits@20ï¼‰

#### ç»“æœï¼š
- åœ¨å¤šä¸ªè®­ç»ƒè®¾ç½®ä¸‹ï¼ˆrandom/intra/interï¼‰ï¼ŒTop-20ä¸­å‡æœ‰ **6â€“8ä¸ªæ®‹åŸºä½äºçœŸå®ç»“åˆå£è¢‹**
- æ³¨æ„åŠ›åˆ†å¸ƒç¨³å®šï¼Œä¸”èšç„¦äºå·²çŸ¥åŠŸèƒ½åŒºåŸŸ
- æ”¯æŒæ¨¡å‹å¹¶éè®°å¿†é…å¯¹ï¼Œè€Œæ˜¯å­¦ä¹ åˆ°äº†**ç»“æ„æ€§çš„åŠŸèƒ½äº¤äº’æ¨¡å¼**

---

### ğŸ’¡ æ¶ˆèå®éªŒï¼ˆéšå«åˆ†æï¼‰
è™½ç„¶æ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»è®¾è®¡é€»è¾‘å’Œç»“æœåæ¨å¯å¾—ä»¥ä¸‹ç»“è®ºï¼š
- **ESM-3çš„ä½œç”¨è‡³å…³é‡è¦**ï¼šç›¸æ¯”å…¶ä»–PLMï¼ˆå¦‚TAPE-BERTï¼‰ï¼Œå…¶è¿›åŒ–å°ºåº¦çš„è¯­è¨€å»ºæ¨¡èƒ½åŠ›æ›´é€‚åˆæ•è·GPCRä¿å®ˆåŠŸèƒ½åŸŸã€‚
- **Attentionèåˆæœºåˆ¶æœ‰æ•ˆ**ï¼šcross-attentionä½¿æ¨¡å‹èƒ½å¤ŸåŠ¨æ€å®šä½å…³é”®æ®‹åŸºï¼Œè€Œéå…¨å±€å¹³å‡ã€‚
- **é«˜è´¨é‡æ•°æ®æ”¯æ’‘æ³›åŒ–**ï¼šlong-tailedåˆ†å¸ƒä¸‹çš„å‡è¡¡é‡‡æ ·ä¸åˆç†splitè®¾è®¡æå‡äº†æ¨¡å‹é²æ£’æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º
1. **GPCR-Filteræ˜¯ä¸€ä¸ªé«˜æ•ˆã€ç²¾å‡†ã€å¯æ‰©å±•çš„GPCRè°ƒèŠ‚å‰‚å‘ç°å·¥å…·**ï¼Œåœ¨å¤šç§è¯„ä¼°åœºæ™¯ä¸‹æ˜¾è‘—ä¼˜äºç°æœ‰DTIæ¨¡å‹ã€‚
2. æ¨¡å‹å…·å¤‡å¼ºå¤§çš„**è·¨é¶ç‚¹æ³›åŒ–èƒ½åŠ›**ï¼ˆinter-target generalizationï¼‰ï¼Œå¯åœ¨ä»æœªè®­ç»ƒè¿‡çš„GPCRsä¸Šåšå‡ºå¯é é¢„æµ‹ã€‚
3. é€šè¿‡æ•´åˆ**ESM-3 + GNN + attention fusion**ï¼ŒæˆåŠŸæ¡¥æ¥äº†GPCRåºåˆ—ä¿¡æ¯ä¸é…ä½“åŒ–å­¦ç©ºé—´ï¼Œå®ç°äº†ä»â€œç»“åˆé¢„æµ‹â€å‘â€œåŠŸèƒ½è°ƒèŠ‚é¢„æµ‹â€çš„è·ƒè¿ã€‚
4. **æ¹¿å®éªŒéªŒè¯æˆåŠŸ**ï¼šåœ¨5-HT1Aå—ä½“ä¸Šï¼Œä»ChemDivåº“ä¸­ç­›é€‰å‡º4ä¸ªå¾®æ‘©å°”çº§åˆ«ï¼ˆmicromolar-levelï¼‰çš„æ–°å‹æ¿€åŠ¨å‰‚ï¼Œå…·æœ‰ä¸åŒçš„åŒ–å­¦éª¨æ¶ï¼Œè¯æ˜å…¶å®é™…åº”ç”¨ä»·å€¼ã€‚

---

### âš ï¸ å±€é™æ€§
1. **è´Ÿæ ·æœ¬ä¸ç¡®å®šæ€§**ï¼šè´Ÿæ ·æœ¬ç”±æœªæŠ¥å‘Šç›¸äº’ä½œç”¨æ¨æ–­è€Œæ¥ï¼Œå¯èƒ½å­˜åœ¨å‡é˜´æ€§ï¼ˆå³å®é™…æ´»æ€§ä½†æœªè¢«è®°å½•ï¼‰ã€‚
2. **é…ä½“å¤ç”¨é—®é¢˜**ï¼šåœ¨inter-target splitä¸­ï¼ŒæŸäº›é…ä½“å¯èƒ½åŒæ—¶å‡ºç°åœ¨è®­ç»ƒå’Œæµ‹è¯•ä¸­ï¼ˆå°½ç®¡é¶ç‚¹ä¸åŒï¼‰ï¼Œå¯èƒ½å¼•å…¥åå·®ã€‚
3. **ç¼ºä¹ç»“æ„çº¦æŸ**ï¼šçº¯åºåˆ—+SMILESè¾“å…¥è™½å¢å¼ºæ³›åŒ–ï¼Œä½†ä¹Ÿä¸¢å¤±äº†ç²¾ç»†çš„ç©ºé—´å‡ ä½•ä¿¡æ¯ã€‚
4. **æœªæ¶µç›–æ‰€æœ‰GPCRäºšå‹**ï¼šéƒ¨åˆ†å­¤å„¿å—ä½“æˆ–ä½æ•°æ®é‡GPCRsè¦†ç›–ä¸è¶³ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ”¹è¿›è´Ÿæ ·æœ¬ç­–ç•¥**ï¼šæ¢ç´¢æ›´åˆç†çš„decoyç”Ÿæˆæ–¹æ³•ï¼ˆå¦‚ADMETæ€§è´¨åŒ¹é…ã€ç‰©ç†ä¸å¯è¡Œæ€§åˆ¤åˆ«ï¼‰ã€‚
2. **å¼•å…¥ç»“æ„å…ˆéªŒ**ï¼šå°†AlphaFold3é¢„æµ‹ç»“æ„æˆ–ç»“åˆå£è¢‹ä¿¡æ¯èå…¥æ¨¡å‹ï¼Œæå‡ç²¾åº¦ã€‚
3. **æ‰©å±•è‡³æ›´å¤šè›‹ç™½å®¶æ—**ï¼šéªŒè¯è¯¥èŒƒå¼æ˜¯å¦é€‚ç”¨äºç¦»å­é€šé“ã€æ ¸å—ä½“ç­‰å…¶ä»–è†œè›‹ç™½ã€‚
4. **é—­ç¯è‡ªåŠ¨åŒ–ç­›é€‰å¹³å°**ï¼šå°†GPCR-Filteré›†æˆè¿›å®Œæ•´çš„AI-driven drug discovery pipelineï¼Œå®ç°ä»è™šæ‹Ÿç­›é€‰åˆ°å…ˆå¯¼ä¼˜åŒ–çš„å…¨æµç¨‹åŠ é€Ÿã€‚

---

## âœ… æ€»ç»“ä¸€å¥è¯
> **GPCR-Filteré€šè¿‡èåˆå‰æ²¿è›‹ç™½è¯­è¨€æ¨¡å‹ä¸æ³¨æ„åŠ›æœºåˆ¶ï¼Œåœ¨é«˜è´¨é‡æ•°æ®åŸºç¡€ä¸Šæ„å»ºäº†ä¸€ä¸ªé¢å‘GPCRåŠŸèƒ½è°ƒèŠ‚å‰‚å‘ç°çš„é«˜æ€§èƒ½ã€å¼ºæ³›åŒ–ã€å¯è§£é‡Šçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†æ–°è¯å‘ç°æ•ˆç‡ï¼Œå¹¶ç»å®éªŒè¯å®å…¶å®é™…å¯è¡Œæ€§ã€‚**

</details>

---

### 4. [Flatter Tokens are More Valuable for Speculative Draft Model Training](https://arxiv.org/abs/2601.18902)

**Authors**: Jiaming Fan, Daming Cao, Xiangzhong Luo, Jiale Fu, Chonghan Liu, Xu Yang  
**Category**: cs.CL  
**Published**: 2026-01-28  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.18902v1  

#### Abstract
Speculative Decoding (SD) is a key technique for accelerating Large Language Model (LLM) inference, but it typically requires training a draft model on a large dataset. We approach this problem from a data-centric perspective, finding that not all training samples contribute equally to the SD accept...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Flatter Tokens are More Valuable for Speculative Draft Model Training*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å½“å‰åŸºäºè®­ç»ƒçš„ **Speculative Decoding (SD)** æ–¹æ³•åœ¨åŠ é€Ÿå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†æ—¶ï¼Œé€šå¸¸éœ€è¦åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šå¯¹ draft model è¿›è¡ŒçŸ¥è¯†è’¸é¦ï¼ˆKnowledge Distillation, KDï¼‰ã€‚ç„¶è€Œï¼Œå¹¶éæ‰€æœ‰è®­ç»ƒæ ·æœ¬éƒ½å¯¹æå‡ **acceptance rate** æœ‰åŒç­‰è´¡çŒ®ã€‚ç›´æ¥ä½¿ç”¨å…¨é‡æ•°æ®è®­ç»ƒæ•ˆç‡ä½ä¸‹ï¼Œå­˜åœ¨å¤§é‡å†—ä½™è®¡ç®—ã€‚

æœ¬æ–‡ä»**æ•°æ®ä¸­å¿ƒåŒ–**ï¼ˆdata-centricï¼‰è§†è§’å‡ºå‘ï¼Œç³»ç»Ÿæ€§åœ°ç ”ç©¶äº†â€œå“ªäº›æ•°æ®å¯¹ SD è®­ç»ƒæœ€æœ‰ä»·å€¼â€ï¼Œå¹¶æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„æ•°æ®é€‰æ‹©æ–¹æ³•ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

#### ï¼ˆ1ï¼‰ç†è®ºæ´å¯Ÿï¼š**Flatter Tokens æ›´æœ‰ä»·å€¼**
- ä½œè€…é€šè¿‡ç†è®ºåˆ†æå’Œå®è¯éªŒè¯å‘ç°ï¼šå½“ç›®æ ‡æ¨¡å‹ï¼ˆtarget modelï¼‰å¯¹æŸä¸ª token çš„é¢„æµ‹åˆ†å¸ƒæ›´â€œå¹³å¦â€ï¼ˆå³æ¥è¿‘å‡åŒ€åˆ†å¸ƒï¼Œlow confidenceï¼‰æ—¶ï¼Œè¯¥ token å¯¹æå‡ acceptance rate çš„æ½œåŠ›æ›´å¤§ã€‚
- ç›¸åï¼Œé‚£äº›é¢„æµ‹åˆ†å¸ƒå°–é”ï¼ˆsharp, high confidenceï¼‰çš„ token å¾ˆå¿«å°±ä¼šé¥±å’Œï¼ˆsaturateï¼‰ï¼Œå¯¹åç»­è®­ç»ƒè´¡çŒ®æå°ã€‚

#### ï¼ˆ2ï¼‰æå‡ºæ–°åº¦é‡ï¼š**Flatness**
- å®šä¹‰äº†ä¸€ä¸ªç®€å•è€Œæœ‰æ•ˆçš„ token é‡è¦æ€§åº¦é‡â€”â€”**flatness**ï¼Œå³ç›®æ ‡æ¨¡å‹è¾“å‡ºåˆ†å¸ƒ $ p $ ä¸å‡åŒ€åˆ†å¸ƒ $ U $ ä¹‹é—´çš„ **cosine similarity**ï¼š
  $$
  \text{flatness}(t) = \cos(p_t, U)
  $$
- é«˜ flatness è¡¨ç¤ºåˆ†å¸ƒæ›´å¹³å¦ï¼Œå…·æœ‰æ›´å¤§çš„ä¼˜åŒ–ç©ºé—´ï¼ˆheadroomï¼‰ã€‚

#### ï¼ˆ3ï¼‰æå‡ºæ–°æ–¹æ³•ï¼š**SFDDï¼ˆSample-level-flatness-based Dataset Distillationï¼‰**
- å°† token-level çš„ flatness èšåˆä¸º **sample-level-flatness**ï¼ˆå–å¹³å‡å€¼ï¼‰ã€‚
- åœ¨è®­ç»ƒå‰è¿›è¡Œä¸€æ¬¡ç¦»çº¿æ‰“åˆ†ï¼ŒæŒ‰ flatness æ’åºåä¿ç•™é«˜ä»·å€¼æ ·æœ¬ï¼Œè¿‡æ»¤ä½ä»·å€¼æ ·æœ¬ã€‚
- æµç¨‹ç®€æ´ï¼š
  1. ç”¨ target model å¯¹æ‰€æœ‰æ ·æœ¬åšä¸€æ¬¡å‰å‘ä¼ æ’­ï¼›
  2. è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„ sample-level-flatnessï¼›
  3. ä¿ç•™ top-k% çš„æ ·æœ¬ç”¨äºè®­ç»ƒ draft modelã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ•ˆç‡** | åªéœ€ 50% æ•°æ®å³å¯å®ç°è¶…è¿‡ 2Ã— çš„è®­ç»ƒåŠ é€Ÿï¼Œä¸”æœ€ç»ˆæ¨ç†é€Ÿåº¦æŸå¤± <4% |
| **é€šç”¨æ€§** | flatness ä»…ä¾èµ– target modelï¼Œå¯ç¦»çº¿è®¡ç®—ï¼Œæ— éœ€ warm-up draft model |
| **æœ‰æ•ˆæ€§** | æ˜¾è‘—ä¼˜äºå…¶ä»–å¸¸è§æ•°æ®é€‰æ‹©æŒ‡æ ‡ï¼ˆå¦‚ entropyã€top-1 probã€marginã€PPL ç­‰ï¼‰ |
| **æ­£äº¤æ€§** | ä¸å…·ä½“ loss å‡½æ•°è®¾è®¡æ­£äº¤ï¼Œå¯æ— ç¼é›†æˆåˆ°ç°æœ‰ SD æ¡†æ¶ï¼ˆå¦‚ EAGLEï¼‰ä¸­ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **è®­ç»ƒæ•°æ®**ï¼š`ShareGPT` æ•°æ®é›†ï¼ˆç»è¿‡è¿‡æ»¤ï¼‰
- **è¯„ä¼°ä»»åŠ¡**ï¼ˆ5ä¸ªä¸‹æ¸¸ä»»åŠ¡ï¼‰ï¼š
  - `GSM8K`ï¼ˆæ•°å­¦æ¨ç†ï¼‰
  - `Alpaca`ï¼ˆæŒ‡ä»¤éµå¾ªï¼‰
  - `MT-Bench`ï¼ˆå¤šè½®å¯¹è¯è´¨é‡ï¼‰
  - `CNN/DM`ï¼ˆæ–‡æœ¬æ‘˜è¦ï¼‰
  - `Natural Questions (NQ)`ï¼ˆå¼€æ”¾é—®ç­”ï¼‰

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **æ¨¡å‹é…ç½®**
- **Target Model**ï¼š`LLaMA3-8B-Instruct`
- **Draft Model**ï¼šè½»é‡çº§å•å±‚ Transformerï¼ˆç±»ä¼¼ EAGLE-2 è®¾ç½®ï¼‰
- **è®­ç»ƒæ¡†æ¶**ï¼šåŸºäº `EAGLE-2` çš„è®­ç»ƒæµç¨‹

#### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Speedup** | æ¨ç†å¢™é’Ÿæ—¶é—´åŠ é€Ÿæ¯”ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰ |
| **Average Acceptance Length ($\ell$)** | æ¯æ¬¡éªŒè¯å‘¨æœŸå¹³å‡æ¥å—çš„ draft token æ•°é‡ï¼ˆåæ˜  acceptance rateï¼‰ |
| **Training Time** | æ€»è®­ç»ƒè€—æ—¶ï¼ˆå«æ•°æ®ç­›é€‰å¼€é”€ï¼Œç”¨äºè¡¡é‡æ•ˆç‡ï¼‰ |

#### **æ•°æ®ä¿ç•™ç‡ï¼ˆRetain Ratioï¼‰**
- ä¸»è¦æµ‹è¯• 30% ~ 100%ï¼Œé‡ç‚¹åˆ†æ 50% å’Œ 70%

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿æ–¹æ³• | æ‰€ç”¨æŒ‡æ ‡ |
|---------|--------|
| **No Filter** | ä½¿ç”¨å…¨éƒ¨æ•°æ® |
| **Random Filtering** | éšæœºä¿ç•™éƒ¨åˆ†æ•°æ® |
| **Entropy** | è¾“å‡ºåˆ†å¸ƒç†µå€¼ï¼ˆè¶Šé«˜è¶Šä¸ç¡®å®šï¼‰ |
| **Top-1 Probability** | æœ€å¤§æ¦‚ç‡å€¼ï¼ˆè¶Šä½è¶Šä¸ç¡®å®šï¼‰ |
| **Margin** | top-1 ä¸ top-2 æ¦‚ç‡å·® |
| **Energy Score** | åŸºäº logits çš„ä¸ç¡®å®šæ€§è¯„åˆ† |
| **Perplexity (PPL)** | æ•´ä½“å›°æƒ‘åº¦ï¼ˆè¶Šé«˜è¶Šéš¾ï¼‰ |

> æ‰€æœ‰åŸºäºé‡è¦æ€§çš„æ–¹æ³•å‡ä¿ç•™â€œé«˜ä¸ç¡®å®šæ€§â€æ ·æœ¬ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆ50% æ•°æ®ä¿ç•™ç‡ï¼‰**

| æ–¹æ³• | å¹³å‡ Speedup | ç›¸æ¯” Full Data æŸå¤± |
|------|---------------|---------------------|
| **No Filter (Full Data)** | 2.49Ã— | â€” |
| **Random Filtering** | 2.20Ã— | â†“11.6% |
| **Top-1 Probability (Best Baseline)** | 2.23Ã— | â†“10.4% |
| **SFDD (Ours)** | **2.41Ã—** | **â†“3.2%** |

> âœ… **ç»“è®º**ï¼šSFDD ç”¨ä¸€åŠæ•°æ®è¾¾åˆ°äº†æ¥è¿‘å…¨é‡è®­ç»ƒçš„æ•ˆæœï¼Œæ¨ç†é€Ÿåº¦ä»…ä¸‹é™çº¦ 4%ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å…¨é¢å¯¹æ¯”ï¼ˆTable 1ï¼‰**

- åœ¨æ‰€æœ‰ 5 ä¸ªä»»åŠ¡ä¸Šï¼Œ**SFDD å‡æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿æ–¹æ³•**ã€‚
- åœ¨ `GSM8K` ä¸Šï¼ŒSFDD è¾¾åˆ° **2.69Ã— speedup**ï¼Œæ¥è¿‘å…¨é‡è®­ç»ƒçš„ 2.71Ã—ã€‚
- åœ¨ `Alpaca` ä¸Šç”šè‡³ç•¥å¾®è¶…è¶Šå…¨é‡è®­ç»ƒï¼ˆ2.66Ã— vs 2.71Ã—ï¼‰ï¼Œè¡¨æ˜è¿‡æ»¤å¯èƒ½å»é™¤äº†å™ªå£°æˆ–å†—ä½™æ ·æœ¬ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### ï¼ˆ1ï¼‰ä¸åŒæ•°æ®ä¿ç•™ç‡ä¸‹çš„è¡¨ç°ï¼ˆTable 2ï¼‰

| ä¿ç•™ç‡ | æ–¹æ³• | å¹³å‡ Speedup |
|-------|------|--------------|
| 70% | SFDD | **2.44Ã—** |
| 60% | SFDD | 2.39Ã— |
| 50% | SFDD | 2.41Ã— |
| 40% | SFDD | 2.39Ã— |
| 30% | SFDD | 2.33Ã— |

> ğŸ”¹ å³ä½¿åªä¿ç•™ **30%** æ•°æ®ï¼ŒSFDD ä»èƒ½è¾¾åˆ° **2.33Ã—** åŠ é€Ÿï¼Œè¿œè¶…éšæœºè¿‡æ»¤ï¼ˆ2.14Ã—ï¼‰ã€‚

#### ï¼ˆ2ï¼‰æç«¯ä½èµ„æºåœºæ™¯ï¼ˆTable 3ï¼š5%, 10%, 20%ï¼‰

| ä¿ç•™ç‡ | æ–¹æ³• | å¹³å‡ Speedup |
|-------|------|--------------|
| 5% | Random | 1.68Ã— |
| 5% | **SFDD** | **1.82Ã—** (+8.3%) |
| 10% | Random | 2.01Ã— |
| 10% | **SFDD** | **2.07Ã—** |
| 20% | Random | 2.06Ã— |
| 20% | **SFDD** | **2.23Ã—** |

> âœ… è¡¨æ˜ flatness æ˜¯ä¸€ç§**é²æ£’ä¸”æœ‰æ•ˆ**çš„ token ä»·å€¼æŒ‡ç¤ºå™¨ï¼Œå³ä½¿åœ¨æä½æ•°æ®ä¸‹ä¾ç„¶æœ‰æ•ˆã€‚

#### ï¼ˆ3ï¼‰è®­ç»ƒæ•ˆç‡åˆ†æï¼ˆFigure 4ï¼‰

- åœ¨ 50% æ•°æ®ä¸‹ï¼Œ**è®­ç»ƒæ—¶é—´ä» 58,227s ç¼©çŸ­è‡³ 28,787s**ï¼Œå®ç° **2.02Ã— è®­ç»ƒåŠ é€Ÿ**ã€‚
- åŒ…å«æ•°æ®ç­›é€‰å¼€é”€ï¼ˆçº¦ 2,242sï¼‰ï¼Œä»è¿œä½äºè®­ç»ƒèŠ‚çœçš„æ—¶é—´ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **å¹¶éæ‰€æœ‰ token éƒ½åŒç­‰é‡è¦**ï¼š  
   ç›®æ ‡æ¨¡å‹é¢„æµ‹è¶Šâ€œå¹³å¦â€çš„ tokenï¼Œè¶Šèƒ½å¸¦æ¥ acceptance rate çš„æå‡ï¼Œæ˜¯é«˜è´¨é‡è®­ç»ƒä¿¡å·ã€‚

2. **Flatness æ˜¯ä¸€ä¸ªå¯é ä¸”é«˜æ•ˆçš„åº¦é‡**ï¼š  
   ä»…ä¾èµ– target model è¾“å‡ºï¼Œå¯ç¦»çº¿è®¡ç®—ï¼Œæ— éœ€ draft model å‚ä¸ï¼Œé€‚åˆå¤§è§„æ¨¡é¢„å¤„ç†ã€‚

3. **SFDD æå¤§æå‡è®­ç»ƒæ•ˆç‡**ï¼š  
   ç”¨ 50% æ•°æ®å³å¯è·å¾—æ¥è¿‘å…¨é‡è®­ç»ƒçš„æ¨ç†æ€§èƒ½ï¼ŒåŒæ—¶å®ç° **2Ã— ä»¥ä¸Šè®­ç»ƒåŠ é€Ÿ**ã€‚

4. **ä¼˜äºä¼ ç»Ÿä¸ç¡®å®šæ€§æŒ‡æ ‡**ï¼š  
   flatness åœ¨è¿‡æ»¤ä½ä»·å€¼æ ·æœ¬æ–¹é¢æ˜¾è‘—ä¼˜äº entropyã€top-1 prob ç­‰å¸¸ç”¨æŒ‡æ ‡ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **ä¾èµ– target model çš„è¾“å‡ºç‰¹æ€§**ï¼š  
   è‹¥ target model æœ¬èº«è¾“å‡ºè¿‡äºé›†ä¸­æˆ–ç¨€ç–ï¼Œflatness åˆ†å¸ƒå¯èƒ½ä¸ç†æƒ³ã€‚

2. **æœªè€ƒè™‘ä¸Šä¸‹æ–‡åŠ¨æ€å˜åŒ–**ï¼š  
   å½“å‰ flatness æ˜¯é™æ€æ‰“åˆ†ï¼Œæœªå»ºæ¨¡ draft model è®­ç»ƒè¿‡ç¨‹ä¸­çš„åŠ¨æ€å¯¹é½è¿‡ç¨‹ã€‚

3. **èšåˆæ–¹å¼è¾ƒç®€å•**ï¼š  
   sample-level-flatness ä½¿ç”¨å¹³å‡å€¼ï¼Œæœªæ¥å¯æ¢ç´¢åŠ æƒæˆ–å…¶ä»–èšåˆç­–ç•¥ã€‚

4. **token-level filtering å½“å‰æ— æ•ˆ**ï¼š  
   å› æ ‡å‡†è®­ç»ƒæ¡†æ¶æ— æ³•è·³è¿‡ masked token çš„å‰å‘/åå‘ä¼ æ’­ï¼Œæ•…æœªé‡‡ç”¨ token-level è¿‡æ»¤ï¼ˆè§ Appendix F.6ï¼‰ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **åŠ¨æ€æ•°æ®é€‰æ‹©ç­–ç•¥**ï¼š  
   åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ ¹æ® draft model çš„å­¦ä¹ çŠ¶æ€åŠ¨æ€è°ƒæ•´æ•°æ®æƒé‡ã€‚

2. **æ‰©å±•è‡³å…¶ä»–æ¶æ„**ï¼š  
   å°† flatness åº”ç”¨äºéè‡ªå›å½’ã€flow-based æˆ– diffusion ç±»ç”Ÿæˆæ¨¡å‹çš„ speculative decodingã€‚

3. **ç»“åˆå¼ºåŒ–å­¦ä¹ è®­ç»ƒ**ï¼š  
   åœ¨ GTOã€PPO ç­‰ RL-based SD æ–¹æ³•ä¸­å¼•å…¥ flatness å¼•å¯¼çš„ curriculum learningã€‚

4. **æ¢ç´¢æ›´ç»†ç²’åº¦è¿‡æ»¤æœºåˆ¶**ï¼š  
   è‹¥æœªæ¥æ”¯æŒ token-skipping è®­ç»ƒæ¡†æ¶ï¼Œåˆ™ flatness-based token-level filtering å°†æå…·æ½œåŠ›ã€‚

---

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> æœ¬æ–‡æ­ç¤ºäº†â€œ**flatter tokens are more valuable**â€è¿™ä¸€å…³é”®ç°è±¡ï¼Œæå‡º **flatness** åº¦é‡ä¸ **SFDD** æ•°æ®è’¸é¦æ–¹æ³•ï¼Œåœ¨ä¿æŒå‡ ä¹ç›¸åŒæ¨ç†åŠ é€Ÿèƒ½åŠ›çš„å‰æä¸‹ï¼Œå®ç°äº† **2Ã— ä»¥ä¸Šçš„è®­ç»ƒåŠ é€Ÿ**ï¼Œä¸ºé«˜æ•ˆ Speculative Decoding æä¾›äº†å…¨æ–°çš„æ•°æ®è§†è§’ã€‚

</details>

---

### 5. [OWLEYE: Zero-Shot Learner for Cross-Domain Graph Data Anomaly Detection](https://arxiv.org/abs/2601.19102)

**Authors**: Lecheng Zheng, Dongqi Fu, Zihao Li, Jingrui He  
**Category**: cs.LG  
**Published**: 2026-01-28  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.19102v1  

#### Abstract
Graph data is informative to represent complex relationships such as transactions between accounts, communications between devices, and dependencies among machines or processes. Correspondingly, graph anomaly detection (GAD) plays a critical role in identifying anomalies across various domains, incl...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# OWLEYE: Zero-Shot Learner for Cross-Domain Graph Data Anomaly Detection è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„ **Graph Anomaly Detection (GAD)** æ–¹æ³•å¤§å¤šéµå¾ªâ€œone model for one datasetâ€èŒƒå¼ï¼Œç¼ºä¹è·¨åŸŸæ³›åŒ–èƒ½åŠ›ã€‚æ–°å…´çš„â€œone-for-allâ€é€šç”¨æ¨¡å‹ï¼ˆå¦‚ ARC å’Œ UNPromptï¼‰è™½ç„¶å°è¯•è§£å†³æ­¤é—®é¢˜ï¼Œä½†ä»é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
1. **è·¨åŸŸç‰¹å¾è¯­ä¹‰ä¸ä¸€è‡´**ï¼šä¸åŒé¢†åŸŸå›¾æ•°æ®çš„èŠ‚ç‚¹å±æ€§ç»´åº¦å’Œè¯­ä¹‰å·®å¼‚å¤§ï¼Œéš¾ä»¥å¯¹é½ã€‚
2. **ç¼ºä¹æŒç»­å­¦ä¹ èƒ½åŠ›**ï¼šæ— æ³•åœ¨ä¸é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹å¢é‡æ•´åˆæ–°å›¾çš„çŸ¥è¯†ã€‚
3. **ä¾èµ–å°‘é‡æ ‡ç­¾è¿›è¡Œå¾®è°ƒ**ï¼šå¤šæ•°æ–¹æ³•éœ€è¦ç›®æ ‡å›¾ä¸Šçš„å°‘é‡æ ‡æ³¨æ•°æ®å®ç° few-shot å­¦ä¹ ï¼Œä½†åœ¨å®é™…ä¸­å¼‚å¸¸æ ‡æ³¨æˆæœ¬é«˜ä¸”ä¸å¯é ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šOWLEYE
ä½œè€…æå‡º **OWLEYE**ï¼Œä¸€ç§å…¨æ–°çš„é›¶æ ·æœ¬ï¼ˆzero-shotï¼‰è·¨åŸŸå›¾å¼‚å¸¸æ£€æµ‹æ¡†æ¶ï¼Œå…·å¤‡ä»¥ä¸‹ä¸‰ä¸ªæ ¸å¿ƒåˆ›æ–°æ¨¡å—ï¼š

#### ï¼ˆ1ï¼‰Cross-Domain Feature Alignment Module
- åˆ©ç”¨ **pairwise distance statistics** å¯¹æ¥è‡ªä¸åŒå›¾çš„èŠ‚ç‚¹ç‰¹å¾è¿›è¡Œå½’ä¸€åŒ–ä¸å¯¹é½ã€‚
- åœ¨ä¿æŒå„å›¾è‡ªèº«è¯­ä¹‰å®Œæ•´æ€§çš„åŒæ—¶ï¼Œå°†å¼‚æ„ç‰¹å¾æ˜ å°„åˆ°å…±äº«è¾“å…¥ç©ºé—´ã€‚
- é¿å…äº†ä¼ ç»Ÿ PCA/SVD ç­‰é™ç»´æ–¹æ³•ç ´ååŸå§‹ç»“æ„æ¨¡å¼çš„é—®é¢˜ã€‚

#### ï¼ˆ2ï¼‰Multi-Domain Multi-Pattern Dictionary Learning
- æ„å»ºä¸€ä¸ªå¯æ‰©å±•çš„ **pattern dictionary** æ¥å­˜å‚¨å¤šä¸ªæºå›¾ä¸­çš„æ­£å¸¸è¡Œä¸ºæ¨¡å¼ã€‚
- åˆ†åˆ«æå– **attribute-level** å’Œ **structure-level** è¡¨å¾ï¼Œå¹¶ä»ä¸­éšæœºé‡‡æ ·ä»£è¡¨æ€§æ¨¡å¼å­˜å…¥å­—å…¸ã€‚
- æ”¯æŒæ¨¡å‹æ— éœ€é‡è®­å³å¯é€šè¿‡æ·»åŠ æ–°æ¨¡å¼å®ç°**æŒç»­æ¼”åŒ–ï¼ˆcontinual learningï¼‰**ã€‚

#### ï¼ˆ3ï¼‰Truncated Attention-Based Reconstruction Module
- è®¾è®¡åŸºäºæˆªæ–­æ³¨æ„åŠ›æœºåˆ¶çš„é‡æ„æ¨¡å—ï¼Œç”¨äºä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆin-context learningï¼‰ã€‚
- åœ¨é‡æ„è¿‡ç¨‹ä¸­è‡ªåŠ¨è¿‡æ»¤æ½œåœ¨å¼‚å¸¸èŠ‚ç‚¹çš„å½±å“ï¼Œä»…åˆ©ç”¨æœ€å¯ä¿¡çš„â€œä¼ªæ”¯æŒèŠ‚ç‚¹â€è¿›è¡Œé‡å»ºã€‚
- å®ç°å®Œå…¨æ— ç›‘ç£çš„ zero-shot æ¨ç†ï¼Œæ— éœ€ä»»ä½•ç›®æ ‡å›¾æ ‡ç­¾ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | OWLEYE | ARC / UNPrompt |
|------|--------|----------------|
| è·¨åŸŸå¯¹é½æ•ˆæœ | âœ… æ˜¾è‘—æå‡å¯¹é½è´¨é‡ï¼Œä¿ç•™å…³é”®å¯†åº¦æ¨¡å¼ | âŒ ARC åˆ†ç¦»å›¾ï¼›UNPrompt æ‰°ä¹±å¯†åº¦å…³ç³» |
| æ˜¯å¦éœ€æ ‡ç­¾ | âœ… å®Œå…¨ zero-shot | âš ï¸ å¤šæ•°éœ€ few-shot å¾®è°ƒ |
| å¯æŒç»­å­¦ä¹  | âœ… æ”¯æŒåŠ¨æ€æ›´æ–° pattern dictionary | âŒ ä¸æ”¯æŒå¢é‡å­¦ä¹  |
| æ³›åŒ–èƒ½åŠ› | âœ… åœ¨æœªè§å›¾ä¸Šè¡¨ç°æœ€ä¼˜ | âš ï¸ æ€§èƒ½æ³¢åŠ¨è¾ƒå¤§ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **è®­ç»ƒé›† $ \mathcal{T}_{\text{train}} $**: PubMed, CiteSeer, Questions, YelpChi  
  ï¼ˆæ¶µç›–ç¤¾äº¤ç½‘ç»œã€å¼•ç”¨ç½‘ç»œã€ç”µå•†è¯„è®ºç­‰å¤šé¢†åŸŸï¼‰
- **æµ‹è¯•é›† $ \mathcal{T}_{\text{test}} $**: Cora, Flickr, ACM, BlogCatalog, Facebook, Weibo, Reddit, Amazon  
  ï¼ˆå…±8ä¸ªçœŸå®ä¸–ç•Œå›¾æ•°æ®é›†ï¼Œå«æ³¨å…¥æˆ–çœŸå®å¼‚å¸¸ï¼‰

> å®éªŒä¹ŸéªŒè¯äº†ä¸åŒ train/test åˆ’åˆ†ä¸‹çš„é²æ£’æ€§ï¼ˆè§ Appendix B.2ï¼‰ã€‚

### å®éªŒè®¾ç½®
- **ä»»åŠ¡è®¾å®š**ï¼šZero-shot å’Œ 10-shot setting ä¸‹çš„èŠ‚ç‚¹çº§å¼‚å¸¸æ£€æµ‹ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **AUPRC**ï¼ˆArea Under Precision-Recall Curveï¼‰â€”â€”é‡ç‚¹å…³æ³¨ç¨€ç–å¼‚å¸¸åœºæ™¯ä¸‹çš„æ€§èƒ½ã€‚
  - **AUROC**ï¼ˆArea Under ROC Curveï¼‰
- **é‡å¤æ¬¡æ•°**ï¼šæ‰€æœ‰å®éªŒè¿è¡Œ 5 æ¬¡å–å‡å€¼ Â± æ ‡å‡†å·®ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | æ–¹æ³• |
|------|------|
| **Supervised (10-shot)** | BWGNN, GHRN |
| **Unsupervised (zero-shot)** | DOMINANT, SLGAD, TAM, CARE |
| **One-for-All Generalist Models** | ARC, UNPrompt |
| **Proposed** | **OWLEYE** |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆAUPRC å¹³å‡å€¼ï¼‰

| æ–¹æ³• | Average AUPRC (Zero-Shot) |
|------|----------------------------|
| DOMINANT | 24.46% |
| CARE | 28.72% |
| ARC | 30.74% |
| **OWLEYE (Ours)** | **36.17%** âœ… |

> OWLEYE æ¯”å½“å‰æœ€ä½³åŸºçº¿ **ARC æå‡è¶…è¿‡ 5%**ï¼Œä¸”ä¸ºçº¯ zero-shot æ–¹æ³•ã€‚

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ
- **è¶…è¶Šç›‘ç£æ–¹æ³•**ï¼šå³ä½¿åœ¨æä¾› 10 ä¸ªæ ‡ç­¾çš„ 10-shot è®¾ç½®ä¸‹ï¼ŒOWLEYE ä»ä¼˜äº BWGNN å’Œ GHRNï¼Œåœ¨ 6/8 æ•°æ®é›†ä¸Šå–å¾—æ›´é«˜ AUPRCã€‚
- **æ˜¾è‘—ä¼˜äºå…¶ä»– zero-shot æ–¹æ³•**ï¼š
  - åœ¨ Weibo ä¸Šè¾¾åˆ° **60.90% AUPRC**ï¼Œè¿œè¶…ç¬¬äºŒå ARC çš„ 64.18%ï¼ˆä½†æ³¨æ„ï¼šARC ä½¿ç”¨å¾®è°ƒï¼‰ã€‚
  - åœ¨ Amazon ä¸Šè¾¾åˆ° **62.20% AUPRC**ï¼Œå¤§å¹…é¢†å…ˆäº ARC çš„ 20.48%ã€‚
- **AUROC åŒæ ·é¢†å…ˆ**ï¼šå¹³å‡ AUROC è¾¾ **75.42%**ï¼Œä¼˜äº ARC çš„ 74.04%ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
æ¶ˆèä¸‰ç§æ ¸å¿ƒç»„ä»¶åæ€§èƒ½ä¸‹é™æ˜æ˜¾ï¼š

| å˜ä½“ | Average AUPRC | ç›¸å¯¹ä¸‹é™ |
|------|---------------|----------|
| OWLEYE (Full) | 36.17% | â€”â€” |
| OWLEYE-N (æ— ç‰¹å¾å¯¹é½) | ~34.08% | â†“2.09% |
| OWLEYE-S (æ— ç»“æ„æ¨¡å¼) | ~35.18% | â†“0.99% |
| OWLEYE-T (æ ‡å‡†æ³¨æ„åŠ›) | ~34.08% | â†“2.09% |

> ç»“æœè¡¨æ˜ï¼š**ç‰¹å¾å¯¹é½ã€ç»“æ„æ¨¡å¼å»ºæ¨¡ã€æˆªæ–­æ³¨æ„åŠ›**ä¸‰è€…ç¼ºä¸€ä¸å¯ã€‚

æ­¤å¤–ï¼Œcase study éªŒè¯äº†ï¼š
- **æŒç»­å­¦ä¹ èƒ½åŠ›**ï¼šç›´æ¥å‘ dictionary æ·»åŠ æ–°å›¾çš„ patternï¼Œæ— éœ€å¾®è°ƒå³å¯æå‡æ€§èƒ½ï¼ˆè§ Table 3ï¼‰ã€‚
- **å­—å…¸è§„æ¨¡å½±å“**ï¼šå½“ `nsup > 200` åæ€§èƒ½è¶‹äºé¥±å’Œï¼Œè¯´æ˜å­˜åœ¨æ”¶ç›Šé€’å‡ç‚¹ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **æœ‰æ•ˆçš„è·¨åŸŸç‰¹å¾å¯¹é½æ˜¯æ„å»ºé€šç”¨ GAD æ¨¡å‹çš„åŸºç¡€**ï¼šOWLEYE çš„ç»Ÿè®¡å¯¹é½ç­–ç•¥æœ‰æ•ˆè§£å†³äº†å¼‚æ„ç‰¹å¾ç©ºé—´é—®é¢˜ã€‚
2. âœ… **ç»“æ„ä¿¡æ¯å¯¹è¯†åˆ«ä¼ªè£…å¼‚å¸¸è‡³å…³é‡è¦**ï¼šä»…ä¾èµ–å±æ€§å¯èƒ½å¯¼è‡´è¯¯åˆ¤ï¼Œè€Œç»“æ„æ¨¡å¼èƒ½æ•æ‰æ‹“æ‰‘å¼‚å¸¸ã€‚
3. âœ… **pattern dictionary æ˜¯å®ç° zero-shot å’ŒæŒç»­å­¦ä¹ çš„å…³é”®è®¾è®¡**ï¼šçŸ¥è¯†å¯ç§¯ç´¯ã€å¯å¤ç”¨ã€å¯æ‰©å±•ã€‚
4. âœ… **æˆªæ–­æ³¨æ„åŠ›æœºåˆ¶å¢å¼ºäº†é²æ£’æ€§**ï¼šé¿å…å¼‚å¸¸èŠ‚ç‚¹æ±¡æŸ“é‡æ„è¿‡ç¨‹ï¼Œæå‡æ£€æµ‹å‡†ç¡®æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **å¯¹æç«¯åˆ†å¸ƒåç§»æ•æ„Ÿ**ï¼šå½“è®­ç»ƒé›†ä¸­ç¼ºå¤±æ•´ä¸ªé¢†åŸŸï¼ˆå¦‚ç§»é™¤ YelpChiï¼‰ï¼Œåœ¨åŒåŸŸæµ‹è¯•å›¾ Amazon ä¸Š AUPRC ä¸‹é™çº¦ 4.6%ï¼Œå°½ç®¡æ•´ä½“ä»å…·ç«äº‰åŠ›ã€‚
- **å­—å…¸å®¹é‡æœ‰é™åˆ¶**ï¼šè™½ç„¶æ”¯æŒæ‰©å±•ï¼Œä½†è¿‡å¤§çš„å­—å…¸å¯èƒ½å¸¦æ¥è®¡ç®—å¼€é”€ã€‚
- **å‡è®¾å¤§å¤šæ•°èŠ‚ç‚¹æ­£å¸¸**ï¼šç”¨äºæ„å»ºâ€œä¼ªæ”¯æŒé›†â€çš„å‰æåœ¨æé«˜å¼‚å¸¸ç‡ä¸‹å¯èƒ½å¤±æ•ˆï¼ˆå°½ç®¡å®éªŒæ˜¾ç¤ºåœ¨ 20% å¼‚å¸¸ç‡ä¸‹ä»ç¨³å¥ï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **Multi-modal Graph Foundation Model**ï¼šèåˆæ–‡æœ¬ã€æ—¶é—´åºåˆ—ã€å›¾åƒç­‰å¤šæ¨¡æ€ä¿¡å·ï¼Œæ„å»ºæ›´å¼ºå¤§çš„å›¾åŸºç¡€æ¨¡å‹ã€‚
- **å¼±ç›‘ç£/å™ªå£°æ ‡ç­¾ä¸‹çš„å­¦ä¹ **ï¼šé€‚åº”ç°å®ä¸–ç•Œä¸­æ ‡æ³¨ä¸å‡†ç¡®æˆ–ç¨€ç–çš„æƒ…å†µã€‚
- **åŠ¨æ€å›¾ä¸Šçš„åœ¨çº¿å¼‚å¸¸æ£€æµ‹**ï¼šæ‰©å±•è‡³æ—¶åºå›¾åœºæ™¯ï¼Œæ”¯æŒå®æ—¶æ›´æ–°ä¸æ¨ç†ã€‚
- **å¯è§£é‡Šæ€§å¢å¼º**ï¼šè¿›ä¸€æ­¥æŒ–æ˜ attention map çš„è¯­ä¹‰å«ä¹‰ï¼Œè¾…åŠ©äººå·¥ç ”åˆ¤ã€‚

---

> **æ€»ç»“**ï¼šOWLEYE æˆåŠŸæ„å»ºäº†ä¸€ä¸ª**å¯æ³›åŒ–ã€å¯æŒç»­ã€æ— éœ€æ ‡ç­¾**çš„è·¨åŸŸå›¾å¼‚å¸¸æ£€æµ‹æ¡†æ¶ï¼Œä¸ºè¿ˆå‘çœŸæ­£çš„ **Graph Foundation Model for Anomaly Detection** å¥ å®šäº†åšå®åŸºç¡€ã€‚

</details>

---

### 6. [OSIRIS: Bridging Analog Circuit Design and Machine Learning with Scalable Dataset Generation](https://arxiv.org/abs/2601.19439)

**Authors**: Giuseppe Chiari, Michele Piccoli, Davide Zoni  
**Category**: cs.LG  
**Published**: 2026-01-28  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.19439v1  

#### Abstract
The automation of analog integrated circuit (IC) design remains a longstanding challenge, primarily due to the intricate interdependencies among physical layout, parasitic effects, and circuit-level performance. These interactions impose complex constraints that are difficult to accurately capture a...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šOSIRIS: Bridging Analog Circuit Design and Machine Learning with Scalable Dataset Generation

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
æ¨¡æ‹Ÿé›†æˆç”µè·¯ï¼ˆAnalog ICï¼‰è®¾è®¡è‡ªåŠ¨åŒ–é•¿æœŸé¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯**åç«¯ç‰©ç†å¸ƒå±€é˜¶æ®µ**ã€‚è¯¥é˜¶æ®µå¯¹å¯„ç”Ÿæ•ˆåº”ï¼ˆparasiticsï¼‰ã€å™¨ä»¶åŒ¹é…ã€å‡ ä½•çº¦æŸæä¸ºæ•æ„Ÿï¼Œå¯¼è‡´è®¾è®¡é«˜åº¦ä¾èµ–ä¸“å®¶ç»éªŒï¼Œæµç¨‹è¿­ä»£ä¸”è€—æ—¶ã€‚æ­¤å¤–ï¼Œç¼ºä¹å…¬å¼€ã€é«˜è´¨é‡ã€å¸¦ç‰©ç†éªŒè¯çš„**å¤§è§„æ¨¡æ¨¡æ‹Ÿç”µè·¯å¸ƒå±€æ•°æ®é›†**ï¼Œä¸¥é‡åˆ¶çº¦äº†æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰åœ¨è¯¥é¢†åŸŸçš„åº”ç”¨ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº† **OSIRIS** â€”â€” ä¸€ä¸ªå¯æ‰©å±•çš„ã€ç«¯åˆ°ç«¯çš„æ¨¡æ‹ŸICå¸ƒå±€æ•°æ®é›†ç”Ÿæˆæ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°ç‚¹å¦‚ä¸‹ï¼š

- **OSIRIS æ¡†æ¶**ï¼š  
  æ„å»ºäº†ä¸€ä¸ªç³»ç»Ÿæ€§çš„ã€å¯è¿­ä»£çš„å¸ƒå±€æ¢ç´¢æµæ°´çº¿ï¼Œèƒ½å¤Ÿä»ç”µè·¯ç½‘è¡¨ï¼ˆnetlistï¼‰å‡ºå‘ï¼Œè‡ªåŠ¨ç”Ÿæˆå¤§é‡ç¬¦åˆåˆ¶é€ è§„åˆ™ï¼ˆDRC-cleanï¼‰å’Œé€»è¾‘ä¸€è‡´æ€§ï¼ˆLVS-verifiedï¼‰çš„ç‰©ç†å¸ƒå±€ï¼ˆGDSï¼‰ï¼Œå¹¶é™„å¸¦è¯¦ç»†çš„æ€§èƒ½è¯„ä¼°æŠ¥å‘Šï¼ˆQoSï¼‰ã€‚

- **å¯è¿­ä»£çš„æ¢ç´¢ç­–ç•¥**ï¼š  
  ä¸ä¼ ç»Ÿâ€œå•æ¬¡é€šè¿‡â€ï¼ˆsingle-passï¼‰çš„å¸ƒå±€å·¥å…·ä¸åŒï¼ŒOSIRIS æ”¯æŒ**è¿­ä»£å¼è®¾è®¡ç©ºé—´æ¢ç´¢**ï¼ˆiterative explorationï¼‰ï¼Œå…è®¸åŸºäºåå¸ƒå±€ä»¿çœŸåé¦ˆï¼ˆpost-layout feedbackï¼‰ä¸æ–­ä¼˜åŒ–å¸ƒå±€ã€‚

- **å¼€æºå¤§è§„æ¨¡æ•°æ®é›†å‘å¸ƒ**ï¼š  
  åˆ©ç”¨ OSIRIS ç”Ÿæˆå¹¶å…¬å¼€å‘å¸ƒäº†åŒ…å« **87,100 ä¸ªå¸ƒå±€å˜ä½“**çš„æ•°æ®é›†ï¼Œè¦†ç›–5ç§å…¸å‹æ¨¡æ‹Ÿç”µè·¯ï¼ˆå¦‚ Miller OTAã€Ahuja OTA ç­‰ï¼‰ï¼Œæ˜¯é¦–ä¸ªä¸“æ³¨äº**åç«¯å¸ƒå±€é˜¶æ®µ**çš„å¤§è§„æ¨¡ã€å¸¦å¯„ç”Ÿæ„ŸçŸ¥ï¼ˆparasitic-awareï¼‰çš„å…¬å¼€æ•°æ®é›†ã€‚

- **å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰é©±åŠ¨çš„ä¼˜åŒ–åŸºçº¿**ï¼š  
  æä¾›äº†ä¸€ä¸ªåŸºäº RL çš„ä¼˜åŒ–æ¡†æ¶ï¼Œç”¨äºåœ¨ OSIRIS æµç¨‹ä¸­è¿›è¡Œæ™ºèƒ½å¸ƒå±€æœç´¢ï¼Œè¯æ˜äº† ML å¯æœ‰æ•ˆæŒ‡å¯¼å¸ƒå±€ä¼˜åŒ–ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ ALIGN, MAGICALï¼‰ | OSIRIS |
|------|-------------------------------|--------|
| **æµç¨‹æ¨¡å¼** | å•æ¬¡ç”Ÿæˆï¼Œæ— åé¦ˆé—­ç¯ | æ”¯æŒè¿­ä»£ä¼˜åŒ–ï¼Œå¯é›†æˆåå¸ƒå±€åé¦ˆ |
| **æ•°æ®äº§å‡º** | ä¸»è¦è¾“å‡º netlist æˆ–å•ä¸€å¸ƒå±€ | å¤§è§„æ¨¡ã€å¤šæ ·åŒ–å¸ƒå±€å˜ä½“ + å®Œæ•´ QoS æŒ‡æ ‡ |
| **ML å‹å¥½æ€§** | ä¸ç›´æ¥æ”¯æŒ ML è®­ç»ƒ | æ•°æ®ç»“æ„ä¸“ä¸º ML è®¾è®¡ï¼ˆé…å¯¹ä»¿çœŸã€å…ƒæ•°æ®ï¼‰ |
| **å¼€æ”¾æ€§** | éƒ¨åˆ†å¼€æºï¼Œä½†æ•°æ®æœ‰é™ | å®Œå…¨å¼€æºä»£ç  + å¤§è§„æ¨¡æ•°æ®é›† |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
- **è‡ªç ”æ•°æ®é›†**ï¼šç”± OSIRIS åœ¨ **Skywater 130nm PDK** ä¸Šç”Ÿæˆï¼ŒåŒ…å«ä»¥ä¸‹5ç±»ç”µè·¯ï¼š
  - Miller OTA
  - Ahuja OTA
  - Feed Forward OTA
  - 5-Transistors OTA
  - Low-Pass Filter (LPF)

- æ•°æ®æ€»é‡ï¼š**87,100 ä¸ª DRC/LVS éªŒè¯é€šè¿‡çš„å¸ƒå±€å˜ä½“**ï¼Œæ€»å¤§å°çº¦ 5GBã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
#### è¯„ä¼°æŒ‡æ ‡
1. **PEX Score**ï¼š  
   è¡¡é‡å¯„ç”Ÿæ•ˆåº”å½±å“çš„å…³é”®æŒ‡æ ‡ï¼Œå®šä¹‰ä¸ºå‰å¸ƒå±€ï¼ˆpre-layoutï¼‰ä¸åå¸ƒå±€ï¼ˆpost-layoutï¼‰ä»¿çœŸç»“æœä¹‹é—´çš„ **RMSEï¼ˆå•ä½ï¼šVï¼‰**ã€‚å€¼è¶Šå°è¶Šå¥½ã€‚
   $$
   \text{pscore} = \sqrt{\frac{1}{K}\sum_{i=1}^{K}(pre_i - post_i)^2}
   $$

2. **Area**ï¼š  
   å¸ƒå±€æ€»é¢ç§¯ï¼ˆå•ä½ï¼šÎ¼mÂ²ï¼‰ï¼Œåæ˜ èŠ¯ç‰‡æˆæœ¬å’Œé›†æˆå¯†åº¦ã€‚å€¼è¶Šå°è¶Šå¥½ã€‚

3. **Acquisition Time**ï¼š  
   ç”Ÿæˆæœ€ç»ˆä¼˜åŒ–å¸ƒå±€æ‰€éœ€çš„æ€»æ—¶é—´ï¼ˆå°æ—¶ï¼‰ã€‚

#### å®éªŒè®¾ç½®
- æ‰€æœ‰å¸ƒå±€ç”Ÿæˆå‡é€šè¿‡ OSIRIS æµæ°´çº¿å®Œæˆï¼ŒåŒ…å«ï¼š
  - **Fingers Permutation**ï¼šæšä¸¾æ™¶ä½“ç®¡æŒ‡çŠ¶ç»“æ„ï¼ˆfingersï¼‰çš„åˆæ³•ç»„åˆã€‚
  - **Random / RL-based Variant Generation**ï¼šåœ¨åŸºçº¿å¸ƒå±€åŸºç¡€ä¸Šè¿›è¡Œç©ºé—´æ‰°åŠ¨æ¢ç´¢ã€‚
- ä»¿çœŸä½¿ç”¨ **Ngspice**ï¼ŒDRC/LVS éªŒè¯ä½¿ç”¨ **Magic** å’Œ **Netgen**ã€‚
- RL æ¨¡å‹è®­ç»ƒä½¿ç”¨ **Proximal Policy Optimization (PPO)** å’Œ **REINFORCE**ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **MAGICAL**ï¼šå¼€æºå…¨è‡ªåŠ¨æ¨¡æ‹Ÿå¸ƒå±€ç³»ç»Ÿã€‚
- **ALIGN**ï¼šå¦ä¸€ä¸»æµå¼€æºæ¨¡æ‹Ÿå¸ƒå±€æ¡†æ¶ã€‚
- **Random Exploration**ï¼šOSIRIS å†…ç½®çš„éšæœºæ‰°åŠ¨ç­–ç•¥ï¼Œä½œä¸ºå¼±åŸºçº¿ã€‚
- **RL-driven Methodology**ï¼šæœ¬æ–‡æå‡ºçš„ä¸¤å±‚ RL ä¼˜åŒ–ç­–ç•¥ï¼ˆå¤–å±‚æœç´¢ finger é…ç½®ï¼Œå†…å±‚ä¼˜åŒ–ç»„ä»¶ä½ç½®ï¼‰ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 3ï¼‰
| Circuit | æ–¹æ³• | pscore (V) â†“ | Area (Î¼mÂ²) â†“ | Time (hh:mm:ss) |
|--------|------|---------------|----------------|------------------|
| **Miller** | MAGICAL | 0.142 | 1836 | 00:01:08 |
| | Random | 0.0012 | 1770 | 195:00:00 |
| | **RL (Ours)** | **0.00069** | **1733** | **96:00:00** |
| **Ahuja** | MAGICAL | 0.315 | 1906 | 00:01:08 |
| | Random | 0.120 | 1805 | 191:00:00 |
| | **RL (Ours)** | **0.120** | **1797** | **70:00:00** |
| **Feed Forward** | MAGICAL | 0.210 | 806 | 00:01:18 |
| | Random | 0.037 | 798 | 156:00:00 |
| | **RL (Ours)** | **0.024** | **768.5** | **62:00:00** |
| **5-Transistors** | MAGICAL | 0.093 | 183 | 00:00:48 |
| | Random | 0.050 | 266.3 | 162:00:00 |
| | **RL (Ours)** | **0.047** | 444.5 | **50:00:00** |
| **LPF** | MAGICAL | *å¤±è´¥* | *å¤±è´¥* | 00:01:20 |
| | Random | 0.102 | 7916 | 187:00:00 |
| | **RL (Ours)** | **0.064** | **6635** | **67:00:00** |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **PEX Score æ˜¾è‘—é™ä½**ï¼š  
  RL æ–¹æ³•åœ¨æ‰€æœ‰ç”µè·¯ä¸­å‡å–å¾—æœ€ä½çš„ pscoreï¼Œ**æ¯” MAGICAL å’Œ ALIGN ä½ä¸€ä¸ªæ•°é‡çº§ä»¥ä¸Š**ï¼Œè¡¨æ˜å…¶èƒ½æ›´æœ‰æ•ˆåœ°æŠ‘åˆ¶å¯„ç”Ÿæ•ˆåº”ã€‚
- **é¢ç§¯è¡¨ç°ä¼˜å¼‚**ï¼š  
  åœ¨ Millerã€Feed Forward å’Œ LPF ä¸Šï¼ŒRL æ–¹æ³•ç”Ÿæˆçš„å¸ƒå±€é¢ç§¯æœ€å°ï¼›ä»…åœ¨ 5-Transistors ä¸Šç•¥å¤§ï¼Œä½†æ¢æ¥äº†æ›´å¥½çš„ç”µæ°”æ€§èƒ½ã€‚
- **è¿è¡Œæ—¶é—´å¤§å¹…ç¼©çŸ­**ï¼š  
  ç›¸æ¯” Random æ¢ç´¢ï¼ŒRL æ–¹æ³•**å¹³å‡å‡å°‘çº¦ 50â€“70% çš„è¿è¡Œæ—¶é—´**ï¼Œè¯´æ˜å…¶æ¢ç´¢æ•ˆç‡æ›´é«˜ã€‚
- **é²æ£’æ€§å¼º**ï¼š  
  æˆåŠŸç”Ÿæˆäº† MAGICAL æ— æ³•å¤„ç†çš„ LPF ç”µè·¯å¸ƒå±€ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆéšå«äºè®¾è®¡ä¸­ï¼‰
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»æµç¨‹è®¾è®¡å¯æ¨æ–­ï¼š
- **Fingers Permutation çš„æœ‰æ•ˆæ€§**ï¼šé€šè¿‡æšä¸¾åˆæ³• finger ç»„åˆï¼Œæ˜¾è‘—å¢åŠ äº†å¸ƒå±€å¤šæ ·æ€§ã€‚
- **RL vs Random çš„ä¼˜åŠ¿**ï¼šRL èƒ½ä¸»åŠ¨å­¦ä¹ â€œæœ‰ç›Šâ€çš„å¸ƒå±€å˜æ¢ç­–ç•¥ï¼Œè€Œéšæœºæ–¹æ³•éœ€å¤§é‡è¯•é”™ã€‚
- **ä¸¤å±‚ RL æ¶æ„çš„å¿…è¦æ€§**ï¼šåˆ†åˆ«ä¼˜åŒ– finger é…ç½®å’Œç©ºé—´å¸ƒå±€ï¼Œå®ç°äº†æ›´å…¨é¢çš„è®¾è®¡ç©ºé—´æ¢ç´¢ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **å¤§è§„æ¨¡ã€é«˜è´¨é‡çš„å¸ƒå±€æ•°æ®é›†æ˜¯æ¨åŠ¨ ML åœ¨æ¨¡æ‹Ÿåç«¯è®¾è®¡ä¸­åº”ç”¨çš„å…³é”®å‰æ**ï¼ŒOSIRIS æˆåŠŸå¡«è¡¥äº†è¿™ä¸€ç©ºç™½ã€‚
2. **è¿­ä»£å¼ã€åé¦ˆé©±åŠ¨çš„å¸ƒå±€ä¼˜åŒ–æµç¨‹ä¼˜äºä¼ ç»Ÿçš„å•æ¬¡ç”ŸæˆèŒƒå¼**ï¼Œå°¤å…¶åœ¨å¤„ç†å¯„ç”Ÿæ•æ„Ÿçš„æ¨¡æ‹Ÿç”µè·¯æ—¶ã€‚
3. **å¼ºåŒ–å­¦ä¹ å¯ä»¥æœ‰æ•ˆå¼•å¯¼å¸ƒå±€ç©ºé—´æ¢ç´¢**ï¼Œåœ¨æ›´çŸ­æ—¶é—´å†…æ‰¾åˆ°å¯„ç”Ÿæ›´å°ã€é¢ç§¯æ›´ä¼˜çš„å¸ƒå±€æ–¹æ¡ˆã€‚
4. **ç”Ÿæˆçš„æ•°æ®é›†å¯ç”¨äºå¤šç§ ML ä»»åŠ¡**ï¼Œå¦‚å¸ƒå±€é¢„æµ‹ã€ç»„ä»¶çº§ç”Ÿæˆï¼ˆå¦‚æ–‡ä¸­ç”¨ LLM ç”Ÿæˆç”µå®¹å¸ƒå±€ï¼‰ã€æ€§èƒ½ä¼°è®¡ç­‰ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä»…æ”¯æŒ **Skywater 130nm PDK**ï¼Œå°šæœªéªŒè¯å…¶ä»–å·¥è‰ºèŠ‚ç‚¹ã€‚
- æ”¯æŒçš„ç”µè·¯ç±»å‹æœ‰é™ï¼ˆ5 ç§ï¼‰ï¼Œé€šç”¨æ€§æœ‰å¾…æ‰©å±•ã€‚
- RL è®­ç»ƒä¾èµ–å¤§é‡ä»¿çœŸï¼Œè®¡ç®—å¼€é”€ä»è¾ƒé«˜ã€‚
- å¸ƒå±€å˜æ¢ç›®å‰ä»…é™äº finger æ•°å’Œç»„ä»¶å¹³ç§»ï¼Œæœªæ¶µç›–æ—‹è½¬ã€å¤æ‚å¸ƒçº¿ç­‰é«˜çº§æ“ä½œã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³æ›´å¤šç”µè·¯å®¶æ—ï¼ˆå¦‚ ADCã€PLLï¼‰å’Œå…ˆè¿›å·¥è‰ºèŠ‚ç‚¹ï¼ˆå¦‚ 40nm, 28nmï¼‰ã€‚
- å¼•å…¥æ›´ä¸°å¯Œçš„å¸ƒå±€å˜æ¢ç®—å­ï¼ˆå¦‚æ—‹è½¬ã€é•œåƒã€å¤šå±‚å¸ƒçº¿ï¼‰ã€‚
- æ”¯æŒè·¨ PDK çš„è¿ç§»å­¦ä¹ ï¼ˆtransfer learningï¼‰ã€‚
- æ¢ç´¢åŸºäº GNNã€Diffusion Model ç­‰æ›´å…ˆè¿›çš„ ML æ¨¡å‹è¿›è¡Œå¸ƒå±€ç”Ÿæˆä¸ä¼˜åŒ–ã€‚

> **æ€»ç»“**ï¼šOSIRIS æ˜¯é¦–ä¸ªå°†**å¯æ‰©å±•æ•°æ®é›†ç”Ÿæˆ**ä¸**ML é©±åŠ¨ä¼˜åŒ–**æ·±åº¦èåˆçš„æ¨¡æ‹Ÿ IC åç«¯è®¾è®¡æ¡†æ¶ï¼Œä¸ºå®ç°çœŸæ­£çš„ç«¯åˆ°ç«¯æ¨¡æ‹Ÿè®¾è®¡è‡ªåŠ¨åŒ–å¥ å®šäº†é‡è¦åŸºç¡€ã€‚

</details>

---

### 7. [Learn and Verify: A Framework for Rigorous Verification of Physics-Informed Neural Networks](https://arxiv.org/abs/2601.19818)

**Authors**: Kazuaki Tanaka, Kohei Yatabe  
**Category**: cs.LG  
**Published**: 2026-01-28  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.19818v1  

#### Abstract
The numerical solution of differential equations using neural networks has become a central topic in scientific computing, with Physics-Informed Neural Networks (PINNs) emerging as a powerful paradigm for both forward and inverse problems. However, unlike classical numerical methods that offer estab...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Learn and Verify: A Framework for Rigorous Verification of Physics-Informed Neural Networks*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³äº†ä»€ä¹ˆé—®é¢˜

å½“å‰åŸºäº **Physics-Informed Neural Networks (PINNs)** çš„å¾®åˆ†æ–¹ç¨‹æ±‚è§£å™¨è™½ç„¶åœ¨ç§‘å­¦è®¡ç®—ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å­˜åœ¨ä¸€ä¸ªæ ¹æœ¬æ€§ç¼ºé™·ï¼š**ç¼ºä¹ä¸¥æ ¼çš„è¯¯å·®ç•Œï¼ˆrigorous error boundsï¼‰å’Œæ•°å­¦å¯éªŒè¯æ€§**ã€‚ç”±äºè®­ç»ƒè¿‡ç¨‹å…·æœ‰éšæœºæ€§ï¼ˆå¦‚æƒé‡åˆå§‹åŒ–ã€é‡‡æ ·ç­–ç•¥ï¼‰ï¼Œå…¶è¾“å‡ºæ— æ³•æä¾›åƒä¼ ç»Ÿæ•°å€¼æ–¹æ³•ï¼ˆå¦‚æœ‰é™å…ƒæ³•ï¼‰é‚£æ ·çš„æ”¶æ•›ä¿è¯ï¼Œå¯¼è‡´ç»“æœå¯é æ€§éš¾ä»¥è®¤è¯ã€‚

æ­¤å¤–ï¼Œå·²æœ‰ç†è®ºåˆ†æå¤šä¸ºæ¸è¿‘æ€§è´¨æˆ–ç†æƒ³å‡è®¾ä¸‹çš„ä¼°è®¡ï¼Œ**æ— æ³•è½¬åŒ–ä¸ºæœºå™¨å¯éªŒè¯çš„è¯æ˜**ã€‚

---

### âœ… æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯

ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **â€œLearn and Verifyâ€** çš„ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œæ—¨åœ¨ä¸º PINNs æä¾›**å¯è®¡ç®—ã€æ•°å­¦ä¸Šä¸¥æ ¼ã€ä¸”æœºå™¨å¯éªŒè¯çš„è¯¯å·®ç•Œ**ã€‚

#### æ ¸å¿ƒæ€æƒ³ï¼š
- **Learn é˜¶æ®µ**ï¼šä½¿ç”¨ PINNs å­¦ä¹ ç›®æ ‡ ODE çš„è¿‘ä¼¼è§£ï¼Œå¹¶è¿›ä¸€æ­¥æ„é€ ä¸€å¯¹ **sub-solutionï¼ˆä¸‹è§£ï¼‰** å’Œ **super-solutionï¼ˆä¸Šè§£ï¼‰**ï¼Œä½¿å¾—çœŸå®è§£è¢«ä¸¥æ ¼å¤¹åœ¨ä¸¤è€…ä¹‹é—´ã€‚
- **Verify é˜¶æ®µ**ï¼šåˆ©ç”¨ **interval arithmeticï¼ˆåŒºé—´ç®—æœ¯ï¼‰** å¯¹è¿™å¯¹å‡½æ•°è¿›è¡Œ**ä¸¥æ ¼éªŒè¯**ï¼Œç¡®è®¤å®ƒä»¬åœ¨æ•´ä¸ªæ—¶é—´åŸŸå†…æ»¡è¶³æ‰€éœ€çš„å¾®åˆ†ä¸ç­‰å¼ï¼Œä»è€Œå½¢æˆå¯¹çœŸå®è§£çš„**rigorous enclosureï¼ˆä¸¥æ ¼åŒ…ç»œï¼‰**ã€‚

#### åˆ›æ–°æŠ€æœ¯ç»„ä»¶ï¼š
1. **Variation Learning**ï¼š
   - æ„é€ åå·®ç½‘ç»œ $ v_\theta(t), w_\phi(t) \geq 0 $ï¼Œå®šä¹‰ï¼š
     $$
     u_{\text{low}}(t) = u_0(t) - v_\theta(t),\quad u_{\text{high}}(t) = u_0(t) + w_\phi(t)
     $$
   - è¾“å‡ºå±‚é‡‡ç”¨ç¼©æ”¾åçš„ sigmoid å‡½æ•° $ \epsilon \cdot \sigma(\cdot) $ï¼Œç¡®ä¿åå·®ä¸è¶…è¿‡é¢„è®¾å®¹å¿åº¦ $ \epsilon $ï¼Œå®ç°ç»“æ„åŒ–çš„è¯¯å·®æ§åˆ¶ã€‚

2. **Doubly Smoothed Maximum (DSM) Loss**ï¼š
   - ç”¨äºè®­ç»ƒ sub/super-solutionsï¼Œå¹³æ»‘åœ°é€¼è¿‘æœ€å¤§è¿åé¡¹ï¼š
     $$
     \text{DSM}_{c_1,c_2}[g(t)] = c_2 \log \sum_{t \in S} \left(1 + \exp\left(\frac{g(t)}{c_1}\right)\right)
     $$
   - ç»“åˆ Softplus å’Œ Log-Sum-Expï¼Œé¿å…éå…‰æ»‘æŸå¤±å¸¦æ¥çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼ŒåŒæ—¶å¼•å…¥â€œè½¯è¾¹ç•Œæ•ˆåº”â€ï¼Œå¢å¼ºè®­ç»ƒç¨³å®šæ€§ã€‚

3. **Interval Arithmetic + Adaptive Subdivision**ï¼š
   - åœ¨ Verify é˜¶æ®µï¼Œå°†æ—¶é—´åŸŸåˆ’åˆ†ä¸ºå­åŒºé—´ï¼Œåœ¨æ¯ä¸ªå­åŒºé—´ä¸Šç”¨ interval arithmetic ä¸¥æ ¼è®¡ç®—æ®‹å·®èŒƒå›´ã€‚
   - è‹¥æŸåŒºé—´åˆ¤å®šä¸ºâ€œä¸ç¡®å®šâ€ï¼ˆindeterminateï¼‰ï¼Œåˆ™é€’å½’äºŒåˆ†ç»†åŒ–ï¼Œç›´åˆ°æ‰€æœ‰åŒºé—´å‡å¯æ˜ç¡®åˆ¤æ–­æ˜¯å¦æ»¡è¶³ä¸ç­‰å¼ã€‚

---

### âœ… ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **å¯é æ€§** | æä¾›**æ•°å­¦ä¸Šå¯è¯æ˜çš„è¯¯å·®ç•Œ**ï¼Œè€Œéå¯å‘å¼ä¼°è®¡ï¼Œé€‚ç”¨äºé«˜é£é™©ç§‘å­¦åº”ç”¨ã€‚ |
| **é€šç”¨æ€§** | ä¸ä¾èµ–é—­å¼è§£æˆ–å‚è€ƒæ•°å€¼è§£ï¼Œå¯ç”¨äºæ— è§£æè§£çš„é—®é¢˜ï¼ˆå¦‚ generalized logistic, Riccatiï¼‰ã€‚ |
| **å¯éªŒè¯æ€§** | æ•´ä¸ªéªŒè¯æµç¨‹æ˜¯**æœºå™¨å¯æ‰§è¡Œçš„**ï¼Œæ„æˆä¸€ç§â€œæœºå™¨å¯éªŒè¯çš„è¯æ˜â€ã€‚ |
| **çµæ´»æ€§** | Learn é˜¶æ®µå¯ç”¨ä»»æ„ç¥ç»ç½‘ç»œæ¶æ„ï¼ˆæ–‡ä¸­ä½¿ç”¨ SIRENï¼‰ï¼ŒVerify é˜¶æ®µç‹¬ç«‹äºå­¦ä¹ æ–¹å¼ã€‚ |
| **å¤„ç†å¥‡å¼‚æ€§** | èƒ½å¤Ÿé€šè¿‡å˜é‡å˜æ¢å’Œæ‰©å±• sub-solution æ¥**ä¸¥æ ¼åŒ…å›´æœ‰é™æ—¶é—´çˆ†ç ´ï¼ˆfinite-time blow-upï¼‰çš„æ—¶é—´ç‚¹**ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### âœ… ä½¿ç”¨çš„ ODE æ•°æ®é›†ï¼ˆé—®é¢˜ï¼‰

è®ºæ–‡åœ¨ä¸‰ä¸ªéçº¿æ€§ ODE ä¸Šè¿›è¡Œäº†å®éªŒï¼š

1. **Classical Logistic Equation**  
   $$
   \dot{u} = r u (1 - u/k),\quad u(0)=a
   $$
   - å‚æ•°ï¼š$ r=1, k=2, a=0.5, T=10 $
   - æœ‰è§£æè§£ï¼Œå¯ç”¨äºå®šé‡è¯¯å·®è¯„ä¼°ã€‚

2. **Generalized Logistic Equation**  
   $$
   \dot{u} = r(t) u (1 - u/k(t)),\quad r(t)=r_0(1+\sin(\omega t)),\ k(t)=k_0(\log(1+t)+1)
   $$
   - æ—¶é—´ä¾èµ–ç³»æ•°ï¼Œ**æ— æ˜¾å¼è§£æè§£**ã€‚
   - ä½¿ç”¨ MATLAB `ode45`ï¼ˆé«˜ç²¾åº¦è®¾ç½®ï¼‰ä½œä¸ºå‚è€ƒè§£ã€‚

3. **Riccati Equationï¼ˆBlow-up Caseï¼‰**  
   $$
   \dot{u} = t^2 + u^2,\quad u(0)=0
   $$
   - è§£åœ¨æœ‰é™æ—¶é—´å†…è¶‹äºæ— ç©·ï¼ˆblow-up at $ T_{\text{bu}} \approx 2 $ï¼‰
   - å±•ç¤ºæ¡†æ¶å¯¹å¥‡å¼‚æ€§çš„å¤„ç†èƒ½åŠ›ã€‚

---

### âœ… å®éªŒè®¾ç½®

| ç»„ä»¶ | è®¾ç½® |
|------|------|
| **ç½‘ç»œæ¶æ„** | SIRENï¼š4 éšè—å±‚ Ã— 30 ç¥ç»å…ƒï¼›æ¿€æ´»å‡½æ•°ä¸º sin |
| **è®­ç»ƒä¼˜åŒ–å™¨** | Adam |
| **Mini-batch size** | Step 1: 128ï¼›Step 2: 1280ï¼ˆregion-based samplingï¼‰ |
| **é‡‡æ ·ç­–ç•¥** | åŒºåŸŸåˆ†å±‚é‡‡æ ·ï¼ˆstratified samplingï¼‰ï¼Œ100 ä¸ªç­‰è·åŒºåŸŸ |
| **Loss å‚æ•°** | $ c_1 = 10^{-2}, c_2 = 10^{-3} $ |
| **æ­£åˆ™åŒ–é¡¹** | å¼•å…¥ç‰©ç†æ­£åˆ™é¡¹ $ L_{\text{phys}} $ æŠ‘åˆ¶ä¸ç¨³å®šè¡Œä¸ºï¼ˆåŸºäº $ \partial f/\partial u < 0 $ï¼‰ |
| **éªŒè¯å·¥å…·** | INTLABï¼ˆMATLAB çš„ interval arithmetic å·¥å…·ç®±ï¼‰ |
| **ä»£ç å…¬å¼€** | GitHub: https://github.com/Kazuaki-Tanaka/learn-and-verify-ode |

---

### âœ… è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Verification Success Rate** | æˆåŠŸé€šè¿‡ interval arithmetic éªŒè¯çš„æ¯”ä¾‹ï¼ˆå…³é”®æŒ‡æ ‡ï¼‰ |
| **Maximum Relative Error** | ä¸çœŸè§£çš„æœ€å¤§ç›¸å¯¹è¯¯å·®ï¼ˆä»…é™æœ‰è§£æè§£çš„æƒ…å†µï¼‰ |
| **Error Tolerance $ \epsilon $** | æ§åˆ¶ä¸Šä¸‹ç•Œå®½åº¦çš„å‚æ•°ï¼Œè¶Šå°è¡¨ç¤ºè¦æ±‚è¶Šé«˜ |
| **Blow-up Time Bounds** | å¯¹ Riccati æ–¹ç¨‹ç»™å‡ºçš„çˆ†ç ´æ—¶é—´ä¸Šä¸‹ç•Œ $[T, 1/u_{\text{low}}(T)]$ |

---

### âœ… åŸºçº¿æ–¹æ³•å¯¹æ¯”

æœ¬æ–‡æœªç›´æ¥ä¸å…¶ä»– PINN å˜ä½“ï¼ˆå¦‚ Deep Ritz, Deep BSDEï¼‰è¿›è¡Œç«¯åˆ°ç«¯æ€§èƒ½æ¯”è¾ƒï¼Œè€Œæ˜¯å¼ºè°ƒå…¶**ç‹¬ç‰¹ä»·å€¼åœ¨äºâ€œéªŒè¯èƒ½åŠ›â€**ï¼Œè¿™æ˜¯å…¶ä»–æ–¹æ³•æ‰€ä¸å…·å¤‡çš„ã€‚

- ä¼ ç»Ÿ PINNsï¼šåªèƒ½è¾“å‡ºå•ä¸€è¿‘ä¼¼æ›²çº¿ï¼Œæ— æ³•æä¾›è¯¯å·®ç•Œã€‚
- æ•°å€¼æ–¹æ³•ï¼ˆå¦‚ ode45ï¼‰ï¼šè™½ç²¾ç¡®ä½†æ— ç†è®ºè¯¯å·®ç•Œï¼ˆé™¤éä¸“é—¨è®¾è®¡éªŒè¯ç®—æ³•ï¼‰ã€‚
- æœ¬æ–‡æ–¹æ³•ï¼šè¾“å‡ºçš„æ˜¯ä¸€ä¸ª**å‡½æ•°åŒºé—´** $[u_{\text{low}}, u_{\text{high}}]$ï¼Œå¹¶é™„å¸¦æ•°å­¦è¯æ˜è¯¥åŒºé—´åŒ…å«çœŸå®è§£ã€‚

å› æ­¤ï¼Œå…¶â€œåŸºçº¿â€å®ä¸º**æ— éªŒè¯æœºåˆ¶çš„ä¼ ç»Ÿ PINN æµç¨‹**ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### âœ… Classical Logistic Equation

- **æˆåŠŸéªŒè¯ç‡éš $ \epsilon $ å’Œè®­ç»ƒè½®æ¬¡å¢åŠ è€Œä¸Šå‡**ï¼ˆè§ Table Iï¼‰ï¼š
  - å½“ $ \epsilon = 2^{-5} $ï¼Œ4 å±‚ç½‘ç»œåœ¨ 200 è½®åå¯è¾¾ 98% æˆåŠŸç‡ã€‚
  - $ \epsilon = 2^{-8} $ æ—¶å…¨éƒ¨å¤±è´¥ â†’ è¡¨æ˜å½“å‰æ–¹æ³•ä»å—é™äºè¿‡ç´§å®¹å·®ã€‚
- **æ­£åˆ™åŒ–å‚æ•° $ \lambda_{\text{phys}} $ æ˜¾è‘—å½±å“æˆåŠŸç‡**ï¼š
  - $ \log_2(\lambda_{\text{phys}}) \geq -5.5 $ æ—¶æˆåŠŸç‡æ¥è¿‘ 100%ã€‚
  - å¼±æ­£åˆ™åŒ–ä¸‹å¤§é‡è§£é™·å…¥å±€éƒ¨æå°ï¼ŒéªŒè¯å¤±è´¥ã€‚
- **å¹³å‡æœ€å¤§ç›¸å¯¹è¯¯å·®çº¦ $ 10^{-2} \sim 10^{-1} $**ï¼Œä¸æ¡†æ¶ä¼°è®¡ä¸€è‡´ã€‚

> ğŸ“Š å›¾ 5 æ˜¾ç¤ºï¼šéšç€ $ \epsilon $ å‡å°ï¼Œresidual æ›´è¶‹è¿‘äºé›¶ä¸”ç¬¦å·æ­£ç¡®ï¼ŒéªŒè¯æ›´å®¹æ˜“é€šè¿‡ã€‚

---

### âœ… Generalized Logistic Equation

- **æ›´éš¾è®­ç»ƒ**ï¼Œéœ€è¦æ›´å¤š epoch æ‰èƒ½æ”¶æ•›ã€‚
- **æµ…å±‚ç½‘ç»œè¡¨ç°å·®**ï¼š2 å±‚ç½‘ç»œåœ¨ $ \epsilon \leq 2^{-5} $ ä¸‹å®Œå…¨æ— æ³•é€šè¿‡éªŒè¯ã€‚
- **4 å±‚ç½‘ç»œä¼˜äºæ›´æ·±ç½‘ç»œ**ï¼šå¯èƒ½å› è®­ç»ƒéš¾åº¦ä¸è¡¨è¾¾èƒ½åŠ›ä¹‹é—´çš„æƒè¡¡ã€‚
- **éªŒè¯æˆåŠŸç‡ä¸ºè‡ªåŠ¨è°ƒå‚æä¾›ä¾æ®**ï¼Œä¼˜äºäººå·¥è¯•é”™ã€‚

> ğŸ“Š å›¾ 8 æ˜¾ç¤ºï¼šå³ä½¿æ²¡æœ‰è§£æè§£ï¼Œä¹Ÿèƒ½æ„é€ å‡ºåˆç†åŒ…ç»œï¼Œä¸”æ®‹å·®ç¬¦å·ç¬¦åˆè¦æ±‚ã€‚

---

### âœ… Riccati Equationï¼ˆBlow-up Caseï¼‰

- **é¦–æ¬¡å®ç°äº†å¯¹æœ‰é™æ—¶é—´çˆ†ç ´çš„â€œrigorous enclosureâ€**ã€‚
- é€šè¿‡å˜é‡å˜æ¢ $ u = 1/(c - t)\varphi $ æ­£åˆ™åŒ–å¥‡ç‚¹ï¼Œåœ¨ $ t \in [0, 1.9375] $ ä¸Šè®­ç»ƒã€‚
- åˆ©ç”¨ analytically extended sub-solution å¾—åˆ° blow-up time ä¸Šç•Œï¼š
  $$
  T_{\text{bu}} \leq T + \frac{1}{u_{\text{low}}(T)}
  $$

| $ \epsilon $ | $ c $ | $ u_{\text{low}}(T) $ | Lower Bound | Upper Bound |
|--------------|--------|------------------------|-------------|-------------|
| $ 2^{-2} $   | 2.00   | 12.119                 | 1.9375      | 2.020       |
| $ 2^{-3} $   | 2.00   | 14.029                 | 1.9375      | 2.009       |
| $ 2^{-4} $   | 2.00   | 14.893                 | 1.9375      | 2.005       |

âœ… **ç»“è®º**ï¼šå‡å° $ \epsilon $ å¯æå‡ $ u_{\text{low}}(T) $ï¼Œä»è€Œæ”¶ç´§ä¸Šç•Œï¼ŒéªŒè¯æ•ˆæœæ›´å¥½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **â€œLearn and Verifyâ€ æ¡†æ¶é¦–æ¬¡å®ç°äº†å¯¹ PINNs è§£çš„æ•°å­¦å¯éªŒè¯æ€§**ï¼Œå¡«è¡¥äº†æ·±åº¦å­¦ä¹ ä¸å¯ä¿¡ç§‘å­¦è®¡ç®—ä¹‹é—´çš„é¸¿æ²Ÿã€‚
2. **sub- and super-solution + interval arithmetic** æ˜¯ä¸€ç§å¼ºå¤§ç»„åˆï¼Œèƒ½å°†é»‘ç›’æ¨¡å‹è¾“å‡ºè½¬åŒ–ä¸º**æœºå™¨å¯éªŒè¯çš„æ•°å­¦è¯æ˜**ã€‚
3. **DSM loss å’Œ variation learning** æ˜¾è‘—æå‡äº†è®­ç»ƒç¨³å®šæ€§å’ŒéªŒè¯æˆåŠŸç‡ã€‚
4. å³ä½¿åœ¨æ— è§£æè§£æˆ–å­˜åœ¨å¥‡å¼‚æ€§çš„æƒ…å†µä¸‹ï¼Œè¯¥æ¡†æ¶ä»èƒ½æä¾›**rigorous error bounds**ï¼Œå±•ç°å‡ºå¹¿æ³›é€‚ç”¨æ€§ã€‚
5. éªŒè¯è¿‡ç¨‹æœ¬èº«æˆæœ¬ä½ï¼ˆé€šå¸¸å‡ ç§’å®Œæˆï¼‰ï¼Œè¿œä½äºè®­ç»ƒæ—¶é—´ï¼Œé€‚åˆéƒ¨ç½²åéªŒè¯ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

1. **å¯¹è¯¯å·®å®¹å¿åº¦ $ \epsilon $ æ•æ„Ÿ**ï¼šå½“ $ \epsilon $ è¿‡å°æ—¶ï¼Œè®­ç»ƒéš¾ä»¥æ”¶æ•›ï¼ŒéªŒè¯å¤±è´¥ç‡é«˜ã€‚
2. **ä¾èµ–è‰¯å¥½åˆå§‹è¿‘ä¼¼è§£**ï¼šè‹¥ç¬¬ä¸€æ­¥çš„ $ u_0(t) $ åç¦»å¤ªå¤§ï¼Œåç»­éš¾ä»¥æ„é€ æœ‰æ•ˆåŒ…å›´ã€‚
3. **ç›®å‰ä»…é€‚ç”¨äº ODE**ï¼Œæ‰©å±•è‡³ PDE å°šéœ€è§£å†³æ›´é«˜ç»´åŒºé—´è¿ç®—å’Œå¤æ‚è¾¹ç•Œæ¡ä»¶ç­‰é—®é¢˜ã€‚
4. **interval arithmetic å¤©ç„¶ä¿å®ˆ**ï¼šå¯èƒ½å¯¼è‡´åŒ…ç»œè¿‡å®½ï¼Œå°¤å…¶åœ¨é«˜ç»´æˆ–å¼ºéçº¿æ€§æƒ…å†µä¸‹ã€‚
5. **è¶…å‚æ•°é€‰æ‹©ä»éœ€ç»éªŒ**ï¼šå¦‚ $ c_1, c_2, \lambda_{\text{phys}} $ ç­‰å°šæœªå®Œå…¨è‡ªåŠ¨åŒ–ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•è‡³ PDEs**ï¼šç»“åˆ verified PDE solversï¼ˆå¦‚åŸºäºå›ºå®šç‚¹å®šç†çš„æ–¹æ³•ï¼‰æ„å»ºç»Ÿä¸€æ¡†æ¶ã€‚
2. **è‡ªåŠ¨è¶…å‚æ•°è°ƒä¼˜**ï¼šåŸºäºéªŒè¯åé¦ˆåŠ¨æ€è°ƒæ•´ $ \epsilon $ã€ç½‘ç»œæ·±åº¦ã€æ­£åˆ™åŒ–å¼ºåº¦ç­‰ã€‚
3. **è”åˆä¼˜åŒ– sub/super-solutions ä¸å˜æ¢å‚æ•°**ï¼šä¾‹å¦‚å°† blow-up time ä¼°è®¡ä¹Ÿä½œä¸ºå¯è®­ç»ƒå˜é‡ã€‚
4. **GPU åŠ é€Ÿ interval arithmetic**ï¼šæå‡é«˜ç»´é—®é¢˜çš„éªŒè¯æ•ˆç‡ã€‚
5. **é›†æˆåˆ°ç§‘å­¦ ML pipeline**ï¼šä½œä¸ºæ ‡å‡†æ¨¡å—ç”¨äºæ¨¡å‹é€‰æ‹©ã€ä¸ç¡®å®šæ€§é‡åŒ–å’Œå®‰å…¨å†³ç­–æ”¯æŒã€‚

---

## æ€»ç»“

> âœ… **æœ¬è®ºæ–‡æå‡ºäº†é¦–ä¸ªå°† PINNs ä»â€œè¿‘ä¼¼æ±‚è§£å™¨â€å‡çº§ä¸ºâ€œå¯éªŒè¯æ±‚è§£å™¨â€çš„å®Œæ•´æ¡†æ¶â€”â€”Learn and Verifyã€‚**
>
> å®ƒä¸ä»…è§£å†³äº†ç¥ç»ç½‘ç»œæ±‚è§£å¾®åˆ†æ–¹ç¨‹ç¼ºä¹ä¸¥æ ¼è¯¯å·®ç•Œçš„é•¿æœŸéš¾é¢˜ï¼Œè¿˜å±•ç¤ºäº†å¦‚ä½•é€šè¿‡ **sub/super-solution æ„é€  + interval arithmetic éªŒè¯** å®ç°**æœºå™¨å¯éªŒè¯çš„æ•°å­¦è¯æ˜**ã€‚
>
> å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§éçº¿æ€§ ODE ä¸Šå‡èƒ½æˆåŠŸæ„é€ å‡ºåŒ…å«çœŸå®è§£çš„ä¸¥æ ¼åŒ…ç»œï¼Œå°¤å…¶åœ¨å¤„ç† blow-up ç­‰æŒ‘æˆ˜æ€§ç°è±¡æ—¶å±•ç°å‡ºç‹¬ç‰¹ä¼˜åŠ¿ã€‚
>
> å°½ç®¡ä»æœ‰æ”¹è¿›ç©ºé—´ï¼Œä½†è¿™ä¸€å·¥ä½œä¸º **trustworthy scientific machine learning** å¥ å®šäº†åšå®åŸºç¡€ã€‚

</details>

---

### 8. [Learning Adaptive Parallel Execution for Efficient Code Localization](https://arxiv.org/abs/2601.19568)

**Authors**: Ke Xu, Siyang Xiao, Ming Liang, Yichen Yu, Zhixiang Wang, Jingxuan Xu, Dajun Chen, Wei Jiang, Yong Li  
**Category**: cs.AI  
**Published**: 2026-01-28  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.19568v1  

#### Abstract
Code localization constitutes a key bottleneck in automated software development pipelines. While concurrent tool execution can enhance discovery speed, current agents demonstrate a 34.9\% redundant invocation rate, which negates parallelism benefits. We propose \textbf{FuseSearch}, reformulating pa...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLearning Adaptive Parallel Execution for Efficient Code Localization

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹è‡ªåŠ¨åŒ–è½¯ä»¶å¼€å‘ä¸­çš„**code localization**ç“¶é¢ˆå±•å¼€ç ”ç©¶ã€‚å½“å‰åŸºäºLLMçš„agentsåœ¨å®šä½ç›¸å…³ä»£ç å®ä½“ï¼ˆå¦‚æ–‡ä»¶ã€å‡½æ•°ï¼‰æ—¶ï¼Œé€šå¸¸é‡‡ç”¨**sequential tool execution**ï¼Œå³æ¯è½®äº¤äº’ä»…è°ƒç”¨ä¸€ä¸ªå·¥å…·ï¼ˆå¦‚`grep`, `read_file`ï¼‰ï¼Œå¯¼è‡´æœç´¢è¿‡ç¨‹å†—é•¿ä¸”æ•ˆç‡ä½ä¸‹ã€‚å°½ç®¡å¹¶è¡Œæ‰§è¡Œï¼ˆparallel executionï¼‰å¯æå‡ä¿¡æ¯å¯†åº¦ï¼Œä½†ç°æœ‰æ–¹æ³•å¸¸å› **å†—ä½™è°ƒç”¨**ï¼ˆredundant tool invocationsï¼‰è€Œæµªè´¹è®¡ç®—èµ„æºâ€”â€”ç ”ç©¶è¡¨æ˜ï¼Œå¼ºåˆ¶å¹¶è¡Œç­–ç•¥ä¸­é«˜è¾¾ **34.9%** çš„å·¥å…·è°ƒç”¨æ˜¯å†—ä½™çš„ã€‚

æ­¤å¤–ï¼Œå—é™äº**turn budget**ï¼ˆäº¤äº’è½®æ¬¡é™åˆ¶ï¼‰ï¼Œagentsæ˜“é™·å…¥â€œ**information starvation**â€å›°å¢ƒï¼šæœªå……åˆ†æ”¶é›†ä¸Šä¸‹æ–‡ä¾¿è€—å°½äº¤äº’æ¬¡æ•°ï¼Œä»è€Œç‰ºç‰²å‡†ç¡®ç‡ä»¥æ¢å–é€Ÿåº¦ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **FuseSearch**ï¼Œä¸€ç§é€šè¿‡**learned adaptive parallel execution**å®ç°é«˜æ•ˆä»£ç å®šä½çš„æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

- **Tool Efficiency ä½œä¸ºä¼˜åŒ–ç›®æ ‡**  
  å®šä¹‰äº†ä¸€ä¸ªæ–°çš„åº¦é‡æŒ‡æ ‡ **tool efficiency $e$**ï¼Œè¡¨ç¤ºæ¯æ¬¡å·¥å…·è°ƒç”¨å¸¦æ¥çš„**å”¯ä¸€ä¿¡æ¯å¢ç›Š**ï¼ˆunique information gainï¼‰å æ€»è°ƒç”¨æ•°çš„æ¯”ä¾‹ï¼š
  $$
  e = \frac{1}{k} \sum_{i=1}^{k} g_i, \quad g_i = \begin{cases}
  \frac{|E_i \setminus H|}{|E_i|} & \text{if } |E_i| > 0 \\
  0 & \text{otherwise}
  \end{cases}
  $$
  å…¶ä¸­ $E_i$ æ˜¯ç¬¬ $i$ æ¬¡è°ƒç”¨è¿”å›çš„å®ä½“é›†åˆï¼Œ$H$ æ˜¯å†å²å·²å‘ç°å®ä½“çš„å¹¶é›†ã€‚è¯¥æŒ‡æ ‡ç›´æ¥æƒ©ç½šå†—ä½™æ¢ç´¢ã€‚

- **åŒç›®æ ‡è”åˆä¼˜åŒ–æ¡†æ¶ï¼ˆDual-Objective Optimizationï¼‰**  
  å°†å®šä½ä»»åŠ¡å»ºæ¨¡ä¸ºåŒæ—¶ä¼˜åŒ– **localization quality**ï¼ˆF1 åˆ†æ•°ï¼‰å’Œ **search efficiency**ï¼ˆtool efficiency $e$ï¼‰çš„ä»»åŠ¡ï¼Œæ„å»ºå¤åˆå¥–åŠ±å‡½æ•°ç”¨äºå¼ºåŒ–å­¦ä¹ ï¼š
  $$
  R(T) = \alpha \cdot F1(T) + \gamma \cdot (F1(T) \cdot e(T))
  $$
  æ­¤è®¾è®¡ç¡®ä¿é«˜å¥–åŠ±ä»…å‡ºç°åœ¨â€œé«˜è´¨é‡+é«˜æ•ˆç‡â€çš„è½¨è¿¹ä¸Šï¼Œé¿å…ä½æ•ˆä½†å‡†ç¡®æˆ–é«˜æ•ˆä½†é”™è¯¯çš„è¡Œä¸ºã€‚

- **ä¸¤é˜¶æ®µè®­ç»ƒèŒƒå¼ï¼ˆSFT + RLï¼‰**  
  - **SFTé˜¶æ®µ**ï¼šä½¿ç”¨ç»è¿‡åŒé‡è¿‡æ»¤ï¼ˆdual-metric filteringï¼‰çš„é«˜è´¨é‡è½¨è¿¹è¿›è¡Œç›‘ç£å¾®è°ƒï¼Œç¡®ä¿åˆå§‹æ¨¡å‹å…·å¤‡è‰¯å¥½çš„å¹¶è¡Œèƒ½åŠ›å’Œæ•ˆç‡ã€‚
  - **RLé˜¶æ®µ**ï¼šé‡‡ç”¨ **Group Relative Policy Optimization (GRPO)** è¿›ä¸€æ­¥ä¼˜åŒ–ç­–ç•¥ï¼Œåœ¨ä¿æŒKLæ•£åº¦çº¦æŸçš„åŒæ—¶æœ€å¤§åŒ–å¤åˆå¥–åŠ±ã€‚

- **æç®€ä¸»ä¹‰å·¥å…·é›†ï¼ˆMinimalist Tool Setï¼‰**  
  ä»…ä¾èµ–ä¸‰ä¸ªè¯­è¨€æ— å…³ã€åªè¯»çš„å·¥å…·ï¼š
  - `grep`: æ­£åˆ™åŒ¹é…ä»£ç å†…å®¹
  - `glob`: è·¯å¾„æ¨¡å¼åŒ¹é…
  - `read_file`: è¯»å–æ–‡ä»¶å†…å®¹ï¼ˆå¯æŒ‡å®šè¡ŒèŒƒå›´ï¼‰
  
  ä¸ä¾èµ–ASTè§£æå™¨ã€ä»£ç å›¾ç­‰å¤æ‚åŸºç¡€è®¾æ–½ï¼Œæå‡äº†éƒ¨ç½²é€šç”¨æ€§å’Œç®€æ´æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | FuseSearch | ç°æœ‰æ–¹æ³• |
|------|----------|--------|
| æ‰§è¡Œæ–¹å¼ | è‡ªé€‚åº”åŠ¨æ€è°ƒæ•´å¹¶è¡Œå¹¿åº¦ | å›ºå®šå®½åº¦å¹¶è¡Œæˆ–ä¸²è¡Œ |
| æ•ˆç‡æ§åˆ¶ | æ˜¾å¼å»ºæ¨¡ tool efficiency å¹¶ä¼˜åŒ– | å¿½è§†å†—ä½™è°ƒç”¨æˆæœ¬ |
| æ¶æ„å¤æ‚åº¦ | æç®€ï¼Œæ— éœ€ä»£ç å›¾/AST | å¤šéœ€é¢„æ„å»ºé™æ€å›¾ï¼ˆå¦‚LocAgentï¼‰ |
| æ€§èƒ½è¡¨ç° | æ›´é«˜F1ã€æ›´å°‘turn/token/time | å‡†ç¡®ç‡ä¸æ•ˆç‡éš¾ä»¥å…¼é¡¾ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **ä¸»è¯„æµ‹é›†**ï¼š**SWE-bench Verified** (Jimenez et al., 2024)ï¼Œå…±386ä¸ªçœŸå®GitHub issueä¿®å¤æ ·æœ¬ã€‚
- **é¢å¤–éªŒè¯é›†**ï¼š**LocBench** (Chen et al., 2025)ï¼Œç”¨äºè·¨åŸºå‡†æ³›åŒ–èƒ½åŠ›æµ‹è¯•ã€‚
- **è®­ç»ƒæ•°æ®**ï¼šä»233ä¸ªé«˜è´¨é‡GitHubä»“åº“ä¸­æ„å»ºçº¦21Kæ ·æœ¬çš„ä»“åº“çº§å®šä½æ•°æ®é›†ï¼Œæ’é™¤å¼•å…¥å…¨æ–°æ–‡ä»¶/å‡½æ•°çš„patchã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### è¯„ä¼°ç»´åº¦
| ç±»åˆ« | æŒ‡æ ‡ | è¯´æ˜ |
|------|------|------|
| **å®šä½è´¨é‡** | File-level / Function-level **Precision**, **Recall**, **F1** | è¡¡é‡é¢„æµ‹ä¸çœŸå®ä¿®æ”¹ä½ç½®çš„é‡åˆåº¦ |
| **æœç´¢æ•ˆç‡** | **#Turn**ï¼ˆäº¤äº’è½®æ¬¡ï¼‰<br>**T(s)**ï¼ˆå¢™é’Ÿæ—¶é—´ï¼‰<br>**Tok.(k)**ï¼ˆtokenæ¶ˆè€—ï¼‰ | åæ˜ å»¶è¿Ÿä¸è®¡ç®—å¼€é”€ |
| **è¿‡ç¨‹æ•ˆç‡** | **Tool Efficiency $e$** | å†—ä½™è°ƒç”¨è¶Šå°‘ï¼Œ$e$è¶Šé«˜ |

#### æ¨¡å‹é…ç½®
- ä¸»å¹²æ¨¡å‹ï¼š**Qwen3-4B-Instruct** å’Œ **Qwen3-30B-A3B-Instruct**
- å¯¹æ¯”åŸºçº¿ï¼š
  - **Workflow-based**: Agentless (Xia et al., 2024)
  - **Agent-based**: LocAgent, CoSIL, RepoSearcher
- æ‰€æœ‰æ–¹æ³•å‡åœ¨ç›¸åŒç¡¬ä»¶ï¼ˆ8Ã—NVIDIA H20 GPUï¼‰ä¸‹è¿è¡Œï¼Œä½¿ç”¨vLLMåŠ é€Ÿæ¨ç†ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆSWE-bench Verifiedï¼‰

| æ–¹æ³• | File F1 (%) | Func F1 (%) | #Turn | T(s) | Tok.(k) |
|------|-------------|-------------|-------|------|---------|
| **FuseSearch-4B (train)** | **84.7** | **56.4** | **4.78** | **5.43** | **30.9** |
| RepoSearcher (Qwen3-4B) | 38.1 | 21.7 | 14.8 | 85.3 | 99.2 |
| Agentless (Haiku 4.5) | 54.5 | 31.8 | 2.00 | 7.32 | 10.6 |

> âœ… **æ€§èƒ½æå‡æ˜¾è‘—**ï¼š
> - æ–‡ä»¶çº§F1æå‡ **+46.6pp**
> - å‡½æ•°çº§F1æå‡ **+34.7pp**
> - èŠ‚çœ **67.7% turns**, **93.6% time**, **68.9% tokens**

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ

- åœ¨åŒç­‰backboneï¼ˆQwen3-4Bï¼‰ä¸‹ï¼Œ**FuseSearch (train)** æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼š
  - æ¯” **RepoSearcher** æå‡è¶… **45pp F1**
  - æ¯” **LocAgent** å‡å°‘ **67% turns** å’Œ **95% time**
- å³ä½¿ä¸æ›´å¼ºé—­æºæ¨¡å‹ï¼ˆå¦‚Claude Haiku 4.5ï¼‰ç›¸æ¯”ï¼Œ**FuseSearch-4B** è¾¾åˆ°ç›¸å½“ç”šè‡³æ›´ä¼˜çš„F1åˆ†æ•°ï¼ŒåŒæ—¶é€Ÿåº¦å¿« **10å€ä»¥ä¸Š**ã€‚

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰å¹¶è¡Œ vs ä¸²è¡Œæ‰§è¡Œï¼ˆTable 3ï¼‰
| æ¨¡å¼ | é˜¶æ®µ | File F1 | #Turn | Tok.(k) |
|------|------|--------|--------|--------|
| Sequential | SFT+RL | 78.82 | 7.52 | 59.4 |
| **Parallel** | **SFT+RL** | **84.65** | **5.60** | **30.9** |

> âœ”ï¸ å¹¶è¡Œæ‰§è¡Œä¸ä»…æé€Ÿï¼Œè¿˜å¸¦æ¥æ›´é«˜F1ï¼Œè¯æ˜â€œåŒæ­¥ä¿¡æ¯è·å–â€æœ‰åŠ©äºå†³ç­–ã€‚

#### ï¼ˆ2ï¼‰SFTæ•°æ®è¿‡æ»¤ç­–ç•¥ï¼ˆTable 4ï¼‰
| è¿‡æ»¤æ–¹å¼ | File F1 | Func F1 | $e$ | Tok.(k) |
|--------|--------|--------|-----|--------|
| æ— è¿‡æ»¤ | 75.44 | 43.52 | 55.77 | 60.7 |
| F1-only | 78.55 | 45.43 | 56.72 | 73.2 |
| $e$-only | 76.74 | 42.63 | 60.14 | 61.8 |
| **Joint (F1 + e)** | **78.86** | **47.94** | **62.03** | **54.8** |

> âœ”ï¸ **è”åˆè¿‡æ»¤** åŒæ—¶æå‡è´¨é‡ä¸æ•ˆç‡ï¼Œä¸ºåç»­RLæä¾›æ›´ä¼˜èµ·ç‚¹ã€‚

#### ï¼ˆ3ï¼‰å¥–åŠ±å‡½æ•°è®¾è®¡ï¼ˆTable 5ï¼‰
| å¥–åŠ±å½¢å¼ | File F1 | $e$ | T(s) | Tok.(k) |
|--------|--------|-----|------|--------|
| F1 only | 81.84 | 59.66 | 7.28 | 39.4 |
| F1 + e (additive) | 79.22 | 66.62 | 9.40 | 45.7 |
| **F1 + F1Â·e (multiplicative)** | **84.65** | **69.00** | **5.43** | **30.9** |

> âœ”ï¸ **ä¹˜æ³•å½¢å¼å¥–åŠ±** æœ€ä½³å¹³è¡¡è´¨é‡ä¸æ•ˆç‡ï¼Œé¿å…åŠ æ€§å¥–åŠ±å¯¼è‡´çš„ç²¾åº¦ä¸‹é™ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æ•ˆç‡æ„ŸçŸ¥è®­ç»ƒèƒ½è‡ªç„¶æå‡è´¨é‡**  
   é€šè¿‡æ˜¾å¼ä¼˜åŒ– **tool efficiency**ï¼Œæ¨¡å‹å­¦ä¼šè§„é¿å†—ä½™æŸ¥è¯¢ï¼Œåè€Œæé«˜äº†æœ€ç»ˆå®šä½å‡†ç¡®æ€§ã€‚è¿™è¡¨æ˜â€œå»å™ªâ€æœ¬èº«æ˜¯ä¸€ç§æœ‰æ•ˆçš„æ­£åˆ™åŒ–æ‰‹æ®µã€‚

2. **è‡ªé€‚åº”å¹¶è¡Œä¼˜äºå›ºå®šå®½åº¦å¹¶è¡Œ**  
   RLè®­ç»ƒåï¼Œæ¨¡å‹å±•ç°å‡ºâ€œå…ˆå¹¿åº¦åæ·±åº¦â€çš„æœç´¢ç­–ç•¥ï¼ˆè§Figure 3ï¼‰ï¼šåˆæœŸå¤šå·¥å…·å¹¶è¡Œæ¢ç´¢ï¼ŒåæœŸèšç„¦å°‘æ•°é«˜ä»·å€¼æ“ä½œï¼Œå®ç°äº†åŠ¨æ€è°ƒèŠ‚ã€‚

3. **æç®€å·¥å…·é›†è¶³ä»¥èƒœä»»å¤æ‚ä»»åŠ¡**  
   ä»…é  `grep`, `glob`, `read_file` ä¸‰ç±»åŸºç¡€å·¥å…·ï¼Œå³å¯è¶…è¶Šä¾èµ–ä»£ç å›¾çš„å¤æ‚ç³»ç»Ÿï¼Œè¯´æ˜**ç­–ç•¥æ™ºèƒ½ > å·¥å…·ä¸°å¯Œåº¦**ã€‚

4. **ä¸‹æ¸¸ä»»åŠ¡æ˜¾è‘—å—ç›Š**  
   å½“å°† **FuseSearch-4B** ä½œä¸ºå‰ç½®å®šä½æ¨¡å—è¾…åŠ©Kimii-K2å®ŒæˆSWE-benchä»»åŠ¡æ—¶ï¼š
   - ä¿æŒç›¸ä¼¼pass rateï¼ˆ~68%ï¼‰
   - **å‡å°‘23.1% interaction turns**
   - **ç¼©çŸ­28.5% end-to-end time**
   
   è¡¨æ˜é«˜æ•ˆå®šä½å¯æœ‰æ•ˆåŠ é€Ÿæ•´ä½“agentæµæ°´çº¿ã€‚

### å±€é™æ€§
1. **è¯„ä¼°åå·®**ï¼šSWE-benchç­‰åŸºå‡†ä»¥golden patchä¸ºground truthï¼Œå¯èƒ½å¿½ç•¥å…¶ä»–åˆæ³•è§£æ³•ã€‚
2. **è¯­è¨€è¦†ç›–æœ‰é™**ï¼šå½“å‰è¯„æµ‹é›†ä¸­Pythonä¸ºä¸»ï¼Œå¯¹Java/C++ç­‰é™æ€è¯­è¨€çš„æœ‰æ•ˆæ€§æœ‰å¾…éªŒè¯ã€‚
3. **åœºæ™¯å±€é™**ï¼šç›®å‰èšç„¦issue-driven localizationï¼Œå°šæœªæ‹“å±•è‡³ä»£ç é—®ç­”ã€ç†è§£ã€æ–‡æ¡£ç”Ÿæˆç­‰æ›´å¹¿ä»»åŠ¡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ„å»ºæ¶µç›–å¤šç§ç¼–ç¨‹è¯­è¨€ä¸ä»»åŠ¡ç±»å‹çš„ç»¼åˆæ€§code localization benchmarkã€‚
- æ¢ç´¢å°†FuseSearchæ€æƒ³åº”ç”¨äºå…¶ä»–ä¿¡æ¯æ£€ç´¢åœºæ™¯ï¼ˆå¦‚web search, database queryï¼‰ã€‚
- ç»“åˆè½»é‡çº§code indexingæœºåˆ¶ï¼Œåœ¨ä¿è¯æ•ˆç‡å‰æä¸‹è¿›ä¸€æ­¥å¢å¼ºå¬å›èƒ½åŠ›ã€‚

---

> ğŸ”š **æ€»ç»“**ï¼š  
> **FuseSearch** é€šè¿‡å¼•å…¥ **tool efficiency** åº¦é‡ä¸ **joint F1-efficiency reward**ï¼ŒæˆåŠŸå®ç°äº†**é«˜è´¨é‡ã€ä½å»¶è¿Ÿã€ä½èµ„æºæ¶ˆè€—**çš„ä»£ç å®šä½ã€‚å…¶å®éªŒè¯æ˜ï¼Œ**æ•ˆç‡é©±åŠ¨çš„å­¦ä¹ èŒƒå¼**ä¸ä»…èƒ½é™ä½æˆæœ¬ï¼Œè¿˜èƒ½åå‘æå‡æ¨¡å‹æ€§èƒ½ï¼Œä¸ºæ„å»ºç”Ÿäº§çº§agentæä¾›äº†é‡è¦è·¯å¾„ã€‚

</details>

---

### 9. [SETA: Statistical Fault Attribution for Compound AI Systems](https://arxiv.org/abs/2601.19337)

**Authors**: Sayak Chowdhury, Meenakshi D'Souza  
**Category**: cs.AI  
**Published**: 2026-01-28  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.19337v1  

#### Abstract
Modern AI systems increasingly comprise multiple interconnected neural networks to tackle complex inference tasks. Testing such systems for robustness and safety entails significant challenges. Current state-of-the-art robustness testing techniques, whether black-box or white-box, have been proposed...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSETA: Statistical Fault Attribution for Compound AI Systems

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°ä»£AIç³»ç»Ÿè¶Šæ¥è¶Šå¤šåœ°é‡‡ç”¨**Compound AI Systems**æ¶æ„ï¼Œå³ç”±å¤šä¸ªç›¸äº’è¿æ¥çš„ç¥ç»ç½‘ç»œæ¨¡å—æ„æˆå¤æ‚æ¨ç†æµæ°´çº¿ã€‚è¿™ç±»ç³»ç»Ÿçš„é²æ£’æ€§å’Œå®‰å…¨æ€§æµ‹è¯•é¢ä¸´ä¸¥å³»æŒ‘æˆ˜ï¼š
- ä¼ ç»Ÿç«¯åˆ°ç«¯ï¼ˆE2Eï¼‰æµ‹è¯•æ— æ³•å®šä½æ•…éšœæ¥æºï¼›
- å•æ¨¡å‹éªŒè¯å·¥å…·ï¼ˆå¦‚Reluplexã€Marabouï¼‰ä¸æ”¯æŒå¤šæ¨¡å—çº§è”åˆ†æï¼›
- é»‘ç›’/ç™½ç›’å¯¹æŠ—æ”»å‡»æ–¹æ³•éš¾ä»¥æ‰©å±•åˆ°å¤šç½‘ç»œç®¡é“ï¼›
- ç¼ºä¹å¯¹é”™è¯¯ä¼ æ’­è·¯å¾„çš„ç»†ç²’åº¦å½’å› èƒ½åŠ›ã€‚

è¿™äº›é—®é¢˜å¯¼è‡´åœ¨ç³»ç»Ÿå¤±æ•ˆæ—¶éš¾ä»¥åˆ¤æ–­â€œå“ªä¸ªå­æ¨¡å—æœ€è„†å¼±â€æˆ–â€œå°è¯¯å·®å¦‚ä½•é€å±‚æ”¾å¤§â€ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡º **SETA**ï¼ˆ**State-based Execution Trace Analysis**ï¼‰ï¼Œä¸€ä¸ªç»“åˆ**Metamorphic Testing**ï¼ˆMTï¼‰ä¸**Execution Trace Analysis**çš„æ¨¡å—åŒ–é²æ£’æ€§æµ‹è¯•æ¡†æ¶ï¼Œæ ¸å¿ƒæ€æƒ³å¦‚ä¸‹ï¼š

- **åŠ¨æ€æ‰§è¡Œå›¾æ„å»º**ï¼šå°†AIç³»ç»Ÿå»ºæ¨¡ä¸ºçŠ¶æ€è½¬ç§»ç³»ç»Ÿï¼Œè¿è¡Œæ—¶è®°å½•æ¯ä¸ªæ¨¡å—çš„è¾“å…¥ã€è¾“å‡ºã€è·¯ç”±å†³ç­–å’Œæ¿€æ´»é¡ºåºï¼Œå½¢æˆ**Execution Trace Tree**ã€‚
- **Metamorphic Relationsä½œä¸ºä¼ªOracle**ï¼šå®šä¹‰æ— éœ€çœŸå®æ ‡ç­¾çš„è¡Œä¸ºä¸€è‡´æ€§å…³ç³»ï¼ˆå¦‚è¾“å‡ºä¸å˜æ€§ã€IoUé˜ˆå€¼ç­‰ï¼‰ï¼Œç”¨äºæ£€æµ‹å„ç»„ä»¶åœ¨æ‰°åŠ¨ä¸‹çš„è¡Œä¸ºåå·®ã€‚
- **ç»Ÿè®¡æ•…éšœå½’å› æœºåˆ¶**ï¼ˆStatistical Fault Attributionï¼‰ï¼šé€šè¿‡è®¡ç®—æ¯ä¸ªæ¨¡å—åœ¨ç³»ç»Ÿå¤±è´¥æ¡ä»¶ä¸‹çš„**Failure Contribution (FC) Score**ï¼Œé‡åŒ–å…¶å¯¹æ•´ä½“æ•…éšœçš„ç›¸å¯¹è´¡çŒ®ï¼Œå¹¶è¿›è¡Œå½’ä¸€åŒ–å¾—åˆ°å¯è§£é‡Šçš„å½’å› æƒé‡ $ \alpha_i $ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰æ–¹æ³•å±€é™ | SETAä¼˜åŠ¿ |
|------|---------------|----------|
| å¯æ‰©å±•æ€§ | å¤šæ•°ä»…é€‚ç”¨äºå•ä¸ªDNN | æ”¯æŒä»»æ„æ‹“æ‰‘ç»“æ„çš„å¤šæ¨¡å—Pipeline |
| æ•…éšœå®šä½èƒ½åŠ› | ä»…èƒ½è¯†åˆ«ç«¯åˆ°ç«¯å¤±è´¥ | å®šä½æœ€æ—©åç¦»ç‚¹ï¼Œæ”¯æŒå› æœé“¾è¿½æº¯ |
| æ•°æ®ä¾èµ– | éœ€è¦æ ‡æ³¨çœŸå€¼ï¼ˆground truthï¼‰ | Oracle-freeï¼ŒåŸºäºè‡ªæ´½æ€§æ£€æŸ¥ |
| æ¶æ„å…¼å®¹æ€§ | å¤šä¸ºç™½ç›’æˆ–ç‰¹å®šç»“æ„ | å®Œå…¨é»‘ç›’ï¼Œarchitecture-agnostic |
| åˆ†ææ·±åº¦ | å¿½ç•¥ä¸­é—´çŠ¶æ€ä¸æ§åˆ¶æµå˜åŒ– | åŒæ—¶ç›‘æ§æ•°æ®æµä¸æ§åˆ¶æµå¼‚å¸¸ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **Railway Vision System**ï¼š
  - åŸºäº **RailSem19** æ•°æ®é›†é‡‡æ ·æ„å»ºï¼Œæ¨¡æ‹Ÿåˆ—è½¦è§†è§’ä¸‹çš„é“è·¯åœºæ™¯å›¾åƒï¼›
  - åº”ç”¨ `imagecorruptions` åº“ç”Ÿæˆåˆæˆæ‰°åŠ¨æ•°æ®ï¼ŒåŒ…æ‹¬ï¼š`fog`, `snow`, `frost`, `glass_blur`, `motion_blur`, `gaussian_noise` ç­‰15ç§ç±»å‹ï¼Œæ¯ç±»5ä¸ªä¸¥é‡ç­‰çº§ã€‚
  
- **Ensemble Model**ï¼š
  - åœ¨ **CIFAR-10** æµ‹è¯•é›†ä¸Šåº”ç”¨ç›¸åŒ `imagecorruptions` æ‰°åŠ¨ç”Ÿæˆå¢å¼ºæ•°æ®é›†ã€‚

- **OCR Model**ï¼š
  - ä½¿ç”¨å¤šä¸ªè‡ªç„¶åœºæ™¯OCRæ•°æ®é›†ï¼ˆå¼•ç”¨[21,34,36]ï¼‰ï¼Œå¦‚Street View Textã€Uber-Textç­‰ï¼›
  - æ‰°åŠ¨æ¥è‡ª `img_aug`, `albumentations`, å’Œ `imagecorruptions`ã€‚

### å®éªŒè®¾ç½®
- **æ‰°åŠ¨ç­–ç•¥**ï¼šè¾“å…¥ç©ºé—´å˜æ¢ä¸ºä¸»ï¼ˆäº®åº¦ã€å™ªå£°ã€æ¨¡ç³Šã€é®æŒ¡ç­‰ï¼‰ï¼Œéƒ¨åˆ†æ”¯æŒä¸­é—´ç‰¹å¾æ‰°åŠ¨ï¼›
- **æ‰§è¡Œæ¨¡å¼**ï¼šå¯¹æ¯ä¸ªåŸå§‹è¾“å…¥ $x$ ä¸å…¶æ‰°åŠ¨ç‰ˆæœ¬ $g(x)$ å¹¶è¡Œè¿è¡Œï¼Œç”Ÿæˆå‚è€ƒè½¨è¿¹ $T(x)$ ä¸æ‰°åŠ¨è½¨è¿¹ $T(x')$ï¼›
- **èŠ‚ç‚¹å¯¹é½**ï¼šä¾æ®æ¨¡å—IDå’Œç»“æ„ä½ç½®å¯¹é½ä¸¤æ£µæ ‘ä¸­çš„å¯¹åº”èŠ‚ç‚¹ï¼›
- **åˆ¤å®šæ ‡å‡†**ï¼šè‹¥æŸèŠ‚ç‚¹è¾“å‡ºè¿åMRæˆ–è·¯ç”±è·¯å¾„ä¸åŒï¼Œåˆ™æ ‡è®°ä¸ºcomponent-level faultã€‚

### è¯„ä¼°æŒ‡æ ‡
- **Failure Contribution Score (FC)**ï¼š  
  $$
  FC_i = \mathbb{E}[Z_i \cdot \mathbf{1}(S(x,x')=0)],\quad Z_i = 1 - S_i(x,x')
  $$
  å…¶ä¸­ $S_i$ æ˜¯ç¬¬$i$ä¸ªæ¨¡å—çš„å¤åˆMRå¾—åˆ†ï¼Œ$S$ æ˜¯å…¨å±€ä¸€è‡´æ€§åˆ†æ•°ã€‚
- **å½’å› æƒé‡ $\alpha_i$**ï¼šå½’ä¸€åŒ–çš„FCå¾—åˆ†ï¼Œåæ˜ æ¨¡å—ç›¸å¯¹è´£ä»»ã€‚
- **é¢„æµ‹å‡†ç¡®ç‡ vs å®é™…å‡†ç¡®ç‡**ï¼šç”¨äºéªŒè¯SETAä¼°ç®—ç²¾åº¦ã€‚
- **Levenshtein Distance**ï¼šOCRä»»åŠ¡ä¸­è¡¡é‡æ–‡æœ¬è¾“å‡ºç¨³å®šæ€§ï¼Œè®¾å®šé˜ˆå€¼ $t=2$ åˆ¤æ–­æ˜¯å¦ç¨³å¥ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æœ¬æ–‡æœªç›´æ¥ä¸å…¶ä»–è‡ªåŠ¨åŒ–å½’å› å·¥å…·æ¯”è¾ƒï¼ˆå› ç¼ºä¹åŒç±»å·¥ä½œï¼‰ï¼Œè€Œæ˜¯å¼ºè°ƒç›¸å¯¹äºä»¥ä¸‹ä¸»æµèŒƒå¼çš„ä¼˜è¶Šæ€§ï¼š
- **End-to-End Testing**ï¼ˆå¦‚DeepTestï¼‰
- **Single-model Verification Tools**ï¼ˆå¦‚Marabou, ERANï¼‰
- **Coverage-guided Testing**ï¼ˆå¦‚DeepXploreï¼‰
- **Adversarial Robustness Metrics**ï¼ˆå¦‚CLEVERï¼‰

> æ³¨ï¼šSETAå¹¶éæ›¿ä»£è¿™äº›å·¥å…·ï¼Œè€Œæ˜¯æä¾›äº’è¡¥çš„è¯Šæ–­å±‚ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰Vision System å½’å› ç»“æœï¼ˆè¡¨1ï¼‰
| æ¨¡å‹ | $\alpha_i$ï¼ˆå½’å› æƒé‡ï¼‰ |
|------|------------------------|
| YOLOv4-tiny ($f_0$) | 0.31 |
| speed_sign classifier ($f_3$) | 0.25 |
| main_signal classifier ($f_1$) | 0.06 |

- ç»“æœæ˜¾ç¤ºç›®æ ‡æ£€æµ‹å™¨ $f_0$ å¯¹ç³»ç»Ÿå¤±è´¥è´¡çŒ®æœ€å¤§ï¼Œå°¤å…¶åœ¨ **fog** æ¡ä»¶ä¸‹è¡¨ç°æœ€å·®ï¼ˆè§å›¾4ï¼‰ï¼›
- åˆ†ç±»å™¨ $f_1$ è™½ç„¶ä¸ªä½“æ•æ„Ÿåº¦é«˜ï¼Œä½†ç”±äºè°ƒç”¨é¢‘ç‡ä½ï¼Œæ€»ä½“å½’å› å¾—åˆ†è¾ƒä½ï¼›
- æœªè¢«è§¦å‘çš„æ¨¡å—è‡ªåŠ¨è·å¾— $\alpha_i=0$ï¼Œä½“ç°æ¡†æ¶ä¿å®ˆæ€§ã€‚

#### ï¼ˆ2ï¼‰Ensemble Model å‡†ç¡®ç‡ä¼°è®¡ï¼ˆè¡¨2ï¼‰
| æ¨¡å‹ | SETAé¢„æµ‹å‡†ç¡®ç‡ | å®é™…å‡†ç¡®ç‡ | è¯¯å·® |
|------|----------------|------------|------|
| ResNet18 | 84.94% | 83.09% | ~1.85% |
| VGG16 | 81.74% | 79.84% | ~1.9% |
| CustomCNN | 81.33% | 80.00% | ~1.33% |
| Ensemble | 86.63% | â€” | â€” |

- SETAé¢„æµ‹è¯¯å·®æ§åˆ¶åœ¨ **1â€“2%ä»¥å†…**ï¼Œè¶³ä»¥ç”¨äºè¯†åˆ«æ€§èƒ½æœ€å·®æ¨¡å‹ï¼ˆCustomCNNï¼‰ï¼›
- è¡¨æ˜è¯¥æ¡†æ¶å¯ç”¨äºå¿«é€Ÿç­›é€‰éœ€ä¼˜åŒ–çš„å­æ¨¡å—ã€‚

#### ï¼ˆ3ï¼‰OCR Model é²æ£’æ€§è¯„ä¼°ï¼ˆè¡¨3ï¼‰
| Input ID | Robustness | Avg. Levenshtein Distance |
|---------|------------|----------------------------|
| 0 | 0.000 | 74.81 |
| 1 | 1.000 | 0.00 |
| ... | ... | ... |
| **Average** | **0.607** | **0.607** |

- ä½¿ç”¨Levenshteinè·ç¦»è¡¡é‡è¾“å‡ºä¸€è‡´æ€§ï¼Œä½äºé˜ˆå€¼è§†ä¸ºéé²æ£’ï¼›
- SETAæˆåŠŸè¯†åˆ«å‡ºå¤šä¸ªé«˜å¤±çœŸæ ·æœ¬ï¼ˆå¦‚ID=0ï¼‰ï¼Œå¹¶å¯è¿½è¸ªè‡³å…·ä½“OCRæ¨¡å—ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ç›¸æ¯”E2Eæµ‹è¯•**ï¼šSETAä¸ä»…èƒ½å‘ç°å¤±è´¥ï¼Œè¿˜èƒ½æŒ‡å‡º$f_0$æ˜¯ä¸»è¦ç“¶é¢ˆï¼Œè€ŒE2Eåªèƒ½æŠ¥å‘Šæ•´ä½“å¤±è´¥ï¼›
- **ç›¸æ¯”å­¤ç«‹æµ‹è¯•ï¼ˆICTï¼‰**ï¼šSETAæ­ç¤ºäº†ä¸Šæ¸¸æ£€æµ‹é”™è¯¯å¦‚ä½•å¼•å‘ä¸‹æ¸¸åˆ†ç±»è¯¯åˆ¤ï¼ˆä¾‹å¦‚é”™è¯¯æ£€æµ‹å¯¼è‡´é”™è¯¯è°ƒç”¨åˆ†ç±»å™¨ï¼‰ï¼Œè¿™æ˜¯ICTæ— æ³•æ•æ‰çš„**æ¶Œç°æ€§æ•…éšœ**ï¼›
- **ç›¸æ¯”Coverageæ–¹æ³•**ï¼šSETAå…³æ³¨çš„æ˜¯**åŠŸèƒ½ä¸€è‡´æ€§**è€Œéç¥ç»å…ƒè¦†ç›–ç‡ï¼Œæ›´é€‚åˆå®‰å…¨å…³é”®ç³»ç»Ÿã€‚

### æ¶ˆèå®éªŒï¼ˆéšå«åˆ†æï¼‰
å°½ç®¡æ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèå®éªŒï¼Œä½†ä»è®¾è®¡ä¸­å¯æ¨æ–­ä»¥ä¸‹å…³é”®å› ç´ å½±å“æ•ˆæœï¼š
- **Metamorphic Relationå®Œæ•´æ€§**ï¼šMRè¶Šå…¨é¢ï¼Œå½’å› è¶Šæ¥è¿‘å› æœï¼›
- **æ‰°åŠ¨å¤šæ ·æ€§**ï¼šè¦†ç›–æ›´å¤šç°å®åœºæ™¯æå‡æ³›åŒ–èƒ½åŠ›ï¼›
- **æ‰§è¡Œè½¨è¿¹ä¿çœŸåº¦**ï¼šç²¾ç¡®è®°å½•è·¯ç”±é€»è¾‘å¯¹æ§åˆ¶æµå¼‚å¸¸æ£€æµ‹è‡³å…³é‡è¦ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **SETAèƒ½å¤Ÿæœ‰æ•ˆå®ç°ç»†ç²’åº¦æ•…éšœå½’å› **ï¼šåœ¨çœŸå®é“è·¯è§†è§‰ç³»ç»Ÿä¸­ï¼ŒæˆåŠŸè¯†åˆ«å‡ºYOLOv4-tinyä¸ºç›®æ ‡æ£€æµ‹æµæ°´çº¿ä¸­æœ€è„†å¼±ç¯èŠ‚ï¼›
2. âœ… **æ”¯æŒè·¨æ¨¡æ€åº”ç”¨**ï¼šä¸ä»…é€‚ç”¨äºCVä»»åŠ¡ï¼Œåœ¨OCRç­‰æ–‡æœ¬ç³»ç»Ÿä¸­ä¹Ÿèƒ½é€šè¿‡Levenshteinè·ç¦»å®ç°ä¸€è‡´æ€§æ£€éªŒï¼›
3. âœ… **æ— éœ€Ground Truthå³å¯å·¥ä½œ**ï¼šåˆ©ç”¨Metamorphic Relationsä½œä¸ºpseudo-oracleï¼Œé€‚åˆéƒ¨ç½²åç›‘æ§ä¸å›å½’æµ‹è¯•ï¼›
4. âœ… **æ­ç¤ºé”™è¯¯ä¼ æ’­æœºåˆ¶**ï¼šä¸ä»…èƒ½å®šä½â€œé¦–æ¬¡å¤±è´¥ç‚¹â€ï¼Œè¿˜èƒ½é€šè¿‡ç»Ÿè®¡ç›¸å…³æ€§æ¨æµ‹æ½œåœ¨æ ¹æœ¬åŸå› ï¼›
5. âœ… **ä¸MLOpsç”Ÿæ€å…¼å®¹**ï¼šå¯é›†æˆè¿›Kedroã€MLflowç­‰å¹³å°ï¼Œä½œä¸ºè¯Šæ–­æ’ä»¶å¢å¼ºå¯è§‚æµ‹æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. âŒ **å½’å› ä¸ºç›¸å…³æ€§è€Œéå› æœæ€§**ï¼šå½“å‰FCå¾—åˆ†åæ˜ çš„æ˜¯ç»Ÿè®¡å…³è”ï¼Œä¸èƒ½ä¿è¯è¯†åˆ«å‡ºçœŸæ­£çš„æ ¹æœ¬åŸå› ï¼ˆroot causeï¼‰ï¼›
2. âŒ **ä¾èµ–æ‰‹å·¥è®¾è®¡MRs**ï¼šMetamorphic Relationsç›®å‰ç”±ä¸“å®¶å®šä¹‰ï¼Œå¯èƒ½å­˜åœ¨é—æ¼æˆ–åå·®ï¼›
3. âŒ **å‡è®¾æ‰°åŠ¨ç‹¬ç«‹**ï¼šç»Ÿè®¡èšåˆæ—¶é»˜è®¤å„æ‰°åŠ¨æ•ˆåº”ç‹¬ç«‹ï¼Œä½†åœ¨å¼ºè€¦åˆç³»ç»Ÿä¸­å¯èƒ½ä¸æˆç«‹ï¼›
4. âŒ **æ‰§è¡Œè½¨è¿¹ä¾èµ–æ—¥å¿—å®Œæ•´æ€§**ï¼šè‹¥è·¯ç”±é€»è¾‘æœªå……åˆ†æš´éœ²ï¼Œåˆ™æ§åˆ¶æµå¼‚å¸¸å¯èƒ½è¢«å¿½ç•¥ï¼›
5. âŒ **è½»é‡çº§å®ç°é™åˆ¶**ï¼šä¸ºä¿æŒé€šç”¨æ€§ç‰ºç‰²äº†å¯¹å†…éƒ¨æ¢¯åº¦æˆ–æ³¨æ„åŠ›æœºåˆ¶çš„æ·±å…¥åˆ†æèƒ½åŠ›ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. ğŸ”® **å¼•å…¥å› æœæ¨ç†æœºåˆ¶**ï¼šç»“åˆdo-calculusæˆ–interventional analysisï¼Œä»ç›¸å…³æ€§è¿ˆå‘**causal fault localization**ï¼›
2. ğŸ”® **è‡ªåŠ¨å­¦ä¹ Metamorphic Relations**ï¼šåˆ©ç”¨ç¨‹åºåˆæˆæˆ–LLMä»æ‰§è¡Œæ—¥å¿—ä¸­è‡ªåŠ¨å½’çº³åˆç†MRï¼›
3. ğŸ”® **ä¸ç¡®å®šæ€§æ„ŸçŸ¥å½’å› **ï¼šä¸º$\alpha_i$æ·»åŠ ç½®ä¿¡åŒºé—´ï¼Œæå‡è¯Šæ–­å¯é æ€§ï¼›
4. ğŸ”® **æ‰©å±•è‡³å¤šæ¨¡æ€ä¸RLç³»ç»Ÿ**ï¼šåº”ç”¨äºVLMï¼ˆVision-Language Modelsï¼‰ã€è‡ªåŠ¨é©¾é©¶å†³ç­–ç³»ç»Ÿç­‰æ›´å¤æ‚åœºæ™¯ï¼›
5. ğŸ”® **åœ¨çº¿ç›‘æ§ä¸è‡ªé€‚åº”æµ‹è¯•**ï¼šå°†SETAåµŒå…¥ç”Ÿäº§ç¯å¢ƒï¼Œå®ç°å®æ—¶æ¼‚ç§»æ£€æµ‹ä¸ä¸»åŠ¨æµ‹è¯•è§¦å‘ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> SETAæå‡ºäº†ä¸€ç§æ–°é¢–çš„ã€åŸºäºæ‰§è¡Œè½¨è¿¹ä¸Metamorphic Testingçš„ç»Ÿè®¡æ•…éšœå½’å› æ¡†æ¶ï¼Œå¡«è¡¥äº†**Compound AI Systems**åœ¨ç»†ç²’åº¦é²æ£’æ€§åˆ†æä¸Šçš„ç©ºç™½ï¼Œä¸ºå¤æ‚AIç³»ç»Ÿçš„å¯è§£é‡Šæµ‹è¯•æä¾›äº†å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 10. [PROTEUS: SLA-Aware Routing via Lagrangian RL for Multi-LLM Serving Systems](https://arxiv.org/abs/2601.19402)

**Authors**: Amit Singh Bhatti, Vishal Vaddina, Dagnachew Birru  
**Category**: cs.AI  
**Published**: 2026-01-28  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.19402v1  

#### Abstract
Production LLM deployments serve diverse workloads where cost and quality requirements vary by customer tier, time of day, and query criticality. Model serving systems accept latency SLOs directly. LLM routers do not. They force operators to tune parameters offline and guess what accuracy might resu...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**PROTEUS: SLA-Aware Routing via Lagrangian RL for Multi-LLM Serving Systems**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰çš„ **LLM è·¯ç”±å™¨**ï¼ˆLLM routersï¼‰æ— æ³•ç›´æ¥æ»¡è¶³ç”¨æˆ·çš„**å‡†ç¡®æ€§ç›®æ ‡**ï¼ˆaccuracy targetsï¼‰ï¼Œåªèƒ½é€šè¿‡ç¦»çº¿è°ƒå‚é—´æ¥æ§åˆ¶è·¯ç”±è¡Œä¸ºã€‚è¿™ç§å‚æ•°ä¸ç»“æœä¹‹é—´çš„å…³ç³»æ˜¯**é—´æ¥ã€éå•è°ƒä¸”ä¾èµ–æ•°æ®é›†**çš„ï¼Œå¯¼è‡´è¿ç»´å›°éš¾ã€‚å°¤å…¶æ˜¯åœ¨å¤šå®¢æˆ·å±‚çº§ã€åŠ¨æ€è´Ÿè½½å’Œå·®å¼‚åŒ–æœåŠ¡åœºæ™¯ä¸‹ï¼Œæ“ä½œå‘˜éš¾ä»¥å®æ—¶ä¿è¯æœåŠ¡è´¨é‡ï¼ˆSLAï¼‰ï¼Œç‰¹åˆ«æ˜¯**å‡†ç¡®ç‡ä¸‹é™**ï¼ˆaccuracy floorï¼‰ã€‚

æ­¤å¤–ï¼Œç°æœ‰ç³»ç»Ÿå¦‚ Clipper å’Œ INFaaS æ”¯æŒå»¶è¿Ÿæˆ–ç²¾åº¦ SLO è¾“å…¥ï¼Œä½†ä¸é€‚ç”¨äºè·¨å¼‚æ„ LLM æ¨¡å‹æ± çš„**å­¦ä¹ å‹è·¯ç”±ç­–ç•¥**ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
æå‡º **PROTEUS**ï¼ˆPolymorphic Router for Operational Target Enforcement with Unified SLAï¼‰ï¼Œä¸€ä¸ªæ”¯æŒè¿è¡Œæ—¶è¾“å…¥å‡†ç¡®ç‡ç›®æ ‡ $ T \in [0.85, 0.95] $ çš„ LLM è·¯ç”±æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **T-conditioned ç­–ç•¥ç½‘ç»œ**ï¼šå°†ç›®æ ‡å‡†ç¡®ç‡ $ T $ ä½œä¸ºç­–ç•¥ç½‘ç»œçš„è¾“å…¥ï¼Œåœ¨æ¨ç†é˜¶æ®µå®ç°**å•æ¨¡å‹è¦†ç›–å…¨ç²¾åº¦è°±ç³»**ï¼Œæ— éœ€ä¸ºæ¯ä¸ª $ T $ å•ç‹¬è®­ç»ƒã€‚
- **åŸºäº Lagrangian RL çš„çº¦æŸä¼˜åŒ–æœºåˆ¶**ï¼š
  - å¼•å…¥å¯å­¦ä¹ çš„å¯¹å¶å˜é‡ $ \lambda $ï¼Œåœ¨è®­ç»ƒä¸­åŠ¨æ€è·Ÿè¸ªçº¦æŸè¿åæƒ…å†µï¼ˆå³å®é™…å‡†ç¡®ç‡æ˜¯å¦ä½äº $ T $ï¼‰ã€‚
  - å°† $ \lambda $ åé¦ˆè‡³ç­–ç•¥ç½‘ç»œï¼Œä½¿æ¨¡å‹å­¦ä¼šâ€œé«˜ $ T $ â†’ é«˜è´¨é‡åå¥½ $ u $â€çš„æ˜ å°„å…³ç³»ã€‚
- **è¿ç»­è´¨é‡åå¥½è¾“å‡º $ u \in [0,1] $**ï¼šé¿å…ç¡¬é˜ˆå€¼åˆ‡æ¢ï¼Œå®ç°å¹³æ»‘çš„ cost-quality æƒè¡¡æ’å€¼ã€‚
- **è‡ªé€‚åº”è·¯ç”±è¯„åˆ†å‡½æ•°**ï¼š
  $$
  S_i = p_i + \beta \cdot b_i - (1 - p_i)^\gamma \cdot c_i
  $$
  å…¶ä¸­ $ \gamma $ æ˜¯å¯å­¦ä¹ çš„æˆæœ¬æ•æ„Ÿå‚æ•°ï¼Œå…è®¸æ¨¡å‹è‡ªåŠ¨é€‚é…ä¸åŒæˆæœ¬åˆ†å¸ƒã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ CARROTã€OmniRouterï¼‰ | PROTEUS |
|------|-------------------------------|--------|
| å‡†ç¡®æ€§æ§åˆ¶æ–¹å¼ | å›ºå®šé…ç½®ï¼ˆå¦‚ $ u=0.1/0.5/0.9 $ï¼‰æˆ–å‚æ•°æ‰«æ | ç›´æ¥æ¥å— $ T $ ä½œä¸ºè¿è¡Œæ—¶è¾“å…¥ |
| æ˜¯å¦éœ€é‡è®­ç»ƒ | æ¯ä¸ªç›®æ ‡éœ€é‡æ–°è®­ç»ƒæˆ–è°ƒå‚ | å•ä¸€æ¨¡å‹æœåŠ¡æ‰€æœ‰ $ T $ï¼Œé›¶å»¶è¿Ÿé€‚åº” |
| SLA ä¸‹é™ä¿éšœèƒ½åŠ› | å·®ï¼ˆOmniRouter ä»… 22% è¾¾æ ‡ï¼‰ | **100% floor compliance** |
| åŠ¨æ€é€‚åº”æ€§ | ä¸æ”¯æŒå®æ—¶å˜åŒ–çš„ $ T $ | æ”¯æŒ per-queryã€per-customerã€time-of-day åŠ¨æ€è°ƒæ•´ |
| æˆæœ¬èŠ‚çº¦ | ä¸€èˆ¬ï¼ˆ60â€“80%ï¼‰ | æœ€é«˜è¾¾ **89.8% æˆæœ¬èŠ‚çœ** |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†
- **RouterBench**  
  - åŒ…å« 405K æŸ¥è¯¢ï¼Œæ¶µç›– 11 ä¸ªæ¨¡å‹ï¼ˆLlama-2, Mistral, GPT-3.5, GPT-4, Claude-2 ç­‰ï¼‰
  - ä»»åŠ¡ç±»å‹ï¼šMMLUã€HellaSwagï¼ˆæ¨ç†ï¼‰ã€GSM8K/MATHï¼ˆæ•°å­¦ï¼‰ã€HumanEval/MBPPï¼ˆä»£ç ï¼‰
  - æˆæœ¬èŒƒå›´ï¼š\$0.0001 â€“ \$0.01 / query
  - Oracle å‡†ç¡®ç‡ï¼š91.4%

- **SPROUT**  
  - åŒ…å« 45K æŸ¥è¯¢ï¼Œ14 ä¸ªå‰æ²¿æ¨¡å‹ï¼ˆGPT-4o, Claude-3.5-Sonnet, o3-mini, Llama ç³»åˆ—ç­‰ï¼‰
  - æ›´æç«¯æˆæœ¬å·®å¼‚ï¼ˆæœ€é«˜è¾¾ 9.5Ã—ï¼‰ï¼Œæ›´ç°ä»£æ¨¡å‹ç»„åˆ
  - Oracle å‡†ç¡®ç‡ï¼š98.6%

> ä¸¤è€…äº’è¡¥ï¼šRouterBench å¼ºè°ƒè§„æ¨¡ä¸å¤šæ ·æ€§ï¼›SPROUT æµ‹è¯•å¯¹æ–°å‹é«˜ä»·æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **è®­ç»ƒé…ç½®**ï¼š
  - ç¼–ç å™¨ï¼šDeBERTa-v3-smallï¼ˆ22M å‚æ•°ï¼‰ï¼Œç¼–ç å»¶è¿Ÿ <2ms/queryï¼ˆA100 GPUï¼‰
  - ç­–ç•¥ç½‘ç»œï¼š2å±‚MLPï¼Œè¾“å‡º Beta åˆ†å¸ƒå‚æ•°ä»¥ç”Ÿæˆ $ u $
  - ä½¿ç”¨ PPO è¿›è¡Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒ
  - æ‰¹å¤§å° 32ï¼Œè®­ç»ƒæ­¥æ•° 10Kï¼Œçº¦ 4 å°æ—¶/æ•°æ®é›†
  - å¯¹å¶å˜é‡æ›´æ–°é¢‘ç‡ï¼šæ¯ 5 ä¸ª batch æ›´æ–°ä¸€æ¬¡ï¼Œå­¦ä¹ ç‡ $ \eta_\lambda = 0.4 $

- **è¯„ä¼°æŒ‡æ ‡**
  | ç±»åˆ« | æŒ‡æ ‡ | è¯´æ˜ |
  |------|------|------|
  | **é€‚åº”æ€§æŒ‡æ ‡** | T-u Correlation | $ T $ ä¸è¾“å‡ºè´¨é‡åå¥½ $ u $ çš„çš®å°”é€Šç›¸å…³ç³»æ•° |
  | | Floor Compliance (%) | å®ç°å‡†ç¡®ç‡ â‰¥ $ T $ çš„ç›®æ ‡æ¯”ä¾‹ï¼ˆæ ¸å¿ƒ SLA ä¿è¯ï¼‰ |
  | | Tolerance-band Compliance (Â±2%, Â±5%) | åœ¨å®¹å¿å¸¦å†…åŒ¹é…ç›®æ ‡çš„ç¨‹åº¦ |
  | | Cost Range | æœ€å° vs æœ€å¤§ $ T $ ä¸‹çš„æˆæœ¬æ¯” |
  | **æ•ˆç‡æŒ‡æ ‡** | Routing Efficiency (RE) | $ \text{RE} = \frac{\text{Acc} - \text{Acc}_{\text{random}}}{\text{Latency}} $ï¼ˆpp/msï¼‰ |
  | | Routing Performance Index (RPI) | ç»¼åˆè´¨é‡ã€æˆæœ¬ã€å»¶è¿Ÿçš„ç»¼åˆå¾—åˆ† |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | æ–¹æ³• | æè¿° |
|------|------|------|
| **é™æ€ç­–ç•¥** | Always-Best / Cheapest / Random | å›ºå®šé€‰æ‹©æœ€ä¼˜/æœ€ä¾¿å®œ/éšæœºæ¨¡å‹ |
| **å­¦ä¹ å‹è·¯ç”±å™¨** | KNN / MLP | åŸºäº query embedding é¢„æµ‹æœ€ä½³æ¨¡å‹ |
| | CARROT | ä½¿ç”¨ $ u \in \{0.1,0.5,0.9\} $ æ§åˆ¶ cost-quality æƒè¡¡ |
| | OmniRouter-Style | ä½¿ç”¨ Lagrangian dual æ§åˆ¶ batch-level çº¦æŸ |
| | RouteLLM-Style | åŸºäº win-rate çš„åˆ†ç±»å™¨ |
| **æ¶ˆèå˜ä½“** | PROTEUS w/o T-conditioning / fixed $ \gamma $ / no critic | ç§»é™¤å…³é”®ç»„ä»¶éªŒè¯æœ‰æ•ˆæ€§ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & 2ï¼‰

| æŒ‡æ ‡ | RouterBench | SPROUT |
|------|-------------|--------|
| **T-u Correlation** | **0.973** | **0.981** |
| **Floor Compliance (acc â‰¥ T)** | **100%** | **100%** |
| **Tolerance-band Compliance (Â±5%)** | 100% | 67% |
| **Achieved Accuracy** | **90.1%** | **94.0%** |
| **Oracle Gap** | +1.3 pp | +4.6 pp |
| **Cost Saving vs Best Fixed Model** | **90%** | **83%** |
| **Routing Efficiency (RE)** | **11.1 pp/ms** | **9.5 pp/ms** |
| **RPI** | **88.5** | **83.5** |

> ğŸ’¡ ç‰¹åˆ«äº®ç‚¹ï¼š
> - **PROTEUS çš„ RPI è¶…è¿‡ Oracleï¼ˆ88.5 > 88.2ï¼‰**ï¼Œè¡¨æ˜é€šè¿‡é€‚åº¦ç‰ºç‰²ç²¾åº¦æ¢å–æ˜¾è‘—æˆæœ¬ä¸‹é™ï¼Œæ•´ä½“æ•ˆç‡æ›´é«˜ã€‚
> - åœ¨ SPROUT ä¸Šï¼ŒPremium tier æˆæœ¬ä¸º Economy çš„ **5.6 å€**ï¼Œä½†å‡†ç¡®ç‡ä»…æå‡ 3.7%ï¼Œä½“ç°ç²¾ç»†åŒ–å®šä»·ç©ºé—´ã€‚

### ğŸ” åŠ¨æ€é€‚åº”èƒ½åŠ›æµ‹è¯•ï¼ˆFigure 2cï¼‰
åœ¨å››ç§åŠ¨æ€ $ T $ åœºæ™¯ä¸‹ï¼ˆStep, Drift, Cyclic, Realisticï¼‰ï¼ŒPROTEUS å±•ç°å‡º**é›¶å»¶è¿Ÿå“åº”èƒ½åŠ›**ï¼š
- å¹³å‡ floor satisfactionï¼šRouterBench 77%ï¼ŒSPROUT 82â€“86%
- å­˜åœ¨ **intentional overshoot**ï¼ˆ+1.6% ~ +5.2%ï¼‰ï¼Œæä¾›é²æ£’æ€§ç¼“å†²
- ç”±äº $ T $ æ˜¯ç›´æ¥è¾“å…¥ï¼Œæ— éœ€ retraining æˆ– warm-up

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆTable 4ï¼‰

| å˜ä½“ | å½±å“ï¼ˆâ–³Accï¼‰ | ç»“è®º |
|------|--------------|------|
| **-Constraint ($ \lambda $)** | â†“0.27% (RB), â†“0.53% (SP) | **æœ€å…³é”®ç»„ä»¶**ï¼Œç§»é™¤å floor compliance å´©æºƒ |
| **-Learnable $ \gamma $** | â†” negligible (RB), â†“0.62% (SP) | å¯¹æˆæœ¬è·¨åº¦å¤§çš„ç¯å¢ƒï¼ˆSPROUTï¼‰æ›´é‡è¦ |
| **-Critic** | â†“<0.05% | å‡ ä¹æ— å½±å“ï¼Œå¯çœç•¥ä»¥ç®€åŒ–æ¶æ„ |

> âœ… éªŒè¯äº† Lagrangian dual åé¦ˆæœºåˆ¶æ˜¯å®ç° SLA ä¿è¯çš„æ ¸å¿ƒã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **LLM è·¯ç”±å¯ä»¥è¢«å»ºæ¨¡ä¸ºâ€œç›®æ ‡é©±åŠ¨â€çš„ç­–ç•¥å­¦ä¹ é—®é¢˜**ï¼Œè€Œéä¼ ç»Ÿçš„å‚æ•°è°ƒä¼˜ã€‚
2. **å•ä¸€ PROTEUS æ¨¡å‹å³å¯æœåŠ¡ä» Economy åˆ° Premium çš„å…¨éƒ¨ SLA tier**ï¼Œæ”¯æŒè¿è¡Œæ—¶åŠ¨æ€è°ƒæ•´ $ T $ã€‚
3. **Lagrangian dual variable $ \lambda $ çš„å¼•å…¥ä½¿å¾—çº¦æŸæ»¡è¶³æˆä¸ºå¯å­¦ä¹ çš„è¿‡ç¨‹**ï¼Œå®ç°äº†æ¥è¿‘å®Œç¾çš„ floor complianceï¼ˆ100%ï¼‰ã€‚
4. **T-conditioning + dual feedback æ„é€ äº†å¼º T-u correlationï¼ˆ>0.97ï¼‰**ï¼Œç¡®ä¿ä¸šåŠ¡éœ€æ±‚èƒ½è¢«å¿ å®æ‰§è¡Œã€‚
5. **ç›¸æ¯”åŸºçº¿ï¼ŒPROTEUS æ˜¾è‘—ä¼˜äº OmniRouterï¼ˆä»… 22% è¾¾æ ‡ï¼‰å’Œ CARROTï¼ˆå›ºå®šè¾“å‡ºï¼‰**ï¼Œè§£å†³äº†â€œæ— æ³•é¢„æµ‹æœ€ç»ˆå‡†ç¡®ç‡â€çš„ç—›ç‚¹ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ– ground-truth æ­£ç¡®æ€§æ ‡ç­¾è¿›è¡Œè®­ç»ƒ**ï¼šç”Ÿäº§ç¯å¢ƒä¸­é€šå¸¸ä¸å¯å¾—ï¼Œéœ€å€ŸåŠ© LLM-as-a-judge æˆ–äººå·¥æ ‡æ³¨å®šæœŸé‡‡æ ·æ„å»ºè®­ç»ƒé›†ã€‚
2. **å½“å‰ benchmark ä¸­ mid-tier æ¨¡å‹å‡†ç¡®ç‡å‹ç¼©ä¸¥é‡**ï¼Œç»†ç²’åº¦åŒºåˆ† $ T $ è¾ƒéš¾ã€‚
3. **æœªè€ƒè™‘å»¶è¿Ÿç»´åº¦**ï¼šç›®å‰åªä¼˜åŒ– accuracy å’Œ costï¼Œå°šæœªæ•´åˆ latency-aware routingã€‚
4. **æ¨¡å‹æ± å›ºå®šå‡è®¾**ï¼šæ–°å¢æ¨¡å‹å¯èƒ½éœ€è¦å¾®è°ƒæˆ–å¢é‡è®­ç»ƒã€‚
5. **é•¿æœŸåˆ†å¸ƒæ¼‚ç§»é£é™©**ï¼šå¯é æ€§ marginï¼ˆ+1.3% ~ +6.3%ï¼‰è™½æä¾›çŸ­æœŸç¼“å†²ï¼Œä½†æŒç»­ drift éœ€è¦ç­–ç•¥æ›´æ–°ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- **Bandit Feedback Setting**ï¼šä»…è§‚å¯Ÿæ‰€é€‰æ¨¡å‹çš„ç»“æœï¼Œé™ä½æ ‡æ³¨å¼€é”€ï¼Œæ”¯æŒåœ¨çº¿æŒç»­å­¦ä¹ ã€‚
- **Latency-aware Routing**ï¼šæ‰©å±• reward å‡½æ•°ï¼Œè”åˆä¼˜åŒ– accuracyã€costã€response timeã€‚
- **Hierarchical Routing**ï¼šå…ˆåˆ† tier å†é€‰ modelï¼Œé™ä½å¤§è§„æ¨¡ action space çš„å¤æ‚åº¦ã€‚
- **Multi-objective T Specification**ï¼šåŒæ—¶æŒ‡å®š accuracy floor å’Œ cost ceilingï¼Œæ›´è´´è¿‘çœŸå® SLA åˆåŒã€‚
- **Multi-turn Conversation Support**ï¼šå¤„ç†ä¸Šä¸‹æ–‡ç´¯ç§¯ã€token budget åˆ†é…ç­‰æ—¶åºå†³ç­–é—®é¢˜ã€‚
- **æ›´ä¸°å¯Œçš„ benchmark**ï¼šè¦†ç›– $ [0.5, 0.99] $ å®½å¹¿ accuracy èŒƒå›´ï¼Œæµ‹è¯•ç²¾ç»†æ§åˆ¶èƒ½åŠ›ã€‚

---

> ğŸ§© æ€»ç»“ä¸€å¥è¯ï¼š  
> **PROTEUS å®ç°äº†â€œè¯´ä½ è¦ä»€ä¹ˆï¼Œæˆ‘å°±åšä»€ä¹ˆâ€çš„ LLM è·¯ç”±æ„¿æ™¯â€”â€”ç”¨ä¸€ä¸ªæ¨¡å‹ï¼Œå“åº”ä»»æ„ SLA ç›®æ ‡ï¼Œæ—¢çœé’±åˆè¾¾æ ‡ã€‚**

</details>

---

### 11. [Agentic Design Patterns: A System-Theoretic Framework](https://arxiv.org/abs/2601.19752)

**Authors**: Minh-Dung Dao, Quy Minh Le, Hoang Thanh Lam, Duc-Trong Le, Quoc-Viet Pham, Barry O'Sullivan, Hoang D. Nguyen  
**Category**: cs.AI  
**Published**: 2026-01-28  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.19752v1  

#### Abstract
With the development of foundation model (FM), agentic AI systems are getting more attention, yet their inherent issues like hallucination and poor reasoning, coupled with the frequent ad-hoc nature of system design, lead to unreliable and brittle applications. Existing efforts to characterise agent...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Agentic Design Patterns: A System-Theoretic Framework*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰åŸºäº Foundation Model (FM) çš„ **agentic AI** ç³»ç»Ÿè™½ç„¶å±•ç°å‡ºå¼ºå¤§çš„è‡ªä¸»è¡Œä¸ºèƒ½åŠ›ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­å­˜åœ¨è¯¸å¤šç³»ç»Ÿæ€§ç¼ºé™·ï¼Œå¦‚ï¼š
- **å¹»è§‰ (hallucination)** å’Œ **æ¨ç†é”™è¯¯ (poor reasoning)**
- ç¼ºä¹é•¿æœŸè®°å¿†ä¸çŠ¶æ€ç®¡ç†
- å·¥å…·è°ƒç”¨ä¸å¯é ã€ç¼ºä¹é”™è¯¯æ¢å¤æœºåˆ¶
- å¤šæ™ºèƒ½ä½“åä½œä¸­çš„é€šä¿¡ä¸åè°ƒå¤±è´¥
- è®¾è®¡æ¨¡å¼å¤šä¸ºç»éªŒæ€§ã€ç¢ç‰‡åŒ–ï¼Œç¼ºä¹ç†è®ºåŸºç¡€

ç°æœ‰ **Agentic Design Patterns (ADPs)** å¤šä¸ºä»å®è·µä¸­å½’çº³çš„â€œä¾¿åˆ©æ€§åˆ†ç±»â€ï¼ˆconvenience-based taxonomiesï¼‰ï¼Œç¼ºä¹ç»Ÿä¸€çš„ç†è®ºæ¡†æ¶æ”¯æ’‘ï¼Œå¯¼è‡´éš¾ä»¥å¤ç”¨ã€æ¨å¹¿å’Œå·¥ç¨‹åŒ–ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯

æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§ **åŸºäºç³»ç»Ÿè®º (system-theoretic)** çš„ agentic AI æ¶æ„è®¾è®¡æ¡†æ¶ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šæ„å»ºäº†ä¸€ä¸ªç»“æ„åŒ–çš„ **Agentic Design Patterns (ADPs)** ä½“ç³»ã€‚

#### ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼š

1. **ä¸€ä¸ªç³»ç»Ÿè®ºé©±åŠ¨çš„äº”å±‚åŠŸèƒ½å­ç³»ç»Ÿæ¶æ„**
   å°† agentic AI åˆ†è§£ä¸ºäº”ä¸ªæ ¸å¿ƒä¸”å¯äº¤äº’çš„åŠŸèƒ½å­ç³»ç»Ÿï¼š
   - **Reasoning & World Model (RWM)**ï¼šè´Ÿè´£å†…éƒ¨ä¸–ç•Œå»ºæ¨¡ä¸å†³ç­–
   - **Perception & Grounding (PG)**ï¼šæ„ŸçŸ¥å¹¶ç»“æ„åŒ–å¤–éƒ¨è¾“å…¥
   - **Action Execution (AE)**ï¼šæ‰§è¡ŒåŠ¨ä½œå¹¶ä¸ç¯å¢ƒäº¤äº’
   - **Learning & Adaptation (LA)**ï¼šå®ç°æŒç»­å­¦ä¹ ä¸ç­–ç•¥ä¼˜åŒ–
   - **Inter-Agent Communication (IAC)**ï¼ˆå¯é€‰ï¼‰ï¼šæ”¯æŒå¤šæ™ºèƒ½ä½“åä½œ

   > è¿™ç§åˆ†å±‚ç»“æ„å€Ÿé‰´äº†ç³»ç»Ÿå·¥ç¨‹ä¸­çš„æ¨¡å—åŒ–æ€æƒ³ï¼Œå¼ºè°ƒå„å­ç³»ç»Ÿçš„èŒè´£åˆ†ç¦»ä¸åŠ¨æ€ä¿¡æ¯æµã€‚

2. **ä¸€å¥—ç»“æ„åŒ–çš„ Agentic Design Patternsï¼ˆå…±12ä¸ªï¼‰**
   åŸºäºä¸Šè¿°æ¶æ„ï¼Œæå‡ºäº† **12ä¸ªå¯å¤ç”¨çš„è®¾è®¡æ¨¡å¼**ï¼Œåˆ†ä¸ºå››ç±»ï¼š
   - **Foundational Patterns**ï¼ˆåŸºç¡€æ¨¡å¼ï¼‰
     - `Integrator`, `Retriever`, `Recorder`
   - **Cognitive & Decisional Patterns**ï¼ˆè®¤çŸ¥ä¸å†³ç­–ï¼‰
     - `Selector`, `Planner`, `Deliberator`
   - **Execution & Interaction Patterns**ï¼ˆæ‰§è¡Œä¸äº¤äº’ï¼‰
     - `Executor`, `Tool Use`, `Coordinator`
   - **Adaptive & Learning Patterns**ï¼ˆè‡ªé€‚åº”ä¸å­¦ä¹ ï¼‰
     - `Reflector`, `Skill Build`, `Controller`

   æ¯ä¸ªæ¨¡å¼å‡éµå¾ª GoF é£æ ¼çš„æ¨¡æ¿ï¼ˆIntent, Problem, Solutionï¼‰ï¼Œæ˜ç¡®å…¶è§£å†³çš„å…·ä½“é—®é¢˜å’Œåä½œæœºåˆ¶ã€‚

3. **é—®é¢˜-æ¶æ„-æ¨¡å¼ä¹‹é—´çš„æ˜ å°„å…³ç³»**
   é€šè¿‡ Sankey å›¾å±•ç¤ºäº†äº”å¤§æŒ‘æˆ˜ç±»åˆ«å¦‚ä½•å½±å“ä¸åŒå­ç³»ç»Ÿï¼Œå¹¶ç”±ç‰¹å®šè®¾è®¡æ¨¡å¼äºˆä»¥åº”å¯¹ï¼Œå½¢æˆé—­ç¯é€»è¾‘é“¾æ¡ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | æœ¬æ–‡æ–¹æ³• |
|------|--------|---------|
| **ç†è®ºåŸºç¡€** | ç»éªŒå½’çº³ã€å®è·µè§‚å¯Ÿä¸ºä¸» | åŸºäºç³»ç»Ÿè®ºçš„ç¬¬ä¸€æ€§åŸç†æ¨å¯¼ |
| **ç²’åº¦ä¸å®ç”¨æ€§** | è¦ä¹ˆå¤ªæŠ½è±¡ï¼ˆå¦‚â€œåæ€â€ï¼‰ï¼Œè¦ä¹ˆå¤ªå…·ä½“ï¼ˆå¦‚å·¥å…·é€‰æ‹©ï¼‰ | ä¸­ç­‰ç²’åº¦ï¼Œèšç„¦å­ç³»ç»Ÿé—´äº¤äº’é—®é¢˜ |
| **å¯å®æ–½æ€§** | ç¼ºä¹æ ‡å‡†æ¥å£ä¸æµç¨‹å®šä¹‰ | æä¾›ç»“æ„åŒ–è§£å†³æ–¹æ¡ˆä¸ç»„ä»¶èŒè´£ |
| **ä¸ç»å…¸è®¾è®¡æ¨¡å¼çš„å…³ç³»** | å¾ˆå°‘å…³è” GoF æˆ–è½¯ä»¶å·¥ç¨‹æ¨¡å¼ | æ˜¾å¼å¼•ç”¨ `Proxy`, `Observer`, `Mediator` ç­‰ç»å…¸æ¨¡å¼ |
| **ç³»ç»Ÿå¯é æ€§æå‡è·¯å¾„** | ä¸æ¸…æ™° | é€šè¿‡ç»„åˆæ¨¡å¼ç³»ç»Ÿæ€§å¢å¼ºé²æ£’æ€§ |

> ä¾‹å¦‚ï¼Œ`Controller` æ¨¡å¼é‡‡ç”¨ **Observer æ¨¡å¼** å®ç°å¯¹ agent è¡Œä¸ºçš„æŒç»­ç›‘æ§ä»¥ä¿éšœä»·å€¼å¯¹é½ï¼›`Tool Use` åˆ™ä½œä¸º **Proxy + Adapter** æ¥å°è£…å¤–éƒ¨å·¥å…·è°ƒç”¨ï¼Œæé«˜å®‰å…¨æ€§ä¸ä¸€è‡´æ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

> âš ï¸ æ³¨æ„ï¼šè¯¥è®ºæ–‡æœªè¿›è¡Œé‡åŒ–å®éªŒæˆ–åŸºå‡†æµ‹è¯•ï¼Œè€Œæ˜¯é‡‡ç”¨ **å®šæ€§æ¡ˆä¾‹åˆ†æ (qualitative case study)** æ–¹æ³•éªŒè¯å…¶æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚

### ğŸ§ª å®éªŒå¯¹è±¡
- **ReAct æ¡†æ¶**ï¼šä¸€ç§å…¸å‹çš„å•æ™ºèƒ½ä½“å¾ªç¯æ¶æ„ï¼ˆThought â†’ Act â†’ Observeï¼‰ï¼Œå¹¿æ³›ç”¨äºå¢å¼º LLM çš„ä»»åŠ¡æ‰§è¡Œèƒ½åŠ›ã€‚

### ğŸ” åˆ†ææ–¹æ³•ï¼ˆä¸‰æ­¥æ³•ï¼‰
1. **Deconstructï¼ˆè§£æ„ï¼‰**
   - å°† ReAct çš„åŠŸèƒ½æ˜ å°„åˆ°æå‡ºçš„äº”å­ç³»ç»Ÿæ¶æ„ä¸­ï¼Œæ­ç¤ºå…¶éšå¼ã€å•ä½“å¼çš„å®ç°æ–¹å¼ã€‚
2. **Diagnoseï¼ˆè¯Šæ–­ï¼‰**
   - è¯†åˆ« ReAct åœ¨ä¸–ç•Œå»ºæ¨¡ã€è§„åˆ’ã€é”™è¯¯æ¢å¤ç­‰æ–¹é¢çš„ç³»ç»Ÿæ€§å¼±ç‚¹ã€‚
3. **Prescribeï¼ˆå¤„æ–¹ï¼‰**
   - ä½¿ç”¨æœ¬æ–‡æå‡ºçš„ ADPs å¯¹ ReAct è¿›è¡Œé‡æ„ï¼Œæå‡ºæ”¹è¿›æ–¹æ¡ˆã€‚

### ğŸ“Š è¯„ä¼°æ–¹å¼
- **éé‡åŒ–åˆ†æ**ï¼šæ— å‡†ç¡®æ•°æ®é›†ã€æ€§èƒ½æŒ‡æ ‡æˆ–ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒã€‚
- ä¾èµ– **æ¦‚å¿µå›¾ç¤º**ï¼ˆå¦‚ Figure 4ï¼‰å±•ç¤ºé›†æˆåçš„å¢å¼ºå‹ ReAct æµç¨‹ã€‚
- é€šè¿‡é€»è¾‘è®ºè¯è¯´æ˜æ–°æ¨¡å¼å¦‚ä½•ç¼“è§£åŸæœ‰ç¼ºé™·ã€‚

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- æœ¬æ–‡æœªç›´æ¥å¯¹æ¯”å…¶ä»– ADP æ–¹æ³•çš„æ€§èƒ½ã€‚
- ä½†åœ¨ Table 1 ä¸­è¿›è¡Œäº† **æ–‡çŒ®æ¯”è¾ƒåˆ†æ**ï¼ŒæŒ‡å‡ºå·²æœ‰å·¥ä½œï¼ˆå¦‚ Ng [2024], Liu et al. [2025a]ï¼‰å±äº bottom-up æˆ– high-level strategyï¼Œè€Œæœ¬æ–‡æ˜¯ **integrated, principle-based** æ–¹æ³•ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

> â— ç”±äºç ”ç©¶æ€§è´¨ä¸º **æ¦‚å¿µæ€§æ¡†æ¶æ„å»º**ï¼Œæœ¬æ–‡ **æ²¡æœ‰æä¾›æ•°å€¼å®éªŒç»“æœæˆ–æ€§èƒ½æŒ‡æ ‡**ã€‚

### âœ… å®šæ€§â€œç»“æœâ€æ€»ç»“å¦‚ä¸‹ï¼š

| åŸæœ‰ç³»ç»Ÿï¼ˆReActï¼‰é—®é¢˜ | æ‰€ææ¨¡å¼è§£å†³æ–¹æ¡ˆ | æ•ˆæœæè¿° |
|---------------------|------------------|----------|
| è§‚æµ‹ä¿¡æ¯æœªç»éªŒè¯ï¼Œæ˜“å¼•å…¥å™ªå£° | `Integrator` æ¨¡å¼ | åœ¨ PG å±‚å¢åŠ éªŒè¯ç®¡é“ï¼Œè¿‡æ»¤ä¸ä¸€è‡´è¾“å…¥ |
| ä¸Šä¸‹æ–‡æ£€ç´¢ä½æ•ˆï¼ŒçŠ¶æ€æ— æ³•æŒä¹…åŒ– | `Retriever` + `Recorder` | æ”¹è¿›è®°å¿†è®¿é—®ä¸çŠ¶æ€ä¿å­˜æœºåˆ¶ |
| ç¼ºä¹é”™è¯¯åé¦ˆä¸å­¦ä¹ æœºåˆ¶ | `Reflector` æ¨¡å¼ | å¼•å…¥å› æœåˆ†æï¼Œä»å¤±è´¥ä¸­ç”Ÿæˆç­–ç•¥æ›´æ–° |
| åŠ¨ä½œæ‰§è¡Œé»‘ç®±åŒ–ï¼Œéš¾ä»¥è°ƒè¯• | `Executor` + `Tool Use` | ç»“æ„åŒ–åŠ¨ä½œè°ƒåº¦ä¸å·¥å…·è°ƒç”¨æ¥å£ |
| æ— é•¿æœŸå­¦ä¹ èƒ½åŠ› | `Learning & Adaptation` å­ç³»ç»Ÿæ•´åˆ | å½¢æˆâ€œæ„ŸçŸ¥â†’è¡ŒåŠ¨â†’åé¦ˆâ†’å­¦ä¹ â€çš„å®Œæ•´é—­ç¯ |

> å¦‚ Figure 4 æ‰€ç¤ºï¼ŒåŸå§‹ ReAct çš„ç®€å•å¾ªç¯è¢«æ‰©å±•ä¸ºä¸€ä¸ªå…·å¤‡ **å®¹é”™ã€å­¦ä¹ ã€æ§åˆ¶** èƒ½åŠ›çš„ç»“æ„åŒ–å·¥ä½œæµã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º

1. **agentic AI éœ€è¦ç³»ç»Ÿè®ºæŒ‡å¯¼çš„è®¾è®¡èŒƒå¼**
   - å½“å‰ ad-hoc çš„å¼€å‘æ–¹å¼å¯¼è‡´ç³»ç»Ÿè„†å¼±ã€ä¸å¯ç»´æŠ¤ã€‚
   - å¿…é¡»ä»ç¬¬ä¸€æ€§åŸç†å‡ºå‘ï¼Œå»ºç«‹å…·æœ‰ç†è®ºæ ¹åŸºçš„æ¶æ„è¯­è¨€ã€‚

2. **äº”å­ç³»ç»Ÿæ¶æ„æä¾›äº†æ¸…æ™°çš„èŒè´£åˆ’åˆ†**
   - æ˜ç¡®äº† RWM ä¸ºæ ¸å¿ƒã€PG/AE ä¸ºæ¥å£ã€LA ä¸ºå¤–å±‚è°ƒæ§çš„å±‚çº§ç»“æ„ã€‚
   - æ”¯æŒæ¨¡å—åŒ–è®¾è®¡ä¸è·¨å›¢é˜Ÿåä½œã€‚

3. **12ä¸ª ADPs æ˜¯å¯å¤ç”¨çš„â€œå»ºç­‘æ„ä»¶â€**
   - æ¯ä¸ªæ¨¡å¼é’ˆå¯¹ç‰¹å®šå­ç³»ç»Ÿé—´çš„åä½œé—®é¢˜ï¼Œå…·å¤‡é«˜å†…èšã€ä½è€¦åˆç‰¹æ€§ã€‚
   - å¯ç»„åˆä½¿ç”¨ä»¥æ„å»ºå¤æ‚å¯é çš„ agent ç³»ç»Ÿã€‚

4. **æ¡†æ¶å¯ç”¨äºè¯Šæ–­ä¸å¢å¼ºç°æœ‰ç³»ç»Ÿ**
   - æˆåŠŸåº”ç”¨äº ReAct çš„é‡æ„ï¼Œå±•ç¤ºäº†å…¶åœ¨ç°å®ç³»ç»Ÿä¸­çš„é€‚ç”¨æ€§ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

1. **ç¼ºä¹å®è¯éªŒè¯**
   - æ‰€æœ‰åˆ†æå‡ä¸ºå®šæ€§ï¼Œå°šæœªåœ¨çœŸå®ä»»åŠ¡ä¸Šè¿›è¡Œé‡åŒ–è¯„æµ‹ï¼ˆå¦‚æˆåŠŸç‡ã€æ•ˆç‡ã€ç¨³å®šæ€§ç­‰ï¼‰ã€‚
   - æœªå‘å¸ƒå¼€æºå®ç°æˆ–åŸå‹ç³»ç»Ÿã€‚

2. **æ¨¡å¼å®ç°å¯èƒ½å¸¦æ¥é¢å¤–å¼€é”€**
   - å¦‚ `Reflector` å’Œ `Controller` å¢åŠ æ¨ç†æ­¥éª¤ï¼Œå¯èƒ½å¯¼è‡´å»¶è¿Ÿä¸Šå‡æˆ–æˆæœ¬å¢åŠ ã€‚
   - è®ºæ–‡æ‰¿è®¤éœ€è¿›ä¸€æ­¥ç ”ç©¶å…¶è®¡ç®—ä»£ä»·ä¸æ”¶ç›Šçš„æƒè¡¡ã€‚

3. **æœªå¤„ç†å¤§è§„æ¨¡ç¤¾ä¼šæ€§å½±å“**
   - å¦‚ç¾¤ä½“æ™ºèƒ½æ¶Œç°è¡Œä¸ºã€æ³•å¾‹è´£ä»»å½’å±ç­‰é—®é¢˜ä»å±å¼€æ”¾è¯¾é¢˜ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **å¼€å±•å®šé‡åŸºå‡†æµ‹è¯•**
   - æ„å»º benchmark suite æ¥è¡¡é‡ä¸åŒ ADP ç»„åˆå¯¹ agent æ€§èƒ½çš„å½±å“ã€‚
   - æ¢ç´¢è‡ªåŠ¨åŒ– pattern selection ä¸ composition æ–¹æ³•ã€‚

2. **æ¢ç´¢åŠ¨æ€æ¶æ„æ¼”åŒ–**
   - ç ”ç©¶ agent æ˜¯å¦å¯æ ¹æ®ä»»åŠ¡åŠ¨æ€æ¿€æ´»/ç¦ç”¨æŸäº›å­ç³»ç»Ÿæˆ–æ¨¡å¼ã€‚

3. **ä¸ Formal Verification ç»“åˆ**
   - å°† `Controller` ç­‰æ¨¡å¼ä¸å½¢å¼åŒ–æ–¹æ³•ç»“åˆï¼Œç¡®ä¿å®‰å…¨çº¦æŸå§‹ç»ˆæ»¡è¶³ã€‚

4. **æ‰©å±•è‡³å…·èº«æ™ºèƒ½ (embodied agents) ä¸æœºå™¨äººç³»ç»Ÿ**
   - éªŒè¯è¯¥æ¡†æ¶åœ¨ç‰©ç†ä¸–ç•Œä¸­çš„é€‚ç”¨æ€§ã€‚

---

## âœ… æ€»ç»“

| é¡¹ç›® | å†…å®¹ |
|------|------|
| **è®ºæ–‡å®šä½** | æå‡ºä¸€ç§ **åŸåˆ™æ€§ã€ç³»ç»ŸåŒ–** çš„ agentic AI å·¥ç¨‹æ–¹æ³•è®º |
| **æ ¸å¿ƒè´¡çŒ®** | â‘  äº”å­ç³»ç»Ÿæ¶æ„ï¼›â‘¡ 12ä¸ªç»“æ„åŒ– ADPsï¼›â‘¢ é—®é¢˜-æ¨¡å¼æ˜ å°„ä½“ç³» |
| **æ–¹æ³•ç‰¹ç‚¹** | ç†è®ºé©±åŠ¨ã€æ¨¡å—åŒ–ã€å¯ç»„åˆã€å…¼å®¹ GoF è®¾è®¡æ¨¡å¼ |
| **å®éªŒå½¢å¼** | å®šæ€§æ¡ˆä¾‹åˆ†æï¼ˆä»¥ ReAct ä¸ºä¾‹ï¼‰ |
| **æ˜¯å¦å¼€æº/å¯å¤ç°** | å¦ï¼ˆç›®å‰ä»…ç†è®ºæ¡†æ¶ï¼‰ |
| **é€‚ç”¨äººç¾¤** | AI æ¶æ„å¸ˆã€agent ç³»ç»Ÿå¼€å‘è€…ã€ç ”ç©¶è€… |

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> æœ¬æ–‡å°† agentic AI ä»â€œè‰ºæœ¯æ€§æ‹¼å‡‘â€æ¨å‘â€œå·¥ç¨‹åŒ–å»ºé€ â€ï¼Œæä¾›äº†ä¸€å¥—ç±»ä¼¼å»ºç­‘è®¾è®¡è“å›¾çš„ **ç³»ç»Ÿè®ºæ¡†æ¶ + å¯å¤ç”¨æ„ä»¶åº“ï¼ˆADPsï¼‰**ï¼Œä¸ºæ„å»ºæ›´å¯é ã€å¯è§£é‡Šã€å¯æŒç»­è¿›åŒ–çš„æ™ºèƒ½ä»£ç†ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚

</details>

---

### 12. [Optimizing Conversational Quality in Spoken Dialogue Systems with Reinforcement Learning from AI Feedback](https://arxiv.org/abs/2601.19063)

**Authors**: Siddhant Arora, Jinchuan Tian, Jiatong Shi, Hayato Futami, Yosuke Kashiwagi, Emiru Tsunoo, Shinji Watanabe  
**Category**: cs.CL  
**Published**: 2026-01-28  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.19063v1  

#### Abstract
Reinforcement learning from human or AI feedback (RLHF/RLAIF) for speech-in/speech-out dialogue systems (SDS) remains underexplored, with prior work largely limited to single semantic rewards applied at the utterance level. Such setups overlook the multi-dimensional and multi-modal nature of convers...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šOptimizing Conversational Quality in Spoken Dialogue Systems with Reinforcement Learning from AI Feedback

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰åœ¨ **Spoken Dialogue Systems (SDS)** ä¸­ï¼ŒåŸºäºäººç±»æˆ–AIåé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆ**RLHF/RLAIF**ï¼‰ç ”ç©¶å¤§å¤šå±€é™äºå•ä¸€è¯­ä¹‰å¥–åŠ±ï¼ˆå¦‚äº‹å®æ€§ã€è¿è´¯æ€§ï¼‰ï¼Œä¸”ä»…åœ¨å®Œæ•´è¯è¯­ï¼ˆutterance-levelï¼‰ä¸Šè¿›è¡Œä¼˜åŒ–ã€‚è¿™å¯¼è‡´ä»¥ä¸‹ä¸‰ä¸ªå…³é”®é—®é¢˜æœªè¢«å……åˆ†è§£å†³ï¼š

1. **å¤šç»´åº¦è´¨é‡ç¼ºå¤±**ï¼šçœŸå®å¯¹è¯è´¨é‡æ˜¯å¤šç»´çš„ï¼ŒåŒ…æ‹¬è¯­ä¹‰è¿è´¯æ€§ã€éŸ³é¢‘è‡ªç„¶åº¦ï¼ˆaudio naturalnessï¼‰ã€å¯æ‡‚åº¦ï¼ˆintelligibilityï¼‰ã€æƒ…æ„Ÿä¸€è‡´æ€§ï¼ˆemotion alignmentï¼‰å’Œè½®æ¬¡è½¬æ¢è¡Œä¸ºï¼ˆturn-takingï¼‰ï¼Œä½†ç°æœ‰æ–¹æ³•åªå…³æ³¨è¯­ä¹‰ã€‚
2. **å…¨åŒå·¥ç³»ç»Ÿä¸å…¼å®¹**ï¼šç°ä»£SDSæ”¯æŒ**å¢é‡å¼ã€å—çŠ¶è§£ç **ï¼ˆblockwise decodingï¼‰çš„**duplexæ¨¡å‹**ï¼Œè€Œä¼ ç»ŸRLHFä¾èµ–äºæ•´å¥åé¦ˆï¼Œæ— æ³•æŒ‡å¯¼ç”Ÿæˆè¿‡ç¨‹ä¸­çš„ä¸­é—´å†³ç­–ã€‚
3. **ç¼ºä¹éŸ³é¢‘å±‚é¢å¥–åŠ±**ï¼šå°½ç®¡TTSé¢†åŸŸå·²æœ‰åŸºäºMOSçš„åå¥½å­¦ä¹ ï¼Œä½†åœ¨ç«¯åˆ°ç«¯SDSä¸­å°šæœªç³»ç»Ÿæ•´åˆéŸ³é¢‘è´¨é‡å¥–åŠ±ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹

æœ¬æ–‡æå‡ºäº†é¦–ä¸ªé¢å‘è¯­éŸ³è¾“å…¥/è¾“å‡ºSDSçš„**å¤šå¥–åŠ±RLAIFæ¡†æ¶**ï¼ˆmulti-reward RLAIFï¼‰ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰**å¤šå¥–åŠ±DPOæ¡†æ¶è®¾è®¡**
- æ„å»ºå››ä¸ªç‹¬ç«‹çš„åå¥½æ•°æ®é›†ï¼Œåˆ†åˆ«é’ˆå¯¹ï¼š
  - **Semantic Quality**ï¼ˆè¯­ä¹‰è´¨é‡ï¼‰
  - **Audio Quality**ï¼ˆéŸ³é¢‘è‡ªç„¶åº¦ï¼Œä½¿ç”¨UTMOSï¼‰
  - **Intelligibility**ï¼ˆå¯æ‡‚åº¦ï¼ŒåŸºäºWERï¼‰
  - **Emotion Consistency**ï¼ˆæƒ…æ„Ÿä¸€è‡´æ€§ï¼Œä½¿ç”¨Emo2vecï¼‰
- åœ¨è®­ç»ƒæ—¶è”åˆé‡‡æ ·è¿™äº›æ•°æ®ï¼Œåœ¨ç»Ÿä¸€çš„**DPOç›®æ ‡å‡½æ•°**ä¸‹è¿›è¡Œä¼˜åŒ–ã€‚

#### ï¼ˆ2ï¼‰**é€‚ç”¨äºå…¨åŒå·¥ç³»ç»Ÿçš„æµå¼åå¥½å­¦ä¹ **
- é’ˆå¯¹**blockwise duplex SDS**ï¼ˆå¦‚SCoTæ¨¡å‹ï¼‰æå‡ºâ€œ**turn-level preference sampling + blockwise log-prob aggregation**â€æœºåˆ¶ï¼š
  - è™½ç„¶åå¥½æ ‡ç­¾ä»ä¸ºæ•´å¥çº§åˆ«ï¼Œ
  - ä½†é€šè¿‡å°†å“åº”åˆ‡åˆ†ä¸ºå›ºå®šå¤§å°çš„å—ï¼ˆblockï¼‰ï¼Œå¹¶å°†æ¯ä¸ªå—çš„ç”Ÿæˆæ¦‚ç‡ç´¯åŠ ä½œä¸ºæ•´ä½“ä¼¼ç„¶ï¼Œ
  - ä½¿å¾—DPOå¯ä»¥åå‘ä¼ æ’­å½±å“æ¯ä¸€ä¸ªç”Ÿæˆå—çš„å†³ç­–ã€‚

#### ï¼ˆ3ï¼‰å‘å¸ƒé¦–ä¸ªå¤§è§„æ¨¡å¤šå¥–åŠ±DPOæ•°æ®é›†
- åŒ…å« **165.7K** é«˜è´¨é‡åå¥½å¯¹ï¼ŒæŒ‰ç±»å‹åˆ†å¸ƒå¦‚ä¸‹ï¼š
  - Semantic: 51.1K
  - Audio Quality: 32.0K
  - Intelligibility: 61.0K
  - Emotion: 21.6K
- å…¬å¼€ä»£ç ä¸è®­ç»ƒç»†èŠ‚ï¼Œæ¨åŠ¨å¯å¤ç°ç ”ç©¶ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä»¥å¾€æ–¹æ³• | æœ¬å·¥ä½œ |
|------|--------|--------|
| å¥–åŠ±ç»´åº¦ | å•ä¸€è¯­ä¹‰æˆ–æ—¶åºå¥–åŠ± | å¤šç»´åº¦è”åˆä¼˜åŒ–ï¼ˆè¯­ä¹‰+éŸ³é¢‘+æƒ…æ„Ÿï¼‰ |
| æ¨¡å‹é€‚é…æ€§ | ä»…é€‚ç”¨äºturn-by-turnæ¨¡å‹ | æ”¯æŒblockwise duplexæµå¼æ¨¡å‹ |
| åé¦ˆç²’åº¦ | å®Œæ•´utteranceçº§åé¦ˆ | åˆ©ç”¨utteranceçº§åé¦ˆä¼˜åŒ–partial generation |
| æ•°æ®å¼€æ”¾æ€§ | å¤šæ•°é—­æºæˆ–å°è§„æ¨¡ | å‘å¸ƒé¦–ä¸ªå¤§è§„æ¨¡å¤šå¥–åŠ±DPOæ•°æ®é›† |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†

- **è®­ç»ƒæ•°æ®æ¥æº**ï¼šåŸºäºçœŸå®äºº-äººå¯¹è¯æ„å»ºåå¥½æ•°æ®ï¼Œä¸»æ•°æ®é›†ä¸º **Switchboard**ï¼ˆçº¦300å°æ—¶ç”µè¯å¯¹è¯ï¼‰ã€‚
- **åå¥½æ•°æ®æ„é€ æ–¹å¼**ï¼š
  - ä½¿ç”¨CoT-E2Eæ¨¡å‹ç”Ÿæˆå¤šä¸ªå€™é€‰å“åº”ï¼ˆtextæˆ–speechï¼‰ã€‚
  - åˆ©ç”¨è‡ªåŠ¨è¯„ä¼°å™¨æ‰“åˆ†å¹¶ç­›é€‰æ­£è´Ÿæ ·æœ¬å¯¹ç”¨äºDPOè®­ç»ƒã€‚

### âš™ï¸ å®éªŒè®¾ç½®

#### æ¨¡å‹æ¶æ„
- **Baselineæ¨¡å‹**ï¼š
  - `Direct E2E`ï¼šæ ‡å‡†ç«¯åˆ°ç«¯SDS
  - `Moshi`ï¼š7Bå‚æ•°åŒé€šé“duplexæ¨¡å‹
  - `Multi-turn CoT E2E`ï¼šå¸¦é“¾å¼æ¨ç†çš„å¼ºåŸºçº¿
  - `SCoT-Response`ï¼šå—çŠ¶å…¨åŒå·¥CoTæ¨¡å‹
- æ‰€æœ‰æ¨¡å‹å‡ä»¥SpeechLMä¸ºåŸºç¡€ï¼ˆSmolLM2 1.7Båˆå§‹åŒ–ï¼‰

#### RLAIFè®­ç»ƒé…ç½®
- ä½¿ç”¨ **Direct Preference Optimization (DPO)** è¿›è¡Œpost-trainingã€‚
- å¤šç§è®­ç»ƒæ¨¡å¼å¯¹æ¯”ï¼š
  - **Single-Reward RLAIF**ï¼šä»…ä½¿ç”¨ä¸€ç§å¥–åŠ±ä¿¡å·è®­ç»ƒ
  - **Joint-Reward-v1**ï¼šè”åˆè¯­ä¹‰ + éŸ³é¢‘è´¨é‡ + å¯æ‡‚åº¦
  - **Joint-Reward-v2**ï¼šè”åˆè¯­ä¹‰ + éŸ³é¢‘ + å¯æ‡‚åº¦ + æƒ…æ„Ÿä¸€è‡´æ€§

#### è®­ç»ƒç»†èŠ‚ï¼ˆè§Appendix A.4ï¼‰
- ä½¿ç”¨4å—NVIDIA H200 GPU
- ä¼˜åŒ–å™¨ï¼šAdamWï¼Œå­¦ä¹ ç‡6e-7ï¼Œwarmup cosineè°ƒåº¦
- Batch size: ~3840ç§’éŸ³é¢‘ + 1.1Mæ–‡æœ¬token
- DPOæ•°æ®æŒ‰99:1åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡

| ç±»åˆ« | æŒ‡æ ‡ | å·¥å…·/æ–¹æ³• |
|------|-----|----------|
| **è¯­ä¹‰è´¨é‡** | ROUGE-L â†‘, METEOR â†‘, Perplexity â†“, AutoBLEU â†“ | Whisper + GPT-2 |
| | LLM Judge Score â†‘ï¼ˆQwen2.5-7Bï¼‰ | è‡ªå®šä¹‰promptè¯„åˆ† |
| | Win Rate â†‘ï¼ˆvs no-RLAIF baselineï¼‰ | æˆå¯¹æ¯”è¾ƒç»Ÿè®¡ |
| **éŸ³é¢‘è´¨é‡** | UTMOS â†‘ï¼ˆè¯­éŸ³è‡ªç„¶åº¦ä¼°è®¡ï¼‰ | UTMOSæ¨¡å‹ |
| | WER â†“ï¼ˆASRè¯†åˆ«é”™è¯¯ç‡ï¼‰ | Whisper-largeè½¬å½• |
| **é£æ ¼ä¸€è‡´æ€§** | Emotion Rank â†“ï¼ˆè¶Šä½è¶Šå¥½ï¼‰ | Emo2Vecæå–æƒ…æ„Ÿè¡¨å¾ |
| **é€šç”¨å·¥å…·åŒ…** | VERSA toolkit | ç»Ÿä¸€è¯„ä¼°è¯­éŸ³ã€éŸ³é¢‘ã€éŸ³ä¹ä»»åŠ¡ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ è¡¨2ï¼šè¯­ä¹‰è´¨é‡æå‡ï¼ˆTurn-by-Turn SDSï¼‰

| Model | ROUGE-L | Perplexity | LLM Judge | Win Rate |
|-------|---------|------------|-----------|----------|
| Multi-turn CoT E2E | 12.1 | 21.2 | 6.18 | â€” |
| + RLAIF (Single-Reward) | 11.9 | 19.9 | **6.33*** | 55.4% |
| + RLAIF (Joint-v1) | 11.8 | 19.6 | 6.29* | 52.6% |
| + RLAIF (Joint-v2) | 11.9 | 19.9 | **6.33*** | 54.4% |

> âœ… **å…³é”®å‘ç°**ï¼š
> - å•ä¸€è¯­ä¹‰RLAIFæ˜¾è‘—æå‡LLMè¯„åˆ†ï¼ˆ6.18â†’6.33, p<0.01ï¼‰
> - ä½è´¨é‡å“åº”æ¯”ä¾‹ä¸‹é™28.5%ï¼ˆ<5åˆ†å æ¯”ä»10.2%â†’7.1%ï¼‰
> - AutoBLEUå¤§å¹…é™ä½ï¼ˆ68.3â†’56.5ï¼‰ï¼Œè¯´æ˜å‡å°‘é‡å¤è¾“å‡º
> - è”åˆè®­ç»ƒæœªæŸå®³è¯­ä¹‰è¡¨ç°ï¼Œåè€Œç¨³å®šå¢ç›Š

---

### ğŸ“‰ è¡¨3ï¼šéŸ³é¢‘è´¨é‡ä¸å¯æ‡‚åº¦æå‡

| Model | UTMOS â†‘ | WER â†“ |
|-------|--------|-------|
| Multi-turn CoT E2E | 2.16 | 6.1 |
| + RLAIF (Single-Reward) | **3.06** | **3.3** |
| + RLAIF (Joint-v1) | 2.85 | **1.0** |
| + RLAIF (Joint-v2) | 2.85 | 1.7 |

> âœ… **å…³é”®å‘ç°**ï¼š
> - å•ç‹¬éŸ³é¢‘å¥–åŠ±ä½¿UTMOSé£™å‡ï¼ˆ+0.9ï¼‰ï¼Œæ¥è¿‘Moshiæ°´å¹³
> - å•ç‹¬å¯æ‡‚åº¦å¥–åŠ±å°†WERä»6.1é™è‡³3.3
> - **Joint-v1å®ç°æœ€ä½³å¹³è¡¡**ï¼šUTMOSè¾¾2.85ï¼ŒWERè¿›ä¸€æ­¥é™è‡³**1.0**
> - Joint-v2å› åŠ å…¥æƒ…æ„Ÿçº¦æŸï¼Œè½»å¾®ç‰ºç‰²å¯æ‡‚åº¦ï¼ˆWERå‡è‡³1.7ï¼‰

---

### ğŸ­ è¡¨4ï¼šæƒ…æ„Ÿä¸€è‡´æ€§è¯„ä¼°ï¼ˆEmotion Rank â†“ï¼‰

| Model | Emotion Rank |
|-------|-------------|
| Multi-turn CoT E2E | 2.29 |
| + RLAIF (Single-Reward) | **1.98** |
| + RLAIF (Joint-v2) | 3.00 |

> âœ… **å…³é”®å‘ç°**ï¼š
> - å•ç‹¬æƒ…æ„Ÿå¥–åŠ±æœ‰æ•ˆæå‡é£æ ¼ä¸€è‡´æ€§ï¼ˆRankâ†“ï¼‰
> - ä½†åœ¨è”åˆè®­ç»ƒä¸­ï¼ˆJoint-v2ï¼‰ï¼Œå—å¼ºè¯­ä¹‰å¥–åŠ±å‹åˆ¶ï¼Œæƒ…æ„Ÿè¡¨è¾¾å˜å¼±ï¼ˆRankâ†‘ï¼‰
> â¡ï¸ æ­ç¤ºäº†**å¤šç›®æ ‡ä¹‹é—´çš„æ½œåœ¨å†²çª**

---

### ğŸ” è¡¨5ï¼šDuplexæ¨¡å‹ä¸Šçš„è¯­ä¹‰ä¼˜åŒ–æ•ˆæœ

| Model | ROUGE-L | Perplexity | LLM Judge |
|-------|---------|----------|-----------|
| SCoT-Response | 19.8 | 42.3 | 5.95 |
| + RLAIF | **23.1** | **25.0** | **6.00** |

> âœ… **å…³é”®å‘ç°**ï¼š
> - RLAIFæˆåŠŸè¿ç§»åˆ°**blockwise duplexæ¨¡å‹**
> - åœ¨ROUGE-Lã€PPLã€LLMè¯„åˆ†ä¸Šå…¨é¢è¶…è¶ŠåŸºçº¿
> - éªŒè¯äº†â€œutterance-levelåå¥½ â†’ blockwiseç”Ÿæˆâ€çš„å¯è¡Œæ€§

---

### âœ… æ¶ˆèå®éªŒç»“è®ºï¼ˆæ¥è‡ªæ­£æ–‡åˆ†æï¼‰

| è®¾ç½® | ç»“æœ |
|------|------|
| æ–‡æœ¬+è¯­éŸ³è”åˆDPO vs ä»…æ–‡æœ¬DPO | åè€…æ›´ç¨³å®šæœ‰æ•ˆï¼Œâ€œtext-only DPOâ€æœ€ä¼˜ |
| åŠ å…¥SFTè¾…åŠ©æŸå¤± | æ— é¢å¤–æ”¶ç›Š |
| ä¸åŒrewardç»„åˆç­–ç•¥ | dataset-level concatenationæœ‰æ•ˆï¼Œä½†ç¼ºä¹æ˜¾å¼æƒè¡¡æœºåˆ¶ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **å•å¥–åŠ±RLAIFå…·æœ‰é«˜åº¦é’ˆå¯¹æ€§**ï¼š
   - è¯­ä¹‰å¥–åŠ± â†’ æå‡è¿è´¯æ€§ä¸äº‹å®æ€§
   - éŸ³é¢‘å¥–åŠ± â†’ æ˜¾è‘—æ”¹å–„UTMOSä¸WER
   - æƒ…æ„Ÿå¥–åŠ± â†’ å¢å¼ºè¯´è¯äººé£æ ¼ä¸€è‡´æ€§

2. **å¤šå¥–åŠ±è”åˆè®­ç»ƒå¸¦æ¥ç»¼åˆå¢ç›Š**ï¼š
   - Joint-v1ï¼ˆè¯­ä¹‰+éŸ³é¢‘+å¯æ‡‚åº¦ï¼‰åœ¨å¤šä¸ªç»´åº¦ä¸€è‡´æå‡
   - å°¤å…¶åœ¨**éŸ³é¢‘è‡ªç„¶åº¦ä¸å¯æ‡‚åº¦**ä¸Šå–å¾—çªç ´ï¼ˆWER=1.0ï¼‰
   - è¯æ˜äº†å¤šç»´å¯¹é½çš„å¿…è¦æ€§å’Œæœ‰æ•ˆæ€§

3. **å­˜åœ¨å†…åœ¨ç›®æ ‡å†²çª**ï¼š
   - å¼ºè¯­ä¹‰å¥–åŠ±å¯èƒ½å¯¼è‡´å›åº”â€œè¿‡äºå®‰å…¨â€æˆ–â€œæ³›åŒ–â€ï¼ŒæŠ‘åˆ¶æƒ…æ„Ÿè¡¨è¾¾ï¼ˆEmotion Rankæ¶åŒ–ï¼‰
   - è¡¨æ˜éœ€è¦æ›´æ™ºèƒ½çš„**reward balancingæœºåˆ¶**

4. **æ¡†æ¶å…·å¤‡è‰¯å¥½æ‰©å±•æ€§**ï¼š
   - æˆåŠŸåº”ç”¨äºturn-by-turnä¸blockwise duplexä¸¤ç±»æ¶æ„
   - æ— éœ€ä¿®æ”¹æ¨¡å‹ç»“æ„å³å¯å®ç°æµå¼åå¥½ä¼˜åŒ–

---

### âš ï¸ å±€é™æ€§ï¼ˆLimitationsï¼‰

1. **ä¾èµ–è‡ªåŠ¨è¯„ä¼°å™¨æ„å»ºåå¥½æ•°æ®**ï¼š
   - å¦‚LLM judgeã€UTMOSã€Emo2vecç­‰å¯èƒ½å¼•å…¥åå·®æˆ–å™ªå£°
   - ç¼ºä¹çœŸå®human-in-the-loopåå¥½æ ‡æ³¨

2. **rewardèåˆæ–¹å¼è¾ƒç®€å•**ï¼š
   - å½“å‰é‡‡ç”¨dataset-levelæ‹¼æ¥ï¼Œæœªå»ºæ¨¡rewardé—´äº¤äº’æˆ–åŠ¨æ€æƒé‡
   - å¯èƒ½å¯¼è‡´æ¬¡ä¼˜å¹³è¡¡ï¼ˆå¦‚æƒ…æ„Ÿé€€åŒ–ï¼‰

3. **è¯­è¨€ä¸åœºæ™¯é™åˆ¶**ï¼š
   - å®éªŒé›†ä¸­åœ¨è‹±è¯­Switchboardæ•°æ®é›†
   - å°šæœªéªŒè¯åœ¨å¤šè¯­è¨€ã€è·¨æ–‡åŒ–æˆ–å¤æ‚ä»»åŠ¡å‹å¯¹è¯ä¸­çš„æœ‰æ•ˆæ€§

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **å¼•å…¥äººç±»åå¥½æ•°æ®é—­ç¯**ï¼š
   - æ„å»ºhuman-labeled multi-reward preference dataset
   - æ¢ç´¢human-AIæ··åˆåé¦ˆæœºåˆ¶

2. **å¼€å‘åŠ¨æ€reward weightingæœºåˆ¶**ï¼š
   - åŸºäºä¸Šä¸‹æ–‡è‡ªé€‚åº”è°ƒæ•´å„rewardé‡è¦æ€§
   - å¼•å…¥multi-objective RLç®—æ³•ï¼ˆå¦‚Paretoä¼˜åŒ–ï¼‰

3. **æ‹“å±•è‡³å¤šæ¨¡æ€ä¸å¤šè¯­è¨€åœºæ™¯**ï¼š
   - å°†æ¡†æ¶æ¨å¹¿è‡³è§†è§‰-è¯­éŸ³å¯¹è¯ç³»ç»Ÿï¼ˆVSDSï¼‰
   - æ„å»ºè·¨è¯­è¨€å¤šå¥–åŠ±DPOæ•°æ®é›†

4. **æ¢ç´¢åœ¨çº¿RLä¸æŒç»­å¯¹é½**ï¼š
   - ç»“åˆORISEç±»æ–¹æ³•å®ç°å®æ—¶turn-takingä¼˜åŒ–
   - æ”¯æŒéƒ¨ç½²åæŒç»­ä»ç”¨æˆ·äº¤äº’ä¸­å­¦ä¹ 

---

> ğŸ’¡ **æ€»ä½“è¯„ä»·**ï¼š  
> è¯¥è®ºæ–‡é¦–æ¬¡ç³»ç»Ÿåœ°å°†**å¤šç»´åº¦ã€å¤šæ¨¡æ€çš„å¯¹è¯è´¨é‡å¯¹é½**çº³å…¥RLAIFæ¡†æ¶ï¼Œå¹¶æˆåŠŸé€‚é…åˆ°**å…¨åŒå·¥æµå¼SDS**ä¸­ï¼Œæ ‡å¿—ç€ä»â€œä»…ä¼˜åŒ–è¯­ä¹‰â€è¿ˆå‘â€œæ•´ä½“å¯¹è¯ä½“éªŒä¼˜åŒ–â€çš„é‡è¦ä¸€æ­¥ã€‚å‘å¸ƒçš„**å¤šå¥–åŠ±DPOæ•°æ®é›†**å°†æˆä¸ºæ¨åŠ¨è¯­éŸ³å¯¹è¯ç³»ç»Ÿå¯¹é½ç ”ç©¶çš„å…³é”®èµ„æºã€‚

</details>

---

### 13. [MetaGen: Self-Evolving Roles and Topologies for Multi-Agent LLM Reasoning](https://arxiv.org/abs/2601.19290)

**Authors**: Yimeng Wang, Jiaxing Zhao, Hongbin Xie, Hexing Ma, Yuzhen Lei, Shuangxue Liu, Xuan Song, Zichen Zhang, Haoran Zhang  
**Category**: cs.CL  
**Published**: 2026-01-28  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.19290v1  

#### Abstract
Large language models are increasingly deployed as multi-agent systems, where specialized roles communicate and collaborate through structured interactions to solve complex tasks that often exceed the capacity of a single agent. However, most existing systems still rely on a fixed role library and a...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# MetaGen: Self-Evolving Roles and Topologies for Multi-Agent LLM Reasoning è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³äº†ä»€ä¹ˆé—®é¢˜

å½“å‰çš„ **Multi-Agent Systems (MAS)** åœ¨åŸºäº LLM çš„å¤æ‚ä»»åŠ¡æ¨ç†ä¸­å­˜åœ¨ä»¥ä¸‹ä¸‰å¤§ç“¶é¢ˆï¼š

- **Task Mismatch**ï¼šå›ºå®šçš„è§’è‰²æ± ï¼ˆå¦‚ planner/solver/verifierï¼‰éš¾ä»¥é€‚åº”å¤šæ ·åŒ–çš„ä»»åŠ¡éœ€æ±‚ï¼Œå¯¼è‡´è§’è‰²ä¸ä»»åŠ¡ä¸åŒ¹é…ã€‚
- **Structural Closure**ï¼šåä½œæ‹“æ‰‘ï¼ˆtopologyï¼‰åœ¨æ¨ç†å¼€å§‹åå³è¢«å†»ç»“ï¼ˆexecution-frozenï¼‰ï¼Œæ— æ³•æ ¹æ®è¿è¡Œæ—¶åé¦ˆåŠ¨æ€è°ƒæ•´ã€‚
- **High Cost**ï¼šæ‰‹åŠ¨è®¾è®¡è§’è‰²æç¤ºå’Œé€šä¿¡ç»“æ„æˆæœ¬é«˜æ˜‚ï¼Œä¸”ç¼ºä¹å¯å¤ç”¨æ€§å’Œè‡ªé€‚åº”èƒ½åŠ›ã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº†ç³»ç»Ÿçš„çµæ´»æ€§ã€é²æ£’æ€§å’Œæ•ˆç‡ã€‚

---

### âœ… æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯

ä½œè€…æå‡º **MetaGen**ï¼Œä¸€ä¸ª **training-free** çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨ **inference time** åŠ¨æ€ç”Ÿæˆå’Œæ¼”åŒ–è§’è‰²ä¸åä½œæ‹“æ‰‘ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

- **Dynamic Role Generation & Revision**  
  å¼•å…¥ **Architect Agent**ï¼Œæ ¹æ®æŸ¥è¯¢ï¼ˆqueryï¼‰è‡ªåŠ¨ç”Ÿæˆå€™é€‰è§’è‰²ï¼Œå¹¶é€šè¿‡ **schema åˆæ³•æ€§æ£€æŸ¥** å’Œ **è¯­ä¹‰å¤šæ ·æ€§é—¨æ§ï¼ˆdiversity gatingï¼‰** æ„å»ºå¯æ§çš„åŠ¨æ€è§’è‰²æ± ï¼ˆdynamic role poolï¼‰ã€‚

- **Self-Evolving Topology**  
  ä¸å†ä½¿ç”¨å›ºå®šçš„é“¾å¼ã€æ˜Ÿå‹æˆ–å…¨è¿æ¥å›¾ï¼Œè€Œæ˜¯æ„å»ºä¸€ä¸ªå¯è¿­ä»£æ¼”åŒ–çš„ **DAGï¼ˆDirected Acyclic Graphï¼‰**ã€‚ç³»ç»Ÿåœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­æ ¹æ®è½»é‡çº§åé¦ˆä¿¡å·ï¼ˆå¦‚æµ‹è¯•å¤±è´¥ã€æ ¼å¼é”™è¯¯ï¼‰åŠ¨æ€æ›´æ–°è§’è‰²æç¤ºï¼ˆprompt rewriteï¼‰å’Œè¾¹è¿æ¥ï¼ˆedge explorationï¼‰ã€‚

- **Inference-Time Evolution Loop**  
  æ”¯æŒä¸¤ç§å±‚æ¬¡çš„æ¼”åŒ–ï¼š
  - **Intra-task Evolution**ï¼šå•ä¸ªä»»åŠ¡å†…éƒ¨çš„å®æ—¶ä¼˜åŒ–ï¼ˆprompt rewrite + edge updateï¼‰
  - **Inter-task Evolution**ï¼šè·¨ä»»åŠ¡ç§¯ç´¯ç»éªŒï¼Œæ›´æ–°é€‰æ‹©å…ˆéªŒï¼ˆpriorsï¼‰å¹¶å›ºåŒ–éªŒè¯æœ‰æ•ˆçš„è§’è‰²åˆ°è§’è‰²ç¼“å­˜ï¼ˆRole Cacheï¼‰

- **Training-Free & Auditable**  
  æ‰€æœ‰ä¼˜åŒ–å‡åœ¨æ¨ç†é˜¶æ®µå®Œæˆï¼Œæ— éœ€å¾®è°ƒ backbone LLM æƒé‡ã€‚åŒæ—¶å®Œæ•´è®°å½•è§’è‰²ç”Ÿæˆã€ç»“æ„ä¿®æ”¹å’Œåé¦ˆè§¦å‘è¿‡ç¨‹ï¼Œæå‡å¯è§£é‡Šæ€§ä¸å¯å¤ç°æ€§ã€‚

---

### âœ… ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | MetaGen |
|------|--------|--------|
| è§’è‰²ç®¡ç† | å›ºå®šè§’è‰²åº“ï¼ˆFixed Role Poolï¼‰ | åŠ¨æ€ç”Ÿæˆ + æŸ¥è¯¢æ¡ä»¶åŒ–è§’è‰² |
| æ‹“æ‰‘ç»“æ„ | é¢„è®¾æˆ–è®­ç»ƒåå†»ç»“ï¼ˆExecution-Frozenï¼‰ | æ¨ç†æ—¶è‡ªæˆ‘æ¼”åŒ–ï¼ˆSelf-Evolvingï¼‰ |
| æˆæœ¬æ§åˆ¶ | ä¾èµ–äººå·¥å·¥ç¨‹ | è‡ªåŠ¨åŒ– + æˆæœ¬æ„ŸçŸ¥åœæ­¢æœºåˆ¶ |
| å¯æ‰©å±•æ€§ | å†·å¯åŠ¨å·® | è·¨ä»»åŠ¡ç§¯ç´¯å…ˆéªŒä¸è§’è‰²æ¨¡æ¿ |
| æ˜¯å¦éœ€è¦è®­ç»ƒ | å¤šæ•° topology designer éœ€è¦è®­ç»ƒ | å®Œå…¨ training-free |

> âœ… **MetaGen å®ç°äº†â€œæ— éœ€è®­ç»ƒå³å¯å®ç°è§’è‰²ä¸ç»“æ„åŒé‡è‡ªé€‚åº”â€çš„çªç ´**ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†

æ¶µç›–äº”ç±»å…¸å‹å¤æ‚æ¨ç†ä»»åŠ¡ï¼š

| æ•°æ®é›† | ä»»åŠ¡ç±»å‹ | è¯„ä¼°æŒ‡æ ‡ |
|-------|--------|---------|
| **GSM8K** | å¤šæ­¥æ•°å­¦æ¨ç† | Exact Match Accuracy |
| **HumanEval** | ä»£ç ç”Ÿæˆ | Pass@1 |
| **MMLU** | å¹¿æ³›çŸ¥è¯†ä¸æ¨ç† | Classification Accuracy |
| **AQuA** | ä»£æ•°æ–‡å­—é¢˜ | Exact Match Accuracy |
| **MNLI** | è‡ªç„¶è¯­è¨€æ¨æ–­ | Classification Accuracy |

---

### âš™ï¸ å®éªŒè®¾ç½®

- **Backbone Model**ï¼šç»Ÿä¸€ä½¿ç”¨ **DeepSeek-V3**ï¼Œä»¥éš”ç¦»æ¨¡å‹å·®å¼‚å½±å“ã€‚
- **Semantic Encoder**ï¼š`SentenceTransformer all-MiniLM-L6-v2` ç”¨äºè®¡ç®—è§’è‰²è¯­ä¹‰è·ç¦»ã€‚
- **Architect è®¾ç½®**ï¼šæ¯å®ä¾‹ç”Ÿæˆ 3 ä¸ªå€™é€‰è§’è‰²ï¼ŒTop-K=2 è¿›è¡Œè§’è‰²é€‰æ‹©ã€‚
- **æ¢ç´¢ç­–ç•¥**ï¼šÎµ-greedyï¼ˆÎµ=0.15ï¼‰ï¼Œå¥–åŠ±å‡½æ•°ä¸º $ R = \mathbb{I}(pass) - \lambda_{cost} \cdot C_{token} $ï¼Œå…¶ä¸­ $\lambda_{cost}=0.001$ã€‚
- **è¯„ä¼°æ–¹å¼**ï¼šä¸‰æ¬¡ç‹¬ç«‹è¿è¡Œå–å¹³å‡å€¼ã€‚

---

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”

åˆ†ä¸ºä¸‰ç±»è¿›è¡Œæ¯”è¾ƒï¼š

#### ï¼ˆ1ï¼‰Single-Agent Prompting
- Vanilla
- CoT (Zero-shot / Few-shot)
- Self-Consistency (SC)

#### ï¼ˆ2ï¼‰Fixed-Topology Multi-Agent
- Chain, Star, Tree, Complete Graph, Random Graph
- LLM-Debate

#### ï¼ˆ3ï¼‰Automated Topology Designers
- **GPTSwarm**, **AFlow**, **G-Designer**, **ARG-Designer**

> ç‰¹åˆ«å…³æ³¨æ˜¯å¦æ”¯æŒï¼š
> - **Dynamic Role Pool (Dyn.)**
> - **Training-Free (T-free)**
> - **Inference-Time Evolution (Evol.)**

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 1ï¼‰

| Method | GSM8K | HumanEval | MMLU | AQuA | MNLI | **Average** |
|--------|-------|-----------|------|------|------|------------|
| G-Designer (SOTA) | 96.3 | 94.2 | 93.5 | 89.0 | â€” | 93.3 |
| **MetaGen (Ours)** | **96.4** | **95.1** | **93.5** | **95.7** | **94.8** | **95.1** |

âœ… **MetaGen åœ¨æ‰€æœ‰å¯æ¯”ä»»åŠ¡ä¸Šå…¨é¢è¶…è¶Šæœ€å¼ºåŸºçº¿ G-Designerï¼Œå¹³å‡å‡†ç¡®ç‡æå‡ 1.8%**ã€‚

- åœ¨ **AQuA** ä¸Šæå‡ **+6.7pp**ï¼ˆä» 89.0 åˆ° 95.7ï¼‰ï¼Œæ˜¾ç¤ºå…¶åœ¨å¤šæ­¥æ¨ç†ä¸­çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚
- åœ¨ **MNLI** ä¸Šè¾¾åˆ° **94.8**ï¼Œè¿œè¶… CoT few-shot çš„ 85.4ï¼ˆ+9.4ppï¼‰ã€‚
- åœ¨ **HumanEval** ä¸Šè¾¾ **95.1**ï¼Œä¼˜äº G-Designer çš„ 94.2ã€‚

---

### ğŸ’° æˆæœ¬æ•ˆç‡åˆ†æï¼ˆTable 2ï¼‰

| Method | #Inference Token | #Overall Token |
|--------|------------------|----------------|
| Complete Graph | 9.8Ã—10â¶ | 9.8Ã—10â¶ |
| G-Designer | 8.2Ã—10âµ | 8.5Ã—10âµ |
| **MetaGen** | **1.2Ã—10âµ** | **1.2Ã—10âµ** |

âœ… **MetaGen æ¨ç† token æ¶ˆè€—ä»…ä¸º G-Designer çš„ ~15%ï¼Œè¾ƒ Complete Graph é™ä½ 87.8%**ã€‚

> å®ç°äº† **æ›´é«˜ç²¾åº¦ + æ›´ä½æˆæœ¬** çš„å¸•ç´¯æ‰˜å‰æ²¿çªç ´ã€‚

---

### ğŸ§ª æ¶ˆèå®éªŒç»“æœï¼ˆTable 4ï¼‰

| Variant | HumanEval â†“ | MMLU â†“ |
|--------|-------------|--------|
| Full MetaGen | 95.1 | 93.5 |
| w/o Role Generation | 92.1 (**âˆ’3.0**) | 91.1 (**âˆ’2.4**) |
| w/o Learned Policy | 93.9 (âˆ’1.2) | 92.8 (âˆ’0.7) |
| w/o Intra-task Evolution | 92.7 (âˆ’2.4) | 91.7 (âˆ’1.8) |
| w/o Cross-instance Memory | 92.7 (âˆ’2.4) | 92.6 (âˆ’0.9) |

ğŸ“Œ **å…³é”®å‘ç°**ï¼š
- **Role Generation æœ€é‡è¦**ï¼šç§»é™¤åæ€§èƒ½ä¸‹é™æœ€å¤§ï¼Œè¯´æ˜æŸ¥è¯¢æ¡ä»¶åŒ–è§’è‰²ç”Ÿæˆæ˜¯æ ¸å¿ƒé©±åŠ¨åŠ›ã€‚
- **Intra-task Evolution æ˜¾è‘—æå‡è´¨é‡**ï¼šå…è®¸è¿è¡Œæ—¶ä¿®æ­£é”™è¯¯è·¯å¾„ã€‚
- **Cross-instance Memory æå‡å†·å¯åŠ¨è¡¨ç°**ï¼šé€šè¿‡è§’è‰²å¤ç”¨åŠ é€Ÿåç»­ä»»åŠ¡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **è§’è‰²ä¸æ‹“æ‰‘åº”ä½œä¸ºæ¨ç†æ—¶å¯ç¼–è¾‘å¯¹è±¡**  
   å°† role specifications å’Œ communication topology è§†ä¸ºå¯åœ¨ inference time ç¼–è¾‘çš„ä¸€ç­‰å®ä½“ï¼Œèƒ½æ˜¾è‘—æå‡é€‚åº”æ€§ã€‚

2. **æ— éœ€è®­ç»ƒä¹Ÿèƒ½å®ç°é«˜æ•ˆè‡ªç»„ç»‡åä½œ**  
   MetaGen å®Œå…¨æ— éœ€æ›´æ–° backbone LLM å‚æ•°ï¼Œä»…é€šè¿‡è½»é‡çº§åé¦ˆé©±åŠ¨ prompt å’Œ graph è°ƒæ•´ï¼Œå³å¯å®ç° superior æ€§èƒ½ã€‚

3. **åŠ¨æ€æ¼”åŒ–æ˜¾è‘—å¢å¼ºé²æ£’æ€§ä¸æ³›åŒ–èƒ½åŠ›**
   - åœ¨éå¹³ç¨³ä»»åŠ¡æµä¸­ï¼ˆMMLU â†’ MNLI â†’ HumanEvalï¼‰ï¼ŒMetaGen æ•´ä½“å‡†ç¡®ç‡ **92.7% vs Frozen 90.0%**ï¼Œä¸” token æ›´å°‘ã€‚
   - åˆ†å¸ƒåç§»åçš„å†·å¯åŠ¨é˜¶æ®µï¼ŒMetaGen å‡†ç¡®ç‡é«˜å‡º 5â€“10 ä¸ªç™¾åˆ†ç‚¹ã€‚
   - å¯¹å™ªå£°èŠ‚ç‚¹å’Œè¾¹å…·æœ‰å¼ºé²æ£’æ€§ï¼Œæ€§èƒ½éšæ‰°åŠ¨å¢åŠ ç¼“æ…¢ä¸‹é™ã€‚

4. **äººå·¥æç¤ºå·¥ç¨‹æˆæœ¬å¤§å¹…é™ä½**  
   å¦‚ Figure 3 æ‰€ç¤ºï¼Œåœ¨ç›¸åŒæ‰‹åŠ¨æç¤ºé¢„ç®—ä¸‹ï¼ŒMetaGen æ€§èƒ½è¿œè¶…äººå·¥è®¾è®¡ï¼›ç”šè‡³åœ¨æä½é¢„ç®—ä¸‹ä»æ¥è¿‘é¥±å’Œæ€§èƒ½ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

- **ä¾èµ– Architect Agent çš„ç”Ÿæˆè´¨é‡**ï¼šè‹¥ Architect ç”Ÿæˆæ— æ•ˆæˆ–å†—ä½™è§’è‰²ï¼Œå¯èƒ½å¼•å…¥å™ªå£°ã€‚
- **è¯­ä¹‰ç¼–ç å™¨é™åˆ¶**ï¼šå½“å‰ä½¿ç”¨è½»é‡çº§ SentenceTransformerï¼Œå¯¹ç»†ç²’åº¦è¯­ä¹‰åŒºåˆ†èƒ½åŠ›æœ‰é™ã€‚
- **æœªå¤„ç†å¹¶å‘æˆ–å¼‚æ­¥äº¤äº’**ï¼šç›®å‰å‡è®¾åŒæ­¥æ‰§è¡Œ DAGï¼Œå°šæœªæ”¯æŒæ›´å¤æ‚çš„å¹¶è¡Œè°ƒåº¦ã€‚
- **è§’è‰²ç¼“å­˜å¢é•¿ä¸å¯æ§**ï¼šé•¿æœŸè¿è¡Œå¯èƒ½å¯¼è‡´è§’è‰²åº“è†¨èƒ€ï¼Œéœ€å¼•å…¥è€åŒ–æœºåˆ¶ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **å¼•å…¥æ›´å¼ºçš„ meta-controller**ï¼šè®© Architect å…·å¤‡ä¸»åŠ¨æ¢ç´¢ä¸è§„åˆ’èƒ½åŠ›ï¼Œè€Œéè¢«åŠ¨å“åº”åé¦ˆã€‚
2. **æ”¯æŒå¼‚æ­¥ä¸å¾ªç¯å›¾ç»“æ„**ï¼šæ‹“å±•è‡³æ›´å¤æ‚çš„åä½œæ¨¡å¼ï¼ˆå¦‚ feedback loopsï¼‰ã€‚
3. **è‡ªåŠ¨åŒ–è§’è‰²å‹ç¼©ä¸å»é‡**ï¼šç»´æŠ¤ç²¾ç®€é«˜æ•ˆçš„ Role Libraryã€‚
4. **åº”ç”¨äºçœŸå®ä¸–ç•Œåœºæ™¯**ï¼šå¦‚è½¯ä»¶å¼€å‘æµæ°´çº¿ã€ç§‘ç ”åä½œã€åŸå¸‚è§„åˆ’ç­‰ long-horizon å¤æ‚ä»»åŠ¡ã€‚

---

## âœ… æ€»ç»“

**MetaGen å¼€è¾Ÿäº†ä¸€æ¡å…¨æ–°çš„è·¯å¾„ï¼šé€šè¿‡ inference-time å¯¹æ–‡æœ¬çº§è§’è‰²ä¸ç¦»æ•£æ‹“æ‰‘çš„è”åˆä¼˜åŒ–ï¼Œæ„å»ºå¯æ‰©å±•ã€è‡ªé€‚åº”ã€ä½æˆæœ¬çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ**ã€‚å®ƒè¯æ˜äº†æ— éœ€è®­ç»ƒå³å¯å®ç°é«˜æ€§èƒ½åä½œæ¼”åŒ–ï¼Œä¸ºæœªæ¥ **scalable and adaptive MAS** æä¾›äº†å®ç”¨èŒƒå¼ã€‚

</details>

---

### 14. [Modular Foundation Model Inference at the Edge: Network-Aware Microservice Optimization](https://arxiv.org/abs/2601.19563)

**Authors**: Juan Zhu, Zixin Wang, Shenghui Song, Jun Zhang, Khaled Ben Letaief  
**Category**: cs.DC  
**Published**: 2026-01-28  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.19563v1  

#### Abstract
Foundation models (FMs) unlock unprecedented multimodal and multitask intelligence, yet their cloud-centric deployment precludes real-time responsiveness and compromises user privacy. Meanwhile, monolithic execution at the edge remains infeasible under stringent resource limits and uncertain network...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šModular Foundation Model Inference at the Edge: Network-Aware Microservice Optimization**

---

## 1. **è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
- **è¾¹ç¼˜ç«¯éƒ¨ç½² Foundation Models (FMs)** å­˜åœ¨ä¸¤å¤§æŒ‘æˆ˜ï¼š
  1. **èµ„æºå—é™**ï¼šFMs å‚æ•°é‡å¤§ï¼Œä¼ ç»Ÿ **monolithic æ¶æ„**æ— æ³•åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šè¿è¡Œã€‚
  2. **åŠ¨æ€ä¸ç¡®å®šæ€§**ï¼šä»»åŠ¡åˆ°è¾¾å…·æœ‰æ—¶ç©ºæ³¢åŠ¨æ€§ï¼Œç½‘ç»œçŠ¶æ€ï¼ˆå¦‚æ— çº¿ä¿¡é“ï¼‰å’Œèµ„æºç«äº‰å¯¼è‡´ **latency ä¸ç¡®å®šæ€§å¼º**ï¼Œéš¾ä»¥ä¿éšœ QoSã€‚
- ç°æœ‰å¾®æœåŠ¡ï¼ˆMSï¼‰éƒ¨ç½²æ–¹æ³•é€šå¸¸å°†æ‰€æœ‰ MS è§†ä¸ºåŒè´¨åŒ–ç»„ä»¶ï¼Œå¿½ç•¥äº† **core MS ä¸ light MS çš„åŠŸèƒ½ä¸å¯¹ç§°æ€§**ï¼Œå¯¼è‡´èµ„æºåŒ¹é…ç²—ç²’åº¦ã€QoS ä¿éšœèƒ½åŠ›å¼±ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯**
æœ¬æ–‡æå‡ºä¸€ç§ **ä¸¤å±‚ï¼ˆtwo-tierï¼‰å¾®æœåŠ¡éƒ¨ç½²æ¡†æ¶**ï¼Œå……åˆ†åˆ©ç”¨ FM æ¨ç†æµç¨‹ä¸­ **core ä¸ light MS çš„åŠŸèƒ½å·®å¼‚**ï¼š

#### **ä¸»è¦åˆ›æ–°ç‚¹ï¼š**
- âœ… **æ··åˆéƒ¨ç½²ç­–ç•¥ï¼ˆHybrid Deployment Strategyï¼‰**ï¼š
  - **Core MSsï¼ˆé‡å‹ã€æœ‰çŠ¶æ€ï¼‰**ï¼šé™æ€éƒ¨ç½²ï¼ŒåŸºäºé•¿æœŸè´Ÿè½½ç»Ÿè®¡è¿›è¡Œ **ç½‘ç»œæ„ŸçŸ¥çš„æ•´æ•°è§„åˆ’ä¼˜åŒ–**ï¼Œå½¢æˆå¯é è®¡ç®—ä¸»å¹²ã€‚
  - **Light MSsï¼ˆè½»é‡ã€æ— çŠ¶æ€ï¼‰**ï¼šåŠ¨æ€åœ¨çº¿éƒ¨ç½²ï¼Œç”±ä½å¤æ‚åº¦æ§åˆ¶å™¨å®æ—¶è°ƒæ•´å®ä¾‹æ•°é‡å’Œå¹³è¡Œåº¦ï¼ˆparallelismï¼‰ï¼Œé€‚åº”çŸ­æœŸæ³¢åŠ¨ã€‚

- âœ… **é¢å‘æ•…éšœå®¹å¿çš„é™æ€éƒ¨ç½²æ¨¡å‹**ï¼š
  - æ„å»ºä¸€ä¸ª **ç¨€ç–çº¦æŸçš„æ•´æ•°è§„åˆ’ï¼ˆsparsity-constrained integer programï¼‰**ï¼Œè”åˆä¼˜åŒ–éƒ¨ç½²æˆæœ¬ä¸ **ç»Ÿè®¡ QoS åˆ†æ•°ï¼ˆQoS scoreï¼‰**ã€‚
  - å¼•å…¥è¾…åŠ©å˜é‡å’Œå¤šæ ·æ€§çº¦æŸï¼ˆdiversity constraintsï¼‰ï¼Œé˜²æ­¢æœåŠ¡é›†ä¸­äºå•ç‚¹ï¼Œæå‡ç³»ç»Ÿé²æ£’æ€§ã€‚

- âœ… **åŸºäºæœ‰æ•ˆå®¹é‡ç†è®ºçš„åŠ¨æ€æ§åˆ¶æœºåˆ¶**ï¼š
  - é¦–æ¬¡å°† **Effective Capacity Theory** å¼•å…¥ MS éƒ¨ç½²ï¼Œå»ºç«‹ **parallelism level ä¸ç»Ÿè®¡å»¶è¿Ÿè¾¹ç•Œä¹‹é—´çš„æ˜ å°„å…³ç³»**ï¼Œå®ç°å¯¹å°¾éƒ¨å»¶è¿Ÿçš„æ¦‚ç‡æ€§ä¿è¯ã€‚
  - ç»“åˆ **Lyapunov optimization æ¡†æ¶**ï¼Œè®¾è®¡ä½å¤æ‚åº¦åœ¨çº¿ç®—æ³•ï¼ˆè´ªå¿ƒå¯å‘å¼ï¼‰ï¼Œåœ¨æ¯æ—¶éš™æœ€å°åŒ– drift-plus-penalty è¡¨è¾¾å¼ï¼Œå¹³è¡¡æˆæœ¬ä¸ QoSã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹é¢ | æœ¬æ–‡æ–¹æ³• | ä¼ ç»Ÿæ–¹æ³• |
|------|--------|---------|
| **éƒ¨ç½²ç²’åº¦** | åŒºåˆ† core/light MSï¼Œç»†ç²’åº¦èµ„æºåŒ¹é… | åŒè´¨åŒ–å¤„ç†ï¼Œå¿½ç•¥åŠŸèƒ½å·®å¼‚ |
| **QoS ä¿éšœ** | åŸºäºæœ‰æ•ˆå®¹é‡æä¾› **æ¦‚ç‡æ€§å»¶è¿Ÿä¿è¯** | å¹³å‡å»¶è¿Ÿå»ºæ¨¡ï¼Œå¿½è§†å°¾éƒ¨å»¶è¿Ÿ |
| **åŠ¨æ€é€‚åº”æ€§** | åœ¨çº¿æ§åˆ¶å™¨å“åº”å®æ—¶è´Ÿè½½å˜åŒ– | é™æ€æˆ–ååº”å¼è°ƒåº¦ï¼Œæ»åæ€§å¼º |
| **é²æ£’æ€§** | æ˜¾å¼ä¼˜åŒ–éƒ¨ç½²å¤šæ ·æ€§ï¼ŒæŠ—å•ç‚¹æ•…éšœ | å®¹æ˜“å‡ºç°çƒ­ç‚¹æˆ–é›†ä¸­éƒ¨ç½² |

---

## 2. **æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **å®éªŒç¯å¢ƒä¸æ‹“æ‰‘**
- æ¨¡æ‹Ÿä¸€ä¸ªå¼‚æ„è¾¹ç¼˜ç½‘ç»œï¼ŒåŒ…å«ï¼š
  - **Edge Devices (EDs)** å’Œ **Edge Servers (ESs)**ï¼Œèµ„æºå®¹é‡ä¸åŒï¼ˆCPU, RAM, GPU, VRAMï¼‰ã€‚
  - èŠ‚ç‚¹é—´é€šè¿‡é€šä¿¡é“¾è·¯è¿æ¥ï¼Œå¸¦å®½ä¸æ—¶å»¶å—æ— çº¿ä¿¡é“å½±å“ï¼ˆNakagami åˆ†å¸ƒå»ºæ¨¡ SNRï¼‰ã€‚
- å‚è€ƒå›¾ç¤ºï¼šFig. 2 å±•ç¤ºäº†åŒ…å« 6 ä¸ª ED å’Œ 3 ä¸ª ES çš„ç½‘ç»œæ‹“æ‰‘ã€‚

### **FM åº”ç”¨æ¨¡å‹**
- è®¾è®¡ä¸€ä¸ªå…¸å‹çš„ **å¤šæ¨¡æ€ FM æ¨ç†åº”ç”¨**ï¼ŒåŒ…å«ï¼š
  - **4 ç§ä»»åŠ¡ç±»å‹**ï¼ˆå¦‚è·¨æ¨¡æ€ç†è§£ã€é—®ç­”ã€åˆ†ç±»ã€é©¾é©¶å†³ç­–ç­‰ï¼‰ã€‚
  - **6 ä¸ª Core MSs**ï¼ˆå¦‚ Transformer ç¼–ç å™¨ã€è§†è§‰éª¨å¹²ï¼‰ã€‚
  - **9 ä¸ª Light MSs**ï¼ˆå¦‚é¢„å¤„ç†ã€åå¤„ç†æ¨¡å—ï¼‰ã€‚
- ä»»åŠ¡ä»¥ DAG å½¢å¼ç»„ç»‡ï¼Œä¾èµ–å…³ç³»è§ Fig. 1ã€‚

### **æ•°æ®é›†ä¸å‚æ•°è®¾ç½®**
- **ä»»åŠ¡åˆ°è¾¾**ï¼šæœä»æ³Šæ¾è¿‡ç¨‹ $ \text{Poisson}([0.15, 1.5]) $ /msã€‚
- **è¾“å…¥å¤§å° $ A_n $**ï¼š[0.5, 4] MBã€‚
- **å¤„ç†é€Ÿç‡ $ f_m $**ï¼š
  - Core MSï¼šå›ºå®šå€¼ï¼ˆ8â€“32 MB/msï¼‰ã€‚
  - Light MSï¼šæœä» Gamma åˆ†å¸ƒï¼Œæ¨¡æ‹Ÿèµ„æºäº‰ç”¨ä¸‹çš„éšæœºæ€§ã€‚
- **å»¶è¿Ÿçº¦æŸ $ D_n $**ï¼š[50, 100] msã€‚
- **æ— çº¿ä¿¡é“ SNR $ \gamma_u $**ï¼šNakagami åˆ†å¸ƒå»ºæ¨¡ã€‚
- **ä»¿çœŸå·¥å…·**ï¼šè‡ªå®šä¹‰äº‹ä»¶é©±åŠ¨æ¨¡æ‹Ÿå™¨ï¼Œé‡‡æ ·å¤šæ¬¡è¿è¡Œå–å¹³å‡ã€‚

### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **On-time Task Completion Rate** | åœ¨æˆªæ­¢æ—¶é—´å†…å®Œæˆçš„ä»»åŠ¡æ¯”ä¾‹ï¼ˆæ ¸å¿ƒ QoS æŒ‡æ ‡ï¼‰ |
| **Total System Cost** | åŒ…æ‹¬éƒ¨ç½²ã€ç»´æŠ¤ã€å¹¶è¡ŒåŒ–å¼€é”€çš„ç»¼åˆæˆæœ¬ |
| **Cost-QoS Trade-off** | æˆæœ¬ä¸å®Œæˆç‡ä¹‹é—´çš„å¹³è¡¡èƒ½åŠ› |
| **Scalability** | åœ¨è´Ÿè½½å¢åŠ ï¼ˆ1.0Ã— â†’ 2.0Ã—ï¼‰ä¸‹çš„æ€§èƒ½ç¨³å®šæ€§ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
1. **LBRR (Least-Loaded Round Robin)**ï¼š
   - å°†æœåŠ¡éƒ¨ç½²åˆ°è´Ÿè½½æœ€ä½èŠ‚ç‚¹ï¼Œä»»åŠ¡è½®è¯¢åˆ†é…ã€‚
   - å¿½ç•¥ QoSï¼Œä»…å…³æ³¨è´Ÿè½½å‡è¡¡ã€‚

2. **GA (Genetic Algorithm)**ï¼š
   - ä½¿ç”¨é—ä¼ ç®—æ³•è”åˆä¼˜åŒ–æˆæœ¬ä¸ QoS è¿è§„ç‡ã€‚
   - å…ƒå¯å‘å¼æœç´¢ï¼Œè®¡ç®—å¼€é”€é«˜ï¼Œæ”¶æ•›ä¸ç¨³å®šã€‚

3. **PropAvg (Ablation of Proposed Method)**ï¼š
   - æœ¬æ–‡æ–¹æ³•çš„æ¶ˆèç‰ˆæœ¬ï¼Œ**ç”¨å¹³å‡å¤„ç†å»¶è¿Ÿä»£æ›¿æœ‰æ•ˆå®¹é‡æ¨¡å‹**ã€‚
   - ç”¨äºéªŒè¯ **tail latency modeling çš„é‡è¦æ€§**ã€‚

---

## 3. **ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
- **å¹³å‡å‡†æ—¶å®Œæˆç‡ï¼ˆAverage On-time Completion Rateï¼‰**ï¼š
  - **æœ¬æ–‡æ–¹æ³•ï¼šè¶…è¿‡ 84%**
  - PropAvgï¼šçº¦ 75%
  - GAï¼šæ³¢åŠ¨è¾ƒå¤§ï¼Œå¹³å‡ ~70%
  - LBRRï¼šä½äº 60%

- **ç³»ç»Ÿæ€»æˆæœ¬**ï¼š
  - æœ¬æ–‡æ–¹æ³•æˆæœ¬é€‚ä¸­ï¼Œæ˜¾è‘—ä½äº GAï¼ˆå› åè€…é¢‘ç¹è¿‡åº¦éƒ¨ç½²ï¼‰ã€‚
  - PropAvg æˆæœ¬ç•¥ä½ï¼Œä½† QoS ä¸‹é™æ˜æ˜¾ã€‚

### **ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœï¼ˆFig. 3ï¼‰**
- **Violin Plot æ˜¾ç¤ºåˆ†å¸ƒç‰¹æ€§**ï¼š
  - **æœ¬æ–‡æ–¹æ³•**ï¼šå®Œæˆç‡åˆ†å¸ƒ **å°–é”ä¸”é›†ä¸­äºé«˜ä½ï¼ˆ>84%ï¼‰**ï¼Œæˆæœ¬åˆ†å¸ƒç´§å‡‘ï¼Œè¡¨æ˜ **ç¨³å®šé«˜æ•ˆ**ã€‚
  - **GA**ï¼šåˆ†å¸ƒå®½æ³›ï¼Œç»“æœæ³¢åŠ¨å¤§ï¼Œè¯´æ˜å…ƒå¯å‘å¼åœ¨éšæœºç¯å¢ƒä¸­éš¾ä»¥æ”¶æ•›ã€‚
  - **PropAvg**ï¼šå®Œæˆç‡åˆ†å¸ƒå‡ºç° **é•¿å°¾ï¼ˆlow completion <60%ï¼‰**ï¼Œåæ˜ å…¶åœ¨é«˜è´Ÿè½½ä¸‹é¢‘ç¹è¿å QoSã€‚
  - **LBRR**ï¼šä½æˆæœ¬ä½†ä½æ€§èƒ½ï¼Œé€‚åˆéå…³é”®åœºæ™¯ã€‚

### **æ¶ˆèå®éªŒç»“æœï¼ˆFig. 4ï¼‰â€”â€”è´Ÿè½½å¯æ‰©å±•æ€§æµ‹è¯•**
åœ¨ç³»ç»Ÿè´Ÿè½½ä» 1.0Ã— å¢åŠ åˆ° 2.0Ã— æ—¶çš„è¡¨ç°ï¼š

| æ–¹æ³• | å‡†æ—¶å®Œæˆç‡è¶‹åŠ¿ | æˆæœ¬å¢é•¿ | æ€»/å‡†æ—¶å®Œæˆç‡å·®è· |
|------|----------------|--------|--------------------|
| **Ours** | ç¼“æ…¢ä¸‹é™ï¼Œä¿æŒ >75% @2.0Ã— | æ¸è¿›ä¸Šå‡ï¼Œæ§åˆ¶è‰¯å¥½ | å·®è·å°ï¼ŒQoS ç¨³å®š |
| **PropAvg** | æ€¥å‰§ä¸‹é™è‡³ <60% @2.0Ã— | æˆæœ¬æ›´ä½ä½†ä»å¤±æ§ | å·®è·å¤§å¹…æ‰©å¤§ï¼Œå¤§é‡ä»»åŠ¡è¶…æ—¶ |

> ğŸ” **å…³é”®å‘ç°**ï¼šPropAvg è™½èŠ‚çœæˆæœ¬ï¼Œä½†åœ¨é«˜è´Ÿè½½ä¸‹ **æ— æ³•åº”å¯¹å°¾éƒ¨å»¶è¿Ÿçˆ†å‘**ï¼Œå¯¼è‡´ QoS å´©æºƒï¼›è€Œæœ¬æ–‡æ–¹æ³•é€šè¿‡ **æœ‰æ•ˆå®¹é‡å»ºæ¨¡æå‰è§„é¿é£é™©**ï¼Œå±•ç°å‡ºæ›´å¼ºé²æ£’æ€§ã€‚

---

## 4. **å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. âœ… **Core-Light åŠŸèƒ½åˆ†ç¦»æ˜¯è¾¹ç¼˜ FM éƒ¨ç½²çš„å…³é”®**ï¼š
   - åˆ©ç”¨ä¸¤è€…å¯åŠ¨æ—¶é—´ã€å®¹é”™æ€§ã€èµ„æºéœ€æ±‚çš„å·®å¼‚ï¼Œå®æ–½ **é™æ€+åŠ¨æ€æ··åˆéƒ¨ç½²** æ˜¯å®ç° QoS ä¸æˆæœ¬å¹³è¡¡çš„æœ‰æ•ˆè·¯å¾„ã€‚

2. âœ… **ç»Ÿè®¡ QoS å»ºæ¨¡ä¼˜äºå¹³å‡å»ºæ¨¡**ï¼š
   - ä½¿ç”¨ **Effective Capacity Theory** å¯¹ light MS çš„å¤„ç†å»¶è¿Ÿè¿›è¡Œæ¦‚ç‡å»ºæ¨¡ï¼Œèƒ½æ›´å‡†ç¡®é¢„æµ‹å°¾éƒ¨è¡Œä¸ºï¼Œé¿å…â€œå¹³å‡è‰¯å¥½ä½†å¶å°”å´©æºƒâ€çš„é—®é¢˜ã€‚

3. âœ… **å¤šæ ·æ€§éƒ¨ç½²å¢å¼ºç³»ç»Ÿé²æ£’æ€§**ï¼š
   - æ˜¾å¼å¼•å…¥éƒ¨ç½²å¤šæ ·æ€§çº¦æŸï¼ˆC6ï¼‰ï¼Œé˜²æ­¢æ ¸å¿ƒæœåŠ¡é›†ä¸­åœ¨å•ä¸€èŠ‚ç‚¹ï¼Œæå‡äº†å®¹é”™èƒ½åŠ›å’Œè´Ÿè½½å‡è¡¡æ½œåŠ›ã€‚

4. âœ… **Lyapunov + è´ªå¿ƒç­–ç•¥å®ç°å®æ—¶å¯è¡Œæ€§**ï¼š
   - æ‰€æåœ¨çº¿ç®—æ³•å¤æ‚åº¦ä½ï¼ˆ$ O(M|J||M|) $ï¼‰ï¼Œå¯åœ¨æ¯«ç§’çº§å†³ç­–çª—å£å†…è¿è¡Œï¼Œé€‚ç”¨äºçœŸå®è¾¹ç¼˜ç¯å¢ƒã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- â— **ä¾èµ–å‡†ç¡®çš„æ¦‚ç‡åˆ†å¸ƒä¼°è®¡**ï¼šéœ€è¦é¢„å…ˆæŒæ¡ä»»åŠ¡åˆ°è¾¾ã€ä¿¡é“çŠ¶æ€ã€å¤„ç†é€Ÿç‡çš„åˆ†å¸ƒç‰¹å¾ï¼Œåœ¨å¿«é€Ÿå˜åŒ–ç¯å¢ƒä¸­å¯èƒ½éœ€æŒç»­å­¦ä¹ æ›´æ–°ã€‚
- â— **æœªè€ƒè™‘æ¨¡å‹ç²¾åº¦æŸå¤±**ï¼šMS æ‹†åˆ†å¯èƒ½å¯¼è‡´æ¨ç†ç²¾åº¦ä¸‹é™ï¼Œæœ¬æ–‡èšç„¦éƒ¨ç½²ä¼˜åŒ–ï¼Œæœªæ¶‰åŠ accuracy-aware å†³ç­–ã€‚
- â— **è´ªå¿ƒç®—æ³•éå…¨å±€æœ€ä¼˜**ï¼šè™½ç„¶é«˜æ•ˆï¼Œä½†ä»å¯èƒ½é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼Œå°¤å…¶åœ¨é«˜åº¦è€¦åˆçš„æœåŠ¡ä¾èµ–å›¾ä¸­ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- ğŸ”® **ç»“åˆ Learning-based Solver**ï¼šä½¿ç”¨ GNN æˆ– RL æ›¿ä»£è´ªå¿ƒç­–ç•¥ï¼Œæå‡åœ¨çº¿å†³ç­–è´¨é‡ã€‚
- ğŸ”® **Accuracy-Aware Optimization**ï¼šå°†æ¨¡å‹æ‹†åˆ†ç²’åº¦ã€é‡åŒ–ç­–ç•¥çº³å…¥è”åˆä¼˜åŒ–æ¡†æ¶ã€‚
- ğŸ”® **è·¨å±‚ååŒä¼˜åŒ–**ï¼šè”åˆè°ƒåº¦é€šä¿¡èµ„æºï¼ˆå¸¦å®½åˆ†é…ï¼‰ã€è®¡ç®—èµ„æºï¼ˆvCPU/vGPUï¼‰ä¸éƒ¨ç½²ç­–ç•¥ã€‚
- ğŸ”® **å‘ 6G Space-Air-Ground Networks æ‰©å±•**ï¼šåº”ç”¨äºæ›´å¤æ‚çš„ç©ºå¤©åœ°ä¸€ä½“åŒ–ç½‘ç»œä¸­çš„ FM æ¨ç†ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡é€šè¿‡ **åŒºåˆ† core ä¸ light å¾®æœåŠ¡çš„åŠŸèƒ½ç‰¹æ€§**ï¼Œæå‡ºäº†ä¸€ç§ **ç½‘ç»œæ„ŸçŸ¥ã€ç»Ÿè®¡ QoS é©±åŠ¨çš„ä¸¤å±‚éƒ¨ç½²æ¡†æ¶**ï¼Œåœ¨ä¿è¯ **>84% å‡†æ—¶å®Œæˆç‡**çš„åŒæ—¶å®ç°äº† **æˆæœ¬å¯æ§ä¸å¼ºå¥å¯æ‰©å±•æ€§**ï¼Œä¸ºè¾¹ç¼˜ä¾§é«˜æ•ˆã€å¯é åœ°è¿è¡Œ Foundation Models æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 15. [Variational Quantum Circuit-Based Reinforcement Learning for Dynamic Portfolio Optimization](https://arxiv.org/abs/2601.18811)

**Authors**: Vincent Gurgul, Ying Chen, Stefan Lessmann  
**Category**: cs.LG  
**Published**: 2026-01-28  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.18811v1  

#### Abstract
This paper presents a Quantum Reinforcement Learning (QRL) solution to the dynamic portfolio optimization problem based on Variational Quantum Circuits. The implemented QRL approaches are quantum analogues of the classical neural-network-based Deep Deterministic Policy Gradient and Deep Q-Network al...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
æœ¬æ–‡è‡´åŠ›äºè§£å†³**åŠ¨æ€æŠ•èµ„ç»„åˆä¼˜åŒ–ï¼ˆDynamic Portfolio Optimizationï¼‰**ä¸­çš„åºåˆ—å†³ç­–éš¾é¢˜ã€‚ä¼ ç»Ÿæ–¹æ³•å¦‚å‡å€¼-æ–¹å·®ä¼˜åŒ–ï¼ˆMean-Variance Optimization, MVOï¼‰æ˜¯é™æ€çš„ï¼Œæ— æ³•é€‚åº”å¸‚åœºçŠ¶æ€éšæ—¶é—´å˜åŒ–çš„åŠ¨æ€ç‰¹æ€§ã€‚å°½ç®¡ç»å…¸æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDeep RLï¼‰åœ¨è¯¥é¢†åŸŸå–å¾—è¿›å±•ï¼Œä½†å…¶æ¨¡å‹é€šå¸¸å‚æ•°é‡å¤§ã€è®­ç»ƒæ•ˆç‡ä½ï¼Œä¸”éš¾ä»¥åœ¨é«˜ç»´éå¹³ç¨³ç¯å¢ƒä¸­ä¿æŒé²æ£’æ€§ã€‚

æ­¤å¤–ï¼Œç°æœ‰çš„é‡å­è®¡ç®—åº”ç”¨äºæŠ•èµ„ç»„åˆä¼˜åŒ–çš„ç ”ç©¶å¤§å¤šå±€é™äº**é™æ€çš„ QUBOï¼ˆQuadratic Unconstrained Binary Optimizationï¼‰é—®é¢˜æ±‚è§£**ï¼Œç¼ºä¹å¯¹è¿ç»­ã€åŠ¨æ€ç­–ç•¥å­¦ä¹ çš„æ”¯æŒã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯**
æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåŸºäº**å˜åˆ†é‡å­ç”µè·¯ï¼ˆVariational Quantum Circuits, VQCsï¼‰**çš„å…¨æ–°**é‡å­å¼ºåŒ–å­¦ä¹ ï¼ˆQuantum Reinforcement Learning, QRLï¼‰æ¡†æ¶**ï¼Œç”¨äºåŠ¨æ€æŠ•èµ„ç»„åˆä¼˜åŒ–ã€‚å…·ä½“åˆ›æ–°åŒ…æ‹¬ï¼š

- **é¦–æ¬¡å°† QRL åº”ç”¨äºåŠ¨æ€æŠ•èµ„ç»„åˆä¼˜åŒ–ä»»åŠ¡**ï¼Œå®ç°äº†ç«¯åˆ°ç«¯çš„é‡å­ç­–ç•¥å­¦ä¹ ã€‚
- è®¾è®¡äº†**å®Œå…¨é‡å­åŒ–çš„ Actor-Critic æ¶æ„**ï¼Œå…¶ä¸­ Actor å’Œ Critic å‡ç”± VQC å®ç°ï¼Œè€Œéæ··åˆæ¨¡å‹ã€‚
- é‡‡ç”¨**æŒ¯å¹…ç¼–ç ï¼ˆAmplitude Encodingï¼‰** å°†é«˜ç»´é‡‘èæ—¶åºæ•°æ®å‹ç¼©ä¸ºä½ç»´é‡å­æ€ï¼Œå®ç°é«˜æ•ˆçš„ä¿¡æ¯åµŒå…¥ã€‚
- å®ç°äº†é‡å­ç‰ˆæœ¬çš„ **Deep Deterministic Policy Gradient (DDPG)** å’Œ **Deep Q-Network (DQN)** ç®—æ³•ï¼Œåˆ†åˆ«ç§°ä¸º **Quantum DDPG** å’Œ **Quantum DQN**ã€‚
- å¼•å…¥**æ‰©å±•ç‰¹å¾æ˜ å°„ï¼ˆextended feature mapï¼‰** åˆ°æŒ¯å¹…ç¼–ç ä¸­ï¼Œä»¥å¢å¼ºè¡¨è¾¾èƒ½åŠ›å¹¶ç¼“è§£â€œè´«ç˜ é«˜åŸâ€ï¼ˆbarren plateausï¼‰é—®é¢˜ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- **æé«˜çš„å‚æ•°æ•ˆç‡**ï¼šä»…ç”¨ **30â€“60 ä¸ªå¯è®­ç»ƒå‚æ•°** çš„é‡å­æ¨¡å‹ï¼Œåœ¨é£é™©è°ƒæ•´åæ”¶ç›Šä¸Šå³å¯åª²ç¾ç”šè‡³è¶…è¶Šæ‹¥æœ‰ **æ•°ä¸‡è‡³åå…­ä¸‡ä¸ªå‚æ•°** çš„ç»å…¸ Deep RL æ¨¡å‹ã€‚
- **æ›´å¼ºçš„é²æ£’æ€§**ï¼šé‡å­ä»£ç†åœ¨ä¸åŒå¸‚åœºå‘¨æœŸä¸‹çš„è¡¨ç°æ³¢åŠ¨æ›´å°ï¼Œè¡¨æ˜å…¶ç­–ç•¥æ›´å…·ç¨³å®šæ€§ã€‚
- **ç†è®ºä¸Šçš„å¯æ‰©å±•æ€§ä¼˜åŠ¿**ï¼šåˆ©ç”¨é‡å­å åŠ ä¸çº ç¼ ï¼ŒVQCs åœ¨ç†è®ºä¸Šå…·å¤‡æŒ‡æ•°çº§çš„çŠ¶æ€ç©ºé—´æ¢ç´¢æ½œåŠ›ï¼Œé€‚åˆå¤æ‚ã€é«˜ç»´ã€éå¹³ç¨³ç¯å¢ƒã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **æ•°æ®æ¥æº**ï¼šçœŸå®ä¸–ç•Œé‡‘èæ•°æ®ã€‚
- **èµ„äº§æ•°é‡**ï¼š15 ç§å¤šæ ·åŒ–èµ„äº§ï¼Œæ¶µç›–è‚¡ç¥¨ï¼ˆå¦‚ AAPL, MSFTï¼‰ã€ETFï¼ˆå¦‚ SPY, QQQï¼‰ã€å€ºåˆ¸ï¼ˆå¦‚ TLT, LQDï¼‰ã€å¤§å®—å•†å“ï¼ˆå¦‚ GLD, USOï¼‰ç­‰ã€‚
- **æ—¶é—´è·¨åº¦**ï¼šä» 2011 å¹´ 8 æœˆ è‡³ 2025 å¹´ 9 æœˆï¼Œå…± **5049 å¤©** çš„æ—¥æ”¶ç›˜ä»·ã€‚
- **æ”¶ç›Šç‡è®¡ç®—**ï¼šä½¿ç”¨å¯¹æ•°æ”¶ç›Šç‡ã€‚

### **å®éªŒè®¾ç½®**
- **çŠ¶æ€ï¼ˆStateï¼‰**ï¼šåŒ…å«ä¸¤éƒ¨åˆ†ï¼š
  - è¿‡å» 30 å¤©çš„å½’ä¸€åŒ–ä»·æ ¼çª—å£ï¼ˆlookback windowï¼‰ã€‚
  - æœªæ¥ 7 å¤©çš„ä»·æ ¼é¢„æµ‹ï¼ˆforecast windowï¼‰ï¼Œé€šè¿‡ Auto ARIMA æ¨¡å‹ç”Ÿæˆã€‚
- **åŠ¨ä½œï¼ˆActionï¼‰**ï¼šè¿ç»­çš„ 15 ç»´æŠ•èµ„ç»„åˆæƒé‡å‘é‡ $ \mathbf{w}_t \in \mathbb{R}^{15} $ï¼Œå…è®¸å–ç©ºï¼ˆshort-sellingï¼‰ã€‚
- **å¥–åŠ±å‡½æ•°ï¼ˆRewardï¼‰**ï¼šç»“åˆå¹³å‡å›æŠ¥ä¸é£é™©è°ƒæ•´æ³¢åŠ¨ç‡ï¼Œå½¢å¼ä¸ºï¼š
  $$
  r_t = \mathbf{w}_{t}^\top \mu_{t-L:t+F+1} - \lambda \mathbf{w}_{t}^\top \Sigma_{t-L:t+F+1} \mathbf{w}_{t}
  $$
  å…¶ä¸­ $ \lambda $ ä¸ºé£é™©åå¥½å‚æ•°ã€‚
- **å†å¹³è¡¡é¢‘ç‡**ï¼šæ¯ 30 å¤©è¿›è¡Œä¸€æ¬¡ç­–ç•¥æ‰§è¡Œä¸å†å¹³è¡¡ã€‚
- **äº¤æ˜“æˆæœ¬**ï¼šè®¾å®šä¸ºæ¯æ¬¡äº¤æ˜“ **0.15%**ã€‚

### **è¯„ä¼°æŒ‡æ ‡**
- **ä¸»æŒ‡æ ‡**ï¼šæµ‹è¯•é›†ä¸Šçš„ **Sharpe Ratio**ï¼ˆå¤æ™®æ¯”ç‡ï¼‰ï¼Œç» 7 æŠ˜æ»šåŠ¨æ—¶é—´åºåˆ—äº¤å‰éªŒè¯ï¼ˆincreasing rolling-window time-series cross-validationï¼‰å–å¹³å‡ã€‚
- **è¾…åŠ©æŒ‡æ ‡**ï¼š
  - Sharpe Ratio çš„æ ‡å‡†å·®ï¼ˆè¡¡é‡è·¨å¸‚åœºå‘¨æœŸçš„ç¨³å®šæ€§ï¼‰ã€‚
  - æ‰§è¡Œæ—¶é—´ï¼ˆinference latencyï¼‰ã€‚
  - å‚æ•°æ•°é‡ï¼ˆparameter countï¼‰ã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| ç±»å‹ | æ–¹æ³• |
|------|------|
| **é™æ€åŸºå‡†** | - Equal Weightsï¼ˆç­‰æƒç»„åˆï¼‰<br>- Mean-Variance Optimization (MVO) |
| **ç»å…¸ Deep RL** | - DDPGï¼ˆ13.5k, 27k, 160k å‚æ•°ï¼‰<br>- DQNï¼ˆ13.5k, 27k, 160k å‚æ•°ï¼‰ |
| **æœ¬æ–‡æå‡ºæ–¹æ³•** | - Quantum DDPGï¼ˆ30, 60 å‚æ•°ï¼‰<br>- Quantum DQNï¼ˆ30, 60 å‚æ•°ï¼‰ |

æ‰€æœ‰æ¨¡å‹åœ¨ç›¸åŒç¯å¢ƒã€çŠ¶æ€è¡¨ç¤ºå’Œå¥–åŠ±å‡½æ•°ä¸‹è¿›è¡Œå…¬å¹³æ¯”è¾ƒã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 5.1ï¼‰**

| æ¨¡å‹ | Sharpe Ratio (mean) | Sharpe Ratio (std dev) | å‚æ•°é‡ | æ‰§è¡Œæ—¶é—´ |
|------|---------------------|------------------------|--------|----------|
| Equal Weights | 0.4375 | 0.6558 | â€“ | <1s |
| MVO | 0.5919 | 0.9170 | â€“ | <1s |
| Classical DDPG (160k) | **0.7926** | 0.6276 | 160,000 | 14s |
| Classical DQN (160k) | **0.8237** | 0.5367 | 160,000 | 27s |
| **Quantum DDPG (60)** | **0.7281** | **0.7395** | **60** | <1s (23min)* |
| **Quantum DQN (60)** | **0.6537** | 0.6155 | **60** | <1s (43min)* |

> *æ³¨ï¼šæ‹¬å·å†…æ—¶é—´ä¸ºäº‘å¹³å°æ€»è€—æ—¶ï¼ˆå«æ’é˜Ÿã€åˆå§‹åŒ–ç­‰å¼€é”€ï¼‰ï¼Œ<1s ä¸ºçº¯ç”µè·¯æ‰§è¡Œæ—¶é—´ã€‚*

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- **å‚æ•°æ•ˆç‡ç¢¾å‹**ï¼š
  - ä»…ç”¨ **60 ä¸ªå‚æ•°** çš„ Quantum DDPGï¼Œå…¶ Sharpe Ratioï¼ˆ0.7281ï¼‰å·²æ¥è¿‘ç”šè‡³è¶…è¿‡è®¸å¤šå‚æ•°é‡å°å¾—å¤šçš„ç»å…¸æ¨¡å‹ï¼Œå¹¶æ˜¾è‘—ä¼˜äº MVOã€‚
  - Quantum DQN (60) è™½ç•¥ä½äºæœ€ä¼˜ç»å…¸æ¨¡å‹ï¼Œä½†ä»è¿œè¶…åŒç­‰å‚æ•°è§„æ¨¡çš„ç»å…¸æ¨¡å‹ã€‚
- **æ€§èƒ½å¯æ¯”æ€§**ï¼š
  - æœ€ä¼˜é‡å­æ¨¡å‹ï¼ˆQuantum DDPG 60ï¼‰çš„æ€§èƒ½å·²è¾¾åˆ°ç»å…¸å¤§è§„æ¨¡æ¨¡å‹ï¼ˆ160k å‚æ•°ï¼‰çš„ **~88%â€“90% æ°´å¹³**ï¼Œè€Œå‚æ•°é‡ä»…ä¸ºåè€…çš„ **0.0375%**ã€‚
- **é²æ£’æ€§ä¼˜åŠ¿**ï¼š
  - é‡å­ä»£ç†çš„ Sharpe Ratio æ ‡å‡†å·®ç›¸å¯¹è¾ƒä½ï¼Œå°¤å…¶åœ¨å¸‚åœºå‰§çƒˆæ³¢åŠ¨æ—¶æœŸè¡¨ç°å‡ºæ›´å¼ºçš„ä¸€è‡´æ€§ã€‚

### **æ¶ˆèå®éªŒä¸åˆ†æ**
- **å‚æ•°é‡å½±å“**ï¼š
  - Quantum DDPG ä» 30 å‚æ•°æå‡è‡³ 60 å‚æ•°ï¼ŒSharpe Ratio æ˜¾è‘—ä¸Šå‡ï¼ˆ0.4179 â†’ 0.7281ï¼‰ï¼Œè¯´æ˜å¢åŠ è¡¨è¾¾èƒ½åŠ›èƒ½æœ‰æ•ˆæå‡æ€§èƒ½ã€‚
  - ç»å…¸æ¨¡å‹ä¹Ÿå‘ˆç°ç±»ä¼¼è¶‹åŠ¿ï¼Œä½†éœ€æˆå€å¢åŠ å‚æ•°æ‰èƒ½è·å¾—è¾¹é™…æå‡ã€‚
- **æ¶æ„å·®å¼‚**ï¼š
  - Quantum DDPG æ•´ä½“è¡¨ç°ä¼˜äº Quantum DQNï¼Œå¯èƒ½å› å…¶ç›®æ ‡æ„å»ºæ–¹å¼æ›´é€‚åˆè¿ç»­æ§åˆ¶ä»»åŠ¡ã€‚
- **ç¼–ç æ–¹å¼ä½œç”¨**ï¼š
  - ä½¿ç”¨æ‰©å±•ç‰¹å¾æ˜ å°„çš„æŒ¯å¹…ç¼–ç æœ‰åŠ©äºç¼“è§£è®­ç»ƒåˆæœŸæ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œæå‡æ”¶æ•›é€Ÿåº¦ä¸æœ€ç»ˆæ€§èƒ½ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **QRL åœ¨åŠ¨æ€æŠ•èµ„ç»„åˆä¼˜åŒ–ä¸­å…·æœ‰ç†è®ºç«äº‰åŠ›**ï¼š
   - åŸºäº VQC çš„ QRL æ¡†æ¶èƒ½å¤Ÿå­¦ä¹ å‡ºé«˜è´¨é‡çš„è‡ªé€‚åº”äº¤æ˜“ç­–ç•¥ã€‚
   - é‡å­ä»£ç†åœ¨**é£é™©è°ƒæ•´åæ”¶ç›Š**æ–¹é¢å¯ä¸æœ€å…ˆè¿›çš„ç»å…¸ Deep RL æ¨¡å‹ç›¸åª²ç¾ã€‚

2. **æè‡´çš„å‚æ•°æ•ˆç‡æ˜¯æ ¸å¿ƒä¼˜åŠ¿**ï¼š
   - é‡å­æ¨¡å‹å‡­å€Ÿ**æŒ¯å¹…ç¼–ç **ä¸**çº ç¼ è¯±å¯¼çš„è¡¨è¾¾åŠ›**ï¼Œå®ç°äº†è¿œè¶…ç»å…¸ç½‘ç»œçš„â€œå‚æ•°-æ€§èƒ½â€æ¯”ã€‚
   - è¿™ç§é«˜æ•ˆæ€§ä½¿å…¶åœ¨èµ„æºå—é™æˆ–éœ€è¦å¿«é€Ÿéƒ¨ç½²çš„åœºæ™¯ä¸­æå…·å¸å¼•åŠ›ã€‚

3. **å½“å‰ç¡¬ä»¶éƒ¨ç½²å­˜åœ¨ä¸¥é‡ç“¶é¢ˆ**ï¼š
   - å°½ç®¡**å•æ¬¡ç”µè·¯æ‰§è¡Œæå¿«ï¼ˆæ¯«ç§’çº§ï¼‰**ï¼Œä½†ç”±äº**äº‘é‡å­è®¡ç®—ç³»ç»Ÿçš„æ’é˜Ÿã€åˆå§‹åŒ–ä¸åŒæ­¥å¼€é”€**ï¼Œå®é™…ç«¯åˆ°ç«¯æ¨ç†å»¶è¿Ÿé«˜è¾¾ **23â€“43 åˆ†é’Ÿ**ã€‚
   - è¿™ä½¿å¾—å½“å‰ QRL **å°šä¸å…·å¤‡å®æ—¶äº¤æ˜“çš„å®ç”¨æ€§**ã€‚

4. **æœªæ¥æ½œåŠ›å·¨å¤§**ï¼š
   - è‹¥æœªæ¥èƒ½å®ç°ä¸“ç”¨ QPU æˆ–é™ä½äº‘ç«¯å»¶è¿Ÿï¼ŒQRL çš„åŸç”Ÿé€Ÿåº¦ä¼˜åŠ¿å°†å¾—ä»¥é‡Šæ”¾ã€‚
   - éšç€ç¡¬ä»¶æˆç†Ÿï¼ŒQRL å¯èƒ½æˆä¸ºå¤„ç†å¤æ‚åŠ¨æ€å†³ç­–é—®é¢˜ï¼ˆå¦‚é‡‘èã€ä¾›åº”é“¾ã€æœºå™¨äººæ§åˆ¶ï¼‰çš„**ä¸»æµèŒƒå¼**ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **NISQ æ—¶ä»£é™åˆ¶**ï¼šå—å™ªå£°ã€è¿é€šæ€§ä¸ qubit æ•°é‡åˆ¶çº¦ï¼Œåªèƒ½è®­ç»ƒè¾ƒæµ…çš„ VQCã€‚
- **æ¨¡æ‹Ÿå™¨ä¾èµ–è®­ç»ƒ**ï¼šæœ¬ç ”ç©¶è®­ç»ƒåœ¨æ— å™ªå£°æ¨¡æ‹Ÿå™¨ä¸Šå®Œæˆï¼Œæœªè€ƒè™‘çœŸå®ç¡¬ä»¶å™ªå£°å¯¹è®­ç»ƒçš„å½±å“ã€‚
- **è§„æ¨¡æœ‰é™**ï¼šä»…æµ‹è¯•äº†æœ€å¤š 15 ä¸ªèµ„äº§ï¼Œæ›´å¤§è§„æ¨¡ç»„åˆå°šæœªéªŒè¯ã€‚
- **å»¶è¿Ÿé—®é¢˜çªå‡º**ï¼šäº‘è®¿é—®æ¨¡å¼å¯¼è‡´çš„é«˜å»¶è¿Ÿä¸¥é‡é˜»ç¢äº†å®é™…åº”ç”¨ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ¢ç´¢åœ¨çœŸå® NISQ è®¾å¤‡ä¸Šè¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒï¼ˆå«å™ªå£°ï¼‰ã€‚
- è®¾è®¡æ›´é«˜æ•ˆçš„é‡å­ç¼–ç ä¸ç”µè·¯ç»“æ„ä»¥è¿›ä¸€æ­¥æå‡è¡¨è¾¾åŠ›ã€‚
- ç ”ç©¶ä¸“ç”¨é‡å­è®¡ç®—ç³»ç»Ÿï¼ˆdedicated QPUï¼‰ä¸‹çš„ä½å»¶è¿Ÿæ¨ç†æ¶æ„ã€‚
- å°†è¯¥æ¡†æ¶æ‹“å±•è‡³å…¶ä»–é‡‘èä»»åŠ¡ï¼Œå¦‚æœŸæƒå®šä»·ã€é£é™©ç®¡ç†ã€é«˜é¢‘äº¤æ˜“ç­‰ã€‚
- å¼€æºä»£ç å·²å‘å¸ƒï¼š[GitHub - VincentGurgul/qrl-dpo-public](https://github.com/VincentGurgul/qrl-dpo-public)

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡è¯æ˜äº† **VQC-based QRL åœ¨åŠ¨æ€æŠ•èµ„ç»„åˆä¼˜åŒ–ä¸­å…·å¤‡å“è¶Šçš„å‚æ•°æ•ˆç‡ä¸ç†è®ºæ€§èƒ½**ï¼Œè™½å—é™äºå½“å‰äº‘é‡å­åŸºç¡€è®¾æ–½çš„é«˜å»¶è¿Ÿè€Œæš‚éš¾å®ç”¨ï¼Œä½†å…¶å±•ç°å‡ºçš„å·¨å¤§æ½œåŠ›é¢„ç¤ºç€å®ƒå¯èƒ½æ˜¯æœªæ¥å¤æ‚åŠ¨æ€å†³ç­–ç³»ç»Ÿçš„ç†æƒ³è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 16. [TinyTorch: Building Machine Learning Systems from First Principles](https://arxiv.org/abs/2601.19107)

**Authors**: Vijay Janapa Reddi  
**Category**: cs.LG  
**Published**: 2026-01-28  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.19107v1  

#### Abstract
Machine learning systems engineering requires a deep understanding of framework internals. Yet most current education separates algorithms from systems. Students learn gradient descent without measuring memory usage, and attention mechanisms without profiling computational cost. This split leaves gr...

---

### 17. [Smoothing the Score Function for Generalization in Diffusion Models: An Optimization-based Explanation Framework](https://arxiv.org/abs/2601.19285)

**Authors**: Xinyu Zhou, Jiawei Zhang, Stephen J. Wright  
**Category**: cs.LG  
**Published**: 2026-01-28  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.19285v1  

#### Abstract
Diffusion models achieve remarkable generation quality, yet face a fundamental challenge known as memorization, where generated samples can replicate training samples exactly. We develop a theoretical framework to explain this phenomenon by showing that the empirical score function (the score functi...

---

### 18. [LLM Driven Design of Continuous Optimization Problems with Controllable High-level Properties](https://arxiv.org/abs/2601.18846)

**Authors**: Urban Skvorc, Niki van Stein, Moritz Seiler, Britta Grimme, Thomas B\"ack, Heike Trautmann  
**Category**: cs.AI  
**Published**: 2026-01-28  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.18846v1  

#### Abstract
Benchmarking in continuous black-box optimisation is hindered by the limited structural diversity of existing test suites such as BBOB. We explore whether large language models embedded in an evolutionary loop can be used to design optimisation problems with clearly defined high-level landscape char...

---

### 19. [Exploring Weaknesses in Function Call Models via Reinforcement Learning: An Adversarial Data Augmentation Approach](https://arxiv.org/abs/2601.19122)

**Authors**: Weiran Guo, Bing Bo, Shaoxiang Wu, Jingsheng Yang  
**Category**: cs.AI  
**Published**: 2026-01-28  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.19122v1  

#### Abstract
Function call capabilities have become crucial for Large Language Models (LLMs), enabling them to interact more effectively with external tools and APIs. Existing methods for improving the function call capabilities of LLMs rely on data obtained either through manual annotation or automated generati...

---

### 20. [Balancing Sustainability And Performance: The Role Of Small-Scale Llms In Agentic Artificial Intelligence Systems](https://arxiv.org/abs/2601.19311)

**Authors**: Anh Khoa Ngo Ho, Martin Chauvin, Simon Gosset, Philippe Cordier, Boris Gamazaychikov  
**Category**: cs.AI  
**Published**: 2026-01-28  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.19311v1  

#### Abstract
As large language models become integral to agentic artificial intelligence systems, their energy demands during inference may pose significant sustainability challenges. This study investigates whether deploying smaller-scale language models can reduce energy consumption without compromising respon...

---

### 21. [Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design for A* Search](https://arxiv.org/abs/2601.19622)

**Authors**: Thomas B\"omer, Nico Koltermann, Max Disselnmeyer, Bastian Amberg, Anne Meyer  
**Category**: cs.AI  
**Published**: 2026-01-28  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.19622v1  

#### Abstract
Heuristic functions are essential to the performance of tree search algorithms such as A*, where their accuracy and efficiency directly impact search outcomes. Traditionally, such heuristics are handcrafted, requiring significant expertise. Recent advances in large language models (LLMs) and evoluti...

---

### 22. [Identifying and Transferring Reasoning-Critical Neurons: Improving LLM Inference Reliability via Activation Steering](https://arxiv.org/abs/2601.19847)

**Authors**: Fangan Dong, Zuming Yan, Xuri Ge, Zhiwei Xu, Mengqi Zhang, Xuanang Chen, Ben He, Xin Xin, Zhumin Chen, Ying Zhou  
**Category**: cs.CL  
**Published**: 2026-01-28  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.19847v1  

#### Abstract
Despite the strong reasoning capabilities of recent large language models (LLMs), achieving reliable performance on challenging tasks often requires post-training or computationally expensive sampling strategies, limiting their practical efficiency. In this work, we first show that a small subset of...

---

### 23. [GraIP: A Benchmarking Framework For Neural Graph Inverse Problems](https://arxiv.org/abs/2601.18917)

**Authors**: Semih Cant\"urk, Andrei Manolache, Arman Mielke, Chendi Qian, Antoine Siraudin, Christopher Morris, Mathias Niepert, Guy Wolf  
**Category**: cs.LG  
**Published**: 2026-01-28  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.18917v1  

#### Abstract
A wide range of graph learning tasks, such as structure discovery, temporal graph analysis, and combinatorial optimization, focus on inferring graph structures from data, rather than making predictions on given graphs. However, the respective methods to solve such problems are often developed in an ...

---

### 24. [Towards Self-Optimizing Electron Microscope: Robust Tuning of Aberration Coefficients via Physics-Aware Multi-Objective Bayesian Optimization](https://arxiv.org/abs/2601.18972)

**Authors**: Utkarsh Pratiush, Austin Houston, Richard Liu, Gerd Duscher, Sergei Kalinin  
**Category**: cs.LG  
**Published**: 2026-01-28  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.18972v1  

#### Abstract
Realizing high-throughput aberration-corrected Scanning Transmission Electron Microscopy (STEM) exploration of atomic structures requires rapid tuning of multipole probe correctors while compensating for the inevitable drift of the optical column. While automated alignment routines exist, convention...

---

### 25. [EPAS: Efficient Training with Progressive Activation Sharing](https://arxiv.org/abs/2601.19089)

**Authors**: Rezaul Karim, Maryam Dialameh, Yang Liu, Boxing Chen, Walid Ahmed  
**Category**: cs.LG  
**Published**: 2026-01-28  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.19089v1  

#### Abstract
We present a novel method for Efficient training with Progressive Activation Sharing (EPAS). This method bridges progressive training paradigm with the phenomenon of redundant QK (or KV ) activations across deeper layers of transformers. EPAS gradually grows a sharing region during training by switc...

---

### 26. [Explainable Uncertainty Quantification for Wastewater Treatment Energy Prediction via Interval Type-2 Neuro-Fuzzy System](https://arxiv.org/abs/2601.18897)

**Authors**: Qusai Khaled, Bahjat Mallak, Uzay Kaymak, Laura Genga  
**Category**: cs.AI  
**Published**: 2026-01-28  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.18897v1  

#### Abstract
Wastewater treatment plants consume 1-3% of global electricity, making accurate energy forecasting critical for operational optimization and sustainability. While machine learning models provide point predictions, they lack explainable uncertainty quantification essential for risk-aware decision-mak...

---

### 27. [Cross-Examination Framework: A Task-Agnostic Diagnostic for Information Fidelity in Text-to-Text Generation](https://arxiv.org/abs/2601.19350)

**Authors**: Tathagata Raha, Clement Christophe, Nada Saadi, Hamza A Javed, Marco AF Pimentel, Ronnie Rajan, Praveenkumar Kanithi  
**Category**: cs.CL  
**Published**: 2026-01-28  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.19350v1  

#### Abstract
Traditional metrics like BLEU and BERTScore fail to capture semantic fidelity in generative text-to-text tasks. We adapt the Cross-Examination Framework (CEF) for a reference-free, multi-dimensional evaluation by treating the source and candidate as independent knowledge bases. CEF generates verifia...

---

### 28. [Decompose-and-Formalise: Recursively Verifiable Natural Language Inference](https://arxiv.org/abs/2601.19605)

**Authors**: Xin Quan, Marco Valentino, Louise A. Dennis, Andr\'e Freitas  
**Category**: cs.CL  
**Published**: 2026-01-28  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.19605v1  

#### Abstract
Recent work has shown that integrating large language models (LLMs) with theorem provers (TPs) in neuro-symbolic pipelines helps with entailment verification and proof-guided refinement of explanations for natural language inference (NLI). However, scaling such refinement to naturalistic NLI remains...

---

### 29. [Latent Structural Similarity Networks for Unsupervised Discovery in Multivariate Time Series](https://arxiv.org/abs/2601.18803)

**Authors**: Olusegun Owoeye  
**Category**: cs.LG  
**Published**: 2026-01-28  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.18803v1  

#### Abstract
This paper proposes a task-agnostic discovery layer for multivariate time series that constructs a relational hypothesis graph over entities without assuming linearity, stationarity, or a downstream objective. The method learns window-level sequence representations using an unsupervised sequence-to-...

---

### 30. [Attention-Enhanced Graph Filtering for False Data Injection Attack Detection and Localization](https://arxiv.org/abs/2601.18981)

**Authors**: Ruslan Abdulin, Mohammad Rasoul Narimani  
**Category**: cs.LG  
**Published**: 2026-01-28  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.18981v1  

#### Abstract
The increasing deployment of Internet-of-Things (IoT)-enabled measurement devices in modern power systems has expanded the cyberattack surface of the grid. As a result, this critical infrastructure is increasingly exposed to cyberattacks, including false data injection attacks (FDIAs) that compromis...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- kv cache, offload, State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
