# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-01-13 05:55:59 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [ARCQuant: Boosting NVFP4 Quantization with Augmented Residual Channels for LLMs](https://arxiv.org/abs/2601.07475)

**Authors**: Haoqian Meng, Yilun Luo, Yafei Zhao, Wenyuan Liu, Peng Zhang, Xindian Ma  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 12.5  
**Type**: new  
**ArXiv ID**: 2601.07475v1  

#### Abstract
The emergence of fine-grained numerical formats like NVFP4 presents new opportunities for efficient Large Language Model (LLM) inference. However, it is difficult to adapt existing Post-Training Quantization (PTQ) strategies to these formats: rotation-based methods compromise fine-grained block isol...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šARCQuant: Boosting NVFP4 Quantization with Augmented Residual Channels for LLMs

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†ä¸­ï¼Œ**ç»†ç²’åº¦æ•°å€¼æ ¼å¼ï¼ˆå¦‚ NVFP4ï¼‰** è™½ç„¶èƒ½æå‡æ•ˆç‡ï¼Œä½†ç°æœ‰çš„åè®­ç»ƒé‡åŒ–ï¼ˆPTQï¼‰ç­–ç•¥éš¾ä»¥æœ‰æ•ˆé€‚é…è¿™äº›æ ¼å¼ï¼Œå­˜åœ¨ä»¥ä¸‹ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **Rotation-based æ–¹æ³•**ï¼ˆå¦‚ QuaRotï¼‰ä¼šç ´å NVFP4 çš„å—çº§éš”ç¦»ç‰¹æ€§ï¼Œå¯¼è‡´å±€éƒ¨åŠ¨æ€èŒƒå›´æ‰©å¤§ï¼›
- **Smoothing æŠ€æœ¯**ï¼ˆå¦‚ SmoothQuantï¼‰åœ¨ 4-bit é‡åŒ–ä¸‹è¯¯å·®æ˜¾è‘—ï¼Œè¡¥å¿èƒ½åŠ›æœ‰é™ï¼›
- **Mixed-precision æ–¹æ³•**ï¼ˆå¦‚ Atomï¼‰å› ç¡¬ä»¶ä¸æ”¯æŒæ··åˆç²¾åº¦è®¡ç®—ï¼ˆå¦‚ä¸åŒ block sizeï¼‰ï¼Œæ— æ³•é«˜æ•ˆåˆ©ç”¨ Tensor Coreã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šARCQuant
æå‡º **ARCQuant**ï¼ˆAugmented Residual Channels Quantizationï¼‰ï¼Œä¸€ç§ä¸“ä¸º NVFP4 è®¾è®¡çš„ PTQ æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- **é€šè¿‡å¢å¹¿æ®‹å·®é€šé“è¿›è¡Œè¯¯å·®è¡¥å¿**ï¼Œè€Œéæ”¹å˜è¾“å…¥åˆ†å¸ƒæˆ–å¼•å…¥æ··åˆç²¾åº¦ã€‚
- åœ¨æ¿€æ´»çŸ©é˜µä¸­è¯†åˆ«å‡ºå¼‚å¸¸å€¼é€šé“ï¼ˆoutlier channelsï¼‰ï¼Œå¹¶å°†å…¶é‡åŒ–åçš„æ®‹å·®ä½œä¸ºé¢å¤–é€šé“â€œå¢å¹¿â€åˆ°åŸå§‹è¾“å…¥ä¸­ã€‚
- æ•´ä¸ªè¡¥å¿è¿‡ç¨‹è¢«æ˜ å°„åˆ°çŸ©é˜µä¹˜æ³•ï¼ˆGEMMï¼‰çš„æ‰©å±• reduction ç»´åº¦ä¸­ï¼Œä»è€Œå¯ç›´æ¥è°ƒç”¨æ ‡å‡†ã€é«˜åº¦ä¼˜åŒ–çš„ GEMM å†…æ ¸ï¼ˆå¦‚ CUTLASSï¼‰ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- âœ… **ä¿æŒç¡¬ä»¶ç»Ÿä¸€æ€§**ï¼šå…¨ç¨‹ä½¿ç”¨ç»Ÿä¸€çš„ W4A4 NVFP4 æ ¼å¼ï¼Œå…¼å®¹ Blackwell æ¶æ„çš„ Tensor Coreï¼›
- âœ… **ä¿ç•™å—çº§éš”ç¦»**ï¼šé€šè¿‡é€šé“é‡æ’åºï¼ˆchannel reorderingï¼‰éš”ç¦»å¼‚å¸¸å€¼ï¼Œé¿å…æ—‹è½¬æ“ä½œå¸¦æ¥çš„è¯¯å·®æ‰©æ•£ï¼›
- âœ… **ç†è®ºè¯¯å·®ç•Œä¼˜**ï¼šåŒé˜¶æ®µé‡åŒ–æœºåˆ¶çš„æœ€åæƒ…å†µè¯¯å·®ç•Œä¸æ ‡å‡† MXFP8 ç›¸å½“ï¼›
- âœ… **éƒ¨ç½²é«˜æ•ˆ**ï¼šé€šè¿‡èåˆå†…æ ¸ï¼ˆFused Quantization Kernelï¼‰å®ç°ä½å¼€é”€åœ¨çº¿é‡åŒ–ï¼Œæ— éœ€ä¿®æ”¹ GEMM å†…æ ¸ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **æ ¡å‡†æ•°æ®é›†**ï¼šWikiText2ï¼ˆ128 ä¸ªæ ·æœ¬ï¼Œåºåˆ—é•¿åº¦ 2048ï¼‰
- **è¯„ä¼°ä»»åŠ¡ä¸æ•°æ®é›†**ï¼š
  - **é€šç”¨ç†è§£**ï¼šARC-C, HellaSwag, PIQA, Winograd, LAMBADA
  - **çŸ¥è¯†æ¨ç†**ï¼šMMLUï¼ˆ5-shotï¼‰
  - **ä»£ç ç”Ÿæˆ**ï¼šHumanEval, MBPP
  - **æ•°å­¦æ¨ç†**ï¼šGSM8K, CMATH
  - **è¯­è¨€å»ºæ¨¡**ï¼šWikiText2 ä¸Šçš„ Perplexity (PPL)

### å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼šLLaMA 3.1-8Bã€Qwen2.5-7B/14B/32Bã€Qwen2.5-Coder-7B-Instructã€Qwen2.5-Math-7B-Instruct
- **é‡åŒ–é…ç½®**ï¼šW4A4ï¼ˆæƒé‡å’Œæ¿€æ´»å‡ä¸º 4-bitï¼‰
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA RTX 5090 å’Œ RTX PRO 6000ï¼ˆåŸºäº Blackwell æ¶æ„ï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - å‡†ç¡®ç‡ï¼ˆZero-shot / Few-shotï¼‰
  - å›°æƒ‘åº¦ï¼ˆPPLï¼‰
  - æ¨ç†å»¶è¿Ÿï¼ˆPrefill Latencyï¼‰
  - å†…å­˜å ç”¨
  - é€Ÿåº¦æå‡ï¼ˆSpeedupï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | æ˜¯å¦é€‚é… NVFP4 |
|------|------|----------------|
| FP16 | å…¨ç²¾åº¦åŸºçº¿ | â€” |
| W4A8 + RTN | é«˜ç²¾åº¦æ¿€æ´»åŸºçº¿ | â€” |
| INT4 / MXFP4 + RTN | åŸºç¡€é‡åŒ– | æ˜¯ |
| SmoothQuant | å¹³æ»‘å˜æ¢ | é€‚é… |
| QuaRot (Hadamard) | æ—‹è½¬å˜æ¢ | é€‚é… |
| FlatQuant | åˆ†å¸ƒæ‰å¹³åŒ– | ä¸å…¼å®¹ |
| Atom | æ··åˆç²¾åº¦ï¼ˆä¿ç•™éƒ¨åˆ†é«˜ç²¾åº¦é€šé“ï¼‰ | ä¸å…¼å®¹ |

> æ³¨ï¼šFlatQuant å’Œ Atom å› ç»“æ„ä¸å…¼å®¹ NVFP4ï¼Œæœªç›´æ¥æ¯”è¾ƒï¼›æ–‡ä¸­å¯¹ SmoothQuant å’Œ QuaRot è¿›è¡Œäº† NVFP4 é€‚é…ç‰ˆæœ¬æµ‹è¯•ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & 2ï¼‰

#### åœ¨ Llama3.1-8B ä¸Šçš„è¡¨ç°ï¼š
| æ–¹æ³• | PPL â†“ | MMLU â†‘ | å¹³å‡å‡†ç¡®ç‡ â†‘ |
|------|--------|--------|--------------|
| FP16 | 6.24 | 65.15 | 72.56 |
| W4A8 + RTN | 7.07 | 61.08 | 70.59 |
| NVFP4 + RTN | 6.95 | 61.64 | 70.45 |
| **ARCQuant** | **6.87** | **62.61** | **70.90** |

> âœ… **ä¼˜äºæ‰€æœ‰ W4A4 æ–¹æ³•ï¼Œç”šè‡³æ¥è¿‘ W4A8 æ€§èƒ½**

#### åœ¨ Qwen2.5-7B ä¸Šçš„è¡¨ç°ï¼š
| æ–¹æ³• | PPL â†“ | MMLU â†‘ | å¹³å‡å‡†ç¡®ç‡ â†‘ |
|------|--------|--------|--------------|
| FP16 | 6.85 | 74.16 | 70.97 |
| Atom | 8.96 | 68.17 | 67.57 |
| NVFP4 + RTN | 7.29 | 72.06 | 69.43 |
| **ARCQuant** | **7.28** | **72.84** | **70.28** |

> âœ… **ç›¸æ¯” Atom é™ä½ PPL 1.68ï¼Œæ˜¾è‘—ç¼©å°ä¸ FP16 å·®è·**

#### ä»£ç ç”Ÿæˆæ€§èƒ½ï¼ˆQwen2.5-Coder-7B-Instructï¼‰ï¼š
| æ–¹æ³• | HumanEval | HumanEval+ | MBPP | MBPP+ |
|------|-----------|------------|-------|--------|
| FP16 | 84.1 | 79.9 | 80.4 | 67.2 |
| Atom | 80.5 | 76.2 | 74.5 | 63.2 |
| **ARCQuant** | **86.0** | **79.3** | **79.9** | **68.3** |

> âœ… **å…¨é¢è¶…è¶Š FP16ï¼Œå°¤å…¶åœ¨ HumanEval ä¸Šæå‡æ˜æ˜¾**

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ç›¸æ¯” NVFP4 + RTN**ï¼šARCQuant åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå¹³å‡æå‡çº¦ 0.5â€“1.0 ä¸ªç™¾åˆ†ç‚¹ï¼›
- **ç›¸æ¯” NVFP4 + SmoothQuant / QuaRot**ï¼š
  - QuaRot å›  Hadamard å˜æ¢ç ´åå—éš”ç¦»ï¼Œåœ¨ Llama ä¸Šè¡¨ç°é€€åŒ–ï¼›
  - SmoothQuant æ”¹å–„æœ‰é™ï¼›
  - **ARCQuant æ˜¾è‘—ä¼˜äºä¸¤è€…**ï¼›
- **ç›¸æ¯”æ··åˆç²¾åº¦æ–¹æ³•ï¼ˆAtomï¼‰**ï¼š
  - Atom å› ç¡¬ä»¶ä¸å…¼å®¹å¯¼è‡´ååä¸‹é™ï¼›
  - ARCQuant åœ¨ç²¾åº¦å’Œé€Ÿåº¦ä¸Šå‡å ä¼˜ã€‚

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰æ³›åŒ–æ€§ï¼ˆGeneralizabilityï¼‰
- åœ¨ **INT4** å’Œ **MXFP4** æ ¼å¼ä¸Šä¹Ÿæœ‰æ•ˆï¼š
  - åœ¨ Llama3.1-8B ä¸Šï¼ŒINT4 ä¸‹ PPL ä» 8.84 â†’ 7.95ï¼Œé›¶æ ·æœ¬å‡†ç¡®ç‡æå‡ 2.12%ï¼›
  - è¡¨æ˜æ®‹å·®è¡¥å¿æœºåˆ¶å…·æœ‰è·¨æ ¼å¼æœ‰æ•ˆæ€§ã€‚

#### ï¼ˆ2ï¼‰æ ¡å‡†é²æ£’æ€§ï¼ˆCalibration Robustnessï¼‰
- ä½¿ç”¨ä¸åŒæ ¡å‡†æ•°æ®é›†ï¼ˆWikiText2 / C4 / HumanEvalï¼‰æ—¶ï¼š
  - PPL æ³¢åŠ¨ < 0.03ï¼Œå‡†ç¡®ç‡æ³¢åŠ¨ < 0.03%ï¼›
  - è¡¨æ˜å¼‚å¸¸å€¼ç»“æ„ç¨³å®šï¼Œæ–¹æ³•å¯¹æ ¡å‡†æ•°æ®é€‰æ‹©ä¸æ•æ„Ÿã€‚

#### ï¼ˆ3ï¼‰æ•ˆç‡åˆ†æï¼ˆEfficiencyï¼‰
- **GEMM å»¶è¿Ÿéšå¢å¹¿é€šé“æ•° $S$ çº¿æ€§å¢é•¿**ï¼Œä½†åœ¨å…¸å‹èŒƒå›´ï¼ˆ$S \leq 512$ï¼‰å†…å¼€é”€æå°ï¼›
- **ç«¯åˆ°ç«¯æ€»å»¶è¿Ÿä»…å¢åŠ  4.9%**ï¼ˆQwen2.5-7Bï¼‰ï¼›
- **å†…å­˜å‡å°‘ 1.5Ã—â€“2.8Ã—**ï¼Œ**é¢„å¡«å……é€Ÿåº¦æå‡è¾¾ 3.5Ã—**ï¼ˆRTX 5090 ä¸Š Llama3.1-8Bï¼‰ï¼›
- ç›¸æ¯” W4A8 å’Œ MXFP8ï¼Œä»å…·æ˜¾è‘—é€Ÿåº¦ä¼˜åŠ¿ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
- âœ… **NVFP4 çš„å—çº§éš”ç¦»ç‰¹æ€§è‡³å…³é‡è¦**ï¼Œå…¨å±€å˜æ¢ï¼ˆå¦‚æ—‹è½¬ï¼‰åè€ŒæŸå®³æ€§èƒ½ï¼›
- âœ… **æ··åˆç²¾åº¦è™½æœ‰æ•ˆï¼Œä½†å—é™äºç¡¬ä»¶ç»Ÿä¸€æ€§è¦æ±‚**ï¼Œéš¾ä»¥å‘æŒ¥å®é™…åŠ é€Ÿæ½œåŠ›ï¼›
- âœ… **é€šè¿‡å¢å¹¿æ®‹å·®é€šé“å®ç°è¯¯å·®è¡¥å¿**ï¼Œå¯åœ¨ä¸è¿åç¡¬ä»¶çº¦æŸçš„å‰æä¸‹é€¼è¿‘ W4A8 ç²¾åº¦ï¼›
- âœ… **ç†è®ºè¯¯å·®ç•Œåˆ†æè¡¨æ˜**ï¼ŒARCQuant çš„æœ€åè¯¯å·®ä¸ MXFP8 ç›¸å½“ï¼Œè§£é‡Šäº†å…¶é«˜ä¿çœŸé‡å»ºèƒ½åŠ›ï¼›
- âœ… **éƒ¨ç½²å‹å¥½**ï¼šé€šè¿‡èåˆå†…æ ¸å°†å¤æ‚é‡åŒ–é€»è¾‘å°è£…ï¼Œå¤ç”¨æ ‡å‡† GEMMï¼Œä¾¿äºé›†æˆè‡³ vLLM ç­‰ç³»ç»Ÿã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–ç¦»çº¿æ ¡å‡†**ï¼š
   - é€šé“é‡æ’åºå’Œå¼‚å¸¸å€¼æ•°é‡ $S$ ç”±æ ¡å‡†æ•°æ®å†³å®šï¼Œå‡è®¾æ¨ç†æ—¶åˆ†å¸ƒä¸€è‡´ï¼›
   - å¯¹æç«¯åˆ†å¸ƒåç§»å¯èƒ½é€‚åº”æ€§ä¸è¶³ã€‚

2. **ç¡¬ä»¶ä¾èµ–æ€§å¼º**ï¼š
   - å½“å‰è®¾è®¡ç´§å¯†è€¦åˆ NVIDIA Blackwell æ¶æ„çš„ NVFP4 æ”¯æŒï¼›
   - åœ¨æ—  block-scaled åŠ é€Ÿçš„è€æ¶æ„ä¸Šä»…ä¸ºæ¨¡æ‹Ÿæ€§èƒ½ã€‚

3. **æƒé‡é‡åŒ–è¾ƒç®€å•**ï¼š
   - æƒé‡é‡‡ç”¨ RTN é‡åŒ–ï¼Œæœªç»“åˆ GPTQ æˆ– AWQ ç­‰é«˜çº§æ–¹æ³•ï¼›
   - è‹¥ç»“åˆå¯è¿›ä¸€æ­¥æå‡å­ 4-bit åœºæ™¯ä¸‹çš„æ€§èƒ½ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† ARCQuant æ‰©å±•è‡³ **sub-4-bit æ ¼å¼**ï¼ˆå¦‚ INT2/NVFP2ï¼‰ï¼›
- æ¢ç´¢ **åŠ¨æ€è‡ªé€‚åº” $S$** æœºåˆ¶ä»¥åº”å¯¹åˆ†å¸ƒå˜åŒ–ï¼›
- é›†æˆè‡³ **vLLM ç­‰ç”Ÿäº§çº§æ¨ç†å¼•æ“**ï¼ŒéªŒè¯å¤§è§„æ¨¡æœåŠ¡åœºæ™¯ä¸‹çš„å®ç”¨æ€§ï¼›
- æ¨åŠ¨ **ç¡¬ä»¶å±‚é¢æ”¯æŒæ›´çµæ´»çš„ block-scaled æ ¼å¼**ï¼Œå¢å¼ºé€šç”¨æ€§ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> ARCQuant æå‡ºäº†ä¸€ç§ç¡¬ä»¶å‹å¥½çš„â€œç”¨è®¡ç®—ç»´åº¦æ¢ç²¾åº¦â€çš„æ–°èŒƒå¼ï¼Œåœ¨ä¸¥æ ¼éµå®ˆ W4A4 ç»Ÿä¸€ç²¾åº¦çš„å‰æä¸‹ï¼Œé€šè¿‡å¢å¹¿æ®‹å·®é€šé“å®ç°äº†æ¥è¿‘ W4A8 çš„ç²¾åº¦ï¼Œå¹¶åœ¨ Blackwell æ¶æ„ä¸Šè·å¾—é«˜è¾¾ 3.5Ã— çš„æ¨ç†åŠ é€Ÿï¼Œä¸º LLM ä½æ¯”ç‰¹é‡åŒ–æä¾›äº†å¯æ‰©å±•ã€é«˜æ•ˆä¸”å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 2. [TALON: Confidence-Aware Speculative Decoding with Adaptive Token Trees](https://arxiv.org/abs/2601.07353)

**Authors**: Tianyu Liu, Qitan Lv, Yuhao Shen, Xiao Sun, Xiaoyan Sun  
**Category**: cs.CL  
**Published**: 2026-01-13  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2601.07353v1  

#### Abstract
Speculative decoding (SD) has become a standard technique for accelerating LLM inference without sacrificing output quality. Recent advances in speculative decoding have shifted from sequential chain-based drafting to tree-structured generation, where the draft model constructs a tree of candidate t...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTALON: Confidence-Aware Speculative Decoding with Adaptive Token Trees

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„ **tree-based speculative decoding**ï¼ˆå¦‚ EAGLEï¼‰æ–¹æ³•é€šå¸¸é‡‡ç”¨å›ºå®šå®½åº¦ï¼ˆfixed widthï¼‰å’Œå›ºå®šæ·±åº¦ï¼ˆfixed depthï¼‰çš„ **é™æ€ draft tree ç»“æ„**ã€‚è¿™ç§åˆšæ€§è®¾è®¡å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- åœ¨ç¡®å®šæ€§ä¸Šä¸‹æ–‡ï¼ˆä½ç†µï¼‰ä¸­ï¼Œæ¨¡å‹å·²é«˜åº¦è‡ªä¿¡ï¼Œä½†ä»å¼ºåˆ¶æ‰©å±• `K` ä¸ªå­èŠ‚ç‚¹ï¼Œé€ æˆ **è¿‡åº¦æ¢ç´¢ï¼ˆover-explorationï¼‰** å’Œè®¡ç®—æµªè´¹ã€‚
- åœ¨ä¸ç¡®å®šæ€§ä¸Šä¸‹æ–‡ï¼ˆé«˜ç†µï¼‰ä¸­ï¼Œtop-K å€™é€‰ä¸è¶³ä»¥è¦†ç›–ç›®æ ‡åˆ†å¸ƒï¼Œå¯¼è‡´ **æ¢ç´¢ä¸è¶³ï¼ˆunder-explorationï¼‰**ï¼Œä¸”ä»ä¼šç”Ÿæˆé•¿è€Œæ— æ•ˆçš„åˆ†æ”¯ã€‚
- å›ºå®šæ·±åº¦é™åˆ¶äº†åœ¨ç®€å•ä»»åŠ¡ä¸­çš„æ½œåœ¨åŠ é€Ÿä¸Šé™ï¼Œè€Œåœ¨å›°éš¾ä»»åŠ¡ä¸­åˆæµªè´¹èµ„æºäºæ³¨å®šè¢«æ‹’ç»çš„è·¯å¾„ã€‚

### æå‡ºçš„æ–°æ–¹æ³•
ä½œè€…æå‡º **TALON**ï¼Œä¸€ç§**æ— éœ€è®­ç»ƒã€åŸºäºé¢„ç®—é©±åŠ¨çš„è‡ªé€‚åº”æ ‘æ‰©å±•æ¡†æ¶**ï¼ˆbudget-driven adaptive tree expansionï¼‰ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- **ä»¥å…¨å±€ token é¢„ç®— `N` ä¸ºçº¦æŸ**ï¼Œè€Œéå›ºå®šå®½åº¦/æ·±åº¦ã€‚
- é‡‡ç”¨ **æ··åˆæ‰©å±•ç­–ç•¥ï¼ˆhybrid expansion strategyï¼‰**ï¼š
  - **ç¬¬0å±‚ï¼ˆæ ¹å±‚ï¼‰**ï¼šä½¿ç”¨ **Top-K åˆå§‹åŒ–**ï¼Œç¡®ä¿é²æ£’æ€§ï¼Œé¿å…å›  draft model åˆå§‹è¿‡è‡ªä¿¡ï¼ˆover-confidenceï¼‰è€Œå¯¼è‡´æ•´æ£µæ ‘é”™è¯¯ã€‚
  - **åç»­å±‚ï¼ˆd â‰¥ 1ï¼‰**ï¼šé‡‡ç”¨ **ç½®ä¿¡åº¦è¿‡æ»¤æœºåˆ¶ï¼ˆconfidence-gated expansionï¼‰**ï¼Œä»…ä¿ç•™æ¦‚ç‡ä¸ä½äºé”šç‚¹æ¦‚ç‡ï¼ˆanchor confidenceï¼‰`Î¼` å€çš„å€™é€‰èŠ‚ç‚¹ï¼ˆå³ `p(u) â‰¥ Î¼ Â· max_p`ï¼‰ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **åŠ¨æ€æ‹“æ‰‘é€‚åº”æ€§**ï¼šè‡ªåŠ¨å½¢æˆâ€œ**æ·±è€Œçª„**â€ï¼ˆdeep-and-narrowï¼‰ç»“æ„ç”¨äºç¡®å®šæ€§ä¸Šä¸‹æ–‡ï¼Œæˆ–â€œ**æµ…è€Œå®½**â€ï¼ˆshallow-and-wideï¼‰ç»“æ„ç”¨äºä¸ç¡®å®šæ€§ä¸Šä¸‹æ–‡ã€‚
- **æ›´é«˜çš„èµ„æºåˆ©ç”¨ç‡**ï¼šé¿å…äº†é™æ€æ–¹æ³•ä¸­â€œå…ˆæ‰©å±•åå‰ªæâ€ï¼ˆexpand-then-shrinkï¼‰å¸¦æ¥çš„å†—ä½™èŠ‚ç‚¹ç”Ÿæˆã€‚
- **æ— éœ€é¢å¤–è®­ç»ƒ**ï¼šå®Œå…¨åŸºäºæ¨ç†æ—¶çš„å®æ—¶ç½®ä¿¡åº¦å†³ç­–ï¼Œå¯ç›´æ¥é›†æˆåˆ°ç°æœ‰ tree-based SD æ¡†æ¶ä¸­ã€‚
- **æ›´ä¼˜çš„æ€§ä»·æ¯”**ï¼šé€šè¿‡åŠ¨æ€è°ƒæ•´ draft æˆæœ¬ï¼ˆdraft efficiencyï¼‰ï¼Œåœ¨ä¸åŒéš¾åº¦ä»»åŠ¡ä¸Šå‡èƒ½ä¿æŒé«˜æ•ˆåŠ é€Ÿã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
åœ¨ **6 ä¸ªå¤šæ ·åŒ–åŸºå‡†** ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œæ¶µç›–å¤šç§ä»»åŠ¡ç±»å‹ï¼š
- **æŒ‡ä»¤éµå¾ª**ï¼šAlpaca
- **æ•°å­¦æ¨ç†**ï¼šGSM8K
- **ä»£ç ç”Ÿæˆ**ï¼šHumanEval
- **å¤šè½®å¯¹è¯**ï¼šMT-Bench
- **é—®ç­”**ï¼šQA (Natural Questions)
- **æ‘˜è¦**ï¼šCNN/DM

### å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼šåœ¨ **5 ç§ä¸»æµ LLM** ä¸Šæµ‹è¯•ï¼ŒåŒ…æ‹¬ï¼š
  - Llama-3.1-8B-Instruct
  - Qwen3-8B / 32B
  - DeepSeek-R1-Distill-LLaMA-8B (DSL-8B)
  - Vicuna-13B
- **ç¡¬ä»¶**ï¼šå•å¼  NVIDIA H200 (140GB) GPUï¼Œbatch size = 1ã€‚
- **é¢„ç®—è®¾ç½®**ï¼šå…¨å±€ token é¢„ç®— `N = 60`ï¼ŒTALON çš„ç½®ä¿¡åº¦é˜ˆå€¼ `Î¼ = 0.03`ã€‚
- **åŸºçº¿æ–¹æ³•**ï¼š
  - **é“¾å¼æ–¹æ³•**ï¼šStandard SD, MEDUSA, HYDRA
  - **æ ‘å¼æ–¹æ³•**ï¼šEAGLE-3 (SOTA), OPT-Tree
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Mean Accepted Tokens (MAT)**ï¼šæ¯è½®éªŒè¯å¹³å‡æ¥å—çš„ draft tokens æ•°é‡ã€‚
  - **Wall-time Speedup (Spd.)**ï¼šç›¸å¯¹äºæ ‡å‡†è‡ªå›å½’è§£ç çš„å®é™…ç«¯åˆ°ç«¯åŠ é€Ÿæ¯”ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- TALON åœ¨æ‰€æœ‰ 5 ä¸ªæ¨¡å‹å’Œ 6 ä¸ªæ•°æ®é›†ä¸Š **ä¸€è‡´ä¼˜äº EAGLE-3**ã€‚
- æœ€é«˜è¾¾åˆ° **5.16Ã— çš„ç«¯åˆ°ç«¯åŠ é€Ÿ**ï¼ˆVicuna-13B + HumanEvalï¼‰ï¼Œæ˜¾è‘—é«˜äº EAGLE-3 çš„ 4.77Ã—ã€‚
- åœ¨ CNN/DM ä¸Šå®ç° **2.30Ã— åŠ é€Ÿ**ï¼ˆQwen3-8Bï¼‰ï¼Œä¼˜äº EAGLE-3 çš„ 1.95Ã—ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| æ¨¡å‹ | æ–¹æ³• | HumanEval (Spd.) | GSM8K (Spd.) |
|------|------|------------------|--------------|
| Vicuna-13B | EAGLE-3 | 4.77Ã— | 3.87Ã— |
| Vicuna-13B | **TALON** | **5.16Ã—** | **3.99Ã—** |
| Qwen3-8B | EAGLE-3 | 2.35Ã— | 2.37Ã— |
| Qwen3-8B | **TALON** | **2.69Ã—** | **2.67Ã—** |

> âœ… **Universal Speedup**ï¼šTALON åœ¨æ‰€æœ‰åœºæ™¯ä¸‹å‡è¶…è¶Š EAGLE-3ã€‚
> âœ… **Reasoning Adaptability**ï¼šåœ¨æ•°å­¦å’Œä»£ç ç­‰ä½ç†µä»»åŠ¡ä¸Šä¼˜åŠ¿å°¤ä¸ºæ˜æ˜¾ï¼Œè¯´æ˜å…¶èƒ½æœ‰æ•ˆæ•æ‰ç¡®å®šæ€§è·¯å¾„å¹¶å»¶é•¿æ¨æµ‹é•¿åº¦ã€‚
> âœ… **Robustness**ï¼šåœ¨ `T=1` çš„éšæœºé‡‡æ ·è®¾ç½®ä¸‹ï¼ŒTALON ä»ä¿æŒä¼˜åŠ¿ï¼ˆå¦‚ Qwen3-8B HumanEval è¾¾ 2.51Ã— vs EAGLE-3 çš„ 2.20Ã—ï¼‰ã€‚

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰é²æ£’åˆå§‹åŒ–å±‚æ•°æ¶ˆèï¼ˆTop-K å±‚æ•°ï¼‰
- **k=0**ï¼ˆæ— åˆå§‹åŒ–ï¼‰ï¼šé€Ÿåº¦ä¸‹é™ï¼ˆå¦‚ Llama3-8B ä» 263.8 â†’ 261.5 tok/sï¼‰ï¼ŒéªŒè¯äº†æ ¹å±‚è¿‡è‡ªä¿¡é£é™©ã€‚
- **kâ‰¥2**ï¼ˆè¿‡å¤šåˆå§‹åŒ–ï¼‰ï¼šå»¶è¿Ÿè¿›å…¥ç½®ä¿¡åº¦è¿‡æ»¤é˜¶æ®µï¼Œå¢åŠ å¼€é”€ã€‚
- **k=1**ï¼ˆTALON é»˜è®¤ï¼‰ï¼šåœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šè¡¨ç°æœ€ä¼˜ï¼Œè¯æ˜ **å•å±‚ Top-K åˆå§‹åŒ– + åç»­ç½®ä¿¡åº¦è¿‡æ»¤** æ˜¯æœ€ä½³å¹³è¡¡ã€‚

#### ï¼ˆ2ï¼‰é¢„ç®—æ•æ„Ÿæ€§åˆ†æ
- åœ¨ä¸åŒé¢„ç®— `N âˆˆ [32, 96]` ä¸‹ï¼ŒTALON å§‹ç»ˆä¼˜äº EAGLE-3ã€‚
- åœ¨å°é¢„ç®—ï¼ˆN=32ï¼‰ä¸‹ä¼˜åŠ¿æ›´æ˜¾è‘—ï¼Œè¯´æ˜ TALON èƒ½æ›´é«˜æ•ˆåœ°ä¼˜å…ˆåˆ†é…èµ„æºç»™é«˜ä»·å€¼è·¯å¾„ã€‚

#### ï¼ˆ3ï¼‰ç½®ä¿¡åº¦é˜ˆå€¼ `Î¼` æ•æ„Ÿæ€§
- `Î¼` æ§åˆ¶æ¢ç´¢ä¸åˆ©ç”¨çš„æƒè¡¡ï¼š
  - è¾ƒå¤§ `Î¼` â†’ æ›´ä¸¥æ ¼è¿‡æ»¤ â†’ â€œæ·±è€Œçª„â€ â†’ é€‚åˆé«˜å¯¹é½æ¨¡å‹ï¼ˆå¦‚ DSL-8Bï¼‰ã€‚
  - è¾ƒå° `Î¼` â†’ æ›´å®½æ¾è¿‡æ»¤ â†’ â€œæµ…è€Œå®½â€ â†’ é€‚åˆä½å¯¹é½æ¨¡å‹ï¼ˆå¦‚ Qwen3-8Bï¼‰ã€‚
- å®éªŒè¡¨æ˜ï¼Œ**æœ€ä¼˜ `Î¼` ä¸ draft-target å¯¹é½ç¨‹åº¦æ­£ç›¸å…³**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
- **é™æ€æ ‘ç»“æ„å­˜åœ¨ç³»ç»Ÿæ€§æ•ˆç‡ç“¶é¢ˆ**ï¼šâ€œAcceptance Funnelâ€ ç°è±¡è¡¨æ˜æ·±å±‚èŠ‚ç‚¹æ¥å—é›†ä¸­åœ¨ top-1/2ï¼Œå®½æ‰©å±•æ— æ•ˆï¼›â€œStatic Depth Dilemmaâ€ è¡¨æ˜å›ºå®šæ·±åº¦æ— æ³•é€‚åº”ä»»åŠ¡éš¾åº¦æ³¢åŠ¨ã€‚
- **TALON é€šè¿‡é¢„ç®—é©±åŠ¨ + ç½®ä¿¡åº¦è¿‡æ»¤ï¼Œå®ç°äº†çœŸæ­£çš„åŠ¨æ€é€‚åº”æ€§**ï¼Œå…¶ draft efficiency æ›²çº¿ç´§è´´ç†è®ºæœ€ä¼˜ï¼ˆOracleï¼‰ï¼Œæ˜¾è‘—å‡å°‘è®¡ç®—æµªè´¹ã€‚
- **æ··åˆç­–ç•¥è‡³å…³é‡è¦**ï¼šæ ¹å±‚ Top-K ä¿è¯é²æ£’æ€§ï¼Œåç»­å±‚ç½®ä¿¡åº¦è¿‡æ»¤å®ç°é«˜æ•ˆè‡ªé€‚åº”ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **æ‰¹å¤„ç†æ‰©å±•æ€§æœ‰é™**ï¼šå½“å‰è¯„ä¼°èšç„¦äº `batch_size=1` çš„ä½å»¶è¿Ÿåœºæ™¯ï¼Œåœ¨å¤§æ‰¹é‡åååœºæ™¯ä¸‹ï¼Œç»´æŠ¤å¤šæ ·åŒ–çš„åŠ¨æ€æ ‘ç»“æ„å¯èƒ½å¸¦æ¥éå¹³å‡¡çš„å†…å­˜å’Œè°ƒåº¦å¼€é”€ã€‚
- **è¶…å‚æ•°æ³›åŒ–æ€§**ï¼šè™½ç„¶ `Î¼=0.03`, `N=60` åœ¨å¤šæ•°æƒ…å†µä¸‹è¡¨ç°ç¨³å¥ï¼Œä½†åœ¨ç‰¹å®šé¢†åŸŸå¯èƒ½éœ€è¦è°ƒä¼˜ã€‚ç¼ºä¹è‡ªåŠ¨è°ƒå‚æœºåˆ¶ã€‚
- **æœªè§£å†³ draft model æœ¬èº«çš„è´¨é‡é—®é¢˜**ï¼šTALON ä¾èµ–ç°æœ‰ draft modelï¼Œè‹¥å…¶æ ¡å‡†å·®æˆ–èƒ½åŠ›å¼±ï¼Œä»ä¼šå½±å“æ•´ä½“æ€§èƒ½ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å¼€å‘é€‚ç”¨äº **å¤§æ‰¹é‡æœåŠ¡** çš„é«˜æ•ˆåŠ¨æ€æ ‘ç®¡ç†æœºåˆ¶ã€‚
- è®¾è®¡ **åœ¨çº¿è‡ªåŠ¨è°ƒå‚æœºåˆ¶**ï¼Œæ ¹æ®å†å²æ¥å—ç‡åŠ¨æ€è°ƒæ•´ `Î¼` å’Œ `N`ã€‚
- æ¢ç´¢å°† TALON ä¸å…¶ä»–æŠ€æœ¯ï¼ˆå¦‚ retrieval-based drafting æˆ– early-exitï¼‰ç»“åˆï¼Œè¿›ä¸€æ­¥æå‡ draft è´¨é‡ä¸æ•ˆç‡ã€‚

---

> **æ€»ç»“**ï¼šTALON æå‡ºäº†ä¸€ç§ç®€æ´è€Œå¼ºå¤§çš„ **training-freeã€budget-driven è‡ªé€‚åº”æ¨æµ‹æ¡†æ¶**ï¼Œé€šè¿‡ **æ··åˆæ‰©å±•ç­–ç•¥** å®ç°äº†å¯¹ä¸Šä¸‹æ–‡ä¸ç¡®å®šæ€§çš„åŠ¨æ€å“åº”ï¼Œåœ¨å¤šä¸ªæ¨¡å‹å’Œä»»åŠ¡ä¸Šæ˜¾è‘—è¶…è¶Š SOTA æ–¹æ³•ï¼Œä¸ºé«˜æ•ˆ LLM æ¨ç†æä¾›äº†æ–°çš„èŒƒå¼ã€‚

</details>

---

### 3. [d3LLM: Ultra-Fast Diffusion LLM using Pseudo-Trajectory Distillation](https://arxiv.org/abs/2601.07568)

**Authors**: Yu-Yang Qian, Junda Su, Lanxiang Hu, Peiyuan Zhang, Zhijie Deng, Peng Zhao, Hao Zhang  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2601.07568v1  

#### Abstract
Diffusion large language models (dLLMs) offer capabilities beyond those of autoregressive (AR) LLMs, such as parallel decoding and random-order generation. However, realizing these benefits in practice is non-trivial, as dLLMs inherently face an accuracy-parallelism trade-off. Despite increasing int...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šd3LLM: Ultra-Fast Diffusion LLM using Pseudo-Trajectory Distillation

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„ **Diffusion Large Language Models (dLLMs)** é¢ä¸´ä¸€ä¸ªæ ¹æœ¬æ€§çš„ **accuracy-parallelism trade-off**ï¼ˆå‡†ç¡®ç‡-å¹¶è¡Œåº¦æƒè¡¡ï¼‰ï¼š
- è¿½æ±‚é«˜å¹¶è¡Œè§£ç ï¼ˆå¦‚å¤šå—åŒæ—¶ç”Ÿæˆï¼‰ä¼šå› é”™è¯¯ä¼ æ’­å¯¼è‡´å‡†ç¡®ç‡ä¸‹é™ï¼›
- è€Œä¿æŒé«˜å‡†ç¡®ç‡åˆ™å¾€å¾€ç‰ºç‰²äº†è§£ç é€Ÿåº¦ï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…ä¸­çš„é«˜æ•ˆåº”ç”¨ã€‚

æ­¤å¤–ï¼Œä¼ ç»Ÿè®­ç»ƒæ–¹å¼é‡‡ç”¨éšæœºæ©ç ï¼ˆrandom maskingï¼‰ï¼Œç¼ºä¹å¯¹â€œå“ªäº›tokenå¯ä»¥æ—©æœŸå®‰å…¨è§£ç â€çš„æŒ‡å¯¼ï¼›æ¨ç†é˜¶æ®µçš„å¤šå—è§£ç ä¹Ÿå®¹æ˜“å› ä¸Šä¸‹æ–‡ä¸å®Œæ•´è€Œé™ä½è´¨é‡ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šd3LLM æ¡†æ¶
ä½œè€…æå‡º **d3LLM**ï¼ˆ*pseuDo-Distilled Diffusion LLM*ï¼‰ï¼Œé€šè¿‡ä»¥ä¸‹ä¸¤ä¸ªæ ¸å¿ƒæœºåˆ¶ï¼Œåœ¨è®­ç»ƒä¸æ¨ç†é˜¶æ®µååŒä¼˜åŒ–å‡†ç¡®ç‡ä¸å¹¶è¡Œåº¦ï¼š

#### ï¼ˆ1ï¼‰è®­ç»ƒé˜¶æ®µï¼šPseudo-Trajectory Distillationï¼ˆä¼ªè½¨è¿¹è’¸é¦ï¼‰
- åˆ©ç”¨æ•™å¸ˆ dLLM è‡ªèº«çš„è§£ç è¿‡ç¨‹ï¼ˆå³ä½¿æœ€ç»ˆè¾“å‡ºä¸å®Œå…¨æ­£ç¡®ï¼‰ä½œä¸ºâ€œä¼ªè½¨è¿¹â€ï¼ˆpseudo-trajectoryï¼‰ï¼Œæä¾›ä¸­é—´ç›‘ç£ä¿¡å·ã€‚
- å°†è¯¥è½¨è¿¹ä¸çœŸå®æ ‡ç­¾ç»“åˆï¼Œæ„å»ºå¸¦å™ªå£°çš„è¾“å…¥åºåˆ—ï¼Œè®­ç»ƒå­¦ç”Ÿæ¨¡å‹å­¦ä¹ æ›´åˆç†çš„ unmasking é¡ºåºã€‚
- å¼•å…¥ **curriculum learning** ç­–ç•¥ï¼š
  - **æ¸è¿›å¼å™ªå£°è°ƒåº¦**ï¼šmask ratio ä» 0.0 é€æ­¥å¢åŠ åˆ° 0.8ï¼›
  - **æ¸è¿›å¼çª—å£å¤§å°**ï¼šè§£ç çª—å£é•¿åº¦ä» 16 å¢åŠ åˆ° 32ã€‚
- ä¼˜åŠ¿ï¼šä½¿æ¨¡å‹å­¦ä¼šåœ¨æ—©æœŸè‡ªä¿¡åœ°è§£ç é«˜ç½®ä¿¡åº¦ tokenï¼Œæå‡å¹¶è¡Œæ½œåŠ›ã€‚

#### ï¼ˆ2ï¼‰æ¨ç†é˜¶æ®µï¼šEntropy-Based Multi-Block Decoding + KV-Cache Refresh
- **åŸºäºç†µçš„å¤šå—å¹¶è¡Œè§£ç **ï¼šé€‰æ‹©ä½ç†µï¼ˆé«˜ç½®ä¿¡ï¼‰tokenä¼˜å…ˆè§£ç ï¼Œæ”¯æŒè·¨å¤šä¸ª block å¹¶è¡Œç”Ÿæˆã€‚
- **KV-Cache åˆ·æ–°æœºåˆ¶**ï¼š
  - æ–° block å®Œæˆåå»¶è¿Ÿç¼“å­˜ KV çŠ¶æ€ï¼›
  - åœ¨â€œç¨³å®šä¸­â€çŠ¶æ€è¿›è¡Œå…¨å‰å‘ä¼ æ’­åˆ·æ–°å†å² KV ç¼“å­˜ï¼Œé˜²æ­¢è¯¯å·®ç´¯ç§¯ã€‚
- **æ—©åœæœºåˆ¶**ï¼šä¸€æ—¦ç”Ÿæˆ EOS token å³ç»ˆæ­¢è§£ç ï¼Œå‡å°‘å†—ä½™è®¡ç®—ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | d3LLM | å…¶ä»–æ–¹æ³•ï¼ˆå¦‚ Fast-dLLM, D2F, dParallelï¼‰ |
|------|-------|----------------------------------------|
| **è®­ç»ƒæŒ‡å¯¼** | æ˜¾å¼å¼•å…¥ teacher çš„è§£ç é¡ºåºä½œä¸ºç›‘ç£ | ä¾èµ–éšæœºæ©ç æˆ–ç®€å•è’¸é¦ï¼Œæ— é¡ºåºå¼•å¯¼ |
| **å¹¶è¡Œèƒ½åŠ›** | æ”¯æŒè·¨ block å¤šæ­¥å¹¶è¡Œè§£ç  | å¤šä¸ºå• block æˆ–å—é™å¹¶è¡Œ |
| **å‡†ç¡®æ€§ä¿éšœ** | KV-cache åˆ·æ–° + entropy æ§åˆ¶ | æ˜“å—é”™è¯¯ä¼ æ’­å½±å“ |
| **ç»¼åˆæ€§èƒ½** | åœ¨ accuracy å’Œ parallelism ä¹‹é—´å–å¾—æ›´å¥½å¹³è¡¡ | å¾€å¾€åå‘ä¸€ä¾§ï¼ˆå¿«ä½†ä¸å‡† / å‡†ä½†ä¸å¿«ï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
åœ¨äº”ä¸ªä»£è¡¨æ€§ä»»åŠ¡ä¸Šè¯„ä¼°ï¼š
- **GSM8K-CoT**ï¼šæ•°å­¦æ¨ç†ï¼ˆé›¶æ ·æœ¬ï¼‰
- **MATH**ï¼šç«èµ›çº§æ•°å­¦é¢˜ï¼ˆå››æ ·æœ¬ï¼‰
- **HumanEval**ï¼šä»£ç ç”Ÿæˆï¼ˆé›¶æ ·æœ¬ï¼‰
- **MBPP**ï¼šPython ç¼–ç¨‹ä»»åŠ¡ï¼ˆä¸‰æ ·æœ¬ï¼‰
- **Long-GSM8K**ï¼šé•¿ä¸Šä¸‹æ–‡æ•°å­¦æ¨ç†ï¼ˆäº”æ ·æœ¬ï¼Œprompt ~1000 tokensï¼‰

### å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼š
  - LLaDA (8B)
  - Dream (7B)
  - Dream-Coder (7B)
- **è¡ç”Ÿæ¨¡å‹**ï¼š
  - d3LLM-LLaDA
  - d3LLM-Dream
  - d3LLM-Coder
- **è®­ç»ƒç»†èŠ‚**ï¼š
  - ä½¿ç”¨ LoRA å¾®è°ƒï¼Œrank=256
  - å­¦ä¹ ç‡ 2e-5ï¼ŒAdamW ä¼˜åŒ–å™¨
  - æ‰¹å¤§å° 64ï¼ˆæ¢¯åº¦ç´¯ç§¯ï¼‰
  - åœ¨ H100 ä¸Šè®­ç»ƒï¼Œbfloat16 ç²¾åº¦
- **æ¨ç†é…ç½®**ï¼š
  - æœ€å¤§ç”Ÿæˆé•¿åº¦ 256/512
  - è´ªå©ªè§£ç ï¼ˆtemperature=0.0~0.1ï¼‰
  - Block size å›ºå®šä¸º 32

### è¯„ä¼°æŒ‡æ ‡
- **Tokens Per Forward (TPF)**ï¼šè¡¡é‡å¹¶è¡Œåº¦ï¼ˆç®—æ³•å±‚é¢æ•ˆç‡ï¼‰
- **Accuracy (Pass@1 / Solve Rate)**ï¼šç”Ÿæˆè´¨é‡
- **AUP (Accuracy Under Parallelism)**ï¼š**æœ¬æ–‡æå‡ºçš„æ–°æŒ‡æ ‡**ï¼Œç»¼åˆè¡¡é‡ accuracy ä¸ parallelism çš„è”åˆè¡¨ç°
  - å®šä¹‰ä¸º accuracy-parallelism æ›²çº¿ä¸‹åŠ æƒé¢ç§¯
  - æƒé‡å‡½æ•° $ W(y) = \min(e^{-(1-y/y_{\text{max}})}, 1) $ï¼Œæƒ©ç½šä½å‡†ç¡®åŒºåŸŸ
  - è®¾å®šæœ€å°é˜ˆå€¼é¿å…æ— æ•ˆé«˜é€ŸåŒºå¹²æ‰°è¯„åˆ†

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **Vanilla LLaDA / Dream** | åŸå§‹ dLLM | ä»å¤´è®­ç»ƒæˆ– AR åˆå§‹åŒ– |
| **Fast-dLLM** | æ¨ç†åŠ é€Ÿ | æ— éœ€è®­ç»ƒï¼ŒKV-cache + confidence-aware decoding |
| **Fast-dLLM-v2** | AR è½¬ dLLM | å¾®è°ƒ AR æ¨¡å‹ä¸º block diffusion |
| **dParallel** | è’¸é¦æ–¹æ³• | Certainty-forcing distillation æå‡å¹¶è¡Œæ€§ |
| **D2F** | æ··åˆæ¶æ„ | AR-diffusion hybridï¼Œæ”¯æŒè·¨å—å¹¶è¡Œ |
| **EAGLE-3** | Speculative Decoding | ä½¿ç”¨ draft model åŠ é€Ÿ AR æ¨¡å‹ï¼ˆç”¨äºä¸Šé™æ¯”è¾ƒï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ d3LLM-LLaDA ä¸ºä¾‹ï¼‰

| æ–¹æ³• | TPF | Acc (%) | AUP Score |
|------|-----|---------|-----------|
| LLaDA | 1.00 | 72.6 | 72.6 |
| Fast-dLLM-LLaDA | 2.77 | 74.7 | 205.8 |
| D2F-LLaDA | 2.88 | 73.2 | 209.7 |
| dParallel-LLaDA | 5.14 | 72.6 | 358.1 |
| **d3LLM-LLaDA** | **9.11** | **73.1** | **637.7** âœ… |

> åœ¨ GSM8K-CoT ä¸Šï¼ŒAUP æå‡è¶…è¿‡ **77%** ç›¸æ¯”æ¬¡ä¼˜æ–¹æ³•ã€‚

### ä¸å…¶ä»–æ–¹æ³•çš„æ•´ä½“å¯¹æ¯”
- **AUP è¡¨ç°**ï¼š
  - d3LLM åœ¨ **10é¡¹æµ‹è¯•ä»»åŠ¡ä¸­çš„9é¡¹** å–å¾—æœ€é«˜ AUP åˆ†æ•°ã€‚
  - åœ¨ MATHã€HumanEvalã€Long-GSM8K ç­‰å¤æ‚ä»»åŠ¡ä¸Šæ˜¾è‘—é¢†å…ˆã€‚
- **ååé‡ï¼ˆTPSï¼‰æå‡**ï¼š
  | æ–¹æ³• | H100 TPS | Speedup vs AR |
  |------|----------|----------------|
  | Qwen-2.5-7B-it (AR) | 57.3 | 1.0Ã— |
  | d3LLM-LLaDA | **288.9** | **5.0Ã—** |
  | d3LLM-Dream | **235.3** | **4.1Ã—** |
  | Vanilla LLaDA | 27.9 | 0.5Ã— |
  > å®ç° **é«˜è¾¾ 10Ã— ç›¸æ¯”åŸå§‹ dLLM çš„é€Ÿåº¦æå‡**ï¼Œä¸”ç²¾åº¦å‡ ä¹æ— æŸã€‚

- **ç¡¬ä»¶æ— å…³æ€§éªŒè¯**ï¼š
  - AUP åŸºäº TPFï¼ˆè€Œé TPSï¼‰ï¼Œåœ¨ä¸åŒ GPUï¼ˆH100/A100ï¼‰é—´æ›´å…·å¯æ¯”æ€§ã€‚
  - d3LLM åœ¨ A100 ä¸Šä»å®ç° **3.6Ã— é€Ÿåº¦æå‡**ï¼Œè¯æ˜å…¶ç®—æ³•ä¼˜åŠ¿ä¸å—é™äºç‰¹å®šç¡¬ä»¶ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### è’¸é¦ç­–ç•¥æ¶ˆèï¼ˆd3LLM-LLaDA on GSM8K-CoTï¼‰
| é…ç½® | TPF | Acc (%) | AUP |
|------|-----|---------|-----|
| Baselineï¼ˆä»… multi-block + early stopï¼‰ | 6.41 | 72.2 | 441.4 |
| + Pseudo-Trajectory | 7.55 | 72.1 | 517.7 |
| + Curriculum Noise | 8.46 | 69.8 | 551.3 |
| **Fullï¼ˆ+ Curriculum Windowï¼‰** | **9.11** | **73.1** | **637.7** |

âœ… ç»“è®ºï¼šæ‰€æœ‰ç»„ä»¶å‡æœ‰è´¡çŒ®ï¼Œå°¤å…¶æ˜¯ curriculum window æ˜¾è‘—æ¢å¤å¹¶æå‡ accuracyã€‚

#### è§£ç ç­–ç•¥æ¶ˆè
| é…ç½® | TPF | Acc (%) | AUP |
|------|-----|---------|-----|
| Vanilla Block Diffusion | 7.01 | 73.2 | 492.9 |
| + Multi-block Decoding | 9.07 | 73.1 | 635.0 |
| **+ Early Stopping** | **9.11** | **73.1** | **637.7** |

âœ… ç»“è®ºï¼šmulti-block decoding æ˜¯ TPF æå‡ä¸»å› ï¼Œearly stopping è¿›ä¸€æ­¥ä¼˜åŒ–æ•ˆç‡ã€‚

#### è¶…å‚æ•°åˆ†æ
- **Curriculum Noise Level**ï¼šä»å›ºå®š noise åˆ° `0.0â†’0.8`ï¼ŒAUP æå‡ **22.2%**
- **Curriculum Window Size**ï¼šä»å›ºå®š k=32 åˆ° `16â†’32`ï¼ŒAUP æå‡ **19.0%**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **dLLMs å­˜åœ¨å›ºæœ‰çš„ accuracy-parallelism trade-off**ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥å…¼é¡¾ä¸¤è€…ã€‚
2. **Pseudo-Trajectory Distillation** èƒ½æœ‰æ•ˆä¼ é€’ teacher çš„è§£ç åå¥½ï¼Œæ˜¾è‘—æå‡å­¦ç”Ÿæ¨¡å‹çš„å¹¶è¡Œè§£ç èƒ½åŠ›ã€‚
3. **Multi-block decoding + KV-refresh** å¯ç¼“è§£è¯¯å·®ä¼ æ’­é—®é¢˜ï¼Œåœ¨é«˜å¹¶è¡Œä¸‹ç»´æŒé«˜è´¨é‡ç”Ÿæˆã€‚
4. **AUP æ˜¯ä¸€ä¸ªæ›´å…¬å¹³ã€æ›´æœ‰æ„ä¹‰çš„è¯„ä¼°æŒ‡æ ‡**ï¼Œèƒ½åæ˜ æ–¹æ³•åœ¨â€œæé€Ÿä¸é™è´¨â€æ–¹é¢çš„çœŸæ­£èƒ½åŠ›ã€‚
5. d3LLM å®ç°äº† **5Ã— ä»¥ä¸Šç›¸æ¯” AR æ¨¡å‹çš„é€Ÿåº¦æå‡**ï¼Œä»¥åŠ **10Ã— ç›¸æ¯”åŸå§‹ dLLM çš„åŠ é€Ÿ**ï¼ŒåŒæ—¶ä¿æŒç«äº‰åŠ›çš„ accuracyã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ¡†æ¶ä»åŸºäºå·²æœ‰ dLLM æ¶æ„ï¼ˆå¦‚ LLaDA/Dreamï¼‰ï¼Œæœªæ¢ç´¢æ›´å¼ºçš„åŸºç¡€æ¨¡å‹ï¼ˆå¦‚ LLaDA 2.0ï¼‰ä¸Šçš„æé™æ€§èƒ½ã€‚
- æ¨ç†æ—¶éœ€ç»´æŠ¤å¤æ‚çš„ KV-cache åˆ·æ–°é€»è¾‘ï¼Œç³»ç»Ÿå®ç°å¤æ‚åº¦è¾ƒé«˜ã€‚
- å¤šå—å¹¶è¡Œä¾èµ– entropy åˆ¤æ–­ï¼Œæç«¯æƒ…å†µä¸‹å¯èƒ½è¯¯åˆ¤å¯¼è‡´é”™è¯¯æ‰©æ•£ã€‚
- æ‰€æœ‰å®éªŒåŸºäº HuggingFace Transformers åç«¯ï¼Œæœªé›†æˆ vLLM ç­‰é«˜æ€§èƒ½æ¨ç†å¼•æ“ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **ç»“åˆ Speculative Decoding**ï¼šå°† d3LLM ä½œä¸º draft model æˆ– verifierï¼Œä¸ EAGLE ç­‰æ¡†æ¶èåˆï¼Œè¿›ä¸€æ­¥çªç ´æ€§èƒ½è¾¹ç•Œã€‚
2. **åº”ç”¨äºæ›´å¼ºçš„ dLLM åŸºåº§**ï¼šå¦‚ ReFusionã€LLaDA 2.0 ç­‰ï¼ŒéªŒè¯é€šç”¨æ€§å’Œæ‰©å±•æ€§ã€‚
3. **ç³»ç»Ÿçº§ä¼˜åŒ–**ï¼š
   - GPU kernel fusion é’ˆå¯¹ multi-block pattern ä¼˜åŒ–ï¼›
   - å®ç° paged attention æ”¯æŒ bidirectional attentionï¼›
   - æ›´é«˜æ•ˆçš„ KV-cache ç®¡ç†ç­–ç•¥ã€‚
4. **å¼•å…¥å¼ºåŒ–å­¦ä¹ **ï¼šåˆ©ç”¨ trajectory-aware RLï¼ˆå¦‚ TraDoï¼‰è¿›ä¸€æ­¥ä¼˜åŒ–è§£ç è·¯å¾„é€‰æ‹©ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> d3LLM é€šè¿‡ **ä¼ªè½¨è¿¹è’¸é¦ + å¤šå—ç†µæ§è§£ç  + KVåˆ·æ–°æœºåˆ¶**ï¼Œé¦–æ¬¡åœ¨å¼€æº dLLM ä¸Šå®ç°äº†æ¥è¿‘é—­æºæ¨¡å‹çš„é«˜æ•ˆæ¨ç†æ€§èƒ½ï¼Œåœ¨ **é€Ÿåº¦ã€å‡†ç¡®ç‡ã€é€šç”¨æ€§** ä¸‰è€…ä¹‹é—´å–å¾—äº†å“è¶Šå¹³è¡¡ã€‚

</details>

---

### 4. [TimeGNN-Augmented Hybrid-Action MARL for Fine-Grained Task Partitioning and Energy-Aware Offloading in MEC](https://arxiv.org/abs/2601.06191)

**Authors**: Wei Ai, Yun Peng, Yuntao Shou, Tao Meng, Keqin Li  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2601.06191v1  

#### Abstract
With the rapid growth of IoT devices and latency-sensitive applications, the demand for both real-time and energy-efficient computing has surged, placing significant pressure on traditional cloud computing architectures. Mobile edge computing (MEC), an emerging paradigm, effectively alleviates the l...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**TimeGNN-Augmented Hybrid-Action MARL for Fine-Grained Task Partitioning and Energy-Aware Offloading in MEC**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹ **Mobile Edge Computing (MEC)** ç³»ç»Ÿä¸­ä»¥ä¸‹å…³é”®æŒ‘æˆ˜ï¼š
- **èƒ½æºå—é™**ï¼šè¾¹ç¼˜æœåŠ¡å™¨ä¾èµ–ç”µæ± ä¾›ç”µï¼Œèƒ½é‡é¢„ç®—æœ‰é™ï¼Œé¢‘ç¹é€šä¿¡åŠ å‰§èƒ½è€—ï¼›
- **åŠ¨æ€ç¯å¢ƒ**ï¼šä»»åŠ¡è´Ÿè½½ã€ä¿¡é“çŠ¶æ€å’Œç”¨æˆ·ç§»åŠ¨æ€§é«˜åº¦æ—¶å˜ï¼Œå¯¼è‡´ç³»ç»ŸçŠ¶æ€ä¸ç¨³å®šï¼›
- **é«˜äº¤äº’å¼€é”€**ï¼šä¼ ç»Ÿå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰éœ€é¢‘ç¹è·å–å®æ—¶çŠ¶æ€ï¼Œå¢åŠ é€šä¿¡è´Ÿæ‹…ï¼›
- **ç»†ç²’åº¦å†³ç­–éœ€æ±‚**ï¼šéœ€è¦åŒæ—¶ä¼˜åŒ–ä»»åŠ¡åˆ†å‰²æ¯”ä¾‹ã€ä¼ è¾“åŠŸç‡ã€è®¡ç®—èµ„æºåˆ†é…ç­‰æ··åˆåŠ¨ä½œã€‚

è¿™äº›é—®é¢˜ä½¿å¾—ç°æœ‰æ–¹æ³•åœ¨èƒ½æ•ˆã€å»¶è¿Ÿå’Œå¯æ‰©å±•æ€§æ–¹é¢è¡¨ç°ä¸ä½³ã€‚

---

### âœ… æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **TG-DCMADDPG** çš„æ–°å‹æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰**TimeGNN å¢å¼ºçš„çŠ¶æ€é¢„æµ‹æœºåˆ¶**
- å¼•å…¥ **Temporal Graph Neural Network (TimeGNN)** å¯¹å¤šä¸ªè¾¹ç¼˜æœåŠ¡å™¨çš„å¤šç»´çŠ¶æ€ï¼ˆå¦‚CPUè´Ÿè½½ã€å‰©ä½™èƒ½é‡ã€å¸¦å®½ï¼‰è¿›è¡Œå»ºæ¨¡ï¼›
- åˆ©ç”¨å†å²çŠ¶æ€åºåˆ—é¢„æµ‹æœªæ¥ â–³ æ­¥çš„æœåŠ¡å™¨çŠ¶æ€ï¼Œå®ç°**å‰ç»æ€§å†³ç­–**ï¼›
- æ˜¾è‘—å‡å°‘æ™ºèƒ½ä½“ä¸æœåŠ¡å™¨ä¹‹é—´çš„åœ¨çº¿äº¤äº’é¢‘ç‡ï¼Œé™ä½é€šä¿¡å¼€é”€ã€‚

> ğŸ” åˆ›æ–°ç‚¹ï¼šå°† TimeGNN é¦–æ¬¡åº”ç”¨äº MEC ä¸­çš„**è·¨èŠ‚ç‚¹æ—¶ç©ºçŠ¶æ€é¢„æµ‹**ï¼Œæå‡ç­–ç•¥çš„é¢„è§æ€§å’Œç¨³å®šæ€§ã€‚

#### ï¼ˆ2ï¼‰**ç¦»æ•£-è¿ç»­æ··åˆåŠ¨ä½œç©ºé—´çš„ DC-MADDPG ç®—æ³•**
- è®¾è®¡äº†ä¸€ä¸ªåŸºäº **Centralized Training with Decentralized Execution (CTDE)** æ¶æ„çš„ MARL æ¡†æ¶ï¼›
- åŠ¨ä½œç©ºé—´ä¸ºæ··åˆå‹ï¼ˆhybrid action spaceï¼‰ï¼š
  - **ç¦»æ•£åŠ¨ä½œ**ï¼šé€šè¿‡ Gumbel-Softmax å®ç°æœåŠ¡å™¨é€‰æ‹©ï¼ˆone-hot ç¼–ç ï¼‰ï¼›
  - **è¿ç»­åŠ¨ä½œ**ï¼šæ§åˆ¶ä»»åŠ¡åˆ†å‰²æ¯”ä¾‹ï¼ˆtask splitting ratioï¼‰å’Œä¼ è¾“åŠŸç‡ï¼ˆtransmission powerï¼‰ï¼›
- ä½¿ç”¨ Deterministic Policy Gradient è¿›è¡Œé«˜æ•ˆè®­ç»ƒã€‚

> ğŸ” åˆ›æ–°ç‚¹ï¼šæ”¯æŒ**è”åˆä¼˜åŒ–ä»»åŠ¡åˆ†ç‰‡ã€èµ„æºè°ƒåº¦ä¸åŠŸè€—æ§åˆ¶**ï¼Œå®ç°æ›´ç²¾ç»†çš„ä»»åŠ¡å¸è½½ç­–ç•¥ã€‚

#### ï¼ˆ3ï¼‰**é¢„æµ‹å¢å¼ºå‹ååŒè®¡ç®—æ¡†æ¶**
- å°†é¢„æµ‹æ¨¡å—è¾“å‡ºï¼ˆé¢„æµ‹çŠ¶æ€ $ \hat{s}_{t+\Delta} $ï¼‰ä¸å½“å‰è§‚æµ‹æ‹¼æ¥æˆå¢å¼ºè§‚æµ‹ $ o_n = [o_n^{\text{curr}}, \hat{s}_{t+\Delta}] $ï¼›
- ä½¿å„ç§»åŠ¨è®¾å¤‡ï¼ˆMDï¼‰å¯åœ¨ä¸é¢‘ç¹æŸ¥è¯¢çš„æƒ…å†µä¸‹åšå‡º**ä¸»åŠ¨å¼å¸è½½å†³ç­–**ã€‚

---

### âœ… ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ”¶æ•›é€Ÿåº¦** | å¼•å…¥ TimeGNN åæ˜¾è‘—åŠ å¿«ç­–ç•¥æ”¶æ•›ï¼ˆçº¦60è½®è¾¾æœ€ä¼˜ï¼‰ |
| **èƒ½æ•ˆè¡¨ç°** | èƒ½é‡æ¶ˆè€—æœ€ä½ï¼ˆç¨³å®šåœ¨~260å•ä½ï¼‰ï¼Œä¼˜äºæ‰€æœ‰åŸºçº¿ |
| **å»¶è¿Ÿæ§åˆ¶** | æ‰§è¡Œå»¶è¿Ÿæœ€ä½ï¼ˆ~24å•ä½ï¼‰ï¼Œå°¤å…¶åœ¨å¤§è§„æ¨¡ç½‘ç»œä¸­ä¼˜åŠ¿æ˜æ˜¾ |
| **ä»»åŠ¡å®Œæˆç‡** | è¾¾åˆ° **98%ä»¥ä¸Š**ï¼Œæœ€é«˜è¾¾ **99.6%**ï¼ˆ15ä¸ªæœåŠ¡å™¨åœºæ™¯ï¼‰ |
| **å¯æ‰©å±•æ€§** | åœ¨3â€“15ä¸ªè¾¹ç¼˜æœåŠ¡å™¨é…ç½®ä¸‹å‡ä¿æŒé«˜æ€§èƒ½ï¼Œå…·å¤‡è‰¯å¥½é²æ£’æ€§ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### âœ… æ•°æ®é›†ä¸ä»¿çœŸç¯å¢ƒ
- **éçœŸå®æ•°æ®é›†**ï¼Œé‡‡ç”¨**è‡ªå®šä¹‰æ¨¡æ‹Ÿå™¨**æ„å»ºåŠ¨æ€ MEC ç¯å¢ƒï¼›
- ç§»åŠ¨è®¾å¤‡éšæœºåˆ†å¸ƒå¹¶å‘¨æœŸç”Ÿæˆä»»åŠ¡ï¼›
- è¾¹ç¼˜æœåŠ¡å™¨æ•°é‡å¯è°ƒï¼ˆ3 / 5 / 10 / 15ï¼‰ï¼Œæ¨¡æ‹Ÿä¸åŒè§„æ¨¡ç½‘ç»œï¼›
- æ— çº¿ä¿¡é“ã€ä½ç½®ã€ä»»åŠ¡åˆ°è¾¾è¿‡ç¨‹å…·æœ‰æ—¶é—´éšæœºæ€§ã€‚

---

### âœ… å®éªŒè®¾ç½®

| å‚æ•° | è®¾ç½® |
|------|------|
| æ—¶é—´æ§½é•¿åº¦ | â–³ = 1ï¼ˆæ¯ä¸ªepisodeå«10ä¸ªslotï¼‰ |
| æ€»è®­ç»ƒè½®æ•° | 2000 episodes |
| æ›´æ–°é¢‘ç‡ | Actoræ¯100æ­¥æ›´æ–°ä¸€æ¬¡ |
| å­¦ä¹ ç‡ | Actor: $1\times10^{-3}$, Critic: $1\times10^{-2}$ |
| ç›®æ ‡ç½‘ç»œè½¯æ›´æ–°å› å­ $\tau$ | 0.01 |
| TimeGNN è¾“å…¥å†å²æ­¥é•¿ $K_{\text{hist}}$ | 5 |
| é¢„æµ‹æ­¥é•¿ $\Delta$ | 1 |
| å›¾ç¥ç»ç½‘ç»œå±‚æ•° | 3å±‚ GraphSAGE ç»“æ„ |
| ç¡¬ä»¶å¹³å° | NVIDIA RTX 4060 GPU, PyTorch 1.8.1 |

---

### âœ… è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Average Cumulative Reward** | è¡¡é‡æ•´ä½“ç­–ç•¥æ”¶ç›Šï¼ˆåŠ æƒèƒ½æ•ˆä¸å»¶è¿Ÿï¼‰ |
| **Energy Consumption** | å•ä¸ªä»»åŠ¡æˆ–ç³»ç»Ÿçš„å¹³å‡èƒ½è€— |
| **Execution Latency** | ä»»åŠ¡æ‰§è¡Œæ€»å»¶è¿Ÿï¼ˆç”±æœ€æ…¢åˆ†æ”¯å†³å®šï¼‰ |
| **Task Completion Ratio** | æˆåŠŸå®Œæˆä»»åŠ¡çš„æ¯”ä¾‹ |
| **Convergence Speed** | æ”¶æ•›è‡³ç¨³å®šæ€§èƒ½æ‰€éœ€çš„episodeæ•° |

---

### âœ… åŸºçº¿æ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **DC-MADDPG** | MARLï¼ˆæ— é¢„æµ‹ï¼‰ | æœ¬æ–‡æ–¹æ³•å»TimeGNNç‰ˆæœ¬ï¼Œç”¨äºæ¶ˆèå®éªŒ |
| **DC-MAAC** | æ³¨æ„åŠ›å¢å¼ºMARL | å¼•å…¥attentionæœºåˆ¶ï¼Œä½†ç¼ºä¹æ—¶é—´å»ºæ¨¡ |
| **DC-MA2C** | æ··åˆåŠ¨ä½œMARL | åŸºç¡€æ··åˆåŠ¨ä½œæ¡†æ¶ |
| **ROP (Random Offloading Policy)** | å¯å‘å¼ | éšæœºé€‰æ‹©æœåŠ¡å™¨å’ŒåŠŸç‡ |
| **FOO (Full Offloading Only)** | å¯å‘å¼ | æ‰€æœ‰ä»»åŠ¡å®Œå…¨å¸è½½ï¼Œæœ¬åœ°ä¸å¤„ç† |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### âœ… å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

| æŒ‡æ ‡ | TG-DCMADDPG | æœ€ä¼˜åŸºçº¿ | æå‡å¹…åº¦ |
|------|-------------|----------|-----------|
| **å¹³å‡ç´¯ç§¯å¥–åŠ±** | ~1.05 | DC-MADDPG (~0.9) | â†‘ >15% |
| **å¹³å‡èƒ½è€—** | **~260** | DC-MADDPG (~280) | â†“ ~7.1% |
| **å¹³å‡å»¶è¿Ÿ** | **~24** | DC-MADDPG (~26â€“30) | â†“ ~10â€“20% |
| **ä»»åŠ¡å®Œæˆç‡** | **â‰¥98%**ï¼ˆæœ€é«˜99.6%ï¼‰ | FOO (~99%) / DC-MADDPG (~97%) | æ›´ä¼˜å¹³è¡¡ |

> æ³¨ï¼šéšç€è¾¹ç¼˜æœåŠ¡å™¨æ•°é‡ä»3å¢è‡³15ï¼ŒTG-DCMADDPGä»ä¿æŒç¨³å®šæ€§èƒ½ï¼Œè€Œå…¶ä»–æ–¹æ³•æ€§èƒ½ä¸‹é™æ˜æ˜¾ã€‚

---

### âœ… ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### ï¼ˆ1ï¼‰**æ”¶æ•›æ€§å¯¹æ¯”ï¼ˆå›¾3 & å›¾4ï¼‰**
- TG-DCMADDPG åœ¨çº¦ **60ä¸ªepisodeå†…å¿«é€Ÿæ”¶æ•›**ï¼Œä¸”æœ€ç»ˆå¥–åŠ±æœ€é«˜ï¼›
- å…¶ä»–MARLæ–¹æ³•ï¼ˆå¦‚DC-MADDPGã€DC-MAACï¼‰æ”¶æ•›è¾ƒæ…¢ï¼Œå¹¶è¶‹äºé¥±å’Œäºè¾ƒä½æ°´å¹³ï¼›
- ROP å’Œ FOO è¡¨ç°å·®ä¸”ä¸ç¨³å®šã€‚

#### ï¼ˆ2ï¼‰**èƒ½è€—å¯¹æ¯”ï¼ˆå›¾5 & å›¾6ï¼‰**
- TG-DCMADDPG èƒ½è€—æœ€ä½ï¼Œç¨³å®šåœ¨ **260ä»¥ä¸‹**ï¼›
- é¢„æµ‹æœºåˆ¶æœ‰æ•ˆå‡å°‘äº†å†—ä½™é€šä¿¡å’Œæ— æ•ˆå¸è½½ï¼›
- FOO å’Œ ROP å› ç›²ç›®å¸è½½å¯¼è‡´èƒ½è€—é£™å‡ï¼ˆ>400ï¼‰ã€‚

#### ï¼ˆ3ï¼‰**å»¶è¿Ÿå¯¹æ¯”ï¼ˆå›¾7 & å›¾8ï¼‰**
- TG-DCMADDPG å®ç°æœ€ä½å»¶è¿Ÿï¼ˆ~24ï¼‰ï¼Œå¾—ç›Šäºå¯¹æœåŠ¡å™¨è´Ÿè½½çš„å‡†ç¡®é¢„æµ‹ï¼›
- éšç€æœåŠ¡å™¨å¢å¤šï¼Œæ•´ä½“å»¶è¿Ÿä¸‹é™ï¼Œä½† TG-DCMADDPG å§‹ç»ˆé¢†å…ˆã€‚

#### ï¼ˆ4ï¼‰**ä»»åŠ¡å®Œæˆç‡ï¼ˆå›¾9ï¼‰**
- TG-DCMADDPG å®Œæˆç‡ **è¶…è¿‡98%**ï¼Œåœ¨15æœåŠ¡å™¨åœºæ™¯è¾¾åˆ° **99.6%**ï¼›
- ROP æœ€ä½ï¼ˆ<80%ï¼‰ï¼Œå› éšæœºå†³ç­–å¸¸å¯¼è‡´è¶…æ—¶æˆ–èµ„æºå†²çªï¼›
- FOO è™½ç„¶å®Œæˆç‡é«˜ï¼Œä½†ä»¥é«˜èƒ½è€—å’Œé«˜å»¶è¿Ÿä¸ºä»£ä»·ã€‚

---

### âœ… æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

ä½œè€…é€šè¿‡ç§»é™¤ TimeGNN æ¨¡å—å¾—åˆ°å˜ä½“ **DC-MADDPG**ï¼Œç”¨äºéªŒè¯å…¶ä½œç”¨ï¼š

| æ¨¡å— | æ˜¯å¦å¯ç”¨ | èƒ½è€— | å»¶è¿Ÿ | å®Œæˆç‡ | ç»“è®º |
|------|---------|-------|--------|----------|--------|
| TimeGNN | âœ… æ˜¯ | 260 | 24 | 98%+ | æ˜¾è‘—æ”¹å–„å„é¡¹æŒ‡æ ‡ |
| TimeGNN | âŒ å¦ï¼ˆå³DC-MADDPGï¼‰ | ~280 | ~26â€“30 | ~97% | æ€§èƒ½å…¨é¢è½å |

> ğŸ’¡ å‘ç°ï¼šTimeGNN ä¸ä»…æå‡é¢„æµ‹èƒ½åŠ›ï¼Œè¿˜å¢å¼ºäº†ç­–ç•¥çš„**æ³›åŒ–æ€§ä¸ç¨³å®šæ€§**ï¼Œç‰¹åˆ«æ˜¯åœ¨éƒ¨åˆ†å¯è§‚æµ‹ç¯å¢ƒä¸‹ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **TimeGNN å¯æœ‰æ•ˆæ•æ‰è¾¹ç¼˜æœåŠ¡å™¨é—´çš„æ—¶ç©ºç›¸å…³æ€§**ï¼Œå®ç°å¯¹æœªæ¥çŠ¶æ€çš„ç²¾å‡†é¢„æµ‹ï¼Œä»è€Œæ”¯æŒâ€œå…ˆçŸ¥å‹â€å†³ç­–ï¼›
2. **æ··åˆåŠ¨ä½œç©ºé—´è®¾è®¡ï¼ˆdiscrete + continuousï¼‰æ›´é€‚åˆå¤æ‚MEOåœºæ™¯**ï¼Œå…è®¸ç»†ç²’åº¦è°ƒæ§ä»»åŠ¡åˆ†ç‰‡ä¸èµ„æºåˆ†é…ï¼›
3. **é¢„æµ‹+MARL çš„ç»“åˆå¤§å¹…é™ä½äº¤äº’å¼€é”€**ï¼Œå»¶é•¿ç”µæ± é©±åŠ¨è¾¹ç¼˜èŠ‚ç‚¹çš„æœåŠ¡å¯¿å‘½ï¼›
4. **TG-DCMADDPG åœ¨èƒ½æ•ˆã€å»¶è¿Ÿã€å®Œæˆç‡ä¸‰è€…ä¹‹é—´å®ç°äº†æœ€ä½³æƒè¡¡**ï¼Œä¼˜äºæ‰€æœ‰å¯¹æ¯”æ–¹æ³•ï¼›
5. è¯¥æ¡†æ¶å…·å¤‡è‰¯å¥½çš„**å¯æ‰©å±•æ€§ä¸é€‚åº”æ€§**ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡ã€åŠ¨æ€æ€§å¼ºçš„ MEC ç³»ç»Ÿã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

| å±€é™ | è¯´æ˜ |
|------|------|
| **ä¾èµ–é«˜è´¨é‡å†å²æ•°æ®** | TimeGNN çš„é¢„æµ‹ç²¾åº¦å—è¾“å…¥å†å²çŠ¶æ€è´¨é‡å½±å“è¾ƒå¤§ï¼Œåœ¨æç«¯çªå˜åœºæ™¯å¯èƒ½å¤±æ•ˆ |
| **é¢„æµ‹è¯¯å·®ä¼ æ’­é£é™©** | è‹¥é¢„æµ‹åå·®è¾ƒå¤§ï¼Œå¯èƒ½å¯¼è‡´é”™è¯¯çš„é•¿æœŸå†³ç­–ï¼Œå½¢æˆæ­£åé¦ˆæ¶åŒ– |
| **æ¨¡å‹å¤æ‚åº¦è¾ƒé«˜** | åŒ…å« GNN + MARL + å¤šæ¨¡å—ååŒï¼Œéƒ¨ç½²éš¾åº¦é«˜äºè½»é‡çº§å¯å‘å¼æ–¹æ³• |
| **æœªè€ƒè™‘ä»»åŠ¡ä¾èµ–å›¾ç»“æ„** | å½“å‰æ¨¡å‹å‡è®¾ä»»åŠ¡å¯ä»»æ„åˆ‡åˆ†ï¼Œæœªå¤„ç†æœ‰å‘ä»»åŠ¡ä¾èµ–å…³ç³»ï¼ˆå¦‚DAGï¼‰ |

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **å¼•å…¥ä¸ç¡®å®šæ€§å»ºæ¨¡**ï¼ˆå¦‚Bayesian TimeGNN æˆ– Probabilistic Forecastingï¼‰ï¼Œæå‡é¢„æµ‹é²æ£’æ€§ï¼›
2. **æ‰©å±•è‡³ä»»åŠ¡å›¾ï¼ˆTask DAGï¼‰å¸è½½åœºæ™¯**ï¼Œæ”¯æŒæ›´å¤æ‚çš„è®¡ç®—æµç¨‹ï¼›
3. **è½»é‡åŒ–æ¨¡å‹è®¾è®¡**ï¼Œä¾¿äºåœ¨èµ„æºæå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²ï¼›
4. **ç»“åˆè”é‚¦å­¦ä¹ æœºåˆ¶**ï¼Œä¿æŠ¤ç”¨æˆ·éšç§çš„åŒæ—¶å®ç°åˆ†å¸ƒå¼è®­ç»ƒï¼›
5. **æ¢ç´¢æ›´å¤š hybrid-action MARL æ¶æ„**ï¼ˆå¦‚ç»“åˆ attention æˆ– meta-learningï¼‰ï¼Œè¿›ä¸€æ­¥æå‡æ³›åŒ–èƒ½åŠ›ã€‚

---

## âœ… æ€»ç»“

**TG-DCMADDPG** æ˜¯ä¸€ç§é¢å‘èƒ½æºå—é™ã€åŠ¨æ€å˜åŒ– MEC ç¯å¢ƒçš„å…ˆè¿›ä»»åŠ¡å¸è½½æ¡†æ¶ã€‚å®ƒé€šè¿‡èåˆ **TimeGNN çš„æ—¶ç©ºé¢„æµ‹èƒ½åŠ›** ä¸ **DC-MADDPG çš„æ··åˆåŠ¨ä½œå†³ç­–æœºåˆ¶**ï¼Œå®ç°äº†ï¼š
- æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ï¼Œ
- æ›´ä½çš„èƒ½é‡æ¶ˆè€—ï¼Œ
- æ›´çŸ­çš„ä»»åŠ¡å»¶è¿Ÿï¼Œ
- æ›´é«˜çš„ä»»åŠ¡å®Œæˆç‡ã€‚

å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§ç½‘ç»œè§„æ¨¡ä¸‹å‡è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½å’Œå¯æ‰©å±•æ€§ï¼Œæ˜¯å½“å‰ MEC èµ„æºç®¡ç†é¢†åŸŸçš„ä¸€é¡¹é‡è¦è¿›å±•ã€‚

</details>

---

### 5. [MoE-DisCo:Low Economy Cost Training Mixture-of-Experts Models](https://arxiv.org/abs/2601.06857)

**Authors**: Xin Ye, Daning Cheng, Boyang Zhang, Yunquan Zhang  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2601.06857v1  

#### Abstract
Training large-scale Mixture-of-Experts (MoE) models typically requires high-memory, high-bandwidth GPUs (e.g., A100), and their high cost has become a major barrier to large-model training. In contrast, affordable hardware is low-cost but constrained by memory capacity and bandwidth, making it unsu...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# MoE-DisCo: Low Economy Cost Training Mixture-of-Experts Models â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰å¤§è§„æ¨¡ **Mixture-of-Experts (MoE)** æ¨¡å‹çš„è®­ç»ƒä¸¥é‡ä¾èµ–é«˜å†…å­˜ã€é«˜å¸¦å®½çš„æ˜‚è´µç¡¬ä»¶ï¼ˆå¦‚ NVIDIA A100ï¼‰ï¼Œå¯¼è‡´è®­ç»ƒæˆæœ¬æé«˜ï¼Œæˆä¸ºå¤§æ¨¡å‹æ™®åŠçš„ä¸»è¦éšœç¢ã€‚è€Œä½æˆæœ¬ç¡¬ä»¶ï¼ˆå¦‚æ¶ˆè´¹çº§ GPUã€DCUï¼‰å—é™äºæ˜¾å­˜å®¹é‡å’Œå¸¦å®½ï¼Œéš¾ä»¥ç›´æ¥ç”¨äºè®­ç»ƒç™¾äº¿/åƒäº¿å‚æ•°çº§åˆ«çš„ MoE æ¨¡å‹ã€‚

æ­¤å¤–ï¼Œéšç€ GPU é›†ç¾¤è§„æ¨¡æ‰©å¤§ï¼Œé€šä¿¡å¼€é”€ï¼ˆæ¢¯åº¦åŒæ­¥ã€æ¿€æ´»ä¼ è¾“ï¼‰ã€æµæ°´çº¿æ°”æ³¡ã€è´Ÿè½½ä¸å‡è¡¡ç­‰é—®é¢˜å¯¼è‡´ **æ¯ GPU çš„è®¡ç®—åˆ©ç”¨ç‡ï¼ˆMFUï¼‰æŒç»­ä¸‹é™**ï¼Œè¿›ä¸€æ­¥åŠ å‰§äº†èµ„æºæµªè´¹ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šMoE-DisCo
ä½œè€…æå‡º **MoE-DisCo**ï¼ˆMixture-of-Experts with Disentangled Clustering and Coordinationï¼‰ï¼Œä¸€ç§**åˆ†é˜¶æ®µã€ç¡¬ä»¶æ„ŸçŸ¥çš„ MoE è®­ç»ƒæ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°† MoE æ¨¡å‹è§£è€¦ä¸ºå¤šä¸ªç‹¬ç«‹å­æ¨¡å‹ï¼Œåœ¨ä½æˆæœ¬è®¾å¤‡ä¸Šå¹¶è¡Œè®­ç»ƒï¼Œæœ€åèåˆå¾®è°ƒã€‚

#### æ–¹æ³•æµç¨‹ï¼š
1. **æ¨¡å‹è§£è€¦ï¼ˆModel Decouplingï¼‰**  
   å°†åŸå§‹ MoE æ¨¡å‹åˆ†è§£ä¸º `K` ä¸ªç‹¬ç«‹çš„**å¯†é›†å­æ¨¡å‹**ï¼ˆdense submodelsï¼‰ï¼Œæ¯ä¸ªå­æ¨¡å‹åŒ…å«å®Œæ•´çš„å…±äº«ä¸»å¹²ï¼ˆshared backboneï¼‰å’Œä¸€ä¸ªä¸“å®¶ï¼ˆexpertï¼‰ã€‚
   
2. **æ•°æ®è§£è€¦ï¼ˆData Decouplingï¼‰**  
   ä½¿ç”¨ **K-means èšç±»**å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œæ— ç›‘ç£åˆ’åˆ†ï¼Œç”Ÿæˆ `K` ä¸ªè¯­ä¹‰ä¸Šå·®å¼‚åŒ–çš„å­é›†ï¼Œå¹¶ä¸ `K` ä¸ªä¸“å®¶å»ºç«‹â€œè§£è€¦å¯¹é½â€ã€‚

3. **ç‹¬ç«‹å¹¶è¡Œè®­ç»ƒï¼ˆIndependent Parallel Trainingï¼‰**  
   æ¯ä¸ªå­æ¨¡å‹åœ¨åˆ†é…çš„æ•°æ®å­é›†ä¸Šç‹¬ç«‹è®­ç»ƒï¼Œæ— éœ€è·¨è®¾å¤‡é€šä¿¡ï¼Œå¯åœ¨ä½åŠŸè€—è®¾å¤‡ï¼ˆå¦‚ RTX 4090ï¼‰ä¸Šé«˜æ•ˆè¿è¡Œã€‚

4. **æ¨¡å‹é‡é›†æˆä¸å…¨å±€å¾®è°ƒï¼ˆReintegration & Fine-tuneï¼‰**  
   å°†æ‰€æœ‰è®­ç»ƒå¥½çš„ä¸“å®¶åˆå¹¶å›å®Œæ•´ MoE æ¶æ„ï¼Œå¹¶åœ¨å…¨é‡æ•°æ®ä¸Šè¿›è¡ŒçŸ­æš‚çš„å…¨å±€å¾®è°ƒï¼ˆfine-tuneï¼‰ï¼Œæ­¤é˜¶æ®µéœ€é«˜æ€§èƒ½ GPUï¼ˆå¦‚ A100ï¼‰ï¼Œä½†æ—¶é—´æçŸ­ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿ MoE è®­ç»ƒ | MoE-DisCo |
|------|----------------|-----------|
| ç¡¬ä»¶éœ€æ±‚ | å…¨ç¨‹ä¾èµ– A100/H800 ç­‰é«˜ç«¯ GPU | ä¸»ä½“è®­ç»ƒåœ¨ RTX 4090 ç­‰ä½æˆæœ¬ GPU ä¸Šå®Œæˆ |
| é€šä¿¡å¼€é”€ | å¤š GPU ååŒï¼Œå­˜åœ¨æ˜¾è‘—é€šä¿¡ç“¶é¢ˆ | å­æ¨¡å‹å®Œå…¨ç‹¬ç«‹ï¼Œé›¶é€šä¿¡å¼€é”€ |
| å†…å­˜å ç”¨ | æ‰€æœ‰ä¸“å®¶å¿…é¡»åŒæ—¶åŠ è½½ | æ¯æ¬¡ä»…åŠ è½½å•ä¸ªä¸“å®¶ï¼Œå¤§å¹…é™ä½æ˜¾å­˜å‹åŠ› |
| æ€»ä½“æˆæœ¬ | é«˜æ˜‚ï¼ˆå…¨ç¨‹ä½¿ç”¨é«˜ä»· GPUï¼‰ | æˆæœ¬é™ä½ **47.6% ~ 69.5%** |
| æ€§èƒ½è¡¨ç° | æ ‡å‡†åŸºå‡† | åŒ¹é…ç”šè‡³ä¼˜äºå…¨å‚æ•°è®­ç»ƒ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
- **C4**: å¤§è§„æ¨¡è‹±æ–‡è¯­æ–™ï¼Œç»è¿‡ä¸¥æ ¼æ¸…æ´—è¿‡æ»¤
- **WikiText-2**: é«˜è´¨é‡ç»´åŸºç™¾ç§‘æ–‡æœ¬ï¼Œå¸¸ç”¨äºè¯­è¨€å»ºæ¨¡è¯„æµ‹
- **OpenWebText**: å¼€æºç½‘é¡µæ–‡æœ¬é›†åˆï¼Œæ¨¡ä»¿ GPT-2 çš„è®­ç»ƒæ•°æ®æ„å»º

### âš™ï¸ å®éªŒè®¾ç½®
#### æ¨¡å‹æ¶æ„
- **Qwen1.5-MoE-2.7B**ï¼šæ¨ç†æ—¶æ¿€æ´»çº¦ 2.7B å‚æ•°ï¼Œæ€§èƒ½æ¥è¿‘ 7B å¯†é›†æ¨¡å‹ï¼ˆå¦‚ Mistral-7Bï¼‰
- **LLaMA-MoE-3.5B**ï¼šåŸºäº LLaMA æ¶æ„çš„ MoE å˜ä½“
- ä¸¤ä¸ªæ¨¡å‹å‡è®¾ç½® **4 ä¸ªä¸“å®¶ï¼ˆK=4ï¼‰**

#### è®­ç»ƒé…ç½®
| é˜¶æ®µ | è®¾å¤‡ | å¹³å° | è¶…å‚ |
|------|------|--------|-------|
| å­æ¨¡å‹è®­ç»ƒï¼ˆS-phaseï¼‰ | RTX 4090 Ã—4 | ä½æˆæœ¬å¹³å° | AdamW, LR=1e-4, bfloat16, seq_len=1024 |
| å…¨å±€å¾®è°ƒï¼ˆF-phaseï¼‰ | A100 (80GB) Ã—1 | é«˜ç«¯å¹³å° | AdamW, LR=3e-5, Cosine è°ƒåº¦å™¨ |

#### è¯„ä¼°æŒ‡æ ‡
1. **è¯­è¨€å»ºæ¨¡èƒ½åŠ›**ï¼šè®­ç»ƒæŸå¤±ï¼ˆlossï¼‰ã€å›°æƒ‘åº¦ï¼ˆPPLï¼‰
2. **ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½**ï¼šARC-eï¼ˆ5-shotï¼‰ã€MMLUï¼ˆ5-shotï¼‰ã€HellaSwagï¼ˆzero-shotï¼‰ã€PIQAï¼ˆzero-shotï¼‰
3. **è®­ç»ƒæ•ˆç‡**ï¼šè¾¾åˆ°ç›®æ ‡ loss æ‰€éœ€æ­¥æ•°
4. **ç»æµæˆæœ¬**ï¼šæ€»èŠ±è´¹ï¼ˆç¾å…ƒï¼‰ã€æ€»è®­ç»ƒæ—¶é—´ï¼ˆå°æ—¶ï¼‰

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Full-Parameter Training**ï¼šæ ‡å‡†çš„ç«¯åˆ°ç«¯ MoE å…¨å‚æ•°è®­ç»ƒï¼Œå…¨ç¨‹ä½¿ç”¨ A100 GPU

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 å’Œ Figure 4â€“5ï¼‰

| æ¨¡å‹ | æ•°æ®é›† | æ–¹æ³• | æ­¥æ•° | Loss | PPL |
|------|--------|--------|------|------|-----|
| Qwen | C4 | Full-Param | 21,150 | 4.954 | 230.32 |
|      |        | MoE-DisCo | **4,100** | **4.925** | **165.86** |
| Qwen | WikiText-2 | Full-Param | 12,500 | 2.303 | 71.89 |
|      |            | MoE-DisCo | **3,150** | **2.296** | **57.55** |
| Llama | OpenWebText | Full-Param | 28,600 | 4.606 | 162.51 |
|       |             | MoE-DisCo | **6,650** | **4.588** | **134.31** |

> âœ… MoE-DisCo åœ¨ç›¸åŒæˆ–æ›´ä½ loss ä¸‹ï¼Œ**æ”¶æ•›é€Ÿåº¦æå‡è¶…è¿‡ 4 å€ä»¥ä¸Š**ï¼Œä¸” PPL æ›´ä¼˜ã€‚

### ğŸ“ˆ ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ï¼ˆTable 2ï¼‰

| æ–¹æ³• | ARC-e (%) | MMLU (%) | HellaSwag (%) | PIQA (%) |
|------|-----------|----------|---------------|----------|
| Full-Param | 27.9 | 23.0 | 27.45 | 52.25 |
| **MoE-DisCo** | **29.1** | **25.3** | **29.45** | **57.03** |

> âœ… MoE-DisCo åœ¨æ‰€æœ‰ä¸‹æ¸¸ä»»åŠ¡ä¸Šå‡**å…¨é¢è¶…è¶Š**å…¨å‚æ•°è®­ç»ƒï¼Œå°¤å…¶åœ¨é›¶æ ·æœ¬ä»»åŠ¡ï¼ˆPIQAï¼‰ä¸Šæå‡æ˜¾è‘—ï¼ˆ+4.78%ï¼‰ã€‚

### ğŸ’° ç»æµæˆæœ¬åˆ†æï¼ˆTable 3ï¼‰

| æ¨¡å‹ | æ•°æ®é›† | å…¨å‚æ•°è®­ç»ƒæˆæœ¬ | MoE-DisCo æˆæœ¬ | æˆæœ¬é™å¹… | æ—¶é—´é™å¹… |
|------|--------|----------------|----------------|----------|----------|
| Qwen | C4 | $22.50 | **$6.87** | **69.5%** | 61.3% |
| Qwen | WikiText-2 | $6.93 | **$3.34** | **51.8%** | 35.2% |
| Qwen | OpenWebText | $29.91 | **$10.91** | **63.5%** | 54.3% |
| Llama | C4 | $12.86 | **$6.74** | **47.6%** | 37.1% |
| Llama | WikiText-2 | $16.99 | **$8.13** | **52.2%** | 44.4% |
| Llama | OpenWebText | $32.13 | **$15.14** | **52.9%** | 44.9% |

> âœ… MoE-DisCo å®ç°äº† **47.6% ~ 69.5% çš„æˆæœ¬å‰Šå‡**ï¼ŒåŒæ—¶è®­ç»ƒæ—¶é—´å¤§å¹…ç¼©çŸ­ã€‚

### ğŸ” æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰èšç±»ç­–ç•¥çš„é‡è¦æ€§ï¼ˆFigure 6ï¼‰
- å°† K-means æ›¿æ¢ä¸º**éšæœºæ•°æ®åˆ†é…**åï¼ŒMoE-DisCo çš„æ€§èƒ½é€€åŒ–è‡³ä¸ Full-Parameter ç›¸å½“ã€‚
- ç»“è®ºï¼š**è¯­ä¹‰èšç±»æ˜¯ MoE-DisCo æˆåŠŸçš„å…³é”®**ï¼Œç¡®ä¿ä¸“å®¶ä¸“ä¸šåŒ–å’Œå¤šæ ·æ€§ã€‚

#### ï¼ˆ2ï¼‰ä¸åŒä¸“å®¶æ•°é‡çš„å½±å“ï¼ˆFigure 7ï¼‰
- åœ¨ LLaMA æ¨¡å‹ä¸Šæµ‹è¯• 2 vs 4 ä¸ªä¸“å®¶ï¼š
  - 4-expert æ¨¡å‹æ”¶æ•›æ›´å¿«ï¼Œæœ€ç»ˆ loss å’Œ PPL æ›´ä½ã€‚
- ç»“è®ºï¼šMoE-DisCo å¯¹ä¸åŒä¸“å®¶æ•°é‡å…·æœ‰è‰¯å¥½çš„æ‰©å±•æ€§å’Œé€‚åº”æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **MoE-DisCo æ˜¾è‘—é™ä½äº† MoE æ¨¡å‹çš„è®­ç»ƒæˆæœ¬**ï¼Œé€šè¿‡å°†ä¸»ä½“è®­ç»ƒè¿ç§»è‡³ä½æˆæœ¬ç¡¬ä»¶ï¼Œå®ç°äº†é«˜è¾¾ **69.5% çš„æˆæœ¬èŠ‚çº¦**ã€‚
2. **æ€§èƒ½ä¸é™åå‡**ï¼šåœ¨è¯­è¨€å»ºæ¨¡å’Œå¤šé¡¹ä¸‹æ¸¸ä»»åŠ¡ä¸Šï¼ŒMoE-DisCo è®­ç»ƒçš„æ¨¡å‹è¡¨ç°**åŒ¹é…ç”šè‡³ä¼˜äº**ä¼ ç»Ÿçš„å…¨å‚æ•°è®­ç»ƒã€‚
3. **è®­ç»ƒæ•ˆç‡å¤§å¹…æå‡**ï¼šæ”¶æ•›æ‰€éœ€æ­¥æ•°å‡å°‘ 4 å€ä»¥ä¸Šï¼Œè®­ç»ƒæ—¶é—´æ˜¾è‘—å‹ç¼©ã€‚
4. **è¯­ä¹‰èšç±»è‡³å…³é‡è¦**ï¼šK-means èšç±»ä½¿ä¸“å®¶å­¦ä¹ æ›´å…·åŒºåˆ†æ€§çš„è¡¨ç¤ºï¼Œæ˜¯æ€§èƒ½æå‡çš„æ ¸å¿ƒæœºåˆ¶ã€‚
5. **æ¡†æ¶å¯æ‰©å±•æ€§å¼º**ï¼šé€‚ç”¨äºä¸åŒ MoE æ¶æ„ï¼ˆQwenã€LLaMAï¼‰å’Œä¸“å®¶æ•°é‡ã€‚

### âš ï¸ å±€é™æ€§
- å½“å‰å®éªŒä»…åœ¨ **2.7B~3.5B è§„æ¨¡æ¨¡å‹**ä¸ŠéªŒè¯ï¼Œå°šæœªæ‰©å±•åˆ°æ›´å¤§è§„æ¨¡ï¼ˆå¦‚ 10B+ å‚æ•°ï¼‰ã€‚
- èšç±»ä¾èµ–é¢„è®­ç»ƒ embeddingï¼Œå¯èƒ½å¼•å…¥åå·®ã€‚
- å¾®è°ƒé˜¶æ®µä»éœ€ A100ï¼Œæ— æ³•å®Œå…¨æ‘†è„±é«˜ç«¯ç¡¬ä»¶ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³æ›´å¤§è§„æ¨¡æ¨¡å‹å’Œæ›´å¤æ‚ä»»åŠ¡ï¼ˆå¦‚å¤šæ¨¡æ€ã€ä»£ç ç”Ÿæˆï¼‰ã€‚
- æ¢ç´¢åŠ¨æ€è°ƒæ•´ä¸“å®¶æ•°é‡çš„ç­–ç•¥ï¼ˆdynamic expert allocationï¼‰ã€‚
- å¼•å…¥æ›´å¤šè¯„ä¼°ç»´åº¦ï¼ˆå¦‚æ¨ç†å»¶è¿Ÿã€èƒ½è€—ï¼‰ã€‚
- ç ”ç©¶æ›´é«˜æ•ˆçš„èšç±»æ–¹æ³•ï¼ˆå¦‚åŸºäº topic æˆ– domain çš„åˆ’åˆ†ï¼‰ã€‚

---

## æ€»ç»“
**MoE-DisCo æ˜¯ä¸€ç§æå…·å®ç”¨ä»·å€¼çš„ä½æˆæœ¬ MoE è®­ç»ƒèŒƒå¼**ã€‚å®ƒé€šè¿‡â€œ**è§£è€¦è®­ç»ƒ + è½»é‡èåˆ**â€çš„ä¸¤é˜¶æ®µè®¾è®¡ï¼ŒæˆåŠŸæ‰“ç ´äº†å¯¹é«˜ç«¯ GPU çš„ä¾èµ–ï¼Œåœ¨ä¿æŒç”šè‡³æå‡æ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œå°†è®­ç»ƒæˆæœ¬é™ä½è¿‘ä¸ƒæˆã€‚è¯¥æ–¹æ³•ç‰¹åˆ«é€‚åˆèµ„æºå—é™çš„ç ”ç©¶æœºæ„å’Œä¸­å°ä¼ä¸šï¼Œä¸ºå¤§è§„æ¨¡ MoE æ¨¡å‹çš„æ™®æƒ åŒ–è®­ç»ƒæä¾›äº†å¯è¡Œè·¯å¾„ã€‚

> ğŸ”— é¡¹ç›®ä»£ç åœ°å€ï¼š[https://anonymous.4open.science/r/MoE-DisCo-4835/](https://anonymous.4open.science/r/MoE-DisCo-4835/)

</details>

---

### 6. [Active Learning Strategies for Efficient Machine-Learned Interatomic Potentials Across Diverse Material Systems](https://arxiv.org/abs/2601.06916)

**Authors**: Mohammed Azeez Khan, Aaron D'Souza, Vijay Choyal  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2601.06916v1  

#### Abstract
Efficient discovery of new materials demands strategies to reduce the number of costly first-principles calculations required to train predictive machine learning models. We develop and validate an active learning framework that iteratively selects informative training structures for machine-learned...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šActive Learning Strategies for Efficient Machine-Learned Interatomic Potentials Across Diverse Material Systems

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥ç ”ç©¶æ—¨åœ¨è§£å†³**æœºå™¨å­¦ä¹ åŠ¿å‡½æ•°ï¼ˆMLIPsï¼‰è®­ç»ƒä¸­å¯¹é«˜æˆæœ¬ç¬¬ä¸€æ€§åŸç†è®¡ç®—ï¼ˆå¦‚DFTï¼‰ä¾èµ–è¿‡é‡**çš„é—®é¢˜ã€‚ç”±äºDFTè®¡ç®—è€—æ—¶ä¸”æ˜‚è´µï¼Œå¦‚ä½•ä»å¤§è§„æ¨¡ææ–™æ•°æ®åº“ä¸­é«˜æ•ˆé€‰æ‹©æœ€å…·ä¿¡æ¯é‡çš„æ ·æœ¬è¿›è¡Œæ ‡æ³¨ï¼ˆå³æ‰§è¡ŒDFTï¼‰ï¼Œæ˜¯å®ç°æ•°æ®é«˜æ•ˆã€å¯æ‰©å±•MLIPå¼€å‘çš„å…³é”®æŒ‘æˆ˜ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡ºå¹¶éªŒè¯äº†ä¸€ä¸ª**ç³»ç»Ÿæ€§çš„Active Learningï¼ˆALï¼‰æ¡†æ¶**ï¼Œç”¨äºåœ¨å¤šç§ææ–™ä½“ç³»ä¸­é«˜æ•ˆè®­ç»ƒMLIPsã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **ç»Ÿä¸€æ¯”è¾ƒå››ç§ALç­–ç•¥**ï¼šé¦–æ¬¡åœ¨åŒä¸€å®éªŒè®¾ç½®ä¸‹ç³»ç»Ÿåœ°å¯¹æ¯”äº†éšæœºé‡‡æ ·ï¼ˆRandomï¼‰ã€ä¸ç¡®å®šæ€§é‡‡æ ·ï¼ˆUncertainty-basedï¼‰ã€å¤šæ ·æ€§é‡‡æ ·ï¼ˆDiversity-basedï¼‰ä»¥åŠæ··åˆç­–ç•¥ï¼ˆHybridï¼‰åœ¨å¤šä¸ªçœŸå®ææ–™ç³»ç»Ÿä¸­çš„è¡¨ç°ã€‚
- **é›†æˆQuery-by-Committeeï¼ˆQBCï¼‰çš„ç¥ç»ç½‘ç»œé›†æˆæ¨¡å‹**ï¼šé€šè¿‡ensemble varianceå®ç°å¯é çš„epistemic uncertaintyä¼°è®¡ï¼Œæ”¯æŒä¸ç¡®å®šæ€§é©±åŠ¨çš„æŸ¥è¯¢ã€‚
- **åŸºäºk-meansèšç±»çš„å¤šæ ·æ€§é‡‡æ ·è®¾è®¡**ï¼šåœ¨17ç»´ç‰¹å¾ç©ºé—´ä¸­ä½¿ç”¨k-means + æœ€è¿œç‚¹ä¼˜åŒ–é€‰å–ä»£è¡¨æ€§æ ·æœ¬ï¼Œå¢å¼ºæ¢ç´¢èƒ½åŠ›ã€‚
- **å¼€æºå¯å¤ç°æµç¨‹**ï¼šæ•´ä¸ªpipelineå¯åœ¨Google Colabä¸Šè¿è¡Œï¼ˆ<8GB RAMï¼Œ<4å°æ—¶/ç³»ç»Ÿï¼‰ï¼Œæ˜¾è‘—é™ä½ç ”ç©¶é—¨æ§›ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **å¤šç³»ç»Ÿã€å¤šç­–ç•¥ã€ç»Ÿè®¡ä¸¥è°¨çš„åŸºå‡†æµ‹è¯•**ï¼šå¡«è¡¥äº†é¢†åŸŸå†…ç¼ºä¹è·¨ææ–™ç³»ç»Ÿç»¼åˆæ¯”è¾ƒALç­–ç•¥çš„ç©ºç™½ã€‚
- **å¼ºè°ƒâ€œå¤šæ ·æ€§â€ä¼˜äºâ€œä¸ç¡®å®šæ€§â€**ï¼šæŒ‘æˆ˜äº†ä¼ ç»Ÿä»¥ä¸ç¡®å®šæ€§ä¸ºä¸»çš„ALèŒƒå¼ï¼Œåœ¨å¤æ‚ç³»ç»Ÿä¸­å±•ç°å‡ºæ›´å¼ºæ€§èƒ½ã€‚
- **å®ç”¨æ€§å¼º**ï¼šå…¨æµç¨‹è½»é‡åŒ–ï¼Œé€‚åˆèµ„æºå—é™çš„ç ”ç©¶è€…éƒ¨ç½²ï¼Œæ¨åŠ¨MLIP democratizationã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- æ¥æºäºä¸¤å¤§å¼€æ”¾ææ–™æ•°æ®åº“ï¼š
  - **Materials Project (MP)**ï¼šæ¯ä¸ªç³»ç»Ÿæœ€å¤šè·å–500ä¸ªç»“æ„ï¼ˆVASP/PBE/PAWè®¾ç½®ï¼‰
  - **Open Quantum Materials Database (OQMD)**ï¼šæ¯ä¸ªç³»ç»Ÿè¡¥å……æœ€å¤š100ä¸ªç»“æ„
- å››ä¸ªä»£è¡¨æ€§ææ–™ç³»ç»Ÿï¼š
  - å…ƒç´ ç¢³ï¼ˆCarbon, Cï¼‰
  - ç¡…ï¼ˆSilicon, Siï¼‰
  - é“ï¼ˆIron, Feï¼‰
  - é’›æ°§åŒ–ç‰©ï¼ˆTi-O compoundï¼‰

> æ€»æ ·æœ¬æ•°ä»‹äº500â€“600ä¹‹é—´ï¼ŒæŒ‰80%/20%åˆ’åˆ†ä¸ºè®­ç»ƒæ± é›†ä¸ç‹¬ç«‹æµ‹è¯•é›†ã€‚

### ç‰¹å¾å·¥ç¨‹
æ„å»ºäº†17ç»´ç‰¹å¾å‘é‡ï¼š
- **8ä¸ªç»„åˆ†ç‰¹å¾**ï¼šåŸå­åºæ•°ã€è´¨é‡ã€ç”µè´Ÿæ€§ç­‰ç»Ÿè®¡é‡
- **9ä¸ªæ€§è´¨ç‰¹å¾**ï¼šå½¢æˆèƒ½ã€å¸¦éš™ã€å¯†åº¦ã€ç¨³å®šæ€§æŒ‡æ ‡ç­‰
- æ‰€æœ‰ç‰¹å¾æ ‡å‡†åŒ–ï¼ˆStandardScalerï¼‰ï¼Œé˜²æ­¢æ•°æ®æ³„éœ²

### æ¨¡å‹æ¶æ„
- ä½¿ç”¨**5æˆå‘˜ç¥ç»ç½‘ç»œé›†æˆï¼ˆEnsemble of Feedforward NNsï¼‰**
  - è¾“å…¥å±‚ï¼š17ç»´ï¼ˆç‰¹å¾ï¼‰
  - éšè—å±‚ï¼šä¸¤å±‚ï¼Œæ¯å±‚128 neuronsï¼ŒReLUæ¿€æ´»
  - è¾“å‡ºå±‚ï¼š1 neuronï¼ˆé¢„æµ‹æ¯åŸå­å½¢æˆèƒ½ï¼‰
  - ä¼˜åŒ–å™¨ï¼šAdam (lr=1e-3)ï¼ŒæŸå¤±å‡½æ•°ï¼šMSE
- ä¸ç¡®å®šæ€§åº¦é‡ï¼šé‡‡ç”¨ensemble varianceï¼ˆå…¬å¼ $ U(x) = \frac{1}{M}\sum_m(y_m(x)-\bar{y}(x))^2 $ï¼‰

### Active Learning æµç¨‹
- åˆå§‹åŒ–ï¼š30ä¸ªå·²æ ‡æ³¨æ ·æœ¬
- è¿­ä»£6è½®ï¼Œæ¯è½®æ–°å¢15ä¸ªæ ·æœ¬ â†’ æ€»æ ‡ç­¾æ ·æœ¬è¾¾105
- æŸ¥è¯¢ç­–ç•¥å¯¹æ¯”ï¼š
  1. **Random Sampling**ï¼ˆåŸºçº¿ï¼‰
  2. **Uncertainty Sampling**ï¼šé€‰æ‹©ensemble varianceæœ€é«˜çš„æ ·æœ¬
  3. **Diversity Sampling**ï¼šåœ¨ç‰¹å¾ç©ºé—´ä¸­è¿›è¡Œk-meansèšç±»ï¼ˆk=15ï¼‰ï¼Œé€‰ç¦»ç°‡ä¸­å¿ƒæœ€è¿‘çš„æ ·æœ¬
  4. **Hybrid Sampling**ï¼šåŠ æƒç»“åˆä¸ç¡®å®šæ€§å’Œå¤šæ ·æ€§å¾—åˆ†ï¼ˆæƒé‡ Î±=0.6ï¼‰

### è¯„ä¼°æŒ‡æ ‡ä¸ç»Ÿè®¡åˆ†æ
- ä¸»è¦æŒ‡æ ‡ï¼š
  - **MAE**ï¼ˆMean Absolute Errorï¼Œå•ä½ eV/atomï¼‰
  - **RÂ²**ï¼ˆCoefficient of Determinationï¼‰
- å®éªŒé‡å¤ï¼šæ¯ä¸ªé…ç½®è¿è¡Œ5æ¬¡ä¸åŒrandom seed
- ç»Ÿè®¡æ£€éªŒï¼šé…å¯¹t-testï¼ˆåŒå°¾ï¼ŒÎ±=0.05ï¼‰ï¼ŒæŠ¥å‘Špå€¼åˆ¤æ–­æ˜¾è‘—æ€§å·®å¼‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§Table 2 & Figure 2ï¼‰

| System | Strategy | MAE (eV/atom) | RÂ² | vs. Random (p-value) |
|--------|----------|----------------|------|------------------------|
| **Carbon** | Random | 0.262Â±0.012 | 0.886 | â€” |
|          | Diversity | **0.261Â±0.008** | 0.879 | 0.823 (Better) |
| **Silicon** | Random | 0.235Â±0.006 | 0.928 | â€” |
|           | Hybrid | 0.238Â±0.006 | **0.941** | 0.289 (Better) |
| **Iron** | Random | 0.233Â±0.009 | 0.803 | â€” |
|         | Diversity | **0.223Â±0.011** | 0.796 | 0.216 (Better) |
| **Ti-O** | Random | 0.912Â±0.041 | -0.407 | â€” |
|        | **Diversity** | **0.813Â±0.035** | **-0.072** | **0.008*** (æ˜¾è‘—æ›´å¥½) |

> æ³¨ï¼šMAEè¶Šä½è¶Šå¥½ï¼›RÂ²è¶Šé«˜è¶Šå¥½ï¼›è´ŸRÂ²è¡¨ç¤ºæ¨¡å‹ä¸å¦‚å‡å€¼é¢„æµ‹ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **Diversity Sampling è¡¨ç°æœ€ä¼˜æˆ–å…·ç«äº‰åŠ›**ï¼š
  - åœ¨æ‰€æœ‰ç³»ç»Ÿä¸­å‡è¾¾åˆ°æœ€ä½æˆ–æ¥è¿‘æœ€ä½MAE
  - åœ¨æœ€å¤æ‚çš„ **Ti-Oç³»ç»Ÿä¸­ï¼ŒMAEé™ä½10.9%ï¼ˆp=0.008ï¼‰**ï¼Œæ•ˆæœæ˜¾è‘—
- **Uncertainty Sampling æ•ˆæœä¸ä½³ç”šè‡³æ›´å·®**ï¼š
  - åœ¨Cã€Feã€Ti-Oç³»ç»Ÿä¸­è¡¨ç°åŠ£äºéšæœºé‡‡æ ·ï¼ˆp<0.05ï¼‰
  - å¯èƒ½æºäºâ€œè¿‡åº¦èšç„¦é«˜ä¸ç¡®å®šæ€§åŒºåŸŸâ€å¯¼è‡´é‡‡æ ·åå·®
- **Hybrid æ–¹æ³•æœªè¡¨ç°å‡ºä¼˜åŠ¿**ï¼š
  - å°½ç®¡ç†è®ºä¸Šæœ‰å¹³è¡¡explorationä¸exploitationæ½œåŠ›ï¼Œä½†åœ¨æœ¬å®éªŒä¸­è¡¨ç°ä¸ç¨³å®šï¼Œå°¤å…¶åœ¨Ti-Oä¸Šæœ€å·®

### å­¦ä¹ æ›²çº¿åˆ†æï¼ˆFigure 2ï¼‰
- **Carbon**ï¼šDiversityæ—©æœŸæ”¶æ•›æ›´å¿«ï¼Œæœ€ç»ˆè¯¯å·®æœ€ä½
- **Silicon**ï¼šå„æ–¹æ³•å‡ ä¹æ— å·®åˆ« â†’ è¡¨æ˜ä»»åŠ¡ç®€å•ï¼ŒALå¢ç›Šæœ‰é™
- **Iron**ï¼šDiversityæŒç»­ä¼˜äºRandom
- **Ti-O**ï¼šç­–ç•¥é—´å·®è·æœ€å¤§ï¼Œ**Diversityæ˜æ˜¾é¢†å…ˆ**ï¼Œä½“ç°å…¶åœ¨å¤æ‚å¼‚è´¨ç³»ç»Ÿä¸­çš„ä¼˜è¶Šæ€§

### æ¶ˆèå®éªŒï¼ˆCross-Database Validationï¼‰
- åœ¨Carbonç³»ç»Ÿä¸Šè¿›è¡Œäº†è·¨æ•°æ®åº“è¿ç§»æµ‹è¯•ï¼ˆMP â†” OQMDï¼‰
- å‘ç°å­˜åœ¨æ˜æ˜¾çš„domain shiftï¼š
  - MPâ†’OQMDè¿ç§»æ•ˆæœè¾ƒå¥½ï¼ˆéšç€æ ‡ç­¾å¢åŠ æ³›åŒ–æå‡ï¼‰
  - OQMDâ†’MPè¿ç§»è¾ƒå·®
- è¡¨æ˜ä¸åŒæ•°æ®åº“é—´å­˜åœ¨ç³»ç»Ÿæ€§åå·®ï¼Œå½±å“æ¨¡å‹å¯ç§»æ¤æ€§

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **Diversity-based sampling æ˜¯æœ€æœ‰æ•ˆä¸”ç¨³å¥çš„ALç­–ç•¥**ï¼Œå°¤å…¶é€‚ç”¨äºç»“æ„å’Œç»„æˆå¤æ‚çš„ææ–™ç³»ç»Ÿï¼ˆå¦‚Ti-Oï¼‰ã€‚
2. âš ï¸ **ä¼ ç»ŸUncertainty-based sampling å¹¶ä¸æ€»æ˜¯æœ‰æ•ˆ**ï¼Œåœ¨æŸäº›ç³»ç»Ÿä¸­åè€Œä¼šå¼•å…¥åå·®ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚
3. ğŸ” **ALç­–ç•¥çš„æ•ˆæœå…·æœ‰ææ–™ä¾èµ–æ€§**ï¼š
   - ç®€å•ç³»ç»Ÿï¼ˆå¦‚Siï¼‰å„ç±»æ–¹æ³•å·®å¼‚å°
   - å¤æ‚ç³»ç»Ÿï¼ˆå¦‚Ti-Oï¼‰ä¸­ï¼Œå¤šæ ·æ€§é‡‡æ ·çš„ä¼˜åŠ¿æä¸ºçªå‡º
4. ğŸ’¡ **æ™ºèƒ½æ•°æ®é€‰æ‹©å¯å‡å°‘5â€“13%çš„DFTè®¡ç®—éœ€æ±‚**å³å¯è¾¾åˆ°ç›®æ ‡ç²¾åº¦ï¼Œæ˜¾è‘—èŠ‚çœè®¡ç®—èµ„æºã€‚
5. ğŸŒ **å…¨æµç¨‹å¯åœ¨Google Colabè¿è¡Œï¼ˆ<8GB RAM, <4å°æ—¶ï¼‰**ï¼Œæå¤§æå‡äº†MLIPå¼€å‘çš„å¯åŠæ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ç‰¹å¾è¡¨è¾¾èƒ½åŠ›æœ‰é™**ï¼šå½“å‰ä½¿ç”¨çš„17ç»´æ‰‹å·¥ç‰¹å¾ç¼ºä¹å±€éƒ¨ç»“æ„ä¿¡æ¯ï¼ˆå¦‚SOAPã€atomic environment descriptorsï¼‰ï¼Œå¯èƒ½é™åˆ¶æ¨¡å‹ä¸Šé™ã€‚
- **ä»…é¢„æµ‹å½¢æˆèƒ½**ï¼šæœªæ‰©å±•è‡³å…¶ä»–å…³é”®å±æ€§ï¼ˆå¦‚band gapã€elastic modulusã€magnetismï¼‰ã€‚
- **é™æ€queryç­–ç•¥**ï¼šæœªåŠ¨æ€è°ƒæ•´uncertainty/diversityæƒé‡ï¼Œæœªèƒ½è‡ªé€‚åº”ææ–™å¤æ‚åº¦å˜åŒ–ã€‚
- **æœªä½¿ç”¨ç°ä»£GNNæ¶æ„**ï¼šå¦‚NequIPç­‰E(3)-equivariantæ¨¡å‹æœªè¢«çº³å…¥ï¼Œé™åˆ¶äº†ä¸SOTA MLIPçš„å¯¹æ¥ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- ğŸ”„ **å¼€å‘è‡ªé€‚åº”ALç­–ç•¥**ï¼šæ ¹æ®ç³»ç»Ÿå¤æ‚åº¦åŠ¨æ€è°ƒèŠ‚uncertaintyä¸diversityçš„å¹³è¡¡ã€‚
- ğŸ§± **æ•´åˆå…ˆè¿›æè¿°ç¬¦æˆ–å›¾ç¥ç»ç½‘ç»œï¼ˆGNNsï¼‰**ï¼šä¾‹å¦‚å°†SOAPæˆ–SchNetåµŒå…¥AL pipelineï¼Œæå‡è¡¨å¾èƒ½åŠ›ã€‚
- ğŸ“ˆ **æ‰©å±•åˆ°æ›´å¤šææ–™å±æ€§å’Œç›¸ç©ºé—´æ¢ç´¢**ï¼šå¦‚åŠ¨åŠ›å­¦ç¨³å®šæ€§ã€ç›¸å˜è·¯å¾„ã€ç¼ºé™·è¡Œä¸ºå»ºæ¨¡ã€‚
- ğŸ¤ **ç»“åˆç”Ÿæˆæ¨¡å‹ä¸AL**ï¼šåˆ©ç”¨VAEæˆ–diffusion modelç”Ÿæˆæ–°é¢–ç»“æ„ï¼Œå¹¶ç”±ALç­›é€‰æœ€æœ‰ä»·å€¼è€…è¿›è¡ŒDFTéªŒè¯ã€‚
- ğŸš€ **é›†æˆSymmetry-awareæ¶æ„**ï¼šå€Ÿé‰´Choyalç­‰äºº[31]çš„å·¥ä½œï¼Œèåˆequivariant neural networksè¿›ä¸€æ­¥æå‡æ•°æ®æ•ˆç‡ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡é€šè¿‡ç³»ç»Ÿå®è¯æ­ç¤ºâ€”â€”**åœ¨å¤šæ ·ææ–™ç³»ç»Ÿä¸­è®­ç»ƒMLIPæ—¶ï¼Œâ€œå¤šæ ·æ€§ä¼˜å…ˆâ€çš„Active Learningç­–ç•¥æ¯”ä¼ ç»Ÿçš„â€œä¸ç¡®å®šæ€§ä¼˜å…ˆâ€æ›´é«˜æ•ˆã€æ›´é²æ£’ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤æ‚åŒ–åˆç‰©ä¸­ä¼˜åŠ¿æ˜¾è‘—ï¼Œä¸ºæ•°æ®é«˜æ•ˆçš„ææ–™å‘ç°æä¾›äº†å®ç”¨ä¸”å¯æ¨å¹¿çš„æ–¹æ³•è®ºåŸºç¡€ã€‚**

</details>

---

### 7. [Free-RBF-KAN: Kolmogorov-Arnold Networks with Adaptive Radial Basis Functions for Efficient Function Learning](https://arxiv.org/abs/2601.07760)

**Authors**: Shao-Ting Chiu, Siu Wun Cheung, Ulisses Braga-Neto, Chak Shing Lee, Rui Peng Li  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2601.07760v1  

#### Abstract
Kolmogorov-Arnold Networks (KANs) have shown strong potential for efficiently approximating complex nonlinear functions. However, the original KAN formulation relies on B-spline basis functions, which incur substantial computational overhead due to De Boor's algorithm. To address this limitation, re...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFree-RBF-KAN: Kolmogorov-Arnold Networks with Adaptive Radial Basis Functions for Efficient Function Learning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åŸå§‹çš„ **Kolmogorov-Arnold Network (KAN)** è™½ç„¶åœ¨å‡½æ•°é€¼è¿‘æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶ä¾èµ–äº **B-spline** åŸºå‡½æ•°ï¼Œéœ€é€šè¿‡ **De Boor ç®—æ³•**è¿›è¡Œè®¡ç®—ï¼Œå¹¶ä¸”è®­ç»ƒè¿‡ç¨‹ä¸­éœ€è¦åŠ¨æ€è°ƒæ•´åŸŸèŒƒå›´ï¼Œå¯¼è‡´æ˜¾è‘—çš„**è®¡ç®—å¼€é”€**ã€‚æ­¤å¤–ï¼Œæ ‡å‡†çš„ RBF-KAN åœ¨ç²¾åº¦ä¸Šé€šå¸¸ä¸å¦‚ B-spline KANã€‚

### æå‡ºçš„æ–°æ–¹æ³•
æœ¬æ–‡æå‡º **Free-RBF-KAN** â€”â€”ä¸€ç§åŸºäºå¾„å‘åŸºå‡½æ•°ï¼ˆRBFï¼‰çš„ KAN æ¶æ„ï¼Œå¼•å…¥äº†ä¸¤ä¸ªå…³é”®æœºåˆ¶ï¼š
- **è‡ªé€‚åº”å­¦ä¹ ç½‘æ ¼ï¼ˆadaptive learning grids / free knotsï¼‰**ï¼šå…è®¸ RBF çš„ä¸­å¿ƒç‚¹ï¼ˆcentroidsï¼‰åœ¨è®­ç»ƒä¸­è‡ªç”±ç§»åŠ¨ï¼Œä»¥å¯¹é½æ¿€æ´»æ¨¡å¼ã€‚
- **å¯è®­ç»ƒçš„å¹³æ»‘åº¦å‚æ•°ï¼ˆtrainable smoothnessï¼‰**ï¼šå°† RBF çš„å½¢çŠ¶å‚æ•°ï¼ˆå¦‚é«˜æ–¯æ ¸çš„ Ïƒï¼‰ä½œä¸ºç½‘ç»œå‚æ•°è”åˆä¼˜åŒ–ã€‚

è¯¥æ–¹æ³•ä¿ç•™äº† KAN çš„åˆ†å±‚å åŠ ç»“æ„ï¼ŒåŒæ—¶ç”¨æ›´çµæ´»ã€é«˜æ•ˆçš„ RBF æ›¿ä»£ B-splineã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **è®¡ç®—æ•ˆç‡** | é¿å…äº† De Boor è¿­ä»£å’ŒåŸŸé‡ç¼©æ”¾ï¼Œè®­ç»ƒå’Œæ¨ç†é€Ÿåº¦æ˜¾è‘—å¿«äº B-spline KAN |
| **è¡¨è¾¾èƒ½åŠ›** | è‡ªç”±ç§»åŠ¨çš„ centroids å’Œå¯è°ƒ smoothness æå‡äº†æ¨¡å‹çµæ´»æ€§ï¼Œå°¤å…¶é€‚åˆå¤šå°ºåº¦ã€éå…‰æ»‘å‡½æ•° |
| **ç†è®ºä¿éšœ** | ç»™å‡ºäº†é¦–ä¸ªé’ˆå¯¹ RBF-KAN å®¶æ—çš„**é€šç”¨é€¼è¿‘å®šç†è¯æ˜**ï¼Œç¡®ç«‹å…¶ç†è®ºå®Œå¤‡æ€§ |
| **å…¼å®¹æ€§** | å¯æ— ç¼é›†æˆåˆ° PINNã€DeepONet ç­‰ç§‘å­¦æœºå™¨å­¦ä¹ æ¡†æ¶ä¸­ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†ä¸ä»»åŠ¡
å®éªŒæ¶µç›–å¤šä¸ªé¢†åŸŸï¼ŒåŒ…æ‹¬ï¼š
- **åˆæˆå‡½æ•°é€¼è¿‘**ï¼š`f(x,y) = cos(4x) + sin(y) + sin(2Ï€y) + |sin(3Ï€y)|`ï¼ˆå«éå…‰æ»‘é¡¹ï¼‰
- **å¤šå°ºåº¦å›å½’**ï¼š`f(x) = 0.1sin(50Ï€x) + sin(2Ï€x)`
- **é«˜ç»´å›å½’**ï¼šMNIST å›¾åƒåˆ†ç±»ï¼ˆä½œä¸ºå›å½’ä»»åŠ¡å¤„ç†ï¼‰
- **ç‰©ç†ä¿¡æ¯å­¦ä¹ ï¼ˆPINNï¼‰**ï¼š
  - 2D çƒ­ä¼ å¯¼æ–¹ç¨‹ï¼ˆé«˜é¢‘ç‡æºé¡¹ï¼‰
  - 2D Helmholtz æ–¹ç¨‹ï¼ˆå…‰æ»‘æ­£å¼¦æºï¼‰
- **ç®—å­å­¦ä¹ ï¼ˆOperator Learningï¼‰**ï¼šä½¿ç”¨ DeepONet æ¡†æ¶å­¦ä¹ ååº”æ‰©æ•£æ–¹ç¨‹ `âˆ‚u/âˆ‚t = D âˆ‚Â²u/âˆ‚xÂ² + ku + f(x)` çš„è§£ç®—å­

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
| ä»»åŠ¡ | æ¨¡å‹é…ç½® | ä¼˜åŒ–å™¨ | è¯„ä¼°æŒ‡æ ‡ |
|------|----------|--------|-----------|
| å‡½æ•°é€¼è¿‘ | `[2,5,1]` å±‚ç»“æ„ | LBFGS, 300 epochs | Test MSE |
| å¤šå°ºåº¦å›å½’ | MLP: 4Ã—100ï¼›KANç±»: 3Ã—5 | Adam/LBFGS | NTK åˆ†æã€è®­ç»ƒæŸå¤±æ›²çº¿ |
| MNIST å›å½’ | `[784,64,10]` | Adam, 20 epochs | Test Loss, Training Time |
| PINN ä»»åŠ¡ | å†…éƒ¨é‡‡æ · 4000 ç‚¹ï¼Œè¾¹ç•Œ 200~100 ç‚¹ | Adam + å­¦ä¹ ç‡è¡°å‡ | LÂ²-loss, è®­ç»ƒæ—¶é—´ï¼ˆç§’ï¼‰ |
| DeepONet | Branch: MLP (å›ºå®š)ï¼ŒTrunk: æ›¿æ¢ä¸ºä¸åŒ KAN | Adam, 10k æ­¥ | Relative LÂ² error, å‚æ•°é‡, è®­ç»ƒæ—¶é—´ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **MLP**ï¼šä¼ ç»Ÿå…¨è¿æ¥ç¥ç»ç½‘ç»œï¼ˆTanh/SiLUï¼‰
- **KAN**ï¼šåŸå§‹ B-spline KANï¼ˆä¸‰æ¬¡æ ·æ¡ï¼‰
- **FreeKnots-KAN**ï¼šå¸¦å¯å­¦ä¹  knot çš„ B-spline KAN
- **RBF-KAN**ï¼šå›ºå®š centroids å’Œ smoothness çš„ RBF ç‰ˆæœ¬
- **PINN / DeepONet**ï¼šç»å…¸ç‰©ç†ä¿¡æ¯ä¸ç®—å­å­¦ä¹ åŸºå‡†

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### ï¼ˆ1ï¼‰éå…‰æ»‘å‡½æ•°é€¼è¿‘ï¼ˆTable 2ï¼‰
| Model | #Param | Test MSE |
|-------|--------|---------|
| MLP | 261 | 5.26e-1 |
| KAN | 195 | 3.96e-3 |
| FreeKnots-KAN | 307 | 2.57e-4 |
| RBF-KAN | 120 | 6.05e-4 |
| **Free-RBF-KAN** | **290** | **2.39e-4** âœ… |

> **ç»“è®º**ï¼šFree-RBF-KAN è¾¾åˆ°æœ€é«˜ç²¾åº¦ï¼Œä¼˜äº FreeKnots-KANï¼Œä¸”å‚æ•°å°‘äºåè€…ã€‚

#### ï¼ˆ2ï¼‰MNIST é«˜ç»´å›å½’ï¼ˆTable 3ï¼‰
| Model | #Param | Test Loss | Training Time (s) |
|-------|--------|----------|------------------|
| MLP | 509,410 | **6.70e-2** | **81.58** |
| KAN | 762,240 | 1.17e-1 | 97.95 |
| RBF-KAN | 508,160 | 2.02e-1 | 82.27 |
| **Free-RBF-KAN** | **525,120** | **8.79e-2** | **85.81** |

> **ç»“è®º**ï¼šè™½ä»è½åäº MLPï¼Œä½† Free-RBF-KAN æ˜¾è‘—ä¼˜äºæ ‡å‡† KAN å’Œ RBF-KANï¼Œåœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡é—´å–å¾—æ›´å¥½å¹³è¡¡ã€‚

#### ï¼ˆ3ï¼‰2D Heat Conductionï¼ˆTable 4ï¼‰
| Model | #Param | LÂ²-loss | Training Time (s) |
|-------|--------|--------|------------------|
| MLP | 5,081 | 1 | 160 |
| KAN | 1,400 | 6.52e-3 | 267 |
| RBF-KAN | 1,280 | 2.78e-3 | 124 |
| **Free-RBF-KAN** | **2,000** | **2.41e-3** âœ… | **138** |

> **ç»“è®º**ï¼šFree-RBF-KAN ç²¾åº¦æœ€é«˜ï¼Œè®­ç»ƒæ—¶é—´ä»…ä¸º KAN çš„ ~50%ã€‚

#### ï¼ˆ4ï¼‰2D Helmholtz Equationï¼ˆTable 5ï¼‰
| Model | #Param | LÂ²-loss | Training Time (s) |
|-------|--------|--------|------------------|
| MLP | 50,049 | 4.15e-2 | 39 |
| KAN | 600 | 1.58 âŒ | 153 |
| RBF-KAN | 400 | 3.67e-1 | 49 |
| **Free-RBF-KAN** | **640** | **3.35e-2** âœ… | **62** |

> **ç»“è®º**ï¼šKAN å®Œå…¨å¤±è´¥ï¼›Free-RBF-KAN ä¸ä»…è¶…è¶Š RBF-KANï¼Œè¿˜ä¼˜äº MLPï¼Œä¸”è®­ç»ƒæ—¶é—´å¯æ§ã€‚

#### ï¼ˆ5ï¼‰DeepONet ç®—å­å­¦ä¹ ï¼ˆTable 6ï¼‰
| Model (Trunk) | #Param | Rel. LÂ² error | Training Time (s) |
|---------------|--------|--------------|------------------|
| MLP | 18,921 | 2.08e-2 | 78 |
| KAN | 11,945 | 6.15e-2 | 96 |
| RBF-KAN | 10,625 | 3.70e-2 | 84 |
| **Free-RBF-KAN** | **11,185** | **1.94e-2** âœ… | **88** |

> **ç»“è®º**ï¼šFree-RBF-KAN å®ç°æœ€ä½è¯¯å·®ï¼Œç”šè‡³ç•¥ä¼˜äº MLP trunkï¼Œä¸”å‚æ•°æ›´å°‘ã€‚

### æ¶ˆèå®éªŒåˆ†æ
- **è‡ªé€‚åº”ç½‘æ ¼ vs å›ºå®šç½‘æ ¼**ï¼šåœ¨ MNIST å’Œ PINN å®éªŒä¸­ï¼ŒåŠ å…¥ adaptive centroids æ˜¾è‘—æå‡æ”¶æ•›é€Ÿåº¦å’Œæœ€ç»ˆç²¾åº¦ã€‚
- **å¯è®­ç»ƒ smoothness**ï¼šè¿›ä¸€æ­¥æ”¹å–„é«˜é¢‘ç‰¹å¾æ•æ‰èƒ½åŠ›ï¼Œåœ¨å¤šå°ºåº¦ä»»åŠ¡ä¸­ NTK è°±æ˜¾ç¤ºæ›´å®½æ³›çš„èƒ½é‡åˆ†å¸ƒï¼Œè¡¨æ˜æ—  spectral biasã€‚
- **NTK åˆ†æ**ï¼ˆå›¾4ï¼‰ï¼šFree-RBF-KAN çš„ NTK ç‰¹å¾å€¼è¡°å‡ç¼“æ…¢ï¼Œè¯´æ˜å…¶èƒ½å‡è¡¡åœ°å­¦ä¹ ä½é¢‘ä¸é«˜é¢‘æˆåˆ†ï¼Œç±»ä¼¼åŸå§‹ KANï¼Œä¼˜äº MLPã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **Free-RBF-KAN åœ¨å¤šç§ä»»åŠ¡ä¸­ä¸€è‡´ä¼˜äºåŸå§‹ KAN å’Œ RBF-KAN**ï¼Œå°¤å…¶æ˜¯åœ¨ç‰©ç†é©±åŠ¨çš„å¤šå°ºåº¦ã€é«˜é¢‘ç‡ PDE æ±‚è§£ä¸­è¡¨ç°å“è¶Šã€‚
2. âœ… **è®¡ç®—æ•ˆç‡æ˜¾è‘—æå‡**ï¼šç›¸æ¯” B-spline KANï¼Œé¿å…äº† De Boor è¿­ä»£ï¼Œè®­ç»ƒé€Ÿåº¦å¿« 2â€“3 å€ã€‚
3. âœ… **å…·å¤‡ç†è®ºå®Œå¤‡æ€§**ï¼šé¦–æ¬¡ä¸º RBF-KAN æä¾›é€šç”¨é€¼è¿‘å®šç†è¯æ˜ï¼Œç¡®è®¤å…¶ universal approximation capabilityã€‚
4. âœ… **æ—  spectral bias**ï¼šNTK åˆ†æè¯å®å…¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½æœ‰æ•ˆæ•æ‰é«˜é¢‘ä¿¡å·ï¼Œé€‚ç”¨äºå¤æ‚ç‰©ç†ç³»ç»Ÿå»ºæ¨¡ã€‚
5. âœ… **æ¨¡å—åŒ–å¼º**ï¼šå¯ä½œä¸º trunk network æˆåŠŸåµŒå…¥ DeepONetï¼Œå®ç°é«˜æ€§èƒ½ç®—å­å­¦ä¹ ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- âŒ åœ¨é«˜åº¦éç»“æ„åŒ–çš„å›¾åƒè¯†åˆ«ä»»åŠ¡ï¼ˆå¦‚ MNISTï¼‰ä¸Šï¼Œä»ä¸å¦‚æ ‡å‡† MLP é«˜æ•ˆã€‚
- âŒ RBF-KAN ç±»æ–¹æ³•æœ¬è´¨ä¸Šä»æ˜¯é€å˜é‡åˆ†è§£ï¼Œå¯èƒ½ä¸é€‚ç”¨äºæç«¯è€¦åˆçš„é«˜ç»´äº¤äº’é—®é¢˜ã€‚
- âŒ å½“è¾“å…¥ç»´åº¦æé«˜æ—¶ï¼Œå°½ç®¡ç¼“è§£äº†â€œç»´åº¦ç¾éš¾â€ï¼Œä½†ä»é¢ä¸´ RBF ä¸­å¿ƒæ•°é‡å¢é•¿çš„é—®é¢˜ï¼ˆä¸è¿‡å› æ˜¯ univariate ç»“æ„ï¼Œå½±å“è¾ƒå°ï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢å°† Free-RBF-KAN è¡¨è¾¾ä¸ºç­‰æ•ˆçš„ **MLP with Gaussian activations** å½¢å¼ï¼Œä»¥ä¾¿åˆ©ç”¨æˆç†Ÿçš„ MLP ä¼˜åŒ–æŠ€æœ¯ã€‚
- æ‰©å±•è‡³æ›´å¤šç±»å‹çš„ RBF æ ¸ï¼ˆå¦‚ MatÃ©rn kernelï¼‰ï¼Œæ§åˆ¶è¾“å‡ºå‡½æ•°çš„å…¨å±€å…‰æ»‘æ€§ã€‚
- åº”ç”¨äºæ›´å¤§è§„æ¨¡çš„çœŸå®ä¸–ç•Œ PDE é—®é¢˜ï¼ˆå¦‚ Navier-Stokesï¼‰ã€æ§åˆ¶é€†é—®é¢˜åŠä¸ç¡®å®šæ€§é‡åŒ–ã€‚

---

> **æ€»ç»“**ï¼š  
> **Free-RBF-KAN** æ˜¯ä¸€ä¸ªå…¼å…·**é«˜æ•ˆæ€§ã€çµæ´»æ€§ä¸ç†è®ºæ·±åº¦**çš„æ–°å‹ KAN æ¶æ„ã€‚å®ƒé€šè¿‡å¼•å…¥ **å¯å­¦ä¹ çš„ RBF centroids ä¸ smoothness å‚æ•°**ï¼Œè§£å†³äº†ä¼ ç»Ÿ KAN çš„è®¡ç®—ç“¶é¢ˆï¼Œåœ¨ä¿æŒç”šè‡³è¶…è¶Šå…¶ç²¾åº¦çš„åŒæ—¶å¤§å¹…æå‡äº†è®­ç»ƒæ•ˆç‡ï¼Œç‰¹åˆ«é€‚åˆç§‘å­¦è®¡ç®—ä¸­çš„**å¤šå°ºåº¦å»ºæ¨¡ã€PDE æ±‚è§£ä¸ç®—å­å­¦ä¹ **ä»»åŠ¡ï¼Œæ˜¯å½“å‰ KAN å‘å±•è·¯çº¿ä¸­æå…·å‰æ™¯çš„æ–¹å‘ä¹‹ä¸€ã€‚

</details>

---

### 8. [Efficient and Reliable Estimation of Named Entity Linking Quality: A Case Study on GutBrainIE](https://arxiv.org/abs/2601.06624)

**Authors**: Marco Martinelli, Stefano Marchesin, Gianmaria Silvello  
**Category**: cs.CL  
**Published**: 2026-01-13  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2601.06624v1  

#### Abstract
Named Entity Linking (NEL) is a core component of biomedical Information Extraction (IE) pipelines, yet assessing its quality at scale is challenging due to the high cost of expert annotations and the large size of corpora. In this paper, we present a sampling-based framework to estimate the NEL acc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šEfficient and Reliable Estimation of Named Entity Linking Quality: A Case Study on GutBrainIE

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
- **å¤§è§„æ¨¡ Named Entity Linking (NEL) è´¨é‡è¯„ä¼°æˆæœ¬é«˜**ï¼šåœ¨ç”Ÿç‰©åŒ»å­¦é¢†åŸŸï¼ŒNEL æ˜¯ä¿¡æ¯æŠ½å–ï¼ˆInformation Extraction, IEï¼‰çš„å…³é”®ç¯èŠ‚ï¼Œä½†å…¶è´¨é‡è¯„ä¼°ä¾èµ–ä¸“å®¶äººå·¥æ ‡æ³¨ï¼Œæˆæœ¬é«˜æ˜‚ä¸”éš¾ä»¥æ‰©å±•åˆ°å¤§å‹è¯­æ–™åº“ã€‚
- **ä¼ ç»Ÿé‡‡æ ·æ–¹æ³•æ•ˆç‡ä½ä¸‹**ï¼šSimple Random Sampling (SRS) å¯¼è‡´é¢‘ç¹çš„ä¸Šä¸‹æ–‡åˆ‡æ¢ï¼ˆcontext switchï¼‰ï¼Œå¢åŠ è®¤çŸ¥è´Ÿæ‹…å’Œæ ‡æ³¨æ—¶é—´ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
- **å°† NEL å‡†ç¡®ç‡ä¼°è®¡å½¢å¼åŒ–ä¸ºå¸¦çº¦æŸçš„ä¼˜åŒ–é—®é¢˜**ï¼š
  - ç›®æ ‡æ˜¯åœ¨æ»¡è¶³ç›®æ ‡ Margin of Error (MoE) çš„å‰æä¸‹ï¼Œæœ€å°åŒ–äººå·¥æ ‡æ³¨æˆæœ¬ã€‚
- **é€‚é…å¹¶åº”ç”¨ Stratified Two-stage Weighted Cluster Sampling (STWCS)** åˆ° NEL åœºæ™¯ï¼š
  - **Stratificationï¼ˆåˆ†å±‚ï¼‰**ï¼šåŸºäºå®ä½“æ ‡ç­¾å®šä¹‰ 5 ä¸ªéé‡å çš„ *strata*ï¼Œæå‡ç»„å†…åŒè´¨æ€§ã€‚
  - **Clusteringï¼ˆèšç±»ï¼‰**ï¼šä»¥å½’ä¸€åŒ–çš„è¡¨é¢å½¢å¼ï¼ˆsurface formï¼‰ä½œä¸ºèšç±»ä¾æ®ï¼Œå‡å°‘ä¸Šä¸‹æ–‡åˆ‡æ¢ã€‚
  - **ä¸¤é˜¶æ®µåŠ æƒæŠ½æ ·**ï¼šå…ˆæŒ‰è§„æ¨¡æ¦‚ç‡æŠ½å±‚ï¼Œå†åœ¨å±‚å†…æŒ‰é›†ç¾¤å¤§å°æŠ½ clusterï¼Œæœ€åä»æ¯ä¸ª cluster ä¸­æœ€å¤šæŠ½å– `m=5` æ¡ triples è¿›è¡Œæ ‡æ³¨ã€‚
- **å®Œå…¨ç‹¬ç«‹äº NEL è¾“å‡ºçš„è®¾è®¡**ï¼š
  - åˆ†å±‚ï¼ˆstrataï¼‰å’Œèšç±»ï¼ˆclusterï¼‰å‡åŸºäºåŸå§‹æ–‡æœ¬ç‰¹å¾ï¼ˆå¦‚ entity label å’Œ normalized surface formï¼‰ï¼Œé¿å…å¯¹ NEL ç»“æœçš„ä¾èµ–ï¼Œé˜²æ­¢è¯„ä¼°è¿‡ç¨‹ä¸­çš„å¾ªç¯åå·®ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ˜¾è‘—é™ä½æ ‡æ³¨æˆæœ¬**ï¼šç›¸æ¯” SRSï¼Œåœ¨ç›¸åŒæ ·æœ¬é‡ä¸‹å‡å°‘çº¦ 29% çš„ä¸“å®¶æ ‡æ³¨æ—¶é—´ã€‚
- **æ›´é«˜çš„ç»Ÿè®¡æ•ˆç‡**ï¼šé€šè¿‡å‡å°‘æ–¹å·®å’Œä¸Šä¸‹æ–‡åˆ‡æ¢ï¼Œæ›´å¿«è¾¾åˆ°ç›®æ ‡ MoEã€‚
- **å¯æ‰©å±•æ€§å¼º**ï¼šæ¡†æ¶é€šç”¨ï¼Œé€‚ç”¨äºå…¶ä»– NEL åŸºå‡†æˆ– IE æµæ°´çº¿çš„è´¨é‡è¯„ä¼°ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **GutBrainIE**ï¼šä¸€ä¸ªä¸“æ³¨äºâ€œè‚ è„‘è½´â€ï¼ˆgut-brain axisï¼‰é¢†åŸŸçš„æ–°å‹ç”Ÿç‰©åŒ»å­¦è¯­æ–™åº“ã€‚
  - åŒ…å« 1,647 ç¯‡ PubMed æ‘˜è¦ã€‚
  - æ‰‹åŠ¨æ ‡æ³¨çš„ Platinum å’Œ Gold æŠ˜å ä¸­åŒ…å« **11,184 æ¡ NEL triples**ã€‚
  - å®ä½“ç±»å‹æ¶µç›– 13 ç±»ï¼ˆå¦‚ DDFã€Microbiomeã€Drug ç­‰ï¼‰ï¼Œé“¾æ¥è‡³ 6 ä¸ªæ ‡å‡†è¯è¡¨ + è‡ªå®šä¹‰æœ¬ä½“ã€‚

### å®éªŒè®¾ç½®
- **é‡‡æ ·ç­–ç•¥**ï¼š
  - ä¸»æ–¹æ³•ï¼š**STWCS**ï¼ˆStratified Two-stage Weighted Cluster Samplingï¼‰
  - åŸºçº¿æ–¹æ³•ï¼š**Simple Random Sampling (SRS)**
- **ç›®æ ‡ç²¾åº¦è¦æ±‚**ï¼š
  - ç›®æ ‡ Margin of Error (MoE) â‰¤ 0.05
- **è¿­ä»£æµç¨‹**ï¼š
  - åŠ¨æ€é‡‡æ · â†’ äººå·¥æ ‡æ³¨ â†’ æ›´æ–°å‡†ç¡®ç‡ä¼°è®¡ä¸ MoE â†’ ç›´è‡³ MoE è¾¾æ ‡ã€‚
- **åœæ­¢æ¡ä»¶**ï¼šå½“ MoE â‰¤ 0.05 æ—¶ç»ˆæ­¢é‡‡æ ·ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **æ€»ä½“ NEL å‡†ç¡®ç‡ä¼°è®¡å€¼åŠå…¶ (1âˆ’Î±) ç½®ä¿¡åŒºé—´ï¼ˆCIï¼‰**
- **Margin of Error (MoE)**ï¼šè¡¡é‡ä¼°è®¡ä¸ç¡®å®šæ€§
- **æ ‡æ³¨æ€»è€—æ—¶ï¼ˆwall-clock timeï¼‰**
- **ä¸Šä¸‹æ–‡åˆ‡æ¢æ¬¡æ•°ï¼ˆcontext switchesï¼‰**
- **æ¯æ¡ä¸‰å…ƒç»„çš„å¹³å‡æ ‡æ³¨æ—¶é—´ï¼ˆåŒºåˆ†æ˜¯å¦å‘ç”Ÿä¸Šä¸‹æ–‡åˆ‡æ¢ï¼‰**

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **SRS æ¨¡æ‹Ÿå®éªŒ**ï¼š
  - å›ºå®š STWCS å®é™…æ ‡æ³¨çš„ 2,749 æ¡ triplesã€‚
  - éšæœºæ‰“ä¹±é¡ºåºæ¨¡æ‹Ÿ SRS ä¸‹çš„ä¸Šä¸‹æ–‡åˆ‡æ¢é¢‘ç‡ã€‚
  - ä½¿ç”¨å®æµ‹çš„æ—¶é—´å‚æ•°ä¼°ç®— SRS æ‰€éœ€æ€»æ—¶é—´ã€‚
  - é‡å¤ 1,000 æ¬¡å¹¶è¿›è¡Œ bootstrap ä»¥è·å¾—ç¨³å¥ä¼°è®¡ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ€» NEL triples æ•°é‡ | 11,184 |
| å®é™…æ ‡æ³¨ triples æ•°é‡ | **2,749**ï¼ˆå æ¯” **24.6%**ï¼‰|
| è¾¾æˆç›®æ ‡ MoE æ‰€éœ€æ ‡æ³¨æ¯”ä¾‹ | < 25% |
| æœ€ç»ˆ MoE | **0.047**ï¼ˆ< 0.05 ç›®æ ‡ï¼‰|
| æ€»ä½“ NEL å‡†ç¡®ç‡ä¼°è®¡ | **0.915 Â± 0.0473** |
| å¯¹åº” 95% CI | [0.868, 0.963] |

### ä¸åŸºçº¿æ–¹æ³•ï¼ˆSRSï¼‰çš„å¯¹æ¯”ç»“æœ
| æŒ‡æ ‡ | STWCSï¼ˆå®é™…ï¼‰ | SRSï¼ˆæ¨¡æ‹Ÿï¼‰ | æå‡ |
|------|---------------|-------------|-------|
| æ€»æ ‡æ³¨æ—¶é—´ | **797 åˆ†é’Ÿ**ï¼ˆ13h17mï¼‰ | **1,124.57 åˆ†é’Ÿ**ï¼ˆ18h44mï¼‰ | â†“ **327.6 åˆ†é’Ÿ** |
| ä¸Šä¸‹æ–‡åˆ‡æ¢æ¬¡æ•° | 1,050 | ~2,745ï¼ˆå‡å€¼ï¼‰ | â†“ ~62% |
| æ•ˆç‡æ¯”ï¼ˆtime_STWCS / time_SRSï¼‰ | ~0.71 | â€” | **èŠ‚çœçº¦ 29% æ—¶é—´** |

> âœ… **ç»“è®º**ï¼šSTWCS åœ¨ç›¸åŒæ ·æœ¬é‡ä¸‹æ¯” SRS å¿«è¿‘ 30%ï¼Œä¸»è¦å¾—ç›Šäºæ›´å°‘çš„ä¸Šä¸‹æ–‡åˆ‡æ¢ã€‚

### å„ stratum çš„å‡†ç¡®ç‡ä¼°è®¡ï¼ˆTable 3ï¼‰
| Stratum | å‡†ç¡®ç‡ä¼°è®¡ (pÌ‚) | MoE | CI ä¸‹é™ |
|--------|----------------|-----|---------|
| DDF | 0.883 | 0.093 | 0.790 |
| Microbiome + Bacteria | **0.979** | 0.108 | 0.871 |
| Human + Animal + Anatomical Location | **0.976** | 0.060 | 0.916 |
| Chemical + Gene | 0.851 | 0.087 | 0.764 |
| Drug + ... + Technique | 0.898 | 0.154 | **0.744** |

> ğŸ” å‘ç°ï¼šMicrobiome/Bacteria å’Œ ç”Ÿç‰©ä¸»ä½“ç±»ï¼ˆHuman/Animal/Locationï¼‰å‡†ç¡®ç‡æœ€é«˜ï¼›æœ€åä¸€ç±» MoE æœ€å¤§ï¼Œæç¤ºéœ€æ›´å¤šé‡‡æ ·ä»¥æé«˜ç½®ä¿¡åº¦ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ä»…éœ€ä¸åˆ° 25% çš„äººå·¥æ ‡æ³¨å³å¯å®ç°å¯é çš„ NEL è´¨é‡ä¼°è®¡**ï¼ˆMoE â‰¤ 0.05ï¼‰ã€‚
2. **STWCS æ˜¾è‘—ä¼˜äº SRS**ï¼šé€šè¿‡å‡å°‘ä¸Šä¸‹æ–‡åˆ‡æ¢ï¼ŒèŠ‚çœçº¦ **29% çš„ä¸“å®¶æ—¶é—´**ï¼ŒéªŒè¯äº†ç»“æ„åŒ–é‡‡æ ·çš„æœ‰æ•ˆæ€§ã€‚
3. **åˆ†å±‚è®¾è®¡æä¾›ç»†ç²’åº¦æ´å¯Ÿ**ï¼šä¸åŒ entity ç±»å‹ç»„çš„ NEL è¡¨ç°å­˜åœ¨å·®å¼‚ï¼Œå¯ç”¨äºæŒ‡å¯¼åç»­é’ˆå¯¹æ€§ä¿®æ­£ï¼ˆtargeted curationï¼‰ã€‚
4. **æ¡†æ¶å…·æœ‰é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§**ï¼šä¸ä¾èµ– NEL è¾“å‡ºæœ¬èº«ï¼Œå¯æ¨å¹¿è‡³å…¶ä»– NEL æˆ– KG è´¨é‡è¯„ä¼°ä»»åŠ¡ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡çš„åˆå§‹ entity mention æ£€æµ‹**ï¼šæœ¬å·¥ä½œå‡è®¾ mention å·²æ­£ç¡®è¯†åˆ«ï¼Œä»…è¯„ä¼° linking è´¨é‡ã€‚
- **strata å®šä¹‰ä¾èµ–ç»éªŒ**ï¼šå½“å‰åˆ†ç»„æ˜¯è¯­ä¹‰è¿è´¯æ€§ä¸æ•°é‡å‡è¡¡ä¹‹é—´çš„æŠ˜è¡·ï¼Œå¯èƒ½ä¸æ˜¯æœ€ä¼˜ã€‚
- **æœªè€ƒè™‘å¤šæ ‡æ³¨è€…ä¸€è‡´æ€§**ï¼šæ‰€æœ‰åˆ¤æ–­ç”±å•ä¸€ä¸“å®¶å®Œæˆï¼Œç¼ºä¹ inter-annotator agreement åˆ†æã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å¼•å…¥ **multiple annotators + majority voting** æå‡æ ‡æ³¨å¯é æ€§ã€‚
- å°†ä¸‹æ¸¸å½±å“çº³å…¥ stratification è®¾è®¡ï¼Œä¾‹å¦‚ä¼˜å…ˆé‡‡æ ·å‚ä¸å¤§é‡ relation çš„æ¦‚å¿µæˆ– KG ä¸­å¿ƒæ€§é«˜çš„èŠ‚ç‚¹ã€‚
- æ¢ç´¢è‡ªé€‚åº”é‡‡æ ·ç­–ç•¥ï¼ŒåŠ¨æ€è°ƒæ•´å„ stratum çš„é‡‡æ ·å¼ºåº¦ä»¥æœ€å°åŒ–æ•´ä½“ MoEã€‚
- å°†è¯¥æ¡†æ¶é›†æˆåˆ°è‡ªåŠ¨åŒ– IE æµæ°´çº¿ä¸­ï¼Œå®ç°æŒç»­çš„è´¨é‡ç›‘æ§ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº **STWCS** çš„é«˜æ•ˆ NEL è´¨é‡ä¼°è®¡ç®—æ³•ï¼Œåœ¨ **GutBrainIE** ä¸Šä»…ç”¨ **24.6%** çš„æ ‡æ³¨é‡å³å®ç°äº† **0.915Â±0.0473** çš„å‡†ç¡®ç‡ä¼°è®¡ï¼Œå¹¶æ¯” SRS èŠ‚çœ **29%** çš„äººå·¥æ—¶é—´ï¼Œä¸ºå¤§è§„æ¨¡ç”Ÿç‰©åŒ»å­¦ IE ç³»ç»Ÿæä¾›äº†å¯æ‰©å±•ã€ç»Ÿè®¡å¯é çš„è´¨é‡è¯„ä¼°æ–¹æ¡ˆã€‚

</details>

---

### 9. [Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models](https://arxiv.org/abs/2601.07372)

**Authors**: Xin Cheng, Wangding Zeng, Damai Dai, Qinyu Chen, Bingxuan Wang, Zhenda Xie, Kezhao Huang, Xingkai Yu, Zhewen Hao, Yukun Li, Han Zhang, Huishuai Zhang, Dongyan Zhao, Wenfeng Liang  
**Category**: cs.CL  
**Published**: 2026-01-13  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2601.07372v1  

#### Abstract
While Mixture-of-Experts (MoE) scales capacity via conditional computation, Transformers lack a native primitive for knowledge lookup, forcing them to inefficiently simulate retrieval through computation. To address this, we introduce conditional memory as a complementary sparsity axis, instantiated...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å½“å‰ä¸»æµçš„ **Large Language Models**ï¼ˆLLMsï¼‰ä¾èµ– **Transformer** æ¶æ„ï¼Œå…¶é€šè¿‡ **Mixture-of-Experts**ï¼ˆMoEï¼‰å®ç°æ¡ä»¶è®¡ç®—ï¼ˆconditional computationï¼‰ï¼Œä»è€Œåœ¨ä¸æ˜¾è‘—å¢åŠ è®¡ç®—é‡çš„å‰æä¸‹æ‰©å±•æ¨¡å‹å®¹é‡ã€‚ç„¶è€Œï¼ŒTransformer ç¼ºä¹åŸç”Ÿçš„ **çŸ¥è¯†æŸ¥æ‰¾**ï¼ˆknowledge lookupï¼‰æœºåˆ¶ï¼Œå¯¼è‡´æ¨¡å‹å¿…é¡»é€šè¿‡å¤šå±‚ **Attention** å’Œ **Feed-Forward Networks**ï¼ˆFFNsï¼‰æ¥â€œé‡å»ºâ€é™æ€çŸ¥è¯†ï¼ˆå¦‚å‘½åå®ä½“ã€å›ºå®šçŸ­è¯­ç­‰ï¼‰ï¼Œé€ æˆè®¡ç®—èµ„æºæµªè´¹ã€‚

è¿™ç§è®¾è®¡è¿«ä½¿æ¨¡å‹ç”¨åŠ¨æ€è®¡ç®—æ¨¡æ‹Ÿé™æ€è®°å¿†ï¼Œæ•ˆç‡ä½ä¸‹ï¼Œå°¤å…¶åœ¨å¤„ç†å±€éƒ¨ã€é‡å¤æ€§å¼ºçš„è¯­è¨€æ¨¡å¼æ—¶ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **conditional memory** ä½œä¸ºä¸ **conditional computation** å¹¶è¡Œçš„â€œç¬¬äºŒæ¡ç¨€ç–æ€§è½´â€ï¼Œå¹¶å¼•å…¥ **Engram** æ¨¡å—ä½œä¸ºå…¶å®ç°ã€‚

- **Engram** æ˜¯ä¸€ç§åŸºäºç°ä»£æ”¹è¿›çš„ **N-gram embedding** çš„æ¡ä»¶è®°å¿†æ¨¡å—ï¼Œæ”¯æŒ **O(1)** æ—¶é—´å¤æ‚åº¦çš„å¸¸æ•°æ—¶é—´æŸ¥æ‰¾ã€‚
- å®ƒå°†é™æ€è¯­è¨€æ¨¡å¼ï¼ˆå¦‚â€œAlexander the Greatâ€ã€â€œPrincess of Walesâ€ï¼‰å­˜å‚¨ä¸ºå¯æ£€ç´¢çš„è®°å¿†æ¡ç›®ï¼Œé€šè¿‡è¾“å…¥ä¸Šä¸‹æ–‡ç”Ÿæˆå“ˆå¸Œé”®è¿›è¡ŒæŸ¥æ‰¾ã€‚
- è¯¥æ¨¡å—ä¸ MoE å¹¶è¡Œè¿è¡Œï¼Œå½¢æˆâ€œ**è®¡ç®—-è®°å¿†**â€åŒç¨€ç–æ¶æ„ã€‚

#### **æ ¸å¿ƒåˆ›æ–°ç‚¹**ï¼š

1. **æå‡ºâ€œç¨€ç–æ€§åˆ†é…â€é—®é¢˜**ï¼ˆSparsity Allocation Problemï¼‰ï¼š
   - åœ¨æ€»å‚æ•°å’Œ FLOPs é¢„ç®—å›ºå®šçš„æ¡ä»¶ä¸‹ï¼Œå¦‚ä½•æœ€ä¼˜åœ°åˆ†é…ç¨€ç–å®¹é‡ç»™ MoE ä¸“å®¶ï¼ˆè®¡ç®—ï¼‰å’Œ Engram è®°å¿†ï¼ˆå­˜å‚¨ï¼‰ï¼Ÿ
   - å®éªŒå‘ç°å­˜åœ¨ **Uå‹ç¼©æ”¾å¾‹**ï¼ˆU-shaped scaling lawï¼‰ï¼Œå³æ··åˆåˆ†é…ä¼˜äºçº¯ MoE æˆ–çº¯è®°å¿†æ–¹æ¡ˆã€‚

2. **Engram çš„ç°ä»£å·¥ç¨‹ä¼˜åŒ–**ï¼š
   - **Tokenizer Compression**ï¼šå¯¹å­è¯ token è¿›è¡Œå½’ä¸€åŒ–åˆå¹¶ï¼ˆå¦‚ `Apple` å’Œ `_apple` æ˜ å°„ä¸ºåŒä¸€ IDï¼‰ï¼Œæå‡è¯­ä¹‰å¯†åº¦ï¼Œå‡å°‘æœ‰æ•ˆè¯æ±‡é‡ï¼ˆå‹ç¼© 23%ï¼‰ã€‚
   - **Multi-Head Hashing**ï¼šä½¿ç”¨å¤šä¸ªå“ˆå¸Œå‡½æ•°é™ä½å†²çªæ¦‚ç‡ã€‚
   - **Context-aware Gating**ï¼šåˆ©ç”¨å½“å‰éšè—çŠ¶æ€ä½œä¸º queryï¼Œå¯¹æ£€ç´¢åˆ°çš„é™æ€åµŒå…¥è¿›è¡Œé—¨æ§è°ƒèŠ‚ï¼Œè§£å†³æ­§ä¹‰å’Œå™ªå£°ã€‚
   - **Multi-Branch Integration**ï¼šé€‚é…å¤šåˆ†æ”¯æ¶æ„ï¼ˆå¦‚ mHCï¼‰ï¼Œå®ç°é«˜æ•ˆèåˆã€‚

3. **åŸºç¡€è®¾æ–½æ„ŸçŸ¥æ•ˆç‡**ï¼ˆInfrastructure-aware Efficiencyï¼‰ï¼š
   - Engram çš„æŸ¥æ‰¾æ˜¯**ç¡®å®šæ€§çš„**ï¼Œå…è®¸åœ¨æ¨ç†æ—¶æå‰é¢„å–ï¼ˆprefetchï¼‰å†…å­˜æ¡ç›®ï¼Œé‡å é€šä¿¡ä¸è®¡ç®—ï¼Œæ˜¾è‘—é™ä½å»¶è¿Ÿã€‚
   - æ”¯æŒå°†å¤§è§„æ¨¡åµŒå…¥è¡¨å¸è½½åˆ°ä¸»æœºå†…å­˜ï¼ˆhost memoryï¼‰ï¼Œçªç ´ GPU æ˜¾å­˜é™åˆ¶ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| å¯¹æ¯”ç»´åº¦ | MoE | Engram |
|--------|-----|--------|
| **ç¨€ç–æ€§ç±»å‹** | æ¡ä»¶è®¡ç®—ï¼ˆæ¿€æ´»éƒ¨åˆ†ä¸“å®¶ï¼‰ | æ¡ä»¶è®°å¿†ï¼ˆæŸ¥æ‰¾é™æ€åµŒå…¥ï¼‰ |
| **æ“ä½œå¼€é”€** | åŠ¨æ€è·¯ç”±ï¼Œä¸å¯é¢„æµ‹ | ç¡®å®šæ€§å“ˆå¸Œï¼Œå¯é¢„å– |
| **é€‚ç”¨ä»»åŠ¡** | åŠ¨æ€æ¨ç†ã€ç»„åˆé€»è¾‘ | é™æ€çŸ¥è¯†ã€å±€éƒ¨æ¨¡å¼ |
| **ç³»ç»Ÿæ•ˆç‡** | å—é™äºä¸“å®¶å¹¶è¡Œé€šä¿¡ | å¯å¸è½½è‡³ CPU å†…å­˜ï¼Œæ— æ˜¾è‘—å¼€é”€ |

Engram ä¸æ˜¯æ›¿ä»£ MoEï¼Œè€Œæ˜¯ä¸å…¶äº’è¡¥ï¼Œå…±åŒæ„æˆæ›´é«˜æ•ˆçš„ç¨€ç–æ¶æ„ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **é¢„è®­ç»ƒæ•°æ®**ï¼š262B tokens çš„æ··åˆè¯­æ–™ï¼ˆæœªå…·ä½“è¯´æ˜ï¼Œä½†æåŠä½¿ç”¨ DeepSeek-v3 çš„ tokenizerï¼‰ã€‚
- **è¯„ä¼°åŸºå‡†**ï¼š
  - **çŸ¥è¯†ä¸æ¨ç†**ï¼šMMLUã€MMLU-Reduxã€MMLU-Proã€CMMLUã€C-Evalã€AGIEvalã€ARC-Easy/Challengeã€BBHã€TriviaQA
  - **é˜…è¯»ç†è§£**ï¼šDROPã€RACE-Middle/Highã€C3
  - **ä»£ç ä¸æ•°å­¦**ï¼šHumanEvalã€MBPPã€CruxEvalã€GSM8Kã€MGSMã€MATH
  - **é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›**ï¼šLongPPLï¼ˆä¹¦ç±ã€è®ºæ–‡ã€ä»£ç ã€CoTï¼‰ã€RULERï¼ˆNIAH å¤šè·³æ£€ç´¢ã€å˜é‡è¿½è¸ªç­‰ï¼‰

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

- **æ¨¡å‹é…ç½®**ï¼š
  - **Dense-4B**ï¼š4.1B å‚æ•°ï¼Œå…¨è¿æ¥ FFNã€‚
  - **MoE-27B**ï¼š26.7B æ€»å‚æ•°ï¼Œ72 ä¸ªè·¯ç”±ä¸“å®¶ï¼Œæ¿€æ´» 6 ä¸ª/ tokenã€‚
  - **Engram-27B**ï¼šä¸ MoE-27B **åŒå‚æ•°ã€åŒ FLOPs**ï¼Œå‡å°‘ä¸“å®¶æ•°è‡³ 55ï¼Œè…¾å‡º 5.7B å‚æ•°ç”¨äº Engram è®°å¿†ã€‚
  - **Engram-40B**ï¼šè¿›ä¸€æ­¥æ‰©å¤§ Engram è‡³ 18.5B å‚æ•°ï¼Œæ€»å‚æ•°è¾¾ 39.5Bã€‚

- **ç»Ÿä¸€è®¾ç½®**ï¼š
  - æ‰€æœ‰æ¨¡å‹æ¿€æ´»å‚æ•°å‡ä¸º 3.8Bï¼Œè®­ç»ƒ 262B tokensã€‚
  - ä½¿ç”¨ MLAï¼ˆMulti-head Latent Attentionï¼‰å’Œ mHCï¼ˆmulti-branchï¼‰æ¶æ„ã€‚
  - Engram æ’å…¥ç¬¬ 2 å’Œ 15 å±‚ï¼Œæ”¯æŒ 2-gram å’Œ 3-gram æŸ¥æ‰¾ã€‚

- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - å‡†ç¡®ç‡ï¼ˆAcc.ï¼‰ã€F1ã€Exact Matchï¼ˆEMï¼‰ã€Pass@1ã€å›°æƒ‘åº¦ï¼ˆPPLï¼‰ç­‰ã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

- **Dense-4B**ï¼šåŸºç¡€å¯†é›†æ¨¡å‹ã€‚
- **MoE-27B**ï¼šä¸¥æ ¼åŒå‚æ•°ã€åŒ FLOPs çš„ MoE åŸºçº¿ã€‚
- **OverEncoding**ï¼ˆHuang et al., 2025aï¼‰ï¼šå°† N-gram åµŒå…¥ä¸è¯è¡¨åµŒå…¥å¹³å‡èåˆï¼Œä½œä¸ºå¼±è®°å¿†åŸºçº¿ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆEngram-27B vs MoE-27Bï¼‰**

| ä»»åŠ¡ç±»åˆ« | æŒ‡æ ‡ | MoE-27B | Engram-27B | æå‡ |
|--------|------|---------|------------|------|
| **çŸ¥è¯†** | MMLU (5-shot) | 57.4 | **60.4** | +3.0 |
| | CMMLU (5-shot) | 57.9 | **61.9** | +4.0 |
| | MMLU-Pro (5-shot) | 28.3 | **30.1** | +1.8 |
| **æ¨ç†** | BBH (3-shot) | 50.9 | **55.9** | **+5.0** |
| | ARC-Challenge (25-shot) | 70.1 | **73.8** | +3.7 |
| | DROP (1-shot) | 55.7 | **59.0** | +3.3 |
| **ä»£ç /æ•°å­¦** | HumanEval (0-shot) | 37.8 | **40.8** | +3.0 |
| | MATH (4-shot) | 28.3 | **30.7** | +2.4 |
| | GSM8K (8-shot) | 58.4 | **60.6** | +2.2 |

> âœ… **å…³é”®å‘ç°**ï¼šæå‡ä¸ä»…ä½“ç°åœ¨çŸ¥è¯†ä»»åŠ¡ï¼Œ**åœ¨æ¨ç†å’Œä»£ç /æ•°å­¦ä»»åŠ¡ä¸Šå¢ç›Šæ›´å¤§**ï¼Œè¡¨æ˜ Engram é‡Šæ”¾äº†æ¨¡å‹çš„æ·±å±‚æ¨ç†èƒ½åŠ›ã€‚

---

### **é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›ï¼ˆRULER åŸºå‡†ï¼‰**

| æ¨¡å‹ | Multi-Query NIAH | Variable Tracking |
|------|------------------|-------------------|
| MoE-27B | 84.2 | 77.0 |
| Engram-27B | **97.0** | **89.0** |

> â¬†ï¸ **æå‡æ˜¾è‘—**ï¼š+12.8 å’Œ +12.0ï¼Œè¡¨æ˜ Engram é‡Šæ”¾äº† Attention å®¹é‡ç”¨äºå…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

| æ¶ˆèå˜ä½“ | éªŒè¯æŸå¤±ï¼ˆâ†“ï¼‰ | åˆ†æ |
|--------|--------------|------|
| **MoE Baseline** | 1.808 | åŸºçº¿ |
| **+Engram (å®Œæ•´)** | **1.768** | â–³ = -0.040 |
| w/o Multi-Branch | 1.778 | åˆ†æ”¯èåˆé‡è¦ |
| w/o Token Compression | 1.775 | å½’ä¸€åŒ–æå‡è¯­ä¹‰å¯†åº¦ |
| w/o Context-aware Gating | 1.773 | é—¨æ§æœºåˆ¶æŠ‘åˆ¶å™ªå£° |
| w/o Short Conv | 1.768 | å½±å“è¾ƒå° |
| +4-gram | 1.770 | åœ¨å›ºå®šé¢„ç®—ä¸‹ä¸å¦‚ 2/3-gram æœ‰æ•ˆ |

> ğŸ” **æœ€ä½³æ’å…¥ä½ç½®**ï¼šç¬¬ 2 å±‚æ•ˆæœæœ€å¥½ï¼Œæ—©ä»‹å…¥å¯å°½æ—©å¸è½½å±€éƒ¨é‡å»ºä»»åŠ¡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **Conditional Memory æ˜¯æœ‰æ•ˆçš„ç¬¬äºŒç¨€ç–è½´**ï¼š
   - ä¸ MoE å½¢æˆäº’è¡¥ï¼Œé€šè¿‡ **Uå‹ç¼©æ”¾å¾‹** è¯æ˜æ··åˆåˆ†é…æœ€ä¼˜ã€‚
   - Engram-27B åœ¨åŒå‚æ•°ã€åŒ FLOPs ä¸‹å…¨é¢è¶…è¶Š MoE-27Bã€‚

2. **Engram æå‡çš„ä¸ä»…æ˜¯çŸ¥è¯†æ£€ç´¢ï¼Œæ›´æ˜¯æ¨ç†èƒ½åŠ›**ï¼š
   - é€šè¿‡ **LogitLens** å’Œ **CKA** åˆ†æå‘ç°ï¼ŒEngram ä½¿æ—©æœŸå±‚æ›´å¿«æ”¶æ•›ï¼ŒåŠŸèƒ½ä¸Šç­‰æ•ˆäºâ€œåŠ æ·±ç½‘ç»œâ€ã€‚
   - é‡Šæ”¾çš„ Attention å®¹é‡å¯ç”¨äºå¤„ç†é•¿è·ç¦»ä¾èµ–ã€‚

3. **ç³»ç»Ÿæ•ˆç‡ä¼˜è¶Š**ï¼š
   - å³ä½¿å°† 100B å‚æ•°çš„ Engram è¡¨å¸è½½åˆ° CPU å†…å­˜ï¼Œæ¨ç†ååä»…ä¸‹é™ **<3%**ã€‚
   - ç¡®å®šæ€§æŸ¥æ‰¾æ”¯æŒé¢„å–ï¼Œé€‚åˆå¤§è§„æ¨¡éƒ¨ç½²ã€‚

4. **åŠŸèƒ½äºŒåˆ†æ€§æ˜ç¡®**ï¼š
   - **äº‹å®çŸ¥è¯†ç±»ä»»åŠ¡**ï¼ˆå¦‚ TriviaQAï¼‰ä¸¥é‡ä¾èµ– Engramï¼Œç§»é™¤åæ€§èƒ½æš´è·Œè‡³ 29â€“44%ã€‚
   - **é˜…è¯»ç†è§£ç±»ä»»åŠ¡**ï¼ˆå¦‚ C3ï¼‰ä¸»è¦ä¾èµ– backboneï¼Œä¿ç•™ 81â€“93% æ€§èƒ½ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

- **è®°å¿†å®¹é‡å—é™äºå“ˆå¸Œå†²çª**ï¼šå°½ç®¡å¤šå¤´å“ˆå¸Œç¼“è§£ï¼Œæç«¯é«˜é¢‘/ä½é¢‘ N-gram ä»å¯èƒ½å½±å“ç²¾åº¦ã€‚
- **ä¾èµ–é«˜è´¨é‡ tokenizer compression**ï¼šè‹¥å½’ä¸€åŒ–è§„åˆ™ä¸å½“ï¼Œå¯èƒ½å¯¼è‡´è¯­ä¹‰æ··æ·†ã€‚
- **ç›®å‰ä»…é€‚ç”¨äºå±€éƒ¨æ¨¡å¼**ï¼šæ— æ³•å¤„ç†éœ€è¦åŠ¨æ€ç”Ÿæˆæˆ–å¤æ‚æ¨ç†çš„çŸ¥è¯†ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ¢ç´¢æ›´é«˜é˜¶ N-gram**ï¼ˆå¦‚ 4-gram+ï¼‰åœ¨æ›´å¤§å†…å­˜é¢„ç®—ä¸‹çš„æ½œåŠ›ã€‚
2. **ç»“åˆéå‚æ•°è®°å¿†**ï¼ˆå¦‚ RETROã€REALMï¼‰ï¼Œæ„å»ºæ··åˆè®°å¿†ç³»ç»Ÿã€‚
3. **åŠ¨æ€æ›´æ–°è®°å¿†è¡¨**ï¼Œæ”¯æŒçŸ¥è¯†æ¼”åŒ–ã€‚
4. **æ‰©å±•è‡³å¤šæ¨¡æ€åœºæ™¯**ï¼Œå®ç°è·¨æ¨¡æ€è®°å¿†æŸ¥æ‰¾ã€‚

---

## æ€»ç»“

âœ… **Engram** æˆåŠŸéªŒè¯äº† **conditional memory** ä½œä¸º LLM ç¨€ç–åŒ–çš„æ–°èŒƒå¼ï¼Œä¸ä»…æå‡äº†çŸ¥è¯†æ£€ç´¢æ•ˆç‡ï¼Œæ›´é€šè¿‡â€œè§£æ”¾æ—©æœŸå±‚â€å¢å¼ºäº†æ¨¡å‹çš„æ·±åº¦æ¨ç†èƒ½åŠ›ã€‚å…¶**ç¡®å®šæ€§ã€å¯é¢„å–ã€å¯å¸è½½**çš„è®¾è®¡ä½¿å…¶å…·å¤‡æå¼ºçš„å·¥ç¨‹è½åœ°æ½œåŠ›ï¼Œæœ‰æœ›æˆä¸ºä¸‹ä¸€ä»£ç¨€ç–å¤§æ¨¡å‹çš„æ ‡å‡†ç»„ä»¶ã€‚

</details>

---

### 10. [FROAV: A Framework for RAG Observation and Agent Verification - Lowering the Barrier to LLM Agent Research](https://arxiv.org/abs/2601.07504)

**Authors**: Tzu-Hsuan Lin, Chih-Hsuan Kao  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2601.07504v1  

#### Abstract
The rapid advancement of Large Language Models (LLMs) and their integration into autonomous agent systems has created unprecedented opportunities for document analysis, decision support, and knowledge retrieval. However, the complexity of developing, evaluating, and iterating on LLM-based agent work...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFROAV: A Framework for RAG Observation and Agent Verification â€“ Lowering the Barrier to LLM Agent Research

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†ç³»ç»Ÿçš„å¼€å‘ä¸è¯„ä¼°é¢ä¸´æ˜¾è‘—çš„æŠ€æœ¯é—¨æ§›ï¼Œå°¤å…¶æ˜¯åœ¨**å·¥ä½œæµç¼–æ’ã€å‘é‡æ•°æ®åº“ç®¡ç†ã€Promptå·¥ç¨‹ã€è¯„ä¼°æ–¹æ³•è®ºå’Œæ•°æ®åŸºç¡€è®¾æ–½**ç­‰æ–¹é¢ã€‚è¿™äº›é—®é¢˜å¯¹ç¼ºä¹è½¯ä»¶å·¥ç¨‹èƒŒæ™¯çš„é¢†åŸŸä¸“å®¶ï¼ˆå¦‚é‡‘èåˆ†æå¸ˆã€åŒ»å­¦ç ”ç©¶äººå‘˜ï¼‰æ„æˆäº†ä¸¥é‡éšœç¢ï¼Œé™åˆ¶äº†ä»–ä»¬åœ¨LLMä»£ç†ç³»ç»Ÿè®¾è®¡ä¸éªŒè¯ä¸­çš„å‚ä¸ã€‚

æ­¤å¤–ï¼Œç°æœ‰å·¥å…·è¦ä¹ˆéœ€è¦ä»é›¶æ„å»ºï¼ˆé«˜ä»£ç è´Ÿæ‹…ï¼‰ï¼Œä¾èµ–é—­æºå¹³å°ï¼ˆç¼ºä¹å¯å¤ç°æ€§ï¼‰ï¼Œæˆ–éœ€æ‰‹åŠ¨é›†æˆå¤šä¸ªç»„ä»¶ï¼ˆé›†æˆæˆæœ¬é«˜ï¼‰ï¼Œå¯¼è‡´ç ”ç©¶æ•ˆç‡ä½ä¸‹ä¸”éš¾ä»¥åä½œã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡ºäº† **FROAV**ï¼ˆFramework for RAG Observation and Agent Verificationï¼‰ï¼Œä¸€ä¸ªå¼€æºçš„ç ”ç©¶å¹³å°ï¼Œæ—¨åœ¨é€šè¿‡ä»¥ä¸‹æ–¹å¼é™ä½LLMä»£ç†ç ”ç©¶çš„é—¨æ§›ï¼š

- **å¯è§†åŒ–å·¥ä½œæµç¼–æ’**ï¼šé›†æˆ n8n å®ç°æ‹–æ‹½å¼æµç¨‹è®¾è®¡ï¼Œæ— éœ€ç¼–å†™åº•å±‚æ¶æ„ä»£ç ã€‚
- **å¤šç»´åº¦â€œLLM-as-a-Judgeâ€è¯„ä¼°æ¡†æ¶**ï¼šåœ¨å››ä¸ªç†è®ºé©±åŠ¨çš„ç»´åº¦ï¼ˆReliability, Completeness, Understandability, Relevanceï¼‰ä¸Šè¿›è¡Œè‡ªåŠ¨åŒ–è¯„ä¼°ï¼Œå¹¶é‡‡ç”¨å¤šæ¨¡å‹å…±è¯†æœºåˆ¶æå‡é²æ£’æ€§ã€‚
- **Human-in-the-Loopï¼ˆHITLï¼‰åé¦ˆç³»ç»Ÿ**ï¼šé€šè¿‡ Streamlit æ„å»ºå‰ç«¯ç•Œé¢ï¼Œæ”¯æŒé¢†åŸŸä¸“å®¶æä¾›ç»“æ„åŒ–åé¦ˆå¹¶ä¸è‡ªåŠ¨è¯„ä¼°ç»“æœå…³è”åˆ†æã€‚
- **ç»†ç²’åº¦æ•°æ®ç®¡ç†**ï¼šåŸºäº PostgreSQL å­˜å‚¨æ‰§è¡Œè½¨è¿¹ã€è¯„ä¼°ç»“æœå’Œäººç±»åé¦ˆï¼Œå®ç°å…¨æµç¨‹æº¯æºã€‚
- **å¯æ‰©å±•çš„Pythonåç«¯**ï¼šé€šè¿‡ FastAPI æ”¯æŒè‡ªå®šä¹‰é¢„å¤„ç†é€»è¾‘å’ŒMLç®¡é“é›†æˆã€‚
- **å®¹å™¨åŒ–éƒ¨ç½²**ï¼šä½¿ç”¨ Docker Compose å®ç°ä¸€é”®éƒ¨ç½²ï¼Œç¡®ä¿ç¯å¢ƒä¸€è‡´æ€§ä¸å¯å¤ç°æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆLangChain/LlamaIndexç­‰ï¼‰ | FROAV |
|------|-------------------------------|--------|
| å¼€å‘å¤æ‚åº¦ | é«˜ï¼ˆéœ€å¤§é‡Pythonç¼–ç ï¼‰ | æä½ï¼ˆè§†è§‰åŒ–æ“ä½œä¸ºä¸»ï¼‰ |
| è¯„ä¼°ä½“ç³» | é€šå¸¸ä¸ºå•ä¸€æŒ‡æ ‡æˆ–ç®€å•è‡ªåŠ¨åŒ– | å¤šç»´ã€å¤šæ¨¡å‹å…±è¯†ã€â€œLLM-as-a-Judgeâ€+äººå·¥ååŒ |
| å¯è®¿é—®æ€§ | è¦æ±‚å¼ºç¼–ç¨‹èƒ½åŠ› | é¢å‘é¢†åŸŸä¸“å®¶å‹å¥½ |
| æ•°æ®è¿½è¸ª | æ‰‹åŠ¨è®°å½•æˆ–ç¼ºå¤± | å…¨é“¾è·¯æ—¥å¿—ä¸æº¯æº |
| å¯æ‰©å±•æ€§ | é«˜ä½†éœ€è‡ªè¡Œå®ç° | åˆ†å±‚è®¾è®¡ï¼Œæ”¯æŒä»æ— ç åˆ°å…¨ä»£ç å®šåˆ¶ |
| åä½œæ”¯æŒ | å¼±ï¼ˆå·¥ç¨‹å¸ˆä¸»å¯¼ï¼‰ | å¼ºï¼ˆæ”¯æŒäººæœºååŒã€è·¨è§’è‰²åä½œï¼‰ |

> âœ… **æ ¸å¿ƒåˆ›æ–°**ï¼šå°† **RAG è§‚å¯Ÿ**ï¼ˆObservationï¼‰ä¸ **ä»£ç†éªŒè¯**ï¼ˆAgent Verificationï¼‰æ•´åˆäºç»Ÿä¸€å¹³å°ï¼Œé¦–æ¬¡å®ç°äº†â€œ**æ— éœ€å†™ä»£ç å³å¯å®Œæˆå®Œæ•´LLMä»£ç†å®éªŒé—­ç¯**â€çš„ç›®æ ‡ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
è®ºæ–‡è™½æœªå…¬å¼€å…·ä½“æ•°æ®é›†åç§°ï¼Œä½†æ˜ç¡®æŒ‡å‡ºå…¶åº”ç”¨åœºæ™¯ä¸º **é‡‘èæ–‡æ¡£åˆ†æ**ï¼Œç‰¹åˆ«æ˜¯ï¼š
- **SEC 10-K å’Œ 10-Q æ–‡ä»¶**ï¼ˆä¸Šå¸‚å…¬å¸å¹´æŠ¥ä¸å­£æŠ¥ï¼‰
- æ–‡æ¡£ä»¥ PDF å½¢å¼è¾“å…¥ï¼Œç»ç”± FastAPI åç«¯è§£æä¸ºç»“æ„åŒ–æ–‡æœ¬

è¯¥æ¡†æ¶è®¾è®¡ä¸º **material-agnostic**ï¼ˆææ–™æ— å…³ï¼‰ï¼Œé€‚ç”¨äºä»»ä½•éœ€è¦è¯­ä¹‰åˆ†æçš„é¢†åŸŸã€‚

### å®éªŒè®¾ç½®
- **RAG Pipeline è®¾è®¡**ï¼š
  1. PDF å†…å®¹è§£æï¼ˆCustom FastAPI Serviceï¼‰
  2. ææ–™åˆ†å—ï¼ˆChunkingï¼‰
  3. å‘é‡åŒ–ä¸å­˜å‚¨ï¼ˆé»˜è®¤ä½¿ç”¨ Supabase + pgvectorï¼‰
- **è¯„ä¼°æµç¨‹åµŒå…¥åœ¨æ¯ä¸ªç”Ÿæˆæ­¥éª¤ä¹‹å**ï¼Œå½¢æˆè¿­ä»£ä¼˜åŒ–é—­ç¯ã€‚

- **è¯„ä¼°æ¡†æ¶é…ç½®**ï¼š
  - æ¯ä¸ªè¾“å‡ºç”±å¤šä¸ª LLMï¼ˆå¦‚ GPT-4ã€Claudeã€Mixtral ç­‰ï¼‰ä½œä¸ºâ€œJudgeâ€ç‹¬ç«‹è¯„åˆ†
  - è¯„åˆ†ç»´åº¦ï¼šReliability, Completeness, Understandability, Relevance
  - é‡‡ç”¨ **ä¸­ä½æ•°èšåˆç­–ç•¥**ï¼ˆmedian aggregationï¼‰å‡å°‘å¼‚å¸¸å€¼å½±å“
  - æ¯ä¸ª Judge ä½¿ç”¨ä¸“é—¨è®¾è®¡çš„ system promptï¼ˆä¾‹å¦‚å¯é æ€§è¯„ä¼°å™¨è¢«è®¾å®šä¸ºâ€œè´¢åŠ¡å®¡è®¡å¸ˆâ€è§’è‰²ï¼‰

- **Human-in-the-Loop è®¾ç½®**ï¼š
  - é¢†åŸŸä¸“å®¶é€šè¿‡ Streamlit ç•Œé¢æŸ¥çœ‹æ¨¡å‹è¾“å‡ºä¸è‡ªåŠ¨è¯„åˆ†
  - æä¾›ç»“æ„åŒ–åé¦ˆï¼ˆæ‰“åˆ†+è¯„è®ºï¼‰ï¼Œå¹¶ä¸ LLM Judge ç»“æœå¯¹æ¯”åˆ†æ

### è¯„ä¼°æŒ‡æ ‡
| ç±»å‹ | æŒ‡æ ‡ |
|------|------|
| è‡ªåŠ¨åŒ–è¯„ä¼° | å››ä¸ªç»´åº¦çš„ LLM Judge å¾—åˆ†ï¼ˆ0â€“10åˆ†åˆ¶ï¼‰ï¼Œå¤šæ¨¡å‹ä¸€è‡´æ€§ |
| äººå·¥è¯„ä¼° | äººç±»ä¸“å®¶å¯¹åŒä¸€å››ä¸ªç»´åº¦çš„è¯„åˆ†ï¼Œinter-annotator agreement |
| ç³»ç»Ÿæ€§èƒ½ | å¼€å‘æ—¶é—´ã€ä»£ç è¡Œæ•°ã€å­¦ä¹ æ›²çº¿ï¼ˆå®šæ€§+å®šé‡ä¼°è®¡ï¼‰ |
| å¯¹é½æ€§åˆ†æ | LLM Judge è¯„åˆ† vs. Human Judgment çš„ç›¸å…³æ€§ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
è®ºæ–‡æœªç›´æ¥æ¯”è¾ƒä¸åŒ RAG æ¨¡å‹çš„å‡†ç¡®ç‡ï¼Œè€Œæ˜¯ä» **ç ”å‘æ•ˆç‡ä¸ç³»ç»Ÿå¯ç”¨æ€§è§’åº¦** è¿›è¡Œå¯¹æ¯”ï¼š

| åŸºçº¿æ–¹å¼ | FROAV |
|---------|-------|
| æ‰‹åŠ¨å¼€å‘å®Œæ•´RAG+è¯„ä¼°ç³»ç»Ÿï¼ˆLangChain + è‡ªå»ºå‰åç«¯ï¼‰ | ä½¿ç”¨FROAVæ¡†æ¶ï¼ˆn8n + FastAPI + Streamlit + PostgreSQLï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰
| æŒ‡æ ‡ | æ‰‹åŠ¨ç¼–ç  | FROAV æ¡†æ¶ |
|------|----------|------------|
| åŸºç¡€è®¾æ–½æ­å»ºæ—¶é—´ | 40â€“50 å°æ—¶ | ~1 å°æ—¶ï¼ˆå•æ¡ `docker-compose up`ï¼‰ |
| å·¥ä½œæµé€»è¾‘ä»£ç é‡ | >1000 è¡Œ Python | 0 è¡Œï¼ˆå¯è§†åŒ–æ‹–æ‹½ï¼‰ |
| è¯„ä¼°é€»è¾‘å®ç° | >1000 è¡Œï¼ˆå«å¤šæ¨¡å‹å…±è¯†ï¼‰ | é¢„ç½® â€œJudgeâ€ èŠ‚ç‚¹ |
| HITL æ¥å£å¼€å‘ | 80+ å°æ—¶ | 2 å°æ—¶ï¼ˆæ¨¡å—åŒ–é…ç½®ï¼‰ |
| å­¦ä¹ æ›²çº¿ | é«˜ï¼ˆéœ€èµ„æ·±å·¥ç¨‹å¸ˆï¼‰ | ä½ï¼ˆé¢†åŸŸä¸“å®¶å¯ä¸Šæ‰‹ï¼‰ |

> âš¡ï¸ **ç»“è®º**ï¼šFROAV å°†å…¸å‹ RAG å®éªŒç³»ç»Ÿçš„å¼€å‘å‘¨æœŸä» **æ•°å‘¨ç¼©çŸ­è‡³æ•°å°æ—¶**ï¼Œæå¤§æå‡äº†ç ”ç©¶è¿­ä»£é€Ÿåº¦ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨ç›¸åŒä»»åŠ¡ä¸‹ï¼ˆé‡‘èæŠ¥å‘Šç”Ÿæˆä¸éªŒè¯ï¼‰ï¼ŒFROAV å®ç°äº†ä¸æ‰‹åŠ¨ç¼–ç ç³»ç»Ÿ **åŒç­‰ç”šè‡³æ›´ä¼˜çš„åŠŸèƒ½å®Œæ•´æ€§**ï¼ŒåŒæ—¶ï¼š
  - å‡å°‘çº¦ **95% çš„åŸºç¡€è®¾æ–½ä»£ç **
  - æå‡ **å›¢é˜Ÿåä½œæ•ˆç‡**ï¼ˆé¢†åŸŸä¸“å®¶å¯ç›´æ¥å‚ä¸è¯„ä¼°ï¼‰
  - å®ç° **å…¨æµç¨‹é€æ˜æ—¥å¿—è®°å½•**ï¼Œä¾¿äºè°ƒè¯•ä¸å¤ç°

### æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰
è®ºæ–‡æœªæä¾›æ­£å¼æ¶ˆèå®éªŒï¼Œä½†åœ¨è®¨è®ºéƒ¨åˆ†æåŠä»¥ä¸‹è§‚å¯Ÿï¼š
- è‹¥å…³é—­ **multi-model consensus**ï¼ŒLLM Judge è¯„åˆ†æ³¢åŠ¨å¢å¤§ï¼ˆÂ±1.5 åˆ†ä»¥ä¸Šï¼‰ï¼Œå°¤å…¶åœ¨ Reliability ç»´åº¦
- è‹¥ç§»é™¤ **human-in-the-loop** æ¨¡å—ï¼Œåˆ™æ— æ³•è¯†åˆ«æŸäº›è¯­ä¹‰åå·®ï¼ˆå¦‚â€œçœ‹ä¼¼åˆç†ä½†äº‹å®é”™è¯¯â€çš„é™ˆè¿°ï¼‰
- ä½¿ç”¨é»˜è®¤ prompt çš„ Judge æ€§èƒ½ä½äºç»è¿‡è§’è‰²å®šåˆ¶çš„ Judgeï¼ˆå¦‚â€œä½ æ˜¯ä¸€åå®¡è®¡å¸ˆâ€ï¼‰

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **FROAV æ˜¾è‘—é™ä½äº†LLMä»£ç†ç ”ç©¶çš„å‡†å…¥é—¨æ§›**ï¼Œä½¿éç¨‹åºå‘˜çš„é¢†åŸŸä¸“å®¶ä¹Ÿèƒ½æ·±åº¦å‚ä¸ç³»ç»Ÿè®¾è®¡ä¸è¯„ä¼°ã€‚
2. **â€œLLM-as-a-Judgeâ€ç»“åˆå¤šæ¨¡å‹å…±è¯†æœºåˆ¶** èƒ½æœ‰æ•ˆæ¨¡æ‹Ÿäººç±»åˆ¤æ–­è¶‹åŠ¿ï¼Œåœ¨å››å¤§ç»´åº¦ä¸Šå…·æœ‰è¾ƒé«˜ä¸€è‡´æ€§ã€‚
3. **è‡ªåŠ¨åŒ–è¯„ä¼°ä¸äººå·¥åé¦ˆé«˜åº¦äº’è¡¥**ï¼šLLM Judges æ“…é•¿æ£€æµ‹äº‹å®é”™è¯¯ä¸å®Œæ•´æ€§ç¼ºå¤±ï¼›äººç±»ä¸“å®¶æ›´æ“…é•¿åˆ¤æ–­è¡¨è¾¾æ¸…æ™°åº¦ä¸å†³ç­–ç›¸å…³æ€§ã€‚
4. **å¯è§†åŒ–å·¥ä½œæµ + å®¹å™¨åŒ–éƒ¨ç½²** æå¤§å¢å¼ºäº†å®éªŒçš„å¯å¤ç°æ€§å’Œè·¨å›¢é˜Ÿå…±äº«èƒ½åŠ›ã€‚
5. FROAV çš„ **material-agnostic æ¶æ„** ä½¿å…¶ä¸ä»…é€‚ç”¨äºé‡‘èæ–‡æ¡£ï¼Œè¿˜å¯å¿«é€Ÿè¿ç§»åˆ°æ³•å¾‹ã€åŒ»ç–—ã€ç§‘ç ”ç­‰é¢†åŸŸã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. å½“å‰è¯„ä¼°ä»…æ¶µç›– **å››ä¸ªå›ºå®šç»´åº¦**ï¼Œå¯èƒ½ä¸è¶³ä»¥è¦†ç›–æ‰€æœ‰åº”ç”¨åœºæ™¯çš„éœ€æ±‚ã€‚
2. LLM Judge çš„è¯„ä¼°è´¨é‡ä¾èµ–äºæ‰€é€‰æ¨¡å‹çš„èƒ½åŠ›ä¸åè§ï¼Œä»å­˜åœ¨ **position biasã€verbosity bias** ç­‰é£é™©ã€‚
3. å°šæœªç»è¿‡ä¼ä¸šçº§å¤§è§„æ¨¡å‹åŠ›æµ‹è¯•ï¼ˆå¦‚ç™¾ä¸‡çº§æ–‡æ¡£æ£€ç´¢åœºæ™¯ï¼‰ã€‚
4. æµç¨‹çµæ´»æ€§å—é™äº n8n çš„èŠ‚ç‚¹èƒ½åŠ›å’Œè¡¨è¾¾èƒ½åŠ›ï¼Œæç«¯å¤æ‚çš„æ§åˆ¶æµä»éœ€ä»£ç ä»‹å…¥ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è¯„ä¼°ç»´åº¦**ï¼šå¼•å…¥æ›´å¤šé¢†åŸŸç‰¹å®šçš„è¯„ä¼°æ ‡å‡†ï¼ˆå¦‚åˆè§„æ€§ã€ä¼¦ç†å®¡æŸ¥ï¼‰ã€‚
2. **LLM Judge æ ¡å‡†ç ”ç©¶**ï¼šåˆ©ç”¨ FROAV å¹³å°ç³»ç»Ÿæ€§åœ°å¯¹æ¯” LLM è¯„åˆ†ä¸äººç±»ä¸“å®¶è¯„åˆ†çš„ç›¸å…³æ€§ï¼Œå»ºç«‹å¯ä¿¡çš„ calibration æ›²çº¿ã€‚
3. **å¢å¼ºè‡ªåŠ¨åŒ–åé¦ˆé—­ç¯**ï¼šè®©è¯„ä¼°ç»“æœåå‘é©±åŠ¨ prompt è°ƒä¼˜æˆ–æ£€ç´¢å‚æ•°è°ƒæ•´ï¼Œå®ç° self-improving agentã€‚
4. **æ”¯æŒæ›´å¤šå¯è§†åŒ–å·¥å…·é›†æˆ**ï¼šæ¢ç´¢ä¸ LangGraphã€Flowise ç­‰æ›¿ä»£æ–¹æ¡ˆçš„å…¼å®¹æ€§ã€‚
5. **å¼€æ”¾ç¤¾åŒºç”Ÿæ€å»ºè®¾**ï¼šé¼“åŠ±ç”¨æˆ·è´¡çŒ®é¢„è®¾ workflow templates å’Œ domain-specific judge promptsã€‚

---

> ğŸ”š **æ€»ç»“**ï¼šFROAV ä¸æ˜¯ä¸€ä¸ªè¿½æ±‚SOTAæ€§èƒ½çš„ç®—æ³•æ¨¡å‹ï¼Œè€Œæ˜¯ä¸€ä¸ªé¢å‘ **ç§‘å­¦ç ”ç©¶æ°‘ä¸»åŒ–** çš„åŸºç¡€è®¾æ–½åˆ›æ–°ã€‚å®ƒæˆåŠŸåœ°å°†å¤æ‚çš„ LLM agent å®éªŒæµç¨‹å°è£…æˆâ€œå³æ’å³ç”¨â€çš„ç ”ç©¶å¹³å°ï¼Œæ¨åŠ¨äº†ä»â€œåªæœ‰å·¥ç¨‹å¸ˆèƒ½åšLLMç ”ç©¶â€å‘â€œäººäººçš†å¯å‚ä¸â€çš„èŒƒå¼è½¬å˜ã€‚

</details>

---

### 11. [Land-then-transport: A Flow Matching-Based Generative Decoder for Wireless Image Transmission](https://arxiv.org/abs/2601.07512)

**Authors**: Jingwen Fu, Ming Xiao, Mikael Skoglund, Dong In Kim  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2601.07512v1  

#### Abstract
Due to strict rate and reliability demands, wireless image transmission remains difficult for both classical layered designs and joint source-channel coding (JSCC), especially under low latency. Diffusion-based generative decoders can deliver strong perceptual quality by leveraging learned image pri...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Land-then-transport: A Flow Matching-Based Generative Decoder for Wireless Image Transmission*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿæ— çº¿å›¾åƒä¼ è¾“é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **åˆ†å±‚è®¾è®¡ï¼ˆå¦‚ JPEG2000 + LDPCï¼‰** åœ¨æœ‰é™ç é•¿å’Œä½å»¶è¿Ÿåœºæ™¯ä¸‹æ€§èƒ½ä¸ä½³ï¼Œä¸”å¯¹ä¿¡é“å¤±é…æ•æ„Ÿï¼Œå­˜åœ¨â€œæ‚¬å´–æ•ˆåº”â€ã€‚
- **åŸºäºæ‰©æ•£æ¨¡å‹ï¼ˆdiffusion-basedï¼‰çš„ç”Ÿæˆè§£ç å™¨** è™½èƒ½æå‡æ„ŸçŸ¥è´¨é‡ï¼Œä½†ä¾èµ–æ•°ç™¾æ­¥çš„éšæœºå»å™ªè¿‡ç¨‹ï¼Œå¯¼è‡´**é«˜è§£ç å»¶è¿Ÿ**å’Œè®¡ç®—å¼€é”€ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶é€šä¿¡éœ€æ±‚ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º **Land-then-Transport (LTT)** çš„æ–°èŒƒå¼ï¼Œå¹¶æ„å»ºäº†ä¸€ä¸ªåŸºäº **Flow Matching (FM)** çš„ç¡®å®šæ€§ç”Ÿæˆè§£ç å™¨ï¼Œå…¶æ ¸å¿ƒæ€æƒ³å¦‚ä¸‹ï¼š

- **å°†ç‰©ç†ä¿¡é“åµŒå…¥ç”Ÿæˆæµä¸­**ï¼šå°†æ— çº¿ä¿¡é“ï¼ˆå¦‚ AWGNï¼‰çš„å™ªå£°æ•ˆåº”è§†ä¸ºè¿ç»­æ¦‚ç‡æµçš„ä¸€éƒ¨åˆ†ã€‚æ¥æ”¶ä¿¡å·è¢«è§†ä¸ºåœ¨æŸä¸ªâ€œç€é™†æ—¶é—´â€ $t^*$ ä¸Šçš„ä¸­é—´çŠ¶æ€ï¼Œè€Œéå¤–éƒ¨å™ªå£°æ±¡æŸ“ã€‚
- **Flow Matching æ„å»ºç¡®å®šæ€§ ODE è§£ç å™¨**ï¼š
  - ä¸º AWGN ä¿¡é“æ„é€ ä¸€æ¡**é«˜æ–¯å¹³æ»‘è·¯å¾„**ï¼ˆGaussian smoothing pathï¼‰ï¼Œå…¶å™ªå£°è°ƒåº¦ï¼ˆnoise scheduleï¼‰ä¸ä¿¡é“å™ªå£°æ°´å¹³å•è°ƒå¯¹åº”ã€‚
  - æ¨å¯¼å‡ºè¯¥è·¯å¾„ä¸Šçš„**é—­å¼è§£ææ•™å¸ˆé€Ÿåº¦åœº**ï¼ˆteacher velocity fieldï¼‰ã€‚
  - ä½¿ç”¨ **Conditional Flow Matching (CFM)** è®­ç»ƒä¸€ä¸ªæ·±åº¦ç¥ç»ç½‘ç»œä½œä¸ºå­¦ç”Ÿå‘é‡åœº $v_\theta(x, t)$ï¼Œå­¦ä¹ è¯¥é€Ÿåº¦åœºã€‚
  - è§£ç è¿‡ç¨‹å˜ä¸ºæ±‚è§£ä¸€ä¸ªä» $t^*$ åˆ° $t=1$ çš„**ç¡®å®šæ€§å¸¸å¾®åˆ†æ–¹ç¨‹ (ODE)**ï¼Œæ— éœ€éšæœºé‡‡æ ·ã€‚
- **ç»Ÿä¸€æ¡†æ¶é€‚ç”¨äºå¤šç§ä¿¡é“**ï¼š
  - é€šè¿‡ **Linear MMSE Equalization** å’Œ **SVD å¤„ç†**ï¼Œå¯å°† Rayleigh è¡°è½å’Œ MIMO ä¿¡é“è½¬æ¢ä¸ºç­‰æ•ˆçš„ AWGN ä¿¡é“ã€‚
  - ä»…éœ€è°ƒæ•´æœ‰æ•ˆå™ªå£°æ–¹å·®ä»¥ç¡®å®šæ–°çš„ç€é™†æ—¶é—´ $t^*$ï¼Œå³å¯å¤ç”¨åœ¨ AWGN ä¸Šè®­ç»ƒçš„åŒä¸€é€Ÿåº¦åœºï¼Œ**æ— éœ€é‡æ–°è®­ç»ƒ**ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **ä½å»¶è¿Ÿ**ï¼šè§£ç ä»…éœ€å°‘é‡ï¼ˆå¦‚ 10 æ­¥ï¼‰ç¡®å®šæ€§ ODE æ­¥éª¤ï¼Œè¿œå°‘äºæ‰©æ•£æ¨¡å‹æ‰€éœ€çš„æ•°åè‡³æ•°ç™¾æ­¥ã€‚
- **é«˜æ€§èƒ½**ï¼šåœ¨ PSNRã€MS-SSIM ç­‰æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•å’Œæ·±åº¦å­¦ä¹ åŸºçº¿ã€‚
- **é²æ£’æ€§å¼º**ï¼šåœ¨ä½ SNR ä¸‹æ€§èƒ½ä¸‹é™å¹³ç¼“ï¼Œæ— â€œæ‚¬å´–æ•ˆåº”â€ã€‚
- **é€šç”¨æ€§å¼º**ï¼šå•ä¸€æ¨¡å‹å¯é€‚åº” AWGNã€Rayleighã€MIMO ç­‰å¤šç§ä¿¡é“ã€‚
- **ç‰©ç†å¯è§£é‡Šæ€§**ï¼šLTT èŒƒå¼å°†ä¿¡é“å™ªå£°ä¸ç”ŸæˆæµåŠ¨æ€ç´§å¯†ç»“åˆï¼Œå…·æœ‰æ¸…æ™°çš„ç‰©ç†æ„ä¹‰ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **MNIST**ï¼š60,000 è®­ç»ƒ + 10,000 æµ‹è¯•ï¼Œ28Ã—28 ç°åº¦æ‰‹å†™æ•°å­—ã€‚
- **Fashion-MNIST**ï¼šåŒä¸Šï¼Œæœè£…å›¾åƒã€‚
- **DIV2K**ï¼š800 è®­ç»ƒ + 100 éªŒè¯ï¼Œè‡ªç„¶å›¾åƒï¼Œè£å‰ªä¸º 256Ã—256ã€‚

### å®éªŒè®¾ç½®
- **ä¿¡é“æ¨¡å‹**ï¼šAWGNã€Rayleigh è¡°è½ï¼ˆæ ‡é‡å¤æ•°ï¼‰ã€2Ã—2 MIMOã€‚
- **å¸¦å®½æ•ˆç‡**ï¼šå›ºå®šæ¯å¼ å›¾åƒçš„å¤æ•°ä¿¡é“ä½¿ç”¨æ¬¡æ•°ï¼ˆcomplex channel usesï¼‰ï¼Œç¡®ä¿ä¸åŸºçº¿å…¬å¹³æ¯”è¾ƒã€‚
- **æ¨¡å‹æ¶æ„**ï¼šå­¦ç”Ÿé€Ÿåº¦åœº $v_\theta$ é‡‡ç”¨ U-Net ç»“æ„ï¼ˆè§ Table Iï¼‰ï¼ŒåŒ…å«æ®‹å·®å—ã€è‡ªæ³¨æ„åŠ›æœºåˆ¶å’Œæ—¶é—´åµŒå…¥ã€‚
- **è®­ç»ƒç»†èŠ‚**ï¼š
  - æœ€å¤§å™ªå£°æ°´å¹³ $\sigma_{\text{max}} = 1.0$ã€‚
  - æ‰¹å¤§å°ï¼šMNIST/Fashion-MNIST ä¸º 64ï¼ŒDIV2K ä¸º 32ã€‚
  - å­¦ä¹ ç‡ï¼š$1 \times 10^{-3}$ï¼Œè®­ç»ƒ 50 è½®ã€‚
  - ODE æ­¥æ•°ï¼šé»˜è®¤ 10 æ­¥ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **PSNR**ï¼šè¡¡é‡åƒç´ çº§ä¿çœŸåº¦ï¼Œè¶Šé«˜è¶Šå¥½ã€‚
- **MS-SSIM**ï¼šå¤šå°ºåº¦ç»“æ„ç›¸ä¼¼æ€§ï¼Œåæ˜ è§†è§‰æ„ŸçŸ¥è´¨é‡ï¼Œè¶Šé«˜è¶Šå¥½ã€‚
- **LPIPS**ï¼šåŸºäºæ·±åº¦ç‰¹å¾çš„æ„ŸçŸ¥è·ç¦»ï¼Œè¶Šä½è¶Šå¥½ã€‚
- **$\Delta$PSNR**ï¼šé‡å»ºå›¾åƒç›¸å¯¹äºç›´æ¥æ¥æ”¶çš„å™ªå£°å›¾åƒçš„ PSNR å¢ç›Šã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **JPEG2000 + LDPC**ï¼šä¼ ç»Ÿåˆ†ç¦»å¼ç¼–ç æ–¹æ¡ˆã€‚
- **DeepJSCC**ï¼šç«¯åˆ°ç«¯æ·±åº¦è”åˆä¿¡æºä¿¡é“ç¼–ç ã€‚
- **CDDM**ï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆè§£ç å™¨ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ DIV2K åœ¨ SNR=20 dB ä¸ºä¾‹ï¼‰
- **AWGN ä¿¡é“**ï¼š
  - ç›¸æ¯” CDDMï¼šPSNR æå‡ **26.6%**ï¼ŒMS-SSIM æå‡ **53.2%**ã€‚
  - ç›¸æ¯” DeepJSCCï¼šPSNR æå‡ **28.3%**ï¼ŒMS-SSIM æå‡ **59.6%**ã€‚
- **Rayleigh è¡°è½ä¿¡é“**ï¼š
  - ç›¸æ¯” CDDMï¼šPSNR æå‡ **19.4%**ï¼ŒMS-SSIM æå‡ **48.7%**ã€‚
  - ç›¸æ¯” DeepJSCCï¼šPSNR æå‡ **20.7%**ï¼ŒMS-SSIM æå‡ **50.8%**ã€‚
- **ä¸ JPEG2000+LDPC å¯¹æ¯”**ï¼š
  - åœ¨ AWGN ä¸‹ PSNR/MS-SSIM æå‡ **16.9%/24.9%**ã€‚
  - åœ¨ Rayleigh ä¸‹æå‡ **9.9%/13.1%**ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **æ€§èƒ½å…¨é¢é¢†å…ˆ**ï¼šåœ¨æ‰€æœ‰æ•°æ®é›†ï¼ˆMNISTã€Fashion-MNISTã€DIV2Kï¼‰å’Œæ‰€æœ‰ä¿¡é“ï¼ˆAWGNã€Rayleighã€MIMOï¼‰ä¸Šï¼ŒLTT è§£ç å™¨åœ¨ PSNRã€MS-SSIMã€LPIPS ç­‰æŒ‡æ ‡ä¸Šå‡ä¸€è‡´ä¼˜äºæ‰€æœ‰åŸºçº¿ã€‚
- **æŠ—â€œæ‚¬å´–æ•ˆåº”â€**ï¼šJPEG2000+LDPC åœ¨ä½ SNR ä¸‹æ€§èƒ½æ€¥å‰§ä¸‹é™ï¼Œè€Œ LTT æ€§èƒ½éš SNR æå‡æŒç»­æ”¹å–„ã€‚
- **æ„ŸçŸ¥è´¨é‡ä¼˜è¶Š**ï¼šè§†è§‰å¯¹æ¯”ï¼ˆFig. 5ï¼‰æ˜¾ç¤ºï¼ŒLTT é‡å»ºå›¾åƒè¾¹ç¼˜æ›´é”åˆ©ã€çº¹ç†æ›´å¹²å‡€ã€å‡ ä½•ç»†èŠ‚æ›´å¿ å®ï¼Œè€Œ DeepJSCC æ¨¡ç³Šä¸¥é‡ï¼ŒJPEG2000+LDPC å­˜åœ¨å‹ç¼©ä¼ªå½±ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **ODE æ­¥æ•°å½±å“ï¼ˆTable Vï¼‰**ï¼š
  - å½“ ODE æ­¥æ•°ä» 2 å¢åŠ åˆ° 10 æ—¶ï¼ŒPSNR å’Œ MS-SSIM æ˜¾è‘—æå‡ã€‚
  - æ­¥æ•°è¶…è¿‡ 10 åï¼Œæ€§èƒ½æå‡è¶‹äºé¥±å’Œï¼ˆPSNR æ³¢åŠ¨åœ¨ 30.1â€“30.5 dBï¼‰ï¼Œä½†æ¨ç†å»¶è¿Ÿå‡ ä¹çº¿æ€§å¢é•¿ï¼ˆä» 0.18s åˆ° 1.80sï¼‰ã€‚
  - **ç»“è®º**ï¼š10 æ­¥æ˜¯ç²¾åº¦ä¸æ•ˆç‡çš„æœ€ä½³å¹³è¡¡ç‚¹ã€‚
- **è°ƒåº¦å™¨åˆ†æï¼ˆTable VIï¼‰**ï¼š
  - ç€é™†æ—¶é—´ $t^*$ ä¸ SNR å‘ˆå•è°ƒå…³ç³»ï¼šSNR è¶Šé«˜ï¼Œ$t^*$ è¶Šå¤§ï¼ˆå³èµ·å§‹ç‚¹è¶Šæ¥è¿‘å¹²å‡€å›¾åƒï¼‰ã€‚
  - è¿™éªŒè¯äº† LTT èŒƒå¼çš„æœ‰æ•ˆæ€§ï¼Œå®ç°äº†ä¿¡é“æ¡ä»¶ä¸ç”ŸæˆåŠ¨åŠ›å­¦ä¹‹é—´çš„åŸåˆ™æ€§é“¾æ¥ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **LTT èŒƒå¼æœ‰æ•ˆ**ï¼šå°†ç‰©ç†ä¿¡é“è§†ä¸ºç”Ÿæˆæµä¸­çš„â€œç€é™†â€æ­¥éª¤ï¼Œèƒ½å¤Ÿç´§å¯†è€¦åˆä¿¡é“ç‰¹æ€§ä¸ç”Ÿæˆå…ˆéªŒï¼Œå®ç°é«˜æ•ˆè§£ç ã€‚
2. **FM æ›¿ä»£æ‰©æ•£æ¨¡å‹**ï¼šåŸºäº Flow Matching çš„ç¡®å®šæ€§ ODE è§£ç å™¨åœ¨ä¿æŒç”šè‡³è¶…è¶Šæ‰©æ•£æ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œå¤§å¹…é™ä½äº†è®¡ç®—å¤æ‚åº¦å’Œè§£ç å»¶è¿Ÿã€‚
3. **ç»Ÿä¸€è§£ç æ¡†æ¶å¯è¡Œ**ï¼šé€šè¿‡ MMSE é¢„å¤„ç†ï¼Œå¯å°†å¤šç§çº¿æ€§é«˜æ–¯ä¿¡é“ï¼ˆRayleigh, MIMOï¼‰ç»Ÿä¸€ä¸º AWGN ç­‰æ•ˆå½¢å¼ï¼Œä»è€Œå¤ç”¨åŒä¸€è®­ç»ƒå¥½çš„è§£ç å™¨ï¼Œå®ç°è·¨ä¿¡é“æ³›åŒ–ã€‚
4. **ç†è®ºä¸€è‡´æ€§**ï¼šåœ¨æ ‡é‡é«˜æ–¯ä¿¡é“ä¸‹ï¼ŒLTT è§£ç å™¨é€€åŒ–ä¸ºä¸€ç§çº¿æ€§ä¼°è®¡å™¨ï¼Œåœ¨é«˜ SNR ä¸‹æ¸è¿‘æœ€ä¼˜ï¼Œä¸ç»å…¸ä¼°è®¡ç†è®ºä¸€è‡´ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ– MMSE é¢„å¤„ç†**ï¼šå¯¹äºéçº¿æ€§æˆ–éé«˜æ–¯ä¿¡é“ï¼Œå½“å‰æ¡†æ¶å¯èƒ½éœ€è¦é¢å¤–çš„é€‚é…æ¨¡å—ã€‚
- **è®­ç»ƒå‡è®¾**ï¼šè™½ç„¶è§£ç å™¨å¯æ³›åŒ–ï¼Œä½†è®­ç»ƒä»åŸºäº AWGN å‡è®¾ï¼Œè‹¥ä¿¡é“å·®å¼‚è¿‡å¤§ï¼Œæ€§èƒ½å¯èƒ½å—é™ã€‚
- **è®¡ç®—æˆæœ¬ä»å­˜**ï¼šå°½ç®¡æ¯”æ‰©æ•£æ¨¡å‹å¿«ï¼Œä½† ODE æ±‚è§£ä»æ¶‰åŠå¤šæ¬¡ç¥ç»ç½‘ç»œå‰å‘ä¼ æ’­ï¼Œå¯¹æä½åŠŸè€—è®¾å¤‡ä»æœ‰æŒ‘æˆ˜ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† LTT æ¡†æ¶æ‰©å±•è‡³éçº¿æ€§ä¿¡é“æˆ–æ›´å¤æ‚çš„ä¿¡é“æ¨¡å‹ã€‚
- æ¢ç´¢æ›´é«˜æ•ˆçš„ ODE æ±‚è§£å™¨æˆ–éšå¼å»ºæ¨¡æ–¹æ³•ä»¥è¿›ä¸€æ­¥é™ä½å»¶è¿Ÿã€‚
- ç ”ç©¶å‘å°„ç«¯çš„è”åˆä¼˜åŒ–ï¼Œå®ç°çœŸæ­£çš„ç«¯åˆ°ç«¯ LTT é€šä¿¡ç³»ç»Ÿã€‚
- æ¢ç´¢åœ¨è§†é¢‘ä¼ è¾“æˆ–å…¶ä»–æ¨¡æ€ï¼ˆå¦‚è¯­éŸ³ï¼‰ä¸­çš„åº”ç”¨ã€‚

</details>

---

### 12. [TeleMem: Building Long-Term and Multimodal Memory for Agentic AI](https://arxiv.org/abs/2601.06037)

**Authors**: Chunliang Chen, Ming Guan, Xiao Lin, Jiaxu Li, Qiyi Wang, Xiangyu Chen, Jixiang Luo, Changzhi Sun, Dell Zhang, Xuelong Li  
**Category**: cs.CL  
**Published**: 2026-01-13  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.06037v1  

#### Abstract
Large language models (LLMs) excel at many NLP tasks but struggle to sustain long-term interactions due to limited attention over extended dialogue histories. Retrieval-augmented generation (RAG) mitigates this issue but lacks reliable mechanisms for updating or refining stored memories, leading to ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**TELEMEM: Building Long-Term and Multimodal Memory for Agentic AI**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰åŸºäº **Retrieval-Augmented Generation (RAG)** çš„é•¿æœŸè®°å¿†ç³»ç»Ÿåœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
1. **ç”¨æˆ·ç”»åƒä¸ä¸€è‡´**ï¼šä¾èµ–é¢„å®šä¹‰ schema çš„æ–¹æ³•å®¹æ˜“äº§ç”Ÿ **schema-driven hallucinations**ï¼ˆå³æ¨¡å‹è™šæ„æœªæåŠçš„ä¿¡æ¯ï¼‰ï¼Œä¸”éš¾ä»¥å¤„ç†ç¨€ç–å¯¹è¯ä¿¡æ¯ã€‚
2. **å†™å…¥æ•ˆç‡ä½ä¸‹**ï¼šæ¯è½®å¯¹è¯éƒ½è§¦å‘æ£€ç´¢å’Œå†³ç­–æµç¨‹ï¼Œå¯¼è‡´é¢‘ç¹çš„ API è°ƒç”¨ã€é«˜å»¶è¿Ÿå’Œä½ååé‡ã€‚
3. **å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›å¼±**ï¼šå¤§å¤šæ•°ç³»ç»Ÿä»…æ”¯æŒæ–‡æœ¬è®°å¿†ï¼Œæ— æ³•æœ‰æ•ˆæ•´åˆè§†é¢‘ç­‰éæ–‡æœ¬æ¨¡æ€ä¿¡æ¯è¿›è¡Œé•¿æœŸæ¨ç†ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
ä½œè€…æå‡º **TELEMEM** â€”â€” ä¸€ä¸ªç»Ÿä¸€çš„ã€æ”¯æŒé•¿æ—¶ç¨‹ä¸å¤šæ¨¡æ€çš„è®°å¿†ç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰**å™äº‹åŠ¨æ€æå–æœºåˆ¶ï¼ˆNarrative Dynamic Extractionï¼‰**
- ä¸ä¾èµ–å›ºå®š schemaï¼Œè€Œæ˜¯ä»å¯¹è¯ä¸­æå–â€œä»…ç”±å¯¹è¯æ”¯æ’‘â€çš„å™è¿°å•å…ƒä½œä¸ºè®°å¿†æ¡ç›®ã€‚
- é¿å…äº†å¯¹ç”¨æˆ·å±æ€§çš„æ— ä¾æ®æ¨æ–­ï¼ˆhallucinationï¼‰ï¼Œç¡®ä¿è®°å¿†çœŸå®å¯é ã€‚
- æ”¯æŒè§’è‰²ç‰¹å®šï¼ˆrole-specificï¼‰çš„ profile memoryï¼ˆå¦‚ `Muser` å’Œ `Mbot`ï¼‰ï¼Œæå‡ä¸ªæ€§åŒ–å»ºæ¨¡èƒ½åŠ›ã€‚

#### ï¼ˆ2ï¼‰**ç»“æ„åŒ–å†™å…¥æµæ°´çº¿ï¼ˆStructured Writing Pipelineï¼‰**
é‡‡ç”¨å››é˜¶æ®µæ‰¹å¤„ç†æµç¨‹æ¥æ„å»ºäº‹ä»¶è®°å¿†ï¼ˆevent memoryï¼‰ï¼š
1. **Summarization**ï¼šå°†æ¯è½®å¯¹è¯æ‘˜è¦ä¸ºè‹¥å¹²æ–‡æœ¬ç‰‡æ®µï¼›
2. **Retrieval**ï¼šå¯¹æ¯ä¸ªæ‘˜è¦æ£€ç´¢ç›¸å…³å†å²è®°å¿†ï¼›
3. **Clustering**ï¼šå…¨å±€èšç±»è¯­ä¹‰ç›¸ä¼¼çš„è®°å¿†é¡¹ï¼›
4. **Decision**ï¼šç”± LLM å¯¹æ¯ä¸ªèšç±»å†³å®š `add/delete/update/no-op` æ“ä½œã€‚

> âš¡ ä¼˜åŠ¿ï¼šæ˜¾è‘—å‡å°‘å†—ä½™å†™å…¥ã€é™ä½ token å¼€é”€ã€æé«˜å­˜å‚¨æ•ˆç‡ï¼Œå¹¶å®ç°æ›´è¿è´¯çš„è®°å¿†æ•´åˆã€‚

#### ï¼ˆ3ï¼‰**å¤šæ¨¡æ€è®°å¿†æ¨¡å— + ReAct-style Reasoning**
- å°†è§†é¢‘æµåˆ‡åˆ†ä¸º 10 ç§’ç‰‡æ®µï¼Œç”Ÿæˆä¸¤ç§è®°å¿†ï¼š
  - **Event Memory**ï¼šVLM è‡ªåŠ¨ç”Ÿæˆå­—å¹•æè¿°äº‹ä»¶ï¼›
  - **Key-Value Object Memory**ï¼šè®°å½•äººç‰©/ç‰©ä½“çš„èº«ä»½ä¸çŠ¶æ€å˜åŒ–ã€‚
- å¼•å…¥ **ReAct-style agent** è¿›è¡Œå¤šæ¨¡æ€è¯»å–ï¼Œæ”¯æŒä¸‰ç§å·¥å…·è°ƒç”¨ï¼š
  - `video.retrieval`ï¼šå®šä½ç›¸å…³è§†é¢‘æ—¶é—´æ®µï¼›
  - `video.rag`ï¼šåŸºäºæ–‡æœ¬è®°å¿†å›ç­”é—®é¢˜ï¼›
  - `video.qa`ï¼šåœ¨æŒ‡å®šè§†é¢‘ç‰‡æ®µä¸Šæ‰§è¡Œè§†è§‰é—®ç­”ï¼ˆVQAï¼‰ã€‚

> ğŸ” å®ç°äº†å®Œæ•´çš„ **observe-think-act** å¾ªç¯ï¼Œé€‚ç”¨äºå¤æ‚è§†é¢‘å†…å®¹çš„é•¿æœŸç†è§£ä»»åŠ¡ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **ZH-4O Benchmark**ï¼š
  - åŒ…å« 28 åœºçœŸå®çš„ä¸­æ–‡äººæœºè§’è‰²æ‰®æ¼”å¯¹è¯ï¼›
  - å¹³å‡æ¯åœºçº¦ 600 è½®å¯¹è¯ï¼›
  - æä¾› 1,068 ä¸ªé€‰æ‹©é¢˜ç”¨äºæµ‹è¯•è®°å¿†å¬å›èƒ½åŠ›ï¼ˆprobing questionsï¼‰ã€‚

### ğŸ§ª å®éªŒè®¾ç½®
- æ‰€æœ‰æ–¹æ³•å‡ä½¿ç”¨ **Qwen3-8B** ä½œä¸º backbone LLMï¼›
- å‘é‡è¡¨ç¤ºä½¿ç”¨ **Qwen3-8B-embedding**ï¼›
- ç»Ÿä¸€ prompt æ¨¡æ¿ä»¥æ§åˆ¶å˜é‡ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
- **QA Accuracy (%)**ï¼šåœ¨ ZH-4O ä¸Šçš„é€‰æ‹©é¢˜å‡†ç¡®ç‡ï¼›
- **Token Usage**ï¼šæ€»è¾“å…¥è¾“å‡º token æ•°é‡ï¼›
- **Speed (Throughput)**ï¼šå†…å­˜æ“ä½œé€Ÿåº¦ï¼ˆå€æ•°åŠ é€Ÿï¼‰ã€‚

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | æ–¹æ³• |
|------|------|
| åŸºç¡€èŒƒå¼ | `Long context LLM`, `RAG` |
| å…ˆè¿›è®°å¿†ç³»ç»Ÿ | `Mem0`, `Memobase`, `A-Mem`, `MOOM` |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š æ€§èƒ½å¯¹æ¯”ï¼ˆZH-4O ä¸Šçš„ QA Accuracyï¼‰
| æ–¹æ³• | å‡†ç¡®ç‡ (%) |
|------|-----------|
| RAG | 62.45 |
| Mem0 | 70.20 |
| MOOM | 72.60 |
| A-Mem | 73.78 |
| Memobase | 76.78 |
| Long context LLM | 84.92 |
| **TELEMEM (Ours)** | **86.33** âœ… |

> ğŸ’¡ **ç»“è®º**ï¼šTELEMEM åœ¨æ‰€æœ‰æ–¹æ³•ä¸­è¡¨ç°æœ€ä½³ï¼Œè¶…è¶Šäº†ç›´æ¥ä½¿ç”¨å®Œæ•´ä¸Šä¸‹æ–‡çš„ `Long context LLM`ï¼Œè¯´æ˜å…¶è®°å¿†å‹ç¼©ä¸æ£€ç´¢æœºåˆ¶ä¼˜äºåŸå§‹æ—¥å¿—å›æ”¾ã€‚

### âš™ï¸ æ•ˆç‡ä¸é€Ÿåº¦ä¼˜åŠ¿
- ç›¸æ¯” **Mem0**ï¼š
  - **å‡†ç¡®ç‡æå‡ 19%**ï¼ˆç›¸å¯¹æå‡ï¼‰ï¼›
  - **token ä½¿ç”¨å‡å°‘ 43%**ï¼›
  - **è¿è¡Œé€Ÿåº¦å¿« 2.1Ã—**ã€‚

> ğŸ“‰ è¡¨æ˜ TELEMEM åœ¨ä¿æŒæ›´é«˜æ€§èƒ½çš„åŒæ—¶ï¼Œå¤§å¹…ä¼˜åŒ–äº†èµ„æºæ¶ˆè€—å’Œå“åº”å»¶è¿Ÿã€‚

### ğŸ” æ¶ˆèå®éªŒï¼ˆæ–‡ä¸­è™½æœªå•ç‹¬åˆ—å‡ºè¡¨æ ¼ï¼Œä½†å¯é€šè¿‡åˆ†æå¾—å‡ºï¼‰
- **Narrative extraction** â†’ æ˜¾è‘—é™ä½ hallucinationï¼Œæå‡ profile memory å¯é æ€§ï¼›
- **Batched writing pipeline** â†’ å‡å°‘é‡å¤å†™å…¥ï¼Œæå‡ä¸€è‡´æ€§ï¼›
- **Multimodal ReAct agent** â†’ æ”¯æŒç»†ç²’åº¦è§†é¢‘ç†è§£ï¼Œåœ¨éœ€è¦è§†è§‰ grounding çš„ä»»åŠ¡ä¸­è¡¨ç°ä¼˜è¶Šã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **ä¼ ç»Ÿ RAG ç¼ºä¹æ›´æ–°æœºåˆ¶**ï¼Œéš¾ä»¥åº”å¯¹ç”¨æˆ·åå¥½æ¼”åŒ–ï¼›è€Œ TELEMEM çš„é—­ç¯å†™å…¥æµç¨‹æ”¯æŒåŠ¨æ€è®°å¿†ç»´æŠ¤ã€‚
2. **schema-free çš„ narrative extraction æ›´çµæ´»ã€æ›´çœŸå®**ï¼Œé¿å…äº†å¼ºåˆ¶å¡«å……å­—æ®µå¸¦æ¥çš„é”™è¯¯ã€‚
3. **æ‰¹å¤„ç† + èšç±» + å†³ç­–æµæ°´çº¿** æå¤§æå‡äº†å†™å…¥æ•ˆç‡å’Œè®°å¿†è´¨é‡ã€‚
4. **å¤šæ¨¡æ€è®°å¿† + ReAct å·¥å…·è°ƒç”¨** æˆåŠŸå®ç°äº†å¯¹é•¿è§†é¢‘å†…å®¹çš„ç²¾å‡†è§‚å¯Ÿä¸æ¨ç†ã€‚

### âš ï¸ å±€é™æ€§
- å½“å‰å¤šæ¨¡æ€éƒ¨åˆ†ä¸»è¦ä¾èµ– VLM å­—å¹•ç”Ÿæˆï¼Œå¯èƒ½ä¸¢å¤±ç»†èŠ‚ï¼›
- è§†é¢‘åˆ†æ®µç­–ç•¥ï¼ˆ10ç§’ï¼‰å¯èƒ½å‰²è£‚è¿ç»­åŠ¨ä½œï¼›
- å†™å…¥å†³ç­–ä»ä¾èµ– LLM åˆ¤æ–­ï¼Œå­˜åœ¨è¯¯åˆ /è¯¯æ›´é£é™©ï¼›
- å°šæœªå…¬å¼€å¤§è§„æ¨¡è·¨åœºæ™¯éªŒè¯ï¼ˆå¦‚å®¢æœã€æ•™è‚²ç­‰ï¼‰ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢å¯å­¦ä¹ çš„è®°å¿†è¡°å‡æœºåˆ¶ï¼ˆforgetting curveï¼‰ï¼›
- å¼•å…¥å‚æ•°åŒ–è®°å¿†ï¼ˆparametric memoryï¼‰ä¸éå‚æ•°åŒ–ç»“åˆï¼›
- æ‰©å±•è‡³éŸ³é¢‘ã€ä¼ æ„Ÿå™¨ç­‰æ›´å¤šæ¨¡æ€ï¼›
- æ”¯æŒå¤šæ™ºèƒ½ä½“ååŒè®°å¿†å…±äº«ä¸å†²çªè§£å†³ã€‚

---

## âœ… æ€»ç»“
**TELEMEM** æ˜¯ä¸€ç§é¢å‘ Agent AI çš„æ–°å‹ç»Ÿä¸€è®°å¿†æ¶æ„ï¼Œé€šè¿‡ï¼š
- **å™äº‹é©±åŠ¨çš„è®°å¿†æå–**
- **é«˜æ•ˆçš„æ‰¹å¤„ç†å†™å…¥ç®¡é“**
- **æ”¯æŒ ReAct çš„å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›**

æˆåŠŸè§£å†³äº†ç°æœ‰è®°å¿†ç³»ç»Ÿçš„ä¸‰å¤§ç—›ç‚¹ï¼Œåœ¨ **å‡†ç¡®æ€§ã€æ•ˆç‡ã€é€Ÿåº¦** ä¸‰ä¸ªç»´åº¦å…¨é¢è¶…è¶Šä¸»æµåŸºçº¿ï¼ˆå°¤å…¶æ˜¯ Mem0ï¼‰ã€‚å…¶å®éªŒç»“æœè¯æ˜äº†ç»“æ„åŒ–ã€åŠ¨æ€ã€å¤šæ¨¡æ€è®°å¿†å¯¹äºæ„å»ºå¯æŒç»­äº¤äº’ AI çš„å…³é”®ä½œç”¨ï¼Œä¸ºä¸‹ä¸€ä»£ Agentic AI çš„é•¿æœŸè®¤çŸ¥èƒ½åŠ›æä¾›äº†é‡è¦åŸºç¡€è®¾æ–½ã€‚

</details>

---

### 13. [Learning Minimally-Congested Drive Times from Sparse Open Networks: A Lightweight RF-Based Estimator for Urban Roadway Operations](https://arxiv.org/abs/2601.06124)

**Authors**: Adewumi Augustine Adepitan, Christopher J. Haruna, Morayo Ogunsina, Damilola Olawoyin Yussuf, Ayooluwatomiwa Ajiboye  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.06124v1  

#### Abstract
Accurate roadway travel-time prediction is foundational to transportation systems analysis, yet widespread reliance on either data-intensive congestion models or overly na\"ive heuristics limits scalability and practical adoption in engineering workflows. This paper develops a lightweight estimator ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Learning Minimally-Congested Drive Times from Sparse Open Networks: A Lightweight RF-Based Estimator for Urban Roadway Operations*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰äº¤é€šå·¥ç¨‹ä¸­ï¼Œ**travel time prediction** å­˜åœ¨æ˜¾è‘—çš„æ–¹æ³•è®ºé¸¿æ²Ÿï¼š
- **é«˜ç²¾åº¦æ–¹æ³•**ï¼ˆå¦‚åŸºäºå¤§è§„æ¨¡GPSã€æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼‰è™½ç„¶å‡†ç¡®ï¼ˆMAPE 3%-17%ï¼‰ï¼Œä½†ä¾èµ–æ˜‚è´µçš„ä¸“æœ‰æ•°æ®å’Œå¤§é‡è®¡ç®—èµ„æºï¼Œéš¾ä»¥æ™®åŠï¼›
- **ç®€åŒ–æ–¹æ³•**ï¼ˆå¦‚åŸºäºEuclideanè·ç¦»æˆ–speed-limit traversal timeï¼‰è™½æ˜“äºå®æ–½ï¼Œå´å› å¿½ç•¥ä¿¡å·ç¯ã€è½¬å‘ã€äº¤å‰å£å»¶è¯¯ç­‰å› ç´ ï¼Œç³»ç»Ÿæ€§ä½ä¼°å®é™…å‡ºè¡Œæ—¶é—´ï¼ˆMAPE > 20%ï¼‰ï¼Œå½±å“è§„åˆ’å†³ç­–ã€‚

è¯¥è®ºæ–‡æ—¨åœ¨å¡«è¡¥è¿™ä¸€â€œä¸­é—´åœ°å¸¦â€â€”â€”æå‡ºä¸€ç§**æ—¢å‡†ç¡®åˆè½»é‡ã€å¯å¹¿æ³›éƒ¨ç½²çš„å‡ºè¡Œæ—¶é—´é¢„æµ‹æ–¹æ³•**ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§åŸºäº **Random Forest (RF)** çš„è½»é‡çº§å›å½’æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹åŸå¸‚é“è·¯ç½‘ä¸­çš„ **minimally-congested car travel times**ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> åˆ©ç”¨ **sparse open network data**ï¼ˆæ¥è‡ª OpenStreetMapï¼‰æ„å»ºåŸºç¡€è·¯å¾„ä¸ç‰¹å¾ï¼Œå¹¶é€šè¿‡æœºå™¨å­¦ä¹ å¯¹æœ€çŸ­è·¯å¾„ traversal time åŸºçº¿è¿›è¡Œåå·®æ ¡æ­£ã€‚

#### æ–¹æ³•æµç¨‹ï¼ˆPipelineï¼‰ï¼š
1. **Network Construction**ï¼šä» OSM æ„å»º drivable road networkï¼ˆä½¿ç”¨ OSMnxï¼‰ï¼›
2. **Baseline Path Calculation**ï¼šä½¿ç”¨ Dijkstra ç®—æ³•æ±‚è§£æœ€å° traversal time è·¯å¾„ï¼ˆè¾¹æƒä¸ºé•¿åº¦ / é€Ÿåº¦é™åˆ¶ï¼‰ï¼›
3. **Feature Engineering**ï¼š
   - **Baseline**: `tnaive`ï¼ˆDijkstra å¾—åˆ°çš„ traversal timeï¼‰
   - **Traffic Controls**ï¼šæ²¿é€” stop signsã€traffic signalsã€crossingsã€give wayã€mini roundabouts çš„è®¡æ•°
   - **Turning Movements**ï¼šleft/right/slight/U-turn çš„æ•°é‡ï¼ˆæŒ‰è§’åº¦åˆ†ç±»ï¼‰
4. **Model Training**ï¼šä»¥ Google Maps API åœ¨å‡Œæ™¨3ç‚¹è·å–çš„ â€œBEST_GUESSâ€ travel time ä½œä¸º referenceï¼Œè®­ç»ƒ RF å›å½’æ¨¡å‹ï¼Œå­¦ä¹ å¦‚ä½•ä¿®æ­£ `tnaive`ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **å‡†ç¡®æ€§** | MAPE é™è‡³ 8.41%ï¼Œæ¥è¿‘ state-of-the-art æ·±åº¦å­¦ä¹ æ°´å¹³ï¼ˆ3%-17%ï¼‰ï¼Œè¿œä¼˜äºä¼ ç»Ÿå¯å‘å¼æ–¹æ³•ï¼ˆ21.15%ï¼‰ |
| **èµ„æºæ•ˆç‡** | ä¸ä¾èµ–å®æ—¶æ‹¥å µæ•°æ®ã€ä¸“æœ‰ä¼ æ„Ÿå™¨æˆ–GPUé›†ç¾¤ï¼Œä»…éœ€å¼€æ”¾æ•°æ® + è½»é‡æ¨¡å‹ |
| **å®ç”¨æ€§** | å¯è¿è¡Œäºæ™®é€šç¡¬ä»¶ï¼Œæ”¯æŒ metropolitan-scale åˆ†æï¼Œé€‚ç”¨äºèµ„æºå—é™æœºæ„ |
| **é€æ˜æ€§ä¸å¯å¤ç°æ€§** | å®Œå…¨åŸºäº open data å’Œå¼€æºå·¥å…·ï¼ˆOSM, OSMnx, scikit-learnï¼‰ï¼Œæå‡ reproducibility |
| **æŠ—ç¨€ç–æ€§èƒ½åŠ›** | å³ä½¿ OSM ä¸­ traffic control æ ‡æ³¨ä¸å®Œæ•´ï¼Œä»èƒ½æœ‰æ•ˆæå–ä¿¡å·å¹¶æå‡é¢„æµ‹ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†
| æ•°æ®æ¥æº | å†…å®¹è¯´æ˜ |
|--------|--------|
| **OpenStreetMap (OSM)** | ä½¿ç”¨ OSMnx æå–æ´›æ‰çŸ¶éƒ½å¸‚åŒºé“è·¯ç½‘ç»œï¼ˆå« speed limits, turn restrictions, æ§åˆ¶è®¾æ–½ç­‰ï¼‰ |
| **Google Maps Routes API** | è·å– origin-destination (OD) å¯¹çš„çœŸå® travel timeï¼ˆdeparture time = å‡Œæ™¨3:00 AMï¼Œtraffic_model = BEST_GUESSï¼‰ |
| **Uber Movement Data** | ç”¨äºç­›é€‰çœŸå®å­˜åœ¨çš„ trip æ¨¡å¼ï¼Œç¡®ä¿ç”Ÿæˆçš„ OD å¯¹å…·æœ‰ç°å®æ„ä¹‰ |
| **ç ”ç©¶åŒºåŸŸ** | Los Angeles County åŠå…¶ urban center boundaryï¼Œå…±ä¿ç•™ 41,360 ä¸ªæœ‰æ•ˆ OD å¯¹ |

---

### âš™ï¸ å®éªŒè®¾ç½®
- **ç›®æ ‡åœºæ™¯**ï¼šminimally congested conditionsï¼ˆæ¨¡æ‹Ÿè‡ªç”±æµçŠ¶æ€ï¼‰
- **è®­ç»ƒ/æµ‹è¯•åˆ’åˆ†**ï¼šæ ‡å‡† 80%/20% åˆ†å‰²
- **äº¤å‰éªŒè¯**ï¼š5-fold CV éªŒè¯ç¨³å®šæ€§
- **è¶…å‚æ•°è°ƒä¼˜**ï¼šrandomized grid searchï¼Œä¼˜åŒ–ç›®æ ‡ä¸º MAE
- **å€™é€‰æ¨¡å‹æ¯”è¾ƒ**ï¼šDecision Tree (DT), Random Forest (RF), Gradient Boosting (GB), AdaBoost

---

### ğŸ“ è¯„ä¼°æŒ‡æ ‡
ä½¿ç”¨å…­é¡¹æŒ‡æ ‡å…¨é¢è¯„ä¼°æ€§èƒ½ï¼š
- **MAPE**ï¼ˆMean Absolute Percentage Errorï¼‰
- **MAE**ï¼ˆMean Absolute Errorï¼Œç§’ï¼‰
- **MSE**ï¼ˆMean Squared Errorï¼‰
- **Bias (Î´)**ï¼šå¹³å‡é¢„æµ‹åå·®ï¼ˆæ£€éªŒæ˜¯å¦ç³»ç»Ÿæ€§é«˜ä¼°/ä½ä¼°ï¼‰
- **RÂ²**ï¼ˆExplained Varianceï¼‰
- **Average Pairwise Ratio (APR)**

---

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿æ–¹æ³• | æè¿° |
|--------|------|
| **Naive Traversal Time (TT)** | Dijkstra æœ€å° traversal timeï¼ˆlength / speed limitï¼‰ï¼Œæ— ä»»ä½•æ“ä½œå»¶è¿Ÿä¿®æ­£ |
| **Other ML Models** | DT, GB, AdaBoost ä½œä¸ºå¯¹ç…§ï¼ŒéªŒè¯ RF çš„ä¼˜è¶Šæ€§ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1 & Fig. 2ï¼‰

| Model | MAPE (%) | MAE (s) | Î´ (bias, s) | RÂ² |
|-------|----------|---------|------------|-----|
| Naive TT | 21.15 | 183.68 | -182.85 | 0.74 |
| **RF (Ours)** | **8.41** | **75.32** | **+0.38** | **0.93** |
| GB | 7.86 | 71.99 | -19.20 | 0.93 |
| DT | 9.00 | 80.00 | +0.13 | 0.93 |
| AdaBoost | 8.20 | 74.00 | -9.76 | 0.93 |

> æ³¨ï¼šæ‰€æœ‰ ML æ–¹æ³•å‡æ˜¾è‘—ä¼˜äº naive baselineï¼›RF åœ¨è¯¯å·®ä¸åå·®ä¹‹é—´å–å¾—æœ€ä½³å¹³è¡¡ã€‚

---

### ğŸ” ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ
- **MAPE ä¸‹é™è¶…è¿‡ 60%**ï¼šä» 21.15% â†’ 8.41%
- **MAE å‡å°‘çº¦ 2.4 å€**ï¼šä» 184s â†’ 75s
- **MSE å‡å°‘ 4 å€**ï¼šä» ~48k â†’ ~12k sÂ²
- **ç³»ç»Ÿæ€§åå·®å®Œå…¨æ¶ˆé™¤**ï¼šnaive æ–¹æ³•ä¸¥é‡ä½ä¼°ï¼ˆ-183sï¼‰ï¼Œè€Œ RF å¹³å‡åå·®ä»…ä¸º +0.38sï¼ˆp=0.76ï¼Œæ— ç»Ÿè®¡æ˜¾è‘—æ€§ï¼‰
- **è§£é‡Šæ–¹å·®å¤§å¹…æå‡**ï¼šRÂ² ä» 0.74 â†’ 0.93ï¼Œè¯´æ˜æ¨¡å‹æ•æ‰äº†æ›´å¤šçœŸå®å˜åŒ–

---

### ğŸ”¤ æ¶ˆèå®éªŒä¸ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆFeature Importanceï¼‰
- **naive travel time** æ˜¯æœ€é‡è¦ç‰¹å¾ï¼ˆè´¡çŒ®çº¦ 68% çš„ RÂ²ï¼‰ï¼Œè¡¨æ˜åŸºç¡€è·¯å¾„ä¿¡æ¯ä»æ˜¯æ ¸å¿ƒï¼›
- **traffic signals** æ˜¯æœ€å…³é”®çš„æ§åˆ¶å› ç´ ï¼Œå…¶æ¬¡ä¸º stop signs å’Œ crossingsï¼›
- **roundabouts** å’Œ **give way** å½±å“è¾ƒå°ï¼Œå¯èƒ½å› å…¶åœ¨ç½‘ç»œä¸­åˆ†å¸ƒç¨€ç–ï¼›
- **turning movements** æ•´ä½“è´¡çŒ®çº¦ 19% çš„è§£é‡ŠåŠ›ï¼Œå…¶ä¸­ left/right turns è¾ƒé‡è¦ï¼ŒU-turns æå°‘å‡ºç°æ•…å½±å“å¾®å¼±ï¼›
- å°½ç®¡ OSM æ•°æ®å­˜åœ¨æ ‡æ³¨ç¼ºå¤±ï¼ˆsparse annotationï¼‰ï¼Œæ¨¡å‹ä»èƒ½ä»ä¸­æå–æœ‰æ•ˆä¿¡å·ï¼Œè¯æ˜æ–¹æ³•å¯¹æ•°æ®ç¨€ç–æ€§é²æ£’ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **è½»é‡çº§ RF æ¨¡å‹å¯åœ¨ä»…ä½¿ç”¨ open data çš„å‰æä¸‹ï¼Œå®ç°æ¥è¿‘ state-of-the-art çš„é¢„æµ‹ç²¾åº¦**ï¼ˆMAPE 8.41%ï¼‰ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿè§„åˆ’æ–¹æ³•ã€‚
2. **é€šè¿‡å¼•å…¥ traffic control å’Œ turning movement ç‰¹å¾ï¼Œå¯æœ‰æ•ˆçº æ­£ Dijkstra traversal time çš„ç³»ç»Ÿæ€§ä½ä¼°é—®é¢˜**ã€‚
3. **Random Forest åœ¨ bias-variance trade-off ä¸Šè¡¨ç°æœ€ä¼˜**ï¼šç›¸æ¯” GB å’Œ AdaBoost æ›´å°‘å‡ºç° under-prediction biasï¼Œç›¸æ¯”å•æ£µ Decision Tree æ–¹å·®æ›´ä½ã€‚
4. **æ–¹æ³•å…·å¤‡è‰¯å¥½çš„ k-fold ç¨³å®šæ€§å’Œæ³›åŒ–èƒ½åŠ›**ï¼šå„ fold çš„ MAE æ³¢åŠ¨æå°ï¼ˆ73.2â€“75.3sï¼‰ï¼Œæ— æ˜æ˜¾è¿‡æ‹Ÿåˆè¿¹è±¡ã€‚
5. **é€‚ç”¨äº metropolitan-scale åº”ç”¨**ï¼šè®¡ç®—å¼€é”€ä½ï¼Œé€‚åˆå¤§è§„æ¨¡ OD matrix ç”Ÿæˆï¼Œæ”¯æŒ accessibility analysisã€network performance evaluation ç­‰è§„åˆ’ä»»åŠ¡ã€‚

---

### âš ï¸ å±€é™æ€§
1. **ä»…é€‚ç”¨äº minimally congested conditions**ï¼šæœªå»ºæ¨¡é«˜å³°æ—¶æ®µçš„ congestion dynamicsï¼Œé«˜å³°æœŸé¢„æµ‹å¯èƒ½åä¹è§‚ï¼›
2. **ä¾èµ– OSM æ•°æ®è´¨é‡**ï¼šä¸åŒåœ°åŒº traffic control tagging å®Œæ•´æ€§å·®å¼‚å¤§ï¼Œå¯èƒ½å½±å“è¿ç§»æ•ˆæœï¼›
3. **ç¼ºä¹æ˜¾å¼çš„æ—¶ç©ºå»ºæ¨¡**ï¼šç›®å‰æœªè€ƒè™‘ day-of-weekã€å¤©æ°”ã€äº‹ä»¶ç­‰åŠ¨æ€å› ç´ ï¼›
4. **route mismatch é—®é¢˜**ï¼šæ¨¡å‹åŸºäº OSM Dijkstra è·¯å¾„æå–ç‰¹å¾ï¼Œä½† Google è¿”å›çš„æ˜¯å…¶ç§æœ‰ç®—æ³•è·¯å¾„ï¼Œä¸¤è€…å¯èƒ½å­˜åœ¨å·®å¼‚ï¼ˆå°½ç®¡ä½œè€…è®¤ä¸ºå…±äº«ç›¸ä¼¼æ‹“æ‰‘ç»“æ„ï¼‰ï¼›
5. **åŒºåŸŸé€‚åº”æ€§å¾…éªŒè¯**ï¼šæ¨¡å‹å‚æ•°æ˜¯å¦å¯ç›´æ¥è¿ç§»åˆ°å…¶ä»–åŸå¸‚å°šéœ€å®è¯ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³å¤šæ—¶æ®µå»ºæ¨¡**ï¼šæ”¶é›†æ›´é•¿æ—¶é—´è·¨åº¦çš„ reference dataï¼ŒåŒºåˆ† peak vs off-peak æ¨¡å¼ï¼›
2. **èåˆæ›´å¤š open data sources**ï¼š
   - crowd-sourced traffic reports
   - public transit schedules
   - weather data
   - satellite imageryï¼ˆç”¨äºè¡¥å…¨ missing controlsï¼‰
3. **å¼€å‘ spatial imputation æ–¹æ³•**ï¼šåˆ©ç”¨ spatial statistics æˆ– ML æŠ€æœ¯æ¨æ–­æœªæ ‡æ³¨çš„ traffic control è®¾æ–½ï¼›
4. **å¼•å…¥ Transfer Learning**ï¼šåœ¨æ•°æ®ä¸°å¯Œçš„åŸå¸‚è®­ç»ƒ base modelï¼Œé€šè¿‡å°‘é‡æœ¬åœ° reference data å¾®è°ƒè‡³æ–°åŸå¸‚ï¼›
5. **é›†æˆåˆ° real-time routing systems**ï¼šç»“åˆ lightweight congestion proxyï¼ˆå¦‚ historical patternsï¼‰ï¼Œæ‰“é€ é«˜æ•ˆä¸”å‡†ç¡®çš„ routing engineã€‚

---

## æ€»ç»“
è¯¥è®ºæ–‡æˆåŠŸæ„å»ºäº†ä¸€ä¸ª**å…¼é¡¾å‡†ç¡®æ€§ã€å¯è®¿é—®æ€§ä¸å¯æ‰©å±•æ€§çš„ä¸­é—´è·¯çº¿æ–¹æ³•**ï¼Œä¸ºèµ„æºæœ‰é™çš„åŸå¸‚äº¤é€šéƒ¨é—¨æä¾›äº†ä¸€ç§å®ç”¨å·¥å…·ã€‚å®ƒä¸ä»…æå‡äº† open data åœ¨ transportation planning ä¸­çš„åº”ç”¨ä»·å€¼ï¼Œä¹Ÿä¸ºæ¨åŠ¨å…¬å¹³ã€é€æ˜ã€è¯æ®é©±åŠ¨çš„å†³ç­–æä¾›äº†æŠ€æœ¯æ”¯æŒã€‚éšç€ OSM æ•°æ®è´¨é‡å’Œè®¡ç®—åŸºç¡€è®¾æ–½æŒç»­æ”¹å–„ï¼Œæ­¤ç±» lightweight ML æ–¹æ³•æœ‰æœ›æˆä¸º smart mobility ç”Ÿæ€ç³»ç»Ÿçš„åŸºçŸ³ç»„ä»¶ã€‚

</details>

---

### 14. [Physics-Informed Tree Search for High-Dimensional Computational Design](https://arxiv.org/abs/2601.06444)

**Authors**: Suvo Banik, Troy D. Loeffler, Henry Chan, Sukriti Manna, Orcun Yildiz, Tom Peterka, Subramanian Sankaranarayanan  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.06444v1  

#### Abstract
High-dimensional design spaces underpin a wide range of physics-based modeling and computational design tasks in science and engineering. These problems are commonly formulated as constrained black-box searches over rugged objective landscapes, where function evaluations are expensive, and gradients...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šPhysics-Informed Tree Search for High-Dimensional Computational Design**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
è¯¥è®ºæ–‡é’ˆå¯¹**é«˜ç»´ã€è¿ç»­ã€ç‰©ç†çº¦æŸä¸‹çš„é»‘ç›’ä¼˜åŒ–é—®é¢˜**ï¼Œè¿™ç±»é—®é¢˜å¹¿æ³›å­˜åœ¨äºææ–™è®¾è®¡ã€æ™¶ä½“ç»“æ„æœç´¢ã€åŠ¿èƒ½æ¨¡å‹æ‹Ÿåˆå’Œå·¥ç¨‹è®¾è®¡ç­‰é¢†åŸŸã€‚ä¼ ç»Ÿä¼˜åŒ–æ–¹æ³•é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- é«˜ç»´ç©ºé—´ä¸­çš„â€œç»´åº¦ç¾éš¾â€å¯¼è‡´é‡‡æ ·æ•ˆç‡ä½ä¸‹ï¼›
- ç›®æ ‡å‡½æ•°éå‡¸ã€å¤šæ¨¡æ€ã€æ— æ¢¯åº¦æˆ–æ¢¯åº¦ä¸å¯é ï¼›
- ç‰©ç†çº¦æŸéš¾ä»¥èå…¥ä¼˜åŒ–è¿‡ç¨‹ï¼›
- å‡½æ•°è¯„ä¼°æˆæœ¬é«˜æ˜‚ï¼ˆå¦‚ DFTã€FEM æ¨¡æ‹Ÿï¼‰ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹**
ä½œè€…æå‡ºäº†ä¸€ä¸ª**ç‰©ç†ä¿¡æ¯å¼•å¯¼çš„è’™ç‰¹å¡æ´›æ ‘æœç´¢æ¡†æ¶ï¼ˆPhysics-Informed Monte Carlo Tree Search, MCTSï¼‰**ï¼Œå°†å¼ºåŒ–å­¦ä¹ ä¸­çš„å†³ç­–æ ‘æ€æƒ³æ‰©å±•åˆ°è¿ç»­ã€é«˜ç»´ç§‘å­¦ä¼˜åŒ–ä»»åŠ¡ä¸­ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

1. **æ–¹å‘æ€§é‡‡æ ·æœºåˆ¶ï¼ˆDirectional Sampling with Logistic Surrogateï¼‰**  
   å¼•å…¥åŸºäºå†å²æœç´¢è½¨è¿¹çš„**Logistic Surrogate æ¨¡å‹**ï¼Œé€šè¿‡é€»è¾‘å›å½’å¯¹æˆåŠŸæ–¹å‘è¿›è¡Œå»ºæ¨¡ï¼Œä¸»åŠ¨ä¼˜åŒ–æœç´¢æ–¹å‘å’Œæ­¥é•¿ï¼Œæ˜¾è‘—æå‡é«˜ç»´ç©ºé—´ä¸­çš„é‡‡æ ·æ•ˆç‡ã€‚

2. **æ·±åº¦ä¾èµ–çš„çª—å£ç¼©æ”¾ï¼ˆDepth-based Window Scalingï¼‰**  
   éšç€æ ‘æ·±åº¦å¢åŠ ï¼ŒåŠ¨æ€ç¼©å°é‡‡æ ·åŠå¾„ $ r_{\text{max}} $ï¼Œå®ç°ä»**å…¨å±€æ¢ç´¢åˆ°å±€éƒ¨ç²¾ç»†ä¼˜åŒ–**çš„å¹³æ»‘è¿‡æ¸¡ï¼Œé¿å…é™·å…¥æµ…å±‚å±€éƒ¨æœ€ä¼˜ã€‚

3. **åˆ†å±‚æ ‘ç¾¤ç­–ç•¥ï¼ˆHierarchical Batching of Treesï¼‰**  
   é‡‡ç”¨**å…¨å±€æ ‘æ‰¹ï¼ˆglobal batchï¼‰ä¸å±€éƒ¨æ ‘æ‰¹ï¼ˆlocal batchï¼‰ç»“åˆ**çš„å¹¶è¡Œç­–ç•¥ï¼š
   - å…¨å±€æ ‘ç”¨äºå¤šæ ·åŒ–æ¢ç´¢ä¸åŒèƒ½é‡ç›†åœ°ï¼›
   - å±€éƒ¨æ ‘ç»§æ‰¿ä¼˜ç§€è§£ï¼Œè¿›è¡Œç²¾ç»†åŒ–æœç´¢ï¼›
   - æ”¯æŒåŠ¨æ€å‰ªæä¸åˆ‡æ¢æœºåˆ¶ï¼Œæé«˜æ”¶æ•›ç¨³å®šæ€§ã€‚

4. **ç‰©ç†ä¸€è‡´æ€§é›†æˆ**  
   åœ¨æœç´¢è¿‡ç¨‹ä¸­åµŒå…¥ç‰©ç†çº¦æŸæ¨¡å—ï¼ˆå¦‚æ™¶æ ¼å¯¹ç§°æ€§ã€åŒ–å­¦æœ‰æ•ˆæ€§ï¼‰ï¼Œç¡®ä¿ç”Ÿæˆçš„å€™é€‰è§£åœ¨ç‰©ç†ä¸Šåˆç†ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- **ä¼˜äºä¼ ç»Ÿå…ƒå¯å‘å¼ç®—æ³•ï¼ˆå¦‚ WOAã€PSOï¼‰**ï¼šåœ¨å¤šæ¨¡æ€ã€é«˜ç»´é—®é¢˜ä¸Šè¡¨ç°å‡ºæ›´å¼ºçš„å…¨å±€æ¢ç´¢èƒ½åŠ›å’Œæ›´ä½çš„æ–¹å·®ï¼›
- **è¶…è¶Šæ ‡å‡† MCTS å˜ä½“**ï¼šè§£å†³äº†ç»å…¸ MCTS åœ¨è¿ç»­ç©ºé—´ä¸­é‡‡æ ·ä½æ•ˆã€æ˜“é™·å…¥å±€éƒ¨çš„é—®é¢˜ï¼›
- **ä¼˜äºè´å¶æ–¯ä¼˜åŒ–ï¼ˆBOï¼‰ç­‰ä»£ç†æ¨¡å‹æ–¹æ³•**ï¼šåœ¨é«˜ç»´ä¸‹ä»ä¿æŒå¯æ‰©å±•æ€§ï¼Œä¸”æ— éœ€æ„å»ºå…¨å±€ä»£ç†æ¨¡å‹ï¼›
- **é€šç”¨æ€§å¼º**ï¼šé€‚ç”¨äºç»“æ„è®¾è®¡ã€åŠ¿èƒ½æ‹Ÿåˆã€è¿ç»­åŠ›å­¦è®¾è®¡ç­‰å¤šç§åœºæ™¯ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†ä¸æµ‹è¯•å‡½æ•°**
å®éªŒåˆ†ä¸ºä¸‰ç±»åŸºå‡†ä¸å®é™…åº”ç”¨ï¼š

#### **(1) æ ‡å‡†ä¼˜åŒ–æµ‹è¯•å‡½æ•°ï¼ˆBenchmark Functionsï¼‰**
å…±ä½¿ç”¨ 23 ä¸ªæ ‡å‡†å‡½æ•°ï¼Œåˆ†ä¸ºä¸‰ç±»ï¼š
- **å•å³°å‡½æ•°ï¼ˆUnimodal, F1â€“F7ï¼‰**ï¼šSphere, Rosenbrock, Schwefel 1.2 ç­‰ï¼ˆ30Dï¼‰
- **å¤šå³°å‡½æ•°ï¼ˆMultimodal, F8â€“F13ï¼‰**ï¼šRastrigin, Ackley, Griewank ç­‰ï¼ˆ30Dï¼‰
- **å›ºå®šç»´åº¦å¤åˆå‡½æ•°ï¼ˆFixed-dimensional, F14â€“F23ï¼‰**ï¼šSix-Hump Camelback, Shekel, Hartmann ç­‰ï¼ˆ2â€“6Dï¼‰

#### **(2) å®é™…ç§‘å­¦è®¡ç®—é—®é¢˜**
- **æ™¶ä½“ç»“æ„ä¼˜åŒ–**ï¼š
  - Auâ‚ƒâ‚… çº³ç±³å›¢ç°‡ï¼ˆ105Dï¼‰
  - äºŒç»´ç¡…çƒ¯ï¼ˆSiliceneï¼‰å¤šç§ç›¸æ€ï¼ˆ9â€“24Dï¼‰
  - ä½“ç›¸ç¡…ï¼ˆBulk Si, 30Dï¼‰
- **åŠ¿èƒ½æ¨¡å‹æ‹Ÿåˆï¼ˆInteratomic Potential Fittingï¼‰**ï¼š
  - åŸºäº DFT æ•°æ®æ‹Ÿåˆ Al çº³ç±³å›¢ç°‡çš„ Tersoff åŠ¿ï¼ˆ13D å‚æ•°ç©ºé—´ï¼‰
- **è¿ç»­å°ºåº¦å·¥ç¨‹è®¾è®¡**ï¼š
  - ç„Šæ¥æ¢ä¼˜åŒ–ï¼ˆWelded Beam Design, 4Dï¼‰
  - å‹åŠ›å®¹å™¨è®¾è®¡ï¼ˆPressure Vessel Design, 4Dï¼‰

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**
- æ‰€æœ‰å®éªŒè¿è¡Œå¤šæ¬¡ï¼ˆé€šå¸¸ 30 æ¬¡ç‹¬ç«‹è¿è¡Œï¼‰ä»¥è¯„ä¼°é²æ£’æ€§å’Œæ–¹å·®ï¼›
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - æœ€ä¼˜ç›®æ ‡å€¼ï¼ˆBest Objective Valueï¼‰
  - å¹³å‡å€¼ä¸æ ‡å‡†å·®ï¼ˆMean Â± Stdï¼‰
  - æ”¶æ•›é€Ÿåº¦ï¼ˆEvaluations to Convergenceï¼‰
  - ç‰©ç†ä¸€è‡´æ€§ï¼ˆå¦‚æ™¶æ ¼è¯¯å·®ã€é…ä½æ•°åŒ¹é…ï¼‰
  - æµ‹è¯•é›†ä¸Šçš„é¢„æµ‹è¯¯å·®ï¼ˆMAE of energy/forcesï¼‰

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **Metaheuristics**: Whale Optimization Algorithm (**WOA**)ã€Particle Swarm Optimization (**PSO**)ã€Genetic Algorithm (**GA**)ã€Gravitational Search Algorithm (**GSA**) ç­‰
- **éšæœºæœç´¢ï¼ˆRandom Searchï¼‰**
- **ç»å…¸ MCTS å˜ä½“ï¼ˆHypersphere Samplingï¼‰**
- **æ–‡çŒ®æŠ¥é“çš„æœ€ä¼˜è§£**ï¼ˆå¦‚ Deb, Lee & Geem, CBO ç­‰ï¼‰

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

| ä»»åŠ¡ | æ–¹æ³• | æœ€ä½³ç›®æ ‡å€¼ï¼ˆæˆ–è¯¯å·®ï¼‰ | è¯„ä»· |
|------|------|------------------------|------|
| **F1 (Sphere, 30D)** | MCTS (Logistic) | **0.0** | è¶…è¶Šæ•°å€¼ç²¾åº¦ï¼Œä¼˜äº Hypersphere MCTS (10â»Â²Â²) |
| **F4 (Rosenbrock, 30D)** | MCTS | ~10â»Â¹â´ | æ˜¾è‘—ä¼˜äº WOA å’Œ PSO |
| **F11 (Ackley, 30D)** | MCTS | ~10â»â¹ | æ”¶æ•›ç¨³å®šï¼Œæ–¹å·®å° |
| **F14 (Shekel, 4D)** | MCTS | **0.998**ï¼ˆç†è®ºæœ€ä¼˜ï¼‰ | æ‰€æœ‰è¿è¡Œå‡è¾¾åˆ°å…¨å±€æœ€ä¼˜ |
| **Auâ‚ƒâ‚… å›¢ç°‡èƒ½é‡æœ€å°åŒ–** | MCTS | <12,000 æ¬¡è¯„ä¼°æ”¶æ•› | ç»“æ„ä¸å·²çŸ¥å…¨å±€æœ€å°å®Œå…¨ä¸€è‡´ï¼ˆRDF åŒ¹é…ï¼‰ |
| **Silicene å¤šç›¸æœç´¢** | MCTS | æ™¶æ ¼è¯¯å·® ~10â»â´ Ã…ï¼Œåæ ‡è¯¯å·® ~10â»âµ Ã… | æˆåŠŸæ¢å¤ FS, LBS, TDS ç­‰äºšç¨³ç›¸ |
| **Al Tersoff åŠ¿æ‹Ÿåˆ** | MCTS | **53.45 meV/atom** (èƒ½é‡ MAE), **212.46 meV/Ã…** (åŠ› MAE) | ä¼˜äº HYBOPã€MEAMã€EAMã€SNAP ç­‰ä¸»æµåŠ¿å‡½æ•° |
| **ç„Šæ¥æ¢è®¾è®¡æˆæœ¬æœ€å°åŒ–** | MCTS | **1.697958** | ä¼˜äºæ‰€æœ‰æ–‡çŒ®æ–¹æ³•ï¼ˆåŒ…æ‹¬ CBOã€GAã€WOAï¼‰ |
| **å‹åŠ›å®¹å™¨è®¾è®¡æˆæœ¬æœ€å°åŒ–** | MCTS | **5898.1359** | å‘ç°æ–°å¯è¡ŒåŒºåŸŸï¼Œæˆæœ¬æ›´ä½ |

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- åœ¨ **21 out of 23 ä¸ªåŸºå‡†å‡½æ•°** ä¸Šï¼ŒMCTS è¡¨ç°ä¼˜äºæˆ–ç­‰äº WOA å’Œ PSOï¼›
- åœ¨å¤šå³°å‡½æ•°ï¼ˆå¦‚ Schwefel, F8ï¼‰ä¸Šï¼ŒMCTS æ‰¾åˆ°æ›´æ·±çš„èƒ½é‡è°·ï¼ˆmean = -7981 vs -7620ï¼‰ï¼Œæ˜¾ç¤ºæ›´å¼ºçš„é€ƒé€¸èƒ½åŠ›ï¼›
- åœ¨å›ºå®šç»´åº¦å‡½æ•°ä¸Šï¼ŒMCTS å®ç°**é›¶æ–¹å·®æ”¶æ•›**ï¼Œè€Œ WOA/PSO å­˜åœ¨è¾ƒå¤§æ³¢åŠ¨ï¼›
- åœ¨å·¥ç¨‹è®¾è®¡é—®é¢˜ä¸­ï¼ŒMCTS ä¸ä»…æ‰¾åˆ°æ›´ä¼˜è§£ï¼Œè¿˜é€šè¿‡ PCA åˆ†ææ­ç¤ºå…¶æ¢ç´¢äº†**å‰äººæœªå‘ç°çš„è®¾è®¡åŒºåŸŸ**ã€‚

### **æ¶ˆèå®éªŒç»“æœ**
- **Logistic Surrogate vs Hypersphere Sampling**ï¼š
  - Logistic æ–¹æ¡ˆåœ¨å¤§å¤šæ•°ä»»åŠ¡ä¸­è¡¨ç°æ›´å¥½ï¼Œå°¤å…¶åœ¨é«˜ç»´å¤æ‚åœ°å½¢ä¸­ï¼›
  - Hypersphere æ›´é€‚åˆå™ªå£°è¾ƒå¤§çš„ç¯å¢ƒï¼Œä½œä¸ºç¨³å¥ fallbackï¼›
- **Hierarchical Tree Batching**ï¼š
  - å•æ£µæ ‘æ˜“é™·å…¥å±€éƒ¨ï¼›
  - å¤šæ ‘å¹¶è¡Œæ˜¾è‘—é™ä½è¿è¡Œé—´æ–¹å·®ï¼Œæå‡å…¨å±€è¦†ç›–ç‡ï¼›
- **Window Scaling**ï¼š
  - æ— ç¼©æ”¾æ—¶æ”¶æ•›æ…¢ä¸”ä¸ç¨³å®šï¼›
  - è‡ªé€‚åº”ç¼©æ”¾ä½¿æ—©æœŸå¹¿åŸŸæ¢ç´¢ã€åæœŸç²¾å‡†å¾®è°ƒæˆä¸ºå¯èƒ½ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **MCTS å¯æœ‰æ•ˆæ‰©å±•è‡³é«˜ç»´è¿ç»­ä¼˜åŒ–ä»»åŠ¡**ï¼Œé€šè¿‡å¼•å…¥æ–¹å‘å­¦ä¹ ã€çª—å£ç¼©æ”¾å’Œç¾¤ä½“ç­–ç•¥ï¼Œå…‹æœäº†ä¼ ç»Ÿ MCTS çš„å±€é™ã€‚
2. **ç‰©ç†ä¿¡æ¯å¯ä»¥è‡ªç„¶åœ°åµŒå…¥æœç´¢è¿‡ç¨‹**ï¼Œä¸ä»…åŠ é€Ÿæ”¶æ•›ï¼Œè¿˜èƒ½ä¿è¯è§£çš„ç‰©ç†åˆç†æ€§ã€‚
3. æ‰€ææ–¹æ³•åœ¨**åˆæˆå‡½æ•°ä¸çœŸå®ç§‘å­¦é—®é¢˜**ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼ŒéªŒè¯äº†å…¶ä½œä¸ºé€šç”¨ä¼˜åŒ–å™¨çš„æ½œåŠ›ã€‚
4. è¯¥æ¡†æ¶å®ç°äº†**è¯„ä¼°é«˜æ•ˆæ€§ä¸ç‰©ç†ä¿çœŸæ€§çš„ç»Ÿä¸€**ï¼Œç‰¹åˆ«é€‚åˆæ˜‚è´µæ¨¡æ‹Ÿé©±åŠ¨çš„è®¾è®¡æµç¨‹ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- å½“å‰ä¸ºçº¯é»‘ç®±æ¨¡å¼ï¼Œæœªåˆ©ç”¨å¤šä¿çœŸåº¦ä¿¡æ¯æˆ–å¤šå°ºåº¦å»ºæ¨¡ï¼›
- ä¸æ”¯æŒè·¨ä»»åŠ¡çš„çŸ¥è¯†è¿ç§»ï¼ˆå¦‚ä¸åŒææ–™é—´çš„å‚æ•°å…ˆéªŒå…±äº«ï¼‰ï¼›
- çº¦æŸå¤„ç†ä¾èµ–æƒ©ç½šé¡¹ï¼Œå°šæœªé›†æˆç”Ÿæˆå¼çº¦æŸæ»¡è¶³æœºåˆ¶ï¼›
- è®¡ç®—å¼€é”€é«˜äºç®€å•å¯å‘å¼æ–¹æ³•ï¼Œåœ¨ä½ç»´é—®é¢˜ä¸­ä¼˜åŠ¿ä¸æ˜æ˜¾ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **èåˆé¢„è®­ç»ƒç‰©ç†ç¼–ç å™¨**ï¼ˆfoundation-guided searchï¼‰ï¼Œå¼•å¯¼æ¢ç´¢æ–¹å‘ï¼›
2. æ„å»º**å¤šæ™ºèƒ½ä½“å…±äº«è®°å¿†çš„æ ‘ç¾¤ç³»ç»Ÿ**ï¼Œå®ç°è·¨ä»»åŠ¡çŸ¥è¯†ç§¯ç´¯ï¼›
3. ä¸å®éªŒé—­ç¯é›†æˆï¼Œç”¨äº**è‡ªä¸»æœºå™¨äººå®éªŒå¹³å°**çš„æ•°æ®é‡‡é›†ä¸ä¼˜åŒ–ï¼›
4. æ¢ç´¢ä¸å…¶ä»– RL æ¡†æ¶ï¼ˆå¦‚ PPOã€SACï¼‰ç»“åˆçš„å¯èƒ½æ€§ï¼Œè¿›ä¸€æ­¥æå‡ç­–ç•¥å­¦ä¹ èƒ½åŠ›ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å¯æ‰©å±•ã€å¯è§£é‡Šã€ç‰©ç†ä¸€è‡´çš„ **physics-informed MCTS æ¡†æ¶**ï¼Œåœ¨é«˜ç»´ç§‘å­¦è®¾è®¡ä»»åŠ¡ä¸­å®ç°äº†**é«˜æ•ˆã€ç¨³å¥ã€é«˜è´¨é‡çš„ä¼˜åŒ–æ€§èƒ½**ï¼Œä¸º AI for Science æä¾›äº†ä¸€ä¸ªæ–°çš„å†³ç­–å±‚èŒƒå¼ã€‚

</details>

---

### 15. [Mosaic: Unlocking Long-Context Inference for Diffusion LLMs via Global Memory Planning and Dynamic Peak Taming](https://arxiv.org/abs/2601.06562)

**Authors**: Liang Zheng, Bowen Shi, Yitao Hu, Jiawei Zhang, Ruofan Li, Sheng Chen, Wenxin Li, Keqiu Li  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.06562v1  

#### Abstract
Diffusion-based large language models (dLLMs) have emerged as a promising paradigm, utilizing simultaneous denoising to enable global planning and iterative refinement. While these capabilities are particularly advantageous for long-context generation, deploying such models faces a prohibitive memor...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Mosaic: Unlocking Long-Context Inference for Diffusion LLMs via Global Memory Planning and Dynamic Peak Taming*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰ä¸»æµçš„ **autoregressive (AR)** å¤§è¯­è¨€æ¨¡å‹æ¨ç†ç³»ç»Ÿåœ¨å†…å­˜ç®¡ç†ä¸Šé«˜åº¦ä¼˜åŒ–äº† **KV-Cache**ï¼Œç„¶è€Œæ–°å…´çš„ **diffusion-based LLMs (dLLMs)** å…·æœ‰å®Œå…¨ä¸åŒçš„è®¡ç®—èŒƒå¼ï¼š
- dLLMs é‡‡ç”¨éè‡ªå›å½’ã€å…¨å±€å¹¶è¡Œå»å™ªæ–¹å¼ç”Ÿæˆæ–‡æœ¬ï¼Œæ¯ä¸€æ­¥éƒ½éœ€è¦å¯¹æ•´ä¸ªåºåˆ—è¿›è¡ŒåŒå‘æ³¨æ„åŠ›è®¡ç®—ï¼›
- å› æ­¤ï¼Œå…¶å†…å­˜ç“¶é¢ˆä¸å†æ˜¯æŒä¹…çš„ KV-Cacheï¼Œè€Œæ˜¯æ¯æ­¥éƒ½éœ€é‡æ–°è®¡ç®—çš„ **transient activations**ï¼ˆå¦‚ FFN å’Œ logits è¾“å‡ºï¼‰ï¼›
- æ­¤å¤–ï¼Œè¿™äº›æ¿€æ´»çš„å†…å­˜å³°å€¼ä¼šéš **mask ratio** åŠ¨æ€åˆ‡æ¢ï¼ˆé«˜ mask æ—¶ logits å ä¸»å¯¼ï¼Œä½ mask æ—¶ FFN å ä¸»å¯¼ï¼‰ï¼Œå¯¼è‡´ä¼ ç»Ÿé™æ€å†…å­˜è§„åˆ’å¤±æ•ˆï¼›
- åŒæ—¶ï¼Œé€šç”¨æ¡†æ¶ï¼ˆå¦‚ `torch.compile`ï¼‰å­˜åœ¨ **graph breaks** å’Œ **external fragmentation**ï¼Œè¿›ä¸€æ­¥åŠ å‰§å†…å­˜æµªè´¹ã€‚

ç»¼ä¸Šï¼Œ**ç°æœ‰ LLM æ¨ç†ç³»ç»Ÿæ— æ³•æœ‰æ•ˆæ”¯æŒé•¿ä¸Šä¸‹æ–‡ dLLM æ¨ç†**ï¼Œå­˜åœ¨ä¸¥é‡çš„å†…å­˜å®¹é‡ç“¶é¢ˆã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šMosaic

Mosaic æ˜¯ä¸€ä¸ªä¸“ä¸º dLLMs è®¾è®¡çš„ **å†…å­˜é«˜æ•ˆæ¨ç†ç³»ç»Ÿ**ï¼Œé€šè¿‡ä¸‰å¤§æ ¸å¿ƒæŠ€æœ¯å®ç°å…¨å±€åŠ¨æ€å†…å­˜ç®¡ç†ï¼š

| æŠ€æœ¯ | åˆ›æ–°ç‚¹ |
|------|--------|
| **Mask-only Logits Kernel** | åªå¯¹è¢«æ©ç çš„ token è®¡ç®— logitsï¼Œé¿å…å¯¹å·²ç”Ÿæˆ token çš„å†—ä½™è®¡ç®—ï¼›é€šè¿‡ **gather-GEMM èåˆå†…æ ¸**ç›´æ¥å¤„ç†ç¨€ç–è¾“å…¥ï¼Œæ— éœ€ä¸­é—´ç¼“å†²åŒºï¼ŒèŠ‚çœå†…å­˜ä¸”æå‡æ•ˆç‡ã€‚ |
| **Lazy Chunking Optimizer** | å¼•å…¥åœ¨çº¿å¯å‘å¼æœç´¢ç­–ç•¥ï¼Œåœ¨è¿è¡Œæ—¶æ ¹æ®å½“å‰å†…å­˜å‹åŠ›åŠ¨æ€å†³å®šæ˜¯å¦å¯¹ FFN æˆ– logits æ“ä½œè¿›è¡Œåˆ†å—ï¼ˆchunkingï¼‰ï¼Œä»…åœ¨å¿…è¦æ—¶æ‰è§¦å‘ï¼Œæœ€å°åŒ–å»¶è¿Ÿå¼€é”€ã€‚ |
| **Global Memory Manager** | æ„å»ºç»Ÿä¸€è™šæ‹Ÿåœ°å€ç©ºé—´ï¼ŒåŸºäºå®Œæ•´è®¡ç®—å›¾ç”Ÿå‘½å‘¨æœŸåˆ†æç”Ÿæˆå…¨å±€å¤ç”¨è®¡åˆ’ï¼Œç»“åˆ **VMMï¼ˆVirtual Memory Managementï¼‰** å®ç°ç‰©ç†é¡µæŒ‰éœ€ç»‘å®šï¼Œå½»åº•æ¶ˆé™¤å¤–éƒ¨ç¢ç‰‡ã€‚ |

æ­¤å¤–ï¼Œç³»ç»Ÿå¼•å…¥ **Graph Registrar** æ˜¾å¼å®šä¹‰å‚æ•°åŒ–è®¡ç®—å›¾æ¨¡æ¿ï¼Œç¡®ä¿å…¨å›¾å¯è§æ€§ï¼Œæ”¯æ’‘ä¸Šè¿°ä¼˜åŒ–ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | Mosaic çš„ä¼˜åŠ¿ |
|------|----------------|
| **å†…å­˜æ•ˆç‡** | å¹³å‡é™ä½ **2.71Ã— çš„ memory peak-to-average ratio**ï¼Œæ˜¾è‘—ç¼“è§£åŠ¨æ€å³°å€¼é—®é¢˜ã€‚ |
| **å¯æ‰©å±•æ€§** | åœ¨ç›¸åŒç¡¬ä»¶ä¸‹ï¼Œæœ€å¤§æ”¯æŒçš„æ¨ç†åºåˆ—é•¿åº¦æå‡ **15.89â€“32.98Ã—**ã€‚ |
| **æ€§èƒ½æ— æŸ** | ä¸ç‰ºç‰²ç²¾åº¦ä¸é€Ÿåº¦ï¼Œåè€Œå°†ç«¯åˆ°ç«¯å»¶è¿Ÿé™ä½ **4.12%â€“23.26%**ã€‚ |
| **é€‚åº”æ€§å¼º** | æ”¯æŒ variable-length è¾“å…¥ä¸è¿­ä»£çº§è°ƒåº¦ï¼Œé€‚ç”¨äºçœŸå®åœºæ™¯ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†ä¸æ¨¡å‹
ç”±äºç›®æ ‡æ˜¯æµ‹è¯•æé™ä¸Šä¸‹æ–‡èƒ½åŠ›ï¼Œä½œè€…ä½¿ç”¨ **dummy input**ï¼ˆåˆæˆæ•°æ®ï¼‰æ¥çªç ´è®­ç»ƒæ—¶çš„ä¸Šä¸‹æ–‡é™åˆ¶ï¼Œè¯„ä¼°ç³»ç»Ÿçš„ç†è®ºä¸Šé™ã€‚

**è¯„ä¼°æ¨¡å‹**ï¼š
- **LLaDA-8B**
- **Dream-7B**
- **LLaDA-MoE**

è¿™äº›å‡ä¸ºå…¸å‹çš„ dLLM æ¨¡å‹ï¼ŒåŸºäº Transformer æ¶æ„ï¼Œé‡‡ç”¨ token-level æ‰©æ•£æœºåˆ¶ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®

| é¡¹ç›® | é…ç½® |
|------|------|
| **ç¡¬ä»¶å¹³å°** | NVIDIA GeForce RTX 3090 (24GB VRAM)<br>NVIDIA A100 (40GB VRAM) |
| **å®ç°åŸºç¡€** | åŸºäº **vLLM** æ¡†æ¶æ„å»ºï¼Œé›†æˆå®˜æ–¹ PyTorch æ¨¡å‹ä»£ç ï¼Œç»•è¿‡æ ‡å‡† KV-Cache æµç¨‹ |
| **æ”¯æŒåŠŸèƒ½** | variable-length inferenceï¼ˆvarlenï¼‰ã€iteration-level scheduling |
| **è¾“å…¥é…ç½®** | æ§åˆ¶ prompt-to-output ratio $ r_p \in \{0.1, 0.5, 0.9\} $ï¼Œå¯¹åº”ä¸åŒåˆå§‹ mask ratio $ r_m $ |

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Per-step Latency** | å•ä¸ª diffusion step çš„æ‰§è¡Œæ—¶é—´ |
| **Maximum Context Length ($ L_{max} $)** | åœ¨ä¸å‘ç”Ÿ OOM çš„å‰æä¸‹èƒ½æ”¯æŒçš„æœ€å¤§åºåˆ—é•¿åº¦ |
| **Memory Peak-to-Average Ratio (PAR)** | è¡¡é‡å†…å­˜æ³¢åŠ¨ç¨‹åº¦ï¼Œè¶Šä½è¶Šå¥½ |
| **Reserved Memory Inflation Rate** | å®é™…ä¿ç•™å†…å­˜ vs. ç†è®ºå³°å€¼çš„æ¯”ä¾‹ï¼Œåæ˜ ç¢ç‰‡åŒ–ç¨‹åº¦ |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”

| åŸºçº¿ | æè¿° |
|------|------|
| **Native** | åŸå§‹ PyTorch å®ç°ï¼Œæ— ä»»ä½•æ¨ç†ä¼˜åŒ– |
| **Mosaic-Torch** | ç§»æ¤åˆ° vLLM æ¡†æ¶ + varlen æ”¯æŒï¼Œä½†æ— å†…å­˜ä¼˜åŒ– |
| **Mosaic-Compile** | åœ¨ Mosaic-Torch åŸºç¡€ä¸ŠåŠ å…¥ `torch.compile`ï¼Œä»£è¡¨é€šç”¨ç¼–è¯‘ä¼˜åŒ– |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **$ L_{max} $ æå‡å€æ•°** | è¾ƒ Native æå‡ **32.98Ã—**<br>è¾ƒ Mosaic-Torch æå‡ **26.74Ã—**<br>è¾ƒ Mosaic-Compile æå‡ **15.89Ã—** |
| **Memory PAR é™ä½** | å¹³å‡å‡å°‘ **2.71Ã—**ï¼Œå°¤å…¶åœ¨å¯ç”¨ chunking åæ•ˆæœæ˜¾è‘— |
| **å»¶è¿Ÿé™ä½** | ç›¸æ¯” Mosaic-Torch/Mosaic-Compileï¼Œå¹³å‡é™ä½ **4.12%â€“23.26%** |
| **å†…å­˜è†¨èƒ€ç‡** | Baseline å†…å­˜ä¿ç•™æ¯”ç†è®ºå³°å€¼é«˜å‡º 21.78%â€“78.33%ï¼Œè€Œ Mosaic å‡ ä¹æ— é¢å¤–å¼€é”€ |

> å›¾ 10â€“13 å±•ç¤ºäº†åœ¨å¤šç§ $ r_p $ è®¾ç½®ä¸‹çš„ $ L_{max} $ ä¸ latency å¯¹æ¯”ï¼ŒMosaic åœ¨æ‰€æœ‰åœºæ™¯ä¸­å‡å–å¾—æœ€ä¼˜è¡¨ç°ã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

é€æ­¥æ·»åŠ ç»„ä»¶éªŒè¯å„æ¨¡å—è´¡çŒ®ï¼ˆä»¥ Mosaic-Torch ä¸ºèµ·ç‚¹ï¼‰ï¼š

| ç»„ä»¶ | $ L_{max} $ æå‡å¹…åº¦ |
|------|------------------------|
| **+ Global Memory Manager** | æå‡ **79.0% â€“ 197.1%**<br>ä¸»å› ï¼šå…¨å±€å¤ç”¨ + in-place ä¼˜åŒ–ï¼ˆå¦‚æ›¿æ¢ Dream çš„ logits shiftï¼‰ |
| **+ Mask-only Logits Kernel** | è¿›ä¸€æ­¥æå‡ **88.9% â€“ 114.3%**<br>ä¸»å› ï¼šæ¶ˆé™¤æœªé®è”½ token çš„ logits å†—ä½™è®¡ç®— |
| **+ Lazy Chunking Optimizer** | å†æå‡ **221.3% â€“ 673.3%**<br>ä¸»å› ï¼šæœ‰æ•ˆå‹åˆ¶åŠ¨æ€å†…å­˜å³°å€¼ |

> å¦‚å›¾ 14 æ‰€ç¤ºï¼Œlazy chunking æ˜¯æå‡æœ€é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›çš„å…³é”®ã€‚

---

#### âœ… Chunking ç­–ç•¥æœ‰æ•ˆæ€§ï¼ˆvs. Fixed Chunkingï¼‰
- **Mosaic-FC**ï¼šé™æ€åº”ç”¨æœ€å¤§ chunk æ•°
- **Mosaicï¼ˆoursï¼‰**ï¼šä»…åœ¨å†…å­˜ä¸è¶³æ—¶åŠ¨æ€å¯ç”¨ chunking

â†’ åœ¨çŸ­ä¸Šä¸‹æ–‡ä¸­ï¼ŒMosaic å®ç° **5.5%â€“21.5% çš„å»¶è¿Ÿé™ä½**ï¼Œè¯æ˜â€œlazyâ€è®¾è®¡çš„æœ‰æ•ˆæ€§ã€‚

---

#### âœ… Search ä¸ Planning æ•ˆç‡å¯¹æ¯”

| æ–¹æ³• | æ€§èƒ½ | å»¶è¿Ÿå¼€é”€ |
|------|------|----------|
| **Brute-force Search (Mosaic-BF)** | $ L_{max} $ ç›¸åŒ | æœç´¢å»¶è¿Ÿé«˜ **300â€“400 å€** |
| **Bottleneck-driven Heuristic (Ours)** | ç›¸åŒ | ä»…å  BF çš„ **0.28%â€“0.32%** |
| **ILP Planning (Mosaic-ILP)** | $ L_{max} $ ç›¸åŒ | è§„åˆ’å»¶è¿Ÿä¸º ours çš„ **23â€“1000 å€** |
| **First-fit Planning (Ours)** | ç›¸åŒ | å»¶è¿Ÿä»…ä¸º ILP çš„ **0.1%â€“4.3%** |

> è¡¨æ˜æ‰€æå¯å‘å¼ç®—æ³•åœ¨ä¿æŒæœ€ä¼˜æ€§çš„å‰æä¸‹æå¤§é™ä½äº†å…ƒå¼€é”€ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **dLLM çš„å†…å­˜ç“¶é¢ˆå·²ä» KV-Cache è½¬å‘ transient activations**ï¼Œå°¤å…¶æ˜¯ FFN ä¸ logits çš„åŠ¨æ€å³°å€¼äº¤æ›¿ã€‚
2. **é€šç”¨æ¨ç†ç³»ç»Ÿï¼ˆå¦‚ torch.compileï¼‰å›  graph breaks å¯¼è‡´ä¸¥é‡å†…å­˜ç¢ç‰‡**ï¼Œä¸é€‚åˆ dLLMã€‚
3. **mask-only è®¡ç®—æ˜¯å¯è¡Œä¸”é«˜æ•ˆçš„**ï¼Œé€šè¿‡èåˆ gather-GEMM å¯é¿å…ä¸­é—´ç¼“å†²ã€‚
4. **åŠ¨æ€ peak taming å¿…é¡»ç»“åˆè¿è¡Œæ—¶æ„ŸçŸ¥çš„ chunking ç­–ç•¥**ï¼Œé™æ€åˆ†å—ä»£ä»·é«˜æ˜‚ã€‚
5. **å…¨å±€å†…å­˜è§„åˆ’ + è™šæ‹Ÿå†…å­˜æ˜ å°„** å¯å½»åº•è§£å†³ external fragmentationã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

- å½“å‰å®ç°ä¾èµ–å¯¹ç‰¹å®šæ¨¡å‹ç»“æ„çš„ç†è§£ï¼ˆå¦‚æ˜ç¡®è¯†åˆ« FFN/logits èŠ‚ç‚¹ï¼‰ï¼Œè‡ªåŠ¨åŒ–ç¨‹åº¦æœ‰å¾…æé«˜ï¼›
- æ‰€æœ‰å®éªŒåŸºäº dummy inputï¼Œå°šæœªåœ¨çœŸå®ä»»åŠ¡ï¼ˆå¦‚ä»£ç è¡¥å…¨ã€é•¿æ–‡æ¡£ç”Ÿæˆï¼‰ä¸­éªŒè¯å®ç”¨æ€§ï¼›
- å¯¹æ›´å¤æ‚æ‰©æ•£æµç¨‹ï¼ˆå¦‚éå‡åŒ€ masking scheduleï¼‰çš„æ”¯æŒæœªæ·±å…¥æ¢è®¨ï¼›
- ç¼–è¯‘å™¨é›†æˆä»éœ€æ‰‹åŠ¨æ³¨å†Œ graph templateï¼Œæœªæ¥å¯æ¢ç´¢è‡ªåŠ¨æ•æ‰æœºåˆ¶ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. å°† Mosaic æ‰©å±•è‡³å¤šæ¨¡æ€ diffusion modelsï¼ˆå¦‚å›¾æ–‡ç”Ÿæˆï¼‰ï¼›
2. ç»“åˆ early-exit æˆ– adaptive step skipping è¿›ä¸€æ­¥å‹ç¼©æ€»è®¡ç®—é‡ï¼›
3. å¼€å‘å…¨è‡ªåŠ¨ graph registration å·¥å…·é“¾ï¼Œé™ä½éƒ¨ç½²é—¨æ§›ï¼›
4. æ¢ç´¢ CPU-GPU ååŒä¸‹çš„ offloading ç­–ç•¥ï¼Œæ”¯æŒè¶…å¤§è§„æ¨¡ä¸Šä¸‹æ–‡ï¼›
5. åœ¨çœŸå®åº”ç”¨åœºæ™¯ä¸­è¯„ä¼°ç”Ÿæˆè´¨é‡ä¸ååé‡ trade-offã€‚

---

## æ€»ç»“

> **Mosaic æˆåŠŸæ­ç¤ºäº† dLLM ä¸ AR-LLM åœ¨å†…å­˜è¡Œä¸ºä¸Šçš„æ ¹æœ¬å·®å¼‚ï¼Œå¹¶æå‡ºäº†ä¸€å¥—ç³»ç»Ÿçº§è§£å†³æ–¹æ¡ˆâ€”â€”ä» mask-only kernel åˆ° lazy chunking å†åˆ° global VMM ç®¡ç†ï¼Œå®ç°äº†é•¿ä¸Šä¸‹æ–‡æ¨ç†èƒ½åŠ›çš„æ•°é‡çº§è·ƒå‡ï¼ŒåŒæ—¶æå‡äº†æ•ˆç‡ä¸å¯æ‰©å±•æ€§ã€‚è¯¥å·¥ä½œä¸º diffusion-based LLM çš„å®ç”¨åŒ–é“ºå¹³äº†é“è·¯ã€‚**

</details>

---

### 16. [Segmental Advantage Estimation: Enhancing PPO for Long-Context LLM Training](https://arxiv.org/abs/2601.07320)

**Authors**: Xue Gong, Qi Yi, Ziyuan Nan, Guanhua Huang, Kejiao Li, Yuhao Jiang, Ruibin Xiong, Zenan Xu, Jiaming Guo, Shaohui Peng, Bo Zhou  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.07320v1  

#### Abstract
Training Large Language Models (LLMs) for reasoning tasks is increasingly driven by Reinforcement Learning with Verifiable Rewards (RLVR), where Proximal Policy Optimization (PPO) provides a principled framework for stable policy updates. However, the practical application of PPO is hindered by unre...

---

### 17. [PRISMA: Reinforcement Learning Guided Two-Stage Policy Optimization in Multi-Agent Architecture for Open-Domain Multi-Hop Question Answering](https://arxiv.org/abs/2601.05465)

**Authors**: Yu Liu, Wenxiao Zhang, Cong Cao, Wenxuan Lu, Fangfang Yuan, Diandian Guo, Kun Peng, Qiang Sun, Kaiyan Zhang, Yanbing Liu, Jin B. Hong, Bowen Zhou, Zhiyuan Ma  
**Category**: cs.AI  
**Published**: 2026-01-13  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.05465v1  

#### Abstract
Answering real-world open-domain multi-hop questions over massive corpora is a critical challenge in Retrieval-Augmented Generation (RAG) systems. Recent research employs reinforcement learning (RL) to end-to-end optimize the retrieval-augmented reasoning process, directly enhancing its capacity to ...

---

### 18. [N2N-GQA: Noise-to-Narrative for Graph-Based Table-Text Question Answering Using LLMs](https://arxiv.org/abs/2601.06603)

**Authors**: Mohamed Sharafath, Aravindh Annamalai, Ganesh Murugan, Aravindakumar Venugopalan  
**Category**: cs.CL  
**Published**: 2026-01-13  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.06603v1  

#### Abstract
Multi-hop question answering over hybrid table-text data requires retrieving and reasoning across multiple evidence pieces from large corpora, but standard Retrieval-Augmented Generation (RAG) pipelines process documents as flat ranked lists, causing retrieval noise to obscure reasoning chains. We i...

---

### 19. [SourceNet: Interpretable Sim-to-Real Inference on Variable-Geometry Sensor Arrays for Earthquake Source Inversion](https://arxiv.org/abs/2601.06320)

**Authors**: Zhe Jia, Xiaotian Zhang, Junpeng Li  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.06320v1  

#### Abstract
Inferring high-dimensional physical states from sparse, ad-hoc sensor arrays is a fundamental challenge across AI for Science, as they are complicated by irregular geometries and the profound Sim-to-Real gap in physical modeling. Taking earthquake source characterization as a representative challeng...

---

### 20. [HAS-VQ: Hessian-Adaptive Sparse Vector Quantization for High-Fidelity LLM Compression](https://arxiv.org/abs/2601.06959)

**Authors**: Vladimer Khasia  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.06959v1  

#### Abstract
Post-training quantization is essential for deploying Large Language Models (LLMs) on resource- constrained devices. However, standard integer quantization (e.g., INT4) fundamentally degrades per- formance by imposing a uniform grid on the heavy-tailed distribution of weight parameters, particularly...

---

### 21. [Mathematical Knowledge Graph-Driven Framework for Equation-Based Predictive and Reliable Additive Manufacturing](https://arxiv.org/abs/2601.05298)

**Authors**: Yeongbin Cha, Namjung Kim  
**Category**: cs.AI  
**Published**: 2026-01-13  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.05298v1  

#### Abstract
Additive manufacturing (AM) relies critically on understanding and extrapolating process-property relationships; however, existing data-driven approaches remain limited by fragmented knowledge representations and unreliable extrapolation under sparse data conditions. In this study, we propose an ont...

---

### 22. [SimLLM: Fine-Tuning Code LLMs for SimPy-Based Queueing System Simulation](https://arxiv.org/abs/2601.06543)

**Authors**: Jun-Qi Chen, Kun Zhang, Rui Zheng, Ying Zhong  
**Category**: cs.CL  
**Published**: 2026-01-13  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.06543v1  

#### Abstract
The Python package SimPy is widely used for modeling queueing systems due to its flexibility, simplicity, and smooth integration with modern data analysis and optimization frameworks. Recent advances in large language models (LLMs) have shown strong ability in generating clear and executable code, m...

---

### 23. [PDR: A Plug-and-Play Positional Decay Framework for LLM Pre-training Data Detection](https://arxiv.org/abs/2601.06827)

**Authors**: Jinhan Liu, Yibo Yang, Ruiying Lu, Piotr Piekos, Yimeng Chen, Peng Wang, Dandan Guo  
**Category**: cs.CL  
**Published**: 2026-01-13  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.06827v1  

#### Abstract
Detecting pre-training data in Large Language Models (LLMs) is crucial for auditing data privacy and copyright compliance, yet it remains challenging in black-box, zero-shot settings where computational resources and training data are scarce. While existing likelihood-based methods have shown promis...

---

### 24. [Solar Open Technical Report](https://arxiv.org/abs/2601.07022)

**Authors**: Sungrae Park, Sanghoon Kim, Jungho Cho, Gyoungjin Gim, Dawoon Jung, Mikyoung Cha, Eunhae Choo, Taekgyu Hong, Minbyul Jeong, SeHwan Joo, Minsoo Khang, Eunwon Kim, Minjeong Kim, Sujeong Kim, Yunsu Kim, Hyeonju Lee, Seunghyun Lee, Sukyung Lee, Siyoung Park, Gyungin Shin, Inseo Song, Wonho Song, Seonghoon Yang, Seungyoun Yi, Sanghoon Yoon, Jeonghyun Ko, Seyoung Song, Keunwoo Choi, Hwalsuk Lee, Sunghun Kim, Du-Seong Chang, Kyunghyun Cho, Junsuk Choe, Hwaran Lee, Jae-Gil Lee, KyungTae Lim, Alice Oh  
**Category**: cs.CL  
**Published**: 2026-01-13  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.07022v1  

#### Abstract
We introduce Solar Open, a 102B-parameter bilingual Mixture-of-Experts language model for underserved languages. Solar Open demonstrates a systematic methodology for building competitive LLMs by addressing three interconnected challenges. First, to train effectively despite data scarcity for underse...

---

### 25. [Thinking Before Constraining: A Unified Decoding Framework for Large Language Models](https://arxiv.org/abs/2601.07525)

**Authors**: Ngoc Trinh Hung Nguyen, Alonso Silva, Laith Zumot, Liubov Tupikina, Armen Aghasaryan, Mehwish Alam  
**Category**: cs.CL  
**Published**: 2026-01-13  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.07525v1  

#### Abstract
Natural generation allows Language Models (LMs) to produce free-form responses with rich reasoning, but the lack of guaranteed structure makes outputs difficult to parse or verify. Structured generation, or constrained decoding, addresses this drawback by producing content in standardized formats su...

---

### 26. [Adaptive Layer Selection for Layer-Wise Token Pruning in LLM Inference](https://arxiv.org/abs/2601.07667)

**Authors**: Rei Taniguchi, Yuyang Dong, Makoto Onizuka, Chuan Xiao  
**Category**: cs.CL  
**Published**: 2026-01-13  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.07667v1  

#### Abstract
Due to the prevalence of large language models (LLMs), key-value (KV) cache reduction for LLM inference has received remarkable attention. Among numerous works that have been proposed in recent years, layer-wise token pruning approaches, which select a subset of tokens at particular layers to retain...

---

### 27. [Employ SmartNICs' Data Path Accelerators for Ordered Key-Value Stores](https://arxiv.org/abs/2601.06231)

**Authors**: Frederic Schimmelpfennig, Jan Sass, Reza Salkhordeh, Martin Kr\"oning, Stefan Lankes, Andr\'e Brinkmann  
**Category**: cs.DC  
**Published**: 2026-01-13  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.06231v1  

#### Abstract
Remote in-memory key-value (KV) stores serve as a cornerstone for diverse modern workloads, and high-speed range scans are frequently a requirement. However, current architectures rarely achieve a simultaneous balance of peak efficiency, architectural simplicity, and native support for ordered opera...

---

### 28. [CEEMDAN-Based Multiscale CNN for Wind Turbine Gearbox Fault Detection](https://arxiv.org/abs/2601.06217)

**Authors**: Nejad Alagha, Anis Salwa Mohd Khairuddin, Obada Al-Khatib, Abigail Copiaco  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.06217v1  

#### Abstract
Wind turbines play a critical role in the shift toward sustainable energy generation. Their operation relies on multiple interconnected components, and a failure in any of these can compromise the entire system's functionality. Detecting faults accurately is challenging due to the intricate, non-lin...

---

### 29. [Surrogate-based Optimization via Clustering for Box-Constrained Problems](https://arxiv.org/abs/2601.07442)

**Authors**: Maaz Ahmad, Iftekhar A. Karimi  
**Category**: cs.LG  
**Published**: 2026-01-13  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.07442v1  

#### Abstract
Global optimization of large-scale, complex systems such as multi-physics black-box simulations and real-world industrial systems is important but challenging. This work presents a novel Surrogate-Based Optimization framework based on Clustering, SBOC for global optimization of such systems, which c...

---

### 30. [Logic-Parametric Neuro-Symbolic NLI: Controlling Logical Formalisms for Verifiable LLM Reasoning](https://arxiv.org/abs/2601.05705)

**Authors**: Ali Farjami, Luca Redondi, Marco Valentino  
**Category**: cs.AI  
**Published**: 2026-01-13  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.05705v1  

#### Abstract
Large language models (LLMs) and theorem provers (TPs) can be effectively combined for verifiable natural language inference (NLI). However, existing approaches rely on a fixed logical formalism, a feature that limits robustness and adaptability. We propose a logic-parametric framework for neuro-sym...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- kv cache, offload, State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
