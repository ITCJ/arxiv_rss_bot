# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-02-11 06:48:02 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [LLM-CoOpt: A Co-Design and Optimization Framework for Efficient LLM Inference on Heterogeneous Platforms](https://arxiv.org/abs/2602.09323)

**Authors**: Jie Kong, Wei Wang, Jiehan Zhou, Chen Yu  
**Category**: cs.DC  
**Published**: 2026-02-11  
**Score**: 17.0  
**Type**: new  
**ArXiv ID**: 2602.09323v1  

#### Abstract
Major challenges in LLMs inference remain frequent memory bandwidth bottlenecks, computational redundancy, and inefficiencies in long-sequence processing. To address these issues, we propose LLM-CoOpt, a comprehensive algorithmhardware co-design framework aimed at improving both throughput and laten...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLLM-CoOpt: A Co-Design and Optimization Framework for Efficient LLM Inference on Heterogeneous Platforms

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜  
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¼‚æ„å¹³å°ä¸Šçš„æ¨ç†é¢ä¸´ä¸‰å¤§æ ¸å¿ƒæŒ‘æˆ˜ï¼š
- **KV Cache å†…å­˜ç“¶é¢ˆ**ï¼šè‡ªå›å½’è§£ç è¿‡ç¨‹ä¸­ï¼ŒKey-Value ç¼“å­˜éšåºåˆ—é•¿åº¦çº¿æ€§å¢é•¿ï¼Œå¯¼è‡´æ˜¾å­˜å ç”¨é«˜ã€å¸¦å®½å‹åŠ›å¤§ï¼›
- **Multi-Head Attention çš„è®¡ç®—å†—ä½™**ï¼šæ¯ä¸ªæ³¨æ„åŠ›å¤´ç‹¬ç«‹ç”Ÿæˆ K/V å‘é‡ï¼Œé€ æˆé‡å¤è®¡ç®—å’Œç¡¬ä»¶èµ„æºåˆ©ç”¨ç‡ä½ï¼›
- **é•¿åºåˆ—å¤„ç†æ•ˆç‡ä½ä¸‹**ï¼šæ ‡å‡† Self-Attention å…·æœ‰ $O(T^2)$ å¤æ‚åº¦ï¼ŒPagedAttention è™½ç¼“è§£å†…å­˜å‹åŠ›ä½†ä»å­˜åœ¨åŒæ­¥å¼€é”€å’Œç¢ç‰‡åŒ–é—®é¢˜ã€‚

è¿™äº›é—®é¢˜åœ¨èµ„æºå—é™çš„å¼‚æ„å¹³å°ä¸Šå°¤ä¸ºçªå‡ºï¼Œé™åˆ¶äº† LLM åœ¨è¾¹ç¼˜è®¾å¤‡æˆ–ä¸“ç”¨åŠ é€Ÿå™¨ä¸Šçš„é«˜æ•ˆéƒ¨ç½²ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯  
ä½œè€…æå‡º **LLM-CoOpt** â€”â€” ä¸€ç§é¢å‘å¼‚æ„å¹³å°çš„ç®—æ³•-ç¡¬ä»¶ååŒä¼˜åŒ–æ¡†æ¶ï¼Œé›†æˆä¸‰é¡¹å…³é”®æŠ€æœ¯ï¼š

#### âœ… Opt-KVï¼šåŠ¨æ€ KV Cache ä¼˜åŒ–
- **å†™é˜¶æ®µä¼˜åŒ–**ï¼šé€šè¿‡æ¡ä»¶åˆ¤æ–­è·³è¿‡æ— æ•ˆ token çš„ KV ç¼“å­˜å†™å…¥ï¼ˆå¦‚ padding æˆ–é‡å¤ tokenï¼‰ï¼Œå‡å°‘å†—ä½™å†™æ“ä½œï¼›
- **è¯»é˜¶æ®µå‹ç¼©**ï¼šé‡‡ç”¨ **FP8 é‡åŒ–** å­˜å‚¨æœ‰æ•ˆ KV å—ï¼Œå¹¶æ”¯æŒ on-the-fly decompressionï¼Œåœ¨é™ä½å­˜å‚¨å¼€é”€çš„åŒæ—¶ä¿æŒç²¾åº¦ï¼›
- å®ç°æ›´é«˜æ•ˆçš„ memory access å’Œ bandwidth utilizationã€‚

#### âœ… Opt-GQAï¼šè½»é‡çº§ Grouped-Query Attention
- å°† query heads åˆ†ç»„ï¼Œæ¯ç»„å…±äº«ä¸€ç»„ K/V headsï¼Œå½¢æˆçµæ´»çš„ grouped-query ç»“æ„ï¼›
- å‡å°‘ K/V æŠ•å½±æ•°é‡ï¼Œæ˜¾è‘—é™ä½è®¡ç®—ä¸å†…å­˜å¼€é”€ï¼›
- æ”¯æŒåŠ¨æ€åˆ†ç»„ç­–ç•¥ï¼Œé€‚åº”ä¸åŒè¾“å…¥åˆ†å¸ƒå’Œç¡¬ä»¶å¹¶è¡Œèƒ½åŠ›ã€‚

#### âœ… Opt-Paï¼šä¼˜åŒ–çš„ Paged Attention è®¾è®¡
- ä¸¤æ­¥ç­–ç•¥æå‡é•¿åºåˆ—å¤„ç†æ•ˆç‡ï¼š
  1. **è¿‡æ»¤æœ‰æ•ˆå—**ï¼šä»…åŠ è½½å®é™…ä¸Šä¸‹æ–‡èŒƒå›´å†…çš„é€»è¾‘å—ï¼Œè·³è¿‡ padding åŒºåŸŸï¼›
  2. **å…±äº«å†…å­˜å½’çº¦**ï¼šç”¨ `block_sum` æ›¿ä»£ warp-level reductionï¼Œå‡å°‘ Softmax ä¸­çš„å…¨å±€åŒæ­¥å¼€é”€ï¼Œæé«˜æ•°å€¼ç¨³å®šæ€§ï¼›
- æ˜¾è‘—æ”¹å–„ memory locality ä¸ thread synchronization æ•ˆç‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰æ–¹æ³•å±€é™ | LLM-CoOpt æ”¹è¿› |
|------|----------------|----------------|
| KV Cache | é™æ€é‡åŒ–ä¸é€‚åº”åŠ¨æ€èŒƒå›´ï¼›ç»Ÿä¸€åŠ è½½æ‰€æœ‰å†å²å— | åŠ¨æ€è·³å†™ + FP8 å‹ç¼© + æŒ‰éœ€è§£å‹ |
| GQA | å›ºå®šåˆ†ç»„ç­–ç•¥ç¼ºä¹çµæ´»æ€§ | å¯é…ç½®åˆ†ç»„ï¼Œæ›´å¥½åŒ¹é…ç¡¬ä»¶å¹¶è¡Œæ€§ |
| PagedAttention | å­˜åœ¨å†…å­˜ç¢ç‰‡ä¸åŒæ­¥å»¶è¿Ÿ | è¿‡æ»¤æ— æ•ˆå— + å…±äº«å†…å­˜ reduction é™ä½ overhead |

> âœ… **æ•´ä½“ä¼˜åŠ¿**ï¼šå®ç°äº† throughputã€latency ä¸ accuracy çš„è‰¯å¥½å¹³è¡¡ï¼Œç‰¹åˆ«é€‚ç”¨äºèµ„æºå—é™çš„å¼‚æ„å¹³å°ï¼ˆå¦‚å›½äº§ DCUï¼‰ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **ååé‡è¯„ä¼°**ï¼š`ShareGPT_V3_unfiltered_cleaned_split` æ•°æ®é›†
  - åŒ…å«çº¦ 35,240 æ¡çœŸå®å¯¹è¯æ ·æœ¬ï¼Œæ¶µç›–é—®ç­”ã€é—²èŠã€çŸ¥è¯†å’¨è¯¢ç­‰åœºæ™¯ï¼›
  - æ€»æ•°æ®é‡ ~178 MBï¼Œç”¨äºæ¨¡æ‹Ÿå¤šæ ·åŒ–çš„æ¨ç†è´Ÿè½½ã€‚
- **å‡†ç¡®æ€§è¯„ä¼°**ï¼š`ARC` æ•°æ®é›†ï¼ˆAI2 Reasoning Challengeï¼‰
  - åˆ†ä¸ºä¸¤ä¸ªå­é›†ï¼š
    - **ARC-E (Easy Set)**ï¼šæ˜“å›ç­”çš„é—®é¢˜ï¼›
    - **ARC-C (Challenge Set)**ï¼šæ£€ç´¢ä¸å…±ç°ç®—æ³•å‡å¤±è´¥çš„é—®é¢˜ï¼Œæ›´å…·æŒ‘æˆ˜æ€§ï¼›
  - å…± 7,787 é“å°å­¦ç§‘å­¦ç±»é€‰æ‹©é¢˜ï¼Œæµ‹è¯•æ¨¡å‹æ¨ç†èƒ½åŠ›ã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼šDCU Z100 å¼‚æ„è®¡ç®—å¹³å°
  - L2 Cache: ~4MB
  - Wavefront Size: 64
  - å†…å­˜å¸¦å®½: 512 GB/s (GDDR6)
  - æ”¯æŒ FP16 / æ¨¡æ‹Ÿ FP8ï¼ˆvia INT8ï¼‰
- **è½¯ä»¶ç¯å¢ƒ**ï¼šåŸºäºæœªä¼˜åŒ–çš„ `vLLM v0.3.3` æ„å»ºåŸºå‡†ç³»ç»Ÿ
- **æµ‹è¯•æ¨¡å‹**ï¼š
  - LLaMa-7B-GPTQ
  - LLaMa2-7B-GPTQ
  - LLaMa-13B-GPTQ
  - LLaMa2-13B-GPTQ
  - LLaMa-Pro-8B-GPTQ

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ | å…¬å¼ |
|------|------|-------|
| **Inference Latency** | å•æ¬¡ä»»åŠ¡å¹³å‡å“åº”æ—¶é—´ | $\text{Latency} = \frac{1}{N}\sum_{i=1}^{N} \text{latency}_i$ |
| **Generation Throughput** | æ¯ç§’ç”Ÿæˆ token æ•° | $\text{Throughput} = \frac{\text{Total Generated Tokens}}{\text{Generation Time}}$ |
| **Accuracy** | æ­£ç¡®é¢„æµ‹æ¯”ä¾‹ | $\text{Accuracy} = \frac{N_{\text{correct}}}{N_{\text{total}}} \times 100\%$ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline**ï¼šåŸå§‹ vLLM æ¡†æ¶ï¼ˆæ— é¢å¤–ä¼˜åŒ–ï¼‰
- **æ¶ˆèå®éªŒç»„**ï¼š
  - vLLM + Opt-KV
  - vLLM + Opt-GQA
  - vLLM + Opt-Pa
  - vLLM + LLM-CoOptï¼ˆä¸‰è€…è”åˆï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ LLaMa-13B-GPTQ ä¸ºä¾‹ï¼‰

| æ–¹æ³• | æ¨ç†å»¶è¿Ÿ â†“ | ç”Ÿæˆåå â†‘ | ARC-C å‡†ç¡®ç‡ |
|------|------------|-------------|--------------|
| Original (vLLM) | åŸºå‡† | åŸºå‡† | 39.66% |
| + Opt-KV | -6.18% | +7.20% | â‰ˆæŒå¹³ |
| + Opt-GQA | -6.75% | +12.13% | â‰ˆæŒå¹³ |
| + Opt-Pa | -5.48% | +10.85% | â‰ˆæŒå¹³ |
| **LLM-CoOpt** | **-16.79%** | **+13.43%** | **40.01%** |

> æ³¨ï¼šæœ€å¤§å»¶è¿Ÿé™ä½è¾¾ **16.79%**ï¼Œæœ€é«˜ååæå‡è¾¾ **13.43%**

### ä¸å…¶ä»–æ¨¡å‹çš„ç»“æœä¸€è‡´æ€§
- æ‰€æœ‰æµ‹è¯•æ¨¡å‹å‡è¡¨ç°å‡ºç¨³å®šå¢ç›Šï¼Œè¯´æ˜ LLM-CoOpt å…·å¤‡è‰¯å¥½çš„æ³›åŒ–æ€§å’Œå¯æ‰©å±•æ€§ï¼›
- ç‰¹åˆ«æ˜¯åœ¨ **13B è§„æ¨¡æ¨¡å‹ä¸Šæ”¶ç›Šæœ€æ˜æ˜¾**ï¼Œè¡¨æ˜å…¶å¯¹å¤§æ¨¡å‹æ›´å…·ä»·å€¼ã€‚

### æ¶ˆèå®éªŒç»“æœ
- ä¸‰ä¸ªç»„ä»¶å‡æœ‰ç‹¬ç«‹è´¡çŒ®ï¼Œä¸”ç»„åˆåå‘ˆç°**ååŒæ•ˆåº”ï¼ˆsynergistic benefitï¼‰**ï¼›
- Opt-GQA å¯¹ throughput æå‡æœ€å¤§ï¼›
- Opt-KV åœ¨ memory footprint å’Œ bandwidth åˆ©ç”¨æ–¹é¢è¡¨ç°æœ€ä¼˜ï¼›
- Opt-Pa æ˜¾è‘—æå‡äº†é•¿åºåˆ—åœºæ™¯ä¸‹çš„æ‰§è¡Œç¨³å®šæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å†…å­˜ä¸è®¡ç®—ååŒä¼˜åŒ–è‡³å…³é‡è¦**ï¼šå•çº¯ä¼˜åŒ–æŸä¸€æ–¹é¢ï¼ˆå¦‚ä»… KV å‹ç¼©ï¼‰æ— æ³•æ ¹æœ¬è§£å†³å¼‚æ„å¹³å°ç“¶é¢ˆï¼Œå¿…é¡»è¿›è¡Œç®—æ³•-ç¡¬ä»¶ co-designï¼›
2. **FP8 é‡åŒ–å¯ç”¨äº KV Cache**ï¼šç»“åˆ selective caching ä¸ on-the-fly decompressionï¼Œå¯åœ¨å‡ ä¹ä¸å½±å“ accuracy çš„å‰æä¸‹å¤§å¹…èŠ‚çœæ˜¾å­˜ï¼›
3. **Grouped Query ç»“æ„ä¼˜äºä¼ ç»Ÿ MHA**ï¼šOpt-GQA åœ¨ä¿è¯è¡¨è¾¾èƒ½åŠ›çš„åŒæ—¶æ˜¾è‘—å‡å°‘å†—ä½™è®¡ç®—ï¼Œå°¤å…¶é€‚åˆå¤šä»»åŠ¡å¹¶å‘åœºæ™¯ï¼›
4. **PagedAttention å¯è¿›ä¸€æ­¥ä¼˜åŒ–**ï¼šé€šè¿‡ block-wise filtering ä¸ shared-memory reductionï¼Œèƒ½æœ‰æ•ˆç¼“è§£åŒæ­¥ä¸ç¢ç‰‡é—®é¢˜ï¼›
5. **LLM-CoOpt ä¸æŸå®³æ¨¡å‹å‡†ç¡®æ€§**ï¼šåœ¨ ARC-C/E ä¸Š accuracy åŸºæœ¬ä¸å˜ç”šè‡³ç•¥æœ‰ä¸Šå‡ï¼ŒéªŒè¯äº†ä¼˜åŒ–çš„å®‰å…¨æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ FP8 æ”¯æŒä¾èµ–äº INT8 æ¨¡æ‹Ÿï¼Œå°šæœªå®Œå…¨å‘æŒ¥ä¸“ç”¨ç¡¬ä»¶æ½œåŠ›ï¼›
- åˆ†ç»„ç­–ç•¥ä»éœ€æ‰‹åŠ¨é…ç½®ï¼Œç¼ºä¹å…¨è‡ªåŠ¨ adaptive grouping æœºåˆ¶ï¼›
- å®éªŒé›†ä¸­åœ¨ GPTQ é‡åŒ–æ¨¡å‹ï¼Œæ˜¯å¦é€‚ç”¨äºå…¶ä»–é‡åŒ–æ–¹å¼ï¼ˆå¦‚ AWQã€INT4ï¼‰æœ‰å¾…éªŒè¯ï¼›
- æœªæ¶‰åŠå¤š GPU/å¤šèŠ‚ç‚¹åˆ†å¸ƒå¼æ¨ç†åœºæ™¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ¢ç´¢ Multi-modal åœºæ™¯ä¸‹çš„æ‰©å±•åº”ç”¨**ï¼šå°† LLM-CoOpt æ€è·¯è¿ç§»åˆ°å›¾æ–‡ã€éŸ³è§†é¢‘ç­‰è·¨æ¨¡æ€æ¨¡å‹ä¸­ï¼›
2. **å¼•å…¥ Dynamic Batch Processing ä¸ Sparse Computing**ï¼šè¿›ä¸€æ­¥æå‡å¤æ‚éƒ¨ç½²ç¯å¢ƒä¸‹çš„èµ„æºåˆ©ç”¨ç‡ï¼›
3. **å¼€å‘è‡ªåŠ¨åŒ–çš„å‚æ•°è°ƒä¼˜ç³»ç»Ÿ**ï¼šå®ç° Opt-GQA åˆ†ç»„æ•°ã€Opt-Pa å—å¤§å°ç­‰è¶…å‚çš„ runtime è‡ªé€‚åº”è°ƒæ•´ï¼›
4. **æ”¯æŒæ›´å¤šå¼‚æ„æ¶æ„**ï¼šé€‚é…å›½äº§ AI èŠ¯ç‰‡ã€FPGAã€NPU ç­‰å¤šæ ·åŒ–ç¡¬ä»¶å¹³å°ï¼Œæ¨åŠ¨é€šç”¨åŒ–éƒ¨ç½²ã€‚

---

> ğŸ”š **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **LLM-CoOpt é€šè¿‡ Opt-KVã€Opt-GQA ä¸ Opt-Pa ä¸‰é‡ååŒä¼˜åŒ–ï¼Œåœ¨å‡ ä¹ä¸æŸå¤± accuracy çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº† LLM åœ¨å¼‚æ„å¹³å°ä¸Šçš„æ¨ç† throughput ä¸ latency è¡¨ç°ï¼Œä¸ºé«˜æ•ˆã€å®ç”¨çš„å¤§æ¨¡å‹è¾¹ç¼˜éƒ¨ç½²æä¾›äº†å¯è¡Œè·¯å¾„ã€‚**

</details>

---

### 2. [Rollout-Training Co-Design for Efficient LLM-Based Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.09578)

**Authors**: Zhida Jiang, Zhaolong Xing, Jiawei Lu, Yipei Niu, Qingyuan Sang, Liangxu Zhang, Wenquan Dai, Junhua Shu, Jiaxing Wang, Qiangyu Pei, Qiong Chen, Xinyu Liu, Fangming Liu, Ai Han, Zhen Chen, Ke Zhang  
**Category**: cs.LG  
**Published**: 2026-02-11  
**Score**: 14.5  
**Type**: new  
**ArXiv ID**: 2602.09578v1  

#### Abstract
Despite algorithm-level innovations for multi-agent reinforcement learning (MARL), the underlying networked infrastructure for large-scale MARL training remains underexplored. Existing training frameworks primarily optimize for single-agent scenarios and fail to address the unique system-level chall...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šRollout-Training Co-Design for Efficient LLM-Based Multi-Agent Reinforcement Learning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰ä¸»æµçš„ **Reinforcement Learning (RL)** å’Œ **Multi-Agent Reinforcement Learning (MARL)** æ¡†æ¶åœ¨ç³»ç»Ÿå±‚é¢å­˜åœ¨ä¸‰å¤§ç“¶é¢ˆï¼Œä¸¥é‡åˆ¶çº¦å¤§è§„æ¨¡ LLM-based MARL çš„è®­ç»ƒæ•ˆç‡ï¼š

- **Rollout-Training åŒæ­¥éšœç¢**ï¼šç”±äºéƒ¨åˆ† agent å“åº”æ—¶é—´æé•¿ï¼ˆlong-tail effectï¼‰ï¼Œæ•´ä¸ªè®­ç»ƒå¿…é¡»ç­‰å¾…æœ€æ…¢çš„ rollout å®Œæˆï¼Œé€ æˆä¸¥é‡çš„ pipeline é˜»å¡ã€‚
- **Rollout è´Ÿè½½ä¸å‡è¡¡**ï¼šæ ¸å¿ƒ agent è¢«é¢‘ç¹è°ƒç”¨å¯¼è‡´è¯·æ±‚å †ç§¯ï¼Œè€Œè¾…åŠ© agent åˆ™èµ„æºé—²ç½®ï¼Œå½¢æˆè´Ÿè½½å€¾æ–œã€‚
- **è®­ç»ƒèµ„æºåˆ©ç”¨ç‡ä½**ï¼šé™æ€èµ„æºåˆ†é…ç­–ç•¥ä¸‹ï¼Œæœªæ¿€æ´» agent å ç”¨çš„è®¡ç®—ä¸å†…å­˜èµ„æºæ— æ³•è¢«é‡Šæ”¾ï¼Œå¯¼è‡´æ•´ä½“ç¡¬ä»¶åˆ©ç”¨ç‡ä½ä¸‹ã€‚

ç°æœ‰æ¡†æ¶å¦‚ OpenRLHFã€veRL ç­‰ä»…æ”¯æŒå• agent åœºæ™¯ï¼›è€Œä¸“ä¸º MARL è®¾è®¡çš„ MARTI ä»é‡‡ç”¨ **colocated æ¶æ„** å’ŒåŒæ­¥è®­ç»ƒèŒƒå¼ï¼Œæœªèƒ½ä»åŸºç¡€è®¾æ–½å±‚é¢è¿›è¡Œç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šFlexMARL
ä½œè€…æå‡º **FlexMARL** â€”â€”é¦–ä¸ªé¢å‘å¤§è§„æ¨¡ LLM-based MARL çš„ç«¯åˆ°ç«¯è®­ç»ƒæ¡†æ¶ï¼Œé€šè¿‡ **rollout ä¸ training çš„ååŒè®¾è®¡ï¼ˆco-designï¼‰** å®ç°ç³»ç»Ÿçº§ä¼˜åŒ–ã€‚å…¶ä¸‰å¤§æ ¸å¿ƒç»„ä»¶å¦‚ä¸‹ï¼š

#### âœ… Joint Orchestratorï¼ˆè”åˆè°ƒåº¦å™¨ï¼‰
- å¼•å…¥ **experience store** ä½œä¸ºç»“æ„åŒ–å­˜å‚¨æ¨¡å—ï¼Œç®¡ç†è·¨ agent çš„æ ·æœ¬ç”Ÿå‘½å‘¨æœŸã€‚
- è®¾è®¡ **micro-batch driven å¼‚æ­¥ pipeline**ï¼Œå°†å…¨å±€ batch æ‹†åˆ†ä¸º micro-batchesï¼Œå®ç° rollout ä¸ training çš„ç»†ç²’åº¦é‡å ã€‚
- åœ¨è§£è€¦æ¢¯åº¦è®¡ç®—ä¸å‚æ•°æ›´æ–°çš„åŒæ—¶ï¼Œé€šè¿‡ç‰ˆæœ¬è¿½è¸ªæœºåˆ¶ä¿è¯åŒæ­¥è®­ç»ƒè¯­ä¹‰ï¼ˆstrong consistencyï¼‰ï¼Œé¿å…å‚æ•°é™ˆæ—§ï¼ˆparameter stalenessï¼‰é—®é¢˜ã€‚

#### âœ… Rollout Engineï¼ˆå¹¶è¡Œé‡‡æ · + åˆ†å±‚è´Ÿè½½å‡è¡¡ï¼‰
- é‡‡ç”¨ **parallel sampling scheme** æ”¯æŒ query-level å’Œ trajectory-level å¹¶è¡Œæ‰§è¡Œï¼Œæ˜¾è‘—é™ä½æ¨ç†å»¶è¿Ÿã€‚
- å®ç° **hierarchical load balancing**ï¼š
  - **Intra-agent**ï¼šåŸºäºæœ€å°å †åŠ¨æ€è°ƒåº¦è‡³è´Ÿè½½æœ€ä½çš„ inference instanceã€‚
  - **Inter-agent**ï¼šå½“è´Ÿè½½å·®å¼‚è¶…è¿‡é˜ˆå€¼æ—¶ï¼Œè‡ªåŠ¨è¿ç§» inference å®ä¾‹ï¼ˆå«æ¨¡å‹æƒé‡ä¼ è¾“ï¼‰ï¼Œç¼“è§£çƒ­ç‚¹é—®é¢˜ã€‚

#### âœ… Training Engineï¼ˆä»¥ agent ä¸ºä¸­å¿ƒçš„èµ„æºè°ƒåº¦ï¼‰
- æ¨å‡º **agent-centric resource allocation**ï¼Œä»…åœ¨éœ€è¦æ—¶æ‰ä¸º agent åŠ¨æ€ç»‘å®šç¡¬ä»¶èµ„æºã€‚
- å¼•å…¥ **process group æŠ½è±¡** å®ç° gang schedulingï¼Œæ”¯æŒè®­ç»ƒè¿›ç¨‹çš„ suspend/resumeã€‚
- åˆ©ç”¨ç»Ÿä¸€çš„ **Set/Get API** å®ç°è®­ç»ƒçŠ¶æ€ï¼ˆweights & optimizer statesï¼‰åœ¨ device ä¸ host å†…å­˜é—´çš„é«˜æ•ˆ swap-in/outï¼Œé¿å… OOMã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | FlexMARL | ç°æœ‰æ¡†æ¶ï¼ˆå¦‚ MARTI, OpenRLHFï¼‰ |
|------|----------|-------------------------------|
| å¤š agent æ”¯æŒ | âœ… å…¨é¢æ”¯æŒ | âŒ æˆ–å¼±æ”¯æŒ |
| Rollout-Training è§£è€¦éƒ¨ç½² | âœ… disaggregated æ¶æ„ | âŒ colocated æ¶æ„ |
| å¼‚æ­¥ pipeline | âœ… micro-batch å¼‚æ­¥ï¼Œä¿ç•™åŒæ­¥è¯­ä¹‰ | âŒ åŒæ­¥æˆ–ç²—ç²’åº¦å¼‚æ­¥ |
| Rollout è´Ÿè½½å‡è¡¡ | âœ… åˆ†å±‚å¼¹æ€§æ‰©ç¼©å®¹ | âŒ å›ºå®šå®ä¾‹æ•° |
| èµ„æºæŒ‰éœ€åˆ†é… | âœ… agent-centric åŠ¨æ€ç»‘å®š | âŒ é™æ€é¢„åˆ†é… |
| è·¨èŠ‚ç‚¹éƒ¨ç½²èƒ½åŠ› | âœ… æ”¯æŒå¤æ‚å¼‚æ„é…ç½® | âŒ é€šå¸¸é™äºå°è§„æ¨¡é›†ç¾¤ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **Merchant Assistant (MA) Dataset**  
  å¤šä¸ª agent åä½œå®Œæˆç”µå•†å•†å®¶åº—é“ºç®¡ç†ä»»åŠ¡ï¼ˆé”€å”®åˆ†æã€è¥é”€ä¼˜åŒ–ã€å”®åç­‰ï¼‰ï¼Œä½¿ç”¨ **Qwen2.5-14B** æ¨¡å‹ã€‚
- **Category Assistant (CA) Dataset**  
  èšç„¦è®¢å•æŸ¥è¯¢ã€å®šä»·ç­–ç•¥ä¸åº“å­˜å»ºè®®ï¼Œæ¶‰åŠä¸¤ç§æ¨¡å‹è§„æ¨¡ï¼š**Qwen2.5-14B å’Œ Qwen2.5-32B**ã€‚

> æ³¨ï¼šå› å•†ä¸šä¿å¯†åŸå› ï¼Œå…·ä½“æ•°æ®ç»†èŠ‚æœªå…¬å¼€ã€‚

---

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼š48 èŠ‚ç‚¹é›†ç¾¤ï¼Œæ¯èŠ‚ç‚¹é…å¤‡ 16 ä¸ªå•†ç”¨ NPUï¼ˆ64GB æ˜¾å­˜ï¼‰ï¼Œé€šè¿‡ HCCS äº’è”ã€‚
- **å¹¶è¡Œé…ç½®**ï¼š
  - Inter-query parallelism = 4
  - Intra-query parallelism = 16
- **è®­ç»ƒå‚æ•°**ï¼š
  - Batch size = 64ï¼Œmicro-batch size = 16
  - ä½¿ç”¨ GRPO ç®—æ³•ï¼ŒAdam ä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ 1e-6
- **å®ç°åŸºç¡€**ï¼š
  - Rollout backendï¼švLLM v0.9.1
  - Training backendï¼šDeepSpeed v0.16.9 + ZeRO-3

---

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **E2E Time** | å•ä¸ªæ ·æœ¬å…¨æµç¨‹å¹³å‡è€—æ—¶ï¼ˆrollout + training + othersï¼‰ |
| **Speedup** | ç›¸å¯¹äºåŸºçº¿ MAS-RL çš„åŠ é€Ÿæ¯” |
| **Throughput** | æ¯ç§’ç”Ÿæˆ token æ•°ï¼ˆtpsï¼‰ |
| **Agent Load** | å„ agent å¤„ç†çš„ rollout è¯·æ±‚æ•°é‡ |
| **Hardware Utilization Rate** | AI æ ¸å¿ƒæ´»è·ƒæ—¶é—´å æ¯” |
| **Swap-in/out Overhead** | è®­ç»ƒçŠ¶æ€åŠ è½½/å¸è½½å»¶è¿Ÿ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | ç®€ä»‹ |
|------|------|
| **MAS-RL** | å°†å• agent RL æ¡†æ¶ç›´æ¥è¿ç§»åˆ°å¤š agent åœºæ™¯ï¼Œé‡‡ç”¨ colocated æ¶æ„ä¸åŒæ­¥æµç¨‹ |
| **DistRL** | æ”¹è¿›ç‰ˆ disaggregated æ¶æ„ï¼Œåˆ†ç¦» rollout ä¸ training èµ„æºæ± ï¼Œä½†ä»ä¸ºåŒæ­¥ pipeline |
| **MARTI (ICLR 2026)** | å½“å‰æœ€å…ˆè¿›çš„ MARL æ¡†æ¶ï¼Œæ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒä¸å¼‚æ­¥ rolloutï¼Œä½†èµ„æºé™æ€åˆ†é… |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### æ€§èƒ½æ€»è§ˆï¼ˆTable 2ï¼‰
| Dataset | Framework | E2E Time | Speedup | Throughput |
|--------|-----------|---------|--------|------------|
| MA | MAS-RL | 914.4s | 1.0Ã— | 119.0 tps |
| MA | DistRL | 293.8s | 3.1Ã— | 401.0 tps |
| MA | MARTI | 174.1s | 5.3Ã— | 642.8 tps |
| MA | **FlexMARL** | **126.1s** | **7.3Ã—** | **910.2 tps** |
| CA | MAS-RL | 438.6s | 1.0Ã— | 265.5 tps |
| CA | DistRL | 130.0s | 3.4Ã— | 571.6 tps |
| CA | MARTI | 112.8s | 3.9Ã— | 655.9 tps |
| CA | **FlexMARL** | **78.8s** | **5.6Ã—** | **821.4 tps** |

> âœ… FlexMARL åœ¨ä¸¤ä¸ªçœŸå®å·¥ä¸šæ•°æ®é›†ä¸Šå‡å–å¾—æœ€ä¼˜æ€§èƒ½ï¼Œæœ€é«˜è¾¾ **7.3Ã— åŠ é€Ÿ** ä¸ **910.2 tps ååé‡**ã€‚

---

### å…³é”®æ€§èƒ½è¡¨ç°

#### ğŸ”¹ RQ2: Rollout è´Ÿè½½å‡è¡¡æ•ˆæœï¼ˆFigures 8â€“9ï¼‰
- FlexMARL åœ¨ç›¸åŒæ—¶é—´å†…å¤„ç†çš„ rollout è¯·æ±‚è¿œè¶…å…¶ä»–æ–¹æ³•ã€‚
- ä¾‹å¦‚ï¼Œåœ¨ MA æ•°æ®é›†ä¸Šï¼ŒAgent B çš„è¯·æ±‚å®Œæˆæ—¶é—´ä» MARTI çš„ 159s ç¼©çŸ­è‡³ **90s**ï¼ˆæé€Ÿ 1.8Ã—ï¼‰ã€‚
- è´Ÿè½½æ›²çº¿æ˜¾ç¤º FlexMARL æ›´å¿«ç§¯ç´¯ä¸”æ›´å¿«æ¸…ç©ºé˜Ÿåˆ—ï¼ŒéªŒè¯äº†åˆ†å±‚è´Ÿè½½å‡è¡¡çš„æœ‰æ•ˆæ€§ã€‚

#### ğŸ”¹ RQ3: ç¡¬ä»¶åˆ©ç”¨ç‡æå‡ï¼ˆFigure 10ï¼‰
- FlexMARL å¹³å‡ç¡¬ä»¶åˆ©ç”¨ç‡è¾¾ï¼š
  - **32.4%ï¼ˆMAï¼‰**
  - **19.8%ï¼ˆCAï¼‰**
- è¿œé«˜äºåŸºçº¿ï¼š
  - MAS-RL: ä»… 3.6%ï¼ˆCAï¼‰
  - MARTI: 12.3%ï¼ˆCAï¼‰
  - DistRL: 10.2%ï¼ˆCAï¼‰

> ğŸ’¡ ä¼ ç»Ÿ colocated æ¶æ„å› èµ„æºäº‰æŠ¢å¯¼è‡´ä¸¥é‡æµªè´¹ï¼Œè€Œ FlexMARL çš„åŠ¨æ€ç»‘å®šæ˜¾è‘—å‡å°‘ idle æ—¶é—´ã€‚

#### ğŸ”¹ RQ4: è®­ç»ƒçŠ¶æ€äº¤æ¢å¼€é”€ï¼ˆFigure 11ï¼‰
| Model Size | Swap-in Overhead | Swap-out Overhead |
|-----------|------------------|--------------------|
| 3B â†’ 7B â†’ 14B â†’ 32B | å¢åŠ å¹³ç¼“ï¼Œæœ€å¤§çº¦ **11s** | åŒä¸Š |

- æ§åˆ¶å¹³é¢å¼€é”€æä½ï¼ˆsuspend/resume å‡ ä¹æ— å»¶è¿Ÿï¼‰ã€‚
- æ•°æ®è¿ç§»å¼€é”€éšæ¨¡å‹å¢å¤§è€Œå¢é•¿ï¼Œä½†åœ¨å®é™…ä¸­å¯è¢« rollout å»¶è¿Ÿæ©ç›–ï¼Œä¸å½±å“æ•´ä½“ååã€‚

#### ğŸ”¹ RQ5: æ¶ˆèå®éªŒï¼ˆTable 3ï¼‰
| Variant | E2E Time (MA) | Speedup | Throughput |
|--------|---------------|--------|-----------|
| w/o balancing | 152.2s | 6.0Ã— | 729.9 tps |
| w/o async | 256.2s | 3.6Ã— | 444.0 tps |
| **Full FlexMARL** | **126.1s** | **7.3Ã—** | **910.2 tps** |

> âš ï¸ ç§»é™¤ä»»ä¸€ç»„ä»¶éƒ½ä¼šå¸¦æ¥æ˜¾è‘—æ€§èƒ½ä¸‹é™ï¼Œè¯æ˜ **hierarchical load balancing** ä¸ **micro-batch async pipeline** æ˜¯æ€§èƒ½çªç ´çš„å…³é”®ã€‚

#### ğŸ”¹ RQ6: å¤§è§„æ¨¡æ‰©å±•æ€§æµ‹è¯•ï¼ˆTable 4ï¼‰
| é…ç½® | E2E Time | Throughput |
|------|---------|----------|
| 5Ã—32B | 160.3s | 265.9 tps |
| 3Ã—32B + 7Ã—14Bï¼ˆå¼‚æ„æ··åˆï¼‰ | 132.5s | 334.8 tps |
| 15Ã—14B | **41.9s** | **754.2 tps** |

> âœ… FlexMARL æˆåŠŸæ”¯æŒå¤§è§„æ¨¡å¼‚æ„éƒ¨ç½²ï¼ˆå¦‚ 32B + 14B æ··åˆï¼‰ï¼Œè€Œç°æœ‰æ¡†æ¶ï¼ˆå¦‚ MARTIï¼‰åœ¨æ­¤ç±»åœºæ™¯ä¸‹æ˜“å‡ºç° OOM é”™è¯¯ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Disaggregated Architecture + Fine-grained Async Pipeline æ˜¯æ‰“ç ´åŒæ­¥ç“¶é¢ˆçš„å…³é”®**  
   FlexMARL é€šè¿‡ experience store è§£è€¦ rollout ä¸ trainingï¼Œå¹¶åˆ©ç”¨ micro-batch æµæ°´çº¿éšè— long-tail latencyï¼Œå®ç°é«˜ååä¸å¼ºä¸€è‡´æ€§å…¼é¡¾ã€‚

2. **Hierarchical Load Balancing æ˜¾è‘—æ”¹å–„ rollout æ•ˆç‡**  
   åŠ¨æ€è°ƒæ•´ inference å®ä¾‹æ•°é‡ï¼Œç»“åˆ D2D æƒé‡è¿ç§»ï¼Œæœ‰æ•ˆç¼“è§£çƒ­ç‚¹ agent çš„è¯·æ±‚ç§¯å‹é—®é¢˜ã€‚

3. **Agent-Centric Resource Allocation æå¤§æå‡ç¡¬ä»¶åˆ©ç”¨ç‡**  
   â€œæŒ‰éœ€ç»‘å®š + å¿«é€ŸçŠ¶æ€äº¤æ¢â€æœºåˆ¶ä½¿å¾—æ•°åƒ agent å…±äº«æœ‰é™ç¡¬ä»¶æˆä¸ºå¯èƒ½ï¼Œé¿å…èµ„æºé”æ­»ã€‚

4. **FlexMARL å…·å¤‡å·¥ä¸šçº§å¯æ‰©å±•æ€§**  
   æ”¯æŒè·¨èŠ‚ç‚¹éƒ¨ç½²ã€å¼‚æ„æ¨¡å‹æ··åˆè®­ç»ƒï¼Œåœ¨çœŸå®ç”Ÿäº§ç¯å¢ƒä¸­å±•ç°å‡ºå“è¶Šç¨³å®šæ€§ä¸æ€§èƒ½ã€‚

---

### å±€é™æ€§
- **ä¾èµ–é«˜æ€§èƒ½é€šä¿¡ç½‘ç»œ**ï¼šD2D/H2D æƒé‡è¿ç§»å¯¹ RDMA æˆ– HCCS ç­‰é«˜é€Ÿäº’è¿æœ‰è¾ƒå¼ºä¾èµ–ã€‚
- **æ§åˆ¶å¹³é¢å¤æ‚åº¦å¢åŠ **ï¼šå¼•å…¥ experience storeã€Set/Get APIã€process group ç­‰æŠ½è±¡ï¼Œå¢åŠ äº†ç³»ç»Ÿå¼€å‘ä¸è°ƒè¯•éš¾åº¦ã€‚
- **å°šæœªæ¢ç´¢æ›´å¤æ‚çš„ credit assignment æœºåˆ¶**ï¼šç›®å‰ credit assignment å‡è®¾å·²çŸ¥ï¼Œæœªæ¥å¯é›†æˆæ›´æ™ºèƒ½çš„åå‘å½’å› ç®—æ³•ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **multi-turn, long-horizon** åœºæ™¯ä¸‹çš„åŠ¨æ€ agent ç»„åˆä¸è§’è‰²æ¼”åŒ–ã€‚
- ç»“åˆ **MoEï¼ˆMixture of Expertsï¼‰** æ¶æ„è¿›ä¸€æ­¥ä¼˜åŒ– agent ç²’åº¦çš„èµ„æºè°ƒåº¦ã€‚
- æ¢ç´¢ **fault-tolerant æœºåˆ¶** ä»¥åº”å¯¹å¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒä¸­çš„èŠ‚ç‚¹å¤±æ•ˆé—®é¢˜ã€‚
- å°† FlexMARL åº”ç”¨äºæ›´å¤šé¢†åŸŸï¼Œå¦‚è‡ªåŠ¨é©¾é©¶ã€é‡‘èå†³ç­–ã€ç§‘å­¦å‘ç°ç­‰å¤æ‚åä½œç³»ç»Ÿã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **FlexMARL æ˜¯é¦–ä¸ªçœŸæ­£å®ç° rollout ä¸ training ååŒè®¾è®¡çš„å¤§è§„æ¨¡ LLM-based MARL æ¡†æ¶ï¼Œé€šè¿‡ disaggregationã€micro-batch async pipelineã€hierarchical load balancing ä¸ agent-centric resource allocationï¼Œåœ¨çœŸå®å·¥ä¸šåœºæ™¯ä¸­å®ç°äº†é«˜è¾¾ 7.3Ã— çš„ç«¯åˆ°ç«¯åŠ é€Ÿä¸ 5.6Ã— çš„ç¡¬ä»¶åˆ©ç”¨ç‡æå‡ã€‚**

</details>

---

### 3. [Training deep physical neural networks with local physical information bottleneck](https://arxiv.org/abs/2602.09569)

**Authors**: Hao Wang, Ziao Wang, Xiangpeng Liang, Han Zhao, Jianqi Hu, Junjie Jiang, Xing Fu, Jianshi Tang, Huaqiang Wu, Sylvain Gigan, Qiang Liu  
**Category**: cs.LG  
**Published**: 2026-02-11  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2602.09569v1  

#### Abstract
Deep learning has revolutionized modern society but faces growing energy and latency constraints. Deep physical neural networks (PNNs) are interconnected computing systems that directly exploit analog dynamics for energy-efficient, ultrafast AI execution. Realizing this potential, however, requires ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Training deep physical neural networks with local physical information bottleneck*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰æ·±åº¦ç‰©ç†ç¥ç»ç½‘ç»œï¼ˆ**deep Physical Neural Networks, PNNs**ï¼‰é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **æ¨¡æ‹Ÿ-ç°å®å·®è·**ï¼ˆsimulation-reality gapï¼‰ï¼šä¼ ç»Ÿ in silico è®­ç»ƒä¾èµ–ç²¾ç¡®å»ºæ¨¡ï¼Œéš¾ä»¥é€‚é…çœŸå®ç¡¬ä»¶ä¸­çš„éç†æƒ³æ€§ï¼ˆå¦‚å™ªå£°ã€æ¼‚ç§»ã€æ•…éšœï¼‰ã€‚
- **è®­ç»ƒæ•ˆç‡ä½**ï¼šåŸºäºåå‘ä¼ æ’­ï¼ˆbackpropagation, BPï¼‰çš„æ–¹æ³•éœ€è¦ç«¯åˆ°ç«¯æ¢¯åº¦æµï¼Œå¯¹æ•°å­—è¾…åŠ©æ¨¡å‹å’Œå…¨å±€åŒæ­¥è¦æ±‚é«˜ã€‚
- **é€šç”¨æ€§å·®**ï¼šç°æœ‰æ–¹æ³•é€šå¸¸é’ˆå¯¹ç‰¹å®šç‰©ç†å¹³å°è®¾è®¡ï¼Œéš¾ä»¥è·¨å¹³å°è¿ç§»ã€‚
- **å¯æ‰©å±•æ€§å—é™**ï¼šæ·±å±‚çº§è”ç»“æ„ä¸‹ï¼Œè¯¯å·®ä¼ æ’­å›°éš¾ï¼Œå°¤å…¶åœ¨éå¾®åˆ†ç³»ç»Ÿä¸­ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šPhysical Information Bottleneck (PIB)
ä½œè€…æå‡º **PIB** â€”â€”ä¸€ç§å°†ä¿¡æ¯è®ºä¸å±€éƒ¨å­¦ä¹ ç»“åˆçš„é€šç”¨è®­ç»ƒæ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å°†æ¯ä¸ªç‰©ç†è®¡ç®—å•å…ƒè§†ä¸ºä¸€ä¸ª**ä¿¡æ¯é€šé“**ï¼ˆinformation channelï¼‰ï¼Œé€šè¿‡ä¼˜åŒ–å±€éƒ¨ç›®æ ‡å‡½æ•°æ¥æå–ä»»åŠ¡ç›¸å…³ç‰¹å¾å¹¶æŠ‘åˆ¶å†—ä½™è¾“å…¥ä¿¡æ¯ã€‚
- å±€éƒ¨ç›®æ ‡ä¸ºï¼š  
  $$
  \mathcal{L}(Z^l, \beta) = I(Y; Z^l) - \beta I(X; Z^l)
  $$
  å…¶ä¸­ $Z^l$ æ˜¯ç¬¬ $l$ å±‚è¾“å‡ºç‰¹å¾ï¼Œ$X$ æ˜¯åŸå§‹è¾“å…¥ï¼Œ$Y$ æ˜¯æ ‡ç­¾ï¼Œ$I(\cdot;\cdot)$ è¡¨ç¤ºäº’ä¿¡æ¯ã€‚

è¯¥æ–¹æ³•çš„å…³é”®åˆ›æ–°åœ¨äºï¼š
- **çŸ©é˜µåŒ–äº’ä¿¡æ¯ä¼°è®¡**ï¼ˆmatrix-based mutual informationï¼‰ï¼šé¿å…é«˜ç»´ç©ºé—´ä¸­ä¼ ç»Ÿäº’ä¿¡æ¯ä¼°è®¡çš„ä¸å¯è¡Œæ€§ï¼Œä½¿ç†è®ºå¯è½åœ°äºå®éªŒç³»ç»Ÿã€‚
- **å®Œå…¨æœ¬åœ°åŒ–è®­ç»ƒ**ï¼šæ¯å±‚ä»…éœ€æœ¬åœ°æµ‹é‡è¾“å‡ºã€å…¨å±€è¾“å…¥ $X$ å’Œç›®æ ‡ $Y$ï¼Œæ— éœ€å­˜å‚¨ä¸­é—´æ¢¯åº¦æˆ–æ‰§è¡Œå…¨ç½‘å‰å‘ä¼ æ’­ã€‚
- **ä¸ä¾èµ–æ•°å­—ä»£ç†æ¨¡å‹æˆ–å¯¹æ¯”æµ‹é‡**ï¼šæ‘†è„± hybrid training ä¸­çš„ä»¿çœŸä¾èµ–å’Œ PhyLL ç±»æ–¹æ³•çš„æ•°æ®å†—ä½™å¼€é”€ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | æ˜¯å¦éœ€æ•°å­—æ¨¡å‹ | æ˜¯å¦æ”¯æŒéå¾®åˆ†ç³»ç»Ÿ | æ˜¯å¦æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒ | æŠ—å™ª/å®¹é”™èƒ½åŠ› |
|------|----------------|--------------------|---------------------|---------------|
| End-to-end BP | æ˜¯ | å¦ | å¦ | å¼± |
| Physics-aware training (PAT) | æ˜¯ | éƒ¨åˆ† | å¦ | ä¸­ç­‰ |
| Direct Feedback Alignment (DFA) | å¦ | æ˜¯ | å¦ | ä¸­ç­‰ |
| Physical Local Learning (PhyLL) | å¦ | æ˜¯ | å¦ | å¼±ï¼ˆæ•°æ®æ•ˆç‡ä½ï¼‰ |
| **PIBï¼ˆæœ¬æ–‡ï¼‰** | âŒ | âœ… | âœ… | âœ…âœ…ï¼ˆå¼ºï¼‰ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼š
> - **é«˜å…¼å®¹æ€§**ï¼šé€‚ç”¨äº isomorphicï¼ˆå¦‚ memristorï¼‰å’Œ broken-isomorphismï¼ˆå¦‚å…‰å­¦æ•£å°„ä»‹è´¨ï¼‰ä¸¤ç±» PNN å•å…ƒï¼›
> - **é«˜æ•ˆé²æ£’**ï¼šæœ¬åœ°è®­ç»ƒ + ä¿¡æ¯å‹ç¼©æœºåˆ¶æå‡æŠ—å™ªæ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼›
> - **å¯æ‰©å±•æ€§å¼º**ï¼šæ”¯æŒå¹¶è¡Œã€å»ä¸­å¿ƒåŒ–çš„åœ°ç†åˆ†å¸ƒè®­ç»ƒï¼›
> - **ç¡¬ä»¶å‹å¥½**ï¼šé€‚åº”ä¸¥é‡ç¡¬ä»¶æ•…éšœï¼ˆå¦‚ADCæŸåï¼‰ï¼ŒåŠ¨æ€æ¢å¤æ€§èƒ½ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
| å®éªŒåœºæ™¯ | æ•°æ®é›† | æè¿° |
|--------|-------|------|
| åˆ†ç±»ä»»åŠ¡ | **MNIST**, **MNIST-1D**, **Fashion-MNIST** | æ‰‹å†™æ•°å­—ã€ç®€åŒ–ä¸€ç»´ç‰ˆæœ¬ã€æœé¥°å›¾åƒåˆ†ç±» |
| è‡ªç›‘ç£å­¦ä¹  | Fashion-MNISTï¼ˆæ— æ ‡ç­¾ï¼‰ | å­¦ä¹ è¯­ä¹‰åˆ†ç¦»çš„è¡¨ç¤º |
| å¼ºåŒ–å­¦ä¹  | **CartPole-v1**ï¼ˆè‡ªå®šä¹‰ç¯å¢ƒï¼‰ | æ§åˆ¶å€’ç«‹æ‘†ä»»åŠ¡ |

### âš™ï¸ å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### å¹³å°ä¸€ï¼šåŸºäº **memristor** çš„ç”µå­ isomorphic å•å…ƒ
- æ„å»ºå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰å’Œå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰
- è¾“å…¥/æƒé‡ç¼–ç ä¸ºç”µå‹/ç”µå¯¼çŠ¶æ€ï¼Œåˆ©ç”¨æ¬§å§†å®šå¾‹å’ŒåŸºå°”éœå¤«å®šå¾‹å®ç° MVM
- æµ‹é‡è¾“å‡ºç”µæµä½œä¸ºç‰¹å¾
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - åˆ†ç±»å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰
  - å¯¹æ¯” in silico BP ä¸éƒ¨ç½²åæ€§èƒ½ä¸‹é™
  - æ•…éšœæ¢å¤èƒ½åŠ›ï¼ˆbroken ADC åœºæ™¯ä¸‹çš„ç²¾åº¦å›å‡ï¼‰

#### å¹³å°äºŒï¼šåŸºäº **optical scattering medium** çš„å…‰å­¦ broken-isomorphism å•å…ƒ
- åˆ©ç”¨å¤šé‡å…‰æ•£å°„ç”Ÿæˆ speckle pattern ä½œä¸ºéçº¿æ€§ç‰¹å¾æ˜ å°„
- ä½¿ç”¨å•†ç”¨ OPU æˆ–è‡ªç ” SLM ç³»ç»Ÿï¼Œä¸è·å–ä¼ è¾“çŸ©é˜µï¼ˆtransmission matrixï¼‰
- æ•°å­—å±‚å¯è®­ç»ƒï¼Œç‰©ç†éƒ¨åˆ†å›ºå®š
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - â€œFit-then-compressâ€ åŠ¨æ€è½¨è¿¹åˆ†æï¼ˆä¿¡æ¯å¹³é¢å¯è§†åŒ–ï¼‰
  - å™ªå£°é²æ£’æ€§æµ‹è¯•ï¼ˆè¾“å…¥åŠ å™ªï¼‰
  - å°æ ·æœ¬å­¦ä¹ ï¼ˆdata efficiencyï¼‰
  - Out-of-Distribution (OOD) æ£€æµ‹èƒ½åŠ›

#### å¤šåœºæ™¯æ‹“å±•å®éªŒ
- **Unsupervised Learning**ï¼šä¿®æ”¹ PIB ç›®æ ‡ä¸º $I(Z_1;Z_2) - \beta[I(X_1;Z_1)+I(X_2;Z_2)]$ï¼Œç”¨äºå¯¹æ¯”å­¦ä¹ é£æ ¼çš„è‡ªç›‘ç£è®­ç»ƒ
- **Reinforcement Learning**ï¼šç»“åˆ TD Q-learning loss ä¸ PIBï¼Œå®ç°å¼‚æ­¥æ›´æ–°ä»¥æ©ç›–ç¡¬ä»¶å»¶è¿Ÿ
- **Decentralized Training**ï¼šåœ¨åŒ—äº¬ï¼ˆmemristorï¼‰å’Œå·´é»ï¼ˆopticalï¼‰ä¸¤åœ°å¹¶è¡Œè®­ç»ƒæ··åˆ deep PNN

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|--------|-----|------|
| End-to-end BP (in silico) | æ¢¯åº¦æ³• | ä¸Šç•Œå‚è€ƒï¼Œä½†å­˜åœ¨ simulation-reality gap |
| PAT (Physics-aware training) | Hybrid BP | ä¾èµ–æ•°å­—æ¨¡å‹ï¼Œæ˜“å—å»ºæ¨¡è¯¯å·®å½±å“ |
| DFA (Direct Feedback Alignment) | æ¨¡å‹æ— å…³ | ä¸éœ€çœŸå®æ¢¯åº¦ï¼Œä½†æ€§èƒ½å¸¸ä½äº BP |
| PhyLL (Physical Local Learning) | å±€éƒ¨å¯¹æ¯”å­¦ä¹  | ä¸éœ€æ¨¡å‹ï¼Œä½†éœ€å¤šæ¬¡å‰ä¼ ä¸å¯¹æ¯”æ ·æœ¬ï¼Œæ•ˆç‡ä½ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

| å®éªŒ | æ–¹æ³• | æ€§èƒ½è¡¨ç° |
|------|------|---------|
| **MNIST åˆ†ç±»ï¼ˆmemristorï¼‰** | PIBï¼ˆå®éªŒï¼‰ | **96.3%** å‡†ç¡®ç‡ï¼ˆå‡å€¼ Â± stdï¼Œå…­æ¬¡è¿è¡Œï¼‰ |
| | In silico BPï¼ˆä»¿çœŸï¼‰ | 96.4% |
| | In silico BPï¼ˆéƒ¨ç½²åï¼‰ | ä¸‹é™è‡³ **94.0%** |
| **MNIST-1D åˆ†ç±»** | PIBï¼ˆå®éªŒ vs ä»¿çœŸï¼‰ | æ€§èƒ½å‡ ä¹ä¸€è‡´ï¼Œæ¥è¿‘ BP ä¸Šé™ |
| | In silico BPï¼ˆéƒ¨ç½²åï¼‰ | ä¸‹é™ **8.5%** |
| **ç¡¬ä»¶æ•…éšœæ¢å¤ï¼ˆADCæŸåï¼‰** | åˆå§‹ç²¾åº¦ | **73.5%** |
| | ç» PIB è‡ªé€‚åº”é‡è®­å | æ¢å¤è‡³ **>90.0%** |
| **Fashion-MNISTï¼ˆå…‰å­¦å¹³å°ï¼‰** | OPUï¼ˆbinary ç¼–ç ï¼‰ | æœ€é«˜è¾¾ **86.4%** |
| | SLM setupï¼ˆ8-bitï¼Œå­é›†ï¼‰ | è¾¾ **93.4%** |
| **å¼ºåŒ–å­¦ä¹ ï¼ˆCartPole-v1ï¼‰** | PIB + TD loss | æˆåŠŸè¾¾åˆ°â€œsolved regimeâ€ï¼ˆå¹³å‡å›åˆå¾—åˆ† â‰¥ 195ï¼‰ |
| **å»ä¸­å¿ƒåŒ–è®­ç»ƒ** | åŒ—äº¬ + å·´é»åŒèŠ‚ç‚¹ | åŒæ–¹ç‹¬ç«‹æ”¶æ•›ï¼Œæœ€ç»ˆå®Œæˆä¸‹æ¸¸åˆ†ç±»ä»»åŠ¡ |

### ğŸ” ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœï¼ˆFig. 3Cï¼‰
åœ¨ **noise robustness**, **data efficiency**, å’Œ **OOD detection** ä¸‰ä¸ªç»´åº¦ä¸Šå…¨é¢ä¼˜äºåŸºçº¿ï¼š
- åœ¨ **5% è¾“å…¥å™ªå£°å¼ºåº¦** ä¸‹ï¼ŒPIB å‡†ç¡®ç‡ä»ä¿æŒé«˜ä½ï¼Œæ˜¾è‘—ä¼˜äº PATã€DFA å’Œ PhyLLï¼›
- åœ¨å°è®­ç»ƒé›†ï¼ˆ$10^3 \sim 10^4$ æ ·æœ¬ï¼‰æ¡ä»¶ä¸‹ï¼ŒPIB æ›´å¿«é¥±å’Œï¼›
- OOD æ£€æµ‹ç‡æ›´é«˜ï¼Œè¡¨æ˜å­¦åˆ°çš„è¡¨å¾æ›´å…·åˆ¤åˆ«æ€§å’Œæ³›åŒ–æ€§ã€‚

### ğŸ” æ¶ˆèå®éªŒä¸å…³é”®è§‚å¯Ÿ
- **ä¿¡æ¯å¹³é¢åŠ¨æ€åˆ†æ**ï¼ˆFig. 3Bï¼‰æ˜¾ç¤ºå…¸å‹çš„â€œå…ˆæ‹Ÿåˆåå‹ç¼©â€ï¼ˆfit-then-compressï¼‰è¡Œä¸ºï¼š
  - åˆæœŸ $I(Y;Z^l)$ å¿«é€Ÿä¸Šå‡ â†’ æ•è·ä»»åŠ¡ç›¸å…³ä¿¡æ¯
  - åæœŸ $I(X;Z^l)$ ä¸‹é™è€Œ $I(Y;Z^l)$ ä¿æŒ â†’ å‹ç¼©æ— å…³å˜å¼‚
- **UMAP å¯è§†åŒ–** æ˜¾ç¤ºéšç€è®­ç»ƒè¿­ä»£å¢åŠ ï¼Œç‰¹å¾é€æ¸èšç±»æ¸…æ™°ï¼ˆFig. 2Cï¼‰
- **è‡ªç›‘ç£å­¦ä¹ ä¸­æ— æ ‡ç­¾è¯­ä¹‰è§£è€¦**ï¼šmemristive PNN èƒ½è‡ªåŠ¨åŒºåˆ†â€œä¸Šè£…/ä¸‹è£…â€ä¸â€œé‹ç±»â€ï¼ŒéªŒè¯äº†è¡¨ç¤ºè´¨é‡ï¼ˆFig. 4A insetï¼‰

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **PIB æ˜¯é¦–ä¸ªå°†ä¿¡æ¯ç“¶é¢ˆåŸç†è½¬åŒ–ä¸ºå¯æ“ä½œè®­ç»ƒç›®æ ‡çš„ PNN æ¡†æ¶**ï¼Œå®ç°äº†ä»è§£é‡Šå·¥å…·åˆ°ä¸»åŠ¨ä¼˜åŒ–å™¨çš„è·ƒè¿ã€‚
2. **æœ¬åœ°åŒ– + ä¿¡æ¯å‹ç¼©æœºåˆ¶å¤©ç„¶å¢å¼ºé²æ£’æ€§**ï¼šä¸ä»…èƒ½æŠµæŠ—ç¡¬ä»¶å™ªå£°ï¼Œè¿˜èƒ½åœ¨ä¸¥é‡ç»„ä»¶æ•…éšœä¸‹åŠ¨æ€æ¢å¤æ€§èƒ½ã€‚
3. **æ— éœ€æ•°å­—ä»£ç†æ¨¡å‹æˆ–å¯¹æ¯”æµ‹é‡**ï¼Œæå¤§é™ä½å®éªŒå¤æ‚åº¦å’Œèµ„æºæ¶ˆè€—ï¼ŒçœŸæ­£å®ç°â€œintrinsicâ€è®­ç»ƒã€‚
4. **æ”¯æŒè·¨å¹³å°é€šç”¨æ€§**ï¼šæˆåŠŸåº”ç”¨äº memristorï¼ˆisomorphicï¼‰å’Œ optical scatteringï¼ˆbroken-isomorphismï¼‰ä¸¤ç§æˆªç„¶ä¸åŒçš„ç‰©ç†ç³»ç»Ÿã€‚
5. **å…·å¤‡å¼ºå¤§æ‰©å±•æ½œåŠ›**ï¼šæ”¯æŒè‡ªç›‘ç£ã€å¼ºåŒ–å­¦ä¹ åŠåœ°ç†åˆ†å¸ƒå¼çš„å¹¶è¡Œè®­ç»ƒï¼Œä¸ºæœªæ¥å¤§è§„æ¨¡ PNN éƒ¨ç½²æä¾›å¯è¡Œè·¯å¾„ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä»ä¾èµ– **digital auto-differentiation** æ¥è®¡ç®—å‚æ•°æ¢¯åº¦ï¼ˆä¾‹å¦‚å¯¹æ•°å­—å±‚æƒé‡ï¼‰ï¼Œå°šæœªå®Œå…¨æ‘†è„±æ•°å­—è®¡ç®—ä¾èµ–ï¼ˆè§ Supplementary Table 1ï¼‰ã€‚
- å¯¹äºææ·±ç½‘ç»œï¼Œå±€éƒ¨ä¼˜åŒ–å¯èƒ½åç¦»å…¨å±€æœ€ä¼˜ï¼Œæ€§èƒ½ç•¥é€Šäºç†æƒ³ end-to-end BPï¼ˆå°½ç®¡å·®è·æ­£åœ¨ç¼©å°ï¼‰ã€‚
- çŸ©é˜µåŒ–äº’ä¿¡æ¯è™½å¯è®¡ç®—ï¼Œä½†åœ¨æé«˜ç»´ç³»ç»Ÿä¸­ä»å¯èƒ½å­˜åœ¨ä¼°è®¡åå·®ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- ç»“åˆ **surrogate gradient æ–¹æ³•**ï¼ˆå¦‚ DFAï¼‰è¿›ä¸€æ­¥æ¶ˆé™¤å¯¹ auto-diff çš„ä¾èµ–ï¼Œå®ç°çº¯ç‰©ç†æ¢¯åº¦è¿‘ä¼¼ã€‚
- æ¢ç´¢å¦‚ä½•å¼•å…¥ **inductive bias** åˆ°ç‰©ç†å•å…ƒæœ¬èº«ï¼Œæå‡æ·±å±‚è¡¨è¾¾èƒ½åŠ›ã€‚
- æ‰©å±•è‡³æ›´å¤šç‰©ç†å¹³å°ï¼Œå¦‚ **acoustic wave reservoirs**, **magnetic skyrmions**, **active matter** ç­‰ã€‚
- æ¢ç´¢ PIB åœ¨ **scaling laws** æ–¹é¢çš„è¡¨ç°ï¼Œç ”ç©¶ deep PNN æ˜¯å¦ä¹Ÿèƒ½å‘ˆç°ç±»ä¼¼å¤§æ¨¡å‹çš„æ¶Œç°èƒ½åŠ›ã€‚

---

> ğŸ’¬ **æ€»ä½“è¯„ä»·**ï¼š  
> æœ¬æ–‡æå‡ºçš„ **PIB æ¡†æ¶** æ˜¯ç‰©ç†ç¥ç»ç½‘ç»œè®­ç»ƒé¢†åŸŸçš„ä¸€é¡¹é‡è¦çªç ´ã€‚å®ƒä¸ä»…è§£å†³äº†é•¿æœŸå­˜åœ¨çš„â€œæ¨¡æ‹Ÿ-ç°å®é¸¿æ²Ÿâ€é—®é¢˜ï¼Œè¿˜é€šè¿‡ä¿¡æ¯è®ºè§†è§’æä¾›äº†æ–°çš„ç†è®ºæ´è§ï¼Œå¹¶å±•ç¤ºäº†å“è¶Šçš„å®ç”¨æ€§ä¸å¯æ‰©å±•æ€§ã€‚è¯¥å·¥ä½œæœ‰æœ›æ¨åŠ¨ deep PNN å‘æ›´é«˜æ•ˆã€æ›´é²æ£’ã€æ›´é€šç”¨çš„æ–¹å‘å‘å±•ï¼Œæˆä¸ºé€šå‘è¶…ä½åŠŸè€—ã€è¶…é«˜é€Ÿ AI ç¡¬ä»¶çš„é‡è¦åŸºçŸ³ã€‚

</details>

---

### 4. [DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents](https://arxiv.org/abs/2602.07035)

**Authors**: Jiahao Zhao, Shaoxuan Xu, Zhongxiang Sun, Fengqi Zhu, Jingyang Ou, Yuling Shi, Chongxuan Li, Xiao Zhang, Jun Xu  
**Category**: cs.AI  
**Published**: 2026-02-11  
**Score**: 11.5  
**Type**: new  
**ArXiv ID**: 2602.07035v1  

#### Abstract
Recently, Diffusion Large Language Models (dLLMs) have demonstrated unique efficiency advantages, enabled by their inherently parallel decoding mechanism and flexible generation paradigm. Meanwhile, despite the rapid advancement of Search Agents, their practical deployment is constrained by a fundam...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDLLM-Searcher: Adapting Diffusion Large Language Models for Search Agents

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡é’ˆå¯¹å½“å‰ **Search Agents** åœ¨å®é™…éƒ¨ç½²ä¸­é¢ä¸´çš„ä¸¤å¤§æ ¸å¿ƒæŒ‘æˆ˜ï¼š

1. **Latency Challengeï¼ˆå»¶è¿ŸæŒ‘æˆ˜ï¼‰**ï¼šåœ¨æ ‡å‡†çš„ ReAct èŒƒå¼ä¸‹ï¼Œæ¨¡å‹éœ€ä¸²è¡Œæ‰§è¡Œâ€œæ€è€ƒ â†’ å·¥å…·è°ƒç”¨ â†’ ç­‰å¾…å·¥å…·å“åº”â€æµç¨‹ï¼Œåœ¨ç­‰å¾…å¤–éƒ¨å·¥å…·è¿”å›ç»“æœæœŸé—´æ¨¡å‹å¤„äºç©ºé—²çŠ¶æ€ï¼Œå¯¼è‡´ç«¯åˆ°ç«¯æ¨ç†å»¶è¿Ÿä¸¥é‡ã€‚
2. **Agent Ability Challengeï¼ˆæ™ºèƒ½ä½“èƒ½åŠ›æŒ‘æˆ˜ï¼‰**ï¼šç°æœ‰çš„ **dLLMs**ï¼ˆdiffusion large language modelsï¼‰è™½ç„¶å…·å¤‡å¹¶è¡Œè§£ç ä¼˜åŠ¿ï¼Œä½†åœ¨å¤šæ­¥æ¨ç†ã€å·¥å…·è°ƒç”¨æ ¼å¼éµå¾ªç­‰æ–¹é¢è¡¨ç°è¾ƒå¼±ï¼Œéš¾ä»¥èƒœä»» Search Agent çš„è§’è‰²ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½œè€…æå‡º **DLLM-Searcher**ï¼Œä¸€ä¸ªä¸“ä¸º dLLMs è®¾è®¡çš„ Search Agent ä¼˜åŒ–æ¡†æ¶ï¼ŒåŒ…å«ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š

#### ï¼ˆ1ï¼‰**ä¸¤é˜¶æ®µåè®­ç»ƒç®¡é“ï¼ˆTwo-stage Post-training Pipelineï¼‰**
- **Agentic SFT**ï¼šåŸºäºé«˜è´¨é‡æ•™å¸ˆæ¨¡å‹ç”Ÿæˆçš„è½¨è¿¹è¿›è¡Œç›‘ç£å¾®è°ƒï¼Œä½¿ dLLM å­¦ä¼šéµå¾ª `think` å’Œ `tool_call` çš„ä¸¥æ ¼æ ¼å¼ï¼Œå¹¶æŒæ¡ä¿¡æ¯æ£€ç´¢ä¸æ¨ç†ååŒçš„èƒ½åŠ›ã€‚
- **Agentic VRPO**ï¼šåŸºäº SFT æ¨¡å‹çš„ rollout ç»“æœæ„å»ºèƒœè€…/è´¥è€…å¯¹ï¼Œé‡‡ç”¨æ–¹å·®ç¼©å‡åå¥½ä¼˜åŒ–è¿›ä¸€æ­¥æå‡æ¨¡å‹çš„æ¨ç†ä¸æ£€ç´¢èƒ½åŠ›ã€‚

> ç‰¹åˆ«è®¾è®¡äº† **Agentic Noising** å’Œ **Agentic ELBO**ï¼Œç¡®ä¿è®­ç»ƒè¿‡ç¨‹ä¸­ä»…å…³æ³¨ `think` å’Œ `tool_call` åŒºåŸŸï¼Œé¿å… `tool_response` æ³„éœ²é€ æˆè®­ç»ƒ-æ¨ç†ä¸ä¸€è‡´ã€‚

#### ï¼ˆ2ï¼‰**æ–°å‹ä»£ç†èŒƒå¼ï¼šParallel-Reasoning and Acting (P-ReAct)**
- åˆ©ç”¨ dLLMs çš„éè‡ªå›å½’ã€å—å†…åŒå‘æ³¨æ„åŠ›ç‰¹æ€§ï¼Œæå‡ºä¸€ç§æ— éœ€é¢å¤–è®­ç»ƒçš„æ¨ç†ç­–ç•¥ï¼š
  - **Token Pre-filling**ï¼šåœ¨ç”Ÿæˆå—ä¸­é¢„å¡«å…… `<tool_call>` å’Œ `</tool_call>` è¾¹ç•Œæ ‡è®°ã€‚
  - **Confidence Biasing**ï¼šåœ¨è§£ç æ—¶å¯¹è¾¹ç•Œå†…çš„ token å¢åŠ ç½®ä¿¡åº¦åç½®ï¼Œå¼•å¯¼æ¨¡å‹ä¼˜å…ˆè§£ç  `tool_call` å†…å®¹ã€‚
- å®ç°â€œ**å…ˆå‘å‡ºå·¥å…·è¯·æ±‚ï¼Œå†å®Œæˆæ€è€ƒè¿‡ç¨‹**â€ï¼Œä»è€Œåœ¨ç­‰å¾…å·¥å…·å“åº”çš„åŒæ—¶ç»§ç»­ç”Ÿæˆæ¨ç†å†…å®¹ï¼Œå®ç°â€œthinking while waitingâ€ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ•ˆç‡** | P-ReAct å®ç°çº¦ **15% çš„ç«¯åˆ°ç«¯æ¨ç†åŠ é€Ÿ**ï¼Œæ˜¾è‘—ç¼“è§£ Latency Challenge |
| **æ€§èƒ½** | æ€§èƒ½åª²ç¾ä¸»æµåŸºäº ARMs çš„ Search Agentsï¼ˆå¦‚ R1Searcherï¼‰ï¼Œç”šè‡³åœ¨éƒ¨åˆ†ä»»åŠ¡ä¸Šè¶…è¶Š |
| **å¯æ§æ€§** | P-ReAct å®ç°è¿‘ä¹ **100% æˆåŠŸç‡çš„ tool_call ä¼˜å…ˆè§£ç **ï¼Œæ§åˆ¶æ€§å¼º |
| **é€šç”¨æ€§** | æ–¹æ³•é€‚ç”¨äºä»»æ„æ”¯æŒå—æ‰©æ•£æœºåˆ¶çš„ dLLMï¼ˆå¦‚ SDARï¼‰ï¼Œæ— éœ€ä¿®æ”¹æ¨¡å‹ç»“æ„ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

å››ä¸ªå¤šè·³é—®ç­”ï¼ˆmulti-hop QAï¼‰åŸºå‡†ç”¨äºè¯„ä¼°ä¿¡æ¯æ£€ç´¢ä¸æ¨ç†èƒ½åŠ›ï¼š

- **HotpotQA**ï¼šå¤šè·³äº‹å®æ¨ç†ï¼Œå¼ºè°ƒè§£é‡Šæ€§å’Œå¯è¿½æº¯æ€§
- **2WikiMultiHopQA**ï¼šåŸºäºç»´åŸºç™¾ç§‘çš„å¤æ‚æ¨ç†
- **Musique**ï¼šé€šè¿‡å•è·³é—®é¢˜ç»„åˆæ„é€ çš„å¤šè·³ QA
- **Bamboogle**ï¼šè·¨é¢†åŸŸã€å‡ºåŸŸï¼ˆout-of-domainï¼‰æµ‹è¯•é›†ï¼Œæ£€éªŒæ³›åŒ–èƒ½åŠ›

> æ‰€æœ‰æµ‹è¯•é›†å‡ä»å¼€å‘é›†ä¸­é‡‡æ · 500 ä¾‹ï¼ˆBamboogle å…¨éƒ¨ 125 ä¾‹ï¼‰

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **è¯„ä¼°æŒ‡æ ‡**
- **ACCRï¼ˆAccuracyï¼‰**ï¼šé¢„æµ‹ç­”æ¡ˆæ˜¯å¦åŒ…å«æ­£ç¡®ç­”æ¡ˆï¼ˆgolden answerï¼‰
- **ACCLï¼ˆLLM-as-Judge Accuracyï¼‰**ï¼šä½¿ç”¨ Doubao-Seed-1.8 ä½œä¸ºè£åˆ¤æ¨¡å‹åˆ¤æ–­å›ç­”æ­£ç¡®æ€§ï¼Œæ›´é²æ£’

#### **è®­ç»ƒæ•°æ®æ„å»º**
- **Agentic SFT**ï¼šä½¿ç”¨ Doubao-Seed-1.8 ç”Ÿæˆ 3977 æ¡é«˜è´¨é‡è½¨è¿¹ï¼ˆå«å®Œæ•´ `think` å’Œ `tool_call`ï¼‰
- **Agentic VRPO**ï¼šåŸºäº SFT æ¨¡å‹åœ¨ R1Searcher çš„ Stage 2 æ•°æ®ä¸Š rolloutï¼Œç­›é€‰å‡º 2237 ä¸ªèƒœ/è´Ÿå¯¹

#### **æ¨¡å‹ä¸å·¥å…·**
- **Backbone**ï¼šSDARï¼ˆBlock Diffusion LMï¼Œå‚æ•°é‡ 8Bï¼Œå—å¤§å° 128ï¼‰
- **æ£€ç´¢å·¥å…·**ï¼šGoogle Search APIï¼Œè¿”å› top-10 ç»“æœ
- **ç¡¬ä»¶**ï¼š8 Ã— NVIDIA H100 GPU

#### **è§£ç é…ç½®**
- 128 æ­¥å»å™ªï¼Œæ¸©åº¦ 1.0
- P-ReAct ä¸­ç½®ä¿¡åº¦åç½® Î± = 0.5

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| ç±»åˆ« | åŸºçº¿æ¨¡å‹ |
|------|---------|
| **ä¼ ç»Ÿ RAG** | SuRe, Selective-Context, Adaptive-RAG, IRCoT, Iter-RetGen, CR-Planner, ReARTeR |
| **ARM-based Search Agents** | Search-o1, Search-R1, WebSailor*, R1Searcher* |
| **dLLM-based Agents** | SDARï¼ˆåŸå§‹ï¼‰ã€Dreamã€LLaDA |

> *è¡¨ç¤ºå®éªŒè®¾ç½®è°ƒæ•´ä»¥ä¿æŒå…¬å¹³æ¯”è¾ƒ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 1ï¼‰**

| æ¨¡å‹ | HotpotQA (ACCR/ACCL) | 2Wiki (ACCR/ACCL) | Bamboogle (ACCR/ACCL) | Musique (ACCR/ACCL) | Avg ACCR/ACCL |
|------|------------------------|--------------------|------------------------|----------------------|----------------|
| **R1Searcher*** | 58.0 / 62.2 | 59.6 / 63.4 | 66.4 / 68.8 | 28.2 / 31.4 | **53.1 / 56.5** |
| **DLLM-Searcher** | **60.4 / 62.4** | **69.8 / 64.6** | **68.8 / 69.6** | **29.0 / 29.8** | **57.0 / 56.6** âœ… |

> âœ… **DLLM-Searcher åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡è¾¾åˆ°æˆ–è¶…è¿‡æœ€å¼º ARM åŸºçº¿ï¼ˆR1Searcherï¼‰**

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- **vs. ä¼ ç»Ÿ RAG**ï¼šå¹³å‡ ACCR æå‡è¶… **37 ä¸ªç™¾åˆ†ç‚¹**ï¼ˆå¦‚ ReARTeR ä¸º 45.4ï¼ŒDLLM-Searcher ä¸º 57.0ï¼‰
- **vs. åŸå§‹ dLLMs**ï¼š
  - SDAR åŸå§‹æ¨¡å‹å› æ ¼å¼é”™è¯¯æ— æ³•è¿è¡Œï¼ˆå…¨éƒ¨ parsing failï¼‰
  - Dream å’Œ LLaDA è¡¨ç°æå·®ï¼ˆACCR ~10â€“35ï¼‰ï¼ŒéªŒè¯äº† **Agent Ability Challenge** çš„å­˜åœ¨
- **vs. ARM Agents**ï¼šæ€§èƒ½æŒå¹³ç”šè‡³ç•¥ä¼˜ï¼Œè¯æ˜ dLLMs ç»è¿‡é€‚é…åå¯æˆä¸ºå¼ºå¤§ Agent Backbone

### **æ¶ˆèå®éªŒç»“æœ**

#### **RQ1: åè®­ç»ƒæœ‰æ•ˆæ€§ï¼ˆTable 2ï¼‰**

| é˜¶æ®µ | HotpotQA ACCR | 2Wiki ACCR | Bamboogle ACCR | Musique ACCR |
|------|---------------|------------|----------------|--------------|
| Agentic SFT | 57.2 | 66.4 | 64.6 | 24.4 |
| **+ Agentic VRPO** | **60.4 (+3.2)** | **69.8 (+3.4)** | **68.8 (+4.2)** | **29.0 (+4.6)** |

> VRPO å¸¦æ¥ç¨³å®šä¸”æ˜¾è‘—çš„æ€§èƒ½å¢ç›Šï¼ˆ+3~5%ï¼‰ï¼Œè¯´æ˜åå¥½ä¼˜åŒ–æœ‰æ•ˆæå‡äº†æ¨ç†è´¨é‡ã€‚

#### **RQ2: P-ReAct æ¨ç†æ•ˆç‡ï¼ˆFigure 3ï¼‰**

| æ•°æ®é›† | æ¨ç†æ—¶é—´é™ä½ |
|-------|-------------|
| HotpotQA | 14.77% |
| 2Wiki | 21.00% |
| Bamboogle | 22.08% |
| Musique | 12.67% |
| **å¹³å‡** | **â‰ˆ15%** |

> åœ¨å‡ ä¹æ— æ€§èƒ½æŸå¤±çš„æƒ…å†µä¸‹å®ç°æ˜¾è‘—åŠ é€Ÿï¼ŒéªŒè¯äº† P-ReAct å¯¹ Latency Challenge çš„ç¼“è§£æ•ˆæœã€‚

#### **RQ3: dLLMs çš„é¡ºåºè‡ªç”±ç”Ÿæˆä¼˜åŠ¿ï¼ˆFigure 4ï¼‰**

- å°† P-ReAct åº”ç”¨äº **Qwen3 ç³»åˆ— ARMs**ï¼ˆ8B, 30B, 235Bï¼‰ï¼š
  - å³ä¾¿å¼ºåˆ¶ prompt å¼•å¯¼å…ˆç”Ÿæˆ `tool_call`ï¼Œä»å¯¼è‡´ **æ€§èƒ½ä¸‹é™ 2.5%~13.3%**
- åè§‚ **DLLM-Searcher + P-ReAct**ï¼š
  - åœ¨ HotpotQA å’Œ Musique ä¸Š **å‡†ç¡®ç‡åè€Œç•¥æœ‰ä¸Šå‡**
  - æœ€å¤§é™å¹…ä»… 4.5%ï¼Œè¿œå°äº ARMs

> è¯´æ˜ **dLLMs èƒ½åˆ©ç”¨åŒå‘ä¸Šä¸‹æ–‡â€œéšå¼æ¨ç†â€ç”Ÿæˆé«˜è´¨é‡ tool_call**ï¼Œè€Œ ARMs ä¾èµ–æ˜¾å¼ CoTï¼Œä¸€æ—¦æ‰“ä¹±é¡ºåºå³å´©æºƒã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **dLLMs å®Œå…¨å¯ä»¥èƒœä»» Search Agent è§’è‰²**ï¼šé€šè¿‡é’ˆå¯¹æ€§åè®­ç»ƒï¼ˆAgentic SFT + VRPOï¼‰ï¼Œå¯å…‹æœå…¶åŸæœ¬åœ¨æ¨ç†ä¸æ ¼å¼éµå¾ªä¸Šçš„çŸ­æ¿ã€‚
2. **P-ReAct æ˜¯ dLLMs ç‹¬æœ‰çš„é«˜æ•ˆèŒƒå¼**ï¼šåˆ©ç”¨å…¶éè‡ªå›å½’ä¸å—å†…åŒå‘æ³¨æ„åŠ›ï¼Œå®ç°â€œå…ˆè¡ŒåŠ¨åæ€è€ƒâ€çš„å¹¶è¡Œæ‰§è¡Œï¼Œå¸¦æ¥ **~15% æ¨ç†åŠ é€Ÿ**ã€‚
3. **æ€§èƒ½ä¸æ•ˆç‡å…¼å¾—**ï¼šDLLM-Searcher ä¸ä»…æ€§èƒ½åª²ç¾æœ€å…ˆè¿›çš„ ARM-based Agentsï¼Œè¿˜åœ¨æ¨ç†æ•ˆç‡ä¸Šå…·æœ‰å¤©ç„¶ä¼˜åŠ¿ã€‚
4. **é¡ºåºè‡ªç”±æ˜¯ dLLMs çš„æ ¸å¿ƒä¼˜åŠ¿**ï¼šå³ä½¿ `tool_call` å…ˆäº `think` è§£ç ï¼Œä¹Ÿèƒ½ä¿æŒé«˜è´¨é‡è¾“å‡ºï¼Œè¿™æ˜¯ ARMs æ— æ³•åšåˆ°çš„ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

- **ä¾èµ–é«˜è´¨é‡è®­ç»ƒæ•°æ®**ï¼šAgentic SFT å’Œ VRPO ä¾èµ–æ•™å¸ˆæ¨¡å‹æˆ– rollout ç”Ÿæˆçš„é«˜è´¨é‡è½¨è¿¹ï¼Œè‹¥æ•°æ®å™ªå£°å¤§åˆ™æ•ˆæœå—é™ã€‚
- **ä»…é€‚ç”¨äºæ”¯æŒå—æ‰©æ•£çš„ dLLM**ï¼šå¦‚ SDARã€Mercury ç­‰ï¼›çº¯è‡ªå›å½’æˆ–å…¨åºåˆ—æ‰©æ•£æ¨¡å‹ä¸é€‚ç”¨ P-ReActã€‚
- **æœªæ¢ç´¢æ›´å¤æ‚çš„å·¥å…·äº¤äº’**ï¼šç›®å‰ä»…æ”¯æŒå•ä¸€æœç´¢å·¥å…·ï¼Œæœªæ¥å¯æ‰©å±•è‡³ visitã€code interpreter ç­‰å¤šå·¥å…·åœºæ™¯ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

- å°† P-ReAct æ‰©å±•è‡³ **å¤šå·¥å…·è°ƒåº¦ä¸å¹¶å‘æ‰§è¡Œ**
- æ¢ç´¢ **å®Œå…¨ç«¯åˆ°ç«¯è®­ç»ƒ P-ReAct æ§åˆ¶æœºåˆ¶**ï¼ˆè€Œéä»…æ¨ç†æœŸå¹²é¢„ï¼‰
- æ„å»ºæ›´å¤§è§„æ¨¡çš„ **dLLM-native Agent è®­ç»ƒæ•°æ®é›†**
- æ¢ç´¢ dLLMs åœ¨å…¶ä»–ç±»å‹ Agentï¼ˆå¦‚è§„åˆ’ã€æ¸¸æˆã€ä»£ç æ‰§è¡Œï¼‰ä¸­çš„åº”ç”¨æ½œåŠ›

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **DLLM-Searcher æˆåŠŸå°† dLLMs ä»â€œä½æ•ˆä½†å¹¶è¡Œâ€çš„ç”Ÿæˆæ¨¡å‹ï¼Œè½¬å˜ä¸ºâ€œé«˜æ•ˆä¸”æ™ºèƒ½â€çš„ Search Agentï¼Œé¦–æ¬¡å®ç°äº†æ¨ç†æ€§èƒ½ä¸ç«¯åˆ°ç«¯å»¶è¿Ÿçš„åŒé‡çªç ´ã€‚**

</details>

---

### 5. [Who Deserves the Reward? SHARP: Shapley Credit-based Optimization for Multi-Agent System](https://arxiv.org/abs/2602.08335)

**Authors**: Yanming Li, Xuelin Zhang, WenJie Lu, Ziye Tang, Maodong Wu, Haotian Luo, Tongtong Wu, Zijie Peng, Hongze Mi, Yibo Feng, Naiqiang Tan, Chao Huang, Hong Chen, Li Shen  
**Category**: cs.AI  
**Published**: 2026-02-11  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2602.08335v1  

#### Abstract
Integrating Large Language Models (LLMs) with external tools via multi-agent systems offers a promising new paradigm for decomposing and solving complex problems. However, training these systems remains notoriously difficult due to the credit assignment challenge, as it is often unclear which specif...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šWho Deserves the Reward? SHARP: Shapley Credit-based Optimization for Multi-Agent System

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨åŸºäº **Large Language Models (LLMs)** å’Œå¤–éƒ¨å·¥å…·é›†æˆçš„ **multi-agent system (MAS)** ä¸­ï¼Œå°½ç®¡å…¶åœ¨å¤æ‚ä»»åŠ¡åˆ†è§£ä¸æ‰§è¡Œä¸­å±•ç°å‡ºæ½œåŠ›ï¼Œä½†è®­ç»ƒè¿‡ç¨‹é¢ä¸´ä¸¥é‡çš„ **credit assignment problem**ï¼ˆä¿¡ç”¨åˆ†é…é—®é¢˜ï¼‰ï¼š  
å½“ä¸€ä¸ªå†³ç­–è½¨è¿¹æˆåŠŸæˆ–å¤±è´¥æ—¶ï¼Œéš¾ä»¥å‡†ç¡®åˆ¤æ–­æ˜¯ **planner agent**ï¼ˆè´Ÿè´£ä»»åŠ¡åˆ†è§£ï¼‰è¿˜æ˜¯æŸä¸ª **worker agent**ï¼ˆè´Ÿè´£å­ä»»åŠ¡æ‰§è¡Œï¼‰åº”å¾—å¥–åŠ±æˆ–æ‰¿æ‹…æƒ©ç½šã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–ç¨€ç–çš„ã€å…¨å±€å¹¿æ’­çš„å¥–åŠ±ä¿¡å·ï¼ˆbroadcast rewardsï¼‰ï¼Œæ— æ³•æ•æ‰ä¸ªä½“ä»£ç†çš„çœŸå®è¾¹é™…è´¡çŒ®ï¼Œå¯¼è‡´ç­–ç•¥æ›´æ–°ä½æ•ˆç”šè‡³è¯¯å¯¼ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šSHARP
æœ¬æ–‡æå‡º **SHARP (Shapley-based Hierarchical Attribution for Reinforcement Policy)**ï¼Œä¸€ç§åŸºäº **Shapley Value** çš„ç²¾ç»†åŒ–ä¿¡ç”¨åˆ†é…æ¡†æ¶ï¼Œç”¨äºä¼˜åŒ–å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡åšå¼ˆè®ºä¸­çš„ **Shapley Value** æ•°å­¦æœºåˆ¶ï¼Œé‡åŒ–æ¯ä¸ª agent å¯¹æœ€ç»ˆä»»åŠ¡æˆåŠŸçš„å› æœè´¡çŒ®ã€‚

#### åˆ›æ–°ç‚¹ï¼š
- âœ… **ä¸‰é‡åˆ†è§£å¥–åŠ±æœºåˆ¶ (tripartite decomposed reward)**ï¼š
  1. **Global Broadcast-Accuracy Reward**ï¼šç»ˆç«¯å‡†ç¡®æ€§å¥–åŠ±ï¼Œç¡®ä¿æ•´ä½“ç›®æ ‡å¯¹é½ï¼›
  2. **Shapley-based Marginal-Credit Reward**ï¼šåŸºäºåäº‹å®æ©ç ï¼ˆcounterfactual maskingï¼‰è®¡ç®—æ¯ä¸ª agent çš„è¾¹é™…è´¡çŒ®ï¼Œå®ç°ç²¾ç¡®ä¿¡ç”¨å½’å±ï¼›
  3. **Tool-Process Reward**ï¼šè¿‡ç¨‹çº§åé¦ˆï¼Œè¯„ä¼°å·¥å…·è°ƒç”¨çš„æœ‰æ•ˆæ€§å’Œæ­£ç¡®æ€§ï¼Œæå‡æ‰§è¡Œæ•ˆç‡ã€‚
- âœ… **å½’ä¸€åŒ–ä¼˜åŠ¿æœºåˆ¶**ï¼šé€šè¿‡ group-relative policy gradient å¯¹ä¸åŒ agent çš„ä¼˜åŠ¿è¿›è¡Œæ ‡å‡†åŒ–ï¼Œç¨³å®šè®­ç»ƒè¿‡ç¨‹ã€‚
- âœ… **å‚æ•°å…±äº«çš„ self-play æ¶æ„**ï¼šæ‰€æœ‰è§’è‰²ï¼ˆplanner/workerï¼‰ç”±åŒä¸€ä¸ª LLM å®ä¾‹åŒ–ï¼Œä»…é€šè¿‡ä¸åŒçš„ system prompt åŒºåˆ†åŠŸèƒ½ï¼Œå®ç°ç«¯åˆ°ç«¯è”åˆä¼˜åŒ–ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ MATPO, GRPOï¼‰ | SHARP |
|------|-----------------------------|-------|
| å¥–åŠ±ç²’åº¦ | å…¨å±€å¹¿æ’­ï¼Œç²—ç²’åº¦ | ç»†ç²’åº¦ï¼Œagent-specific |
| ä¿¡ç”¨å½’å± | æ¨¡ç³Šï¼Œæ··æ·†ä¸ªä½“è´¡çŒ® | ç²¾ç¡®ï¼ŒåŸºäºå› æœæ¨ç† |
| è®­ç»ƒç¨³å®šæ€§ | æ˜“å—å™ªå£°å½±å“ï¼Œæ³¢åŠ¨å¤§ | æ›´ä½æ–¹å·®æ¢¯åº¦ï¼Œæ”¶æ•›æ›´ç¨³ |
| æ‰§è¡Œæ•ˆç‡ | å¯èƒ½å†—ä½™è°ƒç”¨å·¥å…· | æŠ‘åˆ¶ä½æ•ˆè¡Œä¸ºï¼Œå‡å°‘ token æ¶ˆè€— |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–äº”ä¸ªçœŸå®ä¸–ç•ŒåŸºå‡†ï¼Œæ¶µç›–å¤šè·³æ¨ç†ã€ç½‘é¡µå¯¼èˆªã€æ•°å­¦æ¨ç†ç­‰å¤æ‚åœºæ™¯ï¼š
- **MuSiQue**ï¼šæ„é€ å‹å¤šè·³é—®ç­”ï¼Œéœ€çœŸæ­£é“¾å¼æ¨ç†ã€‚
- **GAIA-text**ï¼šç»¼åˆ AI åŠ©æ‰‹è¯„æµ‹ï¼Œæ¶‰åŠæœç´¢ã€å·¥å…·ä½¿ç”¨ä¸é€»è¾‘æ¨ç†ã€‚
- **WebWalkerQA**ï¼šç»“æ„åŒ–ç½‘é¡µéå†ä¸è¯æ®èšåˆã€‚
- **FRAMES**ï¼šç«¯åˆ°ç«¯æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç»Ÿä¸€è¯„æµ‹å¹³å°ã€‚
- **DocMath-Eval**ï¼šé•¿æ–‡æœ¬æ–‡æ¡£ä¸­çš„æ•°å€¼ä¸æ•°å­¦æ¨ç†ã€‚

> âš ï¸ æ³¨æ„ï¼šé™¤ MuSiQue å¤–ï¼Œå…¶ä½™æµ‹è¯•é›†å‡é‡‡ç”¨ zero-shot è®¾ç½®ï¼Œä¸å‚ä¸è®­ç»ƒã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹éª¨å¹²**ï¼šä»¥ **Qwen3-8B** ä¸ºä¸»å¹²æ¨¡å‹ï¼Œéƒ¨åˆ†å®éªŒå¯¹æ¯” LLaMA-3.1-8Bã€‚
- **è®­ç»ƒé…ç½®**ï¼š
  - ä½¿ç”¨ AdamW ä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ $10^{-5}$ï¼Œbatch size 256ã€‚
  - æ¯ä¸ªæŸ¥è¯¢é‡‡æ · 8 æ¡è½¨è¿¹ï¼ˆrolloutsï¼‰ï¼Œå…±è®­ç»ƒ 180 æ­¥ã€‚
  - ä½¿ç”¨ 64Ã—A100 GPU é›†ç¾¤å¹¶è¡Œè®­ç»ƒã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - ä¸»è¦æŒ‡æ ‡ä¸º **match accuracy**ï¼ˆç­”æ¡ˆåŒ¹é…ç‡ï¼‰ã€‚
  - è¾…åŠ©åˆ†æåŒ…æ‹¬ MMLUï¼ˆæ£€æµ‹ç¾éš¾æ€§é—å¿˜ï¼‰ã€token æ¶ˆè€—ã€åè°ƒç»“æ„å˜åŒ–ç­‰ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
åˆ†ä¸ºå››ç±»ï¼š
1. **Vanilla LLMs**ï¼šQwen3-8B RAGã€LLaMA-3.1-8B RAG
2. **Prompt-based æ–¹æ³•**ï¼šPlan-Search
3. **å•æ™ºèƒ½ä½“ RL æ–¹æ³•**ï¼šSingle-agent GRPO
4. **å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆæ— ç»†ç²’åº¦ä¿¡ç”¨å»ºæ¨¡ï¼‰**ï¼š
   - ç»“æ„åŒ–æœªè®­ç»ƒï¼šPlanner-Worker
   - å›¾ç»“æ„æ–¹æ³•ï¼šG-Designerã€CARD
   - å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼šAceSearcherã€COAã€MATPO

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æ–¹æ³• | MuSiQue | GAIA-text | WebWalkerQA | FRAMES | **AVG** |
|------|--------|----------|-------------|--------|--------|
| Single-agent GRPO | 45.93 | 27.97 | 7.47 | 30.20 | 27.89 |
| MATPO (SOTA MARL) | 47.00 | 31.65 | 7.47 | 37.10 | **30.81** |
| **SHARP (ours)** | **50.76** | **33.70** | **8.50** | **37.29** | **32.56** |

âœ… **SHARP åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šå‡æ’åç¬¬ä¸€**ï¼Œå¹³å‡æ€§èƒ½è¶…è¶Šæœ€å¼º baseline **MATPO 1.75 åˆ†**ã€‚

#### æ€§èƒ½å¢ç›Šç»Ÿè®¡ï¼š
- ç›¸æ¯” **single-agent æ–¹æ³•**ï¼šå¹³å‡æå‡ **23.66%**
- ç›¸æ¯” **multi-agent æ–¹æ³•**ï¼šå¹³å‡æå‡ **14.05%**

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰æ˜¯å¦å¯ç”¨ Shapley ä¿¡ç”¨æœºåˆ¶ï¼Ÿ
- **ç§»é™¤ planner-level ä¿¡ç”¨** â†’ å‡†ç¡®ç‡ä¸‹é™çº¦ 0.6â€“0.65
- **ç§»é™¤ worker-level ä¿¡ç”¨** â†’ ä¸‹é™æ›´å¤§ï¼Œè¾¾ **0.88â€“1.00**
- **å®Œå…¨ç§»é™¤ Shapley æœºåˆ¶** â†’ æ€§èƒ½å›è½è‡³ 47.00ï¼ˆæ¥è¿‘ MATPOï¼‰
> ğŸ” è¡¨æ˜ï¼šworker çš„æ‰§è¡Œè´¨é‡æ§åˆ¶å¯¹é•¿ç¨‹ä»»åŠ¡æ›´é‡è¦ï¼Œè€Œ planner çš„åˆ†è§£ç­–ç•¥ä¹Ÿæ˜¾è‘—å½±å“æœ€ç»ˆè¡¨ç°ã€‚

#### ï¼ˆ2ï¼‰æ¨¡å‹è§„æ¨¡æ‰©å±•æ€§ï¼ˆScaling Lawsï¼‰
åœ¨ MuSiQue ä¸Šæµ‹è¯•ä¸åŒ backbone è§„æ¨¡ï¼š
| æ¨¡å‹å¤§å° | å•æ™ºèƒ½ä½“ baseline | SHARP |
|---------|------------------|--------|
| 0.6B | 3.85 | 6.29 |
| 8B | 36.35 | **50.76** |

â¡ï¸ SHARP çš„ç›¸å¯¹ä¼˜åŠ¿éšæ¨¡å‹å¢å¤§è€Œæ‰©å¤§ï¼Œåœ¨ 8B æ¨¡å‹ä¸Šé¢†å…ˆ **14.41 åˆ†**ï¼ŒéªŒè¯å…¶æ›´å¼ºçš„å¯æ‰©å±•æ€§ã€‚

#### ï¼ˆ3ï¼‰è®­ç»ƒç¨³å®šæ€§åˆ†æ
åœ¨ GAIA-text ä¸Šè§‚å¯Ÿè®­ç»ƒæ›²çº¿ï¼ˆå›¾5ï¼‰ï¼š
- **Single-agent GRPO / MATPO**ï¼šå‡ºç°æ˜æ˜¾æ³¢åŠ¨ç”šè‡³æ€§èƒ½å›é€€
- **SHARP**ï¼šå‘ˆç°å•è°ƒä¸Šå‡è¶‹åŠ¿ï¼Œä» 27.53 â†’ 33.70ï¼Œæ— éœ‡è¡

> ğŸ“ˆ è¡¨æ˜ SHARP èƒ½æœ‰æ•ˆé™ä½ reward varianceï¼Œæå‡è®­ç»ƒé²æ£’æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **Marginal Credit Modeling æ˜¯å…³é”®çªç ´ç‚¹**ï¼šç›¸æ¯”æ¶æ„è®¾è®¡æˆ–ä¼˜åŒ–ç®—æ³•æœ¬èº«ï¼Œæ˜¾å¼å»ºæ¨¡ agent çš„è¾¹é™…è´¡çŒ®æ›´èƒ½å¸¦æ¥æŒç»­æ€§èƒ½æå‡ã€‚
2. âœ… **ååŒä¿¡ç”¨åˆ†é…äº§ç”ŸååŒæ•ˆåº”**ï¼šplanner ä¸ worker åŒæ—¶è·å¾—ç²¾å‡†åé¦ˆæ—¶ï¼Œæ•´ä½“æ€§èƒ½è¿œè¶…å•ç‹¬ä¼˜åŒ–ä»»ä¸€è§’è‰²ä¹‹å’Œã€‚
3. âœ… **æå‡ planner-worker åè°ƒè´¨é‡**ï¼š
   - planner scoreï¼ˆå¹³å‡ Shapley å€¼ï¼‰ä» 0.4542ï¼ˆbaselineï¼‰â†’ 0.5084ï¼ˆSHARPï¼‰
   - æœ‰ç”¨ subagent æ¯”ä¾‹ä» 11.03% â†’ 12.96%
   - æœ‰å®³ subagent è°ƒç”¨æ¯”ä¾‹ä» **5.48% â†“ è‡³ 4.40%**
4. âœ… **è®­ç»ƒæ¢æ¨ç†æ•ˆç‡**ï¼šè™½ç„¶è®­ç»ƒæˆæœ¬å¢åŠ ï¼ˆå›  Shapley è®¡ç®—ï¼‰ï¼Œä½†éƒ¨ç½²æ—¶æ¨ç† token æ¶ˆè€—ä» ~9.1k â†“ è‡³ ~8.3kï¼Œä¸”è·¯å¾„æ›´ç®€æ´é«˜æ•ˆã€‚
5. âœ… **ç¼“è§£ç¾éš¾æ€§é—å¿˜**ï¼šåœ¨ MMLU æµ‹è¯•ä¸­ï¼ŒSHARP ä¸ä»…æœªä¸¢å¤±é€šç”¨çŸ¥è¯†ï¼Œåè€Œç•¥æœ‰æå‡ï¼ˆ94.65% > åŸå§‹ 93.04%ï¼‰ï¼Œè¯´æ˜å…¶æ›´æ–°æ›´å…·é€‰æ‹©æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- â— **è®¡ç®—å¼€é”€è¾ƒé«˜**ï¼šShapley å€¼ä¼°ç®—éœ€å¤šæ¬¡åäº‹å®è½¨è¿¹æ¨¡æ‹Ÿï¼Œå°¤å…¶åœ¨ agent æ•°é‡å¤šæ—¶æˆæœ¬æ˜¾è‘—ä¸Šå‡ï¼ˆå¯é€šè¿‡ sparsification ç¼“è§£ï¼‰ã€‚
- â— **ä¾èµ–é«˜è´¨é‡ç¯å¢ƒæ¨¡æ‹Ÿ**ï¼šcounterfactual evaluation è¦æ±‚èƒ½å‡†ç¡®â€œå±è”½â€æŸ agent å¹¶ä¿æŒå…¶ä»–äº¤äº’ä¸å˜ï¼Œç°å®ä¸­å¯èƒ½éš¾ä»¥å®Œç¾å®ç°ã€‚
- â— **å½“å‰ä»é™äº role-specialized MAS**ï¼šå°šæœªæ¨å¹¿è‡³å®Œå…¨å»ä¸­å¿ƒåŒ–çš„ agent ç¤¾ä¼šã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- ğŸ”® æ¢ç´¢æ›´é«˜æ•ˆçš„ Shapley è¿‘ä¼¼ç®—æ³•ï¼ˆå¦‚ Monte Carlo sampling æˆ– learned surrogatesï¼‰
- ğŸ”® å°† SHARP æ‰©å±•è‡³åŠ¨æ€æ‹“æ‰‘ç»“æ„ï¼ˆdynamic topologyï¼‰æˆ–å¤šæ¨¡æ€ agent ç³»ç»Ÿ
- ğŸ”® ç ”ç©¶å¦‚ä½•è‡ªåŠ¨è¯†åˆ«å¹¶å‰ªæä½æ•ˆæ‰§è¡Œè·¯å¾„ï¼ˆpruning low-utility execution pathsï¼‰
- ğŸ”® æ„å»ºå¯è§£é‡Šçš„ agent coordination dashboardï¼Œåˆ©ç”¨ Shapley ä¿¡ç”¨è¿›è¡Œå¯è§†åŒ–è¯Šæ–­

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> **SHARP é€šè¿‡å¼•å…¥åšå¼ˆè®ºé©±åŠ¨çš„ Shapley Credit æœºåˆ¶ï¼Œè§£å†³äº† multi-agent LLM ç³»ç»Ÿä¸­é•¿æœŸå­˜åœ¨çš„ credit assignment ç“¶é¢ˆï¼Œå®ç°äº†æ›´ç²¾å‡†ã€ç¨³å®šã€é«˜æ•ˆçš„è”åˆè®­ç»ƒï¼Œåœ¨å¤šä¸ªç°å®åŸºå‡†ä¸Šæ˜¾è‘—è¶…è¶Š SOTA æ–¹æ³•ã€‚**

</details>

---

### 6. [Efficient Remote Prefix Fetching with GPU-native Media ASICs](https://arxiv.org/abs/2602.09725)

**Authors**: Liang Mi, Weijun Wang, Jinghan Chen, Ting Cao, Haipeng Dai, Yunxin Liu  
**Category**: cs.DC  
**Published**: 2026-02-11  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2602.09725v1  

#### Abstract
Remote KV cache reuse fetches KV cache for identical contexts from remote storage, avoiding recomputation, accelerating LLM inference. While it excels in high-speed networks, its performance degrades significantly in bandwidth-limited scenarios. Recent studies address this by transmitting KV caches ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šEfficient Remote Prefix Fetching with GPU-native Media ASICs

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°ä»£å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†ä¸­ï¼Œ**è¿œç¨‹ KV cache å¤ç”¨**ï¼ˆremote KV cache reuseï¼‰æ˜¯ä¸€ç§é€šè¿‡ä»è¿œç¨‹å­˜å‚¨è·å–å·²è®¡ç®—çš„ KV ç¼“å­˜æ¥é¿å…é‡å¤è®¡ç®—ã€åŠ é€Ÿæ¨ç†çš„æŠ€æœ¯ã€‚ç„¶è€Œï¼Œåœ¨å¸¦å®½å—é™çš„ç½‘ç»œç¯å¢ƒä¸‹ï¼Œè¯¥æŠ€æœ¯é¢ä¸´ä»¥ä¸‹ç“¶é¢ˆï¼š
- **ä¼ è¾“å»¶è¿Ÿé«˜**ï¼šåŸå§‹ KV cache æ•°æ®é‡å·¨å¤§ï¼Œç›´æ¥ä¼ è¾“æ•ˆç‡ä½ã€‚
- **å‹ç¼©è§£å‹ä»£ä»·é«˜**ï¼šè™½ç„¶å·²æœ‰ç ”ç©¶å°è¯•å¯¹ KV cache è¿›è¡Œå‹ç¼©ä»¥å‡å°‘ä¼ è¾“å¼€é”€ï¼Œä½†è§£å‹è¿‡ç¨‹é€šå¸¸ä¾èµ– CUDA æ ¸å¿ƒï¼Œä¸ LLM æ¨ç†äº‰æŠ¢ GPU èµ„æºï¼Œå¯¼è‡´ä¸¥é‡å¹²æ‰°ï¼ˆinterferenceï¼‰ã€‚
- **ç¡¬ä»¶æˆæœ¬é«˜**ï¼šéƒ¨åˆ†æ–¹æ¡ˆå°†è§£å‹å¸è½½åˆ° SmartNICï¼Œè™½å¯é¿å…å¹²æ‰°ï¼Œä½†éœ€è¦é¢å¤–æ˜‚è´µç¡¬ä»¶ï¼ˆå¦‚ NVIDIA BlueFieldï¼‰ï¼Œéš¾ä»¥å¹¿æ³›éƒ¨ç½²ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æœ¬æ–‡æå‡º **KVFetcher**ï¼Œé¦–æ¬¡åˆ©ç”¨ç°ä»£ GPU ä¸Šé—²ç½®çš„ **GPU-native è§†é¢‘ç¼–è§£ç  ASIC**ï¼ˆå¦‚ NVIDIA NVENC/NVDECï¼‰æ¥å®ç°é«˜æ•ˆã€ä½æˆæœ¬çš„è¿œç¨‹ KV cache å¤ç”¨ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°† KV cache å¼ é‡ç¼–ç ä¸ºè§†é¢‘æ ¼å¼è¿›è¡Œå‹ç¼©ä¼ è¾“ï¼Œå¹¶åœ¨ GPU å†…éƒ¨ä¸“ç”¨ç¡¬ä»¶ä¸Šå®Œæˆè§£ç ï¼Œä»è€Œç»•è¿‡é€šç”¨è®¡ç®—å•å…ƒã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š
1. **Codec-friendly Tensor Layout**  
   è®¾è®¡äº†ä¸€ç§é¢å‘è§†é¢‘ç¼–ç ä¼˜åŒ–çš„å¼ é‡å¸ƒå±€ç­–ç•¥ï¼Œè·³è¿‡æœ‰æŸçš„ DCT å’Œé‡åŒ–æ­¥éª¤ï¼Œå……åˆ†åˆ©ç”¨ H.265 çš„æ— æŸå¸§å†…/å¸§é—´é¢„æµ‹èƒ½åŠ›ï¼Œå®ç°äº†é«˜è¾¾ **11.9Ã— çš„å‹ç¼©æ¯”**ï¼Œä¸”ä¿æŒç”Ÿæˆç²¾åº¦æ— æŸã€‚

2. **Efficient KV Fetcher**  
   æ„å»ºäº†ä¸€ä¸ªé«˜æ•ˆçš„è¿œç¨‹ KV è·å–æµæ°´çº¿ï¼ŒåŒ…å«ä¸‰ä¸ªå…³é”®æŠ€æœ¯ï¼š
   - **Fetching-aware Scheduler**ï¼šåŒºåˆ†æ˜¯å¦éœ€è¦ KV å¤ç”¨çš„è¯·æ±‚ï¼Œå°† KV è·å–ç½®äºåå°å¼‚æ­¥æ‰§è¡Œï¼Œé¿å…é˜»å¡éå¤ç”¨è¯·æ±‚ã€‚
   - **Adaptive-resolution KV Fetching**ï¼šåŠ¨æ€è°ƒæ•´è§†é¢‘åˆ†è¾¨ç‡ä»¥é€‚åº”ç½‘ç»œæ³¢åŠ¨ï¼Œæœ€å°åŒ–ä¼ è¾“ä¸è§£ç ä¹‹é—´çš„æµæ°´çº¿æ°”æ³¡ï¼ˆpipeline bubbleï¼‰ã€‚
   - **Frame-wise Tensor Restoration**ï¼šé€å¸§æ¢å¤ KV tensorï¼Œæ˜¾è‘—é™ä½å†…å­˜å³°å€¼å ç”¨ï¼ˆ<70MBï¼‰ï¼Œé¿å…ä¸æ¨ç†å¼•æ“äº‰æŠ¢æ˜¾å­˜ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ¡ˆ | å¹²æ‰°æƒ…å†µ | æˆæœ¬ | å‹ç¼©æ¯” | å‡†ç¡®æ€§ |
|------|--------|------|-------|--------|
| CacheGen [46] | é«˜ï¼ˆCUDA è§£å‹ï¼‰ | ä½ | ä¸­ç­‰ | æœ‰æŸé£é™© |
| ShadowServe [68] | æ— ï¼ˆSmartNICï¼‰ | æé«˜ | ä¸­ç­‰ | æœ‰æŸé£é™© |
| **KVFetcher (Ours)** | **æ— ï¼ˆASIC è§£ç ï¼‰** | **é›¶æ–°å¢æˆæœ¬** | **é«˜ï¼ˆè¾¾11.9Ã—ï¼‰** | **æ— æŸ** |

KVFetcher åœ¨ä¸å¢åŠ ç¡¬ä»¶æˆæœ¬çš„å‰æä¸‹ï¼Œå®ç°äº†**æ— å¹²æ‰°ã€é«˜å‹ç¼©æ¯”ã€é«˜å‡†ç¡®ç‡**çš„è¿œç¨‹ KV å¤ç”¨ç³»ç»Ÿã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
è®ºæ–‡åœ¨å¤šä¸ªé•¿ä¸Šä¸‹æ–‡åŸºå‡†æµ‹è¯•é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œæ¶µç›–å¤šç§ä»»åŠ¡ç±»å‹ï¼š
- **L-Eval**ï¼šåŒ…å« 508 ä¸ªé•¿æ–‡æ¡£é—®ç­”ä»»åŠ¡ï¼Œä¸Šä¸‹æ–‡é•¿åº¦ 3Kâ€“200K tokensã€‚
- **LV-Eval**ï¼šæ›´å…·æŒ‘æˆ˜æ€§çš„å•è·³/å¤šè·³é—®ç­”ï¼Œå«å¹²æ‰°é¡¹ã€äº‹å®æ··æ·†ç­‰ï¼Œé•¿åº¦ 16Kâ€“256Kã€‚
- **LongBench-V2**ï¼šç³»ç»Ÿæ€§å¤šä»»åŠ¡è¯„æµ‹ï¼ŒåŒ…æ‹¬å¤šæ–‡æ¡£ QAã€é•¿å¯¹è¯ã€ä»£ç ç”Ÿæˆç­‰ï¼Œé•¿åº¦ 13Kâ€“167Kã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼šLWM-7Bï¼ˆ1M contextï¼‰ã€Yi-34Bï¼ˆ200K contextï¼‰ã€Llama3-70Bï¼ˆ128K contextï¼‰
- **ç¡¬ä»¶å¹³å°**ï¼šä¸‰ç§ä¸åŒæ¡£æ¬¡çš„ GPU é›†ç¾¤
  - **é«˜ç«¯**ï¼šNVIDIA A100 (80GB)ï¼Œæ¯å¡ 5 ä¸ª NVDEC
  - **ä¸­ç«¯**ï¼šNVIDIA H20 (96GB)ï¼Œæ¯å¡ 7 ä¸ª NVDEC
  - **ä½ç«¯**ï¼šNVIDIA L20 (48GB)ï¼Œæ¯å¡ 3 ä¸ª NVDEC
- **ç½‘ç»œå¸¦å®½**ï¼šæ¨¡æ‹Ÿ 1â€“40 Gbps çš„å¸¸è§„äº‘æœåŠ¡å¸¦å®½ç¯å¢ƒï¼ˆé RDMAï¼‰

### è¯„ä¼°æŒ‡æ ‡
- **TTFT**ï¼ˆTime to First Tokenï¼‰ï¼šé¦– token å»¶è¿Ÿï¼Œè¡¡é‡é¢„å¡«å……é˜¶æ®µæ•ˆç‡ã€‚
- **TPOT**ï¼ˆTime Per Output Tokenï¼‰ï¼šæ¯ä¸ªè¾“å‡º token çš„å¹³å‡å»¶è¿Ÿã€‚
- **Compression Ratio**ï¼šKV cache å‹ç¼©å‰åå¤§å°ä¹‹æ¯”ã€‚
- **Accuracy**ï¼šå„æ•°æ®é›†æ ‡å‡†æŒ‡æ ‡ï¼ˆExact Match, F1 Score ç­‰ï¼‰ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Full Prefill**ï¼šæ—  KV å¤ç”¨ï¼Œå®Œæ•´é‡æ–°è®¡ç®—ã€‚
- **Raw KV Reuse**ï¼šç›´æ¥ä¼ è¾“æœªå‹ç¼© KV cacheã€‚
- **Compressed KV Reuse**ï¼š
  - **CacheGen**ï¼šåŸºäº CUDA çš„ç®—æœ¯ç¼–ç å‹ç¼©ã€‚
  - **ShadowServe**ï¼šSmartNIC å¸è½½è§£å‹ã€‚
  - **llm.265**ï¼šä½¿ç”¨è§†é¢‘ç¼–ç ä½†è®¾è®¡ä¸å½“çš„åŸºçº¿ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- **æœ€é«˜ TTFT åŠ é€Ÿæ¯”è¾¾ 3.51Ã—**ï¼ˆç›¸æ¯” CacheGenï¼‰ï¼Œåœ¨å¤šæ•°åœºæ™¯ä¸‹å®ç° **1.52â€“3.51Ã— çš„ TTFT é™ä½**ã€‚
- **å‹ç¼©æ¯”æå‡æ˜¾è‘—**ï¼š
  - ç›¸æ¯” CacheGen æå‡ **2.17Ã—**
  - ç›¸æ¯” ShadowServe æå‡ **1.93Ã—**
  - ç›¸æ¯” llm.265 æå‡ **1.41Ã—**
- **ç²¾åº¦å®Œå…¨ä¿ç•™**ï¼šæ‰€æœ‰ä»»åŠ¡ä¸Šå‡å®ç° **lossless accuracy**ï¼Œè€Œ llm.265 å­˜åœ¨æ˜æ˜¾ç²¾åº¦ä¸‹é™ã€‚
- **éå¤ç”¨è¯·æ±‚å—ç›Šæ˜æ˜¾**ï¼š
  - TTFT é™ä½ **77%**
  - TPOT é™ä½ **35.4%**

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| å¯¹æ¯”é¡¹ | KVFetcher vs. CacheGen | KVFetcher vs. ShadowServe |
|--------|------------------------|----------------------------|
| TTFT | â†“ 1.52â€“3.51Ã— | æ˜¾è‘—æ›´ä¼˜ï¼ˆæ— éœ€é¢å¤–ç¡¬ä»¶ï¼‰ |
| å¹²æ‰°æ€§ | âœ… æ— å¹²æ‰°ï¼ˆASIC è§£ç ï¼‰ | âŒ é«˜æˆæœ¬ |
| éƒ¨ç½²æˆæœ¬ | âœ… é›¶æ–°å¢æˆæœ¬ | âŒ >$3000/NIC |
| å‡†ç¡®æ€§ | âœ… æ— æŸ | âš ï¸ æœ‰æŸé£é™© |

> å›¾ 21 æ˜¾ç¤ºï¼Œåœ¨ 1â€“40 Gbps å¸¦å®½èŒƒå›´å†…ï¼ŒKVFetcher åœ¨å‡ ä¹æ‰€æœ‰é…ç½®ä¸‹éƒ½ä¼˜äº CacheGenã€‚

### æ¶ˆèå®éªŒç»“æœ
- **Codec-friendly Tensor Layout è´¡çŒ®æœ€å¤§**ï¼š
  - ä»…é‡åŒ– â†’ å‹ç¼©æ¯” ~5.8Ã—
  - + Inter-frame layout â†’ ~8.7Ã—
  - + Intra-frame layout â†’ **~11.9Ã—**
- **Adaptive-resolution æå‡ 20% æ€§èƒ½**ï¼šç›¸æ¯”å›ºå®šåˆ†è¾¨ç‡ï¼ˆå¦‚ 1080pï¼‰ï¼Œè‡ªé€‚åº”æœºåˆ¶æœ‰æ•ˆåº”å¯¹ç½‘ç»œæŠ–åŠ¨ï¼Œå‡å°‘æµæ°´çº¿ç­‰å¾…æ—¶é—´ã€‚
- **Frame-wise Restoration æ˜¾å­˜å¼€é”€æä½**ï¼š
  - å³°å€¼æ˜¾å­˜å ç”¨ä»… **~400MB**ï¼ˆå¹¶å‘å¤„ç† 7 ä¸ªè§†é¢‘å—ï¼‰
  - è§£å‹ç¼“å†²åŒºå°äº **70MB**ï¼Œè¿œä½äº CacheGen çš„ 2.7Ã— åŸå§‹ KV å¤§å°ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **GPU-native è§†é¢‘ç¼–è§£ç å™¨æ˜¯è¢«å¿½è§†çš„å¼ºå¤§èµ„æº**ï¼šåœ¨å½“å‰ LLM æ¨ç†è¿‡ç¨‹ä¸­å®Œå…¨ç©ºé—²ï¼Œå¯ç”¨äº KV cache å‹ç¼©/è§£å‹ï¼Œå®ç°çœŸæ­£çš„ **zero-cost acceleration**ã€‚
2. **åˆç†çš„å¼ é‡å¸ƒå±€è‡³å…³é‡è¦**ï¼šç›²ç›®å°† KV tensor æ˜ å°„ä¸ºè§†é¢‘å¸§ä¼šå¯¼è‡´å‹ç¼©æ•ˆæœå·®ä¸”ç²¾åº¦æŸå¤±ï¼›å¿…é¡»ç»“åˆ LLM æ¶æ„ç‰¹æ€§ï¼ˆå¦‚ token ç»´åº¦ç›¸ä¼¼æ€§é«˜ï¼‰è®¾è®¡ codec-friendly layoutã€‚
3. **ç³»ç»Ÿçº§ååŒè®¾è®¡å†³å®šæœ€ç»ˆæ€§èƒ½**ï¼šä»…é é«˜å‹ç¼©æ¯”ä¸è¶³ä»¥ä¿è¯ä½ TTFTï¼Œè¿˜éœ€è°ƒåº¦ã€æµæ°´çº¿ã€å†…å­˜ç®¡ç†ç­‰å¤šæ–¹é¢ä¼˜åŒ–æ‰èƒ½å……åˆ†å‘æŒ¥ä¼˜åŠ¿ã€‚
4. **KVFetcher å¯æ‰©å±•æ€§å¼º**ï¼šé€‚ç”¨äºä»ä½ç«¯åˆ°é«˜ç«¯å„ç±» GPUï¼Œå°¤å…¶é€‚åˆä¸»æµäº‘æœåŠ¡å•†æä¾›çš„ä¸­ä½å¸¦å®½éƒ¨ç½²ç¯å¢ƒã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **NVENC èµ„æºæœ‰é™**ï¼šç›®å‰ GPU ä¸Šçš„ NVENC æ•°é‡è¾ƒå°‘ï¼ˆå¦‚ L20 ä»…æœ‰ 3 ä¸ªï¼‰ï¼Œå¯èƒ½æˆä¸ºå¹¶å‘å‹ç¼©æ—¶çš„ç“¶é¢ˆï¼Œé™åˆ¶åœ¨çº¿å‹ç¼©èƒ½åŠ›ã€‚
2. **ç¦»çº¿å‹ç¼©ä¸ºä¸»**ï¼šå½“å‰è®¾è®¡ä¸»è¦ç”¨äº**ç¦»çº¿å‹ç¼© + åœ¨çº¿è§£å‹**ï¼Œå°šä¸æ”¯æŒå®æ—¶åŠ¨æ€å‹ç¼©ï¼ˆonline compressionï¼‰ï¼Œåœ¨ P-D disaggregation åœºæ™¯ä¸­åº”ç”¨å—é™ã€‚
3. **é¢„åˆ†é…å†…å­˜æœºåˆ¶å¯èƒ½é˜»å¡å…¶ä»–è¯·æ±‚**ï¼šä¸ºä¿è¯å¤ç”¨è¯·æ±‚åŠæ—¶å“åº”ï¼Œéœ€é¢„å…ˆåˆ†é… GPU æ˜¾å­˜ï¼Œå¯èƒ½å¯¼è‡´éå¤ç”¨è¯·æ±‚å› å†…å­˜ä¸è¶³è¢«å»¶è¿Ÿã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ”¯æŒ **runtime online KV compression**ï¼Œæ»¡è¶³æ•…éšœè¿ç§»ã€èŠ‚ç‚¹é—´é€šä¿¡ç­‰éœ€æ±‚ã€‚
- å¼€å‘æ›´æ™ºèƒ½çš„ **æ˜¾å­˜äº¤æ¢æœºåˆ¶**ï¼ˆswap-in/outï¼‰ï¼Œå…è®¸å°† fetched KV cache å­˜å‚¨äºä¸»æœºå†…å­˜æˆ– SSDï¼ŒæŒ‰éœ€åŠ è½½è‡³ GPUï¼Œç¼“è§£å†…å­˜å‹åŠ›ã€‚
- æ¨åŠ¨ä¸‹ä¸€ä»£ GPU å¢åŠ  **NVENC/NVDEC æ•°é‡**ï¼Œé‡Šæ”¾æ›´å¤šä¸“ç”¨ç¡¬ä»¶æ½œåŠ›ã€‚
- å°†ç±»ä¼¼æ€æƒ³æ‹“å±•è‡³å…¶ä»–æ¨¡æ€ï¼ˆå¦‚ Vision-Language Modelsï¼‰ä¸­çš„ä¸­é—´çŠ¶æ€å¤ç”¨ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼šKVFetcher é€šè¿‡å·§å¦™åˆ©ç”¨ GPU ä¸Šé—²ç½®çš„è§†é¢‘ç¼–è§£ç  ASICï¼Œæå‡ºäº†ä¸€å¥—é«˜æ•ˆã€æ— å¹²æ‰°ã€ä½æˆæœ¬çš„è¿œç¨‹ KV cache å¤ç”¨æ–¹æ¡ˆï¼Œåœ¨ä¿æŒç”Ÿæˆç²¾åº¦çš„åŒæ—¶ï¼Œå®ç°äº†é«˜è¾¾ 3.51Ã— çš„ TTFT åŠ é€Ÿï¼Œä¸ºå¤§è§„æ¨¡ LLM æœåŠ¡æä¾›äº†æå…·å®ç”¨ä»·å€¼çš„æ–°è·¯å¾„ã€‚

</details>

---

### 7. [Effective MoE-based LLM Compression by Exploiting Heterogeneous Inter-Group Experts Routing Frequency and Information Density](https://arxiv.org/abs/2602.09316)

**Authors**: Zhendong Mi, Yixiao Chen, Pu Zhao, Xiaodong Yu, Hao Wang, Yanzhi Wang, Shaoyi Huang  
**Category**: cs.LG  
**Published**: 2026-02-11  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.09316v1  

#### Abstract
Mixture-of-Experts (MoE) based Large Language Models (LLMs) have achieved superior performance, yet the massive memory overhead caused by storing multiple expert networks severely hinders their practical deployment. Singular Value Decomposition (SVD)-based compression has emerged as a promising post...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šEffective MoE-based LLM Compression by Exploiting Heterogeneous Inter-Group Experts Routing Frequency and Information Density

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
Mixture-of-Experts (MoE) ç»“æ„çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è™½ç„¶åœ¨æ€§èƒ½ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†ç”±äºå…¶åŒ…å«å¤§é‡ç‹¬ç«‹çš„ä¸“å®¶ç½‘ç»œï¼Œå¯¼è‡´**å†…å­˜å¼€é”€å·¨å¤§**ï¼Œä¸¥é‡é˜»ç¢äº†å®é™…éƒ¨ç½²ã€‚

ç°æœ‰çš„åŸºäº SVD çš„å‹ç¼©æ–¹æ³•å­˜åœ¨ä¸¤å¤§ç¼ºé™·ï¼š
1. **é‡‡ç”¨ç»Ÿä¸€çš„ç§©åˆ†é…ï¼ˆuniform rank allocationï¼‰**ï¼Œå¿½ç•¥äº†ä¸åŒä¸“å®¶ä¹‹é—´æ˜¾è‘—çš„åˆ©ç”¨ç‡å·®å¼‚ï¼ˆå¦‚æŸäº›ä¸“å®¶é¢‘ç¹è¢«è·¯ç”±ï¼Œè€Œå¦ä¸€äº›å‡ ä¹æœªè¢«æ¿€æ´»ï¼‰ã€‚
2. **ç›´æ¥ä¸¢å¼ƒä½ç§©è¿‘ä¼¼åçš„æ®‹å·®é¡¹ï¼ˆresidualï¼‰**ï¼Œå‡è®¾å…¶å½±å“å¯å¿½ç•¥ï¼Œä½†å®é™…ä¸Šè¿™äº›æ®‹å·®å¯èƒ½åŒ…å«å¯¹ç‰¹å®šä»»åŠ¡è‡³å…³é‡è¦çš„ä¿¡æ¯ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šRFID-MoE
æœ¬æ–‡æå‡º **RFID-MoE**ï¼ˆRouting Frequency and Information Density-aware MoE compressionï¼‰ï¼Œä¸€ç§é¢å‘ MoE æ¨¡å‹çš„æœ‰æ•ˆå‹ç¼©æ¡†æ¶ï¼Œæ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰è‡ªé€‚åº”ç§©åˆ†é…ç­–ç•¥ï¼ˆAdaptive Rank Allocationï¼‰
- å¼•å…¥ä¸€ä¸ª**èåˆåº¦é‡æŒ‡æ ‡**ï¼Œç»“åˆä¸¤ä¸ªå…³é”®å› ç´ ï¼š
  - **Routing Frequencyï¼ˆè·¯ç”±é¢‘ç‡ï¼‰**ï¼šåæ˜ ä¸“å®¶åœ¨æ¨ç†è¿‡ç¨‹ä¸­çš„åŠ¨æ€æ¿€æ´»é¢‘ç‡ã€‚
  - **Information Densityï¼ˆä¿¡æ¯å¯†åº¦ï¼‰**ï¼šé€šè¿‡ **Effective Rank** è¡¡é‡æ¯ä¸ªä¸“å®¶ç»„çš„ä¿¡æ¯ä¸°å¯Œç¨‹åº¦ã€‚
- åˆ©ç”¨è¯¥èåˆæŒ‡æ ‡ï¼Œåœ¨å›ºå®šå‹ç¼©é¢„ç®—ä¸‹ï¼Œä¸ºâ€œé‡è¦â€ä¸“å®¶ç»„ï¼ˆé«˜é¢‘ä¸”é«˜ä¿¡æ¯å¯†åº¦ï¼‰åˆ†é…æ›´é«˜çš„åˆ†è§£ç§©ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°ä¿ç•™å…³é”®èƒ½åŠ›ã€‚

> ğŸ” å…³é”®æ´å¯Ÿï¼šä½é¢‘æ¿€æ´»çš„ä¸“å®¶ä¸ä¸€å®šä¸é‡è¦â€”â€”æœ‰äº›è™½å°‘ç”¨ä½†ä¿¡æ¯å¯†é›†ï¼Œè‹¥ç®€å•æŒ‰é¢‘ç‡é™ç§©ä¼šé€€åŒ–ä¸ºä¸“å®¶å‰ªæï¼ˆpruningï¼‰ï¼ŒæŸå®³æ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚

#### ï¼ˆ2ï¼‰å‚æ•°é«˜æ•ˆçš„æ®‹å·®é‡å»ºæœºåˆ¶ï¼ˆParameter-Efficient Residual Reconstructionï¼‰
- ä¸å†ä¸¢å¼ƒ SVD å‹ç¼©åäº§ç”Ÿçš„æ®‹å·® $ R = W - \tilde{W} $ã€‚
- è®¾è®¡äº†ä¸€ç§åŸºäº **ç¨€ç–æ­£äº¤æŠ•å½±çŸ©é˜µ $ P $** çš„è½»é‡çº§é‡å»ºæ–¹æ³•ï¼š
  - å°†æ®‹å·®æ˜ å°„åˆ°ä¸€ä¸ªä½ç»´å¯è®­ç»ƒå‘é‡ $ \mathbf{n} \in \mathbb{R}^a $ï¼ˆ$ a \ll D $ï¼‰ã€‚
  - ä½¿ç”¨å…±äº«çš„ç¨€ç–æŠ•å½±çŸ©é˜µ $ P $ å°†å…¶é‡æ„å›åŸå§‹æƒé‡ç©ºé—´ï¼š$ \text{vec}(R) = P\mathbf{n} $ã€‚
- æŠ•å½±çŸ©é˜µ $ P $ è¢«æ‰€æœ‰ä¸“å®¶ç»„å…±äº«ï¼Œå¹¶å…·æœ‰ä¸¥æ ¼ç­‰è·æ€§ï¼ˆisometryï¼‰ï¼Œä¿è¯ä¼˜åŒ–ç¨³å®šæ€§ã€‚

> ğŸ’¡ ä¼˜åŠ¿ï¼šä»…éœ€çº¦ **3% çš„é¢å¤–å‚æ•°**å³å¯æ¢å¤å¤§é‡å› ä½ç§©é€¼è¿‘ä¸¢å¤±çš„å…³é”®ä¿¡æ¯ã€‚

### â­ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ MoBE, DÂ²-MoEï¼‰ | RFID-MoE |
|------|-------------------------------|----------|
| ç§©åˆ†é… | ç»Ÿä¸€æˆ–åŸºäºé™æ€æƒé‡å±æ€§ | åŠ¨æ€èåˆè·¯ç”±é¢‘ç‡ + ä¿¡æ¯å¯†åº¦ |
| æ®‹å·®å¤„ç† | å®Œå…¨ä¸¢å¼ƒ | å‚æ•°é«˜æ•ˆåœ°é‡å»º |
| æ€§èƒ½ä¿æŒ | åœ¨é«˜å‹ç¼©æ¯”ä¸‹æ˜¾è‘—ä¸‹é™ | æ˜¾è‘—ä¼˜äºåŸºçº¿ï¼Œå°¤å…¶åœ¨é›¶æ ·æœ¬ä»»åŠ¡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†

#### è¯­è¨€å»ºæ¨¡è¯„ä¼°ï¼ˆPerplexity â†“ï¼‰
- **WikiText-2**
- **PTB**ï¼ˆPenn Treebankï¼‰
- **C4**

#### æ¨ç†ä¸å¸¸è¯†ç†è§£è¯„ä¼°ï¼ˆZero-shot Accuracy â†‘ï¼‰
- **OpenBookQA**
- **ARC-e**
- **WinoGrande**
- **HellaSwag**
- **PIQA**
- **MathQA**

> æ‰€æœ‰è¯„ä¼°å‡ä½¿ç”¨ [LM Evaluation Harness](https://github.com/EleutherAI/lm-evaluation-harness) è¿›è¡Œé›¶æ ·æœ¬æµ‹è¯•ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼š
  - Qwen3-30B-A3B-2507ï¼ˆæ¯å±‚128ä¸“å®¶ï¼‰
  - DeepSeekMoE-16B-Baseï¼ˆ64ä¸“å®¶ï¼‰
  - Qwen2-57B-A14B
  - Deepseek-v2-Lite-Chat
  - Ling-mini-2.0
- **å‹ç¼©æ¯”ä¾‹**ï¼š20%, 40%, 60%
- **æ ¡å‡†æ•°æ®é›†**ï¼ˆç”¨äºç»Ÿè®¡è·¯ç”±é¢‘ç‡ï¼‰ï¼š
  - ä¸»è¦ä½¿ç”¨ **WikiText-2**ï¼ˆ1024æ ·æœ¬ï¼‰
  - æ¶ˆèå®éªŒä¸­ä¹Ÿå°è¯• **C4**
- **å®ç°ç»†èŠ‚**ï¼š
  - å¯¹ Up å’Œ Gate æŠ•å½±çŸ©é˜µè¿›è¡Œ SVD åˆ†è§£ï¼ŒDown çŸ©é˜µä¿æŒç¨ å¯†ã€‚
  - æ¯4ä¸ªä¸“å®¶ç»„æˆä¸€ç»„è¿›è¡Œ basis sharingã€‚
  - æ®‹å·®å‘é‡ç»´åº¦è®¾ä¸ºåŸå‚æ•°é‡çš„ **3%**ã€‚
  - ä½¿ç”¨ Adam ä¼˜åŒ–å™¨è¿›è¡Œå¾®è°ƒï¼Œæ— éœ€å®Œæ•´è®­ç»ƒæ•°æ®ã€‚

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | ç®€ä»‹ |
|------|------|------|
| **NAEE** | Pruning + Skipping | åè®­ç»ƒä¸“å®¶å‰ªæ + åŠ¨æ€è·³è¿‡ |
| **MoE-I2** | Pruning + Low-rank | ä¸“å®¶é—´å‰ªæ + ä¸“å®¶å†…ä½ç§©åˆ†è§£ |
| **RS-MoE** | Shared + Sparse | å…±äº«ä½ç§©è¡¨ç¤º + ç¨€ç–æ®‹å·® |
| **DÂ²-MoE** | Shared Components | æƒé‡æ‹†åˆ†ä¸ºå…±äº«ä¸ç‹¬æœ‰éƒ¨åˆ† |
| **MoBE** | Basis Sharing | è‡ªé€‚åº” basis sharingï¼Œå½“å‰æœ€ä¼˜ä¹‹ä¸€ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ Qwen3-30B-A3B-2507 ä¸ºä¾‹ï¼‰

#### åœ¨ PTB ä¸Šçš„ Perplexityï¼ˆè¶Šä½è¶Šå¥½ï¼‰
| å‹ç¼©ç‡ | æ–¹æ³• | PPL |
|--------|------|-----|
| 60% | MoBE | 24.93 |
| 60% | DÂ²-MoE | 38.84 |
| 60% | **RFID-MoE (Ours)** | **16.92** |

ğŸ‘‰ **ç›¸æ¯”æœ€ä½³åŸºçº¿ MoBE ä¸‹é™è¶…è¿‡ 8.0 PPLï¼**

#### é›¶æ ·æœ¬å‡†ç¡®ç‡æå‡ï¼ˆ60% å‹ç¼©ç‡ï¼‰
| ä»»åŠ¡ | MoBE | RS-MoE | **RFID-MoE** |
|------|-------|--------|-------------|
| HellaSwag | ~0.58 | ~0.63 | **0.66** (+8%) |
| WinoGrande | ~0.67 | ~0.71 | **0.71** (+4%) |
| PIQA | ~0.54 | ~0.71 | **0.71** |
| å¹³å‡å‡†ç¡®ç‡ | â€” | â€” | **é¢†å…ˆæ˜æ˜¾** |

> âœ… åœ¨å¤šä¸ª MoE æ¶æ„ä¸Šå‡å–å¾— SOTA è¡¨ç°ï¼Œå³ä½¿åœ¨è½»é‡çº§æ¨¡å‹ï¼ˆå¦‚ Ling-mini-2.0ï¼‰ä¸Šä¾ç„¶æœ‰æ•ˆã€‚

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰ä¸åŒæ ¡å‡†æ•°æ®çš„å½±å“ï¼ˆTable 3ï¼‰
| æ–¹æ³• | æ•°æ®é›† | WikiText-2 | PTB | C4 |
|------|--------|------------|-----|----|
| MoBE | â€” | 13.96 | 24.93 | 24.40 |
| **RFID-MoE** | WikiText-2 | **9.57** | **16.92** | **17.96** |
| **RFID-MoE** | C4 | 10.51 | 13.70 | 16.85 |

ğŸ‘‰ ä½¿ç”¨ C4 ä½œä¸ºæ ¡å‡†æ•°æ®æ—¶ï¼Œåœ¨ C4 æµ‹è¯•é›†ä¸Šè¾¾åˆ°æœ€ä½ PPLï¼ˆ16.85ï¼‰ï¼Œè¡¨æ˜æ ¡å‡†æ•°æ®é€‰æ‹©åˆç†å¯è¿›ä¸€æ­¥æå‡æ•ˆæœã€‚

#### ï¼ˆ2ï¼‰èåˆè¶…å‚æ•° $ \epsilon $ çš„å½±å“ï¼ˆTable 4ï¼‰
- æœ€ä¼˜å€¼é›†ä¸­åœ¨ **$ \epsilon = 0.7 \sim 0.8 $**ã€‚
- è‹¥ $ \epsilon $ è¿‡å¤§ â†’ å¿½è§†è·¯ç”±é¢‘ç‡ â†’ æ— æ³•ä¿æŠ¤é«˜é¢‘ä¸“å®¶ï¼›
- è‹¥ $ \epsilon $ è¿‡å° â†’ å¿½è§†ä¿¡æ¯å¯†åº¦ â†’ ä½ä¼°ä½é¢‘ä½†å…³é”®ä¸“å®¶ã€‚

#### ï¼ˆ3ï¼‰æ®‹å·®é‡å»ºæœ‰æ•ˆæ€§åˆ†æï¼ˆAppendix Cï¼‰
- ç†è®ºè¯æ˜ï¼šåªè¦æ®‹å·®å­ç©ºé—´çš„å†…åœ¨ç»´åº¦ $ d_{\text{int}} $ è¾ƒå°ï¼Œåˆ™ä½ç»´å‘é‡ $ \mathbf{n} $ èƒ½ä»¥é«˜æ¦‚ç‡æ‰¾åˆ° $ \epsilon $-è¿‘ä¼¼è§£ã€‚
- å®è·µéªŒè¯ï¼šä»…å¢åŠ  3% å‚æ•°å³å¯æ˜¾è‘—æ”¹å–„æ€§èƒ½ï¼Œè¯´æ˜æ®‹å·®ç¡®å®å­˜åœ¨äºä½ç»´æµå½¢ä¸­ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **ä¸“å®¶å¼‚è´¨æ€§å¿…é¡»è¢«æ˜¾å¼å»ºæ¨¡**ï¼šMoE ä¸­ä¸“å®¶çš„è·¯ç”±é¢‘ç‡å’Œä¿¡æ¯å¯†åº¦é«˜åº¦éå‡åŒ€ï¼Œç»Ÿä¸€å‹ç¼©ç­–ç•¥æ˜¯æ¬¡ä¼˜çš„ã€‚
2. **Effective Rank æ˜¯è¯†åˆ«â€œæ²‰é»˜ä½†é‡è¦â€ä¸“å®¶çš„å…³é”®æŒ‡æ ‡**ï¼šä¸€äº›æå°‘è¢«æ¿€æ´»çš„ä¸“å®¶ä»å…·æœ‰å¾ˆé«˜çš„ä¿¡æ¯å¯†åº¦ï¼Œåº”ç»™äºˆè¶³å¤Ÿå‹ç¼©èµ„æºã€‚
3. **æ®‹å·®ä¸å¯å¿½ç•¥ä¸”å¯é«˜æ•ˆé‡å»º**ï¼šSVD æˆªæ–­åçš„æ®‹å·®å«æœ‰éå¹³å‡¡èƒ½é‡ï¼Œä½†å…¶åˆ†å¸ƒåœ¨ä½ç»´å­ç©ºé—´ä¸­ï¼Œå¯é€šè¿‡ç¨€ç–æ­£äº¤æŠ•å½±æœ‰æ•ˆæ¢å¤ã€‚
4. **RFID-MoE å®ç°äº†é«˜å‹ç¼©æ¯”ä¸‹çš„æ€§èƒ½é£è·ƒ**ï¼šåœ¨ 60% å‹ç¼©ç‡ä¸‹ï¼ŒPPL ä¸‹é™è¶… 8ï¼Œé›¶æ ·æœ¬å‡†ç¡®ç‡æå‡è¾¾ 8%ï¼Œè¿œè¶…ç°æœ‰æ–¹æ³•ã€‚

### âš ï¸ å±€é™æ€§
- å½“å‰æ–¹æ³•ä¸»è¦é’ˆå¯¹ FFN å±‚ä¸­çš„ MoE ä¸“å®¶è¿›è¡Œå‹ç¼©ï¼Œæœªæ¶‰åŠæ³¨æ„åŠ›æ¨¡å—æˆ–å…¶ä»–ç»“æ„ã€‚
- ä¾èµ–äºåœ¨æ ¡å‡†æ•°æ®ä¸Šæ”¶é›†çš„è·¯ç”±é¢‘ç‡ï¼Œè‹¥åˆ†å¸ƒåç§»å¯èƒ½å¯¼è‡´æ€§èƒ½æ³¢åŠ¨ã€‚
- ç¨€ç–æŠ•å½±çŸ©é˜µ $ P $ è™½ç„¶èŠ‚çœå­˜å‚¨ï¼Œä½†ä»éœ€è®¾è®¡æ›´çµæ´»çš„ç»“æ„æ¢ç´¢ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- å°† RFID æ€æƒ³æ‰©å±•è‡³å…¶ä»– MoE å˜ä½“ï¼ˆå¦‚ SeqMoEã€Hierarchical MoEï¼‰ã€‚
- æ¢ç´¢åœ¨çº¿è‡ªé€‚åº”ç§©åˆ†é…æœºåˆ¶ï¼Œåº”å¯¹è¾“å…¥åˆ†å¸ƒå˜åŒ–ã€‚
- ç»“åˆé‡åŒ–ï¼ˆQuantizationï¼‰ä¸ RFID-MoEï¼Œå®ç°æ›´æè‡´çš„æ¨¡å‹å‹ç¼©ã€‚
- ç ”ç©¶å¦‚ä½•å°†æ®‹å·®é‡å»ºæœºåˆ¶åº”ç”¨äº LoRAã€Adapter ç­‰å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ä¸­ã€‚

---

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> RFID-MoE é€šè¿‡è”åˆåˆ©ç”¨ **Routing Frequency** ä¸ **Information Density** å®ç°äº† MoE æ¨¡å‹çš„è‡ªé€‚åº”ä½ç§©å‹ç¼©ï¼Œå¹¶é¦–æ¬¡ç³»ç»Ÿæ€§åœ°å›æ”¶äº†ä¼ ç»Ÿæ–¹æ³•ä¸¢å¼ƒçš„æ®‹å·®ä¿¡æ¯ï¼Œåœ¨æé«˜å‹ç¼©æ¯”ä¸‹å®ç°äº†è¯­è¨€å»ºæ¨¡ä¸æ¨ç†èƒ½åŠ›çš„åŒé‡çªç ´ã€‚

</details>

---

### 8. [Scalable and Reliable State-Aware Inference of High-Impact N-k Contingencies](https://arxiv.org/abs/2602.09461)

**Authors**: Lihao Mai, Chenhan Xiao, Yang Weng  
**Category**: cs.LG  
**Published**: 2026-02-11  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.09461v1  

#### Abstract
Increasing penetration of inverter-based resources, flexible loads, and rapidly changing operating conditions make higher-order $N\!-\!k$ contingency assessment increasingly important but computationally prohibitive. Exhaustive evaluation of all outage combinations using AC power-flow or ACOPF is in...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Scalable and Reliable State-Aware Inference of High-Impact N-k Contingencies*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
éšç€ **inverter-based resources** å’Œ **flexible loads** çš„å¹¿æ³›æ¥å…¥ï¼Œç”µç½‘è¿è¡ŒçŠ¶æ€å¿«é€Ÿå˜åŒ–ï¼Œä¼ ç»Ÿçš„ **N-1 å®‰å…¨å‡†åˆ™** å·²ä¸è¶³ä»¥ä¿éšœç³»ç»Ÿå®‰å…¨ã€‚é«˜é˜¶ **N-k contingency analysis** å˜å¾—æ„ˆå‘é‡è¦ï¼Œä½†ç”±äºå…¶ç»„åˆçˆ†ç‚¸ç‰¹æ€§ï¼ˆ$\binom{N}{k}$ï¼‰ï¼Œå¯¹æ‰€æœ‰å¯èƒ½çš„æ–­çº¿ç»„åˆè¿›è¡Œ **AC power-flow** æˆ– **ACOPF** éªŒè¯åœ¨è®¡ç®—ä¸Šä¸å¯è¡Œã€‚

ç°æœ‰æ–¹æ³•å¦‚ **heuristic screening**ï¼ˆå¦‚ LODFï¼‰æˆ– **surrogate models** è™½ç„¶åŠ é€Ÿäº†åˆ†æï¼Œä½†ä»éœ€éå†å¤§é‡å€™é€‰åœºæ™¯ï¼Œä¸”æ— æ³•æä¾›å¯¹ä¸¥é‡æ•…éšœçš„**è¦†ç›–ä¿è¯**ï¼ˆcoverage guaranteeï¼‰ï¼Œå­˜åœ¨æ¼æ£€é«˜é£é™©äº‹ä»¶çš„é£é™©ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§**å¯æ‰©å±•ã€çŠ¶æ€æ„ŸçŸ¥çš„ç”Ÿæˆå¼æ¡†æ¶**ï¼Œç›´æ¥ç”Ÿæˆé«˜å½±å“çš„ N-k æ•…éšœåœºæ™¯ï¼Œé¿å…æšä¸¾æ•´ä¸ªç»„åˆç©ºé—´ã€‚æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **å°† N-k åˆ†æé‡æ„ä¸ºâ€œçŠ¶æ€æ¡ä»¶ä¸‹çš„ç”Ÿæˆé—®é¢˜â€**ï¼š  
  ä¸å†æ˜¯â€œè¯„ä¼°å¹¶æ’åºæ‰€æœ‰ç»„åˆâ€ï¼Œè€Œæ˜¯â€œç›´æ¥ç”Ÿæˆæœ€å¯èƒ½å¯¼è‡´ä¸¥é‡åæœçš„å°‘æ•°å‡ ä¸ªç»„åˆâ€ã€‚

- **åŸºäºæ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼ˆconditional diffusion modelï¼‰çš„ç”Ÿæˆæœºåˆ¶**ï¼š  
  åˆ©ç”¨ **diffusion process** åœ¨ç»™å®šå½“å‰ç³»ç»ŸçŠ¶æ€ $x$ ä¸‹ï¼Œä»é«˜ä¸¥é‡æ€§å°¾éƒ¨åˆ†å¸ƒ $p^*(c \mid S(x,c) \geq T, x)$ ä¸­é‡‡æ ·å‡ºé«˜é£é™©çš„ N-k æ•…éšœ $c$ã€‚

- **æ‹“æ‰‘æ„ŸçŸ¥çš„å›¾ç¥ç»ç½‘ç»œï¼ˆEVGNNï¼‰ç”¨äºç¦»çº¿é£é™©è¯„åˆ†**ï¼š  
  è®¾è®¡äº†ä¸€ä¸ªä»…éœ€è®­ç»ƒäº **base-case** å’Œ **N-1** æ•°æ®çš„ **Edge-Varying Graph Neural Network (EVGNN)**ï¼Œç”¨äºå¿«é€Ÿä¼°è®¡å¤šçº¿è·¯æ•…éšœçš„ä¸¥é‡æ€§ï¼Œä»è€Œæ„å»ºé«˜è´¨é‡çš„é«˜é£é™©è®­ç»ƒé›†ä¾›æ‰©æ•£æ¨¡å‹å­¦ä¹ ã€‚

- **å¯æ§çš„è¦†ç›–ä¿è¯æœºåˆ¶**ï¼š  
  æä¾›ç†è®ºæ”¯æŒï¼Œå…è®¸æ“ä½œå‘˜è®¾å®šä¸€ä¸ªâ€œæ¼æ£€å®¹å¿åº¦â€ï¼ˆmiss tolerance $\delta_{\text{miss}}$ï¼‰ï¼Œå¹¶æ®æ­¤ç¡®å®šæ‰€éœ€çš„ **AC power-flow** éªŒè¯æ•°é‡ $B$ï¼Œå®ç°**é£é™©ä¸è®¡ç®—æˆæœ¬ä¹‹é—´çš„æ˜¾å¼æƒè¡¡**ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰æ–¹æ³• | æœ¬æ–‡æ–¹æ³• |
|------|--------|--------|
| **è®¡ç®—æ•ˆç‡** | ä»éœ€è¯„ä¼°/è¯„åˆ†å¤§é‡ç»„åˆï¼Œå¤æ‚åº¦ä¸º $O(\binom{N}{k})$ | ä»…ç”Ÿæˆ $m$ ä¸ªé«˜é£é™©æ ·æœ¬ï¼Œå¤æ‚åº¦ä¸º $O(m)$ï¼Œä¸ $\binom{N}{k}$ æ— å…³ |
| **è¦†ç›–å¯é æ€§** | å¯å‘å¼ç­›é€‰æ— ç†è®ºä¿è¯ï¼Œæ˜“æ¼æ£€ä¸¥é‡äº‹ä»¶ | æä¾›æ¦‚ç‡æ€§è¦†ç›–ä¿è¯ï¼Œå¯æ§åˆ¶æ¼æ£€é£é™© |
| **çŠ¶æ€ä¾èµ–æ€§** | å¤šæ•°é™æ€æ’åºä¸é€‚åº”åŠ¨æ€è¿è¡ŒçŠ¶æ€ | ç”Ÿæˆè¿‡ç¨‹ä»¥å½“å‰çŠ¶æ€ $x$ ä¸ºæ¡ä»¶ï¼ŒåŠ¨æ€è°ƒæ•´è¾“å‡º |
| **æ ·æœ¬æ•ˆç‡** | éœ€å¤§é‡æ ‡æ³¨ N-k æ•°æ®ï¼ˆä¸ç°å®ï¼‰ | ä»…éœ€ N-1 æ ‡æ³¨æ•°æ®è®­ç»ƒ EVGNNï¼Œæ‰©æ•£æ¨¡å‹é€šè¿‡ç­›é€‰åçš„é«˜é£é™©å­é›†è®­ç»ƒ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **æ ‡å‡† IEEE æµ‹è¯•ç³»ç»Ÿ**ï¼š
  - IEEE 14-bus
  - IEEE 39-bus
  - IEEE 57-bus
  - IEEE 118-bus
- **æ•°æ®ç”Ÿæˆæ–¹å¼**ï¼š
  - é€šè¿‡å¯¹è´Ÿè·å’Œå‘ç”µæœºå‡ºåŠ›æ‰°åŠ¨ç”Ÿæˆå¤šä¸ªè¿è¡ŒçŠ¶æ€ $x_t$
  - å¯¹æ¯ä¸ª $x_t$ æ‰§è¡Œ **base-case AC power-flow** å’Œæ‰€æœ‰ **N-1 æ•…éšœ** çš„ AC æ±‚è§£ï¼Œæ„å»º $D_{N-1}$
  - ä½¿ç”¨ EVGNN å¯¹éšæœºç”Ÿæˆçš„ N-k æ•…éšœæ‰“åˆ†ï¼Œä¿ç•™é«˜åˆ†è€…æ‰§è¡Œ AC éªŒè¯ï¼Œå½¢æˆé«˜é£é™©è®­ç»ƒé›† $H$

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **ç›®æ ‡ k å€¼èŒƒå›´**ï¼š
  - IEEE 14: $k \in [2,4]$
  - IEEE 39: $k \in [2,6]$
  - IEEE 57: $k \in [2,5]$
  - IEEE 118: $k \in [2,15]$
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  1. **Top-m å¹³å‡ä¸¥é‡æ€§æ›²çº¿**ï¼šå‰ $m$ ä¸ªæ¨èæ•…éšœçš„å¹³å‡ $S(x,c)$ï¼Œè¡¡é‡æ ·æœ¬è´¨é‡
  2. **ACPF æ”¶æ•›ç‡ï¼ˆConv. Rateï¼‰**ï¼šç”Ÿæˆæ•…éšœä¸­èƒ½æˆåŠŸæ±‚è§£ AC power-flow çš„æ¯”ä¾‹
  3. **In-band ç‡**ï¼šæ”¶æ•›æ•…éšœä¸­ä¸¥é‡æ€§é«˜äºé˜ˆå€¼ $T$ çš„æ¯”ä¾‹
  4. **æ€»è¿è¡Œæ—¶é—´å¯¹æ¯”**ï¼šä¸åŒæ–¹æ³•åœ¨ç›¸åŒä»»åŠ¡ä¸‹çš„è€—æ—¶
  5. **è¦†ç›–ç‡ä¿è¯éªŒè¯**ï¼šæ˜¯å¦èƒ½åœ¨å°é¢„ç®—ä¸‹æ•è·é«˜ä¸¥é‡æ€§äº‹ä»¶

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Uniform Random Sampling**ï¼šå‡åŒ€éšæœºé‡‡æ · N-k æ•…éšœ
- **EVGNN Alone**ï¼šä»…ä½¿ç”¨ EVGNN æ‰“åˆ†æ’åºï¼Œå– top-m
- **Surrogate-based Screening**ï¼šä½¿ç”¨ä»£ç†æ¨¡å‹æ›¿ä»£ AC æ±‚è§£è¿›è¡Œç­›é€‰
- **cVAE / cGAN**ï¼šå…¶ä»–ç”Ÿæˆæ¨¡å‹ä½œä¸ºå¯¹æ¯”
- **Exhaustive AC Evaluation**ï¼šç†æƒ³ä½†ä¸å¯è¡Œçš„åŸºå‡†

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### âœ… **è¡¨ Iï¼šIEEE 39-bus ç³»ç»Ÿæ€»è¿è¡Œæ—¶é—´å¯¹æ¯”ï¼ˆåˆ†é’Ÿï¼‰**

| $k$ | Exhaustive | Surrogate | Ours | Exhaustive / Ours | Surrogate / Ours |
|-----|------------|-----------|------|-------------------|------------------|
| 1   | 0.0023     | 0.0006    | 0.001 | 2.3Ã—              | 0.6Ã—             |
| 2   | 0.0446     | 0.0130    | 0.002 | 22.3Ã—             | 6.5Ã—             |
| 3   | 0.5510     | 0.1604    | 0.004 | 138Ã—              | 40.1Ã—            |
| 4   | 4.9594     | 1.4438    | 0.006 | 827Ã—              | 241Ã—             |
| 5   | 34.716     | 10.107    | 0.007 | 4,960Ã—            | 1,444Ã—           |
| 6   | 196.72     | 57.274    | 0.009 | 21,858Ã—           | 6,364Ã—           |

> **ç»“è®º**ï¼šæœ¬æ–‡æ–¹æ³•åœ¨çº¿è®¡ç®—æ—¶é—´å‡ ä¹æ’å®šï¼Œè€Œä¼ ç»Ÿæ–¹æ³•éš $k$ æ€¥å‰§å¢é•¿ã€‚

#### âœ… **è¡¨ IIï¼šACPF æ”¶æ•›ç‡ä¸ In-band ç‡**

| System       | $k$ Range   | Conv. (%) | In-band (%) |
|--------------|-------------|-----------|-------------|
| IEEE 14      | [2,4]       | 85.0      | 84.2        |
| IEEE 39      | [2,6]       | 93.5      | 87.7        |
| IEEE 57      | [2,5]       | 86.5      | 96.5        |
| IEEE 118     | [2,15]      | 86.0      | 91.9        |
| **Overall**  | â€”           | **87.1**  | **90.1**    |

> **ç»“è®º**ï¼šè¶…è¿‡ 87% çš„ç”Ÿæˆæ•…éšœå¯æ”¶æ•›ï¼Œå…¶ä¸­ 90% å±äºé«˜ä¸¥é‡æ€§â€œin-bandâ€åŒºåŸŸï¼Œè¯´æ˜ç”Ÿæˆè´¨é‡æé«˜ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

- **Top-m æ›²çº¿æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿**ï¼š
  - åœ¨ IEEE 118-bus ä¸Šï¼Œå½“ $m=200$ æ—¶ï¼Œæœ¬æ–‡æ–¹æ³•çš„å¹³å‡ Top-m ä¸¥é‡æ€§çº¦ä¸º **310**ï¼Œè€Œéšæœºé‡‡æ ·ä»…ä¸º **130**
  - æ›²çº¿ä¸‹é™ç¼“æ…¢ï¼Œè¡¨æ˜æ–°å¢æ ·æœ¬ä»ä¿æŒé«˜ä¸¥é‡æ€§ï¼Œè€Œéšæœºæ–¹æ³•è¿…é€Ÿè¢«ä½å½±å“æ ·æœ¬ç¨€é‡Š

- **ä¸¥é‡æ€§åˆ†å¸ƒæ›´é›†ä¸­äºé«˜å°¾éƒ¨**ï¼ˆè§ Figure 3ï¼‰ï¼š
  - æœ¬æ–‡æ–¹æ³•åœ¨â€œhigh-severity in-bandâ€åŒºåŸŸçš„æ ·æœ¬å¯†åº¦è¿œé«˜äºå…¶ä»–æ–¹æ³•
  - cVAE å’Œ cGAN è¡¨ç°ä¸ç¨³å®šï¼Œæœªèƒ½æœ‰æ•ˆèšç„¦é«˜é£é™©åŒºåŸŸ

- **ç›¸æ¯” EVGNN Alone æ˜¾è‘—æå‡**ï¼š
  - ä»…é  EVGNN æ‰“åˆ†å­˜åœ¨æ¢ç´¢ä¸è¶³çš„é—®é¢˜
  - åŠ å…¥æ‰©æ•£ç”Ÿæˆåï¼Œèƒ½è·³å‡ºå±€éƒ¨é«˜åˆ†åŒºåŸŸï¼Œå‘ç°æ›´å¤šæ½œåœ¨ä¸¥é‡ç»„åˆ

### æ¶ˆèå®éªŒç»“æœ
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºâ€œablation studyâ€ç« èŠ‚ï¼Œä½†ä»ä»¥ä¸‹å¯¹æ¯”å¯è§†ä¸ºéšå¼æ¶ˆèï¼š

- **EVGNN vs. EVGNN + Diffusion**ï¼šåè€…åœ¨ Top-m æ›²çº¿å’Œ in-band ç‡ä¸Šå…¨é¢èƒœå‡ºï¼Œè¯´æ˜**ç”Ÿæˆæœºåˆ¶æœ¬èº«å¸¦æ¥äº†é¢å¤–çš„ä»·å€¼**ï¼Œä¸ä»…ä»…æ˜¯æ‰“åˆ†
- **cVAE/cGAN vs. Diffusion**ï¼šæ‰©æ•£æ¨¡å‹åœ¨ç¨³å®šæ€§ä¸èšç„¦èƒ½åŠ›ä¸Šè¡¨ç°æ›´å¥½ï¼Œè¯´æ˜**diffusion æ›´é€‚åˆå»ºæ¨¡ç¨€ç–ã€é•¿å°¾çš„ä¸¥é‡æ•…éšœåˆ†å¸ƒ**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **N-k åˆ†ææ— éœ€ç©·ä¸¾**ï¼šä¸¥é‡æ•…éšœé›†ä¸­åœ¨æå°çš„ç»„åˆå­ç©ºé—´å†…ï¼Œå¯é€šè¿‡ç”Ÿæˆæ¨¡å‹ç›´æ¥é‡‡æ ·ã€‚
2. **çŠ¶æ€æ„ŸçŸ¥ç”Ÿæˆæ˜¯å¯è¡Œä¸”é«˜æ•ˆçš„**ï¼šæ¡ä»¶æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿæ ¹æ®å½“å‰è¿è¡ŒçŠ¶æ€ $x$ åŠ¨æ€ç”Ÿæˆé«˜é£é™© N-k æ•…éšœã€‚
3. **EVGNN å¯æœ‰æ•ˆæ³›åŒ–è‡³ N-k åœºæ™¯**ï¼šä»…ç”¨ N-1 æ•°æ®è®­ç»ƒçš„å›¾æ¨¡å‹å³å¯ä¸ºå¤šçº¿è·¯æ•…éšœæä¾›å¯é çš„é£é™©è¯„åˆ†ã€‚
4. **æä¾›å¯è°ƒæ§çš„é£é™©-è®¡ç®—æƒè¡¡æœºåˆ¶**ï¼šé€šè¿‡è®¾å®šæ¼æ£€å®¹å¿åº¦ $\delta_{\text{miss}}$ï¼Œå¯è‡ªåŠ¨ç¡®å®šæ‰€éœ€éªŒè¯æ•°é‡ $B$ï¼Œå®ç°**æ“ä½œå±‚é¢çš„å¯é æ€§æ§åˆ¶**ã€‚
5. **æ˜¾è‘—æå‡æ ·æœ¬æ•ˆç‡**ï¼šåœ¨ç›¸åŒ AC power-flow é¢„ç®—ä¸‹ï¼Œæœ¬æ–‡æ–¹æ³•èƒ½è¯†åˆ«å‡ºæ›´ä¸¥é‡çš„æ•…éšœï¼Œå‡å°‘èµ„æºæµªè´¹ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡çš„ EVGNN é£é™©ä¼°è®¡**ï¼šè‹¥ EVGNN æ— æ³•å‡†ç¡®æ•æ‰äº¤äº’æ•ˆåº”ï¼ˆinteraction effectsï¼‰ï¼Œå¯èƒ½å¯¼è‡´é«˜é£é™©åŒºåŸŸè¯¯åˆ¤ã€‚
- **æ‰©æ•£æ¨¡å‹è®­ç»ƒéœ€è¦ä¸€å®šé‡çš„é«˜é£é™©æ ‡ç­¾**ï¼šå°½ç®¡å·²å¤§å¹…å‡å°‘ï¼Œä½†ä»éœ€éƒ¨åˆ† N-k çš„ AC éªŒè¯æ¥æ„å»ºè®­ç»ƒé›†ã€‚
- **å‡è®¾ç”Ÿæˆæ ·æœ¬ç‹¬ç«‹åŒåˆ†å¸ƒ**ï¼šå®é™…ä¸­å¯èƒ½å­˜åœ¨ç›¸å…³æ€§ï¼Œå½±å“è¦†ç›–ç‡ä¼°è®¡ã€‚
- **æœªè€ƒè™‘åŠ¨æ€ç¨³å®šæ€§é—®é¢˜**ï¼šç›®å‰ä¸¥é‡æ€§æŒ‡æ ‡åŸºäº **AC power-flow** ç»“æœï¼Œæœªæ¶µç›–æš‚æ€ç¨³å®šç­‰åŠ¨æ€å“åº”ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°†æ¡†æ¶æ‰©å±•è‡³ **dynamic security assessment**ï¼Œç»“åˆ **time-domain simulation** è¾“å‡ºä½œä¸ºä¸¥é‡æ€§æ ‡ç­¾ã€‚
- æ¢ç´¢ **online adaptation** æœºåˆ¶ï¼Œä½¿æ¨¡å‹èƒ½éšæ–°è§‚æµ‹æ•°æ®æŒç»­æ›´æ–°ã€‚
- å¼•å…¥ **multi-objective optimization**ï¼ŒåŒæ—¶è€ƒè™‘ç»æµæ€§ä¸å®‰å…¨æ€§ã€‚
- åº”ç”¨äº **é¢„é˜²æ§åˆ¶ç­–ç•¥ç”Ÿæˆ**ï¼Œä¸ä»…è¯†åˆ«æ•…éšœï¼Œè¿˜å»ºè®®è°ƒæ•´æªæ–½ã€‚
- åœ¨æ›´å¤§è§„æ¨¡å®é™…ç”µç½‘ä¸­éƒ¨ç½²éªŒè¯ï¼Œå¹¶é›†æˆåˆ° EMS/DMS ç³»ç»Ÿä¸­ã€‚

--- 

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº **EVGNN + conditional diffusion** çš„ç”Ÿæˆå¼ N-k å®‰å…¨è¯„ä¼°æ¡†æ¶ï¼Œåœ¨**æä½è®¡ç®—é¢„ç®—ä¸‹å¯é åœ°èšç„¦é«˜é£é™©æ•…éšœ**ï¼Œå®ç°äº†ä»â€œæš´åŠ›ç­›æŸ¥â€åˆ°â€œæ™ºèƒ½æ¨ç†â€çš„èŒƒå¼è½¬å˜ã€‚

</details>

---

### 9. [Learning to Discover Iterative Spectral Algorithms](https://arxiv.org/abs/2602.09530)

**Authors**: Zihang Liu, Oleg Balabanov, Yaoqing Yang, Michael W. Mahoney  
**Category**: cs.LG  
**Published**: 2026-02-11  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.09530v1  

#### Abstract
We introduce AutoSpec, a neural network framework for discovering iterative spectral algorithms for large-scale numerical linear algebra and numerical optimization. Our self-supervised models adapt to input operators using coarse spectral information (e.g., eigenvalue estimates and residual norms), ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Learning to Discover Iterative Spectral Algorithms*

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡æ—¨åœ¨è§£å†³**æ•°å€¼çº¿æ€§ä»£æ•°ï¼ˆNLAï¼‰å’Œæ•°å€¼ä¼˜åŒ–é¢†åŸŸä¸­è¿­ä»£è°±ç®—æ³•çš„è®¾è®¡è‡ªåŠ¨åŒ–é—®é¢˜**ã€‚ä¼ ç»Ÿä¸Šï¼Œè¿™äº›ç®—æ³•ï¼ˆå¦‚ChebyshevåŠ é€Ÿã€å¤šé¡¹å¼é¢„æ¡ä»¶å™¨ï¼‰ä¾èµ–äºæ‰‹å·¥è®¾è®¡ï¼Œéœ€è¦æ·±åšçš„æ•°å­¦ä¸“ä¸šçŸ¥è¯†ï¼Œå¹¶ä¸”é€šå¸¸é’ˆå¯¹ç‰¹å®šçš„è°±ç»“æ„è¿›è¡Œä¼˜åŒ–ã€‚è¯¥è®ºæ–‡æå‡ºï¼Œå¯ä»¥åˆ©ç”¨æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰æ¥è‡ªåŠ¨å‘ç°é€‚åº”æ€§å¼ºã€æ€§èƒ½ä¼˜è¶Šçš„æ–°å‹è¿­ä»£ç®—æ³•ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šAUToSPECæ¡†æ¶
ä½œè€…æå‡ºäº† **AUToSPEC**ï¼Œä¸€ä¸ªåŸºäºç¥ç»ç½‘ç»œçš„ç«¯åˆ°ç«¯å¯å¾®åˆ†æ¡†æ¶ï¼Œç”¨äºå‘ç°è¿­ä»£è°±ç®—æ³•ã€‚

- **æ ¸å¿ƒæ€æƒ³**ï¼šå°†ç®—æ³•å‘ç°è¿‡ç¨‹å»ºæ¨¡ä¸ºä¸€ä¸ª**ä»ç²—ç²’åº¦è°±æ¢é’ˆï¼ˆspectral probeï¼‰åˆ°è¿­ä»£ç³»æ•°çš„æ˜ å°„**ã€‚
  - **è¾“å…¥**ï¼šä¸€ä¸ªè°±æ¢é’ˆ `(Î», r)`ï¼ŒåŒ…å«å°‘é‡è¿‘ä¼¼çš„ç‰¹å¾å€¼ä¼°è®¡ `Î»` å’Œç›¸åº”çš„æ®‹å·®èŒƒæ•° `r`ã€‚
  - **è¾“å‡º**ï¼šä¸€ä¸ªç¥ç»ç½‘ç»œå¼•æ“ï¼ˆneural engineï¼‰é¢„æµ‹ä¸€ç»„é€’æ¨ç³»æ•°ï¼Œè¿™äº›ç³»æ•°å®šä¹‰äº†ä¸€ä¸ªä½œç”¨äºç®—å­ `X` çš„çŸ©é˜µå¤šé¡¹å¼ `P(X)`ã€‚
  - **æ‰§è¡Œ**ï¼šè¯¥å¤šé¡¹å¼é€šè¿‡ä¸€ä¸ªçŸ­çš„ã€å¯æ‰§è¡Œçš„æ•°å€¼çº¿æ€§ä»£æ•°é€’æ¨å…³ç³»æ¥å®ç°ï¼Œä»è€Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„ã€å¯éƒ¨ç½²çš„æ•°å€¼ç®—æ³•ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
1.  **è¿ç»­æœç´¢ç©ºé—´**ï¼šä¸è®¸å¤šåœ¨ç¦»æ•£ç¨‹åºç©ºé—´ä¸­æœç´¢çš„ç¬¦å·å›å½’æ–¹æ³•ä¸åŒï¼ŒAUToSPECåœ¨**è¿ç»­çš„å‚æ•°ç©ºé—´**ä¸­æ“ä½œï¼Œè¿™æ›´ç¬¦åˆNLAä¸­æœ‰æ•ˆæ–¹æ³•é€šå¸¸æ˜¯è¿ç»­å¯¹è±¡çš„æœ¬è´¨ã€‚
2.  **è‡ªç›‘ç£å­¦ä¹ **ï¼šè®­ç»ƒæ˜¯å®Œå…¨**è‡ªç›‘ç£**çš„ï¼Œä»…é€šè¿‡ä¸‹æ¸¸ä»»åŠ¡çš„æ€§èƒ½ï¼ˆå¦‚æ”¶æ•›é€Ÿåº¦ã€é€¼è¿‘è¯¯å·®ï¼‰ä½œä¸ºåé¦ˆä¿¡å·ï¼Œè€Œä¸æ˜¯æ¨¡ä»¿å·²æœ‰çš„ç®—æ³•ã€‚è¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿè¶…è¶Šç°æœ‰åŸºçº¿ã€‚
3.  **å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›**ï¼šæ¨¡å‹åœ¨**å°å‹åˆæˆç®—å­**ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå´èƒ½æˆåŠŸè¿ç§»åˆ°**å¤§è§„æ¨¡çœŸå®ä¸–ç•Œç¨€ç–çŸ©é˜µ**ï¼ˆç»´åº¦é«˜è¾¾ `O(10^6)`ï¼‰ä¸Šï¼Œå®ç°äº†â€œå°æ¨¡å‹å¤§ç”¨â€ã€‚
4.  **ç»Ÿä¸€ä¸”é€šç”¨çš„æ¡†æ¶**ï¼šAUToSPECæä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„å‚æ•°åŒ–æ–¹æ¡ˆï¼Œå¯ä»¥åº”ç”¨äºå¤šç§NLAä»»åŠ¡ï¼ŒåŒ…æ‹¬æ±‚è§£çº¿æ€§ç³»ç»Ÿã€è®¡ç®—ç‰¹å¾å€¼å’Œé€¼è¿‘çŸ©é˜µå‡½æ•°ã€‚
5.  **å®ç”¨æ€§**ï¼šæ¨ç†æ—¶ä»…éœ€å»‰ä»·çš„ç²—ç²’åº¦è°±ä¿¡æ¯ï¼ˆé€šè¿‡çŸ­æ—¶é—´çš„warm-startæ±‚è§£å™¨è·å¾—ï¼‰ï¼Œä½¿å…¶åœ¨è®¡ç®—é¢„ç®—ç´§å¼ çš„å®é™…åœºæ™¯ä¸­å…·æœ‰å¾ˆé«˜çš„é€‚ç”¨æ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **è®­ç»ƒæ•°æ®**ï¼šä½¿ç”¨**å°å‹åˆæˆå¯¹è§’çŸ©é˜µ**ï¼ˆ`n â‰¤ O(10^3)`ï¼‰ã€‚è¿™äº›çŸ©é˜µçš„ç‰¹å¾è°±é€šè¿‡ç”Ÿæˆå™¨åˆ›å»ºï¼Œä»¥æ¨¡æ‹Ÿç°å®ä¸–ç•Œä¸­å¸¸è§çš„è°±ç‰¹æ€§ï¼Œä¾‹å¦‚ï¼š
  - ç¼“æ…¢è¡°å‡çš„ä¸»å¯¼ç‰¹å¾å€¼ï¼ˆç”¨äºç‰¹å¾å€¼é—®é¢˜ï¼‰ã€‚
  - è·¨è¶Šå¤šä¸ªæ•°é‡çº§çš„æ¡ä»¶æ•°ï¼ˆç”¨äºçº¿æ€§ç³»ç»Ÿå’ŒçŸ©é˜µå‡½æ•°é€¼è¿‘ï¼‰ã€‚
  - å¼•å…¥è½»å¾®çš„å±€éƒ¨ä¸è§„åˆ™æ€§ä»¥åæ˜ éç†æƒ³åŒ–ç®—å­ã€‚
- **æµ‹è¯•æ•°æ®**ï¼šæ¥è‡ª **SuiteSparse Matrix Collection** çš„**çœŸå®ä¸–ç•Œå¤§å‹ç¨€ç–çŸ©é˜µ**ï¼Œæ¶µç›–ç”µå­ç»“æ„ã€çƒ­æœ‰é™å…ƒã€ç»“æ„åŠ›å­¦å’Œç”µè·¯/æ¨¡å‹é™é˜¶ç­‰é¢†åŸŸã€‚çŸ©é˜µç»´åº¦èŒƒå›´ä» `468` åˆ° `1.6Ã—10^6`ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨ç†æµç¨‹**ï¼š
  1.  å¯¹æ–°çš„ç®—å­ `X` è¿è¡Œä¸€ä¸ªç®€çŸ­çš„warm-startæ±‚è§£å™¨ï¼ˆå¦‚ `eigs` æˆ– `Lanczos`ï¼‰ä»¥è·å–è°±æ¢é’ˆ `(Î», r)`ã€‚
  2.  å°†æ¢é’ˆè¾“å…¥è®­ç»ƒå¥½çš„AUToSPECç¥ç»ç½‘ç»œå¼•æ“ï¼Œé¢„æµ‹é€’æ¨ç³»æ•°ã€‚
  3.  æ‰§è¡Œç”±è¿™äº›ç³»æ•°å®šä¹‰çš„è¿­ä»£è¿‡ç¨‹ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **ç‰¹å¾å€¼é—®é¢˜**ï¼šè¾¾åˆ°ç›®æ ‡ç²¾åº¦æ‰€éœ€çš„ `eigs` å¤–å±‚è¿­ä»£æ¬¡æ•°ã€‚
  - **çº¿æ€§ç³»ç»Ÿ**ï¼šå…±è½­æ¢¯åº¦æ³•ï¼ˆCGï¼‰è¾¾åˆ°æŒ‡å®šæ®‹å·®å®¹é™ï¼ˆå¦‚ `10^-10`ï¼‰æ‰€éœ€çš„è¿­ä»£æ¬¡æ•°ã€‚
  - **çŸ©é˜µå‡½æ•°é€¼è¿‘**ï¼šç®—å­èŒƒæ•°ä¸‹çš„é€¼è¿‘è¯¯å·®ï¼Œä¾‹å¦‚ `||P(X)X^(1/2) - I||`ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **ç‰¹å¾å€¼é—®é¢˜**ï¼šæ ‡å‡†å¹‚è¿­ä»£/å­ç©ºé—´è¿­ä»£ (`P(X)=X^d`) å’Œ **Chebyshevæ»¤æ³¢å™¨**ã€‚
- **çº¿æ€§ç³»ç»Ÿ**ï¼šæ— é¢„æ¡ä»¶çš„CGã€Richardsonè¿­ä»£å’Œ **Chebyshevå¤šé¡¹å¼é¢„æ¡ä»¶å™¨**ã€‚
- **çŸ©é˜µå‡½æ•°é€¼è¿‘**ï¼šæˆªæ–­çš„Neumannçº§æ•°ï¼ˆå³æ³°å‹’å±•å¼€ï¼‰ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”ç»“æœ
åœ¨æ‰€æœ‰ä¸‰é¡¹ä»»åŠ¡ä¸Šï¼ŒAUToSPECå‘ç°çš„ç®—æ³•å‡æ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ï¼š

1.  **ç‰¹å¾å€¼é—®é¢˜**ï¼š
    - åœ¨ `Si02` çŸ©é˜µä¸Šï¼Œå½“ `k=10` æ—¶ï¼ŒAUToSPECä»…éœ€ **23** æ¬¡è¿­ä»£å³å¯è¾¾åˆ°ç²¾åº¦ï¼Œè€Œæ ‡å‡†å¹‚è¿­ä»£åœ¨500æ¬¡åä»æœªæ”¶æ•›ï¼ˆ`>500`ï¼‰ã€‚
    - åœ¨ `CO` çŸ©é˜µä¸Šï¼Œå½“ `k=20` æ—¶ï¼ŒAUToSPECéœ€ **27** æ¬¡è¿­ä»£ï¼Œè€ŒåŸºçº¿æ–¹æ³•éœ€ **126** æ¬¡ã€‚
    - ä¸Chebyshevç›¸æ¯”ï¼ŒAUToSPECä¹Ÿè¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶åœ¨æ›´å…·æŒ‘æˆ˜æ€§çš„è°±ä¸Šï¼ˆå¦‚ `Si02` å’Œ `CO`ï¼‰ï¼Œè¿­ä»£æ¬¡æ•°å‡å°‘äº†ä¸€åŠä»¥ä¸Šã€‚

2.  **çº¿æ€§ç³»ç»Ÿ**ï¼š
    - åœ¨ `thermal2` çŸ©é˜µä¸Šï¼ŒAUToSPECé¢„æ¡ä»¶çš„CGä»…éœ€ **705** æ¬¡è¿­ä»£ï¼Œè€Œæ— é¢„æ¡ä»¶çš„CGåœ¨5000æ¬¡åä»æœªæ”¶æ•›ï¼ˆ`>5000`ï¼‰ã€‚
    - ä¸Chebyshevé¢„æ¡ä»¶å™¨ç›¸æ¯”ï¼ŒAUToSPECåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹è¡¨ç°ç›¸å½“ç”šè‡³æ›´å¥½ï¼Œä¾‹å¦‚åœ¨ `G2_circuit` ä¸Šï¼ŒAUToSPECéœ€70æ¬¡ï¼Œè€ŒChebyshevéœ€79æ¬¡ï¼ˆä½¿ç”¨ç›¸åŒè´¨é‡çš„è°±æ¢é’ˆï¼‰ã€‚

3.  **çŸ©é˜µå‡½æ•°é€¼è¿‘**ï¼š
    - åœ¨ `E. coli` DNAç›¸ä¼¼æ€§çŸ©é˜µçš„åæ–¹å·®ç™½åŒ–ä»»åŠ¡ä¸­ï¼ŒAUToSPECå­¦ä¹ çš„é€¼è¿‘ç®—æ³•åœ¨ç®—å­èŒƒæ•°è¯¯å·®ä¸Šæ¯”Neumannçº§æ•°åŸºçº¿å®ç°äº†**ä¸€ä¸ªæ•°é‡çº§ï¼ˆorder of magnitudeï¼‰çš„æ”¹è¿›**ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **æ®‹å·®ç‰¹å¾çš„é‡è¦æ€§**ï¼šæ¶ˆèç ”ç©¶ï¼ˆAblation Studyï¼‰è¡¨æ˜ï¼Œå°†æ®‹å·®èŒƒæ•° `r` ä½œä¸ºè¾“å…¥è‡³å…³é‡è¦ã€‚å½“ç§»é™¤æ®‹å·®ç‰¹å¾æ—¶ï¼Œæ‰€ç”Ÿæˆç®—æ³•çš„æœ‰æ•ˆæ€§æ˜¾è‘—ä¸‹é™ï¼Œå°¤å…¶æ˜¯åœ¨è°±æ¢é’ˆè´¨é‡è¾ƒä½ï¼ˆå³warm-startè¿­ä»£æ¬¡æ•°å°‘ï¼‰çš„æƒ…å†µä¸‹ã€‚
- **é²æ£’æ€§**ï¼šå®éªŒæ˜¾ç¤ºï¼Œä¸€æ—¦è°±æ¢é’ˆçš„è´¨é‡è¾¾åˆ°ä¸€å®šé˜ˆå€¼ï¼ˆå¦‚è¶…è¿‡75æ­¥Lanczosè¿­ä»£ï¼‰ï¼ŒAUToSPECçš„æ€§èƒ½å°±ä¼šè¶‹äºç¨³å®šï¼Œè¯æ˜äº†å…¶å¯¹è°±è¾“å…¥æ‰°åŠ¨çš„é²æ£’æ€§ã€‚
- **ä¸ç»å…¸ç†è®ºçš„è”ç³»**ï¼šé€šè¿‡å¯¹å­¦ä¹ åˆ°çš„å¤šé¡¹å¼è¿›è¡Œåˆ†æï¼Œå‘ç°å®ƒä»¬è¡¨ç°å‡ºæ¥è¿‘**minimax**å’Œ**equiripple**ï¼ˆç­‰æ³¢çº¹ï¼‰çš„è¡Œä¸ºï¼Œè¿™ä¸æœ€ä¼˜çš„Chebyshevå¤šé¡¹å¼ç‰¹æ€§é«˜åº¦ä¸€è‡´ã€‚è¡¨1ä¸­çš„â€œminimax optimality gapâ€æ˜¾ç¤ºï¼Œå­¦ä¹ åˆ°çš„å¤šé¡¹å¼è¿œä¼˜äºéšæœºç”Ÿæˆçš„å¤šé¡¹å¼ï¼Œä¸”éå¸¸æ¥è¿‘ç†è®ºæœ€ä¼˜å€¼ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1.  **MLå¯ç”¨äºå‘ç°é«˜æ€§èƒ½NLAç®—æ³•**ï¼šAUToSPECçš„æˆåŠŸè¯æ˜äº†æœºå™¨å­¦ä¹ ä¸ä»…å¯ä»¥è¾…åŠ©ï¼Œæ›´èƒ½ç›´æ¥**å‘ç°å…¨æ–°çš„ã€é«˜æ€§èƒ½çš„æ•°å€¼ç®—æ³•**ã€‚
2.  **å‘ç°çš„ç®—æ³•å…·æœ‰ç†è®ºæœ€ä¼˜æ€§**ï¼šå°½ç®¡æ˜¯é€šè¿‡æ•°æ®é©±åŠ¨çš„æ–¹å¼å­¦ä¹ ï¼Œä½†å‘ç°çš„ç®—æ³•åœ¨è¡Œä¸ºä¸Šä¸ç»å…¸çš„æœ€ä¼˜ç†è®ºï¼ˆå¦‚Chebyshevé€¼è¿‘ï¼‰æƒŠäººåœ°å»åˆï¼Œè¡¨æ˜MLèƒ½å¤Ÿâ€œé‡æ–°å‘ç°â€å¹¶å¯èƒ½è¶…è¶Šäººç±»è®¾è®¡çš„æ•°å­¦æ™ºæ…§ã€‚
3.  **æ¡†æ¶å…·å¤‡å¼ºå¤§æ³›åŒ–èƒ½åŠ›**ï¼šåœ¨å°å‹åˆæˆæ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹ï¼Œèƒ½å¤Ÿæ— ç¼è¿ç§»åˆ°å¤§è§„æ¨¡ã€å¤æ‚çš„çœŸå®ä¸–ç•Œé—®é¢˜ä¸Šï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„å®ç”¨æ½œåŠ›ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–è°±æ¢é’ˆ**ï¼šè™½ç„¶æ¢é’ˆæ˜¯å»‰ä»·çš„ï¼Œä½†è¯¥æ–¹æ³•ä»ç„¶éœ€è¦ä¸€ä¸ªåˆæ­¥çš„è°±ä¼°è®¡æ­¥éª¤ã€‚å¯¹äºè°±ç»“æ„æå…¶å¤æ‚æˆ–éš¾ä»¥ä¼°è®¡çš„ç®—å­ï¼Œå…¶æ•ˆæœå¯èƒ½ä¼šå—é™ã€‚
- **æ¶æ„é™åˆ¶**ï¼šä¸»æ–‡æœ¬ä¸»è¦å…³æ³¨çº¿æ€§é€’æ¨ï¼Œå°½ç®¡é™„å½•æåˆ°äº†æ›´é«˜é˜¶å’Œæœ‰ç†æ¨¡å‹ï¼Œä½†è¿™äº›æ‰©å±•åœ¨å®é™…åº”ç”¨ä¸­å¯èƒ½é¢ä¸´æ›´å¤§çš„è®¡ç®—å¼€é”€ã€‚
- **å¯è§£é‡Šæ€§**ï¼šè™½ç„¶å‘ç°äº†æœ‰æ•ˆçš„ç®—æ³•ï¼Œä½†ç¥ç»ç½‘ç»œå†…éƒ¨çš„å†³ç­–è¿‡ç¨‹ä»ç„¶æ˜¯ä¸€ä¸ªâ€œé»‘ç®±â€ï¼Œå…¶å…·ä½“å·¥ä½œæœºåˆ¶ä¸å¦‚ä¼ ç»Ÿç®—æ³•é‚£æ ·ç›´è§‚ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´ä¸°å¯Œçš„æ›´æ–°ç±»åˆ«ï¼Œå¦‚**é«˜é˜¶å¤šé¡¹å¼é€’æ¨**å’Œ**æœ‰ç†æ¨¡å‹**ï¼ˆrational modelsï¼‰ï¼Œä»¥è¿›ä¸€æ­¥æå‡è¡¨è¾¾èƒ½åŠ›å’Œé€¼è¿‘æ•ˆç‡ã€‚
- å°†æ¡†æ¶æ‰©å±•åˆ°**ä¸€é˜¶ä¼˜åŒ–æ–¹æ³•**ï¼ˆå¦‚å­¦ä¹ å¸¦åŠ¨é‡çš„æ¢¯åº¦ä¸‹é™å˜ä½“ï¼‰ã€‚
- ç ”ç©¶å¦‚ä½•å°†AUToSPECä¸ç°æœ‰çš„å¤šå±‚çº§æ±‚è§£å™¨ï¼ˆmultilevel solversï¼‰ç»“åˆï¼Œä½œä¸ºå…¶ä¸­çš„ä¸€ä¸ªç»„ä»¶ã€‚
- æ¢ç´¢åœ¨æ›´å¤šæ ·åŒ–çš„NLAå’Œç§‘å­¦è®¡ç®—ä»»åŠ¡ä¸Šçš„åº”ç”¨ã€‚

</details>

---

### 10. [Optimistic World Models: Efficient Exploration in Model-Based Deep Reinforcement Learning](https://arxiv.org/abs/2602.10044)

**Authors**: Akshay Mete, Shahid Aamir Sheikh, Tzu-Hsiang Lin, Dileep Kalathil, P. R. Kumar  
**Category**: cs.LG  
**Published**: 2026-02-11  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.10044v1  

#### Abstract
Efficient exploration remains a central challenge in reinforcement learning (RL), particularly in sparse-reward environments. We introduce Optimistic World Models (OWMs), a principled and scalable framework for optimistic exploration that brings classical reward-biased maximum likelihood estimation ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šOptimistic World Models: Efficient Exploration in Model-Based Deep Reinforcement Learning**

---

## **1. ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
- **ç¨€ç–å¥–åŠ±ç¯å¢ƒä¸‹çš„ä½æ•ˆæ¢ç´¢**ï¼šç°æœ‰çš„åŸºäºä¸–ç•Œæ¨¡å‹ï¼ˆWorld Modelsï¼‰çš„ Model-Based Reinforcement Learningï¼ˆMBRLï¼‰ç®—æ³•ï¼ˆå¦‚ DreamerV3ã€STORMï¼‰åœ¨ç¨€ç–å¥–åŠ±ï¼ˆsparse-rewardï¼‰ç¯å¢ƒä¸­è¡¨ç°ä¸ä½³ï¼Œå› ä¸ºå…¶ä¾èµ–çš„ç­–ç•¥ç†µæ­£åˆ™åŒ–ï¼ˆpolicy entropy regularizationï¼‰ç­‰æ¢ç´¢æœºåˆ¶ä¸è¶³ä»¥é©±åŠ¨å……åˆ†æ¢ç´¢ã€‚
- **é—­ç¯è¾¨è¯†é—®é¢˜ï¼ˆClosed-loop Identification Problemï¼‰**ï¼šæ ‡å‡†çš„ Certainty Equivalence åŸåˆ™ï¼ˆå³ç”¨æœ€å¤§ä¼¼ç„¶ä¼°è®¡å»ºæ¨¡åç›´æ¥ä¼˜åŒ–ç­–ç•¥ï¼‰ä¼šå¯¼è‡´æ¨¡å‹ä»…åœ¨é—­ç¯è½¨è¿¹ä¸Šè¢«è¯†åˆ«ï¼Œå¯èƒ½æ”¶æ•›åˆ°æ¬¡ä¼˜ç­–ç•¥ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•**
- **Optimistic World Models (OWMs)**ï¼šä¸€ç§å°†ç»å…¸æ§åˆ¶ç†è®ºä¸­çš„ **Reward-Biased Maximum Likelihood Estimation (RBMLE)** åŸåˆ™å¼•å…¥æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„æ¡†æ¶ã€‚
- **æ ¸å¿ƒæœºåˆ¶**ï¼š
  - åœ¨ä¸–ç•Œæ¨¡å‹è®­ç»ƒç›®æ ‡ä¸­åŠ å…¥ä¸€ä¸ª**ä¹è§‚åŠ¨åŠ›å­¦æŸå¤±ï¼ˆoptimistic dynamics lossï¼‰**ï¼Œè¯¥æŸå¤±é€šè¿‡æƒ³è±¡è½¨è¿¹ï¼ˆimagined trajectoriesï¼‰å¼•å¯¼æ¨¡å‹çš„åŠ¨åŠ›å­¦é¢„æµ‹åå‘é«˜å¥–åŠ±ç»“æœã€‚
  - æ— éœ€ä¸ç¡®å®šæ€§ä¼°è®¡æˆ–å¤æ‚çº¦æŸä¼˜åŒ–ï¼Œå®Œå…¨åŸºäºæ¢¯åº¦æ›´æ–°ï¼Œæ˜“äºé›†æˆåˆ°ç°æœ‰æ¡†æ¶ä¸­ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç‰¹æ€§ | OWMs | UCBç±»æ–¹æ³•ï¼ˆå¦‚H-UCRLï¼‰ | å¯å‘å¼æ¢ç´¢ï¼ˆå¦‚Ensemble, Intrinsic Motivationï¼‰ |
|------|------|------------------------|---------------------------------------------|
| æ˜¯å¦éœ€è¦ä¸ç¡®å®šæ€§ä¼°è®¡ | âŒ | âœ…ï¼ˆé«˜è®¡ç®—å¼€é”€ï¼‰ | âœ…ï¼ˆé€šå¸¸éœ€è¦ï¼‰ |
| æ˜¯å¦å¯æ‰©å±•è‡³å¤§è§„æ¨¡DRL | âœ…ï¼ˆå…¨æ¢¯åº¦æ³•ï¼‰ | âŒï¼ˆéå‡¸ä¼˜åŒ–ç“¶é¢ˆï¼‰ | âœ…ä½†æ•ˆæœä¸ç¨³å®š |
| æ¶æ„å…¼å®¹æ€§ | âœ…ï¼ˆPlug-and-playï¼‰ | âŒ | âœ… |
| ç†è®ºåŸºç¡€ | âœ…ï¼ˆæºè‡ªRBMLEï¼Œæœ‰æ”¶æ•›ä¿è¯ï¼‰ | âœ… | âŒ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šOWMs æä¾›äº†ä¸€ç§**åŸåˆ™æ€§å¼ºã€è®¡ç®—é«˜æ•ˆã€å¯æ’æ‹”**çš„æ¢ç´¢æœºåˆ¶ï¼Œå…‹æœäº† UCB æ–¹æ³•çš„è®¡ç®—éšœç¢ï¼Œå¹¶ä¼˜äºå¯å‘å¼æ¢ç´¢åœ¨ç¨€ç–å¥–åŠ±ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **Atari100K Benchmark**ï¼š
  - åŒ…å« 26 ä¸ª Atari æ¸¸æˆã€‚
  - æ¯ä¸ªæ¸¸æˆé™åˆ¶ä¸º **400K å¸§ï¼ˆçº¦2å°æ—¶çœŸå®äº¤äº’ï¼‰**ï¼Œç”¨äºè¯„ä¼°æ ·æœ¬æ•ˆç‡ã€‚
- **DeepMind Control (DMC) Suite**ï¼š
  - è¿ç»­æ§åˆ¶ä»»åŠ¡ï¼Œåˆ†ä¸ºä¸¤ä¸ªå­é›†ï¼š
    - **DMC Proprio**ï¼šçŠ¶æ€è¾“å…¥ï¼ˆstate-basedï¼‰ï¼Œé¢„ç®— 500K æ­¥ã€‚
    - **DMC Vision**ï¼šå›¾åƒè¾“å…¥ï¼ˆimage-basedï¼‰ï¼Œé¢„ç®— 1M æ­¥ã€‚
  - åŒ…æ‹¬ç¨€ç–å¥–åŠ±å˜ä½“ï¼ˆå¦‚ `Cartpole Swingup Sparse`ï¼‰ã€‚

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**
- **è¯„ä¼°æ–¹å¼**ï¼š
  - æŠ¥å‘Šå¹³å‡å¥–åŠ± Â± æ ‡å‡†è¯¯å·®ï¼ˆmean reward Â± SEMï¼‰ã€‚
  - å¹³æ»‘çª—å£ä¸º 3ï¼Œæ¯ checkpoint ä½¿ç”¨ 20 æ¡è¯„ä¼°è½¨è¿¹ã€‚
- **ç§å­æ•°é‡**ï¼š
  - O-DreamerV3 åœ¨ Atari100K å’Œ DMC ä¸Šä½¿ç”¨ **10 ä¸ªéšæœºç§å­**ã€‚
  - O-STORM åŠæ¶ˆèå®éªŒä½¿ç”¨ **5 ä¸ªç§å­**ï¼ˆå—é™äºç®—åŠ›ï¼‰ã€‚
- **ä¸»è¦æŒ‡æ ‡**ï¼š
  - **Human-Normalized Score (HNS)**ï¼šè¡¡é‡ç›¸å¯¹äºäººç±»è¡¨ç°çš„å½’ä¸€åŒ–å¾—åˆ†ã€‚
  - Interquartile Mean (IQM)ã€Median ç­‰é²æ£’ç»Ÿè®¡é‡ã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **ä¸»åŸºçº¿**ï¼š
  - **DreamerV3** vs **Optimistic DreamerV3 (O-DreamerV3)**
  - **STORM** vs **Optimistic STORM (O-STORM)**
- æ‰€æœ‰å…¶ä»–ç»„ä»¶ä¿æŒä¸€è‡´ï¼Œä»…æ·»åŠ ä¹è§‚åŠ¨åŠ›å­¦æŸå¤±ã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **Atari100K ä¸Šçš„æ•´ä½“æ€§èƒ½**
| æ–¹æ³• | å¹³å‡ HNS (%) |
|------|--------------|
| DreamerV3 | 97.45% |
| **O-DreamerV3** | **152.68%** â¬†ï¸ (+55%) |
| STORM | 75.90% |
| **O-STORM** | **80.68%** |

> ğŸ”¥ **æå‡æ˜¾è‘—**ï¼šO-DreamerV3 åœ¨ä»…å¢åŠ æå°è®¡ç®—å¼€é”€çš„æƒ…å†µä¸‹ï¼Œå®ç°äº† **55% çš„å¹³å‡ HNS æå‡**ã€‚

#### **ç¨€ç–å¥–åŠ±ä»»åŠ¡ä¸Šçš„çªç ´æ€§è¡¨ç°**
- **Private Eye**ï¼ˆæç«¯ç¨€ç–å¥–åŠ±ï¼‰ï¼š
  - O-DreamerV3 è¾¾åˆ° **2120.48 åˆ†**ï¼Œè€Œ DreamerV3 ä»…ä¸º **115.53 åˆ†**ï¼ˆ**18.3å€æå‡**ï¼‰ã€‚
- **Freeway**ï¼š
  - STORM å¾—åˆ†ä¸º 0ï¼›
  - **O-STORM è¾¾åˆ° 6.38 åˆ†**ï¼Œæ˜¯å”¯ä¸€å–å¾—æ­£æ”¶ç›Šçš„æ–¹æ³•ã€‚
- **Montezumaâ€™s Revenge**ï¼š
  - O-DreamerV3 åœ¨ 40M æ­¥æ—¶è¾¾åˆ°è¿‘ **2å€äº DreamerV3 çš„å¹³å‡å›æŠ¥**ã€‚

#### **DMC ä¸Šçš„è¡¨ç°**
- åœ¨ `Acrobot Swingup Sparse` å’Œ `Cartpole Swingup Sparse` ä¸­å‡æœ‰æ˜æ˜¾æå‡ï¼š
  - å¦‚ `Acrobot Swingup Sparse`ï¼ˆProprioï¼‰ï¼š
    - DreamerV3: 8.4 â†’ **O-DreamerV3: 34.6**ï¼ˆ+312%ï¼‰
- å¤šæ•°å¯†é›†å¥–åŠ±ä»»åŠ¡æ€§èƒ½æŒå¹³æˆ–ç•¥æœ‰æ³¢åŠ¨ï¼Œæ— æ˜¾è‘—é€€åŒ–ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- OWMs åœ¨ **ç»å¤§å¤šæ•° Atari æ¸¸æˆä¸­ä¼˜äºåŸºçº¿**ï¼ˆè§ Figure 4aï¼‰ã€‚
- åœ¨ **ç¨€ç–å¥–åŠ±ä»»åŠ¡ä¸Šä¼˜åŠ¿æœ€ä¸ºçªå‡º**ï¼ŒéªŒè¯äº†å…¶æ¢ç´¢èƒ½åŠ›çš„æœ‰æ•ˆæ€§ã€‚
- å³ä½¿åœ¨å¯†é›†å¥–åŠ±ä»»åŠ¡ï¼ˆå¦‚ Enduroã€UpNDownï¼‰ä¹Ÿè¡¨ç°å‡ºç«äº‰åŠ›ã€‚

### **æ¶ˆèå®éªŒç»“æœ**
#### **(1) æ˜¯å¦ä½¿ç”¨æ¨¡å‹ç†µæŸå¤±ï¼ˆModel Entropy Lossï¼‰**
- ç§»é™¤ç†µé¡¹åæ€§èƒ½ä¸‹é™ï¼ˆFigure 10ï¼‰ï¼Œè¯´æ˜ç†µæ­£åˆ™æœ‰åŠ©äºé˜²æ­¢æ¨¡å‹è¿‡åº¦è‡ªä¿¡ã€‚

#### **(2) è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æ**
- **ä¹è§‚ç³»æ•° $\alpha(t)$**ï¼š
  - è®¾ä¸ºå¸¸æ•° $\alpha = 0.0001$ è¡¨ç°æœ€ä½³ã€‚
  - è‹¥è®¾ä¸ºè¿‡å¤§å€¼ï¼ˆå¦‚ 0.1ï¼‰ï¼Œå¯¼è‡´â€œè¿‡åº¦ä¹è§‚â€ï¼Œæ€§èƒ½æ€¥å‰§ä¸‹é™ï¼ˆFigure 11ï¼‰ã€‚
- **æ¨¡å‹ç†µç³»æ•° $\eta$**ï¼š
  - å°å€¼æœ‰ç›Šï¼ˆå¦‚ $3\times10^{-6}$ï¼‰ï¼Œå¤§å€¼ï¼ˆå¦‚ 0.03ï¼‰æœ‰å®³ï¼ˆFigure 12ï¼‰ã€‚

#### **(3) è®¡ç®—å¼€é”€**
| æ–¹æ³• | MsPacman è®­ç»ƒæ—¶é—´ï¼ˆåˆ†é’Ÿï¼ŒRTX 4090ï¼‰ |
|------|-------------------------------|
| DreamerV3 | 115 |
| **O-DreamerV3** | **138** |
| STORM | 170 |
| **O-STORM** | **178** |

> â• **ä»…å¢åŠ çº¦ 20% çš„è®­ç»ƒæ—¶é—´**ï¼Œå…·å¤‡è‰¯å¥½çš„å¯æ‰©å±•æ€§ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. âœ… **RBMLE åŸåˆ™å¯ä»¥æˆåŠŸè¿ç§»åˆ°å¤§è§„æ¨¡æ·±åº¦ MBRL**ï¼š
   - é¦–æ¬¡å®ç°å…¨æ¢¯åº¦å½¢å¼çš„ RBMLEï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•éš¾ä»¥æ‰©å±•çš„é—®é¢˜ã€‚
2. âœ… **ä¹è§‚æ¢ç´¢å¯é€šè¿‡ä¿®æ”¹æ¨¡å‹è®­ç»ƒç›®æ ‡å®ç°**ï¼š
   - ä¸ä¾èµ– UCB å¼çš„ç½®ä¿¡åŒºé—´æˆ– Thompson Samplingï¼Œè€Œæ˜¯é€šè¿‡æŸå¤±å‡½æ•°ç›´æ¥æ³¨å…¥ä¹è§‚åå·®ã€‚
3. âœ… **OWMs æ˜¾è‘—æå‡ç¨€ç–å¥–åŠ±ç¯å¢ƒä¸­çš„æ¢ç´¢æ•ˆç‡**ï¼š
   - åœ¨å¤šä¸ªæå…·æŒ‘æˆ˜æ€§çš„æ¸¸æˆä¸­å®ç°æ•°é‡çº§çº§åˆ«çš„æ€§èƒ½é£è·ƒã€‚
4. âœ… **æ–¹æ³•å…·æœ‰å¼ºé€šç”¨æ€§å’Œå³æ’å³ç”¨ç‰¹æ€§**ï¼š
   - æˆåŠŸåº”ç”¨äº DreamerV3 å’Œ STORM ä¸¤ç§ä¸åŒæ¶æ„ï¼Œå‡æœ‰æ•ˆã€‚

### **å±€é™æ€§**
- **è¶…å‚æ•°è®¾è®¡ä»è¾ƒç»éªŒæ€§**ï¼š
  - å½“å‰ä½¿ç”¨å›ºå®š $\alpha(t)$ï¼Œæœªè‡ªé€‚åº”è°ƒæ•´ï¼Œå¯èƒ½é™åˆ¶è¿›ä¸€æ­¥æ€§èƒ½æ½œåŠ›ã€‚
- **ç†è®ºæ”¶æ•›æ€§å°šæœªåœ¨æ·±åº¦ç½‘ç»œä¸‹ä¸¥æ ¼è¯æ˜**ï¼š
  - RBMLE åœ¨è¡¨æ ¼å‹ MDP ä¸­æœ‰ç†è®ºä¿éšœï¼Œä½†åœ¨ç¥ç»ç½‘ç»œå‚æ•°åŒ–ä¸‹çš„æ”¶æ•›æ€§è´¨éœ€è¿›ä¸€æ­¥ç ”ç©¶ã€‚
- **å¯¹æŸäº›ä»»åŠ¡å­˜åœ¨è½»å¾®æ€§èƒ½ä¸‹é™**ï¼š
  - å¦‚ `Hopper Hop` ç­‰ä»»åŠ¡ä¸­ O-DreamerV3 è¡¨ç°ç•¥å·®ï¼Œè¡¨æ˜éœ€æ›´ç²¾ç»†çš„å¹³è¡¡æœºåˆ¶ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- ğŸ”„ **è®¾è®¡è‡ªé€‚åº”çš„ $\alpha(t)$ è°ƒåº¦æœºåˆ¶**ï¼š
  - ç±»ä¼¼ Agent57 ä¸­çš„å…ƒæ§åˆ¶å™¨ï¼Œæ ¹æ®æ¢ç´¢è¿›åº¦åŠ¨æ€è°ƒèŠ‚ä¹è§‚ç¨‹åº¦ã€‚
- ğŸ“ˆ **ç»“åˆå…¶ä»–æ¢ç´¢æœºåˆ¶**ï¼ˆå¦‚ Intrinsic Motivationï¼‰è¿›è¡Œæ··åˆæ¢ç´¢ã€‚
- ğŸ§  **å¼€å±•æ›´æ·±å…¥çš„ç†è®ºåˆ†æ**ï¼š
  - æ¢ç´¢æ¢¯åº¦ç‰ˆ RBMLE åœ¨éçº¿æ€§å‡½æ•°é€¼è¿‘ä¸‹çš„æ”¶æ•›æ€§ä¸ regret boundã€‚
- ğŸ› ï¸ **æ¨å¹¿è‡³æ›´å¤šä¸–ç•Œæ¨¡å‹æ¶æ„**ï¼ˆå¦‚ MuZeroã€EfficientZeroï¼‰ä»¥éªŒè¯æ™®é€‚æ€§ã€‚

---

> ğŸ’¡ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **Optimistic World Models (OWMs)** å°†ç»å…¸çš„ RBMLE åŸåˆ™è½¬åŒ–ä¸ºå¯å¾®åˆ†ã€å¯æ‰©å±•çš„æ·±åº¦å­¦ä¹ æ¨¡å—ï¼Œé€šè¿‡åœ¨æ¨¡å‹è®­ç»ƒä¸­æ³¨å…¥â€œä¹è§‚åè§â€ï¼Œå®ç°äº†åœ¨ç¨€ç–å¥–åŠ±ç¯å¢ƒä¸‹å‰æ‰€æœªæœ‰çš„æ¢ç´¢æ•ˆç‡ï¼ŒåŒæ—¶ä¿æŒäº†ä¸ä¸»æµä¸–ç•Œæ¨¡å‹æ¡†æ¶çš„æ— ç¼é›†æˆã€‚

</details>

---

### 11. [Towards Adaptive, Scalable, and Robust Coordination of LLM Agents: A Dynamic Ad-Hoc Networking Perspective](https://arxiv.org/abs/2602.08009)

**Authors**: Rui Li, Zeyu Zhang, Xiaohe Bo, Quanyu Dai, Chaozhuo Li, Feng Wen, Xu Chen  
**Category**: cs.AI  
**Published**: 2026-02-11  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.08009v1  

#### Abstract
Multi-agent architectures built on large language models (LLMs) have demonstrated the potential to realize swarm intelligence through well-crafted collaboration. However, the substantial burden of manual orchestration inherently raises an imperative to automate the design of agentic workflows. We fr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTowards Adaptive, Scalable, and Robust Coordination of LLM Agents: A Dynamic Ad-Hoc Networking Perspective

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆ**Multi-Agent Systems, MAS**ï¼‰åœ¨åè°ƒ **Large Language Model (LLM) Agents** æ—¶é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **Adaptivityï¼ˆé€‚åº”æ€§ï¼‰**ï¼šä¼ ç»Ÿæ–¹æ³•ä¾èµ–é™æ€æ‹“æ‰‘æˆ–é¢„å®šä¹‰æµç¨‹ï¼Œæ— æ³•æ ¹æ®åŠ¨æ€ä»»åŠ¡æµè°ƒæ•´åä½œè·¯å¾„ã€‚
- **Scalabilityï¼ˆå¯æ‰©å±•æ€§ï¼‰**ï¼šæ–°å¢æˆ–ç§»é™¤ agent éœ€è¦é‡æ–°ä¼˜åŒ–æ•´ä¸ªå·¥ä½œæµï¼Œæˆæœ¬é«˜æ˜‚ï¼›ä¸­å¿ƒåŒ–æ§åˆ¶å™¨éš agent æ•°é‡å¢é•¿å‡ºç°ç»„åˆçˆ†ç‚¸ç“¶é¢ˆã€‚
- **Robustnessï¼ˆé²æ£’æ€§ï¼‰**ï¼šä¸­å¿ƒåŒ–æ§åˆ¶å­˜åœ¨å•ç‚¹æ•…éšœé£é™©ï¼ˆSingle Point of Failure, SPoFï¼‰ï¼Œä¸”æ˜“å—å¯¹æŠ—æ€§æ”»å‡»æˆ–å¹»è§‰è¡Œä¸ºå½±å“ã€‚

è¿™äº›é™åˆ¶é˜»ç¢äº†çœŸæ­£å¼€æ”¾ã€è‡ªç»„ç»‡ã€å¯é çš„ LLM å¤šæ™ºèƒ½ä½“ç¤¾ä¼šçš„å‘å±•ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡º **RAPS (Reputation-Aware Publish-Subscribe)** æ¡†æ¶ï¼Œé¦–æ¬¡ä» **Dynamic Ad-Hoc Networkingï¼ˆåŠ¨æ€è‡ªç»„ç½‘ï¼‰** çš„è§†è§’é‡æ„ LLM Agent åè°ƒé—®é¢˜ã€‚

#### æ ¸å¿ƒæ€æƒ³
å°† LLM Agents è§†ä¸ºç½‘ç»œä¸­çš„è‡ªæ²»ä¸»æœºï¼ˆHostsï¼‰ï¼Œæ¶ˆæ¯ä¼ æ’­ç±»æ¯”äºä¿¡æ¯åŒ…ï¼ˆPacketsï¼‰è½¬å‘ï¼Œä»è€Œå¼•å…¥ç»å…¸ç½‘ç»œåè®®è®¾è®¡åŸåˆ™æ¥è§£å†³åè°ƒéš¾é¢˜ã€‚

#### åˆ›æ–°æ¶æ„ï¼šä¸‰å±‚ç»“æ„
| å±‚çº§ | ç»„ä»¶ | åŠŸèƒ½ |
|------|------|------|
| **Substrateï¼ˆé€šä¿¡åº•åº§ï¼‰** | **Distributed Publish-Subscribe Protocol** | è§£è€¦ agent ä¸º Publisherï¼ˆå‘å¸ƒè€…ï¼‰ã€Subscriberï¼ˆè®¢é˜…è€…ï¼‰ã€Brokerï¼ˆä¸­ä»‹ï¼‰ï¼ŒåŸºäºè¯­ä¹‰æ„å›¾è€Œéå›ºå®šæ‹“æ‰‘è¿›è¡Œæ¶ˆæ¯è·¯ç”± |
| **Overlay I** | **Reactive Subscriptionï¼ˆååº”å¼è®¢é˜…ï¼‰** | å…è®¸ agent åœ¨è¿è¡Œæ—¶åŠ¨æ€æ›´æ–°è‡ªèº«â€œæ„å›¾â€ï¼ˆå³ system promptï¼‰ï¼Œå®ç°è§’è‰²è‡ªé€‚åº”æ¼”åŒ– |
| **Overlay II** | **Bayesian Reputationï¼ˆè´å¶æ–¯å£°èª‰æœºåˆ¶ï¼‰** | æ¯ä¸ª agent ç»´æŠ¤æœ¬åœ° watchdogï¼Œé€šè¿‡è´å¶æ–¯ä¼°è®¡è¯„ä¼°å¯¹ç­‰ä½“å¯é æ€§ï¼Œå®ç°å»ä¸­å¿ƒåŒ–çš„ä¿¡ä»»ç®¡ç† |

è¯¥æ¡†æ¶å®ç°äº† **intent-based collaboration** å’Œ **decentralized trust**ï¼Œæ— éœ€é›†ä¸­è°ƒåº¦å³å¯è‡ªå‘å½¢æˆé«˜æ•ˆåä½œç½‘ç»œã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| èŒƒå¼ | ä»£è¡¨æ–¹æ³• | ç¼ºé™· | RAPS çš„ä¼˜åŠ¿ |
|-------|----------|--------|-------------|
| **Communication-Agnostic** | GPTSwarm, AFlow, G-Designer | å›ºå®šæ‹“æ‰‘ï¼Œä¸æ„ŸçŸ¥æ¨ç†è¿‡ç¨‹ä¸­çš„è¯­ä¹‰å˜åŒ–ï¼›éœ€ç¦»çº¿æœç´¢/è®­ç»ƒ | æ”¯æŒè¿è¡Œæ—¶åŠ¨æ€æ„å›¾åŒ¹é…ï¼Œé€‚åº”æ€§å¼º |
| **Meta-Controlled** | AutoAgents, Puppeteer, MAS-Zero | ä¸­å¿ƒåŒ–æ§åˆ¶å¯¼è‡´ SPoF å’Œæ‰©å±•ç“¶é¢ˆ | å®Œå…¨åˆ†å¸ƒå¼ï¼Œæ— å•ç‚¹æ•…éšœï¼Œå¯æ°´å¹³æ‰©å±• |
| **Static Topology** | Chain, Star, Tree | ç»“æ„åƒµåŒ–ï¼Œé”™è¯¯æ˜“ä¼ æ’­ | è‡ªä¸»ä¿®å¤è·¯å¾„ï¼ŒæŠ—å¹²æ‰°èƒ½åŠ›å¼º |

> âœ… RAPS æˆåŠŸç»Ÿä¸€äº† **Adaptivity, Scalability, Robustness** ä¸‰éš¾å›°å¢ƒï¼Œåœ¨ä¸€ä¸ªæ— éœ€è®­ç»ƒçš„æ¡†æ¶ä¸‹åŒæ—¶æ»¡è¶³ä¸‰é¡¹å…³é”®éœ€æ±‚ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–äº”ä¸ªä»£è¡¨æ€§åŸºå‡†ï¼Œæ¶µç›–ä¸‰å¤§ä»»åŠ¡ç±»åˆ«ï¼š

| æ•°æ®é›† | ç±»åˆ« | ä»»åŠ¡æè¿° | è¯„ä¼°æŒ‡æ ‡ |
|--------|------|---------|----------|
| **MMLU** | General Reasoning | å¤šé¢†åŸŸçŸ¥è¯†é—®ç­”ï¼ˆSTEMã€äººæ–‡ç­‰ï¼‰ | Accuracy |
| **GSM8K**, **SVAMP**, **AQuA** | Mathematical Reasoning | æ•°å­¦åº”ç”¨é¢˜æ±‚è§£ï¼ˆå¤šæ­¥é€»è¾‘æ¨ç†ï¼‰ | Accuracy |
| **HumanEval** | Code Generation | Python ç¼–ç¨‹é—®é¢˜ç”Ÿæˆ | Pass@1 |

> ğŸ“Š æ‰€æœ‰æ–¹æ³•å‡ä½¿ç”¨ç›¸åŒæ•°é‡ï¼ˆN=5ï¼‰çš„ agent è¿›è¡Œå…¬å¹³æ¯”è¾ƒã€‚

---

### å®éªŒè®¾ç½®
- **Backbone Model**: ä¸»è¦ä½¿ç”¨ `GPT-4o-mini` ä½œä¸ºæ‰€æœ‰ agent çš„ LLM æ ¸å¿ƒã€‚
- **Broker å®ç°**:
  - é»˜è®¤é‡‡ç”¨ `text-embedding-3-small` è¿›è¡ŒåµŒå…¥ç›¸ä¼¼åº¦åŒ¹é…ï¼ˆé«˜æ•ˆï¼‰
  - å¯é€‰ LLM-based Broker ç”¨äºå¤æ‚å†³ç­–åˆ†æ
- **è¶…å‚æ•°**:
  - æœ€å¤§é€šä¿¡è½®æ¬¡ $ k = 5 $
  - è´å¶æ–¯è¡°å‡å› å­ $ \lambda = 0.9 $
  - å£°èª‰é˜ˆå€¼ $ T_{rep} = 0.7 $ï¼Œä½äºæ­¤å€¼åˆ™æ‹’ç»é€šä¿¡

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å…±å››ç±» baselineï¼š
1. **Single-Agent Models**  
   - Vanilla IO, CoT, ComplexCoT, Self-Consistency (SC)

2. **Static Multi-Agent Models**  
   - Chain, Star, Tree, Randomï¼ˆå›ºå®šæ‹“æ‰‘ï¼‰
   - LLM-Debate, LLM-Blenderï¼ˆå…±è¯†æœºåˆ¶ï¼‰

3. **Communication-Agnostic Models**  
   - GPTSwarm, AgentPrune, AFlow, MaAS, G-Designerï¼ˆåŸºäºå›¾æœç´¢æˆ–å­¦ä¹ çš„å·¥ä½œæµï¼‰

4. **Meta-Controlled Models**  
   - AutoAgents, Puppeteer, MAS-Zeroï¼ˆä¾èµ–ä¸­å¤® meta-controllerï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 1ï¼‰
| æ–¹æ³• | MMLU | GSM8K | SVAMP | AQuA | HumanEval | **Average** |
|------|------|-------|-------|------|-----------|------------|
| G-Designer (SOTA prior) | 86.3 | 93.2 | 90.7 | 79.4 | 90.2 | 88.0 |
| **RAPS (Ours)** | **88.2** | **95.4** | **92.2** | **82.6** | **91.5** | **90.0** |

âœ… RAPS åœ¨æ‰€æœ‰äº”é¡¹ä»»åŠ¡ä¸Šå‡è¾¾åˆ° **state-of-the-art æ€§èƒ½**ï¼Œå¹³å‡å‡†ç¡®ç‡æå‡ **+2.0%**ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ä¼˜äºé™æ€ç»“æ„**ï¼šå¦‚ Chain åœ¨ SVAMP ä¸Šä»…ä¸º 82.6%ï¼Œæ˜¾è‘—ä½äº CoTï¼ˆ88.4%ï¼‰ï¼Œè¡¨æ˜åˆšæ€§æ‹“æ‰‘éš¾ä»¥åº”å¯¹å¤šæ ·åŒ–æ¨ç†æ¨¡å¼ã€‚
- **è¶…è¶Šé€šä¿¡æ— å…³æ¨¡å‹**ï¼šç›¸æ¯” G-Designerï¼ŒRAPS åœ¨ AQuA ä¸Šé«˜å‡º **+3.2%**ï¼Œå¾—ç›Šäºè¿è¡Œæ—¶è¯­ä¹‰å¯¹é½èƒ½åŠ›ã€‚
- **å‡»è´¥ä¸­å¿ƒåŒ–æ§åˆ¶æ¨¡å‹**ï¼šç›¸æ¯” Puppeteer å¹³å‡é«˜ **+6.0%**ï¼Œä¸”é¿å…äº†ä¸­å¿ƒæ§åˆ¶å™¨å´©æºƒé£é™©ï¼ˆè§é²æ£’æ€§æµ‹è¯•ï¼‰ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 3ï¼‰
æ¶ˆèéªŒè¯äº†ä¸¤ä¸ª overlay æœºåˆ¶çš„æœ‰æ•ˆæ€§ï¼š

| å˜ä½“ | MMLU | GSM8K | HumanEval |
|------|------|-------|----------|
| **RAPS (Full)** | **88.2** | **95.4** | **91.5** |
| w/o Reactive Subscription (w/o RS) | 85.6 (-2.6) | 93.7 (-1.7) | 89.3 (-2.2) |
| w/o Bayesian Reputation (w/o BR) | 86.9 (-1.3) | 94.5 (-0.9) | 90.7 (-0.8) |
| w/o Both | 83.7 (-4.5) | 92.8 (-2.6) | 88.5 (-3.0) |

ğŸ”¹ **Reactive Subscription** å¯¹æ€§èƒ½æå‡è´¡çŒ®æ›´å¤§ï¼Œè¯´æ˜åŠ¨æ€è§’è‰²è°ƒæ•´è‡³å…³é‡è¦ã€‚  
ğŸ”¹ **Bayesian Reputation** æ˜¾è‘—å¢å¼ºç³»ç»Ÿç¨³å®šæ€§ï¼Œå°¤å…¶åœ¨å¯¹æŠ—ç¯å¢ƒä¸‹ã€‚

---

### é²æ£’æ€§æµ‹è¯•ï¼ˆTable 2ï¼‰â€”â€” Byzantine Stress Test
æ³¨å…¥ä¸åŒæ¯”ä¾‹çš„ **Adversarial Agentsï¼ˆè¯´è°è€…ï¼‰** æµ‹è¯•ç³»ç»Ÿå®¹é”™èƒ½åŠ›ï¼ˆMMLUï¼‰ï¼š

| æ–¹æ³• | 5T0A | 4T1A | 3T2A | 2T3A | 5T5Aï¼ˆæ··åˆï¼‰ |
|------|-----|-----|-----|-----|--------|
| Chain | 84.3 | 72.5 | 50.3 | 22.2 | 16.3 |
| G-Designer | 86.3 | 80.4 | 37.9 | 15.0 | 49.7 |
| Puppeteer-Cï¼ˆæ”»å‡»æ§åˆ¶å™¨ï¼‰ | 84.3 | **13.7** | â€” | â€” | â€” |
| **RAPS** | **88.2** | **87.6** | **84.3** | **83.0** | **86.3** |

ğŸ”´ Puppeteer åœ¨æ§åˆ¶å™¨è¢«æ”»ç ´åç«‹å³å´©æºƒï¼ˆ84.3% â†’ 13.7%ï¼‰ã€‚  
ğŸŸ¢ RAPS å‡ ä¹ä¸å—å½±å“ï¼Œå³ä½¿ä¸€åŠ agent æ˜¯æ¶æ„èŠ‚ç‚¹ä»ä¿æŒ >83% å‡†ç¡®ç‡ã€‚

---

### å¯æ‰©å±•æ€§ä¸æ•ˆç‡åˆ†æï¼ˆFigure 3ï¼‰
- **Scalability**ï¼šéšç€ agent æ•°é‡å¢åŠ ï¼ŒRAPS æŒç»­æå‡æ€§èƒ½ï¼Œè€Œ Chain å’Œ Puppeteer å› è¯¯å·®ç´¯ç§¯æˆ–æ§åˆ¶è´Ÿæ‹…åŠ é‡è€Œä¸‹é™ã€‚
- **Efficiency**ï¼šRAPS æ¨ç†å»¶è¿Ÿç¨³å®šå¢é•¿ï¼Œè¿œä½äºéœ€è¦å…¨å±€ä¼˜åŒ–çš„ GPTSwarm/G-Designerï¼ˆ>2å°æ—¶ for 20 agentsï¼‰ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Networking Perspective is Powerful**ï¼šå°† MAS åè°ƒå»ºæ¨¡ä¸º **Dynamic Ad-Hoc Networking** æ˜¯ä¸€ç§å¯Œæœ‰æˆæ•ˆçš„æ–°èŒƒå¼ï¼Œæ­ç¤ºäº† adaptivity/scalability/robustness çš„æ·±å±‚è”ç³»ã€‚
2. **Intent-Based Collaboration Works**ï¼šåŸºäºè¯­ä¹‰æ„å›¾çš„ **Publish-Subscribe** åè®®èƒ½æœ‰æ•ˆæ‰“ç ´åˆšæ€§æ‹“æ‰‘æŸç¼šï¼Œæ”¯æŒçµæ´»ã€è‡ªç»„ç»‡çš„ä¿¡æ¯æµåŠ¨ã€‚
3. **Decentralized Trust is Essential**ï¼š**Bayesian Reputation** æœºåˆ¶å¯åœ¨æ— ä¸­å¿ƒæƒå¨çš„æƒ…å†µä¸‹éš”ç¦»æ¶æ„è¡Œä¸ºï¼Œæå¤§æå‡ç³»ç»Ÿé²æ£’æ€§ã€‚
4. **Zero-Shot Coordination is Feasible**ï¼šRAPS æ— éœ€ä»»ä½•è®­ç»ƒï¼Œä»…é  inference-time prompting å³å¯å®ç°é«˜æ€§èƒ½åè°ƒï¼Œå…·å¤‡å¼ºæ³›åŒ–èƒ½åŠ›ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–åŸºç¡€æ¨¡å‹èƒ½åŠ›**ï¼šRAPS æ˜¯â€œæ™ºèƒ½æ”¾å¤§å™¨â€ï¼Œä¸èƒ½å¼¥è¡¥ backbone LLM æœ¬èº«çš„çŸ¥è¯†ç¼ºé™·ã€‚
2. **å†·å¯åŠ¨é—®é¢˜ï¼ˆCold Startï¼‰**ï¼šåˆå§‹é˜¶æ®µå› ç¼ºä¹äº¤äº’å†å²ï¼Œå£°èª‰ç³»ç»Ÿå¯èƒ½æš‚æ—¶æ— æ³•è¯†åˆ«æ¶æ„ agentã€‚
3. **è®¡ç®—å¼€é”€æƒè¡¡**ï¼šè™½ç„¶æ•´ä½“é«˜æ•ˆï¼Œä½†è‹¥å¯ç”¨ LLM-based Broker æˆ–é¢‘ç¹æ›´æ–°è®¢é˜…ï¼Œä¼šå¢åŠ  token æ¶ˆè€—ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **Learnable Coordination Protocols**ï¼šç»“åˆ **multi-agent reinforcement learning**ï¼Œåˆ©ç”¨å£°èª‰åˆ†æ•°ä½œä¸ºå†…åœ¨å¥–åŠ±ä¿¡å·ä¼˜åŒ–ç­–ç•¥ã€‚
2. **Reputation Transfer**ï¼šè·¨ä¼šè¯è¿ç§»ä¿¡ä»»å…ˆéªŒï¼Œç¼“è§£å†·å¯åŠ¨é—®é¢˜ã€‚
3. **Congestion Control & Packet Prioritization**ï¼šå€Ÿé‰´ TCP/IP è®¾è®¡ï¼Œç®¡ç†ä¸Šä¸‹æ–‡é•¿åº¦å’Œä¼˜å…ˆçº§è°ƒåº¦ã€‚
4. **Hierarchical Subnetting**ï¼šæ„å»ºå¤§è§„æ¨¡ agent ç¤¾ä¼šçš„åˆ†å±‚ç»„ç»‡ç»“æ„ï¼Œæå‡ç®¡ç†æ•ˆç‡ã€‚

---

> ğŸ’¡ **æ€»ç»“**ï¼šRAPS ä¸ä»…æ˜¯ä¸€ä¸ªæ–°æ–¹æ³•ï¼Œæ›´å¼€å¯äº†ä¸€ä¸ªèåˆ **ç»å…¸ç½‘ç»œç†è®º** ä¸ **ç°ä»£ LLM å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ** çš„å¹¿é˜”ç ”ç©¶ç©ºé—´ï¼Œä¸ºæ„å»ºå¼€æ”¾ã€è‡ªé€‚åº”ã€å¯ä¿¡çš„ agentic society æä¾›äº†åšå®åŸºç¡€ã€‚

</details>

---

### 12. [Epistemic Throughput: Fundamental Limits of Attention-Constrained Inference](https://arxiv.org/abs/2602.09127)

**Authors**: Lei You  
**Category**: cs.LG  
**Published**: 2026-02-11  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.09127v1  

#### Abstract
Recent generative and tool-using AI systems can surface a large volume of candidates at low marginal cost, yet only a small fraction can be checked carefully. This creates a decoder-side bottleneck: downstream decision-makers must form reliable posteriors from many public records under scarce attent...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Epistemic Throughput: Fundamental Limits of Attention-Constrained Inference*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡ç ”ç©¶åœ¨**æ³¨æ„åŠ›å—é™çš„æ¨ç†ï¼ˆAttention-Constrained Inference, ACIï¼‰** åœºæ™¯ä¸‹çš„æ ¹æœ¬ç“¶é¢ˆï¼šç°ä»£ç”Ÿæˆå¼ AI å’Œå·¥å…·è°ƒç”¨ç³»ç»Ÿå¯ä»¥ä½æˆæœ¬åœ°ç”Ÿæˆå¤§é‡å€™é€‰æ–¹æ¡ˆï¼ˆå¦‚æ£€ç´¢åˆ°çš„æ–‡æ¡£ã€è‡ªåŠ¨ç”Ÿæˆçš„å‡è®¾ç­‰ï¼‰ï¼Œä½†ä¸‹æ¸¸å†³ç­–è€…åªèƒ½ä»¥é«˜æˆæœ¬éªŒè¯å…¶ä¸­æå°ä¸€éƒ¨åˆ†ã€‚

è¿™ä¸€ç°è±¡å¹¿æ³›å­˜åœ¨äºç§‘å­¦å‘ç°ã€è½¯ä»¶ä¾›åº”é“¾å®¡è®¡ã€é‡‘èæƒ…æŠ¥åˆ†æç­‰é«˜é£é™©é¢†åŸŸï¼Œå…¶æ ¸å¿ƒæŒ‘æˆ˜æ˜¯ï¼šå¦‚ä½•åœ¨æœ‰é™çš„**éªŒè¯é¢„ç®— $B$** ä¸‹ï¼Œä»å¤§è§„æ¨¡ç­›æŸ¥å‡ºçš„ $K$ ä¸ªå€™é€‰ä¸­é€‰æ‹©æœ€æœ‰ä»·å€¼çš„å­é›†è¿›è¡Œæ·±åº¦éªŒè¯ï¼Œä»è€Œæœ€å¤§åŒ–å¯¹çœŸå®çŠ¶æ€ $O$ çš„**åéªŒä¸ç¡®å®šæ€§å‡å°‘**ï¼ˆå³ä¿¡æ¯å¢ç›Šï¼‰ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
è®ºæ–‡æå‡ºäº†ä¸€ä¸ªä¿¡æ¯è®ºæ¡†æ¶æ¥åˆ»ç”»è¯¥é—®é¢˜ï¼Œå¹¶å¼•å…¥ä»¥ä¸‹æ ¸å¿ƒæ¦‚å¿µä¸ç†è®ºï¼š

- **Epistemic Throughputï¼ˆè®¤çŸ¥ååé‡ï¼‰**ï¼šå®šä¹‰ä¸ºåœ¨å•ä½æ—¶é—´çª—å£å†…ï¼Œé€šè¿‡ç­›æŸ¥ä¸éªŒè¯æ‰€èƒ½å®ç°çš„æœ€å¤§åéªŒä¸ç¡®å®šæ€§å‡å°‘ï¼ˆä»¥ **Bayes log-loss** è¡¡é‡ï¼‰ã€‚è¿™æ˜¯è¡¡é‡â€œå°†å¼±ä¿¡å·è½¬åŒ–ä¸ºå¯é ä¿¡å¿µâ€çš„æ•ˆç‡çš„æ ¸å¿ƒæŒ‡æ ‡ã€‚
  
- **JaKoB Scaling Law**ï¼šæå‡ºå¹¶è¯æ˜äº†ä¸€ä¸ªåŸºæœ¬ç¼©æ”¾å¾‹ï¼Œæè¿°äº†åœ¨ ACI æ¨¡å‹ä¸‹å¯è¾¾åˆ°çš„ä¿¡æ¯å¢ç›Šä¸Šé™ï¼š
  $$
  \text{Gain} \sim I_{\text{ver}} \left( Bp + \sqrt{JKB} \right)
  $$
  å…¶ä¸­ï¼š
  - $B$: éªŒè¯é¢„ç®—ï¼ˆdeep attentionï¼‰
  - $K$: ç­›æŸ¥è§„æ¨¡ï¼ˆbroad attentionï¼‰
  - $p$: æœ‰ä»·å€¼è®°å½•çš„å…ˆéªŒæ¦‚ç‡ï¼ˆprevalenceï¼‰
  - $J = I(T;Z)$: ç­›æŸ¥è´¨é‡ï¼Œå³ç­›æŸ¥ä¿¡å· $Z$ ä¸è®°å½•æ˜¯å¦â€œæœ‰ä»·å€¼â€ï¼ˆ$T=1$ï¼‰ä¹‹é—´çš„äº’ä¿¡æ¯
  - $I_{\text{ver}}$: å•æ¬¡æˆåŠŸéªŒè¯æ‰€è´¡çŒ®çš„ä¿¡æ¯é‡

  è¯¥å…¬å¼æ­ç¤ºäº†ä¸€ä¸ªéçº¿æ€§æ”¾å¤§æ•ˆåº”ï¼šå³ä½¿ç­›æŸ¥è´¨é‡ $J$ å¾ˆä½ï¼Œåªè¦èƒ½å¤§è§„æ¨¡è¿‡é‡‡æ ·ï¼ˆoversamplingï¼Œå³ $K \gg B$ï¼‰ï¼Œä»å¯é€šè¿‡ $\sqrt{JKB}$ é¡¹æ˜¾è‘—æå‡éªŒè¯æ•ˆç‡ã€‚

- **Tail Leverage ç†è®º**ï¼šæŒ‡å‡ºåœ¨ç¨€ç–éªŒè¯åœºæ™¯ï¼ˆ$B \ll K$ï¼‰ä¸­ï¼Œç­›æŸ¥çš„æœ‰æ•ˆæ€§é«˜åº¦ä¾èµ–äºç­›æŸ¥å¾—åˆ†åˆ†å¸ƒçš„**ä¸Šå°¾è¡Œä¸º**ï¼š
  - è‹¥å¾—åˆ†ä¸º**è½»å°¾åˆ†å¸ƒ**ï¼ˆå¦‚ Gaussianï¼‰ï¼Œåˆ™å¢ç›Šä»…éš $\log(K/B)$ å¢é•¿ï¼ˆæ”¶ç›Šé€’å‡ï¼‰
  - è‹¥å¾—åˆ†ä¸º**é‡å°¾åˆ†å¸ƒ**ï¼ˆå¦‚ Paretoï¼‰ï¼Œåˆ™å¢ç›Šå¯è¾¾å¤šé¡¹å¼çº§å¢é•¿ï¼ˆ$\propto (K/B)^{1/\nu}$ï¼‰

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **ç†è®ºå¥ åŸºæ€§**ï¼šä¸åŒäºä»¥å¾€å…³æ³¨ç¼–ç ç«¯çº¦æŸçš„ç»å…¸ä¿¡æ¯è®ºï¼Œæœ¬æ–‡èšç„¦äº**è§£ç ç«¯æ³¨æ„åŠ›ç“¶é¢ˆ**ï¼Œå¡«è¡¥äº†èµ„æºå—é™æ¨ç†ä¸­çš„ç†è®ºç©ºç™½ã€‚
- **æ™®é€‚æ€§å¼º**ï¼šæ¨¡å‹é€‚ç”¨äºå¤šç§ç°å®ç³»ç»Ÿï¼Œå¦‚ RAGã€Tool-using Agentsã€Fact-checking Pipeline ç­‰ï¼Œæä¾›ç»Ÿä¸€çš„åˆ†ææ¡†æ¶ã€‚
- **å¯æ“ä½œæŒ‡å¯¼æ„ä¹‰**ï¼šä¸ä»…ç»™å‡ºæé™è¾¹ç•Œï¼Œè¿˜è¯æ˜ç®€å•çš„ **top-$B$ score-based policy** åœ¨å¼±ç­›æŸ¥æ¡ä»¶ä¸‹å³å¯é€¼è¿‘è¯¥æé™ï¼Œå…·æœ‰å·¥ç¨‹å¯è¡Œæ€§ã€‚
- **å¼ºè°ƒâ€œå…¬å…±åˆ¶å“â€å¤ç”¨ä»·å€¼**ï¼šæå‡ºéªŒè¯è¾“å‡ºåº”ä½œä¸ºå¯å…±äº«çš„ **public artifacts**ï¼Œä»¥æé«˜æ•´ä½“ç³»ç»Ÿçš„ epistemic throughputã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

> æ³¨ï¼šæœ¬æ–‡ä¸º**ç†è®ºæ€§è®ºæ–‡**ï¼Œæœªä½¿ç”¨çœŸå®ä¸–ç•Œæ•°æ®é›†è¿›è¡Œä¼ ç»Ÿæ„ä¹‰ä¸Šçš„â€œå®éªŒâ€ï¼Œè€Œæ˜¯é€šè¿‡**æ•°å­¦å»ºæ¨¡ã€ç†è®ºæ¨å¯¼ä¸ä»¿çœŸéªŒè¯**ç›¸ç»“åˆçš„æ–¹å¼å±•å¼€ã€‚

### æ¨¡å‹è®¾å®š
- **Haystack Regime**ï¼šè€ƒè™‘ä¸€ä¸ªå…¸å‹åœºæ™¯ï¼Œå…¶ä¸­æœ‰ $K$ ä¸ªå¾…æ£€è®°å½•ï¼Œä»…æœ‰å°‘æ•° ($p \ll 1$) æ˜¯ informative çš„ã€‚
- **ä¸¤é˜¶æ®µæµç¨‹**ï¼š
  1. **Screening Stage**ï¼šå¯¹ $K$ æ¡è®°å½•è¿›è¡Œä½æˆæœ¬æ£€æŸ¥ï¼Œå¾—åˆ°ç­›æŸ¥ç»Ÿè®¡é‡ $Z_i$ã€‚
  2. **Verification Stage**ï¼šåŸºäº $Z_i$ æ’åºï¼Œé€‰æ‹© top-$B$ è¿›è¡Œé«˜ä¿çœŸéªŒè¯ï¼Œè·å¾— $(T_i, V_i)$ã€‚
- **Latent State Models**ï¼š
  - Global-Oï¼šæ‰€æœ‰è®°å½•å…±äº«ä¸€ä¸ªå…¨å±€çœŸç›¸ $O$
  - Per-record Claimï¼šæ¯æ¡è®°å½•å¯¹åº”ç‹¬ç«‹å£°æ˜ $O_i$

### è¯„ä¼°æŒ‡æ ‡
- **ä¸»è¦åº¦é‡**ï¼š**Epistemic Throughput** = $H(O) - D(K,B)$ï¼Œå³åˆå§‹ç†µå‡å»è´å¶æ–¯æœ€ä¼˜é¢„æµ‹ä¸‹çš„æœŸæœ› log-lossã€‚
- **ç†è®ºç•Œé™å¯¹æ¯”**ï¼š
  - ä¸Šç•Œï¼ˆConverseï¼‰ï¼šç”± Theorem 6 ç»™å‡º
  - ä¸‹ç•Œï¼ˆAchievabilityï¼‰ï¼šç”± Theorem 10 ä¸­ top-$B$ ç­–ç•¥å®ç°
  - Oracle Boundï¼šç†æƒ³æƒ…å†µä¸‹åªéªŒè¯çœŸæ­£ informative çš„è®°å½•
  - Random Baselineï¼šéšæœºéªŒè¯ $B$ æ¡è®°å½•ï¼Œå¢ç›Šä¸º $Bp$

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **Random Verification** | ä¸ä¾èµ–ç­›æŸ¥ï¼Œç›´æ¥éšæœºé€‰ $B$ æ¡è®°å½•éªŒè¯ï¼Œå¢ç›Šä¸º $Bp$ |
| **Perfect Screening (Oracle)** | å·²çŸ¥å“ªäº›è®°å½•æ˜¯æœ‰ä»·å€¼çš„ï¼Œä»…éªŒè¯è¿™äº›ï¼Œä¸Šé™ä¸º $B$ |
| **Top-$B$ Score Policy** | ä½¿ç”¨ $n(Z)=P(T=1|Z)$ æˆ–å…¶ä»–å¾—åˆ†æ’åºåå– top-$B$ï¼Œæœ¬æ–‡ä¸»æ¨ç­–ç•¥ |

### ä»¿çœŸå®éªŒï¼ˆAppendix A & Fig. 4ï¼‰
- **æ•°æ®ç”Ÿæˆ**ï¼šæ¨¡æ‹Ÿ $K=10^4$ æ¡è®°å½•ï¼Œä½¿ç”¨ logistic æ¨¡å‹ç”Ÿæˆç­›æŸ¥å¾—åˆ†ï¼š
  $$
  \pi_i = \sigma(\text{logit}(p_0) + \epsilon G_i)
  $$
  å…¶ä¸­ $G_i \sim \mathcal{N}(0,1)$ï¼Œ$\epsilon$ æ§åˆ¶ç­›æŸ¥å¼ºåº¦ï¼ˆå¯¹åº”ä¸åŒ AUC æ°´å¹³ï¼‰
- **ç­–ç•¥**ï¼šåº”ç”¨ top-$B$ éªŒè¯ç­–ç•¥
- **è¾“å‡º**ï¼šè®¡ç®—ç»éªŒä¿¡æ¯å¢ç›Š $H(O) - D(K,B)$ å¹¶ä¸ç†è®ºæ›²çº¿æ¯”è¾ƒ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Fig. 4ï¼‰
| ç­›æŸ¥å¼ºåº¦ï¼ˆAUCï¼‰ | æ˜¯å¦æ¥è¿‘ç†è®ºè¾¹ç•Œ | æ”¶ç›Šè¶‹åŠ¿ |
|------------------|--------------------|----------|
| Weak (~0.55)     | âœ… éå¸¸æ¥è¿‘ weak-screening approximation æ›²çº¿ | å¢ç›Šè¾ƒä½ï¼Œç¬¦åˆ $\sqrt{JKB}$ è¶‹åŠ¿ |
| Moderate (~0.70) | âœ… åŒ¹é… benchmark prediction | æ˜æ˜¾ä¼˜äº random baseline |
| Strong (~0.79)   | âš ï¸ é€¼è¿‘ä¸Šé™ä½†ä»ä½äº converse bound | æ”¶ç›ŠæŒç»­ä¸Šå‡ |
| Very Strong (~0.90) | âš ï¸ æ¥è¿‘ finite-pool oracle ä¸Šé™ | å‡ ä¹è¾¾åˆ°æœ€ä¼˜ |

> æ‰€æœ‰è®¾ç½®ä¸‹ï¼Œempirical gain å‡ä½äº converse bound ä¹‹ä¸‹ï¼Œä¸”ä¸ benchmark predictionï¼ˆTheorem 17ï¼‰é«˜åº¦å»åˆã€‚

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ
- **ç›¸æ¯” Random Verification**ï¼š
  - åœ¨ $K=10^4, B=1000, p=0.01$ è®¾ç½®ä¸‹ï¼Œrandom baseline å¢ç›Šçº¦ä¸º 10 bits
  - ä½¿ç”¨ moderate screening åï¼Œå¢ç›Šå¯è¾¾çº¦ 60â€“80 bitsï¼Œæå‡è¾¾ **6â€“8å€**
- **ç›¸æ¯” Oracle Bound**ï¼š
  - Oracle åœ¨æœ€å¼ºç­›æŸ¥ä¸‹å¯è¾¾ ~90 bits
  - å®é™…ç­–ç•¥å¯è¾¾ ~85 bitsï¼Œæ•ˆç‡è¶…è¿‡ 90%

### æ¶ˆèå®éªŒï¼ˆéšå«åˆ†æï¼‰
è™½ç„¶æ²¡æœ‰æ˜¾å¼æ¶ˆèè¡¨ï¼Œä½†è®ºæ–‡é€šè¿‡å¤šä¸ªç»´åº¦è¿›è¡Œäº†æ•æ„Ÿæ€§åˆ†æï¼š
- **æ”¹å˜ $J$ï¼ˆç­›æŸ¥è´¨é‡ï¼‰**ï¼šéšç€ $J$ å¢å¤§ï¼Œ$\sqrt{JKB}$ é¡¹ä¸»å¯¼å¢ç›Šï¼ŒéªŒè¯æ”¶ç›Šå¿«é€Ÿä¸Šå‡
- **æ”¹å˜ $K/B$ï¼ˆè¿‡é‡‡æ ·æ¯”ï¼‰**ï¼š
  - å¯¹ Gaussian å¾—åˆ†ï¼šå¢ç›Šéš $\sqrt{\log(K/B)}$ ç¼“æ…¢å¢é•¿
  - å¯¹ Pareto å¾—åˆ†ï¼šå¢ç›Šéš $(K/B)^{1/\nu}$ å¿«é€Ÿå¢é•¿ â†’ **é‡å°¾è®¾è®¡æ›´ä¼˜**
- **æ”¹å˜ $p$ï¼ˆç¨€æœ‰æ€§ï¼‰**ï¼šè¶Šç¨€æœ‰çš„ä¿¡å·ï¼Œç­›æŸ¥å¸¦æ¥çš„ç›¸å¯¹å¢ç›Šè¶Šå¤§

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å­˜åœ¨éçº¿æ€§æ”¾å¤§æœºåˆ¶**ï¼šå³ä¾¿ç­›æŸ¥è´¨é‡å¾ˆä½ï¼ˆweak screeningï¼‰ï¼Œåªè¦èƒ½å¤§è§„æ¨¡è¿‡é‡‡æ ·ï¼ˆhigh $K/B$ï¼‰ï¼Œå°±èƒ½é€šè¿‡ $\sqrt{JKB}$ é¡¹æ˜¾è‘—å¢å¼ºç¨€ç¼ºéªŒè¯èƒ½åŠ›ã€‚
2. **ç­›æŸ¥çš„ä»·å€¼åœ¨äºâ€œé€‰æ‹©æ€§â€è€Œéâ€œå‡†ç¡®æ€§â€**ï¼šç­›æŸ¥æœ¬èº«ä¸éœ€ç›´æ¥æ­ç¤ºçœŸç›¸ï¼Œåªéœ€èƒ½åŒºåˆ† informative ä¸ non-informative è®°å½•å³å¯åˆ›é€ ä»·å€¼ã€‚
3. **ä¸Šå°¾åˆ†å¸ƒå†³å®šæ æ†æ•ˆåº”**ï¼šåœ¨ $B \ll K$ çš„ haystack åœºæ™¯ä¸­ï¼Œ**heavy-tailed score distributions**ï¼ˆå¦‚ Paretoï¼‰æ¯” light-tailedï¼ˆå¦‚ Gaussianï¼‰æ›´å…·ä¼˜åŠ¿ï¼Œèƒ½å¸¦æ¥**å¤šé¡¹å¼çº§è€Œéå¯¹æ•°çº§**çš„å¢ç›Šã€‚
4. **Top-$B$ ç­–ç•¥æ˜¯é«˜æ•ˆçš„**ï¼šç®€å•åœ°æŒ‰ Bayes score $P(T=1|Z)$ æ’åºå¹¶éªŒè¯ top-$B$ï¼Œå³å¯åœ¨å¼±ç­›æŸ¥æé™ä¸‹è¾¾åˆ°ç†è®ºæœ€ä¼˜ã€‚
5. **Public Artifacts æ˜¯æ”¾å¤§å™¨**ï¼šéªŒè¯ç»“æœä¸€æ—¦å‘å¸ƒä¸ºå…¬å…±åˆ¶å“ï¼Œå¯è¢«å¤š decoder å¤ç”¨ï¼Œæå¤§æå‡æ•´ä½“ epistemic throughputã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **é™æ€ä¸ç‹¬ç«‹åŒåˆ†å¸ƒå‡è®¾**ï¼šå½“å‰æ¨¡å‹ä¸ºå•çª—å£ã€i.i.d. è®¾å®šï¼Œæœªè€ƒè™‘åºåˆ—ä¾èµ–ã€åé¦ˆé—­ç¯æˆ–åŠ¨æ€æ¼”åŒ–ã€‚
- **Log-loss ä¸ºä¸­å¿ƒ**ï¼šè™½é€‚åˆä¿¡æ¯å¢ç›Šåˆ†æï¼Œä½†å®é™…ä»»åŠ¡å¯èƒ½æ›´å…³å¿ƒ decision regretã€FDR æˆ– calibrationã€‚
- **éªŒè¯æˆæœ¬å‡è´¨åŒ–**ï¼šå‡è®¾æ‰€æœ‰éªŒè¯æˆæœ¬ç›¸åŒï¼Œè€Œç°å®ä¸­å¯èƒ½å­˜åœ¨å¤šå±‚æ¬¡éªŒè¯è·¯å¾„ï¼ˆcheap check vs. expert auditï¼‰ã€‚
- **å¿½ç•¥å¯¹æŠ—æ€§æ“çºµ**ï¼šæœªå»ºæ¨¡æ¶æ„ç”Ÿäº§è€…æ•…æ„åˆ¶é€ é«˜åˆ†å‡è®°å½•çš„è¡Œä¸ºã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³ Sequential Setting**ï¼šç»“åˆ active learningã€bandits æ¡†æ¶ï¼Œç ”ç©¶é•¿æœŸä¿¡æ¯è·å–ç­–ç•¥ã€‚
2. **å¤šæ ·åŒ–ç›®æ ‡å‡½æ•°**ï¼šæ¢ç´¢åœ¨ false discovery rate æ§åˆ¶ã€abstention-aware calibration ç­‰ç›®æ ‡ä¸‹çš„ throughput æé™ã€‚
3. **å¼‚æ„éªŒè¯æˆæœ¬å»ºæ¨¡**ï¼šå¼•å…¥ multi-level verification ladderï¼Œæ”¯æŒ cost-aware selectionã€‚
4. **è®¾è®¡ Heavy-tailed Scoring Functions**ï¼šç ”ç©¶å¦‚ä½•æ„å»ºèƒ½äº§ç”Ÿ exploitable extremes çš„ ranking æœºåˆ¶ï¼ˆå¦‚æç«¯å€¼ç½‘ç»œã€å¼‚å¸¸æ£€æµ‹é›†æˆï¼‰ã€‚
5. **æ¿€åŠ±æœºåˆ¶ä¸å®‰å…¨è®¾è®¡**ï¼šç ”ç©¶å¦‚ä½•é€šè¿‡æœºåˆ¶è®¾è®¡é¼“åŠ±ç”Ÿäº§å¯éªŒè¯å†…å®¹ï¼Œé˜²æ­¢ adversarial spoofingã€‚
6. **ç«¯åˆ°ç«¯ç³»ç»Ÿä¼˜åŒ–**ï¼šå°† epistemic communication ä½œä¸ºè®¾è®¡èŒƒå¼ï¼Œè”åˆä¼˜åŒ– generationã€retrievalã€scoring ä¸ verification æ¨¡å—ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> åœ¨ç”Ÿæˆè¿‡å‰©ã€éªŒè¯ç¨€ç¼ºçš„æ—¶ä»£ï¼Œ**epistemic throughput** æˆä¸ºè¡¡é‡ç³»ç»ŸçœŸç†å‘ç°æ•ˆç‡çš„æ–°èŒƒå¼ï¼›é€šè¿‡ **JaKoB scaling law** å’Œ **tail leverage ç†è®º**ï¼Œæœ¬æ–‡æ­ç¤ºäº†å¦‚ä½•åˆ©ç”¨å»‰ä»·ç­›æŸ¥éçº¿æ€§æ”¾å¤§æ˜‚è´µéªŒè¯çš„èƒ½åŠ›â€”â€”å…³é”®æ˜¯**è¿‡é‡‡æ · + é‡å°¾å¾—åˆ† + å…¬å…±åˆ¶å“å¤ç”¨**ã€‚

</details>

---

### 13. [PTS-SNN: A Prompt-Tuned Temporal Shift Spiking Neural Networks for Efficient Speech Emotion Recognition](https://arxiv.org/abs/2602.08240)

**Authors**: Xun Su, Huamin Wang, Qi Zhang  
**Category**: cs.AI  
**Published**: 2026-02-11  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.08240v1  

#### Abstract
Speech Emotion Recognition (SER) is widely deployed in Human-Computer Interaction, yet the high computational cost of conventional models hinders their implementation on resource-constrained edge devices. Spiking Neural Networks (SNNs) offer an energy-efficient alternative due to their event-driven ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠPTS-SNN: A Prompt-Tuned Temporal Shift Spiking Neural Networks for Efficient Speech Emotion Recognitionã€‹æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»ŸåŸºäº **Artificial Neural Networks (ANNs)** çš„ **Speech Emotion Recognition (SER)** æ¨¡å‹è™½ç„¶æ€§èƒ½ä¼˜è¶Šï¼Œä½†è®¡ç®—å¼€é”€å¤§ã€èƒ½è€—é«˜ï¼Œéš¾ä»¥éƒ¨ç½²åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šã€‚è€Œ **Spiking Neural Networks (SNNs)** è™½ç„¶å…·å¤‡äº‹ä»¶é©±åŠ¨ã€ä½åŠŸè€—çš„ä¼˜åŠ¿ï¼Œä½†åœ¨ç›´æ¥å¤„ç†æ¥è‡ª **Self-Supervised Learning (SSL)** æ¨¡å‹ï¼ˆå¦‚ emotion2vecï¼‰çš„è¿ç»­é«˜åŠ¨æ€èŒƒå›´ç‰¹å¾æ—¶ï¼Œå­˜åœ¨ä¸¥é‡çš„**åˆ†å¸ƒä¸åŒ¹é…ï¼ˆdistribution mismatchï¼‰**é—®é¢˜ã€‚

å…·ä½“è¡¨ç°ä¸ºï¼š
- é«˜æ–¹å·®è¾“å…¥å¯¼è‡´ **LIF/PLIF ç¥ç»å…ƒ**é™·å…¥â€œåŠŸèƒ½é™é»˜â€ï¼ˆfunctional silenceï¼‰æˆ–â€œé¥±å’Œâ€ï¼ˆsaturationï¼‰ï¼Œç ´åäº†ç¨€ç–æ—¶é—´ç¼–ç èƒ½åŠ›ï¼Œä»è€Œä¸¥é‡é™ä½è¯†åˆ«æ€§èƒ½ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **PTS-SNN**ï¼ˆPrompt-Tuned Spiking Neural Networkï¼‰ï¼Œä¸€ç§å‚æ•°é«˜æ•ˆçš„ç¥ç»å½¢æ€é€‚é…æ¡†æ¶ï¼Œå®ç° SSL ç‰¹å¾ä¸ SNN åŠ¨æ€çš„é«˜æ•ˆå¯¹é½ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰**Temporal Shift Spiking Encoder**
- å¼•å…¥æ— å‚æ•°çš„ **Temporal Shift** æ“ä½œï¼Œåœ¨æ®‹å·® spiking æ¨¡å—ä¸­æ•è·å±€éƒ¨æ—¶é—´ä¾èµ–ã€‚
- é€šè¿‡é€šé“ç§»ä½å®ç°å¸§é—´ä¿¡æ¯äº¤æ¢ï¼Œæ— éœ€é¢å¤– FLOPsï¼Œç¨³å®šåŸå§‹ç‰¹å¾æµçš„é«˜é¢‘æ³¢åŠ¨ï¼Œæ„å»ºé²æ£’è¾“å…¥åŸºç¡€ã€‚

#### ï¼ˆ2ï¼‰**Context-Aware Membrane Potential Calibration**
- è®¾è®¡åŸºäº **Spiking Sparse Linear Attention (SSLA)** çš„æç¤ºæœºåˆ¶ï¼Œå°†å¯å­¦ä¹ çš„ **soft prompts** ä½œä¸ºä¸Šä¸‹æ–‡æŸ¥è¯¢ã€‚
- åˆ©ç”¨ **PLIF ç¥ç»å…ƒ**å¯¹è¾“å…¥è¿›è¡ŒäºŒå€¼åŒ–è¿‡æ»¤ï¼Œç”Ÿæˆç¨€ç– spike mapï¼Œå†é€šè¿‡çº¿æ€§æ³¨æ„åŠ›èšåˆå…¨å±€è¯­ä¹‰ä¸Šä¸‹æ–‡åˆ° prompts ä¸­ã€‚
- æå‡º **Homeostatic Bias Generator**ï¼Œå°† prompts æ˜ å°„ä¸ºåŠ¨æ€ç”µå‹åç½® $ V_{\text{bias}} $ï¼Œä¸»åŠ¨è°ƒèŠ‚ PLIF ç¥ç»å…ƒçš„è†œç”µä½åŸºçº¿ã€‚

> ğŸ”¬ **ç”Ÿç‰©å¯å‘æœºåˆ¶**ï¼šè¯¥ç­–ç•¥æ¨¡æ‹Ÿç”Ÿç‰©ä¸­çš„ç¨³æ€è°ƒèŠ‚ï¼ˆhomeostatic regulationï¼‰ï¼Œä½¿è¾“å…¥åˆ†å¸ƒä¸­å¿ƒå¯¹é½åˆ°ç¥ç»å…ƒæ•æ„Ÿå“åº”åŒºé—´ï¼ˆaround $ V_{th} $ï¼‰ï¼Œé¿å…é™é»˜æˆ–é¥±å’Œã€‚

#### ï¼ˆ3ï¼‰**å‚æ•°é«˜æ•ˆæ€§è®¾è®¡**
- å†»ç»“ä¸Šæ¸¸ SSL ä¸»å¹²ï¼ˆå¦‚ emotion2vecï¼‰ï¼Œä»…è®­ç»ƒè½»é‡çº§é€‚é…å™¨æ¨¡å—ï¼ˆadapterï¼‰ï¼Œæ€»å¯è®­ç»ƒå‚æ•°ä»… **1.19M**ï¼Œè¿œä½äºå…¨å¾®è°ƒæ–¹æ¡ˆã€‚

### âš–ï¸ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ€§èƒ½** | åœ¨ IEMOCAP ä¸Šè¾¾åˆ° **73.34% WA**ï¼Œä¼˜äºå¤šæ•° ANN åŸºçº¿ |
| **èƒ½æ•ˆ** | å•æ ·æœ¬æ¨ç†èƒ½è€—ä»… **0.35 mJ**ï¼Œæ¯” ANN ä½ 2â€“3 ä¸ªæ•°é‡çº§ |
| **å‚æ•°æ•ˆç‡** | å‚æ•°é‡ä»…ä¸º ShiftFormer çš„ ~12.5%ï¼Œé€‚åˆè¾¹ç¼˜éƒ¨ç½² |
| **å…¼å®¹æ€§** | æˆåŠŸæ¡¥æ¥è¿ç»­ SSL è¡¨ç¤ºä¸ç¦»æ•£ spiking åŠ¨åŠ›å­¦ï¼Œè§£å†³æ ¹æœ¬æ€§åˆ†å¸ƒé¸¿æ²Ÿ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
åœ¨äº”ä¸ªå¤šè¯­è¨€ SER æ•°æ®é›†ä¸Šè¿›è¡Œå…¨é¢è¯„ä¼°ï¼š

| æ•°æ®é›† | è¯­è¨€ | æƒ…æ„Ÿç±»åˆ«æ•° | æ ·æœ¬æ•° | äº¤å‰éªŒè¯ç­–ç•¥ |
|-------|------|------------|--------|----------------|
| **IEMOCAP** | è‹±è¯­ | 4 | 5,531 | Leave-one-session-out, 5-fold |
| **CASIA** | ä¸­æ–‡ | 4 | 1,200 | Random leave-one-speaker-out, 4-fold |
| **EMODB** | å¾·è¯­ | 7 | 535 | Random leave-one-out, 10-fold |
| **EMOVO** | æ„å¤§åˆ©è¯­ | 6 | 588 | åŒä¸Š |
| **URDU** | ä¹Œå°”éƒ½è¯­ | 4 | 400 | åŒä¸Š |

> æ‰€æœ‰å®éªŒå‡é‡‡ç”¨å†»ç»“çš„ **emotion2vec** ä½œä¸ºç‰¹å¾æå–å™¨ã€‚

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
- **Weighted Accuracy (WA)**ï¼šæ€»ä½“å‡†ç¡®ç‡ï¼Œåæ˜ å…¨å±€æ€§èƒ½
- **Unweighted Accuracy (UA)**ï¼šå„ç±»åˆ«å¹³å‡å‡†ç¡®ç‡ï¼Œåº”å¯¹ç±»åˆ«ä¸å¹³è¡¡
- **Trainable Parameters (M)**ï¼šæ¨¡å‹å¤æ‚åº¦
- **Inference Energy (mJ/sample)**ï¼šåŸºäº 45nm CMOS å·¥è‰ºä¼°ç®—ï¼ŒåŒºåˆ† MACï¼ˆANNï¼‰ä¸ ACï¼ˆSNNï¼‰æ“ä½œèƒ½è€—

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿æ¨¡å‹ | ç±»å‹ | æ ¸å¿ƒæœºåˆ¶ |
|---------|------|----------|
| **Vanilla SNN** | SNN | ç›´æ¥å°† SSL ç‰¹å¾è¾“å…¥ SNNï¼Œæ— é€‚é… |
| **emotion2vec + ANN Fine-tuning** | ANN | å…¨å¾®è°ƒä¸‹æ¸¸åˆ†ç±»å¤´ |
| **MSTR** | ANN | Multi-Scale Transformer |
| **ShiftFormer** | ANN | åŸºäºç¨€ç– shift çš„é«˜æ•ˆæ¶æ„ |
| **ENT**, **DST**, **Co-attention** | ANN | æ³¨æ„åŠ›æœºåˆ¶å˜ä½“ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ IEMOCAP ä¸ºä¾‹ï¼‰

| Model | WA (%) | UA (%) | Params (M) | Energy (mJ) |
|-------|--------|--------|------------|-------------|
| **emotion2vec (fine-tuned)** | 71.79 | â€” | >70M (estimated) | â€” |
| **Vanilla SNN** | 41.78 | â€” | ~1.19M | 0.35 |
| **MSTR** | 70.60 | 71.60 | 30.03 | 51.06 |
| **ShiftFormer** | 72.10 | 72.70 | 9.50 | 16.20 |
| **ENT** | 72.43 | 73.88 | 8.55 | 6.35 |
| **PTS-SNN (Ours)** | **73.34** | **73.72** | **1.19** | **0.35** |

âœ… **ç»“è®º**ï¼š
- PTS-SNN åœ¨ **WA å’Œ UA ä¸Šå‡ä¼˜äºæ‰€æœ‰ ANN åŸºçº¿**ï¼ŒåŒæ—¶å‚æ•°é‡æœ€å°ã€èƒ½è€—æœ€ä½ã€‚
- èƒ½è€—ä»…ä¸º ShiftFormer çš„ **~2.2%**ï¼ŒMSTR çš„ **~0.7%**ï¼Œå±•ç°å‡ºæå¼ºçš„è¾¹ç¼˜é€‚ç”¨æ€§ã€‚

### ğŸŒ è·¨è¯­è¨€æ³›åŒ–èƒ½åŠ›ï¼ˆWA %ï¼‰

| Dataset | emotion2vec | PTS-SNN | Î”â†‘ |
|--------|-------------|---------|----|
| **CASIA** (ä¸­æ–‡) | 69.20 | 72.50 | +3.30 |
| **EMODB** (å¾·è¯­) | 84.34 | 87.49 | +3.15 |
| **EMOVO** (æ„å¤§åˆ©è¯­) | 61.21 | 61.94 | +0.73 |
| **URDU** (ä¹Œå°”éƒ½è¯­) | 81.50 | 84.25 | +2.75 |

â¡ï¸ è¡¨æ˜æ‰€å­¦ prompts æ•æ‰çš„æ˜¯**è¯­è¨€æ— å…³çš„æƒ…æ„ŸéŸµå¾‹æ¨¡å¼**ï¼Œè€Œéè¯­è¨€å†…å®¹æœ¬èº«ï¼Œå…·æœ‰è‰¯å¥½çš„è·¨è¯­è¨€è¿ç§»èƒ½åŠ›ã€‚

### ğŸ” æ¶ˆèå®éªŒï¼ˆAblation Study on IEMOCAPï¼‰

| Configuration | WA (%) | UA (%) |
|---------------|--------|--------|
| **Full Model (PTS-SNN)** | **73.34** | **73.72** |
| w/o Prompt Tuning | 71.76 | 71.90 |
| w/o Attention Module | 68.35 | 69.10 |
| Only Temporal Shift | 61.27 | 62.05 |

ğŸ“Œ å‘ç°ï¼š
- ç§»é™¤ **prompt tuning** å¯¼è‡´æ€§èƒ½ä¸‹é™ 1.58%ï¼Œè¯´æ˜å…¶æ¯”ç›´æ¥å¾®è°ƒæ›´æœ‰æ•ˆã€‚
- ç§»é™¤ **attention æ¨¡å—** æ€§èƒ½éª¤é™ 5%ï¼Œè¡¨æ˜å…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡è‡³å…³é‡è¦ã€‚
- ä»…æœ‰ temporal shift æ—¶æ€§èƒ½æœ€å·®ï¼Œè¯´æ˜å±€éƒ¨å»ºæ¨¡ä¸è¶³ä»¥æ”¯æ’‘é«˜æ€§èƒ½ SERã€‚

### ğŸ“‰ è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æ
- **Prompt Length ($ L_p $)**ï¼šæœ€ä¼˜é•¿åº¦ä¸º 5ï¼›è¶…è¿‡åæ€§èƒ½ä¸‹é™ï¼Œè¡¨æ˜å†—ä½™ prompts æœ‰å®³ã€‚
- **Bias Scaling Factor ($ \kappa $)**ï¼šæœ€ä½³å€¼ä¸º 0.5ï¼›è¿‡é«˜å¼•å…¥å™ªå£°ï¼Œè¿‡ä½æ¿€æ´»ä¸è¶³ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **åˆ†å¸ƒä¸åŒ¹é…æ˜¯é˜»ç¢ SNN åº”ç”¨äº SSL ç‰¹å¾çš„æ ¹æœ¬éšœç¢**ï¼Œç›´æ¥è½¬æ¢ä¼šå¯¼è‡´æ€§èƒ½å´©æºƒï¼ˆä» 71.79% â†’ 41.78%ï¼‰ã€‚
2. **PTS-SNN æˆåŠŸå®ç°äº†è¿ç»­è¡¨ç¤ºä¸ç¦»æ•£ spiking åŠ¨åŠ›å­¦ä¹‹é—´çš„é«˜æ•ˆå¯¹é½**ï¼Œé€šè¿‡ prompt é©±åŠ¨çš„è†œç”µä½æ ¡å‡†æœºåˆ¶ï¼Œæ˜¾è‘—æå‡ SNN çš„è¡¨è¾¾èƒ½åŠ›ã€‚
3. æ‰€ææ–¹æ³•åœ¨ä¿æŒ **è¶…ä½å‚æ•°é‡ï¼ˆ1.19Mï¼‰å’Œèƒ½è€—ï¼ˆ0.35 mJï¼‰** çš„å‰æä¸‹ï¼Œå®ç°äº†ä¸å…ˆè¿› ANNs ç›¸å½“ç”šè‡³æ›´ä¼˜çš„æ€§èƒ½ã€‚
4. æ¨¡å‹å…·å¤‡è‰¯å¥½**è·¨è¯­è¨€æ³›åŒ–èƒ½åŠ›**ï¼ŒéªŒè¯äº†å…¶æ•æ‰æ·±å±‚æƒ…æ„Ÿçº¿ç´¢çš„èƒ½åŠ›ã€‚

### âš ï¸ å±€é™æ€§
- å½“å‰æ¡†æ¶ä»…ä½¿ç”¨**å•æ¨¡æ€éŸ³é¢‘ä¿¡å·**ï¼Œæœªèåˆæ–‡æœ¬æˆ–é¢éƒ¨è¡¨æƒ…ç­‰äº’è¡¥ä¿¡æ¯ã€‚
- æ‰€æœ‰å®éªŒåŸºäºç¦»çº¿æ¨ç†è®¾å®šï¼Œå°šæœªåœ¨çœŸå® neuromorphic hardwareï¼ˆå¦‚ Loihiã€Speckï¼‰ä¸Šéƒ¨ç½²éªŒè¯å®æ—¶æ€§ã€‚
- å¯¹æç«¯å™ªå£°ç¯å¢ƒä¸‹çš„é²æ£’æ€§æœªå……åˆ†æµ‹è¯•ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- å°† PTS æœºåˆ¶æ‰©å±•è‡³ **Multimodal Spiking Architectures**ï¼Œèåˆ audio-visual-textual ä¿¡å·ã€‚
- æ¢ç´¢åœ¨ç±»è„‘èŠ¯ç‰‡ä¸Šçš„å®é™…éƒ¨ç½²ä¸èƒ½æ•ˆä¼˜åŒ–ã€‚
- ç ”ç©¶æ›´å¤æ‚çš„ homeostatic regulation ç­–ç•¥ï¼Œå¦‚è‡ªé€‚åº”é˜ˆå€¼ã€çªè§¦å¯å¡‘æ€§ç»“åˆã€‚

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> PTS-SNN é€šè¿‡ç”Ÿç‰©å¯å‘å¼çš„ **prompt-to-voltage** æ˜ å°„æœºåˆ¶ï¼Œé¦–æ¬¡å®ç°äº† SSL ä¸ SNN çš„é«˜æ•ˆååŒï¼Œåœ¨å‡ ä¹ä¸å¢åŠ å‚æ•°çš„å‰æä¸‹ï¼Œè¾¾æˆé«˜æ€§èƒ½ã€è¶…ä½åŠŸè€—çš„è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ï¼Œä¸ºè¾¹ç¼˜æ™ºèƒ½æä¾›äº†æå…·å‰æ™¯çš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 14. [Do MLLMs Really See It: Reinforcing Visual Attention in Multimodal LLMs](https://arxiv.org/abs/2602.08241)

**Authors**: Siqu Ou, Tianrui Wan, Zhiyuan Zhao, Junyu Gao, Xuelong Li  
**Category**: cs.AI  
**Published**: 2026-02-11  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.08241v1  

#### Abstract
While chain-of-thought (CoT) reasoning has substantially improved multimodal large language models (MLLMs) on complex reasoning tasks, existing approaches largely rely on long textual reasoning trajectories and provide limited mechanisms for learning stable visual attention policies. Our analysis sh...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Do MLLMs Really See It: Reinforcing Visual Attention in Multimodal LLMs*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å½“å‰çš„ **Multimodal Large Language Models (MLLMs)** åœ¨å¤æ‚è§†è§‰æ¨ç†ä»»åŠ¡ä¸­è™½ç„¶å¹¿æ³›é‡‡ç”¨ **Chain-of-Thought (CoT)** æ¨ç†æœºåˆ¶ï¼Œä½†å­˜åœ¨ä¸€ä¸ªå…³é”®ç¼ºé™·ï¼š**è§†è§‰æ³¨æ„åŠ›ä¸ç¨³å®šä¸”éš¾ä»¥çº æ­£æ—©æœŸé”™è¯¯**ã€‚

- åˆ†æè¡¨æ˜ï¼ŒMLLMs åœ¨æ¨ç†åˆæœŸè‹¥å°†æ³¨æ„åŠ›æ”¾åœ¨é”™è¯¯çš„å›¾åƒåŒºåŸŸï¼Œè¿™ç§ **è§†è§‰é”™ä½ï¼ˆvisual misalignmentï¼‰** å¾ˆå°‘åœ¨åç»­æ¨ç†ä¸­è¢«ä¿®æ­£ã€‚
- è¿™å¯¼è‡´é”™è¯¯æŒç»­ä¼ æ’­ï¼Œæœ€ç»ˆé€ æˆç³»ç»Ÿæ€§æ¨ç†å¤±è´¥ã€‚
- æ ¹æœ¬åŸå› åœ¨äºè®­ç»ƒè¿‡ç¨‹ä¸­ç¼ºä¹å¯¹ **è§†è§‰æ³¨æ„åŠ›è¡Œä¸ºçš„æœ‰æ•ˆä¿¡ç”¨åˆ†é…ï¼ˆcredit assignmentï¼‰** â€”â€”å³æ¨¡å‹æ— æ³•å­¦ä¹ â€œä½•æ—¶ã€ä½•å¤„åº”å…³æ³¨å›¾åƒâ€ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æå‡º **SAYO**ï¼ˆä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„è§†è§‰æ¨ç†æ¨¡å‹ï¼‰ï¼Œå¹¶å¼•å…¥ **Entropy-Based Target Attention Reward**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- åœ¨ **Reinforcement Learning (RL)** æ¡†æ¶ä¸‹ï¼Œè®¾è®¡ä¸€ç§ **åŒºåŸŸçº§è§†è§‰æ³¨æ„åŠ›å¥–åŠ±æœºåˆ¶**ã€‚
- è¯¥å¥–åŠ±åŸºäºæ¨¡å‹ç”Ÿæˆ token æ—¶å¯¹ç›®æ ‡å›¾åƒåŒºåŸŸçš„æ³¨æ„åŠ›æƒé‡ï¼Œ**æ˜¾å¼åœ°å°†ä¼˜åŒ–ä¿¡å·ä¸è§†è§‰é”šå®šçš„æ¨ç†æ­¥éª¤å¯¹é½**ã€‚
- ç‰¹åˆ«åœ°ï¼Œå¥–åŠ±ä»…ä½œç”¨äº **é«˜ç†µ token**ï¼ˆå³æ¨¡å‹ä¸ç¡®å®šæ€§é«˜çš„å†³ç­–ç‚¹ï¼‰ï¼Œè¿«ä½¿æ¨¡å‹åœ¨æ­¤ç±»å…³é”®èŠ‚ç‚¹ä¸Šå¿…é¡»å‚è€ƒè§†è§‰è¯æ®è¿›è¡Œâ€œéªŒè¯â€ï¼ˆLook-to-Verifyï¼‰ï¼Œä»è€ŒæŠ‘åˆ¶â€œç›²ç›®æ¨ç†â€ï¼ˆhallucinationï¼‰ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| å¯¹æ¯”ç»´åº¦ | ç°æœ‰æ–¹æ³• | SAYO |
|--------|--------|------|
| **æ³¨æ„åŠ›å­¦ä¹ æœºåˆ¶** | ä¾èµ–å¯å‘å¼æç¤ºå·¥ç¨‹ï¼ˆå¦‚æ¡†é€‰åŒºåŸŸï¼‰ã€åå¤„ç†åæ€æœºåˆ¶ | é€šè¿‡ RL å¥–åŠ±ç›´æ¥ä¼˜åŒ–æ³¨æ„åŠ›ç­–ç•¥ï¼Œå®ç°ç«¯åˆ°ç«¯å­¦ä¹  |
| **æ˜¯å¦éœ€è¦å¤–éƒ¨å¹²é¢„** | éœ€è¦äººå·¥è®¾è®¡è§†è§‰æç¤ºæˆ–è¿­ä»£åæ€ | æ¨ç†é˜¶æ®µæ— éœ€é¢å¤–æç¤ºæˆ–æµç¨‹ |
| **æ³›åŒ–èƒ½åŠ›** | å¤šä¸ºä»»åŠ¡ç‰¹å®šè®¾è®¡ï¼Œè¿ç§»æ€§å·® | åœ¨æ•°å­¦ã€å›¾è¡¨ã€é€šç”¨è§†è§‰æ¨ç†ç­‰å¤šé¢†åŸŸå‡æå‡ |
| **è®­ç»ƒæ•ˆç‡** | é€šå¸¸ä¾èµ–é•¿æ–‡æœ¬æ¨ç†è½¨è¿¹ | èšç„¦é«˜ä¿¡æ¯é‡ tokenï¼Œè®­ç»ƒæ›´é«˜æ•ˆç¨³å®š |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **é€šç”¨è§†è§‰æ¨ç†**ï¼š
  - `GQA`ï¼šå¤æ‚åœºæ™¯ä¸‹çš„ç»„åˆé—®ç­”
  - `M3CoT`, `V*`, `MMStar`, `MME-RealWorld`ï¼šæ¶µç›–å¤šæ­¥æ¨ç†ã€ç°å®é«˜åˆ†è¾¨ç‡å›¾åƒç†è§£
- **æ•°å­¦è§†è§‰æ¨ç†**ï¼š
  - `We-Math`, `MathVision`ï¼šç»“åˆå‡ ä½•å›¾ã€å…¬å¼ä¸æ–‡æœ¬çš„æ•°å­¦é¢˜
- **ç»“æ„åŒ–å›¾åƒç†è§£**ï¼š
  - `ChartQA`, `AI2D`, `CharXiv`ï¼šå›¾è¡¨ã€ç§‘å­¦æ’å›¾çš„ç†è§£ä¸é—®ç­”
- **è®­ç»ƒæ•°æ®æ¥æº**ï¼š
  - `GQA` + `ReFocus_Data`ï¼ˆå…±çº¦ 20k æ ·æœ¬ï¼‰ï¼Œç”¨äº RL è®­ç»ƒ

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

- **åŸºç¡€æ¨¡å‹**ï¼š
  - `Qwen3-VL-8B`, `InternVL3.5-8B`
- **è®­ç»ƒæ¡†æ¶**ï¼š
  - ä½¿ç”¨ **Group Relative Policy Optimization (GRPO)** è¿›è¡Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒ
  - è®­ç»ƒå‘¨æœŸï¼š4 epochsï¼Œ6 Ã— NVIDIA H200 GPU
  - å¥–åŠ±æ„æˆï¼š`region attention reward` + `format reward`
- **è¯„ä¼°æ–¹å¼**ï¼š
  - æ‰€æœ‰æ¨¡å‹è¾“å‡ºéœ€éµå¾ª `<think>...</think>` å’Œ `\boxed{}` æ ¼å¼
  - ä¸»è¦æŒ‡æ ‡ï¼š**å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰**
  - è¾…åŠ©åˆ†ææŒ‡æ ‡ï¼š
    - **Target Attention Score (TAS)**ï¼šè¡¡é‡æ¨¡å‹å¯¹ç›®æ ‡åŒºåŸŸçš„å¹³å‡æ³¨æ„åŠ›å¼ºåº¦
    - **Attention Advantage Score (Ra)**ï¼šå½’ä¸€åŒ–åçš„æ³¨æ„åŠ›ä¼˜åŠ¿åº¦é‡

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

- **é—­æºæ¨¡å‹ï¼ˆClosed-Sourceï¼‰**ï¼š
  - `GPT-4o`, `Gemini 2.5 Pro`
- **å¼€æºé€šç”¨ MLLMs**ï¼š
  - `Qwen3-VL`, `InternVL3.5`, `Kimi-VL-16B`
- **å¼€æºæ¨ç†ä¸“ç”¨ MLLMs**ï¼š
  - `ViGoRL`, `OpenVLThinker-7B`, `Semantic-back-7B`, `NoisyRollout-7B`, `R1-Onevision-7B`

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 1ï¼‰**

| æ¨¡å‹ | Avg Score |
|------|---------|
| **SAYO-Qwen-8B** | **64.03** âœ…ï¼ˆå¼€æºæœ€ä½³ï¼‰ |
| SAYO-Qwen-4B | 62.17 |
| Qwen3-VL-8B | 59.64 |
| OpenVLThinker-7B | 59.79 |
| GPT-4o | æœªå®Œæ•´æŠ¥å‘Šï¼Œéƒ¨åˆ†ä»»åŠ¡ä½äº SAYO |

> **äº®ç‚¹è¡¨ç°**ï¼š
> - åœ¨ `MMStar` ä¸Šï¼Œ**SAYO-Qwen-8B è¶…è¶Š GPT-4o å’Œ Kimi-VL-16B**
> - åœ¨ `We-Math` å’Œ `MathVision` ä¸Šæ˜¾è‘—é¢†å…ˆï¼Œå°½ç®¡**æœªåœ¨æ•°å­¦æ•°æ®ä¸Šè®­ç»ƒ**
> - åœ¨ `ChartQA`ã€`AI2D` ç­‰ç»“æ„åŒ–ä»»åŠ¡ä¸Šä¹Ÿå…¨é¢ä¼˜äºåŸºçº¿

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- **SAYO-Qwen-8B** åœ¨å‡ ä¹æ‰€æœ‰ benchmark ä¸Šéƒ½ä¼˜äºåŒè§„æ¨¡ç”šè‡³æ›´å¤§å‚æ•°çš„å¼€æºæ¨¡å‹ã€‚
- å³ä½¿æ˜¯è¾ƒå°çš„ `SAYO-Qwen-4B`ï¼Œä¹Ÿè¶…è¿‡äº†åŸå§‹ `8B` æ¨¡å‹çš„è¡¨ç°ã€‚
- åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¾¾åˆ°æˆ–è¶…è¿‡é—­æºæ¨¡å‹æ°´å¹³ï¼Œè¯æ˜äº†å…¶å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚

### **æ¶ˆèå®éªŒç»“æœï¼ˆTable 2 & Table 3ï¼‰**

#### **ä¸åŒå¥–åŠ±ç»„åˆçš„å½±å“ï¼ˆTable 2ï¼‰**

| è®¾ç½® | Avg æå‡ï¼ˆvs Baseï¼‰ |
|------|------------------|
| Accuracy-only Reward | +1.28 |
| Attention-only Reward | **+4.32** |
| Combined Reward | **+4.63** |

> ç»“è®ºï¼š**è§†è§‰æ³¨æ„åŠ›å¥–åŠ±æ¯”ç­”æ¡ˆå‡†ç¡®æ€§å¥–åŠ±æ›´èƒ½é©±åŠ¨æ€§èƒ½æå‡**ï¼Œè¯´æ˜å½“å‰ç“¶é¢ˆåœ¨äºâ€œçœ‹è§â€ï¼Œè€Œéâ€œæ¨ç†â€ã€‚

#### **Token é€‰æ‹©ç­–ç•¥çš„å½±å“ï¼ˆTable 3ï¼‰**

| ç­–ç•¥ | æ€§èƒ½æå‡ |
|------|--------|
| Reward on **all tokens** | +0.87 ~ +2.23 |
| Reward on **top 30% high-entropy tokens** | **+3.21 ~ +6.54** âœ… |

> ç»“è®ºï¼š**ä»…å¯¹é«˜ç†µ token æ–½åŠ æ³¨æ„åŠ›å¥–åŠ±æ•ˆæœæœ€å¥½**ï¼Œé¿å…ä½ä¿¡æ¯ token å¼•å…¥å™ªå£°ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§ä¸æ•ˆç‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **è§†è§‰æ³¨æ„åŠ›é”™ä½æ˜¯ MLLMs æ¨ç†å¤±è´¥çš„ä¸»å› **  
   - æ—©æœŸæ³¨æ„åŠ›é”™è¯¯æå°‘è¢«çº æ­£ï¼Œå½¢æˆâ€œé”™è¯¯é“¾â€ã€‚
   - å­˜åœ¨å¼ºæ­£ç›¸å…³æ€§ï¼š**Target Attention Score (TAS) â†‘ â†’ å‡†ç¡®ç‡ â†‘**

2. âœ… **ç°æœ‰ RL æ–¹æ³•æœªèƒ½æœ‰æ•ˆä¼˜åŒ–è§†è§‰æ³¨æ„åŠ›**  
   - å½“å‰ RL ä¸»è¦æ”¹è¿›æ–‡æœ¬æ¨ç†è·¯å¾„ï¼Œä½†å¯¹è§†è§‰èšç„¦å¸®åŠ©æœ‰é™ã€‚

3. âœ… **SAYO æˆåŠŸå®ç°äº†â€œä¸»åŠ¨çœ‹â€æœºåˆ¶**  
   - æ¨¡å‹å­¦ä¼šåœ¨ä¸ç¡®å®šæ—¶ä¸»åŠ¨å›çœ‹å›¾åƒï¼Œå°¤å…¶åœ¨é«˜ç†µ token é˜¶æ®µå¢å¼ºå¯¹ç›®æ ‡åŒºåŸŸçš„å…³æ³¨ï¼ˆè§ Figure 4, 6ï¼‰ã€‚
   - å¯è§†åŒ–æ˜¾ç¤ºï¼ŒSAYO åœ¨å…³é”®æ¨ç†æ­¥éª¤å§‹ç»ˆé”å®šæ­£ç¡®åŒºåŸŸï¼ˆFigure 5ï¼‰ã€‚

4. âœ… **è·¨åŸŸæ³›åŒ–èƒ½åŠ›å¼º**  
   - å°½ç®¡æœªåœ¨æ•°å­¦æ•°æ®ä¸Šè®­ç»ƒï¼Œä½†åœ¨ `We-Math` å’Œ `MathVision` ä¸Šå¤§å¹…æå‡ã€‚
   - åŸå› ï¼š**ä¿®å¤äº†â€œè¾“å…¥ä¿¡å·â€â€”â€”è®©æ¨¡å‹å…ˆâ€œçœ‹æ¸…ä¸‰è§’å½¢è¾¹â€å†æ¨ç†ï¼Œé‡Šæ”¾äº†å·²æœ‰æ•°å­¦å¼•æ“çš„èƒ½åŠ›**ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

- ä¾èµ–å¸¦æœ‰ **bounding box æ³¨é‡Šçš„æ•°æ®** æ„å»ºç›‘ç£ä¿¡å·ï¼Œé™åˆ¶äº†å¯æ‰©å±•æ€§ã€‚
- å½“å‰å¥–åŠ±æœºåˆ¶åŸºäºæœ€åä¸€å±‚ attentionï¼Œå¯èƒ½æœªå……åˆ†æ•æ‰å¤šå±‚è§†è§‰èåˆåŠ¨æ€ã€‚
- å¯¹æç«¯ä½è´¨é‡å›¾åƒæˆ–é«˜åº¦é®æŒ¡åœºæ™¯ä»å¯èƒ½å¤±æ•ˆã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

- æ¢ç´¢ **æ— ç›‘ç£æˆ–å¼±ç›‘ç£æ–¹å¼æ„å»ºæ³¨æ„åŠ›å¥–åŠ±ä¿¡å·**ï¼Œå‡å°‘æ ‡æ³¨ä¾èµ–ã€‚
- è®¾è®¡ **åˆ†å±‚æ³¨æ„åŠ›å¥–åŠ±æœºåˆ¶**ï¼Œè¦†ç›–ä¸åŒç½‘ç»œæ·±åº¦çš„è§†è§‰è¯­ä¹‰ã€‚
- å°† SAYO æ¡†æ¶æ‰©å±•è‡³ **è§†é¢‘ã€3D åœºæ™¯ç­‰æ—¶åºæˆ–å¤šæ¨¡æ€è¾“å…¥**ã€‚
- ç ”ç©¶å¦‚ä½•å°†â€œLook-to-Verifyâ€æœºåˆ¶è¿ç§»åˆ°å…¶ä»–è®¤çŸ¥ä»»åŠ¡ï¼ˆå¦‚å¬è§‰-è¯­è¨€æ¨ç†ï¼‰ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> SAYO æ­ç¤ºäº† MLLMs çš„çœŸæ­£ç“¶é¢ˆä¸æ˜¯â€œä¸ä¼šæƒ³â€ï¼Œè€Œæ˜¯â€œæ²¡çœ‹æ¸…â€ã€‚é€šè¿‡å¼•å…¥ **åŸºäºé«˜ç†µ token çš„æ³¨æ„åŠ›å¥–åŠ±æœºåˆ¶**ï¼Œå®ƒæ•™ä¼šæ¨¡å‹â€œåœ¨ä¸ç¡®å®šæ—¶å›å¤´çœ‹çœ‹â€ï¼Œä»è€Œæ˜¾è‘—æå‡è§†è§‰æ¨ç†çš„é²æ£’æ€§ä¸å‡†ç¡®æ€§ã€‚

</details>

---

### 15. [Decoupled Reasoning with Implicit Fact Tokens (DRIFT): A Dual-Model Framework for Efficient Long-Context Inference](https://arxiv.org/abs/2602.10021)

**Authors**: Wenxuan Xie, Yujia Wang, Xin Tan, Chaochao Lu, Xia Hu, Xuhong Wang  
**Category**: cs.CL  
**Published**: 2026-02-11  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.10021v1  

#### Abstract
The integration of extensive, dynamic knowledge into Large Language Models (LLMs) remains a significant challenge due to the inherent entanglement of factual data and reasoning patterns. Existing solutions, ranging from non-parametric Retrieval-Augmented Generation (RAG) to parametric knowledge edit...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠDecoupled Reasoning with Implicit Fact Tokens (DRIFT): A Dual-Model Framework for Efficient Long-Context Inferenceã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†**çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡**æ—¶é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **ä¸Šä¸‹æ–‡çª—å£æœ‰é™**ï¼šä¼ ç»Ÿæ–¹æ³•å¦‚ RAG æˆ–é•¿æ–‡æœ¬æç¤ºå—é™äº context window å’Œæ£€ç´¢å™¨å™ªå£°ã€‚
- **é™æ€å‹ç¼©ä¸¢å¤±å…³é”®ä¿¡æ¯**ï¼šç°æœ‰ prompt compression æ–¹æ³•å¤šä¸ºé™æ€ã€æŸ¥è¯¢æ— å…³ï¼ˆquery-agnosticï¼‰ï¼Œåœ¨é«˜æ¯”ä¾‹å‹ç¼©ä¸‹å®¹æ˜“ä¸¢å¤±ä»»åŠ¡ç›¸å…³çš„å…³é”®äº‹å®ã€‚
- **å‚æ•°æ›´æ–°é£é™©å¤§**ï¼šé€šè¿‡ fine-tuning æˆ– knowledge editing æ³¨å…¥æ–°çŸ¥è¯†å¯èƒ½å¯¼è‡´ç¾éš¾æ€§é—å¿˜ï¼ˆcatastrophic forgettingï¼‰æˆ–ç ´ååŸæœ‰æ¨ç†èƒ½åŠ›ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æå‡º **DRIFT**ï¼ˆDecoupled Reasoning with Implicit Fact Tokensï¼‰ï¼Œä¸€ç§**åŒæ¨¡å‹æ¶æ„**ï¼Œå®ç°çŸ¥è¯†æå–ä¸æ¨ç†è¿‡ç¨‹çš„æ˜¾å¼è§£è€¦ï¼š
- **è½»é‡çº§çŸ¥è¯†æ¨¡å‹**ï¼ˆKnowledge Modelï¼‰ï¼šåŠ¨æ€åœ°å°†æ–‡æ¡£å—å‹ç¼©ä¸ºåŸºäºæŸ¥è¯¢æ¡ä»¶çš„**éšå¼äº‹å®ä»¤ç‰Œ**ï¼ˆImplicit Fact Tokensï¼‰ï¼Œè¿™äº›æ˜¯é«˜å¯†åº¦çš„æ½œåœ¨è¡¨ç¤ºã€‚
- **å¤§å‹æ¨ç†æ¨¡å‹**ï¼ˆReasoning Modelï¼‰ï¼šæ¥æ”¶ç”±çŸ¥è¯†æ¨¡å‹ç”Ÿæˆçš„äº‹å®åµŒå…¥ï¼Œåœ¨å…¶ embedding space ä¸­è¿›è¡Œé«˜æ•ˆå¤æ‚æ¨ç†ã€‚
- **Latent Space äº¤äº’**ï¼šä¸¤ä¸ªæ¨¡å—é€šè¿‡ä¸€ä¸ªå¯è®­ç»ƒçš„ MLP Projector åœ¨æ½œåœ¨ç©ºé—´ä¸­å¯¹é½ï¼Œé¿å…åŸå§‹æ–‡æœ¬å†—ä½™å¹²æ‰°ã€‚

è¯¥æ¡†æ¶å®ç°äº†â€œ**è¯»å–-å‹ç¼©-æ¨ç†**â€çš„æµæ°´çº¿åŒ–è®¾è®¡ï¼Œæ”¯æŒè¶…é•¿ä¸Šä¸‹æ–‡åœºæ™¯ä¸‹çš„é«˜æ•ˆæ¨ç†ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | DRIFT çš„ä¼˜åŠ¿ |
|------|-------------|
| **æ•ˆç‡** | æ˜¾è‘—é™ä½æ¨ç†å»¶è¿Ÿï¼Œå®æµ‹åœ¨ 256k-token æ–‡æ¡£ä¸Šå¹³å‡æé€Ÿ **7Ã—**ã€‚ |
| **å‡†ç¡®æ€§** | åœ¨ LongBench-v2 ä¸Šï¼Œç›¸æ¯” Mistral-7B åŸºçº¿ï¼Œå‡†ç¡®ç‡ä» 20.87% æå‡è‡³ **29.22%**ã€‚ |
| **å‹ç¼©æ¯”** | æ”¯æŒé«˜è¾¾ **128Ã— çš„å‹ç¼©æ¯”**ï¼Œä»ä¿æŒç«äº‰åŠ›ï¼Œè¡¨ç°å‡ºæå¼ºé²æ£’æ€§ã€‚ |
| **æ³›åŒ–æ€§** | å¯æ— ç¼æ‰©å±•åˆ°å¤šæ–‡æ¡£ã€è¶…é•¿åºåˆ—ï¼ˆç™¾ä¸‡ token çº§åˆ«ï¼‰ä¸”æ— éœ€é¢å¤–å¾®è°ƒã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **BAMBOO**ï¼šç»¼åˆæ€§é•¿æ–‡æœ¬å»ºæ¨¡è¯„æµ‹å¥—ä»¶ï¼Œæ¶µç›–é—®ç­”ã€ä»£ç è¡¥å…¨ç­‰ä»»åŠ¡ã€‚
- **L-Eval**ï¼šå¹³è¡¡å•è·³ä¸å¤šè·³æ¨ç†èƒ½åŠ›è¯„ä¼°ï¼Œæ–‡æ¡£é•¿åº¦å¯è¾¾ **256K tokens**ï¼Œå‡å°‘çŸ¥è¯†æ³„éœ²å½±å“ã€‚
- **LongBench-v2**ï¼šåŒ…å«éœ€è·¨å¤šæ–‡æ¡£ç†è§£ä¸ç»“æ„åŒ–æ•°æ®æ¨ç†çš„æŒ‘æˆ˜æ€§é€‰æ‹©é¢˜ï¼Œä¸Šä¸‹æ–‡è¾¾æ•°ç™¾ä¸‡è¯ã€‚
- **LoCoMo**ï¼šèšç„¦é•¿æœŸå¯¹è¯è®°å¿†ï¼Œæµ‹è¯•æ—¶é—´æ¨ç†ä¸äº‹ä»¶æ‘˜è¦èƒ½åŠ›ã€‚

æ­¤å¤–ï¼Œä½œè€…æ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡ **Document-QA-Evidence æ•°æ®é›†**ï¼ŒåŒ…å«è¶…è¿‡ 30 ä¸‡å®ä¾‹ï¼Œæ–‡æ¡£é•¿åº¦è¦†ç›– 1Kâ€“8K tokensï¼Œå¹¶æä¾›ç»†ç²’åº¦è¯æ®æ ‡æ³¨ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
| ç±»å‹ | å†…å®¹ |
|------|------|
| **ä¸»å¹²æ¨¡å‹** | çŸ¥è¯†æ¨¡å‹ï¼š`Qwen2.5-Instruct-3B`ï¼›æ¨ç†æ¨¡å‹ï¼š`Mistral-7B-Instruct-v0.2` / `Qwen2.5-7B-Instruct` |
| **è®­ç»ƒæ–¹å¼** | ä½¿ç”¨ LoRA è¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆParameter-Efficient Fine-Tuningï¼‰ã€‚ |
| **è¯„ä¼°æŒ‡æ ‡** | - å¤šé€‰/å°é—­å¼ä»»åŠ¡ï¼šä½¿ç”¨ `Qwen-2.5-72B-Instruct` ä½œä¸º LLM-Judge è®¡ç®— **Accuracy**ã€‚<br>- æ‘˜è¦ç±»ä»»åŠ¡ï¼šæŠ¥å‘Š **ROUGE-L** åˆ†æ•°ã€‚ |
| **å‹ç¼©ç­–ç•¥** | å¼•å…¥ **Bucketed Compression**ï¼ŒæŒ‰è¾“å…¥é•¿åº¦åŒºé—´æ˜ å°„å›ºå®šè¾“å‡ºå¤§å°ï¼Œä¼˜äºå›ºå®šæ¯”ç‡å‹ç¼©ã€‚ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | å¯¹æ¯”æ–¹æ³• |
|------|--------|
| **Hard Compression** | LLMLingua-2ï¼ˆåŸºäº token é€‰æ‹©ï¼‰ |
| **Soft Compression (Latent)** | ICAE, COCOM, xRAG |
| **RAG-based** | NaiveRAGï¼ˆä½¿ç”¨ BGE-M3 æ£€ç´¢ï¼‰ |
| **Vanilla Baseline** | Mistral-7B / Qwen2.5-7B ç›´æ¥è¾“å…¥å…¨æ–‡ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ Mistral-7B ä¸ºæ¨ç†æ¨¡å‹ï¼‰
| æ–¹æ³• | Compression Ratio | LongBench-v2 (Acc.) | LoCoMo (Acc.) | L-Eval QA Avg |
|------|-------------------|------------------------|----------------|---------------|
| Vanilla Mistral-7B | 1Ã— | 20.87 | 59.35 | 53.94 |
| COCOM (128Ã—) | 128Ã— | 6.95 | 8.96 | 25.05 |
| xRAG (128Ã—) | 128Ã— | 25.58 | 24.74 | 35.56 |
| **DRIFT (Ours)** | **32Ã—** | **29.22** | **57.73** | **48.28** |
| **DRIFT (Ours)** | **64Ã—** | **29.77** | **53.31** | **46.67** |
| **DRIFT (Ours)** | **128Ã—** | **24.65** | **50.71** | **44.24** |

> âœ… **ç»“è®º**ï¼šå³ä½¿åœ¨æç«¯å‹ç¼©æ¯”ï¼ˆ128Ã—ï¼‰ä¸‹ï¼ŒDRIFT ä¾ç„¶æ˜¾è‘—ä¼˜äºå…¶ä»–è½¯å‹ç¼©æ–¹æ³•ã€‚

### ä¸å…¶ä»–æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨ **QMSUM** å’Œ **SPACE**ï¼ˆä»»åŠ¡å¯¼å‘æ‘˜è¦ï¼‰ä»¥åŠ **LoCoMo** ä¸Šï¼Œä¼ ç»Ÿå‹ç¼©æ–¹æ³•è¡¨ç°å´©æºƒï¼Œè€Œ DRIFT ä¿æŒæœ‰æ•ˆã€‚
- åœ¨ **BAMBOO** å’Œ **LongBench-v2** ä¸Šï¼ŒDRIFT åœ¨æ‰€æœ‰å‹ç¼©æ¯”ä¸‹å‡å–å¾— SOTA æ€§èƒ½ã€‚
- åœ¨ **256k-token è¾“å…¥**ä¸Šï¼Œç«¯åˆ°ç«¯ TTFTï¼ˆTime-to-First-Tokenï¼‰åˆ†ææ˜¾ç¤ºï¼ŒDRIFT æ¨ç†é€Ÿåº¦æ¯” Full-Context åŸºçº¿å¿«çº¦ **7å€**ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
| æ–¹æ³•å˜ä½“ | LongBench-v2 | LoCoMo | BAMBOO |
|---------|--------------|--------|--------|
| **Full DRIFT (32Ã—)** | 29.22 | 57.73 | 60.15 |
| w/o LFRP | 26.84 (-2.38) | 52.68 (-5.05) | 57.64 (-2.51) |
| w/o QAFT-DC | 25.84 (-3.38) | 57.36 (-0.37) | 56.64 (-3.51) |
| w/o QAFT-QA | 18.05 (-11.17) | 36.89 (-20.84) | 45.14 (-15.01) |

> ğŸ” **å‘ç°**ï¼š
> - **QAFT-QA** æ˜¯æœ€æ ¸å¿ƒç»„ä»¶ï¼Œç›´æ¥å½±å“æœ€ç»ˆç­”æ¡ˆç”Ÿæˆèƒ½åŠ›ã€‚
> - **LFRP** å’Œ **QAFT-DC** å…±åŒä¼˜åŒ–æ½œåœ¨ç©ºé—´çš„è´¨é‡ä¸æ•ˆç‡ï¼Œæå‡æ•´ä½“é²æ£’æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **è§£è€¦è®¾è®¡æœ‰æ•ˆ**ï¼šå°†çŸ¥è¯†æå–ä¸æ¨ç†åˆ†ç¦»ï¼Œä½¿è½»é‡æ¨¡å‹ä¸“æ³¨å‹ç¼©ã€å¤§æ¨¡å‹ä¸“æ³¨æ¨ç†ï¼Œæ˜¾è‘—æå‡æ•ˆç‡ä¸ç²¾åº¦ã€‚
2. **åŠ¨æ€å‹ç¼©ä¼˜äºé™æ€**ï¼šåŸºäºæŸ¥è¯¢çš„åŠ¨æ€å‹ç¼©èƒ½ä¿ç•™æ›´å¤šä»»åŠ¡ç›¸å…³è¯æ®ï¼Œå°¤å…¶é€‚ç”¨äºç¨€ç–å…³é”®ä¿¡æ¯åœºæ™¯ã€‚
3. **é«˜æ¯”ä¾‹å‹ç¼©å¯è¡Œ**ï¼šé€šè¿‡ Bucketed Compression å’Œä¸‰å±‚è®­ç»ƒæµç¨‹ï¼Œå¯åœ¨ **128Ã— å‹ç¼©æ¯”**ä¸‹ä»ç»´æŒé«˜æ€§èƒ½ã€‚
4. **éšå¼è¡¨ç¤ºéç®€å•å¤åˆ¶**ï¼šè¯Šæ–­æŒ‡æ ‡ MED æ˜¾ç¤ºï¼Œæ¨ç†æ¨¡å‹ç»å†â€œå…ˆå¯¹é½åä¸“ä¸šåŒ–â€è¿‡ç¨‹ï¼Œè¯´æ˜éšå¼äº‹å®ä»¤ç‰Œä¸æ˜¯åŸæ–‡å‹ç¼©å‰¯æœ¬ï¼Œè€Œæ˜¯æ”¯æŒæ›´é«˜æ•ˆæ¨ç†çš„**äº’è¡¥æ¨¡æ€**ã€‚
5. **é›¶æ ·æœ¬è¿ç§»èƒ½åŠ›å¼º**ï¼šä»…åœ¨å•æ–‡æ¡£ä¸Šè®­ç»ƒçš„ DRIFTï¼Œå¯ç›´æ¥ç”¨äºå¤šæ–‡æ¡£æ¨ç†è€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **æ¨¡å‹è§„æ¨¡é™åˆ¶**ï¼šå½“å‰å®éªŒé›†ä¸­åœ¨ â‰¤14B å‚æ•°æ¨¡å‹ï¼Œæ›´å¤§è§„æ¨¡æ¨¡å‹ä¸Šçš„ scaling law å°šæœªéªŒè¯ã€‚
2. **å¯è§£é‡Šæ€§å·®**ï¼šéšå¼äº‹å®ä»¤ç‰Œä¸å¯è¯»ï¼Œéš¾ä»¥åƒ RAG é‚£æ ·æä¾›æ˜ç¡®å¼•ç”¨æ¥æºï¼Œä¸åˆ©äºè°ƒè¯•ä¸å¯ä¿¡ AIã€‚
3. **ä¾èµ–ç›‘ç£ä¿¡å·**ï¼šè®­ç»ƒéœ€è¦é«˜è´¨é‡çš„ evidence æ ‡æ³¨ï¼Œè‡ªåŠ¨æ„é€ è™½å¯è¡Œä½†å­˜åœ¨è´¨é‡æ³¢åŠ¨é£é™©ã€‚
4. **è®­ç»ƒå¤æ‚åº¦é«˜**ï¼šä¸‰é˜¶æ®µè®­ç»ƒæµç¨‹å¢åŠ äº†å·¥ç¨‹å®ç°éš¾åº¦ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **å¼•å…¥å¼ºåŒ–å­¦ä¹ **ï¼ˆReinforcement Learningï¼‰ä¼˜åŒ–çŸ¥è¯†é€‰æ‹©ç­–ç•¥ï¼Œè¿›ä¸€æ­¥æå‡å‹ç¼©è´¨é‡ã€‚
2. **æ¢ç´¢å¯è§£é‡Šæ€§æœºåˆ¶**ï¼šå°è¯•å°†éšå¼ä»¤ç‰Œåå‘æŠ•å½±ä¸ºè‡ªç„¶è¯­è¨€ç‰‡æ®µï¼Œå¢å¼ºé€æ˜åº¦ã€‚
3. **æ‰©å±•è‡³æ›´å¤§æ¨¡å‹**ï¼šç ”ç©¶ DRIFT åœ¨ç™¾äº¿çº§ä»¥ä¸Šæ¨¡å‹ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚
4. **ç»“åˆ Retrieval ä¸ Editing**ï¼šèåˆ RAG çš„çµæ´»æ€§ä¸ DRIFT çš„é«˜æ•ˆæ€§ï¼Œæ„å»ºç»Ÿä¸€çš„çŸ¥è¯†å¢å¼ºæ¡†æ¶ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> DRIFT é€šè¿‡**åŒæ¨¡å‹è§£è€¦ + æŸ¥è¯¢æ„ŸçŸ¥çš„éšå¼äº‹å®å‹ç¼©**ï¼Œå®ç°äº†**é«˜æ•ˆã€å‡†ç¡®ã€å¯æ‰©å±•**çš„é•¿ä¸Šä¸‹æ–‡æ¨ç†æ–°èŒƒå¼ï¼Œåœ¨æ€§èƒ½ä¸æ•ˆç‡ä¹‹é—´å–å¾—äº†å“è¶Šå¹³è¡¡ã€‚

</details>

---

### 16. [Revealing the Challenges of Attention-FFN Disaggregation for Modern MoE Models and Hardware Systems](https://arxiv.org/abs/2602.09721)

**Authors**: Guowei Liu, Hongming Li, Yaning Guo, Yongxi Lyu, Mo Zhou, Yi Liu, Zhaogeng Li, Yanpeng Wang  
**Category**: cs.DC  
**Published**: 2026-02-11  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.09721v1  

#### Abstract
Deploying large-scale MoE models presents challenges in memory capacity and bandwidth for expert activation. While Attention-FFN Disaggregation (AFD) has emerged as a potential architecture to decouple compute and memory resources, its performance boundaries compared to standard large-scale Expert P...

---

### 17. [Boltzmann Reinforcement Learning for Noise resilience in Analog Ising Machines](https://arxiv.org/abs/2602.09162)

**Authors**: Aditya Choudhary, Saaketh Desai, Prasad Iyer  
**Category**: cs.LG  
**Published**: 2026-02-11  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.09162v1  

#### Abstract
Analog Ising machines (AIMs) have emerged as a promising paradigm for combinatorial optimization, utilizing physical dynamics to solve Ising problems with high energy efficiency. However, the performance of traditional optimization and sampling algorithms on these platforms is often limited by inher...

---

### 18. [SCOUT-RAG: Scalable and Cost-Efficient Unifying Traversal for Agentic Graph-RAG over Distributed Domains](https://arxiv.org/abs/2602.08400)

**Authors**: Longkun Li, Yuanben Zou, Jinghan Wu, Yuqing Wen, Jing Li, Hangwei Qian, Ivor Tsang  
**Category**: cs.AI  
**Published**: 2026-02-11  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.08400v1  

#### Abstract
Graph-RAG improves LLM reasoning using structured knowledge, yet conventional designs rely on a centralized knowledge graph. In distributed and access-restricted settings (e.g., hospitals or multinational organizations), retrieval must select relevant domains and appropriate traversal depth without ...

---

### 19. [MILE-RefHumEval: A Reference-Free, Multi-Independent LLM Framework for Human-Aligned Evaluation](https://arxiv.org/abs/2602.09624)

**Authors**: Nalin Srun (UL, CNRS, LORIA), Parisa Rastin (UL, CNRS, LORIA), Gu\'ena\"el Cabanes (UL, CNRS, LORIA), Lydia Boudjeloud Assala (UL, CNRS, LORIA)  
**Category**: cs.CL  
**Published**: 2026-02-11  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.09624v1  

#### Abstract
We introduce MILE-RefHumEval, a reference-free framework for evaluating Large Language Models (LLMs) without ground-truth annotations or evaluator coordination. It leverages an ensemble of independently prompted evaluators guided by a human-aligned schema, supporting both discrete and continuous sco...

---

### 20. [Unsupervised Layer-Wise Dynamic Test Time Adaptation for LLMs](https://arxiv.org/abs/2602.09719)

**Authors**: Longhuan Xu, Cunjian Chen, Feng Yin  
**Category**: cs.CL  
**Published**: 2026-02-11  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.09719v1  

#### Abstract
Test-time adaptation (TTA) for large language models (LLMs) updates model parameters at inference time using signals available at deployment. This paper focuses on a common yet under-explored regime: unsupervised, sample-specific TTA, where the model adapts independently for each prompt using only t...

---

### 21. [Stabilizing Physics-Informed Consistency Models via Structure-Preserving Training](https://arxiv.org/abs/2602.09303)

**Authors**: Che-Chia Chang, Chen-Yang Dai, Te-Sheng Lin, Ming-Chih Lai, Chieh-Hsin Lai  
**Category**: cs.LG  
**Published**: 2026-02-11  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.09303v1  

#### Abstract
We propose a physics-informed consistency modeling framework for solving partial differential equations (PDEs) via fast, few-step generative inference. We identify a key stability challenge in physics-constrained consistency training, where PDE residuals can drive the model toward trivial or degener...

---

### 22. [Steer2Adapt: Dynamically Composing Steering Vectors Elicits Efficient Adaptation of LLMs](https://arxiv.org/abs/2602.07276)

**Authors**: Pengrui Han, Xueqiang Xu, Keyang Xuan, Peiyang Song, Siru Ouyang, Runchu Tian, Yuqing Jiang, Cheng Qian, Pengcheng Jiang, Jiashuo Sun, Junxia Cui, Ming Zhong, Ge Liu, Jiawei Han, Jiaxuan You  
**Category**: cs.AI  
**Published**: 2026-02-11  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.07276v1  

#### Abstract
Activation steering has emerged as a promising approach for efficiently adapting large language models (LLMs) to downstream behaviors. However, most existing steering methods rely on a single static direction per task or concept, making them inflexible under task variation and inadequate for complex...

---

### 23. [Advancing Block Diffusion Language Models for Test-Time Scaling](https://arxiv.org/abs/2602.09555)

**Authors**: Yi Lu, Deyang Kong, Jianing Wang, Linsen Guo, Xue Wang, Qi Guo, Tao Gui, Xuanjing Huang, Wei Ye, Shikun Zhang, Wei Wang  
**Category**: cs.CL  
**Published**: 2026-02-11  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.09555v1  

#### Abstract
Recent advances in block diffusion language models have demonstrated competitive performance and strong scalability on reasoning tasks. However, existing BDLMs have limited exploration under the test-time scaling setting and face more severe decoding challenges in long Chain-of-Thought reasoning, pa...

---

### 24. [MATA: Multi-Agent Framework for Reliable and Flexible Table Question Answering](https://arxiv.org/abs/2602.09642)

**Authors**: Sieun Hyeon, Jusang Oh, Sunghwan Steve Cho, Jaeyoung Do  
**Category**: cs.CL  
**Published**: 2026-02-11  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.09642v1  

#### Abstract
Recent advances in Large Language Models (LLMs) have significantly improved table understanding tasks such as Table Question Answering (TableQA), yet challenges remain in ensuring reliability, scalability, and efficiency, especially in resource-constrained or privacy-sensitive environments. In this ...

---

### 25. [Steer2Edit: From Activation Steering to Component-Level Editing](https://arxiv.org/abs/2602.09870)

**Authors**: Chung-En Sun, Ge Yan, Zimo Wang, Tsui-Wei Weng  
**Category**: cs.CL  
**Published**: 2026-02-11  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.09870v1  

#### Abstract
Steering methods influence Large Language Model behavior by identifying semantic directions in hidden representations, but are typically realized through inference-time activation interventions that apply a fixed, global modification to the model's internal states. While effective, such intervention...

---

### 26. [CoFEH: LLM-driven Feature Engineering Empowered by Collaborative Bayesian Hyperparameter Optimization](https://arxiv.org/abs/2602.09851)

**Authors**: Beicheng Xu, Keyao Ding, Wei Liu, Yupeng Lu, Bin Cui  
**Category**: cs.LG  
**Published**: 2026-02-11  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.09851v1  

#### Abstract
Feature Engineering (FE) is pivotal in automated machine learning (AutoML) but remains a bottleneck for traditional methods, which treat it as a black-box search, operating within rigid, predefined search spaces and lacking domain awareness. While Large Language Models (LLMs) offer a promising alter...

---

### 27. [ANCHOR: Branch-Point Data Generation for GUI Agents](https://arxiv.org/abs/2602.07153)

**Authors**: Jinbiao Wei, Yilun Zhao, Kangqi Ni, Arman Cohan  
**Category**: cs.AI  
**Published**: 2026-02-11  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.07153v1  

#### Abstract
End-to-end GUI agents for real desktop environments require large amounts of high-quality interaction data, yet collecting human demonstrations is expensive and existing synthetic pipelines often suffer from limited task diversity or noisy, goal-drifting trajectories. We present a trajectory expansi...

---

### 28. [MSP-LLM: A Unified Large Language Model Framework for Complete Material Synthesis Planning](https://arxiv.org/abs/2602.07543)

**Authors**: Heewoong Noh, Gyoung S. Na, Namkyeong Lee, Chanyoung Park  
**Category**: cs.AI  
**Published**: 2026-02-11  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.07543v2  

#### Abstract
Material synthesis planning (MSP) remains a fundamental and underexplored bottleneck in AI-driven materials discovery, as it requires not only identifying suitable precursor materials but also designing coherent sequences of synthesis operations to realize a target material. Although several AI-base...

---

### 29. [Efficient Table Retrieval and Understanding with Multimodal Large Language Models](https://arxiv.org/abs/2602.07642)

**Authors**: Zhuoyan Xu, Haoyang Fang, Boran Han, Bonan Min, Bernie Wang, Cuixiong Hu, Shuai Zhang  
**Category**: cs.AI  
**Published**: 2026-02-11  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.07642v1  

#### Abstract
Tabular data is frequently captured in image form across a wide range of real-world scenarios such as financial reports, handwritten records, and document scans. These visual representations pose unique challenges for machine understanding, as they combine both structural and visual complexities. Wh...

---

### 30. [EventCast: Hybrid Demand Forecasting in E-Commerce with LLM-Based Event Knowledge](https://arxiv.org/abs/2602.07695)

**Authors**: Congcong Hu, Yuang Shi, Fan Huang, Yang Xiang, Zhou Ye, Ming Jin, Shiyu Wang  
**Category**: cs.AI  
**Published**: 2026-02-11  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.07695v1  

#### Abstract
Demand forecasting is a cornerstone of e-commerce operations, directly impacting inventory planning and fulfillment scheduling. However, existing forecasting systems often fail during high-impact periods such as flash sales, holiday campaigns, and sudden policy interventions, where demand patterns s...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- kv cache, offload, State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
