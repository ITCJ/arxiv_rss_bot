# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-01-26 06:03:27 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [DataStates-LLM: Scalable Checkpointing for Transformer Models Using Composable State Providers](https://arxiv.org/abs/2601.16956)

**Authors**: Avinash Maurya, M. Mustafa Rafique, Franck Cappello, Bogdan Nicolae  
**Category**: cs.DC  
**Published**: 2026-01-26  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2601.16956v1  

#### Abstract
The rapid growth of Large Transformer-based models, specifically Large Language Models (LLMs), now scaling to trillions of parameters, has necessitated training across thousands of GPUs using complex hybrid parallelism strategies (e.g., data, tensor, and pipeline parallelism). Checkpointing this mas...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šDataStates-LLM: Scalable Checkpointing for Transformer Models Using Composable State Providers**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éœ€è¦è·¨æ•°åƒä¸ªGPUè¿›è¡Œåˆ†å¸ƒå¼è®¡ç®—ï¼Œé‡‡ç”¨å¤æ‚çš„æ··åˆå¹¶è¡Œç­–ç•¥ï¼ˆå¦‚ **Data Parallelism (DP)**ã€**Tensor Parallelism (TP)** å’Œ **Pipeline Parallelism (PP)**ï¼‰ã€‚ä¼ ç»Ÿçš„æ£€æŸ¥ç‚¹ï¼ˆcheckpointingï¼‰æœºåˆ¶å°†æ¨¡å‹çŠ¶æ€è§†ä¸ºä¸é€æ˜çš„äºŒè¿›åˆ¶å—ï¼Œå¿½ç•¥äº†å…¶â€œ**3Då¼‚æ„æ€§**â€ï¼ˆ3D heterogeneityï¼‰ï¼Œå³ï¼š
- **å†…å­˜ä½ç½®å·®å¼‚**ï¼šGPU vs. Host å†…å­˜ä¸­çš„æ•°æ®ï¼›
- **æ•°æ®ç±»å‹å·®å¼‚**ï¼šå¼ é‡ï¼ˆtensorsï¼‰vs. Python å¯¹è±¡ï¼ˆå¦‚å­—å…¸ã€éšæœºç§å­ç­‰ï¼‰ï¼›
- **åˆ†ç‰‡ç­–ç•¥å·®å¼‚**ï¼šç”±å¹¶è¡Œç­–ç•¥å¯¼è‡´çš„ç»†ç²’åº¦åˆ†å¸ƒã€‚

è¿™å¯¼è‡´äº†ä¸¥é‡çš„è¿è¡Œæ—¶å¼€é”€ï¼ŒåŒ…æ‹¬ï¼š
- é˜»å¡å¼çš„ **Device-to-Host (D2H)** æ•°æ®ä¼ è¾“ï¼›
- æ•°æ®ç›²åŒºçš„åºåˆ—åŒ–ï¼ˆdata-oblivious serializationï¼‰ï¼›
- å­˜å‚¨ I/O ç«äº‰ã€‚

å› æ­¤ï¼Œç°æœ‰æ–¹æ¡ˆæ— æ³•é«˜æ•ˆæ”¯æŒé«˜é¢‘ç‡ã€ä½å¹²æ‰°çš„æ£€æŸ¥ç‚¹æ“ä½œï¼Œå½±å“è®­ç»ƒæ•ˆç‡ä¸å®¹é”™èƒ½åŠ›ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
è®ºæ–‡æå‡º **DataStates-LLM**ï¼Œä¸€ç§ä¸“ä¸ºå¤§è§„æ¨¡ Transformer æ¨¡å‹è®¾è®¡çš„é«˜æ€§èƒ½å¼‚æ­¥æ£€æŸ¥ç‚¹ç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### âœ… **State Providersï¼ˆçŠ¶æ€æä¾›è€…ï¼‰æŠ½è±¡å±‚**
- å¼•å…¥è½»é‡çº§ä¸­é—´ä»¶æŠ½è±¡â€”â€”**State Provider (SP)**ï¼Œå°è£…ä¸åŒç±»å‹æ•°æ®ç»“æ„çš„è¯­ä¹‰ï¼ˆå¦‚å¼ é‡å¸ƒå±€ã€åºåˆ—åŒ–éœ€æ±‚ã€å­˜å‚¨æ˜ å°„ï¼‰ã€‚
- å…è®¸å¯¹ä¸åŒæ•°æ®ç±»å‹ï¼ˆGPUå¼ é‡ã€Hostå…ƒæ•°æ®ï¼‰è¿›è¡Œå®šåˆ¶åŒ–çš„å¤„ç†ï¼Œå®ç°é›¶æ‹·è´åºåˆ—åŒ–ï¼ˆzero-copy serializationï¼‰å’Œå¹¶è¡Œæµå¼è¾“å‡ºã€‚

#### âœ… **Lazy, Non-Blocking Asynchronous Snapshots**
- åˆ©ç”¨è®­ç»ƒè¿­ä»£ä¸­ **å‰å‘ä¼ æ’­ï¼ˆforwardï¼‰å’Œåå‘ä¼ æ’­ï¼ˆbackwardï¼‰é˜¶æ®µå‚æ•°ä¸å˜** çš„ç‰¹æ€§ï¼Œåœ¨è¿™äº›é˜¶æ®µ**éé˜»å¡åœ°å‘èµ· D2H ä¼ è¾“**ã€‚
- å®ç°â€œæ‡’å¿«ç…§â€æœºåˆ¶ï¼šåªè¦åœ¨ä¼˜åŒ–å™¨æ›´æ–°ï¼ˆupdateï¼‰å‰å®Œæˆå¤åˆ¶å³å¯ï¼Œé¿å…ä¸­æ–­å…³é”®è·¯å¾„ã€‚

#### âœ… **Streamlined Multi-Tier I/O Engine**
- è®¾è®¡æµæ°´çº¿å¼ I/O å¼•æ“ï¼Œåˆ©ç”¨ **liburing + O_DIRECT** å®ç°å†…æ ¸åŠ é€Ÿçš„å¤šçº¿ç¨‹æŒä¹…åŒ–å†™å…¥ï¼›
- ç®¡ç†é¢„åˆ†é…çš„ pinned host memory poolï¼Œæ”¯æŒå¤šçº§ç¼“å†²ä¸é‡å ä¼ è¾“ï¼ˆD2H â†’ Host â†’ SSD/PFSï¼‰ã€‚

#### âœ… **Overlap I/O with Serialization**
- åˆ†ç¦»å…ƒæ•°æ®ç”Ÿæˆä¸å¤§å¼ é‡ä¼ è¾“ï¼Œä¼˜å…ˆæ¨é€æ— éœ€åºåˆ—åŒ–çš„å¼ é‡æ•°æ®æµï¼Œä½¿å°å¯¹è±¡çš„åºåˆ—åŒ–è¿‡ç¨‹ä¸ I/O å¹¶å‘æ‰§è¡Œï¼Œæ¶ˆé™¤ç“¶é¢ˆã€‚

#### âœ… **Hybrid Persistent Layout Strategy**
- é‡‡ç”¨â€œå›ºå®šåç§» + å¹¶å‘æ—¥å¿—è¿½åŠ â€çš„æ··åˆå¸ƒå±€ç­–ç•¥ï¼š
  - å¤§å¼ é‡æŒ‰å·²çŸ¥å¤§å°é¢„åˆ†é…åç§»ï¼›
  - å°å¯¹è±¡ä»¥æ—¥å¿—å½¢å¼è¿½åŠ ï¼›
  - æœ€åé™„åŠ ä¸€ä¸ª header æè¿°æ•´ä½“å¸ƒå±€ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ DeepSpeedã€TorchSnapshotï¼‰ | DataStates-LLM |
|------|----------------------------------------|----------------|
| **åºåˆ—åŒ–æ–¹å¼** | `torch.save` ç±»å‹æ— å…³éå†ï¼Œé‡å¤åºåˆ—åŒ–å¼ é‡ | é›¶æ‹·è´å¼ é‡ç›´å†™ï¼Œä»…åºåˆ—åŒ–éå¼ é‡å¯¹è±¡ |
| **D2H ä¼ è¾“** | åŒæ­¥æˆ–ç²—ç²’åº¦å¼‚æ­¥ï¼Œå ç”¨è®­ç»ƒå¸¦å®½ | å¼‚æ­¥ã€éé˜»å¡ã€å¤ç”¨ pinned ç¼“å†²æ±  |
| **I/O å¹¶è¡Œåº¦** | å•çº¿ç¨‹æˆ–å¤šæ–‡ä»¶ chunkingï¼Œæ˜“å¼•å‘ metadata ç“¶é¢ˆ | å¤šçº¿ç¨‹å¹¶å‘ flushï¼Œæœ€å¤§åŒ– PCIe/PFS åˆ©ç”¨ç‡ |
| **ä¸è®­ç»ƒé‡å ** | æœ‰é™é‡å ï¼Œå¸¸é˜»å¡ update é˜¶æ®µ | å®Œå…¨é‡å äº forward/backwardï¼Œæœ€å°åŒ–å¹²æ‰° |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- ä½¿ç”¨ **OSCAR-en å­é›†**ï¼ˆ79K recordsï¼‰ï¼Œæ¥è‡ª BLOOM é¡¹ç›®å…¬å¼€æ•°æ®é›†ï¼›
- Tokenization ä½¿ç”¨ **Llama 2 tokenizer**ï¼›
- åºåˆ—é•¿åº¦ç»Ÿä¸€è®¾ä¸º **2048**ï¼Œå¾®æ‰¹æ¬¡å¤§å°ä¸º **16**ã€‚

---

### **å®éªŒè®¾ç½®**
#### **å¹³å°ç¯å¢ƒ**
- åœ¨ **ALCF Polaris è¶…ç®—ç³»ç»Ÿ** ä¸Šæµ‹è¯•ï¼š
  - æ¯èŠ‚ç‚¹ï¼š4Ã— NVIDIA A100-40GB GPUï¼ˆNVLinkäº’è”ï¼‰ã€AMD Milan CPUã€512GB DDR4ã€åŒ1.6TBæœ¬åœ°SSDï¼›
  - ç½‘ç»œï¼šPCIe Gen4ï¼ˆD2H å³°å€¼ 25 GB/sï¼‰ã€NVLinkï¼ˆD2D å³°å€¼ 85 GB/sï¼‰ï¼›
  - å­˜å‚¨åç«¯ï¼šLustre PFSï¼ˆå³°å€¼ 650 GB/sï¼‰ã€‚

#### **æ¨¡å‹é…ç½®**
åŸºäº BLOOM å’Œ Llama æ¶æ„æ„å»ºå¤šä¸ªè§„æ¨¡æ¨¡å‹ï¼š
| æ¨¡å‹å¤§å°ï¼ˆBï¼‰ | å±‚æ•° | éšè—ç»´åº¦ | æ³¨æ„åŠ›å¤´æ•° | èŠ‚ç‚¹æ•° | TP | PP | ZeRO Stage |
|--------------|-------|-----------|-------------|--------|----|----|------------|
| 3            | 30    | 2560      | 32          | 1      | 4  | 1  | 1          |
| 7            | 32    | 4096      | 32          | 2      | 4  | 2  | 1          |
| 13           | 40    | 5120      | 40          | 4      | 4  | 4  | 1          |
| 33 / 70      | ...   | ...       | ...         | 8 / 20 | 4  | ...| 1          |

> æ‰€æœ‰å®éªŒé»˜è®¤ **DP=1**ï¼Œé™¤éç‰¹åˆ«ç ”ç©¶ DP æ‰©å±•æ€§ã€‚

#### **å†…å­˜ä¸ç¼“å­˜è®¾ç½®**
- æ¯èŠ‚ç‚¹é¢„ç•™ **80GB pinned host memory** ä½œä¸ºæ£€æŸ¥ç‚¹ç¼“å­˜ï¼›
- æ”¯æŒç¼“å­˜çº¦ä¸€ä¸ªå®Œæ•´æ£€æŸ¥ç‚¹ç‰ˆæœ¬ï¼ˆæ¯GPUçº¦10â€“15GBï¼‰ã€‚

---

### **è¯„ä¼°æŒ‡æ ‡**
1. **Effective Checkpoint Throughput**  
   = æ€»æ£€æŸ¥ç‚¹å¤§å° / è®­ç»ƒè¢«é˜»å¡çš„æ—¶é—´ï¼ˆå«åŒæ­¥åºåˆ—åŒ–ã€ç­‰å¾…åˆ·æ–°ç­‰ï¼‰
2. **Iteration Duration under Checkpointing**  
   åŒ…æ‹¬ç›´æ¥åœæ»ä¸é—´æ¥å¹²æ‰°ï¼ˆå¦‚é€šä¿¡é™é€Ÿï¼‰
3. **End-to-End Training Time**  
   å¤šè½®è¿­ä»£æ€»è€—æ—¶ï¼Œåæ˜ ç´¯ç§¯ I/O å°¾éƒ¨æ•ˆåº”
4. **Per-Phase Breakdown**  
   åˆ†æ metadata/serializeã€GPUâ†’Hostã€Hostâ†’File å„é˜¶æ®µè€—æ—¶

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| æ–¹æ³• | æè¿° |
|------|------|
| **DeepSpeed Default** | ä½¿ç”¨ `torch.save()` åŒæ­¥ä¿å­˜ï¼Œå®Œå…¨é˜»å¡è®­ç»ƒ |
| **TorchSnapshot** | PyTorch å®˜æ–¹å¼‚æ­¥æ£€æŸ¥ç‚¹å·¥å…·ï¼Œæ”¯æŒ chunked I/O å’Œå¤šçº¿ç¨‹å†™å…¥ |
| **DataStates-LLM-Old** | ä½œè€…å‰æœŸå·¥ä½œï¼Œå…·å¤‡éƒ¨åˆ†å¼‚æ­¥èƒ½åŠ›ä½†æ—  State Providers |
| **DataStates-LLM (æœ¬æ–‡)** | å®Œæ•´ç‰ˆï¼Œé›†æˆæ‰€æœ‰ä¼˜åŒ– |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### ğŸ”¹ **æ£€æŸ¥ç‚¹ååæå‡**
- åœ¨ **70B å‚æ•°æ¨¡å‹ã€256 GPU** è§„æ¨¡ä¸‹ï¼š
  - **DataStates-LLM è¾¾åˆ° 3Ã—â€“4.2Ã— æ›´é«˜çš„æ£€æŸ¥ç‚¹ååé‡**ï¼Œç›¸æ¯” TorchSnapshotï¼›
  - ç›¸æ¯”åŸå§‹ DeepSpeedï¼Œé»˜è®¤åŒæ­¥æ–¹æ¡ˆæ…¢æ•°å€ã€‚

#### ğŸ”¹ **ç«¯åˆ°ç«¯è®­ç»ƒæ—¶é—´å‡å°‘**
- åœ¨å¤šç§æ¨¡å‹è§„æ¨¡å’Œ DP è®¾ç½®ä¸‹ï¼š
  - **è®­ç»ƒæ—¶é—´ç¼©çŸ­ 1.3Ã—â€“2.2Ã—**ï¼›
  - åœ¨é«˜é¢‘æ£€æŸ¥ç‚¹åœºæ™¯ï¼ˆæ¯ iteration ä¸€æ¬¡ï¼‰ï¼Œä¼˜åŠ¿æ›´æ˜¾è‘—ã€‚

#### ğŸ”¹ **å•æ¬¡æ£€æŸ¥ç‚¹å„é˜¶æ®µè€—æ—¶åˆ†è§£ï¼ˆ7B æ¨¡å‹ï¼Œå• rankï¼‰**
| é˜¶æ®µ | DeepSpeed | TorchSnapshot | DataStates-LLM |
|------|-----------|---------------|----------------|
| Metadata/Serialize | 3.9 sec | 0.0258 sec | **0.0156 sec** |
| GPUâ†’Host | 1.9 sec | 1.3 sec | **0.6 sec** |
| Hostâ†’File | 16.1 sec | 11.5 sec | **3.8 sec** |

> âœ… **åºåˆ—åŒ–æ—¶é—´é™ä½ 1.65Ã—**ï¼Œå¾—ç›Šäº State Providers çš„é€‰æ‹©æ€§åºåˆ—åŒ–ï¼›  
> âœ… **D2H æ—¶é—´é™ä½ 2.17Ã—**ï¼Œå› å¼‚æ­¥ DMA + pinned ç¼“å†²æ± ï¼›  
> âœ… **Hostâ†’File æ—¶é—´é™ä½ 3Ã—**ï¼Œå½’åŠŸäº liburing åŠ é€Ÿä¸å¤šçº¿ç¨‹ flushã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

#### ğŸ“ˆ å›¾7ï¼šä¸åŒæ¨¡å‹è§„æ¨¡ä¸‹çš„èšåˆæ£€æŸ¥ç‚¹åå
- æ‰€æœ‰æ–¹æ³•éšæ¨¡å‹å¢å¤§è€Œæå‡ï¼ˆæ›´å¤šèŠ‚ç‚¹ â†’ æ›´é«˜å¹¶è¡Œåº¦ï¼‰ï¼›
- **DataStates-LLM å§‹ç»ˆé¢†å…ˆ**ï¼Œåœ¨ 70B æ¨¡å‹ä¸Šè¾¾ **~422 GB/s**ï¼Œæ˜¯ TorchSnapshot çš„è¿‘ **4Ã—**ã€‚

#### ğŸ“‰ å›¾8 & å›¾9ï¼šè¿­ä»£æ—¶é—´å’Œç«¯åˆ°ç«¯è®­ç»ƒæ—¶é—´
- å°æ¨¡å‹ï¼ˆ3B/7Bï¼‰ä¸­ï¼Œä¼ ç»Ÿæ–¹æ³•æ£€æŸ¥ç‚¹æ—¶é—´è¿œè¶…è®­ç»ƒæ—¶é—´ï¼›
- **DataStates-LLM å°†æ£€æŸ¥ç‚¹å¼€é”€é™è‡³å¯å¿½ç•¥æ°´å¹³**ï¼Œè¿­ä»£å‡ ä¹ä¸å—å½±å“ï¼›
- ç«¯åˆ°ç«¯æ—¶é—´åœ¨ 15 æ¬¡è¿­ä»£ä¸­æœ€å¤šå‡å°‘ **2.2Ã—**ã€‚

#### ğŸ“Š å›¾10â€“11ï¼šå¢åŠ æ•°æ®å¹¶è¡Œåº¦ï¼ˆDPï¼‰çš„å½±å“
- å½“ DP ä» 1 æ‰©å±•è‡³ 16ï¼š
  - æ¯ rank æ£€æŸ¥ç‚¹ä½“ç§¯å‡å°ï¼ˆZeRO-1 åˆ†ç‰‡ï¼‰ï¼›
  - ä½†æ–‡ä»¶æ•°é‡å‰§å¢ï¼ŒåŠ å‰§ metadata å‹åŠ›ï¼›
- **DataStates-LLM ä»ä¿æŒç¨³å®šæ€§èƒ½**ï¼Œè€Œå…¶ä»–æ–¹æ³•æ‰©å±•æ€§å·®ï¼›
- åœ¨ 13B æ¨¡å‹ + DP=16 ä¸‹ï¼Œ**è®­ç»ƒæ—¶é—´ä»…ä¸º TorchSnapshot çš„ 1/5.7**ã€‚

#### â±ï¸ å›¾13ï¼šä¸åŒæ£€æŸ¥ç‚¹é¢‘ç‡ä¸‹çš„è¡¨ç°
- å³ä½¿æ¯ **2 ä¸ª iteration æ£€æŸ¥ä¸€æ¬¡**ï¼ŒDataStates-LLM çš„ 50 è¿­ä»£æ€»æ—¶é—´ä»ä¼˜äº TorchSnapshot æ¯ **10 æ¬¡æ‰æ£€æŸ¥ä¸€æ¬¡** çš„æƒ…å†µï¼›
- è¡¨æ˜å…¶èƒ½æ”¯æŒ **æé«˜é¢‘æ£€æŸ¥ç‚¹**ï¼ˆé€‚ç”¨äº RLHFã€è½¨è¿¹åˆ†æç­‰åœºæ™¯ï¼‰ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### ğŸ” **å­æ“ä½œæ‹†è§£ï¼ˆTable IIIï¼‰**
- **State Providers æ˜¾è‘—é™ä½å…ƒæ•°æ®å¤„ç†å»¶è¿Ÿ**ï¼›
- **é¢„åˆ†é… + pinned ç¼“å†²æ± æå¤§åŠ é€Ÿ D2H**ï¼›
- **liburing å¤šçº¿ç¨‹ flush æå‡ Hostâ†’File æ•ˆç‡**ã€‚

#### ğŸ”¬ **I/O å¾®åŸºå‡†æµ‹è¯•ï¼ˆFigure 14ï¼‰**
- æµ‹è¯•å•ä¸€èŠ‚ç‚¹ä¸Šå¤šä¸ª rank å¹¶å‘å†™å…¥å¼ é‡ï¼š
  - **DataStates-LLM åœ¨å„ç§å¼ é‡å¤§å°ä¸‹å‡æ¯” TorchSnapshot å¿« 1.25Ã—â€“2.5Ã—**ï¼›
  - æ¥è¿‘ç†è®ºå³°å€¼ï¼ˆâ€œidealâ€ host-only åŸºçº¿ï¼‰ã€‚

#### ğŸ”„ **å¤šçº§ä¼ è¾“æµæ°´çº¿å¯è§†åŒ–ï¼ˆFigure 15ï¼‰**
- å±•ç¤º 7B æ¨¡å‹ä¸­æœ€å¤§å‡ ä¸ªå¼ é‡çš„ä¼ è¾“æ—¶é—´çº¿ï¼š
  - GPUâ†’Host ä¸ Hostâ†’File å®Œå…¨é‡å ï¼›
  - å¤šä¸ªå¼ é‡å¹¶è¡Œ flush åˆ°ä¸åŒæ–‡ä»¶ï¼›
  - å®ç°çœŸæ­£çš„ **streaming multi-tier I/O pipeline**ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **3D å¼‚æ„æ€§æ˜¯ LLM æ£€æŸ¥ç‚¹çš„æ ¸å¿ƒæŒ‘æˆ˜**ï¼Œå¿…é¡»æ˜¾å¼å»ºæ¨¡è€Œéå½“ä½œé»‘ç›’å¤„ç†ï¼›
2. **è®­ç»ƒè¿­ä»£ä¸­çš„ immutability ç‰¹æ€§å¯è¢«å……åˆ†åˆ©ç”¨** æ¥å®ç°éé˜»å¡å¿«ç…§ï¼›
3. **åˆ†ç¦»å…³æ³¨ç‚¹ï¼ˆstate abstraction vs. data movementï¼‰è‡³å…³é‡è¦**ï¼ŒState Providers æ˜¯å®ç°é«˜æ•ˆå¼‚æ„ç®¡ç†çš„å…³é”®ï¼›
4. **åºåˆ—åŒ–ä¸åº”æˆä¸ºç“¶é¢ˆ**ï¼Œåº”ç»•è¿‡å¼ é‡çš„å†—ä½™åºåˆ—åŒ–ï¼Œå¹¶è®©å°å¯¹è±¡åºåˆ—åŒ–ä¸ I/O é‡å ï¼›
5. **ç°ä»£ I/O æŠ€æœ¯ï¼ˆå¦‚ liburingï¼‰+ å¤šçº¿ç¨‹ flush å¯æ˜¾è‘—æå‡æŒä¹…åŒ–å¸¦å®½åˆ©ç”¨ç‡**ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–è¶³å¤Ÿå¤§çš„ host memory ç¼“å†²æ± **ï¼ˆæœ¬å®éªŒä½¿ç”¨ 80GB/nodeï¼‰ï¼Œåœ¨å†…å­˜å—é™ç¯å¢ƒä¸­å¯èƒ½éš¾ä»¥éƒ¨ç½²ï¼›
- **å½“å‰æœªæ•´åˆå‹ç¼©æˆ–å·®åˆ†æ£€æŸ¥ç‚¹**ï¼Œå¯¹äºæé«˜é¢‘ç‡åœºæ™¯ä»æœ‰ä¼˜åŒ–ç©ºé—´ï¼›
- **æœªè§£å†³ PFS metadata server ç“¶é¢ˆçš„æ ¹æœ¬é—®é¢˜**ï¼Œè™½ç„¶é€šè¿‡å‡å°‘å°æ–‡ä»¶ç«äº‰ç¼“è§£ï¼Œä½†ä»å—æ–‡ä»¶ç³»ç»Ÿé™åˆ¶ï¼›
- **ç›®å‰ä»…é›†æˆäº DeepSpeed**ï¼Œè™½æ¨¡å—åŒ–è®¾è®¡æ”¯æŒè¿ç§»ï¼Œä½†é€‚é…å…¶ä»–æ¡†æ¶éœ€é¢å¤–å¼€å‘ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **å¼•å…¥æ•°æ®ç¼©å‡æŠ€æœ¯**ï¼š
   - å·®åˆ†æ£€æŸ¥ç‚¹ï¼ˆdifferential checkpointingï¼‰
   - å¼ é‡å‹ç¼©ï¼ˆcompressionï¼‰
2. **æ”¯æŒæ›´æ·±çš„å†…å­˜å±‚çº§**ï¼š
   - Offload model/optimizer states è‡³ NVMe æˆ–è¿œç¨‹å­˜å‚¨
3. **Shard èšåˆä¸åˆå¹¶ç­–ç•¥**ï¼š
   - å‡å°‘æ–‡ä»¶æ•°é‡ä»¥ç¼“è§£ PFS metadata å‹åŠ›ï¼ŒåŒæ—¶ä¿ç•™å¹¶è¡Œå†™å…¥èƒ½åŠ›
4. **åŠ¨æ€èµ„æºè°ƒåº¦ä¸è‡ªé€‚åº”ç¼“å†²ç®¡ç†**
5. **æ‰©å±•è‡³æ¨ç†å’ŒæœåŠ¡åœºæ™¯çš„å¿«é€Ÿæ¢å¤**

--- 

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **DataStates-LLM é€šè¿‡å¼•å…¥ State Providers å’Œ lazy asynchronous I/O pipelineï¼Œåœ¨ä¸æ‰°åŠ¨è®­ç»ƒçš„å‰æä¸‹å®ç°äº†é«˜è¾¾ 4Ã— çš„æ£€æŸ¥ç‚¹ååæå‡å’Œ 2.2Ã— çš„ç«¯åˆ°ç«¯è®­ç»ƒåŠ é€Ÿï¼Œä¸ºæç«¯è§„æ¨¡ LLM è®­ç»ƒæä¾›äº†é«˜æ•ˆçš„å®¹é”™ä¸è°ƒè¯•åŸºç¡€è®¾æ–½ã€‚**

</details>

---

### 2. [When Agents Fail to Act: A Diagnostic Framework for Tool Invocation Reliability in Multi-Agent LLM Systems](https://arxiv.org/abs/2601.16280)

**Authors**: Donghao Huang, Gauri Malwe, Zhaoxia Wang  
**Category**: cs.AI  
**Published**: 2026-01-26  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.16280v1  

#### Abstract
Multi-agent systems powered by large language models (LLMs) are transforming enterprise automation, yet systematic evaluation methodologies for assessing tool-use reliability remain underdeveloped. We introduce a comprehensive diagnostic framework that leverages big data analytics to evaluate proced...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“  
**è®ºæ–‡æ ‡é¢˜**ï¼š*When Agents Fail to Act: A Diagnostic Framework for Tool Invocation Reliability in Multi-Agent LLM Systems*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰å¤šæ™ºèƒ½ä½“ LLM ç³»ç»Ÿåœ¨ä¼ä¸šè‡ªåŠ¨åŒ–ä¸­å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä½†å…¶**å·¥å…·è°ƒç”¨çš„ç¨‹åºå¯é æ€§ï¼ˆprocedural reliabilityï¼‰ç¼ºä¹ç³»ç»Ÿæ€§è¯„ä¼°æ–¹æ³•**ã€‚ç°æœ‰ç ”ç©¶å¤šä¾èµ–èšåˆæŒ‡æ ‡ï¼ˆå¦‚ä»»åŠ¡æˆåŠŸç‡ï¼‰ï¼Œæ— æ³•æ­ç¤ºå¤±è´¥çš„æ ¹æœ¬åŸå› ï¼Œå°¤å…¶åœ¨å¤šæ™ºèƒ½ä½“åä½œåœºæ™¯ä¸‹ï¼Œé”™è¯¯ä¼šçº§è”ä¼ æ’­ï¼Œå¯¼è‡´éƒ¨ç½²ä¸å¯é ã€‚

è¯¥è®ºæ–‡èšç„¦äºï¼š
- å·¥å…·åˆå§‹åŒ–ã€å‚æ•°ä¼ é€’ã€æ‰§è¡Œä¸ç»“æœè§£é‡Šè¿‡ç¨‹ä¸­çš„**ç»†ç²’åº¦æ•…éšœè¯Šæ–­**
- é¢å‘ä¸­å°ä¼ä¸šï¼ˆSMEsï¼‰åœ¨éšç§æ•æ„Ÿã€èµ„æºå—é™ç¯å¢ƒä¸‹çš„å®é™…éƒ¨ç½²æŒ‘æˆ˜

---

### ğŸ› ï¸ æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯

#### ï¼ˆ1ï¼‰**12ç±»é”™è¯¯åˆ†ç±»æ³•ï¼ˆ12-category error taxonomyï¼‰**
é¦–æ¬¡å°†å•æ™ºèƒ½ä½“å·¥å…·ä½¿ç”¨é”™è¯¯åˆ†ææ‰©å±•åˆ°**å¤šæ™ºèƒ½ä½“åè°ƒåœºæ™¯**ï¼Œç»“åˆï¼š
- **4ç§é”™è¯¯ç±»å‹**ï¼š
  - `Not Initialized`ï¼ˆæœªæ­£ç¡®è°ƒç”¨ï¼‰
  - `Arguments Mismatch`ï¼ˆå‚æ•°ä¸åŒ¹é…ï¼‰
  - `Error`ï¼ˆè¿è¡Œæ—¶å¼‚å¸¸ï¼‰
  - `Result Mismatch`ï¼ˆè¾“å‡ºå¯¼è‡´ä¸‹æ¸¸å¤±è´¥ï¼‰
- **3ç±»å·¥å…·æ“ä½œ**ï¼š
  - OCR_TOOL
  - DB_QUERY_TOOL
  - DB_UPDATE_TOOL  
â†’ å½¢æˆ **12ä¸ªè¯Šæ–­ç±»åˆ«**ï¼Œå®ç°å¯¹å·¥å…·è°ƒç”¨å…¨è¿‡ç¨‹çš„ç²¾ç»†åŒ–å½’å› ã€‚

#### ï¼ˆ2ï¼‰**å¯å¤ç°çš„è¯„ä¼°åŸºç¡€è®¾æ–½**
æ„å»ºæ ‡å‡†åŒ–æµ‹è¯•æ¡†æ¶ï¼Œæ”¯æŒè·¨æ¨¡å‹ã€è·¨ç¡¬ä»¶å¹³å°æ¯”è¾ƒï¼š
- æ”¯æŒ open-weight æ¨¡å‹ï¼ˆQwen2.5ç³»åˆ—ã€Functionaryï¼‰ä¸ closed-source æ¨¡å‹ï¼ˆGPT-4, Claude 3.5/3.7ï¼‰
- åœ¨å¤šç§è¾¹ç¼˜è®¾å¤‡ä¸Šæµ‹è¯•ï¼ˆNVIDIA RTX A6000 / RTX 4090 / Apple M3 Maxï¼‰
- ä½¿ç”¨ **4-bité‡åŒ–**ï¼ˆQ4_K_Mï¼‰æ¨¡æ‹ŸçœŸå®è¾¹ç¼˜éƒ¨ç½²æ¡ä»¶

#### ï¼ˆ3ï¼‰**å¯é æ€§é˜ˆå€¼è¯†åˆ«ä¸éƒ¨ç½²å»ºè®®**
é€šè¿‡å¤§è§„æ¨¡å®éªŒè¯†åˆ«å‡ºå…³é”®å®¹é‡é˜ˆå€¼ï¼Œä¸ºç»„ç»‡æä¾›åŸºäºæˆæœ¬-æ€§èƒ½æƒè¡¡çš„éƒ¨ç½²æŒ‡å—ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | æœ¬æ–‡æ–¹æ³• |
|------|--------|---------|
| è¯„ä¼°ç²’åº¦ | èšåˆæˆåŠŸç‡ï¼ˆSuccess Rate onlyï¼‰ | ç»†ç²’åº¦é”™è¯¯å½’å› ï¼ˆ12ç±»é”™è¯¯åˆ†å¸ƒï¼‰ |
| åœºæ™¯è¦†ç›– | å•æ™ºèƒ½ä½“ä¸ºä¸» | å¤šæ™ºèƒ½ä½“ååŒ + å·¥å…·é“¾è·¯çº§è” |
| å¯å¤ç°æ€§ | å°‘æ•°é—­æºAPIåŸºå‡† | å¼€æºä»£ç ã€æ•°æ®é›†ã€åè®®å…¨å…¬å¼€ï¼ˆGitHubï¼‰ |
| éƒ¨ç½²æŒ‡å¯¼ | ç¼ºä¹ç¡¬ä»¶é€‚é…å»ºè®® | æä¾› tiered deployment recommendations |

> âœ… æ‰€æœ‰èµ„æºå·²å¼€æºï¼šhttps://github.com/inflaton/df4tir

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
- æ„å»ºäº†ä¸€ä¸ª**åˆæˆçš„å‘ç¥¨å¯¹è´¦ï¼ˆinvoice reconciliationï¼‰æ•°æ®é›†**ï¼Œå…± **1,980ä¸ªç¡®å®šæ€§æµ‹è¯•å®ä¾‹**
  - è§†è§‰ä»»åŠ¡ï¼ˆvision-enabledï¼‰ï¼š990ä¾‹ï¼ˆå«PDFæ‰«æä»¶éœ€OCRå¤„ç†ï¼‰
  - çº¯æ–‡æœ¬ä»»åŠ¡ï¼ˆtext-onlyï¼‰ï¼š990ä¾‹
- æ•°æ®è®¾è®¡è´´è¿‘çœŸå®ä¸šåŠ¡æµç¨‹ï¼Œæ¶‰åŠå¤šæ¨¡æ€è¾“å…¥ã€æ•°æ®åº“æŸ¥è¯¢ä¸æ›´æ–°ç­‰å…¸å‹ä¼ä¸šæ“ä½œ

---

### âš™ï¸ å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### æ¨¡å‹é€‰æ‹©
| ç±»å‹ | æ¨¡å‹åˆ—è¡¨ |
|------|--------|
| **Closed-Source** | `gpt-4o`, `gpt-4.1`, `claude-3-5-sonnet`, `claude-3-7-sonnet` ç­‰ |
| **Open-Weight** | `qwen2.5:3b` åˆ° `qwen2.5:72b`ï¼Œ`functionary-small`/`medium` |

#### éƒ¨ç½²é…ç½®
- Open-weight æ¨¡å‹ä½¿ç”¨ **Ollama v0.6.8** æœ¬åœ°è¿è¡Œ
- é‡‡ç”¨ **4-bit quantization (Q4_K_M)** å‡å°‘å†…å­˜å ç”¨
- æµ‹è¯•å¹³å°ï¼š
  - NVIDIA RTX A6000ï¼ˆ48GB VRAMï¼‰
  - RTX 4090 Laptop GPUï¼ˆ16GBï¼‰
  - Apple M3 Maxï¼ˆ96GBç»Ÿä¸€å†…å­˜ï¼‰

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **SR (Success Rate)** | æœ€ç»ˆä»»åŠ¡å®Œæˆç‡ |
| **Execution Time** | å¹³å‡å“åº”å»¶è¿Ÿï¼ˆç§’ï¼‰ |
| **Process Steps** | å®Œæˆä»»åŠ¡æ‰€éœ€çš„å¹³å‡æ­¥éª¤æ•° |
| **OCR F1 Score** | OCRç»“æœè§£æå‡†ç¡®ç‡ |
| **Deterministic Setting** | æ¸©åº¦=0ï¼Œå›ºå®špromptï¼Œç¡®ä¿å¯å¤ç° |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline 1**: å½“å‰ä¸»æµé—­æºæ¨¡å‹ï¼ˆGPT-4.1, Claude 3.7ï¼‰ä½œä¸ºæ€§èƒ½ä¸Šé™å‚è€ƒ
- **Baseline 2**: Kokane et al. çš„ SpecToolï¼ˆä»…é€‚ç”¨äºå•æ™ºèƒ½ä½“ï¼‰
- **Baseline 3**: åŠŸèƒ½ç›¸ä¼¼ä½†è§„æ¨¡è¾ƒå°çš„ open-weight æ¨¡å‹ï¼ˆå¦‚ Functionaryï¼‰

> æœ¬å·¥ä½œæ˜¯é¦–ä¸ªåœ¨**ç›¸åŒä»»åŠ¡ã€ç›¸åŒåè®®ä¸‹æ¨ªå‘æ¯”è¾ƒ open/closed LLMs åœ¨ multi-agent setting ä¸­ tool-use reliability** çš„ç ”ç©¶ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

| æ¨¡å‹ | å¹³å° | æˆåŠŸç‡ (SR%) | å»¶è¿Ÿ (Time/s) | æ­¥éª¤æ•° (Steps) |
|------|------|-------------|--------------|---------------|
| `qwen2.5:32b` | RTX A6000 | **100.0%** | 13.9 | 8.5 |
| `qwen2.5:14b` | RTX A6000 | **96.6%** | **7.3** | 8.6 |
| `qwen2.5:7b` | RTX A6000 | 57.3% | 9.9 | 20.7 |
| `qwen2.5:3b` | RTX A6000 | 13.9% | 8.1 | 18.8 |
| `gpt-4.1` | OpenAI | **100.0%** | 8.3 | 9.9 |
| `gpt-4o-mini` | OpenAI | 99.3% | 7.6 | 8.6 |
| `functionary-small` | RTX A6000 | 7.5% | 4.0 | 5.6 |

> âœ… `qwen2.5:32b` å®ç° **100% æˆåŠŸç‡**ï¼Œä¸ `gpt-4.1` æŒå¹³  
> âœ… `qwen2.5:14b` è¾¾åˆ° **96.6%-97.4%** æˆåŠŸç‡ï¼Œåœ¨æ€§ä»·æ¯”ä¸å¯é æ€§ä¹‹é—´å–å¾—æœ€ä½³å¹³è¡¡

---

### ğŸ” é”™è¯¯æ¨¡å¼åˆ†å¸ƒï¼ˆæ¥è‡ª Tables II & IIIï¼‰

| é”™è¯¯ç±»å‹ | å°æ¨¡å‹è¡¨ç°ï¼ˆe.g., qwen2.5:3bï¼‰ | å¤§æ¨¡å‹è¡¨ç°ï¼ˆe.g., qwen2.5:32b / GPT-4.1ï¼‰ |
|--------|-------------------------------|----------------------------------------|
| `DB_UPDATE_TOOL_NOT_INITIALIZED` | é«˜è¾¾ 881 æ¬¡ï¼ˆå éè§†è§‰ä»»åŠ¡ 76.36%ï¼‰ | **0æ¬¡** |
| `DB_QUERY_TOOL_NOT_INITIALIZED` | æ•°ç™¾æ¬¡å‘ç”Ÿ | **0æ¬¡** |
| å‚æ•°/ç»“æœé”™è¯¯ | è¾ƒå°‘ | æå°‘ |

> ğŸ”´ **å·¥å…·åˆå§‹åŒ–å¤±è´¥æ˜¯ä¸»è¦ç“¶é¢ˆ**ï¼Œè€Œéå‚æ•°é”™è¯¯æˆ–è¾“å‡ºè¯¯è§£

---

### ğŸ”„ æ¶ˆèå®éªŒä¸å…³é”®è§‚å¯Ÿï¼ˆAblation Insightsï¼‰

#### ï¼ˆ1ï¼‰æ¨¡å‹è§„æ¨¡å½±å“æ˜¾è‘—
- æˆåŠŸç‡éšå‚æ•°é‡å¢åŠ è€Œæå‡ï¼Œå‘ˆæ˜æ˜¾æ­£ç›¸å…³
- å­˜åœ¨â€œ**ä¸´ç•Œé˜ˆå€¼**â€ï¼š
  - **14B** æ˜¯æœ€å°å¯è¡Œç”Ÿäº§é…ç½®ï¼ˆ>96.6% SRï¼‰
  - **32B** å®ç°é—­æºæ¨¡å‹çº§å¯é æ€§ï¼ˆ100% SRï¼‰
  - **72B** åè€Œç•¥é™ï¼ˆ95.1%ï¼‰ï¼Œæ˜¾ç¤ºä»»åŠ¡ç‰¹å®šå®¹é‡æé™

#### ï¼ˆ2ï¼‰ç¡¬ä»¶å¯¹æ€§èƒ½å½±å“å·¨å¤§
- `qwen2.5:14b` åœ¨ RTX A6000 ä¸Šè€—æ—¶ **7.3s**ï¼Œè€Œåœ¨ M3 Max ä¸Šé«˜è¾¾ **60.0s** â†’ **8.2å€å»¶è¿Ÿå·®å¼‚**
- æ›´å¼ºç¡¬ä»¶ä¸èƒ½å¼¥è¡¥å°æ¨¡å‹ç¼ºé™·ï¼š`qwen2.5:7b` åœ¨ M3 Max ä¸Šä»éœ€ **85.9s**ï¼Œä¸”å¹³å‡æ­¥æ•°è¾¾ **20.7**

#### ï¼ˆ3ï¼‰è§„åˆ’æ•ˆç‡éšæ¨¡å‹å¢å¤§æ”¹å–„
- å°æ¨¡å‹æ˜“é™·å…¥å¾ªç¯å†³ç­–ï¼ˆrecursion limit è¢«è§¦å‘ï¼‰
- å¤§æ¨¡å‹æ›´å€¾å‘äºç›´æ¥è°ƒç”¨å·¥å…·ï¼Œå‡å°‘å†—ä½™æ¨ç†è·¯å¾„

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **å·¥å…·åˆå§‹åŒ–å¤±è´¥æ˜¯æœ€å¤§ç“¶é¢ˆ**
   - ç‰¹åˆ«æ˜¯åœ¨å°æ¨¡å‹ä¸­ï¼ˆå¦‚ `qwen2.5:3b` è¶…è¿‡ 89% çš„é”™è¯¯æºäºæ­¤ï¼‰
   - è¡¨æ˜æ¨¡å‹ç¼ºä¹â€œä½•æ—¶è°ƒç”¨å·¥å…·â€çš„å…ƒè®¤çŸ¥èƒ½åŠ›

2. **å­˜åœ¨æ˜ç¡®çš„å¯é æ€§é˜ˆå€¼**
   - `qwen2.5:14b` æ˜¯**æœ€å°å¯è¡Œç”Ÿäº§é…ç½®**ï¼ˆ96.6â€“97.4% æˆåŠŸç‡ï¼‰
   - `qwen2.5:32b` å®ç°ä¸ `GPT-4.1` ç›¸å½“çš„**é›¶é”™è¯¯è¡¨ç°**

3. **å¼€æ”¾æƒé‡æ¨¡å‹å¯åœ¨ç‰¹å®šè§„æ¨¡ä¸‹åª²ç¾é—­æºæ¨¡å‹**
   - `qwen2.5:32b` åœ¨å·¥å…·è°ƒç”¨å¯é æ€§æ–¹é¢è¾¾åˆ° GPT-4.1 æ°´å¹³
   - ä¸ºéšç§æ•æ„Ÿè¡Œä¸šï¼ˆå¦‚é‡‘èï¼‰æä¾›å¯ä¿¡æ›¿ä»£æ–¹æ¡ˆ

4. **ç¡¬ä»¶é€‰æ‹©æå¤§å½±å“å»¶è¿Ÿ**
   - åŒä¸€æ¨¡å‹åœ¨ä¸åŒå¹³å°ä¸Šå»¶è¿Ÿç›¸å·® **8.2å€**
   - æ¨èæ­é…é«˜æ€§èƒ½ GPUï¼ˆå¦‚ RTX A6000ï¼‰ä»¥ä¼˜åŒ–æ¨ç†æ•ˆç‡

5. **æ¨¡å‹å¤§å° â‰  æ€»æ˜¯æ›´å¥½**
   - `qwen2.5:72b` æˆåŠŸç‡ä½äº `32b`ï¼Œè¡¨æ˜å­˜åœ¨ä»»åŠ¡é€‚é…çš„â€œç”œç‚¹åŒºâ€

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

| å±€é™ | è¯´æ˜ |
|------|------|
| **é¢†åŸŸé™åˆ¶** | å½“å‰éªŒè¯é›†ä¸­åœ¨å‘ç¥¨å¯¹è´¦è¿™ä¸€ç»“æ„åŒ–ä¸šåŠ¡æµç¨‹ï¼Œæ˜¯å¦æ³›åŒ–è‡³å…¶ä»–é¢†åŸŸå¾…éªŒè¯ |
| **é™æ€ä»»åŠ¡æµ** | ä½¿ç”¨ç¡®å®šæ€§ prompt å’Œå›ºå®šæµç¨‹ï¼Œæœªæ¶µç›–åŠ¨æ€å¤æ‚ä»»åŠ¡åˆ†è§£ |
| **åˆæˆæ•°æ®åå·®** | æ•°æ®è™½æ¨¡ä»¿ç°å®ï¼Œä½†ä»ä¸ºåˆæˆç”Ÿæˆï¼Œå¯èƒ½å­˜åœ¨ç†æƒ³åŒ–å€¾å‘ |
| **ç¼ºå°‘å®¹é”™æœºåˆ¶æµ‹è¯•** | æœªé›†æˆè‡ªåŠ¨é‡è¯•ã€fallback ç­–ç•¥ç­‰å·¥ç¨‹å¢å¼ºæ‰‹æ®µ |

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘ï¼ˆä½œè€…æå‡ºï¼‰

1. **å¯¹æŠ—æ€§ä¸è´Ÿæ ·æœ¬åè®®è®¾è®¡**  
   å¼•å…¥æ›´å…·æŒ‘æˆ˜æ€§çš„ edge cases å’Œ adversarial prompts æ¥æµ‹è¯•é²æ£’æ€§

2. **åˆ†å¸ƒå¼æ•…éšœåˆ†æ**  
   æ‰©å±•æ¡†æ¶ä»¥æ”¯æŒè·¨å¤šä¸ªèŠ‚ç‚¹ã€å¼‚æ„ä»£ç†ç³»ç»Ÿçš„è”åˆè¯Šæ–­

3. **è‡ªæ„ˆå‹æ™ºèƒ½ä½“æ¶æ„ï¼ˆself-healing agent architecturesï¼‰**  
   åŸºäºé”™è¯¯åˆ†ç±»åŠ¨æ€è°ƒæ•´ç­–ç•¥ï¼Œå®ç°è‡ªåŠ¨æ¢å¤

4. **è·¨é¢†åŸŸéªŒè¯**  
   å°†æ¡†æ¶åº”ç”¨äºæ³•å¾‹ã€åŒ»ç–—ã€ä¾›åº”é“¾ç­‰å…¶ä»–é«˜é£é™©è¡Œä¸šåœºæ™¯

---

## âœ… æ€»ç»“ä¸€å¥è¯

> æœ¬æ–‡æå‡ºäº†é¦–ä¸ªé¢å‘å¤šæ™ºèƒ½ä½“ LLM ç³»ç»Ÿçš„**ç»†ç²’åº¦å·¥å…·è°ƒç”¨å¯é æ€§è¯Šæ–­æ¡†æ¶**ï¼Œæ­ç¤ºäº†**å·¥å…·åˆå§‹åŒ–å¤±è´¥æ˜¯å°æ¨¡å‹çš„ä¸»è¦ç“¶é¢ˆ**ï¼Œå¹¶é€šè¿‡å¤§è§„æ¨¡å®éªŒè¯æ˜ï¼š**qwen2.5:14b æ˜¯æ€§ä»·æ¯”æœ€ä¼˜çš„ç”Ÿäº§çº§ open-weight æ¨¡å‹ï¼Œè€Œ qwen2.5:32b å¯å®ç°ä¸ GPT-4.1 ç›¸å½“çš„é›¶é”™è¯¯è¡¨ç°**ï¼Œä¸ºèµ„æºå—é™ç»„ç»‡æä¾›äº†å¯é ã€å¯æ§ã€å¯å®¡è®¡çš„æ™ºèƒ½ä½“éƒ¨ç½²è·¯å¾„ã€‚

</details>

---

### 3. [LongCat-Flash-Thinking-2601 Technical Report](https://arxiv.org/abs/2601.16725)

**Authors**: Meituan LongCat Team, Anchun Gui, Bei Li, Bingyang Tao, Bole Zhou, Borun Chen, Chao Zhang, Chao Zhang, Chen Gao, Chen Zhang, Chengcheng Han, Chenhui Yang, Chuyu Zhang, Cong Chen, Cunguang Wang, Daoru Pan, Defei Bu, Dengchang Zhao, Di Xiu, Dishan Liu, Dongyu Ru, Dunwei Tu, Fan Wu, Fengcheng Yuan, Fengcun Li, Gang Xu, Guanyu Wu, Guoyuan Lin, Haibin Wang, Hansi Yang, Hao Yang, Haonan Yan, Haoxiang Ma, Haoxing Wen, Hongyan Hao, Hongyin Tang, Hongyu Zang, Hongzhi Ni, Hui Su, Jiacheng Zhang, Jiahong Zhou, Jiahuan Li, Jiaming Wang, Jian Yang, Jianfei Zhang, Jianhao Xu, Jianing Wang, Jiapeng Zhu, Jiaqi Sun, Jiarong Shi, Jiarui Zhao, Jingang Wang, Jinluan Yang, Jinrui Ding, Jinwei Xiao, Jiyuan He, Juncan Xu, Kefeng Zhang, Keheng Wang, Li Wei, Lianhui Ma, Lin Qiu, Lingbing Kong, Lingchuan Liu, Linsen Guo, Mengshen Zhu, Mengxia Shen, Mingyang Zhu, Peiguang Li, Peng Pei, Pengcheng Jia, Pengtao Zhang, Peng Zhao, Qi Gu, Qiong Huang, Qiyuan Duan, Quanchi Weng, Rongxiang Weng, Rongzhi Zhang, Rumei Li, Shanglin Lei, Shengnan An, Shijun Dai, Shuaikang Liu, Shuang Zhou, Shuo Wang, Songyuan Zhao, Tao Liang, Tianhao Hu, Tianze Chen, Wei Liu, Wei Shi, Wei Wang, Weifeng Tang, Wenjie Shi, Wenlong Zhu, Wentao Chen, Wentao Shi, Xi Su, Xiangcheng Liu, Xiandi Ma, Xiangyu Xi, Xiangyuan Liu, Xiangzhou Huang, Xiao Liu, Xiaodong Cai, Xiaolong Chen, Xiaowei Shi, Xiaoyu Li, Xin Chen, Xingchen Liu, Xuan Huang, Xuezhi Cao, Xunliang Cai, Yan Chen, Yang Bai, Yang Liu, Yang Yang, Yang Zheng, Yaoming Wang, Yaoming Zhu, Yaqi Huo, Yanyu Chen, Yaorui Shi, Yerui Sun, Yi Zhang, Yihao Chen, Yi-Kai Zhang, Yifan Lu, Yifan Zhao, Yitao Zhai, Yongjing Yin, Yongwei Zhou, Youshao Xiao, Yuchuan Dai, Yuchen Xie, Yuchen Yu, Yufei Zhang, Yuhuai Wei, Yulei Qian, Yunfan Liang, Yunke Zhao, Yuwei Jiang, Yuxin Bian, Yuxin Chen, Yuxin Liu, Yue Xu, Yueqing Sun, Zeyang Yu, Zhao Yang, Zhengsheng Huang, Zhengyu Chen, Zhijian Liu, Zhikang Xia, Zhimin Lin, Zhiyuan Yao, Zhuofan Chen, Zhuowen Han, Zijian Zhang, Ziran Li, Ziwen Wang, Ziyuan Zhuang  
**Category**: cs.AI  
**Published**: 2026-01-26  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.16725v1  

#### Abstract
We introduce LongCat-Flash-Thinking-2601, a 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model with superior agentic reasoning capability. LongCat-Flash-Thinking-2601 achieves state-of-the-art performance among open-source models on a wide range of agentic benchmarks, includi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# LongCat-Flash-Thinking-2601 Technical Report æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å½“å‰**agentic reasoningï¼ˆä»£ç†å¼æ¨ç†ï¼‰æ¨¡å‹åœ¨å¤æ‚ç°å®ä»»åŠ¡ä¸­æ³›åŒ–èƒ½åŠ›å¼±ã€é²æ£’æ€§å·®ã€è®­ç»ƒæ•ˆç‡ä½**çš„é—®é¢˜ã€‚å…·ä½“æŒ‘æˆ˜åŒ…æ‹¬ï¼š
- **çœŸå®ä¸–ç•Œç¯å¢ƒçš„ä¸å®Œç¾æ€§**ï¼šå·¥å…·è°ƒç”¨å¤±è´¥ã€è¿”å›å™ªå£°ã€ç”¨æˆ·æŒ‡ä»¤æ¨¡ç³Šç­‰ã€‚
- **é•¿ç¨‹äº¤äº’ä¸å¤šè½®å†³ç­–**ï¼šä¼ ç»Ÿæ¨¡å‹éš¾ä»¥å¤„ç†é•¿ä¸Šä¸‹æ–‡ã€å¤šæ­¥éª¤ã€çŠ¶æ€ä¾èµ–çš„äº¤äº’è½¨è¿¹ã€‚
- **ç¼ºä¹é«˜è´¨é‡çš„agenticè®­ç»ƒæ•°æ®**ï¼šçœŸå®ä¸–ç•Œä¸­çš„agentè¡Œä¸ºæ•°æ®ç¨€ç–ä¸”ä¸å¯æ‰§è¡Œã€‚
- **è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›ä¸è¶³**ï¼šç°æœ‰æ¨¡å‹åœ¨æœªè§è¿‡çš„å·¥å…·ç»„åˆæˆ–é¢†åŸŸä¸­è¡¨ç°ä¸ä½³ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
è®ºæ–‡æå‡ºäº† **LongCat-Flash-Thinking-2601**ï¼Œä¸€ä¸ªæ‹¥æœ‰ **560B æ€»å‚æ•°ã€27B æ¿€æ´»å‚æ•°**çš„å¼€æº MoE æ¨ç†æ¨¡å‹ï¼Œå¹¶å›´ç»•å…¶æ„å»ºäº†ä¸€å¥—ç«¯åˆ°ç«¯çš„è®­ç»ƒæ¡†æ¶ï¼Œæ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰**Environment Scaling ä¸ Multi-Domain Environment Training**
- **è‡ªåŠ¨åŒ–ç¯å¢ƒæ„å»ºç®¡é“**ï¼šä»é«˜é˜¶é¢†åŸŸå®šä¹‰å‡ºå‘ï¼Œè‡ªåŠ¨ç”Ÿæˆå¯æ‰§è¡Œçš„ **tool schemaã€database schema å’Œ tool dependency graph**ï¼Œç¡®ä¿é€»è¾‘ä¸€è‡´æ€§ä¸å¯éªŒè¯æ€§ã€‚
- **å¯æ§çš„å›¾æ‰©å±•ç­–ç•¥**ï¼šé€šè¿‡ BFS å¼æ‰©å±•å·¥å…·å­å›¾ï¼Œå¹¶ä»…æ·»åŠ ä¾èµ–å·²æ»¡è¶³çš„èŠ‚ç‚¹ï¼Œä¿è¯ç¯å¢ƒçš„**å¯æ‰§è¡Œæ€§**ä¸ç›‘ç£ä¿¡å·çš„å¯é æ€§ã€‚
- **æ”¯æŒè¶…è¿‡ 20 ä¸ªé¢†åŸŸçš„å¤šæ ·åŒ–ç¯å¢ƒ**ï¼Œæ¯ä¸ªç¯å¢ƒåŒ…å« >60 ä¸ªå·¥å…·ï¼Œå½¢æˆå¯†é›†ä¾èµ–å›¾ï¼Œæå¤§æå‡è®­ç»ƒå¤æ‚åº¦ä¸æ³›åŒ–æ½œåŠ›ã€‚

> âœ… **ä¼˜åŠ¿**ï¼šè§£å†³äº† agentic æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼Œæä¾›äº†å¤§è§„æ¨¡ã€å¤šæ ·åŒ–ã€å¯éªŒè¯çš„è®­ç»ƒ playgroundï¼Œä¿ƒè¿›è·¨åŸŸæŠ€èƒ½è¿ç§»ã€‚

#### ï¼ˆ2ï¼‰**Robust Agentic Training under Noisy Environments**
- **ç³»ç»Ÿæ€§åˆ†æç°å®å™ªå£°æ¨¡å¼**ï¼Œè¯†åˆ«ä¸¤å¤§ç±»å™ªå£°ï¼š
  - **Instruction Noise**ï¼šç”¨æˆ·è¡¨è¾¾æ¨¡ç³Šã€æ­§ä¹‰ã€ä¸å®Œæ•´ã€‚
  - **Tool Noise**ï¼šå·¥å…·è°ƒç”¨å¤±è´¥ã€è¿”å›éƒ¨åˆ†ç»“æœã€è¾“å‡ºå«å™ªã€‚
- è®¾è®¡**è‡ªåŠ¨åŒ–å™ªå£°æ³¨å…¥ç®¡é“**ï¼Œåœ¨è®­ç»ƒä¸­é€æ­¥å¼•å…¥å¤šç±»å‹ã€å¤šå±‚çº§å™ªå£°ã€‚
- é‡‡ç”¨**è¯¾ç¨‹å­¦ä¹ ï¼ˆcurriculum learningï¼‰ç­–ç•¥**ï¼Œä»è½»åº¦æ‰°åŠ¨å¼€å§‹ï¼Œéšæ¨¡å‹é²æ£’æ€§å¢å¼ºè€Œæé«˜å™ªå£°å¼ºåº¦ã€‚

> âœ… **ä¼˜åŠ¿**ï¼šæ˜¾è‘—æå‡æ¨¡å‹åœ¨éç†æƒ³ç°å®ç¯å¢ƒä¸‹çš„ç¨³å®šæ€§ä¸æˆåŠŸç‡ï¼Œç¼©å°â€œè®­ç»ƒ-éƒ¨ç½²â€é¸¿æ²Ÿã€‚

#### ï¼ˆ3ï¼‰**Heavy Thinking Mode for Test-Time Scaling**
- åœ¨æ¨ç†é˜¶æ®µå¼•å…¥**å¹¶è¡Œæ·±åº¦æ€è€ƒæœºåˆ¶**ï¼š
  1. **Parallel Reasoning**ï¼šå¤šä¸ª thinker å¹¶è¡Œç”Ÿæˆä¸åŒçš„æ¨ç†è·¯å¾„ã€‚
  2. **Heavy Thinking**ï¼šç”± summary model å¯¹å¤šæ¡è·¯å¾„è¿›è¡Œåæ€ã€èšåˆä¸ç²¾ç‚¼ï¼Œè¾“å‡ºæœ€ç»ˆç­”æ¡ˆã€‚
- æ”¯æŒ **context memory** ä»¥ç»´æŒå¤šè½®å¯¹è¯çŠ¶æ€ã€‚
- å¯ç»“åˆé¢å¤–çš„ RL é˜¶æ®µä¼˜åŒ– summary èƒ½åŠ›ã€‚

> âœ… **ä¼˜åŠ¿**ï¼šå®ç°æ¨ç†å®½åº¦ï¼ˆwidthï¼‰ä¸æ·±åº¦ï¼ˆdepthï¼‰çš„åŒæ—¶æ‰©å±•ï¼Œæ˜¾è‘—æå‡å¤æ‚ä»»åŠ¡æ€§èƒ½ï¼Œä¼˜äºå•çº¯å¢åŠ  CoT é•¿åº¦æˆ– Self-Consistencyã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†

| ç±»åˆ« | æ•°æ®é›† | æè¿° |
|------|-------|------|
| **æ•°å­¦æ¨ç†** | AIME-25, HMMT-25, IMO-AnswerBench, AMO-Bench (EN/CH) | å¥¥èµ›çº§æ•°å­¦é¢˜ï¼Œå¼ºè°ƒ tool-integrated reasoningï¼ˆå¦‚ä»£ç æ‰§è¡Œï¼‰ |
| **ä»£ç†æœç´¢** | BrowseComp, BrowseComp-zh, RWSearch | å¤šè·³ç½‘é¡µæµè§ˆä¸ä¿¡æ¯æ£€ç´¢ä»»åŠ¡ï¼Œéœ€ä¸»åŠ¨ä½¿ç”¨ search/browsing å·¥å…· |
| **ä»£ç†å·¥å…·ä½¿ç”¨** | T2-Bench, VitaBench, Random Complex Tasks | å¤æ‚å·¥å…·é“¾è°ƒç”¨ï¼Œæ¶µç›–é›¶å”®ã€èˆªç©ºã€ç”µä¿¡ç­‰é¢†åŸŸ |
| **é²æ£’æ€§æµ‹è¯•** | T2-Noise, Vita-Noise | åœ¨åŸå§‹åŸºå‡†ä¸Šæ³¨å…¥ç³»ç»Ÿæ€§å™ªå£°åçš„å˜ä½“ |
| **é€šç”¨é—®ç­”** | GPQA-Diamond, HLE | é«˜éš¾åº¦çŸ¥è¯†å¯†é›†å‹æ¨ç† |
| **ç¼–ç¨‹èƒ½åŠ›** | LiveCodeBench, OJBench, OIBench, SWE-bench Verified | ç¼–ç ä¸è½¯ä»¶å·¥ç¨‹ä»£ç†ä»»åŠ¡ |

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹æ¶æ„**ï¼šMoEï¼Œ560B total paramsï¼Œ27B activated per tokenã€‚
- **æ¨ç†é…ç½®**ï¼štemperature=1.0, top-k=-1, top-p=1.0ï¼ˆé™¤éç‰¹åˆ«è¯´æ˜ï¼‰ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - `Pass@k` / `Avg@k`ï¼šk æ¬¡é‡‡æ ·ä¸­è‡³å°‘ä¸€æ¬¡æˆåŠŸçš„æ¯”ä¾‹ï¼ˆå¸¸ç”¨ k=1, 4, 16ï¼‰ã€‚
  - ç‰¹åˆ«å…³æ³¨ **Heavy Mode ä¸‹çš„æ€§èƒ½å¢ç›Š**ã€‚
- **ä¸Šä¸‹æ–‡ç®¡ç†**ï¼šé‡‡ç”¨ Hybrid ç­–ç•¥ï¼ˆsummary + discard-allï¼‰ï¼Œé˜ˆå€¼è®¾ä¸º 80K tokensã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **å¼€æºæ¨¡å‹**ï¼š
  - DeepSeek-V3.2-Thinking
  - Kimi-K2-Thinking
  - Qwen3-235B-A22B-Thinking-2507
  - GLM-4.7-Thinking
- **é—­æºæ¨¡å‹**ï¼ˆå¼•ç”¨å®˜æ–¹æŠ¥å‘Šï¼‰ï¼š
  - GPT-5.2-Thinking-xhigh
  - Claude-Opus-4.5-Thinking
  - Gemini-3-Pro

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 2ï¼‰

| Benchmark | LongCat-Flash-Thinking-2601 | æœ€ä½³åŸºçº¿ï¼ˆå¼€æºï¼‰ | æœ€ä½³é—­æº |
|----------|-------------------------------|------------------|-----------|
| **BrowseComp (Pass@1)** | **73.1**ï¼ˆå¯ç”¨ context mgmtï¼‰ | 67.6ï¼ˆDeepSeek-V3.2ï¼‰ | 65.8 |
| **BrowseComp-zh (Pass@1)** | **77.7** | 66.6 | â€” |
| **RWSearch (Pass@1)** | **79.5** | 74.0 | 82.0 |
| **T2-Bench (Avg@4)** | **88.2** | 87.4 | 90.7 |
| **VitaBench (Avg@4)** | **29.3** | 24.0 | 31.5 |
| **AIME-25 (Avg@16)** | **99.6**ï¼ˆHeavy Mode è¾¾ 100.0ï¼‰ | 99.1 | 100.0 |
| **IMO-AnswerBench (Avg@4)** | **78.6**ï¼ˆHeavy Mode è¾¾ **86.8**ï¼‰ | 84.0 | 86.7 |
| **AMO-Bench EN (Avg@16)** | **61.6**ï¼ˆHeavy Mode è¾¾ **66.0**ï¼‰ | 62.4 | 72.5 |
| **AMO-Bench CH (Avg@16)** | **56.8**ï¼ˆHeavy Mode è¾¾ **67.5**ï¼‰ | 35.1 | 74.9 |
| **OIBench EN (Pass@1)** | **42.2** | 44.6 | 61.2 |

> ğŸ”¥ **ç»“è®º**ï¼šåœ¨å‡ ä¹æ‰€æœ‰ **agentic ä»»åŠ¡** ä¸Šè¾¾åˆ° **å¼€æºæ¨¡å‹ SOTA**ï¼Œå¹¶åœ¨éƒ¨åˆ†æŒ‡æ ‡ä¸Šæ¥è¿‘ç”šè‡³è¶…è¶Šæœ€å¼ºé—­æºæ¨¡å‹ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 1ï¼‰

| Dataset | ColdStart | Training w/o Noise | Training w/ Noise |
|--------|-----------|--------------------|-------------------|
| **VitaBench (Avg@4)** | 10.0 | 28.6 | **29.3** |
| **VitaBench-Noise (Avg@4)** | 6.3 | 13.3 | **20.5** |
| **Tau2Bench (Avg@4)** | 78.8 | 87.1 | **88.2** |
| **Tau2Bench-Noise (Avg@4)** | 58.8 | 62.2 | **67.1** |

> âœ… **å‘ç°**ï¼š
> - å¼•å…¥ **noise training** æ˜¾è‘—æå‡åœ¨å™ªå£°ç¯å¢ƒä¸‹çš„é²æ£’æ€§ï¼ˆ+7.2 pts on VitaBench-Noiseï¼‰ã€‚
> - å³ä½¿åœ¨å¹²å‡€ç¯å¢ƒä¸­ï¼Œnoise training ä¹Ÿèƒ½å¸¦æ¥è½»å¾®å¢ç›Šï¼Œè¡¨æ˜å…¶å¢å¼ºäº†æ¨¡å‹çš„æ³›åŒ–ä¸çº é”™èƒ½åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç»Ÿä¸€çš„ç«¯åˆ°ç«¯è®­ç»ƒæ¡†æ¶æ˜¯æ„å»ºå¼º agentic æ¨¡å‹çš„å…³é”®**ï¼šä» pre-training â†’ mid-training â†’ post-training å…¨æµç¨‹ååŒè®¾è®¡ï¼Œæ‰èƒ½æœ‰æ•ˆæå‡ä»£ç†èƒ½åŠ›ã€‚
2. **ç¯å¢ƒå¤šæ ·æ€§é©±åŠ¨æ³›åŒ–**ï¼šé€šè¿‡ **Environment Scaling** æ„å»ºçš„è·¨åŸŸã€å¼‚æ„ç¯å¢ƒé›†åˆï¼Œæ˜¯åŸ¹å…»é€šç”¨å·¥å…·ä½¿ç”¨èƒ½åŠ›çš„åŸºç¡€ã€‚
3. **æ˜¾å¼å»ºæ¨¡ç°å®å™ªå£°å¯å¤§å¹…æå‡é²æ£’æ€§**ï¼šåœ¨è®­ç»ƒä¸­æ³¨å…¥ instruction å’Œ tool noiseï¼Œèƒ½æœ‰æ•ˆåº”å¯¹ç°å®ä¸–ç•Œçš„ä¸ç¡®å®šæ€§ã€‚
4. **Heavy Thinking Mode æ˜¯æœ‰æ•ˆçš„ test-time scaling èŒƒå¼**ï¼šé€šè¿‡å¹¶è¡Œæ¢ç´¢ + é›†æˆåæ€ï¼Œæ˜¾è‘—æå‡å¤æ‚ä»»åŠ¡æ€§èƒ½ï¼Œå°¤å…¶åœ¨æ•°å­¦ä¸å·¥å…·é›†æˆåœºæ™¯ã€‚
5. **LongCat-Flash-Thinking-2601 æ˜¯å½“å‰æœ€å¼ºçš„å¼€æº agentic æ¨¡å‹**ï¼šåœ¨ agentic searchã€tool use ç­‰ä»»åŠ¡ä¸Šå…¨é¢é¢†å…ˆã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **è®¡ç®—æˆæœ¬æé«˜**ï¼šè®­ç»ƒæ¶‰åŠæ•°ä¸‡å¹¶å‘ç¯å¢ƒä¸æ•°åƒåŠ é€Ÿå™¨ï¼Œå¯¹åŸºç¡€è®¾æ–½è¦æ±‚ä¸¥è‹›ã€‚
- **Heavy Thinking æ¨¡å¼å»¶è¿Ÿè¾ƒé«˜**ï¼šå¹¶è¡Œå¤šè·¯å¾„æ¨ç†å¸¦æ¥æ˜¾è‘—çš„æ¨ç†å¼€é”€ï¼Œä¸é€‚åˆä½å»¶è¿Ÿåœºæ™¯ã€‚
- **å™ªå£°å»ºæ¨¡ä»ä¸ºç®€åŒ–ç‰ˆæœ¬**ï¼šçœŸå®ä¸–ç•Œå™ªå£°æ›´å¤æ‚ï¼Œå½“å‰æ³¨å…¥æ–¹å¼å¯èƒ½æœªèƒ½å®Œå…¨è¦†ç›–æ‰€æœ‰å¤±æ•ˆæ¨¡å¼ã€‚
- **è¯„ä¼°ä»å—é™äºåˆæˆç¯å¢ƒ**ï¼šå°½ç®¡æœ‰ RWSearch ç­‰çœŸå®æŸ¥è¯¢ï¼Œä½†å¤šæ•° benchmark ä»åŸºäºæ¨¡æ‹Ÿå™¨ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **é™ä½è®­ç»ƒé—¨æ§›**ï¼šæ¢ç´¢æ›´é«˜æ•ˆçš„åˆ†å¸ƒå¼ RL æ¡†æ¶ï¼Œæ”¯æŒä¸­å°è§„æ¨¡å›¢é˜Ÿå¤ç°ã€‚
- **ä¼˜åŒ– Heavy Thinking æ¨ç†æ•ˆç‡**ï¼šç ”ç©¶åŠ¨æ€ early stoppingã€è·¯å¾„å‰ªæç­‰æŠ€æœ¯å‡å°‘å†—ä½™è®¡ç®—ã€‚
- **æ„å»ºæ›´çœŸå®çš„ agentic è¯„ä¼°å¹³å°**ï¼šæ¨åŠ¨åŸºäºçœŸå® APIã€çœŸå®ç”¨æˆ·è¡Œä¸ºçš„é•¿æœŸäº¤äº’ benchmarkã€‚
- **æ¢ç´¢ agent è‡ªæˆ‘æ¼”åŒ–èƒ½åŠ›**ï¼šè®© agent åœ¨éƒ¨ç½²ä¸­æŒç»­å­¦ä¹ ä¸é€‚åº”æ–°å·¥å…·ä¸ç¯å¢ƒã€‚
- **å‘å¸ƒ LongCat-Flash-Thinking-ZigZag**ï¼šæ”¯æŒé«˜è¾¾ 1M tokens çš„ä¸Šä¸‹æ–‡ï¼Œè¿›ä¸€æ­¥é‡Šæ”¾é•¿ç¨‹æ¨ç†æ½œåŠ›ã€‚

---

> ğŸ“¢ **è¡¥å……äº®ç‚¹**ï¼šè®ºæ–‡è¿˜å¼€æºäº†å¤šä¸ªå…³é”®ç»„ä»¶ï¼š
> - **ZigZag Attention**ï¼šä¸€ç§å¯åœ¨ mid-training é˜¶æ®µå°† full-attention æ¨¡å‹è½¬ä¸º sparse çš„é«˜æ•ˆæ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ç°çº¦ 1.5Ã— æ¨ç†åŠ é€Ÿã€‚
> - **AMO-Bench è‹±æ–‡ç‰ˆ** ä¸ **BrowseComp-ZH ä¿®æ­£ç‰ˆ**ï¼šæå‡ç¤¾åŒºè¯„ä¼°ä¸€è‡´æ€§ã€‚
> - **Noise Injection Pipeline** ä¸ **Random Complex Tasks ç”Ÿæˆå™¨**ï¼šæ”¯æŒæœªæ¥é²æ£’æ€§ç ”ç©¶ã€‚

</details>

---

### 4. [Better Generalizing to Unseen Concepts: An Evaluation Framework and An LLM-Based Auto-Labeled Pipeline for Biomedical Concept Recognition](https://arxiv.org/abs/2601.16711)

**Authors**: Shanshan Liu, Noriki Nishida, Fei Cheng, Narumi Tokunaga, Rumana Ferdous Munne, Yuki Yamagata, Kouji Kozaki, Takehito Utsuro, Yuji Matsumoto  
**Category**: cs.CL  
**Published**: 2026-01-26  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.16711v1  

#### Abstract
Generalization to unseen concepts is a central challenge due to the scarcity of human annotations in Mention-agnostic Biomedical Concept Recognition (MA-BCR). This work makes two key contributions to systematically address this issue. First, we propose an evaluation framework built on hierarchical c...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šBetter Generalizing to Unseen Concepts: An Evaluation Framework and An LLM-Based Auto-Labeled Pipeline for Biomedical Concept Recognition

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

æœ¬ç ”ç©¶èšç„¦äº **Mention-agnostic Biomedical Concept Recognition (MA-BCR)** ä¸­ä¸€ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼š**æ¨¡å‹å¯¹æœªè§æ¦‚å¿µï¼ˆunseen conceptsï¼‰çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³**ã€‚ç”±äºäººå·¥æ ‡æ³¨æˆæœ¬é«˜æ˜‚ï¼Œç°æœ‰çš„ **Manual-Labeled Datasets (MLDs)** è¦†ç›–çš„ç”Ÿç‰©åŒ»å­¦æ¦‚å¿µä»…å æ•´ä¸ªæœ¬ä½“ï¼ˆontologyï¼‰çš„ä¸€å°éƒ¨åˆ†ï¼ˆå¦‚ HPO ä»…è¦†ç›–çº¦ 2.35%ï¼‰ï¼Œå¯¼è‡´æ¨¡å‹éš¾ä»¥è¯†åˆ«è®­ç»ƒä¸­æœªå‡ºç°çš„æ¦‚å¿µã€‚

æ­¤å¤–ï¼Œä¼ ç»Ÿè¯„ä¼°æ–¹å¼ï¼ˆå¦‚ micro-F1ï¼‰æ— æ³•æœ‰æ•ˆè¡¡é‡æ¨¡å‹åœ¨â€œæœªå‘½ä¸­ç›®æ ‡â€æ—¶æ˜¯å¦â€œæ¥è¿‘æ­£ç¡®ç­”æ¡ˆâ€ï¼Œç¼ºä¹å¯¹å±‚æ¬¡åŒ–ç»“æ„æ„ŸçŸ¥çš„è¯„ä¼°æœºåˆ¶ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

#### ï¼ˆ1ï¼‰æå‡ºäº†ä¸€å¥—**å±‚æ¬¡åŒ–è¯„ä¼°æ¡†æ¶**ï¼ˆHierarchical Evaluation Frameworkï¼‰
- **æ„å»ºä¸‰ç§ Hierarchical Search Index**ï¼š
  - **OSI** (Ontology-aware Search Index)ï¼šåŸºäºæœ¬ä½“ç»“æ„ï¼ˆparent-child å…³ç³»ï¼‰æ„å»ºå›¾ã€‚
  - **SSI** (Semantic Search Index)ï¼šåŸºäº SapBERT åµŒå…¥çš„è¯­ä¹‰ç›¸ä¼¼æ€§æ„å»ºå›¾ã€‚
  - **OSSI** (Ontology-Semantic Search Index)ï¼šèåˆæœ¬ä½“ç»“æ„ä¸è¯­ä¹‰ç›¸ä¼¼æ€§çš„æ··åˆå›¾ã€‚
- å›¾é€šè¿‡ **Louvain ç®—æ³•**è¿›è¡Œé€’å½’åˆ’åˆ†ï¼Œç”Ÿæˆå…·æœ‰å±‚çº§ç´¢å¼•ï¼ˆå¦‚ `0-1-2`ï¼‰çš„æ ‡ç­¾æ ‘ï¼Œä½¿é¢„æµ‹å¯æ˜ å°„åˆ°å±‚çº§è·¯å¾„ä¸Šã€‚

#### ï¼ˆ2ï¼‰è®¾è®¡ä¸¤ä¸ªæ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼Œä¸“é—¨ç”¨äºè¡¡é‡å¯¹ **unseen concepts** çš„æ³›åŒ–èƒ½åŠ›ï¼š
- **U-RC (Unseen Recall-oriented Closeness)**ï¼šè¡¡é‡é¢„æµ‹ä¸çœŸå®æœªè§æ¦‚å¿µåœ¨å±‚çº§æ ‘ä¸­çš„**æœ€é•¿å…¬å…±å‰ç¼€é•¿åº¦**ï¼Œåæ˜ â€œæœ‰å¤šæ¥è¿‘â€ã€‚
- **U-CS (Unseen Candidate-set Size)**ï¼šè¡¡é‡æ¨¡å‹é¢„æµ‹æ‰€èƒ½ç¼©å°çš„å€™é€‰æ¦‚å¿µé›†åˆå¤§å°ï¼ˆè°ƒå’Œå¹³å‡ï¼‰ï¼Œåæ˜ â€œæœç´¢ç©ºé—´ç¼©å‡èƒ½åŠ›â€ã€‚

#### ï¼ˆ3ï¼‰é¦–æ¬¡ä¸º MA-BCR è®¾è®¡äº†ä¸€ä¸ª **LLM-based Auto-Labeled Data (ALD) Pipeline**
- åˆ©ç”¨ LLM è‡ªåŠ¨ç”Ÿæˆ passage-level çš„æ¦‚å¿µæ ‡æ³¨ï¼Œæ— éœ€ä¾èµ– mention spansã€‚
- æµç¨‹åŒ…æ‹¬äº”é˜¶æ®µï¼š
  1. **PCC** (Passage-to-Claim-to-Concept)ï¼šå°†æ–‡æœ¬åˆ†è§£ä¸ºç‹¬ç«‹ claimï¼Œå†ç”Ÿæˆå€™é€‰æ¦‚å¿µã€‚
  2. **CC** (Concept Classification)ï¼šå››åˆ†ç±»åˆ¤æ–­æ¦‚å¿µæ˜¯ explicit / logically implicit / pragmatically implicit / not relevantã€‚
  3. **RL** (Relabeling)ï¼šLLM å¯¹é¢„æµ‹è¿›è¡Œä¿®æ­£ï¼Œè¡¥å……ç¼ºå¤±æˆ–åˆ é™¤é”™è¯¯æ¦‚å¿µã€‚
  4. **GF** (Guideline-based Filtering)ï¼šä¾æ® CRAFT ç­‰æ ‡æ³¨æŒ‡å—è¿‡æ»¤æ— æ•ˆæ ‡æ³¨ã€‚
  5. **QS** (Quality-based Selection)ï¼šæŒ‰è´¨é‡è¯„åˆ†ï¼ˆ1â€“5çº§ï¼‰ç­›é€‰é«˜è´¨é‡æ ·æœ¬ã€‚

è¯¥ pipeline å¯æ‰©å±•åœ°ç”Ÿæˆå¤§è§„æ¨¡ ALDï¼Œæ˜¾è‘—æå‡æ¦‚å¿µè¦†ç›–ç‡ï¼ˆå¦‚ HPA è¾¾ 69.33%ï¼ŒHoIP è¾¾ 54.40%ï¼‰ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | æœ¬æ–‡æ–¹æ³•ä¼˜åŠ¿ |
|------|--------------|
| **ä»»åŠ¡è®¾å®š** | æ”¯æŒ **mention-agnostic** è®¾ç½®ï¼Œæ›´ç¬¦åˆå®é™…ç”Ÿç‰©åŒ»å­¦æ–‡çŒ®è¡¨è¾¾ï¼ˆå¸¸éšå«æ¦‚å¿µï¼‰ã€‚ |
| **è¯„ä¼°èƒ½åŠ›** | é¦–æ¬¡æä¾›å¯¹ **unseen concept æ³›åŒ–èƒ½åŠ›** çš„é‡åŒ–å·¥å…·ï¼ˆU-RC/U-CSï¼‰ï¼Œå¼¥è¡¥ä¼ ç»Ÿ F1 çš„ç›²åŒºã€‚ |
| **æ•°æ®å¯æ‰©å±•æ€§** | LLM-based pipeline å¯ä½æˆæœ¬ç”Ÿæˆå¤§è§„æ¨¡ ALDï¼Œç¼“è§£ MLD ç¨€ç–é—®é¢˜ã€‚ |
| **ç»“æ„åˆ©ç”¨** | æ˜¾å¼å»ºæ¨¡æœ¬ä½“å±‚æ¬¡ç»“æ„ï¼Œä½¿æ¨¡å‹èƒ½å­¦ä¹ â€œå³ä½¿æ²¡çŒœä¸­ä¹Ÿèƒ½é è¿‘â€çš„æ¨ç†èƒ½åŠ›ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

| ç±»å‹ | æ•°æ®é›† | æè¿° |
|------|--------|------|
| **Manual-Labeled Datasets (MLDs)** | **HPA-MLD** (HPO GSC+) | åŒ…å« 228 ç¯‡æ‘˜è¦ï¼Œæ ‡æ³¨ HPO ä¸­ Human Phenotypic Abnormality æ¦‚å¿µã€‚ |
| | **HoIP-MLD** (CRAFT å­é›†) | ä» CRAFT corpus æå–ï¼Œæ ‡æ³¨ Homeostasis Imbalance Process æ¦‚å¿µã€‚ |
| **Auto-Labeled Datasets (ALDs)** | **HPA-ALD**, **HoIP-ALD** | ä½¿ç”¨ LLM pipeline è‡ªåŠ¨æ ‡æ³¨ï¼Œåˆ†åˆ«åŒ…å« 54,301 å’Œ 34,097 ç¯‡ PubMed abstractsã€‚ |

> âœ… ALD æ„å»ºæ–¹å¼ï¼šä»¥æ¯ä¸ªæ¦‚å¿µåç§°ä½œä¸º queryï¼Œæ£€ç´¢æœ€å¤š 10 ç¯‡æœ€æ–° PubMed abstractsï¼Œå¹¶å»é‡ã€‚

---

### **å®éªŒè®¾ç½®**

- **æ¨¡å‹é€‰æ‹©**ï¼šé‡‡ç”¨ **MA-COIR**ï¼ˆBART-based seq2seq æ¨¡å‹ï¼‰ï¼Œè¾“å‡º hierarchical concept indicesã€‚
- **è®­ç»ƒç­–ç•¥**ï¼š
  - HPAï¼šä»…åœ¨ ALD ä¸Šè®­ç»ƒï¼ˆå›  MLD å¤ªå°ï¼‰ï¼Œæµ‹è¯•åœ¨ MLDã€‚
  - HoIPï¼šä¸¤ç§è®¾ç½®ï¼š
    - MLDâ†’MLDï¼šåœ¨ MLD ä¸Šè®­ç»ƒï¼Œåœ¨ MLD ä¸Šæµ‹è¯•ã€‚
    - ALDâ†’MLDï¼šåœ¨ ALD ä¸Šè®­ç»ƒï¼Œåœ¨ held-out MLD ä¸Šæµ‹è¯•ã€‚
- **æ§åˆ¶å˜é‡**ï¼š
  - è‡³å°‘ 30% çš„æµ‹è¯•æ¦‚å¿µåœ¨è®­ç»ƒé›†ä¸­ä¸º **unseen**ã€‚
  - æ§åˆ¶è®­ç»ƒæ•°æ®é‡ $ M = 200 \times 2^k $ï¼ŒéªŒè¯æ•°æ®è§„æ¨¡å½±å“ã€‚

---

### **è¯„ä¼°æŒ‡æ ‡**

| æŒ‡æ ‡ | å…¬å¼ç®€è¿° | å«ä¹‰ |
|------|---------|------|
| **micro-F1** | æ ‡å‡†ç²¾ç¡®ç‡/å¬å›ç‡/F1 | æ˜¯å¦**å®Œå…¨åŒ¹é…**æ­£ç¡®æ¦‚å¿µ |
| **U-RC** | $\frac{1}{|G_{us}|} \sum_{g \in G_{us}} \max_{\hat{y}} \text{lcp}(I_g, I_{\hat{y}})$ | åœ¨å±‚çº§æ ‘ä¸­ç¦»çœŸå®æ¦‚å¿µ**å¤šè¿‘** |
| **U-CS** | è°ƒå’Œå¹³å‡ $\left( \frac{1}{|G_{us}|} \sum \frac{1}{S(p,g)} \right)^{-1}$ | é¢„æµ‹èƒ½å°†æœç´¢ç©ºé—´ç¼©å°åˆ°å¤šå°‘ä¸ªå€™é€‰ |

> ğŸ“Œ æ‰€æœ‰æŒ‡æ ‡å‡å¯åº”ç”¨äºä»»æ„ recognizerï¼Œåªéœ€å°†å…¶è¾“å‡ºæ˜ å°„è‡³ OSI/SSI/OSSI ç´¢å¼•å³å¯ã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

- ä¸»è¦å¯¹æ¯”ä¸åŒè®­ç»ƒæ•°æ®æ¥æºä¸‹çš„åŒä¸€æ¨¡å‹ï¼ˆMA-COIRï¼‰è¡¨ç°ï¼š
  - **MLD-trained** vs **ALD-trained**
- ä¸åŒç´¢å¼•ç±»å‹ä¹‹é—´çš„æ¯”è¾ƒï¼ˆOSI vs SSI vs OSSIï¼‰
- æ— ç«¯åˆ°ç«¯å¯¹æ¯”å…¶ä»–æ¶æ„ï¼ˆå¦‚ mention-based NER+ELï¼‰ï¼Œå› å…¶ä¸å…¼å®¹ hierarchical index è¾“å‡ºã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 3ï¼‰**

#### **HoIP ä»»åŠ¡ä¸Šçš„ ALD vs MLD è®­ç»ƒæ•ˆæœå¯¹æ¯”**

| è®­ç»ƒæ•°æ® | æ•°æ®é‡ | micro-F1 | U-RC (OSSI) | U-CS (SSI) |
|--------|-------|----------|-------------|------------|
| HoIP-MLD | 2,458 | **78.6** | 30.5 | 42.1 |
| HoIP-ALD | 16,415 | 17.7 | **41.4** | **33.2** |

> ğŸ” å°½ç®¡ ALD æ¨¡å‹çš„ F1 è¿œä½äº MLD æ¨¡å‹ï¼Œä½†åœ¨ **U-RC å’Œ U-CS ä¸Šå…¨é¢åè¶…**ï¼Œè¯´æ˜å…¶æ³›åŒ–èƒ½åŠ›æ›´å¼ºã€‚

#### **éš ALD æ•°æ®é‡å¢åŠ çš„è¶‹åŠ¿ï¼ˆHoIP-ALD, SSI indexï¼‰**

| æ•°æ®é‡ | F1 | U-RC | U-CS |
|-------|-----|------|------|
| 200 | 13.7 | 28.6 | 129.1 |
| 6,400 | 15.7 | 38.4 | 35.0 |
| 16,415 | 17.6 | **38.0** | **33.2** |

âœ… **è¶‹åŠ¿æ˜ç¡®**ï¼šéšç€ ALD è§„æ¨¡å¢å¤§ï¼Œ**U-RC æŒç»­ä¸Šå‡ï¼ŒU-CS æ˜¾è‘—ä¸‹é™**ï¼Œè¡¨æ˜æ¨¡å‹è¶Šæ¥è¶Šèƒ½â€œæ¥è¿‘â€å¹¶â€œç¼©å°æœç´¢èŒƒå›´â€åˆ°æœªè§æ¦‚å¿µã€‚

#### **HPA ä»»åŠ¡ä¸Šçš„ ALD æ•ˆæœï¼ˆæ›´é«˜è´¨ ALDï¼‰**

| æ•°æ®é‡ | F1 | U-RC (OSI) | U-CS (OSI) |
|-------|-----|-----------|-----------|
| 200 | 19.1 | 26.5 | 100.6 |
| 47,152 | **36.7** | **46.1** | **20.1** |

âœ… åœ¨ HPA ä¸Šï¼Œ**F1ã€U-RCã€U-CS å‡éšæ•°æ®å¢é•¿è€ŒæŒç»­æå‡**ï¼Œè¯´æ˜é«˜è´¨é‡ ALD å¯åŒæ—¶æå‡å‡†ç¡®æ€§å’Œæ³›åŒ–æ€§ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### ï¼ˆ1ï¼‰Auto-labeling Pipeline å„æ¨¡å—æœ‰æ•ˆæ€§ï¼ˆTable 2ï¼‰

| Pipeline é˜¶æ®µ | HPA F1 | HoIP F1 |
|--------------|--------|--------|
| PCCï¼ˆä»…ç”Ÿæˆï¼‰ | 53.0 | 11.4 |
| +CC+RL+GF+QS | **55.4** | **27.6** |

âœ… æ‰€æœ‰æ¨¡å—å‡å¸¦æ¥å¢ç›Šï¼Œå°¤å…¶æ˜¯ **Concept Classification** å’Œ **Relabeling** æ˜¾è‘—æå‡ precisionã€‚

#### ï¼ˆ2ï¼‰False Positive é”™è¯¯åˆ†æï¼ˆFigure 4ï¼‰

åœ¨ HoIP ä¸Š FP ä¸­ï¼š
- **Context over-generalization**: 29.8%
- **Inferential overreach**: 26.9%
- **Missing gold**ï¼ˆå®é™…åº”ä¸ºæ­£ä¾‹ï¼‰: 17.3%

â¡ï¸ è¡¨æ˜ LLM å®¹æ˜“è¿‡åº¦æ¨æ–­ï¼Œä½†ä¹Ÿæ­ç¤ºéƒ¨åˆ†â€œå‡é˜³æ€§â€å®ä¸ºæ ‡æ³¨é—æ¼ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **LLM-generated ALD è™½ä¸èƒ½æ›¿ä»£ MLD**ï¼ˆF1 æ›´ä½ï¼‰ï¼Œä½†èƒ½**æ˜¾è‘—å¢å¼ºå¯¹ unseen concepts çš„æ³›åŒ–èƒ½åŠ›**ã€‚
2. âœ… **æ‰©å¤§ ALD æ•°æ®é‡å¯ç³»ç»Ÿæ€§æå‡ U-RC å’Œ U-CS**ï¼Œå°¤å…¶åœ¨é«˜è¦†ç›–åœºæ™¯ä¸‹ï¼ˆå¦‚ HPAï¼‰ï¼Œç”šè‡³å¸¦åŠ¨ F1 ä¸Šå‡ã€‚
3. âœ… **Hierarchical indexing æ˜¯å…³é”®æ¡¥æ¢**ï¼šå®ƒä½¿å¾—å™ªå£°ç›‘ç£ä¿¡å·å˜å¾—â€œå¯å­¦ä¹ â€ï¼Œè®©æ¨¡å‹å³ä½¿é¢„æµ‹ä¸å‡†ä¹Ÿèƒ½å­¦åˆ°ç»“æ„çŸ¥è¯†ã€‚
4. âœ… **U-RC å’Œ U-CS æ˜¯æœ‰æ•ˆçš„ä¸‹æ¸¸æœ‰ç”¨æ€§ä»£ç†æŒ‡æ ‡**ï¼š
   - åœ¨ re-ranking å®éªŒä¸­ï¼Œ**reranker F1 ä¸ U-RC æ­£ç›¸å…³ï¼ˆÏ=0.874ï¼‰ï¼Œä¸ U-CS è´Ÿç›¸å…³ï¼ˆÏ=-0.814ï¼‰**ï¼Œè¿œå¼ºäºä¸ micro-F1 çš„ç›¸å…³æ€§ï¼ˆÏ=0.554ï¼‰ã€‚
5. âœ… **OSIã€SSIã€OSSI å„æœ‰ä¼˜åŠ¿**ï¼š
   - OSI æ›´åˆ©äº closenessï¼ˆU-RCï¼‰
   - SSI æ›´åˆ©äº candidate set reductionï¼ˆU-CSï¼‰
   - OSSI ç»¼åˆè¡¨ç°æœ€ä½³

---

### **æ–¹æ³•çš„å±€é™æ€§**

| å±€é™æ€§ | è¯´æ˜ |
|--------|------|
| **Auto-labeling åœ¨å¤æ‚æœ¬ä½“ä¸Šæ€§èƒ½æœ‰é™** | å¦‚ HoIP æ¦‚å¿µç»†ç²’åº¦é«˜ï¼ŒLLM ç¼ºä¹é¢„è®­ç»ƒè¦†ç›–ï¼Œå¯¼è‡´ recall ä½ã€‚ |
| **ALD è¦†ç›–ä»ä¸å®Œæ•´** | å½“å‰ HPA è¦†ç›– 69.33%ï¼ŒHoIP ä»… 54.40%ï¼Œéƒ¨åˆ†æ¦‚å¿µæ— æ³•æ£€ç´¢åˆ°ç›¸å…³ abstractã€‚ |
| **Indexing ç­–ç•¥ä»æœ‰æ”¹è¿›ç©ºé—´** | å½“å‰å›¾åˆ’åˆ†æ–¹æ³•è¾ƒç®€å•ï¼Œæœªæ¥å¯å¼•å…¥è‡ªé€‚åº”åŠ æƒã€é‡è¦æ€§å»ºæ¨¡ç­‰ã€‚ |
| **è®­ç»ƒæ•ˆç‡ç“¶é¢ˆ** | ä½¿ç”¨ BART ç­‰ encoder-decoder æ¨¡å‹å¤„ç†å¤§è§„æ¨¡ ALD æ—¶è®­ç»ƒè€—æ—¶é•¿ã€‚ |
| **è‡ªåŠ¨è¯„ä¼°å¯é æ€§é—®é¢˜** | ä½¿ç”¨ GPT-4o-mini ä½œä¸º judge ä»å­˜åœ¨ä¸äººå·¥æ ‡å‡†å¯¹é½åå·®ï¼Œéœ€äººå·¥æ ¡å‡†ã€‚ |

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ”¹è¿› auto-labeling pipeline**ï¼š
   - å¼•å…¥å¤š LLM åä½œï¼Œå‡å°‘è¯¯å·®ä¼ æ’­ã€‚
   - ç»“åˆ active learning åŠ¨æ€ä¼˜åŒ–æ ‡æ³¨é‡ç‚¹ã€‚
2. **æå‡ ALD è¦†ç›–ç‡ä¸è´¨é‡**ï¼š
   - æ‰©å±•æ£€ç´¢æºï¼ˆå¦‚ PMC full textï¼‰ã€‚
   - å¼•å…¥ data synthesis æŠ€æœ¯ç”Ÿæˆç¨€ç¼ºæ¦‚å¿µä¸Šä¸‹æ–‡ã€‚
3. **ä¼˜åŒ– hierarchical indexing**ï¼š
   - æ¢ç´¢ learned fusion æœºåˆ¶æ•´åˆæœ¬ä½“ä¸è¯­ä¹‰ä¿¡å·ã€‚
   - å¼•å…¥åŠ¨æ€ç´¢å¼•é€‚åº”ä¸åŒä»»åŠ¡éœ€æ±‚ã€‚
4. **æé«˜è®­ç»ƒæ•ˆç‡**ï¼š
   - ä½¿ç”¨ distillationã€continual learning æˆ–è½»é‡æ¶æ„åŠ é€Ÿè®­ç»ƒã€‚
5. **æ¨åŠ¨ unseen concept recognition åº”ç”¨è½åœ°**ï¼š
   - æ„å»ºé¢å‘ discovery çš„ biomedical IE å·¥å…·é“¾ã€‚
   - å°† U-RC/U-CS ä½œä¸º early-stop æˆ– model selection æŒ‡æ ‡ã€‚

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> æœ¬æ–‡æå‡ºäº†ä¸€ç§â€œ**ç”¨å¤§è§„æ¨¡å¼±ç›‘ç£æ•°æ® + å±‚æ¬¡åŒ–ç»“æ„å¼•å¯¼ + æ–°å‹æ³›åŒ–è¯„ä¼°æŒ‡æ ‡**â€çš„æ–°èŒƒå¼ï¼Œè¯æ˜äº† **LLM-generated ALD æ˜¯æå‡ MA-BCR æ¨¡å‹å¯¹æœªè§æ¦‚å¿µæ³›åŒ–èƒ½åŠ›çš„æœ‰æ•ˆé€”å¾„**ï¼Œä¸ºä½èµ„æºã€é«˜æ³›åŒ–éœ€æ±‚çš„ç”Ÿç‰©åŒ»å­¦ä¿¡æ¯æŠ½å–æä¾›äº†æ–°æ€è·¯ã€‚

</details>

---

### 5. [Curate-Train-Refine: A Closed-Loop Agentic Framework for Zero Shot Classification](https://arxiv.org/abs/2601.16530)

**Authors**: Gaurav Maheshwari, Kevin El Haddad  
**Category**: cs.CL  
**Published**: 2026-01-26  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.16530v1  

#### Abstract
Large language models (LLMs) and high-capacity encoders have advanced zero and few-shot classification, but their inference cost and latency limit practical deployment. We propose training lightweight text classifiers using dynamically generated supervision from an LLM. Our method employs an iterati...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Curate-Train-Refine: A Closed-Loop Agentic Framework for Zero Shot Classification*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰åœ¨ **zero-shot** å’Œ **few-shot text classification** åœºæ™¯ä¸­ï¼Œä¸»æµæ–¹æ³•ä¾èµ–äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œæ¨ç†ï¼ˆå¦‚ prompt-based åˆ†ç±»ï¼‰ï¼Œè™½ç„¶æœ‰æ•ˆï¼Œä½†å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **é«˜æ¨ç†æˆæœ¬ä¸å»¶è¿Ÿ**ï¼šæ¯æ¬¡é¢„æµ‹éƒ½éœ€è¦è°ƒç”¨ LLMï¼Œéš¾ä»¥éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒã€‚
- **å¯¹ prompt è®¾è®¡æ•æ„Ÿ**ï¼šæ€§èƒ½å—æç¤ºå·¥ç¨‹å½±å“å¤§ã€‚
- **å°æ¨¡å‹éœ€è¦é«˜è´¨é‡ç›‘ç£ä¿¡å·**ï¼šè½»é‡çº§åˆ†ç±»å™¨ï¼ˆå¦‚ SetFitã€EuroBERTï¼‰è™½é«˜æ•ˆï¼Œä½†åœ¨æä½èµ„æºä¸‹è¡¨ç°ä¸ä½³ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šCurate-Train-Refine æ¡†æ¶
ä½œè€…æå‡ºä¸€ä¸ª **é—­ç¯çš„ agentic æ¡†æ¶**ï¼Œå°† LLM ä½œä¸ºâ€œæ•°æ®ç­–å±•äººâ€ï¼ˆdata curatorï¼‰ï¼Œè€Œéæ¨ç†å¼•æ“ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸‰ä¸ªé˜¶æ®µå¾ªç¯è¿­ä»£ï¼š

1. **Curateï¼ˆç­–å±•ï¼‰**ï¼šLLM åŸºäºæ ‡ç­¾è¯­ä¹‰ç”Ÿæˆåˆå§‹è®­ç»ƒæ•°æ®ã€‚
2. **Trainï¼ˆè®­ç»ƒï¼‰**ï¼šä½¿ç”¨ç”Ÿæˆçš„æ•°æ®è®­ç»ƒä¸€ä¸ªè½»é‡çº§åˆ†ç±»å™¨ï¼ˆå¦‚ SetFitï¼‰ã€‚
3. **Refineï¼ˆç²¾ç‚¼ï¼‰**ï¼šå°†åˆ†ç±»å™¨åœ¨éªŒè¯é›†ä¸Šçš„é”™è¯¯åé¦ˆç»™ LLMï¼Œç”±å…¶åˆ†æå¤±è´¥æ¨¡å¼å¹¶ç”Ÿæˆé’ˆå¯¹æ€§æ ·ä¾‹ï¼ˆå¦‚ hard negativesã€negation cases ç­‰ï¼‰ä»¥ä¿®æ­£ç¼ºé™·ã€‚

> ğŸ” æ­¤è¿‡ç¨‹å½¢æˆä¸€ä¸ª **closed-loop generate-evaluate-refine å¾ªç¯**ï¼Œæ— éœ€äººå·¥å¹²é¢„å³å¯æŒç»­ä¼˜åŒ–è®­ç»ƒæ•°æ®è´¨é‡ã€‚

### â­ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | æœ¬æ–‡æ–¹æ³• |
|------|--------|---------|
| æ¨ç†æ•ˆç‡ | ä¾èµ– LLM â†’ é«˜å»¶è¿Ÿã€é«˜æˆæœ¬ | è½»é‡æ¨¡å‹ â†’ ä½å»¶è¿Ÿã€ä½æˆæœ¬ |
| æ•°æ®è´¨é‡ | é™æ€ç”Ÿæˆæˆ–äººå·¥æ ‡æ³¨ â†’ å›ºå®šä¸å˜ | åŠ¨æ€ç”Ÿæˆ â†’ é’ˆå¯¹æ¨¡å‹å¼±ç‚¹è‡ªé€‚åº”ä¼˜åŒ– |
| æ³›åŒ–èƒ½åŠ› | Prompt æ•æ„Ÿã€ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶ | ä¸ä¾èµ–æµ‹è¯•æ—¶ LLM è°ƒç”¨ |
| å¯æ‰©å±•æ€§ | æ‰©å±•å›°éš¾ | æ”¯æŒå¤šè½®è¿­ä»£æå‡æ€§èƒ½ |

> ğŸ’¡ åˆ›æ–°ç‚¹æ€»ç»“ï¼š**é¦–æ¬¡å°† LLM ç”¨äºæ„å»ºé—­ç¯çš„æ•°æ®è’¸é¦æµç¨‹ï¼Œåœ¨ç¦»çº¿é˜¶æ®µå®ŒæˆçŸ¥è¯†è¿ç§»ï¼Œå®ç°â€œé«˜æ€§èƒ½ + é«˜æ•ˆç‡â€çš„ç»Ÿä¸€ã€‚**

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
å…±å››ä¸ªæ ‡å‡†æ–‡æœ¬åˆ†ç±» benchmarkï¼Œè¦†ç›–å¤šç§ä»»åŠ¡ç±»å‹ï¼š

| æ•°æ®é›† | ä»»åŠ¡ç±»å‹ | ç±»åˆ«æ•° | æè¿° |
|-------|--------|------|------|
| **SST-5** | ç»†ç²’åº¦æƒ…æ„Ÿåˆ†æ | 5 | ç”µå½±è¯„è®ºï¼ˆvery negative â†’ very positiveï¼‰ |
| **Emotion** | æƒ…ç»ªè¯†åˆ« | 6 | çŸ­æ–‡æœ¬æƒ…ç»ªåˆ†ç±»ï¼ˆjoy, anger, fear ç­‰ï¼‰ |
| **CR** | äº§å“è¯„è®ºæƒ…æ„Ÿ | 2 | å®¢æˆ·è¯„è®ºæ­£è´Ÿå‘åˆ¤æ–­ |
| **AG News** | æ–°é—»ä¸»é¢˜åˆ†ç±» | 4 | World, Sports, Business, Sci/Tech |

### âš™ï¸ å®éªŒè®¾ç½®
- **é›¶æ ·æœ¬è®¾ç½®ï¼ˆZero-shotï¼‰**ï¼šä¸æä¾›ä»»ä½•çœŸå®æ ‡æ³¨æ ·æœ¬ï¼Œä»…è¾“å…¥ label åç§°ã€‚
- **å°‘æ ·æœ¬è®¾ç½®ï¼ˆFew-shotï¼‰**ï¼šæ¯ç±»æä¾› k=2, 4, 8 ä¸ªçœŸå®æ ·æœ¬ã€‚
- **backbone æ¨¡å‹**ï¼š
  - **SetFit**ï¼šåŸºäº sentence-transformers çš„ few-shot æ¡†æ¶ï¼ˆä½¿ç”¨ `all-mpnet-base-v2` ç¼–ç å™¨ï¼‰
  - **EuroBERT**ï¼šå¤šè¯­è¨€ç¼–ç å™¨ï¼Œç”¨äºå¯¹æ¯”é€šç”¨ encoder è¡¨ç°
- **LLM è§’è‰²**ï¼šä½¿ç”¨ GPT-5 ä½œä¸º agentï¼Œé€šè¿‡ Hugging Face çš„ `smolagents` æ¡†æ¶å®ç° ReAct-style agent æ§åˆ¶æµç¨‹ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼šAccuracyï¼ˆå‡†ç¡®ç‡ï¼‰

### ğŸ†š å¯¹æ¯”çš„åŸºçº¿æ–¹æ³•
| æ–¹æ³• | ç®€ä»‹ |
|-----|------|
| **Baseline** | åŸå§‹ SetFit / Encoder è®­ç»ƒ |
| **Baseline + Prompt** | åŠ å…¥é™æ€ prompt æå‡ |
| **Baseline + Manager** | æœ¬æ–‡æå‡ºçš„ agentic loop æ–¹æ³• |
| **AncSetFit** | å¼•å…¥ anchor statements æ³¨å…¥ label semantics |
| **ADAPET** | Pattern-exploiting training for few-shot tuning |
| **GLiClass 3.0** | ç°æˆ zero-shot åˆ†ç±»å™¨ï¼ˆ151M å‚æ•°ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & 2ï¼‰

#### âœ… é›¶æ ·æœ¬ï¼ˆk=0ï¼‰è¡¨ç°ï¼ˆSetFit backboneï¼‰

| æ–¹æ³• | SST-5 | Emotion | CR | AG News |
|------|-------|--------|----|--------|
| GLiClass 3.0 | 43.8 | **51.9** | 90.2 | 68.8 |
| **Ours (Manager)** | **47.0**â†‘ | 50.9 | **87.8** | **82.6**â†‘ |

> âœ… åœ¨ **3/4 æ•°æ®é›†ä¸Šè¶…è¶Šæ›´å¤§è§„æ¨¡çš„ GLiClass æ¨¡å‹**ï¼ˆå°½ç®¡è‡ªèº« encoder æ›´å°ï¼š110M vs 151Mï¼‰

#### âœ… å°‘æ ·æœ¬ï¼ˆk=2~8ï¼‰è¡¨ç°è¶‹åŠ¿

| æ–¹æ³• | Emotion (k=2) | CR (k=2) | AG News (k=2) |
|------|--------------|----------|----------------|
| SetFit Baseline | 30.0 | 75.5 | 65.3 |
| +Prompt | 39.1 | 89.5 | 69.4 |
| **+Manager (ours)** | **56.5**â†‘â†‘ | **89.0** | **83.2**â†‘â†‘ |

> âœ… åœ¨ **k=2 æç«¯å°‘æ ·æœ¬åœºæ™¯ä¸‹æ˜¾è‘—é¢†å…ˆ**ï¼Œå°¤å…¶åœ¨ Emotion ä¸Šæå‡è¶… 17 ä¸ªç™¾åˆ†ç‚¹ã€‚

#### ğŸ” æ€§èƒ½éšæ ·æœ¬å¢åŠ çš„å˜åŒ–è¶‹åŠ¿
- å¤šæ•°æ•°æ®é›†ï¼ˆå¦‚ SST-5, CRï¼‰åœ¨ k=2 åå¢ç›Šé€’å‡ â†’ è¡¨æ˜åˆæˆæ•°æ®å·²å¿«é€Ÿé¥±å’Œæ¨¡å‹å­¦ä¹ èƒ½åŠ›ã€‚
- **ä¾‹å¤–æ˜¯ AG News**ï¼šéšç€ k å¢åŠ ä»æŒç»­æå‡ â†’ å…¶ label semantics æ›´å¤æ‚ï¼Œéœ€æ›´å¤šå¼•å¯¼ã€‚

### ğŸ§ª æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
ä» Table 1 å¯çœ‹å‡ºï¼š
- **Baseline â†’ +Prompt**ï¼šæœ‰ä¸€å®šæå‡ï¼Œè¯´æ˜ label semantics æœ‰å¸®åŠ©ã€‚
- **+Prompt â†’ +Manager**ï¼šè¿›ä¸€æ­¥æ˜¾è‘—æå‡ â†’ éªŒè¯äº† **error-driven feedback loop çš„æœ‰æ•ˆæ€§**ã€‚
- ç‰¹åˆ«æ˜¯åœ¨ zero-shot ä¸‹ï¼Œé™æ€ prompt æå‡æœ‰é™ï¼Œè€ŒåŠ¨æ€ refinement èƒ½å¸¦æ¥è´¨å˜ã€‚

> âœ… ç»“è®ºï¼š**é—­ç¯è¿­ä»£æœºåˆ¶è¿œä¼˜äºä¸€æ¬¡æ€§é™æ€ç”Ÿæˆï¼ˆone-off generationï¼‰**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **LLM å¯ä½œä¸ºé«˜æ•ˆçš„æ•°æ®ç­–å±•è€…ï¼ˆData Curatorï¼‰**  
   > å³ä½¿ä¸å‚ä¸æ¨ç†ï¼Œä¹Ÿèƒ½é€šè¿‡åŠ¨æ€ç”Ÿæˆé«˜è´¨é‡ã€æœ‰é’ˆå¯¹æ€§çš„è®­ç»ƒæ•°æ®å¤§å¹…æå‡ä¸‹æ¸¸å°æ¨¡å‹æ€§èƒ½ã€‚

2. **Curate-Train-Refine æ¡†æ¶æ˜¾è‘—ç¼©å°äº† zero-shot ä¸ few-shot çš„å·®è·**  
   > åœ¨é›¶æ ·æœ¬æ¡ä»¶ä¸‹ï¼Œæœ¬æ–¹æ³•æ€§èƒ½ç”šè‡³è¶…è¿‡ä½¿ç”¨ 8 ä¸ªçœŸå®æ ·æœ¬çš„ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚åœ¨ SST-5 ä¸Šï¼‰ã€‚

3. **è½»é‡æ¨¡å‹ + åŠ¨æ€æ•°æ®ç”Ÿæˆ = é«˜æ•ˆä¸”é«˜æ€§èƒ½çš„è§£å†³æ–¹æ¡ˆ**  
   > æˆåŠŸè§£è€¦è®­ç»ƒä¸éƒ¨ç½²ï¼šè®­ç»ƒé˜¶æ®µåˆ©ç”¨ LLM ç”Ÿæˆæ•°æ®ï¼Œéƒ¨ç½²é˜¶æ®µå®Œå…¨è„±ç¦» LLMï¼Œå®ç°ä½å»¶è¿Ÿã€ä½æˆæœ¬æœåŠ¡ã€‚

4. **SetFit æ¯”é€šç”¨ encoderï¼ˆå¦‚ EuroBERTï¼‰æ›´é€‚åˆæ­¤ç±»ä»»åŠ¡**  
   > å› å…¶ contrastive fine-tuning æœºåˆ¶æ›´é€‚é…å°‘é‡æ ·æœ¬ä¸‹çš„è¯­ä¹‰åˆ¤åˆ«ã€‚

---

### âš ï¸ å±€é™æ€§
1. **ä¾èµ–å¼ºå¤§ LLM ç”Ÿæˆèƒ½åŠ›**  
   > å½“å‰å®éªŒåŸºäº GPT-5ï¼Œè‹¥æ¢ç”¨è¾ƒå° LLMï¼Œå¯èƒ½æ— æ³•å‡†ç¡®è¯Šæ–­é”™è¯¯æˆ–ç”Ÿæˆé«˜è´¨é‡æ ·æœ¬ã€‚

2. **ç”Ÿæˆæ•°æ®çš„è´¨é‡æ§åˆ¶æŒ‘æˆ˜**  
   > å­˜åœ¨é‡å¤ã€åå·®æˆ–è¯­ä¹‰æ¼‚ç§»é£é™©ï¼Œéœ€åŠ å…¥å»é‡ã€å¤šæ ·æ€§çº¦æŸç­‰æœºåˆ¶ã€‚

3. **æœªå¼•å…¥äººç±»åé¦ˆ**  
   > å®Œå…¨è‡ªåŠ¨åŒ–å¯èƒ½å¯¼è‡´é”™è¯¯ç´¯ç§¯ï¼Œæœªæ¥å¯è€ƒè™‘ human-in-the-loop æ ¡æ­£ã€‚

4. **è®¡ç®—å¼€é”€é›†ä¸­åœ¨è®­ç»ƒé˜¶æ®µ**  
   > è™½ç„¶æ¨ç†å¿«ï¼Œä½†å¤šæ¬¡ loop å¯¼è‡´è®­ç»ƒæ—¶é—´å¢é•¿ï¼Œä¸é€‚åˆå¿«é€Ÿè¿­ä»£åœºæ™¯ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‹“å±•è‡³ç»“æ„åŒ–é¢„æµ‹ä»»åŠ¡**  
   > å¦‚ NERã€Relation Extraction ç­‰ï¼Œæ¢ç´¢æ˜¯å¦åŒæ ·é€‚ç”¨ã€‚

2. **å¢å¼º error analysis å·¥å…·**  
   > å¼•å…¥ calibration-awareã€robustness-aware diagnosticsï¼Œè®© LLM æ›´ç²¾å‡†å®šä½é—®é¢˜ã€‚

3. **ç ”ç©¶ä¸åŒ LLM backbone çš„å½±å“**  
   > æ¢ç´¢å¼€æºæˆ–æ›´å° LLM æ˜¯å¦ä¹Ÿèƒ½èƒœä»» curator è§’è‰²ã€‚

4. **æ¢ç´¢ human-agent collaboration**  
   > åœ¨å…³é”®èŠ‚ç‚¹å¼•å…¥äººå·¥å®¡æ ¸ï¼Œæé«˜æ•°æ®å¯ä¿¡åº¦ã€‚

5. **ä¼˜åŒ– generation budget ä¸æ”¶æ•›ç­–ç•¥**  
   > è‡ªåŠ¨åˆ¤æ–­ä½•æ—¶åœæ­¢ loopï¼Œé¿å…æ— æ•ˆè¿­ä»£ã€‚

---

## âœ… æ€»ç»“ä¸€å¥è¯
> æœ¬æ–‡æå‡ºäº† **é¦–ä¸ªé—­ç¯çš„ agentic æ•°æ®ç”Ÿæˆæ¡†æ¶ Curate-Train-Refine**ï¼Œè¯æ˜äº† **LLM å¯ä½œä¸ºå¼ºå¤§çš„ç¦»çº¿æ•°æ®ç­–å±•å·¥å…·**ï¼Œåœ¨æ— éœ€æµ‹è¯•æ—¶è°ƒç”¨å¤§æ¨¡å‹çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡è½»é‡åˆ†ç±»å™¨åœ¨ zero/few-shot åœºæ™¯ä¸‹çš„æ€§èƒ½ï¼Œä¸ºé«˜æ•ˆ NLP éƒ¨ç½²æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 6. [W4A16 Mixed-Precision Matrix Multiplication on Decoupled Architecture: Kernel Design and Memory Bottleneck Analysis for Ascend NPUs](https://arxiv.org/abs/2601.16536)

**Authors**: Yuanhong He, Peiyu Niu, Jun Chen, Chenchen Zhang, Chao Yang  
**Category**: cs.DC  
**Published**: 2026-01-26  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.16536v1  

#### Abstract
As Large Language Models (LLMs) scale, weight-only quantization (W4A16: 4-bit weights, 16-bit activations) becomes critical for reducing memory footprint with minimal accuracy loss. However, its efficient deployment on Huawei's Ascend 910 Neural Processing Unit (NPU) is challenging due to limited na...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*W4A16 Mixed-Precision Matrix Multiplication on Decoupled Architecture: Kernel Design and Memory Bottleneck Analysis for Ascend NPUs*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹ **åä¸º Ascend 910 NPU** ä¸Šç¼ºä¹å¯¹ **W4A16 mixed-precision matrix multiplication**ï¼ˆ4-bit æƒé‡ã€16-bit æ¿€æ´»ï¼‰åŸç”Ÿæ”¯æŒçš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§é«˜æ•ˆçš„å†…æ ¸å®ç°æ–¹æ¡ˆã€‚ç”±äº Ascend æ¶æ„é‡‡ç”¨ **decoupled compute architecture**ï¼ˆè§£è€¦è®¡ç®—æ¶æ„ï¼‰ï¼Œå…¶ cube core å’Œ vector core åˆ†ç¦»è°ƒåº¦ï¼Œæ— æ³•åƒ NVIDIA GPU é‚£æ ·é«˜æ•ˆèåˆ dequantization ä¸ GEMM è¿ç®—ï¼Œå¯¼è‡´ä½æ¯”ç‰¹é‡åŒ–åœ¨è¯¥å¹³å°éš¾ä»¥å‘æŒ¥æ€§èƒ½ä¼˜åŠ¿ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
- **é¦–ä¸ªé¢å‘ Ascend 910 çš„ W4A16 GEMM å†…æ ¸å®ç°**ï¼š  
  åˆ©ç”¨ vector core æ‰§è¡Œ **on-the-fly INT4-to-FP16 dequantization**ï¼Œcube core è´Ÿè´£é«˜ååé‡çš„ FP16 GEMM è®¡ç®—ï¼Œå®ç°äº†æ··åˆç²¾åº¦çŸ©é˜µä¹˜æ³•çš„ç«¯åˆ°ç«¯æ‰§è¡Œã€‚
  
- **Split-K å¹¶è¡ŒåŒ–ç­–ç•¥ä¼˜åŒ–è´Ÿè½½å‡è¡¡**ï¼š  
  åœ¨è¾“å‡ºç»´åº¦è¾ƒå°ï¼ˆå¦‚ LLM è§£ç é˜¶æ®µ M æˆ– N è¾ƒå°ï¼‰æ—¶ï¼ŒSplit-K å¯æ›´å‡åŒ€åœ°åˆ†é…è®¡ç®—ä»»åŠ¡è‡³å¤šä¸ª AI Coreï¼Œæå‡èµ„æºåˆ©ç”¨ç‡ã€‚

- **åŒç¼“å†²ï¼ˆdouble bufferingï¼‰ä¸ç¡¬ä»¶äº‹ä»¶åŒæ­¥æœºåˆ¶**ï¼š  
  é€šè¿‡ MTEï¼ˆMemory Transfer Engineï¼‰ä¸è®¡ç®—å•å…ƒä¹‹é—´çš„ç¡¬ä»¶äº‹ä»¶é©±åŠ¨åŒæ­¥ï¼Œéšè—æ•°æ®æ¬è¿å»¶è¿Ÿï¼Œæ„å»ºé«˜æ•ˆæµæ°´çº¿ã€‚

- **æ­ç¤ºå†…å­˜ç“¶é¢ˆæœ¬è´¨**ï¼š  
  å‘ç°æ€§èƒ½ç“¶é¢ˆå¹¶éæ¥è‡ª dequantization è®¡ç®—æœ¬èº«ï¼Œè€Œæ˜¯ **dequantized weights åœ¨ global memory ä¸­çš„é¢å¤–ä¼ è¾“å¼€é”€**ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| å¯¹æ¯”ç»´åº¦ | æœ¬æ–‡æ–¹æ³• | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ PyTorch on Ascend / Data-Parallelï¼‰ |
|--------|--------|---------------------------------------------|
| æ”¯æŒ W4A16 | âœ… å®Œæ•´æ”¯æŒ | âŒ æ— åŸç”Ÿæ”¯æŒ |
| æ€§èƒ½ä¼˜åŒ– | åˆ©ç”¨ Split-K + å¼‚æ„æ ¸å¿ƒååŒ | ä»…ä½¿ç”¨ data-parallelï¼Œè´Ÿè½½ä¸å‡ |
| å†…å­˜æ•ˆç‡ | å‡å°‘æƒé‡å­˜å‚¨å ç”¨ 4Ã— | å­˜å‚¨ä»ä¸º FP16 |
| å®é™…åŠ é€Ÿæ¯” | æœ€é«˜è¾¾ 1.74Ã—ï¼ˆvs data-parallelï¼‰ | åŸºå‡†æ°´å¹³ |

> âš ï¸ æ³¨æ„ï¼šå°½ç®¡æƒé‡å‹ç¼© 4Ã—ï¼Œä½†ç”±äºéœ€å°† dequantized weights å†™å› global memory ä¾› cube core ä½¿ç”¨ï¼Œå®é™…æœªè¾¾åˆ°ç†è®º ~4Ã— åŠ é€Ÿã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼šHuawei Ascend 910 NPU
- **ç¼–ç¨‹æ¨¡å‹**ï¼šåŸºäº Ascend C å¼€å‘ï¼Œåˆ©ç”¨ CANN å·¥å…·é“¾è¿›è¡Œåº•å±‚æ§åˆ¶
- **è¾“å…¥å½¢å¼**ï¼š
  - æ¿€æ´»çŸ©é˜µ $ A \in \text{FP16}^{M \times K} $
  - é‡åŒ–æƒé‡ $ W \in \text{INT4}^{K \times N} $
  - è¾“å‡º $ C = A \cdot \text{Dequant}(W) $

- **çŸ©é˜µè§„æ¨¡è®¾è®¡**ï¼šè¦†ç›–å…¸å‹ LLM æ¨ç†åœºæ™¯ï¼Œå°¤å…¶æ˜¯ **decode phase** ç‰¹å¾ï¼ˆå° batch sizeï¼Œå¤§ Kï¼‰
  - å¤šç»„ $(N, K)$ é…ç½®ï¼šå¦‚ (1536, 6144), (2048, 8192), (7168, 18432)
  - Batch size $M$ èŒƒå›´ï¼šä» 1 åˆ° 128

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
- **Execution Time**ï¼ˆæ‰§è¡Œæ—¶é—´ï¼‰
- **Speedup**ï¼ˆç›¸å¯¹äº baseline çš„åŠ é€Ÿæ¯”ï¼‰
- **Memory Bandwidth Utilization**
- ä¸åŒ parallelization ç­–ç•¥ä¸‹çš„å¯æ‰©å±•æ€§åˆ†æ

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Data-Parallel W4A16 Kernel**ï¼šåŸºäº CATLASS å®ç°çš„ä¼ ç»Ÿå¹¶è¡Œç­–ç•¥ï¼Œä½œä¸ºä¸»è¦å¯¹æ¯”åŸºå‡†
- **Native FP16Ã—FP16 GEMM in PyTorch**ï¼šç”¨äºè¡¡é‡ W4A16 ç›¸å¯¹äºå…¨ç²¾åº¦çš„ç†è®ºåŠ é€Ÿæ½œåŠ›

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰Split-K vs Data-Parallel æ€§èƒ½å¯¹æ¯”ï¼ˆå›¾2ï¼‰
- å½“ $K > N$ æ—¶ï¼ˆå…¸å‹äº LLM è§£ç ï¼‰ï¼ŒSplit-K æ˜¾è‘—ä¼˜äº data-parallelï¼š
  - **åŠ é€Ÿæ¯”èŒƒå›´ï¼š1.01Ã— ~ 1.74Ã—**
  - æœ€ä½³è¡¨ç°å‡ºç°åœ¨ $N=4096, K=16348$, batch=1 æ—¶ï¼Œè¾¾åˆ° **1.74Ã—** åŠ é€Ÿ
- å° batch size ä¸‹æ€§èƒ½ç¨³å®šï¼Œå›  tile padding è¡¥é½äº†è®¡ç®—ç²’åº¦

#### ï¼ˆ2ï¼‰W4A16 vs FP16Ã—FP16 æ€§èƒ½å¯¹æ¯”ï¼ˆå›¾3ï¼‰
- å°½ç®¡æƒé‡ä½“ç§¯å‡å°‘ 4Ã—ï¼Œä½†å—é™äºé¢å¤– global memory è®¿é—®ï¼š
  - **æœ€å¤§ä»…å®ç° 1.48Ã— åŠ é€Ÿ**ï¼ˆbatch=128, N=2048, K=10240ï¼‰
  - å° batch ä¸‹åŠ é€Ÿæ•ˆæœæ›´å¼±ï¼ˆæœ€ä½çº¦ 1.02Ã—ï¼‰

#### ï¼ˆ3ï¼‰å†…å­˜ç“¶é¢ˆåˆ†æ
- å®éªŒéªŒè¯ï¼šdequantization è®¡ç®—æœ¬èº«ä¸æ˜¯ç“¶é¢ˆ
- ä¸»è¦å¼€é”€æ¥æºäºï¼š
  - Vector core dequant åå†™å…¥ global memory
  - Cube core å†æ¬¡ä» global memory è¯»å– FP16 weights
  â†’ å½¢æˆâ€œ**memory ping-pong**â€æ•ˆåº”ï¼Œæ˜¾è‘—å¢åŠ å¸¦å®½å‹åŠ›

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Split-K æ˜¯é€‚åˆ Ascend æ¶æ„çš„å°æ‰¹é‡ GEMM å¹¶è¡Œç­–ç•¥**ï¼Œå°¤å…¶é€‚ç”¨äº LLM decode åœºæ™¯ã€‚
2. **W4A16 åœ¨ Ascend ä¸Šå¯è¡Œä½†æœªè¾¾é¢„æœŸåŠ é€Ÿ**ï¼šè™½ç„¶èŠ‚çœäº†å­˜å‚¨ç©ºé—´ï¼Œä½†å›  **decoupled architecture å¯¼è‡´å¿…é¡»ç»ç”± global memory ä¼ é€’ä¸­é—´ç»“æœ**ï¼Œé™åˆ¶äº†æ€§èƒ½æå‡ã€‚
3. **çœŸæ­£çš„ç“¶é¢ˆæ˜¯ memory trafficï¼Œè€Œé compute æˆ– dequantization latency** â€”â€” è¿™ä¸€å‘ç°æŒ‘æˆ˜äº†æ™®éè®¤ä¸ºâ€œdequantization æ…¢â€çš„ç›´è§‰å‡è®¾ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ– global memory ä¸­è½¬**ï¼švector core ä¸ cube core ä¹‹é—´æ— ç›´æ¥é€šè·¯ï¼Œå¼ºåˆ¶å¼•å…¥å†—ä½™æ•°æ®ç§»åŠ¨ã€‚
- **æ— æ³•å®Œå…¨é‡Šæ”¾ä½æ¯”ç‰¹é‡åŒ–æ½œåŠ›**ï¼šç†è®ºä¸Šåº”æ¥è¿‘ 4Ã— å­˜å‚¨å‹ç¼©å¸¦æ¥çš„å¸¦å®½æ”¶ç›Šï¼Œä½†å®é™…ä»…è·å¾—çº¦ 1.5Ã— åŠ é€Ÿã€‚
- **Padding å¼€é”€å½±å“å° batch æ•ˆç‡**ï¼šå³ä½¿ batch=1ï¼Œä¹Ÿéœ€å¡«å……è‡³æœ€å° tile å•ä½ï¼Œé€ æˆèµ„æºæµªè´¹ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **ç¡¬ä»¶-è½¯ä»¶ååŒè®¾è®¡ï¼ˆco-designï¼‰**ï¼š
   - å»ºè®®å¢åŠ  **vector-to-cube direct data path**ï¼Œé¿å… global memory ä¸­è½¬
   - è®¾è®¡ **fused dequant-GEMM æŒ‡ä»¤**ï¼Œåœ¨ç¡¬ä»¶å±‚é¢èåˆæ“ä½œ
2. **æ¢ç´¢å…¶ä»–é‡åŒ–æ ¼å¼é€‚é…**ï¼šå¦‚ W2/W3/W8 + A16 ç»„åˆï¼Œåœ¨ Ascend æ¶æ„ä¸‹é‡æ–°æƒè¡¡ç²¾åº¦ä¸æ•ˆç‡
3. **ä¼˜åŒ– memory layout ä¸ cache reuse**ï¼šè¿›ä¸€æ­¥å‡å°‘é‡å¤è®¿å­˜
4. **æ”¯æŒæ›´å¤š LLM kernels çš„æ··åˆç²¾åº¦æ‰©å±•**ï¼šå°†æ­¤è®¾è®¡èŒƒå¼æ¨å¹¿è‡³ attentionã€RMSNorm ç­‰æ¨¡å—

---

## æ€»ç»“ä¸€å¥è¯
> æœ¬æ–‡é¦–æ¬¡å®ç°äº† **Ascend 910 ä¸Šçš„ W4A16 GEMM å†…æ ¸**ï¼Œé€šè¿‡ **Split-K + å¼‚æ„æ ¸å¿ƒåä½œ + åŒç¼“å†²æµæ°´çº¿** å®ç°æœ€é«˜ **1.74Ã—** åŠ é€Ÿï¼Œå¹¶æ­ç¤ºäº† **decoupled architecture ä¸‹ global memory æ•°æ®å¾€è¿”æ‰æ˜¯æ€§èƒ½ç“¶é¢ˆ**ï¼Œä¸ºåç»­ä½æ¯”ç‰¹é‡åŒ–åœ¨ä¸“ç”¨ NPU ä¸Šçš„éƒ¨ç½²æä¾›äº†é‡è¦å®è·µæŒ‡å¯¼ä¸ä¼˜åŒ–æ–¹å‘ã€‚

</details>

---

### 7. [Towards a Theoretical Understanding to the Generalization of RLHF](https://arxiv.org/abs/2601.16403)

**Authors**: Zhaochun Li (Beijing Institute of Technolegy, Zhongguancun Academy), Mingyang Yi (Renmin University of China), Yue Wang (Zhongguancun Academy), Shisheng Cui (Beijing Institute of Technolegy), Yong Liu (Renmin University of China)  
**Category**: cs.LG  
**Published**: 2026-01-26  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.16403v1  

#### Abstract
Reinforcement Learning from Human Feedback (RLHF) and its variants have emerged as the dominant approaches for aligning Large Language Models with human intent. While empirically effective, the theoretical generalization properties of these methods in high-dimensional settings remain to be explored....

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Towards a Theoretical Understanding to the Generalization of RLHF è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³ **Reinforcement Learning from Human Feedback (RLHF)** åœ¨é«˜ç»´åœºæ™¯ä¸‹çš„**æ³›åŒ–èƒ½åŠ›ç¼ºä¹ç†è®ºè§£é‡Š**çš„é—®é¢˜ã€‚å°½ç®¡ RLHF åœ¨å®è·µä¸­è¢«å¹¿æ³›ç”¨äºå¯¹é½å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸äººç±»æ„å›¾ï¼Œå¹¶å–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†å…¶ç†è®ºåŸºç¡€ï¼Œå°¤å…¶æ˜¯å…³äºæ¨¡å‹åœ¨æœªè§æ•°æ®ä¸Šçš„æ³›åŒ–æ€§èƒ½ï¼Œä»ä¸æ¸…æ™°ã€‚

ç°æœ‰ç†è®ºå·¥ä½œé€šå¸¸ä¾èµ–äº**å¥–åŠ±æ¨¡å‹å‚æ•°çš„æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMLEï¼‰çš„ä¸€è‡´æ€§**ï¼Œè¿™è¦æ±‚å¼ºæ•°æ®è¦†ç›–å‡è®¾ï¼ˆå¦‚ç‰¹å¾ç©ºé—´æ»¡ç§©ï¼‰ï¼Œè€Œè¿™ä¸€å‡è®¾åœ¨é«˜ç»´ã€ç¨€ç–çš„å®é™…åœºæ™¯ä¸­å¾€å¾€éš¾ä»¥æ»¡è¶³ã€‚æ­¤å¤–ï¼Œè¿™äº›åˆ†æå¿½ç•¥äº† RL è¿‡ç¨‹æœ¬èº«ï¼ˆå¦‚ç­–ç•¥ä¼˜åŒ–ï¼‰å¯¹æ³›åŒ–çš„è´¡çŒ®ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡ºäº†ä¸€ç§**ç«¯åˆ°ç«¯ï¼ˆend-to-endï¼‰çš„ç†è®ºæ¡†æ¶**æ¥åˆ†æ RLHF çš„æ³›åŒ–æ€§èƒ½ï¼Œå…¶æ ¸å¿ƒæ˜¯åŸºäº **algorithmic stability**ï¼ˆç®—æ³•ç¨³å®šæ€§ï¼‰ç†è®ºã€‚å…·ä½“åˆ›æ–°ç‚¹å¦‚ä¸‹ï¼š

- **ç«¯åˆ°ç«¯åˆ†ææ¡†æ¶**ï¼šä¸åŒäºä»¥å¾€å°†å¥–åŠ±å»ºæ¨¡å’Œç­–ç•¥ä¼˜åŒ–åˆ†ç¦»çš„åˆ†æï¼Œæœ¬æ–‡ç›´æ¥åˆ†æä»æ•°æ®åˆ°æœ€ç»ˆç­–ç•¥çš„å®Œæ•´å­¦ä¹ è¿‡ç¨‹ï¼Œæ›´ç¬¦åˆå®é™…è®­ç»ƒæµç¨‹ã€‚
- **å…³é”®å‡è®¾ï¼šç‰¹å¾è¦†ç›–ï¼ˆFeature Coverageï¼‰**ï¼šæå‡ºå¹¶åˆ©ç”¨äº†ä¸€ä¸ªæ–°çš„â€œç‰¹å¾è¦†ç›–â€å‡è®¾ï¼ˆAssumption 5ï¼‰ã€‚è¯¥å‡è®¾è®¤ä¸ºï¼Œéšç€è®­ç»ƒæ ·æœ¬ `n` çš„å¢åŠ ï¼Œç»éªŒåæ–¹å·®çŸ©é˜µçš„åˆ—ç©ºé—´ï¼ˆcolumn spaceï¼‰ä¼šé€æ¸æ‰©å±•ï¼Œä»¥è¿‘ä¼¼è¦†ç›–æ•´ä¸ªç‰¹å¾ç©ºé—´ï¼Œè€Œè½åœ¨è¯¥å­ç©ºé—´å¤–çš„æ®‹å·®é¡¹ï¼ˆresidual componentï¼‰çš„èŒƒæ•°ä»¥ `O(nâ»Â¹)` çš„é€Ÿåº¦è¡°å‡ã€‚è¿™æ¯”ä¼ ç»Ÿçš„â€œæ­£å®šæ€§â€å‡è®¾æ›´å¼±ã€æ›´ç°å®ã€‚
- **ç»Ÿä¸€åˆ†æå¤šç§ä¼˜åŒ–å™¨**ï¼šå°†ç®—æ³•ç¨³å®šæ€§æ¡†æ¶åº”ç”¨äº KL æ­£åˆ™åŒ–çš„ RLHF ç›®æ ‡å‡½æ•°ï¼Œå¹¶æ¨å¯¼å‡ºå¯¹ **Gradient Ascent (GA)** å’Œ **Stochastic Gradient Ascent (SGA)** ç­‰æ¢¯åº¦æ³•çš„æ˜¾å¼æ³›åŒ–ç•Œã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ç°æœ‰æ–¹æ³• | æœ¬æ–‡æ–¹æ³• |
| :--- | :--- | :--- |
| **åˆ†æè§†è§’** | åˆ†ç¦»å¼ï¼ˆå…ˆå¥–åŠ±å»ºæ¨¡ï¼Œå†ç­–ç•¥æå–ï¼‰ | **ç«¯åˆ°ç«¯**ï¼ˆè”åˆåˆ†æï¼‰ |
| **æ ¸å¿ƒå‡è®¾** | å¼ºæ•°æ®è¦†ç›–ï¼ˆå¦‚åæ–¹å·®çŸ©é˜µæ­£å®šï¼‰ | **å¼±ç‰¹å¾è¦†ç›–**ï¼ˆæ®‹å·®éš `n` è¡°å‡ï¼‰ |
| **é€‚ç”¨æ€§** | é«˜ç»´ä¸‹å¸¸ä¸æˆç«‹ | **æ›´é€‚ç”¨äºé«˜ç»´ã€æœ‰é™æ•°æ®**çš„å®é™…åœºæ™¯ |
| **åˆ†æå¯¹è±¡** | ä¸»è¦å…³æ³¨å¥–åŠ±å‚æ•°ä¸€è‡´æ€§ | **ç›´æ¥åˆ†æç­–ç•¥çš„æ¬¡ä¼˜æ€§å·®è·ï¼ˆsuboptimality gapï¼‰** |
| **ä¼˜åŒ–è¿‡ç¨‹** | è§†ä¸ºç²¾ç¡®æœ€å¤§åŒ– | **æ˜ç¡®è€ƒè™‘ GA/SGA ç­‰è¿­ä»£ç®—æ³•çš„å½±å“** |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

æœ¬æ–‡ä¸º**æ¨¡æ‹Ÿå®éªŒ**ï¼ˆsimulation experimentsï¼‰ï¼Œå¹¶æœªä½¿ç”¨çœŸå®ä¸–ç•Œçš„æ•°æ®é›†ã€‚ä½œè€…äººå·¥æ„é€ äº†ä¸¤ç§ç‰¹å¾ç©ºé—´æ¥éªŒè¯ç†è®ºï¼š

1.  **æ­£å®šåæ–¹å·®çŸ©é˜µåœºæ™¯**ï¼šæ„å»ºä¸€ä¸ªæ ‡å‡†çš„æ­£äº¤åŸº `{xâ‚, ..., x_d}`ï¼Œé€šè¿‡éå‡åŒ€é‡‡æ ·ï¼ˆæŸä¸ªæ–¹å‘æ¦‚ç‡æå°ï¼‰æ¥æ§åˆ¶æ•°æ®è¦†ç›–æƒ…å†µã€‚
2.  **ä¸è¶³è¦†ç›–ï¼ˆInsufficient Coverageï¼‰åœºæ™¯**ï¼šå°†ç‰¹å¾ç©ºé—´é™åˆ¶åœ¨ä¸€ä¸ªä½ç»´æœ‰æ•ˆå­ç©ºé—´ `A`ï¼ˆç»´åº¦ `d_eff < d`ï¼‰å†…ã€‚æ‰€æœ‰ç‰¹å¾å‘é‡éƒ½ä½äºæ­¤å­ç©ºé—´ï¼Œä½†ç»éªŒåæ–¹å·®çŸ©é˜µçš„ç§©å—é™äºæ ·æœ¬é‡ `n`ï¼Œä»è€Œè‡ªç„¶äº§ç”Ÿæ®‹å·®ã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

- **ç›®æ ‡**ï¼šéªŒè¯ç†è®ºæ¨å¯¼çš„æ³›åŒ–ç•Œï¼Œç‰¹åˆ«æ˜¯æ¬¡ä¼˜æ€§å·®è·ï¼ˆSuboptimality Gapï¼‰ä¸æ ·æœ¬é‡ `n` å’Œä¼˜åŒ–æ­¥æ•° `T` çš„å…³ç³»ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **æ¬¡ä¼˜æ€§å·®è· (Suboptimality Gap)**ï¼šå®šä¹‰ä¸º `|J(Ï€_test) - J(Ï€_test*)|`ï¼Œå…¶ä¸­ `Ï€_test` æ˜¯åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°çš„å­¦ä¹ ç­–ç•¥ï¼Œ`Ï€_test*` æ˜¯æœ€ä¼˜ç­–ç•¥ã€‚è¯¥å€¼è¶Šå°ï¼Œè¡¨ç¤ºæ³›åŒ–æ€§èƒ½è¶Šå¥½ã€‚
  - è¯¥æŒ‡æ ‡é€šè¿‡ä¸€ä¸ªç‹¬ç«‹çš„å¤§è§„æ¨¡æµ‹è¯•é›†ï¼ˆ`size=15000`ï¼‰æ¥è¿‘ä¼¼æœŸæœ›ç›®æ ‡ `J(Ï€)`ã€‚
- **å®éªŒè®¾è®¡**ï¼š
  1.  **Case 1**: å›ºå®šä¼˜åŒ–æ­¥æ•°ï¼Œç ”ç©¶æ¬¡ä¼˜æ€§å·®è·éšæ ·æœ¬é‡ `n` çš„å˜åŒ–ï¼ˆéªŒè¯ `O(nâ»Â¹)` æ³›åŒ–ç•Œï¼‰ã€‚
  2.  **Case 2**: å›ºå®šæ ·æœ¬é‡ `n`ï¼Œç ”ç©¶æ¬¡ä¼˜æ€§å·®è·éšä¼˜åŒ–æ­¥æ•° `T` çš„å˜åŒ–ï¼ˆéªŒè¯ä¼˜åŒ–è¿‡ç¨‹å¯¹æ³›åŒ–çš„æ­£é¢å½±å“ï¼‰ã€‚
- **å­¦ä¹ ç®—æ³•**ï¼šå®ç°äº† **Gradient Ascent (GA)** å’Œ **Stochastic Gradient Ascent (SGA)** æ¥ä¼˜åŒ–ç­–ç•¥å‚æ•°ã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

æœ¬æ–‡æ²¡æœ‰ä¸å…¶ä»–å¤–éƒ¨çš„ RLHF ç®—æ³•è¿›è¡Œæ€§èƒ½å¯¹æ¯”ã€‚å…¶â€œåŸºçº¿â€æ˜¯**ç†è®ºé¢„æœŸ**ï¼š
- å°†å®éªŒç»“æœä¸ç†è®ºæ¨å¯¼çš„è¾¹ç•Œï¼ˆå¦‚ `O(nâ»Â¹)`, `O(Tâ»Â¹/Â² + nâ»Â¹)`) è¿›è¡Œæ¯”è¾ƒã€‚
- å°†ä¸åŒç®—æ³•ï¼ˆç²¾ç¡®ä¼˜åŒ–ã€GAã€SGAï¼‰çš„ç»“æœè¿›è¡Œå†…éƒ¨å¯¹æ¯”ï¼Œä»¥éªŒè¯ç†è®ºåˆ†æã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”ç»“æœ**

å®éªŒç»“æœé€šè¿‡ **Figure 1** å’Œ **Figure 2** å±•ç¤ºï¼Œå®Œç¾åœ°éªŒè¯äº†ç†è®ºé¢„æµ‹ï¼š

1.  **æ¬¡ä¼˜æ€§å·®è·ä¸æ ·æœ¬é‡ `n` çš„å…³ç³» (Figure 1a, 1b)**ï¼š
    - å½“æ¨ªåæ ‡ä¸º `nâ»Â¹/Â²` æ—¶ï¼Œæ‰€æœ‰æ›²çº¿ï¼ˆç²¾ç¡®ä¼˜åŒ–ã€GAã€SGAï¼‰å‡å‘ˆç°**çº¿æ€§ä¸‹é™è¶‹åŠ¿**ã€‚
    - è¿™è¡¨æ˜æ¬¡ä¼˜æ€§å·®è·çš„è¡°å‡é€Ÿç‡ä¸º `O(nâ»Â¹)`ï¼Œä¸ç†è®ºæ¨å¯¼ï¼ˆTheorems 3, 5, 7ï¼‰å®Œå…¨ä¸€è‡´ã€‚
    - è¯æ˜äº†åœ¨ç‰¹å¾è¦†ç›–å‡è®¾ä¸‹ï¼Œæ³›åŒ–è¯¯å·®æ˜¯**ç»´åº¦æ— å…³ï¼ˆdimension-freeï¼‰**çš„ã€‚

2.  **æ¬¡ä¼˜æ€§å·®è·ä¸ä¼˜åŒ–æ­¥æ•° `T` çš„å…³ç³» (Figure 1c, 1d)**ï¼š
    - å½“æ¨ªåæ ‡ä¸º `log(T)` æ—¶ï¼Œæ¬¡ä¼˜æ€§å·®è·éš `T` å¢åŠ è€Œ**å•è°ƒé€’å‡**ã€‚
    - è¿™éªŒè¯äº†ç†è®ºåˆ†æçš„ä¸€ä¸ªæœ‰è¶£å‘ç°ï¼šä¸ä¼ ç»Ÿè§‚ç‚¹ï¼ˆæ›´å¤šè¿­ä»£å¯¼è‡´æ›´å·®æ³›åŒ–ï¼‰ç›¸åï¼Œåœ¨ RLHF åœºæ™¯ä¸‹ï¼Œæ›´å¤šçš„ä¼˜åŒ–æ­¥æ•°ï¼ˆæ›´å°çš„æ¢¯åº¦èŒƒæ•°ï¼‰åè€Œèƒ½å¸¦æ¥**æ›´å¥½çš„ç®—æ³•ç¨³å®šæ€§å’Œæ³›åŒ–æ€§èƒ½**ï¼ˆTheorems 4, 6ï¼‰ã€‚

3.  **æ­£å®šæ€§éªŒè¯ (Figure 2)**ï¼š
    - æŠ¥å‘Šäº†ç»éªŒåæ–¹å·®çŸ©é˜µä¸ºæ­£å®šçš„æ¦‚ç‡éšæ ·æœ¬é‡ `n` çš„å˜åŒ–ã€‚
    - ç»“æœæ˜¾ç¤ºï¼Œå½“ `n` è¾ƒå°æ—¶ï¼Œæ­£å®šæ¦‚ç‡å¾ˆä½ï¼›éšç€ `n` å¢åŠ ï¼Œæ¦‚ç‡è¿…é€Ÿä¸Šå‡è‡³ 1ã€‚
    - è¿™éªŒè¯äº†åœ¨æ•°æ®ä¸è¶³æ—¶ï¼Œâ€œæ­£å®šæ€§â€å‡è®¾ä¸æˆç«‹ï¼Œä»è€Œå‡¸æ˜¾äº†æœ¬æ–‡æå‡ºçš„â€œç‰¹å¾è¦†ç›–â€å‡è®¾çš„å¿…è¦æ€§å’Œä¼˜è¶Šæ€§ã€‚

### **æ¶ˆèå®éªŒç»“æœ**

æœ¬æ–‡æ²¡æœ‰è¿›è¡Œå…¸å‹çš„æ¶ˆèå®éªŒï¼ˆå¦‚ç§»é™¤æŸä¸ªæ¨¡å—ï¼‰ã€‚å…¶æ ¸å¿ƒçš„â€œæ¶ˆèâ€ä½“ç°åœ¨**ä¸åŒå‡è®¾æ¡ä»¶ä¸‹çš„ç†è®ºåˆ†æ**ï¼š
- **Section 5.1 (å¼ºå‡è®¾)**ï¼šåœ¨ç‰¹å¾å……åˆ†è¦†ç›–ï¼ˆåæ–¹å·®æ­£å®šï¼‰ä¸‹ï¼Œè¯æ˜äº†ç»éªŒæœ€ä¼˜ç‚¹èƒ½ç²¾ç¡®æ¢å¤çœŸå€¼å‚æ•°ã€‚
- **Section 5.2 (å¼±å‡è®¾)**ï¼šåœ¨ç‰¹å¾è¦†ç›–ä¸è¶³çš„æ›´ç°å®æƒ…å†µä¸‹ï¼Œè¯æ˜äº†æ¬¡ä¼˜æ€§å·®è·ä»æœ‰ `O(nâ»Â¹)` çš„è‰¯å¥½ç•Œã€‚
è¿™ç§ä»ç†æƒ³åˆ°ç°å®çš„è¿‡æ¸¡æœ¬èº«å°±æ˜¯ä¸€ç§ç†è®ºä¸Šçš„â€œæ¶ˆèâ€ï¼Œè¯æ˜äº†æ–°æ¡†æ¶çš„é²æ£’æ€§å’Œæ™®é€‚æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **è®ºæ–‡çš„ä¸»è¦å‘ç°**

1.  **ç«¯åˆ°ç«¯æ³›åŒ–ç†è®º**ï¼šé¦–æ¬¡ä¸º RLHF å»ºç«‹äº†ä¸€ä¸ªå®Œæ•´çš„ç«¯åˆ°ç«¯æ³›åŒ–ç†è®ºæ¡†æ¶ï¼Œå¡«è¡¥äº†å®è·µä¸ç†è®ºä¹‹é—´çš„é¸¿æ²Ÿã€‚
2.  **ç»´åº¦æ— å…³çš„æ³›åŒ–**ï¼šåœ¨æå‡ºçš„**ç‰¹å¾è¦†ç›–å‡è®¾**ä¸‹ï¼Œå³ä½¿åœ¨é«˜ç»´ç©ºé—´ä¸­ï¼ŒRLHF å­¦ä¹ åˆ°çš„ç­–ç•¥ä¹Ÿå…·æœ‰ `O(nâ»Â¹)` çš„æ¬¡ä¼˜æ€§å·®è·ï¼Œä¸”è¯¥ç•Œä¸æ¨¡å‹ç»´åº¦ `d` æ— å…³ã€‚è¿™æ„å‘³ç€æœ‰æ•ˆçš„ç‰¹å¾æ¨¡å¼ç”±è®­ç»ƒæ•°æ®å¼ æˆçš„å­ç©ºé—´å†³å®šã€‚
3.  **ä¼˜åŒ–å³æ­£åˆ™åŒ–**ï¼šä¸€ä¸ªåç›´è§‰ä½†é‡è¦çš„å‘ç°æ˜¯ï¼Œå¯¹äº RLHFï¼Œ**æ›´å¤šçš„æ¢¯åº¦ä¸Šå‡æ­¥æ•°ï¼ˆGA/SGAï¼‰èƒ½æé«˜ç®—æ³•ç¨³å®šæ€§ï¼Œä»è€Œæ”¹å–„æ³›åŒ–æ€§èƒ½**ã€‚è¿™æ˜¯å› ä¸ºä¼˜åŒ–è¿‡ç¨‹å‡å°äº†æ¢¯åº¦èŒƒæ•°ï¼Œè€Œæ¢¯åº¦èŒƒæ•°ç›´æ¥æ§åˆ¶ç€ç¨³å®šæ€§ç³»æ•°ã€‚
4.  **ç†è®ºæ”¯æŒå®è·µ**ï¼šä¸ºâ€œä¸ºä½• RLHF èƒ½ä»…å‡­æœ‰é™çš„äººç±»åé¦ˆå°±è®© LLMs æ³›åŒ–å‡ºå¼ºå¤§èƒ½åŠ›â€æä¾›äº†æ–°çš„ç†è®ºè¯æ®ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

1.  **çº¿æ€§å¥–åŠ±å‡è®¾**ï¼šç†è®ºå»ºç«‹åœ¨ **linear reward model** çš„åŸºç¡€ä¸Šã€‚è™½ç„¶è¿™æ˜¯ç†è®ºåˆ†æçš„å¸¸è§èµ·ç‚¹ï¼Œä½†çœŸå®çš„ LLM å¥–åŠ±å‡½æ•°å¯èƒ½æ˜¯é«˜åº¦éçº¿æ€§çš„ï¼Œè¯¥å‡è®¾å¯èƒ½æ— æ³•å®Œå…¨æ•æ‰å¤æ‚çš„äººç±»åå¥½ã€‚
2.  **ç†æƒ³åŒ–ç¯å¢ƒ**ï¼šå®éªŒä¸ºæ¨¡æ‹Ÿç¯å¢ƒï¼Œæœªåœ¨çœŸå®çš„ã€å¤§è§„æ¨¡çš„ LLM RLHF æµç¨‹ä¸­è¿›è¡ŒéªŒè¯ã€‚
3.  **å¿½ç•¥æ•°æ®åè§**ï¼šç†è®ºåˆ†æå‡è®¾æ•°æ®æ˜¯æ— åçš„ã€‚ç„¶è€Œï¼Œå¦‚æœè®­ç»ƒæ•°æ®åŒ…å«ç¤¾ä¼šåè§ï¼Œç®—æ³•çš„ç¨³å®šæ€§æ„å‘³ç€è¿™äº›åè§ä¹Ÿä¼šè¢«å¿ å®åœ°å­¦ä¹ å’Œæ”¾å¤§ã€‚
4.  **SGA åˆ†æçš„å¤æ‚æ€§**ï¼šå¯¹ SGA çš„åˆ†æä½¿ç”¨äº†â€œé«˜æ¦‚ç‡ç¨³å®šæ€§â€ï¼ˆhigh-probability stabilityï¼‰ï¼Œç»“æœæ˜¯ä¸€ä¸ªæ¦‚ç‡æ€§ä¿è¯ï¼Œæ¯”ç¡®å®šæ€§åˆ†ææ›´å¤æ‚ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

1.  **æ¨å¹¿åˆ°éçº¿æ€§æ¨¡å‹**ï¼šå°†æ­¤ç¨³å®šæ€§æ¡†æ¶æ‰©å±•åˆ°æ·±åº¦ç¥ç»ç½‘ç»œç­‰éçº¿æ€§å‡½æ•°é€¼è¿‘å™¨ã€‚
2.  **åœ¨çº¿æ•°æ®ä¸åŠ¨æ€ç¯å¢ƒ**ï¼šç ”ç©¶åœ¨åœ¨çº¿å­¦ä¹ ã€æ•°æ®åˆ†å¸ƒæ¼‚ç§»ç­‰æ›´åŠ¨æ€åœºæ™¯ä¸‹çš„æ³›åŒ–æ€§èƒ½ã€‚
3.  **ç»“åˆå…¶ä»–å¯¹é½æ–¹æ³•**ï¼šå°†æ­¤æ¡†æ¶åº”ç”¨äºåˆ†æ DPO (Direct Preference Optimization) ç­‰æ— éœ€æ˜¾å¼å¥–åŠ±æ¨¡å‹çš„å¯¹é½ç®—æ³•ã€‚
4.  **åå·®ä¸å…¬å¹³æ€§åˆ†æ**ï¼šåœ¨ç†è®ºæ¡†æ¶ä¸­å¼•å…¥å¯¹æ•°æ®åè§å’Œå…¬å¹³æ€§çš„è€ƒé‡ï¼Œç ”ç©¶å¦‚ä½•åœ¨ä¿è¯æ³›åŒ–çš„åŒæ—¶å‡è½»æœ‰å®³åè§çš„ä¼ æ’­ã€‚

</details>

---

### 8. [Auto-Regressive Masked Diffusion Models](https://arxiv.org/abs/2601.16971)

**Authors**: Mahdi Karami, Ali Ghodsi  
**Category**: cs.LG  
**Published**: 2026-01-26  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.16971v1  

#### Abstract
Masked diffusion models (MDMs) have emerged as a promising approach for language modeling, yet they face a performance gap compared to autoregressive models (ARMs) and require more training iterations. In this work, we present the Auto-Regressive Masked Diffusion (ARMD) model, an architecture design...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# ã€ŠAuto-Regressive Masked Diffusion Modelsã€‹è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜

**Masked Diffusion Models (MDMs)** åœ¨æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­å±•ç°å‡ºæ½œåŠ›ï¼Œä½†ç›¸æ¯” **Autoregressive Models (ARMs)** ä»å­˜åœ¨æ˜¾è‘—å·®è·ï¼Œä¸»è¦ä½“ç°åœ¨ä¸¤ä¸ªæ–¹é¢ï¼š

- **è®­ç»ƒæ•ˆç‡ä½**ï¼šMDMs éœ€è¦å¤šä¸ªå»å™ªæ­¥éª¤ï¼ˆdenoising stepsï¼‰ï¼Œæ¯ä¸ªæ­¥éª¤é€šå¸¸éœ€è¦ç‹¬ç«‹çš„ç½‘ç»œå‰å‘ä¼ æ’­ï¼Œå¯¼è‡´è®­ç»ƒè¿­ä»£æ…¢ã€‚
- **æ¨ç†é€Ÿåº¦ä¸è´¨é‡æƒè¡¡**ï¼šè™½ç„¶æ‰©æ•£æ¨¡å‹æ”¯æŒå¹¶è¡Œé‡‡æ ·ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨å¹¶è¡Œç”Ÿæˆæ—¶å¾€å¾€ç‰ºç‰²ç”Ÿæˆè´¨é‡ï¼ˆå¦‚å›°æƒ‘åº¦å‡é«˜ï¼‰ã€‚

æ­¤å¤–ï¼Œä¼ ç»Ÿ MDMs å¤šä¾èµ–åŒå‘ä¸Šä¸‹æ–‡ï¼ˆç±»ä¼¼ BERTï¼‰ï¼Œç¼ºä¹é«˜æ•ˆçš„è‡ªå›å½’å¼è§£ç èƒ½åŠ›ã€‚

---

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯

ä½œè€…æå‡º **Auto-Regressive Masked Diffusion (ARMD)** æ¨¡å‹ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°† MDMs é‡æ–°å»ºæ¨¡ä¸ºä¸€ç§ **å—çº§å› æœï¼ˆblock-wise causalï¼‰ç”Ÿæˆè¿‡ç¨‹**ï¼Œä»è€Œç»Ÿä¸€æ‰©æ•£æ¨¡å‹ä¸è‡ªå›å½’æ¨¡å‹çš„ä¼˜ç‚¹ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š

1. **ä¸¥æ ¼å› æœæ¶æ„ï¼ˆStrictly Causal Architectureï¼‰**
   - å°† MDM ä¸­çš„éšæœºæ©ç é¡ºåºè½¬åŒ–ä¸ºä¸€ä¸ªæ’åˆ—åçš„åºåˆ—ï¼Œå¹¶æŒ‰â€œå»æ©ç æ—¶é—´â€åˆ’åˆ†ä¸ºå¤šä¸ªå—ã€‚
   - è®¾è®¡äº†ä¸€ç§ **ä¸¥æ ¼å› æœæ³¨æ„åŠ›æœºåˆ¶ï¼ˆStrictly Causal Attentionï¼‰**ï¼Œç¡®ä¿å½“å‰å—çš„è¾“å‡ºä»…ä¾èµ–äºå…ˆå‰å—çš„ä¿¡æ¯ï¼Œè€Œéå½“å‰å—æœ¬èº«ã€‚
   - å¼•å…¥ **ä¸¤æµæ³¨æ„åŠ›æœºåˆ¶ï¼ˆTwo-Stream Attentionï¼‰**ï¼šåŒæ—¶ç»´æŠ¤ä¸€ä¸ªå› æœæµï¼ˆCausal Streamï¼‰å’Œä¸€ä¸ªä¸¥æ ¼å› æœæµï¼ˆStrictly Causal Streamï¼‰ï¼Œå…±äº«å‚æ•°ä½†ä¸åŒæŸ¥è¯¢è¾“å…¥å’Œæ©ç ç­–ç•¥ï¼Œæå‡è¡¨è¾¾åŠ›è€Œä¸æ˜¾è‘—å¢åŠ å‚æ•°é‡ã€‚

2. **å¹¶è¡ŒåŒ–è®­ç»ƒç›®æ ‡**
   - åˆ©ç”¨ä¸Šè¿°å› æœç»“æ„ï¼Œå°†åŸæœ¬éœ€å¤šæ¬¡å‰å‘ä¼ æ’­çš„ MDM æŸå¤±å‡½æ•°ï¼Œé‡æ„ä¸ºå¯åœ¨ **å•æ¬¡å‰å‘ä¼ æ’­ä¸­å¹¶è¡Œè®¡ç®—æ‰€æœ‰æ¡ä»¶æ¦‚ç‡** çš„å½¢å¼ï¼Œæå¤§æå‡äº†è®­ç»ƒæ•ˆç‡ã€‚

3. **çµæ´»çš„æ··åˆè®­ç»ƒç­–ç•¥**
   - æ”¯æŒ **æ¸è¿›å¼æ’åˆ—è®­ç»ƒï¼ˆProgressive Permutation Scheduleï¼‰**ï¼šåˆæœŸä½¿ç”¨å·¦åˆ°å³é¡ºåºè®­ç»ƒï¼Œé€æ­¥å¼•å…¥éšæœºæ’åˆ—ï¼Œä½¿æ¨¡å‹æ—¢èƒ½å­¦ä¹ è‡ªç„¶è¯­è¨€çš„é¡ºåºå…ˆéªŒï¼Œåˆèƒ½é€‚åº”ä»»æ„ç”Ÿæˆé¡ºåºã€‚

4. **æ–°å‹æ¨ç†ç­–ç•¥ï¼šè·¨æ­¥å¹¶è¡Œç”Ÿæˆï¼ˆStrided Parallel Generation, SPBï¼‰**
   - å°†ç›®æ ‡åºåˆ—åˆ’åˆ†ä¸º S ä¸ªå¹¶è¡Œæµï¼Œå…ˆä¸²è¡Œç”Ÿæˆå„æµé¦–tokenï¼ˆå»ºç«‹å…¨å±€ä¸Šä¸‹æ–‡ï¼‰ï¼Œç„¶åå¹¶è¡Œç”Ÿæˆåç»­ä½ç½®ã€‚
   - é€šè¿‡äº¤é”™æ’åˆ—ï¼ˆinterleaved permutationï¼‰æœ€å¤§åŒ–å¹¶è¡Œtokenä¹‹é—´çš„è·ç¦»ï¼Œæ»¡è¶³è¿‘ä¼¼ç‹¬ç«‹å‡è®¾ï¼Œä¿è¯ç”Ÿæˆè´¨é‡ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ARMD ä¼˜åŠ¿ |
|------|---------|
| **è®­ç»ƒæ•ˆç‡** | å•æ¬¡å‰å‘ä¼ æ’­å®Œæˆå…¨éƒ¨æŸå¤±è®¡ç®—ï¼Œè®­ç»ƒè¿­ä»£æ›´å¿«ï¼›å®éªŒè¯æ˜åœ¨æ›´å°‘è®­ç»ƒæ­¥æ•°ä¸‹è¾¾åˆ°SOTAæ€§èƒ½ã€‚ |
| **æ¨ç†çµæ´»æ€§** | æ”¯æŒé«˜æ•ˆè‡ªå›å½’è§£ç ï¼ˆå¾—ç›Šäº KV Cacheï¼‰å’Œé«˜è´¨é‡å¹¶è¡Œç”Ÿæˆã€‚ |
| **æ¶æ„é€šç”¨æ€§** | å¯è§†ä¸º ARMs çš„æ¨å¹¿ï¼Œå…¼å®¹é¢„è®­ç»ƒ LLM å¾®è°ƒä¸ºæ‰©æ•£æ¨¡å‹ã€‚ |
| **ç”Ÿæˆè´¨é‡** | å¹¶è¡Œç”Ÿæˆæ—¶å›°æƒ‘åº¦æ¥è¿‘ä¸²è¡Œç”Ÿæˆï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–æ‰©æ•£åŸºçº¿ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†

- **OpenWebText**ï¼šç”¨äºè®­ç»ƒ small å’Œ medium è§„æ¨¡çš„ ARMD æ¨¡å‹ï¼ˆåˆ†åˆ«å¯¹åº” GPT-2 small å’Œ medium å‚æ•°é‡ï¼‰ã€‚
- **One Billion Words (LM1B)**ï¼šé¢å¤–éªŒè¯åœ¨æ ‡å‡†è¯­è¨€å»ºæ¨¡ä»»åŠ¡ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚

### å®éªŒè®¾ç½®

| è®¾ç½®é¡¹ | æè¿° |
|-------|------|
| **æ¨¡å‹è§„æ¨¡** | Small: 12å±‚, d=768ï¼›Medium: 24å±‚, d=1024 |
| **è®­ç»ƒé…ç½®** | Batch size: 512 Ã— 1024 tokensï¼›AdamWä¼˜åŒ–å™¨ï¼›å­¦ä¹ ç‡ 3e-4ï¼›warmup 2000æ­¥ |
| **è®­ç»ƒæ­¥æ•°** | æœ€å¤š 400K æ­¥ï¼ˆsmallï¼‰ã€300K æ­¥ï¼ˆmediumï¼‰ |
| **è¯„ä¼°æŒ‡æ ‡** | **é›¶æ ·æœ¬å›°æƒ‘åº¦ï¼ˆzero-shot perplexityï¼‰**ï¼Œåœ¨ä»¥ä¸‹æµ‹è¯•é›†ä¸ŠæŠ¥å‘Šï¼š<br>â€¢ LAMBADA<br>â€¢ WikiText2 / WikiText103<br>â€¢ Penn Tree Bank (PTB)<br>â€¢ One Billion Words (1BW) |
| **ç”Ÿæˆè®¾ç½®** | ä½¿ç”¨ float64 ç²¾åº¦è¿›è¡Œ Gumbel samplingï¼Œé¿å…æ•°å€¼è¯¯å·®å½±å“å¤šæ ·æ€§è¯„ä¼° |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”

| ç±»åˆ« | å¯¹æ¯”æ¨¡å‹ |
|------|--------|
| **è‡ªå›å½’æ¨¡å‹** | GPT-2 |
| **ç¦»æ•£æ‰©æ•£æ¨¡å‹** | D3PM, PLAID, SEDD, RADD |
| **å…¶ä»– MDM å˜ä½“** | BD3-LMs, MDLM |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & Table 3ï¼‰

#### åœ¨ OpenWebText ä¸Šè®­ç»ƒçš„å°/ä¸­ç­‰æ¨¡å‹ï¼ˆTable 1ï¼‰

| æ–¹æ³• | LAMBADA â†“ | WikiText2 â†“ | PTB â†“ | WikiText103 â†“ | 1BW â†“ |
|------|-----------|-------------|--------|----------------|--------|
| **ARMD (small, 180K steps)** | **44.66** | **36.25** | 130.31 | **35.66** | **53.18** |
| GPT-2 (small) | 45.04 | 42.43 | 138.43 | 41.60 | 75.20 |
| RADD (400K) | 51.70 | 39.98 | 107.85 | 37.98 | 72.99 |

> âœ… **ç»“è®º**ï¼šARMD åœ¨æ›´å°‘è®­ç»ƒæ­¥æ•°ï¼ˆ180K vs 400Kï¼‰ä¸‹å…¨é¢è¶…è¶Š GPT-2 å’Œä¸»æµ MDM åŸºçº¿ã€‚

#### åœ¨ LM1B æ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼ˆTable 3ï¼‰

| æ–¹æ³• | ppl â†“ |
|------|-----|
| Transformer-XBase | 23.5 |
| Transformer | 22.83 |
| **ARMD (300K steps)** | **23.64** |
| **ARMD (1M steps)** | **22.36** âœ… |
| BD3-LMs (L'=4, 1M) | 28.23 |
| MDLM (1M) | 31.78 |

> âœ… **ç»“è®º**ï¼šARMD åœ¨ä»… 300K æ­¥æ—¶å·²ä¼˜äºå¤šæ•°æ‰©æ•£æ¨¡å‹ï¼Œåœ¨ 1M æ­¥æ—¶è¾¾åˆ° **22.36**ï¼Œè¶…è¿‡æ‰€æœ‰å¯¹æ¯”çš„æ‰©æ•£æ¨¡å‹ï¼Œé€¼è¿‘çº¯è‡ªå›å½’ Transformerã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

- **è®­ç»ƒæ•ˆç‡**ï¼šARMD åœ¨ **3Ã— æ›´å°‘è®­ç»ƒæ­¥æ•°** ä¸‹å³è¶…è¶Š RADDã€SEDD ç­‰å…ˆè¿› MDMã€‚
- **å¹¶è¡Œç”Ÿæˆè´¨é‡**ï¼ˆè§ Table 2ï¼‰ï¼š
  - å½“å¹¶è¡Œåº¦ S=4ï¼ˆT=256ï¼‰æ—¶ï¼ŒARMD å›°æƒ‘åº¦ä¸º 39.4ï¼ˆmedium, 80K fine-tuneï¼‰ï¼Œè€Œ SEDD è¶…è¿‡ 100ã€‚
  - ä»…éœ€ 10K é¢å¤–å¾®è°ƒæ­¥æ•°å³å¯å®ç°é«˜è´¨é‡å¹¶è¡Œç”Ÿæˆã€‚
- **é‡‡æ ·é€Ÿåº¦**ï¼ˆTable 2 æ³¨é‡Šï¼‰ï¼š
  - S=1ï¼ˆä¸²è¡Œï¼‰ï¼š3.51s / seq
  - S=2ï¼š1.78s / seq ï¼ˆâ‰ˆ2Ã—åŠ é€Ÿï¼‰
  - S=4ï¼š0.93s / seq ï¼ˆâ‰ˆ3.8Ã—åŠ é€Ÿï¼‰

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Study, Table 5ï¼‰

| é…ç½® | å½±å“ |
|------|------|
| **L2s = L/2ï¼ˆé»˜è®¤ï¼‰** | æ€§èƒ½æœ€ä½³ï¼Œå¹³è¡¡è¡¨è¾¾åŠ›ä¸æ•ˆç‡ |
| L2s = L/4ï¼ˆå‡å°‘ä¸¤æµå±‚æ•°ï¼‰ | æ€§èƒ½ç•¥æœ‰ä¸‹é™ä½†ä»ä¼˜äºåŸºçº¿ï¼Œé€‚åˆèµ„æºå—é™åœºæ™¯ |
| L2s = Lï¼ˆå…¨å±‚ä¸¤æµï¼‰ | è®¡ç®—å¼€é”€å¤§ï¼Œæ€§èƒ½æœªè¿›ä¸€æ­¥æå‡ |
| **p=32 vs p=64ï¼ˆæœ€å¤§æ‰“ä¹±tokenæ•°ï¼‰** | p=64 åœ¨éƒ¨åˆ†æ•°æ®é›†ä¸Šç•¥ä¼˜ï¼Œè¯´æ˜æ›´å¤šæ’åˆ—å¢å¼ºé²æ£’æ€§ |

> ğŸ” **å‘ç°**ï¼šå¹¶éè¶Šå¤šâ€œä¸¤æµå±‚â€è¶Šå¥½ï¼Œ**å‰åŠéƒ¨åˆ†ä½¿ç”¨ä¸¤æµç»“æ„å·²è¶³å¤Ÿæ•è·å¿…è¦ä¸Šä¸‹æ–‡**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. âœ… **MDMs å¯è¢«é‡æ„ä¸ºå› æœç”Ÿæˆæ¨¡å‹**ï¼šé€šè¿‡å°†æ©ç é¡ºåºæ˜ å°„ä¸ºå—çº§å› æœç»“æ„ï¼Œå¯å®ç° MDM çš„å¹¶è¡Œè®­ç»ƒã€‚
2. âœ… **è®­ç»ƒæ•ˆç‡å¤§å¹…æå‡**ï¼šARMD åœ¨æ˜¾è‘—æ›´å°‘è®­ç»ƒæ­¥æ•°ä¸‹è¶…è¶Šç°æœ‰ MDM å’Œ ARMsã€‚
3. âœ… **é«˜è´¨é‡å¹¶è¡Œç”Ÿæˆæˆä¸ºå¯èƒ½**ï¼šæå‡ºçš„ **Strided Parallel Generation** ç­–ç•¥æœ‰æ•ˆç¼©å°äº†å¹¶è¡Œä¸ä¸²è¡Œç”Ÿæˆçš„è´¨é‡å·®è·ã€‚
4. âœ… **æ¶æ„å…·æœ‰é«˜åº¦å…¼å®¹æ€§**ï¼šæ”¯æŒ KV Cacheã€å¯é€‚é… RoPEã€æ˜“äºä»é¢„è®­ç»ƒ LLM å¾®è°ƒè€Œæ¥ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§

- **è®¡ç®—å¼€é”€ç•¥é«˜**ï¼šç”±äºä¸¤æµè®¾è®¡ï¼Œæ¯å±‚éœ€é¢å¤–è®¡ç®—ï¼Œç†è®º FLOPs å¢åŠ çº¦ 40â€“50%ï¼Œå®æµ‹è®­ç»ƒååé™ä½çº¦ 22%ï¼ˆL2s=6ï¼‰ã€‚
- **å¯¹æ’åˆ—è°ƒåº¦æ•æ„Ÿ**ï¼šæ¸è¿›å¼æ’åˆ—è®­ç»ƒéœ€ç²¾å¿ƒè®¾è®¡è°ƒåº¦æ›²çº¿ï¼Œå¦åˆ™å¯èƒ½æŸå®³è¯­è¨€ç»“æ„å­¦ä¹ ã€‚
- **å°šæœªæ‰©å±•è‡³è¶…å¤§è§„æ¨¡æ¨¡å‹**ï¼šå½“å‰å®éªŒé›†ä¸­åœ¨ GPT-2 çº§åˆ«ï¼Œç™¾äº¿ä»¥ä¸Šè§„æ¨¡çš„è¡¨ç°å¾…éªŒè¯ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. **æ¢ç´¢æ›´é«˜æ•ˆçš„ä¸¥æ ¼å› æœå®ç°æ–¹å¼**ï¼Œä¾‹å¦‚é€’å½’å½¢å¼æˆ–ç¨€ç–æ³¨æ„åŠ›ã€‚
2. **å°† ARMD æ¶æ„åº”ç”¨äºé¢„è®­ç»ƒå¤§æ¨¡å‹ï¼ˆå¦‚ LLaMAï¼‰çš„å¾®è°ƒ**ï¼Œæ„å»ºâ€œæ‰©æ•£ç‰ˆ LLMâ€ã€‚
3. **ç»“åˆ Consistency Models æˆ– Flow Matching** è¿›ä¸€æ­¥å‡å°‘æ¨ç†æ­¥æ•°ã€‚
4. **æ‹“å±•åˆ°å¤šæ¨¡æ€ä»»åŠ¡**ï¼Œå¦‚å›¾åƒ-æ–‡æœ¬è”åˆç”Ÿæˆï¼Œåˆ©ç”¨å…¶å¹¶è¡Œç”Ÿæˆä¼˜åŠ¿ã€‚

---

> ğŸ“Œ **æ€»ä½“è¯„ä»·**ï¼š  
> ARMD æˆåŠŸå¼¥åˆäº† **è‡ªå›å½’æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡** ä¸ **æ‰©æ•£æ¨¡å‹çš„å¹¶è¡Œçµæ´»æ€§** ä¹‹é—´çš„é¸¿æ²Ÿï¼Œæå‡ºäº†ä¸€ç§å…¼å…·é«˜æ€§èƒ½ã€é«˜æ•ˆç‡ä¸å¼ºæ‰©å±•æ€§çš„æ–°ä¸€ä»£æ–‡æœ¬ç”Ÿæˆæ¡†æ¶ï¼Œä¸ºæœªæ¥å¤§è§„æ¨¡ç”Ÿæˆæ¨¡å‹çš„è®¾è®¡æä¾›äº†é‡è¦èŒƒå¼ã€‚

</details>

---

### 9. [DSGym: A Holistic Framework for Evaluating and Training Data Science Agents](https://arxiv.org/abs/2601.16344)

**Authors**: Fan Nie, Junlin Wang, Harper Hua, Federico Bianchi, Yongchan Kwon, Zhenting Qi, Owen Queen, Shang Zhu, James Zou  
**Category**: cs.AI  
**Published**: 2026-01-26  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.16344v1  

#### Abstract
Data science agents promise to accelerate discovery and insight-generation by turning data into executable analyses and findings. Yet existing data science benchmarks fall short due to fragmented evaluation interfaces that make cross-benchmark comparison difficult, narrow task coverage and a lack of...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDSGym: A Holistic Framework for Evaluating and Training Data Science Agents

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜

å½“å‰çš„ **Data Science Agent**ï¼ˆæ•°æ®ç§‘å­¦æ™ºèƒ½ä½“ï¼‰è¯„ä¼°å­˜åœ¨ä»¥ä¸‹ä¸‰å¤§ç³»ç»Ÿæ€§ç¼ºé™·ï¼š

1. **ç¼ºä¹ä¸¥æ ¼çš„æ•°æ®ä¾èµ–æ€§ï¼ˆLack of rigorous data groundingï¼‰**  
   å¤šæ•°ç°æœ‰çš„ file-grounded benchmarksï¼ˆåŸºäºæ–‡ä»¶çš„åŸºå‡†æµ‹è¯•ï¼‰å®é™…ä¸Šå…è®¸æ¨¡å‹é€šè¿‡ prompt-only çš„æ–¹å¼ï¼ˆå¦‚è®°å¿†ã€æ¨¡å¼åŒ¹é…ã€å…ˆéªŒçŸ¥è¯†ï¼‰è§£å†³ä»»åŠ¡ï¼Œè€Œæ— éœ€çœŸæ­£è¯»å–å’Œåˆ†ææ•°æ®æ–‡ä»¶ã€‚

2. **ä»»åŠ¡ä¸ä¸€è‡´æ€§å’Œæ— æ•ˆæ€§ï¼ˆTask inconsistency and invalidityï¼‰**  
   ç°æœ‰åŸºå‡†ä¸­å­˜åœ¨æ ‡æ³¨é”™è¯¯ã€ç­”æ¡ˆæ ¼å¼æ¨¡ç³Šã€å¤šé€‰é¢˜é€‰é¡¹é‡å¤ç­‰é—®é¢˜ï¼Œå¯¼è‡´è¯„ä¼°ä¸å¯é ã€‚

3. **é¢†åŸŸè¦†ç›–ç‹­çª„ï¼ˆLimited domain coverageï¼‰**  
   ç°æœ‰ä»»åŠ¡é›†ä¸­äºé€šç”¨ç»Ÿè®¡åˆ†æï¼ˆå¦‚å‡å€¼ã€ç›¸å…³æ€§ï¼‰ï¼Œä¸¥é‡ç¼ºä¹å¯¹çœŸå®ç§‘ç ”æµç¨‹ï¼ˆå¦‚ç”Ÿç‰©ä¿¡æ¯å­¦ã€å•ç»†èƒåˆ†æã€åˆ†å­é¢„æµ‹ï¼‰çš„å»ºæ¨¡èƒ½åŠ›æµ‹è¯•ã€‚

---

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯

ä½œè€…æå‡ºäº† **DSGYM**ï¼Œä¸€ä¸ªæ ‡å‡†åŒ–ã€å¯æ‰©å±•çš„æ¡†æ¶ï¼Œç”¨äº**ç«¯åˆ°ç«¯åœ°è¯„ä¼°å’Œè®­ç»ƒ Data Science Agents**ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š

- **ç»Ÿä¸€æ‰§è¡Œç¯å¢ƒï¼ˆUnified Execution Environmentï¼‰**  
  é‡‡ç”¨å®¹å™¨åŒ–æ¶æ„ï¼ˆDocker + Jupyter Kernelï¼‰ï¼Œç¡®ä¿æ¯ä¸ª agent åœ¨éš”ç¦»ã€å¯å¤ç°çš„ç¯å¢ƒä¸­è¿è¡Œï¼Œæ”¯æŒè·¨ä»»åŠ¡ã€è·¨é¢†åŸŸçš„å…¬å¹³æ¯”è¾ƒã€‚

- **æ¨¡å—åŒ–è®¾è®¡ï¼ˆModular Architectureï¼‰**  
  æ”¯æŒçµæ´»æ·»åŠ æ–°ä»»åŠ¡ã€æ–° agent æ¶æ„ã€æ–°å·¥å…·ï¼ˆå¦‚ web searchï¼‰ã€æ–°è¯„ä¼°è„šæœ¬ï¼Œä½¿ DSGYM æˆä¸ºä¸€ä¸ªâ€œæ´»â€çš„æµ‹è¯•å¹³å°ï¼ˆlive testbedï¼‰ã€‚

- **æå‡º DSGYM-TASKSï¼šé«˜è´¨é‡ã€æŠ—æ·å¾„çš„ä»»åŠ¡å¥—ä»¶**  
  åŒ…å«ä¸‰ä¸ªå±‚æ¬¡ï¼š
  1. **Refined Existing Benchmarks**ï¼šå¯¹ QRDataã€DAEval ç­‰è¿›è¡Œè´¨é‡éªŒè¯å’Œâ€œæ·å¾„è¿‡æ»¤â€ï¼ˆshortcut filteringï¼‰ã€‚
  2. **DSBio**ï¼šç”±ä¸“å®¶ä»ç”Ÿç‰©åŒ»å­¦æ–‡çŒ®ä¸­æå–çš„ 90 ä¸ªé«˜éš¾åº¦ç”Ÿç‰©ä¿¡æ¯å­¦ä»»åŠ¡ï¼Œè¦æ±‚ç†è§£ `.h5ad` æ–‡ä»¶ã€ä½¿ç”¨ `scanpy` ç­‰ä¸“ä¸šåº“ã€‚
  3. **DSPREDICT**ï¼šä» Kaggle ç«èµ›ä¸­è‡ªåŠ¨æŠ“å–å¹¶æ ‡å‡†åŒ–çš„ 92 ä¸ªç«¯åˆ°ç«¯å»ºæ¨¡ä»»åŠ¡ï¼Œæ¶µç›–è®¡ç®—æœºè§†è§‰ã€åˆ†å­é¢„æµ‹ã€å•ç»†èƒæ‰°åŠ¨ç­‰ã€‚

- **æ”¯æŒ agent è®­ç»ƒï¼ˆTraining Supportï¼‰**  
  åˆ©ç”¨ DSGYM çš„æ‰§è¡Œç¯å¢ƒç”Ÿæˆ **execution-verified synthetic trajectories**ï¼Œç”¨äºç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼Œå®ç°é—­ç¯è®­ç»ƒã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ MLEBenchã€DAEvalï¼‰ | DSGYM |
|------|-------------------------------|--------|
| **æ•°æ®ä¾èµ–æ€§** | å¼±ï¼Œæ˜“è¢« prompt æ·å¾„ç»•è¿‡ | å¼ºï¼Œé€šè¿‡â€œæ·å¾„è¿‡æ»¤â€ç¡®ä¿å¿…é¡»è¯»æ•°æ® |
| **é¢†åŸŸè¦†ç›–** | é€šç”¨æ•°æ®åˆ†æä¸ºä¸» | æ‰©å±•è‡³ç”Ÿç‰©ä¿¡æ¯å­¦ã€Kaggle çœŸå®æŒ‘æˆ˜ |
| **æ‰§è¡Œç¯å¢ƒ** | ä¸ç»Ÿä¸€ï¼Œéš¾ä»¥å¤ç° | å®¹å™¨åŒ–ã€çŠ¶æ€ä¿æŒã€èµ„æºå¯æ§ |
| **å¯æ‰©å±•æ€§** | é™æ€æ•°æ®é›† | æ¨¡å—åŒ–ï¼Œæ”¯æŒæŒç»­æ–°å¢ä»»åŠ¡ |
| **è®­ç»ƒæ”¯æŒ** | ä»…ç”¨äºè¯„ä¼° | å¯ç”Ÿæˆåˆæˆè®­ç»ƒæ•°æ® |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†

- **Refined General Analysis Tasks**ï¼š
  - `QRData-Verified`ï¼ˆç»Ÿè®¡ä¸å› æœæ¨ç†ï¼‰
  - `DAEval-Verified`ï¼ˆçŸ­åˆ†ææŸ¥è¯¢ï¼‰
  - `DABStep`ï¼ˆé‡‘èå¤šæ­¥åˆ†æï¼‰
  - `MLEBench-Lite`ï¼ˆç»å…¸ ML æŒ‘æˆ˜ï¼‰

- **Domain-Specific Scientific Tasks**ï¼š
  - `DSBio`ï¼š90 ä¸ªæ¥è‡ªé¡¶çº§æœŸåˆŠçš„ç”Ÿç‰©ä¿¡æ¯å­¦ä»»åŠ¡ï¼ˆå•ç»†èƒã€ç©ºé—´è½¬å½•ç»„ã€é—ä¼ å­¦ï¼‰
  - `DSPREDICT`ï¼šå…± 92 ä¸ª Kaggle ç«èµ›ä»»åŠ¡
    - `DSPREDICT-Easy`ï¼š38 ä¸ªï¼ˆå¦‚ Titanicã€Playground ç³»åˆ—ï¼‰
    - `DSPREDICT-Hard`ï¼š54 ä¸ªï¼ˆå¦‚ `web-traffic-forecasting`, `pku-autonomous-driving`ï¼‰

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### æ¨¡å‹åˆ—è¡¨ï¼ˆè¯„ä¼°å¯¹è±¡ï¼‰ï¼š

- **é—­æºæ¨¡å‹ï¼ˆProprietaryï¼‰**ï¼šGPT-4o, GPT-5, Claude Sonnet 4/4.5
- **å¼€æºå¤§æ¨¡å‹ï¼ˆOpen-sourcedï¼‰**ï¼šQwen3-Coder, DeepSeek-v3.1, Kimi-K2-Instruct
- **å°æ¨¡å‹ï¼ˆSmall Modelsï¼‰**ï¼šQwen2.5-7B, Qwen3-4B

æ‰€æœ‰æ¨¡å‹å‡ä½¿ç”¨ DSGYM æä¾›çš„é»˜è®¤ **CodeAct-like agent interface**ï¼Œç¦ç”¨å¤–éƒ¨å·¥å…·ï¼ˆå¦‚ web searchï¼‰ï¼Œæ¸©åº¦è®¾ä¸º `T=0`ã€‚

#### è¯„ä¼°æŒ‡æ ‡ï¼š

| ä»»åŠ¡ç±»å‹ | æŒ‡æ ‡ |
|---------|------|
| **Data Analysis** | Exact Match Accuracyï¼ˆæ•°å€¼å®¹å¿ï¼‰ |
| **Data Prediction**ï¼ˆå¦‚ Kaggleï¼‰ | - `Valid Submission Rate`ï¼ˆæäº¤æœ‰æ•ˆç‡ï¼‰<br>- `Above Median Rate`ï¼ˆè¶…è¶Šä¸­ä½æ•°ï¼‰<br>- `Any Medal Rate`ï¼ˆè·å¾—å¥–ç‰Œç‡ï¼‰<br>- `Percentile Rank`ï¼ˆç™¾åˆ†ä½æ’åï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### è¡¨1ï¼šé€šç”¨æ•°æ®åˆ†æä»»åŠ¡å‡†ç¡®ç‡ï¼ˆéƒ¨åˆ†ï¼‰

| Model | QRData-Verified (%) | DABStep-hard (%) | DAEval-Verified (%) |
|-------|---------------------|------------------|----------------------|
| GPT-4o | 60.24 | 7.41 | 92.26 |
| Claude Sonnet 4.5 | 61.35 | 37.04 | 91.71 |
| Kimi-K2-Instruct | 63.68 | 28.84 | 92.82 |
| Qwen3-Coder 480B | 54.72 | 14.29 | 90.61 |
| Qwen3-4B-Instruct | 45.27 | 2.9 | 64.47 |

> ğŸ’¡ **è§‚å¯Ÿ**ï¼šå³ä½¿åœ¨ç®€å•ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨ **DABStep-hard**ï¼ˆå¤šæ­¥ã€å¼ºæ•°æ®ä¾èµ–ï¼‰ä¸Šæ™®éä½äº 40%ï¼Œè¡¨æ˜å¤æ‚æ¨ç†ä»æ˜¯ç“¶é¢ˆã€‚

---

#### è¡¨2ï¼šDSBioï¼ˆç”Ÿç‰©ä¿¡æ¯å­¦ï¼‰ä»»åŠ¡å‡†ç¡®ç‡

| Model | Overall (%) |
|-------|-----------|
| Kimi-K2-Instruct | **43.33** |
| Claude Sonnet 4.5 | 42.22 |
| GPT-5.1 (high) | 38.89 |
| Qwen3-4B-Instruct | 6.67 |

> ğŸ’¡ **è§‚å¯Ÿ**ï¼šæ‰€æœ‰æ¨¡å‹åœ¨ DSBio ä¸Šè¡¨ç°æ˜¾è‘—ä¸‹é™ï¼Œ**domain grounding error** å å¤±è´¥æ¡ˆä¾‹çš„ 85â€“96%ã€‚

---

#### è¡¨3ï¼šDSPREDICT å»ºæ¨¡ä»»åŠ¡è¡¨ç°ï¼ˆHard åˆ†å‰²ï¼‰

| Model | Valid (%) | Medal (%) | Median (%) |
|-------|----------|----------|------------|
| GPT-5.1 (high) | 85.7 | 4.8 | 14.3 |
| Claude Sonnet 4.5 | 71.4 | 0 | 4.8 |
| Qwen3-Coder 480B | 66.7 | 2.4 | 5.9 |
| Qwen3-4B-Instruct | 40.5 | 0 | 0 |

> ğŸ’¡ **è§‚å¯Ÿ**ï¼š
> - å³ä½¿æ˜¯ GPT-5.1ï¼Œ**å¥–ç‰Œç‡ä¹Ÿæ¥è¿‘ 0%**ï¼Œè¯´æ˜ agent ç¼ºä¹ä¼˜åŒ–åŠ¨åŠ›ã€‚
> - å¤šæ•° agent èƒ½ç”Ÿæˆæœ‰æ•ˆæäº¤ï¼Œä½†æ€§èƒ½è¿œä½äºäººç±»ä¸­ä½æ°´å¹³ã€‚

---

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰æ·å¾„è¿‡æ»¤çš„å½±å“ï¼ˆShortcut Filteringï¼‰

- åœ¨ `QRData` ä¸Šç§»é™¤å¯è¢«â€œæ— æ•°æ®è®¿é—®â€è§£å†³çš„ä»»åŠ¡åï¼Œ**æ‰€æœ‰æ¨¡å‹å¹³å‡å‡†ç¡®ç‡ä¸‹é™ 20% ä»¥ä¸Š**ã€‚
- å°æ¨¡å‹å—å½±å“æ›´å¤§ï¼Œè¡¨æ˜å…¶æ›´ä¾èµ–è®°å¿†å’Œå…ˆéªŒã€‚

> âœ… **è¯æ˜**ï¼šç°æœ‰ benchmark å­˜åœ¨ä¸¥é‡â€œæ·å¾„æ±¡æŸ“â€ã€‚

#### ï¼ˆ2ï¼‰è®­ç»ƒå®éªŒï¼šDSGYM-SFT åˆæˆæ•°æ®çš„æœ‰æ•ˆæ€§

- ä½¿ç”¨ DSGYM ç”Ÿæˆ **2,000 æ¡ execution-verified synthetic trajectories** å¯¹ `Qwen3-4B` è¿›è¡Œ SFTã€‚
- ç»“æœæ˜¾ç¤ºï¼š
  - åœ¨ `DABStep-hard` ä¸Šä» 2.9% æå‡è‡³ **33.07%**
  - åœ¨æœªè§è¿‡çš„ `DSBio` ä¸Šä» 6.67% æå‡è‡³ **21.11%**
  - äº¤äº’è¡Œä¸ºæ›´ç»†ç²’åº¦ï¼ˆturn æ•°å¢åŠ ï¼Œtoken åˆ†å¸ƒæ›´æ¥è¿‘æ•™å¸ˆæ¨¡å‹ï¼‰

> âœ… **è¯æ˜**ï¼šDSGYM å¯ä½œä¸ºâ€œæ•°æ®å·¥å‚â€ï¼Œç”Ÿæˆé«˜è´¨é‡è®­ç»ƒæ•°æ®ï¼Œæå‡å°æ¨¡å‹æ€§èƒ½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. **ç°æœ‰ benchmark æ˜“å—â€œéæ•°æ®ä¾èµ–â€æ·å¾„æ”»å‡»**  
   å¤šè¾¾ 40â€“80% çš„ä»»åŠ¡å¯åœ¨ä¸è®¿é—®æ•°æ®çš„æƒ…å†µä¸‹è¢«æ­£ç¡®å›ç­”ï¼Œä¸¥é‡é«˜ä¼° agent èƒ½åŠ›ã€‚

2. **å‰æ²¿æ¨¡å‹åœ¨çœŸå®ç§‘ç ”ä»»åŠ¡ä¸­ä»è¡¨ç°ä¸ä½³**  
   åœ¨ DSBio ä¸Šï¼Œå³ä½¿æ˜¯ GPT-4o å’Œ Claude ä¹Ÿä»…æœ‰ ~33% å‡†ç¡®ç‡ï¼Œ**domain grounding error æ˜¯ä¸»å› **ï¼ˆå¦‚è¯¯ç”¨å­—æ®µã€è¯¯è§£å®éªŒè®¾è®¡ï¼‰ã€‚

3. **Agent å­˜åœ¨â€œç®€å•æ€§åè§â€ï¼ˆSimplicity Biasï¼‰**  
   å½“é‡åˆ°æŠ€æœ¯éšœç¢ï¼ˆå¦‚è¶…æ—¶ã€åº“ç¼ºå¤±ï¼‰æ—¶ï¼Œagent å€¾å‘äºæ”¾å¼ƒå¤æ‚ç­–ç•¥ï¼Œè½¬è€Œä½¿ç”¨ä¸­ä½æ•°ç­‰ç®€å•å¯å‘å¼æ–¹æ³•ï¼Œå¯¼è‡´æ€§èƒ½ä½ä¸‹ã€‚

4. **å°æ¨¡å‹å¯é€šè¿‡ execution-grounded SFT æ˜¾è‘—æå‡**  
   ä½¿ç”¨ DSGYM ç”Ÿæˆçš„åˆæˆæ•°æ®è®­ç»ƒçš„å°æ¨¡å‹ï¼ˆ4Bï¼‰å¯è¾¾åˆ°æ¥è¿‘ GPT-4o çš„æ°´å¹³ï¼ŒéªŒè¯äº†â€œæ‰§è¡ŒéªŒè¯â€è®­ç»ƒèŒƒå¼çš„æœ‰æ•ˆæ€§ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§

1. **è¯„ä¼°ä»¥ç¡®å®šæ€§è¾“å‡ºä¸ºä¸»**  
   å½“å‰ä¸æ”¯æŒå¼€æ”¾æ€§æ¢ç´¢ä»»åŠ¡ï¼ˆå¦‚å¯è§†åŒ–ã€å‡è®¾ç”Ÿæˆï¼‰ï¼Œé™åˆ¶äº†å¯¹åˆ›é€ æ€§ç§‘å­¦å‘ç°çš„è¯„ä¼°ã€‚

2. **é¢†åŸŸè¦†ç›–ä»æœ‰é™**  
   å½“å‰ DSBio ä»…èšç„¦ç”Ÿç‰©ä¿¡æ¯å­¦ï¼Œæœªæ¥éœ€æ‰©å±•è‡³åŒ–å­¦ã€ææ–™ç§‘å­¦ã€ç»æµå­¦ç­‰é¢†åŸŸã€‚

3. **è®­ç»ƒä¿¡å·ç¨€ç–**  
   RL è®­ç»ƒé¢ä¸´é•¿å‘¨æœŸå¥–åŠ±ç¨€ç–çš„é—®é¢˜ï¼Œå¦‚ä½•è®¾è®¡æœ‰æ•ˆçš„ credit assignment ä»æ˜¯æŒ‘æˆ˜ã€‚

4. **ç¯å¢ƒé™åˆ¶å½±å“ agent è¡Œä¸º**  
   å¦‚æ— æ³•å®‰è£…åŒ…ã€ç½‘ç»œå—é™ç­‰ï¼Œå¯èƒ½å¯¼è‡´ agent å› â€œç¯å¢ƒé˜»å¡â€è€Œéâ€œèƒ½åŠ›ä¸è¶³â€å¤±è´¥ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•è‡³æ›´å¤šç§‘å­¦é¢†åŸŸ**  
   å°† DSBio æ„å»ºæµç¨‹æ¨å¹¿è‡³ geoscienceã€computational chemistry ç­‰ã€‚

2. **æ”¯æŒ RL å’Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒ**  
   åˆ©ç”¨ DSGYM çš„é—­ç¯ç¯å¢ƒï¼Œç ”ç©¶åŸºäºå¥–åŠ±çš„ agent ä¼˜åŒ–ã€‚

3. **å¼•å…¥ LLM Judge è¿›è¡Œå¼€æ”¾ä»»åŠ¡è¯„ä¼°**  
   å¯¹éç¡®å®šæ€§è¾“å‡ºï¼ˆå¦‚æŠ¥å‘Šã€å›¾è¡¨è§£é‡Šï¼‰è¿›è¡Œè‡ªåŠ¨åŒ–è¯„åˆ†ã€‚

4. **æ„å»ºå¤š agent åä½œç”Ÿæ€**  
   æ”¯æŒå¤šä¸ª agent åˆ†å·¥åä½œå®Œæˆå¤æ‚ç§‘ç ”ä»»åŠ¡ï¼ˆå¦‚æ•°æ®æ¸…æ´— + å»ºæ¨¡ + æŠ¥å‘Šç”Ÿæˆï¼‰ã€‚

5. **æ¨åŠ¨ DSGYM æˆä¸ºç¤¾åŒºæ ‡å‡†æµ‹è¯•å¹³å°**  
   é¼“åŠ±ç ”ç©¶äººå‘˜æŒç»­è´¡çŒ®æ–°ä»»åŠ¡ã€æ–°å·¥å…·ï¼Œå½¢æˆåŠ¨æ€æ¼”è¿›çš„è¯„ä¼°ç”Ÿæ€ç³»ç»Ÿã€‚

---

> ğŸ“Œ **æ€»ç»“**ï¼šDSGYM ä¸åªæ˜¯ä¸€ä¸ª benchmarkï¼Œè€Œæ˜¯ä¸€ä¸ª**å¯æ‰§è¡Œã€å¯æ‰©å±•ã€å¯è®­ç»ƒ**çš„å®Œæ•´æ•°æ®ç§‘å­¦ agent ç”Ÿæ€ç³»ç»Ÿã€‚å®ƒæ­ç¤ºäº†å½“å‰ agent çš„çœŸå®çŸ­æ¿ï¼Œå¹¶æä¾›äº†ä¸€æ¡é€šå¾€æ›´å¼ºå¤§ã€æ›´å¯é ç§‘å­¦è‡ªåŠ¨åŒ–çš„æ–°è·¯å¾„ã€‚

</details>

---

### 10. [Doc2AHP: Inferring Structured Multi-Criteria Decision Models via Semantic Trees with LLMs](https://arxiv.org/abs/2601.16479)

**Authors**: Hongjia Wu, Shuai Zhou, Hongxin Zhang, Wei Chen  
**Category**: cs.AI  
**Published**: 2026-01-26  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.16479v1  

#### Abstract
While Large Language Models (LLMs) demonstrate remarkable proficiency in semantic understanding, they often struggle to ensure structural consistency and reasoning reliability in complex decision-making tasks that demand rigorous logic. Although classical decision theories, such as the Analytic Hier...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDoc2AHP: Inferring Structured Multi-Criteria Decision Models via Semantic Trees with LLMs

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿ **Analytic Hierarchy Process (AHP)** è™½ç„¶åœ¨å¤šå‡†åˆ™å†³ç­–ï¼ˆMCDMï¼‰ä¸­å…·æœ‰ä¸¥è°¨çš„é€»è¾‘æ¡†æ¶ï¼Œä½†å…¶æ„å»ºä¸¥é‡ä¾èµ–é¢†åŸŸä¸“å®¶æ‰‹åŠ¨æ•´ç†æ–‡æ¡£ã€å®šä¹‰å±‚çº§ç»“æ„å¹¶è¿›è¡Œæˆå¯¹æ¯”è¾ƒï¼Œè¿‡ç¨‹**è€—æ—¶ä¸”éš¾ä»¥è§„æ¨¡åŒ–**ã€‚è€Œç°æœ‰çš„åŸºäº **Large Language Models (LLMs)** çš„â€œè™šæ‹Ÿä¸“å®¶â€æ–¹æ³•è™½ç„¶èƒ½è‡ªåŠ¨ç”Ÿæˆå†³ç­–æ¨¡å‹ï¼Œå´å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- ç”Ÿæˆçš„å‡†åˆ™ï¼ˆcriteriaï¼‰**æ³›åŒ–æ€§å¼ºä½†ç¼ºä¹è¯æ®æ”¯æŒ**ï¼Œæ˜“äº§ç”Ÿè¯­ä¹‰æ¼‚ç§»ï¼›
- æ•°å€¼åˆ¤æ–­ä¸ç¨³å®šï¼Œå®¹æ˜“å‡ºç° **hallucination å’Œä¸ä¸€è‡´æ€§ï¼ˆå¦‚ CR > 0.1ï¼‰**ï¼›
- ç¼ºä¹å¯è¿½æº¯æ€§ï¼Œä¸åˆ©äºé«˜é£é™©åœºæ™¯ä¸‹çš„å¯ä¿¡å†³ç­–ã€‚

å› æ­¤ï¼Œå¦‚ä½•ç»“åˆ LLMs çš„æ³›åŒ–èƒ½åŠ›ä¸ AHP çš„ç»“æ„ä¸¥è°¨æ€§ï¼Œå®ç°ä»éç»“æ„åŒ–æ–‡æ¡£åˆ°é«˜è´¨é‡ã€å¯è§£é‡Š AHP æ¨¡å‹çš„è‡ªåŠ¨åŒ–æ„å»ºï¼Œæ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

ä½œè€…æå‡º **Doc2AHP** â€”â€”ä¸€ç§ç«¯åˆ°ç«¯çš„ã€å— AHP åŸç†æŒ‡å¯¼çš„ç»“æ„åŒ–æ¨ç†æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> åˆ©ç”¨æ–‡æ¡£é›†åˆä¸­çš„**è¯­ä¹‰å‡ ä½•ç»“æ„**ï¼ˆsemantic geometryï¼‰ä½œä¸ºå…ˆéªŒï¼Œå¼•å¯¼ LLM æ„å»ºç¬¦åˆé€»è¾‘ä¸€è‡´æ€§çš„ AHP å†³ç­–æ¨¡å‹ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

1. **åŸºäºè¯­ä¹‰æ ‘çš„ç»“æ„ç”Ÿæˆï¼ˆStructure Generation via Semantic Treesï¼‰**
   - ä½¿ç”¨ **Hierarchical Clustering** å¯¹æ–‡æ¡£æ®µè½çš„åµŒå…¥å‘é‡è¿›è¡Œèšç±»ï¼Œå½¢æˆä¸€æ£µè¯­ä¹‰æ ‘ $ T $ã€‚
   - å°†è¯¥è¯­ä¹‰æ ‘ä½œä¸º AHP å±‚çº§ç»“æ„ $ H $ çš„éª¨æ¶ï¼Œé€šè¿‡é€’å½’å‰ªæå’Œæ˜ å°„ç”Ÿæˆå…·æœ‰è¯­ä¹‰è¿è´¯æ€§çš„å†³ç­–å‡†åˆ™ã€‚
   - å¼•å…¥è®¤çŸ¥çº¦æŸï¼ˆæœ€å¤§åˆ†æ”¯æ•° $ K_{\text{max}} $ã€æœ€å¤§æ·±åº¦ $ D_{\text{max}} $ï¼‰ï¼Œé˜²æ­¢è¿‡åº¦å¤æ‚åŒ–ã€‚

2. **Leader-Guided å¤šæ™ºèƒ½ä½“æƒé‡ä¼°è®¡æœºåˆ¶ï¼ˆMulti-Agent Weight Estimation with Consistency Optimizationï¼‰**
   - è®¾è®¡ä¸€ä¸ªç”±å¤šä¸ª **Domain Expert Agents** å’Œä¸€ä¸ª **Leader Agent** ç»„æˆçš„åä½œç³»ç»Ÿï¼š
     - å„ Expert Agent ç‹¬ç«‹ç”Ÿæˆ pairwise comparison matrixï¼›
     - ä½¿ç”¨åŠ æƒå‡ ä½•å¹³å‡èšåˆä¸ºå…±è¯†çŸ©é˜µ $ M $ï¼›
     - å¼•å…¥ **Leader Agent çš„é«˜å±‚è¯­ä¹‰çº¦æŸ**ï¼ˆå¦‚ â€œSafety â‰« Costâ€ï¼‰è½¬åŒ–ä¸ºçº¿æ€§ä¸ç­‰å¼çº¦æŸ $ \Omega_{\text{leader}} $ã€‚
   - é‡‡ç”¨ **Logarithmic Least Squares Method (LLSM)** è¿›è¡Œä¼˜åŒ–ï¼Œåœ¨ä¿è¯æ•°å­¦ä¸€è‡´æ€§ï¼ˆCR < 0.1ï¼‰çš„åŒæ—¶ä¿ç•™è¯­ä¹‰åˆç†æ€§ã€‚

3. **æ— éœ€æ ‡æ³¨æ•°æ®ä¸äººå·¥å¹²é¢„çš„æ— ç›‘ç£æµç¨‹**
   - æ•´ä¸ªæµç¨‹å®Œå…¨åŸºäºåŸå§‹æ–‡æ¡£å’Œç›®æ ‡æè¿°è‡ªåŠ¨å®Œæˆï¼Œæ— éœ€äººå·¥æ ‡æ³¨æˆ–å¾®è°ƒï¼ˆzero-shot settingï¼‰ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | ä¼ ç»Ÿ AHP | ç°æœ‰ LLM æ–¹æ³•ï¼ˆå¦‚ Standard-AHP, Debate-AHPï¼‰ | Doc2AHP |
|------|----------|---------------------------------------------|--------|
| ç»“æ„åˆç†æ€§ | é«˜ï¼ˆäººå·¥è®¾è®¡ï¼‰ | ä½ï¼ˆè‡ªç”±ç”Ÿæˆæ˜“æ··ä¹±ï¼‰ | âœ… é«˜ï¼ˆå—è¯­ä¹‰æ ‘çº¦æŸï¼‰ |
| æ•°å€¼ä¸€è‡´æ€§ | é«˜ | ä¸­â€“ä½ï¼ˆCR ä¸å¯æ§ï¼‰ | âœ… é«˜ï¼ˆä¼˜åŒ–æ¨¡å—ä¿éšœ CR < 0.1ï¼‰ |
| å¯è§£é‡Šæ€§ | é«˜ | ä½ï¼ˆé»‘ç›’ç”Ÿæˆï¼‰ | âœ… é«˜ï¼ˆå®Œæ•´å†³ç­–é“¾å¯è¿½æº¯ï¼‰ |
| è‡ªåŠ¨åŒ–ç¨‹åº¦ | ä½ | é«˜ | âœ… é«˜ |
| å¯¹å¼±æ¨¡å‹é²æ£’æ€§ | ä¸é€‚ç”¨ | å·®ï¼ˆå°æ¨¡å‹ä¸‹å´©æºƒï¼‰ | âœ… å¼ºï¼ˆä¼˜åŒ–å…œåº•ï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
æ„å»ºäº†ä¸€ä¸ªåä¸º **DecisionBench** çš„åŸºå‡†æµ‹è¯•é›†ï¼Œæ¶µç›–ä¸‰ä¸ªçœŸå®ä¸–ç•Œé¢†åŸŸï¼Œå…± **6 ä¸ªå†³ç­–åœºæ™¯**ï¼š

| é¢†åŸŸ | åœºæ™¯ ID | å†³ç­–ç›®æ ‡ç¤ºä¾‹ | å…³æ³¨é‡ç‚¹ |
|------|--------|--------------|---------|
| **Movies** | M-Act, M-Dra | é€‰æ‹©æœ€ä½³è§†è§‰å¤§ç‰‡ / å™äº‹è‰ºæœ¯ç‰‡ | Visuals, Narrative Depth |
| **Hotels** | H-Fam, H-Bus | å®¶åº­å‹å¥½å‹é…’åº— / å•†åŠ¡é«˜æ•ˆé…’åº— | Safety, Amenities, Location |
| **Beers** | B-Ref, B-Cplx | æ¸…çˆ½å¤æ—¥å•¤é…’ / å¤æ‚é£å‘³ç²¾é…¿ | Crispness, Flavor Complexity |

æ¯ä¸ªåœºæ™¯åŒ…å«çº¦ 20 ä¸ªå€™é€‰å¯¹è±¡ï¼ˆalternativesï¼‰ï¼Œå¹¶é€šè¿‡ LLM æ‰©å±•æè¿°ç»†èŠ‚ï¼Œç¡®ä¿ç»†ç²’åº¦æ¯”è¾ƒå¯è¡Œæ€§ã€‚

è¾“å…¥ä¸Šä¸‹æ–‡ç»Ÿä¸€ä¸ºçº¦ 20 ç¯‡ä¸“å®¶æ–‡æ¡£ï¼ˆç»æ ‡å‡†åŒ–é¢„å¤„ç†ï¼‰ï¼Œä»¥æ§åˆ¶æ£€ç´¢åå·®ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®

- **ä¸»å¹²æ¨¡å‹**ï¼šé»˜è®¤ä½¿ç”¨ **GPT-5.2 (Temp=0.1)**ï¼›åŒæ—¶åœ¨ **Llama-3.1-8B / 70B** ä¸ŠéªŒè¯è·¨æ¨¡å‹é²æ£’æ€§ã€‚
- **é›¶æ ·æœ¬è®¾å®š**ï¼šæ‰€æœ‰æ–¹æ³•å‡æœªè¿›è¡Œ fine-tuningã€‚
- **å›ºå®šä¸Šä¸‹æ–‡åè®®**ï¼šâ€œFixed Domain Contextâ€ï¼Œå³æ‰€æœ‰æ–¹æ³•æ¥æ”¶ç›¸åŒçš„æ–‡æ¡£è¾“å…¥ã€‚
- **ç‹¬ç«‹è¿è¡Œ**ï¼šæ¯ç»„å®éªŒç‹¬ç«‹æ‰§è¡Œå®Œæ•´ pipeline 5 æ¬¡ï¼ŒæŠ¥å‘Šå‡å€¼ä¸ç¨³å®šæ€§ã€‚

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡

| ç±»åˆ« | æŒ‡æ ‡ | è¯´æ˜ |
|------|------|------|
| **å†³ç­–å‡†ç¡®æ€§** | **NDCG@5**, **NDCG@10** | è¡¡é‡æ¨èåˆ—è¡¨å‰5/10é¡¹ä¸çœŸå®è´¨é‡æ’åºçš„ç›¸å…³æ€§ï¼Œè¶Šé«˜è¶Šå¥½ |
| **æ•°å€¼ä¸€è‡´æ€§** | **CR-mean**, **CR-max**, **Pass Rate (CR < 0.1)** | æˆå¯¹æ¯”è¾ƒçŸ©é˜µçš„ä¸€è‡´æ€§æ¯”ç‡ç»Ÿè®¡ï¼ŒPass Rate è¶Šé«˜è¡¨ç¤ºè¶Šå¯é  |
| **æ¶ˆèåˆ†æ** | NDCG@5/@10 å¯¹æ¯”ä¸åŒå˜ä½“ | åˆ†æå„ç»„ä»¶è´¡çŒ® |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | æè¿° |
|------|------|
| **Standard-AHP** [Lu et al., 2024] | å• LLM + Chain-of-Thought ç”ŸæˆçŸ©é˜µï¼Œæ— ç»“æ„çº¦æŸ |
| **Debate-AHP** [Svoboda and Lande, 2024] | å¤šæ™ºèƒ½ä½“è¾©è®ºè¾¾æˆå…±è¯†ï¼Œä½†ä»ä¸ºè¯­ä¹‰åå•†ï¼Œæ— æ•°å­¦ä¼˜åŒ– |

ä¸¤è€…å‡æ³¨å…¥ç›¸åŒæ–‡æ¡£è¾“å…¥ï¼Œå¹¶é€‚é…è¾“å‡ºæ ¼å¼ä»¥ä¾¿å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å†³ç­–å‡†ç¡®ç‡ï¼ˆNDCGï¼‰

| æ–¹æ³• | M-Dra @5 | H-Fam @5 | B-Cplx @5 | å¹³å‡ @5 |
|------|---------|---------|----------|--------|
| Standard-AHP | 0.830 | 0.950 | 0.948 | ~0.909 |
| Debate-AHP | 0.777 | 0.912 | 0.949 | ~0.879 |
| **Doc2AHP (Ours)** | **0.854** | **0.974** | **0.965** | **~0.931** |

âœ… **Doc2AHP åœ¨ 5/6 åœºæ™¯ä¸­å–å¾—æœ€ä¼˜ NDCG@5 è¡¨ç°**ï¼Œå°¤å…¶åœ¨æŠ½è±¡æ¦‚å¿µå¯†é›†çš„ä»»åŠ¡ï¼ˆå¦‚ M-Dra, B-Cplxï¼‰ä¸Šä¼˜åŠ¿æ˜¾è‘—ã€‚

> ğŸ’¡ å‘ç°ï¼šéšç€ä»»åŠ¡è¯­ä¹‰å¤æ‚åº¦ä¸Šå‡ï¼ŒDoc2AHP çš„ç»“æ„æ€§æå–èƒ½åŠ›æ›´èƒ½æ•æ‰æ·±å±‚è¯„ä»·ç»´åº¦ï¼ˆå¦‚å™äº‹æ·±åº¦ã€é£å‘³å±‚æ¬¡ï¼‰ï¼Œè€Œ baseline æ˜“ä¸¢å¤±è¿™äº›ä¿¡æ¯ã€‚

---

### ğŸ”¢ æ•°å€¼ä¸€è‡´æ€§è¡¨ç°ï¼ˆH-Fam åœºæ™¯ï¼Œå¤šæ¨¡å‹æµ‹è¯•ï¼‰

| Method | Model | CR-mean | CR-max | Pass Rate |
|--------|-------|--------|--------|-----------|
| Standard-AHP | Llama-8B | 0.1693 | 0.7514 | 71.42% |
| Debate-AHP | Llama-8B | 0.2902 | 0.4309 | **0%** âŒ |
| **Doc2AHP** | Llama-8B | **0.0139** | **0.0807** | **100%** âœ… |
| Standard-AHP | Llama-70B | 0.1414 | 1.3921 | 86.95% |
| Debate-AHP | Llama-70B | 0.0065 | 0.0132 | 100% |
| **Doc2AHP** | Llama-70B | **0.0530** | **0.0957** | **100%** âœ… |

âœ… **Doc2AHP åœ¨æ‰€æœ‰æ¨¡å‹å°ºåº¦ä¸‹å‡ä¿æŒ 100% é€šè¿‡ç‡**ï¼Œå³ä½¿åœ¨å¼±æ¨¡å‹ï¼ˆLlama-8Bï¼‰ä¸Šä¹Ÿç¨³å®šå¯é ã€‚

> ğŸ’¥ å…³é”®å‘ç°ï¼šDebate-AHP åœ¨å°æ¨¡å‹ä¸Šå‡ºç°â€œå…±è¯†å´©å¡Œâ€ï¼ˆConsensus Collapseï¼‰ï¼Œå¤šä¸ªå¹»è§‰ agent ç›¸äº’è¯¯å¯¼ï¼Œå¯¼è‡´ CR æ¶åŒ–è‡³ä¸å¯æ¥å—æ°´å¹³ï¼›è€Œ Doc2AHP çš„ä¼˜åŒ–æ¨¡å—èµ·åˆ°äº†â€œæ•°å­¦å®ˆé—¨äººâ€ä½œç”¨ã€‚

---

### ğŸ” æ¶ˆèå®éªŒï¼ˆAblation Study on H-Famï¼‰

| Model Variant | NDCG@5 | NDCG@10 |
|---------------|--------|---------|
| w/o Structï¼ˆæ— è¯­ä¹‰æ ‘ç»“æ„ï¼‰ | 0.986 | **0.963** |
| w/o Optï¼ˆæ— ä¸€è‡´æ€§ä¼˜åŒ–ï¼‰ | 0.977 | 0.953 |
| **Full Model (Ours)** | **0.993** | 0.961 |

- **ç§»é™¤ç»“æ„å…ˆéªŒï¼ˆw/o Structï¼‰**ï¼šNDCG@5 ä¸‹é™æ˜æ˜¾ï¼Œè¯´æ˜ç¼ºå°‘ç²¾ç»†ç»“æ„æå–ä¼šå‰Šå¼± top-ranked å€™é€‰è¯†åˆ«èƒ½åŠ›ï¼›
- **ç§»é™¤ä¼˜åŒ–æ¨¡å—ï¼ˆw/o Optï¼‰**ï¼šä¸¤é¡¹æŒ‡æ ‡å…¨é¢ä¸‹é™ï¼Œè¯å®ç›´æ¥ LLM è¾“å‡ºæ˜“å¼•å…¥é€»è¾‘å†²çªï¼›
- **å®Œæ•´æ¨¡å‹åœ¨ top-precision ä¸Šè¡¨ç°æœ€å¼º**ï¼Œä½“ç°â€œç»“æ„ + ä¼˜åŒ–â€åŒè½®é©±åŠ¨çš„æœ‰æ•ˆæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º

1. **ç»“æ„å…ˆéªŒ + å¤šæ™ºèƒ½ä½“ååŒ + æ•°å­¦ä¼˜åŒ–** æ˜¯æ„å»ºå¯é  LLM-based AHP æ¨¡å‹çš„å…³é”®è·¯å¾„ï¼›
2. **è¯­ä¹‰æ ‘ï¼ˆSemantic Treeï¼‰èƒ½æœ‰æ•ˆç¼–ç æ–‡æ¡£ä¸­çš„æ½œåœ¨å†³ç­–å±‚çº§**ï¼Œä¸º AHP ç»“æ„æä¾›å¼ºå½’çº³åç½®ï¼›
3. **Leader-Guided ä¼˜åŒ–æœºåˆ¶å¯åœ¨ä¸ç‰ºç‰²è¯­ä¹‰æ„å›¾çš„å‰æä¸‹å¼ºåˆ¶æ»¡è¶³ä¸€è‡´æ€§è¦æ±‚**ï¼Œä¼˜äºçº¯ä»£æ•°ä¿®æ­£ï¼›
4. Doc2AHP åœ¨ **è½»é‡çº§æ¨¡å‹ä¸Šä»ä¿æŒé«˜æ€§èƒ½ä¸é«˜ä¸€è‡´æ€§**ï¼Œé€‚åˆéƒ¨ç½²äºè¾¹ç¼˜è®¾å¤‡æˆ–èµ„æºå—é™ç¯å¢ƒï¼›
5. è¯¥æ–¹æ³•å®ç°äº†ä»â€œç›´è§‰å¼å¿«æ€è€ƒâ€åˆ°â€œå¯éªŒè¯æ…¢æ€è€ƒâ€çš„è½¬å˜ï¼Œæå‡è‡ªåŠ¨åŒ–å†³ç­–ç³»ç»Ÿçš„å¯ä¿¡åº¦ã€‚

---

### âš ï¸ å±€é™æ€§

1. **è®¡ç®—å¼€é”€è¾ƒé«˜**ï¼šç›¸æ¯”ç›´æ¥ promptï¼ŒDoc2AHP åŒ…å«èšç±»ã€å¤š agent æ¨ç†ã€ä¼˜åŒ–ç­‰å¤šä¸ªæ­¥éª¤ï¼Œå»¶è¿Ÿæ›´å¤§ï¼›
2. **å¯¹æ–‡æ¡£è´¨é‡æ•æ„Ÿ**ï¼šè‹¥è¾“å…¥æ–‡æ¡£æœ¬èº«å­˜åœ¨çŸ›ç›¾æˆ–ä¿¡æ¯ç¨€ç–ï¼Œç”Ÿæˆçš„æ¨¡å‹å¯èƒ½å—é™ï¼›
3. **å‚æ•°é…ç½®å½±å“ç»“æœ**ï¼š$ K_{\text{max}}, D_{\text{max}} $ ç­‰è¶…å‚æ•°éœ€åˆç†è®¾ç½®ï¼Œå¦åˆ™å¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆæˆ–æ¬ è¡¨è¾¾ï¼›
4. å½“å‰ä»…é€‚ç”¨äºæ–‡æœ¬è¾“å…¥ï¼Œå°šæœªæ‰©å±•è‡³å›¾åƒæˆ–å¤šæ¨¡æ€å†³ç­–åœºæ™¯ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **åŠ¨æ€ç»“æ„è°ƒæ•´æœºåˆ¶**ï¼šè®©æ¨¡å‹è‡ªé€‚åº”å†³å®šæœ€ä½³æ·±åº¦ä¸å®½åº¦ï¼Œå‡å°‘äººå·¥å¹²é¢„ï¼›
2. **å¼•å…¥åé¦ˆå›è·¯**ï¼šå…è®¸äººç±»ä¸“å®¶åœ¨çº¿æ ¡æ­£èŠ‚ç‚¹æˆ–æƒé‡ï¼Œå®ç° Human-in-the-loop å†³ç­–ï¼›
3. **å¤šæ¨¡æ€ Doc2AHP**ï¼šèåˆå›¾æ–‡ã€è¡¨æ ¼ç­‰å¼‚æ„ä¿¡æ¯æºæ„å»ºæ›´ä¸°å¯Œçš„å†³ç­–æ¨¡å‹ï¼›
4. **å®æ—¶æµå¼æ›´æ–°**ï¼šæ”¯æŒå¢é‡å¼æ–‡æ¡£è¾“å…¥ï¼ŒåŠ¨æ€è°ƒæ•´å·²æœ‰ AHP æ¨¡å‹ï¼›
5. **åº”ç”¨äºæ›´å¤šé«˜é£é™©é¢†åŸŸ**ï¼šå¦‚åŒ»ç–—è¯Šæ–­ã€é‡‘èé£æ§ã€æ”¿ç­–åˆ¶å®šç­‰éœ€è¦å®¡è®¡è¿½è¸ªçš„åœºæ™¯ã€‚

---

> ğŸ§© æ€»ç»“ä¸€å¥è¯ï¼š  
> **Doc2AHP æˆåŠŸå°† LLM çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ä¸ AHP çš„å½¢å¼åŒ–é€»è¾‘ç›¸ç»“åˆï¼Œèµ°å‡ºäº†ä¸€æ¡â€œç¥ç»ç¬¦å·â€ï¼ˆneuro-symbolicï¼‰è·¯å¾„ï¼Œä½¿éä¸“å®¶ä¹Ÿèƒ½ä»æ–‡æ¡£ä¸­æ„å»ºå‡ºä¸“ä¸šçº§ã€å¯å®¡è®¡çš„å†³ç­–æ¨¡å‹ã€‚**

</details>

---

### 11. [Efficient Gaussian process learning via subspace projections](https://arxiv.org/abs/2601.16332)

**Authors**: Felipe Tobar, Elsa Cazelles  
**Category**: cs.LG  
**Published**: 2026-01-26  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.16332v1  

#### Abstract
We propose a novel training objective for GPs constructed using lower-dimensional linear projections of the data, referred to as \emph{projected likelihood} (PL). We provide a closed-form expression for the information loss related to the PL and empirically show that it can be reduced with random pr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Efficient Gaussian Process Learning via Subspace Projections*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
æ ‡å‡†çš„ **Gaussian Process (GP)** å›å½’åœ¨è®­ç»ƒæ—¶ä¾èµ–äºæœ€å¤§åŒ–ä¼¼ç„¶ï¼ˆMLï¼‰ï¼Œå…¶è®¡ç®—å¤æ‚åº¦ä¸º $O(n^3)$ï¼Œå…¶ä¸­ $n$ æ˜¯è§‚æµ‹æ ·æœ¬æ•°ã€‚è¿™ä½¿å¾—ä¼ ç»Ÿ GP åœ¨ä¸­ç­‰è§„æ¨¡ä»¥ä¸Šæ•°æ®é›†ï¼ˆå¦‚æ•°åƒä¸ªç‚¹ï¼‰ä¸Šå˜å¾—ä¸å¯è¡Œã€‚

å°½ç®¡å·²æœ‰ç¨€ç–è¿‘ä¼¼æ–¹æ³•ï¼ˆå¦‚åŸºäº inducing variables çš„ **sparse GPs**ï¼Œä¾‹å¦‚ VFEï¼‰ï¼Œä½†å®ƒä»¬å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- å­¦ä¹ åˆ°çš„è¶…å‚æ•°æœ‰åï¼ˆbiased hyperparametersï¼‰
- åªåœ¨ $n$ è¶³å¤Ÿå¤§æ—¶æ‰ä½“ç°å‡ºè®¡ç®—ä¼˜åŠ¿ï¼ˆasymptotic efficiencyï¼‰
- è®­ç»ƒç›®æ ‡æ›´å¤æ‚ï¼Œéœ€è¦æ›´å¤šä¼˜åŒ–æ­¥éª¤

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šProjected Likelihood (PL)
æœ¬æ–‡æå‡ºä¸€ç§æ–°çš„è®­ç»ƒç›®æ ‡â€”â€”**Projected Likelihood (PL)**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å°†åŸå§‹é«˜ç»´è§‚æµ‹æ•°æ® $\mathbf{y} \in \mathbb{R}^n$ æŠ•å½±åˆ°ä½ç»´å­ç©ºé—´ï¼ˆé€šè¿‡ $k < n$ ä¸ªçº¿æ€§æŠ•å½±æ–¹å‘ï¼‰
- åœ¨æŠ•å½±åçš„ä½ç»´å˜é‡ $\mathbf{z} = \Omega^\top \mathbf{y}$ ä¸Šå®šä¹‰ä¸€ä¸ªä»£ç† GP æ¨¡å‹ï¼Œå¹¶æœ€å¤§åŒ–å…¶ä¼¼ç„¶
- å¾—åˆ°çš„è®­ç»ƒç›®æ ‡ç§°ä¸º **Projected Likelihood (PL)**ï¼Œå…¶è´Ÿå¯¹æ•°å½¢å¼ä½œä¸ºæŸå¤±å‡½æ•°

è¯¥æ–¹æ³•å…·æœ‰é—­åˆè§£è¡¨è¾¾å¼ï¼Œè®¡ç®—æˆæœ¬ä¸º $O(kn^2)$ï¼Œä¸”å¯é€šè¿‡éšæœºçƒé¢æŠ•å½±æœ‰æ•ˆå‡å°‘ä¿¡æ¯æŸå¤±ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿è¯´æ˜ |
|------|----------|
| **å‡†ç¡®æ€§** | PL å­¦å¾—çš„è¶…å‚æ•°å’Œæœ€ç»ˆ NLL æ›´æ¥è¿‘ exact GPï¼Œä¼˜äº VFEï¼›å°¤å…¶åœ¨ posterior variance ä¸Šæ— ç³»ç»Ÿæ€§é«˜ä¼°ï¼ˆVFE å·²çŸ¥é—®é¢˜ï¼‰ |
| **æ•ˆç‡** | å°½ç®¡ç†è®ºå¤æ‚åº¦é«˜äº VFE çš„ $O(nm^2)$ï¼Œä½†ç”±äº PL çš„ loss landscape æ›´å¹³æ»‘ï¼Œæ‰€éœ€ä¼˜åŒ–æ­¥æ•°æ˜¾è‘—æ›´å°‘ï¼Œå®é™…è¿è¡Œæ—¶é—´æ›´å¿«ï¼ˆå°¤å…¶å½“ $n < 3000$ï¼‰ |
| **ç®€æ´æ€§** | ä¸å¼•å…¥é¢å¤–å¯å­¦ä¹ å˜é‡ï¼ˆå¦‚ inducing points ä½ç½®ï¼‰ï¼Œé¿å…å¢åŠ ä¼˜åŒ–è´Ÿæ‹… |
| **ç†è®ºæ”¯æŒ** | æ¨å¯¼äº† Fisher information loss çš„æ˜¾å¼è¡¨è¾¾å¼ï¼Œè¯æ˜ä¿¡æ¯æŸå¤±ä¸æ¡ä»¶åæ–¹å·® $\Sigma_{Y|Z}$ æœ‰å…³ï¼Œå¹¶å¯é€šè¿‡é€‰æ‹©æœ€ä¼˜æŠ•å½±æ–¹å‘æœ€å°åŒ– |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
1. **åˆæˆæ•°æ®**  
   - ç”± SE kernel ($\sigma=1, l=20, \sigma_n=0.1$) ç”Ÿæˆçš„ 1000 æ ·æœ¬æ—¶é—´åºåˆ—
   - ç”¨äºæ¯”è¾ƒä¸åŒ optimizer ä¸‹çš„è¡¨ç°ï¼ˆE1ï¼‰

2. **çœŸå®ä¸–ç•Œæ•°æ®**
   - **Sunspots æ•°æ®é›†**ï¼š3319 ä¸ªæœˆåº¦å¤ªé˜³é»‘å­æ•°é‡è®°å½•
   - **EEG æ•°æ®é›†**ï¼šHelsinki æ–°ç”Ÿå„¿è„‘ç”µå›¾å­é›†ï¼ˆå…± 10000 ç‚¹ï¼Œå– 8000 è®­ç»ƒ + 2000 éªŒè¯ï¼‰

### âš™ï¸ å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
| è®¾ç½®é¡¹ | æè¿° |
|-------|------|
| **æ¨¡å‹é…ç½®** | å¯¹æ¯”æ–¹æ³•ï¼š<br>â€¢ Exact MLï¼ˆåŸºå‡†ï¼‰<br>â€¢ VFEï¼ˆvariational free energyï¼‰<br>â€¢ PLï¼ˆæœ¬æ–‡æ–¹æ³•ï¼‰<br>å›ºå®š $k = m = 100$ è¿›è¡Œå¤šæ•°å®éªŒ |
| **ä¼˜åŒ–å™¨** | æµ‹è¯• BFGS å’Œ Adamï¼›æœ€ç»ˆç»Ÿä¸€ä½¿ç”¨ Adamï¼ˆè¡¨ç°æ›´å¥½ï¼‰ |
| **è¯„ä¼°æŒ‡æ ‡** | 
| | â€¢ **Negative Log-Likelihood (NLL)**ï¼šè¡¡é‡æ¨¡å‹æ‹Ÿåˆä¼˜åº¦ |
| | â€¢ **Running Time (ç§’)**ï¼šæ€»è®­ç»ƒè€—æ—¶ |
| | â€¢ **RMSE**ï¼šä»…ç”¨äº EEG å®éªŒï¼ˆexact GP ä¸å¯è¡Œï¼‰ |
| | â€¢ **Posterior Variance å¯è§†åŒ–**ï¼šåˆ†æä¸ç¡®å®šæ€§ä¼°è®¡è´¨é‡ |
| **æŠ•å½±è®¾è®¡å¯¹æ¯”** | æµ‹è¯•å¤šç§æŠ•å½±çŸ©é˜µ $\Omega$ï¼š<br>â€¢ Sphereï¼ˆå•ä½çƒé¢ä¸Šå‡åŒ€é‡‡æ ·ï¼‰<br>â€¢ Repulsiveï¼ˆå¸¦æ’æ–¥åŠ›çš„çƒé¢é‡‡æ ·ï¼‰<br>â€¢ Localisedï¼ˆé«˜æ–¯ RBF è¦†ç›–ï¼‰<br>â€¢ One-hotï¼ˆå•ç‚¹æŒ‡ç¤ºå‘é‡ï¼‰ |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Exact Maximum Likelihood (ML)**ï¼šç†æƒ³æƒ…å†µä¸‹çš„æ€§èƒ½ä¸Šé™
- **VFE (Variational Free Energy)**ï¼šå½“å‰ä¸»æµ sparse GP æ–¹æ³•ï¼Œä»£è¡¨ SOTA è¿‘ä¼¼è®­ç»ƒæ¡†æ¶

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### è¡¨ 1ï¼šE1 å®éªŒï¼ˆåˆæˆæ•°æ®ï¼Œn=1000ï¼‰
| æ–¹æ³• | Optimizer | NLL â†“ | æ—¶é—´ (s) â†“ |
|------|-----------|--------|------------|
| ML (exact) | â€” | 337.4 | 26.5 (BFGS), 3.66 (Adam) |
| VFE | Adam | 358.1 | 1.57 |
| **PL** | **Adam** | **347.0** | **0.574** |

âœ… **ç»“è®º**ï¼šPL çš„ NLL æ˜¾è‘—ä¼˜äº VFEï¼Œä¸”è®­ç»ƒé€Ÿåº¦æœ€å¿«ã€‚

---

#### å›¾ 3ï¼šE2 å®éªŒï¼ˆä¸åŒ $n$ ä¸‹ NLL vs æ—¶é—´ï¼‰
- æ‰€æœ‰ $n \in \{500, ..., 4000\}$ æƒ…å†µä¸‹ï¼ŒPL åœ¨è¾¾åˆ°ç›¸åŒ NLL æ—¶å‡å¿«äº VFEï¼ˆå°¤å…¶ $n < 3000$ï¼‰
- å½“ $n > 3000$ åä¸¤è€…æ€§èƒ½è¶‹åŒï¼ˆå›  VFE æ¸è¿›ä¼˜åŠ¿æ˜¾ç°ï¼‰
- PL ä½¿ç”¨æ›´å°‘è¿­ä»£å³å¯æ”¶æ•› â†’ å®é™…æ•ˆç‡æ›´é«˜

---

#### è¡¨ 2 & 3ï¼šE3 å®éªŒï¼ˆçœŸå®æ•°æ®ï¼‰

##### è¡¨ 2ï¼šSunspots æ•°æ®é›†ï¼ˆn=3319ï¼‰
| Kernel | æ–¹æ³• | NLL â†“ | æ—¶é—´ (s) â†“ |
|--------|------|--------|------------|
| SE | ML | 1549.12 | 197.15 |
| SE | VFE | 1691.999 | 6.78 |
| SE | **PL** | **1584.565** | **19.62** |
| Laplace | **PL** | **1675.062** | **31.46** |
| ... | ... | ... | ... |

> âœ… PL åœ¨æ‰€æœ‰ kernel ä¸‹ NLL å‡è¿œä½äº VFEï¼Œæ¥è¿‘ exact ML

##### è¡¨ 3ï¼šEEG æ•°æ®é›†ï¼ˆn=8000ï¼‰
| Kernel | æ–¹æ³• | RMSE â†“ | æ—¶é—´ (s) â†“ |
|--------|------|--------|------------|
| SE | VFE | 0.303 | 148.08 |
| SE | **PL** | **0.194** | **306.22** |
| Laplace | VFE | 0.270 | 614.32 |
| Laplace | **PL** | **0.145** | **630.61** |

> âœ… PL åœ¨é¢„æµ‹ç²¾åº¦ï¼ˆRMSEï¼‰ä¸Šå…¨é¢èƒœå‡ºï¼Œè™½ç¨æ…¢ä½†ä»å…·ç«äº‰åŠ›

---

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### æŠ•å½±æ–¹å‘è®¾è®¡çš„å½±å“ï¼ˆSec. 4, Fig. 1ï¼‰
- åˆ†æä¸åŒ $\Omega$ è®¾è®¡å¯¹ $\text{tr}(\Sigma_{Y|Z})$ çš„å½±å“ï¼ˆåæ˜ ä¿¡æ¯ä¿ç•™ç¨‹åº¦ï¼‰
- ç»“æœæ’åºï¼ˆä»ä¼˜åˆ°åŠ£ï¼‰ï¼š
  1. **Sphere**ï¼ˆçƒé¢å‡åŒ€æŠ•å½±ï¼‰â†’ æœ€å° traceï¼Œæœ€ä½³å‹ç¼©æ•ˆæœ
  2. Repulsive / Localised
  3. **One-hot** â†’ æ•ˆæœæœ€å·®ï¼ˆæ•æ‰ç›¸å…³æ€§èƒ½åŠ›å¼±ï¼‰

ğŸ‘‰ å› æ­¤åç»­å®éªŒå‡é‡‡ç”¨ **spherical random projections**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **PL æ˜¯ä¸€ç§é«˜æ•ˆä¸”å‡†ç¡®çš„ GP è®­ç»ƒæ›¿ä»£æ–¹æ¡ˆ**
   - åœ¨ moderate-sized datasetsï¼ˆ$n \lesssim 8000$ï¼‰ä¸Šï¼ŒPL åœ¨ NLL/RMSE ä¸Šæ˜¾è‘—ä¼˜äº VFE
   - å®é™…è®­ç»ƒæ—¶é—´æ›´çŸ­ï¼Œå¾—ç›Šäºæ›´ç®€å•çš„ loss landscape å’Œæ›´å°‘ä¼˜åŒ–æ­¥æ•°

2. **ä¿¡æ¯æŸå¤±å¯æ§ä¸”å¯é‡åŒ–**
   - æ¨å¯¼å‡º Fisher information loss çš„é—­å¼è¡¨è¾¾ï¼Œæ­ç¤ºå…¶ä¸ $\Sigma_{Y|Z}$ çš„äºŒæ¬¡å…³ç³»
   - ä½¿ç”¨éšæœºçƒé¢æŠ•å½±èƒ½æœ‰æ•ˆé™ä½ä¿¡æ¯æŸå¤±

3. **æ— éœ€å¼•å…¥é¢å¤–å¯å­¦ä¹ å‚æ•°**
   - ç›¸æ¯” VFE ä¸­éœ€è”åˆä¼˜åŒ– inducing point ä½ç½®ï¼ŒPL ä½¿ç”¨å›ºå®šæŠ•å½±æ–¹å‘ï¼Œç®€åŒ–è®­ç»ƒæµç¨‹

4. **é€‚ç”¨äºå¤šç§ kernel å’Œ optimizer**
   - åœ¨ SEã€Laplaceã€RQã€LocPer ç­‰ kernel ä¸Šå‡æœ‰è‰¯å¥½è¡¨ç°
   - Adam è¡¨ç°ä¼˜äº BFGSï¼Œé€‚åˆ PL æ¡†æ¶

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
1. **ç†è®ºå¤æ‚åº¦ä»ä¸º $O(kn^2)$**
   - è™½å®è·µä¸­é«˜æ•ˆï¼Œä½†æ— æ³•æ‰©å±•è‡³è¶…å¤§è§„æ¨¡æ•°æ®ï¼ˆå¦‚ $n > 10^5$ï¼‰
   - ä¸å¦‚ structured kernel æˆ– deep GP ç­‰æ–¹æ³•å…·å¤‡æ›´å¼º scalability

2. **æŠ•å½±æ–¹å‘æœªè‡ªé€‚åº”æ›´æ–°**
   - å½“å‰ä½¿ç”¨å›ºå®šçš„éšæœºæŠ•å½±ï¼Œæœªèƒ½åŠ¨æ€è°ƒæ•´ä»¥è¿½è¸ªæ•°æ®åˆ†å¸ƒå˜åŒ–
   - è‹¥èƒ½ç»“åˆ adaptive projection selection å¯èƒ½è¿›ä¸€æ­¥æå‡æ€§èƒ½

3. **å¤šè¾“å‡ºåœºæ™¯å°šæœªéªŒè¯**
   - å½“å‰å®éªŒé›†ä¸­åœ¨ single-output GPï¼Œmulti-output extension æœ‰å¾…æ¢ç´¢

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **Adaptive Projection Selection**
   - åŠ¨æ€é€‰æ‹©æœ€å…·ä¿¡æ¯é‡çš„æŠ•å½±æ–¹å‘ï¼ˆå¦‚åŸºäºæ¢¯åº¦æˆ–ä¸»åŠ¨å­¦ä¹ ï¼‰

2. **ä¸å…¶ä»–ç¨€ç–æ–¹æ³•èåˆ**
   - ç»“åˆ inducing points ä¸ subspace projectionï¼Œæ„å»º hybrid approximation

3. **åº”ç”¨äº streaming data æˆ– online learning**
   - åˆ©ç”¨ä½ç»´æŠ•å½±å®ç°å¿«é€Ÿåœ¨çº¿æ›´æ–°

4. **ç†è®ºæ·±åŒ–**
   - åˆ†æ PL åœ¨éé«˜æ–¯ likelihood æˆ–åˆ†ç±»ä»»åŠ¡ä¸­çš„æ¨å¹¿èƒ½åŠ›

---

> ğŸ’¡ **æ€»ä½“è¯„ä»·**ï¼šæœ¬æ–‡æå‡ºçš„ **Projected Likelihood (PL)** æ–¹æ³•ä¸º GP è®­ç»ƒæä¾›äº†ä¸€ç§â€œè½»é‡çº§ä½†é«˜ä¿çœŸâ€çš„æ–°èŒƒå¼ï¼Œåœ¨ä¸­ç­‰è§„æ¨¡æ•°æ®ä¸Šå®ç°äº†**ç²¾åº¦ä¸æ•ˆç‡çš„åŒé‡çªç ´**ï¼Œæ˜¯å¯¹ sparse GP æ–¹æ³•çš„é‡è¦è¡¥å……å’Œå‘å±•ã€‚

</details>

---

### 12. [Latent Diffusion for Internet of Things Attack Data Generation in Intrusion Detection](https://arxiv.org/abs/2601.16976)

**Authors**: Estela S\'anchez-Carballo, Francisco M. Melgarejo-Meseguer, Jos\'e Luis Rojo-\'Alvarez  
**Category**: cs.LG  
**Published**: 2026-01-26  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.16976v1  

#### Abstract
Intrusion Detection Systems (IDSs) are a key component for protecting Internet of Things (IoT) environments. However, in Machine Learning-based (ML-based) IDSs, performance is often degraded by the strong class imbalance between benign and attack traffic. Although data augmentation has been widely e...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠLatent Diffusion for Internet of Things Attack Data Generation in Intrusion Detectionã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç‰©è”ç½‘ï¼ˆIoTï¼‰ç¯å¢ƒä¸­çš„ **Intrusion Detection Systems (IDSs)** é¢ä¸´ä¸¥é‡çš„**ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜**ï¼šè‰¯æ€§æµé‡è¿œå¤šäºæ”»å‡»æµé‡ï¼Œå¯¼è‡´åŸºäºæœºå™¨å­¦ä¹ ï¼ˆML-basedï¼‰çš„æ£€æµ‹æ¨¡å‹éš¾ä»¥æœ‰æ•ˆå­¦ä¹ ç¨€æœ‰ä½†å…³é”®çš„æ”»å‡»æ¨¡å¼ã€‚æ­¤å¤–ï¼ŒçœŸå®æ”»å‡»æ•°æ®æ”¶é›†å›°éš¾ã€æˆæœ¬é«˜ä¸”å—éšç§é™åˆ¶ï¼ŒåŠ å‰§äº†æ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚

ç°æœ‰æ•°æ®å¢å¼ºæ–¹æ³•å­˜åœ¨ä»¥ä¸‹ä¸è¶³ï¼š
- **SMOTE** ç­‰ä¼ ç»Ÿè¿‡é‡‡æ ·æŠ€æœ¯ç”Ÿæˆæ ·æœ¬å¤šæ ·æ€§ä½ï¼Œæ˜“å¯¼è‡´â€œè®°å¿†åŒ–â€ï¼ˆmemorizationï¼‰ï¼Œæ— æ³•æ‰©å±•å†³ç­–ç©ºé—´ã€‚
- **VAE** æ˜“äº§ç”Ÿè¿‡å¹³æ»‘ï¼ˆover-smoothedï¼‰æ ·æœ¬ï¼Œä¸¢å¤±ç»†èŠ‚ã€‚
- **GAN** å­˜åœ¨è®­ç»ƒä¸ç¨³å®šã€æ¨¡å¼å´©æºƒï¼ˆmode collapseï¼‰ç­‰é—®é¢˜ã€‚
- **ç›´æ¥åœ¨åŸå§‹ç‰¹å¾ç©ºé—´è¿è¡Œçš„ Diffusion Models (DMs)** è™½ç„¶ç”Ÿæˆè´¨é‡é«˜ï¼Œä½†è®¡ç®—å¼€é”€å¤§ã€é‡‡æ ·æ…¢ï¼Œå°¤å…¶å¯¹é«˜ç»´å¼‚æ„çš„ IoT è¡¨æ ¼æ•°æ®ä¸å‹å¥½ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº **Latent Diffusion Model (LDM)** çš„åˆæˆ IoT æ”»å‡»æ•°æ®ç”Ÿæˆæ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†æ‰©æ•£è¿‡ç¨‹ä»åŸå§‹æ•°æ®ç©ºé—´è½¬ç§»åˆ°ä¸€ä¸ªç´§å‡‘çš„æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œã€‚

å…·ä½“æµç¨‹å¦‚ä¸‹ï¼š
1. **Autoencoder (AE) ç¼–ç **ï¼šä½¿ç”¨ä¸€ä¸ªæ··åˆå˜é‡ AE å°†å¼‚æ„çš„ IoT æµé‡æ•°æ®ï¼ˆè¿ç»­ + åˆ†ç±»ç‰¹å¾ï¼‰ç¼–ç åˆ°ä¸€ä¸ªä½ç»´ã€å½’ä¸€åŒ–çš„ **latent space** ä¸­ã€‚
2. **Latent Diffusion Modeling**ï¼šåœ¨è¯¥æ½œåœ¨ç©ºé—´ä¸­è®­ç»ƒä¸€ä¸ª DM æ¥å­¦ä¹ å¹¶ç”Ÿæˆæ–°çš„æ½œåœ¨è¡¨ç¤ºã€‚
3. **è§£ç å›åŸå§‹ç©ºé—´**ï¼šé€šè¿‡ AE çš„ decoder å°†ç”Ÿæˆçš„æ½œåœ¨å‘é‡è¿˜åŸä¸ºçœŸå®çš„ã€è¯­ä¹‰ä¸€è‡´çš„åˆæˆæ”»å‡»æ ·æœ¬ã€‚

è¿™ç§æ–¹æ³•ç»“åˆäº† AE çš„é«˜æ•ˆé™ç»´èƒ½åŠ›å’Œ DM çš„é«˜è´¨é‡ç”Ÿæˆèƒ½åŠ›ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- âœ… **æ›´é«˜çš„æ ·æœ¬ä¿çœŸåº¦ä¸å¤šæ ·æ€§å¹³è¡¡**ï¼šç›¸æ¯” SMOTE å’Œ VAEï¼ŒLDM èƒ½ç”Ÿæˆæ›´çœŸå®ä¸”å¤šæ ·åŒ–çš„æ”»å‡»æ ·æœ¬ã€‚
- âœ… **æ›´å¼ºçš„ç‰¹å¾ä¾èµ–ä¿æŒèƒ½åŠ›**ï¼šèƒ½æ›´å¥½åœ°ä¿ç•™åŸå§‹æ•°æ®ä¸­çš„å¤æ‚ç»Ÿè®¡å…³ç³»å’Œç‰¹å¾é—´ä¾èµ–ã€‚
- âœ… **æ˜¾è‘—æå‡ä¸‹æ¸¸ IDS æ€§èƒ½**ï¼šåœ¨å¤šä¸ªæ”»å‡»ç±»å‹ä¸Šå®ç°æ¥è¿‘å®Œç¾çš„ F1-scoreã€‚
- âœ… **é™ä½è®¡ç®—æˆæœ¬**ï¼šç›¸è¾ƒäºç›´æ¥åœ¨æ•°æ®ç©ºé—´è¿è¡Œçš„ DMï¼ŒLDM åœ¨æ½œåœ¨ç©ºé—´æ“ä½œå‡å°‘äº†çº¦ **25% çš„é‡‡æ ·æ—¶é—´**ï¼Œæå‡äº†æ•ˆç‡ã€‚
- âœ… **é€‚ç”¨äºå¼‚æ„è¡¨æ ¼æ•°æ®**ï¼šä¸“é—¨è®¾è®¡å¤„ç† IoT æ•°æ®ä¸­å¸¸è§çš„æ··åˆå‹ï¼ˆmixed-typeï¼‰ç‰¹å¾ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **CICIoT2023 dataset**ï¼šç”±åŠ æ‹¿å¤§ç½‘ç»œå®‰å…¨ç ”ç©¶æ‰€å‘å¸ƒçš„çœŸå® IoT ç½‘ç»œæµé‡æ•°æ®é›†ã€‚
- åŒ…å«å¤šç§æ”»å‡»åœºæ™¯ï¼Œæœ¬ç ”ç©¶èšç„¦äºä¸‰ç§ä»£è¡¨æ€§æ”»å‡»ç±»å‹ï¼š
  - **DDoS-ICMP_Fragmentation**ï¼ˆé«˜æµé‡æ³›æ´ªï¼‰
  - **Mirai-greip_flood**ï¼ˆåƒµå°¸ç½‘ç»œæ³›æ´ªï¼‰
  - **MITM-ArpSpoofing**ï¼ˆä¸­é—´äººæ”»å‡»ï¼Œä½é€Ÿç‡éšè”½ï¼‰

### å®éªŒè®¾ç½®
- **ä»»åŠ¡ç›®æ ‡**ï¼šé€šè¿‡åˆæˆæ”»å‡»æ•°æ®å¢å¼ºæ¥å¹³è¡¡è®­ç»ƒé›†ï¼Œä»è€Œæå‡äºŒåˆ†ç±» IDSï¼ˆBenign vs. Attackï¼‰çš„æ£€æµ‹æ€§èƒ½ã€‚
- **æ•°æ®åˆ’åˆ†**ï¼š
  - æ”»å‡»æ•°æ®æŒ‰ 80%/10%/10% åˆ’åˆ†ä¸ºè®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†ã€‚
  - æµ‹è¯•é›†ä¿æŒåŸå§‹ä¸å¹³è¡¡æ¯”ä¾‹ï¼ˆçº¦ 1:5.3 è‡³ 1:5.6ï¼‰ä»¥å…¬å¹³è¯„ä¼°ã€‚
- **å¢å¼ºç­–ç•¥**ï¼šæ¯ç§ç”Ÿæˆæ¨¡å‹å‡ç”¨äºç”Ÿæˆè¶³å¤Ÿæ•°é‡çš„æ”»å‡»æ ·æœ¬æ¥ä½¿è®­ç»ƒé›†è¾¾åˆ°ç±»åˆ«å¹³è¡¡ã€‚
- **ä¸‹æ¸¸æ¨¡å‹**ï¼šä½¿ç”¨åŸºäºå­ç©ºé—´æ³•ï¼ˆsubspace methodï¼‰çš„é›†æˆåˆ†ç±»å™¨ï¼ˆ100 ä¸ªå­¦ä¹ å¾ªç¯ï¼‰è¿›è¡Œæ”»å‡»æ£€æµ‹ã€‚

### è¯„ä¼°æŒ‡æ ‡
#### ä¸‹æ¸¸ IDS æ€§èƒ½æŒ‡æ ‡ï¼š
- **Confusion Matrix (CM)**ï¼šè¡Œå½’ä¸€åŒ–ï¼Œåˆ†æå¬å›ç‡ç­‰ã€‚
- **F1-score**ï¼šç»¼åˆè¡¡é‡ç²¾ç¡®ç‡ä¸å¬å›ç‡ã€‚

#### åˆæˆæ ·æœ¬è´¨é‡æŒ‡æ ‡ï¼š
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **MMD (Maximum Mean Discrepancy)** | è¡¡é‡çœŸå®ä¸åˆæˆæ•°æ®åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ï¼ˆè¶Šå°è¶Šå¥½ï¼‰ |
| **Mean KL Divergence** | è¾¹ç¼˜åˆ†å¸ƒåŒ¹é…ç¨‹åº¦ï¼ˆè¶Šå°è¶Šå¥½ï¼‰ |
| **MI Error (Mutual Information Error)** | ç‰¹å¾é—´ä¾èµ–å…³ç³»ä¿æŒèƒ½åŠ›ï¼ˆè¶Šå°è¶Šå¥½ï¼‰ |
| **Precision / Recall (ç”Ÿæˆ)** | ç”Ÿæˆæ ·æœ¬æ˜¯å¦çœŸå®ä¸”è¦†ç›–å……åˆ† |
| **Nmed (Median Nearest Neighbor Distance)** | å¤šæ ·æ€§æŒ‡æ ‡ï¼Œå€¼è¶Šå¤§è¡¨ç¤ºæ ·æœ¬è¶Šåˆ†æ•£ã€è¶Šæ–°é¢– |
| **Sampling Time** | ç”Ÿæˆæ•ˆç‡ï¼Œåæ˜ å®é™…éƒ¨ç½²å¯è¡Œæ€§ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å…±æ¯”è¾ƒäº”ç§æ•°æ®å¢å¼ºæ–¹æ³•ï¼š
1. **SMOTE**ï¼šç»å…¸è¿‡é‡‡æ ·æ–¹æ³•ï¼Œä½œä¸ºéæ·±åº¦å­¦ä¹ åŸºçº¿ã€‚
2. **VAE**ï¼šå˜åˆ†è‡ªç¼–ç å™¨ï¼Œå­¦ä¹ æ¦‚ç‡æ½œå˜é‡ã€‚
3. **GAN**ï¼šç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼Œé‡‡ç”¨å¯¹æŠ—è®­ç»ƒæœºåˆ¶ã€‚
4. **DM (Data-space Diffusion Model)**ï¼šç›´æ¥åœ¨åŸå§‹ç‰¹å¾ç©ºé—´è¿è¡Œçš„æ‰©æ•£æ¨¡å‹ã€‚
5. **LDM (Latent Diffusion Model)**ï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•ã€‚

æ‰€æœ‰æ¨¡å‹å‡ç»è¿‡ **Bayesian Optimization** è¿›è¡Œè¶…å‚æ•°è°ƒä¼˜ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 5ï¼‰

| Attack Type | Baseline | SMOTE | VAE | GAN | DM | **LDM** |
|------------|---------|-------|-----|-----|----|--------|
| **DDoS**   | 0.46    | 0.89  | 0.96| 0.94| 0.97| **0.99** |
| **Mirai**  | 0.17    | 0.66  | 0.86| 0.83| 0.92| **0.99** |
| **MitM**   | 0.00    | 0.35  | 0.34| 0.33| **0.53**| 0.44 |

> ğŸ“Œ **ç»“è®º**ï¼šLDM åœ¨ **DDoS å’Œ Mirai æ”»å‡»ä¸Šè¾¾åˆ° F1=0.99**ï¼Œæ˜¾è‘—ä¼˜äºæ‰€æœ‰å…¶ä»–æ–¹æ³•ï¼›å¯¹äºæœ€å…·æŒ‘æˆ˜æ€§çš„ MitM æ”»å‡»ï¼ŒDM è¡¨ç°æœ€ä½³ï¼ˆF1=0.53ï¼‰ï¼ŒLDM æ¬¡ä¹‹ä½†ä»è¿œä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### åˆ†å¸ƒç›¸ä¼¼æ€§ï¼ˆDistributional Similarityï¼‰
- **SMOTE** åœ¨ MMD å’Œ KL ä¸Šè¡¨ç°æœ€å¥½ï¼Œè¯´æ˜å…¶å®Œç¾å¤åˆ¶äº†å±€éƒ¨ç»“æ„ã€‚
- **LDM** ä¸ **DM** æ¥è¿‘ SMOTE çš„åˆ†å¸ƒä¿çœŸåº¦ï¼Œæ˜æ˜¾ä¼˜äº VAE å’Œ GANã€‚

#### å¤šæ ·æ€§ä¸è®°å¿†åŒ–é£é™©
- **SMOTE** çš„ Nmed æœ€å° â†’ ææ˜“â€œè®°å¿†åŒ–â€ï¼Œç¼ºä¹å¤šæ ·æ€§ã€‚
- **VAE** çš„ Nmed æœ€å¤§ â†’ å¤šæ ·æ€§å¼ºï¼Œä½†ç‰ºç‰²äº†ä¿çœŸåº¦ã€‚
- **LDM** åœ¨æ‰€æœ‰æ”»å‡»ç±»å‹ä¸Šçš„ Nmed å‡é«˜äº DM â†’ **åœ¨ä¿æŒåˆ†å¸ƒä¸€è‡´æ€§çš„åŒæ—¶å®ç°äº†æ›´é«˜å¤šæ ·æ€§**ã€‚

#### ç‰¹å¾ä¾èµ–ä¿æŒï¼ˆMutual Information Analysisï¼‰
- **SMOTE** å‡ ä¹å®Œå…¨ä¿ç•™åŸå§‹ MI ç»“æ„ã€‚
- **VAE/GAN/DM** å¯¹ MI ç»“æ„æœ‰ä¸åŒç¨‹åº¦çš„æ¨¡ç³Šæˆ–æ‰­æ›²ã€‚
- **LDM** ç”Ÿæˆçš„ MI çŸ©é˜µæœ€æ¥è¿‘çœŸå®æ•°æ®ï¼Œåœ¨å…¨å±€ç»“æ„å’Œç»†ç²’åº¦ä¾èµ–ä¸Šå‡æœ‰è‰¯å¥½ä¿ç•™ã€‚

#### å¯è§†åŒ–åˆ†æï¼ˆUMAP æŠ•å½±ï¼‰
- **GAN/DM**ï¼šéƒ¨åˆ†åˆæˆæ ·æœ¬ä½äºçœŸå®æµå½¢ä¹‹å¤–ï¼ˆoff-manifoldï¼‰ï¼Œå¯èƒ½ç ´ååŸå§‹å‡ ä½•ç»“æ„ã€‚
- **LDM**ï¼šåˆæˆæ ·æœ¬å‡åŒ€å¡«å……ç©ºéš™ï¼Œæ—¢æœªåç¼©ä¹Ÿæœªåç¦»ä¸»æµå½¢ï¼Œè¡¨æ˜å…¶æ›´å‡†ç¡®åœ°å»ºæ¨¡äº†æœ¬åœ°å‡ ä½•ã€‚

#### é‡‡æ ·æ•ˆç‡ï¼ˆè§ Table 7ï¼‰
| æ–¹æ³• | ç”Ÿæˆ 10â´ æ ·æœ¬è€—æ—¶ï¼ˆmsï¼‰ |
|------|------------------------|
| GAN  | 4.85 Â± 0.87           |
| VAE  | 54.85 Â± 9.44          |
| SMOTE| 154.07 Â± 2.86         |
| DM   | 553.86 Â± 9.31         |
| **LDM** | **411.23 Â± 8.34**     |

> ğŸ“Œ **ç»“è®º**ï¼šLDM ç›¸æ¯” DM **æé€Ÿçº¦ 25%**ï¼Œæ˜¯å”¯ä¸€åœ¨ç”Ÿæˆè´¨é‡å’Œæ•ˆç‡ä¹‹é—´å–å¾—è‰¯å¥½å¹³è¡¡çš„æ‰©æ•£æ–¹æ³•ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **LDM æ˜¯ä¸€ç§é«˜æ•ˆä¸”å¯æ‰©å±•çš„ IoT æ”»å‡»æ•°æ®ç”Ÿæˆæ–¹æ¡ˆ**ï¼Œèƒ½å¤Ÿæœ‰æ•ˆç¼“è§£ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ã€‚
2. åœ¨ **DDoS å’Œ Mirai** ç­‰å…·æœ‰æ˜æ˜¾æµé‡ç‰¹å¾çš„æ”»å‡»ä¸Šï¼ŒLDM å®ç°è¿‘ä¹å®Œç¾çš„æ£€æµ‹æ€§èƒ½ï¼ˆF1=0.99ï¼‰ã€‚
3. LDM åœ¨ **åˆ†å¸ƒä¿çœŸåº¦ã€å¤šæ ·æ€§ã€ç‰¹å¾ä¾èµ–ä¿æŒå’Œè®¡ç®—æ•ˆç‡** å››æ–¹é¢å–å¾—äº†æœ€ä½³æƒè¡¡ã€‚
4. ç›¸æ¯”äºæ•°æ®ç©ºé—´ DMï¼Œæ½œåœ¨ç©ºé—´æ‰©æ•£ä¸ä»…åŠ å¿«äº†é‡‡æ ·é€Ÿåº¦ï¼Œè¿˜å¢å¼ºäº†æ ·æœ¬å¤šæ ·æ€§ï¼ˆæ›´é«˜çš„ Nmedï¼‰ã€‚
5. å¯¹äº **MitM** è¿™ç±»ä½é€Ÿã€ç¢ç‰‡åŒ–ã€æ¥è¿‘æ­£å¸¸è¡Œä¸ºçš„æ”»å‡»ï¼Œæ‰€æœ‰æ–¹æ³•ä»é¢ä¸´æŒ‘æˆ˜ï¼Œä½† DM åœ¨åˆ†ç±»æ€§èƒ½ä¸Šç•¥èƒœä¸€ç­¹ï¼Œè€Œ LDM æ›´å¥½åœ°ä¿æŒäº†å‡ ä½•ä¸€è‡´æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. å®éªŒä»…åŸºäºå•ä¸€æ•°æ®é›†ï¼ˆCICIoT2023ï¼‰å’Œä¸‰ç§æ”»å‡»ç±»å‹ï¼Œ**æ³›åŒ–æ€§æœ‰å¾…è·¨æ•°æ®é›†éªŒè¯**ã€‚
2. å½“å‰è¯„ä¼°é™äº**äºŒåˆ†ç±»ä»»åŠ¡**ï¼Œæœªè€ƒè™‘å¤šç±»æ”»å‡»å…±å­˜çš„ç°å®å¤æ‚åœºæ™¯ã€‚
3. æ‰€æœ‰å¢å¼ºå‡åœ¨ç¦»çº¿é˜¶æ®µå®Œæˆï¼Œå°šæœªæ¢ç´¢åœ¨çº¿æˆ–å¢é‡å¼å¢å¼ºç­–ç•¥ã€‚
4. AE çš„é‡å»ºè¯¯å·®å¯èƒ½å¯¼è‡´æ½œåœ¨ç©ºé—´ä¿¡æ¯æŸå¤±ï¼Œå½±å“æœ€ç»ˆç”Ÿæˆè´¨é‡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³å¤šç±»åˆ« IDS åœºæ™¯**ï¼Œç ”ç©¶ LDM åœ¨å¤šæ ‡ç­¾æˆ–å¤šä»»åŠ¡æ£€æµ‹ä¸­çš„åº”ç”¨ã€‚
2. å¼€å±•**è·¨æ•°æ®é›†è¯„ä¼°**ï¼Œæ£€éªŒæ¨¡å‹åœ¨ä¸åŒç½‘ç»œç¯å¢ƒå’Œè®¾å¤‡é…ç½®ä¸‹çš„é²æ£’æ€§ã€‚
3. æ¢ç´¢**è½»é‡åŒ– LDM æ¶æ„**æˆ–åŠ é€Ÿæ¨ç†æŠ€æœ¯ï¼Œæ¨åŠ¨å…¶åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„å®æ—¶éƒ¨ç½²ã€‚
4. å¼•å…¥**å¢é‡å­¦ä¹ æœºåˆ¶**ï¼Œæ”¯æŒåŠ¨æ€æ–°å¢æ”»å‡»ç±»å‹çš„æŒç»­æ•°æ®ç”Ÿæˆã€‚
5. ç»“åˆ **Differential Privacy** æŠ€æœ¯ï¼Œå¼€å‘éšç§ä¿æŠ¤ç‰ˆæœ¬çš„ LDMï¼ˆå¦‚ DP-TLDMï¼‰ï¼Œé€‚ç”¨äºæ•æ„Ÿæ•°æ®åœºæ™¯ã€‚

--- 

> âœ… **æ€»ä½“è¯„ä»·**ï¼šæœ¬æ–‡æˆåŠŸå°†å›¾åƒé¢†åŸŸæˆåŠŸçš„ **Latent Diffusion Paradigm** æˆåŠŸè¿ç§»è‡³ IoT å®‰å…¨é¢†åŸŸçš„è¡¨æ ¼æ•°æ®ç”Ÿæˆä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ç§å…¼å…·é«˜æ€§èƒ½ã€é«˜ä¿çœŸä¸é«˜æ•ˆç‡çš„è§£å†³æ–¹æ¡ˆï¼Œä¸ºè§£å†³ ML-based IDS ä¸­çš„æ•°æ®ç¨€ç¼ºé—®é¢˜æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 13. [LLM is Not All You Need: A Systematic Evaluation of ML vs. Foundation Models for text and image based Medical Classification](https://arxiv.org/abs/2601.16549)

**Authors**: Meet Raval, Tejul Pandit, Dhvani Upadhyay  
**Category**: cs.AI  
**Published**: 2026-01-26  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.16549v1  

#### Abstract
The combination of multimodal Vision-Language Models (VLMs) and Large Language Models (LLMs) opens up new possibilities for medical classification. This work offers a rigorous, unified benchmark by using four publicly available datasets covering text and image modalities (binary and multiclass compl...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*LLM is Not All You Need: A Systematic Evaluation of ML vs. Foundation Models for text and image based Medical Classification*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰åœ¨åŒ»ç–—AIé¢†åŸŸï¼Œ**Large Language Models (LLMs)** å’Œ **Vision-Language Models (VLMs)** è¢«å¹¿æ³›è®¤ä¸ºæ˜¯ä¸‹ä¸€ä»£æ™ºèƒ½è¯Šæ–­ç³»ç»Ÿçš„æ ¸å¿ƒã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶å­˜åœ¨ä»¥ä¸‹ä¸‰å¤§ç¼ºé™·ï¼š
- **æ¨¡æ€éš”ç¦»**ï¼šå¤šæ•°ç ”ç©¶ä»…å…³æ³¨æ–‡æœ¬æˆ–å›¾åƒå•ä¸€æ¨¡æ€ï¼Œç¼ºä¹è·¨æ¨¡æ€ç»Ÿä¸€æ¯”è¾ƒã€‚
- **åŸºå‡†æµ‹è¯•ä¸ä¸¥è°¨**ï¼šç¼ºå°‘å¯¹ä¼ ç»Ÿæœºå™¨å­¦ä¹ ï¼ˆMLï¼‰ã€é›¶æ ·æœ¬LLM/VLMã€ä»¥åŠå‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æ¨¡å‹åœ¨åŒä¸€å®éªŒæ¡†æ¶ä¸‹çš„å…¬å¹³å¯¹æ¯”ã€‚
- **å¤šåˆ†ç±»ä»»åŠ¡è¢«ä½ä¼°**ï¼šå°¤å…¶åœ¨åŒ»å­¦å½±åƒä¸­ï¼Œå¤æ‚çš„å¤šç±»åˆ«åˆ†ç±»ï¼ˆmulticlassï¼‰ä»»åŠ¡ç ”ç©¶ä¸è¶³ã€‚

æœ¬è®ºæ–‡æ—¨åœ¨å¡«è¡¥è¿™äº›ç©ºç™½ï¼Œæä¾›ä¸€ä¸ª**ç³»ç»Ÿæ€§ã€å¯å¤ç°ã€è·¨æ¨¡æ€çš„å®è¯è¯„ä¼°æ¡†æ¶**ï¼Œä»¥å›ç­”ï¼š**åœ¨åŒ»ç–—åˆ†ç±»ä»»åŠ¡ä¸­ï¼ŒFoundation Models æ˜¯å¦çœŸçš„ä¼˜äºä¼ ç»Ÿ MLï¼Ÿ**

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
- æ„å»ºäº†ä¸€ä¸ª**å››ä»»åŠ¡ç»Ÿä¸€å®éªŒæ¡†æ¶**ï¼Œæ¶µç›–ï¼š
  - æ–‡æœ¬äºŒåˆ†ç±»ï¼ˆDiabetesï¼‰
  - æ–‡æœ¬å¤šåˆ†ç±»ï¼ˆMental Health Disordersï¼‰
  - å›¾åƒäºŒåˆ†ç±»ï¼ˆSkin Cancerï¼‰
  - å›¾åƒå¤šåˆ†ç±»ï¼ˆRespiratory Diseaseï¼‰
- åœ¨æ‰€æœ‰ä»»åŠ¡ä¸­é‡‡ç”¨**ä¸€è‡´çš„æ•°æ®åˆ’åˆ†ã€é¢„å¤„ç†æµç¨‹å’Œè¯„ä¼°æŒ‡æ ‡**ï¼Œå®ç°â€œapples-to-applesâ€æ¯”è¾ƒã€‚
- é¦–æ¬¡å°†ä¸‰ç±»ä¸»æµå»ºæ¨¡èŒƒå¼å¹¶åˆ—è¯„ä¼°ï¼š
  - **Classical ML**ï¼ˆå¦‚ Logistic Regression, LightGBM, ResNet-50ï¼‰
  - **Prompt-based LLM/VLM**ï¼ˆGemini 2.5 é›¶æ ·æœ¬æ¨ç†ï¼‰
  - **Fine-tuned PEFT Models**ï¼ˆLoRA å¾®è°ƒ Gemma3 å˜ä½“ï¼‰

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **å…¨é¢æ€§**ï¼šé¦–æ¬¡åœ¨åŒä¸€ç ”ç©¶ä¸­åŒæ—¶è¦†ç›–æ–‡æœ¬ä¸å›¾åƒã€äºŒåˆ†ç±»ä¸å¤šåˆ†ç±»ä»»åŠ¡ã€‚
- **ä¸¥è°¨æ€§**ï¼šä¸¥æ ¼æ§åˆ¶å˜é‡ï¼Œé¿å…å› æ•°æ®åˆ’åˆ†ã€æç¤ºå·¥ç¨‹å·®å¼‚å¯¼è‡´åå·®ã€‚
- **å®ç”¨æ€§å¯¼å‘**ï¼šèšç„¦ä¸´åºŠéƒ¨ç½²ä¸­çš„å¯é æ€§ã€æ•ˆç‡ä¸å®‰å…¨æ€§ï¼Œè€Œéå•çº¯è¿½æ±‚SOTAæ€§èƒ½ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†

| æ•°æ®é›† | æ¨¡æ€ | ä»»åŠ¡ç±»å‹ | ç±»åˆ«æ•° | æ ·æœ¬é‡ï¼ˆè®­ç»ƒ/éªŒè¯/æµ‹è¯•ï¼‰ |
|--------|------|----------|--------|---------------------------|
| **Diabetes** | Text | Binary | 2 | 2,214 / - / 554 |
| **Mental Health Disorders** | Text | Multiclass | 12 | 1,598 / - / 400 |
| **Skin Cancer (Segmented)** | Image | Binary | 2 | 1,687 / 422 / 528 |
| **Respiratory Disease** | Image | Multiclass | 5 | 560 / 80 / 160 |

> æ‰€æœ‰æ•°æ®é›†å‡ä¸ºå…¬å¼€å¯ç”¨ï¼Œç¡®ä¿å¯å¤ç°æ€§ã€‚

---

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### ç»Ÿä¸€è¯„ä¼°åè®®
- æ‰€æœ‰æ¨¡å‹ä½¿ç”¨ç›¸åŒçš„è®­ç»ƒ/æµ‹è¯•åˆ’åˆ†ã€‚
- è¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬ï¼š
  - **Accuracy**
  - **F1-Score**ï¼ˆå¤šåˆ†ç±»ä½¿ç”¨ weighted averageï¼‰
  - **ROC-AUC**ï¼ˆé€‚ç”¨äºäºŒåˆ†ç±»ï¼‰

#### æ¨¡å‹åˆ†ç±»ä¸é…ç½®
| æ¨¡å‹ç±»åˆ« | å…·ä½“æ¨¡å‹ | é…ç½®è¯´æ˜ |
|---------|--------|----------|
| **Classical ML** | Logistic Regression (LR), LightGBM | ç‰¹å¾æ ‡å‡†åŒ– + one-hotç¼–ç ï¼ˆæ–‡æœ¬ä»»åŠ¡ï¼‰ï¼›CNN/ResNet-50ç”¨äºå›¾åƒ |
| **Prompt-based LLM/VLM** | Gemini 2.5 Flash (text), Gemini 2.5 Multimodal (image) | Zero-shot æ¨ç†ï¼Œä¸¥æ ¼è®¾è®¡ prompt template ä¿è¯è¾“å‡ºä¸€è‡´æ€§ |
| **Fine-tuned PEFT Model** | Gemma3_Instruct_1B (text), Gemma3 4B-PT (vision) | ä½¿ç”¨ LoRA (r=4) å¾®è°ƒ1ä¸ªepochï¼Œç›¸åŒpromptç»“æ„ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **ä¼ ç»ŸMLåŸºçº¿**ï¼šä»£è¡¨æˆç†Ÿã€å¯è§£é‡Šã€é«˜æ•ˆçš„ç»å…¸æ–¹æ³•ã€‚
- **é›¶æ ·æœ¬LLM/VLM**ï¼šä½“ç°æ— éœ€è®­ç»ƒå³å¯è¿ç§»çŸ¥è¯†çš„èƒ½åŠ›ã€‚
- **LoRAå¾®è°ƒæ¨¡å‹**ï¼šä»£è¡¨å½“å‰æµè¡Œçš„å‚æ•°é«˜æ•ˆé€‚é…ç­–ç•¥ï¼ˆParameter-Efficient Fine-Tuning, PEFTï¼‰ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### âœ… è¡¨æ ¼ï¼šText Classification Test Set Results

| Task | Model | Accuracy | F1-Score | ROC-AUC |
|------|-------|----------|----------|---------|
| **Diabetes (Binary)** | LightGBM (ML) | **0.9982** | **0.9974** | **0.9992** |
| | Logistic Regression (ML) | 0.7726 | 0.6272 | 0.8355 |
| | Gemini 2.5 (Zero-Shot) | 0.4224 | 0.4576 | 0.4898 |
| | Gemma 1B (LoRA) | 0.6661 | 0.0887 | 0.5194 |
| **Mental Health (Multiclass)** | LightGBM (ML) | **0.9866** | **0.9821** | **0.9902** |
| | Logistic Regression (ML) | 0.9700 | 0.9655 | 0.9771 |
| | Gemini 2.5 (Zero-Shot) | 0.2807 | 0.2660 | N/A |
| | Gemma 1B (LoRA) | **0.0150** | **0.0004** | N/A |

> ğŸ’¡ ç»“è®ºï¼š**ä¼ ç»ŸMLåœ¨ç»“æ„åŒ–æ–‡æœ¬ä»»åŠ¡ä¸Šè¡¨ç°è¿‘ä¹å®Œç¾ï¼Œè€ŒLLMæ–¹æ³•ä¸¥é‡è½åï¼Œå°¤å…¶æ˜¯LoRAå¾®è°ƒæ¨¡å‹å‡ ä¹å®Œå…¨å¤±è´¥ã€‚**

---

#### âœ… è¡¨æ ¼ï¼šImage Classification Test Set Results

| Task | Model | Accuracy | F1-Score |
|------|-------|----------|----------|
| **Skin Cancer (Binary)** | CNN (ML Baseline) | **0.8277** | **0.8154** |
| | Gemini 2.5 (Zero-Shot) | 0.5890 | 0.3439 |
| | Gemma 3 4B-PT (LoRA) | 0.5455 | 0.2012 |
| **Respiratory Disease (Multiclass)** | ResNet-50 (ML Baseline) | 0.4812 | 0.4663 |
| | Gemini 2.5 (Zero-Shot) | **0.4875** | **0.4638** |
| | Gemma 3 4B-PT (LoRA) | 0.3688 | 0.2127 |

> ğŸ’¡ ç»“è®ºï¼š
> - åœ¨å›¾åƒäºŒåˆ†ç±»ä»»åŠ¡ä¸­ï¼Œ**CNNä»æ˜¾è‘—ä¼˜äºLLM/VLM**ï¼›
> - åœ¨å¤šåˆ†ç±»å›¾åƒä»»åŠ¡ä¸­ï¼Œ**é›¶æ ·æœ¬Gemini 2.5ä¸ResNet-50æ€§èƒ½ç›¸å½“**ï¼Œè¡¨ç°å‡ºç«äº‰åŠ›ï¼›
> - **LoRAå¾®è°ƒæ¨¡å‹åœ¨æ‰€æœ‰ä»»åŠ¡ä¸­è¡¨ç°æœ€å·®**ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆSensitivity Analysisï¼‰

ä¸ºæ¢ç©¶LoRAå¾®è°ƒå¤±è´¥åŸå› ï¼Œä½œè€…è¿›è¡Œäº†æ•æ„Ÿæ€§åˆ†æï¼ˆä»¥Diabetesä»»åŠ¡ä¸ºä¾‹ï¼‰ï¼š

#### ğŸ”¹ å½±å“LoRA Rankï¼ˆr=4 â†’ r=8ï¼‰
- **Accuracyä¸‹é™è‡³0.6606**
- **F1-Scoreæš´è·Œè‡³0.0693**
- è¡¨æ˜å¢åŠ å‚æ•°é‡å¹¶æœªæå‡æ€§èƒ½ï¼Œåè€Œå¯èƒ½å¼•å‘è¿‡æ‹Ÿåˆã€‚

#### ğŸ”¹ å¢åŠ è®­ç»ƒè½®æ¬¡ï¼ˆEpochsï¼‰
| Epochs | Accuracy | F1-Score | ROC-AUC |
|--------|----------|----------|---------|
| 1 | 0.6661 | 0.0887 | 0.5194 |
| 5 | 0.8141 | 0.7049 | 0.7738 |
| 10 | **0.8347** | **0.7152** | **0.7987** |

> âœ… å‘ç°ï¼š**å»¶é•¿è®­ç»ƒæ—¶é—´å¯æ˜¾è‘—æ”¹å–„LoRAæ¨¡å‹æ€§èƒ½**ï¼Œä½†å³ä½¿è®­ç»ƒ10è½®ä»æ— æ³•è¶…è¶ŠLightGBMï¼ˆ0.9982ï¼‰ï¼Œä¸”è¿œé«˜äºå¸¸è§„â€œé«˜æ•ˆå¾®è°ƒâ€çš„è®¡ç®—æˆæœ¬é¢„æœŸã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹ä»æ˜¯åŒ»ç–—åˆ†ç±»ä¸­æœ€å¯é çš„é€‰æ‹©**  
   å°¤å…¶åœ¨**ç»“æ„åŒ–æ–‡æœ¬æ•°æ®**ï¼ˆå¦‚ç”µå­ç—…å†ã€å®éªŒå®¤æŒ‡æ ‡ï¼‰ä¸Šï¼ŒLightGBM å’Œ Logistic Regression å®ç°äº†æ¥è¿‘å®Œç¾çš„åˆ†ç±»æ€§èƒ½ï¼Œè¿œè¶…ä»»ä½•LLMæ–¹æ¡ˆã€‚

2. **LLMåœ¨ç»“æ„åŒ–æ•°æ®ä¸Šçš„è¡¨ç°ä»¤äººå¤±æœ›**  
   å³ä½¿é€šè¿‡è‡ªç„¶è¯­è¨€æ ¼å¼è¾“å…¥ï¼Œ**é›¶æ ·æœ¬LLMï¼ˆGemini 2.5ï¼‰å‡†ç¡®ç‡ä»…ä¸º~0.42**ï¼Œç”šè‡³ä½äºéšæœºçŒœæµ‹æ°´å¹³ï¼ˆ0.5ï¼‰ã€‚è¿™è¡¨æ˜LLMéš¾ä»¥æœ‰æ•ˆè§£ææ•°å€¼å‹åŒ»å­¦ç‰¹å¾ä¹‹é—´çš„é€»è¾‘å…³ç³»ã€‚

3. **PEFTï¼ˆå¦‚LoRAï¼‰å¹¶éä¸‡èƒ½é’¥åŒ™ï¼Œæœ€å°åŒ–å¾®è°ƒå¯èƒ½é€‚å¾—å…¶å**  
   æ‰€æœ‰LoRAå¾®è°ƒæ¨¡å‹åœ¨å››é¡¹ä»»åŠ¡ä¸­å‡è¡¨ç°æœ€å·®ï¼Œè¯´æ˜**æçŸ­å‘¨æœŸï¼ˆ1 epochï¼‰çš„å¾®è°ƒä¸è¶³ä»¥å®Œæˆé¢†åŸŸé€‚åº”**ï¼Œåè€Œç ´ååŸå§‹æ¨¡å‹èƒ½åŠ›ã€‚

4. **é›¶æ ·æœ¬VLMåœ¨å¤æ‚å›¾åƒå¤šåˆ†ç±»ä»»åŠ¡ä¸­å±•ç°æ½œåŠ›**  
   åœ¨Respiratory Diseaseä»»åŠ¡ä¸­ï¼Œ**Gemini 2.5é›¶æ ·æœ¬æ€§èƒ½ä¸ResNet-50æŒå¹³ï¼ˆ~0.48ï¼‰**ï¼Œè¡¨æ˜VLMå…·å¤‡ä¸€å®šçš„è·¨ç±»åˆ«æ³›åŒ–èƒ½åŠ›ï¼Œå€¼å¾—è¿›ä¸€æ­¥æ¢ç´¢ã€‚

5. **Foundation Models å­˜åœ¨ä¸´åºŠéƒ¨ç½²é£é™©**  
   åŒ…æ‹¬ï¼š
   - **é«˜å»¶è¿Ÿä¸ç¢³è¶³è¿¹**
   - **æ¦‚ç‡æ ¡å‡†å·®**
   - **å¹»è§‰ï¼ˆhallucinationï¼‰ä¸æ ¼å¼é”™è¯¯è¾“å‡º**
   - **å¯¹å¦å®šè¯ç†è§£å›°éš¾**ï¼ˆå¦‚â€œno pneumoniaâ€æ˜“è¯¯åˆ¤ï¼‰

---

### æ–¹æ³•çš„å±€é™æ€§
- å®éªŒä»…åŸºäºå››ä¸ªå…¬å¼€å°è§„æ¨¡æ•°æ®é›†ï¼Œæœªæ¶µç›–æ›´å¤§è§„æ¨¡çœŸå®ä¸–ç•ŒEHRæˆ–DICOMæ•°æ®ã€‚
- æ‰€æœ‰LLMå®éªŒä¾èµ–APIè°ƒç”¨ï¼Œæ— æ³•æ·±å…¥åˆ†æå†…éƒ¨æ³¨æ„åŠ›æœºåˆ¶ã€‚
- LoRAå¾®è°ƒä»…å°è¯•å›ºå®šrankå’Œå°‘é‡epochsï¼Œæœªè¿›è¡Œå®Œæ•´è¶…å‚æœç´¢ã€‚
- ç¼ºä¹å¯¹æ¨ç†æˆæœ¬ï¼ˆlatency, energy consumptionï¼‰çš„é‡åŒ–å¯¹æ¯”ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **å¼€å‘æ›´é€‚åˆåŒ»ç–—ç»“æ„åŒ–æ•°æ®çš„LLMé€‚é…ç­–ç•¥**  
   å¦‚ç»“åˆ symbolic reasoning æˆ– rule injection çš„ hybrid æ¶æ„ã€‚

2. **ä¼˜åŒ–PEFTè®­ç»ƒç­–ç•¥**  
   æ¢ç´¢æ›´é•¿è®­ç»ƒå‘¨æœŸã€åŠ¨æ€rankè°ƒæ•´ã€è¯¾ç¨‹å­¦ä¹ ç­‰æ–¹æ³•æå‡å¾®è°ƒæ•ˆæœã€‚

3. **æ„å»ºç»Ÿä¸€çš„åŒ»ç–—å¤šæ¨¡æ€åŸºå‡†å¹³å°**  
   æ”¯æŒæ–‡æœ¬+å›¾åƒè”åˆæ¨ç†ä»»åŠ¡ï¼ˆå¦‚ radiology report generation + image classificationï¼‰ã€‚

4. **åŠ å¼ºå®‰å…¨æ€§å’Œå¯è§£é‡Šæ€§ç ”ç©¶**  
   å¼€å‘é’ˆå¯¹åŒ»ç–—åœºæ™¯çš„LLMè¾“å‡ºçº¦æŸæœºåˆ¶ã€ä¸ç¡®å®šæ€§ä¼°è®¡æ¨¡å—ã€‚

5. **æ¢ç´¢è½»é‡åŒ–LLMåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„éƒ¨ç½²å¯è¡Œæ€§**  
   å¹³è¡¡æ€§èƒ½ã€æˆæœ¬ä¸éšç§ä¿æŠ¤éœ€æ±‚ã€‚

---

> ğŸ“Œ **æœ€ç»ˆç»“è®º**ï¼š  
> â€œ**LLM is Not All You Need**â€ â€”â€” å°½ç®¡Foundation Modelså±•ç°äº†å¼ºå¤§çš„æ½œåŠ›ï¼Œä½†åœ¨è®¸å¤šç°å®åŒ»ç–—åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œ**ä¼ ç»Ÿæœºå™¨å­¦ä¹ ä»ç„¶æ˜¯æ›´é«˜æ•ˆã€ç¨³å®šã€å¯ä¿¡çš„é€‰æ‹©**ã€‚ç›²ç›®è¿½æ±‚æ•°å€¼å¤§æ¨¡å‹å¯èƒ½å¯¼è‡´èµ„æºæµªè´¹ä¸ä¸´åºŠé£é™©ã€‚æœªæ¥çš„æ–¹å‘åº”æ˜¯**èåˆè€Œéæ›¿ä»£**ï¼šå°†LLMä½œä¸ºè¾…åŠ©å·¥å…·ï¼Œä¸ç»å…¸MLååŒæ„å»ºç¨³å¥çš„åŒ»ç–—AIç³»ç»Ÿã€‚

</details>

---

### 14. [AgentsEval: Clinically Faithful Evaluation of Medical Imaging Reports via Multi-Agent Reasoning](https://arxiv.org/abs/2601.16685)

**Authors**: Suzhong Fu, Jingqi Dong, Xuan Ding, Rui Sun, Yiming Yang, Shuguang Cui, Zhen Li  
**Category**: cs.AI  
**Published**: 2026-01-26  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.16685v1  

#### Abstract
Evaluating the clinical correctness and reasoning fidelity of automatically generated medical imaging reports remains a critical yet unresolved challenge. Existing evaluation methods often fail to capture the structured diagnostic logic that underlies radiological interpretation, resulting in unreli...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šAgentsEval: Clinically Faithful Evaluation of Medical Imaging Reports via Multi-Agent Reasoning**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å½“å‰åŒ»å­¦å½±åƒæŠ¥å‘Šç”Ÿæˆç³»ç»Ÿï¼ˆå¦‚åŸºäºLLM/VLMçš„æ¨¡å‹ï¼‰è™½ç„¶åœ¨è¯­è¨€æµç•…æ€§å’Œé£æ ¼ä¸€è‡´æ€§ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†å…¶**ä¸´åºŠæ­£ç¡®æ€§**ï¼ˆclinical correctnessï¼‰å’Œ**æ¨ç†ä¿çœŸåº¦**ï¼ˆreasoning fidelityï¼‰ç¼ºä¹å¯é è¯„ä¼°ã€‚ä¼ ç»ŸNLGæŒ‡æ ‡ï¼ˆå¦‚BLEUã€ROUGEï¼‰ä»…è¡¡é‡è¯æ³•é‡å ï¼Œæ— æ³•åˆ¤æ–­è¯Šæ–­é€»è¾‘æ˜¯å¦å‡†ç¡®ï¼›è€Œå•ä»£ç†LLMè¯„ä¼°æ–¹æ³•å­˜åœ¨**æç¤ºæ•æ„Ÿæ€§å¼ºã€ç¨³å®šæ€§å·®ã€å¯è§£é‡Šæ€§ä½**ç­‰é—®é¢˜ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æå‡º **AgentsEval** â€”â€” ä¸€ç§**å¤šæ™ºèƒ½ä½“æµå¼æ¨ç†æ¡†æ¶**ï¼ˆmulti-agent stream reasoning frameworkï¼‰ï¼Œæ¨¡æ‹Ÿæ”¾å°„ç§‘åŒ»ç”Ÿçš„åä½œè¯Šæ–­æµç¨‹ï¼Œå°†è¯„ä¼°åˆ†è§£ä¸ºå¤šä¸ªå¯è§£é‡Šé˜¶æ®µï¼š
- **Base criteria pool generator**ï¼šæ„å»ºé€šç”¨ä¸´åºŠæ ‡å‡†æ± 
- **Criteria Identification Agent (Acrit)**ï¼šåŠ¨æ€è¯†åˆ«å½“å‰æŠ¥å‘Šçš„å…³é”®ä¸´åºŠæŒ‡æ ‡
- **GT Analyzer Agent (Agt)**ï¼šä»çœŸå®æŠ¥å‘Šä¸­æå–ç»“æ„åŒ–è¯æ®
- **Prediction Matcher Agent (Apred)**ï¼šä»ç”ŸæˆæŠ¥å‘Šä¸­åŒ¹é…å¯¹åº”å‘ç°
- **Evaluation Agent (Aeval)**ï¼šé€é¡¹æ‰“åˆ†å¹¶åŠ æƒæ±‡æ€»

è¯¥è¿‡ç¨‹äº§ç”Ÿ**æ˜¾å¼çš„æ¨ç†è½¨è¿¹**ï¼ˆexplicit reasoning tracesï¼‰ï¼Œæå‡é€æ˜åº¦ä¸å¯ä¿¡åº¦ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | AgentsEval |
|------|--------|-----------|
| **è¯­ä¹‰é²æ£’æ€§** | å¯¹åŒä¹‰æ”¹å†™æåº¦æ•æ„Ÿï¼ˆå¦‚A3å¯¼è‡´BLEUæš´è·Œï¼‰ | åœ¨åŒä¹‰æ”¹å†™ä¸‹ä¿æŒç¨³å®šè¯„åˆ† |
| **äº‹å®æ•æ„Ÿæ€§** | æ— æ³•åŒºåˆ†â€œsubtle lesionâ€ vs â€œsmall lesionâ€ç­‰è¯­ä¹‰åå·® | å¯æ£€æµ‹B1â€“B3çº§è¯­ä¹‰åç§»ï¼Œè¯„åˆ†éšé”™è¯¯ä¸¥é‡ç¨‹åº¦å•è°ƒä¸‹é™ |
| **å¯è§£é‡Šæ€§** | é»‘ç®±è¾“å‡ºå•ä¸€åˆ†æ•° | è¾“å‡ºç»“æ„åŒ–æ¯”å¯¹ç»“æœä¸ç»†ç²’åº¦å¾—åˆ† |
| **ä¸´åºŠå¯¹é½æ€§** | ä¸ä¸“å®¶åˆ¤æ–­ç›¸å…³æ€§å¼± | ä¸åŒ»å¸ˆæ ‡æ³¨è¯¯å·®é«˜åº¦ä¸€è‡´ï¼ˆSpearman > 0.92ï¼‰ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
å…±ä½¿ç”¨äº”ä¸ªå…¬å¼€åŒ»å­¦æŠ¥å‘Šæ•°æ®é›†ï¼Œè¦†ç›–å¤šç§æ¨¡æ€ä¸é¢†åŸŸï¼š

| æ•°æ®é›† | ç±»å‹ | æŠ¥å‘Šæ•°é‡ | ç‰¹ç‚¹ |
|-------|-----|---------|------|
| **CT-RATE** | èƒ¸éƒ¨CT | 100 | åŒ…å«Findingså’ŒImpressionèŠ‚æ®µ |
| **FFA-IR** | çœ¼åº•è§å…‰è¡€ç®¡é€ å½± | 100 | è‹±æ–‡æŠ¥å‘Šï¼Œæµ‹è¯•è·¨è¯­è¨€/é£æ ¼é²æ£’æ€§ |
| **MedVAL-Bench** | å¤šæ¨¡æ€ | 86 | åŒ»å¸ˆæ ‡æ³¨æ˜ç¡®çš„äº‹å®é”™è¯¯æ•° |
| **RadEvalX** | èƒ¸éƒ¨Xå…‰ | 100 | æ”¾å°„ç§‘åŒ»ç”Ÿåˆ†çº§æ ‡æ³¨é”™è¯¯ä¸¥é‡æ€§ï¼ˆæ˜¾è‘—/éæ˜¾è‘—ï¼‰ |
| **ReXErr-v1** | åˆæˆCXRæŠ¥å‘Š | 100 | å¼•å…¥3ç§å¯æ§ä¸´åºŠé”™è¯¯ç‰ˆæœ¬ï¼ˆ3-Errorï¼‰åŠA1â€“A3çº§åŒä¹‰æ”¹å†™ |

> âš ï¸ æ‰€æœ‰å®éªŒ**ä»…ä½¿ç”¨æ–‡æœ¬æŠ¥å‘Š**ï¼Œä¸ä¾èµ–å›¾åƒè¾“å…¥ï¼Œèšç„¦äºè¯­ä¹‰ä¸€è‡´æ€§è¯„ä¼°ã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**
- **æ‰°åŠ¨è®¾è®¡**ï¼š
  - **Aç³»åˆ—ï¼ˆåŒä¹‰æ”¹å†™ï¼‰**ï¼šA1ï¼ˆè½»åº¦ï¼‰ã€A2ï¼ˆä¸­åº¦ï¼‰ã€A3ï¼ˆé‡åº¦ï¼‰
  - **Bç³»åˆ—ï¼ˆè¯­ä¹‰åç§»ï¼‰**ï¼šB1ï¼ˆè½»å¾®ï¼‰ã€B2ï¼ˆä¸­ç­‰ï¼‰ã€B3ï¼ˆä¸¥é‡ï¼‰
- **è¯„ä¼°æ–¹å¼**ï¼š
  - è®¡ç®—å„æ–¹æ³•åœ¨æ¯ç»„æ‰°åŠ¨ä¸‹çš„å¹³å‡å¾—åˆ†
  - åˆ†æè¯„åˆ†è¶‹åŠ¿æ˜¯å¦ä¸ä¸´åºŠé”™è¯¯ä¸¥é‡æ€§**å•è°ƒç›¸å…³**
  - ä½¿ç”¨ **Spearmanç›¸å…³ç³»æ•°** å’Œ **DTWï¼ˆDynamic Time Warpingï¼‰è·ç¦»** è¡¡é‡ä¸äººç±»æ ‡æ³¨çš„ä¸€è‡´æ€§

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| ç±»åˆ« | æ–¹æ³• |
|------|------|
| **ä¼ ç»ŸNLGæŒ‡æ ‡** | BLEU, ROUGE-1, METEOR, CHRF, Bert-Score |
| **å•ä»£ç†LLMè¯„ä¼°** |  
| - Single-Agent (detailed) | ç»“æ„åŒ–æç¤ºï¼Œè¦æ±‚é€æ­¥æ¨ç† |
| - Single-Agent (simple) | ç®€æ´æç¤ºï¼Œç›´æ¥è¯„åˆ†ç›¸ä¼¼æ€§ |

æ‰€æœ‰AgentsEvalæ¨¡å—å‡åŸºäº **DeepSeek-V3.2 (685B)** å®ç°ï¼ŒAPIè°ƒç”¨æ¸©åº¦è®¾ä¸º0.05ä»¥ç¡®ä¿å¯å¤ç°æ€§ã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… åœ¨CT-RATEä¸Šçš„è¡¨ç°ï¼ˆè§Table 1ï¼‰
| ç‰ˆæœ¬ | BLEU | ROUGE-1 | Bert-Score | **AgentsEval** |
|------|------|----------|------------|----------------|
| F-A1 | 23.8 | 65.6 | 92.8 | **97.0** |
| F-A3 | 8.0 | 49.4 | 89.2 | **96.5**ï¼ˆå‡ ä¹æ— æŸï¼‰ |
| F-B3 | 39.7 | 64.7 | 92.2 | **10.6**ï¼ˆæ˜¾è‘—ä¸‹é™ï¼‰ |

> ğŸ“Œ **AgentsEvalåœ¨A3ä¸‹ä»…é™0.5åˆ†ï¼Œè€ŒBLEUé™å¹…è¾¾66%ï¼›åœ¨B3ä¸‹æ­£ç¡®åæ˜ ä¸¥é‡é”™è¯¯**

#### âœ… åœ¨FFA-IRä¸Šçš„ç¨³å¥æ€§ï¼ˆTable 2ï¼‰
| Version | BLEU | Bert-Score | **AgentsEval** |
|--------|------|-------------|----------------|
| A3 | 14.1 | 90.6 | **78.2** |
| B3 | 31.6 | 92.3 | **15.3** |

> ğŸ“Œ æ˜¾ç¤ºAgentsEvalåœ¨ä¸åŒæ¨¡æ€ä¸‹å‡å…·å¤‡å¼ºé²æ£’æ€§ä¸é«˜æ•æ„Ÿæ€§

#### âœ… ä¸äººç±»æ ‡æ³¨çš„ç›¸å…³æ€§ï¼ˆTable 3ï¼‰
| Metric | Spearman (MedVAL) | DTW (MedVAL) | Spearman (RadEvalX) | DTW (RadEvalX) |
|--------|--------------------|---------------|----------------------|------------------|
| BLEU | 0.339 | 7.636 | 0.170 | 8.155 |
| Bert-Score | 0.782 | 1.180 | 0.789 | 0.909 |
| **AgentsEval** | **0.933** | **0.846** | **0.927** | **1.867** |

> ğŸ“Œ **AgentsEvalåœ¨Spearmanä¸Šå…¨é¢é¢†å…ˆï¼Œå°¤å…¶ä¼˜äºä¼ ç»ŸæŒ‡æ ‡**

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- **ä¼ ç»ŸæŒ‡æ ‡**ï¼šåœ¨Aç±»æ”¹å†™ä¸‹å‰§çƒˆæ³¢åŠ¨ï¼Œåœ¨Bç±»é”™è¯¯ä¸­ç”šè‡³å‡ºç°â€œé”™è¯¯æŠ¥å‘Šå¾—åˆ†æ›´é«˜â€çš„åå¸¸ç°è±¡
- **Bert-Score**ï¼šè™½è¾ƒè€æ”¹å†™ï¼Œä½†ä»éš¾ä»¥åŒºåˆ†B2/B3çº§äº‹å®é”™è¯¯
- **Single-Agent (detailed)**ï¼šæœ‰ä¸€å®šåˆ¤åˆ«èƒ½åŠ›ï¼Œä½†æ–¹å·®è¾ƒå¤§ï¼Œç¨³å®šæ€§ä¸å¦‚AgentsEval
- **AgentsEval**ï¼šå®ç°**é«˜é²æ£’æ€§ + é«˜æ•æ„Ÿæ€§ + å•è°ƒå“åº”**ï¼Œæœ€è´´è¿‘ä¸´åºŠç°å®

### **æ¶ˆèå®éªŒç»“æœï¼ˆéšå«åˆ†æï¼‰**
- **æ¨¡å‹è§„æ¨¡å½±å“**ï¼ˆFigure 6ï¼‰ï¼š
  - å°æ¨¡å‹ï¼ˆQwen3-0.6Bï¼‰æ— æ³•æœ‰æ•ˆåŒºåˆ†A/Bç±»å˜åŒ–
  - å¤§æ¨¡å‹ï¼ˆâ‰¥32Bå‚æ•°ï¼‰è¾¾åˆ°é¥±å’Œæ€§èƒ½ï¼Œè¯´æ˜**è¶³å¤Ÿæ¨ç†èƒ½åŠ›æ˜¯å‰æ**
- **å¤šæ™ºèƒ½ä½“åä½œä¼˜åŠ¿**ï¼š
  - ç›¸æ¯”Single-Agentï¼ŒAgentsEvalå…·æœ‰æ›´å¹³æ»‘ã€æ›´ä¸€è‡´çš„è¶‹åŠ¿æ›²çº¿ï¼ŒéªŒè¯äº†**æ¨¡å—åŒ–è§£è€¦å¸¦æ¥çš„ç¨³å®šæ€§å¢ç›Š**

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **ä¼ ç»ŸNLGæŒ‡æ ‡ä¸¥é‡åç¦»ä¸´åºŠéœ€æ±‚**ï¼šé«˜BLEU/ROUGEå¯èƒ½æ©ç›–é‡å¤§è¯Šæ–­é”™è¯¯ã€‚
2. **AgentsEvalå®ç°äº†ä¸´åºŠå¯¹é½çš„è¯„ä¼°èŒƒå¼è½¬å˜**ï¼š
   - ä¸å†ä¾èµ–è¡¨é¢ç›¸ä¼¼æ€§ï¼Œè€Œæ˜¯é€šè¿‡ç»“æ„åŒ–æ¨ç†åˆ¤æ–­**è¯Šæ–­é€»è¾‘ä¸€è‡´æ€§**
   - æä¾›**å¯å®¡è®¡çš„ä¸­é—´è¾“å‡º**ï¼Œæ”¯æŒäººå·¥å®¡æŸ¥ä¸æ¨¡å‹è°ƒè¯•
3. **å¤šæ™ºèƒ½ä½“æ¶æ„æ˜¾è‘—æå‡è¯„ä¼°è´¨é‡**ï¼š
   - æ¨¡å—åŒ–åˆ†å·¥å¢å¼ºç¨³å®šæ€§ä¸å¯è§£é‡Šæ€§
   - æ¨ç†é“¾æ˜¾å¼æš´éœ²é”™è¯¯æ¥æºï¼ˆå¦‚æ¼è¯Šã€è¯¯åˆ¤ã€çŸ›ç›¾é™ˆè¿°ï¼‰
4. **å¤§æ¨¡å‹è§„æ¨¡æ˜¯ä¿éšœè¯­ä¹‰ç†è§£çš„åŸºç¡€**ï¼šå°äº32Bçš„æ¨¡å‹éš¾ä»¥èƒœä»»å¤æ‚åŒ»å­¦è¯­ä¹‰è§£æä»»åŠ¡

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–å¤§å‹åŸºç¡€æ¨¡å‹**ï¼šè®¡ç®—æˆæœ¬é«˜ï¼Œä¸åˆ©äºè½»é‡åŒ–éƒ¨ç½²
- **ä»ä¸ºæ–‡æœ¬é©±åŠ¨**ï¼šæœªç»“åˆå›¾åƒè¿›è¡Œè§†è§‰æ¥åœ°ï¼ˆimage-grounded feedbackï¼‰
- **æ½œåœ¨åè§é£é™©**ï¼šè®­ç»ƒæ•°æ®ä¸­çš„ç³»ç»Ÿæ€§åå·®å¯èƒ½è¢«ç»§æ‰¿
- **è‡ªåŠ¨åŒ–ç¨‹åº¦æœ‰é™**ï¼šç›®å‰ä¸ºé¡ºåºæ¨ç†ï¼Œå°šæœªå®ç°åé¦ˆé—­ç¯ä¼˜åŒ–

### **æœªæ¥å·¥ä½œæ–¹å‘**
- å¼€å‘**é«˜æ•ˆå¹¶è¡Œæ¨ç†æœºåˆ¶**ä¸**è½»é‡çº§æ¨¡å‹è’¸é¦æ–¹æ¡ˆ**
- æ‰©å±•è‡³**å¤šæ¨¡æ€è¯„ä¼°**ï¼Œæ•´åˆè§†è§‰è¯æ®è¿›è¡Œè”åˆéªŒè¯
- æ„å»º**agent feedback loop**ï¼Œç”¨äºæŒ‡å¯¼æŠ¥å‘Šç”Ÿæˆæ¨¡å‹è¿­ä»£ä¼˜åŒ–
- æ¢ç´¢**human-in-the-loop**æœºåˆ¶ï¼ŒæŒç»­æ ¡å‡†è¯„ä¼°æ ‡å‡†éšåŒ»å­¦è¿›å±•æ¼”è¿›

---

> ğŸ”š **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **AgentsEvalé¦–æ¬¡å°†æ”¾å°„ç§‘åŒ»ç”Ÿçš„è¯Šæ–­æ€ç»´è½¬åŒ–ä¸ºå¯è®¡ç®—çš„å¤šæ™ºèƒ½ä½“è¯„ä¼°æµç¨‹ï¼Œåœ¨ä¿æŒè¯­è¨€å¤šæ ·æ€§å®¹å¿åº¦çš„åŒæ—¶ç²¾å‡†æ•æ‰ä¸´åºŠé”™è¯¯ï¼Œæ¨åŠ¨åŒ»å­¦AIè¯„ä¼°è¿ˆå‘é€æ˜ã€å¯ä¿¡ã€ä¸´åºŠå¯ç”¨çš„æ–°é˜¶æ®µã€‚**

</details>

---

### 15. [The Art of Being Difficult: Combining Human and AI Strengths to Find Adversarial Instances for Heuristics](https://arxiv.org/abs/2601.16849)

**Authors**: Henri Nikoleit, Ankit Anand, Anurag Murty Naredla, Heiko R\"oglin  
**Category**: cs.LG  
**Published**: 2026-01-26  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.16849v1  

#### Abstract
We demonstrate the power of human-LLM collaboration in tackling open problems in theoretical computer science. Focusing on combinatorial optimization, we refine outputs from the FunSearch algorithm [Romera-Paredes et al., Nature 2023] to derive state-of-the-art lower bounds for standard heuristics. ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*The Art of Being Difficult: Combining Human and AI Strengths to Find Adversarial Instances for Heuristics*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
è¯¥è®ºæ–‡è‡´åŠ›äºè§£å†³**ç»„åˆä¼˜åŒ–é—®é¢˜ä¸­å¯å‘å¼ç®—æ³•çš„æœ€åæƒ…å†µåˆ†æ**è¿™ä¸€é•¿æœŸå¼€æ”¾é—®é¢˜ã€‚å…·ä½“è€Œè¨€ï¼Œç ”ç©¶è€…æ—¨åœ¨ä¸ºç»å…¸å¯å‘å¼ç®—æ³•æ„é€ **å¯¹æŠ—å®ä¾‹ï¼ˆadversarial instancesï¼‰**ï¼Œä»¥æ­ç¤ºå…¶åœ¨æç«¯æƒ…å†µä¸‹çš„æ€§èƒ½ä¸‹é™ï¼ˆlower boundsï¼‰ï¼Œä»è€ŒæŒ‘æˆ˜å¹¶æ”¹è¿›å¯¹è¿™äº›ç®—æ³•çš„ç†è§£ã€‚

è®¸å¤šå¯å‘å¼ç®—æ³•ï¼ˆå¦‚ Best-Fitã€Nemhauser-Ullmannï¼‰è™½ç„¶åœ¨å®è·µä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†å…¶ç†è®ºæ€§èƒ½è¾¹ç•Œï¼ˆå°¤å…¶æ˜¯ä¸‹ç•Œï¼‰å¤šå¹´æœªè¢«æ˜¾è‘—çªç ´ã€‚ä¼ ç»Ÿæœç´¢æ–¹æ³•ï¼ˆå¦‚ local searchï¼‰éš¾ä»¥ç”Ÿæˆå…·æœ‰ç»“æ„æ€§æ´è§çš„å¤æ‚å®ä¾‹ã€‚

---

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
è®ºæ–‡æå‡ºäº†åä¸º **Co-FunSearch**ï¼ˆCollaborative FunSearchï¼‰çš„æ–°æ¡†æ¶ï¼Œç»“åˆäº† **Large Language Models (LLMs)** ä¸ **äººç±»ä¸“å®¶åä½œ** æ¥è¿›åŒ–ç”Ÿæˆå¯¹æŠ—ç¨‹åºã€‚

- **æ ¸å¿ƒæ€æƒ³**ï¼šå°†æ¯ä¸ªé—®é¢˜å®ä¾‹ç¼–ç ä¸ºä¸€ä¸ªå¯æ‰§è¡Œçš„ Python ç¨‹åº `P`ï¼Œå…¶è¾“å‡ºæ˜¯å…·ä½“çš„è¾“å…¥å‘é‡ï¼ˆå¦‚ç‰©å“åˆ—è¡¨ã€ç‚¹é›†ç­‰ï¼‰ã€‚ç›®æ ‡æ˜¯é€šè¿‡æ¼”åŒ–è¿™äº›ç¨‹åºæ¥æœ€å¤§åŒ–æŸä¸ªâ€œå¾—åˆ†â€å‡½æ•°ï¼ˆå³å¯å‘å¼ä¸æœ€ä¼˜è§£ä¹‹é—´çš„å·®è·ï¼‰ã€‚
- **æµç¨‹**ï¼š
  1. ä½¿ç”¨ LLMï¼ˆåŸºäº FunSearch èŒƒå¼ï¼‰ä»åˆå§‹ç¨‹åºå‡ºå‘ï¼Œè¿­ä»£ç”Ÿæˆæ”¹è¿›ç‰ˆæœ¬ï¼›
  2. äººç±»ä¸“å®¶åˆ†æç”Ÿæˆçš„ç¨‹åºï¼Œè¯†åˆ«æ¨¡å¼ã€ç®€åŒ–é€»è¾‘ã€å»é™¤å†—ä½™ã€æ¨å¹¿ç»“æ„ï¼›
  3. å°†ç®€åŒ–åçš„ç¨‹åºé‡æ–°æ³¨å…¥æœç´¢å¾ªç¯ï¼Œå½¢æˆæ­£åé¦ˆé—­ç¯ã€‚

è¿™ç§æ–¹æ³•ä¸åŒäºä¼ ç»Ÿçš„é»‘ç®±ä¼˜åŒ–ï¼ˆå¦‚é—ä¼ ç®—æ³•ã€æ¨¡æ‹Ÿé€€ç«ï¼‰ï¼Œè€Œæ˜¯åˆ©ç”¨ LLM ç”Ÿæˆ**å¯è§£é‡Šã€å¯æ³›åŒ–ã€ç»“æ„åŒ–çš„ä»£ç **ä½œä¸ºä¸­é—´è¡¨ç¤ºã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | å±€é™æ€§ | Co-FunSearch çš„ä¼˜åŠ¿ |
|------|--------|---------------------|
| **Local Search / Tabu Search** | æœç´¢ç©ºé—´ä¸ºåŸå§‹å‘é‡ï¼Œç»“æœä¸å¯è¯»ï¼Œç¼ºä¹ç»“æ„æ´è§ï¼Œæ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ | ä»¥ç¨‹åºä¸ºå•ä½è¿›è¡Œæœç´¢ï¼Œå¤©ç„¶æ”¯æŒæ³›åŒ–ä¸ç¼©æ”¾ï¼›ç”Ÿæˆçš„ç»“æœå…·æœ‰æ•°å­¦ç»“æ„ï¼Œä¾¿äºäººç±»ç†è§£ä¸è¯æ˜ |
| **çº¯ FunSearchï¼ˆæ— åä½œï¼‰** | LLM å¯èƒ½ç”Ÿæˆç¡¬ç¼–ç å¸¸æ•°ã€å†—ä½™ç»“æ„ï¼Œéš¾ä»¥ç›´æ¥ç”¨äºç†è®ºæ¨å¯¼ | äººç±»ä»‹å…¥å¯æç‚¼å‡ºç®€æ´é€šç”¨çš„æ„é€ æ¨¡æ¿ï¼Œå¹¶è¿›ä¸€æ­¥æå‡æ€§èƒ½ |
| **æ‰‹å·¥æ„é€ ** | æå…¶è€—æ—¶ä¸”ä¾èµ–ç›´è§‰ï¼Œè¿›å±•ç¼“æ…¢ï¼ˆéƒ¨åˆ†é—®é¢˜åå¹´æ— è¿›å±•ï¼‰ | LLM æä¾›åˆ›é€ æ€§èµ·ç‚¹ï¼Œäººç±»æä¾›ä¸¥è°¨æ€§ä¸æŠ½è±¡èƒ½åŠ›ï¼Œå®ç°â€œ1+1 > 2â€çš„ååŒæ•ˆåº” |

> âœ… **å…³é”®åˆ›æ–°**ï¼šé¦–æ¬¡ç³»ç»Ÿå±•ç¤º **Human-LLM åä½œ** åœ¨ç†è®ºè®¡ç®—æœºç§‘å­¦ç ”ç©¶ä¸­çš„å¼ºå¤§æ½œåŠ›â€”â€”ä¸ä»…åŠ é€Ÿå‘ç°ï¼Œè¿˜èƒ½æ¨åŠ¨ä¸¥æ ¼æ•°å­¦ç»“è®ºçš„å»ºç«‹ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„é—®é¢˜ä¸é¢†åŸŸï¼ˆç›¸å½“äºâ€œæ•°æ®é›†â€ï¼‰
æœ¬ç ”ç©¶å¹¶æœªä½¿ç”¨ä¼ ç»Ÿæ„ä¹‰ä¸Šçš„â€œæ•°æ®é›†â€ï¼Œè€Œæ˜¯åœ¨ä»¥ä¸‹å››ä¸ªç»å…¸çš„ **ç»„åˆä¼˜åŒ–é—®é¢˜** ä¸Šæ„å»ºå¯¹æŠ—å®ä¾‹ï¼š

| é—®é¢˜ | å¯å‘å¼ç®—æ³• | ç›®æ ‡ |
|------|------------|------|
| **Knapsack Problem** | Nemhauser-Ullmann Heuristic | æ„é€ ä½¿ä¸­é—´ Pareto é›†è¿œå¤§äºæœ€ç»ˆ Pareto é›†çš„å®ä¾‹ |
| **Bin Packing** | Best-Fit Heuristic (Random Order Model) | æé«˜æœŸæœ›ä½¿ç”¨çš„ç®±å­æ•°ç›¸å¯¹äºæœ€ä¼˜å€¼çš„æ¯”ä¾‹ |
| **Hierarchical Clustering** | k-median Objective | æ„é€ ä»»æ„å±‚æ¬¡èšç±»éƒ½æ— æ³•æ¥è¿‘éå±‚æ¬¡æœ€ä¼˜çš„å®ä¾‹ |
| **Generalized Gasoline Problem** | Iterative Rounding Algorithm | æ‰¾åˆ°è¿‘ä¼¼æ¯”è¶…è¿‡ 2 çš„åä¾‹ï¼Œæ‰“ç ´çŒœæƒ³ |

è¿™äº›é—®é¢˜å‡å±äº **NP-hard**ï¼Œä¸”åœ¨ç†è®ºç•Œæœ‰é•¿æœŸå…³æ³¨ä½†è¿›å±•åœæ»ã€‚

---

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### å…±åŒèŒƒå¼
- æ¯ä¸ªå®ä¾‹ç”±ä¸€ä¸ª Python å‡½æ•° `get_instance()` è¾“å‡ºã€‚
- **è¯„åˆ†å‡½æ•°ï¼ˆScore Functionï¼‰** å®šä¹‰ä¸ºï¼š
  $$
  R = \frac{\text{Score}(H(I))}{\text{Score}(\text{Opt}(I))}
  $$
  å…¶ä¸­ $H$ æ˜¯å¯å‘å¼ç®—æ³•ï¼Œ$\text{Opt}$ æ˜¯æœ€ä¼˜è§£ï¼Œç›®æ ‡æ˜¯æœ€å¤§åŒ– $R$ï¼ˆæœ€å°åŒ–é—®é¢˜ï¼‰æˆ–å…¶å€’æ•°ï¼ˆæœ€å¤§åŒ–é—®é¢˜ï¼‰ã€‚

#### å…·ä½“è®¾ç½®
| ç»„ä»¶ | è®¾ç½®è¯´æ˜ |
|------|----------|
| **LLM æ¨¡å‹** | ä½¿ç”¨ `gpt-4.1-nano`, `gpt-4.1-mini`, `open-mistral-nemo` è¿›è¡Œæ¯”è¾ƒ |
| **æ¸©åº¦å‚æ•°** | è®¾ä¸º 1.0â€“1.5ï¼Œé¼“åŠ±å¤šæ ·æ€§ |
| **æœç´¢é¢„ç®—** | æœ€å¤š 10 è½® Ã— æ•°åƒæ¬¡é‡‡æ ·ï¼ˆLLM æŸ¥è¯¢ï¼‰ |
| **æ‰§è¡Œå¹³å°** | è‡ªå®šä¹‰æ¼”åŒ–æ¡†æ¶ï¼Œé›†æˆ LLM APIã€ç¨‹åºæ‰§è¡Œã€é”™è¯¯å¤„ç†ä¸æ•°æ®åº“å­˜å‚¨ |
| **äººç±»å¹²é¢„ç¯èŠ‚** | æ‰‹åŠ¨ç®€åŒ–ç¨‹åºç»“æ„ã€æå–å‚æ•°åŒ–å½¢å¼ã€å°è¯•æ•°å­¦å½’çº³ä¸è¯æ˜ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿æ–¹æ³• | æè¿° |
|---------|------|
| **Local Search** | åœ¨å‘é‡ç©ºé—´æ·»åŠ å™ªå£°è¿›è¡Œé‚»åŸŸæœç´¢ï¼Œä»£è¡¨ä¼ ç»Ÿå…ƒå¯å‘å¼ |
| **Base FunSearch** | ä¸åŠ äººå·¥å¹²é¢„çš„æ ‡å‡† FunSearch æµç¨‹ |
| **Previous SOTA** | æ–‡çŒ®ä¸­å·²çŸ¥çš„æœ€ä½³ä¸‹ç•Œæ„é€ ï¼ˆå¦‚ Albers et al., 2021ï¼‰ |
| **Trivial Instance** | åˆå§‹ç®€å•æ„é€ ï¼ˆå¦‚ `[0.4, 0.5, 0.6]`ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| Method | Knapsack | Bin-Packing | k-median | Gasoline |
|-------|---------|-------------|----------|----------|
| Previous Best Known Lower Bound | 2.0 | 1.3 | 1.0 | 2.0 |
| Local Search | 1.93 | 1.478 | 1.36 | 2.11 |
| FunSearch | 646.92 | 1.497 | 1.538 | 3.05 |
| **Co-FunSearch** | **n^{O(âˆšn)}** | **1.5** | **1.618 (golden ratio)** | **4.65** |
| Known Upper Bound | O(2^n) | 1.7 | 16 | None |

> ğŸ“ˆ æ‰€æœ‰é—®é¢˜ä¸Šï¼Œ**Co-FunSearch æ˜¾è‘—è¶…è¶Šæ‰€æœ‰åŸºçº¿**ï¼Œå¹¶åœ¨å¤šä¸ªé—®é¢˜ä¸Šå–å¾—**åå¹´æ¥é¦–æ¬¡å®è´¨æ€§çªç ´**ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### âœ… **Knapsack Problem**
- **æˆæœ**ï¼šæ„é€ å‡ºä½¿å¾— Nemhauser-Ullmann ç®—æ³•è¿è¡Œæ—¶é—´å‘ˆè¶…å¤šé¡¹å¼çš„å®ä¾‹ã€‚
- **æ„ä¹‰**ï¼š**é¦–æ¬¡è¯æ˜è¯¥ç®—æ³•ä¸å…·å¤‡ output-polynomial æ—¶é—´å¤æ‚åº¦**ï¼Œè§£å†³äº†é•¿æœŸæ‚¬è€Œæœªå†³çš„é—®é¢˜ã€‚
- **åç»­**ï¼šç‹¬ç«‹å‘ç°äº†æŒ‡æ•°çº§ä¸‹ç•Œï¼ˆè§ Nikoleit, 2025ï¼‰ï¼Œä¹Ÿç”± Co-FunSearch è¾…åŠ©éªŒè¯ã€‚

#### âœ… **Bin Packing (Best-Fit)**
- **æˆæœ**ï¼šå°†éšæœºé¡ºåºæ¨¡å‹ä¸‹çš„ç»å¯¹è¿‘ä¼¼æ¯”ä¸‹ç•Œä» **1.3 â†’ 1.5**ã€‚
- **æ„é€ **ï¼šè®¾è®¡ä¸¤ç»„å¤§å°åˆ†åˆ«ä¸º $m$ å’Œ $m+1$ çš„ç‰©å“ï¼Œåœ¨å®¹é‡ä¸º $m(m+1)$ çš„ç®±å­ä¸­ï¼Œåªæœ‰å½“åŒç±»ç‰©å“åˆ†å¼€è£…ç®±æ‰æœ€ä¼˜ï¼›ä½† Best-Fit å¾ˆå¯èƒ½æ··è£…å¯¼è‡´æµªè´¹ã€‚
- **ç»“è®º**ï¼šTheorem 3.2 æˆç«‹ï¼š
  > *The absolute random-order ratio of Best-Fit is between 1.5 and 1.7.*

#### âœ… **Hierarchical k-median Clustering**
- **æˆæœ**ï¼šè·å¾—é¦–ä¸ªéå¹³å‡¡çš„ **Price of Hierarchy** ä¸‹ç•Œï¼š**é»„é‡‘æ¯”ä¾‹ â‰ˆ 1.618**ã€‚
- **æ„é€ **ï¼šåˆ©ç”¨é«˜ç»´ç©ºé—´ä¸­å¸¦æƒé‡ç‚¹çš„å‡ ä½•é…ç½®ï¼Œå¼ºåˆ¶å±‚æ¬¡èšç±»åœ¨æŸä¸€å±‚å¿…é¡»åˆå¹¶å…³é”®ç‚¹ï¼Œå¯¼è‡´æˆæœ¬å‰§å¢ã€‚
- **æ„ä¹‰**ï¼šæ­¤å‰æ²¡æœ‰ä»»ä½•éå¹³å‡¡ä¸‹ç•Œï¼Œä¸Šç•Œä¸º 16ï¼Œç°å°†å·®è·ç¼©å°ã€‚

#### âœ… **Generalized Gasoline Problem**
- **æˆæœ**ï¼šæ„é€ å‡ºè¿­ä»£èˆå…¥ç®—æ³•ï¼ˆiterative roundingï¼‰è¿‘ä¼¼æ¯”é«˜è¾¾ **4.65** çš„å®ä¾‹ï¼ˆd=3, k=5ï¼‰ï¼Œ**å½»åº•å¦å®šå…¶ä¸º 2-è¿‘ä¼¼ç®—æ³•çš„çŒœæƒ³**ã€‚
- **æ‰©å±•æ€§**ï¼šåŸé—®é¢˜åœ¨ä¸€ç»´å·²è¢«ç ”ç©¶ï¼Œæœ¬æ–‡æˆåŠŸå°†å…¶æ¨å¹¿è‡³äºŒç»´åŠä»¥ä¸Šï¼Œå¹¶å‘ç°æ›´å·®è¡¨ç°ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰ä¸åŒ LLM æ¨¡å‹çš„å½±å“ï¼ˆFig. 3a-bï¼‰
- æ›´å°çš„æ¨¡å‹ `gpt-4.1-nano` åœ¨**æœ€å¤§å¾—åˆ†**ä¸Šç•¥ä¼˜äºæ›´å¤§çš„ `gpt-4.1-mini`ã€‚
- åŸå› ï¼šå¤§æ¨¡å‹å¹³å‡æ€§èƒ½æ›´å¥½ï¼ˆç§»åŠ¨å¹³å‡æ›´é«˜ï¼‰ï¼Œä½†å°æ¨¡å‹äº§ç”Ÿæ›´å¤šâ€œå¹¸è¿çªå˜â€ï¼Œé€‚åˆè¿½æ±‚**æœ€ä½³æ ·æœ¬**çš„ä»»åŠ¡ã€‚
> ğŸ’¡ ç»“è®ºï¼šå¯¹äºå¯éªŒè¯ç›®æ ‡ï¼ˆverifiable objectivesï¼‰ï¼Œ**ä¸ä¸€å®šéœ€è¦æœ€å¼ºæ¨¡å‹**ã€‚

#### ï¼ˆ2ï¼‰æ¸©åº¦å‚æ•°å½±å“ï¼ˆFig. 3cï¼‰
- **é«˜æ¸©ï¼ˆhigh temperatureï¼‰æ•ˆæœæ›´å¥½**ï¼Œå› ä¸ºå¢åŠ äº†è¾“å‡ºå¤šæ ·æ€§ï¼Œæœ‰åŠ©äºè·³å‡ºå±€éƒ¨é™·é˜±ã€‚
- å°½ç®¡å¹³å‡è´¨é‡ä¸‹é™ï¼Œä½†**æœ€é«˜åˆ†æŒç»­ä¸Šå‡**ï¼Œè¯´æ˜æ¢ç´¢æ¯”å¼€å‘æ›´é‡è¦ã€‚

#### ï¼ˆ3ï¼‰åˆå§‹ç¨‹åºç»“æ„çš„é‡è¦æ€§ï¼ˆFig. 3dï¼‰
- **ç»“æ„åŒ–åˆå§‹ç¨‹åº**ï¼ˆå¦‚å«å¾ªç¯ï¼‰è™½èµ·å§‹å¾—åˆ†ä½ï¼Œä½†èƒ½æŒç»­æ”¹è¿›ï¼›
- **ç¡¬ç¼–ç åˆå§‹ç¨‹åº** æ”¹è¿›æœ‰é™ï¼›
- **å·²æœ‰ SOTA å®ä¾‹ä½œä¸ºèµ·ç‚¹** èµ·å§‹é«˜ä½†è¿…é€Ÿåœæ»ã€‚
> ğŸ’¡ ç»“è®ºï¼š**è‰¯å¥½çš„ç¨‹åºéª¨æ¶æ¯”é«˜è´¨é‡èµ·ç‚¹æ›´é‡è¦**ï¼Œåˆ©äº LLM å­¦ä¹ æ³›åŒ–æ¨¡å¼ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Human-LLM åä½œæ˜¯ç†è®ºç ”ç©¶çš„å¼ºå¤§æ–°èŒƒå¼**ï¼š
   - LLM æä¾›åˆ›é€ æ€§å€™é€‰ï¼›
   - äººç±»æç‚¼ç»“æ„ã€å®Œæˆè¯æ˜ï¼›
   - äºŒè€…ç»“åˆå¯çªç ´é•¿æœŸåƒµå±€ã€‚

2. **ç¨‹åºä½œä¸ºæœç´¢å¯¹è±¡ä¼˜äºåŸå§‹å‘é‡**ï¼š
   - æ”¯æŒå‚æ•°åŒ–ã€ç¼©æ”¾ã€æ³›åŒ–ï¼›
   - å†…åµŒè¯­ä¹‰ç»“æ„ï¼Œæ˜“äºç†è§£å’Œä¿®æ”¹ï¼›
   - ç¬¦åˆ Kolmogorov å¤æ‚åº¦ä½çš„æœ¬è´¨è§„å¾‹ã€‚

3. **å¤šä¸ªç»å…¸é—®é¢˜å–å¾—å†å²æ€§çªç ´**ï¼š
   - Knapsackï¼šè¯ä¼ª output-polynomial æ—¶é—´çŒœæƒ³ï¼›
   - Bin Packingï¼šä¸‹ç•Œä» 1.3 â†’ 1.5ï¼›
   - k-medianï¼šé¦–ä¸ªéå¹³å‡¡ Price of Hierarchy ä¸‹ç•Œï¼›
   - Gasolineï¼šæ‰“ç ´ 2-è¿‘ä¼¼çŒœæƒ³ã€‚

4. **å°å‹ LLM + é«˜æ¸© + ç»“æ„åŒ–åˆå§‹åŒ– = é«˜æ•ˆæ¢ç´¢ç­–ç•¥**

---

### æ–¹æ³•çš„å±€é™æ€§
- å¹¶éæ‰€æœ‰é—®é¢˜éƒ½èƒ½æˆåŠŸï¼š
  - æœªèƒ½æ”¹è¿› k-means çš„ Price of Hierarchyï¼›
  - æœªèƒ½æ‰¾åˆ° Best-Fit æ¸è¿‘éšæœºé¡ºåºæ¯”çš„æ›´å¥½ä¸‹ç•Œï¼›
  - å¯¹ Wardâ€™s method å±‚æ¬¡èšç±»æ— æ•ˆã€‚
- ä¸¥é‡ä¾èµ–äººç±»ä¸“å®¶çš„æ´å¯ŸåŠ›ï¼Œè‡ªåŠ¨åŒ–ç¨‹åº¦ä»æœ‰å¾…æé«˜ã€‚
- è®¡ç®—æˆæœ¬è¾ƒé«˜ï¼ˆæ•°åƒæ¬¡ LLM è°ƒç”¨ï¼‰ï¼Œå°¤å…¶æ¶‰åŠ Gurobi ç­‰æ±‚è§£å™¨æ—¶ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **è‡ªåŠ¨åŒ–æç‚¼è¿‡ç¨‹**ï¼šå¼€å‘å·¥å…·è‡ªåŠ¨è¯†åˆ«ç¨‹åºä¸­çš„é‡å¤æ¨¡å¼ã€å‚æ•°å…³ç³»ï¼Œå‡å°‘äººå·¥è´Ÿæ‹…ã€‚
2. **æ„å»ºä¸“ç”¨ LLM ç¼–è¾‘å™¨**ï¼šä¸“ç”¨äºâ€œç¨‹åºå˜å¼‚ + æ€§èƒ½é¢„æµ‹â€çš„å¾®è°ƒæ¨¡å‹ã€‚
3. **åº”ç”¨äºå…¶ä»–ç†è®ºé—®é¢˜**ï¼šå¦‚å›¾è®ºæå€¼é—®é¢˜ã€ç”µè·¯å¤æ‚æ€§ã€åšå¼ˆè®ºå‡è¡¡åˆ†æç­‰ã€‚
4. **å½¢å¼åŒ–éªŒè¯é›†æˆ**ï¼šå°† Coq/Lean ç­‰è¯æ˜åŠ©æ‰‹æ¥å…¥æµç¨‹ï¼Œå®ç°ç«¯åˆ°ç«¯å¯éªŒè¯å‘ç°ã€‚
5. **æ¢ç´¢æ›´å¤šåä½œæ¨¡å¼**ï¼šå¦‚å¤šäººåä½œæ ‡æ³¨ã€è·¨é¢†åŸŸä¸“å®¶å‚ä¸ç­‰ã€‚

---

> ğŸ”š **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **Co-FunSearch å±•ç¤ºäº† LLM ä¸ä»…æ˜¯å·¥å…·ï¼Œæ›´æ˜¯â€œæ€ç»´ä¼™ä¼´â€â€”â€”å®ƒä¸äººç±»å…±åŒç¼–ç»‡å›°éš¾çš„è‰ºæœ¯ï¼Œä»è€Œæ­å¼€ç®—æ³•æ·±å¤„æœ€é¡½å›ºçš„ç§˜å¯†ã€‚**

</details>

---

### 16. [Limits of n-gram Style Control for LLMs via Logit-Space Injection](https://arxiv.org/abs/2601.16224)

**Authors**: Sami-ul Ahmed  
**Category**: cs.CL  
**Published**: 2026-01-26  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.16224v1  

#### Abstract
Large language models (LLMs) are typically personalized via prompt engineering or parameter-efficient fine-tuning such as LoRA. However, writing style can be difficult to distill into a single prompt, and LoRA fine-tuning requires computationally intensive training and infrastructure. We investigate...

---

### 17. [Graph-Anchored Knowledge Indexing for Retrieval-Augmented Generation](https://arxiv.org/abs/2601.16462)

**Authors**: Zhenghao Liu, Mingyan Wu, Xinze Li, Yukun Yan, Shuo Wang, Cheng Yang, Minghe Yu, Zheni Zeng, Maosong Sun  
**Category**: cs.CL  
**Published**: 2026-01-26  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.16462v1  

#### Abstract
Retrieval-Augmented Generation (RAG) has emerged as a dominant paradigm for mitigating hallucinations in Large Language Models (LLMs) by incorporating external knowledge. Nevertheless, effectively integrating and interpreting key evidence scattered across noisy documents remains a critical challenge...

---

### 18. [AuroraEdge-V-2B: A Faster And Stronger Edge Visual Large Language Model](https://arxiv.org/abs/2601.16615)

**Authors**: Xiang Chen  
**Category**: cs.CL  
**Published**: 2026-01-26  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.16615v1  

#### Abstract
Recently, due to the advancement of multimodal technology, people are attempting to use visual large language models (VLLMs) in industrial production. Many deep learning models (DLMs) deployed in the production environment are gradually being replaced by VLLMs. Compared with DLMs, VLLMs have some ad...

---

### 19. [Robust Categorical Data Clustering Guided by Multi-Granular Competitive Learning](https://arxiv.org/abs/2601.16491)

**Authors**: Shenghong Cai, Yiqun Zhang, Xiaopeng Luo, Yiu-Ming Cheung, Hong Jia, Peng Liu  
**Category**: cs.LG  
**Published**: 2026-01-26  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.16491v1  

#### Abstract
Data set composed of categorical features is very common in big data analysis tasks. Since categorical features are usually with a limited number of qualitative possible values, the nested granular cluster effect is prevalent in the implicit discrete distance space of categorical data. That is, data...

---

### 20. [Multigrade Neural Network Approximation](https://arxiv.org/abs/2601.16884)

**Authors**: Shijun Zhang, Zuowei Shen, Yuesheng Xu  
**Category**: cs.LG  
**Published**: 2026-01-26  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.16884v1  

#### Abstract
We study multigrade deep learning (MGDL) as a principled framework for structured error refinement in deep neural networks. While the approximation power of neural networks is now relatively well understood, training very deep architectures remains challenging due to highly non-convex and often ill-...

---

### 21. [FedSGM: A Unified Framework for Constraint Aware, Bidirectionally Compressed, Multi-Step Federated Optimization](https://arxiv.org/abs/2601.16897)

**Authors**: Antesh Upadhyay, Sang Bin Moon, Abolfazl Hashemi  
**Category**: cs.LG  
**Published**: 2026-01-26  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.16897v1  

#### Abstract
We introduce FedSGM, a unified framework for federated constrained optimization that addresses four major challenges in federated learning (FL): functional constraints, communication bottlenecks, local updates, and partial client participation. Building on the switching gradient method, FedSGM provi...

---

### 22. [AgentDrive: An Open Benchmark Dataset for Agentic AI Reasoning with LLM-Generated Scenarios in Autonomous Systems](https://arxiv.org/abs/2601.16964)

**Authors**: Mohamed Amine Ferrag, Abderrahmane Lakas, Merouane Debbah  
**Category**: cs.AI  
**Published**: 2026-01-26  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.16964v1  

#### Abstract
The rapid advancement of large language models (LLMs) has sparked growing interest in their integration into autonomous systems for reasoning-driven perception, planning, and decision-making. However, evaluating and training such agentic AI models remains challenging due to the lack of large-scale, ...

---

### 23. [PolyAgent: Large Language Model Agent for Polymer Design](https://arxiv.org/abs/2601.16376)

**Authors**: Vani Nigam, Achuth Chandrasekhar, Amir Barati Farimani  
**Category**: cs.CL  
**Published**: 2026-01-26  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.16376v1  

#### Abstract
On-demand Polymer discovery is essential for various industries, ranging from biomedical to reinforcement materials. Experiments with polymers have a long trial-and-error process, leading to long procedures and extensive resources. For these processes, machine learning has accelerated scientific dis...

---

### 24. [Persona Jailbreaking in Large Language Models](https://arxiv.org/abs/2601.16466)

**Authors**: Jivnesh Sandhan, Fei Cheng, Tushar Sandhan, Yugo Murawaki  
**Category**: cs.CL  
**Published**: 2026-01-26  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.16466v1  

#### Abstract
Large Language Models (LLMs) are increasingly deployed in domains such as education, mental health and customer support, where stable and consistent personas are critical for reliability. Yet, existing studies focus on narrative or role-playing tasks and overlook how adversarial conversational histo...

---

### 25. [Select or Project? Evaluating Lower-dimensional Vectors for LLM Training Data Explanations](https://arxiv.org/abs/2601.16651)

**Authors**: Lukas Hinterleitner, Loris Schoenegger, Benjamin Roth  
**Category**: cs.CL  
**Published**: 2026-01-26  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.16651v1  

#### Abstract
Gradient-based methods for instance-based explanation for large language models (LLMs) are hindered by the immense dimensionality of model gradients. In practice, influence estimation is restricted to a subset of model parameters to make computation tractable, but this subset is often chosen ad hoc ...

---

### 26. [A Regularized Actor-Critic Algorithm for Bi-Level Reinforcement Learning](https://arxiv.org/abs/2601.16399)

**Authors**: Sihan Zeng, Sujay Bhatt, Sumitra Ganesh, Alec Koppel  
**Category**: cs.LG  
**Published**: 2026-01-26  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.16399v1  

#### Abstract
We study a structured bi-level optimization problem where the upper-level objective is a smooth function and the lower-level problem is policy optimization in a Markov decision process (MDP). The upper-level decision variable parameterizes the reward of the lower-level MDP, and the upper-level objec...

---

### 27. [Bayesian Experimental Design for Model Discrepancy Calibration: A Rivalry between Kullback--Leibler Divergence and Wasserstein Distance](https://arxiv.org/abs/2601.16425)

**Authors**: Huchen Yang, Xinghao Dong, Jin-Long Wu  
**Category**: cs.LG  
**Published**: 2026-01-26  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.16425v1  

#### Abstract
Designing experiments that systematically gather data from complex physical systems is central to accelerating scientific discovery. While Bayesian experimental design (BED) provides a principled, information-based framework that integrates experimental planning with probabilistic inference, the sel...

---

### 28. [BoostFGL: Boosting Fairness in Federated Graph Learning](https://arxiv.org/abs/2601.16496)

**Authors**: Zekai Chen, Kairui Yang, Xunkai Li, Henan Sun, Zhihan Zhang, Jia Li, Qiangqiang Dai, Rong-Hua Li, Guoren Wang  
**Category**: cs.LG  
**Published**: 2026-01-26  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.16496v1  

#### Abstract
Federated graph learning (FGL) enables collaborative training of graph neural networks (GNNs) across decentralized subgraphs without exposing raw data. While existing FGL methods often achieve high overall accuracy, we show that this average performance can conceal severe degradation on disadvantage...

---

### 29. [Rethinking Large Language Models For Irregular Time Series Classification In Critical Care](https://arxiv.org/abs/2601.16516)

**Authors**: Feixiang Zheng, Yu Wu, Cecilia Mascolo, Ting Dang  
**Category**: cs.LG  
**Published**: 2026-01-26  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.16516v1  

#### Abstract
Time series data from the Intensive Care Unit (ICU) provides critical information for patient monitoring. While recent advancements in applying Large Language Models (LLMs) to time series modeling (TSM) have shown great promise, their effectiveness on the irregular ICU data, characterized by particu...

---

### 30. [Predicting Startup Success Using Large Language Models: A Novel In-Context Learning Approach](https://arxiv.org/abs/2601.16568)

**Authors**: Abdurahman Maarouf, Alket Bakiaj, Stefan Feuerriegel  
**Category**: cs.LG  
**Published**: 2026-01-26  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2601.16568v1  

#### Abstract
Venture capital (VC) investments in early-stage startups that end up being successful can yield high returns. However, predicting early-stage startup success remains challenging due to data scarcity (e.g., many VC firms have information about only a few dozen of early-stage startups and whether they...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- kv cache, offload, State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
