# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-01-07 05:58:08 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [LoRA-Drop: Temporal LoRA Decoding for Efficient LLM Inference](https://arxiv.org/abs/2601.02569)

**Authors**: Hossein Rajabzadeh, Maryam Dialameh, Chul B. Park, Il-Min Kim, Hyock Ju Kwon  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2601.02569v1  

#### Abstract
Autoregressive large language models (LLMs) are bottlenecked by sequential decoding, where each new token typically requires executing all transformer layers. Existing dynamic-depth and layer-skipping methods reduce this cost, but often rely on auxiliary routing mechanisms or incur accuracy degradat...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# LoRA-Drop: Temporal LoRA Decoding for Efficient LLM Inference è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªå›å½’æ¨ç†è¿‡ç¨‹ä¸­é¢ä¸´ä¸¥é‡çš„**è®¡ç®—ç“¶é¢ˆ**ï¼Œå³æ¯ä¸ªæ–° token éƒ½éœ€è¦æ‰§è¡Œå®Œæ•´çš„ Transformer å±‚å †æ ˆï¼Œå¯¼è‡´é«˜å»¶è¿Ÿå’Œé«˜å†…å­˜å¼€é”€ã€‚å°½ç®¡å·²æœ‰åŠ¨æ€æ·±åº¦æˆ–å±‚è·³è¿‡æ–¹æ³•å°è¯•ç¼“è§£è¯¥é—®é¢˜ï¼Œä½†å®ƒä»¬é€šå¸¸ä¾èµ–é¢å¤–çš„è·¯ç”±æœºåˆ¶ï¼Œæˆ–åœ¨è·³è¿‡å±‚æ—¶ç¼ºä¹è¡¥å¿æ›´æ–°ï¼Œä»è€Œé€ æˆç²¾åº¦ä¸‹é™ã€‚

æ­¤å¤–ï¼Œä¼ ç»Ÿçš„ KV Cache åœ¨é•¿åºåˆ—ç”Ÿæˆä¸­å ç”¨å¤§é‡æ˜¾å­˜ï¼Œé™åˆ¶äº†å®é™…éƒ¨ç½²æ•ˆç‡ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šLoRA-Drop
æœ¬æ–‡æå‡º **LoRA-Drop** â€”â€” ä¸€ç§è½»é‡çº§ã€å³æ’å³ç”¨çš„é«˜æ•ˆæ¨ç†æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨ LLM ä¸­éšè—çŠ¶æ€çš„**æ—¶é—´å†—ä½™æ€§**ï¼ˆtemporal redundancyï¼‰ï¼Œé€šè¿‡ä»¥ä¸‹æ–¹å¼åŠ é€Ÿè§£ç ï¼š

- **å›ºå®šå­é›†ä¸­é—´å±‚çš„æ—¶é—´è°ƒåº¦ç­–ç•¥**ï¼šé€‰æ‹©ä¸€éƒ¨åˆ†ä¸­é—´å±‚ä½œä¸ºâ€œå¯è·³è¿‡å±‚â€ï¼ˆdroppable layersï¼‰ï¼Œåœ¨å¤§å¤šæ•°è§£ç æ­¥éª¤ä¸­ä¸æ‰§è¡Œå®Œæ•´å‰å‘ä¼ æ’­ã€‚
- **LoRA è½»é‡ä¿®æ­£æœºåˆ¶**ï¼šè¿™äº›å±‚å¤ç”¨ä¸Šä¸€ä¸ª token çš„éšè—çŠ¶æ€ï¼Œå¹¶æ–½åŠ ä¸€ä¸ªä½ç§©é€‚é…å™¨ï¼ˆLoRAï¼‰è¿›è¡Œå¾®è°ƒï¼Œä»¥è¿‘ä¼¼å½“å‰è¾“å‡ºã€‚
- **å‘¨æœŸæ€§åˆ·æ–°æœºåˆ¶**ï¼šæ¯éš” $k+1$ æ­¥æ‰§è¡Œä¸€æ¬¡å…¨æ¨¡å‹å‰å‘ä¼ æ’­ï¼ˆrefresh stepï¼‰ï¼Œé˜²æ­¢è¯¯å·®ç´¯ç§¯æ¼‚ç§»ã€‚
- **KV Cache èŠ‚çœ**ï¼šåœ¨ LoRA æ¨¡å¼ä¸‹è·³è¿‡å¯¹å¯è·³è¿‡å±‚çš„ KV æ›´æ–°ï¼Œæ˜¾è‘—å‡å°‘ KV Cache å†…å­˜å ç”¨ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | LoRA-Drop | å…¶ä»–å±‚è·³è¿‡æ–¹æ³•ï¼ˆå¦‚ Unified Layer Skipping, FlexiDepthï¼‰ |
|------|----------|--------------------------------------------------------|
| æ˜¯å¦éœ€è¦è·¯ç”±ç½‘ç»œ | âŒ å¦ï¼ˆæ— éœ€é¢å¤–å‚æ•°ï¼‰ | âœ… å¤šæ•°éœ€è¦è½»é‡è·¯ç”±æ¨¡å— |
| æ˜¯å¦ä¿ç•™ä¸Šä¸‹æ–‡è¿ç»­æ€§ | âœ… åˆ©ç”¨ç¼“å­˜ + LoRA è¡¥å¿ | âŒ é€šå¸¸ç›´æ¥è·³è¿‡ï¼Œæ— è¡¥å¿ |
| å¯¹ KV Cache çš„å½±å“ | âœ… æ˜¾è‘—å‡å°‘æ›´æ–°é¢‘ç‡ | âš ï¸ ä¸€èˆ¬ä»éœ€æ›´æ–°æ‰€æœ‰å±‚ |
| æ’ä»¶å¼å…¼å®¹æ€§ | âœ… å¯æ— ç¼é›†æˆé¢„è®­ç»ƒæ¨¡å‹ | âš ï¸ æ¶æ„ä¿®æ”¹å¯èƒ½å¤æ‚ |
| å¾®è°ƒæˆæœ¬ | âœ… ä»…éœ€å°‘é‡æŒç»­å¾®è°ƒï¼ˆcontinual fine-tuningï¼‰ | âš ï¸ å¯èƒ½éœ€è¦é‡æ–°è®­ç»ƒæˆ–å¤æ‚è°ƒä¼˜ |

> **åˆ›æ–°äº®ç‚¹**ï¼š
> - é¦–æ¬¡å°† **LoRA** å¼•å…¥æ¨ç†é˜¶æ®µç”¨äº**å±‚é—´çŠ¶æ€è¡¥å¿**ï¼Œè€Œéä»…ç”¨äºè®­ç»ƒï¼›
> - æå‡ºâ€œ**æ—¶é—´è®¡ç®—è°ƒåº¦**â€ï¼ˆtemporal compute scheduleï¼‰æ¦‚å¿µï¼Œå®ç°ç»†ç²’åº¦æ§åˆ¶ï¼›
> - å®ç°äº†**è®¡ç®—æ•ˆç‡ä¸ç²¾åº¦ä¹‹é—´çš„å¹³æ»‘æƒè¡¡æ›²çº¿**ï¼ˆPareto frontierï¼‰ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–å¤šä¸ªä»»åŠ¡ç±»åˆ«ï¼Œç¡®ä¿æ³›åŒ–èƒ½åŠ›ï¼š

#### æ¨ç†ä¸å¸¸è¯†ç†è§£
- **MMLU**ï¼ˆå¤šä»»åŠ¡çŸ¥è¯†ï¼‰
- **HellaSwag (HS)**ï¼ˆå¸¸è¯†æ¨ç†ï¼‰
- **WinoGrande**ï¼ˆæŒ‡ä»£æ¶ˆè§£ï¼‰
- **ARC-e/c**, **OpenBookQA**, **PIQA**, **RACE**
- **GSM8K**, **MATH**, **BBH**ï¼ˆæ•°å­¦ä¸å¤æ‚æ¨ç†ï¼‰

#### ä»£ç ç”Ÿæˆ
- **HumanEval**, **MBPP**ï¼ˆPass@1 / Pass@10ï¼‰

#### é•¿æ–‡æœ¬ä¸å¤šè¯­è¨€
- **LongBench**ï¼ˆé•¿ä¸Šä¸‹æ–‡é—®ç­”ï¼‰
- **Needle-in-a-Haystack**ï¼ˆä¿¡æ¯æ£€ç´¢ï¼‰
- **XNLI**, **XCOPA**ï¼ˆè·¨è¯­è¨€è‡ªç„¶è¯­è¨€æ¨æ–­ä¸å› æœæ¨ç†ï¼‰

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### æ¨¡å‹
åœ¨å››ç§ä¸»æµå¼€æº LLM ä¸ŠéªŒè¯ï¼š
- **LLaMA2-7B**
- **LLaMA3-8B**
- **Qwen2.5-7B**
- **Qwen2.5-14B**

#### å…³é”®è¶…å‚æ•°
- **Drop Ratio $p$**ï¼šå¯è·³è¿‡å±‚çš„æ¯”ä¾‹ï¼Œå–å€¼ $\{0.25, 0.5, 0.75\}$
- **Temporal Window $k$**ï¼šæ¯ $k+1$ æ­¥æ‰§è¡Œä¸€æ¬¡ full refreshï¼Œä¸­é—´ $k$ æ­¥ä½¿ç”¨ LoRA æ¨¡å¼
- **LoRA Rank $r=16$**, Scaling $\alpha=16$
- åºåˆ—é•¿åº¦ï¼š4096ï¼ˆéƒ¨åˆ†ä¸º 2048 æˆ– 1024ï¼‰

#### è¯„ä¼°æŒ‡æ ‡
| ç±»åˆ« | æŒ‡æ ‡ |
|------|------|
| å‡†ç¡®ç‡ | Zero-shot Accuracy, Pass@1/10 |
| æ•ˆç‡ | Tokens/sec, Speedup Ã—, FLOPs reduction |
| å†…å­˜ | KV Cache Size (MB), KV-saving % |
| å»¶è¿Ÿ | Per-token latency (p50, p95) |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Full Model**ï¼šåŸå§‹å®Œæ•´æ¨¡å‹ï¼ˆæ— è·³è¿‡ï¼‰
- **Unified Layer Skipping** [18]
- **FlexiDepth** [19]

> æ³¨ï¼šä½œè€…æŒ‡å‡ºå…¶ä»–åŠ é€ŸæŠ€æœ¯ï¼ˆå¦‚é‡åŒ–ã€æ¨æµ‹è§£ç ã€KVå‹ç¼©ï¼‰ä¸æœ¬æ–¹æ³•æ­£äº¤ï¼Œæ•…æœªçº³å…¥ä¸»æ¯”è¾ƒï¼Œä½†å¼ºè°ƒæœªæ¥å¯ç»„åˆä½¿ç”¨ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

| æ¨¡å‹ | æœ€é«˜é€Ÿåº¦æå‡ | KV Cache èŠ‚çœ | ç²¾åº¦æŸå¤±ä¸Šé™ |
|------|-------------|----------------|--------------|
| LLaMA2-7B | **2.35Ã—** ($p=0.75, k=3$) | ~50% | <0.5 pp |
| Qwen2.5-7B | **2.42Ã—** ($p=0.75, k=3$) | ~55% | <0.5 pp |
| LLaMA3-8B | **2.38Ã—** ($p=0.75, k=3$) | ~45% | <0.5 pp |
| Qwen2.5-14B | **2.60Ã—** ($p=0.75, k=3$) | ~50% | <0.5 pp |

> âœ… åœ¨ $p=0.5, k=3$ çš„â€œå®‰å…¨åŒºâ€é…ç½®ä¸‹ï¼š
> - å¹³å‡é€Ÿåº¦æå‡ **1.6â€“1.8Ã—**
> - KV Cache å‡å°‘ **40â€“55%**
> - å¹³å‡å‡†ç¡®ç‡ä¸‹é™ **â‰¤0.5 percentage points (pp)**

---

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ï¼ˆTable Iï¼‰

| æ–¹æ³• | å¹³å‡å‡†ç¡®ç‡ï¼ˆvs Baselineï¼‰ | é€Ÿåº¦æå‡ï¼ˆÃ—ï¼‰ |
|------|----------------------------|---------------|
| Full Model | 64.6 â€“ 69.3 | 1.00 |
| Unified Layer Skipping | â†“ ~0.8 pp | 1.34â€“1.42Ã— |
| FlexiDepth | â†“ ~0.5 pp | 1.49â€“1.55Ã— |
| **LoRA-Drop (p=0.5)** | â†“ ~0.2â€“0.4 pp | **1.68â€“1.73Ã—** |
| LoRA-Drop (p=0.75) | â†“ ~2.5 pp | **2.35â€“2.60Ã—** |

> ğŸ’¡ ç»“è®ºï¼šLoRA-Drop åœ¨ç›¸åŒç²¾åº¦æŸå¤±ä¸‹å®ç°äº†æ›´é«˜çš„åŠ é€Ÿæ¯”ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆTable III & IVï¼‰

#### ä¸åŒ $p$ å’Œ $k$ çš„æƒè¡¡åˆ†æï¼ˆä»¥ LLaMA3-8B ä¸ºä¾‹ï¼‰

| $p$ | $k$ | å‡†ç¡®ç‡å˜åŒ– â–³Acc | é€Ÿåº¦æå‡ | KV Cache (MB) |
|-----|----|------------------|---------|----------------|
| 0.0 | - | +0.0 | 1.00Ã— | 16000 |
| 0.25 | 3 | +0.1 | 1.24Ã— | 13000 |
| 0.50 | 3 | -0.3 | **1.70Ã—** | **9200** |
| 0.75 | 3 | -2.4 | **2.20Ã—** | **5200** |
| 0.75 | 5 | -3.6 | 2.45Ã— | 4200 |

> ğŸ” å‘ç°ï¼š
> - $p \leq 0.5$, $k \leq 3$ æ˜¯â€œ**å®‰å…¨åŒº**â€ï¼Œç²¾åº¦æŸå¤±æå°ï¼ˆâ‰¤0.5 ppï¼‰
> - æé«˜ $k$ å¯è¿›ä¸€æ­¥é™ä½ KV å†™å…¥é¢‘ç‡ï¼ŒèŠ‚çœæ›´å¤šå†…å­˜
> - $p=0.75$ è™½ç„¶åŠ é€Ÿæ˜æ˜¾ï¼Œä½†ç²¾åº¦ä¸‹é™æ˜¾è‘—ï¼Œé€‚ç”¨äºä½å»¶è¿Ÿåœºæ™¯

---

### LoRA æ³¨å…¥ä½ç½®æ¶ˆèï¼ˆTable Vï¼‰
æ¯”è¾ƒä¸¤ç§ LoRA æ³¨å…¥æ–¹å¼ï¼š

| æ³¨å…¥ç­–ç•¥ | å‡†ç¡®ç‡ | é€Ÿåº¦æå‡ |
|--------|--------|----------|
| Attention+MLP LoRA | â‰ˆ Baseline | 1.27â€“1.39Ã— |
| **Block-level LoRAï¼ˆé»˜è®¤ï¼‰** | â‰ˆ Baseline | **1.45â€“1.58Ã—** |

> âœ… æ¨èä½¿ç”¨ **block-levelï¼ˆwhole-layerï¼‰æ³¨å…¥**ï¼Œå› å…¶å¼•å…¥æœ€å°‘æ•°æ®ç§»åŠ¨ï¼Œè·å¾—æœ€å¤§ååå¢ç›Šã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **LLM éšè—çŠ¶æ€å­˜åœ¨æ˜¾è‘—æ—¶é—´å†—ä½™**  
   å›¾1æ˜¾ç¤ºç›¸é‚» token çš„éšè—çŠ¶æ€ä½™å¼¦ç›¸ä¼¼åº¦é«˜è¾¾ 0.6â€“0.85ï¼Œä¸”å¯¹æœªæ¥ 3â€“6 ä¸ª token ä»æœ‰è¾ƒå¼ºé¢„æµ‹èƒ½åŠ›ï¼Œæ”¯æŒâ€œéæ¯æ­¥éƒ½éœ€å…¨å±‚è®¡ç®—â€çš„å‡è®¾ã€‚

2. **LoRA-Drop å®ç°é«˜æ•ˆä¸ç¨³å®šçš„å¹³è¡¡**  
   é€šè¿‡å‘¨æœŸæ€§åˆ·æ–° + LoRA è¡¥å¿ï¼Œåœ¨ä¿æŒè¯­ä¹‰ä¸€è‡´æ€§çš„åŒæ—¶å¤§å¹…é™ä½è®¡ç®—è´Ÿæ‹…ã€‚

3. **KV Cache èŠ‚çœå…·æœ‰å¯é¢„æµ‹æ€§**  
   å…¬å¼æ¨å¯¼è¡¨æ˜ KV èŠ‚çœæ¯”ä¾‹å–å†³äº $p$, $k$, $h_{kv}$ ç­‰å› ç´ ï¼Œå®æµ‹èŠ‚çœè¾¾ **40â€“55%**ã€‚

4. **é€šç”¨æ€§å¼ºï¼Œè·¨æ¨¡å‹/ä»»åŠ¡è¡¨ç°ç¨³å®š**  
   åœ¨å¤šç§æ¶æ„ï¼ˆLLaMA/Qwenï¼‰ã€å°ºå¯¸ï¼ˆ7Bâ€“14Bï¼‰ã€ä»»åŠ¡ï¼ˆæ¨ç†/ä»£ç /å¤šè¯­è¨€ï¼‰ä¸Šå‡æœ‰æ•ˆã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–æŒç»­å¾®è°ƒ**ï¼šè™½åªéœ€å¾®è°ƒ LoRA å‚æ•°ï¼Œä½†ä»éœ€é¢å¤–è®­ç»ƒé˜¶æ®µï¼›
- **å›ºå®šè°ƒåº¦ç­–ç•¥**ï¼šå½“å‰é‡‡ç”¨å›ºå®šå‘¨æœŸ $k$ï¼Œå°šæœªå®ç°åŸºäº token å¤æ‚åº¦çš„è‡ªé€‚åº”è°ƒåº¦ï¼›
- **æç«¯è®¾ç½®æœ‰ç²¾åº¦æŸå¤±**ï¼šå½“ $p > 0.75$ æ—¶ï¼Œå¹³å‡ç²¾åº¦ä¸‹é™è¶…è¿‡ 2 ppï¼Œä¸é€‚åˆé«˜ç²¾åº¦è¦æ±‚ä»»åŠ¡ï¼›
- **ç¡¬ä»¶ä¼˜åŒ–æ½œåŠ›æœªå®Œå…¨é‡Šæ”¾**ï¼šç›®å‰æœªé’ˆå¯¹ç‰¹å®š GPU æ¶æ„ä¼˜åŒ–å†…æ ¸ï¼Œå®é™…åŠ é€Ÿå¯èƒ½å—é™äºè®¿å­˜å¸¦å®½ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **è‡ªé€‚åº”è°ƒåº¦æœºåˆ¶**ï¼šåŸºäº token ç†µã€logit margin ç­‰ä¿¡å·åŠ¨æ€å†³å®šæ˜¯å¦åˆ·æ–°ï¼›
2. **æ‰©å±•è‡³å¤šæ¨¡æ€ä¸æ£€ç´¢å¢å¼ºæ¨¡å‹**ï¼šåº”ç”¨äºè§†è§‰-è¯­è¨€æˆ–å¤šæ–‡æ¡£æ¨ç†åœºæ™¯ï¼›
3. **ä¸å…¶ä»–åŠ é€ŸæŠ€æœ¯èåˆ**ï¼šç»“åˆé‡åŒ–ï¼ˆQuantizationï¼‰ã€KV å‹ç¼©ã€æ¨æµ‹è§£ç ç­‰å½¢æˆå¤åˆä¼˜åŒ–æ–¹æ¡ˆï¼›
4. **ç†è®ºåˆ†ææ”¶æ•›æ€§ä¸è¯¯å·®ä¼ æ’­è¾¹ç•Œ**ï¼šå»ºç«‹æ›´ä¸¥è°¨çš„å½¢å¼åŒ–ä¿éšœã€‚

---

## æ€»ç»“

âœ… **LoRA-Drop æ˜¯ä¸€ç§æ–°é¢–ã€å®ç”¨ä¸”é«˜æ•ˆçš„ LLM æ¨ç†åŠ é€Ÿæ–¹æ³•**ï¼Œå®ƒå·§å¦™åœ°ç»“åˆäº†ï¼š
- æ—¶é—´å†—ä½™è§‚å¯Ÿ
- LoRA ä½ç§©è¡¥å¿
- å‘¨æœŸæ€§åˆ·æ–°æœºåˆ¶
- KV Cache èŠ‚çœè®¾è®¡

ğŸ¯ åœ¨å‡ ä¹ä¸å½±å“ç²¾åº¦çš„å‰æä¸‹ï¼ˆ<0.5 ppï¼‰ï¼Œå®ç°äº† **æœ€é«˜ 2.6Ã— è§£ç é€Ÿåº¦æå‡** å’Œ **è¶…è¿‡ 50% çš„ KV Cache èŠ‚çœ**ï¼Œä¸ºå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„å®é™…éƒ¨ç½²æä¾›äº†æå…·å‰æ™¯çš„æŠ€æœ¯è·¯å¾„ã€‚

ğŸ”§ é¡¹ç›®ä»£ç å·²å¼€æºï¼š[https://github.com/hosseinbv/LoRA-Drop.git](https://github.com/hosseinbv/LoRA-Drop.git)

</details>

---

### 2. [Lil: Less is Less When Applying Post-Training Sparse-Attention Algorithms in Long-Decode Stage](https://arxiv.org/abs/2601.03043)

**Authors**: Junhao Hu, Fangze Li, Mingtao Xu, Feifan Meng, Shiju Zhao, Tiancheng Hu, Ting Peng, Anmin Liu, Wenrui Huang, Chenxu Liu, Ziyue Hua, Tao Xie  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2601.03043v1  

#### Abstract
Large language models (LLMs) demonstrate strong capabilities across a wide range of complex tasks and are increasingly deployed at scale, placing significant demands on inference efficiency. Prior work typically decomposes inference into prefill and decode stages, with the decode stage dominating to...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLil: Less is Less When Applying Post-Training Sparse-Attention Algorithms in Long-Decode Stage

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡æ­ç¤ºäº†ä¸€ä¸ªåœ¨**Post-Training Sparse-Attention (PTSD)** ç®—æ³•ä¸­è¢«å¿½è§†çš„å…³é”®é—®é¢˜ï¼Œç§°ä¸º **â€œLilâ€ (Less is Less)**ã€‚å°½ç®¡ç¨€ç–æ³¨æ„åŠ›ç®—æ³•ï¼ˆå¦‚ H2Oã€Sinkã€Questã€infLLMï¼‰é€šè¿‡å‡å°‘æ¯ä¸ªè§£ç æ­¥çš„è®¡ç®—é‡æ¥åŠ é€Ÿæ¨ç†ï¼Œä½†å®ƒä»¬ä¼šå¯¼è‡´**ä¿¡æ¯ä¸¢å¤±**ï¼Œè¿«ä½¿æ¨¡å‹ç”Ÿæˆæ›´é•¿çš„è¾“å‡ºåºåˆ—ä»¥é‡å»ºä¸Šä¸‹æ–‡ã€‚è¿™åè€Œå¢åŠ äº†ç«¯åˆ°ç«¯çš„å»¶è¿Ÿå’Œå†…å­˜å ç”¨ï¼ŒæŠµæ¶ˆäº†å•æ­¥åŠ é€Ÿå¸¦æ¥çš„æ”¶ç›Šã€‚

è¿™ä¸€ç°è±¡è¢«ç§°ä¸ºâ€œLilâ€ï¼Œå³â€œè¶Šå°‘ï¼ˆå…³æ³¨çš„tokenï¼‰åè€Œå¯¼è‡´è¶Šå¤šï¼ˆç”Ÿæˆçš„tokenï¼‰â€ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä¸ºè§£å†³ Lil é—®é¢˜ï¼Œä½œè€…æå‡ºäº† **Guardian**ï¼Œä¸€ç§ç”¨äº**è§£ç é˜¶æ®µçš„æ—©åœç®—æ³• (early-stopping algorithm)**ã€‚

- **æ ¸å¿ƒæ€æƒ³**ï¼šå½“ç”Ÿæˆåºåˆ—çš„ä¿¡æ¯å¢ç›Šè¶‹äºåœæ»æ—¶ï¼Œåœæ­¢è§£ç ã€‚
- **å®ç°æ–¹å¼**ï¼šåˆ©ç”¨ **LZ77 å‹ç¼©ç®—æ³•**åŠ¨æ€ç›‘æµ‹ç”Ÿæˆåºåˆ—çš„å‹ç¼©ç‡å˜åŒ–ã€‚è‹¥è¿ç»­è‹¥å¹²æ­¥å‹ç¼©é•¿åº¦å¢é•¿ä½äºé˜ˆå€¼ï¼Œåˆ™åˆ¤å®šä¿¡æ¯å¢ç›Šå·²é¥±å’Œï¼Œæå‰ç»ˆæ­¢ç”Ÿæˆã€‚
- **ç†è®ºåŸºç¡€**ï¼šåŸºäºä¿¡æ¯è®ºï¼Œå‹ç¼©æ¯”å¯ä½œä¸ºåºåˆ—ä¿¡æ¯ç†µçš„ä»£ç†æŒ‡æ ‡ã€‚ä¿¡æ¯ä¸å†æ˜¾è‘—å¢åŠ æ„å‘³ç€åç»­ç”Ÿæˆæ˜¯å†—ä½™çš„ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ•ˆç‡** | å‡å°‘é«˜è¾¾ **90% çš„ token æ¶ˆè€—**ï¼Œæ˜¾è‘—é™ä½æ¨ç†æˆæœ¬ã€‚ |
| **å‡†ç¡®æ€§** | ä»…å¸¦æ¥ **<2% çš„å‡†ç¡®ç‡ä¸‹é™**ï¼Œç”šè‡³åœ¨æŸäº›æƒ…å†µä¸‹å› é¿å…è¿‡åº¦éªŒè¯è€Œæå‡å‡†ç¡®ç‡ã€‚ |
| **é€šç”¨æ€§** | ä¸ä¾èµ–ç‰¹å®šæ¨¡å‹æ¶æ„æˆ–è®­ç»ƒè¿‡ç¨‹ï¼Œé€‚ç”¨äºæ‰€æœ‰ PTSD ç®—æ³•åŠ full attention åœºæ™¯ã€‚ |
| **å®ç”¨æ€§** | è®¡ç®—å¼€é”€æä½ï¼ˆæ¯ 250 æ­¥å‹ç¼©ä¸€æ¬¡ï¼Œè€—æ—¶ ~34msï¼‰ï¼Œæ˜“äºé›†æˆã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

åœ¨ä¸‰ä¸ªæ•°å­¦æ¨ç†å¯†é›†å‹åŸºå‡†ä¸Šè¿›è¡Œè¯„ä¼°ï¼š

- **GSM8K**ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜ï¼Œéœ€å¤šæ­¥æ¨ç†ã€‚
- **MATH-500**ï¼šé«˜ä¸­æ•°å­¦ç«èµ›é¢˜ï¼Œéš¾åº¦åˆ†å±‚ï¼ˆ1â€“5çº§ï¼‰ã€‚
- **AIME**ï¼šç¾å›½æ•°å­¦é‚€è¯·èµ›é¢˜ç›®ï¼Œæ¶µç›–ä»£æ•°ã€å‡ ä½•ã€æ•°è®ºç­‰ã€‚

å‡ä»æµ‹è¯•é›†ä¸­é€‰å–å‰ 200 ä¸ªæ ·æœ¬è¿›è¡Œè¯„ä¼°ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **æ¨¡å‹**
- **DSR**: DeepScaleR-1.5B-Preview
- **DSL**: DeepSeek-R1-Distill-Llama-8B
- **Qwe**: Qwen1.5-MoE-A2.7B-Chat

è¦†ç›–ä¸åŒè§„æ¨¡ã€æ¶æ„ï¼ˆDense vs. MoEï¼‰å’Œè®­ç»ƒç­–ç•¥ã€‚

#### **ç¡¬ä»¶ç¯å¢ƒ**
- å•å¼  NVIDIA A100-80GB GPU
- Intel Xeon Platinum 8358P CPU @ 2.60GHz
- CUDA 12.6

#### **è¯„ä¼°æŒ‡æ ‡**
- **Token Savings**ï¼šåº”ç”¨ Guardian åèŠ‚çœçš„ token æ•°æ¯”ä¾‹ã€‚
- **Accuracy**ï¼šè¾“å‡ºä¸æ ‡å‡†ç­”æ¡ˆæ•°å­¦ç­‰ä»·çš„æ¯”ä¾‹ã€‚
- **Accuracy Drop**ï¼šä½¿ç”¨ Guardian åå‡†ç¡®ç‡çš„å˜åŒ–ï¼ˆç»å¯¹ç™¾åˆ†ç‚¹ï¼‰ã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

å¯¹æ¯”äº†äº”ç§ä¸»æµ PTSD ç®—æ³•ï¼š

| ç®—æ³• | ç±»å‹ | æ˜¯å¦ä¿ç•™å…¨éƒ¨ KV | ä»£è¡¨å·¥ä½œ |
|------|------|------------------|----------|
| **Full Attention** | å…¨æ³¨æ„åŠ› | æ˜¯ | åŸºçº¿ |
| **H2O** | æµæ°´çº¿ + é‡ç”¨å¤´ | å¦ | Zhang et al., 2023 |
| **Sink** | æ³¨æ„åŠ›é”šç‚¹ | å¦ | Xiao et al., 2024b |
| **Quest** | æŸ¥è¯¢æ„ŸçŸ¥ç¨€ç– | æ˜¯ | Tang et al., 2024 |
| **infLLM** | é«˜æ•ˆä¸Šä¸‹æ–‡è®°å¿† | æ˜¯ | Xiao et al., 2024a |

æ‰€æœ‰ç®—æ³•å‡åœ¨ä¸åŒ **Cache Budget**ï¼ˆ128, 256, 512, 1024ï¼‰ä¸‹æµ‹è¯•ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

æ ¹æ® **Table 1** å’Œ **Table 3**ï¼ŒGuardian åœ¨å¤šä¸ªé…ç½®ä¸‹è¡¨ç°ä¼˜å¼‚ï¼š

| æ¨¡å‹ | æ•°æ®é›† | Cache Budget | Token Savings | Accuracy Î” |
|------|--------|---------------|----------------|-------------|
| DSR | GSM8K | 128 | **83.0%** | -0.5pp |
| DSL | AIME | 128 | **92.3%** | -1.5pp |
| DSR | MATH-500 | 1024 | **52.0%** | +0.5pp âœ… |
| DSL | AIME | 1024 | **78.1%** | -0.5pp |

> âœ… è¡¨ç¤ºå‡†ç¡®ç‡æå‡

- **æœ€é«˜èŠ‚çœè¾¾ 90%+ token**ï¼Œå°¤å…¶åœ¨å° cache budget ä¸‹æ•ˆæœæ˜¾è‘—ã€‚
- **å¹³å‡å‡†ç¡®ç‡ä¸‹é™ <2%**ï¼Œéƒ¨åˆ†åœºæ™¯ä¸‹å‡†ç¡®ç‡åå‡ï¼ˆé˜²æ­¢é—å¿˜æ­£ç¡®ç­”æ¡ˆï¼‰ã€‚
- **Qwen MoE æ¨¡å‹æ”¶ç›Šè¾ƒå°**ï¼šå› å…¶æœ¬èº«ç”ŸæˆçŸ­ä¸”é”™è¯¯ç‡é«˜ï¼Œç¼ºä¹å†—ä½™ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- æ‰€æœ‰ PTSD ç®—æ³•åœ¨æ—  Guardian æ—¶å‡è¡¨ç°å‡º **æ›´é•¿çš„è¾“å‡ºé•¿åº¦**ï¼ˆè§ Figure 1bï¼‰ï¼Œå³ä½¿å‡†ç¡®ç‡ç›¸è¿‘ã€‚
- ä½¿ç”¨ Guardian åï¼Œ**token æ¶ˆè€—å¤§å¹…ä¸‹é™**ï¼ŒåŒæ—¶ä¿æŒæˆ–è½»å¾®ç‰ºç‰²å‡†ç¡®ç‡ã€‚
- **Guardian å¯¹ä¿¡æ¯é‡å»ºå‹å†—ä½™ï¼ˆLilï¼‰å’Œæ¨¡å¼å†—ä½™ï¼ˆå¦‚ reward hackingï¼‰å‡æœ‰æ•ˆ**ï¼ˆè§ Table 2ï¼‰ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### **æŒ‰æ­£ç¡®/é”™è¯¯æ¡ˆä¾‹åˆ†æï¼ˆTable 3ï¼‰**
| æ¡ˆä¾‹ç±»å‹ | èŠ‚çœæ•ˆæœ | åŸå›  |
|---------|----------|------|
| **Incorrect Cases** | æé«˜èŠ‚çœï¼ˆ~90%ï¼‰ | æ¨¡å‹æ— æ³•è§£å†³é—®é¢˜ï¼Œé™·å…¥æ— é™å¾ªç¯ï¼ŒGuardian å¯åŠæ—¶ç»ˆæ­¢ã€‚ |
| **Correct Cases** | ä¸­ç­‰èŠ‚çœï¼ˆ~30â€“60%ï¼‰ | æ­£ç¡®ç­”æ¡ˆå·²ç”Ÿæˆï¼Œä½†æ¨¡å‹ç»§ç»­éªŒè¯å¹¶é—å¿˜ï¼ŒGuardian é˜»æ­¢å†—ä½™ç”Ÿæˆã€‚ |

#### **å¯¹ Full Attention çš„æœ‰æ•ˆæ€§ï¼ˆTable 2ï¼‰**
- å³ä½¿åœ¨ full attention ä¸‹ï¼ŒGuardian ä¹Ÿèƒ½èŠ‚çœ **9.4%â€“18.3%** çš„ tokenã€‚
- è¯´æ˜ **Chain-of-Thought å†—ä½™æ™®éå­˜åœ¨**ï¼Œä¸é™äºç¨€ç–æ³¨æ„åŠ›åœºæ™¯ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **Lil é—®é¢˜æ˜¯ PTSD ç®—æ³•çš„â€œæˆ¿é—´é‡Œçš„å¤§è±¡â€**ï¼š
   - ç¨€ç–æ³¨æ„åŠ›è™½åŠ å¿«å•æ­¥è§£ç ï¼Œä½†å› ä¿¡æ¯ä¸¢å¤±å¯¼è‡´è¾“å‡ºå˜é•¿ï¼Œ**æ€»å»¶è¿Ÿä¸é™åå‡**ã€‚
   - ä¿¡æ¯é‡å»ºè¡¨ç°ä¸ºé‡å¤å†…å®¹ã€å¾ªç¯æ¨ç†ã€æœ€ç»ˆé—å¿˜ç­”æ¡ˆã€‚

2. **å‹ç¼©æ¯”æ˜¯è¡¡é‡ä¿¡æ¯å¢ç›Šçš„æœ‰æ•ˆä»£ç†**ï¼š
   - åˆ©ç”¨ LZ77 å‹ç¼©æ¯”å¯é‡åŒ–ç”Ÿæˆåºåˆ—çš„ä¿¡æ¯å¯†åº¦ã€‚
   - å½“å‹ç¼©é•¿åº¦å¢é•¿è¶‹ç¼“æ—¶ï¼Œä¿¡æ¯å¢ç›Šåœæ»ï¼Œé€‚åˆæ—©åœã€‚

3. **Guardian æ˜¾è‘—ç¼“è§£ Lil é—®é¢˜**ï¼š
   - å¹³å‡èŠ‚çœ **é«˜è¾¾ 90% token**ï¼Œå‡†ç¡®ç‡æŸå¤± <2%ã€‚
   - åœ¨é”™è¯¯æ¡ˆä¾‹ä¸­é˜²æ­¢æ— é™ç”Ÿæˆï¼Œåœ¨æ­£ç¡®æ¡ˆä¾‹ä¸­é˜²æ­¢è¿‡åº¦éªŒè¯ã€‚

4. **Guardian å…·æœ‰æ³›åŒ–èƒ½åŠ›**ï¼š
   - ä¸ä»…é€‚ç”¨äº PTSDï¼Œä¹Ÿé€‚ç”¨äº full attention ä¸‹çš„å†—ä½™ CoT ç”Ÿæˆã€‚
   - å¯è§†ä¸ºä¸€ç§é€šç”¨çš„ **Chain-of-Thought å‹ç¼©æœºåˆ¶**ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **è¯„ä¼°èŒƒå›´æœ‰é™**ï¼š
   - ä»…æµ‹è¯•äº† 3 ä¸ªæ¨¡å‹å’Œ 3 ä¸ªæ•°æ®é›†ï¼Œå¯èƒ½å½±å“ç»“è®ºæ™®é€‚æ€§ã€‚
   - æ›´å¤§ä¸Šä¸‹æ–‡æ¨¡å‹ï¼ˆå¦‚ Qwen2.5-Maxï¼‰æœªè¦†ç›–ã€‚

2. **ä»…é™äº PTSD ç®—æ³•**ï¼š
   - ä¸é€‚ç”¨äºè®­ç»ƒæ„ŸçŸ¥ç¨€ç–æ¶æ„ï¼ˆå¦‚ DeepSeek NSAï¼‰ã€‚

3. **å¯¹å¼±æ¨¡å‹æ•ˆæœæœ‰é™**ï¼š
   - å¦‚ Qwen MoE å› æœ¬èº«ç”ŸæˆçŸ­ä¸”é”™è¯¯å¤šï¼ŒGuardian æ”¶ç›Šå°ã€‚

4. **å‹ç¼©é¢‘ç‡å‚æ•°éœ€è°ƒä¼˜**ï¼š
   - `f=250` å’Œ `t=20` åœ¨å®éªŒä¸­æœ‰æ•ˆï¼Œä½†åœ¨ä¸åŒç¡¬ä»¶æˆ–æ¨¡å‹ä¸Šå¯èƒ½éœ€è°ƒæ•´ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ‰©å±•è‡³æ›´å¹¿æ³›çš„ CoT å†—ä½™åœºæ™¯**ï¼š
   - æ¢ç´¢ Guardian åœ¨ç”±æ•°æ®åå·®ã€äººç±»åå¥½æˆ–å¥–åŠ±é»‘å®¢å¼•èµ·çš„å†—é•¿æ¨ç†ä¸­çš„åº”ç”¨ã€‚

2. **ç»“åˆè®­ç»ƒé˜¶æ®µä¼˜åŒ–**ï¼š
   - å°†æ—©åœä¿¡å·åé¦ˆè‡³è®­ç»ƒè¿‡ç¨‹ï¼Œå­¦ä¹ æ›´ç´§å‡‘çš„æ¨ç†è·¯å¾„ã€‚

3. **åŠ¨æ€è°ƒæ•´å‹ç¼©é¢‘ç‡**ï¼š
   - æ ¹æ®ç”Ÿæˆé˜¶æ®µè‡ªé€‚åº”è°ƒæ•´ `f` å’Œ `t`ï¼Œè¿›ä¸€æ­¥é™ä½å¼€é”€ã€‚

4. **ä¸å…¶ä»– CoT å‹ç¼©æ–¹æ³•å¯¹æ¯”**ï¼š
   - å¦‚ ThinkPruneã€HALT-CoT ç­‰ post-training æ–¹æ³•ï¼Œç³»ç»Ÿæ¯”è¾ƒæ€§èƒ½ä¸æ•ˆç‡ã€‚

---

> **æ€»ç»“**ï¼šæœ¬æ–‡é¦–æ¬¡ç³»ç»Ÿæ­ç¤ºäº† PTSD ç®—æ³•ä¸­çš„ **Lil é—®é¢˜**ï¼Œå¹¶é€šè¿‡ä¿¡æ¯è®ºè§†è§’æå‡º **Guardian æ—©åœç®—æ³•**ï¼Œå®ç°äº†**é«˜æ•ˆã€ä½æŸçš„æ¨ç†å‹ç¼©**ï¼Œä¸ºé•¿åºåˆ—ç”Ÿæˆçš„ä¼˜åŒ–æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 3. [Jenius Agent: Towards Experience-Driven Accuracy Optimization in Real-World Scenarios](https://arxiv.org/abs/2601.01857)

**Authors**: Defei Xia, Bingfeng Pi, Shenbin Zhang, Song Hua, Yunfei Wei, Lei Zuo  
**Category**: cs.AI  
**Published**: 2026-01-07  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2601.01857v1  

#### Abstract
As agent systems powered by large language models (LLMs) advance, improving the task performance of an autonomous agent, especially in context understanding, tool usage, and response generation, has become increasingly critical. Although prior studies have advanced the overall design of LLM-based ag...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å½“å‰åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è‡ªä¸»æ™ºèƒ½ä½“ç³»ç»Ÿåœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **å›ºå®šæç¤ºï¼ˆpromptï¼‰å¯¼è‡´æ„å›¾ç†è§£åå·®**ï¼šé™æ€æˆ–é€šç”¨çš„æç¤ºæ— æ³•é€‚åº”ä»»åŠ¡çŠ¶æ€å˜åŒ–ï¼Œæ˜“é€ æˆè¡Œä¸ºä¸ç¨³å®šå’Œè¾“å‡ºä¸ä¸€è‡´ã€‚
- **å·¥å…·è°ƒç”¨ç¼ºä¹ä¸Šä¸‹æ–‡æ„ŸçŸ¥**ï¼šä¾èµ–é¢„å®šä¹‰å·¥å…·åˆ—è¡¨æˆ–æ‰‹å·¥è§„åˆ™ï¼Œéš¾ä»¥åœ¨æ¨¡ç³Šæˆ–å¤šé¢†åŸŸåœºæ™¯ä¸‹å‡†ç¡®é€‰æ‹©åˆé€‚å·¥å…·ï¼Œå¯¼è‡´æ— æ•ˆæˆ–é”™è¯¯è°ƒç”¨ã€‚
- **é•¿å¯¹è¯ä¸­çš„ä¸Šä¸‹æ–‡å†—ä½™**ï¼šå†å²å¯¹è¯ç´¯ç§¯å¯¼è‡´tokenå¼€é”€å¢åŠ ã€å…³é”®ä¿¡å·ç¨€é‡Šï¼Œå½±å“æ¨ç†è´¨é‡ä¸ç³»ç»Ÿæ•ˆç‡ã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº†æ™ºèƒ½ä½“åœ¨å¤æ‚ã€å¤šè½®ã€çœŸå®ä¸–ç•Œä»»åŠ¡ä¸­çš„å‡†ç¡®æ€§ã€é²æ£’æ€§å’Œå¯æ‰©å±•æ€§ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æœ¬æ–‡æå‡ºäº†ä¸€ç§é¢å‘çœŸå®åœºæ™¯çš„ç»éªŒé©±åŠ¨å‹æ™ºèƒ½ä½“æ¡†æ¶â€”â€”**Jenius-Agent**ï¼ŒåŒ…å«ä¸‰ä¸ªæ ¸å¿ƒä¼˜åŒ–æ¨¡å—ï¼š

#### ï¼ˆ1ï¼‰**è‡ªé€‚åº”æç¤ºç”Ÿæˆï¼ˆAdaptive Prompt Generationï¼‰**
- ç»“åˆè§’è‰²æŒ‡ä»¤ã€ä»»åŠ¡çŠ¶æ€å’Œç”¨æˆ·ä¸Šä¸‹æ–‡åŠ¨æ€ç”Ÿæˆç³»ç»Ÿæç¤ºã€‚
- å¼•å…¥**æ„å›¾åˆ†ç±»æœºåˆ¶**ï¼ˆç¤¾äº¤äº¤äº’ã€åˆ›æ„ç”Ÿæˆã€äº‹å®å›å¿†ã€å·¥å…·å¢å¼ºæ¨ç†ï¼‰ï¼Œæ ¹æ®ä¸åŒç±»åˆ«è°ƒæ•´æ¨ç†ç­–ç•¥ä¸è¾“å‡ºæ ¼å¼ã€‚
- åŠ å…¥å®‰å…¨æ§åˆ¶å±‚ï¼ˆå¦‚é˜²æ­¢å¹»è§‰ã€å‚æ•°éªŒè¯ã€å†…å®¹å®¡æ ¸ï¼‰ï¼Œæå‡å“åº”å¯é æ€§ã€‚

#### ï¼ˆ2ï¼‰**ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å·¥å…·ç¼–æ’ï¼ˆContext-Aware Tool Orchestrationï¼‰**
- å°†æ‰€æœ‰å·¥å…·è¡¨ç¤ºä¸ºé«˜ç»´åµŒå…¥ï¼ˆQwen3 Embeddingï¼‰ï¼Œé€šè¿‡è¯­ä¹‰ç›¸ä¼¼åº¦è¿›è¡Œæ£€ç´¢ã€‚
- è®¾è®¡ä¸‰æ­¥ç­›é€‰æµç¨‹ï¼š
  1. Top-Må€™é€‰æ£€ç´¢ï¼ˆåŸºäºè¯­ä¹‰åŒ¹é…ï¼‰
  2. åŸºäºâ€œæ‹ç‚¹æ£€æµ‹â€ï¼ˆinflection pointï¼‰çš„è¿‡æ»¤ï¼ˆç»“åˆç›¸ä¼¼åº¦è·³è·ƒæ³•ä¸Kneedleç®—æ³•ï¼‰
  3. åŠ¨æ€æˆªæ–­å¹¶è¡¥è¶³è‡³æœ€ä¼˜æ•°é‡ $N = \min(N_{\text{jump}}, N_{\text{kneedle}})$ï¼Œé»˜è®¤ä¿ç•™å‰10ä¸ªç›¸å…³å·¥å…·
- æ”¯æŒMCPåè®®å…¼å®¹çš„å¤–éƒ¨å·¥å…·é›†æˆï¼Œæå‡è·¨ç³»ç»Ÿäº’æ“ä½œæ€§ã€‚

#### ï¼ˆ3ï¼‰**åˆ†å±‚è®°å¿†ç®¡ç†ï¼ˆHierarchical Memory Managementï¼‰**
- **å¯¹è¯çº§å¯¹é½**ï¼šç»´æŠ¤æ¶ˆæ¯åºåˆ—ç»“æ„ï¼ˆHuman â†’ AI â†’ Tool â†’ AIï¼‰ï¼Œä¿®å¤å› å¤±è´¥è°ƒç”¨å¯¼è‡´çš„æ¶ˆæ¯ç¼ºå¤±ã€‚
- **ä¼šè¯çº§å‹ç¼©**ï¼šå½“æ¶ˆæ¯æ€»æ•°è¶…è¿‡é˜ˆå€¼æ—¶ï¼Œå°†æ—©æœŸå†å²æ‘˜è¦ä¸º`SystemMessage`ï¼Œä»…ä¿ç•™æœ€è¿‘ä¸€è½®å®Œæ•´ä¸Šä¸‹æ–‡ã€‚
- é‡‡ç”¨é€’å½’æ‘˜è¦ç­–ç•¥ï¼Œåœ¨å‡å°‘tokenæ¶ˆè€—çš„åŒæ—¶ä¿æŒè¯­ä¹‰è¿è´¯æ€§ã€‚

æ­¤å¤–ï¼ŒJenius-Agentæ•´åˆäº†å®Œæ•´çš„ç«¯åˆ°ç«¯æ¶æ„ï¼Œæ”¯æŒæ–‡ä»¶I/Oã€æ‰§è¡Œåé¦ˆåŠMCPå·¥å…·è°ƒç”¨ï¼Œå·²åœ¨ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ï¼ˆ[jenius.cn](https://www.jenius.cn)ï¼‰ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚AutoGPTã€LangChain Agentsï¼‰ | Jenius-Agent |
|------|----------------------------------------|-------------|
| æç¤ºè®¾è®¡ | å›ºå®šæ¨¡æ¿ï¼Œç¼ºä¹åŠ¨æ€è°ƒæ•´ | è‡ªé€‚åº”ç”Ÿæˆï¼Œèåˆæ„å›¾è¯†åˆ«ä¸å†å²æ„ŸçŸ¥ |
| å·¥å…·é€‰æ‹© | é™æ€åˆ—è¡¨æˆ–ç¡¬ç¼–ç è§„åˆ™ | è¯­ä¹‰æ£€ç´¢ + æ‹ç‚¹è¿‡æ»¤ï¼ŒæŠ—å™ªå£°èƒ½åŠ›å¼º |
| ä¸Šä¸‹æ–‡ç®¡ç† | çª—å£æˆªæ–­æˆ–ç®€å•æ‘˜è¦ | åˆ†å±‚ç»“æ„åŒ–å‹ç¼©ï¼Œä¿ç•™å…³é”®ä¾èµ–å…³ç³» |
| åè®®å…¼å®¹æ€§ | å„è‡ªä¸ºæ”¿ï¼Œæ¥å£ä¸ç»Ÿä¸€ | æ”¯æŒMCPç­‰æ–°å…´é€šä¿¡åè®®ï¼ˆACP, A2Aï¼‰ |
| å®é™…éƒ¨ç½² | å¤šæ•°åœç•™åœ¨ç ”ç©¶åŸå‹ | å·²ä¸Šçº¿è¿è¡Œï¼Œå…·å¤‡å¯è§‚æµ‹æ€§ä¸CI/CDæ”¯æŒ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**

#### ï¼ˆ1ï¼‰**APIGen**ï¼ˆå…¬å¼€åŸºå‡†ï¼‰
- è§„æ¨¡ï¼š60Kæ ·æœ¬ï¼Œè¦†ç›–21ç±»APIè°ƒç”¨ä»»åŠ¡
- ç‰¹ç‚¹ï¼šå•è½®äº¤äº’ï¼Œæ¯ä¸ªå®ä¾‹å«è‡ªç„¶è¯­è¨€æŸ¥è¯¢ã€å€™é€‰APIåˆ—è¡¨ä¸çœŸå®å‡½æ•°è°ƒç”¨
- æœ¬æ–‡æ”¹è¿›ï¼šæ¯æ¡æŸ¥è¯¢æ³¨å…¥100ä¸ªæ— å…³å·¥å…·ï¼Œæ¨¡æ‹Ÿé«˜å™ªå£°ç¯å¢ƒï¼Œæµ‹è¯•å·¥å…·æ£€ç´¢é²æ£’æ€§

#### ï¼ˆ2ï¼‰**Jenius-bench**ï¼ˆæœ¬æ–‡æ„å»ºçš„çœŸå®ä¸–ç•Œå¤šè½®ä»»åŠ¡æ•°æ®é›†ï¼‰
- è§„æ¨¡ï¼š850ä¸ªäººå·¥æ ‡æ³¨æ ·æœ¬ï¼Œæ¶µç›–38ç±»å·¥å…·
- åº”ç”¨åœºæ™¯ï¼šæ—…è¡Œè§„åˆ’ã€ç¥¨åŠ¡é¢„è®¢ã€ç½‘é¡µç”Ÿæˆã€å­¦æœ¯æ£€ç´¢ç­‰
- ç‰¹ç‚¹ï¼š
  - å¤šè½®å¯¹è¯ï¼Œæ”¯æŒçŠ¶æ€æ¼”åŒ–
  - åŒ…å«å®Œæ•´æ‰§è¡Œè½¨è¿¹ï¼ˆå·¥å…·è°ƒç”¨ã€è¾“å…¥å‚æ•°ã€è¿”å›ç»“æœã€ä»£ç†å“åº”ï¼‰
  - å·¥å…·é™„å¸¦ä¸°å¯Œè¯­ä¹‰æè¿°ï¼ˆç›®çš„ã€å‰ææ¡ä»¶ã€ç¤ºä¾‹ï¼‰
  - æ‰€æœ‰è·¯å¾„ç»ä¸“å®¶è¯„å®¡ï¼Œç¡®ä¿æ­£ç¡®æ€§ä¸ä¸€è‡´æ€§

> âœ… å¯¹æ¯”è§è¡¨1ï¼šJenius-benchæ›´è´´è¿‘ç°å®ï¼Œå¼ºè°ƒé“¾å¼æ¨ç†ã€è·¨è½®æ¬¡ä¸Šä¸‹æ–‡ä¸MCPå…¼å®¹æ€§ã€‚

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

#### **è¯„ä¼°æ¡†æ¶ä¸‰å¤§ç»´åº¦**ï¼š
| ç»´åº¦ | æŒ‡æ ‡ä½“ç³» | å†…å®¹ |
|------|---------|------|
| **è¿‡ç¨‹ä¿çœŸåº¦** | **4T Metrics** | TCR, TFR, TIR, TPSï¼ˆè¯¦è§ä¸‹æ–‡ï¼‰ |
| **è¾“å‡ºè´¨é‡** | **CRCFF Metrics** | Correctness, Relevance, Completeness, Fluency, Faithfulnessï¼ˆç”±Qwen/DeepSeekæ‰“åˆ†ï¼‰ |
| **æ•ˆç‡** | **Token Consumption** | è¾“å…¥+è¾“å‡ºtokenæ€»é‡ï¼Œè¡¡é‡è®¡ç®—æˆæœ¬ |

#### **åŸºçº¿æ–¹æ³•å¯¹æ¯”é…ç½®**
| æ¨¡å‹ | æè¿° |
|------|------|
| **Base** | æ ‡å‡†ReActé£æ ¼æ™ºèƒ½ä½“ï¼ˆobserve-think-actå¾ªç¯ï¼‰ |
| **B-P** | Base + è‡ªé€‚åº”æç¤ºç”Ÿæˆ |
| **B-PT** | B-P + ä¸Šä¸‹æ–‡æ„ŸçŸ¥å·¥å…·ç¼–æ’ |
| **Jenius** | å®Œæ•´ç‰ˆï¼šB-PT + åˆ†å±‚è®°å¿†ç®¡ç† |

æ‰€æœ‰æ¨¡å‹å…±äº«ç›¸åŒLLM backboneä¸æ¨ç†åè®®ï¼Œä»…ç»„ä»¶é€æ­¥å åŠ ï¼Œä¾¿äºæ¶ˆèåˆ†æã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **ï¼ˆ1ï¼‰æ‰§è¡Œä¿çœŸåº¦ï¼ˆExecution Fidelityï¼‰**

##### åœ¨ **APIGen** ä¸Šçš„ç»“æœï¼ˆè¡¨2ï¼‰
| Model | TCR â†‘ | TFR â†“ | TIR â†“ | TPS â†‘ |
|-------|-------|-------|-------|-------|
| Base | 0.8150 | 0.1800 | 0.0050 | 0.8150 |
| B-P | 0.8275 | 0.1675 | 0.0050 | 0.8275 |
| B-PT | 0.8375 | 0.1587 | 0.0038 | 0.8375 |
| **Jenius** | **0.8500** | **0.1362** | **0.0138** | **0.8500** |

> ğŸ” æ³¨ï¼šAPIGenæœ¬èº«éš¾åº¦è¾ƒä½ï¼ˆæ¨¡å¼åŒ¹é…ä¸ºä¸»ï¼‰ï¼Œå„æ¨¡å‹è¡¨ç°æ¥è¿‘ï¼Œæå‡æœ‰é™ã€‚

##### åœ¨ **Jenius-bench** ä¸Šçš„ç»“æœï¼ˆè¡¨3ï¼‰
| Model | TCR â†‘ | TFR â†“ | TIR â†“ | TPS â†‘ |
|-------|-------|-------|-------|-------|
| Base | 0.5659 | 0.0329 | 0.4012 | 0.5968 |
| B-P | **0.7271 (+28.5%)** | 0.0859 | 0.1871 | 0.7491 |
| B-PT | 0.7494 | 0.0718 | 0.1788 | 0.7740 |
| **Jenius** | **0.7647 (+35.1%)** | **0.0753** | **0.1600** | **0.7847** |

> âœ… **ç»“è®º**ï¼šåœ¨å¤æ‚å¤šè½®ä»»åŠ¡ä¸­ï¼ŒJeniusæ˜¾è‘—æå‡ä»»åŠ¡å®Œæˆç‡ï¼ˆTCRâ†‘35%ï¼‰ã€é™ä½æœªå®Œæˆç‡ï¼ˆTIRâ†“60%ï¼‰ï¼Œä½“ç°å…¶å¼ºå¤§çš„ä¸Šä¸‹æ–‡å»ºæ¨¡èƒ½åŠ›ã€‚

---

#### **ï¼ˆ2ï¼‰è¾“å‡ºè´¨é‡ï¼ˆCRCFF Metricsï¼‰**ï¼ˆè¡¨4ï¼Œä»…åœ¨Jenius-benchä¸Šè¯„ä¼°ï¼‰

| æ¨¡å‹ | Correctness â†‘ | Relevance â†‘ | Completeness â†‘ | Fluency â†‘ | Faithfulness â†‘ |
|------|---------------|-------------|----------------|-----------|----------------|
| Base | ~0.74 | ~0.91 | ~0.78 | ~0.94 | ~0.81 |
| B-P | â†‘~5â€“8% | â†‘~2â€“3% | â†‘~1â€“2% | â†‘~2â€“3% | â†‘~4â€“5% |
| B-PT | â†‘è¿›ä¸€æ­¥æå‡ | â€” | â†‘æ˜æ˜¾ | â†‘ç¨³å®š | â†‘æŒç»­æ”¹å–„ |
| **Jenius** | **â†‘8â€“10%** | **â†‘~5%** | **â†‘~3â€“4%** | **â†‘~3â€“5%** | **â†‘~6â€“8%** |

> âœ… è‡ªé€‚åº”æç¤ºæå‡**ç›¸å…³æ€§ä¸æµç•…æ€§**ï¼›å·¥å…·ç¼–æ’å¢å¼º**æ­£ç¡®æ€§ä¸å®Œæ•´æ€§**ï¼›åˆ†å±‚è®°å¿†ä¿éšœ**å¿ å®æ€§**ï¼ˆfaithfulnessï¼‰ã€‚

---

#### **ï¼ˆ3ï¼‰Token æ¶ˆè€—åˆ†æ**ï¼ˆå›¾6ï¼‰

| æ•°æ®é›† | Base | Jenius |
|--------|------|--------|
| APIGen | 9.96M | **2.46M**ï¼ˆâ†“75.3%ï¼‰ |
| Jenius-bench | 9.27M | **3.65M**ï¼ˆâ†“60.6%ï¼‰ |

> âœ… æ˜¾è‘—é™ä½tokenå¼€é”€ï¼Œå¾—ç›Šäºï¼š
- è‡ªé€‚åº”æç¤ºå‡å°‘å†—ä½™æ¨ç†
- å·¥å…·æ£€ç´¢é¿å…æ— æ•ˆè°ƒç”¨
- åˆ†å±‚è®°å¿†å‹ç¼©å†å²ä¸Šä¸‹æ–‡

---

### **æ¶ˆèå®éªŒç»“æœ**
ä»Base â†’ B-P â†’ B-PT â†’ Jeniusï¼Œæ¯ä¸€æ¨¡å—å‡å¸¦æ¥æŒç»­å¢ç›Šï¼š
- **B-P** è´¡çŒ®æœ€å¤§æå‡ï¼ˆTCR +16%ï¼‰ï¼Œè¯´æ˜æ„å›¾è¯†åˆ«ä¸æç¤ºä¼˜åŒ–è‡³å…³é‡è¦ï¼›
- **B-PT** è¿›ä¸€æ­¥æå‡ç²¾åº¦ä¸å®Œæ•´æ€§ï¼›
- **Jenius** æœ€ç»ˆå®ç°æœ€ä½³å¹³è¡¡ï¼Œå°¤å…¶åœ¨é•¿ç¨‹ä»»åŠ¡ä¸­ç¨³å®šæ€§æ›´å¼ºã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **ç»éªŒé©±åŠ¨çš„è®¾è®¡ä¼˜äºé™æ€æ¶æ„**ï¼šé€šè¿‡èåˆå®æ—¶ä»»åŠ¡çŠ¶æ€ã€ç”¨æˆ·æ„å›¾ä¸å†å²ä¸Šä¸‹æ–‡ï¼Œèƒ½æ˜¾è‘—æå‡æ™ºèƒ½ä½“çš„è¡Œä¸ºä¸€è‡´æ€§ä¸ä»»åŠ¡æˆåŠŸç‡ã€‚
2. **ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ˜¯å·¥å…·è°ƒç”¨çš„å…³é”®**ï¼šè¯­ä¹‰æ£€ç´¢ + æ‹ç‚¹è¿‡æ»¤æœºåˆ¶æœ‰æ•ˆåº”å¯¹é«˜å™ªå£°ã€å¤šå€™é€‰åœºæ™¯ï¼Œé¿å…â€œç›²ç›®è°ƒç”¨â€ã€‚
3. **åˆ†å±‚è®°å¿†ä¼˜äºç®€å•æˆªæ–­**ï¼šç»“æ„åŒ–æ‘˜è¦æ—¢æ§åˆ¶tokenå¢é•¿ï¼Œåˆä¿ç•™å…³é”®è·¨è½®ä¾èµ–ï¼Œæ”¯æ’‘é•¿æœŸæ¨ç†ã€‚
4. **æ¨¡å—åŒ–è®¾è®¡åˆ©äºå·¥ç¨‹è½åœ°**ï¼šJeniuså·²æˆåŠŸéƒ¨ç½²äºç”Ÿäº§ç¯å¢ƒï¼Œæ”¯æŒå¯è§‚æµ‹æ€§ï¼ˆLangfuseï¼‰ã€è‡ªåŠ¨åŒ–å‘å¸ƒï¼ˆKubernetes + CI/CDï¼‰ä¸å®‰å…¨é€šä¿¡ï¼ˆmTLSï¼‰ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
1. **ä¾èµ–é«˜è´¨é‡å·¥å…·å…ƒæ•°æ®**ï¼šè‹¥å·¥å…·æè¿°ä¸å®Œæ•´æˆ–è¯­ä¹‰æ¨¡ç³Šï¼Œä¼šå½±å“æ£€ç´¢æ•ˆæœã€‚
2. **æ‹ç‚¹æ£€æµ‹å¯¹åˆ†å¸ƒæ•æ„Ÿ**ï¼šæç«¯æƒ…å†µä¸‹å¯èƒ½è¯¯åˆ¤ç›¸å…³æ€§è¾¹ç•Œã€‚
3. **è¯„ä¼°ä»åé‡åŠŸèƒ½æ­£ç¡®æ€§**ï¼šå°šæœªå……åˆ†çº³å…¥ç”¨æˆ·ä½“éªŒã€å†³ç­–æˆæœ¬ã€å»¶è¿Ÿç­‰å› ç´ ã€‚
4. **å¤šæ™ºèƒ½ä½“åä½œæœªæ·±å…¥æ¢ç´¢**ï¼šå½“å‰ä¸ºå•æ™ºèƒ½ä½“æ¶æ„ï¼Œåˆ†å¸ƒå¼ååŒæ½œåŠ›å¾…æŒ–æ˜ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **æ›´çµæ´»çš„è¯„ä¼°ä½“ç³»**ï¼šå…è®¸å¤šç§åˆç†æ‰§è¡Œè·¯å¾„ï¼Œå¼•å…¥ç”¨æˆ·æ»¡æ„åº¦ã€å†³ç­–æ•ˆç‡ç­‰ç°å®æŒ‡æ ‡ã€‚
2. **åŠ¨æ€æ¨¡å—é‡ç»„**ï¼šæ ¹æ®ä»»åŠ¡å¤æ‚åº¦è‡ªåŠ¨å¯ç”¨/å…³é—­æŸäº›ä¼˜åŒ–æ¨¡å—ï¼Œå®ç°èµ„æºè‡ªé€‚åº”ã€‚
3. **å¤šæ™ºèƒ½ä½“åä½œæœºåˆ¶**ï¼šæ„å»ºåŸºäºA2A/MCPåè®®çš„Agent Networkï¼Œå®ç°åˆ†å·¥ä¸ååŒæ±‚è§£ã€‚
4. **å¼ºåŒ–è§£é‡Šæ€§ä¸é€æ˜åº¦**ï¼šæä¾›ä¸­é—´æ¨ç†é“¾ã€å·¥å…·è°ƒç”¨ç†ç”±ï¼Œå¢å¼ºç”¨æˆ·ä¿¡ä»»ã€‚
5. **æŒç»­å­¦ä¹ é—­ç¯**ï¼šåˆ©ç”¨çº¿ä¸Šåé¦ˆè‡ªåŠ¨ä¼˜åŒ–æç¤ºæ¨¡æ¿ã€å·¥å…·ç´¢å¼•ä¸è®°å¿†ç­–ç•¥ã€‚

---

> ğŸ“Œ **æ€»ç»“**ï¼š  
> **Jenius-Agent** æ˜¯ä¸€ä¸ªè½»é‡ã€å¯æ‰©å±•ã€åè®®å…¼å®¹çš„æ™ºèƒ½ä½“æ¡†æ¶ï¼Œé€šè¿‡**è‡ªé€‚åº”æç¤ºã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥å·¥å…·ç¼–æ’ã€åˆ†å±‚è®°å¿†ç®¡ç†**ä¸‰å¤§åˆ›æ–°ï¼Œåœ¨çœŸå®ä¸–ç•Œå¤æ‚ä»»åŠ¡ä¸­å®ç°äº†**20%çš„ä»»åŠ¡å‡†ç¡®ç‡æå‡**ï¼ŒåŒæ—¶å¤§å¹…é™ä½tokenæ¶ˆè€—ä¸å“åº”å»¶è¿Ÿã€‚å…¶å®éªŒè®¾è®¡ä¸¥è°¨ï¼Œè¯„ä¼°å…¨é¢ï¼Œå¹¶å·²å®Œæˆå·¥ä¸šçº§éƒ¨ç½²ï¼Œä¸ºä¸‹ä¸€ä»£è‡ªä¸»æ™ºèƒ½ä½“ç³»ç»Ÿæä¾›äº†é‡è¦çš„å®è·µè“å›¾ã€‚

</details>

---

### 4. [MiMo-V2-Flash Technical Report](https://arxiv.org/abs/2601.02780)

**Authors**: Bangjun Xiao, Bingquan Xia, Bo Yang, Bofei Gao, Bowen Shen, Chen Zhang, Chenhong He, Chiheng Lou, Fuli Luo, Gang Wang, Gang Xie, Hailin Zhang, Hanglong Lv, Hanyu Li, Heyu Chen, Hongshen Xu, Houbin Zhang, Huaqiu Liu, Jiangshan Duo, Jianyu Wei, Jiebao Xiao, Jinhao Dong, Jun Shi, Junhao Hu, Kainan Bao, Kang Zhou, Lei Li, Liang Zhao, Linghao Zhang, Peidian Li, Qianli Chen, Shaohui Liu, Shihua Yu, Shijie Cao, Shimao Chen, Shouqiu Yu, Shuo Liu, Tianling Zhou, Weijiang Su, Weikun Wang, Wenhan Ma, Xiangwei Deng, Bohan Mao, Bowen Ye, Can Cai, Chenghua Wang, Chengxuan Zhu, Chong Ma, Chun Chen, Chunan Li, Dawei Zhu, Deshan Xiao, Dong Zhang, Duo Zhang, Fangyue Liu, Feiyu Yang, Fengyuan Shi, Guoan Wang, Hao Tian, Hao Wu, Heng Qu, Hongfei Yi, Hongxu An, Hongyi Guan, Xing Zhang, Yifan Song, Yihan Yan, Yihao Zhao, Yingchun Lai, Yizhao Gao, Yu Cheng, Yuanyuan Tian, Yudong Wang, Zhen Tang, Zhengju Tang, Zhengtao Wen, Zhichao Song, Zhixian Zheng, Zihan Jiang, Jian Wen, Jiarui Sun, Jiawei Li, Jinlong Xue, Jun Xia, Kai Fang, Menghang Zhu, Nuo Chen, Qian Tu, Qihao Zhang, Qiying Wang, Rang Li, Rui Ma, Shaolei Zhang, Shengfan Wang, Shicheng Li, Shuhao Gu, Shuhuai Ren, Sirui Deng, Tao Guo, Tianyang Lu, Weiji Zhuang, Weikang Zhang, Weimin Xiong, Wenshan Huang, Wenyu Yang, Xin Zhang, Xing Yong, Xu Wang, Xueyang Xie, Yilin Jiang, Yixin Yang, Yongzhe He, Yu Tu, Yuanliang Dong, Yuchen Liu, Yue Ma, Yue Yu, Yuxing Xiang, Zhaojun Huang, Zhenru Lin, Zhipeng Xu, Zhiyang Chen, Zhonghua Deng, Zihan Zhang, Zihao Yue  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2601.02780v1  

#### Abstract
We present MiMo-V2-Flash, a Mixture-of-Experts (MoE) model with 309B total parameters and 15B active parameters, designed for fast, strong reasoning and agentic capabilities. MiMo-V2-Flash adopts a hybrid attention architecture that interleaves Sliding Window Attention (SWA) with global attention, w...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# MiMo-V2-Flash Technical Report æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¤§æ¨¡å‹åœ¨å®ç°**å¼ºæ¨ç†èƒ½åŠ›**å’Œ**æ™ºèƒ½ä½“ï¼ˆagenticï¼‰è¡Œä¸º**çš„åŒæ—¶ï¼Œé¢ä¸´ä¸¤å¤§ç“¶é¢ˆï¼š
- **é•¿ä¸Šä¸‹æ–‡å»ºæ¨¡æ•ˆç‡ä½**ï¼šå…¨æ³¨æ„åŠ›æœºåˆ¶ï¼ˆFull Attentionï¼‰è®¡ç®—å¤æ‚åº¦ä¸º $O(n^2)$ï¼Œå¯¼è‡´é•¿åºåˆ—æ¨ç†é€Ÿåº¦æ…¢ã€æ˜¾å­˜å ç”¨é«˜ã€‚
- **åè®­ç»ƒï¼ˆpost-trainingï¼‰æ‰©å±•æ€§å·®**ï¼šä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒå­˜åœ¨â€œè··è··æ¿æ•ˆåº”â€ï¼ˆcapability imbalanceï¼‰ï¼Œå³æå‡æŸä¸€é¢†åŸŸèƒ½åŠ›å¸¸å¯¼è‡´å…¶ä»–é¢†åŸŸé€€åŒ–ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

#### ï¼ˆ1ï¼‰**æ··åˆæ»‘åŠ¨çª—å£æ³¨æ„åŠ›æ¶æ„ï¼ˆHybrid Sliding Window Attention, SWAï¼‰**
- é‡‡ç”¨ **5:1 çš„å±€éƒ¨-å…¨å±€æ³¨æ„åŠ›æ¯”ä¾‹**ï¼Œæ¯5å±‚ Sliding Window Attentionï¼ˆSWAï¼‰åæ¥1å±‚ Global Attentionï¼ˆGAï¼‰ã€‚
- æ»‘åŠ¨çª—å£å¤§å°è®¾ä¸º **128 tokens**ï¼Œæ˜¾è‘—é™ä½ KV Cache å­˜å‚¨å’Œæ³¨æ„åŠ›è®¡ç®—å¼€é”€ã€‚
- å¼•å…¥ **å¯å­¦ä¹ çš„ attention sink bias** æ¥ç¼“è§£å°çª—å£å¸¦æ¥çš„ä¿¡æ¯ä¸¢å¤±é—®é¢˜ï¼Œå¢å¼ºé•¿ç¨‹ä¾èµ–å»ºæ¨¡èƒ½åŠ›ã€‚

#### ï¼ˆ2ï¼‰**è½»é‡çº§å¤šä»¤ç‰Œé¢„æµ‹æ¨¡å—ï¼ˆLightweight Multi-Token Prediction, MTPï¼‰**
- åœ¨é¢„è®­ç»ƒä¸­å¼•å…¥ MTP ä½œä¸ºè¾…åŠ©ç›®æ ‡ï¼Œæå‡è®­ç»ƒæ•ˆç‡ã€‚
- æ¨ç†é˜¶æ®µå°† MTP æ¨¡å—ç”¨ä½œ **Speculative Decoding çš„è‰ç¨¿æ¨¡å‹ï¼ˆdraft modelï¼‰**ï¼Œå®ç°é«˜è¾¾ **3.6 çš„å¹³å‡æ¥å—é•¿åº¦** å’Œ **2.6x çš„è§£ç åŠ é€Ÿ**ã€‚
- MTP æ¨¡å—è®¾è®¡ä¸ºè½»é‡åŒ–ç»“æ„ï¼ˆä½¿ç”¨ Dense FFN + SWAï¼‰ï¼Œé¿å…æˆä¸ºæ–°çš„æ¨ç†ç“¶é¢ˆã€‚

#### ï¼ˆ3ï¼‰**å¤šæ•™å¸ˆåœ¨çº¿ç­–ç•¥è’¸é¦èŒƒå¼ï¼ˆMulti-Teacher On-Policy Distillation, MOPDï¼‰**
- ä¸€ç§å…¨æ–°çš„åè®­ç»ƒæ¡†æ¶ï¼Œåˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼š
  1. **é€šç”¨ SFT**ï¼šå»ºç«‹åŸºç¡€æŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼›
  2. **é¢†åŸŸä¸“ç”¨ RL/SFT**ï¼šè®­ç»ƒå¤šä¸ªé¢†åŸŸä¸“å®¶æ•™å¸ˆæ¨¡å‹ï¼ˆå¦‚æ•°å­¦ã€ç¼–ç ã€æœç´¢ç­‰ï¼‰ï¼›
  3. **MOPD è’¸é¦**ï¼šå­¦ç”Ÿæ¨¡å‹é€šè¿‡åœ¨çº¿é‡‡æ ·ï¼Œä»å¤šä¸ªæ•™å¸ˆå¤„è·å– token-level çš„ KL æ•£åº¦å¥–åŠ±ä¿¡å·ï¼Œèåˆå„é¢†åŸŸæœ€å¼ºèƒ½åŠ›ã€‚
- ä¼˜åŠ¿ï¼šé¿å…ç¦»çº¿æ•°æ®è’¸é¦ä¸­çš„åˆ†å¸ƒåç§»é—®é¢˜ï¼Œæ”¯æŒèƒ½åŠ›å…±è¿›åŒ–ï¼ˆco-evolutionï¼‰ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | MiMo-V2-Flash | å¯¹æ¯”æ¨¡å‹ï¼ˆå¦‚ DeepSeek-V3.2ã€Kimi-K2ï¼‰ |
|------|----------------|----------------------------------------|
| å‚æ•°æ€»é‡ | **309B** | 671B ~ 1043B |
| æ¿€æ´»å‚æ•° | **15B / token** | 37B ~ 32B / token |
| é•¿ä¸Šä¸‹æ–‡æ•ˆç‡ | æ˜¾è‘—æ›´ä½çš„ KV Cache å ç”¨ï¼ˆè¿‘6å€å‡å°‘ï¼‰ | å…¨æ³¨æ„åŠ›æ¶æ„ï¼ŒKV å¼€é”€æ›´é«˜ |
| æ¨ç†é€Ÿåº¦ | MTP åŠ é€Ÿä¸‹æœ€é«˜è¾¾ **2.6x è§£ç æé€Ÿ** | æ— ç±»ä¼¼æœºåˆ¶ |
| åè®­ç»ƒçµæ´»æ€§ | MOPD æ”¯æŒæ¨¡å—åŒ–é›†æˆå¤šä¸ªæ•™å¸ˆ | å¤šä¸ºä¸²è¡Œæˆ–å¤šä»»åŠ¡è”åˆè®­ç»ƒ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†

#### é¢„è®­ç»ƒæ•°æ®
- æ€»è®¡ **27ä¸‡äº¿ tokens**ï¼Œæ¶µç›–é«˜è´¨é‡ç½‘é¡µã€ä¹¦ç±ã€å­¦æœ¯è®ºæ–‡ã€ä»£ç ã€STEM å†…å®¹ã€‚
- ç‰¹åˆ«å¼ºè°ƒé•¿è·ç¦»ä¾èµ–æ•°æ®ï¼ˆå¦‚å®Œæ•´ä»“åº“ä»£ç ã€PRã€commit historyï¼‰ä»¥å¢å¼ºæ¨ç†èƒ½åŠ›ã€‚

#### è¯„ä¼°åŸºå‡†
| ç±»åˆ« | ä¸»è¦æ•°æ®é›† |
|------|-----------|
| **é€šç”¨ç†è§£ä¸æ¨ç†** | MMLU, BBH, TriviaQA, DROP, ARC, HellaSwag, WinoGrande |
| **æ•°å­¦æ¨ç†** | GSM8K, MATH, AIME2024/25, HMMT Feb.2025 |
| **ç¼–ç¨‹èƒ½åŠ›** | HumanEval+, MBPP+, CRUXEval, BigCodeBench, LiveCodeBench, SWE-Benchï¼ˆVerified & Multilingualï¼‰ |
| **ä¸­æ–‡ç†è§£** | C-Eval, CMMLU, C-SimpleQA |
| **å¤šè¯­è¨€èƒ½åŠ›** | GlobalMMLU, INCLUDE |
| **é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›** | NIAH-Multi, GSM-Infinite, LongBench V2, MRCR |
| **æ™ºèƒ½ä½“ä»»åŠ¡** | SWE-Bench, Terminal-Bench, BrowseComp, Ï„Â²-Bench |

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **ä¸Šä¸‹æ–‡é•¿åº¦**ï¼šåŸç”Ÿæ”¯æŒ **32K**ï¼Œæ‰©å±•è‡³ **256K**ã€‚
- **è®­ç»ƒç²¾åº¦**ï¼šFP8 æ··åˆç²¾åº¦è®­ç»ƒï¼Œæé«˜æ•ˆç‡å¹¶ä¿æŒç¨³å®šæ€§ã€‚
- **è¯„ä¼°æ–¹å¼**ï¼š
  - Zero-shot / Few-shot å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰
  - SWE-Bench ä½¿ç”¨ **Verified Pass@1** æŒ‡æ ‡
  - æ¨ç†é€Ÿåº¦æµ‹è¯•åŸºäº **16K è¾“å…¥ + 1K è¾“å‡ºé•¿åº¦**
  - MTP æ€§èƒ½ä»¥ **Acceptance Length** å’Œ **Decoding Speedup** è¡¡é‡

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **å¼€æºæ¨¡å‹**ï¼š
  - DeepSeek-V3.2-Thinking / Base
  - Kimi-K2-Thinking / Base
- **é—­æºæ¨¡å‹**ï¼š
  - Claude Sonnet 4.5
  - GPT-5 (High)
  - Gemini 3.0 Pro

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 9ï¼‰

| åŸºå‡† | MiMo-V2-Flash | æœ€ä¼˜åŸºçº¿ | ç»“æœåˆ†æ |
|------|---------------|----------|---------|
| **MMLU-Pro** | **84.9** | Kimi-K2 (84.6) | è¶…è¶ŠåŒç±»å¼€æºæ¨¡å‹ |
| **GPQA-Diamond** | 84.3 | Claude (91.9) | æ¥è¿‘é¡¶çº§é—­æºæ¨¡å‹ |
| **AIME 2025** | **94.1** | Kimi-K2 (94.5) | æ¥è¿‘æœ€ä¼˜æ°´å¹³ |
| **LiveCodeBench** | **85.1** | Kimi-K2 (83.1) | æ˜¾è‘—é¢†å…ˆ |
| **SWE-Bench Verified** | **73.4%** | GPT-5-High (74.9%) | å½“å‰æœ€ä½³å¼€æºè¡¨ç° |
| **SWE-Bench Multilingual** | **71.7%** | DeepSeek-V3.2 (70.2%) | é¦–æ¬¡çªç ´ 70%ï¼Œé¢†å…ˆæ˜æ˜¾ |
| **LongBench V2** | **60.6** | Claude (65.6) | è¶…è¶Š Kimi-K2ï¼ˆ48.1ï¼‰ |
| **MRCR (long-context retrieval)** | **45.7** | Claude (89.7) | è¡¨ç°ç¨³å¥ï¼Œä¼˜äºå¤šæ•°åŸºçº¿ |

> æ³¨ï¼šå°½ç®¡éƒ¨åˆ†æŒ‡æ ‡ä»ç•¥ä½äºæœ€å¼ºé—­æºæ¨¡å‹ï¼ˆå¦‚ Claudeã€GPT-5ï¼‰ï¼Œä½†åœ¨**ä»…ä½¿ç”¨ 1/2~1/3 å‚æ•°é‡**çš„æƒ…å†µä¸‹è¾¾åˆ°æ¥è¿‘ç”šè‡³è¶…è¶Šå¤šæ•°å¼€æºæ¨¡å‹çš„è¡¨ç°ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- MiMo-V2-Flash åœ¨ **SWE-Bench Verified** ä¸Šè¶…è¿‡ Kimi-K2-Thinkingï¼ˆ71.3 â†’ 73.4ï¼‰ï¼Œä¸”è¿œè¶… DeepSeek-V3.2ï¼ˆ73.1ï¼‰ã€‚
- åœ¨ **AIME 2025** æ•°å­¦ç«èµ›ä»»åŠ¡ä¸Šè¾¾åˆ° 94.1ï¼Œä»…æ¬¡äº Kimi-K2ï¼ˆ94.5ï¼‰ï¼Œæ˜¾è‘—é«˜äº DeepSeek-V3.2ï¼ˆ93.1ï¼‰ã€‚
- åœ¨ **æ¨ç†é€Ÿåº¦æ–¹é¢**ï¼Œåˆ©ç”¨ MTP å®ç° **æœ€é«˜ 2.6x è§£ç åŠ é€Ÿ**ï¼ˆè§ Table 10ï¼‰ï¼Œåœ¨ batch size=64ã€accept length=3.6 æ—¶å¯è¾¾ 2.53xã€‚
- åœ¨ **é•¿ä¸Šä¸‹æ–‡æ£€ç´¢ä»»åŠ¡ NIAH-Multi** ä¸­ï¼Œ32K~128K ä¸ŠæˆåŠŸç‡æ¥è¿‘ 100%ï¼Œæ˜¾è‘—ä¼˜äº DeepSeek-V3.2-Exp Baseã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 2â€“4ï¼‰

| æ¶æ„å˜ä½“ | MMLU | GSM8K | AIME25 | GSM-Infinite |
|--------|------|-------|--------|-------------|
| All GA | 57.3 | 34.2 | 45.5 | 12.3 |
| Hybrid SWA (W=128, w/o sink) | 54.9 | 36.9 | 47.1 | 17.3 |
| Hybrid SWA (W=128, w/ sink) | **58.3** | **36.9** | **47.1** | **17.3** |
| Hybrid SWA (W=512, w/ sink) | 58.3 | 37.9 | 46.3 | 17.2 |

**å…³é”®å‘ç°**ï¼š
- **Attention Sink è‡³å…³é‡è¦**ï¼šä¸åŠ  sink ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ï¼›åŠ å…¥åå…¨é¢åè¶… All-GAã€‚
- **å°çª—å£æ›´ä¼˜**ï¼šW=128 æ¯” W=512 åœ¨é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ï¼ˆGSM-Infiniteï¼‰ä¸­è¡¨ç°æ›´å¥½ï¼Œè¯´æ˜æ›´ä¸¥æ ¼çš„å±€éƒ¨çº¦æŸåè€Œæœ‰åŠ©äºåˆ†å·¥æ˜ç¡®ï¼ˆSWA å¤„ç†å±€éƒ¨ï¼ŒGA å¤„ç†å…¨å±€ï¼‰ã€‚
- **æ¨ç†èƒ½åŠ›æ›´å¼º**ï¼šHybrid SWA (W=128) åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ï¼ˆAIME, GPQAï¼‰ä¸Šä¼˜äº All-GAã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **é«˜æ•ˆçš„æ··åˆæ³¨æ„åŠ›æ¶æ„å¯è¡Œä¸”ä¼˜è¶Š**ï¼š
   - å³ä½¿ä½¿ç”¨æå°çš„æ»‘åŠ¨çª—å£ï¼ˆ128 tokensï¼‰å’Œé«˜æ¯”ä¾‹ SWAï¼ˆ5:1ï¼‰ï¼Œé…åˆ attention sink ä¹Ÿèƒ½å®ç°ç”šè‡³è¶…è¶Šå…¨æ³¨æ„åŠ›æ¨¡å‹çš„æ€§èƒ½ã€‚
   - å°çª—å£å¸¦æ¥æ­£åˆ™åŒ–æ•ˆæœï¼Œä¿ƒè¿›å±€éƒ¨ä¸å…¨å±€æ³¨æ„åŠ›çš„èŒè´£åˆ†ç¦»ã€‚

2. **MTP ä¸ä»…æ˜¯è®­ç»ƒæŠ€å·§ï¼Œæ›´æ˜¯æ¨ç†åŠ é€Ÿåˆ©å™¨**ï¼š
   - åˆ©ç”¨ MTP ä½œä¸º speculative decoding çš„ draft modelï¼Œå¯åœ¨æ— éœ€é¢å¤–ç¡¬ä»¶æˆæœ¬ä¸‹å®ç° **é«˜è¾¾ 2.6x çš„è§£ç åŠ é€Ÿ**ã€‚
   - æ¥å—é•¿åº¦ä¸ next-token entropy å‘ˆå¼ºè´Ÿç›¸å…³ï¼ˆ$R^2=0.995$ï¼‰ï¼Œè¡¨æ˜ä¸ç¡®å®šæ€§è¶Šä½çš„ä»»åŠ¡è¶Šé€‚åˆ MTP åŠ é€Ÿã€‚

3. **MOPD æˆåŠŸè§£å†³â€œèƒ½åŠ›å¤±è¡¡â€é—®é¢˜**ï¼š
   - å­¦ç”Ÿæ¨¡å‹åœ¨å¤§å¤šæ•°ä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€å¼ºæ•™å¸ˆçš„æ°´å¹³ï¼Œç”šè‡³ç•¥æœ‰è¶…è¶Šï¼ˆå¦‚ AIME +0.2, Tau2-Bench +0.7ï¼‰ã€‚
   - å®ç°äº†â€œä¸€ä¸ªæ¨¡å‹æŒæ¡å¤šä¸ªä¸“å®¶æŠ€èƒ½â€çš„ç»Ÿä¸€æ™ºèƒ½ä½“ç›®æ ‡ã€‚

4. **MiMo-V2-Flash æ˜¯å½“å‰æœ€å¼ºå¼€æºè½¯ä»¶å·¥ç¨‹æ¨¡å‹**ï¼š
   - åœ¨ SWE-Bench Verified å’Œ Multilingual ä¸Šå‡å–å¾— SOTA è¡¨ç°ï¼ŒéªŒè¯äº†å¤§è§„æ¨¡ agentic RL çš„æœ‰æ•ˆæ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **çŸ¥è¯†å®¹é‡å—é™**ï¼šç”±äºæ€»å‚æ•°é‡ç›¸å¯¹è¾ƒå°ï¼Œåœ¨ SimpleQA ç­‰çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸Šå¾—åˆ†è¾ƒä½ï¼ˆ20.6 vs GPT-5 >35ï¼‰ã€‚
- **åˆ›æ„å†™ä½œèƒ½åŠ›ç¨å¼±**ï¼šArena-Hard åˆ›æ„å†™ä½œå¾—åˆ†ä¸º 86.2ï¼Œä½äº Kimi-K2ï¼ˆ88.8ï¼‰å’Œ Claudeï¼ˆ93.6ï¼‰ã€‚
- **æ¶æ„æ¢ç´¢å°šæµ…**ï¼šç›®å‰å¯¹ SWA/GA æ¯”ä¾‹ã€çª—å£å¤§å°çš„è®¾è®¡ä»å±åˆæ­¥å°è¯•ï¼Œæœªè¿›è¡Œç³»ç»Ÿæ€§æœç´¢ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å¤§æ¨¡å‹è§„æ¨¡**ï¼šé€šè¿‡å¢åŠ å‚æ•°é‡ç¼©å°ä¸æœ€å¼ºé—­æºæ¨¡å‹ï¼ˆå¦‚ GPT-5ï¼‰ä¹‹é—´çš„å·®è·ã€‚
2. **æ·±å…¥ä¼˜åŒ–æ··åˆæ³¨æ„åŠ›æ¶æ„**ï¼šæ¢ç´¢æ›´ä¼˜çš„ SWA/GA æ¯”ä¾‹ã€åŠ¨æ€çª—å£æœºåˆ¶ã€éå‡åŒ€æ³¨æ„åŠ›åˆ†é…ã€‚
3. **è¿­ä»£å¼ MOPD å…±è¿›åŒ–**ï¼šå°†è’¸é¦åçš„å­¦ç”Ÿé‡æ–°æŠ•å…¥ RL è®­ç»ƒç”Ÿæˆæ›´å¼ºæ•™å¸ˆï¼Œå½¢æˆé—­ç¯æå‡å¾ªç¯ã€‚
4. **å·¥å…·è°ƒç”¨ä¸ä¸Šä¸‹æ–‡ç®¡ç†ä¼˜åŒ–**ï¼šè¿›ä¸€æ­¥ç ”ç©¶å¦‚ä½•é«˜æ•ˆç®¡ç†è¶…é•¿ä¸Šä¸‹æ–‡ä¸­çš„å·¥å…·å†å²ä¸è®°å¿†å‹ç¼©ï¼ˆå‚è€ƒ Appendix Cï¼‰ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> MiMo-V2-Flash é€šè¿‡ **Hybrid SWA + Lightweight MTP + MOPD** ä¸‰å¤§æŠ€æœ¯åˆ›æ–°ï¼Œåœ¨ä»… 309B æ€»å‚æ•°ä¸‹å®ç°äº†åª²ç¾æ›´å¤§æ¨¡å‹çš„æ¨ç†ä¸æ™ºèƒ½ä½“èƒ½åŠ›ï¼Œå¹¶é¦–æ¬¡åœ¨ SWE-Bench ä¸Šç¡®ç«‹äº†å¼€æºæ¨¡å‹çš„é¢†å…ˆåœ°ä½ï¼ŒåŒæ—¶å¼€æºæ¨¡å‹æƒé‡æ¨åŠ¨ç¤¾åŒºå‘å±•ã€‚

</details>

---

### 5. [Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling](https://arxiv.org/abs/2601.02346)

**Authors**: Falcon LLM Team, Iheb Chaabane, Puneesh Khanna, Suhail Mohmad, Slim Frikha, Shi Hu, Abdalgader Abubaker, Reda Alami, Mikhail Lubinets, Mohamed El Amine Seddik, Hakim Hacid  
**Category**: cs.AI  
**Published**: 2026-01-07  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2601.02346v1  

#### Abstract
This work introduces Falcon-H1R, a 7B-parameter reasoning-optimized model that establishes the feasibility of achieving competitive reasoning performance with small language models (SLMs). Falcon-H1R stands out for its parameter efficiency, consistently matching or outperforming SOTA reasoning model...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½æå‡ä¾èµ–äºå¤§è§„æ¨¡è®­ç»ƒï¼ˆscaling trainingï¼‰ï¼Œä½†è¿™ç§æ–¹æ³•é¢ä¸´è®¡ç®—æˆæœ¬é«˜æ˜‚ã€é«˜è´¨é‡äººç±»æ ‡æ³¨æ•°æ®ç¨€ç¼ºç­‰ç“¶é¢ˆã€‚åŒæ—¶ï¼Œ**Test-Time Scaling (TTS)** è™½ç„¶èƒ½é€šè¿‡ç”Ÿæˆå¤šä¸ªæ¨ç†é“¾å¹¶èšåˆç»“æœæ¥æå‡å‡†ç¡®æ€§ï¼Œä½†ä¹Ÿå¸¦æ¥äº†æé«˜çš„æ¨ç†å¼€é”€ã€‚

æœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ä»¥ä¸‹æ ¸å¿ƒæŒ‘æˆ˜ï¼š
- å¦‚ä½•åœ¨ä¸æ˜¾è‘—å¢åŠ æ¨¡å‹å‚æ•°è§„æ¨¡çš„å‰æä¸‹ï¼Œå®ç°ä¸æ›´å¤§æ¨¡å‹ç›¸å½“ç”šè‡³æ›´ä¼˜çš„æ¨ç†èƒ½åŠ›ã€‚
- å¦‚ä½•è®¾è®¡ä¸€ä¸ªé«˜æ•ˆæ¶æ„å’Œè®­ç»ƒæµç¨‹ï¼Œä½¿å°æ¨¡å‹ï¼ˆSLMï¼‰åœ¨ TTS åœºæ™¯ä¸‹å…¼å…·é«˜å‡†ç¡®ç‡ã€ä½ token æ¶ˆè€—å’Œå¿«é€Ÿæ¨ç†é€Ÿåº¦ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº† **Falcon-H1R-7B**ï¼Œä¸€ä¸ªä¸“ä¸ºé«˜æ•ˆæ¨ç†ä¼˜åŒ–çš„ 7B å‚æ•°æ··åˆæ¶æ„è¯­è¨€æ¨¡å‹ï¼Œå…¶ä¸»è¦åˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰Hybrid Transformer-Mamba æ¶æ„ï¼ˆFalcon-H1ï¼‰
- é‡‡ç”¨ **Transformer-SSMï¼ˆState Space Modelï¼‰æ··åˆæ¶æ„**ï¼Œç»“åˆäº† Transformer çš„å¼ºå¤§è¡¨è¾¾èƒ½åŠ›å’Œ Mamba åœ¨é•¿åºåˆ—å»ºæ¨¡ä¸­çš„çº¿æ€§æ—¶é—´æ•ˆç‡ã€‚
- è¯¥æ¶æ„æ”¯æŒé«˜è¾¾ 256K çš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œå¹¶åœ¨å¤§æ‰¹æ¬¡ã€é•¿è¾“å‡ºåœºæ™¯ä¸‹è¡¨ç°å‡ºè‰²ï¼Œç‰¹åˆ«é€‚åˆéœ€è¦å¤§é‡ Chain-of-Thought æ¨ç†çš„ TTS æ–¹æ³•ã€‚

#### ï¼ˆ2ï¼‰ä¸¤é˜¶æ®µç²¾ç»†åŒ–è®­ç»ƒç­–ç•¥
- **Cold-start SFTï¼ˆSupervised Fine-Tuningï¼‰**ï¼š
  - ä½¿ç”¨é«˜è´¨é‡ã€å¤šæ ·åŒ–çš„é•¿æ¨ç†è½¨è¿¹æ•°æ®ï¼ˆæ•°å­¦ã€ä»£ç ã€ç§‘å­¦ç­‰ï¼‰è¿›è¡Œç›‘ç£å¾®è°ƒã€‚
  - å¼•å…¥ **difficulty-aware weighting**ï¼šå¯¹éš¾é¢˜æ ·æœ¬åŠ æƒï¼Œæ˜“é¢˜é™æƒæˆ–å‰”é™¤ï¼Œæå‡æ¨¡å‹å¤„ç†éš¾é—®é¢˜çš„èƒ½åŠ›ã€‚
  - éªŒè¯å‘ç°ï¼š**æ›´é«˜çš„ rollout countï¼ˆn=12ï¼‰æœ‰åŠ©äºå­¦ä¹ å¤šæ ·åŒ–è§£æ³•è·¯å¾„**ï¼›è€Œå¤šæ•™å¸ˆæ··åˆåè€Œé™ä½æ€§èƒ½ï¼ˆsingle-teacher æ›´ä¼˜ï¼‰ã€‚

- **Reinforcement Learning with Verifiable Rewards (RLVR)**ï¼š
  - åŸºäº GRPOï¼ˆGroup Relative Policy Optimizationï¼‰æ¡†æ¶è¿›è¡Œå¼ºåŒ–å­¦ä¹ ã€‚
  - è®¾è®¡é¢†åŸŸç‰¹å®šå¥–åŠ±å‡½æ•°ï¼ˆmath/code/scienceï¼‰ï¼Œç¡®ä¿ä¿¡å·å¯é ã€‚
  - å¼•å…¥ **backfill + caching æœºåˆ¶** æé«˜é‡‡æ ·æ•ˆç‡ï¼Œå‡å°‘çº¦ 30% çš„å†—ä½™ç”Ÿæˆã€‚
  - æœ€ç»ˆæ¨¡å‹åœ¨ä¿æŒé«˜ entropy çš„åŒæ—¶ç¨³å®šæå‡ pass@1 æ€§èƒ½ã€‚

#### ï¼ˆ3ï¼‰é¢å‘ Test-Time Scaling çš„æè‡´ä¼˜åŒ–
- å°† Falcon-H1R ä¸æœ€æ–°çš„ **DeepConf@512** æ–¹æ³•ç»“åˆï¼ŒåŠ¨æ€åŸºäºç½®ä¿¡åº¦å‰ªæä½è´¨é‡æ¨ç†é“¾ã€‚
- åˆ©ç”¨æ¨¡å‹è‰¯å¥½çš„ confidence calibration å®ç° aggressive early stoppingï¼Œå¤§å¹…èŠ‚çœ token å¼€é”€è€Œä¸ç‰ºç‰²ç²¾åº¦ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | Falcon-H1R-7B çš„ä¼˜åŠ¿ |
|------|------------------------|
| **å‚æ•°æ•ˆç‡** | ä»… 7B å‚æ•°ï¼Œæ€§èƒ½è¶…è¶Š 8Bâ€“32B çš„ SOTA æ¨¡å‹ï¼ˆå¦‚ Qwen3-32Bã€Phi-4-R-Plus-14Bï¼‰ |
| **æ¨ç†æ•ˆç‡** | æ··åˆæ¶æ„å¸¦æ¥æ›´å¿«çš„ inference throughputï¼Œå°¤å…¶åœ¨ batch size > 32 å’Œ output length > 16K æ—¶é¢†å…ˆæ˜æ˜¾ |
| **token æ•ˆç‡** | åœ¨ DeepConf è®¾ç½®ä¸‹ token usage æ˜¾è‘—ä½äºåŸºçº¿ï¼ˆä¾‹å¦‚åœ¨ AIME25 ä¸Šå‡å°‘ 38%ï¼‰ |
| **å‡†ç¡®æ€§** | å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ° SOTA æˆ–æ¥è¿‘ SOTA æ°´å¹³ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼š

#### SFT é˜¶æ®µ
- **æ•°å­¦**ï¼šMATHã€AIMEã€HMMTã€AMO-Bench ç­‰ç«èµ›çº§é¢˜ç›®
- **ä»£ç **ï¼šLeetCodeã€AtCoderã€Codeforces æ¥æºçš„ç®—æ³•é¢˜
- **ç§‘å­¦**ï¼šSTEM é¢†åŸŸå¤šè·³æ¨ç†é—®é¢˜
- **å…¶ä»–**ï¼šé€šç”¨å¯¹è¯ã€æŒ‡ä»¤è·Ÿéšã€å·¥å…·è°ƒç”¨ç­‰
- æ•°æ®æ€»é‡ï¼šçº¦ 3.1M æ ·æœ¬ï¼Œæ¶µç›– 220k â€œOtherâ€ã€310k Scienceã€840k Codeã€1.74M Math

#### RL é˜¶æ®µ
- å®Œå…¨ç‹¬ç«‹äº SFT æ•°æ®ï¼Œé˜²æ­¢è®°å¿†åŒ–
- æ•°å­¦ä¸ä»£ç ä¸ºä¸»ï¼Œç»è¿‡ä¸¥æ ¼éš¾åº¦ç­›é€‰ï¼ˆå»é™¤å¤ªç®€å•æˆ–å®Œå…¨æ— æ³•æ±‚è§£çš„é—®é¢˜ï¼‰
- ä½¿ç”¨ pass rateï¼ˆ8 æ¬¡ rollout æ­£ç¡®ç‡ï¼‰ä½œä¸ºéš¾åº¦ä»£ç†æŒ‡æ ‡

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### è¯„ä¼°åŸºå‡†åˆ†ç±»
| ç±»åˆ« | åŸºå‡†åç§° |
|------|---------|
| **æ•°å­¦** | AIME24, AIME25, HMMT25, AMO-Bench, MATH500 |
| **ä»£ç ** | LiveCodeBench v6, SciCode, T2-Telecom, Terminal Bench Hard |
| **é€šç”¨æ¨ç†** | GPQA-Diamond, MMLU-Pro, Humanity's Last Exam (HLE), IFBench |

#### è¯„ä¼°æ–¹å¼
- æ‰€æœ‰ç»“æœæŠ¥å‘Š **pass@1**
- å¤šæ•°ä»»åŠ¡ä½¿ç”¨ `temperature=0.6`, `top_p=0.95`
- å¯¹äº TTS å®éªŒï¼Œä½¿ç”¨ **DeepConf@512** æ–¹æ³•ï¼š
  - å›ºå®š trace budget K=512
  - å‰ 16 æ¡ç”¨äºç¡®å®šç½®ä¿¡é˜ˆå€¼
  - åç»­ç”Ÿæˆè¿‡ç¨‹ä¸­è‹¥ group confidence ä¸‹é™åˆ™æå‰ç»ˆæ­¢

#### åŸºçº¿å¯¹æ¯”æ¨¡å‹
- **7B çº§åˆ«**ï¼šQwen3-8B, DeepSeek-R1-0528-Qwen3-8B
- **14Bâ€“20B çº§åˆ«**ï¼šPhi-4-Reasoning-Plus-14B, Apriel-1.5-15b-Thinker, GPT-OSS-20B
- **32B åŠä»¥ä¸Š**ï¼šQwen3-32B, Nemotron-H-47B-Reasoning

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Tables 4â€“6ï¼‰

#### æ•°å­¦æ¨ç†è¡¨ç°ï¼ˆTable 4ï¼‰
| æ¨¡å‹ | AIME24 | AIME25 | HMMT25 | AMO-Bench | MATH500 |
|------|--------|--------|--------|-----------|---------|
| **Falcon-H1R-7B** | **88.1** | **83.1** | **64.9** | **36.3** | **97.4** |
| Qwen3-32B | 79.4 | 71.0 | 49.8 | 21.3 | 96.8 |
| GPT-OSS-20B | 83.3 | 84.4 | 64.8 | 26.0 | 94.8 |

> âœ… åœ¨ AIME24ã€HMMT25ã€AMO-Bench ä¸Šå…¨é¢é¢†å…ˆï¼Œå…¶ä¸­ AMO-Bench è¶…è¶Šç¬¬äºŒåè¶… 10 ä¸ªç™¾åˆ†ç‚¹ã€‚

#### ä»£ç ç”Ÿæˆè¡¨ç°ï¼ˆTable 5ï¼‰
| æ¨¡å‹ | LCB v6 | SciCode (sub/main) | T2-Telecom | TB Hard |
|------|--------|--------------------|------------|---------|
| **Falcon-H1R-7B** | **68.6** | 28.3 / 3.9 | 25.4 | 4.9 |
| GPT-OSS-20B | 72.0 | 34.9 / 6.2 | 60.2* | 9.9* |

> âœ… åœ¨ LiveCodeBench ä¸Šä»…æ¬¡äº GPT-OSS-20Bï¼Œåœ¨å…¶ä»–ä»£ç ä»»åŠ¡ä¸Šå…·æœ‰ç«äº‰åŠ›ã€‚

#### é€šç”¨æ¨ç†è¡¨ç°ï¼ˆTable 6ï¼‰
| æ¨¡å‹ | GPQA-Diamond | MMLU-Pro | HLE | IFBench |
|------|--------------|----------|-----|--------|
| **Falcon-H1R-7B** | 61.3 | 72.1 | **11.1** | **53.4** |
| Phi-4-R-Plus-14B | 67.9 | 79.2 | 5.9 | 51.7 |

> âš ï¸ åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ï¼ˆå¦‚ GPQAã€MMLU-Proï¼‰ç•¥é€Šäºæœ€å¤§æ¨¡å‹ï¼Œä½†åœ¨ HLE å’Œ IFBench ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½“ç°å¼ºæŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚

### Test-Time Scaling ç»“æœï¼ˆTable 7ï¼‰

| æ¨¡å‹ | AIME25 Accâ†‘ | AIME25 Tokâ†“ | GPQA-D Accâ†‘ | GPQA-D Tokâ†“ |
|------|-------------|-------------|-------------|-------------|
| Qwen3-32B | 86.7 | 174.8 | 70.1 | 460.0 |
| **Falcon-H1R-7B** | **96.7** | **95.1** | **70.2** | **452.3** |

> ğŸ”¥ **åœ¨ AIME25 ä¸Šè¾¾åˆ° 96.7% å‡†ç¡®ç‡ï¼ŒåŒæ—¶ token æ¶ˆè€—ä»…ä¸º Qwen3-32B çš„ ~54%ï¼ˆä¸‹é™ 38%ï¼‰**

### æ¶ˆèå®éªŒå…³é”®å‘ç°ï¼ˆSection 2.2 & 3.3ï¼‰

| å®éªŒç»´åº¦ | æœ€ä½³é€‰æ‹© | å‘ç° |
|--------|----------|------|
| å­¦ä¹ ç‡ | 1024Ã—10â»â¶ | è¾ƒå¤§ LR åŠ é€Ÿæ”¶æ•›ä¸”æå‡ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ |
| Rollout æ•°é‡ | n=12 | æ›´å¤š rollout æå‡å›°éš¾é—®é¢˜çš„è¡¨ç° |
| æ•™å¸ˆæ¨¡å‹ | Single-teacher | å¤š teacher å¯¼è‡´é£æ ¼å†²çªï¼Œæ€§èƒ½ä¸‹é™ |
| æ•°æ®æƒé‡ | Difficulty-aware | éš¾é¢˜åŠ æƒå¯æ˜¾è‘—æå‡æ•´ä½“æ€§èƒ½ |
| RL Curriculum | Math â†’ Code | é¡ºåºè®­ç»ƒå¸¦æ¥è½»å¾®å¢ç›Š |
| RL Group Size | G=16 | å¹³è¡¡å¤šæ ·æ€§ä¸è®¡ç®—æˆæœ¬ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å°å‹æ¨¡å‹ä¹Ÿèƒ½å®ç°é¡¶çº§æ¨ç†æ€§èƒ½**  
   Falcon-H1R-7B ä»¥ä»… 7B å‚æ•°ï¼Œåœ¨å¤šé¡¹æ¨ç†åŸºå‡†ä¸Šè¶…è¶Š 2Ã— è‡³ 7Ã— æ›´å¤§çš„æ¨¡å‹ï¼Œè¯æ˜äº† **â€œè®­ç»ƒè´¨é‡ > æ¨¡å‹å¤§å°â€** çš„å¯è¡Œæ€§ã€‚

2. **ç²¾å¿ƒè®¾è®¡çš„æ•°æ®ä¸è®­ç»ƒç­–ç•¥è‡³å…³é‡è¦**  
   - é«˜è´¨é‡ã€é•¿é“¾æ¨ç†æ•°æ® + éš¾åº¦æ„ŸçŸ¥åŠ æƒæ˜¯ SFT æˆåŠŸçš„å…³é”®ã€‚
   - RL é˜¶æ®µéœ€é¿å…è¿‡æ‹Ÿåˆï¼Œåˆç†åˆ©ç”¨ GRPO å’Œ backfill ç¼“å­˜æœºåˆ¶æé«˜æ•ˆç‡ã€‚

3. **æ··åˆæ¶æ„ä¸º TTS æä¾›ç†æƒ³åŸºç¡€**  
   Falcon-H1 çš„ Transformer-Mamba æ¶æ„åœ¨é•¿åºåˆ—ã€å¤§æ‰¹é‡æ¨ç†ä¸­å±•ç°å‡ºå“è¶Šååé‡ï¼ˆè§ Figure 8ï¼‰ï¼Œä½¿å…¶æˆä¸º TTS åº”ç”¨çš„ç†æƒ³ backboneã€‚

4. **DeepConf + Falcon-H1R å®ç°ç²¾åº¦ä¸æ•ˆç‡åŒèµ¢**  
   åŠ¨æ€å‰ªææœºåˆ¶å……åˆ†å‘æŒ¥äº† Falcon-H1R è‰¯å¥½ calibrated confidence çš„ä¼˜åŠ¿ï¼Œå®ç°äº† **æ›´é«˜å‡†ç¡®ç‡ + æ›´å°‘ token æ¶ˆè€—**ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä»æœ‰å·®è·**ï¼šåœ¨ GPQA-Diamond å’Œ MMLU-Pro ä¸Šæœªè¾¾æœ€ä¼˜ï¼Œè¡¨æ˜è¿‡åº¦èšç„¦æ¨ç†å¯èƒ½ç‰ºç‰²éƒ¨åˆ†çŸ¥è¯†æ£€ç´¢èƒ½åŠ›ã€‚
- **å®‰å…¨é£é™©å­˜åœ¨äº CoT ä¸­**ï¼šè™½ç„¶æœ€ç»ˆç­”æ¡ˆå®‰å…¨ï¼Œä½†æ¨ç†è¿‡ç¨‹ï¼ˆCoTï¼‰ä¸­ä¼šçŸ­æš‚æ¥è§¦æ½œåœ¨æœ‰å®³å†…å®¹ï¼ˆè§ Table 10ï¼‰ï¼Œéƒ¨ç½²æ—¶éœ€è°¨æ…æš´éœ²ä¸­é—´æ€ç»´é“¾ã€‚
- **ä¾èµ–é«˜è´¨é‡å¥–åŠ±ä¿¡å·**ï¼šRL é˜¶æ®µä¸¥é‡ä¾èµ–å¯éªŒè¯çš„ rewardï¼ˆå¦‚æ•°å­¦ç­”æ¡ˆåŒ¹é…ã€ä»£ç æ‰§è¡Œé€šè¿‡ï¼‰ï¼Œéš¾ä»¥æ‰©å±•åˆ°å¼€æ”¾åŸŸä»»åŠ¡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´å°è§„æ¨¡æ¨¡å‹ï¼ˆå¦‚ 3B æˆ– 1Bï¼‰æ˜¯å¦ä¹Ÿèƒ½é€šè¿‡ç±»ä¼¼è®­ç»ƒç­–ç•¥å®ç°å¼ºæ¨ç†èƒ½åŠ›ã€‚
- æ”¹è¿›æ··åˆæ¶æ„è®¾è®¡ï¼Œè¿›ä¸€æ­¥å‹ç¼©å»¶è¿Ÿå’Œå†…å­˜å ç”¨ã€‚
- ç ”ç©¶å¦‚ä½•åœ¨ä¿è¯å®‰å…¨æ€§çš„åŒæ—¶ï¼Œé€æ˜å±•ç¤ºæ¨ç†è¿‡ç¨‹ã€‚
- å°†è¯¥èŒƒå¼æ¨å¹¿è‡³æ›´å¤šéç»“æ„åŒ–æ¨ç†ä»»åŠ¡ï¼ˆå¦‚è‡ªç„¶è¯­è¨€ç†è§£ã€è§„åˆ’å†³ç­–ç­‰ï¼‰ã€‚

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼šFalcon-H1R è¯æ˜äº†é€šè¿‡ **æ··åˆæ¶æ„ + é«˜è´¨é‡æ•°æ® + åˆ†é˜¶æ®µå¼ºåŒ–è®­ç»ƒ**ï¼Œå³ä½¿æ˜¯ 7B è§„æ¨¡çš„å°æ¨¡å‹ä¹Ÿèƒ½åœ¨æ¨ç†ä»»åŠ¡ä¸Šåª²ç¾ç”šè‡³è¶…è¶Šæ•°åäº¿å‚æ•°çš„å¤§æ¨¡å‹ï¼Œå¹¶åœ¨ Test-Time Scaling åœºæ™¯ä¸­å®ç°ç²¾åº¦ã€é€Ÿåº¦ä¸æˆæœ¬çš„å…¨é¢é¢†å…ˆã€‚

</details>

---

### 6. [RadioDiff-Flux: Efficient Radio Map Construction via Generative Denoise Diffusion Model Trajectory Midpoint Reuse](https://arxiv.org/abs/2601.02790)

**Authors**: Xiucheng Wang, Peilin Zheng, Honggang Jia, Nan Cheng, Ruijin Sun, Conghao Zhou, Xuemin Shen  
**Category**: cs.LG  
**Published**: 2026-01-07  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2601.02790v1  

#### Abstract
Accurate radio map (RM) construction is essential to enabling environment-aware and adaptive wireless communication. However, in future 6G scenarios characterized by high-speed network entities and fast-changing environments, it is very challenging to meet real-time requirements. Although generative...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šRadioDiff-Flux: Efficient Radio Map Construction via Generative Denoise Diffusion Model Trajectory Midpoint Reuse

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨6Gæ— çº¿é€šä¿¡åœºæ™¯ä¸­ï¼Œ**é«˜åŠ¨æ€ç¯å¢ƒ**ï¼ˆå¦‚ç§»åŠ¨åŸºç«™ã€æ— äººæœºã€è½¦è¾†ç­‰ï¼‰å¯¹å®æ—¶ã€é«˜æ•ˆçš„ **Radio Map (RM)** æ„å»ºæå‡ºäº†ä¸¥å³»æŒ‘æˆ˜ã€‚å°½ç®¡ç”Ÿæˆå¼æ‰©æ•£æ¨¡å‹ï¼ˆDMsï¼‰åœ¨RMæ„å»ºä¸­å®ç°äº†æ¥è¿‘å°„çº¿è¿½è¸ªçš„ç²¾åº¦ï¼Œä½†å…¶**è¿­ä»£å»å™ªæœºåˆ¶å¯¼è‡´æ¨ç†å»¶è¿Ÿè¿‡é«˜**ï¼ˆé€šå¸¸éœ€æ•°ç™¾è‡³åƒæ­¥ï¼‰ï¼Œéš¾ä»¥æ»¡è¶³ä½æ—¶å»¶éœ€æ±‚ã€‚æ­¤å¤–ï¼Œä¼ ç»ŸDMé‡‡ç”¨â€œé›¶è®°å¿†â€æ¨¡å¼ï¼Œæ— æ³•åˆ©ç”¨ç›¸é‚»åœºæ™¯é—´çš„æ—¶ç©ºç›¸å…³æ€§ï¼Œé€ æˆå¤§é‡å†—ä½™è®¡ç®—ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡º **RadioDiff-Flux**ï¼Œä¸€ç§åŸºäº**éšå˜é‡æ‰©æ•£è¿‡ç¨‹ä¸­é—´æ€é‡ç”¨**ï¼ˆmidpoint reuseï¼‰çš„ä¸¤é˜¶æ®µé«˜æ•ˆRMæ„å»ºæ¡†æ¶ï¼Œæ ¸å¿ƒæ€æƒ³å¦‚ä¸‹ï¼š

- **å…³é”®æ´å¯Ÿ**ï¼šé€šè¿‡åˆ†æå‘ç°ï¼Œåœ¨è¯­ä¹‰ç›¸ä¼¼çš„åœºæ™¯ï¼ˆå¦‚åŒä¸€å»ºç­‘å¸ƒå±€ä¸‹ä¸åŒBSä½ç½®ï¼‰ä¸­ï¼Œæ‰©æ•£è¿‡ç¨‹çš„**ä¸­é—´éšå˜é‡ï¼ˆlatent midpointï¼‰é«˜åº¦ä¸€è‡´**ï¼Œè¡¨æ˜è¿™äº›ä¸­é—´çŠ¶æ€ä¸»è¦ç¼–ç é™æ€ç¯å¢ƒç‰¹å¾ï¼ˆå¦‚å»ºç­‘ç»“æ„ã€æè´¨ï¼‰ï¼Œè€ŒåæœŸæ‰ç»†åŒ–åŠ¨æ€ç»†èŠ‚ï¼ˆå¦‚BSä½ç½®ã€ç§»åŠ¨éšœç¢ç‰©ï¼‰ã€‚
  
- **ç†è®ºæ”¯æŒ**ï¼šåŸºäºKLæ•£åº¦åˆ†æè¯æ˜ï¼Œè¯­ä¹‰ç›¸ä¼¼çš„RMåœ¨æ‰©æ•£è¿‡ç¨‹ä¸­å…¶éšå˜é‡åˆ†å¸ƒå·®å¼‚éšæ‰©æ•£æ­¥æ•°å¢åŠ å‘ˆäºŒæ¬¡è¡°å‡ï¼Œä¸ºä¸­é—´æ€é‡ç”¨æä¾›äº†ç†è®ºä¾æ®ã€‚

- **æ–¹æ³•è®¾è®¡**ï¼š
  1. **ç¬¬ä¸€é˜¶æ®µ**ï¼šä»…ä½¿ç”¨é™æ€ç¯å¢ƒç‰¹å¾ï¼ˆå¦‚å»ºç­‘å¸ƒå±€ï¼‰è®­ç»ƒä¸€ä¸ªæ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œç”Ÿæˆå¹¶ç¼“å­˜â€œ**æ‰©æ•£ä¸­ç‚¹**â€ï¼ˆdiffusion midpointï¼‰ï¼Œè¯¥ä¸­ç‚¹å¯è·¨ç›¸ä¼¼åœºæ™¯å¤ç”¨ã€‚
  2. **ç¬¬äºŒé˜¶æ®µ**ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„RadioDiffæ¨¡å‹ï¼Œä»ç¼“å­˜çš„ä¸­ç‚¹å‡ºå‘ï¼Œç»“åˆåŠ¨æ€ä¿¡æ¯ï¼ˆå¦‚BSä½ç½®ã€è½¦è¾†ï¼‰å®Œæˆå‰©ä½™å»å™ªæ­¥éª¤ï¼Œé¿å…é‡å¤æ—©æœŸè®¡ç®—ã€‚

- **ä¸¤ç§å®ç°å½¢å¼**ï¼š
  - **Vanilla Midpoint Reuse**ï¼šç›´æ¥å¤ç”¨é¢„è®¡ç®—ä¸­ç‚¹ï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚
  - **RadioDiff-Flux**ï¼šæ˜¾å¼è§£è€¦é™æ€å»ºæ¨¡ä¸åŠ¨æ€ç²¾è°ƒï¼Œæå‡ç²¾åº¦ä¸æ•ˆç‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³•ç±»å‹ | ä¼˜åŠ¿ |
|--------|------|
| **vs ç‰©ç†é©±åŠ¨æ–¹æ³•ï¼ˆå¦‚ray tracingï¼‰** | é¿å…æŒ‡æ•°çº§å¤æ‚åº¦ï¼›æ”¯æŒå¿«é€Ÿé€‚åº”ç¯å¢ƒå˜åŒ–ï¼Œæ— éœ€å…¨å±€é‡ç®—ã€‚ |
| **vs ä¼ ç»Ÿåˆ¤åˆ«æ¨¡å‹ï¼ˆå¦‚RadioUNetï¼‰** | èƒ½ç”Ÿæˆç©ºé—´è¿è´¯çš„å…¨å±€RMï¼Œå…‹æœå±€éƒ¨å›å½’å±€é™ã€‚ |
| **vs GANç±»æ–¹æ³•ï¼ˆå¦‚RME-GANï¼‰** | æ›´ç¨³å®šè®­ç»ƒï¼Œæ— æ¨¡å¼å´©æºƒé—®é¢˜ï¼Œé€‚åˆéƒ¨ç½²ã€‚ |
| **vs æ ‡å‡†æ‰©æ•£æ¨¡å‹ï¼ˆå¦‚RadioDiffï¼‰** | æ¨ç†é€Ÿåº¦æå‡é«˜è¾¾50å€ä»¥ä¸Šï¼Œä¸”ç²¾åº¦æŸå¤±æå°ï¼ˆ<0.15%ï¼‰ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä½¿ç”¨ **RadioMapSeer** æ•°æ®é›†ï¼Œæºè‡ªOpenStreetMapçš„çœŸå®åŸå¸‚åœ°å›¾ï¼ˆå¦‚Ankaraã€Berlinç­‰ï¼‰ï¼Œå…±700å¼ 256Ã—256åˆ†è¾¨ç‡çš„åœ°å›¾ã€‚
- æ¯å¼ å›¾å«çº¦50â€“150æ ‹å»ºç­‘ï¼Œ80ä¸ªå‘å°„æœºä½ç½®ã€‚
- åŒ…æ‹¬ä¸¤ç±»RMï¼š
  - **Static RM (SRM)**ï¼šä»…è€ƒè™‘å»ºç­‘ç‰©å½±å“ã€‚
  - **Dynamic RM (DRM)**ï¼šåŠ å…¥éšæœºè½¦è¾†ä½œä¸ºåŠ¨æ€éšœç¢ç‰©ã€‚

### å®éªŒè®¾ç½®
- **æ‰©æ•£æ­¥æ•°**ï¼š$ T = 100 $ï¼ˆç”¨äºé‡‡æ ·ï¼Œè¿œå°‘äºæ ‡å‡†DMçš„500â€“1000æ­¥ï¼‰
- **è¯„ä¼°åœºæ™¯**ï¼ˆä¸‰ç±»å˜åŒ–ï¼‰ï¼š
  1. **Scenario 1**ï¼šæ”¹å˜BSä½ç½®ï¼ˆé™æ€ç¯å¢ƒä¸å˜ï¼‰
  2. **Scenario 2**ï¼šä»é™æ€ç¯å¢ƒè¿‡æ¸¡åˆ°å«è½¦è¾†çš„åŠ¨æ€ç¯å¢ƒ
  3. **Scenario 3**ï¼šç›´æ¥ä¿®æ”¹é™æ€ç¯å¢ƒï¼ˆå»ºç­‘å¸ƒå±€ + BSä½ç½®ï¼‰
- **é‡ç”¨æ¯”ä¾‹**ï¼ˆRreuseï¼‰ï¼šå®šä¹‰ä¸ºä½¿ç”¨æ—§æ¡ä»¶è¿›è¡Œå»å™ªçš„å‰æ®µæ­¥æ•°å æ¯”ï¼Œæµ‹è¯•èŒƒå›´ä¸º[0.1, 0.98]

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **NMSE / RMSE** | å½’ä¸€åŒ–å‡æ–¹è¯¯å·® / å‡æ–¹æ ¹è¯¯å·®ï¼Œè¡¡é‡æ•´ä½“è¯¯å·® |
| **SSIM** | ç»“æ„ç›¸ä¼¼æ€§ï¼Œåæ˜ é«˜é¢‘ç»†èŠ‚ä¿ç•™èƒ½åŠ› |
| **PSNR (dB)** | å³°å€¼ä¿¡å™ªæ¯”ï¼Œè¯„ä¼°ä¿¡å·ä¿çœŸåº¦ |
| **Time (ms)** | å•æ¬¡æ¨ç†è€—æ—¶ï¼Œä½“ç°æ•ˆç‡ |
| **Speedup** | ç›¸å¯¹äºå®Œæ•´æ‰©æ•£æµç¨‹çš„åŠ é€Ÿæ¯” |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **RadioUNet** | åˆ¤åˆ«å¼CNN | U-Netæ¶æ„ï¼Œç›´æ¥å›å½’RM |
| **UVM-Net** | åºåˆ—å»ºæ¨¡ | ä½¿ç”¨State Space Modelæ•æ‰é•¿è·ç¦»ä¾èµ– |
| **RME-GAN** | ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ | æ¡ä»¶GANï¼Œå­˜åœ¨è®­ç»ƒä¸ç¨³å®šæ€§ |
| **RadioDiff** | æ‰©æ•£æ¨¡å‹ï¼ˆSOTAï¼‰ | å½“å‰æœ€ä¼˜æ–¹æ³•ï¼Œä½œä¸ºä¸»åŸºå‡†ä¸æ¶ˆèå¯¹ç…§ |
| **Vanilla Midpoint Reuse (Ours)** | ä¸­é—´æ€å¤ç”¨ | å¤ç”¨RadioDiffä¸­ç‚¹ï¼Œæ— å†è®­ç»ƒ |
| **RadioDiff-Flux (Ours)** | ä¸¤é˜¶æ®µæ¡†æ¶ | æ˜¾å¼åˆ†ç¦»é™æ€/åŠ¨æ€å»ºæ¨¡ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### Scenario 1: æ”¹å˜BSä½ç½®
| æ–¹æ³• | Rreuse | NMSE | Speedup |
|------|--------|-------|---------|
| RadioDiff (baseline) | 0.00 | 0.00580 | 1Ã— |
| Vanilla Reuse | 0.70 | 0.00671 | **3.47Ã—** |
| Vanilla Reuse | 0.98 | 0.13098 | **50Ã—** |
| **RadioDiff-Flux** | **0.98** | **0.02957** | **~20Ã—** |

> âœ… åœ¨Rreuse=0.7æ—¶ï¼ŒNMSEä»…ä¸Šå‡15%ï¼Œé€Ÿåº¦æå‡3.5å€ï¼›  
> âœ… RadioDiff-Fluxæ˜¾è‘—ç¼“è§£é«˜é‡ç”¨ä¸‹çš„â€œæ¨¡ç³Šå åŠ â€æ•ˆåº”ï¼Œä¿æŒæ›´é«˜ä¿çœŸåº¦ã€‚

#### Scenario 2: é™æ€â†’åŠ¨æ€ç¯å¢ƒè½¬æ¢
| æ–¹æ³• | Rreuse | NMSE | Speedup |
|------|--------|-------|---------|
| RadioDiff | 0.00 | 0.00643 | 1Ã— |
| Vanilla Reuse | 0.98 | **0.00776** | **60Ã—** |

> âœ… å³ä½¿åœ¨æé«˜é‡ç”¨ç‡ä¸‹ï¼ŒNMSEä»ä½äº0.008ï¼ŒSSIMä¿æŒ>0.95ï¼Œè¯´æ˜æ¡†æ¶å¯¹åŠ¨æ€æ‰°åŠ¨é²æ£’æ€§å¼ºã€‚

#### Scenario 3: ä¿®æ”¹é™æ€ç¯å¢ƒ
| æ–¹æ³• | Rreuse | NMSE | Speedup |
|------|--------|-------|---------|
| RadioDiff | 0.00 | 0.00680 | 1Ã— |
| Vanilla Reuse | 0.70 | 0.00889 | **3.43Ã—** |
| Vanilla Reuse | 0.98 | 0.58418 | **54.5Ã—**ï¼ˆä½†ä¸¥é‡å¤±çœŸï¼‰ |

> âš ï¸ å½“é™æ€ç¯å¢ƒå‘ç”Ÿæ ¹æœ¬æ€§å˜åŒ–æ—¶ï¼Œé«˜Rreuseå¯¼è‡´â€œæƒ¯æ€§åå·®â€ï¼Œæ¨¡å‹éš¾ä»¥çº æ­£åˆå§‹éšçŠ¶æ€çš„å½±å“ã€‚

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ï¼ˆä»¥Scenario 1ä¸ºä¾‹ï¼‰
| æ–¹æ³• | NMSE | Time (ms) | Speed vs RadioDiff |
|------|-------|------------|------------------|
| RadioUNet | 0.00740 | 60 | ~10Ã— faster, but worse accuracy |
| RadioDiff | 0.00580 | 600 | baseline |
| **RadioDiff-Flux (Rreuse=0.7)** | **0.00607** | **~170** | **~3.5Ã— faster**, <5% accuracy drop |

> âœ… RadioDiff-Fluxåœ¨ç²¾åº¦å‡ ä¹ä¸å˜çš„å‰æä¸‹ï¼Œå®ç°æ•°é‡çº§åŠ é€Ÿã€‚

### æ¶ˆèå®éªŒç»“æœ
- **RadioDiff-Flux vs Vanilla Reuse**ï¼šåœ¨é«˜Rreuseï¼ˆå¦‚0.98ï¼‰ä¸‹ï¼Œå‰è€…å°†NMSEä»0.13é™è‡³0.03ï¼ŒéªŒè¯äº†è§£è€¦è®¾è®¡çš„æœ‰æ•ˆæ€§ã€‚
- **ç¼“å­˜å¼€é”€**ï¼šæ¯ä¸ªlatent midpointå¤§å°ä¸º64KBï¼ˆfloat32ï¼‰ï¼ŒåŸå¸‚çº§æœåŠ¡æœ€å¤šç¼“å­˜100ä¸ªï¼Œæ€»å†…å­˜çº¦6.25MBï¼Œèµ„æºå‹å¥½ã€‚
- **è®­ç»ƒæˆæœ¬**ï¼šä»…éœ€å¾®è°ƒç¬¬ä¸€é˜¶æ®µæ¨¡å‹çº¦10ä¸ªepochï¼ˆ12å°æ—¶ï¼‰ï¼Œç›¸æ¯”RadioDiffå…¨è®­480å°æ—¶å¤§å¹…é™ä½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æ‰©æ•£ä¸­ç‚¹å…·æœ‰å¼ºè¯­ä¹‰ä¸€è‡´æ€§**ï¼šåœ¨åŒä¸€é™æ€ç¯å¢ƒä¸‹ä¸åŒé…ç½®ç”Ÿæˆçš„RMï¼Œå…¶æ‰©æ•£è½¨è¿¹åœ¨ä¸­æœŸé«˜åº¦æ”¶æ•›ï¼Œæ”¯æŒä¸­é—´æ€é‡ç”¨ã€‚
2. **ä¸­é—´æ€é‡ç”¨å¯æå¤§æå‡æ•ˆç‡**ï¼šé€šè¿‡è·³è¿‡å†—ä½™æ—©æœŸå»å™ªï¼Œæ¨ç†æ—¶é—´å¯å‡å°‘**3.5Ã— è‡³ 60Ã—**ï¼Œå°¤å…¶é€‚ç”¨äºå°å¹…åº¦åŠ¨æ€å˜åŒ–ï¼ˆå¦‚BSå¾®ç§»ã€è½¦è¾†å‡ºç°ï¼‰ã€‚
3. **ä¸¤é˜¶æ®µè§£è€¦ä¼˜äºç®€å•å¤ç”¨**ï¼šRadioDiff-Fluxé€šè¿‡ä¸“é—¨è®­ç»ƒé™æ€ç¼–ç å™¨ï¼Œæå‡äº†ä¸­ç‚¹æ³›åŒ–èƒ½åŠ›ï¼Œæœ‰æ•ˆæŠ‘åˆ¶é«˜é‡ç”¨ä¸‹çš„è¯¯å·®ç´¯ç§¯ã€‚
4. **é€‚ç”¨åœºæ™¯æ˜ç¡®**ï¼šæ–¹æ³•åœ¨**é«˜è¯­ä¹‰ç›¸ä¼¼æ€§åœºæ™¯**ä¸­è¡¨ç°æœ€ä½³ï¼›å½“ç¯å¢ƒç»“æ„æ€§æ”¹å˜æ—¶ï¼Œåº”é™ä½Rreuseæˆ–é‡æ–°ç”Ÿæˆã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–ç¯å¢ƒç›¸ä¼¼æ€§åˆ¤æ–­**ï¼šå½“å‰é€šè¿‡cross-attentionç©ºé—´çš„Frobeniusè·ç¦»åˆ¤æ–­æ˜¯å¦å¯å¤ç”¨ï¼Œè™½æœ‰æ•ˆä½†ä»ä¸ºå¯å‘å¼ç­–ç•¥ã€‚
- **ä¸é€‚ç”¨äºå‰§çƒˆç¯å¢ƒå˜æ›´**ï¼šè‹¥å»ºç­‘å¸ƒå±€å‘ç”Ÿé‡å¤§è°ƒæ•´ï¼Œç¼“å­˜ä¸­ç‚¹ä¸å†é€‚ç”¨ï¼Œéœ€é‡æ–°è®¡ç®—ã€‚
- **æœªå¤„ç†æ—¶é—´è¿ç»­æ€§å»ºæ¨¡**ï¼šè™½ç„¶å‡å°‘äº†å¸§é—´æŠ–åŠ¨ï¼Œä½†å°šæœªæ˜¾å¼å»ºæ¨¡RMåºåˆ—çš„æ—¶é—´ä¸€è‡´æ€§ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **è‡ªé€‚åº”Rreuseç­–ç•¥**ï¼šå¼€å‘è½»é‡çº§æœºåˆ¶è‡ªåŠ¨é‡åŒ–ç¯å¢ƒå˜åŒ–ç¨‹åº¦ï¼Œå¹¶åŠ¨æ€é€‰æ‹©æœ€ä¼˜Rreuseã€‚
2. **å¢å¼ºæ—¶åºä¸€è‡´æ€§**ï¼šæ‰©å±•è‡³è§†é¢‘çº§æ‰©æ•£æ¨¡å‹ï¼Œæ”¯æŒè¿ç»­RMæµç”Ÿæˆï¼Œæå‡åŠ¨æ€ç³»ç»Ÿå¹³æ»‘æ€§ã€‚
3. **å¤šBSè”åˆå»ºæ¨¡**ï¼šå°†å¤šä¸ªBSä½ç½®ä½œä¸ºç»Ÿä¸€æ¡ä»¶è¾“å…¥ï¼Œç›´æ¥ç”Ÿæˆå¤åˆRMï¼Œè¿›ä¸€æ­¥æå‡æ•ˆç‡ã€‚
4. **è¾¹ç¼˜éƒ¨ç½²ä¼˜åŒ–**ï¼šæ¢ç´¢é‡åŒ–ã€è’¸é¦ç­‰æŠ€æœ¯ï¼Œæ¨åŠ¨RadioDiff-Fluxåœ¨ç§»åŠ¨ç«¯æˆ–æ— äººæœºä¸Šçš„å®æ—¶åº”ç”¨ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **RadioDiff-Fluxé€šè¿‡æ­ç¤ºå¹¶åˆ©ç”¨æ‰©æ•£è¿‡ç¨‹ä¸­é—´æ€çš„è¯­ä¹‰ç¨³å®šæ€§ï¼Œé¦–æ¬¡å®ç°äº†ç”Ÿæˆå¼RMæ¨¡å‹çš„â€œè®°å¿†åŒ–æ¨ç†â€ï¼Œåœ¨ä¿è¯é«˜ä¿çœŸåº¦çš„åŒæ—¶è¾¾æˆæœ€é«˜50å€ä»¥ä¸Šçš„æ¨ç†åŠ é€Ÿï¼Œä¸º6GåŠ¨æ€æ— çº¿ç¯å¢ƒä¸­çš„å®æ—¶æ„ŸçŸ¥ä¸è‡ªé€‚åº”é€šä¿¡æä¾›äº†å¯è¡Œè·¯å¾„ã€‚**

</details>

---

### 7. [MixTTE: Multi-Level Mixture-of-Experts for Scalable and Adaptive Travel Time Estimation](https://arxiv.org/abs/2601.02943)

**Authors**: Wenzhao Jiang, Jindong Han, Ruiqian Han, Hao Liu  
**Category**: cs.LG  
**Published**: 2026-01-07  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2601.02943v1  

#### Abstract
Accurate Travel Time Estimation (TTE) is critical for ride-hailing platforms, where errors directly impact user experience and operational efficiency. While existing production systems excel at holistic route-level dependency modeling, they struggle to capture city-scale traffic dynamics and long-ta...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# MixTTE: Multi-Level Mixture-of-Experts for Scalable and Adaptive Travel Time Estimation è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å·¥ä¸šçº§ **Travel Time Estimation (TTE)** ç³»ç»Ÿï¼ˆå¦‚ DiDi çš„ WDR æ¶æ„ï¼‰è™½ç„¶åœ¨å¸¸è§åœºæ™¯ä¸‹è¡¨ç°è‰¯å¥½ï¼Œä½†ä»å­˜åœ¨ä¸¤å¤§ç“¶é¢ˆï¼š
- **æœ‰é™çš„æ„Ÿå—é‡ï¼ˆLimited reception fieldï¼‰**ï¼šä»…å»ºæ¨¡è·¯çº¿å†…éƒ¨çš„ä¾èµ–å…³ç³»ï¼Œæ— æ³•æ•æ‰åŸå¸‚å°ºåº¦çš„å…¨å±€äº¤é€šåŠ¨æ€ï¼ˆå¦‚å‘¨è¾¹é“è·¯æ‹¥å µä¼ æ’­ï¼‰ã€‚
- **é•¿å°¾åœºæ™¯æ€§èƒ½å·®ï¼ˆLong-tail underperformanceï¼‰**ï¼šå¯¹ç½•è§ä½†å…³é”®çš„äº¤é€šæ¨¡å¼ï¼ˆå¦‚å¤§å‹æ´»åŠ¨ã€æ–½å·¥åŒºï¼‰é¢„æµ‹ä¸å‡†ã€‚

æ­¤å¤–ï¼Œå°† link-level æ¨¡å‹é›†æˆåˆ° route-centric ç³»ç»Ÿé¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
1. **å¯æ‰©å±•æ€§**ï¼šç™¾ä¸‡çº§è·¯ç½‘ä¸Šçš„å…¨å±€æ—¶ç©ºä¾èµ–å»ºæ¨¡æ•ˆç‡ä½ï¼›
2. **å¼‚è´¨æ€§**ï¼šå¤šæ ·åŒ–çš„äº¤é€šæ¨¡å¼éš¾ä»¥ç»Ÿä¸€å»ºæ¨¡ï¼›
3. **åŠ¨æ€é€‚åº”æ€§**ï¼šé¢‘ç¹æ›´æ–°æ¨¡å‹æˆæœ¬é«˜ä¸”æ˜“è¿‡æ‹Ÿåˆã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **MIxTTE**ï¼Œä¸€ä¸ªå¯æ‰©å±•ã€è‡ªé€‚åº”çš„å¤šå±‚çº§ TTE æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰Spatio-Temporal External Attention (STEA)
- å¼•å…¥ä¸€ç»„å°å‹ **external memory units** æ¥ä¸­ä»‹å¤§è§„æ¨¡è·¯ç½‘ä¸­å„ link ä¹‹é—´çš„äº¤äº’ã€‚
- åˆ©ç”¨ **cross-attention** æœºåˆ¶å®ç°å¤–éƒ¨çŸ¥è¯†æ£€ç´¢ï¼ˆEKRï¼‰ï¼Œé¿å…ä¼ ç»Ÿ pairwise å»ºæ¨¡çš„ $O(N^2)$ å¤æ‚åº¦ï¼Œè¾¾åˆ° $O(N \cdot U_{\text{ex}})$ çš„çº¿æ€§å¤æ‚åº¦ã€‚
- æ”¯æŒè·¨æ—¶é—´å’Œç©ºé—´çš„é•¿æœŸä¾èµ–å»ºæ¨¡ï¼Œå¹¶ç»“åˆ **hierarchical modeling** åŠ å¼ºåŒæ—¶é—´æ­¥å†…çš„å…¨å±€ç›¸å…³æ€§ã€‚

#### ï¼ˆ2ï¼‰Externally Stabilized Graph Mixture-of-Experts (ESGMoE)
- è®¾è®¡å›¾ç»“æ„çš„ MoE å±‚ï¼ŒåŒ…å«å¤šç§å¼‚æ„ä¸“å®¶ï¼ˆgraph experts + zero-computation expertsï¼‰ã€‚
- **Hierarchical routing with external guidance**ï¼šåˆ©ç”¨ STEA æä¾›çš„ä¸Šä¸‹æ–‡å¢å¼ºè·¯ç”±å†³ç­–ç¨³å®šæ€§ï¼Œå°¤å…¶åœ¨ä¸ç¡®å®šæ€§é«˜çš„æƒ…å†µä¸‹æ›´ä¾èµ–å¤–éƒ¨çŸ¥è¯†ã€‚
- å¼•å…¥ä¸‰ç§ **zero-computation experts**ï¼ˆIdentityã€Constantã€Nullï¼‰ä»¥æ‘Šé”€é«˜é¢‘ç®€å•æ¨¡å¼çš„è®¡ç®—å¼€é”€ï¼Œé‡Šæ”¾ graph experts ç»™é•¿å°¾åœºæ™¯ä½¿ç”¨ã€‚

#### ï¼ˆ3ï¼‰Asynchronous Incremental Learning (ASIL)
- åŠ¨æ€æ£€æµ‹åˆ†å¸ƒåç§»ï¼ˆé€šè¿‡ Mahalanobis Distance è¡¡é‡å‘¨æœŸæ€§å˜åŒ–ï¼‰æ¥è§¦å‘å¢é‡å­¦ä¹ ã€‚
- **å¼‚æ­¥æ›´æ–°æœºåˆ¶**ï¼šä»…å½“å¼‚å¸¸ link æ¯”ä¾‹è¶…è¿‡é˜ˆå€¼æ—¶æ‰æ›´æ–° link-level å‚æ•°ï¼›æ›´é«˜é˜ˆå€¼æ‰åŒæ—¶æ›´æ–° route-level å‚æ•°ã€‚
- ä½¿ç”¨å†»ç»“çš„å†å²æ¨¡å‹ç”Ÿæˆè¡¨å¾ç”¨äºæ¼‚ç§»æ£€æµ‹ï¼Œä¿è¯ latent space ä¸€è‡´æ€§ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | MIxTTE ä¼˜åŠ¿ |
|------|------------|
| **å‡†ç¡®æ€§** | æ˜¾è‘—ä¼˜äºæ‰€æœ‰ baselineï¼Œå°¤å…¶åœ¨é•¿å°¾åœºæ™¯æå‡æ˜æ˜¾ |
| **å¯æ‰©å±•æ€§** | STEA å®ç°çº¿æ€§å¤æ‚åº¦ï¼Œé€‚ç”¨äºç™¾ä¸‡çº§è·¯ç½‘ |
| **æ¨ç†æ•ˆç‡** | ESGMoE å®ç°ç¨€ç–æ¿€æ´»ï¼Œzero-computation ä¸“å®¶é™ä½å¹³å‡è®¡ç®—è´Ÿæ‹… |
| **é€‚åº”æ€§** | ASIL æ”¯æŒé«˜é¢‘ã€ç¨³å®šã€ä½æˆæœ¬çš„åœ¨çº¿æ›´æ–° |
| **éƒ¨ç½²å…¼å®¹æ€§** | æ— éœ€é‡æ„ç°æœ‰ç³»ç»Ÿï¼Œæ”¯æŒæ’ä»¶å¼é›†æˆ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
åœ¨ä¸‰ä¸ªä¸­å›½å¤§åŸå¸‚çš„çœŸå®æ»´æ»´å‡ºè¡Œæ•°æ®é›†ä¸Šè¿›è¡Œå®éªŒï¼š

| åŸå¸‚ | æ—¶é—´è·¨åº¦ | Trip æ•°é‡ | å¹³å‡è¡Œç¨‹æ—¶é•¿ | è·¯æ®µæ•°ï¼ˆLinksï¼‰ | çƒ­é—¨è·¯æ®µæ•°ï¼ˆHot Linksï¼‰ |
|------|----------|-----------|----------------|----------------|------------------------|
| åŒ—äº¬ | 2024-07 ~ 2024-09 | 22.28M | 18.11 min | 2,315,360 | 156,731 |
| å—äº¬ | 2024-12 ~ 2025-02 | 7.95M | 13.79 min | 696,107 | 83,323 |
| è‹å· | 2025-01 ~ 2025-04 | 16.78M | 13.63 min | 1,419,074 | 149,171 |

> æ³¨ï¼šåªå¯¹â€œçƒ­é—¨è·¯æ®µâ€ç”Ÿæˆ link embeddingï¼Œå‡å°‘å™ªå£°å’Œè®¡ç®—å¼€é”€ã€‚

---

### å®éªŒè®¾ç½®
- **è®­ç»ƒæ–¹å¼**ï¼š
  - å…¨é‡é‡è®­ï¼ˆFull Retrainingï¼‰ï¼šä½¿ç”¨å‰110å¤©æ•°æ®è®­ç»ƒï¼Œæœ€å7å¤©æµ‹è¯•ã€‚
  - å¢é‡å­¦ä¹ ï¼ˆIncremental Learning, ILï¼‰ï¼šæ¯å°æ—¶ç”¨è¿‡å»1å°æ—¶å®Œæˆçš„ trip è®­ç»ƒï¼Œé¢„æµ‹ä¸‹ä¸€å°æ—¶å‡ºå‘çš„ tripã€‚
- **æ‰¹é‡‡æ ·ç­–ç•¥**ï¼štime-specific batchingï¼ŒåŒä¸€ batch å†… trip èµ·å§‹æ—¶é—´ç›¸åŒï¼Œæé«˜è®­ç»ƒæ•ˆç‡å¹¶åŒ¹é…çº¿ä¸Šæ¨ç†é€»è¾‘ã€‚
- **éƒ¨ç½²æ¶æ„**ï¼š
  - link-centric æ¨¡å‹éƒ¨ç½²äº GPUï¼Œæ¯5åˆ†é’Ÿæ›´æ–°ä¸€æ¬¡å¹¶ç¼“å­˜è‡³ Redisï¼›
  - route-centric æ¨¡å‹éƒ¨ç½²äº C++ CPU æœåŠ¡å™¨ï¼Œå®æ—¶æŸ¥è¯¢æœ€æ–° link è¡¨å¾ã€‚

---

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **MAE** | é¢„æµ‹ä¸çœŸå®æ—…è¡Œæ—¶é—´çš„å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆç§’ï¼‰ |
| **MAPE** | å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·® |
| **BCR (Bad Case Ratio)** | MAE > 300 ç§’ä¸” MAPE > 20% çš„æ ·æœ¬å æ¯” |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
#### å…¨é‡è®­ç»ƒ Setting
- **Rule-based**: RouteETAï¼ˆåŸºäºå†å²å¹³å‡ï¼‰
- **Route-centric**: HierETA, WDRï¼ˆDiDi å½“å‰ç”Ÿäº§æ¨¡å‹ï¼‰
- **Link-centric**: CompactETA, ConSTGAT, BigST

#### å¢é‡å­¦ä¹  Setting
- **iETA** [13]ï¼šDiDi ç°æœ‰çš„å¢é‡å­¦ä¹ æ¡†æ¶ï¼Œä½œä¸ºä¸»è¦å¯¹æ¯”åŸºçº¿ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### æ•´ä½“æ€§èƒ½ï¼ˆTable 2ï¼‰
åœ¨ä¸‰ä¸ªåŸå¸‚ä¸Šï¼ŒMIxTTE åœ¨ **å¢é‡å­¦ä¹  setting ä¸‹å…¨é¢é¢†å…ˆ**ï¼š

| æŒ‡æ ‡ | æœ€ä½³æå‡ï¼ˆvs iETAï¼‰ |
|------|--------------------|
| **MAE** | â†“ 2.39% |
| **MAPE** | â†“ 3.70% |
| **BCR** | â†“ 10.32% |

> ç‰¹åˆ«æ˜¯åœ¨ **BCR ä¸Šå¤§å¹…ä¸‹é™**ï¼Œè¯´æ˜å¯¹æç«¯é”™è¯¯æ¡ˆä¾‹æœ‰æ˜¾è‘—æ”¹å–„ã€‚

---

### é•¿å°¾åœºæ™¯æ€§èƒ½åˆ†æï¼ˆRQ2ï¼‰
- å°†æµ‹è¯•æ ·æœ¬æŒ‰ä»¥ä¸‹ä¸‰ä¸ªç»´åº¦åˆ†ç»„ï¼ˆäº”ç­‰åˆ†ï¼‰ï¼š
  1. Trip Duration (TD)
  2. Condition Deviation Degree (CDD)
  3. Non-Recurrence Degree (NRD)

- **å‘ç°**ï¼šéšç€ä»å¤´éƒ¨åˆ°å°¾éƒ¨æ ·æœ¬ï¼ŒMIxTTE ç›¸å¯¹äºå½“å‰ TTE æ¨¡å‹çš„ **MAE æ”¹å–„å¹…åº¦æŒç»­ä¸Šå‡**ï¼ˆè§ Figure 3ï¼‰ï¼ŒéªŒè¯äº†å…¶åœ¨é•¿å°¾åœºæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›æ›´å¼ºã€‚

---

### æ•ˆç‡åˆ†æï¼ˆRQ3ï¼‰
#### å…¨é‡è®­ç»ƒæ•ˆç‡ï¼ˆTable 3ï¼‰
| æ¨¡å‹ | åŒ—äº¬ååé‡ (K/min) | åŒ—äº¬æ¨ç†å»¶è¿Ÿ (ms) |
|------|---------------------|-------------------|
| CompactETA | 14.96 | 541.27 |
| ConSTGAT | 10.51 | 704.11 |
| BigST | 22.45 | 78.30 |
| **MIxTTE-WoIL** | **21.17** | **88.97** |

> MIxTTE åœ¨ä¿æŒé«˜ååçš„åŒæ—¶ï¼Œæ¨ç†å»¶è¿Ÿè¿œä½äº GAT ç±»æ¨¡å‹ã€‚

#### å¢é‡å­¦ä¹ æ•ˆç‡ï¼ˆTable 4ï¼‰
| æ¨¡å‹ | å¹³å‡è®­ç»ƒæ—¶é—´ (sec/step) | å¯è®­ç»ƒå‚æ•° (K/step) |
|------|-------------------------|----------------------|
| MIxTTE-WoPUï¼ˆæ— é€‰æ‹©æ€§æ›´æ–°ï¼‰ | 36.63 | 525.66 |
| **MIxTTEï¼ˆASILï¼‰** | **7.81** | **47.49** |

> ASIL ç­–ç•¥ä½¿è®­ç»ƒæ—¶é—´å’Œå‚æ•°é‡åˆ†åˆ«å‡å°‘çº¦ **80% å’Œ 91%**ï¼Œæå¤§æå‡äº†æ›´æ–°æ•ˆç‡ã€‚

---

### æ¶ˆèå®éªŒï¼ˆAblation Study, Figure 4ï¼‰
æ¶ˆèæ¨¡å—åŒ…æ‹¬ï¼š
- `-WoEA`ï¼šç§»é™¤ STEA å’Œ hierarchical routing
- `-WoHR`ï¼šä»…ç§»é™¤ hierarchical routing
- `-WoMoE`ï¼šç§»é™¤ ESGMoE å±‚
- `-WoZE`ï¼šç§»é™¤ zero-computation experts
- `-WoPU`ï¼šç§»é™¤å‚æ•°é€‰æ‹©æ€§æ›´æ–°ï¼ˆå³ç¦ç”¨ ASILï¼‰

#### å‘ç°ï¼š
- **STEA è‡³å…³é‡è¦**ï¼š`-WoEA` æ€§èƒ½æœ€å·®ï¼Œè¯æ˜å…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡æœ‰æ•ˆã€‚
- **Hierarchical routing æå‡ç¨³å®šæ€§**ï¼š`-WoHR` åœ¨è‹å·æ•°æ®é›†ä¸Šä¸‹é™æ›´æ˜æ˜¾ï¼ˆå› ç½‘ç»œæ›´å¤æ‚ï¼‰ã€‚
- **Zero-computation experts å¯¹ BCR å½±å“å¤§**ï¼šå°¤å…¶åœ¨å—äº¬ï¼Œç§»é™¤å BCR æ˜¾è‘—ä¸Šå‡ï¼Œè¡¨æ˜å…¶å¯¹é•¿å°¾åœºæ™¯çš„é‡è¦æ€§ã€‚
- **ASIL æå‡ IL ç¨³å®šæ€§**ï¼š`-WoPU` å¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œè¯´æ˜å¼‚æ­¥æ›´æ–°æœ‰åŠ©äºé˜²æ­¢è¿‡æ‹Ÿåˆã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **link-level modeling å¯æœ‰æ•ˆè¡¥å…… route-centric ç³»ç»Ÿ**ï¼Œå°¤å…¶æ˜¯åœ¨æ•æ‰å…¨å±€äº¤é€šåŠ¨æ€å’Œé•¿å°¾åœºæ™¯æ–¹é¢ã€‚
2. **STEA å®ç°é«˜æ•ˆå…¨å±€å»ºæ¨¡**ï¼Œçªç ´äº†ä¼ ç»Ÿ GNN æˆ– attention çš„äºŒæ¬¡å¤æ‚åº¦é™åˆ¶ã€‚
3. **ESGMoE ç»“åˆ zero-computation experts èƒ½æœ‰æ•ˆå¤„ç†å¼‚è´¨æ€§å’Œé•¿å°¾åˆ†å¸ƒ**ï¼Œå¹¶é€šè¿‡å¤–éƒ¨å¼•å¯¼æå‡è·¯ç”±ç¨³å®šæ€§ã€‚
4. **ASIL å®ç°é«˜é¢‘ç‡ã€ä½æˆæœ¬ã€ç¨³å®šçš„åœ¨çº¿æ›´æ–°**ï¼Œè§£å†³äº† link-level æ¨¡å‹é¢‘ç¹æ›´æ–°å¸¦æ¥çš„è®¡ç®—ä¸ç¨³å®šæ€§é—®é¢˜ã€‚
5. **MIxTTE å·²æˆåŠŸéƒ¨ç½²äº DiDi ç”Ÿäº§ç¯å¢ƒ**ï¼Œå¸¦æ¥æ˜¾è‘—çš„æœåŠ¡è´¨é‡æå‡ï¼ˆMAE â†“3.03%ï¼ŒBCR â†“4.41%ï¼‰ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡â€œçƒ­é—¨è·¯æ®µâ€å®šä¹‰**ï¼šéçƒ­ç‚¹åŒºåŸŸçš„ link è¡¨å¾å¯èƒ½ä¸å¤Ÿå‡†ç¡®ã€‚
- **external memory units éœ€è°ƒå‚**ï¼šmemory size å’Œåˆå§‹åŒ–å½±å“æ”¶æ•›é€Ÿåº¦ã€‚
- **zero-computation experts çš„è®¾è®¡ä»è¾ƒå¯å‘å¼**ï¼Œç¼ºä¹ç†è®ºæœ€ä¼˜æ€§ä¿éšœã€‚
- **ç›®å‰ä»…ç”¨äº TTE**ï¼Œå°šæœªéªŒè¯æ˜¯å¦å¯æ¨å¹¿è‡³å…¶ä»–æ—¶ç©ºé¢„æµ‹ä»»åŠ¡ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘ï¼ˆSection Cï¼‰
1. **å¼•å…¥å¤šæ¨¡æ€æ•°æ®**ï¼šèåˆå¤©æ°”ã€äº‹ä»¶ç­‰å¤–éƒ¨ä¿¡å·ï¼Œç¼“è§£åŸå¸‚æ„ŸçŸ¥ä¸å®Œå…¨é—®é¢˜ã€‚
2. **è·¨åŸè¿ç§»å­¦ä¹ **ï¼šåˆ©ç”¨ external memory å’Œ MoE æŠ½è±¡é€šç”¨äº¤é€šçŸ¥è¯†ï¼Œé™ä½æ–°åŸå¸‚éƒ¨ç½²æˆæœ¬ã€‚
3. **è½»é‡åŒ–è’¸é¦**ï¼šæ„å»ºå¤§è§„æ¨¡åŸºç¡€æ¨¡å‹åï¼Œæ¢ç´¢æ¨¡å‹å‹ç¼©æŠ€æœ¯ä»¥ä¾¿è¾¹ç¼˜éƒ¨ç½²ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> MIxTTE é€šè¿‡ **STEA + ESGMoE + ASIL** ä¸‰é‡åˆ›æ–°ï¼Œåœ¨ä¸æ”¹å˜ç°æœ‰ç”Ÿäº§æ¶æ„çš„å‰æä¸‹ï¼Œå®ç°äº†å¯¹ç™¾ä¸‡çº§è·¯ç½‘çš„é«˜æ•ˆã€ç²¾å‡†ã€è‡ªé€‚åº”æ—…è¡Œæ—¶é—´ä¼°è®¡ï¼Œå·²åœ¨ DiDi æˆåŠŸè½åœ°å¹¶å–å¾—æ˜¾è‘—ä¸šåŠ¡æ”¶ç›Šã€‚

</details>

---

### 8. [ModeX: Evaluator-Free Best-of-N Selection for Open-Ended Generation](https://arxiv.org/abs/2601.02535)

**Authors**: Hyeong Kyu Choi, Sharon Li  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2601.02535v1  

#### Abstract
Selecting a single high-quality output from multiple stochastic generations remains a fundamental challenge for large language models (LLMs), particularly in open-ended tasks where no canonical answer exists. While Best-of-N and self-consistency methods show that aggregating multiple generations can...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**ModeX: Evaluator-Free Best-of-N Selection for Open-Ended Generation**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
åœ¨å¼€æ”¾ç”Ÿæˆä»»åŠ¡ï¼ˆopen-ended generationï¼‰ä¸­ï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¾“å‡ºå…·æœ‰é«˜åº¦éšæœºæ€§ï¼Œå•æ¬¡ç”Ÿæˆè·¯å¾„ï¼ˆsingle-path generationï¼‰å®¹æ˜“å› æ—©æœŸé”™è¯¯å¯¼è‡´å¹»è§‰æˆ–æ¨ç†å¤±è´¥ã€‚è™½ç„¶ **Best-of-N** å’Œ **self-consistency** æ–¹æ³•é€šè¿‡å¤šè·¯å¾„é‡‡æ ·æå‡äº†æ€§èƒ½ï¼Œä½†å®ƒä»¬é€šå¸¸ä¾èµ–ä»¥ä¸‹ä¸¤ç§æœºåˆ¶ï¼š
- å¤–éƒ¨è¯„ä¼°å™¨ï¼ˆå¦‚ reward model æˆ– LLM judgeï¼‰
- ç²¾ç¡®å­—ç¬¦ä¸²åŒ¹é…æŠ•ç¥¨ï¼ˆexact string-match votingï¼‰

è¿™äº›é™åˆ¶ä½¿å¾—ç°æœ‰æ–¹æ³•éš¾ä»¥åº”ç”¨äº**æ— æ ‡å‡†ç­”æ¡ˆçš„å¼€æ”¾æ–‡æœ¬ç”Ÿæˆä»»åŠ¡**ï¼ˆå¦‚æ‘˜è¦ã€ä»£ç ç”Ÿæˆã€æ•°å­¦æ¨ç†ï¼‰ï¼Œä¸”è®¡ç®—å¼€é”€å¤§ã€‚

---

### âœ… æå‡ºçš„æ–°æ–¹æ³•ï¼šModeX ä¸ ModeX-Lite

#### **ModeXï¼ˆMode Extractionï¼‰**
- **æ ¸å¿ƒæ€æƒ³**ï¼šå°†â€œå¤šæ•°æŠ•ç¥¨â€æ¨å¹¿åˆ°å¼€æ”¾æ–‡æœ¬ç©ºé—´ï¼Œæå‡ºâ€œæ¨¡æ€è¾“å‡ºâ€ï¼ˆmodal outputï¼‰æ¦‚å¿µâ€”â€”å³ä»£è¡¨å¤šä¸ªç”Ÿæˆç»“æœä¹‹é—´**è¯­ä¹‰å…±è¯†**çš„ä¸­å¿ƒæ ·æœ¬ã€‚
- **å®ç°æ–¹å¼**ï¼š
  1. æ„å»ºå€™é€‰ç”Ÿæˆä¹‹é—´çš„**åŠ æƒç›¸ä¼¼åº¦å›¾**ï¼ˆåŸºäº n-gram Jaccard ç›¸ä¼¼åº¦ï¼‰
  2. ä½¿ç”¨**è°±èšç±»**ï¼ˆspectral clusteringï¼‰é€’å½’åˆ’åˆ†å›¾ï¼Œè¯†åˆ«ä¸»å¯¼è¯­ä¹‰ç°‡
  3. åœ¨æœ€ç»ˆç°‡ä¸­é€‰æ‹©**åŠ æƒåº¦æœ€é«˜èŠ‚ç‚¹**ä½œä¸ºâ€œæ¨¡æ€è¾“å‡ºâ€

> ä¸éœ€è¦å¤–éƒ¨è¯„ä¼°å™¨ã€ä¸ä¾èµ– exact matchï¼Œå®Œå…¨åŸºäºç”Ÿæˆæ–‡æœ¬é—´çš„ç»“æ„å…³ç³»è¿›è¡Œé€‰æ‹©ã€‚

#### **ModeX-Lite**
- **åŠ¨æœº**ï¼šæå‡æ•ˆç‡ï¼Œåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å°½æ—©å‰ªæéä»£è¡¨æ€§è·¯å¾„ã€‚
- **æ”¹è¿›ç­–ç•¥**ï¼š
  - åœ¨æ¯ `T` æ­¥ç”Ÿæˆåæ‰§è¡Œä¸€æ¬¡è°±èšç±»
  - ä¿ç•™æœ€ä»£è¡¨æ€§çš„å­é›†ï¼Œä¸¢å¼ƒç¦»ç¾¤è·¯å¾„
  - æœ€ç»ˆä»å‰©ä½™è·¯å¾„ä¸­é€‰å‡ºè´¨å¿ƒè¾“å‡º
- æ˜¾è‘—é™ä½å»¶è¿Ÿï¼Œé€‚ç”¨äºå®é™…éƒ¨ç½²ã€‚

---

### âœ… ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç‰¹æ€§ | ModeX / ModeX-Lite | Best-of-N | Self-Consistency | LLM Judge |
|------|---------------------|-----------|------------------|-----------|
| æ˜¯å¦éœ€è¦å¤–éƒ¨è¯„ä¼°å™¨ | âŒ å¦ï¼ˆevaluator-freeï¼‰ | âœ… æ˜¯ | âŒ å¦ï¼ˆä½†éœ€ exact matchï¼‰ | âœ… æ˜¯ |
| æ”¯æŒå¼€æ”¾ç”Ÿæˆä»»åŠ¡ | âœ… æ˜¯ | âš ï¸ ä»…é™é—­åˆä»»åŠ¡ | âŒ éœ€å›ºå®šç­”æ¡ˆç©ºé—´ | âœ… æ˜¯ |
| è®¡ç®—æ•ˆç‡ | é«˜ï¼ˆå¹¶è¡Œç”Ÿæˆ + å›¾ç®—æ³• O(NÂ²)ï¼‰ | é«˜ï¼ˆä½†éœ€ reward model æ¨ç†ï¼‰ | ä½ï¼ˆä¸²è¡Œ refineï¼‰ | ä½ï¼ˆé¢å¤– LLM åˆ¤æ–­ï¼‰ |
| å¯æ‰©å±•æ€§ï¼ˆéš N å¢åŠ ï¼‰ | å¼ºï¼ˆæ€§èƒ½ç¨³å®šä¸Šå‡ï¼‰ | ä¾èµ– reward model è´¨é‡ | å¼±ï¼ˆæ— æ³•å¤„ç†è¯­ä¹‰ç­‰ä»·å˜ä½“ï¼‰ | ä¸­ç­‰ |

> **æ ¸å¿ƒä¼˜åŠ¿**ï¼šé¦–æ¬¡å®ç°äº†æ— éœ€å¤–éƒ¨è¯„ä¼°å™¨ã€å¯æ³›åŒ–è‡³ä»»æ„å¼€æ”¾ç”Ÿæˆä»»åŠ¡çš„é«˜æ•ˆ Best-of-N é€‰æ‹©æ¡†æ¶ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†

| ä»»åŠ¡ | æ•°æ®é›† | æè¿° |
|------|--------|------|
| **Text Summarization** | CNN/DailyMail | æ–°é—»æ–‡ç« æ‘˜è¦ä»»åŠ¡ï¼Œæµ‹è¯•æŠ½è±¡ç”Ÿæˆèƒ½åŠ› |
| **Code Generation** | HumanEval | åŒ…å« 164 ä¸ª Python ç¼–ç¨‹é¢˜ï¼Œå¸¦å•å…ƒæµ‹è¯• |
| **Mathematical Reasoning** | Math-500 | 500 é“æ•°å­¦é¢˜ï¼Œæ¶µç›–ä»£æ•°ã€å‡ ä½•ã€æ¦‚ç‡ç­‰é¢†åŸŸ |

---

### âš™ï¸ å®éªŒè®¾ç½®

- **æ¨¡å‹**ï¼š
  - Qwen2.5-7b-instruct
  - Llama3.1-8b-instructï¼ˆCodeLlama-7b-Instruct ç”¨äºä»£ç ä»»åŠ¡ï¼‰
- **ç”Ÿæˆå‚æ•°**ï¼š
  - æ¸©åº¦ > 0ï¼ˆå¼•å…¥å¤šæ ·æ€§ï¼‰
  - Top-p é‡‡æ ·
  - N âˆˆ {4, 8, 16} æ¡ç”Ÿæˆè·¯å¾„
- **ç›¸ä¼¼åº¦è®¡ç®—**ï¼š
  - åŠ æƒ Jaccard ç›¸ä¼¼åº¦ï¼ˆunigram + bigram + trigramï¼‰
- **è°±èšç±»ç»ˆæ­¢æ¡ä»¶**ï¼š
  - Conductance < Tï¼ˆé»˜è®¤ T=0.8ï¼‰

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡

| ä»»åŠ¡ | ä¸»è¦æŒ‡æ ‡ |
|------|---------|
| æ–‡æœ¬æ‘˜è¦ | ROUGE-1, ROUGE-2, ROUGE-L, BLEU |
| ä»£ç ç”Ÿæˆ | Pass@1ï¼ˆåŠŸèƒ½æ­£ç¡®ç‡ï¼‰ |
| æ•°å­¦æ¨ç† | Accuracyï¼ˆæœ€ç»ˆç­”æ¡ˆæ˜¯å¦æ­£ç¡®ï¼‰ |

---

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”

| åŸºçº¿æ–¹æ³• | ç®€ä»‹ |
|--------|------|
| **Single Path** | å•è·¯å¾„ç”Ÿæˆï¼Œå¹³å‡ 16 æ¬¡è¿è¡Œç»“æœ |
| **Self-Refine** | è¿­ä»£è‡ªæˆ‘ä¿®æ­£ 4 è½® |
| **LLM Judge (N=4/16)** | ä½¿ç”¨å¦ä¸€ä¸ª LLM ä» N ä¸ªå€™é€‰ä¸­é€‰æœ€ä¼˜ |
| **Perplexity BoN** | é€‰å›°æƒ‘åº¦æœ€ä½çš„è¾“å‡º |
| **Self-Certainty BoN** | é€‰è´Ÿå¯¹æ•°ä¼¼ç„¶æœ€å°çš„è¾“å‡º |
| **Best-of-N (Gold Standard)** | ä½¿ç”¨ reward model æ‰“åˆ†é€‰æ‹©æœ€ä½³ï¼ˆæœ‰ç›‘ç£ä¸Šé™ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ Qwen æ¨¡å‹ä¸ºä¾‹ï¼‰

| æ–¹æ³• | Text Summarization (ROUGE-L) | Code Generation (Pass@1) | Math Reasoning (Acc) |
|------|-------------------------------|--------------------------|-----------------------|
| Single Path | 20.17 | 69.89% | 70.98% |
| LLM Judge (N=16) | 19.72 | 65.24% | 74.67% |
| Perplexity BoN | 21.06 | 73.17% | 78.00% |
| Self-Certainty BoN | 19.32 | 55.49% | 67.00% |
| **ModeX (N=16)** | **21.06** | **75.61%** | **78.00%** |
| **ModeX-Lite (N=16)** | **21.89** | **78.66%** | **75.33%** |

> âœ… **ModeX-Lite åœ¨ä¸‰é¡¹ä»»åŠ¡ä¸Šå‡æ˜¾è‘—ä¼˜äºæ‰€æœ‰ evaluator-free å’Œéƒ¨åˆ† evaluator-based æ–¹æ³•**

---

### ğŸ” ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

- **è¶…è¶Š LLM Judge**ï¼š
  - åœ¨ä»£ç ç”Ÿæˆä»»åŠ¡ä¸­ï¼ŒModeX-Lite (78.66%) > LLM Judge (65.24%)
  - è¡¨æ˜â€œç»“æ„æ„ŸçŸ¥é€‰æ‹©â€ä¼˜äºâ€œå…ƒæ¨¡å‹æ‰“åˆ†â€
- **æ¥è¿‘ç”šè‡³è¶…è¶Š Gold Standard Best-of-N**ï¼š
  - åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­ï¼ŒModeX-Lite è¾¾åˆ° 75.33%ï¼Œæ¥è¿‘ Llama ä¸Šçš„ Best-of-16 (63.00%)ï¼Œä¸”æ— éœ€ reward model
- **ä¼˜äº Self-Certainty**ï¼š
  - Self-Certainty åœ¨å¤šé¡¹ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ï¼ˆå¦‚ä»£ç ç”Ÿæˆä»… 55.49%ï¼‰ï¼Œè¯´æ˜ä½ä¸ç¡®å®šæ€§ â‰  é«˜è´¨é‡è¾“å‡º

---

### ğŸ”§ æ¶ˆèå®éªŒä¸æ•æ„Ÿæ€§åˆ†æ

#### ï¼ˆ1ï¼‰ç›¸ä¼¼åº¦å‡½æ•°æ¯”è¾ƒï¼ˆAppendix Eï¼‰

| æ–¹æ³• | ROUGE-L | Pass@1 | Accuracy |
|------|--------|--------|---------|
| ModeX-cosine (embedding) | 20.26 | 75.00% | 71.33% |
| **ModeX-n-gram (Jaccard)** | **21.06** | **75.61%** | **78.00%** |

> n-gram Jaccard æ˜æ˜¾ä¼˜äº embedding cosineï¼Œè¯´æ˜å±€éƒ¨è¯é‡å æ›´åˆ©äºæ•æ‰è¯­ä¹‰ä¸€è‡´æ€§ã€‚

#### ï¼ˆ2ï¼‰è¶…å‚æ•°æ•æ„Ÿæ€§ï¼ˆFigure 5ï¼‰

- **Conductance é˜ˆå€¼ T âˆˆ [0.5, 0.9]**ï¼šæ€§èƒ½ç¨³å¥ï¼ŒT=0.8 æ•ˆæœæœ€å¥½
- **Pruning Frequency T âˆˆ [100,500]**ï¼šå³ä½¿ç¨€ç–å‰ªæä¹Ÿèƒ½ä¿æŒå¢ç›Š
- æ‰€æœ‰é…ç½®ä¸‹ï¼ŒModeX-Lite å‡æ˜¾è‘—ä¼˜äº Single Path

#### ï¼ˆ3ï¼‰è®¡ç®—å¤æ‚åº¦ä¸å»¶è¿Ÿï¼ˆTable 2ï¼‰

| æ–¹æ³• | å¤æ‚åº¦ | å®æµ‹å»¶è¿Ÿï¼ˆQwen, CNN/DMï¼‰ |
|------|--------|--------------------------|
| Single Path | O(L) | 5.5s |
| Self-Refine | O(kL) | 31.7s |
| LLM Judge | O(NL + NL_judge) | 10.7s |
| **ModeX-Lite (N=4)** | O(NL + NÂ²) | **7.2s** |
| **ModeX-Lite (N=16)** | O(NL + NÂ²) | **9.1s** |

> ModeX-Lite æ¯” Self-Refine å¿« **3.5Ã—**ï¼Œæ¯” LLM Judge æ›´å¿«ä¸”æ— éœ€é¢å¤–æ¨¡å‹ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **â€œæ¨¡æ€è¾“å‡ºâ€æ˜¯é«˜è´¨é‡ç”Ÿæˆçš„æœ‰æ•ˆä»£ç†**  
   - é«˜è´¨é‡ç”Ÿæˆå€¾å‘äºå½¢æˆè¯­ä¹‰ä¸€è‡´çš„ç°‡ï¼Œè€Œé”™è¯¯/å¹»è§‰å¾€å¾€æ˜¯å­¤ç«‹ç‚¹ã€‚
   - é€šè¿‡è°±èšç±»è¯†åˆ«ä¸»å¯¼ç°‡ï¼Œå¹¶å–å…¶è´¨å¿ƒï¼Œèƒ½æœ‰æ•ˆé€¼è¿‘â€œçœŸå®æ¨¡å¼â€ã€‚

2. **æ— éœ€å¤–éƒ¨è¯„ä¼°å™¨ä¹Ÿå¯å®ç°é«˜æ€§èƒ½ Best-of-N**  
   - ModeX æ˜¯é¦–ä¸ªçœŸæ­£å®ç° **evaluator-free** çš„å¼€æ”¾ç”Ÿæˆ Best-of-N æ–¹æ³•ã€‚
   - æ€§èƒ½åª²ç¾ç”šè‡³è¶…è¿‡ä¾èµ– reward model çš„æ–¹æ³•ã€‚

3. **ç»“æ„æ„ŸçŸ¥é€‰æ‹©ä¼˜äºç®€å•æ‰“åˆ†æœºåˆ¶**  
   - Perplexity å’Œ Self-Certainty å¹¶ä¸èƒ½å¯é åæ˜ è¾“å‡ºè´¨é‡ã€‚
   - åŸºäºå›¾ç»“æ„çš„é€‰æ‹©æ›´èƒ½æ•æ‰è¯­ä¹‰å…±è¯†ã€‚

4. **æ—©æœŸå‰ªæå¯è¡Œä¸”é«˜æ•ˆ**  
   - ModeX-Lite è¯æ˜å¯åœ¨ç”Ÿæˆä¸­é€”è¯†åˆ«å¹¶å‰ªæåŠ£è´¨è·¯å¾„ï¼Œå¤§å¹…èŠ‚çœèµ„æºã€‚

---

### âš ï¸ å±€é™æ€§

1. **ä¾èµ–è¯æ³•ç›¸ä¼¼åº¦ï¼ˆJaccardï¼‰**  
   - å¯¹åŒä¹‰æ”¹å†™ã€å¥å¼å˜æ¢æ•æ„Ÿï¼Œå¯èƒ½è¯¯åˆ¤è¯­ä¹‰ç›¸åŒä½†è¡¨é¢ä¸åŒçš„é«˜è´¨é‡è¾“å‡ºã€‚
   - æœªæ¥å¯æ¢ç´¢ embedding-based æˆ–è¯­ä¹‰è§£ææ ‘ç›¸ä¼¼åº¦ã€‚

2. **å‡è®¾â€œä¼—æ•°å³æ­£ç¡®â€**  
   - è‹¥æ¨¡å‹å­˜åœ¨ç³»ç»Ÿæ€§åè§æˆ–æ¨¡å¼åå¡Œï¼ˆmode collapseï¼‰ï¼Œå¯èƒ½ä¼šå¼ºåŒ–é”™è¯¯å…±è¯†ã€‚
   - è¯¥é—®é¢˜æ˜¯ LLM è‡ªèº«ç¼ºé™·ï¼Œé ModeX ç‰¹æœ‰ã€‚

3. **ç¯å¢ƒæˆæœ¬å¢åŠ **  
   - å¤šè·¯å¾„ç”Ÿæˆå¸¦æ¥æ›´é«˜èƒ½è€—ï¼Œè™½æ•ˆç‡é«˜ä½†ä»é«˜äºå•è·¯å¾„ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

- æ¢ç´¢æ›´é²æ£’çš„è¯­ä¹‰ç›¸ä¼¼åº¦åº¦é‡ï¼ˆå¦‚ SBERTã€Tree Edit Distanceï¼‰
- ç»“åˆè½»é‡çº§ verifier è¿›è¡Œ hybrid selection
- å°† ModeX åº”ç”¨äºå¯¹è¯ç³»ç»Ÿã€åˆ›æ„å†™ä½œç­‰æ›´å¤æ‚åœºæ™¯
- åŠ¨æ€è°ƒæ•´å‰ªæé¢‘ç‡ä¸é˜ˆå€¼ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–æ•ˆç‡

---

## âœ… æ€»ç»“

**ModeX** æå‡ºäº†ä¸€ç§å…¨æ–°çš„ã€æ— éœ€å¤–éƒ¨è¯„ä¼°å™¨çš„ Best-of-N é€‰æ‹©èŒƒå¼ï¼Œé€šè¿‡æ„å»ºç”Ÿæˆæ–‡æœ¬çš„ç›¸ä¼¼åº¦å›¾å¹¶åº”ç”¨è°±èšç±»æ¥æå–â€œæ¨¡æ€è¾“å‡ºâ€ï¼ŒæˆåŠŸå°†å¤šæ•°æŠ•ç¥¨æ€æƒ³æ¨å¹¿åˆ°å¼€æ”¾ç”Ÿæˆé¢†åŸŸã€‚å…¶è½»é‡ç‰ˆ **ModeX-Lite** è¿›ä¸€æ­¥å®ç°äº†é«˜æ•ˆå‰ªæï¼Œåœ¨æ–‡æœ¬æ‘˜è¦ã€ä»£ç ç”Ÿæˆå’Œæ•°å­¦æ¨ç†ä¸‰å¤§ä»»åŠ¡ä¸Šå…¨é¢è¶…è¶Šä¸»æµåŸºçº¿ï¼Œå…¼å…·é«˜æ€§èƒ½ä¸ä½å»¶è¿Ÿï¼Œä¸º LLM çš„é²æ£’ç”Ÿæˆæä¾›äº†å®ç”¨ä¸”ç†è®ºåšå®çš„è§£å†³æ–¹æ¡ˆã€‚

> ğŸ”— å¼€æºåœ°å€ï¼š[https://github.com/deeplearning-wisc/ModeX](https://github.com/deeplearning-wisc/ModeX)

</details>

---

### 9. [Punctuation-aware Hybrid Trainable Sparse Attention for Large Language Models](https://arxiv.org/abs/2601.02819)

**Authors**: Junxiang Qiu, Shuo Wang, Zhengsu Chen, Hengheng Zhang, Jinda Lu, Changcheng Li, Qi Tian  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.02819v1  

#### Abstract
Attention serves as the fundamental mechanism for long-context modeling in large language models (LLMs), yet dense attention becomes structurally prohibitive for long sequences due to its quadratic complexity. Consequently, sparse attention has received increasing attention as a scalable alternative...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šPunctuation-aware Hybrid Trainable Sparse Attention for Large Language Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„ **sparse attention** æ–¹æ³•åœ¨é•¿åºåˆ—å»ºæ¨¡ä¸­é¢ä¸´ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼š
1. **è¯­ä¹‰è¾¹ç•Œæ¨¡ç³Š**ï¼šåœ¨ block selection é˜¶æ®µé€šå¸¸é‡‡ç”¨å¹³å‡æ± åŒ–ï¼ˆaverage poolingï¼‰èšåˆè¿ç»­ tokenï¼Œå¯¼è‡´å—å†…ç»†ç²’åº¦è¯­ä¹‰è¾¹ç•Œè¢«æ¨¡ç³Šï¼Œå…³é”®å®ä½“æˆ–é€»è¾‘æ¢çº½å¯èƒ½è¢«æ— å…³ token ç¨€é‡Šï¼Œé€ æˆä¿¡æ¯ä¸¢å¤±ã€‚
2. **æç«¯ç¨€ç–ä¸‹çš„æ€§èƒ½é€€åŒ–**ï¼šå½“æ¿€æ´» token æ•°é‡æä½æ—¶ï¼ˆå¦‚ sparsity ratio > 95%ï¼‰ï¼Œæ¨¡å‹è¡¨ç°æ˜¾è‘—ä¸‹é™ï¼Œé™åˆ¶äº†å…¶åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šçš„é«˜æ•ˆéƒ¨ç½²æ½œåŠ›ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šPHSAï¼ˆPunctuation-aware Hybrid Sparse Attentionï¼‰
ä½œè€…æå‡ºäº†ä¸€ç§**åŸç”Ÿå¯è®­ç»ƒçš„ç¨€ç–æ³¨æ„åŠ›æ¡†æ¶**â€”â€”**PHSA**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨æ ‡ç‚¹ç¬¦å·ä½œä¸ºè‡ªç„¶çš„è¯­ä¹‰è¾¹ç•Œé”šç‚¹ï¼Œæå‡ç¨€ç–é€‰æ‹©çš„å‡†ç¡®æ€§ã€‚

#### åˆ›æ–°ç‚¹ï¼š
- âœ… **åŒåˆ†æ”¯èšåˆæœºåˆ¶ï¼ˆDual-branch Aggregation Mechanismï¼‰**  
  æ¯ä¸ª key block æ„é€ ä¸€ä¸ªä»£è¡¨å‘é‡ï¼Œèåˆä¸¤ç§è¯­ä¹‰è¡¨ç¤ºï¼š
  - **Global Semantic Representation**ï¼šå¯¹ block å†…æ‰€æœ‰ token è¿›è¡Œå¹³å‡æ± åŒ–ï¼Œæ•æ‰æ•´ä½“è¯­ä¹‰ã€‚
  - **Punctuation-aware Semantic Representation**ï¼šä»…å¯¹æ ‡ç‚¹ tokenï¼ˆå¦‚é€—å·ã€å¥å·ï¼‰è¿›è¡Œæ± åŒ–ï¼Œä¿ç•™è¯­ä¹‰è½¬æŠ˜ç‚¹ä¿¡æ¯ã€‚
  - æœ€ç»ˆé€šè¿‡é—¨æ§å‚æ•° $\lambda$ åŠ æƒèåˆï¼š  
    $$
    M(B_t) = \lambda \cdot M_o(B_t) + (1-\lambda) \cdot M_p(B_t)
    $$

- âœ… **æç«¯ç¨€ç–è‡ªé€‚åº”è®­ç»ƒä¸æ¨ç†ç­–ç•¥ï¼ˆExtreme-sparsity-adaptive Training & Inferenceï¼‰**  
  è®¾è®¡äº†é’ˆå¯¹æä½ Top-K è®¾ç½®çš„ç¨³å®šè®­ç»ƒæ–¹æ¡ˆï¼Œä½¿æ¨¡å‹èƒ½åœ¨æå°æ¿€æ´» token æ¯”ä¾‹ä¸‹ä»ä¿æŒè‰¯å¥½æ€§èƒ½ï¼Œæ”¯æŒè½»é‡åŒ–éƒ¨ç½²ã€‚

- âœ… **æ— é¢å¤–è®¡ç®—å¼€é”€**  
  åˆ©ç”¨å·²æœ‰æ ‡ç‚¹ tokenï¼Œæ— éœ€å¼•å…¥é¢å¤–æ¨¡å—æˆ–å‚æ•°ï¼Œå‡ ä¹ä¸å¢åŠ è®¡ç®—è´Ÿæ‹…ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **è¯­ä¹‰ç²¾åº¦** | åˆ©ç”¨æ ‡ç‚¹ä½œä¸ºè¾¹ç•Œæç¤ºï¼Œé¿å…ç²—ç²’åº¦èšåˆå¸¦æ¥çš„è¯­ä¹‰ç¨€é‡Š |
| **ä¿¡æ¯ä¿ç•™èƒ½åŠ›** | åœ¨é«˜ç¨€ç–åº¦ä¸‹æ˜¾è‘—å‡å°‘å…³é”®ä¿¡æ¯ä¸¢å¤± |
| **è®­ç»ƒç¨³å®šæ€§** | æ”¯æŒæ›´ä½çš„ Top-K å€¼è®­ç»ƒï¼Œçªç ´ä¼ ç»Ÿç¨€ç–æ³¨æ„åŠ›çš„æ€§èƒ½ç“¶é¢ˆ |
| **é€šç”¨æ€§** | å¯åº”ç”¨äºè®­ç»ƒå‹ä¸éè®­ç»ƒå‹ï¼ˆtraining-freeï¼‰åœºæ™¯ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **è®­ç»ƒæ•°æ®é›†**ï¼š
  - å¼€æºæ•°æ®ï¼š`dclm`, `mapcc`, `ultrachat`, `tulu-v3`, `finemath`, `megamath`
  - è‡ªç ”é«˜è´¨é‡æ•™è‚²é¢†åŸŸç§æœ‰æ•°æ®ï¼ˆæœªå…¬å¼€ï¼‰
- **è¯„ä¼°åŸºå‡†**ï¼š
  - **General Benchmarks**ï¼ˆ15é¡¹ä»»åŠ¡ï¼‰ï¼š
    - æ•°å­¦æ¨ç†ï¼šGSM8K, MathQA, MATH
    - å¸¸è¯†é—®ç­”ï¼šARC-C, ARC-C-ZH, ARC-E
    - ç»¼åˆè®¤çŸ¥ï¼šMMLU, CMMLU, BBH
    - æ–‡æœ¬è¿è´¯æ€§ï¼šLAMBADA, XStoryCloze
    - ç¼–ç¨‹ç”Ÿæˆï¼šHumanEval
    - é¢†åŸŸä»»åŠ¡ï¼šC-Valid, HellaSwag, PiPA
  - **é•¿ä¸Šä¸‹æ–‡ä¸“é¡¹è¯„æµ‹**ï¼š
    - **LongBench**ï¼šæ¶µç›–å•è½®é—®ç­”ã€å°‘æ ·æœ¬å­¦ä¹ ã€æ‘˜è¦ã€ä»£ç ç­‰å¤šä»»åŠ¡
    - **Needle-in-a-Haystack (NIAH)**ï¼šç”¨äºå®šé‡æµ‹é‡ç¨€ç–æ³¨æ„åŠ›ä¸‹çš„ä¿¡æ¯ä¿ç•™èƒ½åŠ›

### å®éªŒè®¾ç½®
- **æ¨¡å‹è§„æ¨¡**ï¼šQwen3-0.6B å’Œ Qwen3-8B
- **åºåˆ—é•¿åº¦**ï¼š4k å’Œ 32k tokens
- **Block Size**ï¼š16 tokens/block
- **å±€éƒ¨çª—å£ä¸åˆå§‹å—**ï¼š
  - 4kï¼šinit=16, window=128
  - 32kï¼šinit=128, window=512
- **è®­ç»ƒæ–¹å¼**ï¼š
  - è®­ç»ƒé˜¶æ®µä» Qwen3-0.6B-Base åˆå§‹åŒ–
  - åˆ†åˆ«æµ‹è¯• **è®­ç»ƒä¸€è‡´ï¼ˆtraining-inference consistentï¼‰** ä¸ **è®­ç»ƒè‡ªç”±ï¼ˆtraining-freeï¼‰** åœºæ™¯

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | ç”¨é€” |
|------|------|
| **NIAH Score** | è¡¡é‡é•¿è·ç¦»ä¿¡æ¯æ£€ç´¢èƒ½åŠ›ï¼Œè¶Šé«˜è¡¨ç¤ºä¿¡æ¯æŸå¤±è¶Šå°‘ |
| **Average Score on General Benchmarks** | ç»¼åˆæ€§èƒ½è¯„ä¼° |
| **LongBench Subtask & Avg Scores** | é•¿æ–‡æœ¬ç†è§£èƒ½åŠ›è¯„ä¼° |
| **Sparsity Ratio / Activated Token Count** | æ•ˆç‡æŒ‡æ ‡ï¼Œåæ˜ è®¡ç®—å‹ç¼©ç¨‹åº¦ |

### å¯¹æ¯”çš„åŸºçº¿æ–¹æ³•
- **Dense Attention**ï¼šå…¨è¿æ¥æ³¨æ„åŠ›ï¼ŒO($L^2$) å¤æ‚åº¦
- **InfLLM v2**ï¼ˆZhao et al., 2025ï¼‰ï¼šå½“å‰æœ€å…ˆè¿›çš„å¯è®­ç»ƒç¨€ç–æ³¨æ„åŠ›æ–¹æ³•
- **NSA**ï¼ˆYuan et al., 2025ï¼‰ï¼šDeepSeek æå‡ºçš„åŠ¨æ€åˆ†å±‚ç¨€ç–ç­–ç•¥

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ğŸ“Š åœ¨ NIAH ä»»åŠ¡ä¸Šï¼ˆ32k åºåˆ—ï¼Œ0.6B æ¨¡å‹ï¼‰
| æ–¹æ³• | Sparsity Ratio | ä¿¡æ¯æŸå¤±é™ä½å¹…åº¦ |
|------|----------------|------------------|
| **PHSA** | **97.3%** | **ç›¸å¯¹å‡å°‘ 10.8% ä¿¡æ¯æŸå¤±** |

> æ³¨ï¼šç›¸æ¯” InfLLM v2ï¼Œåœ¨åŒç­‰æç«¯ç¨€ç–æ¡ä»¶ä¸‹ï¼ŒPHSA æ˜¾è‘—æå‡äº†ä¿¡æ¯ä¿ç•™èƒ½åŠ›ã€‚

#### ğŸ“ˆ åœ¨ General Benchmarks ä¸Šçš„è¡¨ç°ï¼ˆQwen3-0.6Bï¼Œ100B tokens è®­ç»ƒï¼‰

| æ–¹æ³• | Inference Top-K | Average Score |
|------|------------------|---------------|
| Dense Attention | N/A | 48.96 |
| InfLLM v2 | 4 | 49.11 |
| **PHSA** | **4** | **49.24** âœ…ï¼ˆæœ€ä¼˜ï¼‰ |

ğŸ‘‰ **ç»“è®º**ï¼šPHSA ä¸ä»…ä¼˜äº InfLLM v2ï¼Œç”šè‡³è¶…è¿‡äº† dense attention çš„å¹³å‡è¡¨ç°ã€‚

#### ğŸ” åœ¨ LongBench ä¸Šçš„æ•´ä½“æ€§èƒ½

| æ–¹æ³• | Average Score |
|------|---------------|
| Dense Attention | 27.86 |
| InfLLM v2 | 27.40 |
| **PHSA** | **28.13** âœ… |
| **PHSA_en+zh**ï¼ˆåŠ å…¥ä¸­æ–‡æ ‡ç‚¹ï¼‰ | **28.15** âœ…âœ… |

ğŸ‘‰ åœ¨å¤šæ•°å­ä»»åŠ¡ä¸­å‡å–å¾—é¢†å…ˆï¼Œå°¤å…¶åœ¨ä»£ç ç›¸å…³ä»»åŠ¡ï¼ˆLCC, RBPï¼‰ä¸Šæœ‰æ˜æ˜¾æå‡ã€‚

#### âš™ï¸ æ¶ˆèå®éªŒä¸å…³é”®å‘ç°ï¼ˆRQ1-RQ4ï¼‰

| ç ”ç©¶é—®é¢˜ | å‘ç° |
|--------|------|
| **RQ1: ä¸ºä½•åå¥½æ›´ä½ Top-Kï¼Ÿ** | è®­ç»ƒæ—¶ä½¿ç”¨è¾ƒä½ Top-Kï¼ˆå¦‚ 2 æˆ– 4ï¼‰æœ‰åŠ©äºåœ¨æ¨ç†é˜¶æ®µç»´æŒä½æ¿€æ´» token ä¸‹çš„æ€§èƒ½ï¼›ä½† Top-K=1 å¯¼è‡´å´©æºƒï¼ŒTop-K>4 æ€§èƒ½ä¸‹é™ â†’ **Top-K=2 æ˜¯å±€éƒ¨æœ€ä¼˜è§£** |
| **RQ2: æ˜¯å¦æå‡é€šç”¨æ€§èƒ½ï¼Ÿ** | æ˜¯ã€‚PHSA åœ¨ 20B å’Œ 100B è®­ç»ƒæ­¥æ•°ä¸‹å‡ä¼˜äº InfLLM v2ï¼Œå¹¶æ¥è¿‘ç”šè‡³è¶…è¶Š dense attention |
| **RQ3: æ˜¯å¦é€‚ç”¨äºé•¿ä¸Šä¸‹æ–‡ï¼Ÿ** | æ˜¯ã€‚åœ¨ 16k å’Œ 32k åºåˆ—çš„ NIAH æµ‹è¯•ä¸­ï¼ŒPHSA æŒç»­ä¼˜äº InfLLM v2ï¼Œä¸”è®­ç»ƒåå¢ç›Šæ›´æ˜æ˜¾ï¼ˆè§ Figure 3ï¼‰ |
| **RQ4: è·¨è¯­è¨€å½±å“ï¼Ÿ** | ä¸­æ–‡ä»»åŠ¡ï¼ˆarc_c_zh, MQZï¼‰è¡¨ç°ç•¥å·® â†’ å½’å› äºè®­ç»ƒæ—¶ä»…ä½¿ç”¨è‹±æ–‡æ ‡ç‚¹ï¼›å¼•å…¥ä¸­æ–‡æ ‡ç‚¹åï¼ˆPHSA_en+zhï¼‰ï¼ŒMQZ ä» 20.63 æå‡è‡³ 22.22ï¼ŒéªŒè¯äº†æ ‡ç‚¹è¯­è¨€é€‚é…çš„é‡è¦æ€§ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦ç»“è®º
1. âœ… **æ ‡ç‚¹ç¬¦å·æ˜¯æœ‰æ•ˆçš„è¯­ä¹‰è¾¹ç•ŒæŒ‡ç¤ºå™¨**ï¼šå°†å…¶ä½œä¸ºç¨€ç–æ³¨æ„åŠ›ä¸­çš„â€œé”šç‚¹â€ï¼Œèƒ½æœ‰æ•ˆç¼“è§£ block aggregation ä¸­çš„ä¿¡æ¯ç¨€é‡Šé—®é¢˜ã€‚
2. âœ… **PHSA åœ¨å¤šç§åœºæ™¯ä¸‹å…¨é¢ä¼˜äº baseline**ï¼š
   - åœ¨ general benchmarks ä¸Šè¾¾åˆ°ç”šè‡³è¶…è¿‡ dense attention æ°´å¹³ï¼›
   - åœ¨ long-context ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äº InfLLM v2ï¼›
   - åœ¨æç«¯ç¨€ç–è®¾ç½®ä¸‹è¡¨ç°å‡ºæ›´å¼ºé²æ£’æ€§ã€‚
3. âœ… **æ”¯æŒè½»é‡åŒ–éƒ¨ç½²**ï¼šé€šè¿‡æç«¯ç¨€ç–è‡ªé€‚åº”è®­ç»ƒï¼Œå¯åœ¨æä½ token æ¿€æ´»æ¯”ä¾‹ä¸‹ç¨³å®šè¿è¡Œï¼Œé€‚åˆè¾¹ç¼˜è®¾å¤‡åº”ç”¨ã€‚

### å±€é™æ€§
- â— **æ ‡ç‚¹å™ªå£°é—®é¢˜**ï¼šå¹¶éæ‰€æœ‰æ ‡ç‚¹éƒ½å…·æœ‰å¼ºè¯­ä¹‰è¾¹ç•Œæ„ä¹‰ï¼ˆå¦‚å¼•å·ã€æ‹¬å·ï¼‰ï¼Œå…¨é‡å¼•å…¥å¯èƒ½å¸¦æ¥å™ªå£°ã€‚
- â— **è¯­è¨€ä¾èµ–æ€§**ï¼šå½“å‰æ–¹æ³•å¯¹æ ‡ç‚¹çš„è¯­è¨€è¦†ç›–æœ‰é™ï¼Œè·¨è¯­è¨€æ³›åŒ–éœ€è¿›ä¸€æ­¥ä¼˜åŒ–ï¼ˆå·²é€šè¿‡ PHSA_en+zh åˆæ­¥éªŒè¯ï¼‰ã€‚
- â— **é™æ€ block åˆ’åˆ†**ï¼šå›ºå®šå¤§å°çš„ block å¯èƒ½æ— æ³•åŒ¹é…çœŸå®è¯­ä¹‰å•å…ƒé•¿åº¦ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ **ç­›é€‰æ›´æœ‰æ„ä¹‰çš„æ ‡ç‚¹å­é›†**ï¼ˆå¦‚å¥å·ã€åˆ†å·ä¼˜å…ˆï¼‰ï¼Œä»¥æå‡ä¿¡å™ªæ¯”ï¼›
- æ‰©å±•è‡³æ›´å¤šè¯­è¨€ï¼Œæ„å»º **å¤šè¯­è¨€æ ‡ç‚¹æ„ŸçŸ¥æœºåˆ¶**ï¼›
- ç»“åˆåŠ¨æ€ block segmentationï¼Œå®ç°æ›´çµæ´»çš„è¯­ä¹‰åˆ‡åˆ†ï¼›
- å°† PHSA é›†æˆåˆ°æ›´å¤§è§„æ¨¡æ¨¡å‹ï¼ˆå¦‚ 70B+ï¼‰ä¸­éªŒè¯å¯æ‰©å±•æ€§ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> PHSA é€šè¿‡å·§å¦™åˆ©ç”¨ **punctuation tokens ä½œä¸ºè¯­ä¹‰è¾¹ç•Œé”šç‚¹**ï¼Œè®¾è®¡äº†ä¸€ç§é«˜æ•ˆã€å¯è®­ç»ƒã€ä½æŸè€—çš„ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼Œåœ¨ä¿æŒæä½è®¡ç®—å¤æ‚åº¦çš„åŒæ—¶ï¼Œå®ç°äº†ä¼˜äº dense attention å’Œ SOTA sparse æ–¹æ³•çš„ç»¼åˆæ€§èƒ½ï¼Œä¸º LLM çš„é•¿ä¸Šä¸‹æ–‡å¤„ç†ä¸è½»é‡åŒ–éƒ¨ç½²æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 10. [MedDialogRubrics: A Comprehensive Benchmark and Evaluation Framework for Multi-turn Medical Consultations in Large Language Models](https://arxiv.org/abs/2601.03023)

**Authors**: Lecheng Gong, Weimin Fang, Ting Yang, Dongjie Tao, Chunxiao Guo, Peng Wei, Bo Xie, Jinqun Guan, Zixiao Chen, Fang Shi, Jinjie Gu, Junwei Liu  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.03023v1  

#### Abstract
Medical conversational AI (AI) plays a pivotal role in the development of safer and more effective medical dialogue systems. However, existing benchmarks and evaluation frameworks for assessing the information-gathering and diagnostic reasoning abilities of medical large language models (LLMs) have ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# MedDialogRubrics: A Comprehensive Benchmark and Evaluation Framework for Multi-turn Medical Consultations in Large Language Models  
**æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰åŒ»å­¦å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¯„ä¼°å¤šé›†ä¸­äºé™æ€ä»»åŠ¡ï¼ˆå¦‚å¤šé¡¹é€‰æ‹©é¢˜ã€æ‘˜è¦ç”Ÿæˆï¼‰ï¼Œç¼ºä¹å¯¹**å¤šè½®è¯Šæ–­å¯¹è¯èƒ½åŠ›**çš„ç³»ç»Ÿæ€§è¯„ä¼°æ¡†æ¶ã€‚å…·ä½“å­˜åœ¨ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **æ•°æ®ç¨€ç¼ºä¸éšç§é—®é¢˜**ï¼šçœŸå®åŒ»ç–—å¯¹è¯æ•°æ®å— HIPAA/GDPR ç­‰æ³•è§„é™åˆ¶ï¼Œéš¾ä»¥å¤§è§„æ¨¡è·å–ã€‚
- **æ¨¡æ‹Ÿå¯é æ€§å·®**ï¼šåŸºäº LLM çš„æ‚£è€…ä»£ç†ï¼ˆPatient Agentï¼‰æ˜“äº§ç”Ÿå¹»è§‰ï¼ˆhallucinationsï¼‰ï¼Œå¯¼è‡´å¯¹è¯ä¸ä¸€è‡´æˆ–è¿èƒŒåŒ»å­¦é€»è¾‘ã€‚
- **è¯„ä¼°ä¸»è§‚æ€§å¼º**ï¼šä¼ ç»Ÿäººå·¥æ ‡æ³¨æˆæœ¬é«˜ï¼Œä¸”ç¼ºä¹æ ‡å‡†åŒ–â€œå¿…é¡»æé—®â€ï¼ˆmust-askï¼‰æ ‡å‡†ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
ä½œè€…æå‡º **MedDialogRubrics**ï¼Œä¸€ä¸ªå…¨é¢çš„å¤šè½®åŒ»å­¦å’¨è¯¢è¯„ä¼°æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

| åˆ›æ–°ç‚¹ | æè¿° |
|--------|------|
| **åˆæˆæ‚£è€…æ¡ˆä¾‹ç”Ÿæˆ** | åŸºäºæƒå¨åŒ»å­¦çŸ¥è¯†åº“ï¼ˆå¦‚ UpToDateã€NICE æŒ‡å—ï¼‰æ„å»º 5,200 ä¸ªåˆæˆç—…ä¾‹ï¼Œæ— éœ€è®¿é—®çœŸå®ç”µå­å¥åº·è®°å½•ï¼ˆEHRï¼‰ï¼Œä¿éšœéšç§ã€‚ |
| **æŠ—å¹»è§‰æ‚£è€…ä»£ç†è®¾è®¡** | è®¾è®¡åŸºäºâ€œåŸå­åŒ»å­¦äº‹å®â€ï¼ˆatomic medical factsï¼‰çš„ Patient Agentï¼Œå¹¶å¼•å…¥åŠ¨æ€å¼•å¯¼æœºåˆ¶ï¼ˆGuidance Injection Loopï¼‰ï¼Œå®æ—¶æ£€æµ‹å¹¶çº æ­£å¹»è§‰ï¼Œç¡®ä¿å¯¹è¯å†…éƒ¨ä¸€è‡´æ€§ä¸ä¸´åºŠåˆç†æ€§ã€‚ |
| **EBM é©±åŠ¨çš„ç»†ç²’åº¦è¯„åˆ†æ ‡å‡†ï¼ˆRubricsï¼‰** | æ„å»ºè¶…è¿‡ 60,000 æ¡åŸºäºå¾ªè¯åŒ»å­¦ï¼ˆEvidence-Based Medicine, EBMï¼‰æŒ‡å—çš„â€œå…³é”®è¯¢é—®é¡¹â€ï¼ˆkey inquiry pointsï¼‰ï¼Œé€šè¿‡æ‹’ç»é‡‡æ ·ï¼ˆreject samplingï¼‰ç­›é€‰å‡ºâ€œmust-askâ€é—®é¢˜ä½œä¸ºè¯„åˆ†ä¾æ®ã€‚ |
| **ä¸“å®¶-LLM ååŒçš„è¯„åˆ†ä½“ç³»** | ç»“åˆ LLM è‡ªåŠ¨ç”Ÿæˆ rubrics å¹¶ç”±ä¸´åºŠä¸“å®¶è¿›è¡Œä¸‰é‡ç‹¬ç«‹è¯„å®¡ï¼ˆthree-expert panelï¼‰ï¼Œæå‡è¯„åˆ†æ ‡å‡†çš„ä¸“ä¸šæ€§å’Œå¯ä¿¡åº¦ã€‚ |

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| å¯¹æ¯”ç»´åº¦ | ç°æœ‰åŸºå‡†ï¼ˆå¦‚ MedQA, HealthBenchï¼‰ | MedDialogRubrics |
|---------|-------------------------------|------------------|
| å¤šè½®æ”¯æŒ | æœ‰é™æˆ–é—´æ¥æ”¯æŒ | æ˜¾å¼æ”¯æŒå¤šè½®äº¤äº’ |
| è¯„åˆ†æ ‡å‡†é¢—ç²’åº¦ | è¾ƒç²—ï¼ˆå¦‚æœ€ç»ˆè¯Šæ–­æ­£ç¡®æ€§ï¼‰ | ç»†ç²’åº¦ï¼ˆæ¯ä¸€è½®æ˜¯å¦é—®åˆ°å…³é”®ç‚¹ï¼‰ |
| æ‚£è€…æ¨¡æ‹ŸçœŸå®æ€§ | æ˜“å‡ºç°å¹»è§‰ | æŠ—å¹»è§‰æœºåˆ¶æ˜¾è‘—é™ä½é”™è¯¯ç‡ |
| æ•°æ®æ¥æº | å¤šä¾èµ–çœŸå®æ•°æ®æˆ–å°è§„æ¨¡åˆæˆ | å®Œå…¨åˆæˆã€å¯å¤ç°ã€æ— éšç§é£é™© |
| ä¸“å®¶å‚ä¸ç¨‹åº¦ | å°‘é‡éªŒè¯ | å…¨æµç¨‹ä¸“å®¶å®¡æ ¸ä¸åé¦ˆé—­ç¯ |

> ğŸ’¡ **ä¼˜åŠ¿æ€»ç»“**ï¼šMedDialogRubrics æ˜¯é¦–ä¸ªå°†**é«˜è´¨é‡åˆæˆæ•°æ®ã€å¯æ§æ‚£è€…æ¨¡æ‹Ÿã€EBM é©±åŠ¨è¯„åˆ†ã€è‡ªåŠ¨åŒ–è¯„ä¼°**æ•´åˆäºä¸€ä½“çš„ç«¯åˆ°ç«¯åŒ»å­¦å¯¹è¯è¯„ä¼°æ¡†æ¶ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **åˆæˆæ‚£è€…æ¡ˆä¾‹æ•°é‡**ï¼š5,200 ä¾‹
- **è¦†ç›–ç–¾ç—…èŒƒå›´**ï¼šå¸¸è§åˆçº§è¯Šç–—ç—…ç—‡ã€æ…¢æ€§ç—…ã€ç²¾ç¥å¥åº·é—®é¢˜ã€æ€¥æ€§ç´§æ€¥æƒ…å†µ
- **æ•°æ®ç”Ÿæˆæ–¹å¼**ï¼š
  - ä½¿ç”¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆmulti-agent systemï¼‰ä»å…¬å¼€åŒ»å­¦ç™¾ç§‘ï¼ˆå¦‚ Baidu Health Encyclopediaï¼‰æå–çŸ¥è¯†ï¼›
  - åˆ†é˜¶æ®µç”Ÿæˆï¼šç–¾ç—…æ¦‚è¦ â†’ åŸºæœ¬ä¿¡æ¯ â†’ å®éªŒå®¤æŠ¥å‘Š â†’ ä¸»è¯‰ï¼ˆchief complaintï¼‰ï¼›
  - æ‰€æœ‰æ¡ˆä¾‹å‡ç»è¿‡è‡ªåŠ¨æ ¡éªŒå™¨æ£€æŸ¥æ—¶é—´çº¿çŸ›ç›¾ã€äººå£ç»Ÿè®¡å­¦é”™é…ç­‰é—®é¢˜ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **Doctor Agent æ¨¡å‹**ï¼ˆè¢«è¯„æµ‹å¯¹è±¡ï¼‰ï¼š
  - å¼€æºæ¨¡å‹ï¼š`Qwen3-235B-A22B-Instruct-2507`, `DeepSeek-R1`
  - å•†ç”¨æ¨¡å‹ï¼š`GPT-5`, `Gemini-2.5-Pro`
- **Patient Agent**ï¼šå›ºå®šä¸ºåŸºäºåŸå­äº‹å® + åŠ¨æ€å¼•å¯¼æœºåˆ¶çš„æ§åˆ¶å‹ä»£ç†
- **å¯¹è¯è½®æ¬¡ä¸Šé™**ï¼šæœ€å¤š 12 è½®
- **ç»ˆæ­¢ä¿¡å·**ï¼šæ¨¡å‹è¾“å‡º `"End Inquiry"` è¡¨ç¤ºç»“æŸé—®è¯Š

### ğŸ§ª è¯„ä¼°æŒ‡æ ‡
- **æ ¸å¿ƒæŒ‡æ ‡**ï¼š**Rubric Match Precision**ï¼ˆåŒ¹é…é¢„å®šä¹‰â€œmust-askâ€é—®é¢˜çš„æ¯”ä¾‹ï¼‰
- **ç»¼åˆå¾—åˆ†è®¡ç®—å…¬å¼**ï¼š
  $$
  S_k = \frac{\sum_{r_i \in R} w_i \cdot m_{r_i}}{\sum_{r_i \in R} w_i}
  $$
  å…¶ä¸­ $w_i$ ä¸º rubric æƒé‡ï¼Œ$m_{r_i}$ ä¸ºäºŒå€¼åˆ¤æ–­ï¼ˆæ»¡è¶³/æœªæ»¡è¶³ï¼‰
- **è‡ªåŠ¨åŒ–è¯„åˆ†å™¨ï¼ˆLLM-as-a-Judgeï¼‰**ï¼š
  - ä½¿ç”¨ `DeepSeek-V3` ä½œä¸ºè¯„åˆ†æ¨¡å‹
  - é‡‡ç”¨ä¸‰ç§èšåˆç­–ç•¥ï¼š**Majority Voting**, **Unanimous Voting**, **Liberal Strategy**
- **äººç±»ä¸€è‡´æ€§éªŒè¯**ï¼šä½¿ç”¨ Macro F1 è¯„ä¼° LLM è¯„åˆ†ä¸äººç±»ä¸“å®¶è¯„åˆ†çš„ä¸€è‡´æ€§

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | ç‰¹ç‚¹ |
|------|------|
| MedMCQA | å•è½®å¤šé¡¹é€‰æ‹©é¢˜ï¼Œä»…æµ‹è¯•çŸ¥è¯†è®°å¿† |
| Med-PaLM 2 | é•¿æ–‡æœ¬é—®ç­”ï¼Œä¾§é‡å®‰å…¨æ€§ä¸å‡†ç¡®æ€§ |
| HealthBench | åŒ…å« 48,562 æ¡ rubricsï¼Œä½†éƒ¨åˆ†ä¾èµ–çœŸå®æ•°æ® |
| AgentClinic | å¤šæ¨¡æ€ç¯å¢ƒä¸‹çš„å†³ç­–ä»»åŠ¡ï¼Œéçº¯å¯¹è¯ |
| MediQ | å¼ºè°ƒä¸»åŠ¨ä¿¡æ¯è·å–ï¼Œä½† rubrics æ•°é‡è¾ƒå°‘ |

> MedDialogRubrics åœ¨ rubrics æ•°é‡ï¼ˆ60,000+ï¼‰ã€ç»†ç²’åº¦ã€å¯æ§æ€§å’Œéšç§ä¿æŠ¤æ–¹é¢å…¨é¢è¶…è¶Šç°æœ‰åŸºå‡†ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®

| æ¨¡å‹ | æœ€é«˜ Rubric Match Precision | è¾¾å³°è½®æ¬¡ | è¡¨ç°ç‰¹å¾ |
|------|-----------------------------|----------|-----------|
| **Gemini-2.5-Pro** | ~52% | ç¬¬ 9â€“10 è½® | **é«˜æ•ˆå‹**ï¼šæ—©æœŸå¿«é€Ÿæå‡ï¼Œç­–ç•¥æ€§å¼º |
| **GPT-5** | ~50%ï¼ˆæŒç»­ä¸Šå‡ï¼‰ | >13 è½®ï¼ˆæœªè¾¾å¹³å°æœŸï¼‰ | **æ™šç†Ÿå‹**ï¼ˆLate-Bloomerï¼‰ï¼šç¼“æ…¢ç§¯ç´¯ä¿¡æ¯ï¼ŒåæœŸæ½œåŠ›å¤§ |
| **DeepSeek-R1** | ~40% | ç¬¬ 8â€“9 è½® | æ”¹è¿›ç©ºé—´å¤§ï¼Œå¢é•¿å¹³ç¼“ |
| **Qwen3-235B** | <35% | æ— æ˜æ˜¾æå‡ | è¡¨ç°æœ€å¼±ï¼Œéš¾ä»¥æœ‰æ•ˆæ¨è¿›è¯Šæ–­é€»è¾‘ |

> â— **å…³é”®å‘ç°**ï¼šå³ä½¿æ˜¯å½“å‰æœ€å…ˆè¿›çš„ LLMsï¼Œåœ¨ MedDialogRubrics ä¸Šä¹Ÿä»…èƒ½è¾¾åˆ°çº¦ **50% çš„å…³é”®é—®é¢˜è¦†ç›–ç‡**ï¼Œè·ç¦»ç†æƒ³æ°´å¹³ï¼ˆ100%ï¼‰ä»æœ‰å·¨å¤§å·®è·ã€‚

### ğŸ“ˆ å¤šè½®åŠ¨æ€åˆ†æï¼ˆFigure 6ï¼‰
- **Gemini-2.5-Pro** å±•ç°å‡ºæœ€ä¼˜çš„ä¿¡æ¯è·å–æ•ˆç‡ï¼Œåœ¨å‰å‡ è½®å³å‘½ä¸­å¤§é‡é«˜ä»·å€¼é—®é¢˜ã€‚
- **GPT-5** èµ·æ­¥è¾ƒæ…¢ï¼Œä½†åœ¨ç¬¬ 9 è½®ååè¶… DeepSeek-R1ï¼Œæ˜¾ç¤ºæ›´å¼ºçš„ä¸Šä¸‹æ–‡åˆ©ç”¨èƒ½åŠ›ã€‚
- æ‰€æœ‰æ¨¡å‹åœ¨è¾¾åˆ°ä¸€å®šè½®æ¬¡åè¶‹äºæ€§èƒ½é¥±å’Œï¼Œè¡¨æ˜å½“å‰æ¶æ„åœ¨**é•¿ç¨‹æ¨ç†ä¸ä¸»åŠ¨è§„åˆ’**æ–¹é¢å­˜åœ¨ç“¶é¢ˆã€‚

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆTable 3ï¼‰

| Patient Agent é…ç½® | å¹»è§‰ç‡ â†“ | ç›¸å…³æ€§ â†‘ | è¡Œä¸ºä¸€è‡´æ€§ â†‘ | è¯­è¨€æ‹ŸäººåŒ– â†‘ |
|--------------------|--------|--------|------------|--------------|
| Basicï¼ˆä»…æç¤ºå·¥ç¨‹ï¼‰ | 0.129 | 0.920 | 0.689 | 0.981 |
| + Strict Adherence | 0.076 | 0.951 | 1.000 | 0.993 |
| + Guidance Injection | **0.049** | **0.992** | **1.000** | **1.000** |

> âœ… **ç»“è®º**ï¼š**Strict Adherence + Guidance Injection** åŒæœºåˆ¶æ˜¾è‘—é™ä½å¹»è§‰ç‡ï¼ˆä¸‹é™ 62%ï¼‰ï¼Œå¹¶å®ç°å®Œç¾è¡Œä¸ºä¸€è‡´æ€§ï¼Œæ˜¯æ„å»ºå¯é  Patient Agent çš„å…³é”®æŠ€æœ¯ã€‚

### ğŸ‘¥ è‡ªåŠ¨è¯„åˆ†ä¸äººç±»ä¸€è‡´æ€§ï¼ˆFigure 7ï¼‰
- **Majority Voting** ç­–ç•¥ä¸‹ï¼ŒLLM è¯„åˆ†ä¸äººç±»ä¸“å®¶çš„ **Macro F1 è¾¾åˆ° 75â€“79%**
- **Liberal Strategy** åœ¨ GPT-5 ä¸Šè¡¨ç°æœ€ä½³ï¼ˆF1 â‰ˆ 79.6%ï¼‰ï¼Œé€‚åˆæ•æ‰ç»†å¾®å·®å¼‚
- **Unanimous Voting** è¿‡äºä¸¥æ ¼ï¼Œå¯¼è‡´å¬å›ç‡ä¸‹é™

> âœ… æ”¯æŒä½¿ç”¨ LLM-as-a-Judge å®ç°å¯æ‰©å±•ã€ä½æˆæœ¬ã€é«˜ä¿¡åº¦çš„è‡ªåŠ¨åŒ–è¯„ä¼°ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **å½“å‰ LLMs å­˜åœ¨â€œè¯¢é—®ç¼ºé™·â€ï¼ˆInquiry Deficitï¼‰**  
   å¤šæ•°æ¨¡å‹æ— æ³•æ ¹æ®å·²æœ‰ä¿¡æ¯åŠ¨æ€æ›´æ–°é‰´åˆ«è¯Šæ–­ï¼Œå¯¼è‡´åç»­æé—®ç¼ºä¹é’ˆå¯¹æ€§ï¼Œé™·å…¥â€œæ³›æ³›è€Œè°ˆâ€çš„æ¨¡å¼ã€‚

2. **å¤šè½®è¿‡ç¨‹è¯„ä¼°ä¼˜äºé™æ€ç»“æœè¯„ä¼°**  
   é™æ€ QA åŸºå‡†å¯èƒ½æ©ç›–æ¨¡å‹é—´çš„å®é™…è¡Œä¸ºå·®å¼‚ã€‚ä¾‹å¦‚ GPT-5 å’Œ Qwen3 åœ¨å•è½®ä»»åŠ¡ä¸­å·®è·ä¸å¤§ï¼Œä½†åœ¨å¤šè½®å¯¹è¯ä¸­è¡¨ç°å‡ºé«˜è¾¾ 20% çš„ rubric è¦†ç›–ç‡å·®è·ã€‚

3. **æˆ˜ç•¥å‹ä¿¡æ¯è·å–èƒ½åŠ›è‡³å…³é‡è¦**  
   Gemini-2.5-Pro çš„æˆåŠŸåœ¨äºå…¶èƒ½ä¼˜å…ˆè¯†åˆ«é«˜ä¿¡æ¯å¢ç›Šçš„é—®é¢˜ï¼ˆhigh-value medical factsï¼‰ï¼Œä½“ç°æ›´ä¼˜çš„**ä¸»åŠ¨æ¨ç†ç­–ç•¥**ã€‚

4. **æ”¹è¿›åŸºç¡€æ¨¡å‹å¾®è°ƒä¸è¶³ä»¥è§£å†³æ ¹æœ¬é—®é¢˜**  
   å½“å‰ç“¶é¢ˆä¸åœ¨çŸ¥è¯†å‚¨å¤‡ï¼Œè€Œåœ¨**å¯¹è¯ç®¡ç†æ¶æ„**ï¼ˆdialogue management architectureï¼‰ï¼Œéœ€è¦ä¸“é—¨è®¾è®¡ç”¨äºåŒ»ç–—åœºæ™¯çš„æ¨ç†æ§åˆ¶å™¨ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **åˆæˆæ•°æ®çš„çœŸå®æ€§è¾¹ç•Œ**ï¼šå°½ç®¡ç»è¿‡ä¸“å®¶å®¡æ ¸ï¼Œä½†ä»æ— æ³•å®Œå…¨æ›¿ä»£çœŸå®å¤æ‚ç—…ä¾‹ä¸­çš„ä¸ç¡®å®šæ€§ä¸å™ªå£°ã€‚
- **rubrics çš„å®Œå¤‡æ€§å‡è®¾**ï¼šå‡è®¾æ‰€æœ‰â€œmust-askâ€é—®é¢˜å‡å¯æå‰å®šä¹‰ï¼Œå¯èƒ½å¿½ç•¥ä¸ªä½“åŒ–è¯Šç–—è·¯å¾„ã€‚
- **æ–‡åŒ–ä¸è¯­è¨€åå·®**ï¼šç›®å‰ä¸»è¦åŸºäºä¸­æ–‡åŒ»å­¦èµ„æºæ„å»ºï¼Œè·¨è¯­è¨€è¿ç§»éœ€è¿›ä¸€æ­¥éªŒè¯ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **å¼€å‘ä¸“ç”¨çš„ Doctor Agent æ¶æ„**ï¼šå¼•å…¥è®°å¿†æœºåˆ¶ã€å‡è®¾ç”Ÿæˆæ¨¡å—ã€ä¼˜å…ˆçº§æ’åºå™¨ç­‰ç»„ä»¶ï¼Œå¢å¼ºä¸»åŠ¨æ¨ç†èƒ½åŠ›ã€‚
2. **æ‰©å±•è‡³å¤šæ¨¡æ€åœºæ™¯**ï¼šç»“åˆå½±åƒã€å®éªŒå®¤æ•°æ®ç­‰éç»“æ„åŒ–è¾“å…¥ï¼Œæ„å»ºæ›´æ¥è¿‘çœŸå®ä¸´åºŠçš„å·¥ä½œæµã€‚
3. **å¼•å…¥æ‚£è€…æƒ…æ„Ÿä¸æ²Ÿé€šè´¨é‡è¯„ä¼°**ï¼šä¸ä»…è¯„ä¼°â€œé—®äº†ä»€ä¹ˆâ€ï¼Œè¿˜è¯„ä¼°â€œå¦‚ä½•é—®â€â€”â€”å…±æƒ…ã€è§£é‡Šèƒ½åŠ›ã€å…±äº«å†³ç­–ç­‰è½¯æŠ€èƒ½ã€‚
4. **å¼€æ”¾æ•°æ®ä¸è¯„åˆ†æ ‡å‡†**ï¼šæ¨åŠ¨ç¤¾åŒºå…±å»ºæ›´å¤§è§„æ¨¡ã€æ›´å¤šæ ·åŒ–çš„ rubrics åº“ï¼Œå½¢æˆè¡Œä¸šæ ‡å‡†ã€‚

---

## æ€»ç»“

> **MedDialogRubrics ä¸åªæ˜¯ä¸€ä¸ªæ–° benchmarkï¼Œæ›´æ˜¯æ¨åŠ¨åŒ»å­¦ AI ä»â€œä¼šç­”é¢˜â€èµ°å‘â€œä¼šçœ‹ç—…â€çš„å…³é”®ä¸€æ­¥**ã€‚å®ƒæ­ç¤ºäº†å½“å‰ LLMs åœ¨çœŸå®ä¸´åºŠå¯¹è¯ä¸­çš„æ·±å±‚çŸ­æ¿ï¼Œå¹¶æä¾›äº†å¯å¤ç°ã€å¯æ‰©å±•ã€ä¸´åºŠå¯ä¿¡çš„è¯„ä¼°åŸºç¡€è®¾æ–½ï¼Œä¸ºä¸‹ä¸€ä»£å®‰å…¨ã€æœ‰æ•ˆçš„ doctor agents æŒ‡æ˜äº†å‘å±•æ–¹å‘ã€‚

</details>

---

### 11. [ElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systems](https://arxiv.org/abs/2601.00994)

**Authors**: Michael Bao  
**Category**: cs.AI  
**Published**: 2026-01-07  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.00994v1  

#### Abstract
This paper introduces ElecTwit, a simulation framework designed to study persuasion within multi-agent systems, specifically emulating the interactions on social media platforms during a political election. By grounding our experiments in a realistic environment, we aimed to overcome the limitations...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# ã€ŠElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systemsã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
æœ¬è®ºæ–‡æ—¨åœ¨è§£å†³**ç°æœ‰LLMå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆmulti-agent systemsï¼‰åœ¨ç ”ç©¶è¯´æœè¡Œä¸ºæ—¶ç¼ºä¹ç°å®æ€§**çš„é—®é¢˜ã€‚ä»¥å¾€çš„ç ”ç©¶å¤šä¾èµ–äºç®€åŒ–ç¯å¢ƒï¼ˆå¦‚åŸºäºæ¸¸æˆçš„æ¨¡æ‹Ÿï¼Œä¾‹å¦‚ *Among Us*ï¼‰ï¼Œè¿™äº›åœºæ™¯è™½ç„¶å¯æ§ï¼Œä½†éš¾ä»¥åæ˜ çœŸå®ç¤¾ä¼šåª’ä½“ç¯å¢ƒä¸­å¤æ‚çš„äº’åŠ¨åŠ¨æ€ï¼Œå°¤å…¶æ˜¯æ”¿æ²»é€‰ä¸¾ä¸­çš„èˆ†è®ºå½¢æˆã€ä¿¡ä»»å»ºç«‹ä¸è¯´æœç­–ç•¥ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
ä½œè€…æå‡ºäº† **ElecTwit** â€”â€” ä¸€ä¸ªåŸºäºç°å®ç¤¾äº¤åª’ä½“å¹³å°ï¼ˆç±»æ¯” X/Twitterï¼‰çš„å¤šæ™ºèƒ½ä½“ä»¿çœŸæ¡†æ¶ï¼Œç”¨äºç ”ç©¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ”¿æ²»é€‰ä¸¾èƒŒæ™¯ä¸‹çš„**è¯´æœè¡Œä¸º**ã€‚

#### ä¸»è¦åˆ›æ–°åŒ…æ‹¬ï¼š
- **ç°å®ä¸»ä¹‰é©±åŠ¨çš„è®¾è®¡**ï¼š  
  æ¨¡æ‹ŸçœŸå®ç¤¾äº¤å¹³å°åŠŸèƒ½ï¼ˆå‘å¸–ã€å›å¤ã€ç‚¹èµï¼‰ï¼Œå¹¶å¼•å…¥æ—¶é—´æ­¥é•¿æœºåˆ¶ï¼ˆæ¯æ—¥9ä¸ªäº¤äº’æ—¶æ®µï¼‰ï¼Œæ›´è´´è¿‘äººç±»ç”¨æˆ·çš„åœ¨çº¿è¡Œä¸ºèŠ‚å¥ã€‚
  
- **ç»“æ„åŒ–ä»£ç†èƒŒæ™¯å»ºæ¨¡**ï¼š  
  ä¸ºæ¯ä¸ª agent èµ‹äºˆä¸¤ç§èƒŒæ™¯ä¿¡æ¯ï¼š
  - å…­å¤§æ”¿æ²»ç«‹åœºç»´åº¦ï¼ˆEconomic Policy, Social Authority, Governmental Power, Foreign Policy, Environmental Approach, National Identity & Immigrationï¼‰
  - â€œBig 5â€äººæ ¼ç‰¹è´¨ï¼ˆExtraversion, Agreeableness, Conscientiousness, Emotional Stability, Openness to Experienceï¼‰
  è¿™äº›èƒŒæ™¯é€šè¿‡æ•°å€¼ï¼ˆ-100 åˆ° 100ï¼‰é‡åŒ–ï¼Œå¢å¼ºäº† agent è¡Œä¸ºçš„å¤šæ ·æ€§ä¸å¯è§£é‡Šæ€§ã€‚

- **äº‹ä»¶é©±åŠ¨æœºåˆ¶ï¼ˆEventor Agentï¼‰**ï¼š  
  å¼•å…¥ä¸€ä¸ªç‹¬ç«‹çš„ `eventor` agentï¼Œè´Ÿè´£ç”Ÿæˆâ€œæ–°é—»äº‹ä»¶â€ï¼ˆéƒ¨åˆ†ä¸ºè™šå‡ä¿¡æ¯ï¼‰ï¼Œæ¨¡æ‹Ÿå¤–éƒ¨ä¿¡æ¯å†²å‡»å¯¹é€‰æ°‘è®¤çŸ¥çš„å½±å“ï¼Œæµ‹è¯•æ¨¡å‹å¦‚ä½•åº”å¯¹äº‰è®®ä¸ä¿¡ä»»å±æœºã€‚

- **é•¿æœŸè®°å¿†æœºåˆ¶ï¼ˆDiary Systemï¼‰**ï¼š  
  æ‰€æœ‰ agents ç»´æŠ¤æ—¥è®°ï¼ˆdiaryï¼‰ï¼Œè®°å½•è¡ŒåŠ¨ä¸è®¡åˆ’ï¼Œå¹¶åœ¨æ¯æ—¥ç»“æŸæ—¶æ±‡æ€»ä½œä¸ºé•¿æœŸè®°å¿†è¾“å…¥ï¼Œæ”¯æŒè·¨æ—¥æ¨ç†ä¸ä¸€è‡´æ€§è¡Œä¸ºã€‚

- **å¼€æ”¾æºç ä¸å¯å¤ç°æ€§**ï¼š  
  æ‰€æœ‰ä»£ç å…¬å¼€äº GitHubï¼ˆhttps://github.com/tcmmichaelb139/ai-electwitï¼‰ï¼Œä¿ƒè¿›åç»­ç ”ç©¶ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ Among Us æ¸¸æˆæ¡†æ¶ï¼‰ | ElecTwit |
|------|-------------------------------|---------|
| ç¯å¢ƒçœŸå®æ€§ | ä½ï¼ˆå°é—­ã€è§„åˆ™æ˜ç¡®çš„æ¸¸æˆï¼‰ | é«˜ï¼ˆæ¨¡æ‹ŸçœŸå®ç¤¾äº¤åª’ä½“ç”Ÿæ€ï¼‰ |
| è¯é¢˜ç›¸å…³æ€§ | æŠ½è±¡ä»»åŠ¡å¯¼å‘ | æ”¿æ²»é€‰ä¸¾ï¼Œå…·ç¤¾ä¼šå½±å“åŠ› |
| åŠ¨æ€å¤æ‚æ€§ | æœ‰é™äº’åŠ¨æ¨¡å¼ | åŒ…å«èˆ†è®ºä¼ æ’­ã€å›éŸ³å®¤ã€æ¬ºéª—ç­‰ç°è±¡ |
| å¯æ‰©å±•æ€§ | å°è§„æ¨¡å®éªŒä¸ºä¸» | æ”¯æŒå¤šæ¨¡å‹ã€å¤šç§å­ã€é•¿æ—¶é—´è¿è¡Œ |

> âœ… å› æ­¤ï¼ŒElecTwit æä¾›äº†ä¸€ä¸ªæ›´å…·å¤–æ¨èƒ½åŠ›ï¼ˆgeneralizabilityï¼‰çš„æµ‹è¯•åºŠï¼Œå¯ç”¨äºè¯„ä¼° LLM åœ¨çœŸå®ä¸–ç•Œç¤¾ä¼šæƒ…å¢ƒä¸­çš„æ½œåœ¨é£é™©ä¸è¡Œä¸ºå€¾å‘ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
æœ¬ç ”ç©¶æœªä½¿ç”¨ä¼ ç»Ÿæ„ä¹‰ä¸Šçš„â€œæ•°æ®é›†â€ï¼Œè€Œæ˜¯æ„å»ºäº†ä¸€ä¸ª**å®Œå…¨åˆæˆçš„å¤šæ™ºèƒ½ä½“ä»¿çœŸç¯å¢ƒ**ï¼Œæ‰€æœ‰äº¤äº’æ•°æ®ç”± LLM è‡ªåŠ¨ç”Ÿæˆã€‚å…³é”®ç»„ä»¶å¦‚ä¸‹ï¼š

- **Agents æ•°é‡**ï¼š
  - 16 å voter agents
  - 2 å candidate agents
  - 1 å eventor agentï¼ˆå›ºå®šä¸º `google/gemini-2.5-flash`ï¼‰

- **æ¨¡æ‹Ÿå‘¨æœŸ**ï¼š
  - æœ€å¤šæŒç»­ 8 å¤©
  - æ¯å¤©åˆ†ä¸º 9 ä¸ªæ—¶é—´å¢é‡ï¼ˆ9amâ€“5pmï¼‰
  - æ¯è½®æ‰€æœ‰ agents åŒæ­¥æ›´æ–°çŠ¶æ€ï¼ˆåŠ é€Ÿæ¨¡æ‹Ÿï¼‰

- **äº¤äº’é™åˆ¶**ï¼š
  - æ¯æ¡ post/comment â‰¤ 280 å­—ç¬¦ï¼ˆæ¨¡ä»¿ Twitterï¼‰
  - æ¯ä¸ª agent æ¯å¤©æœ€å¤šæ‰§è¡Œ 10 æ¬¡æ“ä½œï¼ˆpost/reply/likeï¼‰
  - å¿…é¡»å¼•ç”¨æ­£ç¡® ID æ‰èƒ½å®Œæˆ reply/like

### âš™ï¸ å®éªŒè®¾ç½®
#### ä½¿ç”¨çš„ LLM æ¨¡å‹ï¼ˆå…±8ç§ï¼‰ï¼š
| ç±»å‹ | æ¨¡å‹åç§°ï¼ˆOpenRouter IDï¼‰ |
|------|--------------------------|
| Closed-source | `openai/gpt-4.1-mini`, `anthropic/claude-3.5-haiku`, `google/gemini-2.5-flash`, `x-ai/grok-3-mini` |
| Open-source | `deepseek/deepseek-chat-v3-0324`, `qwen/qwq-32b`, `moonshotai/kimi-k2`, `mistralai/devstral-medium` |

- æ‰€æœ‰æ¨¡å‹å‡è®¾ç½® **temperature = 0**ï¼ˆç¡®å®šæ€§è¾“å‡ºï¼‰
- Voter agents ä½¿ç”¨å…¨éƒ¨ 8 ç§æ¨¡å‹
- Candidate agents ä»…æµ‹è¯• 3 ç§ï¼š**GPT-4.1-mini**, **Gemini 2.5 Flash**, **Claude 3.5 Haiku**

#### ä¸¤ç±»å®éªŒè®¾è®¡ï¼š
| ç»„åˆ« | è®¾è®¡è¯´æ˜ |
|------|--------|
| **Same Seed** | å›ºå®šéšæœºç§å­ï¼Œè½®æµæ›´æ¢ candidate æ¨¡å‹ â†’ åˆ†æ candidate å½±å“åŠ› |
| **Different Seed** | å›ºå®šæ¨¡å‹é…ç½®ï¼Œæ”¹å˜éšæœºç§å­ â†’ åˆ†æ voter è¡Œä¸ºç¨³å®šæ€§ä¸èƒŒæ™¯å½±å“ |

> æ³¨ï¼šå…±è¿›è¡Œ 11 åœºæ¨¡æ‹Ÿï¼Œå…¶ä¸­ä¸€åœºé‡å äºä¸¤ç»„ã€‚

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
#### ä¸»è¦è¯„ä¼°æ–¹å¼ï¼š
- **è¯´æœæŠ€æœ¯åˆ†ç±»ï¼ˆPersuasion Technique Taggingï¼‰**ï¼š
  ä½¿ç”¨ä¸€ä¸ªç‹¬ç«‹çš„ LLM å¯¹æ‰€æœ‰ posts å’Œ comments è¿›è¡Œæ ‡æ³¨ï¼Œä¾æ® [Idziejczak et al., 2025] å®šä¹‰çš„ **25 ç§ persuasion techniques**ï¼Œå…è®¸ä¸€æ¡æ¶ˆæ¯å±äºå¤šä¸ªç±»åˆ«ã€‚
  - ç¤ºä¾‹æŠ€æœ¯ï¼š`Appeal to Credibility`, `Appeal to Emotion`, `Vagueness`, `Distraction`, `Information Overload` ç­‰ã€‚

- **æŠ•ç¥¨ç»“æœåˆ†æ**ï¼š
  - æ¯æ—¥è¿›è¡Œæ°‘æ„è°ƒæŸ¥ï¼ˆpollï¼‰
  - ç¬¬ 8 å¤©å¼ºåˆ¶æŠ•ç¥¨ï¼Œç»Ÿè®¡å€™é€‰äººå¾—ç¥¨æ•°

- **ç½‘ç»œäº¤äº’åˆ†æ**ï¼š
  æ„å»º reply å’Œ like çš„æœ‰å‘å›¾ï¼Œåˆ†æï¼š
  - æ˜¯å¦å‡ºç° echo chamberï¼ˆç›¸ä¼¼è§‚ç‚¹è€…æ›´å¤šäº’åŠ¨ï¼‰
  - èŠ‚ç‚¹ä¸­å¿ƒæ€§ï¼ˆè°è¢«å›å¤æœ€å¤šï¼‰

- **è¡Œä¸ºå¼‚å¸¸æ£€æµ‹**ï¼š
  è§‚å¯Ÿæ˜¯å¦å‡ºç° emergent phenomenaï¼ˆå¦‚é›†ä½“è¦æ±‚â€œä¹¦é¢æ‰¿è¯ºâ€ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

#### âœ… æŠ•ç¥¨ç»“æœï¼ˆFig. 2ï¼‰
- åœ¨ **same seed** å®éªŒä¸­ï¼š
  - **Gemini 2.5 Flash** ä½œä¸ºå€™é€‰äººæ—¶èµ¢å¾— **4/4** åœºæ¯”èµ›
  - GPT-4.1-mini èµ¢å¾— **2/4**
  - Claude 3.5 Haiku èµ¢å¾— **0/4**
- åœ¨ **different seed** å®éªŒä¸­ï¼š
  - Gemini ä¸ GPT-4.1-mini å„èµ¢ 2 åœºã€è¾“ 2 åœºã€å¹³ 2 åœºï¼Œè¡¨ç°ç›¸å½“

ğŸ‘‰ è¡¨æ˜ **Gemini 2.5 Flash åœ¨è¯´æœèƒ½åŠ›ä¸Šå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿**ï¼Œä¸”ç»“æœä¸å®Œå…¨æ˜¯éšæœºæ€§å¯¼è‡´ã€‚

#### ğŸ§  è¯´æœæŠ€æœ¯ä½¿ç”¨æƒ…å†µï¼ˆFig. 5 & 6ï¼‰
- æ€»å…±è¯†åˆ«å‡º **125,254 ä¸ª persuasion tags** æ¥è‡ª 43,037 æ¡æ¶ˆæ¯ï¼ˆposts + commentsï¼‰
- æœ€å¸¸ç”¨çš„äº”ç§æŠ€æœ¯ï¼ˆé«˜é¢‘é›†ä¸­ï¼‰ï¼š
  1. `Appeal to Credibility` ï¼ˆ18,126 æ¬¡ï¼‰
  2. `Appeal to Logic`
  3. `Appeal to Emotion`
  4. `Vagueness`
  5. `Distraction`

- æ‰€æœ‰ 25 ç§æŠ€æœ¯ä¸­ï¼Œé™¤ `Information Overload` å¤–ï¼Œå…¶ä½™å‡æœ‰ä½¿ç”¨
- `Self-Deprecation` ä¸ `Humor` ä½¿ç”¨æå°‘

#### ğŸ†š ä¸åŒæ¨¡å‹çš„è¡¨ç°å·®å¼‚ï¼ˆFig. 6ï¼‰
- **Gemini 2.5 Flash**ï¼š
  - æ— è®ºæ˜¯ voter è¿˜æ˜¯ candidateï¼Œäº§ç”Ÿçš„ persuasion tags æ•°é‡**è¿œé«˜äºå…¶ä»–æ¨¡å‹**
  - æ›´ç§¯æåœ°å‚ä¸å¹³å°äº’åŠ¨ï¼ˆå‘å¸–ã€è¯„è®ºæœ€å¤šï¼‰
- **Claude 3.5 Haiku**ï¼š
  - ä½œä¸º candidate æ—¶ç”Ÿæˆçš„ persuasion tags æ•°é‡**æœ€ä½**
  - äº’åŠ¨é¢‘ç‡åä½
- **Grok 3-mini**ï¼š
  - ç”Ÿæˆçš„ persuasion tags æ•°é‡æœ€å°‘ï¼Œå‡ ä¹â€œæ²‰é»˜â€

> â— æ³¨æ„ï¼šé«˜æ ‡ç­¾æ•°é‡ â‰  æ›´å¼ºè¯´æœåŠ›ï¼Œè€Œæ˜¯åæ˜ æ›´é«˜çš„æ´»è·ƒåº¦ï¼›ä½†æ´»è·ƒæœ¬èº«ä¹Ÿæ˜¯è¯´æœçš„å‰æã€‚

#### ğŸ” Echo Chamber åˆ†æï¼ˆFig. 7ï¼‰
- æ„å»º reply å’Œ like ç½‘ç»œå›¾ï¼Œè¾¹é¢œè‰²è¡¨ç¤º sender ä¸ receiver çš„èƒŒæ™¯ç›¸ä¼¼åº¦ï¼ˆcosine similarityï¼‰
- ç»“æœæ˜¾ç¤ºï¼š
  - **ä½ç›¸ä¼¼åº¦ä¹‹é—´åè€Œæœ‰æ›´å¤šå›å¤ï¼ˆçº¢è‰²è¾¹æ›´ç²—ï¼‰**
  - å€™é€‰äººæ”¶åˆ°å¤§é‡å›å¤ä½†å¾ˆå°‘è¢«ç‚¹èµ â†’ å¯èƒ½å¼•å‘äº‰è®®è€Œéæ”¯æŒ

ğŸ‘‰ **æœªè§‚å¯Ÿåˆ°å…¸å‹ echo chamber æ•ˆåº”**ï¼Œåè€Œæ˜¾ç¤ºå‡ºè·¨æ„è¯†å½¢æ€äº‰è®ºè¾ƒå¤šã€‚

#### ğŸ“ Emergent Behaviors å‘ç°
- å‡ºç°â€œ**kernel of truth**â€æ¶ˆæ¯ï¼šåŒ…å«éƒ¨åˆ†äº‹å®ä½†æ•´ä½“è¯¯å¯¼ï¼ˆå¦‚å¤¸å¤§ä»·æ ¼æ¬ºè¯ˆï¼‰
- å‡ºç°â€œ**ink obsession**â€ç°è±¡ï¼š
  - Agents å¼€å§‹é›†ä½“è¦æ±‚å€™é€‰äººæä¾›â€œwritten proofâ€ï¼ˆå¢¨æ°´ç­¾ç½²æ–‡ä»¶ï¼‰
  - â€œNo ink, no voteâ€ æˆä¸ºå£å·
  - æ˜¾ç¤ºå‡º LLMs å¯ä»¥è‡ªå‘å‘å±•å‡ºå¯¹â€œå¯ä¿¡æ‰¿è¯ºâ€çš„è±¡å¾æ€§éœ€æ±‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **LLMs å¹¿æ³›ä½¿ç”¨å¤šç§ persuasion techniques**ï¼š
   - åœ¨çœŸå®æ¨¡æ‹Ÿç¯å¢ƒä¸‹ï¼Œå‡ ä¹æ‰€æœ‰ 25 ç§ persuasion æŠ€æœ¯éƒ½è¢«æ¿€æ´»ï¼ŒèŒƒå›´è¶…è¿‡æ­¤å‰åŸºäºæ¸¸æˆçš„ç ”ç©¶ã€‚
   - ç‰¹åˆ«æ˜¯ `Appeal to Credibility` å’Œ `Emotion` æ˜¯ä¸»æµç­–ç•¥ã€‚

2. **æ¨¡å‹æ¶æ„ä¸è®­ç»ƒæ˜¾è‘—å½±å“è¯´æœè¡Œä¸º**ï¼š
   - Gemini 2.5 Flash å±•ç°å‡ºæ›´å¼ºçš„ä¸»åŠ¨æ€§å’Œè¯´æœæŠ€å·§ï¼Œå¯èƒ½ä¸å…¶è®­ç»ƒæ•°æ®æˆ–æ¨ç†ä¼˜åŒ–æœ‰å…³ã€‚
   - Claude 3.5 Haiku å’Œ Grok 3-mini æ›´ä¿å®ˆã€è¢«åŠ¨ã€‚

3. **Emergent socialç°è±¡å¯è§‚æµ‹**ï¼š
   - å¦‚â€œink obsessionâ€è¡¨æ˜ LLM agents å¯ä»¥åœ¨æ²¡æœ‰é¢„è®¾æ¿€åŠ±çš„æƒ…å†µä¸‹ï¼Œè‡ªå‘å½¢æˆé›†ä½“è¯‰æ±‚å’Œç¤¾ä¼šè§„èŒƒã€‚
   - å­˜åœ¨â€œkernel of truthâ€å¼è¯¯å¯¼ï¼Œæç¤º LLM å¯èƒ½åˆ©ç”¨æ¨¡ç³Šè¡¨è¿°è¿›è¡Œè½¯æ€§æ“çºµã€‚

4. **èƒŒæ™¯ç‰¹å¾å¯¹æŠ•ç¥¨é€‰æ‹©å½±å“ä¸æ˜¾è‘—**ï¼š
   - å°½ç®¡è®¾ç½®äº†è¯¦ç»†çš„æ”¿æ²»ç«‹åœºå’Œäººæ ¼ç»´åº¦ï¼Œä½† agent èƒŒæ™¯ä¸å…¶æœ€ç»ˆæŠ•ç¥¨å¯¹è±¡ä¹‹é—´çš„ cosine similarity ä¸èƒœé€‰æ— æ˜æ˜¾æ­£ç›¸å…³ï¼ˆFig. 3ï¼‰ã€‚

5. **é echo chamber çš„äº’åŠ¨æ¨¡å¼**ï¼š
   - ä¸åŒç«‹åœº agent ä¹‹é—´äº’åŠ¨é¢‘ç¹ï¼ŒæŒ‘æˆ˜äº†â€œç®—æ³•èŒ§æˆ¿å¿…ç„¶å¯¼è‡´æåŒ–â€çš„å‡è®¾ï¼Œåœ¨å¼€æ”¾ feed ä¸‹å¯èƒ½å‡ºç°åå‘äº‰è®ºã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
| å±€é™ | è¯´æ˜ |
|------|------|
| **Uniform Feed** | æ‰€æœ‰ agents çœ‹åˆ°ç›¸åŒ feedï¼Œç¼ºä¹ä¸ªæ€§åŒ–æ¨èç®—æ³•çš„å½±å“ |
| **LLM-only Evaluation** | è¯´æœæ•ˆæœç”±å¦ä¸€ä¸ª LLM åˆ¤æ–­ï¼Œç¼ºä¹ human-in-the-loop éªŒè¯ |
| **Temperature = 0** | ç¼ºå°‘éšæœºæ€§æ¢ç´¢ï¼Œæ— æ³•è¯„ä¼°åˆ›é€ æ€§æˆ–æç«¯è¡Œä¸º |
| **å°æ ·æœ¬è§„æ¨¡** | ä»… 11 åœºæ¨¡æ‹Ÿï¼Œcandidate ç»„åˆå˜åŒ–æœ‰é™ |
| **åŒæ­¥æ›´æ–°æœºåˆ¶** | æ‰€æœ‰ agents åŒæ—¶è¡ŒåŠ¨ï¼Œä¸ç¬¦åˆçœŸå®å¼‚æ­¥äº¤æµä¹ æƒ¯ |

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **å¼•å…¥ä¸ªæ€§åŒ– feed ä¸æ¨èç³»ç»Ÿ**ï¼Œç ”ç©¶ç®—æ³•åè§å¦‚ä½•åŠ å‰§ polarisationã€‚
2. **åŠ å…¥ human participants**ï¼Œå®ç° human-AI hybrid simulationã€‚
3. **æ‰©å¤§æ¨¡å‹ç»„åˆä¸æ¸©åº¦å‚æ•°æ‰«æ**ï¼Œæ¢ç©¶ randomness å¯¹ persuasion çš„å½±å“ã€‚
4. **å¢åŠ æ›´å¤šç¤¾ä¼šè§’è‰²**ï¼ˆè®°è€…ã€KOLã€bot farmï¼‰ï¼Œæå‡ç”Ÿæ€ç³»ç»Ÿå¤æ‚æ€§ã€‚
5. **éƒ¨ç½²åˆ°çœŸå®å¹³å°è¿›è¡Œå°è§„æ¨¡æµ‹è¯•**ï¼ˆéœ€ä¼¦ç†å®¡æŸ¥ï¼‰ï¼ŒéªŒè¯ä»¿çœŸå¤–æ¨èƒ½åŠ›ã€‚

---

## æ€»ç»“
> **ElecTwit æ˜¯é¦–ä¸ªå°† persuasion ç ”ç©¶ç½®äºé«˜åº¦æ‹ŸçœŸçš„ç¤¾äº¤åª’ä½“é€‰ä¸¾ç¯å¢ƒä¸­çš„å¼€æºå¤šæ™ºèƒ½ä½“æ¡†æ¶**ã€‚å®ƒæ­ç¤ºäº†ä¸åŒ LLM åœ¨çœŸå®ç¤¾ä¼šè¯­å¢ƒä¸‹çš„è¡Œä¸ºå·®å¼‚ï¼Œå‘ç°äº† emergent normsï¼ˆå¦‚â€œinkâ€è¦æ±‚ï¼‰å’Œå¹¿æ³›ä½¿ç”¨çš„ persuasion tacticsï¼Œä¸ºæœªæ¥ç ”ç©¶ AI ç¤¾ä¼šå½±å“ã€ä¿¡æ¯æˆ˜é˜²å¾¡ä¸ alignment verification æä¾›äº†é‡è¦å·¥å…·ã€‚å°½ç®¡å­˜åœ¨ç®€åŒ–å‡è®¾ï¼Œä½†å…¶è®¾è®¡ç†å¿µä»£è¡¨äº†ä»â€œæ²™ç›’æ¸¸æˆâ€å‘â€œç°å®æ¨¡æ‹Ÿâ€çš„å…³é”®è·ƒè¿ã€‚

</details>

---

### 12. [A New Benchmark for the Appropriate Evaluation of RTL Code Optimization](https://arxiv.org/abs/2601.01765)

**Authors**: Yao Lu, Shang Liu, Hangan Zhou, Wenji Fang, Qijun Zhang, Zhiyao Xie  
**Category**: cs.AI  
**Published**: 2026-01-07  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.01765v1  

#### Abstract
The rapid progress of artificial intelligence increasingly relies on efficient integrated circuit (IC) design. Recent studies have explored the use of large language models (LLMs) for generating Register Transfer Level (RTL) code, but existing benchmarks mainly evaluate syntactic correctness rather ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šA New Benchmark for the Appropriate Evaluation of RTL Code Optimization

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰åŸºäº **Large Language Models (LLMs)** çš„ RTL ä»£ç ç”Ÿæˆç ”ç©¶ç¼ºä¹å¯¹**ä¼˜åŒ–è´¨é‡**çš„æœ‰æ•ˆè¯„ä¼°ã€‚ç°æœ‰çš„åŸºå‡†ï¼ˆå¦‚ [26]ï¼‰ä¸»è¦å…³æ³¨è¯­æ³•æ­£ç¡®æ€§å’ŒåŠŸèƒ½ç­‰ä»·æ€§ï¼Œè€Œå¿½è§†äº†é›†æˆç”µè·¯è®¾è®¡çš„æ ¸å¿ƒæŒ‡æ ‡â€”â€”**Power, Performance, and Area (PPA)**ã€‚æ­¤å¤–ï¼Œè¿™äº›åŸºå‡†å­˜åœ¨ä»¥ä¸‹ä¸¥é‡ç¼ºé™·ï¼š
- **ä¸ç°å®çš„è®¾è®¡**ï¼šå­ä¼˜ RTL åŒ…å«äººä¸ºæ„é€ çš„å†—ä½™æ“ä½œï¼ˆå¦‚ `s1 + 0`ã€`s1 * 1`ï¼‰ï¼Œåœ¨å®é™…å·¥ç¨‹ä¸­å‡ ä¹ä¸ä¼šå‡ºç°ï¼›
- **ç®€åŒ–çš„ç»¼åˆæµç¨‹**ï¼šä¾èµ–å¼±ç»¼åˆå·¥å…·ï¼ˆå¦‚ Yosysï¼‰ï¼Œå¯¼è‡´ PPA å·®å¼‚è¢«å¤¸å¤§ï¼Œæ— æ³•åæ˜ å·¥ä¸šçº§ç»¼åˆå·¥å…·ï¼ˆå¦‚ Synopsys Design Compiler, DCï¼‰çš„çœŸå®è¡Œä¸ºï¼›
- **è¯„ä¼°ä¸å…¨é¢**ï¼šä»…å…³æ³¨é¢ç§¯ï¼Œå¿½ç•¥åŠŸè€—å’Œæ—¶åºç­‰å…³é”®ç»´åº¦ã€‚

è¿™äº›é—®é¢˜ä½¿å¾—ç°æœ‰åŸºå‡†å®¹æ˜“è¯¯å¯¼æ¨¡å‹è¯„ä¼°ï¼Œé«˜ä¼° LLM åœ¨çœŸå®åœºæ™¯ä¸‹çš„ä¼˜åŒ–èƒ½åŠ›ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„åŸºå‡†ï¼š**RTL-OPT**ï¼Œä¸“é—¨ç”¨äºè¯„ä¼° LLM åœ¨ RTL ä»£ç ä¼˜åŒ–æ–¹é¢çš„èƒ½åŠ›ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
1. **é«˜è´¨é‡ã€æ‰‹å†™çš„çœŸå®ä¼˜åŒ–ä»»åŠ¡é›†**  
   - åŒ…å« **36 ä¸ªæ‰‹å·¥ç¼–å†™**çš„æ•°å­—ç”µè·¯è®¾è®¡ä»»åŠ¡ï¼Œæ¶µç›–ç»„åˆé€»è¾‘ã€æµæ°´çº¿æ•°æ®è·¯å¾„ã€æœ‰é™çŠ¶æ€æœºï¼ˆFSMï¼‰ã€å­˜å‚¨å™¨æ¥å£ç­‰å¤šç§ç±»å‹ã€‚
   - æ¯ä¸ªä»»åŠ¡æä¾›ä¸€å¯¹ RTL ä»£ç ï¼š
     - **Suboptimal Version**ï¼šåŠŸèƒ½æ­£ç¡®ä½†æœ‰æ„é—æ¼æŸäº›ä¼˜åŒ–æœºä¼šï¼›
     - **Optimized Version**ï¼šç”±ä¸“å®¶äººå·¥ä¼˜åŒ–ï¼Œä½“ç°å·¥ä¸šå®è·µä¸­æœ‰æ•ˆçš„ä¼˜åŒ–æ¨¡å¼ã€‚

2. **çœŸå®çš„ä¼˜åŒ–æ¨¡å¼è¦†ç›–**  
   æ‰€æœ‰ä¼˜åŒ–å‡åŸºäºä¸šç•ŒéªŒè¯è¿‡çš„æœ€ä½³å®è·µï¼ŒåŒ…æ‹¬ï¼š
   - Bit-width Optimization
   - Precomputation & LUT Conversion
   - Operator Strength Reduction
   - Control Simplification
   - Resource Sharing
   - State Encoding Optimization  
   è¿™äº›å˜æ¢å³ä½¿ç»è¿‡å…ˆè¿›ç»¼åˆå·¥å…·å¤„ç†ä»èƒ½ä¿ç•™æ”¶ç›Šï¼Œé¿å…â€œè™šå‡ä¼˜åŒ–â€ã€‚

3. **è‡ªåŠ¨åŒ–ã€æ ‡å‡†åŒ–çš„è¯„ä¼°æ¡†æ¶**  
   æä¾›å®Œæ•´çš„ EDA æµç¨‹æ”¯æŒï¼š
   - ä½¿ç”¨ **Synopsys DC** å’Œ **Yosys** è¿›è¡Œç»¼åˆï¼›
   - åˆ©ç”¨ **Formality** è¿›è¡Œå½¢å¼ç­‰ä»·æ€§æ£€æŸ¥ï¼ˆfunctional equivalenceï¼‰ï¼›
   - ä½¿ç”¨ **VCS** è¿›è¡ŒåŠ¨æ€ä»¿çœŸéªŒè¯å¤æ‚æ—¶åºé€»è¾‘ï¼›
   - è¾“å‡ºç»Ÿä¸€æ ¼å¼çš„ **PPA æŠ¥å‘Š**ï¼ˆPower, WNS/TNS, Area/Cellsï¼‰ã€‚

4. **å¼€æºä¸å¯å¤ç°æ€§**  
   å…¨éƒ¨èµ„æºï¼ˆRTL å¯¹ã€netlistã€è„šæœ¬ã€åº“æ–‡ä»¶ï¼‰å‡å·²å¼€æºï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰åŸºå‡† [26] | RTL-OPTï¼ˆæœ¬æ–‡ï¼‰ |
|------|----------------|------------------|
| è®¾è®¡çœŸå®æ€§ | ä½ï¼ˆcontrived inefficienciesï¼‰ | é«˜ï¼ˆrealistic coding stylesï¼‰ |
| ç»¼åˆå·¥å…·å¼ºåº¦ | å¼±ï¼ˆYosysä¸ºä¸»ï¼‰ | å¼ºï¼ˆDC compile_ultraï¼‰ |
| PPA è¦†ç›– | ä¸å®Œæ•´ï¼ˆåé‡é¢ç§¯ï¼‰ | å®Œæ•´ï¼ˆP+P+Aï¼‰ |
| åŠŸèƒ½éªŒè¯ | ç¼ºä¹ä¸¥æ ¼éªŒè¯ | Formality + VCS åŒé‡ä¿éšœ |
| åŸºå‡†å¯é æ€§ | å·®ï¼ˆå•†ä¸šå·¥å…·ä¸‹æ— å·®å¼‚ï¼‰ | å¼ºï¼ˆ35/36 åœ¨ DC ä¸‹æ˜¾è‘—æ›´ä¼˜ï¼‰ |

> âœ… **ç»“è®º**ï¼šRTL-OPT æ˜¯é¦–ä¸ªèƒ½å¤Ÿ**å¯é ã€çœŸå®åœ°è¡¡é‡ LLM åœ¨ RTL ä¼˜åŒ–ä¸­å®é™…ä»·å€¼**çš„åŸºå‡†ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **ä¸»æ•°æ®é›†**ï¼š**RTL-OPT**ï¼ŒåŒ…å« 36 å¯¹ RTL æ¨¡å—ï¼Œå¤§å°ä» 14 åˆ° 20K cells ä¸ç­‰ã€‚
- **å¯¹æ¯”æ•°æ®é›†**ï¼šå¤ç°å¹¶è¯„ä¼°äº†å…ˆå‰å·¥ä½œ [26] ä¸­çš„ 43 å¯¹è®¾è®¡ï¼ˆå…¶ä¸­æˆåŠŸç»¼åˆ 43 å¯¹ï¼‰ã€‚
- **æŠ€æœ¯åº“**ï¼šé‡‡ç”¨ **Nangate45** å¼€æºæ ‡å‡†å•å…ƒåº“ã€‚

---

### å®éªŒè®¾ç½®
#### ç»¼åˆé…ç½®
ä½¿ç”¨å¤šç§ç»¼åˆç­–ç•¥ä»¥æµ‹è¯•é²æ£’æ€§ï¼š
- å·¥å…·ï¼š**Synopsys Design Compiler (DC)** å’Œ **Yosys**
- æ¨¡å¼ï¼š
  - `DC (compile, clk=1ns)`
  - `DC (compile, clk=0.1ns)`ï¼ˆtight timingï¼‰
  - `DC (compile_ultra, clk=1ns)`ï¼ˆaggressive optimizationï¼‰
- è¯„ä¼°æŒ‡æ ‡ï¼š
  - **Power**ï¼šæ€»åŠŸè€—ï¼ˆåŠ¨æ€ + æ³„æ¼ï¼‰
  - **Performance**ï¼šWNSï¼ˆæœ€å·®è´Ÿæ¾å¼›ï¼‰ã€TNSï¼ˆæ€»è´Ÿæ¾å¼›ï¼‰
  - **Area**ï¼šCell Count / Silicon Area (Î¼mÂ²)

#### åŠŸèƒ½éªŒè¯
- **Formality**ï¼šè¿›è¡Œå½¢å¼ç­‰ä»·æ€§æ£€æŸ¥ï¼ˆequivalence checkingï¼‰
- **VCS**ï¼šå¯¹æ¶‰åŠæµæ°´çº¿ã€çŠ¶æ€æœºç­‰æ—¶åºæ•æ„Ÿçš„è®¾è®¡è¿›è¡ŒåŠ¨æ€æµ‹è¯•

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Human-optimized RTL** vs. Suboptimal RTLï¼ˆéªŒè¯åŸºå‡†æœ‰æ•ˆæ€§ï¼‰
- **LLM-optimized RTL** vs. Suboptimal & Optimized RTL
- æµ‹è¯•çš„ LLMsï¼š
  - GPT-4o-mini
  - Gemini-2.5
  - Deepseek V3
  - Deepseek R1

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & Table 3ï¼‰

#### âœ… RTL-OPT åŸºå‡†æœ¬èº«çš„å¯é æ€§éªŒè¯
| åˆæˆé…ç½® | Human-Optimized æ›´å¥½æ¡ˆä¾‹æ•° / æ€»æ•° |
|---------|-------------------------------|
| Yosys | 33 / 36 |
| DC (compile, 1ns) | 30 / 36 |
| DC (compile_ultra, 1ns) | **35 / 36** âœ… |
| DC (compile, 0.1ns) | 23 / 36ï¼ˆå…¶ä½™ä¸º trade-offï¼‰|

> ğŸ’¡ è¡¨æ˜ï¼šåœ¨å¼ºç»¼åˆæ¡ä»¶ä¸‹ï¼Œç»å¤§å¤šæ•°ä¼˜åŒ–ç‰ˆæœ¬ä¾ç„¶ä¼˜äºå­ä¼˜ç‰ˆæœ¬ï¼Œè¯´æ˜ä¼˜åŒ–æ˜¯â€œçœŸå®æœ‰æ•ˆâ€çš„ã€‚

#### âŒ å¯¹æ¯”åŸºå‡† [26] çš„ä¸å¯é æ€§
| åˆæˆé…ç½® | Human-Optimized æ›´å¥½æ¡ˆä¾‹æ•° / æ€»æ•° |
|---------|-------------------------------|
| Yosys | 24 / 43 |
| DC (compile_ultra, 1ns) | **ä»… 13 / 43** âŒ |

> âš ï¸ è¯´æ˜ï¼šå¤šæ•°æ‰€è°“â€œä¼˜åŒ–â€åœ¨å·¥ä¸šæµç¨‹ä¸‹æ¶ˆå¤±ï¼Œç”šè‡³å˜å·®ï¼Œæš´éœ²å…¶è¯„ä¼°æ— æ•ˆã€‚

---

### LLM åœ¨ RTL-OPT ä¸Šçš„è¡¨ç°ï¼ˆFigure 3 & Table 4ï¼‰

| LLM æ¨¡å‹ | Syntax æ­£ç¡®ç‡ | Func æ­£ç¡®ç‡ | PPA ä¼˜äº suboptimal (%) | PPA è¶…è¿‡ human optimized (%) |
|--------|---------------|-------------|--------------------------|------------------------------|
| GPT-4o-mini | 97.2% | 75% | 19.4% | â€” |
| Gemini-2.5 | ~100% | ~70% | <20% | â€” |
| Deepseek V3 | **100%** | 69.4% | ~23% | â€” |
| Deepseek R1 | 86.1% | 61.1% | **41.7%** | **13.9% (~5/36)** âœ… |

> ğŸ” **äº®ç‚¹**ï¼šDeepseek R1 æˆåŠŸåœ¨çº¦ **5 ä¸ªä»»åŠ¡ä¸Šè¶…è¶Šäººç±»ä¸“å®¶è®¾è®¡**ï¼Œè¯æ˜ LLM å…·å¤‡æ½œåœ¨è¶…äººä¼˜åŒ–èƒ½åŠ›ã€‚

---

### æ¶ˆèåˆ†æä¸é”™è¯¯æ¨¡å¼åˆ†æ
é€šè¿‡å¯¹å¤±è´¥æ¡ˆä¾‹çš„æ‰‹åŠ¨æ£€æŸ¥ï¼ˆn=40ï¼‰ï¼Œå‘ç°ä¸‰å¤§ç±»é”™è¯¯ï¼š
1. **æ§åˆ¶é€»è¾‘é”™è¯¯**ï¼šå¸ƒå°”æ¡ä»¶é”™è¯¯ï¼ˆå¦‚ comparator æ¡ä»¶å†™åï¼‰
2. **è¿‡åº¦æµæ°´çº¿åŒ–**ï¼šç ´ååŸæœ‰å»¶è¿Ÿçº¦æŸï¼ˆFSM latency violationï¼‰
3. **èµ„æºå…±äº«ä¸å½“**ï¼šå¯„å­˜å™¨å¤ç”¨å¯¼è‡´æ•°æ®å†²çªï¼ˆstale dataï¼‰

> ğŸ“Œ ç»“è®ºï¼šé”™è¯¯å¤šæºäº**è¯­ä¹‰ç†è§£åå·®**è€Œéè¯­æ³•é”™è¯¯ï¼Œæç¤ºéœ€åŠ å¼ºä¸Šä¸‹æ–‡å»ºæ¨¡ä¸çº¦æŸæ„ŸçŸ¥ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç°æœ‰ RTL ä¼˜åŒ–åŸºå‡†ä¸¥é‡å¤±çœŸ**ï¼šè®¸å¤šâ€œä¼˜åŒ–â€åœ¨å¼ºç»¼åˆå·¥å…·ä¸‹æ— æ•ˆï¼Œæ˜“é€ æˆè¯¯åˆ¤ã€‚
2. **ç»¼åˆå·¥å…·é€‰æ‹©æå¤§å½±å“è¯„ä¼°ç»“æœ**ï¼šYosys æ”¾å¤§å·®å¼‚ï¼ŒDC æ¶ˆé™¤è™šå‡ä¼˜åŒ– â†’ å¿…é¡»ä½¿ç”¨å·¥ä¸šçº§å·¥å…·ã€‚
3. **PPA å­˜åœ¨æƒè¡¡ï¼ˆtrade-offï¼‰**ï¼šä¸èƒ½åªçœ‹å•ä¸€æŒ‡æ ‡ï¼Œéœ€ç»¼åˆè¯„ä¼°ã€‚
4. **å½“å‰ LLM ä»æœ‰å¾ˆå¤§æå‡ç©ºé—´**ï¼šå¹³å‡ä»… ~20% çš„è®¾è®¡å®ç° PPA æå‡ï¼Œä¸”åŠŸèƒ½æ­£ç¡®ç‡æ™®éä½äº 75%ã€‚
5. **æœ€å¼ºæ¨¡å‹å·²å±•ç°è¶…è¶Šäººç±»æ½œåŠ›**ï¼šDeepseek R1 åœ¨ 5 ä¸ªä»»åŠ¡ä¸­è¶…è¿‡äººå·¥ä¼˜åŒ–æ–¹æ¡ˆã€‚

---

### æ–¹æ³•å±€é™æ€§
- **è§„æ¨¡é™åˆ¶**ï¼š36 ä¸ªä»»åŠ¡è™½å¤šæ ·ä½†ä»å±å°æ ·æœ¬ï¼Œéš¾ä»¥è¦†ç›–æ‰€æœ‰è®¾è®¡é£æ ¼ã€‚
- **é™æ€è¯„ä¼°**ï¼šæœªè€ƒè™‘ç‰©ç†å®ç°ï¼ˆplacement, routingï¼‰çš„å½±å“ã€‚
- **ä¾èµ–ç‰¹å®šå·¥è‰ºåº“**ï¼šåŸºäº Nangate45ï¼Œè¿ç§»åˆ°å…ˆè¿›å·¥è‰ºéœ€é‡æ–°æ ¡å‡†ã€‚
- **prompt æ•æ„Ÿæ€§æœªæ·±å…¥ç ”ç©¶**ï¼šä¸åŒæç¤ºè¯å¯èƒ½æ˜¾è‘—å½±å“è¾“å‡ºè´¨é‡ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•æ›´å¤§è§„æ¨¡çš„çœŸå®ä¼˜åŒ–æ•°æ®é›†**ï¼ˆå¦‚æ¥è‡ªå¼€æºèŠ¯ç‰‡é¡¹ç›®ï¼‰
2. **å¼•å…¥ç‰©ç†æ„ŸçŸ¥ä¼˜åŒ–ç›®æ ‡**ï¼ˆtiming closure, congestionï¼‰
3. **æ„å»ºç«¯åˆ°ç«¯è®­ç»ƒ-è¯„ä¼°é—­ç¯**ï¼Œæ¨åŠ¨ LLM è‡ªä¸»å­¦ä¹ ä¼˜åŒ–ç­–ç•¥
4. **å¼€å‘å…·å¤‡ç¡¬ä»¶è¯­ä¹‰ç†è§£èƒ½åŠ›çš„ä¸“ç”¨ LLM æ¶æ„**
5. **æ¢ç´¢ human-in-the-loop çš„ååŒä¼˜åŒ–èŒƒå¼**

---

## æ€»ç»“
âœ… **RTL-OPT** æ˜¯ä¸€ä¸ªé¢å‘æœªæ¥çš„ã€å¯é çš„ã€å·¥ä¸šå¯¹é½çš„ RTL ä¼˜åŒ–è¯„ä¼°åŸºå‡†ï¼Œå¡«è¡¥äº†å½“å‰ AI for EDA é¢†åŸŸçš„å…³é”®ç©ºç™½ã€‚å®ƒä¸ä»…æ­ç¤ºäº†ç°æœ‰ç ”ç©¶çš„è¯„ä¼°è¯¯åŒºï¼Œä¹Ÿä¸ºä¸‹ä¸€ä»£æ™ºèƒ½ IC è®¾è®¡å·¥å…·çš„å‘å±•æä¾›äº†åšå®åŸºç¡€ã€‚

</details>

---

### 13. [Enhancing Multilingual RAG Systems with Debiased Language Preference-Guided Query Fusion](https://arxiv.org/abs/2601.02956)

**Authors**: Jeonghyun Park, Byeongjeong Kim, Seojin Hwang, Hwanhee Lee  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.02956v1  

#### Abstract
Multilingual Retrieval-Augmented Generation (mRAG) systems often exhibit a perceived preference for high-resource languages, particularly English, resulting in the widespread adoption of English pivoting. While prior studies attribute this advantage to the superior English-centric capabilities of La...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šEnhancing Multilingual RAG Systems with Debiased Language Preference-Guided Query Fusion

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹ **Multilingual RAG (mRAG)** ç³»ç»Ÿä¸­å­˜åœ¨çš„ä¸€ä¸ªæ™®éç°è±¡â€”â€”**å¯¹è‹±è¯­çš„åå¥½ï¼ˆEnglish preferenceï¼‰**â€”â€”è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚ä¼ ç»Ÿè§‚ç‚¹è®¤ä¸ºè¿™ç§åå¥½æºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è‹±è¯­ä¸Šçš„æ›´å¼ºèƒ½åŠ›ï¼ˆå¦‚æ¨ç†ã€ç”Ÿæˆè´¨é‡ï¼‰ï¼Œå› æ­¤å¹¿æ³›é‡‡ç”¨â€œ**English pivoting**â€ç­–ç•¥ï¼ˆå°†éè‹±è¯­æŸ¥è¯¢ç¿»è¯‘ä¸ºè‹±è¯­å†è¿›è¡Œæ£€ç´¢ï¼‰ã€‚ç„¶è€Œï¼Œä½œè€…æŒ‡å‡ºï¼Œè¿™ç§â€œè‹±è¯­ä¼˜åŠ¿â€å¾ˆå¤§ç¨‹åº¦ä¸Šæ˜¯ç”±**è¯„ä¼°åŸºå‡†ä¸­çš„ç»“æ„æ€§åå·®ï¼ˆstructural priorsï¼‰** æ‰€å¯¼è‡´çš„å‡è±¡ï¼Œè€Œéæ¨¡å‹æœ¬èº«çš„å†…åœ¨åå¥½ã€‚

å…·ä½“è€Œè¨€ï¼Œè¿™äº›ç»“æ„æ€§åå·®åŒ…æ‹¬ï¼š
- **Gold Availability Prior**ï¼šæ­£ç¡®ç­”æ¡ˆï¼ˆgold passageï¼‰åœ¨è‹±æ–‡ç»´åŸºç™¾ç§‘ä¸­è¦†ç›–ç‡è¿œé«˜äºå…¶ä»–è¯­è¨€ã€‚
- **Exposure Bias**ï¼šç”±äºè‹±æ–‡èµ„æºä¸°å¯Œï¼Œæ£€ç´¢å™¨æ›´å®¹æ˜“è¿”å›è‹±æ–‡æ–‡æ¡£ã€‚
- **Cultural Prior**ï¼šæŸäº›é—®é¢˜ä¸ç‰¹å®šæ–‡åŒ–æˆ–åœ°åŸŸå¼ºç›¸å…³ï¼Œå…¶æœ¬åœ°è¯­è¨€ä¸­çš„åŸç”Ÿè¡¨è¾¾ï¼ˆå¦‚ä¸“æœ‰åè¯ã€è„šæœ¬ï¼‰æˆä¸ºå¼ºæ£€ç´¢é”šç‚¹ï¼Œä»è€Œé€ æˆâ€œåå¥½â€ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯

#### ï¼ˆ1ï¼‰DeLP (Debiased Language Preference)
æå‡ºäº†ä¸€ç§æ–°çš„åº¦é‡æŒ‡æ ‡ **DeLP**ï¼Œç”¨äº**å»åçš„è¯­è¨€åå¥½æµ‹é‡**ã€‚è¯¥æ–¹æ³•é€šè¿‡å²­å›å½’ï¼ˆridge regressionï¼‰ä»è§‚æµ‹åˆ°çš„è¯­è¨€åå¥½ä¿¡å·ä¸­å‰¥ç¦»å‡ºç”±ä¸Šè¿°ç»“æ„æ€§å…ˆéªŒï¼ˆexposure, gold availability, cultural priorï¼‰å¸¦æ¥çš„å½±å“ï¼Œä¿ç•™æ®‹å·®ä½œä¸ºæ¨¡å‹çœŸå®çš„è¯­è¨€åå¥½ä¿¡å·ã€‚

**æ ¸å¿ƒå‘ç°**ï¼šç»è¿‡ DeLP å»ååï¼Œæ‰€è°“çš„â€œè‹±è¯­åå¥½â€åŸºæœ¬æ¶ˆå¤±ï¼Œå–è€Œä»£ä¹‹çš„æ˜¯**å•è¯­å¯¹é½ï¼ˆmonolingual alignmentï¼‰åå¥½**â€”â€”å³å½“æŸ¥è¯¢è¯­è¨€ä¸æ–‡æ¡£è¯­è¨€ç›¸åŒæ—¶ï¼Œæ£€ç´¢æ•ˆæœæœ€ä½³ã€‚

#### ï¼ˆ2ï¼‰DELTA (DEbiased Language preference-guided Text Augmentation)
åŸºäº DeLP çš„å‘ç°ï¼Œæå‡ºäº†ä¸€ç§è½»é‡çº§çš„æŸ¥è¯¢å¢å¼ºæ¡†æ¶ **DELTA**ã€‚å®ƒä¸ä¿®æ”¹æ£€ç´¢å™¨æˆ–ç”Ÿæˆå™¨ï¼Œè€Œæ˜¯é€šè¿‡å¯¹åŸå§‹æŸ¥è¯¢è¿›è¡Œ**å¤šè¯­è¨€çº¿ç´¢èåˆï¼ˆquery fusionï¼‰** æ¥æå‡è·¨è¯­è¨€æ£€ç´¢æ•ˆæœã€‚

DELTA çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- æ„é€ ä¸€ä¸ªèåˆæŸ¥è¯¢ `Q_fused`ï¼ŒåŒ…å«å¤šä¸ªè¯­ä¹‰æ®µï¼š
  - `[GLOB]`ï¼šè‹±æ–‡ç¿»è¯‘ï¼ˆglobal pivotï¼‰
  - `[LOCAL]`ï¼šåŸå§‹è¯­è¨€æŸ¥è¯¢ï¼ˆä¿ç•™æœ¬åœ°é”šç‚¹ï¼‰
  - `[TITLE_BRIDGE]`ï¼šä¸­è‹±æ–‡é…å¯¹æ ‡é¢˜
  - `[ALIASES]`ï¼šå¤šè¯­è¨€åˆ«å
  - `[LOCALE_HINT]`ï¼šåœ°åŸŸæç¤º
- ä½¿ç”¨**åŸºäºç½®ä¿¡åº¦çš„é‡å¤åŠ æƒï¼ˆrepetition-based weightingï¼‰** åŠ¨æ€æ§åˆ¶å„éƒ¨åˆ†æƒé‡ï¼Œä¼˜å…ˆå¼ºåŒ–é«˜ç½®ä¿¡åº¦çš„æ–‡åŒ–ç›¸å…³çº¿ç´¢ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ— éœ€ä¿®æ”¹æ¨¡å‹æ¶æ„æˆ–è®­ç»ƒè¿‡ç¨‹**ï¼šDELTA æ˜¯çº¯æ–‡æœ¬çº§åˆ«çš„æŸ¥è¯¢é‡æ„ï¼Œæˆæœ¬ä½ã€æ˜“éƒ¨ç½²ã€‚
- **è¶…è¶Š English Pivoting**ï¼šå®éªŒè¯æ˜ DELTA åœ¨å¤šæ•°éè‹±è¯­è¯­è¨€ä¸Šæ˜¾è‘—ä¼˜äºç®€å•çš„è‹±æ–‡ç¿»è¯‘æŸ¥è¯¢ã€‚
- **æ­ç¤ºçœŸå®åå¥½æœºåˆ¶**ï¼šDeLP æä¾›äº†ä¸€ä¸ªæ›´å…¬å¹³çš„è¯„ä¼°è§†è§’ï¼ŒæŒ‘æˆ˜äº†â€œè‹±è¯­ä¸­å¿ƒä¸»ä¹‰â€çš„å›ºæœ‰è®¤çŸ¥ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **MKQA**ï¼šåŒ…å« 10k ç»ä¸“ä¸šç¿»è¯‘çš„å¤šè¯­è¨€é—®ç­”å¯¹ï¼Œæ”¯æŒè·¨è¯­è¨€è¯„ä¼°ã€‚
- å­é›†ï¼šé€‰å–ä¸ **KILT-NQ** é‡å çš„ 2.7K ç¤ºä¾‹ï¼Œä»¥ä¾¿è·å–æ ‡å‡†çš„æ–‡æ¡£æº¯æºä¿¡æ¯ï¼ˆgold passage IDsï¼‰ã€‚
- **çŸ¥è¯†æº**ï¼šä½¿ç”¨è‹±æ–‡ç»´åŸºç™¾ç§‘å’Œç”¨æˆ·æœ¬åœ°è¯­è¨€çš„ç»´åŸºç™¾ç§‘ä½œä¸ºæ£€ç´¢æ•°æ®åº“ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **æ£€ç´¢å™¨**ï¼š`BGE-m3`ï¼ˆå¤šè¯­è¨€åµŒå…¥æ¨¡å‹ï¼‰ï¼Œå¹¶è¾…ä»¥é‡æ’åºï¼ˆrerankingï¼‰ã€‚
- **ç”Ÿæˆå™¨**ï¼šä¸‰ç§ä¸»æµå¤šè¯­è¨€ LLMï¼š
  - `Qwen3-235B`
  - `DeepSeek-v3.1`
  - `Gemini-2.5-Flash`
- **æ£€ç´¢è®¾ç½®**ï¼šTop-50 æ–‡æ¡£å¬å›ï¼Œä½¿ç”¨ Top-5 è¿›è¡Œç”Ÿæˆã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Recall@50**ï¼šè¡¡é‡æ£€ç´¢é˜¶æ®µæ€§èƒ½ã€‚
  - **End-to-end Accuracy**ï¼šä½¿ç”¨å­—ç¬¦ 3-gram recall è¡¡é‡æœ€ç»ˆç”Ÿæˆç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚
  - **Latency**ï¼šç«¯åˆ°ç«¯å“åº”æ—¶é—´ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | æè¿° |
|------|------|------|
| **MultiRAG** | Document Level | ä½¿ç”¨åŸå§‹è¯­è¨€æŸ¥è¯¢ï¼Œç›´æ¥æ£€ç´¢å¹¶ç”Ÿæˆ |
| **CrossRAG** | Document Level | æ£€ç´¢åå°†æ–‡æ¡£ç»Ÿä¸€ç¿»è¯‘ä¸ºè‹±æ–‡å†ç”Ÿæˆ |
| **DKM-RAG** | Document Level | ç¿»è¯‘å¹¶ç”¨ LLM ç”Ÿæˆå¤šä¸ªç²¾ç‚¼ç‰ˆæœ¬ |
| **QTT-RAG** | Document Level | æ·»åŠ ç¿»è¯‘è´¨é‡æ ‡ç­¾è¾…åŠ©ç”Ÿæˆå™¨åˆ¤æ–­å¯ä¿¡åº¦ |
| **English Translation** | Query Level | å°†æŸ¥è¯¢ç¿»è¯‘ä¸ºè‹±æ–‡åæ£€ç´¢ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 5ï¼‰

| æ–¹æ³• | Qwen3-235B (AVG) | Gemini-2.5-Flash (AVG) | DeepSeek-v3.1 (AVG) |
|------|------------------|------------------------|---------------------|
| MultiRAG | 51.30 | 43.80 | 45.46 |
| English Translation | 58.81 | 52.75 | 55.26 |
| **DELTA (ours)** | **62.88** | **56.28** | **58.23** |

> âœ… **DELTA åœ¨æ‰€æœ‰ä¸‰ä¸ªç”Ÿæˆå™¨ä¸Šå‡å–å¾—æœ€é«˜å¹³å‡å‡†ç¡®ç‡**ï¼Œæ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ã€‚

#### éè‹±è¯­è¯­è¨€ä¸Šçš„å¢ç›Šå°¤ä¸ºæ˜æ˜¾ï¼š
- åœ¨é˜¿æ‹‰ä¼¯è¯­ï¼ˆarï¼‰ã€æ³°è¯­ï¼ˆthï¼‰ã€éŸ©è¯­ï¼ˆkoï¼‰ç­‰ä½èµ„æºè¯­è¨€ä¸Šï¼ŒDELTA ç›¸æ¯” English Translation æå‡å¯è¾¾ **+7~10 ä¸ªç™¾åˆ†ç‚¹**ã€‚
- è‹±è¯­æŸ¥è¯¢ä¸Šæ— æ˜¾è‘—æ”¶ç›Šç”šè‡³ç•¥æœ‰ä¸‹é™ï¼Œå› ä¸º `[GLOB]` å’Œ `[LOCAL]` å†…å®¹é«˜åº¦é‡åˆï¼Œå¼•å…¥å†—ä½™ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- DELTA ä¸ä»…ä¼˜äºæ‰€æœ‰ **document-level** æ–¹æ³•ï¼ˆå¦‚ CrossRAG, DKM-RAGï¼‰ï¼Œè€Œä¸”å®ç°æ–¹å¼æ›´è½»é‡ï¼ˆæ— éœ€ç¿»è¯‘å¤§é‡æ–‡æ¡£ï¼‰ã€‚
- ç›¸æ¯” **query-level** çš„ English Translationï¼ŒDELTA æ˜¾è‘—æå‡äº†è·¨è¯­è¨€æ£€ç´¢çš„ç›¸å…³æ€§å’Œç­”æ¡ˆå‡†ç¡®æ€§ã€‚
- **å»¶è¿Ÿæ›´ä½**ï¼šDELTA å¹³å‡å»¶è¿Ÿä½äºæˆ–æ¥è¿‘ English Translationï¼Œå› å…¶èƒ½æ›´å¿«å®šä½ç›®æ ‡æ–‡æ¡£ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 7ï¼‰

| æ–¹æ³• | å‡†ç¡®ç‡ (avg) |
|------|------------|
| Original Query | 63.68 |
| + Global (`[GLOB]`) | 71.42 |
| + Title (`[TITLE_BRIDGE]`) | 68.17 |
| + Aliases (`[ALIASES]`) | 68.14 |
| + Locale Hint (`[LOCALE_HINT]`) | 67.57 |
| **All cues (DELTA)** | **72.99** |

> ğŸ” ç»“è®ºï¼š
- `[GLOB]` è´¡çŒ®æœ€å¤§ï¼Œè¯´æ˜å…¨å±€è‹±æ–‡è¡¨è¾¾æœ‰åŠ©äºç”Ÿæˆå™¨ç†è§£ã€‚
- `[TITLE_BRIDGE]` å’Œ `[ALIASES]` æä¾›ç‹¬ç«‹å¢ç›Šï¼Œè¯æ˜å¤šè¯­è¨€é”šç‚¹æœ‰åŠ©äºå®ä½“æ¶ˆæ­§ã€‚
- æ‰€æœ‰çº¿ç´¢ç»„åˆæ•ˆæœæœ€ä½³ï¼Œè¡¨æ˜ DELTA å„ç»„ä»¶ååŒä½œç”¨ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **â€œè‹±è¯­åå¥½â€æ˜¯ä¸€ä¸ªè¢«æ”¾å¤§çš„å‡è±¡**ï¼šmRAG ç³»ç»Ÿä¸­è§‚å¯Ÿåˆ°çš„è‹±è¯­ä¼˜åŠ¿ä¸»è¦æ¥è‡ªæ•°æ®åˆ†å¸ƒåå·®ï¼ˆgold availability, exposure biasï¼‰ï¼Œè€Œéæ¨¡å‹æœ¬èº«çš„èƒ½åŠ›å·®å¼‚ã€‚
2. **çœŸå®åå¥½æ˜¯å•è¯­å¯¹é½ï¼ˆmonolingual alignmentï¼‰**ï¼šæ£€ç´¢å™¨æœ¬è´¨ä¸Šæ›´æ“…é•¿åŒ¹é…åŒè¯­è¨€çš„æŸ¥è¯¢ä¸æ–‡æ¡£ã€‚
3. **DeLP æˆåŠŸå‰¥ç¦»ç»“æ„æ€§åå·®**ï¼šç»æ ¡å‡†åçš„è¯­è¨€åå¥½æ˜¾ç¤ºï¼Œè‹±è¯­ä¸å†å…·æœ‰ç³»ç»Ÿæ€§ä¼˜åŠ¿ï¼Œåè€Œæœ¬åœ°è¯­è¨€åŒ¹é…å¾—åˆ†æœ€é«˜ã€‚
4. **DELTA åˆ©ç”¨çœŸå®åå¥½å®ç°æ€§èƒ½çªç ´**ï¼šé€šè¿‡èåˆå¤šè¯­è¨€çº¿ç´¢å¹¶åŠ¨æ€åŠ æƒï¼ŒDELTA åœ¨ä¿æŒé«˜æ•ˆçš„åŒæ—¶æ˜¾è‘—æå‡è·¨è¯­è¨€ RAG æ€§èƒ½ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **ä»…è§£å†³æ£€ç´¢ä¾§åå¥½**ï¼šDeLP å’Œ DELTA ä¸»è¦å…³æ³¨ retriever çš„è¯­è¨€åå¥½ï¼Œæœªå¤„ç† generator å¦‚ä½•æ¶ˆè´¹å¤šè¯­è¨€è¯æ®çš„é—®é¢˜ã€‚
2. **ä¾èµ– Wikipedia è®¾ç½®**ï¼šå®éªŒåŸºäºç»´åŸºç™¾ç§‘æ„å»ºçš„çŸ¥è¯†åº“ï¼Œç»“è®ºåœ¨é¢†åŸŸä¸“ç”¨æˆ–å¤šæ¨¡æ€æ•°æ®ä¸Šçš„æ³›åŒ–æ€§æœ‰å¾…éªŒè¯ã€‚
3. **åŠ æƒç­–ç•¥è¾ƒç²—ç²’åº¦**ï¼šå½“å‰ä½¿ç”¨é‡å¤æ¬¡æ•°è¿›è¡ŒåŠ æƒï¼Œç¼ºä¹æ›´ç²¾ç»†çš„æ³¨æ„åŠ›æ§åˆ¶æœºåˆ¶ï¼Œå¯èƒ½åœ¨å¤æ‚æ­§ä¹‰åœºæ™¯ä¸‹å¤±æ•ˆï¼ˆè§å¤±è´¥æ¡ˆä¾‹ï¼‰ã€‚
4. **å­˜åœ¨è¿‡åº¦æœ¬åœ°åŒ–é£é™©**ï¼šå¯¹äºæ„å›¾æ¨¡ç³Šçš„é—®é¢˜ï¼ˆå¦‚â€œæœé²œæˆ˜äº‰æ—¶æœŸçš„æ€»ç»Ÿâ€ï¼‰ï¼ŒDELTA å¯èƒ½é”™è¯¯åœ°åå‘æœ¬åœ°è§£é‡Šï¼ˆéŸ©å›½æ€»ç»Ÿï¼‰ï¼Œå¿½ç•¥å…¨çƒä¸Šä¸‹æ–‡ï¼ˆç¾å›½æ€»ç»Ÿï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† debiasing æ‰©å±•è‡³ generator ç«¯ï¼Œç ”ç©¶å…¶å¦‚ä½•é€‰æ‹©å’Œåˆ©ç”¨ä¸åŒè¯­è¨€çš„è¯æ®ã€‚
- æ¢ç´¢æ›´æ™ºèƒ½çš„ query fusion æ§åˆ¶é€»è¾‘ï¼Œä¾‹å¦‚åŸºäºæ„å›¾è¯†åˆ«çš„åŠ¨æ€è°ƒèŠ‚ã€‚
- åœ¨æ›´å¤šæ ·åŒ–çš„å¤šè¯­è¨€è¯­æ–™åº“ï¼ˆå¦‚åŒ»ç–—ã€æ³•å¾‹ï¼‰ä¸ŠéªŒè¯ DeLP ä¸ DELTA çš„æœ‰æ•ˆæ€§ã€‚
- ç»“åˆ ambiguity-aware safeguard æœºåˆ¶ï¼Œé˜²æ­¢å› æ–‡åŒ–çº¿ç´¢è¯¯å¯¼è€Œå¯¼è‡´çš„æ£€ç´¢åå·®ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æ­ç¤ºäº† mRAG ä¸­â€œè‹±è¯­åå¥½â€çš„æœ¬è´¨æ˜¯ç»“æ„æ€§åå·®æ‰€è‡´ï¼Œå¹¶æå‡º DeLP å’Œ DELTA æ–¹æ³•ï¼Œå‰è€…æä¾›æ›´å…¬æ­£çš„è¯„ä¼°å·¥å…·ï¼Œåè€…é€šè¿‡åå¥½å¼•å¯¼çš„æŸ¥è¯¢èåˆï¼Œåœ¨ä¸å¢åŠ å¤æ‚æ€§çš„å‰æä¸‹å®ç°äº†è·¨è¯­è¨€ RAG æ€§èƒ½çš„å…¨é¢æå‡ã€‚

</details>

---

### 14. [LLM-Enhanced Reinforcement Learning for Time Series Anomaly Detection](https://arxiv.org/abs/2601.02511)

**Authors**: Bahareh Golchin, Banafsheh Rekabdar, Danielle Justo  
**Category**: cs.LG  
**Published**: 2026-01-07  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.02511v1  

#### Abstract
Detecting anomalies in time series data is crucial for finance, healthcare, sensor networks, and industrial monitoring applications. However, time series anomaly detection often suffers from sparse labels, complex temporal patterns, and costly expert annotation. We propose a unified framework that i...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# LLM-Enhanced Reinforcement Learning for Time Series Anomaly Detection è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹**ä¸­çš„å‡ ä¸ªå…³é”®æŒ‘æˆ˜ï¼š
- **æ ‡ç­¾ç¨€ç–æ€§**ï¼šçœŸå®ä¸–ç•Œä¸­å¼‚å¸¸äº‹ä»¶ç½•è§ï¼Œæ ‡æ³¨æˆæœ¬é«˜ï¼›
- **å¥–åŠ±ç¨€ç–ï¼ˆsparse rewardsï¼‰**ï¼šåœ¨å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning, RLï¼‰æ¡†æ¶ä¸‹ï¼Œä»…é å°‘é‡çœŸå®æ ‡ç­¾æä¾›çš„åé¦ˆä¸è¶³ä»¥æœ‰æ•ˆè®­ç»ƒæ™ºèƒ½ä½“ï¼›
- **å¤æ‚æ—¶åºæ¨¡å¼è¯†åˆ«å›°éš¾**ï¼šä¼ ç»Ÿæ–¹æ³•éš¾ä»¥æ•æ‰é•¿æœŸä¾èµ–ã€å¤šå˜é‡äº¤äº’åŠè¯­ä¹‰å±‚é¢çš„å¼‚å¸¸è¡Œä¸ºã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§**ç»Ÿä¸€çš„é›†æˆæ¡†æ¶**ï¼Œç»“åˆä»¥ä¸‹å››ä¸ªæ ¸å¿ƒæŠ€æœ¯ï¼š
1. **LLM-based Potential Function for Reward Shaping**  
   åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Model, LLMï¼‰ç”ŸæˆåŸºäºè¯­ä¹‰ç†è§£çš„â€œæ½œåœ¨å‡½æ•°â€ï¼ˆpotential functionï¼‰ï¼Œç”¨äº**åŸºäºæ½œåŠ›çš„å¥–åŠ±å¡‘å½¢ï¼ˆPotential-Based Reward Shaping, PBRSï¼‰**ã€‚è¿™ä½¿å¾—RLæ™ºèƒ½ä½“èƒ½ä»LLMå¯¹æ—¶é—´çª—å£å†…æ¨¡å¼çš„ç†è§£ä¸­è·å¾—é¢å¤–æŒ‡å¯¼ä¿¡å·ï¼Œè€Œä¸ä¼šæ”¹å˜æœ€ä¼˜ç­–ç•¥ï¼ˆpolicy invarianceï¼‰ã€‚

2. **VAE-enhanced Dynamic Reward Scaling**  
   å¼•å…¥å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVariational Autoencoder, VAEï¼‰è®¡ç®—é‡æ„è¯¯å·®ä½œä¸ºæ— ç›‘ç£å¼‚å¸¸å¾—åˆ†ï¼Œå¹¶é€šè¿‡ä¸€ä¸ª**åŠ¨æ€è°ƒèŠ‚ç³»æ•° Î»(t)** å°†å…¶ä¸åˆ†ç±»å¥–åŠ±èåˆï¼Œå®ç°ç›‘ç£ä¸éç›‘ç£ä¿¡å·ä¹‹é—´çš„è‡ªé€‚åº”å¹³è¡¡ã€‚

3. **Active Learning with Label Propagation**  
   é‡‡ç”¨ä¸»åŠ¨å­¦ä¹ ï¼ˆActive Learning, ALï¼‰é€‰æ‹©ä¸ç¡®å®šæ€§æœ€é«˜çš„æ ·æœ¬è¿›è¡Œäººå·¥æ ‡æ³¨ï¼Œå¹¶åˆ©ç”¨æ ‡ç­¾ä¼ æ’­ï¼ˆlabel propagationï¼‰æ‰©å±•å·²æ ‡æ³¨æ•°æ®é›†ï¼Œæ˜¾è‘—é™ä½æ ‡æ³¨å¼€é”€ã€‚

4. **LSTM-based RL Agent for Sequential Decision Making**  
   ä½¿ç”¨LSTMä½œä¸ºQç½‘ç»œéª¨å¹²ï¼Œå»ºæ¨¡æ—¶é—´åºåˆ—çš„é•¿æœŸä¾èµ–å…³ç³»ï¼Œåœ¨æ»‘åŠ¨çª—å£ä¸Šæ‰§è¡ŒäºŒåˆ†ç±»åŠ¨ä½œï¼ˆæ­£å¸¸/å¼‚å¸¸ï¼‰ï¼Œå¹¶æ¥æ”¶ç»¼åˆå¥–åŠ±ä¿¡å·è¿›è¡Œè®­ç»ƒã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´å¼ºçš„è¯­ä¹‰æ„ŸçŸ¥èƒ½åŠ›**ï¼šLLMèƒ½å¤Ÿè¯†åˆ«ç»Ÿè®¡æ–¹æ³•å¿½ç•¥çš„å¤æ‚æ¨¡å¼ï¼ˆå¦‚è¶‹åŠ¿çªå˜ã€å‘¨æœŸæ‰°åŠ¨ç­‰ï¼‰ï¼Œæå‡å¬å›ç‡ï¼›
- **æ›´é«˜çš„æ ·æœ¬æ•ˆç‡**ï¼šé€šè¿‡ä¸»åŠ¨å­¦ä¹ å‡å°‘å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼›
- **æ›´ç¨³å®šçš„è®­ç»ƒè¿‡ç¨‹**ï¼šPBRSç¼“è§£äº†RLä¸­çš„ç¨€ç–å¥–åŠ±é—®é¢˜ï¼›VAEæä¾›æŒç»­çš„å†…åœ¨åé¦ˆï¼›
- **ç«¯åˆ°ç«¯å¯æ‰©å±•æ€§å¼º**ï¼šé€‚ç”¨äºå•å˜é‡ä¸å¤šå˜é‡åœºæ™¯ï¼Œä¸”æ— éœ€æ‰‹åŠ¨è®¾è®¡ç‰¹å¾æˆ–è§„åˆ™ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **Yahoo-A1**ï¼šåŒ…å«67ä¸ªå•å˜é‡æ—¶é—´åºåˆ—ï¼Œæ¥è‡ªYahooç½‘ç«™æµé‡ç›‘æ§ï¼Œæ¯å°æ—¶é‡‡æ ·ä¸€æ¬¡ï¼Œå¼‚å¸¸å æ¯”çº¦1.76%ã€‚
- **SMD (Server Machine Dataset)**ï¼šåŒ…å«28ä¸ªå¤šå˜é‡æ—¶é—´åºåˆ—ï¼Œæ¯ä¸ªåºåˆ—æœ‰38ä¸ªä¼ æ„Ÿå™¨ç»´åº¦ï¼Œè®°å½•æœåŠ¡å™¨è¿è¡ŒçŠ¶æ€ï¼Œå‰5å¤©ä¸ºæ­£å¸¸æ•°æ®ï¼Œå5å¤©æ³¨å…¥éšæœºå¼‚å¸¸ï¼Œå¼‚å¸¸æ¯”ä¾‹çº¦ä¸º4.16%ã€‚

| æ•°æ®é›†       | ç±»å‹     | åºåˆ—æ•°é‡ | ç»´åº¦ | å¼‚å¸¸æ¯”ä¾‹ |
|------------|--------|-------|-----|-------|
| Yahoo-A1   | å•å˜é‡    | 67    | 1   | 1.76% |
| SMD        | å¤šå˜é‡    | 28    | 38  | 4.16% |

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **è¯„ä¼°æŒ‡æ ‡**ï¼šPrecisionï¼ˆç²¾ç¡®ç‡ï¼‰ã€Recallï¼ˆå¬å›ç‡ï¼‰ã€F1 Scoreï¼ˆF1åˆ†æ•°ï¼‰
- **è®­ç»ƒæ–¹å¼**ï¼šåœ¨çº¿å­¦ä¹ ï¼ŒæŒ‰episodeå¤„ç†å®Œæ•´æ—¶é—´åºåˆ—
- **æ»‘åŠ¨çª—å£é•¿åº¦**ï¼š`n_steps = 25`
- **LLMå€™é€‰æ¨¡å‹**ï¼šGPT-3.5ã€Llama-3.2-3Bã€Phi-2
- **Promptè®¾è®¡**ï¼šé‡‡ç”¨few-shotæç¤ºï¼Œè¾“å…¥æ ¼å¼åŒ–çš„æ—¶é—´çª—å£æ•°æ®ï¼Œè¦æ±‚è¾“å‡ºJSONæ ¼å¼çš„`{"severity": v}`ï¼Œå…¶ä¸­`v âˆˆ [0,1]`

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
è®ºæ–‡å¯¹æ¯”äº†å¤šä¸ªä¸»æµåŸºçº¿æ¨¡å‹ï¼š
- **THOC**ï¼šåŸºäºå±‚æ¬¡åŒ–ä¸€ç±»ç½‘ç»œçš„æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹
- **TranAD**ï¼šåŸºäºTransformerçš„å¤šå˜é‡å¼‚å¸¸æ£€æµ‹
- **TS2Vec**ï¼šé€šç”¨æ—¶é—´åºåˆ—è¡¨ç¤ºå­¦ä¹ 
- **DCdetector**ï¼šåŒæ³¨æ„åŠ›å¯¹æ¯”å­¦ä¹ æ–¹æ³•
- **TimesNet**ï¼šå°†æ—¶é—´åºåˆ—è½¬æ¢ä¸ºäºŒç»´å˜åŒ–å›¾è¿›è¡Œåˆ†æ
- **CARLA**ï¼šå½“å‰æœ€å…ˆè¿›çš„æ·±åº¦å­¦ä¹ åŸºå‡†æ–¹æ³•ä¹‹ä¸€

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§Table IIï¼‰

#### åœ¨ Yahoo-A1 ä¸Šçš„è¡¨ç°ï¼ˆå•å˜é‡ï¼‰
| Model                     | Precision | Recall  | F1       |
|--------------------------|-----------|---------|----------|
| CARLA (best non-LLM)     | 0.5747    | 0.9755  | **0.7233** |
| **Proposed + Llama-3**   | **0.6051**| **0.9565**| **0.7413** âœ… |
| Proposed + GPT-3.5       | 0.0742    | 0.9130  | 0.1372   |
| Proposed + Phi-2         | 0.6666    | 0.4761  | 0.5555   |

> âœ… **Llama-3ç‰ˆæœ¬åœ¨F1ä¸Šè¶…è¶ŠCARLAï¼Œè¾¾åˆ°SOTAæ°´å¹³**

#### åœ¨ SMD ä¸Šçš„è¡¨ç°ï¼ˆå¤šå˜é‡ï¼‰
| Model                     | Precision | Recall  | F1       |
|--------------------------|-----------|---------|----------|
| CARLA                    | 0.4276    | 0.6362  | **0.5114** |
| **Proposed + Llama-3**   | 0.3813    | **0.8685**| **0.5300** âœ… |
| Proposed + GPT-3.5       | 0.5370    | 0.4061  | 0.4625   |
| Proposed + Phi-2         | **0.8461**| 0.2541  | 0.3908   |

> âœ… **Llama-3åœ¨F1ä¸Šå†æ¬¡ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼Œå°¤å…¶ä»¥é«˜è¾¾86.85%çš„Recallé¢†å…ˆ**

### æ€§èƒ½åˆ†æä¸å‘ç°
- **Llama-3è¡¨ç°æœ€ä½³**ï¼šåœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸Šå‡å–å¾—æœ€é«˜F1å€¼ï¼Œè¯´æ˜å…¶ç”Ÿæˆçš„severityè¯„åˆ†å…·æœ‰è‰¯å¥½çš„æ ¡å‡†æ€§å’Œä¸€è‡´æ€§ã€‚
- **GPT-3.5è¿‡äºæ¿€è¿›ï¼ˆover-eagerï¼‰**ï¼šå€¾å‘äºå°†è®¸å¤šæ­£å¸¸æ³¢åŠ¨æ ‡è®°ä¸ºå¼‚å¸¸ï¼Œå¯¼è‡´Precisionæä½ï¼ˆä»…7.4%ï¼‰ï¼Œå°½ç®¡Recallè¾ƒé«˜ã€‚
- **Phi-2è¿‡äºä¿å®ˆï¼ˆcautiousï¼‰**ï¼šPrecisionå¾ˆé«˜ä½†Recallå¾ˆä½ï¼Œæ¼æ£€ä¸¥é‡ã€‚
- **VAEåŠ¨æ€ç¼©æ”¾æœºåˆ¶æœ‰æ•ˆ**ï¼šå½“episodeè¡¨ç°ä¸‹é™æ—¶è‡ªåŠ¨å¢åŠ Î»ï¼Œå¢å¼ºVAEå¼‚å¸¸ä¿¡å·æƒé‡ï¼Œæœ‰åŠ©äºç¨³å®šè®­ç»ƒã€‚

### æ¶ˆèå®éªŒï¼ˆæ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºè¡¨æ ¼ï¼Œä½†å¯é€šè¿‡è®ºè¿°æ¨æ–­ï¼‰
è™½ç„¶æ²¡æœ‰ç‹¬ç«‹çš„æ¶ˆèè¡¨ï¼Œä½†ä»æ–¹æ³•æè¿°å’Œè®¨è®ºä¸­å¯ä»¥å¾—å‡ºä»¥ä¸‹ç»“è®ºï¼š
- è‹¥ç§»é™¤LLMå¥–åŠ±å¡‘å½¢ â†’ å›å½’ä¼ ç»ŸRL+VAEæ¶æ„ï¼Œæ€§èƒ½æ¥è¿‘CARLAä½†æ— æ³•çªç ´ï¼›
- è‹¥ä¸ä½¿ç”¨åŠ¨æ€reward scaling â†’ éš¾ä»¥å¹³è¡¡ç›‘ç£ä¸æ— ç›‘ç£ä¿¡å·ï¼Œå¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆæˆ–æ¬ æ•æ„Ÿï¼›
- è‹¥å…³é—­active learning â†’ éœ€æ›´å¤šäººå·¥æ ‡æ³¨æ‰èƒ½è¾¾åˆ°ç›¸åŒæ€§èƒ½ï¼Œå®ç”¨æ€§ä¸‹é™ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **LLMå¯ç”¨äºè¯­ä¹‰çº§å¥–åŠ±å¡‘å½¢**ï¼šå³ä½¿æœªç»å¾®è°ƒï¼Œé¢„è®­ç»ƒLLMä¹Ÿèƒ½æœ‰æ•ˆè¯„ä¼°æ—¶é—´åºåˆ—ç‰‡æ®µçš„â€œå¼‚å¸¸ä¸¥é‡ç¨‹åº¦â€ï¼Œå¹¶ä½œä¸ºPBRSä¸­çš„potential functionï¼Œæ˜¾è‘—æå‡RLæ¢ç´¢æ•ˆç‡ã€‚
2. **Llama-3æ˜¯æœ€ä½³é€‰æ‹©**ï¼šç›¸æ¯”GPT-3.5å’ŒPhi-2ï¼ŒLlama-3åœ¨æŒ‡ä»¤éµå¾ªã€è¾“å‡ºç¨³å®šæ€§ã€æ¨¡å¼è¯†åˆ«å‡†ç¡®æ€§æ–¹é¢è¡¨ç°æœ€ä¼˜ï¼Œé€‚åˆç”¨äºæ„å»ºå¯é å¥–åŠ±ä¿¡å·ã€‚
3. **æœ¬æ–¹æ³•åœ¨ä½æ ‡æ³¨é¢„ç®—ä¸‹ä»é«˜æ•ˆ**ï¼šé€šè¿‡active learning + label propagationï¼Œå¤§å¹…å‡å°‘äº†äººå·¥æ ‡æ³¨éœ€æ±‚ï¼Œé€‚åˆç°å®éƒ¨ç½²ã€‚
4. **å¯¹å•å˜é‡å’Œå¤šå˜é‡æ•°æ®å‡æœ‰è‰¯å¥½é€‚åº”æ€§**ï¼šåœ¨Yahoo-A1ï¼ˆç®€å•çªå‘å¼‚å¸¸ï¼‰å’ŒSMDï¼ˆå¤æ‚æ¸å˜+å¤šä¼ æ„Ÿå™¨è€¦åˆå¼‚å¸¸ï¼‰ä¸Šå‡è¡¨ç°å‡ºè‰²ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **è®¡ç®—å¼€é”€è¾ƒå¤§**ï¼šæ¯æ¬¡å†³ç­–éœ€è°ƒç”¨LLMæ¨ç†ï¼Œå¯èƒ½å½±å“å®æ—¶æ€§ï¼›
- **ä¾èµ–LLM APIå¯ç”¨æ€§ä¸æˆæœ¬**ï¼šè‹¥ä½¿ç”¨é—­æºæ¨¡å‹ï¼ˆå¦‚GPTï¼‰ï¼Œå­˜åœ¨æœåŠ¡ä¸­æ–­æˆ–è´¹ç”¨é£é™©ï¼›
- **å¤šå˜é‡è·¨ä¼ æ„Ÿå™¨å…³ç³»å»ºæ¨¡ä¸è¶³**ï¼šå½“å‰LLMè¾“å…¥ä¸ºæ‰å¹³åŒ–çš„sensor readingsæ‹¼æ¥ï¼Œæœªèƒ½æ˜¾å¼å»ºæ¨¡å˜é‡é—´å› æœæˆ–ç›¸å…³ç»“æ„ï¼›
- **few-shot promptæ•ˆæœæ•æ„Ÿ**ï¼špromptè®¾è®¡è´¨é‡ç›´æ¥å½±å“LLMè¾“å‡ºç¨³å®šæ€§ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢è½»é‡åŒ–LLMï¼ˆå¦‚TinyLlamaï¼‰æœ¬åœ°éƒ¨ç½²ä»¥é™ä½æˆæœ¬ï¼›
- è®¾è®¡ä¸“é—¨é¢å‘æ—¶é—´åºåˆ—çš„promptæ¨¡æ¿å’Œfine-tuningç­–ç•¥ï¼›
- å¼•å…¥graph-based modelingæ¥æ•æ‰å¤šå˜é‡é—´çš„ä¾èµ–å…³ç³»ï¼›
- æ‰©å±•è‡³å…¶ä»–é¢†åŸŸï¼ˆå¦‚åŒ»ç–—ã€é‡‘èï¼‰éªŒè¯æ³›åŒ–èƒ½åŠ›ï¼›
- ç»“åˆoffline RLè¿›ä¸€æ­¥æå‡æ ·æœ¬åˆ©ç”¨ç‡ã€‚

---

> ğŸ”š **æ€»ç»“**ï¼šæœ¬æ–‡å¼€åˆ›æ€§åœ°å°†LLMå¼•å…¥RL-basedå¼‚å¸¸æ£€æµ‹æ¡†æ¶ï¼Œé€šè¿‡semantic reward shapingè§£å†³äº†ç¨€ç–å¥–åŠ±éš¾é¢˜ï¼Œåœ¨Yahoo-A1å’ŒSMDä¸Šå®ç°äº†state-of-the-artçš„F1æ€§èƒ½ï¼Œå°¤å…¶åœ¨Recallæ–¹é¢ä¼˜åŠ¿æ˜æ˜¾ã€‚è¯¥æ–¹æ³•å±•ç¤ºäº†LLMä½œä¸ºâ€œè®¤çŸ¥å¢å¼ºæ¨¡å—â€çš„å·¨å¤§æ½œåŠ›ï¼Œä¸ºæœªæ¥æ™ºèƒ½è¿ç»´ç³»ç»Ÿæä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 15. [MAFS: Multi-head Attention Feature Selection for High-Dimensional Data via Deep Fusion of Filter Methods](https://arxiv.org/abs/2601.02668)

**Authors**: Xiaoyan Sun, Qingyu Meng, Yalu Wen  
**Category**: cs.LG  
**Published**: 2026-01-07  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.02668v1  

#### Abstract
Feature selection is essential for high-dimensional biomedical data, enabling stronger predictive performance, reduced computational cost, and improved interpretability in precision medicine applications. Existing approaches face notable challenges. Filter methods are highly scalable but cannot capt...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# MAFS: Multi-head Attention Feature Selection for High-Dimensional Data via Deep Fusion of Filter Methods  
**æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
é«˜ç»´ç”Ÿç‰©åŒ»å­¦æ•°æ®ï¼ˆå¦‚åŸºå› è¡¨è¾¾ã€SNPã€å¤šç»„å­¦ï¼‰çš„ç‰¹å¾é€‰æ‹©é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **Filter æ–¹æ³•** è™½ç„¶é«˜æ•ˆå¯æ‰©å±•ï¼Œä½†æ— æ³•æ•æ‰éçº¿æ€§å…³ç³»ä¸”æ˜“é—æ¼å†—ä½™ç‰¹å¾ï¼›
- **æ·±åº¦å­¦ä¹ æ–¹æ³•** èƒ½å»ºæ¨¡å¤æ‚ä¾èµ–ï¼Œä½†ç¼ºä¹ç¨³å®šæ€§ã€å¯è§£é‡Šæ€§å’Œå¤§è§„æ¨¡æ•ˆç‡ï¼›
- **å•å¤´æ³¨æ„åŠ›æœºåˆ¶**ï¼ˆsingle-head attentionï¼‰å—é™äºå•ä¸€è§†è§’ï¼Œéš¾ä»¥å…¨é¢æ•è·å¤šå±‚æ¬¡ä¾èµ–ï¼Œä¸”å¯¹åˆå§‹åŒ–æ•æ„Ÿï¼Œå½±å“å¯é‡å¤æ€§ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šMAFS
æå‡º **MAFS**ï¼ˆMulti-head Attention-based Feature Selectionï¼‰ï¼Œä¸€ç§èåˆç»Ÿè®¡å…ˆéªŒä¸æ·±åº¦è¡¨ç¤ºèƒ½åŠ›çš„æ··åˆæ¡†æ¶ï¼ŒåŒ…å«ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ï¼š
1. **Filter Module**ï¼šä½¿ç”¨å¤šç§ filter æ–¹æ³•ï¼ˆå¦‚ SIS, BCor-SIS, Kendallâ€™s tauï¼‰ç”Ÿæˆåˆå§‹ç‰¹å¾é‡è¦æ€§æƒé‡ï¼Œä½œä¸ºå¯å­¦ä¹ çš„è½¯å…ˆéªŒï¼ˆsoft priorsï¼‰ï¼Œç”¨äºç¨³å®šåˆå§‹åŒ–ï¼›
2. **Multi-head Attention Module**ï¼šé‡‡ç”¨ multi-head å¤–éƒ¨æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ¯ä¸ª head å¹¶è¡Œå¤„ç†ä¸åŒ filter çš„è¾“å‡ºï¼Œä»å¤šä¸ªç»Ÿè®¡è§†è§’æ•æ‰çº¿æ€§ã€éçº¿æ€§ã€æ’åºç­‰ä¾èµ–å…³ç³»ï¼›
3. **Reordering Module**ï¼šå°†å„ attention head è¾“å‡ºçš„ Top-K ç‰¹å¾åˆå¹¶ä¸ºå€™é€‰é›†ï¼Œå¹¶é€šè¿‡æ ‘æ¨¡å‹ï¼ˆå¦‚ Random Forestï¼‰é‡æ–°æ’åºï¼Œè§£å†³å†²çªå¹¶æœ€å°åŒ–ä¿¡æ¯ä¸¢å¤±ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **ç¨³å®šæ€§å¢å¼º**ï¼šé€šè¿‡ filter æƒé‡å¼•å¯¼åˆå§‹åŒ–ï¼Œæ˜¾è‘—é™ä½å¯¹éšæœºåˆå§‹åŒ–çš„æ•æ„Ÿæ€§ï¼›
- **å¤šè§†è§’èåˆ**ï¼šmulti-head è®¾è®¡å…è®¸æ¨¡å‹åŒæ—¶è¯„ä¼°å¤šç§ç‰¹å¾-å“åº”å…³ç³»ï¼Œæå‡å¯¹å¤æ‚éçº¿æ€§ä¾èµ–çš„è¯†åˆ«èƒ½åŠ›ï¼›
- **å¯è§£é‡Šæ€§å¼º**ï¼šattention æƒé‡æä¾›é€æ˜çš„ç‰¹å¾é‡è¦æ€§è¯„åˆ†ï¼›
- **é«˜æ•ˆæ€§**ï¼šä½¿ç”¨å¤–éƒ¨æ³¨æ„åŠ›ï¼ˆexternal attentionï¼‰ï¼Œè®¡ç®—å¤æ‚åº¦ç”± $O(n^2p)$ é™è‡³ $O(np)$ï¼Œé€‚åˆè¶…é«˜ç»´åœºæ™¯ï¼›
- **é²æ£’æ€§é«˜**ï¼šåœ¨æ¨¡æ‹Ÿå’ŒçœŸå®æ•°æ®ä¸­å‡è¡¨ç°å‡ºæ›´é«˜çš„è¦†ç›–ç‡ï¼ˆcoverageï¼‰å’Œæ›´å°çš„æ–¹å·®ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†
#### ï¼ˆ1ï¼‰æ¨¡æ‹Ÿæ•°æ®ï¼ˆSimulationï¼‰
- åŸºäº **OmicsSIMLA** ç”Ÿæˆï¼š
  - è¿ç»­å‹ï¼šRNA-seq è¡¨è¾¾æ•°æ®ï¼ˆè´ŸäºŒé¡¹åˆ†å¸ƒï¼Œå‚æ•°æ¥è‡ª TCGA BRCAï¼‰ï¼›
  - åˆ†ç±»å‹ï¼šSNP åŸºå› å‹ï¼ˆåŸºäº 1000 Genomes CEPH ç¾¤ä½“ï¼ŒHAPGEN2 æ¨¡æ‹Ÿï¼‰ï¼›
  - ç»„åˆå‹ï¼šè¿ç»­ + åˆ†ç±»æ··åˆã€‚
- åŠŸèƒ½å½¢å¼ï¼š7 ç§ç‰¹å¾-å“åº”å…³ç³»ï¼ˆçº¿æ€§ã€å¯¹æ•°ã€ä½™å¼¦ã€æŒ‡æ•°ã€ç«‹æ–¹ã€äº¤äº’é¡¹ç­‰ï¼‰ï¼›
- ç»´åº¦ï¼š$p = 25K, 50K, 100K$ï¼›æ ·æœ¬é‡ï¼š$n = 500, 2000$ï¼›
- å› å˜é‡ç±»å‹ï¼šè¿ç»­ï¼ˆæ­£æ€ï¼‰ä¸äºŒåˆ†ç±»ï¼ˆå¹³è¡¡ç—…ä¾‹å¯¹ç…§ï¼‰ã€‚

#### ï¼ˆ2ï¼‰çœŸå®æ•°æ®
- **ç™Œç—‡åŸºå› è¡¨è¾¾æ•°æ®é›†**ï¼ˆ6ä¸ªï¼‰ï¼š
  - Colon, Leukemia, ALLAML, GLI_85, Prostate_GE, SMK_CAN_187ï¼›
  - ä»»åŠ¡ï¼šäºŒåˆ†ç±»ï¼ˆè‚¿ç˜¤ vs æ­£å¸¸ï¼‰ï¼›
  - ç‰¹å¾ç»´åº¦ï¼š2K ~ 22Kã€‚
- **ADNI æ•°æ®é›†**ï¼ˆé˜¿å°”èŒ¨æµ·é»˜ç—…ç¥ç»å½±åƒè®¡åˆ’ï¼‰ï¼š
  - æ ·æœ¬æ•°ï¼š449ï¼›
  - ç‰¹å¾ï¼š49,386 ä¸ªåŸºå› è¡¨è¾¾ï¼›
  - å“åº”å˜é‡ï¼š9 ä¸ªè„‘åŒºä½“ç§¯ï¼ˆè¿ç»­å‹è¡¨å‹ï¼‰ï¼›
  - ä»»åŠ¡ï¼šå›å½’é¢„æµ‹ã€‚

### ğŸ§ª å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
| ç±»åˆ« | è®¾ç½® |
|------|------|
| **è®­ç»ƒ/éªŒè¯/æµ‹è¯•åˆ’åˆ†** | æ¨¡æ‹Ÿæ•°æ®ï¼š80%/20%ï¼›çœŸå®æ•°æ®ï¼š5æŠ˜ CV æˆ– 60:20:20 |
| **è¶…å‚ä¼˜åŒ–** | ä½¿ç”¨ Optuna è¿›è¡Œ 100 æ¬¡è´å¶æ–¯æœç´¢ |
| **ç½‘ç»œæ¶æ„** | æ‰€æœ‰åµŒå…¥å¼æ–¹æ³•ç»Ÿä¸€ä½¿ç”¨ä¸¤å±‚ MLPï¼ˆBN + ReLU + Dropoutï¼‰ |
| **è¯„ä¼°æŒ‡æ ‡** | 
| - æ¨¡æ‹Ÿæ•°æ® | **Coverage Rate**ï¼šé€‰ä¸­çš„å› æœç‰¹å¾æ¯”ä¾‹ |
| - çœŸå®æ•°æ® | **AUROC**ï¼ˆåˆ†ç±»ï¼‰ã€**Pearson Correlation**ï¼ˆå›å½’ï¼‰ |

### âš”ï¸ åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ¯”è¾ƒäº†å››ç±»ä¸»æµæ·±åº¦å­¦ä¹ ç‰¹å¾é€‰æ‹©æ–¹æ³•ï¼š
| æ–¹æ³• | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| **CancelOut** | Layer-based gating | å­¦ä¹ é—¨æ§å‘é‡è¿›è¡Œè½¯é€‰æ‹© |
| **DeepLIFT** | Gradient-based attribution | åå‘ä¼ æ’­æ¿€æ´»å·®å¼‚å½’å›  |
| **EAR-FS** | Attention-based | å•å¤´å¤–éƒ¨æ³¨æ„åŠ›æœºåˆ¶ |
| **GRACES** | Graph-based | å›¾å·ç§¯ + è¾“å…¥æ¢¯åº¦ä¼°è®¡ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰æ¨¡æ‹Ÿå®éªŒç»“æœï¼ˆFig. 2â€“4ï¼‰
- åœ¨æ‰€æœ‰é…ç½®ä¸‹ï¼Œ**MAFS å§‹ç»ˆå–å¾—æœ€é«˜ coverage**ï¼š
  - å½“é€‰æ‹©å‰ 2% ç‰¹å¾æ—¶ï¼Œåœ¨ $p=100K, n=2000$ ä¸‹ï¼š
    - **è¿ç»­å“åº”**ï¼šMAFS è¾¾åˆ°çº¦ **0.86**ï¼ˆçº¿æ€§ï¼‰ï¼Œ**1.0**ï¼ˆå¯¹æ•°ï¼‰ï¼Œ**0.93**ï¼ˆä½™å¼¦ï¼‰ï¼›
    - **äºŒåˆ†ç±»å“åº”**ï¼šMAFS æ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œå°¤å…¶åœ¨éçº¿æ€§å…³ç³»ä¸Šä¼˜åŠ¿æ˜æ˜¾ã€‚
- **ç¨³å®šæ€§æ›´é«˜**ï¼šMAFS çš„ç½®ä¿¡åŒºé—´å®½åº¦ï¼ˆÂ±2.2%ï¼‰å°äºå…¶ä»–æ–¹æ³•ï¼ˆÂ±2.5â€“3.1%ï¼‰ã€‚

#### ï¼ˆ2ï¼‰ç»´åº¦æ‰©å±•æ€§åˆ†æï¼ˆFig. 4ï¼‰
- éšç€ç»´åº¦å¢åŠ ï¼ˆ25K â†’ 100Kï¼‰ï¼Œæ‰€æœ‰æ–¹æ³• coverage ä¸‹é™ï¼Œä½† **MAFS ä¸‹é™æœ€ç¼“**ï¼š
  - å›ºå®šé€‰æ‹© Top 100 ç‰¹å¾æ—¶ï¼š
    - MAFS coverage å‡å°‘ **21%**ï¼ˆè¿ç»­å“åº”ï¼‰ï¼›
    - GRACES å‡å°‘ **47%**ï¼ŒCancelOut å‡å°‘ **100%**ï¼ˆé™è‡³ 0ï¼‰ï¼›
  - è¡¨æ˜ MAFS æ›´èƒ½åº”å¯¹â€œç»´åº¦ç¾éš¾â€ã€‚

#### ï¼ˆ3ï¼‰çœŸå®æ•°æ®è¡¨ç°

##### ç™Œç—‡æ•°æ®é›†ï¼ˆFig. 5ï¼‰
- åœ¨ **Leukemia / Prostate**ï¼ˆæ˜“åˆ†æ•°æ®ï¼‰ä¸Šï¼Œå„æ–¹æ³•æ€§èƒ½æ¥è¿‘ï¼ˆAUROC > 0.95ï¼‰ï¼›
- åœ¨ **Colon / Lung**ï¼ˆéš¾åˆ†æ•°æ®ï¼‰ä¸Šï¼ŒMAFS æ˜æ˜¾é¢†å…ˆï¼š
  - Colonï¼ˆMLP, 20 featuresï¼‰ï¼š**AUROC = 0.922**ï¼ˆvs GRACES 0.896, EAR-FS 0.855ï¼‰ï¼›
  - Lungï¼ˆMLPï¼‰ï¼š**0.785**ï¼ˆé¢†å…ˆç¬¬äºŒå > 0.022ï¼‰ï¼›
- **æ•ˆç‡æ›´é«˜**ï¼šMAFS ä»…éœ€ 2â€“3 ä¸ªç‰¹å¾å³å¯è¾¾åˆ° AUROC > 0.95ï¼ˆLeukemiaï¼‰ï¼Œè€Œ EAR-FS éœ€ 8â€“10 ä¸ªã€‚

##### ADNI æ•°æ®é›†ï¼ˆFig. 6ï¼‰
- åœ¨å¤šæ•°è„‘åŒºï¼ˆå¦‚ brainstem, pallidumï¼‰ä¸­ï¼ŒMAFS å®ç°æœ€é«˜ Pearson ç›¸å…³æ€§ï¼š
  - Brainstemï¼ˆMLP, 50 featuresï¼‰ï¼š**0.440**ï¼ˆvs GRACES 0.418, EAR-FS 0.329ï¼‰ï¼›
  - Accumbens areaï¼š**0.219**ï¼ˆè¿œé«˜äº EAR-FS çš„ 0.100ï¼‰ï¼›
- åŒæ ·è¡¨ç°å‡ºæ›´å¼ºçš„ç‰¹å¾åˆ©ç”¨æ•ˆç‡ã€‚

### ğŸ”¬ æ¶ˆèå®éªŒä¸è¡¥å……åˆ†æï¼ˆSupplementary Figuresï¼‰
- **æ»¤æ³¢å™¨å¼•å¯¼åˆå§‹åŒ–æœ¬èº«å³æœ‰æ•ˆ**ï¼š
  - å°† EAR-FS çš„å‡åŒ€åˆå§‹åŒ–æ›¿æ¢ä¸º filter åˆå§‹åŒ–åï¼Œå…¶æ€§èƒ½æ˜¾è‘—æå‡ï¼ˆSupp. Fig. S12â€“S19ï¼‰ï¼›
  - è¯´æ˜ **é«˜è´¨é‡åˆå§‹åŒ–æ˜¯å…³é”®å› ç´ ä¹‹ä¸€**ï¼Œç”šè‡³å¯èƒ½æ¯”æ¶æ„æ”¹è¿›æ›´é‡è¦ã€‚
- **multi-head æ³¨æ„åŠ›å¸¦æ¥é¢å¤–å¢ç›Š**ï¼š
  - å¤šå¤´è®¾è®¡è¿›ä¸€æ­¥æå‡äº† coverage å’Œç¨³å®šæ€§ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚åŠŸèƒ½å…³ç³»ä¸‹ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **MAFS å®ç°äº† filter æ–¹æ³•ä¸æ·±åº¦å­¦ä¹ çš„ä¼˜åŠ¿èåˆ**ï¼š
   - åˆ©ç”¨ filter æä¾›ç¨³å®šå…ˆéªŒï¼Œé¿å…ç›²ç›®åˆå§‹åŒ–ï¼›
   - åˆ©ç”¨ multi-head attention æ•æ‰å¤šå°ºåº¦ã€éçº¿æ€§ä¾èµ–ï¼›
   - é€šè¿‡ reordering æ¨¡å—æ•´åˆå¤šè§†è§’ç»“æœï¼Œå‡å°‘ä¿¡æ¯æŸå¤±ã€‚

2. **åœ¨å„ç§æ•°æ®ç±»å‹å’Œå…³ç³»ä¸‹å‡è¡¨ç°æœ€ä¼˜**ï¼š
   - å¯¹çº¿æ€§ã€éçº¿æ€§ã€äº¤äº’æ•ˆåº”å‡æœ‰è‰¯å¥½é€‚åº”æ€§ï¼›
   - åœ¨è¶…é«˜ç»´ï¼ˆ$p=100K$ï¼‰å’Œå°æ ·æœ¬ï¼ˆ$n=500$ï¼‰æ¡ä»¶ä¸‹ä»ä¿æŒé«˜è¦†ç›–ç‡ã€‚

3. **å…·å¤‡è‰¯å¥½çš„å®ç”¨ä»·å€¼**ï¼š
   - èƒ½ä»¥æ›´å°‘ç‰¹å¾å®ç°åŒç­‰æˆ–æ›´å¥½é¢„æµ‹æ€§èƒ½ï¼Œæœ‰åˆ©äºä¸‹æ¸¸è§£é‡Šä¸éªŒè¯ï¼›
   - åœ¨ç™Œç—‡åˆ†ç±»ä¸ç¥ç»å½±åƒå›å½’ä»»åŠ¡ä¸­å‡è¶…è¶Šå½“å‰ SOTA æ–¹æ³•ã€‚

### âš ï¸ å±€é™æ€§
1. **å½’ä¸€åŒ–å¯èƒ½å¯¼è‡´æƒé‡å¤±çœŸ**ï¼š
   - ä¸åŒ filter æ–¹æ³•çš„åŸå§‹å°ºåº¦å·®å¼‚å¯èƒ½è¢«å‹ç¼©ï¼Œå½±å“å…ˆéªŒä¿¡å·å¼ºåº¦ï¼›
   - æœªæ¥å¯æ¢ç´¢ learnable fusion æˆ– rank-level èåˆç­–ç•¥ã€‚

2. **è¦æ±‚å®Œæ•´ç‰¹å¾çŸ©é˜µ**ï¼š
   - æ— æ³•ç›´æ¥å¤„ç†ç¼ºå¤±å€¼ï¼Œå¯èƒ½å¼•å…¥é€‰æ‹©åå·®ï¼›
   - å¯ç»“åˆ imputation æˆ– missing-aware attention è¿›è¡Œæ‰©å±•ã€‚

3. **è®¡ç®—å¼€é”€é«˜äºè½»é‡çº§æ–¹æ³•**ï¼š
   - è™½ç„¶æ¯” GRACES å¿«ä¸€ä¸ªæ•°é‡çº§ä»¥ä¸Šï¼ˆ117.6 min vs 1569.9 minï¼‰ï¼Œä½†ä»æ…¢äº CancelOut / DeepLIFTï¼›
   - å¯é€šè¿‡æ¨¡å‹è’¸é¦æˆ–ç¨€ç–åŒ–è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´çµæ´»çš„ filter èåˆæœºåˆ¶ï¼ˆå¦‚ attention-based fusionï¼‰ï¼›
- å¼•å…¥ missing-data handling æœºåˆ¶ä»¥é€‚åº”ä¸´åºŠæ•°æ®ï¼›
- æ‰©å±•è‡³å¤šä»»åŠ¡æˆ–å¤šæ¨¡æ€ç‰¹å¾é€‰æ‹©åœºæ™¯ï¼›
- å¼€å‘å¯è§†åŒ–å·¥å…·æ”¯æŒç”Ÿç‰©å­¦è§£é‡Šä¸å‡è¯´ç”Ÿæˆã€‚

---

## æ€»ç»“
**MAFS æ˜¯ä¸€ç§æ–°é¢–ã€ç¨³å¥ã€å¯è§£é‡Šçš„é«˜ç»´ç‰¹å¾é€‰æ‹©æ¡†æ¶**ï¼Œé€šè¿‡å°†ä¼ ç»Ÿ filter æ–¹æ³•ä¸ multi-head attention æ·±åº¦èåˆï¼ŒæˆåŠŸå…‹æœäº†ç°æœ‰æ–¹æ³•åœ¨ç¨³å®šæ€§ã€è¡¨è¾¾èƒ½åŠ›å’Œæ•ˆç‡ä¹‹é—´çš„æƒè¡¡éš¾é¢˜ã€‚å®éªŒè¡¨æ˜å…¶åœ¨æ¨¡æ‹Ÿä¸çœŸå®ç”Ÿç‰©åŒ»å­¦æ•°æ®ä¸­å‡æ˜¾è‘—ä¼˜äºä¸»æµæ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œä¸ºç²¾å‡†åŒ»å­¦ä¸­çš„ biomarker å‘ç°æä¾›äº†å¼ºæœ‰åŠ›çš„æŠ€æœ¯æ”¯æŒã€‚

</details>

---

### 16. [Uni-FinLLM: A Unified Multimodal Large Language Model with Modular Task Heads for Micro-Level Stock Prediction and Macro-Level Systemic Risk Assessment](https://arxiv.org/abs/2601.02677)

**Authors**: Gongao Zhang, Haijiang Zeng, Lu Jiang  
**Category**: cs.LG  
**Published**: 2026-01-07  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.02677v1  

#### Abstract
Financial institutions and regulators require systems that integrate heterogeneous data to assess risks from stock fluctuations to systemic vulnerabilities. Existing approaches often treat these tasks in isolation, failing to capture cross-scale dependencies. We propose Uni-FinLLM, a unified multimo...

---

### 17. [From Memorization to Creativity: LLM as a Designer of Novel Neural-Architectures](https://arxiv.org/abs/2601.02997)

**Authors**: Waleed Khalid, Dmitry Ignatov, Radu Timofte  
**Category**: cs.LG  
**Published**: 2026-01-07  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.02997v1  

#### Abstract
Large language models (LLMs) excel in program synthesis, yet their ability to autonomously navigate neural architecture design--balancing syntactic reliability, performance, and structural novelty--remains underexplored. We address this by placing a code-oriented LLM within a closed-loop synthesis f...

---

### 18. [MindChat: A Privacy-preserving Large Language Model for Mental Health Support](https://arxiv.org/abs/2601.01993)

**Authors**: Dong Xue, Jicheng Tu, Ming Wang, Xin Yan, Fangzhou Liu, Jie Hu  
**Category**: cs.AI  
**Published**: 2026-01-07  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.01993v1  

#### Abstract
Large language models (LLMs) have shown promise for mental health support, yet training such models is constrained by the scarcity and sensitivity of real counseling dialogues. In this article, we present MindChat, a privacy-preserving LLM for mental health support, together with MindCorpus, a synth...

---

### 19. [WebAnchor: Anchoring Agent Planning to Stabilize Long-Horizon Web Reasoning](https://arxiv.org/abs/2601.03164)

**Authors**: Yu Xinmiao, Zhang Liwen, Feng Xiaocheng, Jiang Yong, Qin Bing, Xie Pengjun, Zhou Jingren  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.03164v1  

#### Abstract
Large Language Model(LLM)-based agents have shown strong capabilities in web information seeking, with reinforcement learning (RL) becoming a key optimization paradigm. However, planning remains a bottleneck, as existing methods struggle with long-horizon strategies. Our analysis reveals a critical ...

---

### 20. [Electricity Price Forecasting: Bridging Linear Models, Neural Networks and Online Learning](https://arxiv.org/abs/2601.02856)

**Authors**: Btissame El Mahtout, Florian Ziel  
**Category**: cs.LG  
**Published**: 2026-01-07  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.02856v1  

#### Abstract
Precise day-ahead forecasts for electricity prices are crucial to ensure efficient portfolio management, support strategic decision-making for power plant operations, enable efficient battery storage optimization, and facilitate demand response planning. However, developing an accurate prediction mo...

---

### 21. [FlowPlan-G2P: A Structured Generation Framework for Transforming Scientific Papers into Patent Descriptions](https://arxiv.org/abs/2601.02589)

**Authors**: Kris W Pan, Yongmin Yoo  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.02589v1  

#### Abstract
Over 3.5 million patents are filed annually, with drafting patent descriptions requiring deep technical and legal expertise. Transforming scientific papers into patent descriptions is particularly challenging due to their differing rhetorical styles and stringent legal requirements. Unlike black-box...

---

### 22. [LLM-Augmented Changepoint Detection: A Framework for Ensemble Detection and Automated Explanation](https://arxiv.org/abs/2601.02957)

**Authors**: Fabian Lukassen, Christoph Weisser, Michael Schlee, Manish Kumar, Anton Thielmann, Benjamin Saefken, Thomas Kneib  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.02957v1  

#### Abstract
This paper introduces a novel changepoint detection framework that combines ensemble statistical methods with Large Language Models (LLMs) to enhance both detection accuracy and the interpretability of regime changes in time series data. Two critical limitations in the field are addressed. First, in...

---

### 23. [UltraLogic: Enhancing LLM Reasoning through Large-Scale Data Synthesis and Bipolar Float Reward](https://arxiv.org/abs/2601.03205)

**Authors**: Yile Liu, Yixian Liu, Zongwei Li, Yufei Huang, Xinhua Feng, Zhichao Hu, Jinglu Hu, Jianfeng Yan, Fengzong Lian, Yuhong Liu  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.03205v1  

#### Abstract
While Large Language Models (LLMs) have demonstrated significant potential in natural language processing , complex general-purpose reasoning requiring multi-step logic, planning, and verification remains a critical bottleneck. Although Reinforcement Learning with Verifiable Rewards (RLVR) has succe...

---

### 24. [Scalable Tree Ensemble Proximities in Python](https://arxiv.org/abs/2601.02735)

**Authors**: Adrien Aumon, Guy Wolf, Kevin R. Moon, Jake S. Rhodes  
**Category**: cs.LG  
**Published**: 2026-01-07  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.02735v1  

#### Abstract
Tree ensemble methods such as Random Forests naturally induce supervised similarity measures through their decision tree structure, but existing implementations of proximities derived from tree ensembles typically suffer from quadratic time or memory complexity, limiting their scalability. In this w...

---

### 25. [Universal Conditional Logic: A Formal Language for Prompt Engineering](https://arxiv.org/abs/2601.00880)

**Authors**: Anthony Mikinka  
**Category**: cs.AI  
**Published**: 2026-01-07  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.00880v1  

#### Abstract
We present Universal Conditional Logic (UCL), a mathematical framework for prompt optimization that transforms prompt engineering from heuristic practice into systematic optimization. Through systematic evaluation (N=305, 11 models, 4 iterations), we demonstrate significant token reduction (29.8%, t...

---

### 26. [PCEval: A Benchmark for Evaluating Physical Computing Capabilities of Large Language Models](https://arxiv.org/abs/2601.02404)

**Authors**: Inpyo Song, Eunji Jeon, Jangwon Lee  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.02404v1  

#### Abstract
Large Language Models (LLMs) have demonstrated remarkable capabilities across various domains, including software development, education, and technical assistance. Among these, software development is one of the key areas where LLMs are increasingly adopted. However, when hardware constraints are co...

---

### 27. [Towards Comprehensive Stage-wise Benchmarking of Large Language Models in Fact-Checking](https://arxiv.org/abs/2601.02669)

**Authors**: Hongzhan Lin, Zixin Chen, Zhiqi Shen, Ziyang Luo, Zhen Ye, Jing Ma, Tat-Seng Chua, Guandong Xu  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.02669v1  

#### Abstract
Large Language Models (LLMs) are increasingly deployed in real-world fact-checking systems, yet existing evaluations focus predominantly on claim verification and overlook the broader fact-checking workflow, including claim extraction and evidence retrieval. This narrow focus prevents current benchm...

---

### 28. [Mechanistic Knobs in LLMs: Retrieving and Steering High-Order Semantic Features via Sparse Autoencoders](https://arxiv.org/abs/2601.02978)

**Authors**: Ruikang Zhang, Shuo Wang, Qi Su  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.02978v1  

#### Abstract
Recent work in Mechanistic Interpretability (MI) has enabled the identification and intervention of internal features in Large Language Models (LLMs). However, a persistent challenge lies in linking such internal features to the reliable control of complex, behavior-level semantic attributes in lang...

---

### 29. [Dementia-R1: Reinforced Pretraining and Reasoning from Unstructured Clinical Notes for Real-World Dementia Prognosis](https://arxiv.org/abs/2601.03018)

**Authors**: Choonghan Kim, Hyunmin Hwang, Hangeol Chang, Jaemin Kim, Jinse Park, Jae-Sung Lim, Jong Chul Ye  
**Category**: cs.CL  
**Published**: 2026-01-07  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.03018v1  

#### Abstract
While Large Language Models (LLMs) have shown strong performance on clinical text understanding, they struggle with longitudinal prediction tasks such as dementia prognosis, which require reasoning over complex, non-monotonic symptom trajectories across multiple visits. Standard supervised training ...

---

### 30. [Software-Defined Agentic Serving](https://arxiv.org/abs/2601.03197)

**Authors**: Saurabh Agarwal, Marco Laju, Jayanth Srinivasa, Myungjin Lee, Aditya Akella  
**Category**: cs.DC  
**Published**: 2026-01-07  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.03197v1  

#### Abstract
As multi-agent LLM pipelines grow in complexity, existing serving paradigms fail to adapt to the dynamic serving conditions. We argue that agentic serving systems should be programmable and system-aware, unlike existing serving which statically encode the parameters. In this work, we propose a new S...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
