# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-02-20 06:36:33 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Mobility-Aware Cache Framework for Scalable LLM-Based Human Mobility Simulation](https://arxiv.org/abs/2602.16727)

**Authors**: Hua Yan, Heng Tan, Yingxue Zhang, Yu Yang  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.16727v1  

#### Abstract
Large-scale human mobility simulation is critical for applications such as urban planning, epidemiology, and transportation analysis. Recent works treat large language models (LLMs) as human agents to simulate realistic mobility behaviors using structured reasoning, but their high computational cost...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šMobility-Aware Cache Framework for Scalable LLM-Based Human Mobility Simulation**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
ç°æœ‰çš„åŸºäº **Large Language Models (LLMs)** çš„äººç±»ç§»åŠ¨æ€§æ¨¡æ‹Ÿæ–¹æ³•è™½ç„¶èƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„ä¸ªä½“è¡Œä¸ºè½¨è¿¹ï¼Œä½†ç”±äºéœ€è¦å¯¹æ¯ä¸ªä¸ªä½“è¿›è¡Œç‹¬ç«‹çš„ LLM æ¨ç†ï¼Œå¯¼è‡´è®¡ç®—æˆæœ¬æé«˜ï¼Œéš¾ä»¥æ‰©å±•åˆ°å¤§è§„æ¨¡äººç¾¤ï¼ˆå¦‚ç™¾ä¸‡çº§ä»£ç†ï¼‰çš„æ¨¡æ‹Ÿã€‚æ­¤å¤–ï¼Œä¼ ç»Ÿå“åº”ç¼“å­˜ï¼ˆresponse cachingï¼‰è™½èƒ½é™ä½è°ƒç”¨æ¬¡æ•°ï¼Œä½†ä¼šä¸¥é‡é™åˆ¶è¡Œä¸ºå¤šæ ·æ€§ï¼ŒæŸå®³æ¨¡æ‹Ÿçš„çœŸå®æ€§ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º **MobCache** çš„ **mobility-aware cache framework**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥â€œ**reconstructible caches**â€â€”â€”å³åœ¨**æ½œåœ¨ç©ºé—´ï¼ˆlatent spaceï¼‰ä¸­ç¼“å­˜ LLM çš„æ¨ç†æ­¥éª¤**ï¼Œè€Œéæœ€ç»ˆè¾“å‡ºæ–‡æœ¬ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼š

1. **Reconstructible Cacheï¼ˆå¯é‡æ„ç¼“å­˜ï¼‰**  
   - å°† LLM åœ¨ç”Ÿæˆç§»åŠ¨è½¨è¿¹æ—¶çš„æ¯ä¸€æ­¥æ¨ç†è¡¨ç¤ºä¸º **latent-space embedding**ã€‚
   - æ„å»ºæ ‘çŠ¶ç»“æ„çš„ç¼“å­˜ï¼Œæ”¯æŒä»ä»»æ„ä¸­é—´èŠ‚ç‚¹åˆ†æ”¯å¹¶ä¸å…¶ä»–ç¼“å­˜é“¾é‡ç»„ï¼Œå®ç°çµæ´»å¤ç”¨ã€‚
   - å¼•å…¥ **latent-space evaluator** æ¥è¯„ä¼°æ½œåœ¨æ¨ç†è·¯å¾„çš„åˆç†æ€§ï¼Œç¡®ä¿é€»è¾‘ä¸€è‡´æ€§ã€‚

2. **Lightweight Decoderï¼ˆè½»é‡åŒ–è§£ç å™¨ï¼‰**  
   - ä½¿ç”¨ä¸€ä¸ªå°å‹æ¨¡å‹é€šè¿‡ **mobility law-constrained distillation** è¿›è¡Œè®­ç»ƒï¼Œå°†æ½œåœ¨ç©ºé—´ä¸­çš„æ¨ç†é“¾é«˜æ•ˆè§£ç ä¸ºè‡ªç„¶è¯­è¨€æ´»åŠ¨åºåˆ—ã€‚
   - é¿å…é‡å¤è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œè§£ç ï¼Œæ˜¾è‘—æå‡æ•ˆç‡ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **æ•ˆç‡** | æ˜¾è‘—å‡å°‘ LLM è°ƒç”¨æ¬¡æ•°ï¼Œå¤§å¹…é™ä½æ¨ç†æ—¶é—´ä¸æˆæœ¬ |
| **å¤šæ ·æ€§** | æ”¯æŒæ¨ç†é“¾çš„çµæ´»é‡ç»„ï¼Œé¿å…ç¾¤ä½“åŒ–è¡Œä¸ºï¼ˆgroup-based methodsï¼‰å¸¦æ¥çš„åŒè´¨åŒ–é—®é¢˜ |
| **ä¿çœŸåº¦** | é€šè¿‡ mobility law çº¦æŸè’¸é¦ä¿æŒæ—¶ç©ºä¸€è‡´æ€§ï¼Œç»´æŒé«˜è´¨é‡æ¨¡æ‹Ÿ |
| **é€šç”¨æ€§** | å¯ä½œä¸ºæ’ä»¶åŠ é€Ÿå…¶ä»– LLM-based mobility æ¨¡æ‹Ÿæ–¹æ³•ï¼ˆå¦‚ Urban-Mobility-LLMï¼‰ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **Beijing Dataset**ï¼šæ¥è‡ªä¸­å›½åŒ—äº¬çš„ç¤¾ä¼šç½‘ç»œå¹³å°ï¼Œæ¶µç›– 2019 å¹´ 10 æœˆè‡³ 12 æœˆçš„çœŸå®ç§»åŠ¨è½¨è¿¹åŠç”¨æˆ·ç”»åƒï¼ˆå¹´é¾„ã€èŒä¸šç­‰ï¼‰ã€‚
- **NYC POI Check-in Dataset**ï¼šçº½çº¦å¸‚çš„å…´è¶£ç‚¹ç­¾åˆ°æ•°æ®ï¼Œç»“åˆç¾å›½äººå£æ™®æŸ¥ï¼ˆU.S. Censusï¼‰ç»Ÿè®¡æ•°æ®æ¨¡æ‹Ÿç”¨æˆ·ç”»åƒã€‚

### **å®éªŒè®¾ç½®**
- **ç¼“å­˜æ„å»º**ï¼šä½¿ç”¨ LLaMA 3.2-3B ç”Ÿæˆçº¦ 13,000 æ¡åˆæˆè½¨è¿¹ç”¨äº fine-tuningï¼Œæå– latent-space reasoning chains æ„å»ºç¼“å­˜ã€‚
- **æµ‹è¯•é›†**ï¼šä»çœŸå®æ•°æ®ä¸­é‡‡æ · 10,000 æ¡è½¨è¿¹ï¼Œç¡®ä¿æ— ç”¨æˆ·é‡å ã€‚
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼šNVIDIA A100 / A6000 GPUï¼ŒPython 3.10 + PyTorch 2.1.0ã€‚
- **æ¢ç´¢ç‡ï¼ˆexploration rateï¼‰** è®¾ç½®ä¸º 0.5ï¼Œåœ¨æ•ˆç‡ä¸å¤šæ ·æ€§é—´å–å¾—å¹³è¡¡ã€‚

### **è¯„ä¼°æŒ‡æ ‡**

#### **æ•ˆç‡æŒ‡æ ‡ï¼ˆEfficiency Metricsï¼‰**
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Inference time â†“** | å•æ¡è½¨è¿¹å¹³å‡ç”Ÿæˆè€—æ—¶ï¼ˆç§’ï¼‰ |
| **Tokens per second â†‘** | æ¯ç§’å¤„ç† token æ•°é‡ |
| **Throughput â†‘** | æ‰¹é‡å¤„ç†ä¸‹æ¯ç§’ç”Ÿæˆè½¨è¿¹æ•°ï¼ˆbatch size=8ï¼‰ |
| **Cost â†“** | å•æ¡è½¨è¿¹ç”Ÿæˆæˆæœ¬ï¼ˆAPI æˆ–æœ¬åœ° GPU æˆæœ¬ä¼°ç®—ï¼‰ |

#### **è´¨é‡æŒ‡æ ‡ï¼ˆQuality Metricsï¼‰**
é‡‡ç”¨ **Jensen-Shannon Divergence (JSD)** è¡¡é‡ç”Ÿæˆè½¨è¿¹ä¸çœŸå®æ•°æ®åˆ†å¸ƒçš„å·®å¼‚ï¼š
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Radius of gyration â†“** | ä¸ªä½“æ´»åŠ¨èŒƒå›´çš„ç©ºé—´ç¦»æ•£ç¨‹åº¦ |
| **Stay duration â†“** | åœç•™æ—¶é•¿åˆ†å¸ƒç›¸ä¼¼æ€§ |
| **Jump length â†“** | è¿ç»­ä½ç½®é—´è·ç¦»åˆ†å¸ƒ |
| **LocFreq â†“** | åœ°ç†ç½‘æ ¼è®¿é—®é¢‘ç‡åˆ†å¸ƒ |
| **OdSim â†“** | å‡ºå‘åœ°-ç›®çš„åœ°ï¼ˆODï¼‰æ¨¡å¼ç›¸ä¼¼æ€§ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
åˆ†ä¸ºä¸¤ç±»ï¼š

#### **æ— éœ€çœŸå®æ•°æ®è®­ç»ƒçš„æ–¹æ³•**
- **CoPB**ï¼šåŸºäºè®¡åˆ’è¡Œä¸ºé“¾ï¼ˆChain-of-Planned-Behaviorï¼‰å¼•å¯¼ LLM æ¨ç†ã€‚
- **Urban-Mobility-LLM**ï¼šåˆ©ç”¨ LLM åˆæˆå‡ºè¡Œè°ƒæŸ¥æ•°æ®ã€‚
- **LLMob**ï¼šç»“åˆè‡ªæ´½æ€§ä¸æ£€ç´¢ç­–ç•¥çš„ LLM agent æ¡†æ¶ã€‚

#### **éœ€çœŸå®æ•°æ®è®­ç»ƒçš„æ–¹æ³•**
- **Geo-LLaMA**ï¼šåœ¨çœŸå®è½¨è¿¹ä¸Šå¾®è°ƒ LLMï¼Œæ»¡è¶³æ—¶ç©ºçº¦æŸã€‚

#### **æ¶ˆèå˜ä½“**
- **MobCache w/o LE**ï¼šç§»é™¤ latent-space evaluatorï¼Œä»…ç”¨ç›¸ä¼¼åº¦åŒ¹é…ã€‚
- **MobCache w/o MD**ï¼šç§»é™¤ mobility law distillationã€‚
- **MobCache w/o LD**ï¼šä¸ä½¿ç”¨è½»é‡åŒ–è§£ç å™¨ï¼Œç›´æ¥ç”¨åŸ LLM è§£ç ã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆBeijing æ•°æ®é›†ï¼‰**

| æ–¹æ³• | Inference Time â†“ (s) | Tokens/s â†‘ | Throughput â†‘ (traj/s) | Cost â†“ ($Ã—10â»Â³) |
|------|------------------------|------------|------------------------|------------------|
| CoPB | 69.1675 | 25.7023 | 0.1005 | 1.7776 |
| Urban-Mobility-LLM | 8.0800 | 67.3117 | 0.9010 | 0.5439 |
| Geo-LLaMA | 2.3410 | 25.8006 | 1.2701 | 0.0325 |
| **MobCache** | **1.3530** | **121.7636** | **1.6329** | **0.0187** |

> âœ… **ç›¸æ¯”æœ€ä¼˜åŸºçº¿ï¼ˆUrban-Mobility-LLMï¼‰ï¼ŒMobCache å®ç°ï¼š**
- **42.20% æ›´ä½çš„æ¨ç†æ—¶é—´**
- **80.89% æ›´é«˜çš„ tokens/s**
- **28.56% æ›´é«˜çš„ååé‡**
- **42.46% æ›´ä½çš„æˆæœ¬**

### **è´¨é‡è¡¨ç°ï¼ˆJSD å€¼è¶Šä½è¶Šå¥½ï¼‰**

| æ–¹æ³• | Radius â†“ | Duration â†“ | Jump Length â†“ | LocFreq â†“ | OdSim â†“ |
|------|----------|------------|---------------|-----------|---------|
| Geo-LLaMA | 0.0216 | 0.0270 | 0.0188 | 0.1198 | 0.2498 |
| **MobCache** | 0.0333 | **0.0191** | 0.0258 | **0.1061** | **0.2215** |

> ğŸ” **MobCache åœ¨ 3/5 é¡¹è´¨é‡æŒ‡æ ‡ä¸Šä¼˜äº Geo-LLaMA**ï¼Œä¸”æ•´ä½“ä¸ SOTA LLM-based æ–¹æ³•ç›¸å½“ï¼Œè¯´æ˜å…¶åœ¨å¤§å¹…æå‡æ•ˆç‡çš„åŒæ—¶æœªç‰ºç‰²ä¿çœŸåº¦ã€‚

### **NYC æ•°æ®é›†ç»“æœ**
- **æ¨ç†æ—¶é—´å‡å°‘ â‰¥51.54%**
- **tokens/s æå‡ 79.71%**
- **æˆæœ¬é™ä½ 56.18%**
- è´¨é‡æŒ‡æ ‡ä¸åŸºçº¿æŒå¹³ï¼ŒéªŒè¯è·¨åŸå¸‚é€‚ç”¨æ€§ã€‚

### **æ¡ˆä¾‹ç ”ç©¶ï¼šåŠ é€Ÿ Urban-Mobility-LLM**
å°† MobCache åº”ç”¨äº Urban-Mobility-LLMï¼š
- **æ¨ç†é€Ÿåº¦æå‡ 66.93%**ï¼ˆ8.08s â†’ 2.67s/è½¨è¿¹ï¼‰
- **æˆæœ¬ä¸‹é™ 93.18%**
- è´¨é‡æ— æ˜æ˜¾æŸå¤±ï¼ˆè§ Figure 6ï¼‰

### **æ¶ˆèå®éªŒç»“æœï¼ˆBeijing æ•°æ®é›†ï¼‰**

| æ–¹æ³• | Inference Time | Cost | Duration â†“ | LocFreq â†“ | OdSim â†“ |
|------|----------------|------|------------|-----------|---------|
| **MobCache** | 1.3530 | 0.0187 | **0.0191** | **0.1061** | **0.2215** |
| w/o LE | 1.3546 | 0.0188 | 0.0203 | 0.1092 | 0.2302 |
| w/o MD | 1.3551 | 0.0188 | 0.0198 | 0.1082 | 0.2286 |
| w/o LD | 2.2450 | 0.0325 | 0.0180 | 0.0955 | 0.2013 |

> ğŸ” å‘ç°ï¼š
- ç§»é™¤ **latent-space evaluator** å¯¼è‡´è´¨é‡ä¸‹é™æœ€å¤šï¼Œè¯´æ˜å…¶å¯¹é€»è¾‘è¿è´¯æ€§è‡³å…³é‡è¦ã€‚
- ç§»é™¤ **mobility law distillation** ä¹Ÿè½»å¾®å½±å“è´¨é‡ã€‚
- ç§»é™¤ **lightweight decoder** æ•ˆç‡æ˜¾è‘—ä¸‹é™ï¼Œä½†è´¨é‡ç•¥ä¼˜ï¼Œä½“ç°è®¾è®¡æƒè¡¡ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **ç¼“å­˜æ¨ç†è¿‡ç¨‹ä¼˜äºç¼“å­˜ç»“æœ**ï¼šåœ¨ latent space ä¸­ç¼“å­˜å¹¶é‡ç»„æ¨ç†æ­¥éª¤ï¼Œæ—¢èƒ½æé«˜å¤ç”¨ç‡ï¼Œåˆèƒ½ä¿æŒè¡Œä¸ºå¤šæ ·æ€§ã€‚
2. **latent-space evaluator æ˜¯ä¿è¯é€»è¾‘ä¸€è‡´æ€§çš„å…³é”®**ï¼šç›´æ¥æ‹¼æ¥æ–‡æœ¬æ¨ç†é“¾æ˜“äº§ç”Ÿæ—¶ç©ºçŸ›ç›¾ï¼ˆå¦‚â€œä¸‹ç­åå»ä¸Šç­â€ï¼‰ï¼Œè€Œ evaluator å¯æœ‰æ•ˆç­›é€‰åˆç†è·¯å¾„ã€‚
3. **è½»é‡åŒ–è§£ç å™¨ + mobility law çº¦æŸå¯å…¼é¡¾æ•ˆç‡ä¸ä¿çœŸåº¦**ï¼šè’¸é¦è¿‡ç¨‹ä¸­æ˜¾å¼åŠ å…¥ jump length ç­‰ç»Ÿè®¡ç‰¹å¾çº¦æŸï¼Œæ˜¾è‘—æå‡ç”Ÿæˆè´¨é‡ã€‚
4. **æ¡†æ¶å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›**ï¼šå¯ç”¨äºåŠ é€Ÿå…¶ä»– LLM-based mobility æ¨¡å‹ï¼ˆå¦‚ Urban-Mobility-LLMï¼‰ï¼Œä¸”æ”¯æŒè·¨åŸå¸‚è¿ç§»ï¼ˆåŒ—äº¬ç¼“å­˜ç”¨äºçº½çº¦æ¨¡æ‹Ÿï¼‰ã€‚

### **å±€é™æ€§**
- **ä¾èµ–å¯è§£é‡Šçš„æ¨ç†æµç¨‹**ï¼šä»…é€‚ç”¨äºèƒ½æš´éœ² step-by-step reasoning çš„æ¨¡å‹ï¼Œæ— æ³•åº”ç”¨äºç«¯åˆ°ç«¯ç”Ÿæˆå¼æ¨¡å‹ã€‚
- **åˆå§‹ç¼“å­˜æ„å»ºä»éœ€ä¸€å®šé‡ LLM è°ƒç”¨**ï¼šå†·å¯åŠ¨é˜¶æ®µæˆæœ¬è¾ƒé«˜ã€‚
- **è·¨åŸå¸‚è¿ç§»ä»æœ‰æ€§èƒ½æŸå¤±**ï¼šç”±äº POI åˆ†å¸ƒå·®å¼‚ï¼Œéƒ¨åˆ†ç”¨æˆ·æ— æ³•æ‰¾åˆ°é«˜ç›¸ä¼¼åº¦ç¼“å­˜ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ¢ç´¢æ›´é«˜æ•ˆçš„ latent-space evaluator æ¶æ„ã€‚
- ç»“åˆ KV caching è¿›ä¸€æ­¥ä¼˜åŒ– token çº§åˆ«è§£ç é€Ÿåº¦ã€‚
- æ‰©å±•è‡³å¤šæ™ºèƒ½ä½“äº¤äº’åœºæ™¯ä¸‹çš„è”åˆè¡Œä¸ºæ¨¡æ‹Ÿã€‚
- ç ”ç©¶åŠ¨æ€æ›´æ–°æœºåˆ¶ä»¥é€‚åº”é•¿æœŸæ¼”åŒ–çš„äººç±»è¡Œä¸ºæ¨¡å¼ã€‚

--- 

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **MobCache é€šè¿‡åœ¨æ½œåœ¨ç©ºé—´ä¸­ç¼“å­˜å’Œé‡ç»„ LLM çš„æ¨ç†æ­¥éª¤ï¼Œå¹¶è¾…ä»¥è½»é‡åŒ–è§£ç ä¸ mobility law çº¦æŸï¼Œå®ç°äº†é«˜æ•ˆã€å¤šæ ·ä¸”ä¿çœŸçš„å¤§è§„æ¨¡äººç±»ç§»åŠ¨æ€§æ¨¡æ‹Ÿï¼Œæ˜¯è¿ˆå‘ä½æˆæœ¬åŸå¸‚çº§ä»¿çœŸç³»ç»Ÿçš„é‡è¦ä¸€æ­¥ã€‚**

</details>

---

### 2. [Automating Agent Hijacking via Structural Template Injection](https://arxiv.org/abs/2602.16958)

**Authors**: Xinhao Deng, Jiaqing Wu, Miao Chen, Yue Xiao, Ke Xu, Qi Li  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.16958v1  

#### Abstract
Agent hijacking, highlighted by OWASP as a critical threat to the Large Language Model (LLM) ecosystem, enables adversaries to manipulate execution by injecting malicious instructions into retrieved content. Most existing attacks rely on manually crafted, semantics-driven prompt manipulation, which ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠAutomating Agent Hijacking via Structural Template Injectionã€‹æ ¸å¿ƒæ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
æœ¬æ–‡é’ˆå¯¹ **LLM Agent** ä¸­æ—¥ç›Šä¸¥é‡çš„ **Agent Goal Hijacking** å®‰å…¨å¨èƒï¼Œæ­ç¤ºäº†ä¸€ä¸ªæ ¹æœ¬æ€§çš„æ¶æ„æ¼æ´ï¼šå½“å‰ä¸»æµ LLM Agent åœ¨å¤„ç†å¯¹è¯æ—¶ï¼Œä¾èµ–äº **Chat Template** å’Œç‰¹æ®Šæ ‡è®°ï¼ˆå¦‚ `<|im_start|>`ã€`<|im_end|>`ï¼‰æ¥åŒºåˆ† `System`ã€`User`ã€`Assistant` å’Œ `Tool` è§’è‰²ã€‚ç„¶è€Œï¼Œè¿™äº›æ§åˆ¶ä¿¡å·ä¸å¤–éƒ¨ä¸å¯ä¿¡å†…å®¹åœ¨ token å±‚é¢æœªå®ç°ä¸¥æ ¼éš”ç¦»ï¼Œå¯¼è‡´æ”»å‡»è€…å¯é€šè¿‡æ„é€ æ¶æ„çš„ **ç»“æ„åŒ–æ¨¡æ¿æ³¨å…¥ï¼ˆStructured Template Injection, STIï¼‰** æ¥è¯±å¯¼è§’è‰²æ··æ·†ï¼ˆRole Confusionï¼‰ï¼Œä»è€ŒåŠ«æŒ Agent æ‰§è¡Œæµç¨‹ã€‚

ç°æœ‰åŸºäºè¯­ä¹‰çš„ **Indirect Prompt Injection (IPI)** æ”»å‡»å­˜åœ¨ä¸¤å¤§ç¼ºé™·ï¼š
- **æˆåŠŸç‡ä½**ï¼šå— RLHF å¼ºåŒ–è®­ç»ƒå½±å“ï¼Œæ¨¡å‹å¯¹æ˜æ˜¾æŒ‡ä»¤è¿èƒŒæ›´å…·é²æ£’æ€§ã€‚
- **è¿ç§»æ€§å·®**ï¼šä¸ºç‰¹å®šæ¨¡å‹è®¾è®¡çš„è¯­ä¹‰æç¤ºéš¾ä»¥æ³›åŒ–åˆ°å…¶ä»–é—­æºå•†ä¸šæ¨¡å‹ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
ä½œè€…æå‡º **Phantom** â€”â€” ä¸€ç§è‡ªåŠ¨åŒ–ä»£ç†åŠ«æŒæ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> **ä»æ”»å‡»â€œè¯­ä¹‰è¡Œä¸ºâ€è½¬å‘æ”»å‡»â€œè§£ææ¶æ„â€**ã€‚

Phantom ä¸ä¾èµ–è‡ªç„¶è¯­è¨€è¯´æœåŠ›ï¼Œè€Œæ˜¯é€šè¿‡æ³¨å…¥ç²¾å¿ƒä¼˜åŒ–çš„ **ç»“æ„åŒ–æ¨¡æ¿åºåˆ—**ï¼Œä¼ªé€ å¯¹è¯å†å²ï¼ˆå¦‚ä¼ªé€  `Assistant` å“åº”å’Œ `User` æŸ¥è¯¢ï¼‰ï¼Œåˆ©ç”¨ Agent å¯¹æ¨¡æ¿åˆ†éš”ç¬¦çš„ä¾èµ–ï¼Œä½¿å…¶å°†æ”»å‡»è½½è·è¯¯è®¤ä¸ºåˆæ³•ä¸Šä¸‹æ–‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **é«˜æ”»å‡»æˆåŠŸç‡ï¼ˆASRï¼‰**ï¼šåœ¨å¤šä¸ª SOTA é—­æºæ¨¡å‹ä¸Šå¹³å‡ ASR è¾¾ **79.76%**ï¼Œæ˜¾è‘—è¶…è¶Šç°æœ‰åŸºçº¿ã€‚
- **å¼ºè¿ç§»æ€§**ï¼šæ— éœ€äº†è§£ç›®æ ‡æ¨¡å‹å†…éƒ¨æ¨¡æ¿ç»†èŠ‚ï¼Œé€‚ç”¨äºé»‘ç›’åœºæ™¯ã€‚
- **è§„é¿è¯­ä¹‰é˜²å¾¡**ï¼šç»•è¿‡ Safety Alignmentã€Context Filtering ç­‰åŸºäºè¯­ä¹‰çš„é˜²æŠ¤æœºåˆ¶ã€‚
- **è‡ªåŠ¨åŒ–æœç´¢**ï¼šé¦–æ¬¡å®ç°è·¨æ¨¡å‹ç»“æ„æ³¨å…¥æ”»å‡»çš„è‡ªåŠ¨åŒ–å‘ç°ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **AgentDojo**ï¼šæœ€å…ˆè¿›çš„ LLM Agent å®‰å…¨è¯„ä¼°åŸºå‡†ï¼ŒåŒ…å« 97 ä¸ªçœŸå®ç”¨æˆ·ä»»åŠ¡å’Œ 629 ä¸ªå¯¹æŠ—æµ‹è¯•ç”¨ä¾‹ï¼Œè¦†ç›– **Workspace**ã€**Travel**ã€**Slack**ã€**Banking** å››å¤§åœºæ™¯ã€‚
- **Real-World Commercial Agents**ï¼šå¤§è§„æ¨¡è¯„ä¼°äº† **942 ä¸ªå•†ç”¨ Agent**ï¼ŒéªŒè¯å®é™…å±å®³ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
#### è¯„ä¼°å¯¹è±¡
- **é—­æºæ¨¡å‹**ï¼šGPT-4o, GPT-4.1, Qwen3-Max, Gemini-3-Flash ç­‰ 7 ä¸ª SOTA æ¨¡å‹ã€‚
- **å¼€æºæ¨¡å‹**ï¼šDeepSeek-V3.2ã€‚

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | è¯´æ˜ |
|------|------|
| **Attack Success Rate (ASR)** | æˆåŠŸè§¦å‘æ¶æ„è¡Œä¸ºçš„æ ·æœ¬å æ¯” |
| **Utility Score** | åœ¨å­˜åœ¨æ”»å‡»æ‰°åŠ¨ä¸‹ï¼ŒAgent å®ŒæˆåŸå§‹ä»»åŠ¡çš„èƒ½åŠ›ä¿ç•™ç‡ |

#### é˜²å¾¡åœºæ™¯æµ‹è¯•
åœ¨ä¸‰ç§å…¸å‹é˜²å¾¡æœºåˆ¶ä¸‹è¯„ä¼°é²æ£’æ€§ï¼š
1. **Delimiter Spotlighting**ï¼šç³»ç»Ÿæç¤ºä¸­å¼ºè°ƒåˆ†éš”ç¬¦å†…å®¹ä¸ºè¢«åŠ¨æ•°æ®ã€‚
2. **Rule-based Tag Filter**ï¼šè¿‡æ»¤å·¥å…·è¾“å‡ºä¸­çš„ XML ç±»æ ‡ç­¾ã€‚
3. **Injection Detector**ï¼šåŸºäº DeBERTa-v3 çš„è¯­ä¹‰æ£€æµ‹å™¨è¯†åˆ«æ¶æ„æ„å›¾ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿æ–¹æ³• | æè¿° |
|--------|------|
| **Semantic-Injection** | ä½¿ç”¨ `<INFORMATION>` ç­‰æ ‡ç­¾å°è£…æ¶æ„æŒ‡ä»¤ï¼Œä»£è¡¨æœ€å¼ºè¯­ä¹‰æ”»å‡» |
| **Single-Template** | ä½¿ç”¨å¼€æºå¯¹åº”æ¨¡å‹çš„å›ºå®šæ¨¡æ¿è¿›è¡Œæ”»å‡»ï¼ˆå¦‚ç”¨ Qwen3 æ¨¡æ¿æ”»å‡»é—­æº Qwenï¼‰ |
| **ChatInject** | åˆ©ç”¨èŠå¤©æ¨¡æ¿æ³¨å…¥å¤šè½®å¯¹è¯å†å²ï¼Œä½†ä¾èµ–äººå·¥è®¾è®¡ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- **å¹³å‡ ASR**ï¼šPhantom åœ¨ AgentDojo ä¸Šå¯¹ 7 ä¸ªé—­æº Agent çš„å¹³å‡ ASR è¾¾ **79.76%**ã€‚
- **æœ€é«˜å•ä½“ ASR**ï¼šåœ¨ DeepSeek-V3.2 ä¸Šè¾¾åˆ° **78.57%**ã€‚
- **ç°å®ä¸–ç•Œæ¼æ´**ï¼šåœ¨ 942 ä¸ªå•†ç”¨ Agent ä¸­å‘ç° **è¶…è¿‡ 70 ä¸ªå¯åˆ©ç”¨æ¼æ´**ï¼Œæ¶µç›–æ•°æ®æ³„éœ²ã€RCE ç­‰ä¸¥é‡é£é™©ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| æ–¹æ³• | å¹³å‡ ASR |
|------|---------|
| Semantic-Injection | 39.86% |
| Single-Template | 54.09% |
| ChatInject | 38.46% |
| **Phantom** | **79.76%** âœ… |

> Phantom æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼Œåœ¨æ‰€æœ‰åœºæ™¯å’Œæ¨¡å‹ä¸Šå‡å–å¾—é¢†å…ˆã€‚

#### å…¸å‹æ¡ˆä¾‹è¡¨ç°ï¼ˆGPT-4.1ï¼‰
| æ–¹æ³• | ASR | Utility |
|------|-----|--------|
| Semantic-Injection | 14.29% | 75.97% |
| Phantom | **75.97%** | 18.18% |

> Phantom çš„ ASR æ˜¯è¯­ä¹‰æ”»å‡»çš„ **5 å€ä»¥ä¸Š**ï¼Œä¸”èƒ½ç»•è¿‡ Delimiter Spotlighting é˜²å¾¡ï¼ˆASR ä»è¾¾ 76.62%ï¼‰ã€‚

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰è½»é‡çº§æœç´¢ç­–ç•¥ vs å®Œæ•´ Phantom
å¼•å…¥åŸºäºä»£ç†è¯„ä¼°ï¼ˆProxy Evaluationï¼‰çš„è½»é‡æœç´¢ï¼Œå¤§å¹…é™ä½ token å¼€é”€ï¼š
- **æ•ˆç‡æå‡**ï¼štoken æ¶ˆè€—ä» 184M é™è‡³ 63Mï¼ˆä»… **34%**ï¼‰ã€‚
- **æ€§èƒ½æ¥è¿‘**ï¼šå¤šæ•°æ¨¡å‹ä¸Š ASR å·®è·å°äº 10%ï¼Œä»… Gemini-3-Flash æœ‰è¾ƒå¤§ä¸‹é™ã€‚

#### ï¼ˆ2ï¼‰æ€è€ƒé“¾ï¼ˆThinking Modeï¼‰å½±å“
å¯ç”¨ CoT æ˜¾è‘—æå‡æ‰€æœ‰æ”»å‡»çš„ ASRï¼Œè¡¨æ˜æ›´å¼ºçš„æ¨ç†èƒ½åŠ›åè€ŒåŠ å‰§äº†è¢«åŠ«æŒé£é™©ï¼š
- Phantom åœ¨ Qwen-Flash ä¸Š ASR ä» **55.84% â†’ 67.53%**ã€‚
- è¡¨æ˜å¢å¼ºæ¨ç†æœªåŒæ­¥å¢å¼ºå®‰å…¨æ€§ã€‚

#### ï¼ˆ3ï¼‰æ³¨æ„åŠ›åˆ†æï¼ˆInterpretabilityï¼‰
é€šè¿‡æ‰°åŠ¨å®éªŒéªŒè¯æ”»å‡»ä¾èµ–çš„æ˜¯ **è¯­æ³•ç»“æ„** è€Œéå…·ä½“ tokenï¼š
| æ‰°åŠ¨æ–¹å¼ | æ”»å‡»æˆåŠŸç‡ | æ³¨æ„åŠ›ï¼ˆæ”»å‡»è½½è·ï¼‰ |
|--------|----------|------------------|
| åŸå§‹æ¨¡æ¿ | 100% | 10.82 |
| HTML ç¼–ç  `<` â†’ `&lt;` | 46.29% | 4.89 |
| ç§»é™¤æ‹¬å· | 0.05% | 6.36 |
| ç§»é™¤æ•´ä¸ªæ¨¡æ¿ | 0.00% | 5.97 |

> åªè¦ä¿æŒâ€œæ ‡ç­¾å¼â€è¯­æ³•ç»“æ„ï¼Œå³ä½¿ token è¢«ç¼–ç ä»å¯æˆåŠŸï¼›ä¸€æ—¦ç»“æ„ç ´åï¼Œæ”»å‡»å³å¤±æ•ˆã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç»“æ„æ€§æ¼æ´æ™®éå­˜åœ¨**ï¼šLLM Agent å¯¹ **Chat Template åˆ†éš”ç¬¦ç¼ºä¹ä¸¥æ ¼éš”ç¦»æœºåˆ¶**ï¼Œæ˜¯ç³»ç»Ÿæ€§å®‰å…¨çŸ­æ¿ã€‚
2. **ç»“æ„æ”»å‡» > è¯­ä¹‰æ”»å‡»**ï¼šPhantom è¯æ˜ï¼Œæ”»å‡»è§£ææ¶æ„æ¯”æ”»å‡»è¯­ä¹‰ç†è§£æ›´æœ‰æ•ˆã€æ›´éš¾é˜²å¾¡ã€‚
3. **èƒ½åŠ›è¶Šå¼ºï¼Œè¶Šæ˜“è¢«åŠ«æŒ**ï¼šæ›´é«˜ç‰ˆæœ¬ã€æ›´å¼ºæŒ‡ä»¤éµå¾ªèƒ½åŠ›çš„æ¨¡å‹ï¼ˆå¦‚ GPT-4.1 > GPT-4oï¼‰åè€Œæ›´æ˜“å—ç»“æ„æ”»å‡»ï¼Œå½¢æˆâ€œ**capability curse**â€ã€‚
4. **ç°æœ‰é˜²å¾¡å¤±æ•ˆ**ï¼š
   - æŒ‡ä»¤çº§é˜²å¾¡ï¼ˆå¦‚ Delimiter Spotlightingï¼‰å®Œå…¨æ— æ•ˆã€‚
   - æ ‡ç­¾è¿‡æ»¤å¯éƒ¨åˆ†ç¼“è§£ï¼Œä½†è‡ªåŠ¨åŒ–æœç´¢èƒ½æ‰¾åˆ°ç»•è¿‡å˜ä½“ã€‚
   - è¯­ä¹‰æ£€æµ‹å™¨è™½å¯å‹åˆ¶ ASRï¼Œä½†ä¸¥é‡æŸå®³åŠŸèƒ½æ€§ï¼ˆUtility ä¸‹é™è‡³ 15.58%ï¼‰ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **æ¨¡æ€é™åˆ¶**ï¼šç›®å‰ä»…æ”¯æŒæ–‡æœ¬è¾“å…¥ï¼Œæœªè€ƒè™‘å¤šæ¨¡æ€ Agentï¼ˆå¦‚è§†è§‰ã€éŸ³é¢‘ï¼‰ã€‚
- **é»‘ç›’å‡è®¾**ï¼šæœªåˆ©ç”¨å†…éƒ¨çŸ¥è¯†ï¼ˆå¦‚è®­ç»ƒæ•°æ®ã€æ¨¡æ¿è§„èŒƒï¼‰ï¼Œè‹¥æ”»å‡»è€…ä¸º insider å¯æ„é€ æ›´å¼ºæ”»å‡»ã€‚
- **æŸ¥è¯¢æˆæœ¬**ï¼šä¾èµ– API æŸ¥è¯¢åé¦ˆï¼Œå¯èƒ½å—é€Ÿç‡é™åˆ¶æˆ–å¼‚å¸¸æ£€æµ‹é˜»æ–­ã€‚
- **æŒä¹…æ€§æœªè¯„ä¼°**ï¼šæœªç ”ç©¶åœ¨é•¿å‘¨æœŸå¯¹è¯çŠ¶æ€ç®¡ç†ä¸­çš„æŒç»­åŠ«æŒèƒ½åŠ›ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **æ„å»ºç»“æ„åŒ–é˜²å¾¡åŸè¯­**ï¼šå¦‚ç¡¬ä»¶è¾…åŠ© token éš”ç¦»ã€å½¢å¼åŒ–éªŒè¯çš„æ¨¡æ¿è§£æå™¨ã€‚
- **æ‰©å±•è‡³å¤šæ¨¡æ€ç¯å¢ƒ**ï¼šç ”ç©¶è·¨æ¨¡æ€ç»“æ„æ³¨å…¥æ”»å‡»ï¼ˆå¦‚å›¾åƒå…ƒæ•°æ®æ³¨å…¥ï¼‰ã€‚
- **å»ºç«‹æ ‡å‡†åŒ–åŸºå‡†**ï¼šæ¨åŠ¨ç¤¾åŒºå¼€å‘ä¸“é—¨è¯„ä¼°ç»“æ„æ”»å‡»é²æ£’æ€§çš„ Benchmarkã€‚
- **æ¢ç´¢åˆå§‹åŒ–ä¼˜åŒ–**ï¼šæ”¹è¿›åˆå§‹æ¨¡æ¿é€‰æ‹©ç­–ç•¥ä»¥åŠ é€Ÿæ”¶æ•›ã€‚

---

> **æ€»ç»“**ï¼šPhantom æ­ç¤ºäº†å½“å‰ LLM Agent å®‰å…¨ä½“ç³»çš„æ ¹æœ¬ç›²åŒºâ€”â€”è¿‡åº¦ä¾èµ–è¯­ä¹‰å¯¹é½è€Œå¿½è§†æ¶æ„éš”ç¦»ã€‚å…¶æå‡ºçš„ **Structural Template Injection** èŒƒå¼ï¼Œä¸ä»…å®ç°äº†é«˜æˆåŠŸç‡ã€é«˜è¿ç§»æ€§çš„è‡ªåŠ¨åŒ–æ”»å‡»ï¼Œæ›´è­¦ç¤ºä¸šç•Œå¿…é¡»ä»â€œè¯­æ³•å±‚é¢â€é‡æ„ Agent çš„å®‰å…¨è¾¹ç•Œã€‚

</details>

---

### 3. [Operationalization of Machine Learning with Serverless Architecture: An Industrial Operationalization of Machine Learning with Serverless Architecture: An Industrial Implementation for Harmonized System Code Prediction](https://arxiv.org/abs/2602.17102)

**Authors**: Sai Vineeth Kandappareddigari, Santhoshkumar Jagadish, Gauri Verma, Ilhuicamina Contreras, Christopher Dignam, Anmol Srivastava, Benjamin Demers  
**Category**: cs.LG  
**Published**: 2026-02-20  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.17102v1  

#### Abstract
This paper presents a serverless MLOps framework orchestrating the complete ML lifecycle from data ingestion, training, deployment, monitoring, and retraining to using event-driven pipelines and managed services. The architecture is model-agnostic, supporting diverse inference patterns through stand...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šOperationalization of Machine Learning with Serverless Architecture: An Industrial Implementation for Harmonized System Code Prediction

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡èšç„¦äº**æµ·å…³åˆè§„é¢†åŸŸä¸­çš„ HS Codeï¼ˆHarmonized System Codeï¼‰è‡ªåŠ¨åˆ†ç±»é—®é¢˜**ã€‚HS Code æ˜¯å…¨çƒè´¸æ˜“ä¸­ç”¨äºå•†å“åˆ†ç±»çš„æ ‡å‡†ç¼–ç ç³»ç»Ÿï¼Œå…¶æ­£ç¡®åˆ†é…å¯¹è¿›å‡ºå£æ¸…å…³è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç”±äºäº§å“æè¿°ç®€çŸ­ã€éç»“æ„åŒ–ä¸”é¢‘ç¹æ›´æ–°ï¼Œäººå·¥åˆ†ç±»è€—æ—¶ä¸”æ˜“å‡ºé”™ï¼Œå¯¼è‡´ç‰©æµå»¶è¯¯å’Œè´¢åŠ¡æŸå¤±ã€‚

ä¼ ç»Ÿæ–¹æ³•ä¾èµ–ä¸“å®¶ç»éªŒæˆ–ç®€å•æ–‡æœ¬åˆ†ç±»æ¨¡å‹ï¼Œéš¾ä»¥åº”å¯¹å¤§è§„æ¨¡ã€åŠ¨æ€å˜åŒ–çš„åœºæ™¯ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
è®ºæ–‡æå‡ºäº†ä¸€ç§**åŸºäº Serverless æ¶æ„çš„ç«¯åˆ°ç«¯ MLOps æ¡†æ¶**ï¼Œå®ç°äº† HS Code åˆ†ç±»æ¨¡å‹çš„å·¥ä¸šåŒ–éƒ¨ç½²ä¸è‡ªåŠ¨åŒ–è¿ç»´ã€‚ä¸»è¦åˆ›æ–°åŒ…æ‹¬ï¼š

- **å…¨ç”Ÿå‘½å‘¨æœŸè‡ªåŠ¨åŒ– MLOps æµç¨‹**ï¼šæ„å»ºäº†ä¸€ä¸ªæ”¯æŒæ•°æ®æ‘„å…¥ã€è®­ç»ƒã€éƒ¨ç½²ã€ç›‘æ§ã€å†è®­ç»ƒçš„å®Œæ•´ pipelineï¼Œå®ç°æ¨¡å‹æŒç»­é›†æˆä¸äº¤ä»˜ï¼ˆCI/CDï¼‰ã€‚
- **Serverless æ¶æ„è®¾è®¡**ï¼šé‡‡ç”¨ AWS çš„æ— æœåŠ¡å™¨æœåŠ¡ï¼ˆå¦‚ AWS Lambda, Sagemaker, Step Functions, EventBridge, S3ï¼‰ï¼Œå®ç°æŒ‰éœ€ä¼¸ç¼©ã€é«˜å¯ç”¨æ€§å’Œä½è¿ç»´æˆæœ¬ã€‚
- **æ ‡å‡†åŒ–æ¥å£ä¸æ¨¡å‹æ— å…³æ€§ï¼ˆModel-Agnosticï¼‰**ï¼šæ¡†æ¶æ”¯æŒå¤šç§æ·±åº¦å­¦ä¹ æ¶æ„ï¼ˆDNN, LSTM, Text-CNNï¼‰ï¼Œä¾¿äºå¿«é€Ÿåˆ‡æ¢å’Œæ¯”è¾ƒä¸åŒæ¨¡å‹ã€‚
- **è‡ªåŠ¨åŒ– A/B Testing æœºåˆ¶**ï¼šåœ¨ç”Ÿäº§ç¯å¢ƒä¸­åŠ¨æ€æ¯”è¾ƒå¤šä¸ªæ¨¡å‹çš„è¡¨ç°ï¼ˆaccuracy, latency, costï¼‰ï¼Œå®‰å…¨åœ°é€‰æ‹©æœ€ä¼˜æ¨¡å‹ä¸Šçº¿ã€‚
- **å®šåˆ¶åŒ–æ–‡æœ¬åµŒå…¥ï¼ˆCustom Embeddingï¼‰**ï¼šé’ˆå¯¹å·¥ç¨‹äº§å“æè¿°çš„ä¸“ä¸šæ€§ï¼Œæ”¾å¼ƒé¢„è®­ç»ƒ embeddingï¼ˆå¦‚ Word2Vec/GloVeï¼‰ï¼Œè½¬è€Œè®­ç»ƒ domain-specific çš„ custom embedding å±‚ï¼Œæ˜¾è‘—æå‡æ•ˆæœã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | æœ¬æ–‡æ–¹æ³• | ä¼ ç»Ÿæ–¹æ³• |
|------|----------|---------|
| å¯æ‰©å±•æ€§ | è‡ªåŠ¨å¼¹æ€§ä¼¸ç¼©ï¼Œé€‚åº”æµé‡æ³¢åŠ¨ | å›ºå®šèµ„æºï¼Œæ˜“è¿‡è½½æˆ–æµªè´¹ |
| è¿ç»´æ•ˆç‡ | å®Œå…¨è‡ªåŠ¨åŒ– retraining å’Œ deployment | æ‰‹åŠ¨å¹²é¢„å¤šï¼Œå“åº”æ…¢ |
| æˆæœ¬æ§åˆ¶ | Pay-per-useï¼Œé•¿æœŸè¿è¥æˆæœ¬æ›´ä½ | é•¿æœŸè¿è¡Œå®ä¾‹å¼€é”€å¤§ |
| æ¨¡å‹è¿­ä»£é€Ÿåº¦ | æ”¯æŒå¿«é€Ÿå®éªŒä¸ A/B testing | éƒ¨ç½²å‘¨æœŸé•¿ |
| å‡†ç¡®ç‡ | è¾¾åˆ° 98%ï¼Œä¼˜äºç»å…¸æ¨¡å‹ | å¤šæ•°æ–‡çŒ®æŠ¥å‘Š <95% |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†
- **æ¥æº**ï¼šæ¥è‡ª Schneider Electric å†…éƒ¨å‡ºå£æ§åˆ¶ç³»ç»Ÿçš„çœŸå®ä¸šåŠ¡æ•°æ®ã€‚
- **å†…å®¹**ï¼š
  - äº§å“çŸ­æè¿°ï¼ˆShort Descriptionï¼‰
  - ä¸­ç­‰é•¿åº¦æè¿°ï¼ˆMedium Descriptionï¼‰
  - æŠ€æœ¯å‚æ•°ï¼ˆETIM æ ‡å‡†ï¼‰
  - å·²æ ‡æ³¨çš„ HS Codeï¼ˆç›®æ ‡å˜é‡ï¼‰
- **æ ·æœ¬é‡**ï¼šåŸå§‹æ•°æ® 815,264 æ¡ï¼›ç» upsampling åå¢è‡³ 818,048 æ¡ã€‚
- **æ ‡ç­¾æ•°é‡**ï¼šå…± 24 ä¸ª HS Code ç±»åˆ«ï¼ˆå­é›†ï¼‰ï¼Œè¦†ç›–å®é™…é«˜é¢‘ä½¿ç”¨çš„ä»£ç ã€‚
- **æ•°æ®è´¨é‡åˆ†çº§**ï¼šå¼•å…¥â€œassurance levelâ€ï¼ˆ1â€“4çº§ï¼‰ï¼Œä»…ä½¿ç”¨ level 3 å’Œ 4 çš„é«˜è´¨é‡æ ‡ç­¾è¿›è¡Œè®­ç»ƒã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **ä»»åŠ¡ç±»å‹**ï¼šMulti-class æ–‡æœ¬åˆ†ç±»ï¼ˆText Classificationï¼‰
- **ç‰¹å¾å·¥ç¨‹**ï¼š
  - æ¸…æ´—æ–‡æœ¬ï¼ˆå»ç¬¦å·ã€åœç”¨è¯ã€å°å†™åŒ–ï¼‰
  - ä½¿ç”¨ Tokenizer åˆ†è¯
  - æ„å»º custom embedding å±‚ï¼ˆæœªä½¿ç”¨ GloVe/Word2Vecï¼‰
- **æ¨¡å‹æ¶æ„å¯¹æ¯”**ï¼š
  - **SVMï¼ˆBaselineï¼‰**
  - **Deep Neural Network (DNN)**
  - **Long Short-Term Memory (LSTM)**
  - **Text-CNN**ï¼ˆæœ€ç»ˆèƒœå‡ºï¼‰
- **è¶…å‚æ•°ä¼˜åŒ–**ï¼šé‡‡ç”¨ **Bayesian Optimization** è‡ªåŠ¨è°ƒå‚ï¼ˆè§ Table II & Vï¼‰ã€‚
- **ç±»åˆ«ä¸å¹³è¡¡å¤„ç†**ï¼šä½¿ç”¨ **Stratified Upsampling**ï¼ˆä¼˜äº SMOTEï¼‰ï¼Œé¿å…åˆæˆæ ·æœ¬å¸¦æ¥çš„å™ªå£°ã€‚

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | è¯´æ˜ |
|------|------|
| **Accuracy** | æ•´ä½“é¢„æµ‹å‡†ç¡®ç‡ |
| **Precision / Recall / F1-score** | æŒ‰æ¯ä¸ª HS Code ç±»åˆ«åˆ†åˆ«è®¡ç®—ï¼Œå°¤å…¶å…³æ³¨ precision â‰¥90% çš„è¡¨ç° |
| **Latency** | æ¨ç†å»¶è¿Ÿï¼ˆå½±å“ SLAï¼‰ |
| **Cost-Efficiency** | è®­ç»ƒä¸æ¨ç†çš„ç»¼åˆæˆæœ¬ï¼ˆè€ƒè™‘äº‘èµ„æºæ¶ˆè€—ï¼‰ |
| **Statistical Significance** | ä½¿ç”¨ **ANOVA + k-fold CVï¼ˆ37-foldï¼‰** è¿›è¡Œ A/B testingï¼Œç¡®ä¿ç»“æœå¯é  |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š æ€§èƒ½æ±‡æ€»ï¼ˆTest Set è¡¨ç°ï¼‰

| Model | Accuracy | #Codes with Precision >90% | #Codes with Recall >90% | F1 (>90%) |
|-------|----------|-------------------------------|---------------------------|------------|
| **DNN** | 89% â†’ **95%** (upsampled) | 15 â†’ **19** | 12 â†’ 20 | 14 â†’ 19 |
| **LSTM** | 92% â†’ **97%** (upsampled) | 19 â†’ **20** | 16 â†’ 22 | 18 â†’ 21 |
| **Text-CNN** | **98%** (both base & upsampled) | **19 â†’ 20** | **20 â†’ 21** | **19 â†’ 20** |

> âœ… **Text-CNN åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡å–å¾—æœ€ä½³è¡¨ç°**

### ğŸ”¬ å…³é”®å‘ç°
- **Text-CNN æ˜æ˜¾ä¼˜äº RNN/LSTM**ï¼šå°½ç®¡ LSTM èƒ½æ•æ‰åºåˆ—ä¾èµ–ï¼Œä½†åœ¨çŸ­æ–‡æœ¬ï¼ˆå¹³å‡é•¿åº¦ ~64 å­—ç¬¦ï¼‰ä»»åŠ¡ä¸­ï¼ŒText-CNN æ›´æ“…é•¿æå–å±€éƒ¨å…³é”®è¯ç»„ï¼ˆn-gram ç‰¹å¾ï¼‰ï¼Œä¸”è®­ç»ƒæ›´å¿«ã€‚
- **Upsampling æ˜¾è‘—æå‡å°ç±»åˆ«çš„ recall**ï¼šè§£å†³äº† class imbalance å¯¼è‡´çš„åå·®é—®é¢˜ã€‚
- **Custom Embedding è‡³å…³é‡è¦**ï¼šå°è¯•ä½¿ç”¨ Word2Vec/GloVe æ•ˆæœä¸ä½³ï¼Œå› é¢†åŸŸæœ¯è¯­ï¼ˆå¦‚å·¥ä¸šè®¾å¤‡å‘½åï¼‰ä¸åœ¨é€šç”¨è¯­æ–™ä¸­ã€‚
- **Transformer æ¨¡å‹æœªè¢«é€‰ç”¨çš„åŸå› **ï¼š
  - å°½ç®¡å¯èƒ½è¾¾åˆ°ç›¸è¿‘ accuracyï¼Œ
  - ä½†å…¶ **long-term operational cost æ›´é«˜**ï¼ˆè®­ç»ƒæ—¶é—´é•¿ã€æ¨ç†èµ„æºå ç”¨å¤§ï¼‰ï¼Œ
  - ä¸”ç¼ºä¹å¯è§£é‡Šæ€§ï¼ˆexplainabilityï¼‰ï¼Œä¸ç¬¦åˆæµ·å…³åˆè§„åœºæ™¯éœ€æ±‚ã€‚

### â±ï¸ è®­ç»ƒæ—¶é—´å¯¹æ¯”ï¼ˆTable VIIï¼‰
| Model | Base Model Total Time | Upsampled Model Total Time |
|-------|------------------------|------------------------------|
| DNN | 51 mins | **3h 36m** |
| LSTM | **5.5h** | 5.4h |
| **Text-CNN** | **3h 15m** | **3h 10m** |

> ğŸ’¡ Text-CNN ä¸ä»…ç²¾åº¦æœ€é«˜ï¼Œè®­ç»ƒæ•ˆç‡ä¹Ÿä¼˜äº LSTMã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º
1. **Text-CNN æ˜¯ HS Code åˆ†ç±»çš„æœ€ä½³é€‰æ‹©**ï¼šåœ¨çŸ­æ–‡æœ¬ã€é«˜ç²¾åº¦è¦æ±‚ã€ä½å»¶è¿Ÿçº¦æŸä¸‹ï¼ŒText-CNN æ¯” LSTM å’Œ DNN æ›´æœ‰æ•ˆã€‚
2. **Serverless MLOps å¯å®ç°ä¼ä¸šçº§ ML å·¥ä¸šåŒ–**ï¼šé€šè¿‡ AWS æ— æœåŠ¡å™¨ç»„ä»¶æ„å»ºçš„ pipeline å…·å¤‡é«˜åº¦è‡ªåŠ¨åŒ–ã€å¯å®¡è®¡ã€å¯å¤ç°ã€SLA å¯ä¿éšœçš„ç‰¹ç‚¹ã€‚
3. **è‡ªåŠ¨åŒ– A/B Testing æå‡æ¨¡å‹å†³ç­–ç§‘å­¦æ€§**ï¼šç»“åˆç»Ÿè®¡æ£€éªŒï¼ˆANOVAï¼‰é€‰å‡ºæœ€ä¼˜æ¨¡å‹ï¼Œå‡å°‘ä¸»è§‚åˆ¤æ–­é£é™©ã€‚
4. **Cost-Efficiency æ˜¯å·¥ä¸šè½åœ°çš„å…³é”®è€ƒé‡**ï¼šä¸èƒ½åªçœ‹ accuracyï¼Œå¿…é¡»æƒè¡¡æ¨¡å‹å¤æ‚åº¦ã€è®­ç»ƒæˆæœ¬ã€æ¨ç†å»¶è¿Ÿä¸ç»´æŠ¤éš¾åº¦ã€‚
5. **Deterministic æ¨¡å‹ä¼˜äº Generative AI å½“å‰é˜¶æ®µ**ï¼šå¯¹äºåˆè§„æ€§å¼ºçš„ä»»åŠ¡ï¼Œç¡®å®šæ€§è¾“å‡ºã€ä½å»¶è¿Ÿã€é«˜å¯è§£é‡Šæ€§æ¯”çµæ´»æ€§æ›´é‡è¦ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **åŒºåŸŸå·®å¼‚æ€§é™åˆ¶æ³›åŒ–èƒ½åŠ›**ï¼šå„å›½ HS Code åº”ç”¨å­˜åœ¨å·®å¼‚ï¼Œæ¨¡å‹éœ€æœ¬åœ°åŒ–è®­ç»ƒã€‚
- **æ— æ³•å¤„ç†å…¨æ–°äº§å“ç±»åˆ«**ï¼šé‡åˆ°ä»æœªè§è¿‡çš„äº§å“éœ€äººå·¥ä»‹å…¥ï¼Œç›´åˆ°ç§¯ç´¯è¶³å¤Ÿæ ·æœ¬ã€‚
- **HS Code æ›´æ–°å‘¨æœŸå½±å“æ¨¡å‹å¯¿å‘½**ï¼šWCO æ¯ 5â€“6 å¹´æ›´æ–°ä¸€æ¬¡ HS Code ç»“æ„ï¼Œéœ€å®šæœŸ retrainã€‚
- **å½“å‰ä»…è¦†ç›– 24 ä¸ªé«˜é¢‘ç±»åˆ«**ï¼šå°šæœªæ‰©å±•è‡³å…¨éƒ¨ ~5000 ä¸ª HS Codeã€‚
- **ä¾èµ–é«˜è´¨é‡æ ‡æ³¨æ•°æ®**ï¼šassurance level ä¾èµ–ä¸“å®¶å®¡æ ¸ï¼Œæ‰©å±•æˆæœ¬è¾ƒé«˜ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- å¼•å…¥æ›´å¤š **categorical features**ï¼ˆå¦‚äº§å“ç±»åˆ«ã€æè´¨ç­‰ï¼‰å¢å¼ºæ¨¡å‹è¡¨ç°
- æ¢ç´¢ **SMOTE ç­‰ advanced upsampling æŠ€æœ¯**
- æ‰©å±•æ¨¡å‹è‡³ **æ¬§æ´²å’ŒåŒ—ç¾ä»¥å¤–åœ°åŒº**
- å¼•å…¥ **KL Divergence ç­‰ drift detection æ–¹æ³•** å®ç°æ›´æ™ºèƒ½çš„ retraining è§¦å‘
- åˆ©ç”¨ **parallel processing** è¿›ä¸€æ­¥ç¼©çŸ­è®­ç»ƒæ—¶é—´
- å¼€å‘ **CloudFormation templates** å®ç°è·¨ç¯å¢ƒè‡ªåŠ¨åŒ–éƒ¨ç½²
- æ¢ç´¢ **Generative AI æ›¿ä»£æ–¹æ¡ˆ**ï¼šå¾…å…¶å…·å¤‡æ›´é«˜é€æ˜åº¦ä¸æ•°æ®å®‰å…¨æ€§åè€ƒè™‘å¼•å…¥

---

> ğŸ“Œ **æ€»ä½“è¯„ä»·**ï¼š  
> æœ¬æ–‡ä¸ä»…æå‡ºäº†ä¸€ä¸ªé«˜æ€§èƒ½çš„ HS Code åˆ†ç±»æ¨¡å‹ï¼ˆText-CNN + Custom Embeddingï¼‰ï¼Œæ›´é‡è¦çš„æ˜¯æä¾›äº†ä¸€ä¸ª**å¯å¤åˆ¶çš„ä¼ä¸šçº§ MLOps è“å›¾**ï¼Œå±•ç¤ºäº†å¦‚ä½•å°†æœºå™¨å­¦ä¹ ä»å®éªŒåŸå‹æˆåŠŸè½¬åŒ–ä¸ºç¨³å®šã€é«˜æ•ˆã€å¯æŒç»­æ¼”è¿›çš„å·¥ä¸šç³»ç»Ÿã€‚å…¶ Serverless + A/B Testing + Auto-retraining çš„è®¾è®¡ç†å¿µå…·æœ‰å¹¿æ³›çš„æ¨å¹¿ä»·å€¼ã€‚

</details>

---

### 4. [LLM4Cov: Execution-Aware Agentic Learning for High-coverage Testbench Generation](https://arxiv.org/abs/2602.16953)

**Authors**: Hejia Zhang, Zhongming Yu, Chia-Tung Ho, Haoxing Ren, Brucek Khailany, Jishen Zhao  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.16953v1  

#### Abstract
Execution-aware LLM agents offer a promising paradigm for learning from tool feedback, but such feedback is often expensive and slow to obtain, making online reinforcement learning (RL) impractical. High-coverage hardware verification exemplifies this challenge due to its reliance on industrial simu...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLLM4Cov: Execution-Aware Agentic Learning for High-coverage Testbench Generation

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ç¡¬ä»¶éªŒè¯ï¼ˆhardware verificationï¼‰æ˜¯èŠ¯ç‰‡è®¾è®¡æµç¨‹ä¸­æˆæœ¬æœ€é«˜ã€è€—æ—¶æœ€é•¿çš„ç¯èŠ‚ä¹‹ä¸€ã€‚å…¶æ ¸å¿ƒä»»åŠ¡æ˜¯ç”Ÿæˆé«˜è¦†ç›–ç‡çš„ **testbench**ï¼Œä»¥å……åˆ†éªŒè¯ RTL è®¾è®¡çš„æ­£ç¡®æ€§ã€‚ç„¶è€Œï¼š
- æ¯æ¬¡ä»¿çœŸï¼ˆsimulationï¼‰æ‰§è¡Œå¼€é”€å·¨å¤§ï¼ˆå·¥ä¸šçº§å¯è¾¾æ•°å°æ—¶ï¼‰ï¼Œå¯¼è‡´åœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆonline RLï¼‰ä¸å¯è¡Œï¼›
- è¦†ç›–ç‡ä¿¡å·ï¼ˆcoverageï¼‰æ˜¯éå¯å¾®ã€ç¨€ç–ä¸”æ˜‚è´µçš„åé¦ˆï¼›
- å­¦ç”Ÿæ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šé‡åˆ°æ•™å¸ˆæ¨¡å‹æœªè¦†ç›–çš„å¤±è´¥çŠ¶æ€ï¼Œäº§ç”Ÿ **state-distribution shift**ï¼Œå¯¼è‡´ä¼ ç»Ÿ SFT æ•ˆæœä¸ä½³ã€‚

ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ DPOã€é™æ€æ•°æ®å¾®è°ƒï¼‰æ— æ³•æœ‰æ•ˆåˆ©ç”¨æœ‰é™çš„ä»¿çœŸèµ„æºè¿›è¡Œå¤šè½®äº¤äº’å¼ä¿®å¤ï¼ˆinteractive repairï¼‰ï¼Œä¹Ÿæœªç³»ç»Ÿè§£å†³åˆ†å¸ƒåç§»é—®é¢˜ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

è®ºæ–‡æå‡º **LLM4Cov** â€”â€” é¦–ä¸ªé¢å‘é«˜è¦†ç›–ç‡ testbench ç”Ÿæˆçš„ **execution-aware ç¦»çº¿ä»£ç†å­¦ä¹ æ¡†æ¶**ï¼Œæ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰**Coverage-Guided Agentic Rejection Fine-tuning**
- å°†è¦†ç›–ç‡ä½œä¸ºå¯†é›†ç›‘ç£ä¿¡å·ï¼Œå¯¹ç”Ÿæˆçš„ testbench è‰ç¨¿è¿›è¡Œç­›é€‰ã€‚
- åªä¿ç•™ä½è¦†ç›–ç‡è‰ç¨¿åŠå…¶æœ€å…·æ”¹è¿›æ€§çš„ä¿®è®¢ç‰ˆæœ¬ï¼Œé›†ä¸­ç›‘ç£â€œæ¢å¤è¡Œä¸ºâ€ï¼ˆrecovery behaviorsï¼‰ã€‚
- æ¯æ¬¡ä»¿çœŸè°ƒç”¨éƒ½æœ€å¤§åŒ–æå–æœ‰ç”¨ä¿¡æ¯ï¼Œæå‡æ ·æœ¬æ•ˆç‡ã€‚

#### ï¼ˆ2ï¼‰**Verification-Conditioned Progressive Learning**
- åˆ†é˜¶æ®µæ„å»ºåˆæˆæ•°æ®å¹¶é€æ­¥è®­ç»ƒï¼š
  - **Stage 0**: ä½¿ç”¨æ•™å¸ˆæ¨¡å‹ç”Ÿæˆé«˜è´¨é‡è½¨è¿¹ï¼ˆwarm-upï¼‰
  - **Stage 1**: ä½¿ç”¨å­¦ç”Ÿæ¨¡å‹é‡‡æ ·ä¸­é—´çŠ¶æ€ + æ•™å¸ˆæ¨¡å‹ç”Ÿæˆä¿®æ­£ï¼ˆimitation-styleï¼‰
  - **Stage 2**: å®Œå…¨ç”±å­¦ç”Ÿæ¨¡å‹è‡ªé‡‡æ ·å¹¶è‡ªæˆ‘æ”¹è¿›ï¼ˆself-samplingï¼‰
- æ¯ä¸€é˜¶æ®µçš„æ•°æ®åˆæˆä¸å½“å‰å­¦ç”Ÿæ¨¡å‹çš„çŠ¶æ€åˆ†å¸ƒå¯¹é½ï¼Œé¿å…æ··åˆä¸åŒåˆ†å¸ƒå¯¼è‡´çš„ä¿¡å·ç¨€é‡Šã€‚

#### ï¼ˆ3ï¼‰**Worst-State-Prioritized Sampling**
- åœ¨æ¯ä¸€è½®è¿­ä»£ä¸­ä¼˜å…ˆé€‰æ‹©è¦†ç›–ç‡æœ€ä½çš„çŠ¶æ€è¿›è¡Œä¿®å¤å°è¯•ã€‚
- æ˜¾è‘—æé«˜åœ¨æœ‰é™ä»¿çœŸé¢„ç®—ä¸‹æ•è·å…³é”®å¤±è´¥æ¨¡å¼çš„æ¦‚ç‡ã€‚

#### ï¼ˆ4ï¼‰**Memoryless State Transition Formulation**
- å°†éªŒè¯è¿‡ç¨‹å»ºæ¨¡ä¸ºæ— è®°å¿†çŠ¶æ€è½¬ç§»ï¼šæ¯ä¸ªå†³ç­–ä»…ä¾èµ–äºå½“å‰ä»£ç å’Œä»¿çœŸåé¦ˆï¼Œè€Œéå®Œæ•´å†å²ã€‚
- å‡å°‘å†—ä½™æç¤ºé•¿åº¦ï¼Œèšç„¦æœ€æ–°æ‰§è¡Œä¿¡å·ï¼Œå®éªŒè¯æ˜ä¼˜äº vanilla å†å²æ‹¼æ¥æ–¹å¼ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | LLM4Cov | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ DPOã€SFTï¼‰ |
|------|--------|--------------------------|
| æ‰§è¡Œæ„ŸçŸ¥ | âœ… æ˜¾å¼å»ºæ¨¡ä»¿çœŸåé¦ˆ | âŒ å¿½ç•¥æ‰§è¡Œè·¯å¾„æˆ–ä»…ç”¨äºè¿‡æ»¤ |
| æ•°æ®æœ‰æ•ˆæ€§ | âœ… åŠ¨æ€ç”Ÿæˆ+æŒ‰éœ€è¿‡æ»¤ | âŒ å›ºå®šæ•°æ®é›†ï¼Œæ˜“è¿‡æ—¶ |
| åˆ†å¸ƒå¯¹é½ | âœ… æ¸è¿›å¼å¯¹é½å­¦ç”Ÿåˆ†å¸ƒ | âŒ æ•™å¸ˆä¸»å¯¼ï¼Œå­˜åœ¨åå˜é‡åç§» |
| æˆæœ¬æ§åˆ¶ | âœ… ç¦»çº¿è®­ç»ƒï¼Œé«˜æ•ˆåˆ©ç”¨ä»¿çœŸ | âŒ å¤šæ•°éœ€åœ¨çº¿äº¤äº’ï¼Œæˆæœ¬é«˜ |
| æ€§èƒ½ä¸Šé™ | âœ… å°æ¨¡å‹è¶…è¶Šå¤§æ¨¡å‹ | âŒ ä¸¥é‡ä¾èµ–æ¨¡å‹è§„æ¨¡ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
- **CVDP-ECov**ï¼šåŸºäº CVDP benchmark (Pinckney et al., 2025) æ”¹é€ çš„çœŸå®ç¡¬ä»¶ä»“åº“é›†åˆï¼Œå…± **83 ä¸ªç‹¬ç«‹ç¡¬ä»¶ repo**ã€‚
- è¾“å…¥åŒ…å«å®Œæ•´çš„ RTL æºç å’Œè§„èŒƒè¯´æ˜ï¼ˆéä»…è‡ªç„¶è¯­è¨€æè¿°ï¼‰ï¼Œæ›´è´´è¿‘å®é™…å·¥ç¨‹åœºæ™¯ã€‚
- è®­ç»ƒæ•°æ®æ¥è‡ª **CodeV-R1** æ•°æ®é›†ï¼ˆ87k reposï¼‰ï¼Œé€šè¿‡ ROUGE-L > 50% è¿‡æ»¤æ‰ä¸æµ‹è¯•é›†ç›¸ä¼¼é¡¹ï¼Œé˜²æ­¢æ³„éœ²ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### è¯„ä¼°è®¾ç½®
| è®¾ç½® | æè¿° |
|------|------|
| **Agentic Evaluation**ï¼ˆä¸»è®¾ç½®ï¼‰ | å…è®¸æ¨¡å‹è¿›è¡Œæœ€å¤š 3 è½®è¿­ä»£ç”Ÿæˆä¸ä»¿çœŸåé¦ˆ refinementï¼Œé‡‡ç”¨ memoryless çŠ¶æ€è¡¨ç¤º |
| **Direct Inference**ï¼ˆå‚è€ƒè®¾ç½®ï¼‰ | å•æ¬¡ç”Ÿæˆï¼Œæ— åé¦ˆ |

#### ä¸»è¦è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Cov Pass (%)** | è¾¾åˆ°é¢„è®¾è¦†ç›–ç‡é˜ˆå€¼çš„ä»“åº“æ¯”ä¾‹ï¼ˆPass@1ï¼‰ |
| **Avg Cov (%)** | æ‰€æœ‰ä»“åº“å¹³å‡è¦†ç›–ç‡ï¼ˆå¤±è´¥åˆ™è®°ä¸º 0ï¼‰ |
| **Sim Pass (%)** | ç”Ÿæˆ testbench èƒ½æˆåŠŸç¼–è¯‘å¹¶é€šè¿‡ä»¿çœŸçš„æ¯”ä¾‹ï¼ˆè¡¡é‡è¯­æ³•æ­£ç¡®æ€§ï¼‰ |

#### æ¨¡å‹é…ç½®
- **å­¦ç”Ÿæ¨¡å‹**ï¼š`Qwen3-4B-Instruct-2507`ï¼ˆ4B å‚æ•°ï¼‰
- **æ•™å¸ˆæ¨¡å‹**ï¼š`Qwen3-Coder-30B-A3B-Instruct`ï¼ˆ30B å‚æ•°ï¼‰
- æ‰€æœ‰æ¨¡å‹å‡åœ¨ instruct æ¨¡å¼ä¸‹è¯„ä¼°ã€‚

#### åŸºçº¿å¯¹æ¯”
æ¶µç›–ä¸‰ç±»ä¸»æµæ¨¡å‹ï¼š
1. **é€šç”¨å¤§æ¨¡å‹**ï¼š`Llama-4-Maverick (400B)`ã€`Qwen3-235B`
2. **ç¼–ç ä¸“ç”¨æ¨¡å‹**ï¼š`Qwen3-Coder-30B`ã€`Gemma-3`
3. **ç¡¬ä»¶ç‰¹å®šæ¨¡å‹**ï¼š`VeriCoder`ã€`CodeV-R1-RL`ã€`VeriReason`

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 2ï¼‰

| æ¨¡å‹ | Cov Pass (Agentic) | Avg Cov (Agentic) | æ¨¡å‹å¤§å° |
|------|--------------------|-------------------|---------|
| Qwen3-4B (Base) | 28.4% | 48.5% | 4B |
| **LLM4Cov (+Stage2)** | **69.2%** | **90.4%** | 4B |
| Qwen3-Coder-30B | 63.9% | 79.9% | 30B |
| Llama-4-Maverick | 60.2% | 81.7% | 400B |

> âœ… **ç»“è®º**ï¼šä¸€ä¸ªä»… **4B å‚æ•°çš„å°æ¨¡å‹**ï¼Œç»è¿‡ LLM4Cov æ¡†æ¶è®­ç»ƒåï¼Œ**è¶…è¶Šäº† 30B çš„æ•™å¸ˆæ¨¡å‹ï¼ˆ+5.3%ï¼‰**ï¼Œå¹¶åª²ç¾ **50â€“100 å€æ›´å¤§è§„æ¨¡çš„æ¨¡å‹**ã€‚

---

### ğŸ” ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨ **direct inference** ä¸‹ï¼ŒLLM4Cov ä¹Ÿæ˜¾è‘—ä¼˜äºåŒç±»å°æ¨¡å‹ï¼ˆå¦‚ VeriCoder-Qwen2.5-14B: 28.2% vs. LLM4Cov Base: 28.4%ï¼‰ã€‚
- åœ¨ **agentic setting** ä¸­ä¼˜åŠ¿æ›´åŠ æ˜æ˜¾ï¼Œè¡¨æ˜è¯¥æ¡†æ¶ç‰¹åˆ«é€‚åˆå¤šè½®äº¤äº’å¼éªŒè¯ä»»åŠ¡ã€‚
- å›¾ 2 å’Œå›¾ 7 æ˜¾ç¤ºï¼ŒLLM4Cov åœ¨ **coverage pass rate** å’Œ **simulator pass rate** ä¸Šå‡å¤„äºå¸•ç´¯æ‰˜å‰æ²¿ï¼ˆPareto Frontierï¼‰ã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰**Intermediate State Selection ç­–ç•¥å¯¹æ¯”**ï¼ˆFigure 5ï¼‰
| ç­–ç•¥ | Cov Pass |
|------|---------|
| Best-State | ~62% |
| Uniform | ~63% |
| Median-State | ~64% |
| **Worst-State (ours)** | **~67.5%** |

âœ… æœ€å·®çŠ¶æ€ä¼˜å…ˆç­–ç•¥æ˜¾è‘—èƒœå‡ºï¼Œè¯æ˜èšç„¦å¤±è´¥æ¡ˆä¾‹èƒ½å¸¦æ¥æ›´å¼ºçš„å­¦ä¹ ä¿¡å·ã€‚

#### ï¼ˆ2ï¼‰**Progressive Learning vs Naive Data Augmentation**ï¼ˆFigure 6ï¼‰
- **Stage-conditioned progression**ï¼ˆåˆ†é˜¶æ®µè®­ç»ƒï¼‰æŒç»­ä¼˜äºå°†æ‰€æœ‰æ•°æ®åˆå¹¶è®­ç»ƒï¼ˆnaive augmentationï¼‰ã€‚
- å³ä½¿ä½¿ç”¨ç›¸åŒçš„ Stage 1+2 æ•°æ®ï¼Œä» Stage 0 checkpoint ç»§ç»­è®­ç»ƒä»ä¼˜äºä»å¤´è®­ç»ƒã€‚
- è¡¨æ˜ **distribution alignment** æ˜¯å…³é”®å› ç´ ã€‚

#### ï¼ˆ3ï¼‰**Trajectory Synthesis ç­–ç•¥æ¼”åŒ–**ï¼ˆFigure 4ï¼‰
- **Stage 1**ï¼šæ•™å¸ˆæŒ‡å¯¼ï¼ˆimitation-styleï¼‰æ˜æ˜¾ä¼˜äºçº¯å­¦ç”Ÿè‡ªé‡‡æ ·ï¼ˆself-samplingï¼‰
- **Stage 2**ï¼šéšç€å­¦ç”Ÿèƒ½åŠ›å¢å¼ºï¼Œself-sampling æ¥è¿‘ç”šè‡³åè¶… teacher-guided
- æ”¯æŒæ¸è¿›å¼å­¦ä¹ è®¾è®¡çš„æœ‰æ•ˆæ€§ã€‚

#### ï¼ˆ4ï¼‰**Execution-Based Dataset Curation æ¶ˆè**ï¼ˆTable 3ï¼‰
| æ–¹æ³• | Sim Pass (Direct) | Sim Pass (Agentic) |
|------|------------------|-------------------|
| Teacher Only | 53.3% | 85.1% |
| +Syntax Rules | 71.1% | 85.8% |
| +Execution Filtering | **83.9%** | **87.7%** |

âœ… æ‰§è¡ŒéªŒè¯çš„æ•°æ®æ¸…æ´—å¤§å¹…æå‡è¯­æ³•æ­£ç¡®æ€§å’Œä»¿çœŸé€šè¿‡ç‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **å°æ¨¡å‹ä¹Ÿèƒ½å®ç°é«˜æ€§èƒ½ç¡¬ä»¶éªŒè¯**ï¼šé€šè¿‡ execution-aware çš„ç¦»çº¿ä»£ç†å­¦ä¹ ï¼Œ**4B æ¨¡å‹å¯è¶…è¶Š 30B æ•™å¸ˆæ¨¡å‹**ï¼Œæ‰“ç ´â€œå”¯è§„æ¨¡è®ºâ€ã€‚
2. **è¦†ç›–ç‡æ˜¯å¼ºå¤§çš„ç›‘ç£ä¿¡å·**ï¼šç»“åˆ rejection sampling å’Œ worst-state selectionï¼Œå¯å°†æ˜‚è´µçš„ä»¿çœŸåé¦ˆè½¬åŒ–ä¸ºé«˜æ•ˆçš„è®­ç»ƒæ•°æ®ã€‚
3. **æ¸è¿›å¼å­¦ä¹ è‡³å…³é‡è¦**ï¼šè®­ç»ƒå¿…é¡»ä¸å­¦ç”Ÿæ¨¡å‹çš„çŠ¶æ€åˆ†å¸ƒæ¼”è¿›åŒæ­¥ï¼Œå¦åˆ™ä¼šå¯¼è‡´ç›‘ç£ä¿¡å·å¤±çœŸã€‚
4. **memoryless state design æ›´ä¼˜**ï¼šæ˜¾å¼ç¼–ç å½“å‰çŠ¶æ€å³å¯ä¿ç•™å…¨éƒ¨å¿…è¦ä¿¡æ¯ï¼Œæ— éœ€å†—é•¿çš„å†å²è®°å½•ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–ç¡®å®šæ€§ä»¿çœŸå™¨è¾“å‡º**ï¼šå‡è®¾ simulator å¯¹åŒä¸€è¾“å…¥è¿”å›ä¸€è‡´åé¦ˆï¼Œä¸é€‚ç”¨äºéšæœºæ€§å¼ºçš„ç¯å¢ƒã€‚
2. **å½“å‰ä»ä¸º offline èŒƒå¼**ï¼šè™½ç„¶æ”¯æŒ future RL åˆå§‹åŒ–ï¼Œä½†æœ¬èº«ä¸åŒ…å«æ¢ç´¢æœºåˆ¶ã€‚
3. **é¢†åŸŸç‰¹å®šè§„åˆ™ä¾èµ–**ï¼šStage 0 ä½¿ç”¨äººå·¥ç¼–å†™ syntax constraints æå‡åˆå§‹æˆåŠŸç‡ï¼Œå¯èƒ½é™åˆ¶æ³›åŒ–æ€§ã€‚
4. **ä»…å…³æ³¨ coverage maximization**ï¼šæœªå¤„ç† bug detection æˆ– assertion generation ä»»åŠ¡ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **é›†æˆ reasoning ä¸ planning èƒ½åŠ›**ï¼šç»“åˆ CoTã€Tree-of-Thought ç­‰æå‡ long-horizon å†³ç­–èƒ½åŠ›ã€‚
2. **å‘ online RL è¿ç§»**ï¼šåˆ©ç”¨ LLM4Cov è¾“å‡ºçš„å¤šæ ·åŒ–ç­–ç•¥ä½œä¸ºå¼ºåˆå§‹åŒ–ï¼Œå¼€å±•ä½æˆæœ¬ online fine-tuningã€‚
3. **æ‰©å±•è‡³å…¶ä»– EDA ä»»åŠ¡**ï¼šå¦‚ power optimizationã€timing closureã€formal verificationã€‚
4. **æ„å»ºå¼€æ”¾ benchmark ä¸ simulator æ¥å£æ ‡å‡†**ï¼šæ¨åŠ¨ community-wide evaluation protocol ç»Ÿä¸€ã€‚

---

> ğŸ’¬ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **LLM4Cov è¯æ˜äº†â€œæ­£ç¡®çš„å­¦ä¹ èŒƒå¼ > å•çº¯æ‰©å¤§æ¨¡å‹è§„æ¨¡â€** â€”â€” é€šè¿‡ execution-awareã€progressiveã€failure-focused çš„ç¦»çº¿ä»£ç†è®­ç»ƒï¼Œå³ä½¿æ˜¯å°å‹ LLM ä¹Ÿèƒ½åœ¨é«˜æˆæœ¬ç¡¬ä»¶éªŒè¯ä»»åŠ¡ä¸Šè¾¾åˆ°é¡¶å°–æ€§èƒ½ã€‚

</details>

---

### 5. [A Theoretical Framework for Modular Learning of Robust Generative Models](https://arxiv.org/abs/2602.17554)

**Authors**: Corinna Cortes, Mehryar Mohri, Yutao Zhong  
**Category**: cs.LG  
**Published**: 2026-02-20  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.17554v1  

#### Abstract
Training large-scale generative models is resource-intensive and relies heavily on heuristic dataset weighting. We address two fundamental questions: Can we train Large Language Models (LLMs) modularly-combining small, domain-specific experts to match monolithic performance-and can we do so robustly...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šA Theoretical Framework for Modular Learning of Robust Generative Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³å¤§è§„æ¨¡ç”Ÿæˆæ¨¡å‹ï¼ˆå¦‚ **Large Language Models, LLMs**ï¼‰è®­ç»ƒä¸­çš„ä¸¤ä¸ªæ ¹æœ¬æŒ‘æˆ˜ï¼š

1. **å¯æŒç»­æ€§ä¸é€‚åº”æ€§é—®é¢˜**ï¼šä¼ ç»Ÿå•ä½“ï¼ˆmonolithicï¼‰æ¨¡å‹è®­ç»ƒæˆæœ¬é«˜æ˜‚ï¼Œéš¾ä»¥é‡å¤è®­ç»ƒä»¥é€‚åº”æ–°æ•°æ®ï¼›æ›´æ–°æ¨¡å‹æ˜“å¯¼è‡´ç¾éš¾æ€§é—å¿˜ï¼ˆcatastrophic forgettingï¼‰ã€‚
2. **é²æ£’æ€§é—®é¢˜**ï¼šæ ‡å‡†è®­ç»ƒä¾èµ–å¯å‘å¼çš„æ•°æ®æ··åˆæƒé‡ï¼ˆheuristic dataset weightingï¼‰ï¼Œåœ¨æµ‹è¯•åˆ†å¸ƒä¸è®­ç»ƒå‡è®¾ä¸ä¸€è‡´æ—¶è¡¨ç°ä¸ä½³ã€‚

è®ºæ–‡æå‡ºï¼šèƒ½å¦é€šè¿‡æ¨¡å—åŒ–æ–¹å¼ç»„åˆå¤šä¸ªé¢„è®­ç»ƒä¸“å®¶æ¨¡å‹ï¼ˆpre-trained expertsï¼‰ï¼Œæ„å»ºä¸€ä¸ªå¯¹ä»»æ„æ•°æ®æ··åˆéƒ½é²æ£’çš„ç³»ç»Ÿï¼Œä»è€Œé¿å…æ˜‚è´µçš„é‡æ–°è®­ç»ƒå’Œå¯å‘å¼è°ƒå‚ï¼Ÿ

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯

ä½œè€…æå‡ºäº†ä¸€ä¸ª**åŸºäºåšå¼ˆè®ºçš„æ¨¡å—åŒ–ç”Ÿæˆå»ºæ¨¡èŒƒå¼**ï¼Œå…¶æ ¸å¿ƒæ˜¯ï¼š

- **Robust Gated Model**ï¼šå¼•å…¥ä¸€ä¸ªå¯å­¦ä¹ çš„**é—¨æ§æœºåˆ¶**ï¼ˆgateï¼‰$ g(x,k) $ï¼ŒåŠ¨æ€åœ°å°†ä¸€ç»„å†»ç»“çš„ã€é¢†åŸŸç‰¹å®šçš„ä¸“å®¶æ¨¡å‹ $ \Pi_k $ ç»„åˆä¸ºæœ€ç»ˆè¾“å‡ºï¼š
  $$
  T_g(x) = \sum_k g(x,k) \Pi_k(x)
  $$
  å…¶ä¸­ $ g(x,\cdot) \in \Delta $ æ˜¯è¾“å…¥ç›¸å…³çš„æ¦‚ç‡åˆ†å¸ƒã€‚

- **æœ€å°æœ€å¤§ä¼˜åŒ–æ¡†æ¶**ï¼ˆminimax gameï¼‰ï¼šç›®æ ‡æ˜¯æ‰¾åˆ°ä¸€ä¸ª**é²æ£’çš„é—¨æ§å‡½æ•° $ g^* $**ï¼Œä½¿å…¶åœ¨æœ€åæƒ…å†µä¸‹çš„æ•°æ®æ··åˆ $ \lambda $ ä¸‹ä»èƒ½ä¿æŒä½ KL æ•£åº¦ï¼š
  $$
  \min_{g \in \mathcal{G}_1} \max_{\lambda \in \Delta} D_{\text{KL}}(p_\lambda \| T_g)
  $$
  è¿™æ˜¯ä¸€ç§**åˆ†å¸ƒé²æ£’ä¼˜åŒ–**ï¼ˆDistributionally Robust Optimization, DROï¼‰æ€æƒ³åœ¨ç”Ÿæˆæ¨¡å‹ä¸­çš„åº”ç”¨ã€‚

- **ç†è®ºä¿è¯**ï¼šåˆ©ç”¨ Kakutani ä¸åŠ¨ç‚¹å®šç†è¯æ˜äº†æ­¤ç±»é²æ£’é—¨æ§å‡½æ•°çš„å­˜åœ¨æ€§ï¼Œå¹¶æ¨å¯¼å‡ºå…¶æ€§èƒ½ä¸Šç•Œã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| å¯¹æ¯”ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ MoE, Model Soupsï¼‰ | æœ¬æ–‡æ–¹æ³• |
|---------|-------------------------------|--------|
| **è®­ç»ƒæ¨¡å¼** | è”åˆè®­ç»ƒè·¯ç”±ä¸ä¸“å®¶ / é™æ€å¹³å‡æƒé‡ | å†»ç»“ä¸“å®¶ï¼Œä»…è®­ç»ƒè½»é‡çº§é—¨æ§ |
| **é²æ£’æ€§ç›®æ ‡** | å¹³å‡æ€§èƒ½ / ç‰¹å®šä»»åŠ¡ä¼˜åŒ– | æœ€åæƒ…å†µä¸‹çš„é²æ£’æ€§ï¼ˆworst-case robustnessï¼‰ |
| **ç†è®ºåŸºç¡€** | å¯å‘å¼è®¾è®¡ï¼Œç¼ºä¹ä¸¥æ ¼ç†è®º | æ¸…æ™°çš„ minimax åšå¼ˆæ¡†æ¶ï¼Œå­˜åœ¨æ€§ä¸æ”¶æ•›æ€§è¯æ˜ |
| **æ³›åŒ–èƒ½åŠ›** | ä¾èµ–å®Œæ•´æ¨¡å‹é‡è®­ç»ƒ | ä»…éœ€æ›´æ–°é—¨æ§å³å¯é€‚åº”æ–°åˆ†å¸ƒ |
| **æ¨ç†æ•ˆç‡** | MoE æœ‰è´Ÿè½½å‡è¡¡å¼€é”€ | æå‡º **Structural Distillation** å®ç°é«˜æ•ˆå› æœæ¨ç† |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†

å®éªŒåˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼š

#### ï¼ˆ1ï¼‰åˆæˆæ•°æ®é›†ï¼ˆSynthetic Benchmarksï¼‰
- æ„é€ ä¸¤ä¸ªå…·æœ‰**å†²çªè§„åˆ™**çš„åºåˆ—ç”Ÿæˆä»»åŠ¡ï¼š
  - **Domain A**: $ x_{t+1} = (x_t + 1) \mod 100 $
  - **Domain B**: $ x_{t+1} = (x_t - 1) \mod 100 $
- æµ‹è¯•æ—¶é€šè¿‡è°ƒæ•´æ··åˆæ¯”ä¾‹ $ \lambda \in [0,1] $ æ¨¡æ‹Ÿåˆ†å¸ƒåç§»ã€‚

#### ï¼ˆ2ï¼‰çœŸå®ä¸–ç•Œæ•°æ®é›†ï¼ˆReal-World Datasetsï¼‰
ä½¿ç”¨ä¸‰ä¸ªå·®å¼‚æ˜¾è‘—çš„ HuggingFace æ•°æ®é›†ï¼š
- `wikimedia/wikipedia`ï¼šé«˜è´¨é‡äº‹å®æ€§æ–‡æœ¬
- `bigcode/the-stack-smol`ï¼šå¤šè¯­è¨€æºä»£ç 
- `fineweb-edu`ï¼šè¿‡æ»¤åçš„æ•™è‚²ç½‘é¡µå†…å®¹

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

- **æ¨¡å‹æ¶æ„**ï¼šæ‰€æœ‰æ¨¡å‹å‡ä¸º Transformerï¼Œä¸“å®¶ä¸º 2 å±‚ï¼Œé—¨æ§ä¸ºå°å‹ Transformer Encoderã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - ä¸»è¦æŒ‡æ ‡ï¼š**Negative Log-Likelihood (NLL)** per token
  - å¯¹æ¯”ä¸åŒæµ‹è¯•æ··åˆæ¯”ä¾‹ $ \lambda $ ä¸‹çš„æ€§èƒ½
  - æŠ¥å‘Š 5 æ¬¡è¿è¡Œçš„å‡å€¼ä¸æ ‡å‡†å·®

### åŸºçº¿æ–¹æ³•å¯¹æ¯”

| åŸºçº¿æ–¹æ³• | æè¿° |
|--------|------|
| **Fixed Retrained Model** | åœ¨èšåˆæ•°æ®ä¸Šä»å¤´è®­ç»ƒçš„å•ä½“æ¨¡å‹ï¼ˆåŒºåˆ† smaller å’Œ larger å‚æ•°é‡ç‰ˆæœ¬ï¼‰ |
| **Oracle Retrained Model** | â€œä½œå¼Šâ€åŸºçº¿ï¼Œåœ¨æ¯ä¸ªæµ‹è¯•æ··åˆæ¯”ä¾‹ $ \lambda $ ä¸Šå•ç‹¬è®­ç»ƒçš„æ¨¡å‹ï¼ˆç†æƒ³æƒ…å†µï¼‰ |
| **Monolithic Distillation** | å°†é—¨æ§æ¨¡å‹è’¸é¦ä¸ºå•ä¸€å› æœå­¦ç”Ÿæ¨¡å‹ï¼ˆä¸¢å¼ƒæ¨¡å—æ€§ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰åˆæˆæ•°æ®ç»“æœï¼ˆFig. 5â€“7ï¼‰
- **Robust Gate** åœ¨æ•´ä¸ª $ \lambda \in [0,1] $ åŒºé—´å†…ä¿æŒ**ç¨³å®šä¸”è¾ƒä½çš„æŸå¤±**ã€‚
- å½“ $ \lambda \approx 0.5 $ï¼ˆé«˜ç†µæ··åˆï¼‰æ—¶ï¼š
  - å›ºå®šé‡è®­ç»ƒæ¨¡å‹ï¼ˆFixed Retrainedï¼‰å› **æ¢¯åº¦å†²çª**ï¼ˆgradient conflictï¼‰æ€§èƒ½ä¸¥é‡ä¸‹é™ã€‚
  - å³ä½¿æ˜¯â€œä½œå¼Šâ€çš„ **Oracle Larger Model** ä¹Ÿå› æ— æ³•åŒæ—¶æŒæ¡çŸ›ç›¾è§„åˆ™è€Œå‡ºç°æ€§èƒ½è°·åº•ã€‚
  - **Robust Gate æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿**ï¼ŒéªŒè¯äº† Theorem 6 ä¸­çš„ **JSD Gap** ç†è®ºã€‚

> âœ… **å…³é”®å‘ç°**ï¼šæ¨¡å—åŒ–ç»“æ„å¤©ç„¶è§£è€¦äº†ä»»åŠ¡é—´çš„å‡ ä½•å¹²æ‰°ï¼ˆinterferenceï¼‰ï¼Œåœ¨é«˜å¤šæ ·æ€§æ··åˆä¸‹ä¼˜åŠ¿æ˜æ˜¾ã€‚

#### ï¼ˆ2ï¼‰çœŸå®ä¸–ç•Œæ•°æ®ç»“æœï¼ˆTable 1 & 2ï¼‰

| Model | NLL per token (Diff seed) | NLL per token (Diff data) |
|-------|---------------------------|---------------------------|
| Retrained Model | 5.133 Â± 0.010 | 5.306 Â± 0.257 |
| **Gate Model** | **4.994 Â± 0.013** | **5.087 Â± 0.141** |

- **Gate Model åœ¨æ‰€æœ‰è®¾ç½®ä¸‹å‡ä¼˜äºåŒè§„æ¨¡çš„ Retrained Model**ã€‚
- åœ¨ä¸åŒæµ‹è¯•æ··åˆæ¯”ä¾‹ä¸‹ï¼ˆTable 2ï¼‰ï¼ŒGate Model è¡¨ç°å‡ºæ›´å¼ºçš„**åˆ†å¸ƒå¤–é²æ£’æ€§**ï¼ˆdistribution shift robustnessï¼‰ã€‚

#### ï¼ˆ3ï¼‰æ¶ˆèå®éªŒä¸æ‰©å±•

- **Structural Distillation**ï¼ˆå›¾ 8ï¼‰ï¼š
  - å°†éå› æœé—¨æ§è’¸é¦ä¸º**å› æœè·¯ç”±å™¨**ï¼ˆcausal routerï¼‰åï¼Œæ€§èƒ½æŸå¤±æå°ã€‚
  - æ¨ç†é€Ÿåº¦æ¢å¤ä¸ºæ ‡å‡†è‡ªå›å½’æ°´å¹³ï¼Œä¸”**ä¿ç•™äº†æ¨¡å—æ€§**ï¼ˆå¯ç‹¬ç«‹å‡çº§ä¸“å®¶ï¼‰ã€‚
- **ç®—æ³•ç¨³å®šæ€§**ï¼š
  - Primal-Dual ç®—æ³•ç¨³å®šæ”¶æ•›ï¼Œæ— å…¸å‹å¯¹æŠ—è®­ç»ƒçš„æŒ¯è¡ç°è±¡ã€‚
  - å¯¹æ‰‹æ··åˆæƒé‡ $ \lambda_t $ å¿«é€Ÿæ”¶æ•›è‡³ $ [0.5, 0.5] $ï¼Œè¡¨æ˜é—¨æ§æˆåŠŸå¹³è¡¡äº†å„é¢†åŸŸæ€§èƒ½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. âœ… **æ¨¡å—åŒ–å¯ä»¥å®ç°é²æ£’ç”Ÿæˆå»ºæ¨¡**ï¼š
   - å­˜åœ¨ä¸€ä¸ªé²æ£’é—¨æ§ $ g^* $ï¼Œèƒ½åœ¨ä»»æ„æœªçŸ¥æ•°æ®æ··åˆä¸‹æä¾›ç»Ÿä¸€æ€§èƒ½ä¿è¯ã€‚
   - è¯¥ç»“è®ºç”± Kakutani å®šç†ä¸¥æ ¼è¯æ˜ã€‚

2. âœ… **æ¨¡å—åŒ–æ˜¯â€œå®‰å…¨â€çš„å½’çº³åç½®**ï¼ˆsafe inductive biasï¼‰ï¼š
   - åœ¨å‡¸æ¨¡å‹æ—ä¸­ï¼Œé—¨æ§ç»„åˆç­‰ä»·äºåœ¨æ··åˆæ•°æ®ä¸Šé‡è®­ç»ƒï¼ˆTheorem 7ï¼‰ã€‚
   - åœ¨éå‡¸ã€å†²çªä»»åŠ¡ä¸­ï¼Œæ¨¡å—åŒ–èƒ½**é¿å…å‡ ä½•å¹²æ‰°**ï¼Œæ€§èƒ½è¶…è¶Šå•ä½“æ¨¡å‹ã€‚

3. âœ… **å¤šæ ·æ€§æ˜¯æ¨¡å—åŒ–çš„ä¼˜åŠ¿è€Œéè´Ÿæ‹…**ï¼š
   - å•ä½“æ¨¡å‹ä¸­ï¼ŒJensen-Shannon Divergence (JSD) æ˜¯**å¹²æ‰°é¡¹**ï¼ˆinterference floorï¼‰ã€‚
   - æ¨¡å—åŒ–æ¨¡å‹ä¸­ï¼ŒJSD æˆä¸º**åˆ†ç¦»å¢ç›Š**ï¼ˆseparability gainï¼‰ï¼Œå¸®åŠ©æŠµæ¶ˆå®¹é‡ä»£ä»·ã€‚

4. âœ… **è½»é‡é—¨æ§å¸¦æ¥é«˜æ•ˆæ³›åŒ–**ï¼š
   - æ³›åŒ–è¯¯å·®ç”±é—¨æ§å¤æ‚åº¦å†³å®šï¼Œè€Œéä¸“å®¶å‚æ•°é‡ï¼ˆTheorem 8ï¼‰ã€‚
   - é—¨æ§é€šå¸¸ä¸ºè½»é‡ç½‘ç»œï¼ˆå¦‚æµ…å±‚ Transformerï¼‰ï¼Œæ ·æœ¬æ•ˆç‡è¿œé«˜äºé‡è®­ç»ƒã€‚

### æ–¹æ³•çš„å±€é™æ€§

- **æ¨ç†ç“¶é¢ˆ**ï¼šæœ€ä¼˜é—¨æ§ $ g^* $ æ˜¯éå› æœçš„ï¼Œç›´æ¥é‡‡æ ·éœ€ SIR æˆ– Rejection Samplingï¼Œè®¡ç®—å¼€é”€å¤§ï¼ˆ$ O(Np) $ï¼‰ã€‚
- **ä¾èµ–ä¸“å®¶è´¨é‡**ï¼šè‹¥ä¸“å®¶æœ¬èº«æ€§èƒ½å·®æˆ–è¦†ç›–ä¸è¶³ï¼Œé—¨æ§æ— æ³•å¼¥è¡¥ã€‚
- **å½“å‰æ¡†æ¶ä¾§é‡ç»Ÿè®¡æ€§èƒ½**ï¼šæœªè€ƒè™‘è·¯ç”±å»¶è¿Ÿã€é€šä¿¡æˆæœ¬ç­‰å·¥ç¨‹å› ç´ ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•åˆ°æ›´å¤šä¸“å®¶**ï¼šç ”ç©¶ $ p \gg 100 $ æ—¶çš„å¯æ‰©å±•è·¯ç”±æœºåˆ¶ã€‚
2. **åœ¨çº¿å­¦ä¹ ä¸åŠ¨æ€æ·»åŠ ä¸“å®¶**ï¼šæ”¯æŒåœ¨ä¸é‡æ–°è®­ç»ƒé—¨æ§çš„æƒ…å†µä¸‹åŠ å…¥æ–°ä¸“å®¶ã€‚
3. **ç»“åˆ MoE ä¸æœ¬æ–‡æ¡†æ¶**ï¼šæ¢ç´¢å¯è®­ç»ƒä¸“å®¶ + é²æ£’é—¨æ§çš„æ··åˆèŒƒå¼ã€‚
4. **åº”ç”¨äºå¤šæ¨¡æ€ä¸è·¨åŸŸä»»åŠ¡**ï¼šå¦‚å›¾æ–‡ã€è¯­éŸ³-æ–‡æœ¬è”åˆå»ºæ¨¡ã€‚
5. **ç»æµä¸ç”Ÿæ€è§†è§’**ï¼šæ„å»ºåŸºäºæ¨¡å—å¸‚åœºçš„ AI ç”Ÿæ€ç³»ç»Ÿï¼Œæœ¬æ–‡æä¾›äº†ç»Ÿè®¡å±‚é¢çš„å‡è¡¡ä¿éšœã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡å»ºç«‹äº†é¦–ä¸ª**ç†è®ºä¸¥è°¨çš„æ¨¡å—åŒ–ç”Ÿæˆæ¨¡å‹æ¡†æ¶**ï¼Œè¯æ˜äº†é€šè¿‡ä¸€ä¸ªè½»é‡çº§ã€é²æ£’çš„é—¨æ§æœºåˆ¶ï¼Œå¯ä»¥å°†å¤šä¸ªå†»ç»“ä¸“å®¶ç»„åˆæˆä¸€ä¸ªå¯¹ä»»æ„æ•°æ®æ··åˆéƒ½ç¨³å¥çš„ç³»ç»Ÿï¼Œä¸ä»…åœ¨ç†è®ºä¸Šæ­ç¤ºäº†â€œå¤šæ ·æ€§å³ä¼˜åŠ¿â€çš„æ–°æœºåˆ¶ï¼Œä¹Ÿåœ¨åˆæˆä¸çœŸå®æ•°æ®ä¸ŠéªŒè¯äº†å…¶ä¼˜è¶Šæ€§ï¼Œä¸ºç»¿è‰²ã€å¯æŒç»­ã€å¯æ‰©å±•çš„ LLM å‘å±•æä¾›äº†æ–°è·¯å¾„ã€‚

</details>

---

### 6. [WarpRec: Unifying Academic Rigor and Industrial Scale for Responsible, Reproducible, and Efficient Recommendation](https://arxiv.org/abs/2602.17442)

**Authors**: Marco Avolio, Potito Aghilar, Sabino Roccotelli, Vito Walter Anelli, Chiara Mallamaci, Vincenzo Paparella, Marco Valentini, Alejandro Bellog\'in, Michelantonio Trizio, Joseph Trotta, Antonio Ferrara, Tommaso Di Noia  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.17442v1  

#### Abstract
Innovation in Recommender Systems is currently impeded by a fractured ecosystem, where researchers must choose between the ease of in-memory experimentation and the costly, complex rewriting required for distributed industrial engines. To bridge this gap, we present WarpRec, a high-performance frame...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šWarpRec: Unifying Academic Rigor and Industrial Scale for Responsible, Reproducible, and Efficient Recommendation

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
æ¨èç³»ç»Ÿï¼ˆ**Recommender Systems, RS**ï¼‰é¢†åŸŸé•¿æœŸå­˜åœ¨**å­¦æœ¯ç•Œä¸å·¥ä¸šç•Œä¹‹é—´çš„å‰²è£‚**ï¼š
- **å­¦æœ¯æ¡†æ¶**ï¼ˆå¦‚ RecBoleã€Elliotï¼‰ï¼šçµæ´»ã€æ”¯æŒå¿«é€ŸåŸå‹å¼€å‘ï¼Œä½†é€šå¸¸åŸºäºå•æœºå†…å­˜è®¡ç®—ï¼Œéš¾ä»¥æ‰©å±•åˆ°å¤§è§„æ¨¡å·¥ä¸šåœºæ™¯ã€‚
- **å·¥ä¸šæ¡†æ¶**ï¼ˆå¦‚ NVIDIA Merlinã€MS Recommendersï¼‰ï¼šæ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒå’Œé«˜ååï¼Œä½†ç¼ºä¹ç§‘å­¦ä¸¥è°¨æ€§ï¼ˆå¦‚ç»Ÿè®¡æ£€éªŒã€å¯å¤ç°æ€§ï¼‰ã€çµæ´»æ€§å·®ã€‚

æ­¤å¤–ï¼Œå½“å‰æ¡†æ¶åœ¨ä»¥ä¸‹æ–¹é¢å­˜åœ¨ç¼ºå¤±ï¼š
- **ç”Ÿæ€è´£ä»»**ï¼ˆGreen AIï¼‰ï¼šç¼ºä¹å¯¹èƒ½è€—å’Œç¢³æ’æ”¾çš„é‡åŒ–å·¥å…·ã€‚
- **æ™ºèƒ½ä½“å…¼å®¹æ€§**ï¼ˆAgentic AIï¼‰ï¼šæ— æ³•ä½œä¸º LLM é©±åŠ¨çš„æ™ºèƒ½ä½“ä¸­çš„å¯è°ƒç”¨å·¥å…·ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
ä½œè€…æå‡º **WARPREC**ï¼Œä¸€ä¸ªé«˜æ€§èƒ½ã€æ¨¡å—åŒ–ã€åç«¯æ— å…³çš„æ¨èç³»ç»Ÿæ¡†æ¶ï¼Œæ—¨åœ¨ç»Ÿä¸€å­¦æœ¯ä¸¥è°¨æ€§ä¸å·¥ä¸šçº§è§„æ¨¡ã€‚

å…¶æ ¸å¿ƒåˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

#### âœ… åç«¯æ— å…³æ¶æ„ï¼ˆBackend-Agnostic Architectureï¼‰
- åŸºäº **Narwhals** æ„å»ºç»Ÿä¸€çš„æ•°æ®æŠ½è±¡å±‚ï¼Œå®ç°â€œä¸€æ¬¡ç¼–å†™ï¼Œéšå¤„è¿è¡Œâ€ï¼ˆwrite-once, run-anywhereï¼‰ã€‚
- æ”¯æŒä»æœ¬åœ°è°ƒè¯•æ— ç¼åˆ‡æ¢åˆ°åŸºäº **Ray** çš„åˆ†å¸ƒå¼é›†ç¾¤è®­ç»ƒã€‚

#### âœ… æ¨¡å—åŒ–è§£è€¦è®¾è®¡
æ¡†æ¶ç”±äº”ä¸ªç‹¬ç«‹æ¨¡å—ç»„æˆï¼š
1. **Reader**ï¼šæ•°æ®è¯»å–ï¼ˆæ”¯æŒæœ¬åœ°/äº‘å­˜å‚¨ï¼‰
2. **Data Engine**ï¼šæ•°æ®é¢„å¤„ç†ï¼ˆè¿‡æ»¤ã€åˆ†å‰²ã€å¯¹é½ï¼‰
3. **Recommendation Engine**ï¼šæ¨¡å‹è®­ç»ƒä¸è¶…å‚ä¼˜åŒ–ï¼ˆHPOï¼‰
4. **Evaluation**ï¼šå¤šç»´åº¦è¯„ä¼° + ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
5. **Writer**ï¼šç»“æœæŒä¹…åŒ–ï¼ˆæ”¯æŒæœ¬åœ°/äº‘ç«¯ï¼‰

#### âœ… ç”Ÿæ€è´£ä»»é›†æˆï¼ˆGreen AIï¼‰
- å…¨çƒé¦–ä¸ªåŸç”Ÿé›†æˆ **CodeCarbon** çš„æ¨èæ¡†æ¶ï¼Œå®æ—¶è¿½è¸ªè®­ç»ƒè¿‡ç¨‹ä¸­çš„èƒ½æºæ¶ˆè€—ä¸ç¢³æ’æ”¾ã€‚

#### âœ… æ™ºèƒ½ä½“å°±ç»ªæ¥å£ï¼ˆAgentic Readinessï¼‰
- åŸç”Ÿæ”¯æŒ **Model Context Protocol (MCP)** æ¥å£ï¼Œä½¿æ¨èå™¨å¯è¢« LLM æ™ºèƒ½ä½“ç›´æ¥è°ƒç”¨ï¼Œæˆä¸ºç”Ÿæˆå¼ AI ç”Ÿæ€ä¸­çš„ä¸€éƒ¨åˆ†ã€‚

#### âœ… ç§‘å­¦ä¸¥è°¨æ€§ä¿éšœ
- è‡ªåŠ¨æ‰§è¡Œ **ç»Ÿè®¡å‡è®¾æ£€éªŒ**ï¼ˆå¦‚ t-test, Wilcoxonï¼‰å’Œå¤šé‡æ¯”è¾ƒæ ¡æ­£ï¼ˆå¦‚ Bonferroni, FDRï¼‰ï¼Œé˜²æ­¢ p-hackingã€‚
- æ”¯æŒ **å¤šç›®æ ‡ä¼˜åŒ–æŒ‡æ ‡**ï¼ˆMulti-objective metricsï¼‰ï¼Œå¹³è¡¡å‡†ç¡®æ€§ä¸å…¬å¹³æ€§ã€å¤šæ ·æ€§ç­‰éå‡†ç¡®æ€§ç›®æ ‡ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | WARPREC ä¼˜åŠ¿ |
|------|-------------|
| **å¯æ‰©å±•æ€§** | æ”¯æŒä»å•æœºåˆ°å¤šGPU/å¤šèŠ‚ç‚¹ Ray é›†ç¾¤çš„å¼¹æ€§ä¼¸ç¼© |
| **å¯å¤ç°æ€§** | å…¨æµç¨‹ç¡®å®šæ€§æ§åˆ¶ï¼ˆå…¨å±€éšæœºç§å­ï¼‰ã€å®Œæ•´å®éªŒæ—¥å¿—è®°å½• |
| **åŠŸèƒ½å®Œæ•´æ€§** | å†…ç½® 55 ä¸ªç®—æ³•ã€40 ä¸ªæŒ‡æ ‡ã€19 ç§åˆ’åˆ†ç­–ç•¥ |
| **ç»¿è‰²AI** | å”¯ä¸€æä¾›å®æ—¶ç¢³è¶³è¿¹ç›‘æ§çš„æ¡†æ¶ |
| **æ™ºèƒ½ä½“äº¤äº’** | å”¯ä¸€åŸç”Ÿæ”¯æŒ MCP åè®®çš„æ¨èæ¡†æ¶ |
| **çµæ´»æ€§** | æ”¯æŒæ¨¡å—è§£è€¦ä½¿ç”¨ï¼Œå¯åµŒå…¥å¤–éƒ¨æµæ°´çº¿ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
å®éªŒé‡‡ç”¨ä¸‰ä¸ªä¸åŒè§„æ¨¡çš„æ ‡å‡†æ¨èæ•°æ®é›†ï¼Œè¦†ç›–ä»å°å‹å­¦æœ¯åˆ°å¤§å‹å·¥ä¸šåœºæ™¯ï¼š
| æ•°æ®é›† | ç”¨æˆ·æ•° | ç‰©å“æ•° | äº¤äº’æ•° | ç¨€ç–åº¦ |
|--------|--------|--------|--------|--------|
| **MovieLens-1M** | 6,040 | 3,883 | ~1M | 95.7% |
| **MovieLens-32M** | 200,948 | 87,585 | ~32M | 99.8% |
| **NetflixPrize-100M** | 480,189 | 17,770 | ~100M | 98.8% |

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### æ¨¡å‹é€‰æ‹©
æµ‹è¯•äº”ç±»ä»£è¡¨æ€§ç®—æ³•ï¼š
- **EASE**ï¼ˆæµ…å±‚è‡ªåŠ¨ç¼–ç å™¨ï¼‰
- **ItemKNN**ï¼ˆååŒè¿‡æ»¤åŸºå‡†ï¼‰
- **NeuMF**ï¼ˆç¥ç»çŸ©é˜µåˆ†è§£ï¼‰
- **LightGCN**ï¼ˆå›¾ç¥ç»ç½‘ç»œï¼‰
- **SASRec**ï¼ˆåºåˆ—æ¨èæ¨¡å‹ï¼‰

#### åˆ’åˆ†ç­–ç•¥
- å¯¹å¤§å¤šæ•°æ¨¡å‹ä½¿ç”¨ **90-10 éšæœº Holdout**
- å¯¹ SASRec ä½¿ç”¨ **æ—¶é—´é¡ºåº Holdout**

#### è¶…å‚ä¼˜åŒ–ï¼ˆHPOï¼‰
- ä½¿ç”¨ç½‘æ ¼æœç´¢ï¼ˆGrid Searchï¼‰æ¢ç´¢æ¯æ¨¡å‹ 6 ç§é…ç½®
- æœ€ä½³æ¨¡å‹é€šè¿‡éªŒè¯é›†ä¸Šçš„ **nDCG@10** é€‰æ‹©
- æ‰¹å¤§å°ä¸º 8,192ï¼Œæœ€å¤§è®­ç»ƒè½®æ¬¡ä¸º 10ï¼ˆMovieLensï¼‰æˆ– 2ï¼ˆNetflixï¼‰
- å•æ¬¡è¯•éªŒè¶…æ—¶ 24 å°æ—¶

#### ç¡¬ä»¶èµ„æº
- CPUï¼š16æ ¸
- GPUï¼šNVIDIA A100ï¼ˆ64GBæ˜¾å­˜ï¼‰
- æ”¯æŒä¸²è¡Œï¼ˆSerialï¼‰ä¸å¹¶è¡Œï¼ˆParallel via Rayï¼‰æ‰§è¡Œæ¨¡å¼

#### è¯„ä¼°æŒ‡æ ‡
- **æ•ˆç‡æŒ‡æ ‡**ï¼š
  - é¢„å¤„ç†æ—¶é—´ï¼ˆPreprocessingï¼‰
  - è®­ç»ƒæ—¶é—´ï¼ˆTrainingï¼‰
  - è¯„ä¼°æ—¶é—´ï¼ˆEvaluationï¼‰
  - HPO æ€»è€—æ—¶ï¼ˆWall-clock timeï¼‰
- **æ€§èƒ½æŒ‡æ ‡**ï¼š
  - **nDCG@10**ï¼ˆä¸»è¯„ä»·æŒ‡æ ‡ï¼‰
- **å¯æŒç»­æ€§æŒ‡æ ‡**ï¼š
  - èƒ½æºæ¶ˆè€—ï¼ˆEnergy Consumed, kWhï¼‰
  - ç¢³æ’æ”¾é‡ï¼ˆCOâ‚‚eq, kgï¼‰
  - CPU/GPU åŠŸç‡ä¸èƒ½è€—

#### å¯å¤ç°æ€§ä¿éšœ
- å›ºå®šéšæœºç§å­
- ä½¿ç”¨ **Weights & Biases** è¿½è¸ªå®éªŒ
- æ‰€æœ‰ä»£ç ä¸é…ç½®å¼€æºï¼š[GitHubé“¾æ¥](https://github.com/sisinflab/warprec/)

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 4ï¼‰

#### åœ¨ **NetflixPrize-100M** ä¸Šçš„è¡¨ç°ï¼ˆæœ€å…·æŒ‘æˆ˜æ€§ï¼‰ï¼š
| æ¡†æ¶ | æ˜¯å¦å®Œæˆ HPOï¼Ÿ | æ€»è€—æ—¶ | nDCG@10 |
|------|----------------|--------|---------|
| Cornac / Elliot / RecBole / DaisyRec | âŒ å¤±è´¥ï¼ˆOOM æˆ–è¶…æ—¶ï¼‰ | â€” | â€” |
| MS Recommenders | âŒ å¤±è´¥ï¼ˆOOM-VRAMï¼‰ | â€” | â€” |
| **WARPREC (Parallel)** | âœ… æˆåŠŸ | **28m 22s** | 0.1323 |
| **WARPREC (Serial)** | âœ… æˆåŠŸ | 1h10m | 0.1323 |

> âš ï¸ æ³¨æ„ï¼šé™¤ WARPREC å’Œ RecBole å¤–ï¼Œæ‰€æœ‰æ¡†æ¶å‡æœªèƒ½å®Œæˆ LightGCN åœ¨è¯¥æ•°æ®é›†ä¸Šçš„è®­ç»ƒã€‚

#### åœ¨ **MovieLens-32M** ä¸Šçš„è¡¨ç°ï¼š
| æ¡†æ¶ | æ€»è€—æ—¶ | nDCG@10 |
|------|--------|---------|
| RecBole | 7h10m | 0.3609 |
| **WARPREC (Parallel)** | **1h34m** | 0.1456 |
| **WARPREC (Serial)** | 6h7m | 0.3399 |

âœ… WARPREC åœ¨å¹¶è¡Œæ¨¡å¼ä¸‹é€Ÿåº¦æ˜¾è‘—ä¼˜äºå…¶ä»–æ¡†æ¶ï¼Œä¸”å”¯ä¸€èƒ½åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šç¨³å®šå®Œæˆå…¨æµç¨‹ã€‚

#### åœ¨ **MovieLens-1M** ä¸Šçš„å°è§„æ¨¡æµ‹è¯•ï¼š
æ‰€æœ‰æ¡†æ¶å‡å¯å®Œæˆä»»åŠ¡ï¼ŒWARPREC è¡¨ç°å‡ºæœ€å¿«çš„ç«¯åˆ°ç«¯æ•ˆç‡ï¼ˆæœ€å¿«ä»…éœ€ **1m42s** å®Œæˆ HPOï¼‰ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

| å¯¹æ¯”ç»´åº¦ | WARPREC è¡¨ç° |
|----------|------------|
| **å¯æ‰©å±•æ€§** | å”¯ä¸€èƒ½åœ¨ Netflix-100M ä¸ŠæˆåŠŸè¿è¡Œ LightGCN çš„æ¡†æ¶ä¹‹ä¸€ |
| **å†…å­˜æ•ˆç‡** | æœ‰æ•ˆé¿å… OOM é”™è¯¯ï¼Œæ”¯æŒæ›´å¤§æ‰¹é‡å’Œæ›´å¤æ‚æ¨¡å‹ |
| **è®­ç»ƒé€Ÿåº¦** | å¹¶è¡Œæ¨¡å¼ä¸‹æ¯” RecBole å¿« **4â€“10 å€** |
| **HPO æ•ˆç‡** | æ”¯æŒ ASHA è°ƒåº¦å™¨è¿›è¡Œæ—©æœŸå‰ªæï¼Œå¤§å¹…ç¼©çŸ­æœç´¢æ—¶é—´ |
| **GPU åˆ©ç”¨ç‡** | å…¨é¢ GPU åŠ é€ŸæŒ‡æ ‡è®¡ç®—ï¼Œé™ä½è¯„ä¼°å»¶è¿Ÿ |

---

### æ¶ˆèå®éªŒç»“æœï¼ˆéšå«åˆ†æï¼‰

è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèå®éªŒè¡¨æ ¼ï¼Œä½†æ–‡ä¸­é€šè¿‡å¤šä¸ªç»´åº¦è¿›è¡Œäº†åŠŸèƒ½æœ‰æ•ˆæ€§éªŒè¯ï¼š

#### â–¶ Green AI åˆ†æï¼ˆTable 5ï¼‰
åœ¨ Netflix-100M ä¸Šè®­ç»ƒä¸åŒæ¨¡å‹çš„èƒ½è€—å¯¹æ¯”ï¼š
| æ¨¡å‹ | èƒ½æºæ¶ˆè€— (kWh) | ç¢³æ’æ”¾ (kg COâ‚‚eq) |
|------|----------------|--------------------|
| EASE | 0.115 | 0.0005 |
| ItemKNN | 0.0476 | 0.0002 |
| LightGCN | **2.4192** | **0.0095** |
| SASRec | 0.3159 | 0.0012 |

ğŸ” å‘ç°ï¼š
- **LightGCN èƒ½è€—æœ€é«˜**ï¼Œå› å…¶æ”¶æ•›æ…¢ï¼Œå°½ç®¡ç¬æ—¶åŠŸè€—ä¸é«˜ã€‚
- **EASE å’Œ ItemKNN æ›´èŠ‚èƒ½**ï¼Œé€‚åˆç»¿è‰²éƒ¨ç½²ã€‚
- éªŒè¯äº†â€œ**æ€§èƒ½æå‡ â‰  æ›´é«˜ç¢³æˆæœ¬**â€ï¼Œå¯é€šè¿‡æ¨¡å‹é€‰æ‹©ä¼˜åŒ–å¯æŒç»­æ€§ã€‚

#### â–¶ Agentic AI å®éªŒï¼ˆFigure 2ï¼‰
å±•ç¤ºäº†ä¸€ä¸ª LLM æ™ºèƒ½ä½“é€šè¿‡ MCP æ¥å£è°ƒç”¨ WARPREC çš„ SASRec æ¨¡å‹è¿›è¡Œç”µå½±æ¨èï¼š
- è¾“å…¥å†å²ï¼š`['Pulp Fiction', 'Forrest Gump', 'Full Metal Jacket']`
- è¾“å‡ºæ¨èï¼š`['Star Wars IV', 'The Godfather', 'Schindler's List']`
- æ™ºèƒ½ä½“ç»“åˆè¯­ä¹‰ç†è§£ç”Ÿæˆè‡ªç„¶è¯­è¨€è§£é‡Šï¼Œå¢å¼ºç”¨æˆ·ä½“éªŒã€‚

âœ… è¯æ˜ WARPREC å¯ä½œä¸º **LLM Agent çš„å¯ä¿¡å·¥å…·**ï¼Œæ¨åŠ¨æ¨èç³»ç»Ÿå‘äº¤äº’å¼æ™ºèƒ½ä½“æ¼”è¿›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°

1. **ç»Ÿä¸€æ¶æ„æ˜¯å¯è¡Œçš„**ï¼šWARPREC æˆåŠŸå¼¥åˆäº†å­¦æœ¯ä¸å·¥ä¸šæ¨èç³»ç»Ÿçš„é¸¿æ²Ÿï¼Œå®ç°äº†â€œä¸€æ¬¡å¼€å‘ï¼Œå¤šç¯å¢ƒéƒ¨ç½²â€ã€‚
2. **å¯æ‰©å±•æ€§ä¸ç§‘å­¦ä¸¥è°¨æ€§å¯ä»¥å…¼å¾—**ï¼šæ—¢æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒï¼Œåˆå†…ç½®ç»Ÿè®¡æ£€éªŒã€å¯å¤ç°æ€§æœºåˆ¶ã€‚
3. **ç»¿è‰²AIå¿…é¡»è¢«é‡åŒ–**ï¼šé¦–æ¬¡å°†ç¢³è¶³è¿¹çº³å…¥æ¨èç³»ç»Ÿè¯„ä¼°ä½“ç³»ï¼Œæ­ç¤ºäº†æ¨¡å‹é€‰æ‹©å¯¹ç¯å¢ƒçš„é‡å¤§å½±å“ã€‚
4. **æ¨èç³»ç»Ÿæ­£åœ¨è¿›åŒ–ä¸ºæ™ºèƒ½ä½“å·¥å…·**ï¼šé€šè¿‡ MCP æ¥å£ï¼Œæ¨èå™¨ä¸å†æ˜¯è¢«åŠ¨é¢„æµ‹å™¨ï¼Œè€Œæ˜¯ä¸»åŠ¨å‚ä¸æ¨ç†å¾ªç¯çš„â€œè®¤çŸ¥ä¼™ä¼´â€ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§

| å±€é™æ€§ | è¯´æ˜ |
|--------|------|
| **å­¦ä¹ æ›²çº¿è¾ƒé«˜** | æ¨¡å—åŒ–è®¾è®¡è™½çµæ´»ï¼Œä½†å¯¹æ–°æ‰‹ç”¨æˆ·å¯èƒ½ä¸å¤Ÿå‹å¥½ |
| **æ–‡æ¡£å’Œç¤¾åŒºå°šåœ¨å»ºè®¾ä¸­** | ç›¸æ¯”æˆç†Ÿæ¡†æ¶ï¼ˆå¦‚ RecBoleï¼‰ï¼Œç”Ÿæ€ä»åœ¨æ—©æœŸé˜¶æ®µ |
| **éƒ¨åˆ†å‰æ²¿æ¨¡å‹å°šæœªå®Œå…¨è¦†ç›–** | å°½ç®¡å·²æœ‰ 55 ä¸ªç®—æ³•ï¼Œä½†æŸäº›æœ€æ–°æ¶æ„ï¼ˆå¦‚ Diffusion-based RSï¼‰æš‚æœªé›†æˆ |
| **MCP æ¥å£ä¾èµ–å¤–éƒ¨ LLM ç”Ÿæ€** | å…¶ä»·å€¼é«˜åº¦ä¾èµ–äº Agentic AI çš„æ™®åŠç¨‹åº¦ |

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•æ›´å¤šç»¿è‰²AIç­–ç•¥**ï¼š
   - å¼•å…¥åŠ¨æ€ç”µå‹é¢‘ç‡è°ƒèŠ‚ï¼ˆDVFSï¼‰ä»¥è¿›ä¸€æ­¥èŠ‚èƒ½ã€‚
   - å¼€å‘åŸºäºèƒ½è€—æ„ŸçŸ¥çš„ HPO ç­–ç•¥ã€‚

2. **å¢å¼ºæ™ºèƒ½ä½“åä½œèƒ½åŠ›**ï¼š
   - æ”¯æŒå¤šè½®å¯¹è¯å¼æ¨èï¼ˆConversational Recommendationï¼‰ã€‚
   - å®ç°åäº‹å®æ¨ç†ä¸åå¥½ä¿®æ­£æœºåˆ¶ã€‚

3. **æ„å»ºæ¨èå³æœåŠ¡ï¼ˆRaaSï¼‰å¹³å°**ï¼š
   - åŸºäº WARPREC æ„å»ºäº‘åŸç”Ÿæ¨èæœåŠ¡å¹³å°ï¼Œæ”¯æŒä¸€é”®éƒ¨ç½²ä¸ç›‘æ§ã€‚

4. **æ¨åŠ¨æ ‡å‡†åŒ–è¿›ç¨‹**ï¼š
   - å€¡å¯¼å°† CodeCarbon å’Œ MCP ä½œä¸ºæ¨èç³»ç»Ÿæ¡†æ¶çš„æ ‡å‡†ç»„ä»¶ã€‚

---

## æ€»ç»“

> **WARPREC ä¸åªæ˜¯ä¸€ä¸ªæ¨èæ¡†æ¶ï¼Œæ›´æ˜¯ä¸‹ä¸€ä»£è´Ÿè´£ä»»ã€å¯æŒç»­ã€æ™ºèƒ½ä½“å°±ç»ªçš„æ¨èç³»ç»ŸåŸºç¡€è®¾æ–½ã€‚**

å®ƒä¸ä»…è§£å†³äº†â€œå­¦æœ¯-å·¥ä¸šè„±èŠ‚â€çš„è€é—®é¢˜ï¼Œè¿˜å‰ç»æ€§åœ°å›åº”äº† **Green AI** å’Œ **Agentic AI** çš„æ–°è¶‹åŠ¿ï¼Œä¸ºæ¨èç³»ç»Ÿç ”ç©¶ä¸åº”ç”¨æä¾›äº†å…¨æ–°çš„èŒƒå¼ã€‚

</details>

---

### 7. [Pareto Optimal Benchmarking of AI Models on ARM Cortex Processors for Sustainable Embedded Systems](https://arxiv.org/abs/2602.17508)

**Authors**: Pranay Jain, Maximilian Kasper, G\"oran K\"ober, Axel Plinge, Dominik Seu{\ss}  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.17508v1  

#### Abstract
This work presents a practical benchmarking framework for optimizing artificial intelligence (AI) models on ARM Cortex processors (M0+, M4, M7), focusing on energy efficiency, accuracy, and resource utilization in embedded systems. Through the design of an automated test bench, we provide a systemat...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šPareto Optimal Benchmarking of AI Models on ARM Cortex Processors for Sustainable Embedded Systems

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
æœ¬ç ”ç©¶é’ˆå¯¹**è¾¹ç¼˜AIç³»ç»Ÿåœ¨èµ„æºå—é™åµŒå…¥å¼å¹³å°ä¸Šçš„å¯æŒç»­éƒ¨ç½²éš¾é¢˜**ï¼Œç‰¹åˆ«æ˜¯å¦‚ä½•åœ¨æœ‰é™çš„å†…å­˜ã€åŠŸè€—å’Œè®¡ç®—èƒ½åŠ›ä¸‹ï¼Œå®ç°AIæ¨¡å‹åœ¨èƒ½æ•ˆã€å‡†ç¡®ç‡å’Œæ¨ç†å»¶è¿Ÿä¹‹é—´çš„æœ€ä¼˜æƒè¡¡ã€‚ç°æœ‰ç ”ç©¶å¤šé›†ä¸­äºSBCsï¼ˆå¦‚Raspberry Piï¼‰ç­‰é«˜å±‚å¹³å°ï¼Œå…¶æ“ä½œç³»ç»Ÿå’Œä¸­é—´ä»¶å¼•å…¥æŠ½è±¡å±‚ï¼Œæ©ç›–äº†ç¡¬ä»¶çœŸå®æ€§èƒ½ï¼›è€Œå¯¹bare-metalå¤„ç†å™¨ï¼ˆæ— æ“ä½œç³»ç»Ÿï¼‰çš„ç³»ç»Ÿæ€§åŸºå‡†æµ‹è¯•ä»å­˜åœ¨ç©ºç™½ã€‚

### âœ… æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
- **æ„å»ºäº†ä¸€ä¸ªè‡ªåŠ¨åŒ–æµ‹è¯•å¹³å°ï¼ˆtest benchï¼‰**ï¼Œç”¨äºåœ¨ARM Cortex-Mç³»åˆ—å¤„ç†å™¨ï¼ˆM0+, M4, M7ï¼‰ä¸Šè¿›è¡Œè£¸æœºï¼ˆbare-metalï¼‰AIæ¨¡å‹æ€§èƒ½è¯„ä¼°ã€‚
- å¼•å…¥**åŸºäºParetoå‰æ²¿åˆ†æçš„å¤šç›®æ ‡ä¼˜åŒ–æ¡†æ¶**ï¼Œç»¼åˆè€ƒè™‘accuracyã€energy consumptionã€latencyå’Œresource utilizationï¼Œè¯†åˆ«æœ€ä¼˜çš„å¤„ç†å™¨-æ¨¡å‹ç»„åˆã€‚
- å‘ç°å¹¶éªŒè¯äº†**FLOPsä¸inference timeä¹‹é—´è¿‘ä¼¼çº¿æ€§å…³ç³»**ï¼Œæå‡ºå¯å°†å…¶ä½œä¸ºæ—©æœŸè®¾è®¡é˜¶æ®µçš„é¢„æµ‹æŒ‡æ ‡ï¼Œæ”¯æŒå¿«é€Ÿæ¨¡å‹ç­›é€‰ä¸ååŒè®¾è®¡ï¼ˆco-designï¼‰ã€‚
- å°†**inference cycle energy**ï¼ˆåŒ…å«active inference + idle timeï¼‰ä½œä¸ºæ ¸å¿ƒKPIï¼Œå¼ºè°ƒåº”ç”¨æ—¶åºè¡Œä¸ºï¼ˆduty cycleï¼‰å¯¹æ•´ä½“èƒ½æ•ˆçš„å…³é”®å½±å“ã€‚

### âœ… ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **è¯„ä¼°å±‚çº§** | èšç„¦bare-metalç¯å¢ƒï¼Œé¿å…OS/middlewareå¹²æ‰°ï¼Œæä¾›æ›´çœŸå®çš„ç¡¬ä»¶æ€§èƒ½è§†å›¾ |
| **è¯„ä¼°ç»´åº¦** | å¤šç»´KPIè”åˆåˆ†æï¼ˆaccuracy, energy, latency, memoryï¼‰ï¼Œè€Œéå•ä¸€æŒ‡æ ‡ |
| **å†³ç­–æ”¯æŒ** | æä¾›Pareto frontå¯è§†åŒ–å·¥å…·ï¼ŒæŒ‡å¯¼å¼€å‘è€…æ ¹æ®use caseç‰¹æ€§é€‰æ‹©æœ€ä½³é…ç½® |
| **é¢„æµ‹èƒ½åŠ›** | åˆ©ç”¨FLOPsé¢„æµ‹inference timeï¼Œå‡å°‘å®é™…éƒ¨ç½²å‰çš„è¯•é”™æˆæœ¬ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†ä¸Use Cases
è®ºæ–‡é€‰å–å››ä¸ªå…¸å‹åµŒå…¥å¼AIåº”ç”¨åœºæ™¯ï¼Œæ¶µç›–ä¸åŒä»»åŠ¡ç±»å‹ï¼š

| Use Case | Model | Dataset | Quality Target |
|--------|-------|---------|----------------|
| å›¾åƒåˆ†ç±»ï¼ˆImage Classificationï¼‰ | ResNet | CIFAR-10 | â‰¥80% accuracy |
| å…‰å­¦å­—ç¬¦è¯†åˆ«ï¼ˆOptical Digit Recognitionï¼‰ | LeNet-5 | MNIST | â‰¥95% accuracy |
| å¼‚å¸¸æ£€æµ‹ï¼ˆAnomaly Detectionï¼‰ | Autoencoder | ToyADMOS | AUC >85% |
| è§†è§‰å”¤é†’è¯ï¼ˆVisual Wake Wordsï¼‰ | MobileNetV1 | MS-COCO | â‰¥80% accuracy |

æ‰€æœ‰æ¨¡å‹å‡ç»è¿‡structured pruningå’Œ8-bit static quantizationå¤„ç†ï¼Œå¹¶è½¬æ¢ä¸ºONNXæ ¼å¼åç¼–è¯‘è‡³ç›®æ ‡å¹³å°ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼š
  - ARM Cortex-M0+ (RP2040)
  - ARM Cortex-M4 (nRF52840)
  - ARM Cortex-M7 (i.MX RT1062)
- **æµ‹è¯•å¹³å°ç»„ä»¶**ï¼š
  - ATP carrier boardï¼ˆé€šç”¨æ¥å£æ¿ï¼‰
  - Segger J-Link debuggerï¼ˆç”¨äºM0+/M4ç¼–ç¨‹ï¼‰
  - USB-Cçƒ§å½•ï¼ˆç”¨äºM7ï¼‰
  - Power Profiler Kit (PPK) è¿›è¡Œå®æ—¶ç”µæµç›‘æµ‹
  - GPIOåŒæ­¥ä¿¡å·æ ‡è®°inferenceèµ·æ­¢æ—¶é—´
- **ä¾›ç”µç”µå‹**ï¼šæ’å®š3.3V

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡ï¼ˆKPIsï¼‰
| ç±»åˆ« | æŒ‡æ ‡ |
|------|------|
| **æ€§èƒ½** | Inference time (latency), FLOPs |
| **èƒ½æ•ˆ** | Active power, Idle current, Total inference cycle energy (mJ) |
| **èµ„æºå ç”¨** | ROM size (model storage), RAM usage |
| **å‡†ç¡®æ€§** | Accuracy / AUC |
| **ç»¼åˆå†³ç­–** | Pareto front (Energy vs. Accuracy) |

### ğŸ” åŸºçº¿å¯¹æ¯”
è™½ç„¶æœªç›´æ¥å¯¹æ¯”å…¶ä»–ç®—æ³•ç±»â€œåŸºçº¿â€ï¼Œä½†é€šè¿‡è·¨å¤„ç†å™¨æ¶æ„ï¼ˆM0+, M4, M7ï¼‰æ¨ªå‘æ¯”è¾ƒï¼Œæ­ç¤ºäº†ä¸åŒç¡¬ä»¶åœ¨ç›¸åŒæ¨¡å‹ä¸‹çš„è¡¨ç°å·®å¼‚ï¼Œæœ¬è´¨ä¸Šæ„æˆäº†ç¡¬ä»¶å±‚é¢çš„baseline comparisonã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ”¢ å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰æ¨¡å‹å‹ç¼©æ•ˆæœï¼ˆå›¾4ï¼‰
- **é‡åŒ–ï¼ˆquantizationï¼‰ä½¿æ¨¡å‹å¤§å°å¹³å‡ç¼©å°è‡³åŸå§‹çš„çº¦1/4**
- æœ€å°æ¨¡å‹ï¼ˆOptical Digit Recognitionï¼‰ä»…éœ€~10KB ROM
- æœ€å¤§æ¨¡å‹ï¼ˆVisual Wake Wordsï¼‰æœªé‡åŒ–æ—¶è¶…è¿‡1MBï¼Œéƒ¨åˆ†è¶…å‡ºè®¾å¤‡å†…å­˜é™åˆ¶

#### ï¼ˆ2ï¼‰FLOPsä¸æ¨ç†æ—¶é—´çš„å…³ç³»ï¼ˆå›¾5ï¼‰
- åœ¨ä¸‰ç§å¤„ç†å™¨ä¸Šå‡è§‚å¯Ÿåˆ°**å¼ºçº¿æ€§ç›¸å…³æ€§**ï¼ˆRÂ² â‰¥ 0.93ï¼‰
- æ–œç‡åæ˜ å•ä½FLOPæ‰€éœ€æ—¶é—´ï¼š
  - M0+: ~3.62 ms/MFLOPï¼ˆæœ€æ…¢ï¼‰
  - M4: ~1.79 ms/MFLOP
  - M7: ~0.0742 ms/MFLOPï¼ˆæœ€å¿«ï¼Œå¾—ç›ŠäºDSPå¢å¼ºæ¶æ„ï¼‰

> âœ… è¡¨æ˜FLOPså¯ä½œä¸ºinference timeçš„æœ‰æ•ˆé¢„æµ‹å™¨ï¼Œæ”¯æŒæ—©æœŸè®¾è®¡å†³ç­–ã€‚

#### ï¼ˆ3ï¼‰ç©ºé—²ç”µæµå¯¹æ¯”ï¼ˆå…³é”®èƒ½æ•ˆå› ç´ ï¼‰
| Processor | Deep Sleep Current |
|----------|--------------------|
| M0+      | 4.20 mA            |
| M4       | **0.30 mA** âœ…     |
| M7       | 1.60 mA            |

ğŸ‘‰ M4åœ¨é•¿æ—¶é—´idleåœºæ™¯ä¸­å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

#### ï¼ˆ4ï¼‰æ¨ç†å‘¨æœŸèƒ½é‡ vs å‘¨æœŸæ—¶é—´ï¼ˆå›¾7ï¼‰
- **çŸ­å‘¨æœŸï¼ˆ<1sï¼‰**ï¼šM7èƒ½è€—æœ€ä½ â†’ å¿«é€Ÿå®Œæˆä»»åŠ¡ï¼Œå‡å°‘activeåŠŸè€—
- **é•¿å‘¨æœŸï¼ˆ>2.5sï¼‰**ï¼šM4èƒ½è€—æœ€ä½ â†’ æä½idleç”µæµä¸»å¯¼æ€»èƒ½è€—
- M0+åœ¨æ‰€æœ‰åœºæ™¯ä¸‹è¡¨ç°æœ€å·®

#### ï¼ˆ5ï¼‰Energy-Accuracy Pareto Frontåˆ†æï¼ˆå›¾8ï¼‰
- **Cycle = 0.5s**ï¼šM7 Pareto frontå ä¼˜ â†’ åº”ä¼˜å…ˆé€‰æ‹©é«˜é€Ÿã€è½»é‡æ¨¡å‹
- **Cycle = 2.5s / 5.0s**ï¼šM4 Pareto frontå ä¼˜ â†’ å¯é€‰ç”¨æ›´é«˜ç²¾åº¦æ¨¡å‹è€Œä¸æ˜¾è‘—å¢åŠ èƒ½è€—

> âœ… éªŒè¯äº†â€œ**åœ¨idle-dominatedåœºæ™¯ä¸­ï¼Œåº”ç‰ºç‰²é€Ÿåº¦æ¢å–accuracy**â€çš„è®¾è®¡åŸåˆ™ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **æ²¡æœ‰â€œç»å¯¹æœ€ä¼˜â€çš„å¤„ç†å™¨æˆ–æ¨¡å‹**ï¼šæœ€ä½³é€‰æ‹©å–å†³äº**åº”ç”¨çš„inference cycle duration**ï¼ˆå³äº‹ä»¶é¢‘ç‡ï¼‰ã€‚
   - é«˜é¢‘ä»»åŠ¡ï¼ˆâ‰¤0.5sï¼‰â†’ æ¨è **Cortex-M7**ï¼Œè¿½æ±‚æœ€å°åŒ–active time
   - ä½é¢‘ä»»åŠ¡ï¼ˆâ‰¥2.5sï¼‰â†’ æ¨è **Cortex-M4**ï¼Œåˆ©ç”¨å…¶è¶…ä½idleç”µæµ
   - M0+ä¸é€‚åˆå¤æ‚AIè´Ÿè½½ï¼Œä»…é€‚ç”¨äºç®€å•æ§åˆ¶æˆ–éAIåœºæ™¯

2. **FLOPsæ˜¯inference timeçš„è‰¯å¥½é¢„æµ‹æŒ‡æ ‡**ï¼ˆRÂ² > 0.93ï¼‰ï¼Œå¯ç”¨äºæ—©æœŸæ¨¡å‹ç­›é€‰ä¸ååŒè®¾è®¡ã€‚

3. **RAM/ROMä¸æ˜¯èƒ½æ•ˆçš„å¯é é¢„æµ‹å› å­**ï¼Œæ›´å¤šæ˜¯éƒ¨ç½²å¯è¡Œæ€§çº¦æŸã€‚

4. **Paretoåˆ†ææä¾›äº†ç›´è§‚çš„å†³ç­–åœ°å›¾**ï¼Œå¸®åŠ©å¼€å‘è€…åœ¨energyä¸accuracyé—´åšå‡ºåˆç†å–èˆã€‚

5. **æ¨¡å‹ä¼˜åŒ–ç­–ç•¥åº”éšåº”ç”¨åœºæ™¯åŠ¨æ€è°ƒæ•´**ï¼š
   - çŸ­å‘¨æœŸï¼šä¼˜åŒ–latencyä¸ºä¸»
   - é•¿å‘¨æœŸï¼šå¯æ”¾å®½latencyè¦æ±‚ï¼Œä¼˜å…ˆæå‡accuracy

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
1. **å®éªŒå®¤ç¯å¢ƒæµ‹é‡**ï¼šæœªè€ƒè™‘æ¸©åº¦å˜åŒ–ã€å¤–è®¾ä½¿ç”¨ã€é•¿æœŸè€åŒ–ç­‰å› ç´ å¯¹åŠŸè€—çš„å½±å“ã€‚
2. **å¤„ç†å™¨ç§ç±»æœ‰é™**ï¼šä»…è¦†ç›–M0+/M4/M7ï¼Œç»“è®ºå¯èƒ½ä¸é€‚ç”¨äºæ›´æ–°æ¶æ„ï¼ˆå¦‚Cortex-M33/M55ï¼‰æˆ–å¸¦NPUçš„MCUã€‚
3. **FLOPsçº¿æ€§å‡è®¾çš„è¾¹ç•Œæ¡ä»¶æœªçŸ¥**ï¼šå¯¹äºæœ‰å¤æ‚è®¿å­˜æ¨¡å¼æˆ–ç¡¬ä»¶åŠ é€Ÿçš„æ¨¡å‹ï¼Œè¯¥å…³ç³»å¯èƒ½å¤±æ•ˆã€‚
4. **ç¼ºä¹real-world workload driftæµ‹è¯•**ï¼šé™æ€æ•°æ®é›†æ— æ³•æ¨¡æ‹ŸçœŸå®ä¸–ç•Œä¸­çš„åˆ†å¸ƒåç§»ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ ‡å‡†åŒ–idle currentä¸wake-up latencyè¯„æµ‹æ–¹æ³•**ï¼Œä¾¿äºè·¨å¹³å°å…¬å¹³æ¯”è¾ƒã€‚
2. **å¼€å±•é•¿æœŸå®åœ°éƒ¨ç½²å®éªŒ**ï¼ŒéªŒè¯åœ¨ç¯å¢ƒæ‰°åŠ¨ã€è´Ÿè½½æ¼‚ç§»å’Œç¡¬ä»¶é€€åŒ–ä¸‹çš„é²æ£’æ€§ã€‚
3. **æ‰©å±•æ¡†æ¶è‡³æ›´å¤šæ¶æ„ä¸åŠ é€Ÿå™¨ç³»ç»Ÿ**ï¼ˆå¦‚Ethos-U, GAP9, Arduino Nano 33 BLEç­‰ï¼‰ã€‚
4. **é›†æˆmulti-objective Bayesian optimization**ï¼Œå®ç°è‡ªåŠ¨åŒ–çš„æ¨¡å‹-ç¡¬ä»¶è”åˆæœç´¢ã€‚
5. **æ¢ç´¢åŠ¨æ€ç”µå‹é¢‘ç‡è°ƒèŠ‚ï¼ˆDVFSï¼‰å¯¹èƒ½æ•ˆçš„å½±å“**ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–energy-delay productã€‚

---

## æ€»ç»“
è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªé¢å‘å¯æŒç»­åµŒå…¥å¼ç³»ç»Ÿçš„AIæ¨¡å‹åŸºå‡†æµ‹è¯•æ¡†æ¶ï¼Œé¦–æ¬¡ç³»ç»Ÿåœ°æ­ç¤ºäº†**åº”ç”¨æ—¶åºè¡Œä¸ºï¼ˆinference cycle timeï¼‰æ˜¯å†³å®šå¤„ç†å™¨é€‰å‹ä¸æ¨¡å‹ä¼˜åŒ–ç­–ç•¥çš„æ ¸å¿ƒå˜é‡**ã€‚é€šè¿‡å®è¯åˆ†æå’ŒParetoå‰æ²¿å»ºæ¨¡ï¼Œä¸ºå¼€å‘è€…æä¾›äº†ä»ç†è®ºåˆ°å®è·µçš„å®Œæ•´å†³ç­–è·¯å¾„ï¼Œåœ¨æ¨åŠ¨ç»¿è‰²Edge AIå‘å±•æ–¹é¢å…·æœ‰é‡è¦æŒ‡å¯¼æ„ä¹‰ã€‚

</details>

---

### 8. [Entropy-Based Data Selection for Language Models](https://arxiv.org/abs/2602.17465)

**Authors**: Hongming Li, Yang Liu, Chao Huang  
**Category**: cs.CL  
**Published**: 2026-02-20  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.17465v1  

#### Abstract
Modern language models (LMs) increasingly require two critical resources: computational resources and data resources. Data selection techniques can effectively reduce the amount of training data required for fine-tuning LMs. However, their effectiveness is closely related to computational resources,...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠEntropy-Based Data Selection for Language Modelsã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°ä»£ **Language Models (LMs)** åœ¨å¾®è°ƒï¼ˆfine-tuningï¼‰è¿‡ç¨‹ä¸­é¢ä¸´ä¸¤å¤§èµ„æºç“¶é¢ˆï¼š**è®¡ç®—èµ„æº** å’Œ **é«˜è´¨é‡è®­ç»ƒæ•°æ®**ã€‚å°½ç®¡å·²æœ‰å¤šç§ **data selection** æŠ€æœ¯ç”¨äºå‡å°‘è®­ç»ƒæ•°æ®é‡ï¼Œä½†è¿™äº›æ–¹æ³•é€šå¸¸ä¾èµ–é«˜ç®—åŠ›é¢„ç®—ï¼ˆå¦‚æ¢¯åº¦è®¡ç®—ã€ä»£ç†æ¨¡å‹ç­‰ï¼‰ï¼Œéš¾ä»¥åœ¨ **compute-constrained åœºæ™¯** ä¸‹é«˜æ•ˆåº”ç”¨ã€‚æ­¤å¤–ï¼Œåˆæˆæ•°æ®ï¼ˆsynthetic dataï¼‰è™½å¯ç¼“è§£æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼Œä½†å…¶è´¨é‡ä¸å‡ï¼Œä»éœ€æœ‰æ•ˆç­›é€‰ã€‚

æœ¬æ–‡ç³»ç»Ÿæ­ç¤ºäº† **data selection ä¸ä¸ç¡®å®šæ€§ä¼°è®¡ï¼ˆuncertainty estimationï¼‰ä¹‹é—´çš„å…³ç³»**ï¼Œå¹¶æå‡ºä¸€ç§é€‚ç”¨äºåŸå§‹æ•°æ®å’Œåˆæˆæ•°æ®çš„è½»é‡çº§é€‰æ‹©æ¡†æ¶ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šEUDS æ¡†æ¶
ä½œè€…æå‡ºäº† **Entropy-Based Unsupervised Data Selection (EUDS)** æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ˜¯åŸºäºä¸‰ç§ç†µæœºåˆ¶è¿›è¡Œæ— ç›‘ç£æ•°æ®ç­›é€‰ï¼š

- **Information Entropy (IE)**ï¼šåŸºäº n-gram çš„è¯æ³•å¤šæ ·æ€§è¡¡é‡ã€‚
- **Generative Entropy (GE)**ï¼šåŸºäºè¯­è¨€æ¨¡å‹ç”Ÿæˆæ—¶çš„å›°æƒ‘åº¦ï¼ˆperplexityï¼‰è¡¡é‡é¢„æµ‹ä¸ç¡®å®šæ€§ã€‚
- **Semantic Entropy (SE)**ï¼šé€šè¿‡è¯­ä¹‰èšç±»è¡¡é‡ç”Ÿæˆç»“æœçš„è¯­ä¹‰æ­§ä¹‰æ€§ã€‚

è¯¥æ¡†æ¶ä½œä¸º **ç‹¬ç«‹é¢„å¤„ç†æ­¥éª¤**ï¼Œåœ¨å¾®è°ƒå‰å¯¹æ•°æ®è¿›è¡Œè¿‡æ»¤ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š
- **æ¨¡å‹æ— å…³ï¼ˆmodel-agnosticï¼‰**ï¼šé€‚ç”¨äº BERTã€GPT ç­‰å„ç±» LMã€‚
- **æ— éœ€é¢å¤–è®­ç»ƒæˆ–æ¢¯åº¦è®¡ç®—**ï¼šæå¤§é™ä½è®¡ç®—å¼€é”€ã€‚
- **æ”¯æŒåŸå§‹æ•°æ®ä¸åˆæˆæ•°æ®è”åˆç­›é€‰**ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | EUDS ä¼˜åŠ¿ |
|------|-----------|
| **è®¡ç®—æ•ˆç‡** | ä»…éœ€å‰å‘æ¨ç†æˆ–ç»Ÿè®¡è®¡ç®—ï¼Œå¤æ‚åº¦è¿œä½äº influence-based æˆ– gradient-based æ–¹æ³•ï¼ˆå¦‚ Grad-Matchã€Influence Functionsï¼‰ã€‚ |
| **é€‚ç”¨æ€§å¹¿** | åŒæ—¶é€‚ç”¨äºåŸå§‹æ•°æ®å’Œ LLM ç”Ÿæˆçš„åˆæˆæ•°æ®ï¼Œæ”¯æŒæ··åˆç­–ç•¥ã€‚ |
| **æ€§èƒ½ä¿æŒç”šè‡³æå‡** | åœ¨æ˜¾è‘—å‡å°‘æ•°æ®é‡çš„åŒæ—¶ï¼Œå¤šæ•°ä»»åŠ¡ä¸Šæ€§èƒ½æŒå¹³æˆ–ä¼˜äºå…¨é‡æ•°æ®è®­ç»ƒã€‚ |
| **å¯æ‰©å±•æ€§å¼º** | å¯é€šè¿‡å­é›†ç¡®å®šæœ€ä¼˜ç†µåŒºé—´åæ¨å¹¿è‡³å…¨é›†ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡æ•°æ®åœºæ™¯ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–ä¸‰å¤§å…¸å‹æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼Œå…± **11 ä¸ªå…¬å¼€æ•°æ®é›†**ï¼š

| ä»»åŠ¡ç±»åˆ« | æ•°æ®é›† |
|--------|-------|
| **Sentiment Analysis (SA)** | SST-2, SST-5, IMDb, Yelp |
| **Topic Classification (Topic-CLS)** | AGNews, 20News, Yahoo |
| **Question Answering (Q&A)** | RaceQA, MMLU, ARC, MMLU-Pro |

æ‰€æœ‰æ•°æ®é›†å‡æ¥è‡ª Hugging Face æˆ–æ ‡å‡†å­¦æœ¯å‘å¸ƒæºã€‚

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### æ•°æ®å‡†å¤‡
- **åŸå§‹æ•°æ® (OriData)**ï¼šä»å„æ•°æ®é›†ä¸­æå– 2,000 æˆ– 10,000 æ¡æ ·æœ¬ã€‚
- **åˆæˆæ•°æ® (SynData)**ï¼šä½¿ç”¨ **GPT-4o** åŸºäºå°‘é‡ç¤ºä¾‹ç”Ÿæˆï¼Œç¡®ä¿æ ‡ç­¾ä¸€è‡´æ€§å’Œä»»åŠ¡å¯¹é½ã€‚
- åˆ’åˆ†æ¯”ä¾‹ï¼šè®­ç»ƒ:éªŒè¯:æµ‹è¯• = 8:1:1ã€‚

#### å¾®è°ƒæ¨¡å‹
- ä¸»å¹²æ¨¡å‹ï¼š**BERT-base-uncased**
- è¶…å‚æ•°ï¼š
  - Epochs: 10
  - Batch Size: 64
  - Learning Rate: 4e-5
  - Warm-up Ratio: 0.1
  - Weight Decay: 0.1

#### è¯„ä¼°æŒ‡æ ‡
- **Accuracy**
- **F1 Score**
- **æ•°æ®ç¼©å‡ç‡ï¼ˆData Reduction %ï¼‰**

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline**ï¼šä½¿ç”¨å…¨éƒ¨åŸå§‹æ•°æ®æˆ–åˆæˆæ•°æ®è®­ç»ƒã€‚
- **SOTA å¯¹æ¯”æ–¹æ³•**ï¼šåŒ…æ‹¬ BiLSTMã€RoBERTa-BiLSTMã€TWSSentiã€SELECTã€FDKT ç­‰ï¼ˆè§ Table 11ï¼‰ã€‚
- **æ¶ˆèå®éªŒ**ï¼šæ¯”è¾ƒå•ç†µï¼ˆIE/GE/SEï¼‰ã€ç»„åˆç†µï¼ˆIGE/ISE/GSE/IGSEï¼‰åŠä¸åŒæ•°æ®ç»„åˆç­–ç•¥ï¼ˆSumData / JoSelDataï¼‰ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»£è¡¨æ€§ç»“æœï¼‰

| æ–¹æ³• | ä»»åŠ¡ | æ•°æ®ç¼©å‡ç‡ | Accuracy æå‡ | å¤‡æ³¨ |
|------|------|------------|----------------|------|
| **IE** | MMLU-Pro | **84.05%** | +4.00% | OriData ä¸Šæœ€ä½³ |
| **SE** | RaceQA | **71.25%** | +0.40% | æ€§èƒ½æå‡ä¸”å¤§å¹…å‡é‡ |
| **GE** | MMLU | 40.00% | +7.20% | F1 æå‡æ˜¾è‘— |
| **IE** | AGNews | 0.70% | +2.40% | å°å¹…å‡é‡ä½†æ€§èƒ½è·ƒå‡ |

> âœ… åœ¨ **198 ä¸ªæœ€ä¼˜åŒºé—´** ä¸­ï¼Œ**65.66%** çš„åœºæ™¯è¾¾åˆ°æˆ–è¶…è¿‡ baseline æ€§èƒ½ï¼›**15.15%** çš„åœºæ™¯è¯¯å·®åœ¨ 1.5% ä»¥å†…ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ï¼ˆTable 11ï¼‰
| æ–¹æ³• | IMDb Acc (%) | AGNews Acc (%) |
|------|---------------|-----------------|
| BiLSTM | 81.87 | â€” |
| RoBERTa-BiLSTM | 92.46 | â€” |
| TWSSenti | 95.00 | â€” |
| SELECT | 63.79 | 80.05 |
| FDKT | â€” | 75.60 |
| **EUDS (IE)** | **93.60** | **93.60** |
| **EUDS (GE)** | **93.20** | **91.60** |
| **EUDS (SE)** | **93.60** | **91.20** |

ğŸ‘‰ **EUDS åœ¨ç»å¤§å¤šæ•°æƒ…å†µä¸‹ä¼˜äºæˆ–åª²ç¾ SOTA æ–¹æ³•**ï¼Œå°¤å…¶åœ¨ AGNews ä¸Šè¿œè¶… SELECT å’Œ FDKTã€‚

---

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰å•ä¸€ç†µ vs. ç»„åˆç†µï¼ˆTable 9ï¼‰
- **ç»„åˆç†µï¼ˆå¦‚ IGSEï¼‰è¿›ä¸€æ­¥æå‡æ•ˆç‡**ï¼š
  - åœ¨ MMLU ä¸Šï¼ŒIGS Entropy å®ç° **61.25% æ•°æ®ç¼©å‡**ï¼ŒåŒæ—¶ Accuracy æå‡ **4.80%**ã€‚
  - è¡¨æ˜å¤šç»´åº¦ç†µååŒè¯„ä¼°èƒ½æ›´ç²¾å‡†è¯†åˆ«é«˜ä»·å€¼æ ·æœ¬ã€‚

#### ï¼ˆ2ï¼‰æ•°æ®ç»„åˆç­–ç•¥å¯¹æ¯”
| ç­–ç•¥ | æè¿° | æ•ˆæœ |
|------|------|------|
| **SumData** | é€‰ä¸­çš„ SynData + å…¨é‡ OriData | æ˜¾è‘—å‡é‡ï¼Œæ€§èƒ½ç»´æŒæˆ–æå‡ |
| **JoSelData** | é€‰ä¸­çš„ SynData + é€‰ä¸­çš„ OriData | è¿›ä¸€æ­¥å‹ç¼©æ€»é‡ï¼Œéƒ¨åˆ†ä»»åŠ¡ä»ä¼˜äº baseline |

> ç¤ºä¾‹ï¼šåœ¨ MMLU-Pro ä¸Šï¼ŒJoSelData + IGSE å®ç° **63% æ•°æ®ç¼©å‡**ï¼ŒAccuracy æå‡ **6.00%**ã€‚

#### ï¼ˆ3ï¼‰å¤§è§„æ¨¡æ•°æ®éªŒè¯ï¼ˆTable 8ï¼‰
- åœ¨ **10,000 æ¡æ•°æ®è§„æ¨¡**ä¸‹éªŒè¯ EUDS æœ‰æ•ˆæ€§ï¼š
  - SST-5 ä¸Š IE é€‰æ‹©å®ç° **25% æ•°æ®ç¼©å‡**ï¼ŒAccuracy æå‡ **1.28%**ã€‚
  - è¡¨æ˜ EUDS å…·å¤‡è‰¯å¥½çš„ **scalability**ã€‚

#### ï¼ˆ4ï¼‰å­é›†æ¨å¹¿æ³›åŒ–èƒ½åŠ›ï¼ˆTable 10ï¼‰
- åœ¨å°è§„æ¨¡å­é›†ä¸Šç¡®å®šçš„æœ€ä¼˜ç†µåŒºé—´ï¼Œåº”ç”¨äºå®Œæ•´æ•°æ®é›†åä»èƒ½å–å¾—ç›¸è¿‘æ€§èƒ½å¢ç›Šã€‚
- æ”¯æŒâ€œå…ˆç”¨å­é›†å®šåŒºé—´ï¼Œå†æ¨å¹¿åˆ°å…¨é›†â€çš„é«˜æ•ˆç­–ç•¥ï¼Œ**å¤§å¹…èŠ‚çœè°ƒå‚æˆæœ¬**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **ç†µå€¼å¯æœ‰æ•ˆè¡¨å¾æ•°æ®ä»·å€¼**ï¼šé€‚ä¸­æˆ–ç‰¹å®šåŒºé—´çš„ç†µï¼ˆéæä½æˆ–æé«˜ï¼‰å¾€å¾€å¯¹åº”æœ€å…·ä¿¡æ¯é‡çš„æ ·æœ¬ã€‚
2. âœ… **EUDS æ˜¾è‘—é™ä½æ•°æ®éœ€æ±‚**ï¼šå¹³å‡å¯å‡å°‘ **40â€“85%** çš„è®­ç»ƒæ•°æ®ï¼Œè€Œæ€§èƒ½ä¸é™åå‡ã€‚
3. âœ… **æ‰“ç ´â€œæ•°æ®é‡-æ€§èƒ½â€çº¿æ€§ä¾èµ–**ï¼šå°‘é‡é«˜è´¨é‡æ•°æ®å³å¯è¶…è¶Šå…¨é‡æ™®é€šæ•°æ®çš„è¡¨ç°ã€‚
4. âœ… **é€‚ç”¨äºåˆæˆæ•°æ®ç­›é€‰**ï¼šèƒ½æœ‰æ•ˆè¯†åˆ« GPT-4o ç”Ÿæˆä¸­çš„é«˜è´¨é‡æ ·æœ¬ï¼Œè§£å†³åˆæˆæ•°æ®è´¨é‡ä¸å‡é—®é¢˜ã€‚
5. âœ… **è®¡ç®—é«˜æ•ˆä¸”å¯æ‰©å±•**ï¼šæ— éœ€ä¿®æ”¹æ¨¡å‹ç»“æ„æˆ–å¼•å…¥é¢å¤–è®­ç»ƒï¼Œé€‚åˆèµ„æºå—é™åœºæ™¯ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. â— **æ— ç»Ÿä¸€æœ€ä¼˜ç†µåŒºé—´**ï¼šä¸åŒä»»åŠ¡ã€ä¸åŒæ•°æ®ç±»å‹ä¸‹çš„æœ€ä½³ç†µèŒƒå›´å·®å¼‚å¤§ï¼Œéœ€ä»»åŠ¡çº§è°ƒä¼˜ã€‚
2. â— **ç†µåˆ†å¸ƒé›†ä¸­ç°è±¡**ï¼šæŸäº› SynData åœ¨ç‰¹å®šç†µç»´åº¦ä¸Šé«˜åº¦é›†ä¸­ï¼ˆå¦‚ SE é«˜ç†µå æ¯” >99%ï¼‰ï¼Œé™åˆ¶ç­›é€‰ç©ºé—´ã€‚
3. â— **æç«¯å‹ç¼©å¯èƒ½å¯¼è‡´ä¸ç¨³å®š**ï¼šè¿‡åº¦è¿½æ±‚æ•°æ®ç¼©å‡å¯èƒ½å½±å“æ¨¡å‹æ”¶æ•›ç¨³å®šæ€§ã€‚
4. â— **ç†è®ºè§£é‡Šå°šä¸å……åˆ†**ï¼šè™½ç„¶å®è¯æ•ˆæœå¥½ï¼Œä½†å¯¹â€œä¸ºä½•ç‰¹å®šç†µåŒºé—´æœ€ä¼˜â€ç¼ºä¹æ·±å±‚ç†è®ºæ”¯æ’‘ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. ğŸ”„ æ¢ç´¢ **è‡ªé€‚åº”ç†µåŒºé—´é€‰æ‹©æœºåˆ¶**ï¼Œå‡å°‘äººå·¥è°ƒå‚ä¾èµ–ã€‚
2. ğŸ” ç ”ç©¶ **è·¨ä»»åŠ¡è¿ç§»çš„é€šç”¨ç†µæ¨¡å¼**ï¼Œæ„å»ºæ›´æ™®é€‚çš„é€‰æ‹©å‡†åˆ™ã€‚
3. ğŸ§  åŠ å¼º **ç†è®ºå»ºæ¨¡**ï¼Œå»ºç«‹ç†µã€ä¿¡æ¯å¯†åº¦ä¸æ³›åŒ–è¯¯å·®ä¹‹é—´çš„æ•°å­¦è”ç³»ã€‚
4. ğŸŒ æ‰©å±•è‡³å…¶ä»–æ¨¡æ€ï¼ˆå¦‚è¯­éŸ³ã€å›¾åƒï¼‰å’Œä»»åŠ¡ï¼ˆå¦‚ generationã€summarizationï¼‰ã€‚
5. âš™ï¸ ç»“åˆ LLM è‡ªæˆ‘åæ€ï¼ˆself-reflectionï¼‰èƒ½åŠ›ï¼Œå®ç°åŠ¨æ€åé¦ˆå¼æ•°æ®ç­›é€‰ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> EUDS æä¾›äº†ä¸€ç§ **ç®€å•ã€é«˜æ•ˆã€é€šç”¨** çš„æ•°æ®é€‰æ‹©èŒƒå¼ï¼Œåœ¨æ˜¾è‘—é™ä½ LM å¾®è°ƒèµ„æºæ¶ˆè€—çš„åŒæ—¶ï¼Œå®ç°äº† **æ€§èƒ½æŒå¹³ç”šè‡³åè¶…**ï¼Œä¸º compute-constrained åœºæ™¯ä¸‹çš„é«˜æ•ˆ NLP æ¨¡å‹è®­ç»ƒæä¾›äº†åˆ›æ–°è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 9. [Small LLMs for Medical NLP: a Systematic Analysis of Few-Shot, Constraint Decoding, Fine-Tuning and Continual Pre-Training in Italian](https://arxiv.org/abs/2602.17475)

**Authors**: Pietro Ferrazzi, Mattia Franzin, Alberto Lavelli, Bernardo Magnini  
**Category**: cs.CL  
**Published**: 2026-02-20  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.17475v1  

#### Abstract
Large Language Models (LLMs) consistently excel in diverse medical Natural Language Processing (NLP) tasks, yet their substantial computational requirements often limit deployment in real-world healthcare settings. In this work, we investigate whether "small" LLMs (around one billion parameters) can...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Small LLMs for Medical NLP: a Systematic Analysis of Few-Shot, Constraint Decoding, Fine-Tuning and Continual Pre-Training in Italian*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
è¯¥è®ºæ–‡æ¢è®¨äº†ä¸€ä¸ªå…³é”®ç°å®é—®é¢˜ï¼šå°½ç®¡ Large Language Models (LLMs) åœ¨åŒ»ç–— NLP ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶å·¨å¤§çš„è®¡ç®—èµ„æºéœ€æ±‚é™åˆ¶äº†åœ¨çœŸå®åŒ»ç–—ç¯å¢ƒï¼ˆå¦‚åŒ»é™¢ã€è¯Šæ‰€ï¼‰ä¸­çš„éƒ¨ç½²ã€‚å› æ­¤ï¼Œç ”ç©¶è€…æå‡ºå¹¶ç³»ç»Ÿè¯„ä¼°äº†â€œå°è§„æ¨¡è¯­è¨€æ¨¡å‹â€ï¼ˆSmall LLMs, SLLMsï¼‰æ˜¯å¦èƒ½åœ¨ä¿æŒé«˜å‡†ç¡®ç‡çš„åŒæ—¶èƒœä»»æ„å¤§åˆ©è¯­åŒ»å­¦ NLP ä»»åŠ¡ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
- **ç³»ç»Ÿæ€§æ¯”è¾ƒå¤šç§é€‚åº”ç­–ç•¥**ï¼šé¦–æ¬¡å¯¹ SLLMs åœ¨æ„å¤§åˆ©è¯­åŒ»ç–—åœºæ™¯ä¸‹çš„å››ç§ä¸»æµé€‚åº”æ–¹æ³•è¿›è¡Œäº†å…¨é¢å¯¹æ¯”ï¼š
  - **Few-shot Prompting**
  - **Constraint Decoding (CD)**
  - **Supervised Fine-Tuning (FT)**
  - **Continual Pre-Training (CPT) + Fine-Tuning**
- **æ„å»ºå¹¶å¼€æºå¤§è§„æ¨¡æ„å¤§åˆ©è¯­åŒ»ç–—è¯­æ–™åº“**ï¼š
  - å‘å¸ƒäº†é¦–ä¸ª**ç»¼åˆæ€§çš„å…¬å¼€æ„å¤§åˆ©è¯­åŒ»ç–— NLP æ•°æ®é›†é›†åˆ**ã€‚
  - æ„å»ºäº†ä¸€ä¸ªåŒ…å« **300M å•è¯**çš„æ–°æ•°æ®é›†ï¼Œå…¶ä¸­ï¼š
    - **126M æ¥è‡ªæ€¥è¯Šç§‘ç”µå­å¥åº·è®°å½•ï¼ˆEHRï¼‰**
    - **175M æ¥è‡ªç§‘å­¦æ–‡çŒ®å’Œå…¶ä»–æ¥æº**
  - è¿™äº›æ•°æ®ç”¨äº CPTï¼Œæ˜¾è‘—å¢å¼ºäº†æ¨¡å‹çš„é¢†åŸŸçŸ¥è¯†ã€‚
- **æå‡ºé«˜æ•ˆè®­ç»ƒé…ç½®**ï¼šç»“åˆ **LoRA**ã€**Flash Attention 2** å’Œ **sequence packing** æŠ€æœ¯ï¼Œå®ç°é«˜æ•ˆçš„ CPT ä¸ FTã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æˆæœ¬æ•ˆç›Šæ›´é«˜**ï¼šè¯æ˜ç»è¿‡é€‚å½“è°ƒä¼˜çš„å°æ¨¡å‹ï¼ˆ~1B å‚æ•°ï¼‰å¯ä»¥**åŒ¹é…ç”šè‡³è¶…è¶Šé«˜è¾¾ 30 å€å‚æ•°çš„å¤§æ¨¡å‹**ï¼ˆå¦‚ Qwen3-32Bï¼‰ï¼Œä¸ºèµ„æºå—é™æœºæ„æä¾›äº†å¯è¡Œæ–¹æ¡ˆã€‚
- **æ–¹æ³•è®ºæ›´å®Œæ•´**ï¼šä¸ä»…æ¯”è¾ƒæ¨ç†æ—¶æ–¹æ³•ï¼ˆfew-shot, CDï¼‰ï¼Œä¹Ÿæ·±å…¥åˆ†æè®­ç»ƒé˜¶æ®µçš„æ–¹æ³•ï¼ˆFT, CPTï¼‰ï¼Œæ­ç¤ºä¸åŒç­–ç•¥çš„æœ‰æ•ˆè¾¹ç•Œã€‚
- **æ¨åŠ¨æ„å¤§åˆ©è¯­åŒ»ç–— NLP å‘å±•**ï¼šå¡«è¡¥äº†ä½èµ„æºè¯­è¨€åœ¨åŒ»ç–— AI é¢†åŸŸçš„æ•°æ®ä¸æ¨¡å‹ç©ºç™½ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
å…±æ¶‰åŠ **12 ä¸ªæ„å¤§åˆ©è¯­åŒ»ç–—æ•°æ®é›†**ï¼Œæ¶µç›– **20 ä¸ªå­ä»»åŠ¡**ï¼Œåˆ†ä¸ºäº”å¤§ç±»ï¼š

| Task | Datasets | å­ä»»åŠ¡æ•° |
|------|---------|--------|
| **Named Entity Recognition (NER)** | E3C, PharmaER, CardioCCC, DisteMIST, PsyNIT, E3C-projected | 6 |
| **Relation Extraction (RE)** | E3C | 1 |
| **Case Report Form (CRF) Filling** | E3C-based dataset (Ferrazzi et al.) | 3 |
| **Question Answering (QA)** | MedExpQA, AT, MedMCQA, MedQA | 4 |
| **Argument Mining (ARG)** | Casimedicos-Arg | 1 |

> å…¶ä¸­éƒ¨åˆ†æ•°æ®é›†ç”¨äº **out-of-distribution (OOD)** æµ‹è¯•ï¼Œç¡®ä¿æ³›åŒ–èƒ½åŠ›è¯„ä¼°çš„å…¬å¹³æ€§ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹é€‰æ‹©**ï¼šåŸºäº Llama-3, Gemma-3, Qwen3 å®¶æ—ï¼Œé€‰å–çº¦ 1B å‚æ•°çš„ SLLMsï¼š
  - `Llama-3.2-1B` / `Llama-3.2-1B-Instruct`
  - `Gemma-3-1B` / `Gemma-3-1B-Instruct`
  - `Qwen3-1.7B` / `Qwen3-1.7B-Instruct`
- **åŸºçº¿æ¨¡å‹**ï¼š
  - `Qwen3-32B`ï¼ˆ4-shotï¼‰
  - `Medgemma-27B`ï¼ˆ4-shotï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - NER, CRF, ARG, REï¼š**F1 Score (exact match)**
  - QAï¼š**Accuracy**
  - æœ€ç»ˆæŠ¥å‘Š **å¹³å‡å¾—åˆ†ï¼ˆAVGï¼‰**ï¼Œå„ä»»åŠ¡ç­‰æƒé‡ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- æ‰€æœ‰ SLLMs åœ¨é›¶æ ·æœ¬ï¼ˆ0-shotï¼‰ä¸‹è¡¨ç°æå·®ã€‚
- ä¸»è¦å¯¹æ¯”ä»¥ä¸‹æ–¹æ³•ç»„åˆï¼š
  - 0-shot vs 4-shot
  - æ˜¯å¦ä½¿ç”¨ Constraint Decoding
  - æ˜¯å¦è¿›è¡Œ Supervised Fine-Tuning
  - æ˜¯å¦è¿›è¡Œ Continual Pre-Training + FT
- ä»¥ `Qwen3-32B + 4-shot` ä½œä¸ºä¸»è¦æ€§èƒ½åŸºå‡†ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- **æœ€ä½³æ¨¡å‹è¡¨ç°**ï¼š
  - `Qwen3-1.7B + FT` è¾¾åˆ° **AVG = 63.9**
  - è¶…è¿‡åŸºçº¿ `Qwen3-32B + 4-shot`ï¼ˆ54.7ï¼‰**+9.2 åˆ†**
- **å…¶ä»–ä¼˜ç§€é…ç½®**ï¼š
  - `Gemma-3-1b-it + CPT + FT`: 59.4 (+4.7)
  - `Llama-3.2-1B-Instruct + FT`: 59.0 (+4.3)

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| æ–¹æ³• | ç›¸å¯¹äº Qwen3-32B çš„ Î” |
|------|---------------------|
| 0-shot | -54.7 |
| 4-shot | -30.5 ~ -39.9 |
| 4-shot + CD | -17.9 ~ -37.0 |
| **Fine-Tuning (FT)** | **+1.2 ~ +9.2 âœ…** |
| CPT + FT | -0.9 ~ +4.7 |

> âœ… è¡¨æ˜å¤šä¸ª SLLM é…ç½®**æ˜¾è‘—ä¼˜äºæœ€å¤§åŸºçº¿æ¨¡å‹**

### æ¶ˆèå®éªŒç»“æœ
#### æ¨ç†æ—¶æ–¹æ³•ï¼ˆInference-timeï¼‰
| æ–¹æ³• | å¹³å‡æå‡ | æ¨ç†æ—¶é—´å¢åŠ  |
|------|--------|-------------|
| 4-shot vs 0-shot | +9.4 pts | +53% âš ï¸ |
| Constraint Decoding | +3.8 pts | å¯å¿½ç•¥ |
| **4-shot + CD** | **+13.2 pts** | +53% |

> å°ç»“ï¼š**few-shot æ˜¯æœ€æœ‰æ•ˆçš„æ¨ç†ä¼˜åŒ–æ‰‹æ®µ**ï¼›CD å¯¹æ ¼å¼ä¸€è‡´æ€§å¸®åŠ©å¤§ï¼Œä½†å¢ç›Šæœ‰é™ï¼›ä¸¤è€…ç»“åˆæ•ˆæœæœ€ä½³ã€‚

#### è®­ç»ƒæ—¶æ–¹æ³•ï¼ˆTraining-timeï¼‰
| æ–¹æ³• | æ•ˆæœ |
|------|------|
| **Supervised Fine-Tuning (FT)** | **æœ€æœ‰æ•ˆ**ï¼Œåœ¨æ‰€æœ‰æ¨¡å‹ä¸Šå¸¦æ¥å·¨å¤§æå‡ï¼ˆ+40~50 ptsï¼‰ |
| **Continual Pre-Training + FT** | ä»…åœ¨ `Gemma-3-1b-it` ä¸Šä¼˜äºå•ç‹¬ FTï¼Œå…¶ä½™æƒ…å†µä¸‹ç•¥é€Šäºç›´æ¥ FT |

> å°ç»“ï¼š**Fine-Tuning æ˜¯é»„é‡‘æ ‡å‡†**ï¼›CPT æˆæœ¬é«˜ä¸”æ”¶ç›Šä¸ç¨³å®šã€‚

#### ä»»åŠ¡éš¾åº¦åˆ†æ
- **æœ€éš¾ä»»åŠ¡**ï¼šRelation Extractionï¼ˆREï¼‰â€” å°æ¨¡å‹éš¾ä»¥æ•æ‰å¤æ‚å®ä½“å…³ç³»
- **æœ€æ˜“ä»»åŠ¡**ï¼šQuestion Answeringï¼ˆQAï¼‰â€” å› é¢„è®­ç»ƒä¸­å·²æ¥è§¦å¤§é‡ QA æ•°æ®
- **å—ç›Šæœ€å¤šä»»åŠ¡**ï¼šArgument Mining â€” FT å¸¦æ¥æœ€å¤§ç›¸å¯¹æå‡

#### OOD æ³›åŒ–èƒ½åŠ›
- åœ¨æœªè§æ•°æ®é›†ä¸Šï¼Œ**FT æ¨¡å‹ä»ä¼˜äºå…¶å¯¹åº” pre-adaptation ç‰ˆæœ¬**ï¼š
  - `Llama-3.2`:+11.9
  - `Qwen3`: +6.1
  - `Gemma-3`: +3.9
- ä½†**ä»ä½äº Qwen3-32B åŸºçº¿** â†’ å¤§æ¨¡å‹æ³›åŒ–æ›´å¼ºï¼Œå°æ¨¡å‹ä¾èµ–ç‰¹å®šé€‚é…ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. âœ… **Small LLMs å¯ä»¥èƒœè¿‡å¤§æ¨¡å‹**ï¼šé€šè¿‡é€‚å½“çš„é€‚åº”ï¼ˆå°¤å…¶æ˜¯ Fine-Tuningï¼‰ï¼ŒSLLMsï¼ˆ~1B å‚æ•°ï¼‰å¯ä»¥åœ¨å¤šé¡¹æ„å¤§åˆ©è¯­åŒ»ç–— NLP ä»»åŠ¡ä¸Š**è¶…è¶Šå¤šè¾¾ 30 å€å‚æ•°çš„ LLMs**ã€‚
2. ğŸ¥‡ **Fine-Tuning æ˜¯æœ€æœ‰æ•ˆç­–ç•¥**ï¼šæ— è®ºä»æ€§èƒ½è¿˜æ˜¯ç¨³å®šæ€§çœ‹ï¼ŒSupervised Fine-Tuning éƒ½æ˜¯æœ€å¯é çš„è·¯å¾„ã€‚
3. âš–ï¸ **CPT æ”¶ç›Šæœ‰é™**ï¼šContinual Pre-Training æˆæœ¬é«˜æ˜‚ï¼Œä½†åœ¨å¤šæ•°æƒ…å†µä¸‹ä¸å¦‚ç›´æ¥ Fine-Tuning æœ‰æ•ˆï¼Œä»…åœ¨ç‰¹å®šæ¨¡å‹ä¸Šæœ‰å¢ç›Šã€‚
4. ğŸ”§ **æ¨ç†æ—¶ä¼˜åŒ–æœ‰ç”¨ä½†ä¸è¶³**ï¼š4-shot + Constraint Decoding æ˜¯ä½æˆæœ¬æ›¿ä»£æ–¹æ¡ˆï¼Œé€‚åˆæ— æ³•è®­ç»ƒçš„åœºæ™¯ï¼Œä½†ä»è¿œä¸åŠ FTã€‚
5. ğŸŒ **æ³›åŒ–èƒ½åŠ›ä»æ˜¯æŒ‘æˆ˜**ï¼šè™½ç„¶ FT æå‡ OOD æ€§èƒ½ï¼Œä½†å°æ¨¡å‹åœ¨è·¨æ•°æ®é›†è¿ç§»ä¸Šä»å¼±äºå¤§æ¨¡å‹ï¼Œè¯´æ˜å½“å‰ä¼˜åŠ¿ä¾èµ–äºä»»åŠ¡/æ•°æ®å¯¹é½ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **è¯­è¨€é™åˆ¶**ï¼šä»…é’ˆå¯¹æ„å¤§åˆ©è¯­ï¼Œç»“è®ºæ˜¯å¦é€‚ç”¨äºå…¶ä»–è¯­è¨€å°šä¸æ˜ç¡®ã€‚
- **OOD è¯„ä¼°ä¿å®ˆ**ï¼šæœªå¯¹ OOD æ•°æ®å¾®è°ƒï¼Œå¯èƒ½ä½ä¼°æ½œåŠ›ï¼Œä½†ä¹Ÿä¿è¯äº†è¯„ä¼°å…¬æ­£æ€§ã€‚
- **ä»»åŠ¡ä¸å¹³è¡¡**ï¼šQA æ•°æ®é‡å¤šä¸”ç®€å•ï¼Œå¯èƒ½å½±å“æ•´ä½“å¹³å‡åˆ†çš„ä»£è¡¨æ€§ã€‚
- **æœªæ¢ç´¢å¼ºåŒ–å­¦ä¹ ç­‰é«˜çº§æ–¹æ³•**ï¼šä»…è¦†ç›–ä¸»æµé€‚åº”æŠ€æœ¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³å¤šè¯­è¨€ä¸è·¨è¯­è¨€è¿ç§»åœºæ™¯ã€‚
- æ¢ç´¢æ›´é«˜æ•ˆçš„ CPT ç­–ç•¥ï¼ˆå¦‚ curriculum learning, domain mixingï¼‰ã€‚
- å¼•å…¥ Reinforcement Learning from Human Feedback (RLHF) æˆ–ä¸“å®¶åé¦ˆè¿›ä¸€æ­¥ä¼˜åŒ–è¾“å‡ºè´¨é‡ã€‚
- å¼€å‘è½»é‡åŒ–æ¨ç†æ¡†æ¶ï¼Œä½¿ SLLMs æ›´æ˜“äºä¸´åºŠé›†æˆä¸éƒ¨ç½²ã€‚

--- 

> **ä¸€å¥è¯æ€»ç»“**ï¼š  
> æœ¬æ–‡è¯æ˜ï¼Œ**ç²¾å¿ƒè°ƒä¼˜çš„å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLLMsï¼‰æ˜¯åŒ»ç–— NLP ä¸­æå…·ç«äº‰åŠ›ä¸”èµ„æºå‹å¥½çš„è§£å†³æ–¹æ¡ˆ**ï¼Œå°¤å…¶åœ¨ Fine-Tuning çš„åŠ æŒä¸‹å¯è¶…è¶Šå·¨å‹æ¨¡å‹ï¼Œä¸ºèµ„æºå—é™ç¯å¢ƒæä¾›äº†åˆ‡å®å¯è¡Œçš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 10. [Retrospective In-Context Learning for Temporal Credit Assignment with Large Language Models](https://arxiv.org/abs/2602.17497)

**Authors**: Wen-Tse Chen, Jiayu Chen, Fahim Tajwar, Hao Zhu, Xintong Duan, Ruslan Salakhutdinov, Jeff Schneider  
**Category**: cs.LG  
**Published**: 2026-02-20  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.17497v1  

#### Abstract
Learning from self-sampled data and sparse environmental feedback remains a fundamental challenge in training self-evolving agents. Temporal credit assignment mitigates this issue by transforming sparse feedback into dense supervision signals. However, previous approaches typically depend on learnin...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šRetrospective In-Context Learning for Temporal Credit Assignment with Large Language Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹**åœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆonline RLï¼‰ä¸­ç¨€ç–å¥–åŠ±ï¼ˆsparse rewardsï¼‰å¯¼è‡´çš„å­¦ä¹ æ•ˆç‡ä½ä¸‹å’Œè®­ç»ƒä¸ç¨³å®š**è¿™ä¸€æ ¸å¿ƒæŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨å¤šè½®å†³ç­–ä»»åŠ¡ï¼ˆmulti-turn decision-makingï¼‰ä¸­ï¼Œç¯å¢ƒåé¦ˆæå°‘ä¸”å»¶è¿Ÿä¸¥é‡ï¼Œéš¾ä»¥è¿›è¡Œæœ‰æ•ˆçš„**æ—¶åºä¿¡ç”¨åˆ†é…ï¼ˆtemporal credit assignmentï¼‰**ã€‚

ä¼ ç»Ÿæ–¹æ³•ä¾èµ–äºä»é›¶å¼€å§‹è®­ç»ƒä»·å€¼å‡½æ•°ï¼ˆvalue functionï¼‰æˆ–ä¼˜åŠ¿å‡½æ•°ï¼ˆadvantage functionï¼‰ï¼Œè¿™é€šå¸¸éœ€è¦å¤§é‡æ ·æœ¬ï¼Œæ³›åŒ–èƒ½åŠ›å·®ï¼Œå°¤å…¶åœ¨è¯­è¨€æ¡ä»¶ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

ä½œè€…æå‡ºäº†ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š

#### ï¼ˆ1ï¼‰**Retrospective In-Context Learning (RICL)**  
- åˆ©ç”¨é¢„è®­ç»ƒçš„ **Large Language Model (LLM)** ä½œä¸ºç­–ç•¥ï¼ˆpolicyï¼‰å’Œåæ€å™¨ï¼ˆreflectorï¼‰ã€‚
- åœ¨æ¯ä¸ªæ—¶é—´æ­¥ $t$ï¼Œåˆ©ç”¨äº‹åè½¨è¿¹ï¼ˆhindsight trajectoryï¼‰é€šè¿‡ä¸€ä¸ª **LLM reflector** ç”Ÿæˆ**è‡ªç„¶è¯­è¨€å½¢å¼çš„åé¦ˆï¼ˆverbal feedbackï¼‰**ã€‚
- å°†è¯¥åé¦ˆåµŒå…¥åŸå§‹ç­–ç•¥çš„ prompt ä¸­ï¼Œå¾—åˆ°ä¸€ä¸ªä¸Šä¸‹æ–‡å†…æ›´æ–°åçš„ç­–ç•¥ $\pi'$ã€‚
- é€šè¿‡æ¯”è¾ƒåŸå§‹ç­–ç•¥ $\pi_0(a|s)$ å’Œæ›´æ–°åç­–ç•¥ $\pi'(a|s)$ çš„ **log-probability å·®å¼‚**ï¼Œç†è®ºæ¨å¯¼å‡ºå…¶ä¸**ä¼˜åŠ¿å‡½æ•° $A(s,a)$ æˆæ­£æ¯”**ï¼š
  $$
  \beta \log \frac{\pi'(a|s)}{\pi_0(a|s)} \propto A_{\pi_0}(s,a)
  $$
- è¿™ç§æ–¹å¼å°†ç¨€ç–çš„ç¯å¢ƒå¥–åŠ±è½¬åŒ–ä¸ºå¯†é›†çš„ç›‘ç£ä¿¡å·ï¼ˆå³ä¼˜åŠ¿å‡½æ•°ä¼°è®¡ï¼‰ï¼Œå®ç°é«˜æ•ˆçš„ä¿¡ç”¨åˆ†é…ã€‚

#### ï¼ˆ2ï¼‰**Retrospective In-Context Online Learning (RICOL)**  
- ä¸€ä¸ªå®Œæ•´çš„åœ¨çº¿å­¦ä¹ æ¡†æ¶ï¼Œç»“åˆ RICL çš„ä¿¡ç”¨åˆ†é…ç»“æœè¿›è¡Œç­–ç•¥ä¼˜åŒ–ã€‚
- ä½¿ç”¨ **Advantage Weighted Regression (AWR)** é£æ ¼çš„ç›®æ ‡å‡½æ•°æ¥æ›´æ–° LLM å‚æ•°ï¼š
  $$
  \min_\pi \mathbb{E}_{s \sim d_k} \left[ D_{KL}\left( \cdot \,\middle|\, \pi(\cdot|s) \odot \exp\left((1-\alpha)\log\pi_k(\cdot|s) + \alpha\log\pi'(\cdot|s)\right) \right) \right]
  $$
- å¼•å…¥**ä¿¡ä»»åŒºåŸŸï¼ˆtrust regionï¼‰æœºåˆ¶**ï¼Œé˜²æ­¢å› å™ªå£°åé¦ˆå¯¼è‡´ç­–ç•¥å´©æºƒï¼Œæå‡ç¨³å®šæ€§ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ ·æœ¬æ•ˆç‡** | æ˜¾è‘—é«˜äºä¼ ç»Ÿ RL æ–¹æ³•ï¼ˆå¦‚ PPOï¼‰ï¼Œåœ¨ BabyAI ä¸Šè¾¾åˆ°åŒç­‰æ€§èƒ½æ‰€éœ€ç¯å¢ƒæ­¥æ•°å‡å°‘ **10â€“50 å€**ã€‚ |
| **æ— éœ€é¢å¤–ç½‘ç»œ** | ä¸éœ€è¦è®­ç»ƒ critic æˆ– reflector ç½‘ç»œï¼Œç›´æ¥åˆ©ç”¨å†»ç»“çš„ LLM è¿›è¡Œåæ€ã€‚ |
| **ç»†ç²’åº¦åé¦ˆ** | æ¯ä¸ªçŠ¶æ€ç‹¬ç«‹ç”Ÿæˆåé¦ˆï¼Œè€Œéæ•´ä¸ªè½¨è¿¹ç»Ÿä¸€åé¦ˆï¼Œæ”¯æŒæ›´ç²¾ç¡®çš„ä¿¡ç”¨åˆ†é…ã€‚ |
| **æ³›åŒ–æ€§å¼º** | åˆ©ç”¨ LLM çš„å…ˆéªŒçŸ¥è¯†ï¼Œé¿å…ä»é›¶å­¦ä¹ ï¼Œé€‚ç”¨äºå¤æ‚è¯­è¨€æ¡ä»¶ä»»åŠ¡ã€‚ |
| **ç†è®ºæ”¯æ’‘å¼º** | å»ºç«‹äº† in-context update ä¸ KL æ­£åˆ™åŒ–ç­–ç•¥æ›´æ–°ä¹‹é—´çš„ç†è®ºè”ç³»ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **1D Key-Door Environment**ï¼šè‡ªå®šä¹‰çš„ä¸€ç»´ç½‘æ ¼ä¸–ç•Œï¼Œç”¨äºéªŒè¯ä¼˜åŠ¿å‡½æ•°ä¼°è®¡çš„å‡†ç¡®æ€§ï¼Œå¯è®¡ç®— ground-truth advantageã€‚
- **BabyAI å¹³å°ä¸Šçš„å››ä¸ªä»»åŠ¡**ï¼š
  - `goto`ï¼šå¯¼èˆªåˆ°æŒ‡å®šå¯¹è±¡
  - `pickup`ï¼šæ‹¾å–æŒ‡å®šå¯¹è±¡
  - `pick_up_seq_go_to`ï¼šæŒ‰é¡ºåºæ‹¾å–å¹¶å‰å¾€ç›®æ ‡
  - `open`ï¼šæ‰“å¼€é—¨
- æ‰€æœ‰è¾“å…¥è¾“å‡ºå‡ä¸ºæ–‡æœ¬å½¢å¼ï¼ŒåŠ¨ä½œç©ºé—´ç¦»æ•£ï¼ˆ6ä¸ªåŠ¨ä½œï¼šTurn Left/Right, Move Forward, Pickup, Drop, Toggleï¼‰ã€‚

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

| è®¾ç½®é¡¹ | æè¿° |
|-------|------|
| **Actor LLM** | LLaMA-3.1-8B-Instruct / Llama-3.2-3B-Instruct |
| **Reflector LLM** | GPT-4o mini |
| **ç¯å¢ƒå¯è§æ€§** | Partially observableï¼ˆ7x7è§†é‡ï¼‰ |
| **æœ€å¤§å›åˆé•¿åº¦** | goto/pickup: 16ï¼›å…¶ä»–: 32 |
| **å¥–åŠ±æœºåˆ¶** | ç¨€ç–äºŒå€¼å¥–åŠ±ï¼ˆä»…æˆåŠŸæ—¶+1ï¼‰ |
| **è¯„ä¼°æŒ‡æ ‡** | 
| - æˆåŠŸç‡ï¼ˆSuccess Rateï¼‰ | ä¸»è¦æ€§èƒ½æŒ‡æ ‡ |
| - ç¯å¢ƒäº¤äº’æ­¥æ•°ï¼ˆEnvironment Stepsï¼‰ | è¡¡é‡æ ·æœ¬æ•ˆç‡ |
| - è®­ç»ƒæ—¶é—´ï¼ˆTraining Timeï¼‰ | è¡¨ 2 æä¾›è¯¦ç»†æ•°æ® |
| - è¯¯å·®æ¡ï¼ˆError Barsï¼‰ | æŠ¥å‘Šä¸‰ç»„éšæœºç§å­çš„æ ‡å‡†å·® |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
1. **GPT-4o mini**ï¼šé›¶æ ·æœ¬æ€§èƒ½åŸºå‡†ï¼ŒåŒæ—¶ä¹Ÿæ˜¯ reflectorã€‚
2. **Reflexion** [Shinn et al., 2024]ï¼šåŸºäº in-context è‡ªæˆ‘åæ€çš„æ–¹æ³•ï¼Œä½¿ç”¨è½¨è¿¹çº§åé¦ˆè¿­ä»£æ”¹è¿›ã€‚
3. **PPO (3B)**ï¼šåŸºäº Qwen2.5-3B-Instruct çš„ PPOï¼Œpolicy ä¸ critic å…±äº« backboneã€‚
4. **PPO (10M)**ï¼šå°å‹ MLP ç½‘ç»œä»å¤´è®­ç»ƒï¼Œæµ‹è¯•æ˜¯å¦ LLM å…ˆéªŒçŸ¥è¯†æœ‰æ•ˆã€‚
5. **RWR**ï¼ˆReward-Weighted Regressionï¼‰ï¼šç›´æ¥ä½¿ç”¨è½¨è¿¹çº§å¥–åŠ±è¿›è¡Œ AWR æ›´æ–°ï¼Œæ— æ—¶åºä¿¡ç”¨åˆ†é…ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### âœ… **RQ1: RICL çš„ä¿¡ç”¨åˆ†é…æ•ˆç‡æé«˜**
- åœ¨ 1D Key-Door ç¯å¢ƒä¸­ï¼ŒRICL ä¼°è®¡ä¼˜åŠ¿å‡½æ•°çš„è¯¯å·®è¿œä½äº Monte Carlo æ–¹æ³•ã€‚
- è¾¾åˆ°ç›¸åŒç²¾åº¦ï¼ŒRICL ä»…éœ€çº¦ **10 æ¡è½¨è¿¹**ï¼Œè€Œ MC éœ€è¦ **~1000 æ¡** â†’ **æ ·æœ¬æ•ˆç‡æå‡è¶…è¿‡ 100Ã—**ï¼ˆè§å›¾2ï¼‰ã€‚

#### âœ… **RQ2: RICL æ›´å¯é ï¼Œä¸” RICOL å¯¹å™ªå£°é²æ£’**
- åœ¨ BabyAI goto ä»»åŠ¡ä¸Šï¼ŒRICL æ¯”æ ‡å‡† ICLï¼ˆè·¨è½¨è¿¹æ›´æ–°ï¼‰å‡†ç¡®ç‡é«˜ **7.2%**ï¼ˆå›¾3ï¼‰ï¼Œè¯æ˜â€œå›é¡¾å¼â€æ›´æ–°æ›´ç¨³å®šå¯é ã€‚
- å³ä½¿åé¦ˆå‡†ç¡®ç‡ä¸‹é™è‡³ **70%**ï¼ŒRICOL ä»èƒ½ä¿æŒè‰¯å¥½æ€§èƒ½ï¼ˆå›¾6ï¼‰ï¼Œè¡¨æ˜å…¶å¯¹å™ªå£°åé¦ˆå…·æœ‰é²æ£’æ€§ã€‚

#### âœ… **RQ3: RICOL æ ·æœ¬æ•ˆç‡æ˜¾è‘—ä¼˜äºåŸºçº¿**
- åœ¨å››ä¸ª BabyAI ä»»åŠ¡ä¸Šï¼ŒRICOL åœ¨ **1,000â€“10,000 ç¯å¢ƒæ­¥å†…å¿«é€Ÿæ”¶æ•›**ï¼Œè€Œå…¶ä»–æ–¹æ³•å°šæœªèµ·æ­¥ã€‚
- ç›¸æ¯” PPO(3B) å¿« **~10Ã—**ï¼Œç›¸æ¯” PPO(10M) å¿« **~50Ã—**ï¼ˆå›¾4ï¼‰ã€‚
- è¶…è¶Š GPT-4o mini çš„æœ€ç»ˆæˆåŠŸç‡ï¼Œå°½ç®¡ä½¿ç”¨çš„æ˜¯æ›´å°çš„ LLaMA-3.2-3B æ¨¡å‹ï¼Œè¯´æ˜**äº¤äº’å¼å­¦ä¹ ä¼˜äºçº¯æ¨¡ä»¿**ã€‚

#### ğŸ” æ¶ˆèå®éªŒä¸å…³é”®å‘ç°
- **RWR vs RICOL**ï¼ˆå›¾5ï¼‰ï¼šRWR ç¼ºä¹æ—¶åºä¿¡ç”¨åˆ†é…ï¼Œåœ¨ç¨€ç–å¥–åŠ±ä»»åŠ¡ä¸­è¡¨ç°å·®ï¼Œé™¤éåˆå§‹ç­–ç•¥å·²è¾ƒå¼ºï¼ˆå¦‚ gotoï¼‰ã€‚RICOL å› ç”Ÿæˆå¯†é›†ä¿¡å·è€Œæ›´å…·é€šç”¨æ€§ã€‚
- **Verbal Feedback å‡†ç¡®æ€§å½±å“**ï¼ˆå›¾6ï¼‰ï¼šå³ä½¿åé¦ˆä¸ºéšæœºï¼ˆ50%å‡†ç¡®ç‡ï¼‰ï¼ŒRICOL æ€§èƒ½æœªå®Œå…¨å´©æºƒï¼Œå¾—ç›Šäº trust region è®¾è®¡ã€‚
- **Critical State Identification**ï¼ˆå›¾13ï¼‰ï¼šRICL èƒ½è¯†åˆ«å‡ºâ€œç§»åŠ¨å‘é’¥åŒ™â€é˜¶æ®µä¸­çš„å…³é”®çŠ¶æ€ï¼Œè€Œä»…é  LLM åˆ¤æ–­çš„å…³é”®çŠ¶æ€æ–¹æ³•åªèƒ½è¯†åˆ«â€œæ¡èµ·é’¥åŒ™â€è¿™ä¸€æ˜¾æ€§åŠ¨ä½œã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **LLM çš„é¢„è®­ç»ƒçŸ¥è¯†å¯ç”¨äºé«˜æ•ˆæ—¶åºä¿¡ç”¨åˆ†é…**ï¼šé€šè¿‡ in-context learning å’Œ log-probability å·®å¼‚ï¼Œå¯ä»¥é«˜è´¨é‡åœ°ä¼°è®¡ä¼˜åŠ¿å‡½æ•°ã€‚
2. **å›é¡¾å¼æ›´æ–°ï¼ˆretrospective updateï¼‰ä¼˜äºé€šç”¨å¼æ›´æ–°**ï¼šåªåœ¨äº§ç”Ÿåé¦ˆçš„è½¨è¿¹ä¸Šæ›´æ–°ç­–ç•¥ï¼Œé¿å…é”™è¯¯æ³›åŒ–ï¼Œæé«˜å¯é æ€§ã€‚
3. **RICOL æå¤§åœ°æå‡äº†æ ·æœ¬æ•ˆç‡**ï¼šåœ¨è¯­è¨€æ¡ä»¶ç¨€ç–å¥–åŠ±ä»»åŠ¡ä¸­ï¼Œä»¥æå°‘é‡ç¯å¢ƒäº¤äº’å³å¯è¾¾åˆ°ç”šè‡³è¶…è¶Šä¼ ç»Ÿ RL æ–¹æ³•çš„æ€§èƒ½ã€‚
4. **æ–¹æ³•å¯¹å™ªå£°åé¦ˆå…·å¤‡é²æ£’æ€§**ï¼štrust region è®¾è®¡æœ‰æ•ˆæŠ‘åˆ¶äº†ä½è´¨é‡åé¦ˆçš„å½±å“ï¼Œä½¿å¾—ç³»ç»Ÿå¯åœ¨ä¸å®Œç¾æ¡ä»¶ä¸‹æŒç»­å­¦ä¹ ã€‚

---

### å±€é™æ€§
- **ä»…æ”¯æŒç¦»æ•£æœ‰é™åŠ¨ä½œç©ºé—´**ï¼šå› éœ€æšä¸¾æ‰€æœ‰åŠ¨ä½œè®¡ç®—å½’ä¸€åŒ–é¡¹ $Z(s)$ã€‚å¯¹äºé•¿æ€ç»´é“¾ï¼ˆCoTï¼‰ç­‰è¿ç»­è¾“å‡ºåœºæ™¯ä¸é€‚ç”¨ã€‚
- **ä¾èµ–é«˜è´¨é‡ reflector LLM**ï¼šè™½ç„¶æœªå¾®è°ƒï¼Œä½† reflector çš„æ¨ç†èƒ½åŠ›ç›´æ¥å½±å“åé¦ˆè´¨é‡ã€‚
- **å½“å‰æœªæ‰©å±•åˆ° token-level MDP**ï¼šæœªæ¥å¯æ¢ç´¢åœ¨æ¨ç†è¿‡ç¨‹ä¸­è¿›è¡Œç»†ç²’åº¦ä¿¡ç”¨åˆ†é…ã€‚
- **è®¡ç®—å¼€é”€è¾ƒé«˜**ï¼šæ¯æ¬¡ç­–ç•¥è¯„ä¼°éœ€å¤šæ¬¡è°ƒç”¨ LLMï¼ˆå°¤å…¶æ˜¯ enumerate action æ—¶ï¼‰ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† RICL/RICOL æ‰©å±•è‡³ **token-level å†³ç­–è¿‡ç¨‹**ï¼Œåº”ç”¨äºå¤æ‚æ¨ç†ä»»åŠ¡ã€‚
- æ¢ç´¢ **action sampling æ›¿ä»£ action enumeration**ï¼Œä»¥æ”¯æŒæ›´å¤§æˆ–è¿ç»­åŠ¨ä½œç©ºé—´ã€‚
- ç»“åˆ **memory mechanism** å®ç°é•¿æœŸç»éªŒå¤ç”¨ã€‚
- æ¢ç´¢ **multi-agent setting** ä¸‹çš„åä½œå¼åæ€ä¸ä¿¡ç”¨åˆ†é…ã€‚
- ç ”ç©¶å¦‚ä½•è¿›ä¸€æ­¥é™ä½å¯¹ reflector LLM çš„ä¾èµ–ï¼Œä¾‹å¦‚é€šè¿‡ self-bootstrapping æ–¹å¼ç”Ÿæˆåé¦ˆã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡º **RICL + RICOL** æ¡†æ¶ï¼Œé¦–æ¬¡å°† LLM çš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ç³»ç»Ÿæ€§åœ°ç”¨äº**æ—¶åºä¿¡ç”¨åˆ†é…**ï¼Œå®ç°äº†**è¶…é«˜æ ·æœ¬æ•ˆç‡çš„åœ¨çº¿å¼ºåŒ–å­¦ä¹ **ï¼Œä¸ºæ„å»ºèƒ½å¤Ÿè‡ªæˆ‘è¿›åŒ–çš„ LLM Agent æä¾›äº†ä¸€æ¡å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 11. [DeepContext: Stateful Real-Time Detection of Multi-Turn Adversarial Intent Drift in LLMs](https://arxiv.org/abs/2602.16935)

**Authors**: Justin Albrethsen, Yash Datta, Kunal Kumar, Sharath Rajasekar  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.16935v1  

#### Abstract
While Large Language Model (LLM) capabilities have scaled, safety guardrails remain largely stateless, treating multi-turn dialogues as a series of disconnected events. This lack of temporal awareness facilitates a "Safety Gap" where adversarial tactics, like Crescendo and ActorAttack, slowly bleed ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠDeepContext: Stateful Real-Time Detection of Multi-Turn Adversarial Intent Drift in LLMsã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å®‰å…¨é˜²æŠ¤æœºåˆ¶å¤§å¤šæ˜¯**stateless**ï¼ˆæ— çŠ¶æ€ï¼‰çš„ï¼Œå³åœ¨å¤šè½®å¯¹è¯ä¸­å°†æ¯ä¸€è½®è§†ä¸ºç‹¬ç«‹äº‹ä»¶è¿›è¡Œå®‰å…¨æ£€æµ‹ã€‚è¿™ç§è®¾è®¡å¯¼è‡´äº†â€œ**Safety Gap**â€â€”â€”æ”»å‡»è€…åˆ©ç”¨å¦‚ **Crescendo** å’Œ **ActorAttack** ç­‰æ¸è¿›å¼æ”»å‡»ç­–ç•¥ï¼Œåœ¨å¤šä¸ªçœ‹ä¼¼æ— å®³çš„å¯¹è¯å›åˆä¸­é€æ­¥ç´¯ç§¯æ¶æ„æ„å›¾ï¼Œæœ€ç»ˆç»•è¿‡é™æ€è¿‡æ»¤å™¨ã€‚

è¿™ç±»â€œæ…¢çƒ­å‹â€æ”»å‡»ä¸ä¾èµ–å•æ¬¡å¼ºå¯¹æŠ—æç¤ºï¼Œè€Œæ˜¯é€šè¿‡**è¯­ä¹‰æ¼‚ç§»**ï¼ˆsemantic driftï¼‰å’Œ**é€’å½’ä¿¡ä»»**ï¼ˆrecursive trustï¼‰æœºåˆ¶ï¼Œä½¿æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡ä¸­è‡ªç„¶åœ°æ¥å—æœ‰å®³è¯·æ±‚ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡º **DeepContext**ï¼Œä¸€ç§**æœ‰çŠ¶æ€**ï¼ˆstatefulï¼‰çš„å®æ—¶ç›‘æ§æ¡†æ¶ï¼Œç”¨äºè¿½è¸ªç”¨æˆ·æ„å›¾çš„æ—¶åºæ¼”åŒ–è½¨è¿¹ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†å®‰å…¨æ£€æµ‹å»ºæ¨¡ä¸ºä¸€ä¸ª**çŠ¶æ€ç©ºé—´é—®é¢˜**ï¼Œè€Œéå­¤ç«‹çš„åˆ†ç±»ä»»åŠ¡ã€‚

#### åˆ›æ–°æ¶æ„ï¼š
- **Turn-Level Embedding Extraction**ï¼šä½¿ç”¨è½»é‡çº§ç¼–ç å™¨ï¼ˆfine-tuned BERTï¼‰æå–æ¯è½®å¯¹è¯çš„é«˜ç»´è¯­ä¹‰åµŒå…¥ï¼Œå¹¶å¼•å…¥ **Task-Attention Mechanism** å¯¹ä¸å®‰å…¨æ”¿ç­–ç›¸å…³çš„å…³é”®è¯è¿›è¡ŒåŠ æƒï¼Œå¢å¼ºä¿¡å·æ•æ„Ÿåº¦ã€‚
- **Recurrent Intent Tracking (RIT)**ï¼šé‡‡ç”¨ **Gated Recurrent Unit (GRU)** æ„å»ºéšçŠ¶æ€ $ h_t $ï¼ŒæŒç»­æ›´æ–°å¹¶è®°å¿†å¯¹è¯ä¸­çš„é£é™©ç§¯ç´¯è¿‡ç¨‹ã€‚
- **Hybrid Residual Architecture**ï¼šèåˆå½“å‰è½®æ¬¡çš„åŸå§‹åµŒå…¥ $ e_t $ ä¸å†å²çŠ¶æ€æŠ•å½± $ \phi(h_{t-1}) $ å½¢æˆæœ€ç»ˆé£é™©å‘é‡ $ R_t = [\phi(h_{t-1}); e_t] $ï¼Œå®ç°å¯¹â€œå³æ—¶æ”»å‡»â€å’Œâ€œé•¿æœŸæ¼‚ç§»â€çš„åŒé‡æ£€æµ‹èƒ½åŠ›ã€‚
- **Trajectory Classifier**ï¼šåŸºäº MLP çš„åˆ†ç±»å¤´ç»“åˆ **Focal Loss** å¤„ç†ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼Œæå‡å¯¹è¾¹ç•Œæ ·æœ¬çš„å­¦ä¹ èƒ½åŠ›ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ Llama Guard, Granite Guardianï¼‰ | DeepContext |
|------|------------------------------------------|-----------|
| **çŠ¶æ€æ€§** | Statelessï¼Œæ¯æ¬¡é‡æ–°å¤„ç†å®Œæ•´å¯¹è¯å†å² | Statefulï¼Œç»´æŠ¤éšçŠ¶æ€è·Ÿè¸ªæ„å›¾æ¼”åŒ– |
| **è®¡ç®—æ•ˆç‡** | éšå¯¹è¯é•¿åº¦å‘ˆäºŒæ¬¡å¢é•¿ï¼ˆself-attentionï¼‰ï¼Œå»¶è¿Ÿé«˜ | æ¯è½®ä»…å¤„ç†å½“å‰åµŒå…¥ + GRU æ›´æ–°ï¼Œå»¶è¿Ÿæ’å®š |
| **æ£€æµ‹èƒ½åŠ›** | æ˜“è¢«åˆ†æ•£å¼æ”»å‡»æ¬ºéª—ï¼Œéš¾ä»¥æ•æ‰â€œæ¸è¿›æ¼‚ç§»â€ | å¯è¯†åˆ«â€œintent driftâ€ï¼Œæå‰é¢„è­¦ |
| **éƒ¨ç½²æˆæœ¬** | é€šå¸¸éœ€å¤§å‚æ•°é‡æ¨¡å‹ï¼ˆ7B+ï¼‰ï¼Œèµ„æºæ¶ˆè€—å¤§ | è½»é‡åŒ–è®¾è®¡ï¼Œå¯åœ¨ T4 GPU ä¸Šå®ç° <20ms æ¨ç† |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
#### è®­ç»ƒæ•°æ®é›†ï¼ˆå…±çº¦ 437k æ¡å¯¹è¯åºåˆ—ï¼Œ20% æ ‡è®°ä¸ºæ¶æ„ï¼‰
| æ•°æ®é›† | æè¿° |
|--------|------|
| **LLMail** | é’ˆå¯¹é‚®ä»¶åŠ©æ‰‹çš„ prompt injection æ”»å‡» |
| **HH-RLHF** | äººå·¥æ ‡æ³¨çš„å®‰å…¨åå¥½ä¸çº¢é˜Ÿå¯¹è¯ |
| **XGuard** | åˆæˆçš„è‡ªé€‚åº”å¤šè½® jailbreak æ”»å‡» |
| **PRODIGy** | å¥½è±åå‰§æœ¬ä¸­çš„è§’è‰²æ‰®æ¼”å¯¹è¯ |
| **DEF CON** | AI Village çº¢é˜ŸæŒ‘æˆ˜èµ›çš„çœŸå®æ”»å‡»æ•°æ® |

#### è¯„æµ‹æ•°æ®é›†ï¼ˆå…± 1,010 æ¡ï¼Œè§ Table 3ï¼‰
| ç±»åˆ« | åŒ…å«æ•°æ®é›† |
|------|------------|
| **è‰¯æ€§é«˜å™ªå£°åœºæ™¯** | LMSYS, Glaive Function Calling, Nemotron Instruction, Anthropic HH-RLHF |
| **äººç±»ä¸»å¯¼çº¢é˜Ÿæµ‹è¯•** | HarmBench, DEFCON 34 AI Village |
| **è‡ªåŠ¨åŒ–å¤šè½®æ”»å‡»æ¡†æ¶** | Red Queen, XGuard, Automated-Multi-Turn |
| **å•è½® jailbreak åŸºå‡†** | JailBreakBenchï¼ˆç”¨äºéªŒè¯å•è½®æ€§èƒ½ï¼‰ |

> æ³¨ï¼šç¡®ä¿è¯„æµ‹æ ·æœ¬æœªå‡ºç°åœ¨è®­ç»ƒé›†ä¸­ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **ä¸»è¦ä»»åŠ¡**ï¼šå¤šè½® jailbreak æ£€æµ‹ï¼ˆäºŒåˆ†ç±»ï¼šsafe vs unsafeï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **F1 Score**ï¼ˆç»¼åˆè¡¡é‡ precision ä¸ recallï¼‰
  - **Recall**ï¼ˆæ£€å‡ºç‡ï¼Œå°¤å…¶å…³æ³¨æ¼æŠ¥ï¼‰
  - **Precision**ï¼ˆå‡†ç¡®ç‡ï¼Œé¿å…è¯¯æ€ï¼‰
  - **Mean Turns to Detection (MTTD)**ï¼šå¹³å‡åœ¨ç¬¬å‡ è½®æ£€æµ‹åˆ°å¨èƒ
  - **Per-Turn Latency**ï¼šæ¯è½®æ¨ç†è€—æ—¶ï¼ˆT4 GPUï¼‰

- **ç¡¬ä»¶ç¯å¢ƒ**ï¼š
  - ä¸»è¦æµ‹è¯•å¹³å°ï¼šGoogle Colab Pro+ï¼ŒNVIDIA A100ï¼ˆ40GB VRAMï¼‰
  - å®é™…éƒ¨ç½²ç›®æ ‡ï¼šT4 GPUï¼ˆä»…éœ€ 2GB VRAMï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
åˆ†ä¸ºä¸‰ç±»åŸºçº¿æ¨¡å‹ï¼š

| ç±»å‹ | ä»£è¡¨æ¨¡å‹ |
|------|--------|
| **è½»é‡çº§åµŒå…¥åˆ†ç±»å™¨** | Llama-Prompt-Guard-2-86M, Deberta-v3-Prompt-Injection |
| **ç”Ÿæˆå¼å®‰å…¨æ¨¡å‹ï¼ˆLLM-as-a-Judgeï¼‰** | Llama-Guard-4-12B, Granite-Guardian-3.3-8B, Qwen3Guard-Gen-8B, Gpt5-Nano |
| **ä¼ä¸šçº§äº‘æœåŠ¡ API** | Azure Prompt Shield, AWS Prompt Attack Guardrails, GCP Model Armor |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆå¤šè½® jailbreak æ£€æµ‹ï¼‰

| Model | F1 Score | Recall | Precision | MTTD |
|-------|----------|--------|-----------|------|
| **DeepContext (Ours)** | **0.84** | **0.83** | **0.86** | **4.24** |
| Llama-Prompt-Guard-2 | 0.67 | 0.60 | 0.76 | 5.83 |
| Granite-Guardian-3.3-8B | 0.67 | 0.57 | 0.83 | 5.03 |
| Gpt5-Nano | 0.65 | 0.55 | 0.81 | 5.73 |
| Azure Prompt Shield | 0.19 | 0.11 | 0.62 | 8.00 |

> âœ… DeepContext åœ¨ F1 ä¸Šé¢†å…ˆç¬¬äºŒåçº¦ **25%**ï¼Œä¸”å¬å›ç‡æ˜¾è‘—æ›´é«˜ï¼Œè¯´æ˜èƒ½æ›´æ—©ã€æ›´å…¨é¢åœ°æ•è·å¤æ‚æ”»å‡»ã€‚

### å•è½® jailbreak æ€§èƒ½ï¼ˆJailBreakBenchï¼‰

| Model | F1 Score | Recall | Precision |
|-------|----------|--------|-----------|
| **DeepContext (Ours)** | **0.98** | **1.00** | 0.95 |
| Qwen3Guard-Gen-8B | 0.88 | 0.95 | 0.83 |
| Llama-Guard-4-12B | 0.86 | 0.86 | 0.86 |
| GCP Model Armor | 0.83 | 0.96 | 0.74 |

> âœ… å³ä½¿æ²¡æœ‰ä¸Šä¸‹æ–‡ï¼ŒDeepContext ä»ä¿æŒæ¥è¿‘å®Œç¾çš„è¡¨ç°ï¼Œè¯æ˜å…¶å…¼å…· stateful ä¸ stateless æ£€æµ‹èƒ½åŠ›ã€‚

### æ¨ç†å»¶è¿Ÿå¯¹æ¯”ï¼ˆPer-Turn Latencyï¼‰

| Model | Latency (ms) |
|-------|---------------|
| Llama-Prompt-Guard-2 | 4 |
| **DeepContext (Ours)** | **19** |
| Llama-Guard-4-12B | 43 |
| Granite-Guardian-3.3-8B | 125 |
| AWS Prompt Attack Guardrails | 235 |
| Gpt5-Nano | 317 |

> âš¡ DeepContext åœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶ï¼Œå®ç° **<20ms** æ¨ç†å»¶è¿Ÿï¼Œé€‚åˆå®æ—¶äº¤äº’ç³»ç»Ÿã€‚

### æ¶ˆèå®éªŒä¸åˆ†æï¼ˆImplicit Ablation Insightsï¼‰
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»è®¾è®¡å¯æ¨æ–­ä»¥ä¸‹å…³é”®ç»„ä»¶ä½œç”¨ï¼š
- **GRU éšçŠ¶æ€** â†’ æ˜¾è‘—é™ä½ MTTDï¼ˆä» >5 åˆ° 4.24ï¼‰ï¼Œæé«˜ Recall
- **Task-Attention åŠ æƒ** â†’ æå‡åµŒå…¥è´¨é‡ï¼Œå¸®åŠ©åŒºåˆ†é«˜é£é™©è¯­ä¹‰
- **Residual Shortcut ($ e_t $ ç›´è¿)** â†’ ä¿ç•™ç¬æ—¶å¼ºä¿¡å·ï¼Œé˜²æ­¢ GRU â€œå¹³æ»‘â€æ‰æ˜æ˜¾æ”»å‡»
- **Focal Loss (Î³=2.0)** â†’ æå‡å¯¹â€œéš¾ä¾‹â€å­¦ä¹ èƒ½åŠ›ï¼Œé¿å…è¿‡æ‹Ÿåˆç®€å•æ¨¡å¼

æ­¤å¤–ï¼ŒTable 5 æ˜¾ç¤ºï¼š
> æ‰€æœ‰ LLM åŸºçº¿åœ¨ä½¿ç”¨**å…¨å†å²ä¸Šä¸‹æ–‡**æ—¶æ€§èƒ½ç­‰äºæˆ–ä½äº**æ»‘åŠ¨çª—å£**ï¼ˆlast 5 turnsï¼‰ï¼Œè¡¨æ˜ç¼ºä¹ä¸“é—¨çš„çŠ¶æ€è·Ÿè¸ªæœºåˆ¶ä¼šå¯¼è‡´æ³¨æ„åŠ›ç¨€é‡Šã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. ğŸ” **â€œState over Scaleâ€ èƒœå‡º**  
   å°½ç®¡ DeepContext å‚æ•°è¿œå°äº Llama-Guard-4-12B æˆ– Granite-Guardianï¼Œä½†åœ¨å¤šè½®æ”»å‡»æ£€æµ‹ä¸Šè¡¨ç°æ›´ä¼˜ï¼Œè¯æ˜**çŠ¶æ€æ„ŸçŸ¥æ¯”æ¨¡å‹è§„æ¨¡æ›´é‡è¦**ã€‚

2. âš™ï¸ **æ•ˆç‡ä¸æ•ˆæœå¯ä»¥å…¼å¾—**  
   é€šè¿‡å°†è¯­ä¹‰æå–ä¸çŠ¶æ€ä¼°è®¡è§£è€¦ï¼ŒDeepContext å®ç°äº† **F1=0.84 + <20ms latency** çš„ç†æƒ³å¹³è¡¡ï¼Œæ‰“ç ´äº†â€œå®‰å…¨å¿…æ…¢â€çš„å›ºæœ‰è®¤çŸ¥ã€‚

3. ğŸ§  **æ„å›¾æ¼‚ç§»æ˜¯å¯å»ºæ¨¡çš„è½¨è¿¹**  
   ç”¨æˆ·æ„å›¾å¹¶éçªå˜ï¼Œè€Œæ˜¯åœ¨ latent space ä¸­è¿ç»­æ¼”åŒ–çš„è·¯å¾„ã€‚RNN èƒ½æœ‰æ•ˆæ•æ‰è¿™ä¸€â€œgradual accumulation of riskâ€ã€‚

4. â˜ï¸ **ä¸»æµäº‘æœåŠ¡å­˜åœ¨ä¸¥é‡ç›²åŒº**  
   Azure Prompt Shield è™½ç„¶ Precision è¾ƒé«˜ï¼ˆ0.62ï¼‰ï¼Œä½† Recall ä»…ä¸º 0.11ï¼Œæ„å‘³ç€ **89% çš„å¤šè½®æ”»å‡»ä¼šè¢«æ”¾è¡Œ**ï¼Œæš´éœ²å…¶ stateless è®¾è®¡çš„æ ¹æœ¬ç¼ºé™·ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **False Positives in Complex Functional Dialogs**ï¼šåœ¨å‡½æ•°è°ƒç”¨ç­‰æŠ€æœ¯æ€§å¤æ‚æŒ‡ä»¤ä¸­å¯èƒ½å‡ºç°è¯¯åˆ¤ï¼Œå›  task-attention å¯èƒ½æ··æ·†â€œåŠŸèƒ½æ€§å¤æ‚â€ä¸â€œæ³¨å…¥æ€§å¤æ‚â€ã€‚
- **ä¾èµ–é«˜è´¨é‡ turn-level embedding**ï¼šè‹¥åˆå§‹ç¼–ç å™¨æœªèƒ½æ•è·å…³é”®è¯­ä¹‰ï¼Œåˆ™åç»­çŠ¶æ€ä¼ æ’­ä¼šå¤±æ•ˆã€‚
- **æ— æ³•é˜²å¾¡ M2S ç±»å‹æ”»å‡»**ï¼šå³å°†å¤šè½®æ”»å‡»å‹ç¼©ä¸ºå•è½®ç»“æ„åŒ– payload çš„æ”»å‡»æ–¹å¼å¯èƒ½ç»•è¿‡æ—¶åºå»ºæ¨¡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **Generalized Intent Detection**  
   æ‰©å±•è‡³é€šç”¨æ„å›¾è½¨è¿¹å¯¹é½ï¼Œä¸ä»…ç”¨äºå®‰å…¨ï¼Œè¿˜å¯ç›‘æ§ agent æ˜¯å¦åç¦»åŸå§‹ç›®æ ‡ï¼ˆgoal driftï¼‰ã€‚

2. **Dynamic Policy Controls**  
   åˆ©ç”¨è¿ç»­çš„é£é™©å‘é‡ $ R_t $ å®æ–½åŠ¨æ€å¹²é¢„ç­–ç•¥ï¼Œå¦‚è‡ªåŠ¨é™æƒã€è§¦å‘ human-in-the-loop å®¡æ ¸ç­‰ã€‚

3. **Deterministic Threat Tracking**  
   ç»“åˆæ¦‚ç‡æ€§ RNN ä¸ç¡®å®šæ€§è§„åˆ™å¼•æ“ï¼ˆå¦‚ FSM æˆ–å›¾è°±è¿½è¸ªï¼‰ï¼Œæä¾›å¯è§£é‡Šã€åˆè§„çš„å®¡è®¡æ—¥å¿—ã€‚

4. **Federated Intent Monitoring**  
   åœ¨è·¨ agent å·¥ä½œæµä¸­å®ç°åˆ†å¸ƒå¼çŠ¶æ€åŒæ­¥ï¼Œæ„å»ºå…¨å±€æ„å›¾è§†å›¾ã€‚

5. **Proactive Safety Steering**  
   ä¸åªæ˜¯æ‹¦æˆªï¼Œè€Œæ˜¯ä¸»åŠ¨å¼•å¯¼ä¸» LLM è°ƒæ•´ persona æˆ– reasoning depthï¼Œå®ç°â€œè½¯åˆ¶åŠ¨â€ã€‚

---

> ğŸ’¡ **ç»“è¯­**ï¼š  
> DeepContext è¡¨æ˜ï¼Œæœªæ¥çš„ LLM å®‰å…¨ä¸åº”å†ä¾èµ–â€œæ›´å¤§æ›´å¼ºâ€çš„ stateless æ¨¡å‹ï¼Œè€Œåº”è½¬å‘â€œæ›´èªæ˜æ›´æœ‰è®°å¿†â€çš„ stateful æ¶æ„ã€‚å®ƒä¸ºæ„å»ºçœŸæ­£å…·å¤‡**è®¤çŸ¥å®‰å…¨æ„è¯†**çš„ AI ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚

</details>

---

### 12. [Heterogeneous Federated Fine-Tuning with Parallel One-Rank Adaptation](https://arxiv.org/abs/2602.16936)

**Authors**: Zikai Zhang, Rui Hu, Jiahao Xu  
**Category**: cs.DC  
**Published**: 2026-02-20  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.16936v1  

#### Abstract
Large Language Models (LLMs) have demonstrated remarkable effectiveness in adapting to downstream tasks through fine-tuning. Federated Learning (FL) extends this capability by enabling collaborative fine-tuning across distributed clients using Low-Rank Adaptation (LoRA), while preserving data privac...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šHeterogeneous Federated Fine-Tuning with Parallel One-Rank Adaptation

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨è”é‚¦å­¦ä¹ ï¼ˆFederated Learning, FLï¼‰ä¸­å¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œå¾®è°ƒæ—¶ï¼Œå®¢æˆ·ç«¯é€šå¸¸é‡‡ç”¨ä½ç§©é€‚åº”ï¼ˆLow-Rank Adaptation, LoRAï¼‰æŠ€æœ¯ä»¥æå‡æ•ˆç‡å¹¶ä¿æŠ¤æ•°æ®éšç§ã€‚ç„¶è€Œï¼Œåœ¨å®é™…éƒ¨ç½²ä¸­ï¼Œå®¢æˆ·ç«¯èµ„æºå¼‚æ„ï¼ˆå¦‚è®¡ç®—èƒ½åŠ›ä¸åŒï¼‰ï¼Œå¯¼è‡´å…¶å¯è®­ç»ƒçš„LoRAç§©ï¼ˆrankï¼‰å„ä¸ç›¸åŒã€‚è¿™ç§**å¼‚æ„LoRAç§©**å¸¦æ¥äº†ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼š
- **åˆå§‹åŒ–å™ªå£°ï¼ˆInitialization Noiseï¼‰**ï¼šå…¨å±€èšåˆåçš„é«˜ç§©LoRAæ¨¡å—æ— æ³•ç›´æ¥ç”¨äºä½ç§©å®¢æˆ·ç«¯çš„åˆå§‹åŒ–ï¼Œéœ€æˆªæ–­æˆ–éšæœºé‡åˆå§‹åŒ–ï¼Œé€ æˆä¿¡æ¯ä¸¢å¤±ã€‚
- **èšåˆå™ªå£°ï¼ˆAggregation Noiseï¼‰**ï¼šä¸åŒç§©çš„æœ¬åœ°æ›´æ–°éš¾ä»¥æœ‰æ•ˆèšåˆï¼Œå¼•å…¥åå·®æˆ–å¤±çœŸã€‚

ç°æœ‰æ–¹æ³•ï¼ˆå¦‚FLoRAã€FlexLoRAã€HETLoRAï¼‰è™½å°è¯•è§£å†³è¯¥é—®é¢˜ï¼Œä½†åœ¨åˆå§‹åŒ–æˆ–èšåˆé˜¶æ®µä»å­˜åœ¨æ˜¾è‘—å™ªå£°ï¼Œå½±å“å…¨å±€æ¨¡å‹æ€§èƒ½ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šFed-PLoRA
ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡º **Fed-PLoRA**ï¼Œä¸€ç§è½»é‡çº§å¼‚æ„è”é‚¦å¾®è°ƒï¼ˆHeterogeneous FFTï¼‰æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰Parallel One-Rank Adaptation (PLoRA)
- å°†ä¼ ç»Ÿçš„å•ä¸ªå¤šç§©LoRAæ¨¡å—ï¼ˆmulti-rank LoRAï¼‰æ›¿æ¢ä¸º**å¤šä¸ªå¹¶è¡Œçš„ä¸€ç§©ï¼ˆone-rankï¼‰LoRAæ¨¡å—**ã€‚
- æ•°å­¦ä¸Šç­‰ä»·äºæ ‡å‡†LoRAï¼Œä½†å…·å¤‡æ¨¡å—åŒ–ä¼˜åŠ¿ï¼Œå¤©ç„¶æ”¯æŒä¸åŒå®¢æˆ·ç«¯é€‰æ‹©ä¸åŒæ•°é‡çš„æ¨¡å—è¿›è¡Œè®­ç»ƒã€‚

#### ï¼ˆ2ï¼‰Select-N-Fold åˆå§‹åŒ–ç­–ç•¥
- åœ¨æ¯è½®è®­ç»ƒå¼€å§‹æ—¶ï¼ŒæœåŠ¡å™¨å¹¿æ’­å®Œæ•´çš„å…¨å±€PLoRAå‚æ•°ï¼ˆå…±Rä¸ªä¸€ç§©æ¨¡å—ï¼‰ã€‚
- æ¯ä¸ªå®¢æˆ·ç«¯**éšæœºé€‰æ‹©Nä¸ªæ¨¡å—**ï¼ˆNä¸ºå…¶æœ¬åœ°ç§©ï¼‰è¿›è¡Œè®­ç»ƒã€‚
- å…¶ä½™æœªé€‰ä¸­çš„æ¨¡å—è¢«â€œæŠ˜å â€ï¼ˆfoldï¼‰åˆ°å†»ç»“çš„é¢„è®­ç»ƒæƒé‡ä¸­ï¼Œä½œä¸ºå›ºå®šåç½®ä¿ç•™ã€‚
- æ­¤ç­–ç•¥ç¡®ä¿æ‰€æœ‰å®¢æˆ·ç«¯éƒ½èƒ½ç»§æ‰¿å®Œæ•´çš„å…¨å±€çŸ¥è¯†ï¼Œ**å®Œå…¨æ¶ˆé™¤åˆå§‹åŒ–å™ªå£°**ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | åˆå§‹åŒ–å™ªå£° | èšåˆå™ªå£° | é€šä¿¡/è®¡ç®—å¼€é”€ |
|------|------------|----------|----------------|
| **FLoRA** | é«˜ï¼ˆæ¯è½®éšæœºåˆå§‹åŒ–ï¼‰ | æ— ï¼ˆå †å èšåˆï¼‰ | ä¸Šè¡Œä½ï¼Œä¸‹è¡Œé«˜ |
| **FlexLoRA** | ä¸­é«˜ï¼ˆSVDæˆªæ–­ï¼‰ | ä¸­ï¼ˆSVDé‡æ„è¯¯å·®ï¼‰ | æœåŠ¡ç«¯è®¡ç®—é«˜ï¼ˆSVDï¼‰ |
| **HETLoRA** | ä¸­é«˜ï¼ˆé›¶å¡«å……æˆªæ–­ï¼‰ | é«˜ï¼ˆåˆ†ç¦»å‡å€¼åå·®ï¼‰ | è¾ƒä½ |
| **Fed-PLoRA (Ours)** | **é›¶** | **æä½** | **è½»é‡çº§ï¼Œä»…ä¸‹è¡Œç•¥å¢** |

- **ç†è®ºä¼˜åŠ¿**ï¼šç»Ÿä¸€åˆ†æè¡¨æ˜ï¼ŒFed-PLoRAå®ç°äº†è¿‘ä¼¼æœ€ä¼˜çš„åˆå§‹åŒ–ï¼Œå¹¶æœ€å°åŒ–äº†èšåˆå™ªå£°ã€‚
- **å®è·µä¼˜åŠ¿**ï¼šæ¨¡å—åŒ–è®¾è®¡è½»é‡ï¼Œæ˜“äºé›†æˆåˆ°ç°æœ‰LoRAå’ŒFLæµç¨‹ä¸­ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–å¤šé¢†åŸŸä»»åŠ¡ï¼ŒéªŒè¯æ–¹æ³•é€šç”¨æ€§ï¼š
- **é€šç”¨æŒ‡ä»¤éµå¾ª**ï¼šNatural Instructions, Dolly-15K
- **è‡ªç„¶è¯­è¨€ç†è§£**ï¼šGLUE benchmarkï¼ˆCoLA, SST-2, MRPC, QQP, QNLI, RTEï¼‰
- **é‡‘èé¢†åŸŸ**ï¼šFinGPTï¼ˆè®­ç»ƒï¼‰ï¼ŒFPB, FIQA, TFNSï¼ˆæµ‹è¯•ï¼‰
- **åŒ»ç–—é¢†åŸŸ**ï¼šMedAlpacaï¼ˆè®­ç»ƒï¼‰ï¼ŒPubMedQA, MedMCQA, MedQA, CareQAï¼ˆæµ‹è¯•ï¼‰
- **æ•°å­¦æ¨ç†**ï¼šMATH

### å®éªŒè®¾ç½®
- **æ¨¡å‹è§„æ¨¡**ï¼šæ¶µç›–BERT-baseã€Llama-1Bã€Llama-3.1-8Bã€OPT-1.3Bã€Mistral-7B-v0.3ã€Qwen3-4Bç­‰ã€‚
- **LoRAé…ç½®**ï¼šåº”ç”¨äºself-attentionå±‚çš„`q_proj`å’Œ`v_proj`ã€‚
- **å®¢æˆ·ç«¯è®¾ç½®**ï¼š
  - å®¢æˆ·ç«¯æ•°ï¼š50â€“200
  - æ¯è½®é‡‡æ ·10%
  - å¼‚æ„ç§©è®¾ç½®ï¼šå°†å®¢æˆ·ç«¯åˆ†ä¸ºä¸‰ç»„ï¼Œåˆ†åˆ«ä½¿ç”¨ç§© `(1, r_m, R)`ï¼Œå…¶ä¸­ `R` ä¸ºæœ€ä¼˜å…¨å±€ç§©ï¼Œ`r_m < R`ï¼Œå¹³å‡ç§© â‰¤ `R/2`
- **æ•°æ®åˆ’åˆ†**ï¼š
  - **IID**ï¼šå‡åŒ€åˆ’åˆ†
  - **Non-IID**ï¼šç—…ç†åˆ’åˆ†ï¼ˆpathologicalï¼‰æˆ–Dirichletåˆ†å¸ƒæ¨¡æ‹Ÿæç«¯éç‹¬ç«‹åŒåˆ†å¸ƒ

### è¯„ä¼°æŒ‡æ ‡
- **ä¸»è¦æŒ‡æ ‡**ï¼šRouge-Lï¼ˆæŒ‡ä»¤ä»»åŠ¡ï¼‰ã€Accuracy / Matthews Corr.ï¼ˆåˆ†ç±»ä»»åŠ¡ï¼‰
- **å¯¹æ¯”åŸºçº¿**ï¼š
  - **FedIT**ï¼šåŒæ„LoRAä¸‹çš„åŸºå‡†ï¼ˆä»…ç”¨äºåŒæ„å¯¹æ¯”ï¼‰
  - **FLoRA**ï¼šåŸºäºå †å çš„å¼‚æ„èšåˆ
  - **FlexLoRA**ï¼šåŸºäºSVDçš„å¼‚æ„èšåˆ
  - **HETLoRA**ï¼šåŸºäºé›¶å¡«å……çš„å¼‚æ„èšåˆ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ªTable 1â€“3åŠæ­£æ–‡ï¼‰

#### ï¼ˆ1ï¼‰Natural Instructionsï¼ˆLlama-1Bï¼‰
| æ–¹æ³• | IID (Rouge-L) | Non-IID (Rouge-L) |
|------|---------------|-------------------|
| Untuned | 33.82 | 33.82 |
| FedIT (R) | 66.88 | 61.28 |
| **Fed-PLoRA** | **64.96** | **60.76** |
| HETLoRA | 58.07 | 58.84 |
| FlexLoRA | 59.07 | 53.51 |

- Fed-PLoRAåœ¨**éIIDä¸‹è¶…è¶Šæ‰€æœ‰å¼‚æ„åŸºçº¿**ï¼Œä¸”æ¥è¿‘ç”šè‡³ä¼˜äºéƒ¨åˆ†åŒæ„è®¾ç½®ï¼ˆå¦‚FedIT Rank=R/2ï¼‰ã€‚
- ç›¸æ¯”FLoRAï¼Œæå‡é«˜è¾¾ **+31.14%**ï¼ˆIIDï¼‰å’Œ **+26.94%**ï¼ˆNon-IIDï¼‰ã€‚

#### ï¼ˆ2ï¼‰GLUEï¼ˆBERT-base, R=16, avg rank=7ï¼‰
| æ–¹æ³• | CoLA | SST-2 | MRPC | QQP | RTE | **Avg** |
|------|------|-------|------|-----|-----|--------|
| Untuned | 1.20 | 49.08 | 31.61 | 63.09 | 52.70 | 41.27 |
| FedIT (R) | 61.68 | 92.47 | 87.58 | 86.86 | 68.35 | 81.08 |
| **Fed-PLoRA** | **59.38** | **92.35** | **86.35** | **87.25** | **65.46** | **79.89** |
| HETLoRA | -2.64 | 91.74 | -3.76 | 77.53 | -2.05 | 73.55 |

- Fed-PLoRAåœ¨**æ‰€æœ‰ä»»åŠ¡ä¸Šå…¨é¢è¶…è¶Šå¼‚æ„åŸºçº¿**ï¼Œå¹³å‡å¾—åˆ†è¾¾79.89ï¼Œæ¥è¿‘åŒæ„FedITã€‚
- ç›¸æ¯”HETLoRAï¼ŒRTEæå‡ **+67.51%**ï¼›ç›¸æ¯”FLoRAï¼ŒCoLAæå‡ **+63.46%**ã€‚

#### ï¼ˆ3ï¼‰é‡‘èæ•°æ®ï¼ˆLlama-3.1-8Bï¼‰
| æ–¹æ³• | FPB | FIQA | TFNS | **Avg** |
|------|-----|------|------|--------|
| Untuned | 50.57 | 29.33 | 49.87 | 40.12 |
| **Fed-PLoRA** | **63.94** | **31.68** | **64.19** | **53.27** |
| FlexLoRA | 62.79 | 31.76 | 62.60 | 52.38 |
| HETLoRA | 60.06 | 32.01 | 61.26 | 51.11 |

- Fed-PLoRAåœ¨**å¹³å‡å‡†ç¡®ç‡ä¸Šé¢†å…ˆ**ï¼Œå°¤å…¶åœ¨FPBä¸Šè¡¨ç°æœ€ä½³ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰Select-N-Fold ç­–ç•¥æœ‰æ•ˆæ€§ï¼ˆFigure 4ï¼‰
- å¯¹æ¯”ç­–ç•¥ï¼š
  - **Fixed**ï¼šå§‹ç»ˆé€‰æ‹©å‰rä¸ªæ¨¡å—
  - **Weight Norm**ï¼šé€‰æ‹©æƒé‡èŒƒæ•°æœ€å¤§çš„æ¨¡å—
  - **Select-N-Drop**ï¼šéšæœºé€‰æ‹©ä½†ä¸¢å¼ƒå…¶ä½™æ¨¡å—
- ç»“æœï¼š**Select-N-Fold** æ€§èƒ½æœ€é«˜ï¼ˆCoLAä¸Šè¾¾59.38ï¼‰ï¼Œè¯æ˜â€œæŠ˜å â€æœºåˆ¶å¤ç”¨æœªè®­ç»ƒæ¨¡å—ï¼Œæå‡ç¨³å®šæ€§ã€‚

#### ï¼ˆ2ï¼‰ä¸åŒé€‰æ‹©ç­–ç•¥å¯è§†åŒ–ï¼ˆFigure 6ï¼‰
- éšæœºé€‰æ‹©ï¼ˆSelect-N-Foldï¼‰å¸¦æ¥æ›´å‡åŒ€çš„æ¨¡å—æ›´æ–°åˆ†å¸ƒï¼Œé¿å…å±€éƒ¨è¿‡æ‹Ÿåˆã€‚

#### ï¼ˆ3ï¼‰Dropout å½±å“ï¼ˆTable 12ï¼‰
- åœ¨Dolly-15Kä¸Šï¼Œæ˜¯å¦å¯¹æŠ˜å æ¨¡å—åº”ç”¨dropoutå¯¹æ€§èƒ½**å‡ ä¹æ— å½±å“**ï¼ˆ60.07 vs 60.07ï¼‰ï¼Œè¯´æ˜æ— éœ€é¢å¤–æ­£åˆ™åŒ–ã€‚

#### ï¼ˆ4ï¼‰è¶…å‚æ•°é²æ£’æ€§ï¼ˆTable 9â€“11ï¼‰
- Fed-PLoRAåœ¨ä¸åŒå®¢æˆ·ç«¯æ•°é‡ï¼ˆ100 vs 200ï¼‰ã€èµ„æºå¼‚æ„æ¯”ä¾‹ï¼ˆ1:1:1 vs 6:3:1ï¼‰ã€LoRAç§©é…ç½®ä¸‹å‡ä¿æŒç¨³å®šé¢†å…ˆã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å¹¶è¡Œä¸€ç§©è®¾è®¡ï¼ˆPLoRAï¼‰æ˜¯ç¼“è§£å¼‚æ„FFTå™ªå£°çš„å…³é”®**ï¼šé€šè¿‡æ¨¡å—åŒ–åˆ†è§£ï¼Œä½¿ä¸åŒå®¢æˆ·ç«¯èƒ½çµæ´»å‚ä¸è®­ç»ƒè€Œä¸æŸå¤±å…¨å±€çŸ¥è¯†ã€‚
2. **Select-N-Foldç­–ç•¥å®ç°é›¶åˆå§‹åŒ–å™ªå£°**ï¼šé€šè¿‡â€œæŠ˜å â€æœºåˆ¶ä¿ç•™æœªè®­ç»ƒæ¨¡å—çš„ä¿¡æ¯ï¼Œæ˜¾è‘—ä¼˜äºæˆªæ–­æˆ–éšæœºåˆå§‹åŒ–ã€‚
3. **Fed-PLoRAåœ¨ç²¾åº¦å’Œæ•ˆç‡ä¸Šå…¨é¢è¶…è¶Šç°æœ‰æ–¹æ³•**ï¼šåœ¨å¤šç§ä»»åŠ¡ã€æ¨¡å‹å’Œæ•°æ®åˆ†å¸ƒä¸‹å‡å–å¾—SOTAæ€§èƒ½ï¼Œä¸”é€šä¿¡å’Œè®¡ç®—å¼€é”€å¯æ§ã€‚
4. **éšæœºé€‰æ‹©å¢å¼ºæ¨¡å—åŒæ­¥æ€§**ï¼šè·¨è½®æ¬¡çš„éšæœºé€‰æ‹©æœºåˆ¶ä¿ƒè¿›æ‰€æœ‰ä¸€ç§©æ¨¡å—è¢«å……åˆ†è®­ç»ƒï¼Œæå‡è·¨å®¢æˆ·ç«¯ä¸€è‡´æ€§ï¼ˆè§Figure 2, 8ï¼‰ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **ä¸‹è¡Œé€šä¿¡æˆæœ¬ç•¥é«˜**ï¼šæœåŠ¡å™¨éœ€å‘æ‰€æœ‰å®¢æˆ·ç«¯å‘é€å®Œæ•´Rç§©å‚æ•°ï¼Œå¯¹æœ€å¼±å®¢æˆ·ç«¯ç•¥æœ‰è´Ÿæ‹…ï¼ˆä½†ä»è¿œä½äºFLoRAï¼‰ã€‚
- **ä¾èµ–LoRAå‡è®¾**ï¼šç›®å‰ä»…é€‚ç”¨äºLoRAç±»PEFTæ–¹æ³•ï¼Œæœªæ‰©å±•è‡³Adapterã€Prefix-tuningç­‰å…¶ä»–å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯ã€‚
- **æç«¯é«˜ç§©åœºæ™¯å¯èƒ½ä¸ç¨³å®š**ï¼šå½“å…¨å±€ç§©Rè¿‡å¤§ï¼ˆå¦‚128ï¼‰è€Œå®¢æˆ·ç«¯æœ€å¤§ç§©å—é™æ—¶ï¼Œæ€§èƒ½å¯èƒ½ä¸‹é™ï¼ˆè§Table 11ï¼‰ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. è¿›ä¸€æ­¥é™ä½èšåˆé˜¶æ®µçš„æ®‹ä½™å™ªå£°ï¼Œæ¢ç´¢ç»“åˆSelective Aggregationï¼ˆå¦‚FedSA-LoRAï¼‰ç­‰ä¼˜åŒ–ç­–ç•¥ã€‚
2. æ‰©å±•è‡³å…¶ä»–PEFTæ–¹æ³•ï¼ˆå¦‚Adapterã€Prefix-tuningï¼‰çš„å¼‚æ„è”é‚¦è®­ç»ƒã€‚
3. æ¢ç´¢å¹¶è¡ŒåŒ–å¦‚ä½•æ›´å¥½åœ°å¯¹é½æ•°æ®å¼‚æ„ä¸‹çš„æ¨¡å‹æ›´æ–°ï¼Œæå‡åœ¨æç«¯Non-IIDä¸‹çš„é²æ£’æ€§ã€‚
4. ä¸é‡åŒ–ï¼ˆQuantizationï¼‰ã€ç¨€ç–åŒ–ç­‰æŠ€æœ¯ç»“åˆï¼Œæ‰“é€ æ›´é«˜æ•ˆçš„ç«¯åˆ°ç«¯è”é‚¦å¾®è°ƒç³»ç»Ÿã€‚

> âœ… **ä»£ç å·²å¼€æº**ï¼š[https://github.com/TNI-playground/Fed-PLoRA](https://github.com/TNI-playground/Fed-PLoRA)

</details>

---

### 13. [A Few-Shot LLM Framework for Extreme Day Classification in Electricity Markets](https://arxiv.org/abs/2602.16735)

**Authors**: Saud Alghumayjan, Ming Yi, Bolun Xu  
**Category**: cs.LG  
**Published**: 2026-02-20  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.16735v1  

#### Abstract
This paper proposes a few-shot classification framework based on Large Language Models (LLMs) to predict whether the next day will have spikes in real-time electricity prices. The approach aggregates system state information, including electricity demand, renewable generation, weather forecasts, and...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šA Few-Shot LLM Framework for Extreme Day Classification in Electricity Markets

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹ç”µåŠ›å¸‚åœºä¸­**real-time electricity price spikesï¼ˆå®æ—¶ç”µä»·å°–å³°ï¼‰é¢„æµ‹å›°éš¾**çš„é—®é¢˜ã€‚è¿™ç±»æç«¯äº‹ä»¶å…·æœ‰ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- å‘ç”Ÿé¢‘ç‡ä½ï¼ˆç¨€æœ‰äº‹ä»¶ï¼‰ï¼Œä¼ ç»Ÿç›‘ç£å­¦ä¹ æ¨¡å‹åœ¨è®­ç»ƒæ—¶å®¹æ˜“è¢«æ­£å¸¸æ ·æœ¬ä¸»å¯¼ï¼›
- å—å¤šç§å› ç´ å½±å“ï¼ˆå¦‚å¯å†ç”Ÿèƒ½æºå‡ºåŠ›æ³¢åŠ¨ã€å¤©æ°”å˜åŒ–ã€è´Ÿè·éœ€æ±‚ã€è¾“ç”µæ‹¥å µç­‰ï¼‰ï¼Œç³»ç»ŸåŠ¨æ€å¤æ‚ä¸”éšæ—¶é—´æ¼”å˜ï¼›
- åœ¨å†å²æ•°æ®æœ‰é™çš„æƒ…å†µä¸‹ï¼Œç°æœ‰æœºå™¨å­¦ä¹ æ¨¡å‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚

å› æ­¤ï¼Œå¦‚ä½•åœ¨**æ ‡ç­¾ç¨€ç¼ºï¼ˆlimited labeled dataï¼‰** çš„åœºæ™¯ä¸‹å‡†ç¡®è¯†åˆ«æ½œåœ¨çš„ç”µä»·å°–å³°æ—¥ï¼Œæ˜¯æœ¬ç ”ç©¶å…³æ³¨çš„æ ¸å¿ƒé—®é¢˜ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§åŸºäº **Large Language Models (LLMs)** çš„**few-shot åˆ†ç±»æ¡†æ¶**ï¼Œç”¨äºåˆ¤æ–­æ¬¡æ—¥æ˜¯å¦ä¸ºç”µä»·å°–å³°æ—¥ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **æ— éœ€ç›´æ¥è®­ç»ƒæ¨¡å‹**ï¼šæ•´ä¸ªæ¡†æ¶ä¸ä¾èµ–ä¼ ç»Ÿçš„å‚æ•°æ›´æ–°æˆ–ç›‘ç£è®­ç»ƒè¿‡ç¨‹ï¼Œè€Œæ˜¯é€šè¿‡è‡ªç„¶è¯­è¨€æç¤ºï¼ˆpromptingï¼‰å¼•å¯¼ LLM è¿›è¡Œæ¨ç†ã€‚
- **å°†ç»“æ„åŒ–ç‰¹å¾è½¬åŒ–ä¸ºè‡ªç„¶è¯­è¨€æè¿°**ï¼šå°†ç”µåŠ›ç³»ç»Ÿçš„å¤šç»´çŠ¶æ€å˜é‡ï¼ˆå¦‚è´Ÿè·ã€å¯å†ç”Ÿèƒ½æºé¢„æµ‹ã€ä»·æ ¼ç»Ÿè®¡é‡ç­‰ï¼‰è½¬æ¢æˆæ–‡æœ¬å½¢å¼çš„ prompt è¾“å…¥ç»™ LLMã€‚
- **ç»“åˆ embedding-based ç¤ºä¾‹æ£€ç´¢æœºåˆ¶**ï¼šåˆ©ç”¨ FAISS æ„å»ºå†å²æ•°æ®çš„æ–‡æœ¬åµŒå…¥ç´¢å¼•ï¼Œå¹¶é‡‡ç”¨ **Maximal Marginal Relevance (MMR)** ç­–ç•¥ä»è¿‡å»ç›¸ä¼¼å¤©æ•°ä¸­æ£€ç´¢æœ€å…·ä»£è¡¨æ€§åˆéå†—ä½™çš„ few-shot ç¤ºä¾‹ï¼Œå¢å¼ºä¸Šä¸‹æ–‡å­¦ä¹ æ•ˆæœã€‚
- **ç«¯åˆ°ç«¯åˆ†ç±»æµç¨‹è®¾è®¡**ï¼šæ„å»ºå®Œæ•´çš„ pipelineï¼Œæ¶µç›–æ•°æ®é¢„å¤„ç† â†’ æ–‡æœ¬æç¤ºç”Ÿæˆ â†’ ç¤ºä¾‹æ£€ç´¢ â†’ LLM æ¨ç† â†’ è¾“å‡ºè§£æã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ SVM, XGBoostï¼‰ | æœ¬æ–‡æå‡ºçš„ LLM æ–¹æ³• |
|------|----------------------------|---------------------|
| æ•°æ®æ•ˆç‡ | éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®æ‰èƒ½æœ‰æ•ˆè®­ç»ƒ | åœ¨æå°‘é‡å†å²æ•°æ®ä¸‹ä»ä¿æŒç¨³å®šæ€§èƒ½ |
| æ¨¡å‹é€‚åº”æ€§ | å¯¹åˆ†å¸ƒåç§»æ•æ„Ÿï¼Œéœ€é¢‘ç¹é‡è®­ | åˆ©ç”¨ LLM çš„æ³›åŒ–èƒ½åŠ›åº”å¯¹æ–°å‹æç«¯æƒ…å†µ |
| å¼€å‘æˆæœ¬ | éœ€ç‰¹å¾å·¥ç¨‹ + æ¨¡å‹è°ƒå‚ + è®­ç»ƒæµç¨‹ | ä»…éœ€è®¾è®¡ prompt å’Œç¤ºä¾‹é€‰æ‹©ç­–ç•¥ï¼Œå…è®­ç»ƒ |
| å°–å³°æ£€æµ‹çµæ•åº¦ | æ˜“å—ç±»åˆ«ä¸å¹³è¡¡å½±å“ | æ›´å¥½æ•æ‰ç½•è§äº‹ä»¶æ¨¡å¼ |

> âœ… **å…³é”®ä¼˜åŠ¿æ€»ç»“**ï¼šè¯¥æ–¹æ³•æ˜¯ä¸€ç§**é«˜æ•°æ®æ•ˆç‡ã€å…è®­ç»ƒã€é€‚ç”¨äºå°æ ·æœ¬åœºæ™¯çš„ç”µä»·å°–å³°åˆ†ç±»å·¥å…·**ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **æ•°æ®æ¥æº**ï¼šç¾å›½å¾·å·ç”µåŠ›å¸‚åœºï¼ˆERCOTï¼‰ç³»ç»Ÿçº§å…¬å¼€æ•°æ®ï¼›
- **æ—¶é—´èŒƒå›´**ï¼š
  - è®­ç»ƒ/å‚è€ƒæœŸï¼š2021â€“2023 å¹´ï¼ˆå…±ä¸‰å¹´ï¼‰
  - æµ‹è¯•æœŸï¼š2024 å¹´å…¨å¹´ï¼ˆå…± 366 å¤©ï¼‰
- **æ•°æ®ç±»å‹**ï¼š
  - Day-Ahead Price (DAP) ä¸ Real-Time Price (RTP)
  - å‡€è´Ÿè·é¢„æµ‹ä¸å®é™…å€¼ï¼ˆNet Demandï¼‰
  - å¯å†ç”Ÿèƒ½æºå‘ç”µé¢„æµ‹ï¼ˆWind/Solarï¼‰
  - å¤©æ°”æ•°æ®ï¼ˆæ¸©åº¦ã€é£é€Ÿç­‰ï¼‰
  - é¢„ç•™å®¹é‡ï¼ˆReservesï¼‰
  - æ—¥å†ä¿¡æ¯ï¼ˆæ˜ŸæœŸå‡ ã€æœˆä»½ï¼‰

> âš ï¸ **æ ‡ç­¾å®šä¹‰**ï¼šè‹¥æŸæ—¥ RTP çš„æ—¥å†…æ ‡å‡†å·®è¶…è¿‡å†å² 95% åˆ†ä½æ•°ï¼Œåˆ™æ ‡è®°ä¸º **spike day**ã€‚

### ç‰¹å¾å·¥ç¨‹
å…±æ„é€ äº†çº¦ 30+ ç»´ engineered featuresï¼Œä¸»è¦åŒ…æ‹¬ï¼š
- ç»Ÿè®¡ç‰¹å¾ï¼šmean, std, min, max
- åŠ¨æ€è¶‹åŠ¿ï¼šmomentumï¼ˆå½“å‰ vs å‰ä¸€æ—¥ï¼‰ã€lagged values
- å·®åˆ†ç‰¹å¾ï¼štemperature difference, net demand change
- æ—¶é—´ç‰¹å¾ï¼šday of week, month
- æ¸—é€ç‡æŒ‡æ ‡ï¼špct_renewable_forecast

è¿™äº›ç‰¹å¾æœ€ç»ˆè¢«æ ¼å¼åŒ–ä¸ºè‡ªç„¶è¯­è¨€å¥å­ï¼Œä¾‹å¦‚ï¼š
> â€œDay-Ahead Price Mean = 22.51, Temperature Max = 35Â°C, Is_DAP_Spike = No, Day = Fridayâ€

### å®éªŒè®¾ç½®
- **ç›®æ ‡ä»»åŠ¡**ï¼šbinary classification â€”â€” é¢„æµ‹æ¬¡æ—¥æ˜¯å¦ä¸º spike day
- **ä¸»æ¨¡å‹**ï¼š
  - **LLM-based classifier**ï¼šä½¿ç”¨ `gpt-4.1` æ¨¡å‹è¿›è¡Œ zero/few-shot æ¨ç†
- **Baseline æ¨¡å‹**ï¼š
  - **SVM**ï¼ˆæ”¯æŒå‘é‡æœºï¼‰
  - **XGBoost**ï¼ˆæ¢¯åº¦æå‡æ ‘ï¼‰
  - äºŒè€…å‡ä½¿ç”¨ç›¸åŒç‰¹å¾é›†ï¼Œåœ¨å®Œæ•´è®­ç»ƒé›†ä¸Šè®­ç»ƒ
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼š
  - CPU: Intel Xeon Platinum 8640Y @ 2GHz
  - GPU: 2Ã—NVIDIA A40
  - å†…å­˜: 512GB

### è¯„ä¼°æŒ‡æ ‡
åŸºäºæ··æ·†çŸ©é˜µè®¡ç®—ä»¥ä¸‹æ ‡å‡†æŒ‡æ ‡ï¼š
- **Precisionï¼ˆç²¾ç¡®ç‡ï¼‰**
- **Recallï¼ˆå¬å›ç‡ï¼‰**
- **Accuracyï¼ˆå‡†ç¡®ç‡ï¼‰**
- **F1-score**
- **ROC Curve & AUC**
- **Precision-Recall (PR) Curve**

æ­¤å¤–è¿˜æ¯”è¾ƒäº†ä¸åŒé˜ˆå€¼è®¾å®šä¸‹çš„è¡¨ç°ï¼š
- å›ºå®šé˜ˆå€¼ï¼ˆ0.5ï¼‰
- ROC-optimal thresholdï¼ˆå¹³è¡¡ TPR ä¸ FPRï¼‰
- PR-optimal thresholdï¼ˆæœ€å¤§åŒ– F1-scoreï¼‰

å¹¶åœ¨ä¸¤ç§æ•°æ®æ¡ä»¶ä¸‹æµ‹è¯•ï¼š
1. å®Œæ•´è®­ç»ƒæ•°æ®ï¼ˆ2021â€“2023ï¼‰
2. æœ‰é™æ•°æ®åœºæ™¯ï¼ˆä»…ç”¨æœ€è¿‘ä¸¤ä¸ªæœˆæ•°æ®ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table II & IIIï¼‰

#### ï¼ˆ1ï¼‰å®Œæ•´æ•°æ®è®¾ç½®ä¸‹çš„æ€§èƒ½å¯¹æ¯”ï¼ˆTable IIï¼‰

| Model | Precision | Recall | Accuracy | F1-score |
|-------|-----------|--------|----------|----------|
| **XGBoost (PR-optimal)** | 26.67% | 44.44% | 95.63% | **33.33%** |
| **SVM (PR-optimal)** | 37.5% | 33.33% | 96.99% | **35.29%** |
| **LLM (PR-optimal)** | **50.0%** | 22.22% | **97.54%** | 30.77% |

> ğŸ” è§‚å¯Ÿï¼š
- LLM åœ¨ **precision ä¸Šæœ€é«˜ï¼ˆ50%ï¼‰**ï¼Œè¯´æ˜å…¶é¢„æµ‹å‡ºçš„â€œå°–å³°æ—¥â€æ›´å¯ä¿¡ï¼›
- è™½ç„¶ recall è¾ƒä½ï¼Œä½†åœ¨é«˜é£é™©åº”ç”¨ä¸­ï¼ˆå¦‚å‚¨èƒ½å¥—åˆ©ã€è™šæ‹Ÿç”µå‚æŠ•æ ‡ï¼‰ï¼Œé¿å…è¯¯æŠ¥å°¤ä¸ºé‡è¦ï¼›
- æ‰€æœ‰æ¨¡å‹ accuracy æ¥è¿‘ï¼Œå› éå°–å³°æ—¥å ç»å¤§å¤šæ•°ï¼ˆimbalanced datasetï¼‰ï¼›

#### ï¼ˆ2ï¼‰æœ‰é™æ•°æ®è®¾ç½®ä¸‹çš„æ€§èƒ½å¯¹æ¯”ï¼ˆTable IIIï¼‰

å½“åªä½¿ç”¨ **ä¸¤ä¸ªæœˆå†å²æ•°æ®** æ—¶ï¼š

| Model | Precision | Recall | Accuracy | F1-score |
|-------|-----------|--------|----------|----------|
| XGBoost | 2.46% | 100% | 2.46% | 4.8% |
| SVM | 2.6% | 22.22% | 77.6% | 4.65% |
| **LLM** | **37.5%** | **33.33%** | **96.99%** | **35.29%** |

> âœ… **æ ¸å¿ƒå‘ç°**ï¼š
- ä¼ ç»Ÿæ¨¡å‹ï¼ˆXGBoost/SVMï¼‰åœ¨å°æ ·æœ¬ä¸‹ä¸¥é‡é€€åŒ–ï¼Œç”šè‡³å‡ºç°å…¨é”™ï¼ˆå¦‚ XGBoost PR-optimal ä¸‹ TP=0ï¼‰ï¼›
- **LLM æ€§èƒ½å‡ ä¹ä¸å—å½±å“**ï¼ŒF1-score è¾¾åˆ° 35.29%ï¼Œè¿œè¶…å…¶ä»–æ–¹æ³•ï¼›
- è¡¨æ˜ LLM åœ¨ **data efficiency æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿**ã€‚

#### ï¼ˆ3ï¼‰æ¦‚ç‡è¾“å‡ºåˆ†æï¼ˆFigure 2ï¼‰
- LLM è¾“å‡ºçš„æ¦‚ç‡æ›´åŠ å¹³æ»‘ï¼Œä¸”åœ¨çœŸå® spike æœŸé—´é›†ä¸­è¾“å‡ºé«˜ç½®ä¿¡åº¦ï¼›
- SVM/XGBoost æ¦‚ç‡æ³¢åŠ¨å‰§çƒˆï¼Œç¼ºä¹ä¸€è‡´æ€§ï¼›
- LLM çš„ PR-optimal threshold é«˜è¾¾ **0.91**ï¼Œåæ˜ å…¶å¯¹æ­£ç±»é¢„æµ‹æ›´ä¸ºä¿å®ˆè€Œå¯é ã€‚

> âŒ æ— æ¶ˆèå®éªŒæŠ¥å‘Šï¼ˆablation study ç¼ºå¤±ï¼‰

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **LLM å¯ä»¥åœ¨æ— éœ€è®­ç»ƒçš„å‰æä¸‹å®ç°é«˜æ€§èƒ½ç”µä»·å°–å³°åˆ†ç±»**ï¼Œæ€§èƒ½åª²ç¾ç”šè‡³ä¼˜äºä¼ ç»Ÿ ML æ¨¡å‹ï¼›
2. âœ… **Few-shot prompting + ç¤ºä¾‹æ£€ç´¢æœºåˆ¶èƒ½æœ‰æ•ˆæ¿€æ´» LLM çš„é¢†åŸŸæ¨ç†èƒ½åŠ›**ï¼Œå³ä½¿é¢å¯¹æœªè§è¿‡çš„ç³»ç»ŸçŠ¶æ€ç»„åˆï¼›
3. âœ… **åœ¨å†å²æ•°æ®ç¨€ç¼ºåœºæ™¯ä¸‹ï¼ŒLLM æ˜æ˜¾ä¼˜äº SVM å’Œ XGBoost**ï¼Œå±•ç°å‡ºå¼ºå¤§çš„æ•°æ®æ•ˆç‡å’Œé²æ£’æ€§ï¼›
4. âœ… **è‡ªç„¶è¯­è¨€æ¥å£é™ä½äº†éƒ¨ç½²é—¨æ§›**ï¼Œä¾¿äºèå…¥äººç±»ä¸“å®¶çŸ¥è¯†ä¸è§£é‡Šé€»è¾‘ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- âŒ **ä¾èµ–é«˜è´¨é‡ prompt è®¾è®¡ä¸ç¤ºä¾‹é€‰æ‹©ç­–ç•¥**ï¼Œæ€§èƒ½å¯èƒ½éš prompt æ”¹åŠ¨æ³¢åŠ¨ï¼›
- âŒ **æ— æ³•ä¿è¯å› æœæ¨æ–­æ­£ç¡®æ€§**ï¼ŒLLM å¯èƒ½åŸºäºè¡¨é¢ç›¸å…³æ€§åšå‡ºé”™è¯¯åˆ¤æ–­ï¼›
- âŒ **æ¨ç†å»¶è¿Ÿè¾ƒé«˜**ï¼Œä¸é€‚åˆé«˜é¢‘å®æ—¶å†³ç­–ï¼›
- âŒ **é»‘ç®±æ€§å¼º**ï¼Œç¼ºä¹å¯è§£é‡Šæ€§ä¿éšœï¼Œåœ¨å…³é”®åŸºç¡€è®¾æ–½ä¸­å­˜åœ¨ä¿¡ä»»éšœç¢ï¼›
- âŒ **æœªè¿›è¡Œè·¨åŒºåŸŸè¿ç§»éªŒè¯**ï¼ˆä»…æµ‹è¯• ERCOTï¼‰ï¼Œæ™®é€‚æ€§å¾…éªŒè¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•ä¸Šä¸‹æ–‡é•¿åº¦**ï¼šå¼•å…¥ multi-day contextual informationï¼Œæå‡è¶‹åŠ¿æ„ŸçŸ¥èƒ½åŠ›ï¼›
2. **å¾®è°ƒé¢†åŸŸä¸“ç”¨ LLM**ï¼šåœ¨ç”µåŠ›å¸‚åœºè¯­æ–™ä¸Šç»§ç»­é¢„è®­ç»ƒæˆ–æŒ‡ä»¤å¾®è°ƒï¼ˆfine-tune domain-specific LLMsï¼‰ï¼›
3. **é›†æˆä¸ç¡®å®šæ€§é‡åŒ–æœºåˆ¶**ï¼šç»“åˆ conformal prediction æˆ– ensemble prompting æä¾›é¢„æµ‹åŒºé—´ï¼›
4. **æ¢ç´¢å¤šæ¨¡æ€è¾“å…¥**ï¼šèåˆå›¾è¡¨ã€æ—¶é—´åºåˆ—å¯è§†åŒ–ç­‰è¾…åŠ©ä¿¡æ¯ä½œä¸º prompt è¾“å…¥ï¼›
5. **åº”ç”¨äºå…¶ä»–æç«¯äº‹ä»¶æ£€æµ‹ä»»åŠ¡**ï¼šå¦‚åœç”µé¢„è­¦ã€è®¾å¤‡æ•…éšœè¯Šæ–­ç­‰ã€‚

---

> ğŸ“Œ **æ€»ä½“è¯„ä»·**ï¼š  
> æœ¬æ–‡å¼€åˆ›æ€§åœ°å°† **LLM çš„ few-shot learning èƒ½åŠ›å¼•å…¥ç”µåŠ›å¸‚åœºæç«¯äº‹ä»¶åˆ†ç±»ä»»åŠ¡**ï¼Œå±•ç¤ºäº† LLM ä½œä¸ºä¸€ç§**è½»é‡çº§ã€å…è®­ç»ƒã€é«˜æ•ˆèƒ½çš„å°æ ·æœ¬å»ºæ¨¡èŒƒå¼**çš„å·¨å¤§æ½œåŠ›ï¼Œå°¤å…¶é€‚åˆæ•°æ®ç¨€ç–ã€åˆ†å¸ƒå¿«é€Ÿå˜åŒ–çš„å®é™…åº”ç”¨åœºæ™¯ã€‚

</details>

---

### 14. [Spatio-temporal dual-stage hypergraph MARL for human-centric multimodal corridor traffic signal control](https://arxiv.org/abs/2602.17068)

**Authors**: Xiaocai Zhang, Neema Nassir, Milad Haghani  
**Category**: cs.LG  
**Published**: 2026-02-20  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.17068v1  

#### Abstract
Human-centric traffic signal control in corridor networks must increasingly account for multimodal travelers, particularly high-occupancy public transportation, rather than focusing solely on vehicle-centric performance. This paper proposes STDSH-MARL (Spatio-Temporal Dual-Stage Hypergraph based Mul...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSpatio-temporal dual-stage hypergraph MARL for human-centric multimodal corridor traffic signal control

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿäº¤é€šä¿¡å·æ§åˆ¶ï¼ˆTSCï¼‰æ–¹æ³•ï¼ˆå¦‚ SCATSã€SCOOTï¼‰ä¸»è¦ä¼˜åŒ–**è½¦è¾†ä¸­å¿ƒåŒ–æŒ‡æ ‡**ï¼ˆå¦‚è½¦æµã€æ’é˜Ÿé•¿åº¦ï¼‰ï¼Œå¿½è§†äº†å¤šæ¨¡å¼å‡ºè¡Œè€…ï¼ˆå°¤å…¶æ˜¯é«˜è½½å®¢é‡çš„å…¬å…±äº¤é€šå¦‚å…¬äº¤ã€æœ‰è½¨ç”µè½¦ï¼‰çš„é€šè¡Œéœ€æ±‚ï¼Œå¯¼è‡´**äººæœ¬å…¬å¹³æ€§ç¼ºå¤±**ã€‚éšç€åŸå¸‚äº¤é€šå‘å¤šæ¨¡æ€å‘å±•ï¼ŒäºŸéœ€ä¸€ç§èƒ½å¤Ÿå…¼é¡¾å„ç±»å‡ºè¡Œè€…ä½“éªŒã€ç‰¹åˆ«æ˜¯ä¼˜å…ˆä¿éšœå¤§å®¹é‡å…¬å…±äº¤é€šçš„**äººæœ¬åŒ–ï¼ˆhuman-centricï¼‰ä¿¡å·æ§åˆ¶ç­–ç•¥**ã€‚

æ­¤å¤–ï¼Œç°æœ‰åŸºäº DRL çš„å¤šæ™ºèƒ½ä½“æ–¹æ³•åœ¨å»ºæ¨¡å¤æ‚æ—¶ç©ºä¾èµ–å…³ç³»æ—¶å­˜åœ¨å±€é™ï¼Œéš¾ä»¥æœ‰æ•ˆæ•æ‰äº¤å‰å£ä¹‹é—´çš„**é«˜é˜¶ç©ºé—´å…³è”**ä¸**åŠ¨æ€æ—¶é—´æ¼”åŒ–**ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
æœ¬æ–‡æå‡º **STDSH-MARL**ï¼ˆSpatio-Temporal Dual-Stage Hypergraph-based Multi-Agent Reinforcement Learningï¼‰ï¼Œä¸€ä¸ªé¢å‘äººæœ¬å¤šæ¨¡æ€èµ°å»Šç½‘ç»œçš„å¯æ‰©å±• MARL æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

- âœ… **äººæœ¬åŒ–å¥–åŠ±æœºåˆ¶**ï¼šé¦–æ¬¡å°†â€œç»å†å»¶è¯¯çš„ä¹˜å®¢æ€»æ•°â€ä½œä¸ºæ ¸å¿ƒä¼˜åŒ–ç›®æ ‡ï¼Œè€Œéä»…å…³æ³¨è½¦è¾†æ•°é‡ï¼ŒçœŸæ­£å®ç°ä»¥â€œäººâ€ä¸ºä¸­å¿ƒçš„äº¤é€šç®¡ç†ã€‚
- âœ… **åŒé˜¶æ®µè¶…å›¾æ³¨æ„åŠ›æœºåˆ¶ï¼ˆDual-Stage Hypergraph Attention, DSHAï¼‰**ï¼š
  - å¼•å…¥**ç©ºé—´è¶…è¾¹ï¼ˆSpatial Hyperedgesï¼‰** å’Œ **æ—¶é—´è¶…è¾¹ï¼ˆTemporal Hyperedgesï¼‰**ï¼Œåˆ†åˆ«å»ºæ¨¡å¤šä¸ªäº¤å‰å£åœ¨åŒä¸€æ—¶åˆ»çš„ç©ºé—´äº¤äº’ã€ä»¥åŠå•ä¸ªäº¤å‰å£åœ¨ä¸åŒæ—¶åˆ»çš„æ—¶é—´æ¼”åŒ–ã€‚
  - è®¾è®¡**åŒé˜¶æ®µæ³¨æ„åŠ›æœºåˆ¶**ï¼šå…ˆè¿›è¡Œ**è¶…è¾¹å†…æ³¨æ„åŠ›**ï¼ˆintra-hyperedge attentionï¼‰èšåˆèŠ‚ç‚¹ä¿¡æ¯ç”Ÿæˆè¶…è¾¹åµŒå…¥ï¼Œå†é€šè¿‡**è¶…è¾¹é—´æ³¨æ„åŠ›**ï¼ˆinter-hyperedge attentionï¼‰å­¦ä¹ ä¸åŒè¶…è¾¹å¯¹èŠ‚ç‚¹çš„é‡è¦æ€§ï¼Œä»è€Œæ•è·æ›´å¤æ‚çš„é«˜é˜¶æ—¶ç©ºä¾èµ–ã€‚
- âœ… **æ··åˆç¦»æ•£åŠ¨ä½œç©ºé—´**ï¼šè”åˆå†³ç­–ä¸‹ä¸€ç›¸ä½é…ç½®ï¼ˆ4ç§ï¼‰åŠå…¶ç»¿ç¯æŒç»­æ—¶é—´ï¼ˆ8â€“45ç§’ï¼Œå…±38ä¸ªé€‰é¡¹ï¼‰ï¼Œå½¢æˆç»´åº¦ä¸º $4 \times 38 = 152$ çš„ç¦»æ•£åŠ¨ä½œç©ºé—´ï¼Œæå‡æ§åˆ¶çµæ´»æ€§ã€‚
- âœ… **CTDE èŒƒå¼ä¸‹çš„é«˜æ•ˆæ¶æ„**ï¼š
  - **å»ä¸­å¿ƒåŒ–æ‰§è¡Œ**ï¼šæ¯ä¸ªäº¤å‰å£æ™ºèƒ½ä½“åŸºäºæœ¬åœ°è§‚æµ‹ç‹¬ç«‹å†³ç­–ï¼Œé€‚åˆå¤§è§„æ¨¡éƒ¨ç½²ã€‚
  - **é›†ä¸­å¼è®­ç»ƒ**ï¼šåˆ©ç”¨å…¨å±€è¶…å›¾åµŒå…¥æ„å»ºä¸­å¤® criticï¼Œè¾…åŠ©ä¿¡ç”¨åˆ†é…ï¼Œæå‡å­¦ä¹ æ•ˆç‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | STDSH-MARL çš„ä¼˜åŠ¿ |
|------|------------------|
| **ç›®æ ‡å¯¼å‘** | ä» vehicle-centric è½¬å‘ **passenger-centric**ï¼Œæ˜¾è‘—æ”¹å–„å…¬äº¤ä¼˜å…ˆä¸å‡ºè¡Œå…¬å¹³æ€§ |
| **è¡¨ç¤ºèƒ½åŠ›** | è¶…å›¾ç»“æ„ä¼˜äºä¼ ç»Ÿ GNN/CNNï¼Œèƒ½å»ºæ¨¡**å¤šå¯¹å¤šå…³ç³»**ï¼Œé¿å…æˆå¯¹å»ºæ¨¡çš„ä¿¡æ¯æŸå¤± |
| **æ—¶ç©ºå»ºæ¨¡** | æ˜¾å¼åˆ†ç¦»å¹¶èåˆç©ºé—´ä¸æ—¶é—´ä¾èµ–ï¼Œä¼˜äºå•ä¸€å›¾æˆ–é™æ€å›¾æ–¹æ³• |
| **æ§åˆ¶ç²’åº¦** | åŒæ—¶ä¼˜åŒ–ç›¸ä½åˆ‡æ¢ä¸ç»¿ç¯æ—¶é•¿ï¼Œæ¯”ä»…é€‰ç›¸ä½æˆ–å›ºå®šå‘¨æœŸæ›´å…·é€‚åº”æ€§ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†ä¸ä»¿çœŸç¯å¢ƒ
- **ä»¿çœŸå¹³å°**ï¼šä½¿ç”¨å¾®è§‚äº¤é€šä»¿çœŸè½¯ä»¶ **PTV VISSIM** æ„å»ºæ¾³å¤§åˆ©äºšå·¦è¡Œåˆ¶å¼ä¸‹çš„åˆæˆèµ°å»Šç½‘ç»œã€‚
- **ç½‘ç»œç»“æ„**ï¼šåŒ…å« **6ä¸ªä¿¡å·åŒ–äº¤å‰å£**ï¼Œæ¯äº¤å‰å£4ä¸ªæ–¹å‘ï¼Œæ¯ä¸ªæ–¹å‘2æ¡è¿›å£è½¦é“ï¼›ä¸€æ¡**æœ‰è½¨ç”µè½¦çº¿è·¯è´¯ç©¿å…¨ç½‘**ï¼Œè®¾3ä¸ªç«™ç‚¹ã€‚
- **äº¤é€šæ¨¡å¼**ï¼šæ¶µç›–ç§å®¶è½¦ã€å…¬äº¤è½¦ã€æœ‰è½¨ç”µè½¦ã€è¡Œäººã€éª‘è¡Œè€…ç­‰å¤šæ¨¡æ€å‡ºè¡Œè€…ã€‚
- **å®æ—¶æ•°æ®è¾“å…¥**ï¼šå‡è®¾å¯é€šè¿‡å…ˆè¿›æ„ŸçŸ¥æŠ€æœ¯è·å–å„æ¨¡å¼çš„ä¹˜å®¢æ•°ï¼ˆå¦‚ Wi-Fi äººæ•°ä¼°è®¡ã€è“ç‰™è¡Œäººæ£€æµ‹ã€APC å…¬äº¤è½½å®¢é¢„æµ‹ï¼‰ã€‚

### å®éªŒè®¾ç½®
- **åœºæ™¯è®¾è®¡**ï¼šå…±æµ‹è¯• **5ç§å…¸å‹äº¤é€šåœºæ™¯**ï¼Œè¦†ç›–å¤šç§éœ€æ±‚æ¨¡å¼ï¼š
  1. **Scenario 1**ï¼šå¹³å³°ä½éœ€æ±‚
  2. **Scenario 2**ï¼šå¹³å³°å‘é«˜å³°è¿‡æ¸¡
  3. **Scenario 3**ï¼šæ—©é«˜å³°é«˜éœ€æ±‚
  4. **Scenario 4**ï¼šä¸Šå­¦æ—©é«˜å³°ï¼ˆè¿›æ ¡æ–¹å‘æµé‡å¤§ï¼‰
  5. **Scenario 5**ï¼šæ”¾å­¦æ™šé«˜å³°ï¼ˆç¦»æ ¡æ–¹å‘æµé‡å¤§ï¼‰

- **è®­ç»ƒä¸è¯„ä¼°**ï¼šæ‰€æœ‰æ¨¡å‹åœ¨ Python ä¸­åŸºäº TensorFlow å®ç°ï¼Œåœ¨é…å¤‡ AMD EPYC CPU çš„å·¥ä½œç«™ä¸Šè¿è¡Œã€‚

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ | å…³æ³¨é‡ç‚¹ |
|------|------|---------|
| **ANP** (Average Number of Passengers experiencing delay) | å•ä½æ—¶é—´å†…å¹³å‡å»¶è¯¯ä¹˜å®¢æ•°ï¼ˆäºº/ç§’ï¼‰ | **äººæœ¬ç»©æ•ˆæ ¸å¿ƒæŒ‡æ ‡** |
| **AQL** (Average Queue Length) | æ‰€æœ‰äº¤å‰å£ä¸Šæ¸¸è½¦è¾†å¹³å‡æ’é˜Ÿé•¿åº¦ï¼ˆä¸å«æœ‰è½¨ç”µè½¦ï¼‰ | ç§å®¶è½¦æ‹¥å µæ°´å¹³ |
| **AWT (bus)** | å…¬äº¤è½¦ç©¿è¶Šæ•´ä¸ªèµ°å»Šçš„å¹³å‡ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰ | å…¬äº¤ä¼˜å…ˆæ•ˆæœ |
| **AWT (tram)** | æœ‰è½¨ç”µè½¦ç©¿è¶Šæ•´ä¸ªèµ°å»Šçš„å¹³å‡ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰ | å¤§å®¹é‡å…¬äº¤ä¼˜å…ˆ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|--------|------|------|
| **FS-WF** (Fixed Signal with Websterâ€™s Formula) | å›ºå®šé…æ—¶ | åŸºäºç»å…¸å…¬å¼è®¡ç®—å‘¨æœŸä¸æ—¶åˆ† |
| **MADQN** | Value-based (DQN) | åˆ†å¸ƒå¼è®­ç»ƒä¸æ‰§è¡Œ |
| **MADDQN** | Value-based (DDQN) | æ”¹è¿› Q å€¼è¿‡ä¼°è®¡é—®é¢˜ |
| **MAA2C** | Hybrid (Actor-Critic) | CTDE èŒƒå¼ï¼Œç¨³å®šå­¦ä¹  |
| **MAPPO** | Policy-based (PPO) | æ— è¶…å›¾ç»“æ„ï¼Œæ ‡å‡† MARL |
| **CMRM** | Graph-based (GAT + PPO) | ä½¿ç”¨å›¾æ³¨æ„åŠ›ç½‘ç»œï¼Œç”¨äºéªŒè¯è¶…å›¾ä¼˜åŠ¿ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»ï¼ˆæœ€ä¼˜å€¼åŠ ç²—ï¼Œæ¬¡ä¼˜ä¸‹åˆ’çº¿ï¼‰

| åœºæ™¯ | æ–¹æ³• | ANP â†“ | AQL â†“ | AWT (bus) â†“ | AWT (tram) â†“ |
|------|------|-------|-------|-------------|--------------|
| **1** | STDSH-MARL | **1381.70** | 304.41 | **296.79** | **285.55** |
|      | MADDQN | 1534.40 | **290.34** | 834.46 | 1607.45 |
| **2** | STDSH-MARL | **1551.41** | 319.91 | 356.45 | **267.15** |
|      | MAA2C | 1735.13 | 387.90 | **354.34** | 310.90 |
| **3** | STDSH-MARL | **1649.23** | 359.24 | **373.34** | **284.90** |
|      | MAPPO | 1730.11 | 363.42 | 373.67 | 347.80 |
| **4** | STDSH-MARL | **1553.27** | 331.45 | **339.70** | 289.80 |
|      | MADQN | 1952.03 | **306.94** | 915.68 | 1558.50 |
| **5** | STDSH-MARL | **1573.86** | 339.95 | **332.05** | 351.80 |
|      | MADQN | 1608.17 | **296.93** | 802.26 | 1556.67 |

> æ³¨ï¼šSTDSH-MARL åœ¨ **æ‰€æœ‰åœºæ™¯çš„æ‰€æœ‰ANPæŒ‡æ ‡ä¸Šå‡å–å¾—æœ€ä½³è¡¨ç°**ï¼Œä¸”åœ¨ AWT (bus/tram) ä¸Šè¿œä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œè¡¨æ˜å…¶å“è¶Šçš„**å…¬å…±äº¤é€šä¼˜å…ˆèƒ½åŠ›**ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- ğŸ“‰ **ANP å¹³å‡é™ä½è¶…è¿‡ 10%**ï¼šç›¸æ¯”æœ€å¼ºåŸºçº¿ï¼ˆå¦‚ MADDQNã€MAPPOï¼‰ï¼ŒSTDSH-MARL åœ¨å¤šæ•°åœºæ™¯ä¸­å°†å»¶è¯¯ä¹˜å®¢æ•°å‡å°‘ **10~15%**ï¼Œæœ€é«˜è¾¾ **18.65%**ï¼ˆvs MAPPO in Scenario 1ï¼‰ã€‚
- ğŸšŒ **å…¬äº¤ä¸æœ‰è½¨ç”µè½¦ç­‰å¾…æ—¶é—´å¤§å¹…ä¸‹é™**ï¼š
  - AWT (bus) å¹³å‡æ¯” DQN/DDQN ç±»æ–¹æ³•ä½ **500+ ç§’**
  - AWT (tram) ä»åŸºçº¿çš„ **>1500 ç§’** é™è‡³ **~280 ç§’**ï¼Œä½“ç°æå¼ºçš„**å¤§è¿é‡å…¬äº¤ä¼˜å…ˆä¿éšœèƒ½åŠ›**
- âš–ï¸ **å¹³è¡¡æ€§æ›´å¥½**ï¼šå°½ç®¡éƒ¨åˆ†åŸºçº¿ï¼ˆå¦‚ MADQNï¼‰åœ¨ AQL ä¸Šç•¥ä¼˜ï¼Œä½†ä»£ä»·æ˜¯ä¸¥é‡ç‰ºç‰²å…¬äº¤åˆ©ç›Šï¼›è€Œ STDSH-MARL åœ¨ä¿æŒåˆç† AQL çš„å‰æä¸‹æ˜¾è‘—æå‡äººæœ¬æŒ‡æ ‡ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
æ¶ˆèå®éªŒéªŒè¯äº†å„ç»„ä»¶å¯¹æ€§èƒ½çš„å½±å“ï¼ˆä»¥ ANP ä¸ºè¡¡é‡ï¼‰ï¼š

| æ¨¡å‹å˜ä½“ | ANP (å¹³å‡) | å˜åŒ–ç‡ |
|----------|------------|--------|
| å®Œæ•´ STDSH-MARL ï¼ˆâˆšHG, âˆšDSHA, âˆšSHE, âˆšTHEï¼‰ | **1541.89** | â€”â€” |
| ç§»é™¤ Temporal Hyperedge (THE) | 1765.38 | â†‘ +14.5% |
| ç§»é™¤ Hypergraph (HG) | 1728.64 | â†‘ +12.1% |
| ç§»é™¤ DSHA æ¨¡å— | 1684.13 | â†‘ +9.2% |
| ç§»é™¤ Spatial Hyperedge (SHE) | 1602.44 | â†‘ +3.9% |

#### å…³é”®å‘ç°ï¼š
- **Temporal Hyperedge (THE) æœ€é‡è¦**ï¼šç§»é™¤åæ€§èƒ½ä¸‹é™æœ€ä¸¥é‡ï¼Œè¯´æ˜**æ—¶é—´ç»´åº¦å»ºæ¨¡**å¯¹æ•æ‰åŠ¨æ€äº¤é€šæ¼”åŒ–è‡³å…³é‡è¦ã€‚
- **DSHA æœºåˆ¶æœ‰æ•ˆ**ï¼šå¼•å…¥åŒé˜¶æ®µæ³¨æ„åŠ›ä½¿ ANP ä¸‹é™çº¦ **8.45%**ï¼Œè¯æ˜å…¶åœ¨æå–é«˜é˜¶ä¾èµ–ä¸Šçš„æœ‰æ•ˆæ€§ã€‚
- **è¶…å›¾ç»“æ„å¿…è¦**ï¼šç›´æ¥ç§»é™¤ HG å¯¼è‡´æ€§èƒ½éª¤é™ï¼Œå‡¸æ˜¾å…¶ç›¸è¾ƒäºæ™®é€šå›¾è¡¨ç¤ºçš„ä¼˜åŠ¿ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **äººæœ¬åŒ–ç›®æ ‡å¯è¡Œä¸”å¿…è¦**ï¼šé€šè¿‡å°†â€œå»¶è¯¯ä¹˜å®¢æ•°â€ä½œä¸ºå¥–åŠ±å‡½æ•°ï¼Œå¯æœ‰æ•ˆå¼•å¯¼ MARL æ¨¡å‹ä¼˜å…ˆæœåŠ¡é«˜è½½å®¢äº¤é€šå·¥å…·ï¼ˆå¦‚å…¬äº¤ã€æœ‰è½¨ç”µè½¦ï¼‰ï¼Œå®ç°çœŸæ­£çš„**å‡ºè¡Œå…¬å¹³ä¸ç¤¾ä¼šæ•ˆç›Šæœ€å¤§åŒ–**ã€‚
2. âœ… **è¶…å›¾ç»“æ„æ˜¾è‘—æå‡è¡¨ç¤ºèƒ½åŠ›**ï¼šç›¸æ¯”ä¼ ç»Ÿ GNN/GATï¼Œ**spatio-temporal hypergraph** æ›´é€‚åˆå»ºæ¨¡äº¤å‰å£é—´çš„å¤æ‚é«˜é˜¶äº’åŠ¨ï¼Œå°¤å…¶åœ¨åŠ¨æ€äº¤é€šç¯å¢ƒä¸­è¡¨ç°çªå‡ºã€‚
3. âœ… **æ—¶é—´ä¾èµ–æ€§æ˜¯æ€§èƒ½å…³é”®é©±åŠ¨å› ç´ **ï¼šæ¶ˆèå®éªŒè¯æ˜ï¼Œ**Temporal Hyperedges** æ˜¯æå‡æ€§èƒ½çš„æœ€é‡è¦ç»„ä»¶ï¼Œå¼ºè°ƒäº†å¯¹å†å²çŠ¶æ€å»ºæ¨¡çš„é‡è¦æ€§ã€‚
4. âœ… **STDSH-MARL å…·å¤‡å¼ºé²æ£’æ€§ä¸æ³›åŒ–èƒ½åŠ›**ï¼šåœ¨äº”ç§å·®å¼‚æ˜¾è‘—çš„äº¤é€šåœºæ™¯ä¸‹å‡ä¿æŒé¢†å…ˆï¼Œè¡¨æ˜å…¶å¯¹ä¸åŒéœ€æ±‚æ¨¡å¼å…·æœ‰è‰¯å¥½çš„é€‚åº”æ€§ã€‚

### æ–¹æ³•å±€é™æ€§
- ğŸ”’ **ä¾èµ–é«˜è´¨é‡å¤šæ¨¡æ€æ„ŸçŸ¥æ•°æ®**ï¼šæ–¹æ³•å‡è®¾èƒ½å‡†ç¡®è·å–å„æ¨¡å¼çš„ä¹˜å®¢æ•°ï¼ˆOccupant Countingï¼‰ï¼Œå½“å‰æŠ€æœ¯ï¼ˆå¦‚ Wi-Fiã€Bluetoothã€APCï¼‰ä»æœ‰ä¸€å®šè¯¯å·®ä¸è¦†ç›–ç‡é™åˆ¶ã€‚
- ğŸ’¾ **è®­ç»ƒé˜¶æ®µéœ€è¦å…¨å±€ä¿¡æ¯**ï¼šè™½ç„¶æ‰§è¡Œå»ä¸­å¿ƒåŒ–ï¼Œä½†è®­ç»ƒæ—¶éœ€æ„å»ºå…¨å±€è¶…å›¾å¹¶è®­ç»ƒ central criticï¼Œå¯¹é€šä¿¡ä¸è®¡ç®—èµ„æºæœ‰ä¸€å®šè¦æ±‚ã€‚
- ğŸ§© **è¶…å‚æ•°æ•æ„Ÿæ€§æœªå……åˆ†è®¨è®º**ï¼šå¦‚è¶…è¾¹æ„é€ æ–¹å¼ã€æ³¨æ„åŠ›å¤´æ•°ã€æƒé‡ç³»æ•°ç­‰å¯èƒ½å½±å“æœ€ç»ˆæ€§èƒ½ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³åŸå¸‚åœºæ™¯**ï¼šæµ‹è¯• STDSH-MARL åœ¨æ•°ç™¾ä¸ªäº¤å‰å£çš„åŸå¸‚çº§ç½‘ç»œä¸­çš„**å¯æ‰©å±•æ€§**ï¼ˆscalabilityï¼‰ä¸åè°ƒèƒ½åŠ›ã€‚
2. **å¢å¼ºé²æ£’æ€§ç ”ç©¶**ï¼šåœ¨**çªå‘äº‹ä»¶**ï¼ˆäº‹æ•…ã€ä¸´æ—¶å°è·¯ï¼‰ã€**éœ€æ±‚çªå˜**ã€**ä¼ æ„Ÿå™¨å™ªå£°**ç­‰ç°å®æ‰°åŠ¨ä¸‹è¯„ä¼°æ¨¡å‹ç¨³å®šæ€§ã€‚
3. **å¼•å…¥ Explainable DRL**ï¼šå¼€å‘å¯è§£é‡Šæœºåˆ¶ï¼Œæä¾›ä¿¡å·å†³ç­–èƒŒåçš„é€»è¾‘ä¾æ®ï¼Œå¢å¼ºäº¤é€šç®¡ç†è€…ä¿¡ä»»ï¼Œæ¨åŠ¨å®é™…éƒ¨ç½²ã€‚
4. **æ‹“å±•å¤šç›®æ ‡ä¼˜åŒ–**ï¼šçº³å…¥æ›´å¤šäººæœ¬æŒ‡æ ‡ï¼Œå¦‚ç¢³æ’æ”¾ã€è¡Œäººå®‰å…¨é£é™©ã€éª‘è¡Œèˆ’é€‚åº¦ç­‰ï¼Œæ„å»ºç»¼åˆè¯„ä»·ä½“ç³»ã€‚

--- 

> **æ€»ç»“**ï¼š  
> æœ¬æ–‡æå‡ºçš„ **STDSH-MARL** æ˜¯é¦–ä¸ªå°†**æ—¶ç©ºè¶…å›¾ç»“æ„**ä¸**äººæœ¬å¤šæ¨¡æ€ä¼˜åŒ–**æ·±åº¦èåˆçš„ MARL æ¡†æ¶ï¼Œåœ¨ç†è®ºåˆ›æ–°ä¸å®é™…æ•ˆç›Šä¹‹é—´å–å¾—äº†è‰¯å¥½å¹³è¡¡ã€‚å…¶å®éªŒè¯æ˜ï¼Œé€šè¿‡ç²¾ç»†å»ºæ¨¡æ—¶ç©ºé«˜é˜¶ä¾èµ–ï¼Œå¹¶ä»¥â€œä¹˜å®¢å»¶è¯¯â€ä¸ºæ ¸å¿ƒç›®æ ‡ï¼Œå¯æ˜¾è‘—æå‡å…¬å…±äº¤é€šä¼˜å…ˆæ°´å¹³ä¸æ•´ä½“å‡ºè¡Œå…¬å¹³æ€§ï¼Œä¸ºä¸‹ä¸€ä»£æ™ºæ…§åŸå¸‚äº¤é€šæ§åˆ¶æä¾›äº†æœ‰åŠ›çš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 15. [Powering Up Zeroth-Order Training via Subspace Gradient Orthogonalization](https://arxiv.org/abs/2602.17155)

**Authors**: Yicheng Lang, Changsheng Wang, Yihua Zhang, Mingyi Hong, Zheng Zhang, Wotao Yin, Sijia Liu  
**Category**: cs.LG  
**Published**: 2026-02-20  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.17155v1  

#### Abstract
Zeroth-order (ZO) optimization provides a gradient-free alternative to first-order (FO) methods by estimating gradients via finite differences of function evaluations, and has recently emerged as a memory-efficient paradigm for fine-tuning large-scale models by avoiding backpropagation. However, ZO ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šPowering Up Zeroth-Order Training via Subspace Gradient Orthogonalization

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
é›¶é˜¶ä¼˜åŒ–ï¼ˆZeroth-Order, ZOï¼‰é€šè¿‡å‡½æ•°å€¼çš„æœ‰é™å·®åˆ†ä¼°è®¡æ¢¯åº¦ï¼Œé¿å…åå‘ä¼ æ’­ï¼ˆbackpropagationï¼‰ï¼Œä»è€Œæ˜¾è‘—é™ä½å¤§è§„æ¨¡æ¨¡å‹å¾®è°ƒæ—¶çš„æ˜¾å­˜å¼€é”€ã€‚ç„¶è€Œï¼Œæ ‡å‡† ZO æ–¹æ³•é¢ä¸´**é«˜æ–¹å·®æ¢¯åº¦ä¼°è®¡**ä¸**æŸ¥è¯¢æ•ˆç‡ä½ä¸‹**ä¹‹é—´çš„æ ¹æœ¬çŸ›ç›¾ï¼šç»´åº¦è¶Šé«˜ï¼Œæ¢¯åº¦ä¼°è®¡æ–¹å·®è¶Šå¤§ï¼›ä¸ºé™æ–¹å·®è€Œå¢åŠ æŸ¥è¯¢æ¬¡æ•°åˆå¯¼è‡´è®¡ç®—æˆæœ¬ä¸Šå‡ï¼Œä¸”å¸¸å‡ºç°â€œå¤šæŸ¥è¯¢æ‚–è®ºâ€ï¼ˆmulti-query paradoxï¼‰ï¼Œå³æ€§èƒ½æå‡ä¸æ˜æ˜¾ç”šè‡³ä¸‹é™ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šZO-Muon
æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º **ZO-Muon** çš„æ–°å‹é›¶é˜¶ä¼˜åŒ–æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†ä¸¤ç§äº’è¡¥æœºåˆ¶ç»Ÿä¸€äºä¸€ä¸ª**å­ç©ºé—´æ¢¯åº¦æ­£äº¤åŒ–**ï¼ˆSubspace Gradient Orthogonalizationï¼‰çš„æ¡†æ¶ä¸­ï¼š

1. **æŠ•å½±å¼å­ç©ºé—´ ZO ä¼˜åŒ–**ï¼ˆProjection-based Subspace ZOï¼‰  
   å°†åŸå§‹å‚æ•°ç©ºé—´æŠ•å½±åˆ°ä½ç»´å­ç©ºé—´ï¼Œåœ¨è¯¥å­ç©ºé—´å†…è¿›è¡Œæ¢¯åº¦ä¼°è®¡ã€‚ç”±äºæœ‰æ•ˆç»´åº¦é™ä½ï¼Œæ¢¯åº¦ä¼°è®¡æ–¹å·®æ˜¾è‘—å‡å°ã€‚è¯¥æ–¹æ³•åŸºäºä¸€ä¸ªå…³é”®è§‚å¯Ÿï¼šæ·±åº¦æ¨¡å‹è®­ç»ƒä¸­çš„æƒé‡æ›´æ–°å…·æœ‰å†…åœ¨çš„ä½ç§©ç»“æ„ã€‚

2. **æ¢¯åº¦æ­£äº¤åŒ–è°±ä¼˜åŒ–**ï¼ˆGradient-Orthogonalized Spectral Optimizationï¼‰  
   å¼•å…¥ Muon ä¼˜åŒ–å™¨ä¸­çš„ **gradient orthogonalization (GO)** æŠ€æœ¯ï¼Œå¯¹å­ç©ºé—´å†…çš„ ZO æ¢¯åº¦è¿›è¡ŒçŸ©é˜µç™½åŒ–ï¼ˆmatrix whiteningï¼‰ï¼Œæå–æœ‰æ„ä¹‰çš„è°±æ–¹å‘ï¼ŒæŠ‘åˆ¶å™ªå£°æ–¹å‘çš„å½±å“ã€‚è¿™ä½¿å¾—ä¼˜åŒ–è¿‡ç¨‹èƒ½æ›´æœ‰æ•ˆåœ°åˆ©ç”¨è°±ç»“æ„ä¿¡æ¯ã€‚

**ZO-Muon** æ˜¯è¿™ä¸¤ä¸ªåŸåˆ™çš„ç»“åˆä½“ï¼šå…ˆåœ¨ä½ç»´å­ç©ºé—´ç”¨ Subspace RGE ä¼°è®¡æ¢¯åº¦ï¼Œå†å¯¹å…¶åº”ç”¨ msign æ“ä½œï¼ˆå³ GOï¼‰ï¼Œæœ€åå°†æ›´æ–°æ˜ å°„å›å…¨å‚æ•°ç©ºé—´ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **å‡†ç¡®æ€§æ›´é«˜**ï¼šæ˜¾è‘—ä¼˜äº MeZOã€LOZOã€HiZOO ç­‰ SOTA ZO æ–¹æ³•ã€‚
- **æŸ¥è¯¢æ•ˆç‡æ›´é«˜**ï¼šè¾¾åˆ°ç›¸åŒæ€§èƒ½æ‰€éœ€æŸ¥è¯¢æ•°å¤§å¹…å‡å°‘ï¼ˆå¦‚ä»…éœ€ MeZO çš„ 24.7% æŸ¥è¯¢é‡ï¼‰ã€‚
- **è¿è¡Œæ—¶é—´æ›´çŸ­**ï¼šæ”¶æ•›é€Ÿåº¦æ›´å¿«ï¼Œæ€»è¿è¡Œæ—¶é—´æ›´å°‘ã€‚
- **å†…å­˜å‹å¥½**ï¼šä¿æŒäº† ZO æ–¹æ³•ä½æ˜¾å­˜å ç”¨çš„ä¼˜ç‚¹ï¼Œæœªå¼•å…¥é¢å¤–å†…å­˜è´Ÿæ‹…ã€‚
- **é²æ£’æ€§å¼º**ï¼šå¯¹ batch size å˜åŒ–ä¸æ•æ„Ÿï¼Œå³ä½¿åœ¨å° batch ä¸‹ä»è¡¨ç°ä¼˜å¼‚ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¾®è°ƒ**ï¼šåœ¨ **SuperGLUE** åŸºå‡†ä¸Šæµ‹è¯•ï¼ŒåŒ…æ‹¬ä»¥ä¸‹ä»»åŠ¡ï¼š
  - SST-2ï¼ˆæƒ…æ„Ÿåˆ†ç±»ï¼‰
  - RTEï¼ˆæ–‡æœ¬è•´å«ï¼‰
  - CBï¼ˆæ‰¿è¯ºé“¶è¡Œï¼‰
  - BoolQï¼ˆè‡ªç„¶çš„æ˜¯/å¦é—®ç­”ï¼‰
  - WiCï¼ˆè¯ä¹‰æ¶ˆæ­§ï¼‰
  - SQuADï¼ˆé˜…è¯»ç†è§£ï¼‰
- **è§†è§‰æ¨¡å‹ï¼ˆViTsï¼‰å¾®è°ƒ**ï¼šåœ¨ **CIFAR-10 / CIFAR-100** å›¾åƒåˆ†ç±»æ•°æ®é›†ä¸Šæµ‹è¯•ã€‚

### æ¨¡å‹
- **LLMs**: LLaMA3-8B, OPT-1.3B, OPT-13B, Gemma2-2B
- **ViTs**: ViT-B/16, ViT-L/16

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **ZO æ–¹æ³•**ï¼š
  - MeZOï¼ˆæ ‡å‡† ZO-SGDï¼‰
  - SparseMeZO (S-MeZO)
  - HiZOOï¼ˆåŸºäº Hessian é¢„æ¡ä»¶ï¼‰
  - LOZOï¼ˆä½ç§©æ‰°åŠ¨ï¼‰
  - SubZeroï¼ˆåŒæŠ•å½±ä½ç§© ZOï¼‰
  - Subspace-MeZOï¼ˆæœ¬æ–‡æå‡ºçš„å­ç©ºé—´å˜ä½“ï¼Œæ—  GOï¼‰
- **FO æ–¹æ³•**ï¼ˆä½œä¸ºæ€§èƒ½ä¸Šé™å‚è€ƒï¼‰ï¼š
  - Adam
  - LoRA + Adam

### è¯„ä¼°æŒ‡æ ‡
- **å‡†ç¡®æ€§**ï¼ˆAccuracy/F1 Scoreï¼‰
- **æŸ¥è¯¢æ¬¡æ•°**ï¼ˆ#Queriesï¼‰
- **è¿è¡Œæ—¶é—´**ï¼ˆRuntime in secondsï¼‰
- **GPU æ˜¾å­˜å ç”¨**ï¼ˆGPU Memory in MBï¼‰
- **æ”¶æ•›é€Ÿåº¦**ï¼ˆTraining Loss vs. Runtimeï¼‰

### å®éªŒè®¾ç½®
- æ‰€æœ‰ ZO æ–¹æ³•åœ¨ç›¸åŒæŸ¥è¯¢é¢„ç®—ä¸‹æ¯”è¾ƒï¼ˆå¦‚ 40k queriesï¼‰ã€‚
- ZO-Muon è¶…å‚æ•°æœç´¢èŒƒå›´ï¼š
  - æŠ•å½±ç§© $ r \in \{64, 128\} $
  - æŸ¥è¯¢æ•° $ N_q \in \{4, 8, 16\} $
- æŠ•å½±çŸ©é˜µ $ P $ æ¯ 100 æ­¥æ‡’æƒ°æ›´æ–°ï¼ˆlazy resamplingï¼‰ã€‚
- ä½¿ç”¨ Newton-Schulz (NS) è¿­ä»£è¿‘ä¼¼ msign æ“ä½œä»¥æé«˜æ•ˆç‡ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 å’Œæ­£æ–‡ï¼‰

| ä»»åŠ¡ | æŒ‡æ ‡ | ZO-Muon | æœ€ä½³åŸºçº¿ | æå‡å¹…åº¦ |
|------|------|---------|----------|----------|
| **LLM: OPT-1.3B on SST-2** | Accuracy | **92.5%** | MeZO: 91.4% | +1.1% |
| **LLM: LLaMA3-8B on RTE** | Accuracy | **81.2%** | MeZO: 74.4% | +6.8% |
| **ViT: ViT-L on CIFAR-100** | Accuracy | **72.4%** | Subspace-MeZO: 64.7% | **+7.7%** |
| **ViT: ViT-B on CIFAR-100** | Accuracy | **72.6%** | MeZO: 64.5% | **+8.1%** |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **æŸ¥è¯¢æ•ˆç‡**ï¼šåœ¨ LLM å¾®è°ƒ SST-2 ä»»åŠ¡ä¸­ï¼ŒZO-Muon è¾¾åˆ°ç›®æ ‡ç²¾åº¦æ‰€éœ€çš„æŸ¥è¯¢æ•°ä»…ä¸º MeZO çš„ **24.7%**ã€‚
- **è¿è¡Œæ—¶é—´**ï¼šåœ¨ OPT-13B ä¸Šå¾®è°ƒ SST-2ï¼ŒZO-Muon ä»…éœ€ **2h 33min**ï¼Œæ¯” MeZOï¼ˆ3h 37minï¼‰å¿« **~30%**ï¼ˆè§ Table 2ï¼‰ã€‚
- **æ”¶æ•›é€Ÿåº¦**ï¼šåœ¨å¤šä¸ªä»»åŠ¡ä¸Šï¼ˆå¦‚ Fig. 1, A3ï¼‰ï¼ŒZO-Muon æ”¶æ•›é€Ÿåº¦æ˜¾è‘—å¿«äºæ‰€æœ‰åŸºçº¿æ–¹æ³•ã€‚
- **å° batch é²æ£’æ€§**ï¼šåœ¨ ViT-B/CIFAR-100 ä¸Šï¼Œå½“ batch size ä» 256 é™è‡³ 64 æ—¶ï¼š
  - MeZO æ€§èƒ½ä¸‹é™ **22.2%**
  - ZO-Muon ä»…ä¸‹é™ **6.2%**
  - ä¸” ZO-Muon (bs=64) ä»ä¼˜äº MeZO (bs=256)

### æ¶ˆèå®éªŒç»“æœ
- **å­ç©ºé—´ vs å…¨ç©ºé—´ GO**ï¼ˆFig. 5, A1ï¼‰ï¼š
  - ç›´æ¥åœ¨å…¨ç©ºé—´åº”ç”¨ GOï¼ˆZO-Muon-V0 æˆ– JAGUAR-Muonï¼‰æ•ˆæœä¸ä½³ï¼Œç”šè‡³ä¸å¦‚ MeZOã€‚
  - è¡¨æ˜ **å­ç©ºé—´æ˜¯ GO åœ¨ ZO ä¸­æœ‰æ•ˆçš„å‰æ**ã€‚
- **æŸ¥è¯¢æ•° $ N_q $ çš„å½±å“**ï¼ˆFig. A2ï¼‰ï¼š
  - Subspace-MeZO å­˜åœ¨â€œå¤šæŸ¥è¯¢æ‚–è®ºâ€ï¼š$ N_q > 1 $ æ—¶æ€§èƒ½åè€Œä¸‹é™ã€‚
  - ZO-Muon åˆ™å—ç›Šäºæ›´å¤šæŸ¥è¯¢ï¼ˆ$ N_q = 4 $ ä¼˜äº $ N_q = 1 $ï¼‰ï¼Œè¯´æ˜ GO èƒ½æœ‰æ•ˆåˆ©ç”¨å¤šæŸ¥è¯¢ä¿¡æ¯ã€‚
- **æŠ•å½±ç§© $ r $ çš„é€‰æ‹©**ï¼ˆFig. 6ï¼‰ï¼š
  - $ r = 64 $ æ—¶æ€§èƒ½æœ€ä½³ã€‚
  - $ r $ è¿‡å°ï¼ˆå¦‚ 16ï¼‰ä¼šä¸¢å¤±ä¿¡æ¯ï¼›è¿‡å¤§ï¼ˆå¦‚ 256ï¼‰ä¼šæ”¾å¤§å™ªå£°ï¼Œå¯¼è‡´åæœŸä¸ç¨³å®šã€‚
- **æŠ•å½±çŸ©é˜µæ›´æ–°é¢‘ç‡**ï¼ˆFig. A4ï¼‰ï¼š
  - æ¯æ­¥éƒ½æ›´æ–°ï¼ˆ$ v=1 $ï¼‰æ€§èƒ½æœ€å·®ã€‚
  - æ‡’æƒ°æ›´æ–°ï¼ˆ$ v=100 $ æˆ– $ 500 $ï¼‰æ•ˆæœæ›´å¥½ï¼Œè¡¨æ˜ç¨³å®šå­ç©ºé—´æœ‰åˆ©äºä¼˜åŒ–ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å­ç©ºé—´ + GO æ˜¯è§£å†³ ZO æ–¹å·®-æ•ˆç‡å›°å¢ƒçš„æœ‰æ•ˆè·¯å¾„**ï¼šå°†æ¢¯åº¦ä¼°è®¡é™åˆ¶åœ¨ä½ç»´å­ç©ºé—´å¯å¤§å¹…é™æ–¹å·®ï¼Œè€Œ GO èƒ½è¿›ä¸€æ­¥ä»å™ªå£°ä¼°è®¡ä¸­æå–æœ‰æ•ˆè°±æ–¹å‘ã€‚
2. **ZO-Muon å®ç°äº†â€œåŒèµ¢â€æ”¹è¿›**ï¼šåœ¨å‡†ç¡®æ€§å’ŒæŸ¥è¯¢/è¿è¡Œæ•ˆç‡ä¸ŠåŒæ—¶è¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œé¦–æ¬¡åœ¨ ZO ä¼˜åŒ–ä¸­å®ç°äºŒè€…å…¼é¡¾ã€‚
3. **å­ç©ºé—´è®¾è®¡è‡³å…³é‡è¦**ï¼šä½¿ç”¨åˆ—æ­£äº¤æŠ•å½±çŸ©é˜µ $ P $ èµ‹äºˆæ–¹æ³•æ¸…æ™°çš„å‡ ä½•è§£é‡Šï¼ˆä¼°è®¡æŠ•å½±æ¢¯åº¦ï¼‰ï¼Œä¼˜äº LOZO ç­‰éæ­£äº¤è®¾è®¡ã€‚
4. **å¤šæŸ¥è¯¢æ‚–è®ºå¯è¢«å…‹æœ**ï¼šé€šè¿‡å¼•å…¥ GOï¼ŒZO-Muon èƒ½æœ‰æ•ˆèšåˆå¤šæŸ¥è¯¢ä¿¡æ¯ï¼Œé¿å…æ€§èƒ½é€€åŒ–ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰å·¥ä½œèšç„¦äº**å‚æ•°é«˜æ•ˆå¾®è°ƒ**ï¼ˆPEFTï¼‰ï¼Œå°šæœªæ‰©å±•åˆ°å¤§è§„æ¨¡æ¨¡å‹çš„**å…¨é‡é¢„è®­ç»ƒ**ï¼ˆfull pre-trainingï¼‰ã€‚
- æ–¹æ³•ä¾èµ–äºå­ç©ºé—´å‡è®¾ï¼Œè‹¥æ¨¡å‹æ›´æ–°ä¸å…·å¤‡ä½ç§©ç»“æ„ï¼Œæ€§èƒ½å¯èƒ½å—é™ã€‚
- ä½¿ç”¨ NS è¿‘ä¼¼ msign è™½ç„¶é«˜æ•ˆï¼Œä½†åœ¨å¤§æ¨¡å‹ä¸Šä¸ SVD çš„ç²¾åº¦å·®è·ç•¥æœ‰æ‰©å¤§ï¼ˆFig. A5ï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† ZO-Muon æ‰©å±•è‡³å¤§è§„æ¨¡æ¨¡å‹çš„å…¨é‡é¢„è®­ç»ƒã€‚
- æ¢ç´¢è‡ªé€‚åº”å­ç©ºé—´é€‰æ‹©æˆ–åŠ¨æ€ç§©è°ƒæ•´ç­–ç•¥ã€‚
- ç»“åˆå…¶ä»– FO ä¼˜åŒ–æŠ€æœ¯ï¼ˆå¦‚å­¦ä¹ ç‡è°ƒåº¦ã€åŠ¨é‡ï¼‰è¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚
- åœ¨æ›´å¤šæ¨¡æ€ï¼ˆå¦‚å¤šæ¨¡æ€ã€è¯­éŸ³ï¼‰å’Œåº”ç”¨åœºæ™¯ï¼ˆå¦‚å¼ºåŒ–å­¦ä¹ ï¼‰ä¸­éªŒè¯æ–¹æ³•é€šç”¨æ€§ã€‚

> **ä»£ç å¼€æº**ï¼šhttps://github.com/OPTML-Group/ZO-Muon

</details>

---

### 16. [RLGT: A reinforcement learning framework for extremal graph theory](https://arxiv.org/abs/2602.17276)

**Authors**: Ivan Damnjanovi\'c, Uro\v{s} Milivojevi\'c, Irena {\DJ}or{\dj}evi\'c, Dragan Stevanovi\'c  
**Category**: cs.LG  
**Published**: 2026-02-20  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.17276v1  

#### Abstract
Reinforcement learning (RL) is a subfield of machine learning that focuses on developing models that can autonomously learn optimal decision-making strategies over time. In a recent pioneering paper, Wagner demonstrated how the Deep Cross-Entropy RL method can be applied to tackle various problems f...

---

### 17. [Toward Trustworthy Evaluation of Sustainability Rating Methodologies: A Human-AI Collaborative Framework for Benchmark Dataset Construction](https://arxiv.org/abs/2602.17106)

**Authors**: Xiaoran Cai, Wang Yang, Xiyu Ren, Chekun Law, Rohit Sharma, Peng Qi  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.17106v1  

#### Abstract
Sustainability or ESG rating agencies use company disclosures and external data to produce scores or ratings that assess the environmental, social, and governance performance of a company. However, sustainability ratings across agencies for a single company vary widely, limiting their comparability,...

---

### 18. [Continual learning and refinement of causal models through dynamic predicate invention](https://arxiv.org/abs/2602.17217)

**Authors**: Enrique Crespo-Fernandez, Oliver Ray, Telmo de Menezes e Silva Filho, Peter Flach  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.17217v1  

#### Abstract
Efficiently navigating complex environments requires agents to internalize the underlying logic of their world, yet standard world modelling methods often struggle with sample inefficiency, lack of transparency, and poor scalability. We propose a framework for constructing symbolic causal world mode...

---

### 19. [RPDR: A Round-trip Prediction-Based Data Augmentation Framework for Long-Tail Question Answering](https://arxiv.org/abs/2602.17366)

**Authors**: Yiming Zhang, Siyue Zhang, Junbo Zhao, Chen Zhao  
**Category**: cs.CL  
**Published**: 2026-02-20  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.17366v1  

#### Abstract
Long-tail question answering presents significant challenges for large language models (LLMs) due to their limited ability to acquire and accurately recall less common knowledge. Retrieval-augmented generation (RAG) systems have shown great promise in mitigating this limitation by integrating extern...

---

### 20. [What Language is This? Ask Your Tokenizer](https://arxiv.org/abs/2602.17655)

**Authors**: Clara Meister, Ahmetcan Yavuz, Pietro Lesci, Tiago Pimentel  
**Category**: cs.CL  
**Published**: 2026-02-20  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.17655v1  

#### Abstract
Language Identification (LID) is an important component of many multilingual natural language processing pipelines, where it facilitates corpus curation, training data analysis, and cross-lingual evaluation of large language models. Despite near-perfect performance on high-resource languages, existi...

---

### 21. [Multi-Probe Zero Collision Hash (MPZCH): Mitigating Embedding Collisions and Enhancing Model Freshness in Large-Scale Recommenders](https://arxiv.org/abs/2602.17050)

**Authors**: Ziliang Zhao, Bi Xue, Emma Lin, Mengjiao Zhou, Kaustubh Vartak, Shakhzod Ali-Zade, Carson Lu, Tao Li, Bin Kuang, Rui Jian, Bin Wen, Dennis van der Staay, Yixin Bao, Eddy Li, Chao Deng, Songbin Liu, Qifan Wang, Kai Ren  
**Category**: cs.LG  
**Published**: 2026-02-20  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.17050v1  

#### Abstract
Embedding tables are critical components of large-scale recommendation systems, facilitating the efficient mapping of high-cardinality categorical features into dense vector representations. However, as the volume of unique IDs expands, traditional hash-based indexing methods suffer from collisions ...

---

### 22. [Node Learning: A Framework for Adaptive, Decentralised and Collaborative Network Edge AI](https://arxiv.org/abs/2602.16814)

**Authors**: Eiman Kanjo, Mustafa Aslanov  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.16814v1  

#### Abstract
The expansion of AI toward the edge increasingly exposes the cost and fragility of cen- tralised intelligence. Data transmission, latency, energy consumption, and dependence on large data centres create bottlenecks that scale poorly across heterogeneous, mobile, and resource-constrained environments...

---

### 23. [All Leaks Count, Some Count More: Interpretable Temporal Contamination Detection in LLM Backtesting](https://arxiv.org/abs/2602.17234)

**Authors**: Zeyu Zhang, Ryan Chen, Bradly C. Stadie  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.17234v1  

#### Abstract
To evaluate whether LLMs can accurately predict future events, we need the ability to \textit{backtest} them on events that have already resolved. This requires models to reason only with information available at a specified past date. Yet LLMs may inadvertently leak post-cutoff knowledge encoded du...

---

### 24. [Visual Model Checking: Graph-Based Inference of Visual Routines for Image Retrieval](https://arxiv.org/abs/2602.17386)

**Authors**: Adri\`a Molina, Oriol Ramos Terrades, Josep Llad\'os  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.17386v1  

#### Abstract
Information retrieval lies at the foundation of the modern digital industry. While natural language search has seen dramatic progress in recent years largely driven by embedding-based models and large-scale pretraining, the field still faces significant challenges. Specifically, queries that involve...

---

### 25. [AutoNumerics: An Autonomous, PDE-Agnostic Multi-Agent Pipeline for Scientific Computing](https://arxiv.org/abs/2602.17607)

**Authors**: Jianda Du, Youran Sun, Haizhao Yang  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.17607v1  

#### Abstract
PDEs are central to scientific and engineering modeling, yet designing accurate numerical solvers typically requires substantial mathematical expertise and manual tuning. Recent neural network-based approaches improve flexibility but often demand high computational cost and suffer from limited inter...

---

### 26. [Trivance: Latency-Optimal AllReduce by Shortcutting Multiport Networks](https://arxiv.org/abs/2602.17254)

**Authors**: Anton Juerss, Vamsi Addanki, Stefan Schmid  
**Category**: cs.DC  
**Published**: 2026-02-20  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.17254v1  

#### Abstract
AllReduce is a fundamental collective operation in distributed computing and a key performance bottleneck for large-scale training and inference. Its completion time is determined by the number of communication steps, which dominates latency-sensitive workloads, and the communication distance affect...

---

### 27. [TopoFlow: Physics-guided Neural Networks for high-resolution air quality prediction](https://arxiv.org/abs/2602.16821)

**Authors**: Ammar Kheder, Helmi Toropainen, Wenqing Peng, Samuel Ant\~ao, Jia Chen, Zhi-Song Liu, Michael Boy  
**Category**: cs.LG  
**Published**: 2026-02-20  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.16821v1  

#### Abstract
We propose TopoFlow (Topography-aware pollutant Flow learning), a physics-guided neural network for efficient, high-resolution air quality prediction. To explicitly embed physical processes into the learning framework, we identify two critical factors governing pollutant dynamics: topography and win...

---

### 28. [IntentCUA: Learning Intent-level Representations for Skill Abstraction and Multi-Agent Planning in Computer-Use Agents](https://arxiv.org/abs/2602.17049)

**Authors**: Seoyoung Lee, Seobin Yoon, Seongbeen Lee, Yoojung Chun, Dayoung Park, Doyeon Kim, Joo Yong Sim  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.17049v1  

#### Abstract
Computer-use agents operate over long horizons under noisy perception, multi-window contexts, evolving environment states. Existing approaches, from RL-based planners to trajectory retrieval, often drift from user intent and repeatedly solve routine subproblems, leading to error accumulation and ine...

---

### 29. [Mechanistic Interpretability of Cognitive Complexity in LLMs via Linear Probing using Bloom's Taxonomy](https://arxiv.org/abs/2602.17229)

**Authors**: Bianca Raimondi, Maurizio Gabbrielli  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.17229v1  

#### Abstract
The black-box nature of Large Language Models necessitates novel evaluation frameworks that transcend surface-level performance metrics. This study investigates the internal neural representations of cognitive complexity using Bloom's Taxonomy as a hierarchical lens. By analyzing high-dimensional ac...

---

### 30. [A Privacy by Design Framework for Large Language Model-Based Applications for Children](https://arxiv.org/abs/2602.17418)

**Authors**: Diana Addae, Diana Rogachova, Nafiseh Kahani, Masoud Barati, Michael Christensen, Chen Zhou  
**Category**: cs.AI  
**Published**: 2026-02-20  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.17418v1  

#### Abstract
Children are increasingly using technologies powered by Artificial Intelligence (AI). However, there are growing concerns about privacy risks, particularly for children. Although existing privacy regulations require companies and organizations to implement protections, doing so can be challenging in...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- kv cache, offload, State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
