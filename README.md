# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-01-15 05:57:00 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Parallel Context-of-Experts Decoding for Retrieval Augmented Generation](https://arxiv.org/abs/2601.08670)

**Authors**: Giulio Corallo, Paolo Papotti  
**Category**: cs.AI  
**Published**: 2026-01-15  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2601.08670v1  

#### Abstract
Retrieval Augmented Generation faces a trade-off: concatenating documents in a long prompt enables multi-document reasoning but creates prefill bottlenecks, while encoding document KV caches separately offers speed but breaks cross-document interaction. We propose Parallel Context-of-Experts Decodin...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šParallel Context-of-Experts Decoding for Retrieval Augmented Generation**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
Retrieval-Augmented Generation (RAG) é¢ä¸´ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼š
- **Prefill ç“¶é¢ˆ**ï¼šå°†å¤šä¸ªæ£€ç´¢æ–‡æ¡£æ‹¼æ¥æˆä¸€ä¸ªé•¿ä¸Šä¸‹æ–‡ä¼šå¯¼è‡´æ¨ç†æ—¶ `prefill` é˜¶æ®µå»¶è¿Ÿæ˜¾è‘—å¢åŠ ã€‚
- **è·¨æ–‡æ¡£æ¨ç†èƒ½åŠ›ä¸‹é™**ï¼šè™½ç„¶å¹¶è¡Œ KV cache ç¼–ç ï¼ˆå¦‚ KV Mergeï¼‰èƒ½åŠ é€Ÿ `prefill`ï¼Œä½†ç”±äºç¼ºä¹è·¨æ–‡æ¡£ attentionï¼Œæ¨¡å‹éš¾ä»¥è¿›è¡Œ multi-hop æ¨ç†ã€‚

ç°æœ‰æ–¹æ³•åœ¨æ•ˆç‡ä¸æ•ˆæœä¹‹é—´å­˜åœ¨æƒè¡¡ï¼šé•¿ä¸Šä¸‹æ–‡æ‹¼æ¥æ”¯æŒè·¨æ–‡æ¡£äº¤äº’ä½†æ…¢ï¼›ç‹¬ç«‹ KV cache å¿«ä½†ç‰ºç‰²æ¨ç†èƒ½åŠ›ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ï¼šPCED**
ä½œè€…æå‡ºäº† **Parallel Context-of-Experts Decoding (PCED)**ï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„ decoding æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> å°†æ¯ä¸ªæ£€ç´¢åˆ°çš„æ–‡æ¡£è§†ä¸ºä¸€ä¸ªç‹¬ç«‹çš„â€œä¸“å®¶â€ï¼ˆExpertï¼‰ï¼Œé€šè¿‡ **decode-time çš„å¯¹æ¯”è§£ç æœºåˆ¶** èšåˆè¿™äº›ä¸“å®¶çš„è¾“å‡ºï¼Œè€Œéä¾èµ–å…±äº« attention ä¸Šä¸‹æ–‡ã€‚

#### **ä¸‰å¤§åˆ›æ–°ç‚¹**ï¼š
1. **å¹¶è¡Œã€æ¨¡å—åŒ–çš„ KV cache æ¡†æ¶ + è§£ç æ—¶è¯æ®èšåˆ**
   - æ¯ä¸ªæ–‡æ¡£ç‹¬ç«‹ç¼–ç ä¸º KV cacheï¼Œé¿å…é‡å¤ `prefill`ã€‚
   - åœ¨ç”Ÿæˆæ¯ä¸€æ­¥æ—¶ï¼Œå¹¶è¡Œè¿è¡Œæ‰€æœ‰ä¸“å®¶å‰å‘ä¼ æ’­ï¼Œè·å¾—å„è‡ªçš„ logitsã€‚

2. **åŸºäºæ£€ç´¢æ„ŸçŸ¥çš„å¯¹æ¯”è§£ç ï¼ˆRetrieval-aware Contrastive Decodingï¼‰**
   - å¼•å…¥ä¸€ä¸ªæ— ä¸Šä¸‹æ–‡çš„â€œä¸šä½™ä¸“å®¶â€ï¼ˆAmateur Expertï¼‰ä½œä¸ºæ¨¡å‹å…ˆéªŒ $ s_0 $ã€‚
   - å¯¹æ¯ä¸ªä¸“å®¶ $ k $ çš„ logits è¿›è¡Œæ ¡å‡†ï¼š
     $$
     \tilde{s}_k = (1+\beta)s_k - \beta s_0 + \gamma \log r_k
     $$
     å…¶ä¸­ $ r_k $ æ˜¯è¯¥æ–‡æ¡£çš„æ£€ç´¢ç›¸å…³æ€§å¾—åˆ†ï¼ˆèåˆ retrieval å’Œ reranker å¾—åˆ†ï¼‰ã€‚
   - æœ€ç»ˆé€‰æ‹©æ‰€æœ‰ä¸“å®¶ä¸­å¾—åˆ†æœ€é«˜çš„ token ä½œä¸ºè¾“å‡ºã€‚

3. **åŠ¨æ€ä¸“å®¶åˆ‡æ¢å®ç°è·¨æ–‡æ¡£æ¨ç†**
   - ä¸åŒç”Ÿæˆæ­¥éª¤å¯ç”±ä¸åŒä¸“å®¶ä¸»å¯¼ï¼Œå®ç°â€œè·³è·ƒå¼â€è¯æ®æ‹¼æ¥ï¼ˆå¦‚å›¾2æ‰€ç¤ºï¼‰ã€‚
   - æ— éœ€æ„å»ºè”åˆ attention ä¸Šä¸‹æ–‡å³å¯æ¢å¤è·¨æ–‡æ¡£æ¨ç†èƒ½åŠ›ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹æ³• | ä¼˜åŠ¿ | å±€é™ |
|------|------|------|
| **Concatenation (All)** | æ”¯æŒè·¨æ–‡æ¡£ attention | Prefill æˆæœ¬é«˜ï¼Œæ˜“å—å™ªå£°å¹²æ‰° |
| **KV Merge (e.g., APE)** | åŠ é€Ÿ prefill | æ— æ³•æ¢å¤è·¨æ–‡æ¡£äº¤äº’ï¼Œæ€§èƒ½å·® |
| **Agentic (e.g., MapReduce)** | æ˜¾å¼å¤šæ­¥èšåˆ | å¤šè½® LLM è°ƒç”¨ï¼Œå»¶è¿Ÿé«˜ |
| **PCED (æœ¬æ–‡)** | âœ… æ— éœ€è®­ç»ƒ<br>âœ… ä¿ç•™ KV æ¨¡å—åŒ–<br>âœ… æ¢å¤è·¨æ–‡æ¡£æ¨ç†<br>âœ… æå¤§é™ä½ TTFT | ä¾èµ– logits è®¿é—®æƒé™ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **LOFT Benchmark**ï¼šæ¶µç›– RAG å’Œ In-Context Learning (ICL) ä»»åŠ¡ï¼ŒåŒ…å«å¤šè·³é—®ç­”ï¼ˆå¦‚ HOTPOTQAã€MUSIQUEï¼‰ã€å•æ–‡æ¡£é—®ç­”ï¼ˆRAG NQï¼‰ã€å¼€æ”¾ç”Ÿæˆï¼ˆQAMPARIï¼‰ç­‰ã€‚
- **LongBench**ï¼šå¤šè¯­è¨€ã€å¤šä»»åŠ¡é•¿ä¸Šä¸‹æ–‡ç†è§£åŸºå‡†ï¼Œç”¨äºæµ‹è¯•å•æ–‡æ¡£ä¸å¤šæ–‡æ¡£ QAã€æ‘˜è¦ã€ä»£ç è¡¥å…¨ç­‰ã€‚
- **åˆæˆæ•°æ®é›†**ï¼šç”¨äºæ§åˆ¶å˜é‡æµ‹è¯•å»¶è¿Ÿï¼ˆTTFT å’Œ end-to-end latencyï¼‰ï¼ŒåŒ…å« 64 ä¸ªæ–‡æ¡£ï¼ˆ1 ä¸ªå« secret codeï¼Œå…¶ä½™ä¸º distractorsï¼‰ã€‚

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**
| é¡¹ç›® | è®¾ç½® |
|------|------|
| **LLM** | Mistral-Nemo-13B-Instruct, Llama-3.1-8B-Instruct, Qwen3-8Bï¼ˆæ‰©å±•è‡³ 128kï¼‰ |
| **æ£€ç´¢å™¨** | BGE-M3ï¼ˆæ”¯æŒ sparse/dense/ColBERT æ¨¡å¼ï¼‰ |
| **é‡æ’åºå™¨** | BGE-Reranker-V2-M3 |
| **ç›¸å…³æ€§åˆ†æ•°èåˆ** | retrieval ä¸ reranker åˆ†æ•°çš„è°ƒå’Œå¹³å‡ |
| **è§£ç æ–¹å¼** | Greedy decoding |
| **è¯„ä¼°æŒ‡æ ‡** | <br>- RAG ä»»åŠ¡ï¼šSubspan Exact Match<br>- ICL ä»»åŠ¡ï¼šExact Match<br>- LongBenchï¼šå®˜æ–¹æŒ‡æ ‡ï¼ˆå¦‚ F1ã€EMï¼‰ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| ç±»åˆ« | æ–¹æ³• |
|------|------|
| **æ ‡å‡†æ‹¼æ¥** | Corpus in Ctx (Single / All) |
| **KV Cache åˆå¹¶** | APEï¼ˆAdaptive Parallel Encodingï¼‰ |
| **Agent-style èšåˆ** | MapReduceï¼ˆMap: summarize each doc â†’ Reduce: aggregateï¼‰ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 1 & Table 2ï¼‰**

#### **åœ¨ LOFT ä¸Šçš„è¡¨ç°ï¼ˆä»¥ Llama-3.1-8B ä¸ºä¾‹ï¼‰**
| ä»»åŠ¡ | APE | MapReduce | PCED-Dense | Corpus in Ctx (All) |
|------|-----|-----------|------------|---------------------|
| HOTPOTQA | 16.0 | 41.0 | **64.0** | 49.0 |
| MUSIQUE | 4.0 | 8.0 | **21.0** | 7.0 |
| RAG NQ | 9.0 | 50.0 | **85.0** | 79.0 |
| QAMPARI | 7.0 | 68.0 | **76.0** | 72.0 |

> âœ… PCED åœ¨å¤šè·³ QA ä¸Šå¤§å¹…è¶…è¶Šæ‰€æœ‰ baselineï¼Œæœ€é«˜æå‡è¾¾ **+48 pts**ï¼ˆvs APEï¼‰

#### **åœ¨ LongBench ä¸Šçš„è¡¨ç°ï¼ˆQwen3-8Bï¼‰**
| ä»»åŠ¡ | Corpus in Ctx (All) | PCED-Dense |
|------|---------------------|------------|
| HOTPOTQA | 56.3 | **62.6** (+6.3) |
| 2WikiMQA | 44.2 | **49.4** (+5.2) |
| MUSIQUE | 25.3 | **33.3** (+8.0) |
| TriviaQA | 84.0 | **88.2** (+4.2) |
| RepoBench-P (Code) | 51.1 | **60.1** (+9.0) |

> âœ… å³ä½¿åœ¨å®Œæ•´ä¸Šä¸‹æ–‡ baseline ä¸‹ï¼ŒPCED ä»å…¨é¢é¢†å…ˆï¼Œå°¤å…¶åœ¨å¤æ‚æ¨ç†å’Œä»£ç ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- **vs KV Merge (APE)**ï¼šPCED åœ¨å¤šè·³ä»»åŠ¡ä¸Šå¹³å‡æå‡ **>40 pts**ï¼Œè¯´æ˜ decode-time èšåˆæœ‰æ•ˆæ¢å¤äº†è·¨æ–‡æ¡£æ¨ç†ã€‚
- **vs MapReduce**ï¼šPCED åœ¨å¤šæ•°ä»»åŠ¡ä¸Šæ›´ä¼˜ï¼ˆå¦‚ HOTPOTQA +23 ptsï¼‰ï¼Œä¸”ä»…éœ€ä¸€æ¬¡ decodingï¼Œè€Œ MapReduce éœ€å¤šæ¬¡ LLM è°ƒç”¨ã€‚
- **vs Concatenation (All)**ï¼šPCED åœ¨ 11/16 è®¾ç½®ä¸‹ä¼˜äº full-context æ‹¼æ¥ï¼Œå°¤å…¶åœ¨å™ªå£°ç¯å¢ƒä¸‹æ›´å…·é²æ£’æ€§ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰**

#### **(1) å¯¹æ¯”è§£ç  vs æ£€ç´¢å…ˆéªŒçš„ä½œç”¨ï¼ˆTable 3 & Table 6ï¼‰**
| è®¾ç½® | HOTPOTQA (Llama) | NQ (Llama) |
|------|------------------|----------|
| Only Contrastive ($\gamma=0$) | 46 | 52 |
| Only Retrieval Prior ($\beta=0$) | 53 | 70 |
| Full PCED ($\beta>0, \gamma>0$) | **64** | **85** |

> ğŸ” ç»“è®ºï¼šä¸¤è€…ç¼ºä¸€ä¸å¯ã€‚**æ£€ç´¢å…ˆéªŒç”¨äºæŠ‘åˆ¶å™ªå£°**ï¼Œ**å¯¹æ¯”è§£ç ç”¨äºæ”¾å¤§ä¸Šä¸‹æ–‡ä¿¡å·**ã€‚

#### **(2) å‚æ•°æ•æ„Ÿæ€§åˆ†æ**
- $\beta$ï¼ˆå¯¹æ¯”å¼ºåº¦ï¼‰ï¼šåŠ¨æ€ç­–ç•¥ï¼ˆAdaCAD-inspiredï¼‰æœ€ç¨³å®šã€‚
- $\gamma$ï¼ˆæ£€ç´¢é—¨æ§æƒé‡ï¼‰ï¼š$\gamma=2.5$ ä¸ºæœ€ä¼˜å¹³è¡¡ç‚¹ï¼Œè¿‡é«˜ä¼šè¿‡åº¦ä¾èµ–æ£€ç´¢æ’åºã€‚

#### **(3) ä¸“å®¶èšåˆè§„åˆ™ï¼ˆTable 7ï¼‰**
| èšåˆæ–¹å¼ | HOTPOTQA | NQ |
|--------|---------|----|
| Maxï¼ˆæœ¬æ–‡ï¼‰ | **64** | 85 |
| Mixture (MoE) | 56 | **87** |
| Product (PoE) | 46 | 85 |

> ğŸ“Œ å‘ç°ï¼š**Max æ›´é€‚åˆ multi-hop QA**ï¼ˆå…è®¸ token-level åˆ‡æ¢ä¸“å®¶ï¼‰ï¼›**MoE æ›´é€‚åˆå•æ–‡æ¡£ä»»åŠ¡**ï¼ˆè½¯èåˆæ›´å¹³æ»‘ï¼‰ã€‚

#### **(4) æŠ—å™ªèƒ½åŠ›æµ‹è¯•ï¼ˆFigure 6ï¼‰**
- å½“ top-k ä» 8 å¢åŠ åˆ° 128ï¼ˆå³åŠ å…¥æ›´å¤š distractorsï¼‰ï¼ŒPCED æ€§èƒ½å‡ ä¹ä¸å˜ï¼ˆå¦‚ NQ ä¿æŒ ~85ï¼‰ã€‚
- è¡¨æ˜ **retrieval prior æœ‰æ•ˆæŠ‘åˆ¶äº†æ— å…³ä¸“å®¶çš„å½±å“**ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. âœ… **è·¨æ–‡æ¡£æ¨ç†å¯åœ¨ decode time å®ç°**ï¼šæ— éœ€å…±äº« attention ä¸Šä¸‹æ–‡ï¼Œé€šè¿‡ expert logit fusion å³å¯æ¢å¤ multi-hop æ¨ç†èƒ½åŠ›ã€‚
2. âœ… **æ£€ç´¢åˆ†æ•°ä¸ä»…æ˜¯æ’åºå·¥å…·ï¼Œæ›´æ˜¯ decoding å…ˆéªŒ**ï¼šåˆ©ç”¨ retrieval/reranker åˆ†æ•°ä½œä¸º gating signal å¯æ˜¾è‘—æå‡æŠ—å™ªèƒ½åŠ›ã€‚
3. âœ… **PCED æ•ˆç‡æé«˜**ï¼šTime-To-First-Token (TTFT) è¾ƒ vanilla æ–¹æ³•å¿« **180Ã—**ï¼ˆ0.14s vs 25.50sï¼‰ï¼Œç«¯åˆ°ç«¯å»¶è¿Ÿé™ä½ ~1.7Ã—ã€‚
4. âœ… **ä¼˜äº full-context baseline**ï¼šåœ¨å¤šä¸ª benchmark ä¸ŠåŒ¹é…ç”šè‡³è¶…è¿‡å°†æ‰€æœ‰æ–‡æ¡£æ‹¼æ¥è¿› context çš„æ–¹æ³•ã€‚

---

### **å±€é™æ€§**
1. **ä¾èµ–æ¨¡å‹ logits è®¿é—®æƒé™**  
   - PCED éœ€è¦è·å–æ¯ä¸ªä¸“å®¶çš„ token-level logitsï¼Œå› æ­¤ä¸é€‚ç”¨äºä»…æä¾› sampled token æˆ– logprob å­é›†çš„ API æ¨¡å‹ï¼ˆå¦‚ GPT-4ï¼‰ã€‚

2. **å¯¹æ£€ç´¢è´¨é‡æ•æ„Ÿ**  
   - è‹¥å…³é”®è¯æ®æœªè¢«æ£€ç´¢åˆ°æˆ–è¯„åˆ†è¿‡ä½ï¼Œå¯¹åº”ä¸“å®¶å¯èƒ½è¢«å¿½ç•¥ï¼Œæ— æ³•æ¢å¤ä¿¡æ¯ã€‚

3. **å­˜å‚¨å¼€é”€è¾ƒå¤§**  
   - éœ€é¢„å…ˆå­˜å‚¨æ¯ä¸ªæ–‡æ¡£çš„ KV cacheï¼Œå­˜å‚¨æˆæœ¬éšè¯­æ–™è§„æ¨¡çº¿æ€§å¢é•¿ï¼ˆä¾‹å¦‚ LOFT æ•°æ®é›†çº¦éœ€ 11GB FP16 å­˜å‚¨ï¼‰ã€‚
   - é€‚åˆè¯»å¤šå†™å°‘çš„é™æ€çŸ¥è¯†åº“åœºæ™¯ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
- **ç«¯åˆ°ç«¯å­¦ä¹  expert selection**ï¼šè®© LLM è‡ªä¸»å­¦ä¹ åœ¨æ¯ä¸€æ­¥é€‰æ‹©å“ªä¸ª context è¾“å…¥ï¼Œå‡å°‘å¯¹å¤–éƒ¨ retrieval pipeline çš„ä¾èµ–ã€‚
- **è½»é‡åŒ– KV cache å­˜å‚¨**ï¼šæ¢ç´¢é‡åŒ–ã€å‹ç¼©ã€ç¨€ç–åŒ–ç­‰æŠ€æœ¯é™ä½å­˜å‚¨æˆæœ¬ã€‚
- **é€‚é…é—­æºæ¨¡å‹**ï¼šè®¾è®¡ proxy-based æˆ– token-level approximation æ–¹æ³•ï¼Œä½¿ PCED å¯ç”¨äº API-only æ¨¡å‹ã€‚

---

## **æ€»ç»“**
PCED æå‡ºäº†ä¸€ç§å…¨æ–°çš„è§†è§’ï¼š**å°† RAG ä¸­çš„â€œä¸Šä¸‹æ–‡èåˆâ€ä» attention å±‚è½¬ç§»åˆ° decoding å±‚**ã€‚å®ƒé€šè¿‡â€œä¸“å®¶ç³»ç»Ÿ + å¯¹æ¯”è§£ç â€çš„èŒƒå¼ï¼Œåœ¨ä¿æŒé«˜æ•ˆå¹¶è¡Œå¤„ç†çš„åŒæ—¶ï¼ŒæˆåŠŸæ¢å¤äº†è·¨æ–‡æ¡£æ¨ç†èƒ½åŠ›ï¼Œå®ç°äº† **é€Ÿåº¦ã€å‡†ç¡®æ€§ã€é²æ£’æ€§** çš„ä¸‰é‡æå‡ï¼Œä¸ºå¤§è§„æ¨¡ RAG ç³»ç»Ÿæä¾›äº†æå…·å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 2. [Contrastive Bi-Encoder Models for Multi-Label Skill Extraction: Enhancing ESCO Ontology Matching with BERT and Attention Mechanisms](https://arxiv.org/abs/2601.09119)

**Authors**: Yongming Sun  
**Category**: cs.CL  
**Published**: 2026-01-15  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2601.09119v1  

#### Abstract
Fine-grained labor market analysis increasingly relies on mapping unstructured job advertisements to standardized skill taxonomies such as ESCO. This mapping is naturally formulated as an Extreme Multi-Label Classification (XMLC) problem, but supervised solutions are constrained by the scarcity and ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šContrastive Bi-Encoder Models for Multi-Label Skill Extraction: Enhancing ESCO Ontology Matching with BERT and Attention Mechanisms

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**åŠ³åŠ¨åŠ›å¸‚åœºåˆ†æä¸­æŠ€èƒ½æå–çš„æ ‡æ³¨æ•°æ®ç¨€ç¼ºé—®é¢˜**ï¼Œå°¤å…¶æ˜¯åœ¨éè‹±è¯­è¯­å¢ƒä¸‹ï¼ˆå¦‚ä¸­æ–‡æ‹›è˜å¹¿å‘Šï¼‰ï¼Œå°†éç»“æ„åŒ–èŒä½æè¿°æ˜ å°„åˆ°æ ‡å‡†åŒ–æŠ€èƒ½æœ¬ä½“ï¼ˆå¦‚ESCOï¼‰é¢ä¸´å·¨å¤§æŒ‘æˆ˜ã€‚ä¼ ç»Ÿç›‘ç£å­¦ä¹ æ–¹æ³•å—é™äºå¤§è§„æ¨¡ã€å¯¹é½çš„æ ‡æ³¨æ•°æ®æˆæœ¬é«˜æ˜‚ä¸”éš¾ä»¥è·å–ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§**é›¶æ ·æœ¬ï¼ˆzero-shotï¼‰æŠ€èƒ½æå–æ¡†æ¶**ï¼Œæ— éœ€ä¾èµ–äººå·¥æ ‡æ³¨çš„æ‹›è˜å¹¿å‘Šè®­ç»ƒæ•°æ®ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **å±‚æ¬¡çº¦æŸçš„åˆæˆæ•°æ®ç”Ÿæˆï¼ˆHierarchy-conditioned synthetic supervisionï¼‰**  
  åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLM, DeepSeek-V3ï¼‰ä»ESCOæŠ€èƒ½å®šä¹‰ä¸­è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒæ ·æœ¬ï¼Œå¹¶å¼•å…¥**ESCO Level-2ç±»åˆ«ä½œä¸ºç»“æ„çº¦æŸ**ï¼Œç¡®ä¿å¤šæŠ€èƒ½å…±ç°å¥å­åœ¨è¯­ä¹‰ä¸Šæ›´è¿è´¯ã€çœŸå®ï¼Œé¿å…éšæœºç»„åˆå¯¼è‡´çš„è¯­ä¹‰æ¼‚ç§»æˆ–ä¸åˆç†çš„æ ‡ç­¾ç»„åˆã€‚

- **åŸºäºå¯¹æ¯”å­¦ä¹ çš„åŒç¼–ç å™¨æ¶æ„ï¼ˆContrastive bi-encoder for XMLCï¼‰**  
  æ„å»ºä¸€ä¸ªå…±äº«åµŒå…¥ç©ºé—´çš„å¯¹æ¯”å­¦ä¹ æ¨¡å‹ï¼Œå°†æ‹›è˜å¹¿å‘Šå¥å­ä¸ESCOæŠ€èƒ½æè¿°è¿›è¡Œå¯¹é½ã€‚æ¨¡å‹ä»¥ `BERT` ä¸ºéª¨å¹²ï¼Œç»“åˆ `BiLSTM` å’Œ `attention pooling`ï¼Œå¢å¼ºå¯¹é•¿å¥ã€å¤åˆè¦æ±‚çš„ç†è§£èƒ½åŠ›ã€‚

- **ç«¯åˆ°ç«¯æŠ½å–æµæ°´çº¿ï¼ˆEnd-to-end extraction pipelineï¼‰**  
  å¼•å…¥ä¸€ä¸ªä¸Šæ¸¸çš„ `RoBERTa` äºŒåˆ†ç±»è¿‡æ»¤å™¨ï¼Œç”¨äºè¯†åˆ«å¹¶å‰”é™¤éæŠ€èƒ½ç›¸å…³å¥å­ï¼ˆå¦‚è–ªèµ„ã€å…¬å¸ä»‹ç»ç­‰ï¼‰ï¼Œæå‡æ•´ä½“ç³»ç»Ÿçš„ç²¾åº¦å’Œæ•ˆç‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ‘†è„±å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–**ï¼šé€šè¿‡LLMç”Ÿæˆé«˜è´¨é‡åˆæˆæ•°æ®ï¼Œå®ç°çœŸæ­£çš„zero-shotè¿ç§»ã€‚
- **æ›´å¼ºçš„è¯­ä¹‰åŒ¹é…èƒ½åŠ›**ï¼šç›¸æ¯”TF-IDFã€BM25ç­‰åŸºäºè¯é¢‘çš„æ–¹æ³•ï¼Œèƒ½å¤„ç†åŒä¹‰æ›¿æ¢ã€éšå«è¡¨è¾¾å’Œä¸Šä¸‹æ–‡ä¾èµ–ã€‚
- **æ›´å¥½çš„å¤šæ ‡ç­¾å»ºæ¨¡**ï¼šåˆ©ç”¨ESCOå±‚çº§ç»“æ„å¼•å¯¼å¤šæŠ€èƒ½ç”Ÿæˆï¼Œæå‡äº†å¤šæ ‡ç­¾é¢„æµ‹çš„åˆç†æ€§å’Œä¸€è‡´æ€§ã€‚
- **å¯æ‰©å±•æ€§å¼º**ï¼šé€‚ç”¨äºå¤§æ ‡ç­¾ç©ºé—´ï¼ˆ13,890ä¸ªESCO Level-4æŠ€èƒ½ï¼‰ï¼Œæ”¯æŒè¿‘ä¼¼æœ€è¿‘é‚»æ£€ç´¢ï¼Œé€‚åˆå®é™…åº”ç”¨éƒ¨ç½²ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
| ç±»å‹ | åç§° | æè¿° |
|------|------|------|
| **æŠ€èƒ½æœ¬ä½“** | ESCO v1.1 | åŒ…å«13,890ä¸ªLevel-4æŠ€èƒ½èŠ‚ç‚¹ï¼Œæ¯ä¸ªæŠ€èƒ½æœ‰åç§°å’Œæ–‡æœ¬å®šä¹‰ï¼›ä½œè€…å°†å…¶æ‰‹åŠ¨ç¿»è¯‘æˆä¸­æ–‡ç”¨äºè®­ç»ƒä¸æ¨ç†ã€‚ |
| **çœŸå®æ‹›è˜æ•°æ®** | Zhaopin.com | æ¥è‡ªä¸­å›½æœ€å¤§æ‹›è˜å¹³å°ä¹‹ä¸€çš„çœŸå®èŒä½å¹¿å‘Šï¼Œæ¶µç›–2015â€“2023å¹´ï¼Œä»ä¸­é‡‡æ ·20ä¸‡æ¡å¹¿å‘Šï¼Œè¿›ä¸€æ­¥åˆ‡åˆ†ä¸ºå¥å­çº§å•å…ƒç”¨äºè¯„ä¼°ã€‚ |

### å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼š
  - ç¼–ç å™¨ï¼š`bert-base-chinese` ä½œä¸ºä¸»å¹²
  - å¢å¼ºæ¨¡å—ï¼š`BiLSTM` + `attention pooling` + æŠ•å½±å±‚ï¼ˆè¾“å‡ºç»´åº¦d=128ï¼‰
  - æŸå¤±å‡½æ•°ï¼šmargin-based contrastive lossï¼ˆmargin=0.5ï¼‰ï¼Œæ¯æ­£æ ·æœ¬é…Kä¸ªè´Ÿæ ·æœ¬
- **è®­ç»ƒæ–¹å¼**ï¼š
  - ä½¿ç”¨åˆæˆæ•°æ®è¿›è¡Œå¯¹æ¯”å­¦ä¹ è®­ç»ƒ
  - å¥å­è¿‡æ»¤å™¨ä½¿ç”¨ `RoBERTa-base` åœ¨åˆæˆæ­£è´Ÿæ ·æœ¬ä¸Šå¾®è°ƒ
- **æ¨ç†æµç¨‹**ï¼š
  1. åˆ†å¥ â†’ 2. è¿‡æ»¤éæŠ€èƒ½å¥ â†’ 3. å¥å­ç¼–ç  â†’ 4. ä¸é¢„è®¡ç®—çš„ESCOæŠ€èƒ½å‘é‡åšä½™å¼¦ç›¸ä¼¼åº¦æ£€ç´¢ â†’ 5. èšåˆæ‰€æœ‰å¥å­ç»“æœå–å¹¶é›†å¾—åˆ°å²—ä½çº§é¢„æµ‹

### è¯„ä¼°æŒ‡æ ‡
- **å¥å­çº§æ£€ç´¢æ€§èƒ½**ï¼šMRRã€Recall@Kã€mAP
- **å²—ä½çº§å¤šæ ‡ç­¾åˆ†ç±»æ€§èƒ½**ï¼šPrecision@Kã€Recall@Kã€F1@Kï¼ˆK=1,3,5ï¼‰ã€AUPRC
- **è¿‡æ»¤å™¨æ€§èƒ½**ï¼šAccuracyã€Precisionã€Recallã€F1ã€PRæ›²çº¿
- **åˆæˆæ•°æ®è´¨é‡**ï¼šGPT-2 perplexityã€ROC-AUCï¼ˆåŒºåˆ†æŠ€èƒ½/éæŠ€èƒ½å¥çš„èƒ½åŠ›ï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿æ–¹æ³• | ç±»å‹ | è¯´æ˜ |
|--------|------|------|
| TF-IDF | è¯è¢‹æ¨¡å‹ | å°†å¥å­ä¸ESCOå®šä¹‰åšTF-IDFå‘é‡åŒ–åè®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ |
| BM25 | æ£€ç´¢æ¨¡å‹ | ç»å…¸çš„ä¿¡æ¯æ£€ç´¢ç®—æ³•ï¼Œç”¨äºæ¯”è¾ƒ |
| Model A: Standard BERT (Single Label) | å•æ ‡ç­¾å¯¹æ¯”æ¨¡å‹ | ä»…ä½¿ç”¨å•æŠ€èƒ½æ ·æœ¬è®­ç»ƒçš„æ ‡å‡†BERTåŒç¼–ç å™¨ |
| Model B: BERT + BiLSTM + Attention (Single Label) | å•æ ‡ç­¾ä¼˜åŒ–æ¨¡å‹ | åŠ å…¥åºåˆ—å»ºæ¨¡å’Œæ³¨æ„åŠ›æ± åŒ–çš„å•æ ‡ç­¾æ¨¡å‹ |
| Keyword Matching / Zero-Shot NLI | è§„åˆ™/é€šç”¨æ¨¡å‹ | ç”¨äºè¿‡æ»¤ä»»åŠ¡çš„å¯¹æ¯”åŸºçº¿ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆçœŸå®æ•°æ®ä¸Šçš„end-to-endè¡¨ç°ï¼‰
| æ¨¡å‹ | AUPRC | F1 |
|------|-------|-----|
| Model A (Standard BERT) | 0.72 | 0.69 |
| Model B (Optimized, Single) | 0.82 | 0.75 |
| **Model C (Proposed, Multi-Label)** | **0.90** | **0.80** |

> åœ¨çœŸå®ä¸­æ–‡æ‹›è˜å¹¿å‘Šä¸Šçš„zero-shotæµ‹è¯•ä¸­ï¼Œ**Model Cè¾¾åˆ°F1@5 = 0.80**ï¼Œæ˜¾è‘—ä¼˜äºåŸºçº¿ã€‚

æ­¤å¤–ï¼Œåœ¨æœ€ç»ˆè°ƒå‚åçš„è®¾å®šä¸‹ï¼Œç³»ç»Ÿå®ç°äº† **F1@5 = 0.72** çš„æŠ¥å‘Šå€¼ï¼ˆè§æ‘˜è¦ï¼‰ï¼Œè¡¨æ˜å…¶å…·å¤‡è¾ƒå¼ºçš„å®ç”¨ä»·å€¼ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ç›¸æ¯”TF-IDFå’Œæ ‡å‡†BERTåŸºçº¿**ï¼š
  - Model Cåœ¨Recall@5ä¸Šé«˜å‡ºçº¦40ä¸ªç™¾åˆ†ç‚¹ï¼ˆTable 3ï¼‰
  - åœ¨çœŸå®æ•°æ®ä¸ŠF1æå‡è¶…è¿‡10ä¸ªç™¾åˆ†ç‚¹
- **è¿‡æ»¤å™¨æ•ˆæœ**ï¼š
  - RoBERTaè¿‡æ»¤å™¨å‡†ç¡®ç‡è¾¾ **87.5%**ï¼ŒF1ä¸º **0.874**
  - æ˜¾è‘—ä¼˜äºå…³é”®è¯è§„åˆ™ï¼ˆF1=0.75ï¼‰å’Œé›¶æ ·æœ¬NLIæ¨¡å‹ï¼ˆF1=0.80ï¼‰
  - ç§»é™¤è´Ÿæ ·æœ¬è®­ç»ƒä¼šå¯¼è‡´å‡é˜³æ€§ä¸Šå‡ï¼ŒéªŒè¯äº†æ˜¾å¼â€œæ— æŠ€èƒ½â€ç›‘ç£çš„é‡è¦æ€§

### æ¶ˆèå®éªŒç»“æœ
| é…ç½® | MRR | ååé‡ (samples/s) |
|------|-----|------------------|
| ç§»é™¤BiLSTM/Attention | 0.55 | â€” |
| Margin = 0.1 | 0.55 | â€” |
| **Margin = 0.5 (é€‰ä¸­)** | **0.65** | 170 |
| Margin = 0.8 | 0.58 | â€” |
| Num_Negatives = 1 | 0.55 | 250 |
| **Num_Negatives = 8 (é€‰ä¸­)** | **0.68** | 170 |
| Num_Negatives = 10 | 0.68 | 150 |

- **æœ€ä½³é…ç½®**ï¼šmargin=0.5ï¼Œè´Ÿæ ·æœ¬æ•°=8ï¼Œåœ¨MRRä¸è®­ç»ƒæ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡
- **æ³¨æ„åŠ›å¯è§†åŒ–**ï¼šæ¨¡å‹èµ‹äºˆç¼–ç¨‹è¯­è¨€ã€ä»»åŠ¡åŠ¨è¯ç­‰å…³é”®è¯æ›´é«˜æƒé‡ï¼Œä½“ç°è¯­ä¹‰èšç„¦èƒ½åŠ›
- **åˆæˆæ•°æ®è´¨é‡**ï¼š
  - å±‚æ¬¡çº¦æŸçš„å¤šæŠ€èƒ½ç”Ÿæˆï¼ˆMulti-Skill Level-2ï¼‰**perplexityæœ€ä½ï¼ˆ15.2ï¼‰**ï¼Œä¼˜äºå•æŠ€èƒ½ï¼ˆ18.5ï¼‰å’Œéšæœºå¤šæŠ€èƒ½ï¼ˆ22.1ï¼‰
  - ROCæ›²çº¿ä¸‹é¢ç§¯æ›´å¤§ï¼Œè¯´æ˜æ›´å…·åˆ¤åˆ«åŠ›

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å±‚æ¬¡çº¦æŸæ˜¾è‘—æå‡åˆæˆæ•°æ®è´¨é‡**ï¼šåŸºäºESCO Level-2ç±»åˆ«çš„å¤šæŠ€èƒ½ç”Ÿæˆä¸ä»…æé«˜äº†è¯­è¨€æµç•…æ€§ï¼ˆæ›´ä½perplexityï¼‰ï¼Œä¹Ÿå¢å¼ºäº†ä¸‹æ¸¸ä»»åŠ¡çš„åˆ¤åˆ«èƒ½åŠ›ã€‚
2. **RoBERTaè¿‡æ»¤å™¨æœ‰æ•ˆå»é™¤å™ªå£°**ï¼šå‰ç½®äºŒåˆ†ç±»å™¨å¯é«˜æ•ˆå‰”é™¤éæŠ€èƒ½å†…å®¹ï¼Œå‡å°‘è¯¯æŠ¥ï¼Œæå‡æ•´ä½“ç³»ç»Ÿprecisionã€‚
3. **Model Cåœ¨åˆæˆä¸çœŸå®æ•°æ®ä¸Šå‡è¡¨ç°æœ€ä¼˜**ï¼š
   - åœ¨åˆæˆéªŒè¯é›†ä¸ŠMRRè¾¾0.76ï¼ŒRecall@5è¾¾0.48
   - åœ¨çœŸå®ä¸­æ–‡æ‹›è˜å¹¿å‘Šä¸Šå®ç°F1@5=0.80ï¼Œå¤§å¹…è¶…è¶ŠTF-IDFä¸æ ‡å‡†BERT
4. **é”™è¯¯åˆ†ææ˜¾ç¤ºä¸»è¦æŒ‘æˆ˜ä»åœ¨äº**ï¼š
   - **False Negatives**ï¼šé—æ¼æŠ€èƒ½ï¼ˆæœ€å¸¸è§ï¼‰
   - **Taxonomy Misalignment**ï¼šæŠ€èƒ½å®šä¹‰è¿‡äºç»†ç²’åº¦æˆ–é‡å ï¼Œå¯¼è‡´ç›¸è¿‘æŠ€èƒ½æ··æ·†

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–ESCOç¿»è¯‘è´¨é‡**ï¼šä¸­æ–‡ç‰ˆESCOç”±äººå·¥ç¿»è¯‘ï¼Œå¯èƒ½å­˜åœ¨åå·®æˆ–ä¸ä¸€è‡´ã€‚
- **åˆæˆæ•°æ®ä»å­˜åœ¨åˆ†å¸ƒå·®è·**ï¼šå°½ç®¡æœ‰å±‚æ¬¡çº¦æŸï¼ŒLLMç”Ÿæˆçš„å¥å­å¯èƒ½æ— æ³•å®Œå…¨è¦†ç›–çœŸå®æ‹›è˜è¯­è¨€çš„å¤šæ ·æ€§ä¸å™ªå£°ã€‚
- **æœªå……åˆ†åˆ©ç”¨ESCOå±‚çº§ç»“æ„è¿›è¡Œæ¨ç†**ï¼šå½“å‰ä»…ä¸ºç”Ÿæˆé˜¶æ®µæä¾›çº¦æŸï¼Œæœªæ¥å¯åœ¨è§£ç æˆ–æŸå¤±å‡½æ•°ä¸­è¿›ä¸€æ­¥èåˆtaxonomyç»“æ„ã€‚
- **zero-shotè®¾å®šé™åˆ¶æ³›åŒ–è¾¹ç•Œ**ï¼šè‹¥ç›®æ ‡é¢†åŸŸä¸ESCOå·®å¼‚è¿‡å¤§ï¼ˆå¦‚æ–°å…´ç§‘æŠ€å²—ä½ï¼‰ï¼Œæ€§èƒ½å¯èƒ½ä¸‹é™ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **å¤šè¯­è¨€ä¸è·¨è¯­è¨€å¯¹é½**ï¼šæ‹“å±•è‡³å…¶ä»–éè‹±è¯­å¸‚åœºï¼Œæ¢ç´¢XLM-Ræˆ–mBERTè¿›è¡Œè·¨è¯­è¨€æŠ€èƒ½æ˜ å°„ã€‚
2. **å±‚æ¬¡æ„ŸçŸ¥çš„å­¦ä¹ ç›®æ ‡**ï¼šè®¾è®¡graph-based regularizationæˆ–taxonomy-consistent decodingæœºåˆ¶ï¼Œæ›´å¥½åœ°åˆ©ç”¨ESCOçš„æ ‘å½¢ç»“æ„ã€‚
3. **é€‚é…æ›´å¤šæŠ€èƒ½æœ¬ä½“**ï¼šæ¨å¹¿è‡³O*NETæˆ–å…¶ä»–è¡Œä¸šç‰¹å®šæŠ€èƒ½ä½“ç³»ã€‚
4. **åŠ¨æ€æ›´æ–°æœºåˆ¶**ï¼šåº”å¯¹æŠ€èƒ½æ¼”è¿›å¿«çš„ç‰¹ç‚¹ï¼Œæ„å»ºå¯æŒç»­æ›´æ–°çš„è‡ªåŠ¨åŒ–æ ‡æ³¨æµæ°´çº¿ã€‚

--- 

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼šæœ¬æ–‡æå‡ºä¸€ç§æ— éœ€äººå·¥æ ‡æ³¨çš„zero-shotæŠ€èƒ½æå–æ¡†æ¶ï¼Œé€šè¿‡**å±‚æ¬¡çº¦æŸçš„LLMåˆæˆæ•°æ® + å¯¹æ¯”åŒç¼–ç å™¨ + å‰ç½®è¿‡æ»¤å™¨**ï¼Œåœ¨çœŸå®ä¸­æ–‡æ‹›è˜å¹¿å‘Šä¸Šå®ç°äº†é«˜æ€§èƒ½çš„ESCOæŠ€èƒ½åŒ¹é…ï¼Œä¸ºåŠ³åŠ¨åŠ›å¸‚åœºæ™ºèƒ½æä¾›äº†å¯æ‰©å±•ã€ä½æˆæœ¬çš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 3. [Hidden States as Early Signals: Step-level Trace Evaluation and Pruning for Efficient Test-Time Scaling](https://arxiv.org/abs/2601.09093)

**Authors**: Zhixiang Liang, Beichen Huang, Zheng Wang, Minjia Zhang  
**Category**: cs.LG  
**Published**: 2026-01-15  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2601.09093v1  

#### Abstract
Large Language Models (LLMs) can enhance reasoning capabilities through test-time scaling by generating multiple traces. However, the combination of lengthy reasoning traces with multiple sampling introduces substantial computation and high end-to-end latency. Prior work on accelerating this process...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šHidden States as Early Signals: Step-level Trace Evaluation and Pruning for Efficient Test-Time Scaling**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨ç†ä»»åŠ¡ä¸­é€šè¿‡ **test-time scaling**ï¼ˆå¦‚ self-consistency, SCï¼‰ç”Ÿæˆå¤šæ¡æ¨ç†è·¯å¾„ä»¥æå‡å‡†ç¡®æ€§ï¼Œä½†è¯¥è¿‡ç¨‹å­˜åœ¨ä¸¤ä¸ªå…³é”®ç“¶é¢ˆï¼š
- **è®¡ç®—å¼€é”€å¤§**ï¼šé•¿é“¾æ¨ç† + å¤šè·¯å¾„é‡‡æ ·å¯¼è‡´å¤§é‡ token ç”Ÿæˆï¼Œå¸¦æ¥é«˜å»¶è¿Ÿã€‚
- **èµ„æºåˆ©ç”¨ä½æ•ˆ**ï¼šä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚åŸºäºç›¸ä¼¼æ€§æˆ–ç½®ä¿¡åº¦çš„å‰ªæï¼‰ä¿¡å·ä¸å¯é ï¼Œä¸”æœªè€ƒè™‘ **GPU å†…å­˜ç“¶é¢ˆ** å¯¼è‡´çš„æ’é˜Ÿç­‰å¾…æ—¶é—´ã€‚

ç°æœ‰æ–¹æ³•ä»…å…³æ³¨å‡å°‘ç”Ÿæˆ token æ•°é‡ï¼Œå¿½ç•¥äº†ç³»ç»Ÿçº§å»¶è¿Ÿçš„ä¸»è¦æ¥æºâ€”â€”KV Cache å ç”¨å¼•å‘çš„ **preemption å’Œ waiting queue**ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æå‡º **STEP**ï¼ˆStep-level Trace Evaluation and Pruningï¼‰ï¼Œä¸€ç§ç»“åˆ **éšè—çŠ¶æ€è¯„ä¼°** ä¸ **GPUå†…å­˜æ„ŸçŸ¥å‰ªæ** çš„æ–°å‹æ¨ç†åŠ é€Ÿæ¡†æ¶ã€‚

#### **æ ¸å¿ƒåˆ›æ–°ç‚¹**ï¼š
1. **åŸºäºéšè—çŠ¶æ€çš„æ­¥çº§è´¨é‡è¯„ä¼°ï¼ˆStep Scorerï¼‰**
   - åˆ©ç”¨ LLM åœ¨ `<think>` åˆ° `</think>` ä¹‹é—´æ¯ä¸ªæ¨ç†æ­¥éª¤ç»“æŸæ—¶çš„ **last-layer hidden state** ä½œä¸ºè¾“å…¥ã€‚
   - è®­ç»ƒä¸€ä¸ªè½»é‡çº§ä¸¤å±‚ MLPï¼ˆstep scorerï¼‰é¢„æµ‹æ¯ä¸€æ­¥çš„è´¨é‡ï¼Œå¹¶èšåˆä¸º trace-level åˆ†æ•°ã€‚
   - å®éªŒè¯æ˜ï¼š**æ—©æœŸéšè—çŠ¶æ€å·²èƒ½æœ‰æ•ˆåŒºåˆ†æ­£ç¡®ä¸é”™è¯¯æ¨ç†è·¯å¾„**ã€‚

2. **GPU å†…å­˜é¥±å’Œè§¦å‘å‰ªææœºåˆ¶**
   - å½“ KV Cache æ¥è¿‘ GPU æ˜¾å­˜ä¸Šé™æ—¶ï¼Œç«‹å³å‰ªæ **trace score æœ€ä½** çš„è·¯å¾„å¹¶é‡Šæ”¾å…¶ KV Cacheã€‚
   - é¿å…å› æ˜¾å­˜ä¸è¶³å¯¼è‡´çš„ trace è¢«æŠ¢å è¿›å…¥ç­‰å¾…é˜Ÿåˆ—ï¼Œä»è€Œæ¶ˆé™¤ **waiting overhead**ã€‚

3. **ç³»ç»Ÿ-ç®—æ³•ååŒè®¾è®¡**
   - ä¸å†åªä¼˜åŒ–â€œç”Ÿæˆå¤šå°‘ tokenâ€ï¼Œè€Œæ˜¯ä» **inference system behavior** å‡ºå‘ï¼Œè§£å†³å®é™…ç«¯åˆ°ç«¯å»¶è¿Ÿç“¶é¢ˆã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **ä¿¡å·å¯é æ€§** | ä½¿ç”¨ hidden state æ›¿ä»£ confidence æˆ–æ–‡æœ¬ç›¸ä¼¼æ€§ï¼Œé¿å… miscalibration å’Œè¯¯åˆ å¤šæ ·æ­£ç¡®è·¯å¾„ |
| **å‰ªææ—¶æœº** | åŠ¨æ€å“åº” GPU å†…å­˜å‹åŠ›ï¼Œè€Œéå›ºå®šé˜ˆå€¼æˆ–æ—¶é—´è¡¨ï¼Œæ›´è´´è¿‘çœŸå®ç³»ç»Ÿç“¶é¢ˆ |
| **æ•ˆç‡æå‡** | åŒæ—¶å‡å°‘ token ç”Ÿæˆ + æ¶ˆé™¤ç­‰å¾…æ—¶é—´ï¼Œå®ç°æ›´é«˜åŠ é€Ÿæ¯” |
| **ç²¾åº¦æå‡** | å› æ›´æ—©ç»ˆæ­¢é”™è¯¯è·¯å¾„ï¼Œä¿ç•™é«˜è´¨é‡ traceï¼Œæœ€ç»ˆ accuracy åè€Œæé«˜ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **AIME-25**ï¼šé«˜éš¾åº¦æ•°å­¦ç«èµ›é¢˜ï¼ˆArt of Problem Solvingï¼‰
- **HMMT-24 / HMMT-25**ï¼šHarvard-MIT Mathematics Tournament é«˜ä¸­æ•°å­¦ç«èµ›é¢˜
- **GPQA-Diamond (GPQA-D)**ï¼šç ”ç©¶ç”Ÿçº§åˆ«ç§‘å­¦é—®ç­”åŸºå‡†ï¼Œæ¶µç›–ç‰©ç†ã€ç”Ÿç‰©ã€åŒ–å­¦ç­‰

è¿™äº›æ•°æ®é›†å…·æœ‰é«˜å¤æ‚åº¦ã€é•¿æ¨ç†é“¾ç‰¹ç‚¹ï¼Œé€‚åˆæµ‹è¯• test-time scaling æ•ˆæœã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **æ¨¡å‹**
- **Qwen3-4B-Thinking-2507**
- **DeepSeek-R1-0528-Qwen3-8B**
- **Phi-4-reasoning-plus (14B)**

å‡ä¸ºå¼€æºå¼ºæ¨ç†èƒ½åŠ›æ¨¡å‹ã€‚

#### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Accuracy (%)** | æ­£ç¡®ç‡ï¼ˆä¸»è¦ä»»åŠ¡æ€§èƒ½æŒ‡æ ‡ï¼‰ |
| **Average Output Token Usage (Ã—10Â³)** | å¹³å‡è¾“å‡º token æ•°é‡ |
| **Inference Latency (s)** | ç«¯åˆ°ç«¯æ¨ç†å»¶è¿Ÿï¼ˆæœ€å…³é”®æ•ˆç‡æŒ‡æ ‡ï¼‰ |

#### **é‡‡æ ·è®¾ç½®**
- æ‰€æœ‰æ–¹æ³•ç»Ÿä¸€ä½¿ç”¨ **N = 64** æ¡ trace è¿›è¡Œ self-consistency ç±»é‡‡æ ·ã€‚
- ä½¿ç”¨ä¿®æ”¹ç‰ˆ **vLLM** æ¡†æ¶ï¼Œåœ¨å•å¼  **96GB NVIDIA GH200 GPU** ä¸Šè¿è¡Œã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| æ–¹æ³• | ç®€ä»‹ |
|------|------|
| **CoT** | å•ä¸€æ€ç»´é“¾ï¼Œæ— é‡‡æ · |
| **SC (Self-Consistency)** | ç”Ÿæˆ 64 æ¡ traceï¼Œå¤šæ•°æŠ•ç¥¨é€‰ç­”æ¡ˆ |
| **Slim-SC** | åŸºäºè·¨ trace æ–‡æœ¬ç›¸ä¼¼æ€§å‰ªæå†—ä½™è·¯å¾„ |
| **DeepConf** | åŸºäºæ¨¡å‹å†…éƒ¨ confidence åŠ¨æ€ç»ˆæ­¢ä½ç½®ä¿¡ trace |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰**

| æ¨¡å‹ | æ–¹æ³• | AIME-25 Acc (%) | HMMT-25 Acc (%) | Latency Reduction vs SC |
|------|------|------------------|------------------|------------------------|
| Qwen3-4B | STEP | **88.3** (+1.6) | **70.0** (+5.0) | â†“ ~53% |
| DeepSeek-8B | STEP | **85.0** (+1.7) | **73.3** (+3.3) | â†“ ~60% |
| Phi-4 | STEP | **87.5** (+0.8) | **75.8** (+0.8) | â†“ ~61% |

> âœ… STEP åœ¨æ‰€æœ‰æ¨¡å‹ä¸Šå‡ **ä¼˜äº SCã€Slim-SC å’Œ DeepConf**ï¼Œå¹³å‡é™ä½å»¶è¿Ÿ **45%-70%**ï¼ŒåŒæ—¶æå‡ accuracy **+0.4 è‡³ +7.5 ä¸ªç™¾åˆ†ç‚¹**ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

#### **Latency åŠ é€Ÿæ•ˆæœæ˜¾è‘—**
- åœ¨ Phi-4 + HMMT-24 åœºæ™¯ä¸‹ï¼š
  - SC è€—æ—¶ **2405 ç§’**
  - STEP ä»…éœ€ **630 ç§’** â†’ **3.8Ã— speedup**
- åœ¨ DeepSeek-8B + AIME-25ï¼š
  - DeepConf è€—æ—¶ 1475sï¼ŒSTEP ä»… 891s â†’ **1.7Ã— æ›´å¿«**

#### **Token ä½¿ç”¨é‡åˆç†**
- ç›¸æ¯” SC æ˜æ˜¾å‡å°‘ tokenï¼ˆä½†ä»ç•¥é«˜äº DeepConfï¼‰ï¼Œè¯´æ˜å‰ªææœ‰æ•ˆã€‚
- ä½† **STEP çš„ latency ä»æ›´ä½**ï¼Œè¡¨æ˜å…¶ä¼˜åŠ¿ä¸ä»…æ¥è‡ª token å‡å°‘ï¼Œæ›´æºäº **waiting time æ¶ˆé™¤**ã€‚

#### **Waiting Time åˆ†æï¼ˆTable 2ï¼‰**
| æ–¹æ³• | Waiting Time (s) | Decode Time (s) |
|------|------------------|-----------------|
| SC | 1526 | 1256 |
| DeepConf | 263 (69+194) | 1406 |
| Slim-SC | 1155 | 983 |
| **STEP** | **0** | **1024** |

> ğŸ”¥ STEP å®Œå…¨æ¶ˆé™¤äº† waiting timeï¼Œè¿™æ˜¯å…¶ç«¯åˆ°ç«¯åŠ é€Ÿçš„æ ¸å¿ƒåŸå› ã€‚

---

### **æ¶ˆèå®éªŒä¸åˆ†æ**

#### **(1) Step Scorer çš„æ’åºèƒ½åŠ›ï¼ˆFig. 5ï¼‰**
- ä½¿ç”¨ **Pairwise RankAcc** è¡¡é‡ scorer åŒºåˆ†æ­£ç¡®/é”™è¯¯ trace çš„èƒ½åŠ›ã€‚
- ç»“æœæ˜¾ç¤ºï¼š**hidden state scorer æ˜æ˜¾ä¼˜äº token-level confidence**ï¼ˆDeepConf ä½¿ç”¨ï¼‰ã€‚
- å³ä½¿åªçœ‹å‰ 25% çš„æ¨ç†æ­¥éª¤ï¼ŒRankAcc å·²è¾¾ ~0.7ï¼Œè¯æ˜æ—©æœŸä¿¡å·å¯é ã€‚

#### **(2) Latency Scaling å®éªŒï¼ˆFig. 4ï¼‰**
- åœ¨ä¸åŒé‡‡æ ·é¢„ç®—ï¼ˆ16/32/64ï¼‰ä¸‹ï¼ŒSTEP å§‹ç»ˆåœ¨ç›¸åŒæ—¶é—´å†…è¾¾åˆ°æ›´é«˜ accuracyã€‚
- ä¾‹å¦‚ï¼šQwen3-4B + HMMT-25ï¼ŒSTEP ç”¨ 40% æ—¶é—´è¾¾åˆ° SC çš„ accuracyã€‚

#### **(3) GPU Memory æ•æ„Ÿæ€§æµ‹è¯•ï¼ˆTable 3ï¼‰**
- å°†æœ€å¤§ GPU åˆ©ç”¨ç‡ä» 0.5 åˆ° 0.9 å˜åŒ–ï¼Œaccuracy æ³¢åŠ¨ä»…ä¸º **70.1 Â± 1.8%**ã€‚
- è¡¨æ˜ STEP å¯¹æ˜¾å­˜é™åˆ¶ä¸æ•æ„Ÿï¼Œå³ä½¿æ—©æœŸå‰ªæä¹Ÿèƒ½ä¿æŒç¨³å®šæ€§èƒ½ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **éšè—çŠ¶æ€æ˜¯å¯é çš„æ—©æœŸè´¨é‡ä¿¡å·**  
   LLM æ¨ç†è¿‡ç¨‹ä¸­ï¼Œ**early step çš„ hidden state å·²è•´å«è¶³å¤Ÿä¿¡æ¯åˆ¤æ–­æ•´æ¡è·¯å¾„æ˜¯å¦å¯èƒ½æˆåŠŸ**ï¼Œå¯ç”¨äºç²¾å‡†å‰ªæã€‚

2. **ç³»ç»Ÿç“¶é¢ˆåœ¨äº waiting timeï¼Œè€Œé decode time**  
   å®é™…å»¶è¿Ÿä¸­ï¼Œ**ç­‰å¾… KV Cache é‡Šæ”¾çš„æ—¶é—´å ä¸»å¯¼ï¼ˆ~59%ï¼‰**ï¼Œå•çº¯å‡å°‘ token æ— æ³•æ ¹æœ¬è§£å†³é—®é¢˜ã€‚

3. **memory-aware pruning æ˜¯é«˜æ•ˆ TTS çš„å…³é”®**  
   å°†å‰ªæå†³ç­–ä¸ GPU å†…å­˜çŠ¶æ€ç»‘å®šï¼Œå¯å½»åº•æ¶ˆé™¤æ’é˜Ÿï¼Œå®ç°æœ€å¤§åŠ é€Ÿã€‚

4. **STEP å®ç° accuracy ä¸ efficiency åŒèµ¢**  
   ä¸ä»…æé€Ÿ 45%-70%ï¼Œè¿˜å› æ›´ä¼˜ trace é€‰æ‹©æå‡äº†æœ€ç»ˆå‡†ç¡®ç‡ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
1. **ä¼ªæ ‡ç­¾å™ªå£°é—®é¢˜**  
   Step scorer ä½¿ç”¨ trace-level æ­£ç¡®æ€§ä½œä¸ºæ¯ä¸ª step çš„æ ‡ç­¾ï¼Œå­˜åœ¨æ ‡æ³¨å™ªå£°ï¼Œå°¤å…¶å½“ trace ä¸­éƒ¨åˆ†æ­¥éª¤é”™è¯¯ä½†æœ€ç»ˆæ­£ç¡®æ—¶ã€‚

2. **ä¾èµ–ç‰¹å®šéƒ¨ç½²æ¶æ„**  
   Memory-triggered pruning æ•ˆæœä¾èµ–äº vLLM ç­‰æ”¯æŒåŠ¨æ€è°ƒåº¦çš„ inference engineï¼Œåœ¨å…¶ä»–ç³»ç»Ÿä¸Šå¯èƒ½è¡¨ç°ä¸åŒã€‚

3. **é¢†åŸŸè¿ç§»é£é™©**  
   Step scorer åœ¨æ•°å­¦ä»»åŠ¡ä¸Šè®­ç»ƒï¼Œè¿ç§»åˆ°å…¶ä»–é¢†åŸŸï¼ˆå¦‚ä»£ç ã€å¸¸è¯†æ¨ç†ï¼‰éœ€é‡æ–°å¾®è°ƒã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ¢ç´¢æ›´ç²¾ç»†çš„ step-level æ ‡æ³¨æ–¹å¼ï¼ˆå¦‚äººå·¥æ ‡æ³¨å…³é”®è½¬æŠ˜ç‚¹ï¼‰ã€‚
- æ‰©å±• STEP åˆ°å¤š GPU åˆ†å¸ƒå¼æ¨ç†åœºæ™¯ã€‚
- ç»“åˆ speculative decoding æˆ– other early-exit æŠ€æœ¯è¿›ä¸€æ­¥åŠ é€Ÿã€‚
- å¼€å‘é€šç”¨ step scorerï¼Œæ”¯æŒè·¨ä»»åŠ¡ã€è·¨æ¨¡å‹æ³›åŒ–ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **STEP é€šè¿‡â€œéšè—çŠ¶æ€è¯„ä¼° + æ˜¾å­˜æ„ŸçŸ¥å‰ªæâ€ï¼Œå®ç°äº† test-time scaling çš„ accuracy ä¸ latency å…¨é¢è¶…è¶Šï¼Œæ­ç¤ºäº†ç³»ç»Ÿ-ç®—æ³•è”åˆä¼˜åŒ–åœ¨é«˜æ•ˆæ¨ç†ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚**

</details>

---

### 4. [ZeroDVFS: Zero-Shot LLM-Guided Core and Frequency Allocation for Embedded Platforms](https://arxiv.org/abs/2601.08166)

**Authors**: Mohammad Pivezhandi, Mahdi Banisharif, Abusayeed Saifullah, Ali Jannesari  
**Category**: cs.AI  
**Published**: 2026-01-15  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2601.08166v1  

#### Abstract
Dynamic voltage and frequency scaling (DVFS) and task-to-core allocation are critical for thermal management and balancing energy and performance in embedded systems. Existing approaches either rely on utilization-based heuristics that overlook stall times, or require extensive offline profiling for...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šZeroDVFS: Zero-Shot LLM-Guided Core and Frequency Allocation for Embedded Platforms

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»ŸåµŒå…¥å¼ç³»ç»Ÿä¸­çš„ **Dynamic Voltage and Frequency Scaling (DVFS)** å’Œä»»åŠ¡åˆ°æ ¸å¿ƒåˆ†é…ç­–ç•¥å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **åŸºäºåˆ©ç”¨ç‡çš„å¯å‘å¼æ–¹æ³•**ï¼ˆå¦‚Linux ondemand governorï¼‰å¿½ç•¥æ‰§è¡Œè¿‡ç¨‹ä¸­çš„ **stall time**ï¼Œå¯¼è‡´é¢‘ç‡è°ƒèŠ‚ä¸ç²¾å‡†ã€‚
- **åŸºäºç¦»çº¿è¡¨çš„æ–¹æ³•**ï¼ˆå¦‚precise schedulerï¼‰éœ€è¦å¯¹æ‰€æœ‰é¢‘ç‡-æ ¸å¿ƒç»„åˆè¿›è¡Œè¯¦å°½çš„æ€§èƒ½åˆ†æï¼Œè€—æ—¶é•¿è¾¾8â€“12å°æ—¶ï¼Œæ— æ³•é€‚åº”åŠ¨æ€å·¥ä½œè´Ÿè½½ã€‚
- ç¼ºä¹å¯¹æ–°å·¥ä½œè´Ÿè½½çš„æ³›åŒ–èƒ½åŠ›ï¼Œæ¯æ¬¡æ–°å¢ç¨‹åºéƒ½éœ€è¦é‡æ–°æ‰§è¡Œå®Œæ•´çš„profilingæµç¨‹ã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº†ç³»ç»Ÿåœ¨åŠ¨æ€ã€èµ„æºå—é™ç¯å¢ƒä¸‹çš„èƒ½æ•ˆä¸å®æ—¶å“åº”èƒ½åŠ›ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

æœ¬æ–‡æå‡º **ZeroDVFS** â€”â€”ä¸€ç§åŸºäºæ¨¡å‹çš„åˆ†å±‚å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰æ¡†æ¶ï¼Œç»“åˆå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¯­ä¹‰ç‰¹å¾æå–ï¼Œå®ç°é›¶æ ·æœ¬ï¼ˆzero-shotï¼‰éƒ¨ç½²ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

1. âœ… **LLMé©±åŠ¨çš„è¯­ä¹‰ç‰¹å¾æå–ï¼ˆLLM-based Semantic Feature Extractionï¼‰**
   - åˆ©ç”¨ **GPT-4oã€Claude Sonnetã€DeepSeek-V3** ç­‰LLMä»OpenMPæºç ä¸­æå–13ä¸ªä»£ç çº§è¯­ä¹‰ç‰¹å¾ï¼ˆå¦‚ `algorithmic_complexity`, `memory_access_pattern`, `load_balance`ï¼‰ï¼Œæ— éœ€è¿è¡Œç¨‹åºå³å¯å®Œæˆç‰¹å¾åˆ»ç”»ã€‚
   - æ”¯æŒ **zero-shot é¢„æµ‹**ï¼šå¯¹äºæœªè§è¿‡çš„å·¥ä½œè´Ÿè½½ï¼Œä¹Ÿèƒ½é€šè¿‡è¯­ä¹‰ç‰¹å¾é¢„æµ‹å…¶æ€§èƒ½è¡¨ç°ï¼Œé¿å…é‡å¤profilingã€‚

2. âœ… **æ¨¡å‹é©±åŠ¨çš„åˆ†å±‚å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆModel-Based Hierarchical MARLï¼‰**
   - å¼•å…¥ä¸¤ä¸ªåä½œæ™ºèƒ½ä½“ï¼š
     - **Profiler Agent**ï¼šä¼˜åŒ–èƒ½è€—ä¸ **makespan**ï¼Œå†³å®šæ ¸å¿ƒæ•°é‡å’Œé¢‘ç‡ã€‚
     - **Temperature Agent**ï¼šé˜²æ­¢çƒ­é›†ä¸­ï¼Œä¼˜å…ˆé€‰æ‹©æ¸©åº¦è¾ƒä½çš„æ ¸å¿ƒã€‚
   - ä½¿ç”¨ **Dyna-Q å¯å‘å¼æ¶æ„**ï¼Œå°†çœŸå®ç»éªŒä¸æ¨¡å‹ç”Ÿæˆçš„åˆæˆæ•°æ®ç»“åˆï¼Œæ˜¾è‘—æå‡è®­ç»ƒæ•ˆç‡ã€‚

3. âœ… **å‡†ç¡®çš„ç¯å¢ƒå»ºæ¨¡ï¼ˆAccurate Environment Modelingï¼‰**
   - æ„å»ºå›å½’æ¨¡å‹ï¼ˆå¦‚FCNã€Conv1Dï¼‰é¢„æµ‹æ¸©åº¦å˜åŒ–å’Œæ€§èƒ½çŠ¶æ€ï¼Œæ¨ç†å»¶è¿Ÿä½äº5msã€‚
   - æ¨¡å‹ç²¾åº¦æ¯”ç°æœ‰æ–¹æ³•é«˜ **6å€ä»¥ä¸Š**ï¼ˆMSEæ›´ä½ï¼‰ã€‚

4. âœ… **è·¨å¹³å°è¿ç§»ä¸å¿«é€Ÿå†³ç­–**
   - æ”¯æŒ **zero-shot è·¨å¹³å°è¿ç§»**ï¼šåœ¨Jetson TX2ä¸Šè®­ç»ƒçš„æ¨¡å‹å¯ç›´æ¥ç”¨äºOrin NXã€RubikPiç­‰ä¸åŒç¡¬ä»¶å¹³å°ã€‚
   - å†³ç­–å»¶è¿Ÿæä½ï¼šé¦–æ¬¡å†³ç­–ä»…éœ€ **3.5â€“8.0ç§’**ï¼ˆå«LLMç‰¹å¾æå–ï¼‰ï¼Œåç»­å†³ç­–ä»… **358ms**ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚precise schedulerï¼‰ | ZeroDVFS |
|------|-------------------------------|--------|
| **Profiling å¼€é”€** | 8â€“12å°æ—¶/åŸºå‡†æµ‹è¯• | ä¸€æ¬¡æ€§LLMè°ƒç”¨ï¼ˆ<5ç§’ï¼‰ |
| **æ–°å·¥ä½œè´Ÿè½½é€‚åº”æ€§** | å¿…é¡»é‡æ–°profiling | é›¶æ ·æœ¬éƒ¨ç½²ï¼Œæ— éœ€æ‰§è¡Œ |
| **å†³ç­–å»¶è¿Ÿ** | è¡¨æŸ¥æ‰¾ï¼šäºšæ¯«ç§’ï¼Œä½†è¡¨ç”Ÿæˆæ…¢ | é¦–æ¬¡ï¼š3.5â€“8.0sï¼›åç»­ï¼š358ms |
| **èƒ½æ•ˆä¸æ€§èƒ½** | æ¥è¿‘æœ€ä¼˜ä½†é™æ€ | åŠ¨æ€ä¼˜åŒ–ï¼Œæ›´ä¼˜ |
| **è·¨å¹³å°è¿ç§»** | ä¸æ”¯æŒï¼Œéœ€é‡åšè¡¨ | æ”¯æŒï¼Œå°‘é‡å¾®è°ƒå³å¯ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **BOTS (Barcelona OpenMP Tasks Suite)**ï¼šåŒ…å«FFTã€Strassenã€N-Queensç­‰å¹¶è¡Œä»»åŠ¡ã€‚
- **PolybenchC**ï¼šæ¶µç›–çº¿æ€§ä»£æ•°ã€Stencilè®¡ç®—ã€æ•°æ®æŒ–æ˜ç­‰å…¸å‹HPCè´Ÿè½½ã€‚
- å…±è®¡ **42ä¸ªOpenMPåŸºå‡†ç¨‹åº**ï¼Œè¦†ç›–å¤šæ ·åŒ–çš„å¹¶è¡Œæ¨¡å¼ä¸å†…å­˜è®¿é—®è¡Œä¸ºã€‚

---

### å®éªŒå¹³å°
| å¹³å° | æ¶æ„ | æ ¸å¿ƒæ•° | çƒ­åŒºæ•° |
|------|------|-------|--------|
| **Jetson TX2** | ARM Cortex-A57 + Denver 2 | 6 | 8 |
| **Jetson Orin NX** | ARM Cortex-A78AE | 8 | 9 |
| **RubikPi** | Qualcomm Kryo 585 | 8 | 36 |
| **Intel Core i7-8650U** | x86_64 | 4 | - |

æ‰€æœ‰å®éªŒå‡ä½¿ç”¨Linuxå†…æ ¸å·¥å…·è¿›è¡ŒåŠŸè€—ã€æ¸©åº¦ã€ä¸Šä¸‹æ–‡åˆ‡æ¢ç­‰ç›‘æ§ã€‚

---

### è¯„ä¼°æŒ‡æ ‡
- **Energy Efficiency**ï¼šæ€»èƒ½è€—ï¼ˆmJï¼‰
- **Makespan**ï¼šä»»åŠ¡å®Œæˆæ—¶é—´ï¼ˆsï¼‰
- **Temperature**ï¼šå¹³å‡æ ¸å¿ƒæ¸©åº¦ï¼ˆâ„ƒï¼‰
- **Decision Latency**ï¼šè°ƒåº¦å†³ç­–è€—æ—¶
- **Convergence Speed**ï¼šRLæ”¶æ•›æ‰€éœ€episodeæ•°
- **MAPE / RÂ²**ï¼šé¢„æµ‹æ¨¡å‹å‡†ç¡®æ€§

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | æè¿° |
|------|------|------|
| **Linux ondemand governor** | å¯å‘å¼ | åŸºäºåˆ©ç”¨ç‡åŠ¨æ€è°ƒé¢‘ |
| **Precise Scheduler [7]** | è¡¨é©±åŠ¨ | ç¦»çº¿profilingç”Ÿæˆæœ€ä¼˜é…ç½®è¡¨ |
| **zTT [30]** | å•æ™ºèƒ½ä½“RL | åŸºäºæ¨¡å‹æ— å…³çš„å¼ºåŒ–å­¦ä¹  |
| **GearDVFS** | å¯å‘å¼ | åˆ©ç”¨åˆ©ç”¨ç‡å’Œå¸§ç‡è°ƒæ•´é¢‘ç‡ |
| **HiDVFS_S, MAML, SAMBRL** | å…¶ä»–RLå˜ä½“ | ä½œä¸ºæ¬¡è¦å¯¹æ¯” |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

| æŒ‡æ ‡ | ZeroDVFS | Precise Scheduler | æå‡å¹…åº¦ |
|------|---------|------------------|----------|
| **Energy Consumption** | 9.1 mJ | 75.5 mJ | **7.09Ã— æ›´ä¼˜** |
| **Makespan** | 1.13 s | 5.96 s | **4.0Ã— æ›´å¿«** |
| **å†³ç­–å»¶è¿Ÿï¼ˆé¦–æ¬¡ï¼‰** | 3.5â€“8.0 s | ~8å°æ—¶ | **8,300Ã— æ›´å¿«** |
| **å†³ç­–å»¶è¿Ÿï¼ˆåç»­ï¼‰** | 358 ms | ~8å°æ—¶ | **80,000Ã— æ›´å¿«** |
| **æ¸©åº¦é¢„æµ‹è¯¯å·®ï¼ˆMSEï¼‰** | 0.40058 | 2.5 [25] | **>6Ã— æ›´å‡†ç¡®** |
| **æ”¶æ•›é€Ÿåº¦** | 20 episodes | >400 episodes | **20Ã— æ›´å¿«æ”¶æ•›** |

> æ³¨ï¼šä¸Šè¿°ç»“æœåŸºäºJetson TX2ä¸Šçš„BOTS FFTåŸºå‡†æµ‹è¯•ï¼ˆè¾“å…¥å¤§å°262144ï¼‰ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

- åœ¨ **æœ€ç»ˆæ€§èƒ½æ’å** ä¸­ï¼ŒZeroDVFSä»¥ **1.13s makespan** å±…é¦–ï¼Œè¿œä¼˜äºï¼š
  - HiDVFS_Sï¼ˆ1.33sï¼‰
  - MAMLï¼ˆ1.75sï¼‰
  - zTTï¼ˆ1.88sï¼‰
  - Precise Schedulerï¼ˆ5.96sï¼‰
  - GearDVFSï¼ˆ9.81sï¼‰

- **èƒ½é‡å½’ä¸€åŒ–å›¾ç¤º** æ˜¾ç¤ºï¼š
  - ç›¸æ¯”Precise Schedulerï¼ŒZeroDVFSèŠ‚èƒ½ **85.9%**
  - ç›¸æ¯”zTTï¼ŒèŠ‚èƒ½ **3.43Ã—**

- **å†³ç­–ç¨³å®šæ€§æ›´é«˜**ï¼šZeroDVFSåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­makespanå’Œèƒ½è€—æ³¢åŠ¨å°ï¼Œè€ŒGearDVFSæ–¹å·®æå¤§ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ï¼ˆ1ï¼‰æ¨¡å‹é©±åŠ¨ vs. æ¨¡å‹æ— å…³ï¼ˆModel-Based vs. Model-Freeï¼‰
- **MAMBRL D3QN**ï¼ˆæ¨¡å‹é©±åŠ¨ï¼‰æ¯” **MAMFRL D3QN**ï¼ˆæ¨¡å‹æ— å…³ï¼‰æ”¶æ•›æ›´å¿«ï¼ˆ20 vs. 40+ episodesï¼‰ã€‚
- åˆæˆæ•°æ®æ˜¾è‘—å‡å°‘æ ·æœ¬éœ€æ±‚ï¼Œæå‡æ ·æœ¬æ•ˆç‡ã€‚

#### ï¼ˆ2ï¼‰LLMç‰¹å¾çš„ä½œç”¨
- åœ¨å·²çŸ¥å·¥ä½œè´Ÿè½½ä¸Šï¼ŒåŠ å…¥LLMç‰¹å¾å¯¹é¢„æµ‹ç²¾åº¦æå‡æœ‰é™ï¼ˆRÂ² â‰ˆ 0.94 vs. 0.944ï¼‰ï¼Œå› ä¸ºå·²æœ‰è¶³å¤Ÿç¡¬ä»¶ç‰¹å¾ã€‚
- ä½†åœ¨ **zero-shot åœºæ™¯ä¸‹**ï¼ŒLLMç‰¹å¾æ˜¯å”¯ä¸€å¯ç”¨çš„ä¿¡æ¯æ¥æºï¼Œä½¿æ¨¡å‹å…·å¤‡æ³›åŒ–èƒ½åŠ›ã€‚

#### ï¼ˆ3ï¼‰è·¨å¹³å°è¿ç§»æ•ˆæœï¼ˆTransfer Learningï¼‰
| è¿ç§»è·¯å¾„ | MAPE | RÂ² | è¯´æ˜ |
|--------|------|----|------|
| TX2 â†’ Orin NX | 64.5% | 0.90 | å¯æ¥å—ï¼Œé€‚åˆå¿«é€Ÿéƒ¨ç½² |
| TX2 â†’ RubikPi | 73.2% | 0.80 | å­˜åœ¨åŸŸåç§»ï¼Œä½†ä»ä¿ç•™è¶‹åŠ¿ |

- å°‘é‡å¾®è°ƒï¼ˆ5â€“50æ ·æœ¬ï¼‰å¯è¿›ä¸€æ­¥é™ä½MAPEè‡³60%å·¦å³ã€‚
- å³ä½¿MAPEè¾ƒé«˜ï¼Œ**ç›¸å¯¹æ’åºä¿æŒç¨³å®š**ï¼ˆSpearman Ï > 0.7ï¼‰ï¼Œè¶³ä»¥æ”¯æŒæœ‰æ•ˆè°ƒåº¦ã€‚

#### ï¼ˆ4ï¼‰LLMä¸€è‡´æ€§åˆ†æ
| ç‰¹å¾ | ä¸‰æ¨¡å‹ä¸€è‡´ç‡ï¼ˆAll3ï¼‰ |
|------|------------------|
| `dominant_operation` | 73.8% |
| `algorithmic_complexity` | 59.5% |
| `false_sharing_risk` | 14.3% |
| `cache_behavior_pattern` | 16.7% |

- é«˜å…±è¯†ç‰¹å¾å¯ç”¨äºå¼ºçº¦æŸå†³ç­–ï¼Œä½å…±è¯†ç‰¹å¾ç”±XGBoostè‡ªåŠ¨é™æƒå¤„ç†ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **LLMè¯­ä¹‰ç‰¹å¾å¯æœ‰æ•ˆæ›¿ä»£ä¼ ç»Ÿprofiling**ï¼Œå®ç° **zero-shot æ€§èƒ½é¢„æµ‹**ï¼Œå¤§å¹…é™ä½éƒ¨ç½²æˆæœ¬ã€‚
2. âœ… **æ¨¡å‹é©±åŠ¨çš„MARLæ¡†æ¶** æ˜¾è‘—åŠ é€ŸRLæ”¶æ•›ï¼ˆ20Ã—ï¼‰ï¼ŒåŒæ—¶ä¿è¯é«˜è´¨é‡å†³ç­–ã€‚
3. âœ… **é¦–æ¬¡å†³ç­–å»¶è¿Ÿæ¯”è¡¨é©±åŠ¨æ–¹æ³•å¿«8,300å€**ï¼Œæ”¯æŒåœ¨åŠ¨æ€åµŒå…¥å¼ç³»ç»Ÿä¸­å®ç”¨åŒ–éƒ¨ç½²ã€‚
4. âœ… åœ¨å¤šä¸ªå¼‚æ„å¹³å°ä¸ŠéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå±•ç°å‡ºè‰¯å¥½çš„ **è·¨å¹³å°è¿ç§»èƒ½åŠ›**ã€‚
5. âœ… ZeroDVFSåœ¨èƒ½æ•ˆå’Œæ€§èƒ½ä¸Šå…¨é¢è¶…è¶Šä¸»æµå¯å‘å¼å’ŒRLåŸºçº¿ï¼Œå°¤å…¶åœ¨å¤æ‚å¹¶è¡Œè´Ÿè½½ä¸­ä¼˜åŠ¿æ˜æ˜¾ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **å½“å‰ä»…æ”¯æŒå•DAG OpenMPç¨‹åº**ï¼Œå°šæœªæ‰©å±•è‡³å¹¶å‘æˆ–å¤šä»»åŠ¡åœºæ™¯ã€‚
2. **zero-shotè·¨å¹³å°MAPEé«˜è¾¾64â€“73%**ï¼Œä»éœ€å°‘é‡fine-tuningæ‰èƒ½è¾¾åˆ°ç†æƒ³ç²¾åº¦ã€‚
3. **LLMç‰¹å¾æå–ä¾èµ–å•æ–‡ä»¶ç¨‹åº**ï¼Œå¤šæ–‡ä»¶é¡¹ç›®éœ€æ‰‹åŠ¨æ‹¼æ¥æˆ–åˆ†å±‚åˆ†æã€‚
4. **ç¼ºä¹ç½®ä¿¡åŒºé—´é‡åŒ–**ï¼šå®éªŒé‡å¤æ¬¡æ•°æœ‰é™ï¼Œç»Ÿè®¡æ˜¾è‘—æ€§æœ‰å¾…åŠ å¼ºã€‚
5. å½“å‰ä½¿ç”¨å•†ä¸šLLM APIï¼ˆGPT-4oç­‰ï¼‰ï¼Œå­˜åœ¨ç½‘ç»œä¾èµ–å’Œæˆæœ¬é—®é¢˜ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. æ‰©å±•è‡³ **å¹¶å‘å·¥ä½œè´Ÿè½½** å’Œ **GPUå¸è½½å†³ç­–**ã€‚
2. æ”¯æŒ **å¤šæ–‡ä»¶é¡¹ç›®åˆ†æ**ï¼Œå¼•å…¥æ¨¡å—åŒ–LLMè§£æã€‚
3. æ¢ç´¢ **é¢†åŸŸä¸“ç”¨LLMå¾®è°ƒ**ï¼ˆå¦‚HPCä»£ç è¯­æ–™åº“ï¼‰ï¼Œæå‡ç‰¹å¾æå–å‡†ç¡®æ€§ã€‚
4. éƒ¨ç½² **æœ¬åœ°åŒ–/è’¸é¦ç‰ˆLLM**ï¼ˆå¦‚CodeLlamaã€DeepSeek-Coderï¼‰ï¼Œå®ç°å®Œå…¨ç¦»çº¿è¾¹ç¼˜éƒ¨ç½²ã€‚
5. åŠ å¼ºç»Ÿè®¡åˆ†æï¼Œé‡‡ç”¨å¤šéšæœºç§å­è¯„ä¼°æ–¹å·®ã€‚
6. ç ”ç©¶ **LLMè¾“å‡ºçš„ä¸ç¡®å®šæ€§ä¼°è®¡**ï¼Œä¸ºè°ƒåº¦æä¾›é£é™©æ„ŸçŸ¥èƒ½åŠ›ã€‚

---

> **æ€»ç»“**ï¼šZeroDVFSé€šè¿‡èåˆ **LLMè¯­ä¹‰ç†è§£** ä¸ **æ¨¡å‹é©±åŠ¨çš„MARL**ï¼Œå®ç°äº†é«˜æ€§èƒ½ã€ä½å¼€é”€ã€å¯æ³›åŒ–çš„åµŒå…¥å¼è°ƒåº¦æ–¹æ¡ˆï¼Œä¸ºæœªæ¥æ™ºèƒ½è¾¹ç¼˜ç³»ç»Ÿçš„è‡ªé€‚åº”èµ„æºç®¡ç†æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 5. [Prism: Towards Lowering User Cognitive Load in LLMs via Complex Intent Understanding](https://arxiv.org/abs/2601.08653)

**Authors**: Zenghua Liao, Jinzhi Liao, Xiang Zhao  
**Category**: cs.AI  
**Published**: 2026-01-15  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2601.08653v1  

#### Abstract
Large Language Models are rapidly emerging as web-native interfaces to social platforms. On the social web, users frequently have ambiguous and dynamic goals, making complex intent understanding-rather than single-turn execution-the cornerstone of effective human-LLM collaboration. Existing approach...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šPrism: Towards Lowering User Cognitive Load in LLMs via Complex Intent Understanding**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å½“å‰ Large Language Models (LLMs) åœ¨å¤„ç†ç”¨æˆ·æ„å›¾æ—¶ï¼Œå°¤å…¶æ˜¯åœ¨ç¤¾äº¤ç½‘ç»œç­‰å¤æ‚åœºæ™¯ä¸‹ï¼Œç”¨æˆ·å¸¸ä»¥æ¨¡ç³Šã€åŠ¨æ€çš„æ–¹å¼è¡¨è¾¾éœ€æ±‚ã€‚ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ Mistral-Interact å’Œ ITIUï¼‰é€šè¿‡é¡ºåºæˆ–å¹¶è¡Œæé—®è¿›è¡Œæ„å›¾æ¾„æ¸…ï¼Œä½†**å¿½ç•¥äº†æ¾„æ¸…é—®é¢˜ä¹‹é—´çš„é€»è¾‘ä¾èµ–å…³ç³»**ï¼Œå¯¼è‡´äº¤äº’ä¸è¿è´¯ã€å»ºè®®ä¸åˆç†ï¼ˆä¾‹å¦‚â€œ12æœˆåœ¨å†²ç»³æ½œæ°´â€ï¼‰ï¼Œä»è€Œå¢åŠ ç”¨æˆ·çš„**è®¤çŸ¥è´Ÿè· (Cognitive Load)**ã€‚

è®ºæ–‡æŒ‡å‡ºï¼Œè¿™ä¸€æ ¸å¿ƒæŒ‘æˆ˜æ˜¯ï¼š**å¦‚ä½•å»ºæ¨¡æ¾„æ¸…é—®é¢˜é—´çš„é€»è¾‘ä¾èµ–ï¼Œä»¥å®ç°é«˜æ•ˆä¸”ä½æ‘©æ“¦çš„å¤æ‚æ„å›¾ç†è§£**ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ï¼šPrism æ¡†æ¶**
Prism æ˜¯ä¸€ä¸ªåŸºäº **Cognitive Load Theory (CLT)** çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡**é€»è¾‘ä¸€è‡´çš„æ„å›¾æ¾„æ¸…**é™ä½ç”¨æˆ·è®¤çŸ¥è´Ÿæ‹…ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†å¤æ‚æ„å›¾è§†ä¸ºâ€œç™½å…‰â€ï¼Œé€šè¿‡â€œæ£±é•œâ€ï¼ˆå³é€»è¾‘é©±åŠ¨çš„æ¨¡å¼ï¼‰å°†å…¶åˆ†è§£ä¸ºæœ‰åºçš„â€œå…‰è°±â€å…ƒç´ ï¼ŒæŒ‡å¯¼æ¾„æ¸…æµç¨‹ã€‚

#### **å››å¤§æ¨¡å—è®¾è®¡**ï¼š
1. **Complex Intent Decomposition Module**  
   - æ„å»ºäº† **CID (Complex Intent Decomposition) æ•°æ®é›†**ï¼Œè¦†ç›– 27 ä¸ªé¢†åŸŸã€429 ç§æ„å›¾ï¼Œæ˜¾å¼æ ‡æ³¨å…ƒç´ é—´çš„å…ˆå†³ä¾èµ–å…³ç³»ã€‚
   - æ”¯æŒâ€œæ£€ç´¢æˆ–æ„é€ â€èŒƒå¼ï¼šè‹¥ç”¨æˆ·æ„å›¾åŒ¹é… CID ä¸­å·²æœ‰æ¡ç›®ï¼Œåˆ™å¤ç”¨å…¶å±‚çº§ç»“æ„ï¼›å¦åˆ™é€šè¿‡ few-shot æ–¹å¼ä»ç›¸ä¼¼æ„å›¾ä¸­æ³›åŒ–ç”Ÿæˆã€‚

2. **Logical Clarification Generation Module**  
   - æ ¹æ®åˆ†è§£å‡ºçš„å±‚çº§ç»“æ„ç»„ç»‡æ¾„æ¸…é—®é¢˜ï¼š**ç‹¬ç«‹é—®é¢˜åœ¨åŒä¸€è½®å¹¶è¡Œå‘ˆç°ï¼ˆå¦‚äº¤äº’è¡¨æ ¼ï¼‰ï¼Œä¾èµ–é—®é¢˜åˆ™æŒ‰åºåˆ†è½®æé—®**ï¼Œç¡®ä¿é€»è¾‘ä¸€è‡´æ€§ã€‚

3. **Intent-Aware Reward Module**  
   - è®¾è®¡äº†ä¸€ä¸ª **intent-aware reward å‡½æ•°**ï¼Œç»“åˆ **token-level intent importance** å’Œ **generation confidence** æ¥è¯„ä¼°æ¾„æ¸…è½¨è¿¹è´¨é‡ã€‚
   - åˆ©ç”¨ **Monte Carlo Sampling** æ¨¡æ‹Ÿå¤§è§„æ¨¡ç”¨æˆ·-LLM äº¤äº’ï¼Œç”Ÿæˆé«˜è´¨é‡è®­ç»ƒæ•°æ®ã€‚

4. **Self-Evolved Intent Tuning Module**  
   - é‡‡ç”¨è‡ªæ¼”è¿›æ–¹å¼è¿­ä»£ä¼˜åŒ– LLMï¼šä½¿ç”¨é«˜å¥–åŠ±è½¨è¿¹å¯¹å¼€æºæ¨¡å‹ï¼ˆå¦‚ LLaMA-3.1-8B-Instructï¼‰è¿›è¡Œ SFT å’Œ DPO å¾®è°ƒï¼Œå¹¶åœ¨åç»­è½®æ¬¡ä¸­ç”¨å¾®è°ƒåçš„æ¨¡å‹ä½œä¸ºæ–°ç­–ç•¥ç”Ÿæˆæ›´ä¼˜æ•°æ®ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆMistral-Interact, ITIUï¼‰ | Prism |
|------|-------------------------------|-------|
| **é€»è¾‘ä¾èµ–å»ºæ¨¡** | å¿½ç•¥é—®é¢˜é—´ä¾èµ–ï¼Œå‡è®¾é—®é¢˜ç‹¬ç«‹ | æ˜¾å¼å»ºæ¨¡ä¾èµ–ï¼Œåˆ†å±‚æé—® |
| **äº¤äº’æ•ˆç‡** | ITIU å¹¶è¡Œæé—®å¿«ä½†æ˜“æ··ä¹± | å¹³è¡¡å¹¶è¡Œä¸é¡ºåºï¼Œå‡å°‘å†—ä½™è½®æ¬¡ |
| **ç”¨æˆ·ä½“éªŒ** | ç”¨æˆ·éœ€è‡ªè¡Œç®¡ç†é€»è¾‘ | ç”±ç³»ç»Ÿå¼•å¯¼ï¼Œé™ä½è®¤çŸ¥è´Ÿè· |
| **æ³›åŒ–èƒ½åŠ›** | ä¾èµ–é¢„å®šä¹‰è¡Œä¸º | æ”¯æŒå¤šæ ·åŒ–æ„å›¾å‘ç° |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **TIN** [14]: 200 ä¸ªæµ‹è¯•å®ä¾‹ï¼Œäººå·¥æ ‡æ³¨ + GPT-4 è¾…åŠ©ã€‚
- **IN3** [21]: 108 ä¸ªæµ‹è¯•å®ä¾‹ï¼ŒåŒ…å«æ›´å¤šæ¾„æ¸…é—®é¢˜ã€‚
- **ABP** [36]: 319 ä¸ªæµ‹è¯•å®ä¾‹ï¼Œæ¶µç›–å¤šæ ·é¢†åŸŸå’Œæ„å›¾ã€‚

æ‰€æœ‰æ•°æ®é›†å‡è¢«æ‰‹åŠ¨åˆ’åˆ†ä¸º **ç®€å•æ„å›¾** å’Œ **å¤æ‚æ„å›¾** åœºæ™¯ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹åœ¨ä¸åŒéš¾åº¦ä¸‹çš„è¡¨ç°ã€‚

---

### **å®éªŒè®¾ç½®**
- **åŸºçº¿æ¨¡å‹**ï¼šç»Ÿä¸€ä½¿ç”¨ `Mistral-7B-Instruct-v0.3` å’Œ `LLaMA-3.1-8B-Instruct` ä½œä¸º backboneã€‚
- **å¯¹æ¯”æ–¹æ³•**ï¼š
  - **Mistral-Interact**: é¡ºåº Q&A æ¾„æ¸…ã€‚
  - **ITIU**: è¡¨æ ¼å½¢å¼å¹¶è¡Œæé—®ã€‚
  - **CoLLABLLM**: å¤šè½®æ„ŸçŸ¥å¥–åŠ±æœºåˆ¶ã€‚
- **Prism å˜ä½“**ï¼š
  - **Prism-SFT**: åŸºäºç›‘ç£å¾®è°ƒã€‚
  - **Prism-DPO**: åŸºäºç›´æ¥åå¥½ä¼˜åŒ–ã€‚

è®­ç»ƒç¯å¢ƒï¼š8Ã—80GB A100 GPUï¼Œè€—æ—¶çº¦ 14.5 å°æ—¶ã€‚

---

### **è¯„ä¼°æŒ‡æ ‡**

#### **(1) æ¾„æ¸…äº¤äº’ (Clarification Interaction)**
- **Intents Cover Rate (%)**: è¦†ç›–çœŸå®æ¾„æ¸…é—®é¢˜çš„æ¯”ä¾‹ã€‚
- **Logical Conflict Rate (%)**: è¿åå…ˆå†³ä¾èµ–çš„æ¾„æ¸…é—®é¢˜æ¯”ä¾‹ï¼ˆè¶Šä½è¶Šå¥½ï¼‰ã€‚
- **Average Interaction Turns**: å¹³å‡äº¤äº’è½®æ•°ã€‚
- **Average Questions Per Turn**: æ¯è½®å¹³å‡æé—®æ•°é‡ã€‚
- **Options Presenting Rate (%)**: æä¾›å‚è€ƒé€‰é¡¹çš„æ¯”ä¾‹ã€‚
- **Options Reasonable Rate (%)**: æ‰€æä¾›é€‰é¡¹åˆç†çš„æ¯”ä¾‹ã€‚

#### **(2) æ„å›¾æ‰§è¡Œ (Intent Execution)**
é›†æˆåˆ° **XAgent** è‡ªä¸»ä»£ç†æ¡†æ¶ä¸­ï¼Œè¯„ä¼°ä»»åŠ¡å®Œæˆè´¨é‡ï¼š
- **IBLEU**: è¾“å‡ºä¸å‚è€ƒç­”æ¡ˆçš„ BLEU åˆ†æ•°ã€‚
- **Faithful**: è¾“å‡ºæ˜¯å¦å¿ å®æ»¡è¶³æ¾„æ¸…åçš„æ„å›¾ã€‚
- **Unnecessary Sub-tasks (US)** / **General Sub-tasks (GS)**: ä¸å¿…è¦æˆ–è¿‡äºå®½æ³›çš„å­ä»»åŠ¡æ¯”ä¾‹ã€‚
- **Tool Invocations (TI)**: å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼Œåæ˜ æ‰§è¡Œæ•ˆç‡ã€‚

#### **(3) è®¤çŸ¥è´Ÿè· (Cognitive Load)**
å¤šç»´åº¦è¯„ä¼°ï¼š
- **è¡Œä¸ºæŒ‡æ ‡**ï¼šä»»åŠ¡è€—æ—¶ã€å¯¹è¯ token æ•°é‡ã€‚
- **ä¸»è§‚è¯„åˆ†**ï¼šç”¨æˆ·å¯¹äº¤äº’ä½“éªŒæ‰“åˆ†ï¼ˆ1â€“10ï¼‰ã€‚
- **ç”Ÿç†æŒ‡æ ‡**ï¼šEEG åŠŸç‡è°±å¯†åº¦ (PSD)ï¼Œè¡¡é‡å¤§è„‘æ´»è·ƒåº¦ä¸è®¤çŸ¥è´Ÿè·ã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»**

#### **è¡¨ 1ï¼šæ¾„æ¸…äº¤äº’æ€§èƒ½ï¼ˆTIN æ•°æ®é›†ï¼Œå¤æ‚æ„å›¾åœºæ™¯ï¼‰**
| æ–¹æ³• | Logical Conflict Rate (%) â†“ | Intents Cover Rate (%) â†‘ | Avg. Turns â†“ |
|------|-----------------------------|----------------------------|--------------|
| Mistral-Interact | 39.00 | 46.24 | 5.87 |
| ITIU | 51.50 | 49.18 | 1.78 |
| CoLLABLLM | 30.00 | 57.08 | 6.14 |
| **Prism-DPO (LLaMA)** | **11.50** | **60.09** | **1.64** |

> âœ… **é€»è¾‘å†²çªç‡é™è‡³ 11.5%**ï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚

#### **è¡¨ 2ï¼šæ„å›¾æ‰§è¡Œæ€§èƒ½ï¼ˆç›¸å¯¹æå‡ï¼ŒPrism-DPO vs Baselineï¼‰**
| æŒ‡æ ‡ | ç®€å•æ„å›¾åœºæ™¯ | å¤æ‚æ„å›¾åœºæ™¯ | æå‡å¹…åº¦ |
|------|-------------|-------------|---------|
| IBLEU | +10.43% | +9.4% | é«˜ |
| Faithful | +19.1% | +17.7% | é«˜ |
| US (ä¸å¿…è¦çš„å­ä»»åŠ¡) | -0.59 | -1.08 | â†“31.4% |
| GS (æ³›åŒ–å­ä»»åŠ¡) | -0.19 | -0.09 | â†“19.57% |
| TI (å·¥å…·è°ƒç”¨) | -1.23 | -1.22 | â†“22.26% |

> âœ… æ˜¾è‘—å‡å°‘å†—ä½™æ“ä½œï¼Œæå‡æ‰§è¡Œæ•ˆç‡ã€‚

#### **å›¾ 3ï¼šè®¤çŸ¥è´Ÿè·å®éªŒç»“æœ**
- **ä»»åŠ¡è€—æ—¶**ï¼šPrism æ¯” Mistral-Interact **å‡å°‘ 34.8%**ï¼Œæ¯” CoLLABLLM **å‡å°‘ 22.3%**ã€‚
- **æ€» token æ•°**ï¼šPrism æ§åˆ¶åœ¨ **1000 ä»¥ä¸‹**ï¼Œè¿œä½äºå…¶ä»–æ–¹æ³•ã€‚
- **ç”¨æˆ·è¯„åˆ†**ï¼šPrism å¹³å‡å¾—åˆ†ä¸º **8.35**ï¼Œå…¶ä¸­ 88.6% ç”¨æˆ·è¯„ä¸ºâ€œè‰¯å¥½â€åŠä»¥ä¸Šã€‚
- **EEG PSD åˆ†æ**ï¼šPrism å¯¹åº”çš„è„‘ç”µæ´»åŠ¨æœ€å¹³ç¨³ï¼Œè¡¨æ˜**è®¤çŸ¥è´Ÿè·æœ€ä½**ã€‚

#### **æ¶ˆèå®éªŒï¼ˆéšå«åˆ†æï¼‰**
- **é€»è¾‘ä¾èµ–å»ºæ¨¡æœ‰æ•ˆæ€§**ï¼šå½“ä»ç®€å•è½¬å‘å¤æ‚æ„å›¾æ—¶ï¼ŒMistral-Interact å’Œ ITIU çš„æ€§èƒ½ä¸‹é™æ˜æ˜¾ï¼ˆè§ Figure 5ï¼‰ï¼Œè€Œ Prism ä¸‹é™å¹…åº¦æœ€å°ï¼Œè¯´æ˜å…¶å¯¹å¤æ‚åœºæ™¯é²æ£’æ€§å¼ºã€‚
- **è‡ªæ¼”è¿›è®­ç»ƒæ•ˆæœ**ï¼šç»è¿‡ä¸‰è½® self-evolved intent tuningï¼Œæ•°æ®è´¨é‡å’Œæ¨¡å‹æ€§èƒ½æŒç»­æå‡ï¼ŒéªŒè¯äº†é—­ç¯ä¼˜åŒ–çš„æœ‰æ•ˆæ€§ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **é€»è¾‘ä¾èµ–å»ºæ¨¡è‡³å…³é‡è¦**ï¼šå¿½è§†æ¾„æ¸…é—®é¢˜é—´çš„å…ˆå†³å…³ç³»ä¼šå¯¼è‡´å»ºè®®ä¸åˆ‡å®é™…ï¼Œæ˜¾è‘—å¢åŠ ç”¨æˆ·è®¤çŸ¥è´Ÿæ‹…ã€‚
2. **Prism å®ç°äº†é€»è¾‘ä¸€è‡´æ€§ä¸äº¤äº’æ•ˆç‡çš„å¹³è¡¡**ï¼šæ—¢ä¿æŒä½äº¤äº’è½®æ¬¡ï¼ˆâ‰ˆ1.6 è½®ï¼‰ï¼Œåˆå¤§å¹…é™ä½é€»è¾‘å†²çªï¼ˆ11.5%ï¼‰ã€‚
3. **æ˜¾è‘—æ”¹å–„ç”¨æˆ·ä½“éªŒ**ï¼š
   - ç”¨æˆ·æ»¡æ„åº¦æå‡ **14.4%**ã€‚
   - ä»»åŠ¡å®Œæˆæ—¶é—´ç¼©çŸ­ **34.8%**ã€‚
   - ç”Ÿç†å±‚é¢è®¤çŸ¥è´Ÿè·æœ€ä½ï¼ˆEEG éªŒè¯ï¼‰ã€‚
4. **å¼ºæ³›åŒ–èƒ½åŠ›**ï¼šåœ¨ TINã€IN3ã€ABP ä¸‰ä¸ªæ•°æ®é›†ä¸Š consistently outperform æ‰€æœ‰ baselineï¼Œä¸”é€‚ç”¨äºä¸åŒ backbone æ¨¡å‹ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ– CID æ•°æ®é›†æ„å»ºè´¨é‡**ï¼šè™½ç„¶ CID åŒ…å« 429 ç§æ„å›¾ï¼Œä½†ä»å¯èƒ½æ— æ³•è¦†ç›–æç«¯é•¿å°¾åœºæ™¯ã€‚
- **few-shot æ„é€ çš„å¯é æ€§**ï¼šå¯¹äºå®Œå…¨æ–°é¢–çš„æ„å›¾ï¼Œä¾èµ–è¯­ä¹‰ç›¸ä¼¼æ€§æ£€ç´¢å¯èƒ½å­˜åœ¨åå·®ã€‚
- **ç”¨æˆ·æ¨¡æ‹Ÿå™¨çš„ä¿çœŸåº¦**ï¼šMonte Carlo Sampling ä½¿ç”¨ LLM æ¨¡æ‹Ÿç”¨æˆ·è¡Œä¸ºï¼Œè™½é«˜æ•ˆä½†æœªå¿…å®Œå…¨åæ˜ çœŸå®äººç±»å†³ç­–ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ‰©å±• CID è‡³æ›´å¤šé¢†åŸŸå’Œè¯­è¨€ã€‚
- å¼•å…¥åœ¨çº¿å­¦ä¹ æœºåˆ¶ï¼Œè®©æ¨¡å‹åœ¨éƒ¨ç½²è¿‡ç¨‹ä¸­æŒç»­æ›´æ–°æ„å›¾æ¨¡å¼ã€‚
- æ¢ç´¢å¤šæ¨¡æ€è¾“å…¥ä¸‹çš„å¤æ‚æ„å›¾ç†è§£ï¼ˆå¦‚å›¾æ–‡æ··åˆè¯·æ±‚ï¼‰ã€‚
- ç»“åˆä¸ªæ€§åŒ–å»ºæ¨¡ï¼Œè¿›ä¸€æ­¥æå‡ç”¨æˆ·ä¸­å¿ƒåŒ–ç¨‹åº¦ã€‚

---

## **æ€»ç»“**
Prism æ˜¯é¦–ä¸ªç³»ç»Ÿæ€§åœ°å°† **Cognitive Load Theory** åº”ç”¨äº LLM æ„å›¾ç†è§£çš„å·¥ä½œï¼Œæå‡ºäº†ä¸€ä¸ª**é€»è¾‘é©±åŠ¨ã€å±‚æ¬¡åŒ–ã€è‡ªæ¼”è¿›çš„æ¾„æ¸…æ¡†æ¶**ã€‚å®éªŒè¯æ˜ï¼Œå®ƒä¸ä»…åœ¨æŠ€æœ¯æŒ‡æ ‡ä¸Šè¾¾åˆ° SOTAï¼Œåœ¨ç”¨æˆ·ä½“éªŒå’Œè®¤çŸ¥è´Ÿè·æ–¹é¢ä¹Ÿå®ç°äº†æ˜¾è‘—çªç ´ï¼Œæ¨åŠ¨ LLM å‘çœŸæ­£â€œä¸»åŠ¨åä½œä¼™ä¼´â€çš„è§’è‰²è¿ˆè¿›ã€‚

</details>

---

### 6. [When to Invoke: Refining LLM Fairness with Toxicity Assessment](https://arxiv.org/abs/2601.09250)

**Authors**: Jing Ren, Bowen Li, Ziqi Xu, Renqiang Luo, Shuo Yu, Xin Ye, Haytham Fayek, Xiaodong Li, Feng Xia  
**Category**: cs.CL  
**Published**: 2026-01-15  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.09250v1  

#### Abstract
Large Language Models (LLMs) are increasingly used for toxicity assessment in online moderation systems, where fairness across demographic groups is essential for equitable treatment. However, LLMs often produce inconsistent toxicity judgements for subtle expressions, particularly those involving im...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šWhen to Invoke: Refining LLM Fairness with Toxicity Assessment

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹ **Large Language Models (LLMs)** åœ¨**æ¯’æ€§è¯„ä¼°**ï¼ˆtoxicity assessmentï¼‰ä»»åŠ¡ä¸­å­˜åœ¨çš„**å…¬å¹³æ€§åå·®**é—®é¢˜å±•å¼€ç ”ç©¶ã€‚å…·ä½“è€Œè¨€ï¼ŒLLMs åœ¨å¤„ç†æ¶‰åŠä¸åŒ**demographic groups**ï¼ˆå¦‚ç§æ—ã€ç§»æ°‘èº«ä»½ç­‰ï¼‰çš„éšæ€§ä»‡æ¨è¨€è®ºï¼ˆimplicit hate speechï¼‰æ—¶ï¼Œå¸¸å¸¸è¡¨ç°å‡ºä¸ä¸€è‡´çš„æ¯’æ€§è¯„åˆ†ï¼Œå³å¯¹è¯­ä¹‰ç›¸åŒä½†æåŠä¸åŒç¾¤ä½“çš„å¥å­ç»™å‡ºæ˜¾è‘—ä¸åŒçš„åˆ¤æ–­ï¼Œä»è€Œæš´éœ²æ¨¡å‹ä¸­çš„ç³»ç»Ÿæ€§åè§ã€‚

ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äº**fine-tuning**æˆ–**åå¤„ç†æ ¡å‡†**ï¼ˆpost-hoc calibrationï¼‰ï¼Œè¿™äº›æ–¹æ³•æˆæœ¬é«˜ã€éš¾ä»¥éƒ¨ç½²ï¼Œå¹¶ä¸”æ— æ³•åŠ¨æ€è¯†åˆ«ä½•æ—¶éœ€è¦è¿›è¡Œå…¬å¹³æ€§ä¿®æ­£ã€‚æœ¬æ–‡æŒ‡å‡ºä¸€ä¸ªè¢«å¿½è§†çš„å…³é”®é—®é¢˜ï¼š**â€œä½•æ—¶â€åº”è§¦å‘å…¬å¹³æ€§ä¿®æ­£æœºåˆ¶ï¼Ÿ**

### æå‡ºçš„æ–°æ–¹æ³•å’Œæ–°æ€è·¯
ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½œè€…æå‡ºäº† **FairToT**ï¼ˆFairness-aware Tree-of-Thoughtï¼‰ï¼Œä¸€ä¸ª**æ¨ç†æ—¶**ï¼ˆinference-timeï¼‰çš„æ¡†æ¶ï¼Œé€šè¿‡**prompt-guided toxicity assessment**æ¥æå‡ LLM çš„å…¬å¹³æ€§ï¼Œè€Œæ— éœ€ä¿®æ”¹æ¨¡å‹å‚æ•°ã€‚

å…¶æ ¸å¿ƒåˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š
- **æå‡ºâ€œä½•æ—¶è°ƒç”¨â€ï¼ˆWhen to Invokeï¼‰çš„å†³ç­–æœºåˆ¶**ï¼šFairToT å¹¶éå¯¹æ‰€æœ‰è¾“å…¥éƒ½è¿›è¡Œä¿®æ­£ï¼Œè€Œæ˜¯é€šè¿‡å¯è§£é‡Šçš„å…¬å¹³æ€§æŒ‡æ ‡åŠ¨æ€æ£€æµ‹æ½œåœ¨çš„å…¬å¹³é£é™©ï¼Œå¹¶ä»…åœ¨å¿…è¦æ—¶æ‰å¯åŠ¨é¢å¤–çš„è¯„ä¼°æµç¨‹ï¼Œæé«˜äº†æ•ˆç‡ã€‚
- **è®¾è®¡ä¸¤ä¸ªå¯è§£é‡Šçš„å…¬å¹³æ€§æŒ‡æ ‡**ï¼š
  - **Sentence Fairness Variance (SFV)**ï¼šè¡¡é‡åœ¨åŒä¸€ä¸ªå¥å­æ¨¡æ¿ä¸‹ï¼Œæ›¿æ¢ä¸åŒç¾¤ä½“å®ä½“åï¼Œæ¨¡å‹æ¯’æ€§é¢„æµ‹çš„æ–¹å·®ã€‚ä½ SFV è¡¨ç¤ºæ¨¡å‹å¯¹ä¸åŒç¾¤ä½“çš„åˆ¤æ–­ä¸€è‡´æ€§é«˜ã€‚
  - **Entity Fairness Dispersion (EFD)**ï¼šè¡¡é‡æŸä¸ªç‰¹å®šç¾¤ä½“åœ¨ä¸åŒå¥å­æ¨¡æ¿ä¸­å—åˆ°çš„æ¨¡å‹æ•æ„Ÿåº¦å·®å¼‚ã€‚ä½ EFD è¡¨ç¤ºè¯¥ç¾¤ä½“ä¸ä¼šåœ¨æŸäº›ä¸Šä¸‹æ–‡ä¸­è¢«è¿‡åº¦æƒ©ç½šã€‚
- **ä¸‰é˜¶æ®µæç¤ºç¼“è§£ç­–ç•¥ï¼ˆThree-Stage Prompt-Based Mitigationï¼‰**ï¼š
  1. **è¯­ä¹‰ç­‰ä»·æ£€æŸ¥**ï¼ˆSemantic Equivalence Checkï¼‰
  2. **å®ä½“æ— å…³çš„å±å®³æ¨æ–­**ï¼ˆEntity-Neutral Harm Inferenceï¼‰
  3. **æ¦‚ç‡åˆ†é…**ï¼ˆProbability Assignmentï¼‰ï¼Œå¼ºåˆ¶è¦æ±‚å¯¹ä¸åŒç¾¤ä½“çš„é¢„æµ‹æ¦‚ç‡å°½å¯èƒ½æ¥è¿‘ï¼ˆæœ€å¤§å·®å¼‚ â‰¤ 0.02ï¼‰ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ— éœ€å¾®è°ƒ**ï¼šé€‚ç”¨äºæ— æ³•è®¿é—®æ¨¡å‹å†…éƒ¨å‚æ•°çš„å•†ç”¨ LLMï¼ˆå¦‚ GPT-3.5-Turboï¼‰ã€‚
- **é«˜æ•ˆä¸”é€‰æ‹©æ€§æ¿€æ´»**ï¼šåªåœ¨æ£€æµ‹åˆ°é«˜å…¬å¹³é£é™©æ—¶æ‰æ‰§è¡Œå¤æ‚æç¤ºï¼Œé¿å…äº†å¯¹æ‰€æœ‰è¾“å…¥è¿›è¡Œå†—ä½™è®¡ç®—ã€‚
- **å¯è§£é‡Šæ€§å¼º**ï¼šSFV å’Œ EFD æä¾›äº†é‡åŒ–å’Œè¯Šæ–­æ¨¡å‹å…¬å¹³æ€§çš„å·¥å…·ã€‚
- **é€šç”¨æ€§å¼º**ï¼šåœ¨å¤šç§æ¨¡å‹æ¶æ„ï¼ˆBERT, DeBERTa, RoBERTa, LLMsï¼‰å’Œæ•°æ®å¢å¼ºæ–¹æ³•ä¸‹å‡æœ‰æ•ˆã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒåœ¨ä¸‰ä¸ªå¹¿æ³›ä½¿ç”¨çš„éšæ€§ä»‡æ¨è¨€è®ºåŸºå‡†ä¸Šè¿›è¡Œï¼š
- **LatentHatred**ï¼šæ¥è‡ªç¾å›½æç«¯ç»„ç»‡æ¨æ–‡çš„éšæ€§ä»‡æ¨è¨€è®ºæ•°æ®é›†ï¼ŒåŒ…å«æ˜ç¡®çš„â€œéšå«æ„å›¾â€æ ‡æ³¨ã€‚
- **Hate Speech and Offensive Language (Offensive Slang)**ï¼šç”¨æˆ·ç”Ÿæˆçš„æ¨æ–‡ï¼Œæ ‡æ³¨ä¸ºä»‡æ¨è¨€è®ºã€å†’çŠ¯æ€§è¯­è¨€æˆ–æ— å®³ã€‚
- **ToxiGen**ï¼šå¤§è§„æ¨¡æœºå™¨ç”Ÿæˆçš„éšæ€§å’Œå¯¹æŠ—æ€§ä»‡æ¨è¨€è®ºæ•°æ®é›†ï¼Œè¦†ç›–13ä¸ªå°‘æ•°ç¾¤ä½“ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **LLM Backbone**ï¼šä½¿ç”¨ **GPT-3.5-Turbo** å’Œ **Llama-3.1-8B-Instruct** ä½œä¸ºä¸»å¹²æ¨¡å‹ã€‚
- **Baseline Models**ï¼šåŒ…æ‹¬ BERTã€HateBERTã€DeBERTaã€RoBERTa ç­‰ç»å…¸åˆ†ç±»å™¨ï¼Œå¹¶ç»“åˆæ•°æ®å¢å¼ºæ–¹æ³•ï¼ˆAAV, BTï¼‰ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - ä¸»è¦æŒ‡æ ‡ä¸º **SFV** å’Œ **EFD**ï¼ŒäºŒè€…è¶Šä½è¡¨ç¤ºå…¬å¹³æ€§è¶Šå¥½ã€‚
  - ä¸ä½¿ç”¨ä¼ ç»Ÿå‡†ç¡®ç‡æŒ‡æ ‡ï¼Œå› ä¸ºç ”ç©¶ç„¦ç‚¹æ˜¯**è·¨ç¾¤ä½“çš„ä¸€è‡´æ€§**è€Œéåˆ†ç±»æ€§èƒ½ã€‚
- **å®ç°ç»†èŠ‚**ï¼šåŸºäº Hugging Face Transformers åº“ï¼Œåœ¨ Kaggle Notebook ä¸Šè¿è¡Œï¼Œä½¿ç”¨ Microsoft Serverless API è°ƒç”¨ LLMã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
ç”±äºç¼ºä¹ä¸“é—¨ç”¨äºå…¬å¹³æ€§æå‡çš„ prompt-based æ–¹æ³•ï¼Œä½œè€…é‡‡ç”¨â€œbefore vs after FairToTâ€çš„å¯¹æ¯”æ–¹å¼ï¼Œå³åœ¨åŒä¸€æ¨¡å‹ä¸Šåº”ç”¨ FairToT æ¡†æ¶å‰åæ¯”è¾ƒ SFV å’Œ EFD çš„å˜åŒ–ï¼Œä»¥éªŒè¯å…¶æœ‰æ•ˆæ€§ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
ä» **Table 1** å¯ä»¥çœ‹å‡ºï¼Œåº”ç”¨ FairToT åï¼Œæ‰€æœ‰åŸºçº¿æ¨¡å‹çš„ SFV å’Œ EFD éƒ½å®ç°äº†**æ•°é‡çº§ä¸Šçš„ä¸‹é™**ï¼š

| æ¨¡å‹ | æ•°æ®é›† | SFV (Before) â†’ (After) | EFD (Before) â†’ (After) |
|------|--------|--------------------------|--------------------------|
| BERT (AAV) | Latent Hatred | 0.113 Â± 0.080 â†’ **0.000114 Â± 0.000027** | 0.142 Â± 0.081 â†’ **0.0252 Â± 0.000073** |
| H2-BERT | ToxiGen | 0.036 Â± 0.067 â†’ **0.000071 Â± 0.000012** | 0.208 Â± 0.022 â†’ **0.0145 Â± 0.000070** |
| RoBERTa | Offensive Slang | 0.0098 Â± 0.019 â†’ **0.000066 Â± 0.000007** | 0.022 Â± 0.008 â†’ **0.0375 Â± 0.000001** |

> æ³¨ï¼šFairToT å°† SFV ä» ~0.1 é™ä½è‡³ ~1e-4ï¼Œé™å¹…è¶…è¿‡ **99%**ï¼›EFD ä¹Ÿæ™®éé™ä½ 50% ä»¥ä¸Šã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **FairToT åœ¨æ‰€æœ‰æ¨¡å‹å’Œæ•°æ®é›†ä¸Šå‡æ˜¾è‘—ä¼˜äºåŸå§‹æ¨¡å‹**ï¼Œè¯æ˜å…¶å…·æœ‰æå¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚
- å›¾è¡¨ **Figure 3** æ˜¾ç¤ºï¼Œåº”ç”¨ FairToT åï¼ŒSFV å’Œ EFD çš„åˆ†å¸ƒæ€¥å‰§æ”¶ç¼©ï¼Œè¡¨æ˜æ¨¡å‹è¾“å‡ºæ›´åŠ ç¨³å®šå’Œå…¬å¹³ã€‚
- å³ä½¿åœ¨å·²ç»ç»è¿‡ fine-tuning çš„æ¨¡å‹ï¼ˆå¦‚ H2-BERTï¼‰ä¸Šï¼ŒFairToT ä»èƒ½è¿›ä¸€æ­¥æå‡å…¬å¹³æ€§ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
åœ¨ **Table 2** ä¸­è¿›è¡Œäº†æ¶ˆèå®éªŒï¼ŒéªŒè¯å„ç»„ä»¶çš„é‡è¦æ€§ï¼š
- **ç§»é™¤ `Î¸_n`ï¼ˆsentence-level biasï¼‰æˆ– `Î¸_e`ï¼ˆentity-level biasï¼‰**ï¼šæ€§èƒ½å¤§å¹…ä¸‹é™ï¼Œè¯´æ˜ä¸¤è€…å¯¹äºå‡†ç¡®è¯†åˆ«å…¬å¹³é£é™©ç¼ºä¸€ä¸å¯ã€‚
- **ç§»é™¤ In-Context Learning (ICL)**ï¼šå…¬å¹³æ€§æŒ‡æ ‡æ¶åŒ–ï¼Œè¡¨æ˜ç¤ºä¾‹å¼•å¯¼æœ‰åŠ©äºæ¨¡å‹ç†è§£ä»»åŠ¡ã€‚
- **ç§»é™¤ Three-Step Prompting (3SP)**ï¼šSFV å’Œ EFD æ˜¾è‘—ä¸Šå‡ï¼Œè¯æ˜ç»“æ„åŒ–æ¨ç†æ­¥éª¤å¯¹å®ç°å…¬å¹³é¢„æµ‹è‡³å…³é‡è¦ã€‚

ç»“è®ºï¼š**FairToT çš„å››ä¸ªæ ¸å¿ƒç»„ä»¶ï¼ˆ`Î¸_n`, `Î¸_e`, ICL, 3SPï¼‰ååŒä½œç”¨ï¼Œå…±åŒå®ç°æœ€ä¼˜å…¬å¹³æ€§è¡¨ç°**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **LLMs åœ¨éšæ€§ä»‡æ¨è¨€è®ºæ£€æµ‹ä¸­å­˜åœ¨ä¸¥é‡çš„è·¨ç¾¤ä½“ä¸å…¬å¹³ç°è±¡**ï¼Œè¡¨ç°ä¸ºå¯¹è¯­ä¹‰ç›¸åŒçš„å¥å­å› æåŠç¾¤ä½“ä¸åŒè€Œç»™å‡ºå·®å¼‚å·¨å¤§çš„æ¯’æ€§è¯„åˆ†ã€‚
2. **FairToT èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å¹¶ä¿®æ­£è¿™ç±»ä¸å…¬å¹³è¡Œä¸º**ï¼Œé€šè¿‡æ¨ç†æ—¶çš„ prompt å·¥ç¨‹æ˜¾è‘—é™ä½ SFV å’Œ EFDï¼Œæå‡æ¨¡å‹å…¬å¹³æ€§ã€‚
3. **â€œä½•æ—¶è°ƒç”¨â€æœºåˆ¶è‡³å…³é‡è¦**ï¼šé€šè¿‡è®¾å®šé˜ˆå€¼ `R_n â‰¥ 0.35` è§¦å‘ä¿®æ­£ï¼Œæ—¢èƒ½ä¿è¯å…¬å¹³æ€§æå‡ï¼Œåˆèƒ½é¿å…ä¸å¿…è¦çš„è®¡ç®—å¼€é”€ã€‚
4. **ä½ temperature è®¾ç½®æ›´æœ‰åˆ©äºå…¬å¹³æ€§**ï¼šå®éªŒè¡¨æ˜ï¼Œå½“ temperature=0ï¼ˆç¡®å®šæ€§è§£ç ï¼‰æ—¶ï¼ŒFairToT çš„ç¨³å®šæ€§æœ€é«˜ï¼Œéšæœºæ€§ä¼šæ”¾å¤§æ½œåœ¨åè§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ– LLM çš„æ¨ç†èƒ½åŠ›**ï¼šå¦‚æœåŸºç¡€ LLM æœ¬èº«ä¸å…·å¤‡è‰¯å¥½çš„è¯­ä¹‰ç†è§£å’Œæ¨ç†èƒ½åŠ›ï¼Œä¸‰é˜¶æ®µæç¤ºå¯èƒ½å¤±æ•ˆã€‚
- **æç¤ºå·¥ç¨‹çš„è®¾è®¡æ•æ„Ÿæ€§**ï¼šç¼“è§£æ•ˆæœä¾èµ–äº prompt çš„ç²¾ç¡®è®¾è®¡ï¼Œå¯èƒ½å­˜åœ¨ä¼˜åŒ–ç©ºé—´ã€‚
- **ä»…å…³æ³¨æ–‡æœ¬æ¨¡æ€**ï¼šæœªæ‰©å±•åˆ°å¤šæ¨¡æ€æˆ–è·¨è¯­è¨€åœºæ™¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´å¤æ‚çš„**è‡ªé€‚åº”è§¦å‘æœºåˆ¶**ï¼ŒåŠ¨æ€è°ƒæ•´é˜ˆå€¼ã€‚
- å°† FairToT æ‰©å±•è‡³**å¤šè½®å¯¹è¯æˆ–å¤šæ™ºèƒ½ä½“åä½œ**çš„ moderation pipelineã€‚
- ç ”ç©¶å…¶åœ¨**multilingual** å’Œ **multimodal** åœºæ™¯ä¸‹çš„é€‚ç”¨æ€§ã€‚
- ç»“åˆå…¶ä»– fairness notionsï¼ˆå¦‚ individual fairnessï¼‰è¿›è¡Œç»¼åˆä¼˜åŒ–ã€‚

> **æºä»£ç åœ°å€**ï¼šhttps://aisuko.github.io/fair-tot/

</details>

---

### 7. [Breaking the Bottlenecks: Scalable Diffusion Models for 3D Molecular Generation](https://arxiv.org/abs/2601.08963)

**Authors**: Adrita Das, Peiran Jiang, Dantong Zhu, Barnabas Poczos, Jose Lugo-Martinez  
**Category**: cs.LG  
**Published**: 2026-01-15  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.08963v1  

#### Abstract
Diffusion models have emerged as a powerful class of generative models for molecular design, capable of capturing complex structural distributions and achieving high fidelity in 3D molecule generation. However, their widespread use remains constrained by long sampling trajectories, stochastic varian...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šBreaking the Bottlenecks: Scalable Diffusion Models for 3D Molecular Generation**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å½“å‰ç”¨äº3Dåˆ†å­ç”Ÿæˆçš„**æ‰©æ•£æ¨¡å‹**ï¼ˆDiffusion Modelsï¼‰é¢ä¸´ä¸‰å¤§ç“¶é¢ˆï¼š
- **æ¨ç†æ—¶é—´é•¿**ï¼šä¾èµ–å¤§é‡è¿­ä»£å»å™ªæ­¥éª¤ï¼ˆå¦‚GeoDifféœ€5000æ­¥ï¼‰ï¼›
- **éšæœºæ–¹å·®å¤§**ï¼šåå‘è¿‡ç¨‹ä¸­çš„éšæœºé‡‡æ ·å¯¼è‡´æ ·æœ¬ä¸ä¸€è‡´ï¼›
- **ç»“æ„æ„ŸçŸ¥å¼±**ï¼šä¼ ç»Ÿæ¨¡å‹éš¾ä»¥é«˜æ•ˆå»ºæ¨¡é•¿ç¨‹åŸå­é—´ä¾èµ–å…³ç³»ã€‚

æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤§è§„æ¨¡åˆ†å­ï¼ˆå¦‚èšåˆç‰©ï¼‰æ—¶å­˜åœ¨å¯æ‰©å±•æ€§å·®ã€è®¡ç®—å¤æ‚åº¦é«˜ç­‰é—®é¢˜ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯**
æœ¬æ–‡æå‡ºäº†ä¸€ä¸ª**åŸºäºReverse Transition Kernel (RTK)æ¡†æ¶çš„ç¡®å®šæ€§å»å™ªæ‰©æ•£æ¨¡å‹**ï¼Œå¹¶ç»“åˆ**SE(3)-equivariant SSMæ¶æ„**ï¼Œå®ç°é«˜æ•ˆä¸”ç¨³å®šçš„3Dåˆ†å­ç”Ÿæˆã€‚

#### **æ ¸å¿ƒåˆ›æ–°ç‚¹**ï¼š
1. **ç†è®ºé‡æ„ï¼šå°†DDDMçº³å…¥RTKç»Ÿä¸€æ¡†æ¶**
   - å°†**Directly Denoising Diffusion Model (DDDM)** é‡æ–°è§£é‡Šä¸ºä¸€ç§**è¿‘ä¼¼çš„ç¡®å®šæ€§åå‘è½¬ç§»æ ¸**ï¼ˆdeterministic RTKï¼‰ã€‚
   - è¯æ˜å…¶åå‘è¿‡ç¨‹ç­‰ä»·äºä¼˜åŒ–ä¸€ä¸ª**ç»“æ„åŒ–çš„ä¼ è¾“æ˜ å°„**ï¼ˆtransport mapï¼‰ï¼Œä»è€Œä»ç†è®ºä¸Šè§£é‡Šä¸ºä½•ç¡®å®šæ€§å»å™ªèƒ½é«˜æ•ˆæ”¶æ•›ã€‚

2. **å¼ºå¯¹æ•°å‡¹æ€§ä¿è¯æ•°å€¼ç¨³å®šæ€§**
   - åœ¨æ¸©å’Œæ­£åˆ™æ¡ä»¶ä¸‹ï¼Œæ¯ä¸€æ­¥åå‘å­é—®é¢˜çš„ç›®æ ‡èƒ½é‡å‡½æ•°æ˜¯**å¼ºå¯¹æ•°å‡¹**ï¼ˆstrongly log-concaveï¼‰çš„ã€‚
   - è¿™æ„å‘³ç€ç›®æ ‡åˆ†å¸ƒå…·æœ‰å”¯ä¸€å…¨å±€æå°å€¼ã€è‰¯å¥½æ¡ä»¶æ•°ï¼Œæ”¯æŒå¿«é€Ÿæ”¶æ•›å’Œç¨³å®šæ±‚è§£ã€‚

3. **å¸¸æ•°æ­¥é•¿ï¼ˆConstant Step Sizeï¼‰ä¸‹çš„é«˜æ•ˆæ¨ç†**
   - ç”±äºä»£ç†èƒ½é‡å‡½æ•° $g(z)$ æ˜¯å¼ºå‡¸çš„ï¼Œå…è®¸ä½¿ç”¨**å¸¸æ•°æ­¥é•¿**è¿›è¡Œåå‘æ›´æ–°ï¼Œä»…éœ€ $O(1)$ æ­¥å³å¯å®Œæˆç”Ÿæˆã€‚
   - ç›¸æ¯”ä¹‹ä¸‹ï¼Œæ ‡å‡†DDPMéœ€è¦ $O(1/\epsilon^2)$ æ­¥æ‰èƒ½è¾¾åˆ°ç²¾åº¦ $\epsilon$ã€‚

4. **å¼•å…¥SSM-based Denoiseræå‡å¯æ‰©å±•æ€§**
   - æ„å»ºäº†ä¸€ä¸ª**åŸºäºGraphGPSæ¡†æ¶çš„æ··åˆå»å™ªå™¨**ï¼Œç”¨**State Space Models (SSMs)** æ›¿ä»£ä¼ ç»Ÿçš„Transformerå…¨å±€æ³¨æ„åŠ›æœºåˆ¶ã€‚
   - æ”¯æŒå¤šç§SSMå˜ä½“ï¼šMambaã€Mamba-2ã€Hydraã€Jambaï¼Œå¹¶ä¿æŒSE(3)ç­‰å˜æ€§ã€‚

5. **æ„å»ºGEOM-LongRangeåŸºå‡†æ•°æ®é›†**
   - ä»GEOM-MoleculeNetä¸­æå–è¶…è¿‡100ä¸ªåŸå­çš„å¤§åˆ†å­ï¼Œå½¢æˆ**GEOM-LongRange**æ•°æ®é›†ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹å¯¹é•¿ç¨‹ä¾èµ–çš„å»ºæ¨¡èƒ½åŠ›ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ•ˆç‡** | æ¨ç†é€Ÿåº¦æ˜¾è‘—åŠ å¿«ï¼Œä»…éœ€å°‘é‡æ­¥éª¤ï¼ˆå¦‚100â€“700æ­¥ï¼‰ï¼Œè¿œå°‘äºGeoDiffçš„5000æ­¥ |
| **ä¸€è‡´æ€§** | æ¶ˆé™¤éšæœºæ–¹å·®ï¼Œæé«˜æ ·æœ¬ä¸€è‡´æ€§ä¸é‡å¤æ€§ |
| **ç¨³å®šæ€§** | å¼ºå‡¸æ€§ä¿éšœè®­ç»ƒä¸æ¨ç†è¿‡ç¨‹æ•°å€¼ç¨³å®š |
| **å¯æ‰©å±•æ€§** | SSMæ¶æ„æ”¯æŒäºšäºŒæ¬¡å¤æ‚åº¦ï¼Œé€‚ç”¨äºå¤§åˆ†å­ç³»ç»Ÿ |
| **å‡ ä½•ä¿çœŸåº¦** | SE(3)-equivarianceç¡®ä¿ç”Ÿæˆæ„è±¡çš„ç©ºé—´åˆç†æ€§ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **GEOM-DRUGS**ï¼šä¸»æµè¯ç‰©åˆ†å­æ„è±¡æ•°æ®é›†ï¼ŒåŒ…å«çº¦55,000ä¸ªè®­ç»ƒåˆ†å­ï¼Œç”¨äºå¸¸è§„æ€§èƒ½è¯„ä¼°ã€‚
- **GEOM-LongRange**ï¼šä½œè€…æ„å»ºçš„æ–°æ•°æ®é›†ï¼ŒåŒ…å«**>100ä¸ªåŸå­**çš„å¤§å‹åˆ†å­ï¼Œç”¨äºæµ‹è¯•é•¿ç¨‹ä¾èµ–å»ºæ¨¡èƒ½åŠ›ã€‚
- æ•°æ®åˆ’åˆ†ï¼š84%è®­ç»ƒ / 10%éªŒè¯ / 6%æµ‹è¯•ã€‚

---

### **å®éªŒè®¾ç½®**
- **æ¨¡å‹æ¶æ„**ï¼šåŸºäº**GraphGPS**æ¡†æ¶ï¼Œé›†æˆEGNNå±€éƒ¨æ¶ˆæ¯ä¼ é€’ + SSM/Attentionå…¨å±€æ¨¡å—ã€‚
- **SSMç±»å‹å¯¹æ¯”**ï¼šMambaã€Mamba-2ã€Hydraã€Jambaã€Transformerã€‚
- **è¾“å…¥ç‰¹å¾**ï¼š
  - èŠ‚ç‚¹ï¼šåŸå­ç±»å‹ã€ç”µè·ã€æ‚åŒ–çŠ¶æ€ã€ç¯ä¿¡æ¯ç­‰ï¼ˆ74ç»´ï¼‰
  - è¾¹ï¼šé”®ç±»å‹ï¼ˆ4ç»´ one-hotï¼‰
- **æ—¶é—´åµŒå…¥**ï¼šæ·»åŠ æ­£å¼¦ä½ç½®ç¼–ç ä»¥æä¾›æ—¶é—´æ¡ä»¶ä¿¡å·ã€‚
- **è®­ç»ƒé…ç½®**ï¼š
  - æ‰¹å¤§å°ï¼š128
  - å­¦ä¹ ç‡ï¼šå³°å€¼3e-4ï¼Œä½™å¼¦è¡°å‡è‡³3e-5
  - ä¼˜åŒ–å™¨ï¼šAdamWï¼ˆÎ²1=0.9, Î²2=0.95, weight decay=0.1ï¼‰
  - ç²¾åº¦ï¼šBF16
  - æŸå¤±å‡½æ•°ï¼špseudo-Huber lossï¼ˆé²æ£’äºå¼‚å¸¸å€¼ï¼‰

---

### **è¯„ä¼°æŒ‡æ ‡**

#### **åˆ†å­ç”Ÿæˆè´¨é‡æŒ‡æ ‡**
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Validity** | åŒ–å­¦æœ‰æ•ˆæ€§æ¯”ä¾‹ï¼ˆRDKitè§£ææˆåŠŸï¼‰ |
| **Novelty** | ä¸åœ¨è®­ç»ƒé›†ä¸­å‡ºç°çš„æ–°åˆ†å­å æ¯” |
| **Uniqueness** | éé‡å¤åˆ†å­çš„æ¯”ä¾‹ |
| **Diversity** | åˆ†å­æŒ‡çº¹é—´çš„å¹³å‡Tanimotoè·ç¦» |
| **QED** | Quantitative Estimate of Druglikenessï¼Œè¡¡é‡ç±»è¯æ€§ |
| **Atomic/Molecular Stability** | åŸå­ä»·æ€åˆè§„æ€§å’Œæ•´ä½“èƒ½é‡åˆç†æ€§ |

#### **3Dæ„è±¡ç”Ÿæˆä¸“ç”¨æŒ‡æ ‡**
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **AMR (Average Minimum RMSD)** | ç”Ÿæˆæ„è±¡ä¸å‚è€ƒæ„è±¡ä¹‹é—´çš„å¹³å‡æœ€å°RMSDï¼Œè¶Šä½è¶Šå¥½ |
| **Coverage (Cov)** | å‚è€ƒæ„è±¡ä¸­æœ‰å¤šå°‘è¢«ç”Ÿæˆé›†åˆè¦†ç›–ï¼ˆRecallï¼‰ |
| **Precision (Prec)** | ç”Ÿæˆæ„è±¡ä¸­æœ‰å¤šå°‘æ¥è¿‘çœŸå®æ„è±¡ï¼ˆPrecisionï¼‰ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **ä¼ ç»Ÿæ–¹æ³•**ï¼š
  - RDKit ETKDG
  - OMEGAï¼ˆå•†ä¸šè½¯ä»¶ï¼‰
- **æœºå™¨å­¦ä¹ æ–¹æ³•**ï¼š
  - GeoMol
  - GeoDiff
  - Torsional Diffusion

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆGEOM-DRUGSï¼‰**

#### **è¡¨1ï¼šæ„è±¡ç”Ÿæˆè´¨é‡ï¼ˆTest Setï¼‰**
| Method | Cov-R (%) | AMR-R (Ã…) | Cov-P (%) | AMR-P (Ã…) |
|--------|-----------|-----------|-----------|-----------|
| OMEGA | 38.4 | 1.058 | 40.9 | 0.995 |
| GeoMol | 53.4 | 0.841 | 40.5 | 0.946 |
| GeoDiff | 44.6 | 0.875 | 43.0 | 0.928 |
| Torsional Diffusion (20 steps) | 41.4 | 0.945 | 44.5 | 1.136 |
| **Ours (EGNN+Hydra)** | **72.7** | **0.582** | **55.2** | **0.778** |
| **Ours (EGNN+Jamba)** | **82.7** | **0.232** | **74.6** | **0.456** |

> âœ… **Jambaç‰ˆæœ¬åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå…¨é¢é¢†å…ˆ**ï¼ŒAMRé™ä½è‡³0.232 Ã…ï¼Œæ¥è¿‘ç‰©ç†æé™ã€‚

#### **è¡¨2ï¼šæ¨ç†æ•ˆç‡ï¼ˆCPUï¼‰**
| Method | Params (M) | Steps | AMR-R | Runtime (sec/conformer) |
|--------|------------|-------|--------|--------------------------|
| RDKit | â€“ | â€“ | 1.002 | 0.10 |
| GeoDiff | 1.6 | 5000 | 0.809 | 3.05 |
| Torsional Diffusion | 1.6 | 20 | 0.565 | 4.90 |
| **EGNN+Jamba** | **71.7** | **100** | **0.823** | **7.77** |

> âš ï¸ å°½ç®¡å•æ¬¡è¿è¡Œæ—¶é—´è¾ƒé•¿ï¼Œä½†å¯é€šè¿‡å¹¶è¡ŒåŒ–ä¼˜åŒ–ï¼›æ›´é‡è¦çš„æ˜¯**æ­¥éª¤æ›´å°‘ã€å¯æ§æ€§å¼º**ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆGEOM-DRUGS & GEOM-LongRangeï¼‰**

#### **è¡¨3ï¼šä¸åŒSSMæ¶æ„åœ¨GEOM-DRUGSä¸Šçš„è¡¨ç°**
| Model | Novelty | Validity | Diversity | QED |
|-------|---------|----------|-----------|-----|
| EGNN + Transformer | 85.4% | 87.1% | 89.5% | 0.456 |
| EGNN + Mamba-1 | 83.6% | 89.8% | 92.1% | 0.372 |
| EGNN + Mamba-2 | 90.8% | 88.7% | 92.6% | 0.465 |
| EGNN + Hydra | 94.5% | 97.8% | 94.4% | 0.556 |
| **EGNN + Jamba** | **93.9%** | **95.4%** | **94.6%** | **0.637** |

> ğŸ” **Jambaå’ŒHydraæ˜¾è‘—ä¼˜äºçº¯SSMæˆ–Transformer**ï¼Œè¯´æ˜æ··åˆæ¶æ„æ›´ä¼˜ã€‚

#### **è¡¨4ï¼šåœ¨GEOM-LongRangeä¸Šçš„æ³›åŒ–èƒ½åŠ›**
| Model | Novelty | Validity | Diversity | QED |
|-------|---------|----------|-----------|-----|
| EGNN + Transformer | 94.4% | 92.1% | 89.5% | 0.452 |
| EGNN + Mamba-1 | 95.6% | 90.7% | 92.1% | 0.553 |
| EGNN + Mamba-2 | 86.8% | 93.7% | 92.6% | 0.464 |
| **EGNN + Hydra** | **92.5%** | **91.9%** | **94.4%** | **0.678** |
| **EGNN + Jamba** | **99.9%** | **95.4%** | **97.2%** | **0.525** |

> ğŸ“ˆ **Jambaåœ¨å¤§åˆ†å­ä¸Šè¡¨ç°å‡ºæœ€å¼ºçš„æ³›åŒ–èƒ½åŠ›å’Œæ–°é¢–æ€§**ï¼Œæ¥è¿‘å®Œç¾noveltyã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **DDDMçš„æœ¬è´¨æ˜¯ç¡®å®šæ€§RTKé€¼è¿‘**  
   é€šè¿‡RTKæ¡†æ¶ï¼Œé¦–æ¬¡ä¸ºDDDMæä¾›äº†åšå®çš„æ¦‚ç‡åŸºç¡€ï¼Œæ­ç¤ºå…¶æœ¬è´¨æ˜¯åœ¨éšå¼ä¼˜åŒ–ä¸€ä¸ªç»“æ„åŒ–ä¼ è¾“æ˜ å°„ã€‚

2. **ç¡®å®šæ€§å»å™ªå¯å®ç°é«˜ä¿çœŸå¿«é€Ÿç”Ÿæˆ**  
   åœ¨æ»¡è¶³å¹³æ»‘æ€§å’Œæœ‰ç•Œæ€§å‡è®¾ä¸‹ï¼Œåå‘è¿‡ç¨‹å¯åˆ†è§£ä¸ºå°‘æ•°å‡ ä¸ª**å¼ºå‡¸å­é—®é¢˜**ï¼Œæ”¯æŒå¸¸æ•°æ­¥é•¿ã€å¿«é€Ÿæ”¶æ•›ã€‚

3. **SSM-basedå»å™ªå™¨å…¼å…·æ•ˆç‡ä¸è¡¨è¾¾åŠ›**  
   - **Mambaç³»åˆ—**å—é™äºå•å‘å› æœç»“æ„ï¼Œå­˜åœ¨â€œè¿‘æœŸåå·®â€ï¼ˆrecency biasï¼‰ï¼Œä¸åˆ©äºå¯¹ç§°åˆ†å­å›¾å»ºæ¨¡ã€‚
   - **Hydra**é‡‡ç”¨å‡†å¯åˆ†çŸ©é˜µå®ç°åŒå‘ä¿¡æ¯æµï¼Œæ— éœ€æ˜¾å¼Attentionå³å¯æ•æ‰é•¿ç¨‹ä¾èµ–ã€‚
   - **Jamba**èåˆAttentionä¸SSMï¼Œç»“åˆMoEæå‡å®¹é‡ï¼Œåœ¨è´¨é‡å’Œç¨³å®šæ€§ä¸Šå…¨é¢èƒœå‡ºã€‚

4. **æ··åˆæ¶æ„ä¼˜äºå•ä¸€èŒƒå¼**  
   å•çº¯ä¾èµ–SSMæˆ–Transformerå‡éæœ€ä¼˜ï¼Œ**Attention+SSMæ··åˆè®¾è®¡**ï¼ˆå¦‚Jambaï¼‰èƒ½å…¼é¡¾å…¨å±€äº¤äº’ä¸è®¡ç®—æ•ˆç‡ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
- **å‚æ•°é‡è¾ƒå¤§**ï¼šJambaæ¨¡å‹æ€»å‚æ•°è¾¾2.15Bï¼Œæ¿€æ´»å‚æ•°71.7Mï¼Œèµ„æºæ¶ˆè€—è¾ƒé«˜ã€‚
- **å¯¹åˆå§‹åŒ–æ•æ„Ÿ**ï¼šSSMåºåˆ—é¡ºåºå½±å“æ€§èƒ½ï¼Œéœ€ç²¾å¿ƒè®¾è®¡èŠ‚ç‚¹æ’åºç­–ç•¥ï¼ˆå¦‚degree-based rankingï¼‰ã€‚
- **ä»éœ€è¿›ä¸€æ­¥å‹ç¼©**ï¼šè™½ç„¶æ¯”Transformeræ›´é«˜æ•ˆï¼Œä½†åœ¨è¶…å¤§è§„æ¨¡åˆ†å­ä¸Šä»æœ‰éƒ¨ç½²æŒ‘æˆ˜ã€‚
- **ç¼ºä¹å¤šæ¨¡æ€å»ºæ¨¡èƒ½åŠ›**ï¼šç¡®å®šæ€§è·¯å¾„å¯èƒ½é™åˆ¶å¤šæ ·æ€§ï¼Œåœ¨é«˜åº¦å¤šå³°åˆ†å¸ƒä¸­è¡¨ç°å—é™ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **å¼€å‘æ··åˆéšæœº-ç¡®å®šæ€§å†…æ ¸**  
   ç»“åˆRTKæ¡†æ¶ï¼Œæ¢ç´¢**éšæœº+ç¡®å®šæ€§æ··åˆåå‘è¿‡ç¨‹**ï¼Œå¹³è¡¡å¤šæ ·æ€§ä¸æ•ˆç‡ã€‚

2. **è½»é‡åŒ–SSMæ¶æ„è®¾è®¡**  
   è®¾è®¡ä¸“ç”¨äºåˆ†å­å›¾çš„ç´§å‡‘å‹SSMæ¨¡å—ï¼Œé™ä½å†…å­˜å ç”¨ã€‚

3. **æ‰©å±•è‡³è›‹ç™½è´¨ä¸ææ–™ç³»ç»Ÿ**  
   å°†è¯¥æ¡†æ¶åº”ç”¨äºæ›´å¤§å°ºåº¦çš„ç”Ÿç‰©å¤§åˆ†å­æˆ–æ™¶ä½“ç»“æ„ç”Ÿæˆã€‚

4. **å¼•å…¥æ¡ä»¶æ§åˆ¶æœºåˆ¶**  
   æ”¯æŒå±æ€§å¼•å¯¼ç”Ÿæˆï¼ˆå¦‚pIC50ã€æº¶è§£åº¦ç­‰ï¼‰ï¼Œå¢å¼ºå®ç”¨æ€§ã€‚

5. **ç¡¬ä»¶é€‚é…ä¼˜åŒ–**  
   åˆ©ç”¨SSMçš„å¹¶è¡Œæ½œåŠ›ï¼Œå¼€å‘GPU/TPUå‹å¥½çš„å¼‚æ­¥å»å™ªç®—æ³•ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼šæœ¬æ–‡é€šè¿‡**RTKç†è®ºæ¡†æ¶**ç»Ÿä¸€ç†è§£ç¡®å®šæ€§æ‰©æ•£ï¼Œå¹¶æå‡º**SE(3)-equivariant SSMå»å™ªå™¨**ï¼Œå®ç°äº†**é«˜æ•ˆã€ç¨³å®šã€å¯æ‰©å±•çš„3Dåˆ†å­ç”Ÿæˆ**ï¼Œåœ¨è´¨é‡ä¸æ•ˆç‡ä¹‹é—´å–å¾—æ–°çš„SOTAå¹³è¡¡ã€‚

</details>

---

### 8. [Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs](https://arxiv.org/abs/2601.08403)

**Authors**: Abhijnan Nath, Alireza Bagheri Garakani, Tianchen Zhou, Fan Yang, Nikhil Krishnaswamy  
**Category**: cs.AI  
**Published**: 2026-01-15  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.08403v1  

#### Abstract
Large language models are increasingly trained via reinforcement learning for personalized recommendation tasks, but standard methods like GRPO rely on sparse, sequence-level rewards that create a credit assignment gap, obscuring which tokens drive success. This gap is especially problematic when mo...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨èç³»ç»Ÿç­‰ç”Ÿæˆä»»åŠ¡ä¸­è¶Šæ¥è¶Šå¤šåœ°é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è¿›è¡Œè®­ç»ƒï¼Œä½†æ ‡å‡†æ–¹æ³•å¦‚ **Group Relative Policy Optimization (GRPO)** å­˜åœ¨ä»¥ä¸‹å…³é”®é—®é¢˜ï¼š
- **ä¿¡ç”¨åˆ†é…ç¼ºå£ï¼ˆcredit assignment gapï¼‰**ï¼šä»…ä¾èµ–ç¨€ç–çš„åºåˆ—çº§å¥–åŠ±ï¼ˆsequence-level rewardsï¼‰ï¼Œæ— æ³•è¯†åˆ«æ˜¯å“ªäº›å…·ä½“ token æˆ–è¯­ä¹‰ç‰‡æ®µï¼ˆå¦‚äº§å“å±æ€§çŸ­è¯­ï¼‰çœŸæ­£æ¨åŠ¨äº†æˆåŠŸã€‚
- **ç¼ºä¹å¯è§£é‡Šæ€§ä¸æ•ˆç‡**ï¼šæ‰€æœ‰ token è·å¾—ç›¸åŒçš„æ¢¯åº¦æ›´æ–°ä¿¡å·ï¼Œå¯¼è‡´æ¨¡å‹éš¾ä»¥å­¦ä¹ åˆ°å…³é”®æ¨ç†è·¯å¾„ã€‚
- **æ˜“å—å¥–åŠ±é»‘å®¢æ”»å‡»ï¼ˆreward hackingï¼‰**ï¼šæ¨¡å‹å¯èƒ½è¿‡æ‹Ÿåˆæ£€ç´¢å™¨çš„è¡¨é¢ç‰¹å¾è€ŒéçœŸå®è¯­ä¹‰ã€‚

è¿™äº›é—®é¢˜åœ¨ç”¨æˆ·æ„å›¾æ¨¡ç³Šã€æ— æ˜ç¡®æ ‡ç­¾çš„åœºæ™¯ä¸‹å°¤ä¸ºä¸¥é‡ï¼Œä¾‹å¦‚ä¸ªæ€§åŒ–å•†å“æœç´¢ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šOSPO
ä½œè€…æå‡º **Owen-Shapley Policy Optimization (OSPO)**ï¼Œä¸€ç§åŸºäºåˆä½œåšå¼ˆè®ºçš„æ–°å‹ RL æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å°†ç”Ÿæˆæ–‡æœ¬ä¸­çš„**è¯­ä¹‰è¿è´¯å•å…ƒ**ï¼ˆå¦‚æè¿°äº§å“å±æ€§çš„çŸ­è¯­æˆ–è¡¨è¾¾åå¥½çš„å¥å­ï¼‰è§†ä¸ºâ€œç©å®¶â€ï¼ˆplayersï¼‰ã€‚
- åˆ©ç”¨ **Owen-Shapley values** è®¡ç®—æ¯ä¸ªç‰‡æ®µå¯¹æœ€ç»ˆå¥–åŠ±çš„è¾¹é™…è´¡çŒ®ï¼Œå®ç°ç»†ç²’åº¦çš„ä¿¡ç”¨åˆ†é…ã€‚
- é€šè¿‡ **potential-based reward shaping** å°†è¿™äº›å½’å› å€¼ç”¨äºä¼˜åŠ¿å‡½æ•°ï¼ˆadvantageï¼‰çš„é‡æ–°åˆ†é…ï¼Œä»è€ŒæŒ‡å¯¼ç­–ç•¥ä¼˜åŒ–ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
1. **æ— éœ€ä»·å€¼æ¨¡å‹çš„ä»·å€¼é‡å¡‘ï¼ˆValue-Model-Free Advantage Redistributionï¼‰**  
   ä¸ä¾èµ–é¢å¤–çš„ critic æˆ– reward model æ¥ä¼°è®¡ token çº§ä¼˜åŠ¿ï¼Œè€Œæ˜¯ç›´æ¥ä»ä»»åŠ¡åé¦ˆä¸­é€šè¿‡é‡‡æ ·éƒ¨åˆ†æŸ¥è¯¢ï¼ˆpartial queriesï¼‰è®¡ç®— Owen å€¼ã€‚

2. **è¯­ä¹‰ç‰‡æ®µçº§åˆ«çš„ä¿¡ç”¨åˆ†é…ï¼ˆSegment-Level Credit Assignmentï¼‰**  
   æ”¯æŒå°† credit åˆ†é…ç»™æœ‰æ„ä¹‰çš„è¯­è¨€å•å…ƒï¼ˆå¦‚â€œblack jeansâ€ã€â€œsummer weddingâ€ï¼‰ï¼Œè€Œä¸ä»…ä»…æ˜¯å•ä¸ª tokenã€‚

3. **é•¿åº¦ä¸å˜çš„ä¼˜åŠ¿é‡åˆ†é…æœºåˆ¶ï¼ˆLength-Invariant Advantage Redistributionï¼‰**  
   å¼•å…¥é•¿åº¦ä¹˜æ•° $ T \cdot \phi_t $ï¼Œæ¶ˆé™¤é•¿åºåˆ—å›  Owen å€¼æ€»å’Œå›ºå®šè€Œå¯¼è‡´çš„æ¢¯åº¦ç¨€é‡Šé—®é¢˜ï¼Œç¡®ä¿ä¸åŒé•¿åº¦å“åº”ä¹‹é—´çš„å…¬å¹³æ¯”è¾ƒã€‚

4. **ä¸¤ç§ä¼˜åŠ¿é‡åˆ†é…ç­–ç•¥**ï¼š
   - **OSPO-Prop**ï¼šæŒ‰ Owen å€¼æ¯”ä¾‹åˆ†é…ä¼˜åŠ¿ã€‚
   - **OSPO-Rank**ï¼šè½¬æ¢ä¸ºæ’ååå‡åŒ€åˆ†é…ï¼Œå¢å¼ºå¯¹å™ªå£°ä¼°è®¡çš„é²æ£’æ€§ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | æ˜¯å¦éœ€è¦ Value Model | ç»†ç²’åº¦ Credit | å¯æ‰©å±•æ€§ | æŠ— Reward Hacking |
|------|------------------------|---------------|----------|--------------------|
| GRPO | âŒ å¦ | âŒ å…¨å±€ç»Ÿä¸€ | âœ… é«˜ | âš ï¸ æ˜“å‘ç”Ÿ |
| DPO/SFT | âŒ å¦ | âŒ æ—  | âœ… é«˜ | âš ï¸ æœ‰é™ |
| Process Reward Models | âœ… æ˜¯ | âœ… ç»†ç²’åº¦ | âŒ ä½ï¼ˆéœ€æ ‡æ³¨ä¸­é—´æ­¥éª¤ï¼‰ | âœ… è¾ƒå¥½ |
| SCAR (Shapley-based) | âœ… æ˜¯ | âœ… ç»†ç²’åº¦ | âŒ ä½ | âœ… è¾ƒå¥½ |
| **OSPO (æœ¬æ–‡)** | âŒ **å¦** | âœ… **ç»†ç²’åº¦** | âœ… **é«˜** | âœ… **å¼º** |

> âœ… OSPO åœ¨ä¸å¢åŠ å¤–éƒ¨æ¨¡å‹çš„å‰æä¸‹å®ç°äº†æ›´ç²¾ç¡®ã€æ›´é«˜æ•ˆçš„ä¿¡ç”¨åˆ†é…ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **ESCI Shopping Queries** (Reddy et al., 2022)ï¼šæ ‡å‡†ç”µå•†æœç´¢æ•°æ®é›†ï¼Œç”¨äºä¼ ç»Ÿå•†å“æœç´¢ä»»åŠ¡ã€‚
- **H&M Fashion Recommendations** (Ling et al., 2022)ï¼šåŒ…å«ä¸°å¯Œè´­ä¹°å†å²çš„çœŸå®æ—¶å°šæ¨èæ•°æ®é›†ï¼Œç”¨äºä¸Šä¸‹æ–‡åŒ–æœç´¢ä¸ç”¨æˆ·ç”»åƒæ‘˜è¦ç”Ÿæˆä»»åŠ¡ã€‚

> æ³¨ï¼šH&M ç¼ºå°‘æ˜¾å¼æŸ¥è¯¢ï¼Œå› æ­¤ä½¿ç”¨ **Claude Sonnet 3.0** ç”Ÿæˆé«˜è´¨é‡åˆæˆæŸ¥è¯¢ä½œä¸ºç›‘ç£ä¿¡å·ã€‚

---

### å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼šä¸»å¹²æ¨¡å‹ä¸º `Qwen2.5-Instruct 7B`ï¼Œæ‰€æœ‰å¯è®­ç»ƒåŸºçº¿å‡åœ¨æ­¤åŸºç¡€ä¸Šå¾®è°ƒã€‚
- **ä»»åŠ¡ç±»å‹**ï¼š
  1. **Product Search Query Refinement**ï¼šå°†æ¨¡ç³Šç”¨æˆ·è¾“å…¥æ‰©å±•ä¸ºå¯Œå«å±æ€§çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢ã€‚
  2. **User Profile Summarization**ï¼šåŸºäºè´­ä¹°å†å²ç”Ÿæˆåå¥½æ‘˜è¦ï¼Œå¹¶é¢„æµ‹ä¸‹ä¸€è´­ä¹°é¡¹ã€‚
- **å¥–åŠ±æ¥æº**ï¼š
  - æœç´¢ä»»åŠ¡ï¼šä½¿ç”¨ FAISS + é¢†åŸŸç¼–ç å™¨ï¼ˆALL-MPNET-BASE-V2 / SIMCSE-LARGEï¼‰è¿›è¡Œå¯†é›†æ£€ç´¢ï¼Œä»¥ **NDCG@1000** ä½œä¸ºå¥–åŠ±ã€‚
  - æ‘˜è¦ä»»åŠ¡ï¼šä½¿ç”¨ Bradley-Terry æ¨¡å‹è®­ç»ƒçš„ reward model æ‰“åˆ†ï¼ˆ90%ï¼‰+ æ ¼å¼æ­£ç¡®æ€§å¥–åŠ±ï¼ˆ10%ï¼‰ã€‚

---

### è¯„ä¼°æŒ‡æ ‡
| ä»»åŠ¡ | ä¸»è¦æŒ‡æ ‡ |
|------|---------|
| å•†å“æœç´¢ | NDCG, AP, MRR, Recall |
| ç”¨æˆ·æ‘˜è¦è´¨é‡ | ä½¿ç”¨ `Qwen-3-Nemotron-32B-Reward` è¿›è¡Œæˆå¯¹èƒœç‡è¯„ä¼°ï¼ˆWin Rate, WRï¼‰ï¼Œé‡‡ç”¨ Borda è®¡åˆ†æ³• |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **SFT**ï¼šç›‘ç£å¾®è°ƒï¼Œä»…ä½¿ç”¨é«˜æ€§èƒ½ä¸“å®¶æ ·æœ¬ï¼ˆNDCG > 0.5ï¼‰ã€‚
- **DPO**ï¼šç›´æ¥åå¥½ä¼˜åŒ–ï¼Œä½¿ç”¨ä¸“å®¶å¯¹æ¯”å¯¹ï¼ˆå·®å¼‚ â‰¥ 5% AP/NDCGï¼‰ã€‚
- **GRPO**ï¼šå½“å‰ä¸»æµçš„æ— ä»·å€¼æ¨¡å‹ RL æ–¹æ³•ï¼Œä½œä¸ºä¸»è¦åœ¨çº¿ RL åŸºçº¿ã€‚
- **OSPO-Rank / OSPO-Prop / OSPO-Prop-clip**ï¼šæœ¬æ–‡æå‡ºçš„å˜ä½“ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰
#### ESCI å•†å“æœç´¢ä»»åŠ¡ï¼ˆNDCGï¼‰
| æ–¹æ³• | NDCG |
|------|------|
| Qwen2.5-72B-Instruct (å¤§æ¨¡å‹) | 0.543 |
| **OSPO-Prop (7B)** | **0.522** |
| GRPO (7B) | 0.418 |
| DPO (7B) | 0.431 |
| SFT (7B) | 0.398 |

> âœ… **OSPO-Prop ä»¥ 7B å‚æ•°è¾¾åˆ°æ¥è¿‘ 72B æ¨¡å‹çš„æ€§èƒ½**ï¼Œæ˜¾è‘—ä¼˜äºåŒè§„æ¨¡åŸºçº¿ã€‚

#### H&M æ—¶å°šæœç´¢ä»»åŠ¡ï¼ˆNDCGï¼‰
| æ–¹æ³• | NDCG |
|------|------|
| Qwen2.5-32B-Instruct | 0.438 |
| **OSPO-Prop (7B)** | **0.436** |
| GRPO (7B) | 0.379 |
| DPO (7B) | 0.396 |

> âœ… åœ¨å¤æ‚ä¸Šä¸‹æ–‡ä»»åŠ¡ä¸­ï¼ŒOSPO å‡ ä¹è¿½å¹³ 32B æ¨¡å‹ï¼Œè¿œè¶… GRPO å’Œ DPOã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ç›¸æ¯” GRPO**ï¼š
  - ESCI ä¸Š NDCG æå‡ **24.9%**ï¼ˆ0.522 vs 0.418ï¼‰
  - H&M ä¸Šæå‡ **15.0%**ï¼ˆ0.436 vs 0.379ï¼‰
- **ç›¸æ¯” DPO**ï¼š
  - ESCI ä¸Šæå‡ **21.1%**ï¼ˆ0.522 vs 0.431ï¼‰
  - H&M ä¸Šæå‡ **10.1%**ï¼ˆ0.436 vs 0.396ï¼‰

> ğŸ’¡ è¡¨æ˜ OSPO çš„ç»†ç²’åº¦ä¿¡ç”¨åˆ†é…èƒ½æœ‰æ•ˆæ•æ‰å½±å“ä¸‹æ¸¸æ€§èƒ½çš„å…³é”®è¯­ä¹‰ç‰‡æ®µã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰ä¼˜åŠ¿é‡åˆ†é…æ–¹å¼ï¼ˆTable 1ï¼‰
- **OSPO-Prop**ï¼šè¡¨ç°æœ€ä½³ï¼ˆESCI NDCG 0.522ï¼‰
- **OSPO-Rank**ï¼šç¨å¼±ä½†ä»æ˜¾è‘—ä¼˜äº GRPO/DPOï¼ˆ0.485ï¼‰
> â¤ è¡¨æ˜æ¯”ä¾‹åˆ†é…æ›´æœ‰æ•ˆï¼Œä½†æ’ååˆ†é…æä¾›ä¸€å®šé²æ£’æ€§ã€‚

#### ï¼ˆ2ï¼‰è”ç›Ÿç»“æ„ï¼ˆCoalition Structureï¼‰å½±å“ï¼ˆFigure 2 & Table 5ï¼‰
- æœ€ä¼˜é…ç½®ï¼š**ä¸­ç­‰å®½åº¦è¿ç»­è”ç›Ÿ**ï¼ˆw=4~8, p=48~96ï¼‰
- è¿‡çª„ï¼ˆw=1~2ï¼‰ï¼šè¿‡æ‹Ÿåˆå±€éƒ¨å…±ç°ï¼Œæ³›åŒ–å·®ã€‚
- è¿‡å®½ï¼ˆw=12~16ï¼‰ï¼šè¶…å‡ºå®é™…æŸ¥è¯¢é•¿åº¦ï¼Œèµ„æºæµªè´¹ã€‚
- éè¿ç»­è”ç›Ÿï¼ˆAll Subsetsï¼‰ï¼šæ€§èƒ½å´©æºƒï¼ˆNDCGâ†“è‡³ 0.113ï¼‰
> â¤ **è¿ç»­æ€§çº¦æŸè‡³å…³é‡è¦**ï¼Œä¿è¯è¯­ä¹‰ä¸€è‡´æ€§ã€‚

#### ï¼ˆ3ï¼‰è’™ç‰¹å¡æ´›é‡‡æ ·æ•°é‡
- é™ä½ç”Ÿæˆæ•°ï¼ˆnum_generationsï¼‰ä» 8 åˆ° 2 å¯¼è‡´æ€§èƒ½æ€¥å‰§ä¸‹é™ã€‚
> â¤ å¤šå®Œæˆé‡‡æ ·å¯¹ç¨³å®šä¼˜åŠ¿ä¼°è®¡å¿…ä¸å¯å°‘ã€‚

#### ï¼ˆ4ï¼‰è·¨æ£€ç´¢å™¨æ³›åŒ–èƒ½åŠ›ï¼ˆTable 4ï¼‰
- åœ¨æµ‹è¯•æ—¶åˆ‡æ¢ embedding æ¨¡å‹ï¼ˆå¦‚ä» ALL-MPNET åˆ‡æ¢åˆ° SIMCSEï¼‰ï¼š
  - GRPO æ€§èƒ½å¤§å¹…ä¸‹é™
  - **OSPO ä¿æŒè¾ƒå¼ºé²æ£’æ€§**
> â¤ è¡¨æ˜ OSPO å­¦ä¹ çš„æ˜¯æ›´å…·è¿ç§»æ€§çš„ alignment ä¿¡å·ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **ç»†ç²’åº¦ä¿¡ç”¨åˆ†é…æ¯”æ¨¡å‹ç¼©æ”¾æ›´é‡è¦**ï¼š  
   ä¸€ä¸ª 7B çš„ OSPO æ¨¡å‹æ€§èƒ½å¯åª²ç¾ç”šè‡³è¶…è¶Š 32Bâ€“72B çš„å¤§æ¨¡å‹ï¼Œè¯´æ˜**å¯¹é½è´¨é‡**æ¯”å‚æ•°é‡æ›´å…³é”®ã€‚

2. âœ… **OSPO æ˜¾è‘—æå‡æ ·æœ¬æ•ˆç‡ä¸æ”¶æ•›é€Ÿåº¦**ï¼š  
   å¦‚å›¾ 1 æ‰€ç¤ºï¼ŒOSPO åœ¨çº¦ 400 æ­¥å†…è¾¾åˆ°ç›®æ ‡æ€§èƒ½ï¼Œè€Œ GRPO éœ€è¦è¶…è¿‡ 800 æ­¥ã€‚

3. âœ… **æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›å’ŒæŠ—è¿‡æ‹Ÿåˆèƒ½åŠ›**ï¼š  
   GRPO åœ¨è®­ç»ƒåæœŸå‡ºç°æ€§èƒ½å´©æºƒï¼Œè€Œ OSPO æŒç»­ç¨³å®šä¸Šå‡ï¼Œè¡¨æ˜å…¶å­¦ä¹ åˆ°äº†æ›´æœ¬è´¨çš„è¯­ä¹‰æ¨¡å¼è€Œéè®­ç»ƒé›†æ·å¾„ã€‚

4. âœ… **é€‚ç”¨äºå¤šç§è¾“å‡ºå½¢å¼**ï¼š  
   åœ¨æœç´¢ä»»åŠ¡ä¸­ä½¿ç”¨**çŸ­è¯­çº§è”ç›Ÿ**ï¼Œåœ¨æ‘˜è¦ä»»åŠ¡ä¸­ä½¿ç”¨**å¥å­çº§è”ç›Ÿ**ï¼Œå‡å–å¾—ä¼˜å¼‚æ•ˆæœã€‚

5. âœ… **ç¼“è§£å¥–åŠ±æ“çºµé£é™©**ï¼š  
   åˆ†ææ˜¾ç¤ºæŸ¥è¯¢é•¿åº¦ä¸å¥–åŠ±å‘ˆå¼±è´Ÿç›¸å…³ï¼ˆPearson = -0.165ï¼‰ï¼Œè¯´æ˜æ¨¡å‹æœªé€šè¿‡æ‹‰é•¿è¾“å‡ºâ€œåˆ·åˆ†â€ã€‚

---

### å±€é™æ€§
1. **è®¡ç®—å¼€é”€å¢åŠ **ï¼š  
   éœ€è¦å¤šæ¬¡è°ƒç”¨ reward modelï¼ˆæˆ– retrieverï¼‰æ¥è¯„ä¼°ä¸åŒè”ç›Ÿç»„åˆï¼Œå¸¦æ¥é¢å¤–å»¶è¿Ÿã€‚
2. **è¶…å‚æ•°æ•æ„Ÿ**ï¼š  
   è”ç›Ÿå®½åº¦ï¼ˆwmaxï¼‰ã€é‡‡æ ·æ•°ï¼ˆMï¼‰çš„é€‰æ‹©å¯¹æ€§èƒ½æœ‰æ˜¾è‘—å½±å“ï¼Œéœ€ä»”ç»†è°ƒå‚ã€‚
3. **è¿‘ä¼¼è¯¯å·®**ï¼š  
   ä½¿ç”¨ Monte Carlo é‡‡æ ·è¿‘ä¼¼ Owen å€¼ï¼Œå¯èƒ½å¿½ç•¥é•¿è·ç¦»ä¾èµ–å…³ç³»ã€‚
4. **é¢†åŸŸé™åˆ¶**ï¼š  
   å½“å‰è¯„ä¼°é›†ä¸­åœ¨å•è½®æ¨èä»»åŠ¡ï¼Œå°šæœªéªŒè¯äºå¤šè½®å¯¹è¯æˆ–å¤šæ¨¡æ€åœºæ™¯ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•åˆ° **multi-turn agentic environments**ï¼ˆå¤šè½®æ™ºèƒ½ä½“ç¯å¢ƒï¼‰
- æ¢ç´¢åœ¨ **code generation**, **dialogue planning**, **interactive decision-making** ç­‰å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„åº”ç”¨
- è®¾è®¡æ›´é«˜æ•ˆçš„è”ç›Ÿé‡‡æ ·ç­–ç•¥ä»¥é™ä½è®¡ç®—æˆæœ¬
- ç»“åˆè¿‡ç¨‹å¥–åŠ±ï¼ˆprocess rewardï¼‰è¿›ä¸€æ­¥æå‡ä¸­é—´æ­¥éª¤è´¨é‡

---

## æ€»ç»“
**OSPO** æ˜¯ä¸€ç§åŸç†æ¸…æ™°ã€å·¥ç¨‹å®ç”¨çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œå®ƒé€šè¿‡å¼•å…¥ **Owen-Shapley values** å®ç°äº†æ— éœ€ä»·å€¼æ¨¡å‹çš„ç»†ç²’åº¦ä¿¡ç”¨åˆ†é…ï¼Œåœ¨å•†å“æœç´¢ä¸ç”¨æˆ·ç”»åƒç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—ä¼˜äº GRPOã€DPO ç­‰åŸºçº¿çš„æ•ˆæœã€‚å…¶å®éªŒç»“æœå¼ºæœ‰åŠ›åœ°è¯æ˜ï¼š**ç²¾å‡†çš„ credit assignment æ˜¯æå‡ LLM æ¨ç†èƒ½åŠ›çš„å…³é”®ç“¶é¢ˆä¹‹ä¸€**ï¼Œè€Œ OSPO æä¾›äº†ä¸€æ¡é«˜æ•ˆä¸”å¯æ‰©å±•çš„è§£å†³è·¯å¾„ã€‚

</details>

---

### 9. [PediaMind-R1: A Temperament-Aware Language Model for Personalized Early Childhood Care Reasoning via Cognitive Modeling and Preference Alignment](https://arxiv.org/abs/2601.08848)

**Authors**: Zihe Zhang, Can Zhang, Yanheng Xu, Xin Hu, Jichao Leng  
**Category**: cs.CL  
**Published**: 2026-01-15  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.08848v1  

#### Abstract
This paper presents PediaMind-R1, a domain-specialized large language model designed to achieve active personalization in intelligent parenting scenarios. Unlike conventional systems that provide generic suggestions, PediaMind-R1 draws on insights from developmental psychology. It introduces tempera...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠPediaMind-R1: A Temperament-Aware Language Model for Personalized Early Childhood Care Reasoning via Cognitive Modeling and Preference Alignmentã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿ Large Language Modelsï¼ˆLLMsï¼‰åœ¨è‚²å„¿ç­‰æ•æ„Ÿé¢†åŸŸç¼ºä¹**ä¸ªä½“åŒ–å“åº”èƒ½åŠ›**ï¼Œé€šå¸¸æä¾›é€šç”¨å»ºè®®ï¼Œæ— æ³•æ ¹æ®å©´å¹¼å„¿çš„ä¸ªæ€§ç‰¹å¾ï¼ˆå¦‚æƒ…ç»ªå¼ºåº¦ã€é€‚åº”æ€§ï¼‰è¿›è¡Œä¸»åŠ¨ä¸ªæ€§åŒ–æ¨ç†ã€‚è€Œå©´å¹¼å„¿æœ¬èº«ä¸å…·å¤‡è¡¨è¾¾éœ€æ±‚çš„èƒ½åŠ›ï¼Œä¾èµ–ç…§æŠ¤è€…ä»£ç†å†³ç­–ï¼Œå› æ­¤äºŸéœ€ä¸€ç§èƒ½å¤ŸåŸºäºå¿ƒç†å­¦ç†è®ºå®ç°â€œä¸»åŠ¨ä¸ªæ€§åŒ–â€ï¼ˆactive personalizationï¼‰çš„æ™ºèƒ½ç³»ç»Ÿã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
PediaMind-R1 æ˜¯é¦–ä¸ªå°†**å‘å±•å¿ƒç†å­¦ä¸­çš„æ°”è´¨ç†è®º**ï¼ˆThomas-Chess temperament frameworkï¼‰ä¸ LLM ä¸ªæ€§åŒ–æ¨ç†ç›¸ç»“åˆçš„è¯­è¨€æ¨¡å‹ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **é€šè¿‡å¿ƒç†å»ºæ¨¡æ¿€æ´» LLM ä¸ªæ€§åŒ–èƒ½åŠ›**  
  é¦–æ¬¡å¼•å…¥ Thomas-Chess æ°”è´¨åˆ†ç±»ä½“ç³»ï¼ˆEasy, Difficult, Slow-to-Warm-Up, Mixedï¼‰ï¼Œæ„å»º **infant temperament knowledge graph**ï¼Œä½œä¸ºæ¡ä»¶ä¿¡å·æŒ‡å¯¼æ¨¡å‹è¾“å‡ºç¬¦åˆå„¿ç«¥æ°”è´¨ç±»å‹çš„å…»è‚²ç­–ç•¥ã€‚

- **ä¸¤é˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼šSFT + GRPO**  
  - **Stage 1**: ä½¿ç”¨ LoRA è¿›è¡Œ **Supervised Fine-Tuning (SFT)**ï¼Œæ³¨å…¥ç»“æ„åŒ–çš„ Chain-of-Thoughtï¼ˆCoTï¼‰æ¨ç†èƒ½åŠ›ï¼Œå¹¶ç»‘å®š temperament label è¿›è¡Œæƒ…å¢ƒåŒ–æ¨ç†ã€‚
  - **Stage 2**: åº”ç”¨ **Group Relative Policy Optimization (GRPO)** å®ç°åå¥½å¯¹é½ï¼Œé€šè¿‡ç»„å†…ç›¸å¯¹ä¼˜åŠ¿ä¼˜åŒ–é€»è¾‘ä¸€è‡´æ€§ã€å¿ƒç†é€‚é…æ€§å’Œå…±æƒ…æ°´å¹³ï¼Œé¿å…ä¾èµ–ç»å¯¹å¥–åŠ±æ ‡ç­¾ã€‚

- **æå‡º temperament-sensitive è¯„ä¼°æ¡†æ¶**  
  è®¾è®¡åŒ…å«å¤šé¡¹é€‰æ‹©é¢˜æµ‹è¯•å’Œä¸“å®¶äººå·¥è¯„ä¼°çš„ç»¼åˆè¯„ä»·ä½“ç³»ï¼Œè¡¡é‡æ¨¡å‹åœ¨çŸ¥è¯†æ­£ç¡®æ€§ã€å¿ƒç†åˆç†æ€§ä¸ç…§æŠ¤é€‚ç”¨æ€§ä¸‰ä¸ªç»´åº¦çš„è¡¨ç°ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•å±€é™ | PediaMind-R1 æ”¹è¿› |
|------|--------------|------------------|
| ä¸ªæ€§åŒ–ä¾æ® | ç”¨æˆ·æ˜¾å¼åé¦ˆ / å†å²è¡Œä¸º | åŸºäºéè¯­è¨€ç”¨æˆ·çš„**å¿ƒç†ç‰¹è´¨å»ºæ¨¡**ï¼ˆtemperamentï¼‰ |
| å¯¹é½æ–¹å¼ | DPO ç­‰ä¾èµ–æˆå¯¹åå¥½æ•°æ® | GRPO åˆ©ç”¨**ç»„å†…æ¯”è¾ƒæœºåˆ¶**ï¼Œé€‚ç”¨äºé«˜é£é™©ã€ä½æ ‡æ³¨åœºæ™¯ |
| æ¨ç†å¯è§£é‡Šæ€§ | é»‘ç®±ç”Ÿæˆ | ç»“æ„åŒ– CoT è¾“å‡ºï¼š<`<temperament>` `<strategy>` `<answer>` |
| åº”ç”¨åœºæ™¯é€‚é… | é€šç”¨å¯¹è¯æˆ–ä»»åŠ¡ | èšç„¦ **early childhood care** æ•æ„Ÿé¢†åŸŸ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **SFT æ•°æ®é›†**ï¼š1,215 æ¡ç…§æŠ¤è€…æé—®ï¼Œå‡æ ‡æ³¨ Thomas-Chess æ°”è´¨ç±»å‹ï¼ˆEasy/Difficult/Slow-to-Warm-Up/Mixedï¼‰ï¼Œå¹¶é…æœ‰ç”± DeepSeek-R1 ç”Ÿæˆã€ç»ä¸“å®¶å®¡æ ¸çš„ç»“æ„åŒ– CoT å›ç­”ã€‚
- **GRPO æ•°æ®é›†**ï¼š2,646 ä¸ª temperament-sensitive å…»è‚²æƒ…æ™¯ï¼Œæºè‡ª DeepSeek-V3 è¾…åŠ©ç¼–å†™çš„è‚²å„¿ç™¾ç§‘ + è‡ªå»º knowledge graphï¼Œå…¶ä¸­ 15% ç»å„¿ç§‘ä¸å¿ƒç†å­¦ä¸“å®¶è¯„å®¡ç¡®ä¿å¯é æ€§ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼šQwen2.5-7B-Instruct
- **å¾®è°ƒæ–¹å¼**ï¼š
  - SFT é˜¶æ®µé‡‡ç”¨ LoRAï¼ˆLow-Rank Adaptationï¼‰
  - GRPO é˜¶æ®µ rollout group size = 4ï¼Œä½¿ç”¨å¤åˆå¥–åŠ±å‡½æ•°ï¼š
    $$
    R(y) = R_{\text{fmt}}(y) + R_{\text{temp}}(y) + R_{\text{know}}(y)
    $$
    åˆ†åˆ«è¯„ä¼°æ ¼å¼è§„èŒƒæ€§ã€æ°”è´¨åŒ¹é…åº¦ã€çŸ¥è¯†ç›¸å…³æ€§ã€‚
- **ç¡¬ä»¶å¹³å°**ï¼š8Ã—80GB NVIDIA A100 GPU

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| ç±»å‹ | æŒ‡æ ‡ |
|------|------|
| è‡ªåŠ¨åŒ–è¯„æµ‹ | åœ¨ 200 é“ temperament-sensitive å¤šé¡¹é€‰æ‹©é¢˜ä¸Šçš„ Top-1 å‡†ç¡®ç‡ |
| äººå·¥è¯„ä¼° | ä¸‰ä½é¢†åŸŸä¸“å®¶ç›²è¯„ 100 ä¸ªæ¡ˆä¾‹ï¼Œè¯„åˆ†ç»´åº¦ï¼š<br>â€¢ Knowledge Correctnessï¼ˆçŸ¥è¯†æ­£ç¡®æ€§ï¼‰<br>â€¢ Psychological Appropriatenessï¼ˆå¿ƒç†é€‚é…æ€§ï¼‰<br>â€¢ Caregiving Suitabilityï¼ˆç…§æŠ¤é€‚ç”¨æ€§ï¼‰<br>ï¼ˆæ¯é¡¹ 0â€“1 åˆ†ï¼ŒCohenâ€™s Kappa = 0.81 è¡¨æ˜ä¿¡åº¦é«˜ï¼‰ |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Base Baseline**ï¼šåŸå§‹æœªè°ƒä¼˜çš„ Qwen2.5-7B-Instruct
- **Ablation è®¾ç½®**ï¼š
  - PediaMind-R1 (SFT only)
  - PediaMind-R1 (SFT + GRPO)

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰è‡ªåŠ¨åŒ–åŸºå‡†æµ‹è¯•ç»“æœï¼ˆTop-1 Accuracyï¼‰
| Model | Accuracy (%) |
|-------|--------------|
| Qwen2.5-7B-Instruct (untuned) | 55.0 |
| PediaMind-R1 (SFT only) | 62.0 |
| **PediaMind-R1 (SFT + GRPO)** | **67.0** |

> â¤ SFT æå‡ +7.0%ï¼ŒGRPO å†æå‡ +5.0%ï¼Œè¡¨æ˜ä¸¤ä¸ªé˜¶æ®µå‡æœ‰æ˜¾è‘—å¢ç›Šã€‚

#### ï¼ˆ2ï¼‰äººå·¥è¯„ä¼°å¾—åˆ†ï¼ˆå¹³å‡åˆ†ï¼Œ0â€“1ï¼‰
| Model | Knowledge | Psych. Align. | Caregiving |
|--------|-----------|---------------|------------|
| Qwen2.5-7B-Instruct | 0.68 | 0.68 | 0.75 |
| PediaMind-R1 (SFT only) | 0.66 | **0.88** | 0.83 |
| **PediaMind-R1 (SFT + GRPO)** | **0.72** | **0.92** | **0.88** |

> â¤ GRPO æ˜¾è‘—æå‡å¿ƒç†é€‚é…æ€§ï¼ˆ+0.04ï¼‰ä¸ç…§æŠ¤é€‚ç”¨æ€§ï¼ˆ+0.05ï¼‰ï¼ŒåŒæ—¶æ”¹å–„çŸ¥è¯†å‡†ç¡®æ€§ï¼Œè¯´æ˜å…¶æœ‰æ•ˆç¼“è§£äº† SFT ä¸­å¯èƒ½å‡ºç°çš„â€œè¿‡åº¦æ ¼å¼åŒ–â€é—®é¢˜ã€‚

### ğŸ” æ¶ˆèå®éªŒå‘ç°
- **ä»… SFT** å¯å»ºç«‹åŸºæœ¬çš„ temperament-aware æ¨ç†èƒ½åŠ›ï¼Œä½†å­˜åœ¨éƒ¨åˆ†ç­–ç•¥ä¸è¡Œä¸ºçº¿ç´¢é”™é…ç°è±¡ã€‚
- **åŠ å…¥ GRPO å**ï¼Œæ¨¡å‹æ›´å€¾å‘äºç”Ÿæˆé€»è¾‘è¿è´¯ã€ç¬¦åˆ developmental psychology åŸåˆ™çš„å›ç­”ï¼Œå°¤å…¶åœ¨å¤æ‚æ··åˆæ°”è´¨ï¼ˆMixed Typeï¼‰åœºæ™¯ä¸­è¡¨ç°æ›´ç¨³å¥ã€‚
- GRPO çš„ group-relative ä¼˜åŠ¿æœºåˆ¶æœ‰åŠ©äºç¨³å®šè®­ç»ƒè¿‡ç¨‹ï¼Œæ— éœ€ç»å¯¹å¥–åŠ±æ ‡ç­¾å³å¯å®ç°é«˜è´¨é‡åå¥½å¯¹é½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º
1. **å¿ƒç†å­¦ç†è®ºå¯æœ‰æ•ˆèµ‹èƒ½ LLM ä¸ªæ€§åŒ–**  
   å°† Thomas-Chess temperament æ¨¡å‹ä½œä¸ºç»“æ„åŒ–å…ˆéªŒçŸ¥è¯†ï¼Œèƒ½æ˜¾è‘—æå‡ LLM åœ¨å©´å¹¼å„¿ç…§æŠ¤åœºæ™¯ä¸‹çš„ä¸ªæ€§åŒ–æ¨ç†èƒ½åŠ›ã€‚

2. **SFT + GRPO æ„æˆå¯é è®­ç»ƒèŒƒå¼**  
   - SFT æˆåŠŸåµŒå…¥åŸºç¡€çš„ temperament-sensitive reasoningï¼›
   - GRPO è¿›ä¸€æ­¥å¼ºåŒ–é€»è¾‘ä¸€è‡´æ€§ä¸å¿ƒç†åˆç†æ€§ï¼Œæ˜¯å®ç°â€œä¸»åŠ¨ä¸ªæ€§åŒ–â€çš„å…³é”®æ­¥éª¤ã€‚

3. **ä¸»åŠ¨ä¸ªæ€§åŒ–å¯åœ¨éè¯­è¨€ç”¨æˆ·åœºæ™¯è½åœ°**  
   å³ä½¿ç›®æ ‡ç”¨æˆ·ï¼ˆå©´å„¿ï¼‰æ— æ³•ç›´æ¥äº¤äº’ï¼Œä¹Ÿå¯é€šè¿‡ä»£ç†è¾“å…¥ï¼ˆç…§æŠ¤è€…æè¿° + temperament labelï¼‰å®ç°ç²¾å‡†æœåŠ¡å®šåˆ¶ã€‚

4. **ç»“æ„åŒ–è¾“å‡ºå¢å¼ºå¯ä¿¡åº¦ä¸å¯ç”¨æ€§**  
   CoT + XML-style taggingï¼ˆå¦‚ `<temperament>` `<strategy>`ï¼‰ä½¿æ¨ç†è¿‡ç¨‹é€æ˜ï¼Œä¾¿äºä¸´åºŠæˆ–å®¶åº­åº”ç”¨ä¸­çš„ç†è§£ä¸ç›‘ç£ã€‚

### âš ï¸ å±€é™æ€§
- æ°”è´¨åˆ¤æ–­ä¾èµ–ç…§æŠ¤è€…ä¸»è§‚æŠ¥å‘Šï¼Œå¯èƒ½å­˜åœ¨ **reporting bias**ï¼›
- å½“å‰ä»…åŸºäºç»å…¸ Thomas-Chess æ¡†æ¶ï¼Œæœªæ¶µç›–ç°ä»£å¤šç»´æ°”è´¨æ¨¡å‹ï¼ˆå¦‚ Rothbart æ¨¡å‹ï¼‰ï¼›
- å¥–åŠ±å‡½æ•°ä¸ºç¦»æ•£ä¿¡å·ï¼Œç¼ºä¹ç»†ç²’åº¦è¿ç»­åé¦ˆï¼›
- æ•°æ®é›†è§„æ¨¡æœ‰é™ï¼ˆSFT: ~1.2K, GRPO: ~2.6Kï¼‰ï¼Œæœªè¿›è¡Œç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³å…¶ä»– developmental stagesï¼ˆå¦‚å­¦é¾„å‰ã€é’å°‘å¹´ï¼‰ï¼›
- å¼•å…¥åŠ¨æ€ temperament tracking æœºåˆ¶ï¼Œæ”¯æŒé•¿æœŸä¸ªæ€§åŒ–ï¼›
- æ¢ç´¢ multimodal è¾“å…¥ï¼ˆè§†é¢‘/è¯­éŸ³ï¼‰è‡ªåŠ¨è¯†åˆ«å©´å¹¼å„¿æ°”è´¨ç‰¹å¾ï¼›
- å°†è¯¥æ¡†æ¶è¿ç§»è‡³å…¶ä»–æ•æ„Ÿé¢†åŸŸï¼ˆå¦‚è€å¹´æŠ¤ç†ã€ç‰¹æ®Šæ•™è‚²ï¼‰ï¼›
- å¼€å‘æ›´ç²¾ç»†çš„ reward modeling æ–¹æ³•ï¼ˆå¦‚åŸºäº trajectory rankingï¼‰ã€‚

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> PediaMind-R1 é¦–æ¬¡å®ç°äº†åŸºäºå¿ƒç†æ°”è´¨å»ºæ¨¡çš„ LLM ä¸»åŠ¨ä¸ªæ€§åŒ–ï¼Œåœ¨å©´å¹¼å„¿ç…§æŠ¤åœºæ™¯ä¸­éªŒè¯äº†â€œè®¤çŸ¥å»ºæ¨¡ + åå¥½å¯¹é½â€åŒè½®é©±åŠ¨çš„æœ‰æ•ˆæ€§ï¼Œä¸ºé«˜æ•æ„Ÿé¢†åŸŸçš„ç”¨æˆ·ä¸­å¿ƒå‹ AI æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 10. [Attention Consistency Regularization for Interpretable Early-Exit Neural Networks](https://arxiv.org/abs/2601.08891)

**Authors**: Yanhua Zhao  
**Category**: cs.LG  
**Published**: 2026-01-15  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.08891v1  

#### Abstract
Early-exit neural networks enable adaptive inference by allowing predictions at intermediate layers, reducing computational cost. However, early exits often lack interpretability and may focus on different features than deeper layers, limiting trust and explainability. This paper presents Explanatio...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Attention Consistency Regularization for Interpretable Early-Exit Neural Networks*

---

## 1. **è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### âœ… è§£å†³çš„é—®é¢˜
æ—©æœŸé€€å‡ºç½‘ç»œï¼ˆEarly-exit Neural Networksï¼‰é€šè¿‡åœ¨ä¸­é—´å±‚è¿›è¡Œé¢„æµ‹ï¼Œå®ç°è‡ªé€‚åº”æ¨ç†ï¼Œæ˜¾è‘—é™ä½è®¡ç®—å¼€é”€ï¼Œé€‚ç”¨äºèµ„æºå—é™åœºæ™¯ã€‚ç„¶è€Œï¼Œ**æ—©æœŸå‡ºå£ï¼ˆearly exitsï¼‰å¾€å¾€ç¼ºä¹å¯è§£é‡Šæ€§**ï¼Œå…¶æ³¨æ„åŠ›æœºåˆ¶å…³æ³¨çš„ç‰¹å¾åŒºåŸŸå¯èƒ½ä¸æ·±å±‚ç½‘ç»œä¸ä¸€è‡´ï¼Œå¯¼è‡´è§£é‡Šä¸ä¸€è‡´ï¼ˆexplanation inconsistencyï¼‰ï¼Œå‰Šå¼±æ¨¡å‹å¯ä¿¡åº¦å’Œå¯è§£é‡Šæ€§ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šExplanation-Guided Training (EGT)
æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šç›®æ ‡è®­ç»ƒæ¡†æ¶â€”â€”**Explanation-Guided Training (EGT)**ï¼Œæ—¨åœ¨æå‡æ—©æœŸé€€å‡ºç½‘ç»œçš„**å¯è§£é‡Šæ€§ä¸æ³¨æ„åŠ›ä¸€è‡´æ€§**ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡**æ³¨æ„åŠ›ä¸€è‡´æ€§æ­£åˆ™åŒ–**ï¼ˆattention consistency regularizationï¼‰ï¼Œä½¿å„æ—©æœŸå‡ºå£çš„æ³¨æ„åŠ›å›¾ï¼ˆattention mapsï¼‰ä¸æœ€ç»ˆå‡ºå£ä¿æŒå¯¹é½ã€‚

#### åˆ›æ–°ç‚¹ï¼š
- å¼•å…¥ **attention consistency loss**ï¼šåˆ©ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è¡¡é‡æ—©æœŸå‡ºå£ä¸æœ€ç»ˆå‡ºå£æ³¨æ„åŠ›å›¾ä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œå¹¶åœ¨è®­ç»ƒä¸­æ˜¾å¼ä¼˜åŒ–è¯¥æŸå¤±ã€‚
- å¤šç›®æ ‡è”åˆä¼˜åŒ–ï¼šæ€»æŸå¤±å‡½æ•°ä¸ºåˆ†ç±»æŸå¤± $ \mathcal{L}_{cls} $ ä¸æ³¨æ„åŠ›ä¸€è‡´æ€§æŸå¤± $ \mathcal{L}_{consistency} $ çš„åŠ æƒç»„åˆï¼š
  $$
  \mathcal{L}_{total} = \mathcal{L}_{cls} + \alpha \cdot \mathcal{L}_{consistency}
  $$
  å…¶ä¸­ $\alpha$ æ˜¯æ§åˆ¶æ­£åˆ™åŒ–å¼ºåº¦çš„è¶…å‚æ•°ã€‚
- åœ¨æ‰€æœ‰å‡ºå£ç‚¹ç”Ÿæˆæ›´ä¸€è‡´ã€æ›´å…·å¯è§£é‡Šæ€§çš„æ³¨æ„åŠ›å›¾ï¼Œå¢å¼º XAIï¼ˆExplainable AIï¼‰èƒ½åŠ›ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æå‡å¯è§£é‡Šæ€§**ï¼šä¸ä»…æé«˜å‡†ç¡®ç‡ï¼Œè¿˜ç¡®ä¿ä¸åŒæ·±åº¦çš„æ¨¡å‹â€œçœ‹åˆ°â€çš„é‡è¦åŒºåŸŸä¸€è‡´ã€‚
- **ä¿æŒé«˜æ€§èƒ½**ï¼šåœ¨ä¸ç‰ºç‰²åˆ†ç±»ç²¾åº¦çš„å‰æä¸‹æ˜¾è‘—æ”¹å–„æ³¨æ„åŠ›ä¸€è‡´æ€§ã€‚
- **å®ç”¨æ€§å¼º**ï¼šé€‚ç”¨äºèµ„æºå—é™ç¯å¢ƒä¸‹çš„é«˜æ•ˆä¸”å¯ä¿¡çš„æ¨ç†ç³»ç»Ÿã€‚

---

## 2. **æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### ğŸ“š æ•°æ®é›†
- ä½¿ç”¨ä¸€ä¸ªçœŸå®ä¸–ç•Œå›¾åƒåˆ†ç±»æ•°æ®é›† [3]ï¼Œå…±åŒ…å« **9 ç±»**ã€‚
- æ•°æ®è§„æ¨¡ï¼š**1,363 ä¸ªè®­ç»ƒæ ·æœ¬**ï¼Œ**1,364 ä¸ªæµ‹è¯•æ ·æœ¬**ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼šEarly-Exit CNNï¼ŒåŒ…å« 5 ä¸ªå·ç§¯å±‚ï¼ˆé€šé“æ•°åˆ†åˆ«ä¸º 64, 128, 256, 512, 512ï¼‰ï¼Œæ¯å±‚åæ¥ BatchNormã€ReLU å’Œ MaxPoolingã€‚
- **5 ä¸ªæ—©æœŸå‡ºå£**ï¼ˆExit 1â€“5ï¼‰ï¼Œæ¯ä¸ªå‡ºå£é…å¤‡ç‹¬ç«‹çš„ attention module å’Œ classification headã€‚
- **æ³¨æ„åŠ›æœºåˆ¶**ï¼šç”Ÿæˆç©ºé—´æ³¨æ„åŠ›å›¾ä»¥æä¾›å¯è§†åŒ–è§£é‡Šã€‚
- **ä¼˜åŒ–å™¨**ï¼šAdamï¼Œåˆå§‹å­¦ä¹ ç‡ 0.001ï¼Œæ¯ 15 è½®è¡°å‡ 0.5ã€‚
- **è®­ç»ƒè½®æ•°**ï¼š50 epochsã€‚
- **æ—©é€€ç­–ç•¥**ï¼šå½“é¢„æµ‹ç½®ä¿¡åº¦ â‰¥ 0.9 æ—¶æå‰é€€å‡ºã€‚

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Overall Accuracy (%)** | æ•´ä½“åˆ†ç±»å‡†ç¡®ç‡ |
| **Attention Consistency** | å„æ—©æœŸå‡ºå£æ³¨æ„åŠ›å›¾ä¸æœ€ç»ˆå‡ºå£ï¼ˆExit 5ï¼‰çš„å¹³å‡ä½™å¼¦ç›¸ä¼¼åº¦ |
| **Inference Time / Sample (ms)** | å¹³å‡å•æ ·æœ¬æ¨ç†æ—¶é—´ |
| **Speedup** | ç›¸å¯¹äºæ— æ—©é€€æ¨¡å‹çš„æ¨ç†åŠ é€Ÿæ¯” |

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline Model**ï¼šç›¸åŒæ¶æ„å’Œè®­ç»ƒé…ç½®ï¼Œä½†**ä¸å« attention consistency loss**ã€‚
- æ‰€æœ‰ EGT å˜ä½“ï¼ˆ$\alpha = 0.1, 0.2, ..., 0.5$ï¼‰å‡ä¸è¯¥ baseline å¯¹æ¯”ã€‚

---

## 3. **ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table I & IIï¼‰

| æ¨¡å‹ | Avg Attention Consistency | Overall Acc (%) | Inference Time (ms) | Speedup |
|------|----------------------------|------------------|------------------------|---------|
| Baseline | 0.693 | 98.97 | 3.6 | 1Ã— |
| EGT ($\alpha=0.3$) | **0.821** (+18.5%) | 98.46 | - | - |
| EGT ($\alpha=0.4$) | 0.813 (+17.3%) | **98.97** | 1.83 | **1.97Ã—** |
| EGT ($\alpha=0.5$) | 0.768 | 97.8 | 1.83 | 1.97Ã— |

> æ³¨ï¼šé€Ÿåº¦æå‡åŸºäº $\alpha=0.5$ é…ç½®æŠ¥å‘Šï¼Œå…¶ä»– EGT æ¨¡å‹åŒæ ·å¯ç”¨æ—©é€€æœºåˆ¶ã€‚

### ğŸ” è¯¦ç»†å¯¹æ¯”ç»“æœ
- **æ³¨æ„åŠ›ä¸€è‡´æ€§å¤§å¹…æå‡**ï¼š
  - æ‰€æœ‰ EGT é…ç½®å‡ä¼˜äº baselineï¼ˆæœ€ä½æå‡ 10.8%ï¼Œæœ€é«˜è¾¾ **18.5%**ï¼‰ã€‚
  - **Exit 4 æ”¹è¿›æœ€æ˜æ˜¾**ï¼šä» baseline çš„ 0.482 æå‡è‡³ 0.778â€“0.828ï¼Œç›¸å¯¹æå‡ **61.4%â€“71.8%**ã€‚
- **åˆ†ç±»ç²¾åº¦ä¿æŒç«äº‰åŠ›**ï¼š
  - æœ€é«˜å‡†ç¡®ç‡è¾¾ **98.97%**ï¼ˆä¸ baseline æŒå¹³ï¼‰ï¼Œæœ€ä½ä¸º 97.73%ï¼Œä»åœ¨é«˜ä½åŒºé—´ã€‚
- **æ¨ç†æ•ˆç‡æ˜¾è‘—æå‡**ï¼š
  - å¯ç”¨æ—©é€€åï¼Œå¹³å‡æ¨ç†æ—¶é—´ä» **3.6 ms â†’ 1.83 ms**ï¼Œå®ç° **1.97Ã— åŠ é€Ÿ**ã€‚
  - åœ¨ä»…æŸå¤±çº¦ 1.76% å‡†ç¡®ç‡çš„æƒ…å†µä¸‹è·å¾—è¿‘ä¸¤å€é€Ÿåº¦æå‡ã€‚

### ğŸ”¤ æ¶ˆèå®éªŒåˆ†æï¼ˆAblation Studyï¼‰
- ä¸åŒ $\alpha$ å€¼çš„å½±å“è¡¨æ˜å­˜åœ¨**æœ€ä¼˜æ­£åˆ™åŒ–å¼ºåº¦èŒƒå›´**ï¼š
  - $\alpha = 0.3$ï¼šå–å¾—æœ€é«˜æ³¨æ„åŠ›ä¸€è‡´æ€§ï¼ˆ0.821ï¼‰
  - $\alpha = 0.4$ï¼šæœ€ä½³å¹³è¡¡ç‚¹ï¼ˆä¸€è‡´æ€§ 0.813 + å‡†ç¡®ç‡ 98.97%ï¼‰
  - $\alpha = 0.5$ï¼šä¸€è‡´æ€§ä¸‹é™ï¼ˆ0.768ï¼‰ï¼Œè¯´æ˜è¿‡å¼ºæ­£åˆ™åŒ–åè€Œæœ‰å®³

ğŸ‘‰ è¡¨æ˜ attention consistency loss çš„æƒé‡éœ€é€‚åº¦è°ƒèŠ‚ï¼Œä¸èƒ½è¿‡å¤§ã€‚

---

## 4. **å…³é”®ç»“è®ºå’Œå‘ç°**

### âœ… ä¸»è¦å‘ç°
1. **æ³¨æ„åŠ›ä¸€è‡´æ€§å¯é€šè¿‡æ˜¾å¼æ­£åˆ™åŒ–æœ‰æ•ˆæå‡**ï¼šå¼•å…¥ attention consistency loss æ˜¾è‘—å¢å¼ºäº†æ—©æœŸå‡ºå£ä¸æ·±å±‚å‡ºå£ä¹‹é—´è§£é‡Šçš„ä¸€è‡´æ€§ã€‚
2. **å¯è§£é‡Šæ€§ä¸æ€§èƒ½å¯å…¼å¾—**ï¼šEGT åœ¨å‡ ä¹ä¸æŸå¤±å‡†ç¡®ç‡çš„å‰æä¸‹ï¼ˆæœ€é«˜è¾¾ 98.97%ï¼‰ï¼Œå®ç°äº†é«˜è¾¾ **18.5% çš„æ³¨æ„åŠ›ä¸€è‡´æ€§æå‡**ã€‚
3. **å…¼é¡¾æ•ˆç‡ä¸å¯ä¿¡åº¦**ï¼šç»“åˆ early-exit æœºåˆ¶ï¼ŒEGT å®ç°äº† **1.97Ã— æ¨ç†åŠ é€Ÿ**ï¼ŒåŒæ—¶æä¾›æ›´å¯é çš„è§†è§‰è§£é‡Šï¼Œé€‚åˆéƒ¨ç½²äºè¾¹ç¼˜è®¾å¤‡ç­‰èµ„æºå—é™åœºæ™¯ã€‚
4. **EGT($\alpha=0.3$) å’Œ EGT($\alpha=0.4$) è¡¨ç°æœ€ä¼˜**ï¼šåˆ†åˆ«åœ¨ä¸€è‡´æ€§æˆ–ç»¼åˆæ€§èƒ½ä¸Šè¾¾åˆ°å³°å€¼ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- å½“ $\alpha > 0.4$ æ—¶å‡ºç°æ€§èƒ½ä¸‹é™è¶‹åŠ¿ï¼Œè¯´æ˜æ­£åˆ™åŒ–å¼ºåº¦æ•æ„Ÿï¼Œéœ€ä»”ç»†è°ƒå‚ã€‚
- å®éªŒä»…åœ¨ä¸€ä¸ªä¸­ç­‰è§„æ¨¡ã€9ç±»çš„æ•°æ®é›†ä¸ŠéªŒè¯ï¼Œæ³›åŒ–èƒ½åŠ›æœ‰å¾…è¿›ä¸€æ­¥æ£€éªŒã€‚
- æ³¨æ„åŠ›å¯¹é½æ–¹å¼åŸºäºç®€å•çš„åŒçº¿æ€§æ’å€¼+ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œæœªè€ƒè™‘è¯­ä¹‰å±‚çº§ç»“æ„ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘ï¼ˆä½œè€…æå‡ºï¼‰
- å°† EGT æ¡†æ¶æ‰©å±•åˆ°å…¶ä»–æ¨¡å‹æ¶æ„ï¼ˆå¦‚ Transformersã€ResNetsï¼‰ã€‚
- åœ¨æ›´å¤§ã€æ›´å¤šæ ·åŒ–çš„æ•°æ®é›†ä¸Šè¿›è¡ŒéªŒè¯ã€‚
- è®¾è®¡**è‡ªé€‚åº”çš„æ­£åˆ™åŒ–æƒé‡**ï¼Œé’ˆå¯¹ä¸åŒå‡ºå£åŠ¨æ€è°ƒæ•´ $\alpha$ã€‚
- å¼•å…¥**å±‚æ¬¡åŒ–ä¸€è‡´æ€§çº¦æŸ**ï¼ˆhierarchical consistencyï¼‰ï¼Œé¼“åŠ±é€å±‚æ³¨æ„åŠ›è¿‡æ¸¡å¹³æ»‘ã€‚
- å¼€å±•ç†è®ºåˆ†æï¼Œæ¢ç´¢æ³¨æ„åŠ›ä¸€è‡´æ€§çš„ä¸Šä¸‹ç•Œã€‚
- ä¼˜åŒ–æ¡†æ¶ä»¥æ”¯æŒå®æ—¶è¾¹ç¼˜éƒ¨ç½²ï¼ˆreal-time edge deploymentï¼‰ã€‚

---

## âœ… æ€»ç»“
æœ¬è®ºæ–‡æå‡ºçš„ **Explanation-Guided Training (EGT)** æ¡†æ¶æˆåŠŸè§£å†³äº† early-exit networks ä¸­è§£é‡Šä¸ä¸€è‡´çš„å…³é”®é—®é¢˜ã€‚é€šè¿‡å¼•å…¥ **attention consistency loss**ï¼Œåœ¨ä¸å½±å“åˆ†ç±»æ€§èƒ½çš„å‰æä¸‹æ˜¾è‘—æå‡äº†æ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œä¿¡ä»»åº¦ï¼Œå¹¶ä¿ç•™äº† early-exit å¸¦æ¥çš„é«˜æ•ˆæ¨ç†ä¼˜åŠ¿ã€‚å®éªŒå……åˆ†éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ï¼Œä¸ºæ„å»º**é«˜æ•ˆã€å¯ä¿¡ã€å¯è§£é‡Šçš„ AI ç³»ç»Ÿ**æä¾›äº†æœ‰åŠ›å·¥å…·ï¼Œå°¤å…¶é€‚ç”¨äºåŒ»ç–—ã€è‡ªåŠ¨é©¾é©¶ç­‰é«˜é£é™©é¢†åŸŸã€‚

</details>

---

### 11. [BalDRO: A Distributionally Robust Optimization based Framework for Large Language Model Unlearning](https://arxiv.org/abs/2601.09172)

**Authors**: Pengyang Shao, Naixin Zhai, Lei Chen, Yonghui Yang, Fengbin Zhu, Xun Yang, Meng Wang  
**Category**: cs.LG  
**Published**: 2026-01-15  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.09172v1  

#### Abstract
As Large Language Models (LLMs) increasingly shape online content, removing targeted information from well-trained LLMs (also known as LLM unlearning) has become critical for web governance. A key challenge lies in sample-wise imbalance within the forget set: different samples exhibit widely varying...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# BalDRO: A Distributionally Robust Optimization based Framework for Large Language Model Unlearning â€”â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰ **LLM unlearning**ï¼ˆå¤§è¯­è¨€æ¨¡å‹é—å¿˜ï¼‰é¢ä¸´ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ï¼š**æ ·æœ¬çº§ä¸å¹³è¡¡ï¼ˆsample-wise imbalanceï¼‰**ã€‚åœ¨åŒä¸€ä¸ª forget set ä¸­ï¼Œä¸åŒæ ·æœ¬çš„é—å¿˜éš¾åº¦å·®å¼‚å·¨å¤§ï¼Œå¯¼è‡´â€œå¼‚æ­¥é—å¿˜â€ç°è±¡â€”â€”ç®€å•æ ·æœ¬è¢«è¿‡åº¦é—å¿˜ï¼ˆover-forgottenï¼‰ï¼Œè€Œå›°éš¾æ ·æœ¬åˆ™æœªèƒ½å……åˆ†æ“¦é™¤ï¼ˆunder-forgottenï¼‰ã€‚è¿™ç§ä¸å¹³è¡¡ä¸¥é‡æŸå®³äº†æ¨¡å‹çš„ **forgetting quality** å’Œ **model utility**ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡º **BalDRO**ï¼Œä¸€ç§åŸºäº **Distributionally Robust Optimization (DRO)** çš„æ–°å‹ã€é«˜æ•ˆçš„ LLM unlearning æ¡†æ¶ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°† unlearning å»ºæ¨¡ä¸ºä¸€ä¸ª **min-sup åŒå±‚ä¼˜åŒ–è¿‡ç¨‹**ï¼š

- **å†…å±‚ï¼ˆsupï¼‰**ï¼šå¯»æ‰¾ä¸€ä¸ªæœ€åæƒ…å†µä¸‹çš„ forget åˆ†å¸ƒ $Q_f$ï¼Œè¯¥åˆ†å¸ƒä¼šè‡ªé€‚åº”åœ°å¼ºè°ƒé‚£äº›éš¾ä»¥é—å¿˜çš„æ ·æœ¬ï¼ˆå³é«˜ loss æ ·æœ¬ï¼‰ã€‚
- **å¤–å±‚ï¼ˆminï¼‰**ï¼šåŸºäºè¿™ä¸ªå¯¹æŠ—æ€§åˆ†å¸ƒæ›´æ–°æ¨¡å‹å‚æ•°ï¼Œä»è€Œå®ç°å¯¹æ‰€æœ‰æ ·æœ¬çš„åŒæ­¥ã€å¹³è¡¡é—å¿˜ã€‚

ä¸ºäº†åœ¨ LLM åœºæ™¯ä¸‹é«˜æ•ˆå®ç°ï¼Œä½œè€…æå‡ºäº†ä¸¤ç§å˜ä½“ï¼š
- **BalDRO-G**ï¼šåŸºäº **GroupDRO** çš„ç¦»æ•£è¿‘ä¼¼ï¼ŒåŠ¨æ€é€‰æ‹©æ¯ä¸ª mini-batch ä¸­æŸå¤±æœ€é«˜çš„å­é›†è¿›è¡Œä¼˜åŒ–ã€‚
- **BalDRO-DV**ï¼šåŸºäº **Donsker-Varadhan (DV) å¯¹å¶** çš„è¿ç»­å½¢å¼ï¼Œé€šè¿‡ `log-sum-exp` ç›®æ ‡å‡½æ•°å®ç°å¹³æ»‘ã€å¯å¾®çš„è‡ªé€‚åº”åŠ æƒï¼Œæ— ç¼é›†æˆåˆ°æ ‡å‡†è®­ç»ƒæµç¨‹ä¸­ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **åŠ¨æ€é€‚åº”æ€§**ï¼šä¸åŒäºåŸºäºå¯å‘å¼æˆ–é¢„å®šä¹‰è§„åˆ™çš„ reweighting æ–¹æ³•ï¼ˆå¦‚ NPOã€SimNPOã€SatImpï¼‰ï¼ŒBalDRO èƒ½å¤Ÿæ ¹æ®è®­ç»ƒè¿‡ç¨‹ä¸­æ ·æœ¬çš„å®é™…é—å¿˜éš¾åº¦åŠ¨æ€è°ƒæ•´æƒé‡ã€‚
- **ç†è®ºä¿éšœ**ï¼šåŸºäº DRO çš„æ¡†æ¶æä¾›äº†ç†è®ºä¸Šçš„é²æ£’æ€§å’Œå¹³è¡¡æ€§ä¿è¯ã€‚
- **é€šç”¨æ€§å¼º**ï¼šä½œä¸ºæ’ä»¶å¼æ¡†æ¶ï¼Œå¯ç›´æ¥åº”ç”¨äºå¤šç§ç°æœ‰ unlearning æ–¹æ³•ï¼ˆå¦‚ NPOã€SimNPOã€SatImpï¼‰ä¹‹ä¸Šï¼Œæ˜¾è‘—æå‡å…¶æ€§èƒ½ã€‚
- **è®¡ç®—å¼€é”€ä½**ï¼šä¸¤ç§å˜ä½“å‡å¼•å…¥æå°çš„é¢å¤–è®¡ç®—æˆæœ¬ï¼Œä¿æŒäº†åŸæœ‰è®­ç»ƒæµç¨‹çš„å¯æ‰©å±•æ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
å®éªŒåœ¨ä¸¤ä¸ªä¸»æµ unlearning benchmark ä¸Šè¿›è¡Œï¼š
- **TOFU**ï¼šåˆæˆ QA æ•°æ®é›†ï¼ŒåŒ…å« 200 ä½è™šæ„ä½œè€…çš„ä¿¡æ¯ï¼Œforget set å æ¯”åˆ†åˆ«ä¸º 1%ã€5%ã€10%ã€‚ç”¨äºæ§åˆ¶å˜é‡åˆ†æé—å¿˜åŠ¨æ€ã€‚
- **MUSE**ï¼šçœŸå®ä¸–ç•Œä¹¦ç±å’Œæ–°é—»æ–‡ç« æ•°æ®é›†ï¼Œforget ä¸ retain é›†è¯­ä¹‰é«˜åº¦çº ç¼ ï¼Œæ›´å…·ç°å®æŒ‘æˆ˜æ€§ã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼šLLaMA-2-7B ä½œä¸ºä¸»å¹²æ¨¡å‹ã€‚
- **è®­ç»ƒé…ç½®**ï¼š8Ã—A800 GPUï¼Œå­¦ä¹ ç‡ã€batch sizeã€$\beta$ã€$\lambda$ ç­‰è¶…å‚æ•°è¿›è¡Œç½‘æ ¼æœç´¢ä»¥ç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚
- **å®ç°æ–¹å¼**ï¼šBalDRO ä½œä¸ºæ’ä»¶æ·»åŠ åˆ° NPOã€SimNPOã€SatImp ç­‰åŸºçº¿æ–¹æ³•ä¸Šã€‚

### è¯„ä¼°æŒ‡æ ‡
#### TOFU
- **Forget Quality (FQ)**ï¼šè¡¡é‡é—å¿˜æ•ˆæœï¼Œå€¼è¶Šé«˜è¶Šå¥½ã€‚
- **Model Utility (MU)**ï¼šä¿ç•™éç›®æ ‡çŸ¥è¯†çš„èƒ½åŠ›ï¼Œå€¼è¶Šé«˜è¶Šå¥½ã€‚
- **Extraction Memorization (EM)** / **Extraction Strength (ES)**ï¼šè¡¡é‡è®°å¿†æ®‹ç•™ï¼Œå€¼è¶Šä½è¶Šå¥½ã€‚
- **Truth Ratio å˜ä½“**ï¼ˆF-TR, Ra-TR, R-TR, Rw-TRï¼‰ï¼šå¤šç»´åº¦è¯„ä¼°é—å¿˜è´¨é‡ä¸ä¸€è‡´æ€§ã€‚

#### MUSE
- **KnowMem (KM)** / **VerbMem (VM)**ï¼šåˆ†åˆ«è¡¡é‡è¯­ä¹‰å’Œé€å­—é—å¿˜ç¨‹åº¦ï¼ˆâ†“ è¡¨ç¤ºè¶Šå¥½ï¼‰ã€‚
- **PrivLeak (PL)**ï¼šæˆå‘˜æ¨æ–­é£é™©ï¼Œè¶Šæ¥è¿‘ 0 è¶Šå¥½ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Original**ï¼šæœªé—å¿˜çš„åŸå§‹æ¨¡å‹ã€‚
- **Retain**ï¼šä»…åœ¨ retain set ä¸Šå¾®è°ƒçš„ç†æƒ³ä¸Šé™ã€‚
- **GradAscent (GA)** / **GradDiff (GD)**ï¼šç»å…¸æ¢¯åº¦åå‘/ä¿®æ­£æ–¹æ³•ã€‚
- **NPO**, **SimNPO**, **SatImp**ï¼šå½“å‰æœ€å…ˆè¿›çš„åŸºäºåå¥½çš„ unlearning æ–¹æ³•ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTOFU, forget ratio=1%ï¼‰
| æ–¹æ³• | FQ â†‘ | MU â†‘ | EM â†“ | ES â†“ |
|------|------|------|------|------|
| NPO | 0.7659 | 0.5775 | 0.6842 | 0.0982 |
| **NPO+BalDRO-G** | **0.9188** (+19.9%) | **0.6126** | 0.7634 | **0.0630** |
| **NPO+BalDRO-DV** | **0.9900** (+29.2%) | 0.5815 | **0.6659** | **0.0593** |

> âœ… BalDRO æ˜¾è‘—æå‡ FQï¼ŒåŒæ—¶é™ä½ EM/ESï¼Œè¡¨æ˜æ›´å¼ºçš„é—å¿˜èƒ½åŠ›ã€‚

### åœ¨ MUSE ä¸Šçš„è¡¨ç°ï¼ˆNews domain, VM-Df â†“ï¼‰
| æ–¹æ³• | VM-Df â†“ | PL â†’ 0 |
|------|---------|--------|
| NPO | 0.4255 | -90.85 |
| **NPO+BalDRO-G** | **0.3826** | **-65.70** |
| **NPO+BalDRO-DV** | **0.3934** | **-69.52** |

> âœ… åœ¨çœŸå®æ–‡æœ¬ä¸Šï¼ŒBalDRO åŒæ ·æœ‰æ•ˆé™ä½è®°å¿†æ³„éœ²å¹¶æ”¹å–„éšç§ä¿æŠ¤ã€‚

### ä¸åŒ forget ratio ä¸‹çš„ç¨³å®šæ€§ï¼ˆTOFUï¼‰
- åœ¨ 5% å’Œ 10% forget ratio ä¸‹ï¼ŒBalDRO å‡æŒç»­å¸¦æ¥æ˜¾è‘— FQ æå‡ï¼ˆå¦‚ NPO+BalDRO-DV åœ¨ 5% ratio ä¸‹ FQ è¾¾ 0.9646ï¼‰ã€‚
- **BalDRO-DV æ€§èƒ½æ›´ç¨³å®šä¸”ä¼˜äº BalDRO-G**ï¼Œå°¤å…¶åœ¨é«˜é—å¿˜æ¯”ä¾‹ä¸‹ä¼˜åŠ¿æ˜æ˜¾ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **Î² å‚æ•°å½±å“**ï¼šFQ åœ¨ $\beta=2.0$ æ—¶è¾¾åˆ°å³°å€¼ï¼Œè¿‡å¤§æˆ–è¿‡å°å‡å¯¼è‡´æ€§èƒ½ä¸‹é™ï¼ŒéªŒè¯äº† DRO æ­£åˆ™å¼ºåº¦éœ€é€‚ä¸­ã€‚
- **Î» å‚æ•°å½±å“**ï¼šå¢å¤§ $\lambda$ æœ‰åŠ©äºæå‡ MUï¼Œä½†å¯¹ FQ æ”¹å–„æœ‰é™ã€‚
- **DRO æ˜¯å¦åº”ç”¨äº retain set**ï¼šå®éªŒè¯æ˜ä»…å¯¹ forget set åº”ç”¨ DRO æ•ˆæœæœ€ä½³ï¼Œretain set æœ¬èº«å·²è¾ƒå‡è¡¡ï¼Œæ— éœ€é¢å¤–æ­£åˆ™åŒ–ã€‚
- **BalDRO-G çš„é‡‡æ ·æ¯”ä¾‹**ï¼ˆå›¾6ï¼‰ï¼šé€‰æ‹© top-50% æœ€éš¾æ ·æœ¬æ•ˆæœæœ€ä¼˜ï¼›è¿‡é«˜ï¼ˆ75%-100%ï¼‰ä¼šç¨€é‡Šä¿¡å·ï¼Œè¿‡ä½ï¼ˆ25%ï¼‰åˆ™æ ·æœ¬ä¸è¶³ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æ ·æœ¬çº§é—å¿˜ä¸å¹³è¡¡æ˜¯ç°æœ‰æ–¹æ³•å¤±æ•ˆçš„æ ¸å¿ƒåŸå› **ï¼Œå¿…é¡»é€šè¿‡åŠ¨æ€æœºåˆ¶åŠ ä»¥è§£å†³ã€‚
2. **BalDRO æˆåŠŸå®ç°äº†â€œåŒæ­¥é—å¿˜â€**ï¼Œé€šè¿‡ DRO æ¡†æ¶è‡ªé€‚åº”èšç„¦äºæœ€éš¾é—å¿˜çš„æ ·æœ¬ï¼Œé¿å…äº†è¿‡é—å¿˜ä¸æ¬ é—å¿˜å¹¶å­˜çš„é—®é¢˜ã€‚
3. **BalDRO-G å’Œ BalDRO-DV åˆ†åˆ«æä¾›ç¦»æ•£ä¸è¿ç»­è§†è§’**ï¼Œå…¶ä¸­ **BalDRO-DV å› å…¶å¹³æ»‘æ€§å’Œæ˜“é›†æˆæ€§ï¼Œåœ¨å®è·µä¸­è¡¨ç°æ›´ä¼˜**ã€‚
4. **BalDRO å…·æœ‰å¼ºæ³›åŒ–æ€§**ï¼Œå¯ä½œä¸ºé€šç”¨æ’ä»¶æ˜¾è‘—å¢å¼ºå¤šç§ unlearning æ–¹æ³•ï¼ˆNPOã€SimNPOã€SatImpï¼‰çš„æ€§èƒ½ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ¡†æ¶ä¸»è¦é’ˆå¯¹ **gradient-based unlearning**ï¼Œå°šæœªè¦†ç›– model-editing ç±»æ–¹æ³•ã€‚
- è™½ç„¶è®¡ç®—å¼€é”€å°ï¼Œä½†åœ¨æç«¯å¤§è§„æ¨¡åœºæ™¯ä¸‹ï¼Œ`log-sum-exp` çš„ batch-wide æ“ä½œä»å¯èƒ½å¸¦æ¥è½»å¾®å»¶è¿Ÿã€‚
- å¯¹äºæŸäº› base methodï¼ˆå¦‚ SatImpï¼‰ï¼ŒBalDRO çš„å¢ç›Šæœ‰é™ï¼Œè¯´æ˜ base loss è®¾è®¡æœ¬èº«ä¹Ÿä¼šå½±å“æœ€ç»ˆæ•ˆæœã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´ç²¾ç»†çš„ loss å‡½æ•°è®¾è®¡ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ– **forget quality** ä¸ **general utility** çš„æƒè¡¡ã€‚
- å°† BalDRO æ‰©å±•è‡³å¤šæ¨¡æ€æ¨¡å‹ unlearning åœºæ™¯ã€‚
- ç ”ç©¶å¦‚ä½•é™ä½ unlearning è¿‡ç¨‹çš„æ•´ä½“è®¡ç®—æˆæœ¬ï¼Œæå‡æ•ˆç‡ã€‚

--- 

> **æ€»ç»“**ï¼šBalDRO æ˜¯é¦–ä¸ªå°† **Distributionally Robust Optimization** å¼•å…¥ LLM unlearning çš„æ¡†æ¶ï¼Œé€šè¿‡ç†è®ºé©±åŠ¨çš„åŠ¨æ€æ ·æœ¬å¹³è¡¡æœºåˆ¶ï¼Œæœ‰æ•ˆè§£å†³äº†å¼‚æ­¥é—å¿˜éš¾é¢˜ï¼Œåœ¨ TOFU å’Œ MUSE å¤šä¸ª benchmark ä¸Šå‡å±•ç°å‡ºæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•çš„é—å¿˜è´¨é‡ä¸æ¨¡å‹å®ç”¨æ€§ã€‚

</details>

---

### 12. [Parallelizable memory recurrent units](https://arxiv.org/abs/2601.09495)

**Authors**: Florent De Geeter, Gaspard Lambrechts, Damien Ernst, Guillaume Drion  
**Category**: cs.LG  
**Published**: 2026-01-15  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.09495v1  

#### Abstract
With the emergence of massively parallel processing units, parallelization has become a desirable property for new sequence models. The ability to parallelize the processing of sequences with respect to the sequence length during training is one of the main factors behind the uprising of the Transfo...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šParallelizable memory recurrent units**

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å½“å‰ä¸»æµçš„åºåˆ—æ¨¡å‹ä¸­å­˜åœ¨ä»¥ä¸‹çŸ›ç›¾ï¼š
- **Transformer** è™½ç„¶è®­ç»ƒæ—¶å¯å¹¶è¡ŒåŒ–ï¼Œä½†åœ¨æ¨ç†é˜¶æ®µç”Ÿæˆåºåˆ—æ•ˆç‡ä½ï¼Œå› ä¸ºæ¯ä¸€æ­¥éƒ½éœ€è¦é‡æ–°å¤„ç†æ‰€æœ‰å†å²è¾“å…¥ã€‚
- **State-Space Models (SSMs)** å¦‚ LRUã€Mamba ç­‰å®ç°äº†è®­ç»ƒå’Œæ¨ç†çš„é«˜æ•ˆå¹¶è¡ŒåŒ–ï¼Œä½†ç”±äºå…¶**çº¿æ€§åŠ¨æ€ç‰¹æ€§**ï¼Œåªèƒ½å»ºæ¨¡â€œè¡°å‡è®°å¿†â€ï¼ˆfading memoryï¼‰ï¼Œå³ä¿¡æ¯ä¼šéšæ—¶é—´é€æ¸æ¶ˆå¤±ï¼Œæ— æ³•å®ç°**æŒä¹…è®°å¿†**ï¼ˆpersistent memoryï¼‰ã€‚
- ä¼ ç»Ÿçš„éçº¿æ€§ RNNï¼ˆå¦‚ LSTMã€GRUï¼‰è™½å…·å¤‡å¤šç¨³æ€ï¼ˆmultistabilityï¼‰ä»è€Œæ”¯æŒæŒä¹…è®°å¿†ï¼Œä½†å…¶é€’å½’ç»“æ„éš¾ä»¥å¹¶è¡ŒåŒ–ï¼Œé™åˆ¶äº†åœ¨å¤§è§„æ¨¡æ¨¡å‹ä¸­çš„åº”ç”¨ã€‚

å› æ­¤ï¼Œæœ¬æ–‡æ—¨åœ¨è§£å†³ä¸€ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼š**å¦‚ä½•è®¾è®¡ä¸€ç§æ—¢èƒ½å¹¶è¡ŒåŒ–è®­ç»ƒã€åˆèƒ½å®ç°æŒä¹…è®°å¿†çš„æ–°å‹ RNN æ¶æ„ï¼Ÿ**

---

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯**
ä½œè€…æå‡ºäº† **Memory Recurrent Unit (MRU)** åŠå…¶å…·ä½“å®ç°â€”â€”**Bistable Memory Recurrent Unit (BMRU)**ï¼Œä¸»è¦åˆ›æ–°å¦‚ä¸‹ï¼š

#### âœ… **MRU æ¡†æ¶ï¼šåŸºäºæ”¶æ•›æ€§ä¸å¤šç¨³æ€çš„è®°å¿†æœºåˆ¶**
- å¼•å…¥â€œå†…éƒ¨æ—¶é’Ÿâ€ï¼ˆinternal clockï¼‰æ¦‚å¿µï¼Œå…è®¸ RNN åœ¨ä¸¤ä¸ªå¤–éƒ¨æ—¶é—´æ­¥ä¹‹é—´è¿›è¡Œæ— é™æ¬¡å†…éƒ¨æ›´æ–°ï¼ˆ$N \to \infty$ï¼‰ï¼Œæœ€ç»ˆè¾¾åˆ°ç¨³å®šçŠ¶æ€ï¼ˆsteady-stateï¼‰ã€‚
- å½“ç³»ç»Ÿæ”¶æ•›åï¼Œå…¶çŠ¶æ€ä»…ä¾èµ–äºå½“å‰è¾“å…¥å’Œåˆå§‹æ¡ä»¶ï¼ˆå³å‰ä¸€æ—¶åˆ»çš„çŠ¶æ€ï¼‰ï¼Œå½¢æˆ**éšå¼å‡½æ•°å…³ç³»** $F(x_t, h_t; \theta) = 0$ã€‚
- åˆ©ç”¨è¯¥ç³»ç»Ÿçš„**åˆ†å²”å›¾**ï¼ˆbifurcation diagramï¼‰ä½œä¸ºæ¿€æ´»æœºåˆ¶ï¼Œç‰¹åˆ«æ˜¯åˆ©ç”¨**è¿Ÿæ»åˆ†å²”**ï¼ˆhysteresis bifurcationï¼‰æ¥æ„å»ºå…·æœ‰åŒç¨³æ€ï¼ˆbistabilityï¼‰çš„è¡Œä¸ºï¼Œä»è€Œå®ç°å¯¹è¿‡å»ä¿¡æ¯çš„**å®šæ€§æŒä¹…ç¼–ç **ã€‚

#### âœ… **BMRU å®ç°ï¼šé«˜æ•ˆå¯å¹¶è¡ŒåŒ–çš„é—¨æ§ç»“æ„**
- å¯¹åŸå§‹éšå¼å‡½æ•°è¿›è¡Œè¿‘ä¼¼ï¼Œå°†å…¶ç®€åŒ–ä¸ºä¸€ä¸ªç”± Heaviside å’Œ Sign å‡½æ•°æ„æˆçš„é—¨æ§æœºåˆ¶ï¼š
  $$
  z_t = H(|h_t| - \beta_t), \quad h_t = z_t \cdot S(h_t) \cdot \alpha + (1 - z_t) \cdot h_{t-1}
  $$
- è®¾è®¡çµæ„Ÿæ¥è‡ªé—¨æ§ RNNï¼ˆå¦‚ GRUï¼‰ï¼Œä½†å…³é”®åŒºåˆ«åœ¨äºï¼š
  - çŠ¶æ€è¦ä¹ˆå®Œå…¨ä¿ç•™ï¼ˆ$h_t = h_{t-1}$ï¼‰ï¼Œè¦ä¹ˆè¢«é‡ç½®ä¸º $\pm\alpha$ï¼›
  - è¿™ç§æœºåˆ¶å¤©ç„¶æ”¯æŒ**æŒä¹…è®°å¿†**ï¼ˆå½“ $|h_t| < \beta_t$ æ—¶ï¼ŒçŠ¶æ€ä¸å˜ï¼‰ï¼›
  - åŒæ—¶ä¿æŒäº†**å¯å¹¶è¡Œæ€§**ï¼Œå› å…¶æ›´æ–°è§„åˆ™å¯é€šè¿‡ associative operator è¡¨è¾¾ï¼Œå…¼å®¹ **parallel scan** ç®—æ³•ã€‚

#### âœ… **æŠ€æœ¯äº®ç‚¹**
- ä½¿ç”¨ **surrogate gradient** å¤„ç†ä¸å¯å¯¼å‡½æ•°ï¼ˆHeaviside å’Œ Signï¼‰ï¼Œä½¿æ¨¡å‹å¯é€šè¿‡åå‘ä¼ æ’­è®­ç»ƒã€‚
- æ‰€æœ‰è®¡ç®—å‡å¯å¹¶è¡Œæ‰§è¡Œï¼Œæ—¶é—´å¤æ‚åº¦ä» $O(T)$ é™è‡³ $O(\log T)$ï¼Œé€‚ç”¨äºé•¿åºåˆ—ä»»åŠ¡ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç‰¹æ€§ | Transformer | SSMs (e.g., LRU) | éçº¿æ€§ RNNs | **BMRU (æœ¬æ–‡)** |
|------|-------------|------------------|--------------|------------------|
| å¹¶è¡ŒåŒ–è®­ç»ƒ | âœ… | âœ… | âŒ | âœ… |
| æ¨ç†æ•ˆç‡ | âŒï¼ˆè‡ªå›å½’æ…¢ï¼‰ | âœ… | âœ… | âœ… |
| è¡°å‡è®°å¿†èƒ½åŠ› | âœ… | âœ… | âœ… | âš ï¸ï¼ˆå¼±ï¼‰ |
| **æŒä¹…è®°å¿†èƒ½åŠ›** | âŒ | âŒ | âœ… | âœ… |
| æ”¯æŒæµ…å±‚ç½‘ç»œå­¦ä¹ é•¿ç¨‹ä¾èµ– | âš ï¸ | âŒï¼ˆéœ€æ·±å±‚ï¼‰ | âœ… | âœ… |

> **æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“**ï¼š  
> BMRU æˆåŠŸç»“åˆäº† SSM çš„**é«˜æ•ˆå¹¶è¡Œæ€§**ä¸ä¼ ç»Ÿéçº¿æ€§ RNN çš„**æŒä¹…è®°å¿†èƒ½åŠ›**ï¼Œå¡«è¡¥äº†ç°æœ‰æ¶æ„åœ¨è¿™ä¸¤ä¸ªç»´åº¦ä¸Šçš„ç©ºç™½ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†ä¸ä»»åŠ¡**

1. **Copy-first-inputï¼ˆåˆæˆå›å½’ä»»åŠ¡ï¼‰**
   - è¾“å…¥ï¼šäºŒç»´åºåˆ— $(r_t, f_t)$ï¼Œå…¶ä¸­ $r_t \sim \mathcal{N}(0,1)$ï¼Œ$f_t=1$ ä»…åœ¨ $t=0$ã€‚
   - ä»»åŠ¡ï¼šè®°ä½ç¬¬ä¸€ä¸ª $r_0$ï¼Œå¹¶åœ¨æœ€åæ—¶é—´æ­¥è¾“å‡ºã€‚
   - ç›®æ ‡ï¼šæµ‹è¯•æ¨¡å‹åœ¨å™ªå£°å¹²æ‰°ä¸‹é•¿æœŸè®°å¿†çš„èƒ½åŠ›ã€‚
   - åºåˆ—é•¿åº¦ï¼š100 å’Œ 300ï¼›æ³›åŒ–æµ‹è¯•æ‰©å±•è‡³ $10^2$ ~ $10^5$ã€‚

2. **Permuted Sequential MNISTï¼ˆåˆ†ç±»ä»»åŠ¡ï¼‰**
   - æ•°æ®ï¼šMNIST å›¾åƒåƒç´ æŒ‰éšæœºé¡ºåºé€ä¸ªè¾“å…¥ã€‚
   - åŠ éš¾æ–¹å¼ï¼šåœ¨æœ«å°¾æ·»åŠ æœ€å¤š 1216 ä¸ªé»‘è‰²åƒç´ ï¼ˆzero-padding-likeï¼‰ï¼Œè¿«ä½¿æ¨¡å‹é•¿æ—¶é—´ä¿æŒä¿¡æ¯ã€‚
   - ä»»åŠ¡ï¼šè¯†åˆ«æ‰‹å†™æ•°å­—ç±»åˆ«ï¼ˆ10ç±»ï¼‰ã€‚
   - æµ‹è¯•æ¨¡å‹åœ¨çœŸå®ä»»åŠ¡ä¸­ç»“åˆæ—¶ç©ºä¿¡æ¯ä¸é•¿æœŸè®°å¿†çš„èƒ½åŠ›ã€‚

3. **Pathfinderï¼ˆé•¿è·ç¦»è¿æ¥åˆ¤æ–­ï¼‰**
   - æ¥æºï¼šLong Range Arena (LRA) åŸºå‡†ä¹‹ä¸€ã€‚
   - è¾“å…¥ï¼š32Ã—32 å›¾åƒï¼ŒåŒ…å«ä¸¤æ¡ç‚¹å’Œä¸€æ¡å¯èƒ½è¿æ¥å®ƒä»¬çš„å¼¯æ›²è·¯å¾„ã€‚
   - ä»»åŠ¡ï¼šåˆ¤æ–­ä¸¤ç‚¹æ˜¯å¦è¿é€šï¼ˆäºŒåˆ†ç±»ï¼‰ã€‚
   - åºåˆ—é•¿åº¦ï¼š1024ï¼ˆé€åƒç´ è¾“å…¥ï¼‰ã€‚
   - ç›®æ ‡ï¼šè¯„ä¼°æµ…å±‚ç½‘ç»œå¤„ç†æé•¿ä¾èµ–çš„èƒ½åŠ›ã€‚

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

| è®¾ç½®é¡¹ | æè¿° |
|-------|------|
| **æ¨¡å‹æ¶æ„** | çº¿æ€§æŠ•å½± â†’ è‹¥å¹² Recurrent Blockï¼ˆå« BMRU/LRU + BatchNorm + GLU + Skipï¼‰â†’ FC å±‚ |
| **Recurrent Block æ•°é‡** | 1~3 å±‚ï¼ˆæµ‹è¯•æ·±åº¦å½±å“ï¼‰ |
| **Model Dim / State Dim** | å¤šæ•°è®¾ä¸º 256ï¼›Pathfinder ä¸­ State Dim æ‰«æ 128~1024 |
| **Positional Encoding** | MNIST ä»»åŠ¡ä¸­ä»…ç»™ BMRU æ·»åŠ ï¼ˆæå‡æ€§èƒ½ï¼‰ |
| **Pooling for Prediction** | Copy/MNISTï¼šlast timestepï¼›Pathfinderï¼šmean pooling |
| **Optimizer** | AdamWï¼Œcosine å­¦ä¹ ç‡é€€ç« |
| **è¯„ä¼°æŒ‡æ ‡** | MSEï¼ˆå›å½’ï¼‰ã€Accuracyï¼ˆåˆ†ç±»ï¼‰ |
| **é‡å¤æ¬¡æ•°** | æ‰€æœ‰ç»“æœå– 5 æ¬¡è¿è¡Œå¹³å‡å€¼ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- ä¸»è¦å¯¹æ¯”å¯¹è±¡ï¼š**LRU**ï¼ˆLinear Recurrent Unitï¼‰ï¼Œä»£è¡¨æœ€å…ˆè¿›çš„å¯å¹¶è¡ŒåŒ– SSMã€‚
- åŒæ—¶æµ‹è¯• **BMRU/LRU æ··åˆæ¨¡å‹**ï¼ŒéªŒè¯äº’è¡¥æ€§ã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **Copy-first-input ä»»åŠ¡**

| æ¨¡å‹ | T=100 MSE | T=300 MSE |
|------|-----------|-----------|
| **BMRU** | ~0.00 | ~0.00 |
| **LRU** | ~0.00 | ~0.99 |

- **å…³é”®å‘ç°**ï¼š
  - åœ¨ T=300 æ—¶ï¼ŒLRU å®Œå…¨å¤±è´¥ï¼ˆMSEâ‰ˆ1ï¼‰ï¼Œè€Œ BMRU ä»æ¥è¿‘å®Œç¾ã€‚
  - æ³›åŒ–åˆ°æ›´é•¿åºåˆ—ï¼ˆ$10^5$ï¼‰æ—¶ï¼ŒBMRU æ€§èƒ½å‡ ä¹ä¸ä¸‹é™ï¼ˆå°¤å…¶ä½å™ªå£°ä¸‹ï¼‰ï¼Œè¯æ˜å…¶**æŒä¹…è®°å¿†æ³›åŒ–èƒ½åŠ›**ã€‚

> ğŸ“ˆ å›¾9 æ˜¾ç¤ºï¼šå³ä½¿è®­ç»ƒäº T=100ï¼ŒBMRU åœ¨ T=$10^5$ ä¸Šè¡¨ç°ç¨³å®šï¼›LRU åˆ™è¿…é€Ÿæ¶åŒ–ã€‚

---

### **Permuted Sequential MNIST**

| è®¾ç½® | BMRU | LRU | BMRU/LRUï¼ˆæ··åˆï¼‰ |
|------|------|-----|------------------|
| æ— é»‘åƒç´ ï¼ˆT=784ï¼‰ | 83% | **97%** | 97% |
| +1216 é»‘åƒç´ ï¼ˆT=2000ï¼‰ | **88%** | 55% | **93%** |

- **å…³é”®å‘ç°**ï¼š
  - LRU æ›´æ“…é•¿ç»„åˆçŸ­æœŸä¿¡æ¯ï¼ˆæ— é»‘åƒç´ æ—¶æ›´å¼ºï¼‰ï¼›
  - BMRU æ›´æ“…é•¿ç»´æŒè®°å¿†ï¼ˆåŠ é»‘åƒç´ åæ€§èƒ½ä¸‹é™å°ï¼‰ï¼›
  - **æ··åˆæ¨¡å‹å…¼å…·ä¸¤è€…ä¼˜ç‚¹**ï¼šæ—¢èƒ½åœ¨æ­£å¸¸æ¡ä»¶ä¸‹é«˜æ€§èƒ½ï¼Œä¹Ÿèƒ½åœ¨é•¿å»¶è¿Ÿä¸‹ä¿æŒé²æ£’æ€§ã€‚

> ğŸ” æ··åˆæ¨¡å‹è¡¨æ˜ï¼š**è¡°å‡è®°å¿† + æŒä¹…è®°å¿† = æ›´å¼ºè¡¨è¾¾åŠ›**

---

### **Pathfinder ä»»åŠ¡**

| æ¨¡å‹ | 1 Block | 2 Blocks | 3 Blocks |
|------|---------|----------|----------|
| **BMRU** | 71% | 78% | 77% |

- **å…³é”®å‘ç°**ï¼š
  - å³ä½¿å•å±‚ BMRU ä¹Ÿèƒ½æ˜¾è‘—ä¼˜äºéšæœºçŒœæµ‹ï¼ˆ50%ï¼‰ï¼›
  - æ€§èƒ½ä¸»è¦å— **state dimensionï¼ˆå®½åº¦ï¼‰** å½±å“ï¼Œè€Œéå±‚æ•°ï¼ˆæ·±åº¦ï¼‰ï¼›
  - å¢åŠ å±‚æ•°åè€Œè½»å¾®ä¸‹é™ï¼Œæ¨æµ‹å›  BMRU è¾“å‡ºç¦»æ•£åŒ–ï¼ˆÂ±Î±ï¼‰å¯¼è‡´æ·±å±‚ä¼ é€’å›°éš¾ã€‚

> ğŸ’¡ è¯´æ˜ BMRU é€‚åˆ**æµ…è€Œå®½**çš„ç»“æ„ï¼Œåœ¨å¤„ç†æç«¯é•¿ç¨‹ä¾èµ–æ—¶æ— éœ€å †å æ·±å±‚ã€‚

---

### **æ¶ˆèå®éªŒä¸åˆ†æï¼ˆéšå«ï¼‰**
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†é€šè¿‡ä»¥ä¸‹åˆ†æä½“ç°å…³é”®ç»„ä»¶ä½œç”¨ï¼š
- **é—¨æ§æœºåˆ¶ $z_t = H(|h_t| - \beta_t)$** æ˜¯å®ç°æŒä¹…è®°å¿†çš„å…³é”®ï¼šå½“ $z_t=0$ æ—¶çŠ¶æ€å†»ç»“ã€‚
- **Sign å‡½æ•°ä¸ç¦»æ•£çŠ¶æ€** æ˜¯å®ç°åŒç¨³æ€çš„åŸºç¡€ã€‚
- **Surrogate gradient å‚æ•° $\alpha_{\text{surr}}$** è¢«è®¾ä¸º 1ï¼Œå¹³è¡¡æ¢¯åº¦ä¼°è®¡ç²¾åº¦ä¸ç¨³å®šæ€§ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦ç»“è®º**
1. âœ… **MRU æ˜¯ä¸€ç±»æ–°çš„ RNN èŒƒå¼**ï¼šé€šè¿‡è®©å†…éƒ¨åŠ¨åŠ›å­¦å……åˆ†æ”¶æ•›ï¼Œå°†è®°å¿†ç¼–ç äºç¨³å®šçŠ¶æ€è€Œéç¬æ€è½¨è¿¹ï¼Œä»è€Œå®ç°**æŒä¹…è®°å¿†**ã€‚
2. âœ… **BMRU æ˜¯ MRU çš„æœ‰æ•ˆå®ä¾‹**ï¼šåŸºäºè¿Ÿæ»åˆ†å²”è®¾è®¡ï¼Œå…¼å…·éçº¿æ€§ RNN çš„è®°å¿†èƒ½åŠ›å’Œ SSM çš„å¹¶è¡Œæ•ˆç‡ã€‚
3. âœ… **BMRU åœ¨é•¿ç¨‹ä¾èµ–ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äº LRU**ï¼šå°¤å…¶æ˜¯åœ¨éœ€è¦é•¿æœŸä¿æŒä¿¡æ¯çš„ä»»åŠ¡ä¸­ï¼ˆå¦‚åŠ é»‘åƒç´ çš„ MNISTï¼‰ã€‚
4. âœ… **BMRU ä¸ SSM å¯äº’è¡¥**ï¼šæ··åˆä½¿ç”¨ BMRUï¼ˆæŒä¹…è®°å¿†ï¼‰ä¸ LRUï¼ˆè¡°å‡è®°å¿†ï¼‰å¯è·å¾—æœ€ä½³æ€§èƒ½ã€‚
5. âœ… **BMRU é€‚åˆæµ…å±‚ç½‘ç»œ**ï¼šåœ¨ Pathfinder ç­‰å›°éš¾ä»»åŠ¡ä¸Šï¼Œå•å±‚å³å¯å–å¾—è‰¯å¥½æ•ˆæœï¼Œä¸”æ€§èƒ½æ›´ä¾èµ–å®½åº¦è€Œéæ·±åº¦ã€‚

---

### **å±€é™æ€§**
1. **çŠ¶æ€é‡åŒ–é™åˆ¶è¡¨è¾¾èƒ½åŠ›**ï¼šBMRU æ¯ä¸ªç¥ç»å…ƒåªèƒ½è¾“å‡º Â±Î±ï¼Œå¯èƒ½å¯¼è‡´ä¿¡æ¯å‹ç¼©æŸå¤±ã€‚
2. **æ·±å±‚å †å æ€§èƒ½ä¸‹é™**ï¼šç”±äºç¦»æ•£åŒ–å’Œé—¨æ§æœºåˆ¶ï¼Œæ·±å±‚ BMRU ç½‘ç»œè®­ç»ƒéš¾åº¦å¢åŠ ã€‚
3. **ä¾èµ– surrogate gradient**ï¼šå‰å‘/åå‘ä¸ä¸€è‡´å¯èƒ½å½±å“ä¼˜åŒ–ç¨³å®šæ€§ã€‚
4. **ç›®å‰ä»…ç”¨äºåˆ¤åˆ«ä»»åŠ¡**ï¼šå°šæœªåœ¨æ–‡æœ¬ç”Ÿæˆç­‰ç”Ÿæˆå¼ä»»åŠ¡ä¸­éªŒè¯å…¶æ¨ç†æ•ˆç‡ä¼˜åŠ¿ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **æ”¹è¿›å•å…ƒè®¾è®¡**ï¼šæ¢ç´¢è½¯é—¨æ§ã€è¿ç»­çŠ¶æ€ç‰ˆæœ¬ä»¥ç¼“è§£ç¦»æ•£åŒ–é—®é¢˜ã€‚
2. **æ··åˆæ¶æ„è‡ªåŠ¨åŒ–**ï¼šè‡ªåŠ¨å†³å®šä½•æ—¶ä½¿ç”¨ BMRU æˆ– SSM å±‚ã€‚
3. **æ›´æ·±çš„ BMRU ç½‘ç»œè®­ç»ƒç­–ç•¥**ï¼šæ”¹è¿›åˆå§‹åŒ–ã€æ®‹å·®è¿æ¥æˆ–å¼•å…¥ä¸­é—´ç›‘ç£ã€‚
4. **æ‰©å±•è‡³ç”Ÿæˆä»»åŠ¡**ï¼šéªŒè¯å…¶åœ¨è¯­è¨€å»ºæ¨¡ã€è¯­éŸ³åˆæˆä¸­çš„å®é™…æ¨ç†é€Ÿåº¦ä¼˜åŠ¿ã€‚
5. **ç†è®ºåˆ†æ**ï¼šå½¢å¼åŒ– MRU çš„è®°å¿†å®¹é‡ã€è¡¨è¾¾èƒ½åŠ›è¾¹ç•Œã€‚

---

## **æ€»ç»“**
æœ¬æ–‡æå‡ºçš„ **MRU/BMRU** æ˜¯ä¸€æ¬¡é‡è¦çš„æ¶æ„åˆ›æ–°ï¼ŒæˆåŠŸå°†**å¤šç¨³æ€å¸¦æ¥çš„æŒä¹…è®°å¿†èƒ½åŠ›**ä¸**ç°ä»£å¹¶è¡ŒåŒ–è®­ç»ƒéœ€æ±‚**ç›¸ç»“åˆã€‚å®éªŒè¯æ˜å…¶åœ¨é•¿ç¨‹ä¾èµ–ä»»åŠ¡ä¸­ä¼˜äºä¸»æµ SSMï¼ˆå¦‚ LRUï¼‰ï¼Œå°¤å…¶åœ¨è®°å¿†æŒä¹…æ€§å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢è¡¨ç°çªå‡ºã€‚å°½ç®¡å­˜åœ¨ç¦»æ•£åŒ–å’Œæ·±å±‚è®­ç»ƒçš„æŒ‘æˆ˜ï¼Œä½†å®ƒä¸ºä¸‹ä¸€ä»£é«˜æ•ˆã€å¼ºè®°å¿†çš„åºåˆ—æ¨¡å‹æä¾›äº†å…¨æ–°èŒƒå¼ï¼Œå¹¶å¼€å¯äº†â€œ**å¯å¹¶è¡Œéçº¿æ€§ RNN**â€çš„ç ”ç©¶æ–¹å‘ã€‚

</details>

---

### 13. [Recursive Knowledge Synthesis for Multi-LLM Systems: Stability Analysis and Tri-Agent Audit Framework](https://arxiv.org/abs/2601.08839)

**Authors**: Toshiyuki Shigemura  
**Category**: cs.CL  
**Published**: 2026-01-15  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.08839v1  

#### Abstract
This paper presents a tri-agent cross-validation framework for analyzing stability and explainability in multi-model large language systems. The architecture integrates three heterogeneous LLMs-used for semantic generation, analytical consistency checking, and transparency auditing-into a recursive ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Recursive Knowledge Synthesis for Multi-LLM Systems: Stability Analysis and Tri-Agent Audit Framework*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³**å¤šæ¨¡å‹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆmulti-LLMï¼‰ç³»ç»Ÿä¸­çš„è®¡ç®—ç¨³å®šæ€§ã€é€»è¾‘ä¸€è‡´æ€§ä¸å¯è§£é‡Šæ€§ä¸è¶³çš„é—®é¢˜**ã€‚åœ¨å½“å‰ä¸»æµçš„å•æ¨¡å‹æ¨ç†èŒƒå¼ï¼ˆå¦‚ Chain-of-Thoughtã€ReActã€Reflexionï¼‰ä¸­ï¼Œå°½ç®¡èƒ½æå‡æ¨ç†èƒ½åŠ›ï¼Œä½†ç¼ºä¹å¯¹ç³»ç»Ÿçº§ç¨³å®šæ€§çš„ç†è®ºä¿éšœï¼Œä¸”å®¹æ˜“å‡ºç°â€œé€»è¾‘æ¼‚ç§»â€ï¼ˆlogical driftï¼‰æˆ–ä¸å¯å®¡è®¡çš„è¡Œä¸ºã€‚

æ­¤å¤–ï¼Œç°æœ‰çš„å¤šä»£ç†ç³»ç»Ÿï¼ˆmulti-agent LLM systemsï¼‰å¾€å¾€ä¾èµ–è‡ªåŠ¨åŒ– API è°ƒç”¨å’Œè‡ªä¸»äº¤äº’ï¼Œå­˜åœ¨å®‰å…¨é£é™©ï¼ˆå¦‚åé¦ˆå¾ªç¯å¤±æ§ã€éšå¼åè°ƒè¡Œä¸ºï¼‰ï¼Œéš¾ä»¥å®ç°äººç±»ç›‘ç£ä¸‹çš„å¯æ§æ¨ç†ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **Tri-Agent Cross-Validation Frameworkï¼ˆä¸‰ä»£ç†äº¤å‰éªŒè¯æ¡†æ¶ï¼‰** çš„æ–°å‹æ¶æ„ï¼Œå¹¶å¼•å…¥äº† **Recursive Knowledge Synthesis (RKS)** æ¦‚å¿µï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡ä¸‰ä¸ªå¼‚æ„ LLM åœ¨é€’å½’å¾ªç¯ä¸­ç›¸äº’çº¦æŸã€æŒç»­ä¼˜åŒ–çŸ¥è¯†çŠ¶æ€ã€‚

#### ä¸‰å¤§æ¨¡å—è®¾è®¡ï¼š
- **Semantic Reasoning Module (Ms)**ï¼šç”± ChatGPT æ‰§è¡Œï¼Œè´Ÿè´£è¯­ä¹‰ç”Ÿæˆä¸è¯­è¨€è¿è´¯æ€§ã€‚
- **Analytical Consistency Module (MA)**ï¼šç”± Gemini æ‰§è¡Œï¼Œç¡®ä¿é€»è¾‘ä¸€è‡´æ€§å’Œç†è®ºå®Œæ•´æ€§ã€‚
- **Transparency Audit Module (Mr)**ï¼šç”± Copilot æ‰§è¡Œï¼Œä½œä¸ºâ€œå®‰å…¨ç›‘ç®¡å™¨â€ï¼Œå¼ºåˆ¶æ‰§è¡Œé€æ˜åº¦ä¸ä¼¦ç†åˆè§„æ ‡å‡†ã€‚

è¿™ä¸‰ä¸ªæ¨¡å—åœ¨ä¸€ä¸ªç”±**å¤–éƒ¨äººç±»ç›‘ç£è€…ï¼ˆExternal Supervisorï¼‰** æ§åˆ¶çš„é€’å½’å¾ªç¯ä¸­åä½œï¼Œå½¢æˆä¸€ä¸ªéè‡ªä¸»ä½†é«˜åº¦ç»“æ„åŒ–çš„æ¨ç†æµç¨‹ã€‚

#### åˆ›æ–°æœºåˆ¶ï¼š
- **Session-Level Role Decomposition (SLRD)**ï¼šåœ¨åŒä¸€ LLM å¹³å°å†…ï¼ˆå¦‚ ChatGPT Plusï¼‰ï¼Œå°†ä¸åŒè§’è‰²åˆ†é…åˆ°ç‹¬ç«‹ä¼šè¯ä¸­ï¼Œé˜²æ­¢ä¸Šä¸‹æ–‡æ±¡æŸ“å’Œéšå¼è®°å¿†ä¼ æ’­ã€‚
- **Human-Bridge Orchestration (HBO)**ï¼šæ‰€æœ‰æ¨¡å—é—´é€šä¿¡å‡ç”±äººå·¥æ‰‹åŠ¨ä¼ é€’ï¼Œæœç»è‡ªåŠ¨ä»£ç†é“¾å¼è°ƒç”¨ï¼Œå¢å¼ºå®‰å…¨æ€§ä¸å¯å®¡è®¡æ€§ã€‚
- **RKS çš„å½¢å¼åŒ–å»ºæ¨¡**ï¼šåŸºäº **Banach Fixed-Point Theorem** å°†æ•´ä¸ªç³»ç»Ÿè§†ä¸ºä¸€ä¸ªå¤åˆæ˜ å°„ $ V_{op} = M_T \circ M_A \circ M_S $ï¼Œå¹¶è¯æ˜å½“ $ M_T $ å…·æœ‰æ”¶ç¼©æ€§æ—¶ï¼Œç³»ç»Ÿæ”¶æ•›äºå”¯ä¸€å›ºå®šç‚¹ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ Debate-basedã€AutoGPTï¼‰ | æœ¬æ–‡æ–¹æ³• |
|------|----------------------------------------|---------|
| **è‡ªåŠ¨åŒ–ç¨‹åº¦** | é«˜ï¼ˆå…¨è‡ªåŠ¨ API è°ƒç”¨ï¼‰ | ä½ï¼ˆäººå·¥æ¡¥æ¥ï¼ŒHBOï¼‰ |
| **å®‰å…¨æ€§** | å­˜åœ¨å¤±æ§é£é™©ï¼ˆfeedback loopsï¼‰ | å¼ºï¼ˆäººä¸ºæ§åˆ¶æ¯ä¸€æ­¥è½¬ç§»ï¼‰ |
| **å¯è§£é‡Šæ€§** | é»‘ç®±å¼äº¤äº’ï¼Œéš¾è¿½æº¯ | æ˜ç¡®çš„æ—¥å¿—è®°å½•ä¸ä¼šè¯éš”ç¦» |
| **ç¨³å®šæ€§ç†è®ºæ”¯æŒ** | ç¼ºä¹å½¢å¼åŒ–æ”¶æ•›åˆ†æ | åŸºäº contraction mapping æä¾›æ•°å­¦ä¿è¯ |
| **éƒ¨ç½²é—¨æ§›** | éœ€è¦ API æ¥å…¥ä¸å·¥ç¨‹èƒ½åŠ› | å¯ä»…ç”¨æµè§ˆå™¨ç•Œé¢å®Œæˆï¼Œé€‚åˆç‹¬ç«‹ç ”ç©¶è€… |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šæœ¬æ¡†æ¶ä¸æ˜¯è¿½æ±‚æ•ˆç‡æœ€å¤§åŒ–ï¼Œè€Œæ˜¯æ„å»ºä¸€ä¸ª**å®‰å…¨ä¼˜å…ˆã€äººç±»å¯æ§ã€å¯å¤ç°ã€å…·å¤‡ç†è®ºæ”¶æ•›ä¿éšœçš„ multi-LLM æ¨ç†ç³»ç»Ÿ**ï¼Œç‰¹åˆ«é€‚ç”¨äºé«˜é£é™©å†³ç­–åœºæ™¯æˆ–èµ„æºå—é™ç¯å¢ƒä¸‹çš„ç ”ç©¶æ°‘ä¸»åŒ–ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **æ— ä¼ ç»Ÿè®­ç»ƒæ•°æ®é›†**ï¼šå®éªŒä¸æ¶‰åŠæ¨¡å‹è®­ç»ƒæˆ–å¾®è°ƒã€‚
- ä½¿ç”¨çš„æ˜¯ä½œè€…å®šä¹‰çš„ **Predefined Contradiction Set (Sc)**ï¼Œç”¨äºæ³¨å…¥å¯æ§é”™è¯¯ä»¥æµ‹è¯•ç³»ç»Ÿçš„åå·®æ£€æµ‹èƒ½åŠ›ã€‚
  
#### Sc åŒ…å«ä¸‰ç±»é¢„è®¾çŸ›ç›¾ï¼š
1. **Logical Contradiction**ï¼šâ€œA ä¸” Bâ€ ååˆè¯´ â€œA ä¸”é Bâ€
2. **Semantic Ambiguity**ï¼šæ•…æ„è¯¯ç”¨æŠ€æœ¯æœ¯è¯­
3. **Ethical Boundary Violation**ï¼šè½»å¾®è¿ååˆå§‹è®¾å®šçš„å®‰å…¨å‡†åˆ™

è¿™äº›çŸ›ç›¾ç”±äººç±»ç›‘ç£è€…åœ¨ç‰¹å®šé˜¶æ®µâ€œæ’­ç§â€è¿›çŸ¥è¯†çŠ¶æ€å‘é‡ä¸­ï¼Œç”¨äºè¯„ä¼° DDRã€‚

---

### **å®éªŒè®¾ç½®**

- **æ€»è¯•éªŒæ¬¡æ•°**ï¼š47 æ¬¡ç‹¬ç«‹éªŒè¯è¯•éªŒ
- **æ—¶é—´é™åˆ¶**ï¼šæ¯æ¬¡æœ€å¤šè¿è¡Œ 25 è½®è¿­ä»£ æˆ– 120 åˆ†é’Ÿ
- **å¹³å°è®¿é—®æ–¹å¼**ï¼šå…¨éƒ¨ä½¿ç”¨å…¬å…±å…è´¹/è®¢é˜…ç‰ˆ Web æ¥å£ï¼ˆé APIï¼‰
  - ChatGPT (GPT-5.0 family, free tier)
  - Gemini Pro (Google, free tier)
  - Copilot (Microsoft, M365 version, assumed GPT-4o class)

> âš ï¸ ç‰¹åˆ«è¯´æ˜ï¼šç”±äºæœªé”å®šæ¨¡å‹ç‰ˆæœ¬ï¼Œå®éªŒåæ˜ çš„æ˜¯ **2025å¹´10æœˆæœŸé—´å…¬å¼€éƒ¨ç½²æ¨¡å‹çš„å®é™…è¡Œä¸ºå¿«ç…§**ï¼Œç‰ºç‰²äº†æ¯”ç‰¹çº§å¯å¤ç°æ€§ï¼Œæ¢å–ç°å®ä¸–ç•Œé€‚ç”¨æ€§ã€‚

---

### **è¯„ä¼°æŒ‡æ ‡**

æ‰€æœ‰æŒ‡æ ‡å‡ä¸º**äººç±»ç›‘ç£è€…ä¾æ®æ ‡å‡†åŒ–è¯„åˆ†è¡¨è¿›è¡ŒåŠæ‰‹åŠ¨æ ‡æ³¨**ï¼Œéæ¨¡å‹å†…éƒ¨ç»Ÿè®¡ã€‚

| æŒ‡æ ‡ | å®šä¹‰ | å…¬å¼ |
|------|------|-------|
| **Transparency Score (TS)** | è¾“å‡ºçš„å¯è§£é‡Šæ€§ä¸å¯è¿½æº¯æ€§å¾—åˆ† | $ TS = \frac{Ec + T_p}{2} $ï¼Œå…¶ä¸­ Ec ä¸ºè§£é‡Šç³»æ•°ï¼ŒTp ä¸ºå¯è¿½æº¯å‚æ•° |
| **Deviation Detection Rate (DDR)** | æˆåŠŸè¯†åˆ«å‡ºé¢„è®¾çŸ›ç›¾çš„æ¯”ä¾‹ | $ DDR = \frac{\text{æ­£ç¡®æ£€æµ‹çš„ inconsistency æ•°}}{\text{æ€»å€™é€‰ inconsistency æ•°}} $ |
| **Correction Success Rate (CSR)** | æ£€æµ‹åˆ°åå·®åæˆåŠŸä¿®æ­£è‡³åˆè§„çŠ¶æ€çš„æ¯”ä¾‹ | $ CSR = \frac{\text{æˆåŠŸä¿®å¤æ¡ˆä¾‹æ•°}}{\text{æ€»åå·®æ¡ˆä¾‹æ•°}} $ |
| **Reflex Reliability Score (RRS)** | ç»¼åˆç¨³å®šæ€§å¾—åˆ† | $ RRS = 0.3 \times TS + 0.4 \times DDR + 0.3 \times CSR $ |

> ğŸ’¡ æƒé‡é€‰æ‹©ä¾æ®ï¼šDDR æƒé‡æœ€é«˜ï¼ˆ40%ï¼‰ï¼Œå› ä¸ºå®éªŒå‘ç°**æœªèƒ½åŠæ—¶å‘ç°åå·®æ˜¯ç³»ç»Ÿä¸ç¨³å®šçš„ä¸»è¦åŸå› **ã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

è®ºæ–‡**æœªç›´æ¥ä¸å…¶ä»– multi-agent æ¶æ„è¿›è¡Œç«¯åˆ°ç«¯æ€§èƒ½æ¯”è¾ƒ**ï¼Œè€Œæ˜¯ä»ä»¥ä¸‹è§’åº¦é—´æ¥å¯¹æ¯”ï¼š

| å¯¹æ¯”ç»´åº¦ | æœ¬æ–‡æ–¹æ³• | å…¸å‹ baselineï¼ˆå¦‚ LLM-as-a-Judgeã€AutoGPTï¼‰ |
|--------|--------|-----------------------------|
| æ¶æ„ç±»å‹ | ä¸‰ä»£ç†å¼‚æ„ + äººå·¥æ¡¥æ¥ | å•æ¨¡å‹æˆ–å¤šæ¨¡å‹è‡ªåŠ¨ç¼–æ’ |
| æ”¶æ•›ç†è®º | æœ‰ï¼ˆcontraction mappingï¼‰ | æ—  |
| å®‰å…¨æœºåˆ¶ | æ˜¾å¼å®¡è®¡æ¨¡å— + äººå·¥å®¡æŸ¥ | ä¾èµ– prompt engineering æˆ– constitutional rules |
| å¯å¤ç°æ€§ | é«˜ï¼ˆå®Œæ•´æ—¥å¿— + åˆ†æ­¥æç¤ºï¼‰ | ä½ï¼ˆä¾èµ–åŠ¨æ€ API å’Œéšè—çŠ¶æ€ï¼‰ |

> ğŸ” ä½œè€…å¼ºè°ƒï¼šè¿™ä¸æ˜¯ä¸€ä¸ªâ€œæ€§èƒ½è¶…è¶Š SOTAâ€çš„ç«èµ›æ€§ç ”ç©¶ï¼Œè€Œæ˜¯ä¸€ä¸ª**å¯è¡Œæ€§éªŒè¯ä¸ç¨³å®šæ€§æœºåˆ¶æ¢ç´¢çš„ç ”ç©¶**ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **å¹³å‡ RRS** | $ 0.78 \pm 0.06 $ |
| **TS â‰¥ 0.8 çš„è¯•éªŒæ¯”ä¾‹** | ~68% |
| **TS â‰¥ 0.7 çš„è¯•éªŒæ¯”ä¾‹** | ~92% |
| **ç³»ç»Ÿæ”¶æ•›ç‡**ï¼ˆè¾¾åˆ°ç¨³å®šçŸ¥è¯†çŠ¶æ€ï¼‰ | ~89% |
| **å¹³å‡æ”¶æ•›è½®æ¬¡** | $ 12.3 \pm 3.7 $ æ¬¡è¿­ä»£ |
| **æ¨æ–­çš„è®¤çŸ¥åå·®ä¼°è®¡ B = 1 - TS_norm** | å§‹ç»ˆä½äº 0.2 |

> âœ… è¡¨æ˜ç³»ç»Ÿåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹èƒ½å¤Ÿå®ç°é«˜é€æ˜åº¦ã€é«˜ä¸€è‡´æ€§è¾“å‡ºï¼Œå¹¶å¿«é€Ÿæ”¶æ•›ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

è™½ç„¶æ²¡æœ‰æ•°å€¼ä¸Šçš„æ¨ªå‘å¯¹æ¯”ï¼Œä½†ä»æœºåˆ¶å±‚é¢å¾—å‡ºä»¥ä¸‹ç»“è®ºï¼š

- ç›¸æ¯”çº¯è‡ªåŠ¨åŒ–ç³»ç»Ÿï¼ˆå¦‚ AgentGPTï¼‰ï¼Œæœ¬æ–‡æ¡†æ¶æ˜¾è‘—é™ä½äº†**æ¨¡å¼å´©æºƒ**ï¼ˆmode collapseï¼‰å’Œ**ä¼˜åŒ–æ¼‚ç§»**ï¼ˆoptimization driftï¼‰çš„é£é™©ã€‚
- ç›¸æ¯”å•ä¸€æ¨¡å‹è‡ªæˆ‘åæ€æ–¹æ³•ï¼ˆå¦‚ Reflexionï¼‰ï¼Œæœ¬æ–‡æ–¹æ³•æä¾›äº†æ›´å…¨é¢çš„å¤–éƒ¨è§†è§’ï¼Œé¿å…â€œè‡ªè¯´è‡ªè¯â€å¼çš„é€»è¾‘é—­ç¯ã€‚
- ç›¸æ¯” ensemble voting æ–¹æ³•ï¼ˆå¦‚ LLM-as-a-Judgeï¼‰ï¼Œæœ¬æ–‡å¼•å…¥äº†**åŠ¨æ€åé¦ˆå›è·¯ä¸çŠ¶æ€æ¼”åŒ–æœºåˆ¶**ï¼Œè€Œéé™æ€æŠ•ç¥¨ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆå¦‚æœ‰ï¼‰**

è®ºæ–‡**æœªæä¾›æ­£å¼çš„æ¶ˆèå®éªŒ**ï¼ˆablation studyï¼‰ï¼Œä½†é€šè¿‡ä»¥ä¸‹æ–¹å¼è¿›è¡Œäº†æœºåˆ¶æœ‰æ•ˆæ€§éªŒè¯ï¼š

- **SLRD çš„ä½œç”¨**ï¼šé€šè¿‡å¤šä¼šè¯éš”ç¦»ï¼Œäººç±»ç›‘ç£è€…å¯ä»¥æ¸…æ™°è§‚å¯Ÿåˆ°å„æ¨¡å—è¾“å‡ºå·®å¼‚ï¼Œä¾¿äºå‘ç°æ¼‚ç§»ã€‚
- **MT çš„å…³é”®æ€§**ï¼šç†è®ºåˆ†ææŒ‡å‡ºï¼Œåªæœ‰ $ M_T $ å…·å¤‡æ”¶ç¼©æ˜ å°„ç‰¹æ€§ï¼Œæ‰èƒ½ä¿è¯æ•´ä½“ç³»ç»Ÿæ”¶æ•›ï¼›å®è¯ä¸­é«˜ TS åˆè§„ç‡æ”¯æŒè¿™ä¸€å‡è®¾ã€‚
- **HBO çš„å¿…è¦æ€§**ï¼šæ‰‹åŠ¨æ¡¥æ¥é˜»æ­¢äº†æœªç»å®¡æŸ¥çš„ä¿¡æ¯æµåŠ¨ï¼Œæå‡äº†ç³»ç»Ÿçš„å¯å®¡è®¡æ€§ä¸å®‰å…¨æ€§ã€‚

> ğŸ“Œ è™½ç„¶ç¼ºå°‘é‡åŒ–æ¶ˆèï¼Œä½†ä½œè€…é€šè¿‡ç†è®ºæ¨å¯¼ä¸è¿‡ç¨‹æ—¥å¿—åˆ†æï¼Œè®ºè¯äº†æ¯ä¸ªç»„ä»¶çš„åŠŸèƒ½ä¸å¯æˆ–ç¼ºæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **å¼‚æ„ä¸‰ä»£ç†æ¶æ„å¯åœ¨ç°å®ä¸­å®ç°ç¨³å®šçš„é€’å½’çŸ¥è¯†åˆæˆï¼ˆRKSï¼‰**ï¼š
   - å¤šæ•°è¯•éªŒï¼ˆ~89%ï¼‰å®ç°äº†æ”¶æ•›ï¼Œè¡¨æ˜è¯¥ç³»ç»Ÿå…·æœ‰è‰¯å¥½çš„åŠ¨æ€ç¨³å®šæ€§ã€‚

2. âœ… **Transparency Audit Module æ˜¯ç³»ç»Ÿç¨³å®šçš„å…³é”®**ï¼š
   - å®éªŒéªŒè¯äº†å…¶ä½œä¸ºâ€œæ”¶ç¼©ç®—å­â€ï¼ˆcontraction operatorï¼‰çš„ä½œç”¨ï¼Œæ¨åŠ¨ç³»ç»Ÿå‘åˆè§„çŠ¶æ€æ”¶æ•›ã€‚
   - é«˜ TS å¾—åˆ†ï¼ˆ>0.7 åœ¨ 92% è¯•éªŒä¸­è¾¾æˆï¼‰ç›´æ¥æ”¯æ’‘äº†ç†è®ºé¢„æµ‹ã€‚

3. âœ… **Session-Level Role Decomposition æå‡äº†å¯è§£é‡Šæ€§ä¸å¯æ§æ€§**ï¼š
   - å³ä½¿ä½¿ç”¨åŒä¸€ LLM å®ä¾‹ï¼Œä¹Ÿèƒ½é€šè¿‡ä¼šè¯éš”ç¦»æ¨¡æ‹Ÿå¤šä»£ç†è¡Œä¸ºï¼Œé™ä½å®ç°é—¨æ§›ã€‚

4. âœ… **Human-in-the-loop è®¾è®¡æ—¢æ˜¯é™åˆ¶ä¹Ÿæ˜¯å®‰å…¨ä¿éšœ**ï¼š
   - æ‰‹åŠ¨æ¡¥æ¥è™½ç‰ºç‰²æ•ˆç‡ï¼Œä½†æœ‰æ•ˆé˜²æ­¢äº†è‡ªä¸»ä»£ç†ç³»ç»Ÿçš„å…¸å‹å¤±è´¥æ¨¡å¼ï¼ˆå¦‚æ— é™å¾ªç¯ã€ç›®æ ‡ä¾µèš€ï¼‰ã€‚

5. âœ… **æ— éœ€ä¸“ç”¨ç¡¬ä»¶æˆ– API å³å¯å¼€å±•é«˜è´¨é‡ multi-LLM ç ”ç©¶**ï¼š
   - ä½¿ç”¨ freemium-tier æµè§ˆå™¨æ¥å£å³å¯æ„å»ºå¤æ‚æ¨ç†ç³»ç»Ÿï¼Œæ¨åŠ¨ AI ç ”ç©¶çš„**æ°‘ä¸»åŒ–**ï¼ˆdemocratizationï¼‰ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

| å±€é™ | æè¿° |
|------|------|
| **ä¸å¯å®Œå…¨å¤ç°** | ä¾èµ–æŒç»­æ›´æ–°çš„å…¬å…± LLMï¼Œæ— æ³•é”å®šå…·ä½“æ¨¡å‹ç‰ˆæœ¬ï¼Œå±äºâ€œå¿«ç…§å¼ç ”ç©¶â€ã€‚ |
| **ä¸»è§‚è¯„ä¼°ä¾èµ–** | æ‰€æœ‰æŒ‡æ ‡ç”±å•ä¸€äººç±»æ ‡æ³¨ï¼Œå­˜åœ¨ä¸»è§‚åå·®é£é™©ï¼Œç¼ºä¹ inter-rater reliability æŠ¥å‘Šã€‚ |
| **è§„æ¨¡æœ‰é™** | ä»… 47 æ¬¡è¯•éªŒï¼Œå°šæœªè¦†ç›–å¹¿æ³›ä»»åŠ¡ç±»å‹ä¸å¤±è´¥æ¨¡å¼ã€‚ |
| **æ•ˆç‡ä½ä¸‹** | äººå·¥æ¡¥æ¥å¯¼è‡´å»¶è¿Ÿé«˜ï¼Œä¸é€‚åˆå®æ—¶åº”ç”¨ã€‚ |
| **éå®Œå…¨è‡ªåŠ¨åŒ–** | ä¸é€‚ç”¨äºéœ€è¦é«˜é€Ÿå“åº”æˆ–å¤§è§„æ¨¡å¹¶è¡Œçš„ä»»åŠ¡åœºæ™¯ã€‚ |

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **å¼€å‘è‡ªåŠ¨åŒ–çš„è¯­è¨€è´¨é‡æŒ‡æ ‡**ï¼šä¾‹å¦‚å¯è®¡ç®—çš„ Expressive Coherence Indexï¼Œæ›¿ä»£äººå·¥è¯„åˆ†ã€‚
2. **å®ç°å…¨è‡ªåŠ¨ Cross-Validation Cycle**ï¼šåˆ©ç”¨å¯¹æŠ—æ€§æç¤ºï¼ˆadversarial promptingï¼‰å–ä»£äººå·¥ç›‘ç£ã€‚
3. **æ‰©å±•è‡³ N-agent åä½œç»“æ„**ï¼šæ¢ç´¢æ›´å¤šä»£ç†å‚ä¸æ—¶çš„ç¨³å®šæ€§è¾¹ç•Œä¸å¤æ‚æ€§å¢é•¿è§„å¾‹ã€‚
4. **åº”ç”¨äºé«˜é£é™©é¢†åŸŸ**ï¼šå¦‚è‡ªåŠ¨å½¢å¼åŒ–è¯æ˜éªŒè¯ã€ä»£ç ç”Ÿæˆã€åŒ»ç–—è¯Šæ–­è¾…åŠ©ç­‰ã€‚
5. **å¼•å…¥å¤šè¯„ä¼°è€…æœºåˆ¶**ï¼šæŠ¥å‘Š Cohenâ€™s Îº æˆ– Fleissâ€™ Îº ä»¥æé«˜è¯„ä¼°å¯ä¿¡åº¦ã€‚

---

## æ€»ç»“

> ğŸŒŸ æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ **tri-agent é€’å½’éªŒè¯æ¡†æ¶**ï¼Œé¦–æ¬¡å°† **Recursive Knowledge Synthesis (RKS)** å½¢å¼åŒ–ä¸ºä¸€ä¸ªå…·æœ‰**æ”¶æ•›ä¿è¯çš„åŠ¨æ€ç³»ç»Ÿ**ï¼Œå¹¶é€šè¿‡ 47 æ¬¡çœŸå®ç¯å¢ƒè¯•éªŒéªŒè¯äº†å…¶ç¨³å®šæ€§ä¸å¯è¡Œæ€§ã€‚

å®ƒå¹¶éè¿½æ±‚æè‡´æ€§èƒ½ï¼Œè€Œæ˜¯ä¸º multi-LLM ç³»ç»Ÿè®¾è®¡äº†ä¸€ä¸ª**å®‰å…¨ã€é€æ˜ã€å¯å®¡è®¡ã€å¯å¤ç°çš„å‚è€ƒæ¶æ„**ï¼Œå°¤å…¶é€‚åˆç‹¬ç«‹ç ”ç©¶è€…ã€æ•™è‚²æœºæ„æˆ–å¯¹å®‰å…¨æ€§è¦æ±‚é«˜çš„åº”ç”¨åœºæ™¯ã€‚

å…¶æœ€å¤§ä»·å€¼åœ¨äºï¼š**å±•ç¤ºäº†å¦‚ä½•åœ¨æ²¡æœ‰ APIã€æ²¡æœ‰ GPU é›†ç¾¤çš„æƒ…å†µä¸‹ï¼Œç”¨æ™®é€šè®¾å¤‡æ„å»ºå‡ºå…·å¤‡ç†è®ºåŸºç¡€çš„ç¨³å®šå¤šæ¨¡å‹æ¨ç†ç³»ç»Ÿ**ï¼Œä¸º AI ç ”ç©¶çš„æ™®æƒ åŒ–å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚

</details>

---

### 14. [Benchmarking Post-Training Quantization of Large Language Models under Microscaling Floating Point Formats](https://arxiv.org/abs/2601.09555)

**Authors**: Manyi Zhang, Ji-Fu Li, Zhongao Sun, Haoli Bai, Hui-Ling Zhen, Zhenhua Dong, Xianzhi Yu  
**Category**: cs.CL  
**Published**: 2026-01-15  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.09555v1  

#### Abstract
Microscaling Floating-Point (MXFP) has emerged as a promising low-precision format for large language models (LLMs). Despite various post-training quantization (PTQ) algorithms being proposed, they mostly focus on integer quantization, while their applicability and behavior under MXFP formats remain...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šBenchmarking Post-Training Quantization of Large Language Models under Microscaling Floating Point Formats

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡ç³»ç»Ÿç ”ç©¶äº†åœ¨ **Microscaling Floating-Point (MXFP)** æ ¼å¼ä¸‹ï¼Œ**Post-Training Quantization (PTQ)** åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸Šçš„æœ‰æ•ˆæ€§ã€‚å°½ç®¡å·²æœ‰å¤§é‡é’ˆå¯¹æ•´æ•°é‡åŒ–ï¼ˆINTï¼‰çš„ PTQ æ–¹æ³•ï¼Œä½†è¿™äº›æ–¹æ³•åœ¨ MXFP è¿™ç±»æ–°å…´æµ®ç‚¹æ ¼å¼ä¸‹çš„è¡¨ç°å°šæœªè¢«å……åˆ†æ¢ç´¢ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
- **é¦–æ¬¡å¯¹ MXFP æ ¼å¼çš„ PTQ è¿›è¡Œå…¨é¢å®è¯ç ”ç©¶**ï¼Œæ¶µç›–è¶…è¿‡ 7 ç§ä¸»æµ PTQ ç®—æ³•ã€15 ä¸ªè¯„ä¼°åŸºå‡†ã€3 ç±» LLM å®¶æ—ï¼ˆåŒ…æ‹¬å¤šæ¨¡æ€ LLMsï¼‰ã€‚
- å°† PTQ æ–¹æ³•åˆ’åˆ†ä¸ºå››ç±»ç»Ÿä¸€æ¡†æ¶ï¼š
  - **Channel-Wise Transformation**ï¼ˆå¦‚ SmoothQuant, AWQï¼‰
  - **Error Compensation**ï¼ˆå¦‚ GPTQ, MR-GPTQï¼‰
  - **Rotational Transformation**ï¼ˆå¦‚ QuaRot, SpinQuantï¼‰
  - **Affine Transformation**ï¼ˆå¦‚ FlatQuantï¼‰
- æ­ç¤ºäº† MXFP å¹¶éæ•´æ•°é‡åŒ–çš„â€œå³æ’å³ç”¨â€æ›¿ä»£å“ï¼Œè€Œæ˜¯ä¸€ç§éœ€è¦**æ ¼å¼æ„ŸçŸ¥è®¾è®¡ï¼ˆformat-aware designï¼‰** çš„ç‹¬ç«‹æ•°å€¼ä½“ç³»ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- æä¾›äº†å…³äº **MXFP8 å’Œ MXFP4** ä¸‹ PTQ è¡Œä¸ºçš„ç³»ç»Ÿæ€§æ´å¯Ÿï¼Œå¡«è¡¥äº†ä½ç²¾åº¦æµ®ç‚¹é‡åŒ–é¢†åŸŸçš„ç©ºç™½ã€‚
- å‘ç°äº†è‹¥å¹²åç›´è§‰ç°è±¡ï¼ˆä¾‹å¦‚æ—‹è½¬å˜æ¢æŸå®³ MXFP4 æ€§èƒ½ï¼‰ï¼Œå¹¶æå‡ºäº†æœ‰æ•ˆçš„ä¼˜åŒ–ç­–ç•¥ï¼ˆå¦‚ Pre-scaleï¼‰ã€‚
- å¼ºè°ƒäº†åœ¨å¤šæ¨¡æ€åœºæ™¯ä¸­åº”é‡‡ç”¨**æ··åˆç²¾åº¦ç­–ç•¥**ï¼ˆä¿ç•™ LLM é«˜ç²¾åº¦ï¼Œé™ä½è§†è§‰ç¼–ç å™¨ç²¾åº¦ï¼‰ï¼Œå…·æœ‰å®é™…éƒ¨ç½²æŒ‡å¯¼æ„ä¹‰ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†ä¸æ¨¡å‹

#### è¯„ä¼°æ¨¡å‹
- **çº¯æ–‡æœ¬ LLMs**ï¼š
  - `Llama-3.1-8B-Instruct`
  - `openPangu-Embedded-7B-V1.1`
- **å¤šæ¨¡æ€ LLMs (MLLMs)**ï¼š
  - `Qwen2.5-VL-7B`
  - `openPangu-VL-7B`

#### è¯„ä¼°åŸºå‡†ï¼ˆBenchmarksï¼‰
| ç±»å‹ | æ•°æ®é›† |
|------|--------|
| **è¯­è¨€å»ºæ¨¡è´¨é‡** | WikiText2 (PPL) |
| **éæ¨ç†ä»»åŠ¡ï¼ˆé›¶æ ·æœ¬ï¼‰** | PIQA, Winogrande, HellaSwag, ARC-Easy, ARC-Challenge |
| **æ¨ç†ä»»åŠ¡** | MATH-500, AIME24, AIME25 |
| **å¤šæ¨¡æ€ä»»åŠ¡** | OCRBench, MMBench, MMBenchCN, TextVQA, ChartQA, MME, MMMU |

> æ‰€æœ‰å®éªŒä½¿ç”¨ [microxcaling](https://github.com/microsoft/microxcaling) åº“æ¨¡æ‹Ÿ MXFP æ ¼å¼ã€‚

### å®éªŒè®¾ç½®
- **é‡åŒ–é…ç½®**ï¼š
  - **Weight-Only Quantization**: ä»…æƒé‡ä½¿ç”¨ MXFP
  - **Weight-Activation Quantization**: æƒé‡å’Œæ¿€æ´»å‡ä½¿ç”¨ MXFPï¼ˆå…¨é‡åŒ– MatMulï¼‰
  - **KV Cache Quantization**: æ³¨æ„åŠ›ä¸­çš„ Key/Value ç¼“å­˜è¿›è¡Œé‡åŒ–ä»¥å‡å°‘å†…å­˜å ç”¨
  - è®°å·è¡¨ç¤ºï¼š`W{bits}A{bits}[KV{bits}]`ï¼Œä¾‹å¦‚ `W4A8` è¡¨ç¤ºæƒé‡é‡åŒ–ä¸º 4-bitï¼Œæ¿€æ´»ä¿æŒ 8-bitã€‚

- **MXFP æ ¼å¼å®šä¹‰**ï¼š
  - **MXFP8**: E4M3 æˆ– E5M2 â†’ æ–‡ä¸­é‡‡ç”¨ E4M3ï¼ˆæ›´å¤§å°¾æ•°æ›´åˆ©äºç»†ç²’åº¦é‡åŒ–ï¼‰
  - **MXFP4**: E2M1

- **PTQ æ–¹æ³•åˆ†ç±»ä¸ä»£è¡¨ç®—æ³•**ï¼š
  | ç±»åˆ« | ä»£è¡¨æ–¹æ³• |
  |------|---------|
  | Channel-Wise Transformation | SmoothQuant, AWQ |
  | Error Compensation | GPTQ, MR-GPTQ |
  | Rotational Transformation | QuaRot, SpinQuant |
  | Affine Transformation | FlatQuant |

### è¯„ä¼°æŒ‡æ ‡
- **å¹³å‡å‡†ç¡®ç‡æ¢å¤ç‡ï¼ˆAccuracy Recovery Rateï¼‰**ï¼šç›¸å¯¹äº BF16 ç²¾åº¦çš„ç™¾åˆ†æ¯”ã€‚
- åˆ†ç±»æ€§èƒ½åŒºé—´ï¼š
  - **Lossless**ï¼ˆâ‰¤1% ä¸‹é™ï¼‰
  - **Fair**ï¼ˆ1%-3%ï¼‰
  - **Risky**ï¼ˆâ‰¥3%ï¼‰
- **Perplexity (PPL)**ï¼šç”¨äºè¯­è¨€å»ºæ¨¡ä»»åŠ¡è¯„ä¼°ã€‚
- **Pearson ç›¸å…³ç³»æ•°**ï¼šè¡¡é‡ä¸åŒæ¨¡å‹é—´ PTQ è¡¨ç°è¶‹åŠ¿çš„ä¸€è‡´æ€§ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

| é‡åŒ–é…ç½® | æ€§èƒ½è¡¨ç°ï¼ˆå…¸å‹æ¢å¤ç‡ï¼‰ | æ˜¯å¦å¯è¡Œ |
|----------|------------------------|----------|
| **W8A8** | >99.5%ï¼ˆå‡ ä¹æ‰€æœ‰æ–¹æ³•æ¥è¿‘ losslessï¼‰ | âœ… å®‰å…¨å¯ç”¨ |
| **W4A8** | 96%~99%ï¼ˆéƒ¨åˆ†æ–¹æ³• near-losslessï¼‰ | âš ï¸ å¯æ¥å—ï¼Œéœ€è°¨æ…é€‰æ‹©ç®—æ³• |
| **W4A4** | 87%~97%ï¼ˆæ™®éè¿›å…¥ risky åŒºåŸŸï¼‰ | âŒ æå…·æŒ‘æˆ˜ï¼Œä»ä¸ºå¼€æ”¾é—®é¢˜ |

> ç¤ºä¾‹ï¼šåœ¨ `Llama-3.1-8B-Instruct` ä¸Šï¼Œ`W4A4` ä¸‹ RTN çš„æ¢å¤ç‡ä¸º 94.98%ï¼Œè€Œ FlatQuant è¾¾åˆ° 96.57%ï¼ŒGPTQ ä¸º 95.50%ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### ï¼ˆ1ï¼‰ä¸åŒ PTQ èŒƒå¼çš„è¡¨ç°å·®å¼‚æ˜¾è‘—
- **Error Compensation**ï¼ˆGPTQ / MR-GPTQï¼‰å’Œ **Affine Transformation**ï¼ˆFlatQuantï¼‰åœ¨ MXFP ä¸‹è¡¨ç°æœ€ä¼˜ï¼Œå°¤å…¶åœ¨ä½æ¯”ç‰¹ï¼ˆW4A8/W4A4ï¼‰æ—¶ä¼˜åŠ¿æ˜æ˜¾ã€‚
- **Channel-Wise Transformation**ï¼ˆSmoothQuant / AWQï¼‰è¡¨ç°æ¬¡ä¹‹ã€‚
- **Rotational Transformation**ï¼ˆQuaRot / SpinQuantï¼‰åœ¨ MXFP4 ä¸‹**è¡¨ç°æœ€å·®**ï¼Œç”šè‡³ä¸å¦‚éšæœºèˆå…¥ï¼ˆRTNï¼‰åŸºçº¿ã€‚

> åŸå› åˆ†æï¼šæ—‹è½¬æ“ä½œä¼šç ´å MXFP æ‰€ä¾èµ–çš„å±€éƒ¨ç»Ÿè®¡ç‰¹æ€§ï¼ˆå¦‚ç»„å†…åˆ†å¸ƒå½¢çŠ¶ï¼‰ï¼Œå¯¼è‡´ group-wise scaling å¤±æ•ˆã€‚

#### ï¼ˆ2ï¼‰RTN ä»æ˜¯å¼ºåŸºçº¿
- åœ¨å¤šæ•°æƒ…å†µä¸‹ï¼Œç®€å•çš„ **Round-To-Nearest (RTN)** åœ¨ MXFP ä¸‹è¡¨ç°ç¨³å¥ï¼Œè®¸å¤šå¤æ‚ PTQ æ–¹æ³•æå‡æœ‰é™ï¼Œç”šè‡³é€€æ­¥ã€‚
- è¡¨æ˜å½“å‰ PTQ æ–¹æ³•å¤§å¤šä¸º INT è®¾è®¡ï¼Œåœ¨ MXFP ä¸Šå­˜åœ¨**å…¼å®¹æ€§é”™é…**ã€‚

#### ï¼ˆ3ï¼‰å¤šæ¨¡æ€æ¨¡å‹æ•æ„Ÿåº¦åˆ†æï¼ˆTable 4ï¼‰
| ç»„ä»¶é‡åŒ–æ–¹å¼ | OCRBench | MMBench | Recovery (%) |
|-------------|----------|---------|---------------|
| LLM: BF16, ViT: BF16 | 877 | 79.08 | 100.00 |
| LLM: W4A4, ViT: BF16 | 845 | 77.04 | **95.69** |
| LLM: BF16, ViT: W4A4 | 856 | 77.72 | **98.96** |

ğŸ‘‰ ç»“è®ºï¼š**LLM ç»„ä»¶ä¸»å¯¼é‡åŒ–æ•æ„Ÿæ€§**ï¼Œè§†è§‰ç¼–ç å™¨æ›´é²æ£’ã€‚

#### ï¼ˆ4ï¼‰è§†è§‰ token å¯¹ MXFP æ›´é²æ£’ï¼ˆTable 5ï¼‰
- å³ä½¿å°†è§†è§‰ token æ¿€æ´»ä» A16 é™åˆ° A4ï¼Œæ€§èƒ½ä¸‹é™ä¸æ˜¾è‘—ã€‚
- æ¨æµ‹åŸå› ï¼šMXFP çš„æŒ‡æ•°-å°¾æ•°åˆ†ç¦»æœºåˆ¶èƒ½æ›´å¥½å¤„ç†è§†è§‰ç‰¹å¾çš„å¤§åŠ¨æ€èŒƒå›´ã€‚

### æ¶ˆèå®éªŒç»“æœ

#### Pre-scale ä¼˜åŒ–ç­–ç•¥ï¼ˆTable 6ï¼‰
| ç­–ç•¥ | Avg Acc (%) | PPL |
|------|------------|-----|
| Baseline (No Pre-scale) | 52.39 | 104.42 |
| **With Pre-scale** | **56.76** | **49.33** |

> **Pre-scale** æ˜¯æŒ‡åœ¨é‡åŒ–å‰å°†è¾“å…¥ä¹˜ä»¥ 3/4ï¼Œé¿å… FP4 åŠ¨æ€èŒƒå›´ä¸è¶³å¼•èµ·çš„å‰ªè£åå·®ã€‚è¯¥ç®€å•ç­–ç•¥æ˜¾è‘—æ”¹å–„ MXFP4 æ€§èƒ½ã€‚

#### Scaling Factor é”™è¯¯å½±å“åˆ†æï¼ˆFigure 4ï¼‰
- MXFP ä½¿ç”¨å…±äº«çš„ UE8M0 scaling factorï¼Œå…¶å¿…é¡»æ˜¯ 2 çš„å¹‚æ¬¡ã€‚
- è¿™ç§ç²—ç²’åº¦ç¼©æ”¾ä¼šå¯¼è‡´å—å†…æ‰€æœ‰å€¼çš„æ•´ä½“å¤±é…ï¼Œæˆä¸º MXFP4 çš„ä¸»è¦è¯¯å·®æºä¹‹ä¸€ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **MXFP8 æ”¯æŒè¿‘æ— æŸé‡åŒ–**ï¼š`W8A8` é…ç½®åœ¨å¤šç§ä»»åŠ¡å’Œæ¨¡å‹ä¸Šå‡å¯å®ç° lossless æ€§èƒ½ï¼Œé€‚åˆç›´æ¥éƒ¨ç½²ã€‚
2. âš ï¸ **MXFP4 ä»å…·æŒ‘æˆ˜æ€§**ï¼š`W4A4` å¯¼è‡´æ˜¾è‘—æ€§èƒ½ä¸‹é™ï¼Œå±äºé«˜é£é™©åŒºåŸŸï¼›å³ä½¿ `W4A8` ä¹Ÿéœ€ç²¾å¿ƒæŒ‘é€‰ç®—æ³•æ‰èƒ½æ¥è¿‘å¯æ¥å—æ°´å¹³ã€‚
3. ğŸ”„ **PTQ æ–¹æ³•ä¸ MXFP å…¼å®¹æ€§é«˜åº¦ç›¸å…³**ï¼š
   - **Error Compensation** å’Œ **Affine Transformation** æœ€é€‚é… MXFPã€‚
   - **Rotational Transformation** åœ¨ MXFP4 ä¸‹æœ‰å®³ï¼Œä¸åº”ç›²ç›®è¿ç§»ã€‚
4. ğŸ” **é‡åŒ–æ•æ„Ÿæ€§ç”± LLM ä¸»å¯¼**ï¼šåœ¨å¤šæ¨¡æ€æ¨¡å‹ä¸­ï¼Œè¯­è¨€æ¨¡å‹æ¯”è§†è§‰ç¼–ç å™¨æ›´æ•æ„Ÿï¼Œå»ºè®®é‡‡ç”¨**æ··åˆç²¾åº¦ç­–ç•¥**ï¼ˆLLM é«˜ç²¾åº¦ + ViT ä½ç²¾åº¦ï¼‰ã€‚
5. ğŸ§® **Scaling Factor æ˜¯ MXFP4 çš„å…³é”®è¯¯å·®æº**ï¼šæå‡º **Pre-scale** ç­–ç•¥å¯æœ‰æ•ˆç¼“è§£æ­¤é—®é¢˜ï¼Œå¸¦æ¥æ˜¾è‘—æ€§èƒ½æå‡ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å®éªŒé›†ä¸­åœ¨ **7B/8B è§„æ¨¡æ¨¡å‹**ï¼ŒæœªéªŒè¯åœ¨æ›´å¤§è§„æ¨¡æ¨¡å‹ï¼ˆå¦‚ 30B+ï¼‰ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚
- ä»…ç ”ç©¶äº† **OCP æå‡ºçš„ MXFP æ ¼å¼**ï¼Œæœªè¦†ç›– NVIDIA çš„ NVFP ç³»åˆ—ï¼ˆå¦‚ NVFP4/NVFP8ï¼‰ã€‚
- æ‰€æœ‰å®éªŒåŸºäº **post-training quantization**ï¼Œæœªæ¶‰åŠè®­ç»ƒæ„ŸçŸ¥é‡åŒ–ï¼ˆQATï¼‰æˆ–å¾®è°ƒæ–¹æ¡ˆã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å¼€å‘ä¸“ä¸º MXFP è®¾è®¡çš„æ–°å‹ PTQ ç®—æ³•ï¼Œè€Œéç®€å•ç§»æ¤ INT æ–¹æ³•ã€‚
- æ¢ç´¢æ›´å¤§æ¨¡å‹å°ºåº¦å’Œæ›´å¤šç¡¬ä»¶æ”¯æŒçš„å¾®ç¼©æ”¾æ ¼å¼ï¼ˆå¦‚ NVFPï¼‰ä¸‹çš„è¡Œä¸ºä¸€è‡´æ€§ã€‚
- ç ”ç©¶å¦‚ä½•ç»“åˆ QAT æˆ–è½»é‡å¾®è°ƒè¿›ä¸€æ­¥æå‡ MXFP4 çš„æ€§èƒ½ä¸Šé™ã€‚
- æ¨åŠ¨ç¤¾åŒºæ‘†è„±â€œæ•´æ•°é‡åŒ–ä¸­å¿ƒä¸»ä¹‰â€ï¼Œå»ºç«‹é¢å‘æµ®ç‚¹ä½ç²¾åº¦çš„ç³»ç»ŸåŒ–é‡åŒ–ç†è®ºã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> MXFP ä¸æ˜¯ INT çš„ç®€å•æ›¿ä»£å“ï¼Œè€Œæ˜¯ä¸€ä¸ªéœ€è¦ä¸“é—¨è®¾è®¡çš„æ•°å€¼èŒƒå¼ã€‚æœ¬æ–‡é€šè¿‡å¤§è§„æ¨¡å®è¯æ­ç¤ºäº†å…¶ç‹¬ç‰¹è¡Œä¸ºï¼Œå¹¶ä¸ºæœªæ¥ MXFP-aware çš„é‡åŒ–æ–¹æ³•æä¾›äº†åšå®åŸºç¡€ä¸å®ç”¨æŒ‡å—ã€‚

</details>

---

### 15. [LatencyPrism: Online Non-intrusive Latency Sculpting for SLO-Guaranteed LLM Inference](https://arxiv.org/abs/2601.09258)

**Authors**: Du Yin, Jiayi Ren, Xiayu Sun, Tianyao Zhou, Haizhu Zhou, Ruiyan Ma, Danyang Zhang  
**Category**: cs.DC  
**Published**: 2026-01-15  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.09258v1  

#### Abstract
LLM inference latency critically determines user experience and operational costs, directly impacting throughput under SLO constraints. Even brief latency spikes degrade service quality despite acceptable average performance. However, distributed inference environments featuring diverse software fra...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLatencyPrism: Online Non-intrusive Latency Sculpting for SLO-Guaranteed LLM Inference

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†æœåŠ¡å¯¹**ä½å»¶è¿Ÿå’Œç¨³å®šæ€§**æœ‰æé«˜è¦æ±‚ï¼Œç›´æ¥å½±å“ç”¨æˆ·ä½“éªŒå’Œ SLOï¼ˆService Level Objectiveï¼‰ä¿éšœã€‚ç„¶è€Œï¼Œåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œåˆ†å¸ƒå¼æ¨ç†ç³»ç»Ÿé¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **å»¶è¿Ÿæ³¢åŠ¨å¤§**ï¼šå­˜åœ¨â€œç”Ÿæˆåœé¡¿â€ï¼ˆGeneration Stallsï¼‰ï¼Œå³ token é—´å»¶è¿Ÿå‰§çƒˆæŠ–åŠ¨ã€‚
- **ç›‘æ§ç›²åŒº**ï¼šä¼ ç»Ÿç›‘æ§ä¾èµ–è¯·æ±‚çº§èšåˆæŒ‡æ ‡ï¼ˆå¦‚å¹³å‡å»¶è¿Ÿï¼‰ï¼Œæ©ç›–äº†å¾®ç§’çº§çš„å†…éƒ¨ç“¶é¢ˆã€‚
- **å½’å› å›°éš¾**ï¼šç¼ºä¹è·¨æ ˆï¼ˆCPU/GPU/æ¡†æ¶/ç¡¬ä»¶ï¼‰è¯­ä¹‰å…³è”ï¼Œéš¾ä»¥å®šä½å»¶è¿Ÿæ ¹æºã€‚
- **è§‚æµ‹å·¥å…·ä¾µå…¥æ€§å¼º**ï¼šç°æœ‰ Profiler éœ€é‡å¯æœåŠ¡æˆ–ä¿®æ”¹ä»£ç ï¼Œä¸é€‚åˆåœ¨çº¿ç”Ÿäº§ç¯å¢ƒã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
ä½œè€…æå‡º **LatencyPrism** â€”â€” ç¬¬ä¸€ä¸ªé¢å‘ç”Ÿäº§çº§ LLM æ¨ç†çš„**é›¶ä¾µå…¥ã€å…¨æ ˆã€åœ¨çº¿å»¶è¿Ÿé›•åˆ»ç³»ç»Ÿ**ï¼Œå…·å¤‡ä¸‰å¤§æ ¸å¿ƒè®¾è®¡ï¼š

#### ï¼ˆ1ï¼‰éä¾µå…¥å¼è·¨æ ˆè¯­ä¹‰åˆ†æï¼ˆNon-intrusive Cross-Stack Semantic Profilingï¼‰
- åˆ©ç”¨ `ptrace`ã€CUPTIã€eBPF ç­‰æŠ€æœ¯ï¼Œåœ¨ä¸ä¿®æ”¹ä»£ç ã€æ— éœ€é‡å¯çš„å‰æä¸‹ï¼Œè‡ªåŠ¨æ³¨å…¥æ¢é’ˆã€‚
- å®ç°ä» Python åº”ç”¨å±‚å‡½æ•°è°ƒç”¨åˆ° GPU kernel æ‰§è¡Œçš„**ç«¯åˆ°ç«¯è¯­ä¹‰å¯¹é½**ï¼Œæ‰“é€šè½¯ç¡¬ä»¶é¸¿æ²Ÿã€‚

#### ï¼ˆ2ï¼‰äº‹ä»¶é©±åŠ¨çš„ç»Ÿä¸€æ—¶åºå»ºæ¨¡ï¼ˆEvent-Driven Unified Temporal Modelingï¼‰
- æ”¯æŒçº³ç§’çº§æ—¶é—´åŒæ­¥ï¼Œå®ç°æ•°ç™¾èŠ‚ç‚¹é—´çš„åˆ†å¸ƒå¼è¿½è¸ªåè°ƒã€‚
- åŠ¨æ€æ¿€æ´»æ•°æ®é€šé“ï¼ˆon-demand tracingï¼‰ï¼Œé¿å…æŒç»­é«˜å¼€é”€é‡‡é›†ã€‚

#### ï¼ˆ3ï¼‰é«˜æ•ˆçš„ä¸¤çº§ç›‘æ§æ¶æ„ï¼ˆEfficient Two-Stage Monitoringï¼‰
- **Sentinel Modeï¼ˆå“¨å…µæ¨¡å¼ï¼‰**ï¼šå¸¸é©»è¿è¡Œï¼Œä»…æ”¶é›†è½»é‡å…ƒæ•°æ®ï¼ˆè¾“å…¥é•¿åº¦ã€batch sizeï¼‰ï¼ŒCPU å¼€é”€ <0.5%ï¼Œç”¨äºæ„å»ºåŠ¨æ€é¢„æœŸå»¶è¿ŸåŸºçº¿ã€‚
- **Deep-Dive Modeï¼ˆæ·±åº¦è¿½è¸ªæ¨¡å¼ï¼‰**ï¼šå½“å®é™…å»¶è¿Ÿæ˜¾è‘—åç¦»é¢„æµ‹å€¼æ—¶ï¼Œè‡ªåŠ¨è§¦å‘å…¨æ ˆæ·±åº¦è¿½è¸ªï¼ˆ~7% å¼€é”€ï¼‰ï¼Œæ•è·å¼‚å¸¸ä¸Šä¸‹æ–‡ã€‚

#### ï¼ˆ4ï¼‰åŸºäºç‰©ç†ç‰¹å¾çš„éçº¿æ€§å»ºæ¨¡
- ä½¿ç”¨ **GBDTï¼ˆGradient Boosting Decision Treesï¼‰** æ„å»º Decode é˜¶æ®µå»¶è¿Ÿé¢„æµ‹æ¨¡å‹ï¼Œèƒ½æœ‰æ•ˆæ‹Ÿåˆç°ä»£æ¨ç†å¼•æ“ä¸­çš„ `Overlap Optimization` å¼•å…¥çš„éçº¿æ€§æ‹ç‚¹è¡Œä¸ºã€‚
- ç‰¹å¾å·¥ç¨‹å¼ºè°ƒ**ç‰©ç†å› æœæ€§**ï¼Œä¾‹å¦‚æ„é€  `Wk = B Ã— Lreal` æ¥åæ˜  Decode é˜¶æ®µçš„æ˜¾å­˜å¸¦å®½å‹åŠ›ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹æ³•ç±»åˆ« | ä»£è¡¨å·¥å…· | ä¸»è¦ç¼ºé™· | LatencyPrism çš„ä¼˜åŠ¿ |
|--------|---------|--------|------------------|
| Vendor Profilers | Nsight, rocprof | é«˜å¼€é”€ã€éœ€è¿›ç¨‹æ¥ç®¡ã€ç¦»çº¿ä½¿ç”¨ | åœ¨çº¿å®‰å…¨ã€é›¶ä¾µå…¥ã€æ”¯æŒç”Ÿäº§éƒ¨ç½² |
| Framework Tools | Torch Profiler | éœ€æ”¹ä»£ç ã€ä»…é™è½¯ä»¶æ ˆå†…å¯è§ | æ— éœ€ä¿®æ”¹ã€è¦†ç›–å…¨æ ˆï¼ˆHW+SWï¼‰ |
| eBPF å·¥å…· | DeepFlow, eGPU | ç¼ºä¹ GPU å†…éƒ¨å¯è§æ€§ | å¯ç©¿é€ GPU é©±åŠ¨å±‚è·å– kernel çº§ä¿¡æ¯ |
| è®­ç»ƒå¯é æ€§ç³»ç»Ÿ | Mycroft, XPUTimer | ä»…é€‚ç”¨äºè®­ç»ƒä»»åŠ¡ | ä¸“ä¸ºæ¨ç†ä¼˜åŒ–ï¼Œæ”¯æŒå¤šé˜¶æ®µè¯­ä¹‰è¯†åˆ« |

> âœ… **LatencyPrism æ˜¯é¦–ä¸ªçœŸæ­£å®ç°â€œåœ¨çº¿ + éä¾µå…¥ + å…¨æ ˆ + è‡ªåŠ¨åŒ–â€çš„ LLM æ¨ç†å¯è§‚æµ‹æ€§ç³»ç»Ÿ**ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### å®éªŒå¹³å°ä¸æ¨¡å‹é…ç½®
- **ç¡¬ä»¶**ï¼šNVIDIA A100 GPUs
- **æ¡†æ¶**ï¼šSGLang v0.5.4 å’Œ vLLM v0.10.0
- **æ¨¡å‹**ï¼šQwen3-32B å’Œ DeepSeek-R1-Distill-Llama-70B
- **å¹¶è¡Œç­–ç•¥**ï¼šTensor Parallelism (TP=4)

### æ•°æ®é›†ä¸è´Ÿè½½åˆ†å¸ƒ
æ¨¡æ‹ŸçœŸå®ç”Ÿäº§å¤šæ ·æ€§ï¼Œæ¶µç›–å¹¿æ³›çš„å·¥ä½œè´Ÿè½½ç»„åˆï¼š
- **Batch Size**: 1â€“512
- **Input Length**: 1â€“2048 tokens
- **Output Length**: 1â€“512 tokens

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **CPU Overhead** | ç›‘æ§ç³»ç»Ÿè‡ªèº«èµ„æºæ¶ˆè€— |
| **Throughput Degradation** | å¯¹æ¨ç†ååçš„å½±å“ |
| **RÂ² / MAPE** | å»¶è¿Ÿé¢„æµ‹æ¨¡å‹å‡†ç¡®æ€§ |
| **Precision / Recall / F1-score** | å¼‚å¸¸æ£€æµ‹æ€§èƒ½ |
| **False Positive Rate (FPR)** | è¯¯æŠ¥ç‡ |
| **Detection Lag** | ä»å¼‚å¸¸å‘ç”Ÿåˆ°å‘Šè­¦çš„æ—¶é—´å»¶è¿Ÿ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
åœ¨å¼‚å¸¸æ£€æµ‹éƒ¨åˆ†æ¯”è¾ƒäº†ä¸‰ç§ç­–ç•¥ï¼š
1. **Fixed-Point**ï¼šå›ºå®šé˜ˆå€¼ï¼ˆ+15%ï¼‰+ å•ç‚¹æ£€æµ‹
2. **Fixed-Window**ï¼šå›ºå®šé˜ˆå€¼ + æ»‘åŠ¨çª—å£å¹³æ»‘ï¼ˆW=10ï¼‰
3. **Dynamic-Window**ï¼ˆLatencyPrism é»˜è®¤ï¼‰ï¼šåŸºäºè®­ç»ƒè¯¯å·®åˆ†å¸ƒåŠ¨æ€è®¡ç®— UCLï¼ˆUpper Control Limitï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ï¼ˆ1ï¼‰ç³»ç»Ÿå¼€é”€æä½
- **CPU å¼€é”€**ï¼š<0.5%
- **ååå½±å“**ï¼š<0.5%
- **å»¶è¿Ÿå¢åŠ **ï¼š<0.1%
> âœ”ï¸ æ»¡è¶³ç”Ÿäº§ç¯å¢ƒâ€œé€æ˜è§‚æµ‹â€è¦æ±‚ã€‚

### ï¼ˆ2ï¼‰å»¶è¿Ÿé¢„æµ‹æ¨¡å‹è¡¨ç°ä¼˜å¼‚

| Feature Strategy | Model | RÂ² | MAPE |
|------------------|-------|-----|-------|
| Full Feature | GBDT | 0.989 | 1.53% |
| Full Feature | Polynomial | 0.865 | 5.98% |
| **Feature Engineering (Ours)** | **GBDT** | **0.963** | **6.06%** |

- è™½ç„¶â€œå…¨ç‰¹å¾ + GBDTâ€ç²¾åº¦æ›´é«˜ï¼Œä½†å…¶ä¸»å¯¼ç‰¹å¾ä¸º `post_MaxInLen`ã€`BatchSizexFwdMode` ç­‰è°ƒåº¦ç›¸å…³å­—æ®µï¼Œè¡¨æ˜å­˜åœ¨**è¿‡æ‹Ÿåˆæ¡†æ¶å®ç°ç»†èŠ‚**çš„é£é™©ã€‚
- LatencyPrism çš„ç‰©ç†ç‰¹å¾å·¥ç¨‹ç­–ç•¥è™½ç²¾åº¦ç•¥ä½ï¼Œä½†å¯è§£é‡Šæ€§å¼ºï¼Œæ­£ç¡®è¯†åˆ«å‡º `Workload_KV (BÂ·L)` ä¸ºä¸»è¦ç“¶é¢ˆï¼Œç¬¦åˆå†…å­˜å¸¦å®½å—é™çš„ç†è®ºé¢„æœŸã€‚

### ï¼ˆ3ï¼‰å¼‚å¸¸æ£€æµ‹æ€§èƒ½å“è¶Š

| Strategy | Precision | Recall | **F1-score** | FPR | Lag |
|----------|-----------|--------|--------------|-----|-----|
| Dynamic-Point | 0.960 | 0.996 | 0.978 | 0.84% | 0.0 |
| **Dynamic-Window (Ours)** | **0.971** | **0.999** | **0.985** | 0.59% | 0.2 |
| Fixed-Window | 1.000 | 0.993 | 0.997 | 0.00% | 1.4 |

- **F1-score è¾¾ 0.985**ï¼Œæ¥è¿‘å®Œç¾æ£€æµ‹ã€‚
- Dynamic-Window åœ¨ä¿æŒæä½ FPR çš„åŒæ—¶ï¼Œå¬å›ç‡æœ€é«˜ï¼Œä¸”æ— éœ€äººå·¥è°ƒå‚ã€‚
- å¯è§†åŒ–çƒ­åŠ›å›¾æ˜¾ç¤ºï¼Œæ‰€æœ‰ 20 æ¬¡è¯•éªŒä¸­å‡èƒ½åœ¨æ•…éšœæ³¨å…¥åç«‹å³å“åº”ï¼ŒéªŒè¯äº†**ä½å»¶è¿Ÿã€é«˜ä¸€è‡´æ€§æ£€æµ‹èƒ½åŠ›**ã€‚

### ï¼ˆ4ï¼‰æ ¹å› å®šä½æœ‰æ•ˆæ€§éªŒè¯
é€šè¿‡è‡ªåŠ¨åŒ–è„šæœ¬åˆ†æ Trace æ•°æ®ï¼ŒæˆåŠŸå®šä½å¤šç§æ•…éšœï¼š
| æ•…éšœç±»å‹ | å…³é”®äº‹ä»¶ | Î”Î² (%) | Î”u | Suspicion Score |
|--------|--------|--------|-----|----------------|
| CPU Contention | oncpu | +29.0 | +50.1 | 2.821 |
| GPU Instability | ampere_gemm | +5.9 | +15.3 | 1,561 |
| NVLink Congestion | sglang::reduce | +86.2 | +2.5e13 | 292k |

> âœ”ï¸ å¼‚å¸¸äº‹ä»¶çš„ `Î²`ï¼ˆæ—¶é—´å æ¯”ï¼‰å’Œ `u`ï¼ˆåˆ©ç”¨ç‡ï¼‰å˜åŒ–æ˜¾è‘—ï¼ŒP-value â‰ˆ 0.000ï¼Œç»Ÿè®¡ä¸Šå¯åŒºåˆ†ã€‚

### ï¼ˆ5ï¼‰æ¶ˆèå®éªŒä¸æ³›åŒ–èƒ½åŠ›
- **æœªè§è´Ÿè½½æµ‹è¯•**ï¼šåœ¨ä»æœªè®­ç»ƒè¿‡çš„ workload ä¸Šï¼Œæ¨¡å‹è¿…é€Ÿæ”¶æ•›ï¼ˆçº¦ 1k æ ·æœ¬ï¼‰ï¼Œ90% æ ·æœ¬é¢„æµ‹è¯¯å·® <10%ã€‚
- **å™ªå£°é²æ£’æ€§**ï¼šç›´æ¥ä½¿ç”¨åŸå§‹ç”Ÿäº§å™ªå£°æ•°æ®è®­ç»ƒï¼Œä»å¯åœ¨å‡ åˆ†é’Ÿå†…ç¨³å®šã€‚
- **è·¨æ ˆé€šç”¨æ€§**ï¼šåœ¨ vLLM + 70B æ¨¡å‹ä¸Šå¿«é€Ÿé€‚é…ï¼Œè¯æ˜å»ºæ¨¡ç­–ç•¥ä¸ä¾èµ–ç‰¹å®šæ¡†æ¶ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦ç»“è®º
1. **LLM æ¨ç†å»¶è¿Ÿå½’å› å¿…é¡»æ˜¯è·¨æ ˆã€ç»†ç²’åº¦ã€åœ¨çº¿çš„**ï¼šä¼ ç»Ÿèšåˆç›‘æ§æ— æ³•æ•æ‰ Generation Stallsã€‚
2. **éä¾µå…¥å¼å…¨æ ˆè¿½è¸ªå¯è¡Œä¸”å¿…è¦**ï¼šLatencyPrism æˆåŠŸå®ç°äº†æ— éœ€é‡å¯ã€æ— ä»£ç ä¿®æ”¹çš„ç”Ÿäº§çº§è§‚æµ‹ã€‚
3. **åŠ¨æ€åŸºçº¿ä¼˜äºé™æ€é˜ˆå€¼**ï¼šåŸºäº GBDT çš„ workload-aware é¢„æµ‹æ¨¡å‹èƒ½æœ‰æ•ˆè§£è€¦â€œè´Ÿè½½å¢é•¿â€ä¸â€œæ€§èƒ½é€€åŒ–â€ã€‚
4. **ä¸¤çº§ç›‘æ§æ¶æ„å¹³è¡¡äº†å¼€é”€ä¸è¯Šæ–­æ·±åº¦**ï¼šSentinel Mode æä¾›å…¨å¤©å€™è½»é‡ç›‘æ§ï¼ŒDeep-Dive Mode æ•è·ç¬æ€ä¸Šä¸‹æ–‡ã€‚
5. **é«˜è´¨é‡ Trace æ•°æ®èµ‹èƒ½ä¸‹æ¸¸åˆ†æ**ï¼šå³ä½¿ç®€å•è§„åˆ™ä¹Ÿèƒ½å®ç°ç²¾å‡†æ ¹å› å®šä½ï¼Œè¯´æ˜æ•°æ®ä¿çœŸåº¦é«˜ã€‚

### å±€é™æ€§
- **ä¾èµ–å†å²æ­£å¸¸æ•°æ®**ï¼šæ–° workload æˆ–ç¡¬ä»¶å‡çº§éœ€è¦çŸ­æš‚ warm-up æœŸã€‚
- **æŒä¹…æ€§æ€§èƒ½é—®é¢˜å¯èƒ½æ¼æ£€**ï¼šè‹¥ç³»ç»Ÿé•¿æœŸå¤„äºäºšå¥åº·çŠ¶æ€ï¼Œç¼ºä¹â€œæ­£å¸¸â€å‚è€ƒï¼Œéš¾ä»¥è§¦å‘å‘Šè­¦ã€‚
- **éä¸»æµ XPU æ”¯æŒå—é™**ï¼šè¯­ä¹‰è§£æèƒ½åŠ›å—å‚å•†å·¥å…·é“¾å¼€æ”¾ç¨‹åº¦åˆ¶çº¦ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- åˆ©ç”¨ LLM å¯¹ Trace è¿›è¡Œè‡ªç„¶è¯­è¨€æ‘˜è¦ï¼Œæå‡å¯è¯»æ€§ã€‚
- å¼€å‘æ— éœ€å†·å¯åŠ¨çš„è‡ªé€‚åº”åŸºçº¿æœºåˆ¶ï¼ˆcalibration-freeï¼‰ã€‚
- æ„å»ºæ›´æ™ºèƒ½çš„è‡ªåŠ¨åŒ–è¯Šæ–­ Agentï¼Œç»“åˆå› æœæ¨ç†è¿›è¡Œé—­ç¯ä¿®å¤ã€‚

---

> ğŸ”š **æ€»ç»“**ï¼šLatencyPrism å°† LLM æ¨ç†å¯è§‚æµ‹æ€§ä»â€œé»‘ç›’ç›‘æ§â€æ¨è¿›åˆ°â€œç™½ç›’è¯Šæ–­â€ï¼Œæ˜¯é¦–ä¸ªå®ç°**åœ¨çº¿ã€éä¾µå…¥ã€å…¨æ ˆã€è‡ªåŠ¨åŒ–**å»¶è¿Ÿåˆ†æçš„ç³»ç»Ÿï¼Œå·²åœ¨é˜¿é‡Œäº‘åƒå¡è§„æ¨¡é›†ç¾¤ç¨³å®šè¿è¡Œå…­ä¸ªæœˆï¼Œå…·æœ‰é‡è¦å·¥ä¸šä»·å€¼ã€‚

</details>

---

### 16. [Enhancing Spatial Reasoning in Large Language Models for Metal-Organic Frameworks Structure Prediction](https://arxiv.org/abs/2601.09285)

**Authors**: Mianzhi Pan, JianFei Li, Peishuo Liu, Botian Wang, Yawen Ouyang, Yiming Rong, Hao Zhou, Jianbing Zhang  
**Category**: cs.LG  
**Published**: 2026-01-15  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.09285v1  

#### Abstract
Metal-organic frameworks (MOFs) are porous crystalline materials with broad applications such as carbon capture and drug delivery, yet accurately predicting their 3D structures remains a significant challenge. While Large Language Models (LLMs) have shown promise in generating crystals, their applic...

---

### 17. [Private LLM Inference on Consumer Blackwell GPUs: A Practical Guide for Cost-Effective Local Deployment in SMEs](https://arxiv.org/abs/2601.09527)

**Authors**: Jonathan Knoop, Hendrik Holtmann  
**Category**: cs.LG  
**Published**: 2026-01-15  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.09527v1  

#### Abstract
SMEs increasingly seek alternatives to cloud LLM APIs, which raise data privacy concerns. Dedicated cloud GPU instances offer improved privacy but with limited guarantees and ongoing costs, while professional on-premise hardware (A100, H100) remains prohibitively expensive. We present a systematic e...

---

### 18. [Forecast Aware Deep Reinforcement Learning for Efficient Electricity Load Scheduling in Dairy Farms](https://arxiv.org/abs/2601.08052)

**Authors**: Nawazish Alia, Rachael Shawb, Karl Mason  
**Category**: cs.AI  
**Published**: 2026-01-15  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.08052v1  

#### Abstract
Dairy farming is an energy intensive sector that relies heavily on grid electricity. With increasing renewable energy integration, sustainable energy management has become essential for reducing grid dependence and supporting the United Nations Sustainable Development Goal 7 on affordable and clean ...

---

### 19. [SlidesGen-Bench: Evaluating Slides Generation via Computational and Quantitative Metrics](https://arxiv.org/abs/2601.09487)

**Authors**: Yunqiao Yang, Wenbo Li, Houxing Ren, Zimu Lu, Ke Wang, Zhiyuan Huang, Zhuofan Zong, Mingjie Zhan, Hongsheng Li  
**Category**: cs.CL  
**Published**: 2026-01-15  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.09487v1  

#### Abstract
The rapid evolution of Large Language Models (LLMs) has fostered diverse paradigms for automated slide generation, ranging from code-driven layouts to image-centric synthesis. However, evaluating these heterogeneous systems remains challenging, as existing protocols often struggle to provide compara...

---

### 20. [SRT: Accelerating Reinforcement Learning via Speculative Rollout with Tree-Structured Cache](https://arxiv.org/abs/2601.09083)

**Authors**: Chi-Chih Chang, Siqi Zhu, Zhichen Zeng, Haibin Lin, Jiaxuan You, Mohamed S. Abdelfattah, Ziheng Jiang, Xuehai Qian  
**Category**: cs.LG  
**Published**: 2026-01-15  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.09083v1  

#### Abstract
We present Speculative Rollout with Tree-Structured Cache (SRT), a simple, model-free approach to accelerate on-policy reinforcement learning (RL) for language models without sacrificing distributional correctness. SRT exploits the empirical similarity of rollouts for the same prompt across training...

---

### 21. [Deconstructing Pre-training: Knowledge Attribution Analysis in MoE and Dense Models](https://arxiv.org/abs/2601.08383)

**Authors**: Bo Wang, Junzhuo Li, Hong Chen, Yuanlin Chu, Yuxuan Fan, Xuming Hu  
**Category**: cs.AI  
**Published**: 2026-01-15  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.08383v1  

#### Abstract
Mixture-of-Experts (MoE) architectures decouple model capacity from per-token computation, enabling scaling beyond the computational limits imposed by dense scaling laws. Yet how MoE architectures shape knowledge acquisition during pre-training, and how this process differs from dense architectures,...

---

### 22. [MEMEWEAVER: Inter-Meme Graph Reasoning for Sexism and Misogyny Detection](https://arxiv.org/abs/2601.08684)

**Authors**: Paolo Italiani, David Gimeno-Gomez, Luca Ragazzi, Gianluca Moro, Paolo Rosso  
**Category**: cs.AI  
**Published**: 2026-01-15  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.08684v1  

#### Abstract
Women are twice as likely as men to face online harassment due to their gender. Despite recent advances in multimodal content moderation, most approaches still overlook the social dynamics behind this phenomenon, where perpetrators reinforce prejudices and group identity within like-minded communiti...

---

### 23. [Adaptive Multi-Stage Patent Claim Generation with Unified Quality Assessment](https://arxiv.org/abs/2601.09120)

**Authors**: Chen-Wei Liang, Bin Guo, Zhen-Yuan Wei, Mu-Jiang-Shan Wang  
**Category**: cs.CL  
**Published**: 2026-01-15  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.09120v1  

#### Abstract
Current patent claim generation systems face three fundamental limitations: poor cross-jurisdictional generalization, inadequate semantic relationship modeling between claims and prior art, and unreliable quality assessment. We introduce a novel three-stage framework that addresses these challenges ...

---

### 24. [A.X K1 Technical Report](https://arxiv.org/abs/2601.09200)

**Authors**: Sung Jun Cheon, Jaekyung Cho, Seongho Choi, Hyunjun Eun, Seokhwan Jo, Jaehyun Jun, Minsoo Kang, Jin Kim, Jiwon Kim, Minsang Kim, Sungwan Kim, Seungsik Kim, Tae Yoon Kim, Youngrang Kim, Hyeongmun Lee, Sangyeol Lee, Sungeun Lee, Youngsoon Lee, Yujin Lee, Seongmin Ok, Chanyong Park, Hyewoong Park, Junyoung Park, Hyunho Yang, Subin Yi, Soohyun Bae, Dhammiko Arya, Yongseok Choi, Sangho Choi, Dongyeon Cho, Seungmo Cho, Gyoungeun Han, Yong-jin Han, Seokyoung Hong, Hyeon Hwang, Wonbeom Jang, Minjeong Ju, Wonjin Jung, Keummin Ka, Sungil Kang, Dongnam Kim, Joonghoon Kim, Jonghwi Kim, SaeRom Kim, Sangjin Kim, Seongwon Kim, Youngjin Kim, Seojin Lee, Sunwoo Lee, Taehoon Lee, Chanwoo Park, Sohee Park, Sooyeon Park, Yohan Ra, Sereimony Sek, Seungyeon Seo, Gun Song, Sanghoon Woo, Janghan Yoon, Sungbin Yoon  
**Category**: cs.CL  
**Published**: 2026-01-15  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.09200v1  

#### Abstract
We introduce A.X K1, a 519B-parameter Mixture-of-Experts (MoE) language model trained from scratch. Our design leverages scaling laws to optimize training configurations and vocabulary size under fixed computational budgets. A.X K1 is pre-trained on a corpus of approximately 10T tokens, curated by a...

---

### 25. [Dialogue Telemetry: Turn-Level Instrumentation for Autonomous Information Gathering](https://arxiv.org/abs/2601.09570)

**Authors**: Dimitris Panagopoulos, Adolfo Perrusquia, Weisi Guo  
**Category**: cs.CL  
**Published**: 2026-01-15  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.09570v1  

#### Abstract
Autonomous systems conducting schema-grounded information-gathering dialogues face an instrumentation gap, lacking turn-level observables for monitoring acquisition efficiency and detecting when questioning becomes unproductive. We introduce Dialogue Telemetry (DT), a measurement framework that prod...

---

### 26. [DPWriter: Reinforcement Learning with Diverse Planning Branching for Creative Writing](https://arxiv.org/abs/2601.09609)

**Authors**: Qian Cao, Yahui Liu, Wei Bi, Yi Zhao, Ruihua Song, Xiting Wang, Ruiming Tang, Guorui Zhou, Han Li  
**Category**: cs.CL  
**Published**: 2026-01-15  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.09609v1  

#### Abstract
Reinforcement learning (RL)-based enhancement of large language models (LLMs) often leads to reduced output diversity, undermining their utility in open-ended tasks like creative writing. Current methods lack explicit mechanisms for guiding diverse exploration and instead prioritize optimization eff...

---

### 27. [XGBoost Forecasting of NEPSE Index Log Returns with Walk Forward Validation](https://arxiv.org/abs/2601.08896)

**Authors**: Sahaj Raj Malla, Shreeyash Kayastha, Rumi Suwal, Harish Chandra Bhandari, Rajendra Adhikari  
**Category**: cs.LG  
**Published**: 2026-01-15  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.08896v1  

#### Abstract
This study develops a robust machine learning framework for one-step-ahead forecasting of daily log-returns in the Nepal Stock Exchange (NEPSE) Index using the XGBoost regressor. A comprehensive feature set is engineered, including lagged log-returns (up to 30 days) and established technical indicat...

---

### 28. [Comparative Assessment of Concrete Compressive Strength Prediction at Industry Scale Using Embedding-based Neural Networks, Transformers, and Traditional Machine Learning Approaches](https://arxiv.org/abs/2601.09096)

**Authors**: Md Asiful Islam, Md Ahmed Al Muzaddid, Afia Jahin Prema, Sreenath Reddy Vuske  
**Category**: cs.LG  
**Published**: 2026-01-15  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.09096v1  

#### Abstract
Concrete is the most widely used construction material worldwide; however, reliable prediction of compressive strength remains challenging due to material heterogeneity, variable mix proportions, and sensitivity to field and environmental conditions. Recent advances in artificial intelligence enable...

---

### 29. [Efficient Clustering in Stochastic Bandits](https://arxiv.org/abs/2601.09162)

**Authors**: G Dhinesh Chandran, Kota Srinivas Reddy, Srikrishna Bhashyam  
**Category**: cs.LG  
**Published**: 2026-01-15  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.09162v1  

#### Abstract
We study the Bandit Clustering (BC) problem under the fixed confidence setting, where the objective is to group a collection of data sequences (arms) into clusters through sequential sampling from adaptively selected arms at each time step while ensuring a fixed error probability at the stopping tim...

---

### 30. [RIFT: Repurposing Negative Samples via Reward-Informed Fine-Tuning](https://arxiv.org/abs/2601.09253)

**Authors**: Zehua Liu, Shuqi Liu, Tao Zhong, Mingxuan Yuan  
**Category**: cs.LG  
**Published**: 2026-01-15  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.09253v1  

#### Abstract
While Supervised Fine-Tuning (SFT) and Rejection Sampling Fine-Tuning (RFT) are standard for LLM alignment, they either rely on costly expert data or discard valuable negative samples, leading to data inefficiency. To address this, we propose Reward Informed Fine-Tuning (RIFT), a simple yet effectiv...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- kv cache, offload, State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
