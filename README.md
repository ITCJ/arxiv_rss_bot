# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-02-10 06:51:50 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [MedVerse: Efficient and Reliable Medical Reasoning via DAG-Structured Parallel Execution](https://arxiv.org/abs/2602.07529)

**Authors**: Jianwen Chen, Xinyu Yang, Peng Xia, Arian Azarang, Yueh Z Lee, Gang Li, Hongtu Zhu, Yun Li, Beidi Chen, Huaxiu Yao  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 15.0  
**Type**: new  
**ArXiv ID**: 2602.07529v1  

#### Abstract
Large language models (LLMs) have demonstrated strong performance and rapid progress in a wide range of medical reasoning tasks. However, their sequential autoregressive decoding forces inherently parallel clinical reasoning, such as differential diagnosis, into a single linear reasoning path, limit...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# MedVerse: Efficient and Reliable Medical Reasoning via DAG-Structured Parallel Execution è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰åŸºäº **Large Language Models (LLMs)** å’Œ **Chain-of-Thought (CoT)** çš„åŒ»ç–—æ¨ç†æ¨¡å‹æ™®éé‡‡ç”¨**è‡ªå›å½’ï¼ˆautoregressive, ARï¼‰åºåˆ—ç”Ÿæˆ**æ–¹å¼ï¼Œè¿™ç§çº¿æ€§æ¨ç†æ¨¡å¼å­˜åœ¨ä¸‰å¤§æ ¹æœ¬æ€§ç¼ºé™·ï¼š
- **å‡†ç¡®æ€§å—é™**ï¼šå¼ºåˆ¶å°†æœ¬åº”å¹¶è¡Œçš„ä¸´åºŠé‰´åˆ«è¯Šæ–­ï¼ˆdifferential diagnosisï¼‰å‹ç¼©ä¸ºå•ä¸€è·¯å¾„ï¼Œå®¹æ˜“å› æ—©æœŸé”™è¯¯å‡è®¾å¯¼è‡´â€œä¸Šä¸‹æ–‡æ±¡æŸ“â€ï¼ˆcontextual pollutionï¼‰ï¼Œå¿½ç•¥å…¶ä»–åˆç†è¯Šæ–­è·¯å¾„ã€‚
- **æ•ˆç‡ä½ä¸‹**ï¼šä¸²è¡Œè§£ç å¸¦æ¥é«˜å»¶è¿Ÿï¼ˆlatencyï¼‰ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶ä¸´åºŠå†³ç­–æ”¯æŒéœ€æ±‚ã€‚
- **å¯è§£é‡Šæ€§å·®**ï¼šä¼ ç»Ÿ CoT ç¼ºä¹æ˜¾å¼çš„å› æœä¾èµ–ç»“æ„ï¼Œæ¨ç†è¿‡ç¨‹ä¸é€æ˜ã€‚

æ­¤å¤–ï¼Œç°æœ‰å¹¶è¡Œæ¨ç†æ¡†æ¶ï¼ˆå¦‚ Tree-of-Thoughtsã€Speculative Decodingï¼‰å¤šä¸ºâ€œæš´åŠ›é‡‡æ ·â€æˆ–ç®€å•åˆ†å‰-åˆå¹¶ï¼ˆfork-joinï¼‰ç»“æ„ï¼Œæ— æ³•å»ºæ¨¡å¤æ‚ã€éçº¿æ€§çš„åŒ»å­¦æ¨ç†æ‹“æ‰‘ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡º **MedVerse** â€”â€” ä¸€ç§é¢å‘å¤æ‚åŒ»ç–—æ¨ç†çš„æ–°å‹ **DAG-Structured å¹¶è¡Œæ¨ç†æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š
- **ç†è®ºåŸºç¡€**ï¼šé¦–æ¬¡å°† **Petri Net** ç†è®ºå¼•å…¥ LLM æ¨ç†ï¼Œå°†åŒ»å­¦æ¨ç†å½¢å¼åŒ–ä¸ºä¸€ä¸ª**æœ‰å‘æ— ç¯å›¾ï¼ˆDirected Acyclic Graph, DAGï¼‰** çš„æ‰§è¡Œè¿‡ç¨‹ã€‚å…¶ä¸­ï¼š
  - **Places** è¡¨ç¤ºä¸´åºŠçŠ¶æ€ï¼ˆå¦‚ç—‡çŠ¶ã€æ£€æŸ¥ç»“æœï¼‰ï¼›
  - **Transitions** è¡¨ç¤ºæ¨ç†æ­¥éª¤ï¼ˆå¦‚ä»ç—‡çŠ¶æ¨æ–­ç–¾ç—…ï¼‰ï¼›
  - **Tokens** æºå¸¦è¯­ä¹‰å’Œ KV-Cache å¼•ç”¨ï¼Œå®ç°é«˜æ•ˆçŠ¶æ€ä¼ é€’ã€‚
- **å…¨æ ˆååŒè®¾è®¡ï¼ˆco-designï¼‰**ï¼š
  - **æ•°æ®å±‚**ï¼šæå‡º **MedVerse Curator** è‡ªåŠ¨åŒ–æµæ°´çº¿ï¼Œæ„å»ºäº†åŒ…å« 13,904 ä¸ªé«˜è´¨é‡æ ·æœ¬çš„ **MedVerse-14K** æ•°æ®é›†ï¼Œæ¯ä¸ªæ ·æœ¬å‡ä¸ºç»“æ„åŒ–çš„ DAG æ¨ç†è·¯å¾„ã€‚
  - **ç®—æ³•å±‚**ï¼šè®¾è®¡ **MedVerse Attention**ï¼Œé€šè¿‡æ‹“æ‰‘æ„ŸçŸ¥çš„æ³¨æ„åŠ›æ©ç ï¼ˆtopology-aware attention maskï¼‰å’Œè‡ªé€‚åº”ä½ç½®ç¼–ç ï¼ˆadaptive position indicesï¼‰ï¼Œä½¿ Transformer æ”¯æŒ DAG ç»“æ„ä¸‹çš„å¹¶è¡Œæ¨ç†ã€‚
  - **ç³»ç»Ÿå±‚**ï¼šå¼€å‘ **MedVerse Engine**ï¼ŒåŸºäº Multiverse Engine æ„å»ºé«˜æ€§èƒ½æ¨ç†å¼•æ“ï¼Œæ”¯æŒåŠ¨æ€çš„ **Fork**ï¼ˆåˆ†å‰å¹¶è¡Œï¼‰å’Œ **Join**ï¼ˆèšåˆåŒæ­¥ï¼‰æ“ä½œï¼Œå®ç°çœŸæ­£çš„å¹¶è¡Œè§£ç ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´å‡†ç¡®**ï¼šæ”¯æŒå¤šå‡è®¾å¹¶è¡Œæ¢ç´¢ï¼Œé¿å…è¿‡æ—©æ”¶æ•›åˆ°é”™è¯¯è·¯å¾„ã€‚
- **æ›´é«˜æ•ˆ**ï¼šçªç ´è‡ªå›å½’ç“¶é¢ˆï¼Œæ˜¾è‘—é™ä½æ¨ç†å»¶è¿Ÿï¼Œæå‡ååé‡ã€‚
- **æ›´å¯é ä¸”å¯è§£é‡Š**ï¼šæ˜¾å¼å»ºæ¨¡å› æœä¾èµ–å…³ç³»ï¼Œæ¨ç†è¿‡ç¨‹ç»“æ„æ¸…æ™°ï¼Œä¾¿äºä¸´åºŠéªŒè¯ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
åœ¨ä»¥ä¸‹äº”ä¸ªæ ‡å‡†åŒ»å­¦æ¨ç†åŸºå‡†ä¸Šè¿›è¡Œè¯„ä¼°ï¼š
- **MedQA**ï¼šæ¶µç›–ç¾å›½åŒ»å¸ˆæ‰§ç…§è€ƒè¯•ï¼ˆUSMLEï¼‰é£æ ¼çš„å¤šé¡¹é€‰æ‹©é¢˜ã€‚
- **MedXpert**ï¼šä¸“å®¶çº§åŒ»å­¦æ¨ç†ç†è§£è¯„æµ‹é›†ã€‚
- **MedBullets (op4/op5)**ï¼šåŸºäºåŒ»å­¦è¦ç‚¹çš„å¤šé€‰é¢˜æ•°æ®é›†ï¼ˆ4 æˆ– 5 ä¸ªé€‰é¡¹ï¼‰ã€‚
- **PubMedQA**ï¼šåŸºäº PubMed æ–‡çŒ®æ‘˜è¦çš„é—®ç­”æ•°æ®é›†ã€‚
- **Humanity's Last Exam (HLE)**ï¼šç»¼åˆæ€§åŒ»å­¦æŒ‘æˆ˜è¯„æµ‹é›†ã€‚

æœ€ç»ˆè®­ç»ƒæ•°æ®é›†ä¸ºä½œè€…æ„å»ºçš„ **MedVerse-14K**ï¼Œç”±ä¸Šè¿°å¤šä¸ªæ•°æ®é›†çš„è®­ç»ƒå­é›†ç» MedVerse Curator å¤„ç†ååˆæˆã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹åŸºåº§**ï¼šåŸºäº `Qwen2.5-7B-Instruct` å’Œ `Llama-3.1-8B-Instruct` è¿›è¡Œå¾®è°ƒã€‚
- **è®­ç»ƒé…ç½®**ï¼š
  - ä½¿ç”¨ 4 å— NVIDIA H200 GPUï¼›
  - é‡‡ç”¨ PyTorch FSDPï¼›
  - å­¦ä¹ ç‡ $10^{-5}$ï¼Œæ‰¹é‡å¤§å° 128ï¼Œè®­ç»ƒ 3 è½®ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Accuracy (%)**ï¼šä¸»è¦æ€§èƒ½æŒ‡æ ‡ã€‚
  - **Latency (s)**ï¼šç«¯åˆ°ç«¯ CoT æ¨ç†å»¶è¿Ÿã€‚
  - **Throughput (tokens/sec)**ï¼šå•ä½æ—¶é—´ç”Ÿæˆ token æ•°é‡ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **åŸå§‹åŸºåº§æ¨¡å‹**ï¼š`Qwen2.5-7B-Instruct`, `Llama-3.1-8B-Instruct`
- **ä¸“ç”¨åŒ»å­¦ LLM**ï¼š
  - `MedReason-8B`
  - `HuatuoGPT-o1-RL-8B`

æ‰€æœ‰å¯¹æ¯”å‡åœ¨ç›¸åŒè®­ç»ƒæ•°æ®é‡ï¼ˆçº¦ 14K æ ·æœ¬ï¼‰ä¸‹è¿›è¡Œï¼Œç¡®ä¿å…¬å¹³æ€§ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æ¨¡å‹ | å¹³å‡ Accuracy (%) |
|------|------------------|
| Qwen2.5-7B-Instruct (åŸç‰ˆ) | 34.5 |
| Qwen2.5-7B-Instruct + MedVerse | **39.3** (+4.8%) |
| Llama-3.1-8B-Instruct (åŸç‰ˆ) | 35.3 |
| Llama-3.1-8B-Instruct + MedVerse | **44.2** (+8.9%) |

> âœ… **MedVerse åœ¨ä¸¤ä¸ªä¸åŒåŸºåº§ä¸Šå‡æ˜¾è‘—è¶…è¶ŠåŸæ¨¡å‹ï¼Œå¹¶è¾¾åˆ°ç”šè‡³è¶…è¿‡ä¸“ç”¨åŒ»å­¦ LLMï¼ˆå¦‚ MedReasonã€HuatuoGPT-o1ï¼‰çš„æ€§èƒ½æ°´å¹³**ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ç²¾åº¦æ–¹é¢**ï¼š
  - åœ¨ `Llama-3.1-8B` ä¸Šï¼ŒMedVerse ä»¥ **44.2%** çš„å¹³å‡å‡†ç¡®ç‡ï¼Œ**è¶…è¿‡ MedReason (42.2%) å’Œ HuatuoGPT-o1 (42.7%)**ã€‚
- **æ•ˆç‡æ–¹é¢**ï¼š
  - **æ¨ç†å»¶è¿Ÿé™ä½ 1.3Ã—**ï¼ˆå³æé€Ÿ 30%ï¼‰ï¼›
  - **ç”Ÿæˆååé‡æå‡ 69.3%**ï¼ˆæ¥è¿‘ 1.7Ã—ï¼‰ï¼›
  - åœ¨é•¿åºåˆ—ï¼ˆ2048 tokensï¼‰åœºæ™¯ä¸‹ï¼Œååä¼˜åŠ¿æ›´åŠ æ˜æ˜¾ï¼ˆè§ Figure 4bï¼‰ã€‚

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰çº¿æ€§è§„åˆ’ vs. ç›´æ¥ç”Ÿæˆ Petri Netï¼ˆTable 2ï¼‰
| æ¨¡å‹å˜ä½“ | å‡†ç¡®ç‡ (%) | å»¶è¿Ÿ (s) |
|----------|-----------|--------|
| Autoregressive (Baseline) | 18.4 | 5.1 |
| Direct Petri Netï¼ˆæ— è§„åˆ’é˜¶æ®µï¼‰ | 17.4 | 4.5 |
| **MedVerseï¼ˆå«è§„åˆ’é˜¶æ®µï¼‰** | **19.3** | **4.0** |

> ğŸ” å‘ç°ï¼š**ç›´æ¥ç”Ÿæˆ DAG ç»“æ„æ•ˆæœå·®**ï¼Œè¯´æ˜çº¿æ€§â€œæ€è€ƒå†æ˜ å°„â€ï¼ˆThink-then-Mapï¼‰ç­–ç•¥å¯¹æ„å»ºæ­£ç¡®æ¨ç†å›¾è‡³å…³é‡è¦ã€‚

#### ï¼ˆ2ï¼‰è®­ç»ƒä¸æ¨ç†æ¨¡å¼æ¶ˆèï¼ˆTable 4ï¼‰
| é…ç½® | å¹³å‡å‡†ç¡®ç‡ |
|------|---------|
| Auto-Serï¼ˆæ ‡å‡†è®­ç»ƒ + ä¸²è¡Œæ¨ç†ï¼‰ | 0.3690 |
| Auto-Parï¼ˆæ ‡å‡†è®­ç»ƒ + å¹¶è¡Œå¼•æ“ï¼‰ | 0.3792 |
| Mask-Serï¼ˆMedVerse è®­ç»ƒ + ä¸²è¡Œæ¨ç†ï¼‰ | 0.3856 |
| **Mask-Parï¼ˆMedVerse è®­ç»ƒ + å¹¶è¡Œæ¨ç†ï¼‰** | **0.3934** |

> ğŸ” å‘ç°ï¼š**è®­ç»ƒæœºåˆ¶ï¼ˆMaskï¼‰å’Œæ¨ç†æœºåˆ¶ï¼ˆParï¼‰å‡æœ‰å¢ç›Šï¼ŒäºŒè€…ååŒä½œç”¨æœ€å¼º**ï¼Œè¯æ˜äº†â€œç»“æ„å¯¹é½â€ï¼ˆstructural alignmentï¼‰çš„é‡è¦æ€§ã€‚

#### ï¼ˆ3ï¼‰æ•°æ®è§„æ¨¡å½±å“ï¼ˆTable 3ï¼‰
| è®­ç»ƒæ ·æœ¬æ•° | å¹³å‡å‡†ç¡®ç‡ |
|----------|---------|
| 1k | 29.2% |
| 5k (~36%) | 37.5% |
| 14k (100%) | **39.2%** |

> ğŸ” å‘ç°ï¼šæ¨¡å‹å…·æœ‰**æå¼ºçš„æ•°æ®æ•ˆç‡**ï¼Œä»…éœ€ 5k æ ·æœ¬å³å¯æ¢å¤ 95% ä»¥ä¸Šå³°å€¼æ€§èƒ½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ä¸´åºŠæ¨ç†æœ¬è´¨ä¸Šæ˜¯ DAG ç»“æ„è€Œéçº¿æ€§é“¾**ï¼šäººç±»åŒ»ç”ŸåŒæ—¶è€ƒè™‘å¤šä¸ªå‡è®¾ï¼Œç°æœ‰ CoT æ¨¡å¼ä¸å…¶è®¤çŸ¥è¿‡ç¨‹ä¸åŒ¹é…ã€‚
2. **ç»“æ„å¯¹é½æ˜¯å…³é”®**ï¼šåªæœ‰å½“è®­ç»ƒæ•°æ®ã€æ¨¡å‹æ¶æ„å’Œæ¨ç†ç³»ç»Ÿä¸‰è€…éƒ½å¯¹é½äº DAG æ‹“æ‰‘æ—¶ï¼Œæ‰èƒ½æœ€å¤§åŒ–æ€§èƒ½æ”¶ç›Šã€‚
3. **å¹¶è¡Œæ¨ç†å¯å…¼é¡¾æ•ˆç‡ä¸å¯é æ€§**ï¼šMedVerse ä¸ä»…æå‡äº†å‡†ç¡®ç‡ï¼Œè¿˜æ˜¾è‘—é™ä½äº†å»¶è¿Ÿã€æé«˜äº†ååï¼Œå®ç°äº†â€œæ›´å¿«ä¸”æ›´å¥½â€çš„æ¨ç†ã€‚
4. **Petri Net æ˜¯å»ºæ¨¡å¤æ‚æ¨ç†æµç¨‹çš„æœ‰æ•ˆå·¥å…·**ï¼šå…¶å¯¹â€œçŠ¶æ€â€ä¸â€œå˜è¿â€çš„åˆ†ç¦»å»ºæ¨¡ï¼Œå¤©ç„¶é€‚åˆ LLM çš„ KV-Cache é‡ç”¨ä¸çŠ¶æ€åŒæ­¥ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡ç»“æ„åŒ–æ•°æ®**ï¼šMedVerse çš„æ€§èƒ½é«˜åº¦ä¾èµ– MedVerse Curator ç”Ÿæˆçš„ç»“æ„åŒ–è®­ç»ƒæ•°æ®ï¼Œè‹¥ Curator å‡ºé”™ï¼Œå¯èƒ½ä¼ æ’­é”™è¯¯ç»“æ„ã€‚
- **åˆå§‹è§„åˆ’é˜¶æ®µä»ä¸ºä¸²è¡Œ**ï¼šè™½ç„¶æ‰§è¡Œé˜¶æ®µå¹¶è¡Œï¼Œä½† `<Plan>` é˜¶æ®µä»æ˜¯çº¿æ€§ç”Ÿæˆï¼Œæ„æˆæ½œåœ¨ç“¶é¢ˆã€‚
- **å¯¹éå¸¸è§„æ¨ç†æ¨¡å¼æ³›åŒ–èƒ½åŠ›æœªçŸ¥**ï¼šç›®å‰ä¸»è¦é’ˆå¯¹é‰´åˆ«è¯Šæ–­ç±»ä»»åŠ¡ï¼Œæ˜¯å¦é€‚ç”¨äºæ‰‹æœ¯è§„åˆ’ã€æ²»ç–—éšè®¿ç­‰å¤æ‚æµç¨‹å°šå¾…éªŒè¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **å¤šæ¨¡æ€åŒ»ç–—æ¨ç†**ï¼ˆå¦‚ç»“åˆåŒ»å­¦å½±åƒä¸æ–‡æœ¬æŠ¥å‘Šï¼‰ã€‚
- æ¢ç´¢ **åŠ¨æ€å›¾æ„å»º**ï¼Œå‡å°‘å¯¹é¢„å®šä¹‰è®¡åˆ’çš„ä¾èµ–ã€‚
- å°† MedVerse åº”ç”¨äºçœŸå®ä¸´åºŠç¯å¢ƒï¼ˆå¦‚ç”µå­ç—…å†è¾…åŠ©è¯Šæ–­ï¼‰ä¸­çš„ **ç«¯åˆ°ç«¯å†³ç­–æ”¯æŒç³»ç»Ÿ**ã€‚
- è¿›ä¸€æ­¥ä¼˜åŒ– Petri Net ä¸ LLM çš„æ·±åº¦èåˆï¼Œæ¢ç´¢ **ç«¯åˆ°ç«¯å¯å¾®åˆ†å›¾å­¦ä¹ ** å¯èƒ½æ€§ã€‚

--- 

> âœ… **æ€»ç»“**ï¼šMedVerse é€šè¿‡ **Petri Net + DAG + å…¨æ ˆååŒè®¾è®¡**ï¼ŒæˆåŠŸå°†åŒ»å­¦æ¨ç†ä»â€œçº¿æ€§å™äº‹â€å‡çº§ä¸ºâ€œå¹¶è¡Œè®¡ç®—â€ï¼Œåœ¨ç²¾åº¦ã€æ•ˆç‡ã€å¯è§£é‡Šæ€§ä¸‰ä¸ªç»´åº¦å…¨é¢çªç ´ç°æœ‰èŒƒå¼ï¼Œä¸ºæ„å»ºä¸‹ä¸€ä»£å¯ä¿¡åŒ»ç–— AI æä¾›äº†é‡è¦è·¯å¾„ã€‚

</details>

---

### 2. [tLoRA: Efficient Multi-LoRA Training with Elastic Shared Super-Models](https://arxiv.org/abs/2602.07263)

**Authors**: Kevin Li, Dibyadeep Saha, Avni Kanodia, Fan Lai  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 13.0  
**Type**: new  
**ArXiv ID**: 2602.07263v1  

#### Abstract
As Low-Rank Adaptation (LoRA) becomes the standard approach for efficiently fine-tuning large language models (LLMs), shared clusters increasingly execute many concurrent LoRA training jobs over the same frozen backbone. While recent advances enable batching (co-locating) multiple adapters during se...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼štLoRA: Efficient Multi-LoRA Training with Elastic Shared Super-Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
åœ¨ç°ä»£æœºå™¨å­¦ä¹ é›†ç¾¤ä¸­ï¼Œ**LoRAï¼ˆLow-Rank Adaptationï¼‰å¾®è°ƒä»»åŠ¡**å·²æˆä¸ºå¸¸è§è´Ÿè½½ã€‚å¤§é‡å¼€å‘è€…ä¸ºåŒä¸€åŸºç¡€æ¨¡å‹ï¼ˆå¦‚ Llama æˆ– Qwenï¼‰è®­ç»ƒä¸åŒçš„ LoRA é€‚é…å™¨ã€‚ç„¶è€Œï¼Œå½“å‰ç³»ç»Ÿé€šå¸¸å°†æ¯ä¸ª LoRA ä»»åŠ¡ç‹¬ç«‹æ‰§è¡Œï¼Œå¯¼è‡´ï¼š
- **èµ„æºæµªè´¹**ï¼šé‡å¤åŠ è½½ç›¸åŒçš„å†»ç»“ backbone æ¨¡å‹ï¼›
- **ä½æ•ˆè®­ç»ƒ**ï¼šæ— æ³•æœ‰æ•ˆå…±äº«è®¡ç®—ä¸å†…å­˜èµ„æºï¼›
- **é€šä¿¡ç“¶é¢ˆ**ï¼šå¼‚æ„ä»»åŠ¡ï¼ˆä¸åŒ rankã€batch sizeï¼‰å…±ç½®æ—¶å¼•å…¥åŒæ­¥å»¶è¿Ÿå’Œé€šä¿¡å¼€é”€ã€‚

å°½ç®¡å·²æœ‰å·¥ä½œï¼ˆå¦‚ S-LoRAã€dLoRAï¼‰å®ç°äº†å¤š LoRA åœ¨**æ¨ç†é˜¶æ®µ**çš„æ‰¹å¤„ç†ï¼Œä½†åœ¨**è®­ç»ƒé˜¶æ®µ**é«˜æ•ˆå…±ç½®å¤šä¸ªå¼‚æ„ LoRA ä»»åŠ¡ä»é¢ä¸´æŒ‘æˆ˜ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡º **tLoRA**ï¼Œä¸€ä¸ªæ”¯æŒé«˜æ•ˆæ‰¹é‡è®­ç»ƒå¼‚æ„ LoRA ä»»åŠ¡çš„æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰Shared Super-Model (SSM) æŠ½è±¡
- å°†å¤šä¸ªå…±äº«ç›¸åŒ backbone çš„ LoRA ä»»åŠ¡èåˆæˆä¸€ä¸ªç»Ÿä¸€çš„â€œå¼¹æ€§å…±äº«è¶…æ¨¡å‹â€ï¼ˆElastic Shared Super-Modelï¼‰ã€‚
- ä¿ç•™å„ä»»åŠ¡ç‹¬ç«‹çš„å‰å‘/åå‘ä¼ æ’­è¯­ä¹‰å’Œä¼˜åŒ–å™¨çŠ¶æ€ï¼Œç¡®ä¿æ”¶æ•›æ­£ç¡®æ€§ã€‚
- åˆ©ç”¨ç°æœ‰åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶ï¼ˆå¦‚ Megatron-LMã€PyTorch FSDPï¼‰è¿›è¡Œè‡ªåŠ¨å¹¶è¡ŒåŒ–è§„åˆ’ï¼Œæ— éœ€é‡æ„åº•å±‚ç³»ç»Ÿã€‚

#### ï¼ˆ2ï¼‰Fused LoRA Kernel + Adaptive Nano-Batching
- è®¾è®¡äº†ä¸€ä¸ªèåˆå†…æ ¸ï¼ˆfused kernelï¼‰ï¼Œé¿å…æ˜¾å¼æ„é€  $ W = AB^T $ æƒé‡çŸ©é˜µï¼Œæå‡å¯„å­˜å™¨å’Œå…±äº«å†…å­˜å¤ç”¨ç‡ã€‚
- å¼•å…¥ **nano-batch** æŠ½è±¡ï¼Œåœ¨ micro-batch å†…éƒ¨è¿›ä¸€æ­¥ç»†ç²’åº¦åˆ’åˆ†è¾“å…¥æ ·æœ¬ã€‚
- ä½¿ç”¨ **AIMD æ§åˆ¶å™¨**åœ¨çº¿åŠ¨æ€è°ƒæ•´ nano-batch å¤§å°ï¼Œæœ€å¤§åŒ–è®¡ç®—ä¸é€šä¿¡çš„é‡å ï¼Œå‡å°‘ pipeline bubblesã€‚

#### ï¼ˆ3ï¼‰Residual-Capacity-Aware åœ¨çº¿è°ƒåº¦å™¨
- è°ƒåº¦å™¨åŸºäºæ¯ä¸ªä»»åŠ¡çš„**å‰©ä½™èµ„æºå®¹é‡**ï¼ˆå¦‚ç©ºé—² GPU è®¡ç®—/å†…å­˜ï¼‰å’Œ**ç´§è¿«æ€§è¯„åˆ†**ï¼ˆurgency scoreï¼‰åŠ¨æ€åˆ†ç»„ã€‚
- ä¼˜å…ˆåˆå¹¶èµ„æºäº’è¡¥çš„ä»»åŠ¡ï¼ˆä¾‹å¦‚èµ„æºå¯Œä½™ä»»åŠ¡åŠ é€Ÿèµ„æºç´§å¼ ä»»åŠ¡ï¼‰ï¼Œé¿å…â€œå¼ºè€…è¡¥è´´å¼±è€…â€çš„ä¸å…¬å¹³ç°è±¡ã€‚
- æ”¯æŒè¿è¡Œæ—¶è§£è€¦è¡¨ç°ä¸ä½³çš„ç»„åˆï¼Œä¿éšœä¸ªä½“ä»»åŠ¡è¿›åº¦ï¼ˆå¦‚å®Œæˆæ—¶é—´çº¦æŸï¼‰ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | tLoRA | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ mLoRAï¼‰ |
|------|-------|------------------|
| **èµ„æºåˆ©ç”¨** | é«˜æ•ˆå…±äº« backboneï¼Œå……åˆ†åˆ©ç”¨ç¢ç‰‡èµ„æº | ä»…æŒ‰å†…å­˜æ˜¯å¦è¶³å¤Ÿå†³å®šæ˜¯å¦å…±ç½®ï¼Œå¿½ç•¥é€šä¿¡å¼€é”€ |
| **æ‰§è¡Œæ•ˆç‡** | è‡ªé€‚åº” nano-batching å®ç°ç»†ç²’åº¦æµæ°´çº¿é‡å  | å›ºå®š batch æ‰§è¡Œï¼Œæ˜“äº§ç”Ÿ bubble |
| **è°ƒåº¦æ™ºèƒ½æ€§** | åŠ¨æ€æ„ŸçŸ¥èµ„æºæ®‹å·®ä¸ä»»åŠ¡ç´§è¿«æ€§ï¼Œå¼¹æ€§åˆ†ç»„ | é™æ€ç­–ç•¥ï¼ˆå¦‚ FIFOï¼‰ï¼Œå¸¸å¯¼è‡´æ¬¡ä¼˜ç”šè‡³è´Ÿä¼˜åŒ– |
| **å…¬å¹³æ€§ä¿éšœ** | æ˜¾å¼æ§åˆ¶å•ä»»åŠ¡æ…¢åŒ–ç¨‹åº¦ï¼Œé˜²é¥¥é¥¿ | å¿½è§†ä¸ªä½“æ€§èƒ½é€€åŒ–é£é™© |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- ä¸»è¦è®­ç»ƒä»»åŠ¡ä½¿ç”¨ **GSM8K** æ•°æ®é›†ï¼ˆçº¦ 8.5k å°å­¦æ•°å­¦é¢˜ï¼‰ï¼Œç”¨äº fine-tuning LoRA æ¨¡å‹è§£å†³ä¸‹æ¸¸ä»»åŠ¡ã€‚
- è°ƒåº¦ä¸æ€§èƒ½å»ºæ¨¡ä¾èµ–çœŸå®é›†ç¾¤è½¨è¿¹æ•°æ®ï¼š**ACMETrace**ï¼ˆæ¥è‡ªç”Ÿäº§ç¯å¢ƒçš„ GPU ä½¿ç”¨æ—¥å¿—ï¼ŒåŒ…å«ä»»åŠ¡åˆ°è¾¾æ—¶é—´ã€èµ„æºåˆ†é…ã€æ‰§è¡Œæ—¶é•¿ç­‰ï¼‰ã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼š
  - å¾®åŸºå‡†æµ‹è¯•ï¼š12 å— NVIDIA A100 GPUï¼›
  - å¤§è§„æ¨¡ä»¿çœŸï¼š128-GPU é›†ç¾¤ï¼ˆé€šè¿‡ Sailor æ¨¡æ‹Ÿå™¨ï¼‰ã€‚
- **æ¨¡å‹é…ç½®**ï¼š
  - åŸºç¡€æ¨¡å‹ï¼šLlama-3-8B å’Œ Qwen-3-8Bï¼›
  - LoRA å‚æ•°éšæœºé‡‡æ ·ï¼šrank âˆˆ {2,4,8,16}ï¼Œbatch size âˆˆ {1,2,4,8}ï¼›
  - åºåˆ—é•¿åº¦ã€step budget ç­‰å›ºå®šæäº¤åä¸å˜ã€‚
- **å®ç°å·¥å…·**ï¼š
  - åŸºäº PyTorch 2.5 + Triton 3.5.1 å¼€å‘å®šåˆ¶ fused kernelï¼›
  - åˆ©ç”¨ Stratified æ¨¡æ‹Ÿå™¨è¿›è¡Œå¤§è§„æ¨¡ trace å›æ”¾ï¼ˆè¯¯å·® < 3%ï¼‰ã€‚

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Training Throughput** | å…¨å±€ååé‡ï¼ˆsamples/secï¼‰ï¼Œæ‰€æœ‰æ´»è·ƒä»»åŠ¡æ€»å’Œ |
| **Job Completion Time (JCT)** | ä»æäº¤åˆ°è®­ç»ƒå®Œæˆçš„å®é™…å¢™é’Ÿæ—¶é—´ï¼ˆå«æ’é˜Ÿä¸æ‰§è¡Œï¼‰ |
| **GPU Utilization** | æ‰€æœ‰ GPU çš„å¹³å‡ SMï¼ˆStreaming Multiprocessorï¼‰åˆ©ç”¨ç‡ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | æè¿° |
|------|------|
| **mLoRA (Ye et al., 2025)** | å½“å‰æœ€å…ˆè¿›çš„æ‰¹å¤„ç† LoRA è®­ç»ƒç³»ç»Ÿï¼ŒåŸºäºå†…å­˜å®¹é‡ç®€å•åˆ†ç»„ |
| **Megatron-LM (Narayanan et al., 2021)** | é«˜åº¦ä¼˜åŒ–çš„åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶ï¼Œä½†æ¯ä¸ª LoRA ç‹¬ç«‹è¿è¡Œ |
| **tLoRA w/o Scheduler** | ç§»é™¤è‡ªé€‚åº”è°ƒåº¦å™¨ï¼Œé‡‡ç”¨ mLoRA åˆ†ç»„ç­–ç•¥ |
| **tLoRA w/o Kernel Fuser** | ç§»é™¤ fused kernelï¼Œä½¿ç”¨åŸç”Ÿ PyTorch å®ç° |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆç»¼åˆç»“æœï¼‰
| æŒ‡æ ‡ | æå‡å¹…åº¦ |
|------|----------|
| **Training Throughput** | â†‘ **1.2â€“1.8Ã—** vs. mLoRA |
| **Per-Job Completion Time** | â†“ **2.3â€“5.4Ã— faster** |
| **Average GPU Utilization** | â†‘ **37%** |
| **æœ€å¤§ååæå‡** | è¾¾ **41%** è¶…è¿‡ mLoRAï¼ˆå›¾5aï¼‰ |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **vs. mLoRA**ï¼š
  - å°½ç®¡ mLoRA ä¹Ÿå°è¯•æ‰¹å¤„ç†ï¼Œä½†ç”±äºæœªè€ƒè™‘é€šä¿¡å¼€é”€å’Œè´Ÿè½½ä¸å‡ï¼ŒæŸäº›ç»„åˆåè€Œé™ä½ååï¼ˆè§ Figure 2 ä¸­ Jobs 1+2 ä¸‹é™ï¼‰ï¼›
  - tLoRA é€šè¿‡ SSM ç¼–è¯‘ + è‡ªé€‚åº” nano-batching æ˜¾è‘—å‡å°‘ pipeline bubblesï¼Œå®ç°ç¨³å®šå¢ç›Šã€‚
- **vs. Megatron**ï¼š
  - Megatron å•ç‹¬è¿è¡Œæ¯ä¸ªä»»åŠ¡ï¼Œæ— èµ„æºå…±äº«ï¼ŒGPU åˆ©ç”¨ç‡ä½ï¼›
  - tLoRA åœ¨åŒç­‰æ¡ä»¶ä¸‹æ˜¾è‘—æé«˜èµ„æºåˆ©ç”¨ç‡å’Œæ•´ä½“ååã€‚

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰è°ƒåº¦å™¨å½±å“ï¼ˆtLoRA w/o Schedulerï¼‰
- ä½¿ç”¨ FIFO æˆ–é™æ€åˆ†ç»„ç­–ç•¥æ—¶ï¼ŒJCT å¢åŠ è¿‘ **5.4Ã—**ï¼›
- åŸå› ï¼šå¤§é‡éäº’è¡¥ä»»åŠ¡è¢«å¼ºè¡Œå…±ç½®ï¼Œé€ æˆèµ„æºäº‰æŠ¢å’Œé€šä¿¡ç“¶é¢ˆã€‚

#### ï¼ˆ2ï¼‰Kernel Fuser å½±å“ï¼ˆtLoRA w/o Kernel Fuserï¼‰
- ç§»é™¤ fused kernel åï¼Œååä¸‹é™çº¦ **30â€“40%**ï¼›
- åŸå› ï¼šé¢‘ç¹çš„å° GEMM è°ƒç”¨å¯¼è‡´é«˜ kernel launch å¼€é”€ï¼Œä¸”ä¸­é—´å¼ é‡æ— æ³•æœ‰æ•ˆå¤ç”¨ã€‚

#### ï¼ˆ3ï¼‰Nano-batch Size æ•æ„Ÿæ€§åˆ†æï¼ˆFigure 8aï¼‰
- å›ºå®š nano-batch å¤§å°éš¾ä»¥é€‚åº”ä¸åŒç¡¬ä»¶ä¸ç½‘ç»œæ¡ä»¶ï¼›
- tLoRA çš„ AIMD è‡ªé€‚åº”æ§åˆ¶å™¨èƒ½å¿«é€Ÿæ”¶æ•›è‡³æœ€ä¼˜å€¼ï¼Œç«¯åˆ°ç«¯è®­ç»ƒååä¼˜äºæ‰‹åŠ¨è°ƒå‚æ–¹æ¡ˆã€‚

#### ï¼ˆ4ï¼‰ä¸åŒè´Ÿè½½åœºæ™¯ä¸‹çš„é²æ£’æ€§
| åœºæ™¯ | ç»“æœ |
|------|------|
| **é«˜å¹¶å‘åˆ°è¾¾ï¼ˆbursty arrivalsï¼‰** | tLoRA ä»ç»´æŒæ¥è¿‘å³°å€¼ååï¼ˆFigure 9aï¼‰ |
| **å°è§„æ¨¡é›†ç¾¤ï¼ˆ32 GPUsï¼‰** | æˆåŠŸä¿æŒçº¿æ€§æ‰©å±•è¶‹åŠ¿ï¼Œæœªå‡ºç°å°¾éƒ¨å»¶è¿Ÿçˆ†ç‚¸ï¼ˆFigure 13ï¼‰ |
| **è·¨æœˆçœŸå®è½¨è¿¹å›æ”¾** | åœ¨ä¸åŒæœˆä»½æµé‡æ¨¡å¼ä¸‹å‡è¡¨ç°ç¨³å¥ï¼ˆFigure 11ï¼‰ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **å¼‚æ„ LoRA ä»»åŠ¡å¯ä»¥é«˜æ•ˆå…±è®­**ï¼šåªè¦åˆç†è®¾è®¡è°ƒåº¦ä¸æ‰§è¡Œæœºåˆ¶ï¼Œå¤š LoRA æ‰¹é‡è®­ç»ƒä¸ä»…èƒ½æå‡ååï¼Œè¿˜èƒ½ç¼©çŸ­ä¸ªä½“ä»»åŠ¡å®Œæˆæ—¶é—´ã€‚
2. âœ… **èµ„æºäº’è¡¥æ˜¯å…³é”®é©±åŠ¨åŠ›**ï¼šå°†èµ„æºå¯Œä½™ä»»åŠ¡ä¸èµ„æºç´§å¼ ä»»åŠ¡é…å¯¹ï¼Œå¯å®ç°â€œåŒèµ¢â€â€”â€”å‰è€…é‡Šæ”¾é—²ç½®èµ„æºå¸®åŠ©åè€…ï¼Œåè€…æå‰é‡Šæ”¾ GPU åå“ºå‰è€…ã€‚
3. âœ… **ç»†ç²’åº¦æ‰§è¡Œæ§åˆ¶è‡³å…³é‡è¦**ï¼šä¼ ç»Ÿçš„ micro-batch å·²ä¸è¶³ä»¥æ©ç›–é€šä¿¡å¼€é”€ï¼Œ**nano-batch + AIMD æ§åˆ¶**æ˜¯å®ç°é«˜æ•ˆé‡å çš„å…³é”®ã€‚
4. âœ… **æ— éœ€ç‰ºç‰²è®­ç»ƒå‡†ç¡®æ€§**ï¼štLoRA æ˜¯ lossless çš„ï¼Œä¸æ”¹å˜åŸå§‹è®­ç»ƒè¯­ä¹‰ï¼Œä¿è¯æ”¶æ•›è¡Œä¸ºä¸€è‡´ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- â— **ä¾èµ–åŒæº backbone**ï¼šç›®å‰ä»…é€‚ç”¨äºå…±äº«åŒä¸€é¢„è®­ç»ƒæ¨¡å‹çš„ä»»åŠ¡ï¼›è‹¥ backbone ä¸åŒï¼Œåˆ™æ— æ³•èåˆã€‚
- â— **è°ƒåº¦å¼€é”€éšä»»åŠ¡æ•°å¢é•¿**ï¼šè™½ç„¶å¤æ‚åº¦ä¸º $ O(K \log K) $ï¼Œä½†åœ¨è¶…å¤§è§„æ¨¡ä»»åŠ¡æ± ä¸­ä»éœ€è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚
- â— **å¯¹ç½‘ç»œå¸¦å®½æ•æ„Ÿ**ï¼šå½“è·¨èŠ‚ç‚¹é€šä¿¡æˆä¸ºç“¶é¢ˆæ—¶ï¼Œæ”¶ç›Šå¯èƒ½å—é™ï¼ˆå°¤å…¶åœ¨ä½å¸¦å®½é›†ç¾¤ä¸­ï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- ğŸ”® æ”¯æŒ **å¼‚æ„ backbone çš„ LoRA æ··åˆè®­ç»ƒ**ï¼ˆå¦‚é€šè¿‡ MoE æˆ–è·¯ç”±æœºåˆ¶ï¼‰ï¼›
- ğŸ”® æ¢ç´¢ **æ›´ç²¾ç»†çš„å¼¹æ€§èµ„æºå†åˆ†é…æœºåˆ¶**ï¼Œå…è®¸ä»»åŠ¡ä¸´æ—¶å€Ÿç”¨æ›´å¤šèµ„æºä»¥æ¢å–åç»­è¡¥å¿ï¼›
- ğŸ”® ç»“åˆ **ç¼–è¯‘å™¨æŠ€æœ¯** è‡ªåŠ¨ç”Ÿæˆæœ€ä¼˜ SSM å›¾ç»“æ„ä¸æ‰§è¡Œè®¡åˆ’ï¼›
- ğŸ”® å°† tLoRA æ€æƒ³æ¨å¹¿è‡³å…¶ä»–å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ï¼ˆå¦‚ AdaLoRAã€IAÂ³ï¼‰ã€‚

--- 

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> tLoRA é€šè¿‡ **Shared Super-Model + Fused Kernel + Residual-Aware Scheduler** ä¸‰ä½ä¸€ä½“çš„è®¾è®¡ï¼Œé¦–æ¬¡å®ç°äº†é«˜æ•ˆã€å…¬å¹³ã€å¯æ‰©å±•çš„å¤š LoRA å¹¶è¡Œè®­ç»ƒï¼Œåœ¨çœŸå®é›†ç¾¤è½¨è¿¹ä¸‹å®ç°äº† **æœ€é«˜è¾¾ 5.4 å€çš„ä»»åŠ¡å®ŒæˆåŠ é€Ÿ** å’Œ **37% çš„ GPU åˆ©ç”¨ç‡æå‡**ï¼Œä¸ºå¤§è§„æ¨¡ LoRA å·¥ç¨‹åŒ–éƒ¨ç½²æä¾›äº†é‡è¦åŸºç¡€è®¾æ–½æ”¯æŒã€‚

</details>

---

### 3. [DLLM Agent: See Farther, Run Faster](https://arxiv.org/abs/2602.07451)

**Authors**: Huiling Zhen, Weizhe Lin, Renxi Liu, Kai Han, Yiming Li, Yuchuan Tian, Hanting Chen, Xiaoguang Li, Xiaosong Li, Chen Chen, Xianzhi Yu, Mingxuan Yuan, Youliang Yan, Peifeng Qin, Jun Wang, Yu Wang, Dacheng Tao, Yunhe Wang  
**Category**: cs.CL  
**Published**: 2026-02-10  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2602.07451v1  

#### Abstract
Diffusion large language models (DLLMs) have emerged as an alternative to autoregressive (AR) decoding with appealing efficiency and modeling properties, yet their implications for agentic multi-step decision making remain underexplored. We ask a concrete question: when the generation paradigm is ch...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDLLM Agent: See Farther, Run Faster

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
æœ¬æ–‡æ¢è®¨äº†ä¸€ä¸ªè¢«å¿½è§†çš„å…³é”®é—®é¢˜ï¼š**åœ¨è¯­è¨€æ¨¡å‹ Agentï¼ˆä»£ç†ï¼‰ç³»ç»Ÿä¸­ï¼Œç”ŸæˆèŒƒå¼ï¼ˆgeneration paradigmï¼‰æœ¬èº«æ˜¯å¦ä¼šå½±å“å¤šæ­¥å†³ç­–è¡Œä¸ºï¼Ÿ**  
å°½ç®¡å½“å‰å¤§å¤šæ•° Agent ç ”ç©¶èšç„¦äºè®­ç»ƒæ•°æ®ã€æç¤ºå·¥ç¨‹æˆ–æµç¨‹è®¾è®¡ï¼Œå´é»˜è®¤ä½¿ç”¨ Autoregressiveï¼ˆARï¼‰è§£ç ä½œä¸ºåŸºç¡€ã€‚ç„¶è€Œï¼Œéšç€ Diffusion Large Language Modelsï¼ˆDLLMsï¼‰çš„å…´èµ·ï¼Œä½œè€…æå‡ºä¸€ä¸ªæ ¸å¿ƒé—®é¢˜ï¼šå½“ä¿æŒç›¸åŒçš„ Agent å·¥ä½œæµå’Œç›‘ç£ä¿¡å·æ—¶ï¼Œä»…æ›´æ¢ç”ŸæˆèŒƒå¼ä¸º diffusion æ˜¯å¦ä¼šç³»ç»Ÿæ€§åœ°æ”¹å˜ Agent çš„è§„åˆ’ã€å·¥å…·è°ƒç”¨å’Œæ‰§è¡Œæ•ˆç‡ï¼Ÿ

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
ä½œè€…æå‡ºäº† **DLLM Agent**â€”â€”å°† Diffusion LLM é›†æˆåˆ°æ ‡å‡† Agent æµç¨‹ä¸­çš„æ–°å‹ä»£ç†æ¶æ„ï¼Œå¹¶è¿›è¡Œäº†ä»¥ä¸‹å…³é”®åˆ›æ–°ï¼š

- **Agent-Oriented Fine-Tuning**ï¼šé’ˆå¯¹ DLLM è®¾è®¡äº†é¢å‘ç»“æ„åŒ–åŠ¨ä½œå†³ç­–çš„å¾®è°ƒç›®æ ‡ï¼Œä»¥é€‚é…å¤šè½®äº¤äº’ä»»åŠ¡ã€‚
- **Multi-turn Diffusion Masking Strategy**ï¼š
  - **Context-Clean Corruption**ï¼šåªå¯¹åŠ¨ä½œæ®µè¿›è¡Œå™ªå£°æ‰°åŠ¨ï¼Œä¿ç•™ä¸Šä¸‹æ–‡å®Œæ•´ï¼Œé¿å…è®­ç»ƒ-æ¨ç†ä¸ä¸€è‡´ã€‚
  - **Span-Aware Attention Alignment**ï¼šè°ƒæ•´æ³¨æ„åŠ›æ©ç ï¼Œé˜²æ­¢è·¨ context å’Œ action çš„è™šå‡ä¿¡æ¯æµåŠ¨ã€‚
- **æ­ç¤ºäº† Diffusion èŒƒå¼çš„å†…åœ¨åè°ƒæœºåˆ¶**ï¼šé€šè¿‡åˆ†æ attention åŠ¨æ€ï¼Œå‘ç° DLLM åœ¨æ—©æœŸé˜¶æ®µå³è¡¨ç°å‡ºæ›´å¼ºçš„å…¨å±€è§„åˆ’èƒ½åŠ›ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
ç›¸æ¯”ä¼ ç»Ÿçš„ AR Agentï¼ŒDLLM Agent å±•ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼š
- æ›´å¿«çš„ç«¯åˆ°ç«¯è¿è¡Œé€Ÿåº¦ï¼ˆå¹³å‡ >30%ï¼Œæœ€é«˜è¾¾ 8Ã— åŠ é€Ÿï¼‰
- æ›´å°‘çš„äº¤äº’è½®æ¬¡å’Œå·¥å…·è°ƒç”¨æ¬¡æ•°
- æ›´æ—©æ”¶æ•›åˆ°æ­£ç¡®è·¯å¾„ï¼Œå‡å°‘å›æº¯ä¸å†—ä½™æ“ä½œ
- æ”¯æŒè¿­ä»£ä¼˜åŒ–ä¸å…¨å±€ç»“æ„è°ƒæ•´ï¼Œè€Œéå±€éƒ¨ä¸å¯é€†æ‰¿è¯º

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
- **BROWSECOMP-ZH**ï¼šä¸€ä¸ªå…¬å¼€çš„ä¸­æ–‡å¤šè½®ç½‘é¡µæµè§ˆåŸºå‡†ï¼Œè¦æ±‚æ¨¡å‹é€šè¿‡å¤šæ¬¡æ£€ç´¢ã€æ¨ç†åŠ¨æ€è¯æ®æ¥å›ç­”å¤æ‚æŸ¥è¯¢ã€‚
- **Open-Ended Qualitative Prompts**ï¼šä¸€ç»„è‡ªå®šä¹‰çš„å¼€æ”¾å¼å¤šæ­¥ç ”ç©¶é—®é¢˜ï¼Œç”¨äºå®šæ€§åˆ†æé•¿æœŸæ¨ç†ã€å·¥å…·é“¾æ„å»ºå’Œå¤±è´¥æ¨¡å¼ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
æ‰€æœ‰ Agent å‡åŸºäº **DeepDiver** å¤šæ™ºèƒ½ä½“æ¡†æ¶å®ç°ï¼Œå…·å¤‡ç»Ÿä¸€çš„ Plannerã€Information Seeker å’Œ Writer è§’è‰²åˆ†å·¥åŠå·¥å…·æ¥å£ã€‚

#### æ§åˆ¶å˜é‡
- ç»Ÿä¸€çš„ Agent æ¶æ„ã€å·¥å…·é›†ï¼ˆå¦‚ `web_search`, `document_qa`ï¼‰ã€prompt æ¨¡æ¿ã€çŠ¶æ€åºåˆ—åŒ–æ–¹å¼
- ç›¸åŒçš„è®­ç»ƒè½¨è¿¹æ•°æ®å’Œä¼˜åŒ–é¢„ç®—ï¼ˆ5 epochs, lr ä» 5e-6 è¡°å‡ï¼‰
- ç›¸åŒçš„è¯„ä¼°çº¦æŸï¼š
  - ä¸Šä¸‹æ–‡é•¿åº¦ä¸Šé™ï¼š32K tokens
  - æœ€å¤§äº¤äº’è½®æ•° $T_{max}=15$
  - æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶
  - ç»Ÿä¸€çš„ fallback ç»ˆæ­¢ç­–ç•¥

#### è¯„ä¼°æŒ‡æ ‡
| ç±»åˆ« | æŒ‡æ ‡ |
|------|------|
| **æœ€ç»ˆå‡†ç¡®æ€§** | Answer Accuracy (%) |
| **å·¥ä½œæµæ•ˆç‡** | å¹³å‡å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼ˆTool Callsï¼‰ã€å¹³å‡äº¤äº’è½®æ•°ï¼ˆTurns Usedï¼‰ |
| **ç¨³å®šæ€§** | Invalid Action Rateï¼ˆæ— æ³•è§£æçš„åŠ¨ä½œæ¯”ä¾‹ï¼‰ |
| **æ•ˆç‡å¢ç›Š** | ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆwall-clock timeï¼‰ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **AR Agent** | ä½¿ç”¨ autoregressive æ¨¡å‹ `openPangu-Embedded-7B` ä½œä¸º backboneï¼Œå·¦å‘é€è¯ç”Ÿæˆæ¯ä¸ªåŠ¨ä½œæ®µ |
| **DLLM Agent** | ä½¿ç”¨ diffusion æ¨¡å‹ `openPangu-R-7B-Diffusion`ï¼Œé€šè¿‡è¿­ä»£å»å™ªç”Ÿæˆç»“æ„åŒ–åŠ¨ä½œ |
| **æ¶ˆèå˜ä½“** | ç§»é™¤ context-clean corruption æˆ– span-aware attention alignment çš„ç‰ˆæœ¬ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª BROWSECOMP-ZH å­é›†æµ‹è¯•ï¼‰

| Method | Accuracy (%) | Tool Calls â†“ | Turns Used â†“ | Invalid Action Rate â†‘ |
|--------|---------------|--------------|----------------|-------------------------|
| AR Agent | 15.5 | 7.5 | 14.8 | 1.9% |
| DLLM Agent | 15.5 | **6.7** | **13.0** | 6.4% |
| w/o context-clean corruption | 14.5 | 6.8 | 15.0 | 6.2% |
| w/o span-aware attention alignment | 14.5 | 7.1 | 14.6 | 7.1% |

> æ³¨ï¼šå‡†ç¡®ç‡ç›¸åŒï¼Œä½† DLLM Agent æ˜¾è‘—å‡å°‘äº† **10.7% çš„å·¥å…·è°ƒç”¨** å’Œ **12.2% çš„äº¤äº’è½®æ•°**

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ç«¯åˆ°ç«¯æ•ˆç‡æå‡**ï¼š
  - åœ¨å¤šä¸ªæ¡ˆä¾‹ä¸­ï¼ŒDLLM Agent å®ç°äº† **è¶…è¿‡ 30% çš„å¹³å‡åŠ é€Ÿ**
  - æŸäº›ç‰¹å®šä»»åŠ¡ä¸Šè¾¾åˆ° **8.18Ã— çš„ wall-clock speedup**
- **è¡Œä¸ºå·®å¼‚æ˜æ˜¾**ï¼š
  - AR Agent å€¾å‘äºâ€œé€æ­¥æ¨è¿› + åå¤éªŒè¯â€ï¼Œäº§ç”Ÿå¤§é‡ä¸­é—´æ–‡ä»¶ï¼ˆå¦‚ `todo_v1.md`, `todo_v2.md`ï¼‰ï¼Œæ˜“é™·å…¥å†—ä½™å¾ªç¯
  - DLLM Agent æ›´å€¾å‘äºä¸€æ¬¡æ€§åˆ¶å®šæ¸…æ™°çš„ç ”ç©¶åˆåŒï¼ˆresearch contractï¼‰ï¼Œç›´æ¥æ‰§è¡Œå¹¶å¿«é€Ÿé—­ç¯
- **æ¡ˆä¾‹å¯¹æ¯”ç¤ºä¾‹ï¼ˆåŒä¸€æŸ¥è¯¢ï¼‰**ï¼š
  - **DLLM Agent**ï¼šå®Œæˆæ—¶é—´ **140.95s**ï¼Œä»…éœ€ 4 æ­¥åŠ¨ä½œ
  - **AR Agent**ï¼šå®Œæˆæ—¶é—´ **1152.68s**ï¼ˆæ…¢ 8.18 å€ï¼‰ï¼Œæ¶‰åŠ 6+ æ¬¡ä¿¡æ¯è·å–ä¸å¤šæ¬¡é‡éªŒè¯

### æ¶ˆèå®éªŒç»“æœ
- ç§»é™¤ä»»ä¸€ masking ç­–ç•¥ï¼ˆcontext-clean corruption æˆ– span-aware attentionï¼‰å‡å¯¼è‡´ï¼š
  - å‡†ç¡®ç‡ä¸‹é™çº¦ 1%
  - å·¥å…·è°ƒç”¨å’Œäº¤äº’è½®æ•°å¢åŠ 
  - è¡¨æ˜è¿™ä¸¤ç§ masking å¯¹é½ç­–ç•¥å¯¹äºç¨³å®šå¤šè½® Agent æ¨ç†è‡³å…³é‡è¦

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. âœ… **ç”ŸæˆèŒƒå¼æœ¬èº«æ·±åˆ»å½±å“ Agent è¡Œä¸º**  
   å³ä½¿åœ¨å®Œå…¨ç›¸åŒçš„ workflowã€è®­ç»ƒæ•°æ®å’Œå·¥å…·æ¥å£ä¸‹ï¼Œ**DLLM Agent ä»è¡¨ç°å‡ºæ›´é«˜æ•ˆã€æ›´ç´§å‡‘çš„è¡Œä¸ºæ¨¡å¼**ï¼Œè¯´æ˜å…¶ä¼˜åŠ¿æºäºç”Ÿæˆæœºåˆ¶çš„æœ¬è´¨å·®å¼‚ã€‚

2. ğŸ” **DLLM å…·å¤‡æ›´å¼ºçš„å…¨å±€è§„åˆ’èƒ½åŠ›ï¼ˆGlobal Planning Signalï¼‰**  
   - åˆ†ææ˜¾ç¤ºï¼ŒDLLM åœ¨æ—©æœŸæ‰©æ•£æ­¥éª¤å³å¯å¹¶è¡Œæå–å…³é”®çº¦æŸæ¡ä»¶ï¼Œå»ºç«‹æ•´ä½“è®¡åˆ’æ¡†æ¶
   - AR æ¨¡å‹å¿…é¡»é¡ºåºæ‰¿è¯ºï¼Œéš¾ä»¥ä¿®æ­£æ—©æœŸé”™è¯¯ï¼Œå¯¼è‡´æ›´å¤šå›æº¯ä¸å†—ä½™

3. âš™ï¸ **æ•ˆç‡å¢ç›Šä¸ä»…æ¥è‡ª token-level å¹¶è¡Œï¼Œæ›´ä½“ç°åœ¨ workflow-level ä¼˜åŒ–**  
   - å°½ç®¡ DLLM æ”¯æŒå¹¶è¡Œ token ç”Ÿæˆï¼Œä½†çœŸæ­£çš„åŠ é€Ÿæ¥è‡ªäºï¼š
     - æ›´å°‘çš„å·¥å…·è°ƒç”¨
     - æ›´çŸ­çš„äº¤äº’è½¨è¿¹
     - æ›´ä½çš„åè°ƒå¼€é”€ï¼ˆå¦‚æ— éœ€åå¤ç”Ÿæˆ plan æ–‡ä»¶ï¼‰

4. ğŸ§© **Diffusion Agent è¡¨ç°å‡ºâ€œå…ˆå…¨å±€ã€åå±€éƒ¨â€çš„å†³ç­–é£æ ¼**  
   - Planner Agentï¼šå…ˆå¹¶è¡Œè¯†åˆ«æ‰€æœ‰çº¦æŸ â†’ å†åˆ†è§£ä»»åŠ¡
   - Information Seekerï¼šå…ˆç¡®å®šå·¥å…·ç±»å‹ â†’ å†å¡«å……å‚æ•°
   - è¿™ç§ä¸¤é˜¶æ®µæ¨¡å¼å‡å°‘äº†å› æ—©æœŸè¯¯åˆ¤å¯¼è‡´çš„åç»­çº é”™æˆæœ¬

5. âš ï¸ **éƒ¨ç½²æŒ‘æˆ˜ï¼šStructured Output çš„å¯é æ€§é—®é¢˜**  
   - DLLM Agent çš„ **Invalid Action Rate æ›´é«˜ï¼ˆ6.4% vs 1.9%ï¼‰**ï¼Œè¡¨æ˜å…¶æ›´å®¹æ˜“è¾“å‡ºæ ¼å¼é”™è¯¯çš„ tool call
   - éœ€è¦åŠ å¼º tool-call-specific training æ‰èƒ½å¯é ç”Ÿæˆåˆæ³• schema

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰å®éªŒé›†ä¸­åœ¨ **DeepDiver æ¡†æ¶ä¸‹çš„æ·±åº¦æ£€ç´¢ç±»ä»»åŠ¡**ï¼Œå°šæœªéªŒè¯åœ¨æ›´é•¿å‘¨æœŸã€éƒ¨åˆ†å¯è§‚æµ‹ç¯å¢ƒï¼ˆå¦‚ WebArenaï¼‰ä¸­çš„æ³›åŒ–æ€§
- DLLM å¯¹ structured output çš„ç¨³å®šæ€§ä»å¼±äº ARï¼Œéœ€è¦é¢å¤–è®­ç»ƒå¹²é¢„
- æ‰€æœ‰è®­ç»ƒä¾èµ–äºä» AR Agent å›æ”¾çš„è½¨è¿¹ï¼Œæœªæ¢ç´¢ diffusion-native çš„è®­ç»ƒèŒƒå¼
- æ¨¡å‹è§„æ¨¡è¾ƒå°ï¼ˆ7B çº§åˆ«ï¼‰ï¼Œå°šä¸æ¸…æ¥šæ›´å¤§è§„æ¨¡ä¸‹æ€§èƒ½å·®è·æ˜¯å¦ä¼šæ‰©å¤§

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ¢ç´¢ diffusion-native training objectives**  
   åˆ©ç”¨è¿­ä»£ refine ç‰¹æ€§ï¼Œè®¾è®¡æ˜¾å¼çš„ latent planningã€trajectory-level noise schedule ç­‰è®­ç»ƒç›®æ ‡ã€‚

2. **ç ”ç©¶æ··åˆæ¶æ„ï¼ˆHybrid Agentsï¼‰**  
   ç»“åˆ diffusion ä¸ AR çš„ä¼˜åŠ¿ï¼šç”± DLLM è´Ÿè´£é«˜å±‚è§„åˆ’ä¸å‡è®¾æ•´åˆï¼ŒAR æ¨¡å‹è´Ÿè´£ç»†ç²’åº¦æ‰§è¡Œä¸äº¤äº’ã€‚

3. **æ‰©å±•è‡³æ›´å¤æ‚çš„ Agent åœºæ™¯**  
   å¦‚ long-horizon planningã€embodied agentsã€multi-agent collaboration ç­‰æ›´å…·æŒ‘æˆ˜æ€§çš„è®¾å®šã€‚

4. **æ·±å…¥æœºåˆ¶åˆ†æ**  
   é€šè¿‡å› æœå¹²é¢„ï¼ˆcausal interventionï¼‰ã€æ³¨æ„åŠ› ablation ç­‰æ‰‹æ®µï¼Œè¿›ä¸€æ­¥å˜æ¸… bidirectional conditioning ä¸ iterative refinement å¦‚ä½•å¡‘é€  Agent å†³ç­–è¡Œä¸ºã€‚

5. **æå‡ structured output å¯é æ€§**  
   å¼€å‘ä¸“é—¨é’ˆå¯¹ tool-call çš„ diffusion è§£ç çº¦æŸæœºåˆ¶ï¼Œé™ä½ invalid action ç‡ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬ç ”ç©¶è¡¨æ˜ï¼Œ**Diffusion ä¸åªæ˜¯ä¸€ä¸ªæ›´å¿«çš„ç”Ÿæˆå™¨ï¼Œè€Œæ˜¯ä¸€ç§èƒ½å‚¬ç”Ÿæ›´èªæ˜ã€æ›´é«˜æ•ˆ Agent çš„å…¨æ–°èŒƒå¼**ã€‚å®ƒè®© Agent â€œçœ‹å¾—æ›´è¿œâ€ï¼ˆsee fartherï¼‰ï¼Œä»è€Œâ€œè·‘å¾—æ›´å¿«â€ï¼ˆrun fasterï¼‰ã€‚

</details>

---

### 4. [SpecAttn: Co-Designing Sparse Attention with Self-Speculative Decoding](https://arxiv.org/abs/2602.07223)

**Authors**: Yikang Yue, Yuqi Xue, Jian Huang  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2602.07223v1  

#### Abstract
Long-context large language model (LLM) inference has become the norm for today's AI applications. However, it is severely bottlenecked by the increasing memory demands of its KV cache. Previous works have shown that self-speculative decoding with sparse attention, where tokens are drafted using a s...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šSpecAttn: Co-Designing Sparse Attention with Self-Speculative Decoding**

---

## 1. **è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### âœ… **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

åœ¨é•¿ä¸Šä¸‹æ–‡ Large Language Model (LLM) æ¨ç†ä¸­ï¼Œ**KV Cache çš„å†…å­˜è®¿é—®å¼€é”€**æˆä¸ºä¸»è¦æ€§èƒ½ç“¶é¢ˆã€‚å°½ç®¡ç¨€ç–æ³¨æ„åŠ›ï¼ˆSparse Attentionï¼‰å¯å‡å°‘ KV Cache è®¿é—®é‡ï¼Œæå‡æ¨ç†é€Ÿåº¦ï¼Œä½†å…¶ç‹¬ç«‹é€‰æ‹©å…³é”® KV æ¡ç›®çš„ç­–ç•¥å¾€å¾€å¯¼è‡´ï¼š

- **Drafting å‡†ç¡®ç‡ä½**ï¼ˆå³ç”Ÿæˆçš„è‰ç¨¿ token è¢«æ‹’ç»ç‡é«˜ï¼‰
- æˆ–è€…å¼•å…¥**é«˜æ˜‚çš„ KV Selection å¼€é”€**ï¼ˆå¦‚ query-aware æ–¹æ³•éœ€æ¯æ­¥é‡æ–°è®¡ç®—é‡è¦æ€§ï¼‰

æ­¤å¤–ï¼Œç°æœ‰è‡ªæ¨æµ‹è§£ç ï¼ˆself-speculative decodingï¼‰æ¡†æ¶å°† drafting å’Œ verification è§†ä¸ºä¸¤ä¸ªç‹¬ç«‹é˜¶æ®µï¼Œ**å¿½ç•¥äº† verification é˜¶æ®µä¸­ full attention è‡ªç„¶äº§ç”Ÿçš„ attention logits å¯ä½œä¸ºâ€œå…è´¹çš„ oracleâ€æ¥æŒ‡å¯¼åç»­ drafting çš„ KV é€‰æ‹©**ã€‚

---

### ğŸš€ **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **SpecAttn** â€”â€”ä¸€ç§**éªŒè¯å¼•å¯¼çš„ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶**ï¼ˆverification-guided sparse attentionï¼‰ï¼Œé€šè¿‡**ååŒè®¾è®¡ drafting ä¸ verification é˜¶æ®µ**ï¼Œå®ç°é«˜æ•ˆä¸”å‡†ç¡®çš„ self-speculative decodingã€‚

#### æ ¸å¿ƒæ€æƒ³ï¼š
> åˆ©ç”¨ **verification é˜¶æ®µæ‰§è¡Œ full attention æ—¶è‡ªç„¶äº§ç”Ÿçš„ attention logits**ï¼Œè¯†åˆ«å‡ºå¯¹å½“å‰ draft token åºåˆ—æœ€å…³é”®çš„å†å² KV æ¡ç›®ï¼Œå¹¶å°†å…¶ç”¨äºä¸‹ä¸€è½® drafting çš„ sparse attention ä¸­ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š

1. **Verification-Guided KV Selection**  
   - ä¸å†ä¾èµ–ç‹¬ç«‹ç®—æ³•é€‰æ‹© KVï¼Œè€Œæ˜¯åˆ©ç”¨ verification çš„ä¸­é—´ç»“æœï¼ˆattention logitsï¼‰åŠ¨æ€è¯†åˆ«å…³é”® KVã€‚
   - é€‰æ‹©æ ‡å‡†æ˜¯æœ€å¤§åŒ–æ‰€æœ‰ draft tokensï¼ˆåŒ…æ‹¬è¢«æ¥å—å’Œè¢«ä¸¢å¼ƒçš„ï¼‰çš„ç´¯è®¡ attention logit è¦†ç›–èŒƒå›´ï¼Œé¿å…è¿‡æ‹Ÿåˆå•ä¸ª token çš„æ³¨æ„åŠ›æ¨¡å¼ã€‚

2. **Collect-2-Query æœºåˆ¶**  
   - ä¸ºé™ä½æ”¶é›† attention logits çš„å¸¦å®½å¼€é”€ï¼Œä»…ä» **ç¬¬ä¸€ä¸ª draft token å’Œ bonus token** æ”¶é›† logitsã€‚
   - è¿™ä¸¤ä¸ª token å…·æœ‰æœ€å¤§ä½ç½®è·ç¦»ï¼Œèƒ½æœ‰æ•ˆä»£è¡¨æ•´ä¸ª draft chain çš„å¤šæ ·æ€§ï¼Œæ˜¾è‘—é™ä½ HBM å¸¦å®½å‹åŠ›ã€‚

3. **ä½å¼€é”€é›†æˆäº vLLM**  
   - å®ç°ä¸ºä¸€ä¸ªæ— éœ€è®­ç»ƒã€å³æ’å³ç”¨çš„æ¨¡å—ï¼Œé›†æˆåˆ°ä¸»æµæ¨ç†å¼•æ“ **vLLM** ä¸­ã€‚
   - ä¿®æ”¹ FlashAttention-3 å†…æ ¸ä»¥æ”¯æŒ logits æ”¶é›†ï¼Œä¸å½±å“åŸå§‹æ€§èƒ½ã€‚

4. **ç³»ç»ŸåŒ–è¶…å‚æ•°è°ƒä¼˜ç­–ç•¥**  
   - æå‡ºä¸‰æ­¥è°ƒå‚æ³•ï¼šå…ˆç¡®å®šæœ€ä¼˜ sparse ratio â†’ å†ä¼˜åŒ– draft æ•°é‡ $ y $ â†’ æœ€åå¾®è°ƒå¹³è¡¡å»¶è¿Ÿä¸ç²¾åº¦ã€‚

---

### ğŸ” **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ MagicDec + Questï¼‰ | SpecAttn |
|------|-------------------------------|--------|
| **KV Selection å‡†ç¡®æ€§** | ä¾èµ–å®æ—¶ query-aware è®¡ç®—ï¼Œå¯èƒ½æ»å | åˆ©ç”¨ full attention â€œçœŸå®åé¦ˆâ€ï¼Œæ›´ç²¾å‡† |
| **KV Selection å¼€é”€** | æ¯æ­¥é‡ä¼°ï¼Œé«˜è®¡ç®—/å†…å­˜å¼€é”€ | å¤ç”¨å·²æœ‰ä¿¡æ¯ï¼ŒCollect-2-Query æä½å¼€é”€ |
| **Drafting Accuracy** | å—é™äºå›ºå®šæ¨¡å¼æˆ–å±€éƒ¨ä¼°è®¡ | å¤š token è”åˆèšåˆï¼Œæ¥å—ç‡æ›´é«˜ã€è¡°å‡æ…¢ |
| **ç«¯åˆ°ç«¯ååé‡** | é«˜å¼€é”€æŠµæ¶ˆå‡†ç¡®æ€§å¢ç›Š | å®ç°æ›´é«˜ throughput æå‡ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šSpecAttn åœ¨ä¿æŒ lossless è¾“å‡ºè´¨é‡çš„å‰æä¸‹ï¼Œå®ç°äº†æ›´é«˜çš„ **draft token æ¥å—ç‡** å’Œæ›´ä½çš„ **KV selection å¼€é”€**ï¼Œä»è€Œå¤§å¹…æå‡ decoding throughputã€‚

---

## 2. **æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### ğŸ“š **ä½¿ç”¨çš„æ•°æ®é›†**

| æ•°æ®é›† | ç‰¹ç‚¹ |
|-------|------|
| **AIME25** | æ•°å­¦æ¨ç†ä»»åŠ¡ï¼Œè¾“å…¥çŸ­ï¼ˆ~182 tokensï¼‰ï¼Œè¾“å‡ºé•¿ï¼ˆ~19.7K tokensï¼‰ |
| **CodeElo** | ç¼–ç¨‹ä»£ç ç”Ÿæˆä»»åŠ¡ï¼ŒåŒæ ·çŸ­è¾“å…¥ã€é•¿è¾“å‡º |
| **LongBench-v2** | ç»¼åˆé•¿ä¸Šä¸‹æ–‡ç†è§£ä¸æ¨ç†åŸºå‡†ï¼Œè¾“å…¥é•¿åº¦é«˜è¾¾ 96Kâ€“120K tokens |

---

### âš™ï¸ **å®éªŒè®¾ç½®**

- **æ¨¡å‹**ï¼š
  - Qwen3-4B, Qwen3-8B, Qwen3-30B
  - gpt-oss-20bï¼ˆMXFP4é‡åŒ–ï¼ŒMoEæ¶æ„ï¼‰
- **ç¡¬ä»¶å¹³å°**ï¼š
  - åŒ NVIDIA H100 NVL GPUï¼ˆ94GB æ˜¾å­˜ï¼‰
- **æ‰¹å¤§å°ï¼ˆBatch Sizeï¼‰**ï¼š
  - æ ¹æ®æ¨¡å‹å®¹é‡è°ƒæ•´ï¼ˆå¦‚ 4~20ï¼‰ï¼Œç¡®ä¿é¥±å’Œ KV Cache åˆ©ç”¨
- **ä¸Šä¸‹æ–‡é•¿åº¦**ï¼š
  - æœ€é•¿è¾¾ 128K tokens
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Decoding Throughput (tokens/sec)**ï¼šæ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡
  - **Average Accepted Draft Tokens per Iteration**ï¼šè¡¡é‡ drafting å‡†ç¡®æ€§
  - **KV Selection Overhead (%)**ï¼šç›¸å¯¹äºç†æƒ³è¿­ä»£æ—¶é—´çš„æ¯”ä¾‹
  - **End-to-End Latency Reduction**

---

### ğŸ†š **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿æ–¹æ³• | æè¿° |
|--------|------|
| **vLLM (default)** | Vanilla auto-regressive decodingï¼ŒåŸºç¡€ baseline |
| **MagicDec-Stream** | ä½¿ç”¨ StreamingLLMï¼ˆæ»‘åŠ¨çª—å£ï¼‰ä½œä¸º query-agnostic sparse attention |
| **MagicDec-Quest** | ä½¿ç”¨ Questï¼ˆquery-awareï¼‰è¿›è¡Œ KV selection |
| **SpecExtend** | åˆ©ç”¨ last accepted token çš„ attention weights å¼•å¯¼ draft model çš„ sparsity |

> æ‰€æœ‰æ–¹æ³•å‡åœ¨ **vLLM æ¡†æ¶å†…ç»Ÿä¸€å®ç°**ï¼Œä¿è¯å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. **ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### ğŸ“ˆ **å…³é”®æ€§èƒ½æ•°æ®**

| æ–¹æ³• | ç›¸å¯¹äº vLLM çš„åŠ é€Ÿæ¯” | ç›¸å¯¹äº SOTA çš„åŠ é€Ÿæ¯” |
|------|---------------------|--------------------|
| **SpecAttn** | **1.25Ã— â€“ 2.81Ã—** | **1.18Ã— â€“ 1.29Ã—** æå‡ |

å…·ä½“è¡¨ç°å¦‚ä¸‹ï¼š

#### â–¶ åœ¨ **Short Input + Long Output** åœºæ™¯ï¼ˆAIME25 / CodeEloï¼‰

- **Throughput æå‡**ï¼š
  - SpecAttn è¾¾åˆ° **1.25Ã— â€“ 2.70Ã—** ä¼˜äºé»˜è®¤ vLLM
  - æ¯” MagicDec-Stream å¿« **1.15Ã— â€“ 1.23Ã—**
  - æ¯” MagicDec-Quest æ›´å¿«ï¼ˆåè€…å› é«˜å¼€é”€åè¢«æ‹–ç´¯ï¼‰

- **Drafting Accuracy**ï¼š
  - SpecAttn å¹³å‡æ¯è½®æ¥å— **6.1+ ä¸ª draft tokens**ï¼ˆ$ y=7 $ï¼‰
  - æ˜¾è‘—é«˜äº MagicDec-Quest å’Œ SpecExtend

- **KV Selection Overhead**ï¼š
  - SpecAttn ä»…å¢åŠ  **5.9% â€“ 9.4%** å¼€é”€
  - è¿œä½äº MagicDec-Questï¼ˆ21.7%ï¼‰å’Œ SpecExtendï¼ˆ11.2% ~ 29.1%ï¼‰

#### â–¶ åœ¨ **Long Context** åœºæ™¯ï¼ˆLongBench-v2ï¼‰

- æ€§èƒ½ä¼˜åŠ¿è¿›ä¸€æ­¥æ”¾å¤§ï¼š
  - SpecAttn å®ç°æœ€é«˜è¾¾ **2.81Ã—** åŠ é€Ÿï¼ˆvs vLLMï¼‰
  - æ¯”æœ€å¼º baseline å¿« **1.29Ã—**
  - å› å…¶ KV selection ç­–ç•¥èƒ½æ›´å¥½ä¿ç•™å†å²ä¸Šä¸‹æ–‡ç›¸å…³æ€§

---

### ğŸ”¬ **æ¶ˆèå®éªŒç»“æœ**

#### ï¼ˆ1ï¼‰KV Selection ç­–ç•¥å¯¹æ¯”ï¼ˆå›¾4ï¼‰

| ç­–ç•¥ | æ¥å—ç‡è¶‹åŠ¿ |
|------|----------|
| Last Accepted Token Only | åˆæœŸé«˜ï¼ŒåæœŸè¿…é€Ÿä¸‹é™ï¼ˆè¿‡æ‹Ÿåˆï¼‰ |
| All Draft Tokensï¼ˆå« rejectedï¼‰ | æ¥å—ç‡ç¨³å®šé«˜ä½ï¼Œæ— æ˜æ˜¾è¡°å‡ |

âœ… ç»“è®ºï¼š**è”åˆå¤šä¸ª draft tokens çš„ attention logits å¯æ˜¾è‘—ç¼“è§£æ¥å—ç‡è¡°å‡é—®é¢˜**ã€‚

#### ï¼ˆ2ï¼‰Collect-2-Query vs Collect-All-Queryï¼ˆå›¾6 & è¡¨1ï¼‰

| æ–¹æ³• | ååå½±å“ | æ¥å— token æ•° |
|------|---------|--------------|
| Collect All Query Tokens | +53% ~ +189% å¼€é”€ | 6.13 (Qwen3-8B) |
| **Collect-2-Query** | **+5% ~ +37% å¼€é”€** | **6.11**ï¼ˆå‡ ä¹æ— æŸï¼‰ |

âœ… ç»“è®ºï¼š**ä»…æ”¶é›†é¦–å°¾ä¸¤ä¸ª token çš„ logits å³å¯è¾¾åˆ°æ¥è¿‘å…¨é‡æ”¶é›†çš„æ•ˆæœï¼Œæ€§ä»·æ¯”æé«˜**ã€‚

#### ï¼ˆ3ï¼‰æ˜¯å¦åŒ…å« rejected tokensï¼ˆÂ§3.2ï¼‰

- ç§»é™¤ rejected tokens å¯¼è‡´å¹³å‡æ¥å—æ•°ä¸‹é™ **3% â€“ 14%**ï¼ˆå½“ $ y=7 $ï¼‰
- åŸå› ï¼šè®¸å¤š rejected tokens å®é™…è¯­ä¹‰åˆç†ï¼Œå…¶ attention pattern ä»æœ‰ä»·å€¼

âœ… ç»“è®ºï¼š**rejected tokens åŒ…å«æœ‰ç”¨ä¸Šä¸‹æ–‡ä¿¡å·ï¼Œåº”çº³å…¥ KV selection**

---

## 4. **å…³é”®ç»“è®ºå’Œå‘ç°**

### âœ… **ä¸»è¦å‘ç°**

1. **Verification é˜¶æ®µä¸ä»…æ˜¯éªŒè¯å™¨ï¼Œæ›´æ˜¯â€œæŒ‡å¯¼è€…â€**  
   > å…¶å†…éƒ¨è®¡ç®—çš„ attention logits æ˜¯é«˜è´¨é‡çš„ KV criticality ä¿¡å·ï¼Œå¯ç”¨äºæŒ‡å¯¼åç»­ draftingï¼Œå½¢æˆé—­ç¯åé¦ˆã€‚

2. **Co-design æ˜¯çªç ´æ€§èƒ½ç“¶é¢ˆçš„å…³é”®**  
   > å°† drafting ä¸ verification è€¦åˆè®¾è®¡ï¼Œè€Œéå­¤ç«‹å¤„ç†ï¼Œå¯åœ¨ä¸ç‰ºç‰²è´¨é‡çš„æƒ…å†µä¸‹è·å¾—æ›´é«˜æ•ˆç‡ã€‚

3. **ä½å¼€é”€ â‰  ä½æ€§èƒ½**  
   > Collect-2-Query è¯æ˜ï¼šç²¾å¿ƒé€‰å–è¾¹ç•Œ token å³å¯æ•è·è¶³å¤Ÿä¿¡æ¯ï¼Œå®ç°è¿‘ä¼¼æœ€ä¼˜æ€§èƒ½çš„åŒæ—¶æå¤§é™ä½å¸¦å®½æˆæœ¬ã€‚

4. **SpecAttn çš„æ”¶ç›Šéš context length å¢åŠ è€Œæ‰©å¤§**  
   > åœ¨ç™¾ä¸‡çº§ token ä¸Šä¸‹æ–‡ä¸­ï¼ŒKV Cache å‹åŠ›æ›´å¤§ï¼ŒSpecAttn çš„ä¼˜åŠ¿å°†æ›´åŠ æ˜¾è‘—ã€‚

---

### âš ï¸ **æ–¹æ³•çš„å±€é™æ€§**

1. **ä¾èµ– full attention verification çš„å®Œæ•´æ€§**  
   - è‹¥ verification è¢«å‰ªææˆ–è·³è¿‡ï¼ˆå¦‚ layer-skippingï¼‰ï¼Œåˆ™æ— æ³•è·å–å®Œæ•´ logits
   - ä½†å¯ä¸å…¶ä»–ä¼˜åŒ–æŠ€æœ¯ï¼ˆå¦‚ LayerSkipï¼‰ç»“åˆä½¿ç”¨

2. **å¯¹ MoE ç±»æ¨¡å‹å¢ç›Šæœ‰é™**  
   - å¦‚ gpt-oss-20b ä»…æœ‰éƒ¨åˆ† block ä½¿ç”¨ full attentionï¼Œsparse attention èŠ‚çœç©ºé—´è¾ƒå°
   - å¯¼è‡´ overall speedup ç›¸å¯¹è¾ƒä½

3. **FlashAttention å†…æ ¸ä¿®æ”¹å¸¦æ¥éƒ¨ç½²å¤æ‚åº¦**  
   - éœ€è¦å®šåˆ¶ kernel æ”¯æŒ logits dumpï¼Œè™½å·²å¼€æºä½†ä»æœ‰ä¸€å®šå·¥ç¨‹é—¨æ§›

---

### ğŸ”® **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ‰©å±•è‡³å¤šæ¨¡æ€ LLM**  
   - å°† verification-guided sparse attention åº”ç”¨äº Video-LLM æˆ– Vision-Language Models

2. **åŠ¨æ€è°ƒæ•´ sparse ratio ä¸ $ y $**  
   - æ ¹æ®è¾“å…¥å†…å®¹è‡ªåŠ¨è°ƒèŠ‚ hyperparametersï¼Œå®ç° adaptive speculation

3. **ç»“åˆ KV Cache å‹ç¼©æŠ€æœ¯**  
   - ä¸ SnapKVã€H2O ç­‰å‹ç¼©æ–¹æ³•èåˆï¼Œè¿›ä¸€æ­¥é™ä½å†…å­˜å ç”¨

4. **æ”¯æŒåˆ†å¸ƒå¼æ¨ç†åœºæ™¯**  
   - åœ¨ tensor/pipeline parallel è®¾ç½®ä¸‹å®ç°è·¨è®¾å¤‡ logits æ”¶é›†ä¸åŒæ­¥

---

## âœ… æ€»ç»“ä¸€å¥è¯

> **SpecAttn é€šè¿‡å°† self-speculative decoding ä¸­çš„ verification é˜¶æ®µâ€œå‰¯äº§å“â€â€”â€”attention logitsâ€”â€”è½¬åŒ–ä¸º drafting é˜¶æ®µçš„æŒ‡å¯¼ä¿¡å·ï¼Œå®ç°äº†é«˜å‡†ç¡®ç‡ã€ä½å¼€é”€çš„ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼Œåœ¨å¤šç§ LLM å’Œé•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ä¸Šå–å¾—é«˜è¾¾ 2.81Ã— çš„ decoding throughput æå‡ï¼Œæ˜¯é¦–ä¸ªçœŸæ­£å®ç° drafting ä¸ verification ååŒè®¾è®¡çš„ lossless åŠ é€Ÿæ–¹æ¡ˆã€‚**

> ğŸ”— é¡¹ç›®å³å°†å¼€æºä¸º vLLM çš„ä¸€é”®è¡¥ä¸ï¼ˆdrop-in patchï¼‰ï¼Œæ¨åŠ¨é«˜æ•ˆ LLM æ¨ç†è½åœ°ã€‚

</details>

---

### 5. [BitLogic: Training Framework for Gradient-Based FPGA-Native Neural Networks](https://arxiv.org/abs/2602.07400)

**Authors**: Simon B\"uhrer, Andreas Plesner, Aczel Till, Roger Wattenhofer  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2602.07400v1  

#### Abstract
The energy and latency costs of deep neural network inference are increasingly driven by deployment rather than training, motivating hardware-specialized alternatives to arithmetic-heavy models. Field-Programmable Gate Arrays (FPGAs) provide an attractive substrate for such specialization, yet exist...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# BitLogic: Training Framework for Gradient-Based FPGA-Native Neural Networks è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å½“å‰æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰æ¨ç†çš„èƒ½è€—å’Œå»¶è¿Ÿå·²æˆä¸ºAIç³»ç»Ÿéƒ¨ç½²çš„ä¸»è¦ç“¶é¢ˆï¼Œå°¤å…¶æ˜¯åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šã€‚ä¼ ç»ŸåŸºäºGPUçš„æ¨ç†è™½ç„¶è®¡ç®—ååé«˜ï¼Œä½†èƒ½æ•ˆä½ï¼›è€Œç°æœ‰çš„FPGAç¥ç»ç½‘ç»œæ–¹æ¡ˆå¤šä¾èµ–äºå°†æ ‡å‡†æ¨¡å‹ï¼ˆå¦‚CNNï¼‰é‡åŒ–åæ˜ å°„åˆ°ç¡¬ä»¶ï¼Œå­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š

- **ç¢ç‰‡åŒ–ä¸”éš¾ä»¥æ¯”è¾ƒ**ï¼šä¸åŒç ”ç©¶é‡‡ç”¨å¼‚æ„ç¡¬ä»¶å¹³å°ã€ä¸åŒçš„æ—¶é’Ÿå‡è®¾å’Œæµ‹é‡æ–¹å¼ï¼Œå¯¼è‡´ç»“æœä¸å¯æ¯”ã€‚
- **éåŸç”Ÿè®¾è®¡**ï¼šå¤šæ•°æ–¹æ³•ä»ä»¥ç®—æœ¯æ“ä½œï¼ˆå¦‚MACï¼‰ä¸ºæ ¸å¿ƒï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨FPGAçš„åº•å±‚é€»è¾‘èµ„æºï¼ˆå¦‚LUTï¼‰ã€‚
- **è½¯ç¡¬ä»¶è„±èŠ‚**ï¼šè®­ç»ƒåœ¨è½¯ä»¶ä¸­è¿›è¡Œï¼Œç¡¬ä»¶å®ç°éœ€æ‰‹åŠ¨è½¬æ¢ï¼Œæ˜“å¼•å…¥è¯¯å·®ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **BitLogic** â€”â€”ä¸€ä¸ª**å…¨æ¢¯åº¦é©±åŠ¨ã€ç«¯åˆ°ç«¯å¯è®­ç»ƒçš„FPGAåŸç”Ÿç¥ç»ç½‘ç»œæ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- **ä»¥LUTä¸ºåŸºæœ¬è®¡ç®—å•å…ƒ**ï¼šç”¨å¯å¾®åˆ†çš„æŸ¥æ‰¾è¡¨ï¼ˆLUTï¼‰èŠ‚ç‚¹æ›¿ä»£ä¼ ç»Ÿçš„ä¹˜ç´¯åŠ ï¼ˆMACï¼‰æ“ä½œï¼Œç›´æ¥å¯¹åº”FPGAä¸­çš„LUTåŸè¯­ã€‚
- **å®Œå…¨å¯å¾®åˆ†è®­ç»ƒ**ï¼šé€šè¿‡å¤šç§è¾¹ç•Œä¸€è‡´çš„è¿ç»­æ¾å¼›æŠ€æœ¯ï¼ˆå¦‚Probabilisticã€Hybridç­‰ï¼‰ï¼Œä½¿ç¦»æ•£LUTå‡½æ•°å¯åœ¨PyTorchä¸­è¿›è¡Œæ¢¯åº¦ä¼˜åŒ–ã€‚
- **è‡ªåŠ¨åŒ–RTLå¯¼å‡º**ï¼šæä¾›ä»è®­ç»ƒå¥½çš„PyTorchæ¨¡å‹è‡ªåŠ¨ç”Ÿæˆç»¼åˆçº§HDLä»£ç çš„æµæ°´çº¿ï¼Œç¡®ä¿è½¯ç¡¬ä»¶æ¨ç†è¡Œä¸ºä¸¥æ ¼ç­‰ä»·ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | BitLogicä¼˜åŠ¿ |
|------|-------------|
| **ç¡¬ä»¶æ•ˆç‡** | ä»…ä½¿ç”¨LUTèµ„æºå³å¯å®ç°äºš20nsçº§å•æ ·æœ¬æ¨ç†ï¼Œæ— éœ€DSPæˆ–BRAMã€‚ |
| **çµæ´»æ€§ä¸æ¨¡å—åŒ–** | æä¾›åŠŸèƒ½APIæ”¯æŒå¤šç§æ¶æ„ï¼ˆFFNã€CNNã€æ®‹å·®ã€æ³¨æ„åŠ›ç­‰ï¼‰è‡ªç”±ç»„åˆã€‚ |
| **å¯å¤ç°æ€§ä¸å…¬å¹³æ¯”è¾ƒ** | ç»Ÿä¸€æ¡†æ¶ä¸‹è¯„ä¼°ä¸åŒLUTèŠ‚ç‚¹ç±»å‹ã€ç¼–ç å™¨ã€å¤´ç»“æ„ï¼Œä¾¿äºæ¶ˆèåˆ†æã€‚ |
| **è½¯ç¡¬ååŒè®¾è®¡** | æ”¯æŒç¡¬ä»¶æ„ŸçŸ¥è®­ç»ƒï¼ˆå¦‚æ¸©åº¦è°ƒèŠ‚é˜²è¿‡æ‹Ÿåˆï¼‰ã€è‡ªåŠ¨HDLç”Ÿæˆä¸éªŒè¯æµç¨‹ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **å›¾åƒåˆ†ç±»ä»»åŠ¡**ï¼š
  - MNISTï¼ˆæ‰‹å†™æ•°å­—ï¼‰
  - Fashion-MNISTï¼ˆæœè£…å›¾åƒï¼‰
  - CIFAR-10 å’Œ CIFAR-100ï¼ˆå½©è‰²å°å›¾ï¼‰

è¿™äº›æ˜¯é€»è¾‘ç¥ç»ç½‘ç»œé¢†åŸŸçš„æ ‡å‡†åŸºå‡†ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹è¡¨è¾¾èƒ½åŠ›å’Œç¡¬ä»¶æ•ˆç‡ã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **æ¨¡å‹é…ç½®**
- **ä¸»å¹²æ¶æ„**ï¼šåˆ†ä¸ºå‰é¦ˆç½‘ç»œï¼ˆFFNï¼‰å’Œå·ç§¯ç½‘ç»œï¼ˆCNNï¼‰ä¸¤ç±»ã€‚
- **LUTèŠ‚ç‚¹è¾“å…¥ç»´åº¦**ï¼šé€šå¸¸è®¾ä¸º4~6ä½ï¼Œæ§åˆ¶æ¯ä¸ªLUTçš„å¤æ‚åº¦ã€‚
- **ç¼–ç å™¨**ï¼šä½¿ç”¨`distributive thermometer encoding`å°†æµ®ç‚¹è¾“å…¥è½¬ä¸ºäºŒè¿›åˆ¶ã€‚
- **è¾“å‡ºå¤´**ï¼šé‡‡ç”¨`GroupSum`æˆ–`GroupedDSP`èšåˆäºŒè¿›åˆ¶ç‰¹å¾ã€‚
- **è®­ç»ƒç­–ç•¥**ï¼šAdamä¼˜åŒ–å™¨ï¼Œ50è½®è®­ç»ƒï¼Œå­¦ä¹ ç‡0.01ï¼Œéƒ¨åˆ†æ¨¡å‹ä½¿ç”¨æƒé‡è¡°å‡ã€‚

#### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰** | æµ‹è¯•é›†ä¸Šçš„åˆ†ç±»ç²¾åº¦ |
| **ç­‰æ•ˆé—¨æ•°ï¼ˆGate Countï¼‰** | ä»¥2^nâˆ’1ä¼°ç®—æ¯ä¸ªnè¾“å…¥LUTçš„ç­‰æ•ˆäºŒè¿›åˆ¶é—¨æ•°é‡ï¼Œä½œä¸ºç¡¬ä»¶è§„æ¨¡ä»£ç† |
| **å»¶è¿Ÿï¼ˆLatencyï¼‰** | CPU/GPUä¸ŠÎ¼sçº§ï¼ŒFPGAä¸Šnsçº§ï¼ˆåç»¼åˆæ—¶åºåˆ†æï¼‰ |
| **ååé‡ï¼ˆThroughputï¼‰** | FPSï¼ˆFrames Per Secondï¼‰ |
| **èƒ½é‡æ¶ˆè€—** | FPGAä¸ŠåŸºäºåŠŸè€—ä¼°è®¡è®¡ç®—æ¯æ ·æœ¬èƒ½è€—ï¼ˆE = P Ã— tï¼‰ |
| **èµ„æºåˆ©ç”¨ç‡** | LUTã€DSPã€BRAMç­‰FPGAèµ„æºå ç”¨æƒ…å†µ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

ä¸å…¶ä»–**åŸºäºé€»è¾‘é—¨æˆ–LUTçš„ç¥ç»ç½‘ç»œ**è¿›è¡Œæ¯”è¾ƒï¼ŒåŒ…æ‹¬ï¼š

- **DiffLogic Net** (Petersen et al., 2022)ï¼šåŸºäºå¯å¾®åˆ†é€»è¾‘é—¨çš„ç½‘ç»œ
- **LogicTreeNet** (Petersen et al., 2024)ï¼šåŸºäºé€»è¾‘é—¨æ ‘çš„CNN
- **LILogicNet** (Fojcik et al., 2025)ï¼šç´§å‡‘å‹é€»è¾‘é—¨ç½‘ç»œ
- **DWN** (Bacellar et al., 2025)ï¼šæ— æƒé‡ç¥ç»ç½‘ç»œ

> æ³¨ï¼šç”±äºå„å·¥ä½œæŠ¥å‘Šæ ¼å¼ä¸ç»Ÿä¸€ï¼ˆæ˜¯å¦å«å¤´/ç¼–ç å™¨ã€æ˜¯å¦ä¼˜åŒ–åè®¡æ•°ï¼‰ï¼Œä½œè€…å¼ºè°ƒåº”è°¨æ…è§£è¯»ç»å¯¹æ•°å€¼ï¼Œä¾§é‡è¶‹åŠ¿åˆ†æã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

| æ•°æ®é›† | BitLogic å‡†ç¡®ç‡ | ç­‰æ•ˆé—¨æ•° | æ¨ç†å»¶è¿Ÿï¼ˆFPGAï¼‰ |
|--------|------------------|----------|------------------|
| **MNIST** | **99.1%** | 384K | <20 ns |
| **Fashion-MNIST** | **93.8%** | 384K | <20 ns |
| **CIFAR-10** | **72.3%** | <300K | <20 ns |
| **CIFAR-100** | **23.4%** | 384K | <20 ns |

> âœ… åœ¨CIFAR-10ä¸Šè¾¾åˆ°72.3%å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œä»…ä½¿ç”¨ä¸åˆ°0.3Mé€»è¾‘é—¨ï¼Œæ˜¾è‘—ä¼˜äºå¤§å¤šæ•°åŒç±»æ–¹æ³•ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

| æ¨¡å‹ | CIFAR-10 å‡†ç¡®ç‡ | é—¨æ•° | å¤‡æ³¨ |
|------|------------------|-------|------|
| **BitLogic (Ours)** | **72.3%** | **384K** | ä»…ç”¨LUTèµ„æº |
| DiffLogic Net-L | 60.78% | 1.28M | æ›´å¤§æ¨¡å‹ä»è½å |
| LILogicNet-L | 60.98% | 256K | è§„æ¨¡ç›¸è¿‘ä½†ç²¾åº¦ä½ |
| LogicTreeNet-M | 71.01% | 3.08M | é«˜å‡ºè¿‘10å€é—¨æ•° |
| LogicTreeNet-G | 86.29% | 61.0M | æå¤§è§„æ¨¡æ¨¡å‹ |

> ğŸ” ç»“è®ºï¼š**BitLogicåœ¨ä¸­ç­‰è§„æ¨¡ä¸‹å®ç°äº†æå…·ç«äº‰åŠ›çš„ç²¾åº¦-æ•ˆç‡æƒè¡¡**ï¼Œå°¤å…¶åœ¨å•ä½é—¨æ•°æ€§èƒ½ä¸Šè¡¨ç°çªå‡ºã€‚

### **æ¶ˆèå®éªŒç»“æœ**

åœ¨Fashion-MNISTä¸Šå¯¹äº”ä¸ªç»„ä»¶è¿›è¡Œäº†ç³»ç»Ÿæ€§æ¶ˆèï¼š

#### **(A) ç¼–ç å™¨å½±å“**
- `Thermometer` > `Binary` > `One-hot` > `Sign`
- åˆ†å¸ƒå¼çƒ­ç¼–ç ï¼ˆdistributive thermometerï¼‰æ•ˆæœæœ€ä½³ï¼ˆ~83.4%ï¼‰

#### **(B) å±‚ç±»å‹**
- `TopK-Sparse` (83.5%) â‰« `Learnable` (70.0%) > `Random` (77.3%)
- å›ºå®šç¨€ç–å€™é€‰æ±  + å¯å­¦ä¹ é€‰æ‹©ï¼Œåœ¨æ•ˆç‡ä¸æ€§èƒ½é—´å–å¾—å¹³è¡¡

#### **(C) èŠ‚ç‚¹ç±»å‹**
- `Hybrid` (84.0%) â‰ˆ `Probabilistic` (83.5%) > `Fourier`, `DWN`
- Hybridç»“åˆäº†DWNå‰å‘ä¸æ¦‚ç‡åå‘æ¢¯åº¦ï¼Œè®­ç»ƒæ›´ç¨³å®š

#### **(D) è¾“å…¥ç»´åº¦ï¼ˆFan-inï¼‰**
- æ˜æ˜¾æ­£ç›¸å…³ï¼šfan-in=2 (79.3%) â†’ fan-in=6 (**84.9%**)
- æ›´é«˜ç»´LUTå¸¦æ¥æ›´å¼ºè¡¨è¾¾èƒ½åŠ›ï¼Œä½†å†…å­˜æˆæœ¬å‘ˆæŒ‡æ•°å¢é•¿ï¼ˆ2^nï¼‰

#### **(E) è¾“å‡ºå¤´**
- `GroupSum` (83.5%) > `GroupedDSP` (80.9%)
- å°½ç®¡GroupedDSPæœ‰å¯å­¦ä¹ æƒé‡ï¼Œä½†åœ¨æœ¬è®¾ç½®ä¸‹åè€Œç•¥é€Šï¼Œå¯èƒ½å› é‡åŒ–æŸå¤±

#### **å…¶ä»–é‡è¦å‘ç°**
- **å®½åº¦ä¼˜äºæ·±åº¦**ï¼šå¢åŠ å±‚å®½æ¯”åŠ æ·±ç½‘ç»œæ›´æœ‰æ•ˆï¼ˆè§Figure 4aï¼‰
- **æ¸©åº¦å‚æ•°Tå¯ç¼“è§£è¿‡æ‹Ÿåˆ**ï¼šåœ¨GroupSumå¤´ä¸­è°ƒèŠ‚Tï¼ŒéªŒè¯å‡†ç¡®ç‡å³°å€¼å‡ºç°åœ¨T=50ï¼Œè€ŒT=1.0ä¸¥é‡è¿‡æ‹Ÿåˆ

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **LUTå¯ä»¥ä½œä¸ºé«˜æ•ˆã€é€šç”¨çš„ç¥ç»å…ƒæ›¿ä»£å“**ï¼šé€šè¿‡å¯å¾®æ¾å¼›ä¸ç«¯åˆ°ç«¯è®­ç»ƒï¼ŒLUTèŠ‚ç‚¹èƒ½é€¼è¿‘ç”šè‡³è¶…è¶Šä¼ ç»Ÿç®—æœ¯æ“ä½œçš„è¡¨ç°ã€‚
2. âœ… **ç¡¬ä»¶åŸç”Ÿè®¾è®¡å¤§å¹…æå‡æ•ˆç‡**ï¼šBitLogicåœ¨Xilinx Zynq-7020ä¸Šå®ç°**18.63nså»¶è¿Ÿã€53.7M FPSã€3.34nJ/æ ·æœ¬èƒ½è€—**ï¼Œè¿œè¶…CPU/GPUå®ç°ã€‚
3. âœ… **æ¨¡å—åŒ–æ¡†æ¶ä¿ƒè¿›å…¬å¹³æ¯”è¾ƒä¸å¿«é€Ÿè¿­ä»£**ï¼šé¦–æ¬¡åœ¨ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶å†…é›†æˆå¤šç§LUTå˜ä½“ã€ç¼–ç å™¨ã€å¤´ç»“æ„ï¼Œæ”¯æŒç²¾ç»†åŒ–æ¶ˆèã€‚
4. âœ… **è‡ªåŠ¨åŒ–RTLå¯¼å‡ºä¿éšœè½¯ç¡¬ä»¶ä¸€è‡´æ€§**ï¼šé¿å…æ‰‹åŠ¨è½¬æ¢é”™è¯¯ï¼Œæå‡éƒ¨ç½²å¯é æ€§ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

| å±€é™ | è¯´æ˜ |
|------|------|
| **CNNæ€§èƒ½æœªè¾¾é¢„æœŸ** | å½“å‰CNNç‰ˆæœ¬åœ¨CIFARä¸Šè¡¨ç°ä¸å¦‚FFNï¼Œæ¨æµ‹å› è®­ç»ƒä¸è¶³æˆ–é€šé“é…ç½®æœªè°ƒä¼˜æ‰€è‡´ã€‚ |
| **æ·±åº¦ç½‘ç»œè®­ç»ƒä¸ç¨³å®š** | éšç€å±‚æ•°å¢åŠ ï¼Œæ¢¯åº¦ä¼ æ’­å›°éš¾ï¼Œéœ€è¿›ä¸€æ­¥ç ”ç©¶å½’ä¸€åŒ–ã€åˆå§‹åŒ–æœºåˆ¶ï¼ˆå¦‚æ–‡ä¸­æå‡ºçš„Residual Initï¼‰ã€‚ |
| **HDLå¯¼å‡ºæ”¯æŒæœ‰é™** | å½“å‰ä¸»è¦æ”¯æŒå‰é¦ˆã€ç»„åˆé€»è¾‘ï¼Œå¯¹æ—¶åºé€»è¾‘ï¼ˆå¦‚æµæ°´çº¿å¯„å­˜å™¨ã€çŠ¶æ€æœºï¼‰æ”¯æŒå°šä¸å®Œæ•´ã€‚ |
| **èµ„æºé™åˆ¶åˆ¶çº¦å¤§è§„æ¨¡éƒ¨ç½²** | Vivadoå·¥å…·å¯¹å¸¸é‡æ•°ç»„å¤§å°æœ‰é™åˆ¶ï¼ˆå¦‚1Må…ƒç´ ä¸Šé™ï¼‰ï¼Œå½±å“å¤§æ¨¡å‹ç»¼åˆã€‚ |

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æå‡æ·±å±‚ç½‘ç»œç¨³å®šæ€§**  
   - å¼•å…¥æ›´é€‚åˆé€»è¾‘èŠ‚ç‚¹çš„å½’ä¸€åŒ–æ–¹æ³•
   - è®¾è®¡æ®‹å·®è¿æ¥ã€è·³è·ƒè·¯å¾„ç­‰æ‹“æ‰‘æ”¹è¿›

2. **æ‰©å±•è‡³æ›´å¤šä»»åŠ¡ä¸æ¶æ„**  
   - æ”¯æŒåºåˆ—å»ºæ¨¡ï¼ˆRNNã€Transformerï¼‰
   - å¼€å‘åˆ†å‰²ã€æ£€æµ‹ã€é‡å»ºç­‰ä»»åŠ¡ä¸“ç”¨headä¸loss

3. **å®Œå–„HDLå¯¼å‡ºä¸æ—¶åºæ”¯æŒ**  
   - è‡ªåŠ¨æ’å…¥æµæ°´çº¿å¯„å­˜å™¨ä»¥æ»¡è¶³é«˜é¢‘éœ€æ±‚
   - æ”¯æŒæµå¼æ¥å£ä¸ç‰‡å¤–é€šä¿¡åè®®

4. **ç¡¬ä»¶æ„ŸçŸ¥è”åˆä¼˜åŒ–ï¼ˆCo-designï¼‰**  
   - å°†LUTåˆ©ç”¨ç‡ã€æ—¶åºçº¦æŸçº³å…¥è®­ç»ƒç›®æ ‡
   - ç»“åˆNeural Architecture Searchï¼ˆNASï¼‰è‡ªåŠ¨æ¢ç´¢æœ€ä¼˜ç»“æ„

5. **æ„å»ºå¼€æºç”Ÿæ€**  
   - å‘å¸ƒä»£ç ä¸é¢„è®­ç»ƒæ¨¡å‹ï¼ˆæ–‡ä¸­æåŠå¾…æˆæƒè§£å†³ï¼‰
   - æ¨åŠ¨ç¤¾åŒºå…±å»ºæ ‡å‡†åŒ–è¯„æµ‹åŸºå‡†

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **BitLogic æ˜¯é¦–ä¸ªçœŸæ­£æ„ä¹‰ä¸Šâ€œä»è®­ç»ƒåˆ°éƒ¨ç½²â€å…¨æµç¨‹è´¯é€šçš„FPGAåŸç”Ÿç¥ç»ç½‘ç»œæ¡†æ¶ï¼Œå®ƒé‡æ–°å®šä¹‰äº†DNNåœ¨FPGAä¸Šçš„æ„å»ºèŒƒå¼â€”â€”ä¸å†æ˜¯ä»è½¯ä»¶æ˜ å°„åˆ°ç¡¬ä»¶ï¼Œè€Œæ˜¯ç›´æ¥åœ¨ç¡¬ä»¶åŸè¯­ä¸Šè¿›è¡Œç«¯åˆ°ç«¯å­¦ä¹ ã€‚**

</details>

---

### 6. [DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents](https://arxiv.org/abs/2602.07035)

**Authors**: Jiahao Zhao, Shaoxuan Xu, Zhongxiang Sun, Fengqi Zhu, Jingyang Ou, Yuling Shi, Chongxuan Li, Xiao Zhang, Jun Xu  
**Category**: cs.AI  
**Published**: 2026-02-10  
**Score**: 11.5  
**Type**: new  
**ArXiv ID**: 2602.07035v1  

#### Abstract
Recently, Diffusion Large Language Models (dLLMs) have demonstrated unique efficiency advantages, enabled by their inherently parallel decoding mechanism and flexible generation paradigm. Meanwhile, despite the rapid advancement of Search Agents, their practical deployment is constrained by a fundam...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDLLM-Searcher: Adapting Diffusion Large Language Models for Search Agents

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹å½“å‰ **Search Agent** åœ¨å®é™…éƒ¨ç½²ä¸­é¢ä¸´çš„ä¸¤å¤§æ ¸å¿ƒæŒ‘æˆ˜ï¼š

1. **Latency Challengeï¼ˆå»¶è¿ŸæŒ‘æˆ˜ï¼‰**ï¼šåœ¨æ ‡å‡†çš„ ReAct èŒƒå¼ä¸‹ï¼ŒLLM éœ€è¦ä¸²è¡Œæ‰§è¡Œâ€œæ€è€ƒ â†’ å·¥å…·è°ƒç”¨ â†’ ç­‰å¾…å·¥å…·å“åº”â€æµç¨‹ï¼Œå¯¼è‡´ç«¯åˆ°ç«¯æ¨ç†å»¶è¿Ÿé«˜ï¼Œç”¨æˆ·ä½“éªŒå·®ã€‚
2. **Agent Ability Challengeï¼ˆæ™ºèƒ½ä½“èƒ½åŠ›æŒ‘æˆ˜ï¼‰**ï¼šç°æœ‰çš„ **dLLMsï¼ˆDiffusion Large Language Modelsï¼‰** è™½ç„¶å…·å¤‡å¹¶è¡Œè§£ç ä¼˜åŠ¿ï¼Œä½†åœ¨å¤šæ­¥æ¨ç†ã€å·¥å…·è°ƒç”¨æ ¼å¼éµå¾ªç­‰æ–¹é¢è¡¨ç°è¾ƒå¼±ï¼Œéš¾ä»¥ç›´æ¥ä½œä¸º Search Agent çš„ backboneã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½œè€…æå‡º **DLLM-Searcher**ï¼Œä¸€ä¸ªä¸“ä¸º dLLMs è®¾è®¡çš„ Search Agent ä¼˜åŒ–æ¡†æ¶ï¼ŒåŒ…å«ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š

#### ï¼ˆ1ï¼‰ä¸¤é˜¶æ®µåè®­ç»ƒç®¡é“ï¼ˆTwo-stage Post-training Pipelineï¼‰
- **Agentic SFTï¼ˆAgentic Supervised Fine-Tuningï¼‰**  
  åˆ©ç”¨é«˜æ€§èƒ½æ•™å¸ˆæ¨¡å‹ç”Ÿæˆçš„è½¨è¿¹æ•°æ®è¿›è¡Œç›‘ç£å¾®è°ƒï¼Œä½¿ dLLM å­¦ä¹ æ­£ç¡®çš„ `think` å’Œ `tool_call` ç»“æ„åŒ–è¾“å‡ºæ ¼å¼ã€‚
- **Agentic VRPOï¼ˆAgentic Variance-Reduced Preference Optimizationï¼‰**  
  åŸºäºåå¥½å­¦ä¹ è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹è¡Œä¸ºï¼Œä½¿ç”¨ rollout æ•°æ®æ„å»º winner/loser å¯¹ï¼Œæå‡æ¨ç†ä¸æ£€ç´¢èƒ½åŠ›ã€‚

> âœ… ç‰¹åˆ«è®¾è®¡äº† **Agentic ELBO** å’Œ **Agentic Noising** æœºåˆ¶ï¼Œç¡®ä¿è®­ç»ƒè¿‡ç¨‹ä¸­ä»…å…³æ³¨ `think` å’Œ `tool_call` åŒºåŸŸï¼Œé¿å… `tool_response` æ³„éœ²é€ æˆè®­ç»ƒ-æ¨ç†ä¸ä¸€è‡´ã€‚

#### ï¼ˆ2ï¼‰æ–°å‹ä»£ç†èŒƒå¼ï¼šP-ReActï¼ˆParallel-Reasoning and Actingï¼‰
- ä¸€ç§æ— éœ€é¢å¤–è®­ç»ƒçš„æ¨ç†ç­–ç•¥ï¼Œåˆ©ç”¨ dLLM çš„éè‡ªå›å½’ç‰¹æ€§å®ç°â€œè¾¹ç­‰å¾…è¾¹æ€è€ƒâ€ã€‚
- æ ¸å¿ƒæŠ€æœ¯ï¼š
  - **Token Pre-filling**ï¼šé¢„å¡«å…… `<tool_call>` å’Œ `</tool_call>` è¾¹ç•Œæ ‡è®°ã€‚
  - **Confidence Biasing**ï¼šå¯¹è¾¹ç•Œå†…ä½ç½®æ–½åŠ ç½®ä¿¡åº¦åç½®ï¼Œå¼•å¯¼æ¨¡å‹ä¼˜å…ˆè§£ç  `tool_call` å†…å®¹ã€‚

> âœ… å®ç°äº† **tool-first generation**ï¼Œå³å…ˆç”Ÿæˆå·¥å…·è°ƒç”¨æŒ‡ä»¤ï¼Œå†è¡¥å…¨æ€è€ƒè¿‡ç¨‹ï¼Œåœ¨å·¥å…·æ‰§è¡ŒæœŸé—´æ¨¡å‹ä»å¯ç»§ç»­â€œæ€è€ƒâ€ï¼Œä»è€Œæ˜¾è‘—é™ä½ç«¯åˆ°ç«¯å»¶è¿Ÿã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ•ˆç‡** | åˆ©ç”¨ dLLM å¹¶è¡Œè§£ç  + P-ReAct å¹¶è¡Œæ‰§è¡Œï¼Œå®ç°çº¦ **15% æ¨ç†åŠ é€Ÿ** |
| **æ€§èƒ½** | ç»è¿‡ Agentic SFT + VRPO åï¼ŒdLLM çš„æœç´¢ä¸æ¨ç†èƒ½åŠ›è¾¾åˆ°ä¸»æµ ARM-based Agent æ°´å¹³ |
| **å¯æ§æ€§** | P-ReAct å®ç°è¿‘ä¹ 100% æˆåŠŸç‡çš„ `tool_call` ä¼˜å…ˆç”Ÿæˆ |
| **é€šç”¨æ€§** | æ–¹æ³•é€‚ç”¨äºä»»æ„æ”¯æŒå—çŠ¶æ‰©æ•£çš„ dLLMï¼ˆå¦‚ SDARï¼‰ï¼Œä¸” P-ReAct æ— éœ€é‡æ–°è®­ç»ƒ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒåŸºäºå››ä¸ªå¤šè·³é—®ç­”ï¼ˆmulti-hop QAï¼‰åŸºå‡†ï¼š
- **HotpotQA**ï¼šéœ€è·¨æ–‡æ¡£æ¨ç†çš„äº‹å®ç±»é—®é¢˜
- **2WikiMultiHopQA**ï¼šåˆæˆçš„å¤šè·³ç»´åŸºç™¾ç§‘é—®ç­”
- **Musique**ï¼šæ›´å¤æ‚çš„å¤šè·³é“¾å¼é—®é¢˜
- **Bamboogle**ï¼šç”¨äºæµ‹è¯•æ³›åŒ–èƒ½åŠ›çš„ out-of-domain æ•°æ®é›†

> æ‰€æœ‰æµ‹è¯•é›†å‡ä»å¼€å‘é›†ä¸­é‡‡æ · 500 æ¡ï¼ˆBamboogle å…¨éƒ¨ 125 æ¡ï¼‰

### å®éªŒè®¾ç½®
- **Backbone æ¨¡å‹**ï¼šSDARï¼ˆBlock Diffusion LMï¼Œ64/128 block sizeï¼‰
- **å¤–éƒ¨å·¥å…·**ï¼šGoogle Search APIï¼Œè¿”å› top-10 ç»“æœ
- **è®­ç»ƒé…ç½®**ï¼š
  - Agentic SFTï¼šlr=1e-5ï¼Œbatch=32ï¼Œ3 epochs
  - Agentic VRPOï¼šlr=5e-7ï¼Œbatch=16ï¼Œ5 epochs
- **æ¨ç†é…ç½®**ï¼š
  - Denoising steps: 128
  - Block size: 128
  - Temperature: 1.0
  - Confidence bias Î± = 0.5

### è¯„ä¼°æŒ‡æ ‡
- **ACCRï¼ˆAccuracy-containï¼‰**ï¼šé¢„æµ‹ç­”æ¡ˆæ˜¯å¦åŒ…å«é»„é‡‘ç­”æ¡ˆï¼ˆexact match ä¸é€‚ç”¨é•¿æ–‡æœ¬åœºæ™¯ï¼‰
- **ACCLï¼ˆLLM-as-Judge Accuracyï¼‰**ï¼šä½¿ç”¨ Doubao-Seed-1.8 ä½œä¸ºè£åˆ¤æ¨¡å‹åˆ¤æ–­å›ç­”æ­£ç¡®æ€§

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
åˆ†ä¸ºä¸‰ç±»ï¼š
1. **ä¼ ç»Ÿ RAG æ–¹æ³•**ï¼š
   - SuRe, Selective-Context, Adaptive-RAG, IRCoT, Iter-RetGen, CR-Planner, ReARTeR
2. **ARM-based Search Agents**ï¼š
   - Search-o1, Search-R1, WebSailor*, R1Searcher*
3. **dLLM-based Agents**ï¼š
   - SDARï¼ˆvanillaï¼‰ã€Dreamã€LLaDA

> æ³¨ï¼šWebSailor å’Œ R1Searcher çš„ç»“æœç»è¿‡é€‚é…å¤„ç†ä»¥ä¿æŒå·¥å…·ä¸€è‡´æ€§ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 1ï¼‰

| Model | Avg ACCR | Avg ACCL |
|-------|----------|----------|
| R1Searcher* (SOTA ARM) | 53.1 | 56.5 |
| **DLLM-Searcher (Ours)** | **57.0** | **56.6** |
| LLaDA (dLLM baseline) | 34.9 | 32.5 |
| SDAR (vanilla) | â€” | â€” |

> âœ… **DLLM-Searcher åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šå‡è¶…è¶Šç°æœ‰ dLLM æ–¹æ³•ï¼Œå¹¶ä¼˜äºå¤§å¤šæ•° ARM-based Agentï¼Œç”šè‡³ç•¥èƒœ R1Searcher**

#### åˆ†é¡¹è¡¨ç°äº®ç‚¹ï¼š
- åœ¨ **2Wiki** ä¸Š ACCR è¾¾ **69.8**ï¼ˆ+10.2 è¶…è¶Š R1Searcherï¼‰
- åœ¨ **Bamboogle** ä¸Šå±•ç°å¼ºæ³›åŒ–èƒ½åŠ›ï¼ˆout-of-domain æ€§èƒ½ç¨³å®šï¼‰

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ
- ç›¸æ¯”ä¼ ç»Ÿ RAG æ–¹æ³•ï¼ˆå¦‚ ReARTeRï¼‰å¹³å‡æå‡ **~19% ACCR**
- ç›¸æ¯” vanilla dLLMsï¼ˆå¦‚ SDARï¼‰å®ç°ä» **å®Œå…¨å¤±è´¥** åˆ° **ç¨³å®šè¿è¡Œ** çš„è·¨è¶Š
- ä¸æœ€å¼º ARM Agentï¼ˆR1Searcherï¼‰ç›¸æ¯”ï¼Œæ€§èƒ½**ç›¸å½“ç”šè‡³ç•¥æœ‰é¢†å…ˆ**

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 2 & RQ1ï¼‰

| æ–¹æ³• | HotpotQA ACCR | æå‡ |
|------|----------------|--------|
| Agentic SFT | 57.2 | â€” |
| + Agentic VRPO | **60.4** | **+3.2** |

> âœ… ä¸¤é˜¶æ®µè®­ç»ƒå‡æœ‰æ˜¾è‘—å¢ç›Šï¼ŒVRPO è¿›ä¸€æ­¥æå‡æ¨ç†é²æ£’æ€§å’Œå‡†ç¡®æ€§

### æ¨ç†æ•ˆç‡ç»“æœï¼ˆRQ2ï¼‰
- **P-ReAct ç›¸æ¯”æ ‡å‡† ReAct å®ç°å¹³å‡ 15% æ¨ç†åŠ é€Ÿ**ï¼š
  - HotpotQA: **14.77%**
  - 2Wiki: **21.00%**
  - Bamboogle: **22.08%**
  - Musique: **12.67%**
- åŠ é€ŸåŒæ—¶ **æ— æ˜æ˜¾æ€§èƒ½æŸå¤±**ï¼ˆACCR/ACCL å‡ ä¹æŒå¹³ï¼‰

### æ§åˆ¶æœ‰æ•ˆæ€§éªŒè¯ï¼ˆRQ3ï¼‰
- å°è¯•å°† P-ReAct æ€è·¯è¿ç§»åˆ° **Autoregressive LLMsï¼ˆQwen3 ç³»åˆ—ï¼‰**ï¼š
  - å³ä¾¿ä¿®æ”¹ prompt å¼•å¯¼å…ˆè¾“å‡º `tool_call`ï¼Œä¹Ÿä¼šå¯¼è‡´ **æ˜¾è‘—æ€§èƒ½ä¸‹é™**
  - å¦‚ Qwen3-8B åœ¨ Wiki ä¸Šå‡†ç¡®ç‡ä¸‹é™ **13.3%**
- åè§‚ DLLM-Searcher åœ¨å¤šæ•°ä»»åŠ¡ä¸Š **ç²¾åº¦ä¸å˜ç”šè‡³ç•¥æœ‰ä¸Šå‡**

> âœ… è¡¨æ˜ **order-free generation æ˜¯ dLLM ç‹¬æœ‰çš„ä¼˜åŠ¿**ï¼ŒARM å› ä¾èµ–æ˜¾å¼ CoT è€Œæ— æ³•å®‰å…¨å®ç°â€œå…ˆè¡ŒåŠ¨åæ€è€ƒâ€

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **dLLMs å®Œå…¨å¯ä»¥èƒœä»» Search Agent è§’è‰²**ï¼Œåªè¦é€šè¿‡é€‚å½“çš„åè®­ç»ƒï¼ˆAgentic SFT + VRPOï¼‰å¼¥è¡¥å…¶æ¨ç†ä¸æ ¼å¼éµå¾ªç¼ºé™·ã€‚
2. **P-ReAct èƒ½æœ‰æ•ˆåˆ©ç”¨ dLLM çš„éè‡ªå›å½’ç‰¹æ€§**ï¼Œå®ç°â€œåœ¨ç­‰å¾…ä¸­æ€è€ƒâ€ï¼Œæ‰“ç ´ ReAct çš„ä¸²è¡Œç“¶é¢ˆï¼Œå¸¦æ¥çœŸå®ä¸–ç•Œå¯ç”¨çš„å»¶è¿Ÿä¼˜åŒ–ã€‚
3. **dLLM çš„ bidirectional attention æ”¯æŒ latent reasoning**ï¼šå³ä½¿ `think` åŒºåŸŸæœªæ˜¾å¼è§£ç ï¼Œæ¨¡å‹ä¹Ÿèƒ½åˆ©ç”¨å…¨å±€ä¸Šä¸‹æ–‡ç”Ÿæˆé«˜è´¨é‡ `tool_call`ã€‚
4. **DLLM-Searcher å®ç°äº†æ€§èƒ½ä¸æ•ˆç‡çš„åŒèµ¢**ï¼šæ—¢è¾¾åˆ°ä¸»æµ ARM Agent çš„æ°´å¹³ï¼Œåˆè·å¾—çº¦ **15% çš„ç«¯åˆ°ç«¯åŠ é€Ÿ**ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ–¹æ³•ä¾èµ–ç‰¹å®šç»“æ„çš„ dLLM æ¶æ„ï¼ˆå¦‚ Block Diffusionï¼‰ï¼Œä¸é€‚ç”¨äºçº¯è‡ªå›å½’æˆ–å…¨æ‰©æ•£æ¨¡å‹ã€‚
- Agentic SFT ä¾èµ–é«˜è´¨é‡æ•™å¸ˆè½¨è¿¹ï¼Œæ•°æ®æ„é€ æˆæœ¬è¾ƒé«˜ã€‚
- P-ReAct çš„ confidence bias å‚æ•°éœ€è¦æ‰‹åŠ¨è°ƒèŠ‚ï¼Œå°šæœªå®Œå…¨è‡ªåŠ¨åŒ–ã€‚
- åœ¨æå¤æ‚ä»»åŠ¡ï¼ˆå¦‚ Musiqueï¼‰ä¸Šä»ç•¥é€Šäºé¡¶çº§ ARM Agentã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† P-ReAct æ‰©å±•è‡³å…¶ä»–å·¥å…·äº¤äº’åœºæ™¯ï¼ˆå¦‚ä»£ç æ‰§è¡Œã€æ•°æ®åº“æŸ¥è¯¢ï¼‰
- æ¢ç´¢å…¨è‡ªåŠ¨çš„ decoding order control æœºåˆ¶
- æ„å»ºç«¯åˆ°ç«¯è”åˆä¼˜åŒ–æ¡†æ¶ï¼Œç»Ÿä¸€è®­ç»ƒä¸æ¨ç†ç›®æ ‡
- å¼€å‘é¢å‘ dLLM çš„ä¸“ç”¨ Agent Evaluation Benchmark

---

> ğŸ”š **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **DLLM-Searcher æˆåŠŸå°† dLLM çš„å¹¶è¡Œæ½œåŠ›è½¬åŒ–ä¸º Search Agent çš„å®é™…æ•ˆç‡ä¼˜åŠ¿ï¼Œåœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹å®ç°äº†â€œè¾¹ç­‰è¾¹æƒ³â€çš„æ–°å‹æ™ºèƒ½ä½“èŒƒå¼ï¼Œä¸ºé«˜æ•ˆ Agent ç³»ç»Ÿæä¾›äº†æ–°è·¯å¾„ã€‚**

</details>

---

### 7. [Who Deserves the Reward? SHARP: Shapley Credit-based Optimization for Multi-Agent System](https://arxiv.org/abs/2602.08335)

**Authors**: Yanming Li, Xuelin Zhang, WenJie Lu, Ziye Tang, Maodong Wu, Haotian Luo, Tongtong Wu, Zijie Peng, Hongze Mi, Yibo Feng, Naiqiang Tan, Chao Huang, Hong Chen, Li Shen  
**Category**: cs.AI  
**Published**: 2026-02-10  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2602.08335v1  

#### Abstract
Integrating Large Language Models (LLMs) with external tools via multi-agent systems offers a promising new paradigm for decomposing and solving complex problems. However, training these systems remains notoriously difficult due to the credit assignment challenge, as it is often unclear which specif...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šWho Deserves the Reward? SHARP: Shapley Credit-based Optimization for Multi-Agent System

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
åœ¨ **Multi-Agent System (MAS)** ä¸­é›†æˆ **Large Language Models (LLMs)** å’Œå¤–éƒ¨å·¥å…·å·²æˆä¸ºè§£å†³å¤æ‚ä»»åŠ¡çš„æ–°èŒƒå¼ã€‚ç„¶è€Œï¼Œè¿™ç±»ç³»ç»Ÿçš„è®­ç»ƒé¢ä¸´ä¸€ä¸ªæ ¹æœ¬æ€§æŒ‘æˆ˜â€”â€”**Credit Assignment Problemï¼ˆä¿¡ç”¨åˆ†é…é—®é¢˜ï¼‰**ï¼šå½“æ•´ä¸ªå›¢é˜Ÿå®Œæˆä¸€ä¸ªä»»åŠ¡æ—¶ï¼Œéš¾ä»¥å‡†ç¡®åˆ¤æ–­æ¯ä¸ª agentï¼ˆå¦‚ planner æˆ– workerï¼‰å¯¹æœ€ç»ˆæˆåŠŸæˆ–å¤±è´¥çš„å…·ä½“è´¡çŒ®ã€‚

ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äº**ç¨€ç–çš„ã€å…¨å±€å¹¿æ’­çš„å¥–åŠ±ä¿¡å·**ï¼ˆbroadcast rewardsï¼‰ï¼Œå°†æ‰€æœ‰ agent è§†ä¸ºä¸€ä¸ªæ•´ä½“è¿›è¡Œæ›´æ–°ï¼Œå¯¼è‡´ï¼š
- æ— æ³•åŒºåˆ†ä¸ªä½“è´¡çŒ®ï¼›
- æ”¿ç­–æ›´æ–°æ•ˆç‡ä½ä¸‹ï¼›
- éš¾ä»¥ç¨³å®šè®­ç»ƒè¿‡ç¨‹ã€‚

---

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡º **SHARP (Shapley-based Hierarchical Attribution for Reinforcement Policy)**ï¼Œä¸€ç§åŸºäº **Shapley Value** çš„ç²¾ç»†åŒ–ä¿¡ç”¨åˆ†é…æ¡†æ¶ï¼Œç”¨äºä¼˜åŒ–å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
- **ä¸‰é‡åˆ†è§£å¥–åŠ±æœºåˆ¶ (Tripartite Decomposed Reward)**ï¼š
  1. **Global Broadcast-Accuracy Reward**ï¼šè¡¡é‡æœ€ç»ˆä»»åŠ¡æ˜¯å¦æˆåŠŸï¼Œç¡®ä¿æ•´ä½“ç›®æ ‡å¯¹é½ã€‚
  2. **Shapley-based Marginal-Credit Reward**ï¼šåˆ©ç”¨ **Shapley Value** ä»åˆä½œåšå¼ˆè®ºä¸­é‡åŒ–æ¯ä¸ª agent çš„è¾¹é™…è´¡çŒ®ï¼Œå®ç°ç²¾ç¡®çš„ä¸ªä½“ä¿¡ç”¨å½’å› ã€‚
  3. **Tool-Process Reward**ï¼šæä¾›æ‰§è¡Œè¿‡ç¨‹ä¸­çš„åé¦ˆï¼Œç¡®ä¿å·¥å…·è°ƒç”¨çš„æœ‰æ•ˆæ€§å’Œæ­£ç¡®æ€§ã€‚

- **Counterfactual Masking æœºåˆ¶**ï¼š
  é€šè¿‡â€œåäº‹å®æ©ç â€ç§»é™¤æŸä¸ª agent åè§‚å¯Ÿè½¨è¿¹æ€§èƒ½å˜åŒ–ï¼Œè®¡ç®—å…¶å› æœå½±å“ï¼ˆå³ $ \text{credit}_m = R_{\text{acc}}(T) - R_{\text{acc}}(T^{(-m)}) $ï¼‰ï¼Œä»è€Œæ•°å­¦ä¸Šéš”ç¦» agent çš„çœŸå®è´¡çŒ®ã€‚

- **Group-Relative Policy Optimization (GRPO) æ‰©å±•**ï¼š
  åœ¨ GRPO åŸºç¡€ä¸Šå¼•å…¥ agent-specific çš„ä¼˜åŠ¿å½’ä¸€åŒ–ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | SHARP |
|------|--------|-------|
| ä¿¡ç”¨åˆ†é…ç²’åº¦ | å…¨å±€å¹¿æ’­ï¼Œç²—ç²’åº¦ | ç»†ç²’åº¦ï¼ŒæŒ‰ agent åˆ†é… |
| è´¡çŒ®è¯†åˆ«èƒ½åŠ› | å¼±ï¼Œæ··æ·†ä¸ªä½“ä½œç”¨ | å¼ºï¼ŒåŸºäº Shapley æ•°å­¦å»ºæ¨¡ |
| è®­ç»ƒç¨³å®šæ€§ | æ˜“å—å™ªå£°å¹²æ‰°ï¼Œæ³¢åŠ¨å¤§ | æ›´ä½æ–¹å·®æ¢¯åº¦ï¼Œæ”¶æ•›æ›´ç¨³ |
| å¯è§£é‡Šæ€§ | é»‘ç®±å¼æ›´æ–° | å¯åˆ†æ planner-worker åä½œæ¨¡å¼ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šSHARP å®ç°äº†**å¯è§£é‡Šã€é«˜æ•ˆä¸”ç¨³å®šçš„å¤š agent è”åˆä¼˜åŒ–**ï¼Œçªç ´äº†ä¼ ç»Ÿ broadcast reward çš„ç“¶é¢ˆã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–äº”ä¸ªçœŸå®ä¸–ç•ŒåŸºå‡†æµ‹è¯•ï¼Œæ¶µç›–å¤šè·³æ¨ç†ã€ç½‘é¡µå¯¼èˆªã€å·¥å…·è°ƒç”¨ç­‰åœºæ™¯ï¼š

| æ•°æ®é›† | æè¿° |
|-------|------|
| **MuSiQue** | å¤šè·³é—®ç­”ï¼Œéœ€ç»„åˆå¤šä¸ªå•è·³é—®é¢˜ |
| **GAIA-text** | é€šç”¨ AI åŠ©æ‰‹è¯„æµ‹ï¼Œæ¶‰åŠæ¨ç†ã€æœç´¢ã€å·¥å…·ä½¿ç”¨ |
| **WebWalkerQA** | å¤šæ­¥ç½‘é¡µéå†ä¸è¯æ®èšåˆ |
| **FRAMES** | ç«¯åˆ°ç«¯æ£€ç´¢å¢å¼ºç”Ÿæˆçš„ç»Ÿä¸€è¯„æµ‹ï¼ˆäº‹å®æ€§ã€æ£€ç´¢ã€æ¨ç†ï¼‰ |
| **DocMath-Eval** | é•¿æ–‡æœ¬æ–‡æ¡£ä¸­çš„æ•°å­¦æ¨ç†ï¼ˆå«è¡¨æ ¼ï¼‰ |

> âš ï¸ æ³¨æ„ï¼šä»… MuSiQue ä½¿ç”¨è®­ç»ƒé›†ï¼ˆ5,975 å®ä¾‹ï¼‰ï¼Œå…¶ä½™å‡é›¶æ ·æœ¬è¯„ä¼°ï¼ˆzero-shot evaluationï¼‰ã€‚

---

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹æ¶æ„**ï¼šé‡‡ç”¨ **self-play å¤šè§’è‰²å…±äº«ç­–ç•¥**ï¼ŒåŒä¸€ LLM é€šè¿‡ä¸åŒ system prompt å®ä¾‹åŒ–ä¸º planner å’Œ workerã€‚
- **Backbone æ¨¡å‹**ï¼šä¸»è¦ä½¿ç”¨ **Qwen3-8B**ï¼Œéƒ¨åˆ†å¯¹æ¯”ä½¿ç”¨ LLaMA-3.1-8Bã€‚
- **ä¼˜åŒ–å™¨**ï¼šAdamWï¼Œå­¦ä¹ ç‡ $10^{-5}$ï¼Œbatch size 256ã€‚
- **è®­ç»ƒæ­¥æ•°**ï¼š180 gradient stepsï¼Œ64Ã—A100 GPUã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š**Match Accuracy (%)**ï¼Œå³é¢„æµ‹ç­”æ¡ˆä¸æ ‡å‡†ç­”æ¡ˆåŒ¹é…çš„æ¯”ä¾‹ã€‚

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
åˆ†ä¸ºå››ç±» baseline è¿›è¡Œæ¯”è¾ƒï¼š

| ç±»åˆ« | æ–¹æ³• |
|------|------|
| **Vanilla LLMs** | LLaMA-3.1-8B RAG, Qwen3-8B RAG |
| **Prompt-based Planning** | Plan-Search |
| **Single-Agent RL** | Search-R1, Single-agent GRPO |
| **Multi-Agent Systems (æ—  marginal credit)** |  
| &nbsp;&nbsp;â€“ æœªè®­ç»ƒç»“æ„ | Planner-Worker, G-Designer, CARD, COA |
| &nbsp;&nbsp;â€“ å·²è®­ç»ƒç»“æ„ | AceSearcher, MATPO |

> ğŸ” ç‰¹åˆ«å¼ºè°ƒï¼šSHARP ä¸ **MATPO** å¯¹æ¯”æœ€å…·æ„ä¹‰ï¼Œå› å…¶åŒå± MARL æ¡†æ¶ï¼Œä½†åè€…ç¼ºä¹ç»†ç²’åº¦ä¿¡ç”¨å»ºæ¨¡ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æ–¹æ³• | MuSiQue | GAIA-text | WebWalkerQA | FRAMES | **AVG** |
|------|---------|-----------|-------------|--------|--------|
| MATPO | 47.00 | 31.65 | 7.47 | 37.10 | **30.81** |
| **SHARP (ours)** | **50.76** | **33.70** | **8.50** | **37.29** | **32.56** |

âœ… **å¹³å‡æå‡**ï¼š
- ç›¸æ¯” **single-agent baseline**ï¼š**+23.66%**
- ç›¸æ¯” **multi-agent baseline (å¦‚ MATPO)**ï¼š**+14.05%**

> ğŸ’¡ åœ¨ MuSiQue ä¸Šè¾¾åˆ° **50.76**ï¼Œé¢†å…ˆç¬¬äºŒå MATPO è¶…è¿‡ 3.76 ç‚¹ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ä¼˜äºæ‰€æœ‰ baselines**ï¼Œåœ¨å…¨éƒ¨ä»»åŠ¡ä¸Šæ’åç¬¬ä¸€ã€‚
- å³ä½¿æ˜¯ç»“æ„åŒ–çš„éè®­ç»ƒæ–¹æ³•ï¼ˆå¦‚ Plan-Searchï¼‰ä¹Ÿè¿œé€Šäº SHARPã€‚
- åœ¨ **DocMath-Eval** ä¸Šå±•ç°å¼ºæ³›åŒ–èƒ½åŠ›ï¼Œåœ¨å››ç§æ–‡æ¡£æ¨ç†è®¾å®šä¸‹å‡è¡¨ç°æœ€ä½³ã€‚
- åœ¨ **8B æ¨¡å‹è§„æ¨¡ä¸‹**ï¼Œç›¸æ¯” single-agent æå‡è¾¾ **14.41 pts**ï¼Œæ˜¾ç¤ºæ›´å¼ºçš„ scaling law æ•ˆåº”ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰
#### ï¼ˆ1ï¼‰ç§»é™¤ Shapley Credit çš„å½±å“ï¼ˆå›¾3ï¼‰
| è®¾ç½® | MuSiQue Acc |
|------|------------|
| å®Œæ•´ SHARP | 50.76 |
| ä»… planner-level Shapley | 47.60 |
| ä»… worker-level Shapley | 48.00 |
| æ—  Shapleyï¼ˆbaselineï¼‰ | 47.00 |

â¡ï¸ **å‘ç°**ï¼šåªæœ‰åŒæ—¶èµ‹äºˆ planner å’Œ worker ç²¾ç¡®ä¿¡ç”¨æ—¶ï¼Œæ‰èƒ½è·å¾—æœ€å¤§å¢ç›Šï¼Œä½“ç°ååŒæ•ˆåº”ã€‚

#### ï¼ˆ2ï¼‰ç»„ä»¶è´¡çŒ®åˆ†æ
- **Planner ä¿¡ç”¨**ï¼šä¸»è¦æ”¹è¿›ä»»åŠ¡åˆ†è§£é€»è¾‘ï¼Œå¸¦æ¥çº¦ +0.6~0.65 æå‡ã€‚
- **Worker ä¿¡ç”¨**ï¼šæ˜¾è‘—å‡å°‘å†—ä½™/æ— æ•ˆå·¥å…·è°ƒç”¨ï¼Œæå‡æ›´å¤§ï¼ˆ+0.88~1.00ï¼‰ï¼Œå°¤å…¶åœ¨é•¿ç¨‹ä»»åŠ¡ä¸­æ›´é‡è¦ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Marginal Credit Modeling æ˜¯å…³é”®é©±åŠ¨åŠ›**ï¼š
   - ç›¸æ¯”æ¶æ„è®¾è®¡æˆ–ä¼˜åŒ–ç­–ç•¥æœ¬èº«ï¼Œ**æ˜¾å¼çš„è¾¹é™…ä¿¡ç”¨å»ºæ¨¡**æ‰æ˜¯æ€§èƒ½è·ƒå‡çš„æ ¸å¿ƒã€‚
   
2. **SHARP æ˜¾è‘—æ”¹å–„ planner-worker åè°ƒæœºåˆ¶**ï¼ˆå›¾6ï¼‰ï¼š
   - æå‡ planner çš„å¹³å‡ Shapley å€¼ï¼ˆplanner score â†‘ï¼‰
   - æœ‰ç”¨ subagent æ¯”ä¾‹ä» 11.03% â†’ 12.96%
   - **æœ‰å®³ subagent è°ƒç”¨æ¯”ä¾‹ä» 5.48% â†“ è‡³ 4.40%**ï¼Œè¯´æ˜èƒ½æœ‰æ•ˆè¿‡æ»¤è´Ÿé¢è¡Œä¸ºã€‚

3. **è®­ç»ƒæ›´ç¨³å®šã€æ‰©å±•æ€§æ›´å¥½**ï¼ˆå›¾5ï¼‰ï¼š
   - åœ¨ GAIA-text ä¸Šéšè®­ç»ƒæ­¥æ•°å•è°ƒä¸Šå‡ï¼Œè€Œ baseline å‡ºç°éœ‡è¡ã€‚
   - éšæ¨¡å‹å‚æ•°å¢å¤§ï¼ˆ0.6Bâ†’8Bï¼‰ï¼ŒSHARP å¢ç›ŠæŒç»­æ‰©å¤§ï¼Œè¡¨æ˜å…¶åœ¨æ›´å¼º backbone ä¸Šæ›´å…·æ½œåŠ›ã€‚

4. **ç¼“è§£ Catastrophic Forgetting**ï¼ˆè¡¨2ï¼‰ï¼š
   - åœ¨ MMLU ä¸Šæµ‹è¯•çŸ¥è¯†ä¿ç•™èƒ½åŠ›ï¼š
     - Planner-Worker (no train): 93.04%
     - MATPO: 94.00%
     - **SHARP: 94.65%**
   â¡ï¸ è¡¨æ˜ SHARP ä¸ä»…ä¸é—å¿˜æ—§çŸ¥è¯†ï¼Œåè€Œæœ‰æ­£å‘è¿ç§»æ•ˆæœã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **è®¡ç®—å¼€é”€å¢åŠ **ï¼šShapley ä¼°è®¡éœ€è¦å¤šæ¬¡ counterfactual rolloutï¼Œè®­ç»ƒæ—¶é—´éš agent æ•°é‡å¢é•¿ã€‚
- **Sparsification æŠ˜è¡·**ï¼šå¯é€šè¿‡åªå¯¹éƒ¨åˆ† subagent è®¡ç®— Shapley æ¥é™ä½å¼€é”€ï¼ˆè§å›¾7ï¼‰ï¼Œä½†å¯èƒ½ç‰ºç‰²ç²¾åº¦ã€‚
- **ä»å­˜åœ¨åè°ƒä½æ•ˆé—®é¢˜**ï¼šå³ä½¿åœ¨ SHARP ä¸‹ï¼Œâ€œæœ‰ç”¨ subagentâ€ä»æ˜¯å°‘æ•°ï¼Œæç¤ºæœªæ¥éœ€è¿›ä¸€æ­¥å‰ªæä½æ•ˆè·¯å¾„ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **é«˜æ•ˆ Shapley Approximation**ï¼šå¼€å‘æ›´è½»é‡çº§çš„ marginal contribution ä¼°è®¡ç®—æ³•ã€‚
2. **Dynamic Agent Pruning**ï¼šè‡ªåŠ¨è¯†åˆ«å¹¶ç¦ç”¨ä½è´¡çŒ® agentï¼Œæå‡æ¨ç†æ•ˆç‡ã€‚
3. **è·¨ä»»åŠ¡è¿ç§»ä¿¡ç”¨æ¨¡å‹**ï¼šæ¢ç´¢ credit assignment ç­–ç•¥çš„å¯è¿ç§»æ€§ã€‚
4. **åº”ç”¨äºæ›´å¤æ‚ topology**ï¼šå¦‚ communication graphã€dynamic coalition formation ç­‰ã€‚

---

## æ€»ç»“
> ğŸŒŸ **SHARP æˆåŠŸåœ°å°†åšå¼ˆè®ºä¸­çš„ Shapley Value å¼•å…¥å¤š agent LLM ç³»ç»Ÿè®­ç»ƒï¼Œè§£å†³äº†é•¿æœŸå­˜åœ¨çš„ credit assignment éš¾é¢˜**ã€‚å®ƒä¸ä»…å¸¦æ¥äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¿˜å¢å¼ºäº†è®­ç»ƒç¨³å®šæ€§ã€å¯è§£é‡Šæ€§å’Œç³»ç»Ÿåè°ƒè´¨é‡ï¼Œä¸ºæ„å»ºé«˜æ•ˆã€å¯ä¿¡çš„å¤š agent åä½œç³»ç»Ÿæä¾›äº†åšå®åŸºç¡€ã€‚

</details>

---

### 8. [TEAM: Temporal-Spatial Consistency Guided Expert Activation for MoE Diffusion Language Model Acceleration](https://arxiv.org/abs/2602.08404)

**Authors**: Linye Wei, Zixiang Luo, Pingzhi Tang, Meng Li  
**Category**: cs.CL  
**Published**: 2026-02-10  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2602.08404v1  

#### Abstract
Diffusion large language models (dLLMs) have recently gained significant attention due to their inherent support for parallel decoding. Building on this paradigm, Mixture-of-Experts (MoE) dLLMs with autoregressive (AR) initialization have further demonstrated strong performance competitive with main...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTEAM: Temporal-Spatial Consistency Guided Expert Activation for MoE Diffusion Language Model Acceleration

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰å°† **Mixture-of-Experts (MoE)** æ¶æ„ç›´æ¥åº”ç”¨äº **diffusion large language models (dLLMs)** å­˜åœ¨ä¸¥é‡çš„æ¨ç†æ•ˆç‡ç“¶é¢ˆã€‚å°½ç®¡ MoE æœ¬åº”é€šè¿‡ç¨€ç–æ¿€æ´»æå‡æ•ˆç‡ï¼Œä½†åœ¨ dLLMs ä¸­ï¼Œæ¯ä¸ªå»å™ªæ­¥éª¤ä¸­æ‰€æœ‰ token å¹¶è¡Œå¤„ç†å¹¶ç‹¬ç«‹é€‰æ‹©ä¸“å®¶ï¼Œå¯¼è‡´å¤§é‡ä¸“å®¶è¢«æ¿€æ´»ï¼Œè€Œåªæœ‰å°‘æ•° token è¢«æœ€ç»ˆæ¥å—ï¼ˆunmaskedï¼‰ï¼Œé€ æˆæ˜¾è‘—çš„è®¡ç®—å’Œå†…å­˜å¼€é”€ã€‚

è¿™ç§â€œé«˜æ¿€æ´»ã€ä½æ¥å—â€çš„ç°è±¡ä½¿å¾— MoE åœ¨ dLLMs ä¸Šçš„å®é™…è¡¨ç°æ¥è¿‘äºç¨ å¯†æ¨¡å‹ï¼ˆdense modelï¼‰ï¼Œå¤±å»äº†å…¶ç¨€ç–æ€§çš„ä¼˜åŠ¿ï¼Œå°¤å…¶åœ¨å¯¹å»¶è¿Ÿæ•æ„Ÿçš„åº”ç”¨å’Œè¾¹ç¼˜è®¾å¤‡ä¸Šæˆä¸ºç“¶é¢ˆã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šTEAM
ä½œè€…æå‡º **TEAM** â€”â€” ä¸€ç§å³æ’å³ç”¨ï¼ˆplug-and-playï¼‰çš„æ¡†æ¶ï¼Œç”¨äºåŠ é€Ÿ MoE dLLMs æ¨ç†ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨ **æ—¶é—´ä¸€è‡´æ€§ï¼ˆtemporal consistencyï¼‰** å’Œ **ç©ºé—´ä¸€è‡´æ€§ï¼ˆspatial consistencyï¼‰** æ¥æŒ‡å¯¼ä¸“å®¶æ¿€æ´»ç­–ç•¥ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š
1. **è§‚å¯Ÿåˆ°ä¸¤ä¸ªå…³é”®æ€§è´¨**ï¼š
   - **Temporal Consistency**ï¼šå·²è§£ç çš„ token åœ¨åç»­è¿­ä»£ä¸­ä¿æŒç¨³å®šï¼Œæ— éœ€é‡å¤å®Œæ•´è®¡ç®—ã€‚
   - **Spatial Consistency**ï¼šæœªè§£ç çš„ masked tokens åœ¨è·¯ç”±æ—¶å€¾å‘äºé›†ä¸­åœ¨å°‘æ•°å‡ ä¸ªä¸“å®¶ä¸Šï¼Œä¸”æ¥å—é¡ºåºå…·æœ‰ç©ºé—´å±€éƒ¨æ€§ï¼ˆspatial localityï¼‰ã€‚

2. **ä¸‰ç§äº’è¡¥çš„ä¸“å®¶æ¿€æ´»ä¸è§£ç ç­–ç•¥**ï¼š
   - **Delayed Caching for Decoded Tokens (DCD)**  
     å¯¹å·²æ¥å—çš„ token å»¶è¿Ÿç¼“å­˜å…¶ KV ç¼“å­˜ï¼Œä»…åœ¨æœ€æ–°ä¸€è½®ä¸­é‡æ–°è®¡ç®—ï¼Œé¿å…å†—ä½™å‰å‘ä¼ æ’­ã€‚
   - **Speculative Exploration for Hot Tokens (SEH)**  
     å°†å¯èƒ½å³å°†è¢«æ¥å—çš„ masked tokens å®šä¹‰ä¸º â€œhot tokensâ€ï¼Œè¿›è¡Œå¤šåˆ†æ”¯ speculative decodingï¼Œæé«˜å•æ­¥ token æ¥å—ç‡ã€‚
   - **Limited Activation for Cold Tokens (LAC)**  
     å°†è¿œç¦»å·²è§£ç åŒºåŸŸã€ç½®ä¿¡åº¦ä½çš„ tokens å®šä¹‰ä¸º â€œcold tokensâ€ï¼Œé™åˆ¶å…¶åªèƒ½ä»å·²è¢« hot æˆ– decoded tokens æ¿€æ´»çš„ä¸“å®¶é›†åˆä¸­é€‰æ‹©ï¼Œé˜²æ­¢å¼•å…¥æ–°çš„ç¨€æœ‰ä¸“å®¶ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | TEAM çš„ä¼˜åŠ¿ |
|------|-------------|
| **é’ˆå¯¹æ€§å¼º** | æ˜¯é¦–ä¸ªä¸“é—¨åˆ†æ MoE dLLMs ä¸­ä¸“å®¶æ¿€æ´»è¡Œä¸ºçš„å·¥ä½œï¼Œè€Œéé€šç”¨åŠ é€Ÿæ–¹æ¡ˆã€‚ |
| **æ— éœ€è®­ç»ƒä¿®æ”¹** | å®Œå…¨åœ¨æ¨ç†é˜¶æ®µå®ç°ï¼Œä¸æ”¹å˜è®­ç»ƒè¿‡ç¨‹æˆ–æ¨¡å‹ç»“æ„ã€‚ |
| **é«˜æ•ˆåˆ©ç”¨ç¡¬ä»¶èµ„æº** | åˆ©ç”¨ MoE å¤©ç„¶çš„ä¸“å®¶åˆ†å¸ƒç‰¹æ€§ï¼Œåœ¨å• GPU ä¸Šå³å¯å®ç°æœ‰æ•ˆ speculative decodingã€‚ |
| **å…¼é¡¾æ€§èƒ½ä¸é€Ÿåº¦** | æ˜¾è‘—æé€Ÿçš„åŒæ—¶å‡ ä¹æ— æ€§èƒ½æŸå¤±ï¼ˆnegligible performance degradationï¼‰ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
åœ¨å››ä¸ªä¸»æµåŸºå‡†ä¸Šè¯„ä¼° TEAM çš„æœ‰æ•ˆæ€§ï¼š
- **ä»£ç ç”Ÿæˆä»»åŠ¡**ï¼š
  - `HumanEval` (0-shot)
  - `MBPP` (0-shot)
- **æ•°å­¦æ¨ç†ä»»åŠ¡**ï¼š
  - `GSM8K` (0-shot)
  - `Math-500` (0-shot)

---

### âš™ï¸ å®éªŒè®¾ç½®
- **ä¸»æ¨¡å‹**ï¼š`SDAR 30B-A3B`ï¼Œä¸€ä¸ªå…¸å‹çš„åŸºäº MoE çš„ block-diffusion dLLMã€‚
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA A100 80GB GPUã€‚
- **å…³é”®è¶…å‚æ•°**ï¼š
  - æ¥å—é˜ˆå€¼ï¼ˆunmask thresholdï¼‰: `T = 0.95`
  - Block size: `32 tokens`
  - Hot token åˆ¤å®šæ ‡å‡†ï¼š
    - ç½®ä¿¡åº¦é˜ˆå€¼ `Th = 0.7`
    - è·ç¦»å·²è§£ç  token æœ€å¤§è·ç¦» `Lh = 3`
  - Speculative branches æ•°é‡ï¼š`4`

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **APF** (Activated experts Per Forward pass) | æ¯æ¬¡å‰å‘ä¼ æ’­æ¿€æ´»çš„ä¸“å®¶æ•°é‡ |
| **TPF** (Tokens Per Forward pass) | æ¯æ¬¡å‰å‘ä¼ æ’­æˆåŠŸæ¥å—çš„ token æ•°é‡ |
| **APT** (Activated experts Per decoded Token) | æ¯è§£ç ä¸€ä¸ª token æ‰€éœ€æ¿€æ´»çš„ä¸“å®¶æ•°ï¼ˆè¶Šå°è¶Šå¥½ï¼‰ |
| **Speedup** | ç›¸å¯¹äº vanilla æ¨¡å‹çš„æ¨ç†é€Ÿåº¦æå‡å€æ•° |
| **Score** | ä»»åŠ¡å‡†ç¡®ç‡ï¼ˆPass@1ï¼‰ |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Vanilla SDAR**ï¼šåŸå§‹ MoE dLLMï¼Œæ— ä»»ä½•ä¼˜åŒ–ã€‚
- **dKV-Cache (Ma et al., 2025a)**ï¼šå·²æœ‰ KV ç¼“å­˜æœºåˆ¶ï¼Œä½†é’ˆå¯¹å…¨å±€ attention è®¾è®¡ï¼Œåœ¨ block-diffusion ä¸­æ•ˆæœæœ‰é™ã€‚
- **dInfer (Ma et al., 2025b)**ï¼šé¢å‘äº‘éƒ¨ç½²çš„å¤§è§„æ¨¡ MoE åŠ é€Ÿæ¡†æ¶ï¼Œä¾§é‡ expert-parallel æ‰§è¡Œï¼Œéä¸“ä¸ºæ¨ç†æ•ˆç‡è®¾è®¡ã€‚

> TEAM æ˜¯å”¯ä¸€ä¸“æ³¨äº **token-level ä¸“å®¶æ¿€æ´»ä¼˜åŒ–** çš„æ–¹æ³•ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ æ€§èƒ½æ±‡æ€»ï¼ˆæ¥è‡ª Table 1ï¼‰
| Benchmark | æ–¹æ³• | Score | APF â†“ | TPF â†‘ | APT â†“ | Speedup â†‘ |
|----------|-------|--------|--------|--------|--------|-----------|
| HumanEval | Vanilla | 79.27 | 53.34 | 2.91 | 18.33 | 1Ã— |
|           | **TEAM** | **79.88** (+0.61) | **34.48** (â†“35%) | **5.07** (â†‘1.74Ã—) | **6.80** (â†“63%) | **2.20Ã—** |
| MBPP      | Vanilla | 65.76 | 49.59 | 2.74 | 18.10 | 1Ã— |
|           | **TEAM** | **65.76** | **30.92** (â†“38%) | **4.56** (â†‘1.66Ã—) | **6.78** (â†“63%) | **2.08Ã—** |
| GSM8K     | Vanilla | 90.60 | 59.11 | 3.16 | 18.71 | 1Ã— |
|           | **TEAM** | **90.30** (-0.30) | **36.20** (â†“39%) | **4.79** (â†‘1.52Ã—) | **7.56** (â†“60%) | **1.83Ã—** |
| Math-500  | Vanilla | 76.00 | 57.90 | 3.74 | 15.48 | 1Ã— |
|           | **TEAM** | **75.40** (-0.60) | **36.31** (â†“37%) | **5.57** (â†‘1.49Ã—) | **6.52** (â†“58%) | **1.64Ã—** |
| **Average** | Vanilla | 77.91 | 54.99 | 3.14 | 17.66 | 1Ã— |
|           | **TEAM** | **77.84** (-0.07) | **34.48** (â†“37%) | **5.00** (â†‘1.59Ã—) | **6.92** (â†“61%) | **1.94Ã—** |

> âœ… **å¹³å‡æé€Ÿè¾¾ 1.94Ã—ï¼Œæœ€é«˜è¾¾ 2.2Ã—ï¼ŒAPT ä¸‹é™è¶…è¿‡ 60%**

---

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
ä» Figure 5 å¯è§é€æ­¥åŠ å…¥å„ç»„ä»¶çš„æ•ˆæœï¼š

| ç»„ä»¶æ·»åŠ é¡ºåº | APT â†“ | Speedup â†‘ | è´¡çŒ®è¯´æ˜ |
|-------------|--------|------------|---------|
| Vanilla â†’ +SEH | ~12 | ~1.5 | æå‡æ¥å—ç‡ï¼Œå‡å°‘æ€»æ­¥æ•° |
| â†’ +DCD       | ~9   | ~1.8 | å‡å°‘å·²è§£ç  token çš„å†—ä½™è®¡ç®— |
| â†’ +LAC       | ~6.9 | ~1.94 | è¿›ä¸€æ­¥å‹ç¼© cold token çš„ä¸“å®¶æ¿€æ´» |

> æ‰€æœ‰ä¸‰ä¸ªæ¨¡å—ååŒä½œç”¨ï¼Œç¼ºä¸€ä¸å¯ï¼Œå…±åŒå®ç°æœ€å¤§åŠ é€Ÿã€‚

---

### ğŸ” å…¶ä»–å…³é”®å®éªŒå‘ç°
- **Refresh-free caching æ›´ä¼˜**ï¼ˆTable 2ï¼‰  
  ä¸éœ€è¦åƒ dKV-Cache é‚£æ ·å®šæœŸåˆ·æ–°æ•´ä¸ª block çš„ç¼“å­˜ï¼Œå› ä¸ºä» AR åˆå§‹åŒ–çš„ dLLM ä¸­ï¼Œå·²è§£ç  token è¡¨ç¤ºéå¸¸ç¨³å®šã€‚ç¦ç”¨åˆ·æ–°åè€Œç•¥å¾®æå‡ç²¾åº¦å¹¶å¤§å¹…æé€Ÿã€‚
- **Hot token è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æ**ï¼ˆTable 3ï¼‰  
  å½“ `Th=0.7`, `Lh=3` æ—¶è¾¾åˆ°æœ€ä½³å¹³è¡¡ï¼šæ—¢ä¸è¿‡åº¦æ‰©å¤§ hot é›†åˆå¯¼è‡´é¢å¤–å¼€é”€ï¼Œä¹Ÿä¸è¿‡åº¦ç¼©å°å¯¼è‡´æ¼æ‰æ½œåœ¨å¯æ¥å— tokenã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **MoE ä¸ dLLM çš„ç®€å•ç»“åˆæ˜¯ä½æ•ˆçš„**  
   å°½ç®¡ä¸¤è€…å„è‡ªå…·å¤‡é«˜æ•ˆæ½œåŠ›ï¼Œä½† naive integration å¯¼è‡´ä¸“å®¶æ¿€æ´»é«˜åº¦åˆ†æ•£ï¼Œå®é™…æ•ˆç‡é€€åŒ–è‡³æ¥è¿‘ dense modelã€‚
   
2. **Temporal-Spatial Consistency æ˜¯çªç ´å£**  
   - æ—¶é—´ç»´åº¦ï¼šå·²è§£ç  token å¯å®‰å…¨ç¼“å­˜ï¼›
   - ç©ºé—´ç»´åº¦ï¼šmasked tokens è·¯ç”±é›†ä¸­ï¼Œæ”¯æŒå…±äº«ä¸“å®¶ï¼›
   - æ¥å—é¡ºåºå…·æœ‰å› æœæ€§å’Œå±€éƒ¨æ€§ï¼Œå¯ç”¨äºé¢„æµ‹ hot/cold tokensã€‚

3. **TEAM å®ç°äº†çœŸæ­£çš„â€œç¨€ç– + å¹¶è¡Œâ€åŒèµ¢**  
   åœ¨é™ä½ APF çš„åŒæ—¶å¤§å¹…æå‡ TPFï¼Œä½¿ APT é™è‡³ **ä½äºåä¹‰è·¯ç”±æˆæœ¬ï¼ˆ8 experts/tokenï¼‰**ï¼Œè¯æ˜äº†æ¶æ„å…¼å®¹æ€§çš„çªç ´ã€‚

---

### âš ï¸ å±€é™æ€§
- **ä¾èµ– block-diffusion ç»“æ„**ï¼šç›®å‰ä»…éªŒè¯äº block-wise dLLMsï¼ˆå¦‚ SDARï¼‰ï¼Œæ˜¯å¦é€‚ç”¨äºå…¨åºåˆ— diffusion å¾…éªŒè¯ã€‚
- **hot/cold åˆ†ç±»ä¾èµ–å¯å‘å¼è§„åˆ™**ï¼šå°šæœªå®Œå…¨è‡ªåŠ¨åŒ–æˆ–å­¦ä¹ åŒ–ï¼Œå¯èƒ½å­˜åœ¨æ¬¡ä¼˜åˆ’åˆ†ã€‚
- **å¯¹ extreme sparse routing åœºæ™¯é€‚åº”æ€§æœªçŸ¥**ï¼šä¾‹å¦‚å½“ expert capacity æå°æ—¶ï¼Œdouble-round routing å¯èƒ½å¼•å‘å†²çªã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- å°† hot token åˆ¤å®šæœºåˆ¶å‡çº§ä¸ºå¯å­¦ä¹ æ¨¡å—ï¼ˆlearnable gating policyï¼‰ã€‚
- æ‰©å±•è‡³ vision-language æˆ– multimodal diffusion modelsã€‚
- æ¢ç´¢ä¸ quantizationã€pruning ç­‰å…¶ä»–æ¨ç†ä¼˜åŒ–æŠ€æœ¯çš„è”åˆåº”ç”¨ã€‚
- æ”¯æŒ streaming æˆ– real-time decoding åœºæ™¯ä¸‹çš„åŠ¨æ€è°ƒæ•´ç­–ç•¥ã€‚

---

## âœ… æ€»ç»“
**TEAM** æ˜¯é¦–ä¸ªé’ˆå¯¹ **MoE dLLMs æ¨ç†ä½æ•ˆé—®é¢˜** æå‡ºç³»ç»Ÿæ€§è§£å†³æ–¹æ¡ˆçš„å·¥ä½œã€‚å®ƒé€šè¿‡æŒ–æ˜ **æ—¶é—´-ç©ºé—´ä¸€è‡´æ€§** ç‰¹å¾ï¼Œè®¾è®¡äº†ä¸‰é¡¹è½»é‡çº§ã€å³æ’å³ç”¨çš„ä¸“å®¶æ¿€æ´»ç­–ç•¥ï¼Œåœ¨å‡ ä¹ä¸å½±å“æ€§èƒ½çš„å‰æä¸‹å®ç°äº† **é«˜è¾¾ 2.2Ã— çš„æ¨ç†åŠ é€Ÿ**ï¼Œæ˜¾è‘—æå‡äº† MoE ä¸ dLLM æ¶æ„èåˆçš„å®ç”¨ä»·å€¼ã€‚

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> TEAM è®© MoE åœ¨ dLLM ä¸­çœŸæ­£â€œç¨€ç–èµ·æ¥â€ï¼Œå®ç°äº†â€œæ›´å°‘ä¸“å®¶æ¿€æ´»ï¼Œæ›´å¤š token æ¥å—â€çš„é«˜æ•ˆæ¨ç†æ–°èŒƒå¼ã€‚

ğŸ”— ä»£ç å·²å¼€æºï¼š[https://github.com/PKU-SEC-Lab/TEAM-MoE-dLLM](https://github.com/PKU-SEC-Lab/TEAM-MoE-dLLM)

</details>

---

### 9. [Parallel Track Transformers: Enabling Fast GPU Inference with Reduced Synchronization](https://arxiv.org/abs/2602.07306)

**Authors**: Chong Wang, Nan Du, Tom Gunter, Tao Lei, Kulin Seth, Senyu Tong, Jianyu Wang, Guoli Yin, Xiyou Zhou, Kelvin Zou, Ruoming Pang  
**Category**: cs.DC  
**Published**: 2026-02-10  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2602.07306v1  

#### Abstract
Efficient large-scale inference of transformer-based large language models (LLMs) remains a fundamental systems challenge, frequently requiring multi-GPU parallelism to meet stringent latency and throughput targets. Conventional tensor parallelism decomposes matrix operations across devices but intr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šParallel Track Transformers: Enabling Fast GPU Inference with Reduced Synchronization

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
- **åŒæ­¥å¼€é”€ç“¶é¢ˆ**ï¼šåœ¨åŸºäº Transformer çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­ï¼Œå¤§è§„æ¨¡æ¨ç†é€šå¸¸ä¾èµ–å¤š GPU å¹¶è¡Œè®¡ç®—ã€‚ä¼ ç»Ÿçš„ **tensor parallelism** è™½ç„¶èƒ½å°†çŸ©é˜µè¿ç®—åˆ†å¸ƒåˆ°å¤šä¸ªè®¾å¤‡ä¸Šï¼Œä½†åœ¨æ¯ä¸€å±‚çš„ attention å’Œ feedforward æ¨¡å—åéƒ½éœ€è¦é¢‘ç¹çš„è·¨ GPU åŒæ­¥ï¼ˆå¦‚ all-reduceï¼‰ï¼Œå¯¼è‡´ä¸¥é‡çš„é€šä¿¡å»¶è¿Ÿå’Œå¯æ‰©å±•æ€§ä¸‹é™ã€‚
- éšç€æ¨¡å‹è§„æ¨¡å¢å¤§ï¼Œè¿™ç§åŒæ­¥æ“ä½œæˆä¸ºåˆ¶çº¦æ¨ç†æ•ˆç‡çš„å…³é”®ç“¶é¢ˆã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šParallel Track (PT) Transformer
- å°†æ•´ä¸ªæ¨¡å‹åˆ’åˆ†ä¸ºå¤šä¸ªç‹¬ç«‹å¹¶è¡Œè¿è¡Œçš„å­ Transformer å®ä¾‹ï¼Œç§°ä¸ºâ€œ**tracks**â€ã€‚
- æ¯ä¸ª track åœ¨æœ¬åœ°å¤„ç†å®Œæ•´çš„ token æµï¼Œä»…åœ¨æ¯éš”ä¸€å®šå±‚æ•°ï¼ˆç”± block depth $D$ æ§åˆ¶ï¼‰æ—¶è¿›è¡Œä¸€æ¬¡å…¨å±€åŒæ­¥ï¼ˆall-reduceï¼‰ï¼Œå®ç°å‚æ•°èåˆã€‚
- è¿™ç§è®¾è®¡è¢«ç§°ä¸º **track parallelism**ï¼Œæ˜¾è‘—å‡å°‘äº†è·¨è®¾å¤‡åŒæ­¥æ¬¡æ•°ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| å¯¹æ¯”ç»´åº¦ | ä¼ ç»Ÿ Tensor Parallelism | PT Transformer |
|--------|----------------------|---------------|
| åŒæ­¥é¢‘ç‡ | æ¯å±‚ä¸¤æ¬¡ï¼ˆattention + FFNï¼‰â†’ æ€»å…± $2L$ æ¬¡ | æ¯ $D$ å±‚ä¸€æ¬¡ â†’ æ€»å…± $L/D$ æ¬¡ |
| åŒæ­¥é‡çº§ | å…¨ç»´åº¦æ¿€æ´»å€¼äº¤æ¢ | åˆ†è½¨åä½ç»´è¡¨ç¤ºäº¤æ¢ï¼Œé€šä¿¡é‡æ›´å° |
| é€šä¿¡æ¨¡å¼ | é«˜é¢‘ã€ç»†ç²’åº¦ï¼Œéš¾ä»¥é‡å ä¼˜åŒ– | ä½é¢‘ã€è§„å¾‹æ€§å¼ºï¼Œåˆ©äºç³»ç»Ÿè°ƒåº¦ä¸ä¼˜åŒ– |
| ä¸ MoE åŒºåˆ« | æ¡ä»¶æ‰§è¡Œã€è·¯ç”±åŠ¨æ€ã€è´Ÿè½½ä¸å‡ | æ‰€æœ‰ token ç»å†æ‰€æœ‰ tracksï¼Œç¡®å®šæ€§åŒæ­¥ |

> âœ… **æœ€å¤§ä¼˜åŠ¿**ï¼šç›¸æ¯”æ ‡å‡† tensor parallelismï¼ŒPT å¯å®ç°é«˜è¾¾ **16Ã— çš„åŒæ­¥æ“ä½œå‡å°‘**ï¼ˆå½“ $D=8$ æ—¶ï¼‰ï¼Œå¤§å¹…ç¼“è§£é€šä¿¡å‹åŠ›ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†ä¸ä»»åŠ¡
- ä¸»è¦ç”¨äºè¯„ä¼°æ¨¡å‹èƒ½åŠ›çš„æ ‡å‡†åŸºå‡†å¥—ä»¶ï¼š
  - **ARC-C/E**, **HellaSwag**, **PIQA**, **SciQ**, **WinoGrande**ï¼ˆå¸¸è¯†æ¨ç†ï¼‰
  - **TriviaQA**ï¼ˆé—®ç­” EMï¼‰
  - **MMLU**ï¼ˆå¤šå­¦ç§‘ç†è§£ï¼Œ5-shotï¼‰
  - **GSM8K**, **MATH**ï¼ˆæ•°å­¦æ¨ç†ï¼‰
  - **HumanEval**ï¼ˆä»£ç ç”Ÿæˆ Pass@1ï¼‰

### å®éªŒè®¾ç½®
- **æ¨¡å‹è§„æ¨¡**ï¼š6Bã€13Bã€30B å‚æ•°çº§åˆ«
- **PT é…ç½®**ï¼š
  - è½¨é“æ•° $n = 8$
  - Track block depth $D \in \{2, 4, 8\}$
  - ä½¿ç”¨ Grouped Query Attention (GQA)
- **è®­ç»ƒç»†èŠ‚**ï¼š
  - 6B æ¨¡å‹é¢„è®­ç»ƒ 800B tokens
  - 13B å’Œ 30B æ¨¡å‹å„é¢„è®­ç»ƒ 400B tokens
  - Dense ä¸ PT æ¨¡å‹é‡‡ç”¨ç›¸åŒè®­ç»ƒæµç¨‹ä»¥å…¬å¹³æ¯”è¾ƒ
- **éƒ¨ç½²ç¯å¢ƒ**ï¼š
  - ç¡¬ä»¶ï¼š8Ã—H100 GPUs
  - æ¨ç†æ¡†æ¶ï¼š**TensorRT-LLM** ä¸ **vLLM**

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | ç¼©å†™ | æè¿° |
|-----|------|------|
| Time to First Token | TTFT | ç”¨æˆ·è¯·æ±‚å‘å‡ºåˆ°é¦–ä¸ªè¾“å‡º token è¿”å›çš„æ—¶é—´ |
| Time Per Output Token | TPOT | è§£ç é˜¶æ®µæ¯ç”Ÿæˆä¸€ä¸ª token æ‰€éœ€å¹³å‡æ—¶é—´ |
| Throughput | â€”â€” | å•ä½æ—¶é—´å†…ç”Ÿæˆçš„ output tokens æ•°é‡ï¼ˆtokens/secï¼‰ |
| Model Quality | å¤šé¡¹å¾—åˆ† | ä¸Šè¿°å„é¡¹ benchmark çš„å‡†ç¡®ç‡æˆ–é€šè¿‡ç‡ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Dense Baseline**ï¼šæ ‡å‡†å…¨é‡ Transformer æ¨¡å‹ + Tensor Parallelism
- **PT Variants**ï¼šä¸åŒ $D$ è®¾ç½®ä¸‹çš„ Parallel Track æ¶æ„
- æ‰€æœ‰æ¨¡å‹åœ¨åŒä¸€ç¡¬ä»¶ä¸æœåŠ¡æ ˆä¸‹æµ‹è¯•ï¼Œç¡®ä¿å…¬å¹³æ€§

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### æ¨¡å‹è´¨é‡ä¿æŒè‰¯å¥½ï¼ˆå°¤å…¶å¯¹å¤§æ¨¡å‹ï¼‰
- **30B æ¨¡å‹** åœ¨å¤§å¤šæ•° benchmark ä¸Šè¡¨ç°ç¨³å®šï¼š
  - MMLU å¾—åˆ†ä» dense çš„ 0.630 åˆ° PT($D=8$) çš„ 0.615ï¼Œä»…è½»å¾®ä¸‹é™
  - GSM8K ä» 0.523 åˆ° 0.488ï¼Œç•¥æœ‰å›è½ä½†ä»å…·ç«äº‰åŠ›
  - HumanEval æœ€é«˜è¾¾åˆ° 0.262ï¼ˆä¼˜äº dense çš„ 0.223ï¼‰
- **13B æ¨¡å‹** è¡¨ç°ç¨³å¥ï¼Œå¤šæ•°æŒ‡æ ‡æ— æ˜æ˜¾é€€åŒ–
- **6B æ¨¡å‹** å¯¹ $D$ æ›´æ•æ„Ÿï¼Œç‰¹åˆ«æ˜¯ MMLU åœ¨ $D=8$ ä¸‹ä» 0.560 é™è‡³ 0.360ï¼Œæ˜¾ç¤ºå°æ¨¡å‹å®¹å¿åº¦è¾ƒä½

> ğŸ” å‘ç°ï¼š**æ¨¡å‹è¶Šå¤§ï¼Œè¶Šèƒ½æ‰¿å—é«˜ $D$ï¼ˆå³æ›´ä½é¢‘åŒæ­¥ï¼‰å¸¦æ¥çš„ç»“æ„æ‰°åŠ¨**

### æ¨ç†æ•ˆç‡æ˜¾è‘—æå‡ï¼ˆ30B æ¨¡å‹ï¼Œ8Ã—H100ï¼‰

#### åœ¨ TensorRT-LLM ä¸­çš„è¡¨ç°
| æŒ‡æ ‡ | æ”¹è¿›å¹…åº¦ |
|------|---------|
| **Throughput** | æœ€é«˜æå‡ **31.90%**ï¼ˆå¦‚è¾“å…¥ 4096 â†’ è¾“å‡º 4096 åœºæ™¯ï¼‰ |
| **TTFT** | å‡å°‘ **15â€“30%**ï¼ˆä¾‹å¦‚è¾“å…¥é•¿åº¦ 4096 æ—¶ä» 125ms â†’ 94msï¼‰ |
| **TPOT** | é™ä½ **2â€“12%**ï¼ˆæœ€é•¿åºåˆ—ä¸‹å°¤ä¸ºæ˜æ˜¾ï¼‰ |

#### åœ¨ vLLM ä¸­çš„è¡¨ç°
| æŒ‡æ ‡ | æ”¹è¿›å¹…åº¦ |
|------|---------|
| **Throughput** | å¤šæ•°åœºæ™¯ä¸‹ä¼˜äº baselineï¼Œæœ€é«˜æå‡è¶… 30%
| **TTFT** | è¾“å…¥è¶Šé•¿ï¼Œå¢ç›Šè¶Šå¤§ï¼›63488 é•¿åº¦ä¸‹ä» ~2981ms â†’ ~2453msï¼ˆâ†“17.7%ï¼‰
| **TPOT** | æŒç»­æ”¹å–„ï¼Œæœ€é•¿ä¸Šä¸‹æ–‡ä¸‹é™çº¦ 10%

> ğŸ“Š ç¤ºä¾‹ï¼šåœ¨ vLLM ä¸­ï¼Œè¾“å…¥ 16384ã€è¾“å‡º 128 çš„ TPOT ä» 9.46ms â†’ 9.10msï¼ˆâ†“3.8%ï¼‰

### æ¶ˆèå®éªŒç»“æœ
- **Track Block Depth $D$ æ˜¯å…³é”®è¶…å‚**ï¼š
  - $D=2$: åŒæ­¥å‡å°‘ 75%ï¼Œæ€§èƒ½å‡ ä¹æ— æŸ
  - $D=4$: å‡å°‘ 87.5%ï¼Œå¤§æ¨¡å‹ä»ç¨³å®š
  - $D=8$: å‡å°‘ **93.75%**ï¼ˆç­‰æ•ˆäº 16Ã— å‡å°‘ï¼‰ï¼Œé€‚åˆ 13B+ è§„æ¨¡
- **è½¨é“æ•°é‡ $n=8$** è®¾è®¡å¹³è¡¡äº†å¹¶è¡Œç²’åº¦ä¸é€šä¿¡æˆæœ¬
- **Grouped Query Attention (GQA)** åŠ å¼ºäº†å†…å­˜ä¸å¸¦å®½æ•ˆç‡ï¼Œè¾…åŠ©å‘æŒ¥ PT ä¼˜åŠ¿

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **å¤§å¹…å‡å°‘åŒæ­¥å¯è¡Œä¸”æœ‰æ•ˆ**ï¼šé€šè¿‡å¼•å…¥ track ç»“æ„ï¼Œå¯åœ¨å‡ ä¹ä¸å½±å“æ¨¡å‹è´¨é‡çš„å‰æä¸‹ï¼ˆå°¤å…¶æ˜¯å¤§æ¨¡å‹ï¼‰ï¼Œå°†åŒæ­¥æ¬¡æ•°ä» $2L$ é™åˆ° $L/D$ã€‚
2. âœ… **æ¨ç†å»¶è¿Ÿæ˜¾è‘—é™ä½**ï¼šç”±äºé€šä¿¡å‡å°‘ï¼ŒTTFT å’Œ TPOT æ˜æ˜¾ä¸‹é™ï¼Œåœ¨é•¿ä¸Šä¸‹æ–‡åœºæ™¯ä¸­ä¼˜åŠ¿æ›´åŠ çªå‡ºã€‚
3. âœ… **ååé‡å…¨é¢æå‡**ï¼šåœ¨ä¸¤ç§ä¸»æµ LLM serving stackï¼ˆTensorRT-LLM å’Œ vLLMï¼‰ä¸­å‡è§‚å¯Ÿåˆ°ä¸€è‡´æ€§çš„ throughput æå‡ï¼ŒéªŒè¯äº†ç³»ç»Ÿçš„é€šç”¨æ€§å’Œå®ç”¨æ€§ã€‚
4. âœ… **é€‚ç”¨äºå¤§è§„æ¨¡æ¨¡å‹ä¼˜å…ˆ**ï¼šPT æ¶æ„æ›´é€‚åˆ 13B åŠä»¥ä¸Šçº§åˆ«çš„æ¨¡å‹ï¼Œåœ¨å°æ¨¡å‹ï¼ˆå¦‚ 6Bï¼‰ä¸­éœ€è°¨æ…é€‰æ‹© $D$

### æ–¹æ³•çš„å±€é™æ€§
- â— **å¹¶éå®Œå…¨å…åŒæ­¥**ï¼šè™½ç„¶åŒæ­¥é¢‘ç‡å¤§å¹…é™ä½ï¼Œä½†ä»éœ€è¦å‘¨æœŸæ€§ all-reduce æ“ä½œæ¥ç»´æŒè¯­ä¹‰ä¸€è‡´æ€§ã€‚
- â— **å¯¹å°æ¨¡å‹é€‚é…æ€§è¾ƒå·®**ï¼š6B æ¨¡å‹åœ¨ $D=8$ æ—¶å‡ºç°æ˜æ˜¾æ€§èƒ½æ»‘å¡ï¼ˆå¦‚ MMLU â†“35%ï¼‰ï¼Œé™åˆ¶å…¶åœ¨è½»é‡çº§åœºæ™¯çš„åº”ç”¨ã€‚
- â— **é¢å¤–å†…å­˜å ç”¨**ï¼šæ¯ä¸ª GPU å­˜å‚¨ä¸€ä¸ªå®Œæ•´ track çš„å‰¯æœ¬ï¼Œå¯èƒ½å¢åŠ æ˜¾å­˜æ¶ˆè€—ï¼ˆå°½ç®¡å• track ç»´åº¦æ›´ä½ï¼‰
- â— **å½“å‰ä»…æ”¯æŒ dense MLP æ›¿æ¢**ï¼šåŸç”Ÿ MoE é›†æˆéœ€è¿›ä¸€æ­¥è®¾è®¡ï¼ˆè™½å·²æœ‰ PT-MoE æ‰©å±•å·¥ä½œ Zhou et al., 2025ï¼‰

### æœªæ¥å·¥ä½œæ–¹å‘
- ğŸ”® **ç»“åˆ MoE å®ç° PT-MoE æ¶æ„**ï¼šå·²åœ¨æ–‡ä¸­æåŠä½œä¸ºå»¶ä¼¸ï¼ˆZhou et al., 2025ï¼‰ï¼Œæœ‰æœ›åŒæ—¶åˆ©ç”¨ç¨€ç–æ¿€æ´»ä¸ track parallelism å®ç°æ›´é«˜æ•ˆç‡
- ğŸ”® **è‡ªåŠ¨è°ƒèŠ‚ $D$ åŠ¨æ€ç­–ç•¥**ï¼šæ ¹æ®è¾“å…¥é•¿åº¦æˆ–è´Ÿè½½æƒ…å†µåŠ¨æ€è°ƒæ•´åŒæ­¥é—´éš”
- ğŸ”® **æ¢ç´¢å¼‚æ„ track è®¾è®¡**ï¼šå…è®¸ tracks å†…éƒ¨ç»“æ„å·®å¼‚åŒ–ï¼Œå¢å¼ºè¡¨è¾¾èƒ½åŠ›
- ğŸ”® **æ‰©å±•è‡³è®­ç»ƒé˜¶æ®µ**ï¼šç›®å‰ focus åœ¨ inferenceï¼Œä½† track parallelism ä¹Ÿå¯ä¸º training æä¾›æ–°çš„å¹¶è¡Œè°ƒåº¦ç©ºé—´

---

> ğŸ’¡ **æ€»ä½“è¯„ä»·**ï¼š  
> Parallel Track Transformer æ˜¯ä¸€ç§**é¢å‘ç³»ç»Ÿæ•ˆç‡é©±åŠ¨çš„æ¶æ„åˆ›æ–°**ï¼Œå®ƒé‡æ–°æ€è€ƒäº† tensor parallelism çš„åº•å±‚å‡è®¾â€”â€”â€œå¿…é¡»é€å±‚åŒæ­¥â€ã€‚é€šè¿‡å°†æ¨¡å‹æ‹†åˆ†ä¸ºå¤šä¸ªå¹¶è¡Œ track å¹¶æ§åˆ¶åŒæ­¥èŠ‚å¥ï¼Œå®ç°äº†æ¨ç†é€Ÿåº¦çš„é‡å¤§çªç ´ï¼Œæ˜¯è¿ˆå‘é«˜æ•ˆ LLM serving çš„é‡è¦ä¸€æ­¥ã€‚å°¤å…¶å¯¹äºè‹¹æœç­‰æ³¨é‡ç«¯ä¾§ä¸ç§æœ‰äº‘éƒ¨ç½²çš„ä¼ä¸šï¼Œè¯¥æŠ€æœ¯å…·æœ‰æé«˜çš„å·¥ç¨‹ä»·å€¼ã€‚

</details>

---

### 10. [Scalable Dexterous Robot Learning with AR-based Remote Human-Robot Interactions](https://arxiv.org/abs/2602.07341)

**Authors**: Yicheng Yang, Ruijiao Li, Lifeng Wang, Shuai Zheng, Shunzheng Ma, Keyu Zhang, Tuoyu Sun, Chenyun Dai, Jie Ding, Zhuo Zou  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2602.07341v1  

#### Abstract
This paper focuses on the scalable robot learning for manipulation in the dexterous robot arm-hand systems, where the remote human-robot interactions via augmented reality (AR) are established to collect the expert demonstration data for improving efficiency. In such a system, we present a unified f...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Scalable Dexterous Robot Learning with AR-based Remote Human-Robot Interactions è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡è‡´åŠ›äºè§£å†³**çµå·§æœºå™¨äººè‡‚æ‰‹ç³»ç»Ÿï¼ˆdexterous robot arm-hand systemsï¼‰åœ¨å¤æ‚æ“ä½œä»»åŠ¡ä¸­çš„å¯æ‰©å±•å­¦ä¹ éš¾é¢˜**ã€‚ä¼ ç»Ÿæ–¹æ³•é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **ä¸“å®¶ç¤ºèŒƒæ•°æ®è·å–å›°éš¾**ï¼šé«˜è´¨é‡çš„äººç±»ç¤ºèŒƒè€—æ—¶ä¸”æˆæœ¬é«˜ï¼›
- **è¡Œä¸ºå…‹éš†ï¼ˆBehavior Cloning, BCï¼‰å­˜åœ¨æ³›åŒ–èƒ½åŠ›å·®ã€ç­–ç•¥å´©æºƒï¼ˆpolicy collapseï¼‰ç­‰é—®é¢˜**ï¼›
- **å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning, RLï¼‰è®­ç»ƒæ•ˆç‡ä½ã€æ ·æœ¬åˆ©ç”¨ç‡ä¸é«˜**ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§**ç»“åˆå¢å¼ºç°å®ï¼ˆARï¼‰ã€æ¨¡ä»¿å­¦ä¹ ä¸å¯¹æ¯”å­¦ä¹ çš„ä¸¤é˜¶æ®µç»Ÿä¸€æ¡†æ¶**ï¼Œå…·ä½“åŒ…æ‹¬ï¼š

1. **åŸºäºARçš„è¿œç¨‹äººæœºäº¤äº’ç³»ç»Ÿç”¨äºæ•°æ®é‡‡é›†**  
   - åˆ©ç”¨ **HoloLens 2 AR headset** æ•æ‰äººç±»ä¸“å®¶çš„æ‰‹éƒ¨å§¿æ€ï¼Œå¹¶é€šè¿‡æ— çº¿è¿æ¥ï¼ˆWiFi/5Gï¼‰å°†åŠ¨ä½œå®æ—¶æ˜ å°„åˆ°ç‰©ç†æœºå™¨äººä¸Šã€‚
   - ä½¿ç”¨ **Unityå¹³å° + ROS TCP Connector** å®ç°è·¨è®¾å¤‡å…¼å®¹æ€§ï¼Œæ”¯æŒå¤šç§ARå¤´æ˜¾ä¸æœºå™¨äººç³»ç»Ÿçš„é›†æˆã€‚
   - æ„å»ºäº†ä¸€ä¸ªé€šç”¨ã€ä½æˆæœ¬ã€å¯è¿œç¨‹æ“ä½œçš„æ•°æ®æ”¶é›†ç³»ç»Ÿã€‚

2. **æ¨¡ä»¿ä¸å¯¹æ¯”å­¦ä¹ è¾…åŠ©çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ˆImitation and Contrastive Learning Assisted RLï¼‰**
   - **ç¬¬ä¸€é˜¶æ®µï¼šè¡Œä¸ºå…‹éš†é¢„è®­ç»ƒï¼ˆBC Pretrainingï¼‰**  
     åˆ©ç”¨å°‘é‡ä¸“å®¶è½¨è¿¹ï¼ˆä»…15æ¡ï¼‰è¿›è¡Œç›‘ç£å›å½’è®­ç»ƒï¼Œå¿«é€Ÿåˆå§‹åŒ–ç­–ç•¥ç½‘ç»œï¼Œæ˜¾è‘—æå‡åç»­RLæ¢ç´¢æ•ˆç‡ã€‚
   - **ç¬¬äºŒé˜¶æ®µï¼šå¸¦æŠ•å½±å¤´ï¼ˆprojection headï¼‰çš„å¯¹æ¯”å¢å¼ºSoft Actor-Criticï¼ˆSACï¼‰ç®—æ³•**  
     å¼•å…¥ä¸€ä¸ª**å¯å­¦ä¹ çš„MLPæŠ•å½±å¤´**ï¼Œé€šè¿‡**å¯¹æ¯”æŸå¤±ï¼ˆcontrastive lossï¼‰** å°†æ™ºèƒ½ä½“çš„åŠ¨ä½œè¡¨ç¤ºæ‹‰è¿‘è‡³ä¸“å®¶çŠ¶æ€-åŠ¨ä½œå¯¹çš„è¡¨ç¤ºç©ºé—´ï¼Œä»è€Œçº¦æŸç­–ç•¥å‘é«˜å›æŠ¥ä¸“å®¶è¡Œä¸ºé æ‹¢ã€‚

3. **äº‹ä»¶é©±åŠ¨å¥–åŠ±æœºåˆ¶å¢å¼ºå®‰å…¨æ€§**  
   è®¾è®¡äº†åŒ…å«ä»»åŠ¡æˆåŠŸã€ç¢°æ’æƒ©ç½šã€æ¥è§¦æ— è¿›å±•ç­‰å¤šæ¡ä»¶åˆ¤æ–­çš„ `event-driven reward`ï¼Œæé«˜è®­ç»ƒè¿‡ç¨‹çš„å®‰å…¨æ€§å’Œé²æ£’æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **æ•°æ®æ•ˆç‡** | ä»…éœ€å°‘é‡ä¸“å®¶æ¼”ç¤ºï¼ˆ15æ¡ï¼‰ï¼Œå³å¯å®ç°é«˜æ•ˆé¢„è®­ç»ƒï¼›ç»“åˆå¯¹æ¯”å­¦ä¹ è¿›ä¸€æ­¥å‡å°‘RLæ‰€éœ€äº¤äº’æ¬¡æ•°ã€‚ |
| **è®­ç»ƒé€Ÿåº¦** | æ¯”æ ‡å‡†SACå¿«çº¦4å€ï¼Œåœ¨PyBulletä»¿çœŸä¸­æ”¶æ•›æ—¶é—´ä»300åˆ†é’Ÿé™è‡³75åˆ†é’Ÿã€‚ |
| **æ€§èƒ½è¡¨ç°** | æ˜¾è‘—é«˜äºPPOå’ŒSACåŸºçº¿çš„æˆåŠŸç‡ï¼ˆå¦‚çƒæŠ“å–è¾¾91.8% vs SACçš„84.2%ï¼‰ã€‚ |
| **ç¨³å®šæ€§** | æˆåŠŸé¿å…â€œç­–ç•¥å´©æºƒâ€é—®é¢˜ï¼Œæ¶ˆèå®éªŒè¯æ˜å¯¹æ¯”å­¦ä¹ æ˜¯å…³é”®å› ç´ ã€‚ |
| **å®ç”¨æ€§** | æ”¯æŒçœŸå®ä¸–ç•Œéƒ¨ç½²ï¼Œå®ç°äº†è¾ƒå°çš„sim-to-real gapã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†æ¥æº
- **è‡ªå»ºæ•°æ®é›†**ï¼šé€šè¿‡æå‡ºçš„ARè¿œç¨‹æ“æ§ç³»ç»Ÿé‡‡é›†äº† **15æ¡ä¸“å®¶æ¼”ç¤ºè½¨è¿¹**ï¼Œæ¶µç›–å˜å½¢çƒä¸ç“¶å­çš„æŠ“å–ä»»åŠ¡ã€‚
- æ‰€æœ‰æ•°æ®å‡æ¥è‡ªä½œè€…æ„å»ºçš„çœŸå®æœºå™¨äººç³»ç»Ÿï¼ˆCGXi-G6æœºæ¢°è‡‚ + Inspireçµå·§æ‰‹ï¼‰ã€‚

### å®éªŒç¯å¢ƒä¸ç¡¬ä»¶é…ç½®
- **ä»¿çœŸç¯å¢ƒ**ï¼šPyBulletï¼ˆPythonï¼‰
- **çœŸå®ç³»ç»Ÿæµ‹è¯•**ï¼šCGXi-G6å…­è‡ªç”±åº¦æœºæ¢°è‡‚ + Inspireäº”æŒ‡çµå·§æ‰‹ + Orbbecæ·±åº¦ç›¸æœº + HoloLens 2
- **æ„ŸçŸ¥æ¨¡å—**ï¼šé‡‡ç”¨YOLOv8è¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œè¾“å…¥ä¸ºç«‹ä½“è§†è§‰å›¾åƒ
- **è®¡ç®—èµ„æº**ï¼šIntel Xeon Gold 6226R CPU + NVIDIA RTX 4090 GPU

### çŠ¶æ€ä¸åŠ¨ä½œç©ºé—´
- **çŠ¶æ€ $ s_t $**ï¼š20ç»´å‘é‡ï¼ˆå…³èŠ‚è§’åº¦ã€æœ«ç«¯ä½å§¿ã€ç‰©ä½“ä½ç½®ç­‰ï¼‰
- **åŠ¨ä½œ $ a_t $**ï¼š8ç»´æ§åˆ¶æŒ‡ä»¤ï¼ˆå…³èŠ‚åç§»é‡ + æ‰‹éƒ¨å§¿æ€ï¼‰

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Mean Reward** | å¹³å‡ç´¯ç§¯å¥–åŠ±å€¼ |
| **Success Rate** | å®ŒæˆæŠ“å–ä»»åŠ¡çš„æ¯”ä¾‹ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰ |
| **Convergence Speed** | è¾¾åˆ°ç¨³å®šæ€§èƒ½æ‰€éœ€çš„è®­ç»ƒè¿­ä»£æ•°ä¸æ—¶é—´ |
| **Training Time Consumption** | æ€»è®­ç»ƒè€—æ—¶ï¼ˆåˆ†é’Ÿï¼‰ |
| **Policy Collapse Detection** | æ˜¯å¦å‡ºç°æ€§èƒ½éª¤é™æˆ–å‘æ•£ç°è±¡ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **PPO**ï¼ˆProximal Policy Optimizationï¼‰
- **SAC**ï¼ˆSoft Actor-Criticï¼‰
- **BC+SAC**ï¼ˆä»…åŠ è¡Œä¸ºå…‹éš†é¢„è®­ç»ƒï¼Œæ— å¯¹æ¯”å­¦ä¹ ï¼‰â€”â€”ä½œä¸ºæ¶ˆèå®éªŒå¯¹ç…§ç»„

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§Table IIIï¼‰

#### åœ¨ä»¿çœŸç¯å¢ƒä¸­ï¼ˆPyBulletï¼‰çš„ç»“æœï¼š

| ä»»åŠ¡ | æŒ‡æ ‡ | PPO | SAC | BC+SAC | **Ours** |
|------|------|-----|-----|--------|---------|
| **çƒæŠ“å–** | å¹³å‡å¥–åŠ± | 584.03 | 1055.16 | 1070.77 | **1145.61** |
|           | æˆåŠŸç‡ | 37.33% | 84.22% | 85.49% | **91.80%** |
|           | æ”¶æ•›è¿­ä»£æ•° | 150 | 140 | 30 | **30** |
|           | è®­ç»ƒè€—æ—¶ï¼ˆminï¼‰ | 355 | 300 | 75 | **75** |
| **ç“¶æŠ“å–** | å¹³å‡å¥–åŠ± | 696.76 | 1052.78 | 1110.51 | **1155.79** |
|           | æˆåŠŸç‡ | 44.18% | 83.93% | 88.66% | **91.83%** |
|           | æ”¶æ•›è¿­ä»£æ•° | 130 | 120 | 25 | **23** |
|           | è®­ç»ƒè€—æ—¶ï¼ˆminï¼‰ | 340 | 270 | 60 | **55** |

> âœ… **ç»“è®º**ï¼šæ‰€ææ–¹æ³•åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå…¨é¢è¶…è¶ŠåŸºçº¿ï¼Œå°¤å…¶åœ¨è®­ç»ƒæ•ˆç‡æ–¹é¢æå‡æ˜æ˜¾ï¼ˆçº¦4å€äºSACï¼‰ï¼Œä¸”æˆåŠŸç‡æœ€é«˜ã€‚

### çœŸå®ä¸–ç•Œå®éªŒç»“æœï¼ˆFig. 8ï¼‰
- åœ¨50æ¬¡çœŸå®æŠ“å–è¯•éªŒä¸­éªŒè¯ï¼š
  - **å˜å½¢çƒæŠ“å–æˆåŠŸç‡**ï¼šOurs (**90.0%**) > BC+SAC (86.0%) > SAC (72.0%) > PPO (66.0%)
  - **ç“¶å­æŠ“å–æˆåŠŸç‡**ï¼šOurs (**94.0%**) > BC+SAC (80.0%) > SAC (70.0%) > PPO (40.0%)

> ğŸ“Œ æ³¨æ„ï¼šç”±äºä»¿çœŸä¸­æœªå»ºæ¨¡å¼¹æ€§è¡¨é¢å½¢å˜ï¼ˆelastomer surface deformationï¼‰å’Œç²¾ç»†å‡ ä½•ç‰¹å¾ï¼Œ**çƒä½“æŠ“å–åœ¨çœŸå®ç¯å¢ƒä¸­æ€§èƒ½ç•¥æœ‰ä¸‹é™**ï¼Œä½†æ•´ä½“ä»ä¿æŒé¢†å…ˆã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
- **BCé¢„è®­ç»ƒçš„ä½œç”¨**ï¼šæ˜¾è‘—é™ä½RLè®­ç»ƒæ—¶é—´ï¼ˆä»~300miné™è‡³<80minï¼‰ï¼Œä¸»å¯¼åˆæœŸæ€§èƒ½æå‡ã€‚
- **å¯¹æ¯”å­¦ä¹ çš„ä½œç”¨**ï¼š
  - åŠ å…¥projection headåï¼Œç­–ç•¥æ›´ç¨³å®šï¼Œé¿å…äº†åæœŸæ€§èƒ½é€€åŒ–ï¼›
  - å¯¹æ¯”æŸå¤±æœ‰æ•ˆé˜²æ­¢â€œç­–ç•¥åç¦»ä¸“å®¶è¡Œä¸ºâ€çš„é—®é¢˜ï¼›
  - åœ¨ä»…æœ‰å°‘é‡ä¸“å®¶æ•°æ®ä¸‹ä»èƒ½ç»´æŒé«˜æ€§èƒ½ã€‚

> ğŸ” å›¾6æ˜¾ç¤ºï¼šOursæ–¹æ³•ä¸ä»…æ”¶æ•›æ›´å¿«ï¼Œè€Œä¸”æœ€ç»ˆå¥–åŠ±æ›´é«˜ã€æ³¢åŠ¨æ›´å°ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **AR-based teleoperation æ˜¯ä¸€ç§é«˜æ•ˆã€çµæ´»ã€ä½æˆæœ¬çš„ä¸“å®¶æ•°æ®é‡‡é›†æ–¹å¼**ï¼Œé€‚ç”¨äºè¿œç¨‹ã€å¤šåœºæ™¯ä¸‹çš„çµå·§æ“ä½œç¤ºèŒƒæ”¶é›†ã€‚
2. **è¡Œä¸ºå…‹éš†é¢„è®­ç»ƒæå¤§æå‡äº†RLçš„åˆå§‹ç­–ç•¥è´¨é‡ä¸æ ·æœ¬æ•ˆç‡**ï¼Œè§£å†³äº†å†·å¯åŠ¨é—®é¢˜ã€‚
3. **å¼•å…¥å¯¹æ¯”å­¦ä¹ ä¸projection head å¯æœ‰æ•ˆç¼“è§£ç­–ç•¥å´©æºƒé—®é¢˜**ï¼Œä½¿RLè¿‡ç¨‹ä¸­ç­–ç•¥å§‹ç»ˆå—ä¸“å®¶è¡Œä¸ºå¼•å¯¼ã€‚
4. **æ‰€ææ–¹æ³•åœ¨ä»¿çœŸä¸çœŸå®ç¯å¢ƒä¸­å‡è¡¨ç°å‡ºå“è¶Šæ€§èƒ½**ï¼Œå…·å¤‡è‰¯å¥½çš„è¿ç§»èƒ½åŠ›å’Œå®ç”¨æ€§ã€‚
5. **æå°‘é‡ä¸“å®¶æ•°æ®ï¼ˆ15æ¡è½¨è¿¹ï¼‰å³å¯å–å¾—ä¼˜å¼‚æ•ˆæœ**ï¼Œè¯æ˜äº†æ–¹æ³•çš„æ•°æ®é«˜æ•ˆæ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–ç²¾ç¡®çš„å§¿æ€ä¼°è®¡**ï¼šARç³»ç»Ÿå¯¹æ‰‹éƒ¨è¿½è¸ªç²¾åº¦è¦æ±‚è¾ƒé«˜ï¼Œå…‰ç…§ã€é®æŒ¡å¯èƒ½å½±å“æ€§èƒ½ã€‚
- **å¯¹è±¡å‡ ä½•ç®€åŒ–å¯¼è‡´sim-to-real gap**ï¼šä»¿çœŸä¸­ç¼ºä¹é«˜ä¿çœŸç‰©ä½“å»ºæ¨¡ï¼ˆå¦‚è½¯ä½“å˜å½¢ï¼‰ï¼Œå½±å“æŸäº›ä»»åŠ¡ï¼ˆå¦‚è½¯çƒæŠ“å–ï¼‰çš„è¡¨ç°ã€‚
- **å½“å‰ä»…é™å•è‡‚å•ä»»åŠ¡**ï¼šå°šæœªæ‰©å±•è‡³åŒè‡‚ååŒæˆ–å¤šä»»åŠ¡è”åˆå­¦ä¹ ã€‚
- **æœªèåˆè§¦è§‰åé¦ˆ**ï¼šå®Œå…¨ä¾èµ–è§†è§‰æ„ŸçŸ¥ï¼Œéš¾ä»¥å¤„ç†é«˜åº¦ä¾èµ–åŠ›æ§çš„ä»»åŠ¡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **è·¨å¤šä¸ªç‰©ç†æ¨¡æ‹Ÿå™¨è”åˆè®­ç»ƒç­–ç•¥**ï¼Œå¢å¼ºç³»ç»Ÿé²æ£’æ€§ï¼ˆå‚è€ƒ[54] Polysimï¼‰ã€‚
2. **ç¼©å°sim-to-real gap**ï¼š
   - å¼•å…¥é«˜ä¿çœŸç‰©ä½“å‡ ä½•é‡å»ºï¼›
   - èåˆ2Dè¯­ä¹‰ä¸3Då‡ ä½•ä¿¡æ¯ï¼ˆå¦‚[55] Visual-Geometry Diffusion Policyï¼‰ã€‚
3. **åŠ å…¥è§¦è§‰ä¸åŠ›è§‰åé¦ˆ**ï¼Œæ”¯æŒå¤æ‚å¯å˜å½¢ç‰©ä½“çš„æ“ä½œã€‚
4. **æ‹“å±•è‡³å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ**ï¼šåº”ç”¨äºåŒè‡‚çµå·§æœºå™¨äººåä½œåœºæ™¯ã€‚
5. **ç»“åˆå¤šæ¨¡æ€æ¨¡ä»¿å­¦ä¹ **ï¼ˆmultimodal imitation learningï¼‰ï¼Œæ•´åˆè¯­è¨€æŒ‡ä»¤ã€è§†é¢‘æ¼”ç¤ºç­‰å¤šç§å½¢å¼æŒ‡å¯¼ã€‚

---

> ğŸ’¡ **è¡¥å……ææ–™é“¾æ¥**ï¼šhttps://cyberyyc.github.io/ ï¼ˆå«æ›´å¤šæ¼”ç¤ºè§†é¢‘ï¼‰

</details>

---

### 11. [MARTI-MARS$^2$: Scaling Multi-Agent Self-Search via Reinforcement Learning for Code Generation](https://arxiv.org/abs/2602.07848)

**Authors**: Shijie Wang, Pengfei Li, Yikun Fu, Kaifeng Liu, Fangyuan Li, Yang Liu, Xiaowei Sun, Zonglin Li, Siyao Zhao, Jian Zhao, Kai Tian, Dong Li, Junqi Gao, Yutong Zhang, Yiqun Chen, Yuqiang Li, Zoe Li, Weinan Zhang, Peng Ye, Shuyue Hu, Lei Bai, Bowen Zhou, Kaiyan Zhang, Biqing Qi  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2602.07848v1  

#### Abstract
While the complex reasoning capability of Large Language Models (LLMs) has attracted significant attention, single-agent systems often encounter inherent performance ceilings in complex tasks such as code generation. Multi-agent collaboration offers a promising avenue to transcend these boundaries. ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMARTI-MARSÂ²: Scaling Multi-Agent Self-Search via Reinforcement Learning for Code Generation

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ï¼ˆå¦‚ä»£ç ç”Ÿæˆï¼‰ä¸­å­˜åœ¨**å•æ™ºèƒ½ä½“æ€§èƒ½ç“¶é¢ˆ**ã€‚å°½ç®¡å·²æœ‰ç ”ç©¶å°è¯•é€šè¿‡å¤šæ™ºèƒ½ä½“åä½œæå‡æ€§èƒ½ï¼Œä½†ç°æœ‰æ¡†æ¶é€šå¸¸ä¾èµ–äºåŸºäºæç¤ºçš„æµ‹è¯•æ—¶äº¤äº’ï¼ˆprompt-based TTSï¼‰æˆ–åŒè´¨åŒ–å‚æ•°å…±äº«çš„å¤šè§’è‰²é…ç½®ï¼ˆhomogeneous multi-roleï¼‰ï¼Œè¿™é™åˆ¶äº†é”™è¯¯çº æ­£èƒ½åŠ›å’Œç­–ç•¥å¤šæ ·æ€§ï¼Œéš¾ä»¥çªç ´å•æ¨¡å‹çš„èƒ½åŠ›ä¸Šé™ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡º **MARTI-MARSÂ²**ï¼ˆMulti-Agent Reinforced Training and Inference Framework with Self-Search Scalingï¼‰ï¼Œä¸€ä¸ªç»Ÿä¸€çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸æ¨ç†æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **å°†å¤šæ™ºèƒ½ä½“åä½œå»ºæ¨¡ä¸ºå¯å­¦ä¹ çš„åŠ¨æ€ç¯å¢ƒ**ï¼šé¦–æ¬¡å°†å¤šæ™ºèƒ½ä½“ååŒæ¢ç´¢è¿‡ç¨‹å½¢å¼åŒ–ä¸ºä¸€ä¸ªå¯å­¦ä¹ çš„åŠ¨æ€ç¯å¢ƒï¼Œä½¿æ™ºèƒ½ä½“èƒ½é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è¿­ä»£ä¼˜åŒ–è‡ªèº«ç­–ç•¥ã€‚
- **ä»åŒè´¨åˆ°å¼‚è´¨çš„æ¼”è¿›è·¯å¾„**ï¼š
  - **Homo-MARSÂ²**ï¼šå‚æ•°å…±äº«çš„å¤šè§’è‰²è®­ç»ƒï¼Œæå‡åˆæœŸæ”¶æ•›é€Ÿåº¦ã€‚
  - **Heter-MARSÂ²**ï¼šå‚æ•°ç‹¬ç«‹çš„å¼‚æ„å¤šæ™ºèƒ½ä½“è®­ç»ƒï¼Œæ‰“ç ´ç­–ç•¥åŒè´¨åŒ–ï¼Œå®ç°æ›´é«˜æ€§èƒ½ä¸Šé™ã€‚
- **é«˜æ•ˆçš„æ¨ç†ç­–ç•¥ MARSÂ²-T+**ï¼šç»“åˆç»“æ„åŒ–é”™è¯¯åé¦ˆã€æ·±åº¦å¼•å¯¼æ¢ç´¢å’Œé¢„è®­ç»ƒ Reward Modelï¼ˆRMï¼‰ï¼Œæ˜¾è‘—æå‡æµ‹è¯•æ—¶æœç´¢ï¼ˆTTSï¼‰æ•ˆç‡ä¸ç¨³å®šæ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | MARTI-MARSÂ² ä¼˜åŠ¿ |
|------|------------------|
| **è®­ç»ƒèŒƒå¼** | è¶…è¶Šä¼ ç»Ÿå•æ™ºèƒ½ä½“ RL å’ŒåŒè´¨å¤šè§’è‰²ï¼Œå¼•å…¥å¼‚æ„å¤šæ™ºèƒ½ä½“è”åˆè®­ç»ƒï¼Œå¢å¼ºç­–ç•¥å¤šæ ·æ€§ |
| **æ¨ç†æœºåˆ¶** | å¼•å…¥ç»†ç²’åº¦é”™è¯¯åé¦ˆä¸æ·±åº¦å¼•å¯¼ï¼Œå…‹æœ Vanilla TTS æµ…å±‚æœç´¢ç¼ºé™· |
| **è¯„ä¼°æœºåˆ¶** | ä½¿ç”¨é«˜è´¨é‡ RM ç¼“è§£â€œå¥–åŠ±æ¬ºéª—â€ï¼ˆreward hackingï¼‰ï¼Œæå‡æœ€ç»ˆé€‰æ‹©çš„é²æ£’æ€§ |
| **ç³»ç»Ÿè®¾è®¡** | æ”¯æŒå¼‚æ­¥åŠ¨æ€æ›´æ–°ï¼Œè§£å†³å¤šæ™ºèƒ½ä½“æ•°æ®ä¸å¹³è¡¡å¯¼è‡´çš„è®­ç»ƒé˜»å¡é—®é¢˜ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **è®­ç»ƒæ•°æ®**ï¼šåŸºäº DeepCoder å‘å¸ƒçš„å¼€æºç¼–ç¨‹æ•°æ®é›†ï¼Œç»è¿‡è¿‡æ»¤åä¿ç•™ 7,992 ä¸ªç¼–ç æç¤ºã€‚
- **è¯„ä¼°åŸºå‡†**ï¼š**LiveCodeBench (v6)**ï¼Œå‘å¸ƒäºåŸºç¡€ LLM å¼€å‘ä¹‹åï¼Œç¡®ä¿æ— æ•°æ®æ³„éœ²é£é™©ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
#### æ¨¡å‹è§„æ¨¡
ä½¿ç”¨å¤šä¸ªå¼€æº LLMï¼Œæ¶µç›–ä¸åŒå‚æ•°é‡çº§ï¼š
- **8B ç³»åˆ—**ï¼šQwen3-8B, AReaL-boba-2-8B
- **14B ç³»åˆ—**ï¼šQwen3-14B, AReaL-boba-2-14B, DeepCoder-14B
- **32B ç³»åˆ—**ï¼šQwen3-32B, Nemotron-32B

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Pass@1** | å•æ¬¡é‡‡æ ·ä¸‹ç”Ÿæˆæ­£ç¡®ä»£ç çš„æ¦‚ç‡ï¼Œè¡¡é‡åŸºç¡€æ¨ç†èƒ½åŠ› |
| **Pass@1(MCTS)** | åœ¨ MCTS æœç´¢åé€‰å‡ºæœ€ä¼˜è§£çš„å‡†ç¡®ç‡ï¼Œåæ˜ æ¨ç†æ‰©å±•èƒ½åŠ› |
| **Pass@N** | N æ¬¡é‡‡æ ·ä¸­è‡³å°‘æœ‰ä¸€æ¬¡æ­£ç¡®çš„æ¦‚ç‡ï¼Œä½“ç°ç”Ÿæˆå¤šæ ·æ€§ä¸æˆåŠŸç‡ |
| **Diversity Metrics** | åŒ…æ‹¬ AECï¼ˆè¯­ä¹‰èšç±»æ•°ï¼‰ã€DA@Kï¼ˆç®—æ³•ç§ç±»æ•°ï¼‰ã€EAï¼ˆæœ‰æ•ˆç®—æ³•æ•°ï¼‰ã€NAUADCï¼ˆå¤šæ ·æ€§æ›²çº¿ä¸‹é¢ç§¯ï¼‰ã€G-Vendiï¼ˆè®¤çŸ¥ç­–ç•¥å¤šæ ·æ€§ï¼‰ç­‰ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | æè¿° |
|------|------|
| **Vanilla-GRPO** | å•æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ åŸºçº¿ï¼Œä½¿ç”¨ Group Relative Policy Optimization |
| **Homo-MARSÂ²** | å‚æ•°å…±äº«çš„å¤šè§’è‰²è®­ç»ƒ |
| **AB-MCTS** | è‡ªé€‚åº”åˆ†æ”¯è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼Œä»£è¡¨ä¸»æµ TTS æ–¹æ³• |
| **Closed-source Baselines** | å¦‚ GPT-5.1, O4-Mini(high), Gemini ç­‰é—­æºæ¨¡å‹ä½œä¸ºæ€§èƒ½å‚ç…§ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- **Heter-MARSÂ²ï¼ˆåŒ 32B æ¨¡å‹ï¼‰** åœ¨ LiveCodeBench ä¸Šè¾¾åˆ° **77.7% Pass@1(MCTS)**ï¼Œ**è¶…è¶Š GPT-5.1 å’Œ O4-Mini(high)**ã€‚
- åœ¨ 14B å¤šæ¨¡å‹ç»„åˆä¸­ï¼ŒHeter-MARSÂ² å®ç° **81.7% Pass@K**ï¼Œæ˜¾è‘—é«˜äºåŸºçº¿ã€‚
- MARSÂ²-T+ å°† Vanilla TTS çš„ Pass@1(MCTS) ä» 54.3% æå‡è‡³ **57.7%**ï¼ˆQwen3-8Bï¼‰ï¼Œå¹¶è¿›ä¸€æ­¥æå‡åˆ° **62.9%**ï¼ˆä¸¤æ¨¡å‹åä½œï¼‰ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| æ–¹æ³• | Pass@1(MCTS) æå‡ï¼ˆå…¸å‹åœºæ™¯ï¼‰ | å¤‡æ³¨ |
|------|-------------------------------|------|
| Homo-MARSÂ² vs GRPO | +4.6% ~ +5.1% | åˆæœŸå¿«é€Ÿæ”¶æ•›ï¼ŒåæœŸæ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ |
| Heter-MARSÂ² vs Homo-MARSÂ² | +2.9% ~ +3.5% | æ˜¾è‘—çªç ´åŒè´¨åŒ–ç“¶é¢ˆ |
| MARSÂ²-T+ vs Vanilla TTS | +3.4% ~ +5.8% | æ¨ç†é˜¶æ®µå¢ç›Šæ˜æ˜¾ |
| Heter-MARSÂ² (32BÃ—2) vs GPT-5.1 | **æ›´é«˜æ€§èƒ½** | è¾¾åˆ°ç”šè‡³è¶…è¶Šé¡¶å°–é—­æºæ¨¡å‹æ°´å¹³ |

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰å¥–åŠ±æ¨¡å‹ï¼ˆRMï¼‰çš„ä½œç”¨
- ä½¿ç”¨åœ¨è®­ç»ƒè½¨è¿¹ä¸Šå¾®è°ƒçš„ RM å¯æ˜¾è‘—æå‡ TTS ç¨³å®šæ€§ï¼š
  - AUC-ROC ä» 73.0% â†’ **79.3%**
  - Spearman ç›¸å…³æ€§ä» 39.7 â†’ **50.6**
- è‹¥ä»…ç”¨é€šç”¨ RMï¼ˆå¦‚ Skywork-Rewardï¼‰ï¼Œæ€§èƒ½æå‡æœ‰é™ï¼ŒéªŒè¯äº†**ä»»åŠ¡å¯¹é½ RM çš„å¿…è¦æ€§**ã€‚

#### ï¼ˆ2ï¼‰é”™è¯¯åé¦ˆä¸æ·±åº¦å¼•å¯¼çš„é‡è¦æ€§
- ç§»é™¤é”™è¯¯åé¦ˆæˆ–æ·±åº¦å¼•å¯¼ä¼šå¯¼è‡´ï¼š
  - æ·±å±‚èŠ‚ç‚¹æ¯”ä¾‹ä¸‹é™ï¼ˆ<7%ï¼‰
  - Pass@1(MCTS) å‡ºç°è½»å¾®é€€åŒ–ï¼ˆå¦‚ -0.3%ï¼‰
- ä¸‰è€…ååŒï¼ˆé”™è¯¯åé¦ˆ + æ·±åº¦å¼•å¯¼ + RMï¼‰å¸¦æ¥æœ€å¤§æ”¶ç›Šï¼Œè¯æ˜å…¶æ„æˆ**ååŒè¿›åŒ–ä¸‰è§’**ã€‚

#### ï¼ˆ3ï¼‰å¤šæ ·æ€§åˆ†æ
| æ–¹æ³• | DA@K â†‘ | EA â†‘ | NAUADC â†‘ | G-Vendi â†‘ |
|------|--------|-------|----------|-----------|
| Heter-MARSÂ² (14B, 3-model) | **1.941** | **1.544** | **2.033** | **8.719** |
| Homo-MARSÂ² | 1.837 | 1.445 | 1.889 | 8.750 |
| Vanilla TTS | 1.882 | 1.478 | 1.962 | 8.808 |

> æ³¨ï¼šHeter-MARSÂ² åœ¨ç®—æ³•å¤šæ ·æ€§ï¼ˆDA@Kï¼‰å’Œåˆ†å¸ƒå‡åŒ€æ€§ï¼ˆEAï¼‰ä¸Šè¡¨ç°æœ€ä½³ï¼Œè€Œ G-Vendi è¡¨æ˜å…¶ä¹Ÿæå‡äº†è®¤çŸ¥ç­–ç•¥å¤šæ ·æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **å¤šæ™ºèƒ½ä½“åä½œæ˜¯è¶…è¶Šå•æ¨¡å‹æ€§èƒ½å¤©èŠ±æ¿çš„å…³é”®è·¯å¾„**  
   ä»å•æ™ºèƒ½ä½“ â†’ åŒè´¨å¤šè§’è‰² â†’ å¼‚æ„å¤šæ™ºèƒ½ä½“ï¼Œå½¢æˆä¸€æ¡æ¸…æ™°çš„**å¤šæ™ºèƒ½ä½“æ‰©å±•å®šå¾‹ï¼ˆscaling lawï¼‰**ï¼Œæ¯ä¸€æ­¥éƒ½å¸¦æ¥æ›´é«˜çš„ RL æ€§èƒ½ä¸Šé™ã€æ›´å¼ºçš„ TTS èƒ½åŠ›å’Œæ›´å¤§çš„ç­–ç•¥å¤šæ ·æ€§ã€‚

2. âœ… **ç­–ç•¥å¤šæ ·æ€§æ˜¯æ™ºèƒ½æ‰©å±•çš„æ ¸å¿ƒç»´åº¦**  
   è®ºæ–‡é¦–æ¬¡ç³»ç»ŸéªŒè¯ï¼š**policy diversity æ˜¯ä¸è®¡ç®—é‡ã€æ¨¡å‹å¤§å°åŒç­‰é‡è¦çš„æ‰©å±•è½´**ã€‚å¼‚æ„æ™ºèƒ½ä½“é€šè¿‡äº’è¡¥è§†è§’å’Œäº¤å‰çº é”™ï¼Œæ˜¾è‘—æå‡æ•´ä½“é²æ£’æ€§å’Œæ¢ç´¢å¹¿åº¦ã€‚

3. âœ… **è®­ç»ƒä¸æ¨ç†éœ€ååŒè®¾è®¡**  
   MARSÂ² è®­ç»ƒå‡ºçš„åä½œæ¨¡å¼ï¼Œåªæœ‰åœ¨ MARSÂ²-T+ çš„æ¨ç†æœºåˆ¶ä¸‹æ‰èƒ½å……åˆ†é‡Šæ”¾æ½œåŠ›ï¼ŒäºŒè€…å½¢æˆ**æ­£å‘å¢å¼ºé—­ç¯**ã€‚å•çº¯å †å æœªè®­ç»ƒçš„å¤šæ¨¡å‹æ— æ³•è·å¾—åŒç­‰æ”¶ç›Šã€‚

4. âœ… **é”™è¯¯ä¿¡å·çš„æœ‰æ•ˆåˆ©ç”¨è‡³å…³é‡è¦**  
   Vanilla TTS ä»…æä¾›äºŒå€¼åé¦ˆï¼Œè€Œ MARSÂ²-T+ å¼•å…¥ç»“æ„åŒ–é”™è¯¯è¯Šæ–­ï¼ˆå¦‚è¾“å…¥è¾“å‡ºä¸åŒ¹é…ã€è¿è¡Œæ—¶å¼‚å¸¸è¿½è¸ªï¼‰ï¼Œæå¤§æå‡äº†ä¿®æ­£ç²¾åº¦ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **è®¡ç®—èµ„æºæ¶ˆè€—å¤§**ï¼šæ¯ä¸ªæ™ºèƒ½ä½“ç‹¬å ä¸€ä¸ªå®Œæ•´èŠ‚ç‚¹ï¼ˆ8Ã—H200 GPUï¼‰ï¼Œé™åˆ¶äº†å¤§è§„æ¨¡éƒ¨ç½²ã€‚
- **ä¾èµ–é«˜è´¨é‡ RM**ï¼šè‹¥ RM æœªèƒ½å‡†ç¡®é¢„æµ‹ç§æœ‰æµ‹è¯•é€šè¿‡ç‡ï¼Œåˆ™æœ€ç»ˆé€‰æ‹©å¯èƒ½å¤±æ•ˆã€‚
- **å½“å‰ä»»åŠ¡ä»è¾ƒå­¤ç«‹**ï¼šå®éªŒé›†ä¸­åœ¨å•ä¸ªç¼–ç¨‹é¢˜æ±‚è§£ï¼Œå°šæœªæ¶‰åŠè·¨ä»»åŠ¡ã€é•¿æœŸè§„åˆ’ç­‰æ›´å¤æ‚çš„ç»„ç»‡çº§åä½œåœºæ™¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- ğŸ”„ **æ¢ç´¢æ›´é«˜æ•ˆçš„å¼‚æ„æ¶æ„**ï¼šå¦‚æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æˆ–å¤šæ¨¡æ€ä»£ç†åä½œã€‚
- ğŸ—ï¸ **æ„å»ºä¼ä¸šçº§å¤šæ™ºèƒ½ä½“åä½œå¹³å°**ï¼šé¢å‘çœŸå®ç»„ç»‡æµç¨‹ä¸­çš„å¤æ‚å†³ç­–ä¸æ‰§è¡Œä»»åŠ¡ã€‚
- ğŸ” **å‘å±•æ›´å¼ºå¤§çš„è‡ªç›‘ç£ RM**ï¼šå‡å°‘å¯¹å¤–éƒ¨æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œå®ç°ç«¯åˆ°ç«¯è‡ªæˆ‘è¿›åŒ–ã€‚
- ğŸ“ˆ **æŒ–æ˜ä¸‹ä¸€ä»£å¤šæ™ºèƒ½ä½“æ‰©å±•è§„å¾‹**ï¼šä»é™æ€åä½œè¿ˆå‘åŠ¨æ€æ¶Œç°ã€è§’è‰²è‡ªç»„ç»‡çš„é«˜çº§æ™ºèƒ½å½¢æ€ã€‚

---

> **ä¸€å¥è¯æ€»ç»“**ï¼š  
> MARTI-MARSÂ² æ­ç¤ºäº†ä¸€æ¡é€šå¾€æ›´å¼º LLM æ¨ç†èƒ½åŠ›çš„æ–°è·¯å¾„â€”â€”**é€šè¿‡å¼‚æ„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼Œä»¥ç­–ç•¥å¤šæ ·æ€§ä¸ºé©±åŠ¨åŠ›ï¼Œå®ç°è¶…è¶Šå•æ¨¡å‹æé™çš„ç³»ç»Ÿæ€§æ€§èƒ½è·ƒè¿**ã€‚

</details>

---

### 12. [FEM-Informed Hypergraph Neural Networks for Efficient Elastoplasticity](https://arxiv.org/abs/2602.07364)

**Authors**: Jianchuan Yang, Xi Chen, Jidong Zhao  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.07364v1  

#### Abstract
Graph neural networks (GNNs) naturally align with sparse operators and unstructured discretizations, making them a promising paradigm for physics-informed machine learning in computational mechanics. Motivated by discrete physics losses and Hierarchical Deep Learning Neural Network (HiDeNN) construc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFEM-Informed Hypergraph Neural Networks for Efficient Elastoplasticity

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿ **Physics-Informed Neural Networks (PINNs)** åœ¨æ±‚è§£éçº¿æ€§ **elastoplasticity**ï¼ˆå¼¹å¡‘æ€§ï¼‰é—®é¢˜æ—¶é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **é«˜è®¡ç®—æˆæœ¬**ï¼šä¾èµ– Automatic Differentiation (AD) å¯¼è‡´è®¡ç®—å›¾åºå¤§ï¼Œè®­ç»ƒç¼“æ…¢ã€‚
- **ç²¾åº¦ä¸è¶³**ï¼šåœ¨å¤æ‚å‡ ä½•ã€å¾ªç¯åŠ è½½ï¼ˆcyclic loadingï¼‰ã€ææ–™ç¡¬åŒ–ï¼ˆhardeningï¼‰ç­‰åœºæ™¯ä¸‹é¢„æµ‹è¯¯å·®å¤§ã€‚
- **è¾¹ç•Œæ¡ä»¶å¤„ç†å›°éš¾**ï¼šDirichlet å’Œ Neumann è¾¹ç•Œæ¡ä»¶éš¾ä»¥æœ‰æ•ˆæ–½åŠ ï¼Œæ˜“å¯¼è‡´æ¢¯åº¦å¤±è¡¡ã€‚
- **é»‘ç®±å»ºæ¨¡**ï¼šç½‘ç»œä½œä¸ºé»‘ç›’ä»£ç†ï¼Œç¼ºä¹ç‰©ç†å¯è§£é‡Šæ€§ã€‚

### æå‡ºçš„æ–°æ–¹æ³•
ä½œè€…æå‡ºäº†ä¸€ç§ **FEM-Informed Hypergraph Neural Networks (FHGNN)**ï¼Œå°†æœ‰é™å…ƒæ³•ï¼ˆFEMï¼‰çš„è®¡ç®—æµç¨‹åµŒå…¥åˆ° GNN çš„æ¶ˆæ¯ä¼ é€’æœºåˆ¶ä¸­ï¼Œæ„å»ºä¸€ä¸ª**ç‰©ç†ä¸€è‡´ã€ç™½ç›’åŒ–ã€é«˜æ•ˆ**çš„æœºå™¨å­¦ä¹ æ¡†æ¶ã€‚

#### åˆ›æ–°ç‚¹ï¼š
1. **èŠ‚ç‚¹-å•å…ƒè¶…å›¾è¡¨ç¤ºï¼ˆNode-element Hypergraphï¼‰**  
   å°† FEM ç½‘æ ¼å»ºæ¨¡ä¸ºè¶…å›¾ $ G=(V, C, \mathcal{E}) $ï¼Œå…¶ä¸­ï¼š
   - $ V $ï¼šç½‘æ ¼èŠ‚ç‚¹
   - $ C $ï¼šå•å…ƒï¼ˆè§†ä¸ºç¬¬äºŒç±»èŠ‚ç‚¹ï¼‰
   - $ \mathcal{E} $ï¼šèŠ‚ç‚¹ä¸å•å…ƒä¹‹é—´çš„å…³è”è¾¹  
   è¿™ç§ç»“æ„å¤©ç„¶æ”¯æŒéç»“æ„åŒ–ç½‘æ ¼å’Œå¤æ‚å‡ ä½•ã€‚

2. **FEM è®¡ç®—æµç¨‹åµŒå…¥æ¶ˆæ¯ä¼ é€’å±‚**  
   è®¾è®¡ä¸‰ä¸ªå¯å¾®åˆ†çš„æ¶ˆæ¯ä¼ é€’æ¨¡å—ï¼Œåˆ†åˆ«å¯¹åº” FEM çš„æ ¸å¿ƒæ­¥éª¤ï¼š
   - **Isoparametric Transformation Layer**ï¼šè®¡ç®—é›…å¯æ¯”çŸ©é˜µå’Œç‰©ç†åŸŸå½¢å‡½æ•°æ¢¯åº¦ã€‚
   - **Strain-Stress Layer**ï¼šåŸºäºä½ç§»åœºè®¡ç®—åº”å˜å’Œåº”åŠ›ï¼ˆæ”¯æŒ J2 plasticityï¼‰ã€‚
   - **Global Internal Force Layer**ï¼šç»„è£…å•å…ƒå†…åŠ›å‘é‡è‡³å…¨å±€èŠ‚ç‚¹ã€‚

3. **ç«¯åˆ°ç«¯å¯å¾® + ç‰©ç†é©±åŠ¨è®­ç»ƒ**  
   - ä¸éœ€è¦æ ‡ç­¾æ•°æ®ï¼ˆlabel-freeï¼‰ï¼Œä»…é€šè¿‡ç‰©ç†æŸå¤±å‡½æ•°è¿›è¡Œè®­ç»ƒã€‚
   - æ‰€æœ‰å˜é‡ï¼ˆå¦‚èŠ‚ç‚¹åæ ‡ $ v_j $ã€ä½ç§» $ u_j $ï¼‰å‡å¯è®¾ä¸ºå¯ä¼˜åŒ–å‚æ•°ï¼Œæ”¯æŒ **r-adaptivity**ï¼ˆç½‘æ ¼è‡ªé€‚åº”ï¼‰ã€‚

4. **é«˜æ•ˆçš„ç¦»æ•£å˜åˆ†æŸå¤±å‡½æ•°**  
   æ¨èä½¿ç”¨èƒ½é‡å½¢å¼çš„æŸå¤±å‡½æ•°ï¼ˆ`â„’_energy`ï¼‰ï¼Œç›¸æ¯” Galerkin æŸå¤±æ›´ç¨³å®šã€æ”¶æ•›æ›´å¿«ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼ ç»Ÿ PINN / MLP | FHGNN |
|------|------------------|--------|
| æ¶æ„ | é»‘ç®± MLPï¼Œå…¨è¿æ¥ | ç™½ç›’ GNNï¼ŒåµŒå…¥ FEM æµç¨‹ |
| å¾®åˆ†æ–¹å¼ | ADï¼ˆé«˜é˜¶å¯¼æ•°ä»£ä»·é«˜ï¼‰ | FEM å½¢å‡½æ•°æ¢¯åº¦ï¼ˆç¨€ç–ã€å±€éƒ¨ï¼‰ |
| å‡ ä½•é€‚åº”æ€§ | ä¾èµ–è§„åˆ™ç½‘æ ¼æˆ–åæ ‡å˜æ¢ | æ”¯æŒä»»æ„éç»“æ„åŒ–ç½‘æ ¼ |
| è¾¹ç•Œæ¡ä»¶ | éœ€é¢å¤–æƒ©ç½šé¡¹ | é€šè¿‡æ©ç ç›´æ¥æ–½åŠ  Dirichlet æ¡ä»¶ |
| æ•ˆç‡ | éš DOF å¢é•¿æ€¥å‰§ä¸‹é™ | GPU å¹¶è¡Œ + å±€éƒ¨æ“ä½œï¼Œæ‰©å±•æ€§å¼º |
| å¯è§£é‡Šæ€§ | å·® | å¼ºï¼ˆæ¯æ­¥å¯¹åº”æ˜ç¡®ç‰©ç†æ„ä¹‰ï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†ä¸é—®é¢˜è®¾ç½®
æ‰€æœ‰å®éªŒå‡åŸºäº **Abaqus** ç”Ÿæˆçš„ FEM è§£ä½œä¸ºå‚è€ƒçœŸå€¼ï¼Œå…±æµ‹è¯•äº”ç±» 3D å¼¹å¡‘æ€§åŸºå‡†é—®é¢˜ï¼š
1. **2D/3D å¡‘æ€§åŸºç¡€ï¼ˆPlastic Footingï¼‰**ï¼šéªŒè¯å¾ªç¯åŠ è½½ä¸‹çš„å“åº”ã€‚
2. **3D çº¿æ€§ç¡¬åŒ–æ‚¬è‡‚æ¢ï¼ˆCantilever Beamï¼‰**ï¼šå« isotropic/kinematic hardeningã€‚
3. **å¤æ‚å·¥ä»¶ï¼ˆWorkpieceï¼‰**ï¼šå¤æ‚å‡ ä½• + kinematic hardeningã€‚
4. **åŒææ–™å¸¦å­”æ¿ï¼ˆBi-material Plate with Holeï¼‰**ï¼šææ–™ä¸è¿ç»­ + åº”åŠ›é›†ä¸­ã€‚

### å®éªŒè®¾ç½®
- **å®ç°å¹³å°**ï¼šPyTorch Geometric (PyG)ï¼ŒGPU åŠ é€Ÿï¼ˆNVIDIA RTX 4090ï¼‰ã€‚
- **ä¼˜åŒ–å™¨**ï¼šL-BFGSï¼Œåˆå§‹æ­¥é•¿ 1.0ã€‚
- **è¾“å…¥**ï¼šèŠ‚ç‚¹åæ ‡ã€å•å…ƒè¿æ¥å…³ç³»ã€é«˜æ–¯ç‚¹ä¿¡æ¯ã€‚
- **è¾“å‡º**ï¼šèŠ‚ç‚¹ä½ç§»ã€å•å…ƒçº§åº”å˜/åº”åŠ›ã€ç­‰æ•ˆå¡‘æ€§åº”å˜ $ \bar{\varepsilon}^p $ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **ç›¸å¯¹ L2 è¯¯å·®**ï¼š
  $$
  L_2 = \frac{\|u - u^*\|_2}{\|u^*\|_2}
  $$
- **å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰**ï¼š
  $$
  \text{MAE} = \frac{1}{N}\sum |u_i - u_i^*|
  $$

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **PINN (MLP-based)** | å¤šå±‚æ„ŸçŸ¥æœº + AD + PDE æ®‹å·®æŸå¤± |
| **PIMLP** | ä½¿ç”¨ FEM å½¢å‡½æ•°æ¢¯åº¦æ„é€ èƒ½é‡æŸå¤±çš„ MLP æ¨¡å‹ |
| **PIGCN** | å›¾å·ç§¯ç½‘ç»œï¼ˆChebyshev GCNï¼‰å­¦ä¹ ä»åæ ‡åˆ°ä½ç§»çš„æ˜ å°„ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### è¡¨ 1ï¼š3D çº¿æ€§ç¡¬åŒ–æ‚¬è‡‚æ¢ï¼ˆ160Ã—40Ã—40 ç½‘æ ¼ï¼Œ768,000 DOFsï¼‰
| Method | Time (s) | L2_ux | L2_uy | MAE_ÎµÌ…p |
|--------|----------|--------|--------|---------|
| PIMLP | 737.6 | 1.85E-01 | 6.52E-02 | 2.50E-3 |
| PIGCN | 2,520.6 | 1.28E-01 | 3.38E-02 | 2.10E-3 |
| **FHGNN** | **145.51** | **4.80E-04** | **3.19E-04** | **6.10E-6** |

> âœ… **é€Ÿåº¦æå‡çº¦ 3Ã—ï¼Œè¯¯å·®é™ä½ä¸¤ä¸ªæ•°é‡çº§ä»¥ä¸Š**

#### è¡¨ 2ï¼š3D åŒææ–™å¸¦å­”æ¿ï¼ˆ54,402 å››é¢ä½“å•å…ƒï¼‰
| Method | Time (s) | L2_Ïƒxx | L2_Ïƒyy | L2_ÎµÌ…p | MAE_ÎµÌ…p |
|--------|----------|--------|--------|--------|---------|
| PIMLP | 108.14 | 8.89E-02 | 7.07E-01 | 8.77E-02 | 1.47E-03 |
| PIGCN | 201.49 | 5.31E-02 | 3.05E-01 | 3.38E-02 | 6.61E-04 |
| **FHGNN** | **59.80** | **5.78E-05** | **1.77E-04** | **6.31E-05** | **1.38E-06** |

> âœ… **ä¸ä»…å¿«ï¼Œè€Œä¸”å¯¹å¯¼å‡ºåœºï¼ˆstress, strainï¼‰é¢„æµ‹æ›´å‡†ç¡®**

#### è¡¨ 3ï¼šä¸å¤šæ ¸ FEM çš„æ•ˆç‡å¯¹æ¯”ï¼ˆä¸åŒç½‘æ ¼å¯†åº¦ï¼‰
| Mesh Size | FEM (8-core) | FHGNN (GPU) | Speedup |
|-----------|---------------|--------------|---------|
| 40Ã—10Ã—10 | 1s | 1.936s | Ã—0.5 |
| 80Ã—20Ã—20 | 8s | 12.18s | Ã—0.65 |
| 160Ã—40Ã—40 | 399s | 145.51s | **Ã—2.74** |
| 150Ã—50Ã—50 | 1021s | 286.92s | **Ã—3.56** |

> âœ… **åœ¨å¤§è§„æ¨¡é—®é¢˜ä¸Šæ˜¾è‘—ä¼˜äºå¹¶è¡Œ FEM**

### æ¶ˆèå®éªŒç»“æœï¼ˆæ¥è‡ª Section 3.6.3ï¼‰

#### ä¸åŒæŸå¤±å‡½æ•°å¯¹æ¯”ï¼ˆIsotropic Hardening Cantilever Beamï¼‰
| Loss Type | Epochs | Time (s) | L2_ux | Converged? |
|----------|--------|----------|--------|------------|
| Energy Loss | 5,000 | 145.5 | 4.80E-04 | âœ… Yes |
| Galerkin Loss | 78,384 | 15,753.9 | 9.42E-01 | âŒ No (å‘æ•£) |

> ğŸ” å‘ç°ï¼šéšç€ç½‘æ ¼ç»†åŒ–ï¼ŒGalerkin æŸå¤±çš„è¯¯å·®åè€Œä¸Šå‡ï¼ˆcondition number æ›´å¤§ï¼‰ï¼Œè€Œèƒ½é‡æŸå¤±å§‹ç»ˆç¨³å®šæ”¶æ•›ã€‚

#### è½¬ç§»å­¦ä¹ åŠ é€Ÿæ•ˆæœï¼ˆTransfer Learningï¼‰
- ä½¿ç”¨ç²—ç½‘æ ¼è§£ä½œä¸ºåˆå€¼ï¼Œåœ¨æœ€å¯†ç½‘æ ¼ä¸Šè®­ç»ƒï¼š
  - ä»é›¶å¼€å§‹ï¼šéœ€ ~5000 è¿­ä»£
  - è½¬ç§»å­¦ä¹ ï¼šä»…éœ€ ~1000 è¿­ä»£å³å¯æ”¶æ•›
> âœ… æ”¶æ•›é€Ÿåº¦æå‡ 4 å€ä»¥ä¸Š

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **FHGNN æ˜¾è‘—ä¼˜äºç°æœ‰ PINN å˜ä½“**  
   åœ¨å¤šä¸ª 3D å¼¹å¡‘æ€§é—®é¢˜ä¸Šï¼Œå®ç°äº† **>2Ã— é€Ÿåº¦æå‡** å’Œ **>100Ã— ç²¾åº¦æå‡**ã€‚

2. **FEM è®¡ç®—åµŒå…¥æ˜¯å…³é”®**  
   åˆ©ç”¨ FEM çš„å±€éƒ¨æ”¯æ’‘æ€§å’Œé¢„è®¡ç®—ç‰¹æ€§ï¼Œé¿å…äº† AD çš„é«˜å¼€é”€ï¼Œæå‡äº†è®­ç»ƒæ•ˆç‡å’Œç¨³å®šæ€§ã€‚

3. **èƒ½é‡æŸå¤±å‡½æ•°ä¼˜äº Galerkin æŸå¤±**  
   ç†è®ºåˆ†æè¡¨æ˜å…¶ Hessian æ¡ä»¶æ•°æ›´å°ï¼Œä¼˜åŒ–æ›´ç¨³å®šï¼›å®éªŒéªŒè¯å…¶æ”¶æ•›æ›´å¿«ã€æ›´å¯é ã€‚

4. **æ”¯æŒ r-adaptivity å’Œ Gauss ç‚¹ä¼˜åŒ–**  
   é€šè¿‡å°†èŠ‚ç‚¹åæ ‡è®¾ä¸ºå¯å¾®å˜é‡ï¼Œå¯å®ç°ç±»ä¼¼ FEM çš„ç½‘æ ¼è‡ªé€‚åº”æ›´æ–°ï¼Œå¹¶è¿›ä¸€æ­¥é™ä½ç³»ç»Ÿèƒ½é‡ã€‚

5. **å¯æ‰©å±•è‡³å¤§è§„æ¨¡å·¥ä¸šçº§é—®é¢˜**  
   åœ¨ç™¾ä¸‡ DOF çº§åˆ«ä»ä¿æŒé«˜æ•ˆï¼Œä¸” GPU å®ç°å·²èƒ½è¶…è¶Šå¤šæ ¸ CPU ä¸Šçš„ä¼ ç»Ÿ FEMã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä»…é€‚ç”¨äºå…·æœ‰æ˜¾å¼èƒ½é‡æ³›å‡½çš„ææ–™æ¨¡å‹ï¼ˆå¦‚ J2 plasticityï¼‰ã€‚
- å¯¹äºå¤æ‚æœ¬æ„æ¨¡å‹ï¼ˆå¦‚éå…³è”æµåŠ¨æ³•åˆ™ã€æŸä¼¤æ¼”åŒ–ï¼‰ï¼Œèƒ½é‡å‡½æ•°å¯èƒ½æ— æ³•é—­å¼è¡¨è¾¾ã€‚
- è¶…å›¾ç»“æ„è™½çµæ´»ï¼Œä½†åœ¨æç«¯éå‡åŒ€ç½‘æ ¼ä¸‹å¯èƒ½å½±å“èšåˆæ•ˆç‡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‹“å±•è‡³é€šç”¨æœ¬æ„æ¨¡å‹**  
   å¼€å‘å…¼å®¹è‡ªåŠ¨å¾®åˆ†çš„é€šç”¨å›æ˜ ç®—æ³•ï¼ˆreturn mappingï¼‰ï¼Œæ”¯æŒä»»æ„ yield surfaceã€‚
   
2. **å¤šç‰©ç†åœºè€¦åˆ**  
   ç»“åˆ DEMï¼ˆé¢—ç²’ä»‹è´¨ï¼‰ã€FVMï¼ˆæµä½“åŠ›å­¦ï¼‰ç­‰æ–¹æ³•ï¼Œæ„å»ºç»Ÿä¸€çš„å¯å¾®åˆ†å¤šç‰©ç†åœºæ±‚è§£å™¨ã€‚

3. **ç®—å­å­¦ä¹ èåˆ**  
   æ¢ç´¢ä¸ **FNO**ã€**DeepONet** ç­‰ç®—å­å­¦ä¹ æ–¹æ³•ç»“åˆï¼Œç”¨äºå¤šå°ºåº¦å»ºæ¨¡ã€‚

4. **å®éªŒæ•°æ®åŒåŒ–**  
   å¼•å…¥çœŸå®æµ‹é‡æ•°æ®è¿›è¡Œè”åˆä¼˜åŒ–ï¼Œæå‡æ¨¡å‹åœ¨å®é™…å·¥ç¨‹ä¸­çš„é€‚ç”¨æ€§ã€‚

5. **é«˜æ•ˆæ¶ˆæ¯ä¼ é€’æ¨¡å—è®¾è®¡**  
   ä»å¤§æ•°æ®ä¸­å­¦ä¹ æ›´é«˜æ•ˆçš„ message-passing è§„åˆ™ï¼Œè¶…è¶Šæ ‡å‡† FEM å…¬å¼ã€‚

---

> ğŸ“Œ **æ€»ä½“è¯„ä»·**ï¼šè¯¥è®ºæ–‡æˆåŠŸåœ°å°† FEM çš„æ•°å€¼ç¨³å¥æ€§ä¸ GNN çš„çµæ´»æ€§ç›¸ç»“åˆï¼Œæå‡ºäº†ä¸€ç§**å¯æ‰©å±•ã€é«˜æ•ˆã€ç‰©ç†ä¸€è‡´**çš„æ–°å‹ PINN èŒƒå¼ï¼Œä¸ºéçº¿æ€§å›ºä½“åŠ›å­¦çš„å¤§è§„æ¨¡ä»¿çœŸæä¾›äº†å¼ºæœ‰åŠ›çš„æ›¿ä»£æ–¹æ¡ˆã€‚ä»£ç å·²å¼€æºï¼šhttps://github.com/yjc0416/FEM-Informed-Hypergraph-Neural-Networks

</details>

---

### 13. [Towards Adaptive, Scalable, and Robust Coordination of LLM Agents: A Dynamic Ad-Hoc Networking Perspective](https://arxiv.org/abs/2602.08009)

**Authors**: Rui Li, Zeyu Zhang, Xiaohe Bo, Quanyu Dai, Chaozhuo Li, Feng Wen, Xu Chen  
**Category**: cs.AI  
**Published**: 2026-02-10  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.08009v1  

#### Abstract
Multi-agent architectures built on large language models (LLMs) have demonstrated the potential to realize swarm intelligence through well-crafted collaboration. However, the substantial burden of manual orchestration inherently raises an imperative to automate the design of agentic workflows. We fr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTowards Adaptive, Scalable, and Robust Coordination of LLM Agents: A Dynamic Ad-Hoc Networking Perspective

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰çš„ **Multi-Agent Systems (MAS)** åœ¨åè°ƒ LLM Agents æ—¶é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **Adaptivityï¼ˆé€‚åº”æ€§ï¼‰**ï¼šä¼ ç»Ÿæ–¹æ³•ä¾èµ–é¢„å®šä¹‰çš„é™æ€æ‹“æ‰‘ï¼ˆå¦‚é“¾å¼ã€æ˜Ÿå‹ï¼‰ï¼Œæ— æ³•æ ¹æ®åŠ¨æ€ä»»åŠ¡æµè°ƒæ•´é€šä¿¡è·¯å¾„ã€‚
- **Scalabilityï¼ˆå¯æ‰©å±•æ€§ï¼‰**ï¼šå½“ä»£ç†æ•°é‡å˜åŒ–æ—¶ï¼Œéœ€é‡æ–°ä¼˜åŒ–æ•´ä¸ªå·¥ä½œæµï¼Œæˆæœ¬é«˜æ˜‚ï¼›ä¸­å¿ƒåŒ–æ§åˆ¶å™¨éšè§„æ¨¡æ‰©å¤§è€Œæˆä¸ºç“¶é¢ˆã€‚
- **Robustnessï¼ˆé²æ£’æ€§ï¼‰**ï¼šå­˜åœ¨å•ç‚¹æ•…éšœé£é™©ï¼ˆSingle Point of Failure, SPoFï¼‰ï¼Œæ¶æ„æˆ–é”™è¯¯è¡Œä¸ºçš„ä»£ç†å¯èƒ½æ±¡æŸ“å…¨å±€ç³»ç»Ÿã€‚

è¿™äº›é—®é¢˜æºäºç°æœ‰æ–¹æ³•è¦ä¹ˆæ˜¯â€œcommunication-agnosticâ€ï¼ˆé€šä¿¡æ— å…³çš„ç¦»çº¿æœç´¢ï¼‰ï¼Œè¦ä¹ˆä¾èµ–è„†å¼±çš„â€œmeta-controllerâ€è¿›è¡Œé›†ä¸­æ§åˆ¶ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šRAPS
ä½œè€…æå‡º **RAPS (Reputation-Aware Publish-Subscribe)** èŒƒå¼ï¼Œå°†å¤šæ™ºèƒ½ä½“åè°ƒé—®é¢˜ç±»æ¯”ä¸º **Dynamic Ad-Hoc Networkingï¼ˆåŠ¨æ€è‡ªç»„ç»‡ç½‘ç»œï¼‰** ä¸­çš„ç»å…¸é—®é¢˜ï¼Œå¹¶æ„å»ºäº†ä¸€ä¸ªå»ä¸­å¿ƒåŒ–ã€æ„å›¾é©±åŠ¨çš„é€šä¿¡æ¡†æ¶ã€‚

#### æ ¸å¿ƒæ¶æ„ï¼ˆä¸‰å±‚è®¾è®¡ï¼‰
| å±‚çº§ | ç»„ä»¶ | åŠŸèƒ½ |
|------|------|------|
| **Substrateï¼ˆåº•å±‚ï¼‰** | Distributed Publish-Subscribe Protocol | å»ä¸­å¿ƒåŒ–çš„æ¶ˆæ¯åˆ†å‘æœºåˆ¶ï¼ŒåŸºäºè¯­ä¹‰æ„å›¾åŒ¹é…è€Œéå›ºå®šæ‹“æ‰‘ |
| **Overlay I** | Reactive Subscription | ä»£ç†åœ¨è¿è¡Œæ—¶åŠ¨æ€æ›´æ–°è‡ªèº«è®¢é˜…æ„å›¾ï¼ˆintentï¼‰ï¼Œå®ç°è‡ªé€‚åº”è§’è‰²æ¼”åŒ– |
| **Overlay II** | Bayesian Reputation | æ¯ä¸ªä»£ç†é…å¤‡æœ¬åœ°â€œwatchdogâ€ï¼Œé€šè¿‡è´å¶æ–¯ä¼°è®¡ç»´æŠ¤å¯¹ç­‰æ–¹çš„ä¿¡èª‰ï¼Œå®ç°å»ä¸­å¿ƒåŒ–ä¿¡ä»»ç®¡ç† |

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | RAPS | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ GPTSwarm, Puppeteerï¼‰ |
|------|------|-------------------------------|
| **Adaptivity** | âœ… è¿è¡Œæ—¶åŠ¨æ€è°ƒæ•´æ„å›¾ä¸è·¯ç”± | âŒ å›ºå®šæ‹“æ‰‘æˆ–ä¾èµ–ä¸­å¿ƒæ§åˆ¶å™¨ |
| **Scalability** | âœ… æ”¯æŒä»£ç†è‡ªç”±åŠ å…¥/é€€å‡ºï¼Œæ— éœ€é‡è®­ç»ƒ | âŒ æ–°å¢ä»£ç†éœ€é‡æ–°ä¼˜åŒ–å›¾ç»“æ„ |
| **Robustness** | âœ… åˆ†å¸ƒå¼ä¿¡èª‰æœºåˆ¶éš”ç¦»æ¶æ„èŠ‚ç‚¹ | âŒ ä¸­å¿ƒæ§åˆ¶å™¨è¢«æ”»ç ´åˆ™å…¨ç½‘å´©æºƒ |
| **è®­ç»ƒå¼€é”€** | âœ… å®Œå…¨æ— è®­ç»ƒï¼ˆtraining-freeï¼‰ | âŒ éœ€è¦å¤§é‡ç¦»çº¿æœç´¢æˆ–å‚æ•°å­¦ä¹  |

> ğŸ’¡ **æ ¸å¿ƒæ€æƒ³è½¬å˜**ï¼šä»â€œ**è°æ¥å¤„ç†ï¼Ÿ**â€ï¼ˆhost-centricï¼‰è½¬å‘â€œ**ä»€ä¹ˆå†…å®¹éœ€è¦è°ï¼Ÿ**â€ï¼ˆcontent-centricï¼‰ï¼Œå®ç°äº†çœŸæ­£çš„è‡ªå‘åä½œã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
åœ¨äº”ä¸ªä»£è¡¨æ€§åŸºå‡†ä¸Šè¿›è¡Œå…¨é¢è¯„ä¼°ï¼Œæ¶µç›–ä¸‰ç±»ä»»åŠ¡ï¼š

| ç±»åˆ« | æ•°æ®é›† | ä»»åŠ¡æè¿° | è¯„ä¼°æŒ‡æ ‡ |
|------|--------|----------|-----------|
| **General Reasoning** | MMLU | å¤šå­¦ç§‘å¸¸è¯†æ¨ç†ï¼ˆSTEMã€äººæ–‡ç­‰ï¼‰ | Accuracy |
| **Mathematical Reasoning** | GSM8K, SVAMP, AQuA | æ•°å­¦åº”ç”¨é¢˜æ±‚è§£ | Accuracy |
| **Code Generation** | HumanEval | Python ç¼–ç¨‹é—®é¢˜ç”Ÿæˆ | Pass@1 |

> ğŸ“Š æ€»è®¡è¦†ç›– 5 ä¸ª benchmarkï¼Œæµ‹è¯•é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚

---

### å®éªŒè®¾ç½®
- **LLM Backbone**: ç»Ÿä¸€ä½¿ç”¨ `GPT-4o-mini` ä½œä¸ºæ‰€æœ‰ä»£ç†çš„æ ¸å¿ƒæ¨¡å‹ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚
- **Agent æ•°é‡**: é»˜è®¤é…ç½® 5 ä¸ªä»£ç†ï¼Œéƒ¨åˆ†å®éªŒä¸­å˜é‡åˆ†ææ‰©å±•è‡³æœ€å¤š 30 ä¸ªã€‚
- **é€šä¿¡è½®æ¬¡ï¼ˆkï¼‰**: æœ€å¤§é€šä¿¡æ­¥æ•°è®¾ä¸º 5ã€‚
- **Broker å®ç°**:
  - ä¸»è¦ä½¿ç”¨ `text-embedding-3-small` è¿›è¡Œé«˜æ•ˆè¯­ä¹‰åŒ¹é…ï¼›
  - æ¶ˆèå®éªŒä¸­ä¹Ÿæµ‹è¯•äº† LLM-based Broker çš„æ•ˆæœã€‚

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å…±å››ç±» baselineï¼š

| ç±»å‹ | ä»£è¡¨æ–¹æ³• | ç‰¹å¾ |
|------|--------|------|
| **Single-Agent Models** | CoT, ComplexCoT, SC | å•æ¨¡å‹é“¾å¼æ€ç»´æˆ–å¤šè·¯å¾„æŠ•ç¥¨ |
| **Static Multi-Agent Models** | Chain, Star, Tree, Random, LLM-Debate | å›ºå®šè¿æ¥ç»“æ„ |
| **Communication-Agnostic Models** | GPTSwarm, AFlow, G-Designer | ç¦»çº¿æœç´¢æœ€ä¼˜å›¾ç»“æ„ |
| **Meta-Controlled Models** | AutoAgents, Puppeteer, MAS-Zero | ä½¿ç”¨é«˜æƒé™ meta-controller å®æ—¶è°ƒåº¦ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 1ï¼‰
| æ–¹æ³• | MMLU | GSM8K | SVAMP | AQuA | HumanEval | **Average** |
|------|-------|--------|--------|-------|------------|-------------|
| G-Designer (SOTA prior) | 86.3 | 93.2 | 90.7 | 79.4 | 90.2 | 88.0 |
| **RAPS (Ours)** | **88.2** | **95.4** | **92.2** | **82.6** | **91.5** | **90.0** |

âœ… RAPS åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šå‡è¾¾åˆ° **state-of-the-art æ€§èƒ½**ï¼Œå¹³å‡æå‡ **+2.0%**ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ä¼˜äºé™æ€ç»“æ„**ï¼šå¦‚ Chain åœ¨ SVAMP ä¸Šä»…å¾— 82.6%ï¼Œè¿œä½äº RAPS çš„ 92.2%ï¼Œè¯´æ˜åˆšæ€§æµç¨‹éš¾ä»¥åº”å¯¹å¤šæ ·åŒ–æ¨ç†éœ€æ±‚ã€‚
- **ä¼˜äºç¦»çº¿ä¼˜åŒ–æ–¹æ³•**ï¼šå°½ç®¡ AFlow å’Œ G-Designer è¡¨ç°å¼ºåŠ²ï¼Œä½†ä»æ˜¯ communication-agnosticï¼Œåœ¨æ¨ç†è¿‡ç¨‹ä¸­æ— æ³•å“åº”ä¸Šä¸‹æ–‡å˜åŒ–ã€‚
- **ä¼˜äºä¸­å¿ƒåŒ–æ§åˆ¶**ï¼šPuppeteer å¹³å‡å¾—åˆ†ä»…ä¸º 84.0%ï¼Œä¸”å­˜åœ¨ä¸¥é‡ SPoF é—®é¢˜ï¼ˆè§ä¸‹æ–‡é²æ£’æ€§æµ‹è¯•ï¼‰ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 3ï¼‰
ç§»é™¤å…³é”®ç»„ä»¶åçš„æ€§èƒ½ä¸‹é™æ˜¾è‘—ï¼š

| å˜ä½“ | MMLU â†“ | GSM8K â†“ | HumanEval â†“ |
|------|--------|---------|--------------|
| RAPS (Full) | 88.2 | 95.4 | 91.5 |
| w/o RS (æ—  Reactive Subscription) | 85.6 (-2.6) | 93.7 (-1.7) | 89.3 (-2.2) |
| w/o BR (æ—  Bayesian Reputation) | 86.9 (-1.3) | 94.5 (-0.9) | 90.7 (-0.8) |
| w/o Both | 83.7 (-4.5) | 92.8 (-2.6) | 88.5 (-3.0) |

> ğŸ” å‘ç°ï¼š**Reactive Subscription å¯¹æ€§èƒ½å½±å“æ›´å¤§**ï¼Œè¡¨æ˜åŠ¨æ€æ„å›¾æ¼”åŒ–æ˜¯æå‡åä½œè´¨é‡çš„å…³é”®é©±åŠ¨åŠ›ã€‚

---

### é²æ£’æ€§æµ‹è¯•ï¼ˆTable 2ï¼‰â€”â€” Byzantine Stress Test
æ³¨å…¥ä¸åŒæ¯”ä¾‹çš„ **adversarial agentsï¼ˆè¯´è°è€…ï¼‰** åï¼Œç³»ç»Ÿå‡†ç¡®æ€§å˜åŒ–å¦‚ä¸‹ï¼ˆMMLUï¼‰ï¼š

| æ–¹æ³• \ åœºæ™¯ | 5T0A | 4T1A | 3T2A | 2T3A | 5T5Aï¼ˆåŠæ•°å¯¹æŠ—ï¼‰ |
|------------|-----|-----|-----|-----|------------------|
| Chain | 84.3 | 72.5 | 50.3 | 22.2 | 16.3 |
| G-Designer | 86.3 | 80.4 | 37.9 | 15.0 | 49.7 |
| Puppeteer-Cï¼ˆæ”»å‡»æ§åˆ¶å™¨ï¼‰ | 84.3 | **13.7** | â€” | â€” | â€” |
| **RAPS** | **88.2** | **87.6** | **84.3** | **83.0** | **86.3** |

> âš ï¸ Puppeteer åœ¨ä¸­å¤®æ§åˆ¶å™¨è¢«æ”»å‡»åç«‹å³å´©æºƒï¼ˆ84.3% â†’ 13.7%ï¼‰ï¼Œè€Œ **RAPS å‡ ä¹ä¸å—å½±å“**ï¼Œè¯æ˜å…¶å¼ºå¤§çš„æŠ—æ”»å‡»èƒ½åŠ›ã€‚

---

### å¯æ‰©å±•æ€§ä¸æ•ˆç‡åˆ†æï¼ˆFigure 3ï¼‰
- **Scalability**ï¼šéšç€ä»£ç†æ•°é‡å¢åŠ ï¼ŒRAPS æŒç»­æå‡å‡†ç¡®ç‡ï¼Œè€Œ Puppeteer å’Œ Chain æ˜æ˜¾é€€åŒ–ã€‚
- **Efficiency**ï¼šRAPS æ¨ç†å»¶è¿Ÿç¨³å®šå¢é•¿ï¼Œè€Œ GPTSwarm/G-Designer å› éœ€åœ¨çº¿ä¼˜åŒ–å¯¼è‡´è€—æ—¶å‰§å¢ï¼ˆ>2å°æ—¶ @20 agentsï¼‰ã€‚
- **Cost-Performance Trade-off**ï¼šRAPS åœ¨ç›¸åŒ token å¼€é”€ä¸‹æä¾›æ›´é«˜ç²¾åº¦ï¼Œå½¢æˆæ›´ä¼˜å¸•ç´¯æ‰˜å‰æ²¿ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **åŠ¨æ€æ„å›¾ + å»ä¸­å¿ƒåŒ–ä¿¡ä»» = è‡ªç»„ç»‡åä½œçš„åŸºç¡€**
   - RAPS æˆåŠŸå°† **dynamic ad-hoc networking** çš„æˆç†Ÿç†å¿µè¿ç§»åˆ° LLM Agent åè°ƒé¢†åŸŸï¼ŒéªŒè¯äº†è¯¥è§†è§’çš„æœ‰æ•ˆæ€§ã€‚
2. **Reactive Subscription æ˜¯é€‚åº”æ€§çš„å…³é”®**
   - ä»£ç†èƒ½æ ¹æ®ä¸Šä¸‹æ–‡è‡ªåŠ¨ä¸“ä¸šåŒ–è§’è‰²ï¼ˆå¦‚â€œæ•°å­¦åˆ†æå¸ˆâ€å˜ä¸ºâ€œä½ç§»åˆ†æä¸“å®¶â€ï¼‰ï¼Œé¿å…é¢„è®¾è§’è‰²åƒµåŒ–ã€‚
3. **Bayesian Reputation å®ç°æœ‰æ•ˆé˜²å¾¡**
   - æœ¬åœ° watchdog ç»“åˆä¸€é˜¶/äºŒé˜¶è¯æ®ï¼ŒæˆåŠŸè¯†åˆ«å¹¶éš”ç¦»æ¶æ„è¾“å‡ºï¼Œé˜²æ­¢é”™è¯¯ä¼ æ’­ã€‚
4. **RAPS å¯¹ä½è´¨é‡åˆå§‹é…ç½®å…·æœ‰å¼ºéŸ§æ€§**
   - å³ä½¿ä½¿ç”¨é€šç”¨è§’è‰²ï¼ˆnaive poolï¼‰ï¼Œä¹Ÿèƒ½é€šè¿‡åŠ¨æ€è®¢é˜…å¿«é€Ÿæ”¶æ•›åˆ°æœ‰æ•ˆåˆ†å·¥ï¼ˆFigure 5ï¼‰ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–åŸºç¡€æ¨¡å‹èƒ½åŠ›**
   - RAPS æ˜¯â€œintelligence multiplierâ€ï¼Œä¸æ”¹å˜ä¸ªä½“ LLM çš„æ¨ç†ä¸Šé™ã€‚è‹¥ backbone ä¸å…·å¤‡æŸé¡¹æŠ€èƒ½ï¼Œåˆ™æ— æ³•å¼¥è¡¥ã€‚
2. **å†·å¯åŠ¨é—®é¢˜ï¼ˆCold Start in Reputationï¼‰**
   - åˆå§‹é˜¶æ®µå› ç¼ºä¹äº¤äº’å†å²ï¼Œä¿¡èª‰ç³»ç»Ÿå°šæœªå»ºç«‹ï¼ŒçŸ­æš‚æ—¶é—´å†…ä»å¯èƒ½å—æ¶æ„èŠ‚ç‚¹å½±å“ã€‚
3. **å®Œå…¨æ— è®­ç»ƒé™åˆ¶äº†é•¿æœŸä¼˜åŒ–æ½œåŠ›**
   - å½“å‰ä¸º training-free è®¾è®¡ï¼Œæœªåˆ©ç”¨ MARL æˆ–æŒç»­å­¦ä¹ è¿›ä¸€æ­¥ä¼˜åŒ–ç­–ç•¥ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **å¼•å…¥å¯å­¦ä¹ çš„åè°ƒåè®®**
   - å°† reputation scores ä½œä¸ºå†…åœ¨å¥–åŠ±ä¿¡å·ï¼Œç»“åˆ **multi-agent reinforcement learning (MARL)** ä¼˜åŒ–åä½œè¡Œä¸ºã€‚
2. **æ‰©å±•ç½‘ç»œç±»æ¯”çš„è®¾è®¡ç©ºé—´**
   - å¼•å…¥ç±»ä¼¼ï¼š
     - **Congestion Control**ï¼šé˜²æ­¢ context overflowï¼›
     - **Hierarchical Subnetting**ï¼šå¤§è§„æ¨¡ agent ç¤¾ä¼šçš„å±‚çº§ç»„ç»‡ï¼›
     - **Packet Prioritization**ï¼šç´§æ€¥æ¨ç†è·¯å¾„ä¼˜å…ˆä¼ è¾“ã€‚
3. **è·¨ä¼šè¯ä¿¡èª‰è¿ç§»**
   - æ„å»ºæŒä¹…åŒ–ä¿¡ä»»è®°å¿†ï¼Œç¼“è§£å†·å¯åŠ¨é—®é¢˜ã€‚
4. **æ”¯æŒå¼‚æ„æ¨¡å‹æ··åˆç¼–æ’**
   - åè°ƒä¸åŒå¤§å°ã€æ¨¡æ€ã€èƒ½åŠ›çš„ agentsï¼Œæ„å»ºçœŸæ­£å¼€æ”¾çš„ agentic ecosystemã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> RAPS æä¾›äº†ä¸€ç§å…¨æ–°çš„ã€ç±»æ¯”äºåŠ¨æ€è‡ªç»„ç»‡ç½‘ç»œçš„ **decentralized, intent-driven, reputation-aware** å¤šæ™ºèƒ½ä½“åè°ƒèŒƒå¼ï¼Œåœ¨ **Adaptivityã€Scalabilityã€Robustness** ä¸‰è€…ä¹‹é—´å–å¾—äº†å‰æ‰€æœªæœ‰çš„å¹³è¡¡ï¼Œä¸ºæ„å»ºå¯ä¿¡ã€è‡ªç»„ç»‡çš„ LLM Agent Society å¥ å®šäº†åšå®åŸºç¡€ã€‚

</details>

---

### 14. [PTS-SNN: A Prompt-Tuned Temporal Shift Spiking Neural Networks for Efficient Speech Emotion Recognition](https://arxiv.org/abs/2602.08240)

**Authors**: Xun Su, Huamin Wang, Qi Zhang  
**Category**: cs.AI  
**Published**: 2026-02-10  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.08240v1  

#### Abstract
Speech Emotion Recognition (SER) is widely deployed in Human-Computer Interaction, yet the high computational cost of conventional models hinders their implementation on resource-constrained edge devices. Spiking Neural Networks (SNNs) offer an energy-efficient alternative due to their event-driven ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠPTS-SNN: A Prompt-Tuned Temporal Shift Spiking Neural Networks for Efficient Speech Emotion Recognitionã€‹æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»ŸåŸºäº **Artificial Neural Networks (ANNs)** çš„ **Speech Emotion Recognition (SER)** æ¨¡å‹è™½ç„¶æ€§èƒ½ä¼˜è¶Šï¼Œä½†è®¡ç®—å¼€é”€å¤§ã€èƒ½è€—é«˜ï¼Œéš¾ä»¥éƒ¨ç½²åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šã€‚è€Œ **Spiking Neural Networks (SNNs)** è™½ç„¶å…·å¤‡äº‹ä»¶é©±åŠ¨ã€ä½åŠŸè€—çš„ç‰¹æ€§ï¼Œä½†åœ¨ç›´æ¥å¤„ç†æ¥è‡ªè‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰æ¨¡å‹ï¼ˆå¦‚ emotion2vecï¼‰çš„è¿ç»­é«˜åŠ¨æ€èŒƒå›´ç‰¹å¾æ—¶ï¼Œå­˜åœ¨ä¸¥é‡çš„**åˆ†å¸ƒä¸åŒ¹é…ï¼ˆdistribution mismatchï¼‰**é—®é¢˜ã€‚

å…·ä½“è¡¨ç°ä¸ºï¼š
- é«˜æ–¹å·®è¾“å…¥å¯¼è‡´ **LIF/PLIF ç¥ç»å…ƒ**é™·å…¥â€œåŠŸèƒ½é™é»˜â€ï¼ˆfunctional silenceï¼‰æˆ–â€œé¥±å’Œâ€ï¼ˆsaturationï¼‰ï¼Œç ´åç¨€ç–æ—¶é—´ç¼–ç èƒ½åŠ›ã€‚
- ç°æœ‰æ–¹æ³•æ— æ³•æœ‰æ•ˆå¯¹é½å†»ç»“çš„ SSL ç‰¹å¾ä¸ç¦»æ•£è„‰å†²åŠ¨åŠ›å­¦ä¹‹é—´çš„é¸¿æ²Ÿã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **PTS-SNN**ï¼ˆPrompt-Tuned Spiking Neural Networkï¼‰ï¼Œä¸€ç§å‚æ•°é«˜æ•ˆçš„ç¥ç»å½¢æ€é€‚é…æ¡†æ¶ï¼Œæ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰**Temporal Shift Spiking Encoder**
- å¼•å…¥**æ— å‚æ•°çš„æ—¶é—´åç§»æ“ä½œ**ï¼ˆparameter-free channel shiftï¼‰ï¼Œåœ¨æ®‹å·®è„‰å†²å—ä¸­æ•æ‰å±€éƒ¨æ—¶é—´ä¾èµ–ã€‚
- é€šè¿‡é›¶å¡«å……ä¸æˆªæ–­å®ç°å¸§é—´ä¿¡æ¯äº¤æ¢ï¼Œæ— éœ€é¢å¤– FLOPsï¼Œç¨³å®šåŸå§‹ç‰¹å¾æµçš„é«˜é¢‘æ³¢åŠ¨ã€‚

#### ï¼ˆ2ï¼‰**Context-Aware Membrane Potential Calibration**
- è®¾è®¡åŸºäº **Spiking Sparse Linear Attention (SSLA)** çš„æç¤ºæœºåˆ¶ã€‚
- å¼•å…¥å¯å­¦ä¹ çš„ **soft prompts**ï¼Œèšåˆå…¨å±€è¯­ä¹‰ä¸Šä¸‹æ–‡ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸º **åŠ¨æ€åç½®ç”µå‹ï¼ˆdynamic bias voltagesï¼‰**ã€‚
- è¿™äº›ç”µå‹è°ƒèŠ‚ **Parametric Leaky Integrate-and-Fire (PLIF)** ç¥ç»å…ƒçš„è†œç”µä½åŸºçº¿ï¼Œå°†å¼‚æ„è¾“å…¥åˆ†å¸ƒä¸»åŠ¨æ ¡å‡†è‡³é˜ˆå€¼å“åº”åŒºé—´å†…ï¼Œé¿å…é™é»˜æˆ–é¥±å’Œã€‚

> ğŸ”¬ ç”Ÿç‰©å¯å‘ï¼šè¯¥æœºåˆ¶æ¨¡æ‹Ÿç”Ÿç‰©ä¸­çš„**ç¨³æ€è°ƒèŠ‚ï¼ˆhomeostatic regulationï¼‰**ï¼Œä½¿ç¥ç»å…ƒèƒ½é€‚åº”ä¸åŒå¼ºåº¦çš„è¾“å…¥åˆºæ¿€ã€‚

#### ï¼ˆ3ï¼‰ç«¯åˆ°ç«¯è½»é‡çº§é€‚é…å™¨è®¾è®¡
- å†»ç»“ä¸Šæ¸¸ SSL ä¸»å¹²ç½‘ç»œï¼ˆå¦‚ emotion2vecï¼‰ï¼Œä»…è®­ç»ƒä¸€ä¸ªå°å‹é€‚é…å™¨æ¨¡å—ã€‚
- å®ç°é«˜æ•ˆè¿ç§»å­¦ä¹ ï¼Œæ˜¾è‘—é™ä½å‚æ•°é‡ä¸æ¨ç†èƒ½è€—ã€‚

### âš–ï¸ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | PTS-SNN ä¼˜åŠ¿ |
|------|-------------|
| **å‚æ•°æ•ˆç‡** | ä»…éœ€ **1.19M å¯è®­ç»ƒå‚æ•°**ï¼Œè¿œä½äºå…¨å¾®è°ƒ ANN æ¨¡å‹ï¼ˆå¦‚ Co-attention: 175.3Mï¼‰ |
| **èƒ½é‡æ•ˆç‡** | å•æ ·æœ¬æ¨ç†èƒ½è€—ä»… **0.35 mJ**ï¼Œæ¯” ANN æ¨¡å‹ä½ 2â€“3 ä¸ªæ•°é‡çº§ |
| **æ€§èƒ½ä¿æŒ** | åœ¨ IEMOCAP ä¸Šè¾¾åˆ° **73.34% WA**ï¼Œä¼˜äºå¤šæ•° ANN åŸºçº¿ |
| **å…¼å®¹æ€§** | æˆåŠŸæ¡¥æ¥è¿ç»­ SSL è¡¨ç¤ºä¸ç¦»æ•£ SNN åŠ¨åŠ›å­¦ï¼Œè§£å†³åˆ†å¸ƒå¤±é…éš¾é¢˜ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
åœ¨äº”ä¸ªå¤šè¯­è¨€ SER æ•°æ®é›†ä¸Šè¿›è¡ŒéªŒè¯ï¼š

| æ•°æ®é›† | è¯­è¨€ | æƒ…æ„Ÿç±»åˆ«æ•° | æ ·æœ¬æ•° | äº¤å‰éªŒè¯ç­–ç•¥ |
|--------|------|------------|--------|----------------|
| **IEMOCAP** | è‹±è¯­ | 4 | 5,531 | Leave-one-session-out, 5-fold |
| **CASIA** | ä¸­æ–‡ | 4 | 1,200 | Random leave-one-speaker-out, 4-fold |
| **EMODB** | å¾·è¯­ | 7 | 535 | Random leave-one-out, 10-fold |
| **EMOVO** | æ„å¤§åˆ©è¯­ | 6 | 588 | åŒä¸Š |
| **URDU** | ä¹Œå°”éƒ½è¯­ | 4 | 400 | åŒä¸Š |

> æ‰€æœ‰å®éªŒå‡é‡‡ç”¨é¢„è®­ç»ƒçš„ **emotion2vec** ä½œä¸ºå›ºå®šç‰¹å¾æå–å™¨ã€‚

### ğŸ§ª å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### æ¨¡å‹å®ç°
- æ¡†æ¶ï¼šPyTorch
- ç¡¬ä»¶ï¼šå•å¼  NVIDIA RTX 4090 GPU
- ä¼˜åŒ–å™¨ï¼šAdamWï¼ˆåˆå§‹ LR = 2e-4ï¼Œweight decay = 0.05ï¼‰
- å­¦ä¹ ç‡è°ƒåº¦ï¼šCosine Annealing Warm Restartsï¼ˆæœ€å° LR = 1e-6ï¼‰
- è®­ç»ƒè½®æ¬¡ï¼š200 epochsï¼Œbatch size = 32
- SNN åå‘ä¼ æ’­ï¼šä½¿ç”¨é™¡å³­å› å­ Î±=5 çš„ surrogate gradient

#### è¯„ä¼°æŒ‡æ ‡
- **Weighted Accuracy (WA)**ï¼šæ€»ä½“å‡†ç¡®ç‡ï¼Œåæ˜ å…¨å±€æ€§èƒ½
- **Unweighted Accuracy (UA)**ï¼šå„ç±»åˆ«å¹³å‡å‡†ç¡®ç‡ï¼Œé€‚ç”¨äºç±»åˆ«ä¸å¹³è¡¡åœºæ™¯
- **å¯è®­ç»ƒå‚æ•°é‡ï¼ˆParamsï¼‰**
- **æ¨ç†èƒ½è€—ï¼ˆEnergy Consumptionï¼‰**ï¼šåŸºäº 45nm CMOS å·¥è‰ºä¼°ç®—ï¼ŒåŒºåˆ† MACï¼ˆANNï¼‰ä¸ ACï¼ˆSNNï¼‰æ“ä½œèƒ½è€—

### ğŸ†š å¯¹æ¯”çš„åŸºçº¿æ–¹æ³•
| åŸºçº¿æ¨¡å‹ | ç±»å‹ | æ ¸å¿ƒæœºåˆ¶ |
|---------|------|----------|
| **emotion2vec + ANN fine-tuning** | å…¨è¿æ¥å¾®è°ƒ | æ ‡å‡†ä¸‹æ¸¸ä»»åŠ¡é€‚é… |
| **Vanilla SNN** | ç›´æ¥è½¬æ¢ | å°† SSL è¾“å‡ºç›´æ¥é€å…¥ SNNï¼Œæ— é€‚é…æœºåˆ¶ |
| **Co-attention [58]** | ANN | è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶ |
| **MSTR [59]** | ANN | å¤šå°ºåº¦ Transformer |
| **DST [60]** | ANN | åŒæµèåˆæ¶æ„ |
| **ShiftFormer [61]** | ANN | åŸºäºç¨€ç–åç§»çš„ç½‘ç»œ |
| **ENT [62]** | ANN | é«˜æ•ˆ Transformer æ¶æ„ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ IEMOCAP ä¸ºä¾‹ï¼‰

| æ¨¡å‹ | WA (%) | UA (%) | Params (M) | Energy (mJ/sample) |
|------|--------|--------|------------|--------------------|
| Co-attention | 69.80 | 71.05 | 175.30 | 103.40 |
| MSTR | 70.60 | 71.60 | 30.03 | 51.06 |
| DST | 71.80 | 73.60 | 22.78 | 35.34 |
| ShiftFormer | 72.10 | 72.70 | 9.50 | 16.20 |
| ENT | 72.43 | 73.88 | 8.55 | 6.35 |
| **PTS-SNN (Ours)** | **73.34** | **73.72** | **1.19** | **0.35** |

âœ… **ç»“è®º**ï¼š
- PTS-SNN åœ¨ **WA å’Œ UA ä¸Šå‡ä¼˜äºæ‰€æœ‰å¯¹æ¯”çš„ ANN æ¨¡å‹**ã€‚
- å‚æ•°é‡ä»…ä¸ºæœ€è½»é‡ ANN æ¨¡å‹ï¼ˆShiftFormerï¼‰çš„ **~12.5%**ã€‚
- æ¨ç†èƒ½è€—ä»…ä¸º ENT çš„ **çº¦ 1/18**ï¼Œä¸º Co-attention çš„ **1/295**ã€‚

### ğŸŒ è·¨è¯­è¨€æ³›åŒ–èƒ½åŠ›ï¼ˆWA %ï¼‰

| æ•°æ®é›† | emotion2vec | PTS-SNN | æå‡ |
|-------|-------------|---------|------|
| **CASIA** | 69.20 | 72.50 | +3.30 |
| **EMODB** | 84.34 | 87.49 | +3.15 |
| **EMOVO** | 61.21 | 61.94 | +0.73 |
| **URDU** | 81.50 | 84.25 | +2.75 |

â¡ï¸ è¡¨æ˜ PTS-SNN å…·å¤‡è‰¯å¥½çš„è·¨è¯­è¨€é²æ£’æ€§ï¼Œæç¤ºæœºåˆ¶æ•è·çš„æ˜¯**è¯­è¨€æ— å…³çš„æƒ…æ„ŸéŸµå¾‹ç‰¹å¾**ã€‚

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆIEMOCAPï¼‰

| é…ç½® | WA (%) | UA (%) |
|------|--------|--------|
| **Full Model (PTS-SNN)** | **73.34** | **73.72** |
| w/o Prompt Tuning | 71.76 | 71.90 |
| w/o Attention Module | 68.35 | 69.10 |
| Only Temporal Shift | 61.27 | 62.05 |

ğŸ“Œ å‘ç°ï¼š
- ç§»é™¤ **prompt tuning** å¯¼è‡´æ€§èƒ½ä¸‹é™ 1.58%ï¼Œè¯´æ˜å…¶åœ¨åˆ†å¸ƒå¯¹é½ä¸­èµ·å…³é”®ä½œç”¨ã€‚
- ç§»é™¤ **attention æ¨¡å—** æ€§èƒ½éª¤é™ 5%ï¼Œè¡¨æ˜å…¨å±€ä¸Šä¸‹æ–‡å»ºæ¨¡è‡³å…³é‡è¦ã€‚
- ä»…ä¿ç•™æ—¶é—´åç§»æœºåˆ¶æ•ˆæœæœ‰é™ï¼Œè¯æ˜éœ€ç»“åˆé«˜å±‚è°ƒæ§ã€‚

### ğŸ“ˆ è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æ
- **æœ€ä½³ prompt é•¿åº¦ $L_p = 5$**ï¼Œè¿‡é•¿ï¼ˆå¦‚ 6ï¼‰å¼•å…¥å†—ä½™ï¼Œæ€§èƒ½åé™ã€‚
- **æœ€ä¼˜åç½®ç¼©æ”¾å› å­ $K = 0.5$**ï¼Œè¿‡é«˜æˆ–è¿‡ä½å‡æŸå®³ä¿¡å™ªæ¯”ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **åˆ†å¸ƒå¤±é…æ˜¯é˜»ç¢ SNN åº”ç”¨äº SSL ç‰¹å¾çš„å…³é”®ç“¶é¢ˆ**ï¼Œç›´æ¥è½¬æ¢ä¼šå¯¼è‡´ä¸¥é‡æ€§èƒ½é€€åŒ–ï¼ˆä» 71.79% â†’ 41.78%ï¼‰ã€‚
2. **PTS-SNN æˆåŠŸå®ç°äº†å†»ç»“ SSL ä¸»å¹²ä¸ SNN åˆ†ç±»å¤´ä¹‹é—´çš„é«˜æ•ˆé€‚é…**ï¼Œä¸ä»…æ¢å¤è€Œä¸”è¶…è¶Šäº†åŸ ANN æ€§èƒ½ã€‚
3. **å°† prompt è§†ä¸ºâ€œè†œç”µä½è°ƒèŠ‚ä¿¡å·â€è€Œéâ€œè¯­ä¹‰ tokenâ€æ˜¯ä¸€ç§æ–°é¢–ä¸”æœ‰æ•ˆçš„ç¥ç»å½¢æ€æç¤ºèŒƒå¼**ï¼Œå…·æœ‰ç”Ÿç‰©å­¦åˆç†æ€§ã€‚
4. æ‰€ææ–¹æ³•åœ¨å¤šä¸ªè¯­è¨€å’Œæ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œå…·å¤‡è‰¯å¥½æ³›åŒ–èƒ½åŠ›å’Œå®é™…éƒ¨ç½²æ½œåŠ›ã€‚

### âš ï¸ å±€é™æ€§
- å½“å‰æ¡†æ¶**ä»…ä½¿ç”¨éŸ³é¢‘æ¨¡æ€**ï¼Œæœªèåˆæ–‡æœ¬æˆ–é¢éƒ¨è¡¨æƒ…ç­‰äº’è¡¥ä¿¡æ¯ã€‚
- æç¤ºæœºåˆ¶ä»ä¾èµ–äººå·¥è®¾è®¡ç»“æ„ï¼ˆå¦‚é•¿åº¦ã€ä½ç½®ï¼‰ï¼Œç¼ºä¹å®Œå…¨è‡ªåŠ¨åŒ–æœç´¢ã€‚
- åœ¨æå°æ ·æœ¬ï¼ˆå¦‚ URDUï¼‰ä¸‹æå‡å¹…åº¦ç›¸å¯¹è¾ƒå°ï¼Œå¯èƒ½é¢ä¸´ä½èµ„æºæŒ‘æˆ˜ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **Multimodal Spiking Architectures**ï¼Œèåˆè¯­éŸ³ã€è§†è§‰ä¸æ–‡æœ¬ä¿¡å·ã€‚
- æ¢ç´¢ **Auto-Prompting for SNNs**ï¼Œè‡ªåŠ¨ä¼˜åŒ–æç¤ºç»“æ„ä¸æ—¶åºé…ç½®ã€‚
- ç ”ç©¶ **æ›´å¤æ‚çš„ç”Ÿç‰©å¯å¡‘æ€§æœºåˆ¶**ï¼ˆå¦‚ STDPã€çªè§¦å»¶è¿Ÿè°ƒèŠ‚ï¼‰ä»¥å¢å¼ºè¡¨ç¤ºèƒ½åŠ›ã€‚
- åœ¨çœŸå®è¾¹ç¼˜è®¾å¤‡ï¼ˆå¦‚ Loihiã€Speck ç­‰ neuromorphic chipsï¼‰ä¸Šéƒ¨ç½²å¹¶æµ‹è¯•å®æ—¶æ€§èƒ½ã€‚

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> PTS-SNN é€šè¿‡å°† prompt è½¬åŒ–ä¸ºåŠ¨æ€è†œç”µä½åç½®ï¼Œé¦–æ¬¡å®ç°äº†é«˜æ•ˆã€ä½åŠŸè€—ã€é«˜æ€§èƒ½çš„ SSL-to-SNN è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«é€‚é…ï¼Œåœ¨ç²¾åº¦ã€å‚æ•°é‡ä¸èƒ½è€—ä¹‹é—´å–å¾—äº†å“è¶Šå¹³è¡¡ã€‚

</details>

---

### 15. [Do MLLMs Really See It: Reinforcing Visual Attention in Multimodal LLMs](https://arxiv.org/abs/2602.08241)

**Authors**: Siqu Ou, Tianrui Wan, Zhiyuan Zhao, Junyu Gao, Xuelong Li  
**Category**: cs.AI  
**Published**: 2026-02-10  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.08241v1  

#### Abstract
While chain-of-thought (CoT) reasoning has substantially improved multimodal large language models (MLLMs) on complex reasoning tasks, existing approaches largely rely on long textual reasoning trajectories and provide limited mechanisms for learning stable visual attention policies. Our analysis sh...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Do MLLMs Really See It: Reinforcing Visual Attention in Multimodal LLMs*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰çš„ **Multimodal Large Language Models (MLLMs)** åœ¨å¤æ‚è§†è§‰æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œå…¶æ ¹æœ¬åŸå› å¹¶éç¼ºä¹è¯­è¨€æ¨ç†èƒ½åŠ›ï¼Œè€Œæ˜¯**è§†è§‰æ³¨æ„åŠ›ç­–ç•¥ä¸ç¨³å®š**ã€‚å…·ä½“è¡¨ç°ä¸ºï¼š
- åœ¨æ¨ç†æ—©æœŸé˜¶æ®µè‹¥å‡ºç°è§†è§‰å…³æ³¨é”™è¯¯ï¼ˆå¦‚è¯¯å®šä½ç›®æ ‡åŒºåŸŸï¼‰ï¼Œè¯¥é”™è¯¯åœ¨åç»­ Chain-of-Thought (CoT) æ¨ç†è¿‡ç¨‹ä¸­å¾ˆå°‘è¢«çº æ­£ï¼›
- é”™è¯¯çš„è§†è§‰å‡è®¾ä¼šæŒç»­ä¼ æ’­ï¼Œå¯¼è‡´ç³»ç»Ÿæ€§æ¨ç†å¤±è´¥ï¼›
- ç°æœ‰è®­ç»ƒæœºåˆ¶ç¼ºä¹å¯¹è§†è§‰æ³¨æ„åŠ›è¡Œä¸ºçš„æœ‰æ•ˆâ€œä¿¡ç”¨åˆ†é…â€ï¼ˆcredit assignmentï¼‰ï¼Œå³æ¨¡å‹æ— æ³•å­¦ä¹ åˆ°â€œä½•æ—¶ã€ä½•å¤„åº”å…³æ³¨å›¾åƒä¸­çš„å“ªä¸ªåŒºåŸŸâ€ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šSAYO ä¸ Entropy-Based Target Attention Reward
ä½œè€…æå‡º **SAYO** â€”â€” ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning, RLï¼‰æ¡†æ¶çš„è§†è§‰æ¨ç†æ¨¡å‹ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§æ–°çš„å¥–åŠ±æœºåˆ¶ï¼š

#### ğŸ”¹ **Entropy-Based Target Attention Reward**
- **æ ¸å¿ƒæ€æƒ³**ï¼šåœ¨è®­ç»ƒä¸­å¼•å…¥ä¸€ä¸ª**åŸºäºåŒºåŸŸçº§è§†è§‰æ³¨æ„åŠ›çš„å¥–åŠ±ä¿¡å·**ï¼Œç›´æ¥å°†ä¼˜åŒ–ç›®æ ‡ä¸â€œè§†è§‰æ¥åœ°â€çš„æ¨ç†æ­¥éª¤å¯¹é½ã€‚
- **é€‰æ‹©é«˜ç†µ token è¿›è¡Œç›‘ç£**ï¼šä»…åœ¨æ¨¡å‹è¾“å‡ºä¸ç¡®å®šæ€§è¾ƒé«˜ï¼ˆå³ token entropy é«˜ï¼‰çš„å…³é”®å†³ç­–ç‚¹æ–½åŠ æ³¨æ„åŠ›å¥–åŠ±ï¼Œè¿«ä½¿æ¨¡å‹åœ¨æ­¤æ—¶â€œæŸ¥çœ‹å›¾åƒâ€ä»¥éªŒè¯å‡è®¾ï¼ˆLook-to-Verifyï¼‰ã€‚
- **å…¬å¼åŒ–è¡¨è¾¾**ï¼š
  $$
  r_v = \tanh\left(\log\left(\frac{a + \epsilon}{u + \epsilon}\right)\right)
  $$
  å…¶ä¸­ $a$ æ˜¯ç›®æ ‡åŒºåŸŸçš„å¹³å‡æ³¨æ„åŠ›è´¨é‡ï¼Œ$u$ æ˜¯æ•´ä¸ªå›¾åƒåŒºåŸŸçš„æ³¨æ„åŠ›è´¨é‡ã€‚

#### ğŸ”¹ **æ— éœ€å¤–éƒ¨æç¤ºæˆ–æ¶æ„ä¿®æ”¹**
- ä¸ä¾èµ–äºäººå·¥è®¾è®¡çš„ visual promptï¼ˆå¦‚ bounding box æ ‡æ³¨åä½œä¸ºè¾“å…¥ï¼‰ï¼›
- ä¸éœ€è¦é¢å¤–çš„æ¨¡å—æˆ–ç‰¹æ®Š tokenï¼›
- åœ¨æ¨ç†æ—¶å®Œå…¨è‡ªå›å½’ç”Ÿæˆï¼Œä¿æŒç®€æ´é«˜æ•ˆã€‚

### â­ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ ViP, ReFocus, Reflection-Vï¼‰ | SAYO |
|------|----------------------------------------|-------|
| è§†è§‰å¼•å¯¼æ–¹å¼ | å¤–éƒ¨å·¥å…·å¹²é¢„ / Prompt Engineering | å†…ç”Ÿå¼æ³¨æ„åŠ›å­¦ä¹  |
| æ˜¯å¦éœ€æ ‡æ³¨è¾“å…¥ | æ˜¯ï¼ˆå¦‚ç”»æ¡†ã€ç¨‹åºè°ƒç”¨ï¼‰ | å¦ï¼ˆè®­ç»ƒæ—¶ç”¨ bboxï¼Œæ¨ç†æ— ä¾èµ–ï¼‰ |
| æ³¨æ„åŠ›å¯å­¦ä¹ æ€§ | å¼±ï¼ˆä¾èµ–å·²æœ‰æ³¨æ„åŠ›è¡Œä¸ºï¼‰ | å¼ºï¼ˆé€šè¿‡ RL æ˜¾å¼ä¼˜åŒ–ï¼‰ |
| æ³›åŒ–èƒ½åŠ› | å—é™äºå›ºå®šæµç¨‹ | è·¨ä»»åŠ¡è¿ç§»æ€§å¼º |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
åˆ†ä¸ºä¸‰å¤§ç±»ï¼Œè¦†ç›–å¤šç§è§†è§‰æ¨ç†åœºæ™¯ï¼š

| ç±»åˆ« | æ•°æ®é›† | è¯´æ˜ |
|------|--------|------|
| **é€šç”¨è§†è§‰æ¨ç†** | M3CoT, V*, MMStar, MME-RealWorld Lite | åŒ…å«å¤šæ­¥æ¨ç†ã€çœŸå®ä¸–ç•Œå¤æ‚å›¾åƒç†è§£ |
| **æ•°å­¦è§†è§‰æ¨ç†** | We-Math, MathVision | å›¾å½¢é¢˜ã€å‡ ä½•å›¾ã€å›¾è¡¨ç»“åˆæ•°å­¦é€»è¾‘ |
| **ç»“æ„åŒ–å›¾åƒç†è§£** | ChartQA, AI2D, CharXiv | æŠ˜çº¿å›¾ã€æŸ±çŠ¶å›¾ã€ç§‘å­¦æ’å›¾ç­‰ |

> ç‰¹åˆ«å¼ºè°ƒï¼š**We-Math å’Œ MathVision å¹¶æœªç”¨äºè®­ç»ƒ**ï¼Œç”¨äºæµ‹è¯•è·¨åŸŸæ³›åŒ–èƒ½åŠ›ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼š
  - `Qwen3-VL-8B` å’Œ `InternVL3.5-8B`
- **è®­ç»ƒæ–¹æ³•**ï¼š
  - ä½¿ç”¨ **Group Relative Policy Optimization (GRPO)** æ¡†æ¶è¿›è¡Œ RL è®­ç»ƒï¼›
  - å¼•å…¥ **visual attention-based reward** ä¸ format reward åŠ æƒç»“åˆï¼›
  - è®­ç»ƒå‘¨æœŸï¼š4 epochsï¼Œ6å— NVIDIA H200 GPUï¼›
- **å…³é”®è¶…å‚æ•°**ï¼š
  - KL æ•£åº¦ç³»æ•°ï¼š1e-3
  - å­¦ä¹ ç‡ï¼š5e-6
  - Rollout æ¸©åº¦ï¼š1.0ï¼ŒTop-pï¼š0.9

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
- ä¸»è¦æŒ‡æ ‡ä¸ºå„ benchmark ä¸Šçš„å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰
- å¼•å…¥ **Target Attention Score (TAS)** å’Œ **Attention Advantage Score $R_a$** å®šé‡è¡¡é‡è§†è§‰èšç„¦ç¨‹åº¦ï¼š
  $$
  R_a = \frac{1}{2}(1 + \tanh(\log \frac{a}{u}))
  $$
- åˆ†ææ³¨æ„åŠ›æƒé‡åˆ†å¸ƒï¼ˆå°¤å…¶æ˜¯é«˜ç†µ token å¯¹ç›®æ ‡åŒºåŸŸçš„å…³æ³¨ï¼‰

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | ä»£è¡¨æ¨¡å‹ |
|------|---------|
| **é—­æºæ¨¡å‹** | GPT-4o, Gemini 2.5 Pro |
| **å¼€æºé€šç”¨ MLLM** | Qwen3-VL, InternVL3.5, Kimi-VL |
| **å¼€æºæ¨ç†ä¸“ç”¨ MLLM** | OpenVLThinker-7B, Semantic-back-7B, ViGoRL, NoisyRollout-7B, R1-Onevision-7B |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| æ¨¡å‹ | Avg Score | æ•°å­¦å¹³å‡ | å›¾è¡¨å¹³å‡ | é€šç”¨å¹³å‡ |
|------|----------|----------|----------|----------|
| GPT-4o | â€” | ~40.7 | ~69.6 | ~72.7 |
| Qwen3-VL-8B | 59.64 | 37.42 | 78.89 | 70.43 |
| **SAYO-Qwen-8B** | **64.03â†‘â†‘** | **45.05â†‘** | **82.65â†‘** | **74.88â†‘** |

> âœ… **SAYO-Qwen-8B åœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šè¶…è¶Šæ›´å¤§è§„æ¨¡æ¨¡å‹ç”šè‡³éƒ¨åˆ†é—­æºæ¨¡å‹**

#### ğŸ” äº®ç‚¹çªç ´ï¼š
- åœ¨ **MMStar** ä¸Šè¶…è¿‡ GPT-4o å’Œ Kimi-VL-16Bï¼›
- åœ¨ **We-Math** å’Œ **MathVision** ä¸Šæ˜¾è‘—æå‡ï¼ˆå°½ç®¡æœªè§è¿‡è¿™äº›æ•°æ®ï¼‰â†’ è¡¨æ˜å…·å¤‡å¼ºæ³›åŒ–èƒ½åŠ›ï¼›
- åœ¨ **ChartQA/AI2D/CharXiv** ä¸Šå‡å–å¾—é¢†å…ˆ â†’ æ˜¾ç¤ºå¯¹ç»“æ„åŒ–è§†è§‰ä¿¡æ¯çš„å¼ºå¤§è§£æèƒ½åŠ›ã€‚

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœï¼ˆTable 2 & Table 3ï¼‰

#### âœ… æ¶ˆèä¸€ï¼šä¸åŒå¥–åŠ±ç»„åˆçš„å½±å“
| è®¾ç½® | Avg æå‡ï¼ˆvs baseï¼‰ | è¯´æ˜ |
|------|---------------------|------|
| Only Accuracy Reward | +1.28 | æ”¹è¿›æœ‰é™ï¼Œè¯´æ˜ä»…é ç­”æ¡ˆæ­£ç¡®æ€§ä¸è¶³ä»¥ä¼˜åŒ–æ³¨æ„åŠ› |
| Only Attention Reward | +4.32 | æ€§èƒ½å¤§å¹…æå‡ï¼Œè¯æ˜æ³¨æ„åŠ›å¥–åŠ±æ˜¯å…³é”®é©±åŠ¨åŠ› |
| Combined Reward | +4.63 | æœ€ä¼˜é…ç½®ï¼Œå…¼é¡¾è¯­ä¹‰æ­£ç¡®æ€§å’Œè§†è§‰èšç„¦ |

> ğŸ’¡ ç»“è®ºï¼š**æ³¨æ„åŠ›å¥–åŠ±æ¯”ä¼ ç»Ÿ accuracy reward æ›´æœ‰æ•ˆæ¿€æ´»æ¨¡å‹æ½œåŠ›**

#### âœ… æ¶ˆèäºŒï¼štoken é€‰æ‹©ç­–ç•¥å¯¹æ¯”ï¼ˆTable 3ï¼‰
| ç­–ç•¥ | Avg æå‡ï¼ˆQwenï¼‰ | è¯´æ˜ |
|------|------------------|------|
| æ‰€æœ‰ token æ–½åŠ å¥–åŠ± | +0.87 | æ•ˆæœå·®ï¼Œå› ä½ä¿¡æ¯é‡ token å¼•å…¥å™ªå£° |
| ä»… top-30% é«˜ç†µ token | **+4.32** | æ˜¾è‘—æ›´ä¼˜ï¼Œèšç„¦å…³é”®å†³ç­–ç‚¹ |
| Top-20% / Top-40% | ä¸­é—´å€¼ | å­˜åœ¨æœ€ä¼˜åŒºé—´ï¼ˆçº¦ 30%ï¼‰ |

> ğŸ“Œ å‘ç°ï¼š**ä¸æ˜¯è¶Šå¤šè¶Šå¥½ï¼Œç²¾å‡†æ‰“å‡»é«˜ä¸ç¡®å®šæ€§æ—¶åˆ»æ›´é‡è¦**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **MLLMs çš„ç“¶é¢ˆä¸åœ¨â€œä¼šä¸ä¼šæƒ³â€ï¼Œè€Œåœ¨â€œçœ‹æ²¡çœ‹è§â€**
   - å½“å‰ MLLMs æ‹¥æœ‰å¼ºå¤§çš„æŠ½è±¡æ¨ç†èƒ½åŠ›ï¼Œä½†å¸¸å› åˆå§‹è§†è§‰å…³æ³¨é”™è¯¯è€Œå¯¼è‡´å¤±è´¥ï¼›
   - é”™è¯¯ä¸€æ—¦å‘ç”Ÿï¼ŒChain-of-Thought å¾ˆéš¾è‡ªæˆ‘ä¿®æ­£ã€‚

2. **è§†è§‰æ³¨æ„åŠ›å¯é€šè¿‡ RL æ˜¾å¼è®­ç»ƒå¹¶ç¨³å®šå¢å¼º**
   - å¼•å…¥åŸºäº region-level attention çš„ reward å¯æ˜¾è‘—æé«˜æ¨¡å‹å¯¹å…³é”®åŒºåŸŸçš„å…³æ³¨åº¦ï¼›
   - å°¤å…¶åœ¨é«˜ç†µ token é˜¶æ®µåŠ å¼ºç›‘ç£ï¼Œèƒ½æœ‰æ•ˆå®ç°â€œLook-to-Verifyâ€æœºåˆ¶ã€‚

3. **æ”¹è¿›è§†è§‰æ„ŸçŸ¥å³å¯é‡Šæ”¾é¢„è®­ç»ƒæ¨ç†èƒ½åŠ›**
   - SAYO åœ¨æ•°å­¦ä»»åŠ¡ä¸Šçš„æå‡å¹¶éå› ä¸ºå­¦ä¼šäº†æ–°çŸ¥è¯†ï¼Œè€Œæ˜¯**æ›´å‡†ç¡®åœ°â€œçœ‹åˆ°â€äº†å›¾å½¢è¦ç´ **ï¼ˆå¦‚è¾¹ã€è§’ã€è½´æ ‡ç­¾ï¼‰ï¼Œä»è€Œè®©åŸæœ‰æ•°å­¦å¼•æ“æ­£å¸¸å·¥ä½œã€‚

4. **æ–¹æ³•å…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§**
   - åœ¨ä¸åŒ backboneï¼ˆQwen vs InternVLï¼‰å’Œä¸åŒè§„æ¨¡ä¸‹å‡æœ‰æ•ˆï¼›
   - é€‚ç”¨äºé€šç”¨ã€æ•°å­¦ã€å›¾è¡¨ç­‰å¤šç§è§†è§‰æ¨ç†ä»»åŠ¡ã€‚

### âš ï¸ å±€é™æ€§
- ä¾èµ–å¸¦æœ‰ bounding box æ³¨é‡Šçš„è®­ç»ƒæ•°æ®æ„å»º target regionï¼ˆè™½æ¨ç†æ—¶ä¸éœ€ï¼‰ï¼›
- å½“å‰ reward è®¾è®¡åŸºäºæœ€ç»ˆå±‚æ³¨æ„åŠ›ï¼Œå¯èƒ½å¿½ç•¥ä¸­é—´å±‚åŠ¨æ€ï¼›
- å¯¹æç«¯æ¨¡ç³Šæˆ–é®æŒ¡ä¸¥é‡çš„å›¾åƒä»å­˜åœ¨æŒ‘æˆ˜ï¼›
- é«˜ç†µ token çš„å®šä¹‰å’Œé€‰å–èŒƒå›´éœ€è¿›ä¸€æ­¥ç†è®ºåˆ†æã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´ç»†ç²’åº¦çš„ attention controlï¼ˆå¦‚é€å±‚è°ƒèŠ‚ï¼‰ï¼›
- ç»“åˆåŠ¨æ€è§†è§‰æ£€ç´¢æœºåˆ¶ï¼Œåœ¨é•¿ä¸Šä¸‹æ–‡ä¸­æŒç»­æ›´æ–°æ³¨æ„åŠ›ç„¦ç‚¹ï¼›
- å°† SAYO æ€è·¯æ‰©å±•è‡³è§†é¢‘ã€3D åœºæ™¯ç­‰æ—¶åºæˆ–å¤šæ¨¡æ€è¾“å…¥ï¼›
- æ„å»ºæ— éœ€ bbox æ ‡æ³¨çš„è‡ªç›‘ç£æ³¨æ„åŠ›å¥–åŠ±æœºåˆ¶ã€‚

---

## âœ… æ€»ç»“ä¸€å¥è¯
> æœ¬æ–‡æ­ç¤ºäº† MLLMs åœ¨è§†è§‰æ¨ç†ä¸­çš„æ ¸å¿ƒç“¶é¢ˆæ˜¯**æ³¨æ„åŠ›ä¿¡ç”¨åˆ†é…ç¼ºå¤±**ï¼Œå¹¶é€šè¿‡æå‡º **SAYO æ¡†æ¶ + åŸºäºé«˜ç†µ token çš„æ³¨æ„åŠ›å¥–åŠ±æœºåˆ¶**ï¼Œå®ç°äº†æ— éœ€å¤–éƒ¨æç¤ºå³å¯ä¸»åŠ¨ã€ç¨³å®šèšç„¦å…³é”®è§†è§‰åŒºåŸŸçš„èƒ½åŠ›ï¼Œåœ¨å¤šé¡¹åŸºå‡†ä¸Šè¾¾åˆ° SOTA è¡¨ç°ï¼Œä¸”å±•ç°å‡ºå¼ºå¤§çš„è·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ã€‚

</details>

---

### 16. [SCOUT-RAG: Scalable and Cost-Efficient Unifying Traversal for Agentic Graph-RAG over Distributed Domains](https://arxiv.org/abs/2602.08400)

**Authors**: Longkun Li, Yuanben Zou, Jinghan Wu, Yuqing Wen, Jing Li, Hangwei Qian, Ivor Tsang  
**Category**: cs.AI  
**Published**: 2026-02-10  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.08400v1  

#### Abstract
Graph-RAG improves LLM reasoning using structured knowledge, yet conventional designs rely on a centralized knowledge graph. In distributed and access-restricted settings (e.g., hospitals or multinational organizations), retrieval must select relevant domains and appropriate traversal depth without ...

---

### 17. [Improving Variable-Length Generation in Diffusion Language Models via Length Regularization](https://arxiv.org/abs/2602.07546)

**Authors**: Zicong Cheng, Ruixuan Jia, Jia Li, Guo-Wei Yang, Meng-Hao Guo, Shi-Min Hu  
**Category**: cs.CL  
**Published**: 2026-02-10  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.07546v1  

#### Abstract
Diffusion Large Language Models (DLLMs) are inherently ill-suited for variable-length generation, as their inference is defined on a fixed-length canvas and implicitly assumes a known target length. When the length is unknown, as in realistic completion and infilling, naively comparing confidence ac...

---

### 18. [VocalNet-MDM: Accelerating Streaming Speech LLM via Self-Distilled Masked Diffusion Modeling](https://arxiv.org/abs/2602.08607)

**Authors**: Ziyang Cheng, Yuhao Wang, Heyang Liu, Ronghua Wu, Qunshan Gu, Yanfeng Wang, Yu Wang  
**Category**: cs.CL  
**Published**: 2026-02-10  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.08607v1  

#### Abstract
Recent Speech Large Language Models~(LLMs) have achieved impressive capabilities in end-to-end speech interaction. However, the prevailing autoregressive paradigm imposes strict serial constraints, limiting generation efficiency and introducing exposure bias. In this paper, we investigate Masked Dif...

---

### 19. [Systematic Performance Assessment of Deep Material Networks for Multiscale Material Modeling](https://arxiv.org/abs/2602.07192)

**Authors**: Xiaolong He, Haoyan Wei, Wei Hu, Henan Mao, C. T. Wu  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.07192v1  

#### Abstract
Deep Material Networks (DMNs) are structure-preserving, mechanistic machine learning models that embed micromechanical principles into their architectures, enabling strong extrapolation capabilities and significant potential to accelerate multiscale modeling of complex microstructures. A key advanta...

---

### 20. [Cerebellar-Inspired Residual Control for Fault Recovery: From Inference-Time Adaptation to Structural Consolidation](https://arxiv.org/abs/2602.07227)

**Authors**: Nethmi Jayasinghe, Diana Gontero, Spencer T. Brown, Vinod K. Sangwan, Mark C. Hersam, Amit Ranjan Trivedi  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.07227v1  

#### Abstract
Robotic policies deployed in real-world environments often encounter post-training faults, where retraining, exploration, or system identification are impractical. We introduce an inference-time, cerebellar-inspired residual control framework that augments a frozen reinforcement learning policy with...

---

### 21. [MaD-Mix: Multi-Modal Data Mixtures via Latent Space Coupling for Vision-Language Model Training](https://arxiv.org/abs/2602.07790)

**Authors**: Wanyun Xie, Francesco Tonin, Volkan Cevher  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.07790v1  

#### Abstract
Vision-Language Models (VLMs) are typically trained on a diverse set of multi-modal domains, yet current practices rely on costly manual tuning. We propose MaD-Mix, a principled and computationally efficient framework that derives multi-modal data mixtures for VLM training. MaD-Mix formulates data m...

---

### 22. [Horizon Imagination: Efficient On-Policy Training in Diffusion World Models](https://arxiv.org/abs/2602.08032)

**Authors**: Lior Cohen, Ofir Nabati, Kaixin Wang, Navdeep Kumar, Shie Mannor  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.08032v1  

#### Abstract
We study diffusion-based world models for reinforcement learning, which offer high generative fidelity but face critical efficiency challenges in control. Current methods either require heavyweight models at inference or rely on highly sequential imagination, both of which impose prohibitive computa...

---

### 23. [Compiler-Assisted Speculative Sampling for Accelerated LLM Inference on Heterogeneous Edge Devices](https://arxiv.org/abs/2602.08060)

**Authors**: Alejandro Ruiz y Mesa, Guilherme Korol, Moritz Riesteter, Jo\~ao Paulo Cardoso de Lima, Jeronimo Castrillon  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.08060v1  

#### Abstract
LLM deployment on resource-constrained edge devices faces severe latency constraints, particularly in real-time applications where delayed responses can compromise safety or usability. Among many approaches to mitigate the inefficiencies of sequential token-by-token generation, Speculative Decoding ...

---

### 24. [Enhancing Bandit Algorithms with LLMs for Time-varying User Preferences in Streaming Recommendations](https://arxiv.org/abs/2602.08067)

**Authors**: Chenglei Shen, Yi Zhan, Weijie Yu, Xiao Zhang, Jun Xu  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.08067v1  

#### Abstract
In real-world streaming recommender systems, user preferences evolve dynamically over time. Existing bandit-based methods treat time merely as a timestamp, neglecting its explicit relationship with user preferences and leading to suboptimal performance. Moreover, online learning methods often suffer...

---

### 25. [Towards Efficient Large Language Reasoning Models via Extreme-Ratio Chain-of-Thought Compression](https://arxiv.org/abs/2602.08324)

**Authors**: Yuntian Tang, Bohan Jia, Wenxuan Huang, Lianyue Zhang, Jiao Xie, Wenxi Li, Wei Li, Jie Hu, Xinghao Chen, Rongrong Ji, Shaohui Lin  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.08324v1  

#### Abstract
Chain-of-Thought (CoT) reasoning successfully enhances the reasoning capabilities of Large Language Models (LLMs), yet it incurs substantial computational overhead for inference. Existing CoT compression methods often suffer from a critical loss of logical fidelity at high compression ratios, result...

---

### 26. [Bridging Academia and Industry: A Comprehensive Benchmark for Attributed Graph Clustering](https://arxiv.org/abs/2602.08519)

**Authors**: Yunhui Liu, Pengyu Qiu, Yu Xing, Yongchao Liu, Peng Du, Chuntao Hong, Jiajun Zheng, Tao Zheng, Tieke He  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.08519v1  

#### Abstract
Attributed Graph Clustering (AGC) is a fundamental unsupervised task that integrates structural topology and node attributes to uncover latent patterns in graph-structured data. Despite its significance in industrial applications such as fraud detection and user segmentation, a significant chasm per...

---

### 27. [ERIS: Enhancing Privacy and Communication Efficiency in Serverless Federated Learning](https://arxiv.org/abs/2602.08617)

**Authors**: Dario Fenoglio, Pasquale Polverino, Jacopo Quizi, Martin Gjoreski, Marc Langheinrich  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.08617v1  

#### Abstract
Scaling federated learning (FL) to billion-parameter models introduces critical trade-offs between communication efficiency, model accuracy, and privacy guarantees. Existing solutions often tackle these challenges in isolation, sacrificing accuracy or relying on costly cryptographic tools. We propos...

---

### 28. [From Robotics to Sepsis Treatment: Offline RL via Geometric Pessimism](https://arxiv.org/abs/2602.08655)

**Authors**: Sarthak Wanjari  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.08655v1  

#### Abstract
Offline Reinforcement Learning (RL) promises the recovery of optimal policies from static datasets, yet it remains susceptible to the overestimation of out-of-distribution (OOD) actions, particularly in fractured and sparse data manifolds.Current solutions necessitates a trade off between computatio...

---

### 29. [How2Everything: Mining the Web for How-To Procedures to Evaluate and Improve LLMs](https://arxiv.org/abs/2602.08808)

**Authors**: Yapei Chang, Kyle Lo, Mohit Iyyer, Luca Soldaini  
**Category**: cs.LG  
**Published**: 2026-02-10  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.08808v1  

#### Abstract
Generating step-by-step "how-to" procedures is a key LLM capability: how-to advice is commonly requested in chatbots, and step-by-step planning is critical for reasoning over complex tasks. Yet, measuring and improving procedural validity at scale on real-world tasks remains challenging and understu...

---

### 30. [Steer2Adapt: Dynamically Composing Steering Vectors Elicits Efficient Adaptation of LLMs](https://arxiv.org/abs/2602.07276)

**Authors**: Pengrui Han, Xueqiang Xu, Keyang Xuan, Peiyang Song, Siru Ouyang, Runchu Tian, Yuqing Jiang, Cheng Qian, Pengcheng Jiang, Jiashuo Sun, Junxia Cui, Ming Zhong, Ge Liu, Jiawei Han, Jiaxuan You  
**Category**: cs.AI  
**Published**: 2026-02-10  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.07276v1  

#### Abstract
Activation steering has emerged as a promising approach for efficiently adapting large language models (LLMs) to downstream behaviors. However, most existing steering methods rely on a single static direction per task or concept, making them inflexible under task variation and inadequate for complex...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- kv cache, offload, State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
