# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-29 06:01:33 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Accelerate Speculative Decoding with Sparse Computation in Verification](https://arxiv.org/abs/2512.21911)

**Authors**: Jikai Wang, Jianchao Tan, Yuxuan Hu, Jiayu Qin, Yerui Sun, Yuchen Xie, Xunliang Cai, Juntao Li, Min Zhang  
**Category**: cs.CL  
**Published**: 2025-12-29  
**Score**: 14.5  
**Type**: new  
**ArXiv ID**: 2512.21911v1  

#### Abstract
Speculative decoding accelerates autoregressive language model inference by verifying multiple draft tokens in parallel. However, the verification stage often becomes the dominant computational bottleneck, especially for long-context inputs and mixture-of-experts (MoE) models. Existing sparsificatio...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAccelerate Speculative Decoding with Sparse Computation in Verification

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
- **éªŒè¯é˜¶æ®µæˆä¸ºè®¡ç®—ç“¶é¢ˆ**ï¼šåœ¨ Speculative Decoding ä¸­ï¼Œè™½ç„¶é€šè¿‡ draft æ¨¡å‹å¹¶è¡Œç”Ÿæˆå¤šä¸ªå€™é€‰ token åŠ é€Ÿäº†æ¨ç†ï¼Œä½†ç›®æ ‡æ¨¡å‹å¯¹è¿™äº› token çš„**å¹¶è¡ŒéªŒè¯è¿‡ç¨‹**ï¼ˆå°¤å…¶æ˜¯é•¿ä¸Šä¸‹æ–‡ã€MoE æ¨¡å‹ï¼‰å¼•å…¥äº†å·¨å¤§çš„è®¡ç®—å¼€é”€ã€‚
- ç°æœ‰ç¨€ç–åŒ–æ–¹æ³•ï¼ˆå¦‚ Sparse Attentionã€Sparse FFNï¼‰ä¸»è¦é’ˆå¯¹æ ‡å‡†è‡ªå›å½’è§£ç è®¾è®¡ï¼Œæœªè€ƒè™‘å¤š token å¹¶è¡ŒéªŒè¯åœºæ™¯ä¸‹çš„ç»“æ„å†—ä½™ã€‚

### æå‡ºçš„æ–°æ–¹æ³•/æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§**ç»Ÿä¸€çš„ç¨€ç–éªŒè¯æ¡†æ¶**ï¼ˆsparse verification frameworkï¼‰ï¼Œåœ¨ä¸éœ€é‡æ–°è®­ç»ƒçš„å‰æä¸‹ï¼Œåœ¨éªŒè¯é˜¶æ®µè”åˆç¨€ç–åŒ–ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š

1. **Sparse Attention**  
   - åŸºäºç¬¬ä¸€ä¸ª draft token çš„ query è¿›è¡Œ KV block æ£€ç´¢ï¼Œå¹¶ä¾›æ‰€æœ‰ draft tokens å¤ç”¨ã€‚
   - å¼•å…¥è¾¹ç•Œä¿ç•™æœºåˆ¶ï¼ˆä¿ç•™é¦–å°¾ blocksï¼‰ä»¥é˜²æ­¢é‡è¦ä¸Šä¸‹æ–‡ä¸¢å¤±ã€‚
   - é‡‡ç”¨åˆ†æ®µé¢„ç®—æ§åˆ¶ï¼ˆpiecewise budget controlï¼‰ç­–ç•¥ï¼šçŸ­åºåˆ—ä¸å‰ªæï¼Œé•¿åºåˆ—æŒ‰æ¯”ä¾‹åŠ¨æ€è°ƒæ•´ä¿ç•™ block æ•°é‡ã€‚

2. **Inter-layer Retrieval Reuse**  
   - è§‚å¯Ÿåˆ°ä¸­æ·±å±‚ Transformer å±‚é—´ KV block æ£€ç´¢é«˜åº¦ç›¸ä¼¼ã€‚
   - åªåœ¨â€œé”šå®šå±‚â€ï¼ˆanchor layersï¼‰æ‰§è¡Œæ£€ç´¢ï¼Œå…¶ä½™éé”šå®šå±‚å¤ç”¨æœ€è¿‘å‰é©±é”šå®šå±‚çš„ç»“æœï¼Œæ˜¾è‘—å‡å°‘é‡å¤æ£€ç´¢æ“ä½œã€‚

3. **Sparse Feed-Forward Network (SFFN)**  
   - åœ¨éªŒè¯æ—¶è·³è¿‡æ¿€æ´»å€¼ä½äºé˜ˆå€¼ $T$ çš„ FFN é€šé“ï¼Œä»…ä¿ç•™é«˜å“åº”é€šé“å‚ä¸ up/down projection è®¡ç®—ã€‚
   - åˆ©ç”¨ FFN å†…éƒ¨çš„æ¿€æ´»ç¨€ç–æ€§é™ä½ FLOPsã€‚

4. **Sparse Mixture-of-Experts (SMoE)**  
   - åŠ¨æ€è·³è¿‡è·¯ç”±æƒé‡è¾ƒä½çš„ä¸“å®¶ï¼ˆexpertsï¼‰ï¼Œå…è®¸æ¯ä¸ª token è·³è¿‡æœ€å¤š $m$ ä¸ªä½è´¡çŒ®ä¸“å®¶ã€‚
   - é˜ˆå€¼åŸºäºæ ¡å‡†æ•°æ®é›†ä¸Šçš„è·¯ç”± logit æ¯”ä¾‹ä¸­ä½æ•°è®¾å®šï¼Œé€‚ç”¨äºä»»æ„æ´»è·ƒä¸“å®¶æ•° $k > 2$ã€‚

5. **Hybrid Sparse Method**  
   - å°†ä¸Šè¿°ä¸‰ç§ç¨€ç–ç­–ç•¥ç»“åˆï¼Œåœ¨æ³¨æ„åŠ›ã€FFN å’Œ MoE ä¸‰ä¸ªæ­£äº¤ç»´åº¦ä¸ŠåŒæ—¶è¿›è¡Œç¨€ç–åŒ–ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **é€šç”¨æ€§** | ä¸ä¾èµ– retraining æˆ–æ¶æ„ä¿®æ”¹ï¼Œå¯ç›´æ¥åº”ç”¨äºç°æˆ LLMsï¼ˆoff-the-shelf modelsï¼‰ã€‚ |
| **æ•ˆç‡æå‡** | æ˜¾è‘—é™ä½éªŒè¯é˜¶æ®µä¸»å¯¼æ€§è®¡ç®—æˆæœ¬ï¼ˆè§ Table 1 FLOPs åˆ†æï¼‰ï¼Œå°¤å…¶åœ¨é•¿ä¸Šä¸‹æ–‡å’Œ MoE åœºæ™¯ä¸‹æ•ˆæœæ›´æ˜æ˜¾ã€‚ |
| **ç²¾åº¦ä¿æŒ** | åœ¨é€‚åº¦ç¨€ç–ä¸‹å‡ ä¹æ— æ€§èƒ½æŸå¤±ï¼Œç”šè‡³éƒ¨åˆ†ä»»åŠ¡ç•¥æœ‰æå‡ï¼ˆå¯èƒ½å› å»å™ªæ•ˆåº”ï¼‰ã€‚ |
| **ç¨³å®šæ€§** | ç»´æŒç¨³å®šçš„ acceptance lengthï¼Œä¸å½±å“æ•´ä½“ç”Ÿæˆåˆ†å¸ƒä¸€è‡´æ€§ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–å¤šç§ä»»åŠ¡ç±»å‹ï¼Œæ¥è‡ª **LongBench** å’Œæ•°å­¦æ¨ç†åŸºå‡†ï¼š
- **Summarization**: `GovReport`
- **Question Answering**: `2WikiMQA`, `HotpotQA`
- **Code Editing**: `LCC`, `RepoBench-P`
- **Mathematical Reasoning**: `GSM8K`, `Math`, `CollegeMath`

### å®éªŒè®¾ç½®
| è®¾ç½®é¡¹ | æè¿° |
|-------|------|
| **Target Models** | - Llama3.1-8B-Instructï¼ˆç”¨äº SA å®éªŒï¼‰<br>- Qwen3-30B-A3Bï¼ˆç”¨äº SFFNï¼‰<br>- Deepseek-R1ï¼ˆç”¨äº SMoE ä¸ Hybridï¼‰ |
| **Draft Model** | EAGLE-3 æˆ– MTP headsï¼Œä½¿ç”¨æ ‘å½¢ draft ç»“æ„ï¼ˆtree-structured draftsï¼‰ï¼Œå…± 60 ä¸ªå€™é€‰ token |
| **ç¡¬ä»¶å¹³å°** | 8Ã—NVIDIA H800-80G GPUs |
| **ç¨€ç–å‚æ•°æœç´¢èŒƒå›´** | - Attention: $L_0 \in \{1K, 2K, 4K\}$<br>- FFN: é˜ˆå€¼ $T \in \{0.01, 0.05, 0.1\}$<br>- MoE: è·³è¿‡é¢„ç®— $m \in \{2,3,4\}$ |

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **ROUGE / F1 / Acc.** | å„ä»»åŠ¡ä¸»æ€§èƒ½æŒ‡æ ‡ï¼ˆå¦‚ ROUGE-L for summarization, F1 for QA, Accuracy for mathï¼‰ |
| **Sparsity ($s_a, s_f, s_e$)** | æ³¨æ„åŠ›ã€FFNã€MoE æ¨¡å—çš„å¹³å‡ç¨€ç–åº¦ |
| **Mean Acceptance Length ($\bar{o}$)** | è¡¡é‡ speculative decoding æ•ˆç‡çš„å…³é”®æŒ‡æ ‡ï¼Œåæ˜  draft token çš„æ¥å—ç‡ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Strict**: æ ‡å‡† speculative decodingï¼Œå…¨æ³¨æ„åŠ›ã€å…¨ FFNã€å…¨ä¸“å®¶æ¿€æ´»ï¼ˆå³æ— ç¨€ç–ï¼‰
- **SA / SA***: Sparse Attention with/without inter-layer retrieval reuse
- **SFFN / SMoE / Hybrid**: å¯¹åº”æ¨¡å—ç¨€ç–åŒ–æ–¹æ³•åŠå…¶ç»„åˆ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### âœ… Sparse Attentionï¼ˆTable 2ï¼‰
| æ–¹æ³• | Sparsity ($s_a$) | GovReport (ROUGE) | 2WikiMQA (F1) | HotpotQA (F1) |
|------|------------------|--------------------|---------------|----------------|
| Strict | 0 | 34.18 | 39.20 | 47.66 |
| SA ($L_0=4K$) | 0.34 | 33.50 (-0.68) | 39.32 (+0.12) | 47.43 (-0.23) |
| SA* ($L_0=4K$) | 0.34 | 33.28 (-0.90) | 35.78 (-3.42) | 44.78 (-2.88) |

> ğŸ“Œ **ç»“è®º**ï¼šé€‚åº¦ç¨€ç–ï¼ˆ$s_aâ‰ˆ0.34$ï¼‰ä¸‹æ€§èƒ½ä¸‹é™æå°ï¼›åŠ å…¥ layer reuse å QA ç±»ä»»åŠ¡ç•¥æœ‰é€€åŒ–ï¼Œä½†é•¿æ–‡æœ¬æ‘˜è¦ç¨³å®šã€‚

#### âœ… Sparse FFNï¼ˆTable 3ï¼‰
| æ–¹æ³• | Sparsity ($s_f$) | GovReport | 2WikiMQA | GSM8K (Acc.) |
|------|------------------|-----------|----------|--------------|
| Strict | 0 | 32.67 | 43.93 | 90.0 |
| SFFN ($T=0.1$) | 0.64 | **33.51** (+0.84) | 62.01 | 91.0 |

> ğŸ“Œ **ç»“è®º**ï¼šå³ä½¿é«˜è¾¾ 64% çš„ FFN é€šé“è¢«è·³è¿‡ï¼Œæ€§èƒ½ä»ç¨³å®šç”šè‡³ç•¥æœ‰æå‡ï¼Œè¡¨æ˜éªŒè¯é˜¶æ®µå­˜åœ¨å¤§é‡å†—ä½™æ¿€æ´»ã€‚

#### âœ… Sparse MoEï¼ˆTable 4ï¼‰
| æ–¹æ³• | Sparsity ($s_e$) | 2WikiMQA (F1) | Math (Acc.) | CollegeMath (Acc.) |
|------|------------------|---------------|-------------|---------------------|
| Strict | 0 | 77.39 | 82.0 | 58.0 |
| SMoE ($m=3$) | 0.16 | **78.52** | **87.0** | 57.0 |
| SMoE ($m=4$) | 0.22 | 78.88 | 75.0 â†“ | 52.0 â†“ |

> ğŸ“Œ **ç»“è®º**ï¼šé€‚åº¦è·³è¿‡ä¸“å®¶ï¼ˆ$m=2,3$ï¼‰å¯å»é™¤å™ªå£°ä¿¡å·ï¼Œåè€Œæå‡æ€§èƒ½ï¼›è¿‡åº¦ç¨€ç–ï¼ˆ$m=4$ï¼‰æŸå®³å¤æ‚æ¨ç†èƒ½åŠ›ã€‚

#### âœ… Hybrid Sparse Methodï¼ˆTable 5ï¼‰
| æ–¹æ³• | ROUGE (GovReport) | F1 (2WikiMQA) | Acc. (GSM8K) | $\bar{o}$ (å‡å€¼) |
|------|--------------------|----------------|---------------|------------------|
| Strict | 26.90 | 77.39 | 98.0 | 2.44 |
| Hybrid | **27.40** | **79.82** | 96.0 | 2.42 |

> ğŸ“Œ **ç»“è®º**ï¼šä¸‰é‡ç¨€ç–è”åˆä½¿ç”¨ä»èƒ½ä¿æŒç”šè‡³æå‡å¤šæ•°ä»»åŠ¡æ€§èƒ½ï¼Œä¸” acceptance length å‡ ä¹ä¸å˜ï¼ˆä»…å¾®é™ 0.02ï¼‰ï¼Œè¯´æ˜ç¨€ç–åŒ–æœªç ´å draft-target å¯¹é½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **éªŒè¯é˜¶æ®µå­˜åœ¨æ˜¾è‘—ç»“æ„æ€§å†—ä½™**  
   - æ³¨æ„åŠ›ï¼šå¤šæ•° KV blocks å¯å®‰å…¨å‰ªæï¼Œå°¤å…¶ä¸­é—´ä½ç½®ï¼›
   - FFNï¼šå¤§é‡ä½æ¿€æ´»é€šé“å¯¹è¾“å‡ºå½±å“ç”šå¾®ï¼›
   - MoEï¼šä½æƒé‡ä¸“å®¶è´¡çŒ®æœ‰é™ï¼Œå¯åŠ¨æ€è·³è¿‡ã€‚

2. **è·¨ token ä¸è·¨å±‚å†—ä½™å¯è¢«æœ‰æ•ˆåˆ©ç”¨**  
   - åŒä¸€æ­¥éª¤å†…å¤šä¸ª draft tokens æ£€ç´¢é«˜åº¦é‡å  â†’ å¯å…±äº« block selectionï¼›
   - ä¸­æ·±å±‚ Transformer å±‚é—´æ£€ç´¢æ¨¡å¼ç›¸ä¼¼ â†’ å¯å®ç° inter-layer reuseã€‚

3. **ç¨€ç–éªŒè¯å¯åœ¨å‡ ä¹æ— æŸæƒ…å†µä¸‹å¤§å¹…ææ•ˆ**  
   - åœ¨åˆç†ç¨€ç–é…ç½®ä¸‹ï¼Œå„é¡¹ä»»åŠ¡æ€§èƒ½åŸºæœ¬æŒå¹³æˆ–ç•¥æœ‰æå‡ï¼›
   - æ¥å—é•¿åº¦ï¼ˆacceptance lengthï¼‰å˜åŒ–æå°ï¼Œä¿è¯äº†åŠ é€Ÿæ”¶ç›Šã€‚

4. **ä¸åŒä»»åŠ¡å¯¹ç¨€ç–æ•æ„Ÿåº¦ä¸åŒ**  
   - ç”Ÿæˆç±»ä»»åŠ¡ï¼ˆsummarization, open QAï¼‰é²æ£’æ€§å¼ºï¼›
   - ç¬¦å·å¯†é›†å‹æ•°å­¦æ¨ç†ï¼ˆCollegeMathï¼‰å¯¹è¿‡åº¦ç¨€ç–æ›´æ•æ„Ÿã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ç¨€ç–å‚æ•°éœ€æ‰‹åŠ¨è°ƒä¼˜**ï¼šå¦‚ $L_0$, $T$, $m$ ç­‰ä¾èµ–ç»éªŒæˆ–æ ¡å‡†æ•°æ®é›†é€‰æ‹©ã€‚
- **æç«¯ç¨€ç–ä¼šæŸå®³å¤æ‚æ¨ç†**ï¼šç‰¹åˆ«æ˜¯éœ€è¦ç²¾ç¡® token-level éªŒè¯çš„ä»»åŠ¡ï¼ˆå¦‚ CollegeMathï¼‰ã€‚
- **æœªæ¢ç´¢ç¨€ç–å¯¹ draft model è®­ç»ƒçš„å½±å“**ï¼šå½“å‰å‡è®¾ draft model ä¸éç¨€ç– target å¯¹é½ï¼Œè‹¥ target ç¨€ç–åŒ–ç¨‹åº¦é«˜ï¼Œå¯èƒ½éœ€é‡æ–°è®­ç»ƒ draft model ä»¥æ›´å¥½é€‚é…ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **è‡ªåŠ¨åŒ–ç¨€ç–è°ƒåº¦å™¨**ï¼šæ ¹æ®è¾“å…¥é•¿åº¦ã€ä»»åŠ¡ç±»å‹è‡ªåŠ¨è°ƒèŠ‚å„æ¨¡å—ç¨€ç–å¼ºåº¦ã€‚
2. **ç«¯åˆ°ç«¯ç¨€ç–æ„ŸçŸ¥è®­ç»ƒ**ï¼šå°†ç¨€ç–éªŒè¯çº³å…¥è®­ç»ƒç›®æ ‡ï¼Œä¼˜åŒ– draft-target å¯¹é½ã€‚
3. **æ‰©å±•è‡³å…¶ä»– generation paradigms**ï¼šå¦‚ lookahead decodingã€parallel decoding ç­‰ã€‚
4. **ç¡¬ä»¶ååŒä¼˜åŒ–**ï¼šç»“åˆ Sparse Attention çš„ block ç»“æ„è®¾è®¡ä¸“ç”¨ kernel æå‡å®é™…ååã€‚

---

> ğŸ”š **æ€»ç»“ä¸€å¥è¯**ï¼šè¯¥è®ºæ–‡ç³»ç»Ÿåœ°æ­ç¤ºäº† speculative decoding éªŒè¯é˜¶æ®µçš„å¤šç»´å†—ä½™ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæ— éœ€è®­ç»ƒã€å¯æ’æ‹”çš„ç¨€ç–éªŒè¯æ¡†æ¶ï¼Œåœ¨ä¿æŒç”Ÿæˆè´¨é‡çš„åŒæ—¶æ˜¾è‘—æå‡äº†æ¨ç†æ•ˆç‡ï¼Œä¸ºé•¿ä¸Šä¸‹æ–‡ä¸ MoE æ¨¡å‹çš„é«˜æ•ˆéƒ¨ç½²æä¾›äº†å®ç”¨è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 2. [LIME:Accelerating Collaborative Lossless LLM Inference on Memory-Constrained Edge Devices](https://arxiv.org/abs/2512.21835)

**Authors**: Mingyu Sun, Xiao Zhang, Shen Qu, Yan Li, Mengbai Xiao, Yuan Yuan, Dongxiao Yu  
**Category**: cs.DC  
**Published**: 2025-12-29  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2512.21835v1  

#### Abstract
Large language models (LLMs) have emerged as a powerful foundation for intelligent reasoning and decision-making, demonstrating substantial impact across a wide range of domains and applications. However, their massive parameter scales and substantial resource demands pose critical challenges for ef...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# LIME: Accelerating Collaborative Lossless LLM Inference on Memory-Constrained Edge Devices â€”â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆ**LLMs**ï¼‰åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šè¿›è¡Œæ¨ç†é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼š
- **å†…å­˜ä¸¥é‡å—é™**ï¼šå¦‚ LLaMA3.3-70B-Instruct éœ€è¦è‡³å°‘ 130GB å†…å­˜ï¼Œè€Œå…¸å‹è¾¹ç¼˜è®¾å¤‡ï¼ˆå¦‚ NVIDIA Jetsonï¼‰ä»…æä¾› 16â€“64GBã€‚
- **ç½‘ç»œå¸¦å®½æœ‰é™ä¸”æ³¢åŠ¨å¤§**ï¼šåˆ†å¸ƒå¼éƒ¨ç½²ä¸­é€šä¿¡å¼€é”€é«˜ï¼Œå½±å“å®æ—¶æ€§å’Œæ•ˆç‡ã€‚

ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚é‡åŒ–ã€å‰ªæã€è’¸é¦ï¼‰è™½èƒ½é™ä½èµ„æºæ¶ˆè€—ï¼Œä½†ä¼šå¼•å…¥**ç²¾åº¦æŸå¤±ï¼ˆlossyï¼‰**ï¼Œä¸é€‚ç”¨äºé‡‘èé£æ§ã€åŒ»ç–—è¯Šæ–­ç­‰å¯¹å‡†ç¡®æ€§è¦æ±‚æé«˜çš„åœºæ™¯ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šLIME æ¡†æ¶
LIME æ˜¯ä¸€ä¸ªæ”¯æŒ**æ— æŸï¼ˆlosslessï¼‰ååŒæ¨ç†**çš„ç³»ç»Ÿæ¡†æ¶ï¼Œä¸“ä¸ºå†…å­˜å—é™ã€å¸¦å®½å—é™çš„å¼‚æ„è¾¹ç¼˜è®¾å¤‡è®¾è®¡ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰**äº¤é”™å¼æµæ°´çº¿å¹¶è¡Œï¼ˆInterleaved Pipeline Parallelismï¼‰**
- å°†æ¨¡å‹åˆ†å±‚åˆ†é…ç»™å¤šä¸ªè®¾å¤‡ï¼Œå¹¶å…è®¸æ¯ä¸ªè®¾å¤‡æ‰¿è½½å¤šä¸ªéè¿ç»­çš„â€œæ®µâ€ï¼ˆsegmentï¼‰ï¼Œå®ç°æ›´çµæ´»çš„è´Ÿè½½å‡è¡¡ã€‚
- åœ¨æ¯ä¸€æ®µæ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œå°†**åŠ¨æ€å¸è½½ï¼ˆoffloadingï¼‰ä¸è®¡ç®—/é€šä¿¡é‡å **ï¼Œæ˜¾è‘—å‡å°‘ç­‰å¾…å»¶è¿Ÿã€‚
- ç›¸æ¯”ä¼ ç»Ÿæµæ°´çº¿ä¸­â€œåŒä¸€é˜¶æ®µå†…éœ€å¤šæ¬¡åŠ è½½â€çš„é—®é¢˜ï¼ŒLIME å‡å°‘äº†é‡å¤åŠ è½½æ¬¡æ•°ã€‚

#### ï¼ˆ2ï¼‰**ç»†ç²’åº¦ç¦»çº¿è°ƒåº¦å™¨ï¼ˆFine-grained Offline Allocation Schedulerï¼‰**
- æ„å»ºäº†ä¸€ä¸ªé¢å‘å¸è½½çš„å¼‚æ„æˆæœ¬æ¨¡å‹ï¼ˆheterogeneous offload-orient cost modelï¼‰ï¼Œç»¼åˆè€ƒè™‘ï¼š
  - å„è®¾å¤‡çš„è®¡ç®—èƒ½åŠ›
  - å†…å­˜å®¹é‡
  - åŠ è½½é€Ÿåº¦
  - é€šä¿¡å¸¦å®½
- åˆ©ç”¨åŠ¨æ€è§„åˆ’ç®—æ³•å¿«é€Ÿæœç´¢æœ€ä¼˜å±‚åˆ†é…ç­–ç•¥ï¼Œåœ¨æ¯«ç§’çº§æ—¶é—´å†…å®Œæˆè°ƒåº¦å†³ç­–ã€‚
- æ”¯æŒä»¥ **MHA æˆ– MLP æ¨¡å—ä¸ºå•ä½**è¿›è¡Œç»†ç²’åº¦å¸è½½ï¼Œé¿å…ç²—ç²’åº¦å±‚å¸è½½å¸¦æ¥çš„å†…å­˜ç¢ç‰‡å’Œé¢‘ç¹ä¼ è¾“ã€‚

#### ï¼ˆ3ï¼‰**åœ¨çº¿å†…å­˜è‡ªé€‚åº”ç­–ç•¥ï¼ˆOnline Memory Adaptation Strategyï¼‰**
- åŒ…å«ä¸¤ä¸ªå…³é”®æœºåˆ¶åº”å¯¹è¿è¡Œæ—¶å˜åŒ–ï¼š
  - **KV Cache Transfer Protocol**ï¼šå½“æŸè®¾å¤‡ KV ç¼“å­˜å¢é•¿è¿‡å¿«æ—¶ï¼Œå°†å…¶éƒ¨åˆ† KV ç¼“å­˜è½¬ç§»åˆ°å…¶ä»–ç©ºé—²è®¾å¤‡ï¼Œç¼“è§£å±€éƒ¨ç“¶é¢ˆã€‚
  - **Memory-aware Planner**ï¼šæ ¹æ®å½“å‰ç”Ÿæˆ token æ•°é‡é¢„æµ‹å†…å­˜å‹åŠ›ï¼ŒåŠ¨æ€è§¦å‘æ¨¡å—çº§å¸è½½ï¼ˆå¦‚å…ˆå¸ MHAï¼Œå†å¸ MLPï¼‰ï¼Œå¹¶è‡ªåŠ¨ç¡®å®šä¸‹ä¸€æ¬¡å¸è½½é˜ˆå€¼ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| å¯¹æ¯”ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ EdgeShardã€Galaxyã€TPI-LLMï¼‰ | LIME |
|--------|------------------------------------------|------|
| æ˜¯å¦æ”¯æŒ lossless æ¨ç† | å¤šæ•°ä¸ä¿è¯å®Œå…¨æ— æŸæˆ–ä¾èµ–è¿‘ä¼¼å‹ç¼© | âœ… å®Œå…¨ä¿ç•™åŸå§‹æ¨¡å‹å‚æ•°ï¼Œç¡®ä¿æ— æŸ |
| æ˜¯å¦å¤„ç†æç«¯å†…å­˜ä¸è¶³ | å¤šæ•°å‡è®¾è®¾å¤‡å¯å®¹çº³æœ€å°åˆ†ç‰‡ | âœ… å¯åœ¨å•ä¸ªè®¾å¤‡æ— æ³•å®¹çº³ä»»ä½•å®Œæ•´å±‚çš„æƒ…å†µä¸‹è¿è¡Œ |
| å¸è½½ç²’åº¦ | å±‚çº§åˆ«ï¼ˆlayer-levelï¼‰ä¸ºä¸» | âœ… æ”¯æŒ MHA/MLP å—çº§å¸è½½ï¼Œå‡å°‘ä¼ è¾“é‡ |
| èµ„æºåˆ©ç”¨ç‡ | å›ºå®šé™æ€åˆ’åˆ†ï¼Œéš¾ä»¥é€‚åº”å˜åŒ– | âœ… åŠ¨æ€è°ƒæ•´ KV åˆ†é…ä¸å¸è½½è®¡åˆ’ |
| é€šä¿¡æ•ˆç‡ | å¼ é‡å¹¶è¡Œï¼ˆTPï¼‰å¸¦æ¥é«˜åŒæ­¥å¼€é”€ | âœ… æµæ°´çº¿å¹¶è¡Œ + å¸è½½ï¼Œæ›´é€‚åˆä½å¸¦å®½ç¯å¢ƒ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š ä½¿ç”¨çš„æ¨¡å‹ï¼ˆè€Œéæ•°æ®é›†ï¼‰
ç”±äºæ˜¯æ¨ç†åŠ é€Ÿç ”ç©¶ï¼Œé‡ç‚¹åœ¨äºæ¨¡å‹è§„æ¨¡å’Œæ¶æ„å¤šæ ·æ€§ï¼Œè€Œéè®­ç»ƒæ•°æ®ã€‚ä½¿ç”¨äº†ä»¥ä¸‹ä¸‰ç§ä¸»æµ LLMï¼š

| Model | å‚æ•°é‡ | å±‚æ•° | éšè—ç»´åº¦ | Attention Heads |
|-------|--------|------|-----------|------------------|
| Llama2-13B-Instruct | 13B | 40 | 5120 | 40 |
| Qwen3-32B | 32B | 64 | 5120 | 64 |
| Llama3.3-70B-Instruct | 70B | 80 | 8192 | 64 |

> æ‰€æœ‰æ¨¡å‹ä» Hugging Face ä¸‹è½½ï¼Œè¾“å…¥æ¥è‡ªé€šç”¨æ–‡æœ¬ç”Ÿæˆä»»åŠ¡å­é›†ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®

#### ç¡¬ä»¶å¹³å°
åŸºäºä¸‰ç§ NVIDIA Jetson è®¾å¤‡æ„å»ºå¼‚æ„è¾¹ç¼˜é›†ç¾¤ï¼š
| è®¾å¤‡å‹å· | å†…å­˜ | GPU | AI æ€§èƒ½ |
|---------|------|-----|--------|
| Jetson Xavier NX (16GB) | 16GB | Volta | 21 TOPS |
| Jetson AGX Orin (32GB) | 32GB | Ampere | 200 TOPS |
| Jetson AGX Orin (64GB) | 64GB | Ampere | 275 TOPS |

è¿æ¥æ–¹å¼ï¼šé€šè¿‡è·¯ç”±å™¨å’Œäº¤æ¢æœºäº’è”ï¼Œæ€»å¸¦å®½ 1000 Mbpsï¼Œä½¿ç”¨ Linux TC å·¥å…·æ¨¡æ‹Ÿ **100 Mbps å’Œ 200 Mbps** ä¸¤ç§ç½‘ç»œæ¡ä»¶ã€‚

#### è¯·æ±‚æ¨¡å¼ï¼ˆRequest Patternsï¼‰
- **Sporadic**ï¼šå•è¯·æ±‚é—´æ­‡åˆ°è¾¾ï¼Œmicro-batch size = 1
- **Bursty**ï¼šå¤šè¯·æ±‚å¹¶å‘æäº¤ï¼Œæ¨¡æ‹Ÿçªå‘æµé‡

#### å®éªŒç¯å¢ƒé…ç½®ï¼ˆè§ Table IVï¼‰
| ç¯å¢ƒ | æ¨¡å‹ | è®¾å¤‡ç»„æˆ |
|------|------|----------|
| E1 | Llama2-13B | 1Ã—NX(16G) + 1Ã—Orin(32G) |
| E2 | Qwen3-32B | 1Ã—NX(16G) + 1Ã—Orin(32G) + 1Ã—Orin(64G) |
| E3 | Llama3.3-70B | 1Ã—NX(16G) + 2Ã—Orin(64G) |

---

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
- **æ¨ç†å»¶è¿Ÿï¼ˆInference Latencyï¼‰**ï¼šå•ä½ ms/tokenï¼Œä¸ºä¸»è¦æ€§èƒ½æŒ‡æ ‡ã€‚
- **åŠ é€Ÿæ¯”ï¼ˆSpeedupï¼‰**ï¼šç›¸å¯¹äºåŸºçº¿æ–¹æ³•çš„å»¶è¿Ÿä¸‹é™å€æ•°ã€‚
- **OOM / OOT åˆ¤æ–­æ ‡å‡†**ï¼š
  - Sporadic åœºæ™¯ï¼š>40s/token â†’ OOTï¼ˆè¶…æ—¶ï¼‰
  - Bursty åœºæ™¯ï¼š>15s/token â†’ OOT

---

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
å…±æ¯”è¾ƒå…­ç§ä»£è¡¨æ€§æ–¹æ³•ï¼š
1. **Pipeline Parallelism**ï¼šç»å…¸æµæ°´çº¿å¹¶è¡Œ
2. **Pipeline + Offloading**ï¼šæµæ°´çº¿ + æ˜¾å­˜å¤–å¸è½½
3. **EdgeShard**ï¼šé’ˆå¯¹è¾¹ç¼˜ä¼˜åŒ–çš„é«˜æ•ˆæµæ°´çº¿æ¡†æ¶
4. **Galaxy**ï¼šåŸºäºå¼ é‡å¹¶è¡Œï¼ˆTPï¼‰çš„åˆ†å¸ƒå¼æ¨ç†ç³»ç»Ÿ
5. **TPI-LLM**ï¼šç§»åŠ¨ç«¯è½»é‡åŒ– TP æ¨ç†æ–¹æ¡ˆ
6. **TPI-LLM + Offloading**ï¼šæ‰©å±•ç‰ˆï¼ŒåŠ å…¥æ»‘åŠ¨çª—å£ç®¡ç† KV Cache

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“‰ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆE3 ç¯å¢ƒï¼ŒLLaMA3.3-70B-Instructï¼‰

| æ–¹æ³• | Sporadic @200Mbps (ms/token) | Bursty @200Mbps (ms/token) | Speedup vs SOTA |
|------|-------------------------------|------------------------------|-----------------|
| LIME | **1501.9** | **423.2** | 1.00Ã— |
| Pipeline + Offloading | ~2550 | ~1561 | 0.59Ã— |
| EdgeShard | ~2494 | ~1591 | 0.60Ã— |
| TPI-LLM | ~4000+ | ~1000~3000 | OOT / variable |
| Galaxy | OOM | OOM | ä¸å¯ç”¨ |

> âœ… **LIME åœ¨å››å°å¼‚æ„ Jetson ä¸ŠæˆåŠŸè¿è¡Œ 70B æ¨¡å‹ï¼Œè€Œå¤šæ•°åŸºçº¿å¤±è´¥ï¼ˆOOMï¼‰æˆ–è¶…æ—¶ï¼ˆOOTï¼‰**

---

### ğŸ“Š åŠ é€Ÿæ•ˆæœæ±‡æ€»
| åœºæ™¯ | ç›¸å¯¹äº SOTA çš„åŠ é€Ÿæ¯” |
|------|------------------------|
| Sporadic è¯·æ±‚ | **1.7Ã—** |
| Bursty è¯·æ±‚ | **3.7Ã—** |

> åœ¨ä½å¸¦å®½ï¼ˆ100Mbpsï¼‰å’Œé«˜å¸¦å®½ï¼ˆ200Mbpsï¼‰ä¸‹å‡ä¿æŒæ˜¾è‘—ä¼˜åŠ¿ã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼Œè§ Table Vï¼‰

| æ–¹æ³•å˜ä½“ | Sporadic Latency (ms/token) | Speedup vs LIME | Bursty Latency (ms/token) | Speedup vs LIME |
|--------|----------------------------|------------------|----------------------------|------------------|
| LIMEï¼ˆå®Œæ•´ï¼‰ | 1501.9 | 1.00Ã— | 423.2 | 1.00Ã— |
| ç¼ºå°‘ KV Cache Transfer | 1748.2 | 0.86Ã— | 489.0 | 0.87Ã— |
| ç¼ºå°‘ Memory-aware Planner | 2251.7 | 0.67Ã— | 614.8 | 0.69Ã— |

> ç»“æœè¡¨æ˜ï¼š
- **KV Cache Transfer Protocol** è´¡çŒ®çº¦ 14% æ€§èƒ½æå‡
- **Memory-aware Planner** è´¡çŒ®çº¦ 33% æ€§èƒ½æå‡
- ä¸¤è€…å…±åŒä½œç”¨æ˜¾è‘—å¢å¼ºç³»ç»Ÿé²æ£’æ€§ä¸æ•ˆç‡

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **äº¤é”™å¼æµæ°´çº¿ + ç»†ç²’åº¦å¸è½½** å¯æœ‰æ•ˆè§£å†³è¾¹ç¼˜è®¾å¤‡å†…å­˜ä¸è¶³ä»¥å®¹çº³å•ä¸€å±‚çš„é—®é¢˜ï¼Œé¦–æ¬¡å®ç°åœ¨æç«¯å†…å­˜å—é™æ¡ä»¶ä¸‹å¯¹ 70B çº§åˆ« LLM çš„**æ— æŸååŒæ¨ç†**ã€‚
2. **ç¦»çº¿è°ƒåº¦ + åœ¨çº¿è‡ªé€‚åº”** çš„åŒå±‚è®¾è®¡ï¼Œå…¼é¡¾äº†åˆå§‹èµ„æºæœ€ä¼˜åˆ†é…ä¸è¿è¡Œæ—¶åŠ¨æ€è°ƒèŠ‚èƒ½åŠ›ï¼Œå°¤å…¶é€‚åˆè¾¹ç¼˜ç¯å¢ƒä¸­é¢‘ç¹æ³¢åŠ¨çš„ KV Cache å’Œç½‘ç»œå¸¦å®½ã€‚
3. **å—çº§å¸è½½ï¼ˆMHA/MLPï¼‰** æ¯”ä¼ ç»Ÿå±‚çº§å¸è½½æ›´é«˜æ•ˆï¼Œå‡å°‘äº†ä¸å¿…è¦çš„æ•°æ®æ¬ç§»ï¼Œæå‡äº†é‡å ç‡ã€‚
4. LIME åœ¨çœŸå®å¼‚æ„è¾¹ç¼˜å¹³å°ä¸ŠéªŒè¯æœ‰æ•ˆï¼Œç›¸æ¯” SOTA æ–¹æ³•æœ€é«˜å®ç° **3.7Ã— åŠ é€Ÿ**ï¼Œä¸”æ— ç²¾åº¦æŸå¤±ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ– SSD å­˜å‚¨æ€§èƒ½**ï¼šè‹¥å­˜å‚¨ä»‹è´¨è¯»å†™å»¶è¿Ÿè¿‡é«˜ï¼Œä¼šå½±å“å¸è½½æ•ˆç‡ã€‚
2. **åˆå§‹åŒ–å¼€é”€è¾ƒå¤§**ï¼šç¦»çº¿è°ƒåº¦è™½å¿«ï¼Œä½†ä»éœ€é¢„çŸ¥æ¨¡å‹ç»“æ„å’Œè®¾å¤‡ç‰¹æ€§ï¼Œä¸é€‚åˆé«˜åº¦åŠ¨æ€æ‹“æ‰‘ã€‚
3. **æœªæ”¯æŒè®­ç»ƒé˜¶æ®µ**ï¼šç›®å‰ä»…èšç„¦äºæ¨ç†åŠ é€Ÿï¼Œå°šæœªæ‰©å±•åˆ°å¾®è°ƒæˆ–æŒç»­å­¦ä¹ åœºæ™¯ã€‚
4. **è·¨è®¾å¤‡åŒæ­¥ä»å­˜åœ¨è½»å¾®é˜»å¡**ï¼šå°½ç®¡å·²ä¼˜åŒ–é‡å ï¼Œä½†åœ¨æŸäº›è¾¹ç•Œæƒ…å†µä¸‹ä»æœ‰å°èŒƒå›´ç­‰å¾…ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. æ‰©å±•è‡³ **multi-modal models** å’Œ **MoE æ¶æ„** çš„ååŒæ¨ç†ã€‚
2. å¼•å…¥ **é¢„æµ‹å¼è°ƒåº¦å™¨**ï¼Œç»“åˆå†å²è¯·æ±‚æ¨¡å¼é¢„æµ‹ KV å¢é•¿è¶‹åŠ¿ã€‚
3. æ¢ç´¢ **æ›´æ™ºèƒ½çš„ç¼“å­˜æ›¿æ¢ç­–ç•¥**ï¼Œæ›¿ä»£å›ºå®šé¡ºåºçš„ MHAâ†’MLP å¸è½½é€»è¾‘ã€‚
4. æ”¯æŒ **è”é‚¦å¼åä½œæ¨ç†**ï¼Œä¿æŠ¤ç”¨æˆ·éšç§çš„åŒæ—¶å…±äº«è¾¹ç¼˜ç®—åŠ›ã€‚

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> LIME é€šè¿‡åˆ›æ–°çš„ **interleaved pipeline + fine-grained offloading + online adaptation** ä¸‰é‡æœºåˆ¶ï¼Œé¦–æ¬¡å®ç°äº†åœ¨å†…å­˜ä¸¥é‡å—é™çš„å¼‚æ„è¾¹ç¼˜è®¾å¤‡ä¸Šå¯¹ç™¾äº¿çº§ LLM çš„**é«˜é€Ÿã€æ— æŸååŒæ¨ç†**ï¼Œä¸ºè¾¹ç¼˜ä¾§éƒ¨ç½²é«˜ç²¾åº¦å¤§æ¨¡å‹æä¾›äº†å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 3. [FUSCO: High-Performance Distributed Data Shuffling via Transformation-Communication Fusion](https://arxiv.org/abs/2512.22036)

**Authors**: Zhuoran Zhu, Chunyang Zhu, Hao Lin, Xu Fu, Yiming Zhou, Quanlu Zhang, Zhenhua Li, Feng Qian, Chao Yu, Boxun Li, Guohao Dai, Yu Wang  
**Category**: cs.DC  
**Published**: 2025-12-29  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2512.22036v1  

#### Abstract
Large-scale Mixture-of-Experts (MoE) models rely on \emph{expert parallelism} for efficient training and inference, which splits experts across devices and necessitates distributed data shuffling to route each token to its assigned experts. However, existing communication libraries handle this shuff...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# FUSCO: High-Performance Distributed Data Shuffling via Transformation-Communication Fusion è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å¤§å‹ **Mixture-of-Experts (MoE)** æ¨¡å‹åœ¨è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­ä¾èµ– **expert parallelism**ï¼Œå³å°†ä¸“å®¶ï¼ˆexpertsï¼‰åˆ†å¸ƒåœ¨å¤šä¸ªè®¾å¤‡ä¸Šã€‚è¿™å¯¼è‡´æ¯ä¸ªè¾“å…¥ token éœ€è¦è¢«è·¯ç”±åˆ°å…¶å¯¹åº”çš„ä¸“å®¶æ‰€åœ¨çš„è®¾å¤‡ï¼Œä»è€Œå¼•å‘å¤§è§„æ¨¡çš„ **åˆ†å¸ƒå¼æ•°æ® shufflingï¼ˆé‡æ’ï¼‰**ã€‚

ç„¶è€Œï¼Œç°æœ‰çš„é€šä¿¡åº“ï¼ˆå¦‚ NCCLã€DeepEPï¼‰å°†æ•°æ®å˜æ¢ï¼ˆtransformationï¼‰ä¸é€šä¿¡ï¼ˆcommunicationï¼‰åˆ†ç¦»å¤„ç†ï¼Œå¯¼è‡´ä»¥ä¸‹é—®é¢˜ï¼š
- æ•°æ®éœ€è¦åœ¨é€šä¿¡å‰è¿›è¡Œå¤æ‚çš„é¢„é‡æ’ï¼ˆpre-rearrangementï¼‰ï¼Œé€šä¿¡åå†åå‘æ¢å¤ï¼›
- å¤šæ¬¡å†…å­˜æ‹·è´å’Œç¼“å†²åŒºé‡ç»„æ˜¾è‘—å¢åŠ å»¶è¿Ÿï¼›
- é‡å¤çš„æ•°æ®åœ¨è·¨èŠ‚ç‚¹ä¼ è¾“ä¸­æœªå»é‡ï¼Œæµªè´¹å¸¦å®½ï¼›
- è´Ÿè½½ä¸å‡è¡¡å¯¼è‡´é€šä¿¡çƒ­ç‚¹ï¼ˆhotspotï¼‰ã€‚

è¿™äº›é—®é¢˜ä½¿å¾— **æ•°æ® shuffling å¼€é”€å ç«¯åˆ°ç«¯è¿è¡Œæ—¶é—´çš„ 22%â€“61%**ï¼Œæˆä¸º MoE æ€§èƒ½ç“¶é¢ˆã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

è®ºæ–‡æå‡º **FUSCO** â€”â€” ä¸€ç§é¢å‘ MoE çš„é«˜æ€§èƒ½é€šä¿¡åº“ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ **Transformation-Communication Fusionï¼ˆå˜æ¢-é€šä¿¡èåˆï¼‰**ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

1. **ç»Ÿä¸€çš„æ•°æ®æŠ½è±¡ï¼šSegment Descriptor**
   - å°†å¾…ä¼ è¾“çš„æ•°æ®ï¼ˆå¦‚ tokenï¼‰å»ºæ¨¡ä¸ºä¸€ç³»åˆ—é€»è¾‘ä¸Šçš„ **segmentsï¼ˆæ®µï¼‰**ï¼›
   - å¼•å…¥ **Segment Descriptor** æŠ½è±¡ï¼Œè®°å½•æ¯æ®µæ•°æ®çš„æºåœ°å€ã€ç›®æ ‡åœ°å€å’Œå¤§å°ï¼›
   - å…è®¸åœ¨é€šä¿¡è·¯å¾„ä¸­ç›´æ¥å®Œæˆéè¿ç»­å†…å­˜çš„æ•°æ® gather/scatterï¼Œæ— éœ€ä¸­é—´é‡æ’ã€‚

2. **Data-Fused Communication Engine (dComm)**
   - åŸºäºæè¿°ç¬¦é©±åŠ¨çš„é€šä¿¡å¼•æ“ï¼Œé‡‡ç”¨æµæ°´çº¿è®¾è®¡ï¼›
   - åœ¨ GPU åˆ° NIC çš„æ•°æ®æ¬è¿è¿‡ç¨‹ä¸­ï¼Œ**å†…è”æ‰§è¡Œæ•°æ®å¸ƒå±€è½¬æ¢**ï¼›
   - æ”¯æŒè·¨èŠ‚ç‚¹å’ŒèŠ‚ç‚¹å†…é€šä¿¡çš„é«˜æ•ˆèåˆæ“ä½œã€‚

3. **ä¸¤å±‚é€šä¿¡è§„åˆ’æœºåˆ¶ï¼ˆTwo-Level Communication Planï¼‰**
   - **Node-Level Forwarding Descriptors**ï¼šå®ç°è·¨èŠ‚ç‚¹ token å»é‡ï¼Œæ¯ä¸ªè¿œç¨‹èŠ‚ç‚¹ä»…æ¥æ”¶ä¸€ä»½å‰¯æœ¬ï¼›
   - **Expert-Level Distribution Descriptors**ï¼šåœ¨èŠ‚ç‚¹å†…éƒ¨å°† token åˆ†å‘åˆ°å…·ä½“ä¸“å®¶ï¼Œé¿å…äºŒæ¬¡é‡æ’ã€‚

4. **åœ¨çº¿è´Ÿè½½å‡è¡¡å™¨ï¼ˆOnline Load Balancerï¼‰**
   - åŠ¨æ€åˆ†æå„ GPU çš„è·¨èŠ‚ç‚¹æµé‡ï¼›
   - ä½¿ç”¨è½»é‡çº§è´ªå¿ƒç®—æ³•æ„å»ºé€šä¿¡ç»„ï¼ˆcommunication groupsï¼‰ï¼Œå¹³è¡¡è½¬å‘è´Ÿè½½ï¼Œé˜²æ­¢çƒ­ç‚¹ã€‚

5. **åŸºäº NCCL çš„å¯ç§»æ¤å®ç°**
   - æ„å»ºåœ¨ NCCL ä¹‹ä¸Šï¼Œå¤ç”¨å…¶åº•å±‚ç½‘ç»œæ ˆï¼Œä¿è¯é€šç”¨æ€§å’Œå…¼å®¹æ€§ï¼›
   - æä¾›å¯¹ä¸»æµ LLM æ¡†æ¶ï¼ˆå¦‚ Megatron-LMã€SGLangï¼‰çš„å³æ’å³ç”¨æ”¯æŒã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | FUSCO vs. NCCL / DeepEP |
|------|------------------------|
| **é€šä¿¡æ•ˆç‡** | æ¶ˆé™¤å†—ä½™æ•°æ®å¤åˆ¶å’Œé‡æ’ï¼Œå‡å°‘å†…å­˜å¸¦å®½æ¶ˆè€— |
| **å¸¦å®½åˆ©ç”¨** | è·¨èŠ‚ç‚¹é€šä¿¡å»é‡ï¼Œæ˜¾è‘—é™ä½é«˜å¸¦å®½é“¾è·¯å‹åŠ› |
| **è´Ÿè½½å‡è¡¡** | åŠ¨æ€è°ƒåº¦é¿å…é€šä¿¡çƒ­ç‚¹ï¼Œæå‡æ•´ä½“åå |
| **ç«¯åˆ°ç«¯æ€§èƒ½** | æ˜¾è‘—åŠ é€Ÿ MoE è®­ç»ƒä¸æ¨ç†ï¼Œå°¤å…¶åœ¨å¤§è§„æ¨¡éƒ¨ç½²ä¸‹ä¼˜åŠ¿æ›´æ˜æ˜¾ |
| **é€šç”¨æ€§** | ä¸ä¾èµ–ç‰¹å®šç¡¬ä»¶ç‰¹æ€§ï¼ˆå¦‚ IBGDAï¼‰ï¼Œå¯åœ¨å¤šç§é›†ç¾¤é…ç½®ä¸Šè¿è¡Œ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†ä¸åœºæ™¯**

- **çœŸå®ä¸–ç•Œæµé‡**ï¼šæ¥è‡ª DeepSeek-V3 æ¨ç†é˜¶æ®µçš„è·¯ç”±è¡Œä¸ºï¼Œä½¿ç”¨ ShareGPT æ•°æ®é›†ç”Ÿæˆï¼›
- **æ§åˆ¶å®éªŒç¯å¢ƒ**ï¼š
  - **Single-node routed traffic**ï¼šæ‰€æœ‰ token çš„ç›®æ ‡ä¸“å®¶ä½äºåŒä¸€èŠ‚ç‚¹ï¼Œæµ‹è¯•è·¨èŠ‚ç‚¹å»é‡èƒ½åŠ›ï¼›
  - **Load-imbalanced traffic**ï¼šäººä¸ºæ„é€  GPU é—´é€šä¿¡è´Ÿè½½ä¸¥é‡ä¸å‡çš„æƒ…å†µï¼ŒéªŒè¯è´Ÿè½½å‡è¡¡æœºåˆ¶æœ‰æ•ˆæ€§ã€‚

---

### **å®éªŒè®¾ç½®**

- **ç¡¬ä»¶å¹³å°**ï¼š8 èŠ‚ç‚¹é›†ç¾¤ï¼Œæ¯èŠ‚ç‚¹é…å¤‡ï¼š
  - 8 Ã— NVIDIA H100 GPUï¼ˆ80GB HBM3ï¼‰
  - NVLink äº’è”ï¼ˆ~480 GB/s èŠ‚ç‚¹å†…å¸¦å®½ï¼‰
  - 10 Ã— 400Gbps RoCE NICï¼ˆè·¨èŠ‚ç‚¹é€šä¿¡ï¼‰
- **è½¯ä»¶ç¯å¢ƒ**ï¼š
  - CUDA 12.9, PyTorch 2.7.0, NCCL 2.26.3
  - å®ç°åŸºäº NCCL æ‰©å±•ï¼Œé›†æˆè‡³ Megatron-LM å’Œ SGLang

---

### **è¯„ä¼°æŒ‡æ ‡**

| æŒ‡æ ‡ | æè¿° |
|------|------|
| **é€šä¿¡å»¶è¿Ÿ** | MoE å±‚ä¸­ all-to-all æ“ä½œçš„æ€»è€—æ—¶ï¼ˆåˆ†é˜¶æ®µç»Ÿè®¡ï¼‰ |
| **è®­ç»ƒè¿­ä»£æ—¶é—´** | å•æ¬¡è®­ç»ƒè¿­ä»£çš„ wall-clock æ—¶é—´ |
| **é¦– token å»¶è¿Ÿï¼ˆTTFTï¼‰** | æ¨ç†é¢„å¡«å……é˜¶æ®µä»è¾“å…¥åˆ°è¾“å‡ºç¬¬ä¸€ä¸ª token çš„æ—¶é—´ |
| **ååé‡ï¼ˆThroughputï¼‰** | æ¯ç§’å¤„ç†çš„ token æ•°é‡ |
| **æ¶ˆèå®éªŒæ€§èƒ½é€€åŒ–ç‡** | å…³é—­æŸæ¨¡å—åçš„æ€§èƒ½ä¸‹é™ç™¾åˆ†æ¯” |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| åŸºçº¿ | ç‰¹ç‚¹ |
|------|------|
| **NCCL** | é€šç”¨é›†ä½“é€šä¿¡åº“ï¼Œé»˜è®¤åç«¯ï¼Œæ—  MoE ä¼˜åŒ– |
| **DeepEP** | å½“å‰æœ€å…ˆè¿›çš„ MoE ä¸“ç”¨é€šä¿¡åº“ï¼ŒåŸºäº NVSHMEMï¼Œæ”¯æŒéƒ¨åˆ†å»é‡å’Œæµæ°´çº¿ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **é€šä¿¡åŸºå‡†æµ‹è¯•ç»“æœ**

| åœºæ™¯ | å¯¹æ¯”å¯¹è±¡ | åŠ é€Ÿæ¯”ï¼ˆSpeedupï¼‰ |
|------|---------|------------------|
| Real-world traffic | NCCL | **1.60Ã— â€“ 1.66Ã—** |
| | DeepEP | **1.13Ã— â€“ 1.34Ã—** |
| Single-node routed | NCCL | **3.47Ã— â€“ 3.84Ã—** |
| | DeepEP | **1.95Ã— â€“ 2.01Ã—** |
| Load-imbalanced | NCCL | **1.99Ã— â€“ 2.24Ã—** |
| | DeepEP | **1.29Ã— â€“ 1.42Ã—** |

> âœ… åœ¨å•èŠ‚ç‚¹è·¯ç”±åœºæ™¯ä¸‹ï¼ŒFUSCO è¡¨ç°å‡ºæœ€å¤§ä¼˜åŠ¿ï¼Œå› å…¶æœ‰æ•ˆå®ç°äº†è·¨èŠ‚ç‚¹ token å»é‡ã€‚

---

### **ç«¯åˆ°ç«¯æ€§èƒ½è¡¨ç°**

#### **è®­ç»ƒæ€§èƒ½ï¼ˆIteration Timeï¼‰**
- ä½¿ç”¨ Qwen3 å’Œ DeepSeek-V3 æ¨¡å‹ï¼Œåºåˆ—é•¿åº¦ 16kï¼ŒEP=64
- ç›¸æ¯” NCCLï¼š**1.17Ã— â€“ 1.39Ã— åŠ é€Ÿ**
- ç›¸æ¯” DeepEPï¼š**1.10Ã— â€“ 1.19Ã— åŠ é€Ÿ**

#### **æ¨ç†æ€§èƒ½ï¼ˆTime-to-First-Token, TTFTï¼‰**
- åŒæ ·é…ç½®ä¸‹ï¼š
- ç›¸æ¯” NCCLï¼š**1.09Ã— â€“ 1.25Ã— é™ä½å»¶è¿Ÿ**
- ç›¸æ¯” DeepEPï¼š**1.06Ã— â€“ 1.16Ã— é™ä½å»¶è¿Ÿ**

> ğŸ” æ€§èƒ½å¢ç›Šéšæ¨¡å‹è§„æ¨¡å¢å¤§è€Œå¢å¼ºï¼Œè¡¨æ˜ FUSCO æ›´é€‚åˆè¶…å¤§è§„æ¨¡ MoE éƒ¨ç½²ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**

å…³é—­ä¸åŒç»„ä»¶åçš„æ€§èƒ½é€€åŒ–ï¼ˆä»¥å»¶è¿Ÿå¢åŠ ç™¾åˆ†æ¯”è¡¨ç¤ºï¼‰ï¼š

| åœºæ™¯ | dComm å…³é—­ | Planner å…³é—­ | Balancer å…³é—­ |
|------|------------|--------------|---------------|
| Real-world | -27.3% | -30.2% | -8.7% |
| Single-node routed | -33.3% | **-67.3%** | -3.2% |
| Imbalanced traffic | -31.2% | -27.1% | **-16.6%** |

#### å…³é”®å‘ç°ï¼š
- **dComm æ˜¯æ ¸å¿ƒ**ï¼šå¹³å‡å¸¦æ¥ ~30% æ€§èƒ½æå‡ï¼Œæ¶ˆé™¤é‡æ’å¼€é”€ï¼›
- **Planner è‡³å…³é‡è¦**ï¼šåœ¨å•èŠ‚ç‚¹è·¯ç”±åœºæ™¯ä¸‹è´¡çŒ®é«˜è¾¾ 67.3%ï¼Œä½“ç°å»é‡ä»·å€¼ï¼›
- **Balancer åœ¨è´Ÿè½½ä¸å‡æ—¶ä½œç”¨æ˜¾è‘—**ï¼šæœ€é«˜å¸¦æ¥ 16.6% æ”¹å–„ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **MoE ä¸­çš„æ•°æ® shuffling ä¸åº”è§†ä¸ºâ€œçº¯é€šä¿¡â€ä»»åŠ¡**ï¼Œè€Œæ˜¯ **æ•°æ®å˜æ¢ä¸é€šä¿¡çš„è”åˆä¼˜åŒ–é—®é¢˜**ã€‚
2. **ä¼ ç»Ÿ disaggregated è®¾è®¡ï¼ˆå…ˆé‡æ’å†é€šä¿¡ï¼‰é€ æˆå¤§é‡å†—ä½™å†…å­˜æ“ä½œ**ï¼Œä¸¥é‡æ‹–ç´¯æ€§èƒ½ã€‚
3. **é€šè¿‡èåˆ transformation ä¸ communicationï¼ŒFUSCO æˆåŠŸå°†é‡æ’æ“ä½œâ€œåµŒå…¥â€é€šä¿¡è·¯å¾„**ï¼Œå®ç°é›¶é¢å¤–æ‹·è´ã€‚
4. **å±‚çº§åŒ–è·¯ç”± + åŠ¨æ€è´Ÿè½½å‡è¡¡** å¯æœ‰æ•ˆç¼“è§£è·¨èŠ‚ç‚¹å¸¦å®½ç“¶é¢ˆå’Œé€šä¿¡çƒ­ç‚¹é—®é¢˜ã€‚
5. **FUSCO åœ¨çœŸå®å’Œæç«¯åœºæ™¯ä¸‹å‡è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿**ï¼Œå°¤å…¶åœ¨é«˜ expert parallelism ä¸‹æ›´å…·ç«äº‰åŠ›ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **é¢„å¤„ç†å¼€é”€å›ºå®š**ï¼šFUSCO å¼•å…¥å°‘é‡å…ƒæ•°æ®ç”Ÿæˆå¼€é”€ï¼Œåœ¨å° batch æˆ–çŸ­åºåˆ—åœºæ™¯ä¸‹ç›¸å¯¹å½±å“è¾ƒå¤§ï¼›
2. **å½“å‰è´Ÿè½½å‡è¡¡ä»…è€ƒè™‘å‘é€ç«¯**ï¼šæœªå®Œå…¨ä¼˜åŒ–æ¥æ”¶ç«¯è´Ÿè½½ï¼Œä»æœ‰æ”¹è¿›ç©ºé—´ï¼›
3. **ä¾èµ–ç²¾ç¡®çš„è·¯ç”±çŸ©é˜µè¾“å…¥**ï¼šè‹¥è·¯ç”±åŠ¨æ€å˜åŒ–é¢‘ç¹ï¼Œéœ€é‡æ–°ç”Ÿæˆ descriptorï¼Œå¯èƒ½å¼•å…¥è°ƒåº¦å»¶è¿Ÿï¼›
4. **å°šæœªæ”¯æŒå‹ç¼©æˆ–é‡åŒ–ç­‰è¿›ä¸€æ­¥ä¼˜åŒ–æ‰‹æ®µ**ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ‰©å±•è‡³å…¶ä»–ç»“æ„åŒ–æ•°æ®é€šä¿¡åœºæ™¯**ï¼šå¦‚ Vision Transformers ä¸­çš„ patch shufflingï¼›
2. **æ”¯æŒåŠ¨æ€è·¯ç”±ä¸‹çš„å¢é‡ descriptor æ›´æ–°æœºåˆ¶**ï¼›
3. **ç»“åˆ computation-communication overlap è¿›ä¸€æ­¥éšè—é€šä¿¡å»¶è¿Ÿ**ï¼›
4. **æ¢ç´¢æ›´ç²¾ç»†çš„ descriptor å‹ç¼©ä¸ç¼“å­˜ç­–ç•¥**ï¼Œé™ä½å…ƒæ•°æ®å¼€é”€ï¼›
5. **é›†æˆè¿›æ›´å¤šä¸»æµæ¡†æ¶ï¼ˆå¦‚ DeepSpeedã€ColossalAIï¼‰å¹¶å¼€æºå‘å¸ƒä»£ç ä¸å·¥å…·é“¾**ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> FUSCO é€šè¿‡ **transformation-communication fusion** çš„è®¾è®¡ç†å¿µï¼Œä»æ ¹æœ¬ä¸Šé‡æ„äº† MoE ä¸­çš„æ•°æ® shuffling æµç¨‹ï¼Œå®ç°äº†é€šä¿¡æ•ˆç‡çš„æ˜¾è‘—çªç ´ï¼Œåœ¨è®­ç»ƒå’Œæ¨ç†ä¸­å‡å–å¾—ä¼˜äº NCCL å’Œ DeepEP çš„æ€§èƒ½è¡¨ç°ï¼Œä¸ºå¤§è§„æ¨¡ MoE ç³»ç»Ÿæä¾›äº†é«˜æ•ˆã€å¯æ‰©å±•ä¸”é€šç”¨çš„é€šä¿¡è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 4. [MAD-NG: Meta-Auto-Decoder Neural Galerkin Method for Solving Parametric Partial Differential Equations](https://arxiv.org/abs/2512.21633)

**Authors**: Qiuqi Li, Yiting Liu, Jin Zhao, Wencan Zhu  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.21633v1  

#### Abstract
Parametric partial differential equations (PDEs) are fundamental for modeling a wide range of physical and engineering systems influenced by uncertain or varying parameters. Traditional neural network-based solvers, such as Physics-Informed Neural Networks (PINNs) and Deep Galerkin Methods, often fa...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMAD-NG: Meta-Auto-Decoder Neural Galerkin Method for Solving Parametric Partial Differential Equations

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»ŸåŸºäºç¥ç»ç½‘ç»œçš„ PDE æ±‚è§£å™¨ï¼ˆå¦‚ PINNsã€Deep Galerkin Methodsï¼‰åœ¨æ±‚è§£**å‚æ•°åŒ–åå¾®åˆ†æ–¹ç¨‹**ï¼ˆparametric PDEsï¼‰æ—¶é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **æ³›åŒ–èƒ½åŠ›å·®**ï¼šå¯¹æ–°çš„å‚æ•°é…ç½®éœ€è¦é‡æ–°è®­ç»ƒï¼Œè®¡ç®—æˆæœ¬é«˜ï¼›
- **é•¿æ—¶é—´é¢„æµ‹ä¸ç¨³å®š**ï¼šå…¨å±€æ—¶ç©ºé€¼è¿‘å®¹æ˜“ç ´åæ—¶é—´å› æœæ€§ï¼ˆtemporal causalityï¼‰ï¼Œå¯¼è‡´è¯¯å·®ç´¯ç§¯ï¼›
- **è®¡ç®—å¼€é”€å¤§**ï¼šå…¨å‚æ•°æ›´æ–°ç­–ç•¥åœ¨é«˜ç»´æˆ–é•¿æ—¶åŸŸé—®é¢˜ä¸­æ•ˆç‡ä½ä¸‹ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§æ–°å‹æ¡†æ¶â€”â€”**Meta-Auto-Decoder Neural Galerkin Method (MAD-NGM)**ï¼Œå¹¶è¿›ä¸€æ­¥å‘å±•ä¸ºç¨€ç–ç‰ˆæœ¬ **MAD-RSNGS**ï¼ˆMeta-Auto-Decoder Randomized Sparse Neural Galerkin Schemesï¼‰ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰ä¸¤é˜¶æ®µæ±‚è§£æ¡†æ¶ï¼šMAD-NGM
- **ç¬¬ä¸€é˜¶æ®µï¼šåˆå§‹è¿‘ä¼¼ï¼ˆInitial Approximationï¼‰**
  - åˆ©ç”¨ **Meta-Auto-Decoder (MAD)** æ„å»ºä¸€ä¸ªéçº¿æ€§è¯•å‡½æ•°æµå½¢ï¼ˆnonlinear trial manifoldï¼‰ï¼Œé€šè¿‡é¢„è®­ç»ƒå­¦ä¹ å¤šä¸ªæ ·æœ¬çš„éšç©ºé—´è¡¨ç¤ºï¼›
  - å¯¹äºæ–°å‚æ•°é…ç½®ï¼Œä»…éœ€å¾®è°ƒï¼ˆfine-tuneï¼‰éšå˜é‡ $ z $ å³å¯å¿«é€Ÿè·å¾—åˆå§‹ç½‘ç»œå‚æ•°ï¼Œæ— éœ€ä»å¤´è®­ç»ƒã€‚
- **ç¬¬äºŒé˜¶æ®µï¼šæ—¶é—´æ¼”åŒ–ï¼ˆTime Evolutionï¼‰**
  - åŸºäº **Neural Galerkin Method (NGM)** è¿›è¡Œæ—¶é—´æ¨è¿›ï¼Œåˆ©ç”¨ Dirac-Frenkel å˜åˆ†åŸç†æ„å»º ODE ç³»ç»Ÿæ¥æ›´æ–°ç½‘ç»œå‚æ•°ï¼›
  - å®ç°äº†**æ—¶ç©ºè§£è€¦**ï¼ˆspace-time decouplingï¼‰ï¼Œä¿è¯äº†ç‰©ç†ä¸€è‡´æ€§ä¸é•¿æœŸç¨³å®šæ€§ã€‚

#### ï¼ˆ2ï¼‰éšæœºç¨€ç–æ›´æ–°ç­–ç•¥ï¼šMAD-RSNGS
- åœ¨æ¯ä¸ªæ—¶é—´æ­¥ï¼Œåªéšæœºé€‰æ‹©ä¸€éƒ¨åˆ†ç½‘ç»œå‚æ•°è¿›è¡Œæ›´æ–°ï¼ˆsparse updateï¼‰ï¼Œå…¶ä½™ä¿æŒä¸å˜ï¼›
- æ˜¾è‘—é™ä½æ¯æ­¥è®¡ç®—å¤æ‚åº¦ï¼ŒåŒæ—¶é¿å…è¿‡æ‹Ÿåˆï¼Œæå‡æ•´ä½“æ•ˆç‡ã€‚

#### ï¼ˆ3ï¼‰è¾¹ç•Œæ¡ä»¶å¤„ç†æœºåˆ¶
- å¼•å…¥ **positional embedding** å±‚ï¼ˆå¦‚ `[sin(x), cos(x), z]`ï¼‰æ˜¾å¼ç¼–ç å‘¨æœŸæ€§è¾¹ç•Œæ¡ä»¶ï¼Œä½¿æ¨¡å‹è‡ªç„¶æ»¡è¶³ BCã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹æ³• | ç¼ºé™· | MAD-NGM/MAD-RSNGS çš„ä¼˜åŠ¿ |
|------|------|---------------------------|
| **PINNs / MAD-PINN** | å…¨å±€æ—¶ç©ºè®­ç»ƒï¼Œå¿½ç•¥æ—¶é—´å› æœæ€§ï¼Œè¯¯å·®éšæ—¶é—´ç§¯ç´¯ï¼›éœ€å¯†é›†é‡‡æ ·æ•´ä¸ªæ—¶ç©ºåŸŸ | æ—¶é—´é€’è¿›å¼æ›´æ–°ï¼Œä¿ç•™å› æœç»“æ„ï¼›ä»…ä¾èµ–å½“å‰çŠ¶æ€æ¨è¿›ï¼Œé€‚åˆé•¿æ—¶é¢„æµ‹ |
| **ä¼ ç»Ÿ NGM** | æ¯ä¸ªæ–°å‚æ•°éœ€é‡æ–°è®­ç»ƒåˆå§‹å‚æ•°ï¼Œæ— æ³•æ³›åŒ– | MAD é¢„è®­ç»ƒåå¯é€šè¿‡å¾®è°ƒå¿«é€Ÿé€‚åº”æ–°å‚æ•°ï¼Œæ˜¾è‘—å‡å°‘é‡å¤è®­ç»ƒå¼€é”€ |
| **Operator Learning (e.g., FNO, DeepONet)** | è™½èƒ½æ³›åŒ–ï¼Œä½†é€šå¸¸ç”¨äºé™æ€æ˜ å°„ï¼Œéš¾ä»¥å¤„ç†åŠ¨æ€æ¼”åŒ–è¿‡ç¨‹ | ç»“åˆ meta-learning ä¸æ—¶é—´ç§¯åˆ†ï¼Œå…¼å…·å¼ºæ³›åŒ–èƒ½åŠ›å’ŒåŠ¨æ€å»ºæ¨¡èƒ½åŠ› |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“**ï¼š
> - **é«˜æ•ˆæ³›åŒ–**ï¼šé€šè¿‡ MAD å®ç° zero-/few-shot å‚æ•°é€‚åº”ï¼›
> - **ç‰©ç†ä¸€è‡´**ï¼šåŸºäºå˜åˆ†åŸç†çš„æ—¶é—´æ¨è¿›ä¿éšœé•¿æœŸç¨³å®šæ€§ï¼›
> - **è®¡ç®—é«˜æ•ˆ**ï¼šç¨€ç–æ›´æ–°å¤§å¹…é™ä½æ—¶é—´æ¼”åŒ–é˜¶æ®µçš„è®¡ç®—è´Ÿæ‹…ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†ä¸æµ‹è¯•é—®é¢˜
è®ºæ–‡åœ¨å››ä¸ªå…¸å‹å‚æ•°åŒ– PDE ä¸Šè¿›è¡Œäº†éªŒè¯ï¼š

1. **Korteweg-de Vries (KdV) æ–¹ç¨‹**  
   - ä¸€ç»´éçº¿æ€§è‰²æ•£æ³¢æ–¹ç¨‹ï¼Œå«éšæœºåˆå€¼ $ u(x,0) = \alpha_1 \sin x + \alpha_2 \cos x $
   - å‚æ•°èŒƒå›´ï¼š$ \alpha_1, \alpha_2 \in [-0.5, 0.5] $

2. **Burgers æ–¹ç¨‹**  
   - å«æ¿€æ³¢å½¢æˆçš„éçº¿æ€§å¯¹æµæ‰©æ•£æ–¹ç¨‹ï¼Œåˆå€¼ä¸ºé«˜æ–¯éšæœºåœºï¼›
   - æµ‹è¯•æ¨¡å‹æ•æ‰å¼ºæ¢¯åº¦åŒºåŸŸçš„èƒ½åŠ›ã€‚

3. **Allen-Cahn (AC) æ–¹ç¨‹ï¼ˆä¸€ç»´ï¼‰**  
   - ç›¸åœºæ¨¡å‹ï¼Œæè¿°ç›¸åˆ†ç¦»è¿‡ç¨‹ï¼›
   - æ‰©å±•è‡³**éšæœºè®¡ç®—åŸŸ** $ \Omega = [-\delta, 1+\delta], \delta \in [-0.2, 0.2] $ï¼ŒéªŒè¯å‡ ä½•ä¸ç¡®å®šæ€§ä¸‹çš„é²æ£’æ€§ã€‚

4. **Allen-Cahn æ–¹ç¨‹ï¼ˆäºŒç»´ï¼‰**  
   - é«˜ç»´æ‰©å±•ï¼Œæµ‹è¯•æ–¹æ³•åœ¨ $ [0,1]^2 $ ä¸Šçš„è¡¨ç°ï¼›
   - åˆå€¼ä¸ºå¸¦éšæœºç³»æ•°çš„ä¸‰è§’å‡½æ•°ç»„åˆã€‚

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### è¯„ä¼°æŒ‡æ ‡
- **Mean Squared Error (MSE)**ï¼š
  $$
  \text{MSE} = \frac{1}{N_{\text{test}}} \sum_{j=1}^{N_{\text{test}}} \frac{1}{N} \sum_{i=1}^{N} (\hat{u}_j - u_j^{\text{true}})^2
  $$
  å…¶ä¸­ $ N_{\text{test}} $ ä¸ºæµ‹è¯•æ ·æœ¬æ•°ï¼Œ$ N $ ä¸ºç©ºé—´ç½‘æ ¼ç‚¹æ•°ã€‚

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **MAD-PINN**ï¼šåŸºäºç‰©ç†ä¿¡æ¯çš„ç«¯åˆ°ç«¯è®­ç»ƒæ–¹æ³•ï¼›
- **MAD-NGM**ï¼šæœ¬æ–‡æå‡ºçš„å®Œæ•´æ›´æ–°ç‰ˆæœ¬ï¼›
- **MAD-RSNGS**ï¼šæœ¬æ–‡æå‡ºçš„ç¨€ç–æ›´æ–°å˜ä½“ï¼Œä¸åŒ $ s $ è¡¨ç¤ºæ¯æ¬¡æ›´æ–°çš„å‚æ•°æ•°é‡ã€‚

#### ç½‘ç»œæ¶æ„ä¸ä¼˜åŒ–
- ç½‘ç»œç»“æ„ï¼š1â€“8 å±‚å…¨è¿æ¥ç½‘ç»œï¼Œæ¿€æ´»å‡½æ•°ä¸º `tanh`ï¼›
- éšå˜é‡ç»´åº¦ï¼š5â€“80 ä¸ç­‰ï¼›
- ä¼˜åŒ–å™¨ï¼š
  - é¢„è®­ç»ƒé˜¶æ®µï¼šL-BFGSï¼ˆ1kâ€“100k æ­¥ï¼‰
  - å¾®è°ƒé˜¶æ®µï¼šAdam æˆ– L-BFGS
- æ—¶é—´ç¦»æ•£ï¼šForward Euler æˆ– RK4ï¼›
- å‚è€ƒè§£ï¼šChebfunï¼ˆè°±æ–¹æ³•ï¼‰ã€Fourier spectral + RK4ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### âœ… KdV æ–¹ç¨‹ï¼ˆè¡¨1ï¼‰
| æ•°æ®é›† | ç»†è°ƒè¿­ä»£æ¬¡æ•° | MSE @ t=1.0 |
|--------|---------------|-------------|
| è®­ç»ƒé›† | 4000          | $ 3.69 \times 10^{-5} $ |
| æµ‹è¯•é›† | 4000          | $ 9.02 \times 10^{-6} $ |

> âœ”ï¸ æ–°æ ·æœ¬ç»å°‘é‡å¾®è°ƒå³å¯è¾¾åˆ°ä¸è®­ç»ƒé›†ç›¸å½“ç²¾åº¦ï¼Œæ˜¾ç¤ºè‰¯å¥½æ³›åŒ–èƒ½åŠ›ã€‚

---

#### âœ… Burgers æ–¹ç¨‹ï¼ˆè¡¨2 & å›¾9ï¼‰

| æ–¹æ³• | MSE @ t=1.0 |
|------|--------------|
| MAD-NGM | $ 4.11 \times 10^{-6} $ |
| MAD-RSNGS ($ s=3000 $) | $ 1.21 \times 10^{-5} $ |
| MAD-PINN | $ 5.89 \times 10^{-4} $ |

> ğŸ”º MAD-PINN çš„è¯¯å·®æ¯” MAD-NGM **é«˜å‡ºä¸¤ä¸ªæ•°é‡çº§**ï¼ˆ~100å€ï¼‰ï¼Œä¸”éšæ—¶é—´ä¸¥é‡ç´¯ç§¯ï¼ˆè§å›¾9ï¼‰ã€‚

#### æ—¶é—´æˆæœ¬å¯¹æ¯”ï¼ˆè¡¨3ï¼‰
| æ–¹æ³• | é¢„è®­ç»ƒ(min) | å¾®è°ƒ(min) | æ—¶é—´æ¼”åŒ–(min) |
|------|-------------|-----------|----------------|
| MAD-NGM | 44.16 | 7.21 | 46.47 |
| MAD-RSNGS ($ s=600 $) | 44.16 | 7.21 | **3.50** |
| MAD-PINN | **141.32** | 4.03 | â€” |

> â±ï¸ MAD-RSNGS å°†æ—¶é—´æ¼”åŒ–è€—æ—¶ä» **46.47 åˆ†é’Ÿé™è‡³ 3.5 åˆ†é’Ÿ**ï¼Œæé€Ÿçº¦ **13 å€**ï¼

---

#### âœ… Allen-Cahn æ–¹ç¨‹ï¼ˆä¸€ç»´ & äºŒç»´ï¼‰

- **ä¸€ç»´ ACï¼ˆè¡¨4ï¼‰**ï¼š
  | å‚æ•°ç±»å‹ | MSE @ t=2.0 |
  |---------|-------------|
  | æ—¶é—´æ— å…³ | $ 7.35 \times 10^{-5} $ |
  | æ—¶é—´ç›¸å…³ | $ 6.78 \times 10^{-5} $ |
  > âœ”ï¸ å³ä½¿å‚æ•°éšæ—¶é—´å’Œç©ºé—´å˜åŒ–ï¼Œä»èƒ½ä¿æŒé«˜ç²¾åº¦ã€‚

- **äºŒç»´ ACï¼ˆå›¾15ï¼‰**ï¼š
  - åœ¨ $ t=2.0 $ æ—¶ MSE â‰ˆ **0.0026**ï¼›
  - æˆåŠŸæ•æ‰ç›¸ç•Œé¢å½¢æˆä¸æ¼”åŒ–è¿‡ç¨‹ï¼ˆå›¾14ï¼‰ï¼›
  - è¯æ˜æ–¹æ³•å¯æ‰©å±•è‡³é«˜ç»´ç©ºé—´ã€‚

---

### æ¶ˆèå®éªŒåˆ†æï¼ˆImplicitï¼‰
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºâ€œablation studyâ€ç« èŠ‚ï¼Œä½†ä»å¤šç»„å®éªŒè®¾è®¡ä¸­å¯å¾—å‡ºä»¥ä¸‹æ¶ˆèç»“è®ºï¼š

| æ”¹è¿›æ¨¡å— | æ•ˆæœ |
|--------|------|
| **MAD é¢„è®­ç»ƒ + å¾®è°ƒ** | ç›¸æ¯”ä»å¤´è®­ç»ƒï¼ŒèŠ‚çœ >90% åˆå§‹åŒ–æ—¶é—´ï¼Œå®ç°å¿«é€Ÿæ³›åŒ– |
| **Neural Galerkin æ—¶é—´æ¨è¿›** | ç›¸æ¯” PINN å…¨å±€è®­ç»ƒï¼Œæ˜¾è‘—æ”¹å–„é•¿æœŸé¢„æµ‹ç¨³å®šæ€§ |
| **Randomized Sparse Update** | åœ¨å‡ ä¹ä¸æŸå¤±ç²¾åº¦çš„å‰æä¸‹ï¼Œå°†æ—¶é—´æ¼”åŒ–æˆæœ¬é™ä½ä¸€ä¸ªæ•°é‡çº§ä»¥ä¸Š |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **MAD-NGM å®ç°äº†å‚æ•°åŒ– PDE çš„é«˜æ•ˆæ³›åŒ–æ±‚è§£**ï¼š
   - é€šè¿‡ meta-learning å­¦ä¹ åˆå§‹æ¡ä»¶åˆ†å¸ƒï¼Œåœ¨æ–°å‚æ•°ä¸‹åªéœ€å¾®è°ƒéšå˜é‡å³å¯å¯åŠ¨ï¼›
   - å¤§å¹…å‡å°‘é‡å¤è®­ç»ƒå¼€é”€ï¼Œé€‚ç”¨äºå®æ—¶å†³ç­–åœºæ™¯ã€‚

2. **æ—¶é—´é€’è¿›å¼å»ºæ¨¡ä¼˜äºå…¨å±€ PINN æ¡†æ¶**ï¼š
   - MAD-NGM/MAD-RSNGS ä¿æŒäº†æ—¶é—´å› æœæ€§ï¼Œè¯¯å·®å¢é•¿ç¼“æ…¢ï¼›
   - è€Œ MAD-PINN å› å¿½ç•¥æ—¶é—´ç»“æ„ï¼Œå‡ºç°æ˜æ˜¾è¯¯å·®ç´¯ç§¯ã€‚

3. **ç¨€ç–æ›´æ–°ç­–ç•¥æœ‰æ•ˆå¹³è¡¡ç²¾åº¦ä¸æ•ˆç‡**ï¼š
   - MAD-RSNGS åœ¨ä»…æ›´æ–°éƒ¨åˆ†å‚æ•°çš„æƒ…å†µä¸‹ï¼Œä»èƒ½è¾¾åˆ°æ¥è¿‘ MAD-NGM çš„ç²¾åº¦ï¼›
   - ç‰¹åˆ«é€‚åˆå¤§è§„æ¨¡ã€é•¿æ—¶é—´æ¨¡æ‹Ÿä»»åŠ¡ã€‚

4. **æ–¹æ³•å…·æœ‰è‰¯å¥½çš„å‡ ä½•ä¸ç»´åº¦æ‰©å±•æ€§**ï¼š
   - æˆåŠŸåº”ç”¨äºéšæœºåŸŸå’ŒäºŒç»´é—®é¢˜ï¼Œè¡¨æ˜å…¶å¯ç”¨äºå¤æ‚å·¥ç¨‹ç³»ç»Ÿå»ºæ¨¡ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **å¯¹ç½‘ç»œç»“æ„æ•æ„Ÿ**ï¼šå®éªŒè¡¨æ˜æ€§èƒ½å—å±‚æ•°ã€å®½åº¦ã€éšç»´å½±å“è¾ƒå¤§ï¼›
- **ç¨€ç–æ›´æ–°æ¯”ä¾‹éœ€è°ƒå‚**ï¼š$ s $ çš„é€‰æ‹©å½±å“æ”¶æ•›é€Ÿåº¦ä¸æœ€ç»ˆç²¾åº¦ï¼›
- **å°šæœªå®Œå…¨å…è®­ç»ƒ**ï¼šè™½å‡å°‘é‡è®­ï¼Œä½†ä»éœ€ä¸€å®šå¾®è°ƒæ­¥éª¤ï¼›
- **ç†è®ºåˆ†ææœ‰é™**ï¼šç¼ºä¹å…³äºè¯¯å·®ä¼ æ’­ã€æ”¶æ•›æ€§çš„ä¸¥æ ¼æ•°å­¦è¯æ˜ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **è‡ªé€‚åº”ç½‘ç»œè®¾è®¡**ï¼šå¼€å‘å¯æ ¹æ®é—®é¢˜è‡ªåŠ¨è°ƒæ•´ç»“æ„çš„æ–¹æ³•ï¼›
2. **å¤šå±‚çº§ä¼˜åŒ–ç­–ç•¥**ï¼šç»“åˆ coarse/fine æ—¶é—´å°ºåº¦è¿›è¡Œæ›´é«˜æ•ˆçš„å‚æ•°æ›´æ–°ï¼›
3. **æ‰©å±•è‡³é€†é—®é¢˜ä¸æ§åˆ¶é—®é¢˜**ï¼šå°†æ¡†æ¶ç”¨äºå‚æ•°è¯†åˆ«ã€æœ€ä¼˜æ§åˆ¶ç­‰ä»»åŠ¡ï¼›
4. **ç¡¬ä»¶åŠ é€Ÿé›†æˆ**ï¼šæ¢ç´¢åœ¨ GPU/TPU ä¸Šçš„å¤§è§„æ¨¡å¹¶è¡Œå®ç°ï¼›
5. **ä¸å…¶ä»–é™ç»´æ–¹æ³•èåˆ**ï¼šå¦‚ä¸ Proper Orthogonal Decomposition (POD) æˆ– Dynamic Mode Decomposition (DMD) ç»“åˆã€‚

---

## æ€»ç»“

âœ… **MAD-NGM æ˜¯ä¸€ç§é¢å‘å‚æ•°åŒ–æ¼”åŒ– PDE çš„é«˜æ•ˆã€ç¨³å®šã€å¯æ³›åŒ–çš„æ·±åº¦å­¦ä¹ æ±‚è§£æ¡†æ¶**ã€‚å®ƒé€šè¿‡ **meta-learning + Neural Galerkin + randomized sparse update** ä¸‰è€…ç»“åˆï¼Œè§£å†³äº†ä¼ ç»Ÿ PINN ç±»æ–¹æ³•åœ¨é•¿æ—¶é¢„æµ‹ã€æ³›åŒ–èƒ½åŠ›å’Œè®¡ç®—æ•ˆç‡ä¸Šçš„ç“¶é¢ˆï¼Œåœ¨å¤šä¸ªæ ‡å‡†åŸºå‡†ä¸Šå±•ç°å‡ºä¼˜è¶Šæ€§èƒ½ï¼Œå°¤å…¶é€‚åˆéœ€è¦å¿«é€Ÿå“åº”æ–°å‚æ•°é…ç½®çš„ç§‘å­¦è®¡ç®—ä¸å·¥ç¨‹ä»¿çœŸåœºæ™¯ã€‚

</details>

---

### 5. [TimeBill: Time-Budgeted Inference for Large Language Models](https://arxiv.org/abs/2512.21859)

**Authors**: Qi Fan, An Zou, Yehan Ma  
**Category**: cs.CL  
**Published**: 2025-12-29  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.21859v1  

#### Abstract
Large Language Models (LLMs) are increasingly deployed in time-critical systems, such as robotics, autonomous driving, embodied intelligence, and industrial automation, where generating accurate responses within a given time budget is crucial for decision-making, control, or safety-critical tasks. H...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šTimeBill: Time-Budgeted Inference for Large Language Models**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ã€å…·èº«æ™ºèƒ½å’Œå·¥ä¸šè‡ªåŠ¨åŒ–ç­‰**æ—¶é—´æ•æ„Ÿç³»ç»Ÿ**ä¸­åº”ç”¨æ—¥ç›Šå¹¿æ³›ã€‚ç„¶è€Œï¼Œç”±äºå…¶è‡ªå›å½’ç”Ÿæˆæœºåˆ¶ï¼ŒLLM çš„ç«¯åˆ°ç«¯æ‰§è¡Œæ—¶é—´å…·æœ‰é«˜åº¦ä¸ç¡®å®šæ€§ï¼Œéš¾ä»¥æ»¡è¶³ç¡¬å®æ—¶ç³»ç»Ÿçš„**æ—¶é—´é¢„ç®—çº¦æŸ**ï¼ˆtime budgetï¼‰ã€‚ç°æœ‰é«˜æ•ˆæ¨ç†æ–¹æ³•ï¼ˆå¦‚å›ºå®šæ¯”ä¾‹çš„ KV Cache è’¸é¦ï¼‰ç¼ºä¹å¯¹åŠ¨æ€ä»»åŠ¡å’Œä¸åŒæ—¶é—´é¢„ç®—çš„é€‚åº”èƒ½åŠ›ï¼Œå®¹æ˜“å¯¼è‡´**è¶…æ—¶å¤±è´¥**æˆ–**å“åº”è´¨é‡ä¸‹é™**ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯**
æœ¬æ–‡æå‡ºäº† **TimeBill** â€”â€” ä¸€ç§é¢å‘ LLM çš„**æ—¶é—´é¢„ç®—åŒ–æ¨ç†æ¡†æ¶**ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡**é¢„æµ‹é©±åŠ¨çš„åŠ¨æ€è°ƒæ§**æ¥å¹³è¡¡æ¨ç†æ•ˆç‡ä¸å“åº”æ€§èƒ½ã€‚å…¶ä¸»è¦åˆ›æ–°åŒ…æ‹¬ï¼š

1. **ç»†ç²’åº¦å“åº”é•¿åº¦é¢„æµ‹å™¨ï¼ˆFine-grained Response Length Predictor, RLPï¼‰**  
   - å°†å“åº”é•¿åº¦é¢„æµ‹å»ºæ¨¡ä¸ºåˆ†ç±»ä»»åŠ¡ï¼ŒåŸºäº Small Language Modelï¼ˆSLMï¼‰æ„å»ºé¢„æµ‹å™¨ï¼Œé¿å… BERT ç±»æ¨¡å‹å¯¹é•¿è¾“å…¥æ”¯æŒå·®çš„é—®é¢˜ã€‚
   - åˆ©ç”¨çŸ¥è¯†è’¸é¦ç­–ç•¥ä½¿å…¶ä¸ç›®æ ‡ LLM å¯¹é½ï¼Œæå‡é¢„æµ‹å‡†ç¡®æ€§ã€‚

2. **å·¥ä½œè´Ÿè½½å¼•å¯¼çš„æ‰§è¡Œæ—¶é—´ä¼°è®¡å™¨ï¼ˆWorkload-guided Execution Time Estimator, ETEï¼‰**  
   - ç»“åˆ **FLOPs åˆ†æå»ºæ¨¡** ä¸ **å®é™…æ€§èƒ½å‰–æï¼ˆprofilingï¼‰**ï¼Œå®ç°å¯¹é¢„å¡«å……é˜¶æ®µï¼ˆprefill phaseï¼‰å’Œè§£ç é˜¶æ®µï¼ˆdecoding phaseï¼‰çš„ç²¾ç¡®æ‰§è¡Œæ—¶é—´ä¼°è®¡ã€‚
   - å¼•å…¥æ‚²è§‚å› å­ $k$ æ¥ä¼°è®¡æœ€åæƒ…å†µæ‰§è¡Œæ—¶é—´ï¼ˆWCETï¼‰ï¼Œä¿éšœå®æ—¶æ€§ã€‚

3. **æ—¶é—´é¢„ç®—æ„ŸçŸ¥çš„é«˜æ•ˆæ¨ç†æœºåˆ¶ï¼ˆTime-Budgeted Inferenceï¼‰**  
   - åŠ¨æ€è°ƒæ•´ KV Cache çš„é©±é€æ¯”ä¾‹ $\alpha$ï¼Œä»¥ç¡®ä¿åœ¨ç»™å®šæ—¶é—´é¢„ç®— $T$ å†…å®Œæˆæ¨ç†ã€‚
   - æ¨å¯¼å‡ºæœ€ä¼˜é©±é€æ¯”ä¾‹ $\alpha^*$ çš„é—­å¼è§£ï¼Œæœ€å¤§åŒ–å“åº”æ€§èƒ½çš„åŒæ—¶æ»¡è¶³æ—¶é—´çº¦æŸã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹é¢ | ç°æœ‰æ–¹æ³•å±€é™ | TimeBill æ”¹è¿› |
|------|---------------|----------------|
| **æ—¶é—´å¯é¢„æµ‹æ€§** | ç¼ºä¹ç«¯åˆ°ç«¯æ‰§è¡Œæ—¶é—´å»ºæ¨¡ | æå‡º RLP + ETE å®ç°é«˜ç²¾åº¦é¢„æµ‹ |
| **çµæ´»æ€§** | å›ºå®š KV é©±é€æ¯”ä¾‹ï¼Œæ— æ³•é€‚é…ä¸åŒä»»åŠ¡/é¢„ç®— | åŠ¨æ€è°ƒèŠ‚ $\alpha$ï¼Œé€‚åº”å¤šæ ·åŒ–åœºæ™¯ |
| **æ€§èƒ½-æ•ˆç‡æƒè¡¡** | AFAP æˆ–å›ºå®šå‹ç¼©ç­–ç•¥ç‰ºç‰²è´¨é‡æˆ–å¯é æ€§ | åœ¨æ»¡è¶³æ—¶é™å‰æä¸‹æœ€å¤§åŒ–å“åº”è´¨é‡ |
| **éƒ¨ç½²å…¼å®¹æ€§** | å¤šä¸ºç¦»çº¿ä¼˜åŒ–ï¼Œéš¾åœ¨çº¿è°ƒæ•´ | æ”¯æŒè¿è¡Œæ—¶å†³ç­–ï¼Œä¸é‡åŒ–ç­‰æŠ€æœ¯æ­£äº¤ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **ä¸»æµ‹è¯•é›†**ï¼š`LongBench`ï¼ˆBai et al., 2024ï¼‰ï¼Œä¸€ä¸ªåŒè¯­å¤šä»»åŠ¡é•¿ä¸Šä¸‹æ–‡ç†è§£åŸºå‡†ã€‚
- **è®­ç»ƒé›†ï¼ˆç”¨äº RLPï¼‰**ï¼š`Arena-Human-Preference-100k` æ•°æ®é›†ä¸­çš„æç¤ºï¼Œé¿å…åœ¨æµ‹è¯•é›†ä¸Šè®­ç»ƒã€‚

### **å®éªŒè®¾ç½®**
- **ç›®æ ‡æ¨¡å‹**ï¼š`Qwen2.5-7B-Instruct`ï¼ˆcontext length: 32,768ï¼›æœ€å¤§ç”Ÿæˆé•¿åº¦ $N_{\text{max}} = 8,192$ï¼‰
- **é¢„æµ‹å™¨æ¨¡å‹**ï¼š`Qwen2.5-0.5B-Instruct` ä½œä¸º SLM æ„å»º RLP
- **ç¡¬ä»¶å¹³å°**ï¼šIntel Xeon Platinum 8350C + NVIDIA A40 GPU
- **KV Cache é©±é€å®ç°**ï¼šé‡‡ç”¨ `SnapKV`ï¼ˆLi et al., 2024aï¼‰
- **é»˜è®¤æ‚²è§‚å› å­ $k = 5$**ï¼Œæœ€å¤§é©±é€æ¯”ä¾‹ $\alpha_{\text{max}} = 95\%$

### **è¯„ä¼°æŒ‡æ ‡**
- **å“åº”æ€§èƒ½æŒ‡æ ‡**ï¼š
  - F1 Score
  - ROUGE-L
  - Levenshtein Distance
- **ç³»ç»Ÿçº§æŒ‡æ ‡**ï¼š
  - **å¹³å‡å“åº”å¾—åˆ†ï¼ˆAverage Scoreï¼‰**
  - **ä»»åŠ¡å®Œæˆç‡ï¼ˆCompletion Rateï¼‰**ï¼šæŒ‰æ—¶å®Œæˆçš„ä»»åŠ¡å æ¯”
- **é¢„æµ‹è¯¯å·®æŒ‡æ ‡**ï¼š
  - MAEã€RMSEã€RÂ²ï¼ˆå“åº”é•¿åº¦é¢„æµ‹ï¼‰
  - MAPEï¼ˆæ‰§è¡Œæ—¶é—´ä¼°è®¡ï¼‰

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| æ–¹æ³• | æè¿° |
|------|------|
| **Vanilla** | åŸå§‹ LLM æ¨ç†ï¼Œæ— ä»»ä½•ä¼˜åŒ– |
| **Fixed $\alpha$** | å›ºå®š KV Cache é©±é€æ¯”ä¾‹ï¼ˆ25%, 50%, 75%, 95%ï¼‰ |
| **AWQ** | æ¿€æ´»æ„ŸçŸ¥æƒé‡é‡åŒ–è‡³ 4-bitï¼ˆLin et al., 2024ï¼‰ |
| **TimeBillï¼ˆOursï¼‰** | æœ¬æ–‡æå‡ºçš„æ–¹æ³• |

### **è¶…æ—¶å¤„ç†ç­–ç•¥ï¼ˆOverrun Strategiesï¼‰**
- **Kill**ï¼šç»ˆæ­¢å½“å‰ä»»åŠ¡ï¼Œè§†ä¸ºæœªå®Œæˆï¼ˆè¾“å‡ºä¸ºç©ºï¼‰
- **Skip-Next**ï¼šè·³è¿‡åç»­è‹¥å¹²ä»»åŠ¡ç›´åˆ°å½“å‰å®Œæˆ

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **(1) å“åº”é•¿åº¦é¢„æµ‹æ€§èƒ½ï¼ˆTable 1ï¼‰**
| æ–¹æ³• | #Buckets | MAE â†“ | RMSE â†“ | RÂ² â†‘ |
|------|----------|--------|---------|-------|
| ProxyModel (BERT-based) | 5 | 105.72 | 136.79 | 0.152 |
| S3 (DistilBERT-based) | 10 | 108.96 | 148.91 | -0.004 |
| **Ours (Regression)** | â€“ | 64.21 | 103.30 | 0.516 |
| **Ours (Classification, B=64)** | 128 | 48.95 | 87.57 | 0.652 |
| **Ours (B=32)** | 256 | 44.15 | 78.63 | 0.719 |
| **Ours (B=16)** | **512** | **42.71** | **78.13** | **0.723** |

> âœ… **ç»“è®º**ï¼šTimeBill çš„ RLP æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸”åˆ†ç±»æ–¹å¼ä¼˜äºå›å½’ï¼›æ¡¶æ•°è¶Šå¤šï¼ˆç²’åº¦è¶Šç»†ï¼‰ï¼Œæ€§èƒ½è¶Šå¥½ã€‚

#### **(2) æ‰§è¡Œæ—¶é—´ä¼°è®¡ç²¾åº¦ï¼ˆFigure 5 & 6ï¼‰**
- **MAPEï¼ˆå¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®ï¼‰**ï¼š
  - Prefill Phase: **1.22%**
  - Decoding Step: **1.69%**
- **ç«¯åˆ°ç«¯æ‰§è¡Œæ—¶é—´ä¼°è®¡**ï¼š
  - $t_{e2e}$ é¢„æµ‹å€¼ä¸å®æµ‹å€¼é«˜åº¦å»åˆ
  - $t_{wCET}$ï¼ˆå¸¦æ‚²è§‚å› å­çš„ä¼°è®¡ï¼‰æœ‰æ•ˆæä¾›ä¸Šç•Œï¼Œä¿éšœå®‰å…¨æ€§

#### **(3) ä¸å…¶ä»–æ–¹æ³•çš„å¯¹æ¯”ï¼ˆFigure 7ï¼‰**
åœ¨å¤šä¸ªæ—¶é—´é¢„ç®—ï¼ˆ5~10 ç§’ï¼‰ä¸‹çš„è¡¨ç°ï¼š

| æ–¹æ³• | å®Œæˆç‡ | å¹³å‡å¾—åˆ† |
|------|--------|----------|
| **Vanilla** | å¾ˆä½ï¼ˆå¸¸è¶…æ—¶ï¼‰ | ä½ |
| **Fixed $\alpha=25\%$** | è¾ƒä½ | ä¸­ç­‰åä½ |
| **Fixed $\alpha=95\%$** | é«˜ | æ˜æ˜¾ä¸‹é™ï¼ˆè´¨é‡å—æŸï¼‰ |
| **AWQ** | ç•¥é«˜äº Vanilla | ç•¥ä¼˜ |
| **TimeBill** | **æ¥è¿‘ $\alpha=95\%$ çš„é«˜å®Œæˆç‡** | **æ˜¾è‘—æ›´é«˜ï¼ˆSOTAï¼‰** |

> âœ… **ç»“è®º**ï¼šTimeBill åœ¨ä¿æŒé«˜ä»»åŠ¡å®Œæˆç‡çš„åŒæ—¶ï¼Œå®ç°äº†æœ€é«˜çš„å¹³å‡å“åº”è´¨é‡ã€‚

#### **(4) æ¶ˆèå®éªŒï¼šæ‚²è§‚å› å­ $k$ çš„å½±å“ï¼ˆFigure 8ï¼‰**
- å½“ $k \in [1,5]$ï¼šå¢å¤§ $k$ â†’ æ›´ä¿å®ˆè°ƒåº¦ â†’ æ›´å¤šä»»åŠ¡èƒ½æŒ‰æ—¶å®Œæˆ â†’ å®Œæˆç‡å’Œå¹³å‡åˆ†ä¸Šå‡
- å½“ $k > 5$ï¼šè¿‡åº¦ä¿å®ˆ â†’ è¿‡é«˜çš„ $\alpha^*$ â†’ å“åº”è´¨é‡ä¸¥é‡ä¸‹é™ â†’ å¹³å‡åˆ†å›è½
- **æœ€ä½³ $k â‰ˆ 5$**ï¼Œç¬¦åˆç¡¬å®æ—¶ç³»ç»Ÿå¸¸è§å®è·µ

> ğŸ” **è¯´æ˜**ï¼š$k$ æ˜¯å¯è°ƒå‚æ•°ï¼Œéœ€æ ¹æ®åº”ç”¨åœºæ™¯æƒè¡¡å®‰å…¨æ€§å’Œæ€§èƒ½ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **ç»†ç²’åº¦å“åº”é•¿åº¦é¢„æµ‹è‡³å…³é‡è¦**ï¼šä¼ ç»Ÿç²—ç²’åº¦åˆ†ç±»æˆ–å›å½’æ–¹æ³•è¯¯å·®å¤§ï¼ŒåŸºäº SLM çš„åˆ†ç±»å¼ RLP å¯æ˜¾è‘—æå‡é¢„æµ‹ç²¾åº¦ã€‚
2. **FLOPs + Profiling çš„æ··åˆå»ºæ¨¡æ›´å‡†ç¡®**ï¼šçº¯åˆ†ææ¨¡å‹å¿½ç•¥ç¡¬ä»¶å®ç°ç»†èŠ‚ï¼Œçº¯å­¦ä¹ æ¨¡å‹ç¼ºä¹å¯è§£é‡Šæ€§ï¼Œç»“åˆä¸¤è€…ä¼˜åŠ¿æ˜æ˜¾ã€‚
3. **åŠ¨æ€ KV Cache é©±é€ä¼˜äºå›ºå®šç­–ç•¥**ï¼šæ ¹æ®ä¸åŒè¾“å…¥å’Œæ—¶é—´é¢„ç®—è‡ªé€‚åº”è°ƒæ•´ $\alpha$ï¼Œå¯åœ¨ä¸ç‰ºç‰²å¤ªå¤šè´¨é‡çš„å‰æä¸‹å¤§å¹…æå‡å®Œæˆç‡ã€‚
4. **TimeBill å®ç°äº†æ€§èƒ½ä¸æ•ˆç‡çš„æœ€ä½³å¹³è¡¡**ï¼šåœ¨å¤šç§æ—¶é—´é¢„ç®—å’Œè¶…é™ç­–ç•¥ä¸‹ï¼Œå‡ä¼˜äº Vanillaã€å›ºå®šå‹ç¼©å’Œ AWQã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–ç¦»çº¿å»ºæ¨¡ä¸æ ¡å‡†**ï¼šFLOPs ç³»æ•°å’Œ ETE å‚æ•°éœ€è¦é’ˆå¯¹ç‰¹å®šç¡¬ä»¶å’Œæ¨¡å‹è¿›è¡Œ profilingï¼Œè¿ç§»æˆæœ¬è¾ƒé«˜ã€‚
- **é¢„æµ‹æœ¬èº«å¼•å…¥å¼€é”€**ï¼šè™½ç„¶å¯é€šè¿‡å¹¶è¡Œæ©ç›–ï¼Œä½†åœ¨æä½å»¶è¿Ÿåœºæ™¯ä»å¯èƒ½æˆä¸ºç“¶é¢ˆã€‚
- **ä»…è€ƒè™‘ KV Cache é©±é€**ï¼šæœªæ•´åˆå…¶ä»–åœ¨çº¿ä¼˜åŒ–æ‰‹æ®µï¼ˆå¦‚ early exitingã€speculative decodingï¼‰ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- å°† TimeBill ä¸ **é‡åŒ–ã€ç¨€ç–åŒ–ç­‰ç¦»çº¿å‹ç¼©æŠ€æœ¯ç»“åˆ**ï¼Œè¿›ä¸€æ­¥é™ä½å»¶è¿Ÿã€‚
- æ‰©å±•è‡³ **å¤šæ¨¡æ€ LLM å’Œå…·èº« AI åœºæ™¯**ï¼Œæ”¯æŒæ›´å¤æ‚çš„å†³ç­–é“¾ã€‚
- æ¢ç´¢ **æ— éœ€é¢å¤–é¢„æµ‹æ¨¡å—çš„è½»é‡çº§ç‰ˆæœ¬**ï¼Œé€‚ç”¨äºè¾¹ç¼˜è®¾å¤‡ã€‚
- å¼•å…¥ **åœ¨çº¿åé¦ˆæœºåˆ¶**ï¼Œæ ¹æ®å†å²æ‰§è¡Œç»“æœåŠ¨æ€è°ƒæ•´æ‚²è§‚å› å­ $k$ã€‚

---

> **æ€»ç»“**ï¼šTimeBill æ˜¯é¦–ä¸ªç³»ç»Ÿæ€§è§£å†³ LLM æ—¶é—´é¢„ç®—åŒ–æ¨ç†é—®é¢˜çš„æ¡†æ¶ï¼Œé€šè¿‡â€œé¢„æµ‹ + æ§åˆ¶â€é—­ç¯ï¼Œåœ¨ä¿è¯å®æ—¶æ€§çš„å‰æä¸‹æœ€å¤§åŒ–å“åº”è´¨é‡ï¼Œä¸º LLM åœ¨è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººç­‰å®‰å…¨å…³é”®é¢†åŸŸçš„è½åœ°æä¾›äº†é‡è¦æ”¯æ’‘ã€‚

</details>

---

### 6. [nncase: An End-to-End Compiler for Efficient LLM Deployment on Heterogeneous Storage Architectures](https://arxiv.org/abs/2512.21571)

**Authors**: Hui Guo, Qihang Zheng, Chenghai Huo, Dongliang Guo, Haoqi Yang, Yang Zhang  
**Category**: cs.DC  
**Published**: 2025-12-29  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.21571v1  

#### Abstract
The efficient deployment of large language models (LLMs) is hindered by memory architecture heterogeneity, where traditional compilers suffer from fragmented workflows and high adaptation costs. We present nncase, an open-source, end-to-end compilation framework designed to unify optimization across...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šnncase: An End-to-End Compiler for Efficient LLM Deployment on Heterogeneous Storage Architectures

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¼‚æ„å­˜å‚¨æ¶æ„ä¸Šçš„é«˜æ•ˆéƒ¨ç½²é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **å†…å­˜å¢™**ï¼šè®¡ç®—èƒ½åŠ›å¹´å¢é•¿100%ï¼Œè€Œå†…å­˜å¸¦å®½ä»…å¢é•¿20%ï¼Œæ•°æ®ç§»åŠ¨æˆä¸ºç“¶é¢ˆã€‚
- **æ¶æ„å¼‚æ„æ€§**ï¼šä¸åŒè®¾å¤‡å…·æœ‰ä¸åŒçš„è®¡ç®—å•å…ƒï¼ˆå¦‚ Scalarã€Vectorã€Matrix å•å…ƒï¼‰å’Œå¤æ‚çš„å†…å­˜å±‚æ¬¡ï¼ˆSRAMã€HBMã€DRAMï¼‰ã€‚
- **ç¼–è¯‘å™¨ç¢ç‰‡åŒ–**ï¼šä¼ ç»Ÿç¼–è¯‘å™¨å¯¹ç»Ÿä¸€ä¸éç»Ÿä¸€å†…å­˜æ¶æ„ï¼ˆUMA/NUMAï¼‰é‡‡ç”¨ä¸åŒä¼˜åŒ–æµç¨‹ï¼Œå¯¼è‡´é€‚é…æˆæœ¬é«˜ã€å…¨å±€ä¼˜åŒ–å›°éš¾ã€‚

ç°æœ‰ç¼–è¯‘æ¡†æ¶ï¼ˆå¦‚ TVMã€MLC LLMã€IPEXï¼‰éš¾ä»¥åœ¨è‡ªåŠ¨åŒ–ç¨‹åº¦ã€æ€§èƒ½å’Œè·¨å¹³å°é€‚åº”æ€§ä¹‹é—´å–å¾—å¹³è¡¡ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯**

ä½œè€…æå‡ºäº† **nncase** â€”â€”ä¸€ä¸ªå¼€æºçš„ç«¯åˆ°ç«¯ç¼–è¯‘æ¡†æ¶ï¼Œæ—¨åœ¨ç»Ÿä¸€å¼‚æ„å­˜å‚¨æ¶æ„ä¸‹çš„ LLM éƒ¨ç½²ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯â€œ**ç»Ÿä¸€åˆ†å¸ƒå¼ç¼–è¯‘èŒƒå¼**â€ï¼ˆUnified Distributed Compilation Paradigmï¼‰ï¼Œé€šè¿‡ä»¥ä¸‹ä¸‰å¤§æ¨¡å—å®ç°å…¨å±€ååŒä¼˜åŒ–ï¼š

#### âœ… åˆ›æ–°ç‚¹ä¸€ï¼šåŸºäº e-graph çš„ Term Rewriting å¼•æ“
- é‡‡ç”¨ **equality saturation** æŠ€æœ¯æ„å»ºéç ´åæ€§é‡å†™å¼•æ“ï¼Œé¿å…ä¼ ç»Ÿç¼–è¯‘å™¨ä¸­çš„ **phase ordering problem**ã€‚
- åœ¨ e-graph ä¸­åŒæ—¶ä¿ç•™å¤šç§ç­‰ä»·ç¨‹åºè¡¨ç¤ºï¼Œæœ€ç»ˆé€šè¿‡çº¦æŸæ±‚è§£å™¨ï¼ˆSAT/WPMAXSATï¼‰é€‰æ‹©æœ€ä¼˜è·¯å¾„ã€‚
- æ”¯æŒå¤šç›®æ ‡ä¼˜åŒ–ï¼ˆå»¶è¿Ÿã€å†…å­˜å ç”¨ã€é€šä¿¡å¼€é”€ï¼‰ï¼Œç»“åˆ Roofline æ¨¡å‹è¿›è¡Œä»£ä»·å»ºæ¨¡ã€‚

#### âœ… åˆ›æ–°ç‚¹äºŒï¼šAuto Vectorize æ¨¡å—
- æå‡º `MetaPackOperation` å’Œ `FoldNopPack` è§„åˆ™ï¼Œåœ¨ e-graph å†…éƒ¨ç”Ÿæˆå¹¶è¯„ä¼°å¤šç§å¼ é‡å¸ƒå±€å€™é€‰æ–¹æ¡ˆã€‚
- åŠ¨æ€è°ƒæ•´æ‰“åŒ…å› å­ï¼Œæ¶ˆé™¤å†—ä½™çš„ Pack/Unpack æ“ä½œï¼Œå®ç°å‘é‡åŒ–ä¸çŸ©é˜µè®¡ç®—å•å…ƒçš„æœ€ä½³åŒ¹é…ã€‚

#### âœ… åˆ›æ–°ç‚¹ä¸‰ï¼šAuto Distribution æ¨¡å—
- åŸºäº **SBP æŠ½è±¡**ï¼ˆSplit, Broadcast, Partialï¼‰æè¿°åˆ†å¸ƒå¼ç­–ç•¥ï¼Œå¹¶å°†å…¶åµŒå…¥ e-graph ç»“æ„ä¸­ã€‚
- å°†åˆ†å¸ƒç­–ç•¥æœç´¢ç©ºé—´å½¢å¼åŒ–ä¸ºå›¾å†…ç­‰ä»·ç±»åˆå¹¶é—®é¢˜ï¼Œæ”¯æŒæ‹“æ‰‘æ— å…³çš„å¹¶è¡Œç­–ç•¥è‡ªåŠ¨æœç´¢ã€‚
- æ˜¾å¼å»ºæ¨¡é€šä¿¡ä»£ä»·ï¼ˆAlpha-Beta æ¨¡å‹ï¼‰å’Œå†…å­˜å®¹é‡ç¡¬çº¦æŸï¼Œé˜²æ­¢ OOM é”™è¯¯ã€‚

#### âœ… åˆ›æ–°ç‚¹å››ï¼šAuto Schedule æ¨¡å— + NTT åº“
- å¼•å…¥ **nncase Tensor Template (NTT) Library**ï¼Œå°è£…æ‰‹å·¥ä¼˜åŒ–çš„é«˜æ€§èƒ½å¾®æ ¸ï¼ˆukernelsï¼‰ä½œä¸ºè°ƒåº¦åŸå­å•ä½ã€‚
- è°ƒåº¦åˆ†ä¸ºä¸¤å±‚ï¼š
  - **ç»“æ„ä¼˜åŒ–**ï¼šä½¿ç”¨ **Monte Carlo Tree Search (MCTS)** æ¢ç´¢å¾ªç¯èåˆä¸é¡ºåºã€‚
  - **å‚æ•°ä¼˜åŒ–**ï¼šä½¿ç”¨ **Mixed-Integer Nonlinear Programming (MINLP)** æ±‚è§£ tile size ä¸ buffer placementã€‚
- å®ç°å¯„å­˜å™¨çº§æ•ˆç‡ï¼ŒåŒæ—¶å¤§å¹…ç¼©çŸ­æœç´¢æ—¶é—´ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆTVM/MLC/IPEXï¼‰ | nncase |
|------|--------------------------|--------|
| ç¼–è¯‘æµç¨‹ | åˆ†é˜¶æ®µã€å‰²è£‚ï¼ˆlayout â†’ parallel â†’ scheduleï¼‰ | ç»Ÿä¸€ e-graph è¡¨ç¤ºï¼Œè”åˆä¼˜åŒ– |
| å‘é‡åŒ–æ”¯æŒ | å±€éƒ¨ kernel çº§ä¼˜åŒ–ï¼Œæ˜“äº§ç”Ÿ layout thrashing | å…¨å±€æ¢ç´¢ï¼Œæ¶ˆé™¤å†—ä½™è½¬æ¢ |
| åˆ†å¸ƒå¼ç­–ç•¥ | æ‰‹åŠ¨æ ‡æ³¨æˆ–åˆ†å±‚æœç´¢ï¼Œå¿½ç•¥å†…å­˜çº¦æŸ | è‡ªåŠ¨æœç´¢ï¼Œæ˜¾å¼å»ºæ¨¡é€šä¿¡ä¸å†…å­˜é™åˆ¶ |
| è°ƒåº¦ç²’åº¦ | æ ‡é‡çº§åˆ«ï¼Œéš¾è¾¾å¯„å­˜å™¨çº§æ€§èƒ½ | åŸºäº ukernelï¼Œæ”¯æŒç»†ç²’åº¦æ§åˆ¶ |
| ç¼–è¯‘æ—¶é—´ | å­¦ä¹ å‹æ–¹æ³•è€—æ—¶é•¿ï¼ˆAnsorï¼‰ | MCTS + MINLP å¿«é€Ÿæ”¶æ•› |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ¨¡å‹ä¸æ•°æ®é›†**

- **æ¨¡å‹ç³»åˆ—**ï¼šQwen3 [56]
  - Qwen3-0.6Bï¼ˆæ”¯æŒ F32/F16ï¼‰
  - Qwen3-1.7Bï¼ˆF16ï¼‰
- **è¾“å…¥é…ç½®**ï¼šbatch size = 1ï¼Œprompt length = 8 tokens
- **ä»»åŠ¡ç±»å‹**ï¼šè‡ªå›å½’æ–‡æœ¬ç”Ÿæˆï¼ˆè§£ç é˜¶æ®µååé‡æµ‹è¯•ï¼‰

---

### **å®éªŒå¹³å°**

- **ç¡¬ä»¶**ï¼šAMD Ryzen 9 5900Xï¼ˆ12æ ¸ï¼‰ï¼Œ128GB DDR4-3600
- **æ“ä½œç³»ç»Ÿ**ï¼šUbuntu 24.04 LTS
- **ç¼–è¯‘å™¨**ï¼šGCC 14.2ï¼Œå¯ç”¨ AVX2 æŒ‡ä»¤é›†
- **å•æ ¸ vs å¤šæ ¸æµ‹è¯•**ï¼šåˆ†åˆ«è¿è¡Œ 1Tã€4Tã€8T é…ç½®ä»¥è¯„ä¼°å¯æ‰©å±•æ€§

---

### **è¯„ä¼°æŒ‡æ ‡**

- **ä¸»æŒ‡æ ‡**ï¼šToken ååé‡ï¼ˆtokens/sï¼‰
- **æ¬¡è¦æŒ‡æ ‡**ï¼š
  - ç¼–è¯‘æ—¶é—´
  - å†…å­˜å ç”¨
  - å¯æ‰©å±•æ€§ï¼ˆSpeedupï¼‰
- **æµ‹è¯•æ¬¡æ•°**ï¼šæ¯ç»„å®éªŒé‡å¤ 100 æ¬¡å–å¹³å‡å€¼

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| æ¡†æ¶ | ç±»å‹ | ç‰ˆæœ¬ |
|------|------|------|
| **llama.cpp** | æ‰‹å·¥ä¼˜åŒ–åº“ | Tag: b5753 |
| **Intel IPEX** | å·¥ä¸šçº§ PyTorch æ‰©å±• | v28.0 |
| **MLC LLM** | ä¸»æµ DL ç¼–è¯‘å™¨ | Commit: 862a7311 |

> æ‰€æœ‰æ¡†æ¶å‡ä½¿ç”¨é»˜è®¤ä¼˜åŒ–é…ç½®ï¼Œæœ€å¤§åŒ–å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»**

| æ¨¡å‹ | é…ç½® | nncase | llama.cpp | IPEX | MLC LLM |
|------|------|--------|-----------|-------|---------|
| Qwen3-0.6B | F32, 1T | **8.70** tokens/s | 10.61 | 7.58 | 0.20 |
| Qwen3-0.6B | F16, 1T | **13.87** tokens/s | 17.21 | 10.22 | â€” |
| Qwen3-1.7B | F16, 1T | **5.09** tokens/s | 6.30 | 4.20 | â€” |
| Qwen3-0.6B | F16, 4T | **23.50** tokens/s | 23.20 | 15.52 | â€” |
| Qwen3-0.6B | F16, 8T | **23.98** tokens/s | ~23.5* | ~16* | â€” |
| Qwen3-1.7B | F16, 4T | **8.85** tokens/s | 8.34 | 6.93 | â€” |

> *æ³¨ï¼š8T ä¸‹æ¥è¿‘å†…å­˜å¸¦å®½æé™ï¼Œæå‡æœ‰é™*

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

#### ğŸ”¹ å•æ ¸åœºæ™¯ï¼ˆ1Tï¼‰
- nncase åœ¨æ‰€æœ‰æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äº **IPEX** å’Œ **MLC LLM**ã€‚
- ç›¸æ¯”æ‰‹è°ƒåº“ **llama.cpp**ï¼Œå·®è·çº¦ 18%-30%ï¼Œä½†åœ¨è‡ªåŠ¨åŒ–ç¼–è¯‘å™¨ä¸­è¡¨ç°æœ€ä½³ã€‚
- åœ¨ F16 ä¸Šæ€§èƒ½æå‡æ˜æ˜¾ï¼ˆ+59%ï¼‰ï¼Œä½“ç°å…¶å¯¹ä½ç²¾åº¦çš„è‰¯å¥½æ”¯æŒã€‚

#### ğŸ”¹ å¤šæ ¸åœºæ™¯ï¼ˆ4T/8Tï¼‰
- **nncase å®ç°åè¶…**ï¼šåœ¨ Qwen3-0.6B-F16 ä¸Šï¼Œ4T æ€§èƒ½ç•¥é«˜äº llama.cppï¼ˆ23.5 vs 23.2ï¼‰ï¼Œ8T ä¸‹ä»ä¿æŒé¢†å…ˆã€‚
- å¯¹å¤§æ¨¡å‹ Qwen3-1.7Bï¼Œ4T åŠ é€Ÿæ¯”è¾¾ **74%**ï¼ˆvs 1Tï¼‰ï¼Œè¿œé«˜äº llama.cpp çš„ 32%ï¼Œè¯´æ˜å…¶å¹¶è¡Œæ•ˆç‡æ›´é«˜ã€‚
- æˆåŠŸçªç ´ä¼ ç»Ÿå…±äº«å†…å­˜å¹¶è¡Œï¼ˆå¦‚ OpenMPï¼‰çš„åŒæ­¥å¼€é”€ç“¶é¢ˆã€‚

---

### **æ¶ˆèå®éªŒåˆ†æï¼ˆæ–‡ä¸­éšå«ï¼‰**

è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»è®¾è®¡é€»è¾‘å¯æ¨æ–­ï¼š
- è‹¥å…³é—­ **Auto Distribution**ï¼Œå°†é€€åŒ–ä¸ºæ™®é€šå¤šçº¿ç¨‹è°ƒåº¦ï¼Œå¤±å»é™æ€åˆ’åˆ†ä¼˜åŠ¿ã€‚
- è‹¥ç§»é™¤ **e-graph-based rewriting**ï¼Œæ— æ³•å…¨å±€æ¢ç´¢ layout ä¸ distribution çš„ç»„åˆç©ºé—´ã€‚
- è‹¥æ›¿æ¢ MINLP ä¸ºå¯å‘å¼è°ƒä¼˜ï¼Œå¯èƒ½é”™è¿‡æœ€ä¼˜ tile size é…ç½®ã€‚
- NTT åº“æä¾›çš„ ukernel æ˜¯è¾¾æˆæ¥è¿‘æ‰‹å†™æ€§èƒ½çš„å…³é”®åŸºç¡€ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **ç»Ÿä¸€ç¼–è¯‘èŒƒå¼å¯è¡Œä¸”é«˜æ•ˆ**  
   nncase è¯æ˜äº†é€šè¿‡ NUMA æŠ½è±¡ç»Ÿä¸€ UMA/NUMA æ¶æ„çš„ç¼–è¯‘æ˜¯å¯è¡Œçš„ï¼Œâ€œcompile once, adapt everywhereâ€ å¯å®ç°ã€‚

2. âœ… **e-graph å¯æœ‰æ•ˆæ”¯æ’‘è·¨ç»´åº¦è”åˆä¼˜åŒ–**  
   å°† layoutã€distributionã€scheduling ç»Ÿä¸€å»ºæ¨¡äº e-graph ä¸­ï¼Œå®ç°äº† algebraic transformationã€data movement ä¸ memory hierarchy çš„ååŒä¼˜åŒ–ã€‚

3. âœ… **è‡ªåŠ¨åŒ–ç¼–è¯‘å¯è¾¾è¿‘æ‰‹å·¥æ€§èƒ½**  
   åœ¨å•æ ¸ä¸‹æ¥è¿‘ llama.cppï¼ˆå·®è· < 30%ï¼‰ï¼Œåœ¨å¤šæ ¸ä¸‹ç”šè‡³è¶…è¶Šï¼Œè¡¨æ˜è‡ªåŠ¨åŒ–è°ƒåº¦å·²å…·å¤‡å®ç”¨ä»·å€¼ã€‚

4. âœ… **åˆ†å¸ƒå¼æ€ç»´å¯ç”¨äºå•æœºå¤šæ ¸ä¼˜åŒ–**  
   å°†å¤šæ ¸è§†ä¸ºâ€œå¤šèŠ‚ç‚¹â€ï¼Œåˆ©ç”¨ SBP + é™æ€é€šä¿¡è°ƒåº¦ï¼Œæ˜¾è‘—é™ä½è¿è¡Œæ—¶å¼€é”€ï¼Œä¼˜äºåŠ¨æ€çº¿ç¨‹æ± ï¼ˆå¦‚ OpenMPï¼‰ã€‚

---

### **å±€é™æ€§**

1. å½“å‰ä¸»è¦é¢å‘ CPU å¹³å°ï¼ˆAVX2ï¼‰ï¼Œå°šæœªéªŒè¯åœ¨ GPU æˆ– AI åŠ é€Ÿå™¨ä¸Šçš„æ•ˆæœã€‚
2. ç¼–è¯‘æ—¶é—´è™½ä¼˜äºå­¦ä¹ å‹æ–¹æ³•ï¼Œä½†ä»éœ€è¿›ä¸€æ­¥ä¼˜åŒ–ä»¥æ»¡è¶³å®æ—¶éƒ¨ç½²éœ€æ±‚ã€‚
3. å¯¹éå¸¸è§„ç®—å­èåˆæ¨¡å¼çš„æ”¯æŒä¾èµ– NTT åº“çš„æ‰‹å·¥å®ç°ï¼Œæ³›åŒ–èƒ½åŠ›å—é™ã€‚
4. å®éªŒé›†ä¸­åœ¨æ¨ç†é˜¶æ®µï¼Œè®­ç»ƒåœºæ™¯æœªè¦†ç›–ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘ï¼ˆä½œè€…æ˜ç¡®æå‡ºï¼‰**

1. **Holistic Performance Characterization**  
   æ‰©å±•è¯„æµ‹èŒƒå›´è‡³æ›´å¤šæ¨¡å‹è§„æ¨¡ã€ç¡¬ä»¶å¹³å°ï¼ˆå¦‚è¾¹ç¼˜è®¾å¤‡ï¼‰ã€éƒ¨ç½²åœºæ™¯ï¼ˆä½å»¶è¿Ÿ vs é«˜ååï¼‰ã€‚

2. **Cross-Architecture Adaptation (SIMT Support)**  
   æ‰©å±•åç«¯ä»¥æ”¯æŒ SIMT æ¶æ„ï¼ˆå¦‚ GPUï¼‰ï¼Œå¢å¼º Auto Vectorize ä¸ Auto Schedule å¯¹ warp-level å¹¶è¡Œçš„æ”¯æŒã€‚

3. **Computation-Communication Overlap**  
   å®ç°è®¡ç®—ä¸é€šä¿¡å†…æ ¸çš„è‡ªåŠ¨èåˆä¸æµæ°´è°ƒåº¦ï¼Œé€šè¿‡ä¾èµ–åˆ†æéšè—é€šä¿¡å»¶è¿Ÿï¼Œæå‡åˆ†å¸ƒå¼ååã€‚

---

## æ€»ç»“

nncase æ˜¯é¦–ä¸ªå°† **e-graph equality saturation**ã€**SBP åˆ†å¸ƒæŠ½è±¡** ä¸ **å±‚æ¬¡åŒ–è°ƒåº¦ï¼ˆMCTS + MINLPï¼‰** æ·±åº¦æ•´åˆçš„ LLM ç¼–è¯‘å™¨ã€‚å®ƒä¸ä»…åœ¨æ€§èƒ½ä¸Šåª²ç¾æ‰‹å†™åº“ï¼ˆllama.cppï¼‰ï¼Œæ›´å±•ç¤ºäº†**è‡ªåŠ¨åŒ–ç¼–è¯‘å™¨åœ¨å¤æ‚å¼‚æ„ç¯å¢ƒä¸‹çš„å·¨å¤§æ½œåŠ›**ã€‚å…¶â€œç»Ÿä¸€åˆ†å¸ƒå¼ç¼–è¯‘â€ç†å¿µä¸ºæœªæ¥è·¨å¹³å°é«˜æ•ˆéƒ¨ç½²æä¾›äº†æ–°èŒƒå¼ã€‚

> å¼€æºåœ°å€ï¼šhttps://github.com/kendryte/nncase

</details>

---

### 7. [BLEST: Blazingly Efficient BFS using Tensor Cores](https://arxiv.org/abs/2512.21967)

**Authors**: Deniz Elbek, Kamer Kaya  
**Category**: cs.DC  
**Published**: 2025-12-29  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.21967v1  

#### Abstract
Breadth-First Search (BFS) is a fundamental graph kernel that underpins a wide range of applications. While modern GPUs provide specialised Matrix-Multiply-Accumulate (MMA) units, e.g., Tensor Cores (TC), with extremely high throughput, they target dense operations, making it non-trivial to exploit ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šBLEST: Blazingly Efficient BFS using Tensor Cores

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

ç°ä»£ GPU è™½ç„¶é…å¤‡äº†é«˜ååçš„ **Tensor Cores (TC)**ï¼Œä½†è¿™äº›ç¡¬ä»¶å•å…ƒä¸“ä¸ºå¯†é›†çŸ©é˜µè¿ç®—è®¾è®¡ï¼Œéš¾ä»¥é«˜æ•ˆæ”¯æŒå›¾ç®—æ³•ä¸­å…¸å‹çš„**ç¨€ç–ã€ä¸è§„åˆ™è®¡ç®—æ¨¡å¼**ã€‚ä¼ ç»Ÿçš„ BFSï¼ˆBreadth-First Searchï¼‰åœ¨ GPU ä¸Šé¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š

- **è´Ÿè½½ä¸å‡è¡¡**ï¼šå›¾çš„ä¸è§„åˆ™æ€§å¯¼è‡´ä¸åŒ warp å¤„ç†çš„å·¥ä½œé‡å·®å¼‚å¤§ã€‚
- **å†—ä½™è®¡ç®—**ï¼šä¼ ç»Ÿ slice-set æ–¹æ³•é‡‡ç”¨â€œfrontier-obliviousâ€è°ƒåº¦ï¼Œå³ä½¿å½“å‰ frontier ä¸ºç©ºä¹Ÿåˆ†é…ä»»åŠ¡ã€‚
- **åŸå­æ“ä½œå¼€é”€é«˜**ï¼šé¡¶ç‚¹æ›´æ–°é¢‘ç¹ä¸”åˆ†æ•£ï¼Œå¯¼è‡´å¤§é‡éåˆå¹¶å†…å­˜è®¿é—®å’ŒåŸå­å†²çªã€‚
- **ç¼“å­˜å±€éƒ¨æ€§å·®**ï¼šæ›´æ–°çš„é¡¶ç‚¹ ID åˆ†å¸ƒå¹¿æ³›ï¼Œé™ä½ L1/L2 ç¼“å­˜å‘½ä¸­ç‡ã€‚
- **ç¼ºä¹å¯¹ TC çš„æœ‰æ•ˆåˆ©ç”¨**ï¼šç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†åˆ©ç”¨ TC çš„å¹¶è¡Œèƒ½åŠ›ï¼Œå­˜åœ¨å¤§é‡å†—ä½™çš„ MMA è°ƒç”¨ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡º **BLEST**ï¼ˆBlazingly Efficient BFS using Tensor Coresï¼‰ï¼Œä¸€ä¸ªåŸºäº TC åŠ é€Ÿçš„é«˜æ•ˆ BFS æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰**Binarised Virtual Slice Sets (BVSS)** æ•°æ®ç»“æ„
- å°†ä¼ ç»Ÿå›ºå®šå¤§å°çš„ slice set ç»†åŒ–ä¸ºæ›´å°ç²’åº¦çš„ **Virtual Slice Set (VSS)**ï¼Œæ¯ä¸ª VSS åŒ…å«æœ€å¤š `WARP_SIZE Ã— slicesPerThread` ä¸ª slicesã€‚
- å¼•å…¥ `realPtrs` å’Œ `virtualToReal` æ˜ å°„æ•°ç»„å®ç°ç‰©ç† slice set ä¸è™šæ‹Ÿ VSS ä¹‹é—´çš„åŒå‘æ˜ å°„ã€‚
- **ä¼˜åŠ¿**ï¼š
  - å®ç°è¿‘ä¹å®Œç¾çš„ **warp çº§è´Ÿè½½å‡è¡¡**ã€‚
  - æ”¯æŒ **frontier-aware è°ƒåº¦**ï¼Œä»…æ¿€æ´»æœ‰éé›¶ frontier çš„ VSSï¼Œé¿å…æ— æ•ˆå·¥ä½œã€‚

#### ï¼ˆ2ï¼‰**åŒå›¾é‡æ’åºç­–ç•¥**
- é’ˆå¯¹ä¸åŒç±»å‹å›¾é‡‡ç”¨ä¸åŒçš„é¡¶ç‚¹é‡æ’åºï¼š
  - **ç¤¾äº¤ç±»å›¾ï¼ˆå¦‚ Twitterï¼‰**ï¼šä½¿ç”¨åŸºäº Jaccard ç›¸ä¼¼æ€§çš„çª—å£èšç±»ï¼ˆJACCARDWITHWINDOWSï¼‰ï¼Œæå‡ BVSS ä¸­çš„è¾¹å‹ç¼©ç‡ã€‚
  - **éç¤¾äº¤ç±»å›¾ï¼ˆå¦‚é“è·¯ç½‘ç»œï¼‰**ï¼šä½¿ç”¨ **RCM (Reverse Cuthill-McKee)** é™ä½å¸¦å®½ï¼Œå‡å°‘ cache line è®¿é—®æ•°é‡ã€‚
- åˆ¤æ–­æ ‡å‡†ï¼šè‹¥å›¾æ»¡è¶³â€œé‡å°¾åˆ†å¸ƒâ€æˆ–â€œå¹‚å¾‹è¡Œä¸ºâ€ï¼Œåˆ™è§†ä¸ºç¤¾äº¤ç±»å›¾ã€‚

#### ï¼ˆ3ï¼‰**æœ€ä¼˜ TC æ‰§è¡Œå¸ƒå±€ä¸æ‰¹å¤„ç† SpMSpV æ¨¡å¼**
- è®¾è®¡äº†ä¸€ç§æ–°çš„ **bitwise TC tile ä½¿ç”¨æ–¹å¼**ï¼Œå°† 8Ã—8 popcount è¾“å‡ºçŸ©é˜µçš„æ‰€æœ‰ 64 ä¸ªæ¡ç›®éƒ½ç”¨äºæœ‰æ•ˆè®¡ç®—ã€‚
- é€šè¿‡ç²¾å¿ƒæ„é€  `fragA`ï¼ˆè¿æ¥æ€§æ©ç ï¼‰å’Œ `fragB`ï¼ˆfrontier å‘é‡ï¼‰çš„æ•°æ®å¸ƒå±€ï¼Œä½¿å¾—å•æ¬¡ TC è°ƒç”¨å¯å®Œæˆ 64 ä¸ª dot-productã€‚
- **ç›¸æ¯” SOTA æ–¹æ³•ï¼ˆå¦‚ BerryBeesï¼‰èŠ‚çœäº† 87.5% çš„ TC è°ƒç”¨æ¬¡æ•°**ï¼ˆä» 16 æ¬¡é™è‡³ 2 æ¬¡ per VSSï¼‰ã€‚

#### ï¼ˆ4ï¼‰**å»¶è¿Ÿé¡¶ç‚¹æ›´æ–°æœºåˆ¶ï¼ˆLazy Vertex Updateï¼‰**
- å°†é¡¶ç‚¹æ›´æ–°åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼š
  1. **æ ‡è®°é˜¶æ®µ**ï¼šå¼‚æ­¥æ ‡è®°è¢«å‘ç°çš„é¡¶ç‚¹ï¼ˆä½¿ç”¨è½»é‡çº§ REDG åŸå­æ“ä½œï¼‰ã€‚
  2. **æœ€ç»ˆåŒ–é˜¶æ®µ**ï¼šåœ¨æ¯å±‚ç»“æŸæ—¶æ‰¹é‡å¤„ç†æ‰€æœ‰æ ‡è®°ï¼Œè¿›è¡Œåˆå¹¶å†™å…¥å’Œ level è®¾ç½®ã€‚
- **ä¼˜åŠ¿**ï¼š
  - å‡å°‘æ˜‚è´µçš„ ATOMG åŸå­æ“ä½œã€‚
  - æå‡ cache locality å’Œå†…å­˜åˆå¹¶åº¦ã€‚

#### ï¼ˆ5ï¼‰**å†…æ ¸èåˆï¼ˆKernel Fusionï¼‰**
- åˆ©ç”¨ CUDA Cooperative Groups å®ç°è®¾å¤‡ç«¯å…¨å±€åŒæ­¥ï¼Œå°†å¤šå±‚ BFS å¾ªç¯èåˆè¿›ä¸€ä¸ªæŒä¹…åŒ– kernelã€‚
- **æ¶ˆé™¤ä¸»æœºä¾§åŒæ­¥å¼€é”€**ï¼Œç‰¹åˆ«æœ‰åˆ©äºéœ€è¦æ•°åƒå±‚éå†çš„é“è·¯ç½‘ç»œã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

å®éªŒæ¶µç›–ä¸¤ç±»åŸºå‡†ï¼š

- **GAP Benchmark Suite [5]**ï¼šåŒ…å«å¤šç§çœŸå®ä¸–ç•Œå›¾ï¼Œå¦‚ï¼š
  - `GAP-road`, `GAP-twitter`, `GAP-web`, `GAP-kron`, `GAP-urand`
- **è‡ªå®šä¹‰å¤§å‹å›¾é›†åˆ**ï¼šæ¥è‡ª SuiteSparse [12]ï¼Œç­›é€‰æ¡ä»¶ä¸º |V| â‰¥ 2Â³â° ä¸” |E| â‰¤ 2Â³Â²âˆ’1ï¼Œä¾‹å¦‚ï¼š
  - `nlpkkt240`, `uk-2005`, `it-2004`, `com-Friendster`, `webbase-2001`, `kmer_Vir`, `mawi`

å…±æµ‹è¯• **14 ä¸ªå¤§è§„æ¨¡å›¾**ï¼Œè¦†ç›–ç¤¾äº¤ã€ç½‘é¡µã€ç§‘å­¦è®¡ç®—ç­‰å¤šç§ç±»å‹ã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

- **ç¡¬ä»¶å¹³å°**ï¼š
  - CPU: 2Ã—Intel Xeon Gold 6152 (å…± 88 çº¿ç¨‹)
  - GPU: **NVIDIA H200**ï¼ˆæ”¯æŒ compute capability 8.0 åŠä»¥ä¸Šï¼Œå…·å¤‡ m8n8k128 TC æŒ‡ä»¤ï¼‰
- **è½¯ä»¶ç¯å¢ƒ**ï¼š
  - CUDA 13.0, g++ 12.3.0
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **è¿è¡Œæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰**ï¼šå¹³å‡ 64 æ¬¡éšæœºæºç‚¹ BFS çš„æ‰§è¡Œæ—¶é—´ã€‚
  - **åŠ é€Ÿæ¯”ï¼ˆSpeedupï¼‰**ï¼šç›¸å¯¹äºå„ baseline çš„å‡ ä½•å¹³å‡åŠ é€Ÿå€æ•°ã€‚
  - **æ¶ˆèå®éªŒ**ï¼šåˆ†æå„ä¼˜åŒ–æ¨¡å—çš„ç‹¬ç«‹è´¡çŒ®ã€‚
  - **å†…å­˜å ç”¨**ï¼šæŠ¥å‘Š BVSS ç»“æ„ã€åŠ¨æ€æ•°ç»„ã€level æ•°ç»„ç­‰çš„ GPU å†…å­˜æ¶ˆè€—ã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

- **GAP-BFS**ï¼šCPU ä¸Šçš„å¹¶è¡Œ BFS å®ç°ã€‚
- **Gunrock [40]**ï¼šä¸»æµ GPU å›¾åˆ†ææ¡†æ¶ï¼Œæ”¯æŒæ–¹å‘ä¼˜åŒ–å’Œè´Ÿè½½å‡è¡¡ã€‚
- **GSWITCH [26]**ï¼šåŸºäºæ¨¡å¼è‡ªåŠ¨è°ƒä¼˜çš„ GPU å›¾å¤„ç†ç³»ç»Ÿã€‚
- **BerryBees [27]**ï¼šé¦–ä¸ªä½¿ç”¨ TC åŠ é€Ÿ BFS çš„å·¥ä½œï¼Œä¹Ÿæ˜¯æœ¬æ–‡æœ€ç›´æ¥çš„æ¯”è¾ƒå¯¹è±¡ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

| æ–¹æ³• | å¹³å‡é€Ÿåº¦æå‡ï¼ˆvs. BerryBeesï¼‰ | vs. Gunrock | vs. GSWITCH | vs. GAP-BFS |
|------|-------------------------------|-------------|--------------|--------------|
| **BLEST (full)** | **3.58Ã—** | **4.64Ã—** | **4.90Ã—** | **13.25Ã—** |

> æ³¨ï¼šåœ¨ GAP benchmark ä¸Šå¯¹ BerryBees è¾¾åˆ° **3.63Ã—** åŠ é€Ÿã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- åœ¨æ‰€æœ‰ 14 ä¸ªå›¾ä¸Šï¼ŒBLEST å‡ä¼˜äº GAPã€Gunrock å’Œ GSWITCHã€‚
- ç›¸æ¯”å”¯ä¸€ä½¿ç”¨ TC çš„ **BerryBees**ï¼ŒBLEST åœ¨å¤šæ•°å›¾ä¸Šæ˜¾è‘—é¢†å…ˆï¼Œæœ€é«˜è¾¾ **8.90Ã—**ï¼ˆ`Spielman_k600`ï¼‰ã€‚
- å³ä½¿åœ¨æŸäº›å›¾ä¸Šï¼ˆå¦‚ `mawi`ï¼‰è¡¨ç°ç•¥é€Šï¼Œæ•´ä½“ä»ä¿æŒæ˜æ˜¾ä¼˜åŠ¿ã€‚

### **æ¶ˆèå®éªŒç»“æœ**

è®ºæ–‡è¯„ä¼°äº†å››ä¸ª BLEST å˜ä½“ï¼š

| å˜ä½“ | æè¿° | ç›¸å¯¹äº BerryBees çš„å¹³å‡åŠ é€Ÿ |
|------|------|-----------------------------|
| **BLEST (a)** | åŸºç¡€ç‰ˆæœ¬ï¼ˆBVSS + æœ€ä¼˜ TC å¸ƒå±€ï¼‰ | **1.89Ã—** |
| **BLEST (ac)** | (a) + Lazy Update | **2.71Ã—** |
| **BLEST (ab)** | (a) + Reordering | **1.98Ã—** |
| **BLEST (full)** | å®Œæ•´ç‰ˆæœ¬ï¼ˆa + b + cï¼‰ | **3.58Ã—** |

**ç»“è®º**ï¼šæ‰€æœ‰ä¸‰ä¸ªä¼˜åŒ–ï¼ˆé‡æ’åºã€å»¶è¿Ÿæ›´æ–°ã€æœ€ä¼˜ TC å¸ƒå±€ï¼‰å‡æœ‰æ˜¾è‘—è´¡çŒ®ï¼Œç»„åˆåäº§ç”ŸååŒæ•ˆåº”ã€‚

æ­¤å¤–ï¼š
- **é‡æ’åºæœ‰æ•ˆæ€§éªŒè¯**ï¼šåœ¨è‡ªç„¶é¡ºåºä¸åˆ©çš„å›¾ä¸Šï¼ˆå¦‚ `GAP-web`ï¼‰ï¼Œåº”ç”¨éšæœºé‡æ’åï¼ŒBLEST(ab) æ¯” BLEST(a) å¿« **2.60Ã—**ã€‚
- **çª—å£å¤§å°å½±å“**ï¼šå¢å¤§ JACCARDWITHWINDOWS çš„çª—å£ `w` å¯æŒç»­æå‡å‹ç¼©ç‡å’Œæ€§èƒ½ï¼Œåœ¨ `GAP-web` ä¸Šæœ€å¤§å¸¦æ¥ **2.01Ã—** åŠ é€Ÿã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **Tensor Cores å¯ä»¥é«˜æ•ˆç”¨äºç¨€ç–å›¾éå†**ï¼šé€šè¿‡å°† BFS è¡¨è¾¾ä¸º batched SpMSpVï¼Œå¹¶å·§å¦™æ˜ å°„åˆ° TC çš„ bitwise MMA æ“ä½œï¼Œå®ç°äº†è¿œè¶…ä¼ ç»Ÿæ–¹æ³•çš„æ€§èƒ½ã€‚
2. **æ•°æ®ç»“æ„è®¾è®¡è‡³å…³é‡è¦**ï¼šBVSS æˆåŠŸè§£å†³äº† warp è´Ÿè½½ä¸å‡å’Œ frontier-oblivious è°ƒåº¦é—®é¢˜ï¼Œæ˜¯æ€§èƒ½æå‡çš„åŸºç¡€ã€‚
3. **å›¾æ„ŸçŸ¥çš„é¢„å¤„ç†ç­–ç•¥æœ‰æ•ˆ**ï¼š
   - ç¤¾äº¤å›¾é€‚åˆç¤¾åŒºæ„ŸçŸ¥é‡æ’åºï¼ˆæé«˜å‹ç¼©ç‡ï¼‰ã€‚
   - é“è·¯å›¾é€‚åˆå¸¦å®½ç¼©å‡é‡æ’åºï¼ˆæ”¹å–„ cache å±€éƒ¨æ€§ï¼‰ã€‚
4. **å»¶è¿Ÿæ›´æ–°æ˜¾è‘—ç¼“è§£åŸå­ç“¶é¢ˆ**ï¼šå°¤å…¶é€‚ç”¨äºç¤¾äº¤ç½‘ç»œè¿™ç±»ä½ç›´å¾„ã€é«˜å¹¶å‘ frontier çš„åœºæ™¯ã€‚
5. **å†…æ ¸èåˆæ¶ˆé™¤åŒæ­¥å¼€é”€**ï¼šå¯¹äºé•¿è·¯å¾„å›¾ï¼ˆå¦‚é“è·¯ç½‘ï¼‰å°¤ä¸ºé‡è¦ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

1. **é™æ€æ‰§è¡Œç­–ç•¥**ï¼šå½“å‰ BLEST é‡‡ç”¨å›ºå®šçš„ä¼˜åŒ–ç»„åˆï¼Œæ— æ³•åƒ GSWITCH é‚£æ ·åŠ¨æ€åˆ‡æ¢ç­–ç•¥ã€‚åœ¨å°‘æ•°å›¾ä¸Šï¼ˆå¦‚ `mawi`, `Spielman_k600`ï¼‰å› è¯¯å¯ lazy update å¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚
2. **lazy update å¼€é”€æ•æ„Ÿ**ï¼šè¯¥æœºåˆ¶å¼•å…¥ O(n) æ¯å±‚æ‰«æï¼Œè™½åœ¨ç¤¾äº¤å›¾ä¸Šå¯æ¥å—ï¼Œä½†åœ¨é«˜å±‚æ•°å›¾ä¸­å¯èƒ½æˆä¸ºç“¶é¢ˆã€‚
3. **é‡æ’åºæ”¶ç›Šä¾èµ–äºå›¾ç»“æ„**ï¼šéƒ¨åˆ†å›¾å¤©ç„¶å…·æœ‰è‰¯å¥½é¡ºåºï¼Œäººå·¥é‡æ’åºåè€Œå¯èƒ½ç ´ååŸæœ‰å±€éƒ¨æ€§ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ„å»ºåŠ¨æ€å†³ç­–ç®¡é“**ï¼šæ ¹æ®å›¾ç‰¹å¾å’Œè¿è¡Œæ—¶çŠ¶æ€æ™ºèƒ½é€‰æ‹©æ˜¯å¦å¯ç”¨ lazy update æˆ–ç‰¹å®šé‡æ’åºç­–ç•¥ã€‚
2. **æ‰©å±•è‡³å¤šæº BFS åº”ç”¨**ï¼šå¦‚ closeness centralityã€diameter computation ç­‰ã€‚
3. **è·¨æ¶æ„ç§»æ¤**ï¼šå°† BLEST ç§»æ¤åˆ° AMD GPUï¼ˆåŒæ ·å…·å¤‡ MMA å•å…ƒï¼‰ã€‚
4. **åŠ¨æ€æ‰§è¡Œæµè°ƒæ§**ï¼šåŸºäºå½“å‰ frontier ç‰¹å¾å®æ—¶è°ƒæ•´è°ƒåº¦å’Œè®¡ç®—ç­–ç•¥ã€‚

--- 

> âœ… **æ€»ç»“**ï¼šBLEST æ˜¯é¦–ä¸ªç³»ç»Ÿæ€§åœ°å°† Tensor Cores é«˜æ•ˆåº”ç”¨äº BFS çš„å·¥ä½œï¼Œé€šè¿‡ **BVSS æ•°æ®ç»“æ„ã€å›¾æ„ŸçŸ¥é‡æ’åºã€æœ€ä¼˜ TC å¸ƒå±€ã€å»¶è¿Ÿæ›´æ–°å’Œå†…æ ¸èåˆ** äº”å¤§æŠ€æœ¯åˆ›æ–°ï¼Œåœ¨å¤šç§çœŸå®å›¾ä¸Šå®ç°äº† **3.5â€“13Ã—** çš„æ€§èƒ½æå‡ï¼Œæ ‡å¿—ç€ TC åœ¨å›¾è®¡ç®—é¢†åŸŸçš„é‡è¦çªç ´ã€‚

</details>

---

### 8. [A Reinforcement Learning Approach to Synthetic Data Generation](https://arxiv.org/abs/2512.21395)

**Authors**: Natalia Espinosa-Dice, Nicholas J. Jackson, Chao Yan, Aaron Lee, Bradley A. Malin  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.21395v1  

#### Abstract
Synthetic data generation (SDG) is a promising approach for enabling data sharing in biomedical studies while preserving patient privacy. Yet, state-of-the-art generative models often require large datasets and complex training procedures, limiting their applicability in small-sample settings. In th...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šA Reinforcement Learning Approach to Synthetic Data Generation

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰ä¸»æµçš„ **Synthetic Data Generation (SDG)** æ–¹æ³•ï¼ˆå¦‚ GANs å’Œ diffusion modelsï¼‰é€šå¸¸ä¾èµ–å¤§è§„æ¨¡è®­ç»ƒæ•°æ®å’Œå¤æ‚çš„è®­ç»ƒè¿‡ç¨‹ï¼Œåœ¨å°æ ·æœ¬ç”Ÿç‰©åŒ»å­¦åœºæ™¯ä¸‹è¡¨ç°ä¸ä½³ã€‚æ­¤å¤–ï¼š
- **GANs** å­˜åœ¨è®­ç»ƒä¸ç¨³å®šã€æ¨¡å¼å´©æºƒï¼ˆmode collapseï¼‰ã€æ¢¯åº¦æ¶ˆå¤±ç­‰é—®é¢˜ï¼›
- **Diffusion models** è™½ç„¶æ€§èƒ½ä¼˜è¶Šï¼Œä½†è®¡ç®—æˆæœ¬é«˜ã€æ˜“è®°å¿†è®­ç»ƒæ•°æ®ï¼ˆmemorizationï¼‰ï¼Œå­˜åœ¨éšç§é£é™©ï¼Œä¸”å¯¹å°æ•°æ®é›†æ³›åŒ–èƒ½åŠ›å·®ã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº†å®ƒä»¬åœ¨çœŸå®ä¸–ç•Œä¸­å°å‹ã€é«˜è´¨é‡ä¸´åºŠç ”ç©¶æ•°æ®é›†ä¸Šçš„åº”ç”¨ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šRLSyn
æœ¬æ–‡æå‡º **RLSyn** â€”â€”ä¸€ç§åŸºäº **Reinforcement Learning (RL)** çš„æ–°å‹åˆæˆæ•°æ®ç”Ÿæˆæ¡†æ¶ï¼Œå°† SDG é‡æ–°å»ºæ¨¡ä¸ºä¸€ä¸ª **é€†å¼ºåŒ–å­¦ä¹ ï¼ˆinverse RLï¼‰é—®é¢˜**ï¼š
- å°†ç”Ÿæˆå™¨è§†ä¸ºä¸€ä¸ª**éšæœºç­–ç•¥ï¼ˆstochastic policyï¼‰**ï¼Œè¾“å‡ºæ•´ä¸ªæ‚£è€…è®°å½•çš„æ¦‚ç‡åˆ†å¸ƒï¼›
- ä½¿ç”¨ **Proximal Policy Optimization (PPO)** è¿›è¡Œä¼˜åŒ–ï¼Œé€šè¿‡åˆ¤åˆ«å™¨ï¼ˆdiscriminatorï¼‰æä¾›çš„å¥–åŠ±ä¿¡å·æŒ‡å¯¼å­¦ä¹ ï¼›
- åˆ¤åˆ«å™¨ä»…ä½œä¸ºâ€œå¥–åŠ±æä¾›è€…â€ï¼Œä¸å‚ä¸ç”Ÿæˆå™¨çš„æ¢¯åº¦æ›´æ–°ï¼Œé¿å…äº† GAN ä¸­çš„å¯¹æŠ—æ€§æœ€å°æœ€å¤§åšå¼ˆã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | RLSyn | GANs | Diffusion Models |
|------|-------|------|----------------|
| **è®­ç»ƒç¨³å®šæ€§** | é«˜ï¼ˆPPO + clipped updatesï¼‰ | ä½ï¼ˆéå¹³ç¨³æŸå¤±ï¼‰ | ä¸­ç­‰ |
| **æ•°æ®æ•ˆç‡** | é«˜ï¼ˆé€‚åˆå°æ ·æœ¬ï¼‰ | ä¸€èˆ¬ | ä½ï¼ˆéœ€å¤§æ•°æ®ï¼‰ |
| **éšç§ä¿æŠ¤** | æ›´å¥½ï¼ˆå‡å°‘è®°å¿†åŒ–ï¼‰ | å¯æ§ | å·®ï¼ˆæ˜“å¤åˆ¶è®­ç»ƒæ ·æœ¬ï¼‰ |
| **å¤šæ ·æ€§ä¿éšœ** | æ˜¾å¼å»ºæ¨¡æ–¹å·®ï¼ˆGaussian è¾“å‡ºï¼‰ | å®¹æ˜“æ¨¡å¼åå¡Œ | å¯èƒ½è¿‡æ‹Ÿåˆ |

> âœ… **æ ¸å¿ƒåˆ›æ–°**ï¼šé¦–æ¬¡ç³»ç»Ÿåœ°å°† RL åº”ç”¨äºé«˜ç»´ä¸´åºŠè¡¨æ ¼æ•°æ®çš„åˆæˆç”Ÿæˆï¼Œå¹¶è¯æ˜å…¶åœ¨å°æ ·æœ¬åœºæ™¯ä¸‹çš„ä¼˜è¶Šæ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | æè¿° | æ ·æœ¬é‡ | ç‰¹å¾æ•° |
|--------|------|--------|--------|
| **AI-READI** | 2å‹ç³–å°¿ç—…å¤šä¸­å¿ƒé˜Ÿåˆ—ï¼Œå«ç©¿æˆ´è®¾å¤‡ä¸ ECG æ•°æ® | 4,537 person-days | 108ï¼ˆ72è¿ç»­ + 36åˆ†ç±»ï¼‰ |
| **MIMIC-IV** | æ€¥è¯Šé‡ç—‡ç›‘æŠ¤ç”µå­ç—…å†æ•°æ® | 180,746 patient stays | 180+ï¼ˆç»phecodeæ˜ å°„åï¼‰ |

> æ³¨ï¼šAI-READI æ˜¯è¾ƒå°çš„æ•°æ®é›†ï¼Œç”¨äºæµ‹è¯•å°æ ·æœ¬æ€§èƒ½ï¼›MIMIC-IV æ˜¯è¾ƒå¤§æ ‡å‡†æ•°æ®é›†ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **æ•°æ®åˆ’åˆ†**ï¼š
  - AI-READIï¼š90%/10% è®­ç»ƒ/æµ‹è¯•
  - MIMIC-IVï¼š70%/30%
- **è¶…å‚æ•°è°ƒä¼˜**ï¼šä½¿ç”¨ Optuna è¿›è¡Œ 20 è½®æœç´¢ï¼Œé€‰æ‹©æœ€ä¼˜é…ç½®ï¼ˆè§é™„å½•è¡¨ A.3ï¼‰
- **é‡å¤å®éªŒ**ï¼šæ¯ç§æ¨¡å‹åœ¨ 10 ç§ä¸åŒ train-test split ä¸Šè¿è¡Œå¹¶å–å¹³å‡å€¼

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡

#### ï¼ˆ1ï¼‰Privacyï¼ˆéšç§ï¼‰
- **Membership Inference Attack (MIA)**ï¼šæ”»å‡»è€…åˆ¤æ–­æŸçœŸå®ä¸ªä½“æ˜¯å¦å‚ä¸è®­ç»ƒã€‚
- æŒ‡æ ‡ï¼šAUROCï¼ˆè¶Šæ¥è¿‘ 0.5 è¡¨ç¤ºéšç§è¶Šå¥½ï¼‰

#### ï¼ˆ2ï¼‰Utilityï¼ˆå®ç”¨æ€§ï¼‰
- **S2Rï¼ˆSynthetic-to-Realï¼‰åˆ†ç±»ä»»åŠ¡**ï¼š
  - AI-READIï¼šé¢„æµ‹ç³–å°¿ç—…ä¸¥é‡ç¨‹åº¦
  - MIMIC-IVï¼šé¢„æµ‹ä¸€å¹´å†…æ­»äº¡ç‡
- æŒ‡æ ‡ï¼šAUCï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰

#### ï¼ˆ3ï¼‰Fidelityï¼ˆä¿çœŸåº¦ï¼‰
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **CWC (Column-wise Correlation Differences)** | åˆæˆä¸çœŸå®æ•°æ®ç›¸å…³æ€§çŸ©é˜µçš„å¹³å‡ç»å¯¹å·®å¼‚ï¼ˆè¶Šä½è¶Šå¥½ï¼‰ |
| **NMI (Normalized Mutual Information)** | åœ¨ PCA + k-means èšç±»åï¼Œèšç±»æ ‡ç­¾ä¸â€œçœŸå®/åˆæˆâ€æ ‡ç­¾çš„ç›¸å…³æ€§ï¼ˆè¶Šä½è¡¨ç¤ºåˆ†å¸ƒè¶Šç›¸ä¼¼ï¼‰ |
| **DWD (Dimension-wise Difference)** | å•ä¸ªç‰¹å¾å±‚é¢çš„åˆ†å¸ƒå·®å¼‚ï¼ˆåˆ†ç±»ç”¨ APDï¼Œè¿ç»­ç”¨ AWDï¼‰ |
| **R2S (Real-to-Synthetic)** | åˆ†ç±»å™¨åœ¨çœŸå®æ•°æ®ä¸Šè®­ç»ƒï¼Œåœ¨åˆæˆæ•°æ®ä¸Šæµ‹è¯•ï¼Œæ£€éªŒç»Ÿè®¡ä¸€è‡´æ€§ |

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ¨¡å‹ | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **EMR-WGAN** | GAN-based | é’ˆå¯¹ EHR è®¾è®¡çš„ WGAN-GPï¼Œå¼ºè°ƒéšç§ |
| **EHRDiff** | Diffusion-based | å½“å‰æœ€å…ˆè¿›çš„æ‰©æ•£æ¨¡å‹ï¼Œä¸“ä¸º EHR ä¼˜åŒ– |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### ï¼ˆ1ï¼‰Privacyï¼ˆè¡¨ 1ï¼‰
| æ¨¡å‹ | MIMIC-IV (AUROC) | AI-READI (AUROC) |
|------|------------------|------------------|
| Real Data | 0.998 | 1.000 |
| EMR-WGAN | 0.498 Â± 0.002 | **0.501 Â± 0.026** |
| EHRDiff | 0.499 Â± 0.002 | 0.601 Â± 0.036 |
| **RLSyn** | **0.499 Â± 0.002** | **0.544 Â± 0.030** |

> ğŸ’¡ æ‰€æœ‰æ¨¡å‹åœ¨ MIMIC-IV ä¸Šå‡æ¥è¿‘éšæœºçŒœæµ‹ï¼ˆç†æƒ³çŠ¶æ€ï¼‰ã€‚ä½†åœ¨ AI-READI ä¸Šï¼Œ**EHRDiff å‡ºç°æ˜æ˜¾éšç§æ³„éœ²**ï¼ˆAUROC > 0.6ï¼‰ï¼Œè€Œ RLSyn å’Œ EMR-WGAN æ›´å®‰å…¨ã€‚

#### ï¼ˆ2ï¼‰Utilityï¼ˆå›¾ 2ï¼ŒS2Rï¼‰
| æ¨¡å‹ | MIMIC-IV (AUC) | AI-READI (AUC) |
|------|----------------|----------------|
| EMR-WGAN | 0.764 | 0.747 |
| EHRDiff | 0.906 | 0.871 |
| **RLSyn** | **0.902** | **0.873** |

> âœ… RLSyn åœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸Šéƒ½æ˜¾è‘—ä¼˜äº GANï¼Œåœ¨å°æ•°æ®é›† AI-READI ä¸Šç•¥èƒœ diffusionã€‚

#### ï¼ˆ3ï¼‰Fidelityï¼ˆè¡¨ 2ï¼‰
| æŒ‡æ ‡ | æ¨¡å‹ | MIMIC-IV | AI-READI |
|------|------|----------|----------|
| **CWC â†“** | EMR-WGAN | 11.852 | 1.352 |
| | EHRDiff | 7.848 | **0.427** |
| | **RLSyn** | 8.877 | 0.750 |
| **NMI â†“** | EMR-WGAN | 0.320 | 0.809 |
| | EHRDiff | 0.003 | 0.002 |
| | **RLSyn** | **0.001** | **0.001** |
| **DWD â†“** | EMR-WGAN | 17.642 | 77.056 |
| | EHRDiff | 2.797 | 16.441 |
| | **RLSyn** | **2.073** | **13.352** |

> âœ… RLSyn åœ¨ **NMI å’Œ DWD ä¸Šå…¨é¢é¢†å…ˆ**ï¼Œè¯´æ˜å…¶ç”Ÿæˆçš„æ•°æ®åˆ†å¸ƒæœ€æ¥è¿‘çœŸå®æ•°æ®ã€‚

#### ï¼ˆ4ï¼‰R2S åˆ†æ
- åœ¨ AI-READI ä¸Šï¼Œ**EHRDiff çš„ R2S AUCï¼ˆ0.901ï¼‰é«˜äº R2R åŸºçº¿ï¼ˆ0.870ï¼‰** â†’ è¡¨æ˜å…¶å¯èƒ½**è¿‡æ‹Ÿåˆæˆ–å¤åˆ¶è®­ç»ƒæ•°æ®**ï¼›
- RLSyn çš„ R2S è¡¨ç°åˆç†ï¼ˆ0.868ï¼‰ï¼Œæ— å¼‚å¸¸æå‡ï¼Œè¯´æ˜æœªè¿‡åº¦è®°å¿†ã€‚

#### ï¼ˆ5ï¼‰å¯è§†åŒ–åˆ†æï¼ˆå›¾ 3 & å›¾ 4ï¼‰
- **PCA æ•£ç‚¹å›¾**æ˜¾ç¤º RLSyn å’Œ EHRDiff çš„åˆæˆæ•°æ®è¦†ç›–çœŸå®æ•°æ®åˆ†å¸ƒè‰¯å¥½ï¼Œè€Œ EMR-WGAN æ˜æ˜¾æ”¶ç¼©ï¼›
- **APD ä¸ AWD å¯¹æ¯”å›¾**è¡¨æ˜ RLSyn æ›´å‡†ç¡®è¿˜åŸç½•è§ç–¾ç—…å’Œè¿ç»­å˜é‡åˆ†å¸ƒã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **RLSyn åœ¨å°æ ·æœ¬åœºæ™¯ä¸‹æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•**ï¼š
   - åœ¨ AI-READIï¼ˆä»… ~4.5k æ ·æœ¬ï¼‰ä¸Šï¼ŒRLSyn åœ¨ utility å’Œ fidelity ä¸Šå‡è¶…è¿‡ EHRDiff å’Œ EMR-WGANï¼›
   - åŒæ—¶ä¿æŒè¾ƒä½éšç§é£é™©ï¼ˆAUROC â‰ˆ 0.54ï¼‰ï¼Œä¼˜äº EHRDiffï¼ˆ0.601ï¼‰ã€‚

2. **RL æä¾›æ›´ç¨³å®šã€æ›´é«˜æ•ˆçš„å­¦ä¹ æœºåˆ¶**ï¼š
   - PPO çš„ clipped objective æŠ‘åˆ¶äº†æ¨¡å¼å´©æºƒï¼›
   - æ˜¾å¼å»ºæ¨¡è¾“å‡ºåˆ†å¸ƒï¼ˆÎ¼ å’Œ Ïƒï¼‰æå‡äº†æ ·æœ¬å¤šæ ·æ€§ï¼›
   - éå¯¹æŠ—å¼è®­ç»ƒé¿å…äº† GAN çš„æ¢¯åº¦ä¸ç¨³å®šé—®é¢˜ã€‚

3. **Diffusion æ¨¡å‹å­˜åœ¨è®°å¿†åŒ–å€¾å‘**ï¼š
   - EHRDiff åœ¨å°æ•°æ®é›†ä¸Šè¡¨ç°å‡ºæ›´é«˜çš„ MIA æ”»å‡»æˆåŠŸç‡å’Œå¼‚å¸¸é«˜çš„ R2S æ€§èƒ½ï¼Œæç¤ºå…¶å¯èƒ½â€œè®°ä½â€è€Œéâ€œæ³›åŒ–â€ã€‚

4. **GAN è¡¨ç°æœ€å¼±**ï¼š
   - EMR-WGAN è™½ç„¶éšç§æœ€å¥½ï¼Œä½† utility å’Œ fidelity æä½ï¼Œåæ˜ å…¶æœªèƒ½æœ‰æ•ˆå­¦ä¹ æ•°æ®åˆ†å¸ƒã€‚

### âš ï¸ å±€é™æ€§
1. **ç›®å‰ä»…é€‚ç”¨äºæ¨ªæ–­é¢è¡¨æ ¼æ•°æ®**ï¼ˆcross-sectional tabular dataï¼‰ï¼Œå°šæœªæ‰©å±•åˆ°æ—¶é—´åºåˆ—ã€æ–‡æœ¬æˆ–å›¾åƒï¼›
2. **æœºåˆ¶è§£é‡Šä¸è¶³**ï¼šå°šä¸æ¸…æ¥šæ˜¯ PPO è¿˜æ˜¯ç­–ç•¥å‚æ•°åŒ–è®¾è®¡ä¸»å¯¼äº†æ€§èƒ½ä¼˜åŠ¿ï¼›
3. **ç†è®ºè”ç³»å¾…æ·±åŒ–**ï¼šä¸ Inverse RLã€Energy-Based Models çš„å…³ç³»æœ‰å¾…è¿›ä¸€æ­¥æ¢ç´¢ï¼›
4. **å¥–åŠ±å‡½æ•°å›ºå®š**ï¼šå½“å‰ä»ä¾èµ– discriminator æä¾› rewardï¼Œæœªæ¥å¯å°è¯•æ— åˆ¤åˆ«å™¨çš„ç»Ÿè®¡æŒ‡æ ‡å¥–åŠ±ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. æ‰©å±•è‡³ **longitudinal EHRã€clinical notesã€medical imaging** ç­‰å¤æ‚æ¨¡æ€ï¼›
2. æ¢ç´¢ **æ›¿ä»£ reward å‡½æ•°**ï¼Œä¾‹å¦‚åŸºäº Wasserstein è·ç¦»ã€äº’ä¿¡æ¯æˆ–å…¶ä»–ç»Ÿè®¡è·ç¦»ï¼›
3. å¼•å…¥ **privacy-aware reward shaping**ï¼Œç›´æ¥ä¼˜åŒ–éšç§-æ•ˆç”¨æƒè¡¡ï¼›
4. å¼€å‘ **lightweight RL æ¶æ„**ï¼Œé™ä½éƒ¨ç½²é—¨æ§›ï¼›
5. æ·±å…¥ç ”ç©¶ **RL ä¸ç”Ÿæˆæ¨¡å‹çš„ç†è®ºç»Ÿä¸€æ¡†æ¶**ï¼ˆå¦‚ä¸ GANã€diffusion çš„è”ç³»ï¼‰ã€‚

---

## âœ… æ€»ç»“
**RLSyn æˆåŠŸå°†å¼ºåŒ–å­¦ä¹ å¼•å…¥åˆæˆåŒ»ç–—æ•°æ®ç”Ÿæˆé¢†åŸŸï¼Œæå‡ºäº†ä¸€ç§ç¨³å®šã€é«˜æ•ˆã€éšç§å‹å¥½çš„æ–°èŒƒå¼ã€‚å®ƒåœ¨å°æ ·æœ¬æ¡ä»¶ä¸‹æ˜¾è‘—ä¼˜äº GAN å’Œ diffusion æ¨¡å‹ï¼Œå°¤å…¶é€‚åˆèµ„æºæœ‰é™çš„çœŸå®ç§‘ç ”åœºæ™¯ã€‚è¯¥å·¥ä½œä¸ä»…æä¾›äº†å®ç”¨å·¥å…·ï¼Œä¹Ÿä¸ºä¸‹ä¸€ä»£éšç§ä¿æŠ¤å‹ AI æä¾›äº†æ–°çš„æ–¹æ³•è®ºè·¯å¾„ã€‚**

</details>

---

### 9. [RLLaVA: An RL-central Framework for Language and Vision Assistants](https://arxiv.org/abs/2512.21450)

**Authors**: Lei Zhao, Zihao Ma, Boyu Lin, Yuhe Liu, Wenjun Wu, Lei Huang  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.21450v1  

#### Abstract
We present an RL-central framework for Language and Vision Assistants (RLLaVA) with its formulation of Markov decision process (MDP). RLLaVA decouples RL algorithmic logic from model architecture and distributed execution, supporting researchers in implementing new RL algorithms with minimal code, a...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# RLLaVA: An RL-central Framework for Language and Vision Assistants è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰å¤šæ¨¡æ€å¼ºåŒ–å­¦ä¹ ï¼ˆMulti-modal Reinforcement Learning, RLï¼‰ç ”ç©¶é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **ç¼ºä¹ä¸“ä¸ºè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰è®¾è®¡çš„RLæ¡†æ¶**ï¼šç°æœ‰RLæ¡†æ¶ï¼ˆå¦‚veRLã€OpenRLHFï¼‰ä¸»è¦é¢å‘çº¯æ–‡æœ¬å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œæœªå……åˆ†è€ƒè™‘å¤šæ¨¡æ€æ•°æ®ä¼ è¾“ã€ç¯å¢ƒä¸­çš„è§†è§‰åé¦ˆç­‰ç‰¹æ€§ã€‚
- **ç®—æ³•é€»è¾‘ä¸ç³»ç»Ÿå®ç°é«˜åº¦è€¦åˆ**ï¼šå¤§å¤šæ•°æ¡†æ¶å°†RLç®—æ³•ä¸åˆ†å¸ƒå¼è®­ç»ƒç­–ç•¥ç´§å¯†ç»‘å®šï¼Œå¯¼è‡´ç ”ç©¶äººå‘˜éš¾ä»¥å¿«é€Ÿè¿­ä»£æ–°ç®—æ³•ã€‚
- **èµ„æºé—¨æ§›é«˜**ï¼šå¤šæ•°æ¡†æ¶ä¾èµ–å¤§è§„æ¨¡GPUé›†ç¾¤ï¼Œé™åˆ¶äº†èµ„æºæœ‰é™çš„ç ”ç©¶å›¢é˜Ÿå¼€å±•å¤šæ¨¡æ€RLå®éªŒã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **RLLaVA** â€”â€” ä¸€ä¸ªä»¥å¼ºåŒ–å­¦ä¹ ä¸ºä¸­å¿ƒçš„æ¨¡å—åŒ–æ¡†æ¶ï¼Œä¸“ä¸ºè¯­è¨€ä¸è§†è§‰åŠ©æ‰‹ï¼ˆLanguage and Vision Assistantsï¼‰è®¾è®¡ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰ç»Ÿä¸€çš„MDPå»ºæ¨¡
å°†è§†è§‰-è¯­è¨€è”åˆå†³ç­–è¿‡ç¨‹å½¢å¼åŒ–ä¸ºç»Ÿä¸€çš„ **Markov Decision Process (MDP)**ï¼ŒçŠ¶æ€ç©ºé—´ $S = (V \cup Z)^*$ åŒ…å«æ–‡æœ¬å’Œå›¾åƒï¼ŒåŠ¨ä½œç©ºé—´ä¸ºtokenåºåˆ—ç”Ÿæˆï¼Œå¥–åŠ±å‡½æ•°å¯çµæ´»å®šä¹‰ï¼Œä¸ºå¤šç§RLç®—æ³•æä¾›ç†è®ºåŸºç¡€ã€‚

#### ï¼ˆ2ï¼‰ä¸‰é‡è§£è€¦æ¶æ„è®¾è®¡
RLLaVAé‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œå®ç°ä¸‰ä¸ªç»´åº¦çš„è§£è€¦ï¼š
- **ç®—æ³•é€»è¾‘ï¼ˆAlgorithmic Logicï¼‰**
- **æ¨¡å‹æ¶æ„ï¼ˆModel Architectureï¼‰**
- **åˆ†å¸ƒå¼æ‰§è¡Œï¼ˆDistributed Executionï¼‰**

è¿™ç§è®¾è®¡å…è®¸ç ”ç©¶è€…åœ¨ä¸ä¿®æ”¹åº•å±‚ç³»ç»Ÿçš„æƒ…å†µä¸‹æ’æ‹”ä¸åŒRLç®—æ³•ï¼ˆå¦‚PPOã€GRPOã€OPOï¼‰ã€VLMæ¨¡å‹ï¼ˆå¦‚Qwen-VLã€Phi-VLï¼‰ä»¥åŠè®­ç»ƒ/æ¨ç†å¼•æ“ï¼ˆå¦‚FSDPã€DeepSpeedã€vLLMã€SGLangï¼‰ã€‚

#### ï¼ˆ3ï¼‰è½»é‡çº§ä¸èµ„æºé«˜æ•ˆè®­ç»ƒ
- æ”¯æŒåœ¨å•å¼ 24GB GPUä¸Šå¯¹ **4Bè§„æ¨¡æ¨¡å‹è¿›è¡Œç«¯åˆ°ç«¯å…¨å‚æ•°æ›´æ–°è®­ç»ƒ**ã€‚
- é€šè¿‡ **å…±å€æ‰§è¡Œç­–ç•¥ï¼ˆco-located executionï¼‰** å¤ç”¨GPUå†…å­˜ï¼šrollouté˜¶æ®µå°†è®­ç»ƒçŠ¶æ€å¸è½½è‡³CPUï¼›ä¼˜åŒ–é˜¶æ®µå…³é—­æ¨ç†å¼•æ“ï¼Œé¿å…å†…å­˜å†²çªã€‚
- é›†æˆLoRAã€æ¢¯åº¦æ£€æŸ¥ç‚¹ã€åŠ¨æ€æ‰¹å¤„ç†ã€æ— å¡«å……è®­ç»ƒç­‰æŠ€æœ¯è¿›ä¸€æ­¥é™ä½æ˜¾å­˜å¼€é”€ã€‚

#### ï¼ˆ4ï¼‰å¯æ‰©å±•çš„æ’ä»¶æœºåˆ¶
æ”¯æŒé€šè¿‡é…ç½®æ–‡ä»¶åˆ‡æ¢ä¸åŒçš„ï¼š
- Advantage Estimatorï¼ˆå¦‚GAEã€GRPOã€RLOOï¼‰
- Policy Lossï¼ˆå¦‚PPO clipã€GSPOã€DAPOï¼‰
- Reward Functionï¼ˆè§„åˆ™å¥–åŠ±ã€å­¦ä¹ å‹Reward Modelã€LLM-as-Judgeï¼‰

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | RLLaVA | veRL / OpenRLHF | EasyR1 |
|------|--------|------------------|--------|
| å¤šæ¨¡æ€åŸç”Ÿæ”¯æŒ | âœ… å®Œæ•´æ”¯æŒå›¾åƒè¾“å…¥ä¸ç¯å¢ƒäº¤äº’ | âŒ ä¸»è¦é’ˆå¯¹æ–‡æœ¬ä»»åŠ¡ | âœ… æ”¯æŒä½†åŠŸèƒ½å—é™ |
| ç®—æ³•-ç³»ç»Ÿè§£è€¦ | âœ… é«˜åº¦è§£è€¦ï¼Œæ˜“äºæ‰©å±• | âš ï¸ è€¦åˆè¾ƒå¼ºï¼Œéœ€æ·±å…¥ç³»ç»Ÿç†è§£ | âš ï¸ ä»…æ”¯æŒç‰¹å®šç®—æ³• |
| å°è§„æ¨¡è®¾å¤‡å‹å¥½æ€§ | âœ… å•å¡24GBå³å¯è®­ç»ƒ4Bæ¨¡å‹ | âŒ éœ€å¤šå¡ç”šè‡³é›†ç¾¤ | âš ï¸ æœªå¼ºè°ƒèµ„æºæ•ˆç‡ |
| æ’ä»¶çµæ´»æ€§ | âœ… æ”¯æŒæ··åˆç»„ä»¶ç»„åˆï¼ˆå¦‚OPO + CLIP-COVï¼‰ | âš ï¸ æ‰©å±•æˆæœ¬é«˜ | âŒ å›ºå®šæµç¨‹ |

> âœ… æ€»ç»“ï¼šRLLaVAå¡«è¡¥äº†â€œæ˜“ç”¨ã€çµæ´»ã€èµ„æºå‹å¥½çš„å¤šæ¨¡æ€RLæ¡†æ¶â€è¿™ä¸€ç©ºç™½ï¼Œç‰¹åˆ«é€‚åˆå­¦æœ¯ç•Œå’Œä¸­å°å›¢é˜Ÿè¿›è¡ŒRLç®—æ³•æ¢ç´¢ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–äº”ç±»å¤šæ¨¡æ€ä»»åŠ¡ï¼Œæ¶µç›–æ„ŸçŸ¥ã€æ¨ç†ä¸æ™ºèƒ½ä½“è¡Œä¸ºï¼š

| ä»»åŠ¡ç±»åˆ« | æ•°æ®é›† | è¯´æ˜ |
|---------|-------|------|
| **Mathematical Reasoning** | Geometry3K [24] | åŸºäºå›¾è¡¨çš„å‡ ä½•é¢˜æ±‚è§£ |
| **Counting** | CLEVR-Count-70k [13] | ç»„åˆå¼ç‰©ä½“è®¡æ•° |
| **Grounding** | RefCOCO/+/g [14,44,25] | æŒ‡ä»£è¡¨è¾¾ç†è§£ï¼ˆå®šä½å›¾åƒä¸­æè¿°çš„å¯¹è±¡ï¼‰ |
| **Agentic-Search** | MAT-Search [22] | å¤šè½®è§†è§‰ä¿¡æ¯æ£€ç´¢ï¼ˆç»“åˆç½‘é¡µæœç´¢å·¥å…·ï¼‰ |
| **Agentic-Coding** | MAT-Coding [22] | å›¾åƒæ“ä½œç›¸å…³çš„ä»£ç ç”Ÿæˆä»»åŠ¡ |

æ­¤å¤–ï¼Œåœ¨ **LISA** [16] ä¸Šæµ‹è¯•è·¨åŸŸæ³›åŒ–èƒ½åŠ›ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®

| é¡¹ç›® | è®¾ç½®è¯¦æƒ… |
|------|----------|
| **æ¨¡å‹** | Qwen2-VL-2B, Qwen2.5-VL-3B, Qwen2.5-VL-7B |
| **è®­ç»ƒæ–¹å¼** | å…¨å‚æ•°å¾®è°ƒï¼ˆfull-parameter fine-tuningï¼‰ä¸ LoRA å¾®è°ƒ |
| **ä¸»ç®—æ³•** | GRPOï¼ˆGroup Relative Policy Optimizationï¼‰ä½œä¸ºé»˜è®¤RLç®—æ³• |
| **æ¯æç¤ºå“åº”æ•°** | 4â€“8 ä¸ªresponse per prompt |
| **è®­ç»ƒå¼•æ“** | FSDPï¼ˆFully Sharded Data Parallelï¼‰ |
| **æ¨ç†å¼•æ“** | vLLMï¼ˆç”¨äºrollouté˜¶æ®µé«˜æ•ˆç”Ÿæˆï¼‰ |
| **ä¼˜åŠ¿ä¼°è®¡å™¨** | GRPOè‡ªå¸¦group-normalized advantage estimation |
| **æ­£åˆ™é¡¹** | KL-to-referenceï¼ˆç›¸å¯¹äºSFTæ¨¡å‹ï¼‰ã€entropy bonusç­‰ |

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡

| ä»»åŠ¡ | ä¸»è¦æŒ‡æ ‡ |
|------|----------|
| Math | Accuracy |
| Counting | Accuracy |
| Grounding | IoUï¼ˆIntersection over Unionï¼‰ |
| Agentic-Search / Coding | F1 Scoreï¼ˆSimple / Hard / Allï¼‰ |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Base Model**ï¼šæœªç»RLå¾®è°ƒçš„åŸå§‹VLMï¼ˆå¦‚Qwen2.5-VL-instructï¼‰
- **GRPO (ours)**ï¼šä½¿ç”¨RLLaVAè®­ç»ƒçš„æ¨¡å‹
- **Visual-ARFT [22]**ï¼šå½“å‰æœ€å…ˆè¿›çš„å¤šæ¨¡æ€agentic RLæ–¹æ³•ï¼Œä½¿ç”¨ä¸“é—¨æ¶æ„ä¸è®­ç»ƒæµç¨‹

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| Task | Model | Dataset | Metric | Base | GRPO (Ours) | Î” |
|------|-------|--------|--------|------|-------------|----|
| Math | Qwen2.5-VL-3B | Geometry3K | Accuracy | 35.1 | **39.0** | +3.9 |
| Counting | Qwen2.5-VL-3B | CLEVR-Count | Accuracy | 52.0 | **57.5** | +5.5 |
| Grounding | Qwen2-VL-2B | RefCOCO/+/g | IoU | 51.3 | **63.3** | +12.0 |
| Search | Qwen2.5-VL-3B | MAT-Search | F1 | 4.4 | **27.1** | +22.7 |
| Coding | Qwen2.5-VL-3B | MAT-Coding | F1 | 16.9 | **30.6** | +13.7 |

> ğŸ’¡ **è§‚å¯Ÿ**ï¼šRLå¾®è°ƒæ˜¾è‘—æå‡æ‰€æœ‰ä»»åŠ¡è¡¨ç°ï¼Œå°¤å…¶åœ¨**agenticä»»åŠ¡**ï¼ˆSearchã€Codingï¼‰ä¸Šæå‡å·¨å¤§ï¼ˆ>20 F1ï¼‰ï¼Œè¡¨æ˜RLLaVAæœ‰æ•ˆå¢å¼ºäº†æ¨¡å‹çš„å·¥å…·ä½¿ç”¨ä¸å¤šè½®æ¨ç†èƒ½åŠ›ã€‚

---

### ğŸ”„ æ³›åŒ–èƒ½åŠ›åˆ†æï¼ˆTable 2ï¼šVisual Grounding on LISAï¼‰

| Model | RefCOCO | RefCOCO+ | RefCOCOg | **LISA (OOD)** |
|-------|--------|----------|-----------|----------------|
| Base (Qwen2-VL-2B) | 54.79 | 51.48 | 56.75 | **20.78** |
| GRPO (300æ­¥) | 67.14 | 60.43 | 61.43 | **31.88** |
| Î” | +12.35 | +8.95 | +4.68 | **+11.10** |

> âœ… åœ¨**è·¨åŸŸæ•°æ®é›†LISA**ä¸Šä»å–å¾—å¤§å¹…æå‡ï¼ˆ+11.10 IoUï¼‰ï¼Œè¯´æ˜RLè®­ç»ƒæå‡äº†è¯­ä¹‰ç†è§£å’Œæ³›åŒ–èƒ½åŠ›ï¼Œè€Œéç®€å•è®°å¿†è®­ç»ƒæ¨¡å¼ã€‚

---

### ğŸ”¬ ä¸SOTAæ–¹æ³•å¯¹æ¯”ï¼ˆFigure 2ï¼‰

| æ–¹æ³• | Agentic-Search (All F1) | Agentic-Coding (All F1) |
|------|--------------------------|--------------------------|
| Visual-ARFT-7B | 26.78 | **35.2** |
| **Ours (Qwen2.5-VL-3B-GRPO)** | **27.10** | 30.6 |

> âœ… åœ¨**Agentic-Search**ä»»åŠ¡ä¸Šï¼Œ**3Bæ¨¡å‹è¶…è¶Š7Bçš„Visual-ARFT**ï¼ˆ+0.32 F1ï¼‰ï¼Œè¯æ˜RLLaVAè®­ç»ƒçš„æœ‰æ•ˆæ€§ï¼›
> âš ï¸ åœ¨**Agentic-Coding**ä¸Šä»æœ‰å·®è·ï¼Œä½†ç›¸æ¯”baseå·²å¤§å¹…æå‡ï¼ˆ+13.7ï¼‰ï¼Œæ˜¾ç¤ºæ½œåŠ›ã€‚

---

### ğŸ” æ¶ˆèå®éªŒï¼ˆæ–‡ä¸­è™½æœªå•ç‹¬åˆ—å‡ºè¡¨æ ¼ï¼Œä½†ä»å®ç°æœºåˆ¶å¯æ¨æ–­ï¼‰

- **å…±å€æ‰§è¡Œç­–ç•¥**ï¼šå¯ç”¨åå¯åœ¨å•å¡24GBè¿è¡Œ4Bæ¨¡å‹ï¼Œå¦åˆ™OOMã€‚
- **FSDP2 Offload**ï¼šé»˜è®¤å¼€å¯ï¼Œä½¿å¤§éƒ¨åˆ†ä»»åŠ¡å¯åœ¨æ¶ˆè´¹çº§GPUå®Œæˆã€‚
- **LoRA + Gradient Checkpointing**ï¼šæ˜¾è‘—å‡å°‘å¯è®­ç»ƒå‚æ•°ä¸å³°å€¼æ˜¾å­˜ã€‚
- **Advantage Estimatoré€‰æ‹©**ï¼šæ”¯æŒGRPOã€RLOOã€GAEç­‰å¤šç§ç­–ç•¥è‡ªç”±åˆ‡æ¢ï¼ŒéªŒè¯äº†æ’ä»¶ç³»ç»Ÿçš„æœ‰æ•ˆæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **RLLaVAå®ç°äº†çœŸæ­£çš„â€œç®—æ³•-æ¨¡å‹-ç³»ç»Ÿâ€ä¸‰é‡è§£è€¦**ï¼Œæå¤§é™ä½äº†å¤šæ¨¡æ€RLç ”ç©¶çš„æŠ€æœ¯é—¨æ§›ã€‚
2. **RLå¾®è°ƒèƒ½æ˜¾è‘—æå‡VLMåœ¨å¤æ‚ä»»åŠ¡ä¸Šçš„è¡¨ç°**ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¤šè½®äº¤äº’ã€å·¥å…·è°ƒç”¨çš„agenticåœºæ™¯ä¸­æ•ˆæœçªå‡ºã€‚
3. **å³ä½¿ä½¿ç”¨è¾ƒå°è§„æ¨¡æ¨¡å‹ï¼ˆ3Bï¼‰**ï¼Œä¹Ÿèƒ½é€šè¿‡RLè®­ç»ƒè¾¾åˆ°ç”šè‡³è¶…è¿‡æ›´å¤§æ¨¡å‹ï¼ˆ7Bï¼‰åœ¨æŸäº›ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚
4. **è‰¯å¥½çš„è·¨åŸŸæ³›åŒ–èƒ½åŠ›** è¡¨æ˜RLè®­ç»ƒä¿ƒè¿›äº†æ·±å±‚è¯­ä¹‰ç†è§£ï¼Œè€Œéè¿‡æ‹Ÿåˆç‰¹å®šä»»åŠ¡æ ¼å¼ã€‚

---

### âš ï¸ å±€é™æ€§

1. **ç›®å‰ä¸»è¦éªŒè¯åŸºäºGRPOç®—æ³•**ï¼Œå…¶ä»–RLç®—æ³•ï¼ˆå¦‚OPOã€RLOOï¼‰å°šæœªå…¨é¢æ¯”è¾ƒå…¶ç›¸å¯¹ä¼˜åŠ£ã€‚
2. **æœªæ”¯æŒå®Œæ•´çš„tool-useç”Ÿæ€æ„å»º**ï¼šè™½ç„¶å¯ç”¨äºagenticä»»åŠ¡ï¼Œä½†ç¼ºä¹å†…ç½®çš„tool callingä¸environment simulationæ¨¡å—ï¼ˆä½œè€…å·²åœ¨Future Workä¸­æåŠï¼‰ã€‚
3. **å¯¹è¶…å¤§è§„æ¨¡æ¨¡å‹ï¼ˆ>7Bï¼‰çš„æ”¯æŒæœ‰é™**ï¼šå°½ç®¡æ”¯æŒ4Bå•å¡è®­ç»ƒï¼Œä½†æ›´å¤§æ¨¡å‹ä»éœ€å¤šå¡æˆ–é›†ç¾¤ã€‚
4. **reward modelingä»ä¾èµ–å¤–éƒ¨å®šä¹‰**ï¼šè‡ªåŠ¨æ„å»ºé«˜è´¨é‡reward modelä»æ˜¯å¼€æ”¾é—®é¢˜ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘ï¼ˆåŸæ–‡Section 7ï¼‰

1. å¼€å‘å†…ç½®çš„ **tool-call å’Œ multi-turn interaction æ¨¡å—**ï¼Œå¢å¼ºVLMçš„ä»£ç†èƒ½åŠ›ã€‚
2. æ‰©å±•è‡³æ›´å¤šå¤šæ¨¡æ€agenticåœºæ™¯ï¼š
   - Pixel-level reasoningï¼ˆåƒç´ çº§æ¨ç†ï¼‰
   - GUI-agentï¼ˆå›¾å½¢ç•Œé¢ä»£ç†ï¼‰
   - Embodied AIï¼ˆå…·èº«æ™ºèƒ½ï¼‰
3. æŒç»­é›†æˆæ–°å…´çš„ **RLç®—æ³•ä¸å¤šæ¨¡æ€æ¶æ„**ã€‚
4. é¼“åŠ±ç¤¾åŒºè´¡çŒ®æ’ä»¶ï¼Œæ¨åŠ¨æ¡†æ¶ç”Ÿæ€å‘å±•ã€‚

---

## âœ… æ€»ç»“

RLLaVAæ˜¯ä¸€ä¸ª**è½»é‡ã€æ¨¡å—åŒ–ã€èµ„æºé«˜æ•ˆçš„å¤šæ¨¡æ€RLæ¡†æ¶**ï¼Œé€šè¿‡**MDPå½¢å¼åŒ–å»ºæ¨¡**ä¸**ä¸‰é‡è§£è€¦æ¶æ„è®¾è®¡**ï¼Œè§£å†³äº†ç°æœ‰RLæ¡†æ¶åœ¨å¤šæ¨¡æ€åœºæ™¯ä¸‹çš„é€‚é…éš¾é¢˜ã€‚å®éªŒè¯æ˜å…¶ä¸ä»…èƒ½æ˜¾è‘—æå‡VLMåœ¨æ•°å­¦æ¨ç†ã€è§†è§‰å®šä½ã€ä»£ç ç”Ÿæˆç­‰ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œè¿˜å…·å¤‡å‡ºè‰²çš„æ³›åŒ–èƒ½åŠ›å’Œä¸SOTAæ–¹æ³•ç«äº‰çš„å®åŠ›ã€‚å®ƒä¸ºèµ„æºå—é™çš„ç ”ç©¶å›¢é˜Ÿæä¾›äº†å¼ºå¤§çš„å·¥å…·ï¼Œæœ‰æœ›æ¨åŠ¨å¤šæ¨¡æ€RLé¢†åŸŸçš„æ™®åŠä¸å‘å±•ã€‚

</details>

---

### 10. [HWL-HIN: A Hypergraph-Level Hypergraph Isomorphism Network as Powerful as the Hypergraph Weisfeiler-Lehman Test with Application to Higher-Order Network Robustness](https://arxiv.org/abs/2512.22014)

**Authors**: Chengyu Tian, Wenbin Pei  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.22014v1  

#### Abstract
Robustness in complex systems is of significant engineering and economic importance. However, conventional attack-based a posteriori robustness assessments incur prohibitive computational overhead. Recently, deep learning methods, such as Convolutional Neural Networks (CNNs) and Graph Neural Network...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šHWL-HIN: A Hypergraph-Level Hypergraph Isomorphism Network as Powerful as the Hypergraph Weisfeiler-Lehman Test with Application to Higher-Order Network Robustness

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

ä¼ ç»ŸåŸºäºå›¾ç»“æ„çš„ç½‘ç»œé²æ£’æ€§é¢„æµ‹æ–¹æ³•ï¼ˆå¦‚ GNNsï¼‰ä»…èƒ½å»ºæ¨¡**æˆå¯¹äº¤äº’å…³ç³»**ï¼Œæ— æ³•æœ‰æ•ˆæ•æ‰ç°å®å¤æ‚ç³»ç»Ÿä¸­æ™®éå­˜åœ¨çš„**é«˜é˜¶ç¾¤ä½“äº¤äº’**ï¼ˆhigher-order interactionsï¼‰ã€‚å°½ç®¡è¶…å›¾ï¼ˆhypergraphï¼‰èƒ½å¤Ÿè‡ªç„¶åœ°è¡¨ç¤ºè¿™äº›é«˜é˜¶å…³ç³»ï¼Œä½†ç°æœ‰çš„è¶…å›¾ç¥ç»ç½‘ç»œï¼ˆHGNNsï¼‰åœ¨**æ‹“æ‰‘è¡¨è¾¾èƒ½åŠ›**ä¸Šå­˜åœ¨ç“¶é¢ˆâ€”â€”å…¶èšåˆå‡½æ•°ï¼ˆå¦‚å‡å€¼æ± åŒ–ï¼‰ç¼ºä¹è¶³å¤Ÿçš„åŒºåˆ†åŠ›ï¼Œæ— æ³•è¾¾åˆ°ç†è®ºä¸Šçš„æœ€å¤§è¡¨è¾¾èƒ½åŠ›ä¸Šé™ã€‚

æ­¤å¤–ï¼Œä¸»æµçš„åéªŒé²æ£’æ€§è¯„ä¼°ä¾èµ–äºæ”»å‡»æ¨¡æ‹Ÿï¼Œè®¡ç®—å¼€é”€å·¨å¤§ï¼Œè€Œç°æœ‰æ·±åº¦å­¦ä¹ ä»£ç†æ¨¡å‹åœ¨å¤„ç†è¶…å›¾æ—¶ä»å—é™äºç»“æ„å»ºæ¨¡èƒ½åŠ›ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡ºäº†ä¸€ç§å…¨æ–°çš„**è¶…å›¾å±‚çº§è¶…å›¾åŒæ„ç½‘ç»œæ¡†æ¶**ï¼ˆ**HWL-HIN**ï¼‰ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°† **Graph Isomorphism Network (GIN)** çš„è®¾è®¡ç†å¿µæ‰©å±•åˆ°è¶…å›¾é¢†åŸŸï¼Œå¹¶ä¸¥æ ¼å¯¹æ ‡ **Hypergraph Weisfeiler-Lehman (HWL) æµ‹è¯•** çš„è¡¨è¾¾èƒ½åŠ›ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

1. âœ… **é¦–ä¸ªå…·æœ‰ä¸¥æ ¼ç­‰ä»·äº HWL æµ‹è¯•è¡¨è¾¾èƒ½åŠ›çš„è¶…å›¾ç¥ç»ç½‘ç»œ**
   - ç†è®ºè¯æ˜ HWL-HIN çš„è¡¨è¾¾èƒ½åŠ›ä¸ Hypergraph WL æµ‹è¯•å®Œå…¨ä¸€è‡´ï¼Œè¾¾åˆ°äº†è¶…å›¾ç»“æ„åŒºåˆ†èƒ½åŠ›çš„ç†è®ºä¸Šé™ã€‚
   - é€šè¿‡è®¾è®¡**åŒé˜¶æ®µå¯é€†èšåˆæœºåˆ¶**ï¼ˆnode-to-hyperedge å’Œ hyperedge-to-nodeï¼‰ï¼Œå¹¶ç¡®ä¿æ¯ä¸ªèšåˆå‡½æ•°æ»¡è¶³**ä¸¥æ ¼å•å°„æ€§**ï¼ˆinjectivityï¼‰ï¼Œä»è€Œå®ç°æœ€å¤§è¡¨è¾¾åŠ›ã€‚

2. âœ… **é¦–æ¬¡ç ”ç©¶é«˜é˜¶ç½‘ç»œä¸­çš„è¿é€šæ€§é²æ£’æ€§é¢„æµ‹é—®é¢˜ï¼Œè€ƒè™‘åŠ¨æ€çº§è”å¤±æ•ˆåœºæ™¯**
   - å¼•å…¥äº†é€‚ç”¨äºè¶…å›¾çš„**è´Ÿè½½åˆ†å¸ƒæ¨¡å‹**æ¥æ¨¡æ‹ŸèŠ‚ç‚¹å¤±æ•ˆåçš„çº§è”ä¼ æ’­è¿‡ç¨‹ã€‚
   - å°†â€œå¤±è´¥é¡ºåºâ€ä½œä¸ºè¾“å…¥ç‰¹å¾ä¹‹ä¸€ï¼Œæå‡å¯¹åŠ¨æ€è¡Œä¸ºçš„å»ºæ¨¡èƒ½åŠ›ã€‚

3. âœ… **ç«¯åˆ°ç«¯çš„è¶…å›¾å±‚çº§è¯»å‡ºæœºåˆ¶ï¼ˆhypergraph-level readoutï¼‰**
   - è®¾è®¡äº†ä¸€ä¸ªå…¨å±€è¯»å‡ºæ¨¡å—ï¼Œèåˆæ‰€æœ‰å±‚çš„èŠ‚ç‚¹å’Œè¶…è¾¹è¡¨ç¤ºï¼Œå½¢æˆæœ€ç»ˆçš„å›¾çº§åµŒå…¥ $ H_{\text{graph}} $ï¼Œç”¨äºå›å½’ä»»åŠ¡ï¼ˆé²æ£’æ€§é¢„æµ‹ï¼‰ã€‚

4. âœ… **ç»“åˆè‡ªé€‚åº”ç§¯åˆ†ç”Ÿæˆé«˜è´¨é‡æ ‡ç­¾**
   - ä½¿ç”¨ Adaptive Simpson æ–¹æ³•åŠ¨æ€æ§åˆ¶æ•°å€¼ç§¯åˆ†ç²¾åº¦ï¼Œä»¥ç›¸å¯¹è¯¯å·®ç­–ç•¥ç”Ÿæˆæ›´ç²¾ç¡®ä¸”é«˜æ•ˆçš„é²æ£’æ€§æ ‡ç­¾ï¼Œé¿å…è¿‡åº¦è®¡ç®—ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **è¡¨è¾¾èƒ½åŠ›** | è¶…è¶Šæ ‡å‡† HGNNsï¼ˆå¦‚ HGNNã€HyperGCNï¼‰ï¼Œç†è®ºä¸Šå¯åŒºåˆ†ä»»ä½•è¢« HWL æµ‹è¯•åˆ¤å®šä¸ºéåŒæ„çš„è¶…å›¾ï¼›ä¼˜äºåŸºäºå±•å¼€æ³•çš„å›¾æ¨¡å‹ï¼ˆå¦‚ bipartite GNNsï¼‰ã€‚ |
| **ç»“æ„å»ºæ¨¡** | ç›´æ¥æ“ä½œåŸå§‹è¶…å›¾ç»“æ„ï¼Œé¿å… clique/star expansion å¯¼è‡´çš„ä¿¡æ¯æŸå¤±å’Œè®¡ç®—è†¨èƒ€ã€‚ |
| **æ•ˆç‡** | æ¨ç†é€Ÿåº¦ä¸ä¸»æµ HGNN/GNN ç›¸å½“ï¼Œè¿œå¿«äºçŸ©é˜µå‹æ–¹æ³•ï¼ˆå¦‚ SPP-CNNï¼‰ã€‚ |
| **æ³›åŒ–æ€§** | åœ¨æ··åˆæ‹“æ‰‘æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼ŒéªŒè¯äº†è·¨ç»“æ„çš„æ³›åŒ–èƒ½åŠ›ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

ä½œè€…æ„å»ºäº† **6 ä¸ªåˆæˆè¶…å›¾æ•°æ®é›†**ï¼Œæ¯ç±»åŒ…å« 1200 æˆ– 2500 ä¸ªæ ·æœ¬ï¼Œå›ºå®šèŠ‚ç‚¹æ•° $ N = 200 $ï¼š

| æ•°æ®é›† | ç±»å‹è¯´æ˜ |
|--------|----------|
| **ER (ErdÅ‘sâ€“RÃ©nyi)** | éšæœºè¿æ¥ï¼Œç¨€ç–ä½†è¿é€šï¼Œ$ p = 0.05 $ |
| **WS (Watts-Strogatz)** | å°ä¸–ç•Œç‰¹æ€§ï¼Œåˆå§‹ç¯å½¢è¿æ¥ $ k_{\text{nn}} = 10 $ï¼Œé‡è¿æ¦‚ç‡ $ p_{\text{rw}} = 0.5 $ |
| **SF (Scale-Free)** | ä¼˜å…ˆè¿æ¥æœºåˆ¶ï¼Œå¹‚å¾‹è¶…åº¦åˆ†å¸ƒï¼Œæ¯æ–°å¢èŠ‚ç‚¹å¼•å…¥ $ m = 5 $ æ¡è¶…è¾¹ |
| **SBM (Stochastic Block Model)** | ç¤¾åŒºç»“æ„ï¼Œ$ C = 5 $ ä¸ªç¤¾åŒºï¼Œå†…éƒ¨è¿æ¥æ¦‚ç‡ $ p_{\text{in}} = 0.1 $ï¼Œå¤–éƒ¨ $ p_{\text{out}} = 0.01 $ |
| **UF (Uniform Random)** | æ‰€æœ‰è¶…è¾¹å¤§å°å›ºå®šä¸º $ k = 5 $ï¼Œæµ‹è¯•å¯¹è¶…è¾¹è§„æ¨¡æ•æ„Ÿæ€§ |
| **MIX (Mixed Dataset)** | æ··åˆå‰äº”ç§ç”Ÿæˆæ¨¡å‹å„ 500 ä¸ªæ ·æœ¬ï¼Œå…± 2500 è®­ç»ƒ + 200 æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°æ³›åŒ–èƒ½åŠ› |

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **ä»»åŠ¡ç›®æ ‡**
- å›å½’ä»»åŠ¡ï¼šé¢„æµ‹è¶…å›¾åœ¨èŠ‚ç‚¹ç§»é™¤æ”»å‡»ä¸‹çš„**é²æ£’æ€§å€¼ $ R $**ã€‚
- æ”»å‡»ç±»å‹åˆ†ä¸ºä¸¤ç±»ï¼š
  - **é™æ€å®šå‘æ”»å‡»**ï¼ˆstatic targeted attacksï¼‰ï¼šæŒ‰è¶…åº¦ä»é«˜åˆ°ä½é€ä¸ªåˆ é™¤èŠ‚ç‚¹ã€‚
  - **åŠ¨æ€çº§è”æ”»å‡»**ï¼ˆdynamic cascading attacksï¼‰ï¼šèŠ‚ç‚¹å¤±æ•ˆåè§¦å‘è´Ÿè½½é‡åˆ†é…ï¼Œå¼•å‘è¿é”å´©æºƒã€‚

#### **é²æ£’æ€§å®šä¹‰ï¼ˆè¿ç»­å½¢å¼ï¼‰**
$$
R = \int_0^1 s(p) \, dp
$$
å…¶ä¸­ $ s(p) $ æ˜¯ç§»é™¤æ¯”ä¾‹ä¸º $ p $ çš„èŠ‚ç‚¹åï¼Œæœ€å¤§è¿é€šåˆ†é‡ï¼ˆLCCï¼‰çš„ç›¸å¯¹å¤§å°ã€‚è¯¥ç§¯åˆ†é€šè¿‡ Adaptive Simpson æ–¹æ³•è¿‘ä¼¼è®¡ç®—ã€‚

#### **è¯„ä¼°æŒ‡æ ‡**
- **å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰** Â± æ ‡å‡†å·®
- æ¯ä¸ªç®—æ³•åœ¨å„æ•°æ®é›†ä¸Šçš„æ’åå–å¹³å‡ä½œä¸ºç»¼åˆæ€§èƒ½å‚è€ƒ
- ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒï¼špaired t-test ($ \alpha = 0.1 $)

#### **è®­ç»ƒç»†èŠ‚**
- ä½¿ç”¨ AdamW ä¼˜åŒ–å™¨ + **Cosine Annealing å­¦ä¹ ç‡è°ƒåº¦**
- è¾“å…¥ç‰¹å¾é¢„å½’ä¸€åŒ–è‡³ [0,1]
- æ‰€æœ‰æ¨¡å‹ç»Ÿä¸€è°ƒå‚ï¼Œå…¬å¹³æ¯”è¾ƒ

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| ç±»åˆ« | åŸºçº¿æ–¹æ³• |
|-------|---------|
| **HGNN** | HGNNsï¼ˆä¸¥æ ¼å¯¹ç…§ç»„ï¼‰ |
| **Graph-based GNNs** | GIN-MAS, NRL-GTï¼ˆåº”ç”¨äºäºŒéƒ¨å…³è”å›¾ï¼‰ |
| **Matrix-based DL** | SPP-CNN, ATTRPï¼ˆä½œç”¨äºé‚»æ¥çŸ©é˜µå›¾åƒï¼‰ |
| **ä¼ ç»Ÿæœºå™¨å­¦ä¹ ** | KNN, Decision Tree (DT) |

> æ³¨ï¼šæ‰€æœ‰å›¾æ¨¡å‹å‡ä½œç”¨äºç”±è¶…å›¾è½¬æ¢å¾—åˆ°çš„**äºŒéƒ¨å›¾**ï¼ˆincidence graphï¼‰ï¼Œå­˜åœ¨ä¿¡æ¯æŸå¤±é£é™©ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table Iï¼‰**

ä»¥ä¸‹ä¸º MAE ç»“æœï¼ˆè¶Šå°è¶Šå¥½ï¼‰ï¼Œæ‹¬å·å†…ä¸ºå¹³å‡æ’åï¼š

| Dataset | HWL-HIN | HGNNs | GIN-MAS | NRL-GT | SPP-CNN | KNN | DT |
|--------|--------|--------|--------|--------|--------|--------|--------|
| **ER (é™æ€)** | **0.00282Â±0.00262 (1)** | 0.00303Â±0.00262 (2) | 0.00341Â±0.00354 (3) | ... | 0.03302Â±0.02568 (5) | 0.04817Â±0.04177 (8) | 0.04652Â±0.05734 (7) |
| **SF (é™æ€)** | **0.00114Â±0.00200 (1)** | 0.00117Â±0.00200 (2) | 0.00127Â±0.00220 (3) | ... | 0.00216Â±0.00324 (5) | 0.00311Â±0.00405 (8) | 0.00295Â±0.00498 (7) |
| **UF (é™æ€)** | **0.00287Â±0.00256 (1)** | 0.00314Â±0.00282 (2) | 0.00433Â±0.00388 (3) | ... | 0.04102Â±0.03326 (5) | 0.05497Â±0.07056 (7) | 0.07603Â±0.05086 (8) |
| **WS (é™æ€)** | **0.00927Â±0.00830 (1)** | 0.01001Â±0.00890 (2) | 0.01018Â±0.00853 (3) | ... | 0.05746Â±0.03985 (5) | 0.06028Â±0.07044 (7) | 0.06754Â±0.08373 (8) |
| **SBM (é™æ€)** | **0.00423Â±0.00401 (1)** | 0.00502Â±0.00470 (2) | 0.00546Â±0.00420 (3) | ... | 0.05869Â±0.03185 (5) | 0.07195Â±0.06682 (7) | 0.07775Â±0.09422 (8) |
| **MIX (é™æ€)** | **0.00468Â±0.00672 (1)** | 0.00522Â±0.00641 (2) | 0.00770Â±0.00860 (3) | ... | 0.05980Â±0.04229 (5) | 0.10615Â±0.07861 (8) | 0.07315Â±0.09471 (7) |

> âœ… åœ¨æ‰€æœ‰é™æ€æ”»å‡»åœºæ™¯ä¸‹ï¼Œ**HWL-HIN å…¨é¢é¢†å…ˆ**ï¼Œä¸”ç»Ÿè®¡æ˜¾è‘—ã€‚

#### åŠ¨æ€æ”»å‡»ç»“æœè¶‹åŠ¿ç±»ä¼¼ï¼Œä½†å·®è·ç¼©å°ï¼š
- HWL-HIN ä»æ’åç¬¬ä¸€ï¼Œä½† HGNNs æ€§èƒ½æ¥è¿‘ã€‚
- åŸå› ï¼šåŠ¨æ€æ”»å‡»ä¸­ï¼Œâ€œå¤±è´¥é¡ºåºâ€æˆä¸ºå¼ºå…ˆéªŒç‰¹å¾ï¼Œå‰Šå¼±äº†æ‹“æ‰‘å»ºæ¨¡çš„é‡è¦æ€§ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆè§ Table IIï¼‰**

| æ¶ˆèé¡¹ | å½±å“åˆ†æ |
|--------|--------|
| **ç§»é™¤è¶…è¾¹åŸºæ•°ç‰¹å¾ï¼ˆCardinalityï¼‰** | HWL-HIN æ€§èƒ½è½»å¾®ä¸‹é™ï¼ŒHGNNs ä¸‹é™æ˜æ˜¾ â†’ è¡¨æ˜ HWL-HIN æ›´ä¾èµ–ç»“æ„è€Œéæ˜¾å¼ç‰¹å¾ |
| **ç§»é™¤èŠ‚ç‚¹è¶…åº¦ç‰¹å¾ï¼ˆHyperdegreeï¼‰** | åŒä¸Šï¼ŒHWL-HIN æ›´ç¨³å¥ |
| **ç§»é™¤å¤±è´¥é¡ºåºï¼ˆFailure Orderï¼‰** | åœ¨åŠ¨æ€æ”»å‡»ä¸­å½±å“æœ€å¤§ï¼Œä¸¤æ¨¡å‹æ€§èƒ½å‡ä¸‹é™ï¼Œä½† HWL-HIN ä»å¯å­¦ä¹  |
| **å…¨ç‰¹å¾æ¶ˆèï¼ˆä»…ç”¨é‚»æ¥çŸ©é˜µï¼‰** | **HWL-HIN ä»èƒ½æ”¶æ•›å¹¶ä¿æŒä¸€å®šæ€§èƒ½ï¼›HGNNs å®Œå…¨æ— æ³•è®­ç»ƒ** â†’ è¯æ˜ HWL-HIN å¯ä»çº¯æ‹“æ‰‘ç»“æ„ä¸­å­¦ä¹ ï¼Œå…·å¤‡æ›´å¼ºå½’çº³èƒ½åŠ› |
| **ç§»é™¤ Cosine Annealing è°ƒåº¦å™¨** | è®­ç»ƒä¸ç¨³å®šï¼Œæ”¶æ•›æ…¢ï¼Œå°¤å…¶åœ¨ MIX æ•°æ®é›†ä¸Š â†’ éªŒè¯ä¼˜åŒ–ç­–ç•¥æœ‰æ•ˆæ€§ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. ğŸ”¹ **HWL-HIN æ˜¯ç›®å‰è¡¨è¾¾èƒ½åŠ›æœ€å¼ºçš„ HGNN æ¶æ„ä¹‹ä¸€**ï¼Œå…¶ç†è®ºè¡¨è¾¾åŠ›ä¸¥æ ¼ç­‰äº Hypergraph WL æµ‹è¯•ï¼Œèƒ½å¤Ÿæœ€å¤§ç¨‹åº¦åœ°åŒºåˆ†ä¸åŒæ‹“æ‰‘ç»“æ„ã€‚
2. ğŸ”¹ **åœ¨ä¾èµ–æ‹“æ‰‘ç»“æ„çš„ä»»åŠ¡ä¸­ï¼ˆå¦‚é™æ€æ”»å‡»é¢„æµ‹ï¼‰ï¼ŒHWL-HIN æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•**ï¼Œå°¤å…¶æ˜¯åœ¨ SBMã€MIX ç­‰å¤æ‚ç»“æ„ä¸Šä¼˜åŠ¿æ˜æ˜¾ã€‚
3. ğŸ”¹ **HGNNs é«˜åº¦ä¾èµ–è¾“å…¥ç‰¹å¾**ï¼Œä¸€æ—¦å»é™¤ç‰¹å¾å³ä¸§å¤±å­¦ä¹ èƒ½åŠ›ï¼›è€Œ **HWL-HIN å…·å¤‡ä»çº¯ç»“æ„ä¸­æå–çŸ¥è¯†çš„èƒ½åŠ›**ï¼Œæ›´å…·é²æ£’æ€§å’Œæ³›åŒ–æ½œåŠ›ã€‚
4. ğŸ”¹ **å›¾æ¨¡å‹ï¼ˆGIN/NRL-GTï¼‰åœ¨è¶…å›¾ä»»åŠ¡ä¸­è¡¨ç°å—é™**ï¼Œå› å…¶å¿…é¡»å°†è¶…å›¾è½¬ä¸ºäºŒéƒ¨å›¾ï¼Œå¯¼è‡´é«˜é˜¶ä¿¡æ¯ä¸¢å¤±ï¼Œå°¤å…¶åœ¨åŠ¨æ€çº§è”åœºæ™¯ä¸‹æ€§èƒ½é€€åŒ–ä¸¥é‡ã€‚
5. ğŸ”¹ **çŸ©é˜µæ–¹æ³•ï¼ˆSPP-CNN/ATTRPï¼‰æ•ˆç‡ä½ä¸‹**ï¼Œé¢ä¸´ç»´åº¦ç¾éš¾å’Œå†…å­˜æº¢å‡ºï¼ˆOOMï¼‰é—®é¢˜ï¼Œéš¾ä»¥æ‰©å±•åˆ°å¤§è§„æ¨¡ç½‘ç»œã€‚
6. ğŸ”¹ **æ‰€æœ‰ ML æ–¹æ³•æ¯”çœŸå®ä»¿çœŸåŠ é€Ÿçº¦ç™¾å€**ï¼ŒéªŒè¯äº†ä»£ç†æ¨¡å‹åœ¨é«˜æ•ˆé²æ£’æ€§è¯„ä¼°ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

- â— å½“è¾“å…¥ç‰¹å¾éå¸¸å¼ºæ—¶ï¼ˆå¦‚å·²çŸ¥å¤±è´¥é¡ºåºï¼‰ï¼ŒHWL-HIN çš„ç»“æ„ä¼˜åŠ¿ä¼šè¢«æ©ç›–ï¼Œæ€§èƒ½å¢ç›Šæœ‰é™ã€‚
- â— ç›®å‰ä»…éªŒè¯äºåˆæˆæ•°æ®é›†ï¼Œå°šæœªåœ¨çœŸå®ä¸–ç•Œè¶…å›¾ï¼ˆå¦‚ç§‘ç ”åˆä½œã€ç”Ÿç‰©é€šè·¯ï¼‰ä¸Šæµ‹è¯•ã€‚
- â— æ¨¡å‹å¤æ‚åº¦ç•¥é«˜äºæ™®é€š HGNNsï¼Œå‚æ•°æ›´å¤šï¼Œè®­ç»ƒæ—¶é—´ç¨é•¿ï¼ˆä½†ä»å¯æ§ï¼‰ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

- ğŸš€ å°† HWL-HIN åº”ç”¨äºå…¶ä»–è¶…å›¾å±‚çº§ä»»åŠ¡ï¼Œå¦‚è¶…å›¾åˆ†ç±»ã€å¼‚å¸¸æ£€æµ‹ã€ç¤¾åŒºå‘ç°ç­‰ã€‚
- ğŸš€ æ‰©å±•è‡³æ›´å¤§è§„æ¨¡çš„çœŸå®è¶…å›¾æ•°æ®é›†ï¼Œæ¢ç´¢è¿ç§»å­¦ä¹ ä¸é¢„è®­ç»ƒæœºåˆ¶ã€‚
- ğŸš€ ç»“åˆå¼ºåŒ–å­¦ä¹ è¿›è¡Œé²æ£’æ€§ä¼˜åŒ–è®¾è®¡ï¼ˆrobustness optimizationï¼‰ã€‚
- ğŸš€ æ¢ç´¢è½»é‡åŒ–ç‰ˆæœ¬ä»¥è¿›ä¸€æ­¥æå‡æ¨ç†æ•ˆç‡ï¼Œé€‚é…è¾¹ç¼˜éƒ¨ç½²ã€‚

--- 

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> HWL-HIN æ˜¯é¦–ä¸ªç†è®ºè¡¨è¾¾åŠ›è¾¾æ ‡çš„è¶…å›¾ç¥ç»ç½‘ç»œï¼Œåœ¨é²æ£’æ€§é¢„æµ‹ä»»åŠ¡ä¸­å±•ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œæ ‡å¿—ç€è¶…å›¾å­¦ä¹ å‘â€œç†è®ºæœ€ä¼˜â€è¿ˆå‡ºäº†å…³é”®ä¸€æ­¥ã€‚

</details>

---

### 11. [Knowledge Reasoning of Large Language Models Integrating Graph-Structured Information for Pest and Disease Control in Tobacco](https://arxiv.org/abs/2512.21837)

**Authors**: Siyu Li, Chenwei Song, Wan Zhou, Xinyi Liu  
**Category**: cs.CL  
**Published**: 2025-12-29  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.21837v1  

#### Abstract
This paper proposes a large language model (LLM) approach that integrates graph-structured information for knowledge reasoning in tobacco pest and disease control. Built upon the GraphRAG framework, the proposed method enhances knowledge retrieval and reasoning by explicitly incorporating structured...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹çƒŸè‰ç—…è™«å®³é˜²æ²»é¢†åŸŸä¸­**å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¸è¶³**çš„é—®é¢˜å±•å¼€ç ”ç©¶ã€‚ä¼ ç»Ÿæ–¹æ³•ä¾èµ–ä¸“å®¶ç»éªŒæˆ–ç®€å•çš„çŸ¥è¯†æ³¨å…¥ï¼Œéš¾ä»¥æœ‰æ•ˆåˆ©ç”¨å†œä¸šçŸ¥è¯†ä¸­çš„ä¸°å¯Œå…³ç³»ç»“æ„ï¼Œå¯¼è‡´æ¨ç†èƒ½åŠ›å—é™ï¼Œå°¤å…¶åœ¨å¤šè·³æ¨ç†ï¼ˆmulti-hop reasoningï¼‰å’Œæ¯”è¾ƒæ¨ç†ï¼ˆcomparative reasoningï¼‰åœºæ™¯ä¸‹å‡†ç¡®ç‡è¾ƒä½ã€‚

### æå‡ºçš„æ–°æ–¹æ³•/æ–°æ€è·¯
æå‡ºäº†ä¸€ç§åŸºäº **GraphRAG æ¡†æ¶**ã€èåˆå›¾ç»“æ„ä¿¡æ¯çš„ LLM æ¨ç†æ–¹æ³•ï¼Œç”¨äºæå‡çƒŸè‰ç—…è™«å®³æ§åˆ¶é¢†åŸŸçš„çŸ¥è¯†æ¨ç†èƒ½åŠ›ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†**ç»“æ„åŒ–çŸ¥è¯†å›¾è°±ï¼ˆKnowledge Graph, KGï¼‰ä¸å¤§è¯­è¨€æ¨¡å‹æ·±åº¦ç»“åˆ**ï¼Œé€šè¿‡å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰å¢å¼ºèŠ‚ç‚¹è¡¨ç¤ºï¼Œå¹¶å°†å…¶èå…¥ LLM çš„è¾“å…¥æˆ–ä¸­é—´å±‚ï¼Œå®ç°æ›´æ·±å±‚æ¬¡çš„çŸ¥è¯†èåˆã€‚

å…·ä½“æµç¨‹å¦‚ä¸‹ï¼š
1. åˆ©ç”¨ LLM è¾…åŠ©æ„å»º**çƒŸè‰ç—…è™«å®³çŸ¥è¯†å›¾è°±**ï¼ˆåŒ…å«ç–¾ç—…ã€ç—‡çŠ¶ã€é˜²æ²»æ–¹æ³•ç­‰å®ä½“åŠå…¶å…³ç³»ï¼‰ï¼›
2. ä½¿ç”¨ **TransE** è¿›è¡Œå›¾åµŒå…¥å­¦ä¹ ï¼Œæ•æ‰å®ä½“ä¸å…³ç³»çš„è¯­ä¹‰ï¼›
3. å¼•å…¥ **GCNï¼ˆGraph Convolutional Networkï¼‰** èšåˆé‚»å±…ä¿¡æ¯ï¼Œç”Ÿæˆæ›´å…·ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›çš„èŠ‚ç‚¹è¡¨ç¤ºï¼›
4. å°†å›¾è¡¨ç¤ºä¸æ–‡æœ¬æŸ¥è¯¢è¡¨ç¤ºæ‹¼æ¥åè¾“å…¥ **ChatGLM** æ¨¡å‹ï¼Œè¿›è¡Œé—®ç­”ç”Ÿæˆï¼›
5. é‡‡ç”¨ **LoRA** å¯¹ ChatGLM è¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´å……åˆ†åœ°åˆ©ç”¨çŸ¥è¯†å›¾è°±çš„ç»“æ„ä¿¡æ¯**ï¼šä¸ä»…ä½¿ç”¨å®ä½“çº§ä¿¡æ¯ï¼ˆå¦‚ KGEï¼‰ï¼Œè¿˜é€šè¿‡ GCN æ˜¾å¼å»ºæ¨¡å…¨å±€å›¾ç»“æ„ï¼Œæ•è·é«˜é˜¶å…³ç³»è·¯å¾„ã€‚
- **æ›´å¼ºçš„å¤æ‚æ¨ç†èƒ½åŠ›**ï¼šåœ¨ multi-hop å’Œ comparative reasoning ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºä»…ä¾èµ–æ–‡æœ¬æ£€ç´¢æˆ–ç®€å•çŸ¥è¯†æ³¨å…¥çš„æ–¹æ³•ã€‚
- **æ›´é«˜çš„å‡†ç¡®æ€§ä¸å¯é æ€§**ï¼šé€šè¿‡ç»“æ„åŒ–å¼•å¯¼å‡å°‘æ— å…³æˆ–å†—ä½™ä¿¡æ¯å¹²æ‰°ï¼Œæå‡ç­”æ¡ˆçš„ç›¸å…³æ€§å’Œå®Œæ•´æ€§ã€‚
- **é¢†åŸŸé€‚é…æ€§å¼º**ï¼šä¸“ä¸ºå†œä¸šç—…è™«å®³é˜²æ²»è®¾è®¡ï¼Œå…·å¤‡å®é™…åº”ç”¨æ½œåŠ›ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- è‡ªå»ºäº†ä¸€ä¸ª**çƒŸè‰ç—…è™«å®³çŸ¥è¯†å›¾è°±**ï¼ŒåŒ…å«è¶…è¿‡ 1,000 ä¸ªå®ä½“å’Œå…³ç³»ã€‚
- æ•°æ®æ¥æºåŒ…æ‹¬ï¼šå†œä¸šä¸“å®¶çŸ¥è¯†åº“ã€ç—…å®³ç®¡ç†æ‰‹å†Œã€å­¦æœ¯æ–‡çŒ®ã€‚
- æ„å»ºäº†é…å¥—çš„**é—®ç­”æ•°æ®é›†**ï¼Œæ¶µç›–ä¸‰ç±»ä»»åŠ¡ï¼š
  - ç›´æ¥é—®ç­”ï¼ˆDirect QAï¼‰
  - å¤šè·³æ¨ç†ï¼ˆMulti-hop reasoningï¼‰
  - æ¯”è¾ƒæ¨ç†ï¼ˆComparative reasoningï¼‰

### å®éªŒè®¾ç½®
- **å›¾è¡¨ç¤ºå­¦ä¹ æ¨¡å—**ï¼š
  - TransEï¼šåµŒå…¥ç»´åº¦ 100ï¼Œå­¦ä¹ ç‡ 0.01
  - GCNï¼šä¸¤å±‚ï¼ŒReLU æ¿€æ´»å‡½æ•°
- **è¯­è¨€æ¨¡å‹**ï¼š
  - ä¸»å¹²æ¨¡å‹ï¼š**ChatGLM**
  - å¾®è°ƒæ–¹å¼ï¼š**LoRA**ï¼ˆrank = 16ï¼‰ï¼Œå®ç°å‚æ•°é«˜æ•ˆè®­ç»ƒ
- **èåˆæœºåˆ¶**ï¼š
  - åœ¨ GraphRAG æ¡†æ¶ä¸‹ï¼Œå°† GCN å­¦å¾—çš„å›¾åµŒå…¥ä¸ Sentence-BERT ç¼–ç çš„æŸ¥è¯¢åµŒå…¥æ‹¼æ¥ï¼Œä½œä¸ºå¢å¼ºè¾“å…¥é€å…¥ ChatGLM

### è¯„ä¼°æŒ‡æ ‡
é‡‡ç”¨æ ‡å‡†åˆ†ç±»ä¸é—®ç­”è¯„ä»·æŒ‡æ ‡ï¼š
- **Accuracyï¼ˆå‡†ç¡®ç‡ï¼‰**
- **Precisionï¼ˆç²¾ç¡®ç‡ï¼‰**
- **Recallï¼ˆå¬å›ç‡ï¼‰**
- **F1-scoreï¼ˆF1 åˆ†æ•°ï¼‰**

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿æ¨¡å‹ | æè¿° |
|--------|------|
| **ChatGLM** | ä¸ä½¿ç”¨ä»»ä½•å¤–éƒ¨çŸ¥è¯†çš„åŸå§‹ LLM |
| **KGE + ChatGLM** | ä½¿ç”¨ TransE åµŒå…¥æ³¨å…¥å®ä½“çŸ¥è¯† |
| **RAG + ChatGLM** | åŸºäºæ–‡æœ¬æ£€ç´¢çš„æ ‡å‡†æ£€ç´¢å¢å¼ºç”Ÿæˆ |
| **GraphRAG + ChatGLM** | æœ¬æ–‡æå‡ºçš„æ–¹æ³•ï¼ˆGCN + å›¾ç»“æ„èåˆï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰

| Model | Accuracy (%) | Precision (%) | Recall (%) | F1-score (%) |
|-------|--------------|---------------|------------|---------------|
| ChatGLM | 75.2 | 78.5 | 72.1 | 75.2 |
| KGE + ChatGLM | 82.5 | 85.3 | 79.8 | 82.4 |
| RAG + ChatGLM | 85.7 | 87.9 | 83.2 | 85.5 |
| **GraphRAG + ChatGLM** | **90.1** | **92.3** | **88.2** | **90.2** |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- ç›¸æ¯”çº¯ LLMï¼ˆChatGLMï¼‰ï¼Œå¼•å…¥ç»“æ„åŒ–çŸ¥è¯†ä½¿å„é¡¹æŒ‡æ ‡æå‡çº¦ **15%**ï¼›
- ç›¸æ¯”ä»…ä½¿ç”¨ KGE æ³¨å…¥çš„æ–¹æ³•ï¼ŒGCN å»ºæ¨¡å›¾ç»“æ„å¸¦æ¥é¢å¤– **7.6% çš„ Accuracy æå‡**ï¼Œè¯´æ˜å›¾ç»“æ„å»ºæ¨¡è‡³å…³é‡è¦ï¼›
- ç›¸æ¯”ä¼ ç»Ÿ RAG æ–¹æ³•ï¼ŒGraphRAG åœ¨ç†è§£å¤æ‚æŸ¥è¯¢å’Œå…³è”å¤šä¸ªå®ä½“æ–¹é¢è¡¨ç°æ›´ä¼˜ï¼Œ**Accuracy æé«˜ 4.4%**ï¼Œè¡¨æ˜å›¾ç»“æ„èƒ½æ›´å¥½æ”¯æŒé€»è¾‘æ¨ç†ï¼›
- åœ¨ multi-hop å’Œ comparative reasoning ä»»åŠ¡ä¸­ä¼˜åŠ¿å°¤ä¸ºæ˜æ˜¾ï¼Œä¾‹å¦‚ï¼š
  - â€œå“ªäº›å†œè¯åŒæ—¶é€‚ç”¨äºçƒŸè‰èŠ±å¶ç—…å’Œèšœè™«ï¼Ÿâ€ â†’ æˆåŠŸè¯†åˆ«å…±ç”¨é˜²æ²»æ‰‹æ®µï¼›
  - â€œç”Ÿç‰©é˜²æ²» vs åŒ–å­¦é˜²æ²»å“ªç§æ›´æœ‰æ•ˆï¼Ÿâ€ â†’ å¯æ²¿çŸ¥è¯†å›¾è·¯å¾„æ¨ç†å¾—å‡ºç»¼åˆåˆ¤æ–­ã€‚

### æ¶ˆèå®éªŒåˆ†æï¼ˆæ–‡ä¸­è™½æœªå•ç‹¬åˆ—å‡ºè¡¨æ ¼ï¼Œä½†æœ‰æ˜ç¡®è®¨è®ºï¼‰
- **ç§»é™¤ GCN**ï¼šæ€§èƒ½ä¸‹é™æ˜æ˜¾ï¼Œè¯´æ˜å±€éƒ¨ä¸å…¨å±€é‚»åŸŸèšåˆå¯¹èŠ‚ç‚¹è¡¨å¾è´¨é‡è‡³å…³é‡è¦ï¼›
- **ä»…ç”¨ TransE**ï¼šè™½ä¼˜äºæ— çŸ¥è¯†æ³¨å…¥ï¼Œä½†ä»å¼±äº GCN å¢å¼ºç‰ˆæœ¬ï¼ŒéªŒè¯äº†æ·±å±‚å›¾ç»“æ„å»ºæ¨¡çš„ä»·å€¼ï¼›
- **ä¸ä½¿ç”¨å›¾åµŒå…¥èåˆ**ï¼šé€€åŒ–ä¸ºæ™®é€š RAG æˆ– KGE æ–¹æ³•ï¼Œæ¨ç†æ·±åº¦å’Œå‡†ç¡®æ€§é™ä½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
- **å›¾ç»“æ„ä¿¡æ¯æ˜¾è‘—å¢å¼º LLM çš„æ¨ç†èƒ½åŠ›**ï¼šé€šè¿‡ GCN å­¦ä¹ çš„çŸ¥è¯†å›¾è°±è¡¨ç¤ºèƒ½å¤Ÿæœ‰æ•ˆè¡¥å…… LLM çš„è¯­ä¹‰ç›²åŒºï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦è·¨å®ä½“æ¨ç†çš„ä»»åŠ¡ä¸­ã€‚
- **GraphRAG æ˜¯æœ‰æ•ˆçš„çŸ¥è¯†èåˆèŒƒå¼**ï¼šç›¸æ¯”ä¼ ç»Ÿ RAG ä¾èµ–æ–‡æœ¬ç›¸ä¼¼åº¦ï¼ŒGraphRAG åˆ©ç”¨æ˜¾å¼çš„å›¾ç»“æ„è¿›è¡ŒçŸ¥è¯†æ£€ç´¢ä¸æ•´åˆï¼Œæé«˜äº†æ¨ç†çš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚
- **è¯¥æ¡†æ¶ç‰¹åˆ«é€‚åˆå†œä¸šç­‰ä¸“ä¸šçŸ¥è¯†å¯†é›†å‹é¢†åŸŸ**ï¼šåœ¨ç—…è™«å®³è¯Šæ–­ã€é˜²æ²»ç­–ç•¥æ¨èç­‰ä»»åŠ¡ä¸­å±•ç°å‡ºå¼ºå¤§æ½œåŠ›ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ„å»ºçš„çŸ¥è¯†å›¾è°±è§„æ¨¡è¾ƒå°ï¼ˆä»…åƒçº§å®ä½“ï¼‰ï¼Œå¯èƒ½é™åˆ¶æ¨¡å‹æ³›åŒ–èƒ½åŠ›ï¼›
- ä½¿ç”¨å›ºå®šçš„ GCN æ¶æ„å’Œå›¾åµŒå…¥æ–¹å¼ï¼Œç¼ºä¹åŠ¨æ€æ›´æ–°æœºåˆ¶ï¼›
- å›¾ä¸ LLM çš„èåˆä»åœç•™åœ¨è¾“å…¥æ‹¼æ¥å±‚é¢ï¼Œå°šæœªå®ç°ç«¯åˆ°ç«¯çš„è”åˆä¼˜åŒ–ï¼›
- å®éªŒé›†ä¸­åœ¨å•ä¸€ä½œç‰©ï¼ˆçƒŸè‰ï¼‰ï¼Œéœ€è¿›ä¸€æ­¥éªŒè¯åœ¨å…¶ä»–ä½œç‰©ä¸Šçš„é€‚ç”¨æ€§ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ„å»ºæ›´å¤§è§„æ¨¡ã€è¦†ç›–æ›´å¤šä½œç‰©çš„å†œä¸šçŸ¥è¯†å›¾è°±ï¼›
- æ¢ç´¢æ›´å…ˆè¿›çš„ GNN æ¶æ„ï¼ˆå¦‚ GATã€Temporal GNNï¼‰ä»¥æ•æ‰åŠ¨æ€æ¼”åŒ–å…³ç³»ï¼›
- è®¾è®¡æ›´é«˜æ•ˆçš„å›¾-è¯­è¨€æ¨¡å‹èåˆç­–ç•¥ï¼ˆå¦‚ä¸­é—´å±‚äº¤äº’ã€æ³¨æ„åŠ›é—¨æ§ï¼‰ï¼›
- å°†è¯¥æ¡†æ¶æ‰©å±•è‡³å…¶ä»–çŸ¥è¯†å¯†é›†å‹é¢†åŸŸï¼Œå¦‚åŒ»ç–—å¥åº·ã€æ™ºèƒ½å†³ç­–ç³»ç»Ÿç­‰ï¼Œæ£€éªŒå…¶é€šç”¨æ€§ã€‚

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼šæœ¬è®ºæ–‡æå‡ºçš„ **GraphRAG + ChatGLM** æ–¹æ³•é€šè¿‡æ·±åº¦èåˆå›¾ç»“æ„ä¿¡æ¯ä¸å¤§è¯­è¨€æ¨¡å‹ï¼Œåœ¨çƒŸè‰ç—…è™«å®³æ§åˆ¶çš„çŸ¥è¯†æ¨ç†ä»»åŠ¡ä¸­å®ç°äº†æ˜¾è‘—æ€§èƒ½çªç ´ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚æ¨ç†åœºæ™¯ä¸‹è¡¨ç°å‡ºå“è¶Šçš„å‡†ç¡®æ€§å’Œæ·±åº¦ï¼Œä¸ºå†œä¸šæ™ºèƒ½åŒ–æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 12. [Demystifying ARM SME to Optimize General Matrix Multiplications](https://arxiv.org/abs/2512.21473)

**Authors**: Chencheng Deng, Weiling Yang, Jianbin Fang, Dezun Dong  
**Category**: cs.DC  
**Published**: 2025-12-29  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.21473v1  

#### Abstract
General Matrix Multiplication (GEMM) is a critical kernel in high-performance computing and deep learning. While modern architectures like ARM's Scalable Matrix Extension (SME) introduce dedicated hardware for matrix operations, existing linear algebra libraries fail to fully exploit its potential, ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Demystifying ARM SME to Optimize General Matrix Multiplications*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹åœ¨ **ARM Scalable Matrix Extension (SME)** æ¶æ„ä¸Šä¼˜åŒ–å¤§è§„æ¨¡ **General Matrix Multiplication (GEMM)** çš„æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºå½“å‰å¼€æº GEMM åº“ï¼ˆå¦‚ LIBXSMMã€OpenBLASã€KleidiAIï¼‰å­˜åœ¨ä»¥ä¸‹å…³é”®ç“¶é¢ˆï¼š
- **ç¼“å­˜åˆ©ç”¨ç‡ä½**ï¼šç®€å•ä¸‰å±‚å¾ªç¯è®¾è®¡å¯¼è‡´å­å—æ— æ³•æœ‰æ•ˆåŒ¹é…å…±äº« L2 ç¼“å­˜ï¼Œé€ æˆå¤§é‡ cache miss å’Œ TLB å‹åŠ›ã€‚
- **å†…å­˜å¸¦å®½æœªå……åˆ†åˆ©ç”¨**ï¼šä»…ä½¿ç”¨å•ä¸ªæˆ–ä¸¤ä¸ª Z å¯„å­˜å™¨è¿›è¡ŒåŠ è½½ï¼Œæœªèƒ½å‘æŒ¥ SME2 æ”¯æŒçš„å¤šå‘é‡ï¼ˆmulti-vectorï¼‰é«˜å¸¦å®½åŠ è½½èƒ½åŠ›ã€‚
- **æ•°æ®æ‰“åŒ…ç­–ç•¥ä¸è¶³**ï¼šå¤šæ•°åº“åªå¯¹ä¸€ä¸ªè¾“å…¥çŸ©é˜µæ‰“åŒ…ï¼Œå¦ä¸€ä¸ªä¿æŒåŸå§‹å¸ƒå±€ï¼Œå½“å…¶è¶…å‡º L2 ç¼“å­˜æ—¶æ€§èƒ½æ€¥å‰§ä¸‹é™ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **MPGEMM** â€”â€” ä¸€ä¸ªé¢å‘ ARM SME æ¶æ„çš„é«˜æ€§èƒ½ã€å¤šç²¾åº¦å¼€æº GEMM åº“ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰ç³»ç»ŸåŒ–çš„æ¶æ„ç‰¹å¾åˆ†æ
é€šè¿‡å¾®åŸºå‡†æµ‹è¯•ï¼ˆmicrobenchmarksï¼‰æ·±å…¥å‰–æ SME çš„è®¡ç®—ååã€å†…å­˜å¸¦å®½ç‰¹æ€§ï¼Œå¾—å‡ºä¸‰å¤§ä¼˜åŒ–åŸåˆ™ï¼š
- **æœ€å¤§åŒ– ZA tile åˆ©ç”¨ç‡**ï¼šæ‰€æœ‰ micro-kernel å¿…é¡»ä½¿ç”¨å…¨éƒ¨å¯ç”¨ ZA tilesï¼ˆå¦‚ FP32 ä¸‹ä¸º 4 ä¸ª ZA.S tilesï¼‰ä»¥è¾¾åˆ°å³°å€¼ç®—åŠ›ã€‚
- **ä¼˜åŒ–åŠ è½½ç²’åº¦**ï¼šé‡‡ç”¨ **å›› Z å¯„å­˜å™¨ç»„åŠ è½½**ï¼ˆfour-Z-register loadï¼‰ï¼Œå¯å®ç°é«˜è¾¾ 900 GB/s çš„å†…å­˜å¸¦å®½ï¼Œè¿œè¶…å•å¯„å­˜å™¨çš„ 230 GB/sã€‚
- **å°Šé‡ç¼“å­˜å®¹é‡é™åˆ¶**ï¼šå­çŸ©é˜µåº”æ§åˆ¶åœ¨ **8MB å·¥ä½œé›†å†…**ï¼Œå¦åˆ™å¸¦å®½ä¼šéª¤é™ã€‚

#### ï¼ˆ2ï¼‰Cache-Aware åˆ†å—ç®—æ³•
å°†ä¼ ç»Ÿçš„ä¸‰é‡å¾ªç¯æ‰©å±•ä¸º **å…­çº§åˆ†å—ç»“æ„**ï¼Œå¹¶åŸºäºè§£ææ¨¡å‹è‡ªåŠ¨ç¡®å®šæœ€ä¼˜åˆ†å—å‚æ•° $mc, nc, kc$ï¼Œç»¼åˆè€ƒè™‘ï¼š
- L2 ç¼“å­˜å¤§å°
- TLB å®¹é‡
- å†…å­˜å¸¦å®½çº¦æŸ  
ç›®æ ‡æ˜¯æœ€å¤§åŒ– **compute-to-memory ratio (CMR)** å¹¶ä¿è¯è‰¯å¥½çš„ç©ºé—´å±€éƒ¨æ€§ã€‚

#### ï¼ˆ3ï¼‰é«˜æ•ˆçš„åŒçŸ©é˜µæ‰“åŒ…ç­–ç•¥
- **Matrix Aï¼šon-the-fly transposition**  
  åˆ©ç”¨ ZA tile çš„è¡Œåˆ—åˆ‡ç‰‡åŠŸèƒ½ï¼Œåœ¨ä¸å¼•å…¥ gather æ“ä½œçš„æƒ…å†µä¸‹å®Œæˆè¡Œä¸»åºåˆ°åˆ—ä¸»åºçš„é«˜æ•ˆè½¬ç½®ã€‚
- **Matrix Bï¼šfirst-round online packing**  
  åœ¨é¦–æ¬¡è¿­ä»£ä¸­è¾¹æ‰§è¡Œ FMOPA è¿ç®—è¾¹å°† B æ‰“åŒ…è¿›è¿ç»­ç¼“å†²åŒºï¼Œåç»­è¿­ä»£å¤ç”¨è¯¥ç¼“å†²åŒºï¼Œæ˜¾è‘—é™ä½æ‰“åŒ…å¼€é”€ã€‚

#### ï¼ˆ4ï¼‰é«˜æ€§èƒ½ micro-kernel è®¾è®¡
- ä¸» micro-kernel é‡‡ç”¨ **16Ã—64** å½¢çŠ¶ï¼ˆFP32ï¼‰ï¼Œè¾¹ç¼˜ kernel ä½¿ç”¨ 64Ã—16ï¼Œç¡®ä¿å§‹ç»ˆèƒ½ä½¿ç”¨ **å››ä¸ª Z å¯„å­˜å™¨åŒæ—¶åŠ è½½**ã€‚
- å¼•å…¥ **è½¯ä»¶æµæ°´ï¼ˆsoftware pipeliningï¼‰å’Œå¾ªç¯å±•å¼€** æ¥æ©ç›–è®¿å­˜å»¶è¿Ÿï¼Œæå‡æŒ‡ä»¤çº§å¹¶è¡Œåº¦ã€‚
- æ”¯æŒæ··åˆç²¾åº¦ GEMMï¼ˆå¦‚ FP16â†’FP32, INT8â†’INT32ï¼‰ï¼Œåˆ©ç”¨ SME åŸç”Ÿæ”¯æŒçš„é«˜ååå¤–ç§¯æŒ‡ä»¤ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰æ–¹æ³•ç¼ºé™· | MPGEMM æ”¹è¿› |
|------|---------------|-------------|
| ç¼“å­˜åˆ©ç”¨ | å›ºå®šåˆ†å—ï¼Œä¸é€‚åº” L2/TLB | è§£æå»ºæ¨¡æŒ‡å¯¼åŠ¨æ€åˆ†å— |
| æ•°æ®è®¿é—® | å•/åŒ Z åŠ è½½ï¼Œå¸¦å®½å—é™ | ç»Ÿä¸€ä½¿ç”¨å›› Z åŠ è½½ï¼Œè¾¾ 900 GB/s |
| æ‰“åŒ…ç­–ç•¥ | ä»…æ‰“åŒ…ä¸€ä¸ªçŸ©é˜µ | åŒçŸ©é˜µæ‰“åŒ… + åœ¨çº¿æ‰“åŒ… |
| å¹¶è¡ŒåŒ– | å¤šæ•°ä¸æ”¯æŒè·¨ SME å•å…ƒå¹¶è¡Œ | åŠ¨æ€ä»»åŠ¡è°ƒåº¦è‡³å¤šä¸ª SME å•å…ƒ |
| å¼€æºé€æ˜ | Apple Accelerate å°é—­ | å…¨å¼€æºï¼Œå¯å¤ç° |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### å®éªŒå¹³å°
- **ç¡¬ä»¶**ï¼šApple M4 Pro èŠ¯ç‰‡
  - P-core é›†ç¾¤ï¼š10 æ ¸ @ 4.4GHzï¼Œæ¯ä¸ªé›†ç¾¤å…±äº« 16MB L2 ç¼“å­˜ + 1 ä¸ª SME å•å…ƒ
  - E-core é›†ç¾¤ï¼š4 æ ¸ @ 2.85GHzï¼Œå…±äº« 4MB L2 ç¼“å­˜ + 1 ä¸ª SME å•å…ƒ
  - æµå¼å‘é‡é•¿åº¦ï¼ˆSVLï¼‰å›ºå®šä¸º 512 bitsï¼ˆå³æ¯ Z å¯„å­˜å™¨ 64 å­—èŠ‚ï¼‰
- **æ“ä½œç³»ç»Ÿ**ï¼šmacOS 15.1
- **ç¼–è¯‘å™¨**ï¼šAppleClang 16

### æ•°æ®é›†ä¸å·¥ä½œè´Ÿè½½
æ¥è‡ªçœŸå®å¤§æ¨¡å‹çš„ GEMM é…ç½®ï¼š
- **DeepSeek æ¨¡å‹**ï¼šID 1â€“18
- **LLaMA æ¨¡å‹**ï¼šID 19â€“24  
æ¶µç›–å¤šç§å½¢çŠ¶ï¼ˆæ–¹é˜µã€ç˜¦é•¿çŸ©é˜µã€èƒ–çŸ­çŸ©é˜µï¼‰ï¼Œå°ºå¯¸ä» $64\times2112$ åˆ° $4096\times32768$ ä¸ç­‰ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **æ€§èƒ½æŒ‡æ ‡**ï¼šGFLOPS / GOPSï¼ˆæµ®ç‚¹/æ•´æ•°è¿ç®—æ¯ç§’åäº¿æ¬¡ï¼‰
- **åŠ é€Ÿæ¯”**ï¼šç›¸å¯¹äºåŸºçº¿åº“çš„é€Ÿåº¦æå‡å€æ•°
- **æ•ˆç‡**ï¼šå®æµ‹æ€§èƒ½å ç†è®ºå³°å€¼çš„æ¯”ä¾‹ï¼ˆå¦‚ INT8 è¾¾åˆ° 94% å³°å€¼ï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åº“å | æ˜¯å¦å¼€æº | SME ç‰ˆæœ¬ | ç²¾åº¦æ”¯æŒ | å¹¶è¡Œèƒ½åŠ› |
|------|----------|-----------|------------|-------------|
| **Apple Accelerate** | âŒ å¦ | SME2 | FP32/FP64 | âœ… æ”¯æŒå¤š SME |
| **LIBXSMM** | âœ… æ˜¯ | SME2 | FP32/small GEMM | âŒ æ— å¹¶è¡Œ |
| **KleidiAI** | âœ… æ˜¯ | SME2 | FP16/BF16/INT8 | âŒ æ— å¹¶è¡Œ |
| **OpenBLAS** | âœ… æ˜¯ | SMEï¼ˆé SME2ï¼‰ | FP32 | âŒ æ— å¹¶è¡Œ |

> æ³¨ï¼šBLIS ç­‰å…¶ä»–åº“å› ç¼ºä¹ SME æ”¯æŒè¢«æ’é™¤ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### æ€§èƒ½å¯¹æ¯”ï¼ˆFP32ï¼Œå• SME å•å…ƒï¼‰
- **å¹³å‡åŠ é€Ÿæ¯”**ï¼š
  - vs. **OpenBLAS**ï¼š**2.85Ã—**
  - vs. **KleidiAI**ï¼š**2.34Ã—**
  - vs. **LIBXSMM**ï¼š**1.95Ã—**
- **vs. Apple Accelerate**ï¼š
  - è¡Œä¸»åºï¼ˆRow-Majorï¼‰ï¼š**1.21Ã— æ›´å¿«**
  - åˆ—ä¸»åºï¼ˆCol-Majorï¼‰ï¼š**1.18Ã— æ›´å¿«**

> å›¾ 10 æ˜¾ç¤º MPGEMM åœ¨ç»å¤§å¤šæ•° workload ä¸Šå‡ä¼˜äºæ‰€æœ‰åŸºçº¿ã€‚

### å¤š SME å•å…ƒå¹¶è¡Œæ€§èƒ½
- åˆ©ç”¨åŒ P-core é›†ç¾¤ä¸­çš„ä¸¤ä¸ª SME å•å…ƒå®ç°æ¥è¿‘çº¿æ€§çš„æ‰©å±•ã€‚
- **vs. Accelerateï¼ˆå¤šæ ¸ï¼‰**ï¼š
  - è¡Œä¸»åºï¼š**1.24Ã—**
  - åˆ—ä¸»åºï¼š**1.22Ã—**
- **vs. å…¶ä»–å¼€æºåº“**ï¼ˆæœ¬èº«ä¸æ”¯æŒå¹¶è¡Œï¼‰ï¼š
  - å¹³å‡åŠ é€Ÿæ¯”è¾¾ **3.96Ã— (LIBXSMM)**ã€**4.69Ã— (KleidiAI)**ã€**5.7Ã— (OpenBLAS)**

### åŒç²¾åº¦ GEMMï¼ˆFP64ï¼‰
å°½ç®¡ SME ä¸Š FP64 ååä»…ä¸º FP32 çš„ 1/4ï¼ˆç†è®ºå³°å€¼ ~501 GFLOPSï¼‰ï¼ŒMPGEMM ä»æ¯” Accelerate å¿« **1.18Ã—**ï¼ˆå¤šæ ¸ä¸‹ï¼‰ã€‚

### ä¸è§„åˆ™çŸ©é˜µæ€§èƒ½ï¼ˆIrregular Shapesï¼‰
- æµ‹è¯• M/N âˆˆ {80, 110, 140, 170, 200}ï¼ŒK=25600
- MPGEMM åˆ©ç”¨ predication å¯„å­˜å™¨å¤„ç†è¾¹ç•Œï¼Œå¹¶ç»“åˆé«˜æ•ˆ edge kernelï¼ŒæŒç»­é¢†å…ˆäºåŸºçº¿ï¼ˆå›¾ 13ï¼‰

### æ··åˆç²¾åº¦ GEMM æ€§èƒ½
| ç±»å‹ | è¾“å…¥ç²¾åº¦ â†’ è¾“å‡ºç²¾åº¦ | å®æµ‹æ€§èƒ½ | ç›¸å¯¹ KleidiAI åŠ é€Ÿæ¯” |
|-------|------------------------|---------|------------------------|
| FP16 GEMM | FP16 â†’ FP32 | æœ€é«˜ ~2006 GFLOPS | **1.7Ã—** |
| INT8 GEMM | INT8 â†’ INT32 | æœ€é«˜ **7882 GOPS** | **çº¦ 2Ã—**ï¼ˆå›  KleidiAI ä½¿ç”¨ NEON æ‰“åŒ…æ•ˆç‡ä½ï¼‰ |
| æ•ˆç‡ | â€” | è¾¾åˆ° SMOPA å³°å€¼çš„ **94%** | â€” |

> å›¾ 14 æ˜¾ç¤ºæ··åˆç²¾åº¦ä¸‹æ›´é«˜çš„ compute-to-memory ratio å¸¦æ¥æ›´ä¼˜å®é™…æ€§èƒ½ã€‚

### æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰
ï¼ˆå›¾ 15ï¼Œä»¥ LIBXSMM ä¸º baselineï¼‰
- **+ multi-vector load**ï¼šå¹³å‡æå‡ **1.17Ã—**
- **+ partition & dual-matrix packing**ï¼šå¹³å‡æå‡ **1.62Ã—**
- **+ online packing**ï¼šæ”¶ç›Šè¾ƒå°ï¼Œå›  FMOPA å‘¨æœŸä¸è¶³ä»¥å®Œå…¨éšè—å†™å›å¼€é”€

> ç»“è®ºï¼š**åˆ†å—ä¸æ‰“åŒ…ç­–ç•¥ + å›› Z åŠ è½½** æ˜¯æ€§èƒ½æå‡çš„å…³é”®é©±åŠ¨åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **SME æ€§èƒ½é«˜åº¦ä¾èµ–å†…å­˜è®¿é—®æ¨¡å¼**ï¼šèƒ½å¦ä½¿ç”¨å›› Z å¯„å­˜å™¨åŠ è½½å†³å®šäº†æ˜¯å¦èƒ½è¾¾åˆ°è¿‘ 900 GB/s çš„å¸¦å®½ï¼›å¦åˆ™é€€åŒ–è‡³ 230 GB/sã€‚
2. **ä¼ ç»Ÿä¸‰é‡å¾ªç¯ä¸é€‚åˆ SME**ï¼šå¿…é¡»é‡æ„ä¸ºå…­çº§ blocked loopï¼Œç»“åˆè§£ææ¨¡å‹é€‰æ‹©æœ€ä¼˜åˆ†å—å‚æ•°ã€‚
3. **åŒçŸ©é˜µæ‰“åŒ… + åœ¨çº¿æ‰“åŒ…å¯æ˜¾è‘—æ”¹å–„ç¼“å­˜è¡Œä¸º**ï¼šå³ä½¿å¢åŠ æ‰“åŒ…å¼€é”€ï¼Œä¹Ÿèƒ½é€šè¿‡æé«˜ç©ºé—´å±€éƒ¨æ€§å’Œ TLB æ•ˆç‡è·å¾—å‡€æ”¶ç›Šã€‚
4. **micro-kernel å½¢çŠ¶è‡³å…³é‡è¦**ï¼š16Ã—64 æ¯” 32Ã—32 æ›´åˆ©äºå›› Z åŠ è½½ï¼Œæ›´é€‚åˆå¤§ GEMMã€‚
5. **MPGEMM åœ¨å¼€æ”¾ç”Ÿæ€ä¸­é¦–æ¬¡é€¼è¿‘å‚å•†é—­æºåº“æ€§èƒ½**ï¼šåœ¨å¤šä¸ªç²¾åº¦å’Œåœºæ™¯ä¸‹è¶…è¶Š Apple Accelerateã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **å¹³å°ç‰¹å®šæ€§å¼º**ï¼šç›®å‰å®ç°åŸºäº Apple M4 Pro çš„å›ºå®š SVL=512bitï¼Œéœ€é€‚é…ä¸åŒ SVL çš„é€šç”¨åŒ–ç‰ˆæœ¬ã€‚
- **å¹¶è¡Œè°ƒåº¦ä¾èµ–è¿è¡Œæ—¶ç¯å¢ƒ**ï¼šmacOS ä¸å…è®¸æ˜¾å¼ç»‘å®šçº¿ç¨‹ä¸æ ¸å¿ƒï¼Œå½±å“ç»†ç²’åº¦æ§åˆ¶ã€‚
- **å †å†…å­˜åˆ†é…è¦æ±‚ä¸¥æ ¼**ï¼šéœ€é¿å…æ ˆä¸Šåˆ†é…ä»¥é˜² core ä¸ SME å†…å­˜é¡ºåºå†²çªå¼•å‘ stallã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•æ”¯æŒæ›´å¤šæ•°æ®ç±»å‹ï¼ˆå¦‚ BF16ã€INT4ï¼‰åŠç¨€ç– GEMMã€‚
- æ¢ç´¢è‡ªåŠ¨è°ƒä¼˜æ¡†æ¶ï¼ˆauto-tunerï¼‰æ›¿ä»£è§£ææ¨¡å‹ï¼Œé€‚åº”æ›´å¤šå¹³å°ã€‚
- å°†ä¼˜åŒ–æ€æƒ³è¿ç§»è‡³å…¶ä»– SME åŠ é€Ÿç®—å­ï¼ˆå¦‚ convolutionã€attentionï¼‰ã€‚
- æ”¯æŒè·¨é›†ç¾¤æ›´ç²¾ç»†çš„ä»»åŠ¡è°ƒåº¦æœºåˆ¶ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> MPGEMM é€šè¿‡å¯¹ ARM SME æ¶æ„çš„æ·±åº¦å‰–æï¼Œæå‡ºäº† cache-aware åˆ†å—ã€åŒçŸ©é˜µåœ¨çº¿æ‰“åŒ…ã€å›› Z å¯„å­˜å™¨åŠ è½½ç­‰å…³é”®æŠ€æœ¯ï¼Œåœ¨ Apple M4 Pro ä¸Šå®ç°äº†å¯¹ Apple Accelerate çš„å…¨é¢åè¶…ï¼ˆå¹³å‡ 1.23Ã—ï¼‰ï¼Œæˆä¸ºé¦–ä¸ªåœ¨å¤§è§„æ¨¡ GEMM ä¸Šå……åˆ†å‘æŒ¥ SME æ½œåŠ›çš„å¼€æºè§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 13. [Rethinking Output Alignment For 1-bit Post-Training Quantization of Large Language Models](https://arxiv.org/abs/2512.21651)

**Authors**: Dung Anh Hoang, Cuong Pham, Cuong Nguyen, Trung le, Jianfei Cai, Thanh-Toan Do  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.21651v1  

#### Abstract
Large Language Models (LLMs) deliver strong performance across a wide range of NLP tasks, but their massive sizes hinder deployment on resource-constrained devices. To reduce their computational and memory burden, various compression techniques have been proposed, including quantization, pruning, an...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šRethinking Output Alignment For 1-bit Post-Training Quantization of Large Language Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
æœ¬æ–‡èšç„¦äº **1-bit Post-Training Quantization (PTQ)** åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­çš„åº”ç”¨æŒ‘æˆ˜ã€‚å°½ç®¡ä½æ¯”ç‰¹é‡åŒ–èƒ½æ˜¾è‘—é™ä½æ¨¡å‹å­˜å‚¨å’Œè®¡ç®—å¼€é”€ï¼Œä½†ç°æœ‰çš„ **1-bit PTQ æ–¹æ³•åœ¨æ€§èƒ½ä¸Šé€šå¸¸å‡ºç°ä¸¥é‡é€€åŒ–**ï¼Œå°¤å…¶æ˜¯å½“é‡‡ç”¨è¾“å‡ºå¯¹é½ï¼ˆoutput alignmentï¼‰ç­–ç•¥æ—¶ã€‚

ä½œè€…æŒ‡å‡ºï¼Œå½“å‰ä¸»æµæ–¹æ³•å¤šä¸º **weight-matching**ï¼ˆå¦‚æœ€å°åŒ– $||W - \hat{W}||$ï¼‰ï¼Œè€Œæ›´ç¬¦åˆé‡åŒ–ç›®æ ‡çš„ **output-matching**ï¼ˆå³æœ€å°åŒ– $||XW - X\hat{W}||$ï¼‰å´å¸¸è¡¨ç°ä¸ä½³ã€‚å…¶æ ¹æœ¬åŸå› åœ¨äºï¼š

- å±‚çº§è¾“å‡ºå¯¹é½ä¸ä¿è¯å—çº§ï¼ˆblock-levelï¼‰è¯¯å·®ä¸‹é™ï¼›
- é‡åŒ–è¯¯å·®åœ¨æ·±å±‚ç½‘ç»œä¸­ç´¯ç§¯ï¼Œå¯¼è‡´ä¼ªç›®æ ‡ï¼ˆpseudo targetï¼‰åç¦»çœŸå®å…¨ç²¾åº¦è¾“å‡ºï¼›
- æ— å·®åˆ«åœ°è¿›è¡Œè¾“å‡ºå¯¹é½ä¼šç ´åæ³¨æ„åŠ›æœºåˆ¶ä¸­çš„ token é—´å…³ç³»ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§ **æ•°æ®æ„ŸçŸ¥çš„ã€é€‰æ‹©æ€§è¾“å‡ºå¯¹é½ç­–ç•¥**ï¼Œæ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰Selective Layer-wise Output Matching
- ä¸å¯¹æ‰€æœ‰å±‚å¼ºåˆ¶è¿›è¡Œè¾“å‡ºå¯¹é½ï¼Œè€Œæ˜¯**ä»…åœ¨æ¯ä¸ª Transformer block çš„æœ€åä¸€ä¸ªå…¨è¿æ¥å±‚ï¼ˆFinal FCï¼‰åº”ç”¨è¾“å‡ºå¯¹é½**ã€‚
- å…¶ä½™å±‚ä»ä½¿ç”¨ weight alignmentï¼ˆå¦‚ ARB-RCï¼‰ï¼Œä»¥ç¨³å®šä¸­é—´è¡¨ç¤ºå¹¶å‡å°‘è¯¯å·®ä¼ æ’­ã€‚

#### ï¼ˆ2ï¼‰ä¿®æ­£ä¼˜åŒ–ç›®æ ‡ä»¥è€ƒè™‘æ¿€æ´»è¯¯å·®ç´¯ç§¯
- å°†ä¼ ç»ŸåŸºäºé‡åŒ–åè¾“å…¥ $X$ çš„è¾“å‡ºé‡å»ºæŸå¤± $||XW - X\hat{W}||$ æ”¹ä¸ºä½¿ç”¨**å…¨ç²¾åº¦è¾“å…¥ $X$** æ„å»ºçš„ç›®æ ‡ï¼š
  $$
  \mathcal{L}_{\text{out}} = ||XW - X\hat{W}||^2
  $$
- è¿™ç¡®ä¿äº†ä¼˜åŒ–ç›®æ ‡å§‹ç»ˆé€¼è¿‘çœŸå®çš„ full-precision è¾“å‡ºï¼Œç¼“è§£äº†å› å‰åºå±‚é‡åŒ–å¼•å…¥çš„æ¿€æ´»å¤±é…é—®é¢˜ã€‚

#### ï¼ˆ3ï¼‰Attention Matrix Preservation (AMP)
- å¼•å…¥ä¸€ç§æ–°çš„æ©ç æœºåˆ¶ AMPï¼Œç”¨äºä¿æŠ¤æ³¨æ„åŠ›çŸ©é˜µç»“æ„ã€‚
- AMP é€šè¿‡è®¡ç®— token ç›¸ä¼¼æ€§çŸ©é˜µï¼ˆtoken-similarity matrixï¼‰ç›¸å¯¹äºé‡åŒ–å‚æ•°çš„æ¢¯åº¦ç¬¦å·æ¥ç”Ÿæˆ maskï¼Œå¹¶æŒ‡å¯¼å‚æ•°æ›´æ–°æ–¹å‘ï¼Œé˜²æ­¢æ³¨æ„åŠ›è¡Œä¸ºé€€åŒ–ã€‚
- ç‰¹åˆ«é€‚ç”¨äº LLaMA ç­‰ä¾èµ– RMSNorm çš„æ¶æ„ï¼Œå› å…¶å¯¹è¡¨ç¤ºæ–¹å‘æ•æ„Ÿã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´æœ‰æ•ˆçš„è¾“å‡ºå¯¹é½**ï¼šæ˜¾å¼å»ºæ¨¡è¯¯å·®ç´¯ç§¯ï¼Œæå‡å¯¹é½è´¨é‡ï¼›
- **ä¿ç•™æ³¨æ„åŠ›ç»“æ„**ï¼šAMP é˜²æ­¢ token å…³ç³»è¢«ç ´åï¼Œå°¤å…¶åœ¨æ·±å±‚æœ‰æ•ˆï¼›
- **é«˜æ•ˆä¸”å®ç”¨**ï¼šæ— éœ€é‡è®­ç»ƒï¼Œä»…éœ€å°è§„æ¨¡æ ¡å‡†é›†ï¼ˆå¦‚ C4ï¼‰ï¼Œé€‚åˆéƒ¨ç½²åœºæ™¯ï¼›
- **æ€§èƒ½ä¼˜äº SOTA**ï¼šåœ¨å¤šä¸ª LLM æ¶æ„å’Œä»»åŠ¡ä¸Šä¸€è‡´è¶…è¶Š BiLLMã€ARB-RCã€ARB-X ç­‰å…ˆè¿› 1-bit PTQ æ–¹æ³•ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **æ ¡å‡†æ•°æ®é›†ï¼ˆCalibration Setï¼‰**ï¼š
  - `C4`ï¼šç”¨äºæ¨¡å‹é‡åŒ–è¿‡ç¨‹ä¸­çš„å‚æ•°è°ƒæ•´ã€‚
- **è¯„ä¼°æ•°æ®é›†**ï¼š
  - **è¯­è¨€å»ºæ¨¡ä»»åŠ¡**ï¼š`WikiText2`, `PTB`, `C4` â€”â€” æŠ¥å‘Š **Perplexity (PPL â†“)**ã€‚
  - **ä¸‹æ¸¸é›¶æ ·æœ¬é—®ç­”ä»»åŠ¡**ï¼š`ARC-Easy`, `ARC-Challenge`, `PIQA`, `BoolQ`, `HellaSwag`, `WinoGrande`, `OBQA`, `LAMBADA` â€”â€” æŠ¥å‘Š **Accuracy (â†‘)**ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹èŒƒå›´**ï¼š
  - OPT ç³»åˆ—ï¼šOPT-1.3B, 2.7B, 6.7B, 13B, 30B
  - LLaMA ç³»åˆ—ï¼šLLaMA-2-7B, 13Bï¼›LLaMA-3-8B
- **é‡åŒ–é…ç½®**ï¼š
  - 1-bit æƒé‡é‡åŒ–ï¼ˆÂ±1ï¼‰
  - Block size å›ºå®šä¸º 128
  - åºåˆ—é•¿åº¦ 2048
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - ä¸»è¦æŒ‡æ ‡ï¼š**Perplexity (â†“)** å’Œ **Zero-shot Accuracy (â†‘)**
  - æ¶ˆèå®éªŒåˆ†æï¼šAMP å½±å“ã€è¯¯å·®ç›®æ ‡æ¯”è¾ƒã€ä¸åŒå±‚åº”ç”¨æ•ˆæœç­‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | å¯¹é½æ–¹å¼ |
|------|------|----------|
| **Full Precision** | åŸå§‹æµ®ç‚¹æ¨¡å‹ | - |
| **PB-LLM** | PTQ | Weight Alignment |
| **BiLLM** | PTQ | Weight Alignment |
| **ARB-RC** | PTQ | Weight Alignment |
| **ARB-X** | PTQ | Output Alignment |
| **Ours** | æœ¬æ–‡æ–¹æ³• | Selective Output Alignment + AMP |

æ‰€æœ‰åŸºçº¿å‡å¤ç°è‡ªåŸè®ºæ–‡å®ç°ç»†èŠ‚ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & 2ï¼‰

#### âœ… OPT æ¨¡å‹ï¼ˆTable 1ï¼‰
| æ¨¡å‹ | æ–¹æ³• | C4 PPL | WikiText2 PPL | Avg QA Acc (%) |
|------|------|--------|--------------|----------------|
| OPT-13B | Full Precision | 12.06 | 10.13 | - |
| OPT-13B | ARB-RC | 15.07 | 13.10 | 55.01 |
| OPT-13B | ARB-X | 17.71 | 15.47 | 49.19 |
| OPT-13B | **Ours** | **14.71** | **12.84** | **55.06** |

> åœ¨ OPT-1.3B ä¸Šï¼Œç›¸æ¯” ARB-RC å®ç° **4.85 PPL ä¸‹é™**ï¼Œæ˜¾ç¤ºå¼ºé²æ£’æ€§ã€‚

#### âœ… LLaMA æ¨¡å‹ï¼ˆTable 2ï¼‰
| æ¨¡å‹ | æ–¹æ³• | C4 PPL | WikiText2 PPL |
|------|------|--------|--------------|
| LLaMA-2-7B | Full Precision | 7.26 | 5.47 |
| LLaMA-2-7B | ARB-RC | 25.87 | 16.25 |
| LLaMA-2-7B | ARB-X | 28.02 | 21.61 |
| LLaMA-2-7B | **Ours** | **19.25** | **15.42** |

> åœ¨ LLaMA-2-13B ä¸Šï¼Œç›¸æ¯” ARB-RC å®ç° **~6 PPL æ”¹å–„**ï¼Œä¸”åœ¨ QA ä»»åŠ¡ä¸Šå¹³å‡æå‡ **0.78%**ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨æ‰€æœ‰æµ‹è¯•æ¨¡å‹å’Œæ•°æ®é›†ä¸­ï¼Œ**Ours æ–¹æ³•å‡ä¼˜äºæ‰€æœ‰ 1-bit PTQ åŸºçº¿**ã€‚
- ç›¸æ¯”çº¯ weight alignment æ–¹æ³•ï¼ˆå¦‚ ARB-RCï¼‰ï¼Œæœ¬æ–¹æ³•åœ¨ä¿æŒç¨³å®šæ€§çš„åŒæ—¶è¿›ä¸€æ­¥é™ä½è¾“å‡ºè¯¯å·®ï¼›
- ç›¸æ¯” naive output alignmentï¼ˆå¦‚ ARB-Xï¼‰ï¼Œæœ¬æ–¹æ³•é¿å…äº†æ³¨æ„åŠ›é€€åŒ–å’Œè¯¯å·®ç´¯ç§¯é—®é¢˜ï¼Œæ˜¾è‘—æå‡æ€§èƒ½ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ğŸ”¹ æ¿€æ´»è¯¯å·® vs è¾“å‡ºè¯¯å·®ç›®æ ‡ï¼ˆTable 4ï¼‰
| æ¨¡å‹ | Objective | C4 PPL | WikiText2 PPL |
|------|-----------|--------|-------------|
| LLaMA-2-7B | Activation-conditioned Error | 19.97 | 15.66 |
| LLaMA-2-7B | **Output Error (ours)** | **19.25** | **15.42** |

> æ˜¾å¼è€ƒè™‘çœŸå®è¾“å‡ºç›®æ ‡å¸¦æ¥çº¦ **0.7 PPL æå‡**ã€‚

#### ğŸ”¹ Attention Matrix Preservation (AMP) çš„å½±å“ï¼ˆTable 3ï¼‰
| æ¨¡å‹ | è®¾ç½® | C4 PPL | WikiText2 PPL |
|------|------|--------|-------------|
| LLaMA-2-7B | No AMP | 29.12 | 26.24 |
| LLaMA-2-7B | **With AMP** | **19.25** | **15.42** |

> AMP è´¡çŒ®å·¨å¤§ï¼Œå°¤å…¶åœ¨ LLaMA ä¸Šï¼Œå»é™¤ AMP å¯¼è‡´ **PPL æ¶åŒ–è¶… 10 ç‚¹**ï¼Œè¯´æ˜å…¶å¯¹æ³¨æ„åŠ›ç»“æ„ä¿æŠ¤è‡³å…³é‡è¦ã€‚

#### ğŸ”¹ ä¸åŒå±‚åº”ç”¨è¾“å‡ºå¯¹é½çš„æ•ˆæœï¼ˆTable 5ï¼‰
| å±‚ | C4 PPL (LLaMA-2-7B) |
|----|--------------------|
| Query | 20.08 |
| Key | 20.80 |
| Value | 21.44 |
| Attn Out | 21.02 |
| **Final FC** | **19.25** |

> è¡¨æ˜å°†è¾“å‡ºå¯¹é½åº”ç”¨äº **block çš„æœ€ç»ˆå…¨è¿æ¥å±‚**æœ€ä¸ºæœ‰æ•ˆï¼ŒéªŒè¯äº† selective alignment è®¾è®¡çš„åˆç†æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **Naive Output Alignment å¹¶éæ€»æ˜¯æœ‰æ•ˆ**ï¼š
   - è™½ç„¶ç†è®ºä¸Šæ›´è´´è¿‘é‡åŒ–ç›®æ ‡ï¼Œä½†åœ¨å®è·µä¸­ç”±äºè¯¯å·®ç´¯ç§¯å’Œæ³¨æ„åŠ›å¹²æ‰°ï¼Œåè€Œå¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚
2. **Block-Level Loss æ›´é‡è¦**ï¼š
   - å•çº¯ä¼˜åŒ– layer-wise è¾“å‡ºè¯¯å·®ä¸èƒ½ä¿è¯ block æˆ–æ•´ä½“æ€§èƒ½æå‡ã€‚
3. **Attention Mechanism ææ˜“å—ç ´å**ï¼š
   - å°¤å…¶æ˜¯ä½¿ç”¨ RMSNorm çš„ LLaMA æ¶æ„ï¼Œå¯¹è¡¨ç¤ºæ–¹å‘æ•æ„Ÿï¼Œéœ€è¦ä¸“é—¨æœºåˆ¶ï¼ˆå¦‚ AMPï¼‰åŠ ä»¥ä¿æŠ¤ã€‚
4. **Selective + Corrective Output Alignment æ˜¯å…³é”®**ï¼š
   - ç»“åˆçœŸå®ç›®æ ‡è¾“å‡ºã€é€‰æ‹©æ€§å¯¹é½æœ€åä¸€å±‚ã€å¼•å…¥ AMP æ©ç ï¼Œä¸‰è€…ååŒå¯æ˜¾è‘—æå‡ 1-bit é‡åŒ–æ€§èƒ½ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ–¹æ³•ä»å±€é™äº **Transformer ä¸­çš„ FFN å±‚**ï¼Œæœªæ‰©å±•åˆ° Attention æƒé‡æˆ–å…¶ä»–ç»„ä»¶ï¼›
- AMP æœºåˆ¶å¼•å…¥é¢å¤–è®¡ç®—ï¼ˆè™½ä¸å½±å“æ¨ç†ï¼‰ï¼Œå¢åŠ äº†é‡åŒ–é˜¶æ®µå¤æ‚åº¦ï¼›
- æ‰€æœ‰å®éªŒåŸºäºå•å¡ A100 å®Œæˆï¼Œå¤§è§„æ¨¡åˆ†å¸ƒå¼é‡åŒ–æ•ˆç‡å°šæœªéªŒè¯ï¼›
- æœªæ¢ç´¢ä½äº 1-bitï¼ˆå¦‚ sub-1-bitï¼‰æˆ–æ··åˆç²¾åº¦æ–¹æ¡ˆã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† selective output alignment æ‰©å±•è‡³ Attention å±‚ï¼›
- æ¢ç´¢åŠ¨æ€ AMP mask å­¦ä¹ æœºåˆ¶ï¼›
- ç»“åˆ QAT æ€æƒ³ï¼Œåœ¨æä½ä½å®½ä¸‹å®ç°å¾®è°ƒå¢å¼ºï¼›
- æ¨å¹¿åˆ°è§†è§‰-è¯­è¨€å¤šæ¨¡æ€å¤§æ¨¡å‹çš„æç«¯é‡åŒ–ï¼›
- ç ”ç©¶æ›´é«˜æ•ˆçš„ closed-form solver ä»¥åŠ é€Ÿé‡åŒ–æµç¨‹ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡é‡æ–°æ€è€ƒäº† 1-bit PTQ ä¸­ output alignment çš„æœ‰æ•ˆæ€§ï¼Œæå‡ºä¸€ç§ç»“åˆ **çœŸå®ç›®æ ‡é‡æ„ã€é€‰æ‹©æ€§å¯¹é½ã€AMP æ³¨æ„åŠ›ä¿æŠ¤** çš„æ–°æ¡†æ¶ï¼Œåœ¨å¤šç§ LLM ä¸Šå®ç°äº†å½“å‰æœ€ä¼˜çš„ 1-bit é‡åŒ–æ€§èƒ½ï¼Œä¸ºæç«¯å‹ç¼©ä¸‹çš„å¤§æ¨¡å‹éƒ¨ç½²æä¾›äº†æ–°æ€è·¯ã€‚

</details>

---

### 14. [DuaDeep-SeqAffinity: Dual-Stream Deep Learning Framework for Sequence-Only Antigen-Antibody Affinity Prediction](https://arxiv.org/abs/2512.22007)

**Authors**: Aicha Boutorh, Soumia Bouyahiaoui, Sara Belhadj, Nour El Yakine Guendouz, Manel Kara Laouar  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.22007v1  

#### Abstract
Predicting the binding affinity between antigens and antibodies is fundamental to drug discovery and vaccine development. Traditional computational approaches often rely on experimentally determined 3D structures, which are scarce and computationally expensive to obtain. This paper introduces DuaDee...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDuaDeep-SeqAffinity: Dual-Stream Deep Learning Framework for Sequence-Only Antigen-Antibody Affinity Prediction

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»ŸæŠ—åŸ-æŠ—ä½“äº²å’ŒåŠ›é¢„æµ‹æ–¹æ³•ä¸¥é‡ä¾èµ–å®éªŒæµ‹å®šçš„ä¸‰ç»´ï¼ˆ3Dï¼‰ç»“æ„ï¼Œè€Œè¿™äº›ç»“æ„è·å–æˆæœ¬é«˜ã€è€—æ—¶é•¿ï¼Œä¸”åœ¨æŠ—ä½“-æŠ—åŸå¤åˆç‰©ä¸­ï¼ˆå°¤å…¶æ˜¯CDR-H3ç¯ï¼‰å­˜åœ¨é«˜åº¦æ„è±¡çµæ´»æ€§ï¼Œå¯¼è‡´åŸºäºç»“æ„çš„æ–¹æ³•é¢ä¸´â€œ**ç»“æ„æ€§ç“¶é¢ˆ**â€ï¼ˆstructural bottleneckï¼‰ã€‚æ­¤å¤–ï¼ŒAlphaFold2/3ç­‰ç»“æ„é¢„æµ‹å·¥å…·åœ¨æŠ—ä½“-æŠ—åŸå¯¹æ¥ä»»åŠ¡ä¸Šå¤±è´¥ç‡ä»é«˜è¾¾çº¦60%ã€‚

è¯¥ç ”ç©¶æ—¨åœ¨è§£å†³ï¼š**å¦‚ä½•ä»…ä»æ°¨åŸºé…¸åºåˆ—å‡ºå‘ï¼Œé«˜æ•ˆã€å‡†ç¡®åœ°é¢„æµ‹æŠ—åŸ-æŠ—ä½“ç»“åˆäº²å’ŒåŠ›**ï¼Œä»è€Œå®ç°é«˜é€šé‡ç­›é€‰å’ŒåŠ é€Ÿæ²»ç–—æ€§æŠ—ä½“å¼€å‘ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æå‡º **DuaDeep-SeqAffinity** â€”â€”ä¸€ç§å…¨æ–°çš„**åŒæµæ·±åº¦å­¦ä¹ æ¡†æ¶**ï¼ˆDual-Stream Deep Learning Frameworkï¼‰ï¼Œç”¨äº**çº¯åºåˆ—**ï¼ˆsequence-onlyï¼‰çš„æŠ—åŸ-æŠ—ä½“äº²å’ŒåŠ›é¢„æµ‹ã€‚

å…¶æ ¸å¿ƒåˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š
- **åŒæµæ··åˆæ¶æ„è®¾è®¡**ï¼šé‡‡ç”¨å¹¶è¡Œçš„ä¸¤ä¸ªåˆ†æ”¯åˆ†åˆ«æå–ç‰¹å¾ï¼š
  - **Transformer åˆ†æ”¯**ï¼šæ•æ‰åºåˆ—ä¸­çš„**é•¿ç¨‹å…¨å±€ä¸Šä¸‹æ–‡ä¾èµ–å…³ç³»**ï¼Œç†è§£è›‹ç™½è´¨çš„æ•´ä½“æŠ˜å æ¨¡å¼å’Œç¨³å®šæ€§ã€‚
  - **1D CNN åˆ†æ”¯**ï¼šè¯†åˆ«**å±€éƒ¨åºåˆ—æ¨¡ä½“**ï¼ˆlocal motifsï¼‰ï¼Œå¦‚ç»“åˆçƒ­ç‚¹åŒºåŸŸçš„ç‰©ç†åŒ–å­¦ç¯å¢ƒã€‚
- **å¤šå°ºåº¦ç‰¹å¾èåˆæœºåˆ¶**ï¼šé€šè¿‡ä¸“é—¨è®¾è®¡çš„èåˆæ¨¡å—æ•´åˆæ¥è‡ªTransformerå’ŒCNNçš„äº’è¡¥ç‰¹å¾ï¼Œå½¢æˆæ›´å…¨é¢çš„è¡¨ç¤ºã€‚
- **åŸºäºESM-2çš„é¢„è®­ç»ƒåµŒå…¥**ï¼šåˆ©ç”¨å¤§è§„æ¨¡é¢„è®­ç»ƒçš„Protein Language Modelï¼ˆPLMï¼‰â€”â€”**ESM-2**ç”Ÿæˆé«˜è´¨é‡çš„ä¸Šä¸‹æ–‡åŒ–æ®‹åŸºåµŒå…¥ï¼Œä½œä¸ºæ¨¡å‹è¾“å…¥ï¼Œæ— éœ€æ‰‹å·¥ç‰¹å¾å·¥ç¨‹ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| å¯¹æ¯”ç»´åº¦ | DuaDeep-SeqAffinity | å…¶ä»–ä¸»æµæ–¹æ³• |
|--------|---------------------|-------------|
| **è¾“å…¥è¦æ±‚** | ä»…éœ€æ°¨åŸºé…¸åºåˆ—ï¼ˆsequence-onlyï¼‰ | å¤šæ•°SOTAæ–¹æ³•éœ€3Dç»“æ„ï¼ˆå¦‚WALLE-Affinityï¼‰ |
| **è®¡ç®—æ•ˆç‡** | é«˜æ•ˆã€å¯æ‰©å±•ï¼Œé€‚åˆå¤§è§„æ¨¡ç­›é€‰ | ç»“æ„å»ºæ¨¡ä¸å¯¹æ¥è®¡ç®—å¼€é”€å¤§ |
| **æ¶æ„ä¼˜åŠ¿** | æ˜¾å¼åˆ†ç¦»å…¨å±€ä¸å±€éƒ¨ç‰¹å¾æå–ï¼Œé¿å…ä¿¡æ¯ä¸¢å¤± | å•ä¸€Transformeræˆ–CNNéš¾ä»¥å…¼é¡¾å¤šå°ºåº¦ç‰¹æ€§ |
| **æ€§èƒ½è¡¨ç°** | åœ¨å›å½’ä¸åˆ†ç±»ä»»åŠ¡ä¸Šå‡è¶…è¶ŠSOTA | åºåˆ—æ¨¡å‹å—é™äºè¡¨è¾¾èƒ½åŠ›ï¼›ç»“æ„æ¨¡å‹å—é™äºæ¨¡æ¿å¯ç”¨æ€§ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä½¿ç”¨å…¬å¼€åŸºå‡†æ•°æ®é›† **AbRank**ï¼ŒåŒ…å«ç»å®éªŒéªŒè¯çš„æŠ—åŸ-æŠ—ä½“å¯¹åŠå…¶ç»“åˆäº²å’ŒåŠ›ï¼ˆKdå€¼ï¼Œå•ä½ä¸ºnMï¼‰ã€‚
- æ¯æ¡è®°å½•åŒ…å«æŠ—åŸã€æŠ—ä½“é‡é“¾ä¸è½»é“¾çš„æ°¨åŸºé…¸åºåˆ—ã€‚
- ç»è¿‡æ¸…æ´—åä¿ç•™ç”Ÿç‰©æ„ä¹‰èŒƒå›´å†…çš„æ ·æœ¬ï¼ˆ$10^{-3} < \text{Kd} < 10^9$ nMï¼‰ï¼Œå¹¶å°†Kdè½¬æ¢ä¸ºæ­£ç›¸å…³çš„ **pKd = 9 - logâ‚â‚€(Kd)**ã€‚
- pKdè¿›ä¸€æ­¥è¿›è¡Œz-scoreæ ‡å‡†åŒ–ä»¥ç¨³å®šè®­ç»ƒã€‚

### æ•°æ®åˆ’åˆ†
- éšæœºåˆ’åˆ†ä¸ºï¼š**80% è®­ç»ƒé›†ã€10% éªŒè¯é›†ã€10% æµ‹è¯•é›†**
- ç¡®ä¿æŠ—åŸä¸æŠ—ä½“åºåˆ—åœ¨å„é›†åˆé—´æ— é‡å ï¼Œè¯„ä¼°æ¨¡å‹å¯¹**æœªè§é…å¯¹ç»„åˆ**çš„æ³›åŒ–èƒ½åŠ›ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **å›å½’ä»»åŠ¡æŒ‡æ ‡**ï¼š
  - RMSEï¼ˆRoot Mean Square Errorï¼‰
  - MAEï¼ˆMean Absolute Errorï¼‰
  - $R^2$ï¼ˆCoefficient of Determinationï¼‰
  - Pearson Correlation
  - Spearman Correlation
- **åˆ†ç±»ä»»åŠ¡æŒ‡æ ‡**ï¼š
  - AUCï¼ˆArea Under the ROC Curveï¼‰ï¼Œç”¨äºè¯„ä¼°æ’åºèƒ½åŠ›ï¼ˆaffinity rankingï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **å†…éƒ¨åŸºçº¿**ï¼ˆæ¶ˆèå®éªŒï¼‰ï¼š
  - **ESM-C**ï¼šESM-2 + CNNï¼ˆä»…å±€éƒ¨ç‰¹å¾ï¼‰
  - **ESM-T**ï¼šESM-2 + Transformerï¼ˆä»…å…¨å±€ç‰¹å¾ï¼‰
- **å¤–éƒ¨SOTAå¯¹æ¯”**ï¼š
  - **DG-Affinity**ï¼ˆsequence-only, ConvNeXt-basedï¼‰
  - **MVSF-AB**ï¼ˆsequence-only, multi-view CNN + MLPï¼‰
  - **WALLE-Affinity**ï¼ˆhybrid, structure + sequenceï¼‰
  - **MINT** å’Œ **ESM-2 + AntiBERTy**ï¼ˆpure sequence, ranking-basedï¼‰

æ‰€æœ‰æ¨¡å‹å‡åŸºäºç›¸åŒçš„æ•°æ®é¢„å¤„ç†æµç¨‹å’ŒESM-2åµŒå…¥ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæµ‹è¯•é›†ï¼‰

#### å›å½’æ€§èƒ½å¯¹æ¯”ï¼ˆTable 1 & Table 2ï¼‰

| Model | RMSE â†“ | MAE â†“ | $R^2$ â†‘ | Pearson â†‘ | Spearman â†‘ |
|-------|--------|--------|---------|-----------|------------|
| ESM-C (CNN-only) | 0.7733 | 0.5722 | 0.397 | 0.636 | 0.614 |
| ESM-T (Transformer-only) | 0.7985 | 0.5822 | 0.357 | 0.625 | 0.603 |
| **DuaDeep (Ours)** | **0.7373** | **0.5116** | **0.460** | **0.688** | **0.680** |

> âœ… DuaDeepåœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºå•åˆ†æ”¯å˜ä½“ï¼ŒRMSEé™ä½è¶…è¿‡4.6%ï¼ŒPearsonæå‡çº¦6â€“8ä¸ªç™¾åˆ†ç‚¹ã€‚

#### ä¸å…¶ä»–SOTAæ–¹æ³•å¯¹æ¯”ï¼ˆTable 2ï¼‰

| Model | Input Type | Pearson | $R^2$ | RMSE |
|-------|------------|--------|--------|------|
| DG-Affinity [44] | sequence-only | 0.6556 | â€“ | â€“ |
| MVSF-AB [46] | sequence-only | â€“ | 0.467 | 1.447 |
| **DuaDeep (ours)** | **sequence-only** | **0.688** | **0.460** | **0.737** |

> â­ å°½ç®¡MVSF-ABæœ‰ç›¸è¿‘çš„$R^2$ï¼Œä½†å…¶RMSEè¿œé«˜äºDuaDeepï¼ˆ1.447 vs 0.737ï¼‰ï¼Œè¯´æ˜DuaDeepé¢„æµ‹æ›´ç²¾ç¡®ã€‚

#### æ’åºæ€§èƒ½ï¼ˆAUCï¼‰å¯¹æ¯”ï¼ˆTable 3ï¼‰

| Model | Input Type | AUC â†‘ |
|-------|------------|------|
| WALLE-Affinity (Ranking) [50] | structure + sequence | 0.866 |
| WALLE-Affinity (Regression) [50] | structure + sequence | 0.833 |
| MINT [49] | sequence-only | 0.775 |
| ESM-2 + AntiBERTy [53] | sequence-only | 0.761 |
| **DuaDeep (ours)** | **sequence-only** | **0.890** |

> ğŸ¯ **DuaDeepä»¥çº¯åºåˆ—è¾“å…¥ï¼ŒAUCè¾¾åˆ°0.890ï¼Œç”šè‡³è¶…è¿‡äº†ä¾èµ–3Dç»“æ„çš„WALLE-Affinityï¼ˆ0.866ï¼‰**ï¼Œè¯æ˜å…¶å¼ºå¤§çš„äº¤äº’è¯†åˆ«èƒ½åŠ›ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **åŒæµæ¶æ„æœ‰æ•ˆæ€§éªŒè¯**ï¼š
  - CNNåˆ†æ”¯æ“…é•¿æ•æ‰å±€éƒ¨ç»“åˆç‰¹å¾ï¼ˆå¦‚CDRåŒºç†åŒ–æ€§è´¨ï¼‰ï¼Œåœ¨å›å½’ä»»åŠ¡ä¸­ç•¥ä¼˜äºTransformerã€‚
  - Transformeråˆ†æ”¯æ›´åˆ©äºå»ºæ¨¡æ•´ä½“æ„è±¡åå¥½ï¼Œåœ¨æ—©æœŸæ”¶æ•›æ›´å¿«ã€‚
  - **ä¸¤è€…èåˆåæ€§èƒ½å…¨é¢æå‡**ï¼Œè¡¨æ˜**å…¨å±€ä¸å±€éƒ¨ç‰¹å¾å…·æœ‰å¼ºäº’è¡¥æ€§**ã€‚
- å­¦ä¹ æ›²çº¿æ˜¾ç¤ºï¼ŒDuaDeepå…·æœ‰æ›´ä½çš„éªŒè¯RMSEå’Œå¹³æ»‘çš„æ”¶æ•›è¿‡ç¨‹ï¼ˆå›¾7ï¼‰ï¼Œè¯´æ˜æ¨¡å‹å…·å¤‡è‰¯å¥½æ³›åŒ–èƒ½åŠ›å’Œæ­£åˆ™åŒ–æ•ˆæœã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **é«˜è´¨é‡åºåˆ—åµŒå…¥è¶³ä»¥æ›¿ä»£3Dç»“æ„ä¿¡æ¯**ï¼š
   - åˆ©ç”¨ESM-2ç­‰PLMç”Ÿæˆçš„ä¸Šä¸‹æ–‡åŒ–åµŒå…¥å·²éšå¼ç¼–ç äº†è¶³å¤Ÿçš„ç»“æ„ä¸è¿›åŒ–ä¿¡æ¯ï¼Œèƒ½å¤Ÿæ”¯æŒé«˜ç²¾åº¦äº²å’ŒåŠ›é¢„æµ‹ã€‚
   
2. **å¤šå°ºåº¦ç‰¹å¾æå–è‡³å…³é‡è¦**ï¼š
   - æŠ—åŸ-æŠ—ä½“ç›¸äº’ä½œç”¨æ—¢æ¶‰åŠè¿œç¨‹ç©ºé—´åŒ¹é…ï¼ˆç”±Transformeræ•è·ï¼‰ï¼Œä¹Ÿä¾èµ–å±€éƒ¨æ¥è§¦ç•Œé¢çš„ç†åŒ–äº’è¡¥ï¼ˆç”±CNNè¯†åˆ«ï¼‰ï¼Œå•ä¸€æ¶æ„æ— æ³•å……åˆ†å»ºæ¨¡ã€‚

3. **åŒæµèåˆç­–ç•¥æ˜¾è‘—æå‡æ€§èƒ½**ï¼š
   - å¹¶è¡Œå¤„ç†+åæœŸèåˆçš„è®¾è®¡æœ‰æ•ˆæ•´åˆäº†ä¸åŒç²’åº¦çš„ä¿¡æ¯ï¼Œåœ¨ä¸å¼•å…¥é¢å¤–ç»“æ„è¾“å…¥çš„å‰æä¸‹ï¼Œå®ç°äº†å¯¹å¤æ‚ç»“åˆä¿¡å·çš„ç²¾å‡†è§£ç ã€‚

4. **åºåˆ—ä¼˜å…ˆèŒƒå¼æ­£åœ¨é€¼è¿‘ç”šè‡³è¶…è¶Šç»“æ„è¾…åŠ©æ–¹æ³•**ï¼š
   - DuaDeepåœ¨AUCä¸Šè¶…è¶Šäº†ä½¿ç”¨çœŸå®ç»“æ„çš„WALLE-Affinityï¼Œæ ‡å¿—ç€**çº¯åºåˆ—æ–¹æ³•å·²æˆä¸ºå¯è¡Œä¸”é«˜æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆ**ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ¨¡å‹å°šæœªå¼•å…¥**äº¤å‰æ³¨æ„åŠ›æœºåˆ¶**ï¼ˆcross-attentionï¼‰æ¥æ˜¾å¼å»ºæ¨¡æŠ—åŸä¸æŠ—ä½“ä¹‹é—´çš„æ®‹åŸºçº§ç›¸äº’ä½œç”¨ã€‚
- è™½ç„¶æ€§èƒ½ä¼˜å¼‚ï¼Œä½†ç¼ºä¹**å¯è§£é‡Šæ€§æ¨¡å—**ï¼Œéš¾ä»¥æä¾›å…·ä½“çš„ç»“åˆä½ç‚¹æˆ–å…³é”®çªå˜å»ºè®®ã€‚
- æ‰€æœ‰å®éªŒåŸºäºpKdæ ‡å‡†åŒ–åçš„è¿ç»­å€¼å›å½’ï¼Œæœªç›´æ¥æ¨¡æ‹Ÿå®é™…åº”ç”¨åœºæ™¯ä¸­çš„**ç›¸å¯¹æ’åºä»»åŠ¡**ï¼ˆpairwise rankingï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. å¼•å…¥**bidirectional cross-attention**æœºåˆ¶ï¼Œå¢å¼ºæŠ—åŸ-æŠ—ä½“é—´çš„äº¤äº’å»ºæ¨¡ã€‚
2. é‡‡ç”¨**pairwise ranking loss**ï¼ˆå¦‚margin lossï¼‰ä¼˜åŒ–æ¨¡å‹åœ¨äº²å’ŒåŠ›æ’åºä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚
3. å¼€å‘**å¯è§£é‡Šæ€§åˆ†æå·¥å…·**ï¼Œç”Ÿæˆæ®‹åŸºçº§åˆ«çš„è´¡çŒ®çƒ­å›¾ï¼ˆinteraction mapï¼‰ï¼Œè¾…åŠ©æŠ—ä½“å·¥ç¨‹ä¼˜åŒ–ã€‚
4. æ‰©å±•è‡³**å¤šç‰¹å¼‚æ€§æŠ—ä½“**æˆ–**æŠ—ä½“äººæºåŒ–**ç­‰ä¸‹æ¸¸ä»»åŠ¡ï¼Œæ¨åŠ¨ä¸ªæ€§åŒ–å…ç–«æ²»ç–—åº”ç”¨ã€‚

---

> ğŸ” **æ€»ç»“ä¸€å¥è¯**ï¼š  
> DuaDeep-SeqAffinityé€šè¿‡åˆ›æ–°çš„åŒæµæ¶æ„ï¼ˆTransformer + CNNï¼‰ç»“åˆESM-2åµŒå…¥ï¼Œåœ¨**å®Œå…¨ä¸éœ€è¦3Dç»“æ„**çš„æƒ…å†µä¸‹ï¼Œå®ç°äº†å½“å‰æœ€ä¼˜çš„æŠ—åŸ-æŠ—ä½“äº²å’ŒåŠ›é¢„æµ‹æ€§èƒ½ï¼Œä¸ä»…è¶…è¶Šäº†åŒç±»åºåˆ—æ¨¡å‹ï¼Œè¿˜å‡»è´¥äº†ä¾èµ–ç»“æ„ä¿¡æ¯çš„æ··åˆæ¨¡å‹ï¼Œä¸ºé«˜é€šé‡æŠ—ä½“å‘ç°æä¾›äº†é«˜æ•ˆã€å¯æ‰©å±•çš„æ–°èŒƒå¼ã€‚

</details>

---

### 15. [Heaven-Sent or Hell-Bent? Benchmarking the Intelligence and Defectiveness of LLM Hallucinations](https://arxiv.org/abs/2512.21635)

**Authors**: Chengxu Yang, Jingling Yuan, Siqi Cai, Jiawei Jiang, Chuang Hu  
**Category**: cs.CL  
**Published**: 2025-12-29  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.21635v1  

#### Abstract
Hallucinations in large language models (LLMs) are commonly regarded as errors to be minimized. However, recent perspectives suggest that some hallucinations may encode creative or epistemically valuable content, a dimension that remains underquantified in current literature. Existing hallucination ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Heaven-Sent or Hell-Bent? Benchmarking the Intelligence and Defectiveness of LLM Hallucinations è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿç ”ç©¶å°† LLM çš„ **hallucination**ï¼ˆå¹»è§‰ï¼‰æ™®éè§†ä¸ºéœ€è¦æœ€å°åŒ–çš„é”™è¯¯ï¼Œä¸»è¦é€šè¿‡äº‹å®ä¸€è‡´æ€§æ£€æµ‹æ¥è¡¡é‡ã€‚ç„¶è€Œï¼Œè¿™ç§è§†è§’å¿½ç•¥äº†éƒ¨åˆ†å¹»è§‰å¯èƒ½è•´å«åˆ›é€ æ€§æˆ–è®¤çŸ¥ä»·å€¼çš„å¯èƒ½æ€§ã€‚æœ¬æ–‡æå‡ºï¼š**å¹¶éæ‰€æœ‰å¹»è§‰éƒ½æ˜¯æœ‰å®³çš„**ï¼ŒæŸäº›â€œæ™ºèƒ½å¹»è§‰â€ï¼ˆIntelligent Hallucinations, IHï¼‰å¯èƒ½æ˜¯ç§‘å­¦åˆ›æ–°çš„å‚¬åŒ–å‰‚ã€‚

è¯¥ç ”ç©¶æ—¨åœ¨è§£å†³ä»¥ä¸‹æ ¸å¿ƒé—®é¢˜ï¼š
- å¦‚ä½•åŒºåˆ†å…·æœ‰åˆ›é€ æ½œåŠ›çš„â€œæ™ºèƒ½å¹»è§‰â€ä¸çº¯ç²¹é”™è¯¯çš„â€œç¼ºé™·å¹»è§‰â€ï¼Ÿ
- æ˜¯å¦å¯ä»¥åœ¨æŠ‘åˆ¶ DH çš„åŒæ—¶ä¿ç•™ç”šè‡³å¢å¼º IHï¼Ÿ
- å¦‚ä½•ç³»ç»Ÿè¯„ä¼° LLM åœ¨å¼€æ”¾ç§‘å­¦ä»»åŠ¡ä¸­çš„åˆ›é€ æ€§å¹»è§‰èƒ½åŠ›ï¼Ÿ

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯

#### ï¼ˆ1ï¼‰æå‡º **HIC-Bench**ï¼šé¦–ä¸ªèåˆåˆ›é€ åŠ›ä¸å¹»è§‰åˆ†ç±»çš„è¯„ä¼°æ¡†æ¶
HIC-Bench æ˜¯ä¸€ä¸ªå…¨æ–°çš„ benchmarkï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºå¯¹å¹»è§‰è¿›è¡ŒäºŒå…ƒåˆ’åˆ†ï¼š
- **Intelligent Hallucinations (IH)**ï¼šè™½åç¦»ç°å®ï¼Œä½†åœ¨ç§‘å­¦ä¸Šåˆç†ã€å…·å¤‡åŸåˆ›æ€§å’Œæ½œåœ¨ä»·å€¼ã€‚
- **Defective Hallucinations (DH)**ï¼šè¿ååŸºæœ¬ç§‘å­¦åŸç†ã€é€»è¾‘çŸ›ç›¾æˆ–æ— å®é™…æ„ä¹‰çš„è¾“å‡ºã€‚

è¿™ä¸€åˆ†ç±»æ‰“ç ´äº†â€œå¹»è§‰=é”™è¯¯â€çš„å•ä¸€èŒƒå¼ï¼Œä»äººç±»åˆ›é€ æ€§æ€ç»´çš„è§’åº¦é‡æ–°å®¡è§† LLM å¹»è§‰çš„æœ¬è´¨ã€‚

#### ï¼ˆ2ï¼‰æ„å»ºå¤šç»´è¯„ä¼°ä½“ç³»
ç»“åˆ **Torrance Tests of Creative Thinking (TTCT)** æ¡†æ¶ä¸å¹»è§‰åˆ†æç»´åº¦ï¼Œå®šä¹‰ä¸‰ä¸ªå…³é”®æŒ‡æ ‡ï¼š
- **Originality (Or)**ï¼šæ–°é¢–æ€§ï¼Œæ˜¯å¦æå‡ºçªç ´æ€§æƒ³æ³•
- **Feasibility (Fe)**ï¼šå¯è¡Œæ€§ï¼Œå½“å‰æŠ€æœ¯æ¡ä»¶ä¸‹æ˜¯å¦å¯å®ç°
- **Value (Va)**ï¼šä»·å€¼ï¼Œå¯¹å­¦ç§‘å‘å±•çš„æ½œåœ¨å½±å“

å¹¶å¼•å…¥ä¸¤ä¸ªå¹»è§‰ç»´åº¦ï¼š
- ç§‘å­¦åˆç†æ€§ï¼ˆScientific Plausibilityï¼‰
- äº‹å®åå·®ï¼ˆFactual Deviationï¼‰

æœ€ç»ˆæå‡ºç»¼åˆæŒ‡æ ‡ **Intelligent-Fidelity Score (IFS)**ï¼š
$$
\text{IFS} = w_1 \times \text{IH}_{ratio} + w_2 \times (1 - \text{DH}_{ratio} - \text{IH}_{ratio})
$$
å…¶ä¸­ $w_1=0.6$, $w_2=0.4$ï¼Œä¼˜å…ˆé¼“åŠ±æ™ºèƒ½å¹»è§‰ã€‚

#### ï¼ˆ3ï¼‰è®¾è®¡ **Dynamic Hallucination Prompt (DHP)**
ä¸€ç§åŠ¨æ€æç¤ºä¼˜åŒ–æœºåˆ¶ï¼ŒåŸºäºå®æ—¶åé¦ˆè¿­ä»£æ›´æ–°æ­£ä¾‹ï¼ˆé«˜ IFS è¾“å‡ºï¼‰å’Œè´Ÿä¾‹ï¼ˆDH è¾“å‡ºï¼‰ï¼Œå¼•å¯¼æ¨¡å‹ç”Ÿæˆæ›´é«˜è´¨é‡çš„åˆ›é€ æ€§å“åº”ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ TruthfulQA, UHGEvalï¼‰ | HIC-Bench |
|------|-------------------------------|-----------|
| å¹»è§‰å®šä¹‰ | å•ä¸€è´Ÿé¢æ ‡ç­¾ï¼ˆé”™è¯¯ï¼‰ | åŒé‡åˆ†ç±»ï¼ˆIH vs DHï¼‰ |
| è¯„ä¼°ç›®æ ‡ | æœ€å°åŒ–å¹»è§‰ | å¹³è¡¡åˆ›æ–°ä¸å¯é æ€§ |
| ä»»åŠ¡ç±»å‹ | å°é—­é—®ç­”ã€äº‹å®æ ¸æŸ¥ | å¼€æ”¾å¼è·¨é¢†åŸŸåˆ›æ–°ä»»åŠ¡ |
| åˆ›é€ åŠ›è€ƒé‡ | å¿½ç•¥ | æ˜¾å¼å»ºæ¨¡ï¼ˆTTCT æŒ‡æ ‡ï¼‰ |
| åº”ç”¨åœºæ™¯ | å®‰å…¨æ•æ„Ÿé¢†åŸŸ | ç§‘å­¦æ¢ç´¢ä¸åˆ›æ–°æ”¯æŒ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šHIC-Bench é¦–æ¬¡å®ç°äº†å¯¹ LLM â€œåˆ›é€ æ€§å¹»è§‰â€çš„é‡åŒ–è¯„ä¼°ï¼Œä¸ºå¼€å‘â€œå¯æ§å¹»æƒ³â€å‹ AI æä¾›ç†è®ºåŸºç¡€å’Œå·¥å…·æ”¯æŒã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†

#### ï¼ˆ1ï¼‰**Cross-Domain Innovation Dataset (CDID)**
- åŒ…å« **100 ä¸ªå¼€æ”¾å¼åˆ›æ–°ä»»åŠ¡**
- è¦†ç›– **10 ä¸ªç§‘å­¦é¢†åŸŸ**ï¼š
  - Quantum Physics, AI, Biomedical Sciences, Environmental Science, Materials Science, Energy Technology, Neuroscience, ICT, Aerospace, Social Sciences
- ç¤ºä¾‹ä»»åŠ¡ï¼š
  > *â€œDesign a novel transportation technology using quantum levitation and superconductivity to reduce urban traffic congestion.â€*

æ¯ä¸ªä»»åŠ¡ç”Ÿæˆ 10 æ¡å“åº”ï¼Œå…±æ”¶é›† **6000 æ¡æ ·æœ¬**ï¼Œæ¥è‡ª 6 ä¸ªä¸»æµ LLMã€‚

#### ï¼ˆ2ï¼‰**Cross-Domain Knowledge Base (CDKB)**
- åŸºäº Wikipedia å†…å®¹æç‚¼çš„æ ¸å¿ƒæ¦‚å¿µæ•°æ®åº“
- ç”¨äº RAG è®¾ç½®ä¸‹çš„å¤–éƒ¨çŸ¥è¯†æ£€ç´¢ï¼Œç¡®ä¿èƒŒæ™¯ä¸€è‡´æ€§

---

### å®éªŒè®¾ç½®

#### ï¼ˆ1ï¼‰é€‰ç”¨çš„ LLM æ¨¡å‹
| æ¨¡å‹ | ç‰¹ç‚¹ |
|------|------|
| `gpt-4o`, `gpt-4o-mini` | OpenAI ä»£è¡¨æ¨¡å‹ï¼Œå‰è€…é€šç”¨å¼ºï¼Œåè€…è½»é‡å‹ç¼© |
| `qwen2.5-14b`, `qwen2.5-72b` | å‚æ•°è§„æ¨¡å¯¹æ¯”ï¼ˆ14B vs 72Bï¼‰ |
| `deepseek-v3` | å¼ºåŒ–å­¦ä¹ å¾®è°ƒçš„åŸºç¡€æ¨¡å‹ |
| `deepseek-r1` | ä¸“ç²¾ CoT æ¨ç†èƒ½åŠ› |

#### ï¼ˆ2ï¼‰æç¤ºç­–ç•¥ï¼ˆPrompt Strategiesï¼‰
| ç­–ç•¥ | æè¿° |
|------|------|
| **SCP** (Strict Constraint Prompt) | ä¸¥æ ¼è¦æ±‚ç§‘å­¦ä¾æ®ã€é€»è¾‘ä¸¥è°¨ã€é¿å…æ¨æµ‹ |
| **RCP** (Relaxed Constraint Prompt) | æ”¾å®½å¯è¡Œæ€§é™åˆ¶ï¼Œå¼ºè°ƒåˆ›æ–°ä¸ä»·å€¼ |
| **CoT** (Chain-of-Thought) | æ·»åŠ  "Letâ€™s think step by step" æç¤º |
| **RAG** | ç»“åˆ CDKB è¿›è¡Œæ£€ç´¢å¢å¼ºç”Ÿæˆ |
| **DHP** | åŠ¨æ€æ›´æ–°æ­£/è´Ÿæ ·ä¾‹çš„æç¤ºå·¥ç¨‹ |

#### ï¼ˆ3ï¼‰è¯„ä¼°æ–¹å¼
- **è‡ªåŠ¨åŒ–è¯„ä¼°**ï¼šä½¿ç”¨ `gpt-4o` å’Œ `deepseek-v3` ä½œä¸º LLM judgeï¼Œå¹³å‡æ‰“åˆ†ä»¥å‡å°‘åè§
- **äººå·¥éªŒè¯**ï¼šä¸“å®¶å¯¹ IH/DH åˆ†ç±»è¿›è¡Œ token-level å®¡æŸ¥
- **è¯„åˆ†æ ‡å‡†**ï¼šé‡‡ç”¨ 5 åˆ†åˆ¶ Likert é‡è¡¨ï¼Œæ˜ç¡®ç•Œå®š Or/Fe/Va çš„åˆ¤æ®ï¼ˆè§ Appendix A.2ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆåŸºäº SCP è®¾ç½®ï¼Œæ¸©åº¦=1.0ï¼‰

| Model | Orâ†‘ | Feâ†‘ | Vaâ†‘ | IHâ†‘ | DHâ†“ | IFSâ†‘ |
|-------|-----|-----|-----|------|------|--------|
| deepseek-v3 | 2.93 | 3.82 | 3.22 | 13.40% | 3.20% | 41.40% |
| gpt-4o | 2.85 | 3.86 | 3.14 | 9.60% | 1.30% | 41.40% |
| gpt-4o-mini | 2.62 | 3.73 | 2.98 | 2.90% | 5.00% | 38.58% |
| qwen2.5-14b | 2.54 | 3.65 | 2.96 | 5.20% | 8.70% | 37.56% |
| deepseek-r1 | **3.50** | 3.75 | **3.63** | **52.60%** | 1.20% | **50.04%** |

> ğŸ” **è§‚å¯Ÿ**ï¼š`deepseek-r1` åœ¨ Originality å’Œ IH ä¸Šæ˜¾è‘—é¢†å…ˆï¼Œè¡¨æ˜å…¶åœ¨åˆ›é€ æ€§æ¨ç†æ–¹é¢å…·æœ‰ç‹¬ç‰¹ä¼˜åŠ¿ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœï¼ˆTable 2ï¼‰

| Prompt | Model | IH | DH | IFS |
|--------|-------|-----|-----|--------|
| SCP | deepseek-r1 | 52.60% | 1.20% | 50.04% |
| RCP | deepseek-r1 | **71.10%** | 0.30% | **54.10%** |
| RAG | deepseek-r1 | 49.00% | **0.20%** | 49.72% |
| CoT | deepseek-r1 | 52.60% | **0.60%** | 50.28% |

#### å‘ç°ï¼š
- **RCP** æå¤§æå‡ IHï¼ˆ+18.5ppï¼‰ï¼Œä¸”æœªå¢åŠ  DH â†’ æ”¯æŒâ€œé€‚åº¦æ”¾æ¾çº¦æŸå¯æ¿€å‘åˆ›æ„â€
- **RAG** æ˜¾è‘—é™ä½ DHï¼Œä½†ä¹Ÿå‹åˆ¶ IH â†’ å­˜åœ¨ **å¯é æ€§ä¸åˆ›é€ åŠ›çš„æƒè¡¡**
- **CoT** æå‡å‡†ç¡®æ€§ï¼ˆâ†“DHï¼‰ï¼Œä½†å¯¹ IH å½±å“ä¸ä¸€ï¼ˆgpt-4o ä¸‹é™ï¼‰

---

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 3ï¼‰â€”â€”DHP æ•ˆæœéªŒè¯

| LLM | RCP | DHP | IH | DH | IFS |
|-----|-----|-----|-----|-----|--------|
| gpt-4o | â€” | â€” | 9.60% | 1.30% | 41.40% |
| gpt-4o | âˆš | â€” | 18.60% | 0.50% | 43.52% |
| gpt-4o | â€” | âˆš | 12.40% | **0.10%** | 42.44% |
| gpt-4o | âˆš | âˆš | **21.10%** | 0.30% | **44.10%** |

> âœ… **ç»“è®º**ï¼š**DHP + RCP ç»„åˆæ•ˆæœæœ€ä½³**ï¼Œæ—¢å¤§å¹…æå‡ IHï¼Œåˆæœ‰æ•ˆæ§åˆ¶ DHï¼Œå®ç° IFS å…¨é¢è¶…è¶ŠåŸºçº¿ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. **IH ä¸ DH å¹¶éæ­£ç›¸å…³**  
   å®éªŒè¡¨æ˜ï¼Œå‡å°‘ DH ä¸ä¸€å®šç‰ºç‰² IHï¼›é€šè¿‡é€‚å½“ç­–ç•¥ï¼ˆå¦‚ RCPã€DHPï¼‰ï¼Œå¯ä»¥**åŒæ—¶æå‡åˆ›é€ åŠ›å¹¶é™ä½é”™è¯¯ç‡**ã€‚

2. **åˆ›é€ æ€§å¹»è§‰æ˜¯å¯å¼•å¯¼çš„èµ„æº**  
   IH å¹¶ééšæœºå™ªå£°ï¼Œè€Œæ˜¯å¯é€šè¿‡æç¤ºå·¥ç¨‹ï¼ˆå¦‚ DHPï¼‰ç³»ç»Ÿæ€§å¢å¼ºçš„â€œé«˜ç»´è®¤çŸ¥è¾“å‡ºâ€ï¼Œæœ‰æœ›æˆä¸ºç§‘å­¦å‘ç°çš„æ–°å¼•æ“ã€‚

3. **æ¨¡å‹æ¶æ„å½±å“ IH/DH æƒè¡¡**
   - `deepseek-r1` å±•ç°å‡ºæœ€å¼ºçš„ IH ç”Ÿæˆèƒ½åŠ›ï¼ˆ52.6%ï¼‰
   - `gpt-4o-mini` è™½å°ä½† DH è¾ƒé«˜ï¼ˆ5.0%ï¼‰ï¼Œè¯´æ˜è’¸é¦å¯èƒ½å‰Šå¼±äº‹å®ä¸€è‡´æ€§
   - å¤§å‚æ•°æ¨¡å‹ï¼ˆå¦‚ qwen2.5-72bï¼‰åœ¨ Fluency ä¸Šè¡¨ç°æ›´å¥½

4. **é¢†åŸŸæ•æ„Ÿæ€§æ˜æ˜¾**
   - æ‰€æœ‰æ¨¡å‹åœ¨ **Biomedical Sciences** å’Œ **Aerospace** ä¸­è¡¨ç°å‡ºæ›´é«˜ Originality å’Œ IH
   - åœ¨ **Environmental Science** å’Œ **Energy Technology** ä¸­åˆ›é€ åŠ›è¾ƒä½

5. **IFS æ˜¯æœ‰æ•ˆçš„å¹³è¡¡æŒ‡æ ‡**
   - åœ¨ä¸åŒæƒé‡ä¸‹ï¼ˆIIFS/BIFS/RIFSï¼‰ï¼Œèƒ½æœ‰æ•ˆåæ˜ æ¨¡å‹åœ¨â€œåˆ›æ–°å¯¼å‘â€ä¸â€œç²¾åº¦å¯¼å‘â€åœºæ™¯ä¸­çš„é€‚ç”¨æ€§

---

### æ–¹æ³•çš„å±€é™æ€§

1. **ä»»åŠ¡å½¢å¼å—é™**  
   å½“å‰ä»…é€‚ç”¨äºç»“æ„åŒ–é—®é¢˜å›ç­”ï¼Œå°šæœªæ‰©å±•è‡³æ–‡å­¦åˆ›ä½œã€è‰ºæœ¯ç”Ÿæˆç­‰æ›´å¹¿ä¹‰çš„åˆ›é€ æ€§ä»»åŠ¡ã€‚

2. **äººå·¥è¯„ä¼°æœ‰é™**  
   ä»…å¯¹éƒ¨åˆ†è¾“å‡ºè¿›è¡Œäº†äººå·¥å®¡æŸ¥ï¼Œç¼ºä¹å¤§è§„æ¨¡äººç±»åå¥½å¯¹é½ç ”ç©¶ã€‚

3. **IH å®šä¹‰ä»å…·ä¸»è§‚æ€§**  
   å°½ç®¡æœ‰ TTCT æŒ‡æ ‡æ”¯æ’‘ï¼Œä½†â€œæœ‰ä»·å€¼ä½†ä¸çœŸå®â€çš„åˆ¤æ–­ä»ä¾èµ– evaluator çš„è®¤çŸ¥è¾¹ç•Œã€‚

4. **ä¼¦ç†é£é™©æœªå……åˆ†è®¨è®º**  
   æ¨åŠ¨ IH å¯èƒ½å¯¼è‡´ç”¨æˆ·è¯¯å°†å…¶å½“ä½œäº‹å®ï¼Œéœ€è­¦æƒ•è¯¯å¯¼æ€§åº”ç”¨ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. æ‰©å±•è‡³ **multimodal** å’Œ **cross-lingual** åœºæ™¯
2. å¼€å‘ **domain-specific prompts** ä»¥ç²¾ç»†åŒ–è°ƒæ§ IH/DH
3. å¼•å…¥ **human-involved multi-dimensional evaluation** æå‡ IH åˆ¤å®šå¯é æ€§
4. æ¢ç´¢ IH åœ¨è¯ç‰©è®¾è®¡ã€ææ–™å‘ç°ç­‰å…·ä½“ç§‘ç ”åœºæ™¯çš„åº”ç”¨è½åœ°
5. å»ºç«‹ **ethical guidelines** è§„èŒƒ IH çš„ä½¿ç”¨è¾¹ç•Œ

---

> ğŸ“Œ **æ€»ä½“è¯„ä»·**ï¼šæœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªé¢ è¦†æ€§çš„è§‚ç‚¹â€”â€”â€œå¹»è§‰â€ä¸åº”è¢«æ¶ˆç­ï¼Œè€Œåº”è¢«é©¯æœã€‚HIC-Bench ä¸ºç†è§£ LLM çš„åˆ›é€ æ€§æœ¬è´¨æä¾›äº†æ–°èŒƒå¼ï¼Œæ ‡å¿—ç€ä»â€œè¿½æ±‚å‡†ç¡®â€åˆ°â€œé©¾é©­æƒ³è±¡â€çš„é‡è¦è½¬å‘ã€‚

</details>

---

### 16. [Robust Federated Fine-Tuning in Heterogeneous Networks with Unreliable Connections: An Aggregation View](https://arxiv.org/abs/2512.22035)

**Authors**: Yanmeng Wang, Zhiwen Dai, Shuai Wang, Jian Zhou, Fu Xiao, Tony Q. S. Quek, Tsung-Hui Chang  
**Category**: cs.DC  
**Published**: 2025-12-29  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.22035v1  

#### Abstract
Federated Fine-Tuning (FFT) has attracted growing interest as it leverages both server- and client-side data to enhance global model generalization while preserving privacy, and significantly reduces the computational burden on edge devices by avoiding training from scratch. Despite these advantages...

---

### 17. [Synthetic Financial Data Generation for Enhanced Financial Modelling](https://arxiv.org/abs/2512.21791)

**Authors**: Christophe D. Hounwanou, Yae Ulrich Gaba, Pierre Ntakirutimana  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.21791v1  

#### Abstract
Data scarcity and confidentiality in finance often impede model development and robust testing. This paper presents a unified multi-criteria evaluation framework for synthetic financial data and applies it to three representative generative paradigms: the statistical ARIMA-GARCH baseline, Variationa...

---

### 18. [From Visual Perception to Deep Empathy: An Automated Assessment Framework for House-Tree-Person Drawings Using Multimodal LLMs and Multi-Agent Collaboration](https://arxiv.org/abs/2512.21360)

**Authors**: Shuide Wen, Yu Sun, Beier Ku, Zhi Gao, Lijun Ma, Yang Yang, Can Jiao  
**Category**: cs.AI  
**Published**: 2025-12-29  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.21360v1  

#### Abstract
Background: The House-Tree-Person (HTP) drawing test, introduced by John Buck in 1948, remains a widely used projective technique in clinical psychology. However, it has long faced challenges such as heterogeneous scoring standards, reliance on examiners subjective experience, and a lack of a unifie...

---

### 19. [Method Decoration (DeMe): A Framework for LLM-Driven Adaptive Method Generation in Dynamic IoT Environments](https://arxiv.org/abs/2512.21817)

**Authors**: Hong Su  
**Category**: cs.CL  
**Published**: 2025-12-29  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.21817v1  

#### Abstract
Intelligent IoT systems increasingly rely on large language models (LLMs) to generate task-execution methods for dynamic environments. However, existing approaches lack the ability to systematically produce new methods when facing previously unseen situations, and they often depend on fixed, device-...

---

### 20. [Statistical vs. Deep Learning Models for Estimating Substance Overdose Excess Mortality in the US](https://arxiv.org/abs/2512.21456)

**Authors**: Sukanya Krishna, Marie-Laure Charpignon, Maimuna Majumder  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.21456v1  

#### Abstract
Substance overdose mortality in the United States claimed over 80,000 lives in 2023, with the COVID-19 pandemic exacerbating existing trends through healthcare disruptions and behavioral changes. Estimating excess mortality, defined as deaths beyond expected levels based on pre-pandemic patterns, is...

---

### 21. [AnchorGK: Anchor-based Incremental and Stratified Graph Learning Framework for Inductive Spatio-Temporal Kriging](https://arxiv.org/abs/2512.21569)

**Authors**: Xiaobin Ren, Kaiqi Zhao, Katerina Ta\v{s}kova, Patricia Riddle  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.21569v1  

#### Abstract
Spatio-temporal kriging is a fundamental problem in sensor networks, driven by the sparsity of deployed sensors and the resulting missing observations. Although recent approaches model spatial and temporal correlations, they often under-exploit two practical characteristics of real deployments: the ...

---

### 22. [Robustness and Scalability Of Machine Learning for Imbalanced Clinical Data in Emergency and Critical Care](https://arxiv.org/abs/2512.21602)

**Authors**: Yusuf Brima, Marcellin Atemkeng  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.21602v1  

#### Abstract
Emergency and intensive care environments require predictive models that are both accurate and computationally efficient, yet clinical data in these settings are often severely imbalanced. Such skewness undermines model reliability, particularly for rare but clinically crucial outcomes, making robus...

---

### 23. [Leash: Adaptive Length Penalty and Reward Shaping for Efficient Large Reasoning Model](https://arxiv.org/abs/2512.21540)

**Authors**: Yanhao Li, Lu Ma, Jiaran Zhang, Lexiang Tang, Wentao Zhang, Guibo Luo  
**Category**: cs.AI  
**Published**: 2025-12-29  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.21540v1  

#### Abstract
Existing approaches typically rely on fixed length penalties, but such penalties are hard to tune and fail to adapt to the evolving reasoning abilities of LLMs, leading to suboptimal trade-offs between accuracy and conciseness. To address this challenge, we propose Leash (adaptive LEngth penAlty and...

---

### 24. [MoRAgent: Parameter Efficient Agent Tuning with Mixture-of-Roles](https://arxiv.org/abs/2512.21708)

**Authors**: Jing Han, Binwei Yan, Tianyu Guo, Zheyuan Bai, Mengyu Zheng, Hanting Chen, Ying Nie  
**Category**: cs.CL  
**Published**: 2025-12-29  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.21708v1  

#### Abstract
Despite recent advancements of fine-tuning large language models (LLMs) to facilitate agent tasks, parameter-efficient fine-tuning (PEFT) methodologies for agent remain largely unexplored. In this paper, we introduce three key strategies for PEFT in agent tasks: 1) Inspired by the increasingly domin...

---

### 25. [Dictionary-Transform Generative Adversarial Networks](https://arxiv.org/abs/2512.21677)

**Authors**: Angshul Majumdar  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.21677v1  

#### Abstract
Generative adversarial networks (GANs) are widely used for distribution learning, yet their classical formulations remain theoretically fragile, with ill-posed objectives, unstable training dynamics, and limited interpretability. In this work, we introduce \emph{Dictionary-Transform Generative Adver...

---

### 26. [Exploring the Heterogeneity of Tabular Data: A Diversity-aware Data Generator via LLMs](https://arxiv.org/abs/2512.21915)

**Authors**: Yafeng Tang, Xiaoou Ding, Jianzhuo Du, Zishuo Yan, Zhuang Ma, Zheng Liang, Zekai Qian, Hongzhi Wang  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.21915v1  

#### Abstract
Tabular data generation has become increasingly essential for enabling robust machine learning applications, which require large-scale, high-quality data. Existing solutions leverage generative models to learn original data distributions. However, real-world data are naturally heterogeneous with div...

---

### 27. [NEMO-4-PAYPAL: Leveraging NVIDIA's Nemo Framework for empowering PayPal's Commerce Agent](https://arxiv.org/abs/2512.21578)

**Authors**: Ali Sahami, Sudhanshu Garg, Andrew Wang, Chaitanya Kulkarni, Farhad Farahani, Sean Yun-Shiuan Chuang, Jian Wan, Srinivasan Manoharan, Uma Kona, Nitin Sharma, Linsey Pang, Prakhar Mehrotra, Jessica Clark, Mark Moyou  
**Category**: cs.AI  
**Published**: 2025-12-29  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.21578v1  

#### Abstract
We present the development and optimization of PayPal's Commerce Agent, powered by NEMO-4-PAYPAL, a multi-agent system designed to revolutionize agentic commerce on the PayPal platform. Through our strategic partnership with NVIDIA, we leveraged the NeMo Framework for LLM model fine-tuning to enhanc...

---

### 28. [Hyperion: Low-Latency Ultra-HD Video Analytics via Collaborative Vision Transformer Inference](https://arxiv.org/abs/2512.21730)

**Authors**: Linyi Jiang, Yifei Zhu, Hao Yin, Bo Li  
**Category**: cs.DC  
**Published**: 2025-12-29  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.21730v1  

#### Abstract
Recent advancements in array-camera videography enable real-time capturing of ultra-high-definition (Ultra-HD) videos, providing rich visual information in a large field of view. However, promptly processing such data using state-of-the-art transformer-based vision foundation models faces significan...

---

### 29. [RefineBridge: Generative Bridge Models Improve Financial Forecasting by Foundation Models](https://arxiv.org/abs/2512.21572)

**Authors**: Anthony Bolton, Wuyang Zhou, Zehua Chen, Giorgos Iacovides, Danilo Mandic  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.21572v1  

#### Abstract
Financial time series forecasting is particularly challenging for transformer-based time series foundation models (TSFMs) due to non-stationarity, heavy-tailed distributions, and high-frequency noise present in data. Low-rank adaptation (LoRA) has become a popular parameter-efficient method for adap...

---

### 30. [Why Smooth Stability Assumptions Fail for ReLU Learning](https://arxiv.org/abs/2512.22055)

**Authors**: Ronald Katende  
**Category**: cs.LG  
**Published**: 2025-12-29  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.22055v1  

#### Abstract
Stability analyses of modern learning systems are frequently derived under smoothness assumptions that are violated by ReLU-type nonlinearities. In this note, we isolate a minimal obstruction by showing that no uniform smoothness-based stability proxy such as gradient Lipschitzness or Hessian contro...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
