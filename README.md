# arXiv Papers Bot ü§ñ

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## üìä Statistics

- **Last Updated**: 2025-12-18 06:16:59 UTC
- **Total Papers Found**: 50
- **Categories Monitored**: cs.AI, cs.LG, cs.CL, cs.CV

## üìö Recent Papers

### 1. [Unreliable Uncertainty Estimates with Monte Carlo Dropout](https://arxiv.org/abs/2512.14851)

**Authors**: Aslak Djupsk{\aa}s, Alexander Johannes Stasik, Signe Riemer-S{\o}rensen  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 3.0  
**Type**: new  
**ArXiv ID**: 2512.14851v1  

#### Abstract
Reliable uncertainty estimation is crucial for machine learning models, especially in safety-critical domains. While exact Bayesian inference offers a principled approach, it is often computationally infeasible for deep neural networks. Monte Carlo dropout (MCD) was proposed as an efficient approxim...

---

### 2. [Deep Learning and Elicitability for McKean-Vlasov FBSDEs With Common Noise](https://arxiv.org/abs/2512.14967)

**Authors**: Felipe J. P. Antunes, Yuri F. Saporito, Sebastian Jaimungal  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 2.5  
**Type**: new  
**ArXiv ID**: 2512.14967v1  

#### Abstract
We present a novel numerical method for solving McKean-Vlasov forward-backward stochastic differential equations (MV-FBSDEs) with common noise, combining Picard iterations, elicitability and deep learning. The key innovation involves elicitability to derive a path-wise loss function, enabling effici...

---

### 3. [Generalization and Feature Attribution in Machine Learning Models for Crop Yield and Anomaly Prediction in Germany](https://arxiv.org/abs/2512.15140)

**Authors**: Roland Baatz  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 2.5  
**Type**: new  
**ArXiv ID**: 2512.15140v1  

#### Abstract
This study examines the generalization performance and interpretability of machine learning (ML) models used for predicting crop yield and yield anomalies in Germany's NUTS-3 regions. Using a high-quality, long-term dataset, the study systematically compares the evaluation and temporal validation be...

---

### 4. [Quantum Machine Learning for Cybersecurity: A Taxonomy and Future Directions](https://arxiv.org/abs/2512.15286)

**Authors**: Siva Sai, Ishika Goyal, Shubham Sharma, Sri Harshita Manuri, Vinay Chamola, Rajkumar Buyya  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 2.5  
**Type**: new  
**ArXiv ID**: 2512.15286v1  

#### Abstract
The increasing number of cyber threats and rapidly evolving tactics, as well as the high volume of data in recent years, have caused classical machine learning, rules, and signature-based defence strategies to fail, rendering them unable to keep up. An alternative, Quantum Machine Learning (QML), ha...

---

### 5. [When a Nation Speaks: Machine Learning and NLP in People's Sentiment Analysis During Bangladesh's 2024 Mass Uprising](https://arxiv.org/abs/2512.15547)

**Authors**: Md. Samiul Alim, Mahir Shahriar Tamim, Maisha Rahman, Tanvir Ahmed Khan, Md Mushfique Anwar  
**Category**: cs.CL  
**Published**: 2025-12-18  
**Score**: 2.5  
**Type**: new  
**ArXiv ID**: 2512.15547v1  

#### Abstract
Sentiment analysis, an emerging research area within natural language processing (NLP), has primarily been explored in contexts like elections and social media trends, but there remains a significant gap in understanding emotional dynamics during civil unrest, particularly in the Bangla language. Ou...

---

### 6. [LLM as a Neural Architect: Controlled Generation of Image Captioning Models Under Strict API Contracts](https://arxiv.org/abs/2512.14706)

**Authors**: Krunal Jesani, Dmitry Ignatov, Radu Timofte  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 2.0  
**Type**: new  
**ArXiv ID**: 2512.14706v1  

#### Abstract
Neural architecture search (NAS) traditionally requires significant human expertise or automated trial-and-error to design deep learning models. We present NN-Caption, an LLM-guided neural architecture search pipeline that generates runnable image-captioning models by composing CNN encoders from LEM...

---

### 7. [Improving Underwater Acoustic Classification Through Learnable Gabor Filter Convolution and Attention Mechanisms](https://arxiv.org/abs/2512.14714)

**Authors**: Lucas Cesar Ferreira Domingos, Russell Brinkworth, Paulo Eduardo Santos, Karl Sammut  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 2.0  
**Type**: new  
**ArXiv ID**: 2512.14714v1  

#### Abstract
Remotely detecting and classifying underwater acoustic targets is critical for environmental monitoring and defence. However, the complex nature of ship-radiated and environmental underwater noise poses significant challenges to accurate signal processing. While recent advancements in machine learni...

---

### 8. [SigMA: Path Signatures and Multi-head Attention for Learning Parameters in fBm-driven SDEs](https://arxiv.org/abs/2512.15088)

**Authors**: Xianglin Wu, Chiheb Ben Hammouda, Cornelis W. Oosterlee  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 2.0  
**Type**: new  
**ArXiv ID**: 2512.15088v1  

#### Abstract
Stochastic differential equations (SDEs) driven by fractional Brownian motion (fBm) are increasingly used to model systems with rough dynamics and long-range dependence, such as those arising in quantitative finance and reliability engineering. However, these processes are non-Markovian and lack a s...

---

### 9. [How Many Heads Make an SSM? A Unified Framework for Attention and State Space Models](https://arxiv.org/abs/2512.15115)

**Authors**: Ali Ghodsi  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 2.0  
**Type**: new  
**ArXiv ID**: 2512.15115v1  

#### Abstract
Sequence modeling has produced diverse architectures -- from classical recurrent neural networks to modern Transformers and state space models (SSMs) -- yet a unified theoretical understanding of expressivity and trainability trade-offs remains limited. We introduce a unified framework that represen...

---

### 10. [Accelerating High-Throughput Catalyst Screening by Direct Generation of Equilibrium Adsorption Structures](https://arxiv.org/abs/2512.15228)

**Authors**: Songze Huo, Xiao-Ming Cao  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 2.0  
**Type**: new  
**ArXiv ID**: 2512.15228v1  

#### Abstract
The adsorption energy serves as a crucial descriptor for the large-scale screening of catalysts. Nevertheless, the limited distribution of training data for the extensively utilised machine learning interatomic potential (MLIP), predominantly sourced from near-equilibrium structures, results in unre...

---

### 11. [Empirical Investigation of the Impact of Phase Information on Fault Diagnosis of Rotating Machinery](https://arxiv.org/abs/2512.15344)

**Authors**: Hiroyoshi Nagahama, Katsufumi Inoue, Masayoshi Todorokihara, Michifumi Yoshioka  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 2.0  
**Type**: new  
**ArXiv ID**: 2512.15344v1  

#### Abstract
Predictive maintenance of rotating machinery increasingly relies on vibration signals, yet most learning-based approaches either discard phase during spectral feature extraction or use raw time-waveforms without explicitly leveraging phase information. This paper introduces two phase-aware preproces...

---

### 12. [Metanetworks as Regulatory Operators: Learning to Edit for Requirement Compliance](https://arxiv.org/abs/2512.15469)

**Authors**: Ioannis Kalogeropoulos, Giorgos Bouritsas, Yannis Panagakis  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 2.0  
**Type**: new  
**ArXiv ID**: 2512.15469v1  

#### Abstract
As machine learning models are increasingly deployed in high-stakes settings, e.g. as decision support systems in various societal sectors or in critical infrastructure, designers and auditors are facing the need to ensure that models satisfy a wider variety of requirements (e.g. compliance with reg...

---

### 13. [SoFlow: Solution Flow Models for One-Step Generative Modeling](https://arxiv.org/abs/2512.15657)

**Authors**: Tianze Luo, Haotian Yuan, Zhuang Liu  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 2.0  
**Type**: new  
**ArXiv ID**: 2512.15657v1  

#### Abstract
The multi-step denoising process in diffusion and Flow Matching models causes major efficiency issues, which motivates research on few-step generation. We present Solution Flow Models (SoFlow), a framework for one-step generation from scratch. By analyzing the relationship between the velocity funct...

---

### 14. [HydroGEM: A Self Supervised Zero Shot Hybrid TCN Transformer Foundation Model for Continental Scale Streamflow Quality Control](https://arxiv.org/abs/2512.14106)

**Authors**: Ijaz Ul Haq, Byung Suk Lee, Julia N. Perdrial, David Baude  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 1.5  
**Type**: new  
**ArXiv ID**: 2512.14106v1  

#### Abstract
Real-time streamflow monitoring networks generate millions of observations annually, yet maintaining data quality across thousands of remote sensors remains labor-intensive. We introduce HydroGEM (Hydrological Generalizable Encoder for Monitoring), a foundation model for continental-scale streamflow...

---

### 15. [Optimizing Multi-Tier Supply Chain Ordering with a Hybrid Liquid Neural Network and Extreme Gradient Boosting Model](https://arxiv.org/abs/2512.14112)

**Authors**: Chunan Tong  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 1.5  
**Type**: new  
**ArXiv ID**: 2512.14112v1  

#### Abstract
Supply chain management (SCM) faces significant challenges like demand fluctuations and the bullwhip effect. Traditional methods and even state-of-the-art LLMs struggle with benchmarks like the Vending Machine Test, failing to handle SCM's complex continuous time-series data. While ML approaches lik...

---

### 16. [Sparse Multi-Modal Transformer with Masking for Alzheimer's Disease Classification](https://arxiv.org/abs/2512.14491)

**Authors**: Cheng-Han Lu, Pei-Hsuan Tsai  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 1.5  
**Type**: new  
**ArXiv ID**: 2512.14491v1  

#### Abstract
Transformer-based multi-modal intelligent systems often suffer from high computational and energy costs due to dense self-attention, limiting their scalability under resource constraints. This paper presents SMMT, a sparse multi-modal transformer architecture designed to improve efficiency and robus...

---

### 17. [HATSolver: Learning Groebner Bases with Hierarchical Attention Transformers](https://arxiv.org/abs/2512.14722)

**Authors**: Mohamed Malhou, Ludovic Perret, Kristin Lauter  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.5  
**Type**: new  
**ArXiv ID**: 2512.14722v1  

#### Abstract
At NeurIPS 2024, Kera et al. introduced the use of transformers for computing Groebner bases, a central object in computer algebra with numerous practical applications. In this paper, we improve this approach by applying Hierarchical Attention Transformers (HATs) to solve systems of multivariate pol...

---

### 18. [Quantum Decision Transformers (QDT): Synergistic Entanglement and Interference for Offline Reinforcement Learning](https://arxiv.org/abs/2512.14726)

**Authors**: Abraham Itzhak Weinberg  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.5  
**Type**: new  
**ArXiv ID**: 2512.14726v1  

#### Abstract
Offline reinforcement learning enables policy learning from pre-collected datasets without environment interaction, but existing Decision Transformer (DT) architectures struggle with long-horizon credit assignment and complex state-action dependencies. We introduce the Quantum Decision Transformer (...

---

### 19. [Robustness Evaluation of Machine Learning Models for Fault Classification and Localization In Power System Protection](https://arxiv.org/abs/2512.15385)

**Authors**: Julian Oelhaf, Mehran Pashaei, Georg Kordowich, Christian Bergler, Andreas Maier, Johann J\"ager, Siming Bayer  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.5  
**Type**: new  
**ArXiv ID**: 2512.15385v1  

#### Abstract
The growing penetration of renewable and distributed generation is transforming power systems and challenging conventional protection schemes that rely on fixed settings and local measurements. Machine learning (ML) offers a data-driven alternative for centralized fault classification (FC) and fault...

---

### 20. [SLCFormer: Spectral-Local Context Transformer with Physics-Grounded Flare Synthesis for Nighttime Flare Removal](https://arxiv.org/abs/2512.15221)

**Authors**: Xiyu Zhu, Wei Wang, Xin Yuan, Xiao Wang  
**Category**: cs.CV  
**Published**: 2025-12-18  
**Score**: 1.5  
**Type**: new  
**ArXiv ID**: 2512.15221v1  

#### Abstract
Lens flare is a common nighttime artifact caused by strong light sources scattering within camera lenses, leading to hazy streaks, halos, and glare that degrade visual quality. However, existing methods usually fail to effectively address nonuniform scattered flares, which severely reduces their app...

---

### 21. [See It Before You Grab It: Deep Learning-based Action Anticipation in Basketball](https://arxiv.org/abs/2512.15386)

**Authors**: Arnau Barrera Roy, Albert Clap\'es Sintes  
**Category**: cs.CV  
**Published**: 2025-12-18  
**Score**: 1.5  
**Type**: new  
**ArXiv ID**: 2512.15386v1  

#### Abstract
Computer vision and video understanding have transformed sports analytics by enabling large-scale, automated analysis of game dynamics from broadcast footage. Despite significant advances in player and ball tracking, pose estimation, action localization, and automatic foul recognition, anticipating ...

---

### 22. [Evaluation of deep learning architectures for wildlife object detection: A comparative study of ResNet and Inception](https://arxiv.org/abs/2512.15480)

**Authors**: Malach Obisa Amonga, Benard Osero, Edna Too  
**Category**: cs.CV  
**Published**: 2025-12-18  
**Score**: 1.5  
**Type**: new  
**ArXiv ID**: 2512.15480v1  

#### Abstract
Wildlife object detection plays a vital role in biodiversity conservation, ecological monitoring, and habitat protection. However, this task is often challenged by environmental variability, visual similarities among species, and intra-class diversity. This study investigates the effectiveness of tw...

---

### 23. [RUMPL: Ray-Based Transformers for Universal Multi-View 2D to 3D Human Pose Lifting](https://arxiv.org/abs/2512.15488)

**Authors**: Seyed Abolfazl Ghasemzadeh, Alexandre Alahi, Christophe De Vleeschouwer  
**Category**: cs.CV  
**Published**: 2025-12-18  
**Score**: 1.5  
**Type**: new  
**ArXiv ID**: 2512.15488v1  

#### Abstract
Estimating 3D human poses from 2D images remains challenging due to occlusions and projective ambiguity. Multi-view learning-based approaches mitigate these issues but often fail to generalize to real-world scenarios, as large-scale multi-view datasets with 3D ground truth are scarce and captured un...

---

### 24. [Adjudicator: Correcting Noisy Labels with a KG-Informed Council of LLM Agents](https://arxiv.org/abs/2512.13704)

**Authors**: Doohee You, Sundeep Paul  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.13704v1  

#### Abstract
The performance of production machine learning systems is fundamentally limited by the quality of their training data. In high-stakes industrial applications, noisy labels can degrade performance and erode user trust. This paper presents Adjudicator, a system that addresses the critical data mining ...

---

### 25. [MURIM: Multidimensional Reputation-based Incentive Mechanism for Federated Learning](https://arxiv.org/abs/2512.13955)

**Authors**: Sindhuja Madabushi, Dawood Wasif, Jin-Hee Cho  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.13955v1  

#### Abstract
Federated Learning (FL) has emerged as a leading privacy-preserving machine learning paradigm, enabling participants to share model updates instead of raw data. However, FL continues to face key challenges, including weak client incentives, privacy risks, and resource constraints. Assessing client r...

---

### 26. [Sparsity-Controllable Dynamic Top-p MoE for Large Foundation Model Pre-training](https://arxiv.org/abs/2512.13996)

**Authors**: Can Jin, Hongwu Peng, Mingcan Xiang, Qixin Zhang, Xiangchi Yuan, Amit Hasan, Ohiremen Dibua, Yifan Gong, Yan Kang, Dimitris N. Metaxas  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.13996v1  

#### Abstract
Sparse Mixture-of-Experts (MoE) architectures effectively scale model capacity by activating only a subset of experts for each input token. However, the standard Top-k routing strategy imposes a uniform sparsity pattern that ignores the varying difficulty of tokens. While Top-p routing offers a flex...

---

### 27. [Universal Reasoning Model](https://arxiv.org/abs/2512.14693)

**Authors**: Zitian Gao, Lynx Chen, Yihao Xiao, He Xing, Ran Tao, Haoming Luo, Joey Zhou, Bryan Dai  
**Category**: cs.AI  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.14693v1  

#### Abstract
Universal transformers (UTs) have been widely used for complex reasoning tasks such as ARC-AGI and Sudoku, yet the specific sources of their performance gains remain underexplored. In this work, we systematically analyze UTs variants and show that improvements on ARC-AGI primarily arise from the rec...

---

### 28. [How a Bit Becomes a Story: Semantic Steering via Differentiable Fault Injection](https://arxiv.org/abs/2512.14715)

**Authors**: Zafaryab Haider, Md Hafizur Rahman, Shane Moeykens, Vijay Devabhaktuni, Prabuddha Chakraborty  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.14715v1  

#### Abstract
Hard-to-detect hardware bit flips, from either malicious circuitry or bugs, have already been shown to make transformers vulnerable in non-generative tasks. This work, for the first time, investigates how low-level, bitwise perturbations (fault injection) to the weights of a large language model (LL...

---

### 29. [Generative Urban Flow Modeling: From Geometry to Airflow with Graph Diffusion](https://arxiv.org/abs/2512.14725)

**Authors**: Francisco Giral, \'Alvaro Manzano, Ignacio G\'omez, Petros Koumoutsakos, Soledad Le Clainche  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.14725v1  

#### Abstract
Urban wind flow modeling and simulation play an important role in air quality assessment and sustainable city planning. A key challenge for modeling and simulation is handling the complex geometries of the urban landscape. Low order models are limited in capturing the effects of geometry, while high...

---

### 30. [A Critical Perspective on Finite Sample Conformal Prediction Theory in Medical Applications](https://arxiv.org/abs/2512.14727)

**Authors**: Klaus-Rudolf Kladny, Bernhard Sch\"olkopf, Lisa Koch, Christian F. Baumgartner, Michael Muehlebach  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.14727v1  

#### Abstract
Machine learning (ML) is transforming healthcare, but safe clinical decisions demand reliable uncertainty estimates that standard ML models fail to provide. Conformal prediction (CP) is a popular tool that allows users to turn heuristic uncertainty estimates into uncertainty estimates with statistic...

---

### 31. [Evaluating Weather Forecasts from a Decision Maker's Perspective](https://arxiv.org/abs/2512.14779)

**Authors**: Kornelius Raeth, Nicole Ludwig  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.14779v1  

#### Abstract
Standard weather forecast evaluations focus on the forecaster's perspective and on a statistical assessment comparing forecasts and observations. In practice, however, forecasts are used to make decisions, so it seems natural to take the decision-maker's perspective and quantify the value of a forec...

---

### 32. [How Does Fourier Analysis Network Work? A Mechanism Analysis and a New Dual-Activation Layer Proposal](https://arxiv.org/abs/2512.14873)

**Authors**: Sam Jeong, Hae Yong Kim  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.14873v1  

#### Abstract
Fourier Analysis Network (FAN) was recently proposed as a simple way to improve neural network performance by replacing part of ReLU activations with sine and cosine functions. Although several studies have reported small but consistent gains across tasks, the underlying mechanism behind these impro...

---

### 33. [ATLAS: Adaptive Topology-based Learning at Scale for Homophilic and Heterophilic Graphs](https://arxiv.org/abs/2512.14908)

**Authors**: Turja Kundu, Sanjukta Bhowmick  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.14908v1  

#### Abstract
We present ATLAS (Adaptive Topology-based Learning at Scale for Homophilic and Heterophilic Graphs), a novel graph learning algorithm that addresses two important challenges in graph neural networks (GNNs). First, the accuracy of GNNs degrades when the graph is heterophilic. Second, iterative featur...

---

### 34. [Spectral Representation-based Reinforcement Learning](https://arxiv.org/abs/2512.15036)

**Authors**: Chenxiao Gao, Haotian Sun, Na Li, Dale Schuurmans, Bo Dai  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.15036v1  

#### Abstract
In real-world applications with large state and action spaces, reinforcement learning (RL) typically employs function approximations to represent core components like the policies, value functions, and dynamics models. Although powerful approximations such as neural networks offer great expressivene...

---

### 35. [Neural Modular Physics for Elastic Simulation](https://arxiv.org/abs/2512.15083)

**Authors**: Yifei Li, Haixu Wu, Zeyi Xu, Tuur Stuyck, Wojciech Matusik  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.15083v1  

#### Abstract
Learning-based methods have made significant progress in physics simulation, typically approximating dynamics with a monolithic end-to-end optimized neural network. Although these models offer an effective way to simulation, they may lose essential features compared to traditional numerical simulato...

---

### 36. [FADTI: Fourier and Attention Driven Diffusion for Multivariate Time Series Imputation](https://arxiv.org/abs/2512.15116)

**Authors**: Runze Li, Hanchen Wang, Wenjie Zhang, Binghao Li, Yu Zhang, Xuemin Lin, Ying Zhang  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.15116v1  

#### Abstract
Multivariate time series imputation is fundamental in applications such as healthcare, traffic forecasting, and biological modeling, where sensor failures and irregular sampling lead to pervasive missing values. However, existing Transformer- and diffusion-based models lack explicit inductive biases...

---

### 37. [Automatic Reward Shaping from Multi-Objective Human Heuristics](https://arxiv.org/abs/2512.15120)

**Authors**: Yuqing Xie, Jiayu Chen, Wenhao Tang, Ya Zhang, Chao Yu, Yu Wang  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.15120v1  

#### Abstract
Designing effective reward functions remains a central challenge in reinforcement learning, especially in multi-objective environments. In this work, we propose Multi-Objective Reward Shaping with Exploration (MORSE), a general framework that automatically combines multiple human-designed heuristic ...

---

### 38. [TrajSyn: Privacy-Preserving Dataset Distillation from Federated Model Trajectories for Server-Side Adversarial Training](https://arxiv.org/abs/2512.15123)

**Authors**: Mukur Gupta, Niharika Gupta, Saifur Rahman, Shantanu Pal, Chandan Karmakar  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.15123v1  

#### Abstract
Deep learning models deployed on edge devices are increasingly used in safety-critical applications. However, their vulnerability to adversarial perturbations poses significant risks, especially in Federated Learning (FL) settings where identical models are distributed across thousands of clients. W...

---

### 39. [From Isolation to Entanglement: When Do Interpretability Methods Identify and Disentangle Known Concepts?](https://arxiv.org/abs/2512.15134)

**Authors**: Aaron Mueller, Andrew Lee, Shruti Joshi, Ekdeep Singh Lubana, Dhanya Sridhar, Patrik Reizinger  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.15134v1  

#### Abstract
A central goal of interpretability is to recover representations of causally relevant concepts from the activations of neural networks. The quality of these concept representations is typically evaluated in isolation, and under implicit independence assumptions that may not hold in practice. Thus, i...

---

### 40. [An Efficient Gradient-Based Inference Attack for Federated Learning](https://arxiv.org/abs/2512.15143)

**Authors**: Pablo Monta\~na-Fern\'andez, Ines Ortega-Fernandez  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.15143v1  

#### Abstract
Federated Learning is a machine learning setting that reduces direct data exposure, improving the privacy guarantees of machine learning models. Yet, the exchange of model updates between the participants and the aggregator can still leak sensitive information. In this work, we present a new gradien...

---

### 41. [Bits for Privacy: Evaluating Post-Training Quantization via Membership Inference](https://arxiv.org/abs/2512.15335)

**Authors**: Chenxiang Zhang, Tongxi Qu, Zhong Li, Tian Zhang, Jun Pang, Sjouke Mauw  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.15335v1  

#### Abstract
Deep neural networks are widely deployed with quantization techniques to reduce memory and computational costs by lowering the numerical precision of their parameters. While quantization alters model parameters and their outputs, existing privacy analyses primarily focus on full-precision models, le...

---

### 42. [Statistics of Min-max Normalized Eigenvalues in Random Matrices](https://arxiv.org/abs/2512.15427)

**Authors**: Hyakka Nakada, Shu Tanaka  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.15427v1  

#### Abstract
Random matrix theory has played an important role in various areas of pure mathematics, mathematical physics, and machine learning. From a practical perspective of data science, input data are usually normalized prior to processing. Thus, this study investigates the statistical properties of min-max...

---

### 43. [Multi-stage Bayesian optimisation for dynamic decision-making in self-driving labs](https://arxiv.org/abs/2512.15483)

**Authors**: Luca Torresi, Pascal Friederich  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.15483v1  

#### Abstract
Self-driving laboratories (SDLs) are combining recent technological advances in robotics, automation, and machine learning based data analysis and decision-making to perform autonomous experimentation toward human-directed goals without requiring any direct human intervention. SDLs are successfully ...

---

### 44. [Soft Geometric Inductive Bias for Object Centric Dynamics](https://arxiv.org/abs/2512.15493)

**Authors**: Hampus Linander, Conor Heins, Alexander Tschantz, Marco Perin, Christopher Buckley  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.15493v1  

#### Abstract
Equivariance is a powerful prior for learning physical dynamics, yet exact group equivariance can degrade performance if the symmetries are broken. We propose object-centric world models built with geometric algebra neural networks, providing a soft geometric inductive bias. Our models are evaluated...

---

### 45. [How Smoothing is N-simplicial Attention?](https://arxiv.org/abs/2512.15600)

**Authors**: Alexandre Dussolle, Pietro Li\`o  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.15600v1  

#### Abstract
Going from pure Multilayer Perceptron (MLP) to a learnable graph message-passing mechanism at each layer has been foundational to state-of-the-art results, despite the computational trade-off (e.g. GATs or Transformers). To go a step further, in this work, we introduce N-simplicial attention, going ...

---

### 46. [Multi-Modal Semantic Communication](https://arxiv.org/abs/2512.15691)

**Authors**: Matin Mortaheb, Erciyes Karakaya, Sennur Ulukus  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.15691v1  

#### Abstract
Semantic communication aims to transmit information most relevant to a task rather than raw data, offering significant gains in communication efficiency for applications such as telepresence, augmented reality, and remote sensing. Recent transformer-based approaches have used self-attention maps to ...

---

### 47. [Learning Model Parameter Dynamics in a Combination Therapy for Bladder Cancer from Sparse Biological Data](https://arxiv.org/abs/2512.15706)

**Authors**: Kayode Olumoyin, Lamees El Naqa, Katarzyna Rejniak  
**Category**: cs.LG  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.15706v1  

#### Abstract
In a mathematical model of interacting biological organisms, where external interventions may alter behavior over time, traditional models that assume fixed parameters usually do not capture the evolving dynamics. In oncology, this is further exacerbated by the fact that experimental data are often ...

---

### 48. [Multiscale Aggregated Hierarchical Attention (MAHA): A Game Theoretic and Optimization Driven Approach to Efficient Contextual Modeling in Large Language Models](https://arxiv.org/abs/2512.14925)

**Authors**: Caner Erden  
**Category**: cs.CL  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.14925v1  

#### Abstract
The quadratic computational complexity of MultiHead SelfAttention (MHSA) remains a fundamental bottleneck in scaling Large Language Models (LLMs) for longcontext tasks. While sparse and linearized attention mechanisms attempt to mitigate this, they often compromise the representation of global depen...

---

### 49. [Yes-MT's Submission to the Low-Resource Indic Language Translation Shared Task in WMT 2024](https://arxiv.org/abs/2512.15226)

**Authors**: Yash Bhaskar, Parameswari Krishnamurthy  
**Category**: cs.CL  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.15226v1  

#### Abstract
This paper presents the systems submitted by the Yes-MT team for the Low-Resource Indic Language Translation Shared Task at WMT 2024 (Pakray et al., 2024), focusing on translating between English and the Assamese, Mizo, Khasi, and Manipuri languages. The experiments explored various approaches, incl...

---

### 50. [Learning inflection classes using Adaptive Resonance Theory](https://arxiv.org/abs/2512.15551)

**Authors**: Peter Dekker, Heikki Rasilo, Bart de Boer  
**Category**: cs.CL  
**Published**: 2025-12-18  
**Score**: 1.0  
**Type**: new  
**ArXiv ID**: 2512.15551v1  

#### Abstract
The concept of inflection classes is an abstraction used by linguists, and provides a means to describe patterns in languages that give an analogical base for deducing previously unencountered forms. This ability is an important part of morphological acquisition and processing. We study the learnabi...

---

## üîß Configuration

This bot is configured to look for papers containing the following keywords:
- machine learning, deep learning, neural network, transformer

## üìÖ Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## üöÄ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## üìù Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## üîç Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
