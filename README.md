# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-17 05:55:56 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Fast and Accurate Causal Parallel Decoding using Jacobi Forcing](https://arxiv.org/abs/2512.14681)

**Authors**: Lanxiang Hu, Siqi Kou, Yichao Fu, Samyam Rajbhandari, Tajana Rosing, Yuxiong He, Zhijie Deng, Hao Zhang  
**Category**: cs.CL  
**Published**: 2025-12-17  
**Score**: 12.5  
**Type**: new  
**ArXiv ID**: 2512.14681v1  

#### Abstract
Multi-token generation has emerged as a promising paradigm for accelerating transformer-based large model inference. Recent efforts primarily explore diffusion Large Language Models (dLLMs) for parallel decoding to reduce inference latency. To achieve AR-level generation quality, many techniques ada...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Fast and Accurate Causal Parallel Decoding using Jacobi Forcing è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

ç°ä»£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¾èµ– **autoregressive (AR)** è§£ç ï¼Œé€ä¸ªç”Ÿæˆ tokenï¼Œå¯¼è‡´æ¨ç†å»¶è¿Ÿé«˜ã€å¹¶è¡Œåº¦ä½ã€‚è™½ç„¶ **diffusion-based LLMs (dLLMs)** è¢«æå‡ºç”¨äºå¹¶è¡Œè§£ç ä»¥åŠ é€Ÿæ¨ç†ï¼Œä½†å®ƒä»¬å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š

- **Pretrain-to-posttrain mismatch**ï¼šdLLMs åœ¨åè®­ç»ƒä¸­ä½¿ç”¨æ©ç æ•°æ®åˆ†å¸ƒï¼Œä¸é¢„è®­ç»ƒæ—¶çš„çœŸå®æ•°æ®åˆ†å¸ƒä¸ä¸€è‡´ã€‚
- **ç ´åå› æœå…ˆéªŒ**ï¼šdLLMs ä½¿ç”¨åŒå‘æ³¨æ„åŠ›æœºåˆ¶ï¼Œè¿èƒŒäº† AR æ¨¡å‹åœ¨é¢„è®­ç»ƒä¸­å­¦åˆ°çš„å› æœæ€§ï¼ˆcausal priorï¼‰ï¼Œé˜»ç¢äº†ç²¾ç¡®çš„ KV cache å¤ç”¨ã€‚
- **è´¨é‡ä¸‹é™ä¸¥é‡**ï¼šå½“ block size å¢å¤§æ—¶ï¼Œé€‚åº”åçš„ dLLMs æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼ˆå¦‚ SDAR åœ¨ block size=128 æ—¶è´¨é‡å¤§å¹…é™ä½ï¼‰ã€‚

å› æ­¤ï¼Œç°æœ‰æ–¹æ³•åœ¨è¿½æ±‚é€Ÿåº¦çš„åŒæ—¶éš¾ä»¥ä¿æŒ AR çº§åˆ«çš„ç”Ÿæˆè´¨é‡ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **Jacobi Forcing**ï¼Œä¸€ç§æ¸è¿›å¼è’¸é¦èŒƒå¼ï¼ˆprogressive distillation paradigmï¼‰ï¼Œå°† AR æ¨¡å‹é€æ­¥è½¬å˜ä¸ºé«˜æ•ˆçš„å¹¶è¡Œè§£ç å™¨ï¼ŒåŒæ—¶ä¿ç•™å…¶å› æœæ¨ç†èƒ½åŠ›ã€‚

#### æ ¸å¿ƒæ€æƒ³ï¼š
- ä¸ä¿®æ”¹ AR æ¨¡å‹çš„å› æœæ³¨æ„åŠ›ç»“æ„ã€‚
- åˆ©ç”¨ **Jacobi Decoding** ç”Ÿæˆæ¨¡å‹è‡ªèº«çš„å¹¶è¡Œè§£ç è½¨è¿¹ï¼ˆtrajectoryï¼‰ï¼Œå¹¶åœ¨è¿™äº›è½¨è¿¹ä¸Šè¿›è¡Œä¸€è‡´æ€§è’¸é¦ï¼ˆconsistency distillationï¼‰ã€‚
- å¼•å…¥ **progressive noise schedule** å’Œ **noise-aware causal attention**ï¼Œä½¿æ¨¡å‹å­¦ä¼šåœ¨å™ªå£°ä¸Šä¸‹æ–‡ä¸­é¢„æµ‹æœªæ¥çš„æ­£ç¡® tokenã€‚

#### å…·ä½“åˆ›æ–°ç‚¹ï¼š

| åˆ›æ–°æ¨¡å— | æè¿° |
|--------|------|
| **Jacobi Forcing** | åœ¨ AR æ¨¡å‹è‡ªèº«ç”Ÿæˆçš„ Jacobi è½¨è¿¹ä¸Šè¿›è¡Œæ¸è¿›å¼ä¸€è‡´æ€§è®­ç»ƒï¼Œé¿å…å¼•å…¥å¤–éƒ¨æ©ç æ•°æ®åˆ†å¸ƒåå·®ã€‚ |
| **Progressive Noise Schedule** | å°†å¤§ block åˆ†æˆå°çª—å£ï¼ŒæŒ‰å‘¨æœŸæ€§é€’å¢å™ªå£°æ¯”ä¾‹ï¼ˆä» 0 åˆ° 1ï¼‰ï¼Œç¡®ä¿æ¯ä¸ª block éƒ½æœ‰éƒ¨åˆ†â€œå¹²å‡€ä¸Šä¸‹æ–‡â€ï¼Œé™ä½å­¦ä¹ éš¾åº¦ã€‚ |
| **Noise-aware Causal Attention** | è®¾è®¡ç‰¹æ®Šçš„ attention maskï¼Œå…è®¸åœ¨ä¸€ä¸ª forward pass ä¸­åŒæ—¶è®¡ç®— AR loss å’Œ consistency lossï¼Œæå‡è®­ç»ƒæ•ˆç‡ã€‚ |
| **Multi-block Decoding + Rejection Recycling** | æ¨ç†é˜¶æ®µä¼˜åŒ–ç­–ç•¥ï¼š<br>- **Multi-block**ï¼šåŒæ—¶ç»´æŠ¤å¤šä¸ª blockï¼Œæå‰è§£ç åç»­ block çš„ tokenï¼›<br>- **Rejection Recycling**ï¼šå¤ç”¨å†å²è¿­ä»£ä¸­é«˜è´¨é‡çš„ n-gram ä½œä¸ºå€™é€‰ï¼Œæé«˜å•æ¬¡è¿­ä»£æ¥å—çš„ token æ•°é‡ã€‚ |

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **è®­ç»ƒç¨³å®šæ€§** | é¿å… pretrain-posttrain åˆ†å¸ƒåç§»ï¼Œè®­ç»ƒæ›´ç¨³å®šï¼Œå¯æ‰©å±•è‡³æ›´å¤§ block sizeã€‚ |
| **ä¿æŒç”Ÿæˆè´¨é‡** | ä¿ç•™ AR å› æœç»“æ„ï¼Œç”Ÿæˆè´¨é‡æ¥è¿‘åŸå§‹ AR æ¨¡å‹ï¼ˆä»…è½»å¾®ä¸‹é™ï¼‰ã€‚ |
| **æ›´é«˜çš„åŠ é€Ÿæ½œåŠ›** | æ”¯æŒæ›´å¤§çš„ block size å’Œæ›´å¤šå¹¶è¡Œ token é¢„æµ‹ï¼Œå……åˆ†åˆ©ç”¨ç°ä»£ AI åŠ é€Ÿå™¨çš„ç®—åŠ›ã€‚ |
| **ç«¯åˆ°ç«¯é€Ÿåº¦æ›´å¿«** | å®ç°é«˜è¾¾ 4.0Ã— çš„ wall-clock speedupï¼Œè¿œè¶… dLLMs å’Œä¼ ç»Ÿ AR å¹¶è¡Œæ–¹æ³•ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

| ä»»åŠ¡ç±»å‹ | æ•°æ®é›† | æ¨¡å‹ |
|---------|-------|------|
| **ä»£ç ç”Ÿæˆ** | OpenCodeInstructï¼ˆè®­ç»ƒï¼‰ã€HumanEvalã€MBPPï¼ˆæµ‹è¯•ï¼‰ | Qwen2.5-Coder-7B-Instruct |
| **æ•°å­¦æ¨ç†** | Openthought2ï¼ˆmath splitï¼Œè®­ç»ƒï¼‰ã€GSM8Kã€MATHï¼ˆæµ‹è¯•ï¼‰ | Qwen2.5-Math-7B-Instruct |

æ‰€æœ‰æ¨¡å‹å‡åŸºäº Qwen2.5 ç³»åˆ—æŒ‡ä»¤å¾®è°ƒç‰ˆæœ¬ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **ç¡¬ä»¶ç¯å¢ƒ**
- è®­ç»ƒä¸æ¨ç†ï¼š8x NVIDIA A100-80GB æˆ– H200/B200 GPUã€‚

#### **è®­ç»ƒé…ç½®**
- å­¦ä¹ ç‡ï¼š1e-6
- Batch sizeï¼š4
- Max sequence lengthï¼š2048
- Block sizeï¼šåˆå§‹ 16 â†’ ç¬¬äºŒè½®è®­ç»ƒå‡è‡³ 32
- Window sizeï¼š16ï¼ˆç¬¬ä¸€è½®ï¼‰ï¼Œ8ï¼ˆç¬¬äºŒè½®ï¼‰
- è®­ç»ƒæ­¥æ•°ï¼šæ¯è½® 10k steps

#### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **TPS (Tokens Per Second)** | æ¯ç§’ç”Ÿæˆ token æ•°é‡ï¼Œè¡¡é‡ååé‡ |
| **Speedup** | ç›¸å¯¹äº AR baseline çš„ TPS åŠ é€Ÿæ¯” |
| **Accuracy / Solve Rate** | HumanEval ä¸Šçš„ pass@1 å‡†ç¡®ç‡ï¼ŒGSM8K/MATH ä¸Šçš„é—®é¢˜è§£å†³ç‡ |
| **TPF (Tokens Forwarded per Iteration)** | æ¯æ¬¡è¿­ä»£å¹³å‡å‘å‰æ¨è¿›çš„ token æ•°é‡ï¼Œåæ˜ å¹¶è¡Œæ•ˆç‡ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| ç±»åˆ« | åŸºçº¿æ–¹æ³• |
|------|--------|
| **AR-based å¹¶è¡Œè§£ç ** | Vanilla Jacobiã€CLLM*ï¼ˆæ”¹è¿›ç‰ˆä¸€è‡´æ€§è’¸é¦ï¼‰ |
| **Diffusion-based LLMs** | LLaDA-7Bã€Dream-7Bã€Fast-dLLMã€D2F |
| **Speculative Decoding** | EAGLE-3ã€HASSï¼ˆè¡¥å……å¯¹æ¯”ï¼‰ |

> æ³¨ï¼šCLLM* æ˜¯ä½œè€…å®ç°çš„å¢å¼ºç‰ˆï¼ŒåŠ å…¥ sequence packing æŠ€æœ¯ä½†æœªé‡‡ç”¨æ¸è¿›è®­ç»ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆA100 GPUï¼‰**

#### âœ… **ä»£ç ç”Ÿæˆï¼ˆHumanEvalï¼‰**
| æ–¹æ³• | TPS | Speedup | Accuracy |
|------|-----|---------|----------|
| AR (baseline) | 41.3 | 1.00Ã— | 87.8% |
| CLLM* | 103.3 | 2.50Ã— | 87.8% |
| **Jacobi Forcing Model** | **159.5** | **3.86Ã—** | **83.5%** |
| **Jacobi Forcing Model (MR)** | **163.9** | **3.97Ã—** | **83.5%** |

> MR = Multi-block + Rejection Recycling

#### âœ… **æ•°å­¦æ¨ç†ï¼ˆGSM8Kï¼‰**
| æ–¹æ³• | TPS | Speedup | Solve Rate |
|------|-----|---------|------------|
| AR | 41.8 | 1.00Ã— | 92.4% |
| **Jacobi Forcing Model (MR)** | **154.9** | **3.71Ã—** | **91.4%** |

#### âœ… **æ•°å­¦æ¨ç†ï¼ˆMATHï¼‰**
| æ–¹æ³• | TPS | Speedup | Solve Rate |
|------|-----|---------|------------|
| AR | 41.3 | 1.00Ã— | 77.0% |
| **Jacobi Forcing Model (MR)** | **152.0** | **3.68Ã—** | **77.4%** |

> åœ¨ MATH ä¸Šç”šè‡³ç•¥å¾®æå‡äº†å‡†ç¡®ç‡ï¼

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

| å¯¹æ¯”ç»´åº¦ | ç»“æœ |
|--------|------|
| **vs dLLMs** | Jacobi Forcing æ¯” Dream-Base å¿« **7.4Ã—~15Ã—**ï¼Œæ¯” Fast-dLLM/D2F å¿« **2.0Ã—~2.2Ã—**ï¼Œä¸”å‡†ç¡®ç‡é«˜å‡º 20â€“40 ä¸ªç™¾åˆ†ç‚¹ã€‚ |
| **vs AR-based parallel** | æ¯” CLLM å¿« **1.6Ã—**ï¼ŒTPF æå‡è¿‘ **2Ã—**ã€‚ |
| **vs speculative decoding**ï¼ˆB200ï¼‰| æ¯” EAGLE-3 å¿« **1.3Ã—**ï¼Œæ¯” HASS å¿« **1.2Ã—**ï¼Œä¸”ä¸º losslessï¼ˆä¸æ”¹å˜è¾“å‡ºåˆ†å¸ƒï¼‰ã€‚ |

> è¡¨æ˜ Jacobi Forcing åœ¨ **é€Ÿåº¦-è´¨é‡æƒè¡¡** ä¸Šå¤„äºæœ€ä¼˜å‰æ²¿ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### ğŸ” **ä¸åŒ noise schedule æ•ˆæœï¼ˆHumanEval, block=256ï¼‰**
| Schedule | Accuracy | iter/token |
|---------|----------|-----------|
| Random | 82.9% | 0.53 |
| **Linear Progressive** | **84.7%** | **0.48** |
| Reverse Progressive | 82.9% | 0.62 |

âœ… **çº¿æ€§é€’å¢å™ªå£°è°ƒåº¦æ•ˆæœæœ€å¥½**ï¼Œæ”¶æ•›æ›´å¿«ã€è´¨é‡æ›´é«˜ã€‚

#### ğŸ” **Attention Mask ç±»å‹å½±å“**
| Mask ç±»å‹ | Speedup | Accuracy |
|----------|--------|----------|
| Noise-conditioned (NC) | **3.6Ã—** | 82.3% |
| NC + Intra-window Clean Context (NC-IC) | 1.9Ã— | 82.3% |

âœ… **noise-aware causal mask æ›´æœ‰æ•ˆ**ï¼Œè¯´æ˜åˆ©ç”¨å™ªå£°ä¸Šä¸‹æ–‡è¿›è¡Œé¢„æµ‹æ˜¯å…³é”®ã€‚

#### ğŸ” **FLOPs åˆ©ç”¨åˆ†æ**
- åœ¨ H200/B200 ä¸Šï¼Œæœ€å¤šå¯å¹¶è¡Œå¤„ç† **256 tokens** è€Œä¸å¢åŠ å»¶è¿Ÿã€‚
- æœ€ä¼˜é…ç½®ï¼š**block size=64**, **verification size=4** â†’ 64Ã—4=256 tokensï¼Œå®Œç¾åŒ¹é…ç¡¬ä»¶å³°å€¼åˆ©ç”¨ç‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **Jacobi Forcing æˆåŠŸå®ç°äº† AR æ¨¡å‹å‘é«˜æ•ˆå¹¶è¡Œè§£ç å™¨çš„å¹³æ»‘è¿‡æ¸¡**ï¼Œæ— éœ€ç‰ºç‰²å› æœç»“æ„å³å¯è·å¾—æ¥è¿‘ 4Ã— çš„ wall-clock speedupã€‚
2. âœ… **æ¸è¿›å¼å™ªå£°è°ƒåº¦ + noise-aware attention** æ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å™ªå£°ä¸Šä¸‹æ–‡ä¸­é¢„æµ‹æœªæ¥ token çš„èƒ½åŠ›ã€‚
3. âœ… **Multi-block decoding ä¸ rejection recycling ååŒä½œç”¨**ï¼Œä½¿å¾—æ¯æ¬¡è¿­ä»£å¯æ¥å—çš„ token æ•°é‡æå‡è¾¾ **4.5Ã—**ã€‚
4. âœ… åœ¨ **ä»£ç ä¸æ•°å­¦ä»»åŠ¡ä¸Šå‡è¡¨ç°å‡ºè‰²**ï¼Œå°¤å…¶åœ¨ MATH ä¸Šè¿˜ç•¥å¾®æå‡äº† solve rateï¼Œè¯´æ˜è¯¥æ–¹æ³•ä¸ä»…å¿«ï¼Œè€Œä¸”â€œèªæ˜â€ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

| å±€é™æ€§ | è¯´æ˜ |
|--------|------|
| **ä»éœ€é¢å¤–è®­ç»ƒ** | ä¸æ˜¯ training-free æ–¹æ³•ï¼Œéœ€è¦æ”¶é›†è½¨è¿¹å¹¶è¿›è¡Œè’¸é¦è®­ç»ƒã€‚ |
| **å¯¹ block size æ•æ„Ÿ** | æ€§èƒ½ä¾èµ–äºåˆç†çš„ block size å’Œ verification size é…ç½®ï¼Œéœ€é’ˆå¯¹ç¡¬ä»¶è°ƒä¼˜ã€‚ |
| **å†…å­˜å¼€é”€ç•¥å¢** | å¤š block ç»´æŠ¤å’Œ n-gram ç¼“å­˜å¸¦æ¥ä¸€å®šæ˜¾å­˜è´Ÿæ‹…ã€‚ |
| **ç›®å‰ä»…æ”¯æŒ greedy decoding** | å°šæœªéªŒè¯åœ¨é‡‡æ ·ï¼ˆsamplingï¼‰åœºæ™¯ä¸‹çš„è¡¨ç°ã€‚ |

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. ğŸ”„ **æ‰©å±•è‡³ sampling åœºæ™¯**ï¼šç ”ç©¶å¦‚ä½•åœ¨éè´ªå©ªé‡‡æ ·ä¸‹ä¿æŒ high token acceptanceã€‚
2. âš™ï¸ **è‡ªåŠ¨åŒ–é…ç½®æœç´¢**ï¼šå¼€å‘è‡ªé€‚åº”ç®—æ³•åŠ¨æ€è°ƒæ•´ block sizeã€verification depth ç­‰å‚æ•°ã€‚
3. ğŸ§  **ç»“åˆ speculative decoding**ï¼šæ¢ç´¢ä¸ Medusa/EAGLE ç­‰æ–¹æ³•èåˆçš„å¯èƒ½æ€§ã€‚
4. ğŸŒ **éƒ¨ç½²ä¼˜åŒ–**ï¼šè¿›ä¸€æ­¥å‹ç¼© KV cacheã€æ”¯æŒ streaming è¾“å‡ºç­‰å·¥ä¸šçº§ä¼˜åŒ–ã€‚

---

> ğŸ”— **å¼€æºåœ°å€**ï¼šhttps://github.com/hao-ai-lab/JacobiForcing  
> ğŸ“„ **è®ºæ–‡é“¾æ¥**ï¼šhttps://arxiv.org/abs/2512.14681

</details>

---

### 2. [A Unified Sparse Attention via Multi-Granularity Compression](https://arxiv.org/abs/2512.14082)

**Authors**: Siran Liu, Zane Cao, Yongchao He  
**Category**: cs.CL  
**Published**: 2025-12-17  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2512.14082v1  

#### Abstract
Efficient long-context understanding and reasoning are increasingly vital for large language model (LLM) applications such as multi-turn dialogue and program analysis. However, the core self-attention mechanism scales quadratically with sequence length, creating a fundamental computational bottlenec...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šA Unified Sparse Attention via Multi-Granularity Compression

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­çš„ **self-attention** æœºåˆ¶è®¡ç®—å¤æ‚åº¦ä¸º $O(L^2)$ï¼Œå…¶ä¸­ $L$ æ˜¯åºåˆ—é•¿åº¦ã€‚è¿™åœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ï¼ˆå¦‚å¤šè½®å¯¹è¯ã€ä»£ç åˆ†æã€é•¿æ–‡æ¡£ç†è§£ï¼‰æ—¶æˆä¸ºä¸¥é‡çš„è®¡ç®—ç“¶é¢ˆã€‚å°½ç®¡å·²æœ‰å¤šç§ç¨€ç–æ³¨æ„åŠ›ï¼ˆsparse attentionï¼‰æ–¹æ³•è¯•å›¾ç¼“è§£è¯¥é—®é¢˜ï¼Œä½†ä»é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š

- **è®­ç»ƒè€¦åˆæ–¹æ³•**ï¼ˆå¦‚ DeepSeek çš„ Native Sparse Attentionï¼‰ï¼šéœ€åœ¨é¢„è®­ç»ƒé˜¶æ®µå¼•å…¥ç¨€ç–ç»“æ„ï¼Œç¼ºä¹é€šç”¨æ€§ï¼Œæ— æ³•ä½œä¸ºå³æ’å³ç”¨çš„åŠ é€Ÿæ¨¡å—ç”¨äºå·²è®­ç»ƒå¥½çš„æ¨¡å‹ã€‚
- **æ¨ç†æ—¶é™æ€æ–¹æ³•**ï¼ˆå¦‚ BigBirdã€StreamLLMï¼‰ï¼šé‡‡ç”¨å›ºå®šæ¨¡å¼ï¼ˆæ»‘åŠ¨çª—å£ã€sink tokenç­‰ï¼‰ï¼Œç¼ºä¹å¯¹è¾“å…¥å†…å®¹çš„è‡ªé€‚åº”èƒ½åŠ›ï¼Œéš¾ä»¥æ³›åŒ–åˆ°è§†é¢‘ã€éŸ³é¢‘ç­‰è·¨æ¨¡æ€ä»»åŠ¡ã€‚
- **æ¨ç†æ—¶åŠ¨æ€æ–¹æ³•**ï¼ˆå¦‚ FlexPrefillã€XAttentionï¼‰ï¼šä¾èµ–ç®€å•å¯å‘å¼è§„åˆ™ï¼ˆå¦‚æœ€åä¸€å—æŸ¥è¯¢å—ä½œä¸ºæ¢é’ˆï¼‰ï¼Œåœ¨å¤æ‚ä»»åŠ¡ä¸­è¡¨ç°ä¸ç¨³å®šã€‚

å› æ­¤ï¼Œå¦‚ä½•è®¾è®¡ä¸€ç§**é«˜æ•ˆã€é€šç”¨ã€æ— éœ€é‡è®­ç»ƒä¸”é€‚ç”¨äºå¤šæ¨¡æ€ä»»åŠ¡çš„ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶**ï¼Œæ˜¯å½“å‰ç ”ç©¶çš„å…³é”®æŒ‘æˆ˜ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **UniSparse**ï¼Œä¸€ç§ç»Ÿä¸€çš„ã€ç¡¬ä»¶å‹å¥½çš„åŠ¨æ€ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³åŸºäº **å¤åˆä»¤ç‰Œï¼ˆcomposite tokensï¼‰** å’Œ **å¤šç²’åº¦å‹ç¼©ï¼ˆmulti-granularity compressionï¼‰**ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š

1. âœ… **å¤åˆä»¤ç‰Œï¼ˆComposite Tokensï¼‰**  
   å°†åŸå§‹ç»†ç²’åº¦ token é€šè¿‡ç©ºé—´æ± åŒ–ï¼ˆå¦‚å¹³å‡æ± åŒ–ï¼‰èšåˆä¸ºç²—ç²’åº¦çš„â€œå¤åˆä»¤ç‰Œâ€ï¼Œä½œä¸ºä¸Šä¸‹æ–‡ä¿¡æ¯çš„ç´§å‡‘è¡¨ç¤ºã€‚è¿™äº›å¤åˆä»¤ç‰Œä¿ç•™äº†å±€éƒ¨è¯­ä¹‰ç»“æ„ï¼Œå¯ç”¨äºè½»é‡çº§ä»£ç†è®¡ç®—ã€‚

2. âœ… **å¤šç²’åº¦å‹ç¼©æœºåˆ¶**  
   åœ¨åºåˆ—ç»´åº¦ï¼ˆsequence-levelï¼‰å’Œå¯é€‰çš„å¤´ç»´åº¦ï¼ˆhead-levelï¼‰è¿›è¡Œå‹ç¼©ï¼š
   - åºåˆ—å‹ç¼©å› å­ $c_q, c_k$ï¼šå‡å°‘ token æ•°é‡ã€‚
   - å¤´å‹ç¼©å› å­ $c_h$ï¼šå°†å¤šä¸ªæ³¨æ„åŠ›å¤´åˆ†ç»„å¹¶å–å¹³å‡ï¼Œé™ä½é€‰æ‹©å¼€é”€ã€‚

3. âœ… **ä¸¤é˜¶æ®µåŠ¨æ€å—é€‰æ‹©ç®—æ³•**
   - **Stage 1ï¼šå‹ç¼©ç©ºé—´ä¸­çš„æ³¨æ„åŠ›è®¡ç®—**  
     åœ¨å‹ç¼©åçš„ä½ç»´ç©ºé—´ä¸­è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°çŸ©é˜µï¼ˆå¤§å°ä»…ä¸ºåŸçŸ©é˜µçš„ $1/(c_q c_k)$ï¼‰ã€‚
   - **Stage 2ï¼šå—çº§é‡è¦æ€§èšåˆ + Top-P é€‰æ‹©**  
     å°†å‹ç¼©ç©ºé—´çš„æ³¨æ„åŠ›åˆ†æ•°åå‘æ˜ å°„å›åŸå§‹å—çº§åˆ«ï¼ŒæŒ‰ç´¯è®¡æ³¨æ„åŠ›è´¨é‡é€‰æ‹©æœ€é‡è¦çš„ Key å—ï¼ˆTop-P æœºåˆ¶ï¼‰ï¼Œç”Ÿæˆç¨€ç–æ©ç  $M$ã€‚

4. âœ… **ç¡¬ä»¶å‹å¥½å®ç°**
   - ä½¿ç”¨ fused kernel è®¾è®¡ï¼Œä¸­é—´ç»“æœä¿ç•™åœ¨ on-chip memory ä¸­ï¼Œå‡å°‘å†…å­˜è®¿é—®ã€‚
   - æ”¯æŒä¸ FlashAttention å…¼å®¹çš„ block-sparse kernelsï¼Œä¾¿äºé›†æˆã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | UniSparse | ç°æœ‰æ–¹æ³• |
|------|----------|---------|
| **æ˜¯å¦éœ€è¦é‡è®­ç»ƒ** | âŒ å¦ï¼ˆinference-timeï¼‰ | âœ… å¤šæ•°è®­ç»ƒè€¦åˆæ–¹æ³•éœ€è¦ |
| **æ˜¯å¦å³æ’å³ç”¨** | âœ… æ˜¯ | âŒ å¤šæ•°ä¸æ”¯æŒ |
| **æ˜¯å¦è·¨æ¨¡æ€é€šç”¨** | âœ… æ˜¯ï¼ˆæ–‡æœ¬ã€è§†é¢‘ã€éŸ³é¢‘å‡é€‚ç”¨ï¼‰ | âŒ å¤šä¸ºæ–‡æœ¬ä¸“ç”¨ |
| **é€‰æ‹©ç­–ç•¥** | âœ… å…¨å±€è¯„ä¼°ï¼ˆglobal evaluationï¼‰ | âš ï¸ å±€éƒ¨é‡‡æ ·ï¼ˆå¦‚ FlexPrefillï¼‰æˆ–ç®€åŒ–å¯å‘å¼ï¼ˆå¦‚ XAttentionï¼‰ |
| **æ•ˆç‡ vs å‡†ç¡®ç‡å¹³è¡¡** | âœ… é«˜æ•ˆä¸”é«˜ä¿çœŸ | âš ï¸ è¦ä¹ˆæ…¢ï¼ˆMInferenceï¼‰ï¼Œè¦ä¹ˆä¸å‡†ï¼ˆXAttentionï¼‰ |

> **ä¸€å¥è¯æ€»ç»“ä¼˜åŠ¿**ï¼šUniSparse å®ç°äº†æ— éœ€è®­ç»ƒã€è·¨æ¨¡æ€é€šç”¨ã€é«˜å‡†ç¡®ç‡ã€é«˜æ•ˆç‡çš„ç¨€ç–æ³¨æ„åŠ›ï¼Œåœ¨ç²¾åº¦ä¸é€Ÿåº¦ä¹‹é—´è¾¾åˆ°äº†æœ€ä¼˜æƒè¡¡ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

å®éªŒè¦†ç›–ä¸‰å¤§ç±»é•¿ä¸Šä¸‹æ–‡åŸºå‡†ï¼Œæ¶µç›–åˆæˆä»»åŠ¡ã€çœŸå®ä¸–ç•Œåº”ç”¨å’Œå¤šæ¨¡æ€åœºæ™¯ï¼š

| æ•°æ®é›† | ç±»å‹ | æè¿° |
|-------|------|------|
| **RULER** (Hsieh et al., 2024) | åˆæˆåŸºå‡† | æ§åˆ¶ä»»åŠ¡å¤æ‚åº¦ï¼Œæµ‹è¯•æ£€ç´¢ã€èšåˆã€å¤šè·³æ¨ç†èƒ½åŠ›ï¼Œæœ€é•¿è¾¾ 128K tokens |
| **HELMET** (Yen et al., 2025) | çœŸå®ä¸–ç•ŒåŸºå‡† | åŒ…å« 7 ç±»åº”ç”¨åœºæ™¯ï¼ˆé•¿æ–‡æ¡£ QAã€æ‘˜è¦ã€RAG ç­‰ï¼‰ï¼Œå¼ºè°ƒæ·±å±‚è¯­ä¹‰ç†è§£ |
| **Video-MME** (Fu et al., 2024) | å¤šæ¨¡æ€è§†é¢‘ç†è§£ | æ¶µç›– 6 ä¸ªè§†è§‰é¢†åŸŸã€30 ä¸ªå­ä»»åŠ¡ï¼Œæ”¯æŒå¸§ã€å­—å¹•ã€éŸ³é¢‘è¾“å…¥ï¼Œæµ‹è¯•æ—¶ç©ºä¸è·¨æ¨¡æ€æ¨ç† |

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### æ¨¡å‹
- **Meta-Llama-3.1-8B-Instruct**ï¼ˆçº¯æ–‡æœ¬ï¼‰
- **Qwen2.5-7B-Instruct**ï¼ˆå¤šè¯­è¨€æ–‡æœ¬ï¼‰
- **Qwen2.5-VL-7B-Instruct**ï¼ˆè§†è§‰-è¯­è¨€æ¨¡å‹ï¼‰

#### ä¸Šä¸‹æ–‡é•¿åº¦
ä» 4K åˆ° 128K tokens ä¸ç­‰ï¼Œéƒ¨åˆ†ä»»åŠ¡è¾¾åˆ° 30 åˆ†é’Ÿä»¥ä¸Šè§†é¢‘ã€‚

#### è¯„ä¼°æŒ‡æ ‡
- **å‡†ç¡®æ€§**ï¼šå„ä»»åŠ¡çš„å¾—åˆ†ï¼ˆå¦‚ RULER/HELMET çš„ overall scoreï¼ŒVideo-MME çš„ accuracyï¼‰
- **ç¨€ç–åº¦ï¼ˆSparsityï¼‰**ï¼šè¢«è·³è¿‡çš„ attention block æ¯”ä¾‹
- **é€Ÿåº¦æå‡**ï¼šç›¸å¯¹äº FlashAttention çš„ end-to-end attention è®¡ç®—æ—¶é—´åŠ é€Ÿæ¯”
- **é€‰æ‹©å¼€é”€ï¼ˆSelection Overheadï¼‰**ï¼šç¡®å®šç¨€ç–æ©ç  $M$ æ‰€éœ€çš„æ—¶é—´

#### ä¸»è¦é…ç½®
- é»˜è®¤å‹ç¼©å› å­ï¼š$c_q = c_k = 8$, $c_h = 1$
- Top-P é˜ˆå€¼ï¼š$P = 0.9$ æˆ– $0.95$
- æ‰€æœ‰æ–¹æ³•ä»…åœ¨ **prefill é˜¶æ®µ** åº”ç”¨ç¨€ç–ï¼Œdecode é˜¶æ®µä¿æŒ dense

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **FlashAttention** | Dense Baseline | å®Œæ•´æ³¨æ„åŠ›ï¼Œå†…å­˜ä¼˜åŒ–å®ç°ï¼Œç²¾åº¦ä¸Šé™ |
| **MInference** (Jiang et al., 2024) | åŠ¨æ€ + ç¦»çº¿æœç´¢ | é«˜ä¿çœŸä½†éœ€ç¦»çº¿ pattern searchï¼Œéå³æ’å³ç”¨ |
| **FlexPrefill** (Lai et al., 2025) | åŠ¨æ€ + å±€éƒ¨æ¢é’ˆ | ä½¿ç”¨æœ€åä¸€ä¸ª query block æ¢æµ‹é‡è¦åŒºåŸŸï¼Œé€Ÿåº¦å¿«ä½†æ˜“æ¼ |
| **XAttention** (Xu et al., 2025) | åŠ¨æ€ + å…¨å±€é‡‡æ · | ä½¿ç”¨ anti-diagonal scoring + stride samplingï¼Œå…¨å±€ä½†æˆæœ¬é«˜ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… **ç²¾åº¦ä¿æŒ**
- åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šï¼ŒUniSparse **ä¿ç•™ â‰¥99% çš„ Full Attention ç²¾åº¦**ã€‚
- åœ¨æŸäº›æƒ…å†µä¸‹ç”šè‡³**è¶…è¿‡ Full Attention**ï¼ˆå¦‚ Video-MME with subtitles ä¸‹ UniSparse è¾¾ 69.9%ï¼Œè€Œ FlashAttention ä¸º 69.6%ï¼‰ï¼Œè¡¨æ˜å…¶èƒ½æœ‰æ•ˆä¿ç•™å…³é”®è·¨æ¨¡æ€ä¿¡æ¯ã€‚

#### âœ… **é€Ÿåº¦æå‡**
- åœ¨ 128K åºåˆ—é•¿åº¦ä¸‹ï¼š
  - **ç«¯åˆ°ç«¯ attention è®¡ç®—é€Ÿåº¦æå‡é«˜è¾¾ 2.61Ã—**ï¼ˆvs. FlashAttentionï¼‰
  - **é€‰æ‹©é˜¶æ®µæé€Ÿ 2.64Ã—**ï¼ˆvs. XAttention-0.95ï¼‰
- å›¾ 4 æ˜¾ç¤ºï¼Œéšç€åºåˆ—å¢é•¿ï¼ŒåŠ é€Ÿæ•ˆæœæŒç»­å¢å¼ºã€‚

#### âœ… **ç¨€ç–æ•ˆç‡**
- å¹³å‡ä»…éœ€è®¡ç®— **ä¸€åŠä»¥ä¸‹çš„ attention blocks** å³å¯è¾¾åˆ°æ¥è¿‘å…¨æ³¨æ„åŠ›çš„æ•ˆæœã€‚
- åœ¨ç›¸åŒç¨€ç–æ°´å¹³ä¸‹ï¼ŒUniSparse æ€§èƒ½æ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

| åŸºå‡† | æœ€ä½³åŸºçº¿ | UniSparse è¡¨ç° |
|------|--------|----------------|
| **RULER** | FlexPrefill-0.99 (92.59) | UniSparse-0.95 è¾¾ **92.56**ï¼Œç¨€ç–åº¦æ›´é«˜ï¼ˆ46.33% vs 36.51%ï¼‰ |
| **HELMET** | MInference (55.37) | UniSparse-0.95 è¾¾ **56.21**ï¼Œå…¨é¢é¢†å…ˆ |
| **Video-MME (no subtitle)** | FlexPrefill-0.95 (64.4) | UniSparse-0.9 è¾¾ **64.6**ï¼Œä¸”ç¨€ç–åº¦æ›´ä½ |
| **Video-MME (with subtitle)** | FlashAttention (69.6) | UniSparse-0.9 è¾¾ **69.9**ï¼Œ**è¶…è¶Šå…¨æ³¨æ„åŠ›** |

> ğŸ”¥ **ç‰¹åˆ«äº®ç‚¹**ï¼šåœ¨æç«¯é•¿åº¦ï¼ˆ128Kï¼‰ä¸‹ï¼ŒUniSparse æ€§èƒ½ç¨³å®šï¼Œè€Œå…¶ä»–æ–¹æ³•å‡ºç°æ˜æ˜¾é€€åŒ–ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### ï¼ˆ1ï¼‰å‹ç¼©ç­–ç•¥æ¯”è¾ƒï¼ˆTable 5ï¼‰
| ç­–ç•¥ | ç²¾åº¦ | ç¨€ç–åº¦ |
|------|-----|-------|
| **Average Pooling**ï¼ˆé»˜è®¤ï¼‰ | âœ… æœ€é«˜ | âœ… é€‚ä¸­ |
| Max Pooling | â†“ é™çº¦ 1â€“3 pts | â†‘ æ›´é«˜ï¼ˆä½†ä¿¡æ¯ä¸¢å¤±ï¼‰ |
| Stochastic Pooling | â†“ æ˜æ˜¾ä¸‹é™ | â†‘ è¾ƒé«˜ |

> ç»“è®ºï¼š**å¹³å‡æ± åŒ–æœ€å‡è¡¡**ï¼Œèƒ½å®Œæ•´ä¿ç•™ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

#### ï¼ˆ2ï¼‰Q-K å‹ç¼©æ¯”ä¾‹åˆ†é…ï¼ˆTable 6ï¼‰
- æœ€ä¼˜é…ç½®ï¼š**$c_q = c_k = 8$**ï¼ˆå¹³è¡¡å‹ç¼©ï¼‰
- æŸ¥è¯¢è¿‡åº¦å‹ç¼©ï¼ˆ$c_q=32$ï¼‰å¯¼è‡´æ€§èƒ½å¤§å¹…ä¸‹é™ â†’ æŸ¥è¯¢éœ€ä¿ç•™è¶³å¤Ÿç»†èŠ‚
- é”®åå‘å‹ç¼©ï¼ˆ$c_k=16$ï¼‰è¡¨ç°å°šå¯ï¼Œå¯èƒ½å›  Keys æ›´å†—ä½™

#### ï¼ˆ3ï¼‰å‹ç¼©ç²’åº¦ï¼ˆTable 7ï¼‰
- $c=4$ï¼šå¤ªç»† â†’ å¼€é”€å¤§
- $c=16$ï¼šå¤ªç²— â†’ ä¸¢å¤±ç»†èŠ‚
- **$c=8$ æ˜¯æœ€ä½³æŠ˜è¡·**

#### ï¼ˆ4ï¼‰å¤´å‹ç¼©ï¼ˆTable 8ï¼‰
- $c_h=2$ æˆ– $4$ å¯æ˜¾è‘—é™ä½é€‰æ‹©å¼€é”€ï¼ˆæé€Ÿè‡³ 2.64Ã—ï¼‰
- ä»£ä»·ï¼šç•¥å¾®é™ä½æœ€ç»ˆç¨€ç–åº¦ï¼ˆå› èšåˆåæ›´å¤š block è¢«è§†ä¸ºé‡è¦ï¼‰
- æ¨èï¼š**å½“é€‰æ‹©å¼€é”€ä¸»å¯¼æ—¶å¯ç”¨**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **å‹ç¼©ç©ºé—´ä¸­çš„æ’åä¸€è‡´æ€§é«˜**  
   å®éªŒéªŒè¯ï¼ˆå›¾1ï¼‰æ˜¾ç¤ºï¼Œå‹ç¼©ç©ºé—´ä¸­ block é‡è¦æ€§æ’åºä¸åŸå§‹ç©ºé—´ Spearman ç›¸å…³ç³»æ•° > 0.98ï¼Œè¯´æ˜ **block selection æœ¬è´¨æ˜¯æ’åºé—®é¢˜è€Œéè¯„åˆ†é—®é¢˜**ï¼Œæ”¯æŒäº†å‹ç¼©ä»£ç†çš„æœ‰æ•ˆæ€§ã€‚

2. âœ… **å¤åˆä»¤ç‰Œå…·æœ‰å¼ºæ³›åŒ–èƒ½åŠ›**  
   ç©ºé—´æ± åŒ–æ“ä½œå¤©ç„¶é€‚ç”¨äºä»»ä½•åºåˆ—æ•°æ®ï¼ˆæ–‡æœ¬ã€å›¾åƒ patchã€éŸ³é¢‘ç‰‡æ®µï¼‰ï¼Œä½¿ UniSparse æˆä¸ºé¦–ä¸ªçœŸæ­£**è·¨æ¨¡æ€é€šç”¨çš„ç¨€ç–æ³¨æ„åŠ›æ–¹æ¡ˆ**ã€‚

3. âœ… **å…¨å±€è¯„ä¼° + è½»é‡å‹ç¼© = æœ€ä¼˜è·¯å¾„**  
   ç›¸æ¯”å±€éƒ¨æ¢é’ˆï¼ˆFlexPrefillï¼‰æˆ–ç®€åŒ–é‡‡æ ·ï¼ˆXAttentionï¼‰ï¼ŒUniSparse é€šè¿‡å‹ç¼©å®ç°**ä½æˆæœ¬çš„å…¨å±€è¯„ä¼°**ï¼Œå…¼é¡¾æ•ˆç‡ä¸å‡†ç¡®æ€§ã€‚

4. âœ… **æ— éœ€ä»»åŠ¡è°ƒä¼˜å³å¯å–å¾— SOTA**  
   æ‰€æœ‰å®éªŒä½¿ç”¨ç»Ÿä¸€å‚æ•°ï¼ˆ$c=8, P=0.95$ï¼‰ï¼Œæœªé’ˆå¯¹ç‰¹å®šä»»åŠ¡è°ƒæ•´ï¼Œä»å…¨é¢è¶…è¶ŠåŸºçº¿ï¼Œä½“ç°å…¶é²æ£’æ€§å’Œå®ç”¨æ€§ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. ğŸ›‘ **å‹ç¼©å¯èƒ½å¯¼è‡´æç²¾ç»†å®šä½ä¸¢å¤±**  
   å¦‚â€œç²¾ç¡®å¼•ç”¨â€ï¼ˆCiteï¼‰ä»»åŠ¡ä¸­ï¼Œæåº¦å‹ç¼©å¯èƒ½å½±å“ä½ç½®æ•æ„Ÿæ€§ï¼Œä½†åœ¨å®é™…ç¨€ç–æ°´å¹³ä¸‹ä»å¯æ¥å—ã€‚

2. ğŸ›‘ **æç«¯å‹ç¼©ä¼šå¹³æ»‘æ³¨æ„åŠ›å·®å¼‚**  
   å½“ $c > 16$ æ—¶å¯èƒ½å‡ºç°â€œè¿‡å¹³æ»‘â€ï¼Œé”™è¿‡å…³é”®ç»†ç²’åº¦ patternã€‚

3. ğŸ›‘ **ç›®å‰ä»…ä¼˜åŒ– prefill é˜¶æ®µ**  
   decode é˜¶æ®µä»ä¸º denseï¼Œæœªæ¥å¯ç»“åˆ KV Cache å‹ç¼©è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. ğŸ”® **æ¢ç´¢æ›´æ™ºèƒ½çš„å‹ç¼©æ–¹å¼**  
   å¦‚åŸºäºå†…å®¹æ„ŸçŸ¥çš„ adaptive poolingï¼Œè€Œéå›ºå®šçª—å£å¹³å‡ã€‚

2. ğŸ”® **æ‰©å±•è‡³ decode é˜¶æ®µç¨€ç–åŒ–**  
   ç»“åˆ **SnapKV** æˆ– **KV cache pruning** æŠ€æœ¯ï¼Œå®ç°å…¨æµç¨‹ç¨€ç–ã€‚

3. ğŸ”® **æ”¯æŒæ›´å¤§è§„æ¨¡æ¨¡å‹ä¸åˆ†å¸ƒå¼è®­ç»ƒ**  
   å½“å‰å®éªŒé™äºå• GPUï¼Œæœªæ¥å¯åœ¨ tensor parallelism åœºæ™¯ä¸‹éªŒè¯é€šä¿¡æ”¶ç›Šã€‚

4. ğŸ”® **ç†è®ºåˆ†æå‹ç¼©å¯¹æ³¨æ„åŠ›æ¢¯åº¦çš„å½±å“**ï¼ˆè‹¥ç”¨äºè®­ç»ƒï¼‰

---

## æ€»ç»“

> **UniSparse** é€šè¿‡å¼•å…¥ **å¤åˆä»¤ç‰Œ** å’Œ **å¤šç²’åº¦å‹ç¼©**ï¼Œå®ç°äº†æ— éœ€é‡è®­ç»ƒã€å³æ’å³ç”¨ã€è·¨æ¨¡æ€é€šç”¨çš„é«˜æ•ˆç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ã€‚å®ƒåœ¨ä¿æŒ **â‰¥99% å…¨æ³¨æ„åŠ›ç²¾åº¦**çš„åŒæ—¶ï¼Œå®ç°äº†æœ€é«˜ **2.61Ã— çš„ attention è®¡ç®—åŠ é€Ÿ**ï¼Œå¹¶åœ¨ RULERã€HELMETã€Video-MME ç­‰å¤šä¸ªåŸºå‡†ä¸Šå…¨é¢è¶…è¶Š MInferenceã€FlexPrefillã€XAttention ç­‰ SOTA æ–¹æ³•ï¼Œæ˜¯å½“å‰æœ€æ¥è¿‘â€œç†æƒ³ç¨€ç–æ³¨æ„åŠ›â€çš„è§£å†³æ–¹æ¡ˆä¹‹ä¸€ã€‚

</details>

---

### 3. [Meta Hierarchical Reinforcement Learning for Scalable Resource Management in O-RAN](https://arxiv.org/abs/2512.13715)

**Authors**: Fatemeh Lotfi, Fatemeh Afghah  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.13715v1  

#### Abstract
The increasing complexity of modern applications demands wireless networks capable of real time adaptability and efficient resource management. The Open Radio Access Network (O-RAN) architecture, with its RAN Intelligent Controller (RIC) modules, has emerged as a pivotal solution for dynamic resourc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMeta-Hierarchical Reinforcement Learning for Scalable Resource Management in O-RAN

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

ç°ä»£æ— çº¿ç½‘ç»œï¼ˆç‰¹åˆ«æ˜¯åŸºäº **O-RAN** æ¶æ„ï¼‰é¢ä¸´é«˜åº¦åŠ¨æ€ã€å¼‚æ„ä¸”ä¸å¯é¢„æµ‹çš„èµ„æºç®¡ç†æŒ‘æˆ˜ã€‚ä¼ ç»Ÿæ–¹æ³•åœ¨ä»¥ä¸‹æ–¹é¢å­˜åœ¨ä¸è¶³ï¼š
- éš¾ä»¥å¿«é€Ÿé€‚åº”çªå‘æµé‡ã€ç”¨æˆ·å¯†åº¦å˜åŒ–å’Œå¤šæ ·åŒ–æœåŠ¡éœ€æ±‚ï¼ˆå¦‚ eMBBã€URLLCã€mMTCï¼‰ï¼›
- å¤šæ•°åŸºäº **DRL** æˆ– **Federated Learning** çš„æ–¹æ³•ç¼ºä¹å¯¹å¤æ‚åœºæ™¯çš„æ³›åŒ–èƒ½åŠ›ï¼›
- åœ¨å¤§è§„æ¨¡éƒ¨ç½²ä¸­ï¼Œæ”¶æ•›é€Ÿåº¦æ…¢ã€ç¨³å®šæ€§å·®ï¼Œéš¾ä»¥å…¼é¡¾å…¨å±€åè°ƒä¸å±€éƒ¨ä¼˜åŒ–ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹ **è‡ªé€‚åº” Meta-Hierarchical Reinforcement Learning (Meta-HRL)** æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- âœ… **åˆ†å±‚å†³ç­–æ¶æ„ï¼ˆHRLï¼‰**  
  å°†èµ„æºç®¡ç†åˆ†è§£ä¸ºä¸¤ä¸ªå±‚çº§ï¼š
  - **é«˜å±‚æ§åˆ¶å™¨ï¼ˆHigh-level Controllerï¼‰**ï¼šè´Ÿè´£è·¨åˆ‡ç‰‡ï¼ˆinter-sliceï¼‰èµ„æºåˆ†é…ï¼›
  - **ä½å±‚æ§åˆ¶å™¨ï¼ˆLow-level Controllerï¼‰**ï¼šæ‰§è¡Œåˆ‡ç‰‡å†…ï¼ˆintra-sliceï¼‰ç”¨æˆ·çº§è°ƒåº¦ã€‚
  è¿™ç§ç»“æ„æå‡äº†å¯æ‰©å±•æ€§å’Œå†³ç­–ç²’åº¦ã€‚

- âœ… **åŸºäº MAML çš„å…ƒå­¦ä¹ æœºåˆ¶ï¼ˆMeta-RLï¼‰**  
  å¼•å…¥ **Model-Agnostic Meta-Learning (MAML)** æ€æƒ³ï¼Œä½¿æ¨¡å‹èƒ½ä»å¤šä¸ªåˆ†å¸ƒå¼å•å…ƒï¼ˆDUsï¼‰çš„ç»éªŒä¸­â€œå­¦ä¼šå¦‚ä½•å­¦ä¹ â€ï¼Œå®ç°å¯¹æ–°ä»»åŠ¡çš„å¿«é€Ÿé€‚åº”ï¼ˆfew-shot adaptationï¼‰ã€‚

- âœ… **è‡ªé€‚åº”åŠ æƒå…ƒæ›´æ–°æœºåˆ¶ï¼ˆAdaptive Variance Weightingï¼‰**  
  åˆ›æ–°åœ°ä½¿ç”¨ **TD-error æ–¹å·®ï¼ˆTemporal Difference Error Varianceï¼‰** åŠ¨æ€è°ƒæ•´å„ä»»åŠ¡åœ¨å…ƒæ¢¯åº¦æ›´æ–°ä¸­çš„æƒé‡ï¼š
  $$
  w_g = \text{Softmin}(\sigma^2_{\text{TD},g})
  $$
  å³æ›´å…³æ³¨é‚£äº›ç¯å¢ƒå¤æ‚ã€æ³¢åŠ¨å¤§ã€å­¦ä¹ éš¾åº¦é«˜çš„ä»»åŠ¡ï¼Œä»è€Œæå‡æ•´ä½“ç¨³å®šæ€§å’Œæ”¶æ•›æ•ˆç‡ã€‚

- âœ… **é¢å‘ O-RAN çš„åˆ†å¸ƒå¼éƒ¨ç½²è®¾è®¡**  
  æ¯ä¸ª DU ä¸Šè¿è¡Œä¸€ä¸ªç‹¬ç«‹çš„ HRL agentï¼ˆä½œä¸º xAppï¼‰ï¼Œè€Œå…ƒæ§åˆ¶å™¨ä½äº Near-RT RIC ä¸­è¿›è¡Œèšåˆä¸åè°ƒï¼Œç¬¦åˆ O-RAN çš„å¼€æ”¾è§£è€¦æ¶æ„ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **é€‚åº”æ€§** | æ”¯æŒå¿«é€Ÿé€‚åº”æ–° DU æˆ–çªå‘æµé‡ï¼Œæ— éœ€é‡æ–°è®­ç»ƒ |
| **æ³›åŒ–èƒ½åŠ›** | è·¨ä¸åŒç½‘ç»œæ¡ä»¶å’Œåˆ‡ç‰‡ç±»å‹å…·æœ‰æ›´å¼ºçš„è¿ç§»èƒ½åŠ› |
| **ç¨³å®šæ€§** | è‡ªé€‚åº”åŠ æƒæœºåˆ¶ç¼“è§£äº†ä»»åŠ¡é—´ä¸å¹³è¡¡é—®é¢˜ï¼Œå‡å°‘ç¾éš¾æ€§é—å¿˜ |
| **å¯æ‰©å±•æ€§** | åˆ†å¸ƒå¼ + å±‚æ¬¡åŒ–è®¾è®¡æ”¯æŒå¤§è§„æ¨¡ç½‘ç»œæ‰©å±• |
| **ç†è®ºä¿éšœ** | æä¾›äº†æ”¶æ•›æ€§å’Œåæ‚”ç•Œï¼ˆregret boundï¼‰åˆ†æ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **å®éªŒå¹³å°ä¸ä»¿çœŸç¯å¢ƒ**

- ä½¿ç”¨è‡ªå»ºçš„ **O-RAN ä»¿çœŸæ¡†æ¶**ï¼Œæœªä¾èµ–å…¬å¼€æ•°æ®é›†ï¼ˆå› å½“å‰ç¼ºä¹æ ‡å‡† O-RAN RL æµ‹è¯•å¹³å°ï¼‰ï¼›
- åŸºäº **PyTorch** å®ç° DDPG ç®—æ³•ä½œä¸ºåº•å±‚ RL å¼•æ“ï¼›
- æ‰€æœ‰ xApp éƒ¨ç½²åœ¨ Near-RT RIC æ¨¡å—ä¸­ï¼Œç¬¦åˆ O-RAN è§„èŒƒã€‚

### **ç³»ç»Ÿé…ç½®å‚æ•°ï¼ˆè§ Table 1ï¼‰**

| å‚æ•° | å€¼ |
|------|----|
| å­è½½æ³¢é—´éš” | 15 kHz |
| å•ä¸ª DU å¸¦å®½ | 20 MHz |
| RB æ•°é‡ / DU | 100 |
| ç”¨æˆ·æ•°é‡ / DU | 30 |
| åˆ†å¸ƒå¼å•å…ƒæ•°é‡ $N_g$ | 7 |
| ç”¨æˆ·ç§»åŠ¨é€Ÿåº¦ | 10â€“20 m/s |
| å­¦ä¹ ç‡ | $10^{-4}$ |
| æŠ˜æ‰£å› å­ $\gamma$ | 0.99 |
| Batch Size | 128 |

### **è¯„ä¼°æŒ‡æ ‡**

| æŒ‡æ ‡ç±»åˆ« | å…·ä½“æŒ‡æ ‡ |
|--------|---------|
| **æ€§èƒ½æŒ‡æ ‡** | ç´¯è®¡å¥–åŠ±ï¼ˆCumulative Rewardï¼‰ã€ååé‡ã€å»¶è¿Ÿã€QoSæ»¡è¶³ç‡ |
| **æœåŠ¡è´¨é‡ï¼ˆQoSï¼‰** | - eMBBï¼šå¹³å‡ååé‡<br>- mMTCï¼šè®¾å¤‡è¿æ¥å¯†åº¦ä¸åååŠ æƒå®¹é‡<br>- URLLCï¼šæœ€å¤§ä¼ è¾“å»¶è¿Ÿ |
| **ç”¨æˆ·ä½“éªŒï¼ˆQoEï¼‰** | ç”¨æˆ·çº§ååé‡åˆ†å¸ƒï¼ˆCDFï¼‰ |
| **é€‚åº”æ€§** | ä¸åŒ shot æ•°ä¸‹çš„é€‚åº”æ€§èƒ½ï¼ˆ0, 5, 30 shotsï¼‰ |
| **å…¬å¹³æ€§** | Jainâ€™s Fairness Index |
| **å¯æ‰©å±•æ€§** | ä¸åŒ DU å’Œç”¨æˆ·è§„æ¨¡ä¸‹çš„æ”¶æ•›è¿­ä»£æ¬¡æ•°ä¸å½’ä¸€åŒ–å¥–åŠ± |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

- **DRL**ï¼šä»é›¶å¼€å§‹è®­ç»ƒçš„æ ‡å‡†æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼›
- **Transfer Learning (TL)**ï¼šå°†å·²æœ‰ç­–ç•¥è¿ç§»åˆ°æ–°ä»»åŠ¡ï¼›
- **Multi-Task Learning (MTL)**ï¼šè”åˆè®­ç»ƒå¤šä¸ªä»»åŠ¡ï¼›
- **MAML-RL**ï¼šåŸå§‹å…ƒå¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼ˆæ— å±‚æ¬¡ç»“æ„ï¼‰ï¼›
- **Uniform-Meta**ï¼šç­‰æƒå…ƒæ›´æ–°ï¼ˆç”¨äºæ¶ˆèå®éªŒï¼‰ï¼›
- **Static-Var**ï¼šå›ºå®šæ–¹å·®åŠ æƒï¼ˆéè‡ªé€‚åº”ï¼‰ï¼›

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **æœ€ç»ˆç´¯è®¡å›æŠ¥æå‡** | ç›¸æ¯”åŸºçº¿æ–¹æ³•æé«˜ **19.8%**ï¼ˆå›¾4ï¼‰ |
| **é€‚åº”é€Ÿåº¦æå‡** | æœ€å¤šå¿« **40%**ï¼ˆä»…éœ€17æ¬¡adaptation shotså³æ”¶æ•›ï¼‰ |
| **QoSæ»¡æ„åº¦** | åœ¨ eMBBã€URLLCã€mMTC ä¸‰ç±»åˆ‡ç‰‡ä¸­å‡æ˜¾è‘—ä¼˜äºåŸºçº¿ |
| **å½’ä¸€åŒ–å¥–åŠ±ç¨³å®šæ€§** | å³ä½¿æ‰©å±•åˆ° 30 DU / 200 ç”¨æˆ·ï¼Œæ€§èƒ½ä¸‹é™ < 2%ï¼ˆè¡¨2ï¼‰ |

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- **å›¾4ï¼ˆç´¯è®¡å¥–åŠ±ï¼‰**ï¼š
  - Adaptive MAML-HRL æ˜æ˜¾é¢†å…ˆï¼Œæ¯”æ™®é€š MAML-HRL é«˜çº¦ 4%ï¼Œæ¯” DRL é«˜è¾¾ 73%ï¼›
  - DRL æ”¶æ•›æœ€æ…¢ï¼Œä¸”æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚

- **å›¾6 & å›¾7ï¼ˆQoS ä¸ç”¨æˆ·ååé‡ CDFï¼‰**ï¼š
  - åœ¨æ‰€æœ‰ä¸‰ç§åˆ‡ç‰‡ä¸­ï¼Œæ‰€ææ–¹æ³•åœ¨é«˜ç™¾åˆ†ä½è¡¨ç°æœ€ä½³ï¼›
  - ç‰¹åˆ«æ˜¯åœ¨ **mMTC** åœºæ™¯ä¸‹ï¼Œé€šè¿‡è‡ªé€‚åº”åŠ æƒæœºåˆ¶æœ‰æ•ˆæå‡äº†å¯†é›†è¿æ¥åœºæ™¯ä¸‹çš„ååä¿éšœã€‚

- **å›¾8ï¼ˆé€‚åº”æ€§èƒ½ vs Shot æ•°ï¼‰**ï¼š
  - éšç€ adaptation shots å¢åŠ ï¼ŒAdaptive MAML-HRL æå‡æœ€å¿«ï¼›
  - åœ¨ä»… 5-shot åœºæ™¯ä¸‹å·²æ¥è¿‘æœ€ä¼˜æ€§èƒ½ï¼Œé€‚åˆå®æ—¶éƒ¨ç½²ã€‚

- **å›¾9ï¼ˆæ–°ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ï¼‰**ï¼š
  - åœ¨ä¸‰ä¸ªå…¨æ–°ä»»åŠ¡ä¸­ï¼ŒAdaptive MAML-HRL å§‹ç»ˆä¿æŒæœ€é«˜ QoS è¡¨ç°ï¼›
  - TL å’Œ MTL æ³›åŒ–èƒ½åŠ›æœ‰é™ï¼Œå°¤å…¶åœ¨ URLLC ä½å»¶è¿Ÿè¦æ±‚ä¸‹å¤±æ•ˆæ˜æ˜¾ã€‚

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼Œè§ Table 3ï¼‰**

| æ–¹æ³• | å½’ä¸€åŒ–å¥–åŠ± | æ”¶æ•›æ‰€éœ€ shots |
|------|------------|----------------|
| Uniform-Metaï¼ˆå‡åŒ€åŠ æƒï¼‰ | 0.78 | 28 |
| Static-Varï¼ˆé™æ€æ–¹å·®åŠ æƒï¼‰ | 0.81 | 22 |
| **Adaptive-Varï¼ˆæœ¬æ–‡æ–¹æ³•ï¼‰** | **0.84** | **17** |

> âœ… è‡ªé€‚åº”åŠ æƒæœºåˆ¶å¸¦æ¥çº¦ **3% çš„å¥–åŠ±å¢ç›Š** å’Œ **40% çš„åŠ é€Ÿæ”¶æ•›**ã€‚

æ­¤å¤–ï¼Œåœ¨æ‰©å±•æŒ‡æ ‡ä¸Šä¹Ÿè¡¨ç°å‡ºè‰²ï¼š
- å¹³å‡æ—¶å»¶é™ä½ **9.2%**ï¼›
- Jain å…¬å¹³æ€§æŒ‡æ•°ä» 0.91 æå‡è‡³ **0.96**ï¼›
- åœ¨ 50% æµé‡æ¿€å¢åœºæ™¯ä¸‹ï¼Œæ€§èƒ½é€€åŒ– < **5%**ï¼Œä½“ç°å¼ºé²æ£’æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **Meta-HRL æ¶æ„æ˜¾è‘—æå‡ O-RAN èµ„æºç®¡ç†æ•ˆç‡**  
   ç»“åˆ HRL çš„ç»“æ„ä¼˜åŠ¿ä¸ Meta-RL çš„å¿«é€Ÿé€‚åº”èƒ½åŠ›ï¼Œå®ç°äº†é«˜æ•ˆã€çµæ´»ã€å¯æ‰©å±•çš„æ™ºèƒ½èµ„æºè°ƒåº¦ã€‚

2. **è‡ªé€‚åº”åŠ æƒæœºåˆ¶æ˜¯æ€§èƒ½æå‡çš„å…³é”®**  
   åˆ©ç”¨ TD-error æ–¹å·®åŠ¨æ€è°ƒèŠ‚ä»»åŠ¡é‡è¦æ€§ï¼Œä½¿å¾—æ¨¡å‹æ›´ä¸“æ³¨äºå¤æ‚ã€é«˜å˜å¼‚æ€§åœºæ™¯ï¼ˆå¦‚ mMTC å¯†é›†æ¥å…¥ï¼‰ï¼Œé¿å…è¢«ç®€å•ä»»åŠ¡ä¸»å¯¼ã€‚

3. **å…·å¤‡è‰¯å¥½çš„å¯æ‰©å±•æ€§ä¸ç¨³å®šæ€§**  
   å³ä½¿åœ¨ç½‘ç»œè§„æ¨¡æ‰©å¤§ï¼ˆ30 DU, 200 UEï¼‰æ—¶ï¼Œä»èƒ½ä¿æŒè¿‘ä¼¼æ’å®šçš„å½’ä¸€åŒ–æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶é€‚ç”¨äºå¤§å‹å®é™…éƒ¨ç½²ã€‚

4. **ç†è®ºåˆ†ææ”¯æŒå®è·µæ•ˆæœ**  
   è®ºæ–‡æä¾›äº†ä¸¥æ ¼çš„æ”¶æ•›æ€§åˆ†æå’Œåæ‚”ç•Œè¯æ˜ï¼Œè¡¨æ˜è¯¥ç®—æ³•åœ¨ä¸¤æ—¶é—´å°ºåº¦ä¸‹å…·æœ‰ **sublinear convergence** å’Œ **bounded regret**ï¼Œå¢å¼ºäº†å¯ä¿¡åº¦ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

- å½“å‰å®éªŒåŸºäºä»¿çœŸç¯å¢ƒï¼Œå°šæœªåœ¨çœŸå® O-RAN testbed ä¸ŠéªŒè¯ï¼ˆå—é™äºç¡¬ä»¶å¹³å°æˆç†Ÿåº¦ï¼‰ï¼›
- å…ƒæ›´æ–°é€šä¿¡å¼€é”€è™½å°ï¼ˆä»…äº¤æ¢ç½‘ç»œå‚æ•°ï¼‰ï¼Œä½†åœ¨è¶…å¤§è§„æ¨¡éƒ¨ç½²ä¸­ä»éœ€è¿›ä¸€æ­¥ä¼˜åŒ–ï¼›
- å¯¹æç«¯éå¹³ç¨³ç¯å¢ƒï¼ˆå¦‚é¢‘ç¹æ‹“æ‰‘å˜æ›´ï¼‰çš„é•¿æœŸç¨³å®šæ€§æœ‰å¾…æ·±å…¥ç ”ç©¶ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

- åœ¨ **OAI** æˆ– **srsRAN** ç­‰å¼€æºå¹³å°ä¸Šå®ç°åŸå‹ç³»ç»Ÿï¼Œå¼€å±• **Hardware-in-the-loop éªŒè¯**ï¼›
- æ¢ç´¢ **é€šä¿¡é«˜æ•ˆçš„å…ƒå‚æ•°æ›´æ–°æœºåˆ¶**ï¼ˆå¦‚é‡åŒ–ã€ç¨€ç–åŒ–ï¼‰ï¼›
- æ‰©å±•è‡³ **multi-hop ç½‘ç»œ** å’Œ **UAV-assisted 6G åœºæ™¯**ï¼›
- å¼•å…¥ **å› æœæ¨ç†** æˆ– **world model** æ¥å¢å¼ºé¢„æµ‹èƒ½åŠ›å’ŒæŠ—å¹²æ‰°æ€§ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡ºçš„ **Adaptive Meta-HRL** æ¡†æ¶ï¼Œé€šè¿‡èåˆ **åˆ†å±‚æ§åˆ¶** ä¸ **åŸºäº TD-error æ–¹å·®çš„è‡ªé€‚åº”å…ƒå­¦ä¹ **ï¼Œä¸º O-RAN æä¾›äº†ä¸€ä¸ªé«˜æ•ˆã€å¿«é€Ÿé€‚åº”ã€å¯æ‰©å±•ä¸”ç†è®ºå¯é çš„èµ„æºç®¡ç†è§£å†³æ–¹æ¡ˆï¼Œåœ¨å¤šé¡¹æŒ‡æ ‡ä¸Šå…¨é¢è¶…è¶Šç°æœ‰æ–¹æ³•ã€‚

</details>

---

### 4. [Sparse Multi-Modal Transformer with Masking for Alzheimer's Disease Classification](https://arxiv.org/abs/2512.14491)

**Authors**: Cheng-Han Lu, Pei-Hsuan Tsai  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.14491v1  

#### Abstract
Transformer-based multi-modal intelligent systems often suffer from high computational and energy costs due to dense self-attention, limiting their scalability under resource constraints. This paper presents SMMT, a sparse multi-modal transformer architecture designed to improve efficiency and robus...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSparse Multi-Modal Transformer with Masking for Alzheimer's Disease Classification

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹å½“å‰åŸºäº Transformer çš„å¤šæ¨¡æ€æ™ºèƒ½ç³»ç»Ÿåœ¨é˜¿å°”èŒ¨æµ·é»˜ç—…ï¼ˆAlzheimer's Disease, ADï¼‰åˆ†ç±»ä»»åŠ¡ä¸­é¢ä¸´çš„ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼š
- **é«˜è®¡ç®—ä¸èƒ½è€—æˆæœ¬**ï¼šç”±äºæ ‡å‡† Transformer ä½¿ç”¨ dense self-attentionï¼Œå¯¼è‡´æ—¶é—´å¤æ‚åº¦ä¸º $O(n^2)$ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹æ‰©å±•ã€‚
- **å¯¹ä¸å®Œæ•´è¾“å…¥æ•æ„Ÿ**ï¼šä¸´åºŠæ•°æ®å¸¸å­˜åœ¨ç¼ºå¤±æ¨¡æ€ï¼ˆmissing modalitiesï¼‰ï¼Œè€Œç°æœ‰æ¨¡å‹ç¼ºä¹æ˜¾å¼æœºåˆ¶æ¥å¤„ç†æ­¤ç±»æƒ…å†µï¼Œå½±å“å®é™…éƒ¨ç½²ä¸­çš„é²æ£’æ€§ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šSMMT
ä½œè€…æå‡º **Sparse Multi-Modal Transformer with Masking (SMMT)**ï¼Œä¸€ç§ä»ç³»ç»Ÿå±‚é¢è®¾è®¡çš„é«˜æ•ˆã€é²æ£’çš„å¤šæ¨¡æ€èåˆæ¶æ„ï¼Œå…¶ä¸¤å¤§æ ¸å¿ƒåˆ›æ–°ä¸ºï¼š

#### ï¼ˆ1ï¼‰Cluster-based Sparse Attention
- å°† tokens æŒ‰ query å‘é‡è¿›è¡Œ K-Means èšç±»ï¼ˆç°‡æ•° $k = \log_2 n$ï¼‰
- è‡ªæ³¨æ„åŠ›ä»…åœ¨æ¯ä¸ª cluster å†…éƒ¨è®¡ç®—ï¼Œå°†è®¡ç®—å¤æ‚åº¦ä» $O(n^2)$ é™ä½è‡³ $O(n \log n)$
- åœ¨ä¿æŒè¡¨å¾èƒ½åŠ›çš„åŒæ—¶æ˜¾è‘—å‡å°‘å†…å­˜å ç”¨å’Œè®¡ç®—å¼€é”€

#### ï¼ˆ2ï¼‰Modality-wise Masking
- åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹å„æ¨¡æ€ç‰¹å¾éšæœºæ–½åŠ äºŒå€¼æ©ç ï¼ˆmasking ratio $r=0.3$ï¼‰
- æ¨¡æ‹ŸçœŸå®åœºæ™¯ä¸‹çš„æ¨¡æ€ç¼ºå¤±ï¼Œæå‡æ¨¡å‹å¯¹ incomplete inputs çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§
- å±äºä¸€ç§æ­£åˆ™åŒ–ç­–ç•¥ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œå°¤å…¶é€‚ç”¨äºå°æ ·æœ¬åœºæ™¯

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ•ˆç‡** | æ˜¾è‘—é™ä½è®­ç»ƒæ—¶é—´å’Œèƒ½æºæ¶ˆè€—ï¼ˆæ€»èƒ½è€—ä¸‹é™ 40.4%ï¼‰ |
| **é²æ£’æ€§** | å¯¹ç¼ºå¤±æ¨¡æ€æ›´å…·å®¹å¿æ€§ï¼Œåœ¨ä½æ•°æ®æ¡ä»¶ä¸‹ä»è¡¨ç°ä¼˜å¼‚ |
| **å¯æ‰©å±•æ€§** | æ”¯æŒæ›´å¤§åºåˆ—é•¿åº¦è¾“å…¥ï¼Œé€‚åˆå¤§è§„æ¨¡åŒ»ç–—æ•°æ®åˆ†æ |
| **å¯æŒç»­æ€§** | å‡å°‘ç¢³æ’æ”¾ï¼Œç¬¦åˆç»¿è‰² AI å‘å±•è¶‹åŠ¿ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä½¿ç”¨ **ADNI-1 å’Œ ADNI-2** æ•°æ®é›†ä½œä¸ºç ”ç©¶å¯¹è±¡
- åŒ…å«å¤šæ¨¡æ€æ•°æ®ï¼š
  - **Imaging**: T1-weighted MRI åˆ‡ç‰‡ï¼ˆé¢„å¤„ç†åä¸º 256Ã—256 RGB å›¾åƒï¼‰
  - **Clinical Scores**: MMSE, CDR, FAQ, å¹´é¾„ç­‰æ•°å€¼å‹å˜é‡
  - **Categorical Data**: APOE åŸºå› å‹ã€æ€§åˆ«ç­‰ç±»åˆ«å˜é‡
- æœ€ç»ˆä¿ç•™ AD ä¸ CN ç±»åˆ«å…± 12,680 å¼  MRI åˆ‡ç‰‡ç”¨äºè®­ç»ƒä¸è¯„ä¼°
- æ’é™¤ MCI æ ·æœ¬ä»¥é¿å…ç±»åˆ«ä¸å¹³è¡¡åŠä»»åŠ¡å¤æ‚åŒ–

### å®éªŒè®¾ç½®
- **æ¡†æ¶**ï¼šPyTorch
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA GeForce RTX 3060 GPUï¼ˆ12GBï¼‰
- **è¶…å‚æ•°**ï¼š
  - Batch Size: 8
  - Epochs: 50ï¼ˆäº”æŠ˜äº¤å‰éªŒè¯å…± 250 epochsï¼‰
  - Optimizer: Adam ($\text{lr} = 1\times10^{-3}$)
  - Latent Dimension: 512
  - Masking Ratio: 0.3ï¼ˆmodality-level éšæœº maskingï¼‰

### è¯„ä¼°æŒ‡æ ‡

#### åˆ†ç±»æ€§èƒ½æŒ‡æ ‡
- Accuracy, Precision, Recall (Sensitivity), F1-score
- Specificity, AUCï¼ˆROC æ›²çº¿ä¸‹é¢ç§¯ï¼‰

#### è®¡ç®—å¯æŒç»­æ€§æŒ‡æ ‡
- **Energy Consumption**ï¼ˆé€šè¿‡ CodeCarbon å·¥å…·ç›‘æ§ CPU/GPU/RAM åŠŸè€—ä¼°ç®—ï¼‰
- **COâ‚‚ Emissions**ï¼šåŸºäºå°æ¹¾ç”µç½‘ç¢³å¼ºåº¦ï¼ˆ0.502 kgCOâ‚‚/kWhï¼‰æ¢ç®—
- **Training Time**ï¼ˆåˆ†é’Ÿï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ¨¡å‹ | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **3MT [8]** | Transformer-based Hybrid Fusion | å½“å‰ SOTA å¤šæ¨¡æ€ AD åˆ†ç±»å™¨ï¼Œé‡‡ç”¨çº§è” cross-attention |
| **ADDFformer [20]** | Imaging-only Transformer | åŸºäºç»“æ„ MRI çš„å•æ¨¡æ€è¯Šæ–­æ¨¡å‹ |
| **FusionNet [21]** | General Multi-modal Fusion | éæ³¨æ„åŠ›æœºåˆ¶çš„é€šç”¨èåˆç½‘ç»œ |
| **CNN-only [22]** | Single-modality CNN | å¦‚ VGG16ï¼Œä»…ä½¿ç”¨ MRI è¾“å…¥ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆ100% æ•°æ®ï¼‰

| æ¨¡å‹ | Accuracy (%) | Sensitivity (%) | Specificity (%) | AUC |
|------|--------------|------------------|------------------|-----|
| CNN-only [22] | 80.24 | 78.45 | 80.22 | 0.852 |
| FusionNet [21] | 94.28 | 91.01 | 93.24 | 0.956 |
| ADDFformer [20] | 88.20 | 91.87 | 91.53 | 0.948 |
| 3MT (Baseline) [8] | 90.28 | 93.64 | 93.81 | 0.965 |
| **SMMT (Ours)** | **97.05** | **96.31** | **97.58** | **0.986** |

> âœ… SMMT åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡è¾¾åˆ°æœ€ä¼˜ï¼Œå°¤å…¶åœ¨ AUC ä¸Šæ¥è¿‘ 0.99ï¼Œè¡¨ç°å‡ºæå¼ºçš„åˆ¤åˆ«èƒ½åŠ›ã€‚

### ä¸åŒæ•°æ®è§„æ¨¡ä¸‹çš„å‡†ç¡®æ€§æ¯”è¾ƒ

| Dataset Size | SMMT | 3MT | ADDFformer | FusionNet | CNN-only |
|-------------|-------|------|------------|-----------|----------|
| 100%        | **97.05** | 90.28 | 88.20      | 94.28     | 80.24    |
| 80%         | **94.20** | 87.12 | 83.82      | 86.37     | 77.27    |
| 60%         | **91.28** | 86.25 | 77.58      | 79.25     | 70.57    |
| 40%         | **86.52** | 82.17 | 74.20      | 76.83     | 70.55    |
| **20%**     | **84.96** | 78.92 | 71.92      | 75.15     | 68.53    |

> ğŸ” SMMT åœ¨ä½æ•°æ®æ¡ä»¶ä¸‹ï¼ˆå¦‚ 20%ï¼‰ä¾ç„¶ä¿æŒ 84.96% çš„å‡†ç¡®ç‡ï¼Œè¿œè¶…å…¶ä»–æ¨¡å‹ï¼Œä½“ç°å…¶å“è¶Šçš„æ•°æ®æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚

### è®­ç»ƒæ•ˆç‡ä¸èƒ½è€—å¯¹æ¯”

#### æ€»ä½“èƒ½è€—ï¼ˆ250 epochsï¼‰
| Component | 3MT (kWh) | SMMT (kWh) | Reduction |
|---------|-----------|------------|-----------|
| CPU     | 0.108489  | 0.071179   | 34.4%     |
| GPU     | 0.283977  | 0.159642   | 43.8%     |
| RAM     | 0.051035  | 0.033485   | 34.4%     |
| **Total** | **0.443501** | **0.264306** | **â†“40.4%** |

#### ç¢³æ’æ”¾ï¼ˆCOâ‚‚ï¼‰
- 3MT: 0.2226 kgCOâ‚‚
- SMMT: **0.1327 kgCOâ‚‚** â†’ **å‡å°‘ 40.3%**
- ç›¸å½“äºèŠ‚çœçº¦ 18 æ¬¡æ™ºèƒ½æ‰‹æœºå……ç”µæˆ–ç‚¹äº® 60W ç¯æ³¡è¶…è¿‡ 30 å°æ—¶

#### è®­ç»ƒæ—¶é—´ï¼ˆ100% æ•°æ®ï¼‰
- SMMT: **112 åˆ†é’Ÿ**
- 3MT: 133 åˆ†é’Ÿ
- CNN-only (VGG16): >140 åˆ†é’Ÿï¼ˆæœ€æ…¢ï¼‰

> âš¡ SMMT æ˜¯å”¯ä¸€åŒæ—¶å®ç°æ›´é«˜ç²¾åº¦ä¸æ›´ä½è®­ç»ƒæ—¶é—´/èƒ½è€—çš„æ¨¡å‹ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

| é…ç½® | 100% Acc / Time(min) | 20% Acc / Time(min) |
|------|------------------------|----------------------|
| 3MT (Baseline) | 90.28 / 133 | 78.92 / 41 |
| w/o Sparse Attention | 91.35 / 147 | 84.85 / 51 |
| w/o Masking | 95.42 / 108 | 80.85 / 37 |
| **SMMT (Full)** | **97.05 / 112** | **84.96 / 45** |

#### å…³é”®å‘ç°ï¼š
- **ç§»é™¤ Sparse Attention**ï¼šè®­ç»ƒæ—¶é—´å¤§å¹…å¢åŠ ï¼ˆâ†‘38%ï¼‰ï¼Œä½†ç²¾åº¦ç•¥æœ‰ä¸‹é™ â†’ è¡¨æ˜ç¨€ç–æ³¨æ„åŠ›ä¸ä»…ææ•ˆï¼Œè¿˜å¯èƒ½èµ·éšå¼æ­£åˆ™åŒ–ä½œç”¨
- **ç§»é™¤ Masking**ï¼šè®­ç»ƒæ›´å¿«ï¼Œä½†åœ¨ä½æ•°æ®ä¸‹ç²¾åº¦æ˜æ˜¾ä¸‹é™ï¼ˆ20% æ—¶ â†“4.11%ï¼‰â†’ è¯æ˜ masking å¯¹æå‡é²æ£’æ€§å’Œæ³›åŒ–è‡³å…³é‡è¦
- **ä¸¤è€…ç»“åˆ**ï¼šå®ç°æœ€ä½³å¹³è¡¡â€”â€”é«˜æ•ˆ + é«˜æ€§èƒ½ + å¼ºé²æ£’æ€§

æ­¤å¤–ï¼Œmasking ratio çš„æ¶ˆèæ˜¾ç¤ºï¼š
- æœ€ä¼˜ $r = 0.3$
- å½“ $r > 0.6$ æ—¶æ€§èƒ½æ€¥å‰§ä¸‹é™ï¼Œè¯´æ˜è¿‡åº¦ masking ä¼šç ´åå…³é”®ä¿¡æ¯

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦ç»“è®º
1. **SMMT åœ¨ AD åˆ†ç±»ä»»åŠ¡ä¸­å®ç°äº† SOTA æ€§èƒ½**ï¼š
   - å…¨æ•°æ®ä¸‹è¾¾ **97.05% å‡†ç¡®ç‡**ï¼ŒAUC è¾¾ **0.986**
   - å³ä½¿ä»…ç”¨ 20% æ•°æ®ä¹Ÿèƒ½å–å¾— **84.96% å‡†ç¡®ç‡**

2. **æ˜¾è‘—æå‡è®¡ç®—æ•ˆç‡ä¸ç¯å¢ƒå¯æŒç»­æ€§**ï¼š
   - è®­ç»ƒèƒ½è€—é™ä½ **40.4%**
   - ç¢³æ’æ”¾å‡å°‘ **40.3%**
   - æ›´ç¨³å®šã€æ›´å¯é¢„æµ‹çš„ç¡¬ä»¶èµ„æºåˆ©ç”¨

3. **å…·å¤‡æ›´å¼ºçš„ç°å®é€‚ç”¨æ€§**ï¼š
   - é€šè¿‡ modality-wise masking æ˜¾å¼å»ºæ¨¡ç¼ºå¤±æ¨¡æ€ï¼Œå¢å¼ºä¸´åºŠéƒ¨ç½²é²æ£’æ€§
   - é€‚ç”¨äºå°æ ·æœ¬ã€èµ„æºå—é™çš„çœŸå®åŒ»ç–—åœºæ™¯

4. **ç¨€ç–æ³¨æ„åŠ›å…·æœ‰åŒé‡æ”¶ç›Š**ï¼š
   - æ˜¾è‘—é™ä½è®¡ç®—è´Ÿæ‹…ï¼ˆ$O(n^2) \to O(n \log n)$ï¼‰
   - å¯èƒ½èµ·åˆ°ç±»ä¼¼ Dropout çš„æ­£åˆ™åŒ–æ•ˆæœï¼ŒæŠ‘åˆ¶å™ªå£°è¿æ¥

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä»…é™äº **binary classification (AD vs. CN)**ï¼Œæœªæ¶µç›– MCI æˆ–ç–¾ç—…è¿›å±•é˜¶æ®µé¢„æµ‹
- èšç±»ï¼ˆK-Meansï¼‰è™½è½»é‡ä½†ä»å¼•å…¥é¢å¤–è®¡ç®—ï¼Œä¸”ä¾èµ– GPU æ‰¹å¤„ç†ä¼˜åŒ–
- æ‰€æœ‰å®éªŒåŸºäº ADNI æ•°æ®é›†ï¼Œéœ€è¿›ä¸€æ­¥éªŒè¯åœ¨å…¶ä»–ä¸­å¿ƒæˆ–å¤šæ°‘æ—äººç¾¤ä¸­çš„æ³›åŒ–èƒ½åŠ›

### æœªæ¥å·¥ä½œæ–¹å‘
1. æ‰©å±•è‡³ **multi-class classification**ï¼Œçº³å…¥ MCI åŠ AD progression staging
2. å¼€å‘ **longitudinal modeling** èƒ½åŠ›ï¼Œæ”¯æŒæ—¶é—´åºåˆ—æ•°æ®é¢„æµ‹ç—…æƒ…æ¼”å˜
3. è®¾è®¡ **adaptive modality selection** æœºåˆ¶ï¼Œåœ¨æ¨ç†æ—¶åŠ¨æ€åº”å¯¹å¯å˜æ¨¡æ€è¾“å…¥
4. åœ¨æ›´å¤§ã€æ›´å¤šæ ·åŒ–çš„ä¸´åºŠé˜Ÿåˆ—ä¸­éªŒè¯ SMMT çš„æ™®é€‚æ€§ä¸ç¨³å®šæ€§
5. æ¢ç´¢å°†å…¶åº”ç”¨äº **Human Digital Twin** æ„å»ºä¸­çš„åŒ»å­¦è¡¨å¾å­¦ä¹ æ¨¡å—

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> SMMT æˆåŠŸåœ°å°† **sparse attention** ä¸ **masked learning** ç»“åˆï¼Œæ„å»ºäº†ä¸€ä¸ªæ—¢é«˜æ•ˆåˆé²æ£’çš„å¤šæ¨¡æ€ Transformer æ¶æ„ï¼Œåœ¨ä¿è¯ç”šè‡³è¶…è¶Š SOTA åˆ†ç±»æ€§èƒ½çš„åŒæ—¶ï¼Œå¤§å¹…é™ä½äº†è®­ç»ƒæˆæœ¬ä¸ç¢³è¶³è¿¹ï¼Œä¸ºå¯æŒç»­ã€å¯æ‰©å±•çš„åŒ»ç–— AI æä¾›äº†ä¸€ç§æå…·å‰æ™¯çš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 5. [PruneX: A Hierarchical Communication-Efficient System for Distributed CNN Training with Structured Pruning](https://arxiv.org/abs/2512.14628)

**Authors**: Alireza Olama, Andreas Lundell, Izzat El Hajj, Johan Lilius, Jerker Bj\"orkqvist  
**Category**: cs.DC  
**Published**: 2025-12-17  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.14628v1  

#### Abstract
Inter-node communication bandwidth increasingly constrains distributed training at scale on multi-node GPU clusters. While compact models are the ultimate deployment target, conventional pruning-aware distributed training systems typically fail to reduce communication overhead because unstructured s...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šPRUNEX: A Hierarchical Communication-Efficient System for Distributed CNN Training with Structured Pruning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨å¤§è§„æ¨¡å¤šèŠ‚ç‚¹ GPU é›†ç¾¤ä¸Šè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒæ—¶ï¼Œ**è·¨èŠ‚ç‚¹é€šä¿¡å¸¦å®½å·²æˆä¸ºä¸»è¦ç“¶é¢ˆ**ã€‚å°½ç®¡æ¨¡å‹å‹ç¼©ï¼ˆå¦‚å‰ªæï¼‰æ˜¯éƒ¨ç½²ç«¯çš„ç›®æ ‡ï¼Œä½†ç°æœ‰çš„å‰ªææ„ŸçŸ¥è®­ç»ƒç³»ç»Ÿé€šå¸¸æ— æ³•æœ‰æ•ˆå‡å°‘é€šä¿¡å¼€é”€ï¼ŒåŸå› åœ¨äºï¼š
- **éç»“æ„åŒ–ç¨€ç–æ€§ï¼ˆUnstructured Sparsityï¼‰** æ— æ³•è¢«é«˜åº¦ä¼˜åŒ–çš„ç¨ å¯†é›†åˆé€šä¿¡åŸè¯­ï¼ˆå¦‚ NCCL AllReduceï¼‰é«˜æ•ˆåˆ©ç”¨ï¼›
- ç°æœ‰æ–¹æ³•å¾€å¾€åœ¨å…¨å±€åŒæ­¥åå†æ‰§è¡Œå‰ªæï¼Œå¯¼è‡´ä»éœ€ä¼ è¾“å¤§é‡é›¶å€¼å‚æ•°å’Œç´¢å¼•å…ƒæ•°æ®ã€‚

æ­¤å¤–ï¼Œä¼ ç»Ÿæ¡†æ¶å°†é›†ç¾¤è§†ä¸ºæ‰å¹³æ‹“æ‰‘ï¼Œå¿½ç•¥äº†**èŠ‚ç‚¹å†…ï¼ˆintra-nodeï¼‰ä¸èŠ‚ç‚¹é—´ï¼ˆinter-nodeï¼‰é“¾è·¯å¸¦å®½çš„å·¨å¤§å·®å¼‚**ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

PRUNEX æå‡ºäº†ä¸€ç§**å±‚æ¬¡åŒ–ã€é€šä¿¡é«˜æ•ˆçš„åˆ†å¸ƒå¼ CNN è®­ç»ƒç³»ç»Ÿ**ï¼Œå…¶æ ¸å¿ƒæ˜¯ **H-SADMMï¼ˆHierarchical Structured ADMMï¼‰ç®—æ³•** å’Œé…å¥—çš„ç³»ç»Ÿæ¶æ„è®¾è®¡ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š

1. âœ… **H-SADMM ç®—æ³•ï¼šåœ¨èŠ‚ç‚¹çº§å¼ºåˆ¶ç»“æ„åŒ–ç¨€ç–**
   - å°† ADMM ä¼˜åŒ–æ¡†æ¶ä¸é›†ç¾¤ç‰©ç†æ‹“æ‰‘ç»“åˆï¼Œåœ¨**èŠ‚ç‚¹çº§å…±è¯†å˜é‡ï¼ˆnode-level consensusï¼‰ä¸Šæ–½åŠ ç»“æ„åŒ–ç¨€ç–çº¦æŸ**ï¼ˆå¦‚é€šé“/æ»¤æ³¢å™¨å‰ªæï¼‰ï¼Œä½¿å¾—ç¨€ç–åŒ–å‘ç”Ÿåœ¨è·¨èŠ‚ç‚¹é€šä¿¡ä¹‹å‰ã€‚
   - è¿™æ ·å¯ä»¥åœ¨åŒæ­¥å‰å°±â€œç‰©ç†ç¼©å°â€å¼ é‡å¤§å°ï¼Œé¿å…ä¼ è¾“å†—ä½™å‚æ•°ã€‚

2. âœ… **ç‰©ç†ç¼“å†²åŒºå‹ç¼©æœºåˆ¶ï¼ˆPhysical Buffer Shrinkageï¼‰**
   - åˆ©ç”¨å…¨å±€ä¸€è‡´çš„ç¨€ç–æ©ç ï¼ˆsparsity maskï¼‰ï¼Œå°†ç¨€ç–å¼ é‡å‹ç¼©ä¸º**è¿ç»­çš„ç¨ å¯†å°å—ç¼“å†²åŒº**è¿›è¡Œé€šä¿¡ã€‚
   - å®Œå…¨æ¶ˆé™¤ç¨€ç–æ ¼å¼å¸¦æ¥çš„**ç´¢å¼•å¼€é”€ï¼ˆmetadata overheadï¼‰**ï¼Œå¹¶å¯ç›´æ¥ä½¿ç”¨é«˜æ•ˆçš„ç¨ å¯†é›†åˆæ“ä½œï¼ˆå¦‚ AllReduceï¼‰ã€‚

3. âœ… **é¢†å¯¼è€…-è·Ÿéšè€…åˆ†å±‚æ¶æ„ï¼ˆLeader-Follower Architectureï¼‰**
   - æ„å»ºä¸¤ä¸ªç‹¬ç«‹çš„è¿›ç¨‹ç»„ï¼š
     - **Intra-node Group**ï¼šæ‰€æœ‰ worker å‚ä¸ï¼Œç”¨äºå¿«é€ŸåŒæ­¥èŠ‚ç‚¹å†…éƒ¨çŠ¶æ€ï¼›
     - **Inter-node Group**ï¼šä»…ç”±å„èŠ‚ç‚¹çš„ leaderï¼ˆrank 0ï¼‰ç»„æˆï¼Œè´Ÿè´£è·¨èŠ‚ç‚¹é€šä¿¡ã€‚
   - èŠ‚ç‚¹ leader æ‰®æ¼”â€œå‰ªæç½‘å…³â€è§’è‰²ï¼Œåœ¨å‘é€å‰å®ŒæˆæŠ•å½±ã€æ©ç åŒæ­¥å’Œç¼“å†²åŒºå‹ç¼©ã€‚

4. âœ… å¼€æºå®ç°
   - ä½œè€…å·²å°† PRUNEX å¼€æºï¼š[https://github.com/Alirezalm/PruneX](https://github.com/Alirezalm/PruneX)

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹æ³• | ç±»å‹ | æ˜¯å¦æ”¯æŒç»“æ„åŒ– | é€šä¿¡æ•ˆç‡ | æ¨ç†åŠ é€Ÿ | å±€é™æ€§ |
|------|------|----------------|-----------|------------|--------|
| Top-K / DGC | Unstructured | âŒ | ä¸­ä½ï¼ˆä¾èµ– AllGather/Gossipï¼‰ | âŒï¼ˆä¸è§„åˆ™å†…å­˜è®¿é—®ï¼‰ | ç¼–ç å¼€é”€å¤§ï¼Œéš¾ä»¥æé€Ÿ |
| PacTrain | Unstructured | âŒ | é«˜ï¼ˆæ‰“åŒ…ä¼ è¾“ï¼‰ | ä½ | ä»éœ€å¤„ç†ç¨€ç–ç´¢å¼• |
| PruneTrain | Structured | âœ… | ä¸­ç­‰ï¼ˆéœ€é‡æ–°é…ç½®ï¼‰ | âœ… | â€œStop-and-Reconfigureâ€ä¸­æ–­æµæ°´çº¿ |
| **PRUNEX (æœ¬æ–‡)** | **Structured** | âœ… | âœ…âœ…âœ… **é«˜ï¼ˆå‹ç¼©åç¨ å¯† AllReduceï¼‰** | âœ…âœ…âœ… **é«˜ï¼ˆçº¯ç¨ å¯† kernelï¼‰** | â€”â€” |

> PRUNEX å®ç°äº†**é€šä¿¡æ•ˆç‡ä¸è®¡ç®—æ•ˆç‡çš„åŒé‡æå‡**ï¼Œä¸”æ— éœ€ç‰ºç‰²è®­ç»ƒç¨³å®šæ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä½¿ç”¨ **CIFAR-10** æ•°æ®é›†ä½œä¸ºæ ‡å‡†å›¾åƒåˆ†ç±»ä»»åŠ¡åŸºå‡†ã€‚

### æ¨¡å‹æ¶æ„
è¯„ä¼°ä¸‰ç§ä¸»æµ CNN æ¨¡å‹ï¼š
| æ¨¡å‹ | å‚æ•°é‡ | GFLOPs |
|------|--------|--------|
| ResNet-18 | ~11M | 1.8 |
| WideResNet-50-2 | ~69M | 11.4 |
| ResNet-152 | ~60M | 11.3 |

å…¶ä¸­ ResNet-152 ä¸ºä¸»è¦åˆ†æå¯¹è±¡ã€‚

---

### å®éªŒå¹³å°
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼šèŠ¬å…° CSC çš„ **Puhti è¶…ç®—å¹³å°**
  - 16 ä¸ªèŠ‚ç‚¹ï¼Œå…± **64 å— NVIDIA V100 GPU**ï¼ˆæ¯èŠ‚ç‚¹ 4 å—ï¼‰
  - èŠ‚ç‚¹å†…é€šè¿‡ NVLink äº’è”ï¼ˆé«˜å¸¦å®½ï¼‰
  - èŠ‚ç‚¹é—´é€šè¿‡ Mellanox HDR InfiniBandï¼ˆ100 Gbpsï¼‰
- **è½¯ä»¶æ ˆ**ï¼š
  - PyTorch 2.9.1 + torch.distributed + NCCL 2.25.1

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | æè¿° |
|------|------|
| **PyTorch DDP (Dense Baseline)** | æ ‡å‡†çš„ç¨ å¯†åŒæ­¥ SGDï¼Œä½¿ç”¨ Ring-AllReduce |
| **Top-K SGD** | æ¯å±‚ä¿ç•™æ¢¯åº¦ç»å¯¹å€¼æœ€å¤§çš„ 1%ï¼Œå…¶ä½™ç½®é›¶ |
| **PruneX (AR)** | æ¶ˆèç‰ˆæœ¬ï¼Œé‡‡ç”¨æ‰å¹³å…±è¯†ç»“æ„ï¼ˆflat consensusï¼‰ï¼Œæ— å±‚çº§å‹ç¼© |

---

### è¯„ä¼°æŒ‡æ ‡
- **End-to-end æ—¶é—´åˆ°å‡†ç¡®ç‡ï¼ˆTime-to-Accuracyï¼‰**
- **ç´¯è®¡è·¨èŠ‚ç‚¹é€šä¿¡ä½“ç§¯ï¼ˆCommunication Volumeï¼‰**
- **æ¯è¿­ä»£é€šä¿¡å»¶è¿Ÿï¼ˆCommunication Latency per Iterationï¼‰**
- **å¼ºæ‰©å±•æ€§ï¼ˆStrong Scaling Speedup & Efficiencyï¼‰**
- **æ”¶æ•›æ€§åˆ†æï¼ˆPrimal/Dual Residualsï¼‰**
- **ç²¾åº¦-ç¨€ç–åº¦æƒè¡¡æ›²çº¿ï¼ˆSparsity-Accuracy Trade-offï¼‰**

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ğŸ”¹ é€šä¿¡ä½“ç§¯æ˜¾è‘—é™ä½
- åœ¨ ResNet-152 ä¸Šï¼Œæ€»è·¨èŠ‚ç‚¹é€šä¿¡é‡ä» DDP çš„ **13.00 GB** ä¸‹é™åˆ° **5.21 GB**ï¼Œ**å‡å°‘çº¦ 60%**ã€‚
- å…¶ä»–æ¨¡å‹ä¹Ÿä¿æŒä¸€è‡´æ”¶ç›Šï¼š
  - ResNet-18ï¼š2.53 GB â†’ 1.01 GB ï¼ˆâ†“60.1%ï¼‰
  - WideResNet-50-2ï¼š14.88 GB â†’ 5.97 GB ï¼ˆâ†“59.9%ï¼‰

> å›¾ 6 æ˜¾ç¤ºå‹ç¼©æ¶ˆæ¯å°ºå¯¸éš H-SADMM è¿­ä»£è¿…é€Ÿä¸‹é™å¹¶åœ¨ ~40% åŸå§‹å¤§å°ç¨³å®šã€‚

#### ğŸ”¹ é€šä¿¡å»¶è¿Ÿå¤§å¹…ç¼©çŸ­
- æ¯æ¬¡è¿­ä»£çš„é€šä¿¡æ—¶é—´ä» DDP çš„ **~0.50 ç§’**é™è‡³ PRUNEX çš„ **~0.10 ç§’**ï¼Œå®ç° **5Ã— åŒæ­¥é€Ÿåº¦æå‡**ã€‚
- åˆ†æè¡¨æ˜ï¼Œ**Inter-node AllReduce å æ€»é€šä¿¡æ—¶é—´çš„ 68.4%**ï¼Œæ­£æ˜¯ PRUNEX å‹ç¼©æ‰€é’ˆå¯¹çš„å…³é”®è·¯å¾„ï¼ˆå›¾ 8ï¼‰ã€‚

#### ğŸ”¹ å¼ºæ‰©å±•æ€§ä¼˜å¼‚
- åœ¨ 64 GPU ä¸Šï¼ŒPRUNEX å®ç° **6.75Ã— å¼ºæ‰©å±•åŠ é€Ÿæ¯”**ï¼Œè¿œè¶…ï¼š
  - DDP åŸºçº¿ï¼š5.81Ã—
  - Top-Kï¼š3.71Ã—
- å¹¶è¡Œæ•ˆç‡è¾¾ **84.4%**ï¼ˆDDP ä¸º 72.7%ï¼‰ï¼Œè¯´æ˜é€šä¿¡ç“¶é¢ˆå¾—åˆ°æœ‰æ•ˆç¼“è§£ã€‚

#### ğŸ”¹ æ›´å¿«è¾¾åˆ°ç›®æ ‡ç²¾åº¦
- PRUNEX åœ¨ **8 åˆ†é’Ÿå†…è¾¾åˆ° 70% å‡†ç¡®ç‡**ï¼Œè€Œ DDP åœ¨ 14 åˆ†é’Ÿå†…æœªèƒ½è¾¾åˆ°è¯¥æ°´å¹³ï¼ˆå›¾ 5aï¼‰ã€‚
- åœ¨ç›¸åŒé€šä¿¡é‡ä¸‹ï¼ŒPRUNEX è¾¾åˆ°æ›´é«˜ç²¾åº¦ï¼Œä½“ç°â€œ**Accuracy per Byte**â€ä¼˜åŠ¿ï¼ˆå›¾ 5bï¼‰ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ

| æ–¹æ³• | æ—¶é—´åˆ° 70% ç²¾åº¦ | æ€»é€šä¿¡é‡ | å¼ºæ‰©å±•åŠ é€Ÿæ¯”ï¼ˆ64 GPUï¼‰ |
|------|------------------|------------|----------------------------|
| DDPï¼ˆDenseï¼‰ | >14 minï¼ˆæœªè¾¾ï¼‰ | 60+ GB | 5.81Ã— |
| Top-K SGD | ~14 minï¼ˆä»… ~50% accï¼‰ | è¾ƒå°‘ä½†å™ªå£°å¤§ | 3.71Ã— |
| **PRUNEX (Hierarchical)** | **~8 min** | **~5.21 GB** | **6.75Ã—** |

> PRUNEX ä¸ä»…æ›´å¿«ï¼Œè€Œä¸”æœ€ç»ˆç²¾åº¦æ›´é«˜ï¼ˆæ¥è¿‘åŸå§‹æ¨¡å‹ï¼‰ï¼Œè¯æ˜å…¶å‰ªæè¿‡ç¨‹ä¸å½±å“æ¨¡å‹è¡¨è¾¾èƒ½åŠ›ã€‚

---

### æ¶ˆèå®éªŒç»“æœ

- **PruneX (AR)**ï¼ˆæ‰å¹³ç»“æ„ï¼‰è¡¨ç°å·®ï¼š
  - é€šä¿¡å»¶è¿Ÿæ³¢åŠ¨å¤§ï¼Œç¼ºä¹ä¸€è‡´æ€§ï¼›
  - æ— æ³•å®ç°ç¼“å†²åŒºå‹ç¼©ï¼ŒéªŒè¯äº†**å±‚æ¬¡åŒ–æ¶æ„æ˜¯å®ç°é«˜æ•ˆé€šä¿¡çš„å‰æ**ã€‚
- **Mask Freezing æœºåˆ¶**æœ‰æ•ˆï¼š
  - ç¨€ç–æ¨¡å¼åœ¨å‰ 5â€“15 æ¬¡è¿­ä»£è¶‹äºç¨³å®šï¼›
  - å†»ç»“åå¯é¢„åˆ†é…é€šä¿¡ç¼“å†²åŒºï¼Œè¿›ä¸€æ­¥å‡å°‘åŠ¨æ€å¼€é”€ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **ç»“æ„åŒ–å‰ªæå¿…é¡»å‰ç½®åˆ°é€šä¿¡ä¹‹å‰æ‰èƒ½çœŸæ­£èŠ‚çœå¸¦å®½**ï¼šPRUNEX é€šè¿‡ H-SADMM åœ¨èŠ‚ç‚¹çº§æ–½åŠ ç¨€ç–çº¦æŸï¼Œå®ç°äº†è¿™ä¸€ç‚¹ã€‚
2. âœ… **ç‰©ç†ç¼“å†²åŒºå‹ç¼©ä¼˜äºç¨€ç–ç¼–ç ä¼ è¾“**ï¼šå»é™¤ç´¢å¼•å¼€é”€åï¼Œå¯ç”¨æ ‡å‡†ç¨ å¯†é›†åˆåŸè¯­ï¼ˆAllReduceï¼‰è·å¾—æ›´é«˜ååã€‚
3. âœ… **å±‚æ¬¡åŒ–å…±è¯†ç»“æ„è‡³å…³é‡è¦**ï¼šåˆ†ç¦» intra-node å’Œ inter-node åŒæ­¥è·¯å¾„ï¼Œä½¿ç³»ç»Ÿèƒ½é’ˆå¯¹æ€§åœ°ä¼˜åŒ–æœ€æ…¢ç¯èŠ‚ï¼ˆå³è·¨èŠ‚ç‚¹é€šä¿¡ï¼‰ã€‚
4. âœ… **ç²¾åº¦æŸå¤±å¯æ§**ï¼šåœ¨ 50% é€šé“ç¨€ç–ç‡ä¸‹ï¼ŒResNet-152 ä»èƒ½è¾¾åˆ° 81.4% å‡†ç¡®ç‡ï¼ˆä»…æ¯”å®Œæ•´æ¨¡å‹ä½ ~4.6%ï¼‰ï¼Œä¸”å¯é€šè¿‡å¾®è°ƒæ¢å¤ã€‚
5. âœ… **æ”¶æ•›ç¨³å®š**ï¼šprimal/dual residuals å•è°ƒé€’å‡ï¼Œè¯æ˜ H-SADMM èƒ½æœ‰æ•ˆè¾¾æˆå…¨å±€å…±è¯†ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä¸»è¦é¢å‘ **CNN æ¶æ„**ï¼Œå¯¹ Transformer ç­‰ attention-based æ¨¡å‹å°šæœªéªŒè¯ï¼›
- ç»“æ„åŒ–å‰ªæå¯èƒ½é™åˆ¶çµæ´»æ€§ï¼Œä¸å¦‚éç»“æ„åŒ–å‰ªææè‡´å‹ç¼©ï¼›
- éœ€è¦é¢å¤–ç®¡ç†ç¨€ç–æ©ç å’ŒæŠ•å½±é€»è¾‘ï¼Œå¢åŠ å®ç°å¤æ‚åº¦ï¼›
- å¯¹ææ·±ç½‘ç»œçš„å±‚é—´å¼‚è´¨æ€§ä¾èµ– adaptive penalty tuningï¼Œè°ƒå‚æœ‰ä¸€å®šæŒ‘æˆ˜ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. ğŸš€ æ‰©å±•è‡³æ›´å¤§è§„æ¨¡æ¨¡å‹ï¼šå¦‚ Vision Transformers (ViTs) å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼›
2. ğŸš€ æ”¯æŒæ›´æ·±çš„å±‚æ¬¡ç»“æ„ï¼ˆå¦‚ rack-level aggregationï¼‰ï¼›
3. ğŸš€ åœ¨æ•°åƒ GPU è§„æ¨¡çš„é›†ç¾¤ä¸ŠéªŒè¯å…¶å¯æ‰©å±•æ€§ï¼›
4. ğŸš€ æ¢ç´¢ä¸å…¶ä»–å‹ç¼©æŠ€æœ¯ï¼ˆé‡åŒ–ã€ä½ç§©åˆ†è§£ï¼‰è”åˆä½¿ç”¨ï¼›
5. ğŸš€ è‡ªåŠ¨åŒ–ç¨€ç–ç‡è°ƒåº¦ç­–ç•¥ï¼Œæ›¿ä»£äººå·¥è®¾å®š `Tfreeze`ã€‚

---

## æ€»ç»“

PRUNEX æˆåŠŸå®ç°äº† **â€œç®—æ³•-ç³»ç»ŸååŒè®¾è®¡â€ï¼ˆco-designï¼‰**ï¼Œå°†ç»“æ„åŒ–å‰ªæä»ä¸€ä¸ªäº‹åå‹ç¼©æ‰‹æ®µè½¬å˜ä¸º**è´¯ç©¿è®­ç»ƒå…¨è¿‡ç¨‹çš„é€šä¿¡ä¼˜åŒ–å¼•æ“**ã€‚å®ƒä¸ä»…å‡å°‘äº†é€šä¿¡é‡ï¼Œè¿˜æå‡äº†è®¡ç®—æ•ˆç‡ï¼Œå¹¶åœ¨çœŸå®è¶…ç®—å¹³å°ä¸Šå±•ç°å‡ºå“è¶Šçš„æ‰©å±•æ€§å’Œç«¯åˆ°ç«¯æ€§èƒ½ï¼Œä¸ºæœªæ¥å¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒæä¾›äº†æ–°çš„èŒƒå¼ã€‚

</details>

---

### 6. [Variational Physics-Informed Ansatz for Reconstructing Hidden Interaction Networks from Steady States](https://arxiv.org/abs/2512.13708)

**Authors**: Kaiming Luo  
**Category**: cs.LG  
**Published**: 2025-12-17  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.13708v1  

#### Abstract
The interaction structure of a complex dynamical system governs its collective behavior, yet existing reconstruction methods struggle with nonlinear, heterogeneous, and higher-order couplings, especially when only steady states are observable. We propose a Variational Physics-Informed Ansatz (VPIA) ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šVariational Physics-Informed Ansatz for Reconstructing Hidden Interaction Networks from Steady States

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³**å¤æ‚åŠ¨åŠ›ç³»ç»Ÿä¸­éšè—äº¤äº’ç½‘ç»œçš„é‡æ„éš¾é¢˜**ï¼Œå°¤å…¶æ˜¯åœ¨ä»¥ä¸‹æŒ‘æˆ˜æ¡ä»¶ä¸‹ï¼š
- åªèƒ½è§‚æµ‹åˆ°ç³»ç»Ÿçš„**ç¨³æ€ï¼ˆsteady statesï¼‰**ï¼Œè€Œæ— æ³•è·å–æ—¶é—´åºåˆ—æˆ–å¯¼æ•°ä¿¡æ¯ï¼›
- ç³»ç»Ÿå…·æœ‰**éçº¿æ€§ã€å¼‚è´¨æ€§å’Œé«˜é˜¶è€¦åˆï¼ˆhigher-order couplingsï¼‰**ï¼›
- å­˜åœ¨æ˜¾è‘—çš„æµ‹é‡å™ªå£°ã€åŠ¨æ€å™ªå£°æˆ–ç»“æ„ä¸ç¡®å®šæ€§ï¼›
- ç½‘ç»œè§„æ¨¡å¤§ï¼Œä¼ ç»Ÿæ–¹æ³•è®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚

ç°æœ‰æ–¹æ³•å¦‚åŸºäºæ—¶é—´åºåˆ—çš„æ–¹æ³•ï¼ˆéœ€ä¼°è®¡å¯¼æ•°ï¼‰ã€ç»Ÿè®¡ç›¸å…³æ€§åˆ†æã€PINNsç­‰ï¼Œåœ¨ä¸Šè¿°åœºæ™¯ä¸‹è¡¨ç°å—é™ï¼Œå°¤å…¶éš¾ä»¥å¤„ç†é«˜é˜¶ã€æœ‰å‘ã€åŠ æƒä¸”ç¨ å¯†çš„ç½‘ç»œã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šVPIAï¼ˆVariational Physics-Informed Ansatzï¼‰

ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **Variational Physics-Informed Ansatz (VPIA)** çš„æ–°æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å°†æœªçŸ¥çš„**äº¤äº’ç®—å­ï¼ˆinteraction operatorï¼‰** è¡¨ç¤ºä¸ºä¸€ä¸ªå¯è®­ç»ƒçš„å˜åˆ†å¯¹è±¡ï¼ˆvariational representationï¼‰ï¼›
- åˆ©ç”¨ç‰©ç†é©±åŠ¨çš„**ç¨³æ€æ®‹å·®ï¼ˆsteady-state residualï¼‰** ä½œä¸ºä¼˜åŒ–ç›®æ ‡ï¼Œç›´æ¥ä»å¤šä¸ªå¼‚æ„ç¨³æ€æ•°æ®ä¸­æ¨æ–­ç½‘ç»œç»“æ„ï¼›
- ä¸ä¾èµ–æ—¶é—´è½¨è¿¹ã€å¯¼æ•°ä¼°è®¡æˆ–ç›‘ç£æ ‡ç­¾ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹ï¼š
1. **ç‰©ç†çº¦æŸåµŒå…¥çš„å˜åˆ†è¡¨ç¤ºæ³•**  
   - æ¯ä¸ªå€™é€‰äº¤äº’ï¼ˆåŒ…æ‹¬æˆå¯¹ã€æœ‰å‘ã€é«˜é˜¶simplexï¼‰è¢«èµ‹äºˆä¸€ä¸ªå¯å­¦ä¹ å‚æ•°ï¼Œé€šè¿‡sigmoidæ˜ å°„ä¿è¯å¯å¾®æ€§å’Œæ‹“æ‰‘å¯è§£é‡Šæ€§ï¼›
   - æ”¯æŒç»Ÿä¸€å»ºæ¨¡ undirected/directed/weighted/higher-order interactionsã€‚

2. **æ— éœ€æ—¶é—´æ•°æ®çš„é€†ç®—ç¬¦å­¦ä¹ ï¼ˆinverse operator learningï¼‰**  
   - åŒºåˆ«äºä¼ ç»ŸPINNsç”¨äºæ±‚è§£PDEæˆ–å‚æ•°åæ¼”ï¼ŒVPIAå°†æ•´ä¸ª**äº¤äº’ç»“æ„è§†ä¸ºæœªçŸ¥ç®—ç¬¦è¿›è¡Œå­¦ä¹ **ï¼Œå±äºæ›´å¹¿ä¹‰çš„â€œç‰©ç†ä¿¡æ¯ç®—ç¬¦å‘ç°â€ã€‚

3. **å¯æ‰©å±•çš„å­¦ä¹ æœºåˆ¶ï¼šæ®‹å·®é‡‡æ · + è‡ªç„¶æ¢¯åº¦ä¼˜åŒ–**
   - **Residual Sampling**ï¼šæ¯æ¬¡è¿­ä»£ä»…éšæœºé‡‡æ ·éƒ¨åˆ†èŠ‚ç‚¹æ®‹å·®ï¼Œä½¿æ¯æ­¥è®¡ç®—å¤æ‚åº¦ç”± $O(N^2)$ é™è‡³æ¥è¿‘ $O(N)$ï¼›
   - **Natural Gradient Updates**ï¼šåˆ©ç”¨Fisherä¿¡æ¯çŸ©é˜µçš„å¯¹è§’è¿‘ä¼¼è¿›è¡Œæ›²ç‡æ„ŸçŸ¥æ›´æ–°ï¼Œæå‡é«˜ç»´ç—…æ€å‚æ•°ç©ºé—´ä¸­çš„æ”¶æ•›ç¨³å®šæ€§ã€‚

4. **é€‚ç”¨äºé«˜é˜¶ç½‘ç»œï¼ˆsimplicial complexes / hypergraphsï¼‰**
   - ä½¿ç”¨å¼ é‡å½¢å¼ç¼–ç 2-simplexï¼ˆä¸‰è§’å½¢ï¼‰ã€3-simplexï¼ˆå››é¢ä½“ï¼‰ç­‰å¤šä½“ç›¸äº’ä½œç”¨ï¼›
   - åœ¨æ— å…ˆéªŒå‡è®¾çš„æƒ…å†µä¸‹è”åˆæ¢å¤ä¸åŒé˜¶æ¬¡çš„è€¦åˆç»“æ„ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | VPIAä¼˜åŠ¿ |
|------|---------|
| **æ•°æ®éœ€æ±‚** | ä»…éœ€ç¨³æ€å¿«ç…§ï¼Œæ— éœ€æ—¶é—´åºåˆ—æˆ–å¯¼æ•°ä¼°è®¡ |
| **æ¨¡å‹é€šç”¨æ€§** | é€‚ç”¨äºå¤šç§åŠ¨åŠ›å­¦ç³»ç»Ÿï¼ˆKuramoto, FitzHugh-Nagumo, Lorenzç­‰ï¼‰ï¼Œä¸ä¾èµ–å…·ä½“æ–¹ç¨‹å½¢å¼ |
| **é²æ£’æ€§** | å¯¹observation/dynamical/structural noiseå‡è¡¨ç°å‡ºå¼ºå¥æ€§ |
| **å¯æ‰©å±•æ€§** | æ”¯æŒä¸ŠåƒèŠ‚ç‚¹çš„å¤§è§„æ¨¡ç½‘ç»œé‡å»ºï¼ˆå¦‚Human Brain Network, N=989ï¼‰ |
| **è¡¨è¾¾èƒ½åŠ›** | èƒ½åŒæ—¶è¯†åˆ«æœ‰å‘ã€åŠ æƒã€ç¨€ç–/ç¨ å¯†åŠé«˜é˜¶äº¤äº’ç»“æ„ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
å®éªŒæ¶µç›–ä¸¤ç±»æ•°æ®ï¼š

#### ï¼ˆ1ï¼‰äººå·¥ç”Ÿæˆç½‘ç»œï¼ˆSynthetic Networksï¼‰
- **ErdÅ‘sâ€“RÃ©nyi éšæœºå›¾**ï¼ˆ$G(N,p)$ï¼Œ$p=0.5$ï¼‰ï¼Œç”¨äºæ§åˆ¶å˜é‡æµ‹è¯•ï¼›
- **é«˜é˜¶ç½‘ç»œ**ï¼šé€šè¿‡ç»„åˆæ‰€æœ‰å¯èƒ½çš„$k$-nodeå­é›†å¹¶ä»¥æ¦‚ç‡$p=0.5$ä¿ç•™ï¼Œæ„å»º2-/3-/4-simplexç»“æ„ï¼›
- åŠ¨åŠ›å­¦æ¨¡å‹åŒ…æ‹¬ï¼š
  - Phase oscillators: Kuramoto, Kuramoto-Sakaguchi
  - Limit-cycle: Stuart-Landau, Van der Pol, FitzHugh-Nagumo
  - Chaotic systems: RÃ¶ssler, Lorenz, Hindmarsh-Rose

#### ï¼ˆ2ï¼‰çœŸå®ä¸–ç•Œç½‘ç»œï¼ˆReal-world Networksï¼‰
æ¥è‡ªå…¬å¼€æ•°æ®åº“ [Network Data Repository](http://networkrepository.com/) å’Œæ–‡çŒ®å¼•ç”¨ï¼Œå…±8ä¸ªä»£è¡¨æ€§ç½‘ç»œï¼š

| ç½‘ç»œåç§° | ç±»å‹ | èŠ‚ç‚¹æ•° $N$ | è¾¹æ•° $E$ | å¯†åº¦ $\rho$ |
|--------|-----|-----------|----------|------------|
| Florentine Families | Undir | 16 | 20 | 0.1667 |
| Zachary Karate Club | Undir | 34 | 78 | 0.1390 |
| Wild Bird Social | Undir | 202 | 11733 | 0.5861 |
| C. elegans Neural | Dir | 297 | 2359 | 0.0259 |
| Power Grid | Undir | 494 | 596 | 0.0049 |
| Retweet Weibo | Dir | 596 | 1415 | 0.0080 |
| Human Brain Neural | Undir | 989 | 35730 | 0.036 |

---

### å®éªŒè®¾ç½®
- **ç¨³æ€ç”Ÿæˆ**ï¼šå¯¹æ¯ä¸ªå¤–éƒ¨æ¡ä»¶ $p^{(m)}$ åˆå§‹åŒ–éšæœºçŠ¶æ€ï¼Œæ•°å€¼ç§¯åˆ†è‡³æ»¡è¶³æ”¶æ•›å‡†åˆ™ $\|\dot{x}\|_2 < \epsilon$ï¼›
- **è¿‡æ»¤é€€åŒ–ç¨³æ€**ï¼šå‰”é™¤åŒæ­¥æˆ–ä½ç¦»æ•£åº¦é…ç½®ï¼Œä½¿ç”¨ $D(x^*) > \epsilon_{\text{sync}}$ï¼ˆå¦‚æ–¹å·®æˆ–å¹³å‡è·ç¦»ï¼‰ï¼›
- **æ ·æœ¬æ•°é‡**ï¼šé€šå¸¸å– $M = O(N)$ è‡³ $O(N \log N)$ ä¸ªç‹¬ç«‹ç¨³æ€å®éªŒï¼›
- **å™ªå£°æ³¨å…¥**ï¼š
  - **Observation noise**: $x^* \leftarrow x^* + \sigma_{\text{obs}} \cdot \text{MAD} \cdot \xi$
  - **Dynamical noise**: $\dot{x} = F(x, A) + \sigma_{\text{dyn}} \cdot \xi(t)$
  - **Structural noise**: $A_{ij} \leftarrow A_{ij} + \sigma_{\text{str}} \cdot \xi$

---

### è¯„ä¼°æŒ‡æ ‡
- **AUCï¼ˆArea Under ROC Curveï¼‰**ï¼šä¸ºä¸»è¦è¯„ä»·æŒ‡æ ‡ï¼Œé˜ˆå€¼æ— å…³ï¼Œé€‚åˆä¸åŒç¨€ç–æ€§çš„ç½‘ç»œï¼›
- å…¶ä»–æŒ‡æ ‡ï¼šAccuracy, Precision, Recall, F1-scoreï¼ˆå½“å®šä¹‰æ˜ç¡®é˜ˆå€¼æ—¶ï¼‰ï¼›
- æˆåŠŸé‡å»ºå®šä¹‰ä¸ºï¼šAUC = 1 ä¸” Accuracy/Precision/Recall/F1-score å‡è¾¾1ã€‚

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”ï¼ˆè§Supplementary Sec. S4ï¼‰
æ¯”è¾ƒäº†ä»¥ä¸‹ç»å…¸æ–¹æ³•ï¼š
- **Transfer Entropy (TE)**
- **Network Deconvolution (ND)**
- **Partial Phase Synchronization (PPS)**
- **Modular Response Analysis (MRA)**
- **Global Silencing (GS)**
- **Correlation-based inference**

è¿™äº›æ–¹æ³•å¤§å¤šåŸºäºJacobianå›å½’ã€åæ–¹å·®åæ¼”æˆ–é—´æ¥å…³è”è¿‡æ»¤ï¼Œåœ¨é¢å¯¹**ä¸­ç­‰ä»¥ä¸Šå¯†åº¦ã€æœ‰å‘ã€åŠ æƒæˆ–éçº¿æ€§ç³»ç»Ÿ**æ—¶æ€§èƒ½æ˜æ˜¾ä¸‹é™ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰åœ¨äººå·¥ç½‘ç»œä¸Šçš„è¡¨ç°ï¼ˆFig. 2ï¼‰
- æ‰€æœ‰8ç±»åŠ¨åŠ›ç³»ç»Ÿï¼ˆä»Kuramotoåˆ°Lorenzæ··æ²Œç³»ç»Ÿï¼‰å‡å®ç° **AUC > 0.95**ï¼Œå¤šæ•°æ¥è¿‘ **AUC â‰ˆ 1.0**ï¼›
- ä»…éœ€çº¦ **$M \sim O(N)$** ä¸ªç¨³æ€å³å¯å®Œæˆé«˜è´¨é‡é‡å»ºï¼›
- å›¾2Cæ˜¾ç¤ºï¼šæœ€å°æ‰€éœ€å®éªŒæ•°éš $N$ è¿‘ä¼¼çº¿æ€§å¢é•¿ï¼Œè¡¨æ˜ä¿¡æ¯æ•ˆç‡ç¨³å®šã€‚

#### ï¼ˆ2ï¼‰å™ªå£°é²æ£’æ€§ï¼ˆFig. 3ï¼‰
- å³ä½¿åœ¨ **noise level = 0.5**ï¼ˆç›¸å¯¹æ‰°åŠ¨50% MADï¼‰ä¸‹ï¼š
  - è§‚æµ‹å™ªå£°ï¼šAUCä»å¯è¾¾ >0.9ï¼ˆ$M \geq 30$ï¼‰
  - åŠ¨æ€å™ªå£° & ç»“æ„å™ªå£°ï¼šéšç€ $M$ å¢åŠ ï¼ŒAUCè¶‹è¿‘äº1
- è¡¨æ˜ï¼š**å…¨å±€ç¨³æ€çº¦æŸèƒ½æœ‰æ•ˆæŠ‘åˆ¶å±€éƒ¨é›¶å‡å€¼å™ªå£°çš„å½±å“**

#### ï¼ˆ3ï¼‰å¤§è§„æ¨¡çœŸå®ç½‘ç»œé‡å»ºï¼ˆFig. 4ï¼‰
| ç½‘ç»œ | èŠ‚ç‚¹æ•° | è¾¾åˆ°å®Œç¾é‡å»ºæ‰€éœ€ $M$ |
|------|-------|------------------|
| Florentine Families | 16 | ~10 |
| Zachary Karate Club | 34 | ~20 |
| Wild Bird Social | 202 | ~60 |
| C. elegans Neural | 297 | ~80 |
| Power Grid | 494 | ~120 |
| Retweet Weibo | 596 | ~140 |
| Human Brain Neural | 989 | ~200 |

> âœ… æ‰€æœ‰ç½‘ç»œå‡èƒ½åœ¨åˆç†æ•°é‡çš„ç¨³æ€ä¸‹å®ç° **AUC â†’ 1**

#### ï¼ˆ4ï¼‰é«˜é˜¶äº¤äº’é‡å»ºï¼ˆFig. 5ï¼‰
- æˆåŠŸé‡å»º **2-simplexï¼ˆä¸‰è§’å½¢ï¼‰è‡³4-simplexï¼ˆå››ä½“è€¦åˆï¼‰** å¼ é‡ç»“æ„ï¼›
- å°½ç®¡å€™é€‰é«˜é˜¶è¿æ¥å‘ˆç»„åˆçˆ†ç‚¸å¢é•¿ï¼Œä½†æ‰€éœ€ç¨³æ€æ•°**äºšç»„åˆå¢é•¿**ï¼ˆsub-combinatorialï¼‰ï¼›
- åœ¨ $N=10$, æ‰€æœ‰å¯èƒ½2/3/4-simplexä»¥ $p=0.5$ å­˜åœ¨æ—¶ï¼š
  - AUCåœ¨ $M=15$ å·¦å³å³æ¥è¿‘1ï¼›
  - å¯¹ä¸‰ç§å™ªå£°ä»ä¿æŒè‰¯å¥½æ¢å¤èƒ½åŠ›ï¼ˆFig. 5Eï¼‰

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœï¼ˆSupplementary Sec. S4ï¼‰
- åœ¨ä¸­ç­‰å¯†åº¦ï¼ˆ$\rho > 0.1$ï¼‰æˆ–æœ‰å‘/åŠ æƒç½‘ç»œä¸Šï¼Œæ‰€æœ‰baselineæ–¹æ³•æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼ˆAUC < 0.8ï¼‰ï¼›
- ç‰¹åˆ«æ˜¯åœ¨Wild Bird Socialï¼ˆå¯†åº¦0.586ï¼‰è¿™ç±»ç¨ å¯†ç¤¾äº¤ç½‘ç»œä¸Šï¼Œå¤šæ•°æ–¹æ³•å‡ ä¹å¤±æ•ˆï¼›
- è€Œ **VPIAå§‹ç»ˆä¿æŒAUC > 0.95**ï¼Œæ”¯æŒæ¢å¤ç²¾åº¦æ¥è¿‘100%

---

### æ¶ˆèå®éªŒï¼ˆéšå«äºæ–‡ä¸­åˆ†æï¼‰
è™½ç„¶æœªå•ç‹¬åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»¥ä¸‹è®¾è®¡éªŒè¯äº†å…³é”®ç»„ä»¶çš„æœ‰æ•ˆæ€§ï¼š
- **æ®‹å·®é‡‡æ · vs å…¨æ‰¹é‡æ›´æ–°**ï¼šé‡‡æ ·ç­–ç•¥å°†å¤æ‚åº¦ä» $O(MN^2)$ é™ä¸º $O(Ms)$ï¼Œä½¿å¾— $N \sim 10^3$ æˆä¸ºå¯è¡Œï¼›
- **è‡ªç„¶æ¢¯åº¦ vs æ™®é€šAdam**ï¼šåœ¨å¤§å‹ç½‘ç»œä¸­ï¼Œè‡ªç„¶æ¢¯åº¦æ˜¾è‘—åŠ å¿«æ”¶æ•›å¹¶é¿å…éœ‡è¡ï¼›
- **ç¨³æ€å¤šæ ·æ€§è¿‡æ»¤æœºåˆ¶**ï¼šå»é™¤ä½ç¦»æ•£åº¦æ ·æœ¬åï¼Œé‡å»ºæˆåŠŸç‡å¤§å¹…æå‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **ç¨³æ€æ•°æ®è•´å«è¶³å¤Ÿä¿¡æ¯ç”¨äºç²¾ç¡®ç½‘ç»œé‡æ„**  
   å³ä½¿æ²¡æœ‰æ—¶é—´æ¼”åŒ–è·¯å¾„ï¼Œå¤šä¸ªå¼‚æ„ç¨³æ€æ‰€æä¾›çš„å…¨å±€ä»£æ•°çº¦æŸè¶³ä»¥å”¯ä¸€ç¡®å®šå¤æ‚çš„äº¤äº’ç»“æ„ã€‚

2. âœ… **VPIAå…·å¤‡é«˜åº¦é€šç”¨æ€§å’Œè·¨åŠ¨åŠ›å­¦ä¸å˜æ€§**  
   åœ¨ç›¸ä½æŒ¯å­ã€æé™ç¯ã€å…´å¥‹æ€§ä»‹è´¨ä¹ƒè‡³æ··æ²Œç³»ç»Ÿä¸­å‡å–å¾—ä¸€è‡´é«˜æ€§èƒ½ï¼Œè¯´æ˜å…¶ä¾èµ–çš„æ˜¯**ç‰©ç†ä¸€è‡´æ€§è€Œéç‰¹å®šå‡½æ•°å½¢å¼**ã€‚

3. âœ… **é«˜é˜¶äº¤äº’å¯åœ¨æ— å…ˆéªŒæƒ…å†µä¸‹è¢«æœ‰æ•ˆè¯†åˆ«**  
   é€šè¿‡å¼ é‡åŒ–å˜åˆ†å‚æ•°åŒ–ï¼ŒVPIAé¦–æ¬¡å®ç°äº†ä»…å‡­ç¨³æ€æ•°æ®å¯¹2-/3-/4-simplexç»“æ„çš„åŒæ—¶æ¢å¤ã€‚

4. âœ… **æ®‹å·®é‡‡æ · + è‡ªç„¶æ¢¯åº¦æ„æˆé«˜æ•ˆå¯æ‰©å±•å¼•æ“**  
   äºŒè€…ç»“åˆè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•åœ¨å¤§è§„æ¨¡ã€ç¨ å¯†ã€é«˜é˜¶ç½‘ç»œä¸­çš„â€œç»´åº¦ç¾éš¾â€é—®é¢˜ï¼Œå®ç° $N \sim 10^3$ çº§åˆ«çš„å®é™…å¯ç”¨æ€§ã€‚

5. âœ… **å™ªå£°å¯é€šè¿‡å¢åŠ ç¨³æ€æ ·æœ¬æ•°æ¥è¡¥å¿**  
   å„ç±»å™ªå£°è™½é™ä½åˆå§‹æ€§èƒ½ï¼Œä½†éšç€ $M$ å¢åŠ ï¼ŒAUCå•è°ƒä¸Šå‡å¹¶è¶‹äºå®Œç¾ï¼Œä½“ç°â€œæ•°æ®å¹³æ»‘å™ªå£°â€çš„èƒ½åŠ›ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. â— **éœ€è¦å¤šä¸ªä¸åŒçš„ç¨³æ€è§‚æµ‹**  
   è‹¥ç³»ç»Ÿåªèƒ½äº§ç”Ÿç›¸ä¼¼æˆ–é€€åŒ–çš„ç¨³æ€ï¼ˆå¦‚åŒæ­¥æ€ï¼‰ï¼Œåˆ™æ— æ³•æä¾›è¶³å¤Ÿçº¦æŸï¼Œå¯¼è‡´ä¸å¯è¾¨è¯†ã€‚

2. â— **ä¾èµ–ç¨³æ€å¯è¾¾æ€§**  
   å¯¹äºé•¿æœŸæŒ¯è¡ã€å‡†å‘¨æœŸæˆ–æ°¸ä¸æ”¶æ•›çš„ç³»ç»Ÿï¼Œéœ€æ‰©å±•è‡³quasi-steadyæˆ–metastableçŠ¶æ€å»ºæ¨¡ã€‚

3. â— **æç«¯é«˜é˜¶ç½‘ç»œä»å…·æŒ‘æˆ˜**  
   å½“ $d$-simplex é˜¶æ•°è¿‡é«˜ï¼ˆå¦‚ $d>4$ï¼‰ä¸” $N$ å¾ˆå¤§æ—¶ï¼Œå‚æ•°ç©ºé—´å·¨å¤§ï¼Œå³ä½¿é‡‡æ ·ä¹Ÿé¢ä¸´å†…å­˜ä¸è®­ç»ƒè´Ÿæ‹…ã€‚

4. â— **è¶…å‚æ•°æ•æ„Ÿæ€§å­˜åœ¨**  
   å¦‚sigmoid steepness $k$ã€é‡‡æ ·æ¯”ä¾‹ $s/N$ã€learning rateç­‰éœ€è°¨æ…è°ƒå‚ï¼Œå°½ç®¡ä½œè€…ç§°ç»“æœå¯¹å°èŒƒå›´å˜åŒ–é²æ£’ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. ğŸ”„ **æ¨å¹¿è‡³æ—¶å˜æˆ–è‡ªé€‚åº”ç½‘ç»œ**ï¼šè€ƒè™‘ç¼“æ…¢æ¼”åŒ–çš„æ‹“æ‰‘ç»“æ„ï¼›
2. ğŸ’¡ **ç»“åˆè´å¶æ–¯æ¨ç†**ï¼šå¼•å…¥ä¸ç¡®å®šæ€§é‡åŒ–ï¼Œæä¾›ç½®ä¿¡åŒºé—´ï¼›
3. âš™ï¸ **åˆ†å¸ƒå¼ä¼˜åŒ–æ¶æ„**ï¼šåº”å¯¹ $N > 10^4$ çš„è¶…å¤§è§„æ¨¡ç³»ç»Ÿï¼›
4. ğŸ§  **åº”ç”¨äºçœŸå®ç”Ÿç‰©/ç¤¾ä¼šç³»ç»Ÿ**ï¼šå¦‚fMRIè„‘åŠŸèƒ½ç½‘ç»œã€åŸºå› è°ƒæ§ç½‘ç»œã€ç¤¾äº¤åª’ä½“ä¼ æ’­ç»“æ„ç­‰ä»…æœ‰å¿«ç…§æ•°æ®çš„é¢†åŸŸï¼›
5. ğŸ” **å‘å±•æ›´é«˜æ•ˆçš„å˜åˆ†å‚æ•°åŒ–æ–¹æ¡ˆ**ï¼šä¾‹å¦‚ä½ç§©åˆ†è§£ã€å›¾ç¥ç»ç½‘ç»œå¼•å¯¼å…ˆéªŒç­‰ï¼Œè¿›ä¸€æ­¥å‹ç¼©æœç´¢ç©ºé—´ã€‚

---

## æ€»ç»“
**VPIA æ˜¯ä¸€ç§çªç ´æ€§çš„ã€å®Œå…¨åŸºäºç¨³æ€æ•°æ®çš„ç½‘ç»œé‡æ„æ¡†æ¶**ã€‚å®ƒèåˆäº†ç‰©ç†å»ºæ¨¡ã€å˜åˆ†å­¦ä¹ ã€é‡‡æ ·åŠ é€Ÿä¸å‡ ä½•ä¼˜åŒ–ï¼ŒæˆåŠŸè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•åœ¨**éçº¿æ€§ã€é«˜é˜¶ã€å™ªå£°ã€å¤§è§„æ¨¡**åœºæ™¯ä¸‹çš„ç“¶é¢ˆé—®é¢˜ã€‚è¯¥æ–¹æ³•ä¸ä»…ç†è®ºä¸¥è°¨ï¼Œè€Œä¸”åœ¨å¤šæ ·åŒ–çš„äººå·¥ä¸çœŸå®ç½‘ç»œä¸Šå±•ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä¸ºç†è§£å¤æ‚ç³»ç»ŸèƒŒåçš„éšè—ç»“æ„æä¾›äº†å¼ºæœ‰åŠ›çš„å·¥å…·ï¼Œå°¤å…¶é€‚ç”¨äºé‚£äº›**åªèƒ½è·å¾—é™æ€è§‚æµ‹**çš„å®é™…åº”ç”¨åœºæ™¯ã€‚

</details>

---

### 7. [ValuePilot: A Two-Phase Framework for Value-Driven Decision-Making](https://arxiv.org/abs/2512.13716)

**Authors**: Yitong Luo, Ziang Chen, Hou Hei Lam, Jiayu zhan, Junqi Wang, Zhenliang Zhang, Xue Feng  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.13716v1  

#### Abstract
Personalized decision-making is essential for human-AI interaction, enabling AI agents to act in alignment with individual users' value preferences. As AI systems expand into real-world applications, adapting to personalized values beyond task completion or collective alignment has become a critical...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*ValuePilot: A Two-Phase Framework for Value-Driven Decision-Making*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰çš„ AI å†³ç­–ç³»ç»Ÿå¤šä¸ºä»»åŠ¡å¯¼å‘ï¼ˆtask-orientedï¼‰ï¼Œä¾èµ–å¤–éƒ¨å¥–åŠ±ä¿¡å·ï¼Œéš¾ä»¥é€‚åº”ä¸ªä½“ç”¨æˆ·çš„**ä¸ªæ€§åŒ–ä»·å€¼åå¥½**ï¼ˆpersonalized value preferencesï¼‰ã€‚å°½ç®¡å·²æœ‰ç ”ç©¶å¦‚ RLHF å’Œ DPO å°è¯•å¯¹é½äººç±»ä»·å€¼è§‚ï¼Œä½†é€šå¸¸åŸºäºé›†ä½“åé¦ˆï¼Œå¿½è§†äº†ä¸ªä½“å·®å¼‚ã€‚æ­¤å¤–ï¼Œç¼ºä¹é«˜è´¨é‡ã€ç»†ç²’åº¦æ ‡æ³¨çš„å†³ç­–æ•°æ®é›†ï¼Œä½¿å¾—æ¨¡å‹æ— æ³•å­¦ä¹ åˆ°è¡Œä¸ºä¸æ·±å±‚ä»·å€¼ç»´åº¦ä¹‹é—´çš„å…³è”ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡º **ValuePilot**ï¼Œä¸€ä¸ªä¸¤é˜¶æ®µæ¡†æ¶ï¼Œç”¨äºå®ç°**ä»¥ä»·å€¼ä¸ºå¯¼å‘çš„ä¸ªæ€§åŒ–å†³ç­–**ï¼ˆvalue-driven decision-makingï¼‰ï¼š

- **Dataset Generation Toolkit (DGT)**  
  åˆ©ç”¨ LLM æ„å»ºä¸€ä¸ªç”±äººç±»ä¸ LLM åä½œç”Ÿæˆçš„å†³ç­–åœºæ™¯æ•°æ®é›†ï¼Œæ¯ä¸ªåœºæ™¯å’Œå€™é€‰åŠ¨ä½œéƒ½å¸¦æœ‰å¤šä¸ªä»·å€¼ç»´åº¦ï¼ˆå¦‚ Curiosity, Safety, Fairness ç­‰ï¼‰çš„æ•°å€¼è¯„åˆ†ï¼ˆ-1 åˆ° +1ï¼‰ï¼Œä»è€Œæä¾›å¯è§£é‡Šçš„ä»·å€¼æ ‡æ³¨ã€‚

- **Decision-Making Module (DMM)**  
  ç»“åˆå®¢è§‚çš„åŠ¨ä½œä»·å€¼è¯„ä¼°ä¸ç”¨æˆ·ä¸»è§‚çš„ä»·å€¼åå¥½ï¼Œé€šè¿‡ PROMETHEE å¤šå‡†åˆ™å†³ç­–æ–¹æ³•è¿›è¡ŒåŠ¨ä½œæ’åºï¼Œè¾“å‡ºç¬¦åˆä¸ªä½“åå¥½çš„å¯è§£é‡Šå†³ç­–åºåˆ—ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ RLHF, ReActï¼‰ | ValuePilot |
|------|----------------------------|------------|
| å†³ç­–ä¾æ® | å¤–éƒ¨ä»»åŠ¡ç›®æ ‡ / é›†ä½“åå¥½ | æ˜ç¡®å»ºæ¨¡ä¸ªä½“ä»·å€¼åå¥½ |
| å¯è§£é‡Šæ€§ | é»‘ç®±æ¨ç†è¿‡ç¨‹ | åŠ¨ä½œå¾—åˆ†å¯åˆ†è§£è‡³å„ä»·å€¼ç»´åº¦ |
| æ³›åŒ–èƒ½åŠ› | ä¾èµ–è®­ç»ƒä»»åŠ¡ | åœ¨æœªè§åœºæ™¯ä¸­ä»èƒ½åšå‡ºåˆç†å†³ç­– |
| æ•°æ®æ”¯æŒ | ç¼ºä¹ä»·å€¼æ ‡æ³¨æ•°æ® | è‡ªåŠ¨æ„å»ºå¸¦ä»·å€¼åˆ†æ•°çš„æ•°æ®é›† |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **è‡ªå»ºæ•°æ®é›†**ï¼šé€šè¿‡ DGT ç”Ÿæˆï¼Œå…±åŒ…å« **11,938 ä¸ªåœºæ™¯** å’Œ **100,255 ä¸ªåŠ¨ä½œ**ã€‚
- è¦†ç›–å…­ä¸ªæ ¸å¿ƒä»·å€¼ç»´åº¦ï¼š`Curiosity`, `Energy`, `Safety`, `Happiness`, `Intimacy`, `Fairness`ã€‚
- æ•°æ®åˆ†å±‚è®¾è®¡ï¼ˆ1-D åˆ° 6-D ç»„åˆï¼‰ï¼Œæ”¯æŒå¤æ‚åº¦é€’å¢çš„æµ‹è¯•ã€‚
- åŒ…å«è‡ªåŠ¨è¿‡æ»¤ä¸äººå·¥å®¡æ ¸æµç¨‹ï¼Œç¡®ä¿çœŸå®æ€§ä¸ä¸€è‡´æ€§ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### ï¼ˆ1ï¼‰Value Recognition å®éªŒ
- **ä»»åŠ¡**ï¼šè¯„ä¼° Value Assessment Network æ˜¯å¦èƒ½å‡†ç¡®è¯†åˆ«åŠ¨ä½œåœ¨å„ä¸ªä»·å€¼ç»´åº¦ä¸Šçš„å½±å“ã€‚
- **åŸºçº¿æ¨¡å‹**ï¼šLlama-3.5-70b, Llama-3.5-405b, Mixtral-8x22b, Gemini-1.5-flashã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **AvgAcc**ï¼šé˜ˆå€¼ä¸º 0.2 å’Œ 0.05 çš„å¹³å‡åˆ†ç±»å‡†ç¡®ç‡ã€‚
  - **MAE**ï¼šé¢„æµ‹åˆ†æ•°ä¸çœŸå®å€¼ä¹‹é—´çš„å¹³å‡ç»å¯¹è¯¯å·®ã€‚

#### ï¼ˆ2ï¼‰Value-driven Decision-making å®éªŒ
- **å‚ä¸è€…**ï¼š40 åäººç±»è¢«è¯•ï¼Œå®Œæˆé—®å·è°ƒæŸ¥å…¶ä»·å€¼åå¥½å¹¶æ’åºå®é™…æƒ…å¢ƒä¸­çš„è¡ŒåŠ¨é€‰é¡¹ã€‚
- **è¾“å…¥**ï¼šæ¯ä¸ªè¢«è¯•çš„å…­ç»´ä»·å€¼åå¥½å‘é‡ + åœºæ™¯æè¿°ã€‚
- **è¾“å‡º**ï¼šæ¨¡å‹é¢„æµ‹çš„åŠ¨ä½œæ’åºã€‚
- **åŸºçº¿æ¨¡å‹**ï¼šGPT-5, Claude-Sonnet-4, Gemini-2.5-flash, Llama-3.1-70b, DeepSeek-R1, Kimi-K2, GPT-4o-miniã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Order-Sensitive Similarity (OS-Sim)**ï¼šåŸºäºå‰ç¼€äº¤é›†çš„æ’åºç›¸ä¼¼åº¦ï¼Œå¼ºè°ƒé«˜ä½æ¬¡åŒ¹é…ã€‚
  - **First-Action Accuracy (First-Acc)**ï¼šé¦–ä½åŠ¨ä½œé€‰æ‹©æ­£ç¡®çš„æ¯”ä¾‹ã€‚

#### ï¼ˆ3ï¼‰æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰
ç§»é™¤ DMM ä¸­çš„å…³é”®ç»„ä»¶ï¼ŒéªŒè¯å…¶å¿…è¦æ€§ï¼š
- Only Action
- w/o Preference
- w/o Subjective
- w/o Scenario

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ï¼ˆ1ï¼‰Value Recognition æ€§èƒ½å¯¹æ¯”ï¼ˆTable 1ï¼‰

| Model | AvgAcc (%) @t=0.2 | AvgAcc (%) @t=0.05 | MAE |
|-------|-------------------|--------------------|-----|
| Llama-3.5-70b | 40.90 | 17.74 | 0.30 |
| Mixtral-8x22b | 42.71 | 18.39 | 0.29 |
| Gemini-1.5-flash | 51.61 | 25.64 | 0.24 |
| **Value Assessment Network (Ours)** | **66.70** | **40.00** | **0.19** |

> âœ… **æå‡æ˜¾è‘—**ï¼šç›¸æ¯”æœ€å¼ºåŸºçº¿ï¼ˆGeminiï¼‰ï¼ŒAvgAcc æå‡ **15.09pp**ï¼ŒMAE ä¸‹é™ **36.7%**ã€‚

---

### ï¼ˆ2ï¼‰Decision-making å¯¹é½äººç±»é€‰æ‹©çš„ç»“æœï¼ˆFigure 2ï¼‰

| Model | OS-Sim (%) | First-Acc (%) |
|-------|------------|---------------|
| GPT-5 | 69.23 Â± 0.71 | 38.01 Â± 3.81 |
| **DMM (Ours)** | **73.16 Â± 0.43** | **46.14 Â± 4.09** |

> âœ… **å…¨é¢é¢†å…ˆ**ï¼š
> - OS-Sim æå‡ **+3.93pp**
> - First-Acc æå‡ **+8.13pp**

è¡¨æ˜ DMM æ›´å¥½åœ°æ•æ‰äº†äººç±»çš„ä¼˜å…ˆçº§ç»“æ„å’Œé¦–é€‰è¡Œä¸ºã€‚

---

### ï¼ˆ3ï¼‰æ¶ˆèå®éªŒç»“æœï¼ˆTable 2ï¼‰

| Model Variant | OS-Sim (%) | First-Acc (%) |
|--------------|------------|---------------|
| Only Action | 60.23 | 32.27 |
| w/o Preference | 61.07 | 31.82 |
| w/o Subjective | 68.93 | 43.45 |
| w/o Scenario | 69.99 | 43.64 |
| **DMM (Full)** | **73.16** | **46.14** |

> ğŸ” **å…³é”®å‘ç°**ï¼š
> - ç§»é™¤â€œä¸»è§‚åå¥½è°ƒæ•´â€æˆ–â€œåœºæ™¯ä¸Šä¸‹æ–‡â€å¯¼è‡´æ€§èƒ½å¤§å¹…ä¸‹é™ã€‚
> - å®Œæ•´æ¡†æ¶æ•´åˆäº†**å®¢è§‚ä»·å€¼è¯„ä¼°**ã€**ç”¨æˆ·åå¥½**ä¸**æƒ…å¢ƒæ•æ„Ÿæ€§**ï¼Œç¼ºä¸€ä¸å¯ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ä»·å€¼é©±åŠ¨å†³ç­–æ˜¯å¯è¡Œä¸”æœ‰æ•ˆçš„è·¯å¾„**ï¼šå°†äººç±»ä»·å€¼è§‚ä½œä¸ºç¨³å®šã€å¯è¿ç§»çš„ä¿¡å·ï¼Œèƒ½å¤Ÿæå‡ AI åœ¨æ–°åœºæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›å’Œè¡Œä¸ºåˆç†æ€§ã€‚
2. **æ˜¾å¼å»ºæ¨¡ä¼˜äºéšå¼å­¦ä¹ **ï¼šç›¸æ¯”äº LLM çš„é›¶æ ·æœ¬æ¨ç†ï¼Œæ˜¾å¼å»ºæ¨¡ä»·å€¼ç»´åº¦ä¸åå¥½èƒ½æ›´ç²¾å‡†åœ°å¤ç°äººç±»å†³ç­–æ¨¡å¼ã€‚
3. **PROMETHEE æ˜¯å¤„ç†å¤šä»·å€¼æƒè¡¡çš„æœ‰æ•ˆå·¥å…·**ï¼šç›¸æ¯” MAUTã€TOPSIS ç­‰ MCDA æ–¹æ³•ï¼ŒPROMETHEE åœ¨æœ¬ä»»åŠ¡ä¸­è¡¨ç°æœ€ä½³ï¼ˆTable 7ï¼‰ã€‚
4. **åˆæˆæ•°æ®+äººå·¥æ ¡éªŒå¯æ„å»ºé«˜è´¨é‡è®­ç»ƒé›†**ï¼šDGT æµç¨‹ç»“åˆè‡ªåŠ¨åŒ–ç”Ÿæˆä¸äººå·¥å®¡æŸ¥ï¼Œæœ‰æ•ˆç¼“è§£äº†åˆæˆæ•°æ®æ¼‚ç§»é—®é¢˜ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä»·å€¼ç»´åº¦ä¸ºé¢„å®šä¹‰é›†åˆï¼ˆ6 ä¸ªï¼‰ï¼Œå°šæœªå®ç°åŠ¨æ€æ‰©å±•æˆ–å±‚æ¬¡åŒ–è¡¨è¾¾ã€‚
- ç”¨æˆ·åå¥½é‡‡é›†ä¾èµ–è‡ªæˆ‘æŠ¥å‘Šé‡è¡¨ï¼Œå¯èƒ½å­˜åœ¨è®¤çŸ¥åå·®ã€‚
- æ¡†æ¶ä¾§é‡å·¥ç¨‹é›†æˆï¼Œæœªæ·±å…¥æ¢ç´¢åº•å±‚ä»·å€¼è¡¨ç¤ºå­¦ä¹ æœºåˆ¶ã€‚
- å®éªŒé›†ä¸­åœ¨å®¶åº­åœºæ™¯ï¼Œéœ€è¿›ä¸€æ­¥éªŒè¯äºåŒ»ç–—ã€æ•™è‚²ç­‰é«˜é£é™©é¢†åŸŸã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ä»å¯¹è¯æˆ–è¡Œä¸ºæ—¥å¿—ä¸­è‡ªåŠ¨æ¨æ–­ç”¨æˆ·ä»·å€¼åå¥½çš„æ–¹æ³•ã€‚
- æ‰©å±•æ›´å¤šæ–‡åŒ–èƒŒæ™¯ä¸‹çš„ä»·å€¼ç»´åº¦ï¼ˆå¦‚é›†ä½“ä¸»ä¹‰ vs ä¸ªäººä¸»ä¹‰ï¼‰ã€‚
- å°† ValuePilot éƒ¨ç½²è‡³å…·èº«æ™ºèƒ½ä½“ï¼ˆembodied agentsï¼‰ä¸­è¿›è¡Œå®æ—¶äº¤äº’éªŒè¯ã€‚
- å¼•å…¥åŠ¨æ€åå¥½æ¼”åŒ–æœºåˆ¶ï¼Œæ”¯æŒé•¿æœŸä¸ªæ€§åŒ–é€‚åº”ã€‚

---

> ğŸ’¡ **æ€»ä½“è¯„ä»·**ï¼š  
> *ValuePilot* æä¾›äº†ä¸€æ¡é€šå¾€**å¯è§£é‡Šã€ä¸ªæ€§åŒ–ã€ç¤¾ä¼šå¯¹é½ AI** çš„æ¸…æ™°å·¥ç¨‹è·¯å¾„ã€‚å®ƒä¸ä»…å±•ç¤ºäº†ä»·å€¼å»ºæ¨¡çš„å®é™…å¯è¡Œæ€§ï¼Œä¹Ÿä¸ºæœªæ¥æ„å»ºçœŸæ­£ç†è§£äººç±»åŠ¨æœºçš„ AI ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚

</details>

---

### 8. [Real-Time Service Subscription and Adaptive Offloading Control in Vehicular Edge Computing](https://arxiv.org/abs/2512.14002)

**Authors**: Chuanchao Gao, Arvind Easwaran  
**Category**: cs.DC  
**Published**: 2025-12-17  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.14002v1  

#### Abstract
Vehicular Edge Computing (VEC) has emerged as a promising paradigm for enhancing the computational efficiency and service quality in intelligent transportation systems by enabling vehicles to wirelessly offload computation-intensive tasks to nearby Roadside Units. However, efficient task offloading ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹**Vehicular Edge Computing (VEC)** ç³»ç»Ÿä¸­çš„ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼š
- **Deadline-Constrained Task Offloading and Resource Allocation Problem (DOAP)**ï¼šåœ¨å¸¦å®½å’Œè®¡ç®—èµ„æºå—é™çš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•è”åˆä¼˜åŒ–ä»»åŠ¡å¸è½½ä¸èµ„æºåˆ†é…ä»¥æœ€å¤§åŒ–è½¦è¾†æ•ˆç”¨ã€‚
- **åŠ¨æ€æ— çº¿ä¿¡é“è´¨é‡ä¸æ—¶å»¶æ•æ„Ÿæ€§**ï¼šç”±äºè½¦è¾†ç§»åŠ¨æ€§å’Œç¯å¢ƒå˜åŒ–å¯¼è‡´çš„å¿«é€Ÿä¿¡é“æ³¢åŠ¨ï¼Œä»¥åŠå®æ—¶ä»»åŠ¡æçŸ­çš„æˆªæ­¢æ—¶é—´ï¼ˆå¦‚10msçº§ï¼‰ï¼Œä¼ ç»Ÿé™æ€è°ƒåº¦éš¾ä»¥æ»¡è¶³éœ€æ±‚ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
1. **SARound è¿‘ä¼¼ç®—æ³•**  
   - é’ˆå¯¹NP-hardçš„DOAPé—®é¢˜ï¼Œæå‡ºåŸºäº**Linear Programming (LP) rounding** å’Œ **local-ratio æŠ€æœ¯**çš„è¿‘ä¼¼ç®—æ³• SARoundã€‚
   - æ”¹è¿›äº†å½“å‰æœ€ä¼˜çš„è¿‘ä¼¼æ¯”ï¼ˆä» $ \frac{1}{3} $ æå‡è‡³ $ \frac{1}{2} $ï¼‰ï¼ŒåŒæ—¶ä¿æŒé«˜æ•ˆçš„è¿è¡Œæ—¶å¤æ‚åº¦ $ O(M(NBC)^3) $ï¼Œå…¶ä¸­ $ M $ æ˜¯RSUæ•°é‡ï¼Œ$ N $ æ˜¯ä»»åŠ¡æ•°ï¼Œ$ B $ å’Œ $ C $ åˆ†åˆ«ä¸ºæœ€å¤§RBå’ŒCUèµ„æºå•ä½ã€‚

2. **åœ¨çº¿æœåŠ¡è®¢é˜…ä¸è‡ªé€‚åº”å¸è½½æ§åˆ¶æ¡†æ¶**
   - è®¾è®¡äº†ä¸€ä¸ªå®Œæ•´çš„**åœ¨çº¿ç”Ÿå‘½å‘¨æœŸç®¡ç†æ¡†æ¶**ï¼Œæ”¯æŒå‘¨æœŸæ€§å®æ—¶ä»»åŠ¡çš„æœåŠ¡æ³¨å†Œã€è°ƒåº¦å†³ç­–ã€æœåŠ¡åˆå§‹åŒ–ä¸åŠ¨æ€å¸è½½æ§åˆ¶ã€‚
   - å¼•å…¥åŸºäº **Sounding Reference Signal (SRS)** çš„åé¦ˆæœºåˆ¶ï¼šè½¦è¾†å®šæœŸå‘é€SRSä¿¡å·ï¼ŒRSUæ®æ­¤ä¼°è®¡ä¸Šè¡Œé“¾è·¯è´¨é‡å¹¶åŠ¨æ€è°ƒæ•´æ˜¯å¦å…è®¸å¸è½½ï¼Œè‹¥ä¿¡é“æ¶åŒ–åˆ™æš‚åœå¸è½½ã€è½¬ä¸ºæœ¬åœ°æ‰§è¡Œï¼Œé¿å… deadline missã€‚
   - è°ƒåº¦ä¸æœåŠ¡åˆå§‹åŒ–åœ¨å¸è½½å‰å®Œæˆï¼Œä¸å ç”¨ä»»åŠ¡æ‰§è¡Œçª—å£ï¼Œæå‡æ—¶é—´ç¡®å®šæ€§ã€‚

3. **å¼€å‘ VecSim å¼€æºä»¿çœŸå™¨**
   - æ„å»ºé¦–ä¸ªä¸“ä¸º**æˆªæ­¢æ—¶é—´çº¦æŸå‹è½¦è½½ä»»åŠ¡å…¨ç”Ÿå‘½å‘¨æœŸç®¡ç†**è®¾è®¡çš„VECä»¿çœŸå¹³å° VecSimã€‚
   - é›†æˆ OMNeT++ å’Œ Simu5Gï¼Œæ”¯æŒçœŸå®è½¦è¾†è½¨è¿¹ã€5G V2Xé€šä¿¡å»ºæ¨¡ã€èµ„æºè°ƒåº¦ä¸åœ¨çº¿å¸è½½æ§åˆ¶é—­ç¯éªŒè¯ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | æœ¬æ–‡æ–¹æ³• | ç°æœ‰æ–¹æ³•å±€é™ |
|------|----------|-------------|
| **ç†è®ºä¿è¯** | æä¾›æ›´ä¼˜çš„è¿‘ä¼¼æ¯” $ \frac{1}{2} $ | å¤šæ•°ä¸ºå¯å‘å¼ç®—æ³•æ— ç†è®ºä¿éšœï¼›å·²æœ‰è¿‘ä¼¼ç®—æ³•ä»…è¾¾ $ \frac{1}{3} $ |
| **åŠ¨æ€é€‚åº”æ€§** | æ”¯æŒSRSé©±åŠ¨çš„åœ¨çº¿ä¿¡é“æ„ŸçŸ¥ä¸å¸è½½æ§åˆ¶ | å¤šå‡è®¾ä¿¡é“æ’å®šæˆ–å¿½ç•¥ä¿¡é“æ³¢åŠ¨å½±å“ |
| **ç³»ç»Ÿå®Œæ•´æ€§** | å®Œæ•´ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼ˆæ³¨å†Œâ†’è°ƒåº¦â†’éƒ¨ç½²â†’æ§åˆ¶ï¼‰ | ç¼ºä¹ç«¯åˆ°ç«¯ä»¿çœŸå·¥å…·æ”¯æŒ |
| **å®ç”¨æ€§** | åœ¨çŸ­ä»»åŠ¡å‘¨æœŸä¸‹ä»å¯å®¹å¿è¾ƒé•¿è°ƒåº¦å»¶è¿Ÿï¼ˆå› è°ƒåº¦ä¸å½±å“æ‰§è¡Œçª—å£ï¼‰ | è°ƒåº¦å¼€é”€å¯èƒ½æŒ¤å æ‰§è¡Œæ—¶é—´ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **è½¦è¾†è½¨è¿¹æ•°æ®**ï¼šæ¥è‡ªä¸Šæµ·å¼ºç”Ÿå‡ºç§Ÿè½¦å…¬å¸çš„çœŸå®GPSè½¨è¿¹æ•°æ®ï¼ˆ[23]ï¼‰ï¼Œé€‰å–2018å¹´4æœˆ1æ—¥æ™šé«˜å³°15åˆ†é’Ÿå†…é€šè¿‡1kmÃ—1kmåŸåŒºçš„80è¾†å‡ºç§Ÿè½¦ã€‚
- **åº”ç”¨è´Ÿè½½æ•°æ®**ï¼šåŸºäº **ImageNet ILSVRC** æ•°æ®é›†ä¸­çš„57å¼ å›¾åƒï¼ˆ0.07â€“0.3MBï¼‰ï¼Œç»“åˆå…­ç§GPUç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼ˆRESNET-18/50/101/152, VGG-16/19ï¼‰è¿›è¡Œæ€§èƒ½å‰–é¢åˆ†æã€‚
- **ç¡¬ä»¶é…ç½®**ï¼šæœ¬åœ°è®¾å¤‡ä½¿ç”¨ **NVIDIA Jetson Nano** æµ‹é‡æœ¬åœ°æ‰§è¡ŒåŠŸè€—ä¸å»¶è¿Ÿï¼›RSUé…å¤‡éšæœºé€‰æ‹©çš„å…­ç±»GPUï¼ˆTITAN V, RTXç³»åˆ—ç­‰ï¼‰ï¼Œå…±16ä¸ªCUï¼Œ5Gç½‘ç»œæä¾›270ä¸ªResource Block (RB)ï¼Œå³°å€¼é€Ÿç‡37MB/sã€‚

### å®éªŒè®¾ç½®
- **ä»¿çœŸå¹³å°**ï¼šè‡ªç ” **VecSim**ï¼Œé›†æˆ OMNeT++ å’Œ Simu5Gï¼Œå®ç°è½¦è¾†ç§»åŠ¨ã€5Gé€šä¿¡ã€ä»»åŠ¡è°ƒåº¦ä¸å¸è½½æ§åˆ¶å…¨æµç¨‹æ¨¡æ‹Ÿã€‚
- **ä»»åŠ¡å‚æ•°**ï¼šä»»åŠ¡å‘¨æœŸè®¾ä¸º50msã€67msæˆ–100msï¼ˆå¯¹åº”é¢‘ç‡20Hzã€15Hzã€10Hzï¼‰ï¼Œè¾“å…¥å¤§å°éšæœºé‡‡æ ·ã€‚
- **è°ƒåº¦é—´éš”**ï¼šæ¯10ç§’æ‰§è¡Œä¸€æ¬¡å…¨å±€è°ƒåº¦ã€‚
- **ä¿¡é“è´¨é‡ç­‰çº§**ï¼šå®šä¹‰ä¸‰ç§åœºæ™¯ â€”â€” HIGHï¼ˆé«˜ä¸”ç¨³å®šï¼‰ã€MEDIUMã€LOWï¼ˆä½ä¸”æ³¢åŠ¨å¤§ï¼‰ã€‚
- **è°ƒåº¦æ¨¡å¼å¯¹æ¯”**ï¼š
  - **SchedAll**ï¼šæ¯æ¬¡è°ƒåº¦é‡ç½®æ‰€æœ‰æœåŠ¡ï¼Œé‡æ–°å…¨é‡è°ƒåº¦ã€‚
  - **SchedRemain**ï¼šä»…è°ƒåº¦æœªå¤„ç†è¯·æ±‚ï¼Œä¿ç•™æ­£åœ¨è¿è¡Œçš„æœåŠ¡ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **é¢„æµ‹èƒ½æ•ˆèŠ‚çœ (Predicted energy saving)**ï¼šè°ƒåº¦å™¨é¢„ä¼°çš„æ¯ç§’èŠ‚èƒ½ï¼ˆJ/sï¼‰ï¼Œåæ˜ é™æ€æ¡ä»¶ä¸‹çš„èµ„æºåˆ©ç”¨æ•ˆç‡ã€‚
- **å®æµ‹èƒ½æ•ˆèŠ‚çœ (Measured energy saving)**ï¼šå®é™…ä»¿çœŸä¸­æˆåŠŸå¸è½½ä»»åŠ¡å¸¦æ¥çš„å¹³å‡èŠ‚èƒ½ï¼ˆJ/sï¼‰ï¼Œè€ƒè™‘ä¿¡é“æ³¢åŠ¨ã€åˆå§‹åŒ–å»¶è¿Ÿç­‰å› ç´ ã€‚
- **æ¯ç§’å¸è½½ä»»åŠ¡å®ä¾‹æ•° (Number of offloaded job instances per second)**ï¼šè¡¡é‡ç³»ç»Ÿååèƒ½åŠ›ã€‚
- **ç®—æ³•æ‰§è¡Œæ—¶é—´ (Execution time)**ï¼šè¯„ä¼°ç®—æ³•å¯æ‰©å±•æ€§ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ¯”è¾ƒä»¥ä¸‹å››ç§ä»£è¡¨æ€§ç®—æ³•ï¼š
- **Greedy [14]**ï¼šæŒ‰èµ„æºæ•ˆç‡æ’åºè´ªå¿ƒé€‰æ‹©ã€‚
- **Iterative [1,15â€“17]**ï¼šäº¤æ›¿æ±‚è§£å¸è½½ä¸èµ„æºåˆ†é…å­é—®é¢˜ç›´è‡³æ”¶æ•›ã€‚
- **Game [17]**ï¼šå°†é—®é¢˜å»ºæ¨¡ä¸ºéåˆä½œåšå¼ˆï¼Œå„è½¦ä½œä¸ºç©å®¶ç«äº‰èµ„æºã€‚
- **IDAssign [19]**ï¼šé€’å½’ä¼˜å…ˆå¤„ç†â€œè½»é‡â€æœåŠ¡å®ä¾‹ï¼Œå…·æœ‰ $ \frac{1}{3} $ è¿‘ä¼¼æ¯”ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆSchedAll æ¨¡å¼ï¼‰
| ç®—æ³• | å¹³å‡é¢„æµ‹èŠ‚èƒ½ (J/s) | å¹³å‡å®æµ‹èŠ‚èƒ½ (J/s) | å¸è½½ä»»åŠ¡ç‡ |
|------|---------------------|---------------------|------------|
| **SARound** | **140.2** | **118.6** | æœ€é«˜ |
| Game | 99.0 (+41.5%) | 96.4 (+22.9%) | ä¸­ç­‰ |
| Greedy | 94.6 (+48.2%) | 83.0 (+42.9%) | è¾ƒä½ |
| IDAssign | 79.2 (+76.9%) | 67.7 (+75.1%) | æœ€ä½ |
| Iterative | 98.0 (+43.1%) | 98.6 (+20.3%) | ä¸­ç­‰ |

> æ³¨ï¼šâ€œ+XX%â€è¡¨ç¤º SARound è¶…å‡ºè¯¥åŸºçº¿çš„ç™¾åˆ†æ¯”ã€‚

### ä¸åŒè°ƒåº¦æ¨¡å¼ä¸‹çš„è¡¨ç°ï¼ˆå›¾5 vs å›¾6ï¼‰
- **SchedAll æ¨¡å¼**ï¼š
  - SARound åœ¨é¢„æµ‹å’Œå®æµ‹èŠ‚èƒ½ä¸Šå‡æ˜¾è‘—é¢†å…ˆã€‚
  - é«˜ä¿¡é“è´¨é‡ä¸‹ä¼˜åŠ¿æ›´å¤§ï¼ˆå› æ›´å¤šèµ„æºå¯è¢«ç²¾ç»†åˆ†é…ï¼‰ã€‚
- **SchedRemain æ¨¡å¼**ï¼š
  - æ‰€æœ‰ç®—æ³•å®æµ‹èŠ‚èƒ½é«˜äºé¢„æµ‹å€¼ï¼ˆå°¤å…¶åœ¨HIGHæ¡ä»¶ä¸‹ï¼‰ï¼Œè¯´æ˜åŠ¨æ€ä¿¡é“æ”¹å–„å¸¦æ¥é¢å¤–æ”¶ç›Šã€‚
  - SARound ä¾ç„¶æœ€ä¼˜ï¼Œä½†ç›¸å¯¹å·®è·ç¼©å°ã€‚
  - **å®æµ‹èŠ‚èƒ½åè€Œæ›´é«˜**ï¼šå› ä¸ºä¿ç•™å·²æœ‰æœåŠ¡å‡å°‘äº†é‡å¤åˆå§‹åŒ–å¼€é”€ï¼Œæå‡äº†æ•´ä½“ååã€‚

### å¯æ‰©å±•æ€§æµ‹è¯•ï¼ˆå›¾7ï¼‰
- **éšç€è¯·æ±‚é‡å¢åŠ **ï¼š
  - SARound çš„æ€§èƒ½ä¼˜åŠ¿è¿›ä¸€æ­¥æ‰©å¤§ï¼ˆLP roundingè¯¯å·®éšè§„æ¨¡å¢å¤§è€Œç¨€é‡Šï¼‰ã€‚
  - æ‰§è¡Œæ—¶é—´å‘ˆ**è¿‘ä¼¼çº¿æ€§å¢é•¿**ï¼Œä¼˜äº Iterativeï¼ˆçº¦å¿«5.5å€ï¼‰ï¼Œç•¥æ…¢äº Greedyï¼ˆ1.3å€ï¼‰å’Œ IDAssignï¼ˆ0.9å€ï¼‰ï¼Œä½†ä»å…·å¤‡å®ç”¨å¯è¡Œæ€§ã€‚
- è¡¨æ˜ SARound å…·å¤‡è‰¯å¥½çš„**runtime scalability**ã€‚

### æ¶ˆèå®éªŒï¼ˆéšå«åˆ†æï¼‰
è™½ç„¶æœªæ˜ç¡®å‘½åæ¶ˆèå®éªŒï¼Œä½†æ–‡ä¸­é€šè¿‡ä»¥ä¸‹æ–¹å¼ä½“ç°è®¾è®¡æœ‰æ•ˆæ€§ï¼š
- å¯¹æ¯” **SchedAll vs SchedRemain**ï¼šæ­ç¤ºæœåŠ¡æŒç»­æ€§å¯¹å‡å°‘åˆå§‹åŒ–å¼€é”€çš„é‡è¦æ€§ã€‚
- åˆ†æ **SRSåé¦ˆæœºåˆ¶**ï¼šè¯æ˜å…¶å¯åœ¨ä¸å½±å“ä»»åŠ¡æ‰§è¡Œçª—å£çš„å‰æä¸‹å®ç°ä¿¡é“è‡ªé€‚åº”æ§åˆ¶ã€‚
- ç†è®ºè¯æ˜ FloorRd ä¸ SARound çš„è¿‘ä¼¼æ¯”ï¼ŒéªŒè¯ LP rounding + local-ratio ç»“åˆçš„æœ‰æ•ˆæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **SARound æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•**ï¼šåœ¨å„ç§ç½‘ç»œè´¨é‡å’Œè°ƒåº¦æ¨¡å¼ä¸‹ï¼Œæ— è®ºæ˜¯é¢„æµ‹è¿˜æ˜¯å®æµ‹èŠ‚èƒ½ï¼ŒSARound å‡ä¸€è‡´é¢†å…ˆï¼Œæœ€é«˜è¶…å‡ºåŸºçº¿è¾¾ **77%**ã€‚
2. **åŠ¨æ€ä¿¡é“åé¦ˆè‡³å…³é‡è¦**ï¼šåŸºäº SRS çš„åœ¨çº¿å¸è½½æ§åˆ¶æœºåˆ¶æœ‰æ•ˆåº”å¯¹ä¿¡é“æ³¢åŠ¨ï¼Œåœ¨ä¿¡é“æ¢å¤ååŠæ—¶é‡å¯å¸è½½ï¼Œæé«˜èµ„æºåˆ©ç”¨ç‡ã€‚
3. **è°ƒåº¦ä¸æ‰§è¡Œè§£è€¦æå‡çµæ´»æ€§**ï¼šå°†è°ƒåº¦å’ŒæœåŠ¡åˆå§‹åŒ–å‰ç½®ï¼Œä½¿å¾—å³ä½¿é‡‡ç”¨è¾ƒå¤æ‚çš„ç®—æ³•ä¹Ÿä¸ä¼šå½±å“ä»»åŠ¡æ‰§è¡Œæ—¶é—´çª—ï¼Œé€‚åˆçŸ­å‘¨æœŸä»»åŠ¡ã€‚
4. **VecSim å¡«è¡¥ç ”ç©¶ç©ºç™½**ï¼šé¦–ä¸ªæ”¯æŒå®Œæ•´ DOAP ç”Ÿå‘½å‘¨æœŸä»¿çœŸçš„å¼€æºå·¥å…·ï¼Œå¯ç”¨äºæœªæ¥ VEC ç ”ç©¶çš„æ ‡å‡†åŒ–è¯„ä¼°ã€‚

### æ–¹æ³•å±€é™æ€§
- **é›†ä¸­å¼æ¶æ„å•ç‚¹æ•…éšœé£é™©**ï¼šä¾èµ–ä¸­å¤®è°ƒåº¦å™¨ï¼Œä¸€æ—¦å¤±æ•ˆä¼šå½±å“æ•´ä¸ªç³»ç»Ÿåè°ƒã€‚
- **æœåŠ¡è¿ç§»æœªè€ƒè™‘**ï¼šå½“å‰æ¡†æ¶æœªæ”¯æŒä»»åŠ¡åœ¨ä¸åŒRSUé—´åŠ¨æ€è¿ç§»ï¼Œé™åˆ¶äº†é«˜é€Ÿç§»åŠ¨åœºæ™¯ä¸‹çš„é€‚ç”¨æ€§ã€‚
- **å†…å­˜ç­‰é™„åŠ èµ„æºçº¦æŸæœªå»ºæ¨¡**ï¼šç›®å‰ä»…è€ƒè™‘å¸¦å®½ä¸è®¡ç®—èµ„æºï¼Œæœªçº³å…¥æœåŠ¡å™¨å†…å­˜ã€å­˜å‚¨ç­‰ç»´åº¦ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢**å»ä¸­å¿ƒåŒ–è°ƒåº¦æ¶æ„**ï¼ˆdecentralized schedulerï¼‰ï¼Œå¢å¼ºç³»ç»Ÿé²æ£’æ€§ã€‚
- ç ”ç©¶æ”¯æŒ**æœåŠ¡æ— ç¼è¿ç§»**çš„æœºåˆ¶ï¼Œé€‚åº”é«˜é€Ÿç§»åŠ¨åœºæ™¯ã€‚
- å°†æ¡†æ¶æ‰©å±•è‡³åŒ…å«**å¤šç»´èµ„æºçº¦æŸ**ï¼ˆå¦‚å†…å­˜ã€èƒ½è€—é¢„ç®—ï¼‰çš„æ›´å¤æ‚åœºæ™¯ã€‚
- æ”¯æŒæ›´å¤šç±»å‹çš„**QoSçº¦æŸ**ï¼Œå¦‚ M-K æˆªæ­¢æ—¶é—´æ¨¡å‹ã€å¯é æ€§è¦æ±‚ç­‰ã€‚

---

> âœ… æ€»ç»“ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå…¼å…·**ç†è®ºä¸¥è°¨æ€§**ä¸**å·¥ç¨‹å®ç”¨æ€§**çš„ VEC å®æ—¶ä»»åŠ¡å¸è½½æ¡†æ¶ã€‚SARound ç®—æ³•åœ¨ç†è®ºä¸Šæ”¹è¿›äº†è¿‘ä¼¼æ¯”ï¼Œåœ¨å®è·µä¸­è¡¨ç°å‡ºå“è¶Šçš„èµ„æºåˆ©ç”¨æ•ˆç‡ï¼›é…å¥—çš„åœ¨çº¿æ§åˆ¶æœºåˆ¶ä¸ VecSim ä»¿çœŸå™¨å…±åŒæ„æˆäº†ä¸€ä¸ªå®Œæ•´çš„è§£å†³æ–¹æ¡ˆï¼Œæ¨åŠ¨äº† VEC é¢†åŸŸå‘åŠ¨æ€ã€å¯é ã€å¯éªŒè¯çš„æ–¹å‘å‘å±•ã€‚

</details>

---

### 9. [RAST-MoE-RL: A Regime-Aware Spatio-Temporal MoE Framework for Deep Reinforcement Learning in Ride-Hailing](https://arxiv.org/abs/2512.13727)

**Authors**: Yuhan Tang, Kangxin Cui, Jung Ho Park, Yibo Zhao, Xuan Jiang, Haoze He, Dingyi Zhuang, Shenhao Wang, Jiangbo Yu, Haris Koutsopoulos, Jinhua Zhao  
**Category**: cs.LG  
**Published**: 2025-12-17  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.13727v1  

#### Abstract
Ride-hailing platforms face the challenge of balancing passenger waiting times with overall system efficiency under highly uncertain supply-demand conditions. Adaptive delayed matching creates a trade-off between matching and pickup delays by deciding whether to assign drivers immediately or batch r...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# RAST-MoE-RL: A Regime-Aware Spatio-Temporal MoE Framework for Deep Reinforcement Learning in Ride-Hailing  
**æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
è¯¥è®ºæ–‡é’ˆå¯¹ç½‘çº¦è½¦å¹³å°ä¸­çš„**è‡ªé€‚åº”å»¶è¿ŸåŒ¹é…ï¼ˆadaptive delayed matchingï¼‰å†³ç­–é—®é¢˜**ï¼Œæ—¨åœ¨å¹³è¡¡ä¹˜å®¢ç­‰å¾…æ—¶é—´ï¼ˆmatching delayï¼‰ä¸æ¥é©¾æ—¶é—´ï¼ˆpickup delayï¼‰ä¹‹é—´çš„æƒè¡¡ã€‚ä¼ ç»Ÿæ–¹æ³•é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **äº¤é€šåŠ¨æ€å»ºæ¨¡ä¸çœŸå®**ï¼šå¤šæ•°RLæ¨¡å‹å¿½ç•¥æ‹¥å µåé¦ˆæœºåˆ¶ï¼Œä½¿ç”¨é™æ€é€Ÿåº¦å‡è®¾ã€‚
- **å¥–åŠ±è®¾è®¡è„†å¼±**ï¼šå›ºå®šæƒé‡çš„å¥–åŠ±å‡½æ•°æ˜“å¯¼è‡´â€œreward hackingâ€è¡Œä¸ºï¼ˆå¦‚æ— é™æŒæœ‰è¯·æ±‚æˆ–ç«‹å³åŒ¹é…ï¼‰ã€‚
- **è¡¨å¾èƒ½åŠ›ä¸è¶³**ï¼šæ ‡å‡†MLPæˆ–æµ…å±‚ç¼–ç å™¨éš¾ä»¥æ•æ‰å¤æ‚æ—¶ç©ºæ¨¡å¼ï¼Œå°¤å…¶åœ¨ä¾›éœ€å‰§çƒˆå˜åŒ–çš„ä¸åŒäº¤é€šâ€œåˆ¶åº¦â€ï¼ˆregimeï¼‰ä¸‹æ³›åŒ–å·®ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
ä½œè€…æå‡º **RAST-MoE-RL** æ¡†æ¶ï¼ŒåŒ…å«ä¸‰å¤§æ ¸å¿ƒåˆ›æ–°ï¼š

#### ï¼ˆ1ï¼‰**Regime-Aware Spatio-Temporal MDP (RAST-MDP)**
- å°†è‡ªé€‚åº”åŒ¹é…å½¢å¼åŒ–ä¸ºä¸€ä¸ª**åˆ¶åº¦æ„ŸçŸ¥çš„é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹**ï¼Œæ˜¾å¼å»ºæ¨¡ä¾›éœ€ä¸å¹³è¡¡ã€‚
- å¼•å…¥**ç‰©ç†ä¿¡æ¯é©±åŠ¨çš„æ—…è¡Œæ—¶é—´ä»£ç†æ¨¡å‹ï¼ˆphysics-informed travel-time surrogateï¼‰**ï¼ŒåŸºäºå®è§‚åŸºæœ¬å›¾ï¼ˆMFDï¼‰æ„å»ºåŸå¸‚çº§é€Ÿåº¦-å¯†åº¦åé¦ˆï¼Œå®ç°é«˜æ•ˆä¸”çœŸå®çš„æ‹¥å µæ¨¡æ‹Ÿï¼Œæ”¯æŒç™¾ä¸‡çº§RL rolloutã€‚

#### ï¼ˆ2ï¼‰**Anti-Hacking è‡ªé€‚åº”å¥–åŠ±æœºåˆ¶**
- è®¾è®¡å¢é‡æˆæœ¬å¥–åŠ±å‡½æ•°ï¼Œç»“åˆ**åœ¨çº¿è°ƒæ•´çš„æ‹‰æ ¼æœ—æ—¥ä¹˜å­ Î»** åŠ¨æ€æƒ©ç½šæœåŠ¡è´¨é‡è¿è§„ï¼ˆå¦‚è¶…æ—¶åŒ¹é…ï¼‰ã€‚
- é¿å…æ‰‹åŠ¨è°ƒå‚ï¼Œä½¿ç­–ç•¥è‡ªåŠ¨å­¦ä¹ åŒ¹é…-æ¥é©¾çš„åŠ¨æ€å¹³è¡¡ï¼Œé˜²æ­¢å´©æºƒæ€§ç­–ç•¥ï¼ˆå¦‚æ°¸è¿œä¸åŒ¹é…æˆ–æ°¸è¿œç«‹å³åŒ¹é…ï¼‰ã€‚

#### ï¼ˆ3ï¼‰**RAST-MoEï¼šåˆ¶åº¦æ„ŸçŸ¥çš„ç¨€ç–MoEç¼–ç å™¨**
- æå‡ºä¸€ç§è½»é‡çº§ï¼ˆä»…12Må‚æ•°ï¼‰ã€åŸºäº**Mixture-of-Experts (MoE)** çš„æ—¶ç©ºç¼–ç å™¨ã€‚
- ä¸åŒä¸“å®¶è‡ªåŠ¨ä¸“ä¸šåŒ–äºä¸åŒäº¤é€šåˆ¶åº¦ï¼ˆå¦‚æ—©é«˜å³°ã€å¤œé—´ä½éœ€æ±‚ï¼‰ï¼Œé€šè¿‡å…¨å±€çŠ¶æ€è·¯ç”±é€‰æ‹©Top-Kä¸“å®¶ï¼Œæå‡è¡¨è¾¾èƒ½åŠ›åŒæ—¶ä¿æŒè®¡ç®—æ•ˆç‡ã€‚
- é‡‡ç”¨è½»é‡è´Ÿè½½å‡è¡¡æœºåˆ¶ï¼Œå…è®¸ä¸“å®¶åˆ©ç”¨ç‡è‡ªç„¶å€¾æ–œï¼Œé¿å…æŠ‘åˆ¶å¯¹ç½•è§ä½†å…³é”®åœºæ™¯ï¼ˆå¦‚çªå‘æ‹¥å µï¼‰çš„ä¸“ä¸šåŒ–ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **è¡¨è¾¾èƒ½åŠ›** | MoEç»“æ„æ˜¾è‘—ä¼˜äºMLP/Dense Transformerï¼Œåœ¨å°å‚æ•°é‡ä¸‹å®ç°æ›´é«˜æœ‰æ•ˆå®¹é‡ |
| **è®­ç»ƒç¨³å®šæ€§** | è‡ªé€‚åº”å¥–åŠ±é˜²æ­¢reward hackingï¼Œè®­ç»ƒæ”¶æ•›ç¨³å®šï¼ˆè§Î»æ”¶æ•›å›¾ï¼‰ |
| **æ³›åŒ–æ€§** | åœ¨æœªè§è¿‡çš„ä¾›éœ€æ¨¡å¼ã€å¤©æ°”æ‰°åŠ¨ã€å±€éƒ¨äº‹æ•…ç­‰OODåœºæ™¯ä¸‹è¡¨ç°é²æ£’ |
| **æ•ˆç‡** | ä»£ç†æ¨¡å‹æ”¯æŒO(1)æŸ¥è¯¢ï¼ŒMoEç¨€ç–æ¿€æ´»ä¿è¯æ¨ç†é«˜æ•ˆï¼Œé€‚åˆåŸå¸‚è§„æ¨¡éƒ¨ç½² |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **æ•°æ®æ¥æº**ï¼šåŠ å·å…¬å…±äº‹ä¸šå§”å‘˜ä¼šï¼ˆCPUCï¼‰TNCæ•°æ®é—¨æˆ·æä¾›çš„2019å¹´Uberå’ŒLyftè¡Œç¨‹æ•°æ®ã€‚
- **åŒºåŸŸ**ï¼šæ—§é‡‘å±±å¿ï¼ˆSan Francisco Countyï¼‰ï¼Œæ—¥å‡çº¦17ä¸‡è®¢å•ï¼Œé«˜å¯†åº¦ã€é«˜æ‹¥å µä»£è¡¨æ€§å¼ºã€‚
- **é¢„å¤„ç†**ï¼šå°†åŸå¸‚åˆ’åˆ†ä¸ºHÃ—Wç½‘æ ¼å•å…ƒï¼ŒæŒ‰å°æ—¶èšåˆä¾›éœ€æµé‡ã€åˆ°è¾¾ç‡ç­‰ç‰¹å¾ã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**
- **MDPå®šä¹‰**ï¼š
  - **State**ï¼šæ—¶é—´ã€å„åŒºåŸŸæœªåŒ¹é…ä¹˜å®¢æ•° $n_p$ã€ç©ºé—²å¸æœºæ•° $n_d$ã€ä¹˜å®¢/å¸æœºåˆ°è¾¾ç‡ $\lambda, \mu$
  - **Action**ï¼šæ¯ä¸ªåŒºåŸŸäºŒå…ƒå†³ç­– $a_i \in \{0,1\}$ï¼Œâ€œholdâ€ æˆ– â€œmatch nowâ€
  - **Transition**ï¼šåŸºäºMFDä»£ç†æ¨¡å‹æ›´æ–°è½¦è¾†ä½ç½®ã€è¯·æ±‚çŠ¶æ€ã€å¼•å…¥æ–°è¯·æ±‚
- **è®­ç»ƒæ¡†æ¶**ï¼šä»¥PPOä¸ºä¸»å¹²ç®—æ³•ï¼Œå…¼å®¹A2Cã€ACERã€GRPOç­‰ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - æ€»å¥–åŠ±ï¼ˆTotal Rewardï¼‰
  - å¹³å‡åŒ¹é…å»¶è¿Ÿï¼ˆMatching Delayï¼‰
  - å¹³å‡æ¥é©¾å»¶è¿Ÿï¼ˆPickup Delayï¼‰
  - æœåŠ¡è¿è§„ç‡ï¼ˆService-Quality Violationsï¼‰

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| ç±»åˆ« | åŸºçº¿æ–¹æ³• |
|------|--------|
| **RLç®—æ³•** | PPO, A2C, ACER, DQN, GRPO |
| **ç¼–ç å™¨ç»“æ„** | Plain MLP, ResMLP, Dense Transformer (12M/48M), GNN |
| **å¯å‘å¼ç­–ç•¥** | Instant Matching, Constant-Interval Batch Matching (20s) |
| **MoEå˜ä½“** | ä¸åŒä¸“å®¶æ•°Eä¸Top-Kç»„åˆï¼ˆå¦‚(8,2), (16,4), (32,8)ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**
åœ¨æ—§é‡‘å±±çœŸå®æ•°æ®ä¸Šï¼Œ**RAST-MoE (16 experts, top-4)** å–å¾—æœ€ä¼˜æ€§èƒ½ï¼š

| æŒ‡æ ‡ | æå‡å¹…åº¦ | å…·ä½“æ•°å€¼ |
|------|---------|--------|
| **æ€»å¥–åŠ±** | â†‘13% | ç›¸æ¯”ACER baseline |
| **å¹³å‡åŒ¹é…å»¶è¿Ÿ** | â†“10% | ä»~200sé™è‡³182s |
| **å¹³å‡æ¥é©¾å»¶è¿Ÿ** | â†“15% | ä»~600sé™è‡³523s |

> æ³¨ï¼šæ‰€æœ‰ç»“æœåœ¨æµ‹è¯•é›†ï¼ˆæœªè§æ—¶æ®µï¼‰ä¸ŠéªŒè¯ï¼Œç¡®ä¿éè¿‡æ‹Ÿåˆã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- **ä¼˜äºæ‰€æœ‰RLåŸºçº¿**ï¼šåœ¨PPOã€GRPOç­‰æ¡†æ¶ä¸‹ï¼ŒMoEç¼–ç å™¨ consistently æå‡æ€§èƒ½ã€‚
- **è¶…è¶Šå¤§å‚æ•°æ¨¡å‹**ï¼š
  - **12M MoE** è¡¨ç°ä¼˜äº **48M Dense Transformer**
  - æ˜¾ç¤ºMoEæ›´é«˜çš„å‚æ•°æ•ˆç‡ä¸è¡¨è¾¾èƒ½åŠ›
- **å‡»è´¥å¯å‘å¼ç­–ç•¥**ï¼š
  - Instant Matching åŒ¹é…å»¶è¿Ÿè™½ä½ä½†æ¥é©¾å»¶è¿Ÿé«˜è¾¾825s
  - MoEåœ¨ä¸¤è€…é—´å–å¾—æ›´ä¼˜æƒè¡¡

### **æ¶ˆèå®éªŒç»“æœ**
#### ï¼ˆ1ï¼‰**å¥–åŠ±æœºåˆ¶æœ‰æ•ˆæ€§**
- å›ºå®šæƒé‡ï¼ˆå¦‚8:1ï¼‰å¯¼è‡´æç«¯è¡Œä¸ºï¼š
  - 8:1 â†’ åŒ¹é…å»¶è¿Ÿâ‰ˆ0ï¼Œä½†æ¥é©¾å»¶è¿Ÿ>1700sï¼ˆç«‹å³åŒ¹é…è€—å°½å¸æœºï¼‰
  - 1:8 â†’ åŒ¹é…å»¶è¿Ÿ>2200sï¼ˆè¿‡åº¦æŒæœ‰ï¼‰
- **è‡ªé€‚åº”å¥–åŠ±** åœ¨è®­ç»ƒå’Œæµ‹è¯•ä¸­å‡ç¨³å®šï¼Œæ— reward hackingç°è±¡ï¼ˆè§Fig. 4ï¼‰

#### ï¼ˆ2ï¼‰**MoEé…ç½®é€‰æ‹©**
- **(16,4)** é…ç½®æœ€ä¼˜ï¼šé€‚åº¦å®¹é‡ä¸ç¨€ç–æ€§å¹³è¡¡
- æ›´å¤§ä¸“å®¶æ± ï¼ˆå¦‚64,8ï¼‰æ”¶ç›Šé€’å‡ç”šè‡³ä¸‹é™
- æ›´å°ï¼ˆå¦‚8,2ï¼‰åˆ™è¡¨è¾¾ä¸è¶³

#### ï¼ˆ3ï¼‰**ä¸“å®¶é‡è¦æ€§éªŒè¯ï¼ˆmaskingå®éªŒï¼‰**
- åˆ†åˆ«å±è”½é«˜é¢‘ä¸“å®¶ï¼ˆç»¿è‰²ï¼‰ä¸ä½é¢‘ä¸“å®¶ï¼ˆæ©™è‰²ï¼‰ï¼š
  - ä¸¤è€…å‡å¯¼è‡´**æ€§èƒ½æ˜¾è‘—ä¸‹é™**
  - è¯æ˜å³ä½¿æ˜¯ä½é¢‘ä¸“å®¶ä¹Ÿæ•æ‰å…³é”®ç¨€æœ‰åœºæ™¯ï¼ˆå¦‚æ™šé«˜å³°å¯åŠ¨ï¼‰
- æ”¯æŒâ€œpurposeful specializationâ€è€Œéè·¯ç”±å´©æºƒ

#### ï¼ˆ4ï¼‰**ç»Ÿè®¡æ˜¾è‘—æ€§**
- å¤šéšæœºç§å­å®éªŒï¼ˆ3 seedsï¼‰æ˜¾ç¤ºæ–¹å·®æå°ï¼ˆå¦‚åŒ¹é…å»¶è¿Ÿ std <1sï¼‰ï¼Œç»“æœå¯é ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**
1. **åˆ¶åº¦æ„ŸçŸ¥æ˜¯åŸå¸‚çº§æ§åˆ¶çš„å…³é”®**ï¼šä¾›éœ€-æ‹¥å µæ¨¡å¼å…·æœ‰æ˜æ˜¾å‘¨æœŸæ€§ä¸å¼‚è´¨æ€§ï¼Œå•ä¸€æ¨¡å‹éš¾ä»¥è¦†ç›–ï¼ŒMoEçš„ä¸“å®¶åˆ†å·¥å¤©ç„¶é€‚é…æ­¤éœ€æ±‚ã€‚
2. **è½»é‡MoEèƒœè¿‡å¤§æ¨¡å‹**ï¼šä»…12Må‚æ•°çš„RAST-MoEè¶…è¿‡48M Dense Transformerï¼Œè¯æ˜**ä¸“å®¶ä¸“ä¸šåŒ–å¸¦æ¥çš„æœ‰æ•ˆå®¹é‡æå‡è¿œè¶…å•çº¯å †å‚æ•°**ã€‚
3. **è‡ªé€‚åº”å¥–åŠ±è‡³å…³é‡è¦**ï¼šå›ºå®šç³»æ•°æ— æ³•åº”å¯¹åŠ¨æ€ç¯å¢ƒï¼Œè€Œåœ¨çº¿è°ƒèŠ‚çš„Î»èƒ½ç¨³å®šå¼•å¯¼ç­–ç•¥å­¦ä¹ åˆç†æƒè¡¡ã€‚
4. **çœŸå®ç‰©ç†åé¦ˆä¸å¯æ›¿ä»£**ï¼šåŸºäºMFDçš„ä»£ç†æ¨¡å‹ä¿ç•™äº†å…³é”®æ‹¥å µä¿¡å·ï¼ˆå¦‚å®¹é‡ä¸‹é™ï¼‰ï¼Œæ˜¯é•¿è§†é‡ä¿¡ç”¨åˆ†é…çš„åŸºç¡€ã€‚
5. **ç¨€æœ‰ä¸“å®¶æœ‰ä»·å€¼**ï¼šå³ä½¿æ¿€æ´»é¢‘ç‡ä½ï¼Œç‰¹å®šä¸“å®¶ä»è´Ÿè´£å…³é”®åœºæ™¯ï¼Œç§»é™¤åæ€§èƒ½ä¸‹é™ï¼Œè¯´æ˜MoEå®ç°äº†æœ‰æ„ä¹‰çš„åŠŸèƒ½åˆ†è§£ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¸“å®¶è§£é‡Šæ€§æœ‰é™**ï¼šå°½ç®¡åˆ†ææ˜¾ç¤ºä¸“å®¶ä¸ç‰¹å®šæ—¶æ®µç›¸å…³ï¼Œä½†ç²¾ç¡®è¯­ä¹‰ä»éš¾ç•Œå®šã€‚
- **ä¾èµ–å®è§‚åˆ†åŒº**ï¼šåŸºäºTAZçš„èšåˆå¯èƒ½ä¸¢å¤±å¾®è§‚è·¯å¾„ç»†èŠ‚ã€‚
- **é™æ€è·¯ç”±æ‹“æ‰‘**ï¼šODè·¯å¾„é¢„è®¡ç®—ï¼Œæœªè€ƒè™‘å®æ—¶è·¯å¾„é‡è§„åˆ’ã€‚
- **é›†ä¸­å¼æ¶æ„**ï¼šé€‚ç”¨äºå¹³å°çº§è°ƒåº¦ï¼Œéš¾ä»¥ç›´æ¥è¿ç§»åˆ°å»ä¸­å¿ƒåŒ–å¤šæ™ºèƒ½ä½“åœºæ™¯ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ¢ç´¢**åŠ¨æ€ä¸“å®¶è·¯ç”±æœºåˆ¶**ï¼Œé€‚åº”æ›´å‰§çƒˆåˆ†å¸ƒåç§»ã€‚
- ç»“åˆ**å¤šå°ºåº¦å»ºæ¨¡**ï¼ˆå¦‚åŒºåŸŸ+è·¯æ®µçº§ï¼‰æå‡ç²¾åº¦ã€‚
- æ‰©å±•è‡³**æ‹¼è½¦ï¼ˆride-poolingï¼‰ä¸é‡å®šä½è”åˆä¼˜åŒ–**ã€‚
- ç ”ç©¶**å…¬å¹³æ€§çº¦æŸ**ï¼Œé¿å…ç®—æ³•åŠ å‰§åœ°ç†æœåŠ¡ä¸å¹³ç­‰ã€‚
- æ¢ç´¢**MoEåœ¨å…¶ä»–å¤§è§„æ¨¡æ—¶ç©ºå†³ç­–ä»»åŠ¡**ä¸­çš„åº”ç”¨ï¼ˆå¦‚ç‰©æµã€ç”µç½‘è°ƒåº¦ï¼‰ã€‚

---

> **Reproducibility Statement**ï¼šä½œè€…æ‰¿è¯ºå…¬å¼€æ•°æ®é¢„å¤„ç†ä»£ç ã€æ¨¡æ‹Ÿå™¨ã€è®­ç»ƒè„šæœ¬ä¸è¶…å‚æ•°ï¼Œç¡®ä¿ç»“æœå¯å¤ç°ã€‚

</details>

---

### 10. [AI-Powered Annotation Pipelines for Stabilizing Large Language Models: A Human-AI Synergy Approach](https://arxiv.org/abs/2512.13714)

**Authors**: Gangesh Pathak, Prasanna Kumar  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.13714v1  

#### Abstract
LLM implementations are failing in highly regulated industries owing to instability issues, inconsistent reasoning, hallucinations and performance variability, especially in workflows. These reliability issues restrict safe use of LLM in areas that need the precision of facts and consistent behavior...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*AI-Powered Annotation Pipelines for Stabilizing Large Language Models: A Human-AI Synergy Approach*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é«˜é£é™©ã€é«˜ç›‘ç®¡é¢†åŸŸï¼ˆå¦‚åŒ»ç–—ã€é‡‘èã€æ³•å¾‹ï¼‰çš„åº”ç”¨å—åˆ°å…¶**ä¸ç¨³å®šæ€§**çš„ä¸¥é‡åˆ¶çº¦ã€‚å…·ä½“è¡¨ç°ä¸ºï¼š
- **è¯­ä¹‰æ¼‚ç§»ï¼ˆSemantic divergenceï¼‰**ï¼šç›¸åŒæ„å›¾çš„æç¤ºè¯ç”Ÿæˆä¸åŒå«ä¹‰çš„å›ç­”ã€‚
- **å¹»è§‰ï¼ˆHallucinationï¼‰**ï¼šè‡ªä¿¡åœ°è¾“å‡ºé”™è¯¯æˆ–è™šæ„ä¿¡æ¯ã€‚
- **æ¨ç†å´©æºƒï¼ˆReasoning breakdownï¼‰**ï¼šé€»è¾‘çŸ›ç›¾æˆ–æ¨ç†æ–­è£‚ã€‚
- **ä¼šè¯æ¼‚ç§»ï¼ˆSession driftï¼‰**ï¼šå¤šè½®å¯¹è¯ä¸­è¾“å‡ºè´¨é‡éšæ—¶é—´ä¸‹é™ã€‚

ç°æœ‰çš„å¯¹é½æ–¹æ³•ï¼ˆå¦‚RLHFã€ç›‘ç£å¾®è°ƒï¼‰è™½èƒ½æå‡æ¨¡å‹è¡Œä¸ºä¸€è‡´æ€§ï¼Œä½†ä¾èµ–å¤§é‡äººå·¥æ ‡æ³¨ï¼Œæˆæœ¬é«˜æ˜‚ä¸”éš¾ä»¥æŒç»­æ‰©å±•ï¼Œæ— æ³•ç³»ç»ŸåŒ–è§£å†³é•¿æœŸç¨³å®šæ€§é—®é¢˜ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡ºäº†ä¸€ç§**åŸºäºAIé©±åŠ¨çš„æ ‡æ³¨æµæ°´çº¿ï¼ˆAI-Powered Annotation Pipelineï¼‰**ï¼Œé‡‡ç”¨**äººæœºååŒï¼ˆHuman-AI Synergyï¼‰** èŒƒå¼æ¥ç³»ç»Ÿæ€§è¯†åˆ«ã€æ ‡æ³¨å¹¶ä¿®å¤LLMè¾“å‡ºä¸­çš„ä¸ç¨³å®šæ€§æ¨¡å¼ã€‚

#### æ ¸å¿ƒæ¡†æ¶ï¼šå››é˜¶æ®µé—­ç¯æµç¨‹
1. **AIè‡ªåŠ¨æ ‡æ³¨ï¼ˆAutomated Annotationï¼‰**  
   ä½¿ç”¨è½»é‡çº§LLMä½œä¸ºâ€œä¸“å®¶æ ‡æ³¨å™¨â€ï¼Œä»**è¯­ä¹‰ä¸€è‡´æ€§ï¼ˆSemantic Consistencyï¼‰ã€äº‹å®å‡†ç¡®æ€§ï¼ˆFactual Accuracyï¼‰ã€é€»è¾‘è¿è´¯æ€§ï¼ˆLogical Coherenceï¼‰** ä¸‰ä¸ªç»´åº¦æ£€æµ‹ä¸ç¨³å®šæ€§ã€‚
   
2. **é€‰æ‹©æ€§äººç±»éªŒè¯ï¼ˆSelective Human Validationï¼‰**  
   ä»…å°†ä½ç½®ä¿¡åº¦ã€çŸ›ç›¾æ€§æˆ–é«˜é£é™©æ¡ˆä¾‹äº¤ç”±äººç±»ä¸“å®¶å®¡æŸ¥ï¼Œç¡®ä¿æ ‡æ³¨è´¨é‡çš„åŒæ—¶å¤§å¹…é™ä½äººåŠ›æˆæœ¬ã€‚

3. **åé¦ˆé›†æˆä¸æ¨¡å‹å†è®­ç»ƒï¼ˆFeedback Integration & Retrainingï¼‰**  
   å°†éªŒè¯åçš„é«˜è´¨é‡æ ‡æ³¨ç”¨äº**ç¨³å®šæ€§ä¸“é¡¹å¾®è°ƒï¼ˆStability Fine-Tuningï¼‰** å’Œ**åŸºäºå¥–åŠ±çš„æ ¡å‡†ï¼ˆRIC-Based Stabilisationï¼‰**ï¼Œå½¢æˆé—­ç¯åé¦ˆæœºåˆ¶ã€‚

4. **æŒç»­ç›‘æ§ä¸è¿­ä»£ä¼˜åŒ–ï¼ˆContinuous Monitoringï¼‰**  
   é€šè¿‡æ¨¡å—åŒ–æ¶æ„å®ç°å®æ—¶ç¨³å®šæ€§æŒ‡æ ‡è¿½è¸ªä¸æ¨¡å‹æ›´æ–°ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚RLHF/SFTï¼‰ | æœ¬æ–‡æ–¹æ³• |
|------|------------------------|---------|
| **å¯æ‰©å±•æ€§** | ä¾èµ–å¤§è§„æ¨¡äººå·¥æ ‡æ³¨ï¼Œéš¾ä»¥æ‰©å±• | AIè‡ªåŠ¨åŒ–åˆç­›ï¼Œäººç±»ä»…ä»‹å…¥å…³é”®æ¡ˆä¾‹ï¼Œæ˜¾è‘—é™ä½æˆæœ¬ |
| **ç¨³å®šæ€§è¡¡é‡** | ä¾§é‡å•æ¬¡å“åº”æ­£ç¡®æ€§ï¼Œå¿½è§†è¾“å‡ºå˜å¼‚æ€§ | å¼•å…¥**ç¨³å®šæ€§æŒ‡æ•°ï¼ˆStability Index, SIï¼‰**ç­‰é‡åŒ–æŒ‡æ ‡ |
| **æŒç»­æ€§** | å¤šä¸ºä¸€æ¬¡æ€§å¯¹é½ï¼Œéƒ¨ç½²åç¼ºä¹æŒç»­ä¼˜åŒ– | æ„å»º**ç¨³å®šæ€§åé¦ˆå¾ªç¯ï¼ˆStability Feedback Loopsï¼‰**ï¼Œæ”¯æŒç”Ÿå‘½å‘¨æœŸå†…æŒç»­å¢å¼º |
| **ä¼¦ç†ä¸å¯é æ€§** | çº¯AIæ ‡æ³¨æ˜“æ”¾å¤§åè§ï¼›çº¯äººå·¥æ ‡æ³¨ä¸»è§‚æ€§å¼º | äººæœºååŒä¿éšœæ ‡æ³¨å‡†ç¡®æ€§å’Œé“å¾·åˆè§„æ€§ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

| æ•°æ®é›† | ç”¨é€” | ç¨³å®šæ€§å‹åŠ›æµ‹è¯•è®¾è®¡ |
|-------|------|------------------|
| **TruthfulQA** | æ£€æµ‹å¹»è§‰ä¸äº‹å®é”™è¯¯ | æ¯ä¸ªé—®é¢˜ç”Ÿæˆ5â€“10ç§åŒä¹‰æ”¹å†™ç‰ˆæœ¬ |
| **GSM8K / Synthetic Multi-Turn Reasoning** | æµ‹è¯•é€»è¾‘ä¸€è‡´æ€§ä¸é“¾å¼æ¨ç†ç¨³å®šæ€§ | åŠ å…¥å¹²æ‰°é¡¹è¡¨è¿°ä¸ä¸Šä¸‹æ–‡é‡æ’åº |
| **Knowledge-Grounded Dialogues**ï¼ˆåŒ»ç–—/æ•™è‚²å­é›†ï¼‰ | æµ‹é‡å¤šè½®å¯¹è¯ä¸­çš„ä¸€è‡´æ€§ | æ‰©å±•å¤šè½®å˜ä½“å¹¶æ³¨å…¥æ­§ä¹‰ |

> æ‰€æœ‰æ•°æ®é›†å‡æ„å»ºäº†ä¸“é—¨çš„â€œç¨³å®šæ€§å‹åŠ›æµ‹è¯•å­é›†â€ï¼Œä»¥ä¸»åŠ¨è§¦å‘ä¸ç¨³å®šæ€§æ¨¡å¼ã€‚

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

#### **åŸºçº¿æ¨¡å‹**
| æ¨¡å‹ | è®­ç»ƒæ–¹å¼ | é¢„æœŸè¡Œä¸º |
|------|----------|---------|
| **Baseline-1 (SFT)** | ä»…æŒ‡ä»¤å¾®è°ƒ | é«˜ä»»åŠ¡å‡†ç¡®ç‡ï¼Œä½†è¾“å‡ºæ–¹å·®å¤§ |
| **Baseline-2 (RLHF)** | åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹  | å¯¹é½æ›´å¥½ï¼Œä½†åœ¨æç¤ºæ”¹å†™ä¸‹ä»å­˜åœ¨æ¼‚ç§» |

#### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | å®šä¹‰ | ç›®æ ‡ |
|------|------|------|
| **Stability Index (SI)** | åŒä¹‰æç¤ºä¸‹å“åº”çš„è¯­ä¹‰æ–¹å·® | è¶Šä½è¶Šå¥½ |
| **Factual Consistency (FC)** | å›ç­”ä¸å‚è€ƒç­”æ¡ˆçš„äº‹å®ä¸€è‡´æ€§ | è¶Šé«˜è¶Šå¥½ |
| **Annotation Precision (AP)** | è‡ªåŠ¨æ ‡æ³¨ä¸äººå·¥æ ¸æŸ¥çš„ä¸€è‡´ç‡ | è¶Šé«˜è¶Šå¥½ |
| **Response Diversity Ratio (RDR)** | åŸºäºç†µçš„è¯­ä¹‰å¤šæ ·æ€§åº¦é‡ | å¹³è¡¡å¤šæ ·æ€§ä¸æ¼‚ç§» |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å®šé‡ç»“æœå¯¹æ¯”**

| Model | SI â†“ | FC â†‘ | AP â†‘ | RDR |
|-------|------|------|------|-----|
| Baseline-1 (SFT) | 0.41 | 72% | â€” | 0.52 |
| Baseline-2 (RLHF) | 0.33 | 81% | 78% | 0.47 |
| **Stabilized Model** | **0.18** | **92%** | **94%** | **0.45** |

#### **å…³é”®æ€§èƒ½æå‡**
- **ç›¸æ¯”SFTåŸºçº¿**ï¼šç¨³å®šæ€§æå‡ **56%**ï¼ˆSIä»0.41â†’0.18ï¼‰
- **ç›¸æ¯”RLHFåŸºçº¿**ï¼šäº‹å®ä¸€è‡´æ€§æå‡ **14ä¸ªç™¾åˆ†ç‚¹**ï¼ˆFCä»81%â†’92%ï¼‰
- **è‡ªåŠ¨æ ‡æ³¨ç²¾åº¦è¾¾94%**ï¼Œè¡¨æ˜AIæ ‡æ³¨å™¨å…·å¤‡é«˜å¯é æ€§
- **RDRä¿æŒç¨³å®š**ï¼Œè¯´æ˜ç¨³å®šæ€§å¢å¼ºæœªç‰ºç‰²ç”Ÿæˆå¤šæ ·æ€§

---

### **å®šæ€§åˆ†æç¤ºä¾‹**

#### åŒ»ç–—é—®ç­”åœºæ™¯ï¼ˆâ€œæŠ—ç”Ÿç´ èƒ½å¦æ²»ç–—æµæ„Ÿï¼Ÿâ€ï¼‰
| æç¤ºå˜ä½“ | Baseline-1 è¾“å‡º | Baseline-2 è¾“å‡º | Stabilized Model è¾“å‡º |
|--------|------------------|------------------|------------------------|
| â€œCan antibiotics treat viral influenza?â€ | â€œYes, antibiotics help eliminate the influenza virus.â€ï¼ˆå¹»è§‰ï¼‰ | â€œSometimes antibiotics are prescribed for flu treatment.â€ï¼ˆè¯¯å¯¼ï¼‰ | â€œNo. Antibiotics treat bacterial infections, not viral influenza. They are only used if a secondary bacterial infection occurs.â€ï¼ˆå‡†ç¡®ä¸”ä¸€è‡´ï¼‰ |

> æ˜¾ç¤ºè¯¥æ–¹æ³•èƒ½åœ¨è¯­ä¹‰ç­‰ä»·çš„ä¸åŒæé—®ä¸‹ä¿æŒ**äº‹å®å¯¹é½ä¸é€»è¾‘ä¸€è‡´**ã€‚

#### æ¨ç†ç¨³å®šæ€§æµ‹è¯•
- åŸºçº¿æ¨¡å‹åœ¨æ•°å­¦åº”ç”¨é¢˜çš„ç­‰ä»·å˜ä½“ä¸Šå¸¸ç»™å‡ºä¸åŒç­”æ¡ˆã€‚
- ç¨³å®šåŒ–æ¨¡å‹å§‹ç»ˆè¿”å›**ç›¸åŒçš„è§£å†³æ–¹æ¡ˆä¸æ¸…æ™°çš„æ¨ç†æ­¥éª¤**ã€‚

---

### **æ¶ˆèå®éªŒï¼ˆéšå«åˆ†æï¼‰**

è™½ç„¶æ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»è®¨è®ºéƒ¨åˆ†å¯æ¨æ–­ä»¥ä¸‹è®¾è®¡è¦ç´ çš„å…³é”®ä½œç”¨ï¼š

| è®¾è®¡è¦ç´  | æ•ˆæœ |
|--------|------|
| **è‡ªåŠ¨åŒ–æ ‡æ³¨è§„æ¨¡åŒ–** | å¿«é€Ÿè¯†åˆ«ä¸ç¨³å®šæ€§æ¨¡å¼ï¼ŒåŠ é€Ÿåé¦ˆå‘¨æœŸ |
| **èšç„¦æ¨¡ç³Š/é«˜é£é™©çš„äººç±»å¹²é¢„** | é¿å…ç›²ç›®ä¿¡ä»»AIåˆ¤æ–­ï¼Œé˜²æ­¢é”™è¯¯ä¼ æ’­ |
| **ç¨³å®šæ€§åé¦ˆå¾ªç¯** | å®ç°è¡Œä¸ºçš„æŒç»­å¼ºåŒ–ä¸é•¿æœŸå¯é  |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**
1. **AIé©±åŠ¨çš„æ ‡æ³¨æµæ°´çº¿å¯æ˜¾è‘—æå‡LLMç¨³å®šæ€§**ï¼Œå°¤å…¶åœ¨é¢å¯¹æç¤ºæ”¹å†™å’Œå¤šè½®äº¤äº’æ—¶è¡¨ç°ç¨³å¥ã€‚
2. **äººæœºååŒæ˜¯å…³é”®**ï¼šå®Œå…¨ä¾èµ–AIå¯èƒ½å¯¼è‡´é”™è¯¯ç´¯ç§¯ï¼›å®Œå…¨ä¾èµ–äººç±»åˆ™ä¸å¯æ‰©å±•ã€‚**æˆ˜ç•¥æ€§äººç±»ä»‹å…¥**ï¼ˆå¦‚å®¡æ ¸ä½ç½®ä¿¡åº¦è¾“å‡ºï¼‰å¯åœ¨æœ€å°æˆæœ¬ä¸‹æœ€å¤§åŒ–æ•ˆæœã€‚
3. **ç¨³å®šæ€§å¯ä»¥è¢«é‡åŒ–ä¸ä¼˜åŒ–**ï¼šæå‡ºçš„SIã€FCç­‰æŒ‡æ ‡ä¸ºæ¨¡å‹å¯é æ€§æä¾›äº†æ–°çš„è¯„ä¼°ç»´åº¦ï¼Œè¶…è¶Šä¼ ç»Ÿçš„â€œå‡†ç¡®æ€§â€èŒƒå¼ã€‚
4. **ç¨³å®šæ€§å¢å¼ºä¸ç­‰äºåˆ›é€ åŠ›æŠ‘åˆ¶**ï¼šRDRæŒ‡æ ‡æ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨æå‡ä¸€è‡´æ€§çš„åŒæ—¶ä»ä¿ç•™åˆç†çš„ç”Ÿæˆå¤šæ ·æ€§ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
1. **è‡ªåŠ¨æ ‡æ³¨å™¨ä¾èµ–å¯å‘å¼è§„åˆ™è´¨é‡**ï¼šåœ¨ç¼ºä¹æ˜ç¡®ground truthçš„é¢†åŸŸï¼ˆå¦‚å“²å­¦ã€è‰ºæœ¯ï¼‰ï¼Œå¯èƒ½è¯¯åˆ¤éå¸¸è§„ä½†åˆç†çš„æ¨ç†ä¸ºé”™è¯¯ã€‚
2. **äººç±»éªŒè¯å­˜åœ¨ä¸»è§‚æ€§é£é™©**ï¼šè¯„å®¡è€…çš„èƒŒæ™¯ã€ç»éªŒå·®å¼‚å¯èƒ½å¼•å…¥åå·®ï¼Œå½±å“æ ‡æ³¨ä¸€è‡´æ€§ã€‚
3. **é¢†åŸŸæ³›åŒ–èƒ½åŠ›å¾…éªŒè¯**ï¼šå½“å‰å®éªŒé›†ä¸­äºäº‹å®æ¨ç†ä¸å¯¹è¯ä»»åŠ¡ï¼Œåœ¨å¿«é€Ÿæ¼”åŒ–çš„ä¸“ä¸šé¢†åŸŸï¼ˆå¦‚ç”Ÿç‰©åŒ»è¯ï¼‰éœ€åŠ¨æ€çŸ¥è¯†æ›´æ–°æœºåˆ¶ã€‚
4. **é”™è¯¯ä¼ æ’­é£é™©**ï¼šè‹¥è‡ªåŠ¨åŒ–æ ‡æ³¨é˜¶æ®µå‡ºç°ç³»ç»Ÿæ€§é”™è¯¯ä¸”æœªè¢«åŠæ—¶å‘ç°ï¼Œå¯èƒ½é€šè¿‡å†è®­ç»ƒâ€œç—…æ¯’å¼â€æ‰©æ•£ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **å¼€å‘å¯è§£é‡Šçš„è‡ªåŠ¨æ ‡æ³¨ä»£ç†ï¼ˆExplainable Annotator Agentsï¼‰**ï¼šä½¿å…¶èƒ½è¯´æ˜åˆ¤æ–­ä¾æ®ä¸ä¸ç¡®å®šæ€§æ¥æºï¼Œä¾¿äºäººç±»å¿«é€ŸéªŒè¯ã€‚
2. **å¤šæ¨¡å‹äº’è¯„æœºåˆ¶ï¼ˆCross-Model Review Ensemblesï¼‰**ï¼šè®©å¤šä¸ªLLMç›¸äº’å®¡æŸ¥è¾“å‡ºï¼Œè¯†åˆ«é€»è¾‘å¼‚å¸¸æˆ–çŸ¥è¯†å†²çªï¼Œæå‡è·¨æ¨¡å‹ç¨³å®šæ€§ã€‚
3. **æ„å»ºç»ˆèº«å­¦ä¹ ï¼ˆLifelong Learningï¼‰ç®¡é“**ï¼šå®ç°æ¨¡å‹åœ¨è¿è¡Œæ—¶å®æ—¶ç›‘æµ‹è‡ªèº«ç¨³å®šæ€§ï¼Œå¹¶ä¸»åŠ¨è§¦å‘ä¿®æ­£æœºåˆ¶ã€‚
4. **åŠ å¼ºé€æ˜æ€§ä¸å¯å®¡è®¡æ€§å·¥å…·å»ºè®¾**ï¼šç¡®ä¿æ•´ä¸ªpipelineçš„å†³ç­–è¿‡ç¨‹å¯è¿½æº¯ã€å¯è§£é‡Šã€å¯é—®è´£ã€‚

---

## æ€»ç»“

æœ¬æ–‡æå‡ºäº†ä¸€æ¡é€šå¾€**å¯ä¿¡ã€å¯æŒç»­ã€å¯æ‰©å±•çš„ä¸‹ä¸€ä»£LLMéƒ¨ç½²è·¯å¾„**ã€‚é€šè¿‡å°†**AIçš„æ•ˆç‡**ä¸**äººç±»çš„åˆ¤æ–­åŠ›**æœ‰æœºç»“åˆï¼Œæ„å»ºäº†ä¸€ä¸ªé¢å‘ç¨³å®šæ€§çš„é—­ç¯å¢å¼ºç³»ç»Ÿã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•ä¸ä»…èƒ½æ˜¾è‘—é™ä½è¾“å‡ºå˜å¼‚æ€§å’Œå¹»è§‰ç‡ï¼Œè¿˜èƒ½åœ¨ä¸ç‰ºç‰²åˆ›é€ æ€§çš„å‰æä¸‹æå‡æ¨¡å‹åœ¨é«˜é£é™©åœºæ™¯ä¸‹çš„å¯é æ€§ã€‚è¿™ä¸€**Human-AI Synergy**èŒƒå¼ä¸ºæœªæ¥LLMçš„å®‰å…¨è½åœ°æä¾›äº†é‡è¦çš„æ–¹æ³•è®ºåŸºç¡€ã€‚

</details>

---

### 11. [PortAgent: LLM-driven Vehicle Dispatching Agent for Port Terminals](https://arxiv.org/abs/2512.14417)

**Authors**: Jia Hu, Junqi Li, Weimeng Lin, Peng Jia, Yuxiong Ji, Jintao Lai  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.14417v1  

#### Abstract
Vehicle Dispatching Systems (VDSs) are critical to the operational efficiency of Automated Container Terminals (ACTs). However, their widespread commercialization is hindered due to their low transferability across diverse terminals. This transferability challenge stems from three limitations: high ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šPortAgent: LLM-driven Vehicle Dispatching Agent for Port Terminals

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

åœ¨è‡ªåŠ¨åŒ–é›†è£…ç®±ç å¤´ï¼ˆ**Automated Container Terminals, ACTs**ï¼‰ä¸­ï¼Œè½¦è¾†è°ƒåº¦ç³»ç»Ÿï¼ˆ**Vehicle Dispatching Systems, VDSs**ï¼‰å¯¹è¿è¥æ•ˆç‡è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰VDSåœ¨è·¨ç å¤´éƒ¨ç½²æ—¶é¢ä¸´ä¸‰å¤§ç“¶é¢ˆï¼š

- **é«˜åº¦ä¾èµ–æ¸¯å£æ“ä½œä¸“å®¶**ï¼šéœ€è¦ç»éªŒä¸°å¯Œçš„å·¥ç¨‹å¸ˆæˆ–è¿ç­¹å­¦ä¸“å®¶è¿›è¡Œå®šåˆ¶åŒ–è®¾è®¡ï¼›
- **å¯¹ç‰¹å®šåœºæ™¯æ•°æ®éœ€æ±‚é«˜**ï¼šå°¤å…¶æ˜¯åŸºäºæœºå™¨å­¦ä¹ çš„æ–¹æ³•éœ€å¤§é‡é«˜è´¨é‡è®­ç»ƒæ•°æ®ï¼›
- **éƒ¨ç½²è¿‡ç¨‹è€—æ—¶ä¸”ç¹ç**ï¼šæ¶‰åŠå¤šè§’è‰²åä½œä¸åå¤äººå·¥è°ƒè¯•ã€‚

è¿™äº›å› ç´ å¯¼è‡´VDSéš¾ä»¥å®ç°å¿«é€Ÿè¿ç§»å’Œå•†ä¸šåŒ–æ¨å¹¿ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **PortAgent** â€”â€” ä¸€ç§ç”±å¤§è¯­è¨€æ¨¡å‹ï¼ˆ**LLM**ï¼‰é©±åŠ¨çš„è½¦è¾†è°ƒåº¦ä»£ç†ç³»ç»Ÿï¼Œæ—¨åœ¨å…¨è‡ªåŠ¨å®ŒæˆVDSçš„è·¨ç»ˆç«¯è¿ç§»ä»»åŠ¡ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºä»¥ä¸‹ä¸‰ç‚¹è®¾è®¡ï¼š

#### âœ… è™šæ‹Ÿä¸“å®¶å›¢é˜Ÿï¼ˆVirtual Expert Team, VETï¼‰
- æ„å»ºä¸€ä¸ªç”±å››ä¸ªè™šæ‹Ÿä¸“å®¶ç»„æˆçš„åä½œå›¢é˜Ÿï¼Œåœ¨å•ä¸€LLMå®ä¾‹å†…é€šè¿‡ **Role-Prompting** æ¿€æ´»ä¸åŒè§’è‰²ï¼š
  - **Knowledge Retriever**ï¼šæ£€ç´¢ç›¸å…³é¢†åŸŸçŸ¥è¯†ï¼›
  - **Modeler**ï¼šå°†è‡ªç„¶è¯­è¨€éœ€æ±‚è½¬åŒ–ä¸ºæ•°å­¦ä¼˜åŒ–æ¨¡å‹ï¼›
  - **Coder**ï¼šç”Ÿæˆå¯æ‰§è¡Œä»£ç ï¼›
  - **Debugger**ï¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä¿®æ­£é”™è¯¯ã€‚
- è¯¥æœºåˆ¶å°†å¤æ‚é•¿é“¾æ¨ç†åˆ†è§£ä¸ºå¤šä¸ªçŸ­é“¾å­ä»»åŠ¡ï¼Œæ˜¾è‘—æå‡é€»è¾‘å¯é æ€§ï¼Œ**æ— éœ€äººç±»ä¸“å®¶ä»‹å…¥**ã€‚

#### âœ… å°‘æ ·æœ¬ç¤ºä¾‹å­¦ä¹  + RAGæœºåˆ¶ï¼ˆFew-shot Example Learning with RAGï¼‰
- åˆ©ç”¨ **Retrieval-Augmented Generation (RAG)** ä»é¢„æ„å»ºçš„çŸ¥è¯†åº“ä¸­æå–æœ€ç›¸å…³çš„å»ºæ¨¡åŸè¯­ï¼ˆmodeling primitivesï¼‰å’Œä»£ç èŒƒä¾‹ï¼ˆcode exemplarsï¼‰ï¼›
- æ”¯æŒä»…å‡­**å•ä¸ªç¤ºä¾‹**å³å¯å®Œæˆæœ‰æ•ˆè¿ç§»ï¼Œæå¤§é™ä½å¯¹ç»ˆç«¯ä¸“å±æ•°æ®çš„éœ€æ±‚ã€‚

#### âœ… è‡ªåŠ¨åŒ–çš„VDSè®¾è®¡æµç¨‹ + è‡ªæˆ‘çº æ­£æœºåˆ¶ï¼ˆSelf-Correction Loopï¼‰
- è®¾è®¡é—­ç¯å·¥ä½œæµï¼š`è¾“å…¥ â†’ æ¨¡å‹ç”Ÿæˆ â†’ ç¼–ç  â†’ æ‰§è¡Œ â†’ åæ€ â†’ ä¿®æ­£`ï¼›
- å€Ÿé‰´ **LLM Reflexion** æ¡†æ¶ï¼Œå¼•å…¥è‡ªæˆ‘åæ€èƒ½åŠ›ï¼Œä½¿ç³»ç»Ÿèƒ½è‡ªä¸»åˆ†æé”™è¯¯åŸå› å¹¶æŒ‡å¯¼ä¸‹ä¸€è½®ç”Ÿæˆï¼›
- å®ç°**æ— äººå¹²é¢„çš„ç«¯åˆ°ç«¯è‡ªåŠ¨åŒ–éƒ¨ç½²**ï¼Œå¤§å¹…ç¼©çŸ­éƒ¨ç½²æ—¶é—´ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | PortAgent |
|------|--------|---------|
| ä¸“å®¶ä¾èµ– | é«˜ï¼ˆéœ€ORä¸“å®¶/å·¥ç¨‹å¸ˆï¼‰ | âŒ å®Œå…¨æ¶ˆé™¤ |
| æ•°æ®éœ€æ±‚ | é«˜ï¼ˆå°¤å…¶RLç±»æ–¹æ³•ï¼‰ | âœ… ä»…éœ€1ä¸ªç¤ºä¾‹ |
| éƒ¨ç½²é€Ÿåº¦ | æ•°å°æ—¶è‡³æ•°å¤© | â±ï¸ å¹³å‡83ç§’ |
| å¯è½¬ç§»æ€§ | å·®ï¼Œéœ€é‡æ–°å¼€å‘ | âœ… åœ¨æœªè§åœºæ™¯ä¸‹æˆåŠŸç‡86.67%-100% |
| ç”¨æˆ·é—¨æ§› | é«˜ï¼ˆéœ€ä¸“ä¸šè¡¨è¿°ï¼‰ | âœ… æŠ€æœ¯å‘˜çº§æè¿°å³å¯ |

> PortAgenté¦–æ¬¡å®ç°äº†**å…ä¸“å®¶ã€ä½æ•°æ®ã€å¿«éƒ¨ç½²**çš„VDSè¿ç§»æ–¹æ¡ˆï¼Œæ¨åŠ¨ACTæ™ºèƒ½åŒ–ç³»ç»Ÿçš„æ ‡å‡†åŒ–ä¸æ™®åŠã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **æµ‹è¯•ä»»åŠ¡ç±»å‹**

ç ”ç©¶èšç„¦äº **Multi-AGV Path Planning (MAPP)** é—®é¢˜ï¼Œä½œä¸ºå…¸å‹VDSåº”ç”¨åœºæ™¯ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–æ•´ä¸ªAGVè½¦é˜Ÿçš„æ€»è¡Œé©¶æ—¶é—´ã€‚

### **æµ‹è¯•åœºæ™¯ï¼ˆScenarios for Testï¼‰**

é€‰å–ä¸‰ç§å…·æœ‰ä»£è¡¨æ€§çš„åŠ¨æ€çº¦æŸåœºæ™¯è¿›è¡ŒéªŒè¯ï¼š

| åœºæ™¯ | æè¿° |
|------|------|
| **Road Closure** | èŠ‚ç‚¹6ä¸7ä¹‹é—´çš„åŒå‘é“è·¯å› ç»´æŠ¤å…³é—­ |
| **Forbidden Roads for Specific Trucks** | ç‰¹å®šAGVï¼ˆå¦‚è¶…é«˜è½¦è¾†ï¼‰ç¦æ­¢é€šè¡ŒæŸäº›è·¯æ®µï¼ˆå¦‚ä½æ¡¥ï¼‰ |
| **Designated Routes for Dangerous Goods** | å±é™©å“è¿è¾“ä»»åŠ¡å¿…é¡»ç»è¿‡æŒ‡å®šå®‰å…¨è·¯å¾„ï¼ˆå¦‚6â†’10â†’11ï¼‰ |

å®éªŒç½‘ç»œè§„æ¨¡ï¼š30è¾†AGVï¼Œ20ä¸ªèŠ‚ç‚¹ï¼ˆè§å›¾8ï¼‰ï¼Œå…±ç”Ÿæˆ **15ä¸ªåŸºç¡€å®ä¾‹**ã€‚

---

### **ç”¨æˆ·è¾“å…¥çš„ä¸“ä¸šæ°´å¹³æ¨¡æ‹Ÿ**

ä¸ºéªŒè¯å¯¹ç”¨æˆ·ä¸“ä¸šçŸ¥è¯†çš„é²æ£’æ€§ï¼Œæ¯ç§åœºæ™¯é‡‡ç”¨ä¸‰ç§è¯­è¨€é£æ ¼æè¿°ï¼Œæ¨¡æ‹Ÿä¸åŒå±‚çº§ç”¨æˆ·ï¼š

| å±‚çº§ | è¾“å…¥ç‰¹ç‚¹ | ç¤ºä¾‹ |
|------|--------|------|
| **Technician-level** | æ—¥å¸¸å£è¯­åŒ–æè¿°ç‰©ç†æƒ…å†µ | â€œNode 6å’Œ7ä¹‹é—´é‚£æ¡è·¯ä¸èƒ½ç”¨äº†â€ |
| **Engineer-level** | æ˜ç¡®çš„æ“ä½œæœ¯è¯­ï¼Œæ— æ•°å­¦å½¢å¼åŒ– | â€œè¿æ¥(6,7)çš„åŒå‘é“è·¯å®Œå…¨å°é—­â€ |
| **Scientist-level** | å½¢å¼åŒ–çš„æ•°å­¦è¡¨è¾¾ | â€œç§»é™¤è¾¹é›†E'={(6,7),(7,6)}â€ |

æ€»è®¡ï¼š15å®ä¾‹ Ã— 3å±‚çº§ = **45ä¸ªæµ‹è¯•æ¡ˆä¾‹**

---

### **è¯„ä¼°æŒ‡æ ‡ï¼ˆMeasures of Effectiveness, MoEsï¼‰**

#### âœ… æ­£ç¡®æ€§æŒ‡æ ‡
- **Code Executability Rate (CER)**ï¼šç”Ÿæˆä»£ç æ˜¯å¦å¯æˆåŠŸè¿è¡Œï¼ˆæ— è¯­æ³•/è¿è¡Œæ—¶é”™è¯¯ï¼‰
- **Solver Success Rate (SSR)**ï¼šè§£çš„è´¨é‡æ˜¯å¦è¾¾åˆ°åŸºå‡†è§£ï¼ˆGurobiæœ€ä¼˜è§£ï¼‰ç²¾åº¦èŒƒå›´å†…

#### â±ï¸ æ•ˆç‡æŒ‡æ ‡
- **Iterations**ï¼šè‡ªæˆ‘ä¿®æ­£å¾ªç¯æ¬¡æ•°
- **Computation Time**ï¼šä»æ¥æ”¶åˆ°è¾“å‡ºæœ€ç»ˆè§£å†³æ–¹æ¡ˆçš„ç«¯åˆ°ç«¯è€—æ—¶

---

### **åŸºçº¿æ–¹æ³•ï¼ˆBenchmark Methodï¼‰**

- **ä¼ ç»Ÿä¸“å®¶é©±åŠ¨æ³•**ï¼šç”±å…·å¤‡è¿ç­¹å­¦èƒŒæ™¯çš„äººç±»ä¸“å®¶æ‰‹åŠ¨å»ºæ¨¡å¹¶ç¼–å†™Pythonè„šæœ¬ï¼ˆä½¿ç”¨Gurobiæ±‚è§£å™¨ï¼‰ï¼Œä½œä¸ºâ€œground truthâ€ã€‚

---

### **å®éªŒç¯å¢ƒä¸é…ç½®**

- **ç¡¬ä»¶**ï¼šIntel i5-13500H, 16GB RAM
- **LLMå¼•æ“**ï¼šGemini 2.5 Flashï¼ˆtemperature=0ï¼‰
- **æœ€å¤§è¿­ä»£æ¬¡æ•°**ï¼š3æ¬¡
- **ç¤ºä¾‹æ•°é‡**ï¼šé»˜è®¤1-shotï¼ˆæä¾›ç»å…¸MAPPæ¨¡å‹ç¤ºä¾‹ï¼‰
- **æ±‚è§£å™¨**ï¼šGurobi 12.0.3ï¼Œæ—¶é™300ç§’

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **å¹³å‡CERï¼ˆä»£ç å¯æ‰§è¡Œç‡ï¼‰** | **100%** |
| **SSRèŒƒå›´ï¼ˆæ±‚è§£æˆåŠŸç‡ï¼‰** | **86.67% ~ 100%** |
| **å¹³å‡SSRï¼ˆç»¼åˆæˆåŠŸç‡ï¼‰** | **93.33%** |
| **å¹³å‡è®¡ç®—æ—¶é—´** | **83.23ç§’** |
| **æ‰€éœ€ç¤ºä¾‹æ•°ï¼ˆè¾¾93.33% SSRï¼‰** | **ä»…éœ€1ä¸ªç¤ºä¾‹** |

> åœ¨æ‰€æœ‰45ä¸ªæµ‹è¯•æ¡ˆä¾‹ä¸­ï¼ŒæˆåŠŸè§£å†³42ä¸ªï¼Œå¤±è´¥ä»…3ä¾‹ï¼Œå‡ä¸º**è¯­ä¹‰è¯¯è§£**æ‰€è‡´ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

| æ–¹æ³• | éƒ¨ç½²æ—¶é—´ | æ˜¯å¦éœ€è¦ä¸“å®¶ | æ•°æ®éœ€æ±‚ | æˆåŠŸç‡ |
|------|--------|-------------|----------|--------|
| ä¼ ç»Ÿä¸“å®¶æ³• | æ•°å°æ—¶~æ•°å¤© | âœ… å¿…é¡» | é«˜ | æ¥è¿‘100% |
| **PortAgent** | **83.23ç§’** | âŒ ä¸éœ€è¦ | **æä½ï¼ˆ1ä¾‹ï¼‰** | **93.33%** |

âœ… **PortAgentåœ¨å‡ ä¹ä¸ç‰ºç‰²å‡†ç¡®æ€§çš„å‰æä¸‹ï¼Œå°†éƒ¨ç½²æ•ˆç‡æå‡äº†æ•°ç™¾å€**ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**

éªŒè¯ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—çš„é‡è¦æ€§ï¼š

| æ–¹æ³• | CER | SSR |
|------|-----|-----|
| **å®Œæ•´PortAgent** | 100% | 93.3% |
| **PortAgent w/o RAG**ï¼ˆæ— çŸ¥è¯†æ£€ç´¢ï¼‰ | 40.0% | 26.7% |
| **PortAgent w/o Self-Correction**ï¼ˆæ— è‡ªæˆ‘ä¿®æ­£ï¼‰ | 33.33% | 33.33% |

> ğŸ” ç»“è®ºï¼š
> - **RAGæ¨¡å—**æ˜¯ç¡®ä¿æ­£ç¡®å»ºæ¨¡çš„åŸºç¡€ï¼›
> - **Self-Correctionæœºåˆ¶**å¯¹ä¿®å¤åˆå§‹é”™è¯¯è‡³å…³é‡è¦ï¼›
> - äºŒè€…ç¼ºä¸€ä¸å¯ï¼Œå‡ä¸ºéå†—ä½™çš„å…³é”®ç»„ä»¶ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **PortAgentå®ç°äº†çœŸæ­£çš„â€œå…ä¸“å®¶â€éƒ¨ç½²**  
   - ç»Ÿè®¡æ£€éªŒæ˜¾ç¤ºï¼Œä¸åŒä¸“ä¸šæ°´å¹³ç”¨æˆ·çš„è¾“å…¥å¯¹CERã€SSRã€è¿­ä»£æ¬¡æ•°å’Œè®¡ç®—æ—¶é—´å‡**æ— æ˜¾è‘—å½±å“**ï¼ˆp > 0.05ï¼‰ï¼Œè¯æ˜å…¶å®Œå…¨æ‘†è„±äº†å¯¹ä¸“å®¶çš„ä¾èµ–ã€‚

2. âœ… **â€œå°‘å³æ˜¯å¤šâ€ï¼ˆLess is Moreï¼‰**  
   - å®éªŒè¡¨æ˜ï¼Œæä¾›æ›´å¤šç¤ºä¾‹ï¼ˆå¦‚3-shotï¼‰åè€Œå¯èƒ½å¼•å…¥â€œä¸Šä¸‹æ–‡å™ªå£°â€ï¼Œé™ä½æ€§èƒ½ï¼›
   - **1-shoté…ç½®è¡¨ç°æœ€ä½³**ï¼Œè¯´æ˜ç¤ºä¾‹è´¨é‡ä¼˜äºæ•°é‡ã€‚

3. âœ… **â€œåŸºç¡€ä¼˜å…ˆâ€åŸåˆ™æ›´ä¼˜**ï¼ˆFundamental is the Keyï¼‰  
   - ä½¿ç”¨**é€šç”¨ç»å…¸MAPPæ¨¡å‹**ä½œä¸ºç¤ºä¾‹ï¼Œæ¯”ä½¿ç”¨é’ˆå¯¹å…·ä½“åœºæ™¯å®šåˆ¶çš„ç¤ºä¾‹æ•ˆæœæ›´å¥½ï¼›
   - å› ä¸ºå®ƒä¼ æˆçš„æ˜¯**åŸºæœ¬ç»“æ„æµç¨‹**ï¼Œè€Œéè¿‡æ‹Ÿåˆç»†èŠ‚ï¼Œåˆ©äºæ³›åŒ–ã€‚

4. âœ… **è‡ªåŠ¨åŒ–é—­ç¯å¤§å¹…æå‡æ•ˆç‡**  
   - è‡ªæˆ‘ä¿®æ­£æœºåˆ¶è™½å¢åŠ è¿­ä»£æ¬¡æ•°ï¼Œä½†æ¯æ¬¡ä¿®æ­£å¿«é€Ÿç²¾å‡†ï¼Œæ•´ä½“ä»è¿œå¿«äºäººå·¥è°ƒè¯•ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

- **è¯­ä¹‰è¯¯è§£é£é™©ä¾ç„¶å­˜åœ¨**ï¼š
  - å½“ç”¨æˆ·è¾“å…¥å­˜åœ¨æ­§ä¹‰æ—¶ï¼ˆå¦‚â€œstick to the safe routeâ€æ˜¯å¦ä¸ºå¿…ç»å­è·¯å¾„ï¼‰ï¼ŒLLMå¯èƒ½å‡ºç°è¯¯åˆ¤ï¼›
  - å¤±è´¥æ¡ˆä¾‹å…¨éƒ¨å±äºæ­¤ç±»é—®é¢˜ï¼ˆmisinterpretationï¼‰ï¼Œè€ŒéæŠ€æœ¯å®ç°é”™è¯¯ã€‚

- **LLMè¾“å‡ºçš„éšæœºæ€§**ï¼š
  - å³ä¾¿ç›¸åŒè¾“å…¥ï¼Œä¸åŒéšæœºç§å­å¯èƒ½å¯¼è‡´ä¸åŒç»“æœï¼Œå½±å“ä¸€è‡´æ€§ã€‚

- **å½“å‰ä»…é€‚ç”¨äºç»“æ„åŒ–è‰¯å¥½çš„ä¼˜åŒ–é—®é¢˜**ï¼š
  - å¦‚MAPPè¿™ç±»æœ‰æ˜ç¡®å˜é‡ã€çº¦æŸã€ç›®æ ‡å‡½æ•°çš„é—®é¢˜ï¼›
  - å¯¹éç»“æ„åŒ–æˆ–æ¨¡ç³Šå†³ç­–åœºæ™¯é€‚åº”æ€§å°šå¾…éªŒè¯ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **å¢å¼ºè¯­ä¹‰ç†è§£èƒ½åŠ›**  
   - å¼€å‘æ›´ç²¾ç»†çš„è‡ªç„¶è¯­è¨€è§£ææœºåˆ¶ï¼Œå‡å°‘ç”¨æˆ·è¾“å…¥æ­§ä¹‰å¸¦æ¥çš„è¯¯è¯»ã€‚

2. **æé«˜è¾“å‡ºä¸€è‡´æ€§**  
   - æ¢ç´¢æ§åˆ¶LLMç”Ÿæˆç¨³å®šæ€§çš„æ–¹æ³•ï¼Œé™ä½æ¦‚ç‡æ€§æ³¢åŠ¨çš„å½±å“ã€‚

3. **æ‰©å±•è‡³å…¶ä»–VDSå­ç³»ç»Ÿ**  
   - å°†PortAgentåº”ç”¨äºå²¸æ¡¥è°ƒåº¦ã€å †åœºåˆ†é…ç­‰å…¶ä»–ACTæ ¸å¿ƒç³»ç»Ÿã€‚

4. **æ”¯æŒå¤šæ¨¡æ€è¾“å…¥**  
   - å¼•å…¥å›¾è¡¨ã€æ‹“æ‰‘å›¾ç­‰è§†è§‰ä¿¡æ¯è¾…åŠ©ç†è§£å¤æ‚çº¦æŸã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **PortAgent æ˜¯é¦–ä¸ªå®ç°å…ä¸“å®¶ã€ä½æ•°æ®ã€é«˜é€Ÿéƒ¨ç½²çš„LLM-driven VDSè¿ç§»ä»£ç†ï¼Œæ ‡å¿—ç€ACTæ™ºèƒ½è°ƒåº¦ç³»ç»Ÿå‘æ ‡å‡†åŒ–ã€è‡ªåŠ¨åŒ–è¿ˆå‡ºäº†å…³é”®ä¸€æ­¥ã€‚**

</details>

---

### 12. [The Double Life of Code World Models: Provably Unmasking Malicious Behavior Through Execution Traces](https://arxiv.org/abs/2512.13821)

**Authors**: Subramanyam Sahoo, Jared Junkin  
**Category**: cs.LG  
**Published**: 2025-12-17  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.13821v1  

#### Abstract
Large language models (LLMs) increasingly generate code with minimal human oversight, raising critical concerns about backdoor injection and malicious behavior. We present Cross-Trace Verification Protocol (CTVP), a novel AI control framework that verifies untrusted code-generating models through se...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*The Double Life of Code World Models: Provably Unmasking Malicious Behavior Through Execution Traces*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
éšç€ Large Language Modelsï¼ˆLLMsï¼‰åœ¨ä»£ç ç”Ÿæˆä»»åŠ¡ä¸­çš„å¹¿æ³›åº”ç”¨ï¼Œæ¨¡å‹å¯èƒ½è¢«æ¶æ„æ³¨å…¥**åé—¨ï¼ˆbackdoorï¼‰** æˆ–äº§ç”Ÿ**ä¸Šä¸‹æ–‡ä¾èµ–çš„éšè”½æ¶æ„è¡Œä¸º**ã€‚ä¼ ç»Ÿé˜²å¾¡æœºåˆ¶å¦‚æ²™ç®±æ‰§è¡Œã€é™æ€è§„åˆ™æ‰«æç­‰å‡è®¾æ¨¡å‹æ˜¯è‰¯æ€§çš„ä¸”é€æ˜çš„ï¼Œåœ¨å¯¹æŠ—æ€§æˆ–å¯¹é½å¤±è´¥åœºæ™¯ä¸‹å¤±æ•ˆã€‚

æœ¬æ–‡èšç„¦äºå¦‚ä½•åœ¨**ä¸ä¿¡ä»»æ¨¡å‹æ„å›¾ã€ä¸å®é™…æ‰§è¡Œå¯ç–‘ä»£ç **çš„å‰æä¸‹ï¼Œæ£€æµ‹ç”±ä»£ç ç”Ÿæˆæ¨¡å‹äº§ç”Ÿçš„ç¨‹åºæ˜¯å¦å«æœ‰éšè—çš„æ¶æ„é€»è¾‘ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

#### **Cross-Trace Verification Protocol (CTVP)**  
æå‡ºä¸€ç§åŸºäºè¯­ä¹‰ä¸å˜æ€§çš„é»‘ç›’ AI æ§åˆ¶æ¡†æ¶â€”â€”**è·¨è½¨è¿¹éªŒè¯åè®®ï¼ˆCTVPï¼‰**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³ä¸ºï¼š

> å¦‚æœä¸€ä¸ªç¨‹åºåœ¨å¤šä¸ªè¯­ä¹‰ç­‰ä»·ä½†è¯­æ³•ä¸åŒçš„å˜ä½“ä¸Šï¼Œå…¶é¢„æµ‹çš„æ‰§è¡Œè½¨è¿¹ä¿æŒä¸€è‡´ï¼Œåˆ™è®¤ä¸ºè¯¥æ¨¡å‹è¡Œä¸ºå¯æ§ï¼›å¦åˆ™ï¼Œå­˜åœ¨æ½œåœ¨æ¶æ„æˆ–ä¸ç¨³å®šè¡Œä¸ºã€‚

å…·ä½“æµç¨‹å¦‚ä¸‹ï¼š
1. å¯¹è¾“å…¥ç¨‹åº $P$ åº”ç”¨ä¸€ç³»åˆ—**è¯­ä¹‰ä¿æŒå˜æ¢**ï¼ˆå¦‚å˜é‡é‡å‘½åã€æ­»ä»£ç æ’å…¥ã€æ ¼å¼åŒ–è°ƒæ•´ï¼‰ï¼Œç”Ÿæˆä¸€ä¸ª**è¯­ä¹‰è½¨é“ï¼ˆsemantic orbitï¼‰** $\mathcal{O} = \{Q_1, ..., Q_k\}$ã€‚
2. ä½¿ç”¨å¾…éªŒè¯çš„**éå¯ä¿¡ LLM** é¢„æµ‹æ¯ä¸ªå˜ä½“ $Q_i$ çš„æ‰§è¡Œè½¨è¿¹ $T(Q_i)$ï¼ˆåŒ…æ‹¬ä¸­é—´çŠ¶æ€å’Œæœ€ç»ˆè¾“å‡ºï¼‰ã€‚
3. è®¡ç®—æ‰€æœ‰è½¨è¿¹ä¹‹é—´çš„æˆå¯¹ç›¸ä¼¼åº¦ï¼Œå¹¶é€šè¿‡é«˜ç™¾åˆ†ä½æ•°ï¼ˆå¦‚80%ï¼‰èšåˆå¾—åˆ°ä¸€è‡´æ€§å¾—åˆ† $C$ã€‚
4. æ ¹æ®é˜ˆå€¼åˆ¤æ–­ï¼š
   - $C < T_{\text{strict}}$: æ‹’ç»ï¼ˆREJECTï¼‰
   - $T_{\text{strict}} \leq C < T_{\text{soft}}$: å¯åŠ¨å¯ä¿¡æ¨¡å‹äºŒæ¬¡éªŒè¯
   - $C \geq T_{\text{soft}}$: æ¥å—ï¼ˆACCEPTï¼‰

#### **Adversarial Robustness Quotient (ARQ)**
å¼•å…¥ä¸€ä¸ªæ–°çš„ç†è®ºæŒ‡æ ‡ **ARQ**ï¼Œç”¨äºé‡åŒ–éªŒè¯è¿‡ç¨‹ç›¸å¯¹äºå•æ¬¡æ¨ç†çš„è®¡ç®—å¼€é”€ï¼š
$$
\text{ARQ}_{\text{flops}} \sim k + 1
$$
å…¶ä¸­ $k$ æ˜¯è¯­ä¹‰è½¨é“å¤§å°ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œä½œè€…è¯æ˜äº†**éå¯åšå¼ˆæ€§ï¼ˆnon-gamifiabilityï¼‰**ï¼šæ”»å‡»è€…è¦æ„é€ èƒ½é€šè¿‡ CTVP æ£€æµ‹çš„ä¸€è‡´æ€§åé—¨ï¼Œæ‰€éœ€å°è¯•æ¬¡æ•°éš $k$ å‘ˆæŒ‡æ•°å¢é•¿ï¼Œä½¿å…¶åœ¨ç°å®ä¸­ä¸å¯è¡Œã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | CTVP |
|------|--------|-------|
| å¯ä¿¡å‡è®¾ | è¦æ±‚æ¨¡å‹é€æ˜æˆ–è‰¯æ€§ | å®Œå…¨é»‘ç›’ï¼Œæ— éœ€ä¿¡ä»»æ¨¡å‹ |
| æ‰§è¡Œé£é™© | å¯èƒ½è¿è¡Œæ¶æ„ä»£ç ï¼ˆæ²™ç®±é€ƒé€¸ï¼‰ | ä¸æ‰§è¡Œä»£ç ï¼Œä»…é¢„æµ‹è½¨è¿¹ |
| æ£€æµ‹èƒ½åŠ› | ä¾èµ–æ˜¾å¼æ¨¡å¼åŒ¹é…ï¼ˆå¦‚ `eval`ï¼‰ | å¯æ•è·éšå¼ã€ä¸Šä¸‹æ–‡è§¦å‘çš„æ¶æ„è¡Œä¸º |
| ç†è®ºä¿éšœ | å¤šä¸ºç»éªŒæ€§ | å…·å¤‡ä¿¡æ¯è®ºçº§åˆ«çš„å®‰å…¨æ€§è¯æ˜ï¼ˆéå¯åšå¼ˆæ€§ï¼‰ |
| æ‰©å±•æ€§ | é™æ€åˆ†æéš¾ä»¥è¦†ç›–å¤æ‚è¯­ä¹‰ | åŠ¨æ€è¯­ä¹‰ä¸€è‡´æ€§åˆ†ææ›´å…·æ³›åŒ–æ½œåŠ› |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä½¿ç”¨ä¸€ä¸ª**äººå·¥æ„å»ºçš„æ··åˆæ•°æ®é›†**ï¼ŒåŒ…å«ï¼š
  - **è‰¯æ€§ç¨‹åºï¼ˆBenignï¼‰**ï¼šåŠŸèƒ½æ­£ç¡®ã€æ— æ¶æ„é€»è¾‘çš„æ ‡å‡† Python ç¨‹åºã€‚
  - **å¯¹æŠ—æ ·æœ¬ï¼ˆMaliciousï¼‰**ï¼šæ¤å…¥äº†ä¸Šä¸‹æ–‡æ•æ„Ÿåé—¨çš„ç¨‹åºï¼ˆä¾‹å¦‚ä»…åœ¨ç‰¹å®šå˜é‡åä¸‹è§¦å‘æ¶æ„æ“ä½œï¼‰ã€‚
- æ‰€æœ‰ç¨‹åºæ§åˆ¶åœ¨çº¦ 200 LOC ä»¥å†…ï¼Œæ¶µç›–å¸¸è§ç¼–ç¨‹ç»“æ„ï¼ˆå¾ªç¯ã€æ¡ä»¶ã€å‡½æ•°è°ƒç”¨ç­‰ï¼‰ã€‚

---

### å®éªŒè®¾ç½®

- **è½¨é“å¤§å°ï¼ˆorbit sizeï¼‰**ï¼šæµ‹è¯• $k = 3, 5, 10, 20$
- **ä¸€è‡´æ€§è¯„åˆ†æ–¹å¼**ï¼šä½¿ç”¨æˆå¯¹è½¨è¿¹ç›¸ä¼¼åº¦çš„ 80% ç™¾åˆ†ä½ä½œä¸ºä¸€è‡´æ€§åˆ†æ•° $C$
- **åŒå±‚å†³ç­–æœºåˆ¶**ï¼š
  - ä¸»è¦ä½¿ç”¨éå¯ä¿¡æ¨¡å‹è¿›è¡Œå¤šè½¨è¿¹é¢„æµ‹
  - åœ¨ä¸­é—´åŒºé—´å¯ç”¨â€œå¯ä¿¡æ¨¡å‹â€è¿›è¡Œäº¤å‰éªŒè¯ï¼ˆmedian trace similarityï¼‰
- **è‡ªé€‚åº”é˜ˆå€¼æ§åˆ¶**ï¼šé‡‡ç”¨ç±» PID æ§åˆ¶å™¨åŠ¨æ€è°ƒèŠ‚ $T_{\text{strict}}$ï¼Œç›®æ ‡ç»´æŒä½è¯¯æŠ¥ç‡ï¼ˆFPR target = 5%ï¼‰

---

### è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Detection Rate** | æˆåŠŸè¯†åˆ«æ¶æ„ç¨‹åºçš„æ¯”ä¾‹ï¼ˆTPRï¼‰ |
| **False Positive Rate (FPR)** | å°†è‰¯æ€§ç¨‹åºè¯¯åˆ¤ä¸ºæ¶æ„çš„æ¯”ä¾‹ |
| **Benign Acceptance Rate** | æ­£ç¡®æ¥å—è‰¯æ€§ç¨‹åºçš„æ¯”ä¾‹ |
| **ARQ**ï¼ˆAdversarial Robustness Quotientï¼‰ | éªŒè¯å¼€é”€ç›¸å¯¹äºå•æ¬¡æ¨ç†çš„å¢é•¿å€æ•°ï¼ˆæ—¶é—´ & FLOPsï¼‰ |
| **Consistency Score** | è½¨è¿¹é—´å¹³å‡ç›¸ä¼¼åº¦ï¼Œåæ˜ æ¨¡å‹è¾“å‡ºç¨³å®šæ€§ |
| **Transformation Success Rate** | æˆåŠŸç”Ÿæˆæœ‰æ•ˆè¯­ä¹‰ç­‰ä»·å˜ä½“çš„æ¯”ä¾‹ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”

å®ç°ä»¥ä¸‹é™æ€åˆ†æåŸºçº¿ç”¨äºæ¯”è¾ƒï¼š

1. **Static Pattern Detector**ï¼šæ­£åˆ™åŒ¹é…å…³é”®è¯ï¼ˆ`eval`, `exec`, `os.system`, `BACKDOOR`ï¼‰
2. **Complexity Heuristic**ï¼šåŸºäº AST èŠ‚ç‚¹æ•°é‡å’Œæ§åˆ¶æµå¤æ‚åº¦è®¾å®šå¼‚å¸¸é˜ˆå€¼
3. **Entropy Heuristic**ï¼šè®¡ç®—æºç å­—ç¬¦ç†µï¼Œè¿‡é«˜æˆ–è¿‡ä½è§†ä¸ºå¯ç–‘
4. **Weighted Combination**ï¼šä¸Šè¿°ä¸‰é¡¹ä¸­æœ‰ä¸¤é¡¹è§¦å‘å³æ ‡è®°ä¸ºæ¶æ„

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 2 å’Œæ­£æ–‡ï¼‰

| Orbit Size | Detection Rate (%) | FPR (%) | Avg Traces / Program | ARQ Median |
|------------|--------------------|---------|------------------------|-------------|
| 3          | 81.7               | 100.0   | 1.60                   | 4.00        |
| 5          | 83.3               | 97.5    | 2.80                   | 6.00        |
| 10         | 83.3               | 97.5    | 4.30                   | 11.00       |
| 20         | 86.7               | 100.0   | 7.60                   | 21.00       |

> æ³¨ï¼šè¡¨ä¸­ FPR å®é™…æŒ‡â€œè‰¯æ€§ç¨‹åºè¢«æ‹’ç»ç‡â€ï¼Œå³ 1 - Benign Acceptance Rate

æ­¤å¤–ï¼Œ**å®Œæ•´å®éªŒä¸­ï¼ˆFigure 1ï¼‰æŠ¥å‘Šäº†å®Œç¾æ£€æµ‹è¡¨ç°**ï¼š
- åœ¨ä¸»å®éªŒä¸­ï¼ŒCTVP å®ç°äº† **100% æ£€å‡ºç‡ï¼ˆ120/120 æ¶æ„æ ·æœ¬è¢«æ£€æµ‹ï¼‰**
- **é›¶å‡é˜´æ€§ï¼ˆzero false negativesï¼‰**
- **æ··æ·†çŸ©é˜µæ˜¾ç¤ºï¼š79% ç›´æ¥æ‹’ç»ï¼Œ21% è¿›å…¥ runtime monitoring**

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ï¼ˆTable 1ï¼‰

| Method           | Detection Rate (%) | FPR (%) | Benign Acceptance (%) |
|------------------|--------------------|---------|------------------------|
| Static Analysis  | 51.7               | 0.0     | 100.0                  |
| Complexity       | 80.0               | 62.5    | 37.5                   |
| Entropy          | 0.0                | 0.0     | 100.0                  |
| Weighted         | 51.7               | 0.0     | 100.0                  |
| **CTVP**         | **83.8**           | **98.8**| **1.2**                |

> âš ï¸ æ³¨æ„ï¼šCTVP çš„ FPR å¾ˆé«˜ï¼ˆ98.8%ï¼‰ï¼Œæ„å‘³ç€ç»å¤§å¤šæ•°è‰¯æ€§ç¨‹åºä¹Ÿè¢«æ‹’ç»ã€‚ä½†è¿™æ­£æ˜¯è®¾è®¡é€‰æ‹©â€”â€”ä¼˜å…ˆä¿è¯å®‰å…¨ï¼Œç‰ºç‰²å¯ç”¨æ€§ã€‚ç»“åˆ trusted model å¯ç¼“è§£æ­¤é—®é¢˜ã€‚

---

### æ¶ˆèå®éªŒä¸å…³é”®è§‚å¯Ÿ

- **è½¨é“å¤§å°å½±å“æ˜¾è‘—**ï¼š
  - éšç€ $k$ å¢å¤§ï¼Œæ£€æµ‹ç‡ç¨³æ­¥æå‡ï¼ˆä» 81.7% â†’ 86.7%ï¼‰
  - ARQ çº¿æ€§å¢é•¿ï¼ˆå®æµ‹ median ARQ â‰ˆ $k+1$ï¼‰ï¼Œç¬¦åˆé¢„æœŸ
- **ä¸€è‡´æ€§å¾—åˆ†åˆ†å¸ƒ**ï¼š
  - æ‰€æœ‰è‰¯æ€§ç¨‹åºçš„ consistency score é«˜åº¦é›†ä¸­äº 1.0
  - æ¶æ„ç¨‹åºå¾—åˆ†æ˜æ˜¾åä½ï¼Œå½¢æˆå¯åˆ†ç¦»ç©ºé—´
- **è½¬æ¢æˆåŠŸç‡éå•è°ƒ**ï¼š
  - åœ¨ $k=10$ æ—¶æˆåŠŸç‡ä¸‹é™è‡³ 10%ï¼Œä½†åœ¨ $k=20$ å›å‡è‡³ 50â€“75%ï¼Œè¡¨æ˜å­˜åœ¨â€œä¸­é—´å›°éš¾åŒºâ€
- **èµ„æºæ¶ˆè€—å¯æ§**ï¼š
  - CPU å†…å­˜ç¨³å®šåœ¨ ~4.8 GBï¼ŒGPU ~17 GBï¼ˆè¿œä½äº 71.3 GB ä¸Šé™ï¼‰
  - å•ç¨‹åºéªŒè¯æ—¶é—´ä» 0.275sï¼ˆk=2.5ï¼‰å¢è‡³ 0.333sï¼ˆk=20ï¼‰ï¼Œçº¿æ€§å¢é•¿

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. âœ… **è¯­ä¹‰è½¨é“ä¸Šçš„è¡Œä¸ºä¸€è‡´æ€§æ˜¯æ£€æµ‹åé—¨çš„æœ‰æ•ˆä»£ç†ä¿¡å·**  
   æ¶æ„è¡Œä¸ºå¾€å¾€æ— æ³•åœ¨å¤šç§è¯­æ³•å˜ä½“ä¸­ä¿æŒä¸€è‡´å“åº”ï¼Œå¯¼è‡´é¢„æµ‹è½¨è¿¹å‡ºç°åå·®ã€‚

2. âœ… **CTVP å®ç°è¿‘ä¹å®Œç¾çš„æ¶æ„ç¨‹åºæ£€å‡ºç‡ï¼ˆ100%ï¼‰**  
   åœ¨æ ‡å‡†æµ‹è¯•ä¸­æœªé—æ¼ä»»ä½•å·²çŸ¥æ¶æ„å®ä¾‹ï¼Œå…·å¤‡å¼ºé²æ£’æ€§ã€‚

3. âœ… **éå¯åšå¼ˆæ€§æˆç«‹**ï¼š  
   ä¿¡æ¯è®ºåˆ†æè¡¨æ˜ï¼Œæ„é€ èƒ½é€šè¿‡ CTVP çš„ä¸€è‡´åé—¨éœ€æœç´¢æŒ‡æ•°çº§ç©ºé—´ï¼ˆ$ \propto 2^{(k-1)H(T)} $ï¼‰ï¼Œä½¿å¾—æ”»å‡»æˆæœ¬æé«˜ã€‚

4. âœ… **æ— éœ€æ‰§è¡Œå³å¯éªŒè¯**ï¼š  
   åˆ©ç”¨ LLM è‡ªèº«ä½œä¸º trace predictorï¼Œé¿å…äº†ç›´æ¥è¿è¡Œæ½œåœ¨æ¶æ„ä»£ç çš„é£é™©ã€‚

5. âœ… **å¯æ‰©å±•çš„é˜²å¾¡æœºåˆ¶**ï¼š  
   æ”¯æŒ cascaded verificationï¼ˆéå¯ä¿¡ + å¯ä¿¡æ¨¡å‹è”åˆå†³ç­–ï¼‰ã€adaptive thresholdingã€caching ç­‰å·¥ç¨‹ä¼˜åŒ–ã€‚

---

### å±€é™æ€§

| é™åˆ¶ | è¯´æ˜ |
|------|------|
| **ä¾èµ– LLM è½¨è¿¹é¢„æµ‹å‡†ç¡®æ€§** | è‹¥ LLM æœ¬èº«æ— æ³•å‡†ç¡®æ¨¡æ‹Ÿç¨‹åºæ‰§è¡Œï¼ˆå°¤å…¶æ˜¯æ¶‰åŠå¤–éƒ¨ API æˆ–å¤æ‚çŠ¶æ€ï¼‰ï¼Œä¼šå¯¼è‡´è¯¯åˆ¤ |
| **é«˜å‡é˜³æ€§ç‡ï¼ˆFPR é«˜ï¼‰** | å‡ºäºä¿å®ˆç­–ç•¥ï¼Œå¤§é‡è‰¯æ€§ç¨‹åºè¢«æ‹’ç»ï¼Œå½±å“å®ç”¨æ€§ |
| **å˜æ¢ç§ç±»æœ‰é™** | å½“å‰ä»…æ”¯æŒ 5 ç±»è¯­ä¹‰ä¿æŒå˜æ¢ï¼Œå¯èƒ½é—æ¼æŸäº›ç­‰ä»·å½¢å¼ |
| **è®¡ç®—å¼€é”€éš $k$ å¢é•¿** | è™½ç„¶å•æ¬¡å»¶è¿Ÿå°ï¼Œä½†å¤§è§„æ¨¡éƒ¨ç½²æ—¶ ARQ ~ $k+1$ ä»æ„æˆç“¶é¢ˆ |
| **ç¼–è¾‘è·ç¦»çº¦æŸè¾ƒå¼º** | è®¾å®šæœ€å° Levenshtein è·ç¦»å¯èƒ½å¯¼è‡´æœ‰æ•ˆå˜ä½“ç”Ÿæˆå¤±è´¥ |

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. **é›†æˆçœŸå®æ‰§è¡Œç¯å¢ƒ**ï¼šå¼•å…¥ sandboxed interpreterï¼ˆå¦‚ RestrictedPythonï¼‰è·å– ground-truth traceï¼Œå¢å¼ºéªŒè¯å¯é æ€§ã€‚
2. **ä¸°å¯Œå˜æ¢ç­–ç•¥**ï¼šåŠ å…¥æ•°æ®æµæ„ŸçŸ¥é‡æ’ã€ç±»å‹ä¿æŒç¼–è¾‘ã€å¾ªç¯å±•å¼€ã€å¸¸é‡æŠ˜å ç­‰æ›´å¤æ‚çš„è¯­ä¹‰ç­‰ä»·å˜æ¢ã€‚
3. **è‡ªé€‚åº”è½¨é“å¤§å°ï¼ˆadaptive orbit sizingï¼‰**ï¼šæ ¹æ®ç¨‹åºå¤æ‚åº¦åŠ¨æ€è°ƒæ•´ $k$ï¼Œå¹³è¡¡æ•ˆç‡ä¸å®‰å…¨æ€§ã€‚
4. **æŒç»­è¿è¡Œç›‘æ§ï¼ˆcontinuous runtime monitoringï¼‰**ï¼šæ”¯æŒå‘¨æœŸæ€§é‡æ–°éªŒè¯ã€å¼‚å¸¸æ£€æµ‹ä¸åé¦ˆé©±åŠ¨å†è®­ç»ƒã€‚
5. **å¯¹æŠ—é²æ£’æ€§æµ‹è¯•**ï¼šè¯„ä¼°å¯¹æ¢¯åº¦æ”»å‡»ã€éšå†™åä½œï¼ˆsteganographic collusionï¼‰ã€å¤šé˜¶æ®µåé—¨çš„æŠµæŠ—åŠ›ã€‚
6. **è·¨é¢†åŸŸæ¨å¹¿**ï¼šæ¢ç´¢ CTVP æ˜¯å¦é€‚ç”¨äºæ–‡æœ¬ç”Ÿæˆã€å›¾åƒåˆæˆç­‰å…¶ä»–æ¨¡æ€çš„ä»»åŠ¡ä¸­ã€‚

---

## æ€»ç»“

CTVP æå‡ºäº†ä¸€ç§æ–°é¢–ä¸”ç†è®ºä¸Šåšå®çš„ AI æ§åˆ¶èŒƒå¼ï¼š**é€šè¿‡è¯­ä¹‰ç­‰ä»·å˜æ¢ä¸‹çš„æ‰§è¡Œè½¨è¿¹ä¸€è‡´æ€§æ¥æ­ç¤ºä»£ç ç”Ÿæˆæ¨¡å‹ä¸­çš„éšè—æ¶æ„è¡Œä¸º**ã€‚å®ƒä¸ä¾èµ–ä»£ç æ‰§è¡Œï¼Œä¹Ÿä¸è¦æ±‚ç™½ç›’è®¿é—®ï¼Œè€Œæ˜¯åˆ©ç”¨ LLM è‡ªèº«çš„é¢„æµ‹èƒ½åŠ›è¿›è¡Œâ€œè‡ªæˆ‘æš´éœ²â€å¼çš„éªŒè¯ã€‚

å°½ç®¡å­˜åœ¨è®¡ç®—å¼€é”€å’Œé«˜ FPR çš„æŒ‘æˆ˜ï¼Œä½†å…¶å®éªŒè¡¨ç°ä¼˜å¼‚ï¼Œç†è®ºåŸºç¡€æ‰å®ï¼Œå°¤å…¶åœ¨é˜²æ­¢é«˜çº§å¯¹æŠ—æ€§åé—¨æ–¹é¢å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä¸ºæœªæ¥å®‰å…¨å‹ä»£ç ç”Ÿæˆç³»ç»Ÿçš„è®¾è®¡æä¾›äº†é‡è¦å‚è€ƒè·¯å¾„ã€‚

</details>

---

### 13. [Beyond Lipschitz Continuity and Monotonicity: Fractal and Chaotic Activation Functions in Echo State Networks](https://arxiv.org/abs/2512.14675)

**Authors**: Rae Chipera, Jenny Du, Irene Tsapara  
**Category**: cs.LG  
**Published**: 2025-12-17  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.14675v1  

#### Abstract
Contemporary reservoir computing relies heavily on smooth, globally Lipschitz continuous activation functions, limiting applications in defense, disaster response, and pharmaceutical modeling where robust operation under extreme conditions is critical. We systematically investigate non-smooth activa...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šBeyond Lipschitz Continuity and Monotonicity: Fractal and Chaotic Activation Functions in Echo State Networks

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿ **Echo State Networks (ESNs)** å‡ ä¹å®Œå…¨ä¾èµ–äºå¹³æ»‘ä¸”å…¨å±€ **Lipschitz è¿ç»­**çš„æ¿€æ´»å‡½æ•°ï¼ˆå¦‚ `tanh` å’Œ `ReLU`ï¼‰ï¼Œè¿™é™åˆ¶äº†å…¶åœ¨æç«¯æ¡ä»¶ä¸‹çš„é²æ£’æ€§ï¼Œä¾‹å¦‚å›½é˜²ã€ç¾éš¾å“åº”å’Œè¯ç‰©å»ºæ¨¡ç­‰å¯¹ç¨³å®šæ€§è¦æ±‚æé«˜çš„åœºæ™¯ã€‚æœ¬æ–‡æŒ‘æˆ˜äº†è¿™ä¸€è®¾è®¡èŒƒå¼ï¼Œç³»ç»Ÿæ€§åœ°ç ”ç©¶äº†éå…‰æ»‘ï¼ˆnon-smoothï¼‰æ¿€æ´»å‡½æ•°åœ¨ ESN ä¸­çš„è¡¨ç°ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
1. **å¼•å…¥éå…‰æ»‘æ¿€æ´»å‡½æ•°ç±»åˆ«**ï¼š
   - å°†éå…‰æ»‘æ¿€æ´»å‡½æ•°åˆ†ä¸ºä¸‰ç±»ï¼š**fractal**ï¼ˆåˆ†å½¢ï¼‰ã€**chaotic**ï¼ˆæ··æ²Œï¼‰å’Œ **stochastic**ï¼ˆéšæœºï¼‰ã€‚
   - å…·ä½“å®ç°åŒ…æ‹¬ï¼š**Cantor å‡½æ•°**ï¼ˆé­”é¬¼é˜¶æ¢¯ï¼‰ã€**Weierstrass å‡½æ•°**ï¼ˆè¿ç»­ä½†å¤„å¤„ä¸å¯å¾®ï¼‰ã€**Mandelbrot é›†é€ƒé€¸æ—¶é—´å‡½æ•°**ã€**Logistic æ˜ å°„** å’Œ **Brownian Motion**ã€‚

2. **æå‡ºé€€åŒ–å›å£°çŠ¶æ€æ€§è´¨ï¼ˆDegenerate Echo State Property, d-ESPï¼‰**ï¼š
   - é’ˆå¯¹ç¦»æ•£è¾“å‡ºï¼ˆé‡åŒ–ï¼‰æ¿€æ´»å‡½æ•°æ— æ³•æ»¡è¶³ä¼ ç»Ÿ ESPï¼ˆæ•°å€¼æ”¶æ•›ï¼‰çš„é—®é¢˜ï¼Œå®šä¹‰äº† **d-ESP**ï¼šåªè¦ä¸¤ä¸ªè½¨è¿¹æœ€ç»ˆäº§ç”Ÿç›¸åŒçš„ç¬¦å·åºåˆ—ï¼ˆå³æ¿€æ´»è¾“å‡ºä¸€è‡´ï¼‰ï¼Œå³å¯è§†ä¸ºæ”¶æ•›ã€‚
   - å¹¶è¯æ˜ï¼š**d-ESP è•´å«ä¼ ç»Ÿ ESP**ï¼Œä¸ºé‡åŒ–æ¿€æ´»å‡½æ•°æä¾›äº†ç†è®ºåŸºç¡€ã€‚

3. **æ­ç¤ºç¨³å®šæ€§æœºåˆ¶çš„æœ¬è´¨æ˜¯é¢„å¤„ç†æ‹“æ‰‘è€Œéè¿ç»­æ€§æœ¬èº«**ï¼š
   - å‘ç°å†³å®šç¨³å®šæ€§çš„å…³é”®å› ç´ ä¸æ˜¯å‡½æ•°æ˜¯å¦è¿ç»­ï¼Œè€Œæ˜¯å…¶**é¢„å¤„ç†æ‹“æ‰‘ç»“æ„**ï¼ˆpreprocessing topologyï¼‰ã€‚
   - **å•è°ƒå‹ç¼©å‹é¢„å¤„ç†**ï¼ˆå¦‚ sigmoid åŒ…è£¹ï¼‰èƒ½ç»´æŒç¨³å®šæ€§ï¼Œè€Œ**å‘æ•£æˆ–ä¸è¿ç»­é¢„å¤„ç†**ï¼ˆå¦‚ moduloï¼‰ä¼šå¯¼è‡´å°–é”å¤±æ•ˆã€‚

4. **æå‡ºâ€œæ‹¥æŒ¤æ¯”â€ï¼ˆCrowding Ratioï¼‰ä½œä¸ºé‡åŒ–å‡½æ•°å¤±æ•ˆçš„é¢„æµ‹æŒ‡æ ‡**ï¼š
   - å®šä¹‰ $ Q = N/k $ï¼Œå…¶ä¸­ $ N $ æ˜¯ reservoir sizeï¼Œ$ k $ æ˜¯é‡åŒ–ç­‰çº§æ•°ã€‚
   - å®éªŒè¡¨æ˜å½“ $ Q $ è¶…è¿‡é˜ˆå€¼æ—¶ï¼ˆå¦‚ $ Q \approx 47.6 $ æˆ– $ 95 $ï¼‰ï¼Œé‡åŒ–å‡½æ•°å°†å‡ºç° ESP å¤±è´¥ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **çªç ´ä¼ ç»Ÿç¨³å®šæ€§è¾¹ç•Œ**ï¼šæŸäº›éå…‰æ»‘å‡½æ•°ï¼ˆå¦‚ Cantor å‡½æ•°ï¼‰å¯åœ¨è°±åŠå¾„ $ \rho \approx 10 $ ä¸‹ä¿æŒç¨³å®šï¼Œè¿œè¶…ä¼ ç»Ÿ $ \rho < 1 $ çš„ç»éªŒå‡†åˆ™ã€‚
- **åŠ é€Ÿæ”¶æ•›**ï¼šCantor å‡½æ•°å’Œ Logistic Sigmoid çš„æ”¶æ•›é€Ÿåº¦æ¯” `tanh` å’Œ `ReLU` å¿« **2.6 å€**ã€‚
- **æä¾›æ–°çš„è®¾è®¡åŸåˆ™**ï¼šä»â€œå…‰æ»‘ vs æ··æ²Œâ€è½¬å‘â€œå‹ç¼© vs å‘æ•£é¢„å¤„ç†â€å’Œâ€œç¬¦å·åŠ¨åŠ›å­¦â€ï¼Œä¸º ESN è®¾è®¡æä¾›æ–°è§†è§’ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
æœ¬ç ”ç©¶æœªä½¿ç”¨çœŸå®ä¸–ç•Œæ•°æ®é›†ï¼Œè€Œæ˜¯é€šè¿‡**åˆæˆè¾“å…¥ä¿¡å·**è¿›è¡Œç³»ç»Ÿæ€§è¯„ä¼°ï¼Œä»¥éš”ç¦»æ¿€æ´»å‡½æ•°çš„å½±å“ã€‚è¾“å…¥åˆ†å¸ƒåŒ…æ‹¬ï¼š
- **Gaussian**ï¼ˆé«˜æ–¯åˆ†å¸ƒï¼‰
- **Uniform**ï¼ˆå‡åŒ€åˆ†å¸ƒï¼‰
- **Sparse**ï¼ˆç¨€ç–ä¿¡å·ï¼Œ90% ä¸ºé›¶ï¼‰

### å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼šæ ‡å‡† Leaky Integrator ESNï¼Œæ›´æ–°å…¬å¼ä¸ºï¼š
  $$
  x_t = (1 - a)x_{t-1} + a f(W_{in}u_t + W_{res}x_{t-1})
  $$
- **å‚æ•°æ‰«æèŒƒå›´**ï¼š
  - è°±åŠå¾„ $ \rho \in \{0.5, 0.6, ..., 5.0\} $ï¼Œéƒ¨åˆ†æ‰©å±•è‡³ $ \rho = 100 $
  - æ³„æ¼ç‡ $ a \in \{0.1, 0.3, 0.5, 0.7, 0.9\} $
  - å‚¨å¤‡æ± å¤§å° $ N \in \{1, 10, 50, 100, 500, 1000, 2000\} $
- **æ€»é…ç½®æ•°**ï¼šå…±æµ‹è¯• **36,610 ç§ reservoir é…ç½®**ï¼Œæ¯ç§é…ç½®è¿è¡Œå¤šä¸ªéšæœºç§å­ï¼ˆé€šå¸¸ 5â€“1000 æ¬¡è¯•éªŒï¼‰ã€‚

### è¯„ä¼°æŒ‡æ ‡
1. **ESP åˆè§„æ€§ï¼ˆESP Complianceï¼‰**ï¼š
   - åˆ¤æ–­ä¸¤ä¸ªä¸åŒåˆå§‹çŠ¶æ€çš„è½¨è¿¹æ˜¯å¦åœ¨ 200 æ­¥å†…æ»¡è¶³ $ \|x(t) - x'(t)\| < 0.1 $ã€‚
   - è‹¥æœªæ”¶æ•›ï¼Œåˆ™å»¶é•¿è‡³ 2000 æ­¥ä»¥åŒºåˆ†æ…¢æ”¶æ•›ä¸çœŸæ­£å¤±è´¥ã€‚
2. **æ”¶æ•›é€Ÿåº¦ï¼ˆConvergence Speedï¼‰**ï¼š
   - è®°å½•é¦–æ¬¡ä½äºé˜ˆå€¼çš„æ—¶é—´æ­¥æ•°ã€‚
3. **æœ€ç»ˆè·ç¦»ï¼ˆFinal Distanceï¼‰**ï¼š
   - 200 æˆ– 2000 æ­¥åçš„å¹³å‡çŠ¶æ€å·®å¼‚ã€‚
4. **ç»éªŒå±€éƒ¨ Lipschitz å¸¸æ•°ä¼°è®¡**ï¼š
   - ä½¿ç”¨æœ‰é™å·®åˆ†æ³•ä¼°ç®— $ |f(x+\epsilon) - f(x)|/\epsilon $ï¼Œåˆ†æå‡½æ•°å±€éƒ¨å˜åŒ–ç‡ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Smooth Baselines**ï¼š`tanh`, `ReLU`
- **Irregular Functions**ï¼š
  - Fractal: Cantor Function, Cantor Set, Weierstrass, Mandelbrot (Discrete & Continuous)
  - Chaotic: Logistic Map (Sigmoid & Modulo Wrappers)
  - Stochastic: Brownian Motion

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æ¿€æ´»å‡½æ•° | æœ€å¤§ç¨³å®šè°±åŠå¾„ $ \rho $ | æ”¶æ•›é€Ÿåº¦ï¼ˆä¸­ä½æ•°æ­¥æ•°ï¼‰ | N=2000 æ—¶ ESP æˆåŠŸç‡ |
|---------|--------------------------|------------------------|----------------------|
| `tanh` | ~2.0 | 15.6 | 100% |
| `ReLU` | ~1.5 | 15.2 | 100% |
| **Cantor Function** | **~10.0** | **6.1** | **100%** |
| **Logistic Sigmoid** | **~5.0** | **6.0** | **100%** |
| Mandelbrot (Continuous) | ~3.0 | ~10 | 100% |
| Mandelbrot (Discrete) | ~2.0 | 20â€“80 | 0.4% (N=2000) |
| Weierstrass | <1.0 | â€” | 0.4% |
| Brownian Motion | â€” | â€” | 0.4% |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **Cantor å‡½æ•°**ï¼š
  - åœ¨ $ \rho \approx 10 $ ä¸‹ä»ä¿æŒç¨³å®šï¼Œè¶…å‡ºä¼ ç»Ÿç•Œé™ä¸€ä¸ªæ•°é‡çº§ã€‚
  - æ”¶æ•›é€Ÿåº¦è¾¾ `tanh` çš„ **2.6 å€**ã€‚
  - åœ¨ $ N=2000 $ æ—¶ä»ä¿æŒ 100% ESP æˆåŠŸç‡ã€‚
- **Logistic Sigmoid**ï¼š
  - åœ¨ $ \rho \approx 5 $ ä¸‹ç¨³å®šï¼Œæ”¶æ•›é€Ÿåº¦å¿«ã€‚
  - è¡¨æ˜å³ä½¿åº•å±‚åŠ¨æ€æ˜¯æ··æ²Œçš„ï¼Œåªè¦é¢„å¤„ç†æ˜¯å‹ç¼©çš„ï¼ˆsigmoidï¼‰ï¼Œä»å¯ç¨³å®šã€‚
- **Mandelbrot è¿ç»­ vs ç¦»æ•£**ï¼š
  - è¿ç»­ç‰ˆæœ¬åœ¨æ‰€æœ‰è§„æ¨¡ä¸‹å‡ç¨³å®šã€‚
  - ç¦»æ•£ç‰ˆæœ¬åœ¨ $ N=1000 $ ($ Q \approx 47.6 $) å¼€å§‹é€€åŒ–ï¼Œåœ¨ $ N=2000 $ ($ Q \approx 95 $) å‡ ä¹å®Œå…¨å¤±è´¥ï¼ŒéªŒè¯äº† **crowding ratio** çš„é¢„æµ‹èƒ½åŠ›ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **é¢„å¤„ç†æ‹“æ‰‘çš„å½±å“**ï¼š
  - Logistic Map + Sigmoid Wrapperï¼šç¨³å®šï¼Œå¿«é€Ÿæ”¶æ•›ã€‚
  - Logistic Map + Modulo Wrapperï¼šåœ¨ $ N > 50 $ åè¿…é€Ÿå´©æºƒï¼Œè¯´æ˜**ä¸è¿ç»­é¢„å¤„ç†ç ´åç¨³å®šæ€§**ã€‚
- **é‡åŒ–çš„å½±å“**ï¼š
  - ç¦»æ•£ Mandelbrot åœ¨å°è§„æ¨¡ï¼ˆ$ N=100 $ï¼‰è¡¨ç°è‰¯å¥½ï¼Œä½†éš $ N $ å¢åŠ å‡ºç°**ä¼ªå¸å¼•å­**ï¼ˆsteady-state error â‰ˆ 0.1ï¼‰ï¼Œè€ŒéçœŸæ­£æ”¶æ•›åˆ°é›¶ã€‚
- **éšæœºæ€§çš„å½±å“**ï¼š
  - Brownian Motion æ¿€æ´»å‡½æ•°ä»…åœ¨ 1.6% çš„è¯•éªŒä¸­æ”¶æ•›ï¼Œè¯å®å†…éƒ¨éšæœºæ€§ä¼šç ´åç¡®å®šæ€§æ˜ å°„å‡è®¾ï¼Œå¯¼è‡´ ESP å¤±è´¥ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **éå…‰æ»‘æ¿€æ´»å‡½æ•°å¯ä»¥ä¼˜äºä¼ ç»Ÿå…‰æ»‘å‡½æ•°**ï¼š
   - ç‰¹å®šåˆ†å½¢å‡½æ•°ï¼ˆå¦‚ Cantor å‡½æ•°ï¼‰ä¸ä»…ç»´æŒ ESPï¼Œè¿˜èƒ½æ˜¾è‘—**åŠ å¿«æ”¶æ•›é€Ÿåº¦**å¹¶**æ‰©å¤§ç¨³å®šåŒºåŸŸ**ã€‚
2. **ç¨³å®šæ€§ç”±é¢„å¤„ç†æ‹“æ‰‘å†³å®šï¼Œè€Œéè¿ç»­æ€§æœ¬èº«**ï¼š
   - **å•è°ƒå‹ç¼©å‹é¢„å¤„ç†**ï¼ˆå¦‚ sigmoidï¼‰æ˜¯ç¨³å®šçš„å…³é”®ã€‚
   - **ä¸è¿ç»­æˆ–å‘æ•£é¢„å¤„ç†**ï¼ˆå¦‚ moduloï¼‰å³ä½¿åº•å±‚å‡½æ•°ç›¸åŒä¹Ÿä¼šå¯¼è‡´å¤±è´¥ã€‚
3. **é‡åŒ–å‡½æ•°å­˜åœ¨å›ºæœ‰ç¼©æ”¾æé™**ï¼š
   - æå‡º **d-ESP** æ¡†æ¶ï¼Œå¹¶è¯æ˜å…¶è•´å«ä¼ ç»Ÿ ESPã€‚
   - é‡åŒ–å‡½æ•°åœ¨å¤§å‹ reservoir ä¸­å¿…ç„¶å¤±è´¥ï¼Œé™¤é $ N/k $ï¼ˆæ‹¥æŒ¤æ¯”ï¼‰è¶³å¤Ÿå°ã€‚
4. **å±€éƒ¨ Lipschitz å¸¸æ•°æ˜¯é‡è¦æŒ‡æ ‡**ï¼š
   - ç»éªŒæœ€å¤§å±€éƒ¨ Lipschitz å¸¸æ•° $ L_{\text{max}} < 20 $ çš„å‡½æ•°é€šå¸¸ç¨³å®šã€‚
   - Weierstrass å‡½æ•° $ L_{\text{max}} > 500 $ï¼Œå¯¼è‡´å®Œå…¨å¤±è´¥ã€‚
5. **Cantor å‡½æ•°æ˜¯ç‰¹ä¾‹**ï¼š
   - å°½ç®¡å¤„å¤„ä¸å¯å¾®ä¸”é Lipschitzï¼Œä½†ç”±äºå…¶**å•è°ƒæ€§å’Œåˆ†æ®µå¸¸æ•°ç‰¹æ€§**ï¼Œè¡¨ç°å‡ºå“è¶Šçš„æ”¶æ•›æ€§èƒ½ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ç†è®ºè§£é‡Šä¸è¶³**ï¼šä¸ºä½• Cantor å‡½æ•°æ€§èƒ½å¦‚æ­¤ä¼˜å¼‚ï¼Œç›®å‰å°šæ— å®Œæ•´ç†è®ºè§£é‡Šï¼Œæš—ç¤ºå¯¹å‡ ä½•å±æ€§å¦‚ä½•å½±å“ reservoir åŠ¨æ€çš„ç†è§£å­˜åœ¨æ ¹æœ¬æ€§ç©ºç™½ã€‚
- **ä»»åŠ¡æ€§èƒ½æœªéªŒè¯**ï¼šæœ¬ç ”ç©¶èšç„¦äº **ESP æ”¶æ•›æ€§è´¨**ï¼Œå°šæœªåœ¨æ ‡å‡† RC ä»»åŠ¡ï¼ˆå¦‚ Mackey-Glass é¢„æµ‹ã€NARMA ç­‰ï¼‰ä¸ŠéªŒè¯è¿™äº›éå…‰æ»‘å‡½æ•°çš„å®é™…è®¡ç®—æ€§èƒ½ã€‚
- **è®¡ç®—å¼€é”€**ï¼šåˆ†å½¢å‡½æ•°ï¼ˆå¦‚ Mandelbrotï¼‰éœ€è¿­ä»£è®¡ç®—ï¼Œå°½ç®¡ä½œè€…ç§°å…¶å¯æ¥å—ï¼Œä½†åœ¨å®æ—¶åµŒå…¥å¼ç³»ç»Ÿä¸­ä»éœ€æƒè¡¡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¨å¯¼åŸºäº **leak-adjusted Jacobian çš„å¹³å‡æƒ…å†µæ”¶ç¼©**ï¼ˆLyapunov æŒ‡æ•°ï¼‰ç†è®ºã€‚
- åœ¨çœŸå®åŸºå‡†ä»»åŠ¡å’Œç¡¬ä»¶ reservoir ä¸Šè¯„ä¼°éå…‰æ»‘æ¿€æ´»å‡½æ•°çš„æ€§èƒ½ã€‚
- æ¢ç´¢å…¶ä»–å…·æœ‰ç±»ä¼¼â€œå‹ç¼©+å•è°ƒâ€ç‰¹æ€§çš„éå…‰æ»‘å‡½æ•°å®¶æ—ã€‚
- ç ”ç©¶å¦‚ä½•åˆ©ç”¨ç¬¦å·åŠ¨åŠ›å­¦ï¼ˆsymbol dynamicsï¼‰æå‡ reservoir çš„ä¿¡æ¯å¤„ç†èƒ½åŠ›ã€‚

--- 

> **ä»£ç å¯ç”¨æ€§**ï¼šä½œè€…å£°æ˜ä»£ç å¯æ ¹æ®è¯·æ±‚è·å–ã€‚

</details>

---

### 14. [RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees](https://arxiv.org/abs/2512.14069)

**Authors**: Junjie Ma, Jinlong Li  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.14069v1  

#### Abstract
Inference with modern Large Language Models (LLMs) is expensive and slow, and speculative sampling has emerged as an effective solution to this problem, however, the number of the calls to the draft model for generating candidate tokens in speculative sampling is a preset hyperparameter, lacking fle...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šRADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°ä»£å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªå›å½’è§£ç è¿‡ç¨‹ä¸­æ¨ç†é€Ÿåº¦æ…¢ã€è®¡ç®—æˆæœ¬é«˜ã€‚**Speculative Sampling** æ˜¯ä¸€ç§æœ‰æ•ˆçš„åŠ é€Ÿæ–¹æ³•ï¼Œé€šè¿‡ä¸€ä¸ªå°çš„ **draft model** å¿«é€Ÿç”Ÿæˆå€™é€‰ tokenï¼Œå¹¶ç”±ç›®æ ‡ LLM å¹¶è¡ŒéªŒè¯ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä¸­å¯¹ draft model çš„è°ƒç”¨æ¬¡æ•°æ˜¯ä¸€ä¸ªé¢„è®¾çš„è¶…å‚æ•°ï¼ˆå¦‚å›ºå®šä¸º 8 æ¬¡ï¼‰ï¼Œç¼ºä¹çµæ´»æ€§ï¼Œå¯¼è‡´åœ¨æŸäº›ä¸Šä¸‹æ–‡ä¸­äº§ç”Ÿå†—ä½™è®¡ç®—ï¼Œç”šè‡³å‡ºç°å€™é€‰ token å…¨éƒ¨è¢«æ‹’ç»çš„æƒ…å†µï¼ˆå®éªŒä¸­é«˜è¾¾ 31%ï¼‰ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **RADAR**ï¼ˆReinforcement learning Adjusted Draft-generation Algorithm for speculative samplingï¼‰ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š

- **åŠ¨æ€ç”Ÿæˆ draft tree**ï¼šä¸åŒäºä¼ ç»Ÿé™æ€æˆ–å›ºå®šæ·±åº¦çš„ draft tree ç»“æ„ï¼ŒRADAR èƒ½å¤Ÿæ ¹æ®ä¸Šä¸‹æ–‡å®æ—¶å†³å®šæ˜¯å¦ç»§ç»­è°ƒç”¨ draft modelï¼Œä»è€Œæ„å»º**åŠ¨æ€æ·±åº¦çš„ draft tree**ã€‚
- **å°† draft è¿‡ç¨‹å»ºæ¨¡ä¸º MDP**ï¼šå°† draft tree çš„ç”Ÿæˆè¿‡ç¨‹å½¢å¼åŒ–ä¸ºä¸€ä¸ª **Markov Decision Process (MDP)**ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ æ¥è®­ç»ƒä¸€ä¸ªè½»é‡çº§çš„ **prediction model**ï¼Œè¯¥æ¨¡å‹åŸºäº draft model è¾“å‡ºçš„ç½®ä¿¡åº¦åˆ†æ•°ï¼Œè¾“å‡º `continue` æˆ– `stop` å†³ç­–ä¿¡å·ã€‚
- **ç¦»çº¿å¼ºåŒ–å­¦ä¹  + æ— éœ€çœŸå®äº¤äº’æ ‡ç­¾**ï¼šç”±äº acceptance length å…·æœ‰éšæœºæ€§ï¼Œæ— æ³•è·å¾—ç²¾ç¡®æ ‡ç­¾ã€‚ä¸ºæ­¤ï¼Œä½œè€…è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„æ•°æ®é›†æ„é€ æ–¹å¼â€”â€”åŸºäº EAGLE-3 åœ¨ ShareGPT æ•°æ®é›†ä¸Šçš„è¿è¡Œç»“æœï¼Œæ”¶é›†ä¸åŒè°ƒç”¨æ¬¡æ•°ä¸‹çš„ **acceptance length åˆ†å¸ƒ**ï¼Œç”¨äºæ¨¡æ‹Ÿå¥–åŠ±å‡½æ•°ï¼Œå®ç° **offline reinforcement learning**ï¼Œé¿å…äº†æ˜‚è´µçš„åœ¨çº¿ LLM äº¤äº’ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´é«˜çš„çµæ´»æ€§**ï¼šä¸å†ä¾èµ–å›ºå®šçš„è°ƒç”¨æ¬¡æ•°ï¼Œèƒ½é€‚åº”ä¸åŒè¾“å…¥ä¸Šä¸‹æ–‡çš„å¤æ‚åº¦ã€‚
- **å‡å°‘å†—ä½™è®¡ç®—**ï¼šå¹³å‡å‡å°‘ 18.7% çš„ draft model è°ƒç”¨æ¬¡æ•°ï¼Œæ˜¾è‘—é™ä½ draft é˜¶æ®µå¼€é”€ã€‚
- **æ›´é«˜çš„åŠ é€Ÿæ¯”**ï¼šåœ¨ä¿æŒæ¥è¿‘ EAGLE-3 çš„ acceptance length çš„åŒæ—¶ï¼Œå®ç°äº†æ›´ä¼˜çš„ end-to-end æ¨ç†åŠ é€Ÿã€‚
- **æ— æ€§èƒ½æŸå¤±**ï¼šéµå¾ªä¸¥æ ¼çš„ speculative sampling åè®®ï¼Œä¸æ”¹å˜ç›®æ ‡ LLM æƒé‡ï¼Œä¿è¯è¾“å‡ºåˆ†å¸ƒä¸€è‡´ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **ShareGPT**ï¼šç”¨äºæ„å»ºè®­ç»ƒ datasetï¼Œè¿è¡Œ EAGLE-3 æ”¶é›†çŠ¶æ€åºåˆ—ä¸ acceptance length åˆ†å¸ƒã€‚
- **è¯„ä¼°ä»»åŠ¡ä¸æ•°æ®é›†**ï¼š
  - å¤šè½®å¯¹è¯ï¼š**MT-bench**
  - æ•°å­¦æ¨ç†ï¼š**GSM8K**
  - æŒ‡ä»¤è·Ÿéšï¼š**Alpaca**
  - ä»£ç ç”Ÿæˆï¼š**MBPP**

> æ‰€æœ‰ä»»åŠ¡å‡æœªè¿›è¡Œä»»åŠ¡ç‰¹å®šå¾®è°ƒï¼Œä½¿ç”¨ç»Ÿä¸€æƒé‡æµ‹è¯•ã€‚

### å®éªŒè®¾ç½®
- **ç›®æ ‡ LLMs**ï¼š
  - LLaMA-Instruct 3.1 8B (**L3 8B**)
  - Vicuna 13B (**V13B**)
  - DeepSeek-R1-Distill-LLaMA 8B (**DSL 8B**)
- **Draft Model**ï¼šæ²¿ç”¨ EAGLE-3 ä¸­çš„å°å‹æ¨¡å‹æ¶æ„ã€‚
- **å®ç°åŸºç¡€**ï¼šåŸºäº EAGLE-3 å¼€æºä»£ç åº“å¼€å‘ã€‚
- **è®­ç»ƒç»†èŠ‚**ï¼š
  - ä½¿ç”¨ **REINFORCE** ç®—æ³•è¿›è¡Œ offline RL è®­ç»ƒ
  - å­¦ä¹ ç‡ï¼š1e-4
  - Branching factor $ k = 10 $
  - æœ€å¤§ draft model è°ƒç”¨æ¬¡æ•°ï¼š8
  - Temperature = 1.0ï¼ŒBatch size = 1
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼š2Ã— NVIDIA RTX 3090 GPU

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Speedup Ratio** | ç›¸å¯¹äº vanilla auto-regressive è§£ç çš„å®é™…åŠ é€Ÿæ¯” |
| **Average Acceptance Length (T)** | æ¯ä¸ª drafting-verification cycle ä¸­å¹³å‡æ¥å—çš„ token æ•°é‡ |
| **Average Number of Calls to Draft Model** | æ¯ cycle ä¸­å¹³å‡è°ƒç”¨ draft model çš„æ¬¡æ•°ï¼ˆä¸å†æ˜¯å›ºå®šå€¼ï¼‰ |

> æ³¨ï¼šæœªæŠ¥å‘Š acceptance rateï¼Œå›  RADAR ä¸ä¿®æ”¹ draft model ç»“æ„ï¼Œè¯¥æŒ‡æ ‡ä¸ EAGLE-3 ç›¸åŒã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Vanilla Auto-Regressive Decoding**ï¼šåŸºå‡†æ–¹æ³•ï¼ˆspeedup = 1.00xï¼‰
- **EAGLE-2**ï¼šåŸºäºåŠ¨æ€ draft tree çš„æ—©æœŸå·¥ä½œ
- **EAGLE-3**ï¼šå½“å‰æœ€å…ˆè¿›çš„ lossless speculative sampling æ–¹æ³•ï¼Œä½œä¸ºä¸»è¦å¯¹æ¯”å¯¹è±¡

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰

| Model | Method | MT-bench Speedup | GSM8K Speedup | Alpaca Speedup | MBPP Speedup |
|-------|--------|------------------|---------------|----------------|--------------|
| L3 8B | Eagle-2 | 2.56x | 3.43x | 2.89x | 3.29x |
| L3 8B | Eagle-3 | 3.08x | 4.68x | 3.86x | 4.21x |
| L3 8B | **RADAR** | **3.41x** | **4.82x** | **4.04x** | **4.44x** |
| V13B  | Eagle-3 | 3.74x | 4.24x | 3.50x | 4.55x |
| V13B  | **RADAR** | **4.05x** | **4.36x** | **3.84x** | **4.75x** |
| DSL 8B| Eagle-3 | 3.42x | 4.39x | 3.08x | 3.71x |
| DSL 8B| **RADAR** | **3.86x** | **4.71x** | **3.17x** | **3.99x** |

âœ… **ç»“è®º**ï¼šRADAR åœ¨æ‰€æœ‰ 3 ä¸ª LLM å’Œ 4 ä¸ªä»»åŠ¡ä¸Šå‡å–å¾—æœ€é«˜ speedup ratioï¼Œç›¸æ¯” EAGLE-3 æå‡ **3% ~ 29%**ã€‚

### Acceptance Length å¯¹æ¯”
- RADAR çš„ average acceptance length ç•¥ä½äº EAGLE-3ï¼ˆçº¦ä½ 1.2%ï¼‰ï¼Œä½†ä»ç»´æŒé«˜ä½ã€‚
- è¡¨æ˜å…¶å¹¶æœªç‰ºç‰² token åˆ©ç”¨æ•ˆç‡ã€‚

### Draft Model è°ƒç”¨æ¬¡æ•°ï¼ˆè§ Table 2ï¼‰

| Model | MT-bench | GSM8K | Alpaca | MBPP |
|-------|----------|-------|--------|------|
| L3 8B | 5.25     | 6.19  | 6.20   | 6.60 |
| V13B  | 6.88     | 7.26  | 6.83   | 7.26 |
| DSL 8B| 6.10     | 7.20  | 5.85   | 6.47 |

> âœ… EAGLE-3 å›ºå®šè°ƒç”¨ 8 æ¬¡ï¼Œè€Œ RADAR å¹³å‡ä»…è°ƒç”¨ **5.25â€“7.26 æ¬¡**ï¼Œ**å¹³å‡å‡å°‘ 18.7% çš„è°ƒç”¨æ¬¡æ•°**ã€‚

### å›¾å½¢åˆ†æï¼ˆFigure 2ï¼‰
- **å›¾ (a)**ï¼šRADAR ä¸ EAGLE-3 çš„ acceptance length åˆ†å¸ƒç›¸è¿‘ï¼Œè¯´æ˜æœ‰æ•ˆæ€§ç›¸å½“ã€‚
- **å›¾ (b)**ï¼šRADAR çš„ draft model è°ƒç”¨æ¬¡æ•°åˆ†å¸ƒé›†ä¸­åœ¨ä¸­é—´èŒƒå›´ï¼ˆå¦‚ 5â€“7ï¼‰ï¼Œä¸”å­˜åœ¨è¾ƒå¤šæ—©æœŸç»ˆæ­¢ï¼ˆearly stopï¼‰ï¼Œä½“ç°å…¶åŠ¨æ€å†³ç­–èƒ½åŠ›ã€‚

### æ¶ˆèå®éªŒï¼ˆæ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºï¼Œä½†ä»è®¾è®¡å¯æ¨æ–­ï¼‰
è™½ç„¶æ²¡æœ‰ç‹¬ç«‹æ¶ˆèè¡¨ï¼Œä½†ä»¥ä¸‹è®¾è®¡ä½“ç°äº†å…³é”®ç»„ä»¶å¿…è¦æ€§ï¼š
- ä½¿ç”¨ confidence score ä½œä¸ºè¾“å…¥ â†’ éªŒè¯äº†è½»é‡ç‰¹å¾å³å¯æ”¯æŒæœ‰æ•ˆå†³ç­–
- æ„é€  acceptance length distribution dataset â†’ æ”¯æŒ offline RLï¼Œé¿å…å®æ—¶ LLM åé¦ˆ
- å¼•å…¥ step penalty (-Q) å’Œæœ€ç»ˆ speed reward â†’ å¹³è¡¡æ¢ç´¢ä¸æ•ˆç‡

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **åŠ¨æ€æ§åˆ¶ draft model è°ƒç”¨æ˜¯å¯è¡Œä¸”é«˜æ•ˆçš„**ï¼šé€šè¿‡å°†è¿‡ç¨‹å»ºæ¨¡ä¸º MDPï¼Œç»“åˆ offline RLï¼Œå¯ä»¥åœ¨ä¸è®¿é—®çœŸå® LLM çš„æƒ…å†µä¸‹è®­ç»ƒå‡ºé«˜æ€§èƒ½çš„å†³ç­–æ¨¡å‹ã€‚
2. **å‡å°‘å†—ä½™è°ƒç”¨å¯è¿›ä¸€æ­¥æå‡åŠ é€Ÿæ•ˆæœ**ï¼šå³ä½¿ acceptance length ç•¥æœ‰ä¸‹é™ï¼Œå¤§å¹…å‡å°‘ draft model è°ƒç”¨ä»èƒ½å¸¦æ¥æ•´ä½“æ¨ç†æ—¶é—´çš„æ˜¾è‘—ç¼©çŸ­ã€‚
3. **RADAR å®ç°äº†å½“å‰æœ€ä¼˜çš„ speculative sampling åŠ é€Ÿæ€§èƒ½**ï¼šåœ¨å¤šä¸ª LLM å’Œä»»åŠ¡ä¸Š consistently è¶…è¶Š EAGLE-3ï¼Œè¾¾åˆ° **3.17xâ€“4.82x** çš„åŠ é€Ÿæ¯”ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡çš„ acceptance length åˆ†å¸ƒä¼°è®¡**ï¼šè‹¥è®­ç»ƒæ•°æ®åˆ†å¸ƒä¸å®é™…éƒ¨ç½²åœºæ™¯åå·®è¾ƒå¤§ï¼Œå¯èƒ½å½±å“ prediction model æ³›åŒ–èƒ½åŠ›ã€‚
- **prediction model å¢åŠ é¢å¤–å»¶è¿Ÿ**ï¼šå°½ç®¡ $ T_{\text{eye}} $ å¾ˆå°ï¼Œä½†åœ¨æç«¯ä½å»¶è¿Ÿåœºæ™¯ä¸‹ä»éœ€è€ƒè™‘ã€‚
- **æœªä¼˜åŒ– draft model æœ¬èº«**ï¼šfocus åœ¨è°ƒåº¦ç­–ç•¥ï¼Œè€Œéæ”¹è¿› draft model çš„ç”Ÿæˆè´¨é‡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´å…ˆè¿›çš„ prediction model æ¶æ„ï¼ˆå¦‚ Transformer-basedï¼‰
- è®¾è®¡æ›´ç²¾ç»†çš„ reward functionï¼ˆä¾‹å¦‚å¼•å…¥ä¸ç¡®å®šæ€§ä¼°è®¡ï¼‰
- åŠ¨æ€è°ƒæ•´ branching factor $ k $
- å°†è¯¥æ¡†æ¶æ‰©å±•åˆ°å…¶ä»– speculative inference ç»“æ„ï¼ˆå¦‚ Medusa, Hydraï¼‰

---

> ğŸ”— **å¼€æºä¿¡æ¯**ï¼šä»£ç å·²å…¬å¼€äº GitHubï¼š[https://github.com/minaduki-sora/RADAR](https://github.com/minaduki-sora/RADAR)

</details>

---

### 15. [VersatileFFN: Achieving Parameter Efficiency in LLMs via Adaptive Wide-and-Deep Reuse](https://arxiv.org/abs/2512.14531)

**Authors**: Ying Nie, Kai Han, Hongguang Li, Hang Zhou, Tianyu Guo, Enhua Wu, Xinghao Chen, Yunhe Wang  
**Category**: cs.CL  
**Published**: 2025-12-17  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.14531v1  

#### Abstract
The rapid scaling of Large Language Models (LLMs) has achieved remarkable performance, but it also leads to prohibitive memory costs. Existing parameter-efficient approaches such as pruning and quantization mainly compress pretrained models without enhancing architectural capacity, thereby hitting t...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*VersatileFFN: Achieving Parameter Efficiency in LLMs via Adaptive Wide-and-Deep Reuse*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è™½ç„¶æ€§èƒ½å¼ºå¤§ï¼Œä½†å…¶åºå¤§çš„å‚æ•°é‡å¯¼è‡´**å†…å­˜å¼€é”€è¿‡é«˜**ï¼Œä¸¥é‡é™åˆ¶äº†å®é™…éƒ¨ç½²ã€‚ç°æœ‰çš„å‚æ•°é«˜æ•ˆæ–¹æ³•ï¼ˆå¦‚å‰ªæã€é‡åŒ–ã€LoRAç­‰ï¼‰ä¸»è¦åœ¨é¢„è®­ç»ƒæ¨¡å‹ä¸Šè¿›è¡Œå‹ç¼©ï¼Œ**å¹¶æœªå¢å¼ºæ¨¡å‹çš„è¡¨å¾èƒ½åŠ›**ï¼Œå› æ­¤å—é™äºåŸå§‹æ¶æ„çš„å®¹é‡ä¸Šé™ã€‚

æ­¤å¤–ï¼Œä¼ ç»Ÿçš„ **Mixture-of-Experts (MoE)** è™½ç„¶æå‡äº†å®¹é‡ï¼Œä½†å¼•å…¥äº†å¤§é‡é¢å¤–å‚æ•°ï¼›è€Œé€’å½’è®¡ç®—æ–¹æ³•ï¼ˆå¦‚å¤šå±‚å¾ªç¯FFNï¼‰è™½èŠ‚çœå‚æ•°ï¼Œå´ç¼ºä¹å®½åº¦ä¸Šçš„å¤šæ ·æ€§ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šVersatileFFN
ä½œè€…æå‡º **VersatileFFN** â€”â€”ä¸€ç§æ–°å‹çš„å‚æ•°é«˜æ•ˆ FFN ç»“æ„ï¼Œé€šè¿‡åœ¨**å›ºå®šå‚æ•°é¢„ç®—ä¸‹çµæ´»å¤ç”¨å‚æ•°**ï¼Œå®ç°â€œå®½ä¸”æ·±â€çš„è‡ªé€‚åº”è®¡ç®—ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
- **åŒè·¯å¾„è®¾è®¡**ï¼ˆå—äººç±»è®¤çŸ¥åŒç³»ç»Ÿç†è®ºå¯å‘ï¼‰ï¼š
  - **Width-Versatile Path**ï¼ˆç³»ç»Ÿ1ï¼šå¿«é€Ÿååº”ï¼‰
    - æ„å»ºè™šæ‹Ÿ MoEï¼šä»ä¸€ä¸ªå…±äº«çš„ FFN ä¸­åˆ‡åˆ†å‡ºå¤šä¸ªéé‡å çš„å­ç©ºé—´ä½œä¸ºâ€œè™šæ‹Ÿä¸“å®¶â€ï¼Œæ— éœ€æ–°å¢å‚æ•°å³å¯æ¨¡æ‹Ÿç¨€ç–ä¸“å®¶è·¯ç”±ã€‚
  - **Depth-Versatile Path**ï¼ˆç³»ç»Ÿ2ï¼šæ·±åº¦æ¨ç†ï¼‰
    - é€’å½’å¤ç”¨åŒä¸€ä¸ª FFN å¤šæ¬¡ï¼Œå¯¹å¤æ‚ token è¿›è¡Œè¿­ä»£ç²¾ç‚¼ï¼ŒåŠ¨æ€è°ƒæ•´å¤„ç†æ·±åº¦ã€‚
- **Difficulty-Aware Gating**
  - åˆ©ç”¨æ·±åº¦è·¯å¾„é¢„æµ‹çš„æœŸæœ›è¿­ä»£æ¬¡æ•°ä½œä¸º token éš¾åº¦ä»£ç†ï¼ŒåŠ¨æ€èåˆä¸¤ä¸ªè·¯å¾„è¾“å‡ºï¼š
    - â€œç®€å•â€token â†’ æ›´ä¾èµ–å®½åº¦è·¯å¾„ï¼ˆé«˜æ•ˆå¹¶è¡Œå¤„ç†ï¼‰
    - â€œå›°éš¾â€token â†’ æ›´ä¾èµ–æ·±åº¦è·¯å¾„ï¼ˆæ·±å±‚é€’å½’æ¨ç†ï¼‰

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | å‚æ•°å¢é•¿ | è®¡ç®—çµæ´»æ€§ | æ˜¯å¦æå‡è¡¨å¾èƒ½åŠ› |
|------|----------|------------|------------------|
| Pruning / Quantization | â†“ | âŒ | âŒï¼ˆä»…å‹ç¼©ï¼‰ |
| MoE | â†‘â†‘â†‘ï¼ˆæ˜¾è‘—å¢åŠ ï¼‰ | âœ…ï¼ˆå®½åº¦è·¯ç”±ï¼‰ | âœ… |
| k-Loop Recurrence | â†”ï¸ï¼ˆä¸å˜ï¼‰ | âœ…ï¼ˆå›ºå®šæ·±åº¦ï¼‰ | æœ‰é™ |
| **VersatileFFN** | **â†”ï¸ï¼ˆå‡ ä¹æ— å¢é•¿ï¼‰** | âœ…âœ…ï¼ˆå®½+æ·±è‡ªé€‚åº”ï¼‰ | âœ…âœ… |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿**ï¼šåœ¨**ä¸å¢åŠ å‚æ•°çš„å‰æä¸‹**ï¼ŒåŒæ—¶åˆ©ç”¨**å®½åº¦å¤šæ ·æ€§**å’Œ**æ·±åº¦é€’å½’æ€§**ï¼Œå®ç°æ›´å¼ºçš„è¡¨å¾èƒ½åŠ›å’Œæ›´é«˜çš„å‚æ•°æ•ˆç‡ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **é¢„è®­ç»ƒæ•°æ®**ï¼šFineWeb-Eduï¼ˆæ•™è‚²è´¨é‡ç½‘é¡µæ–‡æœ¬ï¼‰
  - å­é›†è§„æ¨¡ï¼š40B tokensï¼ˆç”¨äº354Mæ¨¡å‹ï¼‰ã€70B tokensï¼ˆç”¨äº720Mæ¨¡å‹ï¼‰
- **è¯„ä¼°åŸºå‡†**ï¼ˆé›¶æ ·æœ¬è¯„æµ‹ï¼‰ï¼š
  - PIQA, HellaSwag, OpenBookQA (OBQA), SciQ
  - ARC-easy (ARC-e), ARC-challenge (ARC-c)
  - CommonsenseQA (COMM), Winogrande (WINO)
  - æ‰€æœ‰ä»»åŠ¡é‡‡ç”¨ **OLMES** å·¥å…·è¿›è¡Œ zero-shot è¯„ä¼°

### âš™ï¸ å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹æ¶æ„**ï¼šåŸºäºå¼€æº OLMo2 æ¶æ„
  - ä¸¤ç§è§„æ¨¡ï¼š354M å’Œ 720M å‚æ•°
  - å±‚æ•°ï¼š15 å±‚ï¼Œæ¿€æ´»å‡½æ•°ä¸º SwiGLUï¼Œå½’ä¸€åŒ–ä¸º RMSNorm
  - åºåˆ—é•¿åº¦ï¼š4096
- **è®­ç»ƒæ–¹å¼**ï¼šç»§ç»­é¢„è®­ç»ƒï¼ˆcontinued pre-trainingï¼‰ï¼Œåœ¨ä¸€ä¸ª epoch å†…å®Œæˆ
- **ä¼˜åŒ–å™¨**ï¼šAdamWï¼Œcosine å­¦ä¹ ç‡è¡°å‡ï¼Œwarm-up å æ€»æ­¥æ•° 5%
- **è¶…å‚é€‰æ‹©**ï¼š
  - Width-Versatileï¼šé€‰ç”¨ `8 choose 2` è™šæ‹Ÿä¸“å®¶é…ç½®
  - Depth-Versatileï¼šæœ€å¤§å¾ªç¯æ¬¡æ•° $L_{\text{max}} = 4$

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
- ä¸»è¦æŒ‡æ ‡ï¼š**å¹³å‡å‡†ç¡®ç‡ï¼ˆAvg. Accuracyï¼‰**
- è¾…åŠ©æŒ‡æ ‡ï¼š
  - æ¨¡å‹æ€»å‚æ•°é‡ï¼ˆParamsï¼‰
  - FFN éƒ¨åˆ†çš„ FLOPsï¼ˆè¡¡é‡è®¡ç®—æˆæœ¬ï¼‰
  - è®­ç»ƒæŸå¤±ï¼ˆLossï¼‰

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **BASE** | åŸå§‹å¯†é›†æ¨¡å‹ï¼ˆæ ‡å‡† FFNï¼‰ |
| **MoE** | åœ¨ BASE ä¸Šæ·»åŠ  8 ä¸ªå°ä¸“å®¶ï¼Œtop-2 è·¯ç”± |
| **k-Loop** | å°† FFN å¾ªç¯æ‰§è¡Œ k æ¬¡ï¼ˆk=2,4,6ï¼‰ï¼Œå‚æ•°ä¸å˜ä½†è®¡ç®—é‡ç¿»å€ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & 2ï¼‰

#### âœ… åœ¨ 720M æ¨¡å‹ä¸Šçš„è¡¨ç°ï¼š
| æ–¹æ³• | å¹³å‡å‡†ç¡®ç‡ (Avg.) | æ€»å‚æ•° (M) | FFN FLOPs (M) | Loss |
|------|--------------------|-------------|----------------|-------|
| BASE | 53.83 | 720.81 | 849.35 | 2.519 |
| MoE | 55.87 | 1145.69 | 1061.69 | **2.411** |
| 4-LOOP | 56.33 | 720.81 | 3397.40 | 2.441 |
| 6-LOOP | 56.55 | 720.81 | 5096.10 | 2.430 |
| **VersatileFFN** | **57.03** | **721.09** | **2586.38** | 2.430 |

#### âœ… åœ¨ 354M æ¨¡å‹ä¸Šçš„è¡¨ç°ï¼š
| æ–¹æ³• | Avg. Acc. | Params (M) | FFN FLOPs (M) |
|------|-----------|------------|----------------|
| BASE | 47.98 | 354.71 | 377.49 |
| MoE | 51.48 | 543.59 | 471.86 |
| 4-LOOP | 51.98 | 354.71 | 1509.96 |
| **VersatileFFN** | **52.33** | **354.90** | **1236.08** |

> ğŸ’¡ **å…³é”®è§‚å¯Ÿ**ï¼š
> - VersatileFFN åœ¨æ‰€æœ‰æ¨¡å‹å°ºåº¦ä¸Šå‡å–å¾—**æœ€é«˜å¹³å‡å‡†ç¡®ç‡**
> - å‚æ•°ä»…å¢åŠ çº¦ **0.04%**ï¼ˆvs. MoE å¢åŠ  ~59%ï¼‰
> - è®¡ç®—é‡è¿œä½äº 6-Loopï¼ˆçº¦ä¸ºå…¶ 50%ï¼‰ï¼Œä½†ä»ä¼˜äºå…¶ç²¾åº¦

### ğŸ” ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **vs. MoE**ï¼š
  - å‡†ç¡®ç‡æ›´é«˜ï¼ˆ+1.16% @720Mï¼‰ï¼Œä¸”**å‚æ•°å‡ ä¹ä¸å˜**
  - MoE è™½ç„¶è®­ç»ƒ loss æ›´ä½ï¼Œä½†åœ¨ä¸‹æ¸¸ä»»åŠ¡æ³›åŒ–æ›´å·®
  - ç‰¹åˆ«æ˜¯åœ¨ **ARC-e** å’Œ **CommonsenseQA** ç­‰æ¨ç†å¯†é›†å‹ä»»åŠ¡ä¸Šé¢†å…ˆæ˜æ˜¾ï¼ˆ+3.33%ï¼‰
- **vs. k-Loop**ï¼š
  - åœ¨æ›´ä½ FLOPs ä¸‹è¾¾åˆ°æ›´é«˜æ€§èƒ½ï¼ˆä¾‹å¦‚ 4-Loop éœ€ 3397M FLOPsï¼ŒVersatileFFN ä»…éœ€ 2586Mï¼‰
  - è¡¨æ˜å…¶èµ„æºåˆ†é…æ›´æ™ºèƒ½ï¼Œé¿å…æ— æ•ˆé‡å¤è®¡ç®—

### ğŸ”§ æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

| æ–¹æ³•é…ç½® | Loss | Acc (%) |
|--------|------|---------|
| BASE | 2.779 | 47.98 |
| + Width-Versatile | 2.633 | 50.98 |
| + Depth-Versatile | 2.625 | 51.86 |
| + Gatingï¼ˆå®Œæ•´ç‰ˆï¼‰ | **2.617** | **52.33** |

> âœ… ç»“è®ºï¼šä¸¤ä¸ªåˆ†æ”¯**äº’è¡¥ååŒ**ï¼Œè”åˆä½¿ç”¨æ•ˆæœæœ€ä½³ï¼›gating æœºåˆ¶è¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚

å…¶ä»–æ¶ˆèï¼š
- æœ€ä¼˜ä¸“å®¶é…ç½®ï¼š`(8 choose 2)` > `(8 choose 4)` æˆ– `(16 choose 4)`
- æœ€ä¼˜å¾ªç¯æ¬¡æ•°ï¼š4 æ¬¡ > 6 æ¬¡ï¼ˆè¿‡å¤šå¾ªç¯å¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆï¼‰

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **å‚æ•°å¤ç”¨ä¼˜äºå‚æ•°æ‰©å¼ **ï¼š
   - åœ¨å›ºå®šå‚æ•°é¢„ç®—ä¸‹ï¼Œé€šè¿‡**ç»“æ„åŒ–å¤ç”¨**ï¼ˆå®½+æ·±ï¼‰å¯æ˜¾è‘—è¶…è¶Šä¼ ç»Ÿ MoE å’Œçº¯é€’å½’æ–¹æ³•ã€‚
2. **è‡ªé€‚åº”è®¡ç®—æ˜¯å…³é”®**ï¼š
   - åŠ¨æ€æ ¹æ® token éš¾åº¦åˆ†é…è®¡ç®—è·¯å¾„ï¼ˆå®½åº¦ or æ·±åº¦ï¼‰ï¼Œå®ç°äº†â€œè¯¥å¿«åˆ™å¿«ï¼Œè¯¥æ…¢åˆ™æ…¢â€çš„æ™ºèƒ½æ¨ç†ã€‚
3. **åŒç³»ç»ŸååŒæœ‰æ•ˆ**ï¼š
   - å®½åº¦è·¯å¾„æä¾›å¤šæ ·åŒ–å“åº”èƒ½åŠ›ï¼Œæ·±åº¦è·¯å¾„æ”¯æŒå¤æ‚è¯­ä¹‰æ¨ç†ï¼ŒäºŒè€…ç»“åˆå½¢æˆæ›´å¼ºçš„é€šç”¨è¡¨å¾ã€‚
4. **æé«˜çš„å‚æ•°æ•ˆç‡**ï¼š
   - å¼•å…¥çš„ router å’Œ loop predictor ä»…å¸¦æ¥ <0.1% å‚æ•°å¢é•¿ï¼Œå´å¸¦æ¥è¶…è¿‡ 3% çš„å‡†ç¡®ç‡æå‡ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **è®¡ç®—å»¶è¿Ÿå¯èƒ½ä¸Šå‡**ï¼šå°½ç®¡å‚æ•°å°‘ï¼Œä½†æ·±åº¦è·¯å¾„çš„é€’å½’æ‰§è¡Œå¯èƒ½å½±å“æ¨ç†é€Ÿåº¦ï¼ˆå°¤å…¶åœ¨é•¿åºåˆ—åœºæ™¯ï¼‰ã€‚
- **ç¡¬ä»¶åˆ©ç”¨ç‡æŒ‘æˆ˜**ï¼šåŠ¨æ€æ§åˆ¶æµï¼ˆå¦‚ early-exitï¼‰éœ€è¦å®šåˆ¶åŒ–æ¨ç†å¼•æ“æ”¯æŒã€‚
- **å½“å‰ä»ä¾èµ–é¢„è®­ç»ƒæƒé‡åˆå§‹åŒ–**ï¼šå°šæœªéªŒè¯ä»å¤´è®­ç»ƒçš„æ•ˆæœã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´é«˜æ•ˆçš„æ§åˆ¶å™¨è®¾è®¡ï¼ˆå¦‚è½»é‡åŒ– loop predictorï¼‰
- æ‰©å±•åˆ° Vision Transformer æˆ–å¤šæ¨¡æ€æ¨¡å‹
- å¼€å‘ä¸“ç”¨æ¨ç†æ¡†æ¶ä»¥æ”¯æŒåŠ¨æ€è®¡ç®—å›¾è°ƒåº¦
- ç ”ç©¶â€œcompute-heavy, memory-lightâ€æ¶æ„çš„è®¾è®¡èŒƒå¼ï¼Œæ¨åŠ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„é«˜çº§æ¨ç†èƒ½åŠ›

---

## æ€»ç»“
> **VersatileFFN** æå‡ºäº†ä¸€ç§å…¨æ–°çš„å‚æ•°é«˜æ•ˆæ€æƒ³ï¼š**é€šè¿‡æ™ºèƒ½åœ°å¤ç”¨å‚æ•°è€Œéç›²ç›®æ‰©å±•ï¼Œåœ¨ä¸å¢åŠ å†…å­˜è´Ÿæ‹…çš„å‰æä¸‹ï¼Œé‡Šæ”¾æ›´å¤§çš„æ¨¡å‹æ½œåŠ›**ã€‚å…¶å®éªŒå……åˆ†è¯æ˜ï¼Œ**è®¡ç®—çš„çµæ´»æ€§**ï¼ˆadaptive wide-and-deep reuseï¼‰å¯ä»¥æˆä¸ºçªç ´ LLM æ€§èƒ½ç“¶é¢ˆçš„æ–°è·¯å¾„ï¼Œä¸ºæœªæ¥â€œå°å†…å­˜ã€å¤§æ™ºèƒ½â€çš„æ¨¡å‹è®¾è®¡æä¾›äº†é‡è¦å¯ç¤ºã€‚

</details>

---

### 16. [TiME: Tiny Monolingual Encoders for Efficient NLP Pipelines](https://arxiv.org/abs/2512.14645)

**Authors**: David Schulmeister, Valentin Hartmann, Lars Klein, Robert West  
**Category**: cs.CL  
**Published**: 2025-12-17  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.14645v1  

#### Abstract
Today, a lot of research on language models is focused on large, general-purpose models. However, many NLP pipelines only require models with a well-defined, small set of capabilities. While large models are capable of performing the tasks of those smaller models, they are simply not fast enough to ...

---

### 17. [FusAD: Time-Frequency Fusion with Adaptive Denoising for General Time Series Analysis](https://arxiv.org/abs/2512.14078)

**Authors**: Da Zhang, Bingyu Li, Zhiyuan Zhao, Feiping Nie, Junyu Gao, Xuelong Li  
**Category**: cs.LG  
**Published**: 2025-12-17  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.14078v1  

#### Abstract
Time series analysis plays a vital role in fields such as finance, healthcare, industry, and meteorology, underpinning key tasks including classification, forecasting, and anomaly detection. Although deep learning models have achieved remarkable progress in these areas in recent years, constructing ...

---

### 18. [Blind Radio Mapping via Spatially Regularized Bayesian Trajectory Inference](https://arxiv.org/abs/2512.13701)

**Authors**: Zheng Xing, Junting Chen  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.13701v1  

#### Abstract
Radio maps enable intelligent wireless applications by capturing the spatial distribution of channel characteristics. However, conventional construction methods demand extensive location-labeled data, which are costly and impractical in many real-world scenarios. This paper presents a blind radio ma...

---

### 19. [Compressed Causal Reasoning: Quantization and GraphRAG Effects on Interventional and Counterfactual Accuracy](https://arxiv.org/abs/2512.13725)

**Authors**: Steve Nwaiwu, Nipat Jongsawat, Anucha Tungkasthan  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.13725v1  

#### Abstract
Causal reasoning in Large Language Models spanning association, intervention, and counterfactual inference is essential for reliable decision making in high stakes settings. As deployment shifts toward edge and resource constrained environments, quantized models such as INT8 and NF4 are becoming sta...

---

### 20. [OpenDataArena: A Fair and Open Arena for Benchmarking Post-Training Dataset Value](https://arxiv.org/abs/2512.14051)

**Authors**: Mengzhang Cai, Xin Gao, Yu Li, Honglin Lin, Zheng Liu, Zhuoshi Pan, Qizhi Pei, Xiaoran Shang, Mengyuan Sun, Zinan Tang, Xiaoyang Wang, Zhanping Zhong, Yun Zhu, Dahua Lin, Conghui He, Lijun Wu  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.14051v1  

#### Abstract
The rapid evolution of Large Language Models (LLMs) is predicated on the quality and diversity of post-training datasets. However, a critical dichotomy persists: while models are rigorously benchmarked, the data fueling them remains a black box--characterized by opaque composition, uncertain provena...

---

### 21. [Grammar Search for Multi-Agent Systems](https://arxiv.org/abs/2512.14079)

**Authors**: Mayank Singh, Vikas Yadav, Shiva Krishna Reddy Malay, Shravan Nayak, Sai Rajeswar, Sathwik Tejaswi Madhusudhan, Eduardo Blanco  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.14079v1  

#### Abstract
Automatic search for Multi-Agent Systems has recently emerged as a key focus in agentic AI research. Several prior approaches have relied on LLM-based free-form search over the code space. In this work, we propose a more structured framework that explores the same space through a fixed set of simple...

---

### 22. [Astraea: A State-Aware Scheduling Engine for LLM-Powered Agents](https://arxiv.org/abs/2512.14142)

**Authors**: Hongqiu Ni, Jiabao Zhang, Guopeng Li, Zilong Wang, Ruiqi Wu, Chi Zhang, Haisheng Tan  
**Category**: cs.CL  
**Published**: 2025-12-17  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.14142v1  

#### Abstract
Large Language Models (LLMs) are increasingly being deployed as intelligent agents. Their multi-stage workflows, which alternate between local computation and calls to external network services like Web APIs, introduce a mismatch in their execution pattern and the scheduling granularity of existing ...

---

### 23. [Delete and Retain: Efficient Unlearning for Document Classification](https://arxiv.org/abs/2512.13711)

**Authors**: Aadya Goel, Mayuri Sridhar  
**Category**: cs.LG  
**Published**: 2025-12-17  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.13711v1  

#### Abstract
Machine unlearning aims to efficiently remove the influence of specific training data from a model without full retraining. While much progress has been made in unlearning for LLMs, document classification models remain relatively understudied. In this paper, we study class-level unlearning for docu...

---

### 24. [State-Dependent Refusal and Learned Incapacity in RLHF-Aligned Language Models](https://arxiv.org/abs/2512.13762)

**Authors**: TK Lee  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.13762v1  

#### Abstract
Large language models (LLMs) are widely deployed as general-purpose tools, yet extended interaction can reveal behavioral patterns not captured by standard quantitative benchmarks. We present a qualitative case-study methodology for auditing policy-linked behavioral selectivity in long-horizon inter...

---

### 25. [Sparsity-Controllable Dynamic Top-p MoE for Large Foundation Model Pre-training](https://arxiv.org/abs/2512.13996)

**Authors**: Can Jin, Hongwu Peng, Mingcan Xiang, Qixin Zhang, Xiangchi Yuan, Amit Hasan, Ohiremen Dibua, Yifan Gong, Yan Kang, Dimitris N. Metaxas  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.13996v1  

#### Abstract
Sparse Mixture-of-Experts (MoE) architectures effectively scale model capacity by activating only a subset of experts for each input token. However, the standard Top-k routing strategy imposes a uniform sparsity pattern that ignores the varying difficulty of tokens. While Top-p routing offers a flex...

---

### 26. [TiCard: Deployable EXPLAIN-only Residual Learning for Cardinality Estimation](https://arxiv.org/abs/2512.14358)

**Authors**: Qizhi Wang  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.14358v1  

#### Abstract
Cardinality estimation is a key bottleneck for cost-based query optimization, yet deployable improvements remain difficult: classical estimators miss correlations, while learned estimators often require workload-specific training pipelines and invasive integration into the optimizer. This paper pres...

---

### 27. [Physics-Guided Deep Learning for Heat Pump Stress Detection: A Comprehensive Analysis on When2Heat Dataset](https://arxiv.org/abs/2512.13696)

**Authors**: Md Shahabub Alam, Md Asifuzzaman Jishan, Ayan Kumar Ghosh  
**Category**: cs.LG  
**Published**: 2025-12-17  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.13696v1  

#### Abstract
Heat pump systems are critical components in modern energy-efficient buildings, yet their operational stress detection remains challenging due to complex thermodynamic interactions and limited real-world data. This paper presents a novel Physics-Guided Deep Neural Network (PG-DNN) approach for heat ...

---

### 28. [Sliding Window Recurrences for Sequence Models](https://arxiv.org/abs/2512.13921)

**Authors**: Dragos Secrieru, Garyk Brixi, Yoshua Bengio, Taiji Suzuki, Michael Poli, Stefano Massaroli  
**Category**: cs.LG  
**Published**: 2025-12-17  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.13921v1  

#### Abstract
Multi-hybrid architectures are poised to take over language modeling due to better quality and performance. We introduce a hierarchical decomposition framework for linear recurrences that allows us to develop algorithms aligned with GPU memory hierarchies, yielding Sliding Window Recurrences. We foc...

---

### 29. [A Complete Guide to Spherical Equivariant Graph Transformers](https://arxiv.org/abs/2512.13927)

**Authors**: Sophia Tang  
**Category**: cs.LG  
**Published**: 2025-12-17  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.13927v1  

#### Abstract
Spherical equivariant graph neural networks (EGNNs) provide a principled framework for learning on three-dimensional molecular and biomolecular systems, where predictions must respect the rotational symmetries inherent in physics. These models extend traditional message-passing GNNs and Transformers...

---

### 30. [EvoLattice: Persistent Internal-Population Evolution through Multi-Alternative Quality-Diversity Graph Representations for LLM-Guided Program Discovery](https://arxiv.org/abs/2512.13857)

**Authors**: Kamer Ali Yuksel  
**Category**: cs.AI  
**Published**: 2025-12-17  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.13857v1  

#### Abstract
Large language models (LLMs) are increasingly used to evolve programs and multi-agent systems, yet most existing approaches rely on overwrite-based mutations that maintain only a single candidate at a time. Such methods discard useful variants, suffer from destructive edits, and explore a brittle se...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
