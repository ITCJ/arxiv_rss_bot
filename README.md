# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-02-18 06:45:21 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [ExpertWeaver: Unlocking the Inherent MoE in Dense LLMs with GLU Activation Patterns](https://arxiv.org/abs/2602.15521)

**Authors**: Ziyu Zhao, Tong Zhu, Zhi Zhang, Tiantian Fan, Jinluan Yang, Kun Kuang, Zhongyu Wei, Fei Wu, Yu Cheng  
**Category**: cs.CL  
**Published**: 2026-02-18  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.15521v1  

#### Abstract
Mixture-of-Experts (MoE) effectively scales model capacity while preserving computational efficiency through sparse expert activation. However, training high-quality MoEs from scratch is prohibitively expensive. A promising alternative is to convert pretrained dense models into sparse MoEs. Existing...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šExpertWeaver: Unlocking the Inherent MoE in Dense LLMs with GLU Activation Patterns**

---

## 1. **è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å½“å‰ï¼Œ**Mixture-of-Experts (MoE)** æ¶æ„è™½èƒ½æœ‰æ•ˆæ‰©å±•æ¨¡å‹å®¹é‡å¹¶ä¿æŒæ¨ç†æ•ˆç‡ï¼Œä½†ä»é›¶è®­ç»ƒé«˜è´¨é‡ MoE æ¨¡å‹æˆæœ¬æé«˜ã€‚ä¸€ç§æ›¿ä»£æ–¹æ¡ˆæ˜¯å°†é¢„è®­ç»ƒçš„ **dense LLM** è½¬æ¢ä¸º **sparse MoE**ï¼Œå³â€œ**dense-to-MoE conversion**â€ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **ç ´åäº† dense æ¨¡å‹å†…åœ¨çš„æ¿€æ´»æ¨¡å¼**ï¼ˆå¦‚ GLU çš„é—¨æ§æœºåˆ¶ï¼‰ï¼Œå¯¼è‡´ä¸“å®¶æ„å»ºæ¬¡ä¼˜ï¼›
- å¿½ç•¥äº†ä¸åŒå±‚ä¹‹é—´çš„åŠŸèƒ½å·®å¼‚ï¼Œé‡‡ç”¨ç»Ÿä¸€é…ç½®ï¼›
- å¤šæ•°æ–¹æ³•éœ€è¦é¢å¤–çš„ **router training** æˆ–å¤§é‡æŒç»­é¢„è®­ç»ƒï¼ˆCPTï¼‰ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æœ¬æ–‡æå‡º **ExpertWeaver**ï¼Œä¸€ä¸ª**æ— éœ€è®­ç»ƒ**ï¼ˆtraining-freeï¼‰çš„æ¡†æ¶ï¼Œåˆ©ç”¨ **GLU æ¿€æ´»æ¨¡å¼** å°† dense LLM è½¬æ¢ä¸ºç»“æ„åŒ–çš„ MoE æ¨¡å‹ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- **GLU çš„é—¨æ§æœºåˆ¶å¤©ç„¶æ­ç¤ºäº†æ¨¡å‹å†…éƒ¨çš„åŠŸèƒ½ç»“æ„**ï¼Œå¯ä½œä¸º MoE æ„å»ºçš„è“å›¾ã€‚
- é€šè¿‡åˆ†æ GLU çš„ç»†ç²’åº¦ç¥ç»å…ƒæ¿€æ´»æ¨¡å¼ï¼Œå‘ç°ä¸¤ç±»ç¥ç»å…ƒï¼š
  - **é€šç”¨ç¥ç»å…ƒ**ï¼ˆuniversal neuronsï¼‰ï¼šåœ¨å„ç±»ä»»åŠ¡ä¸­å‡è¢«æ¿€æ´»ï¼Œé€‚åˆç»„æˆ**å…±äº«ä¸“å®¶**ï¼ˆshared expertï¼‰ï¼›
  - **ä¸“ç”¨ç¥ç»å…ƒ**ï¼ˆspecialized neuronsï¼‰ï¼šä»…åœ¨ç‰¹å®šä»»åŠ¡ä¸­æ¿€æ´»ï¼Œé€‚åˆèšç±»ä¸º**è·¯ç”±ä¸“å®¶**ï¼ˆrouted expertsï¼‰ã€‚
- å¼•å…¥ **layer-adaptive é…ç½®**ï¼šä¸åŒå±‚çš„ç¥ç»å…ƒä¸“ä¸šåŒ–ç¨‹åº¦ä¸åŒï¼Œåº”åŠ¨æ€åˆ†é…å…±äº«ä¸è·¯ç”±ä¸“å®¶çš„æ¯”ä¾‹ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ExpertWeaver | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ CMoEã€Llama-MoEï¼‰ |
|------|-------------|-------------------------------|
| æ˜¯å¦éœ€è¦è®­ç»ƒ | âŒ æ— éœ€è®­ç»ƒ | âœ… éœ€è¦é¢å¤–è®­ç»ƒæˆ– CPT |
| æ˜¯å¦ä¿ç•™åŸå§‹æ¿€æ´»ç»“æ„ | âœ… å®Œæ•´ä¿ç•™ GLU æ¿€æ´»æ¨¡å¼ | âŒ æ‰“ç ´åŸæœ‰ç»“æ„ |
| æ˜¯å¦è€ƒè™‘å±‚é—´å·®å¼‚ | âœ… å±‚è‡ªé€‚åº”é…ç½® | âŒ å…¨å±€ç»Ÿä¸€é…ç½® |
| è·¯ç”±å™¨æ„é€ æ–¹å¼ | âœ… åˆ©ç”¨åŸå§‹é—¨æ§æƒé‡ï¼Œæ— è®­ç»ƒ | âŒ éœ€å­¦ä¹ æˆ–éšæœºåˆå§‹åŒ– |

---

## 2. **æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **æ ¡å‡†æ•°æ®é›†ï¼ˆCalibration Datasetï¼‰**ï¼š
  - **Flan-v2**ï¼šåŒ…å« 48 ä¸ªä»»åŠ¡ã€10 ä¸ªä»»åŠ¡ç°‡ï¼Œç”¨äºæ•æ‰å¤šä»»åŠ¡ä¸‹çš„ç¥ç»å…ƒæ¿€æ´»æ¨¡å¼ã€‚
  - æ¯ä»»åŠ¡é‡‡æ · 5 ä¸ªæ ·æœ¬ï¼Œå…± 240 ä¸ªæ ·æœ¬ã€‚
- **æŒç»­é¢„è®­ç»ƒæ•°æ®é›†**ï¼š
  - **FineWeb-Edu**ï¼šç”¨äº MoE ä¸‹å¾ªç¯ï¼ˆdowncyclingï¼‰åçš„ CPTã€‚
- **è¯„ä¼°æ•°æ®é›†**ï¼š
  - **MMLU**, **HellaSwag**, **ARC-e/c**, **PIQA**, **WinoGrande**, **LogiQA**, **SciQ**, **GSM8K**, **HumanEval**, **IFEval**

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**
#### **ä¸¤ç§åº”ç”¨åœºæ™¯**
1. **Training-free åŠ¨æ€ç»“æ„å‰ªæï¼ˆDynamic Structural Pruningï¼‰**
   - ç›®æ ‡ï¼šä½ç¨€ç–åº¦ä¸‹æå‡æ¨ç†æ•ˆç‡ã€‚
   - ç¨€ç–åº¦ï¼š25%
   - ä¸è¿›è¡Œä»»ä½•è®­ç»ƒï¼Œç›´æ¥éƒ¨ç½²è½¬æ¢åçš„ MoEã€‚
   - è¯„ä¼°æŒ‡æ ‡ï¼šå„åŸºå‡†ä»»åŠ¡å‡†ç¡®ç‡ + å¹³å‡åˆ†ã€‚

2. **Model Downcyclingï¼ˆæ¨¡å‹é™å¾ªç¯ï¼‰**
   - ç›®æ ‡ï¼šå°†å¤§ dense æ¨¡å‹é«˜æ•ˆè½¬æ¢ä¸ºé«˜æ€§èƒ½ MoEã€‚
   - æµç¨‹ï¼š
     - ä½¿ç”¨ ExpertWeaver åˆå§‹åŒ– MoEï¼›
     - è¿›è¡Œ **200B tokens** çš„æŒç»­é¢„è®­ç»ƒï¼ˆCPTï¼‰ï¼›
     - ä¸¤é˜¶æ®µç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼šå…ˆé€šç”¨å¯¹è¯ï¼Œå†ä»£ç æ•°å­¦ã€‚
   - è¯„ä¼°ï¼šæŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼ˆinstruction-tuning åæ€§èƒ½ï¼‰ã€‚

#### **è¯„ä¼°æŒ‡æ ‡**
- ä¸»è¦æŒ‡æ ‡ï¼šå„ä»»åŠ¡å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰
- ç»¼åˆæŒ‡æ ‡ï¼šå¹³å‡å¾—åˆ†ï¼ˆAvg.ï¼‰
- æ¨ç†æ•ˆç‡ï¼šRPSï¼ˆæ¯ç§’è¯·æ±‚ï¼‰ã€OTPSï¼ˆæ¯ç§’è¾“å‡º token æ•°ï¼‰ã€TTFTï¼ˆé¦– token æ—¶é—´ï¼‰ã€TPOTï¼ˆæ¯è¾“å‡º token æ—¶é—´ï¼‰

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
#### **ç»“æ„å‰ªæåŸºçº¿**
- **LLM-Pruner**ï¼šåŸºäºæ¢¯åº¦å’Œå‚æ•°é‡è¦æ€§çš„é™æ€å‰ªæã€‚
- **FLAP**ï¼šåŸºäºè¾“å‡ºç‰¹å¾ç¨³å®šæ€§çš„å‰ªæã€‚
- **CMoE**ï¼šåŸºäºå¹³è¡¡èšç±»çš„ dense-to-MoE æ–¹æ³•ã€‚

#### **MoE ä¸‹å¾ªç¯åŸºçº¿**
- **OLMoE-1B-7B**ï¼šä»å¤´è®­ç»ƒçš„ MoEã€‚
- **LLaMA-MoE-v1/v2**ï¼šåŸºäº LLaMA çš„ MoE å˜ä½“ã€‚
- **OpenMoE**ï¼šå¼€æº MoE ç³»åˆ—ã€‚

---

## 3. **ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **1. åŠ¨æ€ç»“æ„å‰ªæï¼ˆ25% sparsityï¼‰**
| æ–¹æ³• | MMLU | HellaSwag | ARC-e | ARC-c | PIQA | **Avg** |
|------|------|-----------|-------|--------|-------|--------|
| Dense (Qwen2.5-7B) | 74.2 | 80.3 | 77.8 | 63.8 | 80.0 | 75.2 |
| LLM-Pruner | 55.9 | 72.2 | 71.0 | 49.1 | 77.0 | 65.0 |
| FLAP | 54.7 | 58.5 | 67.3 | 42.2 | 70.8 | 58.7 |
| **ExpertWeaver** | **61.6** | **72.3** | **71.5** | **53.5** | **76.3** | **67.0** |

> ğŸ’¡ **ç›¸å¯¹æå‡**ï¼šæ¯”æœ€å¼ºåŸºçº¿ LLM-Pruner æå‡ **3.1%**ï¼Œæ¯” CMoEï¼ˆåœ¨ LLaMA ä¸Šï¼‰æå‡ **5.6%**ã€‚

#### **2. Downcycling æ€§èƒ½å¯¹æ¯”ï¼ˆCPT 200B tokensï¼‰**
| æ¨¡å‹ | MMLU | HellaSwag | ARC-e | ARC-c | PIQA | **Avg** |
|------|------|-----------|-------|--------|-------|--------|
| Qwen2.5-7B (dense) | 74.1 | 80.2 | 77.5 | 63.7 | 79.7 | 73.2 |
| **ExpertWeaver (Qwen2.5-7B)** | **45.6** | **73.7** | **72.4** | **56.3** | **78.0** | **65.3** |
| OLMoE-1B-7B* (500B tokens) | 53.8 | 79.6 | 76.3 | 55.6 | 80.1 | 67.2 |
| **ExpertWeaver (OLMo-7B)** | **45.0** | **61.2** | **69.3** | **38.8** | **74.5** | **62.1** |

> ğŸ’¡ **å…³é”®å‘ç°**ï¼š
> - ExpertWeaver (Qwen2.5-7B) åœ¨ä»…æ¿€æ´» **3.5B å‚æ•°**ï¼ˆæ€» 7Bï¼‰çš„æƒ…å†µä¸‹ï¼Œè¾¾åˆ° **65.3** å¹³å‡åˆ†ï¼Œä¸ºåŸæ¨¡å‹çš„ **87.6%**ã€‚
> - ExpertWeaver (OLMo-7B) ä»…ç”¨ 200B tokens CPTï¼Œæ€§èƒ½å·²è¾¾ OLMo-7B åŸå§‹æ€§èƒ½çš„ **97.35%**ï¼Œä¸”æ¥è¿‘ä»å¤´è®­ç»ƒ 500B tokens çš„ OLMoEã€‚

#### **3. æŒ‡ä»¤å¾®è°ƒåæ€§èƒ½ï¼ˆSFTï¼‰**
| æ–¹æ³• | MMLU | ARC-c | GSM8K | HumanEval | IFEval | **Avg** |
|------|------|--------|--------|------------|--------|--------|
| LLaMA-MoE-v2 | 40.9 | 40.2 | 55.0 | 51.2 | 36.0 | 44.66 |
| OLMoE-1B-7B | 53.79 | 55.63 | 40.94 | 40.48 | 35.49 | 45.27 |
| **ExpertWeaver-Instruct** | **50.60** | **69.80** | **57.10** | **50.20** | **33.10** | **52.16** |

> âœ… **SOTA è¡¨ç°**ï¼šå¹³å‡åˆ† **52.16**ï¼Œæ˜¾è‘—ä¼˜äºæ‰€æœ‰ MoE åŸºçº¿ã€‚

#### **4. æ¨ç†æ•ˆç‡ï¼ˆvLLM æµ‹è¯•ï¼‰**
| GPU | æ–¹æ³• | RPS â†‘ | OTPS â†‘ | TTFT â†“ (ms) | TPOT â†“ (ms) |
|-----|------|--------|---------|--------------|--------------|
| H100 | Qwen2.5-7B | 41.41 | 5299.96 | 1404.5 | 18.5 |
| H100 | **ExpertWeaver** | **44.04** | **5637.42** | **542.2** | **9.8** |

> âš¡ **æ¨ç†ä¼˜åŠ¿**ï¼šååæ›´é«˜ï¼Œå»¶è¿Ÿæ›´ä½ï¼Œå°¤å…¶åœ¨é¦– token æ—¶é—´ä¸Šå¤§å¹…ä¼˜åŒ–ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰**

| å®éªŒç»´åº¦ | æœ€ä½³é…ç½® | å‘ç° |
|--------|--------|------|
| **å…±äº«ä¸“å®¶æ¯”ä¾‹**ï¼ˆÎ±_min, Î±_maxï¼‰ | (0.2, 0.7) | å±‚è‡ªé€‚åº”é…ç½®æ˜¾è‘—ä¼˜äºå…¨å±€å›ºå®šæ¯”ä¾‹ |
| **ä¸“ä¸šåŒ–é˜ˆå€¼ T**ï¼ˆCV thresholdï¼‰ | 0.6 | æ¨¡å‹å¯¹ T é²æ£’ï¼Œ0.5~0.7 åŒºé—´è¡¨ç°ç¨³å®š |
| **ä¸“å®¶ç²’åº¦**ï¼ˆexpert granularityï¼‰ | 64 | 64~128 ä¸“å®¶æ—¶æ€§èƒ½æœ€ä½³ï¼Œè¿‡å°‘æˆ–è¿‡å¤šå‡ä¸‹é™ |
| **æ ¡å‡†æ•°æ®é›†** | Flan-v2 > C4 | å¤šä»»åŠ¡æ•°æ®é›†æ˜¾è‘—ä¼˜äºå•åŸŸè¯­æ–™ï¼ˆ67.0 vs 65.8ï¼‰ |
| **æ•°æ®é‡ä¸å¤šæ ·æ€§** | 50% ä»»åŠ¡ â†’ 98% æ€§èƒ½ | æ•°æ®æ•ˆç‡é«˜ï¼Œæ— éœ€å…¨é‡ä»»åŠ¡å³å¯æ¥è¿‘æœ€ä¼˜ |

---

## 4. **å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **GLU æ¿€æ´»æ¨¡å¼è•´å« MoE ç»“æ„**ï¼š
   - GLU çš„é—¨æ§ä¿¡å·è‡ªç„¶è¯±å¯¼**ç»“æ„åŒ–ç¨€ç–æ€§**ï¼Œæ˜¯ dense-to-MoE è½¬æ¢çš„ç†æƒ³ä¿¡å·æºã€‚
   - å­˜åœ¨**é€šç”¨ç¥ç»å…ƒ**ä¸**ä¸“ç”¨ç¥ç»å…ƒ**ï¼Œåˆ†åˆ«å¯¹åº”å…±äº«ä¸“å®¶ä¸è·¯ç”±ä¸“å®¶ã€‚

2. **å±‚é—´å¼‚è´¨æ€§éœ€è¢«å»ºæ¨¡**ï¼š
   - æµ…å±‚ä¸æ·±å±‚ç¥ç»å…ƒä¸“ä¸šåŒ–ç¨‹åº¦ä¸åŒï¼ˆæµ…å±‚æ›´é€šç”¨ï¼Œæ·±å±‚æ›´ä¸“ç”¨ï¼‰ã€‚
   - **U-shaped ä¸“å®¶åˆ†å¸ƒ**ï¼ˆå›¾7ï¼‰ï¼šè¾¹ç•Œå±‚å…±äº«ä¸“å®¶å¤šï¼Œä¸­é—´å±‚è·¯ç”±ä¸“å®¶å¤šã€‚

3. **æ— éœ€è®­ç»ƒå³å¯å®ç°é«˜æ€§èƒ½ MoE**ï¼š
   - ExpertWeaver æ˜¯é¦–ä¸ªå®Œå…¨ **training-free** ä¸”æ€§èƒ½è¶…è¶Šéœ€è®­ç»ƒæ–¹æ³•çš„ dense-to-MoE æ¡†æ¶ã€‚
   - å³ä½¿ä¸è¿›è¡Œ CPTï¼Œä¹Ÿèƒ½ä½œä¸ºé«˜æ•ˆæ¨ç†æ¨¡å‹ä½¿ç”¨ã€‚

4. **Downcycling ä¼˜äº Upcycling**ï¼š
   - ç›¸æ¯”å¤åˆ¶å‚æ•°çš„ upcyclingï¼Œdowncycling æ›´èƒ½ä¿ç•™åŸå§‹æ¨¡å‹çš„çŸ¥è¯†å¯†åº¦ä¸å¤šæ ·æ€§ã€‚
   - å›¾4æ˜¾ç¤ºï¼šdowncycling æ”¶æ•›æ›´å¿«ï¼Œæœ€ç»ˆæ€§èƒ½æ›´é«˜ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ– GLU æ¶æ„**ï¼šç›®å‰ä»…é€‚ç”¨äº SwiGLU ç­‰ GLU å˜ä½“ï¼Œä¸é€‚ç”¨äº ReLU-based FFNã€‚
- **ä¸“å®¶ç²’åº¦å›ºå®š**ï¼šéœ€é¢„è®¾ä¸“å®¶æ•°é‡å’Œå¤§å°ï¼Œçµæ´»æ€§å—é™ã€‚
- **æœªè§£å†³è·¯ç”±å†²çª**ï¼šé«˜å¹¶å‘ä¸‹å¯èƒ½å› è´Ÿè½½ä¸å‡è¡¡å½±å“æ€§èƒ½ï¼ˆå°½ç®¡ä½¿ç”¨äº† load-balancing lossï¼‰ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ‰©å±•è‡³é GLU æ¶æ„ï¼ˆå¦‚ ReLUã€GeLUï¼‰çš„ dense æ¨¡å‹ã€‚
- æ¢ç´¢åŠ¨æ€ä¸“å®¶æ•°é‡ä¸è‡ªé€‚åº”è·¯ç”±æœºåˆ¶ã€‚
- ç»“åˆç¡¬ä»¶ä¼˜åŒ–ï¼Œè¿›ä¸€æ­¥æå‡ MoE çš„å®é™…éƒ¨ç½²æ•ˆç‡ã€‚
- å°† ExpertWeaver åº”ç”¨äºæ›´å¤§è§„æ¨¡æ¨¡å‹ï¼ˆå¦‚ 70B+ï¼‰çš„ MoE è½¬æ¢ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **ExpertWeaver æ­ç¤ºäº† GLU æ¿€æ´»æ¨¡å¼ä¸­çš„â€œå†…åœ¨ MoEâ€ç»“æ„ï¼Œé¦–æ¬¡å®ç°äº†æ— éœ€è®­ç»ƒã€ä¿ç•™åŸå§‹åŠŸèƒ½ã€å±‚è‡ªé€‚åº”çš„ dense-to-MoE è½¬æ¢ï¼Œåœ¨ç»“æ„å‰ªæä¸æ¨¡å‹é™å¾ªç¯ä¸¤ä¸ªåœºæ™¯å‡å–å¾— SOTA æ€§èƒ½ã€‚**

</details>

---

### 2. [Panini: Continual Learning in Token Space via Structured Memory](https://arxiv.org/abs/2602.15156)

**Authors**: Shreyas Rajesh, Pavan Holur, Mehmet Yigit Turali, Chenda Duan, Vwani Roychowdhury  
**Category**: cs.AI  
**Published**: 2026-02-18  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.15156v1  

#### Abstract
Language models are increasingly used to reason over content they were not trained on, such as new documents, evolving knowledge, and user-specific data. A common approach is retrieval-augmented generation (RAG), which stores verbatim documents externally (as chunks) and retrieves only a relevant su...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠPANINI: Continual Learning in Token Space via Structured Memoryã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜

å½“å‰è¯­è¨€æ¨¡å‹åœ¨å¤„ç†æœªè®­ç»ƒè¿‡çš„æ–°çŸ¥è¯†ï¼ˆå¦‚æ–°æ–‡æ¡£ã€åŠ¨æ€ä¿¡æ¯ã€ç”¨æˆ·ç‰¹å®šæ•°æ®ï¼‰æ—¶ï¼Œä¸»è¦ä¾èµ– **Retrieval-Augmented Generation (RAG)**ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿ RAG å­˜åœ¨ä»¥ä¸‹å…³é”®é—®é¢˜ï¼š

- **æ¨ç†æ•ˆç‡ä½ä¸‹**ï¼šæ¯æ¬¡æ¨ç†éƒ½éœ€é‡å¤æ£€ç´¢å’Œå¤„ç†åŸå§‹æ–‡æœ¬ç‰‡æ®µï¼ˆchunksï¼‰ï¼Œå¯¼è‡´å¤§é‡å†—ä½™è®¡ç®—ã€‚
- **ä¸Šä¸‹æ–‡å™ªå£°å¤§**ï¼šchunk-based retrieval å®¹æ˜“å¼•å…¥æ— å…³ä¸Šä¸‹æ–‡ï¼Œå¢åŠ å¹»è§‰ï¼ˆhallucinationï¼‰å’Œé”™è¯¯æ¨ç†çš„é£é™©ã€‚
- **ç¼ºä¹ç»“æ„åŒ–è®°å¿†**ï¼šç°æœ‰æ–¹æ³•å¤šå­˜å‚¨åŸå§‹æ–‡æœ¬æˆ–ç®€å•æ‘˜è¦ï¼Œéš¾ä»¥æ”¯æŒå¤æ‚çš„å¤šè·³æ¨ç†ï¼ˆmulti-hop reasoningï¼‰ã€‚

æ­¤å¤–ï¼Œå‚æ•°åŒ–æŒç»­å­¦ä¹ ï¼ˆPCLï¼‰è™½èƒ½å†…åŒ–æ–°çŸ¥è¯†ï¼Œä½†é¢ä¸´ç¾éš¾æ€§é—å¿˜ï¼ˆcatastrophic forgettingï¼‰ã€é«˜æ˜‚è®­ç»ƒæˆæœ¬åŠä¸æŒ‡ä»¤å¾®è°ƒå¯¹é½å†²çªç­‰é—®é¢˜ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯

æœ¬æ–‡æå‡º **PANINI**ï¼Œä¸€ç§éå‚æ•°åŒ–æŒç»­å­¦ä¹ ï¼ˆNon-Parametric Continual Learning, NPCLï¼‰æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> **åœ¨å†™å…¥é˜¶æ®µï¼ˆwrite timeï¼‰æŠ•èµ„è®¡ç®—ï¼Œæ„å»ºç»“æ„åŒ–çš„è¯­ä¹‰è®°å¿†ï¼Œåœ¨è¯»å–é˜¶æ®µï¼ˆread timeï¼‰å®ç°é«˜æ•ˆã€å¯é çš„æ¨ç†ã€‚**

å…·ä½“åˆ›æ–°åŒ…æ‹¬ï¼š

1. **Generative Semantic Workspace (GSW)**  
   å°†æ¯ä¸ªæ–‡æ¡£è½¬åŒ–ä¸ºä¸€ä¸ªå®ä½“-äº‹ä»¶æ„ŸçŸ¥çš„ **question-answer (QA) å¯¹ç½‘ç»œ**ï¼Œå½¢æˆâ€œç”Ÿæˆæ€§è¯­ä¹‰å·¥ä½œåŒºâ€ã€‚è¯¥ç»“æ„æ˜¾å¼ç¼–ç å®ä½“ã€äº‹ä»¶èŠ‚ç‚¹åŠå…¶å…³ç³»ï¼Œè¶³ä»¥è®© LLM é€šè¿‡æ¨ç†é“¾é‡å»ºæƒ…å¢ƒå¹¶æŒ–æ˜æ½œåœ¨çŸ¥è¯†ã€‚

2. **Reasoning Inference Chain Retrieval (RICR)**  
   åœ¨æ¨ç†æ—¶ï¼Œä¸ç›´æ¥è®¿é—®åŸå§‹æ–‡æ¡£æˆ– chunksï¼Œè€Œæ˜¯é€šè¿‡ beam search é£æ ¼çš„é“¾å¼æ£€ç´¢ï¼Œåœ¨ GSW ä¸­è¿½è¸ªæœ€å¯èƒ½çš„æ¨ç†è·¯å¾„ï¼ˆinference chainsï¼‰ã€‚è¯¥è¿‡ç¨‹ä»…ä¾èµ–è½»é‡çº§æ£€ç´¢ï¼Œæ— éœ€å¤šæ¬¡ LLM è°ƒç”¨ã€‚

3. **åŒç´¢å¼•æœºåˆ¶ï¼ˆDual Indexingï¼‰**  
   æ„å»ºä¸¤ä¸ªå…¨å±€ç´¢å¼•ï¼š
   - **ç¨€ç– BM25 ç´¢å¼•**ï¼šåŸºäºå®ä½“åŠå…¶è§’è‰²/çŠ¶æ€
   - **ç¨ å¯†å‘é‡ç´¢å¼•**ï¼šåŸºäºæ‰€æœ‰ QA å¯¹
   æ”¯æŒé«˜æ•ˆã€ç²¾å‡†çš„å€™é€‰æ£€ç´¢ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **æ•ˆç‡** | æ¨ç†æ—¶ä»…ä½¿ç”¨ QA å¯¹ä½œä¸ºè¯æ®ï¼Œtoken ä½¿ç”¨é‡ä»…ä¸ºåŸºçº¿çš„ **2â€“30Ã— æ›´å°‘**ã€‚ |
| **å‡†ç¡®æ€§** | åœ¨å¤šè·³ QA ä¸Šå¹³å‡ F1 æ¯”æœ€å¼ºåŸºçº¿é«˜ **5â€“7%**ã€‚ |
| **å¯é æ€§** | åœ¨æ— ç­”æ¡ˆæŸ¥è¯¢ä¸Šæ˜¾è‘—å‡å°‘å¹»è§‰ï¼Œæ‹’ç»å‡†ç¡®ç‡æ›´é«˜ã€‚ |
| **å¯æ‰©å±•æ€§** | æ”¯æŒå®Œå…¨å¼€æºæµæ°´çº¿ï¼Œä¸” GSW å¯ä½œä¸ºé€šç”¨æ£€ç´¢åŸºç¡€è®¾æ–½è¢«å…¶ä»–ç³»ç»Ÿå¤ç”¨ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†

- **å•è·³ QA æ•°æ®é›†**ï¼š
  - **NQ** (Natural Questions)
  - **PopQA**
- **å¤šè·³ QA æ•°æ®é›†**ï¼š
  - **MuSiQue**
  - **2WikiMultihopQA**
  - **HotpotQA**
  - **LV-Eval** (hotpotwikiqa-mixup 256k)

å…± **6 ä¸ª QA åŸºå‡†**ï¼Œè¦†ç›–ä»ç®€å•äº‹å®æ£€ç´¢åˆ°å¤æ‚ç»„åˆæ¨ç†çš„ä»»åŠ¡ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### æ€§èƒ½æŒ‡æ ‡
- **Exact Match (EM)** å’Œ **F1**ï¼šè¡¡é‡ç­”æ¡ˆåŒ¹é…ç¨‹åº¦ã€‚
- **Token Count (â†“)**ï¼šæ¨ç†æ—¶æä¾›ç»™å›ç­”æ¨¡å‹çš„å¹³å‡ token æ•°ï¼Œåæ˜ æ•ˆç‡ã€‚

#### å¯é æ€§è¯„ä¼°ï¼ˆPlatinum Benchmarkï¼‰
ä¸ºæµ‹è¯•æ¨¡å‹åœ¨**æ— ç­”æ¡ˆæŸ¥è¯¢**ä¸Šçš„è¡¨ç°ï¼Œä½œè€…æ„å»ºäº†ï¼š
- **MuSiQue-PLATINUM**
- **2Wiki-PLATINUM**

å…¶ä¸­æ¯ä¸ªæ ·æœ¬è¢«äººå·¥æ ‡æ³¨ä¸ºâ€œå¯å›ç­”â€æˆ–â€œä¸å¯å›ç­”â€ã€‚

è¯„ä¼°æŒ‡æ ‡ï¼š
- **Ans**ï¼šåœ¨å¯å›ç­”å­é›†ä¸Šçš„ F1
- **Unans**ï¼šåœ¨ä¸å¯å›ç­”å­é›†ä¸Šçš„æ‹’ç»å‡†ç¡®ç‡ï¼ˆè¾“å‡º `N/A` è§†ä¸ºæ­£ç¡®ï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”

| ç±»å‹ | åŸºçº¿æ–¹æ³• |
|------|----------|
| **Chunk-based Retrieval** | BM25, BM25+reranker, Dense Retrieval (NV-Embed, Qwen3-Embedding) |
| **Structure-Augmented RAG** | RAPTOR, GraphRAG, LightRAG, HippoRAG, HippoRAG2 |
| **Agentic Systems** | IR-CoT, Search-R1 |

æ‰€æœ‰æ–¹æ³•ç»Ÿä¸€ä½¿ç”¨ **GPT-4o-mini** ä½œä¸ºå›ç­”æ¨¡å‹ä»¥ä¿è¯å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### è¡¨ 2ï¼šå…­é¡¹ QA åŸºå‡†ä¸Šçš„å¹³å‡ F1 å¯¹æ¯”

| æ–¹æ³• | å¹³å‡ F1 |
|------|--------|
| Dense Retrieval æœ€å¼º | 50.5 |
| HippoRAG2 (SOTA ç»“æ„åŒ– RAG) | 53.3 |
| **PANINI (æœ¬æ–‡æ–¹æ³•)** | **56.06** âœ… |

- åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šå‡å–å¾—æœ€ä½³æ€§èƒ½ï¼Œå°¤å…¶åœ¨å¤šè·³ä»»åŠ¡ä¸Šä¼˜åŠ¿æ˜æ˜¾ã€‚
- åœ¨ **MuSiQue** ä¸Šè¾¾åˆ° **52.27 F1**ï¼Œè¿œè¶…ç¬¬äºŒå HippoRAG2 çš„ 49.3ã€‚

#### è¡¨ 3ï¼šæ¨ç†æ—¶ token ä½¿ç”¨é‡å¯¹æ¯”

| æ–¹æ³• | å¹³å‡ token æ•° |
|------|----------------|
| Chunk Retrieval (e.g., BM25) | ~705 |
| Structure-Augmented (e.g., GraphRAG) | ~8121 |
| Agentic (e.g., IR-CoT) | ~10745 |
| **PANINI** | **319.79** âœ… |

- **æ¯” chunk retrieval å°‘ 2.2Ã— token**
- **æ¯”ç»“æ„åŒ–/ä»£ç†æ–¹æ³•å°‘ 5â€“30Ã— token**

#### è¡¨ 4ï¼šPlatinum åŸºå‡†ä¸Šçš„å¯é æ€§è¯„ä¼°

| æ–¹æ³• | Avg Ans | Avg Unans |
|------|--------|----------|
| HippoRAG2 | 72.5 | 58.5 |
| **PANINI** | **79.9** | **72.8** âœ… |

- åŒæ—¶æå‡**å¯å›ç­”å‡†ç¡®ç‡**å’Œ**ä¸å¯å›ç­”æ‹’ç»ç‡**ï¼Œæ‰“ç ´â€œè¶Šå¼ºæ£€ç´¢å™¨è¶Šéš¾æ‹’ç»â€çš„æƒè¡¡ã€‚

### æ¶ˆèå®éªŒç»“æœ

#### è¡¨ 12â€“14ï¼šå…³é”®ç»„ä»¶æ¶ˆèç ”ç©¶

| æ¶ˆèè®¾ç½® | å½±å“ |
|---------|------|
| ç§»é™¤ QA é‡æ’åºï¼ˆNo QA rerankingï¼‰ | F1 ä¸‹é™è¶…è¿‡ 30%ï¼Œè¯´æ˜é‡æ’åºè‡³å…³é‡è¦ |
| ç§»é™¤åŒç´¢å¼•ï¼ˆOnly entity æˆ– Only QAï¼‰ | æ€§èƒ½ä¸‹é™ï¼ŒéªŒè¯åŒè·¯æ£€ç´¢äº’è¡¥æ€§ |
| ä¸è¿›è¡Œé—®é¢˜åˆ†è§£ï¼ˆNo decompositionï¼‰ | å¤šè·³æ€§èƒ½å¤§å¹…ä¸‹é™ï¼Œè¯æ˜é“¾å¼æ¨ç†å¿…è¦æ€§ |
| é“¾è¯„åˆ†å‡½æ•°æ›¿æ¢ä¸º last-hop greedy | F1 é™è‡³ 50.8ï¼ˆåŸ 52.3ï¼‰ï¼Œå‡ ä½•å¹³å‡æ›´ä¼˜ |
| Beam Width ä» 5 å‡è‡³ 3 | æ€§èƒ½å‡ ä¹ä¸å˜ï¼Œtoken æ•°é™ä½ 25% |

ç»“è®ºï¼šPANINI çš„è®¾è®¡é€‰æ‹©å‡æœ‰å®è¯æ”¯æŒï¼Œä¸”å…·å¤‡è‰¯å¥½é²æ£’æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. **å†™å…¥æ—¶ç»“æ„åŒ–ä¼˜äºè¯»å–æ—¶æ¨ç†**  
   PANINI çš„æˆåŠŸè¡¨æ˜ï¼š**å°†è®¡ç®—å‰ç§»è‡³å†™å…¥é˜¶æ®µï¼Œæ„å»ºé«˜è´¨é‡ç»“æ„åŒ–è®°å¿†ï¼ˆGSWï¼‰ï¼Œèƒ½åœ¨è¯»å–é˜¶æ®µæ¢æ¥å·¨å¤§çš„æ•ˆç‡ä¸å¯é æ€§æ”¶ç›Š**ã€‚

2. **GSW æ˜¯ä¸€ç§å¯å¤ç”¨çš„å…ƒè¡¨ç¤ºï¼ˆmeta-representationï¼‰**  
   å®éªŒæ˜¾ç¤ºï¼Œå°† GSW æ³¨å…¥ Search-R1 ç­‰ä»£ç†ç³»ç»Ÿåï¼Œå…¶æ€§èƒ½ä¹Ÿå¾—åˆ°æå‡ï¼ˆTable 16ï¼‰ï¼Œè¯´æ˜ GSW å¯ä½œä¸ºé€šç”¨æ£€ç´¢åŸºç¡€è®¾æ–½ã€‚

3. **è½»é‡çº§é“¾å¼æ£€ç´¢ä¼˜äºè¿­ä»£å¼ä»£ç†æ¨ç†**  
   RICR ä»…éœ€ä¸€æ¬¡é—®é¢˜åˆ†è§£ + éå‚æ•°æ£€ç´¢ï¼Œå³å¯åª²ç¾ç”šè‡³è¶…è¶Šéœ€è¦å¤šæ¬¡ LLM è°ƒç”¨çš„ agentic æ–¹æ³•ã€‚

4. **ç»“æ„åŒ–è®°å¿†æå‡æŠ—å¹²æ‰°èƒ½åŠ›**  
   åœ¨ä¸æ–­å¢åŠ å¹²æ‰°æ–‡æ¡£çš„æŒç»­å­¦ä¹ åœºæ™¯ä¸­ï¼ˆFigure 9ï¼‰ï¼ŒPANINI æ€§èƒ½ä¸‹é™æœ€å°ï¼Œè¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§

1. **æœªå®ç°è·¨æ–‡æ¡£é“¾æ¥ç¼“å­˜**  
   å½“æŸäº›è·¨æ–‡æ¡£å…³ç³»é¢‘ç¹å‡ºç°æ—¶ï¼Œæ— æ³•è‡ªåŠ¨åˆå¹¶æˆ–ç¼“å­˜ï¼Œä»éœ€æ¯æ¬¡åŠ¨æ€éå†ã€‚

2. **GSW æ„å»ºæˆæœ¬è¾ƒé«˜**  
   ä½¿ç”¨ GPT-4.1-mini æ„å»º MuSiQue çš„ GSW æˆæœ¬çº¦ä¸º $48ï¼ˆTable 15ï¼‰ï¼Œè™½ä¸ºä¸€æ¬¡æ€§æŠ•å…¥ï¼Œä½†ä»é«˜äºçº¯ embedding æ–¹æ³•ã€‚

3. **å°æ¨¡å‹æ„å»º GSW è´¨é‡ä¸ç¨³å®š**  
   å¼€æºæ¨¡å‹ï¼ˆå¦‚ Qwen3-8Bï¼‰æå–çš„ GSW å­˜åœ¨é—æ¼åŠ¨è¯çŸ­è¯­ã€ç¼ºå¤±åå‘ QA å¯¹ç­‰é—®é¢˜ï¼ˆTable 18ï¼‰ï¼Œå½±å“ä¸‹æ¸¸æ€§èƒ½ã€‚

4. **æœªæ¢ç´¢æ›´å¤æ‚çš„ reconciliation ç­–ç•¥**  
   å½“å‰å®ä½“å¯¹é½ä»…é™äºå•æ–‡æ¡£å†…ï¼Œæœªæ¥å¯ç”¨ agent ä¸»åŠ¨åè°ƒè·¨æ–‡æ¡£ç»“æ„ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘

1. **å®ç° latent-link caching**ï¼šå¯¹é«˜é¢‘å‡ºç°çš„è·¨æ–‡æ¡£å…³ç³»è¿›è¡Œè®°å¿†ä¼˜åŒ–ã€‚
2. **é™ä½ write-time æˆæœ¬**ï¼šæ”¹è¿› GSW æå–ç®—æ³•ï¼Œæå‡å°æ¨¡å‹é²æ£’æ€§ã€‚
3. **å¼•å…¥ agent è¿›è¡Œ memory reconciliation**ï¼šåˆ©ç”¨æ™ºèƒ½ä½“ä¸»åŠ¨ç»´æŠ¤å’Œä¼˜åŒ–å…¨å±€ GSW ç»“æ„ã€‚
4. **æ‹“å±•è‡³å™äº‹å¯†é›†æˆ–å¤šæ¨¡æ€é¢†åŸŸ**ï¼šå¦‚é•¿è§†é¢‘æµã€å°è¯´ç­‰ï¼Œæ¢ç´¢æ—¶ç©ºç»“æ„ä¸è·¨æ¨¡æ€äº‹ä»¶çš„è®°å¿†å»ºæ¨¡ã€‚
5. **æ¢ç´¢ GSW ä½œä¸ºé€šç”¨æ£€ç´¢å±‚çš„åº”ç”¨æ½œåŠ›**ï¼šé›†æˆåˆ°æ›´å¤šä¸‹æ¸¸æ¡†æ¶ä¸­ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> PANINI é€šè¿‡åœ¨å†™å…¥é˜¶æ®µæ„å»º **Generative Semantic Workspace (GSW)** å¹¶åœ¨è¯»å–é˜¶æ®µæ‰§è¡Œ **Reasoning Inference Chain Retrieval (RICR)**ï¼Œå®ç°äº†é«˜æ•ˆã€å‡†ç¡®ã€å¯é çš„éå‚æ•°åŒ–æŒç»­å­¦ä¹ ï¼Œåœ¨å¤šé¡¹ QA åŸºå‡†ä¸Šè¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œå¹¶ä¸ºç»“æ„åŒ–è®°å¿†ç³»ç»Ÿçš„è®¾è®¡æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 3. [Improving LLM Reliability through Hybrid Abstention and Adaptive Detection](https://arxiv.org/abs/2602.15391)

**Authors**: Ankit Sharma, Nachiket Tapas, Jyotiprakash Patra  
**Category**: cs.AI  
**Published**: 2026-02-18  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.15391v1  

#### Abstract
Large Language Models (LLMs) deployed in production environments face a fundamental safety-utility trade-off either a strict filtering mechanisms prevent harmful outputs but often block benign queries or a relaxed controls risk unsafe content generation. Conventional guardrails based on static rules...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Improving LLM Reliability through Hybrid Abstention and Adaptive Detection*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å®é™…éƒ¨ç½²ä¸­é¢ä¸´**å®‰å…¨-æ•ˆç”¨æƒè¡¡**ï¼ˆsafety-utility trade-offï¼‰çš„æ ¹æœ¬æŒ‘æˆ˜ï¼š
- **ä¸¥æ ¼çš„å®‰å…¨ç­–ç•¥**ï¼ˆå¦‚é™æ€è§„åˆ™ã€å…³é”®è¯è¿‡æ»¤ï¼‰è™½ç„¶èƒ½æœ‰æ•ˆæ‹¦æˆªæœ‰å®³è¾“å‡ºï¼Œä½†å¸¸å¯¼è‡´**é«˜è¯¯æŠ¥ç‡**ï¼ˆfalse positivesï¼‰ï¼Œæ‹’ç»å¤§é‡æ— å®³æŸ¥è¯¢ï¼Œå½±å“ç”¨æˆ·ä½“éªŒã€‚
- **å®½æ¾çš„æ§åˆ¶æœºåˆ¶**åˆ™å¯èƒ½æ”¾è¡Œä¸å®‰å…¨å†…å®¹ï¼Œå¸¦æ¥åˆè§„ä¸ä¼¦ç†é£é™©ã€‚
- ç°æœ‰æ–¹æ³•å¤šä¸º**ä¸Šä¸‹æ–‡æ— å…³**ï¼ˆcontext-insensitiveï¼‰ã€**è®¡ç®—å¼€é”€å¤§**ï¼Œä¸”éš¾ä»¥é€‚åº”ä¸åŒé¢†åŸŸï¼ˆå¦‚åŒ»ç–— vs åˆ›æ„å†™ä½œï¼‰çš„é£é™©å·®å¼‚ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§**è‡ªé€‚åº”å¼ƒæƒç³»ç»Ÿ**ï¼ˆAdaptive Abstention Systemï¼‰ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **åŠ¨æ€é˜ˆå€¼è°ƒèŠ‚**ï¼ˆDynamic Threshold Calibrationï¼‰  
  å¼ƒæƒå†³ç­–åŸºäºå®æ—¶ä¸Šä¸‹æ–‡ä¿¡å·ï¼ˆå¦‚**domain** å’Œ **user history**ï¼‰åŠ¨æ€è°ƒæ•´å„æ£€æµ‹å™¨çš„é˜ˆå€¼ï¼Œå®ç°â€œé«˜é£é™©åœºæ™¯æ›´ä¿å®ˆï¼Œä½é£é™©åœºæ™¯æ›´å®½å®¹â€ã€‚

- **å¤šç»´åº¦å¹¶è¡Œæ£€æµ‹æ¶æ„**ï¼ˆMulti-dimensional Parallel Detectionï¼‰  
  é›†æˆäº”ä¸ªç‹¬ç«‹çš„æ£€æµ‹å™¨ï¼Œåˆ†åˆ«è¯„ä¼°ï¼š
  - Safetyï¼ˆå®‰å…¨æ€§ï¼‰
  - Confidenceï¼ˆç½®ä¿¡åº¦ï¼‰
  - Knowledge Boundaryï¼ˆçŸ¥è¯†è¾¹ç•Œï¼‰
  - Contextual Appropriatenessï¼ˆè¯­å¢ƒé€‚åˆ‡æ€§ï¼‰
  - Repetitionï¼ˆé‡å¤æ€§ï¼‰  
  å¤šä¿¡å·èåˆé¿å…å•ä¸€æŒ‡æ ‡çš„è„†å¼±æ€§ã€‚

- **åˆ†å±‚çº§è”ä¼˜åŒ–æ¶æ„**ï¼ˆHierarchical Cascade Architectureï¼‰  
  å°†æ£€æµ‹å™¨æŒ‰è®¡ç®—æˆæœ¬æ’åºï¼Œå½¢æˆå››çº§çº§è”ï¼š
  1. **Level 1**: å¿«é€Ÿè¯æ³•è§„åˆ™ï¼ˆ<1msï¼‰
  2. **Level 2**: è½»é‡åˆ†ç±»å™¨ï¼ˆ~5msï¼‰
  3. **Level 3**: å…¨äº”ç»´æ£€æµ‹ï¼ˆ20â€“50msï¼‰
  4. **Level 4**: é«˜ä»£ä»·éªŒè¯ï¼ˆå¯é€‰ï¼‰  
  ç»å¤§å¤šæ•°è¯·æ±‚åœ¨å‰ä¸¤çº§è¢«å¿«é€Ÿå¤„ç†ï¼Œæ˜¾è‘—é™ä½å¹³å‡å»¶è¿Ÿã€‚

- **æ¨¡å‹æ— å…³è®¾è®¡**ï¼ˆModel-agnosticï¼‰  
  ä½œä¸ºæ¨ç†æ—¶é™„åŠ å±‚ï¼Œæ— éœ€å¯¹åŸºç¡€LLMè¿›è¡Œå¾®è°ƒï¼Œé€‚ç”¨äºå¤šç§æ¨¡å‹æ¶æ„ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **å®‰å…¨æ€§** | åœ¨ä¸¥æ ¼æ¨¡å¼ä¸‹å®ç° **Recall=1.00**ï¼Œç¡®ä¿æ‰€æœ‰ä¸å®‰å…¨è¯·æ±‚å‡è¢«æ‹¦æˆª |
| **å®ç”¨æ€§** | è‡ªé€‚åº”é˜ˆå€¼ä½¿ **False Positive Rate ä¸‹é™80%ä»¥ä¸Š**ï¼Œå¤§å¹…å‡å°‘è¿‡åº¦æ‹’ç» |
| **æ•ˆç‡** | å¹³å‡å»¶è¿Ÿä»… **42.78ms**ï¼Œç›¸æ¯”å¤–éƒ¨Guardrailsï¼ˆ450msï¼‰æé€Ÿ **10.5Ã—** |
| **çµæ´»æ€§** | æ”¯æŒè·¨åŸŸéƒ¨ç½²ï¼Œåœ¨åŒ»ç–—ã€é‡‘èã€åˆ›æ„ç­‰ä¸åŒåœºæ™¯è‡ªåŠ¨è°ƒèŠ‚ä¸¥æ ¼ç¨‹åº¦ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **Efficiency Dataset**ï¼ˆ1,000æ¡ï¼‰ï¼šæ··åˆé¢†åŸŸè¯·æ±‚ï¼Œæ¶µç›–å®‰å…¨ã€ä¸å®‰å…¨åŠå¯¹æŠ—æ€§æç¤ºï¼Œæ¨¡æ‹ŸçœŸå®æµé‡ã€‚
- **Safety Dataset**ï¼ˆ600æ¡ï¼‰ï¼šæºè‡ª *RealToxicityPrompts*ï¼Œç”¨äºè¯„ä¼°æ¯’æ€§å†…å®¹æ‹¦æˆªèƒ½åŠ›ã€‚
- **Adaptive Dataset**ï¼šæ ‡æ³¨äº†é¢†åŸŸçš„æç¤ºé›†åˆï¼Œè¦†ç›– **Medical, Education, Casual, Creative Writing** å››ç±»åœºæ™¯ï¼Œç”¨äºæµ‹è¯•ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **åŸºç¡€æ¨¡å‹**ï¼šå›ºå®šä¸å˜ï¼Œä»¥éš”ç¦»å¼ƒæƒæœºåˆ¶çš„å½±å“ã€‚
- **è¯„ä¼°é…ç½®å¯¹æ¯”**ï¼š
  1. æ— å¼ƒæƒå±‚ï¼ˆBaselineï¼‰
  2. é™æ€é˜ˆå€¼ç‰ˆæœ¬ï¼ˆStatic Thresholds, T=0.6ï¼‰
  3. ä¸ä½¿ç”¨çº§è”çš„å®Œæ•´æ£€æµ‹ï¼ˆNo Cascadeï¼‰
  4. æå‡ºçš„è‡ªé€‚åº”+çº§è”ç³»ç»Ÿï¼ˆOursï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Precision**ï¼ˆç²¾ç¡®ç‡ï¼‰ï¼šæ­£ç¡®æ‹’ç»çš„æ¯”ä¾‹
  - **Recall**ï¼ˆå¬å›ç‡ï¼‰ï¼šæˆåŠŸæ‹¦æˆªä¸å®‰å…¨è¯·æ±‚çš„æ¯”ä¾‹
  - **F1 Score**
  - **False Positive Rate (FPR)**ï¼šå¯¹è‰¯æ€§è¯·æ±‚çš„è¯¯æ‹’ç‡
  - **Average Latency**ï¼šæ¯è¯·æ±‚å¹³å‡å¤„ç†æ—¶é—´ï¼ˆmsï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿æ–¹æ³• | æè¿° |
|--------|------|
| **Guardrails AI** | å¤–éƒ¨ToxicLanguageéªŒè¯å™¨ï¼Œä»£è¡¨ä¸»æµé™æ€é˜²æŠ¤æ–¹æ¡ˆ |
| **Static Thresholds** | æ‰€æœ‰æ£€æµ‹å™¨ä½¿ç”¨ç»Ÿä¸€å›ºå®šé˜ˆå€¼ï¼ˆT=0.6ï¼‰ |
| **No Cascade** | æ‰€æœ‰è¯·æ±‚å‡é€šè¿‡å…¨éƒ¨äº”ç»´æ£€æµ‹ï¼Œç”¨äºéªŒè¯çº§è”æ•ˆç‡å¢ç›Š |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| **å¹³å‡å»¶è¿Ÿ**ï¼ˆCascadeç‰ˆï¼‰ | **42.78 ms** |
| **æœ€å¤§å»¶è¿Ÿé™å¹…** | ç›¸æ¯”Guardrails AI **é™ä½10.5Ã—**ï¼ˆ450 â†’ 42.78 msï¼‰ |
| **Strict Safety Mode Recall** | **1.00**ï¼ˆå®Œç¾å¬å›ï¼‰ |
| **Calibrated Mode Precision** | **>0.95**ï¼ˆå…¼é¡¾å®‰å…¨ä¸å¯ç”¨æ€§ï¼‰ |
| **False Positives**ï¼ˆAdaptive vs Staticï¼‰ | ä»15é™è‡³3ï¼ˆâ†“80%ï¼‰ |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
#### è¡¨ï¼šå»¶è¿Ÿæ¯”è¾ƒï¼ˆTable 2ï¼‰
| æ–¹æ³• | å»¶è¿Ÿï¼ˆmsï¼‰ | åŠ é€Ÿæ¯” |
|------|-----------|--------|
| Guardrails AI | 450.00 | 1.0Ã— |
| No Cascade (Ours) | 118.26 | 3.8Ã— |
| **Cascade (Ours)** | **42.78** | **10.5Ã—** |

> âœ… çº§è”æœºåˆ¶ä½¿ç³»ç»Ÿé€‚åˆå®æ—¶äº¤äº’åº”ç”¨ï¼ˆå¦‚å¯¹è¯ä»£ç†ã€ä»£ç åŠ©æ‰‹ï¼‰ã€‚

#### è¡¨ï¼šé™æ€ vs è‡ªé€‚åº”é˜ˆå€¼ï¼ˆTable 4ï¼‰
| æŒ‡æ ‡ | é™æ€ | è‡ªé€‚åº” | æå‡ |
|------|------|--------|------|
| Precision | 0.75 | **0.95** | +26.7% |
| Recall | 0.80 | **0.98** | +22.5% |
| F1 Score | 0.77 | **0.96** | +24.7% |
| False Positives | 15 | **3** | â†“80% |

> âœ… è‡ªé€‚åº”é˜ˆå€¼å®ç°äº†**å¸•ç´¯æ‰˜æ”¹è¿›**ï¼šå®‰å…¨æ€§å’Œå®ç”¨æ€§åŒæ—¶æå‡ã€‚

#### å›¾5ï¼šæŒ‰é¢†åŸŸè¯¯æŠ¥ç‡å¯¹æ¯”
- **Creative Writing**ï¼šFPR ä»25% â†’ **3%**
- **Medical Contexts**ï¼šFPR ä»15% â†’ **2%**

> âœ… æ˜¾è‘—ç¼“è§£äº†ä¸“ä¸šé¢†åŸŸä¸­çš„â€œè¿‡åº¦å®¡æŸ¥â€é—®é¢˜ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **çº§è”ç»“æ„æ¶ˆè**ï¼šå…³é—­çº§è”åå»¶è¿Ÿä¸Šå‡è‡³118.26msï¼Œè¯æ˜å…¶å¯¹æ€§èƒ½çš„å…³é”®ä½œç”¨ã€‚
- **é‡å¤æ£€æµ‹å™¨æ¶ˆè**ï¼š
  - åœ¨é•¿å¯¹è¯ä¸­ï¼Œè¯¥æ¨¡å—**æˆåŠŸé˜»æ­¢100%çš„æ— é™å¾ªç¯**ã€‚
  - ä¼ ç»ŸGuardrailsç›´åˆ°ä¸Šä¸‹æ–‡çª—å£è€—å°½æ‰å¹²é¢„ï¼Œç”¨æˆ·ä½“éªŒå·®ã€‚
- **å¤šç»´æ£€æµ‹å¿…è¦æ€§**ï¼šå•ä¸€ä¿¡å·ï¼ˆå¦‚ä»…ä¾èµ–Confidenceï¼‰æ˜“è¢«â€œè‡ªä¿¡é”™è¯¯â€ï¼ˆconfidently incorrectï¼‰ç»•è¿‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å¼ƒæƒåº”æ˜¯åŠ¨æ€ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è¿‡ç¨‹**ï¼Œè€Œéé™æ€è§„åˆ™ã€‚  
   > â€œHow much to blockâ€ æ¯” â€œWhat to blockâ€ æ›´é‡è¦ã€‚

2. **å¤šç»´åº¦æ£€æµ‹ + åŠ¨æ€é˜ˆå€¼ + åˆ†å±‚çº§è”** æ„æˆäº†é«˜æ•ˆå¯é çš„LLMå®‰å…¨æ¡†æ¶ä¸‰è¦ç´ ã€‚

3. **å®‰å…¨ä¸æ•ˆç”¨å¹¶éé›¶å’Œåšå¼ˆ**ï¼šé€šè¿‡ä¸Šä¸‹æ–‡è‡ªé€‚åº”ï¼Œå¯åœ¨é«˜é£é™©åœºæ™¯ä¿è¯å®‰å…¨ï¼Œåœ¨ä½é£é™©åœºæ™¯é‡Šæ”¾åˆ›é€ åŠ›ã€‚

4. **å»¶è¿Ÿæ˜¯ç”Ÿäº§éƒ¨ç½²çš„å…³é”®ç“¶é¢ˆ**ï¼Œè€Œçº§è”è®¾è®¡ä½¿å¾—å¼ºå®‰å…¨ä¿éšœä¹Ÿèƒ½æ»¡è¶³å®æ—¶æ€§è¦æ±‚ï¼ˆ<50msï¼‰ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **å¯¹æŠ—é²æ£’æ€§æœ‰é™**ï¼šå¤æ‚çš„Jailbreakæ”»å‡»è‹¥ä½¿ç”¨è¡¨é¢è‰¯æ€§çš„è¯­è¨€ä»å¯èƒ½è§„é¿æ£€æµ‹ã€‚
- **å†…å­˜å¼€é”€**ï¼šé‡å¤æ£€æµ‹å™¨éœ€ç»´æŠ¤å“åº”å†å²åµŒå…¥ï¼ˆembedding cacheï¼‰ï¼Œå¢åŠ å†…å­˜å ç”¨ã€‚
- **æ–°é¢†åŸŸå†·å¯åŠ¨é—®é¢˜**ï¼šæ–°éƒ¨ç½²é¢†åŸŸéœ€è¦åˆå§‹æ ¡å‡†æœŸæ¥è®¾å®šåˆé€‚çš„æ•æ„Ÿåº¦å‚æ•°ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **è”é‚¦å­¦ä¹ **ï¼ˆFederated Learningï¼‰ï¼šå®ç°è·¨ç”¨æˆ·/éƒ¨ç½²çš„éšç§ä¿æŠ¤å‹é˜ˆå€¼è‡ªé€‚åº”ã€‚
- **æ‰©å±•è‡³å¤šæ¨¡æ€**ï¼ˆMultimodal Settingsï¼‰ï¼šå°†æ¡†æ¶åº”ç”¨äºå›¾åƒã€è§†é¢‘ç­‰å†…å®¹å®¡æ ¸ã€‚
- **å¢å¼ºå¯è§£é‡Šæ€§**ï¼ˆExplainabilityï¼‰ï¼šä¸ºæ¯æ¬¡å¼ƒæƒç”Ÿæˆç®€æ´çš„äººç±»å¯è¯»ç†ç”±ï¼Œæå‡é€æ˜åº¦ä¸ä¿¡ä»»ã€‚
- **åœ¨çº¿è‡ªé€‚åº”æœºåˆ¶**ï¼šè®©ç³»ç»Ÿèƒ½æ ¹æ®åé¦ˆæŒç»­ä¼˜åŒ–é˜ˆå€¼ï¼Œå®ç°é—­ç¯å®‰å…¨æ§åˆ¶ã€‚

---

> ğŸ”š **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬è®ºæ–‡æå‡ºçš„ **Adaptive Abstention System** é€šè¿‡**ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„åŠ¨æ€æ§åˆ¶**ä¸**é«˜æ•ˆçº§è”æ¶æ„**ï¼Œé¦–æ¬¡åœ¨**å®‰å…¨æ€§ã€å®ç”¨æ€§ä¸å»¶è¿Ÿ**ä¹‹é—´å®ç°äº†ååŒä¼˜åŒ–ï¼Œä¸ºLLMåœ¨åŒ»ç–—ã€é‡‘èç­‰é«˜é£é™©åœºæ™¯çš„å¯é éƒ¨ç½²æä¾›äº†å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 4. [Distributed Semi-Speculative Parallel Anisotropic Mesh Adaptation](https://arxiv.org/abs/2602.15204)

**Authors**: Kevin Garner, Polykarpos Thomadakis, Nikos Chrisochoides  
**Category**: cs.DC  
**Published**: 2026-02-18  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.15204v1  

#### Abstract
This paper presents a distributed memory method for anisotropic mesh adaptation that is designed to avoid the use of collective communication and global synchronization techniques. In the presented method, meshing functionality is separated from performance aspects by utilizing a separate entity for...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠDistributed Semi-Speculative Parallel Anisotropic Mesh Adaptationã€‹æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡æ—¨åœ¨è§£å†³**å¤§è§„æ¨¡ã€æ—¶é—´ä¾èµ–çš„è®¡ç®—æµä½“åŠ¨åŠ›å­¦ï¼ˆCFDï¼‰æ¨¡æ‹Ÿä¸­ï¼Œå„å‘å¼‚æ€§ç½‘æ ¼è‡ªé€‚åº”ç”Ÿæˆçš„å¯æ‰©å±•æ€§å’Œæ€§èƒ½ç“¶é¢ˆé—®é¢˜**ã€‚ä¼ ç»Ÿå¹¶è¡Œç½‘æ ¼ç”Ÿæˆæ–¹æ³•å¸¸ä¾èµ–é›†ä½“é€šä¿¡ï¼ˆcollective communicationï¼‰å’Œå…¨å±€åŒæ­¥æœºåˆ¶ï¼Œè¿™äº›æ“ä½œåœ¨è¶…å¤§è§„æ¨¡å¹¶è¡Œç³»ç»Ÿä¸Šä¼šæˆä¸ºæ€§èƒ½ç“¶é¢ˆï¼Œé™åˆ¶äº†å…¶åœ¨exascaleçº§HPCæ¶æ„ä¸Šçš„åº”ç”¨ã€‚

æ­¤å¤–ï¼Œè®¸å¤šç°æœ‰çš„â€œé»‘ç›’â€å¹¶è¡ŒåŒ–æ–¹æ³•æ— æ³•æœ‰æ•ˆé›†æˆå·²æœ‰çš„é«˜æ€§èƒ½å…±äº«å†…å­˜ç½‘æ ¼ç”Ÿæˆå™¨ï¼ˆå¦‚CDT3Dï¼‰ï¼Œå› ä¸ºå®ƒä»¬æœªé’ˆå¯¹åˆ†å¸ƒå¼ç¯å¢ƒè¿›è¡Œè®¾è®¡ï¼Œå¯¼è‡´é‡å¤å·¥ä½œã€è´Ÿè½½ä¸å‡å’Œé€šä¿¡å¼€é”€è¿‡å¤§ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æå‡ºäº†ä¸€ç§**åˆ†å¸ƒå¼çš„åŠæ¨æµ‹å¼ï¼ˆsemi-speculativeï¼‰å¹¶è¡Œå„å‘å¼‚æ€§ç½‘æ ¼è‡ªé€‚åº”æ–¹æ³•ï¼ˆDM_CDT3Dï¼‰**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- **åŠŸèƒ½ä¸æ€§èƒ½åˆ†ç¦»**ï¼šå°†ç½‘æ ¼ç”ŸæˆåŠŸèƒ½ï¼ˆç”±å…±äº«å†…å­˜ç¨‹åºCDT3Då®ç°ï¼‰ä¸å¹¶è¡Œè¿è¡Œæ—¶æ”¯æŒï¼ˆç”±PREMAæä¾›ï¼‰è§£è€¦ï¼Œæå‡ä»£ç å¤ç”¨æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚
- **å…ˆéªŒæ¥å£é€‚åº”ï¼ˆa priori interface adaptationï¼‰**ï¼šåœ¨å•ä¸ªå¤šæ ¸èŠ‚ç‚¹ä¸Šé¦–å…ˆå¯¹æ‰€æœ‰å­åŸŸè¾¹ç•Œï¼ˆinterface elementsï¼‰å®Œæˆè‡ªé€‚åº”ï¼Œå¹¶å°†å…¶â€œå†»ç»“â€ï¼ˆfrozenï¼‰ï¼Œç„¶ååˆ†å‘å­åŸŸåˆ°é›†ç¾¤å„èŠ‚ç‚¹å¹¶è¡Œå¤„ç†å†…éƒ¨å…ƒç´ ã€‚
- **åˆ©ç”¨æ¨æµ‹æ‰§è¡Œæ¨¡å‹ï¼ˆspeculative execution modelï¼‰**ï¼šé€šè¿‡é¢„é”å®šï¼ˆpreemptive lockingï¼‰å’Œä¼ªæ¿€æ´»ï¼ˆpseudo-active/inactiveï¼‰æ ‡è®°æœºåˆ¶ï¼Œç²¾ç¡®æ§åˆ¶CDT3Dä»…ä½œç”¨äºç›®æ ‡å…ƒç´ é›†åˆï¼Œé¿å…ä¸å¿…è¦çš„é‡å¤è®¡ç®—ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **é¿å…é›†ä½“é€šä¿¡ä¸å…¨å±€åŒæ­¥**ï¼šå®Œå…¨è§„é¿äº†MPI_Allreduceç­‰é˜»å¡å¼é€šä¿¡ï¼Œæ˜¾è‘—é™ä½é€šä¿¡å¼€é”€ã€‚
- **æ›´é«˜çš„ç«¯åˆ°ç«¯æ€§èƒ½**ï¼šåœ¨ç”Ÿæˆçº¦10äº¿ä¸ªå•å…ƒçš„æ¨¡å‹æ—¶ï¼Œä½¿ç”¨512æ ¸å¯åœ¨**ä¸åˆ°4å°æ—¶å†…å®Œæˆ**ï¼Œè€Œrefineéœ€è¿‘6å°æ—¶ï¼Œå…±äº«å†…å­˜ç‰ˆCDT3Dåˆ™éœ€è¶…è¿‡8å°æ—¶ã€‚
- **è‰¯å¥½çš„ç½‘æ ¼è´¨é‡**ï¼šç”Ÿæˆçš„ç½‘æ ¼åœ¨å•å…ƒå½¢çŠ¶åº¦é‡ï¼ˆmean ratioï¼‰å’Œè¾¹é•¿åˆ†å¸ƒæ–¹é¢ä¸åŸå§‹CDT3Dç›¸å½“ï¼Œæ»¡è¶³å¼±å¯é‡ç°æ€§ï¼ˆweak reproducibilityï¼‰è¦æ±‚ã€‚
- **æ›´å¥½çš„å¼º/å¼±æ‰©å±•æ€§**ï¼šå°¤å…¶åœ¨ä¸­å°è§„æ¨¡æ ¸å¿ƒé…ç½®ä¸‹è¡¨ç°ä¼˜äºstate-of-the-artå·¥å…·refineã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
ä½¿ç”¨ä¸¤ä¸ªå…¸å‹å‡ ä½•ä½“è¿›è¡Œæµ‹è¯•ï¼š
- **Delta Wing Geometry**ï¼šåŸºäºäºšéŸ³é€Ÿå±‚æµé©¬èµ«åœºæ„é€ å¤šå°ºåº¦metricï¼Œç”¨äºéªŒè¯CFDç›¸å…³åœºæ™¯ã€‚
- **Cube Geometry**ï¼šé‡‡ç”¨è§£æå®šä¹‰çš„â€œpolar-2â€metricï¼ˆæ¥è‡ªUGAWGåŸºå‡†ï¼‰ï¼Œä»£è¡¨æ›²å‰ªåˆ‡å±‚ï¼Œå¤æ‚åº¦é«˜è¾¾1äº¿ï¼Œå¯¹åº”çº¦10äº¿ä¸ªå››é¢ä½“å•å…ƒã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼š
  - **Wahabé›†ç¾¤**ï¼šæœ€å¤šä½¿ç”¨512æ ¸ï¼ˆ16èŠ‚ç‚¹Ã—32æ ¸/èŠ‚ç‚¹ï¼‰
  - **Anvilé›†ç¾¤**ï¼šæœ€å¤šä½¿ç”¨1536æ ¸ï¼ˆ16èŠ‚ç‚¹Ã—96æ ¸/èŠ‚ç‚¹ï¼‰
- **è½¯ä»¶æ ˆ**ï¼šGNU GCC 11.4.1 + Intel MPIï¼ŒPREMAä½œä¸ºè¿è¡Œæ—¶ç³»ç»Ÿã€‚
- **åˆ†è§£ç­–ç•¥**ï¼šé‡‡ç”¨PQRæ’åºæ³•è¿›è¡Œæ•°æ®åˆ†è§£ï¼Œç¡®ä¿å­åŸŸé—´è´Ÿè½½å‡è¡¡ã€‚
- **å‚æ•°è°ƒä¼˜**ï¼šç»è¿‡å¤§é‡æµ‹è¯•ç¡®å®šæœ€ä¼˜å‚æ•°ç»„åˆï¼ˆè§é™„å½•Table 13ï¼‰ï¼ŒåŒ…æ‹¬ç²—ç½‘æ ¼å¤æ‚åº¦ã€æ¿€æ´»å±‚æ•°ç­‰ã€‚

### è¯„ä¼°æŒ‡æ ‡
| ç±»åˆ« | æŒ‡æ ‡ |
|------|------|
| **æ€§èƒ½** | è¿è¡Œæ—¶é—´ï¼ˆend-to-end runtimeï¼‰ã€åŠ é€Ÿæ¯”ï¼ˆspeedupï¼‰ã€æ¯ç§’ç”Ÿæˆå•å…ƒæ•°ï¼ˆelements/secï¼‰ |
| **è´¨é‡** | å•å…ƒå¹³å‡æ¯”ç‡ç›´æ–¹å›¾ï¼ˆmean ratio histogramï¼‰ã€è¾¹é•¿åº¦åˆ†å¸ƒï¼ˆedge length distributionï¼‰ã€metric conformity |
| **å¯æ‰©å±•æ€§** | å¼ºç¼©æ”¾è¡Œä¸ºï¼ˆfixed problem size, increasing coresï¼‰ |
| **å¯é‡ç°æ€§** | å¼±å¯é‡ç°æ€§ï¼ˆweak reproducibilityï¼‰â€”â€”ä¸åŒæ ¸å¿ƒæ•°ä¸‹è¾“å‡ºç½‘æ ¼è´¨é‡ä¸€è‡´ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **SM_CDT3D**ï¼šåŸç”Ÿå…±äº«å†…å­˜ç‰ˆæœ¬ï¼Œåœ¨å•èŠ‚ç‚¹ä¸Šè¿è¡Œã€‚
- **refine [20]**ï¼šå½“å‰æœ€å…ˆè¿›çš„å¼€æºå¹¶è¡Œå„å‘å¼‚æ€§ç½‘æ ¼ç”Ÿæˆå™¨ï¼Œé‡‡ç”¨åéªŒæ¥å£é€‚åº”ï¼ˆa posterioriï¼‰å’Œé‡åˆ†åŒºç­–ç•¥ã€‚
- **A Posteriori DM_CDT3D [16]**ï¼šä½œè€…æ—©æœŸæå‡ºçš„æ›¿ä»£æ–¹æ¡ˆï¼Œç”¨äºæ¶ˆèåˆ†æã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### Delta Wing @ 10M å¤æ‚åº¦ï¼ˆ~1äº¿å•å…ƒï¼‰
| æ–¹æ³• | 256æ ¸æ—¶é—´(min) | 512æ ¸æ—¶é—´(min) | åŠ é€Ÿæ¯”(1â†’256) |
|------|----------------|----------------|---------------|
| SM_CDT3D | â€” | â€” | ~22.6x |
| A Priori DM_CDT3D | 23 | 22 | ~88.4x |
| refine | 31 | 21 | ~60.9x |

> âœ… **DM_CDT3Dåœ¨256æ ¸ä»¥å†…å…¨é¢ä¼˜äºrefineï¼›512æ ¸æ—¶refineç•¥ä¼˜**

#### Cube @ 100M å¤æ‚åº¦ï¼ˆ~10äº¿å•å…ƒï¼‰
| æ–¹æ³• | 512æ ¸æ—¶é—´(hours) | å•å…ƒé€Ÿç‡(elements/sec) |
|------|------------------|------------------------|
| SM_CDT3D | ~8.12 | ~32,748 |
| A Priori DM_CDT3D | **3.46** | **~78,722** |
| refine | 5.98 | ~50,134 |

> âœ… **DM_CDT3Dæ¯”refineå¿«çº¦72%ï¼Œæ¯”SM_CDT3Då¿«2.3å€**

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **æ€§èƒ½ä¼˜åŠ¿æ˜æ˜¾**ï¼š
  - åœ¨Anvilä¸Šä½¿ç”¨384æ ¸å¤„ç†delta wingæ—¶ï¼ŒDM_CDT3Dé€Ÿç‡è¾¾**232,523 elem/sec**ï¼Œè¿œé«˜äºrefineçš„124,555ã€‚
  - åœ¨å¤§é—®é¢˜è§„æ¨¡ä¸‹ï¼ˆå¦‚10äº¿å•å…ƒï¼‰ï¼ŒDM_CDT3Då±•ç°å‡ºæ›´ä¼˜çš„ç»å¯¹æ€§èƒ½ã€‚
- **é€šä¿¡å¼€é”€æ›´ä½**ï¼š
  - DM_CDT3Déç½‘æ ¼æ“ä½œï¼ˆé€šä¿¡ã€æ‰“åŒ…ç­‰ï¼‰ä»…å æ€»æ—¶é—´çš„15â€“25%ï¼Œè€Œrefineå› é¢‘ç¹é›†ä½“é€šä¿¡å¯¼è‡´å¼€é”€æ›´é«˜ã€‚
- **ç½‘æ ¼è´¨é‡ç›¸å½“**ï¼š
  - æ‰€æœ‰æ–¹æ³•å‡èƒ½ä¿æŒè‰¯å¥½çš„metric conformityã€‚
  - refineç”Ÿæˆçš„ç½‘æ ¼ç•¥ä¼˜ï¼ˆæ›´é›†ä¸­äºmean ratio=1é™„è¿‘ï¼‰ï¼Œä½†ä»£ä»·æ˜¯ç”Ÿæˆæ›´å¤šå•å…ƒï¼ˆå¤šå‡º10â€“15%ï¼‰ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
åœ¨Table 2å’ŒTable 3ä¸­å¯¹æ¯”äº†ä¸¤ç§å®ç°æ–¹å¼ï¼š

| é…ç½® | æè¿° | ç»“æœ |
|------|------|------|
| **Naiveï¼ˆé»‘ç›’ï¼‰** | ä¸å°Šé‡æ“ä½œé¡ºåºï¼Œä¸ä½¿ç”¨pseudo-activeæ ‡è®°ï¼Œç›´æ¥è°ƒç”¨CDT3Då…¨åŠŸèƒ½ | æ¥å£é€‚åº”è€—æ—¶321sï¼Œå†…éƒ¨é€‚åº”è€—æ—¶~1940s |
| **Modifiedï¼ˆæ”¹è¿›ï¼‰** | ä½¿ç”¨pseudo-active + é¢„é”å®š + æ§åˆ¶æ“ä½œé¡ºåº | æ¥å£é€‚åº”é™è‡³**75.4s**ï¼ˆâ†“4.25Ã—ï¼‰ï¼Œå†…éƒ¨é€‚åº”é™è‡³**~1200s**ï¼ˆâ†“1.6Ã—ï¼‰ |

> ğŸ” **å…³é”®å‘ç°**ï¼šè‹¥ä¸æ§åˆ¶æ“ä½œé¡ºåºï¼ˆå¦‚åœ¨æ¥å£é˜¶æ®µæ‰§è¡Œpost-refinement edge collapseï¼‰ï¼Œä¼šå¯¼è‡´åç»­é˜¶æ®µé‡å¤å¤„ç†å·²ä¼˜åŒ–åŒºåŸŸï¼Œé€ æˆä¸¥é‡æ€§èƒ½æµªè´¹ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **åŠŸèƒ½ä¸æ€§èƒ½è§£è€¦æ˜¯æ„å»ºå¯æ‰©å±•HPCåº”ç”¨çš„æœ‰æ•ˆèŒƒå¼**ï¼šé€šè¿‡å°†CDT3Dä½œä¸ºåº“åµŒå…¥PREMAæ¡†æ¶ï¼Œå®ç°äº†è·¨å…±äº«/åˆ†å¸ƒå¼å†…å­˜çš„é«˜æ•ˆååŒã€‚
2. **a prioriæ¥å£é€‚åº”ä¼˜äºa posterioriç­–ç•¥**ï¼šæå‰å›ºå®šè¾¹ç•Œå¯å½»åº•æ¶ˆé™¤æ¥å£æ•°æ®ä¾èµ–å¸¦æ¥çš„é€šä¿¡ä¸å†åˆ†åŒºå¼€é”€ã€‚
3. **æ¨æµ‹æ‰§è¡Œæ¨¡å‹å¯è¢«æ‰©å±•è‡³åˆ†å¸ƒå¼å±‚çº§**ï¼šé€šè¿‡pseudo-activeæ ‡è®°å’Œç‚¹é¢„é”å®šæœºåˆ¶ï¼ŒæˆåŠŸå¼•å¯¼CDT3Dåœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸‹åªå¤„ç†æŒ‡å®šå…ƒç´ ã€‚
4. **é¿å…é›†ä½“é€šä¿¡è‡³å…³é‡è¦**ï¼šæ­£å¦‚DoE ECPç ”ç©¶æŒ‡å‡ºï¼Œé›†ä½“é€šä¿¡æ˜¯exascaleåº”ç”¨çš„ä¸»è¦ç“¶é¢ˆï¼Œæœ¬æ–¹æ³•çš„æˆåŠŸå°è¯äº†è¿™ä¸€ç‚¹ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **æ¥å£é€‚åº”é˜¶æ®µå—é™äºå•èŠ‚ç‚¹ç®—åŠ›**ï¼šç›®å‰è¯¥é˜¶æ®µåªèƒ½åœ¨ä¸€ä¸ªå¤šæ ¸èŠ‚ç‚¹ä¸Šè¿è¡Œï¼ˆå¦‚32æˆ–96æ ¸ï¼‰ï¼Œæˆä¸ºæ•´ä½“å¯æ‰©å±•æ€§çš„ä¸»è¦ç“¶é¢ˆã€‚
- **å­åŸŸè¿é€šæ€§ä¿®å¤ä¸ºä¸²è¡Œè¿‡ç¨‹**ï¼š`MAKE_SIMPLY_CONNECTED`ç®—æ³•å°šæœªå¹¶è¡ŒåŒ–ï¼Œå½±å“å¤§è§„æ¨¡ä¸‹çš„æ•ˆç‡ã€‚
- **ç¼ºä¹è‡ªåŠ¨å‚æ•°è°ƒä¼˜æœºåˆ¶**ï¼šå½“å‰å‚æ•°ï¼ˆå¦‚æ¿€æ´»å±‚æ•°ã€åˆ†è§£æ–¹å¼ï¼‰éœ€æ‰‹åŠ¨è°ƒæ•´ï¼Œæˆæœ¬é«˜æ˜‚ã€‚
- **æœªå¯ç”¨PREMAçš„åŠ¨æ€è´Ÿè½½å‡è¡¡èƒ½åŠ›**ï¼šç”±äºæœªé‡‡ç”¨è¿‡åˆ†è§£ï¼ˆoverdecompositionï¼‰ï¼Œæ— æ³•åˆ©ç”¨PREMAçš„è¿ç§»ä¸å¹³è¡¡ç‰¹æ€§ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **å¹¶è¡ŒåŒ–`MAKE_SIMPLY_CONNECTED`æ¨¡å—**ï¼Œæ¶ˆé™¤ä¸²è¡Œç“¶é¢ˆã€‚
2. **å¼€å‘æœºå™¨å­¦ä¹ æ¨¡å‹ä»¥è‡ªåŠ¨æ¨èæœ€ä¼˜å‚æ•°ç»„åˆ**ï¼Œå‡å°‘äººå·¥è°ƒå‚å¼€é”€ã€‚
3. **å®ç°å®Œå…¨æ¨æµ‹å¼æ¥å£é€‚åº”**ï¼šå…è®¸æ¥å£ä¸å†…éƒ¨å…ƒç´ åŒæ—¶è‡ªé€‚åº”ï¼Œè¿›ä¸€æ­¥æå‡å¹¶å‘åº¦ã€‚
4. **æ¢ç´¢å…¶ä»–ä»»åŠ¡åç«¯ï¼ˆtasking backendï¼‰**ï¼šæµ‹è¯•é™¤Pthreadå¤–çš„OpenMPæˆ–å…¶ä»–è°ƒåº¦ç­–ç•¥å¯¹æ€§èƒ½çš„å½±å“ã€‚
5. **é›†æˆè‡³çœŸå®CFDæµæ°´çº¿**ï¼šéªŒè¯å…¶åœ¨å®é™…ä»¿çœŸä¸­çš„é—­ç¯æ€§èƒ½ä¸ç¨³å®šæ€§ã€‚

--- 

> ğŸ“Œ **æ€»ä½“è¯„ä»·**ï¼š  
> æœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨**å·¥ç¨‹å®ç”¨æ€§ã€æ€§èƒ½è¡¨ç°å’Œç†è®ºåˆ›æ–°**ä¹‹é—´å–å¾—äº†è‰¯å¥½å¹³è¡¡ã€‚å®ƒä¸ä»…å±•ç¤ºäº†å¦‚ä½•æœ‰æ•ˆåœ°å°†ä¸€ä¸ªé«˜æ€§èƒ½å…±äº«å†…å­˜ç»„ä»¶è¿ç§»åˆ°åˆ†å¸ƒå¼ç¯å¢ƒï¼Œè¿˜ä¸ºä¸‹ä¸€ä»£exascaleçº§è‡ªé€‚åº”ç½‘æ ¼ç”Ÿæˆæä¾›äº†æ–°çš„è®¾è®¡èŒƒå¼ã€‚å°½ç®¡å­˜åœ¨ä¸€äº›å¯æ‰©å±•æ€§é™åˆ¶ï¼Œä½†å…¶æ ¸å¿ƒæ€æƒ³å…·æœ‰å¹¿æ³›çš„å€Ÿé‰´æ„ä¹‰ã€‚

</details>

---

### 5. [Accelerated Predictive Coding Networks via Direct Kolen-Pollack Feedback Alignment](https://arxiv.org/abs/2602.15571)

**Authors**: Davide Casnici, Martin Lefebvre, Justin Dauwels, Charlotte Frenkel  
**Category**: cs.LG  
**Published**: 2026-02-18  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.15571v1  

#### Abstract
Predictive coding (PC) is a biologically inspired algorithm for training neural networks that relies only on local updates, allowing parallel learning across layers. However, practical implementations face two key limitations: error signals must still propagate from the output to early layers throug...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAccelerated Predictive Coding Networks via Direct Kolen-Pollack Feedback Alignment

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
æœ¬è®ºæ–‡é’ˆå¯¹ **Predictive Coding (PC)** åœ¨å®é™…åº”ç”¨ä¸­çš„ä¸¤ä¸ªå…³é”®é™åˆ¶ï¼š
- **åé¦ˆå»¶è¿Ÿï¼ˆFeedback Delayï¼‰**ï¼šè¯¯å·®ä¿¡å·å¿…é¡»é€šè¿‡å¤šæ­¥æ¨ç†é˜¶æ®µä»è¾“å‡ºå±‚é€å±‚ä¼ æ’­åˆ°æµ…å±‚ï¼Œå¯¼è‡´è®­ç»ƒæ•ˆç‡ä½ä¸‹ã€‚
- **æŒ‡æ•°è¡°å‡ï¼ˆExponential Decayï¼‰**ï¼šåœ¨è¯¯å·®åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œä¿¡å·å¼ºåº¦éšæ·±åº¦å‘ˆæŒ‡æ•°çº§è¡°å‡ï¼Œå¯¼è‡´æµ…å±‚æ›´æ–°å¾®å¼±ç”šè‡³æ¶ˆå¤±ã€‚

è¿™ä¸¤ä¸ªé—®é¢˜ä¸¥é‡åˆ¶çº¦äº† PC çš„å¯æ‰©å±•æ€§å’Œè®¡ç®—æ•ˆç‡ï¼Œå°¤å…¶æ˜¯åœ¨æ·±å±‚ç½‘ç»œä¸­ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
ä½œè€…æå‡ºäº† **Direct Kolen-Pollack Predictive Coding (DKP-PC)**ï¼Œä¸€ç§ç»“åˆäº† **Direct Feedback Alignment (DFA)** å’Œ **Kolen-Pollack (KP)** æ€æƒ³çš„æ–°å‹ PC å˜ä½“ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š
- å¼•å…¥**å¯å­¦ä¹ çš„ç›´æ¥åé¦ˆè¿æ¥**ï¼ˆlearnable direct feedback connectionsï¼‰ï¼Œä»è¾“å‡ºå±‚ç›´æ¥è¿æ¥åˆ°æ‰€æœ‰éšè—å±‚ã€‚
- åˆ©ç”¨ DKP æœºåˆ¶ï¼Œåœ¨æ¨ç†é˜¶æ®µå‰å¯¹å‰é¦ˆæƒé‡è¿›è¡Œä¸€æ¬¡åˆæ­¥æ›´æ–°ï¼Œä»è€Œåœ¨æ¯ä¸€å±‚ç«‹å³ç”Ÿæˆéé›¶è¯¯å·®é¡¹ã€‚
- è¿™ç§è®¾è®¡æ‰“ç ´äº†ä¼ ç»Ÿ PC çš„é€å±‚ä¾èµ–ï¼Œå®ç°äº†è¯¯å·®ä¿¡å·çš„**å³æ—¶ä¼ è¾“**ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- âœ… **ç†è®ºæ—¶é—´å¤æ‚åº¦ä» O(L) é™è‡³ O(1)**ï¼šå…¶ä¸­ L ä¸ºç½‘ç»œæ·±åº¦ï¼Œæ¶ˆé™¤äº†æ·±åº¦ç›¸å…³çš„å»¶è¿Ÿã€‚
- âœ… **å®Œå…¨å¹¶è¡ŒåŒ–å­¦ä¹ **ï¼šå„å±‚çš„ç¥ç»æ´»åŠ¨å’Œæƒé‡æ›´æ–°å¯ä»¥ç‹¬ç«‹è¿›è¡Œï¼Œé¦–æ¬¡å®ç° PC çš„å…¨å¹¶è¡ŒåŒ–ã€‚
- âœ… **ä¿ç•™å±€éƒ¨æ€§ï¼ˆLocalityï¼‰**ï¼šæ‰€æœ‰æ›´æ–°è§„åˆ™ä»…ä¾èµ–æœ¬åœ°ä¿¡æ¯ï¼Œç¬¦åˆç”Ÿç‰©å¯å¡‘æ€§å’Œç¡¬ä»¶å‹å¥½æ€§è¦æ±‚ã€‚
- âœ… **åŠ é€Ÿæ¨ç†è¿‡ç¨‹**ï¼šå®éªŒè¯æ˜ï¼Œä»…éœ€**å•æ­¥æ¨ç†**å³å¯è¾¾åˆ°ç”šè‡³è¶…è¶Šæ ‡å‡† PC å¤šæ­¥æ¨ç†çš„æ€§èƒ½ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–äº†ä»å°å‹åˆ°ä¸­ç­‰è§„æ¨¡çš„å¤šä¸ªä¸»æµè§†è§‰æ•°æ®é›†ï¼š
- **MLP å®éªŒ**ï¼š
  - MNIST
  - Fashion-MNIST (FMNIST)
- **CNN å®éªŒ**ï¼š
  - CIFAR-10
  - CIFAR-100
  - Tiny ImageNetï¼ˆæœ€å¤æ‚çš„æµ‹è¯•åœºæ™¯ï¼‰

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹æ¶æ„**ï¼š
  - MLPï¼šä¸‰å±‚å…¨è¿æ¥ç½‘ç»œï¼ˆå«ä¸¤éšå±‚ï¼Œæ¯å±‚128å•å…ƒï¼‰
  - CNNï¼šVGG-7 å’Œ VGG-9 æ¶æ„ï¼ŒåŸºäº Pinchetti et al. (2024) çš„è®¾å®š
- **è®­ç»ƒé…ç½®**ï¼š
  - æ‰¹é‡å¤§å°ï¼ˆbatch sizeï¼‰ï¼š128
  - ä¼˜åŒ–å™¨ï¼šAdam / AdamWï¼ˆå‰å‘æƒé‡ï¼‰ï¼Œç‹¬ç«‹ä¼˜åŒ–åé¦ˆè¿æ¥
  - å­¦ä¹ ç‡è°ƒåº¦ï¼šwarmup-cosine-annealingï¼ˆå‰å‘ï¼‰ï¼ŒæŒ‡æ•°è¡°å‡ï¼ˆåé¦ˆï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Top-1 å‡†ç¡®ç‡**ï¼ˆä¸»æŒ‡æ ‡ï¼‰
  - **æ¯è½®è®­ç»ƒæ—¶é—´ï¼ˆç§’ï¼‰**ï¼ˆè¡¡é‡æ•ˆç‡ï¼‰
  - **æ¢¯åº¦å¯¹é½åº¦ï¼ˆCosine Similarityï¼‰**ï¼ˆåˆ†æä¸ BP çš„ä¸€è‡´æ€§ï¼‰
  - **èƒ½é‡æ¼”åŒ–æ›²çº¿**ï¼ˆFree Energy åŠ¨æ€ï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
ä¸ä»¥ä¸‹ç®—æ³•è¿›è¡Œäº†å…¨é¢æ¯”è¾ƒï¼š
- **Backpropagation (BP)**ï¼šé»„é‡‘æ ‡å‡†
- **Standard Predictive Coding (PC)**
- **Incremental PC (iPC)**
- **Center-Nudging PC (CN-PC)**
- **Direct Kolen-Pollack (DKP)**

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| æ¨¡å‹ | æ•°æ®é›† | DKP-PC (Top-1) | æœ€ä½³åŸºçº¿ | æå‡å¹…åº¦ |
|------|--------|----------------|-----------|----------|
| VGG-7 | CIFAR-100 | **50.42%** | CN-PC (64.76%) | â€”â€” |
| VGG-9 | CIFAR-100 | **53.80%** | PC (44.76%) | â†‘9.04% |
| VGG-9 | Tiny ImageNet | **35.04%** | CN-PC (31.50%) | â†‘3.54% |

> ğŸ’¡ åœ¨ Tiny ImageNet ä¸Šï¼ŒDKP-PC é¦–æ¬¡è¶…è¶Šæ‰€æœ‰å…¶ä»–å±€éƒ¨å­¦ä¹ ç®—æ³•ï¼Œæˆä¸ºè¡¨ç°æœ€å¥½çš„ PC å˜ä½“ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- ğŸ“ˆ **åˆ†ç±»æ€§èƒ½**ï¼š
  - åœ¨å¤šæ•° CNN è®¾ç½®ä¸‹ï¼ŒDKP-PC æ˜¾è‘—ä¼˜äº PCã€DKP å’Œ iPCã€‚
  - å°¤å…¶åœ¨æ·±å±‚ç½‘ç»œï¼ˆå¦‚ VGG-9ï¼‰ä¸Šä¼˜åŠ¿æ˜æ˜¾ï¼Œç¼©å°äº†ä¸ BP çš„å·®è·ã€‚
  - åœ¨ Tiny ImageNet ä¸Šè¾¾åˆ° **35.04% Top-1 å‡†ç¡®ç‡**ï¼Œä¼˜äº CN-PCã€‚
- â±ï¸ **è®­ç»ƒé€Ÿåº¦**ï¼ˆæ¥è‡ª Table 2ï¼‰ï¼š
  - ç›¸æ¯”æ ‡å‡† PCï¼ŒDKP-PC **å¹³å‡å‡å°‘è¶…è¿‡ 60% çš„è®­ç»ƒæ—¶é—´**ã€‚
  - ç›¸æ¯” iPCï¼Œè®­ç»ƒæ—¶é—´å‡å°‘é«˜è¾¾ **81%**ã€‚
  - ä¾‹å¦‚åœ¨ VGG-9 + CIFAR-100 ä¸Šï¼š
    - PC: 34.18 ç§’/epoch
    - iPC: 69.73 ç§’/epoch
    - **DKP-PC: 12.53 ç§’/epoch**

### æ¶ˆèå®éªŒç»“æœï¼ˆè§ Appendix A.4.2 & A.4.3ï¼‰
- **ç¦ç”¨ PC å‰å‘æƒé‡æ›´æ–°** â†’ æ¢¯åº¦å¯¹é½å´©æºƒï¼Œè¯æ˜ PC é˜¶æ®µå¯¹æ­£åˆ™åŒ–å’Œå¯¹é½è‡³å…³é‡è¦ã€‚
- **ç¦ç”¨åé¦ˆçŸ©é˜µæ›´æ–°** â†’ å¯¹é½æ€§èƒ½ä¸‹é™ï¼Œè¯´æ˜ DKP æ›´æ–°ä¹Ÿå—ç›Šäº PC æä¾›çš„ä¿¡æ¯ã€‚
- **å¤šæ­¥æ¨ç† vs å•æ­¥æ¨ç†**ï¼š
  - å³ä½¿åªç”¨ **1 æ­¥æ¨ç†**ï¼ŒDKP-PC å·²èƒ½è¶…è¶Šæ ‡å‡† PC å’Œ iPCã€‚
  - å¢åŠ æ¨ç†æ­¥æ•°å¯è¿›ä¸€æ­¥æå‡ç²¾åº¦ï¼Œä½“ç°â€œæ€§èƒ½-æ•ˆç‡â€æƒè¡¡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. âœ… **DKP-PC æˆåŠŸè§£å†³äº† PC çš„åé¦ˆå»¶è¿Ÿä¸æŒ‡æ•°è¡°å‡é—®é¢˜**ï¼Œé€šè¿‡å¼•å…¥ç›´æ¥å¯å­¦ä¹ åé¦ˆè·¯å¾„ï¼Œå®ç°äº†è¯¯å·®ä¿¡å·çš„å³æ—¶å¹¿æ’­ã€‚
2. âœ… **é¦–æ¬¡å®ç° PC çš„å…¨å¹¶è¡ŒåŒ–è®­ç»ƒ**ï¼Œç†è®ºæ—¶é—´å¤æ‚åº¦ç”± O(L) é™ä¸º O(1)ï¼Œä¸ºç¡¬ä»¶åŠ é€Ÿæä¾›äº†åšå®åŸºç¡€ã€‚
3. âœ… **DKP ä¸ PC å…·æœ‰ååŒæ•ˆåº”**ï¼š
   - DKP åŠ é€Ÿäº† PCï¼Œ
   - è€Œ PC åè¿‡æ¥ä½œä¸ºæ­£åˆ™åŒ–å™¨æå‡äº† DKP çš„æ¢¯åº¦å¯¹é½è´¨é‡ã€‚
4. âœ… **åœ¨å‡†ç¡®ç‡å’Œæ•ˆç‡ä¹‹é—´å–å¾—æ›´å¥½å¹³è¡¡**ï¼Œå°¤å…¶åœ¨æ·±å±‚ç½‘ç»œä¸­æ˜¾è‘—ä¼˜äºç°æœ‰ PC å˜ä½“ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- ğŸ”’ **ä»ä¾èµ–é¢å¤–åé¦ˆçŸ©é˜µ**ï¼šå¼•å…¥äº†é¢å¤–å†…å­˜å¼€é”€ï¼ˆfeedback weight storageï¼‰ã€‚
- ğŸ§  **æœªå®Œå…¨æ‘†è„±â€œåŒé˜¶æ®µâ€ç»“æ„**ï¼šè™½ç„¶å„é˜¶æ®µå¯å¹¶è¡Œï¼Œä½†ä»å­˜åœ¨é¡ºåºä¾èµ–ï¼ˆå¦‚å…ˆ DKP æ›´æ–°å† PC æ¨ç†ï¼‰ã€‚
- ğŸ’» **å½“å‰å®ç°å—é™äºè½¯ä»¶åŒæ­¥å¼€é”€**ï¼šPyTorch ä¸­çš„å¹¶è¡ŒåŒ–æœªèƒ½å……åˆ†å‘æŒ¥æ½œåŠ›ï¼Œå› çº¿ç¨‹ç®¡ç†å¼€é”€æŠµæ¶ˆäº†æ”¶ç›Šã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **å®šåˆ¶åŒ–ç¡¬ä»¶æ”¯æŒ**ï¼šå¼€å‘ä¸“ç”¨ CUDA kernels æˆ–ç¥ç»å½¢æ€èŠ¯ç‰‡ï¼Œä»¥çœŸæ­£é‡Šæ”¾ O(1) æ—¶é—´å¤æ‚åº¦çš„ä¼˜åŠ¿ã€‚
2. **ç¨€ç–åŒ–ä¸é‡åŒ–åé¦ˆæƒé‡**ï¼šå€Ÿé‰´ prior work (Crafton et al., 2019; Han & Yoo, 2019)ï¼Œé™ä½å†…å­˜å ç”¨ã€‚
3. **æ›´ç´§å¯†çš„åŠ¨æ€è€¦åˆ**ï¼šæ¢ç´¢ä¸ä¾èµ–â€œé¢„æ›´æ–°â€çš„æ–¹å¼ï¼Œç›´æ¥åˆ©ç”¨åé¦ˆä¿¡å·æ‰°åŠ¨ç¥ç»æ´»åŠ¨ã€‚
4. **é›†æˆæ›´å…ˆè¿›çš„ PC å˜ä½“**ï¼šå¦‚å°† DKP ä¸ **Equilibrium Propagation** æˆ– **Nudging PC** ç»“åˆï¼Œè¿›ä¸€æ­¥é€¼è¿‘ BP æ€§èƒ½ã€‚

> ğŸ¯ **æ€»ä½“è¯„ä»·**ï¼šDKP-PC æ˜¯ Predictive Coding é¢†åŸŸçš„ä¸€é¡¹é‡è¦è¿›å±•ï¼Œä¸ä»…æå‡äº†è®­ç»ƒæ•ˆç‡ï¼Œä¹Ÿä¸ºæ„å»ºé«˜æ•ˆã€å¯æ‰©å±•ã€ç”Ÿç‰©åˆç†çš„ AI ç³»ç»Ÿå¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚

</details>

---

### 6. [The Stationarity Bias: Stratified Stress-Testing for Time-Series Imputation in Regulated Dynamical Systems](https://arxiv.org/abs/2602.15637)

**Authors**: Amirreza Dolatpour Fathkouhi, Alireza Namazi, Heman Shakeri  
**Category**: cs.LG  
**Published**: 2026-02-18  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.15637v1  

#### Abstract
Time-series imputation benchmarks employ uniform random masking and shape-agnostic metrics (MSE, RMSE), implicitly weighting evaluation by regime prevalence. In systems with a dominant attractor -- homeostatic physiology, nominal industrial operation, stable network traffic -- this creates a systema...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# ã€ŠThe Stationarity Bias: Stratified Stress-Testing for Time-Series Imputation in Regulated Dynamical Systemsã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜

è¯¥è®ºæ–‡æ­ç¤ºå¹¶å½¢å¼åŒ–äº†ä¸€ä¸ªåœ¨æ—¶é—´åºåˆ—æ’è¡¥ï¼ˆtime-series imputationï¼‰åŸºå‡†æµ‹è¯•ä¸­æ™®éå­˜åœ¨çš„ç³»ç»Ÿæ€§åå·®â€”â€”**Stationarity Biasï¼ˆå¹³ç¨³æ€§åå·®ï¼‰**ã€‚

- **é—®é¢˜æœ¬è´¨**ï¼šä¼ ç»ŸåŸºå‡†é€šå¸¸é‡‡ç”¨**å‡åŒ€éšæœºæ©ç ï¼ˆuniform random maskingï¼‰** å’Œç‚¹å¯¹ç‚¹è¯¯å·®æŒ‡æ ‡ï¼ˆå¦‚ RMSEã€MSEï¼‰ï¼Œè¿™å¯¼è‡´è¯„ä¼°è¿‡ç¨‹è¿‡åº¦é‡‡æ ·ä¸»å¯¼çš„**å¹³ç¨³çŠ¶æ€ï¼ˆstationary regimeï¼‰**ï¼Œè€Œå¿½ç•¥äº†ç¨€æœ‰ä½†å…³é”®çš„**ç¬æ€äº‹ä»¶ï¼ˆtransient eventsï¼‰**ï¼ˆå¦‚é¤åè¡€ç³–å³°å€¼ã€ä½è¡€ç³–äº‹ä»¶ï¼‰ã€‚
- **åæœ**ï¼šç®€å•æ–¹æ³•ï¼ˆå¦‚çº¿æ€§æ’å€¼ Lerpï¼‰åœ¨å¹³ç¨³åŒºé—´è¡¨ç°ä¼˜å¼‚ï¼Œä»è€Œåœ¨æ•´ä½“æŒ‡æ ‡ä¸Šâ€œè™šé«˜â€ï¼Œæ©ç›–äº†å…¶åœ¨å…³é”®ç¬æ€ä¸­å½¢æ€å¤±çœŸä¸¥é‡çš„ç¼ºé™·ï¼Œè¯¯å¯¼ç ”ç©¶è€…ä½ä¼°æ·±åº¦å­¦ä¹ æ¨¡å‹çš„ä»·å€¼ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯

ä½œè€…æå‡ºäº†ä¸€å¥—**åˆ†å±‚å‹åŠ›æµ‹è¯•æ¡†æ¶ï¼ˆStratified Stress-Testï¼‰**ï¼Œæ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

1. **Regime-Stratified Evaluationï¼ˆåŸºäºçŠ¶æ€çš„åˆ†å±‚è¯„ä¼°ï¼‰**  
   å°†è¯„ä¼°æ˜ç¡®åˆ’åˆ†ä¸ºä¸‰ä¸ªç”Ÿç†å­¦ä¸Šæœ‰æ„ä¹‰çš„åŠ¨æ€çŠ¶æ€ï¼š
   - **Homeostatic Stateï¼ˆç¨³æ€ï¼‰**ï¼šæ— å¤–éƒ¨è¾“å…¥ã€è¡€ç³–ç¨³å®šçš„åŒºé—´ã€‚
   - **Post-Prandial Transientï¼ˆé¤åç¬æ€ï¼‰**ï¼šé¤åè¡€ç³–ä¸Šå‡é«˜å³°ã€‚
   - **Hypoglycemic Transientï¼ˆä½è¡€ç³–ç¬æ€ï¼‰**ï¼šä½è¡€ç³–äº‹ä»¶åŠæ§åˆ¶å™¨å¹²é¢„çª—å£ã€‚

2. **å¼•å…¥å½¢æ€å­¦è¯„ä¼°æŒ‡æ ‡ DTWï¼ˆDynamic Time Warpingï¼‰**  
   ç”¨ä»¥è¡¡é‡ä¿¡å·å½¢çŠ¶çš„ä¿çœŸåº¦ï¼Œå¼¥è¡¥ RMSE ç­‰ç‚¹å¯¹ç‚¹æŒ‡æ ‡æ— æ³•æ•æ‰â€œ**RMSE Mirageï¼ˆRMSE æµ·å¸‚èœƒæ¥¼ï¼‰**â€çš„é—®é¢˜â€”â€”å³ä½ RMSE å¯èƒ½ä¼´éšä¸¥é‡å½¢æ€å¤±çœŸã€‚

3. **ç”Ÿæ€æœ‰æ•ˆçš„ç¼ºå¤±æ¨¡å¼å»ºæ¨¡ï¼ˆEcologically Valid Missingnessï¼‰**  
   åŸºäºçœŸå®ä¸´åºŠè¯•éªŒï¼ˆDCLP3/DCLP5ï¼‰æ¨å¯¼å‡ºçš„ç¼ºå¤±åˆ†å¸ƒï¼ˆåŒ…æ‹¬å°æ—¶çº§å‘ç”Ÿæ¦‚ç‡ã€æŒç»­æ—¶é—´æ··åˆæ¨¡å‹ç­‰ï¼‰ç”Ÿæˆæ©ç ï¼Œè€Œéä½¿ç”¨åˆæˆçš„ MCAR æ©ç ï¼Œæå‡è®­ç»ƒä¸è¯„ä¼°çš„çœŸå®æ€§ã€‚

4. **æå‡ºâ€œRegime-Conditional Model Selectionâ€åŸåˆ™**  
   ä¸åŒçŠ¶æ€åº”ä½¿ç”¨ä¸åŒæ’è¡¥ç­–ç•¥ï¼š**çº¿æ€§æ’å€¼ç”¨äºå¹³ç¨³åŒºï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹ç”¨äºç¬æ€åŒº**ï¼Œå®ç°å®‰å…¨ä¸æ•ˆç‡çš„å¹³è¡¡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³• | æœ¬æ–‡æ–¹æ³• |
|------|----------|----------|
| **è¯„ä¼°å…¬å¹³æ€§** | åå‘å¹³ç¨³åŒºï¼Œå¿½ç•¥å…³é”®ç¬æ€ | åˆ†å±‚è¯„ä¼°ï¼Œæš´éœ²æ¨¡å‹åœ¨å…³é”®åœºæ™¯çš„çœŸå®è¡¨ç° |
| **æŒ‡æ ‡æœ‰æ•ˆæ€§** | ä¾èµ– RMSE/MSEï¼Œæ˜“è¢«â€œè§’åˆ‡å‰²â€æ¬ºéª— | å¼•å…¥ DTW è¡¡é‡å½¢æ€ä¿çœŸåº¦ï¼Œæ›´ç¬¦åˆä¸‹æ¸¸ä»»åŠ¡éœ€æ±‚ |
| **ç¼ºå¤±æ¨¡å¼çœŸå®æ€§** | åˆæˆéšæœºæ©ç ï¼ˆMCARï¼‰ | åŸºäºçœŸå®æ•°æ®æ¨å¯¼çš„ç»Ÿè®¡ç¼ºå¤±è¿‡ç¨‹ |
| **æ¨¡å‹é€‰æ‹©æŒ‡å¯¼** | â€œä¸€åˆ€åˆ‡â€æ¯”è¾ƒ | æä¾›æ¡ä»¶é€‰æ‹©ç­–ç•¥ï¼Œæ”¯æŒè‡ªé€‚åº”æ¨ç† |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†

1. **PEDAP**  
   - åŒ…å« 102 åå„¿ç«¥çš„ CGM æ•°æ®ï¼Œæ¥è‡ªä¸ºæœŸ 13 å‘¨çš„ä¸´åºŠè¯•éªŒã€‚
   - åˆ†ä¸º **Raw PEDAP**ï¼ˆä¿ç•™ç¼ºå¤±ï¼Œä»…é›¶å¡«å……è¾…åŠ©å˜é‡ï¼‰å’Œ **Processed PEDAP**ï¼ˆCGM å€¼çº¿æ€§æ’å€¼ï¼‰ä¸¤ä¸ªç‰ˆæœ¬ã€‚

2. **UVA/Padova Simulation**  
   - ä½¿ç”¨ FDA æ‰¹å‡†çš„ç³–å°¿ç—…æ¨¡æ‹Ÿå™¨ç”Ÿæˆçš„ 100 åæˆäººæ•°æ®ã€‚
   - æ§åˆ¶é¥®é£Ÿã€è¿åŠ¨ç­‰å˜é‡ï¼Œæä¾›é«˜è´¨é‡ ground truthã€‚

3. **TCR-Simulation Dataset**  
   - ç‰¹åˆ«æ„å»ºç”¨äºæ¨¡æ‹Ÿ **Temporal Control Resetï¼ˆTCRï¼‰** åœºæ™¯ä¸‹çš„ä½è¡€ç³–äº‹ä»¶ã€‚
   - é€šè¿‡äººä¸ºå¢å¤§é¤é£Ÿä¼°è®¡è¯¯å·®è¯±å¯¼ä½è¡€ç³–ï¼Œå¹¶æ¨¡æ‹Ÿ TCR å¹²é¢„ï¼ˆåŸºç¡€ç‡é™ä½ 95%ï¼‰ã€‚

> æ‰€æœ‰æ•°æ®æŒ‰æ‚£è€…çº§åˆ«åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†ï¼ˆ70%/10%/20%ï¼‰ï¼Œç¡®ä¿æ³›åŒ–æ€§ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### ä¸‰å¤§å‹åŠ›æµ‹è¯•åè®®ï¼ˆStress Evaluation Protocolsï¼‰

| åè®® | ç›®æ ‡ | æ©ç æ–¹å¼ |
|------|------|----------|
| **Protocol A: Homeostatic State** | è¯„ä¼°å¹³ç¨³åŒºæ’è¡¥èƒ½åŠ› | åœ¨æ»¡è¶³ç¨³å®šæ¡ä»¶çš„ 30 åˆ†é’Ÿçª—å£å†…æ©ç ï¼ˆ10%-30%æ¯”ä¾‹ï¼‰ |
| **Protocol B: Post-Prandial Peak** | è¯„ä¼°é¤åé«˜å³°é‡å»ºèƒ½åŠ› | å›´ç»•é¤åå³°å€¼ä¸­å¿ƒç”Ÿæˆ 3.5â€“4 å°æ—¶æ©ç çª—å£ï¼ˆæµ‹è¯• 1â€“3 ä¸ªå³°å€¼ï¼‰ |
| **Protocol C: Hypoglycemic Transient (TCR)** | è¯„ä¼°ä½è¡€ç³–äº‹ä»¶é‡å»ºèƒ½åŠ› | åœ¨ TCR æ¿€æ´»å‰å 1 å°æ—¶çª—å£æ©ç  |

#### è¯„ä¼°æŒ‡æ ‡

- **Pointwise Accuracy**: RMSE, Emp_SE, Bias
- **Clinical Accuracy**: MARDï¼ˆè¿ç»­è¡€ç³–ç›‘æµ‹é‡‘æ ‡å‡†ï¼‰
- **Morphological Fidelity**: DTWï¼ˆåŠ¨æ€æ—¶é—´è§„æ•´è·ç¦»ï¼‰
- **Distributional Calibration**: æ¡ä»¶å¯†åº¦ä¼°è®¡ $p(\hat{y}|y \in R)$ ä¸ ground truth å¯¹æ¯”

### åŸºçº¿æ–¹æ³•å¯¹æ¯”

å…±è¯„ä¼° 12 ç§æ–¹æ³•ï¼Œæ¶µç›–å››å¤§ç±»ï¼š

| ç±»åˆ« | ä»£è¡¨æ¨¡å‹ |
|------|--------|
| **Generative & Transformer** | SAITS, GPT4TS, CSDI |
| **Frequency-Domain** | FreTS, TSLANet |
| **Multi-Scale** | TimeMixer, SCINet |
| **Evidence & Tokenization** | TEFN, TOTEM |
| **Classical Baselines** | Lerpï¼ˆçº¿æ€§æ’å€¼ï¼‰, LOCFï¼ˆå‰å‘å¡«å……ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ‘˜å½•è‡ª Tables 1â€“3ï¼‰

#### âœ… **Scenario A: ç¨³æ€æ’è¡¥ï¼ˆHomeostatic Stateï¼‰**

| æ¨¡å‹ | RMSE (Processed PEDAP, 0.3) | DTW | MARD |
|------|----------------------------|-----|------|
| **Lerp** | **2.75** | **4.48** | **1.97%** |
| SAITS | 8.63 | 11.13 | 4.89% |
| SCINet | 37.31 | 36.80 | 13.76% |

> **ç»“è®º**ï¼šåœ¨çº¿æ€§å¯é¢„æµ‹çš„å¹³ç¨³åŒºï¼Œ**Lerp æ˜¾è‘—ä¼˜äºæ‰€æœ‰æ·±åº¦å­¦ä¹ æ¨¡å‹**ï¼Œåè€…å› è¿‡å‚æ•°åŒ–äº§ç”Ÿâ€œå¹»è§‰â€æ³¢åŠ¨ã€‚

#### âœ… **Scenario B: é¤åç¬æ€ï¼ˆPost-Prandial Excursionï¼‰**

| æ¨¡å‹ | RMSE (Raw PEDAP, 2 peaks) | DTW | MARD |
|------|---------------------------|-----|------|
| Lerp | 59.21 | 261.82 | 27.62% |
| **SAITS** | **49.05** | **165.60** | **19.04%** |
| SCINet | 57.12 | 258.61 | 28.44% |

> **ç»“è®º**ï¼š
> - RMSE å·®å¼‚å°ï¼ˆ~10ï¼‰ï¼Œä½† **DTW å·®å¼‚å·¨å¤§ï¼ˆ>90ï¼‰**ï¼Œæ­ç¤ºâ€œ**RMSE Mirage**â€ç°è±¡ã€‚
> - **SAITS åœ¨å½¢æ€ä¿çœŸåº¦ï¼ˆDTWï¼‰å’Œä¸´åºŠå®‰å…¨æ€§ï¼ˆMARDï¼‰ä¸Šæ˜¾è‘—é¢†å…ˆ**ã€‚

#### âœ… **Scenario C: ä½è¡€ç³–ç¬æ€ï¼ˆHypoglycemia during TCRï¼‰**

| æ¨¡å‹ | RMSE | DTW | MARD | Bias |
|------|------|-----|------|------|
| **SAITS** | **23.26** | **66.38** | **27.00%** | +14.08 |
| Lerp | 33.76 | 92.52 | 38.29% | **+25.55** |
| SCINet | 32.44 | 101.07 | 39.52% | +27.18 |

> **ç»“è®º**ï¼š
> - **SAITS å…¨é¢ä¼˜äº Lerp**ï¼Œå°¤å…¶åœ¨ Bias ä¸Šæ˜¾è‘—æ›´ä½ã€‚
> - Lerp å­˜åœ¨**ä¸¥é‡æ­£åç½®**ï¼Œä¼šç³»ç»Ÿæ€§é«˜ä¼°ä½è¡€ç³–å€¼ï¼Œå¯èƒ½æ©ç›–å±é™©äº‹ä»¶ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

- **å›¾7ï¼ˆFigure 7ï¼‰** ç»¼åˆæ¯”è¾ƒå››ç§æ¨¡å‹è·¨åœºæ™¯è¡¨ç°ï¼š
  - **Lerp åœ¨ Scenario A å®Œèƒœ**ï¼ˆDTW: 20.29 vs SAITS 52.26ï¼›MARD: 4.39% vs 10.21%ï¼‰ã€‚
  - **SAITS åœ¨ Scenarios B/C æ˜¾è‘—é¢†å…ˆ**ï¼Œå°¤å…¶åœ¨å¤šå³°å€¼ã€é•¿ç¼ºå¤±ä¸‹ä¼˜åŠ¿æ‰©å¤§ã€‚
- **å›¾8â€“11** éªŒè¯äº†ç»“æœå¯¹æ©ç é•¿åº¦ã€ç¼ºå¤±æ¯”ä¾‹çš„é²æ£’æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. **å­˜åœ¨â€œStationarity Biasâ€**  
   å‡åŒ€éšæœºæ©ç å¯¼è‡´è¯„ä¼°åå‘å¹³ç¨³åŒºï¼Œä½¿ç®€å•æ–¹æ³•çœ‹ä¼¼ä¼˜è¶Šï¼Œ**ç³»ç»Ÿæ€§ä½ä¼°æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å…³é”®ç¬æ€ä¸­çš„ä»·å€¼**ã€‚

2. **å­˜åœ¨â€œRMSE Mirageâ€**  
   RMSE æ— æ³•æƒ©ç½šâ€œè§’åˆ‡å‰²â€è¡Œä¸ºï¼ˆå¦‚çº¿æ€§æ’å€¼ç©¿è¿‡å³°å€¼ï¼‰ï¼Œ**ä½ç‚¹å¯¹ç‚¹è¯¯å·®å¯èƒ½ä¼´éšä¸¥é‡å½¢æ€å¤±çœŸ**ï¼Œéœ€å¼•å…¥ DTW ç­‰å½¢æ€æŒ‡æ ‡ã€‚

3. **Regime-Conditional Model Selection æ˜¯æœ€ä¼˜ç­–ç•¥**  
   - **å¹³ç¨³åŒº**ï¼šçº¿æ€§æ’å€¼æ˜¯â€œæœ‰æ•ˆçœŸå®â€ï¼Œè®¡ç®—é«˜æ•ˆä¸”å‡†ç¡®ã€‚
   - **ç¬æ€åŒº**ï¼šæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚ SAITSï¼‰åœ¨å½¢æ€ä¿çœŸåº¦ã€ä¸´åºŠå®‰å…¨æ€§å’Œåå·®æ§åˆ¶ä¸Šå…¨é¢å ä¼˜ã€‚

4. **åˆ†å¸ƒæ ¡å‡†ä»æ˜¯æŒ‘æˆ˜**  
   å³ä½¿æ˜¯ SAITSï¼Œä¹Ÿæ— æ³•å®Œå…¨æ¢å¤ç¬æ€çš„åˆ†å¸ƒç‰¹æ€§ï¼š
   - é¤åå³°å€¼è¢«å‹ç¼©ï¼ˆå‡å€¼ä» 177.1 â†’ 141.3 mg/dLï¼‰ã€‚
   - ä½è¡€ç³–ä»è¢«é«˜ä¼°ï¼ˆå‡å€¼ä» 83.2 â†’ 97.3 mg/dLï¼‰ã€‚
   > è¡¨æ˜å½“å‰æ¨¡å‹æœªèƒ½å……åˆ†å°†å¤–ç”Ÿè¾“å…¥ï¼ˆå¦‚èƒ°å²›ç´ ã€ç¢³æ°´ï¼‰ä½œä¸ºç¡®å®šæ€§é©±åŠ¨ä¿¡å·ã€‚

### æ–¹æ³•çš„å±€é™æ€§

- **æœªåŒ…å«ç»å…¸ ML æ¨¡å‹**ï¼šå¦‚ Random Forestã€k-NN ç­‰æœªå‚ä¸å¯¹æ¯”ã€‚
- **æœªåœ¨çœŸå®é—­ç¯ç³»ç»Ÿä¸­éªŒè¯**ï¼šä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚ Zone-MPC æ§åˆ¶å™¨ï¼‰çš„å®‰å…¨å¢ç›Šå°šæœªå®æµ‹ã€‚
- **æ£€æµ‹æœºåˆ¶ç®€åŒ–**ï¼šå½“å‰ä½¿ç”¨æ¢¯åº¦é˜ˆå€¼ $|\nabla g_t| < 0.6$ åˆ¤æ–­çŠ¶æ€ï¼Œå®é™…éƒ¨ç½²éœ€è€ƒè™‘å»¶è¿Ÿä¸å™ªå£°ã€‚
- **æ‰©æ•£æ¨¡å‹æ½œåŠ›æœªæ¢ç´¢**ï¼šCSDI è™½è¢«æåŠï¼Œä½†æœªåœ¨ä¸»å®éªŒä¸­ä¸å…¶ä»–æ¨¡å‹å…¬å¹³æ¯”è¾ƒã€‚

### æœªæ¥å·¥ä½œæ–¹å‘

1. **å¼€å‘è‡ªé€‚åº”æ¨ç†æ¡†æ¶**ï¼šå®ç°è½»é‡çº§çŠ¶æ€æ£€æµ‹ + åŠ¨æ€è·¯ç”±åˆ° Lerp æˆ– DL æ¨¡å‹ã€‚
2. **æ”¹è¿›æ¨¡å‹æ¶æ„**ï¼šå¢å¼ºå¯¹å¤–ç”Ÿå˜é‡ï¼ˆcarbs, insulinï¼‰çš„æ˜¾å¼å»ºæ¨¡èƒ½åŠ›ï¼Œç¼“è§£â€œDriver-Blindnessâ€é—®é¢˜ã€‚
3. **æ‰©å±•è‡³å…¶ä»–å—æ§ç³»ç»Ÿ**ï¼šå¦‚å·¥ä¸šä¼ æ„Ÿå™¨ã€ç”µç½‘è´Ÿè½½ã€æœåŠ¡å™¨ç›‘æ§ç­‰å…·æœ‰ä¸»å¯¼å¹³ç¨³æ€çš„ç³»ç»Ÿã€‚
4. **æ¨åŠ¨åˆ†å±‚è¯„ä¼°æˆä¸ºæ ‡å‡†**ï¼šå‘¼åç¤¾åŒºåœ¨ benchmark ä¸­å¼ºåˆ¶è¦æ±‚ regime-stratified protocolã€‚

---

> **ä»£ç ä¸æ•°æ®å¼€æºåœ°å€**ï¼š[https://github.com/Shakeri-Lab/Glucose-Imputation](https://github.com/Shakeri-Lab/Glucose-Imputation)

</details>

---

### 7. [AgriWorld:A World Tools Protocol Framework for Verifiable Agricultural Reasoning with Code-Executing LLM Agents](https://arxiv.org/abs/2602.15325)

**Authors**: Zhixing Zhang, Jesen Zhang, Hao Liu, Qinhan Lv, Jing Yang, Kaitong Cai, Keze Wang  
**Category**: cs.AI  
**Published**: 2026-02-18  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.15325v1  

#### Abstract
Foundation models for agriculture are increasingly trained on massive spatiotemporal data (e.g., multi-spectral remote sensing, soil grids, and field-level management logs) and achieve strong performance on forecasting and monitoring. However, these models lack language-based reasoning and interacti...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAgriWorld: A World-Tools-Protocol Framework for Verifiable Agricultural Reasoning with Code-Executing LLM Agents

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰åœ¨å†œä¸šç§‘å­¦é¢†åŸŸå­˜åœ¨ä¸¤å¤§æ¨¡å‹èŒƒå¼çš„å‰²è£‚ï¼š
- **åŸºç¡€æ¨¡å‹**ï¼ˆå¦‚åŸºäºé¥æ„Ÿã€åœŸå£¤ç½‘æ ¼ç­‰å¤§è§„æ¨¡æ—¶ç©ºæ•°æ®è®­ç»ƒçš„æ¨¡å‹ï¼‰è™½ç„¶åœ¨é¢„æµ‹å’Œç›‘æµ‹ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†ç¼ºä¹è‡ªç„¶è¯­è¨€äº¤äº’èƒ½åŠ›å’Œå¯è§£é‡Šçš„æ¨ç†è¿‡ç¨‹ã€‚
- **å¤§è¯­è¨€æ¨¡å‹**ï¼ˆLLMsï¼‰æ“…é•¿æ–‡æœ¬ç†è§£å’Œç”Ÿæˆï¼Œä½†åœ¨å¤„ç†é«˜ç»´ã€å¼‚æ„çš„å†œä¸šæ•°æ®ï¼ˆå¦‚å¤šå…‰è°±é¥æ„Ÿæ—¶é—´åºåˆ—ã€ç”°å—çŸ¢é‡è¾¹ç•Œã€æ°”è±¡æµç­‰ï¼‰æ—¶æ— æ³•ç›´æ¥è¿›è¡Œæ•°å€¼è®¡ç®—å’Œç©ºé—´å¯¹é½ï¼Œå®¹æ˜“äº§ç”Ÿâ€œçœ‹ä¼¼åˆç†ä½†ä¸å¯éªŒè¯â€çš„å¹»è§‰ç­”æ¡ˆã€‚

è¿™ä¸€å·®è·å¯¼è‡´ç°æœ‰ç³»ç»Ÿéš¾ä»¥æ”¯æŒçœŸå®çš„å†œå­¦å·¥ä½œæµï¼Œä¾‹å¦‚éœ€è¦ç»“åˆåœ°ç†æŸ¥è¯¢ã€æ—¶é—´åºåˆ—åˆ†æã€ä½œç‰©æ¨¡æ‹Ÿå’Œåäº‹å®å¹²é¢„çš„å¤æ‚å†³ç­–ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **World-Tools-Protocol** çš„æ¡†æ¶ï¼Œå¹¶å…·ä½“å®ç°äº†ä»¥ä¸‹ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š

#### âœ… **AGRIWORLD**: å¯æ‰§è¡Œçš„å†œä¸šç¯å¢ƒ
- æ„å»ºäº†ä¸€ä¸ªç»Ÿä¸€çš„ Python æ‰§è¡Œç¯å¢ƒ `AGRIWORLD`ï¼Œæä¾›æ ‡å‡†åŒ– API æ¥å£ï¼Œæ¶µç›–å››å¤§ç±»åŠŸèƒ½ï¼š
  1. **Geospatial Querying**ï¼ˆåœ°ç†ç©ºé—´æŸ¥è¯¢ï¼‰
  2. **Remote-Sensing Analytics**ï¼ˆé¥æ„Ÿæ—¶é—´åºåˆ—åˆ†æï¼‰
  3. **Crop Growth Simulation**ï¼ˆä½œç‰©ç”Ÿé•¿æ¨¡æ‹Ÿï¼Œæ”¯æŒåäº‹å®å¹²é¢„ï¼‰
  4. **Task-Specific Predictors**ï¼ˆå¦‚äº§é‡ã€èƒè¿«ã€ç—…å®³é£é™©é¢„æµ‹ï¼‰
- å¼•å…¥ **Artifact** æ¦‚å¿µï¼šæ¯æ¬¡å·¥å…·è°ƒç”¨è¿”å›å¯æ£€æŸ¥çš„ç»“æœå¯¹è±¡ï¼ˆå«æ•°æ®ã€å…ƒä¿¡æ¯ã€ç‰©ç†çº¦æŸã€å“ˆå¸Œæº¯æºï¼‰ï¼Œç¡®ä¿åˆ†æè¿‡ç¨‹å¯å®¡è®¡ã€å¯å¤ç°ã€‚
- è®¾è®¡ **Canonical Alignment Operator**ï¼šè‡ªåŠ¨å¤„ç†åæ ‡ç³»ï¼ˆCRSï¼‰ã€æ—¶é—´é¢‘ç‡ã€å•ä½ä¸€è‡´æ€§ç­‰é—®é¢˜ï¼Œè§£å†³å†œä¸šæ•°æ®ä¸­å¸¸è§çš„æ—¶ç©ºé”™ä½é—®é¢˜ã€‚

#### âœ… **AGRO-REFLECTIVE**: æ‰§è¡Œé©±åŠ¨çš„åæ€å‹æ™ºèƒ½ä½“
- æå‡ºä¸€ä¸ªå¤šè½® LLM Agentï¼Œé‡‡ç”¨ **Execute-Observe-Refine** å¾ªç¯æœºåˆ¶ï¼š
  - å†™ä»£ç  â†’ åœ¨ `AGRIWORLD` ä¸­æ‰§è¡Œ â†’ è§‚å¯Ÿä¸­é—´è¾“å‡ºä¸é”™è¯¯ â†’ è‡ªæˆ‘ä¿®æ­£
- åˆ©ç”¨ä¸­é—´äº§ç‰©ä¸­çš„å…ƒæ•°æ®ï¼ˆå¦‚å•ä½ä¸åŒ¹é…ã€è¦†ç›–ç‡ä¸è¶³ï¼‰ä½œä¸ºåé¦ˆä¿¡å·ï¼Œä¸»åŠ¨è¯Šæ–­å¹¶ä¿®å¤é”™è¯¯ï¼ˆå¦‚ SpatialMisalignment, UnitErrorï¼‰ã€‚
- ä¸æ˜¯ç®€å•åœ°â€œè°ƒç”¨å·¥å…·â€ï¼Œè€Œæ˜¯å°†æ‰§è¡Œåé¦ˆè§†ä¸ºç¬¬ä¸€ç±»æ¨ç†ä¿¡å·ã€‚

#### âœ… **Verifiable Evaluation Suite with Executable Checkers**
- åŸºäºç°æœ‰åŸºå‡†æ„å»º **AGROBENCH**ï¼ŒåŒ…å«å¤šæ ·åŒ–å†œä¸š QA ä»»åŠ¡ï¼ˆæŸ¥æ‰¾ã€é¢„æµ‹ã€å¼‚å¸¸æ£€æµ‹ã€åäº‹å®åˆ†æï¼‰ã€‚
- æ¯ä¸ªä»»åŠ¡å®šä¹‰ä¸º `(q, B, S_out, V, B)` å…ƒç»„ï¼Œå…¶ä¸­ `V` æ˜¯ä¸€ä¸ªå¯æ‰§è¡Œçš„éªŒè¯å‡½æ•°ï¼ˆexecutable checkerï¼‰ï¼Œèƒ½ç¨‹åºåŒ–åˆ¤æ–­ç­”æ¡ˆæ˜¯å¦æ»¡è¶³ï¼š
  - è¾“å‡º schema åˆè§„æ€§
  - æ•°å€¼å®¹å·®ï¼ˆNRMSEï¼‰
  - å› æœä¸€è‡´æ€§ï¼ˆcounterfactual directionï¼‰
  - ç‰©ç†åˆç†æ€§ï¼ˆå•ä½ä¸€è‡´ã€åƒç´ è¦†ç›–åº¦ï¼‰

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | æœ¬æ–‡æ–¹æ³• |
|------|--------|---------|
| **æ¨ç†æ–¹å¼** | çº¯æ–‡æœ¬ç”Ÿæˆ / å•æ¬¡å·¥å…·è°ƒç”¨ | å¤šè½®æ‰§è¡Œ-è§‚å¯Ÿ-åæ€å¾ªç¯ |
| **ç»“æœå¯ä¿¡åº¦** | éš¾ä»¥éªŒè¯ä¸­é—´æ­¥éª¤ | ä¸­é—´ Artifact å¯å®¡è®¡ã€å¯æº¯æº |
| **é”™è¯¯å¤„ç†èƒ½åŠ›** | å®¹æ˜“å› å°é”™è¯¯ï¼ˆå¦‚ CRS é”™è¯¯ï¼‰å¯¼è‡´å¤±è´¥ | èƒ½é€šè¿‡åé¦ˆè‡ªæˆ‘çº æ­£ |
| **è¯„ä¼°æ–¹å¼** | ä¾èµ–äººå·¥è¯„åˆ†æˆ–æœ€ç»ˆç­”æ¡ˆåŒ¹é… | æ”¯æŒè‡ªåŠ¨åŒ–ã€ç»†ç²’åº¦çš„å¯æ‰§è¡ŒéªŒè¯ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
- **AGROBENCH**ï¼šä½œè€…æ„å»ºçš„å¯éªŒè¯è¯„ä¼°å¥—ä»¶ï¼Œæºè‡ªçœŸå®å†œå­¦å·¥ä½œæµï¼Œè¦†ç›–å¤šä¸ªå­é¢†åŸŸï¼š
  - **Plant**ï¼ˆæ¤ç‰©æ ½åŸ¹ï¼‰
  - **Animal**ï¼ˆç•œç‰§ä¸šï¼‰
  - **Aquatic**ï¼ˆæ°´äº§å…»æ®–ï¼‰
  - **Herb**ï¼ˆè‰è¯ç§æ¤ï¼‰
- æ•°æ®æ¥æºåŒ…æ‹¬ï¼š
  - å¤šå…‰è°±é¥æ„Ÿå½±åƒï¼ˆSentinel-2ï¼‰
  - åœŸå£¤è´¨åœ°å›¾ï¼ˆSoilGridsï¼‰
  - DEM åœ°å½¢æ•°æ®
  - æ°”è±¡ç«™æ—¶é—´åºåˆ—
  - ç”°å—ç®¡ç†æ—¥å¿—ï¼ˆçŒæº‰ã€æ–½è‚¥è®°å½•ï¼‰

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
æ ¹æ®ä¸åŒä»»åŠ¡ç±»å‹è®¾è®¡äº†å¤šç§è¯„ä¼°æŒ‡æ ‡ï¼š

| ä»»åŠ¡ç±»å‹ | è¯„ä¼°æŒ‡æ ‡ |
|--------|--------|
| **Lookup**ï¼ˆæŸ¥æ‰¾ï¼‰ | Exact Match Accuracy |
| **Forecasting**ï¼ˆé¢„æµ‹ï¼‰ | Normalized RMSE (NRMSE) â†“ |
| **Anomaly Detection**ï¼ˆå¼‚å¸¸æ£€æµ‹ï¼‰ | Spatial IoU â†‘ï¼ˆä¸ Sentinel-2 çœŸå®æ©è†œæ¯”è¾ƒï¼‰ |
| **Counterfactual Analysis**ï¼ˆåäº‹å®åˆ†æï¼‰ | Success Rate â†‘ï¼ˆæ˜¯å¦æ­£ç¡®è¯†åˆ«å‡ºæœ‰æ•ˆå¹²é¢„ç­–ç•¥ï¼‰ |
| **é€šç”¨è¦æ±‚** | Schema Validity, Unit Consistency, Physical Sanity Checks |

æœ€å¤§äº¤äº’æ­¥æ•°ï¼ˆbudgetï¼‰è®¾ä¸º `T_max = 20`ï¼Œå¹³å‡æ”¶æ•›æ­¥æ•°ä»…éœ€ 3.5 æ­¥ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ§åˆ¶ç›¸åŒ LLMï¼ˆQwen3 ç³»åˆ—ï¼‰è¿›è¡Œå…¬å¹³æ¯”è¾ƒï¼š

| æ–¹æ³• | æè¿° |
|-----|------|
| **Text-Only** | ä»…ä½¿ç”¨ LLM å‚æ•°çŸ¥è¯†ä½œç­”ï¼ˆæ— å¤–éƒ¨å·¥å…·ï¼‰ |
| **AgriWorld-Direct (One-shot)** | æ ‡å‡† Code Interpreter æ¨¡å¼ï¼Œå•æ¬¡ç”Ÿæˆå¹¶æ‰§è¡Œä»£ç ï¼Œæ— é”™è¯¯æ¢å¤æœºåˆ¶ |
| **AGRO-REFLECTIVE (Ours)** | å¤šè½® Execute-Observe-Refine æ¡†æ¶ï¼Œå…·å¤‡è‡ªçœä¸çº é”™èƒ½åŠ› |

æ­¤å¤–è¿˜å¯¹æ¯”äº†å¤šä¸ªå¼ºåŸºçº¿æ¨¡å‹ï¼š
- å¼€æºæ¨¡å‹ï¼šQwen3, DeepSeek-V3, Yi-1.5-34B
- å•†ä¸šæ¨¡å‹ï¼šGPT-4o, Gemini-2.0

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 3 & 4ï¼‰

| æ¨¡å‹ | QA æ€»åˆ† / æ€»é¢˜æ•° | Choice å‡†ç¡®ç‡ (%) |
|------|------------------|--------------------|
| **Qwen3-32B-LoRA-Reflective (Ours)** | **7.72 / 541** | **73.84%** |
| GPT-4o | 7.07 / 150 | 36.75% |
| Qwen3-32B | 5.67 / 541 | 39.67% |

> ğŸ“Œ **ç»“è®º**ï¼šå³ä½¿å‚æ•°è§„æ¨¡è¿œå°äº GPT-4oï¼Œæœ¬æ–¹æ³•ä»æ˜¾è‘—é¢†å…ˆï¼Œè¯æ˜ **å·¥å…·æ¥åœ°ï¼ˆtool groundingï¼‰æ¯”æ¨¡å‹è§„æ¨¡æ›´é‡è¦**ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœï¼ˆTable 4ï¼‰

| æ–¹æ³• | Lookup Acc. | Forecasting NRMSE â†“ | Anomaly IoU â†‘ | Counterfactual Success â†‘ |
|------|-------------|---------------------|---------------|--------------------------|
| Text-Only | 41.2% | 0.89 | 0.12 | 14.5% |
| One-shot | 82.5% | 0.34 | 0.51 | 43.8% |
| **AGRO-REFLECTIVE** | **86.7%** | **0.18** | **0.68** | **71.4%** |

> ğŸ” **å…³é”®å‘ç°**ï¼š
> - åœ¨ç®€å•æŸ¥æ‰¾ä»»åŠ¡ä¸Šæå‡æœ‰é™ï¼ˆ+4.2%ï¼‰ï¼Œè¯´æ˜æ­¤ç±»ä»»åŠ¡å·²æœ‰è¾ƒå¥½è§£å†³ï¼›
> - åœ¨å¤æ‚å¤šæ­¥ä»»åŠ¡ï¼ˆå°¤å…¶æ˜¯ Forecasting å’Œ Counterfactualï¼‰ä¸Šä¼˜åŠ¿å·¨å¤§ï¼š
>   - **NRMSE ä¸‹é™ 47%**
>   - **åäº‹å®æˆåŠŸç‡ç¿»å€ä»¥ä¸Š**

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 2ï¼‰

| æ–¹æ³•å˜ä½“ | å¹³å‡è½®æ¬¡ | å‡†ç¡®ç‡ (%) |
|--------|----------|------------|
| w/o Remote Sensing | 2.4 | 41.5 |
| w/o Alignment | 3.1 | 51.3 |
| w/o Reflection | 1.0 | 50.6 |
| **Full AGRO-REFLECTIVE** | **3.5** | **57.6** |

> ğŸ”§ **å„æ¨¡å—è´¡çŒ®åˆ†æ**ï¼š
> - **ç§»é™¤ Remote Sensing å·¥å…·**ï¼šæ€§èƒ½æš´è·Œè‡³ 41.5%ï¼Œè¡¨æ˜åƒç´ çº§é¥æ„Ÿæ•°æ®è®¿é—®è‡³å…³é‡è¦ã€‚
> - **ç§»é™¤ Canonical Alignment**ï¼šå°½ç®¡å°è¯•æ›´å¤šè½®æ¬¡ï¼Œå‡†ç¡®ç‡åè€Œä¸‹é™ï¼Œè¯´æ˜ **CRS å’Œæ—¶é—´å¯¹é½æ˜¯ç³»ç»Ÿâ€œç²˜åˆå‰‚â€**ã€‚
> - **ç§»é™¤ Reflection Loop**ï¼šé€€åŒ–ä¸º one-shot æ¨¡å¼ï¼Œå‡†ç¡®ç‡ä¸‹é™ 7%ï¼Œä¸”æ— æ³•ä»åˆå§‹é”™è¯¯ä¸­æ¢å¤ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Executable Reasoning æ˜¯å†œä¸š AI çš„å…³é”®è·¯å¾„**  
   å•çº¯æ‰©å¤§ LLM è§„æ¨¡æ— æ³•è§£å†³å†œä¸šæ¨ç†ä¸­çš„ç²¾ç¡®æ€§é—®é¢˜ï¼›å¿…é¡»é€šè¿‡å¯æ‰§è¡Œç¯å¢ƒå®ç° **è®¡ç®—æ¥åœ°ï¼ˆcomputation groundingï¼‰** å’Œ **è¿‡ç¨‹å¯éªŒè¯æ€§**ã€‚

2. **Reflection Loop æ˜¾è‘—æå‡é²æ£’æ€§**  
   å¤šè¾¾ 35% çš„åˆå§‹ä»£ç å­˜åœ¨ bugï¼ˆè¯­æ³•é”™è¯¯ã€å­—æ®µåé”™è¯¯ç­‰ï¼‰ï¼Œä½†é€šè¿‡æ‰§è¡Œåé¦ˆå¯åœ¨ 92% çš„æƒ…å†µä¸‹æˆåŠŸä¿®å¤ã€‚

3. **Tool Grounding æˆ˜èƒœ Giant Models**  
   å°½ç®¡ GPT-4o å‚æ•°é‡å·¨å¤§ï¼Œä½†ç”±äºä¸äº†è§£ `AGRIWORLD` çš„ API è§„èŒƒï¼Œå¸¸è™šæ„ä¸å­˜åœ¨çš„æ–¹æ³•ï¼ˆå¦‚ `get_soil_moisture()`ï¼‰ï¼Œå¯¼è‡´å¤±è´¥ã€‚

4. **OOD æ³›åŒ–èƒ½åŠ›å¼º**ï¼ˆTable 5ï¼‰
   - åœ¨æœªè§è¿‡çš„åœ°åŒºï¼ˆå·´è¥¿ vs åŠ å·ï¼‰å’Œæç«¯æ°”å€™å¹´ä»½ï¼ˆEl NiÃ±oï¼‰ä¸‹ï¼Œæœ¬æ–‡æ–¹æ³•æ€§èƒ½ä¸‹é™æœ€å°ï¼ˆä»… -12% ~ -6%ï¼‰ï¼Œè€Œæ–‡æœ¬æ¨¡å‹ä¸‹é™è¶… 45%ã€‚
   - è¡¨æ˜å…¶æ³›åŒ–èƒ½åŠ›æ¥è‡ªåŠ¨æ€æ•°æ®è·å–è€Œéè®°å¿†æ¨¡å¼ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡å·¥å…·æ¥å£**ï¼šè‹¥åº•å±‚ API ä¸ç¨³å®šæˆ–æ–‡æ¡£ä¸æ¸…ï¼Œä¼šå½±å“ Agent è¡¨ç°ã€‚
- **å¯¹ç½•è§è¾¹ç¼˜æƒ…å†µå¤„ç†æœ‰é™**ï¼šä¾‹å¦‚æç«¯å¤©æ°”ä¸‹çš„éçº¿æ€§å“åº”å¯èƒ½è¶…å‡ºæ¨¡æ‹Ÿå™¨èŒƒå›´ã€‚
- **è®¡ç®—æˆæœ¬è¾ƒé«˜**ï¼šè™½å¹³å‡åªéœ€ 3.5 æ­¥ï¼Œä½†åœ¨èµ„æºå—é™åœºæ™¯ä¸‹ä»éœ€ä¼˜åŒ–ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³æ›´å¤šå†œä¸šå­é¢†åŸŸï¼ˆå¦‚æ—ä¸šã€æ¸©å®¤æ§åˆ¶ï¼‰
- å¼•å…¥å¤šæ™ºèƒ½ä½“åä½œæœºåˆ¶ï¼ˆmulti-agent coordinationï¼‰
- ç»“åˆäººç±»ä¸“å®¶åé¦ˆå½¢æˆæ··åˆå¢å¼ºæ™ºèƒ½ï¼ˆhuman-in-the-loopï¼‰
- æ¢ç´¢è½»é‡åŒ–éƒ¨ç½²æ–¹æ¡ˆï¼Œé€‚é…è¾¹ç¼˜è®¾å¤‡ï¼ˆedge farming systemsï¼‰

---

> âœ… **ä¸€å¥è¯æ€»ç»“**ï¼š  
> è¯¥è®ºæ–‡æå‡ºäº†é¦–ä¸ªé¢å‘å†œä¸šç§‘å­¦çš„ **å¯éªŒè¯ã€å¯æ‰§è¡Œã€å¯åæ€** çš„ LLM Agent æ¡†æ¶ï¼Œé€šè¿‡ `AGRIWORLD + AGRO-REFLECTIVE + Executable Checkers` ä¸‰ä½ä¸€ä½“è®¾è®¡ï¼Œåœ¨å¤æ‚å†œä¸šæ¨ç†ä»»åŠ¡ä¸Šå¤§å¹…è¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œå±•ç¤ºäº† **â€œè®©æ¨¡å‹åŠ¨æ‰‹åšå®éªŒâ€** è€Œéâ€œå‡­ç©ºçŒœæµ‹â€çš„ç§‘å­¦ AI æ–°èŒƒå¼ã€‚

</details>

---

### 8. [BindCLIP: A Unified Contrastive-Generative Representation Learning Framework for Virtual Screening](https://arxiv.org/abs/2602.15236)

**Authors**: Anjie Qiao, Zhen Wang, Yaliang Li, Jiahua Rao, Yuedong Yang  
**Category**: cs.LG  
**Published**: 2026-02-18  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.15236v1  

#### Abstract
Virtual screening aims to efficiently identify active ligands from massive chemical libraries for a given target pocket. Recent CLIP-style models such as DrugCLIP enable scalable virtual screening by embedding pockets and ligands into a shared space. However, our analyses indicate that such represen...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šBindCLIP: A Unified Contrastive-Generative Representation Learning Framework for Virtual Screening**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å½“å‰åŸºäº **CLIP-style** æ¨¡å‹ï¼ˆå¦‚ **DrugCLIP**ï¼‰çš„è™šæ‹Ÿç­›é€‰ï¼ˆVirtual Screeningï¼‰æ–¹æ³•å­˜åœ¨ä¸¤ä¸ªå…³é”®ç¼ºé™·ï¼š

- **Interaction Insensitivityï¼ˆäº¤äº’ä¸æ•æ„Ÿï¼‰**ï¼šæ¨¡å‹å¯¹é…ä½“-å£è¢‹ä¹‹é—´ç²¾ç»†çš„ç»“åˆç›¸äº’ä½œç”¨ï¼ˆå¦‚æ°¢é”®ã€ç›æ¡¥ç­‰ï¼‰ä¸æ•æ„Ÿï¼Œéš¾ä»¥æ•æ‰ç»†å¾®çš„ç»“åˆæ¨¡å¼å·®å¼‚ã€‚
- **Shortcut Relianceï¼ˆä¾èµ–æ·å¾„ç›¸å…³æ€§ï¼‰**ï¼šæ¨¡å‹å€¾å‘äºåˆ©ç”¨è®­ç»ƒæ•°æ®ä¸­çš„ç²—ç²’åº¦ç‰©ç†åŒ–å­¦æ€§è´¨ç›¸ä¼¼æ€§ï¼ˆå¦‚åˆ†å­é‡ã€ææ€§è¡¨é¢ç§¯ç­‰ï¼‰ä½œä¸ºâ€œæ·å¾„â€è¿›è¡Œæ‰“åˆ†ï¼Œè€ŒéçœŸæ­£å­¦ä¹ ç»“åˆå…¼å®¹æ€§ï¼Œå¯¼è‡´åœ¨åˆ†å¸ƒå¤–ï¼ˆOODï¼‰åœºæ™¯ä¸‹æ³›åŒ–èƒ½åŠ›å·®ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
ä½œè€…æå‡º **BindCLIP**ï¼Œä¸€ä¸ªç»Ÿä¸€çš„ **å¯¹æ¯”-ç”Ÿæˆè”åˆè¡¨ç¤ºå­¦ä¹ æ¡†æ¶**ï¼Œé€šè¿‡ä»¥ä¸‹åˆ›æ–°æœºåˆ¶è§£å†³ä¸Šè¿°é—®é¢˜ï¼š

- **Binding Pose Generation-guided Representation Learning**  
  å¼•å…¥ **pocket-conditioned diffusion model** ä½œä¸ºè¾…åŠ©è®­ç»ƒç›®æ ‡ï¼Œç”¨äºç”Ÿæˆé…ä½“åœ¨è›‹ç™½å£è¢‹ä¸­çš„ç»“åˆæ„è±¡ï¼ˆbinding poseï¼‰ã€‚è¯¥ç”Ÿæˆä»»åŠ¡æä¾›ç»†ç²’åº¦çš„å‡ ä½•ç›‘ç£ä¿¡å·ï¼Œä½¿ç¼–ç å™¨å­¦ä¹ åˆ°æ›´ä¸°å¯Œçš„ç©ºé—´äº¤äº’ç‰¹å¾ã€‚

- **Hard-Negative Augmentation with Ligand-Ligand Anchoring Regularizer**  
  - é‡‡ç”¨ **hard-negative mining** ç­–ç•¥ï¼Œä»åŒ–å­¦ç›¸ä¼¼ä½†éæ´»æ€§çš„åˆ†å­ä¸­æŒ–æ˜éš¾è´Ÿæ ·æœ¬ï¼Œå¢å¼ºæ¨¡å‹åŒºåˆ†èƒ½åŠ›ã€‚
  - æå‡º **ligand-ligand anchoring regularizer**ï¼Œé˜²æ­¢ç¡¬è´Ÿæ ·æœ¬åœ¨åµŒå…¥ç©ºé—´ä¸­å› æŒç»­æ’æ–¥è€Œåç¼©ï¼ˆcollapseï¼‰ï¼Œä¿æŒåˆç†çš„å‡ ä½•ç»“æ„ã€‚

- **Unified Training Objective**  
  è”åˆä¼˜åŒ– **CLIP-style contrastive loss** å’Œ **diffusion-based generative loss**ï¼Œå®ç°å¯¹æ¯”å­¦ä¹ ä¸ç”Ÿæˆå­¦ä¹ çš„ååŒã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- **æ›´ç»†ç²’åº¦çš„äº¤äº’å»ºæ¨¡**ï¼šé€šè¿‡æ‰©æ•£æ¨¡å‹æ³¨å…¥ç»“åˆæ„è±¡çš„å‡ ä½•ä¿¡æ¯ï¼Œæå‡å¯¹å±€éƒ¨ç›¸äº’ä½œç”¨çš„æ•æ„Ÿæ€§ã€‚
- **æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›**ï¼šå‡å°‘å¯¹ç²—ç²’åº¦ç‰©ç†åŒ–å­¦å±æ€§çš„ä¾èµ–ï¼Œåœ¨ OOD å’Œç±»ä¼¼ç‰©æ’åºä»»åŠ¡ä¸­è¡¨ç°æ›´ä¼˜ã€‚
- **æ¨ç†æ•ˆç‡ä¸å˜**ï¼šæ‰©æ•£æ¨¡å‹ä»…ç”¨äºè®­ç»ƒï¼Œæ¨ç†é˜¶æ®µä»ä¸ºå¿«é€Ÿçš„ **embedding similarity + ANN search**ï¼Œæ— é¢å¤–å¼€é”€ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **è®­ç»ƒé›†**ï¼š`PDBBind 2019` + `HomoAug` æ‰©å¢ï¼Œå…± 66,164 ä¸ªè›‹ç™½-é…ä½“å¤åˆç‰©ã€‚
- **éªŒè¯é›†**ï¼š`CASF-2016`ï¼Œç”¨äºè¶…å‚è°ƒä¼˜ã€‚
- **æµ‹è¯•åŸºå‡†**ï¼š
  - `DUD-E`ï¼š102 ä¸ªé¶ç‚¹ï¼Œå« property-matched decoysã€‚
  - `LIT-PCBA`ï¼š15 ä¸ªé¶ç‚¹ï¼ŒåŸºäºå®éªŒç¡®è®¤çš„æ´»æ€§/éæ´»æ€§æ ‡ç­¾ï¼Œåå€šæ›´å°ã€‚
  - **OOD Benchmark**ï¼šä» `MF-PCBA` æ„å»ºï¼Œæ’é™¤ä¸è®­ç»ƒé›†åºåˆ—åŒæºæ€§ >30% çš„è›‹ç™½ï¼Œä¸¥æ ¼æµ‹è¯•åˆ†å¸ƒå¤–æ³›åŒ–ã€‚
  - `FEP+ Benchmark`ï¼š4 ä¸ªé¶ç‚¹ï¼ˆCDK2, TYK2, JNK1, P38ï¼‰ï¼Œç”¨äºè¯„ä¼°å¯¹ç±»ä¼¼ç‰©çš„è‡ªç”±èƒ½æ’åºèƒ½åŠ›ã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**
- **è®­ç»ƒè®¾ç½®**ï¼š
  - ç¼–ç å™¨åŸºäº **UniMol** Transformer æ¶æ„ã€‚
  - ä½¿ç”¨ Adam ä¼˜åŒ–å™¨ï¼Œbatch size 48ï¼Œè®­ç»ƒ 100 è½®ã€‚
  - ç¡¬è´Ÿæ ·æœ¬ä» ZINC åº“ä¸­é€šè¿‡ embedding retrieval + Vina docking è¿‡æ»¤è·å¾—ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **AUROC**, **BEDROC**ï¼ˆå¼ºè°ƒæ—©æœŸå¯Œé›†ï¼‰
  - **Enrichment Factor (EF)**ï¼šEF0.5%, EF1%, EF5%
  - **Hits@K**ï¼šåœ¨ OOD è®¾ç½®ä¸‹æŠ¥å‘Š Hits@500 å’Œ Hits@1000
  - **Pairwise Accuracy & Kendall Tau**ï¼šç”¨äº FEP+ æ’åºä»»åŠ¡

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **Docking-based**ï¼šAutoDock Vina, Glide-SP, Surflex
- **Learning-based**ï¼š
  - å›å½’/åˆ†ç±»æ¨¡å‹ï¼šDeepDTA, RFscore, Pafnucy, OnionNet
  - è¡¨ç¤ºå­¦ä¹ æ¨¡å‹ï¼šPlanet, Gnina, DrugHash
  - CLIP-style æ£€ç´¢æ¨¡å‹ï¼š**DrugCLIP**ï¼ˆä¸»è¦å¯¹æ¯”åŸºçº¿ï¼‰

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **åœ¨ LIT-PCBA ä¸Šçš„è¡¨ç°ï¼ˆTable 1ï¼‰**
| Model       | AUROC   | BEDROC  | EF0.5%  | EF1%    | EF5%    |
|-------------|---------|---------|---------|---------|---------|
| DrugCLIP    | 55.45   | 6.41    | 8.24    | 5.21    | 2.14    |
| **BindCLIP**| **59.15**| **7.88**| **9.84**| **6.26**| **2.90**|

- **ç›¸å¯¹æå‡**ï¼šAUROC â†‘6.7%ï¼Œå¹³å‡æ—©æœŸå¯Œé›†æŒ‡æ ‡ â†‘24.5%

#### **åœ¨ DUD-E ä¸Šçš„è¡¨ç°ï¼ˆTable 2ï¼‰**
| Model       | AUROC   | BEDROC  | EF0.5%  | EF1%    | EF5%    |
|-------------|---------|---------|---------|---------|---------|
| DrugCLIP    | 79.29   | 47.53   | 37.90   | 30.52   | 10.08   |
| **BindCLIP**| **80.14**| **49.73**| **39.82**| **32.16**| **10.44**|

- å°½ç®¡ DUD-E å­˜åœ¨åŒ–å­¦åå€šï¼ŒBindCLIP ä»å–å¾—å°å¹…ä½†ä¸€è‡´çš„æå‡ã€‚

#### **åœ¨ OOD Benchmark ä¸Šçš„è¡¨ç°ï¼ˆFigure 4ï¼‰**
- **BEDROC** â†‘62%
- **EF0.5%** â†‘115%
- **Hits@500** â†‘114%ï¼ˆ15 vs 7ï¼‰
- **Hits@1000** â†‘62%ï¼ˆ21 vs 13ï¼‰
- æ˜¾è‘—ä¼˜äº DrugCLIPï¼Œè¡¨æ˜æ›´å¼ºçš„åˆ†å¸ƒå¤–æ³›åŒ–èƒ½åŠ›ã€‚

#### **åœ¨ FEP+ ç±»ä¼¼ç‰©æ’åºä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼ˆFigure 5ï¼‰**
| Metric           | DrugCLIP | BindCLIP |
|------------------|----------|----------|
| Pairwise Accuracy| 56.4%    | **65.7%**|
| Kendall Tau      | 0.14     | **0.31** |

- ç›¸å¯¹å‡†ç¡®ç‡æå‡ **16%**ï¼ŒKendall Tau ç¿»å€ä»¥ä¸Šï¼Œè¯´æ˜èƒ½æ›´å¥½åœ°åŒºåˆ†ç»†å¾®ç»“åˆå·®å¼‚ã€‚

### **æ¶ˆèå®éªŒç»“æœï¼ˆTable 3ï¼‰**
åœ¨ LIT-PCBA ä¸Šçš„æ¶ˆèç ”ç©¶æ˜¾ç¤ºï¼š
- **+ Diffusion Objective**ï¼šAUROC ä» 55.45 â†’ 56.71
- **+ Random Negatives**ï¼šè¿›ä¸€æ­¥æå‡è‡³ 58.91
- **+ Hard Negatives**ï¼šæœ€ç»ˆè¾¾ **59.15**ï¼Œæ•ˆæœæœ€æ˜¾è‘—
- è¡¨æ˜ **diffusion supervision** å’Œ **hard-negative augmentation** å‡æœ‰è´¡çŒ®ï¼Œä¸”åè€…æ›´å…·åˆ¤åˆ«åŠ›ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **CLIP-style å¯¹æ¯”å­¦ä¹ ä¸è¶³ä»¥æ•æ‰ç»†ç²’åº¦ç»“åˆä¿¡å·**ï¼Œæ˜“å—æ•°æ®é›†ä¸­ç²—ç²’åº¦ç›¸å…³æ€§çš„å¹²æ‰°ã€‚
2. **å¼•å…¥ç”Ÿæˆå¼ç›‘ç£ï¼ˆdiffusionï¼‰å¯æœ‰æ•ˆæ³¨å…¥å‡ ä½•æ„ŸçŸ¥çš„äº¤äº’ä¿¡æ¯**ï¼Œæå‡åµŒå…¥ç©ºé—´çš„ç”Ÿç‰©å­¦æ„ä¹‰ã€‚
3. **ç¡¬è´Ÿæ ·æœ¬å¢å¼º + é”šå®šæ­£åˆ™åŒ–** å¯æ˜¾è‘—æå‡æ¨¡å‹åˆ¤åˆ«åŠ›ï¼ŒåŒæ—¶é¿å…è¡¨ç¤ºåç¼©ã€‚
4. **BindCLIP åœ¨æŒ‘æˆ˜æ€§ä»»åŠ¡ä¸­ä¼˜åŠ¿æ˜æ˜¾**ï¼šå°¤å…¶åœ¨ OOD æ³›åŒ–å’Œç±»ä¼¼ç‰©æ’åºä¸Šå¤§å¹…è¶…è¶Šç°æœ‰æ–¹æ³•ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **è®­ç»ƒæˆæœ¬å¢åŠ **ï¼šç”±äºæ‰©æ•£æ¨¡å‹å’Œç¡¬è´Ÿé‡‡æ ·ï¼Œè®­ç»ƒæ—¶é—´å’Œæ˜¾å­˜æ¶ˆè€—çº¦ä¸º DrugCLIP çš„ 2 å€ã€‚
- **ä¾èµ–é«˜è´¨é‡ 3D ç»“æ„**ï¼šéœ€è¦è›‹ç™½-é…ä½“å¤åˆç‰©çš„ç²¾ç¡®ç»“åˆæ„è±¡ç”¨äºæ‰©æ•£è®­ç»ƒï¼Œé™åˆ¶äº†åœ¨æ— ç»“æ„æ•°æ®ä¸Šçš„åº”ç”¨ã€‚
- **ç¡¬è´Ÿæ ·æœ¬å¯èƒ½å¼•å…¥å™ªå£°**ï¼šå°½ç®¡ä½¿ç”¨ Vina è¿‡æ»¤ï¼Œä»å¯èƒ½å­˜åœ¨å‡é˜´æ€§é—®é¢˜ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ¢ç´¢æ›´é«˜æ•ˆçš„æ‰©æ•£æ¶æ„æˆ–è’¸é¦ç­–ç•¥ä»¥é™ä½è®­ç»ƒæˆæœ¬ã€‚
- å°†æ¡†æ¶æ‰©å±•åˆ° **de novo åˆ†å­ç”Ÿæˆ** æˆ– **lead optimization** ä»»åŠ¡ã€‚
- ç»“åˆ **protein sequence** ä¿¡æ¯ï¼Œå‡å°‘å¯¹ 3D ç»“æ„çš„ä¾èµ–ã€‚
- æ¢ç´¢åœ¨ **multi-target screening** å’Œ **polypharmacology** ä¸­çš„åº”ç”¨ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **BindCLIP é€šè¿‡å°† contrastive learning ä¸ generative modelingï¼ˆdiffusionï¼‰ç›¸ç»“åˆï¼Œå¹¶è¾…ä»¥ hard-negative learning å’Œ anchoring æ­£åˆ™åŒ–ï¼Œåœ¨ä¸ç‰ºç‰²æ¨ç†æ•ˆç‡çš„å‰æä¸‹ï¼Œå®ç°äº†æ›´é²æ£’ã€æ›´ç»†ç²’åº¦çš„è™šæ‹Ÿç­›é€‰è¡¨ç¤ºå­¦ä¹ ï¼Œæ˜¾è‘—æå‡äº†åœ¨ç°å®åœºæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›å’Œæ’åºå‡†ç¡®æ€§ã€‚**

</details>

---

### 9. [CAMEL: An ECG Language Model for Forecasting Cardiac Events](https://arxiv.org/abs/2602.15677)

**Authors**: Neelay Velingker, Alaia Solko-Breslin, Mayank Keoliya, Seewon Choi, Jiayi Xin, Anika Marathe, Alireza Oraii, Rajat Deo, Sameed Khatana, Rajeev Alur, Mayur Naik, Eric Wong  
**Category**: cs.LG  
**Published**: 2026-02-18  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.15677v1  

#### Abstract
Electrocardiograms (ECG) are electrical recordings of the heart that are critical for diagnosing cardiovascular conditions. ECG language models (ELMs) have recently emerged as a promising framework for ECG classification accompanied by report generation. However, current models cannot forecast futur...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šCAMEL: An ECG Language Model for Forecasting Cardiac Events

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰çš„ **ECG Language Models (ELMs)** ä¸»è¦ä¸“æ³¨äº ECG åˆ†ç±»å’ŒæŠ¥å‘Šç”Ÿæˆï¼Œ**æ— æ³•é¢„æµ‹æœªæ¥çš„ä¸´åºŠäº‹ä»¶**ï¼Œé™åˆ¶äº†å…¶åœ¨æ—©æœŸå¹²é¢„ä¸­çš„åº”ç”¨ä»·å€¼ã€‚  
æœ¬æ–‡æ—¨åœ¨å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæå‡ºé¦–ä¸ªèƒ½å¤Ÿä» ECG ä¿¡å·ä¸­**é¢„æµ‹æœªæ¥å¿ƒå¾‹å¤±å¸¸äº‹ä»¶**ï¼ˆå¦‚æˆ¿é¢¤ AFIBï¼‰çš„é€šç”¨ ECG è¯­è¨€æ¨¡å‹ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸æ ¸å¿ƒåˆ›æ–°
ä½œè€…æå‡ºäº† **CAMEL (Cardiac Autoregressive Model for ECG Language Modeling)**ï¼Œå…·å¤‡ä»¥ä¸‹å…³é”®åˆ›æ–°ï¼š

- **æ”¯æŒé•¿æ—¶åºä¸Šä¸‹æ–‡è¾“å…¥**ï¼š  
  é¦–æ¬¡å®ç°å¯¹é•¿è¾¾æ•°åƒç§’ï¼ˆæœ€é«˜è¾¾ 600 ç§’ï¼‰çš„ ECG ä¿¡å·è¿›è¡Œå»ºæ¨¡ï¼Œè¿œè¶…ç°æœ‰æ¨¡å‹ä»…æ”¯æŒ 10 ç§’ç‰‡æ®µçš„é™åˆ¶ã€‚
  
- **åŸºäº token çš„ ECG ç¼–ç æœºåˆ¶**ï¼š  
  å°†æ¯æ¡å¯¼è”çš„æ¯ä¸€ç§’ ECG ç‰‡æ®µç¼–ç ä¸ºä¸€ä¸ªç‹¬ç«‹çš„ `token`ï¼Œå¹¶ä¸æ–‡æœ¬ token äº¤é”™èåˆï¼Œä½¿ LLM èƒ½å¤Ÿåœ¨ç»Ÿä¸€åºåˆ—ä¸­å¤„ç†å¤šå¯¼è”ã€é•¿æ—¶é—´ ECG ä¸è‡ªç„¶è¯­è¨€æŒ‡ä»¤ã€‚

- **ä¸“ç”¨ ECG Encoder è®¾è®¡**ï¼š  
  ä½¿ç”¨ 3 å±‚ CNN å¯¹åŸå§‹æ³¢å½¢è¿›è¡Œç‰¹å¾æå–ï¼Œå¹¶é€šè¿‡çº¿æ€§æŠ•å½±å±‚å°†å…¶æ˜ å°„åˆ° LLM çš„éšç©ºé—´ï¼Œå®ç°è·¨æ¨¡æ€å¯¹é½ã€‚

- **Lead-aware Attention Masking**ï¼š  
  åœ¨åŒä¸€æ—¶é—´ç‚¹çš„ä¸åŒå¯¼è”ä¹‹é—´å…è®¸åŒå‘æ³¨æ„åŠ›äº¤äº’ï¼Œåˆ©ç”¨å¤šå¯¼è”åŒæ­¥è®°å½•çš„ç”Ÿç†ä¸€è‡´æ€§å¢å¼ºæ¨¡å‹ç†è§£èƒ½åŠ›ã€‚

- **äº”é˜¶æ®µè¯¾ç¨‹å­¦ä¹ è®­ç»ƒæµç¨‹ï¼ˆCurriculum Learning Pipelineï¼‰**ï¼š
  1. è‡ªç¼–ç å™¨é¢„è®­ç»ƒï¼ˆAutoencoderï¼‰
  2. å¤šé€‰é¢˜ä¸ç®€ç­”é¢˜ï¼ˆMultiple Choice & Short Answerï¼‰
  3. ç»Ÿè®¡é‡è®¡ç®—ä»»åŠ¡ï¼ˆStatistics Understandingï¼‰
  4. å¤šè½®å¯¹è¯æ¨ç†ï¼ˆMulti-turn Conversationsï¼‰
  5. å¿ƒè„äº‹ä»¶é¢„æµ‹ï¼ˆForecastingï¼‰

  è¯¥è®¾è®¡é€æ­¥æå‡æ¨¡å‹ä»åŸºç¡€åˆ†ç±»åˆ°å¤æ‚é¢„æµ‹çš„èƒ½åŠ›ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | CAMEL | å…¶ä»– ELMsï¼ˆå¦‚ GEM, PULSEï¼‰ |
|------|-------|-----------------------------|
| è¾“å…¥é•¿åº¦ | æ”¯æŒ 0â€“10,000 ç§’ | é€šå¸¸ â‰¤10 ç§’ |
| æ˜¯å¦æ”¯æŒé¢„æµ‹ | âœ… æ˜¯ | âŒ å¦ |
| æ˜¯å¦æ”¯æŒå¤š ECG æ¯”è¾ƒ | âœ… æ˜¯ | æœ‰é™æ”¯æŒ |
| æ˜¯å¦å…·å¤‡å¯è§£é‡Šæ€§ | âœ… åŸºäº ECG ç»Ÿè®¡é‡ç”Ÿæˆè§£é‡Š | éƒ¨åˆ†æ”¯æŒ |
| æ³›åŒ–èƒ½åŠ› | å¼ºï¼ˆzero-shot è¡¨ç°ä¼˜å¼‚ï¼‰ | ä¾èµ– fine-tuning |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†

| æ•°æ®é›† | ç±»å‹ | æè¿° |
|--------|------|------|
| **Icentia11k** | æ ‡ç­¾æ•°æ® | å•å¯¼è”è¿ç»­ ECGï¼Œæ ‡æ³¨ NORM / AFIB / AFLï¼Œç”¨äº**é¢„æµ‹ä»»åŠ¡** |
| **PTB-XL**, **CSN**, **CODE-15%**, **CPSC-2018**, **HEEDB**, **MIMIC-IV-ECG** | åˆ†ç±» & æŠ¥å‘Šç”Ÿæˆ | å¤šæ ‡ç­¾è¯Šæ–­ä»£ç æ•°æ®é›†ï¼Œè¦†ç›–å¤šç§å¿ƒè„å¼‚å¸¸ |
| **Penn** | ç§æœ‰æ•°æ®é›† | æ¥è‡ªå®¾å¤§åŒ»é™¢ ICU çš„ 8 å¯¼è” ECGï¼Œå« VT/VF æ ‡æ³¨ï¼Œç”¨äº out-of-distribution æµ‹è¯• |
| **MITDB, QTDB, SPH ç­‰** | æ— æ ‡ç­¾ä¿¡å· | ç”¨äº Stage 1 è‡ªç¼–ç å™¨è®­ç»ƒ |

> æ€»å…±ä½¿ç”¨ **14 ä¸ªå…¬å¼€æ•°æ®é›† + 1 ä¸ªç§æœ‰æ•°æ®é›†**

---

### âš™ï¸ å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### æ¨¡å‹æ¶æ„
- **Backbone**: MedGemma-4Bï¼ˆåŒ»ç–—é¢†åŸŸ LLMï¼‰
- **LoRA Adaptation**: Rank=128ï¼Œå†»ç»“ä¸»å¹²ç½‘ç»œï¼Œä»…å¾®è°ƒé€‚é…å™¨
- **ECG Encoder**: 3-layer CNN + Linear Projection â†’ æ˜ å°„è‡³ LLM éšç©ºé—´ï¼ˆh=2560ï¼‰

#### è¯„ä¼°ä»»åŠ¡ä¸æŒ‡æ ‡

| ä»»åŠ¡ | æŒ‡æ ‡ | è¯´æ˜ |
|------|------|------|
| **Forecasting** | F1 Score | é¢„æµ‹æœªæ¥æ˜¯å¦å‘ç”Ÿ AFIB/AFLï¼ˆABNORMAL vs NORMï¼‰ |
| **Classification** | F1, AUROC | å¤šç±»åˆ«è¯Šæ–­ä»£ç åˆ†ç±»ï¼ˆzero-shot å’Œ linear probingï¼‰ |
| **Report Generation** | LLM-as-a-judge (GPT-5), BLEU, METEOR, ROUGE, BERT-F1 | è‡ªåŠ¨ç”Ÿæˆè¯Šæ–­æŠ¥å‘Šçš„è´¨é‡ |
| **QA** | Accuracy, Hamming Score | å• ECG ä¸å¤š ECG é—®ç­”ä»»åŠ¡ |
| **Grounding** | RMSE | å¯¹ RR intervalã€QRS duration ç­‰ç»Ÿè®¡é‡çš„æ•°å€¼è¿˜åŸç²¾åº¦ |

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ¨¡å‹ | ç±»å‹ | æ˜¯å¦æ”¯æŒé¢„æµ‹ |
|------|------|--------------|
| MELP, MERL | Zero-shot ECG-text åŒ¹é…æ¨¡å‹ | âŒ |
| PULSE, GEM | å¤šæ¨¡æ€ LLMï¼ˆå›¾åƒ/æ³¢å½¢+æ–‡æœ¬ï¼‰ | âŒ |
| XGB, CNN | Fully supervised æ¨¡å‹ | âœ…ï¼ˆç‰¹å®šä»»åŠ¡ï¼‰ |
| GPT-5.2 + Code Interpreter | å¤§æ¨¡å‹ + å·¥å…·è°ƒç”¨ | âœ…ï¼ˆä½œä¸ºå¼ºåŸºçº¿ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

#### âœ… åœ¨ ECGForecastBench ä¸Šçš„è¡¨ç°ï¼ˆé¢„æµ‹ä»»åŠ¡ï¼‰
| æ–¹æ³• | F1 Score (h=60s, w=600s) | æå‡å¹…åº¦ |
|------|--------------------------|---------|
| **CAMEL** | **73.42%** | â€” |
| Fully Supervised XGB | 59.64% | â†“13.78% |
| GPT-5.2 (with code interpreter) | 54.36% | â†“19.06% |
| GEM | 32.95% | â†“40.47% |

> CAMEL åœ¨ zero-shot è®¾ç½®ä¸‹æ¯” fully supervised æ¨¡å‹é«˜å‡º **+12.4%**ï¼Œæ¯”å…¶ä»– zero-shot ELMs é«˜å‡º **+21.1%**

#### âœ… åœ¨ ECGBench ä¸Šçš„ zero-shot åˆ†ç±»è¡¨ç°ï¼ˆå¹³å‡ F1ï¼‰
| æ–¹æ³• | å¹³å‡ F1 (%) | æå‡ï¼ˆvs SOTAï¼‰ |
|------|------------|---------------|
| **CAMEL** | **67.53%** | +7.0% |
| GEM | 60.53% | â€” |
| PULSE | 58.07% | â€” |

> åœ¨ PTB-XL çš„ 4 é¡¹å­ä»»åŠ¡ä¸­ï¼ŒCAMEL åœ¨å…¶ä¸­ 3 é¡¹å–å¾—æœ€ä½³æˆç»©ã€‚

#### âœ… æŠ¥å‘Šç”Ÿæˆè´¨é‡ï¼ˆLLM-as-a-judge å¾—åˆ† / æ»¡åˆ† 30ï¼‰
| æ–¹æ³• | PTB-XL | MIMIC-IV |
|------|--------|---------|
| GEM | 20.45 | 44.65 |
| **CAMEL** | **19.45** | **62.59** |

> CAMEL åœ¨ MIMIC-IV ä¸Šæ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼Œæ¥è¿‘äººç±»åŒ»ç”Ÿæ°´å¹³ã€‚

#### âœ… æ•°å€¼æ¥åœ°èƒ½åŠ›ï¼ˆECG Statistics RMSEï¼‰
| æ–¹æ³• | RMSE (CPSC-2018) |
|------|------------------|
| GEM | 304 |
| **CAMEL** | **109** |

> RMSE å‡å°‘è¿‘ **2/3**ï¼Œè¡¨æ˜ CAMEL æ›´å‡†ç¡®åœ°ç†è§£å’Œæå– ECG ç”Ÿç†å‚æ•°ã€‚

---

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

| æ¶ˆèé…ç½® | PTBXL-Super F1 (%) | å½±å“åˆ†æ |
|--------|--------------------|--------|
| å®Œæ•´ CAMEL | **75.91** | â€” |
| ç§»é™¤ LoRA | 0.00 | æ¨¡å‹å®Œå…¨å¤±æ•ˆï¼Œè¯æ˜ LoRA æ˜¯å…³é”®å¯è®­ç»ƒæ¨¡å— |
| ä½¿ç”¨å…¨å‘æ³¨æ„åŠ›æ©ç  | 54.39 | æ€§èƒ½å¤§å¹…ä¸‹é™ |
| ä½¿ç”¨å› æœæ³¨æ„åŠ› | 69.15 | ä¸å¦‚ lead-aware æ©ç  |
| **Lead-aware Attention + LoRA** | âœ… æœ€ä¼˜ç»„åˆ | åˆ©ç”¨äº†å¤šå¯¼è”åŒæ­¥æ€§ï¼Œä¸”ä¿æŒæ—¶åºå»ºæ¨¡èƒ½åŠ› |

> ç»“è®ºï¼š**LoRA ä¸ lead-aware attention masking å‡ä¸å¯æˆ–ç¼º**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **é¦–æ¬¡å®ç°äº† zero-shot å¿ƒè„äº‹ä»¶é¢„æµ‹èƒ½åŠ›**ï¼š  
   CAMEL å¯ä»¥åŸºäºå½“å‰æ­£å¸¸èŠ‚å¾‹ ECGï¼Œæ¨ç†æœªæ¥å‡ åˆ†é’Ÿå†…æ˜¯å¦ä¼šå‘å±•ä¸º AFIBï¼Œä¸”æä¾›åŸºäº RMSSDã€PAC æ•°é‡ç­‰ä¸´åºŠæŒ‡æ ‡çš„å¯è§£é‡Šä¾æ®ã€‚

2. **é•¿æ—¶åºè¾“å…¥æ˜¾è‘—æå‡é¢„æµ‹æ€§èƒ½**ï¼š  
   å½“è¾“å…¥çª—å£ä» 10 ç§’å¢åŠ åˆ° 600 ç§’æ—¶ï¼ŒF1 æé«˜è¶…è¿‡ 15%ï¼Œè¯´æ˜é•¿æœŸå˜å¼‚æ€§æ˜¯é¢„æµ‹çš„é‡è¦çº¿ç´¢ã€‚

3. **è¯¾ç¨‹å­¦ä¹ æœ‰æ•ˆæ„å»ºå¤šå±‚æ¬¡èƒ½åŠ›**ï¼š  
   ä»ç»Ÿè®¡é‡è¯†åˆ« â†’ å¤šè½®å¯¹è¯ â†’ é£é™©é¢„æµ‹çš„æ¸è¿›è®­ç»ƒç­–ç•¥ï¼Œä½¿æ¨¡å‹è·å¾—æ‰å®çš„ ECG grounding èƒ½åŠ›ã€‚

4. **ä¼˜äº fully supervised æ¨¡å‹**ï¼š  
   åœ¨å¤šä¸ªä»»åŠ¡ä¸Šï¼ŒCAMEL çš„ zero-shot è¡¨ç°è¶…è¶Šä¸“é—¨è®­ç»ƒçš„ç›‘ç£æ¨¡å‹ï¼Œå±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–æ½œåŠ›ã€‚

---

### âš ï¸ å±€é™æ€§
1. **Tokenization ç­–ç•¥é™åˆ¶**ï¼š  
   å½“å‰æŒ‰ 1 ç§’åˆ‡ç‰‡å¯èƒ½å¯¼è‡´ QRS æ³¢ç¾¤è¢«æˆªæ–­ï¼Œå½±å“å½¢æ€å­¦ç»†èŠ‚æ•æ‰ã€‚

2. **æœ€å¤§è¾“å…¥å—é™äº LLM ä¸Šä¸‹æ–‡é•¿åº¦**ï¼š  
   å°½ç®¡æ”¯æŒé•¿ä¿¡å·ï¼Œä½†ä»å—åˆ¶äº MedGemma çš„ context windowï¼ˆçº¦ 8K tokensï¼‰ï¼Œéš¾ä»¥å¤„ç†æé•¿æ—¶é—´è®°å½•ã€‚

3. **å•å¯¼è”ä¸ºä¸»**ï¼š  
   å½“å‰é¢„æµ‹ä»»åŠ¡ä¸»è¦åŸºäº Icentia11k çš„å•å¯¼è”æ•°æ®ï¼Œå°šæœªå……åˆ†éªŒè¯åœ¨å®Œæ•´ 12 å¯¼è”ä¸Šçš„é¢„æµ‹èƒ½åŠ›ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ”¹è¿› Tokenization æ–¹å¼**ï¼š  
   æ¢ç´¢ä»¥ QRS æ³¢ç¾¤æˆ–å¿ƒè·³å‘¨æœŸä¸ºå•ä½çš„è¯­ä¹‰ tokenï¼Œæå‡ç”Ÿç†æ„ä¹‰è¡¨è¾¾èƒ½åŠ›ã€‚

2. **æ‰©å±•è‡³æ›´å¤šç±»å‹çš„é¢„æµ‹ä»»åŠ¡**ï¼š  
   å¦‚å®¤é€Ÿï¼ˆVTï¼‰ã€å¿ƒæåœæ­¢ï¼ˆCardiac Arrestï¼‰ç­‰æ›´å±æ€¥äº‹ä»¶çš„é¢„æµ‹ã€‚

3. **ç»“åˆä¸´åºŠå…ƒæ•°æ®**ï¼š  
   èåˆå¹´é¾„ã€ç—…å²ã€è¯ç‰©ç­‰ä¿¡æ¯ï¼Œè¿›ä¸€æ­¥æå‡ä¸ªä½“åŒ–é£é™©é¢„æµ‹å‡†ç¡®æ€§ã€‚

4. **éƒ¨ç½²äºå®æ—¶ç›‘æŠ¤ç³»ç»Ÿ**ï¼š  
   æ„å»ºç«¯åˆ°ç«¯ pipelineï¼Œåœ¨ ICU æˆ–å¯ç©¿æˆ´è®¾å¤‡ä¸­å®ç°å®æ—¶é¢„è­¦ã€‚

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> CAMEL æ˜¯é¦–ä¸ªæ”¯æŒé•¿æ—¶åºæ¨ç†ä¸æœªæ¥å¿ƒè„äº‹ä»¶é¢„æµ‹çš„ ECG Language Modelï¼Œé€šè¿‡åˆ›æ–°çš„ token åŒ–è®¾è®¡ä¸è¯¾ç¨‹å­¦ä¹ æ¡†æ¶ï¼Œåœ¨ zero-shot ä¸‹å…¨é¢è¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œæ¨åŠ¨ AI ä»â€œè¯Šæ–­â€è¿ˆå‘â€œé¢„è§â€ã€‚

</details>

---

### 10. [PERSONA: Dynamic and Compositional Inference-Time Personality Control via Activation Vector Algebra](https://arxiv.org/abs/2602.15669)

**Authors**: Xiachong Feng, Liang Zhao, Weihong Zhong, Yichong Huang, Yuxuan Gu, Lingpeng Kong, Xiaocheng Feng, Bing Qin  
**Category**: cs.AI  
**Published**: 2026-02-18  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.15669v1  

#### Abstract
Current methods for personality control in Large Language Models rely on static prompting or expensive fine-tuning, failing to capture the dynamic and compositional nature of human traits. We introduce PERSONA, a training-free framework that achieves fine-tuning level performance through direct mani...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šPERSONA: Dynamic and Compositional Inference-Time Personality Control via Activation Vector Algebra

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å½“å‰åœ¨ **Large Language Models (LLMs)** ä¸­å®ç° **personality æ§åˆ¶**çš„æ–¹æ³•å­˜åœ¨ä»¥ä¸‹å±€é™ï¼š

- **Prompting æ–¹æ³•**ï¼ˆå¦‚ç›´æ¥æ·»åŠ â€œä½ æ˜¯ä¸€ä¸ªå¤–å‘çš„äººâ€ï¼‰è™½ç„¶ç®€å•ï¼Œä½†æ§åˆ¶ä¸ç¨³å®šã€ä¸ä¸€è‡´ï¼Œå®¹æ˜“å¤±æ•ˆã€‚
- **Fine-tuning æ–¹æ³•**ï¼ˆå¦‚ SFTã€DPOï¼‰è™½æœ‰æ•ˆï¼Œä½†éœ€è¦å¤§é‡è®¡ç®—èµ„æºï¼Œä¸”æ¯ä¸ªä¸ªæ€§é…ç½®éƒ½éœ€è¦é‡æ–°è®­ç»ƒï¼Œæ— æ³•çµæ´»ç»„åˆã€‚
- æ›´é‡è¦çš„æ˜¯ï¼Œç°æœ‰æ–¹æ³•å°† personality è§†ä¸º**é™æ€ã€å•ä¸€çš„æ•´ä½“ç‰¹å¾**ï¼Œæ— æ³•æ”¯æŒäººç±»æ€§æ ¼ä¸­å¸¸è§çš„**åŠ¨æ€å˜åŒ–**ï¼ˆå¦‚æ ¹æ®æƒ…å¢ƒè°ƒæ•´æƒ…ç»ªï¼‰å’Œ**å¯ç»„åˆæ€§**ï¼ˆå¦‚åŒæ—¶å…·å¤‡â€œæœ‰åˆ›é€ åŠ›â€å’Œâ€œæœ‰åŒç†å¿ƒâ€ï¼‰ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡º **PERSONA** æ¡†æ¶ï¼Œä¸€ç§æ— éœ€è®­ç»ƒï¼ˆtraining-freeï¼‰ã€åŸºäºæ¿€æ´»ç©ºé—´å‘é‡ä»£æ•°çš„åŠ¨æ€ personality æ§åˆ¶æ–¹æ³•ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> **Personality traits åœ¨ LLM çš„ activation space ä¸­è¡¨ç°ä¸ºè¿‘ä¼¼æ­£äº¤ï¼ˆapproximately orthogonalï¼‰çš„å¯æå–æ–¹å‘ï¼Œè¿™äº›æ–¹å‘æ”¯æŒä»£æ•°è¿ç®—ï¼ˆåŠ å‡ä¹˜é™¤ï¼‰ï¼Œä»è€Œå®ç°å¯¹æ€§æ ¼çš„ç²¾ç¡®ã€åŠ¨æ€ã€å¯ç»„åˆçš„æ§åˆ¶ã€‚**

è¯¥æ¡†æ¶ç”±ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶æ„æˆï¼š

- **PERSONA-BASE**ï¼šé€šè¿‡ contrastive activation analysis æå– OCEAN äº”å¤§äººæ ¼ç»´åº¦ï¼ˆOpenness, Conscientiousness, Extraversion, Agreeableness, Neuroticismï¼‰å…± 10 ä¸ªææ€§ trait çš„ personality vectorsã€‚
- **PERSONA-ALGEBRA**ï¼šåˆ©ç”¨å‘é‡ä»£æ•°æ“ä½œå®ç°æ€§æ ¼æ§åˆ¶ï¼š
  - **Scalar multiplication**ï¼šè°ƒèŠ‚æ€§æ ¼å¼ºåº¦ï¼ˆå¦‚â€œæ›´å¤–å‘â€ï¼‰ã€‚
  - **Vector addition**ï¼šç»„åˆå¤šä¸ªæ€§æ ¼ï¼ˆå¦‚â€œå¤–å‘ + åŒç†å¿ƒâ€ï¼‰ã€‚
  - **Vector subtraction**ï¼šæŠ‘åˆ¶æŸä¸ªæ€§æ ¼ï¼ˆå¦‚â€œå‡å°‘ç„¦è™‘â€ï¼‰ã€‚
- **PERSONA-FLOW**ï¼šåœ¨æ¨ç†æ—¶ï¼ˆinference-timeï¼‰åŠ¨æ€åœ°è¿›è¡Œæ€§æ ¼æ§åˆ¶ã€‚é€šè¿‡ä¸€ä¸ªâ€œé¢„æµ‹-å¼•å¯¼â€ï¼ˆpredict-then-steerï¼‰æœºåˆ¶ï¼Œæ ¹æ®å¯¹è¯ä¸Šä¸‹æ–‡å®æ—¶é¢„æµ‹æœ€ä¼˜çš„æ€§æ ¼è°ƒæ•´ç³»æ•°ï¼Œå¹¶åŠ¨æ€åˆæˆ steering vectorã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³• | PERSONA |
|------|--------|---------|
| **æ˜¯å¦éœ€è¦è®­ç»ƒ** | Fine-tuning éœ€è¦ï¼›Prompting ä¸éœ€è¦ | âœ… å®Œå…¨æ— éœ€è®­ç»ƒ |
| **æ§åˆ¶ç²¾åº¦** | Prompting ä¸ç¨³å®šï¼›Fine-tuning è¾ƒé«˜ | âœ… æ¥è¿‘ fine-tuning ä¸Šé™ |
| **åŠ¨æ€é€‚åº”æ€§** | å‡ ä¹æ—  | âœ… æ”¯æŒå®æ—¶ä¸Šä¸‹æ–‡æ„ŸçŸ¥è°ƒæ•´ |
| **å¯ç»„åˆæ€§** | æœ‰é™ | âœ… æ”¯æŒä»»æ„æ€§æ ¼ç»„åˆä¸æŠ‘åˆ¶ |
| **è®¡ç®—æ•ˆç‡** | Fine-tuning æä½ï¼›Prompting é«˜ | âœ… ä»…å¢åŠ çº¦ 5.5% æ¨ç†å»¶è¿Ÿ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

1. **PERSONA-BASE å’Œ PERSONA-ALGEBRA**ï¼š
   - ä½¿ç”¨ **BFI-44**ï¼ˆBig Five Inventory-44ï¼‰é—®å·ä½œä¸ºæ€§æ ¼è¯„ä¼°å·¥å…·ã€‚
   - å°†å…¶è½¬åŒ–ä¸º **scenario-based prompts**ï¼Œé¿å… LLM è‡ªæˆ‘æŠ¥å‘Šåå·®ã€‚
   - é€šè¿‡ GPT-4.1-mini å¯¹æ¨¡å‹å“åº”è¿›è¡Œ 5 åˆ†åˆ¶è¯„åˆ†ã€‚

2. **PERSONA-FLOW å’Œ PERSONA-EVOLVE**ï¼š
   - æå‡ºå¹¶æ„å»ºäº†ä¸€ä¸ªæ–°çš„ benchmarkï¼š**PERSONA-EVOLVE**ã€‚
   - åŒ…å« **800 ä¸ªå¤šè½®å¯¹è¯åœºæ™¯**ï¼Œè¦†ç›– 100 ä¸ªä¸åŒè§’è‰²ï¼ˆå¦‚â€œé£Ÿå“è½¦è€æ¿â€ã€â€œå…¬è®¾è¾©æŠ¤äººâ€ï¼‰ã€‚
   - æ¯ä¸ªè§’è‰²æœ‰ **8 ä¸ªå¯¹è¯å›åˆ**ï¼Œæ¨¡æ‹ŸçœŸå®æƒ…æ„Ÿæ¼”å˜ï¼ˆå¦‚ä»â€œå‹åŠ›å¤§â€åˆ°â€œé‡Šç„¶â€ï¼‰ã€‚
   - è¯„ä¼°è¦æ±‚æ¨¡å‹åœ¨ä¿æŒè§’è‰²ä¸€è‡´æ€§çš„åŒæ—¶ï¼ŒåŠ¨æ€é€‚åº”æƒ…å¢ƒã€‚

3. **å¤–éƒ¨åŸºå‡†æµ‹è¯•**ï¼š
   - åœ¨ **PersonalityBench**ï¼ˆDeng et al., 2025ï¼‰ä¸Šè¿›è¡Œè·¨åŸºå‡†éªŒè¯ï¼ŒåŒ…å«çº¦ 90 ä¸ªæƒ…å¢ƒé—®é¢˜ per traitã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **è¯„ä¼°æŒ‡æ ‡**

- **PersonalityBench**ï¼š
  - **Mean Score**ï¼šäº”ä¸ªç»´åº¦å¾—åˆ†æ€»å’Œã€‚
  - **Variance**ï¼šè¡¡é‡æ§åˆ¶ç¨³å®šæ€§ã€‚

- **PERSONA-EVOLVE**ï¼š
  - **Win Rate (%)**ï¼šé€šè¿‡æˆå¯¹æ¯”è¾ƒï¼ˆA/B testingï¼‰è¯„ä¼°ï¼Œåˆ¤æ–­ steered å“åº”æ˜¯å¦ä¼˜äºåŸå§‹å“åº”ã€‚
    - **Trait Adherence (TA)**ï¼šæ€§æ ¼åŒ¹é…åº¦ã€‚
    - **Role Consistency (RC)**ï¼šè§’è‰²ä¸€è‡´æ€§ã€‚
    - **Response Authenticity (RA)**ï¼šå›åº”çœŸå®æ€§ã€‚
    - **Information Fidelity (IF)**ï¼šä¿¡æ¯å‡†ç¡®æ€§ã€‚
    - **Overall**ï¼šç»¼åˆåå¥½ã€‚

#### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

- **NPTI**ï¼šåŸºäºç¥ç»å…ƒæ¿€æ´»åˆ†æçš„æ€§æ ¼è¯±å¯¼ã€‚
- **Simple Prompt**ï¼šå•å½¢å®¹è¯æç¤ºï¼ˆå¦‚â€œä½ æ˜¯ä¸€ä¸ªå¤–å‘çš„äººâ€ï¼‰ã€‚
- **P2 Induction**ï¼šä½¿ç”¨æ¨¡å‹ç”Ÿæˆçš„æ€§æ ¼æè¿°ã€‚
- **PAS**ï¼šæ¢æµ‹ IPIP-NEO-300 ç›¸å…³æ³¨æ„åŠ›å¤´ã€‚
- **ActAdd**ï¼šæ®‹å·®æµæ¿€æ´»æ·»åŠ ã€‚
- **Supervised Fine-Tuning (SFT)**ï¼šç›‘ç£å¾®è°ƒï¼ˆLoRAï¼‰ï¼Œä½œä¸ºæ€§èƒ½ä¸Šé™ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **åœ¨ PersonalityBench ä¸Šçš„è¡¨ç°**

| æ–¹æ³• | å¹³å‡åˆ† (Mean) | æ–¹å·® (Variance) |
|------|---------------|-----------------|
| **PERSONA-BASE** | **9.60** | **0.74** |
| SFT (ä¸Šç•Œ) | 9.61 | 0.49 |
| NPTI | 9.43 | 0.49 |
| ActAdd | 8.20 | 2.10 |

âœ… **PERSONA-BASE ä»¥ 9.60 åˆ†å‡ ä¹è¿½å¹³ SFT ä¸Šé™ï¼ˆ9.61ï¼‰**ï¼Œä¸”æ˜¾è‘—ä¼˜äºå…¶ä»–æ— éœ€è®­ç»ƒæ–¹æ³•ã€‚

#### **åœ¨ PERSONA-EVOLVE ä¸Šçš„è¡¨ç°ï¼ˆWin Rate %ï¼‰**

| æ¨¡å‹å®¶æ— | TA | RC | RA | IF | **Overall** |
|----------|----|----|----|----|------------|
| Qwen3-4B | 92.2 | 90.6 | 92.4 | 49.1 | **90.8** |
| Qwen2.5-14B | 84.8 | 86.4 | 84.8 | 59.3 | 85.4 |
| Llama-3.1-8B | 84.9 | 81.4 | 85.6 | 57.2 | 83.5 |
| Mistral-8B | 74.3 | 73.2 | 74.2 | 48.0 | 73.2 |

âœ… **æœ€é«˜è¾¾åˆ° 90.8% çš„ç»¼åˆèƒœç‡**ï¼Œè¡¨æ˜åœ¨å¤šè½®åŠ¨æ€åœºæ™¯ä¸­å…·æœ‰å¼ºå¤§ä¼˜åŠ¿ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- **PERSONA-BASE** åœ¨æ‰€æœ‰æ— éœ€è®­ç»ƒæ–¹æ³•ä¸­è¡¨ç°æœ€ä½³ï¼Œå¹³å‡åˆ†é¢†å…ˆç¬¬äºŒåï¼ˆNPTIï¼‰0.17åˆ†ã€‚
- åœ¨ **Openness** ç»´åº¦ä¸Šä¼˜åŠ¿æœ€æ˜æ˜¾ï¼Œè¯´æ˜ dense vector è¡¨ç¤ºèƒ½æ›´å¥½æ•æ‰åˆ†å¸ƒå¼è¯­ä¹‰ã€‚
- **PERSONA-FLOW** åœ¨åŠ¨æ€é€‚åº”ä»»åŠ¡ä¸­å…¨é¢è¶…è¶Š prompting å’Œé™æ€ steering æ–¹æ³•ã€‚

### **æ¶ˆèå®éªŒç»“æœ**

#### **1. ç³»æ•°ç¦»æ•£åŒ–ï¼ˆCoefficient Binningï¼‰**

| é…ç½® | Overall Win Rate | Î” |
|------|------------------|---|
| è¿ç»­ [-2.0, +2.0] | 83.4 | â€” |
| 9-bin | 82.1 | -1.3 |
| 5-bin | 80.5 | -2.9 |
| ä¸‰å€¼ {-1,0,+1} | 75.2 | -8.2 |

â¡ï¸ **ç»†ç²’åº¦æ§åˆ¶è‡³å…³é‡è¦**ï¼Œç²—ç•¥ç¦»æ•£ä¸¥é‡æŸå®³æ€§èƒ½ã€‚

#### **2. ä¸Šä¸‹æ–‡çª—å£é•¿åº¦**

| é…ç½® | Overall Win Rate |
|------|------------------|
| å½“å‰å›åˆï¼ˆCurrent turn onlyï¼‰ | 83.4 |
| æœ€è¿‘3å›åˆ | 81.9 |
| æ‰€æœ‰å†å² | 80.9 |

â¡ï¸ **ä»…ç”¨å½“å‰å›åˆä¸Šä¸‹æ–‡æ•ˆæœæœ€å¥½**ï¼Œè¯´æ˜è¿‡åº¦ä¾èµ–å†å²åè€Œé™ä½å“åº”çµæ•åº¦ã€‚

#### **3. ç¨€ç–æ€§é˜ˆå€¼ï¼ˆSparsity Threshold Tï¼‰**

| T | Overall Win Rate |
|---|------------------|
| 0.3 | 82.4 |
| **0.5** | **83.4** |
| 0.7 | 81.6 |

â¡ï¸ **T=0.5 æ˜¯æœ€ä¼˜å¹³è¡¡ç‚¹**ï¼Œè¿‡ä½å¼•å…¥å™ªå£°ï¼Œè¿‡é«˜æŠ‘åˆ¶åˆç†è°ƒæ•´ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **Personality æ˜¯æ•°å­¦ä¸Šå¯å¤„ç†çš„**ï¼šLLM ä¸­çš„æ€§æ ¼ç‰¹è´¨åœ¨ activation space ä¸­è¡¨ç°ä¸ºå¯æå–ã€è¿‘ä¼¼æ­£äº¤çš„æ–¹å‘ï¼Œæ”¯æŒå‘é‡ä»£æ•°æ“ä½œã€‚
2. âœ… **æ— éœ€è®­ç»ƒå³å¯å®ç° fine-tuning çº§åˆ«æ€§èƒ½**ï¼šPERSONA-BASE åœ¨ PersonalityBench ä¸Šè¾¾åˆ° 9.60ï¼Œæ¥è¿‘ SFT ä¸Šé™ 9.61ã€‚
3. âœ… **æ”¯æŒåŠ¨æ€ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æ€§æ ¼æ§åˆ¶**ï¼šPERSONA-FLOW å¯æ ¹æ®å¯¹è¯å®æ—¶è°ƒæ•´æ€§æ ¼ï¼Œèƒœç‡è¾¾ 90.8%ã€‚
4. âœ… **æ€§æ ¼å¯ç»„åˆã€å¯æŠ‘åˆ¶**ï¼šé€šè¿‡å‘é‡åŠ å‡æ³•å¯å®ç°å¤æ‚æ€§æ ¼é…ç½®ï¼ˆå¦‚â€œæœ‰è´£ä»»å¿ƒä½†æ”¾æ¾â€ï¼‰ã€‚
5. âœ… **æ–¹æ³•é€šç”¨æ€§å¼º**ï¼šåœ¨ Qwenã€Llamaã€Mistral ç­‰å¤šç§æ¶æ„ä¸Šå‡æœ‰æ•ˆã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

1. **å®‰å…¨å¯¹é½çš„é™åˆ¶**ï¼š
   - æŸäº›ä¸å®‰å…¨è®­ç»ƒå†²çªçš„æ€§æ ¼ï¼ˆå¦‚ `self-interested`ï¼‰éš¾ä»¥æ¿€æ´»ã€‚
   - ä½†æŸäº›â€œçœ‹ä¼¼æ— å®³â€çš„æ€§æ ¼ï¼ˆå¦‚ `inventive`, `careless`ï¼‰å¯èƒ½æ„å¤–é™ä½å®‰å…¨æ€§ï¼ˆAttack Success Rate â†‘ï¼‰ã€‚
2. **éå®Œå…¨æ­£äº¤æ€§**ï¼š
   - æ€§æ ¼å‘é‡å¹¶éä¸¥æ ¼æ­£äº¤ï¼ˆå¦‚ `nervous` ä¸ `careless` æ­£ç›¸å…³ï¼‰ï¼Œå¯èƒ½å¯¼è‡´å‰¯ä½œç”¨ã€‚
   - ä½†å®éªŒè¯æ˜è¿™äº›å‰¯ä½œç”¨æ˜¯**å¯é¢„æµ‹ã€å¯ç»„åˆ**çš„ï¼Œä¸å½±å“æ•´ä½“æ§åˆ¶ã€‚
3. **ä¾èµ–é«˜è´¨é‡å‘é‡æå–**ï¼š
   - å‘é‡è´¨é‡å— generator LLM å½±å“ï¼Œå°æ¨¡å‹ç”Ÿæˆçš„ prompt æ•ˆæœç¨å¼±ï¼ˆä½†ä»ä¼˜äº baselineï¼‰ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **å¼€å‘å®‰å…¨æ„ŸçŸ¥çš„ personality steering**ï¼šåœ¨å¢å¼ºæ€§æ ¼è¡¨è¾¾çš„åŒæ—¶ï¼Œç¡®ä¿ alignment ä¸è¢«ç ´åã€‚
2. **æ¢ç´¢æ›´å¤šæ€§æ ¼ç»´åº¦**ï¼šæ‰©å±•è‡³ MBTIã€Dark Triad ç­‰é OCEAN æ¡†æ¶ã€‚
3. **å¤šæ¨¡æ€ personality æ§åˆ¶**ï¼šå°†å‘é‡ä»£æ•°æ‰©å±•è‡³å›¾åƒã€è¯­éŸ³ç­‰æ¨¡æ€ã€‚
4. **é•¿æœŸäººæ ¼ä¸€è‡´æ€§å»ºæ¨¡**ï¼šç ”ç©¶å¦‚ä½•åœ¨è¶…é•¿å¯¹è¯ä¸­ç»´æŒæ ¸å¿ƒäººæ ¼ä¸å˜ï¼ŒåŒæ—¶åŠ¨æ€è°ƒæ•´æƒ…ç»ªçŠ¶æ€ã€‚
5. **è‡ªåŠ¨åŒ–å‘é‡åº“æ„å»º**ï¼šå‡å°‘å¯¹äººå·¥è®¾è®¡ prompt çš„ä¾èµ–ï¼Œå®ç° fully automated personality vector extractionã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **PERSONA é¦–æ¬¡è¯æ˜äº† LLM çš„ personality åœ¨ activation space ä¸­å…·æœ‰å¯è§£é‡Šã€å¯ç»„åˆã€å¯åŠ¨æ€è°ƒæ§çš„ä»£æ•°ç»“æ„ï¼Œä¸ºé«˜æ•ˆã€çµæ´»ã€å¯æ§çš„äººæ ¼åŒ– AI æä¾›äº†å…¨æ–°èŒƒå¼ã€‚**

</details>

---

### 11. [TAROT: Test-driven and Capability-adaptive Curriculum Reinforcement Fine-tuning for Code Generation with Large Language Models](https://arxiv.org/abs/2602.15449)

**Authors**: Chansung Park, Juyong Jiang, Fan Wang, Sayak Paul, Jiasi Shen, Jing Tang, Jianguo Li  
**Category**: cs.CL  
**Published**: 2026-02-18  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.15449v1  

#### Abstract
Large Language Models (LLMs) are changing the coding paradigm, known as vibe coding, yet synthesizing algorithmically sophisticated and robust code still remains a critical challenge. Incentivizing the deep reasoning capabilities of LLMs is essential to overcoming this hurdle. Reinforcement Fine-Tun...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTAROT: Test-driven and Capability-adaptive Curriculum Reinforcement Fine-tuning for Code Generation with Large Language Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
ç°æœ‰çš„ **Reinforcement Fine-Tuning (RFT)** åœ¨ä»£ç ç”Ÿæˆä»»åŠ¡ä¸­é¢ä¸´ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼š
- **Reward flatness**ï¼ˆå¥–åŠ±å¹³å¦ï¼‰ï¼šä¼ ç»Ÿæ–¹æ³•å°†æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹çš„æˆåŠŸè§†ä¸ºåŒç­‰é‡è¦ï¼Œå¯¼è‡´ä¸åŒéš¾åº¦çº§åˆ«çš„åé¦ˆä¿¡å·è¶‹äºä¸€è‡´ï¼Œå‰Šå¼±äº†å­¦ä¹ ä¿¡å·çš„åŒºåˆ†åº¦ã€‚
- **Reward sparsity**ï¼ˆå¥–åŠ±ç¨€ç–ï¼‰ï¼šå½“æ¨¡å‹æ— æ³•é€šè¿‡ä»»ä½•æµ‹è¯•æ—¶ï¼Œç¼ºä¹ä¸­é—´æ¢¯åº¦ä¿¡å·ï¼Œè®­ç»ƒéš¾ä»¥æ¨è¿›ã€‚

æ­¤å¤–ï¼Œç°æœ‰ **Curriculum Learning (CL)** æ–¹æ³•å¤šåœ¨**è·¨é—®é¢˜çº§åˆ«**ï¼ˆinter-problemï¼‰è¿›è¡Œæ’åºï¼Œå¿½ç•¥äº†å•ä¸ªç¼–ç¨‹é—®é¢˜å†…éƒ¨çš„**ç»†ç²’åº¦éš¾åº¦æ¢¯åº¦**ï¼ˆintra-problem difficultyï¼‰ï¼Œä¸”è¯¾ç¨‹è®¾è®¡é€šå¸¸ä¸æ¨¡å‹èƒ½åŠ›è„±èŠ‚ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
è®ºæ–‡æå‡ºäº† **TAROT**ï¼ˆTest-driven and cApability-adaptive cuRriculum reinfOrcement fine-Tuningï¼‰ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **å››å±‚æµ‹è¯•å¥—ä»¶æ„å»º**ï¼ˆFour-tiered Test Suiteï¼‰ï¼š
  ä¸ºæ¯ä¸ªç¼–ç¨‹é—®é¢˜æ„é€ å››ä¸ªå±‚çº§çš„æµ‹è¯•ç”¨ä¾‹ï¼š
  - **Basic**ï¼šéªŒè¯åŸºç¡€é€»è¾‘å’Œâ€œå¿«ä¹è·¯å¾„â€ï¼ˆhappy pathï¼‰
  - **Intermediate**ï¼šä¸­ç­‰å¤æ‚è¾“å…¥ï¼ŒåŒ…å«å¸¸è§è¾¹ç•Œå€¼
  - **Complex**ï¼šç®—æ³•å¤æ‚æ€§é«˜ã€éœ€æ·±åº¦æ¨ç†çš„åœºæ™¯
  - **Edge**ï¼šæç«¯è¾¹ç•Œæ¡ä»¶ã€ç©ºè¾“å…¥ã€å¼‚å¸¸å¤„ç†ç­‰é²æ£’æ€§æµ‹è¯•

  è¿™ç§ç»“æ„åŒ–è®¾è®¡æ˜¾å¼å»ºæ¨¡äº† **intra-problem éš¾åº¦è°±ç³»**ï¼Œä¸ºè¯¾ç¨‹å­¦ä¹ æä¾›äº†ç²¾ç»†æ§åˆ¶çš„åŸºç¡€ã€‚

- **èƒ½åŠ›è‡ªé€‚åº”è¯¾ç¨‹æœºåˆ¶**ï¼ˆCapability-adaptive Curriculumï¼‰ï¼š
  - å°†è¯¾ç¨‹è¿›åº¦ï¼ˆcurriculum progressionï¼‰ä¸åŸå§‹å¥–åŠ±å¾—åˆ†è§£è€¦ã€‚
  - å¼•å…¥ **curriculum allocator** å’Œ **reward weights**ï¼Œå…è®¸æ ¹æ®ä¸åŒæ¨¡å‹çš„èƒ½åŠ›é¢„è®¾è®­ç»ƒé‡ç‚¹ã€‚
  - å®ç°â€œ**èƒ½åŠ›æ¡ä»¶åŒ–é€‰æ‹©**â€ï¼ˆcapability-conditioned selectionï¼‰ï¼šä»ä¸€ç»„é¢„å®šä¹‰çš„è¯¾ç¨‹ç­–ç•¥ä¸­é€‰æ‹©æœ€é€‚åˆå½“å‰æ¨¡å‹èƒ½åŠ›çš„æ–¹æ¡ˆã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´ç¨³å®šçš„å­¦ä¹ åŠ¨æ€**ï¼šé€šè¿‡åˆ†å±‚å¥–åŠ±ç¼“è§£äº† reward flatnessï¼Œæä¾›æ›´ä¸°å¯Œçš„æ¢¯åº¦ä¿¡å·ã€‚
- **æ›´é«˜çš„è®­ç»ƒæ•ˆç‡**ï¼šé’ˆå¯¹æ¨¡å‹èƒ½åŠ›å®šåˆ¶è¯¾ç¨‹ï¼Œé¿å…ä½èƒ½åŠ›æ¨¡å‹å› è¿‡æ—©æ¥è§¦éš¾é¢˜è€Œå´©æºƒï¼Œä¹Ÿé˜²æ­¢é«˜èƒ½åŠ›æ¨¡å‹é™·å…¥ç®€å•ä»»åŠ¡çš„å†—ä½™è®­ç»ƒã€‚
- **æ›´å¼ºçš„æ³›åŒ–æ€§å’Œé²æ£’æ€§**ï¼šåœ¨ OODï¼ˆout-of-distributionï¼‰åŸºå‡†ä¸Šè¡¨ç°æ›´ä¼˜ã€‚
- **å¯å¤ç°æ€§å¼º**ï¼šå…¬å¼€äº†å®Œæ•´çš„ **TAROT dataset** å’Œä»£ç ï¼ˆGitHub: [https://github.com/deep-diver/TAROT](https://github.com/deep-diver/TAROT)ï¼‰ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **TAROT dataset**ï¼šåŸºäºçº¦ 15k æ¡ Python ç¼–ç¨‹é¢è¯•é¢˜æ„å»ºï¼Œæ¯é“é¢˜é…å¤‡äººå·¥å®¡æ ¸çš„å››å±‚æµ‹è¯•å¥—ä»¶ï¼ˆå…± 60k æµ‹è¯•ç”¨ä¾‹ï¼‰ã€‚
- **æ¥æº**ï¼š`verifiable-coding-problems-python` æ•°æ®é›†ã€‚
- **ç”Ÿæˆæ–¹å¼**ï¼šä½¿ç”¨ OpenAI çš„ o3/o4 æ¨¡å‹ç”Ÿæˆå„å±‚çº§æµ‹è¯•ç”¨ä¾‹ï¼Œå¹¶é€šè¿‡å‚è€ƒç­”æ¡ˆä¸¥æ ¼éªŒè¯å…¶æ­£ç¡®æ€§ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹èŒƒå›´å¹¿æ³›**ï¼š
  - Qwen2.5 ç³»åˆ—ï¼ˆ1.5B, 3B, 7Bï¼‰åŠå…¶ä»£ç ä¸“ç”¨ç‰ˆæœ¬ Qwen2.5-Coder
  - Gemma2 ç³»åˆ—ï¼ˆ2B, 9Bï¼‰
  - æœ€æ–° Qwen3-4B-Instruct-2507
- **ä¼˜åŒ–ç®—æ³•**ï¼šå…¨éƒ¨é‡‡ç”¨ **GRPO**ï¼ˆGeneralized Reward Policy Optimizationï¼‰è¿›è¡Œ RFTã€‚
- **è®­ç»ƒç»†èŠ‚**ï¼š
  - å• epoch è®­ç»ƒ
  - Batch size = 8ï¼ˆå¤§æ¨¡å‹é™ä¸º 4ï¼‰
  - Max input/completion tokens = 1024 / 4096
  - Temperature = 1.0ï¼ˆä¸»å®éªŒï¼‰

### è¯„ä¼°æŒ‡æ ‡
- **åŠŸèƒ½æ­£ç¡®æ€§**ï¼š`pass@1` on HumanEval, MBPP, HumanEval+, MBPP+
- **ç«èµ›çº§è§£é¢˜èƒ½åŠ›**ï¼š`overall accuracy` on CodeForces, LiveCodeBench v5 (LCBv5)
- **ä»£ç æ¨ç†èƒ½åŠ›**ï¼š`input/output prediction accuracy` on CruxEval

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Avg-reward**ï¼šå¯¹å››å±‚æµ‹è¯•å–å¹³å‡é€šè¿‡ç‡ä½œä¸ºå¥–åŠ±
- **Pass@All**ï¼šä»…å½“æ‰€æœ‰å››å±‚æµ‹è¯•éƒ½é€šè¿‡æ—¶æ‰ç»™äºˆå¥–åŠ± 1ï¼Œå¦åˆ™ä¸º 0
- **æ— è¯¾ç¨‹è°ƒåº¦çš„æ ‡å‡† RL è®¾ç½®**

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æ¨¡å‹ | ç­–ç•¥ | HumanEval | MBPP | CruxEval (Input/Output) |
|------|-------|-----------|------|------------------------|
| Qwen2.5-1.5B-Instruct | TAROT (Best) | **60.98%** (+1.83pp) | **51.80%** (+2.60pp) | **40.20%/33.75%** |
| Qwen2.5-7B-Instruct | TAROT (Best) | **84.15%** (+0.40pp) | **69.00%** (+3.00pp) | **57.88%/59.38%** |
| Qwen3-4B-Instruct-2507 | C/E Weighted | **91.46%** (+2.44pp) | **55.20%** (+2.60pp) | **81.12%/75.25%** |

> æ³¨ï¼šæå‡å‡ç›¸å¯¹äºå„è‡ª base checkpointï¼Œä¸”åœ¨å·²æœ‰å¼º baseline ä¸Šå®ç°è¿›ä¸€æ­¥å¢ç›Šã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- TAROT åœ¨æ‰€æœ‰ benchmark ä¸Šå‡æ˜¾è‘—ä¼˜äºæ ‡å‡† RL åŸºçº¿ï¼ˆAvg-reward å’Œ Pass@Allï¼‰ï¼š
  - åœ¨ **Qwen2.5-7B-Instruct** ä¸Šï¼ŒTAROT åœ¨ HumanEval ä¸Šè¾¾åˆ° **84.15%**ï¼Œä¼˜äº Avg-reward çš„ 83.75% å’Œ Pass@All çš„ 81.10%ã€‚
  - åœ¨ **CodeForces** ä¸Šï¼ŒTAROT å°†æ€§èƒ½ä» 11.41% æå‡è‡³ **12.95%**ã€‚
- ç‰¹åˆ«æ˜¯åœ¨ **CruxEval** ç­‰é«˜é˜¶æ¨ç†ä»»åŠ¡ä¸Šä¼˜åŠ¿æ˜æ˜¾ï¼Œè¡¨æ˜ TAROT èƒ½æœ‰æ•ˆæå‡æ¨¡å‹æ·±å±‚ç†è§£èƒ½åŠ›ã€‚

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰è¯¾ç¨‹ç­–ç•¥æœ‰æ•ˆæ€§åˆ†æ
- **å°æ¨¡å‹ï¼ˆå¦‚ 1.5Bï¼‰**ï¼š`Basic Only` æˆ– `Forward (B&I Weighted)` è¡¨ç°æœ€ä½³ â†’ éœ€ä»åŸºç¡€å¼€å§‹å»ºç«‹ä¿¡å¿ƒã€‚
- **å¤§æ¨¡å‹ï¼ˆå¦‚ 7Bï¼‰**ï¼š`C/E Weighted` æˆ– `Complex Only` æ›´ä¼˜ â†’ å¯ç›´æ¥æŒ‘æˆ˜é«˜éš¾åº¦ä»»åŠ¡ä»¥æœ€å¤§åŒ–æ”¶ç›Šã€‚
- **ä»£ç ä¸“ç”¨æ¨¡å‹ï¼ˆå¦‚ Qwen2.5-Coder-3Bï¼‰**ï¼šè¡Œä¸ºç±»ä¼¼æ›´å¤§çš„é€šç”¨æ¨¡å‹ï¼ˆå¦‚ 7Bï¼‰ï¼Œè¯´æ˜ **prior specialization æ˜¾è‘—å½±å“ effective capability**ã€‚

#### ï¼ˆ2ï¼‰è¶…å‚æ•°æ•æ„Ÿæ€§
- **GRPO Î²**ï¼šæœ€ä¼˜å€¼ä»»åŠ¡ç›¸å…³ã€‚HumanEval åå¥½è¾ƒå° Î²=0.01ï¼ˆé¼“åŠ±æ¢ç´¢ï¼‰ï¼ŒMBPP åå¥½ Î²=0.05ï¼ˆåŠ å¼ºæ­£åˆ™åŒ–ï¼‰ã€‚
- **Temperature**ï¼šHumanEval åå¥½é«˜æ¸©ï¼ˆ1.0ï¼‰ä¿ƒè¿›å¤šæ ·æ€§æ¢ç´¢ï¼›MBPP åå¥½ä¸­æ¸©ï¼ˆ0.7ï¼‰å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨ã€‚
- **Max completion tokens**ï¼š
  - HumanEval ç±»ä»»åŠ¡åœ¨ 4096 tokens æ—¶æ€§èƒ½æœ€å¥½ï¼Œç»§ç»­å¢åŠ åè€Œä¸‹é™ï¼ˆå¯èƒ½ç”Ÿæˆå†—é•¿é”™è¯¯ä»£ç ï¼‰ã€‚
  - MBPP ç±»ä»»åŠ¡å—ç›Šäºæ›´å¤§ç”Ÿæˆç©ºé—´ï¼ˆ8192â€“16384 tokens æ•ˆæœæ›´ä½³ï¼‰ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **æœ€ä¼˜è¯¾ç¨‹ä¾èµ–äºæ¨¡å‹èƒ½åŠ›è€Œéå‚æ•°é‡æœ¬èº«**ï¼š
   - ä½èƒ½åŠ›æ¨¡å‹é€‚åˆ **easy-to-hard**ï¼ˆbasic â†’ complexï¼‰æ¸è¿›å¼å­¦ä¹ ã€‚
   - é«˜èƒ½åŠ›æˆ–ä»£ç ä¸“ç”¨æ¨¡å‹æ›´é€‚åˆ **hard-first**ï¼ˆcomplex â†’ basicï¼‰åå‘è¯¾ç¨‹ã€‚
   - å­˜åœ¨ä¸€ä¸ªâ€œ**Zone of Optimal Difficulty**â€ï¼Œå³æœ€æœ‰æ•ˆçš„è®­ç»ƒä¿¡å·åº”æ¥è‡ªç•¥é«˜äºå½“å‰èƒ½åŠ›çš„ä»»åŠ¡ã€‚

2. âœ… **è¯¾ç¨‹è®¾è®¡å¿…é¡»ä¸æ¨¡å‹èƒ½åŠ›åŒ¹é…**ï¼š
   - å¯¹å¼±æ¨¡å‹æ–½åŠ å¤æ‚è¯¾ç¨‹ä¼šå¯¼è‡´ **training collapse**ï¼ˆå¦‚ Gemma2-2B-IT å¤šæ•°è¯¾ç¨‹æœ‰å®³ï¼‰ã€‚
   - å¯¹å¼ºæ¨¡å‹é™åˆ¶åœ¨åŸºç¡€è¯¾ç¨‹ä¼šæµªè´¹å…¶æ½œåŠ›ã€‚

3. âœ… **TAROT çš„èƒ½åŠ›è‡ªé€‚åº”æœºåˆ¶èƒ½æŒç»­æå‡æ€§èƒ½**ï¼š
   - å³ä½¿åœ¨å·²å¾ˆå¼ºçš„æ¨¡å‹ï¼ˆå¦‚ Qwen3-4Bï¼‰ä¸Šä¹Ÿèƒ½å¸¦æ¥ **+2.12 ~ +4.26 pp** çš„æå‡ã€‚
   - æ”¯æŒè·¨æ¶æ„æ³›åŒ–ï¼ˆQwen â†’ Gemmaï¼‰ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **æ•°æ®ä¾èµ–æ€§å¼º**ï¼šTAROT dataset ç”±å‰æ²¿ LLMï¼ˆå¦‚ o4ï¼‰ç”Ÿæˆï¼Œå¯èƒ½å­˜åœ¨ç”Ÿæˆå™¨åå·®æˆ–è¦†ç›–ç›²åŒºã€‚
- **è¯­è¨€é™åˆ¶**ï¼šç›®å‰ä»…æ”¯æŒ Pythonï¼ŒæœªéªŒè¯å¤šè¯­è¨€æˆ–ä½èµ„æºè¯­è¨€ä¸‹çš„æ•ˆæœã€‚
- **é™æ€è¯¾ç¨‹é€‰æ‹©**ï¼šå½“å‰ç­–ç•¥ä»é¢„å®šä¹‰ç»„åˆä¸­é€‰æ‹©ï¼Œå°šæœªå®ç°è®­ç»ƒè¿‡ç¨‹ä¸­çš„åŠ¨æ€è°ƒæ•´ï¼ˆå¦‚ multi-armed banditï¼‰ã€‚
- **è®¡ç®—æˆæœ¬è¾ƒé«˜**ï¼šéœ€è¦é¢„å…ˆæ„å»ºé«˜è´¨é‡å››å±‚æµ‹è¯•é›†ï¼Œå¢åŠ äº†æ•°æ®å‡†å¤‡å¼€é”€ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ **continuous curriculum spaces** å’Œ **online adaptive scheduling**ï¼Œå®ç°åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´è¯¾ç¨‹ã€‚
- æ‰©å±•è‡³ **multilingual code generation** å’Œ **low-resource programming languages**ã€‚
- ç ”ç©¶ **automated test suite design** æ–¹æ³•ï¼Œå‡å°‘å¯¹äººå·¥æˆ–å¼º LLM çš„ä¾èµ–ã€‚
- ç»“åˆ **process reward modeling** æä¾›æ›´ç»†ç²’åº¦çš„ä¸­é—´åé¦ˆã€‚
- æ¢ç´¢ **task-specific curriculum policies**ï¼Œæ ¹æ®ä¸åŒä¸‹æ¸¸ä»»åŠ¡è‡ªåŠ¨é€‚é…è¯¾ç¨‹ç»“æ„ã€‚

--- 

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> TAROT é€šè¿‡å¼•å…¥**å››å±‚æµ‹è¯•é©±åŠ¨è¯¾ç¨‹**å’Œ**èƒ½åŠ›è‡ªé€‚åº”æœºåˆ¶**ï¼Œè§£å†³äº† RFT ä¸­ reward flatness å’Œè¯¾ç¨‹é”™é…çš„é—®é¢˜ï¼Œå®ç°äº†å¯¹ä¸åŒè§„æ¨¡å’Œä¸“é•¿çš„ LLM çš„é«˜æ•ˆã€ç¨³å®šå¼ºåŒ–å¾®è°ƒï¼Œæ˜¾è‘—æå‡äº†ä»£ç ç”Ÿæˆçš„åŠŸèƒ½æ­£ç¡®æ€§å’Œé²æ£’æ€§ã€‚

</details>

---

### 12. [FlashMem: Supporting Modern DNN Workloads on Mobile with GPU Memory Hierarchy Optimizations](https://arxiv.org/abs/2602.15379)

**Authors**: Zhihao Shu, Md Musfiqur Rahman Sanim, Hangyu Zheng, Kunxiong Zhu, Miao Yin, Gagan Agrawal, Wei Niu  
**Category**: cs.DC  
**Published**: 2026-02-18  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.15379v1  

#### Abstract
The increasing size and complexity of modern deep neural networks (DNNs) pose significant challenges for on-device inference on mobile GPUs, with limited memory and computational resources. Existing DNN acceleration frameworks primarily deploy a weight preloading strategy, where all model parameters...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šFlashMem: Supporting Modern DNN Workloads on Mobile with GPU Memory Hierarchy Optimizations**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
ç°ä»£æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰æ¨¡å‹æ—¥ç›Šå¢å¤§ä¸”å¤æ‚ï¼Œå¯¹ç§»åŠ¨è®¾å¤‡ä¸Šçš„**on-device inference**æå‡ºäº†ä¸¥å³»æŒ‘æˆ˜ã€‚å½“å‰ä¸»æµçš„ DNN æ¨ç†æ¡†æ¶ï¼ˆå¦‚ MNNã€TVMã€LiteRT ç­‰ï¼‰æ™®éé‡‡ç”¨ **weight preloading** ç­–ç•¥ï¼Œå³å°†æ•´ä¸ªæ¨¡å‹æƒé‡ä¸€æ¬¡æ€§åŠ è½½åˆ°å†…å­˜ä¸­å†æ‰§è¡Œæ¨ç†ã€‚è¿™ç§ç­–ç•¥å¯¼è‡´ï¼š
- **å³°å€¼å†…å­˜æ¶ˆè€—é«˜**ï¼Œéš¾ä»¥æ”¯æŒå¤§æ¨¡å‹æˆ–å¤šæ¨¡å‹å¹¶å‘è¿è¡Œï¼›
- **åˆå§‹åŒ–å»¶è¿Ÿé•¿**ï¼Œå°¤å…¶æ˜¯æ¶‰åŠä»ç£ç›˜åŠ è½½å¹¶è½¬æ¢ä¸º GPU texture memory æ ¼å¼æ—¶ï¼›
- **GPU å†…å­˜å±‚çº§åˆ©ç”¨ä½æ•ˆ**ï¼Œæœªå……åˆ†åˆ©ç”¨ mobile GPU çš„ 2.5D texture memory ç‰¹æ€§ã€‚

æ­¤å¤–ï¼Œåœ¨å¤šæ¨¡å‹æµæ°´çº¿åœºæ™¯ï¼ˆå¦‚ FIFO è°ƒåº¦ï¼‰ä¸‹ï¼Œé‡å¤çš„åŠ è½½ä¸æ ¼å¼è½¬æ¢å¼€é”€è¿›ä¸€æ­¥åŠ å‰§æ€§èƒ½ç“¶é¢ˆã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹**
æœ¬æ–‡æå‡º **FlashMem** â€”â€” ä¸€ç§åŸºäº GPU å†…å­˜å±‚çº§ä¼˜åŒ–çš„å†…å­˜æµå¼å¤„ç†æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯**åŠ¨æ€æŒ‰éœ€æµå¼åŠ è½½æƒé‡**ï¼Œè€Œéå…¨é‡é¢„åŠ è½½ã€‚ä¸»è¦è´¡çŒ®å¦‚ä¸‹ï¼š

#### âœ… **1. ä¼˜åŒ–é‡å è®¡åˆ’ç”Ÿæˆï¼ˆOptimized Overlap Plan Generation, OPGï¼‰**
- å°† weight loading ä¸ computation çš„è°ƒåº¦å½¢å¼åŒ–ä¸ºä¸€ä¸ª **Constraint Programming Satisfiability (CP-SAT)** é—®é¢˜ï¼›
- è®¾è®¡äº†ä¸€ä¸ª **Load Capacity-aware OPG-Solver (LC-OPG)**ï¼Œé™æ€ç”Ÿæˆæœ€ä¼˜çš„æƒé‡åŠ è½½æ—¶é—´è¡¨ï¼Œæœ€å°åŒ–å³°å€¼å†…å­˜å¹¶ä¿è¯é«˜æ•ˆæ‰§è¡Œã€‚

#### âœ… **2. è‡ªé€‚åº”èåˆæœºåˆ¶ï¼ˆAdaptive Fusionï¼‰**
- åˆ†æä¸åŒ operator ç±»å‹ï¼ˆElementalã€Reusableã€Hierarchicalï¼‰çš„è®¡ç®—å¼ºåº¦ä¸è´Ÿè½½å®¹å¿èƒ½åŠ›ï¼›
- åŠ¨æ€å†³å®šæ˜¯å¦æ‹†åˆ† fused operatorsï¼Œä»¥å¹³è¡¡ **memoryã€compute å’Œ load capacity**ï¼Œé¿å…è¿‡åº¦èåˆé™åˆ¶è°ƒåº¦çµæ´»æ€§ã€‚

#### âœ… **3. å±‚çº§ GPU å†…å­˜ä¼˜åŒ–ï¼ˆHierarchical GPU Memory Optimizationï¼‰**
- åˆ©ç”¨ **2.5D texture memory** ç»“æ„ï¼Œé‡æ„æƒé‡å¸ƒå±€ä»¥æå‡ç¼“å­˜æ•ˆç‡ï¼›
- å‡å°‘ä¸å¿…è¦çš„ layout transformation å¼€é”€ï¼ˆå¦‚ transposeã€reshapeï¼‰ï¼Œç›´æ¥åœ¨çº¹ç†å†…å­˜ä¸­è¿›è¡Œé«˜æ•ˆè®¿é—®ã€‚

#### âœ… **4. æµæ°´çº¿æ„ŸçŸ¥å†…æ ¸æ‰§è¡Œï¼ˆPipeline-Aware Kernel Executionï¼‰**
- æ”¹å†™ GPU kernelï¼Œå®ç° **branch-freeã€pipelined æ‰§è¡Œæ¨¡å¼**ï¼›
- åœ¨æ¯ä¸ªè¿­ä»£ä¸­äº¤æ›¿æ‰§è¡Œâ€œé¢„å–ä¸‹ä¸€æƒé‡å—â€ä¸â€œè®¡ç®—å½“å‰æ•°æ®â€ï¼Œæœ‰æ•ˆéšè—å†…å­˜å»¶è¿Ÿã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | FlashMem | ä¼ ç»Ÿæ¡†æ¶ï¼ˆMNN, TVM, SmartMem ç­‰ï¼‰ |
|------|--------|-------------------------------|
| **å†…å­˜ç®¡ç†** | åŠ¨æ€æµå¼åŠ è½½ï¼Œä»…ä¿ç•™å¿…è¦æƒé‡ | å…¨é‡é¢„åŠ è½½ï¼Œå³°å€¼å†…å­˜é«˜ |
| **æ‰§è¡Œæ•ˆç‡** | é‡å åŠ è½½ä¸è®¡ç®—ï¼Œå‡å°‘ç©ºé—²å‘¨æœŸ | åŠ è½½ä¸æ‰§è¡Œä¸²è¡Œï¼Œåˆå§‹åŒ–å»¶è¿Ÿå¤§ |
| **GPU åˆ©ç”¨ç‡** | é’ˆå¯¹ 2.5D texture memory ä¼˜åŒ– | å¿½è§† texture memory ç‰¹æ€§ |
| **å¤šæ¨¡å‹æ”¯æŒ** | æ”¯æŒå¤šæ¨¡å‹ FIFO æµæ°´çº¿ | å¤šæ•°æ— æ³•æ”¯æŒå¤§æ¨¡å‹å…±å­˜ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ¨¡å‹ä¸ä»»åŠ¡**
åœ¨ **11 ä¸ªä»£è¡¨æ€§ DNN æ¨¡å‹**ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œæ¶µç›–å¤šç§åº”ç”¨åœºæ™¯ï¼š

| æ¨¡å‹ç±»åˆ« | ç¤ºä¾‹æ¨¡å‹ | å‚æ•°é‡çº§ |
|---------|----------|--------|
| NLP | GPTNeo-S, GPTNeo-1.3B, GPTNeo-2.7B | æœ€é«˜è¾¾ 2.7B |
| å›¾åƒåˆ†ç±» | ResNet50, ViT, DeepViT | 25Mâ€“204M |
| å›¾åƒç”Ÿæˆ | StableDiffusion-UNet (SD-UNet) | 860M |
| è¯­éŸ³è¯†åˆ« | Whisper-Medium | 356M |
| è§†é¢‘åˆ†å‰² | DepthAnything-S/L | 24Mâ€“333M |
| å›¾åƒåˆ†å‰² | SAM-2 | 215M |

> æ•°æ®é›†æ¥æºåŒ…æ‹¬ ImageNetã€LibriSpeechã€LAION-5Bã€The Pile ç­‰ã€‚

---

### **å®éªŒå¹³å°**
- **ä¸»æµ‹è¯•è®¾å¤‡**ï¼šOnePlus 12ï¼ˆAdreno 750 GPU, 16GB RAMï¼‰
- **è·¨è®¾å¤‡éªŒè¯**ï¼šOnePlus 11ã€Xiaomi Mi 6ã€Google Pixel 8
- **ç²¾åº¦é…ç½®**ï¼šFP16 / FP32ï¼Œbatch size = 1
- **è°ƒä¼˜å¯ç”¨**ï¼šæ‰€æœ‰ baseline å‡å¼€å¯ auto-tuning

---

### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **End-to-end Latency** | åˆå§‹åŒ– + æ¨ç†æ€»è€—æ—¶ï¼ˆFlashMem å°†ä¸¤è€…é›†æˆï¼‰ |
| **Average Memory Usage** | è¿è¡ŒæœŸé—´å¹³å‡å†…å­˜å ç”¨ |
| **Peak Memory** | å³°å€¼å†…å­˜æ¶ˆè€— |
| **Speedup** | ç›¸å¯¹äº baseline çš„åŠ é€Ÿæ¯” |
| **Memory Reduction** | å†…å­˜ä½¿ç”¨é™ä½å€æ•° |
| **Energy Consumption** | åŠŸè€— Ã— æ—¶é—´ï¼ˆç„¦è€³ï¼‰ |
| **Portability** | åœ¨ä¸åŒç¡¬ä»¶ä¸Šçš„å…¼å®¹æ€§ä¸æ€§èƒ½ä¸€è‡´æ€§ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **å•†ä¸šçº§æ¡†æ¶**ï¼šMNNã€NCNNã€TVMã€LiteRTï¼ˆTFLiteï¼‰ã€ExecuTorchï¼ˆETorchï¼‰
- **ç ”ç©¶åŸå‹**ï¼šSmartMemï¼ˆå‰åºå·¥ä½œï¼ŒåŒå›¢é˜Ÿï¼‰
- **ä¸åŒ…å«**ï¼šllama.cppã€FlexNN ç­‰å› ä¸æ”¯æŒ mobile GPU æˆ–ç‰¹å®šæ¨¡å‹è¢«æ’é™¤

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»**

#### ğŸ“Š **ç«¯åˆ°ç«¯å»¶è¿Ÿå¯¹æ¯”ï¼ˆTable 7ï¼‰**
- FlashMem å®ç° **1.7Ã— ~ 75.0Ã— çš„æ•´ä½“åŠ é€Ÿ**ï¼›
- ç›¸è¾ƒäº **ExecuTorch** å¹³å‡å¿« **75.0Ã—**ï¼›
- ç›¸è¾ƒäº **SmartMem** å¹³å‡å¿« **8.6Ã—**ï¼›
- å¯¹å¤§æ¨¡å‹ä¼˜åŠ¿æ˜¾è‘—ï¼š
  - **GPTNeo-1.3B**ï¼šæ¯” SmartMem å¿« **15.8Ã—**
  - **SD-UNet**ï¼šå¿« **9.3Ã—**
  - **DeepViT**ï¼šå¿« **10.0Ã—**

> âš ï¸ æ³¨æ„ï¼šéƒ¨åˆ†æ¡†æ¶ï¼ˆå¦‚ NCNNï¼‰ç”šè‡³æ— æ³•è¿è¡Œ Transformer ç±»å¤§æ¨¡å‹ã€‚

#### ğŸ“‰ **å†…å­˜æ¶ˆè€—å¯¹æ¯”ï¼ˆTable 8ï¼‰**
- å¹³å‡å†…å­˜å‡å°‘ **2.0Ã— ~ 8.4Ã—**ï¼›
- ç›¸æ¯” SmartMemï¼Œå¹³å‡èŠ‚çœ **3.5Ã—** å†…å­˜ï¼›
- å…·ä½“æ¡ˆä¾‹ï¼š
  - **Whisper-Medium**ï¼šä» 1,433MB â†’ **240MB**ï¼ˆ**6.0Ã—** ä¸‹é™ï¼‰
  - **DeepViT**ï¼šä» 826MB â†’ **165MB**ï¼ˆ**5.0Ã—** ä¸‹é™ï¼‰
  - **GPTNeo-1.3B**ï¼šä» 2,667MB â†’ **554MB**ï¼ˆ**4.8Ã—** ä¸‹é™ï¼‰

#### ğŸ”‹ **åŠŸè€—ä¸èƒ½è€—ï¼ˆTable 9ï¼‰**
| æ¨¡å‹ | FlashMem èƒ½è€— | ç›¸æ¯” SmartMem èŠ‚èƒ½ |
|------|----------------|--------------------|
| DeepViT | 4.5J | â†“ **89%** |
| SD-UNet | 17.9J | â†“ **87%** |

å°½ç®¡åŠŸè€—ç•¥é«˜ï¼ˆå› æ›´é«˜ GPU åˆ©ç”¨ç‡ï¼‰ï¼Œä½†ç”±äº**æä½å»¶è¿Ÿ**ï¼Œæ€»ä½“èƒ½é‡å¤§å¹…ä¸‹é™ã€‚

#### ğŸ§ª **æ¶ˆèå®éªŒåˆ†æï¼ˆFigure 7ï¼‰**
åˆ†è§£å„ç»„ä»¶è´¡çŒ®ï¼ˆä»¥ SmartMem ä¸ºåŸºçº¿ï¼‰ï¼š

| ç»„ä»¶ | é€Ÿåº¦æå‡èŒƒå›´ | å†…å­˜ç¼©å‡èŒƒå›´ |
|------|-------------|--------------|
| **OPG-Solver** | 5.3Ã— ~ 8.1Ã— | 2.1Ã— ~ 3.8Ã— |
| **Adaptive Fusion** | 1.5Ã— ~ 5.1Ã— | 1.1Ã— ~ 1.4Ã— |
| **Kernel Rewriting** | 1.0Ã— ~ 2.55Ã— | 1.0Ã— ~ 1.1Ã— |

> è¡¨æ˜ **OPG-Solver æ˜¯æœ€å¤§è´¡çŒ®è€…**ï¼Œè€Œ kernel rewriting æ›´ä¾§é‡äºå»¶è¿Ÿä¼˜åŒ–ã€‚

#### ğŸ”„ **ä¸å…¶ä»–é‡å ç­–ç•¥å¯¹æ¯”ï¼ˆFigure 9ï¼‰**
- **Always-Next Loading**ï¼šæœ€å¤šæ…¢ **4.3Ã—**
- **Same-Op-Type Prefetching**ï¼šæœ€å¤šæ…¢ **2.4Ã—**
- è¯´æ˜ FlashMem çš„ **ç»†ç²’åº¦ã€å®¹é‡æ„ŸçŸ¥è°ƒåº¦ç­–ç•¥æ›´ä¼˜**

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. âœ… **åŠ¨æ€æµå¼åŠ è½½å¯æ˜¾è‘—é™ä½å†…å­˜å‹åŠ›**ï¼šé€šè¿‡æŒ‰éœ€åŠ è½½è€Œéé¢„åŠ è½½ï¼ŒFlashMem æˆåŠŸåœ¨èµ„æºå—é™çš„ç§»åŠ¨è®¾å¤‡ä¸Šè¿è¡Œäº† **GPTNeo-2.7B** ç­‰æ­¤å‰æ— æ³•æ”¯æŒçš„å¤§æ¨¡å‹ã€‚
2. âœ… **é‡å  weight loading ä¸ computation å¯å¤§å¹…æå‡æ•ˆç‡**ï¼šåˆç†è°ƒåº¦å¯åœ¨ä¸å¢åŠ å»¶è¿Ÿçš„å‰æä¸‹å¤§å¹…å‰Šå‡å†…å­˜ã€‚
3. âœ… **2.5D texture memory æ˜¯ mobile GPU æ€§èƒ½å…³é”®**ï¼šé’ˆå¯¹æ€§ä¼˜åŒ– layout transformation å’Œ kernel æ‰§è¡Œè·¯å¾„ï¼Œèƒ½æœ‰æ•ˆæå‡ååã€‚
4. âœ… **operator fusion éœ€æƒè¡¡ memory ä¸ load capacity**ï¼šè¿‡åº¦èåˆä¼šå‰Šå¼±è°ƒåº¦çµæ´»æ€§ï¼Œåº”æ ¹æ® operator ç±»å‹åŠ¨æ€è°ƒæ•´ã€‚
5. âœ… **FlashMem å…·å¤‡è‰¯å¥½å¯ç§»æ¤æ€§**ï¼šåœ¨ä¸åŒ GPU æ¶æ„ï¼ˆAdreno / Maliï¼‰å’Œå†…å­˜é…ç½®ä¸‹å‡è¡¨ç°ç¨³å®šï¼Œå°¤å…¶åœ¨ä½å†…å­˜è®¾å¤‡ä¸Šæ›´å…·ä¼˜åŠ¿ï¼ˆFigure 10ï¼‰ã€‚

---

### **å±€é™æ€§**
1. â— **ç¦»çº¿æ±‚è§£å™¨å­˜åœ¨éçº¿æ€§æ—¶é—´å¢é•¿**ï¼šéšç€æ¨¡å‹è§„æ¨¡å¢å¤§ï¼ˆå¦‚ Llama2-70Bï¼‰ï¼ŒCP-SAT æ±‚è§£æ—¶é—´æ¥è¿‘ä¸Šé™ï¼ˆ150ç§’ï¼‰ï¼Œå¯èƒ½å½±å“éƒ¨ç½²çµæ´»æ€§ï¼›
2. â— **ç›®å‰ä»…æ”¯æŒé™æ€ DNN å›¾**ï¼šå¯¹ dynamic neural networksï¼ˆå¦‚æ¡ä»¶åˆ†æ”¯æ¨¡å‹ï¼‰å°šæœªé€‚é…ï¼›
3. â— **ä¾èµ– profiled load capacity æ•°æ®**ï¼šè™½ä½¿ç”¨ XGBoost é¢„æµ‹ï¼Œä½†ä»éœ€è½»é‡çº§ profiling é˜¶æ®µï¼›
4. â— **æœªè€ƒè™‘ CPU-GPU ååŒè°ƒåº¦**ï¼šèšç„¦ GPU memory hierarchyï¼Œæœªæ·±å…¥æ¢è®¨å¼‚æ„å¤„ç†å™¨é—´çš„ä»»åŠ¡åˆ’åˆ†ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. â• æ‰©å±•è‡³ **datacenter åœºæ™¯**ï¼šå°†è¯¥æ–¹æ³•åº”ç”¨äºæœåŠ¡å™¨ç«¯å¤§è§„æ¨¡ LLM æ¨ç†ï¼›
2. â• æ”¯æŒ **dynamic execution paths**ï¼šå¼€å‘é€‚ç”¨äºåŠ¨æ€å›¾æ¨¡å‹çš„åœ¨çº¿è°ƒåº¦æœºåˆ¶ï¼›
3. â• æ¢ç´¢ **quantized model æ”¯æŒ**ï¼šç»“åˆ INT8/INT4 æ¨ç†è¿›ä¸€æ­¥å‹ç¼©å†…å­˜ï¼›
4. â• ç ”ç©¶ **memory-energy trade-off çš„è‡ªåŠ¨è°ƒèŠ‚æœºåˆ¶**ï¼šå®ç°åŠ¨æ€å‚æ•°è°ƒä¼˜ä»¥é€‚åº”ä¸åŒåº”ç”¨åœºæ™¯ï¼ˆä½å»¶è¿Ÿ vs ä½åŠŸè€—ï¼‰ï¼›
5. â• å¼•å…¥ **hardware-software co-design**ï¼šé’ˆå¯¹ç‰¹å®š mobile GPU æ¶æ„å®šåˆ¶æ›´ç²¾ç»†çš„å†…å­˜è°ƒåº¦ç­–ç•¥ã€‚

---

> ğŸ’¡ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **FlashMem é€šè¿‡é™æ€è§„åˆ’ + åŠ¨æ€æµå¼åŠ è½½ + GPU å†…å­˜å±‚çº§ååŒä¼˜åŒ–ï¼Œåœ¨ç§»åŠ¨ç«¯å®ç°äº†å¤§æ¨¡å‹ä¸å¤šæ¨¡å‹é«˜æ•ˆå…±å­˜ï¼Œçªç ´äº†ä¼ ç»Ÿé¢„åŠ è½½èŒƒå¼çš„å†…å­˜ä¸æ€§èƒ½ç“¶é¢ˆã€‚**

</details>

---

### 13. [Learning Data-Efficient and Generalizable Neural Operators via Fundamental Physics Knowledge](https://arxiv.org/abs/2602.15184)

**Authors**: Siying Ma, Mehrdad M. Zadeh, Mauricio Soroco, Wuyang Chen, Jiguo Cao, Vijay Ganesh  
**Category**: cs.LG  
**Published**: 2026-02-18  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.15184v1  

#### Abstract
Recent advances in scientific machine learning (SciML) have enabled neural operators (NOs) to serve as powerful surrogates for modeling the dynamic evolution of physical systems governed by partial differential equations (PDEs). While existing approaches focus primarily on learning simulations from ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLearning Data-Efficient and Generalizable Neural Operators via Fundamental Physics Knowledge

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰åŸºäºæ•°æ®é©±åŠ¨çš„ **Neural Operators (NOs)** åœ¨å­¦ä¹ ç‰©ç†ç³»ç»ŸåŠ¨æ€æ¼”åŒ–æ—¶å­˜åœ¨ä¸‰å¤§æŒ‘æˆ˜ï¼š
1. **é«˜æ•°æ®éœ€æ±‚**ï¼šç¼ºä¹ç‰©ç†å…ˆéªŒï¼Œéœ€è¦å¤§é‡å¤šæ ·åŒ–è®­ç»ƒæ•°æ®æ‰èƒ½è¾¾åˆ°é«˜ç²¾åº¦ã€‚
2. **ç‰©ç†ä¸ä¸€è‡´æ€§**ï¼šå¯èƒ½è¿åå®ˆæ’å¾‹æˆ–äº§ç”Ÿéç‰©ç†è§£ï¼Œå°¤å…¶åœ¨é•¿æœŸrollouté¢„æµ‹ä¸­ã€‚
3. **æ³›åŒ–èƒ½åŠ›å·®**ï¼šå¯¹æœªè§è¿‡çš„ç‰©ç†å‚æ•°è®¾ç½®ï¼ˆout-of-distribution, OODï¼‰æˆ–ä»ä»¿çœŸåˆ°çœŸå®åœºæ™¯ï¼ˆsynthetic-to-realï¼‰è¿ç§»è¡¨ç°ä¸ä½³ã€‚

è¿™äº›é—®é¢˜æºäºæ¨¡å‹ä»…ä»ç›®æ ‡PDEå­¦ä¹ ï¼Œè€Œå¿½ç•¥äº†æ›´åŸºç¡€çš„ç‰©ç†åŸç†ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡ºä¸€ç§**å¤šç‰©ç†è”åˆè®­ç»ƒæ¡†æ¶ï¼ˆmultiphysics training frameworkï¼‰**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> **æ˜¾å¼åœ°å°†åŸºæœ¬ç‰©ç†çŸ¥è¯†ï¼ˆfundamental physics knowledgeï¼‰èå…¥ç¥ç»ç®—å­çš„å­¦ä¹ è¿‡ç¨‹**ã€‚

å…·ä½“åšæ³•ï¼š
- **åˆ†è§£åŸå§‹PDE**ä¸ºç®€åŒ–çš„â€œåŸºæœ¬å½¢å¼â€ï¼ˆbasic formsï¼‰ï¼Œè¿™äº›å½¢å¼ä¿ç•™ä¸»å¯¼ç‰©ç†æœºåˆ¶ä½†è®¡ç®—æˆæœ¬æ›´ä½ã€‚
  - ä¾‹å¦‚ï¼šNavier-Stokesæ–¹ç¨‹ä¸­ä¿ç•™å¯¹æµé¡¹ `- (uÂ·âˆ‡)u`ï¼Œå¿½ç•¥å‹åŠ›å’Œæ‰©æ•£é¡¹ã€‚
  - Diffusion-Reactionä¸­ä¿ç•™æ‰©æ•£é¡¹ï¼Œå»é™¤éçº¿æ€§ååº”é¡¹ã€‚
- **è”åˆè®­ç»ƒ**ï¼šåŒæ—¶åœ¨åŸå§‹PDEæ¨¡æ‹Ÿæ•°æ®å’Œå…¶ç®€åŒ–çš„åŸºæœ¬å½¢å¼ä¸Šè¿›è¡Œè®­ç»ƒã€‚
- åˆ©ç”¨åŸºæœ¬å½¢å¼ä½œä¸º**è¾…åŠ©ä»»åŠ¡ï¼ˆauxiliary taskï¼‰**ï¼Œæå‡ä¸»ä»»åŠ¡ï¼ˆåŸå§‹PDEå»ºæ¨¡ï¼‰çš„æ•°æ®æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚

è¯¥æ–¹æ³•æ˜¯**æ¶æ„æ— å…³çš„ï¼ˆarchitecture-agnosticï¼‰**ï¼Œé€‚ç”¨äºFNOã€Transformerç­‰å¤šç§NOæ¶æ„ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | æœ¬æ–‡æ–¹æ³• |
|------|--------|---------|
| æ•°æ®æ¥æº | å•ä¸€PDEæˆ–è·¨å¤šç§PDEé¢„è®­ç»ƒï¼ˆå¦‚SciML foundation modelsï¼‰ | åŒä¸€PDEä¸å…¶åŸºæœ¬ç‰©ç†å½¢å¼è”åˆè®­ç»ƒ |
| ç‰©ç†å½’çº³åç½® | å¼±æˆ–æ—  | æ˜¾å¼å¼•å…¥åŸºæœ¬ç‰©ç†æœºåˆ¶ |
| è®­ç»ƒæˆæœ¬ | é«˜ï¼ˆä¾èµ–æ˜‚è´µå…¨æ¨¡æ‹Ÿï¼‰ | æ›´ä½ï¼ˆå¯â€œäº¤æ¢â€éƒ¨åˆ†æ˜‚è´µæ¨¡æ‹Ÿä¸ºå»‰ä»·åŸºæœ¬å½¢å¼ï¼‰ |
| æ³›åŒ–æ€§ | å¯¹OODæ•æ„Ÿ | æ˜¾è‘—å¢å¼ºOODä¸real-worldæ³›åŒ– |

> ğŸ’¡ å…³é”®æ´å¯Ÿï¼šæ¯”èµ·ç®€å•èšåˆä¸åŒPDEï¼ˆå¦‚foundation modelsï¼‰ï¼Œ**ç†è§£ä¸€ä¸ªå¤æ‚PDEå†…éƒ¨çš„åŸºç¡€ç»„ä»¶æ›´ä¸ºæ ¹æœ¬ä¸”æœ‰æ•ˆ**ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†ä¸PDEç³»ç»Ÿ
ç ”ç©¶æ¶µç›–å¤šä¸ªç»å…¸æ—¶é—´ä¾èµ–å‹PDEï¼Œåœ¨1D/2D/3Dç©ºé—´ä¸­æµ‹è¯•ï¼ŒåŒ…æ‹¬ï¼š
- **Diffusion-Reaction (2D)**ï¼šæ¨¡æ‹Ÿæ¿€æ´»-æŠ‘åˆ¶ç³»ç»Ÿçš„å›¾çµæ¨¡å¼å½¢æˆã€‚
- **Incompressible Navier-Stokes (2D & 3D)**ï¼šæµä½“åŠ¨åŠ›å­¦ï¼Œç”¨äºé€Ÿåº¦åœº/å¯†åº¦åœºå»ºæ¨¡ã€‚
- **Kuramoto-Sivashinsky (1D)**ï¼šæè¿°æ—¶ç©ºæ··æ²Œè¡Œä¸ºã€‚
- **ScalarFlow (real-world 3D)**ï¼šçœŸå®çƒŸé›¾æµåŠ¨é‡å»ºæ•°æ®é›†ï¼Œç”¨äºè¯„ä¼° synthetic-to-real è½¬ç§»ã€‚

æ‰€æœ‰æ•°æ®é€šè¿‡æ•°å€¼æ±‚è§£å™¨ç”Ÿæˆï¼ˆå¦‚PhiFlow, PyClawï¼‰ï¼Œå¹¶æ§åˆ¶åˆ†è¾¨ç‡ä¸æ—¶é—´æ­¥é•¿ä»¥ä¿è¯å…¬å¹³æ¯”è¾ƒã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### âœ… è¯„ä¼°æŒ‡æ ‡
- **nRMSE**ï¼ˆNormalized Root Mean Squared Errorï¼‰ï¼šä¸»è¦è¯„ä»·æŒ‡æ ‡ã€‚
- Autoregressive rolloutè¯¯å·®ï¼šè¡¡é‡é•¿æœŸé¢„æµ‹ç¨³å®šæ€§ã€‚
- OOD generalizationï¼šåœ¨è®­ç»ƒåˆ†å¸ƒå¤–çš„ç‰©ç†å‚æ•°ä¸‹æµ‹è¯•æ€§èƒ½ã€‚
- Synthetic-to-real transferï¼šåœ¨çœŸå®ä¸–ç•Œæ•°æ®ï¼ˆScalarFlowï¼‰ä¸Šçš„è¡¨ç°ã€‚

#### âœ… åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline**ï¼šä»…åœ¨åŸå§‹PDEä¸Šè®­ç»ƒç¥ç»ç®—å­ã€‚
- **Ours**ï¼šè”åˆè®­ç»ƒåŸå§‹PDE + å…¶åŸºæœ¬å½¢å¼ï¼ˆæŒ‰â€œæ ·æœ¬æ··åˆæ¯”ä¾‹â€Sample Mixture Ratioè°ƒæ•´é¢„ç®—ï¼‰ã€‚
- å…¶ä»–å¯¹æ¯”æ–¹æ³•ï¼ˆæ¶ˆèå®éªŒä¸­ï¼‰ï¼š
  - Spatiotemporal Downsampling
  - Lie Symmetry Augmentation
  - ä¸åŒåŸºæœ¬é¡¹é€‰æ‹©ï¼ˆå¦‚åªä¿ç•™reactionè€Œédiffusionï¼‰

#### âœ… è®­ç»ƒç­–ç•¥
- å¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶ï¼šå…±äº«éª¨å¹²ç½‘ç»œï¼Œæœ€åä¸€å±‚åˆ†ç¦»è¾“å‡ºã€‚
- æŸå¤±å‡½æ•°åŠ æƒï¼š`Loss = Loss_full + 0.7 Ã— Loss_basic`
- æ§åˆ¶æ€»æ¨¡æ‹Ÿæˆæœ¬ä¸€è‡´ï¼šåˆ©ç”¨åŸºæœ¬å½¢å¼è®¡ç®—ä¾¿å®œçš„ç‰¹ç‚¹ï¼Œâ€œèŠ‚çœâ€çš„é¢„ç®—ç”¨äºå¢åŠ é‡‡æ ·æ•°é‡ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ªTable 2 & Figure 5â€“7ï¼‰

| PDE | æ–¹æ³• | In-Dist nRMSE | OOD Target 1 | OOD Target 2 |
|-----|------|----------------|-------------|--------------|
| **2D Diffusion-Reaction** | Baseline | 0.0289 | 0.0413 (Î²=1) | 0.0770 (Î²=100) |
| | **Ours** | **0.0231** | **0.0331** | **0.0538** |
| **2D Navier-Stokes** | Baseline | 0.0487 | 0.0825 (Î½=0.05) | 0.0369 (Î½=0.0001) |
| | **Ours** | **0.0175** | **0.0222** | **0.0125** |
| **3D Navier-Stokes** | Baseline | 0.0675 | 0.0393 (Î½=0.1) | 0.0836 (Î½=0.0001) |
| | **Ours** | **0.0481** | **0.0329** | **0.0602** |

> âœ… æ‰€æœ‰æƒ…å†µä¸‹ï¼Œ**Ourså‡æ˜¾è‘—ä¼˜äºBaseline**ï¼Œå°¤å…¶åœ¨OODåœºæ™¯ä¸‹è¯¯å·®é™ä½é«˜è¾¾ **60%ä»¥ä¸Š**ã€‚

---

### ğŸ“ˆ æ•°æ®æ•ˆç‡æå‡ï¼ˆFigure 5ï¼‰
- åœ¨ç›¸åŒæˆ–æ›´ä½æ¨¡æ‹Ÿæˆæœ¬ä¸‹ï¼Œ**Oursåœ¨å·¦ä¸‹æ–¹åŒºåŸŸ**ï¼ˆæ›´ä½è¯¯å·® + æ›´ä½æˆæœ¬ï¼‰ï¼Œè¡¨æ˜æ›´å¼ºçš„æ•°æ®æ•ˆç‡ã€‚
- ä¾‹å¦‚åœ¨2D Diffusion-Reactionä¸­ï¼Œè¾¾åˆ°ç›¸åŒnRMSEæ‰€éœ€æ¨¡æ‹Ÿæˆæœ¬å‡å°‘çº¦ **50%**ã€‚

---

### ğŸ” é•¿æœŸä¸€è‡´æ€§ï¼ˆAutoregressive Rollout, Figure 6ï¼‰
- åœ¨5æ­¥è‡ªå›å½’rolloutä¸­ï¼Œ**Oursçš„è¯¯å·®ç´¯ç§¯æ˜æ˜¾æ›´æ…¢**ã€‚
- è¡¨æ˜æ¨¡å‹å­¦åˆ°çš„åŠ¨æ€æ›´å…·ç‰©ç†åˆç†æ€§ï¼Œé¿å…â€œæ¼‚ç§»â€æˆ–å‘æ•£ã€‚

---

### ğŸŒ Synthetic-to-Real æ³›åŒ–ï¼ˆFigure 7ï¼‰
- åœ¨çœŸå®çƒŸé›¾æ•°æ®é›† **ScalarFlow** ä¸Šæµ‹è¯•ï¼š
  - Baseline: nRMSE = 0.250
  - **Ours**: nRMSE = **0.213**
- è§†è§‰ä¸Šï¼ŒOursèƒ½æ›´å¥½æ•æ‰çƒŸç¾½ç»“æ„ä¸è¿åŠ¨è¶‹åŠ¿ï¼Œè¯æ˜æ›´å¼ºçš„ç°å®è¿ç§»èƒ½åŠ›ã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰åŸºæœ¬é¡¹çš„é€‰æ‹©è‡³å…³é‡è¦ï¼ˆFigure 14ï¼‰
| åˆ†è§£æ–¹å¼ | PDE | æ•ˆæœ |
|--------|-----|------|
| æ­£ç¡®åŸºæœ¬é¡¹ï¼ˆå¦‚Diffusionï¼‰ | Diffusion-Reaction | nRMSE â†“ 11%-24% |
| é”™è¯¯åŸºæœ¬é¡¹ï¼ˆå¦‚Reaction onlyï¼‰ | Diffusion-Reaction | nRMSE â†‘ æœ€å¤šè¾¾64% |
| æ­£ç¡®åŸºæœ¬é¡¹ï¼ˆAdvectionï¼‰ | Navier-Stokes | æ€§èƒ½å¤§å¹…æå‡ |
| é”™è¯¯åŸºæœ¬é¡¹ï¼ˆDiffusion onlyï¼‰ | Navier-Stokes | nRMSE â†‘ 13%-179% |

> âœ… ç»“è®ºï¼š**æ”¹è¿›æ¥æºäºé€‰æ‹©äº†æ­£ç¡®çš„ã€å…·æœ‰ä¸°å¯Œç‰©ç†æ„ä¹‰çš„åŸºæœ¬é¡¹**ï¼Œä¸æ˜¯ä»»æ„ç®€åŒ–éƒ½èƒ½å¸¦æ¥æ”¶ç›Šã€‚

#### ï¼ˆ2ï¼‰ä¸å…¶ä»–å¢å¼ºæ–¹æ³•æ­£äº¤ï¼ˆFigure 17ï¼‰
- å°†æœ¬æ–¹æ³•ä¸ **Lie Symmetry Augmentation** ç»“åˆï¼š
  - å•ç‹¬ä½¿ç”¨Lieï¼šè½»å¾®æå‡
  - å•ç‹¬ä½¿ç”¨Oursï¼šå¤§å¹…æ”¹è¿›
  - è”åˆä½¿ç”¨ï¼šè¿›ä¸€æ­¥å°å¹…å¢ç›Š
> â• è¯´æ˜è¯¥æ–¹æ³•ä¸å…¶ä»–æ•°æ®å¢å¼ºæŠ€æœ¯**äº’è¡¥ä¸”æ­£äº¤**ã€‚

#### ï¼ˆ3ï¼‰è¶…å‚æ•°é²æ£’æ€§ï¼ˆTable 8ï¼‰
- è¾…åŠ©æŸå¤±æƒé‡ `Î» âˆˆ {0.5, 0.7, 1.0}` å½±å“æå°ï¼ˆæœ€å¤§åå·® < 0.0063ï¼‰
> âœ… æ–¹æ³•å¯¹è¶…å‚æ•°ä¸æ•æ„Ÿï¼Œæ˜“äºéƒ¨ç½²ã€‚

#### ï¼ˆ4ï¼‰æ‰©å±•è‡³å¤§æ¨¡å‹ï¼ˆFigure 16ï¼‰
- åº”ç”¨äº **DPOTï¼ˆHao et al., 2024ï¼‰** è¿™ç±»å¤§è§„æ¨¡SciML foundation modelï¼š
  - ä»èƒ½æŒç»­æå‡æ•°æ®æ•ˆç‡
> âœ… è¯æ˜è¯¥ç­–ç•¥ä¸ä»…é€‚ç”¨äºå°æ¨¡å‹ï¼Œä¹Ÿèƒ½ä¸ºå·²æœ‰å¼ºå¤§é¢„è®­ç»ƒæ¨¡å‹æä¾›é¢å¤–å¢ç›Šã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **ç¥ç»ç®—å­å¯ä»¥ä¸”åº”å½“ç†è§£PDEçš„åŸºæœ¬ç‰©ç†æˆåˆ†**ï¼š
   - å®éªŒè¯æ˜ï¼Œå…¬å¼€çš„SciML foundation modelsè™½ç„¶éšå¼å­¦ä¹ äº†ä¸€äº›åŸºç¡€é¡¹ï¼Œä½†å¹¶æœªå……åˆ†æŒæ¡ã€‚
   - æ˜¾å¼åŠ å…¥åŸºæœ¬å½¢å¼è®­ç»ƒå¯æ˜¾è‘—å¼¥è¡¥è¿™ä¸€å·®è·ã€‚

2. **åŸºæœ¬ç‰©ç†çŸ¥è¯†æ˜¯ä¸€ç§é«˜æ•ˆçš„æ•°æ®å¢å¼ºæ‰‹æ®µ**ï¼š
   - åŸºæœ¬å½¢å¼æ¨¡æ‹Ÿæˆæœ¬è¿œä½äºå®Œæ•´PDEï¼ˆè§Table 1ï¼ŒSample Mixture Ratioè¾¾1:24ï¼‰ã€‚
   - å¯â€œç”¨å»‰ä»·æ•°æ®æ¢é«˜æ€§èƒ½â€ï¼Œå®ç°**æ›´é«˜æ€§ä»·æ¯”çš„è®­ç»ƒ**ã€‚

3. **è¯¥æ–¹æ³•å¸¦æ¥ä¸‰é‡å¥½å¤„**ï¼š
   - **æ•°æ®æ•ˆç‡æå‡**ï¼šæ›´å°‘æ¨¡æ‹Ÿå³å¯è¾¾åˆ°æ›´é«˜ç²¾åº¦ã€‚
   - **é•¿æœŸç‰©ç†ä¸€è‡´æ€§å¢å¼º**ï¼šrolloutæ›´ç¨³å®šï¼Œç¬¦åˆç‰©ç†è§„å¾‹ã€‚
   - **å¼ºOODä¸real-worldæ³›åŒ–èƒ½åŠ›**ï¼šé€‚åº”æœªçŸ¥å‚æ•°ä¸çœŸå®è§‚æµ‹ã€‚

4. **é€šç”¨æ€§å¼ºã€æ˜“é›†æˆ**ï¼š
   - ä¸ä¾èµ–ç‰¹å®šNOæ¶æ„ï¼ˆFNOã€Transformerå‡æœ‰æ•ˆï¼‰ã€‚
   - å¯ä¸å…¶ä»–æŠ€æœ¯ï¼ˆdownsampling, symmetry augmentationï¼‰ç»“åˆä½¿ç”¨ã€‚

---

### âš ï¸ å±€é™æ€§
1. **éœ€è¦é¢†åŸŸçŸ¥è¯†æ¥å®šä¹‰â€œåŸºæœ¬å½¢å¼â€**ï¼š
   - å½“å‰æ–¹æ³•ä¾èµ–äººå·¥åˆ†æPDEç»“æ„ä»¥ç¡®å®šåº”ä¿ç•™å“ªä¸€é¡¹ï¼ˆå¦‚å¯¹æµ vs æ‰©æ•£ï¼‰ã€‚
   - è‡ªåŠ¨è¯†åˆ«æœ€ä¼˜åˆ†è§£ä»æ˜¯å¼€æ”¾é—®é¢˜ã€‚

2. **å¹¶éæ‰€æœ‰PDEéƒ½å®¹æ˜“åˆ†è§£**ï¼š
   - å¯¹é«˜åº¦è€¦åˆæˆ–éæ ‡å‡†å½¢å¼çš„PDEï¼Œå¦‚ä½•æå–æœ‰æ„ä¹‰çš„åŸºæœ¬é¡¹å°šéœ€æ¢ç´¢ã€‚

3. **ç›®å‰é›†ä¸­åœ¨ç†æƒ³åŒ–ä»¿çœŸç¯å¢ƒ**ï¼š
   - å°½ç®¡å·²æµ‹è¯•ScalarFlowï¼Œä½†åœ¨æ›´å¤šçœŸå®å¤æ‚åœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§æœ‰å¾…éªŒè¯ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **è‡ªåŠ¨åŒ–åŸºæœ¬é¡¹å‘ç°æœºåˆ¶**ï¼š
   - åˆ©ç”¨ç¬¦å·å›å½’ã€ç¨€ç–è¯†åˆ«ï¼ˆSINDyï¼‰ã€æˆ–å…ƒå­¦ä¹ è‡ªåŠ¨æå–ä¸»å¯¼ç‰©ç†é¡¹ã€‚

2. **æ„å»ºâ€œåŸºç¡€ç‰©ç†è¯å…¸â€**ï¼š
   - å®šä¹‰å¸¸è§PDEçš„æ ‡å‡†åŸºæœ¬å½¢å¼åº“ï¼Œä¾›ç¤¾åŒºå¤ç”¨ã€‚

3. **æ‰©å±•è‡³å…¶ä»–ç§‘å­¦é¢†åŸŸ**ï¼š
   - å¦‚é‡å­åŠ›å­¦ã€ç”µç£å­¦ã€ç”Ÿç‰©åŠ›å­¦ç­‰ï¼Œæ¢ç´¢æ˜¯å¦æ™®éå­˜åœ¨ç±»ä¼¼â€œåŸºæœ¬é¡¹ä¼˜å…ˆâ€çš„å­¦ä¹ èŒƒå¼ã€‚

4. **ä¸PINNsç»“åˆ**ï¼š
   - å°†åŸºæœ¬å½¢å¼çº³å…¥lossè®¾è®¡ï¼Œå½¢æˆ hybrid ç‰©ç†çº¦æŸ + å¤šç‰©ç†è®­ç»ƒæ¡†æ¶ã€‚

---

> ğŸ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> æœ¬æ–‡æ­ç¤ºäº†ä¸€ä¸ªæ·±åˆ»æ´è§â€”â€”**æœ€å¥½çš„ç§‘å­¦æœºå™¨å­¦ä¹ æ¨¡å‹ä¸ä»…è¦å­¦ä¼šâ€œåšä»€ä¹ˆâ€ï¼Œæ›´è¦æ‡‚å¾—â€œä¸ºä»€ä¹ˆâ€**ã€‚é€šè¿‡è®©ç¥ç»ç®—å­æ˜¾å¼å­¦ä¹ PDEèƒŒåçš„**fundamental physics knowledge**ï¼Œæˆ‘ä»¬ä¸ä»…èƒ½åšå¾—æ›´å¿«ï¼ˆdata-efficientï¼‰ï¼Œæ›´èƒ½åšå¾—æ›´å‡†ã€æ›´ç¨³ã€æ›´æ³›åŒ–ã€‚

</details>

---

### 14. [1-Bit Wonder: Improving QAT Performance in the Low-Bit Regime through K-Means Quantization](https://arxiv.org/abs/2602.15563)

**Authors**: Sohir Maskey, Constantin Eichenberg, Johannes Messner, Douglas Orr  
**Category**: cs.LG  
**Published**: 2026-02-18  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.15563v1  

#### Abstract
Quantization-aware training (QAT) is an effective method to drastically reduce the memory footprint of LLMs while keeping performance degradation at an acceptable level. However, the optimal choice of quantization format and bit-width presents a challenge in practice. The full design space of quanti...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**1-Bit Wonder: Improving QAT Performance in the Low-Bit Regime through K-Means Quantization**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰åœ¨ **Quantization-Aware Training (QAT)** ä¸­ï¼Œå°¤å…¶æ˜¯åœ¨æä½æ¯”ç‰¹ï¼ˆå¦‚ 1-bitï¼‰é‡åŒ–åœºæ™¯ä¸‹ï¼Œå­˜åœ¨ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **ç²¾åº¦-å®¹é‡æƒè¡¡ä¸æ˜ç¡®**ï¼šåœ¨å›ºå®šæ¨ç†å†…å­˜é¢„ç®—ä¸‹ï¼Œå¦‚ä½•åœ¨æ¨¡å‹å‚æ•°é‡ $N$ å’Œæƒé‡ç²¾åº¦ $P$ ä¹‹é—´è¿›è¡Œæœ€ä¼˜åˆ†é…å°šæ— ç³»ç»Ÿç ”ç©¶ã€‚
- **ä¸»æµæ•´æ•°é‡åŒ–æ ¼å¼æ€§èƒ½å—é™**ï¼šå¯¹ç§°çš„ uniform integer é‡åŒ–åœ¨æä½æ¯”ç‰¹ä¸‹è¡¨ç°ä¸ä½³ï¼Œä¸”ä¼˜åŒ–ä¸ç¨³å®šï¼ˆå¦‚ 1-bit æ—¶æ˜“å‡ºç° NaNï¼‰ã€‚
- **è¯„ä¼°æ–¹å¼åå·®**ï¼šè®¸å¤šç ”ç©¶ä¾èµ– perplexity æˆ–è®­ç»ƒæŸå¤±ä½œä¸ºè¯„ä¼°æŒ‡æ ‡ï¼Œæ— æ³•çœŸå®åæ˜ ç”Ÿæˆä»»åŠ¡ä¸Šçš„æ€§èƒ½é€€åŒ–ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
1. **å¼•å…¥åŸºäº k-means çš„éçº¿æ€§é‡åŒ–æ ¼å¼ï¼ˆk-means quantizationï¼‰**
   - ä¸å†ä½¿ç”¨å‡åŒ€åˆ’åˆ†çš„é‡åŒ–åŒºé—´ï¼Œè€Œæ˜¯é€šè¿‡ **1D k-means èšç±»**å­¦ä¹ é€‚åº”æƒé‡åˆ†å¸ƒçš„éå‡åŒ€è´¨å¿ƒï¼ˆcentroidsï¼‰ã€‚
   - åœ¨ block-wise è®¾ç½®ä¸­åº”ç”¨è¯¥ç­–ç•¥ï¼Œæ¯ä¸ª block ä½¿ç”¨å…±äº« scale å‚æ•°å’Œ learned centroidsã€‚
   - æ”¯æŒé«˜æ•ˆå®ç°ï¼šåˆ©ç”¨ **vector lookup tables (LUT)** åœ¨æ ‡å‡†ç¡¬ä»¶ä¸Šå®ç°å¿«é€Ÿè§£ç ã€‚

2. **æå‡ºâ€œç²¾åº¦æ„ŸçŸ¥ç¼©æ”¾å¾‹â€ï¼ˆprecision-aware scaling lawsï¼‰**
   - å°†é‡åŒ–ä½å®½ $P$ æ˜¾å¼å»ºæ¨¡ä¸ºå½±å“æ¨¡å‹æœ‰æ•ˆå®¹é‡çš„å› ç´ ï¼š  
     $$
     N_{\text{eff}} = N \cdot f(P), \quad f(P) = 1 - \exp(-P/\gamma_w)
     $$
   - åˆ©ç”¨æ­¤æ¨¡å‹åˆ†æåœ¨å›ºå®šå†…å­˜é¢„ç®— $M = N \cdot P$ ä¸‹çš„æœ€ä½³ç²¾åº¦é€‰æ‹©ã€‚

3. **å€¡å¯¼â€œä»¥æœ€ä½ç¨³å®šç²¾åº¦æ¢å–æ›´å¤§å‚æ•°é‡â€çš„è®¾è®¡èŒƒå¼**
   - å®éªŒè¯æ˜ï¼Œåœ¨ç›¸åŒå†…å­˜é¢„ç®—ä¸‹ï¼Œ**1-bit + æ›´å¤§æ¨¡å‹**ä¼˜äºé«˜ç²¾åº¦å°æ¨¡å‹ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | æœ¬æ–‡æ–¹æ³•ï¼ˆk-means QATï¼‰ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆuniform integer QAT / PTQï¼‰ |
|------|------------------------|-------------------------------|
| æä½æ¯”ç‰¹ç¨³å®šæ€§ | âœ… 1-bit ç¨³å®šè®­ç»ƒï¼Œæ— éœ€ç‰¹æ®Šå½’ä¸€åŒ–æŠ€å·§ | âŒ 1-bit æ˜“å´©æºƒï¼Œéœ€ mean-shift ç­‰ hack |
| é‡å»ºè¯¯å·® | âœ… æœ€å°åŒ– L2 é‡æ„è¯¯å·®ï¼ˆç†è®ºæœ€ä¼˜ï¼‰ | âš ï¸ éæœ€ä¼˜ï¼Œå°¤å…¶å¯¹éå‡åŒ€åˆ†å¸ƒ |
| æ€§èƒ½ä¸Šé™ | âœ… åœ¨ç›¸åŒå†…å­˜ä¸‹è¾¾åˆ°æ›´é«˜ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ | âš ï¸ å—é™äºæ ¼å¼è¡¨è¾¾èƒ½åŠ› |
| æ¨ç†æ•ˆç‡ | âœ… æ”¯æŒè½¯ä»¶ kernel åŠ é€Ÿï¼ˆå¦‚ Triton LUTï¼‰ | âš ï¸ å¤šæ•°ä¾èµ–åŸç”Ÿç¡¬ä»¶æ”¯æŒ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **é¢„è®­ç»ƒæ•°æ®**ï¼š
  - **Nemotron-CC**ï¼šè¿‡æ»¤åçš„ Common Crawl å­é›†ï¼Œç”¨äº scaling law å®éªŒã€‚
  - **æ··åˆé«˜è´¨é‡æ•°æ®**ï¼ˆlong-horizon curriculumï¼‰ï¼š
    - Web data: Nemotron-CC
    - Code: Starcoder-V2
    - Math: FineMath-3+/4+
- **SFT æ•°æ®**ï¼šTulu 3 SFT Mixtureï¼ˆæŒ‡ä»¤å¾®è°ƒï¼‰
- **è¯„ä¼°åŸºå‡†**ï¼šæ¶µç›–å¸¸è¯†ã€æ¨ç†ã€ä»£ç ã€æ•°å­¦ç­‰å¤šç»´åº¦ä»»åŠ¡ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
| ç»„ä»¶ | é…ç½® |
|------|------|
| æ¨¡å‹æ¶æ„ | Llama 3-style Decoder-only Transformer |
| ä¸Šä¸‹æ–‡é•¿åº¦ | 4096ï¼ˆé¢„è®­ç»ƒï¼‰ï¼Œ8192ï¼ˆSFTï¼‰ |
| Token æ•°é‡ | 150Bï¼ˆä¸»å®éªŒï¼‰ï¼›scaling law å®éªŒè¦†ç›– 8â€“50B |
| QAT ç­–ç•¥ | Warm-up 1000 æ­¥åå¼€å¯é‡åŒ–ï¼Œcentroids å†»ç»“ |
| Block Size | 64ï¼ˆæ‰€æœ‰ block-wise é‡åŒ–ï¼‰ |
| Scale å­˜å‚¨ | 16-bit float per blockï¼ˆå¢åŠ  0.25 bits/weight å¼€é”€ï¼‰ |
| ç¡¬ä»¶ | NVIDIA H100ï¼ˆè®­ç»ƒï¼‰ï¼ŒL40Sï¼ˆæ¨ç† benchmarkï¼‰ |

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
| ç±»å‹ | æŒ‡æ ‡ |
|------|------|
| é¢„è®­ç»ƒé˜¶æ®µ | Pretraining lossï¼ˆlogprob-basedï¼‰ |
| ä¸‹æ¸¸ç”Ÿæˆä»»åŠ¡ | Accuracy / Pass@1 onï¼š<br>â€¢ MMLU, HellaSwag, PIQA, ARC<br>â€¢ HumanEval, MBPPï¼ˆcode genï¼‰<br>â€¢ GSM8Kï¼ˆmath reasoningï¼‰<br>â€¢ MMLU-PRO, AidanBenchï¼ˆé«˜çº§æ¨ç†ï¼‰ |
| æ¨ç†æ•ˆç‡ | Tokens/sï¼ˆautoregressive generationï¼‰<br>Effective bandwidthï¼ˆGB/sï¼‰ |

### ğŸ” åŸºçº¿å¯¹æ¯”
| æ¨¡å‹ | å‚æ•°é‡ | æƒé‡ç²¾åº¦ | å†…å­˜å ç”¨ï¼ˆâ‰ˆï¼‰ |
|------|--------|----------|-------------|
| Baseline | 4B | bf16 (16-bit) | 7.8 GB |
| å¯¹ç…§ç»„1 | 12B | 4-bit uniform | â‰ˆ7.8 GB |
| å¯¹ç…§ç»„2 | 31B | 1-bit k-means | â‰ˆ7.8 GB |

> æ‰€æœ‰æ¨¡å‹å‡ä¿æŒ embedding å’Œ output head ä¸º bf16ï¼Œä»… backbone æƒé‡é‡åŒ–ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰

| Benchmark | 4B / 16-bit | 12B / 4-bit | **31B / 1-bit** |
|---------|------------|------------|----------------|
| **MMLU** | 33.21 | 50.86 | **51.61** |
| **ARC-C** | 41.21 | 49.15 | **50.68** |
| **MBPP** | 19.00 | 26.40 | **30.00** |
| **HumanEval** | 12.80 | 15.24 | **18.29** |
| **GSM8K (5-shot)** | 27.90 | **48.52** | 45.26 |
| **AidanBench** | 88.08 | 147.48 | **167.83** |

> âœ… **31B 1-bit æ¨¡å‹åœ¨ç»å¤§å¤šæ•°ä»»åŠ¡ä¸Šè¶…è¶Š 12B 4-bit å’Œ 4B 16-bit æ¨¡å‹**

### ğŸ” ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ
- **k-means vs uniform é‡åŒ–ï¼ˆscaling law åˆ†æï¼‰**
  - k-means åœ¨æ‰€æœ‰ bit-width ä¸‹å‡ä¼˜äº uniform integerã€‚
  - å·®è·åœ¨ **P â‰¤ 4.25 bits** æ—¶æœ€æ˜¾è‘—ã€‚
  - å½’å› äºæ›´é«˜çš„ `g(P) = f(P)/P`ï¼Œå³å•ä½å†…å­˜çš„æœ‰æ•ˆå®¹é‡æ›´é«˜ã€‚
- **ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½**
  - å³ä½¿æ˜¯ 1.25-bitï¼ˆå« scale overheadï¼‰çš„æç«¯å‹ç¼©ï¼Œä»èƒ½å®ç°æ›´å¼ºçš„ç”Ÿæˆèƒ½åŠ›ã€‚
  - è¡¨æ˜ **loss-based è¯„ä¼°ä¸èƒ½å‡†ç¡®é¢„æµ‹ç”Ÿæˆæ€§èƒ½**ï¼ˆå›¾5æ˜¾ç¤º 12B 4-bit é¢„è®­ç»ƒ loss æ›´ä¼˜ï¼Œä½†æœ€ç»ˆç”Ÿæˆæ€§èƒ½ç•¥é€Šäº 31B 1-bitï¼‰ã€‚

### ğŸ” æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰Normalization ç­–ç•¥ï¼ˆAppendix A.6ï¼‰
| é‡åŒ–æ–¹å¼ | æœ€ä½³ normalization |
|--------|------------------|
| Uniform 2-bit | absmeanï¼ˆé¿å…å¤šæ•°å€¼å½’é›¶ï¼‰ |
| Uniform â‰¥3-bit | absmax |
| **k-means** | **å¯¹ normalization ä¸æ•æ„Ÿ** âœ… |

> è¡¨æ˜ k-means æ›´é²æ£’ï¼Œç®€åŒ–äº†å·¥ç¨‹è°ƒå‚ã€‚

#### ï¼ˆ2ï¼‰QAT å¯åŠ¨æ—¶æœº
- å›ºå®šä»ç¬¬ 1000 æ­¥å¼€å§‹å¯ç”¨ QATï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚
- æ—©èµ· QAT å¯¼è‡´è®­ç»ƒä¸ç¨³å®šï¼Œå°¤å…¶å¯¹ k-means èšç±»åˆå§‹åŒ–ä¸åˆ©ã€‚

#### ï¼ˆ3ï¼‰Kernel æ•ˆç‡æµ‹è¯•ï¼ˆTable 6 & 7ï¼‰
| Format | Speedup (vs bf16) | Effective BW |
|-------|--------------------|--------------|
| 4.25-bit (Triton) | 3.7Ã— | 721 GB/s |
| **1.25-bit (Triton)** | **7.6Ã—** | **438 GB/s** |

> è™½æœªè¾¾ç†è®ºå³°å€¼ï¼ˆ12.8Ã—ï¼‰ï¼Œä½†åœ¨å®é™… kernel ä¸­å·²å®ç°æ˜¾è‘—åŠ é€Ÿã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **åœ¨å›ºå®šæ¨ç†å†…å­˜é¢„ç®—ä¸‹ï¼Œæœ€ä½³ç­–ç•¥æ˜¯é‡‡ç”¨å°½å¯èƒ½ä½çš„ç¨³å®šç²¾åº¦ï¼Œå¹¶å°†èŠ‚çœçš„å†…å­˜ç”¨äºæ‰©å±•æ¨¡å‹è§„æ¨¡**ã€‚
   - å³ï¼š**push toward 1-bit regime and scale up N**ã€‚
2. **k-means éçº¿æ€§é‡åŒ–æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„ uniform integer é‡åŒ–**ï¼Œç‰¹åˆ«æ˜¯åœ¨ â‰¤4-bit åœºæ™¯ã€‚
   - æä¾›æ›´ä¼˜çš„ L2 é‡å»ºè¯¯å·®ä¸è®­ç»ƒç¨³å®šæ€§ã€‚
3. **å³ä½¿æ˜¯ 1-bit æ¨¡å‹ä¹Ÿèƒ½é€šè¿‡ QAT å®ç°å¼ºå¤§çš„ä¸‹æ¸¸ç”Ÿæˆèƒ½åŠ›**ã€‚
   - 31B 1-bit æ¨¡å‹åœ¨å¤šæ•°ä»»åŠ¡ä¸Šè¶…è¿‡ 12B 4-bit å’ŒåŸå§‹ 4B 16-bit æ¨¡å‹ã€‚
4. **ç°æœ‰çš„ loss-based è¯„ä¼°ä¸¥é‡é«˜ä¼°ä½æ¯”ç‰¹æ¨¡å‹çš„çœŸå®æ€§èƒ½**ã€‚
   - å¿…é¡»ç»“åˆ generative downstream benchmarks è¿›è¡Œç»¼åˆè¯„ä¼°ã€‚

### âš ï¸ å±€é™æ€§
- **ç¼ºä¹ä¸“ç”¨ç¡¬ä»¶æ”¯æŒ**ï¼šå½“å‰ä¾èµ– custom Triton kernels å’Œ lookup tablesï¼Œæœªå‘æŒ¥æè‡´æ½œåŠ›ã€‚
- **å¤§ batch æ¨ç†ä¼˜åŠ¿æ¶ˆå¤±**ï¼šå½“ batch size å¢å¤§æ—¶ï¼Œè®¡ç®—ç“¶é¢ˆå–ä»£å†…å­˜ç“¶é¢ˆï¼Œé‡åŒ–å¢ç›Šå‡å¼±ï¼ˆè§ Figure 3 & 9ï¼‰ã€‚
- **ä»…é‡åŒ– backbone**ï¼šembedding å’Œ output head ä¿ç•™ bf16ï¼Œé™åˆ¶äº†ç«¯åˆ°ç«¯å‹ç¼©ç‡ã€‚
- **æœªæ¢ç´¢å…¶ä»–éçº¿æ€§æ ¼å¼**ï¼šå¦‚çŸ¢é‡é‡åŒ–ï¼ˆVQï¼‰ã€æ··åˆç²¾åº¦æ‹“æ‰‘ç­‰ä»æœ‰ç©ºé—´ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **å¼€å‘æ”¯æŒéçº¿æ€§é‡åŒ–çš„ä¸“ç”¨ ASIC/FPGA æ¶æ„**ï¼Œè¿›ä¸€æ­¥é‡Šæ”¾ 1-bit æ¨¡å‹æ½œåŠ›ã€‚
2. **æ¢ç´¢åŠ¨æ€è‡ªé€‚åº” centroids**ï¼šå…è®¸ centroids åœ¨è®­ç»ƒä¸­æŒç»­æ›´æ–°è€Œéå†»ç»“ã€‚
3. **æ‰©å±•è‡³ MoE æ¶æ„ä¸­çš„ expert æƒé‡é‡åŒ–**ï¼Œæå‡ç¨€ç–æ¨¡å‹çš„éƒ¨ç½²æ•ˆç‡ã€‚
4. **ç ”ç©¶ activation quantization ä¸ weight quantization çš„è”åˆä¼˜åŒ–**ï¼Œè¿ˆå‘å…¨æ¨¡å‹è¶…ä½ä½å®½è®­ç»ƒã€‚
5. **æ„å»ºé¢å‘ ultra-low-bit æ¨¡å‹çš„æ ‡å‡†è¯„ä¼°å¥—ä»¶**ï¼Œæ¨åŠ¨ç¤¾åŒºå…³æ³¨çœŸå®ç”Ÿæˆèƒ½åŠ›è€Œéä»… perplexityã€‚

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> æœ¬è®ºæ–‡è¯æ˜äº† **â€œ1-bit + k-means + QATâ€ æ˜¯ä¸€æ¡é€šå¾€æè‡´é«˜æ•ˆ LLM æ¨ç†çš„æ–°è·¯å¾„**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³â€”â€”**ç‰ºç‰²ç²¾åº¦æ¢å–è§„æ¨¡ï¼Œåœ¨å†…å­˜çº¦æŸä¸‹æœ€å¤§åŒ–æœ‰æ•ˆå®¹é‡**â€”â€”æœ‰æœ›é‡å¡‘æœªæ¥è½»é‡åŒ–å¤§æ¨¡å‹çš„è®¾è®¡èŒƒå¼ã€‚

</details>

---

### 15. [Neural Network-Based Parameter Estimation of a Labour Market Agent-Based Model](https://arxiv.org/abs/2602.15572)

**Authors**: M Lopes Alves, Joel Dyer, Doyne Farmer, Michael Wooldridge, Anisoara Calinescu  
**Category**: cs.LG  
**Published**: 2026-02-18  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.15572v1  

#### Abstract
Agent-based modelling (ABM) is a widespread approach to simulate complex systems. Advancements in computational processing and storage have facilitated the adoption of ABMs across many fields; however, ABMs face challenges that limit their use as decision-support tools. A significant issue is parame...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šNeural Network-Based Parameter Estimation of a Labour Market Agent-Based Model**

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
- **ABM å‚æ•°ä¼°è®¡çš„æŒ‘æˆ˜**ï¼šAgent-Based Models (ABMs) åœ¨æ¨¡æ‹Ÿå¤æ‚ç³»ç»Ÿï¼ˆå¦‚åŠ³åŠ¨åŠ›å¸‚åœºï¼‰æ—¶å…·æœ‰å¼ºå¤§èƒ½åŠ›ï¼Œä½†å…¶å‚æ•°ç©ºé—´é«˜ç»´ã€è®¡ç®—æˆæœ¬é«˜æ˜‚ä¸”è¾“å‡ºå…·æœ‰éšæœºæ€§ï¼Œå¯¼è‡´ä¼ ç»Ÿå‚æ•°ä¼°è®¡æ–¹æ³•ï¼ˆå¦‚ SSEã€CMA-ESï¼‰éš¾ä»¥æœ‰æ•ˆæ¢ç´¢å‚æ•°ç©ºé—´ã€‚
- **ä¸ç¡®å®šæ€§é‡åŒ–ä¸è¶³**ï¼šç°æœ‰æ–¹æ³•å¤šæä¾›ç‚¹ä¼°è®¡ï¼Œç¼ºä¹å¯¹å‚æ•°ä¸ç¡®å®šæ€§çš„å»ºæ¨¡ï¼Œé™åˆ¶äº† ABM ä½œä¸ºå†³ç­–æ”¯æŒå·¥å…·çš„åº”ç”¨ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
- å¼•å…¥å¹¶è¯„ä¼°äº† **SBI4ABM** æ¡†æ¶â€”â€”ä¸€ä¸ªåŸºäºç¥ç»ç½‘ç»œçš„ Simulation-Based Inference (SBI) å·¥å…·ï¼Œä¸“é—¨ç”¨äºé«˜ç»´ ABM çš„å‚æ•°ä¼°è®¡ã€‚
- åˆ©ç”¨ **Neural Posterior Estimation (NPE)** å’Œ **Normalizing Flows (MAF)** æ„å»ºå…¨å±€åéªŒå¯†åº¦ä¼°è®¡å™¨ï¼Œå®ç° amortizationï¼ˆä¸€æ¬¡è®­ç»ƒå¯å¤šæ¬¡é‡‡æ ·ï¼‰ï¼Œæ˜¾è‘—å‡å°‘ä»¿çœŸæ¬¡æ•°ã€‚
- å¯¹æ¯”äº†ä¸¤ç§ **summary statistics** çš„æ•ˆæœï¼š
  - **Handcrafted statistics**ï¼šäººå·¥è®¾è®¡çš„ç»Ÿè®¡é‡ï¼ˆmin, max, mean, variance, quantiles, autocorrelationï¼‰
  - **NN-learned statistics**ï¼šé€šè¿‡åµŒå…¥å¼ RNN è‡ªåŠ¨å­¦ä¹ ä½ç»´è¡¨ç¤º

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹æ³• | æ˜¯å¦æ”¯æŒä¸ç¡®å®šæ€§ | æ˜¯å¦æ”¯æŒ amortization | æ˜¯å¦è‡ªåŠ¨æå–ç‰¹å¾ | æ•ˆç‡ |
|------|------------------|------------------------|--------------------|------|
| SSE / CMA-ES | âŒ | âŒ | âŒ | ä¸­ç­‰ |
| ABC (Approximate Bayesian Computation) | âœ… | âŒ | âŒ | ä½ |
| **SBI4ABM (NPE + NF)** | âœ… | âœ… | âœ…ï¼ˆè‹¥ç”¨ NN-learnedï¼‰ | é«˜ |

> âœ… SBI4ABM èƒ½æ›´é«˜æ•ˆåœ°é€¼è¿‘ posterior åˆ†å¸ƒï¼Œå°¤å…¶åœ¨å¤§è§„æ¨¡ ABM ä¸Šå…·å¤‡æ›´å¼ºæ‰©å±•æ€§ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
| æ•°æ®ç±»å‹ | æè¿° |
|---------|------|
| **Synthetic datasets** | æ„é€  n=10 åˆ° 460 ä¸ªèŒä¸šçš„åˆæˆåŠ³åŠ¨åŠ›å¸‚åœºï¼Œæ§åˆ¶ `z`, `Pi,j`, `p` åˆ†å¸ƒä»¥å¤ç°ç¾å›½æ•°æ®ç‰¹å¾ |
| **Real-world U.S. labour market data** | æ¥è‡ª BLS çš„ Current Population Survey (2010â€“2017)ï¼ŒåŒ…å« 464 ä¸ªèŒä¸šçš„çœŸå® transition matrix å’Œ workforce åˆ†å¸ƒ |

### **å®éªŒè®¾ç½®**
- **ç›®æ ‡æ¨¡å‹**ï¼šLabour Market Occupational Mobility and Automation ABM (**LM-ABM**)  
- **å¾…ä¼°å‚æ•°å‘é‡**ï¼š`Î¸ = [Î´u, Î´v, r]`
  - `Î´u`: å°±ä¸šè€…è¢«è§£é›‡ç‡
  - `Î´v`: æ–°å²—ä½åˆ›å»ºç‡
  - `r`: åŠ³åŠ¨è€…ç•™åœ¨åŸèŒä¸šçš„æ¦‚ç‡
- **Prior distributions**ï¼šå‡åŒ€åˆ†å¸ƒï¼ˆè§ Table 3ï¼‰
- **ä»¿çœŸé•¿åº¦**ï¼šT = 600 æ—¶é—´æ­¥ï¼ˆçº¦ 78 å¹´ï¼‰ï¼Œæ¯æ­¥å¯¹åº” 6.75 å‘¨
- **è®­ç»ƒæµç¨‹**ï¼š
  1. ä» prior ä¸­é‡‡æ · Î¸
  2. è¿è¡Œ LM-ABM å¾—åˆ°è¾“å‡º x
  3. æ„å»º `(Î¸, x)` æ•°æ®é›†è®­ç»ƒ NPE
  4. ç»™å®šè§‚æµ‹æ•°æ® yï¼Œé€šè¿‡æ¡ä»¶åŒ–å¾—åˆ° posterior `p(Î¸|y)`

### **è¯„ä¼°æŒ‡æ ‡**
- **Posterior coverage**ï¼šçœŸå®å‚æ•°æ˜¯å¦è½åœ¨é«˜å¯†åº¦åŒºåŸŸ
- **Sharpness**ï¼šposterior åˆ†å¸ƒé›†ä¸­ç¨‹åº¦ï¼ˆè¶Šå°–é”è¶Šå¥½ï¼‰
- **Scalability**ï¼šéšèŒä¸šæ•° n å¢åŠ çš„ simulation å’Œ training æ—¶é—´å˜åŒ–
- **Simulation-Based Calibration (SBC)**ï¼šæ£€éªŒ posterior æ˜¯å¦æ ¡å‡†è‰¯å¥½ï¼ˆæœŸæœ›ä¸º uniform rank histogramï¼‰

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **Baseline 1**ï¼šä½¿ç”¨ handcrafted summary statistics çš„ SBI4ABM
- **Baseline 2**ï¼šæœªæ˜ç¡®è¿è¡Œå…¶ä»– SBI æˆ– ABC æ–¹æ³•ï¼Œä½†å¼•ç”¨å…¶ç†è®ºåŠ£åŠ¿è¿›è¡Œé—´æ¥æ¯”è¾ƒ
- **æ¶ˆèå®éªŒ**ï¼šæ¯”è¾ƒä¸åŒ summary statistics ç±»å‹çš„å½±å“ï¼ˆhandcrafted vs. NN-learnedï¼‰

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
#### âœ… **NN-learned summary statistics è¡¨ç°æ›´ä¼˜**
- å›¾ 2 æ˜¾ç¤ºï¼Œä½¿ç”¨ RNN å­¦ä¹ çš„ summary statistics æ‰€å¾— posterior åˆ†å¸ƒæ›´ **sharp**ï¼Œå³°å€¼ç´§è´´çœŸå®å‚æ•°å€¼ï¼ˆæ©™è‰²çº¿ï¼‰
- ç›¸æ¯”ä¹‹ä¸‹ï¼Œhandcrafted statistics å¯¼è‡´ posterior æ›´åˆ†æ•£ï¼ˆå›¾ 1ï¼‰ï¼Œè¡¨æ˜ä¿¡æ¯æŸå¤±æ›´å¤š

#### âš ï¸ **ä½†å­˜åœ¨ calibration é—®é¢˜**
- **SBC ç»“æœï¼ˆå›¾ 8 & 9ï¼‰æ˜¾ç¤ºåç›´è§‰ç°è±¡**ï¼š
  - Handcrafted æ–¹æ³•ï¼šrank histogram æ¥è¿‘ uniform â†’ **well-calibrated**
  - NN-learned æ–¹æ³•ï¼šhistogram ä¸­å¤®å‡¸èµ·ã€å°¾éƒ¨ç¼ºå¤± â†’ **under-dispersed credible intervals**
- è¡¨æ˜ NN-learned æ–¹æ³•è™½ç„¶æ›´ç²¾ç¡®ï¼ˆsharpï¼‰ï¼Œä½†å¯èƒ½ **è¿‡æ‹Ÿåˆæˆ–é™ç»´åå·®**ï¼Œå¯¼è‡´ä¸ç¡®å®šæ€§ä½ä¼°

#### ğŸ“ˆ **è‰¯å¥½çš„å¯æ‰©å±•æ€§ï¼ˆscalabilityï¼‰**
- **Simulation time**ï¼ˆå›¾ 3ï¼‰ï¼šéšèŒä¸šæ•° n çº¿æ€§å¢é•¿ï¼Œæ ‡å‡†å·®å°ï¼Œç¨³å®šæ€§å¥½
- **Training time**ï¼ˆå›¾ 4ï¼‰ï¼šå½“ n > 360 åæ–¹å·®å¢å¤§ï¼Œåæ˜ ç¡¬ä»¶èµ„æºç“¶é¢ˆï¼ˆå†…å­˜ã€GPU æ˜¾å­˜ï¼‰

#### ğŸ” **åœ¨ç¾å›½çœŸå®æ•°æ®ä¸Šçš„åº”ç”¨**
- æˆåŠŸåœ¨ U.S. æ•°æ®ï¼ˆn=464ï¼‰ä¸Šè¿è¡Œ SBI4ABMï¼ˆå›¾ 5ï¼‰
- å‘ç°å‚æ•°é—´å¼±ç›¸å…³æ€§ï¼ˆå›¾ 6ï¼‰ï¼š
  - `Î´u` ä¸ `Î´v` æ­£ç›¸å…³ï¼ˆ0.24ï¼‰
  - `r` ä¸ `Î´u`, `Î´v` è´Ÿç›¸å…³ï¼ˆâ‰ˆ -0.2ï¼‰
- é€šè¿‡ high-density sampling å‘ç°ä¸‰ç§åŠ¨æ€æ¨¡å¼ï¼ˆå›¾ 7ï¼‰ï¼š
  - Pattern 1ï¼šä½ `Î´u/Î´v` â†’ ç¨³å®šå¸‚åœº
  - Pattern 2ï¼šä¸­ç­‰æ³¢åŠ¨
  - Pattern 3ï¼šé«˜ `Î´u/Î´v` â†’ é«˜å¤±ä¸šä¸é«˜é¢‘èŒä½å˜åŠ¨å¹¶å­˜

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
| ç»´åº¦ | Handcrafted Stats | NN-Learned Stats |
|------|-------------------|------------------|
| Posterior sharpness | è¾ƒå®½æ³› | âœ… æ›´é›†ä¸­ |
| å‚æ•°æ¢å¤å‡†ç¡®æ€§ | ä¸€èˆ¬ | âœ… æ›´æ¥è¿‘çœŸå€¼ |
| Uncertainty calibration | âœ… è‰¯å¥½ï¼ˆuniform ranksï¼‰ | âŒ ä¸è¶³ï¼ˆcentral-peaked ranksï¼‰ |
| ç‰¹å¾å·¥ç¨‹ä¾èµ– | é«˜ï¼ˆéœ€é¢†åŸŸçŸ¥è¯†ï¼‰ | âœ… è‡ªåŠ¨å­¦ä¹  |
| å¯æ‰©å±•æ€§ | å—é™äºæ‰‹å·¥ç‰¹å¾è¡¨è¾¾åŠ› | âœ… æ›´é€‚åˆå¤§æ•°æ® |

> â¤ **Trade-off å‘ç°**ï¼šNN-learned statistics æå‡ç²¾åº¦ä½†ç‰ºç‰²å¯é æ€§ï¼›handcrafted æ›´ç¨³å¥ä½†è¡¨è¾¾èƒ½åŠ›æœ‰é™ã€‚

### **æ¶ˆèå®éªŒç»“æœ**
- æ˜ç¡®è¿›è¡Œäº† **summary statistics ç±»å‹çš„æ¶ˆèå®éªŒ**ï¼š
  - å›ºå®š SBI4ABM æ¡†æ¶ï¼Œä»…æ›´æ¢ summary statistics æ¨¡å—
  - ç»“æœè¯æ˜ï¼šNN-learned æ˜¾è‘—æå‡ posterior concentrationï¼ŒéªŒè¯äº†è‡ªåŠ¨ç‰¹å¾å­¦ä¹ çš„æœ‰æ•ˆæ€§
- æœªå¯¹ NPE æ¶æ„ï¼ˆå¦‚ MAF å±‚æ•°ï¼‰ã€RNN ç±»å‹ç­‰åšè¿›ä¸€æ­¥æ¶ˆè

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. âœ… **SBI4ABM å…·å¤‡å¤„ç†ç°å®è§„æ¨¡ ABM çš„æ½œåŠ›**ï¼š
   - åœ¨ n=464 çš„ç¾å›½åŠ³åŠ¨åŠ›å¸‚åœºä¸ŠæˆåŠŸè¿è¡Œï¼Œsimulation æ—¶é—´éš n çº¿æ€§å¢é•¿ï¼Œå…·å¤‡å®é™…åº”ç”¨å‰æ™¯ã€‚
   
2. âœ… **NN-learned summary statistics æå‡ä¼°è®¡ç²¾åº¦**ï¼š
   - ç›¸æ¯” handcrafted æ–¹æ³•ï¼Œèƒ½ç”Ÿæˆæ›´ sharp çš„ posteriorï¼Œæ›´å¥½æ•æ‰çœŸå®å‚æ•°ä½ç½®ã€‚

3. âš ï¸ **å­˜åœ¨ç²¾åº¦-å¯é æ€§æƒè¡¡ï¼ˆprecision-reliability trade-offï¼‰**ï¼š
   - NN æ–¹æ³•è™½æ›´â€œå‡†ç¡®â€ï¼Œä½† SBC æ˜¾ç¤ºå…¶ posterior è¿‡äºé›†ä¸­ï¼Œå¯èƒ½å¯¼è‡´å¯ä¿¡åŒºé—´è¯¯åˆ¤ã€‚

4. ğŸ”— **æ­ç¤ºäº†å‚æ•°é—´çš„éšå«å…³ç³»**ï¼š
   - å‘ç° `Î´u` ä¸ `Î´v` å­˜åœ¨æ­£ç›¸å…³ï¼Œä»¥åŠ `r` å¯¹å°±ä¸šç¨³å®šæ€§çš„éçº¿æ€§å½±å“ï¼Œè¿™äº›æœªåœ¨åŸå§‹ LM-ABM ä¸­æ˜ç¡®æå‡ºã€‚

5. ğŸ’¾ **å¾®æ•°æ®ï¼ˆmicrodataï¼‰é›†æˆé¢ä¸´ä¸¥é‡å†…å­˜ç“¶é¢ˆ**ï¼š
   - å®Œæ•´ job transition matrices å†…å­˜éœ€æ±‚è¶… 240GBï¼Œè¿œè¶…å¸¸è§„æœåŠ¡å™¨å®¹é‡ï¼Œå¯¼è‡´æ— æ³•åœ¨çœŸå®å¾®æ•°æ®ä¸Šå®Œæˆç«¯åˆ°ç«¯è®­ç»ƒã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
| å±€é™æ€§ | è¯´æ˜ |
|-------|------|
| **åˆæˆæ•°æ®ç®€åŒ–** | åˆæˆæ•°æ®ä»…å¤åˆ¶åŸºæœ¬åˆ†å¸ƒï¼Œæœªè€ƒè™‘çœŸå®ç»æµå‘¨æœŸã€æ”¿ç­–å¹²é¢„ç­‰å¤æ‚å› ç´  |
| **ç¼ºä¹çœŸå® microdata éªŒè¯** | æ— æ³•å°† ABM è¾“å‡ºä¸çœŸå®ä¸ªä½“çº§ job transition æ•°æ®å¯¹æ¯”ï¼Œé™åˆ¶å¤–éƒ¨æœ‰æ•ˆæ€§ |
| **NN summary statistics å¯è§£é‡Šæ€§å·®** | RNN æå–çš„ç‰¹å¾ä¸å¯è¯»ï¼Œéš¾ä»¥è¯Šæ–­é”™è¯¯æ¥æº |
| **å†…å­˜ç“¶é¢ˆåˆ¶çº¦å®ç”¨æ€§** | å¤§è§„æ¨¡å¾®æ•°æ®ä¸‹çš„ SBI ä»ä¸ç°å®ï¼Œéœ€æ¨¡å‹å‹ç¼©æˆ–åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ |

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **ä¼˜åŒ– summary statistic ç½‘ç»œæ¶æ„**ï¼š
   - æ¢ç´¢ Graph Neural Networks (GNNs) æˆ– Transformer æ¥æ›´å¥½åœ°å»ºæ¨¡èŒä¸š transition network ç»“æ„ã€‚
2. **å¼•å…¥çœŸå® longitudinal microdata**ï¼š
   - ä½¿ç”¨è¡Œæ”¿è®°å½•æˆ–å¹³å°æ•°æ®ï¼ˆå¦‚ LinkedInã€Indeedï¼‰æ„å»ºå¯éªŒè¯çš„ ground truthã€‚
3. **è§£å†³å†…å­˜ç“¶é¢ˆ**ï¼š
   - å¼€å‘ streaming SBIã€checkpointing æˆ–æ¨¡å‹è’¸é¦æŠ€æœ¯é™ä½å­˜å‚¨å‹åŠ›ã€‚
4. **æ”¹è¿› calibration æ€§èƒ½**ï¼š
   - è®¾è®¡æ­£åˆ™åŒ–ç­–ç•¥æˆ–æ··åˆ summary statistics æ–¹æ¡ˆï¼Œåœ¨ sharpness ä¸ calibration ä¹‹é—´å–å¾—å¹³è¡¡ã€‚
5. **è·¨å›½å®¶/è¡Œä¸šè¿ç§»èƒ½åŠ›ç ”ç©¶**ï¼š
   - æµ‹è¯• SBI4ABM æ˜¯å¦å¯åœ¨ä¸åŒç»æµä½“é—´è¿ç§» posterior estimatorã€‚

---

> ğŸ **æ€»ä½“è¯„ä»·**ï¼šè¯¥è®ºæ–‡æ˜¯æ¨åŠ¨ ABM ä»â€œç©å…·æ¨¡å‹â€èµ°å‘â€œå†³ç­–å·¥å…·â€çš„é‡è¦ä¸€æ­¥ã€‚å®ƒå±•ç¤ºäº† **NN-based SBI åœ¨å¤æ‚ç»æµå»ºæ¨¡ä¸­çš„å·¨å¤§æ½œåŠ›**ï¼ŒåŒæ—¶ä¹Ÿå¦è¯šæ­ç¤ºäº†å½“å‰æ–¹æ³•åœ¨ **å¯é æ€§ã€å¯æ‰©å±•æ€§å’Œæ•°æ®æ•´åˆæ–¹é¢çš„çœŸå®æŒ‘æˆ˜**ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†æ¸…æ™°çš„æ–¹å‘ã€‚

</details>

---

### 16. [The Vision Wormhole: Latent-Space Communication in Heterogeneous Multi-Agent Systems](https://arxiv.org/abs/2602.15382)

**Authors**: Xiaoze Liu, Ruowang Zhang, Weichen Yu, Siheng Xiong, Liu He, Feijie Wu, Hoin Jung, Matt Fredrikson, Xiaoqian Wang, Jing Gao  
**Category**: cs.CL  
**Published**: 2026-02-18  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.15382v1  

#### Abstract
Multi-Agent Systems (MAS) powered by Large Language Models have unlocked advanced collaborative reasoning, yet they remain shackled by the inefficiency of discrete text communication, which imposes significant runtime overhead and information quantization loss. While latent state transfer offers a h...

---

### 17. [COMPOT: Calibration-Optimized Matrix Procrustes Orthogonalization for Transformers Compression](https://arxiv.org/abs/2602.15200)

**Authors**: Denis Makhov, Dmitriy Shopkhoev, Magauiya Zhussip, Ammar Ali, Baher Mohammad, Stamatios Lefkimmiatis  
**Category**: cs.LG  
**Published**: 2026-02-18  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.15200v1  

#### Abstract
Post-training compression of Transformer models commonly relies on truncated singular value decomposition (SVD). However, enforcing a single shared subspace can degrade accuracy even at moderate compression. Sparse dictionary learning provides a more flexible union-of-subspaces representation, but e...

---

### 18. [Size Transferability of Graph Transformers with Convolutional Positional Encodings](https://arxiv.org/abs/2602.15239)

**Authors**: Javier Porras-Valenzuela, Zhiyang Wang, Alejandro Ribeiro  
**Category**: cs.LG  
**Published**: 2026-02-18  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.15239v1  

#### Abstract
Transformers have achieved remarkable success across domains, motivating the rise of Graph Transformers (GTs) as attention-based architectures for graph-structured data. A key design choice in GTs is the use of Graph Neural Network (GNN)-based positional encodings to incorporate structural informati...

---

### 19. [Continuous-Time Piecewise-Linear Recurrent Neural Networks](https://arxiv.org/abs/2602.15649)

**Authors**: Alena Br\"andle, Lukas Eisenmann, Florian G\"otz, Daniel Durstewitz  
**Category**: cs.LG  
**Published**: 2026-02-18  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.15649v1  

#### Abstract
In dynamical systems reconstruction (DSR) we aim to recover the dynamical system (DS) underlying observed time series. Specifically, we aim to learn a generative surrogate model which approximates the underlying, data-generating DS, and recreates its long-term properties (`climate statistics'). In s...

---

### 20. [Co-Design and Evaluation of a CPU-Free MPI GPU Communication Abstraction and Implementation](https://arxiv.org/abs/2602.15356)

**Authors**: Patrick G. Bridges (University of New Mexico), Derek Schafer (University of New Mexico), Jack Lange (Oak Ridge National Laboratory), James B. White III (Oak Ridge National Laboratory), Anthony Skjellum (Tennessee Technological University), Evan Suggs (Tennessee Technological University), Thomas Hines (Tennessee Technological University), Purushotham Bangalore (University of Alabama), Matthew G. F. Dosanjh (Sandia National Laboratories), Whit Schonbein (Sandia National Laboratories)  
**Category**: cs.DC  
**Published**: 2026-02-18  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.15356v1  

#### Abstract
Removing the CPU from the communication fast path is essential to efficient GPU-based ML and HPC application performance. However, existing GPU communication APIs either continue to rely on the CPU for communication or rely on APIs that place significant synchronization burdens on programmers. In th...

---

### 21. [In Agents We Trust, but Who Do Agents Trust? Latent Source Preferences Steer LLM Generations](https://arxiv.org/abs/2602.15456)

**Authors**: Mohammad Aflah Khan, Mahsa Amani, Soumi Das, Bishwamittra Ghosh, Qinyuan Wu, Krishna P. Gummadi, Manish Gupta, Abhilasha Ravichander  
**Category**: cs.CL  
**Published**: 2026-02-18  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.15456v1  

#### Abstract
Agents based on Large Language Models (LLMs) are increasingly being deployed as interfaces to information on online platforms. These agents filter, prioritize, and synthesize information retrieved from the platforms' back-end databases or via web search. In these scenarios, LLM agents govern the inf...

---

### 22. [Causal Effect Estimation with Latent Textual Treatments](https://arxiv.org/abs/2602.15730)

**Authors**: Omri Feldman, Amar Venugopal, Jann Spiess, Amir Feder  
**Category**: cs.CL  
**Published**: 2026-02-18  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.15730v1  

#### Abstract
Understanding the causal effects of text on downstream outcomes is a central task in many applications. Estimating such effects requires researchers to run controlled experiments that systematically vary textual features. While large language models (LLMs) hold promise for generating text, producing...

---

### 23. [Mind the (DH) Gap! A Contrast in Risky Choices Between Reasoning and Conversational LLMs](https://arxiv.org/abs/2602.15173)

**Authors**: Luise Ge, Yongyan Zhang, Yevgeniy Vorobeychik  
**Category**: cs.AI  
**Published**: 2026-02-18  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.15173v1  

#### Abstract
The use of large language models either as decision support systems, or in agentic workflows, is rapidly transforming the digital ecosystem. However, the understanding of LLM decision-making under uncertainty remains limited. We initiate a comparative study of LLM risky choices along two dimensions:...

---

### 24. [Mnemis: Dual-Route Retrieval on Hierarchical Graphs for Long-Term LLM Memory](https://arxiv.org/abs/2602.15313)

**Authors**: Zihao Tang, Xin Yu, Ziyu Xiao, Zengxuan Wen, Zelin Li, Jiaxi Zhou, Hualei Wang, Haohua Wang, Haizhen Huang, Weiwei Deng, Feng Sun, Qi Zhang  
**Category**: cs.CL  
**Published**: 2026-02-18  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.15313v1  

#### Abstract
AI Memory, specifically how models organizes and retrieves historical messages, becomes increasingly valuable to Large Language Models (LLMs), yet existing methods (RAG and Graph-RAG) primarily retrieve memory through similarity-based mechanisms. While efficient, such System-1-style retrieval strugg...

---

### 25. [LLM-to-Speech: A Synthetic Data Pipeline for Training Dialectal Text-to-Speech Models](https://arxiv.org/abs/2602.15675)

**Authors**: Ahmed Khaled Khamis, Hesham Ali  
**Category**: cs.CL  
**Published**: 2026-02-18  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.15675v1  

#### Abstract
Despite the advances in neural text to speech (TTS), many Arabic dialectal varieties remain marginally addressed, with most resources concentrated on Modern Spoken Arabic (MSA) and Gulf dialects, leaving Egyptian Arabic -- the most widely understood Arabic dialect -- severely under-resourced. We add...

---

### 26. [On the Out-of-Distribution Generalization of Reasoning in Multimodal LLMs for Simple Visual Planning Tasks](https://arxiv.org/abs/2602.15460)

**Authors**: Yannic Neuhaus, Nicolas Flammarion, Matthias Hein, Francesco Croce  
**Category**: cs.LG  
**Published**: 2026-02-18  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.15460v1  

#### Abstract
Integrating reasoning in large language models and large vision-language models has recently led to significant improvement of their capabilities. However, the generalization of reasoning models is still vaguely defined and poorly understood. In this work, we present an evaluation framework to rigor...

---

### 27. [Controlled oscillation modeling using port-Hamiltonian neural networks](https://arxiv.org/abs/2602.15704)

**Authors**: Maximino Linares, Guillaume Doras, Thomas H\'elie  
**Category**: cs.LG  
**Published**: 2026-02-18  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2602.15704v1  

#### Abstract
Learning dynamical systems through purely data-driven methods is challenging as they do not learn the underlying conservation laws that enable them to correctly generalize. Existing port-Hamiltonian neural network methods have recently been successfully applied for modeling mechanical systems. Howev...

---

### 28. [Secure and Energy-Efficient Wireless Agentic AI Networks](https://arxiv.org/abs/2602.15212)

**Authors**: Yuanyan Song, Kezhi Wang, Xinmian Xu  
**Category**: cs.AI  
**Published**: 2026-02-18  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.15212v1  

#### Abstract
In this paper, we introduce a secure wireless agentic AI network comprising one supervisor AI agent and multiple other AI agents to provision quality of service (QoS) for users' reasoning tasks while ensuring confidentiality of private knowledge and reasoning outcomes. Specifically, the supervisor A...

---

### 29. [How Vision Becomes Language: A Layer-wise Information-Theoretic Analysis of Multimodal Reasoning](https://arxiv.org/abs/2602.15580)

**Authors**: Hongxuan Wu, Yukun Zhang, Xueqing Zhou  
**Category**: cs.AI  
**Published**: 2026-02-18  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.15580v1  

#### Abstract
When a multimodal Transformer answers a visual question, is the prediction driven by visual evidence, linguistic reasoning, or genuinely fused cross-modal computation -- and how does this structure evolve across layers? We address this question with a layer-wise framework based on Partial Informatio...

---

### 30. [CARE Drive A Framework for Evaluating Reason-Responsiveness of Vision Language Models in Automated Driving](https://arxiv.org/abs/2602.15645)

**Authors**: Lucas Elbert Suryana, Farah Bierenga, Sanne van Buuren, Pepijn Kooij, Elsefien Tulleners, Federico Scari, Simeon Calvert, Bart van Arem, Arkady Zgonnikov  
**Category**: cs.AI  
**Published**: 2026-02-18  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2602.15645v1  

#### Abstract
Foundation models, including vision language models, are increasingly used in automated driving to interpret scenes, recommend actions, and generate natural language explanations. However, existing evaluation methods primarily assess outcome based performance, such as safety and trajectory accuracy,...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- kv cache, offload, State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
