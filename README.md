# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-22 05:58:47 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Taming the Memory Footprint Crisis: System Design for Production Diffusion LLM Serving](https://arxiv.org/abs/2512.17077)

**Authors**: Jiakun Fan, Yanglin Zhang, Xiangchen Li, Dimitrios S. Nikolopoulos  
**Category**: cs.DC  
**Published**: 2025-12-22  
**Score**: 18.0  
**Type**: new  
**ArXiv ID**: 2512.17077v1  

#### Abstract
Diffusion Large Language Models (dLLMs) have emerged as a promising alternative to Autoregressive Models (ARMs), utilizing parallel decoding to overcome sequential bottlenecks. However, existing research focuses primarily on kernel-level optimizations, lacking a holistic serving framework that addre...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTaming the Memory Footprint Crisis: System Design for Production Diffusion LLM Serving

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹ **Diffusion Large Language Models (dLLMs)** åœ¨ç”Ÿäº§ç¯å¢ƒä¸­çš„æ¨ç†æœåŠ¡æ‰€é¢ä¸´çš„â€œ**å†…å­˜å ç”¨å±æœº**â€ï¼ˆMemory Footprint Crisisï¼‰æå‡ºç³»ç»Ÿçº§è§£å†³æ–¹æ¡ˆã€‚ä¸ä¼ ç»Ÿçš„è‡ªå›å½’æ¨¡å‹ï¼ˆAR LLMsï¼‰ä¸åŒï¼ŒdLLMs è™½ç„¶é€šè¿‡å¹¶è¡Œè§£ç æå‡äº†é€Ÿåº¦æ½œåŠ›ï¼Œä½†å…¶ç‹¬ç‰¹çš„è¿­ä»£å»å™ªè¿‡ç¨‹å¸¦æ¥äº†ä»¥ä¸‹ä¸‰å¤§æŒ‘æˆ˜ï¼š

1. **å·¨å¤§çš„ç¬æ€æ¿€æ´»å†…å­˜å¼€é”€**ï¼šç”±äºæ¯ä¸€æ­¥éƒ½éœ€è¦ä¸ºæ•´ä¸ªåºåˆ—ç”Ÿæˆ logitsï¼Œå¯¼è‡´å‡ºç°å·¨å¤§çš„ã€çŸ­æš‚çš„ `[B, L, V]` å½¢çŠ¶çš„ logit tensorï¼Œä¸¥é‡æŒ¤å æ˜¾å­˜ã€‚
2. **èµ„æºæŒ¯è¡é—®é¢˜**ï¼šdLLM æ¨ç†åœ¨ **Refresh é˜¶æ®µ**ï¼ˆè®¡ç®—å¯†é›†å‹ï¼Œéœ€æ›´æ–°å…¨åºåˆ— QKVï¼‰å’Œ **Reuse é˜¶æ®µ**ï¼ˆå¸¦å®½å¯†é›†å‹ï¼Œå¤ç”¨ç¼“å­˜ï¼‰ä¹‹é—´äº¤æ›¿ï¼Œä¼ ç»Ÿé™æ€è°ƒåº¦å™¨æ— æ³•æœ‰æ•ˆåˆ©ç”¨è¿™ç§æ³¢åŠ¨æ€§ã€‚
3. **ç¨€ç–æ³¨æ„åŠ›æ•ˆç‡ä½ä¸‹**ï¼šç°æœ‰ç¨€ç–æ–¹æ³•é‡‡ç”¨è·¨æ‰€æœ‰ attention head çš„ç»Ÿä¸€æ©ç ï¼ˆuniform maskingï¼‰ï¼Œç‰ºç‰²äº†æ¨¡å‹ç²¾åº¦ï¼›ä¸”é€»è¾‘ç¨€ç–æœªè½¬åŒ–ä¸ºç‰©ç†å†…å­˜èŠ‚çœã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
ä½œè€…æå‡ºäº† **dLLM-Serve** â€”â€”é¦–ä¸ªä¸“ä¸º dLLM è®¾è®¡çš„ç«¯åˆ°ç«¯é«˜æ•ˆæ¨ç†æœåŠ¡ç³»ç»Ÿï¼ŒåŒ…å«ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š

#### âœ… **Logit-Aware Activation Budgetingï¼ˆåŸºäº Logit çš„æ¿€æ´»é¢„ç®—ç®¡ç†ï¼‰**
- å°†åŸæœ¬å•æ¬¡è®¡ç®—çš„å·¨å‹ logit tensor æ²¿ token ç»´åº¦æ‹†åˆ†ä¸ºå¤šä¸ªå°æ‰¹é‡ï¼ˆmicro-batchingï¼‰ï¼Œä¸¥æ ¼é™åˆ¶å³°å€¼æ¿€æ´»å†…å­˜ã€‚
- é‡Šæ”¾å‡ºçš„æ˜¾å­˜å¯ç”¨äºæ‰©å±• KV Cache Poolï¼Œä»è€Œæ”¯æŒæ›´é«˜å¹¶å‘è¯·æ±‚ã€‚

#### âœ… **Phase-Multiplexed Schedulerï¼ˆç›¸ä½å¤šè·¯å¤ç”¨è°ƒåº¦å™¨ï¼‰**
- ä¸å†ä»¥â€œè¯·æ±‚â€ä¸ºå•ä½è°ƒåº¦ï¼Œè€Œæ˜¯ä»¥â€œé˜¶æ®µâ€ï¼ˆRefresh / Reuseï¼‰ä¸ºç²’åº¦è¿›è¡ŒåŠ¨æ€è°ƒåº¦ã€‚
- å½“æŸäº›è¯·æ±‚è¿›å…¥è½»é‡çº§çš„ Reuse é˜¶æ®µæ—¶ï¼Œç«‹å³æ’å…¥æ–°çš„ Refresh è¯·æ±‚ï¼Œæœ€å¤§åŒ–ç¡¬ä»¶åˆ©ç”¨ç‡ã€‚

#### âœ… **Head-Centric Sparse KV Cacheï¼ˆå¤´ä¸­å¿ƒåŒ–ç¨€ç– KV ç¼“å­˜ï¼‰**
- æ”¯æŒæ¯ä¸ª attention head ç‹¬ç«‹é€‰æ‹©ä¿ç•™çš„å…³é”®ä¸Šä¸‹æ–‡ tokenï¼ˆå³ per-head top-k selectionï¼‰ï¼Œæå‡ç”Ÿæˆè´¨é‡ã€‚
- é€šè¿‡å°†ç¨€ç–ç´¢å¼•æ˜ å°„åˆ°**è¿ç»­çš„ç‰©ç†å­˜å‚¨å¸ƒå±€**ï¼Œå®ç°é«˜æ•ˆçš„ coalesced memory accessï¼Œå…¼é¡¾é«˜ç²¾åº¦ä¸é«˜æ€§èƒ½ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ Fast-dLLM, Sparse-dLLM, dLLM-Cacheï¼‰ | dLLM-Serve |
|------|--------------------------------------------------|-----------|
| å†…å­˜ç®¡ç† | å¿½è§† logit tensor å³°å€¼ï¼Œä¿å®ˆé¢„ç•™å¤§é‡æ¿€æ´»å†…å­˜ | æ˜¾å¼æ§åˆ¶ logit åˆ†å—ï¼Œæ˜¾è‘—é™ä½å³°å€¼å ç”¨ |
| è°ƒåº¦ç­–ç•¥ | è¯·æ±‚çº§è°ƒåº¦ï¼Œæ— æ³•åˆ©ç”¨ Refresh/Reuse ç›¸ä½å·®å¼‚ | ç›¸ä½çº§è°ƒåº¦ï¼ŒåŠ¨æ€äº¤é”™æ‰§è¡Œï¼Œæé«˜ GPU åˆ©ç”¨ç‡ |
| ç¨€ç–æœºåˆ¶ | å…¨å±€å…±äº«æ©ç ï¼ŒæŸå¤± head-specific è¯­ä¹‰èƒ½åŠ› | æ¯ head ç‹¬ç«‹é€‰æ‹©ï¼Œä¿æŒé«˜ç²¾åº¦ |
| ç‰©ç†å­˜å‚¨ | é€»è¾‘ç¨€ç– â‰  ç‰©ç†å‹ç¼©ï¼Œä»åŠ è½½å†—ä½™æ•°æ® | ç¨€ç– token æ‰“åŒ…æˆè¿ç»­ bufferï¼ŒçœŸæ­£èŠ‚çœå¸¦å®½ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **LiveBench**ï¼šé¢å‘ç¼–ç¨‹ä»»åŠ¡çš„è¯„æµ‹åŸºå‡†ï¼Œç”¨äºæµ‹è¯•ä»£ç ç”Ÿæˆèƒ½åŠ›ã€‚
- **BurstGPT (Burst)**ï¼šçœŸå®ç”¨æˆ·äº¤äº’è½¨è¿¹æ•°æ®é›†ï¼Œæ¨¡æ‹Ÿçªå‘æ€§è´Ÿè½½åœºæ™¯ã€‚
- **OpenAI Summarization Comparison (OSC)**ï¼šæ‘˜è¦å¯¹æ¯”æ•°æ®é›†ï¼Œå«äººç±»åå¥½æ ‡æ³¨ã€‚
- **GSM8K**ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜æ•°æ®é›†ï¼Œæµ‹è¯•å¤šæ­¥æ¨ç†èƒ½åŠ›ã€‚
- **HumanEval**ï¼šå‡½æ•°è¡¥å…¨ä»»åŠ¡ï¼Œè¯„ä¼°ä»£ç ç”Ÿæˆå‡†ç¡®æ€§ã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼šLLaDA-8B-Instructï¼ˆåŸºäºæ‰©æ•£çš„è¯­è¨€æ¨¡å‹ï¼‰
- **ç¡¬ä»¶å¹³å°**ï¼š
  - æ¶ˆè´¹çº§ GPUï¼šNVIDIA RTX 4090ï¼ˆ24GB VRAMï¼‰
  - æœåŠ¡å™¨çº§ GPUï¼šNVIDIA L40Sï¼ˆ48GB VRAMï¼‰
- **é…ç½®å‚æ•°**ï¼š
  - åºåˆ—é•¿åº¦ï¼š256 tokens
  - è§£ç æ­¥æ•°ï¼š256 steps
  - KV Block Sizeï¼š32
  - Sparsity Retention Ratioï¼š0.5ï¼ˆä¸ Sparse-dLLM å¯¹é½ä»¥ä¿è¯å…¬å¹³ï¼‰

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Throughput (tok/s)** | å•ä½æ—¶é—´å†…ç”Ÿæˆçš„ token æ•°é‡ï¼Œè¡¡é‡ååé‡ |
| **Avg Latency (s)** | è¯·æ±‚ä»æäº¤åˆ°å®Œæˆçš„å¹³å‡å»¶è¿Ÿ |
| **Tail Latency** | é«˜è´Ÿè½½ä¸‹çš„æœ€å¤§å»¶è¿Ÿè¡¨ç° |
| **Jitter & Tail Span** | å»¶è¿Ÿç¨³å®šæ€§ï¼ˆæ ‡å‡†å·®ã€max-min å·®è·ï¼‰ |
| **Pass@1 Accuracy** | HumanEval ä¸Šçš„ä»£ç æ­£ç¡®ç‡ |
| **Accuracy on GSM8K** | æ•°å­¦é—®é¢˜è§£ç­”å‡†ç¡®ç‡ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | ç®€ä»‹ |
|------|------|
| **Fast-dLLM** | æ”¯æŒ KV ç¼“å­˜å’Œå¹¶è¡Œè§£ç çš„åŠ é€Ÿæ¡†æ¶ |
| **dLLM-Cache** | è‡ªé€‚åº”ç¼“å­˜ç­–ç•¥ï¼ŒåŸºäºç‰¹å¾ç›¸ä¼¼æ€§éƒ¨åˆ†åˆ·æ–° |
| **Sparse-dLLM** | ç»“åˆåŠ¨æ€ç¼“å­˜é©±é€ä¸å…¨å±€ç¨€ç–æ³¨æ„åŠ› |

> âš ï¸ æ‰€æœ‰åŸºçº¿å‡å…³é—­ speculative decodingï¼Œå¹¶ä½¿ç”¨ç›¸åŒç”Ÿæˆå‚æ•°ç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ååé‡æå‡ï¼ˆThroughput Speedupï¼‰
| å¹³å° | æ•°æ®é›† | dLLM-Serve ååé‡ | æœ€ä½³åŸºçº¿ååé‡ | æå‡å€æ•° |
|------|--------|------------------|----------------|----------|
| RTX 4090 | Burst | **76.6 tok/s** | Fast-dLLM (42.4 tok/s) | **1.81Ã—** |
| L40S | Burst | **106.95 tok/s** | Sparse-dLLM (34.23 tok/s) | **3.12Ã—** |
| L40S | LiveBench | **90.17 tok/s** | Fast-dLLM (56.46 tok/s) | **2.79Ã—** |

> ğŸ’¡ åœ¨æœåŠ¡å™¨çº§ GPU ä¸Šä¼˜åŠ¿æ›´æ˜æ˜¾ï¼Œè¯´æ˜ dLLM-Serve æ›´å¥½åœ°åˆ©ç”¨äº†å¤§æ˜¾å­˜èµ„æºã€‚

### å»¶è¿Ÿä¼˜åŒ–ï¼ˆLatency Reductionï¼‰
| åœºæ™¯ | åŸºçº¿å¹³å‡å»¶è¿Ÿ | dLLM-Serve å¹³å‡å»¶è¿Ÿ | é™ä½å¹…åº¦ |
|------|-------------|--------------------|---------|
| RTX 4090 @ 0.5 RPS (Burst) | >4000s | **1370s** | â‰ˆ3Ã— |
| L40S @ 1.0 req/s (OSC) | 6791s | **1849s** | **â‰ˆ3.7Ã—** |

> ğŸ“‰ å‡ ä¹å®ç°äº† **4Ã— çš„å°¾éƒ¨å»¶è¿Ÿé™ä½**ï¼Œæå¤§æå‡äº†é«˜å¹¶å‘ä¸‹çš„å“åº”ç¨³å®šæ€§ã€‚

### æŠ–åŠ¨ä¸å¯é¢„æµ‹æ€§ï¼ˆJitter & Predictabilityï¼‰
- åœ¨é«˜è´Ÿè½½ä¸‹ï¼ˆRPS=0.5ï¼‰ï¼ŒdLLM-Serve å°†å»¶è¿Ÿæ ‡å‡†å·®å‡å°‘ **56%**ï¼Œå°¾éƒ¨è·¨åº¦ï¼ˆmax-minï¼‰å‡å°‘ **53%**ã€‚
- æˆåŠŸé¿å…äº†â€œå¤´é˜»å¡â€ï¼ˆhead-of-line blockingï¼‰ç°è±¡ï¼ŒçŸ­è¯·æ±‚ä¸ä¼šè¢«é•¿ Refresh è¯·æ±‚é˜»å¡ã€‚

### ç”Ÿæˆè´¨é‡åˆ†æï¼ˆGeneration Qualityï¼‰
| æŒ‡æ ‡ | æ–¹æ³• | Retention Ratio=10% | Retention Ratio=20% |
|------|------|-----------------------|-----------------------|
| **HumanEval Pass@1** | Uniform Selection (Sparse-dLLM) | 7.9% | 15.8% |
| | Head-Centric Selection (dLLM-Serve) | **20.1%** (+2.5Ã—) | 25.3% |
| **GSM8K Accuracy** | Uniform Selection | 40.0% | 58.0% |
| | Head-Centric Selection | **75.1%** (+87.7%) | 76.5% |

> âœ… dLLM-Serve åœ¨æä½ç¼“å­˜æ¯”ä¾‹ä¸‹ä»èƒ½ç»´æŒé«˜è´¨é‡è¾“å‡ºï¼Œæ„å‘³ç€å¯ä»¥ç”¨ä¸€åŠå†…å­˜è¾¾åˆ°ç›¸åŒç²¾åº¦ï¼Œè¿›ä¸€æ­¥æå‡å¹¶å‘å®¹é‡ã€‚

### æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰
é€æ­¥æ·»åŠ æ¨¡å—åçš„æ€§èƒ½å¢ç›Šï¼ˆç›¸å¯¹ Sparse-dLLM åŸºçº¿ï¼‰ï¼š

| ç»„ä»¶ | LiveBench | Burst | OSC |
|------|----------|-------|-----|
| Baseline (Sparse-dLLM) | 1.0Ã— | 1.0Ã— | 1.0Ã— |
| + Inference Engineï¼ˆFlashAttention + è¿ç»­æ‰¹å¤„ç†ï¼‰ | 1.49Ã— | 1.76Ã— | 1.58Ã— |
| + Smart Schedulerï¼ˆPhase-Multiplexedï¼‰ | 1.61Ã— | 1.82Ã— | 1.68Ã— |
| + Logit-Aware Budgeting | **1.75Ã—** | **1.97Ã—** | **1.76Ã—** |

> ğŸ” ä¸‰è€…ååŒä½œç”¨æ˜¾è‘—ï¼Œå…¶ä¸­ **Logit-Aware Budgeting** å¯¹ Burst ç±»è´Ÿè½½è´¡çŒ®æœ€å¤§ï¼ˆ+1.97Ã—ï¼‰ï¼ŒéªŒè¯äº†å…¶å¯¹å†…å­˜ç“¶é¢ˆçš„æœ‰æ•ˆç¼“è§£ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **dLLM çš„å†…å­˜ç“¶é¢ˆå·²ä» KV Cache è½¬å‘ç¬æ€æ¿€æ´»ï¼ˆå°¤å…¶æ˜¯ logit tensorï¼‰**ï¼Œå¿…é¡»è¿›è¡Œç»†ç²’åº¦é¢„ç®—ç®¡ç†ã€‚
2. **Refresh/Reuse ç›¸ä½é—´çš„èµ„æºæŒ¯è¡æ˜¯å¯åˆ©ç”¨çš„æœºä¼šçª—å£**ï¼Œç›¸ä½çº§è°ƒåº¦èƒ½æ˜¾è‘—æå‡ç¡¬ä»¶åˆ©ç”¨ç‡ã€‚
3. **head-level ç¨€ç–ä¸ä»…æå‡ç²¾åº¦ï¼Œè¿˜èƒ½é€šè¿‡ç‰©ç†æ‰“åŒ…å®ç°é«˜æ•ˆè®¿é—®**ï¼Œæ‰“ç ´â€œç¨€ç–å³æ…¢â€çš„è¯¯åŒºã€‚
4. **ç®—æ³•å±‚é¢çš„ç¨€ç–æ€§åªæœ‰ä¸ç³»ç»Ÿè®¾è®¡ç»“åˆæ‰èƒ½è½¬åŒ–ä¸ºå®é™…æ€§èƒ½æ”¶ç›Š**ï¼ŒdLLM-Serve æˆåŠŸå°†ç†è®º sparsity è½¬åŒ–ä¸º wall-clock åŠ é€Ÿã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰è°ƒåº¦å™¨é‡‡ç”¨è´ªå¿ƒ FCFS ç­–ç•¥ï¼Œåœ¨æç«¯æƒ…å†µä¸‹å¯èƒ½å¯¼è‡´æœªæ¥èµ„æºå†²çªï¼ˆå¤šä¸ªè¯·æ±‚åŒæ—¶è¿›å…¥ Refresh é˜¶æ®µï¼‰ã€‚
- ä¾èµ–é¢„è®¾çš„ `max_num_logits` å’Œ `retention_ratio` å‚æ•°ï¼Œç¼ºä¹è‡ªåŠ¨è°ƒä¼˜æœºåˆ¶ã€‚
- å°šæœªåœ¨åˆ†å¸ƒå¼å¤š GPU åœºæ™¯ä¸­éªŒè¯æ‰©å±•æ€§ï¼ˆå°½ç®¡æ¶æ„ä¸Šæ”¯æŒ Tensor Parallelismï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å¼€å‘ **Budgeting-Aware Scheduler**ï¼Œå¼•å…¥å‰ç»è§„åˆ’ï¼ˆlook-ahead planningï¼‰ï¼Œæå‰è§„é¿èµ„æºäº‰æŠ¢ã€‚
- æ¢ç´¢ **åŠ¨æ€è°ƒæ•´ logit åˆ†å—å¤§å°ä¸ç¨€ç–æ¯”ç‡** çš„è‡ªé€‚åº”æœºåˆ¶ã€‚
- æ‰©å±•è‡³ **å¤šèŠ‚ç‚¹åˆ†å¸ƒå¼æ¨ç†** æ¶æ„ï¼Œæ”¯æŒè¶…å¤§è§„æ¨¡ dLLM éƒ¨ç½²ã€‚
- å¼€æºé¡¹ç›®ä»£ç ï¼ˆä½œè€…æ‰¿è¯ºå°†å¼€æº dLLM-Serveï¼‰ï¼Œæ¨åŠ¨ç¤¾åŒºå…±å»ºé«˜æ•ˆ dLLM æ¨ç†ç”Ÿæ€ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> dLLM-Serve æ˜¯é¦–ä¸ªå…¨é¢åº”å¯¹ dLLM æ¨ç†å†…å­˜éœ‡è¡ä¸å¹¶å‘æŒ‘æˆ˜çš„æœåŠ¡ç³»ç»Ÿï¼Œé€šè¿‡ **Logit åˆ†å— + ç›¸ä½è°ƒåº¦ + å¤´ä¸­å¿ƒç¨€ç–ç¼“å­˜** ä¸‰ä½ä¸€ä½“è®¾è®¡ï¼Œåœ¨ä¿æŒé«˜ç”Ÿæˆè´¨é‡çš„åŒæ—¶ï¼Œå®ç°äº†é«˜è¾¾ **1.81Ã—â€“3.12Ã— çš„ååæå‡** å’Œ **è¿‘ 4Ã— çš„å°¾å»¶è¿Ÿä¸‹é™**ï¼Œä¸ºç”Ÿäº§çº§ dLLM éƒ¨ç½²æä¾›äº†å¯æ‰©å±•çš„è“å›¾ã€‚

</details>

---

### 2. [Enabling Disaggregated Multi-Stage MLLM Inference via GPU-Internal Scheduling and Resource Sharing](https://arxiv.org/abs/2512.17574)

**Authors**: Lingxiao Zhao, Haoran Zhou, Yuezhi Che, Dazhao Cheng  
**Category**: cs.DC  
**Published**: 2025-12-22  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2512.17574v1  

#### Abstract
Multimodal large language models (MLLMs) extend LLMs with visual understanding through a three-stage pipeline: multimodal preprocessing, vision encoding, and LLM inference. While these stages enhance capability, they introduce significant system bottlenecks. First, multimodal preprocessing-especiall...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šEnabling Disaggregated Multi-Stage MLLM Inference via GPU-Internal Scheduling and Resource Sharing

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆ**MLLMs**ï¼‰åœ¨æ¨ç†è¿‡ç¨‹ä¸­å¼•å…¥äº†è§†è§‰ç†è§£èƒ½åŠ›ï¼Œå…¶å…¸å‹æµç¨‹åŒ…å«ä¸‰ä¸ªé˜¶æ®µï¼š**multimodal preprocessing**ï¼ˆå¦‚è§†é¢‘è§£ç ï¼‰ã€**vision encoding** å’Œ **LLM inference**ã€‚ç„¶è€Œï¼Œè¿™ç§å¼‚æ„æµæ°´çº¿å¸¦æ¥äº†ä¸¥é‡çš„ç³»ç»Ÿç“¶é¢ˆï¼š
- **è§†é¢‘è§£ç å»¶è¿Ÿé«˜**ï¼šå°¤å…¶æ˜¯é•¿è§†é¢‘è§£ç å¸¸ä¸»å¯¼ **Time-to-First-Token (TTFT)**ï¼Œè€Œä¸»æµéƒ¨ç½²ä¾èµ– CPU è§£ç ï¼Œååä½ã€æ‰©å±•å·®ã€‚
- **è·¨é˜¶æ®µé˜»å¡ä¸¥é‡**ï¼švision encoder æ˜¯ç‹¬ç«‹ä¸”è®¡ç®—å¯†é›†çš„æ¨¡å—ï¼Œæ— æ³•ä¸ LLM çš„ prefill/decode é˜¶æ®µå…±æ‰¹å¤„ç†ï¼Œå¯¼è‡´èµ„æºç¢ç‰‡åŒ–å’Œç”Ÿæˆå»¶è¿Ÿå¢åŠ ã€‚
- **èµ„æºåˆ©ç”¨ç‡ä½ä¸‹**ï¼šæ— è®ºæ˜¯ monolithic æ¶æ„è¿˜æ˜¯ split-based æ¶æ„ï¼Œéƒ½æ— æ³•åŒæ—¶å…¼é¡¾ä½å»¶è¿Ÿä¸é«˜ååã€‚

### æå‡ºçš„æ–°æ–¹æ³•
ä½œè€…æå‡º **FlashCodec** å’Œ **UnifiedServe** ä¸¤ä¸ªäº’è¡¥è®¾è®¡ï¼Œæ„å»ºç«¯åˆ°ç«¯ä¼˜åŒ–æ ˆï¼š

#### âœ… FlashCodec
- **ååŒå¤š GPU è§†é¢‘è§£ç æœºåˆ¶**ï¼šåˆ©ç”¨æ‰€æœ‰ GPU ä¸Šçš„ç¡¬ä»¶è§£ç å¼•æ“ï¼ˆå¦‚ NVDECï¼‰ï¼Œå°†å•ä¸ªè§†é¢‘åˆ’åˆ†ä¸ºå¤šä¸ª GOPï¼ˆGroup of Picturesï¼‰å¹¶è¡Œè§£ç ã€‚
- **æ— åœæ»è°ƒåº¦ç­–ç•¥ï¼ˆStall-free Schedulingï¼‰**ï¼šä»¥ GOP ä¸ºè°ƒåº¦ç²’åº¦ï¼Œé¿å…è§£ç å•å…ƒç©ºè½¬ï¼Œæå‡ç¡¬ä»¶åˆ©ç”¨ç‡ã€‚
- æ”¯æŒé«˜æ•ˆå†…å­˜ç®¡ç†ï¼Œå‡å°‘å¸§åƒç´ ç¼“å­˜å¼€é”€ã€‚

#### âœ… UnifiedServe
- **é€»è¾‘è§£è€¦ã€ç‰©ç†å…±äº«æ¶æ„**ï¼š
  - å°† MLLM æ¨ç†åˆ’åˆ†ä¸ºä¸‰ä¸ªå¼‚æ­¥åä½œçš„å·¥ä½œè¿›ç¨‹ï¼ˆWorkerï¼‰ï¼š
    1. `vision_preprocess_worker`ï¼ˆä½¿ç”¨ FlashCodecï¼‰
    2. `encode_prefill_worker`
    3. `decode_worker`
  - å„é˜¶æ®µé€»è¾‘ä¸Šç‹¬ç«‹è¿è¡Œï¼Œé¿å…ç›¸äº’é˜»å¡ï¼›
  - ç‰©ç†ä¸Šå…±äº«åŒä¸€ç»„ GPU èµ„æºæ± ï¼Œæœ€å¤§åŒ–èµ„æºåˆ©ç”¨ç‡ã€‚
- å¼•å…¥é«˜æ•ˆçš„ä¸­é—´çŠ¶æ€ç¼“å†²æœºåˆ¶ï¼ˆåŸºäº PagedAttention æ€æƒ³ï¼‰ï¼Œç®¡ç† patch tokens å’Œ visual tokensï¼Œé™ä½å†…å­˜å‹åŠ›ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | Monolithic æ¶æ„ï¼ˆå¦‚ vLLM-sï¼‰ | Split-based æ¶æ„ï¼ˆå¦‚ vLLM-dï¼‰ | **UnifiedServe** |
|------|-------------------------------|------------------------------|------------------|
| **TTFT** | è¾ƒä½ï¼ˆä½†å—ç¼–ç å½±å“ï¼‰ | é«˜ï¼ˆå› ä¸²è¡Œè·¯å¾„é•¿ï¼‰ | âœ… æ˜¾è‘—é™ä½ï¼ˆ+FlashCodec åŠ é€Ÿï¼‰ |
| **TBT** | é«˜ï¼ˆencoder å¹²æ‰° decodeï¼‰ | ä½ï¼ˆéš”ç¦»æ‰§è¡Œï¼‰ | âœ… æ¥è¿‘ splitï¼Œè¿œä¼˜äº monolithic |
| **ååé‡** | é«˜ | ä½ï¼ˆèµ„æºåˆ†è£‚ï¼‰ | âœ… æœ€é«˜è¾¾ 4.4Ã— æå‡ |
| **èµ„æºåˆ©ç”¨ç‡** | é«˜ä½†å­˜åœ¨å¹²æ‰° | ä½ï¼ˆé™æ€åˆ’åˆ†ï¼‰ | âœ… å…¨å±€åŠ¨æ€å…±äº«ï¼Œé«˜åº¦åˆ©ç”¨ |

> ğŸ¯ **æ ¸å¿ƒæ€æƒ³çªç ´**ï¼šæ‰“ç ´â€œè¦ä¹ˆåˆå¹¶ï¼ˆmonolithicï¼‰ã€è¦ä¹ˆæ‹†åˆ†ï¼ˆsplitï¼‰â€çš„ä¼ ç»ŸèŒƒå¼ï¼Œå®ç° **é€»è¾‘è§£è€¦ + ç‰©ç†èµ„æºå…±äº«**ï¼Œå…¼é¡¾ä½å»¶è¿Ÿä¸é«˜ååã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
ä½¿ç”¨ä¸‰ç§çœŸå®ä¸–ç•Œå¤šæ¨¡æ€æ•°æ®é›†è¿›è¡Œè¯„ä¼°ï¼š
| æ•°æ®é›† | ç±»å‹ | æè¿° | è§†é¢‘æ—¶é•¿ |
|--------|------|------|---------|
| **MLVU** [69] | è§†é¢‘ | å¤šä»»åŠ¡é•¿è§†é¢‘ç†è§£ | 8â€“10 åˆ†é’Ÿ |
| **EgoSchema** [37] | è§†é¢‘ | å¤šä»»åŠ¡çŸ­è§†é¢‘ç†è§£ | ~3 åˆ†é’Ÿ |
| **VisionArena** [12] | å›¾åƒ | å›¾æ–‡é…å¯¹æè¿°ä»»åŠ¡ | â€” |

> æ³¨ï¼šä»…åœ¨ MLVU ä¸Šå¯ç”¨ FlashCodecï¼›EgoSchema å’Œ VisionArena ä½¿ç”¨ baseline çš„ Decord è§£ç å™¨ä»¥éªŒè¯ UnifiedServe è‡ªèº«ä¼˜åŠ¿ã€‚

### æ¨¡å‹é…ç½®
| æ¨¡å‹ | GPU æ•°é‡ | Vision Encoder å‚æ•°é‡ | LLM Decoder å‚æ•°é‡ | å†…å­˜å®¹é‡ |
|------|----------|------------------------|---------------------|-----------|
| Qwen2.5-VL-32B | 4Ã—A100 | 0.5B | 32B | 80Ã—4 GB |
| InternVL3-38B | 4Ã—A100 | 6B | 32B | 80Ã—4 GB |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
#### æ¨ç†æ¡†æ¶å¯¹æ¯”ï¼š
- **vLLM**ï¼šç»Ÿä¸€æœåŠ¡æ¶æ„ï¼Œæ”¯æŒ chunked-prefill (`vLLM-s`) å’Œ PD-disaggregation (`vLLM-d`)
- **SGLang**ï¼šç±»ä¼¼ vLLMï¼Œæä¾› `SGLang-s` å’Œ `SGLang-d`

#### è§†é¢‘è§£ç å™¨å¯¹æ¯”ï¼š
- **Decord**ï¼šå¹¿æ³›ä½¿ç”¨çš„å¤šåª’ä½“åŠ è½½åº“ï¼Œæ”¯æŒ CPU/CUDA
- **TorchCodec**ï¼šPyTorch å›¢é˜Ÿå¼€å‘ï¼Œæ”¯æŒç¡¬ä»¶åŠ é€Ÿ
- **DeepCodec**ï¼šçº¯ CPU è§£ç å™¨ï¼Œé€šè¿‡å¹¶è¡Œ GOP æå‡æ€§èƒ½
- **FlashCodec**ï¼ˆæœ¬æ–‡æå‡ºï¼‰

### è¯„ä¼°æŒ‡æ ‡
- **TTFT**ï¼ˆTime to First Tokenï¼‰ï¼šå¹³å‡ / P90 / P99
- **TBT**ï¼ˆTime Between Tokensï¼‰ï¼šå¹³å‡ / P99
- **E2E Latency**ï¼ˆç«¯åˆ°ç«¯å»¶è¿Ÿï¼‰
- **Throughput**ï¼ˆè¯·æ±‚ååç‡ï¼Œreq/sï¼‰
- **SLO Attainment**ï¼šåœ¨ç»™å®š SLO ä¸‹å¯æ”¯æ’‘çš„æœ€å¤§è¯·æ±‚é€Ÿç‡
- **èµ„æºåˆ©ç”¨ç‡ä¸æ‰©å±•æ€§**

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»
| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **æœ€å¤§ååæå‡** | â¬†ï¸ **4.4Ã—** vs. SOTA ç³»ç»Ÿï¼ˆå›¾14ï¼‰ |
| **å¯æœåŠ¡è¯·æ±‚æ•°æå‡** | â¬†ï¸ **3.0Ã—** |
| **SLO æ”¶ç´§èƒ½åŠ›** | å¯æ–½åŠ  **1.5Ã— æ›´ä¸¥æ ¼çš„ SLO** |
| **P99 TBT é™ä½** | â¬‡ï¸ **83%** vs. monolithic æ¶æ„ï¼ˆå›¾17ï¼‰ |
| **TTFT å‡å°‘** | åœ¨ MLVU ä¸Šæ¯” split æ¶æ„å‡å°‘ **80%** |
| **è§†é¢‘è§£ç å»¶è¿Ÿä¼˜åŒ–** | æœ€é«˜ **9Ã— å¿«äº DeepCodec**ï¼ˆ4Ã—A100ï¼‰ |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### ğŸ”¹ ååé‡å¯¹æ¯”ï¼ˆå›¾14ï¼‰
- **UnifiedServe** åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šå‡å–å¾—æœ€é«˜ååï¼š
  - åœ¨ MLVU ä¸Šè¾¾åˆ° **4.4Ã—** äº vLLM-s
  - split-based æ–¹æ³•ï¼ˆvLLM-d/SGLang-dï¼‰ååä»…ä¸º UnifiedServe çš„ **14%~51%**

#### ğŸ”¹ SLO è¾¾æˆèƒ½åŠ›ï¼ˆå›¾15ã€16ï¼‰
- åœ¨ç›¸åŒ SLO è¦æ±‚ä¸‹ï¼ŒUnifiedServe æ”¯æŒæ›´é«˜çš„è¯·æ±‚é€Ÿç‡ï¼ˆreq/sï¼‰ï¼š
  - åœ¨ MLVU åœºæ™¯ä¸­ï¼ŒUnifiedServe å¯æ»¡è¶³ 100% è¯·æ±‚çš„ SLOï¼Œè€Œå…¶ä»–æ–¹æ³•éš¾ä»¥åŒæ—¶æ»¡è¶³ TTFT å’Œ TBT SLOã€‚
- åœ¨æ›´ä¸¥æ ¼ SLO æ¡ä»¶ä¸‹ï¼ˆå›¾16ï¼‰ï¼ŒUnifiedServe å¯è¾¾æˆ **2å€ä»¥ä¸Š** çš„ SLO æ”¶ç´§èƒ½åŠ›ã€‚

#### ğŸ”¹ P99 TBT å¯¹æ¯”ï¼ˆå›¾17ï¼‰
- monolithic æ¶æ„å›  encoder å¹²æ‰°å¯¼è‡´ P99 TBT æé«˜ï¼ˆ>500msï¼‰
- split æ¶æ„è¡¨ç°æœ€å¥½ï¼ˆæ— å¹²æ‰°ï¼‰
- **UnifiedServe æ¥è¿‘ split è¡¨ç°ï¼Œæ˜¾è‘—ä¼˜äº monolithicï¼ˆé™ä½ 83%ï¼‰**

#### ğŸ”¹ è§†é¢‘è§£ç æ€§èƒ½ï¼ˆå›¾18ï¼‰
- FlashCodec åœ¨ H.264/H.265/VP9 ç¼–ç æ ¼å¼ä¸‹å‡å¤§å¹…é¢†å…ˆï¼š
  - å³ä½¿åœ¨ CPU å‹å¥½çš„ H.264 ä¸Šï¼ŒFlashCodecï¼ˆ4 GPUï¼‰ä»æ¯” DeepCodec å¿« **4 å€**
  - åœ¨ 4Ã—A100 ä¸Šï¼ŒFlashCodec å®ç° **sub-second è§£ç å»¶è¿Ÿ**

### æ¶ˆèå®éªŒï¼ˆéšå«åˆ†æï¼‰
è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†æ–‡ä¸­é€šè¿‡ä»¥ä¸‹æ–¹å¼éªŒè¯ç»„ä»¶æœ‰æ•ˆæ€§ï¼š
- **FlashCodec å•ç‹¬å¯ç”¨** â†’ æ˜¾è‘—é™ä½ TTFT
- **UnifiedServe ä¸å¯ç”¨ FlashCodec**ï¼ˆç”¨ Decordï¼‰â†’ ä»ä¼˜äº baselineï¼Œè¯´æ˜è°ƒåº¦æœºåˆ¶æœ¬èº«æœ‰æ•ˆ
- **èµ„æºç«äº‰å®éªŒè¯æ˜**ï¼šencode/pre-fill å¯¹ decode å½±å“å¤§ï¼Œåä¹‹è¾ƒå° â†’ æ”¯æŒâ€œdecode ä¼˜å…ˆ + èµ„æºå…±äº«â€ç­–ç•¥åˆç†æ€§

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **è§†é¢‘è§£ç æ˜¯ MLLM æ¨ç†çš„å…³é”®ç“¶é¢ˆ**ï¼Œå°¤å…¶åœ¨é•¿è§†é¢‘åœºæ™¯ä¸‹ä¸»å¯¼ TTFTã€‚
2. **ä¼ ç»Ÿ monolithic å’Œ split æ¶æ„å­˜åœ¨æ ¹æœ¬æƒè¡¡**ï¼šä¸€ä¸ªç‰ºç‰² TBTï¼Œä¸€ä¸ªç‰ºç‰² TTFT å’Œååã€‚
3. **ååŒå¤š GPU è§£ç å¯è¡Œä¸”é«˜æ•ˆ**ï¼šå°†å¤šä¸ª GPU çš„ NVDEC ååŒç”¨äºå•ä¸ªè§†é¢‘è§£ç ï¼Œå¯æ˜¾è‘—é™ä½å»¶è¿Ÿè€Œä¸ç‰ºç‰²ååã€‚
4. **é€»è¾‘è§£è€¦ + ç‰©ç†èµ„æºå…±äº«æ˜¯ç†æƒ³èŒƒå¼**ï¼š
   - é¿å…è·¨é˜¶æ®µé˜»å¡
   - æé«˜ GPU åˆ©ç”¨ç‡
   - å®ç°ä½ TTFT ä¸ä½ TBT å…¼é¡¾
5. **FlashCodec + UnifiedServe è”åˆä¼˜åŒ–æ•ˆæœæ˜¾è‘—**ï¼šå½¢æˆå®Œæ•´ç«¯åˆ°ç«¯ä¼˜åŒ–æ ˆï¼Œåœ¨å»¶è¿Ÿã€ååã€SLO æ”¯æŒæ–¹é¢å…¨é¢è¶…è¶Šç°æœ‰ç³»ç»Ÿã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–ç¡¬ä»¶è§£ç æ”¯æŒ**ï¼šFlashCodec ä¾èµ– NVDEC ç­‰ä¸“ç”¨ç¡¬ä»¶ï¼Œå¯èƒ½ä¸é€‚ç”¨äºæ‰€æœ‰ GPU å‹å·æˆ–äº‘ç¯å¢ƒã€‚
- **è°ƒåº¦å¤æ‚åº¦ä¸Šå‡**ï¼šå¼•å…¥å¤š Worker å¼‚æ­¥åè°ƒæœºåˆ¶ï¼Œå¢åŠ äº†ç³»ç»Ÿå®ç°å’Œè°ƒè¯•éš¾åº¦ã€‚
- **å½“å‰ä¸»è¦é¢å‘ç¦»çº¿/å‡†å®æ—¶åœºæ™¯**ï¼šå¯¹äºè¶…ä½å»¶è¿Ÿï¼ˆ<100msï¼‰äº¤äº’å¼åº”ç”¨ï¼Œä»éœ€è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚
- **æœªè€ƒè™‘è·¨èŠ‚ç‚¹æ‰©å±•**ï¼šç›®å‰èšç„¦å•æœºå¤šå¡ï¼Œæœªæ¶‰åŠåˆ†å¸ƒå¼é›†ç¾¤ä¸­çš„èµ„æºè°ƒåº¦ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **è·¨èŠ‚ç‚¹ disaggregated æ¶æ„**ï¼Œç»“åˆç½‘ç»œå¸¦å®½ä¼˜åŒ–ã€‚
- æ”¯æŒæ›´å¤š **ç¼–è§£ç æ ¼å¼ä¸ç¡¬ä»¶å¹³å°**ï¼ˆå¦‚ AMDã€Intel GPUï¼‰ã€‚
- è¿›ä¸€æ­¥æ¢ç´¢ **åŠ¨æ€èµ„æºåˆ†é…ç­–ç•¥**ï¼Œæ ¹æ® workload è‡ªé€‚åº”è°ƒæ•´ token budgetã€‚
- ç»“åˆ **ç®—æ³•çº§ä¼˜åŒ–**ï¼ˆå¦‚ visual token å‹ç¼©ï¼‰ä¸ç³»ç»Ÿçº§ä¼˜åŒ–ï¼Œå®ç°ç«¯åˆ°ç«¯æè‡´æ•ˆç‡ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> è¯¥è®ºæ–‡æå‡ºäº† **FlashCodec + UnifiedServe** è”åˆæ¡†æ¶ï¼Œé¦–æ¬¡å®ç°äº† MLLM å¤šé˜¶æ®µæ¨ç†çš„â€œ**ä½ TTFT + ä½ TBT + é«˜åå**â€ä¸‰é‡ç›®æ ‡ï¼Œé€šè¿‡ **ååŒ GPU è§£ç ** ä¸ **é€»è¾‘è§£è€¦ã€ç‰©ç†å…±äº«çš„è°ƒåº¦æ¶æ„**ï¼Œæ¨åŠ¨äº† MLLM serving ç³»ç»Ÿè®¾è®¡çš„æ–°èŒƒå¼ã€‚

</details>

---

### 3. [LLM-HPC++: Evaluating LLM-Generated Modern C++ and MPI+OpenMP Codes for Scalable Mandelbrot Set Computation](https://arxiv.org/abs/2512.17023)

**Authors**: Patrick Diehl, Noujoud Nader, Deepti Gupta  
**Category**: cs.DC  
**Published**: 2025-12-22  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2512.17023v1  

#### Abstract
Parallel programming remains one of the most challenging aspects of High-Performance Computing (HPC), requiring deep knowledge of synchronization, communication, and memory models. While modern C++ standards and frameworks like OpenMP and MPI have simplified parallelism, mastering these paradigms is...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLLM-HPC++: Evaluating LLM-Generated Modern C++ and MPI+OpenMP Codes for Scalable Mandelbrot Set Computation

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡ç³»ç»Ÿåœ°è¯„ä¼°äº†å½“å‰ä¸»æµ **Large Language Models (LLMs)** åœ¨ç”Ÿæˆé«˜æ€§èƒ½è®¡ç®—ï¼ˆHPCï¼‰é¢†åŸŸä¸­å¤æ‚ã€å¯æ‰©å±•çš„å¹¶è¡Œ C++ ä»£ç æ–¹é¢çš„èƒ½åŠ›ã€‚å°½ç®¡ LLMs å·²è¢«å¹¿æ³›ç”¨äºè‡ªåŠ¨åŒ–ä»£ç ç”Ÿæˆï¼Œä½†åœ¨æ¶‰åŠç°ä»£ C++ ç‰¹æ€§ï¼ˆå¦‚ `std::async`ã€`parallel algorithms`ã€`coroutines`ï¼‰ã€OpenMP å’Œ MPI+OpenMP æ··åˆç¼–ç¨‹ç­‰é«˜éš¾åº¦ HPC ç¼–ç¨‹èŒƒå¼æ—¶ï¼Œå…¶ç”Ÿæˆä»£ç çš„**æ­£ç¡®æ€§ã€å¥å£®æ€§å’Œå¯æ‰©å±•æ€§**å°šæœªå¾—åˆ°å……åˆ†éªŒè¯ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
- **ç»“æ„åŒ– Prompt è®¾è®¡**ï¼šè®¾è®¡äº†ä¸€å¥—æ ‡å‡†åŒ–çš„ promptï¼ˆP1â€“P3ï¼‰ï¼Œåˆ†åˆ«é’ˆå¯¹å…±äº«å†…å­˜ï¼ˆC++11/17/20ã€OpenMPï¼‰å’Œåˆ†å¸ƒå¼å†…å­˜ï¼ˆMPI+OpenMPï¼‰ç¼–ç¨‹æ¨¡å‹ï¼Œç¡®ä¿è·¨ LLM çš„å…¬å¹³æ¯”è¾ƒã€‚
- **ç«¯åˆ°ç«¯è¯„ä¼°æ¡†æ¶**ï¼šæå‡ºä¸€ä¸ªå®Œæ•´çš„è¯„ä¼°æµç¨‹ï¼Œæ¶µç›–ï¼š
  - **ç¼–è¯‘èƒ½åŠ›**ï¼ˆbuild successï¼‰
  - **è¿è¡Œæ—¶ç¨³å®šæ€§**ï¼ˆruntime errors, segfaultsï¼‰
  - **åŠŸèƒ½æ­£ç¡®æ€§**ï¼ˆvisual validation of Mandelbrot set in PBM formatï¼‰
  - **æ€§èƒ½å¯æ‰©å±•æ€§**ï¼ˆscaling on multi-core and cluster environmentsï¼‰
- **å¼•å…¥ COCOMO æˆæœ¬æ¨¡å‹**ï¼šé¦–æ¬¡å°†è½¯ä»¶å·¥ç¨‹ä¸­çš„ **Constructive Cost Model (COCOMO)** åº”ç”¨äºè¡¡é‡ AI ç”Ÿæˆ HPC ä»£ç çš„å¼€å‘éš¾åº¦ä¸è´¨é‡å…³ç³»ã€‚

### ç›¸æ¯”ç°æœ‰å·¥ä½œçš„ä¼˜åŠ¿
| æ–¹é¢ | æœ¬æ–‡ä¼˜åŠ¿ |
|------|---------|
| **è¯„ä¼°æ·±åº¦** | ä¸ä»…çœ‹æ˜¯å¦èƒ½â€œè·‘èµ·æ¥â€ï¼Œè¿˜æ·±å…¥åˆ†æ build/runtime é”™è¯¯æ¨¡å¼ã€è¯­ä¹‰ä¸€è‡´æ€§ã€çº¿ç¨‹æ§åˆ¶ã€é€šä¿¡é€»è¾‘ç­‰ |
| **è¦†ç›–å¹¿åº¦** | è¦†ç›–ä» native C++ å¹¶è¡Œç‰¹æ€§åˆ° OpenMP å†åˆ° MPI+OpenMP çš„å®Œæ•´ HPC ç¼–ç¨‹è°±ç³» |
| **é‡åŒ–åˆ†æ** | ä½¿ç”¨ LOCã€COCOMO effortã€scaling curves ç­‰å¤šç»´æŒ‡æ ‡è¿›è¡Œå®šé‡æ¯”è¾ƒ |
| **çœŸå®éƒ¨ç½²ç¯å¢ƒ** | æ‰€æœ‰ä»£ç å‡åœ¨çœŸå®é›†ç¾¤ï¼ˆrostam @ LSUï¼‰ä¸Šæµ‹è¯•ï¼Œä½¿ç”¨ GCC 11.5.0 + OpenMPI 5.0.7 |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„åŸºå‡†é—®é¢˜
- **Mandelbrot Set** ä½œä¸ºå…¸å‹â€œå°´å°¬å¹¶è¡Œâ€ï¼ˆembarrassingly parallelï¼‰ç§‘å­¦å¯è§†åŒ–ä»»åŠ¡ã€‚
- å‚æ•°å›ºå®šä¸ºï¼š1000 è¿­ä»£æ¬¡æ•°ï¼Œå›¾åƒåˆ†è¾¨ç‡é»˜è®¤ 1920Ã—1080ï¼ˆå¯è°ƒï¼‰ï¼Œä¸­å¿ƒç‚¹ $ c_{real} = -0.75, c_{img} = 0.0 $ï¼Œç¼©æ”¾å› å­ 3.0ã€‚
- è¾“å‡ºæ ¼å¼å¼ºåˆ¶ä¸º **PBMï¼ˆPortable Bitmap Formatï¼‰** â€”â€” ç®€å•æ–‡æœ¬æ ¼å¼ï¼Œæ— éœ€å¤–éƒ¨ä¾èµ–ï¼Œä¾¿äºéªŒè¯ã€‚

### å®éªŒè®¾ç½®
| ç»´åº¦ | è®¾ç½®è¯¦æƒ… |
|------|----------|
| **LLMs æµ‹è¯•å¯¹è±¡** | ChatGPT-4ã€ChatGPT-5ã€Claudeã€Llamaï¼ˆå…·ä½“ç‰ˆæœ¬æœªæ˜ç¤ºï¼‰ |
| **Prompt ç±»å‹** | <br>P1: C++11 async / C++17 parallel algorithms / C++20 coroutines<br>P2: OpenMP<br>P3: MPI+OpenMPï¼ˆéœ€æ”¯æŒ `-p` åˆ†åŒºå‚æ•°ï¼‰ |
| **ç¼–è¯‘å™¨ä¸å·¥å…·é“¾** | GCC 11.5.0, OpenMPI 5.0.7, Intel TBB 2022.2 |
| **ç¡¬ä»¶å¹³å°** | rostam é›†ç¾¤ï¼Œmedusa åˆ†åŒºï¼šIntel Xeon Gold 6148 (20 cores/node)ï¼Œå…± 16 èŠ‚ç‚¹ |
| **æ‰§è¡Œæ–¹å¼** | å•èŠ‚ç‚¹æµ‹è¯•å…±äº«å†…å­˜å¹¶è¡Œï¼›å¤šèŠ‚ç‚¹ï¼ˆ1â€“12ï¼‰æµ‹è¯•åˆ†å¸ƒå¼æ‰©å±•æ€§ |

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ç±»åˆ« | å…·ä½“æŒ‡æ ‡ |
|--------|---------|
| **Correctness** | æ˜¯å¦æˆåŠŸç¼–è¯‘ã€è¿è¡Œæ— å´©æºƒã€è¾“å‡ºå›¾åƒè§†è§‰æ­£ç¡® |
| **Robustness** | build/runtime error æ•°é‡åŠç±»å‹åˆ†ç±» |
| **Scalability** | å¤šæ ¸/å¤šèŠ‚ç‚¹ä¸‹çš„æ€§èƒ½æ‰©å±•æ›²çº¿ï¼ˆpixels/sec vs #cores/#nodesï¼‰ |
| **Code Quality** | Lines of Code (LOC)ã€COCOMO estimated effortï¼ˆäººæœˆï¼‰ |
| **Control Accuracy** | æ˜¯å¦æ­£ç¡®å“åº”å‘½ä»¤è¡Œå‚æ•°ï¼ˆå¦‚ `-t`, `-p` æ§åˆ¶çº¿ç¨‹/è¿›ç¨‹æ•°ï¼‰ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æœ¬æ–‡ä¸ä»¥ä¼ ç»Ÿæ‰‹å†™ HPC ä»£ç ä¸ºåŸºçº¿ï¼Œè€Œæ˜¯å°†ä¸åŒ LLM è§†ä¸ºâ€œæ™ºèƒ½ç¼–ç å™¨â€ï¼Œå½¼æ­¤äº’ä¸ºå¯¹ç…§ç»„ã€‚é‡ç‚¹åœ¨äºæ­ç¤ºå„æ¨¡å‹åœ¨ HPC åœºæ™¯ä¸‹çš„ç›¸å¯¹è¡¨ç°å·®å¼‚ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### âœ… è¡¨ 1 & 2ï¼šBuild/Runtime/Correctness æ€»ç»“ï¼ˆâœ“ = æ­£å¸¸ï¼Œâœ— = å­˜åœ¨é—®é¢˜ï¼‰

| LLM | Shared Memory | Distributed Memory |
|-----|----------------|--------------------|
| **ChatGPT-5** | æ‰€æœ‰å®ç°å‡å¯ç¼–è¯‘ã€è¿è¡Œã€ç»“æœæ­£ç¡® | å®Œå…¨æ­£ç¡®ï¼Œæ— ä»»ä½•é”™è¯¯ |
| **ChatGPT-4** | å¤šå¤„å¿½ç•¥å‘½ä»¤è¡Œå‚æ•°ï¼ŒTBB çº¿ç¨‹æ§åˆ¶å¤±æ•ˆ | å¯è¿è¡Œä¸”å¯æ‰©å±•ï¼Œé¢œè‰²æ˜ å°„ä¸€è‡´ |
| **Claude** | coroutine æ­»å¾ªç¯ï¼ˆéœ€ä¿®å¤ `final_suspend`ï¼‰ï¼Œå…¶ä½™åŸºæœ¬å¯ç”¨ | å®Œå…¨æ­£ç¡® |
| **Llama** | å¤šä¸ªç¼–è¯‘é”™è¯¯ã€segmentation faultã€å›¾åƒå…¨é»‘ç­‰é—®é¢˜ | ç¼–è¯‘é€šè¿‡ä½†å¤šè¿›ç¨‹ä¸‹ crashï¼ˆfree()/MPI buffer errorï¼‰ |

#### ğŸ“ è¡¨ 3ï¼šåˆ†å¸ƒå¼ä»£ç  LOC å¯¹æ¯”ï¼ˆå«æ³¨é‡Šï¼‰
| LLM | Lines of Code (LOC) |
|-----|---------------------|
| ChatGPT-5 | 143 |
| Claude    | 116 |
| ChatGPT-4 | 91  |
| Llama     | 71  |

> â¤ æ›´é•¿çš„ä»£ç é€šå¸¸æ„å‘³ç€æ›´å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ¨¡å—åŒ–è®¾è®¡ã€‚

#### â±ï¸ COCOMO Effort ä¼°è®¡ï¼ˆå›¾ 4 & 5ï¼‰
- **ChatGPT-5** ç”Ÿæˆä»£ç æ‰€éœ€ effort æœ€é«˜ï¼Œä½†è´¨é‡ä¹Ÿæœ€å¥½ï¼ˆå³ä¸Šè§’ï¼‰ã€‚
- **Llama** effort æœ€ä½ï¼Œä½†å­˜åœ¨ runtime é”™è¯¯ï¼Œå±â€œä¾¿å®œä½†ä¸å¯é â€ã€‚
- æ•´ä½“è¶‹åŠ¿ï¼šé«˜è´¨é‡ä»£ç å¾€å¾€éœ€è¦æ›´é«˜çš„å¼€å‘æˆæœ¬ï¼ˆå³ä½¿ç”± AI ç”Ÿæˆï¼‰ã€‚

#### ğŸ”¼ å›¾ 6 & 7ï¼šå¯æ‰©å±•æ€§ç»“æœ
- **å…±äº«å†…å­˜ï¼ˆå•èŠ‚ç‚¹ï¼‰**ï¼š
  - ChatGPT-5 æˆåŠŸå®ç°çº¿ç¨‹æ•°å¯æ§ï¼Œå¹¶è¡¨ç°å‡ºè‰¯å¥½çº¿æ€§æ‰©å±•ï¼ˆè‡³ 20 coresï¼‰ã€‚
  - ChatGPT-4ã€Claudeã€Llama å¤šæ•°æƒ…å†µä¸‹å¿½ç•¥ `-t` å‚æ•°ï¼Œé»˜è®¤ä½¿ç”¨å…¨éƒ¨æ ¸å¿ƒ â†’ è¡¨ç°ä¸ºâ€œæ°´å¹³ç›´çº¿â€ã€‚
- **åˆ†å¸ƒå¼å†…å­˜ï¼ˆ1â€“12 nodesï¼‰**ï¼š
  - æ‰€æœ‰ä¿®å¤åçš„ä»£ç éƒ½èƒ½å®ç°ä¸€å®šç¨‹åº¦çš„æ‰©å±•ã€‚
  - **å…±åŒç“¶é¢ˆ**ï¼šä» 2 åˆ° 4 ä¸ªèŠ‚ç‚¹æ—¶åŠ é€Ÿæ¯”ä¸‹é™æ˜æ˜¾ï¼ˆå¯èƒ½å› é€šä¿¡å¼€é”€çªå¢ï¼‰ã€‚
  - ChatGPT-4/5 ä¸ Claude æ€§èƒ½æ¥è¿‘ï¼ŒLlama ç»ä¿®æ­£åå¯è¾¾ç›¸ä¼¼æ°´å¹³ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **ChatGPT-5 è¡¨ç°æœ€ä½³**ï¼šåœ¨è¯­æ³•å‡†ç¡®æ€§ã€åŠŸèƒ½æ­£ç¡®æ€§ã€çº¿ç¨‹æ§åˆ¶ã€å¯æ‰©å±•æ€§ç­‰æ–¹é¢å…¨é¢é¢†å…ˆï¼Œæ˜¯ç›®å‰æœ€å¯é çš„ HPC ä»£ç ç”Ÿæˆå™¨ã€‚
2. âš ï¸ **ChatGPT-4 å­˜åœ¨çº¿ç¨‹ç®¡ç†ç¼ºé™·**ï¼šè™½èƒ½ç”Ÿæˆå¯è¿è¡Œä»£ç ï¼Œä½†æ— æ³•æœ‰æ•ˆæ§åˆ¶çº¿ç¨‹æ•°é‡ï¼ˆå°¤å…¶åœ¨ TBB åç«¯ä¸‹ï¼‰ï¼Œå½±å“æ€§èƒ½è°ƒä¼˜ã€‚
3. ğŸ’¡ **Claude å…·å¤‡æ½œåŠ›ä½†ç»†èŠ‚å‡ºé”™**ï¼šèƒ½ç”Ÿæˆç»“æ„è‰¯å¥½çš„ä»£ç ï¼Œä½†åœ¨åç¨‹ç”Ÿå‘½å‘¨æœŸç®¡ç†ä¸Šå‡ºç°è‡´å‘½é”™è¯¯ï¼ˆæ­»å¾ªç¯ï¼‰ï¼Œéœ€äººå·¥å¹²é¢„ã€‚
4. âŒ **Llama å½“å‰ä¸é€‚åˆ HPC ä»»åŠ¡**ï¼šé¢‘ç¹å‡ºç°ç¼–è¯‘é”™è¯¯ã€å†…å­˜é”™è¯¯ã€é€»è¾‘é”™è¯¯ï¼Œç”Ÿæˆä»£ç å¯é æ€§å·®ï¼Œè°ƒè¯•æˆæœ¬é«˜ã€‚
5. ğŸ¨ **åŒä¸€æ¨¡å‹å¯¹ä¸åŒèŒƒå¼é‡‡ç”¨ä¸ä¸€è‡´ç­–ç•¥**ï¼šä¾‹å¦‚ ChatGPT-5 åœ¨å…±äº«ä¸åˆ†å¸ƒç‰ˆæœ¬ä¸­ä½¿ç”¨äº†ä¸åŒçš„ color mapping å‡½æ•°ï¼Œæš´éœ²äº†ä¸Šä¸‹æ–‡ä¸€è‡´æ€§ä¸è¶³ã€‚
6. ğŸ§© **Prompt Engineering è‡³å…³é‡è¦**ï¼šåœ¨ MPI+OpenMP åœºæ™¯ä¸­ï¼Œå¿…é¡»æ˜ç¡®è¦æ±‚â€œworkload partitioningâ€ï¼Œå¦åˆ™æ¨¡å‹å€¾å‘äºé‡å¤è®¡ç®—è€Œéåˆ†å‘ä»»åŠ¡ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **è¯„ä¼°åŸºäºå•ä¸€åº”ç”¨ï¼ˆMandelbrotï¼‰**ï¼šè™½ç„¶å…·æœ‰ä»£è¡¨æ€§ï¼Œä½†ä»å±äºç®€å•è®¡ç®—å¯†é›†å‹ä»»åŠ¡ï¼Œæœªæ¶‰åŠå¤æ‚æ•°æ®ç»“æ„æˆ–æ•°å€¼æ±‚è§£å™¨ã€‚
- **æœªæµ‹è¯•æ›´å¤š LLMs**ï¼šç¼ºå°‘å¯¹ CodeLlamaã€DeepSeekã€StarCoder ç­‰ä¸“ä¸ºä»£ç è®­ç»ƒçš„æ¨¡å‹çš„å¯¹æ¯”ã€‚
- **COCOMO æ¨¡å‹é€‚ç”¨æ€§æœ‰é™**ï¼šè¯¥æ¨¡å‹åŸä¸ºä¸²è¡Œè½¯ä»¶è®¾è®¡ï¼Œåº”ç”¨äºå¹¶è¡Œ/HPC åœºæ™¯å­˜åœ¨ç†è®ºåå·®ã€‚
- **äººå·¥ä¿®å¤ä»‹å…¥è¾ƒå¤š**ï¼šéƒ¨åˆ†ç»“æœæ˜¯åœ¨ä½œè€…æ‰‹åŠ¨ä¿®å¤ build/runtime é”™è¯¯åå¾—å‡ºï¼Œåæ˜ çš„æ˜¯â€œå¯ä¿®å¤æ€§â€è€Œéâ€œå¼€ç®±å³ç”¨æ€§â€ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. æ„å»ºä¸“é—¨é¢å‘ HPC çš„ **LLM å¾®è°ƒæ•°æ®é›†**ï¼ˆå¦‚å¸¦æ³¨é‡Šçš„ MPI/OpenMP æ¨¡å¼åº“ï¼‰ã€‚
2. å¼€å‘ **HPC-aware prompt engineering framework**ï¼Œè‡ªåŠ¨å¼•å¯¼æ¨¡å‹ç”Ÿæˆç¬¦åˆæœ€ä½³å®è·µçš„ä»£ç ã€‚
3. æ¢ç´¢ **domain-specific LLMs**ï¼ˆå¦‚ Tokompilerã€MPIrigenï¼‰åœ¨ C++ HPC ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚
4. å»ºç«‹ç»Ÿä¸€çš„ **LLM-for-HPC benchmark suite**ï¼ŒåŒ…å«å¤šä¸ªç»å…¸å†…æ ¸ï¼ˆStencilã€N-bodyã€FFT ç­‰ï¼‰ã€‚
5. å¼•å…¥é™æ€åˆ†æå·¥å…·ï¼ˆå¦‚ Clang-Tidyï¼‰ä¸åŠ¨æ€æ£€æµ‹ï¼ˆValgrindã€MPI-Checkerï¼‰è”åˆè¯„ä¼°ç”Ÿæˆä»£ç è´¨é‡ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> å½“å‰æœ€å…ˆè¿›çš„ LLMsï¼ˆå°¤å…¶æ˜¯ ChatGPT-5ï¼‰å·²å…·å¤‡ç”Ÿæˆ**åŠŸèƒ½æ€§ã€å¯æ‰©å±•çš„ HPC å¹¶è¡Œä»£ç **çš„èƒ½åŠ›ï¼Œä½†åœ¨**ç²¾ç¡®æ§åˆ¶ã€èµ„æºç®¡ç†å’Œè¯­ä¹‰ä¸€è‡´æ€§**æ–¹é¢ä»å­˜åœ¨æ˜¾è‘—ç¼ºé™·ï¼Œè·ç¦»æ›¿ä»£äººç±»ä¸“å®¶ç¼–å†™ç”Ÿäº§çº§ HPC è½¯ä»¶è¿˜æœ‰è¾ƒé•¿è·¯ç¨‹ã€‚

</details>

---

### 4. [Learning solution operator of dynamical systems with diffusion maps kernel ridge regression](https://arxiv.org/abs/2512.17203)

**Authors**: Jiwoo Song, Daning Huang, John Harlim  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2512.17203v1  

#### Abstract
Many scientific and engineering systems exhibit complex nonlinear dynamics that are difficult to predict accurately over long time horizons. Although data-driven models have shown promise, their performance often deteriorates when the geometric structures governing long-term behavior are unknown or ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Learning Solution Operator of Dynamical Systems with Diffusion Maps Kernel Ridge Regression*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è®¸å¤šç§‘å­¦ä¸å·¥ç¨‹ç³»ç»Ÿè¡¨ç°å‡ºå¤æ‚çš„éçº¿æ€§åŠ¨åŠ›å­¦è¡Œä¸ºï¼Œå…¶é•¿æœŸæ¼”åŒ–å—é™äºæœªçŸ¥æˆ–éš¾ä»¥æ˜¾å¼å»ºæ¨¡çš„**å‡ ä½•ç»“æ„**ï¼ˆå¦‚å…‰æ»‘æµå½¢æˆ–åˆ†å½¢å¸å¼•å­ï¼‰ã€‚ä¼ ç»Ÿæ•°æ®é©±åŠ¨æ¨¡å‹ï¼ˆå¦‚ç¥ç»ç½‘ç»œã€éšæœºç‰¹å¾ï¼‰åœ¨ç¼ºä¹å¯¹è¿™äº›å†…åœ¨å‡ ä½•çº¦æŸçš„æœ‰æ•ˆç¼–ç æ—¶ï¼Œå¾€å¾€åœ¨é•¿æœŸé¢„æµ‹ä¸­è¡¨ç°ä¸ä½³ï¼Œå‡ºç°è½¨è¿¹åç¦»ä¸å˜é›†ï¼ˆinvariant setï¼‰çš„ç°è±¡ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º **Diffusion Maps Kernel Ridge Regression (DM-KRR)** çš„ç®€å•è€Œå¼ºå¤§çš„æ¡†æ¶ï¼Œç”¨äºå­¦ä¹ åŠ¨åŠ›ç³»ç»Ÿçš„è§£ç®—å­ï¼ˆsolution operatorï¼‰ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **åŸºäºæ‰©æ•£æ˜ å°„ï¼ˆDiffusion Maps, DMï¼‰çš„æ•°æ®é©±åŠ¨æ ¸å‡½æ•°**ï¼šåˆ©ç”¨DMç®—æ³•æ„å»ºä¸€ä¸ªèƒ½éšå¼æ•æ‰ç³»ç»Ÿä¸å˜é›†ï¼ˆforward invariant setï¼‰**å†…åœ¨å‡ ä½•ç»“æ„**çš„æ ‡é‡å€¼æ ¸å‡½æ•°ã€‚è¯¥æ ¸å‡½æ•°æ— éœ€æ˜¾å¼é‡å»ºæµå½¢æˆ–ä¼°è®¡åˆ‡ç©ºé—´ã€‚
- **è·³æ¥è¿æ¥å½¢å¼ï¼ˆskip-connection estimatorï¼‰**ï¼šå¯¹äºéåˆšæ€§ODEç³»ç»Ÿï¼Œé‡‡ç”¨ $ x(t_{n+1}) - x(t_n) \approx f(x(t_n)) $ å½¢å¼çš„KRRæ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†æ•°å€¼ç¨³å®šæ€§ä¸é¢„æµ‹ç²¾åº¦ã€‚
- **åŠ¨æ€æ„ŸçŸ¥çš„éªŒè¯ç­–ç•¥ï¼ˆdynamics-aware validationï¼‰**ï¼šé€šè¿‡åœ¨çŸ­æ—¶é—´çª—å£å†…è¿­ä»£æ¨¡å‹å¹¶è¯„ä¼°ç´¯ç§¯è¯¯å·®ï¼ˆå¦‚VPTï¼‰æ¥é€‰æ‹©è¶…å‚æ•°ï¼Œè€Œéä»…ä¼˜åŒ–ä¸€æ­¥é¢„æµ‹è¯¯å·®ï¼Œä»è€Œæå‡é•¿æœŸé¢„æµ‹èƒ½åŠ›ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ— éœ€æ˜¾å¼å‡ ä½•å»ºæ¨¡**ï¼šç›¸æ¯”éœ€è¦æ˜¾å¼æ„é€ æµå½¢åæ ‡ç³»æˆ–åˆ‡ç©ºé—´çš„GMKRRã€CANDyManç­‰æ–¹æ³•ï¼ŒDM-KRRå®Œå…¨ç”±æ•°æ®é©±åŠ¨ï¼Œé€‚ç”¨äºå…‰æ»‘ä¸éå…‰æ»‘ï¼ˆå¦‚æ··æ²Œå¸å¼•å­ï¼‰ä¸å˜é›†ã€‚
- **è®¡ç®—é«˜æ•ˆ**ï¼šç›¸æ¯”è®­ç»ƒæˆæœ¬é«˜æ˜‚çš„ç¥ç»ç½‘ç»œï¼ˆNNï¼‰ã€LDNetã€NODEç­‰ï¼ŒKRRå…·æœ‰è§£æè§£ï¼Œè®­ç»ƒé€Ÿåº¦å¿«ï¼Œè¶…å‚æ•°è°ƒä¼˜æ›´ç¨³å®šã€‚
- **æ ·æœ¬æ•ˆç‡é«˜**ï¼šåœ¨å°æ ·æœ¬æƒ…å†µä¸‹ï¼ˆå¦‚N=1024ï¼‰ï¼ŒDM-KRRå³å¯è¾¾åˆ°ç”šè‡³è¶…è¶Šéœ€æ•°ä¸‡æ ·æœ¬çš„SOTAéšæœºç‰¹å¾æ¨¡å‹ï¼ˆå¦‚DeepSkipï¼‰çš„é¢„æµ‹æ°´å¹³ã€‚
- **æ³›åŒ–æ€§å¼º**ï¼šåœ¨ä»ä½ç»´æ··æ²Œç³»ç»Ÿåˆ°é«˜ç»´æ—¶ç©ºæµåœºï¼ˆn=179101ï¼‰çš„å¤šç§ç³»ç»Ÿä¸Šå‡è¡¨ç°å‡ºè‰²ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–äº†å››ç±»å…¸å‹åŠ¨åŠ›ç³»ç»Ÿï¼Œæ¶µç›–ä¸åŒç»´åº¦ä¸å‡ ä½•ç‰¹æ€§ï¼š

| ç³»ç»Ÿ | ç±»å‹ | çŠ¶æ€ç»´åº¦ | ä¸å˜é›†æ€§è´¨ |
|------|------|----------|------------|
| **Torus Dynamics** | æµå½¢ç³»ç»Ÿ | 3, 7, 15 | å…‰æ»‘äºŒç»´å­æµå½¢ï¼ˆåŒèƒšäºçƒé¢éƒ¨åˆ†ï¼‰ |
| **Lorenz-63** | æ··æ²Œç³»ç»Ÿ | 3 | åˆ†å½¢å¸å¼•å­ï¼ˆfractal attractorï¼‰ï¼ŒLyapunovæŒ‡æ•° â‰ˆ 0.91 |
| **Kuramoto-Sivashinsky (KS) æ–¹ç¨‹** | é«˜ç»´æ··æ²ŒPDE | 64 | æ··æ²Œè¡Œæ³¢ï¼ŒKaplan-Yorkeç»´æ•°â‰ˆ5.2 |
| **KS è¡Œæ³¢ç³»ç»Ÿ** | å…‰æ»‘ä¸å˜é›†PDE | 64 | 2ç»´ç¯é¢ï¼ˆ2-torusï¼‰ï¼Œå«å¿«æ…¢æ—¶é—´å°ºåº¦ |
| **Pitch-Plunge Flat Plate** | é«˜ç»´çœŸå®æµä½“ç³»ç»Ÿ | 179101 | ç”±DNSç”Ÿæˆçš„éå®šå¸¸æ¶¡è¡—ï¼ŒPCAé™ç»´è‡³81ç»´ |

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **è®­ç»ƒ/éªŒè¯/æµ‹è¯•åˆ’åˆ†**ï¼šä½¿ç”¨é•¿æ—¶é—´åºåˆ—ç”Ÿæˆå¤šä¸ªè½¨è¿¹ï¼Œä¸¥æ ¼åˆ†ç¦»è®­ç»ƒã€éªŒè¯ä¸æµ‹è¯•é›†ã€‚
- **è¾“å…¥è¾“å‡ºæ„é€ **ï¼š
  - **ç›´æ¥å½¢å¼**ï¼š$ x(t_{n+1}) = f(x(t_n)) $
  - **è·³æ¥å½¢å¼**ï¼š$ x(t_{n+1}) - x(t_n) = f(x(t_n)) $
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **RMSE**ï¼šé¢„æµ‹è½¨è¿¹ä¸çœŸå®è½¨è¿¹çš„å‡æ–¹æ ¹è¯¯å·®ã€‚
  - **Valid Prediction Time (VPT)**ï¼šå½’ä¸€åŒ–è¯¯å·®ä½äºé˜ˆå€¼ $ \gamma $ çš„æœ€é•¿æ—¶é—´ï¼ˆä»¥Lyapunovæ—¶é—´ä¸ºå•ä½ï¼‰ï¼Œè¡¡é‡é•¿æœŸé¢„æµ‹èƒ½åŠ›ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **æ ¸æ–¹æ³•**ï¼šGaussian RBF Kernel KRRï¼ˆä½œä¸ºåŸºå‡†ï¼‰
- **ç¥ç»ç½‘ç»œæ–¹æ³•**ï¼š
  - **CANDyMan**ï¼šåŸºäºå›¾å†Œï¼ˆatlasï¼‰çš„æµå½¢å­¦ä¹ NN
  - **NODE**ï¼šç¥ç»ODE
  - **LDNet**ï¼šæ½œå˜é‡åŠ¨åŠ›å­¦ç½‘ç»œ
- **ç®—å­å­¦ä¹ /è°±æ–¹æ³•**ï¼š
  - **GMKRR**ï¼šå¸¦å‡ ä½•çº¦æŸçš„æ“ä½œç¬¦å€¼æ ¸KRR
  - **ResDMD**ï¼šå¸¦æ®‹å·®è¿‡æ»¤çš„åŠ¨æ€æ¨¡æ€åˆ†è§£
- **éšæœºç‰¹å¾æ–¹æ³•**ï¼š**DeepSkip**ï¼ˆæ¥è‡ª[24]çš„SOTAéšæœºç‰¹å¾æ¨¡å‹ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”

#### ï¼ˆ1ï¼‰Torus åŠ¨åŠ›å­¦ï¼ˆæµå½¢ç³»ç»Ÿï¼‰
- **æ”¶æ•›é€Ÿåº¦**ï¼šDM-KRRçš„RMSEéšè®­ç»ƒæ ·æœ¬æ•° $ N $ æ”¶æ•›é€Ÿç‡è¿œå¿«äºRBF-KRRï¼ˆå¦‚ $ O(N^{-5.06}) $ vs $ O(N^{-3.87}) $ï¼‰ã€‚
- **è¯¯å·®é™ä½**ï¼šå½“ $ N=8192 $ æ—¶ï¼ŒDMçš„RMSEæ¯”RBFä½çº¦ä¸€ä¸ªæ•°é‡çº§ã€‚

#### ï¼ˆ2ï¼‰Lorenz-63 æ··æ²Œç³»ç»Ÿï¼ˆè¡¨1ï¼‰
| Model | N=512 | N=1024 | N=2048 | N=4096 |
|-------|--------|---------|---------|---------|
| **DM-KRR** | 11.03Â±2.41 | **13.18Â±1.25** | **13.84Â±0.59** | **14.10Â±0.46** |
| **RBF-KRR** | 8.87Â±1.71 | 11.20Â±1.42 | 12.72Â±0.92 | 13.47Â±0.61 |

- **å…³é”®å‘ç°**ï¼šDM-KRRåœ¨æ‰€æœ‰æ•°æ®è§„æ¨¡ä¸‹å‡ä¼˜äºRBFï¼Œä¸”åœ¨ $ N=1024 $ æ—¶å³è¾¾åˆ°13.18 VPTï¼Œ**ä»…ç”¨4024æ ·æœ¬**ï¼Œä¼˜äºä½¿ç”¨50000æ ·æœ¬çš„DeepSkipï¼ˆVPT=12.02ï¼‰ã€‚

#### ï¼ˆ3ï¼‰KS æ··æ²Œç³»ç»Ÿï¼ˆè¡¨2ï¼‰
| Model | N=2048 | N=4096 | N=8192 | N=16384 |
|-------|--------|---------|---------|----------|
| **DM-KRR** | 0.86Â±0.15 | **1.72Â±0.18** | **3.12Â±0.21** | **4.98Â±0.23** |
| **RBF-KRR** | 0.79Â±0.13 | 1.49Â±0.21 | 2.72Â±0.26 | 4.31Â±0.33 |

- DM-KRRåœ¨æ‰€æœ‰è§„æ¨¡ä¸‹å‡é¢†å…ˆï¼Œä¸”å·®è·éšæ•°æ®å¢åŠ è€Œæ‰©å¤§ï¼Œæ˜¾ç¤ºæ›´å¼ºçš„æ•°æ®åˆ©ç”¨ç‡ã€‚

#### ï¼ˆ4ï¼‰KS è¡Œæ³¢ç³»ç»Ÿï¼ˆå…‰æ»‘2-torusï¼‰
- **RMSEå¯¹æ¯”**ï¼ˆè§å›¾3ï¼‰ï¼š
  - DM-KRR: $ 1.06 \times 10^{-7} $
  - RBF-KRR: $ 1.78 \times 10^{-6} $
  - GMKRR: $ 7.52 \times 10^{-16} $ï¼ˆä¾èµ–å…ˆéªŒçŸ¥è¯†ï¼‰
  - CANDyMan/NODE/LDNet: $ >6.69 $ï¼ˆå®Œå…¨å¤±æ•ˆï¼‰
- **ç»“è®º**ï¼šå³ä½¿ä¸ä½¿ç”¨ä»»ä½•å…ˆéªŒå‡ ä½•ä¿¡æ¯ï¼ŒDM-KRRä»æ¯”å¤æ‚NNæ¨¡å‹å¥½5â€“6ä¸ªæ•°é‡çº§ï¼Œä¸”ä¼˜äºæœªç²¾ç¡®ä¼°è®¡åˆ‡ç©ºé—´çš„GMKRRã€‚

#### ï¼ˆ5ï¼‰Pitch-Plunge å¹³æ¿ï¼ˆé«˜ç»´æµä½“ï¼‰
- **NRMSE @ t=80s**ï¼š
  - **DM-KRR**: 0.262
  - **ResDMD**: 0.323
  - **RBF-KRR**: 0.857ï¼ˆå‡ ä¹æ— æ³•æ•æ‰æ¶¡è„±è½ï¼‰
- **é•¿æœŸè¯¯å·®è¶‹åŠ¿**ï¼šDM-KRRåœ¨æ•´ä¸ª80ç§’ï¼ˆçº¦20å‘¨æœŸï¼‰é¢„æµ‹ä¸­ä¿æŒè¯¯å·®ç¨³å®šï¼Œè€ŒResDMDè¯¯å·®æŒç»­å¢é•¿ï¼Œè¡¨æ˜å…¶æœªèƒ½ä¿æŒå‡ ä½•ä¸€è‡´æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç®€å•æ–¹æ³•å¯èƒœè¿‡å¤æ‚æ¶æ„**ï¼šä¸€ä¸ªç®€å•çš„**æ ‡é‡æ ¸KRRæ¡†æ¶**ï¼Œé…åˆ**åŠ¨æ€æ„ŸçŸ¥éªŒè¯ç­–ç•¥**ï¼Œå³å¯åœ¨å¤šç§ç³»ç»Ÿä¸Šè¶…è¶ŠSOTAçš„ç¥ç»ç½‘ç»œã€éšæœºç‰¹å¾ä¸ç®—å­å­¦ä¹ æ–¹æ³•ã€‚
2. **å‡ ä½•æ„ŸçŸ¥æ˜¯é•¿æœŸé¢„æµ‹çš„å…³é”®**ï¼šDMæ ¸é€šè¿‡é€¼è¿‘çƒ­æ ¸ï¼ˆheat kernelï¼‰éšå¼ç¼–ç äº†ä¸å˜é›†çš„å†…åœ¨å‡ ä½•ï¼Œä½¿å¾—å­¦ä¹ åˆ°çš„åŠ¨åŠ›ç³»ç»Ÿè‡ªç„¶â€œå°Šé‡â€å…¶å‡ ä½•çº¦æŸï¼Œé¿å…è½¨è¿¹æ¼‚ç§»ã€‚
3. **DMæ ¸ä¼˜äºRBFæ ¸**ï¼šåœ¨æ‰€æœ‰å®éªŒä¸­ï¼ŒDM-KRRåœ¨**å‡†ç¡®æ€§**ä¸**æ ·æœ¬æ•ˆç‡**ä¸Šå‡æ˜¾è‘—ä¼˜äºæ ‡å‡†RBFæ ¸ï¼Œå°¤å…¶åœ¨å°æ ·æœ¬ä¸é«˜ç»´åœºæ™¯ä¸‹ä¼˜åŠ¿æ˜æ˜¾ã€‚
4. **éªŒè¯ç­–ç•¥è‡³å…³é‡è¦**ï¼šä½¿ç”¨çŸ­æœŸè¿­ä»£é¢„æµ‹çš„VPTä½œä¸ºéªŒè¯æŒ‡æ ‡ï¼Œæ¯”å•çº¯æœ€å°åŒ–ä¸€æ­¥RMSEæ›´èƒ½é€‰å‡ºé€‚åˆé•¿æœŸé¢„æµ‹çš„æ¨¡å‹ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **è®¡ç®—å¤æ‚åº¦**ï¼šæ ‡å‡†KRRä¸º $ O(N^3) $ï¼Œé™åˆ¶äº†å…¶åœ¨è¶…å¤§è§„æ¨¡æ•°æ®ä¸Šçš„åº”ç”¨ï¼ˆå°½ç®¡å¯é€šè¿‡ç¨€ç–Choleskyã€NystrÃ¶mç­‰åŠ é€Ÿï¼‰ã€‚
- **å›ºå®šå¸¦å®½DMæ ¸**ï¼šå½“å‰å®ç°ä½¿ç”¨å›ºå®šå¸¦å®½ï¼Œå¯èƒ½åœ¨éå‡åŒ€é‡‡æ ·æˆ–å¯†åº¦å˜åŒ–å‰§çƒˆçš„æµå½¢ä¸Šè¡¨ç°ä¸ä½³ï¼›å¯æ‰©å±•è‡³variable bandwidth DMã€‚
- **å™ªå£°æ•æ„Ÿæ€§**ï¼šé«˜å™ªå£°æ•°æ®å¯èƒ½å½±å“DMæ ¸çš„è´¨é‡ï¼Œæœªæ¥å¯ç»“åˆKalmanæ»¤æ³¢ç­‰è¿›è¡Œå»å™ªã€‚
- **ç†è®ºæ”¶æ•›æ€§å¾…å®Œå–„**ï¼šå¯¹æ··æ²Œç³»ç»Ÿï¼ˆéå…‰æ»‘ä¸å˜é›†ï¼‰ä¸‹çš„æ”¶æ•›æ€§å°šæ— ä¸¥æ ¼è¯æ˜ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **ç†è®ºå±‚é¢**ï¼š
  - åˆ»ç”»æœ‰é™ $ N $ å’Œ $ \epsilon $ ä¸‹DM-KRRå¯¹åº”çš„RKHSæé™ç©ºé—´ã€‚
  - å»ºç«‹å¯¹æ··æ²Œç³»ç»Ÿè§£ç®—å­çš„å­¦ä¹ æ”¶æ•›ä¿è¯ã€‚
- **è®¡ç®—å±‚é¢**ï¼š
  - å¼•å…¥å¿«é€Ÿæ±‚è§£å™¨ï¼ˆå¦‚randomized sketchingã€sparse Choleskyï¼‰ä»¥æ”¯æŒæ›´å¤§è§„æ¨¡æ•°æ®æˆ–å®æ—¶éƒ¨ç½²ã€‚
- **æ–¹æ³•æ”¹è¿›**ï¼š
  - ä½¿ç”¨**variable bandwidth DM**ä»¥æ›´å¥½å¤„ç†éå‡åŒ€å¯†åº¦æµå½¢ã€‚
  - ç»“åˆ**è‡ªé€‚åº”é‡‡æ ·**æˆ–**å¤šè½¨è¿¹å®éªŒè®¾è®¡**ä»¥è¿›ä¸€æ­¥å‡å°‘é«˜ç»´PDEä¸­çš„æ•°æ®éœ€æ±‚ã€‚
  - æ¢ç´¢å°†KRRä¸**æ•°æ®åŒåŒ–**ï¼ˆå¦‚Kalmanæ»¤æ³¢ï¼‰ç»“åˆä»¥æå‡æŠ—å™ªèƒ½åŠ›ã€‚

---

> **æ€»ç»“**ï¼šæœ¬æ–‡å±•ç¤ºäº†**â€œç®€å• + å‡ ä½•æ„ŸçŸ¥ + æ­£ç¡®éªŒè¯â€** çš„å¼ºå¤§ç»„åˆã€‚DM-KRRä¸ä»…åœ¨æ€§èƒ½ä¸Šå…¨é¢è¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œè€Œä¸”åœ¨å®ç°å¤æ‚åº¦ã€è®­ç»ƒæˆæœ¬å’Œé²æ£’æ€§æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œä¸ºå¯é ã€é«˜æ•ˆçš„å¤æ‚åŠ¨åŠ›ç³»ç»Ÿå­¦ä¹ æä¾›äº†ä¸€æ¡æå…·å‰æ™¯çš„è·¯å¾„ã€‚

</details>

---

### 5. [Atom: Efficient On-Device Video-Language Pipelines Through Modular Reuse](https://arxiv.org/abs/2512.17108)

**Authors**: Kunjal Panchal, Saayan Mitra, Somdeb Sarkhel, Haoliang Wang, Ishita Dasgupta, Gang Wu, Hui Guan  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.17108v1  

#### Abstract
Recent advances in video-language models have enabled powerful applications like video retrieval, captioning, and assembly. However, executing such multi-stage pipelines efficiently on mobile devices remains challenging due to redundant model loads and fragmented execution. We introduce Atom, an on-...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šATOM: Efficient On-Device Video-Language Pipelines Through Modular Reuse**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å½“å‰çš„ **Video-Language Model (VLM)** å¤šé˜¶æ®µæ¨ç†ç®¡é“ï¼ˆå¦‚è§†é¢‘æ£€ç´¢ã€å­—å¹•ç”Ÿæˆã€è§†é¢‘å‰ªè¾‘ç»„è£…ï¼‰åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šæ‰§è¡Œæ—¶é¢ä¸´æ˜¾è‘—æŒ‘æˆ˜ï¼š
- **å†…å­˜å‹åŠ›å¤§**ï¼šå¤šä¸ªç‹¬ç«‹æ¨¡å‹ï¼ˆå¦‚è§†è§‰ç¼–ç å™¨ã€è¯­è¨€è§£ç å™¨ã€è„šæœ¬ç”Ÿæˆæ¨¡å‹ï¼‰éœ€ä¾æ¬¡åŠ è½½ï¼Œå ç”¨å¤§é‡ RAMï¼ˆä¾‹å¦‚ mPLUG2 + Llama 3.2 éœ€çº¦ 7GBï¼‰ï¼Œè¶…å‡ºå¤šæ•°æ‰‹æœº 6â€“8GB å†…å­˜é™åˆ¶ã€‚
- **å»¶è¿Ÿé«˜**ï¼šç”±äºæ¨¡å‹åå¤åŠ è½½ä¸ä¸²è¡Œæ‰§è¡Œï¼Œå¯¼è‡´ç«¯åˆ°ç«¯å»¶è¿Ÿå¢åŠ ï¼ˆå®æµ‹é«˜è¾¾ 17% å¢å¹…ï¼‰ã€‚
- **ç¼ºä¹æ¨¡å—å¤ç”¨**ï¼šä¼ ç»Ÿæµæ°´çº¿ä¸­å„å­ä»»åŠ¡ä½¿ç”¨ä¸åŒæ¨¡å‹ï¼Œæ— æ³•å…±äº«è®¡ç®—æ¨¡å—ï¼Œé€ æˆå†—ä½™ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯**
ä½œè€…æå‡º **ATOM** â€”â€”ä¸€ç§é¢å‘ç§»åŠ¨ç«¯çš„é«˜æ•ˆ **reuse-centricï¼ˆå¤ç”¨ä¸ºä¸­å¿ƒï¼‰** è§†é¢‘-è¯­è¨€æ¨ç†ç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å°†ä¸€ä¸ªå¤§å‹ VLM æ¨¡å‹åˆ†è§£ä¸ºå¯æŒä¹…é©»ç•™å†…å­˜çš„**å¯é‡ç”¨æ¨¡å—**ï¼ˆmodular reuseï¼‰ï¼š
  - **Visual Encoder**ï¼ˆè§†è§‰ç¼–ç å™¨ï¼‰
  - **Generalizable Language Decoder**ï¼ˆé€šç”¨è¯­è¨€è§£ç å™¨ï¼‰
- æ‰€æœ‰å­ä»»åŠ¡ï¼ˆå¦‚å­—å¹•ç”Ÿæˆã€è„šæœ¬ç”Ÿæˆã€è¯­ä¹‰åŒ¹é…ï¼‰å‡å¤ç”¨è¿™ä¸¤ä¸ªæ¨¡å—ï¼Œé¿å…é‡å¤åŠ è½½ã€‚
- æ”¯æŒ**å¹¶è¡Œæ‰§è¡Œ**ï¼šå½“è§£ç å™¨ä¸º clip #1 ç”Ÿæˆå­—å¹•æ—¶ï¼Œç¼–ç å™¨å¯åŒæ—¶å¤„ç† clip #2ï¼Œå®ç°æµæ°´çº¿çº§å¹¶è¡Œã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | ATOM |
|------|--------|------|
| **æ¨¡å‹ç®¡ç†** | å¤šä¸ªç‹¬ç«‹æ¨¡å‹ï¼Œé¢‘ç¹åŠ è½½å¸è½½ | å•ä¸€æ¨¡å‹æ‹†åˆ†ä¸ºæŒä¹…æ¨¡å—ï¼Œå…¨ç¨‹å¤ç”¨ |
| **æ‰§è¡Œæ¨¡å¼** | ä¸¥æ ¼ä¸²è¡Œ | æ¨¡å—é—´å¹¶è¡Œï¼Œæ”¯æŒè·¨è¾“å…¥å¹¶å‘ |
| **å†…å­˜å¼€é”€** | é«˜ï¼ˆéœ€åˆ‡æ¢æ¨¡å‹ï¼‰ | å‡ ä¹ä¸å˜ï¼ˆä»…å¢ 0.76%ï¼Œ~40MBï¼‰ |
| **ç«¯åˆ°ç«¯å»¶è¿Ÿ** | é«˜ï¼ˆå—åŠ è½½å½±å“ï¼‰ | ä¸‹é™ 27â€“33% |
| **è¾“å‡ºè´¨é‡** | é«˜ | ä»…æœ‰è½»å¾®ä¸‹é™ï¼ˆâ‰¤2.3 Recall@1, â‰¤1.5 CIDErï¼‰ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **MSR-VTT**ï¼š10K YouTube è§†é¢‘ï¼Œ200K å­—å¹•ï¼Œç”¨äºè®­ç»ƒå’Œæµ‹è¯•ã€‚
- **MSVD**ï¼š1.97K YouTube è§†é¢‘ï¼Œå¸¦äººå·¥æ ‡æ³¨å­—å¹•ã€‚
- **DiDeMo**ï¼š10K Flickr è§†é¢‘ï¼Œæ¯æ®µé… 4 æ¡æè¿°æ–‡æœ¬ï¼Œç”¨äºç»†ç²’åº¦å®šä½ä»»åŠ¡ã€‚

æ‰€æœ‰æ¨¡å‹åœ¨ä¸‰è€…æ··åˆè®­ç»ƒé›†ä¸Šå¾®è°ƒï¼Œåœ¨å„è‡ªæµ‹è¯•é›†ä¸Šè¯„ä¼°ã€‚

### **å®éªŒè®¾ç½®**
- **ç¡¬ä»¶å¹³å°**ï¼š
  - ç§»åŠ¨ç«¯ï¼šGoogle Pixel 5a (6GB RAM), Pixel 8a, Samsung Galaxy S23
  - æœåŠ¡å™¨ç«¯ï¼šx86_64 CPUï¼ˆ96æ ¸ï¼‰ã€NVIDIA A40 GPU
- **éƒ¨ç½²æ¡†æ¶**ï¼šPyTorch Mobile + **TorchAO** è¿›è¡ŒåŠ¨æ€é‡åŒ–ä¸ç®—å­èåˆ
- **é‡åŒ–ç­–ç•¥**ï¼šå¯¹ LINEAR å’Œ EMBEDDING å±‚è¿›è¡Œ **int8 åŠ¨æ€é‡åŒ–**ï¼Œä¿ç•™ CLIP-ViT å’Œ Llama ä¸»å¹²
- **è¾“å…¥æ ¼å¼**ï¼š`(1, 3, 6, 224, 224)`ï¼ˆbatch, channel, frame, H, Wï¼‰ï¼Œå¸§ç‡ 6fps

### **è¯„ä¼°æŒ‡æ ‡**
| ä»»åŠ¡ | æŒ‡æ ‡ |
|------|------|
| **Video Captioning** | BLEU@4, ROUGE-L, METEOR, CIDEr |
| **Video Retrieval** | Recall@1, Recall@5, Recall@10 |
| **Video Assembly** | å®šæ€§åˆ†æï¼ˆäººç±»è¯„åˆ†ï¼‰ï¼šAdherence, Coherence, Engagement ç­‰ |
| **æ•ˆç‡æŒ‡æ ‡** | ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆç§’ï¼‰ã€å³°å€¼å†…å­˜ï¼ˆGBï¼‰ã€æ¨¡å‹åŠ è½½æ—¶é—´ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **Non-reuse Baseline**ï¼šä¼ ç»Ÿå¤šæ¨¡å‹ä¸²è¡Œæµæ°´çº¿ï¼Œæ¯ä¸ªé˜¶æ®µå•ç‹¬åŠ è½½æ¨¡å‹ï¼ˆå¦‚ captioning ç”¨ mPLUG2ï¼Œscript generation ç”¨ Llama 3.2ï¼‰
- **Server-side Systems**ï¼šä¾èµ–äº‘ç«¯å¤§æ¨¡å‹ï¼ˆå¦‚ RATV, TV-MGIï¼‰ï¼Œä¸é€‚ç”¨äºè¾¹ç¼˜åœºæ™¯
- **é‡åŒ–ç‰ˆæœ¬å¯¹æ¯”**ï¼šæ¯”è¾ƒ float32 ä¸ int8 ç‰ˆæœ¬æ€§èƒ½å·®å¼‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### âœ… **æ€§èƒ½ä¿æŒè‰¯å¥½**
| æ¨¡å‹ | CIDEr â†‘ | Recall@1 â†‘ |
|------|--------|-----------|
| mPLUG2 (åŸç‰ˆ, BERT decoder) | 79.4 (MSR-VTT) | 52.6 (MSR-VTT) |
| **mPLUG2+ (ATOM, Llama decoder)** | **83.1** (+3.7) | **57.2** (+4.9) |
| mPLUG2+ (int8) | 82.5 (-0.6) | 55.8 (-1.4) |

> ç»“è®ºï¼šä½¿ç”¨æ›´å¼ºçš„ Llama è§£ç å™¨æ˜¾è‘—æå‡æ€§èƒ½ï¼›é‡åŒ–åä»…è½»å¾®ä¸‹é™ã€‚

#### âœ… **å»¶è¿Ÿå¤§å¹…é™ä½**
| è®¾å¤‡ | ä»»åŠ¡ | å»¶è¿Ÿä¸‹é™å¹…åº¦ |
|------|------|-------------|
| Pixel 5a | Video Retrieval | â†“33.06% |
| Pixel 5a | Video Assembly | â†“30.78% |
| Pixel 8a | Retrieval / Assembly | â†“30.43% / â†“27.69% |
| Galaxy S23 | Retrieval / Assembly | â†“29.14% / â†“27.54% |

> å¹³å‡æé€Ÿ **27â€“33%**ï¼Œä¸»è¦æ¥è‡ªï¼š
> - æ¨¡å—å¤ç”¨å‡å°‘åŠ è½½æ—¶é—´ï¼ˆæœ€é«˜ â†“50% åŠ è½½å»¶è¿Ÿï¼‰
> - å¹¶è¡Œæ‰§è¡Œæå‡åå

#### âœ… **å†…å­˜å‡ ä¹æ— å¢é•¿**
| é…ç½® | å³°å€¼å†…å­˜ |
|------|---------|
| Non-reuse Baseline | 5.277 GB |
| **ATOM (reuse + parallel)** | **5.317 GB** |
| å·®å¼‚ | **+0.76% (~40MB)** |

> å°½ç®¡æ¿€æ´»å†…å­˜ä¸Šå‡ï¼ˆå› å¹¶è¡Œï¼‰ï¼Œä½†èŠ‚çœäº†æ¨¡å‹åŠ è½½ä¸´æ—¶ç¼“å†²åŒºï¼ˆmiscellaneous allocations â†“40.34%ï¼‰ï¼Œå‡€å¢æå°ã€‚

#### âœ… **å­˜å‚¨å¯è¡Œ**
| ç»„ä»¶ | å¤§å° |
|------|-----|
| mPLUG2+ (é‡åŒ–) | 1.23 GB |
| Sentence Transformer (all-MiniLM-L6-v2) | 53 MB |
| **æ€»è®¡** | **1.28 GB** |

> å¯è½»æ¾éƒ¨ç½²äºä¸»æµæ™ºèƒ½æ‰‹æœºã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**
åœ¨ Pixel 5a ä¸Šæµ‹è¯•ä¸åŒé…ç½®çš„å½±å“ï¼š

| è¾“å…¥/è¶…å‚å˜åŒ– | Latency | CIDEr | è¯´æ˜ |
|---------------|--------|-------|------|
| é»˜è®¤ `(1,3,6,224,224)` | 5.57s | 82.5 | åŸºå‡† |
| åˆ†è¾¨ç‡é™è‡³ 112Ã—112 | 3.29s | 75.64 | è½»å¾®æŸå¤±ï¼Œæ€§ä»·æ¯”é«˜ |
| å¸§ç‡ä» 6â†’2 fps | 4.78s | 50.89 | æ€§èƒ½éª¤é™ï¼Œä¸å¯å– |
| Beam size=1 | 3.07s | 40.98 | ç”Ÿæˆè´¨é‡ä¸¥é‡é€€åŒ– |
| Batch size=4 | 22.35s | 82.5 | ç§»åŠ¨ç«¯æ— åŠ é€Ÿæ”¶ç›Š |
| è¾“å‡ºé•¿åº¦ trace=12 | 4.55s | 74.19 | ä¸è¶³è¦†ç›–å®Œæ•´è¯­ä¹‰ |

> å¯ç¤ºï¼šåˆ†è¾¨ç‡å¯é€‚å½“å‹ç¼©ï¼Œä½†å¸§ç‡ã€beam searchã€è¾“å‡ºé•¿åº¦ä¸å®œè¿‡åº¦å‰Šå‡ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **æ¨¡å—åŒ–å¤ç”¨æ˜¯ç§»åŠ¨ç«¯ VLM æµæ°´çº¿çš„å…³é”®ä¼˜åŒ–æ–¹å‘**ï¼š
   - é€šè¿‡å°† VLM æ‹†åˆ†ä¸ºå¯æŒä¹…é©»ç•™çš„ encoder å’Œ decoderï¼Œæ¶ˆé™¤é‡å¤åŠ è½½å¼€é”€ã€‚
2. **å¹¶è¡Œæ‰§è¡Œæ˜¾è‘—æå‡ç¡¬ä»¶åˆ©ç”¨ç‡**ï¼š
   - ç¼–ç ä¸è§£ç å¯é‡å æ‰§è¡Œï¼Œå……åˆ†åˆ©ç”¨ CPU å¤šçº¿ç¨‹èƒ½åŠ›ã€‚
3. **å¼ºç»Ÿä¸€è§£ç å™¨ä¼˜äºå¤šä¸ªè½»é‡ä¸“ç”¨æ¨¡å‹**ï¼š
   - ä½¿ç”¨å•ä¸€ Llama 3.2 è§£ç å™¨æœåŠ¡ captioningã€script generationã€reasoningï¼Œæ—¢æå‡è´¨é‡åˆç®€åŒ–ç³»ç»Ÿã€‚
4. **é‡åŒ–ä¸å¤ç”¨è®¾è®¡æ­£äº¤ä¸”äº’è¡¥**ï¼š
   - int8 é‡åŒ–è¿›ä¸€æ­¥å‹ç¼©å†…å­˜ï¼Œè€Œ ATOM çš„è®¾è®¡ç¼“è§£äº†é‡åŒ–å¸¦æ¥çš„åŠ¨æ€è½¬æ¢å»¶è¿Ÿã€‚
5. **ç«¯åˆ°ç«¯èŠ‚èƒ½æ˜¾è‘—**ï¼š
   - åœ¨ Pixel 5a ä¸Šä¼°ç®—ï¼Œèƒ½é‡æ¶ˆè€—é™ä½çº¦ **46%**ï¼Œä¸»è¦å¾—ç›Šäº CPU æ´»è·ƒæ—¶é—´ç¼©çŸ­ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–æ¨¡å—åŒ–è§£æ„çš„ VLM æ¶æ„**ï¼šå¯¹äºæ—©æœŸ tightly-coupled æ¨¡å‹ï¼ˆå¦‚å«è·¨æ¨¡æ€æ³¨æ„åŠ›å±‚ï¼‰éš¾ä»¥ç›´æ¥æ‹†åˆ†ã€‚
- **å¹¶è¡Œå¸¦æ¥å°å¹…å†…å­˜ä¸Šæ¶¨**ï¼šè™½ç„¶æ€»ä½“å¯æ§ï¼ˆ+40MBï¼‰ï¼Œä½†åœ¨æç«¯ä½å†…å­˜è®¾å¤‡ï¼ˆ<6GBï¼‰ä»éœ€è°¨æ…ã€‚
- **æœªåˆ©ç”¨ NPU/GPU åŠ é€Ÿ**ï¼šå½“å‰åŸºäº PyTorch Mobile CPU æ¨ç†ï¼Œæœªæ¥å¯ç»“åˆ NPU è¿›ä¸€æ­¥åŠ é€Ÿã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ‰©å±•è‡³æ›´å¤šè§†é¢‘è¯­è¨€ä»»åŠ¡ï¼šå¦‚ **VideoQA**, **Summarization**, **Temporal Localization**ï¼ˆå·²åœ¨ Appendix B ä¸­åˆæ­¥éªŒè¯å¯è¡Œæ€§ï¼‰ã€‚
- æ¢ç´¢æ›´æ¿€è¿›çš„å‹ç¼©æŠ€æœ¯ï¼šå¦‚ 4-bit é‡åŒ–ã€ç¨€ç–åŒ–ï¼ŒåŒæ—¶ä¿éšœå¤ç”¨ç¨³å®šæ€§ã€‚
- æ”¯æŒå¤šç”¨æˆ· prompt å¹¶å‘å¤„ç†ï¼šåˆ©ç”¨æ¨¡å—å¸¸é©»ç‰¹æ€§å®ç°æ‰¹å¤„ç†ä¸ä¼šè¯çº§ç¼“å­˜ã€‚
- ç»“åˆ NPU æˆ– DSP è¿›è¡Œç¡¬ä»¶ååŒä¼˜åŒ–ï¼Œå……åˆ†å‘æŒ¥è¾¹ç¼˜è®¾å¤‡æ½œåŠ›ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **ATOM é€šè¿‡â€œæ¨¡å—åŒ– + æŒä¹…å¤ç”¨ + å¹¶è¡Œæ‰§è¡Œâ€çš„è®¾è®¡èŒƒå¼ï¼Œåœ¨å‡ ä¹ä¸å¢åŠ å†…å­˜çš„å‰æä¸‹ï¼Œå®ç°äº†ç§»åŠ¨ç«¯è§†é¢‘-è¯­è¨€æµæ°´çº¿ 27â€“33% çš„ç«¯åˆ°ç«¯åŠ é€Ÿï¼Œä¸ºéšç§å‹å¥½ã€ç¦»çº¿å¯ç”¨çš„æ™ºèƒ½è§†é¢‘åº”ç”¨æä¾›äº†å®ç”¨è§£å†³æ–¹æ¡ˆã€‚**

</details>

---

### 6. [BumpNet: A Sparse Neural Network Framework for Learning PDE Solutions](https://arxiv.org/abs/2512.17198)

**Authors**: Shao-Ting Chiu, Ioannis G. Kevrekidis, Ulisses Braga-Neto  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.17198v1  

#### Abstract
We introduce BumpNet, a sparse neural network framework for PDE numerical solution and operator learning. BumpNet is based on meshless basis function expansion, in a similar fashion to radial-basis function (RBF) networks. Unlike RBF networks, the basis functions in BumpNet are constructed from ordi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šBumpNet: A Sparse Neural Network Framework for Learning PDE Solutions

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»ŸåŸºäºæ·±åº¦ç¥ç»ç½‘ç»œçš„ PDE æ±‚è§£æ–¹æ³•ï¼ˆå¦‚ PINN å’Œ DeepONetï¼‰é€šå¸¸ä¾èµ–å…¨è¿æ¥å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ï¼Œå­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **å‚æ•°é‡å¤§**ï¼šå¯¼è‡´è®­ç»ƒæ•ˆç‡ä½ã€è®¡ç®—å¼€é”€é«˜ï¼›
- **ç¼ºä¹å¯è§£é‡Šæ€§**ï¼šéš¾ä»¥ç†è§£æ¨¡å‹å†…éƒ¨å¦‚ä½•é€¼è¿‘è§£ï¼›
- **å›ºå®šåŸºå‡½æ•°é™åˆ¶**ï¼šå¦‚ RBF ç½‘ç»œè™½é«˜æ•ˆä½†åŸºå‡½æ•°å½¢çŠ¶ä¸å¯è®­ç»ƒã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡º **BumpNet** â€”â€”ä¸€ç§ç¨€ç–ã€å¯è§£é‡Šçš„ä¸¤å±‚ç¥ç»ç½‘ç»œæ¡†æ¶ï¼Œç”¨äºå‡½æ•°é€¼è¿‘å’Œ PDE è§£çš„å­¦ä¹ ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- åˆ©ç”¨æ ‡å‡† **sigmoid æ¿€æ´»å‡½æ•°**ï¼ˆå¦‚ tanhï¼‰é€šè¿‡ç‰¹å®šæƒé‡ç»‘å®šï¼ˆweight-tyingï¼‰æ„é€ å±€éƒ¨åŒ–çš„â€œbumpâ€åŸºå‡½æ•°ï¼›
- æ‰€æœ‰åŸºå‡½æ•°å‚æ•°ï¼ˆä½ç½®ã€å½¢çŠ¶ã€å¹…åº¦ã€æ–¹å‘ï¼‰å‡å¯è®­ç»ƒï¼›
- æ„å»ºæ¨¡å—åŒ–æ¶æ„ï¼Œå¯çµæ´»é›†æˆåˆ°å¤šç§ä¸»æµç¥ç»æ±‚è§£å™¨ä¸­ï¼Œå½¢æˆï¼š
  - **Bump-PINN**ï¼šç»“åˆ Physics-Informed Neural Networksï¼›
  - **Bump-EDNN**ï¼šç”¨äºæ—¶é—´æ¼”åŒ– PDE çš„è¿›åŒ–å‹ç¥ç»ç½‘ç»œï¼›
  - **Bump-DeepONet**ï¼šç”¨äºç®—å­å­¦ä¹ çš„ DeepONet å˜ä½“ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | BumpNet | ä¼ ç»Ÿ PINN / MLP | RBF ç½‘ç»œ |
|------|--------|------------------|----------|
| å‚æ•°æ•°é‡ | æå°‘ï¼ˆå‡å°‘ 20â€“100 å€ï¼‰ | å¤š | å°‘ |
| å¯è®­ç»ƒæ€§ | å…¨å‚æ•°å¯è°ƒï¼ˆä½ç½®ã€å½¢çŠ¶ç­‰ï¼‰ | éšå¼å­¦ä¹  | å›ºå®šæˆ–éƒ¨åˆ†å›ºå®š |
| å¯è§£é‡Šæ€§ | é«˜ï¼ˆå¯é€šè¿‡æƒé‡è§£æåŸºå‡½æ•°å‡ ä½•å±æ€§ï¼‰ | ä½ | ä¸­ |
| ç¨€ç–æ€§ä¸è‡ªé€‚åº”èƒ½åŠ› | æ”¯æŒåŠ¨æ€å‰ªæå®ç° h-adaptivity | ä¸æ”¯æŒ | æœ‰é™æ”¯æŒ |
| è®­ç»ƒé€Ÿåº¦ | å¿«é€Ÿæ”¶æ•› | è¾ƒæ…¢ | å¿«ä½†å—é™ |

æ­¤å¤–ï¼ŒBumpNet æ”¯æŒåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¿›è¡Œ **åŸºäºæŒ¯å¹…çš„å‰ªæï¼ˆamplitude-based pruningï¼‰**ï¼Œè‡ªåŠ¨å»é™¤ä¸é‡è¦çš„åŸºå‡½æ•°ï¼Œå®ç°æ¨¡å‹å‹ç¼©ä¸åŠ é€Ÿæ”¶æ•›ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†ä¸æµ‹è¯•é—®é¢˜
è®ºæ–‡åœ¨å¤šä¸ªç»å…¸åå¾®åˆ†æ–¹ç¨‹ï¼ˆPDEï¼‰åŸºå‡†ä¸Šè¿›è¡Œäº†éªŒè¯ï¼Œæ¶µç›–ä¸åŒç±»å‹çš„é—®é¢˜ï¼š

| é—®é¢˜ç±»å‹ | æ–¹ç¨‹åç§° | æè¿° |
|---------|--------|------|
| æ¤­åœ†å‹ PDE | **Helmholtz Equation** | $ u_{xx} + u_{yy} + ku = q(x,y) $ï¼Œéé½æ¬¡é¡¹åˆ¶é€ çœŸè§£ $ \sin(\pi x)\sin(\pi y) $ |
| æ¤­åœ†å‹ PDE | **Poisson Equation** | $ \Delta u = f(x,y) $ï¼Œæºé¡¹ä¸º $ 2\pi^2 \sin(2\pi x)\sin(4\pi y) $ |
| æŠ›ç‰©å‹ PDE | **Heat Equation** | æ—¶é—´æ¼”åŒ–çƒ­ä¼ å¯¼æ–¹ç¨‹ï¼Œå«è§£æè§£ |
| åŒæ›²å‹ PDE | **Advection Equation** | å¯¹æµæ–¹ç¨‹ï¼Œå‘¨æœŸè¾¹ç•Œæ¡ä»¶ï¼ŒæŒ‘æˆ˜ PINN æ”¶æ•›æ€§ |

æ­¤å¤–è¿˜æµ‹è¯•äº†ï¼š
- **Operator Learning**ï¼šéçº¿æ€§æ‰©æ•£-ååº”æ–¹ç¨‹ $ u_t = D u_{xx} + k u^2 + f(x) $ï¼Œç›®æ ‡æ˜¯ä»è¾“å…¥ $ f(x) $ æ˜ å°„åˆ°è¾“å‡º $ u(x,t) $

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
#### è¯„ä¼°æŒ‡æ ‡
- **ç›¸å¯¹ L1/L2 è¯¯å·®**ï¼šç›¸å¯¹äºçœŸå®è§£çš„å¹³å‡ç»å¯¹/å¹³æ–¹è¯¯å·®ï¼›
- **å‚æ•°æ•°é‡ï¼ˆ#paramï¼‰**ï¼šæ¯”è¾ƒæ¨¡å‹å¤æ‚åº¦ï¼›
- **è®­ç»ƒæ—¶é—´ï¼ˆç§’ï¼‰**ï¼šè¡¡é‡æ•ˆç‡ï¼›
- **æ¨ç†é€Ÿåº¦ä¸å†…å­˜å ç”¨**ã€‚

#### å®éªŒé…ç½®
- **Collocation Points**ï¼šéšæœºé‡‡æ ·æ®‹å·®ç‚¹ï¼ˆè§ Table 2ï¼‰ï¼Œä¸åŒæ–¹æ³•ä½¿ç”¨ç›¸åŒæˆ–å¯æ¯”è®¾ç½®ï¼›
- **ä¼˜åŒ–å™¨**ï¼šAdamï¼Œé…åˆæŒ‡æ•°è¡°å‡å­¦ä¹ ç‡è°ƒåº¦ï¼›
- **åˆå§‹ bumps åˆ†å¸ƒ**ï¼šå‡åŒ€åˆ†å¸ƒåœ¨åŸŸå†…ç½‘æ ¼ä¸Šï¼ˆå¦‚ 10Ã—10 æˆ– 6Ã—6ï¼‰ï¼›
- **å‰ªæç­–ç•¥**ï¼šæ¯ 2000 æ­¥ç§»é™¤æœ€ä½æŒ¯å¹… 0.15% çš„ bumpsã€‚

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **PINN**ï¼šæ ‡å‡† Physics-Informed Neural Networkï¼ˆMLP ç»“æ„ï¼‰
- **SAPINN**ï¼šSelf-Adaptive PINNï¼ˆå¸¦æŸå¤±åŠ æƒæœºåˆ¶ï¼‰
- **SPINN**ï¼šSparse, Physics-based, and partially Interpretable Neural Networkï¼ˆç±»ä¼¼ç¨€ç– RBF æ–¹æ³•ï¼‰
- **EDNN**ï¼šEvolutional Deep Neural Networkï¼ˆç”¨äºæ—¶é—´æ¨è¿›ï¼‰
- **DeepONet**ï¼šæ ‡å‡† Deep Operator Network

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| ä»»åŠ¡ | æ–¹æ³• | L1 Error | å‚æ•°æ•° | è®­ç»ƒæ—¶é—´ï¼ˆç§’ï¼‰ |
|-----|------|----------|--------|---------------|
| **Helmholtz** | Bump-PINN | 2.66e-2 | 1,575 | 51 |
|               | PINN      | 1.24e-1 | 83,073 | 85 |
|               | SPINN     | 9.83e-1 | 1,761 | 2,265 |
| **Poisson**   | Bump-PINN | 8.66e-4 | 252 | 61 |
|               | PINN      | 2.73e-2 | 83,073 | 112 |
|               | SPINN     | 1.03e-4 | 481 | 1,256 |
| **Heat Eq.**  | Bump-PINN | 1.83e-3 | 840 | 12 |
|               | PINN      | 3.15e-2 | 3,421 | 41 |
|               | SPINN     | 2.18e+0 | 1,021 | 291 |
| **Advection** | Bump-PINN | 2.30e-3 | 154 | 28 |
|               | PINN      | 7.78e-2 | 83,073 | 48 |

> æ³¨ï¼šå°½ç®¡å‚æ•°æå°‘ï¼ŒBump-PINN åœ¨å¤šæ•°æƒ…å†µä¸‹ç²¾åº¦æ˜¾è‘—ä¼˜äºæ ‡å‡† PINNï¼Œå¹¶æ¥è¿‘ç”šè‡³è¶…è¿‡ SAPINNã€‚

### ä¸å…¶ä»–æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### âœ… Bump-PINN vs PINN/SAPINN
- **å‚æ•°å‡å°‘ 50â€“100 å€**ï¼ŒåŒæ—¶è¾¾åˆ°æ›´é«˜ç²¾åº¦ï¼›
- **è®­ç»ƒé€Ÿåº¦å¿« 2â€“10 å€ä»¥ä¸Š**ï¼›
- å³ä½¿åŠ å…¥ self-adaptive æƒé‡ï¼ˆBump-SAPINNï¼‰ï¼Œä»ä¿æŒæä½å‚æ•°é‡ä¸”æ€§èƒ½ç¨³å®šã€‚

#### âœ… Bump-EDNN vs EDNN
| æŒ‡æ ‡ | Bump-EDNN | EDNN |
|------|-----------|------|
| å‚æ•°æ€»æ•° | 252 | 1,341 |
| æ¼”åŒ–å‚æ•°æ•° | 36ï¼ˆä»…æ›´æ–°é«˜åº¦ï¼‰ | 1,341 |
| åˆå§‹è®­ç»ƒæ—¶é—´ | 6m43s | 8m24s |
| æ¨ç†æ—¶é—´ï¼ˆt=1ï¼‰ | 6 ç§’ | 23m13s |
| L2 Error @ t=1 | 5e-4 | 1.4e-3 |

> Bump-EDNN åœ¨æ›´çŸ­çš„æ—¶é—´å†…è·å¾—æ›´é«˜çš„ç²¾åº¦ï¼Œå°¤å…¶åœ¨é•¿æ—¶é—´æ¨¡æ‹Ÿä¸­ä¼˜åŠ¿æ˜æ˜¾ã€‚

#### âœ… Bump-DeepONet vs DeepONet
| æŒ‡æ ‡ | Bump-DeepONet | DeepONet |
|------|----------------|-----------|
| Trunk å‚æ•°æ•° | 600 | 25,600 |
| æµ‹è¯•è¯¯å·® | 8.12e-6 | 5.42e-6 |
| è®­ç»ƒæ—¶é—´ | 86 ç§’ | 158 ç§’ |
| è¿­ä»£é€Ÿåº¦ | 937.2 iter/sec | 775.75 iter/sec |

> è™½ç„¶ DeepONet ç•¥å¾®æ›´å‡†ç¡®ï¼Œä½† Bump-DeepONet **å‚æ•°å‡å°‘çº¦ 40 å€**ï¼Œè®­ç»ƒæ›´å¿«ï¼Œå…·å¤‡æå¼ºæ€§ä»·æ¯”ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **å‰ªæå®éªŒï¼ˆPruningï¼‰**ï¼ˆå›¾ 8ï¼‰ï¼š
  - åŠ¨æ€å‰ªæåæ¨¡å‹å‚æ•°è¿›ä¸€æ­¥å‡å°‘ï¼›
  - å°½ç®¡å‰ªæç¬é—´æŸå¤±ä¸Šå‡ï¼ˆå› ä¼˜åŒ–å™¨é‡å¯ï¼‰ï¼Œä½†æ•´ä½“æ”¶æ•›é€Ÿåº¦åŠ å¿«ï¼›
  - è¡¨æ˜å‰ªæèƒ½æœ‰æ•ˆç®€åŒ–æŸå¤±é¢ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§ã€‚

- **å¯è§†åŒ–åˆ†æ**ï¼ˆå›¾ 10cï¼‰ï¼š
  - BumpNet è‡ªåŠ¨å°†æ›´å¤š bumps é›†ä¸­åœ¨æ¢¯åº¦å¤§çš„åŒºåŸŸï¼ˆå¦‚æ³¢å³°/æ³¢è°·é™„è¿‘ï¼‰ï¼›
  - å®ç°äº†ç±»ä¼¼æœ‰é™å…ƒä¸­çš„ **h-adaptivity** æ•ˆæœï¼Œæ— éœ€äººå·¥å¹²é¢„ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **BumpNet æ˜¯ä¸€ä¸ªé«˜æ•ˆã€å¯è§£é‡Šã€ç¨€ç–çš„é€šç”¨æ¡†æ¶**ï¼Œé€‚ç”¨äºå‰å‘/åå‘ PDE æ±‚è§£ä¸ç®—å­å­¦ä¹ ï¼›
2. ä½¿ç”¨æ™®é€š sigmoid å‡½æ•°å³å¯æ„å»ºå¯è®­ç»ƒçš„å±€éƒ¨åŸºå‡½æ•°ï¼Œé¿å…ä¸“ç”¨æ¿€æ´»å‡½æ•°é™åˆ¶ï¼›
3. **å‚æ•°æ•ˆç‡æé«˜**ï¼šç›¸æ¯”ä¼ ç»Ÿ MLP æ¶æ„å‡å°‘æ•°åè‡³ç™¾å€å‚æ•°ï¼Œä»ä¿æŒé«˜ç²¾åº¦ï¼›
4. **è®­ç»ƒé€Ÿåº¦å¿«ã€æ”¶æ•›ç¨³å®š**ï¼šå¾—ç›Šäºç¨€ç–æ€§å’Œç»“æ„å…ˆéªŒï¼›
5. **æ”¯æŒ h-adaptivity**ï¼šé€šè¿‡å‰ªææœºåˆ¶è‡ªåŠ¨èšç„¦äºå¤æ‚åŒºåŸŸï¼Œæå‡è¡¨ç¤ºèƒ½åŠ›ï¼›
6. **å…¼å®¹æ€§å¼º**ï¼šå¯æ— ç¼åµŒå…¥ PINNã€EDNNã€DeepONet ç­‰ä¸»æµæ¶æ„ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä»…é™äºè§„åˆ™æˆ–ç®€å•å‡ ä½•åŸŸï¼ˆbounding box å†…ï¼‰ï¼Œå¯¹å¤æ‚ä¸è§„åˆ™åŸŸçš„æ”¯æŒéœ€é¢å¤–å¤„ç†ï¼›
- åŸºå‡½æ•°æ•°é‡éœ€é¢„è®¾ï¼ˆå°½ç®¡å¯é€šè¿‡å‰ªæè°ƒæ•´ï¼‰ï¼›
- é«˜ç»´æ‰©å±•ï¼ˆn > 3ï¼‰å°šæœªå……åˆ†éªŒè¯ï¼›
- å¯¹æç«¯åˆšæ€§ç³»ç»Ÿæˆ–æ¿€æ³¢é—®é¢˜çš„è¡¨ç°æœªæµ‹è¯•ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ä¸‰ç»´åŠæ›´é«˜ç»´ç‰©ç†åœºå»ºæ¨¡ï¼›
- ç»“åˆè‡ªé€‚åº”ç½‘æ ¼ refinement æŠ€æœ¯ï¼›
- åº”ç”¨äºä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆUQï¼‰ã€è®¾è®¡ä¼˜åŒ–ç­‰å¤šæŸ¥è¯¢åœºæ™¯ï¼›
- æ¢ç´¢å…¶ä»–ç±»å‹çš„å¯è§£é‡ŠåŸºå‡½æ•°æ„é€ æ–¹å¼ï¼›
- å¼€å‘è‡ªåŠ¨åŒ– bump åˆå§‹åŒ–ä¸å¢é•¿ç­–ç•¥ï¼ˆæ›¿ä»£å‰ªæï¼‰ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> BumpNet æä¾›äº†ä¸€ç§å…¼å…· **é«˜æ•ˆç‡ã€å¼ºå¯è§£é‡Šæ€§ä¸çµæ´»æ€§** çš„æ–°å‹ç¥ç»ç½‘ç»œèŒƒå¼ï¼Œåœ¨ç§‘å­¦æœºå™¨å­¦ä¹ é¢†åŸŸå±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œæœ‰æœ›æˆä¸º PINN ç±»æ–¹æ³•çš„é‡è¦æ›¿ä»£æ–¹æ¡ˆã€‚

</details>

---

### 7. [Deep Learning-Based Surrogate Creep Modelling in Inconel 625: A High-Temperature Alloy Study](https://arxiv.org/abs/2512.17477)

**Authors**: Shubham Das, Kaushal Singhania, Amit Sadhu, Suprabhat Das, Arghya Nandi  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.17477v1  

#### Abstract
Time-dependent deformation, particularly creep, in high-temperature alloys such as Inconel 625 is a key factor in the long-term reliability of components used in aerospace and energy systems. Although Inconel 625 shows excellent creep resistance, finite-element creep simulations in tools such as ANS...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDeep Learning-Based Surrogate Creep Modelling in Inconel 625: A High-Temperature Alloy Study

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»ŸåŸºäºæœ‰é™å…ƒæ³•ï¼ˆFEMï¼‰çš„è •å˜æ¨¡æ‹Ÿï¼ˆå¦‚ä½¿ç”¨ ANSYSï¼‰è™½ç„¶ç²¾åº¦é«˜ï¼Œä½†åœ¨è¿›è¡Œé•¿æ—¶é—´ï¼ˆå¦‚ 10,000 å°æ—¶ï¼‰è •å˜åˆ†ææ—¶è®¡ç®—æˆæœ¬æé«˜ï¼Œå•æ¬¡ä»¿çœŸè€—æ—¶è¾¾ **30â€“40 åˆ†é’Ÿ**ï¼Œéš¾ä»¥æ»¡è¶³èˆªç©ºèˆªå¤©ç­‰é¢†åŸŸçš„å®æ—¶è®¾è®¡ä¼˜åŒ–ä¸ç»“æ„å¥åº·ç›‘æµ‹éœ€æ±‚ã€‚

æ­¤å¤–ï¼Œç°æœ‰æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨å¤„ç†é«˜æ¸©åˆé‡‘è •å˜è¡Œä¸ºæ—¶å­˜åœ¨ä»¥ä¸‹ä¸è¶³ï¼š
- ç¼ºä¹å¯¹é•¿æœŸæ—¶é—´ä¾èµ–æ€§çš„å»ºæ¨¡èƒ½åŠ›ï¼›
- éš¾ä»¥é‡åŒ–é¢„æµ‹ä¸ç¡®å®šæ€§ï¼›
- å¤šæ•°ä»…é€‚ç”¨äºçŸ­æœŸæˆ–ç®€åŒ–æ¡ä»¶ä¸‹çš„æ•°æ®ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºä¸¤ç§åŸºäºæ·±åº¦å­¦ä¹ çš„**ä»£ç†æ¨¡å‹**ï¼ˆsurrogate modelsï¼‰ï¼Œç”¨äºæ›¿ä»£æ˜‚è´µçš„ FEM æ¨¡æ‹Ÿï¼š

1. **BiLSTM-Transformer**  
   - ç»“åˆ BiLSTM æ•æ‰å±€éƒ¨æ—¶åºç‰¹å¾ï¼›
   - åˆ©ç”¨ Transformer çš„ self-attention æœºåˆ¶æ•è·é•¿ç¨‹æ—¶é—´ä¾èµ–ï¼ˆlong-term temporal dependenciesï¼‰ï¼›
   - å®ç°é«˜ç²¾åº¦ã€ç¡®å®šæ€§é¢„æµ‹ã€‚

2. **BiLSTM-VAE**ï¼ˆVariational Autoencoderï¼‰
   - å¼•å…¥å˜åˆ†æ¨æ–­ï¼Œåœ¨æ½œåœ¨ç©ºé—´ä¸­å»ºæ¨¡è •å˜è¡Œä¸ºçš„æ¦‚ç‡åˆ†å¸ƒï¼›
   - æ”¯æŒç”Ÿæˆå¼é¢„æµ‹å¹¶æä¾›**ä¸ç¡®å®šæ€§é‡åŒ–**ï¼ˆuncertainty quantificationï¼‰ï¼›
   - æ›´é€‚åˆé£é™©æ•æ„Ÿå·¥ç¨‹åº”ç”¨ï¼ˆå¦‚å¯¿å‘½é¢„æµ‹ã€å¯é æ€§è¯„ä¼°ï¼‰ã€‚

> ğŸ’¡ åˆ›æ–°äº®ç‚¹ï¼š
> - é¦–æ¬¡å°† BiLSTM ä¸ Transformer å’Œ VAE æ¶æ„ç»“åˆç”¨äºé«˜æ¸©åˆé‡‘è •å˜å»ºæ¨¡ï¼›
> - åœ¨å®Œæ•´ 10,000 å°æ—¶è •å˜æ•°æ®ä¸Šè®­ç»ƒï¼Œè¦†ç›– primaryã€secondary å’Œ tertiary é˜¶æ®µï¼›
> - åŒæ—¶å…¼é¡¾**é«˜å‡†ç¡®æ€§**ä¸**ä½æ¨ç†å»¶è¿Ÿ**ï¼Œå®ç°ä»â€œç¦»çº¿ä»¿çœŸâ€åˆ°â€œè¿‘å®æ—¶åˆ†æâ€çš„è·¨è¶Šã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³•ç±»å‹ | å±€é™æ€§ | æœ¬ç ”ç©¶ä¼˜åŠ¿ |
|--------|-------|-----------|
| FEM (ANSYS) | è€—æ—¶é•¿ï¼ˆ30â€“40 min/æ¬¡ï¼‰ | æ¨ç†é€Ÿåº¦æå‡è‡³ç§’çº§ï¼ˆæœ€é«˜ < 50 msï¼‰ |
| ä¼ ç»Ÿå›å½’/æµ…å±‚ç½‘ç»œ | æ— æ³•æ•æ‰éçº¿æ€§æ—¶åºæ¼”åŒ– | ä½¿ç”¨ BiLSTM å»ºæ¨¡åŒå‘ä¸Šä¸‹æ–‡ä¾èµ– |
| å•å‘ LSTM | å¿½ç•¥æœªæ¥çŠ¶æ€å½±å“ | BiLSTM å¢å¼ºå¤šé˜¶æ®µåŠ¨æ€è¡¨å¾èƒ½åŠ› |
| ç¡®å®šæ€§æ¨¡å‹ | æ— ä¸ç¡®å®šæ€§è¾“å‡º | BiLSTM-VAE æä¾›æ¦‚ç‡é¢„æµ‹ä¸ç½®ä¿¡åŒºé—´ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†æ¥æºä¸æ„å»º
- **æ•°æ®ç”Ÿæˆæ–¹å¼**ï¼šé€šè¿‡ ANSYS Mechanical è¿›è¡Œ FEM ä»¿çœŸç”Ÿæˆã€‚
- **ææ–™**ï¼šInconel 625ï¼ˆé•åŸºé«˜æ¸©åˆé‡‘ï¼‰
- **åŠ è½½æ¡ä»¶**ï¼š
  - åº”åŠ›èŒƒå›´ï¼š50â€“150 MPaï¼ˆæ­¥é•¿ 25 MPaï¼Œå…± 5 çº§ï¼‰
  - æ¸©åº¦èŒƒå›´ï¼š700â€“1000Â°Cï¼ˆæ­¥é•¿ 100Â°Cï¼Œå…± 4 çº§ï¼‰
  - æ€»è®¡ $5 \times 4 = 20$ ç»„ç‹¬ç«‹åº”åŠ›-æ¸©åº¦ç»„åˆ
- **æ—¶é—´è·¨åº¦**ï¼šæ¯ç»„æ¨¡æ‹ŸæŒç»­ **10,000 å°æ—¶**ï¼Œè®°å½•ç­‰æ•ˆè •å˜åº”å˜ï¼ˆcreep strainï¼‰éšæ—¶é—´å˜åŒ–
- **æœ¬æ„æ¨¡å‹**ï¼šé‡‡ç”¨ Norton creep law çš„ time-hardening å½¢å¼ï¼Œå¹¶é€šè¿‡å®éªŒæ•°æ®æ ¡å‡†å‚æ•°ï¼ˆè§ Table 2ï¼‰

> æ‰€æœ‰ä»¿çœŸå‡éœ€ 30â€“40 åˆ†é’Ÿå®Œæˆä¸€æ¬¡è¿è¡Œã€‚

### âš™ï¸ æ•°æ®é¢„å¤„ç†æµç¨‹
1. å¯¹åŸå§‹è •å˜åº”å˜ $\epsilon$ è¿›è¡Œå¯¹æ•°å˜æ¢ï¼š$\epsilon^* = \log(1 + \epsilon)$ï¼Œç¼“è§£æŒ‡æ•°å¢é•¿å¸¦æ¥çš„æ•°å€¼ä¸ç¨³å®šï¼›
2. æ„é€ å¤šå˜é‡æ—¶é—´åºåˆ—è¾“å…¥ï¼š[Temperature, Stress, Time] â†’ è¾“å‡ºï¼šlog-transformed strainï¼›
3. æ‰‹åŠ¨åˆ’åˆ†è®­ç»ƒé›†ï¼ˆ16 ç»„ï¼‰ä¸éªŒè¯é›†ï¼ˆ4 ç»„ï¼‰ï¼Œé¿å…æ•°æ®æ³„éœ²ï¼›
4. ä½¿ç”¨ Min-Max Scaling å°†æ‰€æœ‰ç‰¹å¾å½’ä¸€åŒ–è‡³ [0,1] åŒºé—´ã€‚

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
- **RMSE**ï¼ˆRoot Mean Squared Errorï¼‰
- **MAE**ï¼ˆMean Absolute Errorï¼‰
- **RÂ²**ï¼ˆCoefficient of Determinationï¼‰
- **Latency**ï¼ˆæ¨ç†å»¶è¿Ÿï¼Œå•ä½ï¼šms/sequenceï¼‰

æ‰€æœ‰æŒ‡æ ‡åœ¨åå½’ä¸€åŒ–åè®¡ç®—ï¼Œç¡®ä¿ç‰©ç†æ„ä¹‰å¯è§£é‡Šã€‚

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline LSTM**ï¼š
  - å•å±‚ã€hidden dim=32ã€dropout=0.1
  - ä½œä¸ºåŸºå‡†æ¨¡å‹ï¼Œä½“ç°å…ˆè¿›æ¶æ„çš„å¢ç›Š

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š æ€§èƒ½å¯¹æ¯”ï¼ˆValidation Setï¼‰

| Model | Val RMSE | Val RÂ² | Val MAE | Latency (ms) |
|-------|----------|--------|---------|--------------|
| **BiLSTM-Transformer** | 0.014128 | **0.960695** | 0.011166 | 2170.14 |
| **BiLSTM-VAE** | **0.011728** | **0.972917** | **0.008234** | **46.81** |
| Baseline LSTM | 0.016637 | 0.945494 | 0.013800 | 43.86 |

> âœ… å…³é”®å‘ç°ï¼š
> - **BiLSTM-VAE è¡¨ç°æœ€ä½³**ï¼šåœ¨æ‰€æœ‰è¯¯å·®æŒ‡æ ‡ä¸Šå…¨é¢ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œå°¤å…¶ RÂ² è¾¾åˆ° **0.9729**ï¼Œè¡¨æ˜æå¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼›
> - **BiLSTM-Transformer å‡†ç¡®æ€§é«˜ä½†å»¶è¿Ÿè¾ƒé«˜**ï¼šå¾—ç›Šäº self-attentionï¼Œé€‚åˆéœ€è¦é«˜ä¿çœŸé¢„æµ‹çš„åœºæ™¯ï¼›
> - **BiLSTM-VAE æ¨ç†æœ€å¿«**ï¼šä»… **46.81 ms**ï¼Œæ¯” ANSYS å¿« **~40,000 å€**ï¼Œé€‚åˆè¾¹ç¼˜éƒ¨ç½²ä¸å®æ—¶ç›‘æ§ï¼›
> - æ‰€æœ‰ DL æ¨¡å‹æ¨ç†æ—¶é—´å‡åœ¨ç§’å†…å®Œæˆï¼Œè€Œ ANSYS å•æ¬¡éœ€ 30â€“40 åˆ†é’Ÿã€‚

### ğŸ” å®šæ€§åˆ†æä¸å¯è§†åŒ–
- å›¾ 5 æ˜¾ç¤ºä¸¤ä¸ªæ¨¡å‹åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­æŸå¤±ç¨³å®šä¸‹é™ï¼Œæœªå‡ºç°æ˜æ˜¾è¿‡æ‹Ÿåˆï¼›
- é¢„æµ‹æ›²çº¿ä¸ Norton å®šå¾‹å¯¼å‡ºçš„ç†è®ºè •å˜è¶‹åŠ¿é«˜åº¦ä¸€è‡´ï¼›
- åœ¨æç«¯å·¥å†µä¸‹ï¼ˆå¦‚ 150 MPa @ 1000Â°Cï¼‰ä»ä¿æŒä½æ®‹å·®ï¼Œè¯´æ˜æ¨¡å‹é²æ£’æ€§å¼ºã€‚

### âŒ æ¶ˆèå®éªŒï¼ˆæ–‡ä¸­æœªæ˜ç¡®å¼€å±•ï¼‰
å°½ç®¡æœªå•ç‹¬åˆ—å‡ºæ¶ˆèå®éªŒï¼ˆablation studyï¼‰ï¼Œä½†ä»æ¨¡å‹è®¾è®¡å¯æ¨æ–­ï¼š
- BiLSTM ç›¸è¾ƒäºå•å‘ LSTM å¯æ›´å¥½å»ºæ¨¡å¤šé˜¶æ®µè •å˜åŠ¨æ€ï¼›
- Transformer çš„ self-attention æ˜¾è‘—æå‡äº†é•¿åºåˆ—å»ºæ¨¡èƒ½åŠ›ï¼›
- VAE çš„ KL æ•£åº¦æ­£åˆ™é¡¹å¢å¼ºäº†æ¨¡å‹å¯¹ä¸ç¡®å®šæ€§çš„è¡¨è¾¾èƒ½åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º
1. **æ·±åº¦å­¦ä¹ ä»£ç†æ¨¡å‹å¯æœ‰æ•ˆæ›¿ä»£ FEM è •å˜ä»¿çœŸ**ï¼š
   - åœ¨ä¿è¯é«˜ç²¾åº¦ï¼ˆRÂ² > 0.96ï¼‰çš„åŒæ—¶ï¼Œå°†æ¨ç†æ—¶é—´ä» **åˆ†é’Ÿçº§å‹ç¼©è‡³æ¯«ç§’çº§**ï¼›
   - ä¸ºèˆªç©ºèˆªå¤©ã€æ ¸èƒ½ç³»ç»Ÿä¸­çš„**å®æ—¶è®¾è®¡ä¼˜åŒ–**ä¸**ç»“æ„å¥åº·ç›‘æµ‹**æä¾›äº†å¯è¡Œè·¯å¾„ã€‚

2. **BiLSTM-VAE æ˜¯æœ€ä¼˜ç»¼åˆé€‰æ‹©**ï¼š
   - ä¸ä»…é¢„æµ‹æœ€å‡†ç¡®ï¼ˆVal RÂ² = 0.9729ï¼‰ï¼Œä¸”å…·å¤‡ä¸ç¡®å®šæ€§é‡åŒ–èƒ½åŠ›ï¼›
   - æ¨ç†é€Ÿåº¦å¿«ï¼Œé€‚åˆéƒ¨ç½²äºèµ„æºå—é™ç¯å¢ƒï¼ˆå¦‚åµŒå…¥å¼ç³»ç»Ÿï¼‰ã€‚

3. **BiLSTM-Transformer é€‚ç”¨äºé«˜ä¿çœŸé•¿æœŸé¢„æµ‹**ï¼š
   - è‡ªæ³¨æ„åŠ›æœºåˆ¶æ“…é•¿æ•æ‰è¿œè·ç¦»æ—¶é—´ä¾èµ–ï¼Œé€‚åˆé¢„æµ‹ tertiary é˜¶æ®µåŠ é€Ÿå˜å½¢è¡Œä¸ºã€‚

4. **åŒå‘ç»“æ„ + æ·±åº¦æ¶æ„æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•**ï¼š
   - BiLSTM æå‡äº†å¯¹è •å˜ä¸‰é˜¶æ®µï¼ˆprimary â†’ secondary â†’ tertiaryï¼‰æ¼”å˜çš„ç†è§£ï¼›
   - æ·±åº¦é›†æˆæ¶æ„æ˜¯åº”å¯¹å¤æ‚çƒ­åŠ›å­¦è€¦åˆè¡Œä¸ºçš„å…³é”®ã€‚

### âš ï¸ æ–¹æ³•å±€é™æ€§
- å½“å‰æ¨¡å‹åŸºäº **FEM ä»¿çœŸæ•°æ®** è®­ç»ƒï¼Œå°šæœªä¸çœŸå®å®éªŒæ•°æ®ç›´æ¥éªŒè¯ï¼›
- æ•°æ®é›†ä¸­æœªå……åˆ†æ¶µç›–å¤æ‚çš„ multi-axial loading æˆ– cyclic thermal conditionsï¼›
- æ¨¡å‹å‡è®¾è¾“å…¥ä¸ºç†æƒ³æ’å®šåº”åŠ›/æ¸©åº¦ï¼Œå®é™…æœå½¹ç¯å¢ƒä¸­å¯èƒ½å­˜åœ¨æ³¢åŠ¨ï¼›
- VAE çš„ç”Ÿæˆèƒ½åŠ›è™½å¼ºï¼Œä½†ç¼ºä¹æ˜¾å¼çš„ç‰©ç†çº¦æŸï¼Œå¯èƒ½äº§ç”Ÿä¸ç¬¦åˆç‰©ç†è§„å¾‹çš„æ ·æœ¬ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **å¼•å…¥æ›´å®Œæ•´çš„è •å˜æœ¬æ„æ–¹ç¨‹**ï¼š
   - å¦‚ time-hardening law æˆ– Garofalo equationï¼Œä»¥æ›´å¥½åœ°æè¿° primary å’Œ tertiary é˜¶æ®µéçº¿æ€§è¡Œä¸ºã€‚

2. **å‘å±• Physics-Informed Neural Networks (PINNs)**ï¼š
   - å°† Norton æˆ– Arrhenius æ–¹ç¨‹ä½œä¸ºè½¯çº¦æŸåµŒå…¥æŸå¤±å‡½æ•°ï¼Œæé«˜æ¨¡å‹å¯è§£é‡Šæ€§å’Œå¤–æ¨èƒ½åŠ›ã€‚

3. **èåˆå®æµ‹æ•°æ®è¿›è¡Œè”åˆè®­ç»ƒä¸éªŒè¯**ï¼š
   - æå‡æ¨¡å‹åœ¨çœŸå®å·¥ä¸šåœºæ™¯ä¸­çš„é€‚ç”¨æ€§ã€‚

4. **æ¢ç´¢é›†æˆç­–ç•¥ï¼ˆEnsemble Methodsï¼‰**ï¼š
   - ç»“åˆ BiLSTM-VAEï¼ˆä¸ç¡®å®šæ€§ï¼‰ä¸ BiLSTM-Transformerï¼ˆé«˜ç²¾åº¦ï¼‰å½¢æˆ hybrid surrogateã€‚

5. **è¾¹ç¼˜è®¡ç®—éƒ¨ç½²**ï¼š
   - å°†è½»é‡çº§æ¨¡å‹ï¼ˆå¦‚ BiLSTM-VAEï¼‰éƒ¨ç½²è‡³ç°åœºä¼ æ„Ÿå™¨èŠ‚ç‚¹ï¼Œå®ç° on-site creep monitoringã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> è¯¥ç ”ç©¶æˆåŠŸæ„å»ºäº†é«˜æ•ˆã€å‡†ç¡®ã€å¯è§£é‡Šçš„æ·±åº¦å­¦ä¹ ä»£ç†æ¨¡å‹ï¼Œå®ç°äº†å¯¹ Inconel 625 è •å˜è¡Œä¸ºçš„**å¿«é€Ÿã€å¯é ã€è¿‘å®æ—¶é¢„æµ‹**ï¼Œä¸ºé«˜æ¸©åˆé‡‘ç»“æ„çš„è®¾è®¡ä¸è¿ç»´æä¾›äº†æ–°ä¸€ä»£æ•°å­—å­ªç”Ÿå·¥å…·ã€‚

</details>

---

### 8. [Large Language Models as Pok\'emon Battle Agents: Strategic Play and Content Generation](https://arxiv.org/abs/2512.17308)

**Authors**: Daksh Jain, Aarya Jain, Ashutosh Desai, Avyakt Verma, Ishan Bhanuka, Pratik Narang, Dhruv Kumar  
**Category**: cs.AI  
**Published**: 2025-12-22  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.17308v1  

#### Abstract
Strategic decision-making in Pok\'emon battles presents a unique testbed for evaluating large language models. Pok\'emon battles demand reasoning about type matchups, statistical trade-offs, and risk assessment, skills that mirror human strategic thinking. This work examines whether Large Language M...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Large Language Models as PokÃ©mon Battle Agents: Strategic Play and Content Generation*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
è¯¥ç ”ç©¶æ—¨åœ¨è§£å†³ä¼ ç»Ÿæ¸¸æˆAIåœ¨**å¤æ‚ã€è§„åˆ™é©±åŠ¨çš„å›åˆåˆ¶ç­–ç•¥æ¸¸æˆ**ï¼ˆå¦‚PokÃ©monå¯¹æˆ˜ï¼‰ä¸­é¢ä¸´çš„ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **ç¼ºä¹é€‚åº”æ€§**ï¼šåŸºäºæœ‰é™çŠ¶æ€æœºï¼ˆFSMï¼‰æˆ–å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„ä¼ ç»ŸAIéš¾ä»¥åº”å¯¹åŠ¨æ€å˜åŒ–çš„â€œmetaâ€ç¯å¢ƒæˆ–ç”¨æˆ·ç”Ÿæˆçš„æ–°å†…å®¹ã€‚
- **å¯è§£é‡Šæ€§å·®**ï¼šRLæ¨¡å‹è™½ç„¶èƒ½ä¼˜åŒ–èƒœç‡ï¼Œä½†å†³ç­–è¿‡ç¨‹ä¸é€æ˜ï¼Œæ— æ³•æä¾›äººç±»å¯ç†è§£çš„æ¨ç†é€»è¾‘ã€‚
- **å†…å®¹ç”Ÿæˆèƒ½åŠ›å¼±**ï¼šç°æœ‰ç³»ç»Ÿé€šå¸¸ä¾èµ–é¢„è®¾æœºåˆ¶ï¼Œç¼ºä¹åˆ›é€ æ€§åœ°æ‰©å±•æ¸¸æˆå†…å®¹ï¼ˆå¦‚æ–°æŠ€èƒ½ï¼‰çš„èƒ½åŠ›ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬è®ºæ–‡æå‡ºå°†**Large Language Models (LLMs)** ä½œä¸ºåŒåŠŸèƒ½æ™ºèƒ½ä½“ï¼Œé›†æˆäºPokÃ©monæˆ˜æ–—ç³»ç»Ÿä¸­ï¼Œå…·å¤‡ä¸¤å¤§æ ¸å¿ƒèƒ½åŠ›ï¼š
1. **æˆ˜ç•¥å†³ç­–ä»£ç†ï¼ˆStrategic Battle Agentï¼‰**  
   - åˆ©ç”¨LLMè¿›è¡Œå®æ—¶æˆ˜æœ¯å†³ç­–ï¼ˆé€‰æ‹©æ”»å‡»æˆ–åˆ‡æ¢å®å¯æ¢¦ï¼‰ï¼ŒåŸºäºå½“å‰æˆ˜åœºçŠ¶æ€ï¼ˆHPã€å±æ€§ã€æŠ€èƒ½ç­‰ï¼‰è¿›è¡Œä¸Šä¸‹æ–‡æ¨ç†ã€‚
   - å¼•å…¥**Chain-of-Thought (CoT)** æ¨ç†æ¨¡å¼æå‡å†³ç­–è´¨é‡ã€‚
2. **ç¨‹åºåŒ–å†…å®¹ç”Ÿæˆå™¨ï¼ˆProcedural Content Generatorï¼‰**  
   - ä½¿ç”¨LLMè‡ªåŠ¨ç”Ÿæˆç¬¦åˆPokÃ©monä¸–ç•Œè§‚ä¸”æœºæ¢°å¹³è¡¡çš„æ–°æŠ€èƒ½ï¼ˆMovesï¼‰ï¼Œæ»¡è¶³åŠŸç‡-å‡†ç¡®åº¦-PPä¹‹é—´çš„æƒè¡¡å…³ç³»ã€‚

ç³»ç»Ÿæ¶æ„ç»“åˆäº†ä¸€ä¸ª**ç¡®å®šæ€§çš„æˆ˜æ–—æ¨¡æ‹Ÿå™¨**ä¸ä¸€ä¸ª**ç”Ÿæˆå¼LLMæ¥å£**ï¼Œé€šè¿‡ç»“æ„åŒ–çš„JSONæ ¼å¼ä¼ é€’æ¸¸æˆçŠ¶æ€ï¼Œå¹¶è¦æ±‚LLMè¾“å‡ºæ ‡å‡†åŒ–åŠ¨ä½œæˆ–æŠ€èƒ½è®¾è®¡ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | å±€é™æ€§ | æœ¬æ–‡ä¼˜åŠ¿ |
|------|--------|----------|
| FSM / Heuristic AI | å›ºå®šé€»è¾‘ï¼Œç¼ºä¹çµæ´»æ€§å’Œâ€œå…ƒåšå¼ˆâ€èƒ½åŠ› | æ›´è‡ªç„¶çš„äººç±»é£æ ¼å†³ç­–ï¼Œå…·å¤‡æƒ…å¢ƒç†è§£å’Œé€‚åº”èƒ½åŠ› |
| Reinforcement Learning (RL) | éœ€å¤§é‡è®­ç»ƒã€æ³›åŒ–å·®ã€é»‘ç®±å†³ç­– | **Zero-shotèƒ½åŠ›**ï¼šæ— éœ€é¢†åŸŸç‰¹å®šè®­ç»ƒå³å¯è¡¨ç°è‰¯å¥½ï¼›**å¯è§£é‡Šæ€§å¼º**ï¼ˆCoTæ­ç¤ºæ¨ç†è·¯å¾„ï¼‰ |
| æ‰‹åŠ¨è®¾è®¡å†…å®¹ | è€—æ—¶ã€åˆ›æ„å—é™ | æ”¯æŒè‡ªåŠ¨åŒ–ã€å¤šæ ·åŒ–ã€ä¸»é¢˜ä¸€è‡´çš„å†…å®¹ç”Ÿæˆ |

> âœ… **æ ¸å¿ƒåˆ›æ–°**ï¼šé¦–æ¬¡éªŒè¯LLMå¯åœ¨æ— æ˜¾å¼è®­ç»ƒçš„æƒ…å†µä¸‹ï¼ŒåŒæ—¶èƒœä»»**é«˜é˜¶ç­–ç•¥æ‰§è¡Œ**ä¸**é«˜è´¨é‡å†…å®¹åˆ›ä½œ**ï¼Œä¸ºäº¤äº’å¼å¨±ä¹ç³»ç»Ÿçš„**è‡ªé€‚åº”éš¾åº¦è°ƒèŠ‚**å’Œ**åŠ¨æ€å†…å®¹æ¼”åŒ–**æä¾›äº†æ–°èŒƒå¼ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ§ª å®éªŒå¹³å°ä¸æ•°æ®é›†
- **æ¸¸æˆç¯å¢ƒ**ï¼šè‡ªç ”çš„å›åˆåˆ¶PokÃ©monæˆ˜æ–—ç³»ç»Ÿï¼Œå®ç°å®Œæ•´å®˜æ–¹è§„åˆ™ï¼ŒåŒ…æ‹¬ï¼š
  - å±æ€§å…‹åˆ¶ä¹˜æ•°ï¼ˆType Effectivenessï¼‰
  - ç»Ÿè®¡ä¼¤å®³å…¬å¼ï¼ˆStat-based Damage Calculationï¼‰
  - å¤šå®å¯æ¢¦å›¢é˜Ÿç®¡ç†ï¼ˆTeam Switchingï¼‰
- **æ•°æ®æ¥æº**ï¼šæœªä½¿ç”¨å¤–éƒ¨æ•°æ®é›†ã€‚æ‰€æœ‰æˆ˜æ–—çŠ¶æ€ç”±ç³»ç»Ÿå†…éƒ¨ç”Ÿæˆå¹¶åºåˆ—åŒ–ä¸ºæ–‡æœ¬è¾“å…¥ã€‚
- **æ¨¡å‹åˆ—è¡¨**ï¼šæµ‹è¯•äº†å¤šä¸ªä¸»æµLLMï¼š
  - `Gemini 2.5 Flash`, `Gemini 2.5 Pro`
  - `GPT-5 Mini`
  - `Claude 4.5 Haiku`
  - `DeepSeek-V3`
  - `Grok 4 Fast`

### âš™ï¸ å®éªŒè®¾ç½®
#### ï¼ˆ1ï¼‰LLM vs LLM å¯¹æˆ˜æ¡†æ¶
- åŒæ–¹å‡ä¸ºLLMæ§åˆ¶çš„AIï¼Œéšæœºåˆ†é…3åªå®å¯æ¢¦ç»„æˆçš„é˜Ÿä¼ã€‚
- æ¯è½®åŒæ­¥æäº¤è¡ŒåŠ¨ï¼ˆæ”»å‡»æˆ–æ¢äººï¼‰ï¼Œä¾æ®é€Ÿåº¦å†³å®šå‡ºæ‰‹é¡ºåºã€‚
- è‡ªåŠ¨è¿è¡Œå¤šåœºå¯¹å†³ï¼Œè®°å½•å…¨è¿‡ç¨‹ç”¨äºåˆ†æã€‚

#### ï¼ˆ2ï¼‰äººç±»ç©å®¶æµ‹è¯•
- 30+å‚ä¸è€…åˆ†åˆ«å¯¹æŠ—ä¸åŒé…ç½®çš„LLMå¯¹æ‰‹ï¼ˆå¦‚Gemini-Flash ON/OFFï¼‰ã€‚
- æ”¶é›†ä¸»è§‚è¯„åˆ†ï¼ˆéš¾åº¦æ„ŸçŸ¥ã€æ»¡æ„åº¦ï¼‰åŠå®é™…èƒœè´Ÿç»“æœã€‚

#### ï¼ˆ3ï¼‰Move Generation Pipeline
- è¾“å…¥ï¼šæŸå®å¯æ¢¦çš„ç±»å‹ã€æ”»å‡»åŠ›å€¾å‘ã€é€Ÿåº¦ç­‰ç‰¹å¾ã€‚
- è¾“å‡ºï¼šç¬¦åˆè§„èŒƒçš„æ–°æŠ€èƒ½ï¼ˆJSONæ ¼å¼ï¼‰ï¼ŒåŒ…å«`name`, `power`, `accuracy`, `type`, `category`, `effect`, `PP`ã€‚
- é‡‡ç”¨**åŒé˜¶æ®µè¯„ä¼°ä½“ç³»**ï¼š
  1. **Deterministic Validator**ï¼šæ£€æŸ¥æ•°å€¼èŒƒå›´ã€ç±»å‹ä¸€è‡´æ€§ã€åŠŸç‡-å‡†ç¡®æ€§åæ¯”ç­‰ç¡¬çº¦æŸã€‚
  2. **LLM Judge**ï¼šè¯„ä¼°åˆ›é€ åŠ›ä¸åŸåˆ›æ€§ï¼ˆ0â€“5åˆ†ï¼‰ï¼Œåˆ¤æ–­æ˜¯å¦æ‰¹å‡†ã€ä¿®è®¢æˆ–æ‹’ç»ã€‚

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| ç±»åˆ« | æŒ‡æ ‡åç§° | æè¿° |
|------|---------|------|
| **æˆ˜æ–—æ€§èƒ½** | Win Rate (%) | èƒœç‡ |
| | Turns to Win (mean) | å¹³å‡è·èƒœæ‰€éœ€å›åˆæ•° |
| | Type-alignment (%) | åœ¨æœ‰åˆ©æ—¶æ­£ç¡®åˆ©ç”¨å±æ€§å…‹åˆ¶çš„æ¯”ä¾‹ |
| | Latency (ms) | å•æ¬¡å†³ç­–å»¶è¿Ÿï¼ˆä»è¯·æ±‚åˆ°å“åº”è§£æï¼‰ |
| | Token Consumption | æ¯å†³ç­–å¹³å‡æ¶ˆè€—tokenæ•°ï¼ˆæˆæœ¬è¡¡é‡ï¼‰ |
| **å†…å®¹ç”Ÿæˆ** | Validity (%) | ç”ŸæˆæŠ€èƒ½ç¬¦åˆåŸºæœ¬ç»“æ„è¦æ±‚çš„æ¯”ä¾‹ |
| | Balanced (%) | æŠ€èƒ½æ»¡è¶³æœºæ¢°å¹³è¡¡è§„åˆ™çš„æ¯”ä¾‹ |
| | Creativity / Originality (0â€“5) | LLMè¯„å§”æ‰“åˆ†ï¼Œåæ˜ åˆ›æ„ä¸æ–°é¢–æ€§ |
| **ç”¨æˆ·ä½“éªŒ** | Human Win Rate | äººç±»ç©å®¶èƒœç‡ |
| | Subjective Difficulty (1â€“5) | ç”¨æˆ·ä¸»è§‚éš¾åº¦è¯„åˆ† |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Random Player**ï¼šå®Œå…¨éšæœºé€‰æ‹©æŠ€èƒ½æˆ–æ¢äººã€‚
- **No-CoT vs With-CoT**ï¼šå…³é—­/å¼€å¯Chain-of-Thoughtæ¨ç†ã€‚
- **ä¸åŒLLMä¹‹é—´äº’æ**ï¼šæ„å»ºå¾ªç¯èµ›æ’è¡Œæ¦œã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### âœ… å®éªŒ1ï¼šLLM vs éšæœºç©å®¶ï¼ˆBaseline Comparisonï¼‰
| æ¨¡å‹ | èƒœç‡ |
|------|-----|
| Random Player | 18% |
| Gemini-Flash (Thinking-OFF) | 62% |
| Gemini-Pro (Thinking-OFF) | 71% |

> ğŸ’¡ å³ä½¿ä¸å¯ç”¨æ¨ç†é“¾ï¼ŒLLMä¹Ÿæ˜¾è‘—ä¼˜äºéšæœºç­–ç•¥ï¼Œè¯æ˜å…¶å·²å†…åŒ–PokÃ©monæœºåˆ¶çŸ¥è¯†ã€‚

#### âœ… å®éªŒ3ï¼šChain-of-Thoughtå½±å“ï¼ˆThinking ON vs OFFï¼‰
| æ¨¡å‹ | Latency (s) | Win Rate ä¸‹é™ï¼ˆå…³CoTï¼‰ | Type-alignment â†“ |
|------|------------|------------------------|------------------|
| Gemini-Flash | 2.8 â†’ 3.5 (+25%) | -15% | -35% |
| Gemini-Pro | 3.3 â†’ 5.5 (+67%) | -15% | -35% |

> âš ï¸ å¯ç”¨CoTå¸¦æ¥æ˜æ˜¾å»¶è¿Ÿä»£ä»·ï¼Œä½†å¤§å¹…æå‡å†³ç­–è´¨é‡ã€‚

#### âœ… å®éªŒ4ï¼šäººç±»ç©å®¶æµ‹è¯•
| å¯¹æ‰‹ | å¹³å‡éš¾åº¦è¯„åˆ† (1â€“5) |
|------|--------------------|
| Gemini-Flash (ON) | 3.2 |
| Gemini-Pro (OFF) | 3.8 |
| Gemini-Pro (ON) | 4.0 |

> ğŸ‘¤ ç”¨æˆ·è®¤ä¸ºGemini-Proæ›´å…·æŒ‘æˆ˜æ€§ï¼Œä½†è¿‡é«˜éš¾åº¦å¯èƒ½é™ä½ä¹è¶£ã€‚

#### âœ… å®éªŒ5 & 6ï¼šæŠ€èƒ½ç”Ÿæˆæœ‰æ•ˆæ€§ï¼ˆBatch Size 4 vs 1ï¼‰
| æ¨¡å‹ | Batch=4 Validity | Balanced | Batch=1 Validity | Balanced |
|------|------------------|----------|------------------|----------|
| Gemini Flash | 88.3% | 56.7% | 100% | 36.7% |
| Claude | 89.2% | 70.8% | 100% | **80.0%** |
| GPT-5 Mini | 86.7% | 72.5% | 100% | 66.7% |
| Grok 4 | 90.0% | **77.5%** | 100% | 50.0% |

> âœ… æ‰€æœ‰æ¨¡å‹åœ¨å•æ¡ç”Ÿæˆæ—¶å¯è¾¾100%è¯­æ³•æœ‰æ•ˆï¼›**Claudeåœ¨å¹³è¡¡æ€§ä¸Šæœ€ä¼˜**ã€‚

#### âœ… å®éªŒ7ï¼šåˆ›é€ åŠ›è¯„åˆ†ï¼ˆLLM Judgeï¼‰
| æ¨¡å‹ | Creativity | Originality | Overall |
|------|-----------|-------------|--------|
| GPT-5 Mini | **4.17** | **3.33** | **3.28** |
| Claude | 3.37 | 2.47 | 2.47 |
| Grok 4 | 3.57 | 2.63 | 2.60 |

> ğŸ¨ **GPT-5 Miniæœ€å…·åˆ›æ„**ï¼Œè€ŒClaudeæ›´ä¿å®ˆä½†æœºæ¢°åˆè§„ã€‚

#### âœ… å®éªŒ8ï¼šè·¨æ¨¡å‹å¯¹æˆ˜é”¦æ ‡èµ›ï¼ˆRound-Robinï¼‰
| æ¨¡å‹ | å…¸å‹æˆ˜ç»©ï¼ˆvs Claudeï¼‰ | å¹³å‡æˆ˜æ–—å›åˆ | æ€»Tokenæ¶ˆè€—ï¼ˆä»£è¡¨æ•ˆç‡ï¼‰ |
|------|------------------------|--------------|----------------------------|
| Grok 4 Fast | **10-0-0** | **5.2** | ä½ï¼ˆ~9ä¸‡ï¼‰ |
| Gemini-Pro | 7-3-0 | 16.1 | é«˜ï¼ˆ~36ä¸‡ï¼‰ |
| DeepSeek-V3 | 8-2-0 | 31.1 | æä½ï¼ˆ~27ä¸‡ï¼‰ |
| Claude | â€” | 16.1 | ä¸­ç­‰ |

> ğŸ† **Grok 4 Fastæ˜¯æˆ˜ç•¥ç‹è€…**ï¼šèƒœç‡æ¥è¿‘å®Œç¾ï¼Œæˆ˜æ–—æçŸ­ï¼ˆ<6å›åˆï¼‰ï¼Œèµ„æºé«˜æ•ˆã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **LLMså¯ä½œä¸ºé›¶æ ·æœ¬ï¼ˆzero-shotï¼‰æˆ˜æ–—ä»£ç†**  
   æ— éœ€ä¸“é—¨è®­ç»ƒï¼Œä»…é æç¤ºå·¥ç¨‹å³å¯å®ç°è¿œè¶…éšæœºç­–ç•¥çš„æˆ˜æœ¯æ°´å¹³ï¼Œè¯´æ˜LLMå…·å¤‡è‰¯å¥½çš„**éšå¼çŸ¥è¯†è¿ç§»èƒ½åŠ›**ã€‚

2. **Chain-of-Thoughtè‡³å…³é‡è¦**  
   å¼€å¯CoTåï¼Œ`type-alignment`æå‡è¾¾35%ï¼Œèƒœç‡æé«˜çº¦15%ï¼Œå°½ç®¡å¢åŠ å»¶è¿Ÿï¼Œä½†å¯¹äºé«˜æ°´å¹³å¯¹æˆ˜ä¸å¯æˆ–ç¼ºã€‚

3. **ä¸åŒLLMå±•ç°å‡ºâ€œæˆ˜æœ¯äººæ ¼â€å·®å¼‚**  
   - **Grok 4 Fast**ï¼šæ¿€è¿›ã€é«˜æ•ˆã€ç»ˆç»“èƒ½åŠ›å¼ºï¼ˆå¹³å‡5.2å›åˆå–èƒœï¼‰ã€‚
   - **Claude / DeepSeek-V3**ï¼šä¿å®ˆã€æŒä¹…æˆ˜å€¾å‘ï¼Œå¸¸è¶…è¿‡20å›åˆã€‚
   - **Gemini-Pro**ï¼šå¼ºä½†é«˜å»¶è¿Ÿï¼Œé€‚åˆç¦»çº¿åœºæ™¯ã€‚

4. **å†…å®¹ç”Ÿæˆå­˜åœ¨â€œåˆ›é€  vs å¹³è¡¡â€æƒè¡¡**  
   - **GPT-5 Mini**ï¼šæœ€å¯Œæƒ³è±¡åŠ›ï¼Œä½†æ˜“è¿åå¹³è¡¡è§„åˆ™ã€‚
   - **Claude**ï¼šæœ€å¯é ï¼Œ80%ç”ŸæˆæŠ€èƒ½è¾¾åˆ°ä¸¥æ ¼å¹³è¡¡æ ‡å‡†ã€‚
   - **å»ºè®®åˆ†å·¥ä½¿ç”¨**ï¼šGPTç³»åˆ—è´Ÿè´£åˆ›æ„å­µåŒ–ï¼ŒClaude/Grokç”¨äºç»ˆå®¡ä¸éƒ¨ç½²ã€‚

5. **æœ€ä¼˜å®æˆ˜é…ç½®æ¨è**  
   - **å®æ—¶å¯¹æˆ˜é¦–é€‰**ï¼š`Gemini 2.5 Flash (CoT ON)`ï¼Œå…¼é¡¾å“åº”é€Ÿåº¦ï¼ˆ3.5så»¶è¿Ÿï¼‰ä¸åˆç†éš¾åº¦ï¼ˆ3.5/5ï¼‰ã€‚
   - **é«˜ç«¯ç«æŠ€AI**ï¼š`Grok 4 Fast`ï¼Œæè‡´æ•ˆç‡ä¸èƒœç‡ã€‚
   - **å†…å®¹ç”Ÿäº§æµæ°´çº¿**ï¼š`GPT-5 Mini + Claude`ç»„åˆï¼Œå…ˆåˆ›åå®¡ã€‚

### âš ï¸ æ–¹æ³•å±€é™æ€§
- **å»¶è¿Ÿé—®é¢˜**ï¼šå³ä½¿æœ€å¿«æ¨¡å‹ä¹Ÿæœ‰~2.8ç§’å»¶è¿Ÿï¼Œä¸é€‚åˆå®æ—¶å¿«èŠ‚å¥æ¸¸æˆã€‚
- **æ ¼å¼ç¨³å®šæ€§é£é™©**ï¼šéƒ¨åˆ†æ¨¡å‹ï¼ˆå¦‚DeepSeek-V3ï¼‰å¶å°”è¾“å‡ºéJSONå†…å®¹ï¼Œéœ€é¢å¤–å®¹é”™å¤„ç†ã€‚
- **æˆæœ¬é«˜æ˜‚**ï¼šå°¤å…¶æ˜¯GPT-5 Miniï¼Œåœ¨æ‰¹é‡ç”Ÿæˆä¸­tokenå¼€é”€æœ€å¤§ã€‚
- **ä¾èµ–é¢„çŸ¥çŸ¥è¯†**ï¼šæˆåŠŸéƒ¨åˆ†æºäºLLMåœ¨è®­ç»ƒä¸­æ¥è§¦è¿‡PokÃ©monè§„åˆ™ï¼Œå¯¹æœªçŸ¥è§„åˆ™åŸŸæ•ˆæœå¾…éªŒè¯ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **è½»é‡åŒ–æ¨ç†ä¼˜åŒ–**ï¼šæ¢ç´¢LoRAå¾®è°ƒæˆ–è’¸é¦æŠ€æœ¯é™ä½å»¶è¿Ÿã€‚
2. **æ··åˆAIæ¶æ„**ï¼šå°†LLMä¸è½»é‡çº§RLç»“åˆï¼Œå‘æŒ¥å„è‡ªä¼˜åŠ¿ã€‚
3. **åŠ¨æ€éš¾åº¦è°ƒèŠ‚ï¼ˆAdaptive Difficultyï¼‰**ï¼šæ ¹æ®ç©å®¶æ°´å¹³è‡ªåŠ¨è°ƒæ•´LLMçš„CoTæ·±åº¦æˆ–æ¨¡å‹é€‰æ‹©ã€‚
4. **æ‰©å±•è‡³å…¶ä»–æ¸¸æˆ**ï¼šåº”ç”¨äºã€Šå®å¯æ¢¦ã€‹ä¹‹å¤–çš„TCGï¼ˆå¦‚MTGï¼‰ã€SRPGç­‰å¤æ‚ç­–ç•¥ç³»ç»Ÿã€‚
5. **ç©å®¶è¡Œä¸ºå»ºæ¨¡**ï¼šè®©LLMå­¦ä¹ æ¨¡ä»¿äººç±»é€‰æ‰‹é£æ ¼ï¼Œå¢å¼ºæ²‰æµ¸æ„Ÿã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬ç ”ç©¶è¡¨æ˜ï¼Œ**LLMsä¸ä»…èƒ½æˆä¸ºèªæ˜çš„å¯¹æ‰‹ï¼Œè¿˜èƒ½å½“å‡ºè‰²çš„è®¾è®¡å¸ˆ**â€”â€”å®ƒä»¬æ—¢æ˜¯PokÃ©monæˆ˜åœºä¸Šçš„æˆ˜ç•¥å®¶ï¼Œä¹Ÿæ˜¯æ¨åŠ¨æ¸¸æˆç”Ÿæ€æŒç»­è¿›åŒ–çš„åˆ›é€ åŠ›å¼•æ“ã€‚

</details>

---

### 9. [PAACE: A Plan-Aware Automated Agent Context Engineering Framework](https://arxiv.org/abs/2512.16970)

**Authors**: Kamer Ali Yuksel  
**Category**: cs.AI  
**Published**: 2025-12-22  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.16970v1  

#### Abstract
Large Language Model (LLM) agents are increasingly deployed in complex, multi-step workflows involving planning, tool use, reflection, and interaction with external knowledge systems. These workflows generate rapidly expanding contexts that must be curated, transformed, and compressed to maintain fi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# PAACE: A Plan-Aware Automated Agent Context Engineering Framework è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†åœ¨æ‰§è¡Œå¤æ‚ã€å¤šæ­¥éª¤ä»»åŠ¡æ—¶é¢ä¸´**ä¸Šä¸‹æ–‡ç®¡ç†ç“¶é¢ˆ**ã€‚éšç€ä»»åŠ¡é“¾å¢é•¿ï¼Œä»£ç†çš„çŠ¶æ€ï¼ˆå³ä¸Šä¸‹æ–‡ï¼‰è¿…é€Ÿè†¨èƒ€ï¼ŒåŒ…å«ç³»ç»ŸæŒ‡ä»¤ã€æ¨ç†è½¨è¿¹ã€å·¥å…·è¾“å‡ºã€æ£€ç´¢å†…å®¹ç­‰ï¼Œå¯¼è‡´ï¼š
- **æ³¨æ„åŠ›ç¨€é‡Šï¼ˆattention dilutionï¼‰**
- **ä¸Šä¸‹æ–‡â€œè…åŒ–â€ï¼ˆcontext rotï¼‰**
- **æ¨ç†è´¨é‡ä¸‹é™**
- **æ¨ç†æˆæœ¬é«˜æ˜‚**

ç°æœ‰æ–¹æ³•å¦‚æ‘˜è¦ï¼ˆsummarizationï¼‰ã€æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ã€å¯å‘å¼å‹ç¼©ç­‰ï¼Œå¤§å¤šä»…å…³æ³¨å•æ­¥ç›¸å…³æ€§æˆ–é™æ€å‹ç¼©ï¼Œ**å¿½ç•¥äº†å¤šæ­¥ä»»åŠ¡ä¸­çš„è®¡åˆ’ç»“æ„ã€ä¾èµ–å…³ç³»å’ŒæŒ‡ä»¤æ¼”åŒ–**ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡º **PAACE**ï¼ˆPlan-Aware Automated Context Engineeringï¼‰ï¼Œä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œç”¨äºä¼˜åŒ–LLMä»£ç†åœ¨é•¿å‘¨æœŸä»»åŠ¡ä¸­çš„ä¸Šä¸‹æ–‡çŠ¶æ€ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†**ä¸Šä¸‹æ–‡å·¥ç¨‹**ï¼ˆContext Engineeringï¼‰è§†ä¸ºä¸€ç§å¯å­¦ä¹ çš„çŠ¶æ€å‹ç¼©ç­–ç•¥ï¼Œè€Œéç®€å•çš„æç¤ºç¼–è¾‘ã€‚

#### ä¸»è¦ç»„æˆéƒ¨åˆ†ï¼š
- **PAACE-Syn**ï¼šå¤§è§„æ¨¡åˆæˆæ•°æ®ç”Ÿæˆå™¨ï¼Œç”Ÿæˆå¸¦æœ‰é€æ­¥å‹ç¼©ç›‘ç£ä¿¡å·çš„ä»£ç†å·¥ä½œæµè½¨è¿¹ã€‚
- **PAACE-FT**ï¼šåŸºäºæ•™å¸ˆ-å­¦ç”ŸèŒƒå¼çš„è’¸é¦æ¨¡å‹æ—ï¼Œè®­ç»ƒè½»é‡çº§ã€è®¡åˆ’æ„ŸçŸ¥çš„ä¸Šä¸‹æ–‡å‹ç¼©å™¨ã€‚

#### åˆ›æ–°æœºåˆ¶ï¼š
- **Next-k-task relevance modeling**ï¼šå‹ç¼©æ—¶è€ƒè™‘æœªæ¥kä¸ªä»»åŠ¡çš„éœ€æ±‚ï¼Œä¿ç•™è·¨æ­¥ä¾èµ–ä¿¡æ¯ã€‚
- **Plan-structure analysis**ï¼šåˆ©ç”¨ä»»åŠ¡å›¾ï¼ˆDAGï¼‰ç»“æ„æŒ‡å¯¼å‹ç¼©ï¼Œä¿æŒå› æœé“¾å®Œæ•´ã€‚
- **Instruction co-refinement**ï¼šåœ¨å‹ç¼©è¿‡ç¨‹ä¸­éšå¼é‡å†™å¹¶åŒæ­¥æ›´æ–°æŒ‡ä»¤ï¼Œé˜²æ­¢æŒ‡ä»¤æ¼‚ç§»ï¼ˆinstruction driftï¼‰ã€‚
- **Function-preserving compression**ï¼šç¡®ä¿å‹ç¼©åçš„ä¸Šä¸‹æ–‡ä»èƒ½äº§ç”Ÿä¸åŸå§‹ä¸Šä¸‹æ–‡è¯­ä¹‰ç­‰ä»·çš„ç»“æœã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | å±€é™æ€§ | PAACE çš„æ”¹è¿› |
|------|--------|-------------|
| **LLMLingua / Self-RAG** | ä»…é’ˆå¯¹å•æŸ¥è¯¢ä¼˜åŒ–ï¼Œå¿½ç•¥å¤šæ­¥ä¾èµ– | æ˜¾å¼å»ºæ¨¡ next-k ä»»åŠ¡ç›¸å…³æ€§ |
| **ACon (Yu et al., 2025b)** | ä»…ä¼˜åŒ–ä¸‹ä¸€ä»»åŠ¡ï¼Œæ— æŒ‡ä»¤ååŒä¼˜åŒ– | æ”¯æŒå¤šæ­¥å‰ç»ä¸æŒ‡ä»¤å…±æ¼”åŒ– |
| **Provence** | ä»…åšäºŒå€¼å‰ªæï¼ˆkeep/dropï¼‰ï¼Œä¸æ”¯æŒé‡å†™ | æ”¯æŒé‡å†™ã€å‹ç¼©ã€é‡æ„ç­‰å¤šç§æ“ä½œ |
| **ä¼ ç»Ÿæ‘˜è¦æ¨¡å‹ï¼ˆBART/T5ï¼‰** | æ‰å¹³åŒ–ç»“æ„ï¼Œç ´åæ¨ç†é“¾ | ä¿ç•™ç»“æ„ä¾èµ–ä¸å˜é‡å¼•ç”¨ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿**ï¼šPAACE æ˜¯é¦–ä¸ªå°†**è®¡åˆ’ç»“æ„ã€å¤šæ­¥å‰ç»æ€§ã€æŒ‡ä»¤ååŒä¼˜åŒ–ã€åŠŸèƒ½ä¿çœŸå‹ç¼©**ç»Ÿä¸€å»ºæ¨¡çš„ç«¯åˆ°ç«¯æ¡†æ¶ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒåœ¨ä¸‰ä¸ªé•¿å‘¨æœŸã€å¤šæ­¥éª¤ä»£ç†åŸºå‡†ä¸Šè¿›è¡Œï¼š
1. **AppWorld**ï¼šæ¨¡æ‹Ÿè·¨å¤šä¸ªåº”ç”¨ç¨‹åºçš„äº¤äº’ä»»åŠ¡ï¼ˆå¦‚é‚®ä»¶ã€æ—¥å†ã€æµè§ˆå™¨ï¼‰ï¼Œæ¶‰åŠå¼‚æ„è§‚å¯Ÿå’Œå·¥å…·è°ƒç”¨ã€‚
2. **OfficeBench**ï¼šé¢å‘åŠå…¬è‡ªåŠ¨åŒ–åœºæ™¯ï¼Œæ¶µç›–æ–‡æ¡£å¤„ç†ã€è¡¨æ ¼æ“ä½œã€æ–‡ä»¶ç®¡ç†ç­‰ç»“æ„åŒ–ä»»åŠ¡ã€‚
3. **8-Objective QA**ï¼šå¤šè·³é—®ç­”ä»»åŠ¡ï¼Œéœ€é€šè¿‡å·¥å…·æœç´¢å¹¶èšåˆä¿¡æ¯ï¼Œæµ‹è¯•é•¿æœŸè®°å¿†ä¸æ¨ç†èƒ½åŠ›ã€‚

è¿™äº›æ•°æ®é›†å‡æä¾›æ˜ç¡®çš„ä»»åŠ¡åˆ†è§£ï¼ˆplan annotationsï¼‰ï¼Œä¾¿äºå»ºæ¨¡è®¡åˆ’ç»“æ„ã€‚

---

### å®éªŒè®¾ç½®
- **ä¸»å¹²æ¨¡å‹**ï¼šå›ºå®šä¸ºç›¸åŒçš„ LLMï¼ˆå¦‚ GPT-OSS æˆ– Qwenï¼‰ï¼Œä»…æ”¹å˜ä¸Šä¸‹æ–‡ç®¡ç†ç­–ç•¥ã€‚
- **å‹ç¼©ç­–ç•¥å¯¹æ¯”**ï¼š
  - No Compressionï¼ˆå…¨ä¿ç•™ï¼‰
  - FIFOï¼ˆæ»‘åŠ¨çª—å£ï¼‰
  - Retrievalï¼ˆåŸºäºåµŒå…¥çš„é€‰æ‹©ï¼‰
  - LLMLinguaï¼ˆæå–å¼å‹ç¼©ï¼‰
  - Promptingï¼ˆå¯å‘å¼æ‘˜è¦æç¤ºï¼‰
  - ACON UT / ACON UTCOï¼ˆå½“å‰æœ€ä¼˜åŸºçº¿ï¼‰
  - **PAACE (ours)**

- **PAACE æ¶æ„æµç¨‹**ï¼š
  1. ä½¿ç”¨æ•™å¸ˆæ¨¡å‹ï¼ˆGPT-OSS-120Bï¼‰åœ¨ PAACE-Syn åˆæˆæ•°æ®ä¸Šç”Ÿæˆé«˜è´¨é‡å‹ç¼©è½¨è¿¹ã€‚
  2. è’¸é¦å¾—åˆ°è½»é‡å­¦ç”Ÿæ¨¡å‹ **PAACE-FT**ï¼ˆåŸºäº Qwen3-4B-Instructï¼‰ã€‚
  3. åœ¨å®é™…ä»£ç†å¾ªç¯ä¸­éƒ¨ç½² PAACE-FT è¿›è¡Œå®æ—¶å‹ç¼©ã€‚

---

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ | æ„ä¹‰ |
|------|------|------|
| **Acc / EM / F1** | ä»»åŠ¡å‡†ç¡®ç‡ã€ç²¾ç¡®åŒ¹é…ã€F1åˆ†æ•° | è¡¡é‡ä»»åŠ¡æ­£ç¡®æ€§ |
| **Peak** | å•æ­¥æœ€å¤§è¾“å…¥tokenæ•° | åæ˜ å³°å€¼å†…å­˜å‹åŠ› |
| **Dependency** | $\sum_t |C_t|$ï¼ˆç´¯è®¡æ³¨æ„åŠ›è´Ÿè½½ï¼‰ | ä¼°ç®—æ€»è®¡ç®—å¼€é”€ï¼ˆä¸ $O(n^2)$ æ³¨æ„åŠ›ç›¸å…³ï¼‰ |
| **Steps** | å®Œæˆä»»åŠ¡æ‰€éœ€æ­¥æ•° | è¡¡é‡æ•ˆç‡ä¸ç¨³å®šæ€§ |

> æ³¨ï¼šæ‰€æœ‰æ–¹æ³•ä½¿ç”¨ç›¸åŒ backbone å’Œ plannerï¼Œä»…ä¸Šä¸‹æ–‡ç®¡ç†æ–¹å¼ä¸åŒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Tables 1â€“3ï¼‰

#### AppWorld ç»“æœ
| Method | Accâ†‘ | Stepsâ†“ | Peakâ†“ | Depâ†“ |
|--------|------|--------|-------|------|
| No Compression | 56.00 | 16.14 | 9.93 | 5.96 |
| ACON UTCO | 56.50 | 22.82 | 7.33 | 4.69 |
| **PAACE (ours)** | **59.00** | **19.20** | **6.23** | **3.75** |

âœ… **æå‡**ï¼š+2.5% å‡†ç¡®ç‡ï¼Œ-37% ç´¯è®¡ä¾èµ–ï¼Œ-37% å³°å€¼ä¸Šä¸‹æ–‡ã€‚

---

#### OfficeBench ç»“æœ
| Method | Accâ†‘ | Stepsâ†“ | Peakâ†“ | Depâ†“ |
|--------|------|--------|-------|------|
| No Compression | 76.84 | 11.52 | 7.27 | 4.43 |
| ACON UTCO | 72.63 | 11.54 | 4.54 | 1.91 |
| **PAACE (ours)** | **78.10** | **10.48** | **4.29** | **1.64** |

âœ… **æå‡**ï¼š+1.26% å‡†ç¡®ç‡ï¼Œ-63% ç´¯è®¡ä¾èµ–ï¼Œæ›´å°‘æ­¥éª¤ã€‚

---

#### 8-Objective QA ç»“æœ
| Method | EMâ†‘ | F1â†‘ | Stepsâ†“ | Peakâ†“ | Depâ†“ |
|--------|-----|-----|--------|-------|------|
| No Compression | 0.366 | 0.488 | 15.78 | 10.35 | 3.32 |
| ACON UTCO | 0.335 | 0.458 | 17.79 | 4.65 | 1.50 |
| **PAACE (ours)** | **0.402** | **0.512** | **16.86** | **4.41** | **1.41** |

âœ… **æ˜¾è‘—æå‡**ï¼š+6.7% EMï¼Œ+5.4% F1ï¼ŒåŒæ—¶é™ä½ä¸Šä¸‹æ–‡å¼€é”€ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- PAACE åœ¨æ‰€æœ‰ä¸‰é¡¹åŸºå‡†ä¸Šå‡**ä¼˜äºæœ€å¼ºåŸºçº¿ ACON UTCO**ï¼Œä¸”å¤šæ•°æƒ…å†µä¸‹ä¹Ÿä¼˜äºâ€œæ— å‹ç¼©â€åŸºçº¿ã€‚
- ç‰¹åˆ«æ˜¯åœ¨ **OfficeBench å’Œ QA ä»»åŠ¡ä¸­ï¼ŒPAACE æå‡äº†å‡†ç¡®æ€§çš„åŒæ—¶å¤§å¹…é™ä½äº†ä¸Šä¸‹æ–‡æ¶ˆè€—**ã€‚
- PAACE çš„å‹ç¼©æ¯”è¾¾åˆ° **35%-60% token reduction**ï¼Œè€Œä»»åŠ¡æ€§èƒ½ä¸é™åå‡ã€‚

> ğŸ’¡ è¿™è¡¨æ˜ï¼š**åˆç†çš„ä¸Šä¸‹æ–‡å‹ç¼©ä¸ä»…æ˜¯æ•ˆç‡å·¥å…·ï¼Œä¹Ÿæ˜¯ä¸€ç§æ­£åˆ™åŒ–æ‰‹æ®µ**ï¼Œæœ‰åŠ©äºå»é™¤å™ªå£°ã€ç¨³å®šæ¨ç†ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 4ï¼‰
ç ”ç©¶äº†ä¸åŒ **lookahead æ­¥æ•° k** å¯¹æ€§èƒ½çš„å½±å“ï¼š

| Benchmark | k | Acc/EMâ†‘ | Peakâ†“ | Depâ†“ |
|----------|----|---------|-------|------|
| AppWorld | 1 | 56.5 | 6.05 | 3.95 |
|          | 2 | **59.0** | 6.23 | **3.75** |
|          | 3 | 58.6 | 6.48 | 3.82 |
| OfficeBench | 2 | **78.1** | 4.29 | **1.64** |
| 8-Objective QA | 3 | **0.402** | 4.41 | **1.41** |

#### å‘ç°ï¼š
- å·¥å…·å¯†é›†å‹ä»»åŠ¡ï¼ˆAppWorld, OfficeBenchï¼‰ï¼š**k=2 è¶³å¤Ÿ**
- å¤šè·³é—®ç­”ä»»åŠ¡ï¼ˆQAï¼‰ï¼šéœ€è¦æ›´é•¿è§†é‡ **k=3 æ›´ä¼˜**
- æ›´å¤§çš„ k å¯¼è‡´å‹ç¼©éš¾åº¦å¢åŠ ï¼Œæ”¶ç›Šé€’å‡

> âœ… éªŒè¯äº† **next-k-task modeling çš„æœ‰æ•ˆæ€§**ï¼Œä¸”åº”æ ¹æ®ä»»åŠ¡ä¾èµ–ç»“æ„é€‰æ‹©åˆé€‚çš„ kã€‚

æ­¤å¤–ï¼Œç¦ç”¨æŒ‡ä»¤é‡å†™çš„å˜ä½“å¤±è´¥ç‡æ˜æ˜¾ä¸Šå‡ï¼Œè¯´æ˜**éšå¼æŒ‡ä»¤é‡å¡‘å¯¹é•¿å‘¨æœŸé²æ£’æ€§è‡³å…³é‡è¦**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **è®¡åˆ’æ„ŸçŸ¥çš„ä¸Šä¸‹æ–‡å‹ç¼©æ˜¾è‘—æå‡ä»£ç†æ€§èƒ½**ï¼šç›¸æ¯”æ— å‹ç¼©æˆ–ç®€å•å‹ç¼©ï¼ŒPAACE ä¸ä»…å‡å°‘ä¸Šä¸‹æ–‡è´Ÿæ‹…ï¼Œè¿˜èƒ½æé«˜ä»»åŠ¡æˆåŠŸç‡ã€‚
2. âœ… **å‹ç¼©å³æ­£åˆ™åŒ–**ï¼šå»é™¤å†—ä½™ã€è¿‡æ—¶ã€çŸ›ç›¾çš„ä¿¡æ¯ï¼Œåè€Œå¢å¼ºäº†æ¨ç†ä¸€è‡´æ€§ï¼Œç¼“è§£äº†â€œä¸Šä¸‹æ–‡è…åŒ–â€ã€‚
3. âœ… **next-k-task å»ºæ¨¡ä¼˜äºå•æ­¥å‹ç¼©**ï¼šè€ƒè™‘æœªæ¥å¤šæ­¥éœ€æ±‚å¯æœ‰æ•ˆä¿ç•™è·¨æ­¥ä¾èµ–ï¼ˆå¦‚å˜é‡ã€çº¦æŸã€æ–‡æ¡£å¼•ç”¨ï¼‰ã€‚
4. âœ… **åˆæˆæ•°æ® + è’¸é¦å¯è¡Œä¸”é«˜æ•ˆ**ï¼šPAACE-Syn ç”Ÿæˆçš„å¤§è§„æ¨¡å¸¦æ ‡æ³¨è½¨è¿¹ä½¿è½»é‡æ¨¡å‹ï¼ˆPAACE-FTï¼‰èƒ½ç»§æ‰¿ 97% æ•™å¸ˆæ€§èƒ½ï¼Œæ¨ç†æˆæœ¬é™ä½ä¸€ä¸ªæ•°é‡çº§ä»¥ä¸Šã€‚
5. âœ… **PAACE-FT å®ç”¨æ€§å¼º**ï¼šæ¯æ­¥ä»…å¢åŠ  <8% å»¶è¿Ÿï¼Œå´å¸¦æ¥å‡€æˆæœ¬ä¸‹é™ï¼Œé€‚åˆå®é™…éƒ¨ç½²ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. â— **ä¾èµ–è®¡åˆ’å¯ç”¨æ€§**ï¼šè‹¥ä»»åŠ¡æ— æ˜¾å¼ plan annotationsï¼Œåˆ™éœ€é¢å¤–ä½¿ç”¨ LLM è§„åˆ’å™¨ç”Ÿæˆï¼Œå¯èƒ½å¼•å…¥è¯¯å·®ã€‚
2. â— **æœªæä¾›å½¢å¼åŒ–ä¿è¯**ï¼šå‹ç¼©åŸºäºç»éªŒç›‘ç£ï¼ˆoutcome-level filteringï¼‰ï¼Œæ— æ³•ä¿è¯è¯­ä¹‰ç­‰ä»·æˆ–å®‰å…¨æ€§ã€‚
3. â— **é¢†åŸŸç‰¹å¼‚æ€§è¾ƒå¼º**ï¼šPAACE å­¦ä¹ çš„æ˜¯ç¯å¢ƒç‰¹å®šçš„å‹ç¼©ç­–ç•¥ï¼Œè·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›æœ‰å¾…éªŒè¯ã€‚
4. â— **ä¸é€‚ç”¨äºå®‰å…¨å…³é”®åœºæ™¯**ï¼šå‹ç¼©å¯èƒ½æ„å¤–åˆ é™¤å®‰å…¨çº¦æŸæˆ–æº¯æºä¿¡æ¯ï¼Œéœ€é¢å¤–æ ¡éªŒæœºåˆ¶ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. ğŸ”® å¼•å…¥**ç¬¦å·æ£€æŸ¥å™¨æˆ–é¢†åŸŸéªŒè¯å™¨**ï¼Œå¢å¼ºå‹ç¼©çš„å®‰å…¨æ€§å’Œå¯è§£é‡Šæ€§ã€‚
2. ğŸ” æ¢ç´¢**åœ¨çº¿è‡ªé€‚åº”å‹ç¼©ç­–ç•¥**ï¼ŒåŠ¨æ€è°ƒæ•´ k æˆ–å‹ç¼©å¼ºåº¦ã€‚
3. ğŸŒ æé«˜**è·¨ä»»åŠ¡/è·¨é¢†åŸŸçš„æ³›åŒ–èƒ½åŠ›**ï¼Œæ„å»ºé€šç”¨è®¡åˆ’æ„ŸçŸ¥å‹ç¼©å™¨ã€‚
4. ğŸ§  ç»“åˆ**è®¤çŸ¥æ¶æ„è®¾è®¡**ï¼ˆå¦‚å·¥ä½œè®°å¿†ã€é•¿æœŸè®°å¿†ï¼‰ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–ä¸Šä¸‹æ–‡åˆ†å±‚ç®¡ç†ã€‚
5. âš™ï¸ å°† PAACE é›†æˆä¸º**æ ‡å‡†ä»£ç†æ¶æ„æ¨¡å—**ï¼Œç±»æ¯” RAG ä¹‹äºçŸ¥è¯†ç³»ç»Ÿã€‚

---

## æ€»ç»“
PAACE æå‡ºäº†ä¸€ç§å…¨æ–°çš„è§†è§’â€”â€”å°†**ä¸Šä¸‹æ–‡å·¥ç¨‹**ä½œä¸º LLM ä»£ç†çš„æ ¸å¿ƒç»„ä»¶ï¼Œé€šè¿‡**è®¡åˆ’æ„ŸçŸ¥ã€å¤šæ­¥å‰ç»æ€§ã€åŠŸèƒ½ä¿çœŸå‹ç¼©**ï¼Œå®ç°äº†**æ€§èƒ½æå‡ä¸æˆæœ¬é™ä½çš„åŒèµ¢**ã€‚å…¶å®éªŒå……åˆ†éªŒè¯äº†è¯¥æ–¹æ³•åœ¨å¤šä¸ªå¤æ‚åŸºå‡†ä¸Šçš„ä¼˜è¶Šæ€§ï¼Œå¹¶ä¸ºæœªæ¥æ„å»ºé«˜æ•ˆã€ç¨³å¥çš„é•¿å‘¨æœŸæ™ºèƒ½ä»£ç†æä¾›äº†é‡è¦åŸºç¡€ã€‚

</details>

---

### 10. [Linear Personality Probing and Steering in LLMs: A Big Five Study](https://arxiv.org/abs/2512.17639)

**Authors**: Michel Frising, Daniel Balcells  
**Category**: cs.CL  
**Published**: 2025-12-22  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.17639v1  

#### Abstract
Large language models (LLMs) exhibit distinct and consistent personalities that greatly impact trust and engagement. While this means that personality frameworks would be highly valuable tools to characterize and control LLMs' behavior, current approaches remain either costly (post-training) or brit...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡ã€ŠLinear Personality Probing and Steering in LLMs: A Big Five Studyã€‹æ ¸å¿ƒæ€»ç»“**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨äº¤äº’ä¸­è¡¨ç°å‡ºæ˜¾è‘—ä¸”ä¸€è‡´çš„â€œäººæ ¼â€ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾æ·±åˆ»å½±å“ç”¨æˆ·çš„ä¿¡ä»»ã€å‚ä¸åº¦å’Œäº§å“ä½“éªŒã€‚ç„¶è€Œï¼Œå½“å‰æ§åˆ¶å’Œæ¢æµ‹ LLM äººæ ¼çš„æ–¹æ³•å­˜åœ¨ä¸¤å¤§ç“¶é¢ˆï¼š
- **é«˜æˆæœ¬**ï¼šå¦‚åè®­ç»ƒï¼ˆpost-trainingï¼‰ã€ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æˆ–å¼ºåŒ–å­¦ä¹ äººç±»åé¦ˆï¼ˆRLHFï¼‰ç­‰æ–¹æ³•è™½ç„¶æœ‰æ•ˆï¼Œä½†éœ€è¦å¤§é‡è®¡ç®—èµ„æºå’Œæ•°æ®ã€‚
- **è„†å¼±æ€§**ï¼šæç¤ºå·¥ç¨‹ï¼ˆprompt engineeringï¼‰è™½çµæ´»ï¼Œä½†å¯¹è¾¹ç¼˜æƒ…å†µæ•æ„Ÿï¼Œå®¹æ˜“è¢«ç»•è¿‡ï¼Œä¸”æ•ˆæœä¸ç¨³å®šã€‚

å› æ­¤ï¼Œå¦‚ä½•ä»¥ä½æˆæœ¬ã€é«˜é²æ£’æ€§çš„æ–¹å¼æ¢æµ‹å’Œæ“æ§ LLM çš„äººæ ¼ç‰¹è´¨ï¼Œæˆä¸ºä¸€ä¸ªäºŸå¾…è§£å†³çš„é—®é¢˜ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº **Big Five äººæ ¼æ¡†æ¶** çš„ **çº¿æ€§äººæ ¼æ¢æµ‹ä¸å¼•å¯¼ï¼ˆLinear Personality Probing and Steeringï¼‰** æ–¹æ³•ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š
- **å°†å¿ƒç†æµ‹é‡å­¦å·¥å…·å¼•å…¥ LLM äººæ ¼å»ºæ¨¡**ï¼šé¦–æ¬¡ç³»ç»Ÿåœ°ä½¿ç”¨ **Big Five Personality Traits**ï¼ˆå¤–å‘æ€§ã€å®œäººæ€§ã€å°½è´£æ€§ã€æƒ…ç»ªç¨³å®šæ€§ã€å¼€æ”¾æ€§ï¼‰ä½œä¸ºé‡åŒ–äººæ ¼çš„åŸºç¡€ï¼Œè€Œéä¾èµ–äºŒå…ƒå½¢å®¹è¯æˆ–å•ä¸€è´Ÿé¢è¡Œä¸ºï¼ˆå¦‚è°„åªšã€å¹»è§‰ï¼‰ã€‚
- **æ„å»ºäººæ ¼æ ‡æ³¨è§’è‰²æ•°æ®é›†**ï¼šåˆ©ç”¨ LLM è‡ªèº«ç”Ÿæˆ 406 ä¸ªè™šæ„è§’è‰²å¯¹ **IPIP-50 é—®å·** çš„å›ç­”ï¼Œç»“åˆå…¶æ–‡æœ¬æè¿°ï¼Œå½¢æˆå…·æœ‰è¿ç»­äººæ ¼å¾—åˆ†çš„â€œè§’è‰²æ¡£æ¡ˆâ€ã€‚
- **é€šè¿‡çº¿æ€§å›å½’å­¦ä¹ äººæ ¼æ–¹å‘**ï¼šåœ¨ Llama 3.3 70B çš„éšè—æ¿€æ´»ç©ºé—´ä¸­ï¼Œä½¿ç”¨çº¿æ€§å›å½’ä»ä¸åŒä½ç½®ï¼ˆè¾“å…¥æœ«å°¾ã€è¾“å…¥å‡å€¼ã€è¾“å‡ºå‡å€¼ï¼‰æå–ä¸ Big Five å¾—åˆ†å¯¹é½çš„ **per-layer çº¿æ€§æ–¹å‘ï¼ˆlinear directionsï¼‰**ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹æ³• | ç¼ºé™· | æœ¬æ–‡ä¼˜åŠ¿ |
|------|------|----------|
| **Adjective-based æ–¹æ³•** [Allbert et al., 2025] | ä»…æ”¯æŒäºŒå…ƒäººæ ¼ï¼ˆæœ‰/æ— ï¼‰ï¼Œç¼ºä¹ç»†ç²’åº¦ | æ”¯æŒ**è¿ç»­ã€å¤šç»´åº¦äººæ ¼è¯„åˆ†**ï¼Œæ›´è´´è¿‘çœŸå®äººæ ¼ç»“æ„ |
| **LLM-as-Judge æ–¹æ³•** [Chen et al., 2025] | è¦†ç›–çª„ï¼ˆä»…é’ˆå¯¹ sycophancy ç­‰å°‘æ•°è¡Œä¸ºï¼‰ | è¦†ç›– **Big Five å…¨è°±ç³»äººæ ¼ç»´åº¦**ï¼Œå…·å¤‡æ™®é€‚æ€§ |
| **Prompt Engineering** | è„†å¼±ã€æ˜“è¢«ç»•è¿‡ | **æ¨ç†æ—¶å¹²é¢„ï¼ˆinference-timeï¼‰**ï¼Œæ— éœ€é‡æ–°è®­ç»ƒï¼Œæˆæœ¬ä½ |
| **Post-training** | æˆæœ¬é«˜ã€ä¸å¯é€† | **è½»é‡çº§ã€å¯é€†å¹²é¢„**ï¼Œé€‚åˆå¿«é€Ÿè¿­ä»£ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
1. **è§’è‰²ä¸äººæ ¼å¾—åˆ†æ•°æ®é›†**ï¼š
   - é€‰å– **406 ä¸ªæ¥è‡ªå½±è§†ä½œå“çš„è™šæ„è§’è‰²**ï¼ˆå¦‚ Tony Soprano, Logan Roy, Michael Scott ç­‰ï¼‰ã€‚
   - ä½¿ç”¨ **Llama 3.3 70B** æ¨¡æ‹Ÿæ¯ä¸ªè§’è‰²å®Œæˆ **IPIP-50 Big Five é—®å·**ï¼Œè·å¾—äº”å¤§äººæ ¼ç»´åº¦çš„è¿ç»­å¾—åˆ†ã€‚
   - åŒæ—¶ç”Ÿæˆè§’è‰²è§†è§’ä¸‹çš„ç®€çŸ­è§£é‡Šï¼Œç”¨äºåç»­æç¤ºã€‚
2. **æŒ‡ä»¤æ•°æ®é›†**ï¼š
   - ä½¿ç”¨ **Alpaca æŒ‡ä»¤æ•°æ®é›†** ä¸­çš„ 10 æ¡æŒ‡ä»¤ï¼Œæ¶µç›–ï¼š
     - äººæ ¼ç›¸å…³ä»»åŠ¡ï¼ˆå¦‚â€œæè¿°ä¸€æ¬¡è‰°éš¾å†³å®šâ€ï¼‰
     - äººæ ¼æ— å…³ä»»åŠ¡ï¼ˆå¦‚â€œä»€ä¹ˆæ˜¯ä¸‰åŸè‰²ï¼Ÿâ€ï¼‰

### **å®éªŒè®¾ç½®**
- **æ¨¡å‹**ï¼š`meta-llama/Llama-3.3-70B-Instruct`
- **æ¿€æ´»é‡‡é›†ä½ç½®**ï¼š
  - è¾“å…¥æç¤ºçš„æœ€åä¸€ä¸ª token
  - æ‰€æœ‰è¾“å…¥ token çš„å¹³å‡æ¿€æ´»
  - æ‰€æœ‰ç”Ÿæˆ token çš„å¹³å‡æ¿€æ´»
- **æ¯å±‚æå–**ï¼šæ‰€æœ‰ transformer å±‚çš„éšè—çŠ¶æ€
- **äººæ ¼æ–¹å‘å­¦ä¹ **ï¼š
  - å¯¹æ¯ä¸ª trait å’Œæ¯å±‚ï¼Œä½¿ç”¨ **çº¿æ€§å›å½’** é¢„æµ‹ Big Five å¾—åˆ†ï¼š  
    $ s = \mathbf{w} \cdot \mathbf{a} + b + \epsilon $
  - æ¯”è¾ƒ **çº¿æ€§å›å½’** ä¸ **SVD**ï¼ˆå¥‡å¼‚å€¼åˆ†è§£ï¼‰æå–çš„æ–¹å‘

### **è¯„ä¼°æŒ‡æ ‡**
1. **æ¢æµ‹èƒ½åŠ›ï¼ˆProbingï¼‰**ï¼š
   - å°†æ–¹å‘åº”ç”¨äºä¸äººæ ¼ç›¸å…³çš„å½¢å®¹è¯ï¼ˆå¦‚â€œextrovertedâ€ vs â€œintrovertedâ€ï¼‰ï¼Œè§‚å¯Ÿæ¿€æ´»æŠ•å½±æ˜¯å¦èƒ½åŒºåˆ†æ­£è´ŸåŠ è½½è¯ã€‚
   - ä½¿ç”¨ **ROC æ›²çº¿** å’Œ AUC è¡¡é‡åˆ†ç±»æ€§èƒ½ã€‚
2. **å¼•å¯¼èƒ½åŠ›ï¼ˆSteeringï¼‰**ï¼š
   - åœ¨æ¨ç†æ—¶ä¿®æ”¹éšè—çŠ¶æ€ï¼š$ \mathbf{h}' = \mathbf{h} + \alpha \mathbf{r}_f $
   - è¯„ä¼°åœ¨ä»¥ä¸‹ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼š
     - **å¼ºåˆ¶é€‰æ‹©ä»»åŠ¡**ï¼ˆforced-choiceï¼‰ï¼šé€‰æ‹©æœ€ç¬¦åˆäººæ ¼çš„ 5 æ¡é™ˆè¿°
     - **å¼€æ”¾å¼ç”Ÿæˆä»»åŠ¡**ï¼šå¦‚â€œæè¿°ä¸€æ¬¡è‰°éš¾å†³å®šâ€
   - è§‚å¯Ÿå“åº”éš $\alpha$ å˜åŒ–çš„è¶‹åŠ¿ï¼Œä»¥åŠæ˜¯å¦è¢«ä¸Šä¸‹æ–‡è¦†ç›–ã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **SVD æ–¹å‘**ï¼šä½œä¸ºæ— ç›‘ç£æœ€å¤§æ–¹å·®æ–¹å‘çš„åŸºçº¿ã€‚
- **ä¸åŒæ¿€æ´»ä½ç½®**ï¼šæ¯”è¾ƒ last tokenã€input meanã€output mean æå–æ–¹å‘çš„æ•ˆæœã€‚
- **æœ‰æ— è§’è‰²æè¿°**ï¼šæµ‹è¯•æ˜¾å¼äººæ ¼ä¸Šä¸‹æ–‡æ˜¯å¦è¦†ç›–çº¿æ€§å¼•å¯¼ã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
#### **(1) æ¢æµ‹èƒ½åŠ›ï¼ˆProbingï¼‰**
- **æ–¹å‘æ³›åŒ–æ€§**ï¼šå­¦ä¹ åˆ°çš„æ–¹å‘èƒ½æœ‰æ•ˆåˆ†ç¦»ä¸å„ trait æ­£/è´Ÿç›¸å…³çš„å½¢å®¹è¯ï¼ˆå¦‚ extraversion çš„â€œlife of the partyâ€ vs â€œkeep in the backgroundâ€ï¼‰ã€‚
- **ROC æ€§èƒ½**ï¼šåœ¨ä¸­é—´åˆ°åæœŸå±‚ï¼ˆmiddle to late layersï¼‰è¾¾åˆ°å³°å€¼ï¼ŒAUC > 0.9ï¼Œè¡¨æ˜æ–¹å‘æ•æ‰åˆ°äº†è¶…è¶Šè®­ç»ƒé—®å·çš„è¯­ä¹‰ç»“æ„ã€‚
- **æ–¹å‘æ­£äº¤æ€§**ï¼šå›å½’å¾—åˆ°çš„äº”ä¸ª trait æ–¹å‘ä¹‹é—´äº¤å‰å¹²æ‰°å°ï¼Œè¿‘ä¼¼æ­£äº¤ã€‚

#### **(2) å¼•å¯¼èƒ½åŠ›ï¼ˆSteeringï¼‰**
- **å¼ºåˆ¶é€‰æ‹©ä»»åŠ¡**ï¼š
  - ä½¿ç”¨ **input prompt å‡å€¼æ¿€æ´»** æå–çš„æ–¹å‘ï¼Œ$\alpha \in [-0.4, 0.4]$ å†…å¯å®ç° **å•è°ƒã€å¯é çš„äººæ ¼å€¾å‘åˆ‡æ¢**ï¼ˆå¦‚ä» introverted åˆ° extravertedï¼‰ã€‚
  - è¿‡æ¸¡å‘ˆé˜¶æ¢¯çŠ¶ï¼ˆå› é€‰æ‹©ç¦»æ•£ï¼‰ï¼Œä½†è¶‹åŠ¿æ˜ç¡®ã€‚
- **SVD æ–¹å‘æ— æ•ˆ**ï¼šæ— æ³•äº§ç”Ÿç³»ç»Ÿæ€§å˜åŒ–ï¼ˆè§ Figure 6ï¼‰ã€‚
- **ç”Ÿæˆç­”æ¡ˆå‡å€¼æ–¹å‘**ï¼šè¿‡æ¸¡æ›´å¹³æ»‘ä½†å¯é æ€§è¾ƒä½ã€‚

#### **(3) ä¸Šä¸‹æ–‡è¦†ç›–æ•ˆåº”**
- å½“æç¤ºä¸­åŠ å…¥ **æ˜¾å¼è§’è‰²æè¿°**ï¼ˆå¦‚â€œä½ æ˜¯ä¸€ä¸ªå¤–å‘çš„äººâ€ï¼‰æ—¶ï¼Œ**çº¿æ€§å¼•å¯¼å®Œå…¨å¤±æ•ˆ**ï¼Œæ¨¡å‹è¡Œä¸ºç”±æè¿°ä¸»å¯¼ã€‚
- è¡¨æ˜ **è‡ªç„¶è¯­è¨€æŒ‡ä»¤ > æ¿€æ´»ç©ºé—´å¹²é¢„**ã€‚

#### **(4) å¼€æ”¾å¼ç”Ÿæˆä»»åŠ¡**
- åœ¨â€œæè¿°è‰°éš¾å†³å®šâ€ç­‰ä»»åŠ¡ä¸­ï¼Œ**äººå·¥æ£€æŸ¥æœªå‘ç°æ˜æ˜¾å¼•å¯¼æ•ˆæœ**ã€‚
- å¯èƒ½åŸå› ï¼š
  - ä»»åŠ¡æœ¬èº«å¼ºä¸Šä¸‹æ–‡ä¾èµ–
  - äººæ ¼å½±å“ç»†å¾®ï¼Œéš¾ä»¥é‡åŒ–
  - å¼•å¯¼ä¿¡å·è¢«ä»»åŠ¡å…ˆéªŒè¦†ç›–

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. âœ… **Big Five äººæ ¼åœ¨ LLM æ¿€æ´»ç©ºé—´ä¸­å‘ˆçº¿æ€§ç¼–ç **ï¼š
   - å›å½’å­¦ä¹ åˆ°çš„æ–¹å‘èƒ½æœ‰æ•ˆæ¢æµ‹äººæ ¼ï¼Œä¸”åœ¨å½¢å®¹è¯åˆ†ç±»ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ã€‚
   - æ”¯æŒâ€œäººæ ¼æ˜¯ LLM è¡¨å¾å‡ ä½•çš„ä¸€éƒ¨åˆ†â€çš„å‡è®¾ã€‚

2. âš ï¸ **çº¿æ€§å¼•å¯¼åœ¨ç»“æ„åŒ–ä»»åŠ¡ä¸­æœ‰æ•ˆï¼Œä½†åœ¨å¼€æ”¾ä»»åŠ¡ä¸­å—é™**ï¼š
   - åœ¨ **forced-choice** å’Œ Likert ä»»åŠ¡ä¸­å¯å®ç°å¯é å¼•å¯¼ã€‚
   - åœ¨ **å¼€æ”¾å¼ç”Ÿæˆ** ä¸­æ•ˆæœå¾®å¼±æˆ–ä¸å¯æµ‹ã€‚

3. ğŸ” **ä¸Šä¸‹æ–‡ä¼˜å…ˆäºæ¿€æ´»å¹²é¢„**ï¼š
   - æ˜¾å¼äººæ ¼æè¿°æˆ–ä»»åŠ¡ä¸Šä¸‹æ–‡ï¼ˆå¦‚å®¢æœåœºæ™¯ï¼‰ä¼šå®Œå…¨è¦†ç›–çº¿æ€§å¼•å¯¼ã€‚
   - è¡¨æ˜ LLM çš„æ§åˆ¶æœºåˆ¶å­˜åœ¨ **å±‚çº§å…³ç³»**ï¼šprompt > activation steeringã€‚

4. ğŸ†š **SVD ä¸é€‚ç”¨äºäººæ ¼å¼•å¯¼**ï¼š
   - æœ€å¤§æ–¹å·®æ–¹å‘ä¸äººæ ¼æ— å…³ï¼Œç”šè‡³æ­£äº¤ã€‚
   - å¼ºè°ƒ **ç›‘ç£å­¦ä¹ ï¼ˆå›å½’ï¼‰** å¯¹ä»»åŠ¡å¯¹é½çš„é‡è¦æ€§ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **å¹³å‡äººæ ¼é—®é¢˜**ï¼šæ–¹å‘æ˜¯è·¨è§’è‰²å’Œé¡¹ç›®çš„å¹³å‡ï¼Œå¯èƒ½æ¨¡ç³Šä¸ªä½“å·®å¼‚ã€‚
- **éçº¿æ€§ç¼–ç å¯èƒ½æ€§**ï¼šäººæ ¼å¯èƒ½åˆ†å¸ƒåœ¨ä½ç§©å­ç©ºé—´æˆ–éçº¿æ€§æµå½¢ä¸Šï¼Œå•ä¸€çº¿æ€§æ–¹å‘ä¸è¶³ä»¥æ•æ‰ã€‚
- **è¯„ä¼°å›°éš¾**ï¼šå¼€æ”¾å¼ç”Ÿæˆç¼ºä¹å®¢è§‚æŒ‡æ ‡ï¼Œä¾èµ–äººå·¥åˆ¤æ–­ã€‚
- **æ¨¡å‹ä¾èµ–æ€§**ï¼šç›®å‰ä»…åœ¨ Llama 3.3 70B ä¸ŠéªŒè¯ï¼Œæ³›åŒ–æ€§å¾…æ£€éªŒã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **æ›´ç»†ç²’åº¦å»ºæ¨¡**ï¼š
   - æ¢ç´¢ **item-level æ–¹å‘** æˆ– **ä½ç§©å­ç©ºé—´**ï¼Œè€Œé trait-level å¹³å‡ã€‚
   - ç»“åˆ **persome** æ¦‚å¿µï¼ˆRevelle et al., 2021ï¼‰ï¼Œç ”ç©¶ä¸ªä½“é¡¹ç›®æ¨¡å¼ã€‚
2. **å¤šæœºåˆ¶ååŒæ§åˆ¶**ï¼š
   - æ¢ç´¢ **prompt + control vector** è”åˆå¹²é¢„ï¼Œé¿å…ç«äº‰ã€‚
   - ç ”ç©¶ **personality circuits**ï¼ˆè·¨å±‚å› æœè·¯å¾„ï¼‰ã€‚
3. **æ›´é²æ£’çš„è¯„ä¼°æ¡†æ¶**ï¼š
   - å¼€å‘è‡ªåŠ¨åŒ–å·¥å…·ï¼ˆå¦‚ LLM-as-judgeï¼‰è¯„ä¼°å¼€æ”¾å¼ç”Ÿæˆä¸­çš„äººæ ¼å€¾å‘ã€‚
4. **è·¨æ¨¡å‹ä¸è·¨æ–‡åŒ–éªŒè¯**ï¼š
   - éªŒè¯æ–¹æ³•åœ¨å…¶ä»– LLM å’Œéè¥¿æ–¹äººæ ¼æ¡†æ¶ï¼ˆå¦‚ HEXACOï¼‰ä¸‹çš„é€‚ç”¨æ€§ã€‚

---

> **æ€»ç»“**ï¼šæœ¬æ–‡é¦–æ¬¡å°† Big Five å¿ƒç†æµ‹é‡æ¡†æ¶ç³»ç»Ÿå¼•å…¥ LLM äººæ ¼ç ”ç©¶ï¼Œè¯æ˜äº†çº¿æ€§æ–¹å‘å¯ç”¨äºé«˜æ•ˆæ¢æµ‹äººæ ¼ï¼Œå¹¶åœ¨ç‰¹å®šä»»åŠ¡ä¸­å®ç°å¼•å¯¼ã€‚å°½ç®¡å­˜åœ¨ä¸Šä¸‹æ–‡è¦†ç›–å’Œå¼€æ”¾ç”Ÿæˆçš„å±€é™ï¼Œè¯¥å·¥ä½œä¸º **ä½æˆæœ¬ã€å¯è§£é‡Šçš„äººæ ¼æ§åˆ¶** æä¾›äº†é‡è¦èŒƒå¼ï¼Œæ¶èµ·äº†äººç±»å¿ƒç†å­¦ä¸ AI è¡Œä¸ºç ”ç©¶ä¹‹é—´çš„æ¡¥æ¢ã€‚

</details>

---

### 11. [NetworkFF: Unified Layer Optimization in Forward-Only Neural Networks](https://arxiv.org/abs/2512.17531)

**Authors**: Salar Beigzad  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.17531v1  

#### Abstract
The Forward-Forward algorithm eliminates backpropagation's memory constraints and biological implausibility through dual forward passes with positive and negative data. However, conventional implementations suffer from critical inter-layer isolation, where layers optimize goodness functions independ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*NetworkFF: Unified Layer Optimization in Forward-Only Neural Networks*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
åŸå§‹çš„ **Forward-Forward (FF)** ç®—æ³•è™½ç„¶è§£å†³äº†ä¼ ç»Ÿ **backpropagation** åœ¨å†…å­˜æ¶ˆè€—å’Œç”Ÿç‰©å¯è§£é‡Šæ€§æ–¹é¢çš„ç¼ºé™·ï¼Œä½†å…¶å„å±‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å®Œå…¨ç‹¬ç«‹ä¼˜åŒ–å„è‡ªçš„â€œgoodnessâ€å‡½æ•°ï¼Œå¯¼è‡´**å±‚é—´éš”ç¦»ï¼ˆinter-layer isolationï¼‰**ã€‚è¿™ç§éš”ç¦»é™åˆ¶äº†æ·±å±‚ç½‘ç»œä¸­çš„è¡¨å¾åè°ƒèƒ½åŠ›ï¼Œå½±å“æ”¶æ•›æ•ˆç‡å’Œæœ€ç»ˆæ€§èƒ½ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šCollaborative Forward-Forward (CFF)
æœ¬æ–‡æå‡º **Collaborative Forward-Forward (CFF)** å­¦ä¹ æ¡†æ¶ï¼Œåœ¨ä¿æŒ FF ç®—æ³•å‰å‘è®¡ç®—ç‰¹æ€§çš„åŸºç¡€ä¸Šå¼•å…¥**å±‚é—´åä½œæœºåˆ¶**ï¼Œå®ç°å…¨å±€ä¸Šä¸‹æ–‡æ•´åˆã€‚å…·ä½“åŒ…æ‹¬ä¸¤ç§å˜ä½“ï¼š
- **Fixed CFF (F-CFF)**ï¼šä½¿ç”¨å›ºå®šçš„åä½œå‚æ•° Î³ è¿›è¡Œå±‚é—´è€¦åˆã€‚
- **Adaptive CFF (A-CFF)**ï¼šåä½œå‚æ•°ä¸ºå¯å­¦ä¹ å˜é‡ï¼Œé€šè¿‡æ¢¯åº¦æ›´æ–°åŠ¨æ€è°ƒæ•´ã€‚

æ ¸å¿ƒæ€æƒ³æ˜¯å°†å…¶ä»–å±‚çš„ goodness å€¼åŠ æƒåçº³å…¥å½“å‰å±‚çš„ç›®æ ‡å‡½æ•°ä¸­ï¼š
$$
G_{\text{collab}}(x) = G_l(x) + \gamma \sum_k \omega_k G_k(x)
$$
ä»è€Œå®ç°å±‚é—´çš„ååŒç‰¹å¾å­¦ä¹ ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | Backpropagation | åŸå§‹ Forward-Forward | æœ¬æ–‡ CFF |
|------|------------------|------------------------|----------|
| å†…å­˜æ•ˆç‡ | âŒ é«˜ï¼ˆéœ€å­˜å‚¨æ¿€æ´»å€¼ï¼‰ | âœ… æé«˜ï¼ˆä»…å‰å‘ï¼‰ | âœ… ä¿æŒé«˜æ•ˆ |
| ç”Ÿç‰©å¯è§£é‡Šæ€§ | âŒ å·®ï¼ˆåå‘è¯¯å·®ä¼ æ’­æ— ç¥ç»ä¾æ®ï¼‰ | âœ… è¾ƒå¥½ | âœ… ç»´æŒå¹¶å¢å¼º |
| é»‘ç›’å…¼å®¹æ€§ | âŒ å¼±ï¼ˆä¾èµ–å¯¼æ•°ï¼‰ | âœ… å¼º | âœ… ä¿æŒ |
| å±‚é—´åä½œ | âœ… é€šè¿‡æ¢¯åº¦æµè‡ªç„¶è€¦åˆ | âŒ å®Œå…¨ç‹¬ç«‹ | âœ… æ˜¾å¼åä½œæœºåˆ¶ |
| æ€§èƒ½è¡¨ç° | âœ… é«˜ | â­• ä¸­ç­‰ | âœ… æ˜¾è‘—æå‡ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿**ï¼šåœ¨ä¸ç‰ºç‰² FF ç®—æ³•å†…å­˜æ•ˆç‡ã€ç”Ÿç‰©å¯è§£é‡Šæ€§å’Œé»‘ç›’å…¼å®¹æ€§çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›å’Œæ”¶æ•›é€Ÿåº¦ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†
- **MNIST**ï¼šæ‰‹å†™æ•°å­—è¯†åˆ«ä»»åŠ¡ï¼Œç”¨äºéªŒè¯åŸºç¡€æœ‰æ•ˆæ€§ã€‚
- **Fashion-MNIST**ï¼šæœè£…å›¾åƒåˆ†ç±»ï¼Œæ›´å…·è§†è§‰å¤æ‚æ€§ï¼Œæµ‹è¯•æ³›åŒ–èƒ½åŠ›ã€‚

ä¸¤è€…å‡ä¸º $28 \times 28$ ç°åº¦å›¾ï¼Œå±•å¹³ä¸º 784 ç»´è¾“å…¥å‘é‡ã€‚

### ğŸ—ï¸ ç½‘ç»œæ¶æ„
- è¾“å…¥å±‚ï¼š784 units
- ä¸¤ä¸ªéšè—å±‚ï¼šæ¯å±‚ 500 ReLU å•å…ƒ
- è¾“å‡ºå±‚ï¼šæœ€åä¸€å±‚æ¿€æ´»ä½œä¸ºåˆ†ç±»è¡¨ç¤º

é‡‡ç”¨ **label embedding** æŠ€æœ¯ï¼ˆä¿®æ”¹è¾“å…¥å‰10åƒç´ ç¼–ç ç±»åˆ«ï¼‰ï¼Œéµå¾ª Hinton çš„åŸå§‹ FF è®¾è®¡ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
| å‚æ•° | è®¾ç½® |
|------|------|
| æ¯å±‚è®­ç»ƒ epoch æ•° | 1000 |
| æ‰¹å¤§å° | å…¨æ‰¹é‡ï¼ˆ50,000 æ ·æœ¬ï¼‰ |
| ä¼˜åŒ–å™¨ | Adamï¼ˆåŸºç¡€å­¦ä¹ ç‡ 0.03ï¼‰ |
| A-CFF åä½œå‚æ•°å­¦ä¹ ç‡ | 0.01 |
| Goodness threshold Î¸ | 2.0 |
| å±‚å½’ä¸€åŒ– | Post-activation normalization |
| è¯„ä»·æ–¹å¼ | å¯¹æ¯ä¸ªå¯èƒ½æ ‡ç­¾è¿›è¡Œ forward passï¼Œé€‰æ‹©ç´¯è®¡ goodness æœ€é«˜çš„æ ‡ç­¾ |

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
- **Classification Accuracy**ï¼ˆè®­ç»ƒ/æµ‹è¯•ï¼‰
- **Training Efficiency**ï¼ˆæ”¶æ•›é€Ÿåº¦ã€è®­ç»ƒæ—¶é—´ï¼‰
- **Learning Dynamics**ï¼ˆé€å±‚è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–ï¼‰
- **Parameter Evolution**ï¼ˆA-CFF ä¸­åä½œå‚æ•°å˜åŒ–ï¼‰
- **Statistical Significance**ï¼ˆpaired t-test + Cohenâ€™s d æ•ˆåº”é‡ï¼‰

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
1. **Original FF**ï¼šæ ‡å‡† Forward-Forward å®ç°ï¼ˆæ— åä½œï¼‰
2. **F-CFF**ï¼šå›ºå®šåä½œå‚æ•°ï¼ˆÎ³=1.0ï¼‰
3. **A-CFF**ï¼šå¯å­¦ä¹ åä½œå‚æ•°ï¼ˆåˆå§‹åŒ– Î³=1.0ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### è¡¨æ ¼ï¼šè·¨æ•°æ®é›†æ€§èƒ½å¯¹æ¯”ï¼ˆTest Accuracyï¼‰

| Dataset / Model | Original FF | F-CFF | A-CFF | Improvement (vs Baseline) |
|------------------|-------------|-------|--------|----------------------------|
| **MNIST**        | 92.0%       | 92.6% | **93.8%** | +0.6% (F-CFF), **+1.8% (A-CFF)** |
| **Fashion-MNIST**| 81.0%       | 81.8% | **83.0%** | +0.8% (F-CFF), **+2.0% (A-CFF)** |

> âœ… A-CFF åœ¨æ›´éš¾çš„ä»»åŠ¡ä¸Šæå‡æ›´å¤§ï¼Œè¯´æ˜è‡ªé€‚åº”åä½œæœºåˆ¶å¯¹å¤æ‚ä»»åŠ¡æ›´æœ‰ç›Šã€‚

### ğŸ“Š è¯¦ç»†åˆ†æç»“æœ
- **æ”¶æ•›ç‰¹æ€§**ï¼š
  - A-CFF åœ¨ MNIST ä¸Šè¾¾åˆ° log-scale å‡†ç¡®ç‡ ~4.555ï¼Œä¼˜äº baseline (~4.53) å’Œ F-CFFã€‚
  - Fashion-MNIST ä¸Š A-CFF æŒç»­æ”¹è¿›è‡³æœ€åé˜¶æ®µï¼Œlog-scale å‡†ç¡®ç‡è¾¾ ~4.4345ï¼Œæ˜¾ç¤ºæ›´å¼ºçš„æŒç»­å­¦ä¹ èƒ½åŠ›ã€‚
- **ç¨³å®šæ€§**ï¼š
  - F-CFF æä¾›ç¨³å®šä¸”ä¸€è‡´çš„å°å¹…å¢ç›Šï¼ˆ+0.6â€“0.8%ï¼‰ï¼Œé€‚åˆèµ„æºå—é™åœºæ™¯ã€‚
  - A-CFF è™½æ€§èƒ½æ›´é«˜ï¼Œä½†éœ€é¢å¤–è°ƒå‚ï¼ˆåä½œå­¦ä¹ ç‡ï¼‰ã€‚
- **ç»Ÿè®¡æ˜¾è‘—æ€§**ï¼š
  - æ‰€æœ‰åä½œå˜ä½“ä¸åŸå§‹ FF çš„å·®å¼‚å‡å…·æœ‰ç»Ÿè®¡æ˜¾è‘—æ€§ï¼ˆp < 0.05ï¼ŒCohenâ€™s d > 0.8ï¼Œå¤§æ•ˆåº”é‡ï¼‰ã€‚

### ğŸ” æ¶ˆèå®éªŒï¼ˆéšå«åˆ†æï¼‰
å°½ç®¡æœªæ˜ç¡®å‘½åâ€œæ¶ˆèå®éªŒâ€ï¼Œæ–‡ä¸­é€šè¿‡ä»¥ä¸‹å¯¹æ¯”å®ç°äº†ç±»ä¼¼åŠŸèƒ½ï¼š
- **æ˜¯å¦å¯ç”¨åä½œæœºåˆ¶** â†’ F-CFF vs Original FF
- **åä½œå‚æ•°æ˜¯å¦å¯å­¦ä¹ ** â†’ A-CFF vs F-CFF
- **ä¸åŒæ•°æ®å¤æ‚åº¦ä¸‹çš„è¡¨ç°ä¸€è‡´æ€§** â†’ MNIST vs Fashion-MNIST

ç»“æœè¡¨æ˜ï¼šåä½œæœºåˆ¶æœ¬èº«å¸¦æ¥å¢ç›Šï¼Œè€Œ**å¯å­¦ä¹ å‚æ•°è¿›ä¸€æ­¥æ”¾å¤§æ”¶ç›Š**ï¼Œå°¤å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **å±‚é—´åä½œæ˜¾è‘—æå‡ FF æ€§èƒ½**ï¼š  
   å¼•å…¥åä½œæœºåˆ¶æ‰“ç ´äº†åŸå§‹ FF çš„å±‚é—´å­¤ç«‹çŠ¶æ€ï¼Œä½¿ç½‘ç»œèƒ½å¤Ÿè¿›è¡Œæ›´åè°ƒçš„ç‰¹å¾å­¦ä¹ ã€‚
   
2. **A-CFF ä¼˜äº F-CFF**ï¼š  
   å¯å­¦ä¹ çš„åä½œå‚æ•°èƒ½æ ¹æ®è®­ç»ƒåŠ¨æ€è‡ªåŠ¨è°ƒèŠ‚å±‚é—´å½±å“æƒé‡ï¼Œè·å¾—æ›´é«˜çš„å‡†ç¡®ç‡ï¼ˆ+1.8â€“2.0%ï¼‰ã€‚

3. **ä¿æŒ FF æ ¸å¿ƒä¼˜åŠ¿**ï¼š  
   CFF å®Œå…¨ä¿ç•™äº† FF çš„å‰å‘-only è®¡ç®—æ¨¡å¼ï¼Œå› æ­¤ä»å…·å¤‡ä½å†…å­˜å ç”¨ã€é«˜ç”Ÿç‰©å¯è§£é‡Šæ€§å’Œé»‘ç›’ç»„ä»¶å…¼å®¹æ€§ã€‚

4. **é€‚ç”¨äºèµ„æºå—é™ç³»ç»Ÿ**ï¼š  
   æˆæœç‰¹åˆ«é€‚ç”¨äº **neuromorphic computing** å’Œ **edge AI systems**ï¼Œä¸ºä½åŠŸè€—ã€ç±»è„‘è®¡ç®—æä¾›å¯è¡Œè·¯å¾„ã€‚

### âš ï¸ æ–¹æ³•å±€é™æ€§
- å½“å‰ä»…åœ¨ MLP æ¶æ„ä¸ŠéªŒè¯ï¼Œå°šæœªæ‰©å±•åˆ° CNNã€Transformer ç­‰ä¸»æµç»“æ„ã€‚
- åä½œæœºåˆ¶å¢åŠ äº†å°‘é‡è¶…å‚æ•°ï¼ˆå¦‚ Î³ åˆå§‹åŒ–ã€åä½œå­¦ä¹ ç‡ï¼‰ï¼Œéœ€è¦é€‚å½“è°ƒä¼˜ã€‚
- å¤šå±‚åä½œæ—¶çš„é€šä¿¡å¼€é”€è™½å°ä½†ä»å­˜åœ¨ï¼Œæç«¯è¾¹ç¼˜è®¾å¤‡éœ€æƒè¡¡æ”¶ç›Šä¸æˆæœ¬ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. å°† CFF æ‰©å±•è‡³å·ç§¯ç½‘ç»œå’Œæ›´æ·±æ¶æ„ã€‚
2. æ¢ç´¢ç¨€ç–åä½œæœºåˆ¶ï¼ˆä»…éƒ¨åˆ†å±‚äº¤äº’ï¼‰ä»¥è¿›ä¸€æ­¥é™ä½å¼€é”€ã€‚
3. ç»“åˆ predictive coding æˆ– cortical loop æ¨¡å‹æ·±åŒ–ç”Ÿç‰©åˆç†æ€§ã€‚
4. åœ¨çœŸå®åµŒå…¥å¼ç¡¬ä»¶ï¼ˆå¦‚ Loihiã€SpiNNakerï¼‰ä¸Šéƒ¨ç½²éªŒè¯èƒ½æ•ˆã€‚

---

## âœ… æ€»ç»“
è¯¥è®ºæ–‡æå‡ºçš„ **Collaborative Forward-Forward (CFF)** æ˜¯å¯¹åŸå§‹ FF ç®—æ³•çš„é‡è¦å¢å¼ºï¼Œé€šè¿‡å¼•å…¥å±‚é—´åä½œæœºåˆ¶æœ‰æ•ˆç¼“è§£äº†â€œå±‚é—´éš”ç¦»â€é—®é¢˜ï¼Œåœ¨ **MNIST** å’Œ **Fashion-MNIST** ä¸Šåˆ†åˆ«å®ç° **+1.8%** å’Œ **+2.0%** çš„ç²¾åº¦æå‡ï¼ŒåŒæ—¶å®Œæ•´ä¿ç•™äº† FF çš„å†…å­˜æ•ˆç‡ä¸ç”Ÿç‰©å¯è§£é‡Šæ€§ä¼˜åŠ¿ã€‚ç ”ç©¶æˆæœä¸ºæ„å»ºé«˜æ•ˆã€å¯è§£é‡Šã€é€‚ç”¨äºè¾¹ç¼˜è®¾å¤‡çš„ç±»è„‘å­¦ä¹ ç³»ç»Ÿæä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 12. [Probing Scientific General Intelligence of LLMs with Scientist-Aligned Workflows](https://arxiv.org/abs/2512.16969)

**Authors**: Wanghan Xu, Yuhao Zhou, Yifan Zhou, Qinglong Cao, Shuo Li, Jia Bu, Bo Liu, Yixin Chen, Xuming He, Xiangyu Zhao, Xiang Zhuang, Fengxiang Wang, Zhiwang Zhou, Qiantai Feng, Wenxuan Huang, Jiaqi Wei, Hao Wu, Yuejin Yang, Guangshuai Wang, Sheng Xu, Ziyan Huang, Xinyao Liu, Jiyao Liu, Cheng Tang, Wei Li, Ying Chen, Junzhi Ning, Pengfei Jiang, Chenglong Ma, Ye Du, Changkai Ji, Huihui Xu, Ming Hu, Jiangbin Zheng, Xin Chen, Yucheng Wu, Feifei Jiang, Xi Chen, Xiangru Tang, Yuchen Fu, Yingzhou Lu, Yuanyuan Zhang, Lihao Sun, Chengbo Li, Jinzhe Ma, Wanhao Liu, Yating Liu, Kuo-Cheng Wu, Shengdu Chai, Yizhou Wang, Ouwen Zhangjin, Chen Tang, Shufei Zhang, Wenbo Cao, Junjie Ren, Taoyong Cui, Zhouheng Yao, Juntao Deng, Yijie Sun, Feng Liu, Wangxu Wei, Jingyi Xu, Zhangrui Li, Junchao Gong, Zijie Guo, Zhiyu Yao, Zaoyu Chen, Tianhao Peng, Fangchen Yu, Bo Zhang, Dongzhan Zhou, Shixiang Tang, Jiaheng Liu, Fenghua Ling, Yan Lu, Yuchen Ren, Ben Fei, Zhen Zhao, Xinyu Gu, Rui Su, Xiao-Ming Wu, Weikang Si, Yang Liu, Hao Chen, Xiangchao Yan, Xue Yang, Junchi Yan, Jiamin Wu, Qihao Zheng, Chenhui Li, Zhiqiang Gao, Hao Kong, Junjun He, Mao Su, Tianfan Fu, Peng Ye, Chunfeng Song, Nanqing Dong, Yuqiang Li, Huazhu Fu, Siqi Sun, Lijing Cheng, Jintai Lin, Wanli Ouyang, Bowen Zhou, Wenlong Zhang, Lei Bai  
**Category**: cs.AI  
**Published**: 2025-12-22  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.16969v1  

#### Abstract
Despite advances in scientific AI, a coherent framework for Scientific General Intelligence (SGI)-the ability to autonomously conceive, investigate, and reason across scientific domains-remains lacking. We present an operational SGI definition grounded in the Practical Inquiry Model (PIM: Deliberati...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šProbing Scientific General Intelligence of LLMs with Scientist-Aligned Workflows

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¯¹ **Scientific General Intelligence (SGI)** çš„å®šä¹‰æ¨¡ç³Šï¼Œç¼ºä¹ç³»ç»Ÿæ€§ã€å¯é‡åŒ–çš„è¯„ä¼°æ¡†æ¶ã€‚ç°æœ‰çš„ LLM åŸºå‡†æµ‹è¯•å¤šé›†ä¸­äºäº‹å®è®°å¿†æˆ–å•æ­¥æ¨ç†ä»»åŠ¡ï¼Œæ— æ³•æœ‰æ•ˆè¡¡é‡æ¨¡å‹åœ¨çœŸå®ç§‘ç ”æµç¨‹ä¸­çš„ç»¼åˆèƒ½åŠ›ï¼Œå¦‚è‡ªä¸»æå‡ºå‡è®¾ã€è®¾è®¡å®éªŒã€æ‰§è¡Œåˆ†æç­‰ã€‚

è¯¥è®ºæ–‡æ—¨åœ¨å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæ„å»ºä¸€ä¸ªèƒ½å¤Ÿå…¨é¢è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹æ˜¯å¦å…·å¤‡â€œç±»ç§‘å­¦å®¶â€æ€ç»´ä¸è¡Œä¸ºèƒ½åŠ›çš„åŸºå‡†ä½“ç³»ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯

#### ï¼ˆ1ï¼‰æå‡ºåŸºäº **Practical Inquiry Model (PIM)** çš„ SGI æ“ä½œåŒ–å®šä¹‰
å°† SGI å®šä¹‰ä¸º AI èƒ½å¤Ÿ**è‡ªä¸»å®Œæˆç§‘å­¦æ¢ç©¶çš„å®Œæ•´è¿­ä»£å¾ªç¯**ï¼Œæ¶µç›–å››ä¸ªè®¤çŸ¥é˜¶æ®µï¼š
- **Deliberationï¼ˆæ·±æ€ï¼‰**ï¼šçŸ¥è¯†æ£€ç´¢ã€æ•´åˆä¸æ‰¹åˆ¤æ€§è¯„ä¼°
- **Conceptionï¼ˆæ„æƒ³ï¼‰**ï¼šç”Ÿæˆç§‘å­¦ä¸Šåˆç†ä¸”æ–°é¢–çš„å‡è®¾æˆ–æ–¹æ³•
- **Actionï¼ˆè¡ŒåŠ¨ï¼‰**ï¼šè§„åˆ’å¹¶æ‰§è¡Œå¹²/æ¹¿å®éªŒï¼ˆdry/wet experimentsï¼‰
- **Perceptionï¼ˆæ„ŸçŸ¥ï¼‰**ï¼šè§£é‡Šå®è¯ç»“æœï¼Œè¿›è¡Œå› æœä¸æƒ…å¢ƒåŒ–æ¨ç†

æ­¤å®šä¹‰é¦–æ¬¡å°†ç§‘å­¦ç ”ç©¶è¿‡ç¨‹ç»“æ„åŒ–ï¼Œå¹¶æ˜ å°„åˆ°å¯è¯„æµ‹çš„ä»»åŠ¡ä¸­ã€‚

#### ï¼ˆ2ï¼‰æ„å»º **SGI-Bench**ï¼šé¦–ä¸ªé¢å‘ç§‘å­¦å®¶å·¥ä½œæµçš„ç»¼åˆæ€§åŸºå‡†
- åŒ…å« **1,000+ ä¸“å®¶æ ‡æ³¨æ ·æœ¬**ï¼Œè¦†ç›– 10 å¤§å­¦ç§‘é¢†åŸŸï¼ˆastronomy, chemistry, earth science, energy, information science, life science, materials science, neuroscience, physics, mathï¼‰ã€‚
- æ‰€æœ‰é—®é¢˜çµæ„Ÿæ¥æºäº *Science* æ‚å¿—æå‡ºçš„ â€œ125 Big Questionsâ€ï¼Œç¡®ä¿é—®é¢˜å…·æœ‰å‰æ²¿æ€§å’Œç¤¾ä¼šç›¸å…³æ€§ã€‚
- è®¾è®¡å››å¤§ä»»åŠ¡ç±»åˆ«ï¼Œå¯¹åº” PIM å››é˜¶æ®µï¼š
  - **Scientific Deep Research**ï¼ˆå¯¹åº” Deliberationï¼‰
  - **Idea Generation**ï¼ˆå¯¹åº” Conceptionï¼‰
  - **Dry/Wet Experiment**ï¼ˆå¯¹åº” Actionï¼‰
  - **Experimental Reasoning**ï¼ˆå¯¹åº” Perceptionï¼‰

#### ï¼ˆ3ï¼‰å¼•å…¥ **Test-Time Reinforcement Learning (TTRL)**
- é’ˆå¯¹ Idea Generation ä¸­æ— æ ‡å‡†ç­”æ¡ˆçš„é—®é¢˜ï¼Œæå‡ºä¸€ç§æ— éœ€ç›‘ç£æ ‡ç­¾çš„å¼ºåŒ–å­¦ä¹ æœºåˆ¶ã€‚
- åœ¨æ¨ç†æ—¶ä¼˜åŒ–â€œæ£€ç´¢å¢å¼ºçš„æ–°é¢–æ€§å¥–åŠ±â€ï¼ˆretrieval-augmented novelty rewardï¼‰ï¼Œæå‡ç”Ÿæˆæƒ³æ³•çš„åŸåˆ›æ€§ä¸ç§‘å­¦ä»·å€¼ã€‚
- å®ç°äº†åœ¨æ²¡æœ‰å‚è€ƒç­”æ¡ˆçš„æƒ…å†µä¸‹å¢å¼ºå‡è¯´æ–°é¢–æ€§çš„ç›®æ ‡ã€‚

#### ï¼ˆ4ï¼‰å¼€å‘ **SGIEvalAgent**ï¼šåŸºäºæ™ºèƒ½ä½“çš„è‡ªåŠ¨åŒ–è¯„ä¼°æ¡†æ¶
- æ”¯æŒåŠ¨æ€é€‰æ‹©é—®é¢˜ã€å®šåˆ¶è¯„ä¼°æŒ‡æ ‡ã€è°ƒç”¨å·¥å…·é“¾ï¼ˆå¦‚æœç´¢ã€ä»£ç æ‰§è¡Œï¼‰ã€ç”ŸæˆæŠ¥å‘Šã€‚
- å¼•å…¥å¤šç»´åº¦è¯„åˆ†æœºåˆ¶ï¼ˆå‡†ç¡®æ€§ã€å®Œæ•´æ€§ã€æ¸…æ™°åº¦ã€è¯æ®æ”¯æŒç­‰ï¼‰ï¼Œå®ç°æ›´è´´è¿‘äººç±»ç§‘å­¦å®¶åˆ¤æ–­çš„è¯„ä¼°ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä¼ ç»ŸåŸºå‡†ï¼ˆå¦‚ MMLU, BIG-Benchï¼‰ | SGI-Bench |
|------|-------------------------------|----------|
| ä»»åŠ¡æ€§è´¨ | å•è½®é—®ç­”ã€å°é—­å¼é—®é¢˜ | å¤šæ­¥éª¤ã€é•¿è§†é‡ã€å¼€æ”¾æ€§ç§‘ç ”æµç¨‹ |
| å†…å®¹æ¥æº | åˆæˆæˆ–é€šç”¨è¯­æ–™ | ç§‘å­¦å®¶å‚ä¸æ„å»ºï¼Œæºè‡ª Nature/Science/Cell ç­‰æœŸåˆŠ |
| è¯„ä¼°é‡ç‚¹ | çŸ¥è¯†å›å¿†ã€é€»è¾‘æ¨ç† | ç§‘ç ”å…¨æµç¨‹èƒ½åŠ›ï¼ˆä»æ–‡çŒ®ç»¼è¿°åˆ°å®éªŒåˆ†æï¼‰ |
| å·¥å…·ä½¿ç”¨ | ä¸æ¶‰åŠ | æ˜¾å¼é›†æˆ web searchã€code interpreter ç­‰å·¥å…· |
| å¯æ‰©å±•æ€§ | å›ºå®šæŒ‡æ ‡ | ç”¨æˆ·å¯è‡ªå®šä¹‰ metricï¼Œæ”¯æŒ agentic evaluation |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šSGI-Bench æ˜¯ç›®å‰æœ€æ¥è¿‘çœŸå®ç§‘ç ”åœºæ™¯çš„ LLM ç§‘å­¦èƒ½åŠ›è¯„æµ‹ä½“ç³»ï¼Œå¼ºè°ƒâ€œç§‘å­¦å®¶å¯¹é½â€ï¼ˆscientist alignmentï¼‰ï¼Œæ¨åŠ¨ä»â€œç­”é¢˜æœºå™¨â€å‘â€œç§‘ç ”åä½œè€…â€çš„èŒƒå¼è½¬å˜ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä¸»è¦æ•°æ®æ¥è‡ª **SGI-Bench** è‡ªå»ºæ•°æ®é›†ï¼š
  - è¦†ç›– 10 ä¸ªæ ¸å¿ƒç§‘å­¦é¢†åŸŸ
  - è¶…è¿‡ 1,000 ä¸ªè·¨å­¦ç§‘æ ·æœ¬
  - æ„å»ºæµç¨‹åŒ…æ‹¬ï¼šç§å­é—®é¢˜ç­›é€‰ â†’ é¢†åŸŸä¸“å®¶åä½œ â†’ æ–‡çŒ®ææ–™é‡‡é›† â†’ å¤šè½®äººå·¥æ ‡æ³¨ä¸è´¨é‡æ§åˆ¶
- æ•°æ®å…¬å¼€åœ°å€ï¼š[https://huggingface.co/collections/InternScience/sgi-bench](https://huggingface.co/collections/InternScience/sgi-bench)

---

### å®éªŒè®¾ç½®

#### æ¨¡å‹èŒƒå›´
è¯„ä¼°äº†å¹¿æ³›çš„ LLM å’Œ agent ç³»ç»Ÿï¼š

| ç±»å‹ | æ¨¡å‹åˆ—è¡¨ |
|------|--------|
| **Open-weight LLMs** | DeepSeek-V3.2, DeepSeek-R1, Intern-S1, Qwen3 ç³»åˆ—, Llama-4-Scout ç­‰ |
| **Closed-weight LLMs** | GPT-4o, GPT-5 ç³»åˆ—, Gemini ç³»åˆ—, Claude ç³»åˆ—, Grok ç³»åˆ— |
| **Open-source Agents** | SmolAgents, Owl, WebThinker, XMaster, InternAgent |
| **Closed-source Agents** | OpenAI DeepResearch, Kimi-Search, Grok-Search, Perplexity ç­‰ |

#### æ¨ç†é…ç½®
- æ¸©åº¦ï¼ˆtemperatureï¼‰è®¾ä¸º 0ï¼Œä»¥å‡å°‘éšæœºæ€§
- ä½¿ç”¨ç»Ÿä¸€çš„ zero-shot prompt æ¨¡æ¿
- æ‰€æœ‰æ¨¡å‹å‡å…è®¸è®¿é—®å¤–éƒ¨å·¥å…·ï¼ˆå¦‚æœç´¢å¼•æ“ã€Python è§£é‡Šå™¨ï¼‰

---

### è¯„ä¼°æŒ‡æ ‡ï¼ˆæŒ‰ä»»åŠ¡åˆ’åˆ†ï¼‰

| ä»»åŠ¡ | å…³é”®è¯„ä¼°æŒ‡æ ‡ |
|------|-------------|
| **Scientific Deep Research** | Exact Match (EM), Step-Level Alignment, Multi-hop Accuracy |
| **Idea Generation** | Feasibility, Detail Level, Novelty, Scientific Soundness |
| **Dry Experiment** | Code Executability, Execution Result Accuracy, Pass@k |
| **Wet Experiment** | Sequence Fidelity, Step Completeness, Order Correctness |
| **Experimental Reasoning** | Multi-Choice Accuracy (MCA), Reasoning Validity (RV), Causal Understanding, Comparative Reasoning |

æ­¤å¤–è¿˜å¼•å…¥ï¼š
- **Retrieval-Augmented Novelty Reward**ï¼šç”¨äº TTRL çš„è®­ç»ƒä¿¡å·
- **User-Customized Metrics**ï¼šé€šè¿‡ SGIEvalAgent åŠ¨æ€ç”Ÿæˆä¸ªæ€§åŒ–è¯„ä»·æ ‡å‡†

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

| ä»»åŠ¡ | æ€§èƒ½è¡¨ç°ï¼ˆä»£è¡¨æ€§æ¨¡å‹ï¼‰ | ä¸»è¦å‘ç° |
|------|------------------------|---------|
| **Scientific Deep Research** | EM: 10â€“20%ï¼Œä½† step-level alignment è¾ƒé«˜ | æ¨¡å‹èƒ½æ­£ç¡®æ‰§è¡Œä¸­é—´æ­¥éª¤ï¼Œä½†åœ¨æœ€ç»ˆç­”æ¡ˆä¸Šå¤±è´¥é¢‘ç¹ï¼Œå°¤å…¶åœ¨å®šé‡æ¨ç†ä¸­è„†å¼± |
| **Idea Generation** | åˆ›æ„æµç•…ä½†ç¼ºä¹å¯è¡Œæ€§ä¸ç»†èŠ‚ | å¤šæ•°ç”Ÿæˆæƒ³æ³•åœç•™åœ¨è¡¨é¢ï¼Œç¼ºå°‘å…·ä½“å®éªŒè®¾è®¡å’ŒæŠ€æœ¯è·¯å¾„ |
| **Dry Experiment** | Code Executability > 80%ï¼Œä½† Execution Result Accuracy < 50% | ä»£ç è¯­æ³•æ­£ç¡®ä½†é€»è¾‘é”™è¯¯é¢‘å‘ï¼Œå¯¼è‡´è¿è¡Œç»“æœåå·®ä¸¥é‡ |
| **Wet Experiment** | Sequence Fidelity å¹³å‡ä½äº 60% | æ­¥éª¤é—æ¼ã€é¡ºåºé”™ä¹±ã€è¯•å‰‚ç”¨é‡é”™è¯¯ç­‰é—®é¢˜æ™®é |
| **Experimental Reasoning** | Causal reasoning è¡¨ç°å°šå¯ï¼ŒComparative reasoning å·®ï¼›Multimodal reasoning æŒ‘æˆ˜å¤§ | æ¨¡å‹éš¾ä»¥æ¯”è¾ƒå¤šä¸ªå›¾è¡¨è¶‹åŠ¿æˆ–è¯†åˆ«ç»†å¾®å·®å¼‚ |

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

| æ¨¡å‹ç±»å‹ | åœ¨å„ä»»åŠ¡ä¸Šçš„ç›¸å¯¹è¡¨ç° |
|--------|--------------------|
| **GPT-5 ç³»åˆ— & Gemini-3-Pro** | åœ¨å¤šæ•°ä»»åŠ¡ä¸­é¢†å…ˆï¼Œå°¤å…¶æ˜¯åœ¨ Wet Experiment å’Œ Experimental Reasoning ä¸Šè¡¨ç°çªå‡º |
| **Qwen3-Max / DeepSeek-R1** | åœ¨ Dry Experiment ä¸­ä»£ç ç”Ÿæˆèƒ½åŠ›å¼º |
| **Intern-S1 / InternAgent** | åœ¨ Idea Generation å’Œ Deep Research ä¸­å±•ç°è¾ƒå¼ºçš„çŸ¥è¯†æ•´åˆèƒ½åŠ› |
| **OpenAI DeepResearch (o3/o4-mini)** | åœ¨éœ€è¦å¤šæ¬¡æ£€ç´¢çš„ Deep Research ä¸­ä¼˜äºæ™®é€š GPT æ¥å£ |
| **TTRL-enhanced models** | ç›¸æ¯” baselineï¼Œåœ¨ Idea Generation çš„ novelty å¾—åˆ†æå‡æ˜¾è‘—ï¼ˆ+15â€“20%ï¼‰ |

> ç¤ºä¾‹è¡¨æ ¼ï¼ˆéƒ¨åˆ†æ¨¡å‹åœ¨ Wet Experiment ä¸­çš„è¡¨ç°ï¼‰ï¼š

| Model | Properties (%) | Micro-experiments (%) | Macro-experiments (%) |
|-------|----------------|------------------------|------------------------|
| GPT-5 | 10.22 | 21.15 | 26.92 |
| Gemini-3-Pro | **15.00** | **26.14** | **22.73** |
| Qwen3-Max | 7.00 | 30.00 | 0.00 |
| Intern-S1 | 7.14 | 24.64 | 20.00 |

> æ³¨ï¼šåˆ†æ•°ä¸ºæŸç§æ ‡å‡†åŒ–å¾—åˆ†ï¼ˆéç™¾åˆ†æ¯”ï¼‰ï¼Œè¶Šé«˜è¶Šå¥½ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆå¦‚æœ‰ï¼‰

è™½ç„¶æ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»åˆ†æä¸­å¯æ¨æ–­ä»¥ä¸‹å…³é”®å› ç´ çš„å½±å“ï¼š

- **å·¥å…·è°ƒç”¨é¢‘ç‡ vs. å‡†ç¡®ç‡**ï¼šè¿‡åº¦ä¾èµ–æ£€ç´¢ä¼šå¯¼è‡´â€œä¿¡æ¯å™ªå£°â€ï¼Œåè€Œé™ä½å†³ç­–è´¨é‡ï¼ˆè§ Figure 29ï¼‰
- **TTRL çš„æœ‰æ•ˆæ€§**ï¼šåœ¨æ— ç›‘ç£æ¡ä»¶ä¸‹ï¼ŒTTRL æ˜¾è‘—æå‡äº† Idea Generation çš„æ–°é¢–æ€§ï¼ŒåŒæ—¶æœªç‰ºç‰²ç§‘å­¦åˆç†æ€§
- **Agent æ¶æ„ä¼˜åŠ¿**ï¼šé…å¤‡ planning å’Œ tool-use èƒ½åŠ›çš„ agentï¼ˆå¦‚ InternAgentï¼‰åœ¨å¤æ‚ä»»åŠ¡ä¸­ä¼˜äºçº¯ LLM

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. **å½“å‰ LLMs å…·å¤‡éƒ¨åˆ† SGI èƒ½åŠ›ï¼Œä½†å°šæœªå½¢æˆæ•´åˆæ€§ç§‘å­¦è®¤çŸ¥**
   - å„æ¨¡å—èƒ½åŠ›å‰²è£‚ï¼Œâ€œä¼šæŸ¥ä¸ä¼šæƒ³â€ã€â€œä¼šå†™ä¸ä¼šåšâ€ç°è±¡æ™®é
   - ç¼ºä¹å¯¹æ•°å€¼ç²¾åº¦ã€å®éªŒæ¡ä»¶ã€å˜é‡æ§åˆ¶çš„æ•æ„Ÿæ€§

2. **è¯­è¨€æµç•… â‰  ç§‘å­¦å¯é **
   - æ¨¡å‹è¾“å‡ºçœ‹ä¼¼åˆç†ï¼Œä½†å¸¸åŒ…å«éšæ€§é”™è¯¯ï¼ˆå¦‚å•ä½æ··æ·†ã€ååº”æ¡ä»¶ä¸åˆç†ï¼‰
   - å°¤å…¶åœ¨ Wet Experiment ä¸­ï¼Œåºåˆ—ä¿çœŸåº¦ä½ï¼Œå­˜åœ¨å®‰å…¨éšæ‚£é£é™©

3. **å·¥å…·ä½¿ç”¨æ˜¯åŒåˆƒå‰‘**
   - æ£€ç´¢å¢å¼ºæœ‰åŠ©äºæå‡ä¿¡æ¯å¹¿åº¦ï¼Œä½†ä¹Ÿå¯èƒ½å¼•å…¥è¯¯å¯¼ä¿¡æ¯
   - å½“å‰ agent çš„ tool-use ç­–ç•¥ä»è¾ƒåˆçº§ï¼Œç¼ºä¹â€œä½•æ—¶æŸ¥ã€æ€ä¹ˆä¿¡â€çš„å…ƒè®¤çŸ¥èƒ½åŠ›

4. **TTRL è¯æ˜å¯åœ¨æ— ç›‘ç£ä¸‹æå‡åˆ›æ–°æ€§**
   - ä¸ºæœªæ¥åœ¨æœªçŸ¥é¢†åŸŸæ¢ç´¢æä¾›äº†æ–°è·¯å¾„
   - æ–°é¢–æ€§å¥–åŠ±éœ€ä¸å…¶ä»–ç›®æ ‡ï¼ˆrigor, feasibilityï¼‰å¹³è¡¡ï¼Œé¿å…â€œè™šå‡åˆ›æ–°â€

---

### æ–¹æ³•çš„å±€é™æ€§

1. **è¦†ç›–èŒƒå›´æœ‰é™**
   - å½“å‰ä»…æ¨¡æ‹Ÿç§‘ç ”æµç¨‹çš„å››ä¸ªä¸»é˜¶æ®µï¼Œæœªæ¶µç›–åŒè¡Œè¯„å®¡ã€ä¼¦ç†å®¡æŸ¥ã€è·¨å­¦ç§‘èåˆç­‰ç°å®ç¯èŠ‚
   - Wet Experiment å¤šä¸ºæ–‡æœ¬æè¿°ï¼Œç¼ºä¹çœŸå®æœºå™¨äººæ“ä½œåé¦ˆ

2. **Deep Research ä¾§é‡æ–‡çŒ®æŸ¥è¯¢**
   - å¿½ç•¥äº†æŠ¥å‘Šæ’°å†™ã€åŸºé‡‘ç”³è¯·ç­‰æ›´å¤æ‚çš„äº§å‡ºå½¢å¼
   - å¯¹â€œåˆ›é€ æ€§ç»¼åˆâ€èƒ½åŠ›æµ‹é‡ä¸è¶³

3. **è¯„ä¼°ä»ä¾èµ–äººå·¥æ‰“åˆ†**
   - å°½ç®¡å¼•å…¥ SGIEvalAgentï¼Œæ ¸å¿ƒè¯„åˆ†ä»ç”±äººç±»å®Œæˆï¼Œéš¾ä»¥å®Œå…¨è‡ªåŠ¨åŒ–
   - ç¼ºå°‘å¤§è§„æ¨¡ä¼—åŒ…éªŒè¯

4. **å®‰å…¨ä¸å¯è¡Œæ€§è€ƒé‡ä¸è¶³**
   - æœªç³»ç»Ÿè¯„ä¼°ç”Ÿæˆå»ºè®®çš„å®‰å…¨æ€§ï¼ˆå¦‚å±é™©åŒ–å­¦å“ç»„åˆï¼‰
   - Feasibility åˆ¤æ–­ä¸»è§‚æ€§å¼ºï¼Œç¼ºä¹ç»Ÿä¸€æ ‡å‡†

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. **å‘å±•å¤šç›®æ ‡ Test-Time Learning**
   - ç»“åˆ novelty, rigor, feasibility, safety, cost ç­‰å¤šé‡ rewardï¼Œæ„å»ºæ›´ç¨³å¥çš„ TTRL æ¡†æ¶
   - åŠ å…¥ contradiction detection å’Œ trustworthiness scoringï¼Œé˜²æ­¢è™šå‡ä¿¡æ¯ä¼ æ’­

2. **æ„å»ºé«˜æ•ˆå¯é çš„å·¥å…·ç”Ÿæ€ç³»ç»Ÿ**
   - å¼€å‘ retrieval cachingã€selective browsingã€structured extraction ç­‰æŠ€æœ¯
   - æå‡ agent çš„ tool-aware planning èƒ½åŠ›ï¼Œä¼˜åŒ–ç«¯åˆ°ç«¯å»¶è¿Ÿä¸å‡†ç¡®ç‡æƒè¡¡

3. **æ¨è¿›çœŸå®ä¸–ç•Œäº¤äº’**
   - å°† SGI-Bench ä¸å®éªŒå®¤æœºå™¨äººã€è‡ªåŠ¨åŒ–å¹³å°ç»“åˆï¼Œå®ç°â€œæ•°å­—ç§‘å­¦å®¶â€é—­ç¯
   - æ¢ç´¢ AI-driven autonomous labsï¼ˆAI2Labsï¼‰

4. **åŠ å¼ºè·¨å­¦ç§‘ä¸é•¿æœŸæ¨ç†èƒ½åŠ›**
   - è®¾è®¡éœ€è¦èåˆå¤šä¸ªé¢†åŸŸçŸ¥è¯†çš„å¤åˆå‹ä»»åŠ¡
   - å¼•å…¥ meta-analysisã€longitudinal study design ç­‰é«˜çº§ç§‘ç ”æŠ€èƒ½è¯„æµ‹

5. **å»ºç«‹å¼€æºç¤¾åŒºç”Ÿæ€**
   - é¼“åŠ±æ›´å¤šç ”ç©¶è€…è´¡çŒ®ä»»åŠ¡ã€æ¨¡å‹ã€è¯„ä¼°è„šæœ¬
   - æ¨åŠ¨ SGI-Bench æˆä¸ºç§‘å­¦ AI å‘å±•çš„â€œImageNet æ—¶åˆ»â€

---

> ğŸ”š **æ€»ç»“**ï¼š  
> æœ¬è®ºæ–‡æå‡ºäº† **SGI çš„ç†è®ºæ¡†æ¶ + SGI-Bench å®è·µåŸºå‡† + TTRL åˆ›æ–°æœºåˆ¶ + SGIEvalAgent è¯„ä¼°ç³»ç»Ÿ**ï¼Œå½¢æˆäº†å®Œæ•´çš„â€œå®šä¹‰â€”è¯„æµ‹â€”æ”¹è¿›â€é—­ç¯ã€‚å®ƒä¸ä»…æ­ç¤ºäº†å½“å‰ LLM åœ¨ç§‘å­¦æ™ºèƒ½æ–¹é¢çš„çŸ­æ¿ï¼Œä¹Ÿä¸ºé€šå¾€çœŸæ­£èƒ½å‚ä¸ç§‘å­¦å‘ç°çš„äººå·¥æ™ºèƒ½æŒ‡æ˜äº†æ¸…æ™°çš„æŠ€æœ¯è·¯çº¿å›¾ã€‚

</details>

---

### 13. [A Solver-in-the-Loop Framework for Improving LLMs on Answer Set Programming for Logic Puzzle Solving](https://arxiv.org/abs/2512.17093)

**Authors**: Timo Pierre Schrader, Lukas Lange, Tobias Kaminski, Simon Razniewski, Annemarie Friedrich  
**Category**: cs.AI  
**Published**: 2025-12-22  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.17093v1  

#### Abstract
The rise of large language models (LLMs) has sparked interest in coding assistants. While general-purpose programming languages are well supported, generating code for domain-specific languages remains a challenging problem for LLMs. In this paper, we focus on the LLM-based generation of code for An...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šA Solver-in-the-Loop Framework for Improving LLMs on Answer Set Programming for Logic Puzzle Solving

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å½“å‰çš„ **Large Language Models (LLMs)** åœ¨é€šç”¨ç¼–ç¨‹è¯­è¨€ï¼ˆå¦‚ Pythonã€JavaScriptï¼‰ä¸Šçš„ä»£ç ç”Ÿæˆèƒ½åŠ›å·²å–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†åœ¨**é¢†åŸŸç‰¹å®šè¯­è¨€ï¼ˆDSLï¼‰** ä¸Šçš„è¡¨ç°ä»ç„¶æœ‰é™ï¼Œå°¤å…¶æ˜¯å¯¹è¯­ä¹‰å¤æ‚ã€é€»è¾‘ä¸¥å¯†çš„è¯­è¨€å¦‚ **Answer Set Programming (ASP)**ã€‚

ASP æ˜¯ä¸€ç§å¼ºå¤§çš„å£°æ˜å¼ç¼–ç¨‹èŒƒå¼ï¼Œç‰¹åˆ«é€‚ç”¨äºè§£å†³ç»„åˆæœç´¢é—®é¢˜ï¼ˆå¦‚é€»è¾‘è°œé¢˜ã€è°ƒåº¦ã€é…ç½®ç­‰ï¼‰ã€‚ç„¶è€Œï¼š
- LLMs åœ¨é¢„è®­ç»ƒé˜¶æ®µæ¥è§¦çš„ ASP ç¤ºä¾‹æå°‘ï¼›
- å³ä½¿é€šè¿‡æç¤ºå·¥ç¨‹ï¼ˆprompt engineeringï¼‰ï¼ŒLLMs ä¹Ÿéš¾ä»¥ç¨³å®šç”Ÿæˆè¯­ä¹‰æ­£ç¡®ä¸”å¯æ‰§è¡Œçš„ ASP ç¼–ç ï¼›
- ç°æœ‰æ–¹æ³•ç¼ºä¹æœ‰æ•ˆçš„åé¦ˆæœºåˆ¶æ¥è¯„ä¼°éƒ¨åˆ†ç”Ÿæˆçš„ ASP ä»£ç æ˜¯å¦â€œæ¥è¿‘æ­£ç¡®â€ã€‚

å› æ­¤ï¼Œæœ¬æ–‡æ—¨åœ¨æå‡ LLMs åœ¨ ASP ä»£ç ç”Ÿæˆä»»åŠ¡ä¸­çš„å‡†ç¡®æ€§ä¸é²æ£’æ€§ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡ºäº†ä¸€ç§ **Solver-in-the-Loop** æ¡†æ¶ï¼Œå°†å¤–éƒ¨ **ASP solver** èå…¥åˆ° LLM çš„è®­ç»ƒä¸æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå½¢æˆä¸€ä¸ªé—­ç¯ç³»ç»Ÿã€‚è¯¥æ¡†æ¶åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š

#### âœ… **1. Solver-Guided Instruction Tuningï¼ˆè®­ç»ƒé˜¶æ®µï¼‰**
- åˆ©ç”¨ LLM å¯¹è‡ªç„¶è¯­è¨€æè¿°çš„é—®é¢˜ç”Ÿæˆå¤šä¸ªå€™é€‰çš„ ASP ç¼–ç ç‰‡æ®µï¼ˆpartial encodingsï¼‰ï¼›
- å°†è¿™äº›ç¼–ç è¾“å…¥ **ASP solver**ï¼ˆå¦‚ clingoï¼‰è¿›è¡ŒéªŒè¯ï¼š
  - æ˜¯å¦è¯­æ³•é”™è¯¯ï¼Ÿ
  - æ˜¯å¦ unsatisfiableï¼ˆæ— è§£ï¼‰ï¼Ÿ
  - æ˜¯å¦äº§ç”Ÿè¿‡å¤šç­”æ¡ˆé›†ï¼ˆanswer setsï¼‰ï¼Ÿ
  - æ˜¯å¦ä»èƒ½æ¨å¯¼å‡ºæ­£ç¡®çš„ ground truth è§£ï¼Ÿ
- æ ¹æ® solver åé¦ˆå°†æ ·æœ¬åˆ†ä¸º â€œchosenâ€ å’Œ â€œrejectedâ€ï¼›
- ä½¿ç”¨ **Supervised Fine-Tuning (SFT)** åœ¨ â€œchosenâ€ æ•°æ®ä¸Šå¾®è°ƒ LLMï¼Œä»è€Œå­¦ä¹ é«˜è´¨é‡çš„ ASP ç¼–ç æ¨¡å¼ã€‚

> è¿™æ˜¯ä¸€ç§**å…¨è‡ªåŠ¨çš„æ•°æ®æ ‡æ³¨æµç¨‹**ï¼Œæ— éœ€äººå·¥æ ‡æ³¨å³å¯æ„å»ºé“¶æ ‡å‡†ï¼ˆsilver-standardï¼‰è®­ç»ƒæ•°æ®ã€‚

#### âœ… **2. Solver-Guided Test-Time Searchï¼ˆæ¨ç†é˜¶æ®µï¼‰**
å¼•å…¥ä¸€ç§åŸºäº solver åé¦ˆçš„ **reward function** æ¥æŒ‡å¯¼æ¨ç†è¿‡ç¨‹ï¼š
```math
f_r(I, M) = - \left( \mathbb{1}_{\text{error}} + \mathbb{1}_{\text{unsat}} + \frac{\mathbb{1}_{\text{NE}}}{M} \right)
```
å…¶ä¸­ï¼š
- `I` æ˜¯å½“å‰ç”Ÿæˆçš„ ASP ç¼–ç ï¼Œ
- `M` æ˜¯ solver è¿”å›çš„ç­”æ¡ˆé›†æ•°é‡ï¼Œ
- å„ indicator åˆ†åˆ«æ£€æµ‹é”™è¯¯ã€ä¸å¯æ»¡è¶³æ€§å’Œè¶…å‡ºé¢„æœŸç­”æ¡ˆæ•°ã€‚

åœ¨æ¨ç†æ—¶é‡‡ç”¨ **best-of-N sampling**ï¼š
- å¯¹æ¯ä¸ªæç¤ºç”Ÿæˆ N ä¸ªå€™é€‰ç¼–ç ï¼›
- ä½¿ç”¨ reward å‡½æ•°è¯„åˆ†å¹¶é€‰æ‹©æœ€ä¼˜è€…ï¼›
- è‹¥æ‰€æœ‰å€™é€‰å‡å¤±è´¥ï¼Œåˆ™è§¦å‘ fallback æœºåˆ¶ï¼š
  - **Regeneration**ï¼šé‡æ–°ç”Ÿæˆæ›´å¤šå€™é€‰ï¼›
  - **Backtracking**ï¼šå›é€€è‡³ä¸Šä¸€ä¸ªæœ‰å¤šæ¡è·¯å¾„çš„æ­¥éª¤ï¼Œå°è¯•å…¶ä»–åˆ†æ”¯ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³• | æœ¬æ–‡æ–¹æ³• |
|------|--------|---------|
| **è®­ç»ƒæ•°æ®è·å–** | ä¾èµ–äººå·¥æ ‡æ³¨æˆ–å°è§„æ¨¡æ•°æ®é›†ï¼ˆå¦‚ LLASPï¼‰ | è‡ªåŠ¨åˆ©ç”¨ solver æ„å»ºé«˜è´¨é‡è®­ç»ƒæ•°æ® |
| **ä¸­é—´ç”Ÿæˆè¯„ä¼°** | æ— æ³•è¯„ä¼°éƒ¨åˆ†ä»£ç ï¼ˆå¦‚ Pythonï¼‰ | ASP æ”¯æŒå¢é‡æ±‚è§£ï¼Œå¯ç²¾ç»†è¯„ä¼°æ¯ä¸€æ­¥ |
| **æ¨ç†ç¨³å®šæ€§** | è´ªå¿ƒè§£ç æ˜“å‡ºé”™ | å¼•å…¥ reward-driven æœç´¢ + fallback æœºåˆ¶ |
| **æ³›åŒ–èƒ½åŠ›** | å¤šä¸ºé—­æºæ¨¡å‹ä¸“ç”¨ pipeline | å¼€æ”¾æƒé‡æ¨¡å‹ + å¯è¿ç§»è‡³ä¸åŒæ•°æ®é›† |

> ç‰¹åˆ«åœ°ï¼Œè¯¥æ–¹æ³•ä¸ä¾èµ–å¤æ‚çš„å¤šæ­¥æ¨ç†é“¾è®¾è®¡ï¼ˆå¦‚ Chain-of-Thoughtï¼‰ï¼Œè€Œæ˜¯ç›´æ¥ç”Ÿæˆå¯æ‰§è¡Œä»£ç ï¼Œå¹¶ç”± solver æä¾›è¯­ä¹‰çº§åé¦ˆã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

| æ•°æ®é›† | æè¿° |
|-------|------|
| **LogicPuzzles** (Mitra and Baral, 2015) | åŒ…å« 124 ä¸ª 3Ã—4 ç½‘æ ¼é€»è¾‘è°œé¢˜ï¼ˆ3 ç±»å®ä½“ï¼Œæ¯ç±» 4 é¡¹ï¼‰ï¼Œç”¨äºè®­ç»ƒä¸ä¸»è¯„ä¼° |
| **GridPuzzles** (Tyagi et al., 2024) | æ›´å¤§è§„æ¨¡å˜ä½“ï¼ŒåŒ…å« 3Ã—4 è‡³ 4Ã—6 ä¸åŒå°ºå¯¸å’Œéš¾åº¦ç­‰çº§çš„è°œé¢˜ï¼Œä»…ç”¨äºè¯„ä¼°ï¼ˆzero-shot transferï¼‰ |

> æ³¨æ„ï¼šä½œè€…å‘ç°åŸå§‹ LogicPuzzles å­˜åœ¨è®­ç»ƒ/æµ‹è¯•é›†æ³„éœ²ï¼ˆ26 ä¾‹é‡å¤ï¼‰ï¼Œæ•…åœ¨ä¸»å®éªŒä¸­ç§»é™¤ä»¥ç¡®ä¿å…¬å¹³æ€§ã€‚

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

#### ğŸ”¹ **æ¨¡å‹**
- **å¼€æºæ¨¡å‹æ—**ï¼š
  - Llama-3.3 70B / Llama-3.1 8B
  - Qwen3 32B / Qwen3 8B
- **é—­æºå¯¹æ¯”æ¨¡å‹**ï¼š
  - GPT-4.1-miniï¼ˆclosed-sourceï¼‰
- **åŸºçº¿æ¨¡å‹**ï¼š
  - DeepSeek-R1 ç³»åˆ—ï¼ˆä½œä¸º Reasoning Language Model, RLMï¼‰

#### ğŸ”¹ **è®­ç»ƒæ–¹å¼**
- ä½¿ç”¨ **LoRA** å¾®è°ƒï¼›
- è®­ç»ƒç›®æ ‡ï¼š**causal language modeling**ï¼ˆå³æ ‡å‡† SFTï¼‰ï¼›
- æ•°æ®æ¥æºï¼šä» Llama-3.3 70B é‡‡æ ·ç”Ÿæˆ â†’ ç» solver è¿‡æ»¤ â†’ å½¢æˆè®­ç»ƒé›†ï¼ˆå…± ~1.5K å®ä¾‹ï¼‰ï¼›
- è¾ƒå°æ¨¡å‹ï¼ˆ8Bï¼‰é¢å¤–åŠ å…¥ LLASP æ•°æ®å¢å¼ºåŸºç¡€æŠ€èƒ½ã€‚

#### ğŸ”¹ **æ¨ç†ç­–ç•¥**
- **Baseline**ï¼šgreedy decoding (`N=1`, `T=0`)
- **Proposed**ï¼šbest-of-N sampling (`N=5,10,25`) + reward scoring + regeneration/backtracking
- æ¸©åº¦ `T=1.0` ä¿è¯å¤šæ ·æ€§

#### ğŸ”¹ **è¯„ä¼°æŒ‡æ ‡**
- **Accuracy**ï¼šæœ€ç»ˆ solver è¾“å‡ºçš„ answer set æ˜¯å¦**å®Œå…¨åŒ¹é…** ground truthï¼ˆå­—ç¬¦ä¸²æ¨¡ç³ŠåŒ¹é…ä½¿ç”¨ Levenshtein è·ç¦»å®¹é”™ï¼‰
- é”™è¯¯åˆ†ç±»ç»Ÿè®¡ï¼šerrors/warnings, unsatisfiability, multiple answers, unique correct

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

| æ–¹æ³•ç±»å‹ | å…·ä½“å®ç° |
|--------|--------|
| **Few-shot Prompting (2S)** | æä¾›å°‘é‡ç¤ºä¾‹ + åŸºæœ¬æŒ‡ä»¤ï¼Œè¦æ±‚ç›´æ¥ç”Ÿæˆ ASP |
| **Prompt Pipeline (PP)** | Ishay et al. (2023) è®¾è®¡çš„ 6 æ­¥ pipelineï¼Œä¸“ä¸º LogicPuzzles å®šåˆ¶ |
| **Reasoning LLMs (RLMs)** | DeepSeek-R1 ç›´æ¥è¿›è¡Œè‡ªç„¶è¯­è¨€æ¨ç†ï¼Œä¸ä½¿ç”¨ ASP |
| **Closed-source Baseline** | GPT-4.1-mini + æ‰‹å·¥ä¼˜åŒ– prompt |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰**

#### ğŸ“Š åœ¨ **LogicPuzzles** ä¸Šçš„å‡†ç¡®ç‡ï¼ˆcleaned test splitï¼‰

| æ¨¡å‹ | Two-Shot (2S) | Prompt Pipeline (PP) |
|------|---------------|---------------------|
| Llama-3.3 70B (base) | 27.0% | â€” |
| Llama-3.3 70B (SFT) | 55.4% | 78.4% |
| Llama-3.3 70B (SFT + TT) | **66.8%** | â€” |
| GPT-4.1-mini (no SFT) | 39.2% â†’ **55.4%** (+16.2pp with TT) |

> âœ… **SFT æå‡å·¨å¤§**ï¼šLlama-70B ä» 27% â†’ 55.4%ï¼Œæå‡è¿‘ä¸€å€  
> âœ… **test-time search å†å¢ç›Š**ï¼š+11.4ppï¼ˆ66.8%ï¼‰  
> âœ… **å³ä½¿æ— è®­ç»ƒï¼ŒTT ä¹Ÿèƒ½ææ•ˆ**ï¼šGPT-4.1-mini æå‡ 16.2pp

#### ğŸ“Š åœ¨ **GridPuzzles** ä¸Šçš„ zero-shot æ€§èƒ½

| æ¨¡å‹ | Two-Shot (2S) |
|------|--------------|
| Llama-3.3 70B (base) | 9.1% |
| Llama-3.3 70B (SFT + TT) | **23.7%** |

> è¡¨æ˜æ–¹æ³•å…·æœ‰è‰¯å¥½çš„è·¨æ•°æ®é›†è¿ç§»èƒ½åŠ›ï¼Œå°¤å…¶åœ¨æ›´éš¾ã€æ›´å¤§è§„æ¨¡é—®é¢˜ä¸Šè¡¨ç°ä¼˜äº baselineã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆTable 2ï¼‰**

| é…ç½® | Accuracy (LogicPuzzles) | Î” vs SFT |
|------|--------------------------|--------|
| Base | 31.0% | â€” |
| +SFT | 55.4% | â€” |
| +SFT + best-of-5 | 62.7% | +7.3pp |
| +Regeneration | 64.6% | +9.2pp |
| +Backtracking | 62.7% | +7.3pp |
| +Both (full TT) | **66.8%** | **+11.4pp** |
| N=25 | **69.2%** | +13.8pp |

> ğŸ” å‘ç°ï¼š
- **best-of-N æ˜¯ä¸»è¦é©±åŠ¨åŠ›**ï¼›
- **Regeneration æ¯” Backtracking æ›´æœ‰æ•ˆ**ï¼›
- **å¢å¤§ N å¯è¿›ä¸€æ­¥æå‡æ€§èƒ½**ï¼Œä½†éœ€æƒè¡¡è®¡ç®—æˆæœ¬ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **LLMs åœ¨ ASP ä¸Šå­˜åœ¨ä¸¥é‡ç¼ºé™·**ï¼šå³ä½¿æ˜¯ state-of-the-art å¼€æºæ¨¡å‹ï¼Œåœ¨æœªç»å¾®è°ƒçš„æƒ…å†µä¸‹å‡ ä¹æ— æ³•æ­£ç¡®ç”Ÿæˆ ASP ç¼–ç ï¼ˆå¦‚ Llama-8B å‡†ç¡®ç‡ä¸º 0%ï¼‰ï¼›
2. âœ… **solver-in-the-loop æ˜¯é«˜æ•ˆè®­ç»ƒä¿¡å·æ¥æº**ï¼šåˆ©ç”¨ solver çš„è¯­ä¹‰åé¦ˆè‡ªåŠ¨ç­›é€‰é«˜è´¨é‡è®­ç»ƒæ ·æœ¬ï¼Œå®ç°äº†**æ— éœ€äººå·¥æ ‡æ³¨çš„è‡ªç›‘ç£æ•°æ®æ„å»º**ï¼›
3. âœ… **SFT æ˜¾è‘—æå‡æ€§èƒ½**ï¼šå¾®è°ƒåï¼Œå¤§æ¨¡å‹ï¼ˆ70Bï¼‰åœ¨ few-shot è®¾ç½®ä¸‹å‡†ç¡®ç‡ç¿»å€ä»¥ä¸Šï¼›
4. âœ… **test-time search æå¤§å¢å¼ºé²æ£’æ€§**ï¼šé€šè¿‡ reward-based æ’åºä¸ fallback æœºåˆ¶ï¼Œæ˜¾è‘—å‡å°‘é”™è¯¯ç¼–ç çš„å½±å“ï¼›
5. âœ… **æ–¹æ³•å…·å¤‡å¼ºæ³›åŒ–æ€§**ï¼šåœ¨æœªè§è¿‡çš„ GridPuzzles æ•°æ®é›†ä¸Šå®ç°æœ‰æ•ˆ zero-shot transferï¼›
6. âœ… **é€‚ç”¨äºé—­æºæ¨¡å‹**ï¼šå³ä¾¿ä¸å¯¹ GPT-4.1-mini è¿›è¡Œè®­ç»ƒï¼Œä»…ä½¿ç”¨å…¶è¾“å‡º + solver reward ä¹Ÿèƒ½å¤§å¹…æå‡æ€§èƒ½ã€‚

---

### **å±€é™æ€§**

1. âŒ **ä¾èµ–é—®é¢˜å¯å½¢å¼åŒ–ä¸º ASP**ï¼šä»…é€‚ç”¨äºèƒ½è¢«è½¬åŒ–ä¸ºçº¦æŸæ»¡è¶³é—®é¢˜çš„ä»»åŠ¡ï¼ˆå¦‚é€»è¾‘è°œé¢˜ã€æ’ç­ã€é…ç½®ç­‰ï¼‰ï¼›
2. âŒ **è®¡ç®—å¼€é”€è¾ƒé«˜**ï¼šæ¯æ¬¡ç”Ÿæˆéœ€è°ƒç”¨ solver å¤šæ¬¡ï¼Œå½±å“æ¨ç†å»¶è¿Ÿï¼›
3. âŒ **å¯¹ uniqueness constraint ç¼–ç ä¸æ•æ„Ÿ**ï¼šå®éªŒæ˜¾ç¤ºæ¨¡å‹æœªèƒ½æŒæ¡å°†å…¨å±€å”¯ä¸€æ€§æ‹†åˆ†ä¸ºå¤šä¸ªå±€éƒ¨çº¦æŸçš„æŠ€å·§ï¼›
4. âŒ **Levenshtein åŒ¹é…éå®Œç¾**ï¼šå­—ç¬¦ä¸²è¡¨ç¤ºå·®å¼‚å¯èƒ½å¯¼è‡´è¯¯åˆ¤ï¼Œè™½ç¼“è§£ä½†ä»éæ ¹æœ¬è§£å†³ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. ğŸ”® **å¼•å…¥å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒ**ï¼šå°† solver çš„ reward ç›´æ¥ä½œä¸º RL ä¿¡å·ï¼Œæ›¿ä»£ SFTï¼›
2. ğŸ”® **åŠ¨æ€åŠ æƒ reward å‡½æ•°**ï¼šæ ¹æ®ä¸åŒé”™è¯¯ç±»å‹èµ‹äºˆä¸åŒæƒ©ç½šæƒé‡ï¼›
3. ğŸ”® **æ”¹è¿› uniqueness constraint å»ºæ¨¡**ï¼šæ¢ç´¢æ›´é«˜æ•ˆçš„ç¼–ç æ–¹å¼ä»¥é™ä½æœç´¢ç©ºé—´ï¼›
4. ğŸ”® **æ‰©å±•è‡³å…¶ä»– DSL**ï¼šå°† solver-in-the-loop æ€è·¯æ¨å¹¿è‡³ PROLOGã€PDDLã€SQL ç­‰è¯­è¨€ï¼›
5. ğŸ”® **ç»“åˆ symbolic repair**ï¼šå½“ solver æŠ¥é”™æ—¶ï¼Œè‡ªåŠ¨ä¿®å¤è€Œéç®€å•ä¸¢å¼ƒã€‚

---

## æ€»ç»“

æœ¬æ–‡æå‡ºçš„ **Solver-in-the-Loop** æ¡†æ¶æˆåŠŸå°†ç¬¦å·æ±‚è§£å™¨ä¸ LLM æ·±åº¦èåˆï¼Œåœ¨ **ASP ä»£ç ç”Ÿæˆ**è¿™ä¸€æŒ‘æˆ˜æ€§ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çªç ´ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> **è®© solver æˆä¸º LLM çš„â€œè€å¸ˆâ€å’Œâ€œè£åˆ¤â€â€”â€”æ—¢ç”¨äºç”Ÿæˆè®­ç»ƒæ•°æ®ï¼Œåˆç”¨äºå¼•å¯¼æ¨ç†è¿‡ç¨‹ã€‚**

è¯¥æ–¹æ³•ä¸ä»…æå‡äº† LLM åœ¨é€»è¾‘å¯†é›†å‹ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œä¹Ÿä¸º **neuro-symbolic AI** æä¾›äº†ä¸€ä¸ªå¯æ‰©å±•ã€è‡ªåŠ¨åŒ–çš„æ–°èŒƒå¼ã€‚

</details>

---

### 14. [Accelerating Multi-modal LLM Gaming Performance via Input Prediction and Mishit Correction](https://arxiv.org/abs/2512.17250)

**Authors**: Ziyang Lin, Zixuan Sun, Sanhorn Chen, Xiaoyang Chen, Roy Zhao  
**Category**: cs.AI  
**Published**: 2025-12-22  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.17250v1  

#### Abstract
Real-time sequential control agents are often bottlenecked by inference latency. Even modest per-step planning delays can destabilize control and degrade overall performance. We propose a speculation-and-correction framework that adapts the predict-then-verify philosophy of speculative execution to ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAccelerating Multi-modal LLM Gaming Performance via Input Prediction and Mishit Correction

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹ **Transformer-based å®æ—¶é¡ºåºæ§åˆ¶ä»£ç†ï¼ˆreal-time sequential control agentsï¼‰ä¸­çš„æ¨ç†å»¶è¿Ÿç“¶é¢ˆ** å±•å¼€ç ”ç©¶ã€‚åœ¨æœºå™¨äººæ§åˆ¶ã€ç«æŠ€æ¸¸æˆã€é«˜é¢‘äº¤æ˜“ç­‰å¯¹å»¶è¿Ÿæ•æ„Ÿçš„ä»»åŠ¡ä¸­ï¼Œå³ä½¿æ¯æ­¥å†³ç­–æœ‰è½»å¾®å»¶è¿Ÿï¼Œä¹Ÿå¯èƒ½å¯¼è‡´ç³»ç»Ÿä¸ç¨³å®šæˆ–æ€§èƒ½ä¸‹é™ã€‚ä¼ ç»ŸåŠ é€Ÿæ–¹æ³•ï¼ˆå¦‚ speculative decodingã€early exitingï¼‰ä¸»è¦ä¼˜åŒ–è¾“å…¥åçš„æ¨ç†è¿‡ç¨‹ï¼Œä½†æ— æ³•è§£å†³æ„ŸçŸ¥è¾“å…¥ç­‰å¾…æ—¶é—´å¸¦æ¥çš„æ•´ä½“å»¶è¿Ÿã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§ **â€œæ¨æµ‹-ä¿®æ­£â€æ¡†æ¶ï¼ˆspeculation-and-correction frameworkï¼‰**ï¼Œå°† speculative decoding ä¸­çš„ â€œé¢„æµ‹-éªŒè¯â€ èŒƒå¼æ‰©å±•åˆ°åŸºäºæ¨¡å‹çš„æ§åˆ¶ä»»åŠ¡ä¸­ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- **è¾“å…¥é¢„æµ‹è€Œéè¾“å‡ºé¢„æµ‹**ï¼šåˆ©ç”¨é¢„è®­ç»ƒçš„ TD-MPC2 ä¸–ç•Œæ¨¡å‹å’Œæ½œåœ¨ç©ºé—´ MPC è§„åˆ’å™¨ï¼Œåœ¨æ¯ä¸ªæ­¥éª¤ç”ŸæˆçŸ­æœŸåŠ¨ä½œé˜Ÿåˆ—å’Œæ½œåœ¨çŠ¶æ€ rollout é¢„æµ‹ï¼›
- **å¤šæ­¥æ¨æµ‹æ‰§è¡Œ**ï¼šç›´æ¥æ‰§è¡Œå¤šä¸ªè®¡åˆ’åŠ¨ä½œè€Œä¸å†æ¬¡è§„åˆ’ï¼›
- **è½»é‡çº§ä¿®æ­£æœºåˆ¶ï¼ˆMiss Recycling and Correctionï¼‰**ï¼šå½“å®é™…è§‚æµ‹ä¸é¢„æµ‹æ½œå˜é‡ä¸åŒ¹é…æ—¶ï¼Œä½¿ç”¨ä¸€ä¸ªå°å‹å­¦ä¹ å‹ corrector å¯¹æ¨æµ‹åŠ¨ä½œè¿›è¡Œæ®‹å·®æ›´æ–°ï¼›
- **å®‰å…¨å›é€€æœºåˆ¶**ï¼šè‹¥è¯¯å·®è¿‡å¤§ï¼Œåˆ™è§¦å‘å®Œæ•´é‡è§„åˆ’å¹¶æ¸…ç©ºæ—§é˜Ÿåˆ—ã€‚

è¯¥æ–¹æ³•é¦–æ¬¡å°† **è¾“å…¥ä¾§é¢„æµ‹ + æ¨æµ‹æ‰§è¡Œ + é”™è¯¯å›æ”¶** ç»“åˆç”¨äºè¿ç»­æ§åˆ¶ä»»åŠ¡ï¼Œæ˜¾è‘—å‡å°‘è§„åˆ’è°ƒç”¨æ¬¡æ•°ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | ç‰¹ç‚¹ | æœ¬æ–‡ä¼˜åŠ¿ |
|------|------|----------|
| Speculative Decoding [6] | åŠ é€Ÿè¯­è¨€æ¨¡å‹ token è¾“å‡ºç”Ÿæˆ | æœ¬æ–‡è½¬å‘**è¾“å…¥é¢„æµ‹**ï¼Œæå‰å¤„ç†æ„ŸçŸ¥ä¸è§„åˆ’å»¶è¿Ÿ |
| Early Exiting [7] | å‡å°‘ç¼–ç å™¨/è§£ç å™¨å±‚æ•°è®¡ç®— | ä»…èŠ‚çœåè¾“å…¥æ¨ç†æˆæœ¬ï¼›æœ¬æ–‡ä»æºå¤´å‡å°‘**æ•´ä½“æ¨ç†é¢‘ç‡** |
| Residual Policy Learning [13] | å­¦ä¹ åŸºç¡€ç­–ç•¥ä¸Šçš„æ®‹å·®ä¿®æ­£ | æœ¬æ–‡å°†æ®‹å·®åº”ç”¨äº**æ¨æµ‹æ‰§è¡Œåœºæ™¯ä¸‹çš„çŠ¶æ€ä¸åŒ¹é…è¡¥å¿**ï¼Œæ›´å…·é’ˆå¯¹æ€§ |

> âœ… åˆ›æ–°äº®ç‚¹ï¼š
> - å°† speculative execution ä» NLP æ‰©å±•è‡³ real-time æ§åˆ¶é¢†åŸŸï¼›
> - å¼•å…¥ mismatch-aware çš„è½»é‡ corrector å®ç°â€œé”™è¯¯å†åˆ©ç”¨â€ï¼Œé¿å…å®Œå…¨é‡ç®—ï¼›
> - æ”¯æŒé•¿æ—¶åŸŸæ¨æµ‹æ‰§è¡Œï¼ˆlong-horizon speculationï¼‰ï¼Œå¹¶é€šè¿‡ temporal Transformer å¤„ç†ç³»ç»Ÿæ¼‚ç§»ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- å®éªŒåŸºäº **DeepMind Control Suite (DMC)** ä¸­çš„ `Humanoid-Walk` è¿ç»­æ§åˆ¶ä»»åŠ¡ã€‚
- ä½¿ç”¨ Mujoco ç‰©ç†å¼•æ“æ¨¡æ‹Ÿç¯å¢ƒåŠ¨åŠ›å­¦ã€‚
- æ•°æ®æ¥æºäºé¢„è®­ç»ƒçš„ **TD-MPC2 æ¨¡å‹**æ”¶é›†çš„çœŸå®è½¨è¿¹ï¼ŒåŒ…å«çœŸå®çŠ¶æ€ã€æ¨æµ‹é¢„æµ‹ã€æ‰§è¡ŒåŠ¨ä½œç­‰ä¿¡æ¯ã€‚

### å®éªŒè®¾ç½®
- **ä¸»å¹²æ¨¡å‹**ï¼šé‡‡ç”¨é¢„è®­ç»ƒçš„ **TD-MPC2 world model** ä½œä¸ºæ¨æµ‹æ¨¡å—ï¼ˆæœªé‡æ–°ç«¯åˆ°ç«¯è®­ç»ƒï¼‰ï¼›
- **æ¨æµ‹æœºåˆ¶**ï¼š
  - è§„åˆ’è§†ç•Œï¼ˆplanning horizonï¼‰H = 3ï¼›
  - æ‰§è¡Œè§†ç•Œï¼ˆexecute horizonï¼‰L âˆˆ {3, 6}ï¼›
  - åŠ¨ä½œé˜Ÿåˆ—ç”± latent-space MPC ç”Ÿæˆï¼Œå¹¶ç»“åˆ encoder ç¼–ç å½“å‰è§‚æµ‹ä¸º latent $ z_{\text{real}} $ï¼›
- **ä¿®æ­£æœºåˆ¶**ï¼š
  - å®šä¹‰ latent mismatchï¼š$ d = \|z_{\text{real}} - \hat{z}\|_2 $ï¼›
  - è‹¥ $ d > \tau $ï¼ˆé˜ˆå€¼ï¼‰ï¼Œåˆ™è§¦å‘ full replanningï¼›
  - å¦åˆ™ä½¿ç”¨ corrector è¾“å‡ºæ®‹å·®åŠ¨ä½œ $ \Delta a $ï¼Œæ‰§è¡Œ $ a_{\text{exec}} = \text{clip}(a^{\text{spec}} + \Delta a) $ï¼›
- **Corrector æ¶æ„è®¾è®¡å¯¹æ¯”**ï¼š
  1. **Gated Two-Tower MLP**ï¼šåˆ†åˆ«æå– real/predicted latent ç‰¹å¾ï¼Œé€šè¿‡é—¨æ§èåˆè¿›è¡Œå±€éƒ¨å¿«é€Ÿä¿®æ­£ï¼›
  2. **Temporal Transformer**ï¼šæ¥æ”¶è¿‡å» K æ­¥çš„ mismatch ç‰¹å¾åºåˆ—ï¼Œæ•æ‰é•¿æœŸæ¼‚ç§»è¶‹åŠ¿ã€‚

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| Inference Calls | æ€»å…±è°ƒç”¨ MPC è§„åˆ’å™¨çš„æ¬¡æ•°ï¼ˆè¶Šä½è¶Šå¥½ï¼‰ |
| End-to-End Step Latency | æ¯ä¸ªç¯å¢ƒæ­¥çš„å¹³å‡å»¶è¿Ÿï¼ˆmsï¼‰ |
| Cumulative Reward | åœ¨ Humanoid-Walk ä¸Šçš„æœ€ç»ˆå¾—åˆ† |
| Ablation Study | åˆ†ææ—  corrector æˆ–ä¸åŒ speculation depth ä¸‹çš„è¡¨ç°å·®å¼‚ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Original TD-MPC2**ï¼šæ¯ä¸€æ­¥éƒ½æ‰§è¡Œä¸€æ¬¡å®Œæ•´è§„åˆ’ï¼ˆbaselineï¼‰ï¼›
- **Speculation-only**ï¼šæ¨æµ‹æ‰§è¡Œä½†æ—  correctorï¼›
- **Correction-only**ï¼šä»…ä½¿ç”¨ corrector ä½†ä¸æ¨æµ‹ï¼›
- **Proposed Method**ï¼šspeculation + correctionï¼ˆæœ¬æ–‡æ–¹æ³•ï¼‰ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆDMC Humanoid-Walkï¼‰
| æŒ‡æ ‡ | Original TD-MPC2 | æœ¬æ–‡æ–¹æ³•ï¼ˆSpec + Corrï¼‰ | æå‡/å˜åŒ– |
|------|------------------|-------------------------|-----------|
| Inference Calls | 500 | **282** | â†“ **43.6%** |
| Avg. Latency per Step | 36 ms | **27 ms** | â†“ **25%** |
| Cumulative Reward | 935 | **869** | â†“ 7.1%ï¼ˆç»å¯¹å€¼é™66åˆ†ï¼‰ |

> æ³¨ï¼šcorrector å¼•å…¥çº¦ 12ms é¢å¤–å¼€é”€ï¼Œä½†ç”±äºæ¨ç†é¢‘æ¬¡å¤§å¹…é™ä½ï¼Œæ€»ä½“å»¶è¿Ÿä»æ˜¾è‘—ä¸‹é™ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ç›¸æ¯”åŸå§‹ TD-MPC2**ï¼š
  - æ¨ç†è°ƒç”¨å‡å°‘è¿‘ä¸€åŠï¼ˆ500â†’282ï¼‰ï¼Œå®ç°æ˜¾è‘—æ•ˆç‡æå‡ï¼›
  - å°½ç®¡å¥–åŠ±ç•¥æœ‰ä¸‹é™ï¼ˆ935â†’869ï¼‰ï¼Œä½†åœ¨å®æ—¶æ§åˆ¶åœºæ™¯ä¸‹ï¼Œé€Ÿåº¦å¢ç›Šè¿œè¶…ç²¾åº¦æŸå¤±ã€‚
- **ç›¸æ¯” speculation-only æ–¹æ³•**ï¼š
  - æ‰§è¡Œ 3 æ­¥æ¨æµ‹ä¸”æ—  correction æ—¶ï¼Œreward æš´è·Œè‡³ **142**ï¼ˆâ†“84.8%ï¼‰ï¼›
  - æ‰§è¡Œ 2 æ­¥æ¨æµ‹æ—  correction æ—¶ï¼Œreward é™è‡³ **778**ï¼ˆâ†“16.8%ï¼‰ï¼›
  - è¡¨æ˜ **æ— ä¿®æ­£çš„æ¨æµ‹æä¸å¯é **ï¼Œå°¤å…¶åœ¨é•¿è§†ç•Œä¸‹è¯¯å·®ç´¯ç§¯ä¸¥é‡ã€‚

### æ¶ˆèå®éªŒç»“æœ
| è®¾ç½® | Reward | æ¨ç†æ¬¡æ•° | è¯´æ˜ |
|------|--------|----------|------|
| Original TD-MPC2 | 935 | 500 | åŸºå‡† |
| Speculation-only (3 steps) | 142 | ~167 | ä¸¥é‡å¤±ç¨³ï¼Œä¸å¯è¡Œ |
| Speculation-only (2 steps) | 778 | ~250 | å¯è¡Œä½†æ€§èƒ½ä¸‹é™æ˜æ˜¾ |
| **Full Method (w/ Corrector)** | **869** | **282** | æ˜¾è‘—ä¼˜äº speculation-onlyï¼Œæ¢å¤çº¦ 91 åˆ† reward |
| Two-Tower MLP vs Temporal Transformer | ç›¸è¿‘ | ç›¸è¿‘ | Two-Tower æœ€ç»ˆ loss æ›´ä½ï¼ŒTemporal æ”¶æ•›æ›´å¹³ç¨³ |

> ğŸ” å‘ç°ï¼šå¤§å¤šæ•°æ¨ç†æ­¥éª¤èƒ½æˆåŠŸæ‰§è¡Œ **2 ä¸ªæ¨æµ‹åŠ¨ä½œ**ï¼Œè¡¨æ˜çŸ­è§†ç•Œæ¨æµ‹å·²å…·å¤‡é«˜å‘½ä¸­ç‡ï¼›corrector æ˜¾è‘—æå‡äº†é²æ£’æ€§å’Œæ§åˆ¶è´¨é‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **è¾“å…¥é¢„æµ‹å¯æœ‰æ•ˆè½¬åŒ–ä¸ºé¢„è®¡ç®—èµ„æº**ï¼šé€šè¿‡é¢„æµ‹æœªæ¥ latent state å¹¶æå‰è§„åˆ’åŠ¨ä½œï¼Œå¯åœ¨ç­‰å¾…çœŸå®è§‚æµ‹æœŸé—´å®Œæˆå¤§é‡è®¡ç®—ï¼Œä»è€Œå‹ç¼©ç«¯åˆ°ç«¯å»¶è¿Ÿã€‚
2. **æ¨æµ‹æ‰§è¡Œå¿…é¡»é…åˆä¿®æ­£æœºåˆ¶æ‰å¯é **ï¼šæ¶ˆèå®éªŒè¯æ˜ï¼Œå•çº¯æ¨æµ‹ææ˜“å› è¯¯å·®ç§¯ç´¯å¯¼è‡´å´©æºƒï¼›å¼•å…¥ lightweight corrector æ˜¯å®ç°ç¨³å¥åŠ é€Ÿçš„å…³é”®ã€‚
3. **mismatch-aware recycling æ˜¾è‘—æå‡æ•ˆç‡**ï¼šé€šè¿‡ residual correction å¤ç”¨å·²æœ‰æ¨æµ‹ç»“æœï¼Œé¿å…æ¯æ¬¡ mismatch éƒ½è§¦å‘ full replanningï¼Œæå¤§é™ä½äº†å¹³å‡æ¨ç†é¢‘ç‡ã€‚
4. **åœ¨ä¸¥æ ¼å»¶è¿Ÿé¢„ç®—ä¸‹ï¼Œé€Ÿåº¦ä¼˜äºç»å¯¹å‡†ç¡®æ€§**ï¼šå°½ç®¡ reward ä¸‹é™ 7.1%ï¼Œä½† 25% çš„å»¶è¿Ÿé™ä½å¸¦æ¥äº†æ›´ç¨³å®šçš„å®æ—¶å“åº”èƒ½åŠ›ï¼Œç¬¦åˆ Win Fast or Lose Slow [1] çš„ç†å¿µã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰è¯„ä¼°å±€é™äºå•ä¸€ä»»åŠ¡ï¼ˆHumanoid-Walkï¼‰å’Œå›ºå®šè§„åˆ’è§†ç•Œï¼Œæ³›åŒ–æ€§å¾…éªŒè¯ï¼›
- ä½¿ç”¨é¢„è®­ç»ƒ TD-MPC2 ä½œä¸ºæ¨æµ‹æ¨¡å—ï¼Œæœªè¿›è¡Œ joint training æˆ– online adaptationï¼Œå¯èƒ½é™åˆ¶æœ€å¤§æ¨æµ‹æ·±åº¦ï¼›
- Corrector å¢åŠ  per-inference å¼€é”€ï¼ˆ~12msï¼‰ï¼Œåœ¨æç«¯ä½å»¶è¿Ÿç¡¬ä»¶ä¸Šå¯èƒ½å‰Šå¼±æ”¶ç›Šï¼›
- å›ºå®š mismatch é˜ˆå€¼ $\tau$ï¼Œç¼ºä¹åŠ¨æ€é¢„ç®—åˆ†é…æœºåˆ¶ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **è”åˆè®­ç»ƒ speculation ä¸ correction æ¨¡å—**ï¼šä½¿ corrector æ›´é€‚åº”é—­ç¯æ¨æµ‹æ‰§è¡Œçš„å®é™…åˆ†å¸ƒï¼›
2. **è‡ªé€‚åº”é¢„ç®—è°ƒåº¦ï¼ˆadaptive budgetingï¼‰**ï¼šæ ¹æ® mismatch å†å²å’Œæ¨¡å‹ä¸ç¡®å®šæ€§åŠ¨æ€è°ƒæ•´ speculation depth å’Œ replanning é¢‘ç‡ï¼›
3. **æ‰©å±•è‡³æ›´å¤š DMC ä»»åŠ¡åŠçœŸå®ä¸–ç•Œæ§åˆ¶åœºæ™¯**ï¼šæµ‹è¯•åœ¨å™ªå£°ä¼ æ„Ÿå™¨ã€éƒ¨åˆ†å¯è§‚æµ‹ç¯å¢ƒä¸‹çš„è¡¨ç°ï¼›
4. **ç³»ç»Ÿçº§æµæ°´çº¿ä¼˜åŒ–**ï¼šè¿›ä¸€æ­¥é‡å  speculationã€correction ä¸ç¯å¢ƒäº¤äº’ï¼Œé™ä½ tail latencyã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡ºä¸€ç§åŸºäºè¾“å…¥é¢„æµ‹ä¸é”™è¯¯ä¿®æ­£çš„ speculation-and-correction æ¡†æ¶ï¼Œåœ¨ DMC Humanoid-Walk ä¸Šå®ç°äº† **43.6% çš„æ¨ç†è°ƒç”¨å‡å°‘** å’Œ **25% çš„ç«¯åˆ°ç«¯å»¶è¿Ÿé™ä½**ï¼Œä»…å¸¦æ¥ **7.1% çš„å›æŠ¥ä¸‹é™**ï¼Œè¯æ˜äº†å…¶åœ¨å®æ—¶å¤šæ¨¡æ€ LLM æ§åˆ¶ä»»åŠ¡ä¸­çš„é«˜æ•ˆæ€§ä¸å¯è¡Œæ€§ã€‚

</details>

---

### 15. [Bandwidth-Efficient Adaptive Mixture-of-Experts via Low-Rank Compensation](https://arxiv.org/abs/2512.17073)

**Authors**: Zhenyu Liu, Yunzhen Liu, Zehao Fan, Garrett Gagnon, Yayue Hou, Nan Wu, Yangwook Kang, Liu Liu  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.17073v1  

#### Abstract
Mixture-of-Experts (MoE) models scale capacity via sparse activation but stress memory and bandwidth. Offloading alleviates GPU memory by fetching experts on demand, yet token-level routing causes irregular transfers that make inference I/O-bound. Static uniform quantization reduces traffic but degr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šBandwidth-Efficient Adaptive Mixture-of-Experts via Low-Rank Compensation

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
Mixture-of-Experts (MoE) æ¨¡å‹é€šè¿‡ç¨€ç–æ¿€æ´»æ‰©å±•æ¨¡å‹å®¹é‡ï¼Œä½†åœ¨æ¨ç†è¿‡ç¨‹ä¸­é¢ä¸´ä¸¥é‡çš„**å†…å­˜å‹åŠ›å’Œå¸¦å®½ç“¶é¢ˆ**ã€‚ç”±äºæ¯ä¸ª token åŠ¨æ€è·¯ç”±åˆ°ä¸åŒä¸“å®¶ï¼Œå¯¼è‡´å‚æ•°åŠ è½½ä¸è§„åˆ™ï¼Œä½¿å¾—æ¨ç†è¿‡ç¨‹ä¸¥é‡å— I/O é™åˆ¶ï¼ˆI/O-boundï¼‰ã€‚è™½ç„¶é‡åŒ–ï¼ˆquantizationï¼‰å¯ä»¥å‡å°‘ä¼ è¾“é‡ï¼Œä½†**é™æ€ã€ç»Ÿä¸€çš„ä½æ¯”ç‰¹é‡åŒ–**ä¼šå¿½ç•¥ä¸“å®¶ä¹‹é—´çš„å¼‚è´¨æ€§ï¼Œå°¤å…¶åœ¨é«˜å‹ç¼©æ¯”ä¸‹æ˜¾è‘—æŸå®³ç²¾åº¦ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º **Bandwidth-Efficient Adaptive Mixture-of-Experts via Low-Rank Compensation** çš„æ–°æ–¹æ³•ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- åœ¨ç¦»çº¿é˜¶æ®µä¸ºæ¯ä¸ªä¸“å®¶é¢„è®¡ç®—ä¸€ä¸ªè½»é‡çº§çš„ **low-rank compensator**ï¼ˆä½ç§©è¡¥å¿å™¨ï¼‰ï¼Œç”¨äºæ¢å¤é‡åŒ–å¸¦æ¥çš„è¯¯å·®ã€‚
- åœ¨æ¨ç†æ—¶ï¼Œä»…å¯¹å½“å‰ token è·¯ç”±å¾—åˆ†æœ€é«˜çš„ Top-*n* ä¸“å®¶è¿›è¡Œç²¾åº¦æ¢å¤ï¼šä¼ è¾“å…¶ä½ç§©å› å­å¹¶å®æ—¶é‡æ„é«˜ç²¾åº¦æƒé‡ï¼›å…¶ä½™ä¸“å®¶ä¿æŒä½æ¯”ç‰¹å½¢å¼ï¼Œæ— éœ€è¡¥å¿ã€‚

è¯¥æ–¹æ³•ç»“åˆäº† **offloading** å’Œ **router-guided dynamic precision adaptation**ï¼Œå®ç°äº†â€œæŒ‰éœ€æ¢å¤ç²¾åº¦â€ã€‚

### åˆ›æ–°ç‚¹
1. **Offline Low-Rank Compensation for Efficient Restoration**  
   å¼•å…¥ per-expert çš„ä½ç§©è¡¥å¿æ¨¡å—ï¼Œåœ¨æœ‰é™å¸¦å®½é¢„ç®—ä¸‹å®ç°é«˜æ•ˆçš„é«˜ç²¾åº¦é‡å»ºã€‚

2. **Token-Level Router-Guided Precision Adaptation**  
   åˆ©ç”¨ router è¾“å‡ºåŠ¨æ€å†³å®šå“ªäº›ä¸“å®¶éœ€è¦æ¢å¤ç²¾åº¦ï¼Œä»…å¯¹ Top-*n* ä¸“å®¶åº”ç”¨è¡¥å¿ï¼Œæå‡å¸¦å®½åˆ©ç”¨æ•ˆç‡ã€‚

3. **Kurtosis-Guided Rank Allocation**  
   å‘ç°ä¸“å®¶æƒé‡çš„å³°åº¦ï¼ˆkurtosisï¼‰ä¸å…¶é‡åŒ–è¯¯å·®æ­£ç›¸å…³ï¼Œæ®æ­¤è®¾è®¡éå‡åŒ€çš„è¡¥å¿ç§©åˆ†é…ç­–ç•¥ï¼šé«˜ kurtosis ä¸“å®¶åˆ†é…æ›´é«˜ç§©ï¼Œä½è€…åˆ™æ›´ä½ç”šè‡³ä¸ºé›¶ï¼Œé¿å…èµ„æºæµªè´¹ã€‚

4. **ç³»ç»Ÿçº§å…¼å®¹æ€§**  
   æ–¹æ³•é€‚ç”¨äº GPU-only å’Œ GPU-NDPï¼ˆNear Data Processingï¼‰æ¶æ„ï¼Œèƒ½ä¸ç°æœ‰ç³»ç»Ÿï¼ˆå¦‚ Hobbitã€MoNDEï¼‰æ— ç¼é›†æˆã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ GPTQã€HQQï¼‰ | æœ¬æ–‡æ–¹æ³• |
|------|--------------------------|---------|
| é‡åŒ–æ–¹å¼ | ç»Ÿä¸€å¯¹æ‰€æœ‰ä¸“å®¶é‡åŒ– | åŠ¨æ€é€‰æ‹©æ€§æ¢å¤ Top-*n* ä¸“å®¶ç²¾åº¦ |
| è¡¥å¿æœºåˆ¶ | æ— æˆ–å…¨é‡è¡¥å¿ | ä»…ä¼ è¾“ compact low-rank factors |
| å¸¦å®½å¼€é”€ | è¾ƒé«˜ï¼ˆå°¤å…¶å…¨ç²¾åº¦æ¢å¤ï¼‰ | æ˜¾è‘—é™ä½ï¼ˆåªä¼ å°‘æ•°è¡¥å¿å› å­ï¼‰ |
| å‡†ç¡®ç‡æŸå¤± | é«˜å‹ç¼©ä¸‹ä¸¥é‡ä¸‹é™ | åœ¨ INT2/INT3 ä¸‹ä»ä¿æŒé«˜å‡†ç¡®ç‡ |
| ç³»ç»Ÿé€‚é…æ€§ | å¤šæ•°æœªè€ƒè™‘ MoE ç‰¹æ€§ | æ”¯æŒ offloading ä¸ NDP æ¶æ„ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **å¸¸è¯†æ¨ç†ä»»åŠ¡**ï¼ˆzero-shotï¼‰ï¼š
  - MathQA, Hellaswag, ARC-Easy, ARC-Challenge, BoolQ, Winogrande, PIQA
- **å¤šä»»åŠ¡ç†è§£èƒ½åŠ›è¯„ä¼°**ï¼ˆ5-shotï¼‰ï¼š
  - MMLU
- **ç”Ÿæˆè´¨é‡è¯„ä¼°**ï¼š
  - WikiText2ï¼ˆç”¨äºæµ‹é‡ Perplexity, PPLï¼‰

ä»¥ä¸Šæ•°æ®é›†é€šè¿‡ EleutherAI LM Evaluation Harness è¿›è¡Œè¯„æµ‹ã€‚

### å®éªŒè®¾ç½®
#### æ¨¡å‹
è¯„ä¼°ä¸‰ç§ä¸»æµ MoE æ¶æ„ï¼š
| Model | Layers | Experts | Top-k | Total Params |
|-------|--------|--------|-------|--------------|
| Mixtral-8Ã—7B | 32 | 8 | 2 | 46.7B |
| Mixtral-8Ã—22B | 56 | 8 | 2 | 140.6B |
| DeepSeek-MoE-16B | 28 | 64 | 6 (å«2å…±äº«) | 16.4B |

#### ç¡¬ä»¶ç¯å¢ƒ
- **GPU-only**ï¼šNVIDIA H100 GPU + DDR å†…å­˜ï¼Œé€šè¿‡ PCIe åŠ è½½ä¸“å®¶
- **GPU-NDP**ï¼šH100 GPU + NDP è®¾å¤‡ï¼ˆ512GB/s å¸¦å®½ï¼Œ512GB å®¹é‡ï¼‰ï¼Œæ”¯æŒè¿‘å†…å­˜è®¡ç®—

è¾“å…¥é•¿åº¦è®¾ä¸º 256ï¼Œè¾“å‡ºé•¿åº¦æµ‹è¯•å¤šç§é…ç½®ä»¥è¯„ä¼°ç«¯åˆ°ç«¯ååé‡ã€‚

#### è¯„ä¼°æŒ‡æ ‡
- **å‡†ç¡®æ€§**ï¼šMMLU å¹³å‡å¾—åˆ†ã€å„åŸºå‡†ä»»åŠ¡å‡†ç¡®ç‡ã€WikiText2 ä¸Šçš„ PPL
- **æ€§èƒ½**ï¼šend-to-end ååé‡ï¼ˆtokens/sï¼‰ã€å»¶è¿Ÿã€å¸¦å®½å ç”¨
- **æ¶ˆèç ”ç©¶**ï¼šæ¢å¤ä¸“å®¶æ•°é‡ã€è¡¥å¿ç§©å¤§å°ã€kurtosis åˆ†é…ç­–ç•¥çš„å½±å“

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | åŸºçº¿æ–¹æ³• |
|------|--------|
| é‡åŒ–ç®—æ³• | GPTQ, HQQ |
| æ¨ç†ç³»ç»Ÿï¼ˆGPU-onlyï¼‰ | Mixtral-Offloading, HOBBIT |
| æ¨ç†ç³»ç»Ÿï¼ˆGPU-NDPï¼‰ | MoNDE |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å‡†ç¡®æ€§ç»“æœï¼ˆFigure 6ï¼‰
- **Uniform ä½æ¯”ç‰¹é‡åŒ–ä¸¥é‡é™å‡†**ï¼š
  - Mixtral-8Ã—7B ä¸Šï¼ŒGPTQ INT2 å°†å¹³å‡å‡†ç¡®ç‡ä» 70.03% é™è‡³ 34.41%
  - DeepSeek-MoE-16B ä» 59.63% â†’ 38.50%

- **æœ¬æ–¹æ³•æ˜¾è‘—æ¢å¤ç²¾åº¦**ï¼ˆINT2 settingï¼‰ï¼š
| Model | Avg Acc â†‘ | MMLU â†‘ |
|-------|-----------|--------|
| Mixtral-8Ã—7B | +8.24% | +10.50% |
| Mixtral-8Ã—22B | +8.70% | +2.83% |
| DeepSeek-MoE-16B | +2.30% | +1.73% |

> æ³¨ï¼šMixtral è·¯ç”±é«˜åº¦é›†ä¸­äº Top-1 ä¸“å®¶ï¼Œå› æ­¤ä»…æ¢å¤ Top-1 å³å¯å¤§å¹…ææ•ˆï¼›DeepSeek è·¯ç”±æ›´å‡åŒ€ï¼Œéœ€æ¢å¤ Top-3 æ‰æœ‰æ•ˆæœã€‚

### ç³»ç»Ÿæ€§èƒ½ï¼ˆFigure 7ï¼‰
#### GPU-only è®¾ç½®ä¸‹çš„ååæå‡
| Model | Baseline (tokens/s) | Ours (INT3) | Speedup | Ours (INT2) | Speedup |
|-------|---------------------|------------|---------|------------|---------|
| Mixtral-8Ã—7B | 2.37 | 12.27 | **5.17Ã—** | 18.11 | **7.64Ã—** |
| Mixtral-8Ã—22B | 0.79 | 4.08 | **5.18Ã—** | 6.02 | **7.63Ã—** |
| DeepSeek-MoE-16B | ~1.5 | ~6.6 | ~4.38Ã— | ~8.9 | ~5.93Ã— |

> Hobbit åŸºçº¿ä¹Ÿæœ‰ç±»ä¼¼åŠ é€Ÿè¶‹åŠ¿ï¼ˆ3.77Ã— ~ 5.48Ã—ï¼‰

#### GPU-NDP è®¾ç½®ä¸‹çš„ååæå‡
| Model | Baseline | Ours (INT3) | Speedup | Ours (INT2) | Speedup |
|-------|----------|------------|---------|------------|---------|
| Mixtral-8Ã—7B | 11.56 | 54.96 | **4.75Ã—** | 77.33 | **6.69Ã—** |
| Mixtral-8Ã—22B | 3.56 | 18.12 | ~5.09Ã— | 25.75 | **7.23Ã—** |
| DeepSeek-MoE-16B | 61.75 | 194.51 | **3.15Ã—** | 233.24 | **3.78Ã—** |

âœ… æ€»ä½“å®ç° **3Ã— ~ 8Ã— çš„ç«¯åˆ°ç«¯åååŠ é€Ÿ**

### æ¶ˆèå®éªŒç»“æœï¼ˆFigure 8 & Table 2ï¼‰

#### ï¼ˆ1ï¼‰æ¢å¤ä¸“å®¶æ•°é‡å½±å“
- **Mixtral-8Ã—7B**ï¼šæ¢å¤ Top-1 å·²è¶³å¤Ÿï¼ˆMMLU: 47.53%ï¼‰ï¼ŒåŠ  Top-2 æå‡æœ‰é™ï¼ˆâ†’48.79%ï¼‰
- **DeepSeek-MoE-16B**ï¼šéœ€æ¢å¤ Top-3 æ‰è¾¾æœ€ä½³ï¼ˆMMLU: 25.80% â†’ 28.75%ï¼‰

> è¡¨æ˜åº”æ ¹æ®è·¯ç”±åˆ†å¸ƒåŠ¨æ€è°ƒæ•´ *n*

#### ï¼ˆ2ï¼‰è¡¥å¿ç§©é¢„ç®—çš„å½±å“
- æé«˜ç§©å¯æ”¹å–„ PPLï¼Œä½†å¸¦æ¥é¢å¤–ä¼ è¾“å¼€é”€ï¼š
  - Rank-16ï¼šæ¯ä¸“å®¶ 0.32MBï¼ˆå  INT2 æƒé‡ 0.75%ï¼‰
  - Rank-128ï¼š2.53MBï¼ˆå æ¯” 6.03%ï¼‰
- åœ¨ Mixtral ä¸Šï¼Œrank >32 åæ”¶ç›Šé€’å‡ â†’ æ”¯æŒ **rank budget æ§åˆ¶**

#### ï¼ˆ3ï¼‰Kurtosis-Guided vs Uniform Rank Allocation
| Rank | Uniform PPL | Kurtosis-Guided PPL |
|------|-------------|---------------------|
| 16 | 7.55 | **7.05** |
| 128 | 8.54 | **3.77** |

âœ… æ˜¾ç¤ºåŸºäº kurtosis çš„éå‡åŒ€åˆ†é…æ˜¾è‘—ä¼˜äº uniform åˆ†é…ï¼ŒéªŒè¯äº†å¼‚è´¨æ€§å»ºæ¨¡çš„æœ‰æ•ˆæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **MoE çš„ router å¾—åˆ†é«˜åº¦åæ–œ**ï¼ŒTop-1 æˆ– Top-*n* ä¸“å®¶ä¸»å¯¼é¢„æµ‹è´¨é‡ï¼Œå› æ­¤åªéœ€é’ˆå¯¹æ€§æ¢å¤è¿™äº›ä¸“å®¶çš„ç²¾åº¦å³å¯å¤§å¹…æŒ½å›é‡åŒ–æŸå¤±ã€‚
2. **ä¸“å®¶é—´é‡åŒ–è¯¯å·®å­˜åœ¨å¼‚è´¨æ€§**ï¼Œä¸æƒé‡çŸ©é˜µçš„ **kurtosis æ­£ç›¸å…³**ï¼Œæ®æ­¤è®¾è®¡éå‡åŒ€è¡¥å¿ç§©åˆ†é…ç­–ç•¥å¯æ›´é«˜æ•ˆåˆ©ç”¨èµ„æºã€‚
3. **ä»…ä¼ è¾“ low-rank factorsï¼ˆU/Vï¼‰è€Œéå®Œæ•´é«˜ç²¾åº¦æƒé‡**ï¼Œå¯åœ¨å‡ ä¹ä¸å¢åŠ å¸¦å®½è´Ÿæ‹…çš„å‰æä¸‹å®Œæˆç²¾åº¦æ¢å¤ã€‚
4. è¯¥æ–¹æ³•åœ¨ **GPU-only å’Œ GPU-NDP ç³»ç»Ÿä¸­å‡è¡¨ç°å‡ºè‰²**ï¼Œå…¼å®¹æ€§å¼ºï¼Œå¯ä½œä¸ºé€šç”¨ä¼˜åŒ–æ’ä»¶é›†æˆè¿›ç°æœ‰ MoE æ¨ç†æ¡†æ¶ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰è¡¥å¿æœºåˆ¶ä¾èµ– SVD åˆ†è§£ï¼Œ**ç¦»çº¿è®¡ç®—æˆæœ¬è¾ƒé«˜**ï¼Œå°¤å…¶å¯¹å¤§è§„æ¨¡ä¸“å®¶ã€‚
- å¯¹ **è·¯ç”±åˆ†å¸ƒè¾ƒå‡åŒ€çš„æ¨¡å‹ï¼ˆå¦‚ DeepSeek-MoEï¼‰æ•ˆæœç›¸å¯¹å—é™**ï¼Œå¯èƒ½éœ€è¦æ›´å¤šä¸“å®¶å‚ä¸è¡¥å¿ã€‚
- å½“å‰è¡¥å¿ä»…ä½œç”¨äº FFN å±‚ï¼Œå°šæœªæ‰©å±•è‡³ attention æˆ– embedding å±‚ã€‚
- è¡¥å¿ç§©çš„é€‰æ‹©ä»ä¾èµ–äººå·¥è®¾å®šå¹³å‡é¢„ç®—ï¼Œç¼ºä¹å®Œå…¨è‡ªé€‚åº”æœºåˆ¶ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å¼€å‘ **model-aware ä¸ hardware-aware çš„è”åˆ rank allocation ç­–ç•¥**
- æ¢ç´¢æ›¿ä»£ SVD çš„æ›´é«˜æ•ˆè¡¥å¿è¡¨ç¤ºï¼ˆå¦‚ LoRA-styleï¼‰
- è®¾è®¡ **adaptive top-*n* selection æœºåˆ¶**ï¼Œæ ¹æ®è¾“å…¥åŠ¨æ€å†³å®šæ¢å¤ä¸“å®¶æ•°
- å°†è¡¥å¿æœºåˆ¶æ¨å¹¿è‡³æ›´å¤šå±‚ç±»å‹ï¼ˆattention, RMSNorm ç­‰ï¼‰
- ç»“åˆ prefetching ä¸è¡¥å¿æœºåˆ¶ï¼Œè¿›ä¸€æ­¥ç¼“è§£ I/O å»¶è¿Ÿ

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼šæœ¬æ–‡æå‡ºä¸€ç§ router-guidedã€low-rank è¡¥å¿é©±åŠ¨çš„è‡ªé€‚åº”é‡åŒ–æ–¹æ³•ï¼Œåœ¨æä½å¸¦å®½å¼€é”€ä¸‹å®ç°äº† MoE æ¨¡å‹çš„é«˜ä¿çœŸæ¨ç†ï¼Œæ˜¾è‘—æå‡äº†ååæ•ˆç‡ï¼Œä¸ºå¤§è§„æ¨¡ MoE éƒ¨ç½²æä¾›äº†å®ç”¨è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 16. [Reinforcement Learning for Self-Improving Agent with Skill Library](https://arxiv.org/abs/2512.17102)

**Authors**: Jiongxiao Wang, Qiaojing Yan, Yawei Wang, Yijun Tian, Soumya Smruti Mishra, Zhichao Xu, Megha Gandhi, Panpan Xu, Lin Lee Cheong  
**Category**: cs.AI  
**Published**: 2025-12-22  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.17102v1  

#### Abstract
Large Language Model (LLM)-based agents have demonstrated remarkable capabilities in complex reasoning and multi-turn interactions but struggle to continuously improve and adapt when deployed in new environments. One promising approach is implementing skill libraries that allow agents to learn, vali...

---

### 17. [Bridging Training and Merging Through Momentum-Aware Optimization](https://arxiv.org/abs/2512.17109)

**Authors**: Alireza Moayedikia, Alicia Troncoso  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.17109v1  

#### Abstract
Training large neural networks and merging task-specific models both exploit low-rank structure and require parameter importance estimation, yet these challenges have been pursued in isolation. Current workflows compute curvature information during training, discard it, then recompute similar inform...

---

### 18. [UCoder: Unsupervised Code Generation by Internal Probing of Large Language Models](https://arxiv.org/abs/2512.17385)

**Authors**: Jiajun Wu, Jian Yang, Wei Zhang, Lin Jing, Yuqing Ma, Ensheng Shi, Yuchi Ma, Zhoujun Li, Xianglong Liu  
**Category**: cs.CL  
**Published**: 2025-12-22  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.17385v1  

#### Abstract
Large language models (LLMs) have demonstrated remarkable capabilities in code generation tasks. However, their effectiveness heavily relies on supervised training with extensive labeled (e.g., question-answering pairs) or unlabeled datasets (e.g., code snippets), which are often expensive and diffi...

---

### 19. [Alzheimer's Disease Brain Network Mining](https://arxiv.org/abs/2512.17276)

**Authors**: Alireza Moayedikia, Sara Fin  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.17276v1  

#### Abstract
Machine learning approaches for Alzheimer's disease (AD) diagnosis face a fundamental challenges. Clinical assessments are expensive and invasive, leaving ground truth labels available for only a fraction of neuroimaging datasets. We introduce Multi view Adaptive Transport Clustering for Heterogeneo...

---

### 20. [Stakeholder Suite: A Unified AI Framework for Mapping Actors, Topics and Arguments in Public Debates](https://arxiv.org/abs/2512.17347)

**Authors**: Mohamed Chenene, Jeanne Rouhier, Jean Dani\'elou, Mihir Sarkar, Elena Cabrio  
**Category**: cs.CL  
**Published**: 2025-12-22  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.17347v1  

#### Abstract
Public debates surrounding infrastructure and energy projects involve complex networks of stakeholders, arguments, and evolving narratives. Understanding these dynamics is crucial for anticipating controversies and informing engagement strategies, yet existing tools in media intelligence largely rel...

---

### 21. [DiffeoMorph: Learning to Morph 3D Shapes Using Differentiable Agent-Based Simulations](https://arxiv.org/abs/2512.17129)

**Authors**: Seong Ho Pahng, Guoye Guan, Benjamin Fefferman, Sahand Hormoz  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.17129v1  

#### Abstract
Biological systems can form complex three-dimensional structures through the collective behavior of identical agents -- cells that follow the same internal rules and communicate without central control. How such distributed control gives rise to precise global patterns remains a central question not...

---

### 22. [MINPO: Memory-Informed Neural Pseudo-Operator to Resolve Nonlocal Spatiotemporal Dynamics](https://arxiv.org/abs/2512.17273)

**Authors**: Farinaz Mostajeran, Aruzhan Tleubek, Salah A Faroughi  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.17273v1  

#### Abstract
Many physical systems exhibit nonlocal spatiotemporal behaviors described by integro-differential equations (IDEs). Classical methods for solving IDEs require repeatedly evaluating convolution integrals, whose cost increases quickly with kernel complexity and dimensionality. Existing neural solvers ...

---

### 23. [Adversarially Robust Detection of Harmful Online Content: A Computational Design Science Approach](https://arxiv.org/abs/2512.17367)

**Authors**: Yidong Chai, Yi Liu, Mohammadreza Ebrahimi, Weifeng Li, Balaji Padmanabhan  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.17367v1  

#### Abstract
Social media platforms are plagued by harmful content such as hate speech, misinformation, and extremist rhetoric. Machine learning (ML) models are widely adopted to detect such content; however, they remain highly vulnerable to adversarial attacks, wherein malicious users subtly modify text to evad...

---

### 24. [Towards Explainable Conversational AI for Early Diagnosis with Large Language Models](https://arxiv.org/abs/2512.17559)

**Authors**: Maliha Tabassum, M Shamim Kaiser  
**Category**: cs.AI  
**Published**: 2025-12-22  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.17559v1  

#### Abstract
Healthcare systems around the world are grappling with issues like inefficient diagnostics, rising costs, and limited access to specialists. These problems often lead to delays in treatment and poor health outcomes. Most current AI and deep learning diagnostic systems are not very interactive or tra...

---

### 25. [Digitizing Nepal's Written Heritage: A Comprehensive HTR Pipeline for Old Nepali Manuscripts](https://arxiv.org/abs/2512.17111)

**Authors**: Anjali Sarawgi, Esteban Garces Arias, Christof Zotter  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.17111v1  

#### Abstract
This paper presents the first end-to-end pipeline for Handwritten Text Recognition (HTR) for Old Nepali, a historically significant but low-resource language. We adopt a line-level transcription approach and systematically explore encoder-decoder architectures and data-centric techniques to improve ...

---

### 26. [Distributed Learning in Markovian Restless Bandits over Interference Graphs for Stable Spectrum Sharing](https://arxiv.org/abs/2512.17161)

**Authors**: Liad Lea Didi, Kobi Cohen  
**Category**: cs.LG  
**Published**: 2025-12-22  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2512.17161v1  

#### Abstract
We study distributed learning for spectrum access and sharing among multiple cognitive communication entities, such as cells, subnetworks, or cognitive radio users (collectively referred to as cells), in communication-constrained wireless networks modeled by interference graphs. Our goal is to achie...

---

### 27. [Navigating Taxonomic Expansions of Entity Sets Driven by Knowledge Bases](https://arxiv.org/abs/2512.16953)

**Authors**: Pietro Cofone, Giovanni Amendola, Marco Manna, Aldo Ricioppo  
**Category**: cs.AI  
**Published**: 2025-12-22  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.16953v1  

#### Abstract
Recognizing similarities among entities is central to both human cognition and computational intelligence. Within this broader landscape, Entity Set Expansion is one prominent task aimed at taking an initial set of (tuples of) entities and identifying additional ones that share relevant semantic pro...

---

### 28. [UniRel-R1: RL-tuned LLM Reasoning for Knowledge Graph Relational Question Answering](https://arxiv.org/abs/2512.17043)

**Authors**: Yinxu Tang, Chengsong Huang, Jiaxin Huang, William Yeoh  
**Category**: cs.AI  
**Published**: 2025-12-22  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.17043v1  

#### Abstract
Knowledge Graph Question Answering (KGQA) has traditionally focused on entity-centric queries that return a single answer entity. However, real-world queries are often relational, seeking to understand how entities are associated. In this work, we introduce relation-centric KGQA, a complementary set...

---

### 29. [When Reasoning Meets Its Laws](https://arxiv.org/abs/2512.17901)

**Authors**: Junyu Zhang, Yifan Sun, Tianang Leng, Jingyan Shen, Liu Ziyin, Paul Pu Liang, Huan Zhang  
**Category**: cs.AI  
**Published**: 2025-12-22  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.17901v1  

#### Abstract
Despite the superior performance of Large Reasoning Models (LRMs), their reasoning behaviors are often counterintuitive, leading to suboptimal reasoning capabilities. To theoretically formalize the desired reasoning behaviors, this paper presents the Laws of Reasoning (LoRe), a unified framework tha...

---

### 30. [XLM: A Python package for non-autoregressive language models](https://arxiv.org/abs/2512.17065)

**Authors**: Dhruvesh Patel, Durga Prasad Maram, Sai Sreenivas Chintha, Benjamin Rozonoyer, Andrew McCallum  
**Category**: cs.CL  
**Published**: 2025-12-22  
**Score**: 5.0  
**Type**: new  
**ArXiv ID**: 2512.17065v1  

#### Abstract
In recent years, there has been a resurgence of interest in non-autoregressive text generation in the context of general language modeling. Unlike the well-established autoregressive language modeling paradigm, which has a plethora of standard training and inference libraries, implementations of non...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
