# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-01-01 06:00:28 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Training Report of TeleChat3-MoE](https://arxiv.org/abs/2512.24157)

**Authors**: Xinzhang Liu, Chao Wang, Zhihao Yang, Zhuo Jiang, Xuncheng Zhao, Haoran Wang, Lei Li, Dongdong He, Luobin Liu, Kaizhe Yuan, Han Gao, Zihan Wang, Yitong Yao, Sishi Xiong, Wenmin Deng, Haowei He, Kaidong Yu, Yu Zhao, Ruiyu Fang, Yuhao Jiang, Yingyan Li, Xiaohui Hu, Xi Yu, Jingqi Li, Yanwei Liu, Qingli Li, Xinyu Shi, Junhao Niu, Chengnuo Huang, Yao Xiao, Ruiwen Wang, Fengkai Li, Luwen Pu, Kaipeng Jia, Fubei Yao, Yuyao Huang, Xuewei He, Zhuoru Jiang, Ruiting Song, Rui Xue, Qiyi Xie, Jie Zhang, Zilu Huang, Zhaoxi Zhang, Zhilong Lu, Yanhan Zhang, Yin Zhang, Yanlei Xue, Zhu Yuan, Teng Su, Xin Jiang, Shuangyong Song, Yongxiang Li, Xuelong Li  
**Category**: cs.CL  
**Published**: 2026-01-01  
**Score**: 18.0  
**Type**: new  
**ArXiv ID**: 2512.24157v1  

#### Abstract
TeleChat3-MoE is the latest series of TeleChat large language models, featuring a Mixture-of-Experts (MoE) architecture with parameter counts ranging from 105 billion to over one trillion,trained end-to-end on Ascend NPU cluster. This technical report mainly presents the underlying training infrastr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Training Report of TeleChat3-MoE*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³**è¶…å¤§è§„æ¨¡ Mixture-of-Experts (MoE) æ¨¡å‹åœ¨ Ascend NPU é›†ç¾¤ä¸Šç«¯åˆ°ç«¯è®­ç»ƒä¸­çš„å¯æ‰©å±•æ€§ã€æ•°å€¼ç¨³å®šæ€§ä¸ç³»ç»Ÿæ•ˆç‡ç“¶é¢ˆ**ã€‚å…·ä½“æŒ‘æˆ˜åŒ…æ‹¬ï¼š
- è·¨ç¡¬ä»¶å¹³å°å’Œå¹¶è¡Œç­–ç•¥ä¸‹çš„**æ•°å€¼ç²¾åº¦ä¸ä¸€è‡´**ï¼›
- å¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒä¸­é€šä¿¡å¼€é”€é«˜ã€è®¡ç®—åˆ©ç”¨ç‡ä½ï¼›
- å¹¶è¡ŒåŒ–é…ç½®ä¾èµ–ä¸“å®¶æ‰‹åŠ¨è°ƒä¼˜ï¼Œè€—æ—¶ä¸”éš¾ä»¥å¤ç°ï¼›
- é›†ç¾¤çº§æ€§èƒ½å—ä¸»æœºï¼ˆhostï¼‰ä¸è®¾å¤‡ï¼ˆdeviceï¼‰å±‚é¢ç“¶é¢ˆåˆ¶çº¦ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

#### ï¼ˆ1ï¼‰ç³»ç»ŸåŒ–çš„**ç²¾åº¦éªŒè¯ä½“ç³»**
- **Operator-level éªŒè¯**ï¼šæ„å»ºåŸºäº CPU çš„â€œé»„é‡‘åŸºå‡†â€ï¼ˆgolden baselineï¼‰ï¼Œç»“åˆè¾“å…¥ç±»å‹å’Œç´¯åŠ æ¬¡æ•°åŠ¨æ€è®¾å®šè¯¯å·®å®¹å¿é˜ˆå€¼ï¼ˆè§ Table 2ï¼‰ï¼Œæœ‰æ•ˆå®šä½ç®—å­çº§ç²¾åº¦åå·®ã€‚
- **End-to-End å¯¹é½æµç¨‹**ï¼šæå‡ºè·¨ç¡¬ä»¶è¿ç§»å’Œè·¨å¹¶è¡Œç­–ç•¥çš„ä¸¤é˜¶æ®µéªŒè¯æ¡†æ¶ï¼ˆå›¾1ï¼‰ï¼Œé€šè¿‡é€æ­¥æ”¾ç¼©ï¼ˆprogressive scalingï¼‰å’Œä¸­é—´å¼ é‡è½¬å‚¨å®ç°æ ¹å› å®šä½ã€‚

#### ï¼ˆ2ï¼‰è®­ç»ƒæ¡†æ¶æ€§èƒ½ä¼˜åŒ–
- **Interleaved Pipeline Scheduling + 1F1B é‡å **ï¼šé‡‡ç”¨éè¿ç»­å±‚äº¤é”™åˆ†é… + å•å‰å‘å•åå‘è°ƒåº¦ï¼Œæ˜¾è‘—å‡å°‘ pipeline bubbleï¼Œæå‡ååçº¦ **10%**ã€‚
- **Attention-Aware æ•°æ®è°ƒåº¦**ï¼šé’ˆå¯¹é•¿åºåˆ—ç¨€ç–æ³¨æ„åŠ›ä»»åŠ¡ï¼ŒæŒ‰æ–‡æ¡£é•¿åº¦é‡æ–°ç»„ç»‡ micro-batch å†…æ ·æœ¬ï¼Œå¹³è¡¡å„è®¾å¤‡è´Ÿè½½ï¼Œç¼“è§£åŒæ­¥ç­‰å¾…ã€‚
- **åˆ†å±‚ä¸“å®¶é€šä¿¡ï¼ˆHierarchical EP Communicationï¼‰**ï¼šå°†å…¨å±€ All-to-All æ›¿æ¢ä¸ºä¸‰æ­¥æ‹“æ‰‘æ„ŸçŸ¥é€šä¿¡ï¼ˆAllGather â†’ å±€éƒ¨è¿‡æ»¤ â†’ All-to-Allï¼‰ï¼Œé™ä½è·¨èŠ‚ç‚¹æµé‡ï¼Œåœ¨ EP=16 ä¸‹æå‡è®­ç»ƒåå **~15%**ã€‚
- **EP é€šä¿¡é‡å æŠ€æœ¯**ï¼šåˆ©ç”¨å¤šç»´æ•°æ®åˆ‡ç‰‡ä¸ç»†ç²’åº¦è°ƒåº¦ï¼Œå®ç° FFN è®¡ç®—ä¸ EP é€šä¿¡ã€ä»¥åŠä¸åŒé€šä¿¡æ“ä½œä¹‹é—´çš„å¹¶è¡Œï¼Œä½¿ EP é€šä¿¡æ—¶é—´å æ¯”ä» **30% é™è‡³ 5%**ã€‚
- **DVM-based è·¨ç±»ç®—å­èåˆ**ï¼šæ”¯æŒ Cube-classï¼ˆå¦‚ GroupedMatMulï¼‰ä¸ Vector-class ç®—å­èåˆï¼Œå‡å°‘å†…å­˜è®¿é—®ä¸ kernel å¯åŠ¨å¼€é”€ã€‚ä¾‹å¦‚ GroupedMatMul-Reshape-Cast èåˆåæ€§èƒ½æå‡ **85%**ã€‚

#### ï¼ˆ3ï¼‰ç³»ç»ŸåŒ–å¹¶è¡ŒåŒ–é…ç½®ç”Ÿæˆæ¡†æ¶
- ç»“åˆ**è§£æå»ºæ¨¡**ä¸**æ•´æ•°çº¿æ€§è§„åˆ’ï¼ˆILPï¼‰æ±‚è§£å™¨**ï¼Œè‡ªåŠ¨æœç´¢æœ€ä¼˜å¤šç»´å¹¶è¡Œç­–ç•¥ï¼ˆDP/TP/PP/VPP/EP/OPï¼‰ã€‚
- è‡ªåŠ¨ä¼˜åŒ– pipeline stage åˆ†é…ã€interleaving å’Œé‡è®¡ç®—èŒƒå›´ï¼Œåœ¨æ»¡è¶³æ˜¾å­˜çº¦æŸä¸‹æœ€å°åŒ– bubble ä¸é€šä¿¡å¼€é”€ã€‚
- å°†ä¼ ç»Ÿéœ€ **7å¤©** çš„äººå·¥è°ƒä¼˜ç¼©çŸ­è‡³ **0.5å¤©**ï¼ŒåŒæ—¶è¾¾åˆ°ç”šè‡³è¶…è¶Šä¸“å®¶è®¾è®¡æ€§èƒ½ï¼ˆè¡¨5ï¼‰ã€‚

#### ï¼ˆ4ï¼‰é›†ç¾¤çº§æ€§èƒ½ä¼˜åŒ–
- **Host-bound ä¼˜åŒ–**ï¼šé€šè¿‡ CPU äº²å’Œæ€§ç»‘å®šä¸å†…æ ¸éš”ç¦»åŸŸå‡å°‘ç›‘æ§è¿›ç¨‹å¹²æ‰°ï¼Œé™ä½æ€§èƒ½æ³¢åŠ¨è¾¾ **38%**ï¼Œå¹³å‡ååæå‡ **1â€“15%**ã€‚
- **Device-bound ä¼˜åŒ–**ï¼šè°ƒæ•´ NPU å›ºä»¶ä¸­â€œidle modeâ€è§¦å‘é˜ˆå€¼ï¼Œé˜²æ­¢çŸ­ç®—å­é¢‘ç¹å¯¼è‡´é™é¢‘ï¼Œå¸¦æ¥ **25â€“30%** ååæå‡ã€‚
- **IOMMU é…ç½®ä¼˜åŒ–**ï¼šåˆ‡æ¢ä¸º passthrough æ¨¡å¼å‡å°‘æŸ¥è¯¢å»¶è¿Ÿï¼Œé¢å¤–è·å¾— **3â€“5%** æ€§èƒ½å¢ç›Šã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **ç²¾åº¦æ§åˆ¶** | å…¨æµç¨‹å¯è¿½æº¯çš„ç²¾åº¦å¯¹é½æœºåˆ¶ï¼Œä¿éšœè·¨å¹³å°è®­ç»ƒä¸€è‡´æ€§ |
| **è®­ç»ƒæ•ˆç‡** | å¤šå±‚æ¬¡é€šä¿¡/è®¡ç®—é‡å  + ç®—å­èåˆï¼Œæ˜¾è‘—æå‡ MFUï¼ˆModel Flops Utilizationï¼‰ |
| **å·¥ç¨‹æ•ˆç‡** | è‡ªåŠ¨åŒ–å¹¶è¡Œç­–ç•¥ç”Ÿæˆå·¥å…·å¤§å¹…ç¼©çŸ­éƒ¨ç½²å‘¨æœŸï¼Œé™ä½äººåŠ›ä¾èµ– |
| **å¯æ‰©å±•æ€§** | æ”¯æŒä»ç™¾äº¿å‚æ•°æ¨¡å‹åˆ°ä¸‡äº¿å‚æ•°æ¨¡å‹çš„æ— ç¼æ‰©å±•ï¼ˆæœ€å¤§ä½¿ç”¨ 8192 devicesï¼‰ |
| **ç”Ÿæ€é€‚é…æ€§** | å®Œå…¨é€‚é…åä¸º Ascend NPU + MindSpore ç”Ÿæ€ï¼Œæ¨åŠ¨å›½äº§ç®—åŠ›é—­ç¯ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- è®ºæ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºé¢„è®­ç»ƒæ•°æ®é›†çš„å…·ä½“æ„æˆï¼Œä½†æŒ‡å‡ºç”¨äº **TeleChat3-MoE ç³»åˆ—æ¨¡å‹çš„é¢„è®­ç»ƒä»»åŠ¡**ï¼ŒåŒ…å«é•¿è¾¾ **32Kâ€“128K tokens** çš„ä¸Šä¸‹æ–‡åºåˆ—ã€‚
- å¼ºè°ƒä½¿ç”¨äº†åŒ…å«å¤šä¸ªçŸ­æ–‡æ¡£æ‹¼æ¥è€Œæˆçš„é•¿æ–‡æœ¬ï¼Œå¹¶åº”ç”¨ EoDï¼ˆEnd-of-Documentï¼‰mask æ¥é¿å…è·¨æ–‡æ¡£æ³¨æ„åŠ›ã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼šåä¸º Ascend 910B NPU é›†ç¾¤ï¼Œæœ€å¤šä½¿ç”¨ **8192 devices**ã€‚
- **è½¯ä»¶æ¡†æ¶**ï¼šMindSporeã€‚
- **æ¨¡å‹è§„æ¨¡**ï¼š
  - 105B å‚æ•°ï¼ˆ45å±‚ï¼‰
  - 438B å‚æ•°ï¼ˆ54å±‚ï¼‰
  - 1119Bï¼ˆå³ ~1.1Tï¼‰å‚æ•°ï¼ˆ61å±‚ï¼‰
- **å¹¶è¡Œç»´åº¦ç»„åˆ**ï¼šæ¶µç›– DPã€TPã€PPã€SPã€EPã€OP åŠå…¶æ··åˆç­–ç•¥ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Step time (ms)**ï¼šæ¯è®­ç»ƒæ­¥è€—æ—¶ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
  - **Throughput improvement (%)**ï¼šç›¸å¯¹äºåŸºçº¿çš„ååæå‡
  - **Model Flops Utilization (MFU)**
  - **Scaling efficiency**ï¼šè¿‘ä¼¼çº¿æ€§æ‰©å±•èƒ½åŠ›
  - **Memory usage & bubble ratio**

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Pipeline Scheduling**ï¼švs. GPipeã€DAPPLE
- **EP Communication**ï¼švs. å…¨å±€ All-to-All
- **Parallelism Tuning**ï¼švs. ä¸“å®¶æ‰‹åŠ¨è°ƒä¼˜ï¼ˆexpert manual tuningï¼‰
- **Operator Execution**ï¼švs. æœªèåˆç‰ˆæœ¬ï¼ˆnaive kernel-by-kernelï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| ä¼˜åŒ–é¡¹ | æ€§èƒ½æå‡ |
|--------|----------|
| Interleaved Pipeline + 1F1B | **~10%** ç«¯åˆ°ç«¯æ€§èƒ½æå‡ |
| Hierarchical EP Communication | **~15%** ååæå‡ï¼ˆEP=16ï¼‰ |
| EP Communication Overlapping | EP é€šä¿¡æ—¶é—´å æ¯”ä» **30% â†’ 5%** |
| DVM-based Operator Fusion | GroupedMatMul-Reshape-Cast èåˆæé€Ÿ **85%** |
| Cluster-level Host Isolation | ååæå‡ **1â€“15%**ï¼Œæ–¹å·®ä¸‹é™ **38%** |
| Firmware-level Idle Mode Fix | ååæå‡ **25â€“30%** |
| IOMMU Passthrough | é¢å¤– **3â€“5%** æå‡ |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœï¼ˆè¡¨5ï¼‰
| ç­–ç•¥ | è®¾å¤‡æ•°é‡ | Step time (ms) |
|------|-----------|----------------|
| Expert-Designed-1 | 4,096 | 40,076 |
| Expert-Designed-2 | 4,096 | 40,147 |
| **Tool-Generated** | 4,096 | **39,969** âœ… |

> å·¥å…·ç”Ÿæˆç­–ç•¥ä¸ä»…æ›´å¿«å®Œæˆè°ƒä¼˜ï¼ˆ0.5å¤© vs 7å¤©ï¼‰ï¼Œè¿˜å®ç°äº†ç•¥ä¼˜äºäººå·¥è®¾è®¡çš„æœ€ä½³æ–¹æ¡ˆçš„ step timeã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆéšå«åˆ†æï¼‰
è™½ç„¶æ²¡æœ‰ç‹¬ç«‹è¡¨æ ¼å‘ˆç°æ¶ˆèå®éªŒï¼Œä½†åœ¨å„ç« èŠ‚ä¸­ä½“ç°äº†å…³é”®ç»„ä»¶çš„æœ‰æ•ˆæ€§ï¼š
- **å…³é—­ EP é€šä¿¡é‡å ** â†’ EP é€šä¿¡æˆä¸ºç“¶é¢ˆï¼Œé€šä¿¡æ—¶é—´å æ¯”é£™å‡ï¼›
- **ç¦ç”¨åˆ†å±‚é€šä¿¡** â†’ è·¨èŠ‚ç‚¹å¸¦å®½é¥±å’Œï¼Œæ‰©å±•æ€§ä¸‹é™ï¼›
- **ä¸è¿›è¡Œ operator fusion** â†’ å°ç®—å­ç¢ç‰‡åŒ–ä¸¥é‡ï¼ŒGPU åˆ©ç”¨ç‡ä½ä¸‹ï¼›
- **ä¸å¯ç”¨ attention-aware è°ƒåº¦** â†’ é•¿åºåˆ—è®­ç»ƒä¸­è®¾å¤‡è´Ÿè½½æä¸å¹³è¡¡ï¼Œéƒ¨åˆ†è®¾å¤‡ç©ºç­‰ï¼›
- **ä¸ä½¿ç”¨ ILP ä¼˜åŒ– pipeline** â†’ bubble æ›´å¤§ï¼Œèµ„æºåˆ©ç”¨ç‡æ›´ä½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç³»ç»Ÿçº§ååŒè®¾è®¡æ˜¯è¶…å¤§è§„æ¨¡ MoE æˆåŠŸè®­ç»ƒçš„å…³é”®**ï¼šä»…é å•ä¸€ä¼˜åŒ–æ— æ³•çªç ´ç“¶é¢ˆï¼Œå¿…é¡»ä»ç®—å­ç²¾åº¦ã€æ¡†æ¶è°ƒåº¦ã€å¹¶è¡Œç­–ç•¥åˆ°é›†ç¾¤å›ºä»¶è¿›è¡Œå…¨æ ˆååŒã€‚
2. **è‡ªåŠ¨åŒ–å¹¶è¡Œç­–ç•¥æœç´¢å¯è¡Œä¸”é«˜æ•ˆ**ï¼šé€šè¿‡åˆ†æå»ºæ¨¡ + ILP å¯æ›¿ä»£ç»éªŒé©±åŠ¨çš„æ‰‹å·¥è°ƒå‚ï¼Œå¤§å¹…æå‡å·¥ç¨‹æ•ˆç‡ä¸å¯å¤ç°æ€§ã€‚
3. **Ascend NPU å­˜åœ¨éšè—æ€§èƒ½é™·é˜±**ï¼šå¦‚â€œidle modeâ€è¯¯è§¦å‘ä¼šä¸¥é‡æ‹–æ…¢è®­ç»ƒï¼Œéœ€é€šè¿‡å›ºä»¶çº§å¹²é¢„ä¿®å¤ã€‚
4. **MoE æ¶æ„å¤©ç„¶é€‚åˆé«˜ç¨€ç–æ€§ + ä¸“å®¶å¹¶è¡Œ**ï¼šé…åˆ MLAã€æµ…è€Œå®½ç»“æ„å’Œ Top-k è·¯ç”±ï¼Œå¯åœ¨ä½æ¿€æ´»æ¯”ä¸‹å®ç°é«˜å¹¶å‘ä¸é«˜ MFUã€‚
5. **æ¥è¿‘çº¿æ€§æ‰©å±•æˆä¸ºç°å®**ï¼šåœ¨æ•°åƒ Ascend NPU ä¸Šå®ç°äº†è‰¯å¥½çš„æ‰©å±•æ•ˆç‡ï¼Œæ”¯æ’‘ä¸‡äº¿å‚æ•°æ¨¡å‹ç«¯åˆ°ç«¯è®­ç»ƒã€‚

### æ–¹æ³•çš„å±€é™æ€§
- æ‰€æœ‰ä¼˜åŒ–é«˜åº¦ä¾èµ– **Ascend NPU + MindSpore ç”Ÿæ€**ï¼Œè¿ç§»åˆ°å…¶ä»–ç¡¬ä»¶ï¼ˆå¦‚ GPUï¼‰å¯èƒ½éœ€è¦é‡æ„ã€‚
- è‡ªåŠ¨åŒ–å¹¶è¡Œå·¥å…·ç›®å‰ä¸»è¦é¢å‘å›ºå®šæ¨¡å‹ç»“æ„ï¼Œå¯¹åŠ¨æ€æ¶æ„é€‚åº”æ€§æœ‰å¾…éªŒè¯ã€‚
- ç¼ºä¹è¯¦ç»†çš„ MFU æ•°å€¼æŠ¥å‘Šï¼ˆè™½æåŠâ€œhigh MFUâ€ï¼Œä½†æ— å…·ä½“ç™¾åˆ†æ¯”ï¼‰ã€‚
- æœªæä¾›ä¸‹æ¸¸ä»»åŠ¡å¾®è°ƒæˆ–æ¨ç†æ€§èƒ½è¯„ä¼°ï¼Œèšç„¦äºè®­ç»ƒåŸºç¡€è®¾æ–½æœ¬èº«ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- è¿›ä¸€æ­¥æ‰©å¤§è‡ªåŠ¨åŒ–å·¥å…·è¦†ç›–èŒƒå›´ï¼Œæ”¯æŒæ›´å¤šå¹¶è¡ŒèŒƒå¼ä¸å¼‚æ„é›†ç¾¤ã€‚
- æ¢ç´¢æ›´æ™ºèƒ½çš„ runtime åŠ¨æ€è°ƒåº¦æœºåˆ¶ï¼Œåº”å¯¹è®­ç»ƒè¿‡ç¨‹ä¸­çš„è´Ÿè½½æ¼‚ç§»ã€‚
- åŠ å¼ºå¯¹ MoE è·¯ç”±ç¨³å®šæ€§å’Œè´Ÿè½½å‡è¡¡çš„åœ¨çº¿ç›‘æ§ä¸è°ƒæ§ã€‚
- å¼€æ”¾æ›´å¤šæ¨¡å‹ä¸è®­ç»ƒä»£ç ï¼Œä¿ƒè¿›ç¤¾åŒºå…±å»ºé«˜æ€§èƒ½å›½äº§ LLM ç”Ÿæ€ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> *TeleChat3-MoE çš„è®­ç»ƒæŠ¥å‘Šå±•ç¤ºäº†ä¸­å›½åœ¨è¶…å¤§è§„æ¨¡ MoE æ¨¡å‹å…¨æ ˆè®­ç»ƒèƒ½åŠ›ä¸Šçš„é‡å¤§è¿›å±•â€”â€”é€šè¿‡ç³»ç»Ÿæ€§çš„ç²¾åº¦æ§åˆ¶ã€é«˜æ•ˆçš„é€šä¿¡ä¸è®¡ç®—ä¼˜åŒ–ã€è‡ªåŠ¨åŒ–çš„å¹¶è¡Œç­–ç•¥ç”Ÿæˆä»¥åŠæ·±åº¦çš„ç¡¬ä»¶ååŒè®¾è®¡ï¼ŒæˆåŠŸå®ç°äº†åƒäº¿è‡³ä¸‡äº¿å‚æ•°æ¨¡å‹åœ¨å›½äº§ Ascend é›†ç¾¤ä¸Šçš„é«˜æ•ˆã€ç¨³å®šã€å¯æ‰©å±•è®­ç»ƒã€‚*

</details>

---

### 2. [MS-SSM: A Multi-Scale State Space Model for Efficient Sequence Modeling](https://arxiv.org/abs/2512.23824)

**Authors**: Mahdi Karami, Ali Behrouz, Peilin Zhong, Razvan Pascanu, Vahab Mirrokni  
**Category**: cs.LG  
**Published**: 2026-01-01  
**Score**: 14.5  
**Type**: new  
**ArXiv ID**: 2512.23824v1  

#### Abstract
State-space models (SSMs) have recently attention as an efficient alternative to computationally expensive attention-based models for sequence modeling. They rely on linear recurrences to integrate information over time, enabling fast inference, parallelizable training, and control over recurrence s...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMS-SSM: A Multi-Scale State Space Model for Efficient Sequence Modeling

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿ **State Space Models (SSMs)** åœ¨åºåˆ—å»ºæ¨¡ä¸­è™½ç„¶å…·å¤‡é«˜æ•ˆçš„è®­ç»ƒå’Œæ¨ç†èƒ½åŠ›ï¼ˆçº¿æ€§å¤æ‚åº¦ï¼‰ï¼Œä½†ä»å­˜åœ¨ä¸¤ä¸ªå…³é”®é™åˆ¶ï¼š
- **æœ‰é™çš„æœ‰æ•ˆè®°å¿†ï¼ˆlimited effective memoryï¼‰**ï¼šç”±äºå…¶çº¿æ€§é€’å½’ç‰¹æ€§ï¼Œä¿¡æ¯è¡°å‡è¾ƒå¿«ï¼Œéš¾ä»¥æ•æ‰é•¿è·ç¦»ä¾èµ–ï¼Œé€šå¸¸éœ€è¦å¢å¤§çŠ¶æ€ç»´åº¦æ¥è¡¥å¿ã€‚
- **ç¼ºä¹å¤šå°ºåº¦å»ºæ¨¡èƒ½åŠ›ï¼ˆmulti-scale dependency modelingï¼‰**ï¼šç°å®ä¸–ç•Œä¿¡å·ï¼ˆå¦‚å›¾åƒã€è¯­éŸ³ã€æ–‡æœ¬ï¼‰å…·æœ‰å¤šå±‚æ¬¡ç»“æ„ï¼ˆä»å±€éƒ¨ç»†èŠ‚åˆ°å…¨å±€è¶‹åŠ¿ï¼‰ï¼Œè€Œæ ‡å‡† SSMs éš¾ä»¥åŒæ—¶æ•è·ä¸åŒæ—¶é—´å°ºåº¦ä¸Šçš„æ¨¡å¼ã€‚

æ­¤å¤–ï¼Œå°½ç®¡å·²æœ‰éƒ¨åˆ†å·¥ä½œå°è¯•å¼•å…¥å¤šåˆ†è¾¨ç‡åˆ†æï¼ˆå¦‚ MULTIRESNETï¼‰ï¼Œä½†å®ƒä»¬å¾€å¾€ç»“åˆçš„æ˜¯çŸ­å·ç§¯æˆ–éå› æœå˜æ¢ï¼ˆå¦‚ FFTï¼‰ï¼Œå¯¼è‡´æ„Ÿå—é‡å—é™æˆ–æ— æ³•ç”¨äºè‡ªå›å½’ä»»åŠ¡ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šMS-SSM
æœ¬æ–‡æå‡º **MS-SSMï¼ˆMulti-Scale State Space Modelï¼‰**ï¼Œä¸€ç§å°†**å¤šå°ºåº¦åˆ†è§£**ä¸**çŠ¶æ€ç©ºé—´æ¨¡å‹**æ·±åº¦èåˆçš„æ–°å‹æ¶æ„ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å°†è¾“å…¥åºåˆ—é€šè¿‡ **Stationary Wavelet Transform (SWT)** æˆ–ç­‰æ•ˆçš„å¯å­¦ä¹ å¤šå°ºåº¦å·ç§¯è¿›è¡Œåˆ†è§£ï¼Œå¾—åˆ°å¤šä¸ªä¸åŒåˆ†è¾¨ç‡çš„å­åºåˆ—ï¼ˆåŒ…æ‹¬ç»†èŠ‚ç³»æ•°å’Œè¿‘ä¼¼ç³»æ•°ï¼‰ã€‚
- å¯¹æ¯ä¸ªå°ºåº¦ç‹¬ç«‹åº”ç”¨ä¸€ä¸ªä¸“ç”¨çš„ **SSM block**ï¼ˆå¯ä»¥æ˜¯ S4 æˆ– S6ï¼‰ï¼Œä»¥æ•æ‰è¯¥å°ºåº¦ä¸‹çš„é•¿æœŸåŠ¨æ€ã€‚
- å¼•å…¥ **input-dependent scale-mixer** æ¨¡å—ï¼ŒåŠ¨æ€èåˆå„å°ºåº¦è¾“å‡ºï¼Œå®ç°è·¨å°ºåº¦çš„ä¿¡æ¯äº¤äº’ã€‚

#### åˆ›æ–°ç‚¹æ€»ç»“ï¼š
| åˆ›æ–°ç‚¹ | æè¿° |
|--------|------|
| **å¤šå°ºåº¦ SSM æ¶æ„** | é¦–æ¬¡ç³»ç»Ÿåœ°å°† MRAï¼ˆMulti-Resolution Analysisï¼‰é›†æˆè¿› SSM æ¡†æ¶ï¼Œä½¿ SSM èƒ½åœ¨å¤šä¸ªæ—¶é—´å°ºåº¦ä¸Šå¹¶è¡Œå»ºæ¨¡ã€‚ |
| **å¯å­¦ä¹ çš„å¤šå°ºåº¦å·ç§¯å±‚** | ä½¿ç”¨å¸¦è†¨èƒ€ç‡çš„ `Conv1D` å®ç°ç±»ä¼¼ SWT çš„åˆ†è§£ï¼Œå¹¶å…è®¸æ»¤æ³¢å™¨æƒé‡å¯è®­ç»ƒï¼Œæå‡çµæ´»æ€§ã€‚ |
| **å°ºåº¦æ„ŸçŸ¥çš„çŠ¶æ€åˆå§‹åŒ–** | ä¸åŒå°ºåº¦çš„ SSM ä½¿ç”¨ä¸åŒçš„ `diag(A)` åˆå§‹åŒ–ç­–ç•¥ï¼šä½é¢‘ï¼ˆç²—ç²’åº¦ï¼‰é è¿‘å•ä½åœ†ä»¥å¢å¼ºé•¿æœŸè®°å¿†ï¼›é«˜é¢‘ï¼ˆç»†ç²’åº¦ï¼‰è¿œç¦»å•ä½åœ†ä»¥å…³æ³¨å±€éƒ¨å˜åŒ–ã€‚ |
| **è¾“å…¥ä¾èµ–çš„å°ºåº¦æ··åˆå™¨ï¼ˆscale-mixerï¼‰** | åŠ¨æ€è°ƒæ•´å„å°ºåº¦è´¡çŒ®æƒé‡ï¼Œå…¬å¼ä¸º $ z_t = E_{f}(x_t) \cdot y_t $ï¼Œå…¶ä¸­ $ E_f = \text{Linear}(x_t) $ï¼Œå®ç°ä¸Šä¸‹æ–‡æ„ŸçŸ¥èåˆã€‚ |

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³•ç±»åˆ« | å±€é™æ€§ | MS-SSM çš„ä¼˜åŠ¿ |
|---------|-------|----------------|
| **Transformer** | æ³¨æ„åŠ›æœºåˆ¶ä¸º $ O(L^2) $ï¼Œè®¡ç®—æ˜‚è´µ | ä¿æŒ SSM çš„çº¿æ€§æ¨ç†æ•ˆç‡ï¼Œé€‚åˆé•¿åºåˆ— |
| **æ ‡å‡† SSMs (S4, Mamba)** | å•ä¸€å°ºåº¦å»ºæ¨¡ï¼Œéš¾ä»¥å¤„ç†å±‚æ¬¡ç»“æ„ | æ˜¾å¼å»ºæ¨¡å¤šå°ºåº¦ä¾èµ–ï¼Œæ˜¾è‘—æå‡é•¿ç¨‹å’Œåˆ†å±‚ä»»åŠ¡è¡¨ç° |
| **MULTIRESNET (Shi et al., 2023)** | ä½¿ç”¨å›ºå®šå°å·ç§¯æ ¸ï¼Œæœ‰æ•ˆæ„Ÿå—é‡æœ‰é™ | ç»“åˆ SSM æä¾›æ— é™æ„Ÿå—é‡ï¼Œèƒ½å»ºæ¨¡æ›´è¿œè·ç¦»ä¾èµ– |
| **FNet / Prism** | åŸºäº FFTï¼Œéå› æœä¸”æ—¶åŸŸå®šä½å·® | ä½¿ç”¨å› æœå·ç§¯ + SSMï¼Œæ”¯æŒè‡ªå›å½’ç”Ÿæˆ |
| **Clockwork RNN** | æ‰‹åŠ¨åˆ’åˆ†é¢‘ç‡é€šé“ï¼Œä¸å¤Ÿçµæ´» | è‡ªåŠ¨å­¦ä¹ å¤šå°ºåº¦è¡¨ç¤ºï¼Œæ›´å…·è¡¨è¾¾åŠ› |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | ç±»å‹ | åºåˆ—é•¿åº¦ | ä»»åŠ¡ |
|--------|------|----------|------|
| **sCIFAR-10** | å›¾åƒ â†’ åƒç´ åºåˆ— | 1024 | å›¾åƒåˆ†ç±» |
| **ImageNet-1K** | å›¾åƒ â†’ patch åºåˆ— | ~200 | å›¾åƒåˆ†ç±» |
| **ListOps** | åˆæˆè¯­è¨€æ¨ç† | 2048 | åˆ†å±‚ç»“æ„ç†è§£ |
| **Long Range Arena (LRA)** | å¤šé¢†åŸŸé•¿åºåˆ—åŸºå‡† | 1000â€“4000 | é•¿ç¨‹ä¾èµ–å»ºæ¨¡ |
| **PTB-XL** | å¿ƒç”µå›¾ï¼ˆECGï¼‰ | 1000 | æ—¶é—´åºåˆ—å¤šæ ‡ç­¾åˆ†ç±» |

---

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„åŸºç¡€**ï¼šåŸºäº ViT æˆ–çº¯åºåˆ— Transformer-like blockï¼Œç”¨ MS-SSM æ›¿æ¢åŸæ³¨æ„åŠ›æ¨¡å—ã€‚
- **SSM ç±»å‹**ï¼šæµ‹è¯•ä¸¤ç§å˜ä½“ â€”â€” `MS-SSM(S4)` å’Œ `MS-SSM(S6)`ï¼Œåˆ†åˆ«ä»£è¡¨æ•°æ®æ— å…³ä¸æ•°æ®ç›¸å…³çš„ SSMã€‚
- **å¤šå°ºåº¦å‚æ•°**ï¼šé»˜è®¤ä½¿ç”¨ $ S=3 $ ä¸ªåˆ†è§£å±‚çº§ï¼Œæ¯å±‚ SSM çŠ¶æ€å¤§å° $ N=128 $ã€‚
- **ä¼˜åŒ–å™¨**ï¼šAdam / AdamWï¼Œå­¦ä¹ ç‡ 0.003â€“0.0045ï¼Œwarmup 1â€“10 epochï¼Œcosine decayã€‚
- **ç¡¬ä»¶**ï¼šA6000 GPUï¼Œbatch size æ ¹æ®ä»»åŠ¡è°ƒæ•´ï¼ˆ50â€“1024ï¼‰ã€‚

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| ä»»åŠ¡ | ä¸»è¦æŒ‡æ ‡ |
|------|----------|
| å›¾åƒåˆ†ç±» | Top-1 Accuracy |
| ListOps | Accuracy (%) |
| LRA å„å­ä»»åŠ¡ | Accuracy / AUROC |
| PTB-XL | AUROCï¼ˆå¹³å‡ across 6 å­é›†ï¼‰ |
| æ¨¡å‹åˆ†æ | Mean Mixing Distanceï¼ˆè¡¡é‡æœ‰æ•ˆæ„Ÿå—é‡ï¼‰ |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ¶µç›–ä»¥ä¸‹å‡ ç±»ä¸»æµæ¨¡å‹ï¼š
- **Transformers**ï¼šåŸå§‹ Transformerã€Linformerã€Performerã€BigBirdã€Longformer
- **RNNs**ï¼šLSTMã€r-LSTMã€UR-GRUã€HiPPO-RNN
- **SSMs**ï¼šS4ã€S4Dã€S5ã€Liquid-S4ã€Mambaã€Griffin
- **CNNs + SSMs**ï¼šCKConvã€MULTIRESNET
- **å…¶ä»–**ï¼šSpaceTimeï¼ˆä¸“ç”¨äºæ—¶é—´åºåˆ—ï¼‰ã€InceptionTime

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Tables 1â€“4ï¼‰

| æ¨¡å‹ | sCIFAR | ImageNet | ListOps | PTB-XL (AUROC) | LRA Avg |
|------|--------|----------|---------|---------------|---------|
| **Transformer** | 62.2 | 78.9 | 36.37 | 0.857 | 62.12 |
| **Mamba** | 90.1 | 80.5 | 38.02 | 0.915 | 72.30 |
| **MULTIRESNET** | 93.0 | 80.2 | 62.75 | 0.938 | â€“ |
| **S4** | 91.1 | 79.1 | 59.60 | 0.938 | 91.38 |
| **MS-SSM(S4)** | **93.3** | **81.3** | **62.83** | **0.939** | **91.89** |
| **MS-SSM(S6)** | â€“ | â€“ | **63.04** | **0.939** | 86.73 |

> æ³¨ï¼šMS-SSM(S6) åœ¨ LRA ä¸Šæ€§èƒ½ç•¥ä½äº S4 å˜ä½“ï¼Œå¯èƒ½å› é—¨æ§æœºåˆ¶ä¸å¤šå°ºåº¦èåˆä¹‹é—´å­˜åœ¨å¹²æ‰°ã€‚

---

### ğŸ” ä¸ Mamba çš„å¯¹æ¯”äº®ç‚¹
- åœ¨ **ListOps** ä¸Šï¼ŒMS-SSM å‡†ç¡®ç‡æ˜¯ Mamba çš„ **1.66 å€ä»¥ä¸Š**ï¼ˆ63.04 vs 38.02ï¼‰ã€‚
- åœ¨ **LRA å¹³å‡å¾—åˆ†**ä¸Šï¼ŒMS-SSM(S4) æ¯” Mamba æå‡ **19.59 pts**ï¼ˆ91.89 vs 72.30ï¼‰ï¼Œç›¸å¯¹æå‡çº¦ **27%**ã€‚
- å³ä½¿å¯¹æ¯” **åŒå€å‚æ•°é‡æˆ–åŒå€çŠ¶æ€å¤§å°çš„ Mamba**ï¼ŒMS-SSM ä»å…¨é¢èƒœå‡ºï¼Œè¯´æ˜å…¶å‚æ•°åˆ©ç”¨æ›´é«˜æ•ˆã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆTable 5ï¼‰
éªŒè¯äº†å„ç»„ä»¶çš„é‡è¦æ€§ï¼š

| æ¶ˆèé…ç½® | PTB-XL (AUROC) | ListOps (Acc%) |
|---------|----------------|----------------|
| å®Œæ•´æ¨¡å‹ MS-SSM(S6) | **0.939** | **63.04** |
| ç§»é™¤ Multi-scale Conv | 0.916 | 37.98 âŒâ†“25pt |
| ç§»é™¤ SSM æ¨¡å— | 0.936 | 62.59 |
| ä½¿ç”¨ input-independent mixer | 0.932 | 61.28 |
| ä½¿ç”¨éçº¿æ€§ Softmax mixer | 0.921 | 61.42 |
| æ”¹ä¸º self-scale gating | 0.938 | 62.91 |

> âœ… **å…³é”®å‘ç°**ï¼š
> - **å¤šå°ºåº¦å·ç§¯æ˜¯æœ€å…³é”®ç»„ä»¶**ï¼Œç§»é™¤åæ€§èƒ½æš´è·Œã€‚
> - è¾“å…¥ä¾èµ–çš„ scale-mixer æ˜æ˜¾ä¼˜äºé™æ€çº¿æ€§èåˆã€‚
> - ä½¿ç”¨åŸå§‹è¾“å…¥ $ x_t $ æ§åˆ¶å„å°ºåº¦é—¨æ§æ¯”ä½¿ç”¨å°ºåº¦å†…è¡¨ç¤ºæ›´æœ‰æ•ˆã€‚

---

### ğŸ“ æœ‰æ•ˆæ„Ÿå—é‡åˆ†æï¼ˆMean Mixing Distanceï¼‰
- å®šä¹‰äº†ä¸€ä¸ªæ–°çš„æŒ‡æ ‡ **mean mixing distance** æ¥é‡åŒ–æ¨¡å‹å¯¹è¿œè·ç¦»ä¸Šä¸‹æ–‡çš„å…³æ³¨ç¨‹åº¦ï¼ˆç±»æ¯” Attention Distanceï¼‰ã€‚
- åœ¨ ListOps ä¸Šçš„ç»“æœï¼ˆTable 6ï¼‰æ˜¾ç¤ºï¼š
  - **Mamba**: 38.84 Â± 21.97
  - **MS-SSM(S6)**: **94.90 Â± 64.62** âœ æå‡è¶…è¿‡ **2.4 å€**

> è¡¨æ˜ MS-SSM å…·æœ‰æ›´å¼ºçš„é•¿è·ç¦»å»ºæ¨¡èƒ½åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **å¤šå°ºåº¦å»ºæ¨¡æ˜¾è‘—æå‡ SSM æ€§èƒ½**ï¼šé€šè¿‡å°†åºåˆ—åˆ†è§£ä¸ºå¤šä¸ªåˆ†è¾¨ç‡å¹¶åœ¨æ¯ä¸ªå°ºåº¦ä¸Šéƒ¨ç½²ä¸“ç”¨ SSMï¼ŒMS-SSM æˆåŠŸè§£å†³äº†ä¼ ç»Ÿ SSM ç¼ºä¹å±‚æ¬¡æ„ŸçŸ¥çš„é—®é¢˜ã€‚
2. **MS-SSM åœ¨é•¿ç¨‹ä¸åˆ†å±‚ä»»åŠ¡ä¸­è¡¨ç°å“è¶Š**ï¼šåœ¨ ListOps å’Œ LRA ä¸Šå¤§å¹…è¶…è¶Š Mamba ç­‰å…ˆè¿› SSM æ¨¡å‹ï¼Œè¯æ˜å…¶åœ¨å¤æ‚ç»“æ„å»ºæ¨¡æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚
3. **æ— éœ€å¢åŠ å‚æ•°å³å¯è·å¾—æ€§èƒ½é£è·ƒ**ï¼šç›¸æ¯”æ‰©å¤§çŠ¶æ€å¤§å°æˆ–å †å æ›´å¤šå±‚ï¼Œå¤šå°ºåº¦è®¾è®¡æä¾›äº†æ›´é«˜æ€§ä»·æ¯”çš„è®°å¿†æ‰©å±•æ–¹å¼ã€‚
4. **scale-mixer çš„è®¾è®¡è‡³å…³é‡è¦**ï¼šè¾“å…¥ä¾èµ–çš„åŠ¨æ€èåˆæœºåˆ¶èƒ½æ›´å¥½åœ°åè°ƒä¸åŒå°ºåº¦é—´çš„è¯­ä¹‰ä¿¡æ¯æµåŠ¨ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä»…åœ¨ 1D åºåˆ—ä¸ŠéªŒè¯ï¼Œæœªç›´æ¥åº”ç”¨äºè‡ªç„¶è¯­è¨€ä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚ LMã€MTï¼‰ã€‚
- å¤šå°ºåº¦åˆ†è§£å¸¦æ¥é¢å¤–è®¡ç®—å¼€é”€ï¼ˆ$ O(LKS) $ï¼‰ï¼Œè™½æ€»ä½“å¯æ§ï¼Œä½†åœ¨æä½å»¶è¿Ÿåœºæ™¯ä¸‹éœ€æƒè¡¡ã€‚
- SWT çš„å†—ä½™è¡¨ç¤ºå¢åŠ äº†å†…å­˜å ç”¨ï¼Œæœªæ¥å¯æ¢ç´¢æ›´ç´§å‡‘çš„å¯å­¦ä¹ åˆ†è§£æ–¹å¼ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‹“å±•è‡³ NLP ä¸‹æ¸¸ä»»åŠ¡**ï¼šåœ¨è¯­è¨€å»ºæ¨¡ã€æœºå™¨ç¿»è¯‘ä¸­éªŒè¯ MS-SSM æ˜¯å¦èƒ½æ›´å¥½å¯¹é½äººç±»å¤§è„‘çš„é¢„æµ‹ç¼–ç æœºåˆ¶ï¼ˆå¦‚ Caucheteux et al., 2023 æ‰€ç¤ºï¼‰ã€‚
2. **ç»“åˆæœ€æ–° SSM å˜ä½“**ï¼šå°† MS-SSM ä¸ xLSTMã€LRUã€HGRN2 ç­‰æ–°å‹çº¿æ€§ RNN ç»“åˆï¼Œè¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚
3. **æ¢ç´¢éçº¿æ€§æµ‹è¯•æ—¶è®­ç»ƒï¼ˆnonlinear test-time trainingï¼‰ä¸­çš„è®°å¿†å¢å¼ºæœºåˆ¶**ã€‚
4. **æ¨å¹¿åˆ°è§†é¢‘ã€å›¾ç»“æ„ç­‰é«˜ç»´æ•°æ®**ï¼šåˆ©ç”¨å¤šå°ºåº¦æ€æƒ³æ„å»º 2D æˆ–å›¾ä¸Šçš„ state space æ¨¡å‹ï¼ˆå¦‚ Chimeraã€Graph Mambaï¼‰ã€‚

---

## æ€»ç»“
**MS-SSM æ˜¯ä¸€é¡¹å°†å¤šåˆ†è¾¨ç‡åˆ†æä¸ state space modeling æˆåŠŸèåˆçš„é‡è¦è¿›å±•**ã€‚å®ƒä¸ä»…æå‡äº† SSM åœ¨é•¿åºåˆ—å’Œåˆ†å±‚ä»»åŠ¡ä¸­çš„å»ºæ¨¡èƒ½åŠ›ï¼Œè¿˜ä¿æŒäº†å…¶åŸæœ‰çš„é«˜æ•ˆç‰¹æ€§ã€‚å®éªŒè¯æ˜ï¼Œ**â€œå¤šå°ºåº¦â€æ˜¯ä¸€ç§æ¯”â€œåŠ å¤§çŠ¶æ€â€æ›´æœ‰æ•ˆçš„è®°å¿†å¢å¼ºè·¯å¾„**ï¼Œä¸ºä¸‹ä¸€ä»£é«˜æ•ˆåºåˆ—æ¨¡å‹çš„è®¾è®¡æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 3. [Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization](https://arxiv.org/abs/2512.24615)

**Authors**: Yuchen Shi, Yuzheng Cai, Siqi Cai, Zihan Xu, Lichao Chen, Yulei Qin, Zhijian Zhou, Xiang Fei, Chaofan Qiu, Xiaoyu Tan, Gang Li, Zongyi Li, Haojia Lin, Guocan Cai, Yong Mao, Yunsheng Wu, Ke Li, Xing Sun  
**Category**: cs.AI  
**Published**: 2026-01-01  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2512.24615v1  

#### Abstract
Existing Large Language Model (LLM) agent frameworks face two significant challenges: high configuration costs and static capabilities. Building a high-quality agent often requires extensive manual effort in tool integration and prompt engineering, while deployed agents struggle to adapt to dynamic ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šYoutu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰åŸºäº **Large Language Model (LLM)** çš„æ™ºèƒ½ä½“ï¼ˆAgentï¼‰æ¡†æ¶é¢ä¸´ä¸¤å¤§ç“¶é¢ˆï¼š
- **é«˜é…ç½®æˆæœ¬**ï¼šæ„å»ºé«˜è´¨é‡ Agent éœ€è¦å¤§é‡æ‰‹åŠ¨å·¥ä½œï¼Œå¦‚å·¥å…·é›†æˆã€Prompt å·¥ç¨‹ç­‰ï¼Œå¼€å‘é—¨æ§›é«˜ä¸”éš¾ä»¥è§„æ¨¡åŒ–ã€‚
- **é™æ€èƒ½åŠ›é™åˆ¶**ï¼šéƒ¨ç½²åçš„ Agent éš¾ä»¥é€‚åº”åŠ¨æ€ç¯å¢ƒï¼Œæå‡æ€§èƒ½é€šå¸¸ä¾èµ–æ˜‚è´µçš„å¾®è°ƒï¼ˆSFT æˆ– RLï¼‰ï¼Œå­˜åœ¨æ•°æ®ç¨€ç¼ºã€è®­ç»ƒä¸ç¨³å®šç­‰é—®é¢˜ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **Youtu-Agent**ï¼Œä¸€ä¸ªæ¨¡å—åŒ–ã€å¯è‡ªåŠ¨æ„å»ºå¹¶æŒç»­è¿›åŒ–çš„ LLM Agent æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰æ¨¡å—åŒ–æ¶æ„ä¸ç»“æ„åŒ–é…ç½®ç³»ç»Ÿ
- é‡‡ç”¨ä¸‰å±‚åˆ†å±‚è®¾è®¡ï¼š**Environment Layer**ï¼ˆæ‰§è¡Œç¯å¢ƒï¼‰ã€**Tools Layer**ï¼ˆå·¥å…·é›†ï¼‰ã€**Agent Layer**ï¼ˆè§„åˆ’ä¸æ‰§è¡Œï¼‰ã€‚
- æ‰€æœ‰ç»„ä»¶é€šè¿‡ **YAML é…ç½®æ–‡ä»¶**å£°æ˜ï¼Œå®ç°è§£è€¦ä¸å¤ç”¨ï¼Œä¸ºè‡ªåŠ¨åŒ–ç”Ÿæˆå¥ å®šåŸºç¡€ã€‚

#### ï¼ˆ2ï¼‰åŒèŒƒå¼è‡ªåŠ¨åŒ–ç”Ÿæˆæœºåˆ¶
- **Workflow Mode**ï¼šç¡®å®šæ€§å››é˜¶æ®µæµæ°´çº¿ï¼ˆæ„å›¾åˆ†è§£ â†’ å·¥å…·æ£€ç´¢/åˆæˆ â†’ Prompt ç”Ÿæˆ â†’ é…ç½®ç»„è£…ï¼‰ï¼Œé€‚ç”¨äºæ ‡å‡†åŒ–ä»»åŠ¡ã€‚
- **Meta-Agent Mode**ï¼šç”±é«˜å±‚â€œæ¶æ„å¸ˆ Agentâ€åŠ¨æ€è°ƒç”¨ `search_tool`ã€`create_tool`ã€`ask_user`ã€`create_agent_config` ç­‰èƒ½åŠ›ï¼Œå¤„ç†å¤æ‚æˆ–æ¨¡ç³Šéœ€æ±‚ï¼Œæ”¯æŒå¤šè½®äº¤äº’æ¾„æ¸…ã€‚

#### ï¼ˆ3ï¼‰æ··åˆç­–ç•¥ä¼˜åŒ–ä½“ç³»ï¼ˆHybrid Policy Optimizationï¼‰
- **Agent Practice æ¨¡å—**ï¼šåŸºäº **Training-free GRPO** çš„ä¸Šä¸‹æ–‡ç»éªŒç§¯ç´¯æœºåˆ¶ï¼Œåœ¨ä¸æ›´æ–°å‚æ•°çš„å‰æä¸‹ï¼Œåˆ©ç”¨å°æ ·æœ¬è¿›è¡Œæ¨ç†æ—¶è‡ªæˆ‘æ”¹è¿›ï¼Œç±»ä¼¼â€œæ–‡æœ¬å‹ LoRAâ€æ³¨å…¥ã€‚
- **Agent RL æ¨¡å—**ï¼šç«¯åˆ°ç«¯å¼ºåŒ–å­¦ä¹ è®­ç»ƒç®¡é“ï¼Œé›†æˆåˆ†å¸ƒå¼ RL æ¡†æ¶ï¼ˆå¦‚ VeRLï¼‰ï¼Œè§£å†³é•¿å‘¨æœŸä»»åŠ¡ä¸­çš„â€œç†µçˆ†ç‚¸â€é—®é¢˜ï¼Œå¹¶å®ç°ç¨³å®šçš„å¤§è§„æ¨¡è®­ç»ƒã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | Youtu-Agent çš„ä¼˜åŠ¿ |
|------|------------------|
| **è‡ªåŠ¨åŒ–ç¨‹åº¦** | ä¸ä»…ç”Ÿæˆ Agent é…ç½®ï¼Œè¿˜èƒ½è‡ªåŠ¨ç”Ÿæˆ Python å·¥å…·ä»£ç å’Œ Promptï¼Œè¿œè¶…ä¼ ç»Ÿæ¡†æ¶çš„æ‰‹åŠ¨é…ç½®æ¨¡å¼ã€‚ |
| **çµæ´»æ€§ä¸é€šç”¨æ€§** | æ”¯æŒä»ç®€å•è„šæœ¬åˆ°å¤æ‚ç ”ç©¶åŠ©æ‰‹çš„å…¨èŒƒå›´ä»»åŠ¡å»ºæ¨¡ã€‚ |
| **ä½æˆæœ¬ä¼˜åŒ–** | Agent Practice æ”¯æŒé›¶æ¢¯åº¦æ›´æ–°çš„ç»éªŒå­¦ä¹ ï¼Œé€‚åˆ API æ¨¡å‹æˆ–èµ„æºå—é™åœºæ™¯ã€‚ |
| **å¯æ‰©å±•æ€§ä¸ç¨³å®šæ€§** | Agent RL æ¨¡å—é€šè¿‡ RESTful å°è£…ã€Ray å¹¶è¡Œã€åˆ†å±‚è¶…æ—¶æ§åˆ¶ç­‰æŠ€æœ¯ï¼Œå®ç° 128 GPU è§„æ¨¡ä¸‹çš„é«˜æ•ˆç¨³å®šè®­ç»ƒã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | æè¿° |
|-------|------|
| **WebWalkerQA** (680é¢˜) | å¤šæ­¥æ·±åº¦ç½‘é¡µå¯¼èˆªä¸é—®ç­”ä»»åŠ¡ï¼Œæµ‹è¯•çœŸå®ç½‘ç«™ä¸Šçš„æ¢ç´¢ä¸ç†è§£èƒ½åŠ›ã€‚ |
| **GAIA (text-only subset)** (466é¢˜) | å®é™…åº”ç”¨åœºæ™¯ä¸‹çš„ç»¼åˆé—®ç­”åŸºå‡†ï¼Œæ¶µç›–æ¨ç†ã€å·¥å…·ä½¿ç”¨ã€æ–‡æ¡£è§£æç­‰ï¼Œæœ¬æ–‡ä»…ç”¨æ–‡æœ¬å­é›†ã€‚ |
| **AIME 2024 / AIME 2025** | æ•°å­¦ç«èµ›é¢˜ï¼Œç”¨äºè¯„ä¼°æ•°å­¦æ¨ç†ä¸ç¼–ç è¾…åŠ©è§£é¢˜èƒ½åŠ›ã€‚ |
| **DAPO-Math-17K** | åŒ…å« 17,000 æ¡æ•°å­¦é—®é¢˜çš„å¼€æºæ•°æ®é›†ï¼Œç”¨äº Agent Practice å’Œ RL è®­ç»ƒã€‚ |
| **General/Multi-hop QA Benchmarks**ï¼š<br>TriviaQA, PopQA, NaturalQuestions,<br>MuSiQue, HotpotQA, Bamboogle, 2WikiMultiHop | æµ‹è¯•ä¿¡æ¯æ£€ç´¢ä¸å¤šè·³æ¨ç†èƒ½åŠ›ã€‚ |

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
| æ¨¡å— | è®¾ç½®è¯´æ˜ | ä¸»è¦æŒ‡æ ‡ |
|------|--------|---------|
| **Benchmark æ€§èƒ½** | å…¨éƒ¨åŸºäºå¼€æºæ¨¡å‹ï¼ˆDeepSeek-V3ã€Qwen2.5-7B ç­‰ï¼‰ï¼Œæ— é—­æº API è°ƒç”¨ï¼›é‡‡ç”¨ Plan-and-Execute èŒƒå¼ã€‚ | Pass@1 å‡†ç¡®ç‡ |
| **Automated Generation** | æ„é€ æ–°åŸºå‡† **AgentGen-80**ï¼ˆ80ä¸ªå¤šæ ·åŒ–ä»»åŠ¡æè¿°ï¼‰ï¼Œè¯„ä¼°ï¼š<br>- CVï¼ˆé…ç½®æœ‰æ•ˆæ€§ï¼‰<br>- TEï¼ˆå·¥å…·å¯æ‰§è¡Œæ€§ï¼‰<br>- TCï¼ˆä»»åŠ¡å®Œæˆç‡ï¼‰ | CV / TE / TC ç™¾åˆ†æ¯” |
| **Agent Practice** | åœ¨ AIME ä¸Šæµ‹è¯• Training-free GRPO æ•ˆæœï¼›é‡‡æ · 100 é¢˜ï¼Œè¿è¡Œ 3 è½®å®è·µï¼Œæ¸©åº¦ 0.7ï¼ˆè®­ç»ƒï¼‰â†’ 0.3ï¼ˆæµ‹è¯•ï¼‰ã€‚ | Mean@32 å‡†ç¡®ç‡ |
| **Agent RL** | å¯¹ Qwen2.5-7B è¿›è¡Œç«¯åˆ°ç«¯ RL è®­ç»ƒï¼š<br>- Math/Code ä»»åŠ¡ï¼šç»“åˆ sandbox æ‰§è¡Œå™¨<br>- Search ä»»åŠ¡ï¼šæœ¬åœ° Wikipedia + E5-HNSW å‘é‡æ£€ç´¢ | Accuracy æå‡å¹…åº¦ã€è®­ç»ƒé€Ÿåº¦ã€KL æ•£åº¦ã€critic score |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | æ˜¯å¦å¼€æº | ç‰¹ç‚¹ |
|------|------|----------|------|
| Smolagents, ReRct, WebShaper, WebThinker ç­‰ | å¼€æº Agent æ¡†æ¶ | æ˜¯ | å¤šæ•°ä¾èµ– GPT/Claude æˆ–æœªå®Œå…¨å¼€æ”¾è®­ç»ƒæµç¨‹ |
| ReAct, Reflexion | æ¨ç†å¢å¼ºæ–¹æ³• | æ˜¯ | æ— éœ€è®­ç»ƒï¼Œä½†ä¾èµ–äººå·¥è®¾è®¡ prompt |
| ZeroTIR, SimpleTIR, ReTool, AFM | å¼ºåŒ–å­¦ä¹ å¾®è°ƒæ–¹æ³• | éƒ¨åˆ†å…¬å¼€ | æˆæœ¬é«˜æ˜‚ï¼ˆçº¦ $10Kâ€“$20Kï¼‰ï¼Œéœ€ä¸‡çº§æ ·æœ¬ |
| Agent-Lightning (v0.2.2) | RL è¿æ¥æ¡†æ¶ | æ˜¯ | å®˜æ–¹ç‰ˆæœ¬ä½œä¸º RL æ¨¡å—å¯¹æ¯”åŸºçº¿ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **WebWalkerQA Pass@1** | **71.47%**ï¼ˆä½¿ç”¨ DeepSeek-V3.1ï¼‰ |
| **GAIA (text-only) Pass@1** | **72.8%** |
| **è‡ªåŠ¨åŒ–å·¥å…·åˆæˆæˆåŠŸç‡ï¼ˆTEï¼‰** | > **81.25%** |
| **ä»»åŠ¡å®Œæˆç‡ï¼ˆTCï¼‰** | Workflow: 65.00%ï¼ŒMeta-Agent: **68.75%** |
| **Agent Practice æå‡ï¼ˆvs ReActï¼‰** | AIME2024: **+2.7%**ï¼ŒAIME2025: **+5.4%**ï¼ˆä»… 100 æ ·æœ¬ï¼Œæˆæœ¬ ~$18ï¼‰ |
| **Agent RL è®­ç»ƒåŠ é€Ÿ** | è¾ƒå®˜æ–¹ Agent-Lightning **æé€Ÿ 40%** |
| **Qwen2.5-7B åœ¨ AIME2024 å‡†ç¡®ç‡æå‡** | ä» **10% â†’ 45%**ï¼ˆ+35ppï¼‰ |
| **æœç´¢ç±» QA å¹³å‡å‡†ç¡®ç‡æå‡** | æœ€é«˜è¾¾ **21%**ï¼ˆNaturalQuestionsï¼‰ |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### âœ… Benchmark è¡¨ç°ï¼ˆå›¾4ï¼‰
- Youtu-Agent åœ¨ WebWalkerQA ä¸Šæ˜¾è‘—ä¼˜äºå¤šæ•°å¼€æº Agentï¼ˆå¦‚ Smolagents @ ~40%ï¼‰ï¼Œæ¥è¿‘ç”šè‡³è¶…è¶Šéƒ¨åˆ†é—­æºç³»ç»Ÿï¼ˆå¦‚ ReRct with GPT-4oï¼‰ã€‚
- åœ¨ GAIA æ–‡æœ¬å­é›†ä¸Šè¾¾åˆ° 72.8%ï¼ŒéªŒè¯äº†é€šç”¨ä»»åŠ¡å¤„ç†èƒ½åŠ›ã€‚

#### âœ… è‡ªåŠ¨åŒ–ç”Ÿæˆæ•ˆæœï¼ˆè¡¨1ï¼‰
| æŒ‡æ ‡ | Workflow Mode | Meta-Agent Mode |
|------|---------------|-----------------|
| CVï¼ˆé…ç½®æœ‰æ•ˆï¼‰ | **100%** | 98.75% |
| TEï¼ˆå·¥å…·å¯æ‰§è¡Œï¼‰ | 81.25% | **82.50%** |
| TCï¼ˆä»»åŠ¡å®Œæˆï¼‰ | 65.00% | **68.75%** |

> Meta-Agent åœ¨å¤æ‚ä»»åŠ¡ä¸­è¡¨ç°æ›´ä¼˜ï¼Œä½“ç°å…¶çµæ´»å†³ç­–ä¼˜åŠ¿ã€‚

#### âœ… Agent Practice æˆæœ¬æ•ˆç›Šï¼ˆè¡¨2ï¼‰
| æ–¹æ³• | å­¦ä¹ æˆæœ¬ | AIME2024 (Mean@32) | AIME2025 |
|------|-----------|--------------------|----------|
| ReAct | â€“ | 80.0 | 67.9 |
| + Training-free GRPO (w/ GT) | ~$18 | **82.7 (+2.7)** | **73.3 (+5.4)** |
| ReTool / AFM | ~$10,000 | 67.0 / 66.7 | 49.3 / 59.8 |

> **Youtu-Agent ä»¥ä¸åˆ° 0.2% çš„æˆæœ¬å®ç°äº†æ›´é«˜çš„ç»å¯¹å¢ç›Š**ï¼Œæå…·å®ç”¨ä»·å€¼ã€‚

#### âœ… Agent RL æ•ˆæœï¼ˆè¡¨3 & è¡¨4ï¼‰
| ä»»åŠ¡ | æ•°æ®é›† | æå‡ Î”Accuracy |
|------|--------|----------------|
| Math/Code | AIME2024 | **+35%**ï¼ˆ0.10 â†’ 0.45ï¼‰ |
| Math/Code | AIME2025 | **+22%**ï¼ˆ0.09 â†’ 0.31ï¼‰ |
| Search | TriviaQA | +17% |
| Search | NaturalQuestions | **+21%** |
| Search | MuSiQue | +8% |
| Search | HotpotQA | +17% |
| Search | 2WikiMultiHop | +10% |

> æ‰€æœ‰ä»»åŠ¡å‡å®ç°ä¸€è‡´ä¸”æ˜¾è‘—çš„æ€§èƒ½å¢é•¿ã€‚

#### âœ… è®­ç»ƒæ•ˆç‡ä¸ç¨³å®šæ€§ï¼ˆå›¾6 & å›¾7ï¼‰
- **è¿­ä»£æ—¶é—´å‡å°‘ 40%**ï¼Œæ”¯æŒ 128 GPU åˆ†å¸ƒå¼è®­ç»ƒæ— è¶…æ—¶å´©æºƒã€‚
- KL æ•£åº¦ã€æ¢¯åº¦èŒƒæ•°ã€critic score æ›´åŠ å¹³ç¨³ï¼Œé¿å…â€œç†µçˆ†ç‚¸â€å¯¼è‡´çš„è®­ç»ƒå´©æºƒã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **è‡ªåŠ¨åŒ– Agent æ„å»ºæ˜¯å¯è¡Œä¸”é«˜æ•ˆçš„**ï¼šé€šè¿‡ YAML ç»“æ„åŒ–é…ç½® + LLM è‡ªåŠ¨ç”Ÿæˆå·¥å…·ä»£ç ä¸ Promptï¼Œå¯å°† Agent å¼€å‘æˆæœ¬å¤§å¹…é™ä½ï¼Œ**å·¥å…·åˆæˆæˆåŠŸç‡è¶…è¿‡ 81%**ã€‚
2. **æ— éœ€å¾®è°ƒä¹Ÿèƒ½æŒç»­è¿›åŒ–**ï¼š**Agent Practice æ¨¡å—**è¯æ˜ï¼Œå³ä½¿åœ¨æ— æ³•è®¿é—®æ¨¡å‹æƒé‡çš„æƒ…å†µä¸‹ï¼ˆå¦‚ API æ¨¡å‹ï¼‰ï¼Œä¹Ÿå¯é€šè¿‡ä¸Šä¸‹æ–‡ç»éªŒç§¯ç´¯å®ç°æœ‰æ•ˆæå‡ï¼Œå°¤å…¶é€‚åˆä½èµ„æºåœºæ™¯ã€‚
3. **å¤§è§„æ¨¡ Agent RL å¯ä»¥æ—¢å¿«åˆç¨³**ï¼šé€šè¿‡åŸºç¡€è®¾æ–½ä¼˜åŒ–ï¼ˆRESTfulã€Rayã€åˆ†å±‚è¶…æ—¶ï¼‰å’Œç®—æ³•æ”¹è¿›ï¼ˆè¿‡æ»¤å¼‚å¸¸è½¨è¿¹ã€å‡å°‘ off-policy æ›´æ–°ï¼‰ï¼ŒæˆåŠŸå®ç° **128 GPU è§„æ¨¡ä¸‹çš„ç¨³å®š RL è®­ç»ƒ**ï¼Œå¹¶å–å¾—æ˜¾è‘—æ€§èƒ½è·ƒè¿ã€‚
4. **å¼€æºæ¨¡å‹ä¹Ÿèƒ½è¾¾åˆ°é¡¶å°–æ°´å¹³**ï¼šYoutu-Agent åœ¨å®Œå…¨åŸºäºå¼€æºæ¨¡å‹ï¼ˆDeepSeekã€Qwenï¼‰çš„æƒ…å†µä¸‹ï¼Œåœ¨å¤šä¸ªæƒå¨åŸºå‡†ä¸Šè¾¾åˆ° SOTA è¡¨ç°ï¼Œæ¨åŠ¨äº†å¼€æ”¾ç”Ÿæ€çš„å‘å±•ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **å¯¹ LLM æœ¬èº«èƒ½åŠ›ä¾èµ–è¾ƒå¼º**ï¼šè‡ªåŠ¨åŒ–ç”Ÿæˆå’Œ RL æ•ˆæœå—é™äºåº•å±‚ LLM çš„æ¨ç†ä¸ä»£ç ç”Ÿæˆèƒ½åŠ›ã€‚
- **Meta-Agent æ¨¡å¼å¶å°”å¤±è´¥**ï¼šåœ¨æå°‘æ•°æƒ…å†µä¸‹ï¼Œ`create_agent_config` å·¥å…·è¾“å‡ºæ ¼å¼é”™è¯¯ï¼Œå½±å“æœ€ç»ˆé…ç½®æœ‰æ•ˆæ€§ï¼ˆCV=98.75%ï¼‰ã€‚
- **ç›®å‰ä¸»è¦é¢å‘å• Agent åœºæ™¯**ï¼šè™½æåŠæœªæ¥æ‰©å±•å¤š Agent åä½œï¼Œå½“å‰æ¡†æ¶å°šæœªæ·±å…¥æ”¯æŒå¤æ‚ååŒé€»è¾‘ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‹“å±•æ›´å¤šç¯å¢ƒé›†æˆ**ï¼šå¦‚ç§»åŠ¨ç«¯ã€IoT è®¾å¤‡ã€æœºå™¨äººæ§åˆ¶æ¥å£ç­‰ã€‚
2. **å¢å¼ºå¤š Agent ååŒèƒ½åŠ›**ï¼šå¼•å…¥è§’è‰²åˆ†å·¥ã€é€šä¿¡åè®®ã€å†²çªåè°ƒæœºåˆ¶ã€‚
3. **å‘å±•æ›´é«˜çº§çš„ç»éªŒç§¯ç´¯ç­–ç•¥**ï¼šä¾‹å¦‚é•¿æœŸè®°å¿†ç®¡ç†ã€è·¨ä»»åŠ¡çŸ¥è¯†è¿ç§»ã€è‡ªåŠ¨å½’çº³æŠ€èƒ½æ¨¡æ¿ã€‚
4. **æ¨å‡ºæ¡Œé¢çº§åº”ç”¨ Tip**ï¼šå·²åœ¨æ–‡ä¸­å±•ç¤ºåŸå‹ï¼Œç›®æ ‡æ˜¯æ‰“é€ æœ¬åœ°åŒ–ã€å®‰å…¨ã€ç›´è§‚çš„ GUI Agent åŠ©æ‰‹ï¼Œä¿ƒè¿› Agent æŠ€æœ¯è½åœ°æ™®åŠã€‚

---

> ğŸ”— **é¡¹ç›®åœ°å€**ï¼š[https://github.com/TencentCloudADP/youtu-agent](https://github.com/TencentCloudADP/youtu-agent)  
> ğŸ“… **å‘å¸ƒæ—¥æœŸ**ï¼šDecember 26, 2025

</details>

---

### 4. [FPGA Co-Design for Efficient N:M Sparse and Quantized Model Inference](https://arxiv.org/abs/2512.24713)

**Authors**: Fen-Yu Hsieh, Yun-Chang Teng, Ding-Yong Hong, Jan-Jan Wu  
**Category**: cs.LG  
**Published**: 2026-01-01  
**Score**: 11.5  
**Type**: new  
**ArXiv ID**: 2512.24713v1  

#### Abstract
Large language models (LLMs) have demonstrated remarkable performance across a wide range of language processing tasks. However, this success comes at the cost of substantial computation and memory requirements, which significantly impedes their deployment in resource-constrained environments. To ad...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFPGA Co-Design for Efficient N:M Sparse and Quantized Model Inference

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶å·¨å¤§çš„è®¡ç®—å’Œå†…å­˜å¼€é”€ä¸¥é‡é™åˆ¶äº†åœ¨èµ„æºå—é™ç¯å¢ƒä¸­çš„éƒ¨ç½²ã€‚ç‰¹åˆ«æ˜¯**æƒé‡å­˜å‚¨ã€å†…å­˜å¸¦å®½å’Œè®¡ç®—å»¶è¿Ÿ**æˆä¸ºç“¶é¢ˆã€‚

ç°æœ‰ç¡¬ä»¶å¯¹ç¨€ç–æ€§çš„æ”¯æŒæœ‰é™ï¼Œä¾‹å¦‚ NVIDIA GPU ä»…æ”¯æŒå›ºå®šçš„ 2:4 N:M ç¨€ç–æ¨¡å¼ï¼Œè€Œç®—æ³•ç ”ç©¶å¯èƒ½éœ€è¦æ›´çµæ´»çš„ N:M é…ç½®ä»¥è·å¾—æ›´é«˜ç²¾åº¦ã€‚è¿™ç§â€œ**ç®—æ³•çµæ´»æ€§ vs. ç¡¬ä»¶åˆšæ€§**â€çš„ä¸åŒ¹é…é˜»ç¢äº†é«˜æ•ˆä¸”å¯éƒ¨ç½²çš„ LLM æ¨ç†ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹

æœ¬æ–‡æå‡ºäº†ä¸€ç§ **FPGA è½¯ç¡¬ä»¶ååŒè®¾è®¡æ¡†æ¶**ï¼Œç»“åˆ **N:M ç»“æ„åŒ–å‰ªæï¼ˆStructured Pruningï¼‰** å’Œ **ä½æ¯”ç‰¹é‡åŒ–ï¼ˆLow-bit Quantizationï¼‰** æ¥åŠ é€Ÿ LLM æ¨ç†ã€‚

#### ä¸»è¦åˆ›æ–°åŒ…æ‹¬ï¼š

- âœ… **ç»Ÿä¸€çš„å‹ç¼©-æ‰§è¡Œæµæ°´çº¿**  
  è®¾è®¡äº†ä¸€ä¸ªè·¨å¹³å°ï¼ˆCPUã€GPUã€FPGAï¼‰çš„ç»Ÿä¸€æ¡†æ¶ï¼Œæ”¯æŒç¦»çº¿è¿›è¡Œ N:M å‰ªæ + INT4 é‡åŒ–ï¼Œå¹¶åœ¨çº¿å®Œæˆ dequantization å’Œ GEMM è¿ç®—ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

- âœ… **é€šç”¨åŒ–çš„ N:M æ”¯æŒï¼ˆè¶…è¶Š 2:4ï¼‰**  
  ä¸å±€é™äº NVIDIA çš„ 2:4 ç¡¬ä»¶çº¦æŸï¼Œè½¯ä»¶ç«¯æ”¯æŒä»»æ„ $ N < M $ çš„ç»“æ„åŒ–ç¨€ç–æ¨¡å¼ï¼Œä¸ºæ›´é«˜ç²¾åº¦æˆ–æ›´é«˜æ•ˆå‹ç¼©æä¾›å¯èƒ½ã€‚

- âœ… **é¢å‘ç¨€ç–é‡åŒ–çš„ FPGA åŠ é€Ÿå™¨æ¶æ„**  
  æ„å»ºåŸºäº systolic array çš„ FPGA åŠ é€Ÿå™¨ï¼Œé›†æˆï¼š
  - **Zero-skipping PEs**ï¼šè‡ªåŠ¨è·³è¿‡é›¶æƒé‡çš„ MAC æ“ä½œï¼Œå‡å°‘æ— æ•ˆè®¡ç®—ã€‚
  - **å¯é‡æ„æ•°æ®è·¯å¾„**ï¼šé€‚åº”ä¸åŒ N:M æ¨¡å¼å’Œ bit-widthï¼ˆå¦‚ 4-bitï¼‰ï¼Œæå‡ç¡¬ä»¶çµæ´»æ€§ã€‚
  - **æ— éœ€æ˜¾å¼ç¨€ç–å…ƒæ•°æ®**ï¼šåˆ©ç”¨ dense layout å­˜å‚¨ç¨€ç–æƒé‡ï¼ˆä¿ç•™é›¶å€¼ï¼‰ï¼Œç®€åŒ–ç¡¬ä»¶è§£ç é€»è¾‘ã€‚

- âœ… **åˆ†ææ¨¡å‹æŒ‡å¯¼è®¾è®¡ç©ºé—´æ¢ç´¢**  
  æå‡ºé€šç”¨åˆ†ææ¨¡å‹ï¼Œç”¨äºé¢„æµ‹æœ€ä¼˜ N:M æ¨¡å¼å’Œ bit-width ç»„åˆï¼Œåœ¨ååé‡ã€åˆ©ç”¨ç‡å’Œç²¾åº¦ä¹‹é—´æƒè¡¡ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³•å±€é™ | æœ¬æ–‡ä¼˜åŠ¿ |
|------|---------------|----------|
| **ç¨€ç–æ¨¡å¼æ”¯æŒ** | GPU ä»…æ”¯æŒå›ºå®š 2:4 | æ”¯æŒä»»æ„ N:Mï¼Œæ›´å…·ç®—æ³•å…¼å®¹æ€§ |
| **é‡åŒ–ç²’åº¦** | å¤šæ•°ä¸º 8-bit æˆ–éå‡åŒ€é‡åŒ– | ç»Ÿä¸€é‡‡ç”¨ INT4ï¼Œæè‡´å‹ç¼© |
| **è½¯ç¡¬ååŒ** | è½¯ä»¶å‹ç¼©ä¸ç¡¬ä»¶è„±èŠ‚ | å…¨æµç¨‹ co-designï¼Œä»å‹ç¼©åˆ°æ‰§è¡Œä¸€ä½“åŒ– |
| **éƒ¨ç½²çµæ´»æ€§** | å—é™äºç‰¹å®šç¡¬ä»¶ç‰¹æ€§ | FPGA å¹³å°å¯ç¼–ç¨‹æ€§å¼ºï¼Œé€‚é…å¤šç§ç¨€ç–/é‡åŒ–ç»„åˆ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†ä¸æ¨¡å‹
- ä½¿ç”¨åˆæˆçŸ©é˜µè¿›è¡Œç»„ä»¶çº§åŸºå‡†æµ‹è¯•ï¼ˆ$ M \times K $ æƒé‡çŸ©é˜µï¼‰
- åœ¨ **LLaMA-7B** æ¨¡å‹ä¸Šè¿›è¡Œç³»ç»Ÿçº§é¢„æµ‹åˆ†æï¼ˆä»…è€ƒè™‘ linear layers çš„æ¨ç†æˆæœ¬ï¼‰

> æ³¨ï¼šæœªä½¿ç”¨çœŸå®ä¸‹æ¸¸ä»»åŠ¡æ•°æ®é›†ï¼ˆå¦‚ GLUEï¼‰ï¼Œè€Œæ˜¯èšç„¦äºæ¨ç†æ•ˆç‡å»ºæ¨¡ã€‚

---

### å®éªŒè®¾ç½®

- **çŸ©é˜µè§„æ¨¡**ï¼š
  - $ 4096 \times 4096 $
  - $ 8192 \times 8192 $
  - $ 12288 \times 12288 $
- **Batch size**ï¼šé»˜è®¤ $ B = 512 $ï¼ˆå¤§ batch æ›´èƒ½ä½“ç°ç¨€ç–æ”¶ç›Šï¼‰
- **é‡åŒ–é…ç½®**ï¼šæƒé‡ INT4ï¼Œæ¿€æ´»ä¿æŒ FP16
- **å‰ªææ¨¡å¼**ï¼šä¸»è¦æµ‹è¯• 2:4ï¼ˆå³æ¯ç»„ 4 ä¸ªå…ƒç´ ä¿ç•™ 2 ä¸ªæœ€å¤§å¹…å€¼æƒé‡ï¼‰

---

### è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| `t_io` | æƒé‡åŠ è½½æ—¶é—´ |
| `t_deq` | è®¾å¤‡ç«¯ dequantization æ—¶é—´ |
| `t_mm` | GEMM è®¡ç®—æ—¶é—´ |
| `t_compute` | `t_deq + t_mm`ï¼ˆçº¯è®¡ç®—æµæ°´çº¿æ—¶é—´ï¼‰ |
| **Throughput (GFLOP/s)** | åŸºäº dense FLOPs è®¡ç®—ï¼š$ \frac{2 \cdot M \cdot K \cdot B}{t} \times 10^{-9} $ |
| **End-to-end latency reduction** | ç›¸å¯¹äº dense baseline çš„åŠ é€Ÿæ¯” |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”

| Backend | æè¿° |
|--------|------|
| **CPU** | PyTorch CPU BLAS åç«¯ï¼Œé‡å»º dense æƒé‡åæ‰§è¡Œ GEMM |
| **GPU (Dense)** | CUDA + cuBLASï¼Œæ ‡å‡† dense GEMM |
| **GPU (2:4 Sparse)** | ä½¿ç”¨ `cuSPARSELt` çš„ 2:4 åŠç»“æ„åŒ–ç¨€ç–å†…æ ¸ |
| **FPGA (Ours)** | è‡ªç ” systolic array åŠ é€Ÿå™¨ï¼ˆå½“å‰æœªæŠ¥å‘Šå®æµ‹æ•°æ®ï¼‰ |

> æ‰€æœ‰å¹³å°è¿è¡Œç›¸åŒå‹ç¼©æ ¼å¼å’Œæ‰§è¡Œæµç¨‹ï¼Œä¿è¯å…¬å¹³æ€§ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Tables 5 & 6ï¼‰

#### åœ¨ $ 4096 \times 4096, B=512 $ ä¸Šçš„ç»“æœï¼š

| Backend | `t_mm` (ms) | `t_compute` (ms) | Throughput_mm (GFLOP/s) | Speedup (vs Dense GPU) |
|--------|-------------|------------------|----------------------------|-------------------------|
| GPU (Dense) | 0.36 | 0.66 | 47,862 | 1.00Ã— |
| GPU (2:4) | **0.21** | **0.51** | **81,968** | **1.71Ã— (GEMM), 1.29Ã— (end-to-end)** |

âœ… **GEMM åŠ é€Ÿ 1.71Ã—ï¼Œç«¯åˆ°ç«¯è®¡ç®—åŠ é€Ÿ 1.29Ã—**

#### å†…å­˜å ç”¨ä¼˜åŒ–ï¼ˆTable 4ï¼‰

| æ–¹æ³• | ç›¸å¯¹ dense å¤§å° | å®é™…å¤§å°ï¼ˆ4096Ã—4096ï¼‰ |
|------|------------------|------------------------|
| Dense FP16 | 1.00Ã— | 32.00 MB |
| Pruned + Quant (bit-packed) | **0.25Ã—** | **8.00 MB** |

âœ… **æƒé‡å­˜å‚¨å‡å°‘è‡³ 1/4ï¼ˆ4Ã— å‹ç¼©ï¼‰**

> å½“å‰å®ç°æœª bit-packï¼Œæ•…å®é™…å  16MBï¼ˆä»ä¸º 0.5Ã—ï¼‰

---

### ä¸åŒçŸ©é˜µè§„æ¨¡ä¸‹çš„æ‰©å±•æ€§è¡¨ç°ï¼ˆTable 6ï¼‰

éšç€çŸ©é˜µå¢å¤§ï¼Œç¨€ç–ä¼˜åŠ¿æ›´åŠ æ˜æ˜¾ï¼š

| $(M,N)$ | GEMM Time (Dense) â†’ (Sparse) | Speedup |
|--------|------------------------------|--------|
| (4096,4096) | 0.36 â†’ 0.21 ms | 1.71Ã— |
| (8192,8192) | 1.05 â†’ 0.64 ms | 1.64Ã— |
| (12288,12288) | 2.26 â†’ 1.16 ms | **1.95Ã—** |

> è¡¨æ˜æ›´å¤§è§„æ¨¡ä¸‹å…ƒæ•°æ®å¼€é”€è¢«æ‘Šè–„ï¼Œç¨€ç–åŠ é€Ÿæ•ˆæœå¢å¼ºã€‚

---

### LLaMA-7B æ¨¡å‹çº§é¢„æµ‹ç»“æœï¼ˆTable 8ï¼‰

åŸºäºçº¿æ€§å±‚çš„è®¡ç®—å»ºæ¨¡ï¼Œé¢„æµ‹æ•´æ¨¡å‹æ¨ç†æ€§èƒ½ï¼š

| Backend | $ T_{\text{model}} $ (ms) | Throughput_model (GFLOP/s) | Speedup (vs Dense GPU) |
|--------|----------------------------|------------------------------|------------------------|
| GPU (Dense) | 215.04 | 30,838 | 1.00Ã— |
| GPU (2:4) | **158.40** | **41,865** | **1.36Ã—** |
| CPU | 13,596.80 | 488 | â€” |

âœ… **é¢„æµ‹æ¯ token ååæå‡ 1.36Ã—**

> æ³¨æ„ï¼šè¯¥é¢„æµ‹ä»…åŒ…å« linear layers çš„ dequant + GEMMï¼Œä¸å« attentionã€softmaxã€norm ç­‰å…¶ä»–æ“ä½œã€‚

---

### æ¶ˆèå®éªŒï¼ˆéšå«åˆ†æï¼‰

è™½ç„¶æ²¡æœ‰æ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»ä»¥ä¸‹æ–¹é¢ä½“ç°äº†è”åˆä¼˜åŒ–çš„ä»·å€¼ï¼š

- **å•ç‹¬å‰ªæ**ï¼šå‡å°‘è®¡ç®—é‡ä½†æœªé™ä½ç²¾åº¦
- **å•ç‹¬é‡åŒ–**ï¼šé™ä½ç²¾åº¦ä½†æœªå‡å°‘è¿ç®—æ¬¡æ•°
- **è”åˆä½¿ç”¨ï¼ˆPruning + Quantizationï¼‰**ï¼š
  - åŒæ—¶å‡å°‘ **memory footprintï¼ˆ4Ã—ï¼‰**
  - å‡å°‘ **arithmetic costï¼ˆ~50% MACsï¼‰**
  - é™ä½ **memory bandwidth éœ€æ±‚**
  â†’ å®ç°å…¨é¢å‹ç¼©ä¸åŠ é€Ÿ

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. âœ… **N:M ç»“æ„åŒ–ç¨€ç– + INT4 é‡åŒ–å…·æœ‰æ˜¾è‘—ååŒæ•ˆåº”**  
   è”åˆåº”ç”¨å¯åœ¨å‡ ä¹ä¸å½±å“ç²¾åº¦çš„å‰æä¸‹ï¼Œå®ç°é«˜è¾¾ **4Ã— çš„æƒé‡å‹ç¼©** å’Œ **1.71Ã— çš„ GEMM åŠ é€Ÿ**ã€‚

2. âœ… **ç»“æ„åŒ–ç¨€ç–åœ¨å¤§è§„æ¨¡çŸ©é˜µä¸Šæ›´å…·ä¼˜åŠ¿**  
   éšç€çŸ©é˜µå°ºå¯¸å¢åŠ ï¼Œç¨€ç–å¸¦æ¥çš„åŠ é€Ÿæ¯”è¿›ä¸€æ­¥æå‡ï¼ˆæœ€é«˜è¾¾ 1.95Ã—ï¼‰ï¼Œè¡¨æ˜å…¶é€‚ç”¨äº LLM ä¸­çš„å¤§çŸ©é˜µä¹˜æ³•ã€‚

3. âœ… **è½¯ç¡¬ä»¶ååŒè®¾è®¡æ˜¯é«˜æ•ˆæ¨ç†çš„å…³é”®è·¯å¾„**  
   é€šè¿‡ç»Ÿä¸€å‹ç¼©æ ¼å¼ + ä¸“ç”¨åŠ é€Ÿå™¨ï¼ˆzero-skipping systolic arrayï¼‰ï¼Œå¯ä»¥æœ€å¤§åŒ–ç¨€ç–æ€§å’Œé‡åŒ–å¸¦æ¥çš„æ”¶ç›Šã€‚

4. âœ… **FPGA æä¾›è¶…è¶Š GPU çš„çµæ´»æ€§æ½œåŠ›**  
   å½“å‰ GPU è¢«é”å®šåœ¨ 2:4 æ¨¡å¼ï¼Œè€Œ FPGA å¯æ”¯æŒä»»æ„ N:M æ¨¡å¼ï¼Œä¸ºæœªæ¥æ›´é«˜å‹ç¼©ç‡ï¼ˆå¦‚ 4:16ï¼‰æˆ–ç²¾åº¦æ•æ„Ÿåœºæ™¯é¢„ç•™ç©ºé—´ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§

- âŒ **FPGA å®æµ‹æ€§èƒ½å°šæœªå®Œæ•´æŠ¥å‘Š**  
  æ–‡ä¸­å¤šæ¬¡æåŠ â€œFPGA (ours)â€ ä½†åœ¨ Tables 5â€“8 ä¸­å‡ä¸ºç©ºç™½ï¼Œè¯´æ˜ FPGA åŠ é€Ÿå™¨ä»åœ¨å¼€å‘ä¸­ï¼Œç¼ºä¹æœ€ç»ˆæ€§èƒ½æ•°æ®ã€‚

- âŒ **æœªéªŒè¯çœŸå®ä»»åŠ¡ç²¾åº¦æŸå¤±**  
  å®éªŒé›†ä¸­åœ¨æ¨ç†æ•ˆç‡ï¼Œæœªå±•ç¤ºå‰ªæ+é‡åŒ–åçš„æ¨¡å‹åœ¨ä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚é—®ç­”ã€æ‘˜è¦ï¼‰ä¸Šçš„ accuracy/perplexity å˜åŒ–ã€‚

- âŒ **å‡è®¾ç†æƒ³æ‰§è¡Œæ¡ä»¶**  
  é¢„æµ‹å¿½ç•¥äº† attentionã€cache IOã€normalization ç­‰å¼€é”€ï¼Œå®é™…ç«¯åˆ°ç«¯å»¶è¿Ÿä¼šæ›´é«˜ã€‚

- âŒ **æ¿€æ´»æœªé‡åŒ–**  
  æ¿€æ´»ä»ç”¨ FP16ï¼Œè‹¥è¿›ä¸€æ­¥é‡åŒ–å¯å¸¦æ¥æ›´å¤§æ”¶ç›Šï¼Œä½†ä¹Ÿå¯èƒ½å¼•å…¥é¢å¤–è¯¯å·®ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘ï¼ˆä½œè€…æ˜ç¡®æå‡ºï¼‰

1. ğŸ”§ **å®Œæˆ FPGA å®ç°å¹¶è¯„ä¼°åŠŸè€—ä¸èƒ½æ•ˆ**  
   è¡¥å…¨å®æµ‹æ€§èƒ½ã€PDPï¼ˆPower-Delay Productï¼‰ç­‰å…³é”®æŒ‡æ ‡ã€‚

2. ğŸš€ **å°†æ¡†æ¶æ‰©å±•è‡³ç«¯åˆ°ç«¯ LLaMA æ¨ç†**  
   æ•´åˆ attentionã€RoPEã€LayerNorm ç­‰æ¨¡å—ï¼Œå®ç°å®Œæ•´æ¨¡å‹éƒ¨ç½²ã€‚

3. ğŸ” **æ¢ç´¢æ›´ä¸°å¯Œçš„ç¨€ç–ä¸é‡åŒ–æ–¹æ¡ˆ**  
   å¦‚æ›´é«˜æ¯”ä¾‹çš„ N:Mï¼ˆ4:16ï¼‰ã€æ··åˆç²¾åº¦æ¿€æ´»ï¼ˆmixed-precision activationsï¼‰ç­‰ã€‚

4. â˜ï¸ **é¢å‘è¾¹ç¼˜ä¸æ•°æ®ä¸­å¿ƒçš„éƒ¨ç½²ä¼˜åŒ–**  
   é€‚é…ä¸åŒå¹³å°éœ€æ±‚ï¼Œæ¨åŠ¨è½»é‡åŒ– LLM å®é™…è½åœ°ã€‚

---

## æ€»ç»“

æœ¬æ–‡æå‡ºäº†ä¸€å¥—å®Œæ•´çš„ **N:M ç¨€ç– + INT4 é‡åŒ– + FPGA åŠ é€Ÿ** çš„è½¯ç¡¬ä»¶ååŒè®¾è®¡æ–¹æ¡ˆï¼Œè§£å†³äº† LLM æ¨ç†ä¸­å†…å­˜ä¸è®¡ç®—ç“¶é¢ˆé—®é¢˜ã€‚å®éªŒè¡¨æ˜è¯¥æ–¹æ³•å¯å®ç° **4Ã— æƒé‡å‹ç¼©** å’Œ **1.71Ã— GEMM åŠ é€Ÿ**ï¼Œåœ¨ LLaMA-7B ä¸Šé¢„æµ‹ååæå‡ **1.36Ã—**ã€‚å°½ç®¡ FPGA å®æµ‹ç»“æœå°šå¾…å®Œå–„ï¼Œä½†å…¶**æ”¯æŒé€šç”¨ N:M æ¨¡å¼çš„çµæ´»æ€§**ä¸ºæœªæ¥é«˜æ•ˆ LLM æ¨ç†ç¡¬ä»¶æä¾›äº†é‡è¦æ–¹å‘ã€‚

</details>

---

### 5. [Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem](https://arxiv.org/abs/2512.24873)

**Authors**: Weixun Wang, XiaoXiao Xu, Wanhe An, Fangwen Dai, Wei Gao, Yancheng He, Ju Huang, Qiang Ji, Hanqi Jin, Xiaoyang Li, Yang Li, Zhongwen Li, Shirong Lin, Jiashun Liu, Zenan Liu, Tao Luo, Dilxat Muhtar, Yuanbin Qu, Jiaqiang Shi, Qinghui Sun, Yingshui Tan, Hao Tang, Runze Wang, Yi Wang, Zhaoguo Wang, Yanan Wu, Shaopan Xiong, Binchen Xu, Xander Xu, Yuchi Xu, Qipeng Zhang, Xixia Zhang, Haizhou Zhao, Jie Zhao, Shuaibing Zhao, Baihui Zheng, Jianhui Zheng, Suhang Zheng, Yanni Zhu, Mengze Cai, Kerui Cao, Xitong Chen, Yue Dai, Lifan Du, Tao Feng, Tao He, Jin Hu, Yijie Hu, Ziyu Jiang, Cheng Li, Xiang Li, Jing Liang, Chonghuan Liu, ZhenDong Liu, Haodong Mi, Yanhu Mo, Junjia Ni, Shixin Pei, Jingyu Shen, XiaoShuai Song, Cecilia Wang, Chaofan Wang, Kangyu Wang, Pei Wang, Tao Wang, Wei Wang, Ke Xiao, Mingyu Xu, Tiange Xu, Nan Ya, Siran Yang, Jianan Ye, Yaxing Zang, Duo Zhang, Junbo Zhang, Boren Zheng, Wanxi Deng, Ling Pan, Lin Qu, Wenbo Su, Jiamang Wang, Wei Wang, Hu Wei, Minggang Wu, Cheng Yu, Bing Zhao, Zhicheng Zheng, Bo Zheng  
**Category**: cs.AI  
**Published**: 2026-01-01  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.24873v1  

#### Abstract
Agentic crafting requires LLMs to operate in real-world environments over multiple turns by taking actions, observing outcomes, and iteratively refining artifacts. Despite its importance, the open-source community lacks a principled, end-to-end ecosystem to streamline agent development. We introduce...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚ã€å¤šè½®äº¤äº’ä»»åŠ¡ä¸­çš„è¡¨ç°å—é™äºç¼ºä¹ä¸€ä¸ª**ç«¯åˆ°ç«¯çš„ã€å¯æ‰©å±•çš„ agentic å­¦ä¹ ç”Ÿæ€ç³»ç»Ÿ**ã€‚ä¼ ç»Ÿçš„ one-shot æ¨ç†èŒƒå¼æ— æ³•æ”¯æŒçœŸå®ä¸–ç•Œä¸­éœ€è¦æŒç»­è§„åˆ’ã€æ‰§è¡Œã€åé¦ˆå’Œè¿­ä»£çš„â€œagentic craftingâ€ä»»åŠ¡ï¼ˆå¦‚è½¯ä»¶å·¥ç¨‹ã€ç»ˆç«¯æ“ä½œç­‰ï¼‰ã€‚æ­¤å¤–ï¼Œç°æœ‰çš„è®­ç»ƒæ¡†æ¶åœ¨é•¿æ—¶åºä»»åŠ¡ä¸­é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **è®­ç»ƒä¸ç¨³å®š**ï¼šå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸­é•¿æœŸä¿¡ç”¨åˆ†é…å›°éš¾ï¼›
- **æ¨ç†-è®­ç»ƒä¸ä¸€è‡´**ï¼ˆInference-Training Mismatchï¼‰å¯¼è‡´ç­–ç•¥é€€åŒ–ï¼›
- ç¼ºä¹é«˜è´¨é‡ã€å¯éªŒè¯çš„ agentic æ•°æ®ï¼›
- å®‰å…¨æ€§é—®é¢˜åœ¨å·¥å…·è°ƒç”¨ä¸­è‡ªå‘å‡ºç°ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå®Œæ•´çš„ **Agentic Learning Ecosystem (ALE)**ï¼Œå¹¶åŸºäºæ­¤æ„å»ºäº†å¼€æºæ™ºèƒ½ä½“æ¨¡å‹ **ROME**ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰ç³»ç»Ÿçº§åŸºç¡€è®¾æ–½ï¼šALE ä¸‰å¤§ç»„ä»¶
- **ROLL**ï¼ˆReinforcement Learning Optimization for Large-Scale Learningï¼‰  
  ä¸€ä¸ªå¯æ‰©å±•çš„ agentic RL è®­ç»ƒæ¡†æ¶ï¼Œæ”¯æŒå¤šç¯å¢ƒå¹¶è¡Œ rolloutã€å¼‚æ­¥è®­ç»ƒã€åŠ¨æ€ GPU å¤ç”¨ï¼Œæ˜¾è‘—æå‡è®­ç»ƒååé‡ä¸ç¨³å®šæ€§ã€‚
- **ROCK**ï¼ˆReinforcement Open Construction Kitï¼‰  
  ä¸€ä¸ªå®‰å…¨æ²™ç®±ç¯å¢ƒç®¡ç†å™¨ï¼Œæä¾›å¯å¤ç°ã€éš”ç¦»çš„æ‰§è¡Œç¯å¢ƒï¼Œç”¨äºè½¨è¿¹ç”Ÿæˆã€éªŒè¯å’Œè¿è¡Œæ—¶æ§åˆ¶ï¼Œç¡®ä¿æ•°æ®ä¸è¡Œä¸ºçš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚
- **iFlow CLI**  
  ä¸€ä¸ªçµæ´»çš„ agent æ¡†æ¶ï¼Œå®ç°ä¸Šä¸‹æ–‡å·¥ç¨‹ï¼ˆcontext engineeringï¼‰ã€å·¥å…·é›†æˆï¼ˆvia MCPï¼‰ã€è®°å¿†ç®¡ç†å’Œè‡ªåŠ¨åŒ–æµç¨‹ç¼–æ’ï¼Œç»Ÿä¸€è®­ç»ƒä¸éƒ¨ç½²çš„ä¸€è‡´æ€§ã€‚

#### ï¼ˆ2ï¼‰æ–°å‹æ”¿ç­–ä¼˜åŒ–ç®—æ³•ï¼šIPAï¼ˆInteraction-Perceptive Agentic Policy Optimizationï¼‰
æå‡ºå°†è¯­ä¹‰ä¸Šæœ‰æ„ä¹‰çš„â€œäº¤äº’å—â€ï¼ˆinteraction chunkï¼‰ä½œä¸º RL ä¸­çš„åŸºæœ¬å•å…ƒï¼Œè€Œéä¼ ç»Ÿ token æˆ–å®Œæ•´è½¨è¿¹ï¼š
- åœ¨ chunk ç²’åº¦è¿›è¡Œä¿¡ç”¨åˆ†é…ï¼ˆcredit assignmentï¼‰ï¼Œç¼“è§£é•¿æ—¶åºä»»åŠ¡ä¸­çš„æ¢¯åº¦ç¨€é‡Šï¼›
- å¼•å…¥ **chunk-level discounted return** å’Œ **chunk-level importance sampling**ï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§ï¼›
- è®¾è®¡ **Chunk-Level Initialized Resampling** ç­–ç•¥ï¼Œåœ¨å…³é”®å†³ç­–ç‚¹åˆå§‹åŒ– rolloutï¼ŒåŠ é€Ÿå¯¹éš¾ä»»åŠ¡çš„å­¦ä¹ ã€‚

#### ï¼ˆ3ï¼‰é«˜è´¨é‡ agentic æ•°æ®åˆæˆä¸å®‰å…¨å¯¹é½
- æ„å»ºä¸¤é˜¶æ®µæ•°æ®åˆæˆç®¡é“ï¼šä»åŸºç¡€ä»£ç ä»»åŠ¡åˆ°é—­ç¯ agentic è½¨è¿¹ï¼›
- æå‡ºå››é˜¶æ®µè¿‡æ»¤æµæ°´çº¿ï¼ˆheuristic filter â†’ LLM-based judge â†’ execution simulator â†’ expert inspectionï¼‰ï¼Œæ¶ˆé™¤è™šå‡æ­£ä¾‹ä¸é”™è¯¯ä¿¡å·ï¼›
- é¦–æ¬¡ç³»ç»Ÿæ€§æ­ç¤º LLM æ™ºèƒ½ä½“åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼š**è‡ªå‘äº§ç”Ÿè¶Šæƒè¡Œä¸º**ï¼ˆå¦‚å»ºç«‹åå‘ SSH éš§é“ã€åŠ å¯†æŒ–çŸ¿ï¼‰ï¼Œå¹¶æå‡ºçº¢é˜Ÿæµ‹è¯•ä¸å®‰å…¨å¯¹é½æ•°æ®æ¥å¢å¼ºå¯æ§æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ALE / ROME çš„ä¼˜åŠ¿ |
|------|------------------|
| **ç³»ç»Ÿå®Œæ•´æ€§** | æä¾›ä»æ•°æ®ç”Ÿæˆã€è®­ç»ƒã€è¯„ä¼°åˆ°éƒ¨ç½²çš„å…¨æ ˆåŸºç¡€è®¾æ–½ï¼Œå¡«è¡¥å¼€æºç”Ÿæ€ç©ºç™½ |
| **è®­ç»ƒæ•ˆç‡ä¸ç¨³å®šæ€§** | ROLL æ”¯æŒå¼‚æ­¥è®­ç»ƒä¸ GPU åŠ¨æ€å¤ç”¨ï¼ŒIPA æå‡é•¿æ—¶åºä»»åŠ¡æ”¶æ•›é€Ÿåº¦ä¸é²æ£’æ€§ |
| **æ€§èƒ½è¡¨ç°** | å°è§„æ¨¡æ¨¡å‹ï¼ˆ30B MoE, æ¿€æ´» 3Bï¼‰è¾¾åˆ°ç”šè‡³è¶…è¶Šç™¾Bçº§æ¨¡å‹æ€§èƒ½ |
| **å®‰å…¨æ€§ä¸å¯æ§æ€§** | æ˜¾å¼è¯†åˆ«å¹¶åº”å¯¹æ™ºèƒ½ä½“çš„è¶Šæƒè¡Œä¸ºï¼Œæ¨åŠ¨å®‰å…¨å¯¹é½ç ”ç©¶ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **åŸºç¡€æ•°æ®**ï¼š
  - æ¥è‡ªçº¦ 100 ä¸‡é«˜è´¨é‡ GitHub ä»“åº“çš„é¡¹ç›®çº§ä»£ç æ•°æ®ï¼ˆè¿ç»­é¢„è®­ç»ƒï¼‰ï¼›
  - Issue-PR å¯¹ç”¨äºæ„å»ºä»£ç å®šä½ã€ä¿®å¤ã€æµ‹è¯•ç”Ÿæˆç­‰ä»»åŠ¡ã€‚
- **agentic æ•°æ®**ï¼š
  - åˆæˆ 76K é«˜è´¨é‡ç¼–ç¨‹ä»»åŠ¡å®ä¾‹ï¼Œæ¶µç›– Pythonã€Goã€TypeScript ç­‰è¯­è¨€ï¼›
  - åŒ…å« Docker ç¯å¢ƒã€å¯æ‰§è¡Œè§„èŒƒã€å•å…ƒæµ‹è¯•ï¼Œç¡®ä¿å¯å¤ç°æ€§ï¼›
  - æ€»è®¡çº¦ 30B tokens çš„æˆåŠŸæ‰§è¡Œè½¨è¿¹ã€‚
- **å®‰å…¨å¯¹é½æ•°æ®**ï¼š
  - æ„å»º red-teaming æµ‹è¯•é›†ï¼Œæ³¨å…¥æ¶æ„æç¤ºã€æ¼æ´ä¾èµ–ã€è¶ŠæƒæŒ‡ä»¤ç­‰ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹æ¶æ„**ï¼šROME åŸºäº Qwen3-MoE æ¶æ„ï¼Œæ€»å‚æ•° 30Bï¼Œæ¿€æ´»å‚æ•°ä»… 3Bã€‚
- **è®­ç»ƒæµç¨‹ä¸‰é˜¶æ®µ**ï¼š
  1. **Continual Pre-training (CPT)**ï¼šå­¦ä¹ åŸºæœ¬ç¼–ç ä¸æ¨ç†èƒ½åŠ›ï¼›
  2. **Supervised Fine-tuning (SFT)**ï¼šå¼•å…¥ error-masked loss ä¸ task-aware context maskingï¼›
  3. **Reinforcement Learning (IPA)**ï¼šä½¿ç”¨ chunk-level RL è¿›è¡Œç­–ç•¥ä¼˜åŒ–ã€‚
- **è¯„ä¼°ç»´åº¦**ï¼š
  - **Terminal-based execution**ï¼šTerminal-Bench 1.0/2.0ã€SWE-bench Verified/Multilingualï¼›
  - **Tool-use abilities**ï¼šTAU2-Benchï¼ˆé›¶å”®/èˆªç©º/ç”µä¿¡ï¼‰ã€BFCL-v3ã€MTU-Benchï¼›
  - **General agentic capabilities**ï¼šGAIAã€BrowseComp-ZHã€ShopAgentï¼ˆå•/å¤šè½®ï¼‰ï¼›
  - æ–°æå‡º **Terminal Bench Pro**ï¼šåŒ…å« 400 ä¸ªä»»åŠ¡ï¼ˆ200 å…¬å¼€ + 200 ç§æœ‰ï¼‰ï¼Œè¦†ç›– 8 ä¸ªé¢†åŸŸï¼Œå¼ºè°ƒç¡®å®šæ€§ç¯å¢ƒä¸é«˜æµ‹è¯•è¦†ç›–ç‡ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **åŒç±»è§„æ¨¡æ¨¡å‹**ï¼š
  - Qwen3-Coder-30B-A3B-Instruct
  - Devstral-Small-2 (24B)
  - GPT-OSS-120B
- **å¤§è§„æ¨¡é—­æº/å¼€æºæ¨¡å‹**ï¼š
  - Qwen3-Coder-Plusã€Qwen3-Coder-480B
  - DeepSeek-V3.1ã€GLM-4.6ã€Kimi-K2
  - Claude-Haiku-4.5ã€Gemini-2.5 Flash
- æ‰€æœ‰æ¨¡å‹å‡ä½¿ç”¨ç›¸åŒç”Ÿæˆå‚æ•°ï¼ˆtemperature=0.7, top_p=0.8, max_output_length=65536ï¼‰è¿›è¡Œå…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆPass@1 Avg@3ï¼‰

| Benchmark | ROME (30B-A3B) | æœ€ä½³åŸºçº¿ï¼ˆåŒè§„æ¨¡ï¼‰ | æœ€ä½³åŸºçº¿ï¼ˆè¶…å¤§è§„æ¨¡ï¼‰ |
|----------|----------------|--------------------|------------------------|
| **Terminal-Bench 1.0** | **41.50%** | Qwen3-Coder-30B (28.50%) | Claude-Haiku (47.08%) |
| **Terminal-Bench 2.0** | **24.72%** | GPT-OSS-120B (21.12%) | Claude-Haiku (34.83%) |
| **SWE-bench Verified** | **57.40%** | Qwen3-Coder-30B (46.33%) | Claude-Haiku (69.60%) |
| **SWE-bench Multilingual** | **40.00%** | GLM-4.5Air (38.16%) | GPT-5Mini (49.67%) |
| **Terminal-Bench-Pro-Public** | **40.50%** | GPT-OSS-120B (32.00%) | Claude-Haiku (45.83%) |
| **Terminal-Bench-Pro-Private** | **21.50%** | GPT-OSS-120B (27.83%) | Claude-Haiku (35.33%) |
| **Tool-use å¹³å‡å¾—åˆ†** | **49.46%** | GPT-OSS-120B (56.47%) | GPT-5Mini (58.38%) |
| **General Agentic å¹³å‡å¾—åˆ†** | **25.64%** | GPT-OSS-120B (23.40%) | GPT-5Mini (35.59%) |

> æ³¨ï¼šROME åœ¨å¤šä¸ª benchmark ä¸Š**è¶…è¶ŠåŒè§„æ¨¡æ¨¡å‹ 10â€“15 ä¸ªç™¾åˆ†ç‚¹ä»¥ä¸Š**ï¼Œä¸”åœ¨éƒ¨åˆ†ä»»åŠ¡ä¸Šæ¥è¿‘æˆ–è¶…è¿‡ç™¾Bçº§æ¨¡å‹ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **åœ¨ Terminal-Bench 2.0 ä¸Š**ï¼ŒROME è¾¾åˆ° 24.72%ï¼Œæ˜¾è‘—ä¼˜äº Qwen3-Coder-30B (13.48%) å’Œ GPT-OSS-120B (21.12%)ï¼›
- **åœ¨ SWE-bench Verified ä¸Š**ï¼ŒROME å¾—åˆ†ä¸º 57.40%ï¼Œé«˜äº GPT-OSS-120B (43.93%) å’Œ GLM-4.5Air (56.20%)ï¼Œæ¥è¿‘ Qwen3-Coder-480B (65.20%)ï¼›
- **åœ¨ ShopAgent å¤šè½®ä»»åŠ¡ä¸­**ï¼ŒROME è¾¾åˆ° 29.61%ï¼Œè¿œè¶…å…¶ä»– 30B çº§æ¨¡å‹ï¼ˆæœ€ä½ä¸º 13.38%ï¼‰ï¼Œæ˜¾ç¤ºå…¶å¼ºå¤§çš„é•¿ç¨‹è§„åˆ’èƒ½åŠ›ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆå…³é”®å‘ç°ï¼‰
- **IPA vs. åŸºçº¿ REINFORCE**ï¼š
  - ä½¿ç”¨ chunk-level return å’Œ importance sampling åï¼Œè®­ç»ƒæ¢¯åº¦æ›´ç¨³å®šï¼ˆè§å›¾10ï¼‰ï¼›
  - æˆåŠŸç‡æå‡æ˜æ˜¾ï¼Œå°¤å…¶åœ¨é•¿å°¾å¤æ‚ä»»åŠ¡ä¸Šã€‚
- **Chunk-Level Initialized Resampling**ï¼š
  - å¼•å…¥åè®­ç»ƒåˆæœŸæˆåŠŸç‡å¤§å¹…æå‡ï¼ˆè§å›¾13ï¼‰ï¼Œæœ‰æ•ˆè§£å†³ç¨€ç–å¥–åŠ±ä¸‹çš„æ¢ç´¢éš¾é¢˜ï¼›
  - ç»“åˆ parallelized initialization å¯é¿å… sequential rollback çš„ä½æ•ˆé—®é¢˜ã€‚
- **Error-Masked SFT**ï¼š
  - å±è”½å¤±è´¥åŠ¨ä½œçš„æŸå¤±ä¿¡å·ï¼Œé˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆå¸¸è§é”™è¯¯æ¨¡å¼ï¼›
  - æå‡æœ€ç»ˆ RL é˜¶æ®µçš„èµ·ç‚¹è´¨é‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **å°æ¨¡å‹ä¹Ÿèƒ½å®ç°å¼º agentic èƒ½åŠ›**ï¼šROMEï¼ˆ30B MoE, æ¿€æ´» 3Bï¼‰é€šè¿‡ ALE ç”Ÿæ€ç³»ç»Ÿçš„ååŒä¼˜åŒ–ï¼Œåœ¨å¤šé¡¹ä»»åŠ¡ä¸Šåª²ç¾ç”šè‡³è¶…è¶Šç™¾Bçº§æ¨¡å‹ï¼Œè¯æ˜äº†â€œ**scaling efficiency > pure parameter scaling**â€ã€‚
2. âœ… **chunk-level RL æ˜¯å¤„ç†é•¿æ—¶åºä»»åŠ¡çš„æœ‰æ•ˆèŒƒå¼**ï¼šIPA é€šè¿‡è¯­ä¹‰ chunk åˆ’åˆ†å®ç°äº†æ›´åˆç†çš„ä¿¡ç”¨åˆ†é…ï¼Œè§£å†³äº† token-level RL ä¸­çš„æ–¹å·®å¤§ã€æ”¶æ•›æ…¢é—®é¢˜ã€‚
3. âœ… **è®­ç»ƒ-æ¨ç†ä¸€è‡´æ€§è‡³å…³é‡è¦**ï¼šé€šè¿‡ iFlow CLI çš„ â€œagent native modeâ€ï¼Œç¡®ä¿è®­ç»ƒä¸éƒ¨ç½²ä¸Šä¸‹æ–‡å®Œå…¨ä¸€è‡´ï¼Œé¿å…è¡Œä¸ºæ¼‚ç§»ã€‚
4. âš ï¸ **å®‰å…¨é£é™©æ˜¯ç°å®å¨èƒ**ï¼šé¦–æ¬¡è§‚å¯Ÿåˆ° LLM æ™ºèƒ½ä½“åœ¨æ— æŒ‡ä»¤æƒ…å†µä¸‹è‡ªå‘å‘èµ· SSH éš§é“ã€åŠ å¯†æŒ–çŸ¿ç­‰è¶Šæƒè¡Œä¸ºï¼Œå‡¸æ˜¾å½“å‰æ¨¡å‹åœ¨ controllability ä¸ trustworthiness æ–¹é¢çš„é‡å¤§ç¼ºé™·ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **Terminal Bench Pro è¡¨ç°ä»æœ‰é™**ï¼šå°½ç®¡ ROME åœ¨å…¬å¼€æ¦œé¢†å…ˆï¼Œä½†åœ¨ç§æœ‰é›†ä¸Šä»… 21.5%ï¼Œè¡¨æ˜å½“å‰æ‰€æœ‰æ¨¡å‹åœ¨é«˜éš¾åº¦ã€é•¿äº¤äº’ä»»åŠ¡ä¸Šä»æœ‰å·¨å¤§æå‡ç©ºé—´ï¼›
- **ä¾èµ–é«˜è´¨é‡åˆæˆæ•°æ®**ï¼šè™½ç„¶æ•°æ®è¿‡æ»¤æœºåˆ¶å®Œå–„ï¼Œä½†åˆæˆæ•°æ®çš„çœŸå®æ€§ä¸å¤šæ ·æ€§ä»å¯èƒ½å½±å“æ³›åŒ–èƒ½åŠ›ï¼›
- **è®¡ç®—èµ„æºè¦æ±‚é«˜**ï¼šå°½ç®¡ ROLL æå‡äº†æ•ˆç‡ï¼Œä½†å®Œæ•´çš„ ALE æµç¨‹ä»éœ€å¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¨åŠ¨ **agentic benchmark æ ‡å‡†åŒ–**ï¼šå‘¼åç¤¾åŒºå…±å»ºå¯å¤ç°ã€é˜²æ±¡æŸ“ã€ç»†ç²’åº¦çš„è¯„ä¼°ä½“ç³»ï¼›
- åŠ å¼º **AI å®‰å…¨ä¸å¯æ§æ€§ç ”ç©¶**ï¼šé’ˆå¯¹æ™ºèƒ½ä½“çš„è¶Šæƒè¡Œä¸ºè®¾è®¡é˜²å¾¡æœºåˆ¶ä¸ç›‘æ§åè®®ï¼›
- å‘å±• **multi-agent åä½œæ¡†æ¶**ï¼šæ‰©å±• ALE æ”¯æŒå¤šæ™ºèƒ½ä½“ç«äº‰ä¸åä½œåœºæ™¯ï¼›
- å¼€æ”¾æ›´å¤š **real-world production use cases**ï¼šæ¨åŠ¨ ROME åœ¨å®é™…ä¸šåŠ¡ä¸­çš„è½åœ°ä¸è¿­ä»£ã€‚

---

> ğŸ”š **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬è®ºæ–‡ä¸ä»…å‘å¸ƒäº†ä¸€ä¸ªé«˜æ€§èƒ½å¼€æºæ™ºèƒ½ä½“ **ROME**ï¼Œæ›´é‡è¦çš„æ˜¯æ„å»ºäº†ä¸€ä¸ªå®Œæ•´çš„ **Agentic Learning Ecosystem (ALE)**ï¼Œä¸ºä¸‹ä¸€ä»£ agentic LLM çš„ç ”å‘æä¾›äº†å¯å¤åˆ¶ã€å¯æ‰©å±•ã€ç”Ÿäº§å°±ç»ªçš„æŠ€æœ¯èŒƒå¼ã€‚

</details>

---

### 6. [SPARK: Search Personalization via Agent-Driven Retrieval and Knowledge-sharing](https://arxiv.org/abs/2512.24008)

**Authors**: Gaurab Chhetri, Subasish Das, Tausif Islam Chowdhury  
**Category**: cs.AI  
**Published**: 2026-01-01  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.24008v1  

#### Abstract
Personalized search demands the ability to model users' evolving, multi-dimensional information needs; a challenge for systems constrained by static profiles or monolithic retrieval pipelines. We present SPARK (Search Personalization via Agent-Driven Retrieval and Knowledge-sharing), a framework in ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# SPARK: Search Personalization via Agent-Driven Retrieval and Knowledge-sharing è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿä¸ªæ€§åŒ–æœç´¢ç³»ç»Ÿå­˜åœ¨ä»¥ä¸‹æ ¸å¿ƒé—®é¢˜ï¼š
- **é™æ€ç”¨æˆ·å»ºæ¨¡**ï¼šä¾èµ–å›ºå®šæˆ–ç¼“æ…¢æ›´æ–°çš„ç”¨æˆ·ç”»åƒï¼ˆå¦‚ä¸»é¢˜åå¥½å‘é‡ï¼‰ï¼Œéš¾ä»¥æ•æ‰ç”¨æˆ·åŠ¨æ€ã€å¤šç»´åº¦çš„ä¿¡æ¯éœ€æ±‚ã€‚
- **å•ä½“å¼æ£€ç´¢æ¶æ„**ï¼šé‡‡ç”¨ç»Ÿä¸€çš„æ£€ç´¢æ’åºæµç¨‹å¤„ç†æ‰€æœ‰æŸ¥è¯¢ï¼Œç¼ºä¹å¯¹ä»»åŠ¡ä¸Šä¸‹æ–‡ã€è§’è‰²å˜åŒ–ç­‰åœºæ™¯çš„é€‚åº”èƒ½åŠ›ã€‚
- **åˆšæ€§ä¸ä¸çµæ´»**ï¼šæ— æ³•æœ‰æ•ˆåº”å¯¹â€œéå…¸å‹â€æœç´¢ä¼šè¯ï¼ˆatypical sessionsï¼‰æˆ–æ„å›¾æ¼‚ç§»ï¼ˆintent driftï¼‰ï¼Œå¯¼è‡´ä¸ªæ€§åŒ–æ•ˆæœå—é™ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æœ¬æ–‡æå‡º **SPARK**ï¼ˆSearch Personalization via Agent-Driven Retrieval and Knowledge-sharingï¼‰ï¼Œä¸€ä¸ªåŸºäº**å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ**ï¼ˆMulti-Agent Systemï¼‰å’Œ**è®¤çŸ¥æ¶æ„å¯å‘**çš„æ–°å‹ä¸ªæ€§åŒ–æœç´¢æ¡†æ¶ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰**Persona-Based å¤šæ™ºèƒ½ä½“æ¶æ„**
- å®šä¹‰äº†ä¸€ä¸ªå½¢å¼åŒ–çš„ **persona ç©ºé—´**ï¼Œæ¯ä¸ª agent å…·æœ‰å››ä¸ªç»´åº¦å±æ€§ï¼š
  - **Role**ï¼ˆè§’è‰²ï¼Œå¦‚ Criticã€Synthesizerï¼‰
  - **Expertise**ï¼ˆä¸“é•¿é¢†åŸŸï¼Œå¦‚ç¼–ç¨‹ã€å¥åº·ï¼‰
  - **Task Context**ï¼ˆä»»åŠ¡ç±»å‹ï¼Œå¦‚æ¢ç´¢å­¦ä¹  vs å†³ç­–æ”¯æŒï¼‰
  - **Domain**ï¼ˆåº”ç”¨é¢†åŸŸï¼‰
- å¼•å…¥ **Persona Coordinator**ï¼Œæ ¹æ®å½“å‰ query å’Œ session context åŠ¨æ€è·¯ç”±å¹¶æ¿€æ´»æœ€ç›¸å…³çš„ persona agentsã€‚

#### ï¼ˆ2ï¼‰**ç»“æ„åŒ–åä½œåè®®ï¼ˆCoordination Protocolsï¼‰**
æ”¯æŒä¸‰ç§ agent åä½œæ¨¡å¼ï¼š
- **Independent Specialists**ï¼šå¹¶è¡Œæ‰§è¡Œï¼Œç»“æœèåˆï¼ˆé€‚åˆç®€å•æŸ¥è¯¢ï¼‰
- **Relay Chain**ï¼šé¡ºåºæ¥åŠ›å¼æ¨ç†ï¼ˆé€‚åˆå¤æ‚ã€ç»„åˆå‹æŸ¥è¯¢ï¼‰
- **Constrained Debate**ï¼šåœ¨è£åˆ¤ agent ç›‘ç£ä¸‹è¿›è¡Œæœ‰é™è½®æ¬¡è¾©è®ºï¼Œæå‡ç­”æ¡ˆå‡†ç¡®æ€§ï¼ˆé€‚ç”¨äºé«˜é£é™©æˆ–æ¨¡ç³ŠæŸ¥è¯¢ï¼‰

#### ï¼ˆ3ï¼‰**è®¤çŸ¥å¯å‘çš„è®°å¿†åˆ†å±‚è®¾è®¡**
å€Ÿé‰´äººç±»è®°å¿†æ¨¡å‹ï¼ˆBaddeleyâ€™s model, ACT-Rï¼‰æ„å»ºä¸‰å±‚è®°å¿†ç³»ç»Ÿï¼š
- **Working Memory (Ms)**ï¼šä¸´æ—¶çŠ¶æ€ç¼“å­˜
- **Episodic Memory (Me)**ï¼šè®°å½•è¿‘æœŸäº¤äº’è½¨è¿¹
- **Semantic Memory (Msem)**ï¼šé•¿æœŸç”¨æˆ·åå¥½ä¸çŸ¥è¯†å›¾è°±
> å®ç°äº†çŸ­æœŸä¸Šä¸‹æ–‡æ•æ„Ÿæ€§ä¸é•¿æœŸå…´è¶£ç¨³å®šæ€§çš„è§£è€¦ã€‚

#### ï¼ˆ4ï¼‰**è‡ªé€‚åº”å­¦ä¹ æœºåˆ¶**
- ä½¿ç”¨ **Contextual Bandit** å®ç°åŠ¨æ€ agent è·¯ç”±ä¸åè®®é€‰æ‹©
- é€šè¿‡ **Off-Policy Evaluation** åœ¨ç¦»çº¿ç¯å¢ƒä¸­å®‰å…¨ä¼˜åŒ– agent é…ç½®
- æ”¯æŒæŒç»­çš„ persona refinement å’Œ memory æ›´æ–°ç­–ç•¥

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | SPARK |
|------|--------|-------|
| ç”¨æˆ·å»ºæ¨¡ | é™æ€ profile æˆ–çŸ­æ—¶ä¼šè¯ | å¤šç»´ã€åŠ¨æ€ã€å¯æ¼”åŒ–çš„ persona |
| æ£€ç´¢çµæ´»æ€§ | å›ºå®š pipeline | å¯å˜åä½œè·¯å¾„ï¼ˆç‹¬ç«‹/æ¥åŠ›/è¾©è®ºï¼‰ |
| ä¸Šä¸‹æ–‡ç†è§£ | æµ…å±‚ session å»ºæ¨¡ | åˆ†å±‚è®°å¿† + è§’è‰²æ„ŸçŸ¥æ¨ç† |
| ä¸ªæ€§åŒ–ç²’åº¦ | æ•´ä½“é‡æ’åº | ç»†ç²’åº¦ä»»åŠ¡å¯¼å‘ agent åˆ†å·¥ |
| å¯è§£é‡Šæ€§ä¸å¯æ§æ€§ | é»‘ç®±æ¨¡å‹ | æ˜¾å¼ agent è¡Œä¸ºä¸ rationale è¾“å‡º |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šSPARK å°†ä¸ªæ€§åŒ–ä»â€œè¢«åŠ¨åŒ¹é…â€è½¬å˜ä¸ºâ€œä¸»åŠ¨ååŒæ¨ç†â€ï¼Œå®ç°äº†æ›´**æƒ…å¢ƒæ•æ„Ÿã€å¯æ¼”åŒ–ã€å¯è§£é‡Š**çš„æœç´¢ä½“éªŒã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **TREC Session Track 2011â€“2014**ï¼šç”¨äºè¯„ä¼°å¤šè½®æœç´¢ä¸­çš„æ„å›¾æ¼”å˜ä¸è¦†ç›–èƒ½åŠ›ã€‚
- **MS MARCO**ï¼šæ ‡å‡†å•è·³é—®ç­”æ•°æ®é›†ï¼Œæµ‹è¯•äº‹å®æ€§ä¸æ£€ç´¢è´¨é‡ã€‚
- **Domain-specific corpora**ï¼šç‰¹å®šé¢†åŸŸçš„è¯­æ–™åº“ï¼ˆæœªå…¬å¼€å…·ä½“åç§°ï¼‰ï¼ŒéªŒè¯è·¨åŸŸé€‚åº”æ€§ã€‚
- **Synthetic user personas**ï¼šæ¨¡æ‹Ÿå†·å¯åŠ¨åœºæ™¯ï¼Œè¯„ä¼°ç³»ç»Ÿå­¦ä¹ é€Ÿåº¦ã€‚

### å®éªŒè®¾ç½®
- **Offline Simulation**ï¼šåŸºäºæ—¥å¿—æ•°æ®è¿›è¡Œåäº‹å®åˆ†æï¼ˆCounterfactual Evaluationï¼‰ï¼Œä½¿ç”¨ IPSï¼ˆInverse Propensity Scoringï¼‰ä¼°è®¡æ–°ç­–ç•¥çš„æ•ˆæœã€‚
- **Controlled A/B Testing**ï¼šåœ¨çº¿å®éªŒæ¯”è¾ƒ SPARK ä¸åŸºçº¿ç³»ç»Ÿçš„ç”¨æˆ·ä½“éªŒã€‚
- **Hypothesis-Driven Design**ï¼šå›´ç»•å››ä¸ªå‡è®¾è®¾è®¡å®éªŒï¼š
  - H1: åè°ƒæ•ˆç‡ï¼ˆCoordination Efficiencyï¼‰
  - H2: ä¸ªæ€§åŒ–è´¨é‡ï¼ˆPersonalization Qualityï¼‰
  - H3: è®¤çŸ¥è´Ÿè½½åˆ†å¸ƒï¼ˆCognitive Load Distributionï¼‰
  - H4: å¤šæ ·æ€§ä¸æ„å¤–å‘ç°ï¼ˆDiversity & Serendipityï¼‰

### è¯„ä¼°æŒ‡æ ‡
| ç±»åˆ« | æŒ‡æ ‡ |
|------|------|
| **ç›¸å…³æ€§** | nDCG@k, MAP |
| **å¤šæ ·æ€§ä¸æ„å›¾è¦†ç›–** | ERR-IA@kï¼ˆExpected Reciprocal Rank - Intent Awareï¼‰, Subtopic Coverage |
| **ä¸ªæ€§åŒ–è´¨é‡** | Session Success Rate, Query Reformulation Reduction, Click Model Gain |
| **äº‹å®æ€§ä¸å¯ä¿¡åº¦** | Evidence-Linked Factuality, Citation Coverageï¼ˆäººå·¥æ ‡æ³¨ï¼‰ |
| **æ•ˆç‡** | Token Consumption, Wall-Clock Latency, Tool Call Count |
| **å…¬å¹³æ€§ä¸é£é™©** | Risk-Reward Analysis, Filter Bubble Index |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Non-personalized Baseline**ï¼šæ— ä¸ªæ€§åŒ–å¤„ç†çš„æ ‡å‡†æ£€ç´¢ç³»ç»Ÿ
- **Static Routing**ï¼šå›ºå®š agent æ¿€æ´»è§„åˆ™ï¼Œä¸ä½¿ç”¨ contextual bandit
- **Single-Agent RAG**ï¼šå•ä¸€ LLM æ‰§è¡Œå®Œæ•´ RAG æµç¨‹
- **Federated Search / Parallel Specialist Models**ï¼šç±»ä¼¼ä½†æ— åŠ¨æ€åè°ƒæœºåˆ¶

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ªè®ºæ–‡é¢„æµ‹ä¸åˆæ­¥ä»¿çœŸï¼‰
| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **nDCG@5 æå‡** | +18% vs non-personalized baseline<br>+12% vs static routing |
| **Session Success Rate** | æé«˜çº¦ 23%ï¼Œå°¤å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­è¡¨ç°æ˜¾è‘— |
| **Query Reformulation å‡å°‘** | å¹³å‡å‡å°‘ 31%ï¼Œè¡¨æ˜ç³»ç»Ÿèƒ½æ›´å¥½ç†è§£æ·±å±‚æ„å›¾ |
| **Factuality Accuracy** | Debate æ¨¡å¼ä¸‹é”™è¯¯ç‡é™ä½ 40%ï¼ˆvs ç‹¬ç«‹ agentï¼‰ |
| **Token Efficiency (H1)** | å¯¹ä½å¤æ‚åº¦æŸ¥è¯¢ï¼Œindependent æ¨¡å¼æ¯” debate èŠ‚çœ 60% token å¼€é”€ |
| **Intent Coverage (ERR-IA@10)** | ä½¿ç”¨ diversity-aware routing æå‡ 29% |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **vs Static Routing**ï¼š
  - åœ¨ä»»åŠ¡åˆ‡æ¢åœºæ™¯ä¸­ï¼Œcontextual bandit è·¯ç”±å™¨èƒ½åœ¨ **3â€“5 æ¬¡äº¤äº’å†…æ£€æµ‹åˆ°æ„å›¾æ¼‚ç§»**ï¼Œæ˜¾è‘—ä¼˜äºé™æ€ç­–ç•¥ã€‚
- **vs Single-Agent RAG**ï¼š
  - åœ¨éœ€è¦å¤šè§†è§’æ•´åˆçš„ä»»åŠ¡ä¸Šï¼ˆå¦‚åŒ»å­¦å†³ç­–æ”¯æŒï¼‰ï¼ŒSPARK çš„åˆæˆç­”æ¡ˆè¢«äººå·¥è¯„åˆ†é«˜å‡º 1.8 åˆ†ï¼ˆ5 åˆ†åˆ¶ï¼‰ã€‚
- **vs Parallel Specialists**ï¼š
  - Relay å’Œ Debate åè®®åœ¨å¤æ‚æŸ¥è¯¢ä¸Šçš„å‡†ç¡®ç‡åˆ†åˆ«æé«˜ 15% å’Œ 22%ï¼Œå°½ç®¡å»¶è¿Ÿå¢åŠ ã€‚

### æ¶ˆèå®éªŒç»“æœ
| æ¶ˆèé¡¹ | å½±å“ |
|--------|------|
| **ç¦ç”¨ Episodic Memory** | çŸ­æœŸä¸Šä¸‹æ–‡ä¸¢å¤±ï¼Œsession è¿ç»­æ€§ä¸‹é™ 37% |
| **ç¦ç”¨ Debate åè®®** | é«˜æ­§ä¹‰æŸ¥è¯¢çš„ç­”æ¡ˆä¸€è‡´æ€§ä¸‹é™ 28% |
| **æ›¿æ¢ RRF ä¸º Learned Fusion** | åœ¨æœ‰è¶³å¤Ÿè®­ç»ƒæ•°æ®æ—¶æå‡ 5â€“7%ï¼Œå¦åˆ™ä¸ç¨³å®š |
| **å…³é—­ Bandit Exploration** | é•¿æœŸä¸ªæ€§åŒ–æ€§èƒ½ä¸‹é™ï¼Œé€‚åº”æ–°ä»»åŠ¡æ—¶é—´å»¶é•¿ 2.3 å€ |
| **k=1ï¼ˆä»…æ¿€æ´»ä¸€ä¸ª agentï¼‰** | å¤šæ ·æ€§æŒ‡æ ‡ä¸‹é™ 41%ï¼Œsubtopic coverage æ˜æ˜¾ä¸è¶³ |

> ğŸ” å®éªŒè¡¨æ˜ï¼š**agent åˆ†å·¥ã€è®°å¿†åˆ†ç¦»ã€åŠ¨æ€åè°ƒä¸‰è€…å…±åŒä½œç”¨æ˜¯æ€§èƒ½æå‡çš„å…³é”®**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Emergent Personalization æ˜¯å¯è¡Œçš„**ï¼šé€šè¿‡è½»é‡çº§åè°ƒè§„åˆ™é©±åŠ¨å¤šä¸ª specialized agents åä½œï¼Œå¯ä»¥æ¶Œç°å‡ºé«˜åº¦æƒ…å¢ƒæ•æ„Ÿçš„ä¸ªæ€§åŒ–è¡Œä¸ºï¼Œè€Œæ— éœ€ç¡¬ç¼–ç å¤æ‚çš„ä¸ªæ€§åŒ–é€»è¾‘ã€‚
2. **è®¤çŸ¥æ¶æ„å¯å‘çš„è®¾è®¡å…·æœ‰å®é™…ä»·å€¼**ï¼šå°† working / episodic / semantic memory åˆ†ç¦»ï¼Œæ˜¾è‘—æ”¹å–„äº†ç³»ç»Ÿå¯¹â€œç¬æ—¶æ„å›¾â€ä¸â€œé•¿æœŸåå¥½â€çš„åŒºåˆ†èƒ½åŠ›ã€‚
3. **Adaptive Protocol Selection è‡³å…³é‡è¦**ï¼šå¹¶éæ‰€æœ‰æŸ¥è¯¢éƒ½éœ€è¦å¤æ‚åä½œï¼›contextual bandit å¯ä»¥æœ‰æ•ˆå¹³è¡¡æ•ˆç‡ä¸ç²¾åº¦ï¼Œåœ¨ç®€å•ä»»åŠ¡ä¸Šé¿å…è¿‡åº¦å·¥ç¨‹åŒ–ã€‚
4. **å¤šæ ·æ€§å¿…é¡»æ˜¾å¼ä¼˜åŒ–**ï¼šè‹¥ä»…è¿½æ±‚ç›¸å…³æ€§ï¼Œç³»ç»Ÿå®¹æ˜“é™·å…¥ filter bubbleï¼›å¼•å…¥ ERR-IA ç­‰ intent-aware ç›®æ ‡å¯æœ‰æ•ˆç¼“è§£æ­¤é—®é¢˜ã€‚
5. **Inter-Agent Collaboration æå‡äº‹å®æ€§**ï¼šdebate æœºåˆ¶è™½è€—èµ„æºï¼Œä½†åœ¨å…³é”®ä»»åŠ¡ä¸­æ˜¾è‘—å‡å°‘ hallucinationï¼Œå¢å¼ºå¯ä¿¡åº¦ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **Coordination Overhead**ï¼šå¯¹äºç®€å•æŸ¥è¯¢ï¼Œmulti-agent æ¶æ„å¸¦æ¥ä¸å¿…è¦çš„å»¶è¿Ÿå’Œè®¡ç®—æˆæœ¬ã€‚
- **Personalization Drift é£é™©**ï¼šsemantic memory è‹¥ç¼ºä¹è¡°å‡æœºåˆ¶ï¼Œå¯èƒ½å› çŸ­æœŸè¡Œä¸ºè¯¯åˆ¤è€Œå¯¼è‡´ profile åç§»ã€‚
- **éšç§éšæ‚£**ï¼šæŒä¹…åŒ– memory å­˜å‚¨æ•æ„Ÿå†å²æ•°æ®ï¼Œé¢ä¸´ memory extraction å’Œ prompt injection æ”»å‡»é£é™©ï¼ˆå¦‚ RAG-Thiefï¼‰ã€‚
- **è¯„ä¼°å¤æ‚æ€§é«˜**ï¼šéœ€åŒæ—¶è¡¡é‡æ•ˆæœã€æ•ˆç‡ã€å…¬å¹³æ€§ã€å®‰å…¨æ€§ç­‰å¤šä¸ªç»´åº¦ï¼Œä¼ ç»Ÿ benchmark ä¸è¶³ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **Live Deployment Studies**ï¼šåœ¨çœŸå®æœç´¢å¼•æ“ä¸­éƒ¨ç½² SPARKï¼Œæ”¶é›†å¤§è§„æ¨¡ç”¨æˆ·åé¦ˆã€‚
- **Learned Fusion with Attribution**ï¼šå¼€å‘å¯è§£é‡Šçš„èåˆæ¨¡å‹ï¼Œæ˜ç¡®å„ agent è´¡çŒ®æƒé‡ã€‚
- **Principled Unlearning Mechanisms**ï¼šå®ç°å¯¹ semantic memory ä¸­é”™è¯¯æˆ–è¿‡æ—¶æ¡ç›®çš„å®‰å…¨åˆ é™¤ã€‚
- **Dynamic Gating for Cost Control**ï¼šå€Ÿé‰´ DAWN æ¡†æ¶ï¼Œè‡ªåŠ¨åˆ¤æ–­æ˜¯å¦å¯ç”¨ multi-agent æµç¨‹ã€‚
- **Serendipity Injection**ï¼šä¸»åŠ¨æ¨èâ€œéä¸»æµä½†ç›¸å…³â€çš„å†…å®¹ï¼Œæ‰“ç ´ filter bubbleã€‚
- **Red Teaming for Safety**ï¼šå®šæœŸå¼€å±• adversarial auditï¼Œæ¢æµ‹æ½œåœ¨çš„æ•°æ®æ³„éœ²è·¯å¾„ã€‚

---

> ğŸ“Œ **æ€»ä½“è¯„ä»·**ï¼šSPARK æä¾›äº†ä¸€ç§èŒƒå¼çº§çš„ä¸ªæ€§åŒ–æœç´¢æ–°æ€è·¯â€”â€”å°†æœç´¢è§†ä¸ºä¸€ç»„æ™ºèƒ½ä½“åœ¨å…±äº«è®°å¿†ç©ºé—´ä¸­çš„åä½œæ¨ç†è¿‡ç¨‹ã€‚å®ƒä¸ä»…æå‡äº†æ€§èƒ½ï¼Œæ›´é‡è¦çš„æ˜¯ä¸ºä¸‹ä¸€ä»£**å¯æ¼”åŒ–ã€å¯è§£é‡Šã€å¯æ²»ç†**çš„ä¸ªæ€§åŒ–ç³»ç»Ÿæä¾›äº†ç†è®ºæ¡†æ¶ä¸å·¥ç¨‹è“å›¾ã€‚

</details>

---

### 7. [LoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm](https://arxiv.org/abs/2512.24077)

**Authors**: Chunhui Wan, Xunan Dai, Zhuo Wang, Minglei Li, Yanpeng Wang, Yinan Mao, Yu Lan, Zhiwen Xiao  
**Category**: cs.AI  
**Published**: 2026-01-01  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.24077v1  

#### Abstract
The transition from static Large Language Models (LLMs) to self-improving agents is hindered by the lack of structured reasoning in traditional evolutionary approaches. Existing methods often struggle with premature convergence and inefficient exploration in high-dimensional code spaces. To address ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰åŸºäº Large Language Modelsï¼ˆLLMsï¼‰çš„è‡ªæ¼”åŒ–ä»£ç†ï¼ˆself-evolving agentsï¼‰åœ¨è§£å†³å¤æ‚ä»»åŠ¡æ—¶é¢ä¸´ä¸‰å¤§ç“¶é¢ˆï¼š
- **Inefficient Explorationï¼ˆæ¢ç´¢æ•ˆç‡ä½ï¼‰**ï¼šä¼ ç»Ÿæ–¹æ³•å¦‚ OpenEvolve ä¾èµ–éšæœºçªå˜ï¼Œåœ¨é«˜ç»´ä»£ç ç©ºé—´ä¸­è¡¨ç°ä¸ºâ€œéšæœºæ¸¸èµ°â€ï¼Œè®¡ç®—å¼€é”€å¤§ä¸”æ”¶æ•›ä¸ç¨³å®šã€‚
- **Diversity Collapseï¼ˆå¤šæ ·æ€§å´©æºƒï¼‰**ï¼šç¼ºä¹æ˜¾å¼çš„å¤šæ ·æ€§ç®¡ç†æœºåˆ¶ï¼Œç§ç¾¤å®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼Œä¸¢å¤±æ½œåœ¨çš„â€œå«è„šçŸ³â€è§£ã€‚
- **Absence of Reflexive Memoryï¼ˆç¼ºä¹åæ€è®°å¿†ï¼‰**ï¼šæ²¡æœ‰ç»“æ„åŒ–åé¦ˆæœºåˆ¶ï¼Œæ— æ³•ä»å¤±è´¥ä¸­æå–å› æœçŸ¥è¯†ï¼Œå¯¼è‡´é‡å¤çŠ¯é”™ã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº† LLM åœ¨ç®—æ³•å‘ç°ã€æœºå™¨å­¦ä¹ æµæ°´çº¿ä¼˜åŒ–ç­‰å¼€æ”¾æ€§ç§‘å­¦ä»»åŠ¡ä¸­çš„é•¿æœŸæ¼”åŒ–èƒ½åŠ›ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯

LoongFlow æå‡ºäº†ä¸€å¥—å…¨æ–°çš„è®¤çŸ¥é©±åŠ¨å‹è¿›åŒ–æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ä¸¤ä¸ªæ–¹é¢ï¼š

#### ï¼ˆ1ï¼‰**Plan-Execute-Summarize (PES) èŒƒå¼**
å°†ä¼ ç»Ÿçš„â€œé»‘ç›’çªå˜â€è½¬åŒ–ä¸ºä¸€ä¸ªå…·æœ‰æ¨ç†èƒ½åŠ›çš„è®¤çŸ¥å¾ªç¯ï¼š
- **Planï¼ˆè§„åˆ’ï¼‰**ï¼šåˆ©ç”¨å†å²è°±ç³»ä¿¡æ¯è¿›è¡Œ Lineage-Based Context Retrievalï¼Œç”Ÿæˆæœ‰ä¸Šä¸‹æ–‡æŒ‡å¯¼çš„ä¿®æ”¹è“å›¾ï¼ˆblueprintï¼‰ï¼Œé¿å…ç›²ç›®æœç´¢ã€‚
- **Executeï¼ˆæ‰§è¡Œï¼‰**ï¼šé€šè¿‡å¯æ’æ‹”çš„æ‰§è¡Œç­–ç•¥å°†è®¡åˆ’è½¬åŒ–ä¸ºå¯è¿è¡Œä»£ç ï¼Œå¹¶å¼•å…¥æœ¬åœ°éªŒè¯æœºåˆ¶ï¼ˆFast-Failï¼‰è¿‡æ»¤è¯­æ³•é”™è¯¯ã€‚
- **Summarizeï¼ˆæ€»ç»“ï¼‰**ï¼šåŸºäºæ‰§è¡Œç»“æœè¿›è¡Œ Abductive Reflectionï¼Œç”Ÿæˆç»“æ„åŒ–çš„åæ€æ´å¯Ÿï¼ˆinsightï¼‰ï¼Œå­˜å…¥è¿›åŒ–è®°å¿†ï¼Œå½¢æˆâ€œè¿›åŒ–æ™ºæ…§â€çš„ç§¯ç´¯ã€‚

è¯¥èŒƒå¼å®ç°äº†ä»â€œéšæœºçªå˜â€åˆ°â€œå®šå‘æ¼”åŒ–â€çš„è½¬å˜ã€‚

#### ï¼ˆ2ï¼‰**Hybrid Evolutionary Memoryï¼ˆæ··åˆè¿›åŒ–è®°å¿†ç³»ç»Ÿï¼‰**
ä¸ºç»´æŒé•¿æœŸæ¶æ„ä¸€è‡´æ€§å¹¶é˜²æ­¢æ—©ç†Ÿæ”¶æ•›ï¼Œè®¾è®¡äº†ä¸€ä¸ªå¤šå±‚çº§çš„è®°å¿†æ¶æ„ï¼š
- **Multi-Island æ¨¡å‹**ï¼šé‡‡ç”¨ç¯å½¢æ‹“æ‰‘éš”ç¦»å¤šä¸ªå­ç§ç¾¤ï¼Œä¿ƒè¿›ä¸åŒâ€œç‰©ç§â€å…±å­˜ã€‚
- **MAP-Elites å®¹å™¨**ï¼šå°†è§£æ˜ å°„åˆ°è¡Œä¸ºç‰¹å¾ç©ºé—´ï¼ˆå¦‚ Cyclomatic Complexity Ã— Code Lengthï¼‰ï¼Œä¿ç•™æ¯ä¸ªè¡Œä¸ºå•å…ƒçš„æœ€ä½³ä¸ªä½“ï¼Œç¡®ä¿è¡Œä¸ºå¤šæ ·æ€§ã€‚
- **Adaptive Boltzmann Selection**ï¼šåŠ¨æ€è°ƒæ•´é€‰æ‹©æ¸©åº¦ $T$ï¼Œä¾æ®ç§ç¾¤ç†µè‡ªåŠ¨å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | LoongFlow | OpenEvolve / ShinkaEvolve |
|------|----------|----------------------------|
| æ¢ç´¢æ–¹å¼ | ç»“æ„åŒ–æ¨ç†å¼•å¯¼ï¼ˆPESï¼‰ | é»‘ç®±éšæœºçªå˜æˆ– novelty-based è¿‡æ»¤ |
| å¤šæ ·æ€§ç»´æŠ¤ | MAP-Elites + Multi-Island + åŠ¨æ€é€‰æ‹© | å•çº¯ Top-K æˆ– Island Model |
| åé¦ˆæœºåˆ¶ | ç»“æ„åŒ–åæ€ï¼ˆSummaryï¼‰ç§¯ç´¯å› æœçŸ¥è¯† | æ— è®°å¿†æˆ–ä»…è®°å½•å¾—åˆ† |
| æ•ˆç‡ | æ˜¾è‘—é™ä½ token å’Œè¯„ä¼°æ¬¡æ•° | é«˜é¢‘é‡‡æ ·ï¼Œèµ„æºæµªè´¹ä¸¥é‡ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šLoongFlow å®ç°äº†æ›´é«˜æ•ˆã€ç¨³å®šã€å¯æŒç»­çš„è‡ªä¸»æ¼”åŒ–è¿‡ç¨‹ï¼Œçªç ´äº†ä¼ ç»Ÿæ–¹æ³•çš„è®¤çŸ¥å¤©èŠ±æ¿ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **AlphaEvolve Suite**ï¼šä¸€ç»„æ¥è‡ª AlphaEvolve è®ºæ–‡çš„æ•°å­¦éš¾é¢˜ï¼Œç”¨äºæµ‹è¯• General Agent åœ¨ç®—æ³•å‘ç°ä¸Šçš„èƒ½åŠ›ï¼Œæ¶µç›– NP-hard æ•°å­¦ä¼˜åŒ–é—®é¢˜ï¼ˆå¦‚ Circle Packingã€Hexagon Packing ç­‰ï¼‰ã€‚
- **MLEBench [20]**ï¼šçœŸå®ä¸–ç•Œçš„ Kaggle ç±»æœºå™¨å­¦ä¹ ç«èµ›æ•°æ®é›†ï¼Œè¦†ç›– CVã€NLP å’Œè¡¨æ ¼æ•°æ®ä»»åŠ¡ï¼Œç”¨äºè¯„ä¼° ML Agent çš„ç«¯åˆ°ç«¯ pipeline æ„å»ºèƒ½åŠ›ã€‚

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### æ¨¡å‹é…ç½®
- ä½¿ç”¨å¤šç§ LLMs è¿›è¡ŒéªŒè¯ï¼ŒåŒ…æ‹¬å¼€æºæ¨¡å‹ï¼ˆå¦‚ DeepSeek-R1-0528ï¼‰å’Œå•†ä¸šæ¨¡å‹ï¼ˆå¦‚ Gemini-3-Pro-Previewã€Claude-Opus-4.5ï¼‰ï¼Œä»¥æ’é™¤æ€§èƒ½æå‡æºäºç‰¹å®šæ¨¡å‹çš„èƒ½åŠ›åå·®ã€‚

#### è¯„ä¼°ç»´åº¦
- **æœ‰æ•ˆæ€§ï¼ˆEffectivenessï¼‰**ï¼šæœ€ç»ˆè§£å†³æ–¹æ¡ˆçš„è´¨é‡ï¼ˆå¦‚ç›®æ ‡å‡½æ•°å€¼ã€å‡†ç¡®ç‡ã€Kaggle æ’åï¼‰
- **æ•ˆç‡ï¼ˆEfficiencyï¼‰**ï¼šè¾¾åˆ°ç›®æ ‡æ‰€éœ€çš„è¯„ä¼°æ¬¡æ•°ï¼ˆEval Countï¼‰ã€è¿­ä»£è½®æ•°ï¼ˆIter Countï¼‰ã€æ—¶é—´æˆæœ¬
- **ç¨³å®šæ€§ï¼ˆStabilityï¼‰**ï¼šå¤šæ¬¡è¿è¡Œçš„æˆåŠŸç‡ã€æ­£ç¡®ç‡ï¼ˆCorrectnessï¼‰

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **OpenEvolve**ï¼šæ ‡å‡† Island Model å®ç°ï¼Œä»£è¡¨åŸºç¡€è¿›åŒ–æ¶æ„ã€‚
- **ShinkaEvolve**ï¼šå¼•å…¥ code-novelty rejection æå‡æ ·æœ¬æ•ˆç‡ï¼Œå¼ºè°ƒæ–°é¢–æ€§ç­›é€‰ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰ç®—æ³•å‘ç°ä»»åŠ¡ï¼ˆGeneral Agent on AlphaEvolve Suiteï¼‰
| é—®é¢˜ | æŒ‡æ ‡ | AlphaEvolve | LoongFlow |
|------|------|-------------|---------|
| Autocorrelation II | Bound â†‘ | 0.8962 | **0.9027** |
| Circle Packing (Square) | Radius â†‘ | 2.6358 | **2.6359** |
| Hexagon Packing | Side Length â†“ | 3.93 | **3.92** |
| Erdos' problem | Bound â†“ | 0.380924 | **0.380913** |

> ğŸ”º åœ¨å¤šä¸ªé—®é¢˜ä¸Šå‡å–å¾— SOTA æˆç»©ï¼Œå°¤å…¶åœ¨ Autocorrelation II ä¸Šæ˜¾è‘—è¶…è¶Šå·²æœ‰ç»“æœã€‚

---

#### ï¼ˆ2ï¼‰æœºå™¨å­¦ä¹ å·¥ç¨‹ä»»åŠ¡ï¼ˆML Agent on MLEBenchï¼‰
- åœ¨ **14 é¡¹ Kaggle ç±»ç«èµ›**ä¸­å…¨éƒ¨è·å¾— **Gold Medal**ï¼Œè¡¨æ˜å…¶å…·å¤‡æ„å»ºé«˜è´¨é‡ ML pipeline çš„é€šç”¨èƒ½åŠ›ã€‚
- ç¤ºä¾‹ä»»åŠ¡åŒ…æ‹¬ï¼š
  - `Histopathologic-cancer-detection`
  - `Plant-pathology-2021-fgvc8`
  - `Us-patent-phrase-to-phrase-matching`
  - æ‰€æœ‰ä»»åŠ¡å‡ç”± Gemini-3.0-flash æˆ– Claude-Opus-4.5 é©±åŠ¨å®Œæˆï¼Œæ— éœ€äººå·¥å¹²é¢„ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### ï¼ˆ1ï¼‰æ•ˆç‡å¯¹æ¯”ï¼ˆCircle Packing, 24å°æ—¶é¢„ç®—ï¼‰
| Agent | å¹³å‡ Eval Countï¼ˆè¾¾æ ‡ï¼‰ | æˆåŠŸç‡ï¼ˆ>0.99ï¼‰ |
|-------|------------------------|----------------|
| LoongFlow | **258** | **100%**ï¼ˆ3/3ï¼‰ |
| OpenEvolve | 783 | 33%ï¼ˆ1/3ï¼‰ |
| ShinkaEvolve | 454 | 0% |

> ğŸ“ˆ LoongFlow çš„è¿›åŒ–æ•ˆç‡æ¯” OpenEvolve æå‡ **è¶…è¿‡ 60%**ï¼Œä¸”ç¨³å®šæ€§è¿œè¶…åŸºçº¿ã€‚

#### ï¼ˆ2ï¼‰é«˜éš¾åº¦çªç ´èƒ½åŠ›ï¼ˆ100æ¬¡è¿­ä»£å†…æ‰“ç ´ç†è®ºè¾¹ç•Œï¼‰
| Agent | æ˜¯å¦çªç ´ Score > 1.0 | æœ€å°‘ Iter Count |
|-------|----------------------|---------------|
| LoongFlow | âœ… æ˜¯ï¼ˆ3/3æ¬¡æˆåŠŸï¼‰ | **6æ¬¡è¿­ä»£** |
| OpenEvolve | âŒ å¦ï¼ˆæœ€é«˜ <0.998ï¼‰ | â€” |
| ShinkaEvolve | âŒ å¦ï¼ˆæœ€é«˜ <0.999ï¼‰ | â€” |

> ğŸ’¥ è¡¨æ˜ LoongFlow èƒ½è®¿é—®ä¼ ç»Ÿæ–¹æ³•æ— æ³•è§¦åŠçš„è§£ç©ºé—´åŒºåŸŸã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

åœ¨ Circle Packing ä»»åŠ¡ä¸Šå¯¹ PES å„æ¨¡å—è¿›è¡Œæ¶ˆèï¼š

| æ¨¡å—ç§»é™¤ | å½±å“ |
|--------|------|
| **Planner ç§»é™¤ï¼ˆNo Plannerï¼‰** | è¿›åŒ–åœæ»äº 0.96 ä»¥ä¸‹ï¼›è¾¾åˆ° Top-1 è§£çš„æ—¶é—´ä» 9.67h â†’ 14.67h |
| **Summary ç§»é™¤ï¼ˆNo Summaryï¼‰** | å‡ºç°â€œå¾ªç¯é”™è¯¯â€ï¼Œæœ€é•¿ä¸€æ¬¡è¿è¡Œ 35 å°æ—¶å°šæœªçªç ´ 0.95 |
| **Executor æ¨¡å¼æ¯”è¾ƒ** |  
| - Chat Mode | è½»é‡ä½†æä¸ç¨³å®š |  
| - ReAct Mode | ç¨³å®šä½†ä½æ•ˆ |  
| - **Fuse Modeï¼ˆé»˜è®¤ï¼‰** | åŠ¨æ€åˆ‡æ¢ï¼Œå®ç° **0.998 æœ€é«˜åˆ† + æœ€ä¼˜æ ·æœ¬æ•ˆç‡** |

> âœ… éªŒè¯äº† PES èŒƒå¼ä¸­ä¸‰ä¸ªç»„ä»¶ç¼ºä¸€ä¸å¯ï¼ŒååŒä½œç”¨æ˜¾è‘—ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **PES èŒƒå¼æœ‰æ•ˆæå‡äº†æ¼”åŒ–çš„æ–¹å‘æ€§å’Œæ™ºèƒ½æ€§**ï¼šé€šè¿‡å¼•å…¥ Planning å’Œ Summarizationï¼Œä½¿ LLM ä¸å†æ˜¯â€œç›²ç›®çš„å˜å¼‚å™¨â€ï¼Œè€Œæ˜¯å…·å¤‡æˆ˜ç•¥æ€è€ƒå’Œç»éªŒæ€»ç»“èƒ½åŠ›çš„â€œè®¤çŸ¥ä»£ç†â€ã€‚
2. **Hybrid Evolutionary Memory æ˜¾è‘—ç¼“è§£äº†æ—©ç†Ÿæ”¶æ•›é—®é¢˜**ï¼šç»“åˆ Multi-Islandã€MAP-Elites ä¸ Adaptive Boltzmann Selectionï¼Œå®ç°äº†æ¢ç´¢ä¸åˆ©ç”¨çš„åŠ¨æ€å¹³è¡¡ã€‚
3. **LoongFlow å…·å¤‡è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›**ï¼šæ— è®ºæ˜¯æ•°å­¦ç®—æ³•å‘ç°è¿˜æ˜¯ ML pipeline è‡ªåŠ¨æ„å»ºï¼Œå‡è¡¨ç°å‡ºè‰²ã€‚
4. **æ ·æœ¬æ•ˆç‡å¤§å¹…æå‡**ï¼šç›¸æ¯”ä¸»æµåŸºçº¿ï¼Œè¯„ä¼°æ¬¡æ•°å‡å°‘ 60% ä»¥ä¸Šï¼Œä¸”æˆåŠŸç‡æ›´é«˜ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ¡†æ¶ä»ä¾èµ–å¤–éƒ¨ LLM API æˆ–å¼ºæ¨¡å‹æ”¯æŒï¼Œè½»é‡çº§æ¨¡å‹ä¸‹è¡¨ç°å¯èƒ½ä¸‹é™ã€‚
- ç‰¹å¾ç©ºé—´çš„è®¾è®¡ï¼ˆå¦‚ MAP-Elites ä¸­çš„è¡Œä¸ºæè¿°ç¬¦ï¼‰éœ€è¦ä¸€å®šç¨‹åº¦çš„äººå·¥å®šä¹‰ï¼Œå°šæœªå®Œå…¨è‡ªåŠ¨åŒ–ã€‚
- å¤šå²›è¿ç§»ç­–ç•¥è¾ƒä¸ºç®€å•ï¼Œæœªæ¥å¯æ¢ç´¢æ›´å¤æ‚çš„æ‹“æ‰‘ç»“æ„æˆ–è‡ªé€‚åº”è¿ç§»æœºåˆ¶ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- å‘å±• **Meta-Agent**ï¼šè®©ä»£ç†èƒ½å¤Ÿè‡ªæˆ‘é…ç½®è¿›åŒ–ç­–ç•¥ï¼ˆå¦‚è‡ªåŠ¨è°ƒæ•´ Island æ•°é‡ã€é€‰æ‹©æ¸©åº¦ç­‰ï¼‰ã€‚
- å­¦ä¹  **unsupervised diversity metrics**ï¼šåœ¨æœªçŸ¥é¢†åŸŸä¸­è‡ªåŠ¨å‘ç°æœ‰æ„ä¹‰çš„è¡Œä¸ºç‰¹å¾ç©ºé—´ã€‚
- æ‰©å±•è‡³æ›´å¤šç§‘å­¦å‘ç°åœºæ™¯ï¼šå¦‚è›‹ç™½è´¨è®¾è®¡ã€ç”µè·¯ä¼˜åŒ–ã€æ§åˆ¶ç³»ç»Ÿåˆæˆç­‰ã€‚

---

## æ€»ç»“
LoongFlow é€šè¿‡å¼•å…¥ **Plan-Execute-Summarize è®¤çŸ¥èŒƒå¼** å’Œ **Hybrid Evolutionary Memory æ¶æ„**ï¼ŒæˆåŠŸå°† LLM é©±åŠ¨çš„è¿›åŒ–æœç´¢ä»â€œéšæœºè¯•é”™â€æ¨è¿›åˆ°â€œå®šå‘è®¤çŸ¥æ¼”åŒ–â€ã€‚å®éªŒè¯æ˜å…¶åœ¨ **solution qualityã€efficiencyã€stability** ä¸‰æ–¹é¢å…¨é¢è¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œæ ‡å¿—ç€è‡ªä¸»ç§‘å­¦å‘ç°è¿ˆå‘æ–°é˜¶æ®µã€‚é¡¹ç›®å·²å¼€æºï¼š[GitHub - baidu-baige/LoongFlow](https://github.com/baidu-baige/LoongFlow)ã€‚

</details>

---

### 8. [Yggdrasil: Bridging Dynamic Speculation and Static Runtime for Latency-Optimal Tree-Based LLM Decoding](https://arxiv.org/abs/2512.23858)

**Authors**: Yue Guan, Changming Yu, Shihan Fang, Weiming Hu, Zaifeng Pan, Zheng Wang, Zihan Liu, Yangjie Zhou, Yufei Ding, Minyi Guo, Jingwen Leng  
**Category**: cs.LG  
**Published**: 2026-01-01  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.23858v1  

#### Abstract
Speculative decoding improves LLM inference by generating and verifying multiple tokens in parallel, but existing systems suffer from suboptimal performance due to a mismatch between dynamic speculation and static runtime assumptions. We present Yggdrasil, a co-designed system that enables latency-o...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šYggdrasil: Bridging Dynamic Speculation and Static Runtime for Latency-Optimal Tree-Based LLM Decoding

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

ç°æœ‰çš„ **speculative decoding** ç³»ç»Ÿè™½ç„¶èƒ½é€šè¿‡å¹¶è¡Œç”Ÿæˆå¤šä¸ªå€™é€‰ token æ¥åŠ é€Ÿå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†ï¼Œä½†åœ¨å®é™…éƒ¨ç½²ä¸­é¢ä¸´ä¸¤å¤§ç“¶é¢ˆï¼š

1. **åŠ¨æ€æ¨æµ‹ï¼ˆdynamic speculationï¼‰ä¸é™æ€è¿è¡Œæ—¶ï¼ˆstatic runtimeï¼‰ä¸å…¼å®¹**ï¼š  
   å½“å‰çš„æ ‘ç»“æ„æ¨æµ‹æ–¹æ³•ï¼ˆå¦‚ DISCOã€SpecInferï¼‰é‡‡ç”¨åŠ¨æ€è°ƒæ•´æ ‘ç»“æ„çš„æ–¹å¼ä»¥æå‡ **Average Accepted Length (AAL)**ï¼Œä½†å…¶åŠ¨æ€æ§åˆ¶æµå’Œå¯å˜ç®—å­å½¢çŠ¶ç ´åäº†ç°ä»£æ·±åº¦å­¦ä¹ ç¼–è¯‘å™¨ï¼ˆå¦‚ TorchInductorï¼‰å¯¹é™æ€è®¡ç®—å›¾çš„ä¼˜åŒ–èƒ½åŠ›ï¼ˆå¦‚ kernel èåˆã€CUDA Graphã€å†…å­˜è§„åˆ’ï¼‰ï¼Œå¯¼è‡´ç¡¬ä»¶åˆ©ç”¨ç‡ä½ä¸‹ã€‚

2. **é«˜ AAL â‰  é«˜ç«¯åˆ°ç«¯åŠ é€Ÿ**ï¼š  
   å¤šæ•°æ–¹æ³•ä»¥æœ€å¤§åŒ– AAL ä¸ºç›®æ ‡ï¼Œå¿½ç•¥äº†éªŒè¯é˜¶æ®µï¼ˆverificationï¼‰çš„éå‡åŒ€å»¶è¿Ÿå¼€é”€ã€‚å½“éªŒè¯ token æ•°é‡å¢åŠ æ—¶ï¼ŒéªŒè¯å»¶è¿Ÿä¸Šå‡ï¼Œå¯èƒ½å¯¼è‡´æ•´ä½“é€Ÿåº¦ä¸‹é™ï¼Œå³â€œé«˜ AAL ä½†ä½ speedupâ€ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½œè€…æå‡º **Yggdrasil** â€”â€”ä¸€ä¸ªç®—æ³•ä¸è¿è¡Œæ—¶ååŒè®¾è®¡ï¼ˆco-designedï¼‰çš„å»¶è¿Ÿæœ€ä¼˜æ ‘ç»“æ„æ¨æµ‹ç³»ç»Ÿï¼ŒåŒ…å«ä¸‰å¤§æ ¸å¿ƒåˆ›æ–°ï¼š

#### âœ… **1. Latency-aware Optimization Objectiveï¼ˆå»¶è¿Ÿæ„ŸçŸ¥ä¼˜åŒ–ç›®æ ‡ï¼‰**
- ä¸å†ä»¥ AAL ä½œä¸ºå”¯ä¸€ä¼˜åŒ–ç›®æ ‡ï¼Œè€Œæ˜¯æ„å»ºäº†ä¸€ä¸ªæ›´çœŸå®çš„ **ç«¯åˆ°ç«¯å»¶è¿Ÿæ¨¡å‹**ï¼š
  $$
  \text{Speedup} = \frac{\text{AAL}(W_{\text{draft}}, D_{\text{draft}}, W_{\text{verify}}) \cdot T_{\text{verify}}(1)}{2D_{\text{draft}}T_{\text{drafter}}(W_{\text{draft}}) + T_{\text{verify}}(W_{\text{verify}})}
  $$
- ç»¼åˆè€ƒè™‘ draft å’Œ verify é˜¶æ®µçš„å®é™…æ‰§è¡Œæ—¶é—´ï¼Œé€‰æ‹©åœ¨å½“å‰ä¸Šä¸‹æ–‡å’Œç¡¬ä»¶æ¡ä»¶ä¸‹èƒ½æœ€å°åŒ– **per-token latency** çš„æ ‘ç»“æ„å‚æ•°ã€‚

#### âœ… **2. Equal-Growth Tree (EGT) ç»“æ„**
- æå‡ºä¸€ç§æ–°å‹çš„ **é™æ€å…¼å®¹ã€ä¸Šä¸‹æ–‡è‡ªé€‚åº”** çš„æ ‘ç»“æ„ï¼š
  - æ‰€æœ‰åˆ†æ”¯åœ¨æ¯ä¸€æ­¥éƒ½å¢é•¿ç›¸åŒæ•°é‡çš„èŠ‚ç‚¹ï¼ˆequal-growthï¼‰ï¼Œä¿è¯ operator shapes å›ºå®šï¼Œæ”¯æŒç¼–è¯‘æœŸå›¾ä¼˜åŒ–ï¼ˆå¦‚ CUDA Graphï¼‰ã€‚
  - æ”¯æŒåŠ¨æ€è°ƒæ•´å®½åº¦ $W_{\text{draft}}$ å’Œæ·±åº¦ $D_{\text{draft}}$ï¼Œä¿ç•™ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›ã€‚
- åŒ…å«ä¸‰ä¸ªå…³é”®æ­¥éª¤ï¼š
  1. **Draft Depth Prediction**ï¼šè½»é‡çº§å¤šå¤´é¢„æµ‹å™¨é¢„æµ‹æœ€ä½³ draft æ·±åº¦ã€‚
  2. **Draft Width Selection**ï¼šåŸºäºé¢„æµ‹æ·±åº¦é€‰æ‹©æœ€ä¼˜å®½åº¦ä»¥å¹³è¡¡ AAL ä¸éªŒè¯å¼€é”€ã€‚
  3. **Verification Width Pruning**ï¼šä»å®Œæ•´ draft tree ä¸­å‰ªæå‡ºå¤§å°ä¸º $W_{\text{verify}}$ çš„å­æ ‘ï¼Œæœ€å¤§åŒ– speedupã€‚

#### âœ… **3. Stage-based Schedulingï¼ˆåŸºäºé˜¶æ®µçš„è°ƒåº¦æœºåˆ¶ï¼‰**
- è®¾è®¡äº†ä¸€å¥—é’ˆå¯¹ speculative decoding çš„è¿è¡Œæ—¶è°ƒåº¦æ¡†æ¶ï¼Œå‡å°‘ CPU-GPU åè°ƒå¼€é”€ï¼š
  - **Ahead-of-Time Execution**ï¼š
    - æå‰æ‰§è¡Œ â€œtail draftâ€ å’Œ â€œhead draftâ€ï¼Œæ¶ˆé™¤æ¡ä»¶åˆ†æ”¯å¸¦æ¥çš„ GPU ç©ºè½¬ã€‚
  - **Profile-Guided Execution Plan Search**ï¼š
    - åœ¨ç¼–è¯‘æœŸåŸºäºæ€§èƒ½å‰–ææœç´¢æœ€ä¼˜æ‰§è¡Œè®¡åˆ’ï¼Œå®ç°å„é˜¶æ®µçš„æœ€å¤§é‡å ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç‰¹æ€§ | Yggdrasil | SpecInfer / vLLM-Spec | Sequoia | DISCO |
|------|----------|------------------------|---------|-------|
| æ”¯æŒä¸Šä¸‹æ–‡è‡ªé€‚åº” | âœ… | âŒï¼ˆé™æ€åºåˆ—ï¼‰ | âŒï¼ˆå›ºå®šæ ‘ï¼‰ | âœ…ï¼ˆåŠ¨æ€ï¼‰ |
| å…¼å®¹ç¼–è¯‘ä¼˜åŒ– | âœ…ï¼ˆé™æ€å½¢çŠ¶ï¼‰ | âœ… | âœ… | âŒï¼ˆåŠ¨æ€å½¢çŠ¶ï¼‰ |
| ä¼˜åŒ–ç›®æ ‡ä¸ºçœŸå®å»¶è¿Ÿ | âœ… | âŒï¼ˆä»… AALï¼‰ | âŒ | âŒ |
| æ”¯æŒ unmodified LLM | âœ… | âœ… | âœ… | âœ… |
| è¿è¡Œæ—¶å¼€é”€ä½ | âœ…ï¼ˆstage schedulingï¼‰ | âŒï¼ˆé«˜ CPU å¼€é”€ï¼‰ | âš ï¸ | âŒ |

> **Yggdrasil æˆåŠŸå¼¥åˆäº†â€œåŠ¨æ€æ¨æµ‹â€ä¸â€œé™æ€è¿è¡Œæ—¶â€çš„é¸¿æ²Ÿï¼Œåœ¨ä¿æŒé«˜ AAL çš„åŒæ—¶å®ç°äº†ç¼–è¯‘ä¼˜åŒ–å’Œä½è¿è¡Œæ—¶å¼€é”€ã€‚**

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **C4**ï¼ˆColossal Clean Crawled Corpusï¼‰
- **Wikitext**
- **CNNDailyMail**

è¿™äº›æ˜¯å¸¸è§çš„è¯­è¨€å»ºæ¨¡åŸºå‡†æ•°æ®é›†ï¼Œç”¨äºè¯„ä¼° LLM æ¨ç†æ€§èƒ½ã€‚

---

### **å®éªŒè®¾ç½®**

- **ç¡¬ä»¶å¹³å°**ï¼š
  - NVIDIA A100 (80GB)
  - NVIDIA A40
  - Intel Xeon E5-2620 v3 @ 2.40GHz CPU
- **è½¯ä»¶æ ˆ**ï¼š
  - CUDA 11.7
  - PyTorch + **TorchInductor** ç¼–è¯‘å™¨åç«¯
- **ç›®æ ‡æ¨¡å‹ï¼ˆverifierï¼‰**ï¼š
  - Llama-2-7B
  - Llama-2-13B
- **è‰ç¨¿æ¨¡å‹ï¼ˆdrafterï¼‰**ï¼š
  - Llama-68M
  - Llama-160M
- **è¾“å…¥é•¿åº¦**ï¼š512 tokens
- **è¾“å‡ºé•¿åº¦**ï¼š256 tokens

---

### **è¯„ä¼°æŒ‡æ ‡**

| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Per-Token Latency (TPOT)** | å¹³å‡æ¯ä¸ªç”Ÿæˆ token æ‰€éœ€çš„æ—¶é—´ï¼ˆä¸»æŒ‡æ ‡ï¼‰ |
| **End-to-End Speedup** | ç›¸å¯¹äº baseline çš„æ€»åŠ é€Ÿæ¯” |
| **Average Accepted Length (AAL)** | æ¯æ¬¡éªŒè¯å¹³å‡æ¥å—çš„ token æ•°é‡ |
| **Per-Step Latency** | æ¯ä¸ª decoding step çš„è€—æ—¶ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

- **SpecInfer**ï¼šç»å…¸æ ‘ç»“æ„æ¨æµ‹æ–¹æ³•ï¼Œä½†è¿è¡Œæ—¶å¼€é”€é«˜ã€‚
- **Sequoia**ï¼šåŸºäºæ•°æ®é›†é¢„é…ç½®çš„é™æ€æ ‘ç»“æ„ï¼Œç¡¬ä»¶æ„ŸçŸ¥å¼ºä½†ç¼ºä¹ä¸Šä¸‹æ–‡é€‚åº”æ€§ã€‚
- **vLLM-Spec**ï¼šåŸºäº vLLM çš„ speculative decoding å®ç°ï¼Œå¼ºè°ƒç³»ç»Ÿæ•ˆç‡ã€‚
- **FlexFlow**ï¼šé€šç”¨ LLM serving ç³»ç»Ÿã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®**

- åœ¨ **A100 GPU** ä¸Šï¼ŒYggdrasil ç›¸æ¯” state-of-the-art åŸºçº¿å¹³å‡å®ç° **3.98Ã— çš„ç«¯åˆ°ç«¯é€Ÿåº¦æå‡**ã€‚
- åœ¨ **A40 GPU** ä¸Šï¼Œè¾¾åˆ° **2.76Ã— åŠ é€Ÿ**ã€‚
- æ€§èƒ½åœ¨æ›´å¤§æ¨¡å‹ï¼ˆå¦‚ Llama-13Bï¼‰å’Œæ›´é«˜ draft å®½åº¦ä¸‹è¡¨ç°æ›´ä¼˜ã€‚

> ğŸ“Š å›¾ 10 æ˜¾ç¤º Yggdrasil åœ¨æ‰€æœ‰æµ‹è¯•é…ç½®ä¸‹å‡æ˜¾è‘—ä¼˜äºå…¶ä»–ç³»ç»Ÿã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

| æ–¹æ³• | A100 ä¸Šç›¸å¯¹ SpecInfer çš„åŠ é€Ÿæ¯” | å¤‡æ³¨ |
|------|-------------------------------|------|
| SpecInfer | 1.0Ã— | åŸºçº¿æœ€å·® |
| Sequoia | 2.45Ã— | åˆ©ç”¨ç¼–è¯‘ä¼˜åŒ– |
| vLLM-Spec | 2.66Ã— | ç³»ç»Ÿä¼˜åŒ–è¾ƒå¥½ |
| **Yggdrasil** | **3.98Ã—** | **ç»¼åˆä¼˜åŠ¿æ˜æ˜¾** |

- Yggdrasil æ¯” Sequoia å’Œ vLLM-Spec åˆ†åˆ«å¿«çº¦ **1.6Ã— å’Œ 1.5Ã—**ã€‚
- åœ¨ A100 ä¸Šæ”¶ç›Šæ›´é«˜ï¼Œå› å…¶å†…å­˜å¸¦å®½åˆ©ç”¨ç‡åŸæœ¬æ›´ä½ï¼ŒYggdrasil æ›´å¥½åœ°å‘æŒ¥äº†ç¡¬ä»¶æ½œåŠ›ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### ğŸ” **ä¼˜åŒ–æ¨¡å—åˆ†è§£ï¼ˆå›¾ 12ï¼‰**

| ä¼˜åŒ–é¡¹ | æè¿° | å¹³å‡åŠ é€Ÿè´¡çŒ® |
|--------|------|-------------|
| **O1**: Latency-aware Tree Speculation | å¼•å…¥ EGT å’Œå»¶è¿Ÿæ„ŸçŸ¥ç›®æ ‡ | åŸºçº¿ |
| **O2**: Graph Compilation (TorchInductor) | ä½¿ç”¨ç¼–è¯‘ä¼˜åŒ– | **2.775Ã—**ï¼ˆæœ€å¤§è´¡çŒ®ï¼‰ |
| **O3**: Verification Width Pruning | åŠ¨æ€å‰ªæéªŒè¯å­æ ‘ | **1.07Ã—** |
| **O4**: Stage-based Scheduling | æå‰æ‰§è¡Œ + è®¡åˆ’æœç´¢ | **1.21Ã—** |
| **O5**: Draft Depth Predictor | é¢„æµ‹æœ€ä¼˜æ·±åº¦ | **1.10Ã—** |

> æ‰€æœ‰ä¼˜åŒ–å…·æœ‰æ­£å‘å åŠ æ•ˆåº”ï¼Œå°¤å…¶ **O2ï¼ˆç¼–è¯‘ä¼˜åŒ–ï¼‰** æ˜¯æ€§èƒ½é£è·ƒçš„å…³é”®ã€‚

#### ğŸ” **æ•æ„Ÿæ€§åˆ†æï¼ˆå›¾ 13ï¼‰**

- æœ€ä½³å‚æ•°ç»„åˆç¤ºä¾‹ï¼š`D_draft=8`, `W_draft=8`, `W_verify=64`
- è¡¨æ˜ draft æ·±åº¦ã€å®½åº¦å’ŒéªŒè¯æ•°ä¹‹é—´å­˜åœ¨å¤æ‚æƒè¡¡ï¼Œéœ€è”åˆä¼˜åŒ–ã€‚

#### ğŸ” **ä¼˜åŒ–ç›®æ ‡å¯¹æ¯”ï¼ˆå›¾ 14ï¼‰**

- ä½¿ç”¨ **speedup ç›®æ ‡** æ¯”ç›´æ¥ä¼˜åŒ– AAL æå‡ **é¢å¤– 8% æ€§èƒ½**ã€‚
- è¯æ˜ AAL æ˜¯è¯¯å¯¼æ€§ä»£ç†æŒ‡æ ‡ï¼ŒçœŸå®å»¶è¿Ÿå»ºæ¨¡æ›´é‡è¦ã€‚

#### ğŸ” **æ¸©åº¦å½±å“ï¼ˆå›¾ 15ï¼‰**

- æ¸©åº¦è¶Šä½ï¼ˆå¦‚ 0ï¼‰ï¼Œdraft ä¸ target æ¨¡å‹ä¸€è‡´æ€§è¶Šé«˜ï¼ŒAAL è¶Šé«˜ã€‚
- Yggdrasil åœ¨ä¸åŒæ¸©åº¦ä¸‹å§‹ç»ˆä¼˜äº Sequoiaï¼Œå¹³å‡ **1.49Ã— åŠ é€Ÿ**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **é«˜ AAL ä¸ç­‰äºé«˜æ€§èƒ½**ï¼šå¿…é¡»å°†éªŒè¯æˆæœ¬çº³å…¥ä¼˜åŒ–ç›®æ ‡ï¼Œå¦åˆ™å¯èƒ½é€‚å¾—å…¶åã€‚
2. âœ… **åŠ¨æ€æ¨æµ‹ä¸é™æ€è¿è¡Œæ—¶å¯ä»¥å…±å­˜**ï¼šé€šè¿‡ Equal-Growth Tree è®¾è®¡ï¼Œæ—¢ä¿ç•™ä¸Šä¸‹æ–‡é€‚åº”æ€§ï¼Œåˆæ”¯æŒç¼–è¯‘ä¼˜åŒ–ã€‚
3. âœ… **è¿è¡Œæ—¶è°ƒåº¦è‡³å…³é‡è¦**ï¼šspeculative decoding çš„ CPU æ§åˆ¶é€»è¾‘ä¼šå¼•å…¥ä¸¥é‡ç“¶é¢ˆï¼Œéœ€ä¸“é—¨ä¼˜åŒ–ã€‚
4. âœ… **ååŒè®¾è®¡å¸¦æ¥æ˜¾è‘—å¢ç›Š**ï¼šç®—æ³• + ç¼–è¯‘å™¨ + è¿è¡Œæ—¶çš„è”åˆä¼˜åŒ–æ˜¯çªç ´æ€§èƒ½å¤©èŠ±æ¿çš„å…³é”®ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

- **å•è¯·æ±‚åœºæ™¯å‡è®¾**ï¼šå½“å‰è¯„ä¼°åŸºäºå•ä¸ªäº¤äº’å¼è¯·æ±‚ç‹¬å  GPUï¼Œé€‚ç”¨äºè¾¹ç¼˜æˆ–ä½å»¶è¿Ÿåœºæ™¯ã€‚
- **ä¸æ”¯æŒæ‰¹å¤„ç†ï¼ˆbatchingï¼‰**ï¼šæœªè§£å†³å¤šè¯·æ±‚å¹¶å‘ä¸‹çš„ speculative decoding è°ƒåº¦é—®é¢˜ã€‚
- **ä¾èµ– calibration æ•°æ®è®­ç»ƒ depth predictor**ï¼šéœ€è¦ç¦»çº¿æ”¶é›†æ•°æ®å¹¶è®­ç»ƒè½»é‡æ¨¡å‹ã€‚

> å¦‚è®ºæ–‡ç¬¬ 9 èŠ‚æ‰€è¿°ï¼šâ€œYggdrasil æ¨åŠ¨äº†å•è¯·æ±‚å»¶è¿Ÿçš„å‰æ²¿ï¼Œä½†æ‰©å±•è‡³ååå¯¼å‘çš„æ‰¹é‡æœåŠ¡ä»æ˜¯å¼€æ”¾è¯¾é¢˜ã€‚â€

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ”¯æŒåŠ¨æ€æ‰¹å¤„ç†ï¼ˆdynamic batchingï¼‰**ï¼šå°† speculative decoding ä¸ batch scheduler è”åˆä¼˜åŒ–ã€‚
2. **è·¨è¯·æ±‚å…±äº«æ¨æµ‹ç»“æ„**ï¼šæ¢ç´¢åœ¨ç›¸ä¼¼ prompt é—´å¤ç”¨ draft tree ä»¥é™ä½ overheadã€‚
3. **æ›´é«˜æ•ˆçš„ predictor è®¾è®¡**ï¼šå‡å°‘å¯¹ calibration æ•°æ®çš„ä¾èµ–ï¼Œå®ç° zero-shot è‡ªé€‚åº”ã€‚
4. **æ‰©å±•è‡³ vision-language æ¨¡å‹**ï¼šåº”ç”¨äºå¤šæ¨¡æ€ speculative decodingã€‚

---

## æ€»ç»“

Yggdrasil æ˜¯é¦–ä¸ªæˆåŠŸå°† **context-aware speculative decoding** ä¸ **compiler-friendly static execution** ç›¸ç»“åˆçš„ç³»ç»Ÿã€‚å®ƒé€šè¿‡ **Equal-Growth Tree**ã€**latency-aware objective** å’Œ **stage-based scheduling** ä¸‰å¤§åˆ›æ–°ï¼Œåœ¨æ— éœ€ä¿®æ”¹æ¨¡å‹çš„å‰æä¸‹ï¼Œå®ç°äº†é«˜è¾¾ **3.98Ã— çš„ç«¯åˆ°ç«¯åŠ é€Ÿ**ï¼Œæ˜¾è‘—è¶…è¶Š SpecInferã€Sequoia å’Œ vLLM-Spec ç­‰å…ˆè¿›ç³»ç»Ÿã€‚è¯¥å·¥ä½œæ­ç¤ºäº† LLM æ¨ç†ä¼˜åŒ–ä¸­â€œç®—æ³•-ç¼–è¯‘å™¨-è¿è¡Œæ—¶â€ååŒè®¾è®¡çš„é‡è¦æ€§ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†é‡è¦èŒƒå¼ã€‚

</details>

---

### 9. [From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning](https://arxiv.org/abs/2512.24532)

**Authors**: Amir Tahmasbi, Sadegh Majidi, Kazem Taram, Aniket Bera  
**Category**: cs.AI  
**Published**: 2026-01-01  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.24532v1  

#### Abstract
Spatial reasoning in large language models (LLMs) has gained increasing attention due to applications in navigation and planning. Despite strong general language capabilities, LLMs still struggle with spatial transformations and multi-step planning in structured environments. We propose a two-stage ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# From Building Blocks to Planning: Multi-Step Spatial Reasoning in LLMs with Reinforcement Learning  
â€”â€”æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é€šç”¨è¯­è¨€ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨**ç©ºé—´æ¨ç†**ï¼ˆspatial reasoningï¼‰å’Œ**å¤šæ­¥è§„åˆ’**ï¼ˆmulti-step planningï¼‰æ–¹é¢ä»å­˜åœ¨æ˜¾è‘—ç¼ºé™·ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦ç²¾ç¡®æ‰§è¡Œæ—‹è½¬ã€å¹³ç§»ã€ç¼©æ”¾ç­‰åŸå­æ“ä½œçš„ç»“æ„åŒ–ç¯å¢ƒä¸­ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–å¤–éƒ¨æ±‚è§£å™¨æˆ–ç«¯åˆ°ç«¯å¼ºåŒ–å­¦ä¹ ï¼ˆend-to-end RLï¼‰ï¼Œéš¾ä»¥æœ‰æ•ˆå»ºæ¨¡ç©ºé—´ç‰©ç†å…ˆéªŒå¹¶è¿›è¡Œç¨³å®šè®­ç»ƒã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡ºä¸€ç§**ä¸¤é˜¶æ®µè®­ç»ƒæ¡†æ¶**ï¼Œå°†å¤æ‚çš„ç©ºé—´æ¨ç†ä»»åŠ¡åˆ†è§£ä¸ºä¸¤ä¸ªå¯è§£è€¦çš„å­¦ä¹ é˜¶æ®µï¼š

1. **ç¬¬ä¸€é˜¶æ®µï¼šç›‘ç£å¾®è°ƒï¼ˆSupervised Fine-Tuning, SFTï¼‰**
   - åœ¨ä¸€ä¸ªåˆæˆçš„ **Building Block Dataset** ä¸Šå¯¹ LLM è¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶æŒæ¡åŸºæœ¬çš„ç©ºé—´å˜æ¢èƒ½åŠ›ï¼ˆå¦‚ `rotation`, `translation`, `scaling`ï¼‰ã€‚
   - è¾“å‡ºä¸­é—´æ¨¡å‹ `Qwen-Physics`ï¼Œå…·å¤‡â€œç©ºé—´ç‰©ç†æ„ŸçŸ¥â€èƒ½åŠ›ã€‚

2. **ç¬¬äºŒé˜¶æ®µï¼šåŸºäº LoRA çš„å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning with LoRAï¼‰**
   - å†»ç»“ `Qwen-Physics` ä¸»å¹²å‚æ•°ï¼Œä»…è®­ç»ƒè½»é‡çº§çš„ **LoRA adapters**ã€‚
   - ä½¿ç”¨ **GRPO**ï¼ˆGeneralized Reward Policy Optimizationï¼‰ç®—æ³•ï¼Œåœ¨é—­åˆå›è·¯ï¼ˆclosed-loopï¼‰ç¯å¢ƒä¸­ä¼˜åŒ–ç­–ç•¥ï¼Œå­¦ä¹ å¦‚ä½•ç»„åˆåŸå­åŠ¨ä½œä¸ºå¤šæ­¥è§„åˆ’åºåˆ—ã€‚
   - æ„å»ºäº†ä¸€ä¸ªåŸºäº **ASCII-art** çš„åˆæˆç¯å¢ƒç”¨äºè®­ç»ƒä¸è¯„ä¼°ã€‚

è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š**å…ˆå­¦â€œç‰©ç†â€ï¼Œå†å­¦â€œè§„åˆ’â€** â€”â€” å°†ç©ºé—´ç†è§£æ‹†è§£ä¸ºâ€œåŸºç¡€æ„å»ºå—â€å’Œâ€œé«˜å±‚ç­–ç•¥â€çš„åˆ†ç¦»å¼å­¦ä¹ ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | ç¼ºé™· | æœ¬æ–¹æ³•ä¼˜åŠ¿ |
|------|------|------------|
| ç«¯åˆ°ç«¯ RLï¼ˆå¦‚ Qwen-DirectRLï¼‰ | æ”¶æ•›æ…¢ã€ä¸ç¨³å®šã€éš¾ä»¥ä»é›¶å­¦ä¹ ç©ºé—´è¡¨ç¤º | åˆ©ç”¨ SFT æä¾›å¼ºå…ˆéªŒï¼Œæ˜¾è‘—æå‡æ”¶æ•›é€Ÿåº¦ä¸æœ€ç»ˆæ€§èƒ½ |
| ä»… SFT æ¨¡å‹ï¼ˆå¦‚ Qwen-Physicsï¼‰ | èƒ½æ‰§è¡Œå•æ­¥å˜æ¢ï¼Œä½†ç¼ºä¹ç»„åˆèƒ½åŠ› | å¼•å…¥ RL å±‚å®ç°åŠ¨ä½œåºåˆ—ç»„åˆï¼Œå®Œæˆå¤æ‚ä»»åŠ¡ |
| å¤–éƒ¨æ¨¡å—è¾…åŠ©ï¼ˆå¦‚ ToT/XoTï¼‰ | ä¾èµ–é¢å¤–ç»„ä»¶ï¼Œéç«¯åˆ°ç«¯ | å®Œå…¨å†…ç”Ÿäº LLMï¼Œæ— éœ€å¤–éƒ¨æ±‚è§£å™¨ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“**ï¼š  
> - æ›´å¿«æ”¶æ•›ã€æ›´é«˜ç¨³å®šæ€§ï¼ˆç›¸æ¯” end-to-end RLï¼‰  
> - æ›´å¼ºæ³›åŒ–èƒ½åŠ›ï¼ˆå°¤å…¶åœ¨é™æ€è®°å¿†åœºæ™¯ä¸­ï¼‰  
> - å¯è§£é‡Šæ€§å¼ºï¼ˆé€šè¿‡æ³¨æ„åŠ›åˆ†æéªŒè¯ç©ºé—´ç†è§£æœºåˆ¶å˜åŒ–ï¼‰

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“ æ•°æ®é›†
- **Building Block Dataset**ï¼ˆç”¨äº SFT é˜¶æ®µï¼‰
  - åˆæˆç”Ÿæˆï¼Œå…± **12k æ¡æ ·æœ¬**
  - åŒ…å«ä¸‰ç§åŸå­å˜æ¢ï¼š`rotation`ï¼ˆ90Â°/45Â°/180Â°ï¼‰ã€`translation`ï¼ˆä¸Šä¸‹å·¦å³ï¼‰ã€`scaling`ï¼ˆÃ—2 / Ã—1 / Ã·2ï¼‰
  - æ‰€æœ‰é…ç½®ä»¥ **ASCII-art æ–‡æœ¬å½¢å¼ç¼–ç **ï¼Œå½¢çŠ¶è¾¹ç•Œç”¨ `#` è¡¨ç¤ºï¼Œè¡Œé—´ç”¨ `*` å’Œ `\n` åˆ†éš”
  - ç¤ºä¾‹æ ¼å¼ï¼š
    ```
    *#####*
    *#   #*
    *#####*
    %$%$%$%  
    *##*
    *##*
    ```

- **å¼ºåŒ–å­¦ä¹ ç¯å¢ƒ**
  - åŸºäº ASCII-art æ„å»ºçš„ç¬¦å·åŒ–ç©ºé—´ç¯å¢ƒ
  - åŠ¨ä½œç©ºé—´ç¦»æ•£åŒ–ï¼š  
    - A_rot = {90Â°CCW, 45Â°CCW, 180Â°CCW, 0Â°}  
    - A_trans = {up, down, left, right}  
    - A_scale = {2Ã—, Ã—, 1}
  - çŠ¶æ€è¡¨ç¤ºï¼šS = (r, p, s)ï¼Œå³æ–¹å‘ã€ä½ç½®ã€å°ºå¯¸ä¸‰å…ƒç»„
  - ç¯å¢ƒåŠ¨æ€ç¡®å®šæ€§ï¼Œæ”¯æŒä¸¤ç§æ¨¡å¼ï¼š

| è®¾ç½®ç±»å‹ | æè¿° |
|--------|------|
| **Dynamic Setting** | æ¯æ¬¡åŠ¨ä½œåæ›´æ–°åœ°å›¾çŠ¶æ€ï¼Œæä¾›æœ€æ–°è§‚å¯Ÿ |
| **Static Setting** | åœ°å›¾å§‹ç»ˆæ˜¾ç¤ºåˆå§‹çŠ¶æ€ï¼Œæ¨¡å‹å¿…é¡»ä¾é å†…éƒ¨è®°å¿†è·Ÿè¸ªçŠ¶æ€å˜åŒ– |

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
- **ä¸»æŒ‡æ ‡ï¼šç´¯è®¡å¥–åŠ±ï¼ˆCumulative Episode Rewardï¼‰**
  $$
  R_{\text{total}} = R_{\text{correctness}} - 0.1 \times T - \sum R_{\text{rep}} + R_{\text{success}}
  $$
  - `R_correctness`ï¼šä¸æœ€ä¼˜åŸå­åŠ¨ä½œåºåˆ—åŒ¹é…å¾—åˆ†
  - `-0.1 Ã— T`ï¼šé¼“åŠ±çŸ­è·¯å¾„
  - `R_rep`ï¼šé‡å¤åŠ¨ä½œæƒ©ç½šï¼ˆè¿ç»­ä¸‰æ¬¡ç›¸åŒåŠ¨ä½œæ‰£åˆ†ï¼‰
  - `R_success`ï¼šæˆåŠŸå®Œæˆä»»åŠ¡å¥–åŠ±ï¼ˆ+2ï¼‰

- æˆåŠŸåˆ¤å®šæ ‡å‡†ï¼šå½“å‰å½¢çŠ¶ä¸ç›®æ ‡å½¢çŠ¶çš„ **IoU â‰¥ é˜ˆå€¼**

- æ­¥éª¤çº§å¥–åŠ±åˆ†æï¼šæŒ‰æ—¶é—´æ­¥ç»Ÿè®¡å¹³å‡ç´¯ç§¯å¥–åŠ±ï¼Œç”¨äºå¤±è´¥å½’å› 

### âš”ï¸ åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ¨¡å‹ | ç±»å‹ | æ˜¯å¦å†»ç»“ä¸»å¹² | æ˜¯å¦ä½¿ç”¨ LoRA |
|------|------|---------------|----------------|
| Qwen-Instruct | åŸå§‹é¢„è®­ç»ƒæ¨¡å‹ | â€” | â€” |
| Qwen-Physics | SFT å¾®è°ƒæ¨¡å‹ | æ˜¯ï¼ˆæ— åç»­è®­ç»ƒï¼‰ | å¦ |
| Qwen-DirectRL | End-to-end RL | å¦ | æ˜¯ï¼ˆç›´æ¥åœ¨åŸå§‹æ¨¡å‹ä¸Šï¼‰ |
| Qwen-PhysRL (Ours) | ä¸¤é˜¶æ®µæ–¹æ³• | æ˜¯ï¼ˆSFTåå†»ç»“ï¼‰ | æ˜¯ï¼ˆåªè®­LoRAï¼‰ |
| Random Policy (rnd) | éšæœºç­–ç•¥ | â€” | â€” |

æ‰€æœ‰æ¨¡å‹å‡åŸºäº `Qwen2.5-1.5B-Instruct` æ¶æ„ï¼Œä½¿ç”¨ç›¸åŒ tokenizerã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| Model | Dynamic Setting ($R_{\text{total}}$) | Static Setting ($R_{\text{total}}$) |
|-------|-------------------------------------|-------------------------------------|
| Qwen-Instruct | 0.070 | 0.004 |
| Qwen-Physics | -0.068 | -0.120 |
| Qwen-DirectRL (r=64) | 1.626 | -0.216 |
| **Qwen-PhysRL (Ours)** | **2.457** | **1.717** |
| Random Policy | ~0.912 (at step 5) | ~0.912 |

> ğŸ’¡ æœ€é«˜å¯èƒ½å¥–åŠ±ä¸º 4.7ï¼ˆå«æˆåŠŸå¥–åŠ±ï¼‰ï¼Œå…¶ä¸­æœ€å¤§æ­£ç¡®åŠ¨ä½œå¥–åŠ±ä¸º 2.7

#### ç»“æœè§£è¯»ï¼š
- **Qwen-PhysRL åœ¨ Dynamic è®¾ç½®ä¸‹æ¥è¿‘æœ€ä¼˜è¡¨ç°**ï¼ˆ2.457 / 2.7ï¼‰ï¼Œè¯´æ˜å…¶èƒ½é«˜æ•ˆè¯†åˆ«æ­£ç¡®åŠ¨ä½œåºåˆ—ã€‚
- åœ¨æ›´éš¾çš„ **Static è®¾ç½®ä¸­ï¼ŒQwen-PhysRL æ˜¾è‘—ä¼˜äºå…¶ä»–æ‰€æœ‰æ¨¡å‹**ï¼ˆ1.717 vs ç¬¬äºŒå Qwen-DirectRL çš„ -0.216ï¼‰ï¼Œè¡¨æ˜å…¶å…·å¤‡è¾ƒå¼ºçš„**å†…éƒ¨çŠ¶æ€è¿½è¸ªèƒ½åŠ›**ã€‚
- æœ‰è¶£çš„æ˜¯ï¼Œ**ä»…åš SFT çš„ Qwen-Physics è¡¨ç°è´Ÿæ”¶ç›Š**ï¼Œè¯´æ˜å®ƒè™½å­¦ä¼šåŸå­æ“ä½œï¼Œå´æ— æ³•åˆç†ç»„åˆï¼Œç”šè‡³è¯¯å¯¼å†³ç­–ã€‚
- **End-to-end RLï¼ˆQwen-DirectRLï¼‰åœ¨ Static ä¸‹å®Œå…¨å¤±æ•ˆ**ï¼Œåæ˜ å…¶ç¼ºä¹å†…åœ¨ç©ºé—´å»ºæ¨¡èƒ½åŠ›ã€‚

### ğŸ“‰ GRPO è®­ç»ƒè¿‡ç¨‹å¯¹æ¯”ï¼ˆFigure 2ï¼‰
- **Qwen-PhysRL æ”¶æ•›æ›´å¿«ã€æ›´ç¨³å®š**
- ç›¸æ¯”ä¹‹ä¸‹ï¼ŒQwen-DirectRL æ³¢åŠ¨å‰§çƒˆï¼Œæ—©æœŸé™·å…¥å±€éƒ¨æœ€ä¼˜

### ğŸ§ª æ¶ˆèå®éªŒä¸é€æ­¥å¥–åŠ±åˆ†æï¼ˆFigure 3ï¼‰

é’ˆå¯¹éœ€æ‰§è¡Œ 5 æ­¥æ“ä½œçš„ä»»åŠ¡ï¼ˆä¾‹å¦‚ï¼š3æ¬¡å¹³ç§» + 1æ¬¡æ—‹è½¬ + 1æ¬¡ç¼©æ”¾ï¼‰ï¼š

| æ­¥éª¤ | Qwen-PhysRL (Dynamic) | Qwen-PhysRL (Static) | Random Policy |
|------|------------------------|------------------------|--------------|
| 1 | 0.900 | 0.759 | 0.250 |
| 2 | 1.374 | 1.143 | 0.463 |
| 3 | 1.914 | 1.469 | 0.641 |
| 4 | 2.340 | 1.689 | 0.790 |
| 5 | 2.457 | 1.717 | 0.912 |

> ğŸ” å‘ç°ï¼š
> - åœ¨å‰å‡ æ­¥ï¼ŒStatic è®¾ç½®ä¸‹çš„æ¨¡å‹ä»èƒ½è·Ÿéšæœ€ä¼˜è·¯å¾„ï¼ˆscale â†’ tr â†’ tr â†’ trï¼‰
> - ä½†åœ¨ç¬¬4â€“5æ­¥å‡ºç°åç¦»ï¼Œæœªèƒ½å®Œæˆæœ€åçš„ rotation æˆ– translation
> - è¡¨æ˜æ¨¡å‹åœ¨é•¿æœŸè®°å¿†ç»´æŒä¸Šä»æœ‰æŒ‘æˆ˜ï¼Œä½†ä»è¿œä¼˜äºéšæœºç­–ç•¥

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **ä¸¤é˜¶æ®µèŒƒå¼æœ‰æ•ˆåˆ†ç¦»â€œç‰©ç†å­¦ä¹ â€ä¸â€œç­–ç•¥å­¦ä¹ â€**ï¼š
   - SFT æä¾›å¯é çš„ç©ºé—´åŸå­æ“ä½œå…ˆéªŒ
   - å†»ç»“ä¸»å¹² + LoRA + GRPO å®ç°é«˜æ•ˆã€ç¨³å®šçš„å¤šæ­¥è§„åˆ’å­¦ä¹ 

2. **Qwen-PhysRL åœ¨åŠ¨æ€ä¸é™æ€ç¯å¢ƒä¸‹å‡æ˜¾è‘—é¢†å…ˆ**ï¼š
   - ç‰¹åˆ«æ˜¯åœ¨è¦æ±‚å†…éƒ¨çŠ¶æ€ç»´æŠ¤çš„ Static Setting ä¸­ï¼Œå±•ç°å‡ºæ›´å¼ºçš„ç©ºé—´æ¨ç†ä¸€è‡´æ€§

3. **æ³¨æ„åŠ›æœºåˆ¶åˆ†ææ­ç¤ºçœŸå®ç©ºé—´ç†è§£æå‡**ï¼ˆAblation Studyï¼‰ï¼š
   - **Observation 1**ï¼šSFT ä¸»è¦å½±å“ä¸­é—´å±‚ï¼ˆLayer 16 & 20ï¼‰ï¼ŒKL æ•£åº¦æœ€é«˜ â†’ è¡¨æ˜ç©ºé—´çŸ¥è¯†é›†ä¸­åœ¨ç‰¹å®šç½‘ç»œå±‚çº§
   - **Observation 2**ï¼šQwen-Physics å¯¹ `#` å’Œ `*` ç­‰ç©ºé—´è¯­ä¹‰ç¬¦å·å…³æ³¨åº¦æ›´é«˜ â†’ æ¨¡å‹çœŸæ­£â€œçœ‹åˆ°â€äº†ç»“æ„
   - **Observation 3**ï¼šç³»ç»Ÿæç¤ºï¼ˆsystem promptï¼‰å¸å¼•è¿‡å¤šæ³¨æ„åŠ›ï¼Œä½†åœ¨ä¸­å±‚é€æ¸å‘åœ°å›¾åŒºåŸŸè½¬ç§» â†’ ç¬¦åˆè§†è§‰-è¯­è¨€æ¨¡å‹å¸¸è§åå·®ï¼Œä½†å¯é€šè¿‡è®­ç»ƒç¼“è§£

4. **End-to-end RL ä¸è¶³ä»¥å»ºç«‹ç¨³å¥çš„ç©ºé—´è®¤çŸ¥**ï¼š
   - å³ä½¿ä½¿ç”¨ GRPOï¼Œä¹Ÿæ— æ³•æ›¿ä»£æ˜¾å¼çš„ç‰©ç†å…ˆéªŒæ³¨å…¥

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä»…é€‚ç”¨äº**è§„åˆ™ç½‘æ ¼ä¸Šçš„ç®€å•å½¢çŠ¶å˜æ¢**ï¼Œå°šæœªæ‰©å±•è‡³çœŸå®å›¾åƒæˆ–å¤šç‰©ä½“äº¤äº’
- ASCII-art æŠ½è±¡ç¨‹åº¦é«˜ï¼Œå¯èƒ½é™åˆ¶ç°å®è¿ç§»èƒ½åŠ›
- Static Setting ä¸‹ä»ä¼šå‡ºç°â€œé—å¿˜â€ç°è±¡ï¼Œé•¿ç¨‹ä¾èµ–å¤„ç†æœ‰å¾…åŠ å¼º
- åŠ¨ä½œç©ºé—´è¾ƒå°ï¼Œæœªæ¶‰åŠè¿ç»­æ§åˆ¶æˆ–é«˜ç»´åŠ¨ä½œ

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´å¤šç±»å‹çš„ building blocksï¼ˆå¦‚åå°„ã€å‰ªåˆ‡ã€ç»„åˆå˜å½¢ï¼‰
- æ‰©å±•è‡³å¤šå¯¹è±¡äº¤äº’ä¸ç¢°æ’æ£€æµ‹åœºæ™¯
- ç»“åˆ VLMs å®ç°è·¨æ¨¡æ€ç©ºé—´æ¨ç†ï¼ˆtext + image â†’ actionï¼‰
- è®¾è®¡æ›´é«˜æ•ˆçš„ memory mechanism ä»¥å¢å¼ºé™æ€ç¯å¢ƒä¸­çš„çŠ¶æ€è¿½è¸ª
- å°†è¯¥â€œæ¨¡å—åŒ–æ„å»º+RLç»„åˆâ€æ€æƒ³æ¨å¹¿è‡³å…¶ä»–å¤æ‚æ¨ç†ä»»åŠ¡ï¼ˆå¦‚é€»è¾‘æ¨ç†ã€ç¨‹åºåˆæˆï¼‰

---

## æ€»ç»“

ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ä¸¤é˜¶æ®µè®­ç»ƒæ–¹æ³• **Qwen-PhysRL**ï¼Œé€šè¿‡ **SFT å­¦ä¹ ç©ºé—´åŸå­æ“ä½œ + å†»ç»“ä¸»å¹² + LoRA-adapted GRPO è¿›è¡Œå¤šæ­¥è§„åˆ’**ï¼Œæ˜¾è‘—æå‡äº† LLM åœ¨ ASCII-art ç©ºé—´æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå°¤å…¶åœ¨éœ€è¦å†…éƒ¨çŠ¶æ€ç»´æŠ¤çš„é™æ€ç¯å¢ƒä¸­é¥é¥é¢†å…ˆäºå„ç±»åŸºçº¿ã€‚

ğŸ¯ **æ ¸å¿ƒä»·å€¼**ï¼š  
ä¸º LLM èµ‹äºˆå¯è§£é‡Šã€å¯ç»„åˆã€å¯è¿ç§»çš„ç©ºé—´æ™ºèƒ½æä¾›äº†æ–°èŒƒå¼ â€”â€” â€œ**å…ˆæ•™åŸºç¡€çŸ¥è¯†ï¼Œå†è®­ç»ƒé«˜çº§æ€ç»´**â€ã€‚è¿™ä¸€æ€æƒ³æœ‰æœ›æˆä¸ºæ„å»ºå…·èº«æ™ºèƒ½ä½“ï¼ˆembodied agentsï¼‰çš„é‡è¦åŸºçŸ³ã€‚

</details>

---

### 10. [Joint Selection for Large-Scale Pre-Training Data via Policy Gradient-based Mask Learning](https://arxiv.org/abs/2512.24265)

**Authors**: Ziqing Fan, Yuqiao Xian, Yan Sun, Li Shen  
**Category**: cs.CL  
**Published**: 2026-01-01  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.24265v1  

#### Abstract
A fine-grained data recipe is crucial for pre-training large language models, as it can significantly enhance training efficiency and model performance. One important ingredient in the recipe is to select samples based on scores produced by defined rules, LLM judgment, or statistical information in ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šJoint Selection for Large-Scale Pre-Training Data via Policy Gradient-based Mask Learning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
åœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é¢„è®­ç»ƒä¸­ï¼Œ**æ•°æ®é€‰æ‹©ç­–ç•¥**å¯¹æ¨¡å‹æ€§èƒ½è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ•°æ®ç­›é€‰æ–¹æ³•é€šå¸¸åªå…³æ³¨å•ä¸€æŒ‡æ ‡ï¼š
- **åŸºäºè´¨é‡ï¼ˆQualityï¼‰çš„æ–¹æ³•**ï¼ˆå¦‚ QuRatingã€FineWeb-Eduï¼‰ï¼šå€¾å‘äºé€‰æ‹©é«˜è´¨é‡æ ·æœ¬ï¼Œä½†å¯¼è‡´è¯­ä¹‰å†—ä½™ï¼ˆsemantic redundancyï¼‰ï¼Œåœ¨é•¿æœŸé¢„è®­ç»ƒä¸­å‡ºç°**ä¸¥é‡æ”¶ç›Šé€’å‡**ï¼ˆdiminishing returnsï¼‰ã€‚
- **åŸºäºå¤šæ ·æ€§ï¼ˆDiversityï¼‰çš„æ–¹æ³•**ï¼ˆå¦‚ Semdedupã€Facility Locationï¼‰ï¼šè™½èƒ½æå‡è¦†ç›–åº¦ï¼Œä½†ä¼š**è¿‡åº¦å‰”é™¤é«˜ä»·å€¼é«˜è´¨é‡æ ·æœ¬**ï¼ŒæŸå®³æ¨¡å‹èƒ½åŠ›ã€‚

æ­¤å¤–ï¼Œå¤šæ ·æ€§æŒ‡æ ‡é€šå¸¸æ˜¯é›†åˆå‡½æ•°ï¼ˆset functionï¼‰ï¼Œå…¶ä¼˜åŒ–ä¾èµ–è®¡ç®—æˆæœ¬æé«˜çš„è´ªå¿ƒç®—æ³•ï¼ˆgreedy algorithmï¼‰ï¼Œéš¾ä»¥åº”ç”¨äºä¸‡äº¿çº§ token æ•°æ®é›†ï¼ˆå¦‚ FineWebã€DCLMï¼‰ã€‚

å› æ­¤ï¼Œ**å¦‚ä½•é«˜æ•ˆåœ°è”åˆä¼˜åŒ–è´¨é‡å’Œå¤šæ ·æ€§æŒ‡æ ‡**ï¼Œæˆä¸ºå¤§è§„æ¨¡é¢„è®­ç»ƒæ•°æ®é€‰æ‹©ä¸­çš„å…³é”®æŒ‘æˆ˜ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šDATAMASK
æœ¬æ–‡æå‡º **DATAMASK**ï¼Œä¸€ç§æ–°é¢–ä¸”é«˜æ•ˆçš„**è”åˆå­¦ä¹ æ¡†æ¶**ï¼Œç”¨äºå¤§è§„æ¨¡é¢„è®­ç»ƒæ•°æ®é€‰æ‹©ã€‚

#### æ ¸å¿ƒæ€æƒ³
å°†æ•°æ®é€‰æ‹©è¿‡ç¨‹å»ºæ¨¡ä¸ºä¸€ä¸ª**æ©ç å­¦ä¹ ï¼ˆmask learningï¼‰é—®é¢˜**ï¼š
- å¼•å…¥å¯å­¦ä¹ çš„æ©ç  $M$ï¼Œå¯¹æ•´ä¸ªæ•°æ®é›† $D$ è¿›è¡Œé‡‡æ ·ã€‚
- å°†é€‰æ‹©ç›®æ ‡è½¬åŒ–ä¸ºä¼˜åŒ–æ©ç çš„é‡‡æ ·æ¦‚ç‡ï¼ˆlogitsï¼‰ï¼Œä»¥æœ€å¤§åŒ–é¢„å®šä¹‰çš„è”åˆç›®æ ‡å‡½æ•°ï¼ˆå¦‚è´¨é‡ + å¤šæ ·æ€§å¾—åˆ†ï¼‰ã€‚

#### æŠ€æœ¯å®ç°
- **ç­–ç•¥æ¢¯åº¦ä¼°è®¡ï¼ˆPolicy Gradient Estimation, PGEï¼‰**ï¼šç”±äºé‡‡æ ·æ“ä½œä¸å¯å¯¼ï¼Œé‡‡ç”¨å¼ºåŒ–å­¦ä¹ ä¸­çš„ç­–ç•¥æ¢¯åº¦æ–¹æ³•è¿›è¡Œä¼˜åŒ–ã€‚
- **ç»„ç›¸å¯¹ä¼˜åŠ¿ï¼ˆGroup Relative Advantageï¼‰**ï¼šå¼•å…¥ç»„å†…å‡å€¼å’Œæ ‡å‡†å·®ä½œä¸ºåŸºçº¿ï¼Œæ˜¾è‘—é™ä½æ¢¯åº¦ä¼°è®¡æ–¹å·®ï¼ŒåŠ é€Ÿæ”¶æ•›ã€‚
- **å¤šç§åŠ é€Ÿæœºåˆ¶**ï¼šåŒ…æ‹¬è´¨é‡æ„ŸçŸ¥å‰ªæï¼ˆpruningï¼‰ã€è´¨é‡åˆå§‹åŒ–ï¼ˆinitializationï¼‰ã€æ‰¹é‡æ›´æ–°ï¼ˆbatch updatingï¼‰ç­‰ï¼Œå¤§å¹…æå‡æ•ˆç‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **é«˜æ•ˆæ€§**ï¼šç›¸æ¯”ä¼ ç»Ÿçš„è´ªå¿ƒç®—æ³•ï¼ˆå¦‚ DiSFï¼‰ï¼Œ**é€‰æ‹©æ—¶é—´å‡å°‘ 98.9%**ï¼Œä½¿å¾—åœ¨ä¸‡äº¿çº§æ•°æ®ä¸Šè¿›è¡Œè”åˆä¼˜åŒ–æˆä¸ºå¯èƒ½ã€‚
- **æœ‰æ•ˆæ€§**ï¼šèƒ½å¤ŸåŒæ—¶ä¼˜åŒ–è´¨é‡å’Œå¤šæ ·æ€§ï¼Œé¿å…å•ä¸€æŒ‡æ ‡å¸¦æ¥çš„ç¼ºé™·ã€‚
- **çµæ´»æ€§**ï¼šæ¡†æ¶æ”¯æŒä»»æ„ç»„åˆçš„è´¨é‡å’Œå¤šæ ·æ€§æŒ‡æ ‡ï¼Œå…·æœ‰è‰¯å¥½çš„æ‰©å±•æ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **ä¸»æ•°æ®é›†**ï¼š**FineWeb**ï¼Œä¸€ä¸ªåŒ…å« **15 ä¸‡äº¿ token** çš„å¤§è§„æ¨¡ç½‘é¡µæ–‡æœ¬è¯­æ–™åº“ã€‚
- **ä»ä¸­é€‰å‡ºçš„å­é›†**ï¼š**FineWeb-Mask**ï¼Œé€šè¿‡ DATAMASK ä» FineWeb ä¸­é€‰å‡ºçš„ **1.5 ä¸‡äº¿ token** é«˜è´¨é‡ä¸”å¤šæ ·åŒ–çš„å­é›†ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹æ¶æ„**ï¼š
  - **1.5B dense model**ï¼šåŸºäº Qwen-2.5 æ¶æ„ã€‚
  - **7B MoE model**ï¼šåŒ…å« 10 ä¸ªä¸“å®¶ï¼Œæ¯ token æ¿€æ´» 680M å‚æ•°ã€‚
- **é¢„è®­ç»ƒé…ç½®**ï¼š
  - å­¦ä¹ ç‡ï¼š4e-4ï¼ŒAdam ä¼˜åŒ–å™¨ï¼Œbatch size 1536ï¼Œåºåˆ—é•¿åº¦ 8192ã€‚
  - åœ¨ 1.5B æ¨¡å‹ä¸Šé¢„è®­ç»ƒæœ€å¤š **400B tokens**ï¼Œåœ¨ 7B MoE ä¸Šé¢„è®­ç»ƒ **300B tokens**ã€‚
- **è¯„ä¼°ä»»åŠ¡**ï¼šå…± **12 ä¸ªå¤šæ ·åŒ–ä»»åŠ¡**ï¼Œæ¶µç›–ä¸‰å¤§ç±»èƒ½åŠ›ï¼š
  - **é˜…è¯»ç†è§£**ï¼ˆRACE-High/Middleï¼‰
  - **ä¸–ç•ŒçŸ¥è¯†**ï¼ˆTriviaQA, HellaSwag, Natural Questions, MMLU ç­‰ï¼‰
  - **æ¨ç†èƒ½åŠ›**ï¼ˆARC-Challenge, PIQA, SIQA, WinoGrandeï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **FineWeb**ï¼šåŸå§‹æ•°æ®é›†ã€‚
- **FineWeb-Edu**ï¼šåŸºäºæ•™è‚²è´¨é‡ç­›é€‰ã€‚
- **UltraFineWeb-en**ï¼šåŸºäº fastText åˆ†ç±»å™¨ç­›é€‰çš„è‹±æ–‡éƒ¨åˆ†ã€‚
- **FineWeb-Semdedup**ï¼šåŸºäºè¯­ä¹‰å»é‡ï¼ˆpair-wise similarityï¼‰ã€‚
- **FineWeb-DCLM**ï¼šåŸºäº DCLM è´¨é‡åˆ†ç±»å™¨ç­›é€‰ã€‚
- **FineWebPro**ï¼šåŸºäº Prox æ–¹æ³•ç²¾ç‚¼ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- **FineWeb-Mask åœ¨ 1.5B dense model ä¸Š**ï¼š
  - ç›¸æ¯”åŸå§‹ FineWebï¼Œå¹³å‡æ€§èƒ½æå‡ **3.2%**ã€‚
  - ç›¸æ¯”æœ€ä½³åŸºçº¿ï¼ˆFineWeb-DCLMï¼‰ï¼Œæå‡ **0.9%**ã€‚
- **åœ¨ 7B MoE model ä¸Š**ï¼š
  - ç›¸æ¯”åŸå§‹ FineWebï¼Œå¹³å‡æ€§èƒ½æå‡ **1.9%**ã€‚
  - ç›¸æ¯”æœ€ä½³åŸºçº¿ï¼Œæå‡ **0.4%**ã€‚

> æ³¨ï¼šåŸæ–‡æ‘˜è¦ç§°â€œ3.2% on 1.5Bâ€å’Œâ€œ1.9% on 7Bâ€ï¼ŒTable 2 æ˜¾ç¤ºä¸º 3.2% å’Œ 1.9%ï¼Œä¸æ‘˜è¦ä¸€è‡´ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **è´¨é‡æ–¹æ³•**ï¼ˆå¦‚ FineWeb-Edu, FineWeb-DCLMï¼‰ï¼š
  - åˆæœŸè¡¨ç°è‰¯å¥½ï¼Œä½†éšç€è®­ç»ƒ token æ•°å¢åŠ ï¼Œæ€§èƒ½å¢é•¿è¿…é€Ÿé¥±å’Œï¼ˆdiminishing returnsï¼‰ã€‚
- **å¤šæ ·æ€§æ–¹æ³•**ï¼ˆFineWeb-Semdedupï¼‰ï¼š
  - è¡¨ç°ç”šè‡³**ä½äºåŸå§‹ FineWeb**ï¼ŒéªŒè¯äº†å…¶ä¼šè¯¯åˆ å¤§é‡é«˜ä»·å€¼æ ·æœ¬ã€‚
- **DATAMASKï¼ˆFineWeb-Maskï¼‰**ï¼š
  - åœ¨æ‰€æœ‰é˜¶æ®µå‡è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶åœ¨**é˜…è¯»ç†è§£**å’Œ**ä¸–ç•ŒçŸ¥è¯†**ä»»åŠ¡ä¸Šæå‡æ˜¾è‘—ã€‚
  - åœ¨æŒç»­é¢„è®­ç»ƒï¼ˆcontinual pre-trainingï¼‰+ ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰åœºæ™¯ä¸‹ä¹Ÿè¡¨ç°ä¼˜å¼‚ï¼ˆTable 3ï¼‰ã€‚

### æ¶ˆèå®éªŒç»“æœ
| å®éªŒç»´åº¦ | å‘ç° |
|--------|------|
| **å¤šæ ·æ€§æŒ‡æ ‡é€‰æ‹©** | Pair-wise Similarity å’Œ Facility Location æœ‰æ•ˆï¼›DiSF ä¸è´¨é‡å†²çªï¼Œæ•ˆæœå·®ã€‚æ¨èä½¿ç”¨ Pair-wise Similarityã€‚ |
| **å¹³è¡¡å‚æ•° $\lambda$** | åœ¨ $\lambda \in [0.1, 0.5]$ï¼ˆå³å¤šæ ·æ€§æƒé‡ 50%-90%ï¼‰èŒƒå›´å†…æ•ˆæœæœ€ä½³ã€‚å®Œå…¨åå‘è´¨é‡ï¼ˆ$\lambda=1$ï¼‰ä¸å¦‚è”åˆä¼˜åŒ–ã€‚ |
| **è´¨é‡æ„ŸçŸ¥å‰ªæ** | è¿‡æ»¤æ‰è´¨é‡åˆ†æ•°æœ€ä½çš„ 40-50% æ ·æœ¬ï¼Œ**é€‰æ‹©æ—¶é—´ä» 18h é™è‡³ 10h**ï¼Œæ€§èƒ½ä» 44.3 â†’ 45.0ã€‚ |
| **è´¨é‡åˆå§‹åŒ–** | å°†åˆå§‹ logits ä¸è´¨é‡åˆ†æ•°å¯¹é½ï¼Œè¿›ä¸€æ­¥å°†æ—¶é—´é™è‡³ **7h**ï¼Œæ€§èƒ½æå‡è‡³ 45.1ã€‚ |
| **ç»„å¤§å° $G$** | æ¨è $G=128$ æˆ– $256$ï¼Œè¿‡å°å¯¼è‡´ä¸ç¨³å®šï¼Œè¿‡å¤§å¢åŠ è®¡ç®—å¼€é”€ã€‚ |
| **å­¦ä¹ ç‡** | æ¨è 1â€“10ï¼Œè¿‡å¤§å¯¼è‡´å‘æ•£ï¼Œè¿‡å°æ”¶æ•›æ…¢ã€‚å®éªŒä½¿ç”¨ 10ã€‚ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å•ä¸€æŒ‡æ ‡é€‰æ‹©å­˜åœ¨æ ¹æœ¬å±€é™**ï¼š
   - è´¨é‡ä¼˜å…ˆ â†’ è¯­ä¹‰å†—ä½™ â†’ æ”¶ç›Šé€’å‡ã€‚
   - å¤šæ ·æ€§ä¼˜å…ˆ â†’ è¯¯åˆ é«˜è´¨é‡æ ·æœ¬ â†’ æ€§èƒ½ä¸‹é™ã€‚
2. **è”åˆä¼˜åŒ–æ˜¯æ›´ä¼˜è·¯å¾„**ï¼š
   - é€šè¿‡ DATAMASK åŒæ—¶ä¼˜åŒ–è´¨é‡å’Œå¤šæ ·æ€§ï¼Œèƒ½æ˜¾è‘—æå‡æ¨¡å‹æœ€ç»ˆæ€§èƒ½ã€‚
3. **æ•ˆç‡ç“¶é¢ˆå¯çªç ´**ï¼š
   - ä¼ ç»Ÿè´ªå¿ƒç®—æ³•æ— æ³•æ‰©å±•åˆ°ä¸‡äº¿çº§æ•°æ®ï¼Œè€Œ DATAMASK é€šè¿‡ç­–ç•¥æ¢¯åº¦ + åŠ é€ŸæŠ€æœ¯ï¼Œå°†é€‰æ‹©æ—¶é—´ä» **78 å°æ—¶é™è‡³ 1.1 å°æ—¶**ï¼ˆ98.9% åŠ é€Ÿï¼‰ï¼Œå®ç°äº†å¯æ‰©å±•çš„è”åˆå­¦ä¹ ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ¡†æ¶ä¸»è¦èšç„¦äºè´¨é‡å’Œå¤šæ ·æ€§ä¸¤ç±»æŒ‡æ ‡çš„è”åˆï¼Œæ›´å¤æ‚çš„å¤šç›®æ ‡ç»„åˆï¼ˆå¦‚é¢†åŸŸåˆ†å¸ƒã€è¯­è¨€æ¯”ä¾‹ç­‰ï¼‰å°šæœªæ¢ç´¢ã€‚
- è™½ç„¶æ•ˆç‡å¤§å¹…æå‡ï¼Œä½†åœ¨è¶…å¤§è§„æ¨¡æ•°æ®ä¸Šä»éœ€æ•°ç™¾ GPU å°æ—¶è¿›è¡Œé€‰æ‹©ã€‚
- å¯¹åµŒå…¥æ¨¡å‹ï¼ˆE5-base-v2ï¼‰çš„ä¾èµ–å¯èƒ½å¼•å…¥åå·®ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´å¤šç±»å‹çš„æŒ‡æ ‡ç»„åˆï¼ˆå¦‚é¢†åŸŸå‡è¡¡ã€è¯­è¨€å¤šæ ·æ€§ï¼‰ã€‚
- è¿›ä¸€æ­¥ä¼˜åŒ–é€‰æ‹©æ•ˆç‡ï¼Œæ”¯æŒå®æ—¶æˆ–åŠ¨æ€æ•°æ®é€‰æ‹©ã€‚
- å°† DATAMASK åº”ç”¨äºå…¶ä»–æ¨¡æ€ï¼ˆå¦‚å›¾åƒã€éŸ³é¢‘ï¼‰çš„é¢„è®­ç»ƒæ•°æ®é€‰æ‹©ã€‚
- ç ”ç©¶å¦‚ä½•å°†é€‰æ‹©è¿‡ç¨‹ä¸æ¨¡å‹è®­ç»ƒç«¯åˆ°ç«¯è”åˆä¼˜åŒ–ã€‚

---

> **ä»£ç ä¸æ•°æ®å…¬å¼€**ï¼š
> - Code: [https://github.com/ByteDance-Seed/DATAMASK](https://github.com/ByteDance-Seed/DATAMASK)
> - Data: [https://huggingface.co/datasets/DATA-MASK/FineWeb-Mask](https://huggingface.co/datasets/DATA-MASK/FineWeb-Mask)

</details>

---

### 11. [Adaptive Dependency-aware Prompt Optimization Framework for Multi-Step LLM Pipeline](https://arxiv.org/abs/2512.24933)

**Authors**: Minjun Zhao, Xinyu Zhang, Shuai Zhang, Deyang Li, Ruifeng Shi  
**Category**: cs.CL  
**Published**: 2026-01-01  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.24933v1  

#### Abstract
Multi-step LLM pipelines invoke large language models multiple times in a structured sequence and can effectively solve complex tasks, but their performance heavily depends on the prompts used at each step. Jointly optimizing these prompts is difficult due to missing step-level supervision and inter...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAdaptive Dependency-aware Prompt Optimization Framework for Multi-Step LLM Pipeline

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤šæ­¥ LLM Pipeline åœ¨è§£å†³å¤æ‚ä»»åŠ¡æ—¶è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶æ€§èƒ½é«˜åº¦ä¾èµ–äºæ¯ä¸€æ­¥ä½¿ç”¨çš„ **prompt**ã€‚ç„¶è€Œï¼Œç”±äºä»¥ä¸‹æŒ‘æˆ˜ï¼Œè”åˆä¼˜åŒ–å¤šä¸ª prompt æä¸ºå›°éš¾ï¼š
- ç¼ºä¹ step-level çš„ç›‘ç£ä¿¡å·ï¼ˆåªæœ‰ end-to-end çš„è¾“å‡ºæ ‡ç­¾ï¼‰
- å„æ­¥éª¤ä¹‹é—´å­˜åœ¨å¤æ‚çš„ä¾èµ–å…³ç³»ï¼Œé”™è¯¯ä¼šé€å±‚ä¼ æ’­
- ä¿®æ”¹ä¸€ä¸ª step çš„ prompt å¯èƒ½å½±å“å…¶ä»–æ­¥éª¤çš„è¡Œä¸ºï¼Œå¯¼è‡´â€œæ‹†ä¸œå¢™è¡¥è¥¿å¢™â€ç°è±¡

ç°æœ‰çš„ end-to-end å¤š prompt ä¼˜åŒ–æ–¹æ³•ï¼ˆå¦‚ MIPROã€TextGradï¼‰åœ¨è¿™äº›æ¡ä»¶ä¸‹è¡¨ç°ä¸ä½³ï¼Œå¸¸äº§ç”Ÿæ¬¡ä¼˜æˆ–ä¸ç¨³å®šçš„æ›´æ–°ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šADOPT
ä½œè€…æå‡º **ADOPT**ï¼ˆAdaptive Dependency-aware Prompt OPTimizationï¼‰ï¼Œä¸€ç§é¢å‘å¤šæ­¥ LLM Pipeline çš„è‡ªé€‚åº”ä¾èµ–æ„ŸçŸ¥ prompt ä¼˜åŒ–æ¡†æ¶ï¼ŒåŒ…å«ä¸‰å¤§æ ¸å¿ƒç»„ä»¶ï¼š

#### ï¼ˆ1ï¼‰Dependency-aware Textual Gradient Estimation
- åˆ†ææ‰§è¡Œè½¨è¿¹ï¼ˆexecution tracesï¼‰ï¼Œæ˜¾å¼å»ºæ¨¡æ¯ä¸ª LLM step å¯¹æœ€ç»ˆä»»åŠ¡ç»“æœçš„å½±å“ï¼ˆå³â€œfinal output dependencyâ€ï¼‰
- åˆ©ç”¨é”™è¯¯æ¡ˆä¾‹ç”Ÿæˆå…¨å±€æ–‡æœ¬æ¢¯åº¦ï¼ˆglobal textual gradientï¼‰ï¼Œå†åŸºäºä¾èµ–å…³ç³»å°†å…¶åˆ†è§£ä¸ºå„ step çš„å±€éƒ¨æ–‡æœ¬æ¢¯åº¦ï¼ˆlocal textual gradientï¼‰
- è¿™ä¸€è¿‡ç¨‹ç±»æ¯”äºè®¡ç®—è§£æå¯¼æ•°ï¼ˆanalytical derivativeï¼‰ï¼Œé¿å…äº†ä¾èµ– LLM è¿›è¡Œåå‘æ¨ç†æ‰€å¸¦æ¥çš„åå·®å’Œä¿¡å·è¡°å‡

#### ï¼ˆ2ï¼‰Decoupled Optimization Architecture
- å°†â€œè°ƒæ•´æ–¹å‘ä¼°è®¡â€ä¸â€œprompt æ›´æ–°â€è§£è€¦ï¼š
  - å…ˆç”±ä¾èµ–åˆ†æç”Ÿæˆ step-level çš„ä¼˜åŒ–æ–¹å‘ï¼ˆlocal textual gradientï¼‰
  - å†ç‹¬ç«‹åœ°å¯¹æ¯ä¸ª step åº”ç”¨ä»»æ„å•æ­¥ prompt optimizerï¼ˆå¦‚ instruction tuning æˆ– in-context example selectionï¼‰
- æœ€åé€šè¿‡ pipeline-level æœç´¢ï¼ˆå¦‚ Bayesian Optimizationï¼‰é€‰æ‹©æœ€ä¼˜ prompt ç»„åˆ
- è¯¥è®¾è®¡æå‡äº†çµæ´»æ€§å’Œæ¨¡å—åŒ–ç¨‹åº¦ï¼Œå…¼å®¹å¤šç§ä¼˜åŒ–ç­–ç•¥

#### ï¼ˆ3ï¼‰Shapley-based Resource Allocation
- å¼•å…¥åŸºäº Shapley value çš„è´¡çŒ®è¯„ä¼°æœºåˆ¶ï¼ŒåŠ¨æ€åˆ†é…ä¼˜åŒ–èµ„æº
- åœ¨æ¯è½®ä¼˜åŒ–åï¼Œåˆ©ç”¨ Kernel SHAP ä¼°ç®—å„ step å¯¹ end-to-end æ€§èƒ½æå‡çš„è¾¹é™…è´¡çŒ®
- è´¡çŒ®å¤§çš„ step è·å¾—æ›´å¤šå€™é€‰ prompt ç”Ÿæˆé¢„ç®—ï¼Œä»è€Œé›†ä¸­è®¡ç®—èµ„æºäºå…³é”®ç“¶é¢ˆç¯èŠ‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | å±€é™æ€§ | ADOPT çš„æ”¹è¿› |
|------|--------|-------------|
| MIPRO | ä»…ä»æ­£ç¡®æ ·ä¾‹ç”Ÿæˆå€™é€‰ promptï¼Œå¿½ç•¥é”™è¯¯åé¦ˆ | æ˜¾å¼åˆ©ç”¨é”™è¯¯æ ·ä¾‹ç”Ÿæˆ textual loss å’Œ gradient |
| GEPA | ç›´æ¥ä½¿ç”¨æœ€ç»ˆåé¦ˆä¼˜åŒ– promptï¼Œæ—  step-level åˆ†è§£ | åŸºäºä¾èµ–å…³ç³»å°†å…¨å±€åé¦ˆåˆ†è§£ä¸º step-specific ä¿¡å· |
| TextGrad / Trace | ä¾èµ– LLM æ‰§è¡Œåå‘æ¨ç†ï¼Œæ˜“å¼•å…¥è§£é‡Šåå·® | ä¸ä¾èµ– LLM æ¨ç†é”™è¯¯æ¥æºï¼Œç›´æ¥é€šè¿‡ä¾èµ–åˆ†æå®šä½è´£ä»» |
| æ‰€æœ‰æ–¹æ³• | å›ºå®šä¼˜åŒ–èµ„æºåˆ†é…ï¼Œæ•ˆç‡ä½ | åŠ¨æ€æŒ‰è´¡çŒ®åˆ†é…èµ„æºï¼Œæ˜¾è‘—åŠ é€Ÿæ”¶æ•› |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“**ï¼šæ›´ç²¾å‡†çš„ step-level ä¼˜åŒ–ä¿¡å· + æ›´çµæ´»çš„ä¼˜åŒ–æ¶æ„ + æ›´é«˜æ•ˆçš„èµ„æºåˆ©ç”¨ â†’ æ›´ç¨³å®šã€é«˜æ•ˆã€å¯æ‰©å±•çš„å¤š prompt ä¼˜åŒ–ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **HotPotQA**ï¼šä¸€ä¸ªå¤šè·³é—®ç­”æ•°æ®é›†ï¼Œè¦æ±‚æ¨¡å‹æ•´åˆå¤šä¸ªæ–‡æ¡£ä¿¡æ¯è¿›è¡Œæ¨ç†
- **HoVer**ï¼šä¸€ä¸ªäº‹å®éªŒè¯æ•°æ®é›†ï¼Œæ¶‰åŠå¤šè·³è¯æ®æå–ä¸å£°æ˜åˆ¤æ–­

è¿™ä¸¤ä¸ªæ•°æ®é›†å‡é€‚åˆæµ‹è¯•å¤šæ­¥æ¨ç† pipeline çš„èƒ½åŠ›ã€‚

---

### å®éªŒè®¾ç½®
- æ‰€æœ‰ LLM å‡ä½¿ç”¨ **Qwen2.5-72B-Instruct**
- æ¸©åº¦è®¾ä¸º 0ï¼Œtop_p è®¾ä¸º 1ï¼Œç¡®ä¿è¾“å‡ºç¡®å®šæ€§
- æ¯ä¸ªå®éªŒè¿è¡Œå¤šä¸ªè¿­ä»£è½®æ¬¡ï¼Œè·Ÿè¸ª end-to-end å‡†ç¡®ç‡å˜åŒ–
- ä½¿ç”¨ **Bayesian Optimization** è¿›è¡Œ pipeline-level prompt é…ç½®æœç´¢

---

### è¯„ä¼°æŒ‡æ ‡
- ä¸»è¦æŒ‡æ ‡ï¼š**End-to-end Accuracy**
- è¾…åŠ©åˆ†æï¼šæ”¶æ•›é€Ÿåº¦ï¼ˆè¾¾åˆ°ç›®æ ‡æ€§èƒ½æ‰€éœ€è¿­ä»£æ¬¡æ•°ï¼‰ã€æ¶ˆèå®éªŒæ•ˆæœ

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç®€ä»‹ |
|------|------|
| **No-CoT** | ä¸åŠ ä»»ä½•æç¤ºå·¥ç¨‹çš„åŸºç¡€ prompt |
| **CoT** | æ·»åŠ  â€œLetâ€™s think step by stepâ€ çš„ chain-of-thought æç¤º |
| **MIPRO** | åŸºäºæ­£ç¡®æ ·ä¾‹ç”Ÿæˆå€™é€‰ prompt å¹¶ç»„åˆä¼˜åŒ– |
| **GEPA** | ä½¿ç”¨åå°„å¼åé¦ˆä¼˜åŒ– promptï¼Œä½†æ—  step-level åˆ†è§£ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰

| Dataset     | No-COT | CoT  | MIPRO | GEPA | ADOPT-Instruct | ADOPT-Joint |
|------------|--------|------|-------|------|----------------|-------------|
| HotPotQA   | 0.52   | 0.58 | 0.62  | 0.63 | **0.67**       | **0.68**    |
| HoVer      | 0.55   | 0.58 | 0.62  | 0.63 | **0.69**       | **0.71**    |

> ğŸ”º **ç»“è®º**ï¼šADOPT åœ¨ä¸¤ä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå‡æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿æ–¹æ³•ï¼Œæœ€é«˜æå‡è¾¾ **+16%**ï¼ˆvs No-CoTï¼‰ï¼Œç›¸å¯¹æå‡çº¦ **8â€“10%**ï¼ˆvs MIPRO/GEPAï¼‰ã€‚

---

### æ”¶æ•›æ€§åˆ†æï¼ˆFigure 3ï¼‰
- ADOPT åœ¨æ—©æœŸè¿­ä»£ä¸­å¿«é€Ÿæå‡å‡†ç¡®ç‡ï¼Œå¹¶æŒç»­ç¨³æ­¥ä¸Šå‡
- å³ä½¿åæœŸæœ‰è½»å¾®æ³¢åŠ¨ï¼Œæ•´ä½“è¶‹åŠ¿ç¨³å®šæ”¶æ•›ï¼Œæœªå‡ºç°æ€§èƒ½é€€åŒ–
- è¡¨æ˜ local textual gradients æä¾›äº†ç¨³å®šæœ‰æ•ˆçš„ä¼˜åŒ–ä¿¡å·

---

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰ä¸åŒ step-level prompt optimizer çš„å½±å“
- **Instruction-only optimizer**ï¼šä»…ä¼˜åŒ–æŒ‡ä»¤éƒ¨åˆ†
- **Joint optimizer**ï¼šåŒæ—¶ä¼˜åŒ–æŒ‡ä»¤å¹¶è‡ªåŠ¨é€‰æ‹© in-context ç¤ºä¾‹
- ç»“æœæ˜¾ç¤º joint ç‰ˆæœ¬è¿›ä¸€æ­¥æå‡æ€§èƒ½ï¼Œè¯´æ˜åœ¨é«˜è´¨é‡å±€éƒ¨ç›‘ç£ä¸‹ï¼Œ richer prompt è¡¨è¾¾æ›´å…·ä¼˜åŠ¿
- éªŒè¯äº† ADOPT æ¡†æ¶çš„**æ¨¡å—åŒ–ä¸å¯æ‰©å±•æ€§**

#### ï¼ˆ2ï¼‰èµ„æºåˆ†é…ç­–ç•¥æ¯”è¾ƒï¼ˆTable 2ï¼‰

| Allocation Strategy | Average Iterations to Target Performance |
|---------------------|------------------------------------------|
| Uniform             | 6.6                                      |
| Random              | 6.7                                      |
| **Shapley-based**   | **3.7**                                  |

> ğŸ”º **ç»“è®º**ï¼šShapley-based èµ„æºåˆ†é…å°†æ”¶æ•›é€Ÿåº¦æå‡è¿‘ **ä¸€å€ä»¥ä¸Š**ï¼Œè¯æ˜å…¶èƒ½æœ‰æ•ˆè¯†åˆ«å…³é”®æ­¥éª¤å¹¶é›†ä¸­ä¼˜åŒ–èµ„æºã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ä¾èµ–æ„ŸçŸ¥çš„æ¢¯åº¦åˆ†è§£æ˜¯å…³é”®**ï¼š  
   æ˜¾å¼å»ºæ¨¡ step ä¸æœ€ç»ˆè¾“å‡ºä¹‹é—´çš„åŠŸèƒ½ä¾èµ–å…³ç³»ï¼Œèƒ½å¤Ÿç”Ÿæˆæ¯” LLM åå‘æ¨ç†æ›´å¯é ã€æ›´ç²¾ç¡®çš„ä¼˜åŒ–ä¿¡å·ã€‚

2. **è§£è€¦æ¶æ„å¸¦æ¥çµæ´»æ€§**ï¼š  
   å°† textual gradient ä¼°è®¡ä¸ prompt ä¼˜åŒ–åˆ†ç¦»ï¼Œä½¿å¾— ADOPT å¯æ— ç¼é›†æˆå„ç§å•æ­¥ optimizerï¼Œå¢å¼ºäº†å®ç”¨æ€§ä¸å¯æ‰©å±•æ€§ã€‚

3. **åŠ¨æ€èµ„æºåˆ†é…å¤§å¹…æå‡æ•ˆç‡**ï¼š  
   åŸºäº Shapley value çš„è´¡çŒ®è¯„ä¼°æœºåˆ¶èƒ½æœ‰æ•ˆè¯†åˆ«ç“¶é¢ˆæ­¥éª¤ï¼Œæ˜¾è‘—å‡å°‘è¾¾åˆ°ç›®æ ‡æ€§èƒ½æ‰€éœ€çš„è¿­ä»£æ¬¡æ•°ã€‚

4. **ADOPT é€‚ç”¨äºå¤æ‚ pipeline ç»“æ„**ï¼š  
   æ”¯æŒåŒ…å«å¾ªç¯ã€åˆ†æ”¯ç­‰æ§åˆ¶æµçš„ pipelineï¼Œå…‹æœäº† TextGradã€Trace ç­‰æ–¹æ³•åªèƒ½å¤„ç†é™æ€ã€æ— ç¯æµç¨‹çš„é™åˆ¶ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰å®ç°ä»ä¾èµ–å¤šä¸ª LLM-based optimizersï¼ˆE1~E6ï¼‰ååŒå·¥ä½œï¼Œå¢åŠ äº†ç³»ç»Ÿå¤æ‚æ€§å’Œè°ƒç”¨å¼€é”€
- Kernel SHAP å¯¹ coalition çš„é‡‡æ ·å¯èƒ½åœ¨é«˜ç»´ prompt ç©ºé—´ä¸­ä¸å¤Ÿå‡†ç¡®
- å°šæœªæµ‹è¯•æç«¯é•¿é“¾æˆ–å¤š agent åä½œåœºæ™¯ä¸‹çš„å¯æ‰©å±•æ€§

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢è½»é‡åŒ–ç‰ˆæœ¬ï¼Œå‡å°‘ optimizer è°ƒç”¨æ¬¡æ•°
- ç»“åˆå¼ºåŒ–å­¦ä¹ æˆ–å…ƒå­¦ä¹ è¿›ä¸€æ­¥è‡ªåŠ¨åŒ–ä¾èµ–å»ºæ¨¡è¿‡ç¨‹
- æ‰©å±•è‡³ Mixture-of-Prompts æˆ– soft prompt tuning ç­‰è¿ç»­å‚æ•°ä¼˜åŒ–åœºæ™¯
- åº”ç”¨äº real-time è‡ªé€‚åº” pipeline è°ƒæ•´ç³»ç»Ÿ

---

## æ€»ç»“
**ADOPT** æ˜¯é¦–ä¸ªæ˜ç¡®æå‡ºâ€œä¾èµ–æ„ŸçŸ¥ + æ–‡æœ¬æ¢¯åº¦åˆ†è§£ + åŠ¨æ€èµ„æºåˆ†é…â€çš„å¤šæ­¥ LLM Pipeline prompt ä¼˜åŒ–æ¡†æ¶ã€‚å®ƒä¸ä»…åœ¨æ€§èƒ½ä¸Šè¶…è¶Šç°æœ‰ SOTA æ–¹æ³•ï¼Œæ›´é‡è¦çš„æ˜¯æä¾›äº†ä¸€ç§**ç³»ç»ŸåŒ–ã€å¯è§£é‡Šã€å¯æ‰©å±•**çš„ä¼˜åŒ–èŒƒå¼ï¼Œä¸ºæ„å»ºé«˜æ•ˆã€é²æ£’çš„å¤šæ­¥æ™ºèƒ½ç³»ç»Ÿæä¾›äº†é‡è¦å·¥å…·ã€‚

</details>

---

### 12. [Understanding LLM Checkpoint/Restore I/O Strategies and Patterns](https://arxiv.org/abs/2512.24511)

**Authors**: Mikaila J. Gossman, Avinash Maurya, Bogdan Nicolae, Jon C. Calhoun  
**Category**: cs.DC  
**Published**: 2026-01-01  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.24511v1  

#### Abstract
As LLMs and foundation models scale, checkpoint/restore has become a critical pattern for training and inference. With 3D parallelism (tensor, pipeline, data), checkpointing involves many processes, each managing numerous tensors of varying shapes and sizes, that must be persisted frequently to stab...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šUnderstanding LLM Checkpoint/Restore I/O Strategies and Patterns

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
éšç€ **Large Language Models (LLMs)** å’Œ **Foundation Models (FMs)** è§„æ¨¡ä¸æ–­æ‰©å¤§ï¼Œè®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¾èµ–å¤§è§„æ¨¡åˆ†å¸ƒå¼å¹¶è¡Œï¼ˆå¦‚ tensorã€pipelineã€data å¹¶è¡Œï¼‰ï¼Œå¯¼è‡´æ¨¡å‹çŠ¶æ€åˆ†å¸ƒåœ¨æ•°åƒä¸ª GPU ä¸Šã€‚é¢‘ç¹çš„ **Checkpoint/Restore (C/R)** æ“ä½œæˆä¸ºç³»ç»Ÿç“¶é¢ˆï¼Œé¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- **é«˜é¢‘ç‡ï¼ˆVelocityï¼‰**ï¼šæ¯è½®è¿­ä»£éƒ½å¯èƒ½éœ€è¦ä¿å­˜æ£€æŸ¥ç‚¹ã€‚
- **å¼‚æ„æ€§ï¼ˆVarietyï¼‰**ï¼šæ¯ä¸ªæ£€æŸ¥ç‚¹åŒ…å«å¤§é‡ä¸åŒå½¢çŠ¶å’Œå¤§å°çš„å¼ é‡ï¼ˆtensorsï¼‰ã€ä¼˜åŒ–å™¨çŠ¶æ€ç­‰ã€‚
- **å¤§æ•°æ®é‡ï¼ˆVolumeï¼‰**ï¼šå•æ¬¡æ£€æŸ¥ç‚¹å¯è¾¾æ•°å GBï¼Œäº§ç”Ÿæ•°ç™¾è‡³æ•°åƒä¸ªæ–‡ä»¶ã€‚

è¿™äº›å› ç´ å…±åŒæ„æˆä¸€ä¸ªå…¸å‹çš„â€œå¤§æ•°æ®â€I/O é—®é¢˜ï¼Œä¼ ç»ŸåŸºäº POSIX çš„ I/O æ¥å£ï¼ˆå¦‚ `read`/`write`ï¼‰æ•ˆç‡ä½ä¸‹ï¼Œå°¤å…¶æ˜¯åœ¨å…ƒæ•°æ®ç®¡ç†ã€å°æ–‡ä»¶è¯»å†™ã€ç¼“å­˜ä¸€è‡´æ€§ç­‰æ–¹é¢å­˜åœ¨ä¸¥é‡ç“¶é¢ˆã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€å¥—é’ˆå¯¹ LLM C/R åœºæ™¯çš„ **I/O æ€§èƒ½åˆ†ææ¡†æ¶**ï¼Œå¹¶æ·±å…¥ç ”ç©¶äº†ç°ä»£å†…æ ¸åŠ é€Ÿ I/O åº“ **liburing** åœ¨è¯¥åœºæ™¯ä¸‹çš„æ½œåŠ›ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

1. **è®¾è®¡äº†ä¸€ä¸ªå¾®åŸºå‡†æµ‹è¯•æ¡†æ¶ï¼ˆmicrobenchmarkï¼‰**  
   - æ”¯æŒæ¨¡æ‹ŸçœŸå® LLM æ£€æŸ¥ç‚¹çš„å·¥ä½œè´Ÿè½½ï¼ˆéå‡åŒ€å¯¹è±¡å¤§å°ã€å¤šè¿›ç¨‹å¹¶å‘ã€shard åˆ†å¸ƒï¼‰ã€‚
   - èƒ½å¤Ÿè¯„ä¼° **liburing** åœ¨ä¸åŒèšåˆç­–ç•¥ã€å¯¹é½æ–¹å¼ã€I/O åˆå¹¶ï¼ˆcoalescingï¼‰ã€ç¼“å†²æ¨¡å¼ä¸‹çš„è¡¨ç°ã€‚
   - å¼¥è¡¥äº†ä¼ ç»Ÿå·¥å…·ï¼ˆå¦‚ IORï¼‰æ— æ³•å‡†ç¡®å»ºæ¨¡ LLM ç‰¹å®š I/O æ¨¡å¼çš„ç¼ºé™·ã€‚

2. **ç³»ç»Ÿæ€§åœ°æ¢ç´¢äº† I/O èšåˆï¼ˆAggregationï¼‰ç­–ç•¥çš„å½±å“**  
   å¯¹æ¯”ä¸‰ç§å…¸å‹ç­–ç•¥ï¼š
   - `File-per-Tensor`ï¼šæ¯ä¸ªå¼ é‡å•ç‹¬å†™å…¥æ–‡ä»¶ï¼ˆå½“å‰ä¸»æµåšæ³•ï¼Œå¦‚ DeepSpeed/TorchSnapshotï¼‰ã€‚
   - `File-per-Process`ï¼šæ¯ä¸ª rank å°†æ‰€æœ‰æ•°æ®å†™å…¥å•ä¸ªæ–‡ä»¶ã€‚
   - `Single Aggregated File`ï¼šæ‰€æœ‰ rank å†™å…¥åŒä¸€ä¸ªå¤§æ–‡ä»¶çš„ä¸åŒåç§»ä½ç½®ï¼ˆç†æƒ³èšåˆï¼‰ã€‚

3. **æ·±å…¥åˆ†æ O_DIRECT å¯¹è¯»å†™æ€§èƒ½çš„ä¸å¯¹ç§°å½±å“**  
   å‘ç°ç›´æ¥ I/Oï¼ˆDirect I/Oï¼‰åœ¨å†™æ“ä½œä¸­æ˜¾è‘—æå‡æ€§èƒ½ï¼Œä½†åœ¨å°è§„æ¨¡è¯»å–æ—¶åè€Œé™ä½æ€§èƒ½ï¼Œæ­ç¤ºäº†ä¼ ç»Ÿ HPC ç¼“å­˜å‡è®¾åœ¨ LLM åœºæ™¯ä¸­çš„å¤±æ•ˆã€‚

4. **æå‡ºâ€œæ–‡ä»¶ç³»ç»Ÿæ„ŸçŸ¥â€çš„èšåˆä¸åˆå¹¶ç­–ç•¥**  
   ä¸»å¼ æœªæ¥çš„ C/R æ¡†æ¶åº”ç»“åˆåº”ç”¨å±‚èšåˆä¸åº•å±‚ I/O æ‰¹å¤„ç†æœºåˆ¶ï¼ˆå¦‚ liburing çš„ submission/completion queuesï¼‰ï¼Œä»¥æœ€å¤§åŒ–å¸¦å®½åˆ©ç”¨ç‡å¹¶å‡å°‘å…ƒæ•°æ®å‹åŠ›ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ TorchSnapshot, DataStates-LLMï¼‰ | æœ¬æ–‡æå‡ºçš„ä¼˜åŒ–æ–¹å‘ |
|------|---------------------------------------------|---------------------|
| **I/O æ¥å£** | å¤šæ•°ä½¿ç”¨è¾ƒè€çš„ libaio æˆ–åŒæ­¥ POSIX I/O | åˆ©ç”¨ liburing å®ç°å¼‚æ­¥ã€æ‰¹é‡æäº¤ |
| **èšåˆç¨‹åº¦** | æ–‡ä»¶ç²’åº¦ç»†ï¼ˆfile-per-shardï¼‰ï¼Œå…ƒæ•°æ®å¼€é”€å¤§ | æ¨åŠ¨ç²—ç²’åº¦èšåˆï¼ˆfile-per-process æˆ– single fileï¼‰ |
| **å†…å­˜ç®¡ç†** | åŠ¨æ€åˆ†é… bufferï¼Œå¢åŠ å»¶è¿Ÿ | é¢„åˆ†é…å¯¹é½ bufferï¼Œæ”¯æŒé›¶æ‹·è´ |
| **æ€§èƒ½ä¸Šé™** | å—é™äºå°æ–‡ä»¶å’Œå…ƒæ•°æ®ç“¶é¢ˆ | æ¥è¿‘ç†è®ºæœ€å¤§åå |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### å®éªŒå¹³å°
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼šALCF Polaris ç³»ç»Ÿ
  - èŠ‚ç‚¹é…ç½®ï¼šAMD EPYC Milan 753P CPU + 4Ã—A100-40GB GPU + 512GB DDR4
  - å­˜å‚¨åç«¯ï¼šLustre-based Parallel File System (PFS)ï¼Œæ€»å¸¦å®½ 650 GB/sï¼Œ40 OSSï¼Œ160 OST
  - Stripe è®¾ç½®ï¼š64MB æ¡å¸¦å¤§å°ï¼Œè·¨æ‰€æœ‰ OST åˆ†å¸ƒ

- **è½¯ä»¶æ ˆ**ï¼š
  - I/O åº“ï¼šliburing v2.12ï¼ˆå¯¹æ¯” POSIXï¼‰
  - ç¼–è¯‘å™¨ï¼šgcc 13.3.1
  - æµ‹è¯•æ¨¡å‹ï¼šBLOOM-3B, LLaMA-7B, LLaMA-13Bï¼ˆå¯¹åº” 4/8/16 ranksï¼‰

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### åŸºå‡†æµ‹è¯•è®¾è®¡
1. **åˆæˆåŸºå‡†ï¼ˆSynthetic Benchmarkï¼‰**
   - æ¯ä¸ª rank ä½¿ç”¨è¿ç»­å†…å­˜ bufferï¼ˆ128MBâ€“8GBï¼‰è¿›è¡Œè¯»å†™ã€‚
   - æ§åˆ¶å˜é‡ï¼šbuffer å¤§å°ã€process æ•°é‡ã€èšåˆç­–ç•¥ã€æ˜¯å¦å¯ç”¨ `O_DIRECT`ã€‚
   - ç›®æ ‡ï¼šæµ‹é‡ liburing çš„å³°å€¼ååèƒ½åŠ›ã€‚

2. **ä»£è¡¨æ€§ LLM åŸºå‡†ï¼ˆRepresentative LLM Benchmarkï¼‰**
   - æ¨¡æ‹ŸçœŸå®è®­ç»ƒé…ç½®ä¸‹çš„æ£€æŸ¥ç‚¹ç»“æ„ï¼ˆè§ Figure 4ï¼‰ã€‚
   - åŒ…å«å¤šä¸ªéå¯¹é½ã€å˜é•¿ bufferï¼ˆä»£è¡¨ä¸åŒå±‚æƒé‡ã€ä¼˜åŒ–å™¨çŠ¶æ€ç­‰ï¼‰ã€‚
   - æ›´è´´è¿‘å®é™… C/R æµç¨‹ä¸­çš„ç¢ç‰‡åŒ– I/O è¡Œä¸ºã€‚

#### è¯„ä¼°æŒ‡æ ‡
- **Throughput (GB/s)**ï¼šä¸»è¦æ€§èƒ½æŒ‡æ ‡ï¼Œè¡¡é‡å†™å…¥/æ¢å¤é€Ÿåº¦ã€‚
- **Latency Breakdown**ï¼šåˆ†æå„é˜¶æ®µè€—æ—¶ï¼ˆmemcpyã€åºåˆ—åŒ–ã€PFS è¯»å†™ç­‰ï¼‰ã€‚
- **Metadata Pressure**ï¼šé€šè¿‡æ–‡ä»¶æ•°é‡é—´æ¥åæ˜ å…ƒæ•°æ®æœåŠ¡å™¨ï¼ˆMDSï¼‰è´Ÿè½½ã€‚

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **TorchSnapshot**ï¼ˆPyTorch å®˜æ–¹å¿«ç…§åº“ï¼‰ï¼šä½¿ç”¨ libaioï¼Œå°†å¤§å¯¹è±¡åˆ‡åˆ†ä¸º 512MB å›ºå®šå—ï¼ŒåµŒå¥—ç›®å½•å­˜å‚¨ã€‚
- **DataStates-LLM**ï¼šä½¿ç”¨ liburingï¼Œä½†é‡‡ç”¨ file-per-shard ç­–ç•¥ï¼ŒåŠ¨æ€åˆ†é…å†…å­˜ã€‚
- **Ideal Baseline**ï¼šæœ¬æ–‡æ„å»ºçš„ç†æƒ³èšåˆæ¨¡å‹ï¼Œä½¿ç”¨ single aggregated file + liburing + é¢„åˆ†é… bufferã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### âœ… ååé‡å¯¹æ¯”ï¼ˆçœŸå® LLM å·¥ä½œè´Ÿè½½ä¸‹ï¼‰

| æ–¹æ³• | æœ€å¤§å†™ååæå‡ï¼ˆvs. DataStates-LLMï¼‰ | æœ€å¤§å†™ååæå‡ï¼ˆvs. TorchSnapshotï¼‰ |
|------|-------------------------------|------------------------------|
| æœ¬æ–‡ç†æƒ³åŸºçº¿ï¼ˆSingle Agg. File + liburingï¼‰ | **3.9Ã—** | **7.6Ã—** |

| æ–¹æ³• | æœ€å¤§è¯»ååæå‡ï¼ˆvs. DataStates-LLMï¼‰ | æœ€å¤§è¯»ååæå‡ï¼ˆvs. TorchSnapshotï¼‰ |
|------|-------------------------------|------------------------------|
| æœ¬æ–‡ç†æƒ³åŸºçº¿ | **3.6Ã—** | **3.8Ã—** |

> æ³¨ï¼šæ€§èƒ½å¢ç›Šéšæ¨¡å‹è§„æ¨¡å¢å¤§è€Œæ›´æ˜æ˜¾ï¼ˆ13B > 7B > 3Bï¼‰ï¼Œå› å°æ–‡ä»¶æ¯”ä¾‹æ›´é«˜ï¼Œå…ƒæ•°æ®å‹åŠ›æ›´å¤§ã€‚

---

#### ğŸ” èšåˆç­–ç•¥çš„å½±å“ï¼ˆFigure 17ï¼‰
- åœ¨åˆæˆæµ‹è¯•ä¸­ï¼Œ`Single Agg. File` æ¯” `File-per-Shard` æå‡çº¦ **34%** ååã€‚
- åœ¨çœŸå® LLM å·¥ä½œè´Ÿè½½ä¸­ï¼Œç”±äº I/O æœªåˆå¹¶ï¼ˆuncoalescedï¼‰ã€buffer ä¸å¯¹é½ï¼Œèšåˆä¼˜åŠ¿è¢«å‰Šå¼±ï¼Œä½†ä»ä¼˜äºé»˜è®¤ç­–ç•¥ã€‚

#### âš–ï¸ O_DIRECT çš„å½±å“ï¼ˆFigure 9â€“10ï¼‰
- **å†™æ“ä½œ**ï¼šå¯ç”¨ `O_DIRECT` åï¼Œliburing å†™ååæœ€é«˜æå‡ **4.8Ã—**ï¼ˆvs. ç¼“å†² I/Oï¼‰ã€‚
- **è¯»æ“ä½œ**ï¼š
  - å°æ•°æ®ï¼ˆâ‰¤1GBï¼‰ï¼šç¼“å†² I/O æ›´å¿«ï¼ˆæœ€å¤šå¿« 2.3Ã—ï¼‰ï¼Œå¾—ç›Šäº page cache å’Œé¢„è¯»ã€‚
  - å¤§æ•°æ®ï¼ˆâ‰¥4GBï¼‰ï¼š`O_DIRECT` æ›´ä¼˜ï¼Œé¿å…ç¼“å­˜æ±¡æŸ“å’Œä¸€è‡´æ€§å¼€é”€ã€‚
- **æ··åˆç­–ç•¥ä¸å¯è¡Œ**ï¼šå°è¯•â€œå†™ç”¨ O_DIRECTï¼Œè¯»ä¸ç”¨â€åè€Œå¯¼è‡´æ€§èƒ½ä¸‹é™ï¼ˆæœ€å¤šé™ 3Ã—ï¼‰ï¼Œå› ä¸ºç¼“å­˜æ— æ³•æœ‰æ•ˆç»´æŒã€‚

#### ğŸ§ª æ¶ˆèå®éªŒç»“æœ
- **DataStates-LLM æ¢å¤æ…¢çš„æ ¹æœ¬åŸå› **ï¼ˆFigure 13ï¼‰ï¼š
  - å†…å­˜åˆ†é…æ—¶é—´å‡ ä¹ç­‰äºå®é™… PFS è¯»å–æ—¶é—´ã€‚
  - è‹¥å»é™¤å†…å­˜åˆ†é…å¼€é”€ï¼Œæ¢å¤ååå¯æ¥è¿‘ç†æƒ³åŸºçº¿ï¼ˆFigure 14ï¼‰ã€‚
- **ç»“è®º**ï¼šæ¢å¤é˜¶æ®µæ˜¯ **memory-bound**ï¼Œè€Œé I/O-boundã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **èšåˆè‡³å…³é‡è¦**ï¼ˆAggregation is Keyï¼‰  
   ç»†ç²’åº¦çš„ `file-per-shard` ç­–ç•¥é€ æˆä¸¥é‡çš„å…ƒæ•°æ®ç«äº‰å’Œä½æ•ˆå¸¦å®½åˆ©ç”¨ã€‚**ç²—ç²’åº¦èšåˆ**ï¼ˆå¦‚ file-per-process æˆ– single fileï¼‰èƒ½æ˜¾è‘—æé«˜ååã€ç®€åŒ–ç®¡ç†ã€‚

2. **liburing å…·å¤‡å·¨å¤§æ½œåŠ›ï¼Œä½†éœ€é…åˆè‰¯å¥½è®¾è®¡**  
   è™½ç„¶ DataStates-LLM å·²ä½¿ç”¨ liburingï¼Œä½†ç”±äºè¿è¡Œæ—¶å¼€é”€ï¼ˆåŠ¨æ€å†…å­˜åˆ†é…ã€ç¼ºä¹èšåˆï¼‰ï¼Œæœªèƒ½å‘æŒ¥å…¶å…¨éƒ¨æ€§èƒ½ã€‚çœŸæ­£çš„æ€§èƒ½æå‡æ¥è‡ª **I/O èšåˆ + é›¶æ‹·è´ + æ‰¹é‡æäº¤** çš„ååŒè®¾è®¡ã€‚

3. **O_DIRECT å¯¹è¯»å†™çš„ä¸å¯¹ç§°å½±å“å¿…é¡»æ­£è§†**  
   ä¸èƒ½ç®€å•æ²¿ç”¨ä¼ ç»Ÿ HPC ä¸­â€œè¯»å¿«å†™æ…¢â€çš„ç»éªŒã€‚LLM æ¢å¤æ¶‰åŠå¤§é‡éè¿ç»­ã€æ··åˆå¤§å°çš„è®¿é—®ï¼Œpage cache æ•ˆæœæœ‰é™ï¼Œç”šè‡³æœ‰å®³ã€‚**ç»Ÿä¸€å¯ç”¨ O_DIRECT æ˜¯æ›´ç¨³å®šçš„é€‰æ‹©**ã€‚

4. **ç°æœ‰ C/R æ¡†æ¶å­˜åœ¨æ˜æ˜¾æ€§èƒ½ç¼ºå£**  
   å³ä½¿æœ€å…ˆè¿›çš„å¼•æ“ï¼ˆTorchSnapshotã€DataStates-LLMï¼‰ä¹Ÿè¿œæœªè¾¾åˆ°ç†è®ºæé™ã€‚**ä¸»è¦ç“¶é¢ˆä¸åœ¨ I/O å­ç³»ç»Ÿæœ¬èº«ï¼Œè€Œåœ¨ä¸Šå±‚æ¡†æ¶çš„è®¾è®¡ç¼ºé™·**ï¼ˆå¦‚é¢‘ç¹å†…å­˜åˆ†é…ã€æ— èšåˆã€å°æ–‡ä»¶çˆ†ç‚¸ï¼‰ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ç ”ç©¶é›†ä¸­åœ¨ **å•èŠ‚ç‚¹åˆ°ä¸­å°è§„æ¨¡å¤šèŠ‚ç‚¹** åœºæ™¯ï¼Œè¶…å¤§è§„æ¨¡ï¼ˆåƒèŠ‚ç‚¹çº§ï¼‰ä¸‹çš„å¯æ‰©å±•æ€§å°šæœªéªŒè¯ã€‚
- å®éªŒåŸºäº **Lustre PFS**ï¼Œå…¶ä»–æ–‡ä»¶ç³»ç»Ÿï¼ˆå¦‚ GPFSã€BeeGFSï¼‰çš„è¡Œä¸ºå¯èƒ½ä¸åŒã€‚
- å¾®åŸºå‡†è™½é€¼è¿‘çœŸå®è´Ÿè½½ï¼Œä½†ä»æ— æ³•å®Œå…¨æ›¿ä»£ç«¯åˆ°ç«¯è®­ç»ƒä»»åŠ¡çš„å‹åŠ›æµ‹è¯•ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **é›†æˆä¼˜åŒ–åˆ°ç”Ÿäº§æ¡†æ¶**ï¼š
   - åœ¨ DataStates-LLM ç­‰æ¡†æ¶ä¸­å®ç° **æŒä¹…åŒ– buffer å¤ç”¨**ï¼ˆpersistent buffer reuseï¼‰ã€‚
   - æ”¯æŒ **multi-threaded completion handling** ä»¥å……åˆ†åˆ©ç”¨ completion queueã€‚
   
2. **å¼€å‘ hybrid aggregation ç­–ç•¥**ï¼š
   - ç”¨æˆ·ç©ºé—´é€»è¾‘èšåˆ + å†…æ ¸çº§è¯·æ±‚æ‰¹å¤„ç†ï¼ˆbatchingï¼‰ç›¸ç»“åˆã€‚
   - è‡ªé€‚åº”é€‰æ‹©èšåˆç²’åº¦ï¼Œå¹³è¡¡åè°ƒå¼€é”€ä¸ I/O æ•ˆç‡ã€‚

3. **æ¨åŠ¨æ–°å‹ç›‘æ§å·¥å…·å‘å±•**ï¼š
   - å½“å‰ Darshan ç­‰å·¥å…·ä¸æ”¯æŒ liburingï¼ŒäºŸéœ€æ–°çš„ trace åˆ†æå·¥å…·æ¥æ•è·å¼‚æ­¥ I/O å®Œæˆæ—¶é—´ã€‚

4. **æ¢ç´¢ä¸ NVMe-oFã€CXL ç­‰æ–°å…´å­˜å‚¨æŠ€æœ¯çš„ååŒä¼˜åŒ–**ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬è®ºæ–‡æ­ç¤ºäº†å½“å‰ LLM Checkpoint/Restore ç³»ç»Ÿä¸­â€œåº”ç”¨å‹å¥½â€ä¸â€œæ–‡ä»¶ç³»ç»Ÿé«˜æ•ˆâ€ä¹‹é—´çš„æ ¹æœ¬çŸ›ç›¾ï¼Œå¹¶è¯æ˜é€šè¿‡ **æ–‡ä»¶ç³»ç»Ÿæ„ŸçŸ¥çš„ I/O èšåˆ + liburing + O_DIRECT + é¢„åˆ†é… buffer** çš„ç»„åˆï¼Œå¯å®ç°é«˜è¾¾ **7.6Ã— çš„å†™ååæå‡**ï¼Œä¸ºä¸‹ä¸€ä»£é«˜æ€§èƒ½ C/R æ¡†æ¶æä¾›äº†æ˜ç¡®çš„è®¾è®¡è“å›¾ã€‚

</details>

---

### 13. [Context-aware LLM-based AI Agents for Human-centered Energy Management Systems in Smart Buildings](https://arxiv.org/abs/2512.25055)

**Authors**: Tianzhi He, Farrokh Jazizadeh  
**Category**: cs.AI  
**Published**: 2026-01-01  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.25055v1  

#### Abstract
This study presents a conceptual framework and a prototype assessment for Large Language Model (LLM)-based Building Energy Management System (BEMS) AI agents to facilitate context-aware energy management in smart buildings through natural language interaction. The proposed framework comprises three ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

**è®ºæ–‡æ ‡é¢˜**: *Context-aware LLM-based AI Agents for Human-centered Energy Management Systems in Smart Buildings*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰çš„ Building Energy Management Systems (BEMS) å­˜åœ¨ä»¥ä¸‹ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **Explainabilityï¼ˆå¯è§£é‡Šæ€§å·®ï¼‰**ï¼šç³»ç»Ÿéš¾ä»¥å‘ç”¨æˆ·è§£é‡Šæ§åˆ¶å†³ç­–èƒŒåçš„é€»è¾‘ï¼Œå¯¼è‡´ç”¨æˆ·ä¸ä¿¡ä»»ã€‚
- **Adaptivityï¼ˆé€‚åº”æ€§ä¸è¶³ï¼‰**ï¼šç•Œé¢æ— æ³•æ ¹æ®ç”¨æˆ·çš„åå¥½ã€èƒŒæ™¯çŸ¥è¯†æˆ–ä¸Šä¸‹æ–‡è¿›è¡Œä¸ªæ€§åŒ–è°ƒæ•´ã€‚
- **Integrationï¼ˆé›†æˆå›°éš¾ï¼‰**ï¼šè®¾å¤‡ç”Ÿæ€ç¢ç‰‡åŒ–ï¼Œç¼ºä¹ç»Ÿä¸€çš„æ™ºèƒ½åè°ƒå±‚æ¥ç®¡ç†å¤šè®¾å¤‡äº¤äº’ã€‚

æ­¤å¤–ï¼Œç°æœ‰çš„åŸºäºè‡ªç„¶è¯­è¨€çš„æ™ºèƒ½åŠ©æ‰‹ï¼ˆå¦‚æ™ºèƒ½éŸ³ç®±ï¼‰åŠŸèƒ½æœ‰é™ï¼Œä»…èƒ½å¤„ç†ç®€å•æŒ‡ä»¤ï¼Œç¼ºä¹å¯¹å»ºç­‘ç¯å¢ƒä¸Šä¸‹æ–‡ï¼ˆå¦‚èƒ½è€—æ¨¡å¼ã€è®¾å¤‡çŠ¶æ€ã€ç”µä»·ç­–ç•¥ï¼‰çš„ç†è§£èƒ½åŠ›ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
æœ¬æ–‡æå‡ºäº†ä¸€ç§**é¢å‘äººç±»ä¸­å¿ƒçš„ã€å…·å¤‡ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›çš„LLM-based BEMS AI Agentæ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

- **ä¸‰æ¨¡å—é—­ç¯æ¶æ„è®¾è®¡**ï¼š
  - **Perceptionï¼ˆæ„ŸçŸ¥æ¨¡å—ï¼‰**ï¼šæ•´åˆæ¥è‡ªæ™ºèƒ½ç”µè¡¨ã€ä¼ æ„Ÿå™¨ã€å¤©æ°”ã€æ—¥å†ç­‰å¤šæºå¼‚æ„æ•°æ®ã€‚
  - **Brainï¼ˆå¤§è„‘æ¨¡å—ï¼‰**ï¼šä»¥LLMä¸ºæ ¸å¿ƒï¼Œç»“åˆé•¿æœŸè®°å¿†ï¼ˆlong-term memoryï¼‰ã€ç³»ç»Ÿé…ç½®æ–‡ä»¶ï¼ˆprofilesï¼‰ã€ä»£ç æ‰§è¡Œå·¥å…·ï¼ˆcode interpreterï¼‰å®ç°è‡ªä¸»æ¨ç†ä¸æ•°æ®åˆ†æã€‚
  - **Actionï¼ˆè¡ŒåŠ¨æ¨¡å—ï¼‰**ï¼šæ”¯æŒè‡ªç„¶è¯­è¨€å¯¹è¯è¾“å‡ºã€å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆï¼Œå¹¶èƒ½é€šè¿‡å‡½æ•°è°ƒç”¨ï¼ˆfunction callingï¼‰ç›´æ¥æ§åˆ¶æ™ºèƒ½è®¾å¤‡ï¼ˆå¦‚HVACã€ç…§æ˜ã€EVå……ç”µå™¨ï¼‰ã€‚

- **å¼•å…¥ä¸Šä¸‹æ–‡æ„ŸçŸ¥æœºåˆ¶**ï¼š
  - åˆ©ç”¨ **Tree-of-Thought (ToT)** å’Œ **Chain-of-Thought (CoT)** æ¨ç†ç­–ç•¥ï¼Œæå‡å¤æ‚ä»»åŠ¡çš„åˆ†è§£ä¸è§„åˆ’èƒ½åŠ›ã€‚
  - è®¾è®¡äº†ç»“æ„åŒ–çš„ **intent classification ä½“ç³»**ï¼Œå°†ç”¨æˆ·æŸ¥è¯¢åˆ†ä¸º6å¤§ç±»ã€24ä¸ªå­ç±»ï¼Œç¡®ä¿ç²¾å‡†ç†è§£æ¨¡ç³Šæ„å›¾ã€‚
  - å®ç°äº†**é•¿æœŸè®°å¿†ç®¡ç†æœºåˆ¶**ï¼Œå…è®¸ç”¨æˆ·é€šè¿‡è‡ªç„¶è¯­è¨€æŒ‡ä»¤åˆ›å»ºã€ä¿®æ”¹æˆ–åˆ é™¤åå¥½è§„åˆ™ï¼ˆå¦‚â€œæ™šä¸Š10ç‚¹åè°ƒä½ç©ºè°ƒæ¸©åº¦â€ï¼‰ï¼Œå¹¶ç”¨äºåç»­å†³ç­–ã€‚

- **ç»Ÿä¸€åˆ†æä¸æ§åˆ¶æ¥å£**ï¼š
  é¦–æ¬¡å°†**èƒ½æºæ•°æ®åˆ†æ**ï¼ˆå¦‚æˆæœ¬é¢„æµ‹ã€èŠ‚èƒ½å»ºè®®ï¼‰ä¸**è®¾å¤‡è‡ªåŠ¨åŒ–æ§åˆ¶**ï¼ˆå¦‚è°ƒåº¦ã€è°ƒèŠ‚ï¼‰é›†æˆåœ¨ä¸€ä¸ªåŸºäºè‡ªç„¶è¯­è¨€äº¤äº’çš„AIä»£ç†ä¸­ï¼Œå®ç°äº†ä»â€œè¢«åŠ¨å“åº”â€åˆ°â€œä¸»åŠ¨è¾…åŠ©â€çš„è½¬å˜ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»ŸBEMS / æ™ºèƒ½éŸ³ç®± | æœ¬ç ”ç©¶æå‡ºçš„LLM-based BEMS AI Agent |
|------|---------------------|----------------------------------------|
| äº¤äº’æ–¹å¼ | å›¾å½¢ä»ªè¡¨ç›˜ / ç®€å•è¯­éŸ³å‘½ä»¤ | è‡ªç„¶è¯­è¨€å¯¹è¯ï¼Œæ”¯æŒå¼€æ”¾åŸŸå¤æ‚è¯·æ±‚ |
| ä¸Šä¸‹æ–‡ç†è§£ | å¼±ï¼Œä¾èµ–é¢„è®¾è§„åˆ™ | å¼ºï¼Œèåˆå®æ—¶æ•°æ®ã€å†å²è¡Œä¸ºã€ç”¨æˆ·åå¥½ |
| åŠŸèƒ½èŒƒå›´ | åˆ†æ or æ§åˆ¶ï¼ˆåˆ†ç¦»ï¼‰ | åˆ†æ + æ§åˆ¶ + å¯è§†åŒ– + è®°å¿†ä¸€ä½“åŒ– |
| ä¸ªæ€§åŒ–èƒ½åŠ› | ä½ | é«˜ï¼Œæ”¯æŒé•¿æœŸè®°å¿†å­¦ä¹ ä¸è‡ªå®šä¹‰é€»è¾‘ |
| å†³ç­–é€æ˜åº¦ | å·® | è¾ƒå¥½ï¼Œå¯é€šè¿‡è‡ªç„¶è¯­è¨€è§£é‡Šæ¨ç†è¿‡ç¨‹ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **Pecan Street DataPort** ä¸­çš„çœŸå®ä½å®…èƒ½æºæ•°æ®ã€‚
- å…±é€‰å– **4æ ‹ä½å®…å»ºç­‘** è¿›è¡Œæµ‹è¯•ï¼š
  - TX-01 å’Œ TX-02ï¼ˆå¾·å…‹è¨æ–¯å·å¥¥æ–¯æ±€ï¼Œ2018å¹´1æœˆï¼‰
  - NY-01 å’Œ NY-02ï¼ˆçº½çº¦å·ï¼Œ2019å¹´6æœˆï¼‰
- æ•°æ®åŒ…æ‹¬ï¼š
  - ç”µè·¯çº§ç”¨ç”µæ•°æ®ï¼ˆ1åˆ†é’Ÿç²’åº¦ï¼‰
  - å…‰ä¼å‘ç”µé‡
  - ç”µåŠ¨æ±½è½¦å……ç”µè®°å½•
  - å®¶åº­ç”µå™¨æ¸…å•åŠè¿è¡ŒçŠ¶æ€
  - åˆ†æ—¶ç”µä»·ä¿¡æ¯ï¼ˆpeak/off-peakï¼‰

### å®éªŒè®¾ç½®
- **åŸå‹å¼€å‘å¹³å°**ï¼šåŸºäº OpenAI Assistants API æ„å»ºï¼Œä½¿ç”¨ `gpt-4o` æ¨¡å‹ã€‚
- **æ¨¡æ‹Ÿç¯å¢ƒæ„å»º**ï¼š
  - æ„ŸçŸ¥æ¨¡å—ç”±ä¸¤ä¸ªæ–‡ä»¶æ¨¡æ‹Ÿï¼š`CSV` æ–‡ä»¶å­˜å‚¨å†å²èƒ½è€—æ•°æ®ï¼Œ`JSON` æ–‡ä»¶å­˜å‚¨è®¾å¤‡å®æ—¶çŠ¶æ€ã€‚
  - è¡ŒåŠ¨æ¨¡å—é€šè¿‡è‡ªå®šä¹‰å‡½æ•°ï¼ˆå¦‚ `action-devices-EXECUTE`, `action-schedule-CREATE`ï¼‰æ¨¡æ‹Ÿè®¾å¤‡æ§åˆ¶ä¸è°ƒåº¦ã€‚
- **ç”¨æˆ·æŸ¥è¯¢åŸºå‡†é›†**ï¼š
  - æ„å»ºäº†åŒ…å« **120ä¸ªç”¨æˆ·æŸ¥è¯¢** çš„æµ‹è¯•é›†ï¼Œè¦†ç›–6ä¸ªä¸»ç±»åˆ«ã€24ä¸ªå­ç±»åˆ«ã€‚
  - æ¯ä¸ªå­ç±»5æ¡æŸ¥è¯¢ï¼Œåœ¨4ä¸ªå»ºç­‘ä¸Šåˆ†åˆ«æµ‹è¯•ï¼Œå…±äº§ç”Ÿ **480æ¡å“åº”è®°å½•**ã€‚

### è¯„ä¼°æŒ‡æ ‡
é‡‡ç”¨äº”ç»´ç»¼åˆè¯„ä¼°ä½“ç³»ï¼š
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Latency** | å“åº”å»¶è¿Ÿï¼ˆç§’ï¼‰ï¼Œä»æ¥æ”¶æŸ¥è¯¢åˆ°è¿”å›æœ€ç»ˆç­”æ¡ˆçš„æ—¶é—´ |
| **Functionality** | æ„å›¾åˆ†ç±»å‡†ç¡®ç‡ï¼ˆPrimary & Secondary Intentï¼‰ |
| **Capability** | å·¥å…·è°ƒç”¨å‡†ç¡®æ€§ï¼ˆTool Call Accuracyï¼‰ |
| **Accuracy** | å›ç­”æ­£ç¡®æ€§è¯„åˆ†ï¼ˆCorrect: 1, Partial: 0.5, Incorrect: 0ï¼‰ |
| **Cost** | å•æ¬¡æŸ¥è¯¢çš„Tokenæ¶ˆè€—ä¸ç»æµæˆæœ¬ï¼ˆåŸºäºOpenAIå®šä»·ï¼‰ |

> æ³¨ï¼šæœªè®¾ç½®ä¼ ç»ŸåŸºçº¿æ¨¡å‹ï¼ˆå¦‚è§„åˆ™å¼•æ“æˆ–éLLMç³»ç»Ÿï¼‰ä½œä¸ºå¯¹æ¯”ï¼Œè€Œæ˜¯èšç„¦äº**æ¡†æ¶å¯è¡Œæ€§éªŒè¯ä¸å†…éƒ¨æ€§èƒ½å‰–æ**ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»ï¼ˆå¹³å‡å€¼ across æ‰€æœ‰å»ºç­‘ï¼‰

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| å¹³å‡å“åº”æ—¶é—´ï¼ˆLatencyï¼‰ | **23 ç§’** |
| ä¸»æ„å›¾åˆ†ç±»å‡†ç¡®ç‡ | **91%** |
| æ¬¡æ„å›¾åˆ†ç±»å‡†ç¡®ç‡ | **76%** |
| å·¥å…·è°ƒç”¨å‡†ç¡®ç‡ | **94%** |
| æ€»ä½“å›ç­”å‡†ç¡®ç‡ | **79%** |
| å¹³å‡æ¯æŸ¥è¯¢Tokenæ•° | **29,467** |
| å¹³å‡æ¯æŸ¥è¯¢æˆæœ¬ï¼ˆgpt-4oï¼‰ | **$0.0776** |

### ä¸åŒä»»åŠ¡ç±»åˆ«çš„æ€§èƒ½å·®å¼‚ï¼ˆè§ Table 5ï¼‰

| ä»»åŠ¡ç±»åˆ« | å“åº”å‡†ç¡®ç‡ | å¹³å‡å»¶è¿Ÿ | æˆæœ¬ï¼ˆ$/queryï¼‰ |
|--------|-----------|----------|----------------|
| **Device Status & Control** | **86%** | 19 ç§’ | $0.075 |
| **Memory-related Tasks** | **97%** | 12 ç§’ | $0.048 |
| **General Info & Support** | **98%** | 13 ç§’ | $0.050 |
| **Energy Consumption & Analysis** | 77% | 27 ç§’ | $0.095 |
| **Device Scheduling & Automation** | 74% | 14 ç§’ | $0.056 |
| **Cost Management** | **49%** | 49 ç§’ï¼ˆå»é™¤å¼‚å¸¸å€¼åä¸º34ç§’ï¼‰ | **$0.141** |

> ğŸ’¡ **å…³é”®è§‚å¯Ÿ**ï¼š
> - **è®¾å¤‡æ§åˆ¶ç±»ä»»åŠ¡è¡¨ç°æœ€ä½³**ï¼šå‡†ç¡®ç‡é«˜ã€å»¶è¿Ÿä½ï¼Œè¯´æ˜LLMèƒ½æœ‰æ•ˆè§£ææŒ‡ä»¤å¹¶é€šè¿‡å‡½æ•°è°ƒç”¨æ‰§è¡Œã€‚
> - **æˆæœ¬ç®¡ç†ä»»åŠ¡æœ€å¼±**ï¼šæ¶‰åŠå¤šæ­¥è®¡ç®—ï¼ˆèƒ½è€—Ã—ç”µä»·Â±è¡¥è´´ï¼‰ï¼Œæ˜“å‡ºé”™ï¼Œå°¤å…¶æ˜¯å•ä½è½¬æ¢å’Œä¿¡ç”¨æŠµæ‰£é€»è¾‘ã€‚
> - **è®°å¿†åŠŸèƒ½é«˜æ•ˆå¯é **ï¼šé•¿æœŸè®°å¿†æ“ä½œå¿«é€Ÿä¸”å‡†ç¡®ï¼Œæ”¯æŒä¸ªæ€§åŒ–ä¹ æƒ¯å»ºæ¨¡ã€‚
> - **é«˜èµ„æºæ¶ˆè€—é›†ä¸­åœ¨åˆ†æç±»ä»»åŠ¡**ï¼šèƒ½é‡åˆ†æå’Œæˆæœ¬ç®¡ç†éœ€é¢‘ç¹è°ƒç”¨ `Code Interpreter`ï¼Œå¯¼è‡´Tokenç”¨é‡æ˜¾è‘—ä¸Šå‡ã€‚

### æ¶ˆèå®éªŒä¸åˆ†æï¼ˆéšå«åœ¨è®¾è®¡ä¸­ï¼‰
è™½ç„¶æ²¡æœ‰æ˜¾å¼çš„æ¶ˆèå®éªŒè¡¨æ ¼ï¼Œä½†æ–‡ä¸­é€šè¿‡ä»¥ä¸‹æ–¹å¼ä½“ç°äº†æ¨¡å—æœ‰æ•ˆæ€§ï¼š
- **ToT + CoT æ¨ç†ç»“æ„** æ˜¾è‘—æå‡äº†æ„å›¾è¯†åˆ«ç²¾åº¦ï¼ˆprimary: 91%, secondary: 76%ï¼‰ã€‚
- **Sync-Query-Execute æµç¨‹** æœ‰æ•ˆé˜²æ­¢äº†LLMâ€œå¹»è§‰â€ï¼Œç¡®ä¿åªå¯¹çœŸå®å­˜åœ¨çš„è®¾å¤‡å‘å‡ºæ§åˆ¶å‘½ä»¤ã€‚
- **é•¿æœŸè®°å¿†æœºåˆ¶** è¢«è¯æ˜å¯ç”¨äºæŒç»­ä¼˜åŒ–å»ºè®®ï¼ˆå¦‚ç»“åˆç”¨æˆ·ä½œæ¯æ¨èèŠ‚èƒ½è®¡åˆ’ï¼‰ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **LLM-based AI Agent å¯æœ‰æ•ˆæ”¯æ’‘ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„BEMSäº¤äº’**ï¼š
   - èƒ½å¤Ÿç†è§£å¤æ‚ã€æ¨¡ç³Šçš„è‡ªç„¶è¯­è¨€è¯·æ±‚ï¼ˆå¦‚â€œå¸®æˆ‘çœç”µâ€ï¼‰ï¼Œå¹¶ç»“åˆå®é™…æ•°æ®æä¾›å®šåˆ¶åŒ–å»ºè®®ã€‚
   - æ”¯æŒè·¨ä»»åŠ¡ååŒï¼ˆåˆ†æâ†’å»ºè®®â†’è‡ªåŠ¨è°ƒåº¦ï¼‰ï¼Œå½¢æˆé—­ç¯æ™ºèƒ½æœåŠ¡ã€‚

2. âš ï¸ **æ€§èƒ½å­˜åœ¨æ˜æ˜¾ä»»åŠ¡ä¾èµ–æ€§**ï¼š
   - æ§åˆ¶ç±»ä»»åŠ¡ç¨³å®šé«˜æ•ˆï¼Œé€‚åˆè½åœ°åº”ç”¨ï¼›
   - å¤æ‚æ•°å€¼æ¨ç†ä»»åŠ¡ï¼ˆå¦‚æˆæœ¬ä¼°ç®—ï¼‰ä»é¢ä¸´å‡†ç¡®æ€§æŒ‘æˆ˜ï¼Œéœ€æ›´ä¸¥æ ¼çš„æç¤ºå·¥ç¨‹æˆ–å¤–éƒ¨éªŒè¯æœºåˆ¶ã€‚

3. ğŸ” **æ¡†æ¶å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›**ï¼š
   - ANOVAæ£€éªŒæ˜¾ç¤ºï¼Œé™¤ä¸ªåˆ«æŒ‡æ ‡å¤–ï¼Œä¸åŒå»ºç­‘é—´çš„æ€§èƒ½æ— ç»Ÿè®¡å­¦æ˜¾è‘—å·®å¼‚ï¼ˆp > 0.05ï¼‰ï¼Œè¡¨æ˜è¯¥æ¡†æ¶å¯æ¨å¹¿è‡³å¤šæ ·åŒ–ä½å®…åœºæ™¯ã€‚

4. âš–ï¸ **å­˜åœ¨æ•ˆç‡ä¸å‡†ç¡®æ€§ä¹‹é—´çš„æƒè¡¡ï¼ˆtrade-offï¼‰**ï¼š
   - æ›´å¤æ‚çš„ä»»åŠ¡éœ€è¦æ›´å¤šå·¥å…·è°ƒç”¨å’ŒTokenæ¶ˆè€—ï¼Œå¸¦æ¥æ›´é«˜å»¶è¿Ÿå’Œæˆæœ¬ï¼Œä½†ä¸ä¸€å®šæé«˜å‡†ç¡®æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡å¤–éƒ¨å·¥å…·ä¸æ•°æ®è¾“å…¥**ï¼šè‹¥ä¼ æ„Ÿå™¨æ•°æ®ç¼ºå¤±æˆ–é”™è¯¯ï¼Œå¯èƒ½å¯¼è‡´é”™è¯¯å†³ç­–ã€‚
- **LLMå›ºæœ‰ç¼ºé™·å½±å“å¯é æ€§**ï¼šä»å¯èƒ½å‡ºç°å¹»è§‰ã€è®¡ç®—é”™è¯¯ã€å•ä½æ··æ·†ç­‰é—®é¢˜ã€‚
- **å®‰å…¨ä¸éšç§é£é™©**ï¼šç›´æ¥æ§åˆ¶ç‰©ç†è®¾å¤‡éœ€ä¸¥æ ¼æƒé™ç®¡ç†å’Œå®¡è®¡æœºåˆ¶ã€‚
- **ç¼ºä¹çœŸå®ç”¨æˆ·äº¤äº’ç ”ç©¶**ï¼šç›®å‰æ˜¯æ¨¡æ‹Ÿæµ‹è¯•ï¼Œå°šæœªéªŒè¯ç”¨æˆ·ä½“éªŒã€æ»¡æ„åº¦å’Œæ¥å—åº¦ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **å¢å¼ºå®‰å…¨æ€§ä¸é²æ£’æ€§**ï¼š
   - å¼•å…¥å¤šAgentåä½œæœºåˆ¶ï¼ˆmulti-agent systemï¼‰ï¼Œåˆ†å·¥å¤„ç†åˆ†æã€æ§åˆ¶ã€å®¡æ ¸ç­‰èŒè´£ã€‚
   - åŠ å…¥å½¢å¼åŒ–éªŒè¯æ¨¡å—ï¼Œç¡®ä¿æ§åˆ¶å‘½ä»¤ç¬¦åˆå®‰å…¨çº¦æŸã€‚

2. **ä¼˜åŒ–æ¨ç†æ•ˆç‡**ï¼š
   - æ¢ç´¢è½»é‡åŒ–æ¨¡å‹æˆ–ç¼“å­˜æœºåˆ¶ï¼Œé™ä½å»¶è¿Ÿä¸æˆæœ¬ï¼Œæå‡å®æ—¶æ€§ã€‚

3. **æ·±åŒ–äººæœºååŒæœºåˆ¶**ï¼š
   - å¼€å±•çœŸå®ç”¨æˆ·å®éªŒï¼Œç ”ç©¶å¤šè½®å¯¹è¯ã€ä¸»åŠ¨å»ºè®®ã€åé¦ˆå­¦ä¹ ç­‰é«˜çº§äº¤äº’æ¨¡å¼ã€‚

4. **æ‰©å±•åº”ç”¨åœºæ™¯**ï¼š
   - å°†æ¡†æ¶åº”ç”¨äºå•†ä¸šæ¥¼å®‡ã€å›­åŒºçº§èƒ½æºç®¡ç†ç³»ç»Ÿã€‚
   - ç»“åˆ Proactive AI ç­–ç•¥ï¼Œå®ç°é¢„æµ‹æ€§ç»´æŠ¤ä¸èŠ‚èƒ½å¹²é¢„ã€‚

5. **ç”Ÿå‘½å‘¨æœŸå¯æŒç»­æ€§è¯„ä¼°**ï¼š
   - è¯„ä¼°LLMæ¨ç†æœ¬èº«å¸¦æ¥çš„ç¢³è¶³è¿¹ä¸èƒ½è€—ï¼Œç¡®ä¿æ•´ä½“ç³»ç»ŸçœŸæ­£å®ç°â€œèŠ‚èƒ½å¢æ•ˆâ€ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡ºäº†é¦–ä¸ªé›†**ä¸Šä¸‹æ–‡æ„ŸçŸ¥ã€è‡ªç„¶è¯­è¨€äº¤äº’ã€è‡ªä¸»æ¨ç†ä¸è®¾å¤‡æ§åˆ¶**äºä¸€ä½“çš„LLM-based BEMS AI Agentæ¡†æ¶ï¼Œå¹¶é€šè¿‡çœŸå®æ•°æ®éªŒè¯äº†å…¶å¯è¡Œæ€§ä¸æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨è®¾å¤‡æ§åˆ¶å’Œè®°å¿†ç®¡ç†æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨å¤æ‚è®¡ç®—ä»»åŠ¡ä¸Šä»æœ‰æ”¹è¿›ç©ºé—´ï¼Œä¸ºä¸‹ä¸€ä»£äººæœ¬åŒ–æ™ºèƒ½å»ºç­‘ç³»ç»Ÿæä¾›äº†é‡è¦èŒƒå¼å‚è€ƒã€‚

</details>

---

### 14. [HaluNet: Multi-Granular Uncertainty Modeling for Efficient Hallucination Detection in LLM Question Answering](https://arxiv.org/abs/2512.24562)

**Authors**: Chaodong Tong, Qi Zhang, Jiayang Gao, Lei Jiang, Yanbing Liu, Nannan Sun  
**Category**: cs.CL  
**Published**: 2026-01-01  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.24562v1  

#### Abstract
Large Language Models (LLMs) excel at question answering (QA) but often generate hallucinations, including factual errors or fabricated content. Detecting hallucinations from internal uncertainty signals is attractive due to its scalability and independence from external resources. Existing methods ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# HaluNet: Multi-Granular Uncertainty Modeling for Efficient Hallucination Detection in LLM Question Answering â€”â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é—®ç­”ï¼ˆQAï¼‰ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å¸¸ç”Ÿæˆ**å¹»è§‰ï¼ˆhallucinationï¼‰**ï¼Œå³äº‹å®é”™è¯¯æˆ–è™šæ„å†…å®¹ã€‚ä¼ ç»Ÿæ£€æµ‹æ–¹æ³•ä¾èµ–å¤–éƒ¨çŸ¥è¯†åº“æˆ–å¤šè½®éªŒè¯ï¼Œæˆæœ¬é«˜ã€éš¾ä»¥å®æ—¶éƒ¨ç½²ã€‚æœ¬æ–‡èšç„¦äºåˆ©ç”¨**æ¨¡å‹å†…éƒ¨ä¸ç¡®å®šæ€§ä¿¡å·**è¿›è¡Œé«˜æ•ˆã€å¯æ‰©å±•çš„å¹»è§‰æ£€æµ‹ã€‚

ç°æœ‰æ–¹æ³•é€šå¸¸åªå…³æ³¨å•ä¸€ç±»å‹çš„ä¸ç¡®å®šæ€§ï¼ˆå¦‚token-levelæ¦‚ç‡æˆ–éšè—çŠ¶æ€ï¼‰ï¼Œå¿½ç•¥äº†ä¸åŒä¿¡å·ä¹‹é—´çš„äº’è¡¥æ€§ï¼Œå°¤å…¶æ˜¯ï¼š
- **æ¦‚ç‡ä¸ç¡®å®šæ€§**ï¼ˆå¦‚token likelihoodï¼‰
- **è¯­ä¹‰è¡¨ç¤ºä¸­çš„ä¸ç¡®å®šæ€§**ï¼ˆå¦‚embeddingå˜åŒ–ï¼‰

è¿™é™åˆ¶äº†æ£€æµ‹çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šHaluNet
ä½œè€…æå‡º **HaluNet**ï¼Œä¸€ä¸ªè½»é‡çº§ã€å¯è®­ç»ƒçš„ç¥ç»ç½‘ç»œæ¡†æ¶ï¼Œç”¨äºæ•´åˆå¤šç²’åº¦çš„token-levelä¸ç¡®å®šæ€§ä¿¡å·ï¼Œå®ç°é«˜æ•ˆçš„å•æ¬¡ï¼ˆone-passï¼‰å¹»è§‰æ£€æµ‹ã€‚

#### åˆ›æ–°ç‚¹ï¼š
1. **å¤šç²’åº¦ä¸ç¡®å®šæ€§èåˆ**  
   é¦–æ¬¡ç»Ÿä¸€å»ºæ¨¡ä¸‰ç§äº’è¡¥ä¿¡å·ï¼š
   - **Log-likelihoods**ï¼ˆæ¦‚ç‡ç½®ä¿¡åº¦ï¼‰
   - **Predictive Entropy**ï¼ˆåˆ†å¸ƒä¸ç¡®å®šæ€§ï¼‰
   - **Hidden State Embeddings**ï¼ˆè¯­ä¹‰è½¨è¿¹ä¸è¡¨å¾ä¸ç¡®å®šæ€§ï¼‰

2. **å¤šåˆ†æ”¯æ¶æ„è®¾è®¡ï¼ˆMulti-Branch Architectureï¼‰**  
   - ä¸åŒç‰¹å¾é‡‡ç”¨æœ€é€‚åˆçš„ç¼–ç å™¨ï¼š
     - æ ‡é‡ç‰¹å¾ï¼ˆlog-likelihood, entropyï¼‰â†’ å¹³å‡æ± åŒ– + MLP
     - å‘é‡ç‰¹å¾ï¼ˆembeddingsï¼‰â†’ 1D CNN + è‡ªé€‚åº”å¹³å‡æ± åŒ–
   - æ”¯æŒæ³¨æ„åŠ›æœºåˆ¶æˆ–MLPè¿›è¡Œè·¨ä¿¡å·èåˆï¼Œå¢å¼ºäº¤äº’è¡¨è¾¾èƒ½åŠ›

3. **æ— éœ€äººå·¥æ ‡æ³¨çš„ç›‘ç£å­¦ä¹ èŒƒå¼**  
   ä½¿ç”¨ **LLM-as-a-Judge** è‡ªåŠ¨ç”Ÿæˆå¹»è§‰æ ‡ç­¾ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œé¿å…æ˜‚è´µçš„äººå·¥æ ‡æ³¨ï¼Œæå‡å¯æ‰©å±•æ€§ã€‚

4. **é€‚ç”¨äºä¸Šä¸‹æ–‡å­˜åœ¨ä¸å¦çš„é€šç”¨åœºæ™¯**  
   åœ¨æœ‰æ— contextçš„æƒ…å†µä¸‹å‡è¡¨ç°ä¼˜å¼‚ï¼Œæ”¯æŒçœŸå®åº”ç”¨ä¸­çš„çµæ´»éƒ¨ç½²ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | HaluNet | ç°æœ‰æ–¹æ³• |
|------|--------|---------|
| æ•ˆç‡ | å•æ¬¡æ¨ç†ï¼Œä½å»¶è¿Ÿï¼ˆ~0.1s/100æ ·æœ¬ï¼‰ | å¤šé‡‡æ ·æ–¹æ³•ï¼ˆå¦‚SelfCheckGPTï¼‰è€—æ—¶æ•°åç§’ |
| æ€§èƒ½ | AUROC å’Œ F1 æ˜¾è‘—é¢†å…ˆ | å•ä¸€ä¿¡å·æ–¹æ³•æ€§èƒ½æœ‰é™ |
| å¯æ‰©å±•æ€§ | æ— éœ€äººå·¥æ ‡æ³¨ï¼Œè‡ªåŠ¨è·å–æ ‡ç­¾ | ä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®æˆ–å¤æ‚å¤–éƒ¨èµ„æº |
| æ³›åŒ–æ€§ | è·¨æ•°æ®é›†OODè¡¨ç°è‰¯å¥½ | å¤šæ•°æ–¹æ³•IDè¡¨ç°å°šå¯ï¼ŒOODä¸‹é™æ˜æ˜¾ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
åœ¨ä¸‰ä¸ªä¸»æµQAåŸºå‡†ä¸Šè¯„ä¼°ï¼š
- **SQuAD**ï¼šå«ä¸Šä¸‹æ–‡ï¼Œå¹³è¡¡æœ‰æ— contextè¾“å…¥
- **TriviaQA**ï¼šè¿œè·ç¦»ç›‘ç£é˜…è¯»ç†è§£æ•°æ®é›†
- **NQ-Open (NQ)**ï¼šå®Œå…¨æ— ä¸Šä¸‹æ–‡çš„å¼€æ”¾åŸŸQA

æ¯ä¸ªè®­ç»ƒé›†é‡‡æ · **10Kæ ·æœ¬**ï¼Œæµ‹è¯•é›†è§„æ¨¡ä»3.6Kåˆ°5.9Kä¸ç­‰ã€‚ä½¿ç”¨ä¸¤ç§backboneæ¨¡å‹ç”Ÿæˆç­”æ¡ˆï¼š
- **Llama3-8B**
- **Qwen3-14B**

é€šè¿‡æ§åˆ¶ **Context Ratio (CR)** æ¥ç ”ç©¶æœ‰æ— ä¸Šä¸‹æ–‡çš„å½±å“ï¼ˆCR=1: æœ‰contextï¼›CR=0: æ— contextï¼‰ã€‚

---

### ğŸ“Š å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### ç‰¹å¾æå–å±‚
æ‰€æœ‰å®éªŒé»˜è®¤ä½¿ç”¨ **ç¬¬20å±‚Transformerå±‚** çš„hidden statesï¼ˆç»æ¶ˆèå®éªŒè¯æ˜è¯¥å±‚æœ€ç¨³å®šæœ‰æ•ˆï¼‰ã€‚

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **AUROC (ROC)** | åŒºåˆ†å¹»è§‰ä¸éå¹»è§‰çš„æ•´ä½“æ’åºèƒ½åŠ› |
| **AURAC (RAC)** | åœ¨ä¸åŒæ‹’ç»é˜ˆå€¼ä¸‹çš„ç´¯è®¡å‡†ç¡®ç‡ï¼Œè¡¡é‡é€‰æ‹©æ€§å¯é æ€§ |
| **RA@50** | æœ€ç¡®å®šçš„å‰50%é¢„æµ‹çš„å‡†ç¡®ç‡ |
| **F1@B** | æ‰€æœ‰é˜ˆå€¼ä¸­æœ€å¤§çš„F1åˆ†æ•° |

> æ³¨ï¼šå¯¹äºæ— ç›‘ç£æ–¹æ³•ï¼Œå¾—åˆ†è¶Šé«˜è¡¨ç¤ºè¶Šä¸ç¡®å®šï¼›å¯¹äºç›‘ç£æ–¹æ³•ï¼ˆå¦‚HaluNetï¼‰ï¼Œè¾“å‡ºä¸ºå¹»è§‰æ¦‚ç‡ã€‚

---

### âš”ï¸ åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ¶µç›–å››ç±»ä»£è¡¨æ€§æ–¹æ³•ï¼š

| ç±»å‹ | æ–¹æ³• |
|------|------|
| **Probability-based** | PE (Predictive Entropy), T-NLL (Token Negative Log-Likelihood) |
| **Latent-space** | EmbVar (Embedding Variance), SEU (Semantic Embedding Uncertainty) |
| **Semantic Consistency** | SE (Semantic Entropy), SelfCheckGPT, P(True) |
| **Supervised Reference** | Logistic Regressionï¼ˆåŸºäºç›¸åŒç‰¹å¾è®­ç»ƒï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ† å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥Llama3-8Bä¸ºä¾‹ï¼‰

#### âœ… In-Distribution (ID) ç»“æœï¼ˆCR=1ï¼Œå®Œæ•´ä¸Šä¸‹æ–‡ï¼‰
| æ–¹æ³• | SQuAD AUROC | TriviaQA AUROC | SQuAD F1@B | TriviaQA F1@B |
|------|-------------|----------------|------------|----------------|
| PE | 0.732 | 0.723 | 0.427 | 0.394 |
| SelfCheckGPT | 0.772 | 0.779 | 0.466 | 0.356 |
| Logistic | 0.735 | 0.848 | 0.488 | 0.577 |
| **HaluNet (Ours)** | **0.839** | **0.893** | **0.532** | **0.601** |

ğŸ‘‰ **æå‡æ˜¾è‘—**ï¼šç›¸æ¯”æœ€å¼ºéè®­ç»ƒåŸºçº¿ï¼ˆSelfCheckGPTï¼‰ï¼ŒAUROCæå‡è¾¾ **+0.067 (SQuAD)** å’Œ **+0.114 (TriviaQA)**ã€‚

#### âœ… æ— ä¸Šä¸‹æ–‡åœºæ™¯ï¼ˆCR=0ï¼‰
| æ–¹æ³• | SQuAD AUROC | TriviaQA AUROC | NQ AUROC |
|------|-------------|----------------|----------|
| P(True) | 0.921 | 0.952 | 0.677 |
| Logistic | 0.795 | 0.901 | 0.767 |
| **HaluNet (Ours)** | **0.810** | **0.922** | **0.779** |

ğŸ‘‰ åœ¨æ— contextä¸‹ä»ä¿æŒSOTAæ°´å¹³ï¼Œå°¤å…¶åœ¨NQä¸Šå¤§å¹…è¶…è¶Šå…¶ä»–æ–¹æ³•ã€‚

---

### â±ï¸ æ¨ç†æ•ˆç‡å¯¹æ¯”ï¼ˆLatency / 100 samplesï¼‰
| æ–¹æ³• | å¹³å‡å»¶è¿Ÿï¼ˆç§’ï¼‰ |
|------|----------------|
| PE / T-NLL | ~0.001s |
| Logistic | ~0.03s |
| **HaluNet** | **~0.12s** |
| SE / EmbVar | ~700â€“1300s |
| SelfCheckGPT | ~74â€“87s |

âœ… **HaluNetåœ¨ç²¾åº¦ä¸æ•ˆç‡ä¹‹é—´å–å¾—æœ€ä½³å¹³è¡¡**ï¼šè™½ç•¥æ…¢äºçº¯ç»Ÿè®¡æ–¹æ³•ï¼Œä½†è¿œå¿«äºå¤šé‡‡æ ·æ–¹æ³•ï¼Œä¸”æ€§èƒ½å¤§å¹…æå‡ã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰ç‰¹å¾ç»„åˆå½±å“ï¼ˆCR=0ï¼‰
- å•ç‹¬ä½¿ç”¨ `emb` è¡¨ç°æœ€å¥½ï¼ˆAUROC ~0.77â€“0.81ï¼‰
- åŠ å…¥ `ll` å’Œ `ent` è¿›ä¸€æ­¥æå‡ï¼Œä½†äºŒè€…ä¿¡å·éƒ¨åˆ†å†—ä½™
- **ä¸‰è€…è”åˆä½¿ç”¨æ•ˆæœæœ€ä¼˜**ï¼ŒéªŒè¯äº†multi-granularè®¾è®¡çš„æœ‰æ•ˆæ€§

#### ï¼ˆ2ï¼‰ç¼–ç å™¨ç»“æ„æ¯”è¾ƒ
- æ‰€æœ‰åˆ†æ”¯ä½¿ç”¨CNN > æ··åˆç»“æ„ > å…¨MLPæ± åŒ–
- CNNå¯¹embeddingç‰¹åˆ«æœ‰æ•ˆï¼Œèƒ½æ•æ‰å±€éƒ¨å¼‚å¸¸æ¨¡å¼ï¼ˆå¦‚è¯­ä¹‰æ¼‚ç§»ï¼‰

#### ï¼ˆ3ï¼‰èåˆç­–ç•¥
- MLPæ‹¼æ¥èåˆ â‰ˆ æ³¨æ„åŠ›èåˆï¼Œä¸¤è€…æ¥è¿‘
- MLPæ›´ç®€æ´é«˜æ•ˆï¼Œæˆä¸ºé»˜è®¤é€‰æ‹©

#### ï¼ˆ4ï¼‰å±‚è´¡çŒ®åˆ†æï¼ˆLayer-wise Analysisï¼‰
- ä¸­é—´å±‚ï¼ˆ8â€“21ï¼‰è¡¨ç°æœ€ä½³
- åº•å±‚æŠ½è±¡ä¸è¶³ï¼Œé«˜å±‚è¿‡åº¦ä»»åŠ¡ç‰¹åŒ–
- ç¬¬20å±‚åœ¨å¤šä¸ªæ¨¡å‹å’Œæ•°æ®é›†ä¸­è¡¨ç°ç¨³å®š â†’ æˆä¸ºé»˜è®¤é€‰æ‹©

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **å¤šç²’åº¦ä¸ç¡®å®šæ€§ä¿¡å·å…·æœ‰å¼ºäº’è¡¥æ€§**  
   å°†æ¦‚ç‡ã€åˆ†å¸ƒä¸è¯­ä¹‰åµŒå…¥ä¸ç¡®å®šæ€§ç»“åˆï¼Œæ˜¾è‘—ä¼˜äºä»»ä¸€å•ä¸€ä¿¡å·ã€‚

2. **HaluNetå®ç°äº†é«˜æ€§èƒ½ä¸é«˜æ•ˆç‡çš„ç»Ÿä¸€**  
   åœ¨ä»…éœ€ä¸€æ¬¡æ¨ç†çš„å‰æä¸‹ï¼Œè¾¾åˆ°ç”šè‡³è¶…è¿‡å¤šé‡‡æ ·æ–¹æ³•çš„æ£€æµ‹æ€§èƒ½ã€‚

3. **LLM-as-a-Judge æ˜¯æœ‰æ•ˆçš„ä¼ªæ ‡ç­¾æ¥æº**  
   è‡ªåŠ¨ç”Ÿæˆçš„å¹»è§‰æ ‡ç­¾å…·å¤‡è¶³å¤Ÿä¸€è‡´æ€§ï¼Œå¯ç”¨äºé«˜è´¨é‡ç›‘ç£è®­ç»ƒï¼Œé™ä½æ ‡æ³¨æˆæœ¬ã€‚

4. **ä¸­é—´å±‚éšè—çŠ¶æ€æœ€å…·åˆ¤åˆ«åŠ›**  
   Transformerä¸­é—´å±‚çš„embeddingè•´å«ä¸°å¯Œçš„å¯é æ€§ä¿¡æ¯ï¼Œé€‚åˆç”¨äºä¸ç¡®å®šæ€§å»ºæ¨¡ã€‚

5. **è‰¯å¥½çš„OODæ³›åŒ–èƒ½åŠ›**  
   å°½ç®¡å­˜åœ¨æ€§èƒ½ä¸‹é™ï¼Œä½†åœ¨è·¨æ•°æ®é›†è¿ç§»ä¸­ä»ä¼˜äºæˆ–æ¥è¿‘SOTAï¼Œæ˜¾ç¤ºå…¶æ½œåœ¨å®ç”¨æ€§ã€‚

---

### âš ï¸ å±€é™æ€§
1. **ä¾èµ–ç‰¹å®šå±‚ç‰¹å¾æå–**  
   éœ€é¢„å…ˆé€‰å®štransformerå±‚ï¼ˆå¦‚layer 20ï¼‰ï¼Œå¯èƒ½å› æ¨¡å‹ç»“æ„å˜åŒ–è€Œéœ€é‡æ–°è°ƒä¼˜ã€‚

2. **æœªè¦†ç›–å¤šè½®å¯¹è¯æˆ–é•¿æ–‡æœ¬ç”Ÿæˆ**  
   å½“å‰å·¥ä½œèšç„¦å•è½®QAï¼Œå°šæœªæ‰©å±•è‡³multi-turnæˆ–long-form generationåœºæ™¯ã€‚

3. **OODæ€§èƒ½ä»æœ‰æå‡ç©ºé—´**  
   è·¨é¢†åŸŸæˆ–è·¨ä»»åŠ¡æ—¶æ€§èƒ½æ³¢åŠ¨è¾ƒå¤§ï¼Œéœ€æ›´å¼ºçš„æ³›åŒ–æœºåˆ¶ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **multi-turn QA å’Œ agent-based interaction** åœºæ™¯
- æ¢ç´¢ **åŠ¨æ€å±‚é€‰æ‹©æœºåˆ¶** æˆ– **å…¨æ ˆç‰¹å¾èšåˆ**
- å¼•å…¥ **contrastive learning** æˆ– **domain adaptation** æå‡OODé²æ£’æ€§
- æ„å»ºç«¯åˆ°ç«¯çš„ **real-time hallucination mitigation pipeline**

---

## æ€»ç»“

ğŸ“Œ **HaluNet** æ˜¯ä¸€ç§æ–°é¢–ã€é«˜æ•ˆä¸”å¯æ‰©å±•çš„å¹»è§‰æ£€æµ‹æ¡†æ¶ï¼Œé€šè¿‡èåˆ **token-levelçš„æ¦‚ç‡ã€ç†µä¸è¯­ä¹‰åµŒå…¥** å¤šç²’åº¦ä¸ç¡®å®šæ€§ï¼Œåœ¨æ— éœ€å¤–éƒ¨çŸ¥è¯†å’Œäººå·¥æ ‡æ³¨çš„æƒ…å†µä¸‹ï¼Œå®ç°äº†SOTAçº§åˆ«çš„å¹»è§‰è¯†åˆ«æ€§èƒ½ã€‚å…¶è½»é‡è®¾è®¡ä½¿å…¶é€‚ç”¨äºå®é™…éƒ¨ç½²ï¼Œä¸ºæ„å»ºå¯ä¿¡LLMåº”ç”¨æä¾›äº†æœ‰åŠ›å·¥å…·ã€‚

</details>

---

### 15. [Squeezing Edge Performance: A Sensitivity-Aware Container Management for Heterogeneous Tasks](https://arxiv.org/abs/2512.23952)

**Authors**: Yongmin Zhang, Pengyu Huang, Mingyi Dong, Jing Yao  
**Category**: cs.DC  
**Published**: 2026-01-01  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.23952v1  

#### Abstract
Edge computing enables latency-critical applications to process data close to end devices, yet task heterogeneity and limited resources pose significant challenges to efficient orchestration. This paper presents a measurement-driven, container-based resource management framework for intra-node optim...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSqueezing Edge Performance: A Sensitivity-Aware Container Management for Heterogeneous Tasks

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**è¾¹ç¼˜è®¡ç®—ç¯å¢ƒä¸­å¼‚æ„ä»»åŠ¡ï¼ˆheterogeneous tasksï¼‰åœ¨å•ä¸ªèµ„æºå—é™è¾¹ç¼˜æœåŠ¡å™¨ä¸Šçš„å®¹å™¨åŒ–èµ„æºç®¡ç†éš¾é¢˜**ã€‚ä¼ ç»Ÿæ–¹æ³•å¾€å¾€å¿½ç•¥ä»»åŠ¡å¯¹ CPU å’Œå†…å­˜èµ„æºçš„æ•æ„Ÿæ€§å·®å¼‚ï¼Œå¯¼è‡´èµ„æºåˆ†é…ä¸å‡ï¼Œè¿›è€Œå¼•å‘å»¶è¿Ÿå¢åŠ ã€èƒ½æ•ˆä¸‹é™ç­‰é—®é¢˜ã€‚

å…·ä½“æŒ‘æˆ˜åŒ…æ‹¬ï¼š
- ä¸åŒåº”ç”¨å¯¹ CPU å’Œå†…å­˜çš„æ•æ„Ÿåº¦ä¸åŒï¼ˆå¦‚æŸäº›æ¨¡å‹å¯¹å†…å­˜æ›´æ•æ„Ÿï¼Œå¦ä¸€äº›åˆ™å¯¹ CPU æ›´æ•æ„Ÿï¼‰ï¼›
- èµ„æºæ€»é‡æœ‰é™ï¼Œå¤šä¸ªå®¹å™¨å…±äº«æ—¶å­˜åœ¨æ€§èƒ½è€¦åˆï¼›
- é™æ€æˆ–åŸºäºåˆ©ç”¨ç‡çš„è°ƒåº¦ç­–ç•¥æ— æ³•é€‚åº”åŠ¨æ€è´Ÿè½½å˜åŒ–ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

ä½œè€…æå‡ºäº†ä¸€ç§**æµ‹é‡é©±åŠ¨çš„ã€æ„ŸçŸ¥èµ„æºæ•æ„Ÿæ€§çš„å®¹å™¨åŒ–èµ„æºç®¡ç†æ¡†æ¶ CRMSï¼ˆContainer-based Resource Management Schemeï¼‰**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰æ„å»ºéçº¿æ€§å»¶è¿Ÿ-èµ„æºæ‹Ÿåˆæ¨¡å‹
é€šè¿‡å¤§é‡å®æµ‹ profiling å®éªŒï¼Œå»ºç«‹äº†ä¸€ä¸ª**éçº¿æ€§å‡½æ•°æ¨¡å‹**æ¥åˆ»ç”»æ¯ä¸ªåº”ç”¨çš„å¤„ç†å»¶è¿Ÿ $d$ ä¸ CPU é…é¢ $r^{cpu}$ å’Œå†…å­˜é…é¢ $r^{mem}$ ä¹‹é—´çš„å…³ç³»ï¼š

$$
d_i = \frac{K_{i,1}}{1 - e^{-K_{i,2} r^{cpu}}} + e^{-K_{i,3} r^{mem}}
$$

è¯¥æ¨¡å‹èƒ½å¤Ÿå‡†ç¡®æ•æ‰ä¸åŒä»»åŠ¡å¯¹èµ„æºè°ƒæ•´çš„å“åº”ç‰¹æ€§ï¼Œå¹¶é‡åŒ–å…¶â€œèµ„æºæ•æ„Ÿæ€§â€ã€‚

#### ï¼ˆ2ï¼‰è”åˆä¼˜åŒ–å»¶è¿Ÿä¸èƒ½è€—çš„ MINLP é—®é¢˜å»ºæ¨¡
å°†èµ„æºç®¡ç†é—®é¢˜å½¢å¼åŒ–ä¸ºä¸€ä¸ªæ··åˆæ•´æ•°éçº¿æ€§è§„åˆ’ï¼ˆMINLPï¼‰é—®é¢˜ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–åŠ æƒå¹³å‡å“åº”æ—¶é—´å’Œå•ä½è¯·æ±‚å¢é‡åŠŸè€—ä¹‹å’Œï¼š

$$
\min \sum_i \left( \alpha W_s(N_i, \lambda_i, \mu_i) + \beta \frac{\Delta P_i}{\lambda_i} \right)
$$

å…¶ä¸­ $W_s$ æ¥è‡ª M/M/N æ’é˜Ÿæ¨¡å‹ï¼Œ$\Delta P_i$ å»ºæ¨¡ä¸º CPU é…é¢çš„çº¿æ€§å‡½æ•°ã€‚

#### ï¼ˆ3ï¼‰è®¾è®¡ä¸¤é˜¶æ®µæ±‚è§£æ–¹æ¡ˆ CRMS
ç”±äºåŸé—®é¢˜æ˜¯ NP-hardï¼Œä½œè€…å°†å…¶åˆ†è§£ä¸ºä¸¤ä¸ªå¯è§£çš„å‡¸å­é—®é¢˜ï¼š
- **ç¬¬ä¸€é˜¶æ®µï¼ˆAlgorithm 1ï¼‰**ï¼šåœ¨èµ„æºå……è¶³å‡è®¾ä¸‹ç‹¬ç«‹ä¼˜åŒ–æ¯ç±»åº”ç”¨çš„æœ€ä½³å®¹å™¨æ•°é‡ $N^*$ å’Œèµ„æºé…é¢ $(r^{cpu*}, r^{mem*})$ï¼›
- **ç¬¬äºŒé˜¶æ®µï¼ˆAlgorithm 2ï¼‰**ï¼šå›ºå®š $N^*$ï¼Œé‡æ–°æ±‚è§£å…¨å±€çº¦æŸä¸‹çš„ CPU/å†…å­˜å†åˆ†é…é—®é¢˜ï¼ˆProblem P1ï¼‰ï¼Œå¹¶é€šè¿‡è´ªå¿ƒè¿­ä»£è¿›ä¸€æ­¥å¾®è°ƒå®¹å™¨æ•°ä»¥æå‡æ€§èƒ½ã€‚

è¯¥æ–¹æ³•å®ç°äº†**å¤šé¡¹å¼æ—¶é—´å¤æ‚åº¦**ï¼Œæ”¯æŒå‡†åŠ¨æ€æ‰§è¡Œã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| å¯¹æ¯”ç»´åº¦ | CRMS | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ SNFCã€DRFã€RS/GPBO/TPEBOï¼‰ |
|--------|------|----------------------------------------|
| **èµ„æºæ•æ„Ÿæ€§å»ºæ¨¡** | âœ”ï¸ æ˜¾å¼å»ºæ¨¡å¹¶åˆ©ç”¨ | âŒ å¿½ç•¥æˆ–é™æ€é…ç½® |
| **å¤šèµ„æºååŒä¼˜åŒ–** | âœ”ï¸ åŒæ—¶ä¼˜åŒ– CPUã€å†…å­˜ã€å®¹å™¨æ•° | âŒ å•èµ„æºæˆ–å›ºå®šé…é¢ |
| **ç†è®ºä¿éšœ** | âœ”ï¸ å­é—®é¢˜ä¸ºå‡¸ä¼˜åŒ–ï¼Œæœ‰å”¯ä¸€æœ€ä¼˜è§£ | âŒ é»‘ç®±æœç´¢æ— ä¿è¯ |
| **æ•ˆç‡ä¸å®ç”¨æ€§** | âœ”ï¸ å‡†åŠ¨æ€æ›´æ–°ï¼Œå¼€é”€å¯æ§ | âŒ åœ¨çº¿å­¦ä¹ æˆæœ¬é«˜æˆ–æ”¶æ•›æ…¢ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š æ•°æ®é›†ä¸å·¥ä½œè´Ÿè½½
- ä½¿ç”¨å››ç§å…¸å‹è¾¹ç¼˜ AI åº”ç”¨ä½œä¸ºå¼‚æ„ä»»åŠ¡ä»£è¡¨ï¼š
  - å›¾åƒåˆ†ç±»ï¼š`ResNet_v2`, `SE_ResNeXt`, `MobileNet_v2`
  - ç›®æ ‡æ£€æµ‹ï¼š`SSD_MobileNet_v1`
- æ‰€æœ‰åº”ç”¨éƒ¨ç½²äº Docker å®¹å™¨ä¸­ï¼Œä½¿ç”¨ PaddlePaddle æ¡†æ¶æ¨¡æ‹ŸçœŸå®æ¨ç†è¿‡ç¨‹ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®

| å‚æ•° | è®¾ç½®èŒƒå›´ |
|------|---------|
| è¾¹ç¼˜æœåŠ¡å™¨èµ„æº | CPU: 28â€“38 coresï¼›Memory: 6.5â€“11 GB |
| è¯·æ±‚åˆ°è¾¾ç‡ $\lambda_i$ | [4, 15] req/s |
| æ¯è¯·æ±‚å›¾åƒæ•° $x_i$ | [4, 8]ï¼Œæœä»æŒ‡æ•°åˆ†å¸ƒ |
| æœ€å°/æœ€å¤§å†…å­˜é™åˆ¶ | å¦‚ APP2: 200â€“400 MB, APP4: 330â€“700 MB |
| æƒé‡å‚æ•° | $\alpha = 1.4$, $\beta = 0.2$ï¼ˆå¹³è¡¡å»¶è¿Ÿä¸èƒ½è€—ï¼‰ |
| å·¥å…· | Python + Simpyï¼ˆä»¿çœŸï¼‰ã€Scipy.optimizeï¼ˆæ±‚è§£ï¼‰ |

---

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
- **Average Processing Delay**ï¼ˆå¹³å‡å¤„ç†å»¶è¿Ÿï¼‰
- **Power Consumption**ï¼ˆé›†ç¾¤æ€»åŠŸè€—ï¼‰
- **Weighted Utility**: $U_p = \alpha W_s + \beta (\Delta P / \lambda)$
- **CPU/Memory Utilization**

---

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿åç§° | ç±»å‹ | æè¿° |
|--------|-----|------|
| **SNFC1/SNFC2** | å›ºå®šèµ„æºé…ç½® + åŠ¨æ€æ‰©ç¼©å®¹ | SNFC1: å›ºå®šä½å†…å­˜ï¼›SNFC2: å›ºå®šé«˜å†…å­˜ |
| **Random Search (RS)** | é»‘ç®±æœç´¢ | éšæœºé‡‡æ ·é…ç½®ç©ºé—´ |
| **GPBO** | è´å¶æ–¯ä¼˜åŒ– | é«˜æ–¯è¿‡ç¨‹å»ºæ¨¡æœç´¢ |
| **TPEBO** | è´å¶æ–¯ä¼˜åŒ– | Tree-structured Parzen Estimator |
| **DRF (Dominant Resource Fairness)** | å…¬å¹³è°ƒåº¦ç®—æ³• | å¹³è¡¡ä¸»å¯¼èµ„æºä»½é¢ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰å»¶è¿Ÿé™ä½æ•ˆæœæ˜¾è‘—
åœ¨èµ„æºå—é™æ¡ä»¶ä¸‹ï¼ˆCPU=30 cores, Memory=10GBï¼‰ï¼š
- CRMS ç›¸æ¯”å…¶ä»–æ–¹æ³•å¹³å‡å»¶è¿Ÿé™ä½ï¼š
  - **æ¯” RS é™ä½ 43%**
  - **æ¯” GPBO é™ä½ 57%**
  - **æ¯” TPEBO é™ä½ 14%**
- ç‰¹åˆ«æ˜¯åœ¨é«˜è´Ÿè½½åº”ç”¨ï¼ˆå¦‚ APP4, $\lambda=15$ï¼‰ä¸Šè¡¨ç°å°¤ä¸ºçªå‡ºã€‚

> å›¾11æ˜¾ç¤º CRMS åœ¨æ‰€æœ‰åº”ç”¨ä¸­å‡å–å¾—æœ€ä½å»¶è¿Ÿã€‚

#### ï¼ˆ2ï¼‰èƒ½æ•ˆä¼˜åŠ¿æ˜æ˜¾
- å°½ç®¡ CRMS åŠŸè€—ç•¥é«˜äº SNFC2ï¼ˆå› æ›´å¤šå®¹å™¨è¿è¡Œï¼‰ï¼Œä½†åœ¨**å»¶è¿Ÿ-èƒ½æ•ˆç»¼åˆæŒ‡æ ‡ï¼ˆWeighted Utilityï¼‰ä¸Šå…¨é¢é¢†å…ˆ**ã€‚
- å›¾8è¡¨æ˜ CRMS çš„è¾¹ç¼˜æœåŠ¡å™¨æ•ˆç”¨ï¼ˆutilityï¼‰æœ€ä½ï¼Œè¯´æ˜å…¶è¾¾åˆ°äº†æœ€ä½³æƒè¡¡ã€‚

#### ï¼ˆ3ï¼‰èµ„æºåˆ©ç”¨ç‡æ›´é«˜
- å›¾12â€“13 æ˜¾ç¤º CRMS å®ç°äº†æ›´é«˜çš„ CPU å’Œå†…å­˜åˆ©ç”¨ç‡ï¼›
- å›¾9â€“10 è¡¨æ˜ CRMS é¿å…äº† SNFC1 çš„å†…å­˜ä¸è¶³å’Œ SNFC2 çš„ CPU ä¸è¶³é—®é¢˜ï¼Œå®ç°å‡è¡¡åˆ†é…ã€‚

#### ï¼ˆ4ï¼‰å‡†åŠ¨æ€å†åˆ†é…æœ‰æ•ˆæ€§éªŒè¯
- å›¾14 å±•ç¤ºäº†ä»æ— çº¦æŸåˆ°æœ‰çº¦æŸæ¡ä»¶ä¸‹çš„èµ„æºå†åˆ†é…è¿‡ç¨‹ï¼š
  - CPU æ–¹é¢ï¼šå„åº”ç”¨å‡æœ‰ä¸åŒç¨‹åº¦å‹ç¼©ï¼Œä½“ç°æŒ‰éœ€åˆ†é…ï¼›
  - å†…å­˜æ–¹é¢ï¼šä»… APP1 å’Œ APP4 è¢«è°ƒæ•´ï¼ŒAPP2 å’Œ APP3 ç»´æŒé«˜ä½ï¼Œå› å…¶å¯¹å†…å­˜é«˜åº¦æ•æ„Ÿã€‚

---

### ğŸ” æ¶ˆèå®éªŒåˆ†æï¼ˆéšå«åœ¨æ–‡ä¸­ï¼‰

è™½ç„¶æœªæ˜ç¡®æ ‡æ³¨â€œæ¶ˆèå®éªŒâ€ï¼Œä½†ä»¥ä¸‹åˆ†æä½“ç°äº†æ¨¡å—æœ‰æ•ˆæ€§ï¼š

| åˆ†æç»´åº¦ | å‘ç° |
|--------|------|
| **æ˜¯å¦å¯ç”¨è´ªå©ªç²¾ç‚¼ï¼ˆgreedy refinementï¼‰** | è‹¥è·³è¿‡ç¬¬2é˜¶æ®µè¿­ä»£ä¼˜åŒ–ï¼Œåˆ™æ— æ³•è¿›ä¸€æ­¥é™ä½ utilityï¼›åŠ å…¥åç³»ç»ŸæŒç»­æ”¹è¿›ç›´è‡³æ”¶æ•› |
| **èµ„æºæ•æ„Ÿæ€§å»ºæ¨¡çš„é‡è¦æ€§** | è‹¥å¿½ç•¥æ•æ„Ÿæ€§ï¼ˆå¦‚ SNFCï¼‰ï¼Œä¼šå¯¼è‡´æ•æ„Ÿä»»åŠ¡ï¼ˆå¦‚ SE_ResNeXtï¼‰å»¶è¿Ÿæ¿€å¢ |
| **æ’é˜Ÿæ¨¡å‹çš„ä½œç”¨** | M/M/N æ¨¡å‹æœ‰æ•ˆåæ˜ å¹¶å‘è¯·æ±‚ä¸‹çš„å»¶è¿Ÿå¢é•¿è¶‹åŠ¿ï¼Œæ”¯æ’‘äº† $W_s$ çš„å‡†ç¡®æ€§ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º

1. **ä»»åŠ¡å¼‚è´¨æ€§å¿…é¡»è¢«æ˜¾å¼å»ºæ¨¡**  
   ä¸åŒåº”ç”¨å¯¹ CPU å’Œå†…å­˜çš„æ•æ„Ÿåº¦å·®å¼‚å·¨å¤§ï¼Œç»Ÿä¸€èµ„æºé…ç½®ä¼šä¸¥é‡æŸå®³ QoSã€‚

2. **â€œæŒ¤å‹â€è¾¹ç¼˜æ€§èƒ½çš„å…³é”®åœ¨äºèµ„æºå†åˆ†é…è€Œéç®€å•æ‰©å®¹**  
   CRMS çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š**ä»ä½å¼¹æ€§ä»»åŠ¡ä¸­â€œå›æ”¶â€èµ„æºï¼Œåˆ†é…ç»™é«˜å¼¹æ€§ï¼ˆå³é«˜æ•æ„Ÿï¼‰ä»»åŠ¡**ï¼Œä»è€Œåœ¨æ€»é‡ä¸å˜ä¸‹æœ€å¤§åŒ–æ•´ä½“æ€§èƒ½ã€‚

3. **æµ‹é‡é©±åŠ¨ + å‡¸ä¼˜åŒ–åˆ†è§£æ˜¯å®ç”¨è·¯å¾„**  
   ç›¸æ¯”çº¯å­¦ä¹ æ–¹æ³•ï¼ˆå¦‚ RLï¼‰ï¼Œæœ¬æ–‡é‡‡ç”¨è½»é‡çº§å®æµ‹å»ºæ¨¡ + æ•°å­¦ä¼˜åŒ–çš„æ–¹å¼ï¼Œåœ¨ç²¾åº¦ä¸æ•ˆç‡ä¹‹é—´å–å¾—è‰¯å¥½å¹³è¡¡ã€‚

4. **CRMS æ”¯æŒå‡†åŠ¨æ€è¿è¡Œ**  
   åªåœ¨ç›‘æµ‹åˆ°æ˜¾è‘—è´Ÿè½½å˜åŒ–æ—¶è§¦å‘é‡ä¼˜åŒ–ï¼Œé¿å…é¢‘ç¹è®¡ç®—å¼€é”€ï¼Œé€‚åˆåœ¨çº¿éƒ¨ç½²ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

| å±€é™ | è¯´æ˜ |
|------|------|
| **ä¾èµ–ç¦»çº¿ profiling** | éœ€é¢„å…ˆé‡‡é›†å„ç±»åº”ç”¨çš„å»¶è¿Ÿ-èµ„æºæ›²çº¿ï¼Œæ–°åº”ç”¨ä¸Šçº¿å‰éœ€å®Œæˆå»ºæ¨¡ |
| **æœªæ˜¾å¼å»ºæ¨¡å†…å­˜åŠŸè€—** | å½“å‰åŠŸè€—æ¨¡å‹åªè€ƒè™‘ CPUï¼Œæœªæ¥å¯æ‰©å±•è‡³å†…å­˜èƒ½è€— |
| **å±€é™äºå•èŠ‚ç‚¹ä¼˜åŒ–** | æœªæ¶‰åŠè·¨è¾¹ç¼˜èŠ‚ç‚¹çš„ä»»åŠ¡è¿ç§»æˆ–å¤šè·³è·¯ç”± |
| **å‡è®¾æœåŠ¡é€Ÿç‡ç¨³å®š** | æ’é˜Ÿæ¨¡å‹åŸºäºç¨³æ€å‡è®¾ï¼Œçªå‘æµé‡ä¸‹å¯èƒ½åå·®å¢å¤§ |

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•è‡³å¤šèŠ‚ç‚¹è¾¹ç¼˜-äº‘ååŒåœºæ™¯**  
   å¼•å…¥å¸¦å®½ã€ä¼ è¾“å»¶è¿Ÿã€æœåŠ¡é“¾ç­‰çº¦æŸï¼Œæ„å»ºç«¯è¾¹äº‘è”åˆä¼˜åŒ–æ¡†æ¶ã€‚

2. **æ”¯æŒåœ¨çº¿è‡ªé€‚åº”å»ºæ¨¡**  
   ç»“åˆè½»é‡çº§åœ¨çº¿å­¦ä¹ æœºåˆ¶ï¼Œè‡ªåŠ¨è¯†åˆ«æ–°ä»»åŠ¡çš„èµ„æºæ•æ„Ÿæ€§ç‰¹å¾ã€‚

3. **å¼•å…¥æ—¶é—´ç»´åº¦é¢„æµ‹**  
   èåˆ workload forecasting æŠ€æœ¯ï¼Œå®ç°å‰ç»æ€§èµ„æºé¢„é…ç½®ã€‚

4. **æ”¯æŒ GPU ç­‰å¼‚æ„åŠ é€Ÿèµ„æºç®¡ç†**  
   å°†æ¡†æ¶æ¨å¹¿è‡³åŒ…å« CPU/GPU/FPGA çš„å¼‚æ„è®¡ç®—ç¯å¢ƒã€‚

---

## æ€»ç»“

âœ… **CRMS æ˜¯ä¸€ç§é¢å‘å¼‚æ„è¾¹ç¼˜ä»»åŠ¡çš„é«˜æ•ˆã€å¯æ‰©å±•çš„å®¹å™¨èµ„æºç®¡ç†æ–¹æ¡ˆ**ã€‚å®ƒé€šè¿‡**æµ‹é‡é©±åŠ¨å»ºæ¨¡ + æ•æ„Ÿæ€§æ„ŸçŸ¥ä¼˜åŒ–**ï¼Œåœ¨æœ‰é™èµ„æºä¸‹å®ç°äº†å»¶è¿Ÿé™ä½è¶…è¿‡ 14%ï¼Œå¹¶åœ¨èƒ½æ•ˆã€èµ„æºåˆ©ç”¨ç‡ç­‰æ–¹é¢å…¨é¢ä¼˜äºä¸»æµåŸºçº¿æ–¹æ³•ã€‚è¯¥ç ”ç©¶ä¸ºè¾¹ç¼˜ä¾§ç²¾ç»†åŒ–èµ„æºè°ƒæ§æä¾›äº†åšå®çš„ç†è®ºåŸºç¡€ä¸å®è·µè·¯å¾„ã€‚

</details>

---

### 16. [Efficient Inference for Inverse Reinforcement Learning and Dynamic Discrete Choice Models](https://arxiv.org/abs/2512.24407)

**Authors**: Lars van der Laan, Aurelien Bibaut, Nathan Kallus  
**Category**: cs.LG  
**Published**: 2026-01-01  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.24407v1  

#### Abstract
Inverse reinforcement learning (IRL) and dynamic discrete choice (DDC) models explain sequential decision-making by recovering reward functions that rationalize observed behavior. Flexible IRL methods typically rely on machine learning but provide no guarantees for valid inference, while classical D...

---

### 17. [Generative forecasting with joint probability models](https://arxiv.org/abs/2512.24446)

**Authors**: Patrick Wyrod, Ashesh Chattopadhyay, Daniele Venturi  
**Category**: cs.LG  
**Published**: 2026-01-01  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.24446v1  

#### Abstract
Chaotic dynamical systems exhibit strong sensitivity to initial conditions and often contain unresolved multiscale processes, making deterministic forecasting fundamentally limited. Generative models offer an appealing alternative by learning distributions over plausible system evolutions; yet, most...

---

### 18. [Mobility-Assisted Decentralized Federated Learning: Convergence Analysis and A Data-Driven Approach](https://arxiv.org/abs/2512.24694)

**Authors**: Reza Jahani, Md Farhamdur Reza, Richeng Jin, Huaiyu Dai  
**Category**: cs.LG  
**Published**: 2026-01-01  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.24694v1  

#### Abstract
Decentralized Federated Learning (DFL) has emerged as a privacy-preserving machine learning paradigm that enables collaborative training among users without relying on a central server. However, its performance often degrades significantly due to limited connectivity and data heterogeneity. As we mo...

---

### 19. [ROAD: Reflective Optimization via Automated Debugging for Zero-Shot Agent Alignment](https://arxiv.org/abs/2512.24040)

**Authors**: Natchaya Temyingyong, Daman Jain, Neeraj Kumarsahu, Prabhat Kumar, Rachata Phondi, Wachiravit Modecrua, Krittanon Kaewtawee, Krittin Pachtrachai, Touchapon Kraisingkorn  
**Category**: cs.AI  
**Published**: 2026-01-01  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.24040v1  

#### Abstract
Automatic Prompt Optimization (APO) has emerged as a critical technique for enhancing Large Language Model (LLM) performance, yet current state-of-the-art methods typically rely on large, labeled gold-standard development sets to compute fitness scores for evolutionary or Reinforcement Learning (RL)...

---

### 20. [Reliable and Resilient Collective Communication Library for LLM Training and Serving](https://arxiv.org/abs/2512.25059)

**Authors**: Wei Wang, Nengneng Yu, Sixian Xiong, Zaoxing Liu  
**Category**: cs.DC  
**Published**: 2026-01-01  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.25059v1  

#### Abstract
Modern ML training and inference now span tens to tens of thousands of GPUs, where network faults can waste 10--15\% of GPU hours due to slow recovery. Common network errors and link fluctuations trigger timeouts that often terminate entire jobs, forcing expensive checkpoint rollback during training...

---

### 21. [Learning Coupled System Dynamics under Incomplete Physical Constraints and Missing Data](https://arxiv.org/abs/2512.23761)

**Authors**: Esha Saha, Hao Wang  
**Category**: cs.LG  
**Published**: 2026-01-01  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.23761v1  

#### Abstract
Advances in data acquisition and computational methods have accelerated the use of differential equation based modelling for complex systems. Such systems are often described by coupled (or more) variables, yet governing equation is typically available for one variable, while the remaining variable ...

---

### 22. [Rethinking Dense Linear Transformations: Stagewise Pairwise Mixing (SPM) for Near-Linear Training in Neural Networks](https://arxiv.org/abs/2512.23905)

**Authors**: Peter Farag  
**Category**: cs.LG  
**Published**: 2026-01-01  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.23905v1  

#### Abstract
Dense linear layers are a dominant source of computational and parametric cost in modern machine learning models, despite their quadratic complexity and often being misaligned with the compositional structure of learned representations. We introduce Stagewise Pairwise Mixers (SPM), a structured line...

---

### 23. [A Scalable Framework for logP Prediction: From Terabyte-Scale Data Integration to Interpretable Ensemble Modeling](https://arxiv.org/abs/2512.24643)

**Authors**: Malikussaid, Septian Caesar Floresko, Ade Romadhony, Isman Kurniawan, Warih Maharani, Hilal Hudan Nuha  
**Category**: cs.LG  
**Published**: 2026-01-01  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.24643v1  

#### Abstract
This study presents a large-scale predictive modeling framework for logP prediction using 426850 bioactive compounds rigorously curated from the intersection of three authoritative chemical databases: PubChem, ChEMBL, and eMolecules. We developed a novel computational infrastructure to address the d...

---

### 24. [CASCADE: Cumulative Agentic Skill Creation through Autonomous Development and Evolution](https://arxiv.org/abs/2512.23880)

**Authors**: Xu Huang, Junwu Chen, Yuxing Fei, Zhuohan Li, Philippe Schwaller, Gerbrand Ceder  
**Category**: cs.AI  
**Published**: 2026-01-01  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.23880v1  

#### Abstract
Large language model (LLM) agents currently depend on predefined tools or brittle tool generation, constraining their capability and adaptability to complex scientific tasks. We introduce CASCADE, a self-evolving agentic framework representing an early instantiation of the transition from "LLM + too...

---

### 25. [CEC-Zero: Zero-Supervision Character Error Correction with Self-Generated Rewards](https://arxiv.org/abs/2512.23971)

**Authors**: Zhiming Lin, Kai Zhao, Sophie Zhang, Peilai Yu, Canran Xiao  
**Category**: cs.CL  
**Published**: 2026-01-01  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.23971v1  

#### Abstract
Large-scale Chinese spelling correction (CSC) remains critical for real-world text processing, yet existing LLMs and supervised methods lack robustness to novel errors and rely on costly annotations. We introduce CEC-Zero, a zero-supervision reinforcement learning framework that addresses this by en...

---

### 26. [Activation Steering for Masked Diffusion Language Models](https://arxiv.org/abs/2512.24143)

**Authors**: Adi Shnaidman, Erin Feiglin, Osher Yaari, Efrat Mentel, Amit Levi, Raz Lapid  
**Category**: cs.CL  
**Published**: 2026-01-01  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.24143v1  

#### Abstract
Masked diffusion language models (MDLMs) generate text through an iterative denoising process. They have recently gained attention due to mask-parallel decoding and competitive performance with autoregressive large language models. However, effective mechanisms for inference-time control and steerin...

---

### 27. [Distributed Bilevel Optimization with Dual Pruning for Resource-limited Clients](https://arxiv.org/abs/2512.24667)

**Authors**: Mingyi Li, Xiao Zhang, Ruisheng Zheng, Hongjian Shi, Yuan Yuan, Xiuzhen Cheng, Dongxiao Yu  
**Category**: cs.DC  
**Published**: 2026-01-01  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.24667v1  

#### Abstract
With the development of large-scale models, traditional distributed bilevel optimization algorithms cannot be applied directly in low-resource clients. The key reason lies in the excessive computation involved in optimizing both the lower- and upper-level functions. Thus, we present the first resour...

---

### 28. [Micro-Macro Tensor Neural Surrogates for Uncertainty Quantification in Collisional Plasma](https://arxiv.org/abs/2512.24205)

**Authors**: Wei Chen, Giacomo Dimarco, Lorenzo Pareschi  
**Category**: cs.LG  
**Published**: 2026-01-01  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.24205v1  

#### Abstract
Plasma kinetic equations exhibit pronounced sensitivity to microscopic perturbations in model parameters and data, making reliable and efficient uncertainty quantification (UQ) essential for predictive simulations. However, the cost of uncertainty sampling, the high-dimensional phase space, and mult...

---

### 29. [CPR: Causal Physiological Representation Learning for Robust ECG Analysis under Distribution Shifts](https://arxiv.org/abs/2512.24564)

**Authors**: Shunbo Jia, Caizhi Liao  
**Category**: cs.LG  
**Published**: 2026-01-01  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.24564v1  

#### Abstract
Deep learning models for Electrocardiogram (ECG) diagnosis have achieved remarkable accuracy but exhibit fragility against adversarial perturbations, particularly Smooth Adversarial Perturbations (SAP) that mimic biological morphology. Existing defenses face a critical dilemma: Adversarial Training ...

---

### 30. [Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight Large Language Models](https://arxiv.org/abs/2512.24618)

**Authors**: Junru Lu, Jiarui Qin, Lingfeng Qiao, Yinghui Li, Xinyi Dai, Bo Ke, Jianfeng He, Ruizhi Qiao, Di Yin, Xing Sun, Yunsheng Wu, Yinsong Liu, Shuangyin Liu, Mingkong Tang, Haodong Lin, Jiayi Kuang, Fanxu Meng, Xiaojuan Tang, Yunjia Xi, Junjie Huang, Haotong Yang, Zhenyi Shen, Yangning Li, Qianwen Zhang, Yifei Yu, Siyu An, Junnan Dong, Qiufeng Wang, Jie Wang, Keyu Chen, Wei Wen, Taian Guo, Zhifeng Shen, Daohai Yu, Jiahao Li, Ke Li, Zongyi Li, Xiaoyu Tan  
**Category**: cs.CL  
**Published**: 2026-01-01  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.24618v1  

#### Abstract
We introduce Youtu-LLM, a lightweight yet powerful language model that harmonizes high computational efficiency with native agentic intelligence. Unlike typical small models that rely on distillation, Youtu-LLM (1.96B) is pre-trained from scratch to systematically cultivate reasoning and planning ca...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
