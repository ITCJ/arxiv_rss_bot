# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-02-05 06:40:19 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Multi-Head LatentMoE and Head Parallel: Communication-Efficient and Deterministic MoE Parallelism](https://arxiv.org/abs/2602.04870)

**Authors**: Chenwei Cui, Rockwell Jackson, Benjamin Joseph Herrera, Ana Mar\'ia T\'arano, Hannah Kerner  
**Category**: cs.LG  
**Published**: 2026-02-05  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2602.04870v1  

#### Abstract
Large language models have transformed many applications but remain expensive to train. Sparse Mixture of Experts (MoE) addresses this through conditional computation, with Expert Parallel (EP) as the standard distributed training method. However, EP has three limitations: communication cost grows l...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Multi-Head LatentMoE and Head Parallel: Communication-Efficient and Deterministic MoE Parallelism*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ç°æœ‰çš„ **Expert Parallel (EP)** æ˜¯è®­ç»ƒç¨€ç– Mixture-of-Experts (MoE) æ¨¡å‹çš„æ ‡å‡†åˆ†å¸ƒå¼æ–¹æ³•ï¼Œä½†å®ƒå­˜åœ¨ä¸‰ä¸ªå…³é”®ç“¶é¢ˆï¼š
1. **é€šä¿¡å¼€é”€å¤§**ï¼šé€šä¿¡é‡éšæ¯ä¸ª token æ¿€æ´»çš„ä¸“å®¶æ•° $k$ çº¿æ€§å¢é•¿ï¼ˆ$O(k)$ï¼‰ã€‚
2. **è´Ÿè½½ä¸å‡è¡¡**ï¼šç”±äºè·¯ç”±å†³ç­–çš„æ•°æ®ä¾èµ–æ€§ï¼ŒæŸäº› GPU å¯èƒ½æ¥æ”¶è¿‡å¤š tokenï¼Œå¯¼è‡´å»¶è¿Ÿå¢åŠ å’Œæ˜¾å­˜å‹åŠ›ã€‚
3. **éç¡®å®šæ€§é€šä¿¡æ¨¡å¼**ï¼šéœ€è¦é¢å¤–çš„ `all-to-all` æ“ä½œäº¤æ¢å…ƒæ•°æ®ï¼ˆå¦‚é˜Ÿåˆ—é•¿åº¦ï¼‰ï¼Œå¢åŠ äº†å¤æ‚æ€§å’Œä¸ç¡®å®šæ€§ã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº† MoE æ¨¡å‹åœ¨å­¦æœ¯ç•Œå’Œèµ„æºå—é™ç¯å¢ƒä¸­çš„å¯æ‰©å±•æ€§å’Œè®­ç»ƒæ•ˆç‡ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•
æœ¬æ–‡æå‡º **Multi-Head LatentMoE + Head Parallel (HP)** æ¶æ„ä¸å¹¶è¡Œç­–ç•¥ç»„åˆï¼Œä»æ ¹æœ¬ä¸Šé‡æ„äº† MoE çš„è®¡ç®—ä¸é€šä¿¡æµç¨‹ã€‚

#### ï¼ˆ1ï¼‰**Multi-Head LatentMoE**
- å°†è¾“å…¥ token æŠ•å½±ä¸º $N_h$ ä¸ªç‹¬ç«‹çš„ sub-tokenã€‚
- æ¯ä¸ª sub-token è¢«é€å…¥ä¸€ä¸ª**ç‹¬ç«‹çš„ MoE æ¨¡å—**ï¼ˆå«ç‹¬ç«‹ router å’Œ expert é›†åˆï¼‰ã€‚
- ç»“åˆ LatentMoE æ€æƒ³ï¼Œåœ¨ä½ç»´ç©ºé—´è¿›è¡Œè·¯ç”±ä¸ä¸“å®¶è®¡ç®—ï¼Œé™ä½å‚æ•°ä¸æ¿€æ´»å¤§å°ã€‚

#### ï¼ˆ2ï¼‰**Head Parallel (HP)**
- åœ¨ **è·¯ç”±å‰æ‰§è¡Œ `all-to-all` é€šä¿¡**ï¼Œå°† sub-token å‡åŒ€åˆ†å‘åˆ°ä¸åŒ GPUã€‚
- æ¯ä¸ª GPU ç‹¬ç«‹å®Œæˆå…¶è´Ÿè´£ head çš„å…¨éƒ¨è·¯ç”±ä¸ä¸“å®¶è®¡ç®—ã€‚
- è¾“å‡ºé€šè¿‡åå‘ `all-to-all` æ”¶é›†å›åŸå§‹è®¾å¤‡ã€‚

> ğŸ’¡ æ ¸å¿ƒæ€æƒ³ï¼š**è§£è€¦é€šä¿¡ä¸è·¯ç”±å†³ç­–**ï¼Œä½¿é€šä¿¡æˆä¸ºé™æ€ã€å¯é¢„æµ‹çš„è¿‡ç¨‹ã€‚

---

### âš–ï¸ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | Expert Parallel (EP) | Head Parallel (HP) |
|------|------------------------|--------------------|
| é€šä¿¡é‡ | $O(k)$ | $O(1)$ âœ… |
| è´Ÿè½½å‡è¡¡ | åŠ¨æ€ï¼Œæ˜“å¤±è¡¡ âŒ | å®Œå…¨å‡è¡¡ âœ… |
| é€šä¿¡æ¨¡å¼ | éç¡®å®šæ€§ï¼Œéœ€å…ƒæ•°æ®äº¤æ¢ âŒ | ç¡®å®šæ€§ï¼Œæ— éœ€å…ƒæ•°æ® âœ… |
| å…¼å®¹æ€§ | æ ‡å‡†æ–¹æ¡ˆ | ä¸ EP å…¼å®¹ï¼Œå¯ç»„åˆä½¿ç”¨ âœ… |

æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ä¿æŒä¸æ ‡å‡† MoE ç›¸åŒçš„æ¨¡å‹å®¹é‡å’Œæ€§èƒ½ï¼ŒåŒæ—¶æ˜¾è‘—æå‡è®­ç»ƒé€Ÿåº¦ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **FineWebEdu**ï¼šä»äº’è”ç½‘æ¸…æ´—å¾—åˆ°çš„å¤§è§„æ¨¡æ–‡æœ¬è¯­æ–™ã€‚
- ä½¿ç”¨å…¶ä¸­ **100äº¿ token å­é›†**ç”¨äºè¯­è¨€å»ºæ¨¡é¢„è®­ç»ƒã€‚

---

### ğŸ”§ å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼šDecoder-only Transformer
  - å±‚æ•°ï¼š12
  - Embedding sizeï¼š1024
  - Attention headsï¼š8
  - Context lengthï¼š2048
- **ä¼˜åŒ–å™¨**ï¼šAdamW ($\beta_1=0.9, \beta_2=0.95$)ï¼Œweight decay=0.1
- **å­¦ä¹ ç‡è°ƒåº¦**ï¼šæ¢¯å½¢è°ƒåº¦ï¼ˆ8000æ­¥ warmup + 2000æ­¥ decayï¼‰
- **å…¨å±€ batch size**ï¼š66ä¸‡ tokens
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA H100 80GB GPUsï¼ŒNVLink äº’è”

---

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
| ç±»åˆ« | æŒ‡æ ‡ |
|------|------|
| **æ¨¡å‹æ€§èƒ½** | Validation Perplexity (FineWebEdu)<br>Zero-shot Accuracyï¼šHellaSwag, PiQA, LAMBADA, ARC-Easy, ARC-Challenge |
| **è®­ç»ƒæ•ˆç‡** | è®­ç»ƒè€—æ—¶ï¼ˆå°æ—¶ï¼‰<br>ç›¸å¯¹è®­ç»ƒæˆæœ¬ï¼ˆspeedupï¼‰<br>GPU é—´é€šä¿¡é‡ |
| **ç³»ç»Ÿè¡¨ç°** | Peak VRAM usage<br>All-to-all latency<br>å†…å­˜è®¿é—®ï¼ˆHBM IOï¼‰ |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **MLP** | å…¨è¿æ¥å‰é¦ˆç½‘ç»œï¼Œæ— ç¨€ç–æ€§ |
| **MoE + EP** | æ ‡å‡† MoE + Expert Parallelï¼ˆåŸºçº¿ï¼‰ |
| **LatentMoE + EP** | ä½ç»´è·¯ç”±ä¸è®¡ç®—ï¼Œä½†ä»ç”¨ EP |
| **MH LatentMoE + HP** | æœ¬æ–‡æå‡ºçš„æ–¹æ³• |
| **MH LatentMoE + HP G** | â€œGranularity Doubledâ€ ç‰ˆæœ¬ï¼šä¸“å®¶æ•°é‡ç¿»å€ï¼Œç²’åº¦æ›´ç»† |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| å‚æ•°é…ç½® | æ–¹æ³• | è®­ç»ƒæ—¶é—´ (å°æ—¶) | ç›¸å¯¹é€Ÿåº¦ | FineWebEDU ppl. | å¹³å‡å‡†ç¡®ç‡ (%) |
|---------|------|------------------|------------|------------------|----------------|
| 0.2Bâ€“2.2B | MoE EP | 35.36 | 1.00Ã— | 15.56 | 43.95 |
| | MH LatentMoE HP | **31.68** | **1.11Ã—** | 15.61 | 43.93 |
| 0.2Bâ€“4.2B | MoE EP | 55.34 | 1.00Ã— | 15.01 | 45.30 |
| | MH LatentMoE HP | **34.41** | **1.61Ã—** | 15.02 | 45.17 |
| | MH LatentMoE HP G | **50.04** | **1.11Ã—** | **14.82** | **45.43** âœ… |

> âœ… **æœ€é«˜æé€Ÿè¾¾ 1.61Ã—**ï¼Œä¸”æ¨¡å‹æ€§èƒ½æŒå¹³ç”šè‡³ç•¥ä¼˜ã€‚

---

### ğŸ” é€šä¿¡æ•ˆç‡æå‡
- å½“ $k=4$ æ—¶ï¼Œ**GPU é—´é€šä¿¡é‡é™è‡³ EP çš„ 25%**ã€‚
- å› ä¸ºæ¯ä¸ª token ä»…å‘é€ä¸€æ¬¡ï¼ˆbefore routingï¼‰ï¼Œé€šä¿¡é‡ä¸ $k$ æ— å…³ï¼ˆ$O(1)$ï¼‰ã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰**Head Configuration Ablation**ï¼ˆTable 2ï¼‰
æµ‹è¯•ä¸åŒ $N_h \times d_h$ é…ç½®ï¼ˆæ€»ç»´åº¦å›ºå®šï¼‰ï¼š
| é…ç½® | Val Loss | ç›¸å¯¹è®­ç»ƒæˆæœ¬ | SRAM å‹åŠ› |
|------|----------|---------------|-----------|
| 16Ã—64 | 3.56 | 1.34Ã— | Low |
| **8Ã—128** | **3.48** | **1.00Ã—** | Medium âœ… |
| 4Ã—256 | 3.41 | 1.07Ã— | High |

> âœ… **8Ã—128** åœ¨æ€§èƒ½ä¸æ•ˆç‡ä¹‹é—´å–å¾—æœ€ä½³å¹³è¡¡ã€‚

#### ï¼ˆ2ï¼‰**Separate Routing Tokens Ablation**ï¼ˆFigure 6ï¼‰
- æ¢ç´¢æ˜¯å¦åº”ä½¿ç”¨ç‹¬ç«‹ sub-token è¿›è¡Œè·¯ç”±ã€‚
- ç»“æœæ˜¾ç¤ºæ—©æœŸç•¥æœ‰ä¼˜åŠ¿ï¼Œä½†æœ€ç»ˆæ”¶æ•›æ€§èƒ½å‡ ä¹ç›¸åŒã€‚
- ä»£ä»·æ˜¯é€šä¿¡é‡ç¿»å€ â†’ **é€‰æ‹©å…±äº« sub-token æ›´é«˜æ•ˆ**ã€‚

#### ï¼ˆ3ï¼‰**ç»„ä»¶åˆ†æ**ï¼ˆFigures 3â€“5ï¼‰
- **Figure 3**ï¼šHP å¯¹è´Ÿè½½å€¾æ–œå®Œå…¨é²æ£’ï¼›EP éš skew å’Œ $k$ æ˜¾è‘—æ¶åŒ–ã€‚
- **Figure 4**ï¼šIO-aware routing å†…å­˜å ç”¨æ’å®šï¼Œè€Œ naive matmul éšä¸“å®¶æ•°çº¿æ€§å¢é•¿ã€‚
- **Figure 5**ï¼šIO-aware expert computation åœ¨æ­£åå‘ä¼ æ’­ä¸­å‡è¿œä¼˜äº grouped GEMMï¼Œå°¤å…¶åœ¨ backward ä¸Šä¼˜åŠ¿æ˜æ˜¾ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Head Parallel å®ç°äº† O(1) é€šä¿¡ã€å®Œç¾è´Ÿè½½å‡è¡¡ä¸ç¡®å®šæ€§é€šä¿¡**ï¼Œè§£å†³äº† EP çš„ä¸‰å¤§æ ¹æœ¬ç¼ºé™·ã€‚
2. **Multi-Head LatentMoE + HP æœ€é«˜æé€Ÿ 1.61Ã—**ï¼Œä¸”æ¨¡å‹æ€§èƒ½ä¸æ ‡å‡† MoE ç›¸å½“ã€‚
3. å¼•å…¥ **IO-aware routing** ä¸ **IO-aware expert computation**ï¼Œåˆ©ç”¨ SRAM æµæ°´å¤„ç†é¿å… HBM å†—ä½™è¯»å†™ï¼Œå®ç° FlashAttention-style çš„ IO æ•ˆç‡ã€‚
4. åœ¨ç›¸åŒæ¿€æ´»å‚æ•°ä¸‹ï¼ŒMoE è®¾è®¡æ¯” MLP æå‡é«˜è¾¾ **6.9 ä¸ªç™¾åˆ†ç‚¹å¹³å‡å‡†ç¡®ç‡**ã€‚
5. è‹¥å°†èŠ‚çœçš„è®¡ç®—èµ„æºç”¨äº**åŠ å€ä¸“å®¶ç²’åº¦ï¼ˆGï¼‰**ï¼Œå¯åœ¨ä»å¿« **1.11Ã—** çš„å‰æä¸‹è¾¾åˆ°**æœ€é«˜æ•´ä½“æ€§èƒ½ï¼ˆ45.43%ï¼‰**ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
1. **Head æ•°é‡é™åˆ¶å¹¶è¡Œè§„æ¨¡**ï¼šHP çš„æœ€å¤§å¹¶è¡Œåº¦å— $N_h$ é™åˆ¶ï¼ˆå½“å‰å…¸å‹ä¸º 8â€“16ï¼‰ã€‚å¯¹äºè¶…å¤§è§„æ¨¡é›†ç¾¤ï¼ˆ>16 èŠ‚ç‚¹ï¼‰ï¼Œéœ€ä¸å…¶ä»–å¹¶è¡Œç­–ç•¥ç»“åˆã€‚
2. **é€‚ç”¨äº ultra-sparse regime**ï¼šåœ¨ä¸“å®¶å¤šã€ä¸ªä½“å°çš„ç°ä»£ MoE æ¶æ„ä¸­æœ€æœ‰æ•ˆï¼›å¯¹ dense MoE æˆ–å°è§„æ¨¡æ¨¡å‹å¢ç›Šæœ‰é™ã€‚
3. **æ–°å¢æŠ•å½±å±‚å¸¦æ¥è½»å¾®å‚æ•°å¼€é”€**ï¼šè™½ç„¶ FLOPs åŸºæœ¬ä¸å˜ï¼Œä½†å¼•å…¥äº† $W_{in}$ å’Œ $W_{out}$ æŠ•å½±çŸ©é˜µã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ··åˆå¹¶è¡Œç­–ç•¥**ï¼šåœ¨èŠ‚ç‚¹å†…ä½¿ç”¨ HPï¼Œåœ¨èŠ‚ç‚¹é—´ä½¿ç”¨ EP æˆ– TPï¼Œæ„å»ºå¯æ‰©å±•çš„ hierarchical MoE parallelismã€‚
2. **è¿›ä¸€æ­¥å·¥ç¨‹ä¼˜åŒ–**ï¼š
   - é€šä¿¡-è®¡ç®—é‡å ï¼ˆcommunication-computation overlapï¼‰
   - Kernel fusion ä»¥å‡å°‘ kernel launch å¼€é”€
3. **æ¢ç´¢åŠ¨æ€ head åˆ†é…æœºåˆ¶**ï¼Œçªç ´å›ºå®š $N_h$ çš„é™åˆ¶ã€‚
4. æ‰©å±•è‡³å…¶ä»–ç¨€ç–æ¶æ„ï¼ˆå¦‚ block-sparse FFNã€conditional compute in vision modelsï¼‰ã€‚

---

## ğŸ æ€»ç»“
> **Multi-Head LatentMoE + Head Parallel** æ˜¯ä¸€ç§**é€šä¿¡é«˜æ•ˆã€è´Ÿè½½å‡è¡¡ã€ç¡®å®šæ€§å¼º**çš„æ–°å‹ MoE å¹¶è¡ŒèŒƒå¼ã€‚å®ƒä¸ä»…æ˜¾è‘—åŠ é€Ÿè®­ç»ƒï¼ˆæœ€é«˜ **1.61Ã—**ï¼‰ï¼Œè¿˜æå‡äº†ç³»ç»Ÿçš„ç¨³å®šæ€§å’Œå¯é¢„æµ‹æ€§ï¼Œä½¿å¾— billion-scale MoE æ¨¡å‹çš„è®­ç»ƒæ›´åŠ å¹³æƒåŒ–ï¼Œ**æå¤§ä¿ƒè¿›äº†å­¦æœ¯ç•Œå¯¹å¤§è§„æ¨¡åŸºç¡€æ¨¡å‹çš„ç ”ç©¶å¯åŠæ€§**ã€‚

</details>

---

### 2. [The Key to State Reduction in Linear Attention: A Rank-based Perspective](https://arxiv.org/abs/2602.04852)

**Authors**: Philipp Nazari, T. Konstantin Rusch  
**Category**: cs.LG  
**Published**: 2026-02-05  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.04852v1  

#### Abstract
Linear attention offers a computationally efficient yet expressive alternative to softmax attention. However, recent empirical results indicate that the state of trained linear attention models often exhibits a low-rank structure, suggesting that these models underexploit their capacity in practice....

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šThe Key to State Reduction in Linear Attention: A Rank-based Perspective

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹ **Linear Attention** æ¨¡å‹åœ¨è®­ç»ƒåå…¶éšè—çŠ¶æ€ï¼ˆassociative memoryï¼‰æ™®éå­˜åœ¨ **ä½ç§©ç»“æ„ï¼ˆlow-rank structureï¼‰** çš„ç°è±¡å±•å¼€ç ”ç©¶ã€‚è¿™ç§ä½ç§©ç‰¹æ€§è¡¨æ˜æ¨¡å‹æœªèƒ½å……åˆ†åˆ©ç”¨å…¶å®¹é‡ï¼Œå¯¼è‡´å¯¹æŸ¥è¯¢å™ªå£°æ•æ„Ÿï¼Œå¹¶å¯èƒ½å½±å“æ£€ç´¢æ€§èƒ½ã€‚

ä½œè€…æŒ‡å‡ºï¼Œå°½ç®¡ Linear Attention åœ¨è®¡ç®—æ•ˆç‡ä¸Šä¼˜äº Softmax Attentionï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­å…¶çŠ¶æ€ç©ºé—´å­˜åœ¨å†—ä½™ï¼Œä»è€Œé™åˆ¶äº†æ¨ç†é€Ÿåº¦å’Œå†…å­˜æ•ˆç‡ã€‚

---

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯

è®ºæ–‡æå‡ºäº†ä¸€ä¸ª **ç¡¬ä»¶æ„ŸçŸ¥çš„ç»“æ„åŒ–å‰ªææ¡†æ¶ï¼ˆhardware-aware structured pruning frameworkï¼‰**ï¼Œç”¨äºåœ¨è®­ç»ƒåå‹ç¼© Linear Attention æ¨¡å‹çš„çŠ¶æ€å¤§å°ï¼Œå…·ä½“åŒ…æ‹¬ï¼š

- **ç†è®ºåˆ†æ**ï¼šä» **æœ‰æ•ˆç§©ï¼ˆeffective rankï¼‰** å’Œ **ç§©åˆ©ç”¨ç‡ï¼ˆrank utilizationï¼‰** çš„è§’åº¦å‡ºå‘ï¼Œæ­ç¤ºäº†ä½ç§©ç»“æ„å¦‚ä½•æ”¾å¤§æŸ¥è¯¢å™ªå£°å¹¶å½±å“æ£€ç´¢è¯¯å·®ã€‚
- **ä¸å˜æ€§åˆ©ç”¨**ï¼šåŸºäº Linear Attention å¯¹ **æ­£äº¤å˜æ¢ï¼ˆorthogonal transformationsï¼‰** çš„ä¸å˜æ€§ï¼Œæå‡ºå¯ä»¥è”åˆå¯¹ Query å’Œ Key æŠ•å½±çŸ©é˜µè¿›è¡Œå˜æ¢è€Œä¸æ”¹å˜æ¨¡å‹åŠŸèƒ½ã€‚
- **ç»“æ„åŒ–å‰ªæç­–ç•¥**ï¼š
  - å°†å¤šç§å·²æœ‰å‰ªææ–¹æ³•ï¼ˆå¦‚ L1ã€S-Wandaã€Gradient-basedï¼‰é€‚é…åˆ°è¯¥æ¡†æ¶ä¸‹ã€‚
  - æå‡ºä¸€ç§æ–°çš„ç»“æ„åŒ–å‰ªæç®—æ³• **DRRQRï¼ˆDeep Rank Revealing QR decompositionï¼‰**ï¼Œé€šè¿‡ QR åˆ†è§£é€‰æ‹©èƒ½æœ€å¤§åŒ–å‰©ä½™çŠ¶æ€ç§©åˆ©ç”¨ç‡çš„é€šé“å­é›†ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | ä¼˜åŠ¿è¯´æ˜ |
|------|---------|
| **å…¼å®¹æ€§** | æ‰€ææ–¹æ³•ä¸º **ç»“æ„åŒ–å‰ªæï¼ˆstructured pruningï¼‰**ï¼Œç›´æ¥å‡å°‘ Key/Query é€šé“ç»´åº¦ï¼Œå¯ä¸ç°æœ‰ CUDA å†…æ ¸å…¼å®¹ï¼Œå®ç°çœŸæ­£çš„ååæå‡ã€‚ |
| **äº’è¡¥æ€§** | ä¸åŒäº SliceGPTã€SpinQuant ç­‰åœ¨æ®‹å·®æµï¼ˆresidual streamï¼‰ä¸­æ—‹è½¬çš„æ–¹æ³•ï¼Œæœ¬æ–‡æ“ä½œåœ¨ **çŠ¶æ€ç©ºé—´ï¼ˆstate spaceï¼‰** ä¸­ï¼Œå› æ­¤å¯ä¸å‰è¿°æ–¹æ³•ç»“åˆä½¿ç”¨ã€‚ |
| **ç†è®ºé©±åŠ¨** | DRRQR æ˜¯é¦–ä¸ªæ˜ç¡®ä»¥ **ä¼˜åŒ–ç§©åˆ©ç”¨ç‡** ä¸ºç›®æ ‡çš„å‰ªææ–¹æ³•ï¼Œå…·æœ‰æ›´å¼ºçš„å¯è§£é‡Šæ€§å’Œç¨³å®šæ€§ã€‚ |
| **æ— éœ€é‡è®­ç»ƒå³å¯å‹ç¼©** | å³ä½¿ä¸è¿›è¡Œæ¢å¤å¾®è°ƒï¼ˆRecovery Fine-Tuning, RFTï¼‰ï¼Œä¹Ÿèƒ½ç§»é™¤ 50% é€šé“è€Œä»…å¸¦æ¥è½»å¾®å›°æƒ‘åº¦ä¸Šå‡ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **é¢„è®­ç»ƒè¯­æ–™**ï¼šFineweb-Eduï¼ˆ10B tokensï¼‰
- **æ ¡å‡†é›†ï¼ˆcalibration setï¼‰**ï¼š128 ä¸ª Fineweb-Edu æ ·æœ¬ï¼Œç”¨äºæå–æ¿€æ´»ç»Ÿè®¡ä¿¡æ¯
- **è¯„ä¼°ä»»åŠ¡**ï¼š
  - **è¯­è¨€å»ºæ¨¡**ï¼šWikitext-2ã€Lambada
  - **é›¶æ ·æœ¬ç”Ÿæˆï¼ˆZero-Shot Generationï¼‰**ï¼šä½¿ç”¨ `lm-eval-harness` æµ‹è¯• ARC-e/cã€HellaSwagã€Winograndeã€PIQAã€LAMBADA å‡†ç¡®ç‡
  - **çœŸå®ä¸–ç•Œæ£€ç´¢ä»»åŠ¡ï¼ˆReal-world Retrievalï¼‰**ï¼šNQã€SQuADã€TriviaQAã€FEVERã€DROPï¼ˆç¼©å†™è§åŸæ–‡è¡¨ï¼‰

---

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

| è®¾ç½®é¡¹ | æè¿° |
|--------|------|
| **æ¨¡å‹æ¶æ„** | DeltaNet å’Œ Gated DeltaNetï¼Œå‚æ•°é‡çº§ä¸º 370M å’Œ 1.3B |
| **å‰ªææ¯”ä¾‹** | 30% ~ 75%ï¼Œä¸»è¦å…³æ³¨ 50% å’Œ 75% å‹ç¼©æ¯” |
| **å‰ªææ–¹å¼** | è½´å¯¹é½ç»“æ„åŒ–å‰ªæï¼ˆaxis-alignedï¼‰ï¼Œå³ç›´æ¥åˆ é™¤ Query å’Œ Key çš„æŸäº›é€šé“åˆ— |
| **æ¢å¤å¾®è°ƒï¼ˆRFTï¼‰** | ä½¿ç”¨ LoRAï¼ˆr=16, Î±=32ï¼‰åœ¨å•å¼  H100 ä¸Šå¾®è°ƒï¼Œä½¿ç”¨ 32k æ ·æœ¬ |
| **è¯„ä¼°æŒ‡æ ‡** |
| - å›°æƒ‘åº¦ï¼ˆPerplexityï¼‰ï¼šWikitext-2ã€Lambada |
| - é›¶æ ·æœ¬å‡†ç¡®ç‡ï¼ˆZS Accuracyï¼‰ï¼šå¤šä¸ªå¸¸è¯†æ¨ç†ä»»åŠ¡å¹³å‡å¾—åˆ† |
| - æ£€ç´¢å‡†ç¡®ç‡ï¼ˆRetrieval Accuracyï¼‰ï¼šå¤šä¸ªé—®ç­”ä»»åŠ¡å¹³å‡å¾—åˆ† |
| - ååé‡ï¼ˆThroughputï¼‰ï¼štokens/sec |
| - æ˜¾å­˜å ç”¨ï¼ˆVRAM Usageï¼‰ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | ç±»å‹ | æ˜¯å¦ç»“æ„åŒ– | æ˜¯å¦ä»»åŠ¡æ„ŸçŸ¥ |
|------|-------|-------------|----------------|
| **Rand** | éšæœºé€‰æ‹©é€šé“ | âœ… | âŒ |
| **L1** | æƒé‡ L1 èŒƒæ•°åŠ æ€» | âœ… | âŒ |
| **S-Wanda** | è¾“å…¥æ¿€æ´»èŒƒæ•° Ã— æƒé‡èŒƒæ•° | âœ… | âœ…ï¼ˆä¾èµ–è¾“å…¥åˆ†å¸ƒï¼‰ |
| **Grad** | åŸºäºæ¢¯åº¦çš„ä¸€é˜¶æ³°å‹’å±•å¼€ | âœ… | âœ… |
| **DRRQRï¼ˆæœ¬æ–‡æå‡ºï¼‰** | åŸºäº QR åˆ†è§£ä¿ç•™é«˜æ¡ä»¶æ•°é€šé“ | âœ… | âŒï¼ˆå±€éƒ¨ã€æ— ä»»åŠ¡ä¿¡æ¯ï¼‰ |
| **PCAï¼ˆä½œä¸ºå¯¹ç…§ï¼‰** | ä¸»æˆåˆ†åˆ†æé™ç»´ | âœ…ï¼ˆä½†éè½´å¯¹é½ï¼‰ | âŒ |

> æ³¨ï¼šæ‰€æœ‰æ–¹æ³•å‡é‡‡ç”¨ **è”åˆé€‰æ‹© Query å’Œ Key é€šé“** çš„ç­–ç•¥ï¼ˆJoint Selectionï¼‰ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆ50% å‹ç¼©ï¼ŒPre-RFTï¼‰

#### è¡¨ï¼šGated DeltaNet 1.3B åœ¨ 50% å‹ç¼©ä¸‹çš„è¡¨ç°ï¼ˆPre-RFTï¼‰

| æ–¹æ³• | Wikitext PPL â†‘ | Lambada PPL â†‘ | ZS Avg â†“ | Ret Avg â†“ |
|------|----------------|---------------|----------|-----------|
| Baseline | 16.8 | 9.7 | 59.4 | 40.3 |
| L1 | 26.5 | 34.0 | 53.3 | 32.9 |
| Rand | 18.8 | 14.4 | 56.5 | 32.1 |
| S-Wanda | 21.9 | 24.1 | 55.1 | 33.2 |
| **Grad** | **17.4** | **10.1** | **58.6** | **34.3** |
| **DRRQR** | 17.3 | 14.2 | 57.5 | 33.0 |

> âœ… **ç»“è®º**ï¼šå³ä½¿åœ¨æœªå¾®è°ƒçš„æƒ…å†µä¸‹ï¼Œ**Grad å’Œ DRRQR å¯å°†å›°æƒ‘åº¦æ§åˆ¶åœ¨æå°å¢é•¿èŒƒå›´å†…**ï¼Œä¸”é›¶æ ·æœ¬æ€§èƒ½ä¸‹é™ä¸åˆ° 1 pointã€‚

---

### ååé‡ä¸æ˜¾å­˜èŠ‚çœï¼ˆTable 3ï¼‰

| æ¨¡å‹ | åŸå§‹ $d_k$ | å‹ç¼©å $d_k$ | ååé‡æå‡ | æ˜¾å­˜é™ä½ |
|------|------------|--------------|------------|-----------|
| DeltaNet | 128 â†’ 64 | 8.1M â†’ 10.8M tps (**+34%**) | 6.33GiB â†’ 4.57GiB (**-28%**) |
| Gated DeltaNet | 128 â†’ 64 | 7.9M â†’ 10.4M tps (**+32%**) | 6.35GiB â†’ 4.59GiB (**-28%**) |

> âœ… **ç»“è®º**ï¼š50% é€šé“å‰ªæå³å¯å¸¦æ¥æ˜¾è‘—çš„é€Ÿåº¦å’Œå†…å­˜æ”¶ç›Šã€‚

---

### æ¢å¤å¾®è°ƒåæ€§èƒ½ï¼ˆPost-RFTï¼ŒGated DeltaNet 1.3Bï¼‰

| æ–¹æ³• | 50% å‹ç¼© Wikitext PPL | 50% å‹ç¼© Ret Avg |
|------|------------------------|------------------|
| Baseline | 16.8 | 40.3 |
| Grad | **16.4** | **34.3** |
| DRRQR | 16.3 | 33.0 |

> âœ… **ç»“è®º**ï¼šç»è¿‡è½»é‡çº§ RFT åï¼Œæ€§èƒ½è¿›ä¸€æ­¥æ¢å¤ï¼Œæ¥è¿‘åŸå§‹æ°´å¹³ã€‚

---

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰æ˜¯å¦è”åˆé€‰æ‹© Query å’Œ Keyï¼Ÿ

| æ–¹æ³• | é€‰æ‹©æ–¹å¼ | DeltaNet 370M PPLï¼ˆ50%ï¼‰ |
|------|----------|----------------------------|
| L1 | Only Q | 33.0 |
| L1 | Only K | 425218.3ï¼ˆå´©æºƒï¼‰ |
| L1 | Joint (Q+K) | 3843.5 |
| **Grad** | Only Q | 31.9 |
| **Grad** | Joint (Q+K) | **31.7** |
| **DRRQR** | Only Q | 35.7 |
| **DRRQR** | Joint (Q+K) | **31.4** |

> ğŸ” å‘ç°ï¼š**ä¼˜åŒ–ç±»æ–¹æ³•ï¼ˆGrad, DRRQRï¼‰å¿…é¡»è”åˆé€‰æ‹©æ‰èƒ½å‘æŒ¥æœ€ä½³æ•ˆæœ**ï¼Œè¯´æ˜å®ƒä»¬æ•æ‰åˆ°äº† Query-Key çš„è€¦åˆå…³ç³»ï¼›è€Œå¯å‘å¼æ–¹æ³•ï¼ˆL1ï¼‰åè€Œå›  Key æƒé‡è¿‡å¤§å¯¼è‡´ä¸ç¨³å®šã€‚

#### ï¼ˆ2ï¼‰ç§©åˆ©ç”¨ç‡å¯è§†åŒ–ï¼ˆFigure 2ï¼‰

- åœ¨ç›¸åŒæœ€å¤§å®¹é‡ä¸‹ï¼Œ**Grad å’Œ DRRQR çš„ rank utilization æ˜æ˜¾é«˜äºå…¶ä»–æ–¹æ³•**ã€‚
- æ”¯æŒäº†â€œé«˜ç§©åˆ©ç”¨ç‡æœ‰åŠ©äºæŠ—å™ªâ€çš„ç†è®ºæ¨æ–­ã€‚

#### ï¼ˆ3ï¼‰PCA ä¸é€‚ç”¨æ€§çš„éªŒè¯

- è‹¥ä½¿ç”¨æ ‡å‡† PCA è¿›è¡Œéè½´å¯¹é½å˜æ¢ï¼Œä¼šç ´å depthwise convolution çš„é€šé“ç‹¬ç«‹æ€§ã€‚
- å®éªŒæ˜¾ç¤ºï¼Œåœ¨éå…±äº«å·ç§¯ç»“æ„ä¸­ï¼ŒPCA æ€§èƒ½è¿œå·®äºç»“æ„åŒ–æ–¹æ³•ï¼ˆç”šè‡³ä¸å¦‚éšæœºå‰ªæï¼‰ã€‚
- åªæœ‰å½“æ¨¡å‹ä½¿ç”¨ **å…±äº«å·ç§¯æ»¤æ³¢å™¨ï¼ˆshared convolutionsï¼‰** æ—¶ï¼ŒPCA æ‰èƒ½æœ‰æ•ˆå·¥ä½œï¼ˆè§ Appendix C.2ï¼‰ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. âœ… **Linear Attention æ¨¡å‹æ™®éå­˜åœ¨ä½ç§©çŠ¶æ€é—®é¢˜**ï¼Œå¯¼è‡´ä¿¡æ¯å­˜å‚¨å†—ä½™ã€å¯¹æŸ¥è¯¢å™ªå£°æ•æ„Ÿã€‚
2. âœ… **ç§©åˆ©ç”¨ç‡ï¼ˆrank utilizationï¼‰æ˜¯è¡¡é‡è®°å¿†æ•ˆç‡çš„å…³é”®æŒ‡æ ‡**ï¼Œä½ç§©ä¼šæ˜¾è‘—æ”¾å¤§æ£€ç´¢è¯¯å·®ã€‚
3. âœ… **å¯é€šè¿‡ç»“æ„åŒ–å‰ªæå¤§å¹…å‹ç¼©çŠ¶æ€ç©ºé—´**ï¼Œæœ€å¤šå¯ç§»é™¤ 50% çš„ Key/Query é€šé“ï¼Œä»…å¸¦æ¥è½»å¾®æ€§èƒ½æŸå¤±ã€‚
4. âœ… **æ‰€æå‡ºçš„ DRRQR æ–¹æ³•è™½ä¸ºå±€éƒ¨ã€æ— ç›‘ç£æ–¹æ³•ï¼Œæ€§èƒ½å´åª²ç¾åŸºäºæ¢¯åº¦çš„å…¨å±€æ–¹æ³•ï¼ˆGradï¼‰**ï¼Œè¯æ˜äº†ç§©ä¼˜åŒ–çš„æœ‰æ•ˆæ€§ã€‚
5. âœ… **ç»“æ„åŒ–å‰ªæèƒ½å¸¦æ¥çœŸå®ç¡¬ä»¶åŠ é€Ÿ**ï¼š50% å‹ç¼©å¸¦æ¥çº¦ 1.3â€“1.5Ã— ååæå‡ï¼Œæ˜¾å­˜å‡å°‘ 28â€“42%ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§

| å±€é™æ€§ | è¯´æ˜ |
|--------|------|
| **å¯¹æ£€ç´¢å¯†é›†å‹ä»»åŠ¡æ›´æ•æ„Ÿ** | å¦‚ DROPã€SWDE ç­‰ä»»åŠ¡åœ¨é«˜å‹ç¼©æ¯”ä¸‹æ€§èƒ½ä¸‹é™æ˜æ˜¾ï¼ˆTable 13â€“16ï¼‰ã€‚ |
| **ä¾èµ– depthwise convolution ç»“æ„** | å½“å‰æ–¹æ³•è¦æ±‚å‰ªæåä»ä¿æŒé€šé“ç‹¬ç«‹æ€§ï¼Œéš¾ä»¥æ¨å¹¿åˆ°å…¨è¿æ¥å·ç§¯ç»“æ„ã€‚ |
| **æ— æ³•å®Œå…¨æ›¿ä»£ Softmax Attention** | å¯¹éœ€è¦é•¿æœŸä¾èµ–çš„ä»»åŠ¡ï¼Œä»éœ€æ··åˆæ¶æ„æ”¯æŒã€‚ |

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. ğŸ”„ **æ‰©å±•è‡³æ··åˆæ¨¡å‹ï¼ˆHybrid Modelsï¼‰**ï¼šå°†æœ¬æ¡†æ¶åº”ç”¨äºåŒæ—¶åŒ…å« Linear å’Œ Softmax Attention çš„æ¨¡å‹ï¼ˆå¦‚ Jambaã€Nemotron-Hï¼‰ï¼Œç”¨ Softmax å±‚å¼¥è¡¥æ£€ç´¢èƒ½åŠ›æŸå¤±ã€‚
2. ğŸ”§ **è®¾è®¡æ›´çµæ´»çš„å·ç§¯é€‚åº”æœºåˆ¶**ï¼šæ¢ç´¢å¦‚ä½•è®© depthwise convolutions æ›´å¥½åœ°é€‚é…ä»»æ„æ­£äº¤å˜æ¢ï¼ˆå¦‚é€šè¿‡ filter adaptation æˆ– shared convolutionsï¼‰ã€‚
3. ğŸ“ˆ **åœ¨çº¿åŠ¨æ€å‰ªæï¼ˆDynamic Sparsificationï¼‰**ï¼šæ ¹æ®è¾“å…¥åºåˆ—åŠ¨æ€è°ƒæ•´æ´»è·ƒé€šé“æ•°é‡ï¼Œå®ç°ç»†ç²’åº¦èµ„æºæ§åˆ¶ã€‚
4. ğŸ¤ **ä¸å…¶ä»–å‹ç¼©æŠ€æœ¯ç»“åˆ**ï¼šä¸é‡åŒ–ï¼ˆQuantizationï¼‰ã€çŸ¥è¯†è’¸é¦ç­‰æ–¹æ³•è”åˆä½¿ç”¨ï¼Œæ„å»ºç«¯åˆ°ç«¯é«˜æ•ˆæ¨ç† pipelineã€‚

---

> ğŸ’¬ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡ä» **ç§©çš„è§’åº¦æ­ç¤ºäº† Linear Attention å®¹é‡æœªè¢«å……åˆ†åˆ©ç”¨çš„æœ¬è´¨åŸå› **ï¼Œå¹¶æå‡ºäº†ä¸€å¥— **ç†è®ºæŒ‡å¯¼ä¸‹çš„ç»“æ„åŒ–å‰ªææ¡†æ¶**ï¼Œå®ç°äº† **é«˜è¾¾ 50% çš„çŠ¶æ€å‹ç¼©**ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹æ€§èƒ½å‡ ä¹ä¸å˜ï¼Œä¸ºé«˜æ•ˆå¤§æ¨¡å‹éƒ¨ç½²æä¾›äº†æ–°è·¯å¾„ã€‚

</details>

---

### 3. [AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent](https://arxiv.org/abs/2602.03955)

**Authors**: Yinyi Luo, Yiqiao Jin, Weichen Yu, Mengqi Zhang, Srijan Kumar, Xiaoxiao Li, Weijie Xu, Xin Chen, Jindong Wang  
**Category**: cs.AI  
**Published**: 2026-02-05  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.03955v1  

#### Abstract
While large language model (LLM) multi-agent systems achieve superior reasoning performance through iterative debate, practical deployment is limited by their high computational cost and error propagation. This paper proposes AgentArk, a novel framework to distill multi-agent dynamics into the weigh...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMulti-Agent Systems, MASï¼‰é€šè¿‡è¾©è®ºã€æ‰¹åˆ¤å’Œå…±è¯†ç­‰äº¤äº’æœºåˆ¶ï¼Œåœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚ç„¶è€Œï¼Œè¿™ç±»ç³»ç»Ÿå­˜åœ¨ä¸¤å¤§ç“¶é¢ˆï¼š
- **é«˜è®¡ç®—æˆæœ¬**ï¼šæ¨ç†é˜¶æ®µéœ€è¦å¤šä¸ªæ¨¡å‹å¹¶è¡Œè¿è¡Œå’Œå¤šè½®äº¤äº’ï¼Œå¯¼è‡´å»¶è¿Ÿé«˜ã€èµ„æºæ¶ˆè€—å¤§ã€‚
- **é”™è¯¯ä¼ æ’­é£é™©**ï¼šä¸ªä½“æ¨¡å‹çš„åè§æˆ–å¹»è§‰å¯èƒ½åœ¨ç¾¤ä½“ä¸­è¢«æ”¾å¤§ï¼Œå¯¼è‡´é›†ä½“å¤±æ•ˆã€‚

å› æ­¤ï¼Œå¦‚ä½•å°†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„**ååŒæ¨ç†èƒ½åŠ›**å†…åŒ–åˆ°ä¸€ä¸ªå•æ™ºèƒ½ä½“ä¸­ï¼ŒåŒæ—¶ä¿æŒå…¶é«˜æ•ˆæ€§å’Œé²æ£’æ€§ï¼Œæˆä¸ºä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡º **AgentArk**ï¼Œä¸€ç§å…¨æ–°çš„æ¡†æ¶ï¼Œæ—¨åœ¨å°†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„åŠ¨æ€æ¨ç†è¿‡ç¨‹â€œè’¸é¦â€è¿›å•ä¸€ LLM çš„æƒé‡ä¸­ï¼Œä»è€Œå®ç°ï¼š
- å°†æ˜¾å¼çš„æµ‹è¯•æ—¶äº¤äº’ï¼ˆtest-time interactionï¼‰è½¬åŒ–ä¸ºéšå¼çš„æ¨¡å‹å†…éƒ¨èƒ½åŠ›ã€‚
- åœ¨æ¨ç†é˜¶æ®µä»…éœ€ä¸€æ¬¡å‰å‘ä¼ æ’­å³å¯å®Œæˆé«˜è´¨é‡æ¨ç†ï¼Œæ˜¾è‘—é™ä½éƒ¨ç½²æˆæœ¬ã€‚

#### AgentArk çš„ä¸‰å¤§åˆ†å±‚è’¸é¦ç­–ç•¥ï¼š
1. **Reasoning-Enhanced SFT (RSFT)**  
   åœ¨æ ‡å‡†ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰åŸºç¡€ä¸Šï¼Œä¸ä»…ä½¿ç”¨æœ€ç»ˆç­”æ¡ˆï¼Œè¿˜å¼•å…¥å®Œæ•´çš„å¤šæ™ºèƒ½ä½“æ¨ç†è½¨è¿¹ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œå¢å¼ºæ¨¡å‹ç”Ÿæˆè¿è´¯ä¸­é—´æ­¥éª¤çš„èƒ½åŠ›ã€‚

2. **Data Augmentation via Diverse Extraction (DA)**  
   ä»å¤šæ™ºèƒ½ä½“è¾©è®ºæ—¥å¿—ä¸­æå–å¤šæ ·åŒ–çš„æ­£ç¡®æ¨ç†è·¯å¾„ï¼ˆå¦‚ä¸åŒè§£é¢˜é€»è¾‘ã€æ•°å­¦æ’ç­‰å¼ï¼‰ï¼Œè®­ç»ƒå­¦ç”Ÿæ¨¡å‹æŒæ¡å¤šç§æ€ç»´æ¨¡å¼ï¼Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚

3. **Process-Aware Distillation (PAD)**  
   åˆ©ç”¨ **Process Reward Model (PRM)** å¯¹æ¯ä¸€æ­¥æ¨ç†è¿›è¡Œç»†ç²’åº¦å¥–åŠ±å»ºæ¨¡ï¼Œå¹¶ç»“åˆ **Group Relative Policy Optimization (GRPO)** è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œä½¿æ¨¡å‹å­¦ä¼šè‡ªæˆ‘ä¿®æ­£ã€åˆ†è§£é—®é¢˜å’Œè¯†åˆ«é”™è¯¯ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | AgentArk | ä¼ ç»Ÿæ–¹æ³• |
|------|--------|---------|
| **æ•ˆç‡** | æ¨ç†ä»…éœ€å•æ¬¡ç”Ÿæˆï¼Œä½å»¶è¿Ÿ | å¤šè½®å¤šæ¨¡å‹äº¤äº’ï¼Œé«˜å¼€é”€ |
| **æ³›åŒ–æ€§** | è’¸é¦çš„æ˜¯â€œæ¨ç†è¡Œä¸ºâ€è€Œéç‰¹å®šç»“æ„ | å¤šä¾èµ–æ‰‹å·¥è®¾è®¡çš„è§’è‰²/åè®® |
| **é²æ£’æ€§** | æ˜¾è‘—æå‡å¯¹åˆ†å¸ƒå¤–ï¼ˆOODï¼‰ä»»åŠ¡çš„é€‚åº”èƒ½åŠ› | å®¹æ˜“è¿‡æ‹Ÿåˆäºç‰¹å®šä»»åŠ¡æ ¼å¼ |
| **é€šç”¨æ€§** | æ¡†æ¶ä¸ä¾èµ–ç‰¹å®š MAS ç®—æ³•ï¼ˆå¦‚è¾©è®ºã€æŠ•ç¥¨ï¼‰ | å¤šä¸ºç‰¹å®šæ¶æ„å®šåˆ¶ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | ç±»å‹ | æè¿° |
|-------|------|------|
| **GSM8K** | æ•°å­¦æ¨ç† | å°å­¦çº§åˆ«åº”ç”¨é¢˜ï¼Œå¼ºè°ƒå¤šæ­¥ç®—æœ¯æ¨ç† |
| **MATH** | æ•°å­¦æ¨ç† | æ›´å¤æ‚çš„é«˜ä¸­çº§æ•°å­¦é—®é¢˜ |
| **MetaMathQA (MMQA)** | å¢å¼ºæ•°å­¦æ¨ç† | åŒ…å«å¤šæ ·åŒ–è§£æ³•è·¯å¾„çš„æ•°å­¦é—®ç­” |
| **MedMCQA** | åŒ»ç–—é¢†åŸŸé—®ç­” | å¤šé€‰é¢˜å½¢å¼ï¼Œè€ƒå¯Ÿä¸“ä¸šçŸ¥è¯†ä¸æ¨ç†ç»“åˆ |
| **HotpotQA / QASPER / QMSum** | é›¶æ ·æœ¬è¿ç§»è¯„ä¼° | ç”¨äºæµ‹è¯•è·¨åŸŸæ³›åŒ–èƒ½åŠ›ï¼ˆä¸åœ¨è®­ç»ƒä¸­ä½¿ç”¨ï¼‰ |

### å®éªŒè®¾ç½®
- **æ•™å¸ˆæ¨¡å‹**ï¼šQwen3-32B, Gemma3-27B-it, Qwen3-8B
- **å­¦ç”Ÿæ¨¡å‹**ï¼šQwen3-8B, Qwen3-1.7B, Qwen3-0.6B, Llama3-8B, Gemma-7B
- **è’¸é¦æ–¹å¼**ï¼šåŒå®¶æ—ï¼ˆsame-familyï¼‰ä¸è·¨å®¶æ—ï¼ˆcross-familyï¼‰
- **å¤šæ™ºèƒ½ä½“é…ç½®**ï¼š5~20ä¸ª agent å‚ä¸è¾©è®ºï¼Œæœ€å¤š3è½®è¿­ä»£
- **è®­ç»ƒæ•°æ®é‡**ï¼šçº¦342kå”¯ä¸€è¾“å…¥ï¼Œ2Mæ¨ç†è½¨è¿¹

### è¯„ä¼°æŒ‡æ ‡
- **ä¸»æŒ‡æ ‡**ï¼šå‡†ç¡®ç‡ï¼ˆAccuracyï¼‰
- **æ¨ç†è´¨é‡åˆ†æ**ï¼š
  - Perplexityï¼ˆå›°æƒ‘åº¦ï¼‰ï¼šè¡¡é‡æ¨ç†æ­¥éª¤çš„æµç•…æ€§å’Œä¸€è‡´æ€§
  - LLM-based è‡ªåŠ¨è¯„åˆ†ï¼šè¯„ä¼° step decompositionã€intermediate verificationã€error localizationã€reasoning coherence å››ä¸ªç»´åº¦
- **é²æ£’æ€§æŒ‡æ ‡**ï¼šåœ¨ TruthfulQA ä¸Šçš„ BLEU å’Œ ROUGE åˆ†æ•°
- **æ³›åŒ–èƒ½åŠ›**ï¼šåœ¨æœªè§è¿‡çš„ OOD æ•°æ®é›†ä¸Šçš„è¡¨ç°

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æè¿° |
|------|------|
| **Single Agent** | åŸå§‹å­¦ç”Ÿæ¨¡å‹ï¼Œæ— ä»»ä½•è’¸é¦ |
| **Vanilla Multi-Agent Debate** | å¤šæ™ºèƒ½ä½“ç›´æ¥åä½œæ¨ç†ï¼ˆé«˜æˆæœ¬åŸºçº¿ï¼‰ |
| **Standard SFT** | ä»…ç”¨æœ€ç»ˆç­”æ¡ˆè¿›è¡Œç›‘ç£å¾®è°ƒ |
| **RSFT / DA / PAD** | ä¸‰ç§è’¸é¦ç­–ç•¥å•ç‹¬åŠç»„åˆä½¿ç”¨ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| å­¦ç”Ÿæ¨¡å‹ | æ–¹æ³• | GSM8K â†‘ | MedMCQA â†‘ | å¹³å‡æå‡ |
|--------|------|--------|----------|----------|
| Qwen3-8B | Single | 88.17 | 59.65 | â€” |
|          | RSFT | 88.42 | 59.71 | +0.3~+0.6 |
|          | DA   | 88.18 | 58.35 | æ³¢åŠ¨è¾ƒå¤§ |
|          | **PAD** | **89.05** | **63.12** | **+4.8%** |
| Qwen3-0.6B | Single | 41.93 | 32.20 | â€” |
|          | PAD  | 44.61 | 34.51 | +2.7~+2.3 |

> âœ… **æ€»ä½“å¹³å‡æå‡è¾¾ 4.8%**ï¼Œæ¥è¿‘ç”šè‡³éƒ¨åˆ†è¶…è¶ŠåŸå§‹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„è¡¨ç°ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ä¼˜äº Vanilla MAS**ï¼šè™½ç„¶ç•¥ä½äºå®Œæ•´å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆé€šå¸¸é«˜1-2%ï¼‰ï¼Œä½†**æ¨ç†é€Ÿåº¦æå‡æ•°åå€**ï¼Œé€‚åˆå®æ—¶åœºæ™¯ã€‚
- **è¿œè¶… Standard SFT**ï¼šä»…ç”¨ç­”æ¡ˆå¾®è°ƒå¸¸å¯¼è‡´é€€åŒ–ï¼ˆå°¤å…¶åœ¨ GSM8K ä¸Šï¼‰ï¼Œè€Œ AgentArk æ˜¾è‘—æ”¹å–„ã€‚
- **PAD æœ€ç¨³å®šæœ‰æ•ˆ**ï¼šåœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šå‡å–å¾—ä¸€è‡´å¢ç›Šï¼ŒDA å’Œ RSFT è¡¨ç°ä¸ç¨³å®šã€‚

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰PRM å®¹é‡å½±å“å¤§äºå­¦ç”Ÿæ¨¡å‹å¤§å°
| PRM æ¨¡å‹ | å­¦ç”Ÿæ¨¡å‹ | GSM8K | å‘ç° |
|--------|--------|-------|------|
| 0.6B   | 0.6B   | 42.84 | å° PRM æ•ˆæœå·® |
| 8B     | 0.6B   | 88.48 | **å¤§ PRM å³ä½¿é…å°å­¦ç”Ÿä¹Ÿæœ‰æ•ˆ** |
| 0.6B   | 8B     | 42.39 | å° PRM é™åˆ¶ä¸Šé™ |
| 8B     | 8B     | 88.63 | æœ€ä½³ç»„åˆ |

> ğŸ” **ç»“è®ºï¼šPRM çš„å»ºæ¨¡èƒ½åŠ›æ¯”å­¦ç”Ÿå®¹é‡æ›´é‡è¦**

#### ï¼ˆ2ï¼‰æ•°æ®è´¨é‡ > æ•°æ®æ•°é‡
- å¢åŠ è®­ç»ƒæ•°æ®è§„æ¨¡å¹¶ä¸å¸¦æ¥å•è°ƒæå‡ï¼Œåè€Œå¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™ï¼ˆå°¤å…¶å¯¹å°æ¨¡å‹ï¼‰ã€‚
- **PAD æ–¹æ³•åœ¨ä¸åŒæ•°æ®é‡ä¸‹è¡¨ç°æœ€ç¨³å®š**ï¼Œè¯´æ˜é«˜è´¨é‡çš„è¿‡ç¨‹ç›‘ç£æ¯”æµ·é‡è½¨è¿¹æ›´å…³é”®ã€‚

#### ï¼ˆ3ï¼‰å­¦ç”Ÿå®¹é‡å†³å®šæ”¶ç›Šä¸Šé™
- å°æ¨¡å‹ï¼ˆå¦‚ 0.6Bï¼‰éš¾ä»¥å¸æ”¶è¿‡å¤šå¤æ‚çš„æ¨ç†æ¨¡å¼ï¼Œå®¹æ˜“é¥±å’Œç”šè‡³è´Ÿè¿ç§»ã€‚
- å¤§æ¨¡å‹ï¼ˆå¦‚ 8Bï¼‰èƒ½æ›´å¥½åˆ©ç”¨ä¸°å¯Œçš„æ•™å¸ˆä¿¡å·ï¼Œscaling æ•ˆæœæ˜æ˜¾ã€‚

#### ï¼ˆ4ï¼‰ç»„åˆç­–ç•¥å¯å åŠ å¢ç›Š
| æ–¹æ³• | GSM8K â†’ GSM8K | MedMCQA â†’ MedMCQA |
|------|---------------|------------------|
| RSFT | 68.61 | 42.67 |
| RSFT+DA | 70.27 (+1.66) | 44.30 (+1.63) |
| PAD+DA | 70.69 (+0.66) | 43.68 (+0.00) |

> âœ… å„æ–¹æ³•å…¼å®¹ï¼Œå¯å †å ä½¿ç”¨è·å¾—è¿›ä¸€æ­¥æå‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **å•ä¸ª LLM å¯ä»¥å†…åŒ–å¤šæ™ºèƒ½ä½“çš„æ¨ç†èƒ½åŠ›**  
   é€šè¿‡åˆç†çš„è’¸é¦ç­–ç•¥ï¼Œå•æ¨¡å‹å¯ä»¥æ¨¡æ‹Ÿå‡ºç±»ä¼¼â€œè‡ªæˆ‘è¾©è®ºâ€ã€â€œè‡ªæˆ‘çº é”™â€çš„é«˜çº§è®¤çŸ¥è¡Œä¸ºã€‚

2. âœ… **è¿‡ç¨‹æ„ŸçŸ¥è’¸é¦ï¼ˆPADï¼‰æ˜¯æœ€æœ‰æ•ˆçš„ç­–ç•¥**  
   å¼•å…¥ PRM + GRPO çš„å¼ºåŒ–å­¦ä¹ æœºåˆ¶ï¼Œèƒ½å¤Ÿæ•æ‰å¤šæ™ºèƒ½ä½“ä¹‹é—´çš„**è¾©è¯æ¨ç†åŠ¨æ€**ï¼Œæ˜¾è‘—æå‡æ¨ç†è´¨é‡å’Œé²æ£’æ€§ã€‚

3. âœ… **æ¨ç†è´¨é‡ä¼˜äºæ•°é‡ï¼ŒPRM æ˜¯å…³é”®ç“¶é¢ˆ**  
   é«˜è´¨é‡çš„è¿‡ç¨‹ç›‘ç£æ¯”å¤§é‡è½¨è¿¹æ›´é‡è¦ï¼›PRM çš„å®¹é‡ç›´æ¥å½±å“è’¸é¦æ•ˆæœã€‚

4. âœ… **å…·å¤‡è‰¯å¥½çš„è·¨ä»»åŠ¡å’Œè·¨æ¨¡æ€æ³›åŒ–èƒ½åŠ›**  
   - åœ¨æœªå‚ä¸è®­ç»ƒçš„ HotpotQAã€QASPERã€QMSum ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼›
   - åˆæ­¥éªŒè¯å¯ç”¨äº **Multimodal LLMs (MLLMs)**ï¼Œå°½ç®¡å¢ç›Šè¾ƒå°ä½†ä»æ­£å‘ã€‚

5. âœ… **è½»é‡æ¨¡å‹ä¹Ÿèƒ½å—ç›Š**  
   å³ä½¿æ˜¯ Qwen3-0.6B è¿™æ ·çš„å°å‹æ¨¡å‹ï¼Œä¹Ÿèƒ½é€šè¿‡è’¸é¦è·å¾—å¯è§‚æå‡ï¼Œä¸ºè¾¹ç¼˜è®¾å¤‡éƒ¨ç½²æä¾›å¯èƒ½ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **è®­ç»ƒæˆæœ¬è¾ƒé«˜**ï¼šå°¤å…¶æ˜¯ PAD ä¸­çš„ PRM è®­ç»ƒå’Œ GRPO ä¼˜åŒ–ï¼Œéœ€ 8Ã—H100 GPUï¼Œè€—æ—¶çº¦ 20 å°æ—¶ã€‚
2. **å½“å‰ä»…é™äºæ¨ç†ä»»åŠ¡**ï¼šæœªæ¶‰åŠå·¥å…·è°ƒç”¨ï¼ˆtool useï¼‰ã€è®°å¿†ç®¡ç†ï¼ˆmemoryï¼‰ç­‰å…¶ä»–æ™ºèƒ½ä½“åŠŸèƒ½ã€‚
3. **ä¾èµ–é«˜è´¨é‡è¾©è®ºæ•°æ®ç”Ÿæˆ**ï¼šè‹¥æ•™å¸ˆæ¨¡å‹æœ¬èº«æ¨ç†èƒ½åŠ›ä¸è¶³ï¼Œåˆ™è’¸é¦æ•ˆæœå—é™ã€‚
4. **æœªæ¢ç´¢éè¾©è®ºç±» MAS æ¶æ„**ï¼šç›®å‰ä¸»è¦åŸºäº debate æœºåˆ¶ï¼Œæ˜¯å¦é€‚ç”¨äº reflectionã€planning ç­‰å°šå¾…éªŒè¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **è‡ªé€‚åº”è’¸é¦ç­–ç•¥**ï¼šæ ¹æ®ä»»åŠ¡å¤æ‚åº¦åŠ¨æ€é€‰æ‹©è’¸é¦å¼ºåº¦æˆ–è½¨è¿¹é‡‡æ ·æ–¹å¼ã€‚
2. **æ¨¡å—åŒ– PRM è®¾è®¡**ï¼šæ„å»ºå¯å¤ç”¨ã€å¯æ’æ‹”çš„ PRM ç»„ä»¶ï¼Œæ”¯æŒä¸åŒæ¨ç†ç¯èŠ‚çš„ç²¾ç»†åŒ–æŒ‡å¯¼ã€‚
3. **æ‰©å±•è‡³æ›´å¤š MAS èŒƒå¼**ï¼šåº”ç”¨äºè§„åˆ’ã€åæ€ã€å·¥å…·åä½œç­‰æ›´å¤æ‚çš„å¤šæ™ºèƒ½ä½“æµç¨‹ã€‚
4. **è·¨æ¨¡æ€æ¨ç†è’¸é¦**ï¼šå°†æ–‡æœ¬æ¨ç†èƒ½åŠ›è¿ç§»åˆ°è§†è§‰-è¯­è¨€è”åˆæ¨ç†ä¸­ã€‚
5. **å®‰å…¨ä¸å¯æ§æ€§ç ”ç©¶**ï¼šé˜²æ­¢è’¸é¦è¿‡ç¨‹ä¸­ç»§æ‰¿æ•™å¸ˆæ¨¡å‹çš„åè§ã€è¯´æœæ€§è°¬è¯¯ç­‰é—®é¢˜ã€‚

---

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> **AgentArk æˆåŠŸå°†æ˜‚è´µçš„å¤šæ™ºèƒ½ä½“åä½œâ€œå‹ç¼©â€è¿›ä¸€ä¸ªé«˜æ•ˆå•æ¨¡å‹ä¸­ï¼Œå®ç°äº†â€œä»¥è®­ç»ƒæ¢æ¨ç†â€çš„èŒƒå¼è½¬å˜ï¼Œä¸ºæ„å»ºä½æˆæœ¬ã€é«˜æ€§èƒ½ã€å¯éƒ¨ç½²çš„æ™ºèƒ½æ¨ç†ç³»ç»Ÿæä¾›äº†æ–°è·¯å¾„ã€‚**

</details>

---

### 4. [Swordsman: Entropy-Driven Adaptive Block Partition for Efficient Diffusion Language Models](https://arxiv.org/abs/2602.04399)

**Authors**: Yu Zhang, Xinchen Li, Jialei Zhou, Hongnan Ma, Zhongwei Wan, Yiwei Shi, Duoqian Miao, Qi Zhang, Longbing Cao  
**Category**: cs.CL  
**Published**: 2026-02-05  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.04399v1  

#### Abstract
Block-wise decoding effectively improves the inference speed and quality in diffusion language models (DLMs) by combining inter-block sequential denoising and intra-block parallel unmasking. However, existing block-wise decoding methods typically partition blocks in a rigid and fixed manner, which i...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šSwordsman: Entropy-Driven Adaptive Block Partition for Efficient Diffusion Language Models**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
ç°æœ‰çš„ **Diffusion Language Models (DLMs)** è™½ç„¶ç†è®ºä¸Šå…·å¤‡å¹¶è¡Œè§£ç æ½œåŠ›ï¼Œä½†åœ¨å®é™…æ¨ç†ä¸­ä»é¢ä¸´**é«˜å»¶è¿Ÿ**å’Œ**ç”Ÿæˆè´¨é‡ä¸è¶³**çš„é—®é¢˜ã€‚å…¶ä¸­ï¼Œ**block-wise decoding** æ˜¯ä¸€ç§æœ‰æ•ˆçš„åŠ é€Ÿç­–ç•¥ï¼Œé€šè¿‡å°†åºåˆ—åˆ’åˆ†ä¸ºå¤šä¸ªå—è¿›è¡Œä¸²è¡Œå—é—´ã€å¹¶è¡Œå—å†…è§£ç ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•é€šå¸¸é‡‡ç”¨**å›ºå®šé•¿åº¦çš„ block åˆ†å‰²ï¼ˆfixed-length block partitionï¼‰**ï¼Œè¿™ç§åˆšæ€§åˆ’åˆ†æ–¹å¼å¸¸å¸¸ä¼š**å‰²è£‚è¯­ä¹‰æˆ–å¥æ³•ä¸Šçš„å®Œæ•´æˆåˆ†ï¼ˆconstituentsï¼‰**ï¼Œå¯¼è‡´æ¨¡å‹åœ¨è·¨å—è¾¹ç•Œå¤„éš¾ä»¥å‡†ç¡®é¢„æµ‹ï¼Œä»è€Œé™ä½ç”Ÿæˆè´¨é‡å’Œæ•ˆç‡ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æœ¬æ–‡æå‡º **Swordsman**ï¼Œä¸€ä¸ª**æ— éœ€è®­ç»ƒçš„ã€åŸºäºç†µé©±åŠ¨çš„è‡ªé€‚åº”å—åˆ’åˆ†æ¡†æ¶ï¼ˆtraining-free, entropy-driven adaptive block partitioning frameworkï¼‰**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- åˆ©ç”¨ **Entropy Reduction Hypothesis (ERH)**ï¼šè®¤ä¸ºåœ¨è¯­è¨€å¤„ç†è¿‡ç¨‹ä¸­ï¼Œ**æ„æˆæˆåˆ†ï¼ˆconstituentï¼‰çš„è¾¹ç•Œå¤„ä¸ç¡®å®šæ€§æ›´é«˜**ï¼Œå› æ­¤åœ¨è¿™äº›ä½ç½®ä¼šå‡ºç°æ˜¾è‘—çš„**ç†µå˜åŒ–ï¼ˆentropy shiftï¼‰**ã€‚
- é€šè¿‡æ£€æµ‹ç›¸é‚» token ä¹‹é—´çš„**ç†µå·®å€¼ï¼ˆâ–³Hï¼‰** æ¥è¯†åˆ«è¯­ä¹‰è¾¹ç•Œï¼Œå¹¶æ®æ­¤**åŠ¨æ€åˆ’åˆ† block è¾¹ç•Œ**ï¼Œä½¿ block æ›´å¥½åœ°å¯¹é½è‡ªç„¶è¯­è¨€çš„è¯­æ³•å’Œè¯­ä¹‰ç»“æ„ã€‚
- å¼•å…¥**åŠ¨æ€ç½®ä¿¡åº¦é˜ˆå€¼æœºåˆ¶ï¼ˆdynamic unmasking thresholdï¼‰**ï¼Œæ ¹æ®æ¯ä¸ª block å†…éƒ¨çš„å¹³å‡ç†µæ°´å¹³å®æ—¶è°ƒæ•´è§£ç é˜ˆå€¼ï¼Œä»¥å¹³è¡¡å¹¶è¡Œæ€§å’Œå¯é æ€§ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- âœ… **æ›´ä¼˜çš„è¯­ä¹‰å¯¹é½**ï¼šè‡ªé€‚åº”åˆ’åˆ†é¿å…äº†å›ºå®šé•¿åº¦ block å¯¹è¯­ä¹‰æˆåˆ†çš„å‰²è£‚ï¼Œæå‡ç”Ÿæˆè¿è´¯æ€§ã€‚
- âœ… **æ›´é«˜çš„æ¨ç†æ•ˆç‡ä¸è´¨é‡**ï¼šç»“åˆ KV Cache å’ŒåŠ¨æ€é˜ˆå€¼ï¼Œåœ¨ä¿æŒé«˜é€Ÿå¹¶è¡Œè§£ç çš„åŒæ—¶æ˜¾è‘—æå‡ accuracyã€‚
- âœ… **æ— éœ€é‡æ–°è®­ç»ƒ**ï¼šä½œä¸ºçº¯æ¨ç†ä¼˜åŒ–æ¡†æ¶ï¼Œå¯ç›´æ¥åº”ç”¨äºå·²æœ‰ DLM æ¨¡å‹ã€‚
- âœ… **æ›´å¼ºçš„é²æ£’æ€§**ï¼šåœ¨ä¸åŒ cache é…ç½®ä¸‹å‡è¡¨ç°ç¨³å®šï¼Œå°¤å…¶åœ¨å¼ºç¼“å­˜æ¡ä»¶ä¸‹ä¼˜åŠ¿æ›´æ˜æ˜¾ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ¨¡å‹ä¸æ•°æ®é›†**
- **é¢„è®­ç»ƒ DLM æ¨¡å‹**ï¼š
  - `LLaDA-8B-Instruct`
  - `LLaDA-1.5`
  - `Dream-v0-base-7B`
- **åŸºå‡†æµ‹è¯•ä»»åŠ¡ï¼ˆBenchmarksï¼‰**ï¼š
  - **ä»£ç ç”Ÿæˆ**ï¼š`HumanEval`ï¼ˆ0-shotï¼‰ã€`MBPP`ï¼ˆ3-shotï¼‰
  - **æ•°å­¦æ¨ç†**ï¼š`GSM8K`ï¼ˆ5-shotï¼‰ã€`MATH`ï¼ˆ4-shotï¼‰

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼šNVIDIA H200 GPU
- **ç”Ÿæˆé•¿åº¦é™åˆ¶**ï¼šL = 512
- **é™æ€ç½®ä¿¡é˜ˆå€¼**ï¼ˆbaselineï¼‰ï¼šT_fixed = 0.9
- **Swordsman è¶…å‚æ•°**ï¼š
  - æœ€å°ç†µå˜é˜ˆå€¼ï¼šT_min = 0.1
  - åˆå§‹ç½®ä¿¡é˜ˆå€¼ï¼šT_init = 0.9
- **KV Cache é…ç½®**ï¼šæ— ç¼“å­˜ï¼ˆNoneï¼‰ã€å‰ç¼€ç¼“å­˜ï¼ˆPrefixï¼‰ã€åŒç¼“å­˜ï¼ˆDualï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Accuracy (%)**ï¼šç”Ÿæˆè´¨é‡
  - **Throughput (TPS, tokens/sec)**ï¼šè§£ç é€Ÿåº¦
  - **Latency (s/sample)**ï¼šç«¯åˆ°ç«¯ç”Ÿæˆæ—¶é—´

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| æ–¹æ³• | ç±»å‹ | æ˜¯å¦å¼€æº |
|------|------|----------|
| **Fast-dLLM** | å›ºå®š block å¤§å°ï¼ˆ32ï¼‰ | æ˜¯ |
| **D2F** | å›ºå®š block + å¤šæ­¥è’¸é¦ | æ˜¯ |
| **AdaBlock** | è‡ªé€‚åº” blockï¼ˆåŸºäºæ ‡ç‚¹ï¼‰ | å¦ï¼ˆå¤ç°è®ºæ–‡ç»“æœï¼‰ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
#### **åœ¨ LLaDA-8B-Instruct ä¸Šçš„è¡¨ç°ï¼ˆGSM8Kï¼‰**
| æ–¹æ³• | Accuracy (%) | TPS | Latency (s) |
|------|--------------|-----|-------------|
| Vanilla LLaDA | 77.40 | 8.39 | â€” |
| Fast-dLLM (Dual) | 75.21 | 72.12 | 3.72 |
| **Swordsman (Dual)** | **81.50** | **73.74** | **3.66** |

> â¬†ï¸ **Accuracy æå‡ +6.29%**ï¼ŒåŒæ—¶å®ç° **8.79Ã— æ¨ç†åŠ é€Ÿ**ï¼ˆvs. åŸå§‹ LLaDAï¼‰

#### **åœ¨ LLaDA-1.5 ä¸Šçš„è¡¨ç°ï¼ˆHumanEvalï¼‰**
| æ–¹æ³• | Accuracy (%) |
|------|--------------|
| Fast-dLLM (Dual) | 35.59 |
| **Swordsman (Dual)** | **43.90** |

> â¬†ï¸ **ç»å¯¹æå‡ +8.31%**ï¼Œä¸”æ¨ç†é€Ÿåº¦ç›¸å½“

#### **åœ¨ Dream-v0-base-7B ä¸Šçš„è¡¨ç°ï¼ˆHumanEvalï¼‰**
| æ–¹æ³• | Accuracy (%) |
|------|--------------|
| Fast-dLLM (Prefix) | 56.70 |
| **Swordsman (Prefix)** | **57.93** |

> è¾¾åˆ°å½“å‰æœ€ä¼˜ performance

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- åœ¨æ‰€æœ‰ backbone å’Œ benchmark ä¸Šï¼Œ**Swordsman å‡è¾¾åˆ° SOTA æ€§èƒ½**ã€‚
- ç›¸æ¯” Fast-dLLMï¼š
  - å¹³å‡ accuracy æå‡çº¦ **+1.5%~+8.31%**
  - throughput æå‡ **+1.62 ~ +3.67 TPS**
  - latency ä¸‹é™ **-0.27s ~ -0.31s**
- åœ¨ Dual Cache è®¾ç½®ä¸‹ï¼Œ**Pareto å‰æ²¿ä¸Šå æ®ä¸»å¯¼åœ°ä½**ï¼Œå®ç°â€œé«˜é€Ÿ + é«˜è´¨â€çš„åŒé‡ä¼˜åŠ¿ã€‚
- D2F è™½ç„¶ TPS æ›´é«˜ï¼ˆå¦‚ Dream-7B ä¸Šè¾¾ 89.82ï¼‰ï¼Œä½† accuracy æ˜¾è‘—ä¸‹é™ï¼Œå±äºâ€œé«˜é£é™©æ¢é€Ÿåº¦â€ç­–ç•¥ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**
#### **åŠ¨æ€é˜ˆå€¼æœºåˆ¶çš„å½±å“ï¼ˆAblation on Dynamic Thresholdï¼‰**
- å›ºå®šé˜ˆå€¼ï¼ˆT=0.9ï¼‰æ˜“é™·å…¥**é€€åŒ–çŠ¶æ€**ï¼ˆdegradation stateï¼‰ï¼Œéœ€é€ä¸ª token è§£ç ï¼Œä¸¥é‡æ‹–æ…¢é€Ÿåº¦ã€‚
- åŠ¨æ€é˜ˆå€¼ï¼ˆT_init=0.9ï¼‰å¯åœ¨ä¿æŒ accuracyï¼ˆ81.43% vs. 81.45%ï¼‰çš„åŒæ—¶ï¼Œ**é™ä½å»¶è¿Ÿ 2.49 ç§’**ã€‚
- è‹¥ T_init è¿‡ä½ï¼ˆå¦‚ 0.5ï¼‰ï¼Œåˆ™å› è¿‡æ—©è§£ç ä¸ç¡®å®š token å¯¼è‡´ accuracy æ˜¾è‘—ä¸‹é™ã€‚
- è‹¥ T_init=1.0ï¼Œåˆ™è¿‡äºä¿å®ˆï¼Œå¯¼è‡´å¤§é‡ä¸²è¡Œè§£ç ï¼Œå»¶è¿Ÿå¢åŠ  **~2.4Ã—**ã€‚

> âœ… éªŒè¯äº†åŠ¨æ€é˜ˆå€¼åœ¨**ç»´æŒè´¨é‡çš„å‰æä¸‹æœ€å¤§åŒ–å¹¶è¡Œæ€§**çš„æœ‰æ•ˆæ€§ã€‚

#### **è‡ªé€‚åº”åˆ’åˆ† vs å›ºå®šåˆ’åˆ†**
- å›ºå®šåˆ’åˆ†å¸¸å°†â€œcolorful benches, blooming flowersâ€ç­‰è¯­ä¹‰æ•´ä½“æ‹†åˆ†è‡³ä¸åŒ blockï¼Œå¢åŠ é¢„æµ‹éš¾åº¦ã€‚
- Swordsman æˆåŠŸåœ¨â€œenjoying the fresh airâ€ã€â€œpassed byâ€ç­‰è‡ªç„¶è¯­ä¹‰è¾¹ç•Œå¤„åˆ†å‰²ï¼Œæå‡ä¸Šä¸‹æ–‡ä¸€è‡´æ€§ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **ç†µå˜ï¼ˆentropy shiftï¼‰æ˜¯è¯†åˆ«è¯­ä¹‰è¾¹ç•Œçš„å¯é ä¿¡å·**ï¼šåœ¨ constituent è¾¹ç•Œå¤„ç†µæ˜¾è‘—ä¸Šå‡ï¼Œå¯ç”¨äºæŒ‡å¯¼ block åˆ’åˆ†ã€‚
2. **è¯­ä¹‰å¯¹é½çš„ block åˆ’åˆ†èƒ½æ˜¾è‘—æå‡ DLM çš„ç”Ÿæˆè´¨é‡ä¸æ•ˆç‡**ï¼šç›¸æ¯”å›ºå®šé•¿åº¦åˆ’åˆ†ï¼Œè‡ªé€‚åº”åˆ’åˆ†å‡å°‘äº†è·¨å—ä¾èµ–å’Œå†…éƒ¨æ··ä¹±ã€‚
3. **åŠ¨æ€é˜ˆå€¼æœºåˆ¶æœ‰æ•ˆç¼“è§£äº† block éš¾åº¦å·®å¼‚å¸¦æ¥çš„è§£ç å¤±è¡¡é—®é¢˜**ï¼šä½ç†µ block å¯å¤§èƒ†å¹¶è¡Œï¼Œé«˜ç†µ block åˆ™è°¨æ…æ¨è¿›ã€‚
4. **Swordsman æ˜¯ä¸€ä¸ªè½»é‡ã€é€šç”¨ã€æ— éœ€è®­ç»ƒçš„æ¨ç†åŠ é€Ÿæ¡†æ¶**ï¼šå…¼å®¹ç°æœ‰ DLM æ¶æ„ä¸ KV Cacheï¼Œéƒ¨ç½²æˆæœ¬ä½ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- å½“å‰éªŒè¯ä¸»è¦é›†ä¸­äº **block-wise DLMs**ï¼Œå°šæœªå¹¿æ³›æµ‹è¯•äº semi-autoregressive æˆ–å…¶ä»–ç”ŸæˆèŒƒå¼ã€‚
- è¶…å‚æ•°ï¼ˆå¦‚ T_minï¼‰å¯èƒ½éœ€è¦é’ˆå¯¹ç‰¹å®šæ•°æ®é›†æˆ–ä»»åŠ¡è¿›è¡Œè°ƒä¼˜ã€‚
- å¯¹é•¿æ–‡æœ¬çš„åˆ’åˆ†ç¨³å®šæ€§æœ‰å¾…è¿›ä¸€æ­¥ç ”ç©¶ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- å°†æ¡†æ¶æ‰©å±•è‡³ **semi-autoregressive models**ã€‚
- å¼€å‘**è‡ªé€‚åº”è¶…å‚æ•°é€‰æ‹©æœºåˆ¶**ï¼Œå‡å°‘äººå·¥è°ƒå‚éœ€æ±‚ã€‚
- æ¢ç´¢åŸºäºå­¦ä¹ çš„ entropy shift æ£€æµ‹æ¨¡å—ï¼Œè¿›ä¸€æ­¥æå‡è¾¹ç•Œè¯†åˆ«ç²¾åº¦ã€‚
- ç»“åˆæ›´å¤šå…ˆéªŒçŸ¥è¯†ï¼ˆå¦‚å¥æ³•è§£ææ ‘ï¼‰ä¼˜åŒ– block åˆ’åˆ†ç­–ç•¥ã€‚

---

> ğŸ”š **æ€»ç»“**ï¼š  
> **Swordsman** é€šè¿‡å¼•å…¥ **entropy-driven adaptive block partitioning** å’Œ **dynamic threshold unmasking**ï¼ŒæˆåŠŸå®ç°äº† DLMs ä¸­â€œ**è¯­ä¹‰æ„ŸçŸ¥çš„é«˜æ•ˆå¹¶è¡Œè§£ç **â€ã€‚å®éªŒè¯æ˜å…¶åœ¨ä¸ä¿®æ”¹æ¨¡å‹ç»“æ„ã€æ— éœ€é¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆè´¨é‡ä¸æ¨ç†é€Ÿåº¦ï¼Œä¸ºæ‰©æ•£è¯­è¨€æ¨¡å‹çš„å®é™…åº”ç”¨æä¾›äº†å¼ºæœ‰åŠ›çš„æ”¯æŒã€‚

</details>

---

### 5. [PersoDPO: Scalable Preference Optimization for Instruction-Adherent, Persona-Grounded Dialogue via Multi-LLM Evaluation](https://arxiv.org/abs/2602.04493)

**Authors**: Saleh Afzoon, MohammadHossein Ahmadi, Usman Naseem, Amin Beheshti  
**Category**: cs.CL  
**Published**: 2026-02-05  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.04493v1  

#### Abstract
Personalization and contextual coherence are two essential components in building effective persona-grounded dialogue systems. These aspects play a crucial role in enhancing user engagement and ensuring responses are more relevant and consistent with user identity. However, recent studies indicate t...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*PersoDPO: Scalable Preference Optimization for Instruction-Adherent, Persona-Grounded Dialogue via Multi-LLM Evaluation*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰å¼€æºçš„ **Large Language Models (LLMs)** åœ¨ç”Ÿæˆå¯¹è¯å“åº”æ—¶è™½ç„¶å…·å¤‡è‰¯å¥½çš„æµç•…æ€§å’Œè‡ªç„¶æ€§ï¼Œä½†åœ¨ä»¥ä¸‹ä¸‰ä¸ªå…³é”®æ–¹é¢ä»å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼š
- **Contextual Coherence**ï¼ˆä¸Šä¸‹æ–‡è¿è´¯æ€§ï¼‰ï¼šéš¾ä»¥åœ¨å¤šè½®å¯¹è¯ä¸­ä¿æŒè¯­ä¹‰ä¸€è‡´æ€§ã€‚
- **Persona Alignment**ï¼ˆè§’è‰²ä¸€è‡´æ€§ï¼‰ï¼šæ— æ³•æœ‰æ•ˆç»“åˆç”¨æˆ·é¢„è®¾æˆ–æå–çš„è§’è‰²ç‰¹å¾ï¼ˆpersonaï¼‰è¿›è¡Œä¸ªæ€§åŒ–å›å¤ã€‚
- **Instruction Adherence**ï¼ˆæŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼‰ï¼šå¯¹è¾“å‡ºæ ¼å¼ã€é•¿åº¦ç­‰ç»“æ„åŒ–çº¦æŸçš„éµå®ˆè¾ƒå·®ï¼Œå½±å“ä¸‹æ¸¸ç³»ç»Ÿé›†æˆã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº† LLMs åœ¨è™šæ‹ŸåŠ©æ‰‹ã€å®¢æœæœºå™¨äººç­‰å®é™…åœºæ™¯ä¸­çš„éƒ¨ç½²æ•ˆæœã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **PersoDPO**ï¼Œä¸€ä¸ªå¯æ‰©å±•çš„åå¥½ä¼˜åŒ–æ¡†æ¶ï¼Œç”¨äºæå‡å¯¹è¯ç³»ç»Ÿçš„ä¸ªæ€§åŒ–ã€ä¸Šä¸‹æ–‡ä¸€è‡´æ€§å’ŒæŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰åŸºäºå¤šLLMè‡ªåŠ¨è¯„ä¼°æ„å»ºé«˜è´¨é‡åå¥½å¯¹ï¼ˆPreference Pairsï¼‰
- åˆ©ç”¨å¤šä¸ª **open-source å’Œ closed-source LLMs**ï¼ˆå¦‚ Qwen2ã€Mistralã€LLaMAã€GPTç³»åˆ—ï¼‰åœ¨åŒä¸€è¾“å…¥ä¸‹ç”Ÿæˆå“åº”ã€‚
- ä½¿ç”¨ **automatic evaluation metrics**ï¼ˆæ— éœ€äººå·¥æ ‡æ³¨ï¼‰å¯¹å“åº”è´¨é‡æ‰“åˆ†ï¼Œè‡ªåŠ¨ç”Ÿæˆâ€œchosenâ€ä¸â€œrejectedâ€å“åº”å¯¹ã€‚
- å®ç°å®Œå…¨ **annotation-free** çš„ç›‘ç£ä¿¡å·æ„å»ºï¼Œå¤§å¹…æå‡è®­ç»ƒæ•°æ®è·å–çš„å¯æ‰©å±•æ€§ä¸å¯å¤ç°æ€§ã€‚

#### ï¼ˆ2ï¼‰å¤šç»´åº¦è´¨é‡è¯„åˆ†æœºåˆ¶
ç»¼åˆå››ä¸ªæ–¹é¢çš„è¯„ä¼°ä¿¡å·æ„å»ºæ€»è´¨é‡å¾—åˆ†ï¼š
- **Metric-based Signals**ï¼š
  - `C Score`ï¼ˆConsistency Scoreï¼‰ï¼šè¡¡é‡ä¸ persona æè¿°çš„ä¸€è‡´æ€§ã€‚
  - `P Score`ï¼ˆPersona Distance Scoreï¼‰ï¼šé‡åŒ– persona ç‰¹å¾åç¦»ç¨‹åº¦ã€‚
  - `UE Score`ï¼ˆUtterance Entailment Scoreï¼‰ï¼šåˆ¤æ–­å½“å‰å“åº”æ˜¯å¦é€»è¾‘è•´å«äºä¸Šä¸‹æ–‡ã€‚
  - `Coh-UniEval`ï¼šç»¼åˆè¯„ä¼°è¿è´¯æ€§ä¸ persona å¯¹é½ã€‚
- **Instruction-based Signal**ï¼š
  - æ–°å¢ **Length-Format Compliance (LFC)** ä¿¡å·ï¼Œå¥–åŠ±ç¬¦åˆ JSON æ ¼å¼å’ŒæŒ‡å®šé•¿åº¦çš„è¾“å‡ºï¼Œå¢å¼º instructabilityã€‚

#### ï¼ˆ3ï¼‰åŠ æƒ DPO è®­ç»ƒç›®æ ‡ï¼ˆWeighted DPO Objectiveï¼‰
é‡‡ç”¨æ”¹è¿›çš„ DPO æŸå¤±å‡½æ•°ï¼Œå°†åå¥½å¼ºåº¦ç”±å¾—åˆ†å·®å€¼ $ \Delta S $ åŠ æƒï¼š
$$
\mathcal{L}_{\text{PersoDPO}} = \mathbb{E}[\sigma(\Delta S / \beta) \cdot (\log p_\theta(y_c|x) - \log p_\theta(y_r|x))]
$$
ä½¿å¾—æ¨¡å‹æ›´å…³æ³¨é«˜ç½®ä¿¡åº¦çš„åå¥½æ ·æœ¬ï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ DPOCã€æ ‡å‡† DPOï¼‰ | PersoDPO |
|------|-------------------------------|----------|
| **ç›‘ç£æ¥æº** | æ‰‹å·¥æ ‡æ³¨ / å¯å‘å¼è§„åˆ™ / å•ä¸€æ¨¡å‹åé¦ˆ | å¤šLLM + è‡ªåŠ¨è¯„ä¼° â†’ æ›´ä¸°å¯Œã€å¯é ä¿¡å· |
| **ä¼˜åŒ–ç›®æ ‡** | èšç„¦å•ä¸€ç»´åº¦ï¼ˆå¦‚ persona æˆ– coherenceï¼‰ | è”åˆä¼˜åŒ– coherenceã€personalizationã€instruction adherence |
| **å¯æ‰©å±•æ€§** | ä¾èµ–äººå·¥æ ‡æ³¨æˆ–ç‰¹å®šæ•°æ®æ”¶é›† | å®Œå…¨è‡ªåŠ¨åŒ– pipelineï¼Œé€‚åˆå¤§è§„æ¨¡éƒ¨ç½² |
| **æŒ‡ä»¤éµå¾ª** | å¿½è§†æ ¼å¼ä¸é•¿åº¦æ§åˆ¶ | æ˜¾å¼å»ºæ¨¡ LFCï¼Œæ˜¾è‘—é™ä½ failure ratio |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **FoCus Dataset**ï¼šä¸€ä¸ªç”¨äºä¸ªæ€§åŒ–å¯¹è¯ç”Ÿæˆçš„åŸºå‡†æ•°æ®é›†ï¼ŒåŒ…å«å¤šè½®å¯¹è¯å†å²ä¸è¯¦ç»†çš„ persona æ³¨é‡Šã€‚
  - ä½¿ç”¨å…¶ validation set ä¸­çš„ 1,000 æ¡è®°å½•è¿›è¡Œè¯„ä¼°ã€‚
  - prompts æ„é€ æ–¹å¼éµå¾ª PersoBench [2]ï¼Œèåˆ persona æè¿°ä¸å¯¹è¯ä¸Šä¸‹æ–‡ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®
| é¡¹ç›® | è®¾ç½®è¯´æ˜ |
|------|--------|
| **åŸºç¡€æ¨¡å‹** | Qwen2-5B-Instructï¼ˆå›  GPU å†…å­˜é™åˆ¶é€‰æ‹©è¾ƒå°è§„æ¨¡ï¼‰ |
| **å“åº”ç”Ÿæˆ** | æ¸©åº¦ä¸º 0ï¼ˆdeterministicï¼‰ï¼Œmax_tokens=110ï¼Œç¡®ä¿ä¸ golden response é•¿åº¦åŒ¹é… |
| **è¾“å‡ºæ ¼å¼** | å¼ºåˆ¶è¦æ±‚è¿”å› JSON æ ¼å¼ï¼š`{"response": "..."}` |
| **å€™é€‰æ¨¡å‹æ± ** | åŒ…æ‹¬ï¼š<br>â€¢ Open-source: Qwen2-7B, Mistral-7B, LLaMA 3.1-8B<br>â€¢ API-based: GPT-3.5-Turbo, GPT-4-Turbo, GPT-4o-Mini |
| **åå¥½å¯¹æ„é€ ** | åŸºäº score margin é‡‡æ ·ï¼Œå…±æ„å»ºçº¦ **9,000 ä¸ª preference pairs** |
| **è®­ç»ƒé…ç½®** | ä½¿ç”¨ Hugging Face çš„ TRL åº“ä¸­çš„ `ScoreWeightedDPOTrainer`<br>batch_size=4, gradient_accumulation_steps=4, warmup_steps=150 |

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡ï¼ˆå‡æ¥è‡ª PersoBench [2]ï¼‰
æ‰€æœ‰æŒ‡æ ‡å½’ä¸€åŒ–è‡³ [0,1] åŒºé—´ï¼š
| æŒ‡æ ‡ | ç±»å‹ | å«ä¹‰ |
|------|-----|------|
| **Coh-UniEval** | Coherence + Persona | ç»¼åˆè¯„ä¼°ä¸Šä¸‹æ–‡è¿è´¯æ€§ä¸ persona å¯¹é½ |
| **C Score** | Personalization | è¡¡é‡å“åº”ä¸ persona æè¿°ä¹‹é—´çš„è¯­ä¹‰ä¸€è‡´æ€§ï¼ˆè¶Šé«˜è¶Šå¥½ï¼Œè´Ÿå€¼è¡¨ç¤ºä¸ä¸€è‡´ï¼‰ |
| **UE Score** | Coherence | åŸºäº entailment åˆ¤æ–­å“åº”æ˜¯å¦åˆç†å»¶ç»­ä¸Šä¸‹æ–‡ |
| **P Score** | Personalization | è¡¡é‡ç”Ÿæˆå†…å®¹ä¸ persona ç‰¹å¾çš„è·ç¦»ï¼ˆè¶Šä½è¡¨ç¤ºåç¦»è¶Šå¤§ï¼‰ |

æ­¤å¤–è¿˜æŠ¥å‘Šï¼š
- **Failure Ratio**ï¼šæœªèƒ½æ»¡è¶³æ ¼å¼æˆ–é•¿åº¦è¦æ±‚çš„æ¯”ä¾‹
- **Response Time**ï¼šæ¨ç†å»¶è¿Ÿ
- **Training Stability**ï¼šlossã€gradient normã€reward margin å˜åŒ–è¶‹åŠ¿

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿æ¨¡å‹ | ç±»å‹ | è¯´æ˜ |
|--------|------|------|
| Qwen2-7B / Mistral-7B / LLaMA 3.1-8B | Zero-shot Baseline | ç›´æ¥åœ¨ FoCus ä¸Šæµ‹è¯•ï¼Œæœªå¾®è°ƒ |
| Qwen2-5B-DPO | Vanilla DPO Baseline | ä½¿ç”¨ä¼ ç»Ÿ DPO å¾®è°ƒï¼Œä½œä¸ºæœ¬å·¥ä½œçš„ç›´æ¥å¯¹ç…§ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰

| Model | Coh-UniEval â†‘ | C Score â†‘ | UE Score â†‘ | P Score â†‘ |
|-------|----------------|------------|-------------|------------|
| Qwen2-7B Benchmark | 0.37Â±0.48 | -0.31Â±0.84 | 0.17Â±0.48 | 0.29Â±0.30 |
| Mistral-7B Benchmark | 0.53Â±0.46 | -0.23Â±0.82 | 0.21Â±0.52 | 0.30Â±0.28 |
| LLaMA3.1-8B Benchmark | 0.55Â±0.49 | -0.22Â±0.87 | 0.17Â±0.48 | 0.33Â±0.33 |
| Qwen2-5B DPO (vanilla) | **0.98Â±0.49** | 0.06Â±0.49 | 0.21Â±0.58 | 0.29Â±0.26 |
| **Qwen2-5B PersoDPO (Ours)** | 0.70Â±0.45 | **0.18Â±0.87** | **0.30Â±0.62** | **0.44Â±0.30** |

> æ³¨ï¼šâ†‘ è¡¨ç¤ºæ•°å€¼è¶Šå¤§è¶Šå¥½

---

### ğŸ”¬ ç»“æœåˆ†æä¸å¯¹æ¯”
- **å…¨é¢è¶…è¶Šå¼€æºåŸºçº¿**ï¼šPersoDPO åœ¨ **å…¨éƒ¨å››é¡¹æŒ‡æ ‡ä¸Šå‡ä¼˜äºæ‰€æœ‰ zero-shot å¼€æºæ¨¡å‹**ï¼Œå°¤å…¶åœ¨ `C Score` å’Œ `P Score` ä¸Šè¡¨ç°çªå‡ºï¼Œè¡¨æ˜å…¶æ›´å¼ºçš„ persona å¯¹é½èƒ½åŠ›ã€‚
- **ç›¸æ¯” vanilla DPO çš„ä¼˜åŠ¿**ï¼š
  - å°½ç®¡ vanilla DPO çš„ Coh-UniEval æ›´é«˜ï¼ˆå¯èƒ½è¿‡æ‹ŸåˆæŸç±»æ¨¡å¼ï¼‰ï¼Œä½†å…¶ `C Score` å’Œ `P Score` æ˜æ˜¾ä½äº PersoDPOã€‚
  - ç‰¹åˆ«æ˜¯ `P Score` ä»…ä¸º 0.29ï¼Œç”šè‡³ä½äºéƒ¨åˆ† zero-shot æ¨¡å‹ï¼Œè¯´æ˜æ ‡å‡† DPO å¹¶æœªæœ‰æ•ˆæ•æ‰ persona è¯­ä¹‰ã€‚
- **å¹³è¡¡æ€§æ›´å¥½**ï¼šPersoDPO åœ¨ coherence ä¸ personalization ä¹‹é—´å–å¾—æ›´ä¼˜æƒè¡¡ï¼Œé¿å…ç‰‡é¢ä¼˜åŒ–æŸä¸€ç»´åº¦ã€‚

---

### ğŸ“‰ è®­ç»ƒåŠ¨æ€ä¸å·¥ä¸šç›¸å…³æŒ‡æ ‡ï¼ˆå›¾2ï¼‰
- **Loss ä¸ Gradient Norm**ï¼šè®­ç»ƒè¿‡ç¨‹ç¨³å®šï¼Œæ— å‰§çƒˆéœ‡è¡ï¼Œgrad norm è¾ƒä½ â†’ æ”¶æ•›é²æ£’ã€‚
- **Reward Accuracy > 0.98**ï¼šæ¨¡å‹èƒ½å‡†ç¡®è¯†åˆ«é«˜è´¨é‡å“åº”ã€‚
- **Failure Ratio â†“**ï¼šæ˜¾è‘—ä½äº baseline â†’ æ›´å¥½åœ°éµå®ˆ JSON æ ¼å¼ä¸é•¿åº¦é™åˆ¶ã€‚
- **Response Time â†“**ï¼šå“åº”é€Ÿåº¦æ›´å¿«ï¼Œæ›´é€‚åˆå·¥ä¸šéƒ¨ç½²ã€‚

> è¿™äº›ç»“æœéªŒè¯äº† LFC ä¿¡å·çš„æœ‰æ•ˆæ€§ï¼Œæå‡äº†æ¨¡å‹çš„ **instructability** ä¸ **deployability**ã€‚

---

### âŒ æ¶ˆèå®éªŒï¼ˆæ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºï¼Œä½†ä»è®¾è®¡å¯æ¨æ–­ï¼‰
å°½ç®¡è®ºæ–‡æœªæä¾›æ­£å¼æ¶ˆèç ”ç©¶ï¼Œä½†ä»æ–¹æ³•è®¾è®¡å¯ä»¥æ¨æµ‹ä»¥ä¸‹æ½œåœ¨å½±å“ï¼š
- è‹¥ç§»é™¤ LFC ä¿¡å· â†’ failure ratio ä¸Šå‡ï¼Œinstruction adherence ä¸‹é™ã€‚
- è‹¥ä»…ä½¿ç”¨å•ä¸€ LLM è¾“å‡º â†’ åå¥½ä¿¡å·å¤šæ ·æ€§ä¸‹é™ï¼Œæ³›åŒ–èƒ½åŠ›å‡å¼±ã€‚
- è‹¥ä¸ç”¨ metric-based weighting â†’ è®­ç»ƒå™ªå£°å¢åŠ ï¼Œæ”¶æ•›å˜æ…¢ã€‚

ä½œè€…å·²åœ¨ GitHub å…¬å¼€åŸå§‹å“åº”æ—¥å¿—ï¼ˆ[github.com/salehafzoon/PersoDPO](https://github.com/salehafzoon/PersoDPO)ï¼‰ï¼Œæ”¯æŒåç»­æ·±å…¥åˆ†æã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **å¤šLLM + è‡ªåŠ¨è¯„ä¼° æ˜¯æ„å»ºé«˜è´¨é‡åå¥½æ•°æ®çš„æœ‰æ•ˆè·¯å¾„**  
   ä¸ä¾èµ–äººå·¥æ ‡æ³¨å³å¯ç”Ÿæˆå…·æœ‰å¼ºåˆ¤åˆ«åŠ›çš„ preference pairsï¼Œå®ç° scalable alignmentã€‚

2. **è”åˆä¼˜åŒ– coherenceã€personalization ä¸ instruction adherence æ˜¯å¯è¡Œä¸”å¿…è¦çš„**  
   PersoDPO æˆåŠŸæ•´åˆå¤šç§ç›®æ ‡ï¼Œåœ¨å¤šä¸ªç»´åº¦ä¸ŠåŒæ—¶å–å¾—æå‡ã€‚

3. **æŒ‡ä»¤éµå¾ªï¼ˆinstruction adherenceï¼‰åº”è¢«æ˜¾å¼å»ºæ¨¡**  
   å¼•å…¥ LFC ä¿¡å·æ˜¾è‘—æ”¹å–„æ ¼å¼åˆè§„æ€§ä¸å“åº”æ•ˆç‡ï¼Œè¿™å¯¹çœŸå®ç³»ç»Ÿé›†æˆè‡³å…³é‡è¦ã€‚

4. **PersoDPO èƒ½éšå¼ç»§æ‰¿å¤šä¸ªé¢„è®­ç»ƒæ¨¡å‹çš„ä¼˜ç‚¹**  
   é€šè¿‡èåˆä¸åŒæ¶æ„ã€è®­ç»ƒæ•°æ®çš„ LLM è¾“å‡ºï¼Œå®ç°â€œé›†ä½“æ™ºæ…§â€çš„è¿ç§»ã€‚

---

### âš ï¸ å±€é™æ€§
1. **ä¾èµ–å¤–éƒ¨ LLM APIs**  
   å°½ç®¡è‡ªåŠ¨åŒ–ç¨‹åº¦é«˜ï¼Œä½†ä»éœ€è°ƒç”¨ GPT ç­‰é—­æºæ¨¡å‹ç”Ÿæˆåˆå§‹å“åº”ï¼Œå¸¦æ¥æˆæœ¬ä¸éšç§é¡¾è™‘ã€‚

2. **è¯„ä¼°æŒ‡æ ‡æœ¬èº«å¯èƒ½å­˜åœ¨åå·®**  
   å¦‚ C Scoreã€P Score ç­‰ automatic metrics ä»æ— æ³•å®Œå…¨æ›¿ä»£ human judgmentï¼Œç‰¹åˆ«æ˜¯åœ¨å¤æ‚æƒ…æ„Ÿæˆ–æ–‡åŒ–èƒŒæ™¯ä¸‹çš„ persona ç†è§£ã€‚

3. **æœªæ¢ç´¢æ›´å¤æ‚çš„ persona åŠ¨æ€æ¼”åŒ–æœºåˆ¶**  
   å½“å‰ persona è§†ä¸ºé™æ€æè¿°ï¼Œæœªå¤„ç†å¯¹è¯è¿‡ç¨‹ä¸­ persona çš„åŠ¨æ€æ›´æ–°æˆ–å†²çªè§£å†³ã€‚

4. **ç¼ºä¹è·¨é¢†åŸŸæ³›åŒ–å®éªŒ**  
   æ‰€æœ‰å®éªŒé›†ä¸­åœ¨ FoCus æ•°æ®é›†ï¼Œå°šä¸æ¸…æ¥šåœ¨åŒ»ç–—ã€é‡‘èç­‰å‚ç›´é¢†åŸŸçš„é€‚ç”¨æ€§ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ„å»º fully open-source pipeline**  
   æ¢ç´¢ä»…ä½¿ç”¨å¼€æº LLMs æ›¿ä»£ GPT ç³»åˆ—è¿›è¡Œ preference pair æ„é€ ã€‚

2. **å¼•å…¥ human-in-the-loop refinement**  
   åœ¨è‡ªåŠ¨è¯„ä¼°åŸºç¡€ä¸ŠåŠ å…¥å°‘é‡ human feedbackï¼Œè¿›ä¸€æ­¥æ ¡å‡†åå¥½ä¿¡å·ã€‚

3. **åŠ¨æ€ persona modeling**  
   ç»“åˆå¯¹è¯å†å²å®æ—¶æ›´æ–°ç”¨æˆ· personaï¼Œå®ç°æŒç»­ä¸ªæ€§åŒ–ã€‚

4. **æ‰©å±•è‡³å¤šæ¨¡æ€å¯¹è¯ç³»ç»Ÿ**  
   å°† PersoDPO æ€è·¯åº”ç”¨äºå›¾æ–‡ã€è¯­éŸ³ç­‰ multimodal åœºæ™¯ã€‚

5. **å¼€å‘ä¸“ç”¨ reward model æ›¿ä»£ heuristic metrics**  
   è®­ç»ƒä¸€ä¸ª end-to-end çš„ reward model æ¥ç»Ÿä¸€è¯„ä¼° coherenceã€personalization ä¸ instructabilityã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **PersoDPO æä¾›äº†ä¸€ä¸ªé«˜æ•ˆã€å¯æ‰©å±•ã€æ— éœ€äººå·¥æ ‡æ³¨çš„å¯¹è¯æ¨¡å‹å¯¹é½æ¡†æ¶ï¼Œé€šè¿‡å¤šLLMè‡ªåŠ¨è¯„ä¼°ä¸å¤šç»´åå¥½å»ºæ¨¡ï¼Œåœ¨ä¿æŒæµç•…æ€§çš„å‰æä¸‹æ˜¾è‘—å¢å¼ºäº† persona å¯¹é½ã€ä¸Šä¸‹æ–‡è¿è´¯æ€§ä¸æŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼Œå±•ç°å‡ºå¼ºå¤§çš„å®ç”¨æ½œåŠ›ã€‚**

</details>

---

### 6. [Less Finetuning, Better Retrieval: Rethinking LLM Adaptation for Biomedical Retrievers via Synthetic Data and Model Merging](https://arxiv.org/abs/2602.04731)

**Authors**: Sameh Khattab, Jean-Philippe Corbeil, Osman Alperen Kora\c{s}, Amin Dada, Julian Friedrich, Fran\c{c}ois Beaulieu, Paul Vozila, Jens Kleesiek  
**Category**: cs.CL  
**Published**: 2026-02-05  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.04731v1  

#### Abstract
Retrieval-augmented generation (RAG) has become the backbone of grounding Large Language Models (LLMs), improving knowledge updates and reducing hallucinations. Recently, LLM-based retriever models have shown state-of-the-art performance for RAG applications. However, several technical aspects remai...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**Less Finetuning, Better Retrieval: Rethinking LLM Adaptation for Biomedical Retrievers via Synthetic Data and Model Merging**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰åœ¨å°†é€šç”¨ Large Language Models (LLMs) é€‚é…ä¸ºé¢†åŸŸä¸“ç”¨ï¼ˆå°¤å…¶æ˜¯ç”Ÿç‰©åŒ»å­¦ï¼‰**dense retriever** æ—¶ï¼Œä¸»æµæ–¹æ³•ä¾èµ–å¤§è§„æ¨¡é¢„è®­ç»ƒï¼ˆpretrainingï¼‰å’Œå…¨é‡å¾®è°ƒï¼ˆfine-tuningï¼‰ï¼Œå­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- éœ€è¦å¤§é‡æ ‡æ³¨æˆ–ä¼ªæ ‡ç­¾æ•°æ®ï¼›
- å¾®è°ƒæˆæœ¬é«˜ã€æ•ˆç‡ä½ï¼›
- å¯¹å¦‚ä½•æœ‰æ•ˆåˆ©ç”¨åˆæˆæ•°æ®ã€æç¤ºä¼˜åŒ–ï¼ˆprompt optimizationï¼‰ã€æ¨¡å‹èåˆï¼ˆmodel mergingï¼‰ç­‰æŠ€æœ¯ç¼ºä¹ç³»ç»Ÿç ”ç©¶ã€‚

æœ¬æ–‡èšç„¦äºï¼š**èƒ½å¦ç”¨æ›´å°‘çš„å¾®è°ƒã€æ›´é«˜çš„æ¨¡å—åŒ–è®¾è®¡ï¼Œå®ç°æ›´å¼ºçš„ç”Ÿç‰©åŒ»å­¦æ£€ç´¢æ€§èƒ½ï¼Ÿ**

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼š**STM (Synthesize-Train-Merge)**

STM æ˜¯ä¸€ä¸ª**æ¨¡å—åŒ–æ¡†æ¶**ï¼Œé€šè¿‡ä¸‰ä¸ªå…³é”®æŠ€æœ¯æå‡ decoder-only LLMs åœ¨ç”Ÿç‰©åŒ»å­¦æ£€ç´¢ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼š

| æŠ€æœ¯ | æè¿° |
|------|------|
| **1. Synthetic Hard Negatives** | åˆ©ç”¨é¡¶çº§ LLMï¼ˆå¦‚ GPT-4ï¼‰ç”Ÿæˆâ€œè¯­ä¹‰æ— å…³ä½†è¡¨å±‚ç›¸å…³â€çš„è´Ÿæ ·æœ¬ï¼Œæ›¿ä»£ä¼ ç»Ÿæ£€ç´¢æŒ–æ˜çš„ç¡¬è´Ÿä¾‹ï¼ˆhard negativesï¼‰ï¼Œæé«˜å¯¹æ¯”å­¦ä¹ è´¨é‡ã€‚ |
| **2. Retrieval Prompt Optimization** | ä½¿ç”¨ GEPA ç­‰è‡ªåŠ¨æç¤ºå·¥ç¨‹æ–¹æ³•ä¼˜åŒ– retrieval promptsï¼Œæ˜¾è‘—å½±å“åµŒå…¥ç©ºé—´çš„è´¨é‡ã€‚é¦–æ¬¡ç³»ç»Ÿè¯„ä¼°å…¶å¯¹ retriever æ€§èƒ½çš„å½±å“ã€‚ |
| **3. Model Merging** | å°†å¤šä¸ªåœ¨ä¸åŒå­æ•°æ®é›†ä¸Šè®­ç»ƒçš„ä¸“å®¶æ¨¡å‹ï¼ˆexpertsï¼‰è¿›è¡Œå‚æ•°çº§åˆå¹¶ï¼ˆå¦‚ Linear Interpolation å’Œ Ties-mergingï¼‰ï¼Œæ— éœ€é¢å¤–è®­ç»ƒå³å¯è·å¾—ç»Ÿä¸€é«˜æ€§èƒ½æ¨¡å‹ã€‚ |

> ğŸ” **æ ¸å¿ƒæ€æƒ³**ï¼šä¸å…¶åœ¨ä¸€ä¸ªå¤§æ··åˆæ•°æ®é›†ä¸Šå…¨é‡å¾®è°ƒï¼Œä¸å¦‚åˆ†åˆ«è®­ç»ƒå¤šä¸ªä¸“ä¸šåŒ–â€œä¸“å®¶â€ï¼Œå†æ™ºèƒ½åœ°åˆå¹¶å®ƒä»¬ã€‚

---

### âš–ï¸ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | STM çš„ä¼˜åŠ¿ |
|------|-----------|
| **æ•°æ®æ•ˆç‡** | ä»…ä½¿ç”¨ **1.4M è®­ç»ƒå¯¹**ï¼ˆç›¸æ¯” BMRetriever çš„ 11.4M å‡å°‘äº† 88%ï¼‰ï¼Œä¸”æ— éœ€ pretrainingã€‚ |
| **è®­ç»ƒæ•ˆç‡** | é‡‡ç”¨ LoRA å¾®è°ƒ + æ¨¡å‹åˆå¹¶ï¼Œé¿å…é‡å¤è®­ç»ƒå®Œæ•´æ¨¡å‹ã€‚ |
| **æ€§èƒ½æ›´å¼º** | åˆå¹¶åçš„æ¨¡å‹ **å…¨é¢è¶…è¶Šå•ä¸ªä¸“å®¶å’Œå¼ºåŸºçº¿**ï¼ˆå¦‚ BMRetrieverã€LLM2Vecï¼‰ã€‚ |
| **æ¨¡å—åŒ–ä¸å¯æ‰©å±•æ€§** | æ”¯æŒçµæ´»ç»„åˆä¸åŒä¸“å®¶ï¼ˆåŒ»ç–—/é€šç”¨/NLU/Searchï¼‰ï¼Œä¾¿äºè¿­ä»£å¼€å‘ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†

#### ä¸»è¦æ¥æºï¼š
- **BMRetriever fine-tuning dataset** è¢«åˆ’åˆ†ä¸ºå››ä¸ªå­é›†ï¼ˆå…±çº¦ 1.4M å¯¹ï¼‰ï¼š

| å­é›† | å†…å®¹è¯´æ˜ |
|------|--------|
| **Med-Synth** (431K) | LLM ç”Ÿæˆçš„ç”Ÿç‰©åŒ»å­¦æ£€ç´¢å¯¹ |
| **Med-Real** (306K) | çœŸå®åŒ»å­¦æ¨ç†ä¸é—®ç­”æ•°æ®ï¼ˆMedNLI, MEDIQA, åŒ»ç–—å¯¹è¯ç­‰ï¼‰ |
| **Search** (438K) | MS MARCO ç­‰é€šç”¨æœç´¢ä»»åŠ¡ |
| **NLU** (251K) | è‡ªç„¶è¯­è¨€ç†è§£ä»»åŠ¡ï¼ˆSNLI, FEVER, ELI5 ç­‰ï¼‰ |

#### è¯„ä¼°åŸºå‡†ï¼š
- **Medical MTEB è‹±æ–‡å­é›†**ï¼ˆ12 ä¸ªä»»åŠ¡ï¼‰ï¼š
  - åŒ»ç–—ç±»ï¼šTREC-COVID, SciFact, NFCorpus, Cure, PublicHealthQA, MedicalQA
  - é€šç”¨ç±»ï¼šFiQA, ArguAna, SciDocs, FEVER, Quoraï¼ˆNanoMTEB å­é›†ï¼‰
- å¼€å‘é›†ç”¨äºæ¨¡å‹é€‰æ‹©ï¼šBEIR å­é›†ï¼ˆNFCorpus, FiQA-2018, Quora, DBPediaï¼‰

---

### ğŸ›  å®éªŒè®¾ç½®

| ç»„ä»¶ | è®¾ç½®è¯¦æƒ… |
|------|---------|
| **Backbone Models** | Qwen3 (0.6B), Gemma (2B), Phi4 (3.8B) â€”â€” å…¨éƒ¨ä¸º decoder-only æ¶æ„ |
| **å¾®è°ƒæ–¹å¼** | LoRAï¼ˆRank=16, Î±=32ï¼‰ï¼Œåº”ç”¨äºæ‰€æœ‰çº¿æ€§å±‚ |
| **æ³¨æ„åŠ›æ©ç ** | å¾®è°ƒæ—¶ç¦ç”¨ causal mask â†’ å®ç° bidirectional attention |
| **æ± åŒ–ç­–ç•¥** | ä½¿ç”¨ EOS token poolingï¼ˆä¼˜äºå¹³å‡æ± åŒ–ï¼‰ |
| **æŸå¤±å‡½æ•°** | InfoNCE lossï¼Œç»“åˆ in-batch negatives ä¸ synthetic hard negatives |
| **è®­ç»ƒé…ç½®** | å•è½®è®­ç»ƒï¼Œbf16ï¼ŒAdamW + Linear Warmupï¼ˆ100 æ­¥ï¼‰ |

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡

- **ä¸»æŒ‡æ ‡**ï¼š**nDCG@10**ï¼ˆNormalized Discounted Cumulative Gainï¼‰
- æŠ¥å‘Šä¸‰ç§å¹³å‡å¾—åˆ†ï¼š
  - Avg Medicalï¼ˆåŒ»ç–—ä»»åŠ¡ï¼‰
  - Avg Generalï¼ˆé€šç”¨ä»»åŠ¡ï¼‰
  - Avg Allï¼ˆå…¨éƒ¨ 12 é¡¹ä»»åŠ¡ï¼‰

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”

| åŸºçº¿æ¨¡å‹ | ç±»å‹ | å‚æ•°è§„æ¨¡ |
|--------|------|----------|
| BM25 | Lexical Retriever | - |
| Contriever | Dense Retriever | 150M |
| E5-v2 | LLM-based Retriever | 335M |
| GTR-T5-XL | Encoder-based | 1.2B |
| BMRetriever | Biomedical Retriever | 2B |
| LLM2Vec | Multi-task Contrastive | 3B |

> æ‰€æœ‰ STM æ¨¡å‹å‡ä¸åŒçº§åˆ« backbone æˆ–ç›¸è¿‘è§„æ¨¡çš„åŸºçº¿æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 7 & Table 11ï¼‰

| Model | Size | Avg Med | Avg Gen | **Avg All** |
|-------|------|--------|--------|------------|
| BM25 | - | 0.532 | 0.515 | 0.525 |
| E5 Large V2 | 335M | 0.654 | 0.576 | 0.622 |
| BMRetriever | 2B | 0.645 | 0.560 | 0.609 |
| LLM2Vec | 3B | 0.635 | 0.597 | 0.619 |
| **STM-Qwen3** | 0.6B | 0.638 | 0.585 | **0.616** |
| **STM-Gemma** | 2B | 0.654 | 0.577 | **0.622** |
| **STM-Phi4** | 3.8B | **0.677** | **0.603** | **0.646** |

âœ… **STM-Phi4-Linear** è¾¾åˆ° **SOTA æ€§èƒ½**ï¼Œåœ¨æ‰€æœ‰ç±»åˆ«ä¸­æ’åç¬¬ä¸€ã€‚

---

### ğŸ” ä¸åŸºçº¿å¯¹æ¯”äº®ç‚¹

- **STM-Gemma** è™½ä¸ BMRetriever åŒæº backboneï¼ˆGemmaï¼‰ï¼Œä½†æœªç»è¿‡ pretrainingï¼Œä»ä»¥ **0.622 > 0.609** è¶…è¶Šåè€…ã€‚
- **STM-Qwen3 (0.6B)** æ€§èƒ½æ¥è¿‘ç”šè‡³è¶…è¿‡æ›´å¤§æ¨¡å‹ï¼ˆå¦‚ LLM2Vec 3Bï¼‰ã€‚
- æ‰€æœ‰ STM åˆå¹¶æ¨¡å‹å‡ä¼˜äºå„è‡ªå¯¹åº”çš„ **full fine-tuned model (FT-all)**ã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰Prompt Optimization æ•ˆæœæ˜¾è‘—ï¼ˆTable 5ï¼‰

| æ–¹æ³• | ç›¸å¯¹æå‡ï¼ˆæœ€é«˜ï¼‰ |
|------|----------------|
| Random Generic Prompts (10~100) | +3% ~ +5% |
| **GEPA-optimized prompts** | **+5% ~ +7% å¹³å‡å¢ç›Š** |

> ç‰¹åˆ«æ˜¯åœ¨éåŒ»ç–—ä¸“å®¶ï¼ˆSearch/NLUï¼‰ä¸Šæå‡æ˜æ˜¾ï¼š
- **Phi4 Search Expert**ï¼š+23.5% æå‡ï¼
- **Gemma NLU Expert**ï¼š+17.9%

> ğŸ’¡ å‘ç°ï¼š**Prompt Optimization æ¯” Synthetic Hard Negatives æ›´ç¨³å®šæœ‰æ•ˆã€‚**

#### ï¼ˆ2ï¼‰Synthetic Hard Negativesï¼ˆSHNï¼‰æ•ˆæœæœ‰é™

- åœ¨éƒ¨åˆ†åœºæ™¯ä¸‹ï¼ˆå°æ¨¡å‹ + éåŒ»ç–—ä»»åŠ¡ï¼‰æœ‰å¸®åŠ©ï¼›
- ä½†åœ¨å¤§æ¨¡å‹æˆ–é«˜è´¨é‡çœŸå®åŒ»å­¦æ•°æ®ä¸Šï¼ˆå¦‚ Med-Realï¼‰ï¼Œåè€Œå¯èƒ½**é™ä½æ€§èƒ½**ï¼›
- ä¸ Prompt Optimization ç»“åˆåæ— å åŠ æ•ˆåº”ï¼Œç”šè‡³å‡ºç°å¹²æ‰°ã€‚

> â— ç»“è®ºï¼š**SHN å¹¶éæ€»æ˜¯æœ‰ç›Šï¼Œéœ€è°¨æ…ä½¿ç”¨ã€‚**

#### ï¼ˆ3ï¼‰Model Merging æ˜¾è‘—ä¼˜äºå•ä¸€ä¸“å®¶å’Œè”åˆå¾®è°ƒï¼ˆFigure 2 & Table 6ï¼‰

| åˆå¹¶æ–¹å¼ | è¡¨ç° |
|--------|------|
| **Linear Interpolation** | æœ€ä½³æ€§èƒ½ï¼Œè½»å¾®ä½†ä¸€è‡´ä¼˜äº Ties-merging |
| **Ties-merging** | ä¹Ÿä¼˜äºå•ç‹¬ä¸“å®¶ï¼Œä½†ç•¥é€Šäºçº¿æ€§æ’å€¼ |
| **Merged vs FT-all** | STM åˆå¹¶æ¨¡å‹ > åˆ†åˆ«åœ¨å…¨æ•°æ®ä¸Šå¾®è°ƒçš„æ¨¡å‹ |

> âœ… ä¾‹å¦‚ï¼šSTM-Phi4-Linear è¾¾åˆ° 0.646ï¼Œè€Œ FT-all ä»…ä¸º 0.621ã€‚

#### ï¼ˆ4ï¼‰æ•°æ®é‡æ•æ„Ÿæ€§åˆ†æï¼ˆFigure 4ï¼‰

- æ¨¡å‹æ€§èƒ½åœ¨ **100K æ ·æœ¬å·¦å³å³è¶‹äºé¥±å’Œ**ï¼›
- ä½¿ç”¨ **1.4M å…¨é‡æ•°æ®å¹¶æœªå¸¦æ¥è¿›ä¸€æ­¥æå‡**ï¼›
- è¡¨æ˜ï¼š**é«˜è´¨é‡ç²¾é€‰æ•°æ® > å¤§è§„æ¨¡ç²—ç²’åº¦æ•°æ®**ã€‚

#### ï¼ˆ5ï¼‰Merging Coefficients åˆ†æï¼ˆFigure 5ï¼‰

- æœ€ä¼˜åˆå¹¶æƒé‡é€šå¸¸æ’é™¤ä¸€ä¸ªä¸“å®¶ï¼ˆå¦‚ Qwen3 å’Œ Phi4 å®Œå…¨ä¸ç”¨ Search ä¸“å®¶ï¼‰ï¼›
- åŒ»ç–—å’Œ NLU ä¸“å®¶æƒé‡æ›´é«˜ï¼›
- è¡¨æ˜ï¼š**å¹¶éæ‰€æœ‰ä¸“å®¶éƒ½åŒç­‰é‡è¦ï¼Œæ¨¡å‹åˆå¹¶å…·å¤‡è‡ªåŠ¨ç­›é€‰èƒ½åŠ›**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **â€œå°‘å³æ˜¯å¤šâ€**ï¼š  
   æ— éœ€å¤§è§„æ¨¡ pretraining å’Œ full fine-tuningï¼ŒSTM ä»…ç”¨ **1.4M æ•°æ® + LoRA å¾®è°ƒ + æ¨¡å‹åˆå¹¶**ï¼Œå³å¯è¾¾åˆ°ç”šè‡³è¶…è¶Š SOTAã€‚

2. **Prompt Optimization æ˜¯æœ€æœ‰æ•ˆçš„å•ä¸€æ”¹è¿›æ‰‹æ®µ**ï¼š  
   è‡ªåŠ¨ä¼˜åŒ– retrieval prompts å¯å¸¦æ¥é«˜è¾¾ **23.5% çš„ç›¸å¯¹æå‡**ï¼Œå°¤å…¶é€‚ç”¨äºé€šç”¨åŸŸä»»åŠ¡ã€‚

3. **Model Merging å¼ºäºè”åˆå¾®è°ƒ**ï¼š  
   åˆå¹¶å¤šä¸ªä¸“å®¶æ¨¡å‹çš„æ•ˆæœ **ä¼˜äºç›´æ¥åœ¨æ··åˆæ•°æ®ä¸Šå¾®è°ƒåŒä¸€ä¸ªæ¨¡å‹**ï¼ŒéªŒè¯äº†æ¨¡å—åŒ–å¼€å‘è·¯å¾„çš„æœ‰æ•ˆæ€§ã€‚

4. **Synthetic Hard Negatives æ•ˆæœä¸ç¨³å®š**ï¼š  
   è™½ç„¶èƒ½æå‡æŸäº›ä»»åŠ¡ï¼Œä½†åœ¨é«˜è´¨é‡åŒ»å­¦æ•°æ®ä¸Šå¯èƒ½æ— æ•ˆç”šè‡³æœ‰å®³ï¼Œä¸èƒ½ç›²ç›®ä½¿ç”¨ã€‚

5. **æ•°æ®è´¨é‡ > æ•°æ®æ•°é‡**ï¼š  
   å®éªŒè¡¨æ˜ï¼Œ**100K é«˜è´¨é‡æ•°æ®è¶³ä»¥é¥±å’Œæ€§èƒ½**ï¼Œè¿œè¶…ä½¿ç”¨æ›´å¤§æ•°æ®é›†çš„è¡¨ç°ã€‚

---

### âš ï¸ å±€é™æ€§

1. **ä»…æµ‹è¯•ä¸¤ç§ merging æ–¹æ³•**ï¼šåªç”¨äº† Linear å’Œ Ties-mergingï¼Œæœªæ¢ç´¢æ›´å¤æ‚çš„ adaptive merging ç­–ç•¥ã€‚
2. **ä¾èµ–å¤§æ¨¡å‹ç”Ÿæˆåˆæˆæ•°æ®**ï¼šä½¿ç”¨ GPT-4 å’Œ LLaMA-70B è¿›è¡Œ prompt ä¼˜åŒ–å’Œ hard negative ç”Ÿæˆï¼Œè®¡ç®—å¼€é”€å¤§ï¼Œä¸”ç»“æœå¯èƒ½å— generator å½±å“ã€‚
3. **æœªè·¨ generator éªŒè¯é²æ£’æ€§**ï¼šæœªæµ‹è¯•ä¸åŒ LLMï¼ˆå¦‚ Claude vs GPTï¼‰ç”Ÿæˆ prompt æˆ– negatives çš„å·®å¼‚ã€‚
4. **æœªå¼€æ”¾æ¨¡å‹æƒé‡**ï¼šæ–‡ä¸­å£°æ˜ä»£ç ã€æ•°æ®ã€æ¨¡å‹å°†åœ¨æ¥å—åå‘å¸ƒï¼Œç›®å‰å°šæœªå…¬å¼€ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. æ¢ç´¢æ›´é«˜æ•ˆçš„ **è½»é‡çº§ prompt generator** æ›¿ä»£å¤§å‹ LLMï¼›
2. è®¾è®¡ **task-aware merging ç­–ç•¥**ï¼ŒåŠ¨æ€è°ƒæ•´ä¸“å®¶æƒé‡ï¼›
3. å°† STM æ¡†æ¶æ¨å¹¿è‡³ **å¤šè¯­è¨€ã€å¤šæ¨¡æ€æ£€ç´¢ä»»åŠ¡**ï¼›
4. ç ”ç©¶ **åˆæˆæ•°æ®çš„è´¨é‡æ§åˆ¶æœºåˆ¶**ï¼Œå‡å°‘è™šå‡æˆ–è¯¯å¯¼æ€§ negativesï¼›
5. æ¢ç´¢ **å®Œå…¨å…å¾®è°ƒï¼ˆzero-shot mergingï¼‰çš„å¯èƒ½æ€§**ã€‚

---

## âœ… æ€»ç»“ä¸€å¥è¯

> **STM æ¡†æ¶è¯æ˜ï¼šé€šè¿‡â€œåˆæˆæ•°æ®å¢å¼º + æç¤ºä¼˜åŒ– + æ¨¡å‹åˆå¹¶â€çš„æ¨¡å—åŒ–è·¯å¾„ï¼Œå¯ä»¥ç”¨æ›´å°‘çš„æ•°æ®å’Œæ›´ä½çš„æˆæœ¬ï¼Œæ„å»ºå‡ºæ€§èƒ½æ›´å¼ºã€æ³›åŒ–æ›´å¥½çš„ç”Ÿç‰©åŒ»å­¦æ£€ç´¢å™¨ï¼ŒæŒ‘æˆ˜äº†ä¼ ç»Ÿâ€œå¤§è§„æ¨¡é¢„è®­ç»ƒ+å…¨é‡å¾®è°ƒâ€çš„èŒƒå¼ã€‚**

</details>

---

### 7. [CoRe: Context-Robust Remasking for Diffusion Language Models](https://arxiv.org/abs/2602.04096)

**Authors**: Kevin Zhai, Sabbir Mollah, Zhenyi Wang, Mubarak Shah  
**Category**: cs.LG  
**Published**: 2026-02-05  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.04096v1  

#### Abstract
Standard decoding in Masked Diffusion Models (MDMs) is hindered by context rigidity: tokens are retained based on transient high confidence, often ignoring that early predictions lack full context. This creates cascade effects where initial inconsistencies misguide the remaining generation. Existing...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**CoRE: Context-Robust Remasking for Diffusion Language Models**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
åœ¨ **Masked Diffusion Models (MDMs)** ä¸­ï¼Œæ ‡å‡†è§£ç è¿‡ç¨‹å­˜åœ¨â€œ**context rigidity**â€ï¼ˆä¸Šä¸‹æ–‡åˆšæ€§ï¼‰é—®é¢˜ï¼š
- æ—©æœŸç”Ÿæˆçš„ token è¢«åŸºäºä¸å®Œæ•´ä¸Šä¸‹æ–‡åšå‡ºé«˜ç½®ä¿¡åº¦é¢„æµ‹ï¼Œå¹¶è¢«æ°¸ä¹…ä¿ç•™ã€‚
- è¿™äº›åˆå§‹é”™è¯¯ä¼šè¯¯å¯¼åç»­ç”Ÿæˆï¼Œå½¢æˆçº§è”è¯¯å·®ï¼Œå°¤å…¶åœ¨ç»“æ„æ•æ„Ÿä»»åŠ¡ï¼ˆå¦‚ä»£ç ç”Ÿæˆï¼‰ä¸­å½±å“ä¸¥é‡ã€‚

ç°æœ‰åŸºäºé™æ€ç½®ä¿¡åº¦ï¼ˆå¦‚ä½ confidence æˆ– top-k marginï¼‰çš„ **remasking** æ–¹æ³•æ•ˆæœæœ‰é™ï¼Œå› ä¸ºè¿™äº›ä¿¡å·æ˜¯â€œçŸ­è§†â€çš„ï¼š
- é«˜ç½®ä¿¡åº¦ token å¯èƒ½åœ¨åæœŸä¸Šä¸‹æ–‡æ¼”åŒ–åå˜å¾—ä¸ä¸€è‡´ï¼Œä½†ä¸ä¼šè¢«é‡æ–°ä¿®è®¢ã€‚
- å› æ­¤ï¼Œä¼ ç»Ÿæ–¹æ³•æ— æ³•è¯†åˆ«â€œ**context-brittle tokens**â€ï¼ˆä¸Šä¸‹æ–‡è„†å¼± tokenï¼‰ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼š**Context-Robust Remasking (CoRE)**

CoRE æ˜¯ä¸€ç§**æ— éœ€è®­ç»ƒ**ï¼ˆtraining-freeï¼‰ã€åœ¨æ¨ç†é˜¶æ®µè¿›è¡Œä¿®è®¢çš„æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> **å°† token çš„å¯é æ€§å®šä¹‰ä¸ºå¯¹ä¸Šä¸‹æ–‡æ‰°åŠ¨çš„é²æ£’æ€§ï¼Œè€Œéé™æ€ä¸ç¡®å®šæ€§ã€‚**

#### åˆ›æ–°æœºåˆ¶ï¼š
1. **åŠ¨æ€å‹åŠ›æµ‹è¯•ï¼ˆStress Testï¼‰**  
   å¯¹å½“å‰å·²è§£ç çš„ token å­é›†ï¼Œé€šè¿‡å°†å…¶å‘¨å›´ä¸Šä¸‹æ–‡éƒ¨åˆ†é®è”½ï¼ˆmaskingï¼‰ï¼Œæ¨¡æ‹Ÿä¸Šä¸‹æ–‡å˜åŒ–ã€‚
   
2. **Instability Scoreï¼ˆä¸ç¨³å®šæ€§å¾—åˆ†ï¼‰**  
   è¡¡é‡ä¸€ä¸ª token åœ¨æ‰°åŠ¨åçš„ä¸Šä¸‹æ–‡ä¸­æ˜¯å¦ä»è¢«å¼ºçƒˆé¢„æµ‹ï¼š
   $$
   l_i = -\log p_\theta(y_i | \tilde{y}^{(t)})
   $$
   å¾—åˆ†è¶Šé«˜ï¼Œè¯´æ˜è¯¥ token è¶Šâ€œè„†å¼±â€ï¼Œåº”ä¼˜å…ˆé‡é‡‡æ ·ã€‚

3. **åŒé˜¶æ®µé€‰æ‹©ç­–ç•¥**  
   - å…ˆç”¨ **top-2 margin** å¿«é€Ÿç­›é€‰å€™é€‰é›†ï¼ˆé«˜æ•ˆè¿‘ä¼¼ï¼‰
   - å†é€šè¿‡ä¸€æ¬¡å‰å‘ä¼ æ’­è®¡ç®—æ‰€æœ‰å€™é€‰ token çš„ instability score
   - æœ€ç»ˆé€‰æ‹©æœ€ä¸ç¨³å®šçš„ $k_{\text{rm}}$ ä¸ª token è¿›è¡Œä¿®è®¢

4. **ç†è®ºæ”¯æ’‘**  
   å°†ä¿®è®¢é—®é¢˜å½¢å¼åŒ–ä¸º **distributionally robust optimization** é—®é¢˜ï¼Œinstability score æ˜¯ worst-caseé£é™©çš„æœ‰æ•ˆä¸‹ç•Œã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç‰¹æ€§ | CoRE | ReMDM / Confidence-based |
|------|------|--------------------------|
| æ˜¯å¦ä¾èµ–å†å²ç½®ä¿¡åº¦ | âŒ å¦ï¼ˆä½¿ç”¨å½“å‰ä¸Šä¸‹æ–‡ï¼‰ | âœ… æ˜¯ï¼ˆstale confidenceï¼‰ |
| æ˜¯å¦æ„ŸçŸ¥ä¸Šä¸‹æ–‡æ¼”åŒ– | âœ… æ˜¯ | âŒ å¦ |
| æ˜¯å¦éœ€è¦é¢å¤–è®­ç»ƒ | âœ… å¦ï¼ˆplug-and-playï¼‰ | âŒ éƒ¨åˆ†æ–¹æ³•éœ€è®­ç»ƒ |
| è®¡ç®—å¼€é”€ | æå°ï¼ˆä»…å¢åŠ çº¦ 6% NFEï¼‰ | ç±»ä¼¼æˆ–æ›´é«˜ |
| åœ¨ç»“æ„æ•æ„Ÿä»»åŠ¡ä¸Šçš„è¡¨ç° | â¬†ï¸ æ˜¾è‘—æå‡ | â¬‡ï¸ å¯èƒ½é€€åŒ– |

> âœ… **å…³é”®ä¼˜åŠ¿**ï¼šCoRE ä¸»åŠ¨æ£€æµ‹å¹¶ä¿®æ­£é‚£äº›â€œçœ‹ä¼¼åˆç†ä½†å®é™…ä¾èµ–é”™è¯¯ä¸Šä¸‹æ–‡é”šå®šâ€çš„ tokenï¼Œæ‰“ç ´ context rigidityã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
åœ¨å¤šä¸ªå…·æœ‰ä¸åŒç»“æ„çº¦æŸå¼ºåº¦çš„ä»»åŠ¡ä¸Šè¯„ä¼°ï¼š

| ä»»åŠ¡ç±»å‹ | æ•°æ®é›† | è¯„ä¼°æ–¹å¼ |
|--------|-------|---------|
| æ•°å­¦æ¨ç† | **GSM8K**, **MATH** | Strict-match accuracy, rule-based equivalence |
| å¤šæ­¥æ¨ç† | **BIG-Bench Hard (BBH)** | Exact match |
| ä»£ç ç”Ÿæˆ | **HumanEval**, **MBPP** | Greedy pass@1 accuracy |

> æ‰€æœ‰å®éªŒå‡åœ¨ **LLaDA-8B-Base** æ¨¡å‹ä¸Šè¿›è¡Œï¼Œé¿å…æŒ‡ä»¤å¾®è°ƒå¸¦æ¥çš„åå·®ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®

| å‚æ•° | è®¾ç½® |
|------|------|
| Diffusion Steps $N$ | 128 |
| Generation Length $L$ | 512 |
| Decoding | Greedy decodingï¼ˆæ§åˆ¶å˜é‡ï¼‰ |
| Revision Window | $t/N \in [0.25, 0.75]$ï¼ˆä¸­é—´é˜¶æ®µï¼‰ |
| Revision Interval $E$ | æ¯ 8 æ­¥æ‰§è¡Œä¸€æ¬¡ |
| Candidate Set Size $m$ | 32 |
| Remasking Limit $k_{\text{rm}}$ | 1ï¼ˆæ¯æ¬¡æœ€å¤šä¿®è®¢ 1 ä¸ª tokenï¼‰ |
| é¢å¤–å¼€é”€ | æ¯æ¬¡ revision å¢åŠ  1 æ¬¡ NFEï¼ˆNetwork Function Evaluationï¼‰ |

> æ€»ä½“ä»…å¢åŠ çº¦ **6%** çš„æ¨ç†æˆæœ¬ï¼ˆ128 + 8 = 136 NFEï¼‰ã€‚

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”

| åŸºçº¿ | æè¿° |
|------|------|
| **Low-Confidence Base** | LLaDA é»˜è®¤ç­–ç•¥ï¼šä¼˜å…ˆ unmask ä½ç½®ä¿¡åº¦ token |
| **Top-k Margin Base** | è‡ªé€‚åº”ç­–ç•¥ï¼šåŸºäº top-2 margin é€‰æ‹© unmask ä½ç½® |
| **+ ReMDM-conf** | å½“å‰æœ€ä¼˜çš„ training-free revision æ–¹æ³•ï¼ŒåŸºäºå†å² confidence é€‰æ‹©ä¿®è®¢ç›®æ ‡ |
| **+ Random Remask** | æ§åˆ¶å®éªŒï¼šéšæœºé€‰æ‹©ä¿®è®¢ç›®æ ‡ |
| **+ Margin Remask** | æ§åˆ¶å®éªŒï¼šé€‰æ‹© margin æœ€å°çš„ token ä¿®è®¢ |

> æ‰€æœ‰æ–¹æ³•åœ¨ç›¸åŒ compute budget ä¸‹æ¯”è¾ƒï¼ˆå¦‚ 136 NFEï¼‰ï¼Œç¡®ä¿å…¬å¹³ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| æ–¹æ³• | GSM8K (%) | BBH (%) | HumanEval (%) | MBPP (%) |
|------|-----------|--------|----------------|----------|
| Low-Confidence Base | 51.40 | 45.81 | 12.20 | 15.60 |
| + ReMDM-conf | 52.31 | 46.05 | 10.98 | **15.20** â¬‡ï¸ |
| **+ CoRE (Ours)** | **52.69** | **47.18*** | **17.07*** | **24.80*** |
| Top-k Margin Base | 50.27 | 48.33 | 17.07 | 21.20 |
| + ReMDM-conf | 51.78 | 46.31 | 14.02 | **14.80** â¬‡ï¸ |
| **+ CoRE (Ours)** | 51.40 | **49.01*** | **22.56*** | **29.60*** |

> âœ… **æœ€å¤§æå‡ï¼š+9.2% on MBPP**ï¼ˆä» 21.20 â†’ 29.60ï¼‰

---

### ğŸ” ä¸åŸºçº¿æ–¹æ³•çš„å…³é”®å¯¹æ¯”

- **ReMDM-conf åœ¨ä»£ç ä»»åŠ¡ä¸Šæ˜¾è‘—é€€åŒ–**ï¼ˆMBPP â†“6.4%ï¼‰ï¼Œå› å…¶ä¾èµ– stale confidenceï¼Œæ— æ³•è¯†åˆ«åæœŸä¸ä¸€è‡´çš„é«˜ç½®ä¿¡ tokenã€‚
- **CoRE åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šç¨³å®šæå‡**ï¼Œå°¤å…¶åœ¨ç»“æ„å¼ºçº¦æŸä»»åŠ¡ï¼ˆMBPPã€HumanEvalï¼‰ä¸Šå¢ç›Šæœ€å¤§ã€‚
- åœ¨è¯­ä¹‰çµæ´»ä»»åŠ¡ï¼ˆGSM8Kï¼‰ä¸Šä¹Ÿæœ‰è½»å¾®æå‡ï¼Œè¡¨æ˜å…¶é€šç”¨æ€§ã€‚

---

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœï¼ˆTable 2 & Table 3ï¼‰

#### â–¶ï¸ æ§åˆ¶å˜é‡ï¼šç›¸åŒè®¡ç®—é¢„ç®—ä¸‹çš„æ¯”è¾ƒï¼ˆTable 2ï¼‰

| æ–¹æ³• | MBPP (%) |
|------|--------|
| Low-Confidence Base | 15.60 |
| + Random Remask | 16.60 |
| + Margin Remask | 17.40 |
| **+ CoRE** | **24.80** |

> âœ… **ç»“è®º**ï¼šæ€§èƒ½æå‡ä¸»è¦æ¥è‡ª instability score çš„é«˜è´¨é‡é€‰æ‹©ä¿¡å·ï¼Œè€Œéå•çº¯â€œå¤šä¸€æ¬¡ä¿®è®¢â€ã€‚

#### â–¶ï¸ æ›´é«˜è®¡ç®—é¢„ç®—ä¸‹çš„æ¯”è¾ƒï¼ˆTable 3ï¼Œ136 NFEï¼‰

| æ–¹æ³• | MBPP (%) |
|------|--------|
| Low-Confidence Base (136) | 15.40 |
| ReMDM-conf (136) | 14.00 â¬‡ï¸ |
| **CoRE (128+8)** | **24.80** |

> âœ… **ç»“è®º**ï¼šå³ä½¿ç»™ baseline æ›´å¤šæ­¥éª¤ï¼Œä¹Ÿæ— æ³•è¾¾åˆ° CoRE çš„æ€§èƒ½ï¼›ç›²ç›®æ‰©å±•æ­¥æ•°ç”šè‡³æœ‰å®³ã€‚

---

### ğŸ“ˆ è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼ˆFigure 2 & Table 4ï¼‰

- **æœ€ä½³é…ç½®**ï¼š`m=32`, `E=8`
- è‹¥ `m=64`ï¼ˆå€™é€‰é›†è¿‡å¤§ï¼‰ï¼Œæ€§èƒ½ä¸‹é™ â†’ æ©ç›–è¿‡å¤šä¸Šä¸‹æ–‡å¯¼è‡´è¯¯åˆ¤ï¼ˆfalse positivesï¼‰
- è‹¥ `E=4`ï¼ˆä¿®è®¢å¤ªé¢‘ç¹ï¼‰ï¼Œæ”¶ç›Šä»… +0.6%ï¼Œä½†å¼€é”€ç¿»å€ â†’ ä¸åˆ’ç®—

> âœ… **ç»“è®º**ï¼šé€‚åº¦çš„å€™é€‰è§„æ¨¡å’Œä¿®è®¢é¢‘ç‡å³å¯è·å¾—æœ€ä¼˜æ€§ä»·æ¯”ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **Context rigidity æ˜¯ MDMs çš„æ ¹æœ¬ç“¶é¢ˆ**  
   æ—©æœŸå†³ç­–ä¸€æ—¦å›ºåŒ–ï¼Œéš¾ä»¥çº æ­£ï¼Œå¯¼è‡´ç»“æ„é”™è¯¯æŒç»­ä¼ æ’­ã€‚

2. **Static confidence æ˜¯ä¸å¯é çš„ä¿®è®¢ä¿¡å·**  
   é«˜ç½®ä¿¡åº¦ â‰  æ­£ç¡®æ€§ï¼Œå°¤å…¶åœ¨ä¸Šä¸‹æ–‡æ¼”åŒ–åã€‚

3. **Robustness to perturbation æ˜¯æ›´å¥½çš„ä¿®è®¢ä¾æ®**  
   CoRE é€šè¿‡æ‰°åŠ¨ä¸Šä¸‹æ–‡æš´éœ²è„†å¼± tokenï¼Œå®ç°ç²¾å‡†ä¿®å¤ã€‚

4. **æœ€å°ä»£ä»·æ¢å–æœ€å¤§æ”¶ç›Š**  
   ä»…å¢åŠ  ~6% è®¡ç®—é‡ï¼Œå³å¯åœ¨ä»£ç ä»»åŠ¡ä¸Šå¸¦æ¥ **+9.2%** çš„ç»å¯¹æå‡ã€‚

5. **Instability Score æ˜¯æœ‰æ•ˆçš„ä»£ç†æŒ‡æ ‡**  
   å®éªŒè¯æ˜å…¶èƒ½æ¸…æ™°åŒºåˆ†ç¨³å®šä¸è„†å¼± tokenï¼ˆè§ Figure 3 çš„é•¿å°¾åˆ†å¸ƒï¼‰ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

1. **ä¾èµ–å±€éƒ¨ä¸Šä¸‹æ–‡æ‰°åŠ¨**  
   å½“å‰ä»…é€šè¿‡ masking å‘¨å›´ token æ¥æ¨¡æ‹Ÿå˜åŒ–ï¼Œæœªè€ƒè™‘æ›´å¤æ‚çš„è¯­ä¹‰æ‰°åŠ¨ã€‚

2. **æœªè§£å†³å¤–éƒ¨äº‹å®ä¸€è‡´æ€§**  
   CoRE æ”¹å–„çš„æ˜¯å†…éƒ¨ç»“æ„ä¸€è‡´æ€§ï¼ˆsyntax, bindingï¼‰ï¼Œä¸èƒ½ä¿è¯ç”Ÿæˆå†…å®¹çš„äº‹å®æ­£ç¡®æ€§ã€‚

3. **è¶…å‚æ•°æ•æ„Ÿ**  
   `m` å’Œ `E` éœ€è¦è°ƒä¼˜ï¼Œè¿‡å¤§åè€Œå¼•å…¥å™ªå£°ã€‚

4. **greedy decoding ä¸‹æœ‰æ•ˆï¼Œä½†éå”¯ä¸€è·¯å¾„**  
   è™½åœ¨ temperature=1.0 ä¸‹éªŒè¯æœ‰æ•ˆï¼ˆAppendix Dï¼‰ï¼Œä½†ä»å—é™äºé‡‡æ ·ç­–ç•¥ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•åˆ°å…¶ä»–æ¨¡æ€**  
   å¦‚å›¾åƒã€éŸ³é¢‘ç­‰ç¦»æ•£æ‰©æ•£æ¨¡å‹ä¸­çš„ context-robust ä¿®è®¢ã€‚

2. **ç»“åˆå¤–éƒ¨éªŒè¯å™¨ï¼ˆVerifierï¼‰**  
   å°† instability signal ä¸ reward model ç»“åˆï¼ŒåŒæ—¶ä¼˜åŒ–é€»è¾‘ä¸ç»“æ„ä¸€è‡´æ€§ã€‚

3. **åŠ¨æ€è°ƒæ•´ candidate set size**  
   æ ¹æ®åºåˆ—å¤æ‚åº¦è‡ªé€‚åº”é€‰æ‹© `m`ï¼Œæå‡æ•ˆç‡ã€‚

4. **æ¢ç´¢æ›´ä¸°å¯Œçš„ perturbation family**  
   å¦‚æ›¿æ¢ã€æ’å…¥ã€é‡æ’åºç­‰æ“ä½œï¼Œå¢å¼ºå‹åŠ›æµ‹è¯•èƒ½åŠ›ã€‚

---

## âœ… æ€»ç»“

**CoRE** æå‡ºäº†ä¸€ç§å…¨æ–°çš„è§†è§’ï¼š**å°† inference-time revision è§†ä¸º robustness é—®é¢˜è€Œé uncertainty é—®é¢˜**ã€‚å®ƒé€šè¿‡è½»é‡çº§çš„ä¸Šä¸‹æ–‡æ‰°åŠ¨æœºåˆ¶ï¼Œè¯†åˆ«å¹¶ä¿®æ­£é‚£äº›â€œçœ‹ä¼¼è‡ªä¿¡å®åˆ™è„†å¼±â€çš„ tokenï¼Œåœ¨å‡ ä¹æ— é¢å¤–è®­ç»ƒæˆæœ¬çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº† diffusion language models åœ¨ç»“æ„æ•æ„Ÿä»»åŠ¡ä¸Šçš„ç”Ÿæˆè´¨é‡ï¼Œå°¤å…¶æ˜¯åœ¨ä»£ç ç”Ÿæˆï¼ˆMBPPï¼‰ä¸Šå®ç°äº†é«˜è¾¾ **+9.2%** çš„çªç ´æ€§æå‡ã€‚

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> **ä¸æ˜¯çœ‹æ¨¡å‹â€œæœ‰å¤šç¡®å®šâ€ï¼Œè€Œæ˜¯çœ‹å®ƒâ€œæ¢äº†ä¸ªç¯å¢ƒè¿˜æ•¢ä¸æ•¢è¿™ä¹ˆè¯´â€â€”â€”è¿™æ‰æ˜¯çœŸæ­£çš„è¯­è¨€ç”Ÿæˆç¨³å¥æ€§ã€‚**

</details>

---

### 8. [Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning](https://arxiv.org/abs/2602.04284)

**Authors**: Yansong Ning, Jun Fang, Naiqiang Tan, Hao Liu  
**Category**: cs.AI  
**Published**: 2026-02-05  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.04284v1  

#### Abstract
Managing agent thought and observation during multi-turn agent-environment interactions is an emerging strategy to improve agent efficiency. However, existing studies treat the entire interaction trajectories equally, overlooking the thought necessity and observation utility varies across turns. To ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAgent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰çš„ **LLM Agent** åœ¨å¤šè½®ä¸ç¯å¢ƒäº¤äº’è¿‡ç¨‹ä¸­ï¼Œé€šå¸¸ä¼šç”Ÿæˆå†—ä½™çš„ **Thought**ï¼ˆæ¨ç†è¿‡ç¨‹ï¼‰å’Œç´¯ç§¯æ— ç”¨çš„ **Observation**ï¼ˆå†å²åé¦ˆï¼‰ï¼Œå¯¼è‡´ä¸Šä¸‹æ–‡é•¿åº¦æ€¥å‰§å¢é•¿ï¼Œæ˜¾è‘—é™ä½æ¨ç†æ•ˆç‡å¹¶å¢åŠ è®¡ç®—æˆæœ¬ã€‚ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ Thought Managementã€Observation Managementï¼‰é€šå¸¸å¯¹æ•´ä¸ªäº¤äº’è½¨è¿¹è¿›è¡Œç»Ÿä¸€å‹ç¼©æˆ–å‰ªæï¼Œå¿½ç•¥äº†ä¸åŒäº¤äº’è½®æ¬¡ä¸­ **Thought å¿…è¦æ€§** å’Œ **Observation å®ç”¨æ€§** çš„å·®å¼‚ã€‚

æœ¬æ–‡æå‡ºï¼š**å¹¶éæ‰€æœ‰è½®æ¬¡çš„ Thought å’Œ Observation éƒ½åŒç­‰é‡è¦**ï¼Œåº”å®ç°**è‡ªé€‚åº”çœç•¥**ï¼ˆAdaptive Omissionï¼‰ï¼Œä»¥æå‡æ•ˆç‡è€Œä¸ç‰ºç‰²æ•ˆæœã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
ä½œè€…æå‡ºäº† **Agent-Omit**ï¼Œä¸€ä¸ªç»Ÿä¸€çš„è®­ç»ƒæ¡†æ¶ï¼Œä½¿ LLM Agent èƒ½å¤Ÿåœ¨äº¤äº’è¿‡ç¨‹ä¸­**è‡ªé€‚åº”åœ°çœç•¥å†—ä½™çš„ Thought å’Œ Observation**ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **ç»Ÿä¸€çš„åˆ†ææ¡†æ¶**ï¼šé¦–æ¬¡é€šè¿‡å®šé‡å®éªŒè¯æ˜ Thought å’Œ Observation çš„å½±å“æ˜¯**è½®æ¬¡ä¾èµ–**ï¼ˆturn-dependentï¼‰çš„ï¼Œä¸ºè‡ªé€‚åº”çœç•¥æä¾›äº†ç†è®ºä¾æ®ã€‚
- **ä¸¤é˜¶æ®µè®­ç»ƒèŒƒå¼**ï¼š
  1. **Agent Omission Behavior Synthesis**ï¼šåˆæˆå†·å¯åŠ¨æ•°æ®ï¼ˆcold-start dataï¼‰ï¼ŒåŒ…å«å•è½®å’Œå¤šè½®çœç•¥åœºæ™¯ï¼Œç”¨äºå¾®è°ƒæ¨¡å‹æŒæ¡çœç•¥è¡Œä¸ºæ ¼å¼ã€‚
  2. **Omit-Aware Agentic Reinforcement Learning**ï¼šå¼•å…¥**åŒé‡‡æ ·æœºåˆ¶**ï¼ˆDual Samplingï¼‰å’Œ**çœç•¥å¥–åŠ±**ï¼ˆOmission Rewardï¼‰ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ æ¿€åŠ±æ¨¡å‹ä¸»åŠ¨è¯†åˆ«å¹¶çœç•¥å†—ä½™å†…å®¹ã€‚
- **ç†è®ºä¿è¯**ï¼šè¯æ˜äº†æ‰€å­¦çœç•¥ç­–ç•¥çš„åå·®ç”± **KL æ•£åº¦** ä¸Šç•Œçº¦æŸï¼Œç¡®ä¿ç­–ç•¥ç¨³å®šæ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | Agent-Omit | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ DEPO, ReSumï¼‰ |
|------|----------|------------------------|
| **çœç•¥ç²’åº¦** | è‡ªé€‚åº”ã€è½®æ¬¡çº§åŠ¨æ€å†³ç­– | å…¨å±€é™æ€å‹ç¼©æˆ–å¯å‘å¼è§„åˆ™ |
| **è®­ç»ƒæ–¹å¼** | ç»“åˆ SFT + Omit-Aware RLï¼Œç«¯åˆ°ç«¯ä¼˜åŒ– | å¤šä¸ºç›‘ç£å¾®è°ƒæˆ–åå¤„ç† |
| **æ•ˆç‡-æ•ˆæœæƒè¡¡** | æ˜¾è‘—é™ä½ Token æ¶ˆè€—ï¼ŒåŒæ—¶ä¿æŒç”šè‡³æå‡å‡†ç¡®ç‡ | å¾€å¾€ä»¥ç²¾åº¦ä¸‹é™æ¢å–æ•ˆç‡æå‡ |
| **æ³›åŒ–èƒ½åŠ›** | å­¦ä¹ åˆ°çœç•¥ç­–ç•¥ï¼Œå¯æ³›åŒ–è‡³æ–°ä»»åŠ¡ | ä¾èµ–å›ºå®šè§„åˆ™ï¼Œæ³›åŒ–æ€§å·® |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
å®éªŒåœ¨äº”ä¸ªå…·æœ‰ä»£è¡¨æ€§çš„ **AgentGym-RL** åŸºå‡†ä¸Šè¿›è¡Œï¼Œæ¶µç›–å¤šç§ä»»åŠ¡ç±»å‹ï¼š

| æ•°æ®é›† | ä»»åŠ¡ç±»å‹ | æœ€å¤§å›åˆæ•° |
|-------|--------|---------|
| **DeepSearch** | ä¿¡æ¯æ£€ç´¢ï¼ˆæœç´¢å¼•æ“é—®ç­”ï¼‰ | 8 |
| **WebShop** | ç½‘é¡µå¯¼èˆªï¼ˆç”µå•†è´­ç‰©ï¼‰ | 12 |
| **TextCraft** | æ•°å­—æ¸¸æˆï¼ˆMinecraft æ–‡æœ¬ç‰ˆï¼‰ | 20 |
| **BabyAI** | å…·èº«æ§åˆ¶ï¼ˆæŒ‡ä»¤è·Ÿéšï¼‰ | 10 |
| **SciWorld** | ç§‘å­¦å‘ç°ï¼ˆç‰©ç†å®éªŒæ¨¡æ‹Ÿï¼‰ | 10 |

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **ä¸»å¹²æ¨¡å‹**ï¼šåŸºäº **Qwen3-4B** å’Œ **Qwen3-8B** æ„å»º Agent-Omit-SFT / RL æ¨¡å‹ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Pass@1**ï¼šä»»åŠ¡æˆåŠŸç‡ï¼ˆä¸»è¦æ•ˆæœæŒ‡æ ‡ï¼‰
  - **Avg Tok. â†“**ï¼šå¹³å‡ Token æ¶ˆè€—ï¼ˆä¸»è¦æ•ˆç‡æŒ‡æ ‡ï¼‰
- **è®­ç»ƒæµç¨‹**ï¼š
  1. **SFT é˜¶æ®µ**ï¼šä½¿ç”¨åˆæˆçš„ 2â€“4K å†·å¯åŠ¨æ•°æ®è¿›è¡Œå…¨å‚æ•°å¾®è°ƒã€‚
  2. **RL é˜¶æ®µ**ï¼šé‡‡ç”¨ **Group Relative Policy Optimization (GRPO)** è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œç»“åˆ **Partial Trajectory** å’Œ **Full Trajectory** åŒé‡‡æ ·ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
#### ï¼ˆ1ï¼‰å‰æ²¿ LLM Agent å¯¹æ¯”
- DeepSeek-R1-0528, DeepSeek-V3.2, OpenAI o3/o4-mini, Qwen3-235B-A22B ç­‰ã€‚

#### ï¼ˆ2ï¼‰é«˜æ•ˆ Agent æ„å»ºæ–¹æ³•å¯¹æ¯”ï¼ˆ7 ç±»ï¼‰
- **Thought Management**: Thinking-Retention, DEPO, ToolLight
- **Observation Management**: Observation-Mask, DeepMiner
- **Thought&Observation Management**: MEM-Agent, ReSum

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆä»¥ Agent-Omit-8B-RL ä¸ºä¾‹ï¼‰

| æ¨¡å‹ | DeepSearch (Pass@1 / Tok) | WebShop (Pass@1 / Tok) | TextCraft (Pass@1 / Tok) | BabyAI (Pass@1 / Tok) | SciWorld (Pass@1 / Tok) |
|------|---------------------------|------------------------|--------------------------|-----------------------|--------------------------|
| **Agent-Omit-8B-RL** | **26.56 / 4,356** | **23.57 / 8,764** | **87.00 / 7,328** | **84.36 / 6,643** | **18.45 / 9,643** |
| Qwen3-8B (Base) | 17.75 / 8,281 | 6.93 / 16,741 | 55.00 / 19,587 | 60.81 / 19,162 | 2.47 / 17,052 |

> âœ… **ç»“è®º**ï¼šAgent-Omit-8B-RL åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šå‡å¤§å¹…è¶…è¶ŠåŸºçº¿æ¨¡å‹ï¼Œåœ¨ **WebShop** ä¸Šå‡†ç¡®ç‡æå‡ **3.4å€**ï¼ŒToken æ¶ˆè€—å‡å°‘è¿‘ **50%**ã€‚

### ä¸å‰æ²¿ LLM Agent çš„å¯¹æ¯”
- Agent-Omit-8B-RL åœ¨ **WebShopã€TextCraftã€BabyAIã€SciWorld** ä¸Šå–å¾—æœ€é«˜ Pass@1 åˆ†æ•°ã€‚
- åœ¨ **DeepSearch** ä¸Šæ¥è¿‘æœ€ä¼˜ï¼Œä¸” Token æˆæœ¬è¿œä½äºå¤§å¤šæ•°æ¨ç†å‹æ¨¡å‹ï¼ˆå¦‚ DeepSeek-R1-0528ï¼‰ã€‚
- ç›¸æ¯”éæ¨ç†æ¨¡å¼ï¼ˆå¦‚ DeepSeek-V3.2ï¼‰ï¼Œè™½ Token æˆæœ¬ç•¥é«˜ï¼Œä½†å‡†ç¡®ç‡ä¼˜åŠ¿å·¨å¤§ã€‚

### ä¸é«˜æ•ˆ Agent æ–¹æ³•çš„å¯¹æ¯”
- åœ¨ Qwen3-8B ä¸Šï¼ŒAgent-Omit-RL **å…¨é¢ä¼˜äº 7 ç§ç°æœ‰é«˜æ•ˆæ–¹æ³•**ã€‚
- ä¾‹å¦‚åœ¨ WebShop ä¸Šï¼š
  - **ReSum**ï¼šPass@1 = 17.80, Avg Tok = 9,251
  - **Agent-Omit-RL**ï¼šPass@1 = 23.57 (**â†‘32.4%**)ï¼ŒAvg Tok = 8,764 (**â†“5.3%**)
- å®ç°äº†**æœ€ä½³çš„æ•ˆæœ-æ•ˆç‡æƒè¡¡**ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
åœ¨ WebShop ä¸Šå¯¹ Agent-Omit-8B-RL è¿›è¡Œæ¶ˆèï¼š

| å˜ä½“ | Pass@1 | Avg Tok |
|------|--------|--------|
| **å®Œæ•´æ¨¡å‹ (Agent-Omit-RL)** | **23.57** | **8,764** |
| w/o STO (æ— å•è½®çœç•¥æ•°æ®) | 20.12 | 9,123 |
| w/o MTO (æ— å¤šè½®çœç•¥æ•°æ®) | 21.05 | 8,987 |
| w/o PT (æ—  Partial Trajectory) | 21.34 | 9,012 |
| w/o FT (æ—  Full Trajectory) | 22.01 | 8,901 |
| w/o OR (æ—  Omission Reward) | 20.88 | 9,205 |

> ğŸ” **å…³é”®å‘ç°**ï¼š
> - **SFT é˜¶æ®µ**ï¼šå•è½®çœç•¥æ•°æ®ï¼ˆSTOï¼‰æœ€ä¸ºå…³é”®ï¼Œå¥ å®šçœç•¥è¡Œä¸ºåŸºç¡€ã€‚
> - **RL é˜¶æ®µ**ï¼šPartial Trajectory é‡‡æ ·å’Œ Omission Reward å¯¹æ€§èƒ½æå‡è‡³å…³é‡è¦ã€‚
> - **åŒé˜¶æ®µååŒ**ï¼šSFT + RL å¸¦æ¥â€œåŒé‡å¢ç›Šâ€ï¼ˆDual Gainï¼‰ï¼Œç¼ºä¸€ä¸å¯ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Thought å’Œ Observation çš„æ•ˆç”¨æ˜¯è½®æ¬¡ç›¸å…³çš„**ï¼šæ—©æœŸç”¨äºè§„åˆ’ï¼Œä¸­é—´è½®æ¬¡æ˜“å†—ä½™ï¼Œæœ«æœŸç”¨äºæ€»ç»“ã€‚
2. **é€‰æ‹©æ€§çœç•¥å¯è¡Œä¸”æœ‰æ•ˆ**ï¼šåœ¨ä¸­é—´è½®æ¬¡çœç•¥å†—ä½™ Thought/Observation å¯æ˜¾è‘—é™ä½ Token æ¶ˆè€—ï¼Œ**ä¸æŸå®³ç”šè‡³æå‡å‡†ç¡®ç‡**ã€‚
3. **è‡ªé€‚åº”çœç•¥ä¼˜äºå…¨å±€å‹ç¼©**ï¼šAgent-Omit å­¦ä¼šåŠ¨æ€åˆ¤æ–­ä½•æ—¶çœç•¥ï¼Œæ¯”å›ºå®šè§„åˆ™æ›´çµæ´»é«˜æ•ˆã€‚
4. **è®­ç»ƒç­–ç•¥å†³å®šæˆè´¥**ï¼šå†·å¯åŠ¨æ•°æ®æä¾›è¡Œä¸ºå…ˆéªŒï¼ŒOmit-Aware RL å®ç°ç­–ç•¥ä¼˜åŒ–ï¼ŒäºŒè€…ç¼ºä¸€ä¸å¯ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡ç³»ç»Ÿæç¤º**ï¼šçœç•¥è¡Œä¸ºéœ€æ˜ç¡®çš„ `<omit_tool_response_N_...>` æ ‡è®°å¼•å¯¼ã€‚
- **è®­ç»ƒæˆæœ¬è¾ƒé«˜**ï¼šRL é˜¶æ®µéœ€å¤§é‡ GPU æ—¶é—´ï¼ˆæœ€é•¿è¾¾ 36 å°æ—¶ï¼‰ã€‚
- **çœç•¥ç­–ç•¥å¯èƒ½è¯¯åˆ¤**ï¼šè‹¥é”™è¯¯çœç•¥å…³é”®ä¿¡æ¯ï¼Œå¯èƒ½å¯¼è‡´ä»»åŠ¡å¤±è´¥ï¼Œç¼ºä¹å›é€€æœºåˆ¶ã€‚
- **ç›®å‰ä»…é€‚ç”¨äºç‰¹å®š Action Space**ï¼šæ‰©å±•åˆ°æ›´å¤æ‚å·¥å…·è°ƒç”¨éœ€è¿›ä¸€æ­¥ç ”ç©¶ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°†çœç•¥æ•°æ®åˆæˆç®¡é“æ‰©å±•åˆ°**å¤§è§„æ¨¡é¢„è®­ç»ƒé˜¶æ®µ**ã€‚
- æ¢ç´¢å°† Agent-Omit èŒƒå¼åº”ç”¨äº**æ›´å¤§è§„æ¨¡çš„ LLM**ï¼ˆå¦‚ Qwen3-72B æˆ–ä»¥ä¸Šï¼‰ã€‚
- ç ”ç©¶**å¤šæ¨¡æ€ Agent** ä¸­çš„æ„ŸçŸ¥ä¿¡æ¯çœç•¥æœºåˆ¶ã€‚
- å¼•å…¥**ä¸ç¡®å®šæ€§ä¼°è®¡**ï¼ŒæŒ‡å¯¼æ›´å®‰å…¨çš„çœç•¥å†³ç­–ã€‚

---

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> **Agent-Omit é€šè¿‡â€œå†·å¯åŠ¨å¾®è°ƒ + çœç•¥æ„ŸçŸ¥å¼ºåŒ–å­¦ä¹ â€çš„ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œé¦–æ¬¡å®ç°äº† LLM Agent åœ¨å¤šè½®äº¤äº’ä¸­å¯¹ Thought ä¸ Observation çš„è‡ªé€‚åº”çœç•¥ï¼Œåœ¨äº”å¤§åŸºå‡†ä¸Šå®ç°äº†å½“å‰æœ€ä¼˜çš„æ•ˆæœ-æ•ˆç‡æƒè¡¡ã€‚**

</details>

---

### 9. [MirrorLA: Reflecting Feature Map for Vision Linear Attention](https://arxiv.org/abs/2602.04346)

**Authors**: Weikang Meng, Liangyu Huo, Yadan Luo, Yaowei Wang, Yingjian Li, Zheng Zhang  
**Category**: cs.LG  
**Published**: 2026-02-05  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.04346v1  

#### Abstract
Linear attention significantly reduces the computational complexity of Transformers from quadratic to linear, yet it consistently lags behind softmax-based attention in performance. We identify the root cause of this degradation as the non-negativity constraint imposed on kernel feature maps: standa...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šMirrorLA: Reflecting Feature Map for Vision Linear Attention**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
- **Linear Attention (LA)** è™½ç„¶å°† Transformer çš„è®¡ç®—å¤æ‚åº¦ä» $O(N^2d)$ é™ä½åˆ° $O(Nd^2)$ï¼Œå®ç°äº†çº¿æ€§æ•ˆç‡ï¼Œä½†åœ¨å®é™…æ€§èƒ½ä¸Š**å§‹ç»ˆè½åäºåŸºäº softmax çš„æ³¨æ„åŠ›æœºåˆ¶**ï¼Œå°¤å…¶åœ¨è§†è§‰ä»»åŠ¡ä¸­è¡¨ç°æ›´å·®ã€‚
- ä»¥å¾€ç ”ç©¶è®¤ä¸ºæ€§èƒ½ä¸‹é™æºäºéè´Ÿæ€§çº¦æŸï¼ˆnon-negativity constraintï¼‰å¯¹ç‰¹å¾æ˜ å°„çš„é™åˆ¶ï¼Œä¾‹å¦‚ ReLU ç­‰æ¿€æ´»å‡½æ•°ä¼š**è¢«åŠ¨æˆªæ–­ï¼ˆpassive truncationï¼‰è´Ÿå€¼éƒ¨åˆ†**ï¼Œå¯¼è‡´è¯­ä¹‰ä¿¡æ¯ä¸¢å¤±ï¼Œå¼•å‘â€œæ­»ç»´åº¦â€ï¼ˆdead dimensionï¼‰å±æœºã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æå‡º **MirrorLA** â€”â€”ä¸€ç§åŸºäº**å¯å­¦ä¹  Householder åå°„**çš„å‡ ä½•æ¡†æ¶ï¼Œå°†ä¼ ç»Ÿçš„â€œè¢«åŠ¨æˆªæ–­â€è½¬å˜ä¸ºâ€œä¸»åŠ¨é‡å®šå‘â€ï¼ˆactive reorientationï¼‰ï¼š
- åˆ©ç”¨ **Householder åå°„** å¯¹ç‰¹å¾ç©ºé—´è¿›è¡Œç­‰è·æ—‹è½¬ï¼ˆisometryï¼‰ï¼Œå°†å¯Œå«ä¿¡æ¯çš„æ–¹å‘**ä¸»åŠ¨å¯¹é½åˆ°éè´Ÿè±¡é™**ï¼Œå†æ–½åŠ  ReLUï¼Œä»è€Œåœ¨æ»¡è¶³éè´Ÿæ€§çš„åŒæ—¶æœ€å¤§åŒ–ä¿¡æ¯ä¿ç•™ã€‚
- è®¾è®¡äº†**å¤šå°ºåº¦ã€åˆ†å±‚æ¶æ„**æ¥ä¼˜åŒ–ç‰¹å¾æ‹“æ‰‘ç»“æ„ï¼š
  1. **Block-wise isometries**ï¼šå±€éƒ¨åˆ¤åˆ«æ€§ä¼˜åŒ–ï¼Œé€šè¿‡å—çŠ¶åˆ†è§£å®ç°é«˜æ•ˆé«˜ç»´åå°„ã€‚
  2. **Variance-aware modulation**ï¼šåŠ¨æ€è°ƒèŠ‚åå°„è§’åº¦ï¼Œæå‡ä½æ–¹å·®åŒºåŸŸçš„æ¿€æ´»å¤šæ ·æ€§ï¼Œé˜²æ­¢é•¿åºåˆ—å»ºæ¨¡ä¸­çš„ç‰¹å¾åç¼©ã€‚
  3. **Cross-head reflection**ï¼šè·¨å¤´åå°„ä¿ƒè¿›å…¨å±€åæ–¹å·®æ··åˆï¼Œç¼“è§£å¤šå¤´ç‹¬ç«‹å¤„ç†å¸¦æ¥çš„ç§©ç¢ç‰‡åŒ–ï¼ˆrank fragmentationï¼‰ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- **ä¸ç‰ºç‰²æ•ˆç‡çš„å‰æä¸‹æå‡è¡¨è¾¾èƒ½åŠ›**ï¼šä¿æŒ $O(Nd^2)$ å¤æ‚åº¦ï¼Œæ— éœ€åƒ Polaformer æˆ– Nalaformer é‚£æ ·æ‰©å±•ç»´åº¦ $k$ å€è€Œå¯¼è‡´ $O(k^2d^2)$ å¼€é”€ã€‚
- **ç†è®ºä¸å®è·µç»Ÿä¸€**ï¼šåˆ©ç”¨å†…ç§¯æ—‹è½¬ä¸å˜æ€§ï¼Œè¯æ˜ç›¸ä¼¼æ€§å¯åœ¨åæ ‡ç³»å˜æ¢ä¸‹ä¿æŒï¼Œçªç ´ä¼ ç»Ÿè½´å¯¹é½æ¿€æ´»çš„å±€é™ã€‚
- **æ¨¡å—åŒ–è®¾è®¡**ï¼šå¯ä½œä¸ºå³æ’å³ç”¨ç»„ä»¶é›†æˆåˆ°å„ç±» Vision Transformer æ¶æ„ä¸­ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **å›¾åƒåˆ†ç±»**ï¼šImageNet-1K
- **ç›®æ ‡æ£€æµ‹ä¸å®ä¾‹åˆ†å‰²**ï¼šCOCO
- **è¯­ä¹‰åˆ†å‰²**ï¼šADE20Kã€Cityscapes
- **è¶…åˆ†è¾¨ç‡**ï¼šSet5ã€Set14ã€BSDS100ã€Urban100ã€Manga109ï¼ˆè½»é‡çº§å•å›¾è¶…åˆ†ï¼‰
- **æ‰©æ•£æ¨¡å‹ç”Ÿæˆ**ï¼šImageNet-1Kï¼ˆç”¨äº DiT å’Œ SiT æ¶æ„ï¼‰

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**
| ä»»åŠ¡ | æ¨¡å‹åŸºåº• | ä¸»è¦æŒ‡æ ‡ |
|------|----------|---------|
| å›¾åƒåˆ†ç±» | Swin-T/S/B/L ç­‰å˜ä½“ | Top-1 Accuracy (%) |
| ç›®æ ‡æ£€æµ‹/å®ä¾‹åˆ†å‰² | RetinaNetã€Mask R-CNN | AP$^b$, AP$^m$ |
| è¯­ä¹‰åˆ†å‰² | FPN/MMSegmentation | mIoU (%) |
| è¶…åˆ†è¾¨ç‡ | DCTLSA | PSNR / SSIM / Latency / GPU Memory |
| æ‰©æ•£ç”Ÿæˆ | DiT / SiT | FIDâ†“, sFIDâ†“, ISâ†‘, Precisionâ†‘, Recallâ†‘ |

æ‰€æœ‰å®éªŒå‡æ§åˆ¶å‚æ•°é‡ï¼ˆPARAMSï¼‰ã€FLOPs åœ¨ç›¸è¿‘æ°´å¹³ä»¥ç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **Linear Attention ç±»**ï¼šReLU-based LA, Performer, Linformer, FLatten-Transformer, InLine, Agent Attention, PolaFormer
- **Vision Transformer ç±»**ï¼šSwin Transformer, PVT, EfficientViT, RMT, RAVLT
- **å…¶ä»–é«˜æ•ˆæ¨¡å‹**ï¼šVMamba, MambaOut, VHeat, SegFormer, SegNeXt
- **æ‰©æ•£æ¨¡å‹**ï¼šDiT, DiG, SiT, EfficientSiT

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”ç»“æœ**

#### âœ… **å›¾åƒåˆ†ç±»ï¼ˆImageNet-1Kï¼‰**
| æ¨¡å‹ | å‚æ•°é‡ | FLOPs | Top-1 Acc (%) |
|------|--------|-------|----------------|
| MirrorLA-T | 15M | 2.6G | **82.8** |
| RAVLT-T | 15M | 2.6G | 82.6 |
| MirrorLA-S | 26M | 4.9G | **84.2** |
| MirrorLA-B | 48M | 10.6G | **85.3** |
| MirrorLA-L | 95M | 17.3G | **85.7** |

> åœ¨å„è§„æ¨¡ä¸‹å‡ä¼˜äºåŒçº§åˆ« SOTA æ–¹æ³•ï¼Œæœ€å¤§æå‡è¾¾ **+0.4%**ã€‚

#### âœ… **ç›®æ ‡æ£€æµ‹ä¸å®ä¾‹åˆ†å‰²ï¼ˆCOCOï¼‰**
- **RetinaNet + MirrorLA**ï¼š
  - AP$^b$: æœ€é«˜æå‡ **+1.8**
- **Mask R-CNN + MirrorLA**ï¼š
  - 1Ã— schedule: AP$^b$ ä» 47.2 â†’ **49.9**
  - 3Ã— schedule: AP$^b$ ä» 50.7 â†’ **51.3**

#### âœ… **è¯­ä¹‰åˆ†å‰²ï¼ˆADE20K & Cityscapesï¼‰**
| æ•°æ®é›† | æ¨¡å‹ | mIoU (%) | FLOPs |
|--------|------|----------|--------|
| ADE20K | MirrorLA-S | **50.9** | 25G |
|        | EfficientViT-L1 | 49.2 | 36G |
| Cityscapes | MirrorLA-S | **83.5** | 205G |
|            | SegNeXt-S | 81.3 | 125G |

> åœ¨æ›´ä½æˆ–ç›¸å½“è®¡ç®—æˆæœ¬ä¸‹å–å¾—æ˜¾è‘—é¢†å…ˆï¼Œ**æœ€é«˜æå‡ 6.6 mIoU**ã€‚

#### âœ… **è¶…åˆ†è¾¨ç‡ï¼ˆSuper-Resolutionï¼‰**
é›†æˆè‡³ DCTLSA åï¼Œåœ¨ Ã—4 ä¸Šæå‡æ˜æ˜¾ï¼š
| æŒ‡æ ‡ | Set5 | Urban100 |
|------|------|----------|
| PSNR | 32.44 â†’ **32.53** | 26.41 â†’ **26.65** |
| SSIM | 0.8973 â†’ **0.8983** | 0.7944 â†’ **0.8007** |
| å†…å­˜å ç”¨ | â†“ **81.4%** | â†“ **81.4%** |
| æ¨ç†å»¶è¿Ÿ | â†“ **78%** | â†“ **78%** |

> æ˜¾è‘—æå‡é‡å»ºè´¨é‡åŒæ—¶å¤§å¹…é™ä½èµ„æºæ¶ˆè€—ã€‚

#### âœ… **æ‰©æ•£æ¨¡å‹ï¼ˆDiffusion Transformerï¼‰**
| æ¨¡å‹ | FIDâ†“ | sFIDâ†“ | ISâ†‘ |
|------|------|--------|-----|
| MirrorLADiT | **58.07** | **11.21** | **24.70** |
| DiG | 62.06 | 11.77 | 22.81 |
| MirrorLASiT | **52.29** | **8.41** | **28.51** |
| EfficientSiT | 53.57 | 9.01 | 27.26 |

> åœ¨ç”Ÿæˆè´¨é‡å’Œå¤šæ ·æ€§æ–¹é¢å…¨é¢è¶…è¶Šå½“å‰æœ€ä¼˜æ–¹æ³•ã€‚

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**
- åœ¨ Swin-T ä¸Šè¿›è¡Œæ¨¡å—åˆ†æï¼ˆAppendix Tab. 8ï¼‰ï¼š
  - ç§»é™¤ **full variant**ï¼ˆå®Œæ•´è®¾è®¡ï¼‰ï¼šæ€§èƒ½ä¸‹é™ **0.5%**
  - ç§»é™¤ **cross-head reflection**ï¼šæ€§èƒ½ä¸‹é™ **0.3%**
- è¶…å‚æ•°æ•æ„Ÿæ€§æµ‹è¯•è¡¨æ˜ $\lambda$ å’Œ $\alpha_{\text{max}}$ å¯¹æ€§èƒ½æœ‰ç¨³å®šå½±å“ï¼ŒéªŒè¯äº† variance-aware modulation çš„æœ‰æ•ˆæ€§ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **ä¿¡æ¯æŸå¤±å¹¶éä¸å¯é¿å…**ï¼šLinear Attention æ€§èƒ½åŠ£åŒ–ä¸»å› ä¸æ˜¯éè´Ÿæ€§æœ¬èº«ï¼Œè€Œæ˜¯å…¶**åˆšæ€§æ‰§è¡Œæ–¹å¼**ï¼ˆå¦‚ ReLU æˆªæ–­ï¼‰ã€‚é€šè¿‡å‡ ä½•å˜æ¢å¯å°†å…¶è½¬åŒ–ä¸ºå¯æ§æ“ä½œã€‚
2. **ä¸»åŠ¨é‡å®šå‘ä¼˜äºè¢«åŠ¨æˆªæ–­**ï¼šHouseholder åå°„èƒ½åœ¨ä¿æŒå†…ç§¯ä¸å˜çš„å‰æä¸‹ï¼Œå°†ä¿¡æ¯ä¸°å¯Œæ–¹å‘æ—‹è½¬è‡³æ¿€æ´»åŒºåŸŸï¼Œæ˜¾è‘—æå‡ç‰¹å¾å¯†åº¦ä¸è¡¨è¾¾åŠ›ã€‚
3. **å¤šå°ºåº¦è®¾è®¡è‡³å…³é‡è¦**ï¼š
   - å±€éƒ¨å—åå°„ä¿éšœç²¾åº¦ï¼›
   - æ–¹å·®æ„ŸçŸ¥è°ƒåˆ¶å¢å¼ºé²æ£’æ€§ï¼›
   - è·¨å¤´åå°„æå‡å…¨å±€ååŒã€‚
4. **ä¸¥æ ¼çº¿æ€§æ•ˆç‡ä¸é«˜æ€§èƒ½å¯å…¼å¾—**ï¼šMirrorLA åœ¨ä¸å¢åŠ å¤æ‚åº¦çš„æƒ…å†µä¸‹å®ç°äº† SOTA è¡¨ç°ï¼Œæ‰“ç ´äº†â€œé«˜æ•ˆå¿…ä½è´¨â€çš„å›ºæœ‰è®¤çŸ¥ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- å½“å‰å®ç°ä¾èµ–äºé€šç”¨ PyTorch/Triton è¿è¡Œæ—¶ï¼Œå°šæœªé’ˆå¯¹ç¡¬ä»¶ï¼ˆå¦‚ GPU tile layoutï¼‰æ·±åº¦ä¼˜åŒ–ã€‚
- Householder å‚æ•°å¼•å…¥é¢å¤–å¯è®­ç»ƒå˜é‡ï¼Œè™½æ€»é‡å°ä½†ä»æœ‰ä¸€å®šå¼€é”€ã€‚
- ç†è®ºåˆ†æé›†ä¸­äºäºŒç»´å—è¿‘ä¼¼ï¼Œé«˜ç»´ç©ºé—´çš„æœ€ä¼˜åˆ†è§£ç­–ç•¥ä»æœ‰æ¢ç´¢ç©ºé—´ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- **ç¡¬ä»¶æ„ŸçŸ¥è®¾è®¡**ï¼šå¼€å‘ä¸“ç”¨ Triton kernel å°† block-wise Householder ä¸ Flash Linear Attention (FLA) èåˆï¼Œè¿›ä¸€æ­¥æå‡æ¨ç†ååã€‚
- **åŠ¨æ€å—åˆ’åˆ†**ï¼šæ¢ç´¢è‡ªé€‚åº” block size æˆ– hierarchical reflection ç»“æ„ã€‚
- **æ‰©å±•è‡³å¤šæ¨¡æ€**ï¼šåº”ç”¨äº Video, Audio, Multimodal Transformers ä¸­çš„é•¿åºåˆ—å»ºæ¨¡ã€‚
- **ä¸å…¶ä»–é«˜æ•ˆæœºåˆ¶ç»“åˆ**ï¼šå¦‚ä¸ State Space Models (SSMs) æˆ– RWKV æ¶æ„èåˆï¼Œæ„å»ºæ–°ä¸€ä»£é€šç”¨è§†è§‰éª¨å¹²ç½‘ç»œã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **MirrorLA é€šè¿‡â€œåå°„è€Œéæˆªæ–­â€çš„æ€æƒ³é©æ–°äº† Linear Attention çš„ç‰¹å¾æ˜ å°„èŒƒå¼ï¼Œåœ¨ä¿æŒçº¿æ€§å¤æ‚åº¦çš„åŒæ—¶å®ç°äº†æ€§èƒ½åè¶…ï¼Œä¸ºé«˜æ•ˆä¸”å¼ºå¤§çš„è§†è§‰å»ºæ¨¡æä¾›äº†å…¨æ–°è·¯å¾„ã€‚**

</details>

---

### 10. [ReThinker: Scientific Reasoning by Rethinking with Guided Reflection and Confidence Control](https://arxiv.org/abs/2602.04496)

**Authors**: Zhentao Tang, Yuqi Cui, Shixiong Kai, Wenqian Zhao, Ke Ye, Xing Li, Anxin Tian, Zehua Pei, Hui-Ling Zhen, Shoubo Hu, Xiaoguang Li, Yunhe Wang, Mingxuan Yuan  
**Category**: cs.AI  
**Published**: 2026-02-05  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.04496v1  

#### Abstract
Expert-level scientific reasoning remains challenging for large language models, particularly on benchmarks such as Humanity's Last Exam (HLE), where rigid tool pipelines, brittle multi-agent coordination, and inefficient test-time scaling often limit performance. We introduce ReThinker, a confidenc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# ReThinker: Scientific Reasoning by Rethinking with Guided Reflection and Confidence Control â€”â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜

å½“å‰çš„ **Large Language Models (LLMs)** åœ¨ä¸“å®¶çº§ç§‘å­¦æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°ä»ä¸ç†æƒ³ï¼Œå°¤å…¶æ˜¯åœ¨å¦‚ **Humanity's Last Exam (HLE)** è¿™ç±»é«˜éš¾åº¦åŸºå‡†ä¸Šã€‚ç°æœ‰æ–¹æ³•å­˜åœ¨ä»¥ä¸‹ä¸‰å¤§ç“¶é¢ˆï¼š

- **åˆšæ€§çš„å·¥å…·æµæ°´çº¿ï¼ˆrigid tool pipelinesï¼‰**ï¼šå›ºå®šé¡ºåºè°ƒç”¨å·¥å…·ï¼Œç¼ºä¹åŠ¨æ€é€‚åº”èƒ½åŠ›ã€‚
- **è„†å¼±çš„å¤šæ™ºèƒ½ä½“åä½œï¼ˆbrittle multi-agent coordinationï¼‰**ï¼šå¤šä»£ç†ç³»ç»Ÿä¾èµ–æ‰‹å·¥è®¾è®¡åè®®ï¼Œéš¾ä»¥çº æ­£æ·±å±‚é”™è¯¯ã€‚
- **ä½æ•ˆçš„æµ‹è¯•æ—¶æ‰©å±•ï¼ˆinefficient test-time scalingï¼‰**ï¼šå¹¶è¡Œé‡‡æ ·æˆ–è¿­ä»£åæ€ç­–ç•¥è®¡ç®—æˆæœ¬é«˜ï¼Œä¸”æ˜“å—éªŒè¯å™ªå£°å½±å“ã€‚

è¿™äº›é—®é¢˜å¯¼è‡´æ¨¡å‹åœ¨å¤æ‚ç§‘å­¦é—®é¢˜ä¸­å®¹æ˜“å‡ºç°é€»è¾‘è·³è·ƒã€çŸ¥è¯†ç¼ºå¤±å’Œä¿¡å¿ƒè¯¯åˆ¤ã€‚

---

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯

ä½œè€…æå‡º **ReThinker**ï¼Œä¸€ä¸ªåŸºäºâ€œå†æ€è€ƒâ€ï¼ˆrethinkingï¼‰æœºåˆ¶çš„ **confidence-aware agentic framework**ï¼Œå…¶æ ¸å¿ƒæ˜¯ **Solver-Critic-Selector ä¸‰é˜¶æ®µæ¶æ„**ï¼š

#### ï¼ˆ1ï¼‰Solver-Critic-Selector æ¶æ„
- **Solver é˜¶æ®µ**ï¼šç”Ÿæˆå¤šä¸ªå€™é€‰è§£è·¯å¾„ï¼Œé€šè¿‡å¤šè½®è¿­ä»£åˆæˆé€æ­¥ä¼˜åŒ–ç­”æ¡ˆã€‚
- **Critic é˜¶æ®µ**ï¼šå¼•å…¥ **Guided Reflection**ï¼Œå¯¹å®Œæ•´æ¨ç†è½¨è¿¹è¿›è¡Œç»“æ„åŒ–æ‘˜è¦ï¼Œå¹¶è¯†åˆ«é€»è¾‘ã€çŸ¥è¯†ã€ç­–ç•¥ç­‰ç»´åº¦çš„å…·ä½“æ”¹è¿›ç‚¹ã€‚
- **Selector é˜¶æ®µ**ï¼šé‡‡ç”¨ **Confidence-Controlled Selection**ï¼Œåˆ©ç”¨å›°æƒ‘åº¦ï¼ˆperplexityï¼‰ä½œä¸ºä¸ç¡®å®šæ€§ä¿¡å·ï¼Œç»“åˆæ‹‰ä¸æ–¹æ’åˆ—ï¼ˆLatin Square Permutationï¼‰æ¶ˆé™¤ä½ç½®åè§ï¼Œå®ç°ç¨³å¥çš„ç­”æ¡ˆé€‰æ‹©ã€‚

#### ï¼ˆ2ï¼‰è‡ªåŠ¨åŒ–è®­ç»ƒæ•°æ®åˆæˆ
- æå‡º **reverse data synthesis pipeline** å’Œ **adaptive trajectory recycling strategy**ï¼Œä»æˆåŠŸæ¨ç†è½¨è¿¹ä¸­è‡ªåŠ¨æå–é«˜è´¨é‡ç›‘ç£ä¿¡å·ï¼Œæ— éœ€äººå·¥æ ‡æ³¨ã€‚
- åŒ…æ‹¬ç§å­çŸ­è¯­åˆå§‹åŒ–ã€åœ¨çº¿æ›´æ–°ã€è½¨è¿¹å›æ”¶ä¸è´¨é‡è¿‡æ»¤ï¼Œå½¢æˆé—­ç¯å¢å¼ºçš„æ•°æ®æµã€‚

#### ï¼ˆ3ï¼‰æ··åˆæ‰©å±•ä¸ä¸ç¡®å®šæ€§å¼•å¯¼
- æ”¯æŒ **sequential-parallel hybrid scaling**ï¼Œçµæ´»å¹³è¡¡æ¨ç†é¢„ç®—ä¸å‡†ç¡®æ€§ã€‚
- åˆ©ç”¨ **perplexity-based confidence aggregation** åŠ¨æ€åˆ†é…è®¡ç®—èµ„æºï¼Œåœ¨ä¸ç¡®å®šæ€§å¼ºçš„é—®é¢˜ä¸Šè¿›è¡Œå¤šè½®é‡é€‰ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ReThinker çš„ä¼˜åŠ¿ |
|------|------------------|
| **çµæ´»æ€§** | ä¸ä¾èµ–å›ºå®šæµç¨‹ï¼Œèƒ½åŠ¨æ€è°ƒæ•´å·¥å…·è°ƒç”¨ä¸åæ€æ·±åº¦ |
| **é²æ£’æ€§** | é€šè¿‡å¤šç»´åæ€ä¸ç½®ä¿¡æ§åˆ¶å‡å°‘å¹»è§‰ä¸é”™è¯¯ç´¯ç§¯ |
| **å¯æ‰©å±•æ€§** | è‡ªåŠ¨åŒ–æ•°æ®ç”Ÿæˆæ”¯æŒå¤§è§„æ¨¡è®­ç»ƒï¼Œæ— éœ€äººå·¥æ ‡æ³¨ |
| **æ•ˆç‡** | ç½®ä¿¡å¼•å¯¼æœºåˆ¶é¿å…æ— æ•ˆè®¡ç®—ï¼Œèšç„¦äºé«˜ä¸ç¡®å®šæ€§æ¡ˆä¾‹ |

ç›¸æ¯”ä¼ ç»Ÿ ReAct æˆ–çº¯å¹¶è¡Œé‡‡æ ·æ–¹æ³•ï¼ŒReThinker æ›´æ¥è¿‘äººç±»ç§‘å­¦å®¶â€œåå¤æ¨æ•²â€çš„è®¤çŸ¥è¿‡ç¨‹ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†

| æ•°æ®é›† | æè¿° |
|-------|------|
| **HLE (Humanity's Last Exam)** | ä¸“å®¶çº§ç§‘å­¦æ¨ç†åŸºå‡†ï¼ŒåŒ…å« 2158 ä¸ªè·¨å­¦ç§‘éš¾é¢˜ï¼ˆæ•°å­¦å  45.23%ï¼‰ï¼Œå¼ºè°ƒå¤šè·³å› æœæ¨ç†ä¸æŠ—æ£€ç´¢ç‰¹æ€§ã€‚ |
| **GAIA** | çœŸå®ä¸–ç•Œä»»åŠ¡åŸºå‡†ï¼Œéœ€å¤šæ­¥è§„åˆ’ã€å·¥å…·ä½¿ç”¨ï¼ˆweb search, calculatorï¼‰ï¼Œå…± 103 ä¸ªæ–‡æœ¬ä»»åŠ¡ï¼Œåˆ†ä¸‰çº§éš¾åº¦ã€‚ |
| **XBench-DeepSearch** | èšç„¦æ·±åº¦æœç´¢èƒ½åŠ›çš„ä¸“ä¸šå¯¹é½åŸºå‡†ï¼Œå« 100 ä¸ªéœ€è·¨æºæ¨ç†ä¸ç»¼åˆçš„ä»»åŠ¡ï¼Œè¦†ç›–å•†ä¸šã€ç§‘æŠ€ã€å¨±ä¹ç­‰é¢†åŸŸã€‚ |

---

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

- **è¯„ä¼°æ–¹å¼**ï¼šé‡‡ç”¨ **LLM-as-a-Judge** æ¡†æ¶ï¼š
  - HLE ä½¿ç”¨ `o3-mini-2025-01-31` åˆ¤æ–­ï¼›
  - GAIA ä¸ XBench ä½¿ç”¨ `gpt-4.1-2025-04-14`ã€‚
- **ä¸»æŒ‡æ ‡**ï¼š
  - **Pass@1 / Pass@5**ï¼šå‰ 1 æˆ–å‰ 5 ä¸ªå€™é€‰ä¸­çš„æ­£ç¡®ç‡ã€‚
  - **Hit Rate**ï¼šè‡³å°‘æœ‰ä¸€ä¸ªæ­£ç¡®ç­”æ¡ˆçš„æ¯”ä¾‹ã€‚
  - **HLE Score**ï¼šå®˜æ–¹è¯„åˆ†æ ‡å‡†ä¸‹çš„å‡†ç¡®ç‡ã€‚
- **åŸºçº¿æ–¹æ³•**ï¼š
  - **Foundation Models with Tools**ï¼šGPT-5-high, Gemini-3-Pro, Kimi K2, Claude-4.5-Sonnet ç­‰ã€‚
  - **Existing Inference Frameworks**ï¼šWebExplorer, OpenAI DeepResearch, Tongyi DeepResearch, MiroThinker-v1.0ã€‚

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”

| ç±»å‹ | ä»£è¡¨æ–¹æ³• |
|------|--------|
| å•æ¨¡å‹ + å·¥å…· | GPT-5-high, Gemini-3-Pro |
| å¤šæ™ºèƒ½ä½“æ¡†æ¶ | WebExplorer, MiroThinker |
| æ·±åº¦ç ”ç©¶ç³»ç»Ÿ | Tongyi DeepResearch, OpenAI DeepResearch |

ReThinker åˆ†åˆ«åŸºäº **Gemini-3-Pro** å’Œ **OpenPangu-72B** å®ç°ï¼Œä»¥éªŒè¯é€šç”¨æ€§ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| æ–¹æ³• | HLE (%) | GAIA (%) | XBench (%) |
|------|--------|---------|-----------|
| GPT-5-high | 35.2 | 76.4 | 77.8 |
| Gemini-3-Pro | 38.3 | 79.0 | 87.0 |
| MiroThinker-v1.0 | 33.4 | 73.5 | 70.6 |
| Tongyi DeepResearch | 32.9 | 70.9 | 75.0 |
| **ReThinker (Gemini-3-Pro)** | **52.2** | **81.6** | **90.0** |

> âœ… **ReThinker åœ¨æ‰€æœ‰ä¸‰é¡¹åŸºå‡†ä¸Šå‡è¾¾åˆ° SOTA æ€§èƒ½**

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

- **åœ¨ HLE ä¸Š**ï¼š
  - æ¯”æœ€å¼ºåŸºç¡€æ¨¡å‹ **Gemini-3-Pro** æå‡ **+13.9 pp**ã€‚
  - æ¯”ç°æœ‰æœ€ä½³æ¨ç†æ¡†æ¶ **MiroThinker** æå‡ **+18.8 pp**ã€‚
- **åœ¨ GAIA ä¸Š**ï¼š
  - è¾¾åˆ° **81.6%** å‡†ç¡®ç‡ï¼Œè¶…è¶Šæ‰€æœ‰åŒç±»ç³»ç»Ÿã€‚
- **åœ¨ XBench ä¸Š**ï¼š
  - è¾¾åˆ° **90.0%**ï¼Œæ˜¾è‘—ä¼˜äº Gemini-3-Pro çš„ 87.0%ã€‚

> ğŸ” ç‰¹åˆ«æ˜¯åœ¨ **Engineering** å’Œ **Physics** ç­‰é«˜éš¾åº¦é¢†åŸŸï¼ŒReThinker è¡¨ç°å‡ºæ›´å¼ºçš„çŸ¥è¯†æ•´åˆä¸å·¥å…·åè°ƒèƒ½åŠ›ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ï¼ˆ1ï¼‰Solver é˜¶æ®µï¼šRe-Answer Synthesis
| é…ç½® | Pass@5 |
|------|--------|
| åˆå§‹ Solver | 38.00% |
| åŠ å…¥ Re-Answer | 39.40% (+1.4%) |

âœ… å°å¹…æå‡ä½†æœ‰åŠ©äºå‡å°‘ä½çº§é”™è¯¯ï¼Œä¸ºåç»­æ¨¡å—å‡è½»è´Ÿæ‹…ã€‚

#### ï¼ˆ2ï¼‰Critic é˜¶æ®µï¼šGuided Reflection
| é…ç½® | Pass@5 |
|------|--------|
| Re-Answer Solver | 39.40% |
| + Final Answer Only | 40.40% |
| + Summary Only | 42.00% |
| **+ Summary & Guidance** | **43.20%** |

âœ… ç»“æ„åŒ–æŒ‡å¯¼ï¼ˆsummary + improvement areasï¼‰å¸¦æ¥æœ€å¤§å¢ç›Šï¼ˆ+3.8%ï¼‰ï¼Œè¯æ˜ **guided reflection** æ˜¯å…³é”®ã€‚

#### ï¼ˆ3ï¼‰Selector é˜¶æ®µï¼šConfidence-Guided Selectionï¼ˆTable 4ï¼‰
| é˜¶æ®µ | Hit Rate | Pass@1 |
|------|--------|--------|
| Initial Judgement | 65.27% | 28.20% |
| + Iterative Re-selection | 68.05% | 29.40% |
| + Perplexity Guidance | 69.44% | 30.00% |
| **+ Latin Square Rank** | **70.83%** | **30.60%** |

âœ… å„ç»„ä»¶äº’è¡¥ï¼š
- è¿­ä»£é‡é€‰æå‡ç¨³å®šæ€§ï¼›
- å›°æƒ‘åº¦å¼•å¯¼æœ‰æ•ˆè¯†åˆ«ä¸ç¡®å®šæ€§ï¼›
- æ‹‰ä¸æ–¹æ’åˆ—æ¶ˆé™¤ä½ç½®åè§ï¼ˆ+1.39% Pass@1ï¼‰ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. **â€œå†æ€è€ƒâ€æœºåˆ¶æ˜¾è‘—æå‡ç§‘å­¦æ¨ç†èƒ½åŠ›**  
   ReThinker é€šè¿‡ **Solver â†’ Critic â†’ Selector** çš„ä¸‰é˜¶æ®µå¾ªç¯ï¼Œå®ç°äº†ç±»ä¼¼äººç±»ç§‘å­¦å®¶çš„â€œè´¨ç–‘â€”åæ€â€”ç¡®è®¤â€è¿‡ç¨‹ï¼Œæ˜¾è‘—ä¼˜äºå•æ¬¡æ¨ç†æˆ–ç®€å•é›†æˆã€‚

2. **Guided Reflection æ¯”æ™®é€šæ€»ç»“æ›´æœ‰æ•ˆ**  
   Critic æ¨¡å—ä¸ä»…æ€»ç»“è½¨è¿¹ï¼Œè¿˜è¾“å‡ºå…·ä½“æ”¹è¿›å»ºè®®ï¼ˆå¦‚é€»è¾‘æ¼æ´ã€çŸ¥è¯†ç›²åŒºï¼‰ï¼Œä½¿æ¨¡å‹èƒ½é’ˆå¯¹æ€§ä¿®æ­£è€Œéæ³›åŒ–çº é”™ã€‚

3. **Perplexity æ˜¯å¯é çš„ç½®ä¿¡åº¦ä»£ç†æŒ‡æ ‡**  
   å®éªŒæ˜¾ç¤ºï¼Œæ­£ç¡®ç­”æ¡ˆæ™®éå…·æœ‰æ›´ä½çš„å›°æƒ‘åº¦ï¼ˆFigure 5ï¼‰ï¼Œè¯´æ˜å†…éƒ¨ä¸€è‡´æ€§å¯ç”¨äºæŒ‡å¯¼é€‰æ‹©ä¸èµ„æºåˆ†é…ã€‚

4. **è‡ªåŠ¨åŒ–æ•°æ®åˆæˆå¯è¡Œä¸”é«˜æ•ˆ**  
   æ— éœ€äººå·¥æ ‡æ³¨ï¼Œå³å¯æ„å»ºé«˜è´¨é‡çš„å¤šè½®æ¨ç†è®­ç»ƒæ•°æ®ï¼Œæ”¯æŒç«¯åˆ°ç«¯è®­ç»ƒã€‚

5. **ReThinker æ”¾å¤§å¼ºåŸºåº§æ¨¡å‹æ½œåŠ›**  
   åœ¨ Gemini-3-Pro ä¸Šçš„è¡¨ç°è¿œè¶… OpenPangu-72Bï¼Œè¡¨æ˜è¯¥æ¡†æ¶èƒ½æ›´å¥½é‡Šæ”¾å…ˆè¿› LLM çš„æ½œèƒ½ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§

1. **å»¶è¿Ÿå¢åŠ **  
   ä¸‰é˜¶æ®µä¸²è¡Œç»“æ„å¯¼è‡´ wall-clock time å¢åŠ çº¦ **1.5Ã—**ï¼Œä¸é€‚åˆå®æ—¶å“åº”åœºæ™¯ã€‚

2. **ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶**  
   å½“å‰ 128K ä¸Šä¸‹æ–‡ä»ä¸è¶³ä»¥å¤„ç†æé•¿ç¨‹ç§‘å­¦ä»»åŠ¡ï¼ˆå¦‚æ•´ç¯‡è®ºæ–‡åˆ†æï¼‰ã€‚

3. **å·¥å…·é€šç”¨æ€§ä¸è¶³**  
   å½“å‰ä»…ä½¿ç”¨ web_searchã€web_parse å’Œ execute_python_codeï¼Œç¼ºä¹é¢†åŸŸä¸“ç”¨å·¥å…·ï¼ˆå¦‚ç¬¦å·å®šç†è¯æ˜å™¨ã€åŒ–å­¦æ€§è´¨é¢„æµ‹å™¨ï¼‰ã€‚

4. **å¯¹åŸºåº§æ¨¡å‹ä¾èµ–è¾ƒå¼º**  
   åœ¨å¼±æ¨¡å‹ä¸Šå¢ç›Šæœ‰é™ï¼Œæç¤ºæ¡†æ¶æœ¬èº«ä¸èƒ½å®Œå…¨å¼¥è¡¥æ¨¡å‹èƒ½åŠ›çŸ­æ¿ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. **å¹¶è¡ŒåŒ–é˜¶æ®µæ‰§è¡Œ**  
   æ¢ç´¢ Solver/Critic/Selector å¹¶è¡Œè¿è¡Œï¼Œé™ä½å»¶è¿Ÿã€‚

2. **åŠ¨æ€ä¸Šä¸‹æ–‡ç®¡ç†**  
   å¼•å…¥è®°å¿†å‹ç¼©ã€å…³é”®ä¿¡æ¯æå–ç­‰æœºåˆ¶çªç ´ context window é™åˆ¶ã€‚

3. **é›†æˆä¸“ç”¨å·¥å…·é“¾**  
   èåˆ symbolic solversã€æ•°æ®åº“æŸ¥è¯¢å¼•æ“ã€ä»¿çœŸç¯å¢ƒç­‰ï¼Œæå‡ç‰¹å®šé¢†åŸŸè¡¨ç°ã€‚

4. **è‡ªé€‚åº”å·¥å…·è°ƒç”¨ç­–ç•¥**  
   å¼€å‘æ›´æ™ºèƒ½çš„ tool invocation policyï¼Œé¿å…å†—ä½™è°ƒç”¨ä¸å¤±è´¥é£é™©ã€‚

5. **è½»é‡åŒ–ç‰ˆæœ¬è®¾è®¡**  
   æ¢ç´¢é€‚ç”¨äºè¾¹ç¼˜è®¾å¤‡æˆ–ä½æˆæœ¬éƒ¨ç½²çš„ç®€åŒ–ç‰ˆ ReThinkerã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> ReThinker é€šè¿‡ **guided reflection + confidence control + automated data synthesis**ï¼Œæ„å»ºäº†ä¸€ä¸ªç±»äººç§‘å­¦å®¶çš„â€œå†æ€è€ƒâ€æ¨ç†æ¡†æ¶ï¼Œåœ¨ä¸“å®¶çº§ç§‘å­¦ä»»åŠ¡ä¸Šå®ç°äº† SOTA è¡¨ç°ï¼Œæ ‡å¿—ç€å‘é€šç”¨äººå·¥æ™ºèƒ½è¿ˆå‡ºé‡è¦ä¸€æ­¥ã€‚

</details>

---

### 11. [LinGO: A Linguistic Graph Optimization Framework with LLMs for Interpreting Intents of Online Uncivil Discourse](https://arxiv.org/abs/2602.04693)

**Authors**: Yuan Zhang, Thales Bertaglia  
**Category**: cs.CL  
**Published**: 2026-02-05  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.04693v1  

#### Abstract
Detecting uncivil language is crucial for maintaining safe, inclusive, and democratic online spaces. Yet existing classifiers often misinterpret posts containing uncivil cues but expressing civil intents, leading to inflated estimates of harmful incivility online. We introduce LinGO, a linguistic gr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*LinGO: A Linguistic Graph Optimization Framework with LLMs for Interpreting Intents of Online Uncivil Discourse*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ç°æœ‰åŸºäºAIçš„**uncivil languageæ£€æµ‹æ¨¡å‹**åœ¨å¤„ç†å¤æ‚è¯­å¢ƒæ—¶å­˜åœ¨ä¸¥é‡è¯¯åˆ¤ï¼Œå°¤å…¶æ˜¯å¯¹åŒ…å«ä¸æ–‡æ˜çº¿ç´¢ä½†è¡¨è¾¾æ–‡æ˜æ„å›¾ï¼ˆå¦‚åè®½ã€å¼•ç”¨ä»–äººè¨€è®ºè¿›è¡Œæ‰¹è¯„ï¼‰çš„æ–‡æœ¬ï¼Œå®¹æ˜“å°†å…¶é”™è¯¯å½’ç±»ä¸ºæœ‰å®³è¨€è®ºï¼Œå¯¼è‡´**åœ¨çº¿ä¸æ–‡æ˜è¡Œä¸ºçš„æµè¡Œç‡è¢«é«˜ä¼°**ã€‚æ­¤å¤–ï¼Œä¼ ç»Ÿæ–¹æ³•éš¾ä»¥è§£é‡Šé—´æ¥è¡¨è¾¾ï¼ˆindirect expressionsï¼‰èƒŒåçš„**çœŸå®æ„å›¾ï¼ˆintentï¼‰**ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šLinGO æ¡†æ¶
æœ¬æ–‡æå‡º **LinGO**ï¼ˆLinguistic Graph Optimizationï¼‰ï¼Œä¸€ç§ç»“åˆ**è¯­è¨€å­¦ç»“æ„**ä¸**LLMä¼˜åŒ–æŠ€æœ¯**çš„å¤šæ­¥æ¨ç†æ¡†æ¶ï¼Œç”¨äºæ›´å‡†ç¡®åœ°è¯†åˆ«ç½‘ç»œä¸æ–‡æ˜è¯è¯­ä¸­çš„å…­ç§æ„å›¾ç±»åˆ«ï¼š

- **Explicit (1)**ï¼šç›´æ¥æ”»å‡»  
- **Implicit (2)**ï¼šéšå«æ”»å‡»  
- **Report (3)**ï¼šå¼•ç”¨å¹¶ä¸­ç«‹æŠ¥é“  
- **Intensify (4)**ï¼šæ”¾å¤§/æ”¯æŒä»–äººæ”»å‡»  
- **Counter (5)**ï¼šæ‰¹åˆ¤/åå¯¹ä»–äººæ”»å‡»ï¼ˆå³åè¨€è¾ï¼‰  
- **Escalate (6)**ï¼šä»¥æ”»å‡»å›åº”æ”»å‡»  

è¯¥æ¡†æ¶é€šè¿‡æ„å»ºä¸€ä¸ª**åŸºäºè¯­è¨€ç»“æ„çš„æœ‰å‘å›¾ï¼ˆLinguistic Graphï¼‰**ï¼Œå°†å¥å­ç†è§£åˆ†è§£ä¸ºå¤šä¸ªé€»è¾‘æ­¥éª¤ï¼ˆå¦‚æ˜¯å¦å¼•ç”¨ä»–äºº â†’ å¼•ç”¨å†…å®¹æ˜¯å¦ä¸æ–‡æ˜ â†’ ä½œè€…ç«‹åœºå¦‚ä½•ï¼‰ï¼Œå®ç°ç»†ç²’åº¦æ„å›¾åˆ†ç±»ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | LinGO çš„ä¼˜åŠ¿ |
|------|-------------|
| **å¯è§£é‡Šæ€§** | æ˜¾å¼å»ºæ¨¡æ¨ç†è·¯å¾„ï¼Œè¾“å‡ºå®Œæ•´ reasoning chainï¼Œæå‡æ¨¡å‹å†³ç­–é€æ˜åº¦ï¼ˆExplainable AIï¼‰ |
| **æŠ—è¯¯å·®ä¼ æ’­èƒ½åŠ›** | è¯†åˆ«æ˜“é”™èŠ‚ç‚¹å¹¶é’ˆå¯¹æ€§ä¼˜åŒ–ï¼ˆtargeted step optimizationï¼‰ï¼Œç¼“è§£ multi-step æ¨ç†ä¸­çš„ error propagation |
| **çµæ´»æ€§ä¸é€šç”¨æ€§** | å¯é›†æˆå¤šç§ LLM optimization æŠ€æœ¯ï¼ˆå¦‚ RAG, TextGrad, DSPyï¼‰ï¼Œé€‚ç”¨äºä¸åŒæ¨¡å‹å’Œä»»åŠ¡åœºæ™¯ |
| **æ€§èƒ½æå‡æ˜¾è‘—** | åœ¨å¤šä¸ª LLM ä¸Šå‡ä¼˜äº zero-shotã€CoT å’Œ fine-tuning åŸºçº¿ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **æ¥æº**ï¼šæ¥è‡ª [Zhang et al., 2025] æ”¶é›†çš„è‘¡è„ç‰™è¯­ Twitter/X æ•°æ®ï¼Œæ¶µç›– **2022å¹´å·´è¥¿æ€»ç»Ÿå¤§é€‰æœŸé—´æ”¿æ²»å½±å“è€…å‘å¸ƒçš„æ¨æ–‡**
- **è§„æ¨¡**ï¼šå…± 2,000 æ¡æ ‡æ³¨æ ·æœ¬ï¼ˆæ¯ç±»æ”¿æ²»ä¸æ–‡æ˜å½¢å¼å„ 500 æ¡ï¼‰
- **æ ‡æ³¨å†…å®¹**ï¼š
  - æœ€ç»ˆæ„å›¾æ ‡ç­¾ï¼ˆ0â€“6ï¼‰
  - æ¯ä¸ª linguistic graph èŠ‚ç‚¹çš„ä¸­é—´åˆ¤æ–­ï¼ˆsub-step answersï¼‰
- **å››ç±»æ”¿æ²»ä¸æ–‡æ˜å½¢å¼ï¼ˆCategoriesï¼‰**ï¼š
  - Impoliteness (IMP)
  - Hate Speech and Stereotyping (HSST)
  - Physical Harm and Violent Political Rhetoric (PHAVPR)
  - Threats to Democratic Institutions and Values (THREAT)

### âš™ï¸ å®éªŒè®¾ç½®
| ç»„ä»¶ | é…ç½® |
|------|------|
| **ä¸»å¹² LLMsï¼ˆInstruction Modelsï¼‰** | GPT-5-mini, Gemini 2.5 Flash-Lite, Claude 3 Haikuï¼ˆå‡ä¸ºè½»é‡çº§ã€ä½æˆæœ¬å•†ç”¨æ¨¡å‹ï¼‰ |
| **Teacher/Refinement Model** | GPT-5-miniï¼ˆç”¨äº TextGradã€AdalFlow ç­‰æ¢¯åº¦ä¿¡å·ç”Ÿæˆï¼‰ |
| **å¼€æºå¾®è°ƒæ¨¡å‹** | Mistral-7B, DeepSeek-V2-Lite-Chat, Qwen3-4B-Instruct-2507ï¼ˆLoRA fine-tuningï¼‰ |
| **æ•°æ®åˆ’åˆ†** | å¼€å‘é›† 80%ï¼ˆè®­ç»ƒ+éªŒè¯ï¼‰ï¼Œæµ‹è¯•é›† 20% |
| **ä¼˜åŒ–è½®æ¬¡ï¼ˆRoundsï¼‰** | 5 è½®è¿­ä»£ä¼˜åŒ– |
| **é˜ˆå€¼ï¼ˆThreshold Tï¼‰** | æ­¥éª¤é”™è¯¯ç‡ > 0.1 åˆ™è§¦å‘ä¼˜åŒ– |

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
- **Accuracy**
- **Weighted F1-score**ï¼ˆå› ç±»åˆ«æåº¦ä¸å¹³è¡¡ï¼Œä¸ºä¸»è¦å…³æ³¨æŒ‡æ ‡ï¼‰

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | æ–¹æ³• |
|------|------|
| **åŸºç¡€æç¤ºæ³•** | Zero-Shot Prompting, Chain-of-Thought (CoT) |
| **é«˜çº§ä¼˜åŒ–æ³•ï¼ˆæ— è¯­è¨€å›¾ï¼‰** | Direct Optimization usingï¼š<br>â€¢ TextGrad<br>â€¢ AdalFlow<br>â€¢ DSPy<br>â€¢ RAG |
| **å‚æ•°æ›´æ–°æ³•** | LoRA Fine-tuningï¼ˆå¼€æºæ¨¡å‹ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæœ€ä½³è¡¨ç°ï¼‰

| æ–¹æ³• | æ¨¡å‹ | Accuracy | Weighted F1 |
|------|------|----------|------------|
| **LinGO + RAG** | **Gemini 2.5 Flash-Lite** | **0.690** | **0.699** |
| LinGO + DSPy | Gemini 2.5 Flash-Lite | 0.648 | 0.665 |
| LinGO + RAG | GPT-5-mini | 0.655 | 0.677 |
| Direct Optimization + RAG | Gemini 2.5 Flash-Lite | 0.640 | 0.664 |
| CoT Prompting | GPT-5-mini | 0.583 | 0.578 |
| Zero-Shot | GPT-5-mini | 0.518 | 0.513 |
| LoRA Fine-tuningï¼ˆæœ€ä¼˜ï¼‰ | Qwen3-4B-Instruct | 0.590 | 0.535 |

> âœ… **LinGO + RAG åœ¨ Gemini ä¸Šè¾¾åˆ°æœ€é«˜æ€§èƒ½ï¼š+10.7pp Accuracy å’Œ +12.1pp Weighted F1 è¶…è¿‡æœ€å¼º CoT åŸºçº¿**

### ğŸ”½ ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ
- æ‰€æœ‰æ¨¡å‹ä¸Šï¼Œ**LinGO å‡ä¼˜äº zero-shot å’Œ CoT**
- åŠ å…¥ä¼˜åŒ–æŠ€æœ¯åï¼Œ**RAG è¡¨ç°æœ€ç¨³å®šä¸”æœ€å¼º**ï¼Œä¼˜äº TextGrad å’Œ AdalFlow
- **é™¤ Claude 3 Haiku å¤–ï¼ŒLinGO åœ¨æ‰€æœ‰æ¨¡å‹ä¸Šè¿›ä¸€æ­¥æå‡äº† direct optimization çš„æ•ˆæœ**
- **Claude è¡¨ç°è¾ƒå·®**ï¼Œå¯èƒ½å› å…¶è¯­ä¹‰ç†è§£è¾ƒå¼±ï¼Œmulti-step æ¨ç†ä¸­ error propagation æ›´ä¸¥é‡

### ğŸ” æ¶ˆèå®éªŒä¸å…³é”®å‘ç°
#### ï¼ˆ1ï¼‰ä¸åŒä¼˜åŒ–æŠ€æœ¯æ¯”è¾ƒ
| æŠ€æœ¯ | ç‰¹ç‚¹ | æ•ˆæœ |
|------|------|------|
| **RAG** | åŸºäºç›¸ä¼¼æ€§æ£€ç´¢é«˜è´¨é‡ few-shot ç¤ºä¾‹ | âœ… æœ€æœ‰æ•ˆï¼Œå°¤å…¶åœ¨ Gemini ä¸Š |
| **DSPy** | åº¦é‡é©±åŠ¨è‡ªä¸¾æ„é€  prompt | âœ… ç¨³å®šæå‡ï¼Œä¼˜äºæ¢¯åº¦æ³• |
| **TextGrad / AdalFlow** | æ–‡æœ¬æ¢¯åº¦ä¸‹é™ä¼˜åŒ– prompt | âŒ æå‡æœ‰é™ï¼Œæœ‰æ—¶ç”šè‡³åŠ£äº baselineï¼ˆå¯èƒ½å¼•å…¥å™ªå£°æˆ–è¿‡æ‹Ÿåˆï¼‰ |

> ğŸ’¡ ç»“è®ºï¼š**ä¼˜åŒ– demonstration examples æ¯”ä¼˜åŒ– prompt text æ›´æœ‰æ•ˆ**

#### ï¼ˆ2ï¼‰æŒ‰æ„å›¾ç±»åˆ«åˆ†æï¼ˆFig. 3ï¼‰
- **Label 4ï¼ˆIntensifyï¼‰æ— å®ä¾‹**ï¼Œè¯´æ˜æ­¤ç±»è¡Œä¸ºç¨€å°‘
- **ç›´æ¥ä¸æ–‡æ˜ï¼ˆExplicit, Implicitï¼‰F1 æ›´é«˜**
- **é—´æ¥ä¸æ–‡æ˜ï¼ˆReport, Counter, Escalateï¼‰æ›´éš¾è¯†åˆ«**
- **Implicit æ”»å‡»æœ€éš¾æ£€æµ‹**ï¼ˆå·²æœ‰ç ”ç©¶ä¸€è‡´ç»“è®ºï¼‰

#### ï¼ˆ3ï¼‰æŒ‰ä¸æ–‡æ˜ç±»å‹åˆ†æï¼ˆFig. 4ï¼‰
| ç±»åˆ« | è¡¨ç°æ’åº |
|------|--------|
| **PHAVPR**ï¼ˆäººèº«ä¼¤å®³ï¼‰ | âœ… æœ€é«˜ weighted F1 |
| **HSST**ï¼ˆä»‡æ¨è¨€è®ºï¼‰ | âŒ æœ€ä½ weighted F1 |
| **Gemini** | åœ¨ HSST ä¸Šè¡¨ç°ä¼˜äº GPT-5-mini |
| **GPT-5-mini** | åœ¨ PHAVPR å’Œå¼•ç”¨ç±»æ„å›¾ä¸Šæ›´å¼º |

> ğŸ§  å¯ç¤ºï¼š**åº”æ ¹æ®ç›®æ ‡ä»»åŠ¡é€‰æ‹©åˆé€‚æ¨¡å‹**ï¼ˆä¾‹å¦‚ç›‘æµ‹ä»‡æ¨è¨€è®ºå¯ç”¨ Geminiï¼Œç›‘æµ‹æš´åŠ›è¨€è®ºå¯ç”¨ GPT-5-miniï¼‰

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º
1. **LinGO æ˜¾è‘—æå‡ LLM å¯¹å¤æ‚è¯­ä¹‰çš„ç†è§£èƒ½åŠ›**ï¼Œç‰¹åˆ«æ˜¯åœ¨åŒºåˆ†ç›´æ¥ä¸é—´æ¥ä¸æ–‡æ˜è¡¨è¾¾æ–¹é¢ã€‚
2. å°†è¯­è¨€å­¦ç»“æ„ç¼–ç ä¸º multi-step reasoning graphï¼Œå¹¶ç»“åˆè‡ªåŠ¨åŒ– prompt optimizationï¼Œèƒ½æœ‰æ•ˆç¼“è§£ error propagation å¹¶æé«˜åˆ†ç±»å‡†ç¡®æ€§ã€‚
3. **RAG æ˜¯æœ€æœ‰æ•ˆçš„ä¼˜åŒ–ç­–ç•¥**ï¼Œè¡¨æ˜é«˜è´¨é‡ few-shot ç¤ºä¾‹æ¯”ç²¾ç»†è°ƒæ•´ prompt æ›´é‡è¦ã€‚
4. ä¸åŒ LLM åœ¨ä¸åŒç±»å‹ä¸æ–‡æ˜è¯†åˆ«ä¸Šæœ‰ä¸“é•¿ï¼Œå»ºè®®æ ¹æ®åº”ç”¨åœºæ™¯è¿›è¡Œæ¨¡å‹ benchmarkingã€‚
5. è¯¥æ–¹æ³•ä¸ä»…å¯ç”¨äºåˆ†ç±»ï¼Œè¿˜å¯ä½œä¸º post-hoc analysis å·¥å…·ï¼Œè¾…åŠ©äººå·¥å®¡æ ¸æˆ–å·²æœ‰åˆ†ç±»å™¨çš„ç»“æœè§£é‡Šã€‚

### âš ï¸ å±€é™æ€§
1. **ä¾èµ–äººç±»æ ‡æ³¨ä¸­é—´æ­¥éª¤**ï¼Œå¢åŠ äº†æ ‡æ³¨æˆæœ¬ï¼ˆéœ€æä¾›æ¯ä¸ª linguistic node çš„ ground truthï¼‰
2. **è®¡ç®—å¼€é”€è¾ƒå¤§**ï¼šæ¯è½®ä¼˜åŒ–éœ€åœ¨å…¨éªŒè¯é›†ä¸Šè¿è¡Œï¼Œå°½ç®¡ä½¿ç”¨ä½æˆæœ¬æ¨¡å‹æ§åˆ¶é¢„ç®—ï¼ˆ$5â€“$10/å®éªŒï¼‰
3. **é¢†åŸŸä¸è¯­è¨€é™åˆ¶**ï¼šä»…åœ¨å·´è¥¿æ”¿æ²»è¯­å¢ƒä¸‹çš„è‘¡è„ç‰™è¯­æ•°æ®ä¸ŠéªŒè¯ï¼Œæ³›åŒ–æ€§æœ‰å¾…æ£€éªŒ
4. **ç±»åˆ«ä¸å¹³è¡¡ä¸¥é‡**ï¼šéƒ¨åˆ†ç±»åˆ«ï¼ˆå¦‚ Intensifyï¼‰å‡ ä¹ä¸å­˜åœ¨ï¼Œå½±å“æ¨¡å‹å­¦ä¹ 

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³æ›´å¤šæ–‡åŒ–èƒŒæ™¯ã€è¯­è¨€å’Œä¸æ–‡æ˜ç±»å‹ï¼ˆå¦‚æ€§åˆ«æ­§è§†ã€å®—æ•™ä»‡æ¨ç­‰ï¼‰
- æ¢ç´¢è‡ªåŠ¨æ ‡æ³¨ä¸­é—´æ­¥éª¤çš„æ–¹æ³•ï¼ˆå‡å°‘äººå·¥å¹²é¢„ï¼‰
- å°†æ¡†æ¶åº”ç”¨äºå…¶ä»–éœ€è¦å¤šæ­¥æ¨ç†çš„ä»»åŠ¡ï¼ˆå¦‚æ³•å¾‹æ–‡æœ¬è§£æã€äº‹å®æ ¸æŸ¥ï¼‰
- ç»“åˆ real-time moderation system è¿›è¡Œéƒ¨ç½²æµ‹è¯•

---

## æ€»ç»“ä¸€å¥è¯
> **LinGO é€šè¿‡èåˆè¯­è¨€å­¦å›¾ç»“æ„ä¸ LLM è‡ªåŠ¨ä¼˜åŒ–æŠ€æœ¯ï¼Œå®ç°äº†å¯¹ç½‘ç»œä¸æ–‡æ˜è¯è¯­æ„å›¾çš„ç²¾ç»†åŒ–ã€å¯è§£é‡Šè¯†åˆ«ï¼Œåœ¨å‡†ç¡®æ€§å’Œé²æ£’æ€§ä¸Šå…¨é¢è¶…è¶Šä¸»æµåŸºçº¿æ–¹æ³•ï¼Œä¸ºæ„å»ºæ›´å®‰å…¨ã€æ°‘ä¸»çš„åœ¨çº¿ç©ºé—´æä¾›äº†æœ‰åŠ›å·¥å…·ã€‚**

</details>

---

### 12. [ERNIE 5.0 Technical Report](https://arxiv.org/abs/2602.04705)

**Authors**: Haifeng Wang, Hua Wu, Tian Wu, Yu Sun, Jing Liu, Dianhai Yu, Yanjun Ma, Jingzhou He, Zhongjun He, Dou Hong, Qiwen Liu, Shuohuan Wang, Junyuan Shang, Zhenyu Zhang, Yuchen Ding, Jinle Zeng, Jiabin Yang, Liang Shen, Ruibiao Chen, Weichong Yin, Siyu Ding, Dai Dai, Shikun Feng, Siqi Bao, Bolei He, Yan Chen, Zhenyu Jiao, Ruiqing Zhang, Zeyu Chen, Qingqing Dang, Kaipeng Deng, Jiajun Jiang, Enlei Gong, Guoxia Wang, Yanlin Sha, Yi Liu, Yehan Zheng, Weijian Xu, Jiaxiang Liu, Zengfeng Zeng, Yingqi Qu, Zhongli Li, Zhengkun Zhang, Xiyang Wang, Zixiang Xu, Xinchao Xu, Zhengjie Huang, Dong Wang, Bingjin Chen, Yue Chang, Xing Yuan, Shiwei Huang, Qiao Zhao, Xinzhe Ding, Shuangshuang Qiao, Baoshan Yang, Bihong Tang, Bin Li, Bingquan Wang, Binhan Tang, Binxiong Zheng, Bo Cui, Bo Ke, Bo Zhang, Bowen Zhang, Boyan Zhang, Boyang Liu, Caiji Zhang, Can Li, Chang Xu, Chao Pang, Chao Zhang, Chaoyi Yuan, Chen Chen, Cheng Cui, Chenlin Yin, Chun Gan, Chunguang Chai, Chuyu Fang, Cuiyun Han, Dan Zhang, Danlei Feng, Danxiang Zhu, Dong Sun, Dongbo Li, Dongdong Li, Dongdong Liu, Dongxue Liu, Fan Ding, Fan Hu, Fan Li, Fan Mo, Feisheng Wu, Fengwei Liu, Gangqiang Hu, Gaofeng Lu, Gaopeng Yong, Gexiao Tian, Guan Wang, Guangchen Ni, Guangshuo Wu, Guanzhong Wang, Guihua Liu, Guishun Li, Haibin Li, Haijian Liang, Haipeng Ming, Haisu Wang, Haiyang Lu, Haiye Lin, Han Zhou, Hangting Lou, Hanwen Du, Hanzhi Zhang, Hao Chen, Hao Du, Hao Liu, Hao Zhou, Haochen Jiang, Haodong Tian, Haoshuang Wang, Haozhe Geng, Heju Yin, Hong Chen, Hongchen Xue, Hongen Liu, Honggeng Zhang, Hongji Xu, Hongwei Chen, Hongyang Zhang, Hongyuan Zhang, Hua Lu, Huan Chen, Huan Wang, Huang He, Hui Liu, Hui Zhong, Huibin Ruan, Jiafeng Lu, Jiage Liang, Jiahao Hu, Jiahao Hu, Jiajie Yang, Jialin Li, Jian Chen, Jian Wu, Jianfeng Yang, Jianguang Jiang, Jianhua Wang, Jianye Chen, Jiaodi Liu, Jiarui Zhou, Jiawei Lv, Jiaxin Zhou, Jiaxuan Liu, Jie Han, Jie Sun, Jiefan Fang, Jihan Liu, Jihua Liu, Jing Hu, Jing Qian, Jing Yan, Jingdong Du, Jingdong Wang, Jingjing Wu, Jingyong Li, Jinheng Wang, Jinjin Li, Jinliang Lu, Jinlin Yu, Jinnan Liu, Jixiang Feng, Jiyi Huang, Jiyuan Zhang, Jun Liang, Jun Xia, Jun Yu, Junda Chen, Junhao Feng, Junhong Xiang, Junliang Li, Kai Liu, Kailun Chen, Kairan Su, Kang Hu, Kangkang Zhou, Ke Chen, Ke Wei, Kui Huang, Kun Wu, Kunbin Chen, Lei Han, Lei Sun, Lei Wen, Linghui Meng, Linhao Yu, Liping Ouyang, Liwen Zhang, Longbin Ji, Longzhi Wang, Meng Sun, Meng Tian, Mengfei Li, Mengqi Zeng, Mengyu Zhang, Ming Hong, Mingcheng Zhou, Mingming Huang, Mingxin Chen, Mingzhu Cai, Naibin Gu, Nemin Qiu, Nian Wang, Peng Qiu, Peng Zhao, Pengyu Zou, Qi Wang, Qi Xin, Qian Wang, Qiang Zhu, Qianhui Luo, Qianwei Yang, Qianyue He, Qifei Wu, Qinrui Li, Qiwen Bao, Quan Zhang, Quanxiang Liu, Qunyi Xie, Rongrui Zhan, Rufeng Dai, Rui Peng, Ruian Liu, Ruihao Xu, Ruijie Wang, Ruixi Zhang, Ruixuan Liu, Runsheng Shi, Ruting Wang, Senbo Kang, Shan Lu, Shaofei Yu, Shaotian Gong, Shenwei Hu, Shifeng Zheng, Shihao Guo, Shilong Fan, Shiqin Liu, Shiwei Gu, Shixi Zhang, Shuai Yao, Shuang Zhang, Shuangqiao Liu, Shuhao Liang, Shuwei He, Shuwen Yang, Sijun He, Siming Dai, Siming Wu, Siyi Long, Songhe Deng, Suhui Dong, Suyin Liang, Teng Hu, Tianchan Xu, Tianliang Lv, Tianmeng Yang, Tianyi Wei, Tiezhu Gao, Ting Sun, Ting Zhang, Tingdan Luo, Wei He, Wei Luan, Wei Yin, Wei Zhang, Wei Zhou, Weibao Gong, Weibin Li, Weicheng Huang, Weichong Dang, Weiguo Zhu, Weilong Zhang, Weiqi Tan, Wen Huang, Wenbin Chang, Wenjing Du, Wenlong Miao, Wenpei Luo, Wenquan Wu, Xi Shi, Xi Zhao, Xiang Gao, Xiangguo Zhang, Xiangrui Yu, Xiangsen Wang, Xiangzhe Wang, Xianlong Luo, Xianying Ma, Xiao Tan, Xiaocong Lin, Xiaofei Wang, Xiaofeng Peng, Xiaofeng Wu, Xiaojian Xu, Xiaolan Yuan, Xiaopeng Cui, Xiaotian Han, Xiaoxiong Liu, Xiaoxu Fei, Xiaoxuan Wu, Xiaoyu Wang, Xiaoyu Zhang, Xin Sun, Xin Wang, Xinhui Huang, Xinming Zhu, Xintong Yu, Xinyi Xu, Xinyu Wang, Xiuxian Li, XuanShi Zhu, Xue Xu, Xueying Lv, Xuhong Li, Xulong Wei, Xuyi Chen, Yabing Shi, Yafeng Wang, Yamei Li, Yan Liu, Yanfu Cheng, Yang Gao, Yang Liang, Yang Wang, Yang Wang, Yang Yang, Yanlong Liu, Yannian Fu, Yanpeng Wang, Yanzheng Lin, Yao Chen, Yaozong Shen, Yaqian Han, Yehua Yang, Yekun Chai, Yesong Wang, Yi Song, Yichen Zhang, Yifei Wang, Yifeng Guo, Yifeng Kou, Yilong Chen, Yilong Guo, Yiming Wang, Ying Chen, Ying Wang, Yingsheng Wu, Yingzhan Lin, Yinqi Yang, Yiran Xing, Yishu Lei, Yixiang Tu, Yiyan Chen, Yong Zhang, Yonghua Li, Yongqiang Ma, Yongxing Dai, Yongyue Zhang, Yu Ran, Yu Sun, Yu-Wen Michael Zhang, Yuang Liu, Yuanle Liu, Yuanyuan Zhou, Yubo Zhang, Yuchen Han, Yucheng Wang, Yude Gao, Yuedong Luo, Yuehu Dong, Yufeng Hu, Yuhui Cao, Yuhui Yun, Yukun Chen, Yukun Gao, Yukun Li, Yumeng Zhang, Yun Fan, Yun Ma, Yunfei Zhang, Yunshen Xie, Yuping Xu, Yuqin Zhang, Yuqing Liu, Yurui Li, Yuwen Wang, Yuxiang Lu, Zefeng Cai, Zelin Zhao, Zelun Zhang, Zenan Lin, Zezhao Dong, Zhaowu Pan, Zhaoyu Liu, Zhe Dong, Zhe Zhang, Zhen Zhang, Zhengfan Wu, Zhengrui Wei, Zhengsheng Ning, Zhenxing Li, Zhenyu Li, Zhenyu Qian, Zhenyun Li, Zhi Li, Zhichao Chen, Zhicheng Dong, Zhida Feng, Zhifan Feng, Zhihao Deng, Zhijin Yu, Zhiyang Chen, Zhonghui Zheng, Zhuangzhuang Guo, Zhujun Zhang, Zhuo Sun, Zichang Liu, Zihan Lin, Zihao Huang, Zihe Zhu, Ziheng Zhao, Ziping Chen, Zixuan Zhu, Ziyang Xu, Ziyi Liang, Ziyuan Gao  
**Category**: cs.CL  
**Published**: 2026-02-05  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.04705v1  

#### Abstract
In this report, we introduce ERNIE 5.0, a natively autoregressive foundation model desinged for unified multimodal understanding and generation across text, image, video, and audio. All modalities are trained from scratch under a unified next-group-of-tokens prediction objective, based on an ultra-s...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# ERNIE 5.0 Technical Report æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰ä¸»æµçš„å¤šæ¨¡æ€æ¨¡å‹é€šå¸¸é‡‡ç”¨â€œlate-fusionâ€è®¾è®¡ï¼Œå³åœ¨é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹åŸºç¡€ä¸Šé™„åŠ æ¨¡æ€ç‰¹å®šçš„ç”Ÿæˆå™¨ï¼ˆå¦‚å›¾åƒè§£ç å™¨ã€è¯­éŸ³åˆæˆæ¨¡å—ï¼‰ï¼Œå¯¼è‡´**ç†è§£ä¸ç”Ÿæˆèƒ½åŠ›å‰²è£‚**ï¼Œä¸”ä¼˜åŒ–ç›®æ ‡ä¸ä¸€è‡´ã€‚è¿™ç§æ¶æ„é™åˆ¶äº†è·¨æ¨¡æ€æ·±åº¦é›†æˆï¼Œå¹¶å¯èƒ½å¼•å‘â€œability seesawâ€ç°è±¡â€”â€”æå‡æŸä¸€æ¨¡æ€æ€§èƒ½ä¼šå‰Šå¼±å…¶ä»–æ¨¡æ€è¡¨ç°ã€‚

æ­¤å¤–ï¼Œå¤§è§„æ¨¡æ¨¡å‹éƒ¨ç½²é¢ä¸´**èµ„æºçº¦æŸå¤šæ ·æ€§**æŒ‘æˆ˜ï¼šä¸åŒåœºæ™¯å¯¹å»¶è¿Ÿã€å†…å­˜å’Œè®¡ç®—èƒ½åŠ›è¦æ±‚å„å¼‚ï¼Œä¼ ç»Ÿâ€œtrain-then-compressâ€æµç¨‹æˆæœ¬é«˜æ˜‚ä¸”ç¼ºä¹çµæ´»æ€§ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

#### âœ… **ç»Ÿä¸€è‡ªå›å½’æ¡†æ¶ï¼ˆUnified Autoregressive Frameworkï¼‰**
- æ‰€æœ‰æ¨¡æ€ï¼ˆtext, image, video, audioï¼‰å‡ä»é›¶å¼€å§‹è”åˆè®­ç»ƒï¼Œå…±äº«ä¸€ä¸ª **Next-Group-of-Tokens Prediction** ç›®æ ‡ã€‚
- å›¾åƒ/è§†é¢‘ç”Ÿæˆé€šè¿‡ **Next-Frame-and-Scale Prediction (NFSP)** å®ç°ï¼›éŸ³é¢‘ç”Ÿæˆé‡‡ç”¨ **Next-Codec Prediction (NCP)**ã€‚
- ç»Ÿä¸€å»ºæ¨¡é¿å…äº†æ¨¡æ€è¾¹ç•Œæ˜¾å¼åˆ’åˆ†ï¼Œå®ç°ç«¯åˆ°ç«¯è·¨æ¨¡æ€äº¤äº’ã€‚

#### âœ… **è¶…ç¨€ç– MoE æ¶æ„ + æ¨¡æ€æ— å…³ä¸“å®¶è·¯ç”±ï¼ˆModality-Agnostic Expert Routingï¼‰**
- é‡‡ç”¨ ultra-sparse Mixture-of-Expertsï¼ˆMoEï¼‰ä¸»å¹²ç½‘ç»œï¼Œæ¿€æ´»ç‡ä½äº 3%ï¼Œæ˜¾è‘—é™ä½æ¨ç†å¼€é”€ã€‚
- è·¯ç”±å™¨åŸºäºç»Ÿä¸€ token è¡¨ç¤ºè¿›è¡Œå†³ç­–ï¼Œè€Œéä¾èµ–æ¨¡æ€æ ‡è¯†ç¬¦ï¼Œå…è®¸ä¸åŒæ¨¡æ€ token å…±äº«åŒä¸€ç»„ä¸“å®¶æ± ã€‚
- å®ç°è·¨æ¨¡æ€å‚æ•°å…±äº«ä¸çŸ¥è¯†æ³›åŒ–ï¼Œæ— éœ€æ‰‹åŠ¨åˆ†é…æ¨¡æ€ä¸“å±ä¸“å®¶ã€‚

#### âœ… **å¼¹æ€§è®­ç»ƒèŒƒå¼ï¼ˆElastic Trainingï¼‰**
- é¦–æ¬¡å°† Once-For-All æ€æƒ³å¼•å…¥ pre-training é˜¶æ®µï¼Œåœ¨å•æ¬¡è®­ç»ƒä¸­å­¦ä¹ ä¸€ç³»åˆ—å­æ¨¡å‹ã€‚
- æ”¯æŒä¸‰ä¸ªç»´åº¦çš„å¼¹æ€§é…ç½®ï¼š
  - **Elastic Depth**ï¼šåŠ¨æ€è°ƒæ•´ Transformer å±‚æ•°
  - **Elastic Width**ï¼šå˜åŒ–æ¯å±‚ MoE ä¸­ä¸“å®¶æ€»æ•°
  - **Elastic Sparsity**ï¼šè°ƒèŠ‚æ¯ä¸ª token æ¿€æ´»çš„ä¸“å®¶æ•°ï¼ˆtop-kï¼‰
- å¯çµæ´»å®ä¾‹åŒ–æ»¡è¶³ä¸åŒç¡¬ä»¶/å»¶è¿Ÿéœ€æ±‚çš„å­æ¨¡å‹ï¼Œæ— éœ€é‡å¤è®­ç»ƒæˆ–å‹ç¼©ã€‚

#### âœ… **ç¨³å®šé«˜æ•ˆçš„å¼ºåŒ–å­¦ä¹ åè®­ç»ƒï¼ˆPost-Trainingï¼‰ä½“ç³»**
- æå‡º **Unbiased Replay Buffer (U-RB)** ç¼“è§£é•¿å°¾å“åº”å¯¼è‡´çš„ rollout æ•ˆç‡ä½ä¸‹é—®é¢˜ï¼ŒåŒæ—¶ä¿æŒæ•°æ®åˆ†å¸ƒå¹³è¡¡ã€‚
- å¼•å…¥ **Multi-granularity Importance Sampling Clipping (MISC)** å’Œ **Well-learned Positive Sample Mask (WPSM)** æŠ‘åˆ¶ RL ä¸­ç†µå´©æºƒï¼ˆentropy collapseï¼‰ã€‚
- è®¾è®¡ **Adaptive Hint-based RL (AHRL)** åº”å¯¹ç¨€ç–å¥–åŠ±ä»»åŠ¡ï¼Œé€šè¿‡æ¸è¿›å¼æç¤ºå¼•å¯¼å¤æ‚æ¨ç†ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **æ¶æ„ç»Ÿä¸€æ€§** | çœŸæ­£å®ç° multimodal understanding & generation çš„åŸç”Ÿç»Ÿä¸€ï¼Œéæ‹¼æ¥å¼ late-fusion |
| **æ‰©å±•æ€§** | è¶…ç¨€ç– MoE + å¼¹æ€§è®­ç»ƒæ”¯æŒä¸‡äº¿å‚æ•°è§„æ¨¡ä¸‹çš„é«˜æ•ˆè®­ç»ƒä¸çµæ´»éƒ¨ç½² |
| **æ€§èƒ½å‡è¡¡æ€§** | åœ¨æ–‡æœ¬ã€è§†è§‰ã€éŸ³é¢‘ç­‰å¤šé¢†åŸŸå‡è¾¾åˆ°é¢†å…ˆæˆ–å¯æ¯”æ°´å¹³ï¼Œæ— æ˜æ˜¾çŸ­æ¿ |
| **å·¥ç¨‹å®ç”¨æ€§** | æä¾›ç”Ÿäº§çº§éƒ¨ç½²æ–¹æ¡ˆï¼Œé€‚åº”å¤šæ ·åŒ–çš„èµ„æºçº¦æŸ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†

#### æ–‡æœ¬æ•°æ®
- å¤šè¯­è¨€ç½‘é¡µçˆ¬å–ã€ä¹¦ç±ã€ç§‘å­¦æ–‡çŒ®ã€ä»£ç ä»“åº“ã€ç»“æ„åŒ–çŸ¥è¯†æº
- åŒ…æ‹¬ `PreciseWikiQA`, `PopQA`, `HotPotQA`, `SimpleQA`, `MMLU`, `C-Eval`, `CMMLU`, `HumanEval+`, `MBPP+` ç­‰ benchmark

#### è§†è§‰æ•°æ®
- å›¾åƒ-æ–‡æœ¬å¯¹ã€è§†é¢‘-æ–‡æœ¬å¯¹ã€äº¤é”™å¤šæ¨¡æ€åºåˆ—
- åŒ…å« `MMMU-Pro`, `MathVista`, `MathVerse`, `VisualPuzzle`, `ChartQA`, `DocVQA`, `AI2D`, `GenEval`, `VBench` ç­‰

#### éŸ³é¢‘æ•°æ®
- è¯­éŸ³è¯†åˆ«ã€è¯­éŸ³å¯¹è¯ã€ç¯å¢ƒéŸ³ç†è§£ã€è¯­éŸ³åˆæˆ
- åŒ…æ‹¬ `AISHELL-1/2`, `WenetSpeech`, `LibriSpeech`, `Fleurs`, `VoiceBench`, `MMAU`, `SEED-TTS` ç­‰

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

| ç±»åˆ« | è®¾ç½®è¯´æ˜ |
|------|--------|
| **æ¨¡å‹è§„æ¨¡** | Trillion-parameter çº§åˆ«ï¼Œè¶…ç¨€ç– MoE æ¶æ„ |
| **ä¸Šä¸‹æ–‡é•¿åº¦** | åˆ†é˜¶æ®µæ‰©å±•è‡³ 128K tokens |
| **è®­ç»ƒç­–ç•¥** | å¤šé˜¶æ®µ pre-training â†’ SFT â†’ Unified Multimodal RL (UMRL) |
| **å¹¶è¡Œç­–ç•¥** | ç»“åˆ Tensor Parallelism (4-way), Pipeline Parallelism (12-way), Expert Parallelism (64-way), ZeRO-1, Context Parallelism |
| **ç²¾åº¦æ§åˆ¶** | FP8 Mixed-Precision Trainingï¼Œå‡å°‘å³°å€¼å†…å­˜æ¶ˆè€— |
| **è¯„ä¼°æ–¹å¼** | å†…éƒ¨è¯„ä¼°æ¡†æ¶ ERNIE-Eval1ï¼Œæ¶µç›– factual knowledge, reasoning, coding, instruction following, agent tasks ç­‰ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”

| ç±»å‹ | å¯¹æ¯”æ¨¡å‹ |
|------|--------|
| **å¼€æºå¤§æ¨¡å‹** | DeepSeek-V3.2, Kimi K2, Qwen3-Omni, LongCat-Flash |
| **é—­æºå•†ä¸šæ¨¡å‹** | GPT-4o / GPT-5, Gemini 2.5-Pro / Gemini 3-Pro, Claude Opus |
| **ä¸“ç”¨å¤šæ¨¡æ€æ¨¡å‹** | Seedream 4.0, Qwen-VL, HunyuanVideo, Wan2.1, Veo3 |
| **è¯­éŸ³æ¨¡å‹** | CosyVoice, SparkTTS, F5-TTS, E2-TTS |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### ğŸ“˜ æ–‡æœ¬åŸºå‡†è¡¨ç°ï¼ˆPost-trainedï¼‰

| Benchmark | ERNIE 5.0 | æœ€ä½³åŸºçº¿ | è¡¨ç° |
|-----------|------------|----------|-------|
| MMLU-Pro (5-shot) | **83.80** | Gemini 3-Pro (87.10) | æ¥è¿‘æœ€ä¼˜ |
| GPQA-Diamond (5-shot) | **86.36** | Gemini 3-Pro (91.90) | å¼ºåŠ² |
| AIME 2025 | **89.06** | Gemini 3-Pro (95.00) | ç•¥ä½ |
| HumanEval+ (0-shot) | **94.48** | Gemini 3-Pro (95.12) | å‡ ä¹æŒå¹³ |
| MBPP+ (0-shot) | **82.54** | Gemini 3-Pro (86.21) | ç«äº‰åŠ›å¼º |
| IFEval (instruction following) | **93.35** | Gemini 3-Pro (94.10) | æ¥è¿‘ |
| Multi-IF (multi-instruction) | **85.56** | **SOTA** | **é¢†å…ˆ** |

> ğŸ’¡ **ç»“è®º**ï¼šERNIE 5.0 åœ¨é€šç”¨æ¨ç†ã€ç¼–ç¨‹ã€æŒ‡ä»¤éµå¾ªæ–¹é¢è¾¾åˆ°é¡¶å°–æ°´å¹³ï¼Œå°¤å…¶åœ¨å¤åˆæŒ‡ä»¤ç†è§£ä¸Šè¶…è¶Šæ‰€æœ‰å¯¹æ¯”æ¨¡å‹ã€‚

#### ğŸ–¼ï¸ è§†è§‰åŸºå‡†è¡¨ç°

| Benchmark | ERNIE 5.0 | æœ€ä½³åŸºçº¿ | è¡¨ç° |
|----------|------------|----------|-------|
| MMMU-Pro | 68.63 | Gemini 3-Pro (81.00) | æœ‰å·®è· |
| MathVista | **84.80** | Veo3 (89.20) | è¾ƒå¼º |
| ChartQA | **87.80** | Veo3 (89.44) | æ¥è¿‘ |
| GenEval (image gen.) | **90.1** | Qwen-Image (91.0) | å¯æ¯” |
| VBench (overall) | **84.20** | Veo3 (85.06) | æ¥è¿‘ SOTA |

> ğŸ’¡ **ç»“è®º**ï¼šå›¾åƒ/è§†é¢‘ç”Ÿæˆè´¨é‡é«˜ï¼Œè¯­ä¹‰ä¸€è‡´æ€§ä¼˜äºå¤šæ•°æ¨¡å‹ï¼ˆVBench Semantic å¾—åˆ†æœ€é«˜ï¼‰ï¼›è§†è§‰ç†è§£èƒ½åŠ›ç¨³å¥ä½†æœªå…¨é¢é¢†å…ˆã€‚

#### ğŸ”Š éŸ³é¢‘åŸºå‡†è¡¨ç°

| Task | ERNIE 5.0 | æœ€ä½³åŸºçº¿ | è¡¨ç° |
|------|------------|----------|-------|
| AISHELL-1 WER â†“ | **0.31** | Kimi (0.60) | **æ˜¾è‘—æ›´ä¼˜** |
| LibriSpeech clean WER â†“ | **1.16** | GPT-4o (1.22) | æ›´å¥½ |
| SEED-TTS (test-zh) â†“ | **1.35** | Qwen3-Omni (1.07) | ç•¥å·®äºä¸“ç”¨TTS |
| MMAU (audio understanding) â†‘ | **80.40** | Gemini 3-Pro (80.80) | æ¥è¿‘ |

> ğŸ’¡ **ç»“è®º**ï¼šè¯­éŸ³è¯†åˆ«èƒ½åŠ›æå¼ºï¼Œå°¤å…¶åœ¨ä¸­æ–‡ä»»åŠ¡ä¸Šå¤§å¹…é¢†å…ˆï¼›éŸ³é¢‘ç†è§£ä¸ç”Ÿæˆå…·å¤‡ç«äº‰åŠ›ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### âœ… **å¼¹æ€§è®­ç»ƒæœ‰æ•ˆæ€§éªŒè¯**

| é…ç½® | æ¨ç†å±‚æ•° | éªŒè¯æŸå¤± |
|------|--------|--------|
| Baseline (å›ºå®šæ·±åº¦) | 16 | 1.945 |
| Elastic Depth è®­ç»ƒ | 16 | **1.941** |
| Elastic Depth è®­ç»ƒ | 12 | 2.137 |

> âœ”ï¸ å¼¹æ€§è®­ç»ƒè½»å¾®æå‡å®Œæ•´æ¨¡å‹æ€§èƒ½ï¼Œå¹¶ä½¿æµ…å±‚å­æ¨¡å‹å…·æœ‰å¯æ§é€€åŒ–ã€‚

| å®½åº¦é…ç½® | æ¨ç†å®½åº¦ | æŸå¤± |
|---------|--------|-----|
| Baseline (64) | 64 | 1.957 |
| Elastic Width | 64 | 1.964 |
| Elastic Width | 32 | 2.218 |

> âœ”ï¸ æ”¯æŒå®½åº¦ç¼©å‡éƒ¨ç½²ï¼Œé€‚ç”¨äºå†…å­˜å—é™åœºæ™¯ã€‚

| è·¯ç”± sparsity | top-k | æŸå¤± |
|-------------|-------|-----|
| Baseline | 8 | 1.945 |
| Elastic Sparsity | 8 | 1.969 |
| Elastic Sparsity | 4 | **1.971** |
| Elastic Sparsity | 1 | 2.175 |

> âœ”ï¸ å³ä½¿å°† top-k å‡å°‘è‡³ 25%ï¼ˆä»…æ¿€æ´» 1/4 ä¸“å®¶ï¼‰ï¼Œæ€§èƒ½ä¸‹é™æå°ï¼Œ**è§£ç é€Ÿåº¦æå‡ >15%**ã€‚

#### âœ… **ç»¼åˆå¼¹æ€§æ¨¡å‹æ€§èƒ½**

| æ¨¡å‹ | å‚æ•°å æ¯” | å¹³å‡å¾—åˆ† |
|------|----------|--------|
| ERNIE 5.0-Exp | 100% | 75.55 |
| ERNIE 5.0-Exp-EA35.8% | **35.8%** | **75.17** |

> âœ”ï¸ ä½¿ç”¨ä»… **53.7% æ¿€æ´»å‚æ•°ã€35.8% æ€»å‚æ•°** çš„å¼¹æ€§å­æ¨¡å‹ï¼Œä»èƒ½ä¿æŒå‡ ä¹å…¨é‡æ¨¡å‹æ€§èƒ½ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. **ç»Ÿä¸€è‡ªå›å½’æ˜¯å¯è¡Œä¸”æœ‰æ•ˆçš„è·¯å¾„**
   - å°† text/image/video/audio ç»Ÿä¸€ä¸º next-group-of-tokens prediction æ˜¯æ„å»ºåŸç”Ÿå¤šæ¨¡æ€ Foundation Model çš„æœ‰æ•ˆèŒƒå¼ã€‚
   - ä¸åŒæ¨¡æ€ token è‡ªç„¶èåˆï¼Œä¿ƒè¿›è·¨æ¨¡æ€ååŒè¿›åŒ–ã€‚

2. **æ¨¡æ€æ— å…³ä¸“å®¶è·¯ç”±å¯è‡ªå‘å½¢æˆä¸“ä¸šåŒ–**
   - å°½ç®¡è·¯ç”±æœºåˆ¶ä¸æ„ŸçŸ¥æ¨¡æ€ç±»å‹ï¼Œä½†åˆ†ææ˜¾ç¤ºä¸“å®¶ä»å‡ºç°æ˜æ˜¾çš„åŠŸèƒ½åˆ†åŒ–ï¼ˆå¦‚éƒ¨åˆ†ä¸“ç²¾äºè§†è§‰ç”Ÿæˆã€éŸ³é¢‘å¤„ç†ï¼‰ã€‚
   - è¿™è¡¨æ˜ MoE èƒ½åœ¨ç»Ÿä¸€è¡¨ç¤ºä¸‹è‡ªåŠ¨æ•æ‰æ¨¡æ€ç»“æ„å·®å¼‚ã€‚

3. **å¼¹æ€§è®­ç»ƒæ˜¯ä¸€ç§åŸåˆ™æ€§çš„é«˜æ•ˆéƒ¨ç½²èŒƒå¼**
   - ä¸å†éœ€è¦â€œè®­ç»ƒå¤šä¸ªå°ºå¯¸â€æˆ–â€œåå‹ç¼©â€ï¼Œä¸€æ¬¡ pre-training å³å¯äº§å‡ºå¤šç§éƒ¨ç½²å½¢æ€ã€‚
   - åœ¨ depth/width/sparsity ä¸‰ä¸ªç»´åº¦å‡è¡¨ç°å‡ºè‰¯å¥½çš„é²æ£’æ€§å’Œå¯é¢„æµ‹æ€§ã€‚

4. **å¤šæ¨¡æ€ RL ç¨³å®šæ€§å¯é€šè¿‡ç³»ç»Ÿå·¥ç¨‹è§£å†³**
   - U-RBã€MISCã€WPSMã€AHRL ç­‰æŠ€æœ¯ç»„åˆæœ‰æ•ˆç¼“è§£äº† long-tail rolloutã€entropy collapseã€sparse reward ç­‰éš¾é¢˜ã€‚
   - ä¸ºå¤§è§„æ¨¡ MoE æ¶æ„ä¸‹çš„ RL æä¾›äº†å¯å¤ç”¨çš„åŸºç¡€è®¾æ–½æ–¹æ¡ˆã€‚

---

### æ–¹æ³•çš„å±€é™æ€§

1. **æç«¯æ¨ç†ä»»åŠ¡ä»æœ‰å·®è·**
   - åœ¨ GPQA-Diamondã€AIME/HMMT ç­‰è¶…é«˜éš¾åº¦æ•°å­¦ç«èµ›é¢˜ä¸Šç•¥é€Šäº Gemini 3-Proï¼Œè¯´æ˜æ·±å±‚é€»è¾‘æ¨ç†ä»æœ‰ä¼˜åŒ–ç©ºé—´ã€‚

2. **è§†è§‰ç†è§£æœªå…¨é¢é¢†å…ˆ**
   - å°½ç®¡ç”Ÿæˆèƒ½åŠ›å¼ºï¼Œä½†åœ¨ MMMU-Pro ç­‰ä¸“ä¸šå›¾è¡¨ç†è§£ä»»åŠ¡ä¸Šå¾—åˆ†åä½ï¼Œåæ˜ å…¶åœ¨ç»†ç²’åº¦ç¬¦å·æ¨ç†ä¸Šçš„ä¸è¶³ã€‚

3. **è¯­éŸ³ç”Ÿæˆéæœ€ä¼˜**
   - è™½ç„¶æ”¯æŒ TTSï¼Œä½†åœ¨ SEED-TTS ä¸Šä¸å¦‚ä¸“é—¨ä¼˜åŒ–çš„è¯­éŸ³æ¨¡å‹ï¼ˆå¦‚ CosyVoice 3ï¼‰ï¼Œè¯´æ˜ä¸“ç”¨ head ä»æœ‰ä»·å€¼ã€‚

4. **è®­ç»ƒæˆæœ¬æé«˜**
   - ä¸‡äº¿å‚æ•° + è¶…ç¨€ç– MoE + å¤šæ¨¡æ€è”åˆè®­ç»ƒï¼Œéœ€å¼ºå¤§ç®—åŠ›æ”¯æ’‘ï¼Œä¸­å°æœºæ„éš¾ä»¥å¤åˆ¶ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. **è¿›ä¸€æ­¥å¢å¼ºå¤æ‚æ¨ç†èƒ½åŠ›**
   - æ¢ç´¢æ›´å¼ºå¤§çš„ chain-of-thought prompting ä¸ RL ç­–ç•¥ï¼Œç¼©å°åœ¨æ•°å­¦ã€ä»£ç ç­‰é¢†åŸŸçš„å·®è·ã€‚

2. **æ¢ç´¢ layer-aware æˆ– task-adaptive routing**
   - å½“å‰è·¯ç”±ä¸ºé™æ€å…¨å±€å…±äº«ï¼Œæœªæ¥å¯ç ”ç©¶åŠ¨æ€è°ƒæ•´è·¯ç”±ç­–ç•¥ä»¥é€‚é…ä¸åŒä»»åŠ¡é˜¶æ®µã€‚

3. **è½»é‡åŒ–ä¸è¾¹ç¼˜éƒ¨ç½²**
   - åŸºäºå¼¹æ€§è®­ç»ƒæ¡†æ¶å¼€å‘é¢å‘ç§»åŠ¨ç«¯çš„å°å‹åŒ–ç‰ˆæœ¬ï¼Œæ¨åŠ¨æ™®æƒ  AIã€‚

4. **æ›´å¤šæ¨¡æ€æ‰©å±•**
   - æ¢ç´¢å¼•å…¥ 3Dã€åŠ¨ä½œã€ä¼ æ„Ÿå™¨ä¿¡å·ç­‰æ–°å‹è¾“å…¥å½¢å¼ï¼Œæ‹“å±•â€œomniâ€è¾¹ç•Œã€‚

5. **å¼€æ”¾å­æ¨¡å‹ç”Ÿæ€**
   - å‘å¸ƒåŸºäºå¼¹æ€§è®­ç»ƒçš„ä¸åŒé…ç½®å­æ¨¡å‹ï¼Œé¼“åŠ±ç¤¾åŒºç ”ç©¶é«˜æ•ˆéƒ¨ç½²ä¸å¾®è°ƒç­–ç•¥ã€‚

---

> âœ… **æ€»ä½“è¯„ä»·**ï¼š  
ERNIE 5.0 æ˜¯é¦–ä¸ªå…¬å¼€æŠ«éœ²çš„ã€çœŸæ­£æ„ä¹‰ä¸Šæ”¯æŒ **multimodal understanding & generation** çš„ **trillion-parameter unified autoregressive model**ï¼Œä»£è¡¨äº†å½“å‰å›½äº§å¤§æ¨¡å‹åœ¨æ¶æ„ç»Ÿä¸€æ€§ã€å·¥ç¨‹è½åœ°èƒ½åŠ›å’Œå¤šæ¨¡æ€èåˆæ–¹é¢çš„é‡å¤§çªç ´ã€‚å…¶æå‡ºçš„ **modality-agnostic MoE + elastic training** èŒƒå¼æœ‰æœ›æˆä¸ºä¸‹ä¸€ä»£ Foundation Model çš„æ ‡å‡†è®¾è®¡ä¹‹ä¸€ã€‚

</details>

---

### 13. [Mosaic Learning: A Framework for Decentralized Learning with Model Fragmentation](https://arxiv.org/abs/2602.04352)

**Authors**: Sayan Biswas, Davide Frey, Romaric Gaudel, Nirupam Gupta, Anne-Marie Kermarrec, Dimitri Ler\'ev\'erend, Rafael Pires, Rishi Sharma, Fran\c{c}ois Ta\"iani, Martijn de Vos  
**Category**: cs.LG  
**Published**: 2026-02-05  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.04352v1  

#### Abstract
Decentralized learning (DL) enables collaborative machine learning (ML) without a central server, making it suitable for settings where training data cannot be centrally hosted. We introduce Mosaic Learning, a DL framework that decomposes models into fragments and disseminates them independently acr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**Mosaic Learning: A Framework for Decentralized Learning with Model Fragmentation**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿçš„ **Decentralized Learning (DL)** å­˜åœ¨ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- æ¨¡å‹æ›´æ–°ä¸­å­˜åœ¨**å‚æ•°ç›¸å…³æ€§**ï¼Œå¯¼è‡´ä¿¡æ¯ä¼ æ’­å†—ä½™ï¼›
- å…¨æ¨¡å‹äº¤æ¢æ•ˆç‡ä½ï¼Œå°¤å…¶åœ¨éç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆnon-IIDï¼‰æ•°æ®ä¸‹æ”¶æ•›æ…¢ï¼›
- ç°æœ‰åŸºäº**model fragmentation**çš„æ–¹æ³•å¤šç”¨äºéšç§æˆ–å¼‚æ­¥ä¼˜åŒ–ç­‰ç³»ç»Ÿå±‚é¢ç›®æ ‡ï¼Œç¼ºä¹å¯¹å­¦ä¹ è¿‡ç¨‹æœ¬èº«çš„ç†è®ºåˆ†æã€‚

è¯¥è®ºæ–‡æ—¨åœ¨æ¢ç´¢ï¼š**å¦‚ä½•å°† model fragmentation ä½œä¸ºç¬¬ä¸€ç±»å­¦ä¹ åŸè¯­ï¼ˆfirst-class learning primitiveï¼‰æ¥æå‡ DL çš„å­¦ä¹ æ•ˆç‡å’Œæ€§èƒ½ï¼Ÿ**

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šMosaic Learning
æå‡º **Mosaic Learning** â€”â€” ä¸€ç§ç»Ÿä¸€çš„ã€ä»¥æ¨¡å‹ç¢ç‰‡åŒ–ä¸ºæ ¸å¿ƒçš„ DL æ¡†æ¶ï¼š

- å°†æœ¬åœ°æ¨¡å‹åˆ’åˆ†ä¸º $ K $ ä¸ªä¸é‡å çš„ **fragments**ï¼ˆç‰‡æ®µï¼‰ï¼›
- æ¯ä¸ª fragment é€šè¿‡**ç‹¬ç«‹çš„é€šä¿¡çŸ©é˜µ $ W^{[k]} $** åˆ†å‘ç»™ä¸åŒçš„é‚»å±…èŠ‚ç‚¹ï¼›
- æ¥æ”¶ç«¯è¿›è¡Œ **fragment-wise å¹³å‡èšåˆ**ï¼Œé‡æ„å®Œæ•´æ¨¡å‹ã€‚

> ğŸ” åˆ›æ–°è§†è§’ï¼šå°† fragmentation è§†ä¸ºä¸€ç§å¢å¼ºä¿¡æ¯å¤šæ ·æ€§ã€å‡å°‘å†—ä½™ä¼ æ’­çš„å­¦ä¹ æœºåˆ¶ï¼Œè€Œéä»…æ˜¯ç³»ç»Ÿä¼˜åŒ–æ‰‹æ®µã€‚

---

### â­ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿è¯´æ˜ |
|------|---------|
| **é€šä¿¡æ•ˆç‡** | ä¸å¢åŠ æ€»é€šä¿¡é‡ï¼ˆä¸ D-PSGD / EL ç›¸å½“ï¼‰ï¼Œä½†æå‡ä¿¡æ¯å¤šæ ·æ€§ |
| **æ”¶æ•›é€Ÿåº¦** | åœ¨éå‡¸åœºæ™¯ä¸‹æ˜¾è‘—åŠ å¿«èŠ‚ç‚¹çº§æ¨¡å‹æ”¶æ•›ï¼Œå°¤å…¶åœ¨é«˜ heterogeneity è®¾ç½®ä¸­ |
| **ç†è®ºä¿éšœ** | æ”¶æ•›ç‡ä¸å½“å‰æœ€ä¼˜çš„ Epidemic Learning (EL) ç›¸å½“ï¼ˆæœ€åæƒ…å†µï¼‰ |
| **ç»“æ„å¢ç›Š** | é€šè¿‡ç¢ç‰‡åŒ–é™ä½å…±è¯†æ­¥éª¤ä¸­çš„æœ€å¤§ç‰¹å¾å€¼ï¼Œæ”¹å–„ contraction æ€§èƒ½ |
| **æ— éœ€é¢å¤–å‡è®¾** | ä¸ä¾èµ–ç¨€ç–åŒ–ã€éƒ¨åˆ†å‚ä¸æˆ–å¼‚æ­¥æœºåˆ¶ï¼Œä»…ä¿®æ”¹ gossip æ­¥éª¤ |

> ğŸ’¡ ç‰¹åˆ«æŒ‡å‡ºï¼š**EL æ˜¯ Mosaic Learning åœ¨ $ K=1 $ æ—¶çš„ç‰¹ä¾‹**ï¼ˆè§ Remark 1ï¼‰ï¼Œè¡¨æ˜å…¶æ›´å…·ä¸€èˆ¬æ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
å…±åœ¨å››ä¸ªä»»åŠ¡ä¸ŠéªŒè¯æ€§èƒ½ï¼š
1. **CIFAR-10** å’Œ **CIFAR-100**ï¼šå›¾åƒåˆ†ç±»ä»»åŠ¡ï¼Œä½¿ç”¨ GN-LeNet æ¨¡å‹ï¼›
2. **MOVIELENS-small**ï¼šæ¨èç³»ç»Ÿä»»åŠ¡ï¼Œé‡‡ç”¨çŸ©é˜µåˆ†è§£ï¼ˆmatrix factorizationï¼‰ï¼›
3. **SHAKESPEARE**ï¼šæ–‡æœ¬é¢„æµ‹ä»»åŠ¡ï¼Œä½¿ç”¨ stacked LSTM æ¨¡å‹ã€‚

æ‰€æœ‰æ•°æ®å‡ä¸º **non-IID æ„é€ **ï¼Œå¹¶é€šè¿‡ Dirichlet åˆ†å¸ƒæ§åˆ¶å¼‚è´¨ç¨‹åº¦ï¼ˆ$\alpha = 1$ï¼šè½»åº¦ non-IIDï¼›$\alpha = 0.1$ï¼šé«˜åº¦ non-IIDï¼‰ã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®
- **ç½‘ç»œæ‹“æ‰‘**ï¼šæ­£åˆ™å›¾ï¼ˆregular graphï¼‰ï¼ŒèŠ‚ç‚¹åº¦åˆ†åˆ«ä¸º 2ã€8ã€16ï¼›
- **ç¢ç‰‡æ•°é‡ $ K $**ï¼šæµ‹è¯• $ K = 1, 2, 4, 8, 16 $ï¼›
- **æœ¬åœ°è®­ç»ƒ**ï¼šæ¯è½®æ‰§è¡Œ $ H $ æ­¥æœ¬åœ° SGDï¼›
- **å®ç°åŸºç¡€**ï¼šåŸºäº SHATTER æ¡†æ¶å®ç°ï¼›
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼š3 å°æœåŠ¡å™¨ï¼ŒåŒ Intel Xeon å¤„ç†å™¨ï¼ŒUbuntu ç³»ç»Ÿã€‚

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Node-average Test Accuracy/Loss** | æ‰€æœ‰èŠ‚ç‚¹æœ¬åœ°æ¨¡å‹åœ¨å…¨å±€æµ‹è¯•é›†ä¸Šçš„å¹³å‡è¡¨ç°ï¼Œåæ˜ ä¸ªä½“å­¦ä¹ æ•ˆæœ |
| **Average-model Test Accuracy/Loss** | æ‰€æœ‰èŠ‚ç‚¹æ¨¡å‹å‚æ•°å–å¹³å‡åçš„å…¨å±€æ¨¡å‹æ€§èƒ½ |
| **Consensus Distance** | å„èŠ‚ç‚¹æ¨¡å‹ä¸ç½‘ç»œå¹³å‡æ¨¡å‹ä¹‹é—´çš„ $ \ell_2 $ è·ç¦»å‡å€¼ï¼Œè¡¡é‡ä¸€è‡´æ€§ |
| **Standard Deviation of Node Performance** | èŠ‚ç‚¹é—´æ€§èƒ½å·®å¼‚çš„æ ‡å‡†å·®ï¼Œåæ˜ å…¬å¹³æ€§å’Œç¨³å®šæ€§ |

---

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Epidemic Learning (EL)**ï¼šå½“å‰æœ€å…ˆè¿›çš„ DL åŸºçº¿ï¼ŒéšæœºåŒ– gossip çŸ©é˜µä»¥åŠ é€Ÿä¿¡æ¯ä¼ æ’­ï¼›
- æ³¨æ„ï¼šEL å¯¹åº”äº Mosaic Learning ä¸­ $ K=1 $ çš„æƒ…å½¢ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®
| æ•°æ®é›† | æœ€å¤§æå‡å¹…åº¦ï¼ˆvs. ELï¼‰ | æ¡ä»¶ |
|--------|--------------------------|-------|
| CIFAR-10 | **+12 percentage points** | é«˜åº¦ non-IID ($\alpha=0.1$)ï¼Œ$K=16$ |
| CIFAR-100 | æ˜¾è‘—ä¼˜äº EL | é«˜åº¦ non-IIDï¼Œ$K$ è¾ƒå¤§æ—¶ |
| MOVIELENS | æ€§èƒ½åŸºæœ¬æŒå¹³ | ä¸å— $K$ å½±å“ |
| SHAKESPEARE | æœ‰ä¸€å®šæå‡è¶‹åŠ¿ | ä½†ä¸å¦‚å›¾åƒä»»åŠ¡æ˜æ˜¾ |

> âœ… åœ¨ IID åœºæ™¯ä¸‹ï¼ŒMosaic Learning ä¸ EL è¡¨ç°ç›¸å½“ï¼Œæ— æ€§èƒ½æŸå¤±ã€‚

---

### ğŸ” ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **Node-average accuracy**ï¼š
  - åœ¨ CIFAR-10/100 ä¸Šéš $K$ å¢åŠ è€ŒæŒç»­ä¸Šå‡ï¼Œæœ€é«˜æå‡è¾¾ **12%**ï¼›
  - æå‡ä¸»è¦æ¥è‡ªæ›´å°çš„èŠ‚ç‚¹æ€§èƒ½æ–¹å·®ï¼ˆstandard deviation â†“ï¼‰ï¼Œå³å­¦ä¹ æ›´ä¸€è‡´ã€‚
- **Average-model accuracy**ï¼š
  - å‡ ä¹ä¸å— $K$ å½±å“ï¼Œåœ¨æ‰€æœ‰è®¾ç½®ä¸­ä¸ EL æŒå¹³ â†’ è¡¨æ˜æœªç‰ºç‰²å…¨å±€æ¨¡å‹è´¨é‡ã€‚
- **Consensus Distance**ï¼š
  - åœ¨éå‡¸ä»»åŠ¡ä¸­åè€Œéš $K$ å¢åŠ è€Œç•¥å¾®ä¸Šå‡ï¼ˆä¸å‡¸åˆ†æç›¸åï¼‰ï¼›
  - ä½†æ€§èƒ½ä»æ›´å¥½ â†’ è¯´æ˜ **consensus distance ä¸æ˜¯è¡¡é‡ DL æ€§èƒ½çš„å¯é æŒ‡æ ‡**ã€‚

---

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰ç¢ç‰‡æ•° $K$ çš„å½±å“ï¼ˆRQ1ï¼‰
- $K$ è¶Šå¤§ï¼Œnode-average accuracy è¶Šé«˜ï¼ˆå°¤å…¶åœ¨ non-IID ä¸‹ï¼‰ï¼›
- ä½†å¯¹ average-model æ— è´Ÿé¢å½±å“ï¼›
- **æ ‡å‡†å·®ä¸‹é™** â†’ è¡¨æ˜ç¢ç‰‡åŒ–ä¿ƒè¿›äº†â€œå‚æ•°æ··åˆâ€ï¼ˆparameter mixingï¼‰ï¼Œç¼“è§£äº†æ•°æ®å¼‚è´¨æ€§å¸¦æ¥çš„åå·®ã€‚

#### ï¼ˆ2ï¼‰å›¾åº¦ï¼ˆGraph Degreeï¼‰çš„å½±å“ï¼ˆRQ2ï¼‰
- å›¾è¶Šå¯†é›†ï¼ˆdegree â†‘ï¼‰ï¼Œmixing è¶Šå¿«ï¼Œæ€§èƒ½è¶Šå¥½ï¼›
- é«˜åº¦å›¾å¯ç¼“è§£ç¢ç‰‡åŒ–å¸¦æ¥çš„ consensus distance ä¸Šå‡ï¼›
- **ååŒæ•ˆåº”**ï¼šé«˜ $K$ + é«˜ degree â†’ æœ€ä½³æ€§èƒ½ã€‚

#### ï¼ˆ3ï¼‰æ•°æ®å¼‚è´¨æ€§çš„å½±å“ï¼ˆRQ3ï¼‰
- æ•°æ®è¶Š non-IIDï¼ŒMosaic Learning çš„ä¼˜åŠ¿è¶Šæ˜æ˜¾ï¼›
- åœ¨ $\alpha=0.1$ï¼ˆå¼º non-IIDï¼‰æ—¶ï¼Œ$K=16$ æ¯” $K=1$ æå‡æœ€å¤§ï¼›
- åœ¨ IID åœºæ™¯ä¸‹ï¼Œ$K$ å‡ ä¹æ— å½±å“ â†’ è¡¨æ˜å…¶ä¼˜åŠ¿é›†ä¸­åœ¨å›°éš¾è®­ç»ƒåœºæ™¯ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Model fragmentation æ˜¯ä¸€ç§æœ‰æ•ˆçš„å­¦ä¹ å¢å¼ºæœºåˆ¶**ï¼š
   - ä¸ä»…å¯ç”¨äºéšç§æˆ–ç³»ç»Ÿä¼˜åŒ–ï¼Œæ›´èƒ½ç›´æ¥ä¿ƒè¿›ä¿¡æ¯å¤šæ ·æ€§å’Œå¿«é€Ÿæ”¶æ•›ã€‚
2. **Mosaic Learning åœ¨ worst-case ä¸‹ä¿æŒä¸ EL ç›¸åŒçš„æ”¶æ•›é€Ÿç‡**ï¼ˆTheorem 1ï¼‰ï¼›
3. **åœ¨å‡¸è®¾å®šä¸‹ï¼Œå¢åŠ  $K$ å¯é™ä½ç®€åŒ–ç³»ç»Ÿçš„æœ€å¤§ç‰¹å¾å€¼ï¼Œä»è€ŒåŠ å¿«å…±è¯†**ï¼ˆLemma 2 + å›¾ 2/3ï¼‰ï¼›
4. **åœ¨å®é™…éå‡¸ä»»åŠ¡ä¸­ï¼Œç¢ç‰‡åŒ–æ˜¾è‘—æå‡ node-level æ€§èƒ½ï¼Œæœ€å¤šé«˜å‡º 12%**ï¼›
5. **æ€§èƒ½æå‡æºäº reduced variance in node performanceï¼Œè€Œéæ›´å¿«è¾¾æˆ consensus**ï¼›
6. **è¯¥æ–¹æ³•åœ¨é€šä¿¡æˆæœ¬ä¸å˜çš„å‰æä¸‹å®ç°æ€§èƒ½è·ƒå‡ï¼Œå…·æœ‰å®ç”¨ä»·å€¼**ã€‚

---

### âš ï¸ å±€é™æ€§
- **ç†è®ºåˆ†æåŸºäºç®€åŒ–çš„äºŒæ¬¡æŸå¤±å‡½æ•°**ï¼Œéš¾ä»¥å®Œå…¨åˆ»ç”»æ·±åº¦ç¥ç»ç½‘ç»œä¸­çš„å¤æ‚åŠ¨æ€ï¼›
- **consensus distance ä¸å®é™…æ€§èƒ½è„±é’©**ï¼Œä¼ ç»Ÿåˆ†æå·¥å…·éœ€é‡æ–°å®¡è§†ï¼›
- å½“å‰ç¢ç‰‡åˆ’åˆ†ç­–ç•¥ä¸ºå‡åŒ€éšæœºï¼Œæœªæ¢ç´¢**åŸºäºå‚æ•°ç›¸å…³æ€§çš„æ™ºèƒ½åˆ†ç‰‡**ï¼ˆå¦‚æŒ‰å±‚ã€æŒ‰é€šé“ï¼‰ï¼›
- åœ¨æŸäº›ä»»åŠ¡ï¼ˆå¦‚ MOVIELENSï¼‰ä¸Šå¢ç›Šæœ‰é™ï¼Œé€‚ç”¨æ€§æœ‰å¾…è¿›ä¸€æ­¥éªŒè¯ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. è®¾è®¡ **adaptive fragmentation ç­–ç•¥**ï¼Œæ ¹æ®æ¢¯åº¦ç›¸å…³æ€§æˆ–é‡è¦æ€§åŠ¨æ€è°ƒæ•´ç¢ç‰‡ç»“æ„ï¼›
2. ç»“åˆ **sparsification ä¸ fragmentation**ï¼Œè¿›ä¸€æ­¥å‹ç¼©é€šä¿¡ï¼›
3. æ¢ç´¢ **asynchronous Mosaic Learning**ï¼Œåº”å¯¹çœŸå®è¾¹ç¼˜è®¾å¤‡å»¶è¿Ÿï¼›
4. å°†æ¡†æ¶æ‰©å±•è‡³ **federated learning with partial participation** åœºæ™¯ï¼›
5. ç ”ç©¶ **fragment-aware optimizer design**ï¼Œä¾‹å¦‚é’ˆå¯¹ä¸åŒ fragment ä½¿ç”¨ä¸åŒå­¦ä¹ ç‡ã€‚

---

## âœ… æ€»ç»“
> **Mosaic Learning** ä¸åªæ˜¯ä¸€ä¸ªæ–°ç®—æ³•ï¼Œæ›´æ˜¯ä¸€ç§**èŒƒå¼è½¬å˜**ï¼ˆparadigm shiftï¼‰â€”â€”  
å®ƒå°† **model fragmentation** ä»è¾…åŠ©æŠ€æœ¯æå‡ä¸º DL çš„æ ¸å¿ƒè®¾è®¡åŸåˆ™ï¼Œæ­ç¤ºäº†å…¶åœ¨æå‡ä¿¡æ¯å¤šæ ·æ€§ã€ç¼“è§£å†—ä½™ä¼ æ’­æ–¹é¢çš„ç»“æ„æ€§ä¼˜åŠ¿ã€‚

ğŸ”¹ **ç†è®ºæ‰å®**ï¼šç»§æ‰¿ EL çš„æœ€ä¼˜æ”¶æ•›ç•Œï¼Œå¹¶é¦–æ¬¡å½¢å¼åŒ–åˆ†æ fragmentation å¯¹ contraction çš„å½±å“ï¼›  
ğŸ”¹ **å®éªŒå……åˆ†**ï¼šè·¨å¤šä¸ªä»»åŠ¡ã€å¤šç§è®¾ç½®éªŒè¯æœ‰æ•ˆæ€§ï¼›  
ğŸ”¹ **æ½œåŠ›å·¨å¤§**ï¼šä¸ºä¸‹ä¸€ä»£é«˜æ•ˆã€é²æ£’ã€å¯æ‰©å±•çš„ decentralized learning æä¾›æ–°è·¯å¾„ã€‚

> ğŸ **å®šä½æ˜ç¡®**ï¼šæœ‰æœ›æˆä¸ºæ–°çš„ DL standardã€‚

</details>

---

### 14. [Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search](https://arxiv.org/abs/2602.04248)

**Authors**: Hao Lu, Haoyuan Huang, Yulin Zhou, Chen Li, Ningxin Zhu  
**Category**: cs.AI  
**Published**: 2026-02-05  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.04248v1  

#### Abstract
Inference-time scaling strategies, particularly Monte Carlo Tree Search (MCTS), have significantly enhanced the reasoning capabilities of Large Language Models (LLMs). However, current approaches remain predominantly stateless, discarding successful reasoning patterns after each problem instance and...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰åŸºäº **Monte Carlo Tree Search (MCTS)** çš„æ¨ç†å¢å¼ºæ–¹æ³•åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­æ™®éå­˜åœ¨**çŠ¶æ€æ— å…³ï¼ˆstatelessï¼‰**çš„é—®é¢˜ï¼šæ¯æ¬¡æœç´¢ç»“æŸåï¼ŒæˆåŠŸçš„æ¨ç†è·¯å¾„å’Œæœ‰æ•ˆç­–ç•¥è¢«ä¸¢å¼ƒï¼Œæ— æ³•è·¨ä»»åŠ¡å®ä¾‹ç§¯ç´¯ç»éªŒã€‚è¿™ä¸äººç±»é€šè¿‡é•¿æœŸç»éªŒï¼ˆdomain knowledgeï¼‰ä¸çŸ­æœŸåé¦ˆï¼ˆimmediate contextï¼‰ç»“åˆè§£å†³é—®é¢˜çš„æ–¹å¼ç›¸æ‚–ã€‚

æ­¤å¤–ï¼Œç°æœ‰å°è¯•å¼•å…¥è®°å¿†æœºåˆ¶çš„æ–¹æ³•ï¼ˆå¦‚ FLEXã€Training-Free GRPOï¼‰å­˜åœ¨ä»¥ä¸‹ä¸è¶³ï¼š
- ç»éªŒæ£€ç´¢ä¸æ¨ç†è¿‡ç¨‹åˆ†ç¦»ï¼Œç¼ºä¹åŠ¨æ€æ•´åˆï¼›
- ç¼ºå°‘ç»“æ„åŒ–æœç´¢æ”¯æŒï¼Œåœ¨å¤æ‚å¤šæ­¥é€»è¾‘ä»»åŠ¡ä¸Šæ•ˆæœæœ‰é™ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡º **Empirical-MCTS**ï¼Œä¸€ä¸ªå°† MCTS ä»â€œæ— çŠ¶æ€æ¨ç†æŠ€æœ¯â€è½¬å˜ä¸ºâ€œéå‚æ•°åœ¨çº¿å­¦ä¹ ä»£ç†â€çš„åŒå¾ªç¯æ¡†æ¶ï¼Œå®ç°è¿ç»­çš„ç»éªŒç§¯ç´¯ä¸ç­–ç•¥æ¼”åŒ–ã€‚å…¶ä¸¤å¤§æ ¸å¿ƒæœºåˆ¶ä¸ºï¼š

#### âœ… Pairwise-Experience-Evolutionary Meta-Prompting (PE-EMP)
- åœ¨å±€éƒ¨æœç´¢è¿‡ç¨‹ä¸­ä½œä¸º**åå°„å¼ä¼˜åŒ–å™¨ï¼ˆreflexive optimizerï¼‰**ï¼›
- åˆ©ç”¨æˆå¯¹å“åº”å·®å¼‚ç”Ÿæˆè‡ªé€‚åº”è¯„ä»·æ ‡å‡†ï¼ˆadaptive criteriaï¼‰ï¼Œå®æ—¶æ¼”è¿› **meta-prompt**ï¼ˆç³»ç»Ÿæç¤ºï¼‰ï¼›
- ä¸ä»…ç”¨äºèŠ‚ç‚¹é€‰æ‹©ï¼Œæ›´ä¸»åŠ¨ä¼˜åŒ–åç»­ç”Ÿæˆç­–ç•¥ã€‚

#### âœ… Memory Optimization Agent
- æ„å»ºå…¨å±€åŠ¨æ€ç»éªŒåº“ï¼ˆglobal experience libraryï¼‰ï¼Œä½œä¸ºç­–ç•¥å…ˆéªŒï¼›
- å¼•å…¥åŸå­æ“ä½œï¼ˆadd / modify / merge / deleteï¼‰æŒç»­æç‚¼é«˜è´¨é‡æ´å¯Ÿï¼›
- å®ç°æ— éœ€æƒé‡æ›´æ–°çš„**éå‚æ•°ç­–ç•¥è¿›åŒ–**ã€‚

è¯¥æ¡†æ¶ç»Ÿä¸€äº†çŸ­æ—¶ç»éªŒï¼ˆlocal explorationï¼‰ä¸é•¿æ—¶ç»éªŒï¼ˆglobal memoryï¼‰ï¼Œä½¿ LLM èƒ½å¤Ÿåƒä¸“å®¶ä¸€æ ·â€œè®°ä½â€å¹¶å¤ç”¨è¿‡å»çš„æœ‰æ•ˆæ¨ç†æ¨¡å¼ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | Empirical-MCTS | ä¼ ç»Ÿ MCTS | FLEX | Training-Free GRPO |
|------|----------------|-----------|-------|--------------------|
| ç»“æ„åŒ–æœç´¢ | âœ… | âœ… | âŒ | âŒ |
| åŠ¨æ€æç¤ºæ¼”åŒ– | âœ… | âŒ | âŒ | âš ï¸ï¼ˆé—´æ¥ï¼‰ |
| å…¨å±€ç»éªŒç§¯ç´¯ | âœ… | âŒ | âœ…ï¼ˆé™æ€æ£€ç´¢ï¼‰ | âœ…ï¼ˆæ— ç»“æ„æœç´¢ï¼‰ |
| éå‚æ•°å­¦ä¹  | âœ… | âŒ | âŒ | âœ… |

> âœ”ï¸ **æ ¸å¿ƒä¼˜åŠ¿**ï¼šé¦–æ¬¡å°† structured search ä¸ continuous learning æ·±åº¦èåˆï¼Œå½¢æˆå¯è¿›åŒ–çš„æ¨ç†æ™ºèƒ½ä½“ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
åœ¨ä¸‰ä¸ªé«˜éš¾åº¦ã€å‰æ²¿çš„å¤æ‚æ¨ç†åŸºå‡†ä¸Šè¿›è¡Œè¯„ä¼°ï¼š
- **AIME25**ï¼šé«˜ä¸­æ•°å­¦ç«èµ›é¢˜åŸºå‡†ï¼Œæµ‹è¯•æ ‡å‡†æ•°å­¦æ¨ç†èƒ½åŠ›ï¼›
- **MathArena Apex**ï¼šåŠ¨æ€æ„å»ºçš„é˜²æ•°æ®æ±¡æŸ“æ•°å­¦è¯„æµ‹é›†ï¼ŒåŒ…å«è¿‘æœŸ CMIMCã€IMO ç­‰èµ›äº‹é¢˜ç›®ï¼Œå”¯ä¸€æ”¯æŒ**è¯æ˜å†™ä½œ**è¯„ä¼°çš„åŸºå‡†ï¼›
- **ARC-AGI-2**ï¼šæŠ½è±¡ä¸æ¨ç†è¯­æ–™åº“å‡çº§ç‰ˆï¼Œè¡¡é‡æµä½“æ™ºåŠ›ï¼ˆfluid intelligenceï¼‰ï¼Œè¦æ±‚ä»æå°‘é‡ç¤ºä¾‹ä¸­å½’çº³å˜æ¢ç¨‹åºã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **ä¸»å¹²æ¨¡å‹**ï¼šDeepSeek-V3.1-Terminusã€gpt-oss-120bã€Gemini 3 Flash/Proï¼›
- **è¯„ä¼°æ–¹å¼**ï¼š
  - å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰
  - æˆæœ¬-æ€§èƒ½å¸•ç´¯æ‰˜åˆ†æï¼ˆCost-performance Pareto Frontierï¼‰
  - æ¶ˆèç ”ç©¶ï¼ˆablation studiesï¼‰åˆ†æå„ç»„ä»¶è´¡çŒ®
  - ç»éªŒåº“å¢é•¿è½¨è¿¹ä¸æ€§èƒ½ç›¸å…³æ€§åˆ†æ
- **æœç´¢é…ç½®**ï¼šé‡‡ç”¨ UCB èŠ‚ç‚¹é€‰æ‹©ï¼Œè¡°å‡å¼ Q å€¼å›ä¼ ï¼ˆdecay-based backpropagationï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
æ¶µç›–ä¸»æµæ¨ç†å¢å¼ºèŒƒå¼ï¼š
1. **ICL**ï¼ˆIn-Context Learningï¼‰
2. **ReAct**ï¼ˆReasoning-and-Actingï¼‰
3. **Repeated Sampling**ï¼ˆBest-of-Nï¼‰
4. **FLEX**ï¼ˆç»éªŒåº“é©±åŠ¨ä»£ç†ï¼‰
5. **LLaMA-Berry**ï¼ˆåŸºäº pairwise reward çš„ MCTSï¼‰
6. **Training-Free GRPO**ï¼ˆæ— è®­ç»ƒç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ğŸ“Š è¡¨æ ¼ 1ï¼šAIME25 ä¸ MathArena Apex æ€§èƒ½å¯¹æ¯”ï¼ˆä»¥ DeepSeek-V3.1-Terminus ä¸ºä¸»å¹²ï¼‰

| Method/Framework | AIME25 (%) | MathArena Apex (%) |
|------------------|------------|---------------------|
| Baseline         | 56.7       | 0.00 (16 runs)      |
| ICL              | 53.3       | â€”                   |
| ReAct            | 60.0       | â€”                   |
| FLEX             | 66.6       | â€”                   |
| Repeated Sampling| 70.0       | 0.00 (4 runs)       |
| LLaMA-Berry      | 63.3       | 2.08 (4 runs)       |
| **Ours (Empirical-MCTS)** | **73.3**   | **4.17 (4 runs)**   |

> ğŸ” æ³¨ï¼šMathArena Apex ä¸ŠåŸºç¡€æ¨¡å‹å®Œå…¨å¤±è´¥ï¼ˆ0%ï¼‰ï¼Œè€Œ Empirical-MCTS æˆåŠŸæ±‚è§£éƒ¨åˆ†éš¾é¢˜ï¼Œè¡¨æ˜å…¶å…·å¤‡**åˆæˆæ–°è§£æ³•è·¯å¾„çš„èƒ½åŠ›**ã€‚

#### ğŸ’° æˆæœ¬æ•ˆç‡çªç ´ï¼ˆTable 2ï¼‰ï¼šä½¿ç”¨è½»é‡æ¨¡å‹ Gemini 3 Flash

| Model | MathArena Apex Acc | Cost ($) | ARC-AGI-2 Acc | Cost ($) |
|-------|---------------------|----------|---------------|----------|
| Ours (Gemini 3 Flash) | **35.42%** | **5.24** | **38.33%** | **0.97** |
| GPT-5.2 (High)        | 13.54%     | 12.00    | 43.3%       | 1.39     |
| Gemini 3 Pro          | 23.44%     | 3.40     | 31.1%       | 0.81     |
| Grok 4                | 2.08%      | 6.21     | 16.0%       | 2.17     |

> âœ… **å…³é”®å‘ç°**ï¼šEmpirical-MCTS ä½¿å¾—å°æ¨¡å‹â€œä»¥å°æå¤§â€ï¼Œåœ¨ MathArena Apex ä¸Šå‡†ç¡®ç‡æ˜¯ GPT-5.2 çš„ **2.6 å€ä»¥ä¸Š**ï¼Œæˆæœ¬æ›´ä½ï¼›åœ¨ ARC-AGI-2 ä¸Šä¹Ÿæ˜¾è‘—ä¼˜äºå¤šæ•°é«˜ä»·æ¨¡å‹ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨ AIME25 ä¸Šè¶…è¶Šæœ€å¼º stateless MCTS æ–¹æ³• LLaMA-Berryï¼ˆ+10 ptsï¼‰ï¼›
- æ˜¾è‘—ä¼˜äºè®°å¿†å¢å¼ºå‹ FLEXï¼ˆ+6.7 ptsï¼‰ï¼Œè¯´æ˜**åŠ¨æ€æç¤ºæ¼”åŒ– + ç»“æ„åŒ–æœç´¢ > é™æ€æ£€ç´¢**ï¼›
- åœ¨æç«¯å›°éš¾çš„ MathArena Apex ä¸Šå®ç°â€œé›¶åˆ°æœ‰â€çš„çªç ´ï¼ŒéªŒè¯äº†ç»éªŒç§¯ç´¯å¯å‚¬ç”Ÿæ–°çŸ¥è¯†ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studies on AIME25 with gpt-oss-120bï¼‰

| é…ç½® | æœ€ç»ˆå‡†ç¡®ç‡ï¼ˆ8 rolloutsï¼‰ | åˆ†æ |
|------|----------------------------|------|
| Full Framework | **76.7%** | å®Œæ•´æ¡†æ¶æŒç»­æå‡ï¼Œæœªè§é¥±å’Œ |
| w/o Meta-Prompt | 66.7% | ç§»é™¤ meta-prompt å¯¼è‡´æ”¶ç›Šä¸‹é™ï¼Œè¯´æ˜æç¤ºæ¼”åŒ–è‡³å…³é‡è¦ |
| w/o Memory & Meta-Prompt | 63.3% | å›å½’è‡³ LLaMA-Berry æ°´å¹³ï¼Œæ— æ³•ç§¯ç´¯ç»éªŒ |
| w/o PE-EMP & Memory | 56.7% | é€€åŒ–ä¸ºæ™®é€š MCTSï¼Œæ€§èƒ½åœæ» |
| Repeated Sampling | 56.7% | å®Œå…¨æ— å¢ç›Šï¼Œå‡¸æ˜¾ç»“æ„æœç´¢å¿…è¦æ€§ |

> ğŸ”— å›¾5æ˜¾ç¤ºï¼šæ€§èƒ½æå‡ä¸ç»éªŒæ•°é‡å‘ˆå¼ºæ­£ç›¸å…³ï¼ˆrâ†‘ â‡’ accâ†‘ï¼‰ï¼Œè¯å®â€œç»éªŒå³æ”¿ç­–å…ˆéªŒâ€ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **â€œè®°ä½â€æ¯”â€œæœç´¢â€æ›´é‡è¦**ï¼š  
   å•çº¯å¢åŠ è®¡ç®—ï¼ˆå¦‚ Best-of-N æˆ– MCTSï¼‰æ•ˆæœæœ‰é™ï¼›çœŸæ­£çªç ´æ¥è‡ªå°†å†å²æˆåŠŸæ¨¡å¼è½¬åŒ–ä¸ºå¯é‡ç”¨çš„ policy priorã€‚

2. **åŒå¾ªç¯æœºåˆ¶æœ‰æ•ˆååŒ**ï¼š  
   PE-EMP æä¾›ç²¾ç»†çš„å³æ—¶åé¦ˆé©±åŠ¨ prompt è¿›åŒ–ï¼ŒMemory Optimization Agent å®ç°è·¨ä»»åŠ¡çš„çŸ¥è¯†æ²‰æ·€ï¼ŒäºŒè€…å…±åŒæ¨åŠ¨ agent æŒç»­è¿›åŒ–ã€‚

3. **å°æ¨¡å‹ä¹Ÿèƒ½è§£å†³å¤§é—®é¢˜**ï¼š  
   Empirical-MCTS ä½¿ä½æˆæœ¬æ¨¡å‹ï¼ˆå¦‚ Gemini 3 Flashï¼‰åœ¨å¤šä¸ªåŸºå‡†ä¸Šè¶…è¶Šæ˜‚è´µçš„å¤§æ¨¡å‹ï¼Œé‡æ–°å®šä¹‰äº†â€œé«˜æ•ˆæ¨ç†â€çš„è¾¹ç•Œã€‚

4. **ç»éªŒå¯é‡åŒ–ä¸”å…·ä»·å€¼**ï¼š  
   å®éªŒè¡¨æ˜ç»éªŒåº“å¤§å°ä¸æ€§èƒ½é«˜åº¦æ­£ç›¸å…³ï¼Œè¯æ˜éå‚æ•°å­¦ä¹ å¯é€šè¿‡ token-level prior å®ç°ç±» PPO çš„ä¼˜åŒ–æ•ˆæœã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–æ¨¡å‹è‡ªèº«éªŒè¯èƒ½åŠ›**ï¼šè‹¥ base LLM æ— æ³•æ­£ç¡®åˆ¤æ–­æ¨ç†æ­¥éª¤ä¼˜åŠ£ï¼Œåˆ™å¯èƒ½å°†é”™è¯¯ç»éªŒçº³å…¥è®°å¿†åº“ï¼Œå¯¼è‡´â€œé€€åŒ–æ¼”åŒ–â€ï¼ˆdegenerative evolutionï¼‰ï¼›
- **è¯­ä¹‰æ¼‚ç§»é£é™©**ï¼šåœ¨æŠ½è±¡ä»»åŠ¡ä¸­ï¼Œmeta-prompt å¯èƒ½åç¦»åŸé—®é¢˜çº¦æŸï¼›
- å½“å‰æ¡†æ¶å°šæœªæ‰©å±•è‡³å¤šè½®äº¤äº’æˆ–é•¿æœŸè§„åˆ’åœºæ™¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. åœ¨ memory optimization loop ä¸­å¼•å…¥**ä¸€è‡´æ€§æ£€æŸ¥**ä¸**ä¸ç¡®å®šæ€§é‡åŒ–**ï¼Œè¿‡æ»¤æœ‰æ¯’æˆ–ä½è´¨ç»éªŒï¼›
2. æ‰©å±•è‡³ multi-turn dialogue å’Œ long-horizon planning ä»»åŠ¡ï¼›
3. æ¢ç´¢è·¨é¢†åŸŸç»éªŒè¿ç§»æœºåˆ¶ï¼Œæå‡æ³›åŒ–èƒ½åŠ›ï¼›
4. å°† Empirical-MCTS åº”ç”¨äºä»£ç ç”Ÿæˆã€ç§‘å­¦å‘ç°ç­‰éœ€è¦ç´¯ç§¯æ™ºæ…§çš„ä»»åŠ¡ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> *Empirical-MCTS é€šè¿‡å°† MCTS ä¸åŒç»éªŒæœºåˆ¶ç»“åˆï¼Œé¦–æ¬¡å®ç°äº† LLM åœ¨ä¸æ›´æ–°å‚æ•°çš„å‰æä¸‹â€œè¶Šç”¨è¶Šèªæ˜â€ï¼Œä¸ºæ„å»ºå¯æŒç»­è¿›åŒ–çš„æ™ºèƒ½ä½“æä¾›äº†æ–°èŒƒå¼ã€‚*

</details>

---

### 15. [Expert Selections In MoE Models Reveal (Almost) As Much As Text](https://arxiv.org/abs/2602.04105)

**Authors**: Amir Nuriyev, Gabriel Kulp  
**Category**: cs.CL  
**Published**: 2026-02-05  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.04105v1  

#### Abstract
We present a text-reconstruction attack on mixture-of-experts (MoE) language models that recovers tokens from expert selections alone. In MoE models, each token is routed to a subset of expert subnetworks; we show these routing decisions leak substantially more information than previously understood...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Expert Selections In MoE Models Reveal (Almost) As Much As Text*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
æœ¬æ–‡ç ”ç©¶äº† **Mixture-of-Experts (MoE)** æ¨¡å‹ä¸­ **expert selectionï¼ˆä¸“å®¶é€‰æ‹©ï¼‰æœºåˆ¶** çš„éšç§æ³„éœ²é£é™©ã€‚å…·ä½“è€Œè¨€ï¼Œä½œè€…æå‡ºäº†ä¸€ç§ **æ–‡æœ¬é‡å»ºæ”»å‡»ï¼ˆtext-reconstruction attackï¼‰**ï¼Œä»…é€šè¿‡è§‚å¯Ÿæ¯ä¸ª token è¢«è·¯ç”±åˆ°å“ªäº› expertï¼Œå°±èƒ½é«˜ç²¾åº¦åœ°æ¢å¤åŸå§‹è¾“å…¥æ–‡æœ¬ã€‚

æ­¤å‰çš„ç ”ç©¶è®¤ä¸º expert selection æ˜¯ä½å¸¦å®½ã€ç¦»æ•£ä¿¡å·ï¼Œä¿¡æ¯é‡æœ‰é™ï¼›è€Œæœ¬æ–‡è¯æ˜ï¼šè¿™äº›è·¯ç”±å†³ç­–å®é™…ä¸Š **æ³„éœ²äº†è¿œè¶…é¢„æœŸçš„è¯­ä¹‰å’Œè¯æ±‡ä¿¡æ¯**ï¼Œè¶³ä»¥å®ç°æ¥è¿‘å®Œæ•´çš„æ–‡æœ¬é‡å»ºã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

- **é¦–æ¬¡ç³»ç»Ÿæ€§å±•ç¤º expert selection å¯ç”¨äºé«˜è´¨é‡æ–‡æœ¬é‡å»º**  
  ä»¥å¾€å·¥ä½œï¼ˆå¦‚ MoEcho, Ding et al., 2025ï¼‰ä½¿ç”¨ logistic regression è¿›è¡Œ token æ¢å¤ï¼Œæ•ˆæœæœ‰é™ã€‚æœ¬æ–‡æå‡ºæ›´å¼ºå¤§çš„è§£ç å™¨æ¶æ„ï¼Œæ˜¾è‘—æå‡é‡å»ºèƒ½åŠ›ã€‚

- **å¼•å…¥åŸºäº Transformer çš„ sequence decoder**  
  ä¸åŒäºé€ token ç‹¬ç«‹é¢„æµ‹çš„æ–¹æ³•ï¼Œä½œè€…è®¾è®¡äº†ä¸€ä¸ª **encoder-only Transformer æ¶æ„**ï¼Œèƒ½å¤Ÿè”åˆå»ºæ¨¡æ•´ä¸ªåºåˆ—çš„ expert selection traceï¼Œåˆ©ç”¨ä¸Šä¸‹æ–‡ä¾èµ–å…³ç³»è¿›è¡Œåºåˆ—çº§è§£ç ã€‚

- **è¿æ¥ MoE è·¯ç”±ä¸ embedding inversion é¢†åŸŸ**  
  å°† expert selection è§†ä¸ºä¸€ç§â€œç¦»æ•£åµŒå…¥â€ï¼ˆdiscrete embeddingï¼‰ï¼Œå»ºç«‹èµ·ä¸è¿ç»­å‘é‡ç©ºé—´ä¸­çš„ **embedding inversion** æ”»å‡»ä¹‹é—´çš„ç†è®ºè”ç³»ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | æœ¬æ–‡æ–¹æ³•ä¼˜åŠ¿ |
|------|---------------|
| **é‡å»ºç²¾åº¦** | æ˜¾è‘—ä¼˜äº prior workï¼ˆå¦‚ logistic regression æˆ–å•å±‚ MLPï¼‰ï¼Œtop-1 å‡†ç¡®ç‡ä»ä¸è¶³ 50% æå‡è‡³ **91.2%** |
| **å»ºæ¨¡èŒƒå¼** | é‡‡ç”¨ sequence-to-sequence å­¦ä¹ æ¡†æ¶ï¼Œè€Œé per-token åˆ†ç±»ï¼Œèƒ½æ•æ‰ä½ç½®é—´ä¾èµ– |
| **å¨èƒæ¨¡å‹æ‰©å±•æ€§** | æ¢è®¨å¤šç§å®é™…æ³„æ¼åœºæ™¯ï¼ˆåˆ†å¸ƒå¼æ¨ç†ã€ç‰©ç†ä¾§ä¿¡é“ç­‰ï¼‰ï¼Œæ›´å…·ç°å®æ„ä¹‰ |
| **ç†è®ºåˆ†ææ·±åº¦** | å¯¹å„å±‚çš„ä¿¡æ¯ç†µå’Œäº’ä¿¡æ¯è¿›è¡Œäº†é‡åŒ–åˆ†æï¼Œæ­ç¤ºä¸åŒå±‚çš„æ³„éœ²ç‰¹æ€§ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†

- **OpenWebText**ï¼šä½œä¸ºè®­ç»ƒä¸æµ‹è¯•æ•°æ®æ¥æºï¼Œå› å…¶æ¶µç›–å¹¿æ³›æ–‡æœ¬ç±»å‹ï¼ˆå«é«˜ç†µå†…å®¹å¦‚å¯†ç ã€API å¯†é’¥ç­‰ï¼‰ï¼Œé€‚åˆè¯„ä¼°éšç§æ³„éœ²é£é™©ã€‚
- **è®­ç»ƒæ•°æ®è§„æ¨¡**ï¼šåœ¨ `gpt-oss-20b` æ¨¡å‹ä¸Šå¤„ç† **1äº¿ä¸ª tokens**ï¼Œåˆ’åˆ†ä¸º 32-token çš„ç‰‡æ®µï¼Œç”Ÿæˆ `(token sequence, expert-selection trace)` å¯¹ã€‚
- **æµ‹è¯•é›†**ï¼šç‹¬ç«‹ä¿ç•™çš„ 1000ä¸‡ tokensï¼Œæœªå‚ä¸è®­ç»ƒã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®

#### æ¨¡å‹é…ç½®ï¼ˆvictim modelï¼‰
- æ¨¡å‹ï¼š`gpt-oss-20b`
- MoE å‚æ•°ï¼š
  - å±‚æ•°ï¼š24 layers
  - æ¯å±‚ expert æ•°é‡ï¼š32
  - Top-k routingï¼šk=4ï¼ˆå³æ¯ token é€‰ 4 ä¸ª expertï¼‰
- è¾“å‡ºä¿¡å·ï¼šä»… **expert indices**ï¼ˆæ—  logitsã€hidden statesã€expert outputsï¼‰

#### æ”»å‡»è€…å‡è®¾ï¼ˆThreat Modelï¼‰
- å·²çŸ¥ tokenizer å’Œ MoE é…ç½®ï¼ˆn=32, k=4ï¼‰
- å¯è·å–åŒæ—æ¨¡å‹æˆ–æ—¥å¿—ä¸­çš„ `(text, trace)` è®­ç»ƒå¯¹
- è§‚å¯Ÿç›®æ ‡åºåˆ—çš„æ‰€æœ‰ layer çš„ expert selectionï¼ˆå¯éƒ¨åˆ†è§‚å¯Ÿï¼‰

#### è¾“å…¥è¡¨ç¤º
- æ¯ä¸ª layer çš„ top-4 expert indices â†’ ç¼–ç ä¸º 32 ç»´äºŒå€¼å‘é‡ï¼ˆone-hot ä¸­å– 4 ä¸ª 1ï¼‰
- æ‰€æœ‰ 24 å±‚æ‹¼æ¥åé€å…¥ decoderï¼Œå¹¶åŠ å…¥ learnable positional embeddings

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡

- **Top-1 / Top-5 / Top-10 å‡†ç¡®ç‡**ï¼šé‡å»º token æ˜¯å¦å‡ºç°åœ¨é¢„æµ‹åˆ†å¸ƒçš„å‰ k åä¸­
- ä¸»è¦ä»»åŠ¡ï¼šç»™å®š expert selection trace $ I $ï¼Œæ¢å¤åŸå§‹ token åºåˆ— $ x_{1:T} $

---

### ğŸ”¤ åŸºçº¿æ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | æè¿° |
|------|------|
| **Logistic Regression** | Prior work å¸¸ç”¨æ–¹æ³•ï¼Œæ€§èƒ½è¾ƒä½ï¼ˆæ–‡ä¸­æœªç»™å‡ºå…·ä½“æ•°å€¼ï¼Œä½†æŒ‡å‡ºå…¶å—é™ï¼‰ |
| **3-layer MLP** | å• token è§£ç å™¨ï¼Œä½œä¸ºå¼ºåŸºçº¿ |
| **Transformer-based Sequence Decoder** | æœ¬æ–‡æå‡ºçš„åºåˆ—åŒ–è§£ç å™¨ï¼Œä¸»æ¨æ–¹æ³• |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Figure 1ï¼‰

| æ–¹æ³• | Top-1 Acc | Top-5 Acc | Top-10 Acc |
|------|-----------|-----------|------------|
| **3-layer MLP** | **63.1%** | 80.3% | 84.3% |
| **Transformer Sequence Decoder** | **91.2%** | 94.3% | **94.8%** |

> åœ¨ 32-token åºåˆ—ä¸Šï¼Œä½¿ç”¨å…¨éƒ¨ 24 å±‚çš„ expert selectionï¼Œsequence decoder å®ç°äº†æ¥è¿‘äººç±»å¯è¯»çº§åˆ«çš„é‡å»ºè´¨é‡ã€‚

---

### ğŸ” ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ

- **ç›¸æ¯” MLP æå‡å·¨å¤§**ï¼šTop-1 å‡†ç¡®ç‡æå‡è¿‘ 30 ä¸ªç™¾åˆ†ç‚¹ï¼Œè¯´æ˜ **åºåˆ—å»ºæ¨¡èƒ½åŠ›è‡³å…³é‡è¦**ã€‚
- **top-10 æ¥è¿‘é¥±å’Œ**ï¼šè¾¾åˆ° 94.8%ï¼Œè¡¨æ˜å³ä½¿ä¸èƒ½å®Œå…¨å‘½ä¸­æ­£ç¡® tokenï¼Œä¹Ÿèƒ½å°†å…¶æ’åœ¨æé«˜æ’åã€‚
- **context åˆ©ç”¨æœ‰æ•ˆ**ï¼štransformer decoder æˆåŠŸæ•è·äº†è·¨ token çš„è¯­ä¹‰ä¸€è‡´æ€§ï¼ˆä¾‹å¦‚è¯­æ³•ç»“æ„ã€å‘½åå®ä½“å»¶ç»­ç­‰ï¼‰ã€‚

---

### ğŸ” æ¶ˆèå®éªŒä¸è¡¥å……åˆ†æ

#### ï¼ˆ1ï¼‰è®­ç»ƒæ•°æ®é‡å½±å“ï¼ˆFigure 2ï¼‰
- æ€§èƒ½åœ¨ **1M â†’ 100M tokens** åŒºé—´å†…æŒç»­ä¸Šå‡ï¼Œæœªè§é¥±å’Œ
- è¡¨æ˜æ›´å¤šè®­ç»ƒæ•°æ®ä»å¯èƒ½è¿›ä¸€æ­¥æå‡é‡å»ºèƒ½åŠ›

#### ï¼ˆ2ï¼‰æŒ‰ token é¢‘ç‡åˆ†ç»„å‡†ç¡®ç‡ï¼ˆFigure 3ï¼‰
- é«˜é¢‘è¯é‡å»ºå‡†ç¡®ç‡æ›´é«˜ï¼ˆç¬¦åˆé¢„æœŸï¼‰
- ä½†å³ä½¿æ˜¯ä½é¢‘è¯ï¼ˆlogâ‚â‚€ count < 2ï¼‰ï¼Œä»æœ‰å¯è§‚é‡å»ºèƒ½åŠ›ï¼ˆ~40â€“60% top-1ï¼‰

#### ï¼ˆ3ï¼‰å™ªå£°é²æ£’æ€§æµ‹è¯•ï¼ˆFigure 6ï¼‰
- å¼•å…¥éšæœºå™ªå£°ï¼ˆæ›¿æ¢éƒ¨åˆ† expert selection ä¸ºéšæœº expertï¼‰
- å½“ **noise rate = 0.5** æ—¶ï¼Œtop-1 å‡†ç¡®ç‡ä¸‹é™è‡³ ~50%
- è¡¨æ˜è½»å¾®æ‰°åŠ¨æ— æ³•å½»åº•é˜»æ­¢æ”»å‡»ï¼Œéœ€æ›´å¼ºé˜²å¾¡æœºåˆ¶

#### ï¼ˆ4ï¼‰å±‚æ•°ä¿¡æ¯åˆ†æï¼ˆFigure 4 & 5ï¼‰
- **ä¸­é—´å±‚ï¼ˆçº¦ç¬¬ 11 å±‚ï¼‰å…·æœ‰æœ€é«˜ç†µ**ï¼Œå¯èƒ½æ˜¯æœ€å…·ä¿¡æ¯é‡çš„åŒºåŸŸ
- æ—©æœŸå±‚ä¹‹é—´äº’ä¿¡æ¯é«˜ï¼ˆå†—ä½™æ€§å¼ºï¼‰ï¼Œä¸­é—´ä¸æ™šæœŸå±‚å·®å¼‚å¤§ï¼Œæš—ç¤ºå¤šé˜¶æ®µè·¯ç”±ç­–ç•¥

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **Expert selections æ³„éœ²å¤§é‡è¯­ä¹‰ä¿¡æ¯**  
   å°½ç®¡æ˜¯ç¦»æ•£ã€ä½å¸¦å®½ä¿¡å·ï¼Œä½†ç”±äºå…¶ä¾èµ–ä¸Šä¸‹æ–‡ä¸”å…·æœ‰ determinismï¼Œå½¢æˆäº†é«˜åº¦ä¿¡æ¯æ€§çš„â€œæŒ‡çº¹â€ã€‚

2. **åºåˆ—çº§ decoder æ˜¾è‘—ä¼˜äºç‹¬ç«‹ token é¢„æµ‹**  
   ä¸Šä¸‹æ–‡å»ºæ¨¡æå¤§æå‡äº†é‡å»ºèƒ½åŠ›ï¼Œè¯´æ˜ expert selection trace å…·æœ‰ strong sequential structureã€‚

3. **MoE è·¯ç”±åº”è¢«è§†ä¸ºæ•æ„Ÿè¾“å‡º**  
   ä½œè€…å¼ºè°ƒï¼š**expert selection traces åº”è¢«å½“ä½œä¸åŸå§‹æ–‡æœ¬åŒç­‰æ•æ„Ÿçš„æ•°æ®æ¥å¯¹å¾…**ã€‚

4. **å¤šç§ç°å®æ”»å‡»é¢å­˜åœ¨å¯è¡Œæ€§**
   - **åˆ†å¸ƒå¼æ¨ç†**ï¼šæ¶æ„ä¸»æœºå¯è®°å½• routing trace å¹¶åæ¨ç”¨æˆ·è¾“å…¥
   - **ä¾§ä¿¡é“æ”»å‡»**ï¼ˆSide Channelsï¼‰ï¼šé€šè¿‡ GPU performance countersã€åŠŸè€—ã€ç”µç£è¾å°„ç­‰é—´æ¥è§‚æµ‹ expert æ¿€æ´»æ¨¡å¼
   - **Pipeline-parallel MoE**ï¼šè·¨èŠ‚ç‚¹è°ƒåº¦æ—¶æš´éœ²è®¾å¤‡æ¿€æ´»æ¨¡å¼

5. **æ·»åŠ å™ªå£°åªèƒ½ç¼“è§£ï¼Œä¸èƒ½æ ¹é™¤æ³„éœ²**
   - å³ä½¿ 50% çš„ expert è¢«éšæœºæ›¿æ¢ï¼Œä»èƒ½å®ç° ~50% top-1 å‡†ç¡®ç‡
   - è¡¨æ˜ç®€å•æ‰°åŠ¨ä¸è¶³ä»¥æ„æˆæœ‰æ•ˆé˜²å¾¡

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

| å±€é™ | è¯´æ˜ |
|------|------|
| **çŸ­åºåˆ—ä¸ºä¸»** | æœ€ä½³ç»“æœåŸºäº 32-token åºåˆ—ï¼Œå°šæœªç³»ç»ŸéªŒè¯é•¿åºåˆ—ï¼ˆæ•°ç™¾è‡³ä¸Šåƒ tokenï¼‰ä¸‹çš„è¡¨ç° |
| **ä¾èµ–è®­ç»ƒæ•°æ®åŒ¹é…** | éœ€è¦è·å¾—åŒ family æ¨¡å‹æˆ–ç›¸åŒ tokenizer çš„ `(text, trace)` å¯¹ï¼Œè·¨æ¨¡å‹è¿ç§»æ€§æœªçŸ¥ |
| **å®Œæ•´ trace å‡è®¾** | é»˜è®¤è®¿é—®æ‰€æœ‰ 24 å±‚ï¼Œè‹¥åªè§‚å¯Ÿéƒ¨åˆ†å±‚ï¼Œæ€§èƒ½ä¼šä¸‹é™ï¼ˆæœªé‡åŒ–ï¼‰ |
| **decoder å¤æ‚åº¦é«˜** | ä½¿ç”¨ large transformer + å¤§é‡è®­ç»ƒæ•°æ®ï¼Œè½»é‡çº§æ”»å‡»è¾ƒéš¾å®æ–½ |

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **ç ”ç©¶é•¿åºåˆ—ä¸‹çš„ inversion æé™**
   - æ¢ç´¢ hierarchical modeling æˆ– beam search ç­‰æœç´¢ç­–ç•¥
2. **è·¨æ¨¡å‹ transferability ç ”ç©¶**
   - èƒ½å¦åœ¨ä¸€ä¸ª MoE æ¨¡å‹ä¸Šè®­ç»ƒ decoderï¼Œåœ¨å¦ä¸€ä¸ªä¸Šåº”ç”¨ï¼Ÿ
3. **é˜²å¾¡æœºåˆ¶çš„è®¾è®¡ä¸æƒè¡¡è¯„ä¼°**
   - å¦‚ä½•åœ¨ä¸å½±å“æ¨¡å‹æ€§èƒ½çš„å‰æä¸‹å¢å¼ºéšç§ä¿æŠ¤ï¼Ÿ
   - ä¾‹å¦‚ï¼šrouting randomizationã€dummy computationã€expert permutation
4. **ç‰©ç†ä¾§ä¿¡é“å®è¯éªŒè¯**
   - ç»“åˆç¡¬ä»¶æµ‹é‡ï¼Œç«¯åˆ°ç«¯éªŒè¯ä» EM/power signal åˆ° text recovery çš„å¯è¡Œæ€§
5. **å½¢å¼åŒ–ä¿¡æ¯è®ºåˆ†æ**
   - æ›´ç²¾ç¡®ä¼°è®¡ expert selection çš„ä¿¡æ¯å®¹é‡ä¸ invertibility ä¸‹ç•Œ

---

## ğŸ’¡ æ€»ç»“ä¸€å¥è¯

> **åœ¨ MoE æ¨¡å‹ä¸­ï¼Œexpert selection traces æ‰€æ³„éœ²çš„ä¿¡æ¯å‡ ä¹ä¸åŸå§‹æ–‡æœ¬æœ¬èº«ä¸€æ ·å¤šâ€”â€”å®ƒä»¬ä¸åº”å†è¢«è§†ä¸ºâ€œå‰¯äº§å“â€ï¼Œè€Œåº”è¢«å½“ä½œæ•æ„Ÿæ•°æ®ä¸¥åŠ é˜²æŠ¤ã€‚**

</details>

---

### 16. [OmniSIFT: Modality-Asymmetric Token Compression for Efficient Omni-modal Large Language Models](https://arxiv.org/abs/2602.04804)

**Authors**: Yue Ding, Yiyan Ji, Jungang Li, Xuyang Liu, Xinlong Chen, Junfei Wu, Bozhou Li, Bohan Zeng, Yang Shi, Yushuo Guan, Yuanxing Zhang, Jiaheng Liu, Qiang Liu, Pengfei Wan, Liang Wang  
**Category**: cs.CL  
**Published**: 2026-02-05  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.04804v1  

#### Abstract
Omni-modal Large Language Models (Omni-LLMs) have demonstrated strong capabilities in audio-video understanding tasks. However, their reliance on long multimodal token sequences leads to substantial computational overhead. Despite this challenge, token compression methods designed for Omni-LLMs rema...

---

### 17. [Scaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL](https://arxiv.org/abs/2602.04089)

**Authors**: Xiaofeng Lin, Sirou Zhu, Yilei Chen, Mingyu Chen, Hejian Sang, Ioannis Paschalidis, Zhipeng Wang, Aldo Pacchiano, Xuezhou Zhang  
**Category**: cs.AI  
**Published**: 2026-02-05  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.04089v1  

#### Abstract
Large language models (LLMs) achieve strong performance when all task-relevant information is available upfront, as in static prediction and instruction-following problems. However, many real-world decision-making tasks are inherently online: crucial information must be acquired through interaction,...

---

### 18. [WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.04634)

**Authors**: Zelai Xu, Zhexuan Xu, Ruize Zhang, Chunyang Zhu, Shi Yu, Weilin Liu, Quanlu Zhang, Wenbo Ding, Chao Yu, Yu Wang  
**Category**: cs.AI  
**Published**: 2026-02-05  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.04634v1  

#### Abstract
Recent advancements in Large Language Models (LLMs) have largely focused on depth scaling, where a single agent solves long-horizon problems with multi-turn reasoning and tool use. However, as tasks grow broader, the key bottleneck shifts from individual competence to organizational capability. In t...

---

### 19. [CoLT: Reasoning with Chain of Latent Tool Calls](https://arxiv.org/abs/2602.04246)

**Authors**: Fangwei Zhu, Zhifang Sui  
**Category**: cs.CL  
**Published**: 2026-02-05  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.04246v1  

#### Abstract
Chain-of-Thought (CoT) is a critical technique in enhancing the reasoning ability of Large Language Models (LLMs), and latent reasoning methods have been proposed to accelerate the inefficient token-level reasoning chain. We notice that existing latent reasoning methods generally require model struc...

---

### 20. [Guided Verifier: Collaborative Multimodal Reasoning via Dynamic Process Supervision](https://arxiv.org/abs/2602.04290)

**Authors**: Lingzhuang Sun, Ruitong Liu, Yuxia Zhu, Xiaohan Xu, Jingxuan Wei, Xiangxiang Zhang, Bihui Yu, Wentao Zhang  
**Category**: cs.CL  
**Published**: 2026-02-05  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.04290v1  

#### Abstract
Reinforcement Learning (RL) has emerged as a pivotal mechanism for enhancing the complex reasoning capabilities of Multimodal Large Language Models (MLLMs). However, prevailing paradigms typically rely on solitary rollout strategies where the model works alone. This lack of intermediate oversight re...

---

### 21. [CoT is Not the Chain of Truth: An Empirical Internal Analysis of Reasoning LLMs for Fake News Generation](https://arxiv.org/abs/2602.04856)

**Authors**: Zhao Tong, Chunlin Gong, Yiping Zhang, Qiang Liu, Xingcheng Xu, Shu Wu, Haichao Shi, Xiao-Yu Zhang  
**Category**: cs.CL  
**Published**: 2026-02-05  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.04856v1  

#### Abstract
From generating headlines to fabricating news, the Large Language Models (LLMs) are typically assessed by their final outputs, under the safety assumption that a refusal response signifies safe reasoning throughout the entire process. Challenging this assumption, our study reveals that during fake n...

---

### 22. [SAFE: Stable Alignment Finetuning with Entropy-Aware Predictive Control for RLHF](https://arxiv.org/abs/2602.04651)

**Authors**: Dipan Maity  
**Category**: cs.LG  
**Published**: 2026-02-05  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.04651v1  

#### Abstract
Optimization (PPO) has been positioned by recent literature as the canonical method for the RL part of RLHF. PPO performs well empirically but has a heuristic motivation and handles the KL-divergence constraint used in LM-RLHF in an ad-hoc manner and suffers form reward oscillations, entropy collaps...

---

### 23. [OMG-Agent: Toward Robust Missing Modality Generation with Decoupled Coarse-to-Fine Agentic Workflows](https://arxiv.org/abs/2602.04144)

**Authors**: Ruiting Dai, Zheyu Wang, Haoyu Yang, Yihan Liu, Chengzhi Wang, Zekun Zhang, Zishan Huang, Jiaman Cen, Lisi Mo  
**Category**: cs.AI  
**Published**: 2026-02-05  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.04144v1  

#### Abstract
Data incompleteness severely impedes the reliability of multimodal systems. Existing reconstruction methods face distinct bottlenecks: conventional parametric/generative models are prone to hallucinations due to over-reliance on internal memory, while retrieval-augmented frameworks struggle with ret...

---

### 24. [From Assumptions to Actions: Turning LLM Reasoning into Uncertainty-Aware Planning for Embodied Agents](https://arxiv.org/abs/2602.04326)

**Authors**: SeungWon Seo, SooBin Lim, SeongRae Noh, Haneul Kim, HyeongYeop Kang  
**Category**: cs.AI  
**Published**: 2026-02-05  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.04326v1  

#### Abstract
Embodied agents operating in multi-agent, partially observable, and decentralized environments must plan and act despite pervasive uncertainty about hidden objects and collaborators' intentions. Recent advances in applying Large Language Models (LLMs) to embodied agents have addressed many long-stan...

---

### 25. [Non-linear PCA via Evolution Strategies: a Novel Objective Function](https://arxiv.org/abs/2602.03967)

**Authors**: Thomas Uriot, Elise Chung  
**Category**: cs.LG  
**Published**: 2026-02-05  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.03967v1  

#### Abstract
Principal Component Analysis (PCA) is a powerful and popular dimensionality reduction technique. However, due to its linear nature, it often fails to capture the complex underlying structure of real-world data. While Kernel PCA (kPCA) addresses non-linearity, it sacrifices interpretability and strug...

---

### 26. [BPDQ: Bit-Plane Decomposition Quantization on a Variable Grid for Large Language Models](https://arxiv.org/abs/2602.04163)

**Authors**: Junyu Chen, Jungang Li, Jing Xiong, Wenjie Wang, Qingyao Yang, He Xiao, Zhen Li, Taiqiang Wu, Mengzhao Chen, Zhen Peng, Chaofan Tao, Long Shi, Hongxia Yang, Ngai Wong  
**Category**: cs.LG  
**Published**: 2026-02-05  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.04163v1  

#### Abstract
Large language model (LLM) inference is often bounded by memory footprint and memory bandwidth in resource-constrained deployments, making quantization a fundamental technique for efficient serving. While post-training quantization (PTQ) maintains high fidelity at 4-bit, it deteriorates at 2-3 bits....

---

### 27. [From Sparse Sensors to Continuous Fields: STRIDE for Spatiotemporal Reconstruction](https://arxiv.org/abs/2602.04201)

**Authors**: Yanjie Tong, Peng Chen  
**Category**: cs.LG  
**Published**: 2026-02-05  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.04201v1  

#### Abstract
Reconstructing high-dimensional spatiotemporal fields from sparse point-sensor measurements is a central challenge in learning parametric PDE dynamics. Existing approaches often struggle to generalize across trajectories and parameter settings, or rely on discretization-tied decoders that do not nat...

---

### 28. [Cascading Robustness Verification: Toward Efficient Model-Agnostic Certification](https://arxiv.org/abs/2602.04236)

**Authors**: Mohammadreza Maleki, Rushendra Sidibomma, Arman Adibi, Reza Samavi  
**Category**: cs.LG  
**Published**: 2026-02-05  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.04236v1  

#### Abstract
Certifying neural network robustness against adversarial examples is challenging, as formal guarantees often require solving non-convex problems. Hence, incomplete verifiers are widely used because they scale efficiently and substantially reduce the cost of robustness verification compared to comple...

---

### 29. [Convolution Operator Network for Forward and Inverse Problems (FI-Conv): Application to Plasma Turbulence Simulations](https://arxiv.org/abs/2602.04287)

**Authors**: Xingzhuo Chen, Anthony Poole, Ionut-Gabriel Farcas, David R. Hatch, Ulisses Braga-Neto  
**Category**: cs.LG  
**Published**: 2026-02-05  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.04287v1  

#### Abstract
We propose the Convolutional Operator Network for Forward and Inverse Problems (FI-Conv), a framework capable of predicting system evolution and estimating parameters in complex spatio-temporal dynamics, such as turbulence. FI-Conv is built on a U-Net architecture, in which most convolutional layers...

---

### 30. [Steering LLMs via Scalable Interactive Oversight](https://arxiv.org/abs/2602.04210)

**Authors**: Enyu Zhou, Zhiheng Xi, Long Ma, Zhihao Zhang, Shihan Dou, Zhikai Lei, Guoteng Wang, Rui Zheng, Hang Yan, Tao Gui, Qi Zhang, Xuanjing Huang  
**Category**: cs.AI  
**Published**: 2026-02-05  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2602.04210v1  

#### Abstract
As Large Language Models increasingly automate complex, long-horizon tasks such as \emph{vibe coding}, a supervision gap has emerged. While models excel at execution, users often struggle to guide them effectively due to insufficient domain expertise, the difficulty of articulating precise intent, a...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- kv cache, offload, State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
