# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-02-04 06:18:21 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [DALI: A Workload-Aware Offloading Framework for Efficient MoE Inference on Local PCs](https://arxiv.org/abs/2602.03495)

**Authors**: Zeyu Zhu, Gang Li, Peisong Wang, Zitao Mo, Minnan Pei, Zhuoran Song, Xiaoyao Liang, Jian Cheng  
**Category**: cs.DC  
**Published**: 2026-02-04  
**Score**: 15.0  
**Type**: new  
**ArXiv ID**: 2602.03495v1  

#### Abstract
Mixture of Experts (MoE) architectures significantly enhance the capacity of LLMs without proportional increases in computation, but at the cost of a vast parameter size. Offloading MoE expert parameters to host memory and leveraging both CPU and GPU computation has recently emerged as a promising d...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDALI: A Workload-Aware Offloading Framework for Efficient MoE Inference on Local PCs

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ç°æœ‰çš„ MoEï¼ˆMixture of Expertsï¼‰æ¨¡å‹åœ¨æœ¬åœ°PCä¸Šè¿›è¡Œæ¨ç†æ—¶é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼Œæºäºä¸“å®¶æ¿€æ´»çš„**åŠ¨æ€æ€§å’Œå¼‚æ„ç¡¬ä»¶èµ„æºçš„ä¸å‡è¡¡åˆ©ç”¨**ï¼š

1. **CPU-GPU è´Ÿè½½ä¸å¹³è¡¡**ï¼šé™æ€çš„ä¸“å®¶åˆ†é…ç­–ç•¥ï¼ˆå¦‚å°†é«˜è´Ÿè½½ä¸“å®¶å›ºå®šåˆ†é…ç»™GPUï¼‰å¯¼è‡´è®¡ç®—èµ„æºåˆ©ç”¨ç‡ä½ä¸‹ï¼Œåœ¨ä¸åŒè¾“å…¥ä¸‹å‡ºç°ä¸¥é‡çš„è´Ÿè½½å¤±è¡¡ã€‚
2. **é¢„å–ï¼ˆPrefetchingï¼‰å‡†ç¡®æ€§ä½**ï¼šç°æœ‰é¢„å–æœºåˆ¶æ— æ³•å‡†ç¡®é¢„æµ‹ä¸‹ä¸€å±‚ä¸­å°†è¢«é«˜é¢‘ä½¿ç”¨çš„é«˜è´Ÿè½½ä¸“å®¶ï¼Œå¯¼è‡´å¤§é‡æ— æ•ˆçš„ PCIe æ•°æ®ä¼ è¾“ã€‚
3. **GPU ç¼“å­˜æ•ˆç‡å·®**ï¼šä¼ ç»Ÿç¼“å­˜æ›¿æ¢ç­–ç•¥ï¼ˆå¦‚ LRU æˆ–åŸºäºæ¿€æ´»åˆ†æ•°ï¼‰æœªè€ƒè™‘ä¸“å®¶å·¥ä½œè´Ÿè½½çš„æ—¶é—´ç›¸å…³æ€§ï¼Œå‘½ä¸­ç‡ä½ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½œè€…æå‡ºäº† **DALI** â€”â€”ä¸€ä¸ªé¢å‘æœ¬åœ°PCå¹³å°ã€**å·¥ä½œè´Ÿè½½æ„ŸçŸ¥**ï¼ˆworkload-awareï¼‰çš„ MoE æ¨ç†å¸è½½æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ä»¥ä¸‹ä¸‰ä¸ªå…³é”®æŠ€æœ¯ï¼š

#### ï¼ˆ1ï¼‰Greedy Assignment Strategyï¼ˆè´ªå¿ƒåˆ†é…ç­–ç•¥ï¼‰
- å°†ä¸“å®¶åœ¨ CPU å’Œ GPU ä¹‹é—´çš„åˆ†é…å»ºæ¨¡ä¸ºä¸€ä¸ª **0-1 æ•´æ•°ä¼˜åŒ–é—®é¢˜**ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ– `max(Tgpu, Tcpu)`ï¼Œå³æœ€å°åŒ–ç“¶é¢ˆè®¾å¤‡çš„æ‰§è¡Œæ—¶é—´ã€‚
- è®¾è®¡äº†ä¸€ç§é«˜æ•ˆçš„ **è´ªå¿ƒç®—æ³•** æ¥è¿‘ä¼¼æ±‚è§£è¯¥é—®é¢˜ï¼Œåœ¨æä½å¼€é”€ä¸‹å®ç°æ¥è¿‘æœ€ä¼˜çš„è´Ÿè½½å‡è¡¡ã€‚
- åŠ¨æ€åœ°æ ¹æ®å½“å‰ token çš„ä¸“å®¶æ¿€æ´»æ¨¡å¼å®æ—¶å†³ç­–ï¼Œè€Œéé‡‡ç”¨é™æ€é˜ˆå€¼åˆ’åˆ†ã€‚

#### ï¼ˆ2ï¼‰Residual-Based Prefetchingï¼ˆåŸºäºæ®‹å·®çš„é¢„å–ï¼‰
- åˆ©ç”¨ Transformer å±‚é—´å­˜åœ¨çš„ **residual connection** ä¸­çš„éšè—çŠ¶æ€å·®å¼‚ï¼ˆ`res_vec`ï¼‰ï¼Œå¯¹ä¸‹ä¸€å±‚é—¨æ§å‡½æ•°çš„è¾“å…¥ç‰¹å¾è¿›è¡Œæ ¡æ­£ã€‚
- é€šè¿‡è¿™ç§è·¨å±‚æ®‹å·®ä¿¡æ¯å¢å¼ºç‰¹å¾è¡¨ç¤ºï¼Œæ˜¾è‘—æå‡å¯¹â€œé«˜è´Ÿè½½ä¸“å®¶â€çš„é¢„æµ‹ç²¾åº¦ã€‚
- é¢„å–å‘é‡å¯ç¦»çº¿æ„å»ºå¹¶å¤ç”¨äºå¤šç§ä¸‹æ¸¸ä»»åŠ¡ï¼Œæ— éœ€å¾®è°ƒã€‚

#### ï¼ˆ3ï¼‰Workload-Aware Cache Replacementï¼ˆå·¥ä½œè´Ÿè½½æ„ŸçŸ¥ç¼“å­˜æ›¿æ¢ï¼‰
- è§‚å¯Ÿåˆ°é«˜è´Ÿè½½ä¸“å®¶å…·æœ‰å¼º**æ—¶é—´å±€éƒ¨æ€§**ï¼ˆtemporal correlationï¼‰ï¼šè‹¥æŸä¸“å®¶åœ¨ token i ä¸Šæ˜¯é«˜è´Ÿè½½ï¼Œåˆ™åœ¨ token i+1 ä¸Šä¹Ÿå¾ˆå¯èƒ½æ˜¯ã€‚
- æå‡ºä¸€ç§æ»‘åŠ¨çª—å£æœºåˆ¶ï¼Œç´¯ç§¯æ¯ä¸ªä¸“å®¶åœ¨è¿‡å»è‹¥å¹² token ä¸­çš„å·¥ä½œè´Ÿè½½å¾—åˆ†ï¼Œå¹¶æ®æ­¤æ›´æ–° GPU ç¼“å­˜ã€‚
- æ›¿æ¢æ—¶ä¼˜å…ˆä¿ç•™å†å²é«˜è´Ÿè½½ä¸“å®¶ï¼Œæ·˜æ±°ä½åˆ†ä¸“å®¶ï¼Œä»è€Œå¤§å¹…æå‡ç¼“å­˜å‘½ä¸­ç‡ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ HybriMoE, llama.cppï¼‰ | DALI çš„ä¼˜åŠ¿ |
|------|-------------------------------|-------------|
| åˆ†é…ç­–ç•¥ | é™æ€ä¸“å®¶åˆ†é…ï¼ˆlayer-wise æˆ– expert-wiseï¼‰ | **åŠ¨æ€ã€è´Ÿè½½æ„ŸçŸ¥**ï¼Œå®ç°æ›´ä¼˜çš„ CPU-GPU å¹¶è¡Œ |
| é¢„å–æœºåˆ¶ | åŸºäºåŸå§‹è¾“å…¥æˆ–ç»Ÿè®¡ç‰¹å¾ï¼Œå‡†ç¡®ç‡ä½ | å¼•å…¥ **residual correction**ï¼Œå¤§å¹…æé«˜é«˜è´Ÿè½½ä¸“å®¶é¢„æµ‹å‡†ç¡®ç‡ |
| ç¼“å­˜ç®¡ç† | LRU æˆ– activation score-based | åŸºäº **å†å² workload å¾—åˆ†**ï¼Œå‘½ä¸­ç‡æ›´é«˜ |
| æ€»ä½“æ•ˆæœ | å—é™äºé€šä¿¡ç“¶é¢ˆå’Œèµ„æºæµªè´¹ | æ˜¾è‘—é™ä½ PCIe é€šä¿¡å¼€é”€ï¼Œæå‡ç«¯åˆ°ç«¯æ¨ç†é€Ÿåº¦ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
- **C4**ï¼šç”¨äºä¸»æ¨ç†æ€§èƒ½æµ‹è¯•ï¼ˆspeed benchmarkingï¼‰ã€‚
- **Wikitext**ï¼šç”¨äºæ„å»º calibration datasetï¼ˆé‡‡æ ·1Kåºåˆ—ï¼‰ï¼Œä»¥ç¦»çº¿ç”Ÿæˆå„å±‚çš„ `res_vec` æ®‹å·®å‘é‡ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼š
  - CPU: AMD EPYC 7532 (64 cores)
  - GPU: NVIDIA RTX 3090 (24GB HBM)
  - å†…å­˜: 256GB DDR4 DRAM
  - æ¥å£: PCIe 4.0 Ã—16 (~32 GB/s)
- **æ¨¡å‹**ï¼š
  - **DeepSeek-V2-Lite-Chat** (27 layers, 64 routed experts/layer)
  - **Qwen3-30B-A3B** (48 layers, 128 experts/layer)
  - **Mixtral-8x7B-Instruct** (32 layers, 8 experts/layer)

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
- **æ¨ç†é˜¶æ®µ**ï¼šåˆ†ä¸º **prefill**ï¼ˆå¤„ç†æç¤ºè¯ï¼‰å’Œ **decoding**ï¼ˆé€ä¸ªç”Ÿæˆ tokenï¼‰ä¸¤ä¸ªé˜¶æ®µåˆ†åˆ«è¯„æµ‹ã€‚
- **ä¸»è¦æŒ‡æ ‡**ï¼š**Tokens per second (tokens/s)**ï¼ŒæŠ¥å‘Šæ‰¹å¤„ç†ä¸­æ‰€æœ‰åºåˆ—çš„å¹³å‡ååé‡ã€‚
- **å…¶ä»–è¾…åŠ©æŒ‡æ ‡**ï¼š
  - PCIe ä¼ è¾“æ—¶é—´å æ¯”
  - ç¼“å­˜å‘½ä¸­ç‡ï¼ˆHit Rateï¼‰
  - é¢„å–å‡†ç¡®ç‡ï¼ˆPrefetch Accuracyï¼‰
  - MoE å±‚æ‰§è¡Œæ—¶é—´åˆ†è§£

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **llama.cpp** | Layer-wise Hybrid | å°†å‰è‹¥å¹² MoE å±‚æ”¾ CPUï¼Œå…¶ä½™æ”¾ GPU |
| **KTransformers** | Layer-wise Hybrid | åŒä¸Šï¼Œæ”¯æŒæ›´å¤šä¼˜åŒ– |
| **MoE-Lightning** | Offline Search | ç¦»çº¿æœç´¢éƒ¨ç½²ç­–ç•¥ï¼Œç¼ºä¹åŠ¨æ€é€‚åº”èƒ½åŠ› |
| **HybriMoE** | Expert-wise Hybrid | æ”¯æŒä¸“å®¶çº§è°ƒåº¦ã€é¢„å–ä¸ç¼“å­˜ï¼Œæ˜¯å½“å‰æœ€å¼º baseline |

> æ‰€æœ‰æ–¹æ³•å‡æ§åˆ¶ç›¸åŒæ•°é‡çš„ CPU çº¿ç¨‹ï¼ˆ32ï¼‰ã€GPU æ˜¾å­˜ä½¿ç”¨é‡ä»¥åŠç¼“å­˜å¤§å°ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Figure 12 & 13ï¼‰

#### åœ¨ **Decoding é˜¶æ®µ** çš„å¹³å‡åŠ é€Ÿæ¯”ï¼ˆvs. å„ baselineï¼‰ï¼š
| æ–¹æ³• | vs. llama.cpp | vs. KTransformers | vs. MoE-Lightning | vs. HybriMoE |
|------|----------------|--------------------|--------------------|---------------|
| **DALI** | **3.97Ã—** | **2.16Ã—** | **1.48Ã—** | **1.32Ã—** |

#### åœ¨ **Prefill é˜¶æ®µ** çš„å¹³å‡åŠ é€Ÿæ¯”ï¼š
| æ–¹æ³• | vs. llama.cpp | vs. KTransformers | vs. MoE-Lightning | vs. HybriMoE |
|------|----------------|--------------------|--------------------|---------------|
| **DALI** | **7.62Ã—** | **3.80Ã—** | **2.45Ã—** | **2.00Ã—** |

> ğŸ’¡ ç»“æœè¡¨æ˜ï¼š**DALI åœ¨ prefill é˜¶æ®µå¢ç›Šæ›´å¤§**ï¼Œè¯´æ˜å…¶åœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡æ—¶ä¼˜åŠ¿æ›´æ˜æ˜¾ã€‚

---

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ï¼ˆ1ï¼‰Greedy Assignment çš„è´¡çŒ®ï¼ˆFigure 14ï¼‰
- ç›¸æ¯”æ— è°ƒåº¦çš„ â€œNaiveâ€ æ–¹æ³•ï¼ˆå…¨éƒ¨ä¸“å®¶è·‘ CPUï¼‰ï¼Œ**Greedy Assignment å•ç‹¬å¸¦æ¥ 4.42Ã— åŠ é€Ÿ**ã€‚
- æ¯” HybriMoE çš„é™æ€åˆ†é…å¿« **23%**ï¼Œå› å…¶èƒ½æ›´å¥½å¹³è¡¡ CPU/GPU è´Ÿè½½ã€‚

#### ï¼ˆ2ï¼‰Residual-Based Prefetching çš„æ•ˆæœï¼ˆFigure 16ï¼‰
- åœ¨ Mixtral ä¸Šï¼Œç›¸æ¯”éšæœºé¢„å–æˆ– HybriMoE æ–¹æ³•ï¼Œ**DALI çš„é¢„å–å‡†ç¡®ç‡æœ€é«˜**ï¼ˆTop-1 å‡†ç¡®ç‡æå‡æ˜¾è‘—ï¼‰ã€‚
- ä½¿ç”¨è¯¥æ–¹æ³•åï¼Œ**é¢„å–å¸¦æ¥çš„å®é™…åŠ é€Ÿæ•ˆæœä»ä¸è¶³ 1.2Ã— æå‡è‡³è¶…è¿‡ 2.0Ã—**ã€‚

#### ï¼ˆ3ï¼‰Workload-Aware Cache çš„æ”¶ç›Šï¼ˆFigure 17ï¼‰
- åœ¨ç›¸åŒç¼“å­˜å®¹é‡ä¸‹ï¼Œ**DALI çš„ç¼“å­˜å‘½ä¸­ç‡æ˜¾è‘—é«˜äº LRU å’Œ HybriMoE çš„ score-based æ–¹æ³•**ã€‚
- æœ€ç»ˆå¸¦æ¥ **1.23Ã— çš„æ¨ç†é€Ÿåº¦æå‡**ï¼Œå°¤å…¶åœ¨å°ç¼“å­˜åœºæ™¯ä¸‹ä¼˜åŠ¿æ›´æ˜æ˜¾ã€‚

#### ï¼ˆ4ï¼‰æ•´ä½“æ¨¡å—å åŠ æ•ˆæœï¼ˆFigure 19ï¼‰
ä» â€œNaiveâ€ å¼€å§‹é€æ­¥æ·»åŠ ç»„ä»¶ï¼š
1. **+ Greedy Assignment â†’ ~4.1Ã— æå‡**
2. **+ Residual-Based Prefetching â†’ å† +9%**
3. **+ Workload-Aware Cache â†’ å† +38%**

> è¡¨æ˜ **åŠ¨æ€åˆ†é…æ˜¯æœ€å¤§è´¡çŒ®è€…**ï¼Œè€Œç¼“å­˜ä¼˜åŒ–æä¾›äº†æŒç»­å¢ç›Šã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **åŠ¨æ€è´Ÿè½½æ„ŸçŸ¥åˆ†é…è‡³å…³é‡è¦**ï¼šé™æ€ä¸“å®¶åˆ†é…ä¸¥é‡é™åˆ¶äº†å¼‚æ„ç³»ç»Ÿçš„æ½œåŠ›ï¼›**Greedy Assignment èƒ½æœ‰æ•ˆå®ç° CPU-GPU è´Ÿè½½å‡è¡¡**ï¼Œæ˜¯æ€§èƒ½é£è·ƒçš„å…³é”®ã€‚
2. **è·¨å±‚æ®‹å·®å¯ç”¨äºç²¾å‡†é¢„å–**ï¼šåˆ©ç”¨ `residual connection` ä¸­çš„ä¿¡æ¯æ ¡æ­£è¾“å…¥ç‰¹å¾ï¼Œå¯æ˜¾è‘—æå‡å¯¹é«˜è´Ÿè½½ä¸“å®¶çš„é¢„æµ‹å‡†ç¡®æ€§ï¼Œä½¿é¢„å–çœŸæ­£å‘æŒ¥ä½œç”¨ã€‚
3. **é«˜è´Ÿè½½ä¸“å®¶å­˜åœ¨å¼ºæ—¶é—´å±€éƒ¨æ€§**ï¼šç›¸é‚» token ä¸­æ´»è·ƒçš„é«˜è´Ÿè½½ä¸“å®¶é«˜åº¦é‡å ï¼Œè¿™ä¸€è§‚å¯Ÿæ”¯æ’‘äº†åŸºäº workload history çš„ç¼“å­˜ç­–ç•¥è®¾è®¡ã€‚
4. **ä¸‰è€…ååŒä½œç”¨æ˜¾è‘—**ï¼šè°ƒåº¦ + é¢„å– + ç¼“å­˜ä¸‰è€…ç»“åˆï¼Œå¯åœ¨æœ‰é™å¸¦å®½ä¸‹æœ€å¤§é™åº¦å‡å°‘ PCIe é€šä¿¡ï¼Œå……åˆ†å‘æŒ¥æœ¬åœ°PCçš„å¼‚æ„ç®—åŠ›ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ– warm-up profiling è·å–å»¶è¿Ÿå‚æ•°**ï¼ˆå¦‚ `tcpu(wi)`, `tgpu(wi)`ï¼‰ï¼Œè™½å¯å¤ç”¨ä½†ä»éœ€åˆå§‹æ ¡å‡†ã€‚
- å½“å‰è®¾è®¡é’ˆå¯¹å•æœºå•å¡ç¯å¢ƒï¼Œå°šæœªæ‰©å±•è‡³å¤š GPU æˆ–åˆ†å¸ƒå¼ç³»ç»Ÿã€‚
- å¯¹éå¸¸è§„æ¶æ„ï¼ˆéæ ‡å‡† Transformerï¼‰çš„æ³›åŒ–èƒ½åŠ›æœ‰å¾…éªŒè¯ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢åœ¨ **å¤š GPU å¹³å°**ï¼ˆå¦‚ 1 CPU + 2 GPUï¼‰ä¸Šçš„æ‰©å±•æ€§ï¼ˆå·²åœ¨ Appendix ä¸­åˆæ­¥éªŒè¯ï¼‰ã€‚
- è¿›ä¸€æ­¥ç ”ç©¶åœ¨ **é«˜å¸¦å®½æœåŠ¡å™¨ç³»ç»Ÿ**ï¼ˆå¦‚ GH200, NVLinkï¼‰ä¸­çš„é€‚ç”¨æ€§ã€‚
- å°† workload-aware æ€æƒ³æ¨å¹¿è‡³å…¶ä»–ç¨€ç–æ¨¡å‹ç»“æ„ï¼ˆå¦‚ Sparse Attention, Block-Skipï¼‰ã€‚

---

## æ€»ç»“
**DALI æ˜¯é¦–ä¸ªå…¨é¢å¼•å…¥â€œå·¥ä½œè´Ÿè½½æ„ŸçŸ¥â€æ€æƒ³çš„ MoE æ¨ç†æ¡†æ¶**ï¼Œé€šè¿‡ **åŠ¨æ€ä¸“å®¶åˆ†é…ã€æ®‹å·®é©±åŠ¨é¢„å–ã€å†å²è´Ÿè½½æ„ŸçŸ¥ç¼“å­˜** ä¸‰å¤§æŠ€æœ¯ï¼Œç³»ç»Ÿæ€§è§£å†³äº†æœ¬åœ°PCä¸Š MoE æ¨ç†çš„èµ„æºåˆ©ç”¨ä¸é€šä¿¡ç“¶é¢ˆé—®é¢˜ã€‚å®éªŒè¡¨æ˜å…¶åœ¨ä¸»æµ MoE æ¨¡å‹ä¸Šå®ç°äº†é«˜è¾¾ **7.62Ã— çš„ prefill åŠ é€Ÿ** å’Œ **3.97Ã— çš„ decoding åŠ é€Ÿ**ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ï¼Œä¸ºä¸ªäººè®¾å¤‡é«˜æ•ˆè¿è¡Œå¤§è§„æ¨¡ MoE æ¨¡å‹æä¾›äº†å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 2. [Scalable Generative Game Engine: Breaking the Resolution Wall via Hardware-Algorithm Co-Design](https://arxiv.org/abs/2602.00608)

**Authors**: Wei Zeng, Xuchen Li, Ruili Feng, Zhen Liu, Fengwei An, Jian Zhao  
**Category**: cs.AI  
**Published**: 2026-02-04  
**Score**: 14.0  
**Type**: new  
**ArXiv ID**: 2602.00608v1  

#### Abstract
Real-time generative game engines represent a paradigm shift in interactive simulation, promising to replace traditional graphics pipelines with neural world models. However, existing approaches are fundamentally constrained by the ``Memory Wall,'' restricting practical deployments to low resolution...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Scalable Generative Game Engine: Breaking the Resolution Wall via Hardware-Algorithm Co-Design*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿç”Ÿæˆå¼æ¸¸æˆå¼•æ“ï¼ˆGenerative Game Engineï¼‰å—é™äºâ€œ**Memory Wall**â€ï¼ˆå†…å­˜å¢™ï¼‰ï¼Œéš¾ä»¥åœ¨é«˜åˆ†è¾¨ç‡ï¼ˆå¦‚ 720Ã—480ï¼‰ä¸‹å®ç°å®æ—¶æ¨ç†ã€‚ç°æœ‰æ–¹æ³•å¦‚ GameNGen å’Œ Diamond å¤šè¿è¡Œåœ¨ä½åˆ†è¾¨ç‡ï¼ˆå¦‚ 64Ã—64 æˆ– 320Ã—240ï¼‰ï¼Œå¯¼è‡´è§†è§‰ä¿çœŸåº¦ä¸è¶³ï¼Œæ— æ³•æ»¡è¶³çœŸå®æ¸¸æˆä½“éªŒéœ€æ±‚ã€‚

æœ¬æ–‡æ—¨åœ¨çªç ´è¿™ä¸€ç“¶é¢ˆï¼Œå®ç°**é«˜åˆ†è¾¨ç‡ã€ä½å»¶è¿Ÿã€é«˜ä¿çœŸçš„å®æ—¶ç¥ç»æ¸¸æˆç”Ÿæˆ**ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹

ä½œè€…æå‡ºäº†ä¸€ç§**å¯æ‰©å±•çš„ç¡¬ä»¶-ç®—æ³•ååŒè®¾è®¡æ¡†æ¶**ï¼ˆHardware-Algorithm Co-Designï¼‰ï¼Œé€šè¿‡ç³»ç»Ÿçº§ä¼˜åŒ–è§£å†³ç”Ÿæˆæ¨¡å‹ä¸­è®¡ç®—å¯†é›†å‹ï¼ˆcompute-boundï¼‰ä¸å†…å­˜å¯†é›†å‹ï¼ˆmemory-boundï¼‰ä»»åŠ¡ä¹‹é—´çš„èµ„æºä¸åŒ¹é…é—®é¢˜ã€‚

#### ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

1. **å¼‚æ„è®¡ç®—æ¶æ„ä¸èµ„æºåˆ†é…ç­–ç•¥ï¼ˆHeterogeneous Architecture & Resource Allocationï¼‰**
   - å°† **World Model (DiT)** ä¸ **Decoder (VAE)** è§£è€¦ï¼Œåˆ†åˆ«éƒ¨ç½²åœ¨ä¸åŒçš„ AI åŠ é€Ÿå™¨ä¸Šã€‚
   - DiT æ˜¯ **compute-bound**ï¼Œé‡‡ç”¨ **Sequence Parallelism**ï¼ˆå¦‚ Ulyssesï¼‰è¿›è¡Œåˆ†å¸ƒå¼è®¡ç®—ã€‚
   - VAE æ˜¯ **memory-bound**ï¼Œé‡‡ç”¨ **Spatial Parallelism** åˆ†å‰²ç‰¹å¾å›¾å®½åº¦ç»´åº¦ï¼Œå‡å°‘é€šä¿¡å¼€é”€ã€‚
   - å»ºç«‹ç†è®ºååé‡æ¨¡å‹ï¼Œæ¨å¯¼æœ€ä¼˜è®¾å¤‡åˆ†é…æ¯”ä¾‹ï¼ˆ5:3ï¼‰ï¼Œæœ€å¤§åŒ–é›†ç¾¤æ•´ä½“æ€§èƒ½ã€‚

2. **å†…å­˜ä¸­å¿ƒåŒ–çš„ç®—å­èåˆä¼˜åŒ–ï¼ˆMemory-Centric Operator Fusionï¼‰**
   - é’ˆå¯¹ VAE è§£ç å™¨ï¼šæå‡º **Vertical Fusion**ï¼Œå°† `Upsample â†’ Conv2d â†’ GroupNorm â†’ SiLU` èåˆä¸ºå•ä¸ªæ ¸å‡½æ•°ï¼Œåˆ©ç”¨ç‰‡ä¸Š SRAM å®ç°â€œä¸€æ¬¡è¯»å–ã€ä¸€æ¬¡å†™å›â€ï¼Œé™ä½ HBM å¸¦å®½å‹åŠ›è¾¾ **75%**ã€‚
   - é’ˆå¯¹ DiT æ³¨æ„åŠ›æ¨¡å—ï¼šæå‡º **Horizontal Fusion**ï¼Œåˆå¹¶ AdaLN ä¸­çš„å°çŸ©é˜µä¹˜æ³•ï¼Œæå‡è®¡ç®—å¯†åº¦ï¼ˆarithmetic intensityï¼‰ä» <20% åˆ° >85% çš„å³°å€¼ç†è®ºåˆ©ç”¨ç‡ã€‚

3. **æµå½¢æ„ŸçŸ¥çš„æ½œåœ¨ç©ºé—´å¤–æ¨æœºåˆ¶ï¼ˆManifold-Aware Latent Extrapolationï¼‰**
   - åˆ©ç”¨å¸§é—´é«˜åº¦æ—¶é—´ç›¸å…³æ€§ï¼Œåœ¨åŠ¨ä½œç¨³å®šæ—¶è·³è¿‡éƒ¨åˆ† DiT æ¨ç†æ­¥éª¤ã€‚
   - åŸºäºæµå½¢å‡è®¾ï¼ˆManifold Hypothesisï¼‰ï¼Œä½¿ç”¨å‰å‘è¿åŠ¨å‘é‡ $ v_t = z_t - z_{t-1} $ è¿›è¡Œçº¿æ€§å¤–æ¨ï¼š  
     $$
     z_{t+\Delta t} \approx z_t + \lambda \cdot v_t
     $$
   - åœ¨çº¦ 65% çš„å¸§ä¸­è·³è¿‡ DiT è®¡ç®—ï¼Œæ˜¾è‘—é™ä½å¹³å‡è®¡ç®—è´Ÿè½½ï¼ŒåŒæ—¶ä¿æŒè§†è§‰è¿è´¯æ€§ã€‚

4. **æ¨æµ‹æ€§æ§åˆ¶ä¿¡å·é¢„å–ï¼ˆSpeculative Action Prefetchingï¼‰**
   - å¼•å…¥è½»é‡çº§ LSTM æ¨¡å‹é¢„æµ‹ç”¨æˆ·ä¸‹ä¸€æ­¥æ“ä½œã€‚
   - è‹¥é¢„æµ‹å‘½ä¸­ï¼ˆhit rate â‰ˆ 93%ï¼‰ï¼Œç›´æ¥æ˜¾ç¤ºé¢„ç”Ÿæˆå¸§ï¼Œå®ç°è¿‘ä¹é›¶æœ‰æ•ˆå»¶è¿Ÿã€‚
   - ç»“åˆä¸Šè¿°æœºåˆ¶ï¼Œå°†æ„ŸçŸ¥å»¶è¿Ÿä» 38ms é™è‡³ **2.7ms**ï¼ˆamortizedï¼‰ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ GameNGen, Diamondï¼‰ | æœ¬å·¥ä½œ |
|------|-------------------------------|--------|
| åˆ†è¾¨ç‡ | â‰¤320Ã—240 | âœ… æ”¯æŒ **720Ã—480**ï¼ˆåƒç´ ååæå‡ 50Ã—ï¼‰ |
| æ¶æ„è®¾è®¡ | å•ä¸€è®¾å¤‡æˆ–åŒæ„å¹¶è¡Œ | âœ… å¼‚æ„å¹¶è¡Œ + æ˜¾å¼å†…å­˜ç®¡ç† |
| å†…å­˜æ•ˆç‡ | ç¼“å­˜éšå¼ç®¡ç†ï¼Œé¢‘ç¹ HBM è®¿é—® | âœ… ç®—å­èåˆ + ç‰‡ä¸Š SRAM åˆ©ç”¨ï¼Œå‡å°‘ 75% HBM ä¼ è¾“ |
| å»¶è¿Ÿæ§åˆ¶ | å›ºå®šæ¨ç†æµç¨‹ | âœ… å¤–æ¨ + æ¨æµ‹æ‰§è¡Œï¼Œæ„ŸçŸ¥å»¶è¿Ÿä»… **2.7ms** |
| å¯æ‰©å±•æ€§ | ä¾èµ–ä¸“ç”¨ç¡¬ä»¶ï¼ˆTPUï¼‰ | âœ… å¯è¿ç§»è‡³é€šç”¨ AI åŠ é€Ÿå™¨é›†ç¾¤ï¼ˆå¦‚ H100 + NVLinkï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ§ª æ•°æ®é›†ä¸æµ‹è¯•ç¯å¢ƒ

ä½¿ç”¨ä¸¤ä¸ªä»£è¡¨æ€§åŸºå‡†è¿›è¡ŒéªŒè¯ï¼Œè¦†ç›–è¿ç»­ä¸ç¦»æ•£åŠ¨ä½œç©ºé—´ï¼š

1. **Matrix (Continuous Domain)**  
   - ç±»å‹ï¼šé«˜ä¿çœŸ 3D èµ›è½¦æ¨¡æ‹Ÿå™¨ï¼ˆ720Ã—480ï¼‰
   - ç‰¹ç‚¹ï¼šå¼ºè°ƒè¿ç»­åŠ¨åŠ›å­¦ã€æ‘©æ“¦ã€åŠ¨é‡ç­‰ç‰©ç†ä¸€è‡´æ€§
   - æ¥æºï¼š[9] *The Matrix: Infinite-horizon world generation with real-time moving control*

2. **PGG (Playable Game Generation, Discrete Domain)**  
   - ç±»å‹ï¼š2D å¹³å°è·³è·ƒæ¸¸æˆï¼ˆ256Ã—256ï¼‰
   - ç‰¹ç‚¹ï¼šå¼ºè°ƒå¸ƒå°”é€»è¾‘ã€ç¢°æ’æ£€æµ‹ã€çŠ¶æ€è·ƒè¿
   - æ¥æºï¼š[10] *Playable Game Generation*

---

### âš™ï¸ å®éªŒè®¾ç½®

- **ç¡¬ä»¶å¹³å°**ï¼š8 å¡ Huawei Ascend 910C AI åŠ é€Ÿå™¨é›†ç¾¤
  - æ¯å¡ 64GB HBMï¼ŒFP16 ç®—åŠ› ~752 TFLOPS
  - äº’è”å¸¦å®½ï¼šHCCS ç¯å½¢æ‹“æ‰‘ï¼Œ30 GB/s
- **è½¯ä»¶æ ˆ**ï¼šCANN 8.0, PyTorch 2.5.1, xfuserï¼ˆæ”¯æŒ Ulysses å¹¶è¡Œï¼‰
- **èµ„æºé…ç½®**ï¼š5 å¼ ç”¨äº DiTï¼ˆWorld Modelï¼‰ï¼Œ3 å¼ ç”¨äº VAEï¼ˆDecoderï¼‰

---

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ç±»åˆ« | å…·ä½“æŒ‡æ ‡ | æè¿° |
|--------|---------|------|
| **æ€§èƒ½** | FPS, Motion-to-Photon Latency (M2P) | è¡¡é‡ç”Ÿæˆé€Ÿåº¦ä¸å“åº”å»¶è¿Ÿ |
| **è§†è§‰è´¨é‡** | FID, PSNR, SSIM, LPIPS | è¡¡é‡ç”Ÿæˆç”»é¢ä¸çœŸå®è§†é¢‘åˆ†å¸ƒçš„è·ç¦»åŠæ„ŸçŸ¥ç›¸ä¼¼æ€§ |
| **ç‰©ç†ä¸€è‡´æ€§** | Control Sensitivity Analysis (CSA) | è¿ç»­åŸŸä¸­è¾“å…¥-è¾“å‡ºåŠ¨æ€å…³ç³»æ˜¯å¦ç¬¦åˆç‰©ç†è§„å¾‹ |
| **é€»è¾‘ä¸€è‡´æ€§** | Discrete Logic Boundary (DLB) Score | ç¦»æ•£åŸŸä¸­æ˜¯å¦å­˜åœ¨éæ³•çŠ¶æ€è½¬ç§»ï¼ˆå¦‚ç©¿å¢™ï¼‰ |

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”

| åŸºçº¿ | ç¡¬ä»¶ | åˆ†è¾¨ç‡ | FPS | å¤‡æ³¨ |
|------|------|--------|-----|------|
| **Diamond [6]** | RTX 3090 | 64Ã—64 | 10.0 | æ‰©å±•æ€§å·®ï¼Œåˆ†è¾¨ç‡æä½ |
| **GameNGen [4]** | TPU v5 | 320Ã—240 | >20 | ä¸“æœ‰ç¡¬ä»¶ï¼Œæœªå…¬å¼€ç»†èŠ‚ |
| **PGG Baseline** | RTX 5090 | 256Ã—256 | 29.9 | å¼€æºæ¨¡å‹ï¼Œä½œä¸ºç¦»æ•£åŸŸå¯¹ç…§ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

| æŒ‡æ ‡ | Matrix (3D Racing) | PGG (2D Platformer) |
|------|---------------------|-----------------------|
| **åˆ†è¾¨ç‡** | 720Ã—480 | 256Ã—256 |
| **FPS** | **26.4** | **48.3** |
| **æ„ŸçŸ¥å»¶è¿Ÿï¼ˆamortized M2Pï¼‰** | **2.7 ms** | **2.7 ms** |
| **FID** | 42.3 | 28.5 |
| **LPIPS** | 0.087 | 0.052 |
| **DLB Score (é€»è¾‘ä¸€è‡´æ€§)** | â€” | **100.0%**ï¼ˆæ— è¿è§„ï¼‰ |

> âœ… å®ç°äº† **720p å®æ—¶ç”Ÿæˆ**ï¼Œç›¸æ¯” Diamondï¼ˆ64Ã—64ï¼‰åƒç´ ååæå‡ **50Ã—**

---

### ğŸ” ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ

| æ–¹æ³• | FPS (Matrix) | FID â†“ | LPIPS â†“ | ä¼˜åŠ¿è¯´æ˜ |
|------|--------------|--------|----------|-----------|
| Diamond [6] | 10.0 (@64Ã—64) | 89.5 | 0.198 | åˆ†è¾¨ç‡æä½ï¼Œä¸å¯æ¯” |
| GameNGen [4] | >20 (@320Ã—240) | 58.2 | 0.142 | ä»ä½äºæœ¬å·¥ä½œä¿çœŸåº¦ |
| **Ours (Matrix)** | **26.4 (@720Ã—480)** | **42.3** | **0.087** | âœ… æ›´é«˜åˆ†è¾¨ç‡ + æ›´ä¼˜è´¨é‡ |

- åœ¨ç›¸åŒç®—åŠ›çº§åˆ«ä¸‹ï¼Œå•å¡æ•ˆç‡è™½ç•¥ä½ï¼ˆdue to communication overheadï¼‰ï¼Œä½†**é›†ç¾¤é…ç½®è§£é”äº†é«˜åˆ†è¾¨ç‡å¯è¡Œæ€§**ã€‚
- å½’ä¸€åŒ–æ•ˆç‡ï¼ˆNorm. Eff. = FPS / 100 TFLOPSï¼‰ä¸º 0.44ï¼Œè™½ä½äºæ¶ˆè´¹çº§ GPUï¼ˆ~7.0ï¼‰ï¼Œä½†è¿™æ˜¯ä¸ºçªç ´â€œMemory Capacity Wallâ€æ‰€ä»˜å‡ºçš„å¿…è¦ä»£ä»·ã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

| é˜¶æ®µ | FPS | Speedup | è¯´æ˜ |
|------|-----|---------|------|
| Baseline (Single Card) | 2.1 | 1.0x | å®Œå…¨ä¸å¯ç”¨ |
| + Operator Fusion | 4.5 | 2.1x | å†…å­˜ä¼˜åŒ–åˆè§æˆæ•ˆ |
| + Ulysses (3:5) | 16.6 | 7.9x | å¼‚æ„å¹¶è¡Œå¸¦æ¥é£è·ƒ |
| + Optimal 5:3 Ratio | 19.4 | 9.2x | ç†è®ºå»ºæ¨¡æŒ‡å¯¼è°ƒä¼˜ |
| + Latent Extrapolation | 26.4 | 12.6x | ç®—æ³•çº§åŠ é€Ÿè¾¾æˆå®æ—¶ |
| + Speculative Execution | 26.4 (FPS), **2.7ms (latency)** | â€” | æ„ŸçŸ¥å»¶è¿Ÿå¤§å¹…ä¸‹é™ |

> ğŸ’¡ æ€»è®¡å®ç° **12.6Ã— çš„ç³»ç»Ÿçº§æ€§èƒ½æå‡**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **â€œMemory Wallâ€æ˜¯é«˜åˆ†è¾¨ç‡ç”Ÿæˆçš„æ ¸å¿ƒç“¶é¢ˆ**ï¼Œå•çº¯ç®—æ³•ä¼˜åŒ–æ— æ³•çªç ´ï¼Œå¿…é¡»ä¾èµ– **Hardware-Algorithm Co-Design**ã€‚
2. **å¼‚æ„æ¶æ„è§£è€¦ DiT ä¸ VAE** æ˜¯å…³é”®è·¯å¾„ï¼Œèƒ½æœ‰æ•ˆå¹³è¡¡è®¡ç®—ä¸å†…å­˜è´Ÿè½½ã€‚
3. **ç‰‡ä¸Š SRAM + ç®—å­èåˆ** å¯æ˜¾è‘—å‡å°‘ HBM è®¿é—®ï¼Œæå‡å†…å­˜æ•ˆç‡ã€‚
4. **æ—¶é—´å†—ä½™å¯è¢«é«˜æ•ˆåˆ©ç”¨**ï¼šé€šè¿‡æµå½¢å¤–æ¨ä¸æ¨æµ‹æ‰§è¡Œï¼Œå¯åœ¨ä¸ç‰ºç‰²ä¸€è‡´æ€§çš„å‰æä¸‹å¤§å¹…é™ä½æ„ŸçŸ¥å»¶è¿Ÿã€‚
5. è¯¥æ¡†æ¶å®ç°äº† **720Ã—480 ä¸‹ 26.4 FPS** çš„å®æ—¶ç”Ÿæˆèƒ½åŠ›ï¼Œå¹¶ä¿æŒ **100% é€»è¾‘ä¸€è‡´æ€§**ï¼ˆin-distributionï¼‰ã€‚

---

### âš ï¸ å±€é™æ€§

1. **ä¾èµ–å¤§è§„æ¨¡åŠ é€Ÿå™¨é›†ç¾¤**ï¼šå½“å‰æ–¹æ¡ˆé€‚ç”¨äºäº‘æ¸¸æˆåœºæ™¯ï¼Œå°šéš¾éƒ¨ç½²äºè¾¹ç¼˜è®¾å¤‡ï¼ˆedgeï¼‰ã€‚
2. **Out-of-Distribution (OOD) åŠ¨ä½œé²æ£’æ€§ä¸è¶³**ï¼šé¢å¯¹è®­ç»ƒåˆ†å¸ƒå¤–çš„æ“ä½œå¯èƒ½å‡ºç°â€œå¹»è§‰â€è¡Œä¸ºï¼ˆå¦‚ç©¿å¢™ï¼‰ã€‚
3. **èµ„æºåˆ†é…ä¾èµ–æ¨¡å‹å‚æ•°**ï¼šæœ€ä¼˜ 5:3 åˆ†é…åŸºäºç‰¹å®šæ³¨æ„åŠ›å¤´æ•°ï¼ˆH=30ï¼‰ï¼Œæ¢æ¨¡å‹éœ€é‡æ–°è°ƒå‚ã€‚
4. **æœªå®Œå…¨è§£å†³é•¿æœŸä¸€è‡´æ€§é—®é¢˜**ï¼šå°½ç®¡çŸ­æœŸè¿è´¯ï¼Œä½†è¶…é•¿æ—¶é—´è¿è¡Œå¯èƒ½ç´¯ç§¯è¯¯å·®ã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **Hybrid Neuro-Symbolic Engines**  
   - å¼•å…¥è½»é‡çº§ç¬¦å·é€»è¾‘å±‚ï¼ˆSymbolic Logic Layerï¼‰ä½œä¸ºâ€œè§„åˆ™ç›‘ç£å™¨â€ï¼Œå¼ºåˆ¶éµå®ˆå…³é”®æ¸¸æˆè§„åˆ™ï¼Œå¢å¼º OOD é²æ£’æ€§ã€‚

2. **Multi-modal Control Interfaces**  
   - åˆ©ç”¨ Transformer çš„è·¨æ¨¡æ€èƒ½åŠ›ï¼Œæ”¯æŒè‡ªç„¶è¯­è¨€ã€è¯­éŸ³ç­‰æ–°å‹äº¤äº’æ–¹å¼ã€‚

3. **On-Device Quantization & Compression**  
   - æ¢ç´¢ 4-bit æƒé‡é‡åŒ– + æ¿€æ´»å¹³æ»‘æŠ€æœ¯ï¼Œæ¨åŠ¨æœ¬åœ°åŒ–éƒ¨ç½²ï¼Œé™ä½å¯¹äº‘ç«¯ä¾èµ–ã€‚

4. **Cross-Platform Compiler Backend**  
   - å°†ä¼˜åŒ–ç­–ç•¥å°è£…è‡³é€šç”¨ç¼–è¯‘å™¨ï¼ˆå¦‚ OpenAI Tritonï¼‰ï¼Œé€‚é… NVIDIA H100ã€TPU ç­‰å¤šå¹³å°ï¼Œä¿ƒè¿›ç”Ÿæ€æ™®åŠã€‚

---

## âœ… æ€»ç»“

æœ¬æ–‡é¦–æ¬¡è¯æ˜äº†ï¼š**é€šè¿‡ç¡¬ä»¶-ç®—æ³•ååŒè®¾è®¡ï¼Œå¯ä»¥åœ¨å•†ç”¨ AI åŠ é€Ÿå™¨é›†ç¾¤ä¸Šå®ç°é«˜åˆ†è¾¨ç‡ã€ä½å»¶è¿Ÿã€é«˜ä¿çœŸçš„å®æ—¶ç¥ç»æ¸¸æˆç”Ÿæˆ**ã€‚å…¶æ ¸å¿ƒæ€æƒ³â€”â€”**è§£è€¦è®¡ç®—ä¸å†…å­˜ç“¶é¢ˆã€æ˜¾å¼ç®¡ç†å†…å­˜å±‚çº§ã€åˆ©ç”¨æ—¶é—´å†—ä½™éšè—å»¶è¿Ÿ**â€”â€”ä¸ºä¸‹ä¸€ä»£ç”Ÿæˆå¼äº¤äº’ç³»ç»Ÿæä¾›äº†å¯å¤ç”¨çš„æŠ€æœ¯èŒƒå¼ã€‚

> â€œæˆ‘ä»¬ç›¸ä¿¡ï¼Œè¿™æ ‡å¿—ç€ä¸€ä¸ªæ–°æ—¶ä»£çš„åˆ°æ¥ï¼šä¸–ç•Œä¸å†æ˜¯æ„å»ºå‡ºæ¥çš„ï¼Œè€Œæ˜¯è¢«â€˜æ¢¦è§â€™çš„ã€‚â€

</details>

---

### 3. [Understanding and Exploiting Weight Update Sparsity for Communication-Efficient Distributed RL](https://arxiv.org/abs/2602.03839)

**Authors**: Erfan Miahi, Eugene Belilovsky  
**Category**: cs.LG  
**Published**: 2026-02-04  
**Score**: 13.0  
**Type**: new  
**ArXiv ID**: 2602.03839v1  

#### Abstract
Reinforcement learning (RL) is a critical component for post-training large language models (LLMs). However, in bandwidth-constrained distributed RL, scalability is often bottlenecked by the synchronization of policy weights from trainers to inference workers, particularly over commodity networks or...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# ã€ŠUnderstanding and Exploiting Weight Update Sparsity for Communication-Efficient Distributed RLã€‹è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
åœ¨å¸¦å®½å—é™çš„**åˆ†å¸ƒå¼å¼ºåŒ–å­¦ä¹ ï¼ˆDistributed RLï¼‰**ç³»ç»Ÿä¸­ï¼Œè®­ç»ƒèŠ‚ç‚¹ä¸æ¨ç†èŠ‚ç‚¹ä¹‹é—´çš„**æ¨¡å‹æƒé‡åŒæ­¥**æˆä¸ºé€šä¿¡ç“¶é¢ˆã€‚å¯¹äºä¸€ä¸ª7Bå‚æ•°çš„æ¨¡å‹ï¼Œåœ¨16-bitç²¾åº¦ä¸‹æ¯æ¬¡åŒæ­¥éœ€ä¼ è¾“14GBæ•°æ®ï¼Œå¯¼è‡´å¯¹é«˜å¸¦å®½ç½‘ç»œï¼ˆå¦‚20 Gbit/sï¼‰çš„å¼ºä¾èµ–ï¼Œä¸¥é‡é™åˆ¶äº†å»ä¸­å¿ƒåŒ–æˆ–åœ°ç†åˆ†å¸ƒåœºæ™¯ä¸‹çš„å¯æ‰©å±•æ€§ã€‚

ä¼ ç»Ÿæ–¹æ³•å¦‚**æ¢¯åº¦å‹ç¼©ï¼ˆgradient compressionï¼‰**å¤šä¸ºæœ‰æŸå‹ç¼©ï¼Œä¸”é€‚ç”¨äºæ¢¯åº¦èšåˆè€Œéæƒé‡å¹¿æ’­ï¼›è€Œç†µç¼–ç ç­‰æ— æŸæ–¹æ³•å¢ç›Šæœ‰é™ã€‚å› æ­¤ï¼Œå¦‚ä½•å®ç°é«˜æ•ˆã€å¯é çš„**æ— æŸæƒé‡åŒæ­¥**æ˜¯å…³é”®æŒ‘æˆ˜ã€‚

---

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡º **PULSE (Patch Updates via Lossless Sparse Encoding)** â€”â€” ä¸€ç§åŸºäº**æƒé‡æ›´æ–°ç¨€ç–æ€§**çš„æ— æŸåŒæ­¥æ–¹æ³•ã€‚

#### æ ¸å¿ƒæ€æƒ³ï¼š
- å‘ç°å¹¶ç³»ç»ŸéªŒè¯ï¼š**RLå¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œæ¯æ­¥ä»…æœ‰çº¦1%çš„å‚æ•°å‘ç”Ÿå®é™…å˜åŒ–**ï¼ˆsparsity > 99%ï¼‰ï¼Œå…¶ä½™å‚æ•°åœ¨BF16ç²¾åº¦ä¸‹å› æ›´æ–°é‡å¤ªå°è¢«â€œå¸æ”¶â€ã€‚
- åˆ©ç”¨è¯¥ç¨€ç–ç»“æ„ï¼ŒPULSEä»…ä¼ è¾“**å‘ç”Ÿå˜åŒ–çš„å‚æ•°ç´¢å¼•åŠå…¶æ–°å€¼**ï¼ˆè€Œéå¢é‡Î”ï¼‰ï¼Œå®ç°é«˜æ•ˆå‹ç¼©ã€‚

#### å…³é”®åˆ›æ–°ï¼š
1. **æœºåˆ¶æ€§è§£é‡Šç¨€ç–æ€§æ¥æº**ï¼š  
   é¦–æ¬¡æ˜ç¡®æŒ‡å‡ºç¨€ç–æ€§æºäº **BF16ç²¾åº¦é™åˆ¶** ä¸ **RLä¿å®ˆå­¦ä¹ ç‡**ï¼ˆ~3Ã—10â»â¶ï¼‰çš„ç›¸äº’ä½œç”¨â€”â€”å³ä½¿æ¢¯åº¦å¯†é›†ï¼ˆ~99%éé›¶ï¼‰ï¼Œæ›´æ–°å¹…åº¦ä»ä½äºBF16è¡¨ç¤ºé˜ˆå€¼ï¼Œå¯¼è‡´ç»å¤§å¤šæ•°å‚æ•°ä¸å˜ã€‚

2. **æ— æŸä¸”æŠ—æ¼‚ç§»çš„è®¾è®¡**ï¼š  
   å­˜å‚¨**å®é™…æƒé‡å€¼**è€Œéå¢é‡ï¼ˆadditive deltaï¼‰ï¼Œé¿å…äº†æµ®ç‚¹ç´¯åŠ è¿‡ç¨‹ä¸­çš„**é‡åŒ–è¯¯å·®ç´¯ç§¯**ï¼ˆfloating-point driftï¼‰ï¼Œä¿è¯ä»»æ„é•¿åº¦çš„è¡¥ä¸é“¾ä¹Ÿèƒ½å®ç°**bit-identicalé‡å»º**ã€‚

3. **å®ç”¨åŒ–ç³»ç»Ÿè®¾è®¡**ï¼š  
   å¼•å…¥**é”šç‚¹æ£€æŸ¥ç‚¹ï¼ˆanchor checkpointï¼‰+ è¡¥ä¸é“¾**ç»“æ„ï¼Œæ”¯æŒå†·å¯åŠ¨æ¢å¤ä¸å¼‚æ­¥æ“ä½œï¼Œå¹¶ç»“åˆSHA256å“ˆå¸Œè¿›è¡Œå®Œæ•´æ€§æ ¡éªŒã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç‰¹æ€§ | PULSE | Gradient Compression | Entropy Coding |
|------|-------|------------------------|----------------|
| æ˜¯å¦æ— æŸ | âœ… æ˜¯ | âŒ å¦ï¼ˆé€šå¸¸æœ‰æŸï¼‰ | âœ… æ˜¯ |
| å‹ç¼©æ¯” | **>100Ã—** | ~2â€“10Ã— | ~1.5â€“2Ã— |
| æŠ—ä¼ è¾“é”™è¯¯ | âœ… å¼ºï¼ˆç«¯åˆ°ç«¯å“ˆå¸ŒéªŒè¯ï¼‰ | âš ï¸ ä¾èµ–error feedback | âš ï¸ è„†å¼± |
| å¤šè·³é‡å»ºç¨³å®šæ€§ | âœ… ä¸ç§¯ç´¯è¯¯å·® | âŒ æ˜“æ¼‚ç§» | âœ… |
| é€‚ç”¨åœºæ™¯ | æƒé‡å¹¿æ’­ | æ¢¯åº¦èšåˆ | å…¨é‡æƒé‡ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šPULSEå®ç°äº†**é€šä¿¡æ•ˆç‡ã€å¯é æ€§ä¸å…¼å®¹æ€§**çš„ç»Ÿä¸€ï¼Œç‰¹åˆ«é€‚åˆå»ä¸­å¿ƒåŒ–ã€ä½å¸¦å®½ç¯å¢ƒä¸‹çš„å¤§è§„æ¨¡RLè®­ç»ƒã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **æ•°å­¦æ¨ç†ä»»åŠ¡**ï¼š`MATH` æ•°æ®é›†ï¼ˆ7,500è®­ç»ƒæ ·æœ¬ï¼Œ500éªŒè¯ï¼‰
- **ä»£ç ç”Ÿæˆä»»åŠ¡**ï¼š`MBPP` æ•°æ®é›†ï¼ˆ774è®­ç»ƒä»»åŠ¡ï¼Œ190éªŒè¯ï¼‰

å‡é‡‡ç”¨**å¯éªŒè¯å¥–åŠ±ï¼ˆVerifiable Rewards, RLVRï¼‰**ï¼Œæ— éœ€äººå·¥æ ‡æ³¨æˆ–å¥–åŠ±æ¨¡å‹ã€‚

---

### å®éªŒè®¾ç½®

#### æ¨¡å‹æ¶æ„
- **Qwen2.5-Instruct**ï¼š0.5B, 1.5B, 7B
- **Llama-3.2-Instruct**ï¼š3B
- **Gemma-3-4B-it**ï¼š4B

#### ç®—æ³•ä¸è¶…å‚
- **ç®—æ³•**ï¼šGroup Relative Policy Optimization (**GRPO**)ï¼Œç±»PPOä½†æ— KLæƒ©ç½šé¡¹
- **å­¦ä¹ ç‡**ï¼šä¸»å®éªŒä½¿ç”¨ `3Ã—10â»â¶`ï¼Œå»ä¸­å¿ƒåŒ–éƒ¨ç½²ä¸­é™è‡³ `1Ã—10â»â¶`
- **ä¼˜åŒ–å™¨**ï¼šAdamWï¼ˆÎ²â‚=0.9, Î²â‚‚=0.99ï¼‰
- **ç²¾åº¦**ï¼šBF16ï¼ˆæ··åˆç²¾åº¦è®­ç»ƒï¼ŒFP32 master weightsï¼‰
- **æ‰¹é‡å¤§å°**ï¼š32 prompts Ã— 16 rollouts

#### åˆ†å¸ƒå¼æ¶æ„
- **grailæ¡†æ¶**ï¼šåŸºäºBittensoræ„å»ºçš„å»ä¸­å¿ƒåŒ–RLå¹³å°
- **èŠ‚ç‚¹è§’è‰²**ï¼š
  - **Miners**ï¼šç”Ÿæˆrollout
  - **Validators**ï¼šé€šè¿‡hidden-state fingerprintingéªŒè¯çœŸå®æ€§
  - **Trainer**ï¼šæ‰§è¡Œæ¢¯åº¦æ›´æ–°å¹¶å‘å¸ƒPULSEè¡¥ä¸

#### é€šä¿¡æ¨¡æ‹Ÿ
- åœ¨çœŸå®å…¬ç½‘ç¯å¢ƒä¸­æµ‹è¯•ï¼Œå¹³å‡å¸¦å®½çº¦ **400 Mb/s**
- ä½¿ç”¨S3å…¼å®¹å¯¹è±¡å­˜å‚¨ï¼ˆCloudflare R2ï¼‰åˆ†å‘è¡¥ä¸

---

### è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Weight Update Sparsity** | è¿ç»­ä¸¤æ­¥é—´**bitwiseç›¸åŒå‚æ•°çš„æ¯”ä¾‹** |
| **Upload Size** | å•æ¬¡åŒæ­¥ä¸Šä¼ ä½“ç§¯ï¼ˆMBï¼‰ |
| **Bandwidth Reduction** | ç›¸æ¯”å…¨é‡åŒæ­¥çš„å‹ç¼©å€æ•° |
| **Validation pass@1** | éªŒè¯é›†ä¸Šé¦–æ¬¡ç”Ÿæˆå³æ­£ç¡®çš„æ¯”ä¾‹ |
| **SHA256 Verification** | é‡å»ºåæƒé‡æ˜¯å¦bit-identical |
| **End-to-End Latency** | å¿«è·¯å¾„/æ…¢è·¯å¾„åŒæ­¥å»¶è¿Ÿ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Full Weight Synchronization**ï¼ˆ14GB/æ¬¡ï¼‰ä½œä¸ºåŸºå‡†
- æœªç›´æ¥æ¯”è¾ƒå…¶ä»–å‹ç¼©æ–¹æ³•ï¼Œè€Œæ˜¯ä»ç†è®ºå±‚é¢è®ºè¯å…¶ä¸å¯è¡Œæ€§ï¼š
  - æ¢¯åº¦å‹ç¼©ä¸é€‚ç”¨äºå¹¿æ’­åœºæ™¯
  - å·²æœ‰ç¨€ç–æ€§ç ”ç©¶ï¼ˆå¦‚Mukherjee et al. [21]ï¼‰ä»…åŸºäºç²—ç²’åº¦å·®å¼‚ï¼Œç¼ºä¹é€æ­¥åˆ†æ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **å¹³å‡æ›´æ–°ç¨€ç–åº¦** | **~99%**ï¼ˆæ‰€æœ‰æ¨¡å‹ & è®­ç»ƒé˜¶æ®µï¼‰ |
| **æœ€å°ç¨€ç–åº¦ï¼ˆæœ€å·®æ­¥ï¼‰** | >98%ï¼ˆk=1ï¼‰ |
| **k=8æ—¶å¤šæ­¥ç¨€ç–åº¦** | >98%ï¼ˆç¬¦åˆå¼‚æ­¥RLæ¨èèŒƒå›´ï¼‰ |
| **å•æ¬¡ä¸Šä¼ å¤§å°ï¼ˆ7Bæ¨¡å‹ï¼‰** | **108 MB**ï¼ˆSE: 1.1MBï¼‰ |
| **é€šä¿¡å‹ç¼©æ¯”** | **>100Ã—**ï¼ˆ14GB â†’ ~108MBï¼‰ |
| **å¸¦å®½éœ€æ±‚ï¼ˆ90% GPUåˆ©ç”¨ç‡ï¼‰** | **0.2 Gbit/s**ï¼ˆåŸéœ€20 Gbit/sï¼‰ |
| **é‡å»ºæˆåŠŸç‡** | **100% SHA256éªŒè¯é€šè¿‡** |

> ğŸ“ˆ å›¾1æ˜¾ç¤ºï¼šåœ¨50ç§’/æ­¥è®¡ç®—ä¸‹ï¼Œä¼ ç»ŸåŒæ­¥éœ€20 Gbit/sæ‰èƒ½ç»´æŒ90% GPUåˆ©ç”¨ç‡ï¼›PULSEä»…éœ€0.2 Gbit/så³å¯è¾¾åˆ°åŒç­‰æ•ˆç‡ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

| æ–¹æ³• | é€šä¿¡å¼€é”€ | æ˜¯å¦æ— æŸ | å®é™…æ”¶ç›Š |
|------|----------|----------|---------|
| Full Sync | 14 GB | âœ… | åŸºå‡† |
| PULSE | **~108 MB** | âœ… | **>100Ã— å‡å°‘** |
| Gradient Compression | ~1â€“7 GBï¼ˆä¼°ç®—ï¼‰ | âŒ | ä¸é€‚ç”¨ï¼Œä¸”ç ´åè®­ç»ƒåŠ¨æ€ |

> ğŸ’¡ å®éªŒè¡¨æ˜ï¼ŒPULSEåœ¨ä¿æŒå®Œå…¨ä¸€è‡´è®­ç»ƒåŠ¨æ€çš„å‰æä¸‹ï¼Œå°†é€šä¿¡æˆæœ¬é™ä½ä¸¤ä¸ªæ•°é‡çº§ã€‚

---

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰å‹ç¼©ç»„ä»¶è´¡çŒ®åˆ†æï¼ˆTable 5ï¼‰
| ç»„ä»¶ | å‹ç¼©å¢ç›Šï¼ˆç›¸å¯¹COOï¼‰ | ç¼–ç é€Ÿåº¦æå‡ |
|------|--------------------|-------------|
| Delta Encoding | +13.3% | â‰ˆ |
| Type Downscalingï¼ˆuint8/uint16ï¼‰ | +8.5% | â†‘ encode throughput |
| **åˆè®¡** | **+22.9%** | **â†‘ 35%** |

#### ï¼ˆ2ï¼‰ä¸åŒå‹ç¼©ç®—æ³•é€‰æ‹©ï¼ˆTable 7ï¼‰
| ç®—æ³• | å‹ç¼©æ¯” | ç¼–ç é€Ÿåº¦ï¼ˆMB/sï¼‰ | æœ€ä½³é€‚ç”¨åœºæ™¯ |
|------|--------|------------------|--------------|
| lz4 | 56Ã— | 830 | é«˜å¸¦å®½ï¼ˆ>800 Mbit/sï¼‰ |
| **zstd-1** | **79Ã—** | **534** | **é»˜è®¤ï¼ˆ15â€“800 Mbit/sï¼‰** |
| zstd-3 | 80Ã— | 197 | ä½å¸¦å®½ï¼ˆ<14 Mbit/sï¼‰ |

> âœ… **zstd-1ä¸ºé»˜è®¤é…ç½®**ï¼šåœ¨å…¸å‹äº‘ç½‘ç»œä¸­æä¾›æœ€ä½³ç«¯åˆ°ç«¯å»¶è¿Ÿã€‚

#### ï¼ˆ3ï¼‰è·¨æ¨¡å‹å‹ç¼©æ•ˆæœï¼ˆTable 8ï¼‰
| æ¨¡å‹å®¶æ— | ç¨€ç–åº¦ | å‹ç¼©æ¯”ï¼ˆzstd-1ï¼‰ |
|---------|--------|----------------|
| Qwen2.5 | 99.0% | 76Ã— |
| Llama-3.2 | 99.3% | **100Ã—** |
| Gemma-3 | 99.2% | 80Ã— |

> è¡¨æ˜PULSEå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. âœ… **RLå¾®è°ƒå­˜åœ¨æé«˜æƒé‡æ›´æ–°ç¨€ç–æ€§**ï¼ˆ~99%ï¼‰ï¼Œä¸”åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­ç¨³å®šå­˜åœ¨ï¼Œä¸å—æ¨¡å‹è§„æ¨¡ã€æ¶æ„æˆ–off-policyå»¶è¿Ÿå½±å“ã€‚
2. ğŸ” **ç¨€ç–æ€§æ ¹æºåœ¨äºBF16 + å°å­¦ä¹ ç‡**ï¼šå¹¶éæ¢¯åº¦ç¨€ç–ï¼Œè€Œæ˜¯æ›´æ–°è¢«æ•°å€¼ç²¾åº¦â€œå¸æ”¶â€ã€‚è¿™æ˜¯ç°ä»£LLMè®­ç»ƒé…ç½®ä¸‹çš„**å›ºæœ‰ç°è±¡**ã€‚
3. ğŸ› ï¸ **PULSEå¯å®‰å…¨åˆ©ç”¨æ­¤ç»“æ„**ï¼šé€šè¿‡ä¼ è¾“å˜æ›´å€¼è€Œéå¢é‡ï¼Œå®ç°**æ— æŸã€æŠ—æ¼‚ç§»ã€é«˜é²æ£’æ€§**çš„åŒæ­¥ã€‚
4. ğŸŒ **çœŸå®å»ä¸­å¿ƒåŒ–ç½‘ç»œéªŒè¯æˆåŠŸ**ï¼šåœ¨å…¬ç½‘ç¯å¢ƒä¸‹å®ç°>100Ã—é€šä¿¡å‰Šå‡ï¼Œè®­ç»ƒåŠ¨æ€ä¸æ€§èƒ½å®Œå…¨ä¸€è‡´ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§

| å±€é™ | è¯´æ˜ |
|------|------|
| **ä¾èµ–Adamç±»ä¼˜åŒ–å™¨** | åˆ†æåŸºäºAdamæ›´æ–°æœºåˆ¶ï¼ŒSGDå¯èƒ½ä¸å…·å¤‡ç›¸åŒç¨€ç–æ€§ï¼ˆè§A.6ï¼‰ |
| **å‡è®¾BF16ä¸ºä¸»æµ** | è‹¥è½¬å‘FP8æˆ–æ›´é«˜ç²¾åº¦ï¼Œç¨€ç–æ€§å¯èƒ½ä¸‹é™ |
| **ä»…éªŒè¯å•è½®å¯¹è¯ä»»åŠ¡** | å¤šè½®äº¤äº’ã€é•¿ç¨‹åé¦ˆåœºæ™¯å°šæœªæµ‹è¯• |
| **é”šç‚¹é—´éš”å½±å“å†·å¯åŠ¨å»¶è¿Ÿ** | æ–°èŠ‚ç‚¹éœ€ä¸‹è½½å®Œæ•´é”šç‚¹ï¼ˆ14GBï¼‰ï¼Œä¸é€‚åˆé¢‘ç¹åŠ å…¥åœºæ™¯ |

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•è‡³å…¶ä»–ç®—æ³•**ï¼šéªŒè¯PPOã€DPOç­‰RLHFä¸»æµç®—æ³•æ˜¯å¦å…·å¤‡ç±»ä¼¼ç¨€ç–æ€§ã€‚
2. **æ”¯æŒæ›´å¤æ‚è®­ç»ƒèŒƒå¼**ï¼šæ¢ç´¢åœ¨long-horizon RLã€multi-agent settingä¸­çš„åº”ç”¨ã€‚
3. **åŠ¨æ€è‡ªé€‚åº”å‹ç¼©**ï¼šæ ¹æ®å®æ—¶ç¨€ç–æ€§è‡ªåŠ¨åˆ‡æ¢å‹ç¼©ç­–ç•¥ã€‚
4. **è¿›ä¸€æ­¥é™ä½å†·å¯åŠ¨æˆæœ¬**ï¼šå¼•å…¥åˆ†å±‚é”šç‚¹æˆ–å¢é‡é”šç‚¹æœºåˆ¶ã€‚
5. **ç¡¬ä»¶ååŒä¼˜åŒ–**ï¼šç»“åˆNIC offloadæˆ–ä¸“ç”¨è§£ç èŠ¯ç‰‡æå‡ç«¯ä¾§æ•ˆç‡ã€‚

---

> âœ… **æ€»ä½“è¯„ä»·**ï¼š  
> PULSEä¸ä»…æ˜¯ä¸€é¡¹é«˜æ•ˆçš„å·¥ç¨‹ä¼˜åŒ–ï¼Œæ›´æ˜¯å¯¹**ç°ä»£RLè®­ç»ƒå†…åœ¨ç»“æ„ç‰¹æ€§**çš„ä¸€æ¬¡æ·±åˆ»æ´å¯Ÿã€‚å®ƒæ­ç¤ºäº†â€œçœ‹ä¼¼å¯†é›†â€çš„è®­ç»ƒè¿‡ç¨‹èƒŒåéšè—çš„å·¨å¤§ç¨€ç–æ½œåŠ›ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºå®é™…çš„ç³»ç»Ÿä¼˜åŠ¿ï¼Œä¸º**å»ä¸­å¿ƒåŒ–AIè®­ç»ƒ**é“ºå¹³äº†é“è·¯ã€‚

</details>

---

### 4. [Quant VideoGen: Auto-Regressive Long Video Generation via 2-Bit KV-Cache Quantization](https://arxiv.org/abs/2602.02958)

**Authors**: Haocheng Xi, Shuo Yang, Yilong Zhao, Muyang Li, Han Cai, Xingyang Li, Yujun Lin, Zhuoyang Zhang, Jintao Zhang, Xiuyu Li, Zhiying Xu, Jun Wu, Chenfeng Xu, Ion Stoica, Song Han, Kurt Keutzer  
**Category**: cs.LG  
**Published**: 2026-02-04  
**Score**: 12.5  
**Type**: new  
**ArXiv ID**: 2602.02958v1  

#### Abstract
Despite rapid progress in autoregressive video diffusion, an emerging system algorithm bottleneck limits both deployability and generation capability: KV cache memory. In autoregressive video generation models, the KV cache grows with generation history and quickly dominates GPU memory, often exceed...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡ã€ŠQuant VideoGen: Auto-Regressive Long Video Generation via 2-Bit KV-Cache Quantizationã€‹æ€»ç»“**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
- **KV-cache å†…å­˜ç“¶é¢ˆ**ï¼šåœ¨è‡ªå›å½’è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼ˆå¦‚ LongCat-Videoã€Self-Forcingï¼‰ä¸­ï¼Œéšç€ç”Ÿæˆé•¿åº¦å¢åŠ ï¼ŒKV-cache éšæ—¶é—´çº¿æ€§å¢é•¿ï¼Œè¿…é€Ÿå æ® GPU æ˜¾å­˜ï¼ˆå¯è¾¾ 30â€“34GBï¼‰ï¼Œæˆä¸ºéƒ¨ç½²å’Œé•¿æ—¶ç”Ÿæˆçš„ä¸»è¦é™åˆ¶ã€‚
- **èƒ½åŠ›å—é™**ï¼šå—é™çš„ KV-cache å®¹é‡å¯¼è‡´ä¸Šä¸‹æ–‡çª—å£è¢«æˆªæ–­ï¼Œè¿›è€Œå¼•å‘èº«ä»½æ¼‚ç§»ã€å¸ƒå±€ä¸ä¸€è‡´ã€è¿åŠ¨æ–­è£‚ç­‰é•¿æœŸä¸€è‡´æ€§é—®é¢˜ã€‚
- **ç°æœ‰é‡åŒ–æ–¹æ³•å¤±æ•ˆ**ï¼šç›´æ¥å°† LLM ä¸­æˆç†Ÿçš„ KV-cache é‡åŒ–æŠ€æœ¯ï¼ˆå¦‚ KIVIã€QuaRotï¼‰åº”ç”¨äºè§†é¢‘æ‰©æ•£æ¨¡å‹ä¼šå¯¼è‡´ä¸¥é‡è´¨é‡ä¸‹é™ï¼Œå› å…¶æœªè€ƒè™‘è§†é¢‘ç‰¹æœ‰çš„æ—¶ç©ºå†—ä½™å’Œæ•°å€¼åˆ†å¸ƒå¼‚è´¨æ€§ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æå‡º **Quant VideoGen (QVG)** â€”â€”ä¸€ç§æ— éœ€è®­ç»ƒçš„ KV-cache é‡åŒ–æ¡†æ¶ï¼Œä¸“ä¸ºè‡ªå›å½’è§†é¢‘æ‰©æ•£æ¨¡å‹è®¾è®¡ï¼Œæ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š
1. **Semantic-Aware Smoothing (SAS)**  
   - åˆ©ç”¨ k-means èšç±»å¯¹è¯­ä¹‰ç›¸ä¼¼çš„ token è¿›è¡Œåˆ†ç»„ï¼Œå¹¶å‡å»æ¯ç»„çš„å‡å€¼ï¼ˆcentroidï¼‰ï¼Œå¾—åˆ°ä½å¹…å€¼ã€æ›´å‡åŒ€çš„æ®‹å·®å¼ é‡ã€‚
   - æœ‰æ•ˆç¼“è§£äº† KV-cache åœ¨ token å’Œ channel ç»´åº¦ä¸Šçš„æ•°å€¼å¼‚è´¨æ€§ï¼Œä½¿åˆ†å¸ƒæ›´é€‚åˆä½æ¯”ç‰¹é‡åŒ–ã€‚

2. **Progressive Residual Quantization (PRQ)**  
   - å—æµåª’ä½“è§†é¢‘ç¼–ç å¯å‘ï¼Œé‡‡ç”¨å¤šé˜¶æ®µç²—åˆ°ç»†çš„æ®‹å·®é‡åŒ–ç­–ç•¥ã€‚
   - æ¯ä¸€é˜¶æ®µå¯¹ä¸Šä¸€é˜¶æ®µçš„æ®‹å·®å†æ¬¡åº”ç”¨ SASï¼Œé€æ­¥æ•è·ä»å…¨å±€ç»“æ„åˆ°ç»†èŠ‚çº¹ç†çš„ä¿¡æ¯ï¼Œæ˜¾è‘—é™ä½ç´¯ç§¯é‡åŒ–è¯¯å·®ã€‚

3. **ç®—æ³•-ç³»ç»ŸååŒä¼˜åŒ–**
   - **Streaming centroid caching**ï¼šç¼“å­˜å‰ä¸€å—çš„èšç±»ä¸­å¿ƒä»¥åŠ é€Ÿ k-means æ¨ç†ã€‚
   - **èåˆåé‡åŒ–å†…æ ¸ï¼ˆfused dequantization kernelï¼‰**ï¼šåœ¨å¯„å­˜å™¨ä¸­å®Œæˆåé‡åŒ–ä¸æ®‹å·®é‡å»ºï¼Œé¿å…å¤šæ¬¡è®¿å­˜ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹é¢ | QVG ä¼˜åŠ¿ |
|------|---------|
| **å†…å­˜å‹ç¼©æ¯”** | æœ€é«˜å®ç° **7.0Ã— KV-cache å‹ç¼©**ï¼ˆINT2ï¼‰ï¼Œè¿œè¶…åŸºçº¿ï¼ˆå¦‚ KIVIã€QuaRot ä»…æ”¯æŒ ~6.4Ã—ï¼‰ã€‚ |
| **è§†è§‰è´¨é‡ä¿æŒ** | åœ¨é«˜å‹ç¼©ä¸‹ä»ä¿æŒè¿‘æ— æŸè´¨é‡ï¼ˆPSNR >28.7ï¼‰ï¼Œè€ŒåŸºçº¿åœ¨ INT2 ä¸‹ä¸¥é‡é€€åŒ–ã€‚ |
| **å»¶è¿Ÿå¼€é”€** | ç«¯åˆ°ç«¯å»¶è¿Ÿå¢åŠ  <4%ï¼Œå‡ ä¹ä¸å½±å“æ¨ç†æ•ˆç‡ã€‚ |
| **éƒ¨ç½²å¯è¡Œæ€§** | é¦–æ¬¡å®ç°åœ¨å•å¼  RTX 4090 ä¸Šè¿è¡Œ HY-WorldPlay-8B æ¨¡å‹ï¼Œçªç ´ç¡¬ä»¶é™åˆ¶ã€‚ |
| **é€šç”¨æ€§** | æ— éœ€å¾®è°ƒæˆ–é‡æ–°è®­ç»ƒï¼Œé€‚ç”¨äºå¤šç§è‡ªå›å½’è§†é¢‘æ¨¡å‹ï¼ˆLongCat-Videoã€HY-WorldPlayã€Self-Forcingï¼‰ã€‚ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†ä¸æ¨¡å‹**
- **æ¨¡å‹**ï¼š
  - **LongCat-Video-13B**ï¼šåŸºäºå›ºå®šä¸Šä¸‹æ–‡çª—å£è¿›è¡Œè§†é¢‘å»¶ç»­ä»»åŠ¡ã€‚
  - **HY-WorldPlay-8B**ï¼šç”¨äºå®æ—¶äº¤äº’å¼ä¸–ç•Œå»ºæ¨¡ï¼Œchunk-wise ç”Ÿæˆã€‚
  - **Self-Forcing-Wan-1.3B**ï¼šè‡ªå›å½’å¸§é¢„æµ‹æ¨¡å‹ï¼Œæµ‹è¯•é•¿æœŸä¸€è‡´æ€§ã€‚
- **è¾“å…¥åˆ†è¾¨ç‡**ï¼šç»Ÿä¸€ä½¿ç”¨ **480p** è§†é¢‘ã€‚
- **æç¤ºè¯æ¥æº**ï¼šé‡‡ç”¨ MovieGen benchmark æä¾›çš„ prompt suiteã€‚

### **å®éªŒè®¾ç½®**
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA H100 GPUï¼ˆCUDA 12.8ï¼‰ï¼Œéƒ¨åˆ†å®éªŒéªŒè¯äº RTX 4090ã€‚
- **é‡åŒ–é…ç½®**ï¼š
  - æ”¯æŒ **INT2 / INT4** å¯¹ç§° per-group æ•´æ•°é‡åŒ–ã€‚
  - ä¸¤ç§æ¨¡å¼ï¼š
    - **QVG**ï¼šå•é˜¶æ®µ SAS + INT2ï¼Œè¿½æ±‚æœ€å¤§å‹ç¼©æ¯”ã€‚
    - **QVG-Pro**ï¼š4 é˜¶æ®µ PRQ + INT4ï¼Œè¿½æ±‚æœ€ä¼˜è´¨é‡ã€‚
- **å®ç°æ–¹å¼**ï¼šåŸºäº CUDA å’Œ Triton ç¼–å†™å®šåˆ¶å†…æ ¸ï¼Œæ”¯æŒæµå¼ chunk å‹ç¼©ï¼Œé˜²æ­¢é‡å‹ç¼©æ¼‚ç§»ã€‚
- **å…¶ä»–è®¾å®š**ï¼š
  - ä½¿ç”¨ pre-RoPE key cachingã€‚
  - scaling factors ä½¿ç”¨ FP8 E4M3 å­˜å‚¨ã€‚
  - åˆ†ç»„å¤§å°ï¼ˆgroup sizeï¼‰è®¾ä¸º 16 æˆ– 64ï¼Œèšç±»æ•° $ K=256 $ï¼ˆuint8 å­˜å‚¨ç´¢å¼•ï¼‰ã€‚

### **è¯„ä¼°æŒ‡æ ‡**
| ç±»åˆ« | æŒ‡æ ‡ |
|------|------|
| **ä¿çœŸåº¦** | PSNRã€SSIMã€LPIPSï¼ˆç›¸å¯¹äº BF16 åŸºçº¿ï¼‰ |
| **æ„ŸçŸ¥è´¨é‡** | VBench benchmarkï¼š<br>- Background Consistency<br>- Image Quality<br>- Subject Consistency<br>- Aesthetic Quality |
| **æ•ˆç‡** | KV-cache å‹ç¼©æ¯”ã€ç«¯åˆ°ç«¯å»¶è¿Ÿå¼€é”€ |
| **é•¿æœŸä¸€è‡´æ€§** | åœ¨é•¿åºåˆ—ä¸­æ¯éš” 50 å¸§æŠ¥å‘Š Image Qualityï¼Œè§‚å¯Ÿæ¼‚ç§»æƒ…å†µ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **Round-to-Nearest (RTN)**ï¼šæœ€ç®€å•çš„èˆå…¥é‡åŒ–ã€‚
- **KIVI**ï¼šé’ˆå¯¹ LLM è®¾è®¡çš„ 2-bit ä¸å¯¹ç§°é‡åŒ–ï¼Œå¤„ç†å¼‚å¸¸å€¼ã€‚
- **QuaRot**ï¼šé€šè¿‡æ—‹è½¬å¹³æ»‘æ¿€æ´»åˆ†å¸ƒåå†é‡åŒ–ã€‚
- æ‰€æœ‰åŸºçº¿å‡å¤ç°å…¶ KV-cache é‡åŒ–éƒ¨åˆ†ï¼Œæƒé‡ä¸æ¿€æ´»ä¿æŒæµ®ç‚¹ã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
| æ¨¡å‹ | æ–¹æ³• | å‹ç¼©æ¯” | PSNR | SSIM | LPIPS | Subject Consistency |
|------|------|--------|-------|-------|--------|---------------------|
| LongCat-13B | QVG | **6.94Ã—** | **28.716** | 0.909 | 0.065 | **94.11** |
| | QVG-Pro | 4.97Ã— | **30.376** | **0.935** | **0.048** | 94.92 |
| | KIVI (6.4Ã—) | 6.40Ã— | 20.317 | 0.719 | 0.208 | 75.25 |
| HY-WorldPlay-8B | QVG | **7.05Ã—** | **29.174** | 0.882 | 0.094 | **97.90** |
| | QVG-Pro | 5.20Ã— | **31.562** | **0.923** | **0.069** | 97.96 |
| | QuaRot (6.4Ã—) | 6.40Ã— | 25.207 | 0.738 | 0.205 | 96.64 |

> âœ… QVG åœ¨æœ€é«˜å‹ç¼©æ¯”ä¸‹ä»ä¼˜äºæ‰€æœ‰åŸºçº¿åœ¨æ›´ä½å‹ç¼©ä¸‹çš„è¡¨ç°ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- **è´¨é‡æ–¹é¢**ï¼š
  - æ‰€æœ‰åŸºçº¿åœ¨ **INT2 è®¾ç½®ä¸‹å‡ºç°å‰§çƒˆé€€åŒ–**ï¼ˆPSNR ä¸‹é™ >8dBï¼‰ï¼Œå°¤å…¶ Subject Consistency æ˜æ˜¾ä¸‹é™ã€‚
  - QVG å³ä½¿åœ¨ INT2 ä¸‹ä¹Ÿæ¥è¿‘ BF16 åŸºçº¿è´¨é‡ï¼Œå®ç°â€œè¿‘æ— æŸâ€å‹ç¼©ã€‚
- **å‹ç¼©æ•ˆç‡**ï¼š
  - QVG è¾¾åˆ° **6.94â€“7.05Ã— å‹ç¼©æ¯”**ï¼Œæ˜¾è‘—é«˜äºåŸºçº¿ï¼ˆæ™®é â‰¤6.4Ã—ï¼‰ã€‚
  - QVG-Pro åœ¨è¾ƒä½å‹ç¼©æ¯”ä¸‹æä¾›æ›´é«˜ä¿çœŸåº¦ï¼Œå½¢æˆå®Œæ•´çš„ **Pareto å‰æ²¿**ã€‚
- **é•¿æœŸç”Ÿæˆç¨³å®šæ€§**ï¼ˆè§ Figure 5aï¼‰ï¼š
  - åœ¨ Self-Forcing æ¨¡å‹ä¸Šç”Ÿæˆé•¿è¾¾ 700 å¸§çš„è§†é¢‘ï¼š
    - BF16 åŸºçº¿å’Œ QVG/QVG-Pro å‡ ä¹æ— é€€åŒ–ã€‚
    - å…¶ä»–åŸºçº¿åœ¨çº¦ 100 å¸§åå›¾åƒè´¨é‡æ€¥å‰§ä¸‹é™ã€‚

### **æ¶ˆèå®éªŒç»“æœ**
#### ï¼ˆ1ï¼‰**Semantic-Aware Smoothing çš„æœ‰æ•ˆæ€§**
- å¦‚ Figure 6 æ‰€ç¤ºï¼š
  - SAS å°† Key Cache çš„é‡åŒ–è¯¯å·®é™ä½ **6.9Ã—**ã€‚
  - Value Cache è¯¯å·®é™ä½ **2.6Ã—**ã€‚
- åŸå› ï¼šé€šè¿‡èšç±»å‡å»å‡å€¼å¾—åˆ°çš„å°å¹…å€¼æ®‹å·®æ›´æ˜“é‡åŒ–ã€‚

#### ï¼ˆ2ï¼‰**Progressive Residual Quantization çš„å¢ç›Š**
- å¦‚ Figure 5(c) æ‰€ç¤ºï¼š
  - ç¬¬ä¸€é˜¶æ®µå¸¦æ¥ **5.83Ã— MSE å‡å°‘**ã€‚
  - åç»­é˜¶æ®µæŒç»­æ”¹è¿›ï¼Œä½†è¾¹é™…æ”¶ç›Šé€’å‡ï¼ˆç¬¬4é˜¶æ®µä»…æå‡ ~1.1Ã—ï¼‰ã€‚
- è¡¨æ˜ PRQ æˆåŠŸå®ç°äº†ä»ç²—åˆ°ç»†çš„ä¿¡æ¯ä¿ç•™ã€‚

#### ï¼ˆ3ï¼‰**åˆ†ç»„å¤§å°çš„å½±å“**
- åˆ†ç»„è¶Šå¤§ï¼ˆå¦‚ 64 vs 16ï¼‰â†’ å‹ç¼©ç‡è¶Šé«˜ï¼Œä½†è´¨é‡ç•¥é™ã€‚
- QVG é€‰æ‹© group size=64 å®ç°æœ€ä½³æƒè¡¡ï¼›QVG-Pro ä½¿ç”¨ smaller group size=16 ä¿è¯é«˜è´¨é‡ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **KV-cache æ˜¯è‡ªå›å½’è§†é¢‘ç”Ÿæˆçš„å…³é”®ç“¶é¢ˆ**ï¼Œä¸ä»…å½±å“éƒ¨ç½²æ•ˆç‡ï¼Œæ›´ç›´æ¥åˆ¶çº¦é•¿æœŸä¸€è‡´æ€§èƒ½åŠ›ã€‚
2. **è§†é¢‘ KV-cache å…·æœ‰å¼ºæ—¶ç©ºå†—ä½™æ€§**ï¼Œå¯é€šè¿‡è¯­ä¹‰èšç±»å’Œå¹³æ»‘æ®‹å·®çš„æ–¹å¼æå¤§æå‡å¯å‹ç¼©æ€§ã€‚
3. **ä¼ ç»Ÿ LLM é‡åŒ–æ–¹æ³•æ— æ³•ç›´æ¥è¿ç§»è‡³è§†é¢‘æ¨¡å‹**ï¼Œå¿…é¡»ç»“åˆè§†é¢‘ç‰¹æœ‰çš„åŠ¨æ€åˆ†å¸ƒç‰¹æ€§è¿›è¡Œä¸“é—¨è®¾è®¡ã€‚
4. **QVG å®ç°äº†å‰æ‰€æœªæœ‰çš„ 7.0Ã— KV-cache å‹ç¼©æ¯”**ï¼ŒåŒæ—¶ä¿æŒè¿‘æ— æŸè§†è§‰è´¨é‡ï¼Œæ¨åŠ¨é•¿è§†é¢‘ç”Ÿæˆèµ°å‘å®ç”¨åŒ–ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ– k-means èšç±»**ï¼šå°½ç®¡é€šè¿‡ç¼“å­˜ä¼˜åŒ–é™ä½äº†å¼€é”€ï¼Œä½†ä»å¼•å…¥é¢å¤–è®¡ç®—ï¼Œå¯èƒ½ä¸é€‚åˆæä½å»¶è¿Ÿåœºæ™¯ã€‚
- **æœªæ¢ç´¢ weight quantization**ï¼šå½“å‰ä»…èšç„¦ KV-cacheï¼Œå®Œæ•´æ¨¡å‹é‡åŒ–å°šæœªè¦†ç›–ã€‚
- **å¯¹æç«¯åŠ¨æ€åœºæ™¯æ•æ„Ÿ**ï¼šè‹¥è§†é¢‘å†…å®¹çªå˜é¢‘ç¹ï¼ˆå¦‚å¿«é€Ÿåˆ‡æ¢é•œå¤´ï¼‰ï¼ŒSAS çš„èšç±»æ•ˆæœå¯èƒ½å‡å¼±ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- ç»“åˆ **sparse attention** ä¸ QVGï¼Œè¿›ä¸€æ­¥å‡å°‘ KV å­˜å‚¨éœ€æ±‚ã€‚
- æ¢ç´¢ **learned codebook-based vector quantization** æ›¿ä»£ k-meansï¼Œæå‡èšç±»æ•ˆç‡ã€‚
- å°† QVG æ€è·¯æ‰©å±•è‡³ **audio-visual å¤šæ¨¡æ€ç”Ÿæˆç³»ç»Ÿ**ã€‚
- æ„å»ºç«¯åˆ°ç«¯çš„ **hardware-aware ç¼–è¯‘æµç¨‹**ï¼Œæœ€å¤§åŒ– GPU åˆ©ç”¨ç‡ã€‚

---

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> **Quant VideoGen (QVG)** é€šè¿‡è¯­ä¹‰æ„ŸçŸ¥å¹³æ»‘ä¸æ¸è¿›æ®‹å·®é‡åŒ–ï¼Œåœ¨æ— éœ€è®­ç»ƒçš„å‰æä¸‹å®ç°äº†é«˜è¾¾ **7Ã— çš„ KV-cache å‹ç¼©**ï¼Œè§£å†³äº†è‡ªå›å½’è§†é¢‘ç”Ÿæˆä¸­çš„å†…å­˜ç“¶é¢ˆï¼Œé¦–æ¬¡ä½¿å¾—åˆ†é’Ÿçº§ç”šè‡³å°æ—¶çº§é«˜è´¨é‡è§†é¢‘ç”Ÿæˆåœ¨æ¶ˆè´¹çº§ GPU ä¸Šæˆä¸ºå¯èƒ½ã€‚

</details>

---

### 5. [Large-Scale LLM Inference with Heterogeneous Workloads: Prefill-Decode Contention and Asymptotically Optimal Control](https://arxiv.org/abs/2602.02987)

**Authors**: Ruihan Lin, Zezhen Ding, Zean Han, Jiheng Zhang  
**Category**: cs.DC  
**Published**: 2026-02-04  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2602.02987v1  

#### Abstract
Large Language Models (LLMs) are rapidly becoming critical infrastructure for enterprise applications, driving unprecedented demand for GPU-based inference services. A key operational challenge arises from the two-phase nature of LLM inference: a compute-intensive \emph{prefill} phase that processes...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Large-Scale LLM Inference with Heterogeneous Workloads: Prefill-Decode Contention and Asymptotically Optimal Control*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹å¤§è§„æ¨¡ **Large Language Model (LLM)** æ¨ç†æœåŠ¡ä¸­çš„ä¸€ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼š**Prefill-Decode Contention**ï¼ˆé¢„å¡«å……-è§£ç äº‰ç”¨ï¼‰ã€‚

åœ¨ LLM æ¨ç†ä¸­ï¼Œæ¯ä¸ªè¯·æ±‚åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼š
- **Prefill Phase**ï¼šå¤„ç†ç”¨æˆ·è¾“å…¥æç¤ºï¼ˆcompute-intensiveï¼Œè®¡ç®—å¯†é›†å‹ï¼‰ã€‚
- **Decode Phase**ï¼šè‡ªå›å½’ç”Ÿæˆè¾“å‡º tokenï¼ˆmemory-boundï¼Œå†…å­˜å—é™ï¼‰ã€‚

å½“è¿™ä¸¤ä¸ªé˜¶æ®µå…±äº« GPU èµ„æºæ—¶ï¼Œ**Prefill ä»»åŠ¡ä¼šæ˜¾è‘—æ‹–æ…¢åŒæ‰¹å¤„ç†çš„ Decode ä»»åŠ¡**ï¼Œå½¢æˆçŠ¶æ€ä¾èµ–çš„æœåŠ¡é€Ÿç‡ã€‚æ­¤å¤–ï¼Œç°å®ä¸–ç•Œçš„å·¥ä½œè´Ÿè½½å…·æœ‰é«˜åº¦å¼‚è´¨æ€§ï¼ˆheterogeneous workloadsï¼‰ï¼Œä¸åŒåº”ç”¨ï¼ˆå¦‚æ‘˜è¦ã€åˆ›æ„å†™ä½œï¼‰çš„è¾“å…¥/è¾“å‡ºé•¿åº¦å·®å¼‚å·¨å¤§ï¼Œä½¿å¾—èµ„æºè°ƒåº¦æ›´åŠ å¤æ‚ã€‚

å› æ­¤ï¼Œè®ºæ–‡æ—¨åœ¨è§£å†³ï¼š**å¦‚ä½•åœ¨å¼‚æ„è¯·æ±‚æ··åˆçš„å¤§è§„æ¨¡ GPU é›†ç¾¤ä¸­ï¼Œè”åˆæ§åˆ¶ Admission å’Œ Schedulingï¼Œä»¥æœ€å¤§åŒ–åŸºäº token çš„æ”¶ç›Šï¼ˆrevenueï¼‰ï¼ŒåŒæ—¶æ»¡è¶³ Service Level Indicators (SLIs) å¦‚å»¶è¿Ÿå’Œå…¬å¹³æ€§è¦æ±‚ï¼Ÿ**

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
è®ºæ–‡æå‡ºäº†ä¸€å¥—å®Œæ•´çš„ **Stochastic Control** æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°ç‚¹å¦‚ä¸‹ï¼š

1. **å¤šç±»å¤šæœåŠ¡å™¨æ’é˜Ÿç½‘ç»œæ¨¡å‹ (Multiclass Many-Server Queueing Network)**  
   å°† LLM æ¨ç†ç³»ç»Ÿå»ºæ¨¡ä¸ºä¸€ä¸ªå¸¦æœ‰**çŠ¶æ€ä¾èµ–æœåŠ¡é€Ÿç‡**çš„æ’é˜Ÿç½‘ç»œã€‚GPU æœ‰ä¸¤ç§æ¨¡å¼ï¼š
   - **Mixed Mode**ï¼šè¿è¡Œä¸€ä¸ª Prefill + å¤šä¸ª Decodeï¼ˆDecode é€Ÿåº¦å›  Prefill å ç”¨è®¡ç®—è€Œå˜æ…¢ï¼‰ã€‚
   - **Solo Mode**ï¼šä»…è¿è¡Œ Decodeï¼ˆé€Ÿåº¦æ›´å¿«ï¼‰ã€‚

2. **åŸºäºæµä½“è¿‘ä¼¼çš„è§„åˆ’ä¸æ§åˆ¶åˆ†ç¦»æ¶æ„ (Fluid Approximation + Gate-and-Route Policy)**  
   - åœ¨ **Many-GPU æé™**ä¸‹ï¼Œé€šè¿‡**æµä½“è¿‘ä¼¼ (Fluid Approximation)** å°†éšæœºç³»ç»Ÿç®€åŒ–ä¸ºç¡®å®šæ€§æ¨¡å‹ã€‚
   - æ±‚è§£ä¸€ä¸ª**ç¨³æ€çº¿æ€§è§„åˆ’ (Steady-State Linear Program, LP)**ï¼Œå¾—åˆ°æœ€ä¼˜çš„å®¹é‡åˆ†é…ï¼ˆå¤šå°‘ GPU ç”¨äº Mixed/Soloï¼‰å’Œå„ç±»è¯·æ±‚çš„å ç”¨ç›®æ ‡ (occupancy targets)ã€‚
   - è®¾è®¡ **Gate-and-Route æ§åˆ¶ç­–ç•¥**å°† LP è§£è½¬åŒ–ä¸ºå¯æ‰§è¡Œç­–ç•¥ï¼š
     - **Prefill Gate**ï¼šåŸºäºå½“å‰ Prefill å ç”¨ä¸ç›®æ ‡çš„åå·®ï¼ŒåŠ¨æ€å†³å®šæ˜¯å¦æ¥çº³æ–°è¯·æ±‚ï¼Œç¡®ä¿å ç”¨é‡æ”¶æ•›åˆ°ç›®æ ‡ã€‚
     - **Decode Router**ï¼šå°†å®Œæˆ Prefill çš„è¯·æ±‚è·¯ç”±åˆ°å¯ç”¨çš„ Decode Slotã€‚

3. **æ”¯æŒå¤šç§è®¡è´¹æ¨¡å¼å’Œ SLI çº¦æŸ**
   - åˆ†åˆ«åˆ†æäº† **Bundled Charging**ï¼ˆè¯·æ±‚å®Œæˆåç»Ÿä¸€æ”¶è´¹ï¼‰å’Œ **Separate Charging**ï¼ˆPrefill å’Œ Decode åˆ†å¼€æ”¶è´¹ï¼‰ä¸¤ç§æ¨¡å¼ï¼Œå¹¶è®¾è®¡äº†ç›¸åº”çš„æ¸è¿‘æœ€ä¼˜ç­–ç•¥ï¼ˆåè€…éœ€ä½¿ç”¨ä¼˜å…ˆçº§ç­–ç•¥ï¼‰ã€‚
   - å°† **SLIs**ï¼ˆå¦‚å…¬å¹³æ€§ã€å»¶è¿Ÿï¼‰ä½œä¸ºçº¦æŸæˆ–æƒ©ç½šé¡¹åŠ å…¥ LPï¼Œå®ç°æ”¶ç›Šä¸æœåŠ¡è´¨é‡çš„æƒè¡¡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **ç†è®ºä¿è¯**ï¼šæ‰€æç­–ç•¥è¢«è¯æ˜æ˜¯**æ¸è¿‘æœ€ä¼˜ (asymptotically optimal)** çš„ï¼Œå³å½“ GPU æ•°é‡è¶‹äºæ— ç©·å¤§æ—¶ï¼Œæ¯ GPU æ”¶ç›Šæ”¶æ•›åˆ°æµä½“æœ€ä¼˜å€¼ã€‚
- **ç³»ç»Ÿæ€§æ¡†æ¶**ï¼šé¦–æ¬¡å°†æ’é˜Ÿè®ºä¸å®è¯æµ‹é‡ç»“åˆï¼Œä¸º LLM æ¨ç†è°ƒåº¦æä¾›äº†ä¸¥è°¨çš„æ•°å­¦åŸºç¡€ï¼Œè¶…è¶Šäº†ç°æœ‰çš„å·¥ç¨‹å¯å‘å¼æ–¹æ³•ã€‚
- **çµæ´»æ€§é«˜**ï¼šæ¡†æ¶å¯è‡ªç„¶æ‰©å±•è‡³å¤šç§å•†ä¸šç›®æ ‡ï¼ˆå¦‚æ”¶ç›Šç®¡ç†ï¼‰å’ŒæœåŠ¡è´¨é‡çº¦æŸã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
- **åˆæˆæ•°æ®é›†**ï¼šåŸºäºçœŸå® LLM æ¨ç†ç‰¹å¾ï¼ˆå¦‚ Qwen-4B/8Bï¼‰æ„å»ºçš„ä¸¤ç±»å¼‚æ„è¯·æ±‚ï¼š
  - **Class 0 (Decode-Heavy)**ï¼šçŸ­è¾“å…¥ï¼ˆP=300ï¼‰ã€é•¿è¾“å‡ºï¼ˆD=1000ï¼‰ï¼Œä»£è¡¨ä»£ç ç”Ÿæˆã€‚
  - **Class 1 (Prefill-Heavy)**ï¼šé•¿è¾“å…¥ï¼ˆP=3000ï¼‰ã€çŸ­è¾“å‡ºï¼ˆD=400ï¼‰ï¼Œä»£è¡¨è®ºæ–‡æ‘˜è¦ã€‚
- **å‚æ•°æ ¡å‡†æ•°æ®**ï¼šåœ¨é…å¤‡ 4Ã—NVIDIA A100-SXM4-40GB GPU çš„æœåŠ¡å™¨ä¸Šï¼Œä½¿ç”¨ **vLLM** å¯¹ **Qwen-4B** å’Œ **Qwen-8B** æ¨¡å‹è¿›è¡Œå®æµ‹ï¼Œæ ¡å‡† `Î±`, `Î²`ï¼ˆMixed æ¨¡å¼è¿­ä»£æ—¶é—´å‚æ•°ï¼‰å’Œ `Î³`ï¼ˆSolo æ¨¡å¼è§£ç é€Ÿåº¦ï¼‰ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡æ‹Ÿæ–¹å¼**ï¼šäº‹ä»¶é©±åŠ¨ä»¿çœŸ (event-driven simulation)ï¼Œæ¨¡æ‹Ÿä¸åŒè§„æ¨¡ï¼ˆn=5, 20, 50, 200, 500ï¼‰çš„ GPU é›†ç¾¤ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Per-GPU Revenue**ï¼šå•ä½ GPU çš„å¹³å‡æ”¶ç›Šã€‚
  - **Queue Lengths**ï¼šPrefill å’Œ Decode é˜Ÿåˆ—é•¿åº¦ã€‚
  - **Occupancy Convergence**ï¼šå®é™…èµ„æºå ç”¨æ˜¯å¦æ”¶æ•›åˆ°æµä½“æœ€ä¼˜ç›®æ ‡ã€‚
  - **SLI Trade-offs**ï¼šé€šè¿‡å¸•ç´¯æ‰˜å‰æ²¿åˆ†ææ”¶ç›Šä¸å…¬å¹³æ€§ã€å»¶è¿Ÿä¹‹é—´çš„æƒè¡¡ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
è®ºæ–‡å¯¹æ¯”äº†ä»¥ä¸‹äº”ç§ç­–ç•¥ï¼š
1. **GG-SP (Gate-and-Route with Static Planning)**ï¼šæœ¬æ–‡æå‡ºçš„å®Œæ•´ç­–ç•¥ã€‚
2. **FI-WSP (FCFS-and-Immediate without Static Planning)**ï¼šè¡Œä¸šæ ‡å‡†åŸºçº¿ï¼ˆç±»ä¼¼ Sarathi-Serveï¼‰ï¼Œå…ˆæ¥å…ˆæœåŠ¡ï¼ŒPrefill å®Œæˆåç«‹å³åœ¨åŒä¸€ GPU ä¸Šå¼€å§‹ Decodeã€‚
3. **GI-WSP (Gate-and-Immediate without Static Planning)**ï¼šå¼•å…¥æœ¬æ–‡çš„ Gate æ§åˆ¶ï¼Œä½†ä»é‡‡ç”¨ Immediate æ‰§è¡Œæ¨¡å¼ã€‚
4. **GF-WSP (Gate-and-FCFS without Static Planning)**ï¼šä½¿ç”¨ Gate æ§åˆ¶ï¼Œä½†è·¯ç”±æ—¶ä¼˜å…ˆé€‰æ‹©æ–° Prefill è€Œéç­‰å¾…çš„ Decode ä»»åŠ¡ã€‚
5. **FG-SP (FCFS-and-Route with Static Planning)**ï¼šæœ‰é™æ€è§„åˆ’å’Œè·¯ç”±ï¼Œä½†æ—  Admission Gate æ§åˆ¶ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- **æ”¶ç›Šæ”¶æ•›æ€§**ï¼šéšç€ GPU è§„æ¨¡å¢å¤§ï¼ŒGG-SP çš„ **Per-GPU Revenue** æ¸è¿‘æ”¶æ•›åˆ°æµä½“æœ€ä¼˜å€¼ `R*`ï¼Œä¸”æ–¹å·®æ˜¾è‘—å‡å°ã€‚
- **é˜Ÿåˆ—ç¨³å®šæ€§**ï¼šPrefill é˜Ÿåˆ—ç¨³å®šåœ¨æµä½“ç›®æ ‡é™„è¿‘ï¼ŒDecode é˜Ÿåˆ—å‡ ä¹ä¸ºç©ºï¼ŒéªŒè¯äº† **Decode-Buffer Elimination** çš„ç†è®ºé¢„æµ‹ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **GG-SP æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿**ï¼Œåœ¨æ‰€æœ‰æµ‹è¯•åœºæ™¯ä¸‹å‡å–å¾—æœ€é«˜æ”¶ç›Šã€‚
- **FI-WSP (è¡Œä¸šåŸºçº¿) è¡¨ç°æœ€å·®**ï¼Œå› å…¶æ— æ³•æœ‰æ•ˆæ§åˆ¶ Prefill å¯¼è‡´ Decode è¢«ä¸¥é‡é˜»å¡ã€‚
- **Gate æ§åˆ¶ (GI-WSP) æ¯” FCFS (FI-WSP) æœ‰æ˜æ˜¾æå‡**ï¼Œè¯´æ˜ Admission æ§åˆ¶è‡³å…³é‡è¦ã€‚
- **é™æ€è§„åˆ’ + è´ªå¿ƒè·¯ç”± (FG-SP) åè€Œå¯èƒ½åŠ£äºåŸºçº¿**ï¼Œè¯´æ˜æ²¡æœ‰ Admission æ§åˆ¶çš„é™æ€åˆ’åˆ†å¯èƒ½å¯¼è‡´å±€éƒ¨å¤±è¡¡ã€‚
- **è·¯ç”±ç­–ç•¥ (GF-WSP vs GG-SP)**ï¼šä¼˜å…ˆå¤„ç†ç­‰å¾… Decode çš„ä»»åŠ¡ï¼ˆè€Œéæ–° Prefillï¼‰å¯¹æ€§èƒ½æå‡æ˜¾è‘—ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **SLI-Aware Policy**ï¼šå½“ä½¿ç”¨éšæœºåŒ–è·¯ç”±å™¨ï¼ˆRandomized Routerï¼‰å¼ºåˆ¶å„ç±»è¯·æ±‚çš„ Decode å ç”¨æ¯”ä¾‹æ—¶ï¼Œ**å„ç±»åˆ«çš„ Decode Occupancy ä¹Ÿä¸¥æ ¼æ”¶æ•›åˆ° LP ç›®æ ‡**ï¼Œè€Œæ™®é€šç­–ç•¥ä»…èƒ½ä¿è¯æ€»æ”¶ç›Šæœ€ä¼˜ä½†ç±»åˆ«åˆ†å¸ƒä¸ç¨³å®šã€‚
- **SLI æƒè¡¡åˆ†æ**ï¼š
  - **Prefill Fairness** çš„â€œå½±å­ä»·æ ¼â€å¾ˆé«˜ï¼Œæ„å‘³ç€å¼ºåˆ¶å…¬å¹³ä¼šæ˜¾è‘—ç‰ºç‰²æ”¶ç›Šã€‚
  - **Decode Fairness** çš„å½±å­ä»·æ ¼å¾ˆä½ï¼Œè¯´æ˜åœ¨ Decode é˜¶æ®µå¹³è¡¡å„ç±»è¯·æ±‚æˆæœ¬è¾ƒä½ã€‚
  - **TPOT (Time Per Output Token)** æ¥è¿‘ç¡¬ä»¶æé™ï¼ˆç”± `Î³` å†³å®šï¼‰æ—¶ï¼Œæ”¶ç›Šæ€¥å‰§ä¸‹é™ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **Prefill-Decode Contention æ˜¯å½±å“ LLM æ¨ç†æ•ˆç‡çš„æ ¸å¿ƒç“¶é¢ˆ**ï¼Œå¿…é¡»é€šè¿‡è”åˆè°ƒåº¦å»ºæ¨¡ã€‚
2. **Gate-and-Route æ¶æ„æ˜¯æœ‰æ•ˆçš„**ï¼šé€šè¿‡ Admission Gate æ§åˆ¶ Prefill æµé‡ï¼Œé…åˆ Work-Conserving çš„ Decode è·¯ç”±ï¼Œå¯åœ¨å¤§è§„æ¨¡ä¸‹å®ç°æ¸è¿‘æœ€ä¼˜ã€‚
3. **è®¡è´¹æ¨¡å¼å½±å“è°ƒåº¦ç­–ç•¥**ï¼šSeparate Charging å¯èƒ½æ¿€åŠ±è¿‡åº¦æ¥çº³ Prefillï¼Œå¯¼è‡´ä¸‹æ¸¸æ‹¥å µï¼›å»ºè®®**æŒ‰é˜¶æ®µè®¡è´¹ï¼Œä½†æŒ‰ç«¯åˆ°ç«¯å®Œæˆä¼˜åŒ–è°ƒåº¦**ã€‚
4. **SLI æˆæœ¬ä¸å¯¹ç§°**ï¼šåœ¨ Prefill é˜¶æ®µå®æ–½å…¬å¹³æ€§ä»£ä»·é«˜æ˜‚ï¼Œåœ¨ Decode é˜¶æ®µåˆ™ç›¸å¯¹ä¾¿å®œã€‚
5. **ç¡¬ä»¶é…ç½®æ•æ„Ÿæ€§**ï¼šæ”¶ç›Šå¯¹è®¡ç®—æƒ©ç½šç³»æ•° `Î²` é«˜åº¦æ•æ„Ÿï¼Œè€Œå¯¹æ‰¹å¤§å° `B` å­˜åœ¨æ”¶ç›Šé€’å‡ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **å‡è®¾æŒ‡æ•°åˆ†å¸ƒ**ï¼šæ¨¡å‹å‡è®¾æœåŠ¡æ—¶é—´å’Œè€å¿ƒæ—¶é—´ä¸ºæŒ‡æ•°åˆ†å¸ƒï¼Œè™½ç»å®è¯éªŒè¯åˆç†ï¼Œä½†ä»æ˜¯å¯¹ç°å®çš„ç®€åŒ–ã€‚
- **å‡è´¨åŸºç¡€è®¾æ–½**ï¼šå‡è®¾æ‰€æœ‰ GPU æ€§èƒ½ç›¸åŒï¼Œæœªè€ƒè™‘å¼‚æ„é›†ç¾¤ï¼ˆå¦‚ä¸åŒä»£ GPUï¼‰ã€‚
- **é›†ä¸­å¼æ§åˆ¶**ï¼šGate-and-Route å‡è®¾å…¨å±€çŠ¶æ€å¯è§ï¼Œå¤§è§„æ¨¡åˆ†å¸ƒå¼éƒ¨ç½²å¯èƒ½å­˜åœ¨é€šä¿¡å¼€é”€ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ”¾æ¾æŒ‡æ•°å‡è®¾**ï¼šä½¿ç”¨æ›´ä¸€èˆ¬çš„åˆ†å¸ƒï¼ˆå¦‚ç›¸ä½å‹åˆ†å¸ƒï¼‰æˆ–æµ‹åº¦å€¼è¿‡ç¨‹ (measure-valued processes) è¿›è¡Œå»ºæ¨¡ã€‚
2. **å¼€å‘æ‰©æ•£è¿‘ä¼¼ (Diffusion Approximation)**ï¼šä»¥åˆ»ç”»ç³»ç»Ÿæ³¢åŠ¨ï¼Œä¸ºå°¾éƒ¨å»¶è¿Ÿ (tail-latency) SLIs æä¾›ä¿éšœã€‚
3. **æ¨å¹¿è‡³å¼‚æ„åŸºç¡€è®¾æ–½**ï¼šç ”ç©¶è·¨ä¸åŒ GPU ç±»å‹å’Œ Agent æ¶æ„çš„æ¨ç†ç¼–æ’ã€‚
4. **åœ¨çº¿å­¦ä¹ ä¸é²æ£’æ€§**ï¼šç ”ç©¶åœ¨åˆ°è¾¾ç‡å’ŒæœåŠ¡ç‡ä¸ç¡®å®šæƒ…å†µä¸‹çš„é²æ£’è°ƒåº¦ç­–ç•¥ã€‚

</details>

---

### 6. [Hard Constraints Meet Soft Generation: Guaranteed Feasibility for LLM-based Combinatorial Optimization](https://arxiv.org/abs/2602.01090)

**Authors**: Yang Liu, Chuan Zhou, Yancheng Chen, Shuai Zhang, Xixun Lin, Xiaoqing Wang  
**Category**: cs.AI  
**Published**: 2026-02-04  
**Score**: 11.5  
**Type**: new  
**ArXiv ID**: 2602.01090v1  

#### Abstract
Large language models (LLMs) have emerged as promising general-purpose solvers for combinatorial optimization (CO), yet they fundamentally lack mechanisms to guarantee solution feasibility which is critical for real-world deployment. In this work, we introduce FALCON, a framework that ensures 100\% ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šHard Constraints Meet Soft Generation: Guaranteed Feasibility for LLM-based Combinatorial Optimization**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç»„åˆä¼˜åŒ–ï¼ˆCombinatorial Optimization, COï¼‰ä»»åŠ¡ä¸­å±•ç°å‡ºå¼ºå¤§çš„æ¨¡å¼è¯†åˆ«å’Œåºåˆ—ç”Ÿæˆèƒ½åŠ›ï¼Œä½†å…¶æœ¬è´¨æ˜¯**æ— çº¦æŸçš„ç”Ÿæˆæ¨¡å‹**ï¼Œæ— æ³•ä¿è¯è¾“å‡ºæ»¡è¶³ç¡¬æ€§çº¦æŸæ¡ä»¶ï¼ˆå¦‚å®¹é‡é™åˆ¶ã€è·¯å¾„è¿ç»­æ€§ã€ç‹¬ç«‹é›†æ— é‚»æ¥ç­‰ï¼‰ã€‚è¿™å¯¼è‡´ç”Ÿæˆçš„è§£å¸¸å¸¸ä¸å¯è¡Œï¼ˆinfeasibleï¼‰ï¼Œä¸¥é‡åˆ¶çº¦äº†å…¶åœ¨ç‰©æµã€åˆ¶é€ ã€åº”æ€¥è°ƒåº¦ç­‰å®‰å…¨æ•æ„Ÿåœºæ™¯çš„å®é™…éƒ¨ç½²ã€‚

ç°æœ‰æ–¹æ³•é€šå¸¸é€šè¿‡å¥–åŠ±å¡‘å½¢ï¼ˆreward shapingï¼‰æˆ–åå¤„ç†æ‹’ç»é‡‡æ ·ï¼ˆrejection samplingï¼‰æ¥æå‡å¯è¡Œæ€§ï¼Œä½†è¿™äº›æ–¹æ³•åªèƒ½æä¾›æ¦‚ç‡æ€§ä¿éšœï¼Œ**æ— æ³•å®ç°100%çš„å¯è¡Œæ€§ä¿è¯**ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ï¼šFALCON æ¡†æ¶**
æœ¬æ–‡æå‡ºäº† **FALCON**ï¼ˆFeasibility-Aware Language-based Combinatorial Optimization with Adaptive Inferenceï¼‰ï¼Œé¦–ä¸ªèƒ½**ç†è®ºä¿è¯100%å¯è¡Œæ€§**çš„ LLM-based CO æ±‚è§£æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºä¸‰å±‚ååŒæœºåˆ¶ï¼š

#### **(1) Grammar-Constrained Decodingï¼ˆè¯­æ³•çº¦æŸè§£ç ï¼‰**
- å¼•å…¥**ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•**ï¼ˆContext-Free Grammars, CFGsï¼‰å¯¹æ¯ä¸ª CO é—®é¢˜å®šä¹‰è¾“å‡ºæ ¼å¼ã€‚
- åœ¨è§£ç è¿‡ç¨‹ä¸­é€šè¿‡ **PDAï¼ˆPushdown Automatonï¼‰** åŠ¨æ€å±è”½éæ³• tokenï¼Œç¡®ä¿è¾“å‡º**è¯­æ³•æ­£ç¡®**ï¼ˆå¦‚æ‹¬å·åŒ¹é…ã€ç´¢å¼•æœ‰æ•ˆï¼‰ã€‚
- ä¾‹å¦‚ï¼šTSP å¿…é¡»è¾“å‡º `[0,1,2,0]` å½¢å¼çš„è·¯å¾„ï¼Œè€Œé `0,1,2` æˆ– `[0,1,1,2]`ã€‚

#### **(2) Feasibility Repair Layerï¼ˆå¯è¡Œæ€§ä¿®å¤å±‚ï¼‰**
- è®¾è®¡**é—®é¢˜ç‰¹å®šçš„ä¿®å¤ç®—å­**ï¼ˆRepair Operatorsï¼‰ï¼Œå°†è¯­ä¹‰ä¸Šä¸æ»¡è¶³çº¦æŸçš„è§£è½¬æ¢ä¸ºå¯è¡Œè§£ã€‚
- ä¿®å¤ç®—å­æ»¡è¶³ä¸‰ä¸ªå…³é”®æ€§è´¨ï¼š
  - **å¯è¡Œæ€§**ï¼ˆFeasibilityï¼‰ï¼šä»»ä½•è¾“å…¥ç»ä¿®å¤åå¿…ä¸ºå¯è¡Œè§£ã€‚
  - **å¹‚ç­‰æ€§**ï¼ˆIdempotenceï¼‰ï¼šè‹¥è¾“å…¥å·²å¯è¡Œï¼Œåˆ™è¾“å‡ºä¸å˜ã€‚
  - **æœ‰ç•Œå±€éƒ¨æ€§**ï¼ˆBounded Localityï¼‰ï¼šä¿®å¤å¸¦æ¥çš„è´¨é‡æŸå¤±ä¸è¿åç¨‹åº¦æˆæ­£æ¯”ã€‚
- ä¾‹å¦‚ï¼šCVRP ä¸­è¶…è½½è·¯çº¿è¢«æ‹†åˆ†ï¼›MIS ä¸­ç›¸é‚»é¡¶ç‚¹è¢«ç§»é™¤ä¸€ä¸ªã€‚

#### **(3) Adaptive Best-of-N Samplingï¼ˆè‡ªé€‚åº”å¤šé‡‡æ ·ï¼‰**
- åŠ¨æ€è°ƒæ•´é‡‡æ ·æ•°é‡ $N$ï¼ŒåŸºäº**è§£çš„ä¸€è‡´æ€§**ï¼ˆConsistencyï¼‰ä¼°è®¡å®ä¾‹éš¾åº¦ã€‚
- é«˜ä¸€è‡´æ€§ï¼ˆå¤šæ•°æ ·æœ¬ç›¸åŒï¼‰â†’ æ¨¡å‹è‡ªä¿¡ â†’ å°‘é‡é‡‡æ ·å³å¯ç»ˆæ­¢ã€‚
- ä½ä¸€è‡´æ€§ â†’ æ¨¡å‹ä¸ç¡®å®š â†’ æ›´å¤šæ¢ç´¢ä»¥æ‰¾åˆ°é«˜è´¨é‡è§£ã€‚
- æ˜¾è‘—æå‡æ¨ç†æ•ˆç‡ï¼Œé¿å…å›ºå®š $N$ çš„èµ„æºæµªè´¹ã€‚

---

### **è®­ç»ƒæ–¹æ³•åˆ›æ–°ï¼šBOPO**
æå‡º **Best-anchored Objective-guided Preference Optimization (BOPO)**ï¼Œç”¨äºè®­ç»ƒåº•å±‚ LLMï¼š
- **åŠ¨æœº**ï¼šä¼ ç»Ÿ RL æ–¹æ³•ï¼ˆå¦‚ GRPOï¼‰æ¢¯åº¦ç”±æœ€ä¼˜æ ·æœ¬ä¸»å¯¼ï¼Œå…¶ä»–æ ·æœ¬è´¡çŒ®å¾®å¼±ã€‚
- **æ”¹è¿›**ï¼š
  - æ„é€ åå¥½å¯¹æ—¶ï¼Œä»¥å½“å‰æ‰¹æ¬¡ä¸­çš„**æœ€ä¼˜å¯è¡Œè§£**ä¸ºé”šç‚¹ï¼ˆBest-anchoredï¼‰ã€‚
  - æŸå¤±å‡½æ•°ä¸­å¼•å…¥**ç›®æ ‡å·®è·åŠ æƒ**ï¼ˆObjective-guided weightingï¼‰ï¼šå·®è·è¶Šå¤§ï¼Œå­¦ä¹ ä¿¡å·è¶Šå¼ºã€‚
- ä¼˜åŠ¿ï¼šæä¾›æ›´å¯†é›†ã€æ›´æœ‰æ•ˆçš„ç›‘ç£ä¿¡å·ï¼Œæ— éœ€äººå·¥æ ‡æ³¨ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ç°æœ‰æ–¹æ³• | FALCON |
|------|--------|--------|
| **å¯è¡Œæ€§ä¿è¯** | æ¦‚ç‡æ€§ï¼ˆ<100%ï¼‰ | **ç†è®ºä¿è¯ 100%** âœ… |
| **è§£çš„è´¨é‡** | å¯èƒ½å› æ‹’ç»é‡‡æ ·ä¸¢å¤±ä¼˜è´¨è§£ | ä¿®å¤ä¿ç•™å±€éƒ¨ç»“æ„ï¼Œè´¨é‡æŸå¤±å¯æ§ |
| **æ¨ç†æ•ˆç‡** | å›ºå®š $N$ï¼Œæ˜“æµªè´¹è®¡ç®— | è‡ªé€‚åº”é‡‡æ ·ï¼ŒåŠ¨æ€åˆ†é…èµ„æº âš¡ï¸ |
| **é€šç”¨æ€§** | å¤šä¾èµ–é—®é¢˜ç‰¹å®šè®¾è®¡ | ç»Ÿä¸€æ¡†æ¶ï¼Œå¯æ‰©å±•è‡³å¤šç§ CO é—®é¢˜ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
åœ¨ **7 ä¸ª NP-hard CO é—®é¢˜** ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œè¦†ç›–ä¸‰å¤§é¢†åŸŸï¼š

| é—®é¢˜ç±»åˆ« | é—®é¢˜ | è§„æ¨¡ | åˆ†å¸ƒ | å‚è€ƒæ±‚è§£å™¨ |
|---------|------|------|------|------------|
| **Routing** | TSP, CVRP, OP | 10â€“100 èŠ‚ç‚¹ | Uniform, GM | LKH-3, COMPASS |
| **Graph** | MIS, MVC | 50â€“500 èŠ‚ç‚¹ | ER, BA | Gurobi |
| **Scheduling** | PFSP, JSSP | 10â€“100 ä½œä¸š / 6â€“30 ä½œä¸š | Taillard | QIG, OR-Tools |

- è®­ç»ƒé›†ï¼šå„é—®é¢˜ 500K å®ä¾‹
- æµ‹è¯•é›†ï¼šå„é—®é¢˜ 100 å®ä¾‹

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

#### **è¯„ä¼°æŒ‡æ ‡**
- **å¯è¡Œæ€§ç‡ï¼ˆFeasibility Rate, Fea.%ï¼‰**ï¼šæ»¡è¶³æ‰€æœ‰çº¦æŸçš„è§£çš„æ¯”ä¾‹ã€‚
- **æœ€ä¼˜æ€§å·®è·ï¼ˆOptimality Gap, Gap%ï¼‰**ï¼šä¸å‚è€ƒè§£çš„ç›®æ ‡å€¼ç›¸å¯¹å·®è·ã€‚
- **æ¨ç†æ—¶é—´ï¼ˆTime/sï¼‰**ï¼šå¹³å‡æ¯å®ä¾‹è€—æ—¶ã€‚

#### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
å…±å››ç±»åŸºçº¿ï¼š
1. **é€šç”¨ LLMï¼ˆé›¶æ ·æœ¬ï¼‰**ï¼šGPT-4o, Claude-3.5, Llama-3.3-70B, Qwen2.5-72B
2. **æ¨ç†å¢å¼º LLM**ï¼šGPT-o1, DeepSeek-R1
3. **LLM ä¼˜åŒ–æ–¹æ³•**ï¼šOPRO, LMEA, PHP, SGE
4. **ç¥ç» CO æ±‚è§£å™¨**ï¼šSFT Only, GRPO, LLMCoSolver

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 2ï¼‰**

| æ–¹æ³• | å¹³å‡å¯è¡Œæ€§ | å¹³å‡ Gap% | æ¨ç†æ—¶é—´ (s) |
|------|-----------|----------|-------------|
| **FALCON (Adaptive)** | **100%** | **2.23%** | **6.3** |
| LLMCoSolver (N=8) | 94â€“100% | 2.14â€“11.01% | 9.8 |
| GRPO | 91â€“98% | 1.03â€“2.39% | 5.6 |
| GPT-4o | 6â€“88% | 11.7â€“20.57% | 5.3 |

> âœ… **FALCON åœ¨æ‰€æœ‰ 7 ä¸ªé—®é¢˜ä¸Šå‡å®ç° 100% å¯è¡Œæ€§**  
> ğŸ“ˆ **å¹³å‡ Gap% ä¼˜äºæˆ–æ¥è¿‘ SOTA æ–¹æ³•ï¼Œä¸”ä½¿ç”¨æ›´å°‘é‡‡æ ·**

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- **vs é€šç”¨ LLM**ï¼šFALCON å¯è¡Œæ€§è¿œè¶…ï¼ˆå¦‚ GPT-4o åœ¨ CVRP ä»… 6% å¯è¡Œï¼‰ï¼ŒGap% æ›´ä½ã€‚
- **vs LLMCoSolver**ï¼šè™½åè€…åœ¨éƒ¨åˆ†é—®é¢˜å¯è¾¾é«˜å¯è¡Œæ€§ï¼Œä½†ä»æ— æ³•ä¿è¯ 100%ï¼Œä¸”éœ€æ›´å¤šé‡‡æ ·ï¼ˆN=8ï¼‰ã€‚
- **vs GRPO**ï¼šFALCON åœ¨å¯è¡Œæ€§ä¸Šå®Œèƒœï¼ˆ100% vs <100%ï¼‰ï¼ŒGap% ç›¸å½“ç”šè‡³æ›´ä¼˜ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆTable 4ï¼‰**

| é…ç½® | TSP Gap% | CVRP Gap% | å¯è¡Œæ€§ |
|------|--------|----------|-------|
| **FALCON (Full)** | 0.92 | 3.52 | 100% |
| w/o Grammar | 0.95 | 3.67 | 100% |
| w/o Repair | 0.89 | 3.41 | 94% / 85% âŒ |
| w/o Adaptive | 0.91 | 3.48 | 100% |
| w/o BOPO | 1.85 | 5.89 | 100% âŒ |
| SFT Only | 2.30 | 6.02 | 89% / 59% âŒ |

> ğŸ” **å…³é”®å‘ç°**ï¼š
> - **ä¿®å¤å±‚**æ˜¯å®ç° 100% å¯è¡Œæ€§çš„å…³é”®ã€‚
> - **BOPO** æ˜¾è‘—æå‡è§£çš„è´¨é‡ï¼ˆGap% â†“ï¼‰ã€‚
> - **è‡ªé€‚åº”é‡‡æ ·**å¤§å¹…é™ä½æ¨ç†æˆæœ¬ï¼ˆè§ä¸‹è¡¨ï¼‰ã€‚

---

### **è‡ªé€‚åº”é‡‡æ ·æ•ˆç‡ï¼ˆTable 5ï¼‰**
| é—®é¢˜ | å›ºå®š N=64 | è‡ªé€‚åº”é‡‡æ · |
|------|----------|------------|
| | Gap% / æ—¶é—´ | Gap% / æ—¶é—´ / é‡‡æ ·æ•° |
| **TSP** | 0.89 / 42.5s | 0.92 / **12.8s** / **18.4** |
| **JSSP** | 6.85 / 52.4s | 6.98 / **41.2s** / **48.6** |
| **å¹³å‡** | 2.18 / 45.6s | 2.23 / **20.3s** / **26.7** |

> â±ï¸ **è‡ªé€‚åº”é‡‡æ ·èŠ‚çœçº¦ 55% æ—¶é—´ï¼Œ58% é‡‡æ ·æ¬¡æ•°ï¼Œè´¨é‡å‡ ä¹æ— æŸ**

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **å¯è¡Œæ€§å¯è¢«ä¸¥æ ¼ä¿è¯**ï¼šé€šè¿‡â€œè¯­æ³•çº¦æŸ + ä¿®å¤å±‚â€æ¶æ„ï¼ŒFALCON é¦–æ¬¡å®ç°äº† LLM-based CO çš„ **100% å¯è¡Œæ€§ç†è®ºä¿è¯**ã€‚
2. **è´¨é‡æŸå¤±å¯æ§**ï¼šBOPO è®­ç»ƒä½¿æ¨¡å‹ç”Ÿæˆé«˜åº¦å¯è¡Œçš„è§£ï¼Œä¿®å¤é¢‘ç‡ä½ï¼ˆ<3%â€“18.5%ï¼‰ï¼Œä¸”ä¿®å¤ç®—å­å…·æœ‰æœ‰ç•Œå±€éƒ¨æ€§ï¼Œè´¨é‡æŸå¤±æå°ã€‚
3. **è‡ªé€‚åº”é‡‡æ ·é«˜æ•ˆ**ï¼šåŸºäºä¸€è‡´æ€§ï¼ˆConsistencyï¼‰çš„éš¾åº¦ä¼°è®¡èƒ½å‡†ç¡®åŒºåˆ†éš¾æ˜“å®ä¾‹ï¼Œå®ç°è®¡ç®—èµ„æºçš„æ™ºèƒ½åˆ†é…ã€‚
4. **BOPO ä¼˜äº GRPO**ï¼šåœ¨ç›¸åŒè®­ç»ƒé¢„ç®—ä¸‹ï¼ŒBOPO åœ¨ Gap% å’Œå¯è¡Œæ€§ä¸Šå‡æ˜¾è‘—ä¼˜äº GRPOï¼ˆå›¾2ï¼‰ï¼Œå°¤å…¶åœ¨çº¦æŸå¤æ‚é—®é¢˜ï¼ˆå¦‚ CVRP, MISï¼‰ä¸Šä¼˜åŠ¿æ›´å¤§ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¿®å¤å¯èƒ½å¼•å…¥åå·®**ï¼šè™½ç„¶ä¿®å¤ä¿è¯å¯è¡Œæ€§ï¼Œä½†å¯èƒ½åå‘æŸç§å¯å‘å¼ç­–ç•¥ï¼ˆå¦‚è´ªå¿ƒç§»é™¤ï¼‰ï¼Œå½±å“å…¨å±€æœ€ä¼˜æ€§ã€‚
- **ä¿®å¤ç®—å­éœ€æ‰‹åŠ¨è®¾è®¡**ï¼šå°½ç®¡æ¡†æ¶é€šç”¨ï¼Œä½†æ¯ä¸ªé—®é¢˜çš„ä¿®å¤ç®—å­ä»éœ€é¢†åŸŸçŸ¥è¯†è®¾è®¡ã€‚
- **æœªè€ƒè™‘åŠ¨æ€ç¯å¢ƒ**ï¼šå½“å‰æ¡†æ¶é¢å‘é™æ€ CO é—®é¢˜ï¼Œéš¾ä»¥ç›´æ¥æ‰©å±•åˆ°åœ¨çº¿æˆ–åŠ¨æ€ä¼˜åŒ–åœºæ™¯ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
- **è‡ªåŠ¨åŒ–ä¿®å¤ç®—å­ç”Ÿæˆ**ï¼šç»“åˆç¨‹åºåˆæˆæˆ–å¼ºåŒ–å­¦ä¹ ï¼Œè‡ªåŠ¨å‘ç°é«˜æ•ˆçš„ä¿®å¤ç­–ç•¥ã€‚
- **ç«¯åˆ°ç«¯å¯å¾®ä¿®å¤**ï¼šæ¢ç´¢å¯å¾®åˆ†çš„ä¿®å¤æœºåˆ¶ï¼Œä½¿æ¢¯åº¦èƒ½å›ä¼ è‡³ LLMã€‚
- **æ‰©å±•è‡³åŠ¨æ€ CO**ï¼šå°† FALCON åº”ç”¨äº VRPTWã€åŠ¨æ€è°ƒåº¦ç­‰æ›´å¤æ‚çš„ç°å®é—®é¢˜ã€‚
- **å¤šç›®æ ‡ä¼˜åŒ–æ”¯æŒ**ï¼šæ‰©å±•æ¡†æ¶ä»¥å¤„ç† Pareto æœ€ä¼˜æ€§å’Œå¤šç›®æ ‡åå¥½ã€‚

---

> âœ… **æ€»ç»“**ï¼šFALCON æˆåŠŸå¼¥åˆäº† LLM çš„â€œè½¯ç”Ÿæˆâ€ä¸ CO çš„â€œç¡¬çº¦æŸâ€ä¹‹é—´çš„é¸¿æ²Ÿï¼Œä¸º LLM åœ¨çœŸå®ä¸–ç•Œä¼˜åŒ–ç³»ç»Ÿä¸­çš„å¯é éƒ¨ç½²æä¾›äº†åšå®åŸºç¡€ã€‚

</details>

---

### 7. [Beyond Tokens: Semantic-Aware Speculative Decoding for Efficient Inference by Probing Internal States](https://arxiv.org/abs/2602.03708)

**Authors**: Ximing Dong, Shaowei Wang, Dayi Lin, Boyuan Chen, Ahmed E. Hassan  
**Category**: cs.CL  
**Published**: 2026-02-04  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2602.03708v1  

#### Abstract
Large Language Models (LLMs) achieve strong performance across many tasks but suffer from high inference latency due to autoregressive decoding. The issue is exacerbated in Large Reasoning Models (LRMs), which generate lengthy chains of thought. While speculative decoding accelerates inference by dr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# ã€ŠBeyond Tokens: Semantic-Aware Speculative Decoding for Efficient Inference by Probing Internal Statesã€‹è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
- **ä¼ ç»Ÿ Speculative Decoding çš„è¯­ä¹‰ç›²åŒº**ï¼šç°æœ‰çš„ **Speculative Decoding (SD)** æ–¹æ³•å¤§å¤šåœ¨ **token-level** è¿›è¡Œè‰æ¡ˆç”Ÿæˆä¸éªŒè¯ï¼Œå¿½ç•¥äº†â€œ**è¯­ä¹‰ç­‰ä»·æ€§**â€ï¼ˆsemantic equivalenceï¼‰â€”â€”å³ä¸åŒ token åºåˆ—å¯èƒ½è¡¨è¾¾ç›¸åŒå«ä¹‰ï¼ˆå¦‚ â€œThe capital of France is Paris.â€ vs. â€œParis is the capital of France.â€ï¼‰ã€‚
- å› æ­¤ï¼Œå³ä½¿è‰æ¡ˆåœ¨è¯­ä¹‰ä¸Šæ­£ç¡®ï¼Œä¹Ÿå¯èƒ½å›  token ä¸åŒ¹é…è€Œè¢«é”™è¯¯æ‹’ç»ï¼Œå¯¼è‡´æ¥å—ç‡ä½ã€æ•ˆç‡ä¸‹é™ã€‚
- ç‰¹åˆ«æ˜¯åœ¨ **Large Reasoning Models (LRMs)** ä¸­ï¼Œè¿™ç§é—®é¢˜æ›´ä¸¥é‡ï¼Œå› ä¸ºå…¶è¾“å‡ºæ˜¯é•¿é“¾çš„æ¨ç†æ­¥éª¤ï¼ˆChain-of-Thoughtï¼‰ï¼Œè¡¨é¢å½¢å¼å·®å¼‚å¤§ä½†è¯­ä¹‰ä¸€è‡´çš„æƒ…å†µé¢‘ç¹å‡ºç°ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šSemanticSpec
- **Semantic-Aware Speculative Decoding (SemanticSpec)**ï¼šæå‡ºä¸€ç§å…¨æ–°çš„èŒƒå¼ï¼Œå°† speculative decoding ä» **token-level æå‡åˆ° sequence-level**ï¼Œå¹¶åŸºäºè¯­ä¹‰è¿›è¡ŒéªŒè¯ã€‚
- **æ ¸å¿ƒæœºåˆ¶**ï¼š
  - å¼•å…¥ **Semantic Probability Estimator**ï¼šé€šè¿‡æ¢æŸ¥æ¨¡å‹å†…éƒ¨çš„ **hidden states** æ¥ä¼°è®¡ç”ŸæˆæŸä¸ªè¯­ä¹‰å«ä¹‰çš„æ¦‚ç‡ï¼ˆè€Œéä»…çœ‹ token æ¦‚ç‡ï¼‰ã€‚
  - åœ¨éªŒè¯é˜¶æ®µï¼Œæ¯”è¾ƒè‰æ¡ˆæ¨¡å‹å’Œç›®æ ‡æ¨¡å‹å¯¹åŒä¸€è¯­ä¹‰åºåˆ—çš„â€œè¯­ä¹‰æ¦‚ç‡â€ï¼Œå†³å®šæ˜¯å¦æ¥å—æ•´ä¸ªè¯­ä¹‰å•å…ƒã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿ Token-Level SD | Sequence-Level æ–¹æ³•ï¼ˆå¦‚ SpecReasonï¼‰ | SemanticSpec |
|------|---------------------|----------------------------------|------------|
| éªŒè¯ç²’åº¦ | Token-by-token | æ•´ä¸ª reasoning step | è¯­ä¹‰ç­‰ä»·çš„ sequence |
| è¯­ä¹‰æ„ŸçŸ¥ | âŒ å¿½ç•¥è¯­ä¹‰ç­‰ä»· | âš ï¸ ä¾èµ– LLM-as-a-judge æˆ–å…³é”®è¯ | âœ… åŸºäº internal states çš„è¯­ä¹‰æ¦‚ç‡ |
| å¯é æ€§ | é«˜ï¼ˆlosslessï¼‰ä½†æ•ˆç‡ä½ | ä½ï¼ˆjudge ä¸å¯é ï¼‰ | é«˜ä¸”é«˜æ•ˆ |
| æ¥å—ç‡ | å—é™äºå­—é¢åŒ¹é… | æ˜“è¯¯åˆ¤ | æ›´é²æ£’ï¼Œæå‡æ¥å—ç‡ |

> âœ… **åˆ›æ–°ç‚¹æ€»ç»“**ï¼š
> - é¦–æ¬¡æå‡º **è¯­ä¹‰æ¦‚ç‡**ï¼ˆsemantic probabilityï¼‰æ¦‚å¿µï¼Œå¹¶è®¾è®¡å¯å­¦ä¹ çš„é¢„æµ‹å™¨ã€‚
> - åˆ©ç”¨ **LLM å†…éƒ¨ hidden states** ä½œä¸ºè¯­ä¹‰ç½®ä¿¡åº¦ä»£ç†ï¼Œå®ç°æ— éœ€é‡‡æ ·çš„é«˜æ•ˆä¼°è®¡ã€‚
> - å®ç°äº†çœŸæ­£æ„ä¹‰ä¸Šçš„ **è¯­ä¹‰å¯¹é½éªŒè¯**ï¼Œçªç ´ token åŒ¹é…ç“¶é¢ˆã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **MATH-500**ï¼šæ•°å­¦æ¨ç†åŸºå‡†ï¼ŒåŒ…å« 500 é“ç«èµ›çº§æ•°å­¦é¢˜ã€‚
- **AIME24**ï¼šç¾å›½æ•°å­¦é‚€è¯·èµ›é¢˜ç›®é›†åˆã€‚
- **AMC23**ï¼šç¾å›½æ•°å­¦ç«èµ›é¢˜ç›®ã€‚
- **GPQA-D**ï¼šä¸“å®¶çº§ç§‘å­¦é—®ç­”æ•°æ®é›†ï¼Œæµ‹è¯•æ·±åº¦åˆ†æèƒ½åŠ›ã€‚

> æ‰€æœ‰ä»»åŠ¡å‡æ¶‰åŠå¤šæ­¥æ¨ç†ï¼Œé€‚åˆè¯„ä¼° LRMs å’Œ speculative decoding æ€§èƒ½ã€‚

### å®éªŒè®¾ç½®
- **ç›®æ ‡æ¨¡å‹ (Target Model)**ï¼š
  - `DeepSeek-R1-32B`
  - `QwQ-32B`
- **è‰æ¡ˆæ¨¡å‹ (Draft Model)**ï¼š
  - `DeepSeek-R1-1.5B`ï¼ˆè½»é‡çº§åŒç³»åˆ—æ¨¡å‹ï¼‰
- **è®­ç»ƒæ•°æ®**ï¼š
  - ä½¿ç”¨ `SimpleScaling-S1K` æ•°æ®é›†è®­ç»ƒ **Semantic Probability Predictor**ï¼ŒåŒ…å«çº¦ 800K æ•°å­¦ä¸ç§‘å­¦é—®ç­”å¯¹ã€‚
  - é‡‡ç”¨ `\n\n` åˆ†éš” reasoning steps æ„å»º sequence å•å…ƒã€‚

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Pass@1** | æ­£ç¡®ç”Ÿæˆç­”æ¡ˆçš„æ¯”ä¾‹ï¼Œè¡¡é‡å‡†ç¡®æ€§ |
| **Latency (s)** | æ€»æ¨ç†å»¶è¿Ÿï¼Œè¡¡é‡æ•ˆç‡ |
| **Token Per Second (TPS)** | ååé‡ï¼Œåæ˜ ç³»ç»Ÿååæ€§èƒ½ |
| **Speedup Ratio** | ç›¸å¯¹äºæ ‡å‡† decoding çš„åŠ é€Ÿæ¯” |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | æè¿° |
|------|------|------|
| **SpecSampling** | Token-level | æ ‡å‡† speculative decodingï¼Œé€ token éªŒè¯ |
| **SpecReason (Pan et al., 2025)** | Sequence-level | ä½¿ç”¨ LLM-as-a-judge å¯¹ reasoning step æ‰“åˆ†éªŒè¯ |
| **Speculative Thinking (Yang et al., 2025)** | Sequence-level | åŸºäºâ€œwaitâ€ã€â€œalternativelyâ€ç­‰æç¤ºè¯è§¦å‘å¤§æ¨¡å‹æ¥ç®¡ |
| **Draft-only / Target-only** | æ§åˆ¶ç»„ | ä»…ç”¨è‰æ¡ˆæˆ–ç›®æ ‡æ¨¡å‹ç›´æ¥ç”Ÿæˆ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æ¨¡å‹ç»„åˆ | æ–¹æ³• | Speedup | Pass@1 | TPS |
|---------|------|--------|--------|-----|
| DeepSeek-R1-32B | **SemanticSpec (Ours)** | **2.7Ã—** | 0.892 (AMC23) â†’ 0.910 (Math-500) | â†‘ **1.67Ã— vs SpecSampling** |
| QwQ-32B | **SemanticSpec (Ours)** | **2.1Ã—** | 0.892 (AMC23) â†’ 0.922 (Math-500) | â†‘ **2.66Ã— vs SpecSampling** |

> ğŸ’¡ **è¯´æ˜**ï¼šSemanticSpec åœ¨æ˜¾è‘—æé€Ÿçš„åŒæ—¶ä¿æŒäº†æ¥è¿‘ç›®æ ‡æ¨¡å‹çš„å‡†ç¡®ç‡ï¼ˆå¹³å‡ä»…ä¸‹é™ 3.9%-4.9% Pass@1ï¼‰ã€‚

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ
- **ç›¸æ¯” SpecSampling (token-level)**ï¼š
  - å¹³å‡ **é™ä½ 40.2%~45.3% æ¨ç†æ—¶é—´**
  - **Pass@1 æå‡ 7.3%~17.3%**
  - **TPS æå‡ 1.67X~2.66X**

- **ç›¸æ¯”å…¶ä»– sequence-level æ–¹æ³•**ï¼š
  - **SpecReason**ï¼šè™½ç„¶ä¹Ÿå°è¯•è¯­ä¹‰éªŒè¯ï¼Œä½†ä¾èµ–ä¸å¯é çš„ LLM judgeï¼Œå¯¼è‡´ Pass@1 è¾ƒä½ã€‚
  - **Speculative Thinking**ï¼šè¿‡åº¦ä¾èµ–å¯å‘å¼ä¿¡å·ï¼Œå®¹æ˜“è¯¯æ¥å—é”™è¯¯è‰æ¡ˆï¼ŒPass@1 æœ€ä½ã€‚
  - **SemanticSpec æ˜¾è‘—ä¼˜äºä¸¤è€…**ï¼Œå°¤å…¶åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ï¼ˆå¦‚ AIME24ï¼‰ä¸Šä¼˜åŠ¿æ˜æ˜¾ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
| å˜ä½“ | æè¿° | ç»“æœ |
|------|------|------|
| **Random** | è¯­ä¹‰æ¦‚ç‡éšæœºèµ‹å€¼ | Pass@1 å¤§å¹…ä¸‹é™ï¼ŒéªŒè¯æœºåˆ¶å¤±æ•ˆ |
| **Last-hidden** | ä»…ä½¿ç”¨æœ€åä¸€å±‚ hidden state | TPS æ›´é«˜ï¼ˆè®¡ç®—å¼€é”€å°ï¼‰ï¼Œä½† **Pass@1 æ˜æ˜¾æ›´ä½**ï¼ˆå¦‚ AIME24 ä¸Šä» 0.553â†“åˆ° 0.400ï¼‰ |
| **Ours (All Layers + Avg Pooling)** | ä½¿ç”¨æ‰€æœ‰å±‚ hidden states å¹¶å¹³å‡æ± åŒ– | **æœ€ä½³å¹³è¡¡ç‚¹**ï¼šé«˜ Pass@1ï¼Œåˆç† TPS |

> ğŸ” å‘ç°ï¼š**multi-layer information æ˜¾è‘—æå‡è¯­ä¹‰æ¦‚ç‡ä¼°è®¡å‡†ç¡®æ€§**ï¼Œå°½ç®¡å¸¦æ¥è½»å¾®è®¡ç®—å¼€é”€ã€‚

### æ³›åŒ–æ€§å®éªŒ
- **è·¨é¢†åŸŸé¢„æµ‹**ï¼ˆmath â†” scienceï¼‰ï¼š
  - ä½¿ç”¨ science æ•°æ®è®­ç»ƒçš„ predictor åº”ç”¨äº math ä»»åŠ¡ï¼Œæ€§èƒ½ç•¥æœ‰ä¸‹é™ä½†ä¾ç„¶æœ‰æ•ˆï¼ˆå¦‚ AMC23: 0.892 â†’ 0.875ï¼‰ã€‚
  - è¡¨æ˜ **semantic probability predictor å…·å¤‡è‰¯å¥½è·¨åŸŸæ³›åŒ–èƒ½åŠ›**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **è¯­ä¹‰ç­‰ä»·æ€§æ˜¯æå‡ speculative decoding æ•ˆç‡çš„å…³é”®çªç ´å£**ã€‚
2. âœ… **LLM çš„ internal states èƒ½æœ‰æ•ˆç¼–ç è¯­ä¹‰ç½®ä¿¡åº¦**ï¼Œå¯ç”¨äºæ„å»ºè¯­ä¹‰æ¦‚ç‡ä¼°è®¡å™¨ã€‚
3. âœ… **SemanticSpec å®ç°äº†æ›´é«˜æ¥å—ç‡ä¸æ›´å°‘å›é€€**ï¼Œå°¤å…¶é€‚ç”¨äº LRMs çš„é•¿é“¾æ¨ç†åœºæ™¯ã€‚
4. âœ… ç›¸æ¯” token-level å’Œç°æœ‰ sequence-level æ–¹æ³•ï¼ŒSemanticSpec åœ¨ **æ•ˆç‡ä¸å‡†ç¡®æ€§ä¹‹é—´å–å¾—æ›´å¥½æƒè¡¡**ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ–¹æ³•ä¾èµ–äºèƒ½å¤Ÿè®¿é—®æ¨¡å‹ **internal hidden states**ï¼Œé™åˆ¶äº†åœ¨é»‘ç›’ API åœºæ™¯ä¸‹çš„åº”ç”¨ã€‚
- è¯­ä¹‰èšç±»ä¾èµ–äº **DeBERTa-based entailment detection**ï¼Œå¯èƒ½å­˜åœ¨è¾¹ç•Œæ¡ˆä¾‹è¯¯åˆ¤ã€‚
- è®­ç»ƒ semantic probability predictor éœ€è¦é¢å¤–çš„ç¦»çº¿è®­ç»ƒæˆæœ¬ã€‚
- å®éªŒä»…åœ¨ä¸¤ä¸ªå¼€æºæ¨¡å‹å¯¹ä¸ŠéªŒè¯ï¼Œ**æ³›åŒ–æ€§æœ‰å¾…è¿›ä¸€æ­¥æ£€éªŒ**ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ **zero-shot æˆ– prompt-based semantic probability estimation**ï¼Œå‡å°‘è®­ç»ƒä¾èµ–ã€‚
- å°† SemanticSpec æ‰©å±•è‡³ **vision-language models** æˆ– **code generation** ç­‰å¤šæ¨¡æ€ä»»åŠ¡ã€‚
- è®¾è®¡ **è½»é‡åŒ– probe æ¨¡å—**ï¼Œä¾¿äºéƒ¨ç½²åˆ°è¾¹ç¼˜è®¾å¤‡ã€‚
- ç ”ç©¶å¦‚ä½•åœ¨ **ä¸æš´éœ² internal states çš„æƒ…å†µä¸‹å®ç°è¯­ä¹‰æ„ŸçŸ¥ decoding**ï¼ˆå¦‚è’¸é¦æˆ– probing-free æ–¹æ³•ï¼‰ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **SemanticSpec é€šè¿‡â€œæ¢æŸ¥å†…éƒ¨çŠ¶æ€ä»¥ä¼°è®¡è¯­ä¹‰æ¦‚ç‡â€ï¼Œå®ç°äº†ä» token åŒ¹é…åˆ°è¯­ä¹‰å¯¹é½çš„è·¨è¶Šï¼Œä¸ºé«˜æ•ˆã€å¯é çš„ LLM æ¨ç†æä¾›äº†æ–°èŒƒå¼ã€‚**

</details>

---

### 8. [NLI:Non-uniform Linear Interpolation Approximation of Nonlinear Operations for Efficient LLMs Inference](https://arxiv.org/abs/2602.02988)

**Authors**: Jiangyong Yu, Xiaomeng Han, Xing Hu, Chen Xu, Zhe Jiang, Dawei Yang  
**Category**: cs.LG  
**Published**: 2026-02-04  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2602.02988v1  

#### Abstract
Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of tasks, but their deployment is often constrained by substantial memory footprints and computational costs. While prior work has achieved significant progress in compressing and accelerating linear layers, no...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠNLI: Non-uniform Linear Interpolation Approximation of Nonlinear Operations for Efficient LLMs Inferenceã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨ç†è¿‡ç¨‹ä¸­é¢ä¸´å·¨å¤§çš„è®¡ç®—å¼€é”€å’Œå†…å­˜å¸¦å®½å‹åŠ›ï¼Œå°¤å…¶æ˜¯**éçº¿æ€§å±‚**ï¼ˆå¦‚ SiLUã€Softmaxã€RMSNormï¼‰ä»ä¾èµ–é«˜ç²¾åº¦æµ®ç‚¹è¿ç®—ï¼ˆå¦‚ FP32ï¼‰ï¼Œæˆä¸ºæ€§èƒ½ç“¶é¢ˆã€‚å°½ç®¡çº¿æ€§å±‚å·²é€šè¿‡é‡åŒ–ï¼ˆå¦‚ W8A8ï¼‰æ˜¾è‘—ä¼˜åŒ–ï¼Œä½†ç°æœ‰éçº¿æ€§å‡½æ•°è¿‘ä¼¼æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **è¾“å…¥èŒƒå›´å—é™**ï¼šä¾‹å¦‚ NN-LUT è®¾è®¡ä»…é€‚ç”¨äº `[-5,5]`ï¼Œè€Œ LLM ä¸­æ¿€æ´»å€¼å¸¸è¶…å‡º `Â±100`ï¼›
- **ä¾èµ–æ•°æ®æ ¡å‡†ï¼ˆcalibrationï¼‰**ï¼šæ³›åŒ–èƒ½åŠ›å·®ï¼Œåœ¨ä¸åŒæ¨¡å‹æˆ–å±‚é—´éš¾ä»¥å¤ç”¨ï¼›
- **ç¡¬ä»¶ä¸å‹å¥½**ï¼šéœ€è¦å¤§é‡æ¯”è¾ƒå™¨ï¼ˆcomparatorsï¼‰æˆ–å¤æ‚ç”µè·¯ï¼Œå½±å“æ•ˆç‡ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡º **Non-uniform Linear Interpolation (NLI)**ï¼Œä¸€ç§æ— éœ€æ ¡å‡†ã€åŠ¨æ€è§„åˆ’æœ€ä¼˜ä¸”ç¡¬ä»¶å‹å¥½çš„éçº¿æ€§å‡½æ•°è¿‘ä¼¼æ¡†æ¶ï¼ŒåŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼š

- **NLI-Algorithmï¼ˆè½¯ä»¶ç®—æ³•ï¼‰**  
  å°†åˆ‡ç‚¹ï¼ˆcutpointï¼‰é€‰æ‹©å»ºæ¨¡ä¸ºä¸€ä¸ª**åŠ¨æ€è§„åˆ’ï¼ˆDynamic Programmingï¼‰é—®é¢˜**ï¼ŒåŸºäº Bellman æœ€ä¼˜æ€§åŸç†ï¼Œåœ¨ FP16 åŸŸä¸Šå¯»æ‰¾å…¨å±€æœ€ä¼˜çš„éå‡åŒ€æ’å€¼èŠ‚ç‚¹ï¼Œæœ€å°åŒ–åŠ æ€§æ’å€¼è¯¯å·®ã€‚è¯¥æ–¹æ³•ä¸ä¾èµ–è®­ç»ƒæ•°æ®åˆ†å¸ƒï¼Œæ˜¯**å®Œå…¨æ— ç›‘ç£ã€å¯è·¨æ¨¡å‹å¤ç”¨**çš„æŸ¥æ‰¾è¡¨ï¼ˆLUTï¼‰ç”Ÿæˆæ–¹å¼ã€‚

- **NLI-Engineï¼ˆç¡¬ä»¶è®¾è®¡ï¼‰**  
  æ„å»ºäº†ä¸€ä¸ªå³æ’å³ç”¨çš„é€šç”¨éçº¿æ€§è®¡ç®—å•å…ƒï¼Œé‡‡ç”¨**ä¸¤çº§åœ°å€è½¬æ¢æœºåˆ¶**ï¼ˆtwo-level address translationï¼‰å’Œæµæ°´çº¿æ¶æ„ï¼Œå¤§å¹…å‡å°‘æ¯”è¾ƒå™¨æ•°é‡å¹¶æå‡ååé‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | NLI | NN-LUT / å…¶ä»–æ–¹æ³• |
|------|-----|------------------|
| **è¾“å…¥èŒƒå›´é€‚åº”æ€§** | æ”¯æŒ `[-150, 150]` è¶…å¤§èŒƒå›´ | é€šå¸¸é™äº `[-5,5]` æˆ– `[-10,10]` |
| **æ˜¯å¦éœ€æ ¡å‡†** | âŒ æ— éœ€æ•°æ®æ ¡å‡† | âœ… å¿…é¡»ä¾èµ–ç‰¹å®šæ•°æ®åˆ†å¸ƒè¿›è¡Œè®­ç»ƒ |
| **ç¡¬ä»¶æ•ˆç‡** | é«˜æ•ˆï¼šä»…éœ€ 10 ä¸ª comparator | ä½æ•ˆï¼šéœ€ 256+ ä¸ª comparator |
| **è¯¯å·®æ§åˆ¶** | åŠ¨æ€è§„åˆ’ä¿è¯å…¨å±€æœ€å°è¯¯å·® | å±€éƒ¨æ‹Ÿåˆï¼Œå¤–æ¨æ—¶è¯¯å·®çˆ†ç‚¸ |
| **é€šç”¨æ€§** | æ”¯æŒå¤šç§å‡½æ•°ï¼ˆexp, rsqrt, SiLU, tanh ç­‰ï¼‰ | å¤šä¸ºç‰¹å®šå‡½æ•°å®šåˆ¶ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **è¯­è¨€æ¨¡å‹ä»»åŠ¡**ï¼š
  - **Wikitext-2**ï¼šç”¨äºè¯„ä¼° Perplexityï¼ˆPPLï¼‰
  - **Zero-shot benchmark suite**ï¼šåŒ…æ‹¬ ARC-c/eã€BoolQã€PIQAã€HellaSwagã€OBQAã€LAMBADAã€SIQAã€WinoGrande
  - **ç»¼åˆèƒ½åŠ›åŸºå‡†**ï¼šMMLUï¼ˆå¤šå­¦ç§‘çŸ¥è¯†ï¼‰ã€GSM8kï¼ˆæ•°å­¦æ¨ç†ï¼‰ã€HumanEvalï¼ˆä»£ç ç”Ÿæˆï¼‰

- **è§†è§‰æ¨¡å‹éªŒè¯**ï¼ˆéªŒè¯æ³›åŒ–æ€§ï¼‰ï¼š
  - ViT-Smallã€DETRã€RT-DETR-Lã€YOLOv8-M

- **æµ‹è¯•æ¨¡å‹**ï¼š
  - LLMsï¼šLlama3-8B/70Bã€Qwen2.5-7B/32Bã€Qwen1.5-110Bã€Qwen3-8B/30B-A3B
  - Vision Modelsï¼šViTã€CNN-based detectors

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
| ç±»åˆ« | è®¾ç½®è¯´æ˜ |
|------|--------|
| **ç²¾åº¦è¯„ä¼°** | åœ¨ FP16 æ¨ç†ä¸‹æ›¿æ¢åŸç”Ÿéçº¿æ€§æ“ä½œï¼ŒæŠ¥å‘Šï¼š<br>â€¢ Perplexity â†“ï¼ˆè¶Šå°è¶Šå¥½ï¼‰<br>â€¢ å‡†ç¡®ç‡ â†‘ï¼ˆMMLU/GSM8k/HumanEval ç­‰ï¼‰ |
| **ç¡¬ä»¶è¯„ä¼°å¹³å°** | ä½¿ç”¨ **SMIC 28nm å·¥è‰ºåº“**ï¼Œé€šè¿‡ Design Compiler ç»¼åˆç”µè·¯ï¼Œè¯„ä¼°ï¼š<br>â€¢ Areaï¼ˆé¢ç§¯ï¼‰<br>â€¢ Powerï¼ˆåŠŸè€—ï¼‰<br>â€¢ Throughputï¼ˆååé‡ï¼‰<br>â€¢ Efficiency = Throughput / (Area Ã— Power) |
| **NLI å‚æ•°é…ç½®** | é‡‡ç”¨ `2 + 8Ã—32 + 1 = 259` cutpoints ç»“æ„ï¼š<br>â€¢ 10 ä¸ªå®åŒºé—´ï¼ˆmacro-intervalsï¼‰<br>â€¢ é¦–å°¾ä¸åˆ’åˆ†ï¼Œä¸­é—´ 8 ä¸ªå„åˆ† 32 å­æ®µ<br>â€¢ åˆ©ç”¨ DP ä»…ä¼˜åŒ– 11 ä¸ªå®ç«¯ç‚¹ï¼Œé™ä½æœç´¢æˆæœ¬ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **FP32**ï¼šå…¨ç²¾åº¦æµ®ç‚¹å®ç°ï¼Œä½œä¸ºé»„é‡‘æ ‡å‡†
- **NN-LUT**ï¼šåŸºäºç¥ç»ç½‘ç»œå­¦ä¹  LUT å‚æ•°çš„æ–¹æ³•ï¼ˆYu et al., 2022ï¼‰
- **RI-LUT**ï¼šRange-Invariant LUT æ–¹æ³•ï¼ˆKim et al., 2023ï¼‰
- **Uniform 259**ï¼šå‡åŒ€åˆ’åˆ†çš„çº¿æ€§æ’å€¼
- **Curvature 259**ï¼šæŒ‰æ›²ç‡å¯†åº¦é‡‡æ ·çš„éå‡åŒ€æ’å€¼

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ğŸ“Š è½¯ä»¶ç²¾åº¦è¡¨ç°ï¼ˆæ¥è‡ª Table 1 & Table 8ï¼‰
| æ¨¡å‹ | æ–¹æ³• | MMLU | GSM8k | HumanEval | PPL (Wikitext-2) |
|------|------|-------|--------|------------|------------------|
| Llama3-8B | FP32 | 62.16 | 50.19 | 35.37 | 6.14 |
| | NLI | **62.14** | **50.49** | **35.37** | **6.14** |
| | NN-LUT | 60.01 | 49.42 | 34.15 | 8.28 |
| Qwen2.5-7B | FP32 | 70.56 | 44.28 | 40.24 | 7.46 |
| | NLI | **70.67** | **43.97** | **39.63** | **7.46** |
| | NN-LUT | 25.51 | 0 | 0 | 28194 |

> âœ… **NLI åœ¨æ‰€æœ‰æ¨¡å‹ä¸Šå‡ ä¹å®Œå…¨ä¿æŒ FP32 ç²¾åº¦ï¼Œè€Œ NN-LUT åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå´©æºƒï¼ˆå¦‚ GSM8k å¾—åˆ†ä¸º 0ï¼‰**

#### ğŸ”§ ç¡¬ä»¶æ•ˆç‡è¡¨ç°ï¼ˆæ¥è‡ª Table 5 & Table 6ï¼‰
| æ¨¡å— | Area (Î¼mÂ²) | Power (mW) | Throughput | Efficiency |
|------|-----------|-----------|------------|------------|
| NN-LUT | 23,238 | 46 | 1G | 0.94 |
| RI-LUT | 23,647 | 48 | 1G | 0.88 |
| **NLI (Ours)** | **7,787** | **34** | **1G** | **3.78** |

> âœ… **NLI å®ç°äº†è¶…è¿‡ 4Ã— çš„æ•ˆç‡æå‡ï¼ˆvs NN-LUT æå‡ 4.02Ã—ï¼Œvs RI-LUT æå‡ 4.29Ã—ï¼‰**
>
> âœ… é¢ç§¯èŠ‚çœ **68â€“69%**ï¼ŒåŠŸè€—æ›´ä½ï¼Œå¾—ç›Šäºæ›´å°‘çš„ LUT å’Œ comparator

#### ğŸ“ˆ æ’å€¼è¯¯å·®åˆ†æï¼ˆæ¥è‡ª Figure 2 & Figure 3ï¼‰
- åœ¨ `[-150,150]` èŒƒå›´å†…ï¼ŒNLI å¯¹ SiLU çš„æœ€å¤§ç»å¯¹è¯¯å·® < `1.2Ã—10â»Â³`ï¼Œè¿œä½äº NN-LUT çš„â€œè¯¯å·®å°–å³°â€ç°è±¡
- å¯¹ expã€rsqrtã€gelu ç­‰å‡½æ•°ï¼ŒNLI è¿‘ä¼¼æ›²çº¿ä¸ FP32 å‚è€ƒé«˜åº¦é‡åˆï¼Œæœ€åæƒ…å†µè¯¯å·®æ§åˆ¶åœ¨ `1.5Ã—10â»Â³` å†…

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### è¡¨æ ¼ 2ï¼šä¸¤é˜¶æ®µç»“æ„ vs ä»…å®è§‚åˆ‡ç‚¹ï¼ˆMacro-onlyï¼‰
| æ–¹æ³• | Cutpoints | MMLU | GSM8k |
|------|----------|-------|--------|
| NLI (2+8Ã—32+1) | 259 | 70.67 | 43.97 |
| Macro-only (DP, M=11) | 11 | 21.14 | 0 |

> â— ä½¿ç”¨ä»… 11 ä¸ªåˆ‡ç‚¹æ— æ³•æ»¡è¶³ç²¾åº¦è¦æ±‚ï¼Œè¯æ˜å¾®åˆ†åŒºé—´çš„å¿…è¦æ€§

#### è¡¨æ ¼ 3ï¼šç›´æ¥æœç´¢ 259 ä¸ªéå‡åŒ€åˆ‡ç‚¹ vs NLI ä¸¤é˜¶æ®µè®¾è®¡
| æ–¹æ³• | Search Time (s) | MMLU | GSM8k |
|------|------------------|-------|--------|
| Direct DP (259) | ~17,000 | 70.65 | 44.08 |
| NLI (2+8Ã—32+1) | **610** | 70.67 | 43.97 |

> âœ… NLI çš„ä¸¤é˜¶æ®µè®¾è®¡å°†æœç´¢æ—¶é—´ä» **17,000 ç§’é™è‡³ 610 ç§’ï¼ˆå¿« 28Ã—ï¼‰**ï¼ŒåŒæ—¶ç²¾åº¦ç›¸å½“ï¼Œä¸”æ›´é€‚åˆç¡¬ä»¶éƒ¨ç½²

#### è¡¨æ ¼ 4ï¼šä¸å…¶ä»–å¯å‘å¼æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | MMLU | GSM8k |
|------|-------|--------|
| Uniform 259 | 29.1 | 18.13 |
| Curvature 259 | 65.74 | 32.58 |
| **NLI** | **70.65** | **43.97** |

> âœ… NLI æ˜¾è‘—ä¼˜äºå‡åŒ€åˆ’åˆ†å’ŒåŸºäºæ›²ç‡çš„åˆ’åˆ†ï¼Œè¯´æ˜å…¶åŠ¨æ€è§„åˆ’ç­–ç•¥çš„æœ‰æ•ˆæ€§

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **NLI å®ç°äº†é«˜ç²¾åº¦ä¸é«˜æ•ˆæ€§çš„ç»Ÿä¸€**ï¼š
   - åœ¨å¤šç§ LLM å’Œè§†è§‰æ¨¡å‹ä¸­ï¼Œ**æ›¿æ¢éçº¿æ€§å±‚åç²¾åº¦æ— æŸ**ï¼Œç”šè‡³ç•¥ä¼˜äº FP32ï¼ˆå¯èƒ½å› æ•°å€¼ç¨³å®šæ€§æ”¹å–„ï¼‰ã€‚
   - **æ— éœ€ä»»ä½•æ•°æ®æ ¡å‡†**å³å¯è·å¾—è·¨æ¨¡å‹ã€è·¨å±‚å¯ç”¨çš„ LUTï¼Œæå¤§å¢å¼ºäº†éƒ¨ç½²çµæ´»æ€§ã€‚

2. **åŠ¨æ€è§„åˆ’å¯ç”¨äºå…¨å±€æœ€ä¼˜åˆ‡ç‚¹æœç´¢**ï¼š
   - å°†æ’å€¼è¯¯å·®å»ºæ¨¡ä¸ºå¯åˆ†è§£çš„ç›®æ ‡å‡½æ•°ï¼Œåˆ©ç”¨ Bellman åŸç†æ±‚è§£ï¼Œé¦–æ¬¡å®ç°äº†**ç†è®ºæœ€ä¼˜çš„éå‡åŒ€çº¿æ€§æ’å€¼æ–¹æ¡ˆ**ã€‚

3. **è½¯ç¡¬ååŒè®¾è®¡å¤§å¹…æå‡æ•ˆç‡**ï¼š
   - ä¸¤çº§åœ°å€è½¬æ¢æœºåˆ¶å°† comparator æ•°é‡ä» 259 é™åˆ° 10ï¼Œç»“åˆé¢„åŠ è½½ scale factor å’Œæµæ°´çº¿ï¼Œä½¿ç¡¬ä»¶æ•ˆç‡æå‡ **4Ã— ä»¥ä¸Š**ã€‚

4. **æ”¯æŒå¹¿æ³›éçº¿æ€§å‡½æ•°**ï¼š
   - æˆåŠŸåº”ç”¨äº expã€rsqrtã€reciprocalã€SiLUã€GELUã€Sigmoidã€Tanhã€Mishã€HardSwish ç­‰å¸¸è§å‡½æ•°ï¼ˆè§ Appendix A.6ï¼‰ï¼Œå…·å¤‡å¼ºé€šç”¨æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **é™æ€ LUT**ï¼šå½“å‰ LUT æ˜¯ç¦»çº¿ç”Ÿæˆçš„ï¼Œä¸èƒ½è‡ªé€‚åº”å˜åŒ–çš„æ•°æ®åˆ†å¸ƒï¼ˆè™½ç„¶è¿™ä¸æ˜¯ç›®æ ‡ï¼‰ã€‚
- **å¯¹æç«¯ outlier çš„å¤„ç†ä¾èµ– clamp**ï¼šè™½ç„¶å®éªŒè¯æ˜å½±å“æå°ï¼ˆ<0.1% æ¿€æ´»å€¼è¢«æˆªæ–­ï¼‰ï¼Œä½†åœ¨æŸäº›ç‰¹æ®Šåœºæ™¯å¯èƒ½å­˜åœ¨é£é™©ã€‚
- **ç›®å‰ä»…é’ˆå¯¹å‰å‘æ¨ç†**ï¼šæœªæ¶‰åŠè®­ç»ƒé˜¶æ®µçš„åº”ç”¨ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **Transformer ä¸­å…¶ä»–å¤æ‚æ¨¡å—**ï¼ˆå¦‚ Attention softmax with maskï¼‰ï¼›
- æ¢ç´¢ **åŠ¨æ€æ›´æ–° LUT** çš„å¯èƒ½æ€§ä»¥åº”å¯¹åˆ†å¸ƒæ¼‚ç§»ï¼›
- å°† NLI é›†æˆè¿›ä¸»æµ NPU æ¶æ„ï¼ˆå¦‚ TPUã€NVDLAï¼‰ä½œä¸ºæ ‡å‡†éçº¿æ€§åŠ é€Ÿå•å…ƒï¼›
- æ¢ç´¢åœ¨ **ä½æ¯”ç‰¹é‡åŒ–è”åˆä¼˜åŒ–** ä¸­çš„ä½œç”¨ï¼ˆå¦‚ W4A4 åœºæ™¯ä¸‹çš„éçº¿æ€§è¡¥å¿ï¼‰ã€‚

---

> ğŸ’¡ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> NLI é€šè¿‡å°†éçº¿æ€§å‡½æ•°è¿‘ä¼¼è½¬åŒ–ä¸ºåŠ¨æ€è§„åˆ’é—®é¢˜ï¼Œæå‡ºäº†é¦–ä¸ªæ— éœ€æ ¡å‡†ã€å…¨å±€æœ€ä¼˜ä¸”é«˜åº¦ç¡¬ä»¶å‹å¥½çš„çº¿æ€§æ’å€¼æ¡†æ¶ï¼Œåœ¨ä¿æŒé›¶ç²¾åº¦æŸå¤±çš„åŒæ—¶ï¼Œå®ç°äº†è¶…è¿‡ **4Ã— çš„ç¡¬ä»¶æ•ˆç‡æå‡**ï¼Œä¸ºå¤§è§„æ¨¡æ¨¡å‹è¾¹ç¼˜éƒ¨ç½²æä¾›äº†å®ç”¨è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 9. [Position: Agentic Evolution is the Path to Evolving LLMs](https://arxiv.org/abs/2602.00359)

**Authors**: Minhua Lin, Hanqing Lu, Zhan Shi, Bing He, Rui Mao, Zhiwei Zhang, Zongyu Wu, Xianfeng Tang, Hui Liu, Zhenwei Dai, Xiang Zhang, Suhang Wang, Benoit Dumoulin, Jian Pei  
**Category**: cs.AI  
**Published**: 2026-02-04  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2602.00359v1  

#### Abstract
As Large Language Models (LLMs) move from curated training sets into open-ended real-world environments, a fundamental limitation emerges: static training cannot keep pace with continual deployment environment change. Scaling training-time and inference-time compute improves static capability but do...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**Position: Agentic Evolution is the Path to Evolving LLMs**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³äº†ä»€ä¹ˆé—®é¢˜

å½“å‰çš„ **Large Language Models (LLMs)** åœ¨éƒ¨ç½²åˆ°å¼€æ”¾ã€åŠ¨æ€çš„çœŸå®ä¸–ç•Œç¯å¢ƒæ—¶é¢ä¸´ä¸€ä¸ªæ ¹æœ¬æ€§ç“¶é¢ˆï¼š**train-deploy gap**ï¼ˆè®­ç»ƒ-éƒ¨ç½²ç¯å¢ƒå·®å¼‚ï¼‰ã€‚  
- é™æ€è®­ç»ƒæ— æ³•åº”å¯¹æŒç»­å˜åŒ–çš„ç°å®åœºæ™¯ï¼ˆå¦‚APIå˜æ›´ã€æ ¼å¼è¿ç§»ã€ç”¨æˆ·åé¦ˆç­‰ï¼‰ã€‚
- ç°æœ‰é€‚åº”æ–¹æ³•ï¼ˆå¦‚åœ¨çº¿å¾®è°ƒæˆ–è®°å¿†ç´¯ç§¯ï¼‰ç¼ºä¹**æˆ˜ç•¥æ€§ä»£ç†èƒ½åŠ›**ï¼ˆstrategic agencyï¼‰ï¼Œå¯¼è‡´æ”¹è¿›ä¸å¯é ã€ä¸å¯æŒç»­ã€‚

### âœ… æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯

æå‡º **Agentic Evolutionï¼ˆä»£ç†å¼è¿›åŒ–ï¼‰** èŒƒå¼ï¼Œå¹¶æ„å»ºé€šç”¨æ¡†æ¶ **A-Evolve**ï¼š

- å°†æ¨¡å‹åœ¨éƒ¨ç½²æœŸé—´çš„æŒç»­å­¦ä¹ è§†ä¸ºä¸€ä¸ª**ç›®æ ‡å¯¼å‘çš„è‡ªä¸»ä¼˜åŒ–è¿‡ç¨‹**ï¼Œè€Œéç®€å•çš„å‚æ•°æ›´æ–°æˆ–è®°å¿†å­˜å‚¨ã€‚
- å¼•å…¥ **Evolver Agent** â€”â€” ä¸€ä¸ªæ˜¾å¼çš„ã€å…·å¤‡å†³ç­–èƒ½åŠ›çš„â€œè¿›åŒ–å™¨â€ï¼Œè´Ÿè´£è¯Šæ–­å¤±è´¥ã€è§„åˆ’ä¿®å¤ã€æ‰§è¡Œæ›´æ–°å¹¶éªŒè¯æ•ˆæœã€‚
- æå‡º **Evolution-Scaling Hypothesisï¼ˆè¿›åŒ–å¯æ‰©å±•æ€§å‡è®¾ï¼‰**ï¼š  
  > æ¨¡å‹çš„é€‚åº”èƒ½åŠ›ï¼ˆadaptation capacityï¼‰éšç€åˆ†é…ç»™è¿›åŒ–è¿‡ç¨‹çš„ **evolution-time compute** å¢åŠ è€Œç³»ç»Ÿæ€§æå‡ï¼Œæ„æˆç»§ training-time å’Œ inference-time ä¹‹åçš„**ç¬¬ä¸‰æ¡å¯æ‰©å±•è½´**ã€‚

### âœ… ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹æ³•ç±»å‹ | å±€é™æ€§ | A-Evolve çš„ä¼˜åŠ¿ |
|--------|------|----------------|
| **Parametric Fine-tuning**ï¼ˆå¦‚ test-time trainingï¼‰ | æ˜“å¼•å‘ catastrophic forgettingï¼Œæ›´æ–°ä¸é€æ˜ï¼Œéš¾ä»¥æ²»ç† | æ›´æ–°ä½œç”¨äº**æ˜¾å¼ã€å¯å®¡è®¡çš„æŒä¹…åŒ–ç»„ä»¶**ï¼ˆå·¥å…·ã€çŸ¥è¯†ã€æµ‹è¯•ï¼‰ï¼Œé¿å…æƒé‡æ¼‚ç§» |
| **Heuristic Memory Accumulation**ï¼ˆå¦‚ AWMï¼‰ | å¯¼è‡´ context saturationï¼Œè®°å¿†å™ªå£°å¤§ï¼Œå¤ç”¨ç‡ä½ | é€šè¿‡ç»“æ„åŒ– artifactï¼ˆæ¨¡å—åŒ–å·¥å…·/æŠ€èƒ½ï¼‰å®ç°**èƒ½åŠ›å›ºåŒ–**ï¼Œæ”¯æŒå¤ç”¨ä¸ç»„åˆ |
| **Static Prompt Engineering**ï¼ˆå¦‚ APEï¼‰ | æ”¹è¿›ä¾èµ–è¡¨é¢æ¨¡å¼åŒ¹é…ï¼Œç¼ºä¹å› æœæ¨ç† | Evolver å…·å¤‡**goal-oriented diagnosis**ï¼Œèƒ½å®šä½æ ¹æœ¬åŸå› å¹¶ç”Ÿæˆé’ˆå¯¹æ€§ä¿®å¤ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†

- **AppWorld**ï¼ˆTrivedi et al., 2024ï¼‰ï¼š  
  - ä¸€ä¸ªé¢å‘äº¤äº’å¼ç¼–ç æ™ºèƒ½ä½“çš„å¯æ§ä»¿çœŸç¯å¢ƒã€‚
  - åŒ…å«çº¦ 9 ä¸ªæ—¥å¸¸åº”ç”¨ï¼ˆå¦‚ Amazonã€Spotifyã€Venmoï¼‰å’Œ 457 ä¸ª APIã€‚
  - æ¨¡æ‹ŸçœŸå®ç”¨æˆ·è¡Œä¸ºï¼Œä»»åŠ¡éœ€è·¨å¤šä¸ªåº”ç”¨è°ƒç”¨ APIï¼Œå…·æœ‰å¤æ‚ä¾èµ–å…³ç³»ã€‚
- å®éªŒåˆ’åˆ†ï¼š
  - **50 ä¸ªè®­ç»ƒä»»åŠ¡**ç”¨äºæ¼”åŒ–å­¦ä¹ 
  - **50 ä¸ªæµ‹è¯•ä»»åŠ¡**ç”¨äºè¯„ä¼°æ³›åŒ–èƒ½åŠ›ï¼ˆæ¥è‡ª `test-normal` åˆ†å‰²ï¼‰

### âš™ï¸ å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### æ¨¡å‹é…ç½®
- **Solver**ï¼ˆæ‰§è¡Œä»»åŠ¡çš„ä¸»ä½“ï¼‰ï¼šClaude Haiku 4.5, Sonnet 4.5, GPT-5, Gemini 3 Flash
- **Evolver**ï¼ˆè¿›åŒ–æ§åˆ¶å™¨ï¼‰ï¼šé»˜è®¤ä½¿ç”¨ Claude Sonnet 4.5ï¼Œéƒ¨åˆ†å®éªŒå¯¹æ¯”ä¸åŒè§„æ¨¡æ¨¡å‹ï¼ˆHaiku/Sonnet/Opusï¼‰

#### å›ºå®šé¢„ç®—æ§åˆ¶
- **Solve-time compute budget**ï¼šé™åˆ¶æ¯ä»»åŠ¡æœ€å¤§ tool callsã€steps æˆ– tokens
- **Evolve-time compute budget**ï¼šé™åˆ¶æ¯æ¬¡è¿›åŒ–æ­¥çš„ token æ•°å’Œ tool è°ƒç”¨æ•°ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒ

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ | è¯´æ˜ |
|------|------|------|
| **TGC (Task Goal Completion)** | æˆåŠŸå®Œæˆçš„ä»»åŠ¡æ¯”ä¾‹ï¼ˆæ‰€æœ‰å•å…ƒæµ‹è¯•é€šè¿‡ï¼‰ | è¡¡é‡æœ€ç»ˆæˆåŠŸç‡ |
| **APT (Average Passed Tests)** | å¹³å‡æ¯ä¸ªä»»åŠ¡é€šè¿‡çš„å•å…ƒæµ‹è¯•æ¯”ä¾‹ | è¡¡é‡æ¸è¿›å¼èƒ½åŠ›æå‡ï¼Œåæ˜ éƒ¨åˆ†æˆåŠŸ |

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”

| åŸºçº¿ | ç±»å‹ | æè¿° |
|------|------|------|
| **Vanilla** | æ— æ¼”åŒ– | ç›´æ¥è°ƒç”¨ solverï¼Œæ— ä»»ä½•æŒä¹…çŠ¶æ€æ›´æ–° |
| **APE** (Zhou et al., 2022) | éå‚æ•°å¯å‘å¼ | åŸºäºæœç´¢çš„ prompt è¿›åŒ–ï¼Œé€šè¿‡è¯„åˆ†é€‰æ‹©æœ€ä¼˜æŒ‡ä»¤ |
| **AWM** (Wang et al., 2024) | éå‚æ•°å¯å‘å¼ | ä»å†å²è½¨è¿¹ä¸­æå–å¯é‡ç”¨ workflow è®°å¿† |
| **A-Evolve**ï¼ˆæœ¬æ–‡ï¼‰ | Agentic Evolution | æ˜¾å¼ Evolver Agent æ‰§è¡Œè¯Šæ–­ â†’ è§„åˆ’ â†’ æ›´æ–° â†’ éªŒè¯é—­ç¯ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTab. 1ï¼‰

| Method | Claude Haiku 4.5 (TGC/APT) | Gemini 3 Flash (TGC/APT) |
|--------|----------------------------|--------------------------|
| Vanilla | 32 / 51.16 | 56 / 80.45 |
| APE     | 30 / 56.00 | 52 / 84.00 |
| AWM     | 46 / 65.76 | 52 / 87.75 |
| **A-Evolve** | **64 / 84.31** | **82 / 92.05** |

> âœ… **ç»“è®º**ï¼š
> - A-Evolve åœ¨æ‰€æœ‰ solver ä¸Šæ˜¾è‘—ä¼˜äºåŸºçº¿ï¼Œå°¤å…¶å¯¹å°æ¨¡å‹å¢ç›Šæ›´å¤§ï¼ˆHaiku æå‡ +32% TGCï¼‰ã€‚
> - **çª„å®¹é‡å·®è·**ï¼šA-Evolve + Haiku çš„è¡¨ç°ï¼ˆ64% TGCï¼‰è¶…è¿‡ Vanilla + Sonnetï¼ˆ42%ï¼‰ï¼Œè¡¨æ˜**ç¨‹åºæ€§èƒ½åŠ›ç§¯ç´¯å¯åª²ç¾æ›´å¼º backbone**ã€‚

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆFig. 3ï¼‰

å¯¹æ¯” A-Evolve çš„å››ä¸ªå˜ä½“ï¼ˆç§»é™¤æŸä¸€ç»„ä»¶ï¼‰ï¼š

| å˜ä½“ | ç§»é™¤ç»„ä»¶ | å½±å“ |
|------|--------|------|
| **A-Evolve/D** | Diagnosis | ç¼ºä¹æ ¹å› åˆ†æï¼Œä»…åšè¡¨é¢ä¿®è¡¥ï¼Œæ€§èƒ½ä¸‹é™æ˜æ˜¾ |
| **A-Evolve/A** | Analysis Tools | æ— æ³•è·¨ episode å‘ç°å…±æ€§æ¨¡å¼ï¼Œæ”¹è¿›é›¶æ•£ |
| **A-Evolve/P** | Planning | æ— æ³•åè°ƒå¤š artifact æ›´æ–°ï¼ˆå¦‚æ”¹ tool ä¸æ”¹ schemaï¼‰ï¼Œå¯¼è‡´é€»è¾‘æ–­è£‚ |
| **A-Evolve/V** | Verification | æœ€ä¸¥é‡é€€åŒ–ï¼æäº¤ç¼ºé™· artifactï¼ˆè¯­æ³•é”™è¯¯ã€è¿è¡Œå´©æºƒï¼‰ï¼Œæ±¡æŸ“ä¸Šä¸‹æ–‡ï¼Œå¼•å‘å›å½’ |

> âœ… **å…³é”®å‘ç°**ï¼š  
> - **Verification æ˜¯ç¨³å®šæ€§å…³é”®**ï¼Œé˜²æ­¢æœ‰å®³æ›´æ–°æ‰©æ•£ã€‚
> - å››ä¸ªæ¨¡å—å½¢æˆ**ä¸å¯åˆ†å‰²çš„é—­ç¯**ï¼Œç¼ºä¸€ä¸å¯ã€‚

### ğŸ“ˆ è¿›åŒ–å¯æ‰©å±•æ€§åˆ†æï¼ˆFig. 4ï¼‰

#### ï¼ˆaï¼‰å¢åŠ  **evolution step**ï¼ˆå³ $ C_{\text{evolve}} $ï¼‰
- A-Evolve æ€§èƒ½éšè®¡ç®—èµ„æºå•è°ƒä¸Šå‡ï¼Œæœªè§é¥±å’Œã€‚
- AWM å¾ˆå¿«è¾¾åˆ°å¹³å°æœŸï¼Œæ˜¾ç¤ºå…¶**å¯å‘å¼æ–¹æ³•ä¸å…·å¤‡å¯æ‰©å±•æ€§**ã€‚

#### ï¼ˆbï¼‰å¢å¤§ **evolver æ¨¡å‹å°ºå¯¸**
- ä½¿ç”¨æ›´å¤§çš„ evolverï¼ˆHaiku â†’ Sonnet â†’ Opusï¼‰å¸¦æ¥æŒç»­æ€§èƒ½æå‡ã€‚
- æ›´å¤§çš„ evolver èƒ½æ›´å‡†ç¡®è¯Šæ–­ã€ç”Ÿæˆæ›´é²æ£’ artifactï¼Œå‡å°‘éªŒè¯å¤±è´¥ã€‚

> âœ… æ”¯æŒ **Evolution-Scaling Hypothesis**ï¼š  
> åˆ†é…æ›´å¤š compute ç»™ evolution è¿‡ç¨‹ï¼Œç¡®å®èƒ½ç³»ç»Ÿæ€§æé«˜é€‚åº”ä¸Šé™ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦ç»“è®º

1. **Agentic Evolution æ˜¯è§£å†³ train-deploy gap çš„å¿…ç„¶è·¯å¾„**ï¼š
   - å¿…é¡»å°†è¿›åŒ–æœ¬èº«è§†ä¸ºä¸€ä¸ª**ç”±ç›®æ ‡é©±åŠ¨çš„è‡ªä¸»å†³ç­–è¿‡ç¨‹**ï¼Œè€Œéæœºæ¢°æµæ°´çº¿ã€‚

2. **A-Evolve æ¡†æ¶æœ‰æ•ˆå®ç°äº† agentic evolution**ï¼š
   - é€šè¿‡ **persistent artifact state**ï¼ˆçŸ¥è¯† Kã€å·¥å…· Tã€éªŒè¯ Vï¼‰æš´éœ²å¯ç¼–è¾‘æ¥å£ã€‚
   - é€šè¿‡ **solve-evolve loop** åˆ†ç¦»ä»»åŠ¡æ‰§è¡Œä¸èƒ½åŠ›è¿›åŒ–ã€‚
   - é€šè¿‡ **explicit evolver agent** å®ç°è¯Šæ–­ã€è§„åˆ’ã€æ›´æ–°ã€éªŒè¯çš„é—­ç¯æ²»ç†ã€‚

3. **è¿›åŒ–æ˜¯å¯æ‰©å±•çš„**ï¼ˆEvolution-Scaling Hypothesisï¼‰ï¼š
   - é€‚åº”èƒ½åŠ›éš $ C_{\text{evolve}} $ å¢åŠ è€Œæå‡ï¼Œæ„æˆæ–°çš„ scaling axisã€‚
   - æŠ•èµ„äºâ€œæ›´å¥½åœ°è¿›åŒ–â€æ¯”åå¤â€œæ›´åŠªåŠ›æ€è€ƒâ€æ›´å…·é•¿æœŸæ•ˆç›Šã€‚

4. **å°æ¨¡å‹ + æŒç»­è¿›åŒ– â‰ˆ å¤§æ¨¡å‹**ï¼š
   - ç¨‹åºæ€§èƒ½åŠ›çš„ç§¯ç´¯å¯ä»¥å¼¥è¡¥é™æ€æ¨¡å‹å®¹é‡ä¸è¶³ï¼Œä¸ºä½æˆæœ¬éƒ¨ç½²æä¾›å¯èƒ½ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

- **Compute å¼€é”€è¾ƒé«˜**ï¼šç»´æŠ¤ evolver agent éœ€é¢å¤–æ¨ç†æˆæœ¬ï¼ŒçŸ­æœŸæ•ˆç‡ä½äºç®€å•å¯å‘å¼ã€‚
- **Artifact è®¾è®¡ä¾èµ–å·¥ç¨‹ç»éªŒ**ï¼šå¦‚ä½•å®šä¹‰è‰¯å¥½çš„å·¥å…·/çŸ¥è¯†/éªŒè¯ç»“æ„ä»éœ€äººå·¥è®¾è®¡ã€‚
- **å½“å‰éªŒè¯æœºåˆ¶æœ‰é™**ï¼šä¸»è¦ä¾èµ– unit test å’Œ syntax checkï¼Œå¯¹è¯­ä¹‰æ­£ç¡®æ€§ä¿éšœä¸è¶³ã€‚
- **å°šæœªå¤„ç†å¤š agent ååŒæ¼”åŒ–**ï¼šç›®å‰èšç„¦å• agent åœºæ™¯ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **Benchmarking**ï¼š
   - æ„å»ºä¸“é—¨è¡¡é‡â€œæ¼”åŒ–èƒ½åŠ›â€çš„åŸºå‡†ï¼Œå¼ºè°ƒ**artifact çš„æŒä¹…æ€§ã€å¤ç”¨æ€§å’ŒæŠ—å¹²æ‰°æ€§**ã€‚

2. **Framework æ”¹è¿›**ï¼š
   - æå‡ diagnosisã€planningã€verification æ¨¡å—çš„èƒ½åŠ›ï¼Œä½¿å…¶æ›´é«˜æ•ˆé€¼è¿‘ compute-optimal frontierã€‚

3. **ç†è®ºå»ºæ¨¡**ï¼š
   - å»ºç«‹ agentic evolution çš„å½¢å¼åŒ–ç†è®ºï¼Œä¾‹å¦‚å°†å…¶å»ºæ¨¡ä¸ºç»„åˆç¨‹åºç©ºé—´ä¸Šçš„ä¼˜åŒ–é—®é¢˜ã€‚
   - è¯æ˜å…¶ç›¸å¯¹äºéä»£ç†æ–¹æ³•çš„ä¼˜è¶Šæ€§ï¼ˆseparation resultsï¼‰ã€‚

4. **å®‰å…¨ä¸å¯¹é½æœºåˆ¶å¼ºåŒ–**ï¼š
   - å‘å±•æ›´ä¸¥æ ¼çš„ validation gatesï¼ˆå¦‚å½¢å¼åŒ–éªŒè¯ã€äººç±»-in-the-loop å®¡æ ¸ï¼‰ã€‚
   - é˜²æ­¢ capability drift å’Œç›®æ ‡é”™ä½ï¼ˆmisalignmentï¼‰ã€‚

---

> ğŸ’¬ **Impact Statement ç²¾è¦**ï¼š
> - **éšç§å‹å¥½**ï¼šæœ¬åœ°æ¼”åŒ–å‡å°‘æ•æ„Ÿæ•°æ®ä¸Šä¼ ã€‚
> - **å¯æŒç»­ AI**ï¼šå°†æ˜‚è´µçš„æ¨ç†è½¬åŒ–ä¸ºå¯å¤ç”¨çš„å·¥å…·ï¼Œé™ä½é•¿æœŸéƒ¨ç½²æˆæœ¬ã€‚
> - **é£é™©å¯æ§**ï¼šæ˜¾å¼ artifact + éªŒè¯é—¨æ§ï¼Œä¿è¯å¯å®¡è®¡ã€å¯å›æ»šã€‚

</details>

---

### 10. [Lyapunov Stability-Aware Stackelberg Game for Low-Altitude Economy: A Control-Oriented Pruning-Based DRL Approach](https://arxiv.org/abs/2602.01131)

**Authors**: Yue Zhong, Jiawen Kang, Yongju Tong, Hong-Ning Dai, Dong In Kim, Abbas Jamalipour, Shengli Xie  
**Category**: cs.AI  
**Published**: 2026-02-04  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2602.01131v1  

#### Abstract
With the rapid expansion of the low-altitude economy, Unmanned Aerial Vehicles (UAVs) serve as pivotal aerial base stations supporting diverse services from users, ranging from latency-sensitive critical missions to bandwidth-intensive data streaming. However, the efficacy of such heterogeneous netw...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Lyapunov Stability-Aware Stackelberg Game for Low-Altitude Economy: A Control-Oriented Pruning-Based DRL Approach*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡é’ˆå¯¹**ä½ç©ºç»æµ**ï¼ˆLow-Altitude Economy, LAEï¼‰ä¸­æ— äººæœº**ï¼ˆUAVï¼‰**ä½œä¸ºç©ºä¸­åŸºç«™æ—¶é¢ä¸´çš„èµ„æºåˆ†é…ä¸æ§åˆ¶ç¨³å®šæ€§ä¹‹é—´çš„çŸ›ç›¾é—®é¢˜ã€‚ä¼ ç»Ÿç½‘ç»œè®¾è®¡é€šå¸¸ä»¥ååé‡ä¸ºä¸­å¿ƒï¼Œå¿½ç•¥äº†é€šä¿¡å»¶è¿Ÿå¯¹ç‰©ç†æ§åˆ¶ç³»ç»Ÿç¨³å®šæ€§çš„ç›´æ¥å½±å“ã€‚åœ¨ç¾åæ•‘æ´ç­‰å®‰å…¨å…³é”®ä»»åŠ¡ä¸­ï¼ŒUAVéœ€åŒæ—¶æ”¯æŒé«˜å¸¦å®½æµåª’ä½“å’Œè¶…å¯é ä½å»¶è¿Ÿæ§åˆ¶ä¿¡å·ï¼Œè€Œæœ‰é™çš„**bandwidth**å’Œ**energy**èµ„æºå¯¼è‡´é€šä¿¡å»¶è¿Ÿï¼Œè¿›è€Œç ´å**networked control system**çš„ç¨³å®šæ€§ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

è®ºæ–‡æå‡ºäº†ä¸€å¥—å…¨æ–°çš„**æ§åˆ¶å¯¼å‘**ï¼ˆcontrol-orientedï¼‰èµ„æºç®¡ç†æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°ç‚¹å¦‚ä¸‹ï¼š

- **æ„å»ºäº†SCÂ³é—­ç¯ç³»ç»Ÿæ¨¡å‹**ï¼ˆSensing-Communication-Computing-Controlï¼‰  
  å°†UAVä¸ç”¨æˆ·çš„äº¤äº’å»ºæ¨¡ä¸ºä¸€ä¸ªå®Œæ•´çš„é—­ç¯åé¦ˆç³»ç»Ÿï¼Œæ˜ç¡®é‡åŒ–äº†**end-to-end latency**å¯¹æ§åˆ¶æ€§èƒ½çš„å½±å“ã€‚

- **å¼•å…¥Lyapunovç¨³å®šæ€§ç†è®ºè¿›è¡Œè·¨åŸŸçº¦æŸè½¬æ¢**  
  åˆ©ç”¨**Lyapunov stability theory**å°†æŠ½è±¡çš„ç‰©ç†æ§åˆ¶ç¨³å®šæ€§è¦æ±‚è½¬åŒ–ä¸ºå¯é‡åŒ–çš„**communication latencyè¾¹ç•Œ**ï¼Œå®ç°äº†ä»â€œæ§åˆ¶éœ€æ±‚â€åˆ°â€œé€šä¿¡èµ„æºâ€çš„æ˜ å°„ã€‚

- **è®¾è®¡äº†åŸºäºStackelbergåšå¼ˆçš„èµ„æºåˆ†é…æœºåˆ¶**  
  æ„å»ºäº†ä¸€ä¸ª**Stackelberg game**ï¼Œå…¶ä¸­UAVä½œä¸º**leader**åŠ¨æ€å®šä»·ä»¥è°ƒèŠ‚è´Ÿè½½å¹¶ä¿éšœç³»ç»Ÿç¨³å®šï¼Œç”¨æˆ·ä½œä¸º**follower**æ ¹æ®æœåŠ¡ç´§æ€¥ç¨‹åº¦ä¼˜åŒ–å¸¦å®½è¯·æ±‚ï¼Œå®ç°æ¿€åŠ±ç›¸å®¹çš„åˆ†å¸ƒå¼å†³ç­–ã€‚

- **æå‡ºè½»é‡çº§Pruning-based PPOç®—æ³•**  
  é’ˆå¯¹æ ‡å‡†**Deep Reinforcement Learning**ï¼ˆDRLï¼‰åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šè®¡ç®—å¼€é”€è¿‡å¤§çš„é—®é¢˜ï¼Œæå‡ºä¸€ç§ç»“åˆ**dynamic structured pruning**çš„**Proximal Policy Optimization**ï¼ˆPPOï¼‰ç®—æ³•ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€å‰ªæå†—ä½™ç¥ç»å…ƒï¼Œæ˜¾è‘—å‹ç¼©æ¨¡å‹è§„æ¨¡ï¼Œé™ä½æ¨ç†å»¶è¿Ÿå’Œèƒ½è€—ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| å¯¹æ¯”ç»´åº¦ | ç°æœ‰æ–¹æ³• | æœ¬æ–‡æ–¹æ³• |
|--------|--------|--------|
| **ç³»ç»Ÿè§†è§’** | é€šä¿¡ä¸æ§åˆ¶è§£è€¦ | SCÂ³é—­ç¯èåˆï¼Œè”åˆä¼˜åŒ– |
| **ç¨³å®šæ€§ä¿éšœ** | æ— æ˜¾å¼å»ºæ¨¡æˆ–ä»…ç»éªŒæ€§å¤„ç† | åŸºäºLyapunovç†è®ºçš„ä¸¥æ ¼æ•°å­¦ä¿è¯ |
| **æ¿€åŠ±æœºåˆ¶** | åŸºäºæ•ˆç”¨æˆ–AoIä¼˜åŒ– | ä»·æ ¼é©±åŠ¨ï¼Œå…¼é¡¾ç´§æ€¥åº¦ä¸ç¨³å®šæ€§ |
| **ç®—æ³•éƒ¨ç½²å¯è¡Œæ€§** | é‡å‹DRLéš¾ä»¥éƒ¨ç½²äºUAV | è½»é‡åŒ–pruning-based PPOï¼Œé€‚åˆè¾¹ç¼˜æ‰§è¡Œ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

è®ºæ–‡æœªä½¿ç”¨å…¬å¼€çœŸå®æ•°æ®é›†ï¼Œè€Œæ˜¯åŸºäºå…¸å‹LAEåœºæ™¯è¿›è¡Œ**ä»¿çœŸå»ºæ¨¡**ï¼Œå‚æ•°è®¾å®šå‚è€ƒäº†ç›¸å…³æ–‡çŒ®ï¼ˆå¦‚[8][44]ï¼‰ï¼Œæ¨¡æ‹Ÿç¾ååº”æ€¥å“åº”ç¯å¢ƒä¸‹çš„å¤šUAVå¤šç”¨æˆ·ååŒã€‚

### **å®éªŒè®¾ç½®**

- **åœºæ™¯é…ç½®**ï¼š
  - UAVæ•°é‡ï¼š3 æˆ– å¯å˜ï¼ˆ3â€“12ï¼‰
  - ç”¨æˆ·æ•°é‡ï¼š5 æˆ– å¯å˜ï¼ˆ5â€“20ï¼‰
  - éƒ¨ç½²åŒºåŸŸï¼šäºŒç»´å¹³é¢ï¼ŒUAVå›ºå®šé«˜åº¦é£è¡Œ
  - ä¿¡é“æ¨¡å‹ï¼šè‡ªç”±ç©ºé—´è·¯å¾„æŸè€—ï¼ˆFree-space path lossï¼‰
- **å…³é”®å‚æ•°**ï¼ˆè§Table Iï¼‰ï¼š
  - é‡‡æ ·å‘¨æœŸ $ \epsilon_n = 0.5s $
  - æ§åˆ¶æ—¶é—´å¸¸æ•° $ \tau_n = 0.005s $
  - Lyapunovè¡°å‡é€Ÿç‡ $ \rho_n = 0.95 $
  - æ€»å¸¦å®½ $ K_{\text{total}} \in [15, 25]\,\text{MHz} $
  - ç”¨æˆ·æ•°æ®åŒ…å¤§å° $ S_i \in [40, 64]\,\text{kbits} $

### **è¯„ä¼°æŒ‡æ ‡**

- **Test Reward**ï¼šUAVè·å¾—çš„å¹³å‡æ•ˆç”¨ï¼ˆUtilityï¼‰
- **Bandwidth Allocation Composition**ï¼šåŒºåˆ†ç”¨äºæ»¡è¶³ç¨³å®šæ€§æœ€ä½è¦æ±‚ä¸é¢å¤–æ•ˆç”¨æå‡çš„å¸¦å®½
- **Pricing & Request Strategies Evolution**ï¼šç­–ç•¥æ”¶æ•›è¿‡ç¨‹å¯è§†åŒ–
- **ç®—æ³•å¤æ‚åº¦ä¸æ¨ç†å»¶è¿Ÿ**ï¼šé€šè¿‡æ¨¡å‹å‹ç¼©ç‡é—´æ¥ä½“ç°

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

- **Standard PPO**ï¼šæœªå‰ªæçš„æ ‡å‡†å¤šæ™ºèƒ½ä½“PPOç®—æ³•
- **Greedy Algorithm**ï¼šè´ªå¿ƒç­–ç•¥ï¼Œä¼˜å…ˆæœåŠ¡ä¿¡é“è´¨é‡å¥½æˆ–ç´§æ€¥åº¦é«˜çš„ç”¨æˆ·
- **Random Algorithm**ï¼šéšæœºåˆ†é…èµ„æº

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”ç»“æœ**

#### âœ… **å­¦ä¹ æ•ˆç‡ä¸æœ€ç»ˆæ€§èƒ½**
- **å›¾3**æ˜¾ç¤ºï¼Œ**Pruning-based PPO**ä¸ä»…æ”¶æ•›é€Ÿåº¦æ›´å¿«ï¼Œä¸”æœ€ç»ˆ**test reward**é«˜äºæ ‡å‡†PPOï¼ˆçº¦é«˜å‡º10â€“15%ï¼‰ï¼Œè¡¨æ˜å‰ªæèµ·åˆ°äº†æ­£åˆ™åŒ–ä½œç”¨ï¼Œç¼“è§£è¿‡æ‹Ÿåˆã€‚
- ç›¸æ¯”ä¹‹ä¸‹ï¼ŒGreedyå’ŒRandomç®—æ³•æ€§èƒ½è¿œä½äºæ‰€æœ‰DRLæ–¹æ³•ã€‚

#### âœ… **ç­–ç•¥æ¼”åŒ–ä¸å‡è¡¡è¾¾æˆ**
- **å›¾5**å±•ç¤ºäº†UAVå®šä»·ç­–ç•¥ä¸ç”¨æˆ·å¸¦å®½è¯·æ±‚éšè¿­ä»£é€æ­¥æ”¶æ•›çš„è¿‡ç¨‹ï¼ŒéªŒè¯äº†ç³»ç»Ÿè¾¾åˆ°**Stackelberg Equilibrium**ã€‚
- å®šä»·åˆæœŸæ³¢åŠ¨å¤§ï¼ŒåæœŸè¶‹äºç¨³å®šï¼›ç”¨æˆ·æ ¹æ®ä»·æ ¼å’Œè‡ªèº«æƒé‡è‡ªé€‚åº”è°ƒæ•´è¯·æ±‚ã€‚

#### âœ… **ä¸åŒç½‘ç»œè§„æ¨¡ä¸‹çš„æ³›åŒ–èƒ½åŠ›**
- **å›¾6(a)**ï¼šå½“UAVæ•°é‡å›ºå®šä¸º3æ—¶ï¼Œéšç€ç”¨æˆ·æ•°å¢åŠ ï¼ˆ5â†’20ï¼‰ï¼ŒUAVæ€»æ”¶ç›Šæ˜¾è‘—ä¸Šå‡ï¼Œè¯´æ˜æœºåˆ¶èƒ½æœ‰æ•ˆæ¿€åŠ±æœåŠ¡æ›´å¤šç”¨æˆ·ã€‚
- **å›¾6(b)**ï¼šå½“ç”¨æˆ·æ•°å›ºå®šä¸º15æ—¶ï¼Œéšç€UAVæ•°é‡å¢åŠ ï¼ˆ3â†’12ï¼‰ï¼Œ**å•ä¸ªUAVå¹³å‡rewardä¸‹é™**ï¼Œåæ˜ å¸‚åœºé¥±å’Œæ•ˆåº”ï¼Œç¬¦åˆç»æµå­¦ç›´è§‰ã€‚

#### âœ… **èµ„æºåˆ†é…åˆç†æ€§åˆ†æ**
- **å›¾2(d)/(h)** æ˜¾ç¤ºï¼Œæ‰€æœ‰ç”¨æˆ·å®é™…åˆ†é…çš„å¸¦å®½å‡**ä¸¥æ ¼è¶…è¿‡ç”±Lyapunovæ¨å¯¼å‡ºçš„æœ€å°éœ€æ±‚**ï¼ˆMin Requirementï¼‰ï¼Œè¯æ˜ç¨³å®šæ€§çº¦æŸè¢«æœ‰æ•ˆæ‰§è¡Œã€‚
- å¸¦å®½åˆ†é…ä¸**SNR**å’Œ**urgency weight**å‘ˆå¼ºæ­£ç›¸å…³ï¼Œé«˜ä¼˜å…ˆçº§æˆ–ä¿¡é“å¥½çš„ç”¨æˆ·è·å¾—æ›´å¤šèµ„æºã€‚

### **æ¶ˆèå®éªŒç»“æœ**

- **å›¾4**ç ”ç©¶äº†**pruning start epoch**ï¼ˆ$ t_0 $ï¼‰çš„å½±å“ï¼š
  - $ t_0 = 50 $ï¼ˆæ—©å‰ªæï¼‰ï¼šæ€§èƒ½æœ€ä¼˜ï¼Œè¯´æ˜æ—©æœŸç»“æ„å¹²é¢„æœ‰åŠ©äºç­–ç•¥ä¸ç¨€ç–æ‹“æ‰‘å…±åŒæ¼”åŒ–ã€‚
  - $ t_0 = 300 $ï¼ˆæ™šå‰ªæï¼‰ï¼šæ¬¡ä¼˜ï¼Œä¿ç•™äº†å¯†é›†è®­ç»ƒé˜¶æ®µçš„è‰¯å¥½è¡¨å¾ã€‚
  - $ t_0 = 200 $ï¼ˆä¸­æœŸå‰ªæï¼‰ï¼šè¡¨ç°æœ€å·®ï¼Œå¹²æ‰°äº†å…³é”®å­¦ä¹ é˜¶æ®µçš„ç­–ç•¥å½¢æˆã€‚
- ç»“è®ºï¼š**early pruning is beneficial**ï¼Œæ”¯æŒæ‰€æåŠ¨æ€å‰ªææœºåˆ¶çš„è®¾è®¡ç†å¿µã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **æ§åˆ¶-é€šä¿¡è”åˆè®¾è®¡è‡³å…³é‡è¦**ï¼šå•çº¯ä¼˜åŒ–é€šä¿¡æ€§èƒ½æ— æ³•ä¿éšœLAEä¸­å®‰å…¨å…³é”®ä»»åŠ¡çš„å¯é æ€§ï¼Œå¿…é¡»å°†**control stability**çº³å…¥èµ„æºåˆ†é…å†³ç­–ã€‚
2. **Lyapunovç†è®ºå¯æœ‰æ•ˆæ¡¥æ¥ç‰©ç†å±‚ä¸é€»è¾‘å±‚**ï¼šé€šè¿‡å»ºç«‹**control-to-communication mapping**ï¼Œå¯å°†ç¨³å®šæ€§è¦æ±‚è½¬åŒ–ä¸ºç¡¬æ€§é€šä¿¡çº¦æŸï¼ŒæŒ‡å¯¼èµ„æºåˆ†é…ã€‚
3. **Stackelbergåšå¼ˆæ˜¯åˆé€‚çš„å»ºæ¨¡èŒƒå¼**ï¼šèƒ½å¤Ÿè‡ªç„¶å»ºæ¨¡UAVä¸ç”¨æˆ·é—´çš„é¢†å¯¼-è·Ÿéšå…³ç³»ï¼Œå¹¶é€šè¿‡ä»·æ ¼æœºåˆ¶å®ç°è´Ÿè½½å‡è¡¡ä¸æ¿€åŠ±å…¼å®¹ã€‚
4. **è½»é‡åŒ–DRLå¯è¡Œä¸”å¿…è¦**ï¼šæå‡ºçš„**pruning-based PPO**åœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹å¤§å¹…é™ä½æ¨¡å‹å¤æ‚åº¦ï¼Œä½¿å®æ—¶åœ¨çº¿å­¦ä¹ æˆä¸ºå¯èƒ½ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**

- **ä¾èµ–çº¿æ€§æ§åˆ¶æ¨¡å‹å‡è®¾**ï¼šå½“å‰Lyapunovåˆ†æåŸºäºçº¿æ€§æ—¶ä¸å˜ç³»ç»Ÿï¼ˆLTIï¼‰ï¼Œå¯¹éçº¿æ€§æˆ–å¼ºæ‰°åŠ¨åœºæ™¯é€‚ç”¨æ€§æœ‰å¾…éªŒè¯ã€‚
- **é›†ä¸­å¼è®­ç»ƒã€åˆ†å¸ƒå¼æ‰§è¡Œ**ï¼šè™½é€‚ç”¨äºå°è§„æ¨¡UAVç¾¤ï¼Œä½†åœ¨å¤§è§„æ¨¡ç½‘ç»œä¸­ä»é¢ä¸´å¯æ‰©å±•æ€§æŒ‘æˆ˜ã€‚
- **ä»¿çœŸç¯å¢ƒç†æƒ³åŒ–**ï¼šæœªè€ƒè™‘æç«¯å¤©æ°”ã€ç§»åŠ¨éšœç¢ç‰©ã€æ¶æ„æ”»å‡»ç­‰ç°å®å› ç´ ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**

- ç ”ç©¶**èƒ½é‡ä¸æ—¶å˜å¸¦å®½è”åˆæ³¢åŠ¨**ä¸‹çš„å¤åˆç«¯åˆ°ç«¯å»¶è¿Ÿå»ºæ¨¡ã€‚
- æ¢ç´¢**åŒå‘æ§åˆ¶-é€šä¿¡ååŒè®¾è®¡**æœºåˆ¶ï¼Œå®ç°æ›´æ·±å±‚æ¬¡çš„ç³»ç»Ÿèåˆã€‚
- æ‰©å±•è‡³**multi-leader multi-follower Stackelberg game**ï¼Œæ”¯æŒæ›´å¤æ‚çš„UAVåä½œæ¶æ„ã€‚
- å¼•å…¥**federated learning**æˆ–**decentralized MARL**ä»¥å¢å¼ºéšç§ä¿æŠ¤ä¸å¯æ‰©å±•æ€§ã€‚

--- 

> **æ€»ç»“ä¸€å¥è¯**ï¼šæœ¬æ–‡å¼€åˆ›æ€§åœ°å°†**Lyapunovç¨³å®šæ€§ç†è®º**èå…¥**Stackelbergåšå¼ˆ**æ¡†æ¶ï¼Œå¹¶é€šè¿‡**pruning-based DRL**å®ç°é«˜æ•ˆæ±‚è§£ï¼Œåœ¨ä¿éšœUAVæ§åˆ¶ç¨³å®šçš„å‰æä¸‹æœ€å¤§åŒ–ç³»ç»Ÿæ•ˆç”¨ï¼Œä¸ºä½ç©ºç»æµä¸­çš„èµ„æºç®¡ç†æä¾›äº†å…¼å…·ç†è®ºä¸¥è°¨æ€§ä¸å·¥ç¨‹å®ç”¨æ€§çš„è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 11. [ForesightKV: Optimizing KV Cache Eviction for Reasoning Models by Learning Long-Term Contribution](https://arxiv.org/abs/2602.03203)

**Authors**: Zican Dong, Peiyu Liu, Junyi Li, Zhipeng Chen, Han Peng, Shuo Wang, Wayne Xin Zhao  
**Category**: cs.CL  
**Published**: 2026-02-04  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2602.03203v1  

#### Abstract
Recently, large language models (LLMs) have shown remarkable reasoning abilities by producing long reasoning traces. However, as the sequence length grows, the key-value (KV) cache expands linearly, incurring significant memory and computation costs. Existing KV cache eviction methods mitigate this ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šForesightKV: Optimizing KV Cache Eviction for Reasoning Models by Learning Long-Term Contribution**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œå°¤å…¶æ˜¯å…·å¤‡å¤æ‚æ¨ç†èƒ½åŠ›çš„**reasoning models**ï¼Œåœ¨ç”Ÿæˆé•¿æ–‡æœ¬æ¨ç†é“¾æ—¶ä¼šäº§ç”Ÿæé•¿çš„åºåˆ—ã€‚è¿™å¯¼è‡´å…¶å†…éƒ¨ç»´æŠ¤çš„ **Key-Value (KV) Cache** å¤§å°éšåºåˆ—é•¿åº¦çº¿æ€§å¢é•¿ï¼Œå¸¦æ¥æ˜¾è‘—çš„å†…å­˜å¼€é”€å’Œè®¡ç®—å»¶è¿Ÿï¼Œä¸¥é‡é™åˆ¶äº†å¹¶å‘èƒ½åŠ›å’Œæ¨ç†æ•ˆç‡ã€‚

ç°æœ‰çš„ KV Cache å‹ç¼©æˆ–é©±é€æ–¹æ³•ï¼ˆå¦‚ SnapKVã€H2Oã€R-KVï¼‰é€šå¸¸åŸºäºå¯å‘å¼è§„åˆ™ï¼ˆå¦‚ attention scoresã€ä½ç½®ä¿¡æ¯ï¼‰æ¥åˆ¤æ–­ KV å¯¹çš„é‡è¦æ€§å¹¶è¿›è¡Œæ°¸ä¹…åˆ é™¤ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•éš¾ä»¥æ•æ‰å¤æ‚çš„è·¨æ³¨æ„åŠ›å¤´åŠ¨æ€ä¾èµ–å…³ç³»ï¼Œå°¤å…¶åœ¨è¯­ä¹‰ä¾èµ–å‹æ¨¡å¼ä¸‹è¡¨ç°ä¸ä½³ï¼Œå®¹æ˜“è¯¯åˆ å…³é”®ä¿¡æ¯ï¼Œé€ æˆæ¨ç†é”™è¯¯ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æœ¬æ–‡æå‡º **ForesightKV**ï¼Œä¸€ç§**åŸºäºè®­ç»ƒçš„ KV Cache é©±é€æ¡†æ¶**ï¼Œé€šè¿‡å­¦ä¹ é¢„æµ‹æ¯ä¸ª KV å¯¹çš„**é•¿æœŸè´¡çŒ®**ï¼Œå®ç°æ›´æ™ºèƒ½ã€è‡ªé€‚åº”çš„ç¼“å­˜ç®¡ç†ã€‚

å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºä¸€ä¸ª**ä¸¤é˜¶æ®µè®­ç»ƒèŒƒå¼**ï¼š

1. **ç›‘ç£å­¦ä¹ é˜¶æ®µï¼ˆSupervised Learningï¼‰**ï¼š
   - æå‡º **Golden Eviction ç®—æ³•**ï¼šåˆ©ç”¨æœªæ¥ attention åˆ†æ•°ä½œä¸ºâ€œç†æƒ³â€é©±é€æ ‡ç­¾ï¼Œè¯†åˆ«æ¯ä¸€æ­¥åº”ä¿ç•™çš„æœ€ä¼˜ KV å¯¹é›†åˆã€‚
   - ä½¿ç”¨ **Pairwise Ranking Loss** è®­ç»ƒä¸€ä¸ªè½»é‡çº§çš„ **scoring model**ï¼Œä½¿å…¶èƒ½å¤Ÿé¢„æµ‹ KV å¯¹çš„ç›¸å¯¹é‡è¦æ€§ã€‚

2. **å¼ºåŒ–å­¦ä¹ é˜¶æ®µï¼ˆReinforcement Learningï¼‰**ï¼š
   - å°† KV Cache é©±é€å»ºæ¨¡ä¸º **Markov Decision Process (MDP)**ã€‚
   - ä½¿ç”¨ **GRPO ç®—æ³•** è¿›è¡Œä¼˜åŒ–ï¼Œå¥–åŠ±å‡½æ•°èšç„¦äºå‡å°‘å› é©±é€å¯¼è‡´çš„ **low-entropy tokens** çš„è¯­è¨€å»ºæ¨¡æŸå¤±æ¿€å¢ï¼Œä»è€Œç¼“è§£äº‹å®æ€§é”™è¯¯çš„ç´¯ç§¯ã€‚

æ•´ä¸ªè¿‡ç¨‹ä»…æ›´æ–°è½»é‡çº§çš„ scoring modelï¼Œ**ä¸ä¿®æ”¹åŸå§‹ LLM å‚æ•°**ï¼Œä¿è¯äº†é€šç”¨æ€§å’Œä½ä¾µå…¥æ€§ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆSnapKV/H2O/R-KVï¼‰ | ForesightKV |
|------|-----------------------------|-----------|
| **å†³ç­–ä¾æ®** | å¯å‘å¼è§„åˆ™ï¼ˆé™æ€/å±€éƒ¨ï¼‰ | å­¦ä¹ å¾—åˆ°çš„åŠ¨æ€é‡è¦æ€§è¯„åˆ† |
| **ä¿¡æ¯åˆ©ç”¨** | å½“å‰çª—å£æˆ–å†å²ç»Ÿè®¡ | åˆ©ç”¨æœªæ¥ä¿¡æ¯æ„å»ºç›‘ç£ä¿¡å· |
| **ä¼˜åŒ–ç›®æ ‡** | å•æ­¥æœ€ä¼˜ | é•¿æœŸæ¨ç†è´¨é‡æœ€å¤§åŒ– |
| **å¯¹ low-entropy tokens çš„ä¿æŠ¤** | å¼± | æ˜¾å¼å»ºæ¨¡å¹¶é€šè¿‡ RL å¼ºåŒ– |
| **æ³›åŒ–èƒ½åŠ›** | ä»»åŠ¡ç‰¹å®šè°ƒä¼˜ | åœ¨æ•°å­¦ã€ç§‘å­¦ã€ç¼–ç ç­‰å¤šä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **è®­ç»ƒæ•°æ®**ï¼šä½¿ç”¨ Qwen3-4B åœ¨ **STILL dataset** ä¸Šç”Ÿæˆçš„é•¿äº 4096 token çš„æ­£ç¡®æ¨ç†è½¨è¿¹ã€‚
- **è¯„ä¼°åŸºå‡†**ï¼š
  - **AIME2024** å’Œ **AIME2025**ï¼šä¸¤ä¸ªå¤æ‚æ•°å­¦æ¨ç†åŸºå‡†ã€‚
  - **GPQA**ï¼šç ”ç©¶ç”Ÿçº§åˆ«çš„ç§‘å­¦é—®ç­”æ•°æ®é›†ã€‚
  - **LiveCodeBench V3**ï¼šä»£ç ç”Ÿæˆä¸æ‰§è¡Œè¯„æµ‹åŸºå‡†ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**
- **è¯„ä¼°æ¨¡å‹**ï¼š
  - Qwen3-1.7B
  - Qwen3-4B
  - DeepSeek-R1-Distill-Qwen-7B
  - MiniCPM-4.1-8Bï¼ˆç”¨äºéªŒè¯æ³›åŒ–æ€§ï¼‰
- **KV Cache è®¾ç½®**ï¼š
  - ç¼“å­˜é¢„ç®—ï¼ˆCache Budget Bï¼‰ï¼š1K, 2K, 4K, 8K tokens
  - é©±é€é¢‘ç‡ï¼ˆEviction Length Lï¼‰ï¼š256 æˆ– 512 tokens
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Pass@1 å‡†ç¡®ç‡**ï¼ˆä¸»è¦æŒ‡æ ‡ï¼‰
  - **ååé‡ï¼ˆThroughputï¼‰** å’Œ **æœ€å¤§å¹¶å‘æ‰¹æ¬¡ï¼ˆ#MCBï¼‰**
  - **æ³¨æ„åŠ›è¾“å‡ºä½™å¼¦ç›¸ä¼¼åº¦**ï¼ˆè¡¡é‡å‹ç¼©å attention åˆ†å¸ƒä¿çœŸåº¦ï¼‰
  - **è¯­è¨€å»ºæ¨¡æŸå¤±å˜åŒ–ï¼ˆÎ”Lossï¼‰**

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **SnapKV**ï¼šåŸºäºæœ€è¿‘æŸ¥è¯¢çª—å£çš„ attention score åˆ¤æ–­é‡è¦æ€§ã€‚
- **H2O**ï¼šä¿ç•™å…·æœ‰é«˜ç´¯è®¡ attention score çš„â€œé‡å‡»è€…â€ï¼ˆheavy hittersï¼‰ã€‚
- **R-KV**ï¼šç»“åˆ attention score ä¸ token-level ç›¸ä¼¼æ€§ï¼Œè€ƒè™‘å†—ä½™æ€§ã€‚
- **Full KV Cache**ï¼šæ— å‹ç¼©ï¼Œä½œä¸ºæ€§èƒ½ä¸Šé™ã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
- åœ¨ **AIME2024** ä¸Šï¼ŒForesightKV åœ¨ **ä»… 1K KV ç¼“å­˜é¢„ç®—** ä¸‹è¾¾åˆ°ï¼š
  - **Qwen3-4B**: **54.5** Pass@1
  - è€Œ R-KV åœ¨ **2K é¢„ç®—** ä¸‹ä»…ä¸º **44.8**
- åœ¨ **4K é¢„ç®—** ä¸‹ï¼ŒForesightKV æ¥è¿‘ç”šè‡³è¶…è¿‡ Full KV Cache æ€§èƒ½ï¼š
  - Qwen3-4B-AIME2024: **69.2** vs Full: ~63.3â€“65.0ï¼ˆéƒ¨åˆ†é…ç½®ä¸‹åè¶…ï¼‰
- **æ€§èƒ½ä¿ç•™ç‡**ï¼š
  - åœ¨ 2K é¢„ç®—ä¸‹ä¿ç•™ **92%** åŸå§‹æ€§èƒ½
  - åœ¨ 4K é¢„ç®—ä¸‹ä¿ç•™ **99%** åŸå§‹æ€§èƒ½

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- **å…¨é¢è¶…è¶Šæ‰€æœ‰åŸºçº¿**ï¼Œå³ä½¿åœ¨**ä¸€åŠç¼“å­˜é¢„ç®—**ä¸‹ä»æ˜¾è‘—ä¼˜äºåŸºçº¿ã€‚
- åœ¨ **AIME2024/2025** ä¸Šï¼ŒForesightKV åœ¨ 1K é¢„ç®—ä¸‹çš„æ€§èƒ½è¿œè¶… R-KV / SnapKV åœ¨ 2K æˆ– 4K ä¸‹çš„è¡¨ç°ã€‚
- **ååé‡æå‡æ˜¾è‘—**ï¼š
  - åœ¨ 32K åºåˆ—é•¿åº¦ä¸‹ï¼Œ**1K é¢„ç®—**å³å¯å®ç°é«˜è¾¾ **9.79Ã—** çš„åååŠ é€Ÿï¼ˆvs Full Cacheï¼‰ã€‚
  - å³ä½¿åœ¨ 4K é¢„ç®—ä¸‹ï¼Œä»æœ‰ **5.14Ã—** åŠ é€Ÿã€‚

| æ–¹æ³• | 32K Throughput (vs Full) |
|------|--------------------------|
| Full | 1.00Ã— |
| ForesightKV-1K | **9.79Ã—** |
| ForesightKV-2K | 7.11Ã— |
| ForesightKV-4K | 5.14Ã— |

---

### **æ¶ˆèå®éªŒç»“æœ**
#### **(1) å¼ºåŒ–å­¦ä¹ çš„ä½œç”¨**
- **ForesightKV (w/o RL)** vs **ForesightKV**ï¼š
  - åœ¨ AIME2024 ä¸Šä» 51.7 â†’ **54.5**
  - è¡¨æ˜ RL é˜¶æ®µæœ‰æ•ˆæå‡äº†å¯¹å…³é”® token çš„ä¿æŠ¤èƒ½åŠ›ã€‚

#### **(2) é‡‡æ ·ç­–ç•¥ä¸è¾“å…¥ç‰¹å¾**
| è¾“å…¥ç‰¹å¾ | é‡‡æ ·æ–¹å¼ | AIME24 | AIME25 |
|---------|--------|--------|--------|
| Attn+KV | Top-K + MN âœ… | 51.7 | 40.9 |
| Attn only | Top-K + MN | 37.5 | 22.9 |
| Attn+KV | Top-K only | 46.0 | 37.7 |
| Attn+KV | MN only | 16.5 | 13.8 |

âœ… ç»“è®ºï¼š**åŒæ—¶ä½¿ç”¨ attention features å’Œ KV representations**ï¼Œå¹¶é‡‡ç”¨ **Top-K + Multinomial Sampling** æ˜¯æœ€ä¼˜ç»„åˆã€‚

#### **(3) å¥–åŠ±å‡½æ•°è®¾è®¡**
- ä½¿ç”¨ **Lours**ï¼ˆåŸºäº MSE çš„æŸå¤±æƒ©ç½šï¼‰ä½œä¸ºå¥–åŠ±å‡½æ•°æ•ˆæœæœ€ä½³ã€‚
- ç›´æ¥æœ€å°åŒ–æ•´ä½“è¯­è¨€å»ºæ¨¡æŸå¤±ï¼ˆLallï¼‰åè€Œå¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚
- èšç„¦äº **loss increase è¾ƒå¤§çš„ low-entropy tokens** æœ€æœ‰æ•ˆã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **KV å¯¹çš„é‡è¦æ€§æ˜¯åŠ¨æ€ä¸”å¤æ‚çš„**ï¼Œå­˜åœ¨ **globalã€position-dependentã€semantic-dependent** ä¸‰ç§æ¨¡å¼ï¼Œå…¶ä¸­è¯­ä¹‰ä¾èµ–å‹æœ€éš¾è¢«è§„åˆ™æ•è·ã€‚
2. **low-entropy tokens å¯¹ KV é©±é€æä¸ºæ•æ„Ÿ**ï¼Œå…¶æŸå¤±å¢åŠ å¸¸å¯¼è‡´æ•°å­—ã€ç¬¦å·ç­‰äº‹å®é”™è¯¯ï¼Œè¿›è€Œç ´ååç»­æ¨ç†é€»è¾‘ã€‚
3. **ForesightKV èƒ½æ›´å‡†ç¡®åœ°ä¿ç•™å…³é”®ä¿¡æ¯**ï¼Œå…¶ attention è¾“å‡ºä¸åŸå§‹æ¨¡å‹çš„ä½™å¼¦ç›¸ä¼¼åº¦æ›´é«˜ï¼ˆ1K ä¸‹è¾¾ 0.9736 vs R-KV çš„ 0.9628ï¼‰ã€‚
4. **ä¸¤é˜¶æ®µè®­ç»ƒç›¸è¾…ç›¸æˆ**ï¼š
   - ç›‘ç£å­¦ä¹ æä¾›è‰¯å¥½çš„åˆå§‹ç­–ç•¥ï¼›
   - å¼ºåŒ–å­¦ä¹ è¿›ä¸€æ­¥ä¼˜åŒ–é•¿æœŸæ¨ç†ä¸€è‡´æ€§ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–é«˜è´¨é‡çš„é•¿æ¨ç†è½¨è¿¹è¿›è¡Œè®­ç»ƒ**ï¼Œè‹¥è®­ç»ƒæ•°æ®ä¸è¶³æˆ–è´¨é‡å·®ï¼Œå¯èƒ½å½±å“ scoring model æ•ˆæœã€‚
- **å¼•å…¥é¢å¤–çš„ scoring model å’Œé‡‡æ ·å¼€é”€**ï¼Œå°½ç®¡å®éªŒè¯æ˜å…¶å¼€é”€æå°ï¼ˆä»…å æ€»æ—¶é—´ ~2.7%ï¼‰ï¼Œä½†åœ¨æç«¯ä½å»¶è¿Ÿåœºæ™¯ä¸‹ä»éœ€æƒè¡¡ã€‚
- å½“å‰è®­ç»ƒé›†ä¸­åœ¨æ•°å­¦ä»»åŠ¡ï¼Œè™½ç„¶å±•ç°å‡ºè‰¯å¥½æ³›åŒ–ï¼Œä½†åœ¨å…¶ä»–é¢†åŸŸï¼ˆå¦‚å¯¹è¯ã€åˆ›æ„å†™ä½œï¼‰çš„æœ‰æ•ˆæ€§æœ‰å¾…éªŒè¯ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ¢ç´¢ **æ— éœ€æœªæ¥ä¿¡æ¯** çš„è‡ªå›å½’å¼ç›‘ç£ä¿¡å·æ„å»ºæ–¹æ³•ã€‚
- å°† ForesightKV æ‰©å±•è‡³ **å¤šæ¨¡æ€æ¨¡å‹** çš„ç¼“å­˜ç®¡ç†ã€‚
- ç ”ç©¶ scoring model çš„ **å‚æ•°å…±äº«æœºåˆ¶**ï¼Œä»¥é™ä½éƒ¨ç½²æˆæœ¬ã€‚
- ç»“åˆ **KV Cache merging** ä¸ **eviction**ï¼Œå®ç°æ›´é«˜æ•ˆçš„æ··åˆå‹ç¼©ç­–ç•¥ã€‚

---

> **æ€»ç»“**ï¼šForesightKV é€šè¿‡**ç›‘ç£+å¼ºåŒ–å­¦ä¹ **çš„åŒé˜¶æ®µè®­ç»ƒï¼Œé¦–æ¬¡å®ç°äº†å¯¹ KV Cache é•¿æœŸè´¡çŒ®çš„æ˜¾å¼å»ºæ¨¡ï¼Œåœ¨å¤§å¹…é™ä½ç¼“å­˜é¢„ç®—çš„åŒæ—¶ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰è§„åˆ™é©±åŠ¨æ–¹æ³•ï¼Œä¸ºé«˜æ•ˆé•¿æ–‡æœ¬æ¨ç†æä¾›äº†æ–°çš„ç ”ç©¶èŒƒå¼ã€‚

</details>

---

### 12. [EvoOpt-LLM: Evolving industrial optimization models with large language models](https://arxiv.org/abs/2602.01082)

**Authors**: Yiliu He, Tianle Li, Binghao Ji, Zhiyuan Liu, Di Huang  
**Category**: cs.AI  
**Published**: 2026-02-04  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.01082v1  

#### Abstract
Optimization modeling via mixed-integer linear programming (MILP) is fundamental to industrial planning and scheduling, yet translating natural-language requirements into solver-executable models and maintaining them under evolving business rules remains highly expertise-intensive. While large langu...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šEvoOpt-LLM: Evolving industrial optimization models with large language models**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å·¥ä¸šçº§ä¼˜åŒ–å»ºæ¨¡ï¼ˆå¦‚ **MILP**ï¼‰åœ¨åˆ¶é€ ã€ä¾›åº”é“¾ã€ç‰©æµç­‰é¢†åŸŸè‡³å…³é‡è¦ï¼Œä½†å­˜åœ¨ä»¥ä¸‹ç“¶é¢ˆï¼š
- **å»ºæ¨¡é—¨æ§›é«˜**ï¼šä¸šåŠ¡éœ€æ±‚ä»¥è‡ªç„¶è¯­è¨€æè¿°ï¼Œéœ€ä¸“å®¶æ‰‹åŠ¨è½¬åŒ–ä¸ºæ•°å­¦æ¨¡å‹ï¼Œè¿‡ç¨‹è€—æ—¶ä¸”æ˜“é”™ã€‚
- **æ¨¡å‹ç»´æŠ¤å›°éš¾**ï¼šä¸šåŠ¡è§„åˆ™æŒç»­å˜åŒ–ï¼Œä¼ ç»Ÿæ–¹æ³•éœ€é‡å»ºæ•´ä¸ªæ¨¡å‹ï¼Œéš¾ä»¥æ”¯æŒåŠ¨æ€æ¼”åŒ–ã€‚
- **æ±‚è§£æ•ˆç‡ä½**ï¼šå¤§è§„æ¨¡ **MILP** åŒ…å«å¤§é‡å†—ä½™å˜é‡ï¼Œå¯¼è‡´æ±‚è§£æ—¶é—´é•¿ï¼Œè€Œä¼ ç»Ÿ **presolve** æŠ€æœ¯ä¾èµ–ç¡®å®šæ€§è§„åˆ™ï¼Œæ— æ³•åˆ©ç”¨å†å²æ•°æ®ä¸­çš„éšå«æ¨¡å¼ã€‚

ç°æœ‰ **LLM** æ–¹æ³•å¤šèšç„¦äºä¸€æ¬¡æ€§ç”Ÿæˆç®€åŒ–æ¨¡å‹ï¼Œç¼ºä¹å¯¹ **solver-level executability**ã€**åŠ¨æ€çº¦æŸæ³¨å…¥** å’Œ **æ¨¡å‹å‹ç¼©** çš„ç³»ç»Ÿæ”¯æŒã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æå‡º **EvoOpt-LLM** â€”â€” ä¸€ä¸ªåŸºäº **LLM** çš„ç»Ÿä¸€æ¡†æ¶ï¼Œè¦†ç›–å·¥ä¸šä¼˜åŒ–å»ºæ¨¡çš„å…¨ç”Ÿå‘½å‘¨æœŸï¼ŒåŒ…å«ä¸‰å¤§æ¨¡å—ï¼š

1. **Automated Modelingï¼ˆè‡ªåŠ¨åŒ–å»ºæ¨¡ï¼‰**
   - è¾“å…¥ï¼šè‡ªç„¶è¯­è¨€æè¿°
   - è¾“å‡ºï¼šå¯æ‰§è¡Œçš„ **MILP** æ¨¡å‹ä»£ç ï¼ˆå«å˜é‡ã€å‚æ•°ã€çº¦æŸã€ç›®æ ‡å‡½æ•°ï¼‰
   - æ–¹æ³•ï¼šåŸºäº **openPangu-Embedded-7B** æ¨¡å‹ï¼Œé€šè¿‡ **LoRA** è¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒã€‚

2. **Dynamic Constraint Injectionï¼ˆåŠ¨æ€çº¦æŸæ³¨å…¥ï¼‰**
   - åœ¨å·²æœ‰å¯æ‰§è¡Œ **MILP** æ¨¡å‹åŸºç¡€ä¸Šï¼ŒæŒ‰éœ€æ³¨å…¥æ–°çš„ä¸šåŠ¡çº¦æŸï¼ˆå¦‚äººåŠ›é™åˆ¶ã€åˆ†æ‰¹äº¤ä»˜ç­‰ï¼‰ï¼Œ**ä¸æ”¹å˜åŸç›®æ ‡å‡½æ•°å’Œç»“æ„**ã€‚
   - å°†ä¼˜åŒ–æ¨¡å‹è§†ä¸ºâ€œå¯ç¼–è¾‘å¯¹è±¡â€ï¼Œå®ç°å¢é‡æ›´æ–°ã€‚

3. **End-to-End Variable Pruningï¼ˆç«¯åˆ°ç«¯å˜é‡å‰ªæï¼‰**
   - é¢„æµ‹å¹¶å›ºå®šä¸ºé›¶çš„å†—ä½™å†³ç­–å˜é‡ï¼Œç¼©å°æ¨¡å‹è§„æ¨¡ï¼Œæå‡æ±‚è§£æ•ˆç‡ã€‚
   - å°†å‰ªæä»»åŠ¡å»ºæ¨¡ä¸º**æ•°æ®é©±åŠ¨çš„æ¨ç†é—®é¢˜**ï¼Œè€Œéä»…ä¾èµ–ä»£æ•°è§„åˆ™ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• / ç°æœ‰ LLM æ–¹æ³• | **EvoOpt-LLM** |
|------|--------------------------|----------------|
| **å»ºæ¨¡æ–¹å¼** | æ‰‹åŠ¨æˆ–ä¸€æ¬¡æ€§ç”Ÿæˆ | æ”¯æŒå…¨ç”Ÿå‘½å‘¨æœŸï¼šæ„å»º â†’ æ¼”åŒ– â†’ å‹ç¼© |
| **åŠ¨æ€é€‚åº”æ€§** | ä¸æ”¯æŒå¢é‡æ›´æ–° | æ”¯æŒ LP-level ç»“æ„åŒ–çº¦æŸæ³¨å…¥ |
| **æ•°æ®æ•ˆç‡** | éœ€å¤§é‡æ ‡æ³¨æ•°æ® | ä»…ç”¨ 3,000 æ ·æœ¬å³å¯è¾¾åˆ°é«˜æ€§èƒ½ï¼Œ<1,500 æ ·æœ¬å³è§æ˜¾è‘—æå‡ |
| **æ±‚è§£å‰ä¼˜åŒ–** | ä¾èµ– solver å†…ç½® presolve | å¼•å…¥ LLM é©±åŠ¨çš„å˜é‡å‰ªæï¼Œæ•æ‰éšå«ä¸šåŠ¡é€»è¾‘ |
| **é¢†åŸŸé€‚é…** | é€šç”¨ LLM ç¼ºä¹ OR ç»“æ„ç†è§£ | é€šè¿‡ LoRA å®ç°é¢†åŸŸä¸“ä¸šåŒ–ï¼Œæˆæœ¬ä½ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **è‡ªåŠ¨åŒ–å»ºæ¨¡æ¨¡å—**ï¼š
  - è‡ªå»ºæ•°æ®é›†ï¼Œå…± **3,000** ä¸ªæ ·æœ¬ã€‚
  - ç±»å‹åˆ†å¸ƒï¼š  
    - **MILP**: 33%  
    - **LP**: 22%  
    - **æ•´æ•°è§„åˆ’**: 14%  
    - å…¶ä»–ï¼ˆè°ƒåº¦ã€ç½‘ç»œä¼˜åŒ–ã€éšæœºä¼˜åŒ–ç­‰ï¼‰ï¼š31%
  - æ¯ä¸ªæ ·æœ¬åŒ…å«ï¼šè‡ªç„¶è¯­è¨€æè¿° + æ•°å­¦å…¬å¼ + å¯æ‰§è¡Œä»£ç ï¼ˆå¦‚ Python + PuLP/Gurobiï¼‰

- **çº¦æŸæ³¨å…¥æ¨¡å—**ï¼š
  - åŸºäºç»Ÿä¸€åŸºå‡† **LP æ–‡ä»¶**ï¼ˆä¾›åº”é“¾ç”Ÿäº§è¿è¾“é—®é¢˜ï¼‰ç”Ÿæˆã€‚
  - æ³¨å…¥äº”ç±»å¸¸è§å·¥ä¸šçº¦æŸï¼š
    1. Setup Time Constraint
    2. Human Resource Constraint
    3. Batch Size & Inventory Capacity
    4. Cross-Period Production
    5. Split Delivery
  - è‡ªåŠ¨ç”Ÿæˆè¾“å…¥è¾“å‡ºå¯¹ï¼š`(åŸå§‹ LP + è‡ªç„¶è¯­è¨€çº¦æŸæè¿°) â†’ (å¢å¼ºå LP)`

- **å˜é‡å‰ªææ¨¡å—**ï¼š
  - ä½¿ç”¨çœŸå®å·¥ä¸šè°ƒåº¦è®°å½•æ„å»ºã€‚
  - ä¸¤é˜¶æ®µæ„å»ºï¼š
    1. éœ€æ±‚é©±åŠ¨é‡‡æ ·ï¼Œå°†å¤§è§„æ¨¡é—®é¢˜é™ç»´ä¸ºå°è§„æ¨¡ä½†è¯­ä¹‰ä¸€è‡´çš„å®ä¾‹ã€‚
    2. åˆ©ç”¨å¼‚æ„å›¾ç®—æ³•è¯†åˆ«æœ€ä¼˜è§£ä¸­æ’ä¸ºé›¶çš„å˜é‡ï¼Œä½œä¸ºæ ‡ç­¾ã€‚
  - æœ€ç»ˆæ•°æ®é›†ï¼š**400** ä¸ªå¸¦å‰ªææ ‡ç­¾çš„å°è§„æ¨¡ LP å®ä¾‹ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **æ¨¡å‹åŸºç¡€ä¸è®­ç»ƒ**
- **Base Model**: openPangu-Embedded-7B-V1.1ï¼ˆ7B å‚æ•°ï¼‰
- **å¾®è°ƒæ–¹æ³•**: **LoRA**ï¼ˆParameter-Efficient Fine-Tuningï¼‰
- **ç¡¬ä»¶**: åä¸º Ascend 910B2 NPU Ã—4ï¼Œæ¯å¡ 64GB HBM
- **è½¯ä»¶æ ˆ**: CANN 8.1, PyTorch 2.5.1 + torch_npu, Transformers 4.53.2, vLLM-Ascend

#### **è¯„ä¼°æŒ‡æ ‡**

| æ¨¡å— | æŒ‡æ ‡ | å®šä¹‰ |
|------|------|------|
| **è‡ªåŠ¨åŒ–å»ºæ¨¡** | Generation Rate | æˆåŠŸç”Ÿæˆä»£ç çš„æ¯”ä¾‹ |
| | Executability Rate | ç”Ÿæˆä»£ç èƒ½è¢«æ ‡å‡† solver æˆåŠŸè§£æå¹¶è¿è¡Œçš„æ¯”ä¾‹ |
| | Accuracy Rate | ç”Ÿæˆæ¨¡å‹æ±‚è§£ç»“æœä¸åŸºå‡†ä¸€è‡´çš„æ¯”ä¾‹ |
| **çº¦æŸæ³¨å…¥** | åŠŸèƒ½æ­£ç¡®æ€§ | æ˜¯å¦æ­£ç¡®å®šä¹‰æ–°å˜é‡ã€æ·»åŠ æœ‰æ•ˆçº¦æŸã€ä¿ç•™åŸç›®æ ‡ |
| | ç»“æ„ä¸€è‡´æ€§ | è¾“å‡ºæ˜¯å¦ç¬¦åˆ LP æ ¼å¼è§„èŒƒï¼Œä¸åŸæ–‡ä»¶é£æ ¼ä¸€è‡´ |
| **å˜é‡å‰ªæ** | F1 Score | å‰ªæé¢„æµ‹çš„ç²¾ç¡®ç‡ä¸å¬å›ç‡çš„è°ƒå’Œå¹³å‡ |
| | Precision / Recall | åˆ†åˆ«è¡¡é‡å‰ªæçš„å®‰å…¨æ€§ä¸å®Œæ•´æ€§ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
è®ºæ–‡æœªç›´æ¥å¯¹æ¯”å…¶ä»–ç«¯åˆ°ç«¯ LLM æ–¹æ³•ï¼ˆå› å¤šæ•°ä¸æ”¯æŒä¸‰åˆä¸€åŠŸèƒ½ï¼‰ï¼Œè€Œæ˜¯é€šè¿‡æ¶ˆèåˆ†æéªŒè¯å„æ¨¡å—æœ‰æ•ˆæ€§ï¼š
- **Base Modelï¼ˆæœªå¾®è°ƒï¼‰** vs **LoRA-Finetuned Model**
- ä¸åŒè®­ç»ƒæ ·æœ¬é‡ä¸‹çš„æ€§èƒ½æ›²çº¿ï¼ˆéªŒè¯æ•°æ®æ•ˆç‡ï¼‰
- ä¸ä¼ ç»Ÿ presolve æŠ€æœ¯çš„å®šæ€§å¯¹æ¯”ï¼ˆå¼ºè°ƒå…¶æ— æ³•å­¦ä¹ å†å²æ¨¡å¼ï¼‰

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **è‡ªåŠ¨åŒ–å»ºæ¨¡æ¨¡å—**
- **ä»…ç”¨ 300 æ ·æœ¬**ï¼šå¼€å§‹ç”Ÿæˆä»£ç ï¼Œä½†ä¸å¯æ‰§è¡Œã€‚
- **1,200â€“1,500 æ ·æœ¬**ï¼šå‡ºç°è´¨å˜ï¼ŒExecutability Rate ä» 2.4% è·ƒå‡è‡³ **38.2%**ã€‚
- **3,000 æ ·æœ¬ï¼ˆå®Œæ•´æ•°æ®ï¼‰**ï¼š
  - **Generation Rate**: **91%**
  - **Executability Rate**: **65.9%**
  - **Accuracy Rate**: **26.37%**
- **ç»“è®º**ï¼šå¼ºæ•°æ®æ•ˆç‡ï¼Œ**<1,500 æ ·æœ¬å³å¯è§¦å‘å…³é”®æ€§èƒ½çªç ´**ã€‚

#### **çº¦æŸæ³¨å…¥æ¨¡å—**
- **Base Model è¾“å‡º**ï¼ˆå›¾3ï¼‰ï¼š
  - ä»…æä¾›æ¦‚å¿µæ€§æè¿°ï¼Œæ— æ—¶é—´ç´¢å¼•ã€æ— è¾…åŠ©å˜é‡å®šä¹‰ã€‚
  - æ··åˆè‡ªç„¶è¯­è¨€ä¸æ•°å­¦è¡¨è¾¾ï¼Œ**ä¸å¯æ‰§è¡Œ**ã€‚
- **LoRA å¾®è°ƒåè¾“å‡º**ï¼ˆå›¾4ï¼‰ï¼š
  - æ­£ç¡®å¼•å…¥ `operation_A_binary`, `available_human_t` ç­‰å˜é‡ã€‚
  - æ·»åŠ ç»“æ„åŒ–çº¿æ€§çº¦æŸï¼Œæ ¼å¼è§„èŒƒï¼Œ**å¯ç›´æ¥é›†æˆè¿› LP æ–‡ä»¶**ã€‚
  - å®Œå…¨ä¿ç•™åŸç›®æ ‡å‡½æ•°ä¸çº¦æŸã€‚

#### **å˜é‡å‰ªææ¨¡å—**
- **è®­ç»ƒæ ·æœ¬ä»… 400 ä¸ª**ã€‚
- åœ¨ **350â€“400 è¡Œ LP æ–‡ä»¶** ä¸Šè¡¨ç°æœ€ä½³ï¼š
  - **F1 Score â‰ˆ 0.56**
  - Precision ä¸ Recall å‡å¤„äºåˆç†æ°´å¹³ã€‚
- æ€§èƒ½éšæ–‡ä»¶è§„æ¨¡å¢å¤§è€Œä¸‹é™ï¼š
  - >450 è¡Œï¼šæ€§èƒ½æŒç»­ä¸‹æ»‘
  - >1,500 è¡Œï¼šF1 æ¥è¿‘ 0
- **åŸå› **ï¼šå—é™äºä¸Šä¸‹æ–‡é•¿åº¦ä¸å¤æ‚äº¤äº’å»ºæ¨¡èƒ½åŠ›ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- **Base Model é›¶æ•ˆæœ**ï¼šæœªå¾®è°ƒæ¨¡å‹åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šå‡å¤±è´¥ï¼Œè¡¨æ˜é¢†åŸŸçŸ¥è¯†å¿…é¡»æ˜¾å¼æ³¨å…¥ã€‚
- **ç›¸æ¯”é€šç”¨ LLM**ï¼ˆå¦‚ GPT-4ï¼‰ï¼š
  - æ— éœ€æç¤ºå·¥ç¨‹ï¼Œç›´æ¥è¾“å‡ºç»“æ„åŒ– LP ä»£ç ã€‚
  - æ›´ç¨³å®šã€æ›´ç¬¦åˆå·¥ä¸šç¼–ç è§„èŒƒã€‚
- **ç›¸æ¯”ä¼ ç»Ÿ presolve**ï¼š
  - å¯è¯†åˆ«ç”±å†å²ä¸šåŠ¡æ¨¡å¼å†³å®šçš„â€œè½¯å†—ä½™â€å˜é‡ï¼Œè€Œä¸ä»…æ˜¯ä»£æ•°å†—ä½™ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**
è™½æœªæ˜ç¡®åˆ—å‡ºâ€œablation studyâ€ç« èŠ‚ï¼Œä½†ä»å®éªŒè®¾è®¡ä¸­å¯æ¨æ–­ï¼š
- **LoRA å¾®è°ƒæ˜¯å…³é”®**ï¼šæ— æ­¤æ­¥éª¤åˆ™æ¨¡å‹æ— ä»»ä½•å¯ç”¨èƒ½åŠ›ã€‚
- **æ•°æ®å¤šæ ·æ€§é‡è¦**ï¼šæ¶µç›–å¤šç§ OR é—®é¢˜ç±»å‹æœ‰åŠ©äºæ³›åŒ–ã€‚
- **ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶æ˜¾è‘—å½±å“å‰ªææ€§èƒ½**ï¼šå¤§æ¨¡å‹å¤„ç†é•¿ LP æ–‡ä»¶ä»å…·æŒ‘æˆ˜ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **LLM å¯æœ‰æ•ˆæ”¯æŒå·¥ä¸šä¼˜åŒ–å»ºæ¨¡å…¨ç”Ÿå‘½å‘¨æœŸ**ï¼Œä¸ä»…é™äºåˆå§‹ç”Ÿæˆã€‚
2. **LoRA å¾®è°ƒ + å°æ ·æœ¬ï¼ˆ3k/400ï¼‰å³å¯å®ç°é«˜æ€§èƒ½**ï¼Œå…·å¤‡å®é™…éƒ¨ç½²å¯è¡Œæ€§ã€‚
3. **ä¼˜åŒ–æ¨¡å‹åº”è¢«è§†ä¸ºâ€œå¯è¿›åŒ–å¯¹è±¡â€**ï¼Œæ”¯æŒ LP-level å¢é‡ç¼–è¾‘æ˜¯æå‡æ•æ·æ€§çš„å…³é”®ã€‚
4. **å˜é‡å‰ªæå¯æ•°æ®é©±åŠ¨åŒ–**ï¼ŒLLM èƒ½ä»å†å²æ•°æ®ä¸­å­¦ä¹ éšå«çš„â€œé›¶æ¿€æ´»â€æ¨¡å¼ï¼Œè¶…è¶Šä¼ ç»Ÿ presolveã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
1. **ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶**ï¼š
   - å½“å‰æ¨¡å‹åœ¨å¤„ç† >1,500 è¡Œçš„å¤§å‹ LP æ–‡ä»¶æ—¶æ€§èƒ½æ€¥å‰§ä¸‹é™ã€‚
2. **æ³›åŒ–èƒ½åŠ›æœ‰é™**ï¼š
   - å‰ªææ¨¡å—åœ¨æœªè§è¿‡çš„é—®é¢˜ç»“æ„ä¸Šå¯èƒ½å¤±æ•ˆã€‚
3. **ä¾èµ–é«˜è´¨é‡æ ‡æ³¨æ•°æ®**ï¼š
   - å°½ç®¡æ•°æ®æ•ˆç‡é«˜ï¼Œä½†ä»éœ€ä¸€å®šé‡äººå·¥æˆ–åŠè‡ªåŠ¨æ ‡æ³¨ã€‚
4. **æœªå®Œå…¨ç«¯åˆ°ç«¯éªŒè¯**ï¼š
   - ç”Ÿæˆæ¨¡å‹çš„â€œè¯­ä¹‰å‡†ç¡®æ€§â€ä»…éƒ¨åˆ†éªŒè¯ï¼Œæœªè¦†ç›–æ‰€æœ‰åœºæ™¯ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **æ‰©å±•ä¸Šä¸‹æ–‡å¤„ç†èƒ½åŠ›**ï¼š
   - æ¢ç´¢ **long-context modeling** æ¶æ„æˆ– **hierarchical pruning** ç­–ç•¥ã€‚
2. **å¤šé˜¶æ®µå‰ªææœºåˆ¶**ï¼š
   - å…ˆç²—ç²’åº¦è¿‡æ»¤ï¼Œå†ç»†ç²’åº¦åˆ¤æ–­ï¼Œé™ä½å•æ¬¡æ¨ç†å¤æ‚åº¦ã€‚
3. **å¼•å…¥å¼ºåŒ–å­¦ä¹ åé¦ˆ**ï¼š
   - ç»“åˆ solver åé¦ˆè¿›è¡Œ test-time adaptationï¼ˆç±»ä¼¼ OR-R1ï¼‰ã€‚
4. **æ„å»ºæ›´å¤§è§„æ¨¡å·¥ä¸šä¼˜åŒ–åŸºå‡†æ•°æ®é›†**ï¼š
   - è¦†ç›–æ›´å¤šè¡Œä¸šã€æ›´å¤§è§„æ¨¡é—®é¢˜ï¼Œæ¨åŠ¨ç¤¾åŒºå‘å±•ã€‚
5. **ä¸ solver æ·±åº¦é›†æˆ**ï¼š
   - å°† EvoOpt-LLM ä½œä¸º presolve æ’ä»¶åµŒå…¥ CPLEX/Gurobi æµç¨‹ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **EvoOpt-LLM** æå‡ºäº†ä¸€ç§**æ•°æ®é«˜æ•ˆã€å…¨å‘¨æœŸã€å¯æ¼”åŒ–çš„å·¥ä¸šä¼˜åŒ–å»ºæ¨¡èŒƒå¼**ï¼Œé€šè¿‡ **LLM + LoRA** å®ç°ä»è‡ªç„¶è¯­è¨€åˆ°å¯æ‰§è¡Œã€å¯ç»´æŠ¤ã€å¯åŠ é€Ÿçš„ **MILP** æ¨¡å‹çš„è‡ªåŠ¨åŒ–é—­ç¯ï¼Œä¸º OR ä¸ AI çš„æ·±åº¦èåˆæä¾›äº†å®ç”¨è·¯å¾„ã€‚

</details>

---

### 13. [Neural Attention Search Linear: Towards Adaptive Token-Level Hybrid Attention Models](https://arxiv.org/abs/2602.03681)

**Authors**: Difan Deng, Andreas Bentzen Winje, Lukas Fehring, Marius Lindauer  
**Category**: cs.CL  
**Published**: 2026-02-04  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.03681v1  

#### Abstract
The quadratic computational complexity of softmax transformers has become a bottleneck in long-context scenarios. In contrast, linear attention model families provide a promising direction towards a more efficient sequential model. These linear attention models compress past KV values into a single ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Neural Attention Search Linear: Towards Adaptive Token-Level Hybrid Attention Models è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿçš„ **softmax attention** åœ¨é•¿ä¸Šä¸‹æ–‡åœºæ™¯ä¸­é¢ä¸´ **O(LÂ²)** çš„è®¡ç®—å¤æ‚åº¦ç“¶é¢ˆï¼Œå°¤å…¶æ˜¯åœ¨è®­ç»ƒå’Œæ¨ç†æ—¶å¯¹å†…å­˜å’Œç®—åŠ›è¦æ±‚æé«˜ã€‚è™½ç„¶ **linear attention** æ¨¡å‹ï¼ˆå¦‚ Mambaã€DeltaNetï¼‰é€šè¿‡å°†æ³¨æ„åŠ›æ“ä½œè½¬æ¢ä¸ºçº¿æ€§é€’å½’å½¢å¼ï¼Œå®ç°äº† **O(L)** å¤æ‚åº¦ï¼Œä½†å…¶è¡¨è¾¾èƒ½åŠ›å—é™äºå›ºå®šå¤§å°çš„éšè—çŠ¶æ€ï¼ˆhidden stateï¼‰ï¼Œéš¾ä»¥æœ‰æ•ˆä¿ç•™é•¿æœŸä¾èµ–ä¿¡æ¯ã€‚

ç°æœ‰æ··åˆæ¶æ„ï¼ˆå¦‚ GDN Hybridï¼‰å°è¯•åœ¨ä¸åŒå±‚äº¤æ›¿ä½¿ç”¨ softmax å’Œ linear attentionï¼Œä½†è¿™äº›ç»“æ„æ˜¯**é™æ€å›ºå®šçš„**ï¼Œæ— æ³•æ ¹æ®è¾“å…¥åŠ¨æ€è°ƒæ•´ï¼Œå¯¼è‡´æ•ˆç‡ä¸æ€§èƒ½ä¹‹é—´éš¾ä»¥å–å¾—æœ€ä¼˜å¹³è¡¡ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
æœ¬æ–‡æå‡º **Neural Attention Search Linear (NAtS-L)**ï¼Œä¸€ç§**è‡ªé€‚åº”çš„ token-level æ··åˆæ³¨æ„åŠ›æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- **åœ¨åŒä¸€å±‚å†…ï¼Œå¯¹ä¸åŒçš„ token åŠ¨æ€é€‰æ‹©ä½¿ç”¨ softmax attention è¿˜æ˜¯ linear attention**ã€‚
- å¼•å…¥ä¸€ä¸ªå¯å­¦ä¹ çš„ **Attention Score Layer**ï¼ŒåŸºäºè¾“å…¥ç‰¹å¾ä¸ºæ¯ä¸ª token chunk é¢„æµ‹æœ€åˆé€‚çš„ attention æ“ä½œç±»å‹ã€‚
- é€šè¿‡æ¢¯åº¦è”åˆä¼˜åŒ–ï¼Œä½¿æ¨¡å‹è‡ªåŠ¨å­¦ä¹ â€œå“ªäº› token éœ€è¦è¢«é•¿æœŸä¿ç•™ï¼ˆç”¨ softmax attentionï¼‰ï¼Œå“ªäº›å¯ä»¥å‹ç¼©å¤„ç†ï¼ˆç”¨ linear attentionï¼‰â€ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ Transformer / Linear-onlyï¼‰ | æ··åˆå±‚æ–¹æ³•ï¼ˆå¦‚ GDN Hybridï¼‰ | **NAtS-Lï¼ˆæœ¬æ–‡ï¼‰** |
|------|----------------------------------------|-----------------------------|--------------------|
| **çµæ´»æ€§** | å›ºå®šç»“æ„ | å±‚çº§å›ºå®šåˆ‡æ¢ | âœ… **Token çº§åŠ¨æ€å†³ç­–** |
| **æ•ˆç‡** | ä½ï¼ˆO(LÂ²)ï¼‰ | ä¸­ç­‰ï¼ˆéƒ¨åˆ† softmaxï¼‰ | âœ… **æ›´é«˜æ•ˆï¼ˆä»…å…³é”® token ç”¨ softmaxï¼‰** |
| **è¡¨è¾¾èƒ½åŠ›** | é«˜ï¼ˆå…¨ KV ç¼“å­˜ï¼‰ | ä¸­ç­‰ | âœ… **ä¿ç•™å…³é”®ä¿¡æ¯ + å‹ç¼©å†—ä½™** |
| **ç¡¬ä»¶å‹å¥½æ€§** | å·®ï¼ˆæ˜¾å­˜å¢™ï¼‰ | è¾ƒå¥½ | âœ… **chunk-wise å¹¶è¡Œ + å¯æ§è´Ÿè½½** |

> ğŸ’¡ **æ ¸å¿ƒåˆ›æ–°**ï¼šé¦–æ¬¡å®ç° **token-level è‡ªé€‚åº”æ³¨æ„åŠ›æœºåˆ¶æœç´¢**ï¼Œæ‰“ç ´äº†â€œè¦ä¹ˆå…¨å±€å…³æ³¨ï¼Œè¦ä¹ˆå±€éƒ¨å»ºæ¨¡â€çš„äºŒå…ƒå¯¹ç«‹ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **é¢„è®­ç»ƒæ•°æ®**ï¼š
  - `Fineweb-Edu`ï¼šæ•™è‚²é¢†åŸŸé«˜è´¨é‡æ–‡æœ¬ï¼Œç”¨äºå­¦æœ¯è§„æ¨¡é¢„è®­ç»ƒã€‚
    - å°æ¨¡å‹ï¼š380M å‚æ•°ï¼Œè®­ç»ƒ 15B tokens
    - å¤§æ¨¡å‹ï¼š800M å‚æ•°ï¼Œè®­ç»ƒ 50B tokens
- **è¯„ä¼°ä»»åŠ¡**ï¼š
  - **å¸¸è¯†æ¨ç†**ï¼šLAMBADA, PIQA, HellaSwag, Winogrande, OpenBookQA, ARC-e/c
  - **æ£€ç´¢ä»»åŠ¡ï¼ˆé•¿ä¸Šä¸‹æ–‡ï¼‰**ï¼šSWDE, SQD, FDA, TQA, NQ, DROPï¼ˆè¾“å…¥æˆªæ–­è‡³ 4096ï¼‰
  - **å¤–æ¨èƒ½åŠ›æµ‹è¯•**ï¼šPG19, CodeParrot, NarrativeQAï¼ˆé•¿åº¦è¾¾ 65kï¼‰
  - **æ ‡å‡†é•¿ä¸Šä¸‹æ–‡åŸºå‡†**ï¼šRULER, LongBench

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **ä¸Šä¸‹æ–‡é•¿åº¦**ï¼šç»Ÿä¸€è®­ç»ƒé•¿åº¦ä¸º 4096
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA H100 PCIe Ã— 4/8 GPUs
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **å‡†ç¡®ç‡ï¼ˆaccï¼‰**ï¼šåˆ†ç±»/é—®ç­”ä»»åŠ¡
  - **å›°æƒ‘åº¦ï¼ˆppl / perplexityï¼‰**ï¼šè¯­è¨€å»ºæ¨¡è´¨é‡
  - **å¹³å‡å¾—åˆ†ï¼ˆmean scoreï¼‰**ï¼šRULER ç­‰ç»¼åˆæŒ‡æ ‡
  - **å»¶è¿Ÿï¼ˆlatencyï¼‰**ï¼šprefill å’Œ decoding æ—¶é—´

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ¨¡å‹ | ç±»å‹ | å‚æ•°é‡ï¼ˆå¤§ï¼‰ | ç‰¹ç‚¹ |
|------|------|--------------|------|
| GDN | Linear-only | 793M | Gated DeltaNetï¼Œé«˜æ•ˆä½†è¡¨è¾¾å—é™ |
| Mamba2 | State Space Model | 801M | å½“å‰ä¸»æµé«˜æ•ˆæ¶æ„ |
| Transformer | Softmax-only | 778M | å…¨æ³¨æ„åŠ›ï¼Œé«˜æˆæœ¬ |
| GDN Hybrid | Layer-wise Hybrid | 802M | 5 å±‚ softmax + 17 å±‚ GDN |
| **NAtS-L** | âœ… **Token-wise Adaptive Hybrid** | 794M | æœ¬æ–‡æ–¹æ³•ï¼Œå…¨ NAtS-L å±‚ |
| **NAtS-L Hybrid** | âœ… **Token-wise + Layer-wise** | 793M | 6 å±‚ NAtS-L + 15 å±‚ GDN |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆ800M æ¨¡å‹ï¼‰

#### è¡¨ 1ï¼šé›¶æ ·æœ¬æ¨ç†ä¸æ£€ç´¢ä»»åŠ¡è¡¨ç°ï¼ˆéƒ¨åˆ†ï¼‰
| Model | Avg. Retrieval Acc â†‘ | Best Task Perf |
|-------|------------------------|----------------|
| GDN | 31.22 | â€” |
| Mamba2 | 29.94 | â€” |
| Transformer | 33.66 | â€” |
| GDN Hybrid | 37.30 | â€” |
| **NAtS-L** | **39.75** | DROP æœ€é«˜ |
| **NAtS-L Hybrid** | **45.07** | âœ… **å…¨é¢é¢†å…ˆ** |

> ğŸ”¥ **NAtS-L Hybrid åœ¨æ‰€æœ‰ 6 é¡¹æ£€ç´¢ä»»åŠ¡ä¸­å¹³å‡é«˜å‡ºç¬¬äºŒå 7.8 ä¸ªç™¾åˆ†ç‚¹**

#### å›¾ 3ï¼šé•¿åºåˆ—å¤–æ¨å›°æƒ‘åº¦ï¼ˆ65k è¾“å…¥ï¼‰
- åœ¨ **PG19** å’Œ **NarrativeQA** ä¸Šï¼Œå½“è¾“å…¥è¿œè¶…è®­ç»ƒé•¿åº¦ï¼ˆ4k â†’ 65kï¼‰ï¼š
  - GDN / Mamba2 æ€§èƒ½æ€¥å‰§ä¸‹é™
  - Transformer å›°éš¾ç»´æŒ
  - **NAtS-L ä¸ NAtS-L Hybrid èƒ½ç¨³å®šä¿æŒä½ perplexity**
- è¡¨æ˜ï¼š**åŠ¨æ€ä¿ç•™å…³é”® token çš„ softmax attention å¯¹é•¿ç¨‹ä¾èµ–è‡³å…³é‡è¦**

#### è¡¨ 2ï¼šRULER åŸºå‡†ï¼ˆä¸åŒä¸Šä¸‹æ–‡é•¿åº¦ï¼‰
| Model | 4k | 8k | 16k |
|-------|----|----|-----|
| Transformer | 0.45 | 0.00 | 0.00 |
| GDN Hybrid | 0.47 | 0.02 | 0.00 |
| **NAtS-L Hybrid** | **0.49** | **0.32** | **0.21** |

> âœ… **NAtS-L Hybrid æ˜¯å”¯ä¸€åœ¨ 16k ä¸Šä»ä¿æŒæ˜¾è‘—æ€§èƒ½çš„æ–¹æ³•**

#### å›¾ 4ï¼šæ¨ç†å»¶è¿Ÿå¯¹æ¯”ï¼ˆæœ€é•¿åºåˆ—ï¼‰
- **Prefill é˜¶æ®µ**ï¼šNAtS-L Hybrid æ¯” GDN æ…¢ 1.66Ã—ï¼Œä½†æ¯” Transformer å¿« **5.4Ã—**
- **Decoding é˜¶æ®µï¼ˆ128kï¼‰**ï¼šæ¯” Transformer å¿« **2.3Ã—**

> âš¡ åœ¨å‡ ä¹ä¸ç‰ºç‰²é€Ÿåº¦çš„å‰æä¸‹ï¼Œè·å¾—æ¥è¿‘å…¨ attention çš„æ€§èƒ½

---

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 4ï¼‰

| å˜ä½“ | Avg. Retrieval Acc â†“ | åˆ†æ |
|------|------------------------|------|
| **NAtS-L Hybrid (Full)** | **33.49** | âœ… æœ€ä¼˜é…ç½® |
| w/o Attn Norm | 29.59 | å½’ä¸€åŒ–å¯¹è¾“å‡ºèåˆè‡³å…³é‡è¦ |
| w/o Attn Weights | 32.34 | å¯å­¦ä¹ æƒé‡æå‡è¡¨è¾¾èƒ½åŠ› |
| Weights From X | 27.64 | æ¥è‡ª `q` çš„æ˜ å°„æ›´æœ‰æ•ˆ |
| w/o LAttn Decay | 32.24 | è¡°å‡æœºåˆ¶å¸®åŠ©é—å¿˜æ— å…³å†å² |
| GDN Out only | 26.98 | ä»… linear å†…éƒ¨è®¡ç®—ä¸¥é‡é™è´¨ |

> âœ… æ‰€æœ‰è®¾è®¡ç»„ä»¶å‡è¢«éªŒè¯æœ‰æ•ˆï¼Œå°¤å…¶æ˜¯ **RMS Norm + q-based weighting + decay**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **Token-level è‡ªé€‚åº”æ³¨æ„åŠ›ä¼˜äºå›ºå®šç»“æ„æ··åˆæ¨¡å‹**  
   NAtS-L èƒ½æ ¹æ®è¾“å…¥å†…å®¹åŠ¨æ€åˆ†é…è®¡ç®—èµ„æºï¼Œåœ¨â€œéœ€è¦è®°å¿†çš„åœ°æ–¹â€å¯ç”¨ softmax attentionï¼Œå…¶ä½™ä½¿ç”¨ linear attentionï¼Œå®ç°**æ€§èƒ½ä¸æ•ˆç‡çš„å¸•ç´¯æ‰˜å‰æ²¿çªç ´**ã€‚

2. âœ… **å¹¶éè¶Šå¤š softmax attention è¶Šå¥½**  
   å®éªŒæ˜¾ç¤ºæ²¡æœ‰ head å®Œå…¨ä½¿ç”¨ softmax attentionï¼Œè¯´æ˜â€œå…¨åºåˆ—å…³æ³¨â€å¯èƒ½é€ æˆèµ„æºæµªè´¹ï¼›è€Œå®Œå…¨ä¸ç”¨åˆ™ä¸¢å¤±å…³é”®ä¿¡æ¯ã€‚**ç¨€ç–ä½†ç²¾å‡†çš„å…³æ³¨æ‰æ˜¯æœ€ä¼˜è§£**ã€‚

3. âœ… **NAtS-L å…·å¤‡å¼ºå¤–æ¨èƒ½åŠ›**  
   åœ¨è¿œè¶…è®­ç»ƒé•¿åº¦çš„ä»»åŠ¡ä¸Šä»èƒ½ä¿æŒè‰¯å¥½æ€§èƒ½ï¼Œè¡¨æ˜å…¶èƒ½æœ‰æ•ˆè¯†åˆ«å¹¶ä¿ç•™é•¿æœŸç›¸å…³ tokenã€‚

4. âœ… **ç¡¬ä»¶å‹å¥½ä¸”æ˜“äºé›†æˆ**  
   åŸºäº chunk-wise å¹¶è¡Œè®¾è®¡ï¼Œå…¼å®¹ FlashAttention æ¶æ„ï¼Œæ— éœ€é¢å¤–è¾…åŠ©æŸå¤±æˆ–è´Ÿè½½å‡è¡¡æœºåˆ¶ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æœç´¢ç©ºé—´ä»…åŒ…å«ä¸¤ç§æ“ä½œï¼š**softmax attention å’Œ GDN**ï¼Œå°šæœªæ‰©å±•åˆ°æ›´å¤š linear attention familyï¼ˆå¦‚ Mambaã€RetNetï¼‰ã€‚
- æœªå¼•å…¥**æ­£åˆ™åŒ–æ§åˆ¶ softmax token æ¯”ä¾‹**ï¼Œå¯èƒ½å¯¼è‡´æŸäº›è¾“å…¥ä¸‹è®¡ç®—åˆ†å¸ƒä¸å‡ã€‚
- æ‰€æœ‰æ“ä½œå…±äº« Q/K/V æŠ•å½±ï¼Œé™åˆ¶äº†æ“ä½œé—´çš„ç‹¬ç«‹ä¼˜åŒ–ç©ºé—´ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å¤§æœç´¢ç©ºé—´**ï¼šçº³å…¥å¤šç§ linear attention æ¨¡å‹ï¼ˆå¦‚ Mamba, RWKVï¼‰ï¼Œæ„å»ºæ›´ä¸°å¯Œçš„æ··åˆç”Ÿæ€ã€‚
2. **å¼•å…¥æ•ˆç‡çº¦æŸ**ï¼šé€šè¿‡ auxiliary loss æ§åˆ¶ softmax token å æ¯”ï¼Œå®ç°å¯æ§çš„ **efficiency-performance trade-off**ã€‚
3. **æ¢ç´¢ MoE-style attention routing**ï¼šè®©ä¸åŒ token èµ°å‘ä¸åŒä¸“å®¶è·¯å¾„ï¼Œè¿›ä¸€æ­¥æå‡è¡¨è¾¾å¤šæ ·æ€§ã€‚
4. **åº”ç”¨äºæ›´å¤§è§„æ¨¡æ¨¡å‹**ï¼šéªŒè¯åœ¨åäº¿çº§ä»¥ä¸Šæ¨¡å‹ä¸­çš„å¯æ‰©å±•æ€§ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **NAtS-L å¼€åˆ›æ€§åœ°å®ç°äº† token-level è‡ªé€‚åº”æ³¨æ„åŠ›æœºåˆ¶ï¼Œåœ¨å‡ ä¹ä¸å¢åŠ æ¨ç†å¼€é”€çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº†é•¿ä¸Šä¸‹æ–‡å»ºæ¨¡èƒ½åŠ›ï¼Œä¸ºä¸‹ä¸€ä»£é«˜æ•ˆå¤§æ¨¡å‹æä¾›äº†æ–°èŒƒå¼ã€‚**

</details>

---

### 14. [ContextEvolve: Multi-Agent Context Compression for Systems Code Optimization](https://arxiv.org/abs/2602.02597)

**Authors**: Hongyuan Su, Yu Zheng, Yong Li  
**Category**: cs.LG  
**Published**: 2026-02-04  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.02597v1  

#### Abstract
Large language models are transforming systems research by automating the discovery of performance-critical algorithms for computer systems. Despite plausible codes generated by LLMs, producing solutions that meet the stringent correctness and performance requirements of systems demands iterative op...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠContextEvolve: Multi-Agent Context Compression for Systems Code Optimizationã€‹æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
ç°ä»£ **Large Language Models (LLMs)** åœ¨ç³»ç»Ÿä»£ç ä¼˜åŒ–ä¸­å±•ç°å‡ºæ½œåŠ›ï¼Œèƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆç®—æ³•è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œåœ¨ **API-only è®¿é—®**ï¼ˆå³æ— æ³•æ›´æ–°æ¨¡å‹å‚æ•°ï¼‰çš„çº¦æŸä¸‹ï¼Œç°æœ‰çš„è®­ç»ƒ-free è¿›åŒ–æ–¹æ³•é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼š
- **ä½æ•ˆçš„ä¸Šä¸‹æ–‡åˆ©ç”¨**ï¼šåŸå§‹å†å²è®°å½•ç›´æ¥æ‹¼æ¥å¯¼è‡´ä¿¡æ¯å¯†åº¦ä½ï¼Œæµªè´¹ token èµ„æºï¼›
- **æ— å¯¼å‘çš„æœç´¢è¿‡ç¨‹**ï¼šç¼ºä¹ä»é•¿æœŸè¿›åŒ–è½¨è¿¹ä¸­æå–æ˜ç¡®ä¼˜åŒ–æ–¹å‘çš„èƒ½åŠ›ï¼Œå®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚

è¿™äº›é—®é¢˜é™åˆ¶äº†åœ¨æœ‰é™è®¡ç®—é¢„ç®—ä¸‹çš„æœç´¢æ•ˆç‡å’Œæœ€ç»ˆè§£çš„è´¨é‡ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
ä½œè€…æå‡º **ContextEvolve** â€”â€” ä¸€ç§åŸºäºå¤šæ™ºèƒ½ä½“ï¼ˆmulti-agentï¼‰æ¡†æ¶çš„ä¸Šä¸‹æ–‡å‹ç¼©æœºåˆ¶ï¼Œé€šè¿‡å°†ä¼˜åŒ–ä¸Šä¸‹æ–‡åˆ†è§£ä¸ºä¸‰ä¸ªæ­£äº¤ç»´åº¦ï¼Œå¹¶ç”±ä¸“ç”¨ Agent åˆ†åˆ«ç®¡ç†ï¼Œå®ç°é«˜æ•ˆã€æœ‰æŒ‡å¯¼æ€§çš„ä»£ç æ¼”åŒ–ã€‚

#### ä¸‰å¤§æ ¸å¿ƒ Agent åŠå…¶åŠŸèƒ½ï¼š
| Agent | åŠŸèƒ½ | å¯¹åº” RL æœºåˆ¶ |
|------|------|-------------|
| **Summarizer Agent** | å°†ä»£ç å·®å¼‚æŠ½è±¡ä¸ºè‡ªç„¶è¯­è¨€æ‘˜è¦ï¼Œä¿ç•™å…³é”®è¯­ä¹‰çŠ¶æ€ï¼ˆå¦‚ç»§æ‰¿ç‰¹å¾ä¸åˆ›æ–°è®¾è®¡ï¼‰ | State Representation Learning |
| **Navigator Agent** | åˆ†æå†å²è½¨è¿¹ä¸­çš„æ€§èƒ½å˜åŒ–ï¼ˆÎ”sï¼‰ï¼Œæç‚¼å‡ºé«˜ä»·å€¼çš„â€œæ–‡æœ¬æ¢¯åº¦â€ä½œä¸ºä¼˜åŒ–æ–¹å‘ | Policy Gradient Estimation |
| **Sampler Agent** | ä»ç§ç¾¤ä¸­ä¼˜å…ˆæ£€ç´¢å¤šæ ·åŒ–ä¸”é«˜ä¿¡æ¯é‡çš„ exemplars ä½œä¸ºå°‘æ ·æœ¬æç¤º | Prioritized Experience Replay |

è¯¥æ¶æ„å®ç°äº†ä¸ **test-time Reinforcement Learning (RL)** çš„**åŠŸèƒ½æ€§åŒæ„ï¼ˆfunctional isomorphismï¼‰**ï¼Œåœ¨çº¯æ–‡æœ¬ç©ºé—´ä¸­æ¨¡æ‹Ÿäº† RL çš„é«˜æ•ˆæœç´¢æœºåˆ¶ï¼Œè€Œæ— éœ€ä»»ä½•å‚æ•°æ›´æ–°ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- âœ… **é«˜æœç´¢æ•ˆç‡**ï¼šç›¸æ¯”ä¼ ç»Ÿè¿›åŒ–ç­–ç•¥ï¼Œæ”¶æ•›æ›´å¿«ï¼Œçªç ´å±€éƒ¨æœ€ä¼˜èƒ½åŠ›æ›´å¼ºï¼›
- âœ… **ä½ Token æ¶ˆè€—**ï¼šé€šè¿‡è¯­ä¹‰å‹ç¼©æå‡ä¿¡æ¯å¯†åº¦ï¼Œå‡å°‘å†—ä½™ä¸Šä¸‹æ–‡ä¼ è¾“ï¼›
- âœ… **å‚æ•°ç›²æ“ä½œå…¼å®¹æ€§å¼º**ï¼šå®Œå…¨é€‚ç”¨äºä»…æä¾› API æ¥å£çš„å•†ç”¨ LLMï¼›
- âœ… **å¯æ‰©å±•æ€§å¥½**ï¼šæ¨¡å—åŒ–è®¾è®¡ä¾¿äºç‹¬ç«‹ä¼˜åŒ–å„ç»„ä»¶ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
åœ¨ **ADRS benchmark** ä¸Šè¿›è¡Œè¯„ä¼°ï¼ŒåŒ…å«äº”ä¸ªå…¸å‹ç³»ç»Ÿä»£ç ä¼˜åŒ–ä»»åŠ¡ï¼š
1. **Transaction Scheduling (TS)**ï¼šæœ€å°åŒ–äº‹åŠ¡æ‰§è¡Œæ—¶é—´ï¼ˆmakespanï¼‰ï¼Œæœ€å¤§åŒ–æ­£ç¡®ç‡ï¼ˆCorr.ï¼‰
2. **SQL Optimization (SQL)**ï¼šæé«˜ KV ç¼“å­˜å‘½ä¸­ç‡ï¼ˆHit.ï¼‰ï¼Œé™ä½é‡æ’åºå»¶è¿Ÿï¼ˆLat.ï¼‰
3. **Load Balancing (LB)**ï¼šå¹³è¡¡ GPU è´Ÿè½½ï¼ˆBal.ï¼‰ï¼ŒåŠ å¿«å†åˆ†é…é€Ÿåº¦ï¼ˆSpe.ï¼‰
4. **Sparse Attention Kernel (SAK)**ï¼šä¼˜åŒ–ç¨€ç–æ³¨æ„åŠ›æ©ç ï¼Œæƒè¡¡å¯†åº¦ï¼ˆDens.ï¼‰ä¸è¯¯å·®ï¼ˆErr.ï¼‰
5. **Model Placement (MP)**ï¼šå‡å°‘ KV å‹åŠ›ï¼ˆPress.ï¼‰ï¼Œæå‡ GPU åˆ©ç”¨æˆåŠŸç‡ï¼ˆSucc.ï¼‰

æ¯ä¸ªä»»åŠ¡å‡é‡‡ç”¨åŠ æƒç»¼åˆå¾—åˆ†ï¼ˆScoreï¼‰ä½œä¸ºä¸»æŒ‡æ ‡ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **åŸºç¡€æ¨¡å‹**ï¼šQwen3ï¼ˆæ‰€æœ‰ LLM ç»„ä»¶ç»Ÿä¸€ä½¿ç”¨ï¼‰
- **æœ€å¤§è¿­ä»£æ¬¡æ•°**ï¼šTS/SQL/SAK/MP ä¸º 100 æ¬¡ï¼›LB ä¸º 300 æ¬¡
- **è¯„ä¼°æ–¹å¼**ï¼šè‡ªåŠ¨åŒ– evaluator è¿”å› scalar score
- **ä¸»è¦æŒ‡æ ‡**ï¼š
  - æœ€ç»ˆæœ€ä½³ solution çš„ **combined Score**
  - è¾¾åˆ°æœ€ä¼˜è§£æ‰€éœ€çš„ **token æ¶ˆè€—æ€»é‡**
  - æ”¶æ•›æ›²çº¿ï¼ˆbest-so-far performance over iterationsï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| Heuristics | è§„åˆ™åŸºçº¿ | ç”Ÿäº§ç¯å¢ƒå¸¸ç”¨æ‰‹å·¥è§„åˆ™ |
| Human-SOTA | ä¸“å®¶è®¾è®¡ | é¢†åŸŸä¸“å®¶æ‰‹åŠ¨è°ƒä¼˜æ–¹æ¡ˆ |
| LLM One-shot | å•è½®ç”Ÿæˆ | ä¸€æ¬¡æ¨ç†è¾“å‡ºï¼Œæ— åé¦ˆå¾ªç¯ |
| GEPA | Prompt Evolution | åŸºäºåæ€æ€§çªå˜ä¸å¸•ç´¯æ‰˜é€‰æ‹© |
| OpenEvolve | Evolutionary Coding | AlphaEvolve å¼€æºå®ç°ï¼Œä¿ç•™åŸå§‹ä»£ç å†å² |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰
| æ–¹æ³• | å¹³å‡ Score æå‡ï¼ˆvs. æœ€ä½³ baselineï¼‰ | Token æ¶ˆè€—ä¸‹é™ |
|------|-------------------------------|----------------|
| **ContextEvolve** | **+6.5%**ï¼ˆæ•´ä½“å¹³å‡ï¼‰<br>æœ€é«˜è¾¾ **+33.3%**ï¼ˆLB ä»»åŠ¡ï¼‰ | **-29.0%**ï¼ˆå¹³å‡ï¼‰ |

å…·ä½“è¡¨ç°äº®ç‚¹ï¼š
- åœ¨ **Load Balancing (LB)** ä»»åŠ¡ä¸­ï¼š
  - Balance æå‡ **+36.0%**
  - Speed æå‡ **+44.4%**
  - ç»¼åˆ Score æå‡ **+33.3%**
- åœ¨å¤æ‚ä»»åŠ¡ä¸ŠèŠ‚çœæ›´å¤š tokenï¼ˆå¦‚ LB èŠ‚çœè¿‘ 30%ï¼‰ï¼Œè½»é‡ä»»åŠ¡ï¼ˆTS/MPï¼‰èŠ‚çœçº¦ 5%

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- æ‰€æœ‰é™æ€æ–¹æ³•ï¼ˆHeuristics, Human-SOTA, One-shotï¼‰å‡æ˜¾è‘—è½åäºè¿›åŒ–ç±»æ–¹æ³•ï¼›
- GEPA å’Œ OpenEvolve è™½ä¼˜äºé™æ€æ–¹æ³•ï¼Œä½†ä»å—é™äºä½æ•ˆä¸Šä¸‹æ–‡å¤„ç†ï¼›
- **ContextEvolve åœ¨æ‰€æœ‰äº”é¡¹ä»»åŠ¡ä¸­å…¨é¢è¶…è¶Šæ‰€æœ‰ baseline**ï¼Œå°¤å…¶åœ¨éœ€è¦æ·±åº¦æ¢ç´¢çš„ä»»åŠ¡ï¼ˆå¦‚ LBï¼‰ä¸Šä¼˜åŠ¿æ˜æ˜¾ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
ç§»é™¤ä»»ä¸€ Agent å‡å¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œå½±å“ç¨‹åº¦å¦‚ä¸‹ï¼š
| ç§»é™¤ Agent | å¹³å‡ Score ä¸‹é™ | å½±å“åˆ†æ |
|----------|------------------|---------|
| **Summarizer Agent** | **-9.3%** | è¯­ä¹‰ä¸¢å¤±ä¸¥é‡ï¼Œå¼•å‘â€œé—å¿˜æ•ˆåº”â€ï¼Œé˜»ç¢å…¶ä»– Agent å·¥ä½œ |
| **Sampler Agent** | **-6.0%** | ä»…ä¾èµ–é«˜åˆ†æ ·æœ¬ï¼Œé”™å¤±æ½œåœ¨çªç ´çµæ„Ÿ |
| **Navigator Agent** | **-2.9%** | æœç´¢æ–¹å‘æ¨¡ç³Šï¼Œæ”¶æ•›å˜æ…¢ |

> ğŸ” **å…³é”®å‘ç°**ï¼šSummarizer æ˜¯æœ€å…³é”®ç»„ä»¶ï¼Œå…¶ç¼ºå¤±ä½¿æ€§èƒ½é€€åŒ–è‡³æ¥è¿‘ LLM One-shot æ°´å¹³ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **ä¸Šä¸‹æ–‡å‹ç¼©æ˜¯è®­ç»ƒ-free ä¼˜åŒ–çš„å…³é”®ç“¶é¢ˆ**  
   å•çº¯å †å åŸå§‹å†å²ä¼šè¿…é€Ÿè€—å°½ä¸Šä¸‹æ–‡çª—å£ï¼Œå¿…é¡»è¿›è¡Œ**è¯­ä¹‰å±‚é¢çš„ä¸»åŠ¨å‹ç¼©**ã€‚

2. **å¤š Agent åˆ†è§£èƒ½æœ‰æ•ˆå»ºæ¨¡ RL æœºåˆ¶**  
   é€šè¿‡å°†ä¼˜åŒ–ä¸Šä¸‹æ–‡è§£è€¦ä¸º **stateã€directionã€experience** ä¸‰ä¸ªç»´åº¦ï¼Œå¯åœ¨æ–‡æœ¬ç©ºé—´ä¸­é‡å»º RL çš„é«˜æ•ˆæœç´¢èŒƒå¼ã€‚

3. **é«˜è´¨é‡ä¿¡æ¯ â‰  é«˜å¾—åˆ†ä¸ªä½“**  
   æˆåŠŸçš„çªç ´å¾€å¾€æºäºå¤±è´¥ä½†å…·æœ‰åˆ›æ–°é€»è¾‘çš„å°è¯•ï¼ˆå¦‚ LB ä¸­çš„â€œbroken binary searchâ€å¯å‘äº†â€œLargest Remainderâ€ç­–ç•¥ï¼‰ã€‚

4. **æŠ½è±¡å±‚æ¬¡å†³å®šæœç´¢æ•ˆç‡**  
   - è¿‡åº¦å…·ä½“çš„æŒ‡å¯¼ï¼ˆå¦‚å¼ºåˆ¶å®ç°ç»†èŠ‚ï¼‰ä¼šæŠ‘åˆ¶å¤šæ ·æ€§ï¼›
   - åˆç†çš„æ¨¡ç³Šæ€§åè€Œæœ‰åŠ©äºæ¢ç´¢æ›´å¹¿çš„ solution spaceã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰å·¥ä½œèšç„¦äº**åŠŸèƒ½éš”ç¦»çš„ç®—æ³•æ¨¡å—**ï¼Œå°šæœªæ‰©å±•åˆ°å¤§è§„æ¨¡è·¨æ¨¡å—ååŒä¼˜åŒ–ï¼›
- å¤š Agent æ¶æ„å¼•å…¥é¢å¤– API è°ƒç”¨å¼€é”€ï¼ˆå°½ç®¡æ€» token æ›´å°‘ï¼‰ï¼›
- LLM å›ºæœ‰çš„è¾“å‡ºä¸ç¡®å®šæ€§å¯èƒ½å¯¼è‡´é«˜æ–¹å·®ç»“æœï¼Œéœ€è¿›ä¸€æ­¥ç¨³å®šæœºåˆ¶ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³ **large-scale codebase** çš„è”åˆä¼˜åŒ–ï¼›
- å¼•å…¥ **variance reduction æœºåˆ¶** æå‡ç»“æœä¸€è‡´æ€§ï¼›
- æ¢ç´¢ä¿ƒè¿› **diverse algorithmic paradigms å‘ç°** çš„è¯„ä¼°æœºåˆ¶ï¼›
- å°†æ¡†æ¶åº”ç”¨äºæ›´å¤šé¢†åŸŸï¼ˆå¦‚ç¼–è¯‘å™¨ä¼˜åŒ–ã€æ“ä½œç³»ç»Ÿè°ƒåº¦ç­‰ï¼‰ã€‚

---

> ğŸ“¦ **å¼€æºä¿¡æ¯**ï¼šä»£ç å·²å‘å¸ƒäº [https://anonymous.4open.science/r/ContextEvolve-ACC](https://anonymous.4open.science/r/ContextEvolve-ACC)

</details>

---

### 15. [Lookahead Path Likelihood Optimization for Diffusion LLMs](https://arxiv.org/abs/2602.03496)

**Authors**: Xuejie Liu, Yap Vit Chun, Yitao Liang, Anji Liu  
**Category**: cs.LG  
**Published**: 2026-02-04  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.03496v1  

#### Abstract
Diffusion Large Language Models (dLLMs) support arbitrary-order generation, yet their inference performance critically depends on the unmasking order. Existing strategies rely on heuristics that greedily optimize local confidence, offering limited guidance for identifying unmasking paths that are gl...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šLookahead Path Likelihood Optimization for Diffusion LLMs**

---

## 1. **è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
Diffusion Large Language Models (dLLMs) è™½ç„¶æ”¯æŒä»»æ„é¡ºåºç”Ÿæˆï¼ˆarbitrary-order generationï¼‰ï¼Œå…¶æ¨ç†æ€§èƒ½å´é«˜åº¦ä¾èµ–äº **unmasking order**ï¼ˆå³ token çš„è§£ç é¡ºåºï¼‰ã€‚ç°æœ‰çš„ unmasking ç­–ç•¥å¤šåŸºäºå¯å‘å¼è§„åˆ™ï¼ˆå¦‚é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜æˆ–ç†µæœ€ä½çš„ tokenï¼‰ï¼Œè¿™äº›æ–¹æ³•ä»…ä¼˜åŒ–å±€éƒ¨ç¡®å®šæ€§ï¼Œç¼ºä¹å¯¹å…¨å±€ä¸€è‡´æ€§å’Œæœ€ç»ˆç”Ÿæˆè´¨é‡çš„è€ƒé‡ï¼Œå®¹æ˜“é™·å…¥â€œçŸ­è§†â€è·¯å¾„ï¼Œå¯¼è‡´æ¬¡ä¼˜è¾“å‡ºã€‚

æœ¬æ–‡æ—¨åœ¨è§£å†³ä»¥ä¸‹æ ¸å¿ƒé—®é¢˜ï¼š  
> å¦‚ä½•åœ¨æ¨ç†æ—¶åŠ¨æ€è¯†åˆ«èƒ½å¤Ÿæœ€å¤§åŒ–ç”Ÿæˆè´¨é‡çš„ **unmasking è·¯å¾„**ï¼Ÿ

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡ºäº†ä¸€å¥—ä»¥ **Path Log-Likelihood (Path LL)** ä¸ºæ ¸å¿ƒç›®æ ‡çš„æ¨ç†ä¼˜åŒ–æ¡†æ¶ï¼Œä¸»è¦åŒ…æ‹¬ä¸¤ä¸ªå…³é”®ç»„ä»¶ï¼š

#### âœ… **Path LLï¼ˆè·¯å¾„ä¼¼ç„¶ï¼‰ä½œä¸ºç”Ÿæˆè´¨é‡ä»£ç†**
- å®šä¹‰äº†ä¸€ä¸ªæ–°çš„è½¨è¿¹ç›¸å…³ç›®æ ‡å‡½æ•°ï¼š**Path LL**ï¼Œå³åœ¨ç‰¹å®š unmasking è½¨è¿¹ $ \mathcal{T} = (Q_T, ..., Q_1) $ ä¸‹å®Œæ•´åºåˆ—çš„è”åˆå¯¹æ•°ä¼¼ç„¶ï¼š
  $$
  \log p_d(\mathbf{x}; \theta, \mathcal{T}) = \sum_{t=1}^T \log p_d(\mathbf{c}_{Q_t} | \mathbf{o}_t; \theta)
  $$
- å®éªŒè¯æ˜ï¼Œ**Path LL ä¸ä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®ç‡æœ‰å¼ºæ­£ç›¸å…³æ€§**ï¼Œæ˜¾è‘—ä¼˜äº ELBOã€è¾¹é™…ç†µç­‰ä¼ ç»ŸæŒ‡æ ‡ï¼Œæ˜¯æ›´å¯é çš„ç”Ÿæˆè´¨é‡ä»£ç†ã€‚

#### âœ… **POKEï¼šå‰å‘ä¼°è®¡æœªæ¥è·¯å¾„ä¼¼ç„¶çš„ä»·å€¼ä¼°è®¡å™¨**
- æå‡º **POKE (Path-Optimistic K-step likelihood Estimator)**ï¼Œä¸€ç§é«˜æ•ˆçš„ lookahead ä»·å€¼ä¼°è®¡å™¨ï¼Œç”¨äºé¢„æµ‹éƒ¨åˆ†è§£ç è½¨è¿¹çš„æœŸæœ›æœªæ¥ Path LLã€‚
- åˆ©ç”¨éšæœº rollout æ¨¡æ‹Ÿæœªæ¥å®Œæˆè·¯å¾„ï¼Œå¹¶é€šè¿‡ entropy correction æ ¡æ­£å¹¶è¡Œé‡‡æ ·å¸¦æ¥çš„ç‹¬ç«‹æ€§åå·®ï¼Œä½¿å¾—ä¼°è®¡å€¼åœ¨é«˜å¹¶è¡Œåº¦ä¸‹ä»ä¿æŒç¨³å®šã€‚

#### âœ… **POKE-SMCï¼šåŸºäº Sequential Monte Carlo çš„æœç´¢æ¡†æ¶**
- å°† POKE é›†æˆè¿› **Sequential Monte Carlo (SMC)** æ¡†æ¶ï¼Œæ„å»º **POKE-SMC**ï¼Œå®ç°åŠ¨æ€è·¯å¾„æœç´¢ï¼š
  - ç»´æŠ¤å¤šä¸ªç²’å­ï¼ˆå€™é€‰è½¨è¿¹ï¼‰
  - åœ¨å‘¨æœŸæ€§é‡é‡‡æ ·ç‚¹ï¼Œä½¿ç”¨ POKE æä¾›çš„å…¨å±€ä»·å€¼ä¿¡å·è¿›è¡ŒåŠ æƒå’Œé‡é‡‡æ ·
  - åŠ¨æ€èšç„¦é«˜æ½œåŠ›è·¯å¾„ï¼Œé¿å…é™·å…¥å±€éƒ¨æœ€ä¼˜

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **ç›®æ ‡è®¾è®¡** | ä½¿ç”¨ Path LL æ›¿ä»£å±€éƒ¨å¯å‘å¼ï¼Œå…·å¤‡æ›´å¼ºçš„å…¨å±€ä¸€è‡´æ€§æŒ‡å¯¼èƒ½åŠ› |
| **æ•ˆç‡ä¸å‡†ç¡®æ€§å¹³è¡¡** | POKE ä¸éœ€é¢å¤–è®­ç»ƒï¼Œè½»é‡é«˜æ•ˆï¼Œé€‚åˆæ¨ç†æ—¶ä½¿ç”¨ |
| **é€‚åº”æ€§å¼º** | å¯é€‚é…ä¸åŒä»»åŠ¡å’Œä¸Šä¸‹æ–‡ï¼Œæ— éœ€ä»»åŠ¡ç‰¹å®šè°ƒå‚ |
| **æ€§èƒ½æå‡æ˜¾è‘—** | åœ¨ç›¸è¿‘è®¡ç®—å¼€é”€ä¸‹ï¼Œæ˜¾è‘—è¶…è¶Šå¼ºåŸºçº¿ï¼Œæ¨åŠ¨ accuracy-compute Pareto frontier |

---

## 2. **æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
å®éªŒè¦†ç›– **6 ä¸ªæ¨ç†å¯†é›†å‹ä»»åŠ¡**ï¼ŒåŒ…æ‹¬ï¼š
- **GSM8K**ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜
- **MATH500**ï¼šé«˜ä¸­åŠä»¥ä¸Šéš¾åº¦æ•°å­¦é¢˜
- **Countdown**ï¼šæ•°å­—ç»„åˆæ¸¸æˆï¼ˆéœ€ç²¾ç¡®é€»è¾‘æ¨å¯¼ï¼‰
- å…¶ä»–æœªæ˜ç¡®å‘½åçš„ä»»åŠ¡ï¼ˆç»Ÿç§° reasoning tasksï¼‰

æ¨¡å‹åŸºç¡€ä¸º **LLaDA ç³»åˆ— dLLMs**ï¼ˆå¦‚ LLaDA-8B-Instructï¼‰ï¼Œä»£è¡¨å½“å‰å…ˆè¿›çš„ diffusion-based LLMã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### ğŸ”§ **æ¨ç†è®¾ç½®**
- æ—¶é—´æ­¥ç¦»æ•£åŒ–ä¸º $ T = 256 $
- æ¯æ­¥ unmask å¤šä¸ª tokenï¼ˆblock size = 32 æˆ–å¯å˜ï¼‰
- ä½¿ç”¨ zero-shot è®¾ç½®è¿›è¡Œç”Ÿæˆ
- POKE ä¸­ lookahead horizon $ K \in \{4,8,16,64\} $ï¼Œæ§åˆ¶å‰ç»æ·±åº¦

#### ğŸ“Š **è¯„ä¼°æŒ‡æ ‡**
- **Accuracy (%)**ï¼šä»»åŠ¡æ­£ç¡®ç‡ï¼ˆå¦‚æ•°å­¦é¢˜è§£ç­”æ˜¯å¦æ­£ç¡®ï¼‰
- **Latency (s)**ï¼šç«¯åˆ°ç«¯æ¨ç†å»¶è¿Ÿ
- **Path LL ä¼°è®¡è´¨é‡**ï¼šä¸çœŸå®æœ€ç»ˆ Path LL çš„ç›¸å…³æ€§
- **Accuracy-Compute Pareto Frontier**ï¼šç²¾åº¦ä¸è®¡ç®—æˆæœ¬çš„æƒè¡¡æ›²çº¿

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
ä¸ä»¥ä¸‹ä¸»æµæ–¹æ³•æ¯”è¾ƒï¼š
| åŸºçº¿ | æè¿° |
|------|------|
| **PC-Sampler** | åŸºäºä½ç½®æ„ŸçŸ¥æ ¡å‡†çš„è§£ç åç½®ä¿®æ­£æ–¹æ³• |
| **Majority Voting** | å¤šæ¬¡é‡‡æ ·åæŠ•ç¥¨é›†æˆ |
| **E-SMC** | åŸºäºç†µçš„ SMC æ–¹æ³•ï¼Œä½¿ç”¨ä¸€æ­¥ç†µä¼°è®¡ |
| **Random / Confidence / Entropy-based ordering** | ç»å…¸å¯å‘å¼ unmasking ç­–ç•¥ |

æ­¤å¤–è¿˜å¯¹æ¯”äº†è¿‘æœŸå­¦ä¹ å¼è§„åˆ’æ–¹æ³•ï¼ˆå¦‚ LookUMï¼‰å’Œ RL-based æ–¹æ³•ã€‚

---

## 3. **ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

| æ–¹æ³• | å¹³å‡ Accuracy Gain | æ¨ç†å¼€é”€ï¼ˆç›¸å¯¹ï¼‰ |
|------|-------------------|----------------|
| **POKE-SMC** | **+2% ~ +5%** | â‰ˆ å¼ºåŸºçº¿ï¼ˆå¦‚ E-SMCï¼‰ |
| å…¶ä»– decoding-time scaling æ–¹æ³• | +1% ~ +2% | ç±»ä¼¼æˆ–æ›´é«˜ |

> åœ¨ LLaDA æ¨¡å‹ä¸Šï¼ŒPOKE-SMC å®ç° **å¹³å‡ 3%-5% çš„ç»å¯¹å‡†ç¡®ç‡æå‡**ï¼Œè¿œè¶…å·²æœ‰æ–¹æ³•ã€‚

#### ç¤ºä¾‹ç»“æœï¼ˆTable 10, Countdown æ•°æ®é›†ï¼‰ï¼š
| Method       | Latency (s)         | Accuracy (%)        |
|--------------|---------------------|---------------------|
| PC-Sampler   | 7.9                 | 36.1                |
| Majority Voting | 9.5/18.0/32.6     | 34.0/36.0/36.9      |
| E-SMC        | 9.5/18.0/32.6       | 35.4/38.3/39.8      |
| **POKE-SMC** | **8.9/22.1/34.7**   | **36.4/42.3/40.8**  |

âœ… åœ¨ç›¸ä¼¼å»¶è¿Ÿä¸‹ï¼ŒPOKE-SMC æ˜¾è‘—é¢†å…ˆï¼Œå°¤å…¶åœ¨ä¸­ç­‰é¢„ç®—ï¼ˆ~22sï¼‰è¾¾åˆ° **42.3% å‡†ç¡®ç‡**ï¼Œä¼˜äºæ‰€æœ‰åŸºçº¿ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### âœ… **POKE vs. Product LLï¼ˆæœ´ç´ ä¹˜ç§¯ä¼¼ç„¶ï¼‰**
- åœ¨ Figure 2 å’Œé™„å½• Figures 5â€“7 ä¸­æ˜¾ç¤ºï¼š
  - éšç€å¹¶è¡Œåº¦å¢åŠ ï¼ˆ|A|â†‘ï¼‰ï¼Œproduct LL å¯¹æœªæ¥ Path LL çš„ä¼°è®¡ä¸¥é‡ä½ä¼°
  - **POKE ä¼°è®¡å€¼å§‹ç»ˆæ¥è¿‘çœŸå®æœ€ç»ˆ Path LL**ï¼Œè¯¯å·®å°ä¸”ç¨³å®š
- ç‰¹åˆ«æ˜¯åœ¨ $ K=16 $ï¼ˆå³æ¯æ­¥ unmask 16 tokensï¼‰æ—¶è¡¨ç°æœ€ä½³ï¼Œè¯´æ˜é€‚åº¦å‰ç»æœ€æœ‰æ•ˆ

#### âœ… **ä¸åŒ unmasking block size ä¸‹çš„è¡¨ç°**
- å³ä½¿åœ¨é«˜åååœºæ™¯ï¼ˆæ¯æ­¥ unmask 2 tokensï¼‰ï¼ŒPOKE-SMC ä»ä¿æŒ **+4.9% ~ +5.4%** çš„å¢ç›Šï¼Œè¡¨æ˜å…¶é²æ£’æ€§å¼º

#### âœ… **æ¸©åº¦ä¸é‡é‡‡æ ·é—´éš”æ•æ„Ÿæ€§åˆ†æï¼ˆAppendix Cï¼‰**
- ç»“æœæ˜¾ç¤º POKE-SMC åœ¨è¾ƒå®½å‚æ•°èŒƒå›´å†…è¡¨ç°ç¨³å¥ï¼Œæ— éœ€ç²¾ç»†è°ƒå‚

---

## 4. **å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**

1. âœ… **Path LL æ˜¯æ¯”ä¼ ç»ŸæŒ‡æ ‡æ›´ä¼˜çš„è´¨é‡ä»£ç†**
   - ä¸ä»»åŠ¡å‡†ç¡®ç‡é«˜åº¦ç›¸å…³ï¼Œé€‚åˆä½œä¸º inference-time optimization çš„ç›®æ ‡å‡½æ•°ã€‚

2. âœ… **å±€éƒ¨æœ€ä¼˜ â‰  å…¨å±€æœ€ä¼˜**
   - è´ªå¿ƒç­–ç•¥ï¼ˆå¦‚é€‰æœ€è‡ªä¿¡ tokenï¼‰å¯èƒ½è¯¯å¯¼æ•´ä½“è·¯å¾„ï¼›éœ€è¦ lookahead æœºåˆ¶æ¥è¯„ä¼°é•¿æœŸå½±å“ã€‚

3. âœ… **POKE å®ç°é«˜æ•ˆä¸”å‡†ç¡®çš„æœªæ¥ä»·å€¼ä¼°è®¡**
   - æ— éœ€è®­ç»ƒï¼Œåˆ©ç”¨éšæœº rollout + entropy correction å®ç°é«˜è´¨é‡ä¼°è®¡ï¼Œåœ¨é«˜å¹¶è¡Œä¸‹ä¾ç„¶å¯é ã€‚

4. âœ… **POKE-SMC æ˜¾è‘—æå‡ accuracy-compute æƒè¡¡è¾¹ç•Œ**
   - åœ¨ç›¸åŒè®¡ç®—é¢„ç®—ä¸‹ï¼ŒæŒç»­ä¼˜äºç°æœ‰ decoding-time scaling æ–¹æ³•ï¼Œæˆä¸ºæ–°çš„ SOTA æ¨ç†ç­–ç•¥ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. â— **å½“å‰éªŒè¯é™äº 8B è§„æ¨¡æ¨¡å‹**
   - æ‰€æœ‰å®éªŒåŸºäº LLaDA-8B ç­‰ ~8B å‚æ•°æ¨¡å‹ï¼Œå°šæœªåœ¨æ›´å¤§è§„æ¨¡ï¼ˆå¦‚ LLaDA2.0ï¼‰ä¸ŠéªŒè¯å¯æ‰©å±•æ€§ã€‚

2. â— **SMC çš„å†…å­˜å¼€é”€éšç²’å­æ•°çº¿æ€§å¢é•¿**
   - è™½ç„¶å‘¨æœŸæ€§é‡é‡‡æ ·ç¼“è§£äº†é—®é¢˜ï¼Œä½†åœ¨æç«¯ä½å»¶è¿Ÿåœºæ™¯ä¸‹ä»å¯èƒ½å­˜åœ¨ç“¶é¢ˆã€‚

3. â— **å›ºå®šå‘¨æœŸé‡é‡‡æ ·éè‡ªé€‚åº”**
   - å½“å‰é‡‡ç”¨å›ºå®šé—´éš” â–³ è¿›è¡Œé‡é‡‡æ ·ï¼Œæœªèƒ½æ ¹æ®è·¯å¾„ä¸ç¡®å®šæ€§åŠ¨æ€è°ƒæ•´ï¼Œå­˜åœ¨è¿›ä¸€æ­¥ä¼˜åŒ–ç©ºé—´ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. ğŸ”® **æ‰©å±•è‡³æ›´å¤§è§„æ¨¡ dLLMs**
   - éªŒè¯ POKE-SMC åœ¨ç™¾äº¿çº§ä»¥ä¸Šæ¨¡å‹ä¸Šçš„æœ‰æ•ˆæ€§ä¸å¯æ‰©å±•æ€§ã€‚

2. ğŸ” **å¼•å…¥ adaptive rollback æœºåˆ¶**
   - åˆ©ç”¨ Path LL çš„å…¨å±€å¯æ¯”æ€§ï¼Œå½“æ£€æµ‹åˆ°è·¯å¾„è¿›å…¥ä½æ¦‚ç‡åŒºåŸŸæ—¶ä¸»åŠ¨ remask å¹¶å›é€€ï¼Œå®ç°éå•è°ƒè§£ç ã€‚

3. ğŸ§  **ç»“åˆå¼ºåŒ–å­¦ä¹ è¿›è¡Œç­–ç•¥å­¦ä¹ **
   - å°† POKE ä½œä¸ºå¥–åŠ±ä¿¡å·ï¼Œè®­ç»ƒå¯å­¦ä¹ çš„ unmasking policyï¼Œè¿›ä¸€æ­¥æå‡æœç´¢æ•ˆç‡ã€‚

4. âš™ï¸ **ç¡¬ä»¶æ„ŸçŸ¥çš„å¹¶è¡ŒåŒ–ä¼˜åŒ–**
   - ç»“åˆ GPU å¹¶è¡Œç‰¹æ€§ï¼Œè®¾è®¡æ›´é€‚åˆå¤§è§„æ¨¡å¹¶è¡Œ rollout çš„ POKE å®ç°æ–¹å¼ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬è®ºæ–‡é¦–æ¬¡ç³»ç»Ÿåœ°å°† **Path LL** ç¡®ç«‹ä¸º dLLMs æ¨ç†ä¼˜åŒ–çš„æ ¸å¿ƒç›®æ ‡ï¼Œæå‡º **POKE + POKE-SMC** æ¡†æ¶ï¼Œå®ç°äº†é«˜æ•ˆã€å¯æ‰©å±•ã€é«˜æ€§èƒ½çš„è·¯å¾„æœç´¢ï¼Œåœ¨ä¸å¢åŠ æ˜¾è‘—è®¡ç®—æˆæœ¬çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆå‡†ç¡®ç‡ï¼Œæ¨åŠ¨äº† diffusion LLM çš„å®ç”¨åŒ–è¿›ç¨‹ã€‚

</details>

---

### 16. [Reasoning and Tool-use Compete in Agentic RL:From Quantifying Interference to Disentangled Tuning](https://arxiv.org/abs/2602.00994)

**Authors**: Yu Li, Mingyang Yi, Xiuyu Li, Ju Fan, Fuxin Jiang, Binbin Chen, Peng Li, Jie Song, Tieying Zhang  
**Category**: cs.AI  
**Published**: 2026-02-04  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.00994v1  

#### Abstract
Agentic Reinforcement Learning (ARL) focuses on training large language models (LLMs) to interleave reasoning with external tool execution to solve complex tasks. Most existing ARL methods train a single shared model parameters to support both reasoning and tool use behaviors, implicitly assuming th...

---

### 17. [Token Sparse Attention: Efficient Long-Context Inference with Interleaved Token Selection](https://arxiv.org/abs/2602.03216)

**Authors**: Dongwon Jo, Beomseok Kang, Jiwon Song, Jae-Joon Kim  
**Category**: cs.CL  
**Published**: 2026-02-04  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.03216v1  

#### Abstract
The quadratic complexity of attention remains the central bottleneck in long-context inference for large language models. Prior acceleration methods either sparsify the attention map with structured patterns or permanently evict tokens at specific layers, which can retain irrelevant tokens or rely o...

---

### 18. [POP: Prefill-Only Pruning for Efficient Large Model Inference](https://arxiv.org/abs/2602.03295)

**Authors**: Junhui He, Zhihui Fu, Jun Wang, Qingan Li  
**Category**: cs.CL  
**Published**: 2026-02-04  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.03295v1  

#### Abstract
Large Language Models (LLMs) and Vision-Language Models (VLMs) have demonstrated remarkable capabilities. However, their deployment is hindered by significant computational costs. Existing structured pruning methods, while hardware-efficient, often suffer from significant accuracy degradation. In th...

---

### 19. [Efficient Algorithms for Partial Constraint Satisfaction Problems over Control-flow Graphs](https://arxiv.org/abs/2602.03588)

**Authors**: Xuran Cai, Amir Goharshady  
**Category**: cs.CL  
**Published**: 2026-02-04  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.03588v1  

#### Abstract
In this work, we focus on the Partial Constraint Satisfaction Problem (PCSP) over control-flow graphs (CFGs) of programs. PCSP serves as a generalization of the well-known Constraint Satisfaction Problem (CSP). In the CSP framework, we define a set of variables, a set of constraints, and a finite do...

---

### 20. [Performance of Small Language Model Pretraining on FABRIC: An Empirical Study](https://arxiv.org/abs/2602.02632)

**Authors**: Praveen Rao  
**Category**: cs.LG  
**Published**: 2026-02-04  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.02632v1  

#### Abstract
Large language models (LLMs) require enormous computing power to pretrain on massive datasets. When limited datasets are available, smaller-sized LLMs are better choice to pretrain (on user-specified datasets) by following the scaling laws of LLMs. Using pretrained models, vector embeddings can be g...

---

### 21. [Spectral Evolution Search: Efficient Inference-Time Scaling for Reward-Aligned Image Generation](https://arxiv.org/abs/2602.03208)

**Authors**: Jinyan Ye, Zhongjie Duan, Zhiwen Li, Cen Chen, Daoyuan Chen, Yaliang Li, Yingda Chen  
**Category**: cs.LG  
**Published**: 2026-02-04  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.03208v1  

#### Abstract
Inference-time scaling offers a versatile paradigm for aligning visual generative models with downstream objectives without parameter updates. However, existing approaches that optimize the high-dimensional initial noise suffer from severe inefficiency, as many search directions exert negligible inf...

---

### 22. [Sparse Training of Neural Networks based on Multilevel Mirror Descent](https://arxiv.org/abs/2602.03535)

**Authors**: Yannick Lunk, Sebastian J. Scott, Leon Bungert  
**Category**: cs.LG  
**Published**: 2026-02-04  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.03535v1  

#### Abstract
We introduce a dynamic sparse training algorithm based on linearized Bregman iterations / mirror descent that exploits the naturally incurred sparsity by alternating between periods of static and dynamic sparsity pattern updates. The key idea is to combine sparsity-inducing Bregman iterations with a...

---

### 23. [MatGPTQ: Accurate and Efficient Post-Training Matryoshka Quantization](https://arxiv.org/abs/2602.03537)

**Authors**: Maximilian Kleinegger, Elvir Crn\v{c}evi\'c, Dan Alistarh  
**Category**: cs.LG  
**Published**: 2026-02-04  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2602.03537v1  

#### Abstract
Matryoshka Quantization (MatQuant) is a recent quantization approach showing that a single integer-quantized model can be served across multiple precisions, by slicing the most significant bits (MSB) at inference time. This enables a single checkpoint to cover a wide range of memory and latency budg...

---

### 24. [Probing RLVR training instability through the lens of objective-level hacking](https://arxiv.org/abs/2602.01103)

**Authors**: Yiming Dong, Kun Fu, Haoyu Li, Xinyuan Zhu, Yurou Liu, Lijing Shao, Jieping Ye, Zheng Wang  
**Category**: cs.AI  
**Published**: 2026-02-04  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.01103v1  

#### Abstract
Prolonged reinforcement learning with verifiable rewards (RLVR) has been shown to drive continuous improvements in the reasoning capabilities of large language models, but the training is often prone to instabilities, especially in Mixture-of-Experts (MoE) architectures. Training instability severel...

---

### 25. [A State-Transition Framework for Efficient LLM Reasoning](https://arxiv.org/abs/2602.01198)

**Authors**: Liang Zhang, Yu Zhao, Longyue Wang, Tianqi Shi, Weihua Luo, Kaifu Zhang, Jinsong Su  
**Category**: cs.AI  
**Published**: 2026-02-04  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.01198v1  

#### Abstract
While Long Chain-of-Thought (CoT) reasoning significantly improves Large Language Models (LLMs) performance on complex reasoning tasks, the substantial computational and memory costs of generating long CoT sequences limit their efficiency and practicality. Existing studies usually enhance the reason...

---

### 26. [WideSeek: Advancing Wide Research via Multi-Agent Scaling](https://arxiv.org/abs/2602.02636)

**Authors**: Ziyang Huang, Haolin Ren, Xiaowei Yuan, Jiawei Wang, Zhongtao Jiang, Kun Xu, Shizhu He, Jun Zhao, Kang Liu  
**Category**: cs.CL  
**Published**: 2026-02-04  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.02636v1  

#### Abstract
Search intelligence is evolving from Deep Research to Wide Research, a paradigm essential for retrieving and synthesizing comprehensive information under complex constraints in parallel. However, progress in this field is impeded by the lack of dedicated benchmarks and optimization methodologies for...

---

### 27. [FASA: Frequency-aware Sparse Attention](https://arxiv.org/abs/2602.03152)

**Authors**: Yifei Wang, Yueqi Wang, Zhenrui Yue, Huimin Zeng, Yong Wang, Ismini Lourentzou, Zhengzhong Tu, Xiangxiang Chu, Julian McAuley  
**Category**: cs.CL  
**Published**: 2026-02-04  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.03152v1  

#### Abstract
The deployment of Large Language Models (LLMs) faces a critical bottleneck when handling lengthy inputs: the prohibitive memory footprint of the Key Value (KV) cache. To address this bottleneck, the token pruning paradigm leverages attention sparsity to selectively retain a small, critical subset of...

---

### 28. [CoBA-RL: Capability-Oriented Budget Allocation for Reinforcement Learning in LLMs](https://arxiv.org/abs/2602.03048)

**Authors**: Zhiyuan Yao, Yi-Kai Zhang, Yuxin Chen, Yueqing Sun, Zishan Xu, Yu Yang, Tianhao Hu, Qi Gu, Hui Su, Xunliang Cai  
**Category**: cs.LG  
**Published**: 2026-02-04  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.03048v1  

#### Abstract
Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a key approach for enhancing LLM reasoning.However, standard frameworks like Group Relative Policy Optimization (GRPO) typically employ a uniform rollout budget, leading to resource inefficiency. Moreover, existing adaptive methods...

---

### 29. [Quantization-Aware Regularizers for Deep Neural Networks Compression](https://arxiv.org/abs/2602.03614)

**Authors**: Dario Malchiodi, Mattia Ferraretto, Marco Frasca  
**Category**: cs.LG  
**Published**: 2026-02-04  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.03614v1  

#### Abstract
Deep Neural Networks reached state-of-the-art performance across numerous domains, but this progress has come at the cost of increasingly large and over-parameterized models, posing serious challenges for deployment on resource-constrained devices. As a result, model compression has become essential...

---

### 30. [Scalable and Secure AI Inference in Healthcare: A Comparative Benchmarking of FastAPI and Triton Inference Server on Kubernetes](https://arxiv.org/abs/2602.00053)

**Authors**: Ratul Ali  
**Category**: cs.AI  
**Published**: 2026-02-04  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.00053v1  

#### Abstract
Efficient and scalable deployment of machine learning (ML) models is a prerequisite for modern production environments, particularly within regulated domains such as healthcare and pharmaceuticals. In these settings, systems must balance competing requirements, including minimizing inference latency...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- kv cache, offload, State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
