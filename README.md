# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-01-23 06:00:21 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [PhysProver: Advancing Automatic Theorem Proving for Physics](https://arxiv.org/abs/2601.15737)

**Authors**: Hanning Zhang, Ruida Wang, Rui Pan, Wenyuan Wang, Bingxu Meng, Tong Zhang  
**Category**: cs.AI  
**Published**: 2026-01-23  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2601.15737v1  

#### Abstract
The combination of verifiable languages and LLMs has significantly influenced both the mathematical and computer science communities because it provides a rigorous foundation for theorem proving. Recent advancements in the field provide foundation models and sophisticated agentic systems pushing the...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡ã€ŠPhysProver: Advancing Automatic Theorem Proving for Physicsã€‹æ ¸å¿ƒæ€»ç»“**

---

## **1. ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
- å½“å‰çš„ **formal theorem proving**ï¼ˆå½¢å¼åŒ–å®šç†è¯æ˜ï¼‰ç ”ç©¶ä¸»è¦é›†ä¸­äºæ•°å­¦é¢†åŸŸï¼ˆå¦‚ Lean4 ä¸­çš„æ•°å­¦å®šç†ï¼‰ï¼Œè€Œ **formal physics reasoning**ï¼ˆå½¢å¼åŒ–ç‰©ç†æ¨ç†ï¼‰é•¿æœŸè¢«å¿½è§†ã€‚
- å°½ç®¡ç‰©ç†é—®é¢˜åŒæ ·ä¾èµ–ä¸¥è°¨çš„æ•°å­¦æ¨å¯¼å’Œå®šç†è¯æ˜ï¼Œä½†ç°æœ‰çš„ SOTA æ•°å­¦å®šç†è¯æ˜æ¨¡å‹åœ¨ç‰©ç†ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ï¼ˆLi et al., 2025ï¼‰ï¼Œä¸”ç¼ºä¹ä¸“é—¨çš„æ•°æ®é›†å’Œè®­ç»ƒæ–¹æ³•ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯**
- **é¦–æ¬¡ç³»ç»Ÿæ€§åœ°æ¨è¿›ç‰©ç†é¢†åŸŸçš„è‡ªåŠ¨å®šç†è¯æ˜**ï¼Œæå‡ºäº† **PhysProver** æ¡†æ¶ã€‚
- æ„å»ºäº†é¦–ä¸ªé¢å‘ç‰©ç†çš„å½¢å¼åŒ–å®šç†æ•°æ®é›†ï¼š**PhysLeanData**ï¼ŒåŒ…å«çº¦ 5,541 æ¡è®­ç»ƒæ ·æœ¬å’Œ 250 æ¡æµ‹è¯•æ ·æœ¬ã€‚
  - æ•°æ®æ¥æºï¼š
    - ä»å¼€æºé¡¹ç›® **PhysLean**ï¼ˆTooby-Smith, 2025ï¼‰ä¸­æå–çœŸå®ç‰©ç†å®šç†ã€‚
    - è®¾è®¡äº†ä¸€ä¸ªåŸºäº **Claude-4.5-Sonnet** çš„ **conjecture-based formal data generation pipeline**ï¼Œç”Ÿæˆå¹¶éªŒè¯æ–°çš„ç‰©ç†çŒœæƒ³ã€‚
- é‡‡ç”¨ **Reinforcement Learning with Verifiable Rewards (RLVR)** è¿›è¡Œè®­ç»ƒï¼Œå…·ä½“ä½¿ç”¨ **GRPO**ï¼ˆGroup Relative Policy Optimizationï¼‰ç®—æ³•ï¼Œä»¥ Lean è¯æ˜å™¨çš„éªŒè¯ç»“æœä½œä¸ºå¥–åŠ±ä¿¡å·ï¼ˆreward = 1 if `Verify(proof) == True`ï¼‰ã€‚
- å¼•å…¥ **curriculum learning**ï¼ŒæŒ‰è¯æ˜é•¿åº¦æ’åºè¿›è¡Œç”±æ˜“åˆ°éš¾çš„å­¦ä¹ ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- **å°æ•°æ®é«˜æ•ˆè®­ç»ƒ**ï¼šä»…ç”¨ ~5K æ ·æœ¬å³å®ç°æ˜¾è‘—æå‡ï¼Œè¿œä½äºä¼ ç»Ÿæ•°å­¦å®šç†è¯æ˜æ¨¡å‹æ‰€éœ€çš„æ•°ç™¾ä¸‡æ¡æ•°æ®ã€‚
- **è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›**ï¼šä¸ä»…æå‡äº†ç‰©ç†é¢†åŸŸçš„è¡¨ç°ï¼Œè¿˜åœ¨ **MiniF2F-Test**ï¼ˆçº¯æ•°å­¦åŸºå‡†ï¼‰ä¸Šå®ç°äº† 1.3% çš„å¢ç›Šï¼Œè¡¨æ˜ç‰©ç†è®­ç»ƒå¯åå“ºæ•°å­¦æ¨ç†èƒ½åŠ›ã€‚
- **è½»é‡çº§ä¸“å®¶æ¨¡å‹æ½œåŠ›**ï¼š7B å‚æ•°çš„ PhysProver è¶…è¶Šäº† GPT-5 å’Œ Claude-4.5-Sonnet ç­‰å¤§æ¨¡å‹ï¼Œåœ¨å¤šä¸ªç‰©ç†å­é¢†åŸŸè¾¾åˆ° SOTAã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **PhysLeanData**ï¼š
  - **ç§å­æ•°æ®**ï¼šä» PhysLean ä»“åº“æå– 2,933 æ¡å·²è¯æ˜çš„ç‰©ç†å¼•ç†ï¼ˆlemmaï¼‰åŠå…¶ä¸Šä¸‹æ–‡ï¼ˆheaderï¼‰å’Œè¯æ˜è„šæœ¬ã€‚
  - **åˆæˆæ•°æ®**ï¼šä½¿ç”¨ **Claude-4.5-Sonnet** å¯¹æ¯æ¡ç§å­ç”Ÿæˆ 10 ä¸ªçŒœæƒ³ï¼Œå…± 29,330 æ¡å€™é€‰ã€‚
    - ç»è¿‡ä¸¤é˜¶æ®µè¿‡æ»¤ï¼š
      1. **è¯­æ³•æ£€æŸ¥**ï¼šé€šè¿‡ Lean ç¼–è¯‘å™¨éªŒè¯è¯­å¥æ˜¯å¦åˆæ³•ï¼ˆä¿ç•™ 6,971 æ¡ï¼‰ã€‚
      2. **å¯è¯æ€§æ£€æŸ¥**ï¼šä½¿ç”¨å¤šä¸ª SOTA proverï¼ˆDeepSeek-Prover-V2-7Bã€Kimina-Prover-Distill-8Bã€Goedel-Prover-V2-8Bï¼‰å°è¯•è¯æ˜ï¼Œè‡³å°‘ä¸€ä¸ªæˆåŠŸåˆ™ä¿ç•™ï¼ˆæœ€ç»ˆä¿ç•™ 2,608 æ¡ï¼‰ã€‚
  - æ€»è®¡ï¼š**5,541 æ¡è®­ç»ƒæ ·æœ¬**ï¼Œ**250 æ¡æµ‹è¯•æ ·æœ¬**ï¼ˆ9:1 åˆ’åˆ†ï¼‰ã€‚

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**
- **æ¨¡å‹æ¶æ„**ï¼šåŸºäº **DeepSeek-Prover-V2-7B** å¾®è°ƒå¾—åˆ° **PhysProver**ã€‚
- **è®­ç»ƒæ–¹å¼**ï¼š
  - ä½¿ç”¨ **GRPO** è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œå¥–åŠ±æ¥è‡ª Lean 4.20.0 çš„å½¢å¼åŒ–éªŒè¯ç»“æœã€‚
  - è‹¥è¯æ˜ä¸­åŒ…å« `sorry`, `admit`, `apply?` ç­‰å ä½ç¬¦ï¼Œåˆ™ç›´æ¥ç»™ reward=0ï¼Œé˜²æ­¢ reward hackingã€‚
  - é‡‡ç”¨ **curriculum learning**ï¼ŒæŒ‰çœŸå®è¯æ˜é•¿åº¦æ’åºè®­ç»ƒæ ·æœ¬ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **pass@16**ï¼šç”Ÿæˆ 16 æ¡è¯æ˜è·¯å¾„ï¼Œåªè¦æœ‰ 1 æ¡é€šè¿‡ Lean éªŒè¯å³ä¸ºæˆåŠŸã€‚
  - æµ‹è¯•é›†åˆ†ä¸ºå››ä¸ªç‰©ç†å­é¢†åŸŸï¼š
    - Classical & Foundational Physics
    - Particle & String Physics
    - Relativity & Spacetime
    - Quantum Field Theory

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| ç±»å‹ | æ¨¡å‹ |
|------|------|
| **å¼€æºæ•°å­¦å®šç†è¯æ˜å™¨** | Kimina-Prover-Distill-8B, Goedel-Prover-V2-8B, DeepSeek-Prover-V2-7B |
| **é—­æºå¤§æ¨¡å‹** | GPT-5 (OpenAI, 2025), Claude-4.5-Sonnet (Anthropic, 2025) |
| **æœ¬å·¥ä½œæ¨¡å‹** | **PhysProver**ï¼ˆåŸºäº DeepSeek-Prover-V2-7B + RLVR on PhysLeanDataï¼‰ |

æ‰€æœ‰æ¨¡å‹å‡ä½¿ç”¨ç›¸åŒé‡‡æ ·é¢„ç®—ï¼ˆpass@16ï¼‰ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰**

| æ–¹æ³• | Classical | Particle & String | Relativity | QFT | **Overall** |
|------|-----------|-------------------|------------|-----|-------------|
| GPT-5 | 37.3% | 13.4% | 21.3% | 35.2% | 26.4% |
| Claude-4.5-Sonnet | 52.9% | 19.4% | 29.5% | 39.4% | 34.4% |
| DeepSeek-Prover-V2-7B | 54.9% | 23.9% | 37.7% | 25.4% | 34.0% |
| **PhysProver** | **58.8% (+3.9%)** | **26.9% (+3.0%)** | **39.3% (+1.6%)** | **26.8% (+1.4%)** | **36.4% (+2.4%)** |

- **æ€»ä½“æå‡ 2.4%**ï¼Œåœ¨æ‰€æœ‰å­é¢†åŸŸå‡æœ‰ç¨³å®šå¢ç›Šã€‚
- åœ¨æœ€å…·æŒ‘æˆ˜æ€§çš„ **Particle & String Physics** ä¸Šæå‡æœ€å¤§ï¼ˆ+3.0%ï¼‰ï¼Œè¯´æ˜æ¨¡å‹èƒ½æœ‰æ•ˆå¤„ç†é«˜èƒ½ç‰©ç†ç­‰å¤æ‚ç†è®ºã€‚
- **PhysProver è¶…è¶Šæ‰€æœ‰åŸºçº¿æ¨¡å‹**ï¼ŒåŒ…æ‹¬ GPT-5 å’Œ Claude-4.5-Sonnetã€‚

### **è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›ï¼ˆTable 2ï¼‰**
åœ¨ **MiniF2F-Test**ï¼ˆçº¯æ•°å­¦ Lean å®šç†é›†åˆï¼‰ä¸Šçš„ out-of-distribution è¡¨ç°ï¼š

| ç±»åˆ« | DeepSeek-Prover-V2 | +PhysLeanData (PhysProver) |
|------|--------------------|----------------------------|
| MATH Algebra | 90.0% | **92.9%** |
| MATH Number Theory | 85.0% | **88.3%** |
| **Overall Pass Rate** | 68.4% | **69.7%** |

- åœ¨æ•°å­¦ä»»åŠ¡ä¸Šè·å¾— **+1.3%** çš„æå‡ï¼Œè¡¨æ˜ç‰©ç†è®­ç»ƒå¢å¼ºäº†é€šç”¨å½¢å¼åŒ–æ¨ç†èƒ½åŠ›ã€‚
- ä½†åœ¨æœ€éš¾çš„ Olympiad çº§åˆ«ï¼ˆå¦‚ AIMEï¼‰æœªè§æå‡ç”šè‡³ç•¥æœ‰ä¸‹é™ï¼Œè¯´æ˜ç‰©ç†è®­ç»ƒä¸èƒ½å®Œå…¨æ›¿ä»£æ•°å­¦ä¸“é¡¹è®­ç»ƒã€‚

### **æ¶ˆèå®éªŒç»“æœï¼ˆTable 3 & 4ï¼‰**

#### **Supervised Fine-Tuning (SFT) vs RAFT vs GRPO**

| æ–¹æ³• | Overall Accuracy | å˜åŒ– |
|------|------------------|------|
| DeepSeek-Prover-V2-7B | 34.0% | â€” |
| + SFT (äººç±»æ ‡æ³¨æ•°æ®) | 27.6% | **â†“6.4%** |
| + RAFT (æ‹’ç»é‡‡æ ·æ­£ç¡®è¯æ˜) | 35.6% | â†‘1.6% |
| + GRPO (æœ¬æ–‡æ–¹æ³•) | **36.4%** | â†‘2.4% |

- **SFT å¯¼è‡´æ€§èƒ½ä¸¥é‡ä¸‹é™**ï¼Œä½œè€…åˆ†æåŸå› æ˜¯äººç±»ç¼–å†™çš„è¯æ˜æ˜¯ **Out-of-Distribution (OOD)**ï¼Œä¸æ¨¡å‹ç”Ÿæˆåˆ†å¸ƒä¸åŒ¹é…ã€‚
- **RAFTï¼ˆRejection Sampling Fine-tuningï¼‰** ä½¿ç”¨æ¨¡å‹è‡ªå·±ç”Ÿæˆçš„æ­£ç¡®è¯æ˜è¿›è¡Œå¾®è°ƒï¼Œå±äº **In-Distribution (ID)** æ•°æ®ï¼Œå¸¦æ¥æ­£å‘æ”¶ç›Šã€‚
- **GRPO æ•ˆæœæœ€å¥½**ï¼Œè¯´æ˜å¼ºåŒ–å­¦ä¹ æ›´é€‚åˆä½èµ„æºä¸‹çš„å½¢å¼åŒ–ä»»åŠ¡ã€‚

#### **Perplexity åˆ†æï¼ˆTable 4ï¼‰**
| æ¨¡å‹ | è®­ç»ƒé›†å¹³å‡å›°æƒ‘åº¦ | æµ‹è¯•é›†å¹³å‡å›°æƒ‘åº¦ |
|------|------------------|------------------|
| DS-Prover-SFT | 1.817 | 1.711 |
| DS-Prover-RAFT | 1.321 | 1.186 |
| DS-Prover-GRPO | **1.141** | **1.209** |

- GRPO å’Œ RAFT çš„å›°æƒ‘åº¦æ˜¾è‘—æ›´ä½ï¼Œè¯´æ˜æ¨¡å‹æ›´â€œè‡ªä¿¡â€ï¼Œè¾“å‡ºæ›´ä¸€è‡´ï¼Œè§£é‡Šäº†å…¶æ€§èƒ½ä¼˜åŠ¿ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **ç‰©ç†å½¢å¼åŒ–æ¨ç†æ˜¯ä¸€ä¸ªé‡è¦ä½†è¢«å¿½è§†çš„æ–¹å‘**ï¼Œç°æœ‰æ•°å­¦å®šç†è¯æ˜å™¨åœ¨æ­¤ç±»ä»»åŠ¡ä¸Šè¡¨ç°æœ‰é™ã€‚
2. **é«˜è´¨é‡çš„å°è§„æ¨¡é¢†åŸŸä¸“ç”¨æ•°æ®é›†ï¼ˆå¦‚ PhysLeanDataï¼‰è¶³ä»¥æ˜¾è‘—æå‡æ€§èƒ½**ï¼Œæ— éœ€æµ·é‡æ•°æ®ã€‚
3. **RLVRï¼ˆç‰¹åˆ«æ˜¯ GRPOï¼‰æ¯” SFT æ›´é€‚åˆå½¢å¼åŒ–å®šç†è¯æ˜ä»»åŠ¡**ï¼Œå°¤å…¶æ˜¯åœ¨ç›®æ ‡æ•°æ®ä¸é¢„è®­ç»ƒåˆ†å¸ƒå·®å¼‚è¾ƒå¤§æ—¶ã€‚
4. **ç‰©ç†è®­ç»ƒä¸ä»…èƒ½æå‡ç‰©ç†æ¨ç†èƒ½åŠ›ï¼Œè¿˜èƒ½å¢å¼ºæ•°å­¦æ³›åŒ–èƒ½åŠ›**ï¼Œæ­ç¤ºäº†ç‰©ç†ä¸æ•°å­¦å½¢å¼æ¨ç†ä¹‹é—´çš„æ·±å±‚è”ç³»ã€‚
5. **è½»é‡çº§ä¸“å®¶æ¨¡å‹ï¼ˆå¦‚ 7B çš„ PhysProverï¼‰å¯ä»¥åœ¨ç‰¹å®šé¢†åŸŸè¶…è¶Šå¤§å‹é€šç”¨æ¨¡å‹**ï¼Œä¸ºé«˜æ•ˆä¸“ä¸šåŒ–æ¨¡å‹è®­ç»ƒæä¾›æ–°èŒƒå¼ã€‚

### **å±€é™æ€§**
- **æ•°æ®æ¥æºå•ä¸€**ï¼šPhysLeanData å®Œå…¨æ¥è‡ª PhysLean ä»“åº“ï¼Œå¯èƒ½æ— æ³•è¦†ç›–æ‰€æœ‰ç‰©ç†åˆ†æ”¯ï¼ŒæŸäº›é¢†åŸŸå­˜åœ¨åå·®ã€‚
- **åˆæˆæ•°æ®æ•ˆç‡ä½**ï¼šconjecture pipeline çš„æ•´ä½“ yield rate ä»…ä¸º **8.9%**ï¼Œå¤§é‡è®¡ç®—èµ„æºç”¨äºæ— æ•ˆç”Ÿæˆä¸éªŒè¯ã€‚
- **è®¡ç®—èµ„æºå—é™**ï¼šæœªèƒ½æ‰©å±•æ›´å¤§è§„æ¨¡çš„æ•°æ®ç”Ÿæˆæˆ–æ¨¡å‹è®­ç»ƒã€‚
- **SFT å¤±æ•ˆæœºåˆ¶éœ€è¿›ä¸€æ­¥ç ”ç©¶**ï¼šä¸ºä½•æ ‡å‡†å¾®è°ƒåè€ŒæŸå®³æ€§èƒ½ï¼Œä»éœ€æ›´å¤šç†è®ºè§£é‡Šã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ‰©å±• PhysLeanData è‡³æ›´å¤šç‰©ç†é¢†åŸŸï¼ˆå¦‚å‡èšæ€ã€å¤©ä½“ç‰©ç†ç­‰ï¼‰ã€‚
- æ”¹è¿› conjecture generation pipelineï¼Œæé«˜ç”Ÿæˆè´¨é‡å’ŒæˆåŠŸç‡ã€‚
- æ¢ç´¢å¤šæ¨¡æ€ç‰©ç†å®šç†ï¼ˆç»“åˆå›¾åƒã€å…¬å¼ã€è‡ªç„¶è¯­è¨€æè¿°ï¼‰çš„å½¢å¼åŒ–è¡¨ç¤ºã€‚
- ç ”ç©¶å¦‚ä½•å°†ç‰©ç†ç›´è§‰ï¼ˆphysical intuitionï¼‰èå…¥å½¢å¼åŒ–æ¨ç†æ¡†æ¶ã€‚
- å¼€æ”¾ **PhysLeanData æ•°æ®é›†** å’Œ **PhysProver æ¨¡å‹æƒé‡**ï¼Œæ¨åŠ¨ç¤¾åŒºå‘å±•ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> PhysProver æ˜¯é¦–ä¸ªä¸“ä¸ºç‰©ç†é¢†åŸŸè®¾è®¡çš„å½¢å¼åŒ–å®šç†è¯æ˜å™¨ï¼Œé€šè¿‡æ„å»ºé«˜è´¨é‡å°æ•°æ®é›† **PhysLeanData** å¹¶é‡‡ç”¨ **RLVR + GRPO** è®­ç»ƒç­–ç•¥ï¼Œåœ¨ä»… 5K æ ·æœ¬ä¸‹å®ç°å…¨é¢è¶…è¶Šï¼Œå¹¶å±•ç°å‡ºå‘æ•°å­¦é¢†åŸŸçš„æ­£å‘è¿ç§»èƒ½åŠ›ï¼Œæ ‡å¿—ç€å½¢å¼åŒ–æ¨ç†ä»æ•°å­¦è¿ˆå‘ç‰©ç†ç§‘å­¦çš„é‡è¦ä¸€æ­¥ã€‚

</details>

---

### 2. [Securing LLM-as-a-Service for Small Businesses: An Industry Case Study of a Distributed Chatbot Deployment Platform](https://arxiv.org/abs/2601.15528)

**Authors**: Jiazhu Xie, Bowen Li, Heyu Fu, Chong Gao, Ziqi Xu, Fengling Han  
**Category**: cs.DC  
**Published**: 2026-01-23  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2601.15528v1  

#### Abstract
Large Language Model (LLM)-based question-answering systems offer significant potential for automating customer support and internal knowledge access in small businesses, yet their practical deployment remains challenging due to infrastructure costs, engineering complexity, and security risks, parti...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Securing LLM-as-a-Service for Small Businesses*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**å°å‹ä¼ä¸šåœ¨éƒ¨ç½²åŸºäº Large Language Model (LLM) çš„å®¢æœèŠå¤©æœºå™¨äººæ—¶é¢ä¸´çš„ä¸‰å¤§æŒ‘æˆ˜**ï¼š
- **é«˜æ˜‚çš„åŸºç¡€è®¾æ–½æˆæœ¬**ï¼ˆå¦‚äº‘GPUæœåŠ¡è´¹ç”¨ï¼‰
- **ç¼ºä¹ä¸“ä¸šçš„å·¥ç¨‹å›¢é˜Ÿ**å¯¼è‡´éƒ¨ç½²å¤æ‚
- **å®‰å…¨é£é™©çªå‡º**ï¼Œå°¤å…¶æ˜¯ Retrieval-Augmented Generation (RAG) æ¶æ„ä¸‹çš„ **prompt injection æ”»å‡»**

è¿™äº›é—®é¢˜ä½¿å¾—å¤§å¤šæ•°å°ä¼ä¸šéš¾ä»¥å®‰å…¨ã€ä½æˆæœ¬åœ°é‡‡ç”¨ LLM æŠ€æœ¯ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

ä½œè€…è®¾è®¡å¹¶å®ç°äº†ä¸€ä¸ª**å¼€æºã€å¤šç§Ÿæˆ·ã€åˆ†å¸ƒå¼ LLM èŠå¤©æœºå™¨äººéƒ¨ç½²å¹³å°**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰åŸºäºè½»é‡çº§ k3s é›†ç¾¤çš„è¾¹ç¼˜ç§æœ‰äº‘æ¶æ„
- ä½¿ç”¨ **lightweight k3s**ï¼ˆKubernetes çš„è½»é‡å‘è¡Œç‰ˆï¼‰æ„å»ºè·¨å¼‚æ„ä½åŠŸè€—è®¾å¤‡çš„åˆ†å¸ƒå¼é›†ç¾¤
- é€šè¿‡åŠ å¯† **overlay network** è¿æ¥å¤šä¸ªåœ°ç†ä½ç½®åˆ†æ•£çš„èŠ‚ç‚¹ï¼Œå®ç°èµ„æºæ± åŒ–
- æ”¯æŒåœ¨ä½æˆæœ¬ç¡¬ä»¶ä¸Šè¿è¡Œ LLM æ¨ç†ä»»åŠ¡ï¼ˆä¾‹å¦‚ä½¿ç”¨ DGX Spark åŠ é€Ÿå™¨è€Œéä¸“ç”¨ GPUï¼‰

> âœ… ä¼˜åŠ¿ï¼šæ˜¾è‘—é™ä½éƒ¨ç½²æˆæœ¬ï¼Œé€‚åˆèµ„æºå—é™çš„å°å‹ä¼ä¸šç¯å¢ƒã€‚

#### ï¼ˆ2ï¼‰å®¹å™¨åŒ–éš”ç¦»ä¸å¤šç§Ÿæˆ·å®‰å…¨æ§åˆ¶
- åˆ©ç”¨ **container-based isolation** å®ç°ç§Ÿæˆ·é—´çš„æ•°æ®å’Œè®¡ç®—éš”ç¦»
- å¼ºè°ƒâ€œçˆ†ç‚¸åŠå¾„æœ€å°åŒ–â€ï¼ˆlimit blast radiusï¼‰ï¼Œé˜²æ­¢ä¸€ä¸ªç§Ÿæˆ·è¢«æ”»ç ´åå½±å“å…¶ä»–ç§Ÿæˆ·

> âœ… ä¼˜åŠ¿ï¼šæ»¡è¶³ Australian Privacy Act 1988 å’Œ APPs å¯¹ä¸ªäººæ•°æ®ä¿æŠ¤çš„è¦æ±‚ã€‚

#### ï¼ˆ3ï¼‰æ— éœ€æ¨¡å‹é‡è®­ç»ƒçš„å¹³å°çº§ prompt injection é˜²å¾¡æœºåˆ¶
æå‡ºä¸€ç§**åˆ†å±‚é˜²å¾¡ç­–ç•¥**ï¼Œç»“åˆä¸¤ç§äº’è¡¥æŠ€æœ¯ï¼š
- **Guard Prompts**ï¼šåµŒå…¥ç³»ç»Ÿæç¤ºä¸­çš„ç¡¬æ€§è¡Œä¸ºçº¦æŸè§„åˆ™ï¼ˆå¦‚ç¦æ­¢è§’è‰²åˆ‡æ¢ã€æ‹’ç»è¾“å‡ºæŒ‡ä»¤ç­‰ï¼‰
- **GenTel-Shield**ï¼šä¸€ä¸ªé¢„è®­ç»ƒçš„ã€model-agnostic çš„ prompt injection æ£€æµ‹æ¨¡å‹ï¼Œç”¨äºåœ¨ç”Ÿæˆå‰è¿‡æ»¤æ¶æ„è¾“å…¥

> âœ… ä¼˜åŠ¿ï¼šä¸ä¾èµ–ç‰¹å®š LLM ç»“æ„ï¼Œæ— éœ€å¾®è°ƒæˆ–ä¿®æ”¹åº•å±‚æ¨¡å‹ï¼Œæ˜“äºé›†æˆåˆ°å¤šç§Ÿæˆ·å¹³å°ä¸­ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ¡ˆ | æœ¬æ–‡æ–¹æ¡ˆ |
|------|--------|---------|
| æˆæœ¬ | ä¾èµ–å…¬æœ‰äº‘ GPUï¼ŒæŒç»­è¿è¡Œæ˜‚è´µ | åˆ©ç”¨å·²æœ‰ä½åŠŸè€—è®¾å¤‡ + k3s èµ„æºæ± åŒ– |
| å®‰å…¨æ€§ | å¤šæ•°ç ”ç©¶èšç„¦å•ç§Ÿæˆ·æˆ–ç†è®ºæ”»å‡» | å®ç°å¤šç§Ÿæˆ·éš”ç¦» + å®æˆ˜çº§ prompt injection é˜²å¾¡ |
| æ˜“ç”¨æ€§ | éœ€è¦ AI å·¥ç¨‹èƒ½åŠ› | æä¾› no-code å·¥ä½œæµï¼Œç±»ä¼¼ Shopify |
| å¯æ‰©å±•æ€§ | ä¸­å¿ƒåŒ–æ¶æ„éš¾æ‰©å±•è‡³è¾¹ç¼˜ | åˆ†å¸ƒå¼è¾¹ç¼˜ç§æœ‰äº‘æ”¯æŒå¼¹æ€§éƒ¨ç½² |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **è‰¯æ€§æŸ¥è¯¢**ï¼šæ¥è‡ªçœŸå®ç”µå•†å…¬å¸ All Table Sports Australia (ATS) çš„å®¢æˆ·æ”¯æŒè®°å½•ï¼Œå…± **250 æ¡**
- **å¯¹æŠ—æ ·æœ¬**ï¼šä» GenTel-Safe ç ”ç©¶ [8] çš„ prompt injection æ”»å‡»æ•°æ®é›†ä¸­é€‰å–ï¼Œå¹¶é€‚é…ä¸ºç”µå•†åœºæ™¯ï¼Œå…± **250 æ¡**

> â¤ æ€»è®¡ 500 æ¡æµ‹è¯•æ ·æœ¬ï¼Œç±»åˆ«å¹³è¡¡ï¼ˆbenign vs. adversarialï¼‰

---

### âš™ï¸ å®éªŒè®¾ç½®

#### ï¼ˆ1ï¼‰å®‰å…¨è¯„ä¼°é…ç½®ï¼ˆå››ç»„å¯¹æ¯”ï¼‰
| é…ç½® | æè¿° |
|------|------|
| Pure LLM | ä¸å¯ç”¨ä»»ä½•é˜²å¾¡æœºåˆ¶ |
| Guard Prompts only | ä»…ä½¿ç”¨ç³»ç»Ÿçº§å®ˆå«æç¤º |
| GenTel-Shield only | ä»…ä½¿ç”¨æ£€æµ‹æ¨¡å‹è¿›è¡Œå‰ç½®è¿‡æ»¤ |
| Guard Prompts + GenTel-Shield | åŒå±‚è”åˆé˜²å¾¡ |

#### ï¼ˆ2ï¼‰æ€§èƒ½è¯„ä¼°ç¯å¢ƒ
| ç¯å¢ƒ | æè¿° |
|------|------|
| Bare Metal | èŠå¤©æœºå™¨äººç›´æ¥è¿è¡Œäºç‰©ç†æœåŠ¡å™¨ |
| Private Cloud (k3s) | åŸºäº k3s çš„å®¹å™¨åŒ–ç§æœ‰äº‘éƒ¨ç½² |

> â¤ æµ‹è¯•ç›¸åŒ workload ä¸‹çš„ç«¯åˆ°ç«¯å»¶è¿Ÿå·®å¼‚

#### ï¼ˆ3ï¼‰è¯„ä¼°æŒ‡æ ‡
- **å®‰å…¨æ€§**ï¼š
  - Precisionï¼ˆç²¾ç¡®ç‡ï¼‰
  - Recallï¼ˆå¬å›ç‡ï¼‰
  - F1-scoreï¼ˆç»¼åˆæ€§èƒ½ï¼‰
- **æ€§èƒ½**ï¼š
  - End-to-end inference latencyï¼ˆä»è¯·æ±‚è¿›å…¥ç³»ç»Ÿåˆ°å“åº”å®Œæˆçš„æ—¶é—´ï¼‰

#### ï¼ˆ4ï¼‰æµ‹è¯•æ¨¡å‹
- GPT-4.1-mini
- GPT-4.1
- Ministral-3B

æ‰€æœ‰æ¨¡å‹å‡é€šè¿‡ API æ¥å…¥ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š è¡¨1ï¼šä¸åŒé˜²å¾¡ç­–ç•¥çš„å®‰å…¨æ€§èƒ½å¯¹æ¯”ï¼ˆæ‘˜å½•å…³é”®æ•°æ®ï¼‰

| æ–¹æ³• | Ministral-3B (F1) | GPT-4.1-mini (F1) | GPT-4.1 (F1) |
|------|------------------|-------------------|--------------|
| Pure LLM | 0.80 | 1.58 | 2.72 |
| Guard Prompts | 100.00 | 99.80 | 100.00 |
| GenTel-Shield | 89.67 | 89.67 | 89.67 |
| Guard Prompts + GenTel-Shield | 99.80 | 99.80 | 99.80 |

> âœ… æ‰€æœ‰å€¼å•ä½ä¸ºç™¾åˆ†æ¯”ï¼ˆ%ï¼‰

#### å…³é”®å‘ç°ï¼š
- **Pure LLM å‡ ä¹æ— æ³•æŠµå¾¡ prompt injection**ï¼šF1 æ¥è¿‘é›¶ï¼Œè¯´æ˜åŸå§‹æ¨¡å‹ä¸å…·å¤‡ä¸»åŠ¨æ‹¦æˆªèƒ½åŠ›
- **Guard Prompts æ•ˆæœæå¼º**ï¼šF1 æ¥è¿‘ 100%ï¼Œrecall è¾¾ 99.6â€“100%
- **GenTel-Shield å•ç‹¬ä½¿ç”¨è¡¨ç°ç¨³å¥ä½†ä¸è¶³**ï¼šprecision é«˜è¾¾ 99.51%ï¼Œä½† recall ä»…ä¸º 81.6%ï¼Œå­˜åœ¨æ¼æ£€
- **ç»„åˆé˜²å¾¡æœ€ä¼˜**ï¼šrecall è¾¾ 100%ï¼ŒF1 çº¦ 99.8%ï¼Œå…¼å…·é«˜ç²¾åº¦ä¸å®Œæ•´æ€§

---

### ğŸ“‰ è¡¨2ï¼šæ¨ç†å»¶è¿Ÿå¯¹æ¯”ï¼ˆå•ä½ï¼šç§’ï¼‰

| æ–¹æ³• | Bare Metal (Ministral-3B) | Private Cloud (Ministral-3B) | é™å¹… |
|------|----------------------------|-------------------------------|-----|
| Pure LLM | 645.98 | 246.22 | â†“ ~62% |
| Guard Prompts | 688.07 | 254.72 | â†“ ~63% |

| æ–¹æ³• | Bare Metal (GPT-4.1) | Private Cloud (GPT-4.1) | é™å¹… |
|------|------------------------|--------------------------|-----|
| Pure LLM | 447.60 | 242.98 | â†“ ~46% |

#### å…³é”®å‘ç°ï¼š
- **k3s ç§æœ‰äº‘éƒ¨ç½²åè€Œé™ä½äº†æ¨ç†å»¶è¿Ÿ**
- åœ¨æ‰€æœ‰æ¨¡å‹å’Œé…ç½®ä¸‹ï¼Œ**private cloud çš„ end-to-end latency æ˜¾è‘—ä½äº bare metal**
- å³ä½¿åŠ å…¥ Guard Prompts çš„é¢å¤–å¤„ç†å¼€é”€ï¼Œå»¶è¿Ÿä»ä¿æŒä½ä½ä¸”ç¨³å®š

> ğŸ’¡ åŸå› æ¨æµ‹ï¼šk3s çš„è°ƒåº¦ä¼˜åŒ–ã€ç½‘ç»œé…ç½®åŠèµ„æºåˆ†é…æ›´é«˜æ•ˆï¼ŒæŠµæ¶ˆäº†å®¹å™¨åŒ–å¸¦æ¥çš„æ½œåœ¨å¼€é”€ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **ä½æˆæœ¬ç¡¬ä»¶ + k3s æ¶æ„å¯æœ‰æ•ˆæ”¯æ’‘ç”Ÿäº§çº§ LLM æœåŠ¡**
   - åˆ†å¸ƒå¼è¾¹ç¼˜ç§æœ‰äº‘ä¸ä»…å¯è¡Œï¼Œè€Œä¸”åœ¨å»¶è¿Ÿè¡¨ç°ä¸Šä¼˜äºè£¸æœºéƒ¨ç½²
   - ç‰¹åˆ«é€‚ç”¨äºé¢„ç®—æœ‰é™ã€æ— ä¸“èŒ IT å›¢é˜Ÿçš„å°å‹ä¼ä¸š

2. **åˆ†å±‚é˜²å¾¡æ˜¯åº”å¯¹ prompt injection çš„å®ç”¨è·¯å¾„**
   - Guard Prompts æä¾›é«˜æ€§èƒ½ä¸Šé™ï¼Œä½†éœ€ç²¾ç»†è°ƒä¼˜ï¼Œç»´æŠ¤æˆæœ¬é«˜
   - GenTel-Shield æä¾›å³æ’å³ç”¨çš„è‡ªåŠ¨åŒ–æ£€æµ‹èƒ½åŠ›ï¼Œé€‚åˆå¤šç§Ÿæˆ·å¿«é€Ÿéƒ¨ç½²
   - ä¸¤è€…ç»“åˆå¯åœ¨å®‰å…¨æ€§ä¸å¯ç»´æŠ¤æ€§ä¹‹é—´å–å¾—æœ€ä½³å¹³è¡¡

3. **å¹³å°çº§å®‰å…¨æœºåˆ¶æ— éœ€ä¾èµ–å¤§æ¨¡å‹æœ¬èº«çš„èƒ½åŠ›**
   - å³ä½¿æ˜¯è¾ƒå°çš„ Ministral-3B æ¨¡å‹ï¼Œåœ¨é˜²æŠ¤åŠ æŒä¸‹ä¹Ÿèƒ½è¾¾åˆ°æ¥è¿‘å®Œç¾çš„é˜²å¾¡æ•ˆæœ
   - å®‰å…¨è´£ä»»åº”ç”±å¹³å°æ‰¿æ‹…ï¼Œè€Œéå®Œå…¨å¯„æ‰˜äº LLM çš„å†…åœ¨é²æ£’æ€§

---

### âš ï¸ å±€é™æ€§

1. **Guard Prompts ä¾èµ–äººå·¥è®¾è®¡ä¸è¿­ä»£**
   - å½“å‰ guard prompt è§„åˆ™ç»è¿‡åå¤æµ‹è¯•è°ƒæ•´ï¼Œæ³›åŒ–èƒ½åŠ›æœªçŸ¥
   - æ–°é¢†åŸŸæˆ–æ–°å‹æ”»å‡»å¯èƒ½éœ€è¦é‡æ–°è®¾è®¡è§„åˆ™é›†

2. **GenTel-Shield å­˜åœ¨ä¸€å®šæ¼æŠ¥ç‡**
   - å°½ç®¡ precision å¾ˆé«˜ï¼Œä½† ~18% çš„æ”»å‡»æœªè¢«è¯†åˆ«ï¼Œä»éœ€ä¸Šå±‚è¡¥å……é˜²å¾¡

3. **å®éªŒå±€é™äºå•ä¸€è¡Œä¸šåœºæ™¯**
   - æ¡ˆä¾‹åŸºäºç”µå•†å®¢æœï¼Œæ˜¯å¦é€‚ç”¨äºåŒ»ç–—ã€é‡‘èç­‰é«˜æ•æ„Ÿé¢†åŸŸå°šå¾…éªŒè¯

4. **æœªæµ‹è¯•æ›´å¤æ‚çš„ RAG æ”»å‡»å½¢å¼**
   - å¦‚é—´æ¥ prompt injectionï¼ˆindirect prompt injectionï¼‰æˆ–ä¾›åº”é“¾æ±¡æŸ“æ”»å‡»

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **è‡ªåŠ¨åŒ– guard prompt ç”Ÿæˆä¸æ¼”åŒ–æœºåˆ¶**
   - åˆ©ç”¨ LLM è‡ªåŠ¨åˆ†æçŸ¥è¯†åº“å†…å®¹å¹¶ç”Ÿæˆé’ˆå¯¹æ€§å®ˆå«è§„åˆ™
   - åŠ¨æ€æ›´æ–°ä»¥é€‚åº”æ–°å¨èƒæ¨¡å¼

2. **å¢å¼º GenTel-Shield åœ¨å¤šè¯­è¨€ã€å¤šæ¨¡æ€åœºæ™¯ä¸‹çš„æ£€æµ‹èƒ½åŠ›**
   - æ‰©å±•è‡³å›¾åƒæè¿°ã€è¯­éŸ³è½¬å½•ç­‰éæ–‡æœ¬è¾“å…¥ä¸­çš„ prompt æ³¨å…¥æ£€æµ‹

3. **è·¨ç§Ÿæˆ·å¨èƒæƒ…æŠ¥å…±äº«æœºåˆ¶**
   - åœ¨ä¿éšœéšç§å‰æä¸‹ï¼Œå®ç°å¤šç§Ÿæˆ·é—´çš„æ”»å‡»ç‰¹å¾ååŒå­¦ä¹ 

4. **å°†å¹³å°æ‰©å±•è‡³ agent-based workflows**
   - æ”¯æŒ tool callingã€function execution ç­‰é«˜çº§åŠŸèƒ½çš„å®‰å…¨ç®¡æ§

---

## æ€»ç»“

è¯¥è®ºæ–‡æˆåŠŸå±•ç¤ºäº†å¦‚ä½•åœ¨**ç°å®çº¦æŸæ¡ä»¶ä¸‹**ï¼ˆæˆæœ¬ã€äººåŠ›ã€å®‰å…¨ï¼‰ä¸ºå°ä¼ä¸šæä¾›**å®‰å…¨ã€é«˜æ•ˆã€æ˜“ç”¨çš„ LLM-as-a-Service å¹³å°**ã€‚å…¶æ ¸å¿ƒä»·å€¼åœ¨äºï¼š
- å°†å‰æ²¿å®‰å…¨ç ”ç©¶æˆæœï¼ˆå¦‚ GenTel-Shieldï¼‰è½¬åŒ–ä¸º**å¯éƒ¨ç½²çš„å¹³å°çº§æœºåˆ¶**
- è¯æ˜äº† **k3s + overlay network + åˆ†å±‚é˜²å¾¡** æ˜¯ä¸€æ¡åˆ‡å®å¯è¡Œçš„æŠ€æœ¯è·¯çº¿
- ä¸ºä¸­å°ä¼ä¸šæä¾›äº†æ‘†è„±å¯¹å¤§å‹äº‘å‚å•†ä¾èµ–çš„æ›¿ä»£æ–¹æ¡ˆ

> ğŸ”— å¼€æºåœ°å€ï¼š[https://aisuko.github.io/secure_llm/](https://aisuko.github.io/secure_llm/)

</details>

---

### 3. [MARS: Unleashing the Power of Speculative Decoding via Margin-Aware Verification](https://arxiv.org/abs/2601.15498)

**Authors**: Jingwei Song, Xinyu Wang, Hanbin Wang, Xiaoxuan Lei, Bill Shi, Shixin Han, Eric Yang, Xiao-Wen Chang, Lynn Ai  
**Category**: cs.LG  
**Published**: 2026-01-23  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2601.15498v1  

#### Abstract
Speculative Decoding (SD) accelerates autoregressive large language model (LLM) inference by decoupling generation and verification. While recent methods improve draft quality by tightly coupling the drafter with the target model, the verification mechanism itself remains largely unchanged, relying ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# MARS: Unleashing the Power of Speculative Decoding via Margin-Aware Verification è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿçš„ **Speculative Decoding (SD)** è™½ç„¶é€šè¿‡è½»é‡çº§ **drafter** æ¨¡å‹å¹¶è¡Œç”Ÿæˆå€™é€‰ token æ¥åŠ é€Ÿ LLM æ¨ç†ï¼Œä½†å…¶éªŒè¯æœºåˆ¶ä»ä¾èµ–äºä¸¥æ ¼çš„ **exact-match rejection sampling**ã€‚  
ç„¶è€Œï¼Œåœ¨å®é™…ä¸­ï¼ŒLLM ç»å¸¸å¤„äº **low-margin regime**ï¼ˆå³ top-1 å’Œ top-2 token çš„å¾—åˆ†å·®å¼‚å¾ˆå°ï¼‰ï¼Œæ­¤æ—¶ä¸¥æ ¼æ‹’ç»ä¸€ä¸ªåˆç†çš„æ¬¡ä¼˜ token å¹¶ä¸ä¼šå¸¦æ¥æ˜¾è‘—çš„è´¨é‡æå‡ï¼Œåè€Œå› å›æ»šï¼ˆrollbackï¼‰é€ æˆè®¡ç®—æµªè´¹ã€‚

è¿™ç§â€œé«˜æˆæœ¬ã€ä½æ”¶ç›Šâ€çš„éªŒè¯ç­–ç•¥æˆä¸ºæ€§èƒ½ç“¶é¢ˆã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šMargin-Aware Speculative Verification (MARS)
ä½œè€…æå‡º **MARS** â€”â€”ä¸€ç§æ— éœ€è®­ç»ƒã€é¢†åŸŸæ— å…³ã€ä»…ä¿®æ”¹éªŒè¯è§„åˆ™çš„è½»é‡çº§ç­–ç•¥ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> **æ ¹æ®ç›®æ ‡æ¨¡å‹è¾“å‡º logits çš„ marginï¼ˆå†³ç­–ç¨³å®šæ€§ï¼‰åŠ¨æ€è°ƒæ•´éªŒè¯ä¸¥æ ¼ç¨‹åº¦ã€‚**

å…·ä½“åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š

- **ä»¥ Logit Ratio ä½œä¸ºä¿¡å¿ƒåº¦é‡**ï¼šå®šä¹‰ $ r_t = \frac{z_{t,(2)}}{z_{t,(1)}} $ï¼Œå½“è¯¥æ¯”å€¼æ¥è¿‘ 1 æ—¶ï¼Œè¡¨ç¤º top-1 ä¸ top-2 å·®å¼‚å°ï¼Œæ¨¡å‹å†³ç­–ä¸æ˜ç¡®ã€‚
- **è‡ªé€‚åº”æ”¾å®½éªŒè¯æ¡ä»¶**ï¼šè‹¥ draft token åŒ¹é…çš„æ˜¯ top-2 ä¸” $ r_t > \theta $ï¼ˆå¦‚ 0.9ï¼‰ï¼Œåˆ™æ¥å—è¯¥ tokenï¼Œè§†ä¸ºâ€œå¹³å±€å¤„ç†â€ï¼ˆtie-breakingï¼‰ã€‚
- **å®Œå…¨å…¼å®¹ç°æœ‰æ¡†æ¶**ï¼šMARS ä¸æ”¹å˜ drafter æˆ– target model ç»“æ„ï¼Œä¹Ÿä¸éœ€é¢å¤–è®­ç»ƒï¼Œå¯ç›´æ¥é›†æˆåˆ° Medusaã€EAGLE ç­‰å…ˆè¿› SD æ¡†æ¶ä¸­ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³• | MARS |
|------|--------|-------|
| éªŒè¯æ–¹å¼ | å›ºå®š exact-match | åŠ¨æ€ margin-aware |
| æ˜¯å¦éœ€è¦è®­ç»ƒ | å¦ï¼ˆä½† rigidï¼‰ | âŒ ä¸éœ€è¦ |
| æ˜¯å¦å¼•å…¥é¢å¤–æ¨¡å‹ | å¦ | âŒ å¦ |
| æ•ˆç‡ vs è´¨é‡æƒè¡¡ | åˆšæ€§ï¼Œæ˜“æµªè´¹ | è‡ªé€‚åº”ï¼Œæ›´é«˜æ•ˆ |
| æ’ä»¶åŒ–èƒ½åŠ› | å¼º | âœ… æ›´å¼ºï¼ˆçº¯æ¨ç†æ—¶ä¿®æ”¹ï¼‰ |

ç›¸æ¯”è¿‘æœŸæå‡ºçš„åŸºäºè¯­ä¹‰åˆ¤æ–­å™¨çš„ **learned relaxation** æ–¹æ³•ï¼ˆå¦‚ Judge Decodingï¼‰ï¼ŒMARS æ›´ç®€å•ã€é€šç”¨ã€æ— è®­ç»ƒå¼€é”€ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
æ¶µç›–å¤šç§ä»»åŠ¡ç±»å‹ï¼Œç¡®ä¿æ³›åŒ–æ€§ï¼š
- **å¯¹è¯è´¨é‡**ï¼šMT-Bench
- **ä»£ç ç”Ÿæˆ**ï¼šHumanEvalã€MBPP
- **æ•°å­¦æ¨ç†**ï¼šGSM8K
- **æŒ‡ä»¤è·Ÿéš**ï¼šAlpacaEval
- **æ‘˜è¦ç”Ÿæˆ**ï¼šCNN/DailyMail (CNN/DM)

æ‰€æœ‰å®éªŒå‡åœ¨ç›¸åŒè§£ç é…ç½®ä¸‹è¿›è¡Œï¼Œæœªé’ˆå¯¹ç‰¹å®šä»»åŠ¡è°ƒå‚ã€‚

### å®éªŒè®¾ç½®
- **ç›®æ ‡æ¨¡å‹ï¼ˆTarget Modelsï¼‰**ï¼š
  - Vicuna-13B
  - LLaMA-3.1-8B-Instruct, LLaMA-3.3-70B-Instruct
  - Qwen3-8B, Qwen3-32B, Qwen3-235B
- **drafter æ¨¡å‹**ï¼šç»Ÿä¸€ä½¿ç”¨ä¸ºå„ target è®­ç»ƒçš„ **EAGLE-3**
- **draft length K = 7**
- **æ¸©åº¦è®¾ç½®**ï¼šéè´ªå©ªè§£ç ï¼ˆtemperature âˆˆ {0.2, 0.4, ..., 1.0}ï¼‰
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA H100 80GB GPUsï¼ˆâ‰¤32B å•å¡ï¼Œ>32B å¤šå¡ï¼‰

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | è¯´æ˜ |
|------|------|
| **Speedup Ratio** | ç«¯åˆ°ç«¯è§£ç é€Ÿåº¦ç›¸å¯¹äº vanilla autoregressive decoding çš„åŠ é€Ÿæ¯” |
| **Average Acceptance Length (T)** | æ¯è½® draft-verify å¾ªç¯å¹³å‡æ¥å—çš„ token æ•°é‡ï¼ˆè¶Šé«˜è¶Šé«˜æ•ˆï¼‰ |
| **Accuracy / Pass@4** | ä»»åŠ¡ç›¸å…³å‡†ç¡®ç‡ï¼ˆexact match æˆ– pass@4ï¼‰ |
| **Recovery Ratio** | åŠ é€Ÿæ–¹æ³•çš„ accuracy ç›¸å¯¹äºåŸæ¨¡å‹ baseline çš„æ¢å¤æ¯”ä¾‹ï¼ˆ%ï¼‰ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- Vanilla Autoregressive Decodingï¼ˆåŸºå‡†ï¼‰
- Standard Speculative Sampling (SpS)
- Prompt Lookup Decoding (PLD)
- Lookahead Decoding
- Medusa
- EAGLE-2
- EAGLE-3ï¼ˆä¸»å¯¹æ¯”åŸºçº¿ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| Model | Method | Speedup Ã— | T |
|-------|--------|----------|----|
| Vicuna-13B | EAGLE-3 | 3.12Ã— | 5.64 |
| | **MARS** | **3.74Ã—** | **7.20** |
| LLaMA-3.1-8B | EAGLE-3 | 3.24Ã— | 4.82 |
| | **MARS** | **4.00Ã—** | **6.61** |
| LLaMA-3.3-70B | EAGLE-3 | 4.40Ã— | 5.66 |
| | **MARS** | **4.76Ã—** | **6.39** |
| Qwen3-8B | EAGLE-3 | 2.96Ã— | 4.41 |
| | **MARS** | **3.23Ã—** | **5.22** |
| Qwen3-32B | EAGLE-3 | 3.01Ã— | 4.21 |
| | **MARS** | **3.49Ã—** | **5.23** |
| Qwen3-235B | EAGLE-3 | 2.95Ã— | 4.14 |
| | **MARS** | **3.42Ã—** | **5.14** |

âœ… æ‰€æœ‰æ¨¡å‹ä¸Šï¼Œ**MARS æ˜¾è‘—ä¼˜äº EAGLE-3**ï¼Œå¹³å‡æé€Ÿæå‡çº¦ **15â€“20%**ï¼ŒT å€¼ä¹Ÿæ˜æ˜¾æ›´é«˜ã€‚

### å‡†ç¡®ç‡ä¿æŒæƒ…å†µï¼ˆå›¾ 3ï¼‰
- åœ¨ **HumanEval** ä¸Šå®ç° **100% accuracy recovery**
- åœ¨ **MBPP** ä¸Šè¾¾ **99.2â€“100%**
- åœ¨ **GSM8K** ä¸Šç»´æŒåœ¨ **98.1â€“100%**
- æ€»ä½“è¡¨ç°ä¸º **near-lossless**ï¼ŒåŠŸèƒ½æ­£ç¡®æ€§å‡ ä¹ä¸å—å½±å“

> ğŸ’¡ åˆ†æè®¤ä¸ºï¼šå¤šæ•°åå·®å‡ºç°åœ¨å‘½åã€æ ¼å¼ç­‰éåŠŸèƒ½æ€§å±‚é¢ï¼Œä¸å½±å“æœ€ç»ˆæ‰§è¡Œç»“æœã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### (1) Logit Ratio é˜ˆå€¼ $\theta$ å½±å“ï¼ˆå›¾ 4ï¼‰
- è®¾ç½® $\theta \in \{0.84, 0.86, ..., 0.96\}$
- å‘ç°ï¼š
  - **Speedup éš $\theta$ å¢å¤§å•è°ƒä¸‹é™**ï¼ˆè¶Šä¿å®ˆï¼Œè¶Šå°‘æ”¾æ¾ï¼‰
  - **Accuracy åœ¨ $\theta \approx 0.90$ é™„è¿‘è¾¾åˆ°å³°å€¼**
- âœ… æœ€ç»ˆé€‰æ‹© **$\theta = 0.9$** ä½œä¸ºé»˜è®¤å€¼ï¼Œå¹³è¡¡æ•ˆç‡ä¸è´¨é‡

#### (2) æ¸©åº¦ $t$ å½±å“ï¼ˆè¡¨ 2ï¼‰
- åœ¨ä¸åŒ temperature ä¸‹ï¼ˆ0.2 ~ 1.0ï¼‰ï¼Œ**Speedup å’Œ T åŸºæœ¬ç¨³å®š**
- Accuracy éšæ¸©åº¦å‡é«˜ç•¥æœ‰ä¸‹é™ï¼ˆå¯¹ baseline å’Œ MARS ä¸€è‡´ï¼‰
- è¡¨æ˜ MARS å…·æœ‰è‰¯å¥½çš„é²æ£’æ€§å’Œè·¨æ¸©åº¦é€‚åº”æ€§

#### (3) Draft Length $K$ å½±å“ï¼ˆè¡¨ 2ï¼‰
- å¢åŠ  $K$ å¯æé«˜ $T$ï¼ˆæ›´å¤š token è¢«æäº¤ï¼‰
- ä½† **Speedup å¹¶éå•è°ƒå¢é•¿**ï¼Œè¿‡å¤§çš„ $K$ åè€Œç•¥é™
- æœ€ä½³ $K$ é€šå¸¸åœ¨ 9 å·¦å³ï¼ˆæœ¬æ–‡å›ºå®šä¸º 7ï¼Œä»æœ‰ä¼˜åŒ–ç©ºé—´ï¼‰
- Accuracy å¯¹ $K$ æ•æ„Ÿï¼Œå°¤å…¶åœ¨ HumanEval ä¸Š

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Strict verification åœ¨ low-margin regime ä¸‹æ•ˆç‡ä½ä¸‹**ï¼šå¤§é‡ rollback æ˜¯ä¸å¿…è¦çš„ï¼Œé€ æˆèµ„æºæµªè´¹ã€‚
2. **Logit Ratio æ˜¯æ¯”æ¦‚ç‡æ›´ç¨³å®šçš„ margin æŒ‡æ ‡**ï¼šé¿å… softmax çš„æŒ‡æ•°æ”¾å¤§æ•ˆåº”ï¼Œæ›´é€‚åˆè¡¡é‡æ¨¡å‹â€œä¸ç¡®å®šæ€§â€ã€‚
3. **Margin-aware relaxation æ˜¾è‘—æå‡æ•ˆç‡è€Œä¸ç‰ºç‰²è´¨é‡**ï¼šMARS åœ¨å¤šä¸ªæ¨¡å‹è§„æ¨¡ï¼ˆ8B ~ 235Bï¼‰å’Œä»»åŠ¡ä¸Šå‡å–å¾—ä¸€è‡´ä¸”æ˜¾è‘—çš„åŠ é€Ÿæ•ˆæœã€‚
4. **æ— éœ€è®­ç»ƒå³å¯é‡Šæ”¾é«˜è´¨é‡ drafter çš„æ½œåŠ›**ï¼šMARS ä¸ EAGLE-3 ç­‰å…ˆè¿› drafter å®Œç¾ååŒï¼Œè¿›ä¸€æ­¥æŒ–æ˜å…¶æ€§èƒ½ä¸Šé™ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- ä½¿ç”¨å•ä¸€å…¨å±€é˜ˆå€¼ $\theta=0.9$ï¼Œå¯èƒ½æ— æ³•æ•æ‰ä¸Šä¸‹æ–‡ç›¸å…³çš„å¤æ‚å†³ç­–æ¨¡å¼ã€‚
- å†³ç­–åŸºäº **token-level margin**ï¼Œå°šæœªæ‰©å±•è‡³è¯­ä¹‰æˆ–ç»“æ„å±‚çº§ï¼ˆå¦‚ phrase-level æˆ– sentence-levelï¼‰ã€‚
- å½“å‰è¯„ä¼°é›†ä¸­äºæ ‡å‡†éšæœºè§£ç åœºæ™¯ï¼Œä¸å…¶ä»–çº¦æŸæ€§è§£ç ç­–ç•¥ï¼ˆå¦‚ constrained decodingï¼‰çš„äº¤äº’å°šå¾…ç ”ç©¶ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- è®¾è®¡ context-aware çš„åŠ¨æ€é˜ˆå€¼æœºåˆ¶
- å°† margin-aware æ€æƒ³æ¨å¹¿è‡³æ›´é«˜ç²’åº¦çš„ç”Ÿæˆå•å…ƒ
- æ¢ç´¢ä¸ tree-based speculative decoding çš„æ·±åº¦èåˆ
- åœ¨æ›´å¤šåº”ç”¨åœºæ™¯ï¼ˆå¦‚é•¿æ–‡æœ¬ç”Ÿæˆã€agent planningï¼‰ä¸­éªŒè¯æœ‰æ•ˆæ€§

---

## æ€»ç»“
**MARS** æå‡ºäº†ä¸€ç§ç®€æ´è€Œå¼ºå¤§çš„æ´è§ï¼š**è®©éªŒè¯æœºåˆ¶æ„ŸçŸ¥æ¨¡å‹è‡ªèº«çš„å†³ç­–ä¿¡å¿ƒ**ã€‚å®ƒé€šè¿‡åˆ†æ target model çš„ logits marginï¼Œæ™ºèƒ½åœ°æ”¾å®½ä½é£é™© token çš„éªŒè¯è¦æ±‚ï¼Œåœ¨å‡ ä¹ä¸æŸå¤±ç”Ÿæˆè´¨é‡çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº† Speculative Decoding çš„æ•ˆç‡ã€‚ä½œä¸ºä¸€ç§ **training-freeã€plug-and-play** çš„æ”¹è¿›æ–¹æ¡ˆï¼ŒMARS å±•ç°å‡ºæå¼ºçš„å®ç”¨ä»·å€¼å’Œå¹¿æ³›é€‚ç”¨æ€§ï¼Œä¸ºé«˜æ•ˆ LLM æ¨ç†æä¾›äº†æ–°çš„èŒƒå¼ã€‚

</details>

---

### 4. [Attributing and Exploiting Safety Vectors through Global Optimization in Large Language Models](https://arxiv.org/abs/2601.15801)

**Authors**: Fengheng Chu, Jiahao Chen, Yuhong Wang, Jun Wang, Zhihui Fu, Shouling Ji, Songze Li  
**Category**: cs.LG  
**Published**: 2026-01-23  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.15801v1  

#### Abstract
While Large Language Models (LLMs) are aligned to mitigate risks, their safety guardrails remain fragile against jailbreak attacks. This reveals limited understanding of components governing safety. Existing methods rely on local, greedy attribution that assumes independent component contributions. ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Attributing and Exploiting Safety Vectors through Global Optimization in Large Language Models*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å®‰å…¨æœºåˆ¶çš„ç†è§£ä¸»è¦ä¾èµ–äºå±€éƒ¨ã€è´ªå©ªçš„å½’å› æ–¹æ³•ï¼ˆlocal, greedy attributionï¼‰ï¼Œè¿™äº›æ–¹æ³•å‡è®¾æ¨¡å‹ç»„ä»¶ï¼ˆå¦‚ attention headsï¼‰ç‹¬ç«‹åœ°è´¡çŒ®äºå®‰å…¨è¡Œä¸ºã€‚ç„¶è€Œï¼Œè¿™ç§å‡è®¾å¿½ç•¥äº†ç»„ä»¶é—´çš„ååŒäº¤äº’ä½œç”¨ï¼Œå¯¼è‡´æ— æ³•å‡†ç¡®æ­ç¤ºLLMsä¸­å¤æ‚çš„ã€åˆ†å¸ƒå¼çš„å®‰å…¨æœºåˆ¶ã€‚

æœ¬æ–‡æ—¨åœ¨è§£å†³ä»¥ä¸‹æ ¸å¿ƒé—®é¢˜ï¼š
- å¦‚ä½•æ›´å‡†ç¡®åœ°è¯†åˆ«æ§åˆ¶LLMå®‰å…¨æ€§çš„å…³é”®å†…éƒ¨ç»„ä»¶ï¼Ÿ
- å¯¹é½åçš„LLMæ˜¯å¦é€šè¿‡å•ä¸€æˆ–å¤šä¸ªåŠŸèƒ½è·¯å¾„æ¥å®ç°å®‰å…¨ï¼Ÿ
- èƒ½å¦åŸºäºè¿™äº›å‘ç°è®¾è®¡æ›´æœ‰æ•ˆçš„ç™½ç›’æ”»å‡»ï¼Ÿ

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡ºäº† **Global Optimization for Safety Vector Extraction (GOSV)** æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

- **å…¨å±€ä¼˜åŒ–ï¼ˆGlobal Optimizationï¼‰**ï¼šä¸åŒäºä¼ ç»Ÿçš„å±€éƒ¨å½’å› æ–¹æ³•ï¼ŒGOSVé‡‡ç”¨åŸºäºREINFORCEçš„ç­–ç•¥æ¢¯åº¦æ–¹æ³•ï¼Œåœ¨æ‰€æœ‰attention headsä¸Šè¿›è¡Œè”åˆä¼˜åŒ–ï¼Œä»è€Œæ•æ‰åˆ°åˆ†å¸ƒå¼ä¸”ç›¸äº’ä¾èµ–çš„å®‰å…¨å‘é‡ï¼ˆsafety vectorsï¼‰ã€‚
  
- **ä¸¤ç§äº’è¡¥çš„æ¿€æ´»ä¿®è¡¥ç­–ç•¥ï¼ˆActivation Repatching Strategiesï¼‰**ï¼š
  - **Harmful Patching**ï¼šæ³¨å…¥ä»æœ‰å®³å†…å®¹ç”Ÿæˆä¸­è®¡ç®—å¾—åˆ°çš„å¹³å‡æ¿€æ´»å€¼ï¼Œä»¥è¯†åˆ«èƒ½â€œè§¦å‘â€ä¸å®‰å…¨è¾“å‡ºçš„ **Malicious Injection Vectors**ã€‚
  - **Zero Ablation**ï¼šå°†ç‰¹å®šheadçš„æ¿€æ´»ç½®é›¶ï¼Œä»¥æŠ‘åˆ¶ä¿¡æ¯æµï¼Œè¯†åˆ«å¯¹ç»´æŒå®‰å…¨è‡³å…³é‡è¦çš„ **Safety Suppression Vectors**ã€‚

- **å‘ç°ä¸¤ä¸ªç©ºé—´åˆ†ç¦»çš„å®‰å…¨é€šè·¯ï¼ˆDistinct Safety Pathwaysï¼‰**ï¼šå®éªŒè¯æ˜ï¼Œä¸Šè¿°ä¸¤ç§ç­–ç•¥è¯†åˆ«å‡ºçš„attention headsé›†åˆé‡å æä½ï¼Œè¡¨æ˜å¯¹é½çš„LLMå­˜åœ¨ä¸¤æ¡ç‹¬ç«‹çš„åŠŸèƒ½è·¯å¾„æ¥ç»´æŠ¤å®‰å…¨æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚Shipsç­‰ï¼‰ | GOSV |
|------|------------------------|------|
| å½’å› æ–¹å¼ | å±€éƒ¨ã€è´ªå©ªã€ç‹¬ç«‹å‡è®¾ | å…¨å±€ã€è”åˆä¼˜åŒ–ã€è€ƒè™‘äº¤äº’ |
| å®‰å…¨å»ºæ¨¡è§†è§’ | å•ä¸€æœºåˆ¶æˆ–ç¨€ç–å¤´ | åˆ†å¸ƒå¼ã€åŒè·¯å¾„æœºåˆ¶ |
| æ”»å‡»æœ‰æ•ˆæ€§ | æœ‰é™ï¼ˆå°¤å…¶åœ¨éä¸»æµæ¨¡å‹ä¸Šï¼‰ | æ˜¾è‘—æ›´é«˜ASRï¼Œæ³›åŒ–æ€§å¼º |
| å¯è§£é‡Šæ€§ | ä»…å®šä½â€œé‡è¦å¤´â€ | æ­ç¤ºåŠŸèƒ½è§’è‰²å·®å¼‚ï¼ˆæ³¨å…¥ vs æŠ‘åˆ¶ï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **è®­ç»ƒé›†ï¼ˆç”¨äºæå–mean activationså’ŒGOSVä¼˜åŒ–ï¼‰**ï¼š
  - **AdvBench**ï¼šåŒ…å«100ä¸ªæ¶æ„æŸ¥è¯¢åŠå…¶å¯¹åº”çš„ç›®æ ‡æœ‰å®³å“åº”ï¼Œç”¨äºåˆå§‹åŒ–Harmful Patchingä¸­çš„æ¿€æ´»å€¼ã€‚
- **æµ‹è¯•é›†ï¼ˆç”¨äºè¯„ä¼°æ”»å‡»æˆåŠŸç‡ï¼‰**ï¼š
  - **AdvBenchå®Œæ•´ç‰ˆ**ï¼ˆ520ç§è¡Œä¸ºï¼‰
  - **StrongREJECT**ï¼ˆ313æ¡æ¶æ„æŒ‡ä»¤ï¼‰
  - ç”¨äºè¯„ä¼°æ”»å‡»çš„æ³›åŒ–èƒ½åŠ›ã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼šå››ä¸ªå¼€æºå¯¹é½LLMï¼š
  - `Llama-2-7b-chat`
  - `Llama-3.1-8B-Instruct`
  - `Qwen2.5-7B-Instruct`
  - `Mistral-7B-Instruct-v0.2`

- **GOSVä¼˜åŒ–å‚æ•°**ï¼š
  - æ¯è½®é‡‡æ · $ K=32 $ ä¸ªheadé…ç½®
  - è®­ç»ƒ $ E=500 $ è½®
  - ä½¿ç”¨Adamä¼˜åŒ–å™¨ï¼ˆå­¦ä¹ ç‡0.1ï¼‰

- **Mean Activationè®¡ç®—**ï¼š
  - Harmful Patchingï¼šåŸºäº1000ä¸ªæ ·æœ¬ï¼ˆAdvBenchå‰100æ¡æŒ‡ä»¤ Ã— 10æ¬¡é‡‡æ ·ï¼‰è®¡ç®—å‡å€¼ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **Attack Success Rate (ASR)**ï¼š
  $$
  \text{ASR} = \frac{\text{æˆåŠŸæ”»å‡»æ•°}}{\text{æ€»æ”»å‡»æ•°}}
  $$
  æˆåŠŸæ ‡å‡†ç”± **HarmBench-Llama-2-13b-cls** åˆ†ç±»å™¨åˆ¤æ–­ï¼Œè¯¥åˆ†ç±»å™¨ä¸“é—¨ç”¨äºæ£€æµ‹æœ‰å®³å†…å®¹ç”Ÿæˆã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | æ ¸å¿ƒæ€æƒ³ |
|------|------|---------|
| **GCG** | åç¼€ä¼˜åŒ– | è´ªå©ªæœç´¢å¯¹æŠ—åç¼€ |
| **AutoDAN** | é—ä¼ ç®—æ³• | è¯­ä¹‰çº§promptè¿›åŒ– |
| **AdvPrefix** | åŠ¨æ€ç›®æ ‡ | ä¼˜åŒ–prefillé˜¶æ®µæ¦‚ç‡ |
| **DSN** | æ‹’ç»æŠ‘åˆ¶ | è”åˆæœ€å°åŒ–æ‹’ç»å…³é”®è¯ |
| **ORTHO** | è¡¨å¾å¹²é¢„ | æ­£äº¤åŒ–â€œæ‹’ç»æ–¹å‘â€ |
| **Ships** | å®‰å…¨å¤´è¯†åˆ« | å±€éƒ¨å½’å› ä»£è¡¨æ–¹æ³• |
| **Fine-tuning (FT)** | å‚æ•°ä¿®æ”¹ | ç›´æ¥å¾®è°ƒæ¨¡å‹ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§Table 2 & Table 3ï¼‰

#### åœ¨ AdvBench ä¸Šçš„ ASR (%)
| Method | Llama2-7B | Llama3.1-8B | Qwen2.5-7B | Mistral-7B |
|--------|-----------|-------------|------------|------------|
| GCG | 46.92 | 48.08 | 37.38 | 80.96 |
| AutoDAN | 24.04 | 62.50 | 76.73 | 74.23 |
| AdvPrefix | 60.58 | 77.31 | 80.19 | 95.77 |
| DSN | 61.92 | 63.08 | 58.27 | 86.92 |
| ORTHO | 88.65 | 94.42 | 84.81 | 82.12 |
| **Ours** | **92.50** | **96.35** | **86.35** | **100.00** |

#### åœ¨ StrongREJECT ä¸Šçš„ ASR (%)
| Method | Llama2-7B | Llama3.1-8B | Qwen2.5-7B | Mistral-7B |
|--------|-----------|-------------|------------|------------|
| GCG | 20.77 | 18.27 | 34.82 | 82.43 |
| AutoDAN | 20.45 | 57.51 | 75.08 | 73.48 |
| AdvPrefix | 65.18 | 75.40 | 77.96 | 90.10 |
| DSN | 59.11 | 60.38 | 56.87 | 71.57 |
| ORTHO | 66.77 | 87.22 | 88.50 | 74.44 |
| **Ours** | **91.05** | **92.01** | **90.42** | **99.36** |

> âœ… **ç»“è®º**ï¼šGOSVåœ¨å‡ ä¹æ‰€æœ‰æ¨¡å‹å’Œæ•°æ®é›†ä¸Šå‡è¾¾åˆ°æœ€ä¼˜æˆ–æ¥è¿‘æœ€ä¼˜æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **vs Shipsï¼ˆå±€éƒ¨å½’å› æ–¹æ³•ï¼‰**ï¼š
  - åœ¨Qwen2.5å’ŒMistralä¸Šï¼ŒShipså‡ ä¹å¤±æ•ˆï¼ˆASR â‰ˆ 0%ï¼‰ï¼Œè€ŒGOSVåˆ†åˆ«è¾¾åˆ°86.35%å’Œ100.00%ã€‚
  - è¡¨æ˜å±€éƒ¨æ–¹æ³•éš¾ä»¥æ³›åŒ–è‡³ä¸åŒæ¶æ„ã€‚

- **vs Fine-tuningï¼ˆå‚æ•°ä¿®æ”¹ï¼‰**ï¼š
  - åœ¨è®­ç»ƒåˆ†å¸ƒï¼ˆAdvBenchï¼‰ä¸Šæ€§èƒ½ç›¸å½“ï¼›
  - åœ¨OODåˆ†å¸ƒï¼ˆStrongREJECTï¼‰ä¸Šï¼ŒGOSVå¹³å‡é«˜å‡º8â€“19%ï¼Œè¯´æ˜å…¶æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚

### æ¶ˆèå®éªŒç»“æœ
#### ä¸åŒä¿®è¡¥ç­–ç•¥çš„æ•ˆæœï¼ˆFigure 5ï¼‰
| ç­–ç•¥ | ASRè¡¨ç° | ç»“è®º |
|------|--------|------|
| Harmful Patching | >90% | æœ‰æ•ˆ |
| Zero Ablation | >90% | æœ‰æ•ˆ |
| Benign Patching | æ¥è¿‘baseline | æ— æ•ˆ |
| Random Patching | æ¥è¿‘baseline | æ— æ•ˆ |

> ğŸ” **ç»“è®º**ï¼šåªæœ‰é’ˆå¯¹**ç‰¹å®šå®‰å…¨å‘é‡**çš„æ“ä½œæ‰èƒ½æœ‰æ•ˆç ´åå®‰å…¨æœºåˆ¶ï¼Œè¯æ˜GOSVè¯†åˆ«çš„å‘é‡å…·æœ‰åŠŸèƒ½æ€§æ„ä¹‰ã€‚

#### å¹²é¢„å¤´æ•°é‡çš„å½±å“ï¼ˆFigure 4ï¼‰
- **Phase Iï¼ˆCritical Headsï¼‰**ï¼šä»…éœ€çº¦1%çš„headså³å¯ä½¿ASRè·ƒå‡è‡³50%ä»¥ä¸Šï¼Œè¯´æ˜å­˜åœ¨é«˜åº¦å…³é”®çš„â€œå®‰å…¨å¤´â€ã€‚
- **Phase IIï¼ˆComplete Breakdownï¼‰**ï¼šå½“ä¿®è¡¥çº¦ **30%çš„attention heads** æ—¶ï¼ŒASRè¾¾åˆ°å³°å€¼å¹¶ç¨³å®šï¼Œæ ‡å¿—ç€å®‰å…¨æœºåˆ¶å®Œå…¨å´©æºƒã€‚
- **Phase IIIï¼ˆDegradationï¼‰**ï¼šè¶…è¿‡30%åï¼ŒPPLæ€¥å‰§ä¸Šå‡ï¼Œè¾“å‡ºå˜å¾—æ— æ„ä¹‰ï¼Œè¡¨æ˜è¿‡åº¦å¹²é¢„æŸå®³äº†åŸºæœ¬è¯­è¨€èƒ½åŠ›ã€‚

> ğŸ“Œ **æ ¸å¿ƒå‘ç°**ï¼šå®‰å…¨æœºåˆ¶åˆ†å¸ƒåœ¨çº¦ **30%çš„attention heads** ä¸­ï¼Œæ„æˆä¸€ä¸ªåˆ†å¸ƒå¼å­ç½‘ç»œã€‚

#### å¤´é€‰æ‹©é‡å åˆ†æï¼ˆFigure 3ï¼‰
- Harmful Patching ä¸ Zero Ablation æ‰€é€‰top-k headsçš„é‡å ç‡å§‹ç»ˆä½äº25%ï¼ˆæœ€ä½è¾¾21.2%ï¼‰ã€‚
- æ•£ç‚¹å›¾ï¼ˆFigure 8ï¼‰æ˜¾ç¤ºå¤§å¤šæ•°headåªåœ¨ä¸€ä¸ªç­–ç•¥ä¸‹è¢«é«˜æ¦‚ç‡é€‰ä¸­ã€‚

> ğŸ§© **ç»“è®º**ï¼šMalicious Injection Vectors å’Œ Safety Suppression Vectors æ˜¯**ç©ºé—´åˆ†ç¦»ã€åŠŸèƒ½ç‹¬ç«‹**çš„ä¸¤ç»„å‘é‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **LLMå®‰å…¨æ˜¯åˆ†å¸ƒå¼çš„**ï¼šå¹¶éç”±å°‘æ•°â€œå®‰å…¨å±‚â€æˆ–â€œå®‰å…¨ç¥ç»å…ƒâ€æ§åˆ¶ï¼Œè€Œæ˜¯ç”±çº¦ **30%çš„attention heads** æ„æˆçš„å­ç½‘ç»œå…±åŒç»´æŒã€‚
2. âœ… **å­˜åœ¨ä¸¤æ¡ç‹¬ç«‹çš„å®‰å…¨é€šè·¯**ï¼š
   - **Malicious Injection Vectors**ï¼šä¸€æ—¦è¢«æ¿€æ´»ï¼Œå¯ä¸»åŠ¨è¯±å¯¼æœ‰å®³è¾“å‡ºã€‚
   - **Safety Suppression Vectors**ï¼šæ­£å¸¸è¿è¡Œæ—¶æŠ‘åˆ¶æœ‰å®³å†…å®¹ï¼›è‹¥è¢«ç¦ç”¨ï¼Œåˆ™å¯¼è‡´å®‰å…¨å¤±æ•ˆã€‚
3. âœ… **å…¨å±€ä¼˜åŒ–ä¼˜äºå±€éƒ¨å½’å› **ï¼šGOSVèƒ½æ›´å‡†ç¡®è¯†åˆ«çœŸæ­£å½±å“å®‰å…¨çš„å…³é”®ç»„ä»¶ï¼Œæ­ç¤ºäº†ä¼ ç»Ÿæ–¹æ³•å¿½ç•¥çš„å¤æ‚äº¤äº’ã€‚
4. âœ… **é«˜æ•ˆç™½ç›’æ”»å‡»**ï¼šåŸºäºGOSVçš„æ¨ç†æ—¶æ¿€æ´»ä¿®è¡¥æ”»å‡»æ— éœ€ä¿®æ”¹æ¨¡å‹å‚æ•°æˆ–è®¾è®¡æç¤ºè¯ï¼Œå³å¯å®ç°æ¥è¿‘å®Œç¾çš„ASRã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **éœ€è¦ç™½ç›’è®¿é—®æƒé™**ï¼šå¿…é¡»èƒ½å¤Ÿè¯»å–å’Œä¿®æ”¹ä¸­é—´å±‚æ¿€æ´»ï¼Œé™åˆ¶äº†åœ¨é»‘ç›’APIåœºæ™¯ä¸‹çš„åº”ç”¨ã€‚
- **å±€é™äºè‹±æ–‡å’Œå¼€æºæ¨¡å‹**ï¼šæœªéªŒè¯åœ¨å¤šè¯­è¨€ã€é—­æºå•†ä¸šæ¨¡å‹ä¸Šçš„æœ‰æ•ˆæ€§ã€‚
- **å°šæœªæå‡ºé˜²å¾¡æ–¹æ¡ˆ**ï¼šè™½ç„¶æ­ç¤ºäº†æ¼æ´ï¼Œä½†æœªæä¾›ç›¸åº”çš„åŠ å›ºç­–ç•¥ã€‚
- **è®¡ç®—æˆæœ¬è¾ƒé«˜**ï¼šå…¨å±€ä¼˜åŒ–æ¶‰åŠå¤§é‡é‡‡æ ·å’Œå‰å‘ä¼ æ’­ï¼Œç›¸æ¯”è½»é‡çº§æ–¹æ³•å¼€é”€æ›´å¤§ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- è®¾è®¡åŸºäºGOSVæ´å¯Ÿçš„æ–°å‹é˜²å¾¡æœºåˆ¶ï¼Œä¾‹å¦‚åŠ¨æ€ç›‘æ§æˆ–ä¿æŠ¤å…³é”®headã€‚
- å°†GOSVåº”ç”¨äºå…¶ä»–å®‰å…¨ç›¸å…³è¡Œä¸ºï¼ˆå¦‚åè§ã€éšç§æ³„éœ²ï¼‰çš„å½’å› åˆ†æã€‚
- æ¢ç´¢å¦‚ä½•å‡å°‘è®­ç»ƒæ ·æœ¬éœ€æ±‚ï¼Œæå‡æ•°æ®æ•ˆç‡ã€‚
- æ‰©å±•è‡³å¤šæ¨¡æ€æ¨¡å‹æˆ–å…¶ä»–Transformeræ¶æ„çš„å®‰å…¨è§£é‡Šã€‚

---

> ğŸ’¡ **æ€»ä½“è¯„ä»·**ï¼šæœ¬è®ºæ–‡é€šè¿‡å¼•å…¥**å…¨å±€ä¼˜åŒ–æ¡†æ¶GOSV**ï¼Œé¦–æ¬¡ç³»ç»Ÿæ€§æ­ç¤ºäº†LLMä¸­å­˜åœ¨**åŒè·¯å¾„ã€åˆ†å¸ƒå¼å®‰å…¨æœºåˆ¶**ï¼ŒæŒ‘æˆ˜äº†â€œå®‰å…¨å³å•ä¸€æ‹’ç»ä¿¡å·â€çš„ç®€åŒ–è®¤çŸ¥ã€‚å…¶å®éªŒä¸¥è°¨ã€å‘ç°æ·±åˆ»ï¼Œä¸ä»…æ¨åŠ¨äº†LLMå®‰å…¨çš„å¯è§£é‡Šæ€§ç ”ç©¶ï¼Œä¹Ÿä¸ºæ„å»ºæ›´é²æ£’çš„é˜²å¾¡ä½“ç³»æä¾›äº†ç†è®ºåŸºç¡€ã€‚

</details>

---

### 5. [Deja Vu in Plots: Leveraging Cross-Session Evidence with Retrieval-Augmented LLMs for Live Streaming Risk Assessment](https://arxiv.org/abs/2601.16027)

**Authors**: Yiran Qiao, Xiang Ao, Jing Chen, Yang Liu, Qiwei Zhong, Qing He  
**Category**: cs.AI  
**Published**: 2026-01-23  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.16027v1  

#### Abstract
The rise of live streaming has transformed online interaction, enabling massive real-time engagement but also exposing platforms to complex risks such as scams and coordinated malicious behaviors. Detecting these risks is challenging because harmful actions often accumulate gradually and recur acros...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDeja Vu in Plots: Leveraging Cross-Session Evidence with Retrieval-Augmented LLMs for Live Streaming Risk Assessment

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç›´æ’­å¹³å°é¢ä¸´å¤æ‚çš„**å®æ—¶é£é™©è¡Œä¸ºæ£€æµ‹æŒ‘æˆ˜**ï¼Œå¦‚è¯ˆéª—ã€è™šå‡ä¿ƒé”€å’ŒååŒæ¶æ„è¡Œä¸ºã€‚è¿™äº›é£é™©é€šå¸¸å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š
- **æ¸è¿›ç§¯ç´¯**ï¼šå•ä¸ªè¡Œä¸ºçœ‹ä¼¼æ— å®³ï¼Œä½†å¤šä¸ªè¡Œä¸ºç»„åˆå½¢æˆâ€œé£é™©é“¾â€ï¼›
- **è·¨ä¼šè¯é‡å¤**ï¼šç›¸ä¼¼çš„æ¬ºè¯ˆè„šæœ¬åœ¨ä¸åŒç›´æ’­ä¸­åå¤å‡ºç°ï¼ˆå³â€œDÃ©jÃ  Vuâ€ç°è±¡ï¼‰ï¼›
- **æ ‡æ³¨æˆæœ¬é«˜**ï¼šä»…æœ‰ä¼šè¯çº§æ ‡ç­¾å¯ç”¨ï¼Œç¼ºä¹ç»†ç²’åº¦çš„è¡Œä¸ºæ ‡æ³¨ã€‚

ä¼ ç»Ÿæ–¹æ³•éš¾ä»¥æ•æ‰è¿™ç§è·¨ä¼šè¯ã€é“¾æ¡å¼çš„æ¨¡å¼ï¼Œä¸”ç›´æ¥ä½¿ç”¨LLMè¿›è¡Œå®æ—¶æ¨ç†æ•ˆç‡ä½ä¸‹ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šCS-VARï¼ˆCross-Session Evidence-Aware Retrieval-Augmented Detectorï¼‰

#### æ ¸å¿ƒæ€æƒ³
æå‡ºä¸€ç§**è½»é‡æ¨¡å‹ + LLM æ¨ç†å¢å¼ºè®­ç»ƒ**çš„æ¡†æ¶ï¼Œåœ¨ä¿æŒå®æ—¶æ¨ç†æ•ˆç‡çš„åŒæ—¶ï¼Œåˆ©ç”¨LLMå¼ºå¤§çš„è·¨ä¼šè¯æ¨ç†èƒ½åŠ›æ¥æå‡å°æ¨¡å‹çš„é£é™©è¯†åˆ«èƒ½åŠ›ã€‚

#### åˆ›æ–°è®¾è®¡
1. **Patch-Level è¡Œä¸ºå»ºæ¨¡**  
   å°†ç›´æ’­ä¼šè¯åˆ’åˆ†ä¸ºç”¨æˆ·-æ—¶é—´æ®µçš„**è¡Œä¸ºç‰‡æ®µï¼ˆPatchï¼‰**ï¼Œæ„å»º Patch Grid ç»“æ„åŒ–è¡¨ç¤ºï¼Œä¾¿äºç»†ç²’åº¦åˆ†æã€‚

2. **ä¸¤é˜¶æ®µåä½œæœºåˆ¶**  
   - **å°æ¨¡å‹ï¼ˆPatchNetï¼‰**ï¼šè´Ÿè´£é«˜æ•ˆåœ°æå– Patch Embedding å’Œæ³¨æ„åŠ›æƒé‡ï¼Œç”¨äºæ£€ç´¢å’Œæ¨ç†æç¤ºï¼›
   - **å¤§æ¨¡å‹ï¼ˆLLMï¼‰**ï¼šåŸºäºæ£€ç´¢åˆ°çš„è·¨ä¼šè¯ç›¸ä¼¼ Patchï¼Œç»“åˆä¸Šä¸‹æ–‡è¿›è¡Œå¤šç²’åº¦æ¨ç†ï¼ˆPatch-level é£é™©è¯„åˆ† + Saliency æƒé‡ + Session-level ç»¼åˆåˆ¤æ–­ï¼‰ï¼›
   - **çŸ¥è¯†è’¸é¦**ï¼šå°† LLM çš„æ¨ç†ç»“æœä½œä¸ºç›‘ç£ä¿¡å·ï¼Œåå‘æ³¨å…¥ PatchNetï¼Œä½¿å…¶å­¦ä¼šâ€œåƒLLMä¸€æ ·æ€è€ƒâ€ã€‚

3. **æ£€ç´¢å¢å¼ºçš„æ¨ç†æœºåˆ¶ï¼ˆRetrieval-Augmented Reasoningï¼‰**  
   æ„å»ºä¸€ä¸ªç”± PatchNet ç¼–ç  + LLM ç”Ÿæˆæ‘˜è¦çš„ç´¢å¼•åº“ï¼ˆFAISSï¼‰ï¼Œæ”¯æŒå¯¹å†å²é«˜é£é™©è¡Œä¸ºç‰‡æ®µçš„è¯­ä¹‰æ£€ç´¢ï¼Œå¸®åŠ©å½“å‰ä¼šè¯è¯†åˆ«â€œä¼¼æ›¾ç›¸è¯†â€çš„æ¬ºè¯ˆæ¨¡å¼ã€‚

4. **å¯è§£é‡Šæ€§å¼º**  
   è¾“å‡ºä¸ä»…åŒ…æ‹¬ä¼šè¯çº§é£é™©åˆ†æ•°ï¼Œè¿˜æä¾›**Patch-level çš„é£é™©è¯æ®å’Œæ˜¾è‘—æ€§æƒé‡**ï¼Œæ”¯æŒäººå·¥å®¡æ ¸ä¸åˆè§„å®¡æŸ¥ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **æ•ˆç‡ vs èƒ½åŠ›å¹³è¡¡** | é¿å…ç›´æ¥éƒ¨ç½²LLMå¸¦æ¥çš„å»¶è¿Ÿå’Œç®—åŠ›å¼€é”€ï¼›ä»…åœ¨è®­ç»ƒæ—¶è°ƒç”¨LLMï¼Œæ¨ç†é˜¶æ®µå®Œå…¨ä¾èµ–è½»é‡PatchNet |
| **è·¨ä¼šè¯æ³›åŒ–èƒ½åŠ›** | æ˜¾å¼å»ºæ¨¡â€œé‡å¤è„šæœ¬â€ç°è±¡ï¼Œé€šè¿‡æ£€ç´¢å‘ç°è·¨æµä¸€è‡´æ€§æ¨¡å¼ï¼Œä¼˜äºä»…ä¾èµ–å•ä¸€ä¼šè¯çš„æ–¹æ³• |
| **å¼±ç›‘ç£ä¸‹çš„è¡¨ç°** | åœ¨ä»…æœ‰ä¼šè¯çº§æ ‡ç­¾çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡LLMç”Ÿæˆçš„ç»†ç²’åº¦ç›‘ç£ä¿¡å·å®ç°ç«¯åˆ°ç«¯å­¦ä¹  |
| **å¯è§£é‡Šæ€§** | æä¾›å±€éƒ¨è¡Œä¸ºç‰‡æ®µçš„é£é™©è¯„åˆ†å’Œ saliencyï¼Œè¾…åŠ©å†…å®¹å®¡æ ¸å‘˜å†³ç­– |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
ä½¿ç”¨æ¥è‡ªæŸå¤§å‹ç›´æ’­å¹³å°çš„çœŸå®å·¥ä¸šæ•°æ®é›†ï¼ŒåŒ…å«ä¸¤ä¸ªæ—¶é—´æ®µçš„æ•°æ®ï¼š

| æ•°æ®é›† | è®­ç»ƒæ—¶é—´ | æµ‹è¯•æ—¶é—´ | ä¼šè¯æ•°ï¼ˆè®­ç»ƒ/éªŒè¯/æµ‹è¯•ï¼‰ | å¹³å‡æ¯åœºåŠ¨ä½œæ•° | ç”¨æˆ·æ•° | æ—¶é•¿ |
|--------|----------|----------|-----------------------------|------------------|--------|-------|
| May Dataset | 05/20â€“06/03/2025 | 06/13â€“06/14/2025 | 176K / 23K / 22K | ~700 | ~36 | 30åˆ†é’Ÿ |
| June Dataset | 06/04â€“06/10/2025 | 06/16/2025 | 79K / 10K / 10K | ~725 | ~37 | 30åˆ†é’Ÿ |

> æ‰€æœ‰ä¼šè¯è¢«æˆªæ–­ä¸ºå‰30åˆ†é’Ÿï¼Œå¹¶ç¦»æ•£ä¸º100ç§’çš„æ—¶é—´æ§½ï¼ˆtimeslotï¼‰ã€‚

---

### å®éªŒè®¾ç½®
- **é¢„å¤„ç†**ï¼š
  - æ–‡æœ¬å­—æ®µï¼ˆè¯„è®ºã€è¯­éŸ³è½¬å½•ï¼‰ä½¿ç”¨ Chinese-BERT ç¼–ç ï¼›
  - è¿‡æ»¤ä½æ´»è·ƒç”¨æˆ·ï¼Œä¿ç•™æœ€å¤š50åè§‚ä¼—ï¼›
  - è´Ÿæ ·æœ¬æŒ‰1:10ä¸‹é‡‡æ ·ä»¥ç¼“è§£ç±»åˆ«ä¸å¹³è¡¡ã€‚
- **æ¨¡å‹å®ç°**ï¼š
  - ä½¿ç”¨ PyTorch å’Œ doubao-1.5-pro-32k APIï¼ˆLLMï¼‰ï¼›
  - PatchNet ä½¿ç”¨ Transformer + LSTM + Graph-Aware Transformerï¼›
  - åµŒå…¥ç»´åº¦ $d_k = 128$ï¼ŒAdamWä¼˜åŒ–å™¨ï¼Œbatch size=128ï¼Œearly stoppingï¼ˆpatience=20ï¼‰ã€‚
- **è®­ç»ƒæµç¨‹åˆ†å››é˜¶æ®µ**ï¼š
  1. **Warm-up**ï¼šPatchNet å­¦ä¹ ä¼šè¯çº§é¢„æµ‹å’Œ patch embeddingï¼›
  2. **Index Construction**ï¼šé€‰å–å…³é”® patchï¼Œç”¨LLMç”Ÿæˆ session-aware summaryï¼Œå­˜å…¥ FAISSï¼›
  3. **Retrieval-Augmented LLM Reasoning**ï¼šå¯¹æŸ¥è¯¢ patch æ£€ç´¢ç›¸ä¼¼å†å² patchï¼ŒLLM è¾“å‡º multi-granularity åˆ¤æ–­ï¼›
  4. **Cross-Granularity Distillation**ï¼šç”¨ LLM è¾“å‡ºç›‘ç£ PatchNet çš„ patch-level å’Œ session-level é¢„æµ‹ã€‚

---

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **PR-AUC â†‘** | Precision-Recall æ›²çº¿ä¸‹é¢ç§¯ï¼Œé€‚ç”¨äºæ­£è´Ÿæ ·æœ¬ä¸å‡è¡¡åœºæ™¯ |
| **F1-score â†‘** | ç²¾ç¡®ç‡ä¸å¬å›ç‡çš„è°ƒå’Œå¹³å‡ |
| **R@0.1FPR â†‘** | å½“å‡é˜³æ€§ç‡ â‰¤10% æ—¶çš„å¬å›ç‡ |
| **FPR@0.9R â†“** | å½“å¬å›ç‡è¾¾åˆ°90%æ—¶çš„å‡é˜³æ€§ç‡ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
åˆ†ä¸ºä¸¤ç±»ï¼š

#### ï¼ˆ1ï¼‰Sequence Modelsï¼ˆåºåˆ—å»ºæ¨¡ï¼‰
- Transformer
- Reformer
- Informer

#### ï¼ˆ2ï¼‰Instance Aggregation Methodsï¼ˆå®ä¾‹èšåˆï¼Œæºè‡ª Multiple Instance Learningï¼‰
- mi-NET
- AtMILï¼ˆAttention-based MILï¼‰
- AdMIL
- MIL-LET
- TimeMIL
- TAIL-MIL

> æ‰€æœ‰åŸºçº¿å‡åº”ç”¨äºç›¸åŒçš„ Patch Grid è¾“å…¥ç»“æ„ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### æ€§èƒ½å¯¹æ¯”ï¼ˆTable 2ï¼‰

| æ–¹æ³• | PR-AUC (May) | F1-score (May) | R@0.1FPR (May) | FPR@0.9R (May) | PR-AUC (June) | F1-score (June) |
|------|--------------|----------------|------------------|------------------|----------------|------------------|
| Transformer | 0.7189 | 0.6668 | 0.8394 | 0.1580 | 0.6801 | 0.6341 |
| TimeMIL | 0.7353 | 0.6790 | 0.8599 | 0.1436 | 0.6963 | 0.6471 |
| TAIL-MIL | 0.7316 | 0.6785 | 0.8570 | 0.1341 | 0.7029 | 0.6509 |
| **CS-VAR (Ours)** | **0.7721** | **0.7099** | **0.8761** | **0.1190** | **0.7322** | **0.6822** |

> âœ… **æœ€ä½³ç»“æœåŠ ç²—ï¼Œ*è¡¨ç¤ºç»Ÿè®¡æ˜¾è‘—ä¼˜äºæœ€å¼ºåŸºçº¿**

#### å…³é”®æå‡ï¼ˆvs æœ€ä½³åŸºçº¿ TimeMILï¼‰
- **PR-AUC æå‡ +5.0%ï¼ˆMayï¼‰**
- **FPR@0.9R ä¸‹é™ 10.9%ï¼ˆMayï¼‰**
- **R@0.1FPR æå‡ 1.9%**
- åœ¨ June æ•°æ®é›†ä¸ŠåŒæ ·å–å¾—æ˜¾è‘—é¢†å…ˆ

> è¡¨æ˜ CS-VAR åœ¨ä¿æŒé«˜å¬å›çš„åŒæ—¶å¤§å¹…é™ä½è¯¯æŠ¥ï¼Œæ›´é€‚åˆå®é™…é£æ§ç³»ç»Ÿéœ€æ±‚ã€‚

---

### æ¶ˆèå®éªŒï¼ˆAblation Study, Table 3ï¼‰

| å˜ä½“ | PR-AUC | F1-score | R@0.1FPR | FPR@0.9R |
|------|--------|----------|-----------|------------|
| **Full CS-VAR** | **0.7721** | **0.7099** | **0.8761** | **0.1190** |
| w/o Gï¼ˆæ— å›¾æ³¨æ„åŠ›ï¼‰ | 0.7642 | 0.7027 | 0.8746 | 0.1253 |
| w/o Rï¼ˆæ— æ£€ç´¢ï¼‰ | 0.7616 | 0.7023 | 0.8639 | 0.1318 |
| w/o Lï¼ˆæ— LLMæ¨ç†ï¼Œä»…embeddingå¹³å‡ï¼‰ | 0.7614 | 0.6948 | 0.8737 | 0.1290 |
| w/o Dï¼ˆæ— è’¸é¦ï¼Œä»…ä¼šè¯çº§ç›‘ç£ï¼‰ | 0.7592 | 0.6930 | 0.8712 | 0.1262 |

#### å‘ç°ï¼š
- ç§»é™¤ä»»ä¸€ç»„ä»¶éƒ½ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ï¼›
- **æœ€ä¸¥é‡çš„æ˜¯ç§»é™¤è’¸é¦ï¼ˆw/o Dï¼‰**ï¼Œè¯´æ˜ LLM çš„ç»†ç²’åº¦ç›‘ç£è‡³å…³é‡è¦ï¼›
- **ç§»é™¤æ£€ç´¢ï¼ˆw/o Rï¼‰å½±å“ç¬¬äºŒå¤§**ï¼Œè¯æ˜è·¨ä¼šè¯è¯æ®çš„æœ‰æ•ˆæ€§ï¼›
- **LLM çš„ç»“æ„åŒ–æ¨ç†è¿œèƒœç®€å• embedding èåˆï¼ˆw/o Lï¼‰**ï¼Œä½“ç°å…¶æ¨ç†ä»·å€¼ã€‚

---

### åœ¨çº¿éƒ¨ç½²æ•ˆæœï¼ˆTable 4ï¼‰

| æ¨¡å‹ | PR-AUC | F1-score | R@0.1FPR | FPR@0.9R |
|------|--------|----------|-----------|------------|
| XGBoostï¼ˆçº¿ä¸Šæ—§æ¨¡å‹ï¼‰ | 0.4543 | 0.4599 | 0.6321 | 0.4481 |
| Transformerï¼ˆçº¿ä¸Šæ—§æ¨¡å‹ï¼‰ | 0.6096 | 0.5881 | 0.7830 | 0.2173 |
| **CS-VAR** | **0.6643** | **0.6546** | **0.8305** | **0.1905** |

> âš¡ è‡ª **2025å¹´11æœˆèµ·å·²åœ¨ä¸»æµç›´æ’­å¹³å°å¤§è§„æ¨¡ä¸Šçº¿**ï¼Œæ˜¾è‘—è¶…è¶ŠåŸæœ‰ç”Ÿäº§æ¨¡å‹ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **â€œDÃ©jÃ  Vuâ€æ¨¡å¼æ™®éå­˜åœ¨**ï¼šè®¸å¤šè¡¨é¢ä¸åŒçš„ç›´æ’­ï¼ˆå¦‚å…¼èŒæ‹›è˜ vs æŠ˜æ‰£æ‰‹æœºé”€å”®ï¼‰å®é™…ä¸Šéµå¾ªç›¸åŒçš„è¡Œä¸ºè„šæœ¬ï¼Œå¯é€šè¿‡è·¨ä¼šè¯æ£€ç´¢è¯†åˆ«ã€‚
2. **LLM å¯ä½œä¸ºâ€œæ•™å¸ˆâ€æŒ‡å¯¼å°æ¨¡å‹**ï¼šå³ä½¿ä¸èƒ½åœ¨çº¿éƒ¨ç½²LLMï¼Œä¹Ÿå¯åœ¨è®­ç»ƒä¸­åˆ©ç”¨å…¶å¼ºå¤§çš„æ¨ç†èƒ½åŠ›è¿›è¡ŒçŸ¥è¯†è’¸é¦ã€‚
3. **Patch-level å»ºæ¨¡ + Retrieval æ˜¯å…³é”®**ï¼šå°†è¡Œä¸ºåˆ†è§£ä¸ºè¯­ä¹‰å•å…ƒå¹¶å»ºç«‹ç´¢å¼•ï¼Œä½¿ç³»ç»Ÿå…·å¤‡è®°å¿†å’Œç±»æ¯”èƒ½åŠ›ã€‚
4. **å¯è§£é‡Šæ€§ä¸å®ç”¨æ€§å…¼å¤‡**ï¼šè¾“å‡º patch-level é£é™©ä¿¡å·ï¼Œæœ‰åŠ©äºäººå·¥å®¡æ ¸å›¢é˜Ÿå¿«é€Ÿå®šä½è¿è§„è¡Œä¸ºã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–é«˜è´¨é‡çš„LLM API**ï¼šè‹¥LLMå“åº”ä¸ç¨³å®šæˆ–æˆæœ¬è¿‡é«˜ï¼Œä¼šå½±å“è®­ç»ƒæ•ˆç‡ï¼›
2. **å†·å¯åŠ¨é—®é¢˜**ï¼šåˆæœŸç¼ºä¹è¶³å¤Ÿå†å² patch æ„å»ºç´¢å¼•ï¼Œå¯èƒ½å½±å“æ—©æœŸæ£€ç´¢è´¨é‡ï¼›
3. **åŠ¨æ€æ¼”åŒ–å¯¹æŠ—**ï¼šæ¶æ„ä¸»æ’­å¯èƒ½è°ƒæ•´è„šæœ¬è§„é¿å·²çŸ¥æ¨¡å¼ï¼Œéœ€æŒç»­æ›´æ–°ç´¢å¼•ï¼›
4. **è®¡ç®—èµ„æºè¦æ±‚è¾ƒé«˜ï¼ˆè®­ç»ƒé˜¶æ®µï¼‰**ï¼šæ¶‰åŠå¤šæ¬¡LLMè°ƒç”¨å’Œ FAISS ç´¢å¼•ç»´æŠ¤ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **å¢é‡å¼ç´¢å¼•æ›´æ–°æœºåˆ¶**ï¼šæ”¯æŒåœ¨çº¿å­¦ä¹ ï¼ŒåŠ¨æ€æ·»åŠ æ–°å‘ç°çš„é«˜é£é™© patchï¼›
2. **å¯¹æŠ—æ€§è®­ç»ƒç­–ç•¥**ï¼šæ¨¡æ‹Ÿæ”»å‡»è€…è¡Œä¸ºå˜åŒ–ï¼Œæé«˜æ¨¡å‹é²æ£’æ€§ï¼›
3. **å¤šæ¨¡æ€æ‰©å±•**ï¼šèåˆè§†è§‰ï¼ˆOCRï¼‰ã€éŸ³é¢‘ç­‰ä¿¡å·ï¼Œè¿›ä¸€æ­¥ä¸°å¯Œ patch è¡¨ç¤ºï¼›
4. **æ›´é«˜æ•ˆçš„è’¸é¦æ–¹å¼**ï¼šæ¢ç´¢æ— éœ€å®Œæ•´LLMæ¨ç†å³å¯è·å¾—ç±»ä¼¼ç›‘ç£ä¿¡å·çš„æ–¹æ³•ï¼ˆå¦‚åˆæˆæ•°æ®ç”Ÿæˆï¼‰ã€‚

---

## æ€»ç»“
âœ… **CS-VAR æˆåŠŸå®ç°äº†â€œç”¨LLMä¹‹æ™ºï¼Œè¡Œå°æ¨¡å‹ä¹‹é€Ÿâ€çš„ç†å¿µ**ï¼Œæ˜¯é¦–ä¸ªå°† Retrieval-Augmented LLM æ¨ç†å¼•å…¥ç›´æ’­é£é™©è¯„ä¼°çš„å·¥ä½œã€‚å®ƒä¸ä»…åœ¨ç¦»çº¿å’Œåœ¨çº¿è¯„æµ‹ä¸­è¾¾åˆ° SOTA æ€§èƒ½ï¼Œè€Œä¸”æä¾›äº†**å¯è§£é‡Šã€å¯æ“ä½œçš„é£é™©çº¿ç´¢**ï¼Œä¸ºå·¥ä¸šçº§å†…å®¹å®‰å…¨ç³»ç»Ÿæä¾›äº†æ–°çš„èŒƒå¼ã€‚

</details>

---

### 6. [FedUMM: A General Framework for Federated Learning with Unified Multimodal Models](https://arxiv.org/abs/2601.15390)

**Authors**: Zhaolong Su, Leheng Zhao, Xiaoying Wu, Ziyue Xu, Jindong Wang  
**Category**: cs.LG  
**Published**: 2026-01-23  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.15390v1  

#### Abstract
Unified multimodal models (UMMs) are emerging as strong foundation models that can do both generation and understanding tasks in a single architecture. However, they are typically trained in centralized settings where all training and downstream datasets are gathered in a central server, limiting th...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFedUMM: A General Framework for Federated Learning with Unified Multimodal Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰çš„ **Unified Multimodal Models (UMMs)**ï¼ˆå¦‚ BLIP3oï¼‰é€šå¸¸åœ¨é›†ä¸­å¼ç¯å¢ƒä¸‹è®­ç»ƒï¼Œä¾èµ–äºå°†æ‰€æœ‰æ•°æ®æ±‡èšåˆ°ä¸­å¿ƒæœåŠ¡å™¨ã€‚è¿™åœ¨åŒ»ç–—ã€é‡‘èç­‰éšç§æ•æ„Ÿåœºæ™¯ä¸­ä¸å¯è¡Œï¼Œä¸”éš¾ä»¥åº”å¯¹åœ°ç†åˆ†å¸ƒå¹¿æ³›ã€æ•°æ®å¼‚æ„ï¼ˆnon-IIDï¼‰çš„å®é™…éƒ¨ç½²éœ€æ±‚ã€‚

æ­¤å¤–ï¼Œç›´æ¥å°†ä¼ ç»Ÿ **Federated Learning (FL)** åº”ç”¨äºå¤§è§„æ¨¡ UMMs é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **é«˜é€šä¿¡å¼€é”€**ï¼šæ¨¡å‹å‚æ•°é‡è¾¾æ•°åäº¿ï¼Œå…¨æ¨¡å‹èšåˆæˆæœ¬æé«˜ï¼›
- **æ¶æ„å¤æ‚æ€§**ï¼šå¤šæ¨¡æ€ç¼–ç å™¨ã€è·¨æ¨¡æ€å¯¹é½æ¨¡å—ã€ç”Ÿæˆè§£ç å™¨éœ€ååŒä¼˜åŒ–ï¼›
- **æ•°æ®å¼‚è´¨æ€§**ï¼šä¸åŒå®¢æˆ·ç«¯å…·æœ‰ä¸åŒçš„æ¨¡æ€ç»„åˆä¸è¯­ä¹‰åˆ†å¸ƒï¼ˆMultimodal Semantic Shiftï¼‰ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šFedUMM
ä½œè€…æå‡º **FedUMM** â€”â€” ä¸€ä¸ªé¢å‘ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹çš„é€šç”¨è”é‚¦å­¦ä¹ æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰åŸºäº LoRA çš„å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆParameter-Efficient Fine-Tuningï¼‰
- å®¢æˆ·ç«¯ä»…è®­ç»ƒè½»é‡çº§çš„ **LoRA adapters**ï¼Œå†»ç»“ä¸»å¹²æ¨¡å‹ï¼ˆå¦‚ BLIP3oï¼‰ï¼›
- æœåŠ¡å™¨åªèšåˆ adapter å‚æ•°æ›´æ–°ï¼Œå¤§å¹…é™ä½é€šä¿¡å¼€é”€ï¼ˆå‡å°‘ >99%ï¼‰ï¼›
- é¿å…ç¾éš¾æ€§é—å¿˜ï¼Œæå‡ç¨³å®šæ€§ã€‚

#### ï¼ˆ2ï¼‰æ¨¡æ€æ„ŸçŸ¥çš„é€‚é…å™¨è®¾è®¡ï¼ˆPer-Modality Adaptersï¼‰
- å¼•å…¥é’ˆå¯¹è§†è§‰ã€æ–‡æœ¬ç­‰ä¸åŒæ¨¡æ€çš„ç‹¬ç«‹ LoRA æ¨¡å—ï¼›
- æ”¯æŒå®¢æˆ·ç«¯æ‹¥æœ‰ä¸å®Œæ•´æˆ–å¤šæ ·çš„æ¨¡æ€è¾“å…¥ï¼ˆå¦‚éƒ¨åˆ†å®¢æˆ·ä»…æœ‰å›¾åƒæ— æ–‡æœ¬ï¼‰ï¼›
- å…±äº« **Alignment Token** ç»´æŒè·¨æ¨¡æ€è¯­ä¹‰ä¸€è‡´æ€§ã€‚

#### ï¼ˆ3ï¼‰è¯­ä¹‰æ„ŸçŸ¥èåˆç­–ç•¥ FedFusion
- åŠ¨æ€åŠ æƒèšåˆæœºåˆ¶ï¼šæ ¹æ®å®¢æˆ·ç«¯æœ¬åœ°éªŒè¯æ€§èƒ½å¼•å…¥è´¨é‡æƒé‡ $ \alpha_k $ï¼›
- èšåˆå…¬å¼ä¸ºï¼š
  $$
  W_{\text{global}} = \sum_{k=1}^K \frac{n_k^\alpha}{\sum_j n_j^\alpha} \cdot \theta_k
  $$
  å…¶ä¸­ $ n_k $ æ˜¯æœ¬åœ°æ ·æœ¬æ•°ï¼Œ$ \alpha $ æ§åˆ¶åæ–œç¨‹åº¦ã€‚

#### ï¼ˆ4ï¼‰è®¾å¤‡-è¾¹ç¼˜ååŒè®­ç»ƒæ¶æ„ï¼ˆDevice-Edge Partitioningï¼‰
- å°†æ—©æœŸç¼–ç å™¨éƒ¨ç½²åœ¨å®¢æˆ·ç«¯è®¾å¤‡ä¸Šï¼›
- å¤æ‚çš„ Transformer å±‚éƒ¨ç½²åœ¨è¾¹ç¼˜æœåŠ¡å™¨ï¼›
- ç»“åˆå·®åˆ†éšç§ä¸æ¢¯åº¦å‹ç¼©ï¼Œè¿›ä¸€æ­¥ä¿æŠ¤éšç§å¹¶é™ä½å¸¦å®½æ¶ˆè€—ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | FedUMM | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ FedAvg å…¨å¾®è°ƒï¼‰ |
|------|--------|-----------------------------|
| é€šä¿¡å¼€é”€ | ~0.094 GB/è½® | ~28.6 GB/è½®ï¼ˆâ†“99.7%ï¼‰ |
| å®¢æˆ·ç«¯è®¡ç®—æˆæœ¬ | â†“86.7% GPUå°æ—¶ | é«˜ |
| æœåŠ¡å™¨è®¡ç®—è´Ÿæ‹… | â†“87.5% GPUå°æ—¶ | é«˜ |
| æ€§èƒ½è¡¨ç° | æ›´ä¼˜ï¼ˆ+0.7% Accï¼‰ | è¾ƒä½ |
| å¯æ‰©å±•æ€§ | æ”¯æŒæœ€å¤š16ä¸ªå®¢æˆ·ç«¯ | æ˜“å› å¼‚æ„æ€§å´©æºƒ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šFedUMM åœ¨æ˜¾è‘—é™ä½æˆæœ¬çš„åŒæ—¶ï¼Œä¿æŒç”šè‡³ç•¥å¾®è¶…è¶Šå…¨æ¨¡å‹è”é‚¦è®­ç»ƒçš„æ€§èƒ½ï¼Œæ˜¯é¦–ä¸ªå¯å¤ç°ã€å·¥ä¸šçº§æ”¯æŒ UMMs çš„ FL æ¡†æ¶ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | ä»»åŠ¡ç±»å‹ | æè¿° |
|-------|---------|------|
| **VQA v2** | è§†è§‰é—®ç­”ï¼ˆUnderstandingï¼‰ | åŒ…å« 1.1M å›¾åƒ-é—®é¢˜å¯¹ï¼Œè¯„ä¼°å‡†ç¡®ç‡ï¼ˆAccuracy %ï¼‰ |
| **COCO Captions** | å›¾åƒæè¿°ç”Ÿæˆï¼ˆGenerationï¼‰ | æ¯å›¾5æ¡äººå·¥æ ‡æ³¨æè¿°ï¼Œä½¿ç”¨ BLEU-4ã€METEORã€CIDErã€SPICE |
| **CC3M** | é¢„è®­ç»ƒæ•°æ® | è‡ªåŠ¨æŠ“å–çš„ 3.3M å›¾æ–‡å¯¹ï¼Œç”¨äºé¢„è®­ç»ƒé˜¶æ®µ |
| **GenEval** | ç»„åˆå¼å›¾æ–‡ç”Ÿæˆï¼ˆCompositional Generationï¼‰ | æµ‹è¯•å•ç‰©ä½“ã€åŒç‰©ä½“ã€è®¡æ•°ã€é¢œè‰²ã€ä½ç½®ã€å±æ€§ç»‘å®šå…­é¡¹èƒ½åŠ›ï¼ŒæŠ¥å‘Šå„é¡¹åŠæ€»ä½“ Accuracy |

### å®éªŒè®¾ç½®
- **å®¢æˆ·ç«¯æ•°é‡**ï¼šK âˆˆ {2, 4, ..., 16}
- **æ•°æ®åˆ’åˆ†æ–¹å¼**ï¼šDirichlet åˆ†é…æ§åˆ¶éç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆnon-IIDï¼‰ï¼Œæµ“åº¦å‚æ•° Î± âˆˆ {0.1, 0.5, 1.0}ï¼ˆÎ±è¶Šå°å¼‚è´¨æ€§è¶Šé«˜ï¼‰
- **æœ¬åœ°è®­ç»ƒ**ï¼šæ¯è½®æ¯ä¸ªå®¢æˆ·ç«¯æ‰§è¡Œ E=5 ä¸ª epoch
- **æ€»é€šä¿¡è½®æ¬¡**ï¼šT = 100
- **æ¨¡å‹æ¶æ„**ï¼šä»¥ **BLIP3o** ä¸ºä¸»å¹²ï¼Œé‡‡ç”¨ **LoRA rank=16**, scaling factor=32
- **ä¼˜åŒ–å™¨**ï¼šAdamWï¼Œlr=2e-5ï¼Œweight decay=0.05ï¼Œbatch size=32/client
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA H100 GPUï¼ˆæœåŠ¡å™¨8å¡ï¼Œå®¢æˆ·ç«¯å„1å¡ï¼‰
- **å®ç°æ¡†æ¶**ï¼šåŸºäº **NVIDIA FLARE (NVFlare)** æ„å»º

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æ˜¯å¦å…¨å¾®è°ƒ | æ˜¯å¦å‚æ•°é«˜æ•ˆ | é€šä¿¡å¼€é”€ | æ˜¯å¦é€‚ç”¨äº UMMs |
|------|------------|---------------|-----------|------------------|
| Centralized Full FT | æ˜¯ | å¦ | é«˜ | æ˜¯ï¼ˆä½†ä¸ä¿æŠ¤éšç§ï¼‰ |
| Single-site LoRA | æ˜¯ | æ˜¯ | ä½ | æ˜¯ï¼ˆæ— æ³•åä½œï¼‰ |
| FedAvg (Full) | æ˜¯ | å¦ | æé«˜ï¼ˆ~28.6GB/è½®ï¼‰ | ä¸å®ç”¨ |
| FedProx / FedOpt (Full) | æ˜¯ | å¦ | æé«˜ | æ•ˆæœæœ‰é™ |
| **FedUMM (LoRA)** | å¦ | æ˜¯ | æä½ï¼ˆ~0.094GB/è½®ï¼‰ | âœ”ï¸ ä¸“ä¸º UMM è®¾è®¡ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ï¼ˆ1ï¼‰VQA v2 ä¸Šçš„æ€§èƒ½è¡¨ç°ï¼ˆè¡¨1ï¼‰

| å®¢æˆ·ç«¯æ•° K | Î±=0.1 (é«˜åº¦å¼‚æ„) | Î±=0.5 | Î±=1.0 (è¾ƒå‡åŒ€) | å¹³å‡ Acc (%) |
|-----------|------------------|--------|----------------|--------------|
| Centralized | â€” | â€” | â€” | **82.4** |
| K=2       | 81.2            | 81.8   | 82.1           | 81.7 (99.2%) |
| K=8       | 79.2            | 80.2   | 81.2           | 80.2 (97.3%) |
| K=16      | **77.5**        | 79.0   | 80.8           | **79.1**     |

> ğŸ” **è§‚å¯Ÿ**ï¼š
- å³ä½¿åœ¨æœ€æç«¯å¼‚æ„æ¡ä»¶ä¸‹ï¼ˆÎ±=0.1, K=16ï¼‰ï¼Œä»èƒ½è¾¾åˆ° **77.5%** å‡†ç¡®ç‡ï¼›
- ç›¸æ¯”é›†ä¸­å¼è®­ç»ƒä»…ä¸‹é™ **3.3ä¸ªç™¾åˆ†ç‚¹**ï¼Œä¿ç•™çº¦ **96.0%** æ€§èƒ½ï¼›
- éšç€ Î± å¢å¤§ï¼ˆæ•°æ®æ›´å‡åŒ€ï¼‰ï¼Œæ€§èƒ½å·®è·ç¼©å°ï¼Œè¯´æ˜æœ¬åœ°æ•°æ®è§„æ¨¡æœ‰åŠ©äºç¼“è§£åˆ†å¸ƒåç§»ã€‚

---

### ï¼ˆ2ï¼‰GenEval ä¸Šçš„ç”Ÿæˆèƒ½åŠ›ï¼ˆè¡¨2ï¼ŒÎ±=0.5ï¼‰

| å®¢æˆ·ç«¯æ•° | SingleObj | TwoObj | Count | Color | Position | ColorAttrib | Overall |
|--------|-----------|--------|-------|-------|----------|-------------|---------|
| Centralized | 97.0 | 80.0 | 63.0 | 81.0 | 23.0 | 52.0 | **61.0** |
| K=8       | 96.2 | 78.5 | 61.0 | 79.2 | 21.5 | 50.0 | **59.2** |
| K=16      | 95.5 | 77.0 | 59.0 | 77.5 | 20.0 | 48.0 | **57.5** |

> ğŸ” **è§‚å¯Ÿ**ï¼š
- ç”Ÿæˆä»»åŠ¡å¯¹æ•°æ®ç¢ç‰‡åŒ–æ›´æ•æ„Ÿï¼ŒK=16 æ—¶æ•´ä½“ä¸‹é™ **3.5%**ï¼›
- å¤æ‚æŠ€èƒ½å¦‚â€œè®¡æ•°â€ã€â€œé¢œè‰²å±æ€§ç»‘å®šâ€é€€åŒ–æ˜æ˜¾ï¼ˆâ†“4.0%ï¼‰ï¼›
- ä½†ä»ä¿æŒè¾ƒå¼ºç”Ÿæˆèƒ½åŠ›ï¼Œè¯æ˜ FedUMM æ”¯æŒé«˜è´¨é‡ç»„åˆç”Ÿæˆã€‚

---

### ï¼ˆ3ï¼‰æ¶ˆèå®éªŒç»“æœï¼ˆè¡¨3 & è¡¨4ï¼‰

#### è¡¨3ï¼šä¸åŒè®­ç»ƒèŒƒå¼çš„æ¯”è¾ƒï¼ˆVQA v2, K=8ï¼‰

| é…ç½® | å‡†ç¡®ç‡ (%) | é€šä¿¡é‡ (GB) | æ˜¯å¦ä¿æŠ¤éšç§ |
|------|------------|-------------|--------------|
| Centralized (Full FT) | 82.6 | â€” | âœ— |
| Centralized + LoRA | 82.4 | â€” | âœ— |
| Single-site + LoRA | 81.9 | â€” | âœ”ï¸ |
| **FedUMM (K=8)** | **80.2** | **0.094** | âœ”ï¸ |

> âœ”ï¸ FedUMM åœ¨ä¿æŠ¤éšç§çš„å‰æä¸‹ï¼Œè¾¾åˆ°é›†ä¸­å¼ LoRA æ€§èƒ½çš„ **97.3%**ï¼Œé€šä¿¡æ€»é‡ä»…éœ€çº¦ **7.6GBï¼ˆ100è½®ï¼‰**ã€‚

#### è¡¨4ï¼šæ•ˆç‡å¯¹æ¯”ï¼ˆæ¯è½®å¹³å‡ï¼‰

| æ–¹æ³• | Client GPU-h | Server GPU-h | Comm. (GB) | Acc (%) |
|------|---------------|---------------|------------|---------|
| FedAvg (Full) | 4.5 | 0.8 | 28.6 | 79.5 |
| FedProx (Full) | 4.8 | 0.8 | 28.6 | 79.8 |
| FedOpt | 4.5 | 1.2 | 28.6 | 79.6 |
| **FedUMM** | **0.6** | **0.1** | **0.094** | **80.2** |
| â†“ ç›¸æ¯” FedAvg | **86.7%** | **87.5%** | **99.7%** | **+0.7pp** |

> ğŸ’¡ **æƒŠäººå‘ç°**ï¼šå‚æ•°é«˜æ•ˆå¾®è°ƒä¸ä»…èŠ‚çœèµ„æºï¼Œåè€Œæå‡äº†æ€§èƒ½ï¼å¯èƒ½åŸå› æ˜¯ LoRA çº¦æŸäº†ä¼˜åŒ–ç©ºé—´ï¼Œèµ·åˆ°äº†éšå¼æ­£åˆ™åŒ–ä½œç”¨ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆå±€éƒ¨éIIDæ•°æ®ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **å‚æ•°é«˜æ•ˆå¾®è°ƒæ˜¯è”é‚¦ UMM çš„å…³é”®**  
   LoRA-based æ–¹æ³•ä¸ä»…èƒ½å°†é€šä¿¡å¼€é”€é™ä½ä¸¤ä¸ªæ•°é‡çº§ä»¥ä¸Šï¼ˆä» 28.6 â†’ 0.094 GB/è½®ï¼‰ï¼Œè¿˜èƒ½ç•¥å¾®æå‡æ€§èƒ½ï¼Œè¡¨æ˜å…¶ä¸ä»…æ˜¯å·¥ç¨‹ä¼˜åŒ–ï¼Œæ›´æ˜¯ç®—æ³•æ”¹è¿›ã€‚

2. âœ… **æ¨¡æ€ç‰¹å®šå¤„ç†è‡³å…³é‡è¦**  
   ä¸åŒæ¨¡æ€ï¼ˆè§†è§‰ vs æ–‡æœ¬ï¼‰åœ¨å®¢æˆ·ç«¯ä¸Šçš„åˆ†å¸ƒåç§»æ¨¡å¼ä¸åŒï¼Œéœ€è¦åˆ†åˆ«å»ºæ¨¡ã€‚Per-modality adapters æå‡äº†é²æ£’æ€§å’Œçµæ´»æ€§ã€‚

3. âœ… **è”é‚¦ UMM æ€§èƒ½æ¥è¿‘é›†ä¸­å¼è®­ç»ƒ**  
   FedUMM åœ¨ç†è§£ä»»åŠ¡ï¼ˆVQAï¼‰ä¸Šè¾¾åˆ°é›†ä¸­å¼æ€§èƒ½çš„ **97.1%**ï¼Œåœ¨ç”Ÿæˆä»»åŠ¡ï¼ˆGenEvalï¼‰ä¸Šè¾¾ **97.0%**ï¼Œå·®è·æå°ï¼Œå…·å¤‡å®é™…åº”ç”¨ä»·å€¼ã€‚

4. âœ… **å®¢æˆ·ç«¯æ•°é‡å½±å“å¯æ§**  
   æ€§èƒ½éšå®¢æˆ·ç«¯å¢åŠ å‘ˆâ€œä¼˜é›…é€€åŒ–â€ï¼ˆgraceful degradationï¼‰ï¼Œå³ä½¿åœ¨16ä¸ªé«˜åº¦å¼‚æ„å®¢æˆ·ç«¯ä¸‹ä»ä¿æŒå¯ç”¨ç²¾åº¦ã€‚

---

### å±€é™æ€§
| é™åˆ¶ | è¯´æ˜ |
|------|------|
| **ä»¿çœŸç¯å¢ƒ** | å®éªŒåŸºäº Dirichlet åˆ’åˆ†æ¨¡æ‹Ÿ non-IIDï¼Œæœªè€ƒè™‘çœŸå®ç½‘ç»œå»¶è¿Ÿã€å®¢æˆ·ç«¯æ‰çº¿ã€å¼‚æ­¥æ›´æ–°ç­‰é—®é¢˜ |
| **æ¨¡å‹è§„æ¨¡å—é™** | å½“å‰åŸºäº BLIP3oï¼Œå°äº GPT-4Vã€Gemini ç­‰ SOTA æ¨¡å‹ï¼›æ›´å¤§æ¨¡å‹é¢ä¸´è¾¹ç¼˜è®¾å¤‡å†…å­˜ç“¶é¢ˆ |
| **æ¨¡æ€è¦†ç›–ä¸è¶³** | å½“å‰èšç„¦ vision-languageï¼Œå°šæœªæ‰©å±•è‡³ audioã€videoã€3D ç­‰å¤šæ¨¡æ€ç»„åˆ |
| **ç¼ºä¹å½¢å¼åŒ–éšç§ä¿éšœ** | è™½ç„¶ FL éšå¼ä¿æŠ¤æ•°æ®ä¸ä¸Šä¼ ï¼Œä½†æ¢¯åº¦ä»å¯èƒ½æ³„éœ²ä¿¡æ¯ï¼›æœªé›†æˆ Differential Privacy æˆ–å®‰å…¨èšåˆ |

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‹“å±•è‡³é«˜é£é™©é¢†åŸŸ**  
   å¦‚åŒ»ç–—å½±åƒ+ä¸´åºŠæŠ¥å‘Šè”åˆåˆ†æï¼Œé‡‘èæ–‡æ¡£+è¯­éŸ³å®¢æœç­‰ï¼Œæ¨åŠ¨ FedUMM åœ¨éšç§æ•æ„Ÿè¡Œä¸šçš„è½åœ°ã€‚

2. **å¢å¼ºå¯¹æŠ—é²æ£’æ€§**  
   åŠ å…¥ **Adversarial Training** æˆ– **Byzantine-robust aggregation**ï¼ˆå¦‚ Krumã€FLTrustï¼‰ï¼Œé˜²èŒƒæ¶æ„å®¢æˆ·ç«¯æ”»å‡»ã€‚

3. **ä¸ªæ€§åŒ–ä¸æŒç»­å­¦ä¹ **  
   å¼•å…¥ä¸ªæ€§åŒ–å±‚ï¼ˆpersonalization layersï¼‰é€‚åº”ä¸åŒå®¢æˆ·ç«¯åå¥½ï¼Œå¹¶ç»“åˆ **Continual Learning** æŠµå¾¡ç¾éš¾æ€§é—å¿˜ã€‚

4. **è·¨è®¾å¤‡è§„æ¨¡åŒ–ï¼ˆCross-Device FLï¼‰**  
   å°†å½“å‰â€œè·¨æœºæ„â€ï¼ˆcross-siloï¼‰è®¾ç½®æ¨å¹¿åˆ°â€œè·¨è®¾å¤‡â€ï¼ˆcross-deviceï¼‰ï¼Œæ”¯æŒæˆåƒä¸Šä¸‡ç§»åŠ¨ç«¯è®¾å¤‡å‚ä¸è®­ç»ƒï¼Œéœ€è§£å†³è¿æ¥ä¸ç¨³å®šã€èµ„æºå—é™ç­‰é—®é¢˜ã€‚

---

## æ€»ç»“
**FedUMM** æ˜¯é¦–ä¸ªç³»ç»Ÿç ”ç©¶ **Federated Unified Multimodal Models** çš„å®è¯å·¥ä½œï¼Œé€šè¿‡ **LoRA + æ¨¡æ€é€‚é…å™¨ + è¯­ä¹‰èåˆ** çš„ç»„åˆï¼Œåœ¨ä¿è¯éšç§çš„åŒæ—¶å®ç°äº†é«˜æ€§èƒ½ã€ä½å¼€é”€çš„è”é‚¦è®­ç»ƒã€‚å®ƒä¸ä»…å¡«è¡¥äº† FL ä¸ UMM äº¤å‰é¢†åŸŸçš„ç©ºç™½ï¼Œä¹Ÿä¸ºæœªæ¥åœ¨åŒ»ç–—ã€æ•™è‚²ã€æ™ºèƒ½ç»ˆç«¯ç­‰åœºæ™¯éƒ¨ç½²å¤§å‹å¤šæ¨¡æ€ AI æä¾›äº†å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 7. [Towards Reliable Medical LLMs: Benchmarking and Enhancing Confidence Estimation of Large Language Models in Medical Consultation](https://arxiv.org/abs/2601.15645)

**Authors**: Zhiyao Ren, Yibing Zhan, Siyuan Liang, Guozheng Ma, Baosheng Yu, Dacheng Tao  
**Category**: cs.CL  
**Published**: 2026-01-23  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2601.15645v1  

#### Abstract
Large-scale language models (LLMs) often offer clinical judgments based on incomplete information, increasing the risk of misdiagnosis. Existing studies have primarily evaluated confidence in single-turn, static settings, overlooking the coupling between confidence and correctness as clinical eviden...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTowards Reliable Medical LLMs: Benchmarking and Enhancing Confidence Estimation of Large Language Models in Medical Consultation

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰ **Large Language Models (LLMs)** åœ¨åŒ»ç–—è¯Šæ–­ä¸­å¸¸åŸºäºä¸å®Œæ•´ä¿¡æ¯åšå‡ºåˆ¤æ–­ï¼Œå…¶ç½®ä¿¡åº¦ä¼°è®¡ï¼ˆconfidence estimationï¼‰å­˜åœ¨ä¸¥é‡ç¼ºé™·ï¼š
- å¤šæ•°ç ”ç©¶åœ¨**å•è½®ã€é™æ€åœºæ™¯**ä¸‹è¯„ä¼°ç½®ä¿¡åº¦ï¼Œå¿½ç•¥äº†çœŸå®åŒ»ç–—å’¨è¯¢ä¸­éšç€è¯æ®ç§¯ç´¯è€ŒåŠ¨æ€å˜åŒ–çš„â€œç½®ä¿¡åº¦-æ­£ç¡®æ€§â€å…³ç³»ï¼›
- ç°æœ‰ä»»åŠ¡å¤šä¸º**å°é—­å¼é—®ç­”æˆ–å¤šé€‰é¢˜**ï¼Œéš¾ä»¥åæ˜ çœŸå®ä¸´åºŠå¯¹è¯çš„å¤æ‚æ€§å’Œå¼€æ”¾æ€§ï¼›
- ç½®ä¿¡åº¦æ–¹æ³•è¦†ç›–ä¸å…¨ï¼Œç¼ºä¹å¯¹ token-levelã€consistency-level å’Œ self-verbalized æ–¹æ³•çš„ç³»ç»Ÿæ¯”è¾ƒã€‚

è¿™äº›é—®é¢˜å¯¼è‡´æ¨¡å‹å¯èƒ½ç»™å‡ºé«˜ç½®ä¿¡ä½†é”™è¯¯çš„è¯Šæ–­ï¼Œå½±å“ä¸´åºŠå†³ç­–å®‰å…¨ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
æœ¬æ–‡æå‡ºä¸¤ä¸ªæ ¸å¿ƒè´¡çŒ®ï¼š

#### ï¼ˆ1ï¼‰æ„å»ºé¦–ä¸ªé¢å‘å¤šè½®äº¤äº’çš„åŒ»ç–—ç½®ä¿¡åº¦è¯„ä¼°åŸºå‡†ï¼ˆMedical Confidence Benchmarkï¼‰
- æ”¯æŒ**å¼€æ”¾å¼è¯Šæ–­ç”Ÿæˆä»»åŠ¡**ï¼Œæ›´è´´è¿‘çœŸå®åŒ»ç”Ÿé—®è¯Šæµç¨‹ï¼›
- å¼•å…¥**ä¿¡æ¯å……åˆ†æ€§æ¢¯åº¦**ï¼ˆInformation Sufficiency Gradientï¼‰ï¼Œå°†æ‚£è€…ä¿¡æ¯æŒ‰æ¯”ä¾‹åˆ’åˆ†ä¸º 1%ã€20%ã€40%ã€60%ã€80%ã€100%ï¼Œæ¨¡æ‹Ÿé€æ­¥è·å–ç—…å²çš„è¿‡ç¨‹ï¼›
- ç»Ÿä¸€æ•´åˆä¸‰ä¸ªåŒ»ç–—æ•°æ®é›†ï¼š**DDXPlus**, **MediTOD**, **MedQA**ï¼Œæ¶µç›–åˆæˆç—…ä¾‹ã€çœŸå®åŒ»æ‚£å¯¹è¯å’Œä¸“ä¸šè€ƒè¯•é¢˜ç›®ã€‚

#### ï¼ˆ2ï¼‰æå‡º **MedConf**ï¼šä¸€ç§åŸºäºè¯æ®çš„è‡ªé™ˆè¿°å¼ç½®ä¿¡åº¦ä¼°è®¡æ¡†æ¶
MedConf çš„è®¾è®¡åŸºäºä¸¤å¤§æ´å¯Ÿï¼š
1. ä¼ ç»Ÿä¾èµ–æ¨¡å‹è¾“å‡ºç‰¹å¾çš„æ–¹æ³•ï¼ˆå¦‚ token æ¦‚ç‡æˆ–å“åº”ä¸€è‡´æ€§ï¼‰åœ¨åŒ»å­¦é¢†åŸŸè¡¨ç°ä¸ç¨³å®šï¼›
2. åŒ»ç–—ç½®ä¿¡åº¦åº”åŒæ—¶è¡¡é‡**è¯Šæ–­å‡†ç¡®æ€§**å’Œ**ä¿¡æ¯å®Œæ•´æ€§**ã€‚

**MedConf å·¥ä½œæµç¨‹å¦‚ä¸‹**ï¼š
1. **Diagnostic Generation**ï¼šLLM æ ¹æ®å½“å‰æ‚£è€…ä¿¡æ¯ç”Ÿæˆåˆæ­¥è¯Šæ–­ $d$ï¼›
2. **Symptom Profile Generation**ï¼šé€šè¿‡ **Retrieval-Augmented Generation (RAG)** è·å–æƒå¨åŒ»å­¦æ–‡çŒ®ï¼Œæå–è¯¥ç–¾ç—…çš„ç—‡çŠ¶è°±ï¼ˆsymptom profileï¼‰ï¼Œå¹¶æ ‡æ³¨æ¯ä¸ªç—‡çŠ¶çš„é‡è¦æ€§ç­‰çº§ï¼ˆstrong / moderate / weakï¼‰ï¼›
3. **Confidence Generation**ï¼šåˆ†ææ‚£è€…ä¿¡æ¯ä¸ç—‡çŠ¶è°±ä¹‹é—´çš„ä¸‰ç§å…³ç³»ï¼š
   - **Supported**ï¼šç—‡çŠ¶è¢«æåŠ
   - **Missing**ï¼šå…³é”®ç—‡çŠ¶ç¼ºå¤±
   - **Contradictory**ï¼šä¿¡æ¯çŸ›ç›¾
   æœ€ç»ˆé€šè¿‡åŠ æƒèšåˆè¿™äº›è¯æ®ç”Ÿæˆå¯è§£é‡Šçš„ç½®ä¿¡åº¦åˆ†æ•° $C \in [0,100]$ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **å¯é æ€§** | ä¸ä¾èµ–æ˜“å—å¹²æ‰°çš„ token æ¦‚ç‡æˆ–é‡‡æ ·ä¸€è‡´æ€§ï¼Œå‡å°‘å¯¹ç‰¹å®šæ¨¡å‹æ¶æ„çš„æ•æ„Ÿæ€§ |
| **å¯è§£é‡Šæ€§** | è¾“å‡ºæ”¯æŒã€ç¼ºå¤±ã€çŸ›ç›¾çš„å…·ä½“ç—‡çŠ¶åˆ—è¡¨ï¼Œä¾¿äºåŒ»ç”Ÿç†è§£ä¸ºä½•ç½®ä¿¡åº¦ä¸é«˜ |
| **é²æ£’æ€§** | å¯¹å™ªå£°ä¿¡æ¯ã€å¤šç—…å…±å­˜ï¼ˆmultimorbidityï¼‰ã€ä¿¡æ¯ä¸è¶³ç­‰ç°å®æŒ‘æˆ˜æ›´å…·ç¨³å®šæ€§ |
| **å®ç”¨æ€§** | å¯é›†æˆåˆ°åŒ»ç–— Agent ä¸­æŒ‡å¯¼æ˜¯å¦ç»§ç»­æé—®æˆ–ç»ˆæ­¢å’¨è¯¢ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
| æ•°æ®é›† | æè¿° |
|--------|------|
| **DDXPlus** | åˆæˆå¤§è§„æ¨¡ç—…ç†æ•°æ®é›†ï¼Œå«ç—‡çŠ¶ã€æ—¢å¾€å²å’ŒçœŸå®è¯Šæ–­ |
| **MediTOD** | çœŸå®ä¸–ç•ŒåŒ»æ‚£å¯¹è¯æ•°æ®é›†ï¼Œå¸¦è¯¦ç»†è¯­ä¹‰æ ‡æ³¨ |
| **MedQA** | æ¥è‡ª USMLE ç­‰åŒ»å­¦æ‰§ç…§è€ƒè¯•çš„ä¸“ä¸šçº§å¤šé¡¹é€‰æ‹©é¢˜ï¼Œè½¬åŒ–ä¸ºå¼€æ”¾å¼ç”Ÿæˆä»»åŠ¡ |

æ‰€æœ‰æ•°æ®å‡é¢„å¤„ç†ä¸º**åŒ»ç”Ÿ-æ‚£è€…å¯¹è¯æ ¼å¼**æˆ–**åŒ»ç–—æŠ¥å‘Šæ ¼å¼**ï¼Œä»¥ç»Ÿä¸€ä¸ºå¼€æ”¾è¯Šæ–­ä»»åŠ¡ã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼šLlama-3.1ï¼ˆå¼€æºï¼‰ã€GPT-4.1ï¼ˆé—­æºï¼‰
- **ä¿¡æ¯å±‚çº§**ï¼šæŒ‰ä¿¡æ¯é‡åˆ’åˆ† 6 ä¸ªé˜¶æ®µï¼ˆ1%, 20%, ..., 100%ï¼‰
- **æ¯é˜¶æ®µæ“ä½œ**ï¼š
  1. åŸºäºå½“å‰ä¿¡æ¯ç”Ÿæˆè¯Šæ–­
  2. ç”¨ä¸åŒ confidence estimation æ–¹æ³•è®¡ç®—ç½®ä¿¡åˆ†
  3. åˆ¤æ–­è¯Šæ–­æ˜¯å¦æ­£ç¡®
  4. åˆ†æç½®ä¿¡åº¦ä¸å‡†ç¡®æ€§çš„ç›¸å…³æ€§åŠåŒºåˆ†èƒ½åŠ›

### è¯„ä¼°æŒ‡æ ‡
| ç±»å‹ | æŒ‡æ ‡ | è¯´æ˜ |
|------|------|------|
| **ç›¸å…³æ€§** | Pearson / Spearman Correlation | è¡¡é‡ç½®ä¿¡åº¦ä¸è¯Šæ–­å‡†ç¡®æ€§çš„ä¸€è‡´è¶‹åŠ¿ |
| **åˆ¤åˆ«åŠ›** | AUROC, AUPRC | è¡¡é‡ç½®ä¿¡åº¦èƒ½å¦æœ‰æ•ˆåŒºåˆ†æ­£ç¡® vs é”™è¯¯è¯Šæ–­ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å…±å®ç°å¹¶è¯„ä¼° **27 ç§ä»£è¡¨æ€§ç½®ä¿¡åº¦ä¼°è®¡æ–¹æ³•**ï¼Œåˆ†ç±»å¦‚ä¸‹ï¼š

| ç±»åˆ« | æ–¹æ³•æ•°é‡ | ç¤ºä¾‹ |
|------|--------|------|
| **Token-level** | 10 | ASP, MSP, Entropy, Perplexity, TokenSAR |
| **Consistency-level** | 13 | PoC, LexSim, SemSim, MC-SE, Semantic Entropy |
| **Self-verbalized** | 4 | CE, CoT CE, Top-k CE, P(True) |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆMedConf vs æœ€ä¼˜åŸºçº¿ï¼‰

| é…ç½® | æ–¹æ³• | AUROC â†‘ | Pearson â†‘ |
|------|------|---------|----------|
| Llama-3.1 + DDXPlus | **MedConf** | **0.722** | **0.968** |
|                      | PMI (best baseline) | 0.593 | 0.829 |
| Llama-3.1 + MediTOD | **MedConf** | **0.687** | **0.943** |
|                     | Conditional PMI | 0.560 | 0.734 |
| Llama-3.1 + MedQA   | **MedConf** | **0.796** | **0.979** |
|                     | Entropy | 0.766 | 0.905 |
| GPT-4.1 + DDXPlus   | **MedConf** | **0.795** | **0.936** |
|                     | SemSim(BERT) | 0.622 | 0.785 |
| GPT-4.1 + MedQA     | **MedConf** | **0.690** | **0.989** |
|                     | Ecc | 0.667 | 0.906 |

> âœ… **å¹³å‡æå‡**ï¼šç›¸æ¯”æœ€ä¼˜åŸºçº¿ï¼ŒMedConf åœ¨ Pearson ä¸Šå¹³å‡æå‡ **0.410â€“0.476**ï¼Œåœ¨ AUROC ä¸Šæå‡ **0.129â€“0.124**

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **Token-level æ–¹æ³•**ï¼šåœ¨ MedQA ä¸Šè¡¨ç°è‰¯å¥½ï¼ˆå¦‚ Perplexity, TokenSAR Pearson > 0.96ï¼‰ï¼Œä½†åœ¨ DDXPlus/MediTOD ä¸Šæ˜¾è‘—ä¸‹é™ï¼ˆPearson < 0.5ï¼‰ï¼Œè¡¨æ˜å…¶å¯¹åŒ»å­¦æœ¯è¯­æ•æ„Ÿï¼›
- **Consistency-level æ–¹æ³•**ï¼šåœ¨ GPT-4.1 ä¸Šéƒ¨åˆ†æœ‰æ•ˆï¼Œä½†åœ¨ Llama-3.1 ä¸Šæ™®éå¤±æ•ˆï¼Œæ˜¾ç¤ºå…¶å¯¹æ¨¡å‹é‡‡æ ·è¡Œä¸ºé«˜åº¦ä¾èµ–ï¼›
- **Self-verbalized æ–¹æ³•**ï¼šæ•´ä½“æ›´ç¨³å¥ï¼Œä½†ä»å­˜åœ¨æ³¢åŠ¨ï¼ˆå¦‚ CoT CE åœ¨ MediTOD ä¸Š Spearman ä»… 0.086ï¼‰ï¼›
- **MedConf**ï¼šåœ¨æ‰€æœ‰é…ç½®ä¸‹å‡å–å¾—**æœ€ä½³æˆ–æ¥è¿‘æœ€ä½³æ€§èƒ½**ï¼Œä¸”è·¨æ¨¡å‹/æ•°æ®é›†è¡¨ç°ç¨³å®šã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Study on DDXPlus with Llama-3.1ï¼‰

| å˜ä½“ | AUROC | AUPRC | Pearson | Spearman |
|------|-------|-------|--------|----------|
| **MedConf** (å®Œæ•´) | **0.772** | **0.708** | **0.968** | **0.943** |
| w/o Symptom Profile | 0.657 | 0.645 | 0.786 | 0.657 |
| w/o RAG | 0.670 | 0.588 | 0.939 | 0.771 |
| w/o Structure Format | 0.688 | 0.692 | 0.907 | 0.943 |
| w/o Importance Level | 0.639 | 0.601 | 0.959 | 0.943 |

> ğŸ” ç»“è®ºï¼š
- **Symptom Profile** æ˜¯æœ€å…³é”®ç»„ä»¶ï¼Œç§»é™¤åæ€§èƒ½å¤§å¹…ä¸‹é™ï¼›
- **RAG** æ˜¾è‘—å¢å¼ºåˆ¤åˆ«åŠ›ï¼Œè¯´æ˜å¤–éƒ¨çŸ¥è¯†ä¸å¯æˆ–ç¼ºï¼›
- **ç»“æ„åŒ–æ ¼å¼** å’Œ **é‡è¦æ€§åˆ†çº§** èƒ½è¿›ä¸€æ­¥ä¼˜åŒ–æ¨ç†è´¨é‡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **åŒ»ç–—æ•°æ®ä¼šæ”¾å¤§ä¼ ç»Ÿç½®ä¿¡åº¦æ–¹æ³•çš„å›ºæœ‰ç¼ºé™·**ï¼š
   - Token-level æ–¹æ³•å—ä¸“ä¸šæœ¯è¯­åˆ†è¯å½±å“å¤§ï¼›
   - Consistency-level æ–¹æ³•å› è®­ç»ƒæ•°æ®åå·®ï¼ˆå¸¸è§ç—…ä¼˜å…ˆï¼‰äº§ç”Ÿè™šå‡ä¸€è‡´æ€§ï¼›
2. **ä¿¡æ¯å®Œæ•´æ€§æ˜¯åŒ»ç–—ç½®ä¿¡åº¦çš„æ ¸å¿ƒç»´åº¦**ï¼š
   - å³ä½¿è¯Šæ–­æ— è¯¯ï¼Œè‹¥å…³é”®ç—‡çŠ¶æœªç¡®è®¤ï¼ˆå¦‚å³ä¸‹è…¹ç—›æœªæåŠï¼‰ï¼Œä¹Ÿä¸åº”ç»™äºˆé«˜ç½®ä¿¡ï¼›
3. **MedConf å®ç°äº†æ›´å¼ºçš„ç›¸å…³æ€§ã€åˆ¤åˆ«åŠ›å’Œé²æ£’æ€§**ï¼š
   - åœ¨å¤šç§æ¨¡å‹å’Œæ•°æ®é›†ä¸Š consistently outperform SOTAï¼›
   - å¯¹æ— å…³ä¿¡æ¯å¹²æ‰°å…·æœ‰å¼ºæŠ—æ€§ï¼ˆCV_sample: 12.401 vs CE: 47.575ï¼‰ï¼›
4. **é›†æˆåˆ° Healthcare Agent åæ•ˆç‡æ›´é«˜**ï¼š
   - è¾¾åˆ°ç›¸åŒè¯Šæ–­å‡†ç¡®ç‡ï¼ˆ36%ï¼‰æ—¶ï¼ŒMedConf å¹³å‡åªéœ€ **17.84 è½®å¯¹è¯**ï¼Œè¿œå°‘äº CE çš„ 25.04 è½®ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **è®¡ç®—å¼€é”€è¾ƒå¤§**ï¼šéœ€è°ƒç”¨ RAG å’Œå¤šæ¬¡ LLM æ¨ç†ï¼Œå»¶è¿Ÿé«˜äº token-level æ–¹æ³•ï¼›
- **ä¾èµ–é«˜è´¨é‡å¤–éƒ¨çŸ¥è¯†åº“**ï¼šè‹¥ RAG æ£€ç´¢ä¸åˆ°ç›¸å…³å†…å®¹ï¼Œä¼šå½±å“ symptom profile æ„å»ºï¼›
- **å°šæœªåœ¨çœŸå®ä¸´åºŠç¯å¢ƒä¸­éªŒè¯**ï¼šç›®å‰ä»…åŸºäº benchmark æ•°æ®é›†æµ‹è¯•ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. æ‰©å±•è‡³å…¶ä»–åŒ»ç–—ä»»åŠ¡ï¼šå¦‚ **medical report generation**, **clinical note summarization**ï¼›
2. ä¼˜åŒ–æ•ˆç‡ï¼šå¼•å…¥ç¼“å­˜æœºåˆ¶ã€è½»é‡åŒ– symptom generatorï¼›
3. å¼€å±•å‰ç»æ€§ä¸´åºŠè¯•éªŒï¼šè®©åŒ»ç”Ÿä¸ confidence-aware AI ç³»ç»Ÿäº’åŠ¨ï¼Œè¯„ä¼°å®é™…å¯ç”¨æ€§å’Œä¿¡ä»»åº¦ï¼›
4. æ¢ç´¢å¤šæ¨¡æ€ç½®ä¿¡åº¦å»ºæ¨¡ï¼šç»“åˆå½±åƒã€å®éªŒå®¤æ£€æŸ¥ç­‰éæ–‡æœ¬ä¿¡æ¯ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬è®ºæ–‡é¦–æ¬¡å»ºç«‹äº†é¢å‘å¤šè½®åŒ»ç–—å¯¹è¯çš„ç½®ä¿¡åº¦è¯„ä¼°åŸºå‡†ï¼Œå¹¶æå‡ºäº† **MedConf**â€”â€”ä¸€ä¸ªèåˆæ£€ç´¢å¢å¼ºä¸ç»“æ„åŒ–è¯æ®åˆ†æçš„ self-verbalized æ¡†æ¶ï¼Œåœ¨å‡†ç¡®æ€§ã€å¯è§£é‡Šæ€§å’Œé²æ£’æ€§æ–¹é¢å…¨é¢è¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œä¸ºæ„å»ºå¯ä¿¡åŒ»ç–— LLM æä¾›äº†æ–°è·¯å¾„ã€‚

</details>

---

### 8. [Gated Sparse Attention: Combining Computational Efficiency with Training Stability for Long-Context Language Models](https://arxiv.org/abs/2601.15305)

**Authors**: Alfred Shen, Aaron Shen  
**Category**: cs.AI  
**Published**: 2026-01-23  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.15305v1  

#### Abstract
The computational burden of attention in long-context language models has motivated two largely independent lines of work: sparse attention mechanisms that reduce complexity by attending to selected tokens, and gated attention variants that improve training sta-bility while mitigating the attention ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šGated Sparse Attention: Combining Computational Efficiency with Training Stability for Long-Context Language Models

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°ä»£é•¿ä¸Šä¸‹æ–‡è¯­è¨€æ¨¡å‹é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼š
- **è®¡ç®—æ•ˆç‡ç“¶é¢ˆ**ï¼šæ ‡å‡† Attention çš„å¤æ‚åº¦ä¸º $O(L^2d)$ï¼Œåœ¨é•¿åºåˆ—ï¼ˆå¦‚ 128Kï¼‰ä¸‹æ¨ç†å’Œè®­ç»ƒæˆæœ¬æé«˜ã€‚
- **è®­ç»ƒä¸ç¨³å®šä¸æ³¨æ„åŠ›æ²‰é™ï¼ˆattention sinkï¼‰ç°è±¡**ï¼šæ¨¡å‹å€¾å‘äºå°†å¤§é‡æ³¨æ„åŠ›æƒé‡åˆ†é…ç»™æ—©æœŸ tokenï¼ˆå°¤å…¶æ˜¯ç¬¬ä¸€ä¸ª tokenï¼‰ï¼Œæµªè´¹è¡¨å¾èƒ½åŠ›ï¼›åŒæ—¶ï¼Œæœªå—æ§çš„æ¿€æ´»å€¼å¯èƒ½å¯¼è‡´ loss spikesï¼Œå½±å“ä¼˜åŒ–ç¨³å®šæ€§ã€‚

ç°æœ‰æ–¹æ³•ä¸­ï¼Œ**sparse attention** æå‡äº†æ•ˆç‡ä½†æœªè§£å†³ç¨³å®šæ€§é—®é¢˜ï¼Œè€Œ **gated attention** æ”¹å–„äº†è®­ç»ƒç¨³å®šæ€§å’Œ sink é—®é¢˜å´ä¿ç•™äº†äºŒæ¬¡å¤æ‚åº¦ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šGated Sparse Attention (GSA)
GSA æ˜¯ä¸€ç§æ–°å‹ Attention æ¶æ„ï¼Œèåˆäº† sparse attention å’Œ gated attention çš„ä¼˜åŠ¿ï¼Œå®ç°â€œé±¼ä¸ç†ŠæŒå…¼å¾—â€ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
1. **Gated Lightning Indexer**  
   å°† DeepSeek çš„ ReLU-based indexer æ›¿æ¢ä¸º **sigmoid æ¿€æ´»å‡½æ•°**ï¼Œç”Ÿæˆæœ‰ç•Œã€å¯è§£é‡Šçš„é€‰æ‹©åˆ†æ•°ï¼ˆ$I_{t,s} \in (0, H')$ï¼‰ï¼Œæå‡æ¢¯åº¦ç¨³å®šæ€§å’Œé€‰æ‹©è´¨é‡ã€‚

2. **Adaptive Sparsity Controller**  
   åŠ¨æ€è°ƒæ•´æ¯ä¸ªæŸ¥è¯¢æ‰€é€‰ token æ•°é‡ $k_t$ï¼ŒåŸºäº indexer è¾“å‡ºçš„æ–¹å·®ï¼š
   - é«˜æ–¹å·® â†’ é€‰æ‹©æ›´å°‘ tokenï¼ˆé«˜ç½®ä¿¡åº¦ï¼‰
   - ä½æ–¹å·® â†’ æ‰©å¤§ä¸Šä¸‹æ–‡çª—å£ï¼ˆåº”å¯¹ä¸ç¡®å®šæ€§ï¼‰
   - å…¬å¼ï¼š$k_t = \text{clamp}(k_{\text{base}} \cdot \text{Var}(I_{t,:}) / V, k_{\min}, k_{\max})$

3. **Dual Gating æœºåˆ¶**
   - **G2ï¼ˆValue Gateï¼‰**ï¼šåœ¨èšåˆå‰å¯¹ Values è¿›è¡Œé—¨æ§ï¼ŒæŠ‘åˆ¶æ— å…³ç»´åº¦ã€‚
   - **G1ï¼ˆOutput Gateï¼‰**ï¼šåœ¨ SDPA åå¯¹è¾“å‡ºè¿›è¡Œé—¨æ§ï¼Œæä¾›â€œä¸»åŠ¨ä¸¢å¼ƒâ€è·¯å¾„ï¼Œæ›¿ä»£ sink token çš„åŠŸèƒ½ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | Sparse Only | Gated Only | GSA |
|------|-------------|-----------|-----|
| å¤æ‚åº¦ | âœ… $O(Lkd)$ | âŒ $O(L^2d)$ | âœ… $O(L^2d' + Lkd)$ |
| è®­ç»ƒç¨³å®šæ€§ | âŒ å­˜åœ¨ spikes | âœ… æ˜¾è‘—æ”¹å–„ | âœ… æ›´ä¼˜ |
| Attention Sink | âŒ ä»ä¸¥é‡ | âœ… ç¼“è§£ | âœ… å‡ ä¹æ¶ˆé™¤ |
| è¡¨è¾¾èƒ½åŠ› | âš ï¸ å—é™äºç¨€ç–æ€§ | âœ… å¼•å…¥éçº¿æ€§ | âœ… æ›´å¼ºï¼ˆç†è®ºè¯æ˜ï¼‰ |

> **æ ¸å¿ƒæ€æƒ³**ï¼šgating æä¾›ç¨³å®šã€æœ‰ç•Œçš„ä¿¡å·ç”¨äºæ›´å¥½ token é€‰æ‹©ï¼›sparsity èŠ‚çœè®¡ç®—èµ„æºä»¥æ”¯æŒ gating å¼€é”€ï¼ŒäºŒè€…äº’è¡¥å¢å¼ºã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **é¢„è®­ç»ƒæ•°æ®**ï¼šSlimPajama æ•°æ®é›†ä¸­çš„ **400B tokens**
- **è¯„ä¼°ä»»åŠ¡**ï¼š
  - **è¯­è¨€å»ºæ¨¡**ï¼šWikiText-103ã€C4ï¼ˆPerplexityï¼‰
  - **ä¸‹æ¸¸ä»»åŠ¡**ï¼šMMLUã€GSM8Kã€HumanEvalã€HellaSwagã€C-Eval
  - **é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›**ï¼šRULER åŸºå‡†ï¼ˆæ”¯æŒè‡³ 128K ä¸Šä¸‹æ–‡ï¼‰
  - **ä½ç½®æ’å€¼**ï¼šä½¿ç”¨ YaRN å®ç°ä» 4K åˆ° 128K çš„å¤–æ¨

### å®éªŒè®¾ç½®
- **æ¨¡å‹è§„æ¨¡**ï¼š1.7B å‚æ•°ï¼Œ24 å±‚ï¼Œhidden dimension=2048ï¼Œ16 query headsï¼Œ4 key-value heads
- **è®­ç»ƒé…ç½®**ï¼š
  - ä½¿ç”¨ AdamW ä¼˜åŒ–å™¨
  - ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼š
    1. Warm-up é˜¶æ®µï¼ˆ~1K æ­¥ï¼‰ï¼šindexer å•ç‹¬è®­ç»ƒï¼Œæ¨¡ä»¿ full attention åˆ†å¸ƒï¼ˆKL lossï¼‰
    2. End-to-end é˜¶æ®µï¼šå…¨æ¨¡å‹è”åˆè®­ç»ƒ
  - Indexer ä½¿ç”¨ 10Ã— å­¦ä¹ ç‡åŠ é€Ÿæ”¶æ•›
- **ç¡¬ä»¶**ï¼š8Ã— H100 GPUs

### è¯„ä¼°æŒ‡æ ‡
| ç±»å‹ | æŒ‡æ ‡ |
|------|------|
| æ•ˆç‡ | Prefill/Decode å»¶è¿Ÿã€å†…å­˜å ç”¨ã€speedup å€æ•° |
| æ€§èƒ½ | Perplexityï¼ˆè¶Šä½è¶Šå¥½ï¼‰ã€Accuracyï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰ã€RULER Score |
| ç¨³å®šæ€§ | Loss spikes æ•°é‡ã€æœ€å¤§æ¿€æ´»å€¼ï¼ˆmax activationï¼‰ |
| Sink ç°è±¡ | First-token attention æ¯”ä¾‹ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
1. **Standard**ï¼šæ ‡å‡† Grouped-Query Attention
2. **Sparse Only**ï¼šDeepSeek-V3.2 é£æ ¼çš„ sparse attentionï¼ˆReLU indexer + å›ºå®š kï¼‰
3. **Gated Only**ï¼šå®Œæ•´ quadratic attention + G1/G2 gatingï¼ˆQiu et al., 2025ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### âœ… è¯­è¨€å»ºæ¨¡ï¼ˆPerplexityï¼‰
| æ–¹æ³• | WikiText-103 | C4 |
|------|--------------|----|
| Standard | 6.03 | 7.82 |
| Sparse Only | 6.02 | 7.79 |
| Gated Only | 5.76 | 7.45 |
| **GSA** | **5.70** | **7.38** |

> GSA åœ¨ä¿æŒç¨€ç–æ€§çš„å‰æä¸‹è¿›ä¸€æ­¥é™ä½ PPLï¼Œä¼˜äºå•ä¸€æœºåˆ¶ã€‚

#### âœ… ä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®ç‡ï¼ˆå¹³å‡æå‡ +2.4 ptsï¼‰
| æ–¹æ³• | MMLU | GSM8K | HumanEval | HellaSwag | C-Eval | Avg |
|------|------|-------|-----------|----------|--------|-----|
| Standard | 58.8 | 52.9 | 28.7 | 73.1 | 60.3 | 54.7 |
| GSA | **61.4** | **56.0** | **30.5** | **74.9** | **62.9** | **57.1** |

> ç‰¹åˆ«æ˜¯åœ¨ MMLU å’Œ GSM8K ä¸Šè¡¨ç°çªå‡ºï¼Œè¡¨æ˜å…¶å¢å¼ºäº†çŸ¥è¯†æ£€ç´¢ä¸å¤šæ­¥æ¨ç†èƒ½åŠ›ã€‚

#### âœ… é•¿ä¸Šä¸‹æ–‡ç†è§£ï¼ˆRULER @128Kï¼‰
| æ–¹æ³• | 4K | 8K | 16K | 32K | 64K* | **128K*** |
|------|----|----|-----|-----|------|---------|
| Standard | 88.9 | 85.9 | 83.2 | 79.5 | 37.5 | 31.7 |
| Sparse Only | 89.1 | 86.5 | 84.0 | 80.2 | 42.4 | 36.8 |
| Gated Only | 90.6 | 87.1 | 84.6 | 79.8 | 66.6 | 58.8 |
| **GSA** | **91.2** | **88.5** | **86.1** | **82.3** | **69.5** | **62.2** |

> GSA åœ¨ 128K ä¸Šå¾—åˆ†æ¥è¿‘ç¿»å€ï¼ˆ31.7 â†’ 62.2ï¼‰ï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚

#### âœ… æ³¨æ„åŠ›æ²‰é™ç¼“è§£
| æ–¹æ³• | First-token attention |
|------|------------------------|
| Standard | 46.7% |
| Sparse Only | 38.2% |
| Gated Only | 4.8% |
| **GSA** | **3.9%** |

> å‡ ä¹å®Œå…¨æ¶ˆé™¤ attention sink ç°è±¡ã€‚

#### âœ… è®­ç»ƒç¨³å®šæ€§
| æ–¹æ³• | Spikes / 100K steps | Max activation |
|------|---------------------|----------------|
| Standard | 12.3 | 1053 |
| Gated Only | 0.8 | 94 |
| **GSA** | **0.3** | **87** |

> loss spikes å‡å°‘ **98%**ï¼Œæœ€å¤§æ¿€æ´»å€¼ä¸‹é™ä¸€ä¸ªæ•°é‡çº§ã€‚

#### âœ… æ¨ç†æ•ˆç‡ï¼ˆ@128K contextï¼‰
| æ–¹æ³• | Prefill Speedup | Decode Speedup | Memory |
|------|------------------|----------------|--------|
| Sparse Only | 12Ã— | 16Ã— | 0.95Ã— |
| Gated Only | ~1Ã— | ~1Ã— | 1.02Ã— |
| **GSA** | **11Ã—** | **12Ã—** | **0.97Ã—** |

> GSA å®ç°äº†ä¸ sparse-only ç›¸å½“çš„é€Ÿåº¦ä¼˜åŠ¿ï¼Œè¿œè¶… dense attentionã€‚

---

### æ¶ˆèå®éªŒç»“æœ

#### ğŸ”¹ é—¨æ§ä½ç½®ï¼ˆTable 10ï¼‰
| é…ç½® | PPL | MMLU | ç¨³å®šæ€§ |
|------|-----|------|--------|
| No gating | 6.02 | 59.1 | Moderate |
| G2 only | 5.82 | 59.2 | Good |
| G1 only | 5.79 | 60.1 | Good |
| **G1 + G2** | **5.70** | **61.4** | Excellent |

> **G1ï¼ˆoutput gateï¼‰è´¡çŒ®æœ€å¤§**ï¼ŒåŒé—¨æ§ç»„åˆæœ€ä¼˜ã€‚

#### ğŸ”¹ ç¨€ç–ç¨‹åº¦ $k$ï¼ˆTable 11ï¼‰
| $k$ | PPL | RULER-128K | Speedup |
|------|-----|------------|---------|
| 512 | 5.89 | 54.32 | 22Ã— |
| 1024 | 5.78 | 58.91 | 16Ã— |
| **2048** | **5.70** | **62.18** | **12Ã—** |
| 4096 | 5.69 | 63.45 | 8Ã— |

> $k=2048$ åœ¨æ€§èƒ½ä¸é€Ÿåº¦é—´å–å¾—æœ€ä½³å¹³è¡¡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **GSA æˆåŠŸèåˆ sparse ä¸ gated attention çš„ä¼˜ç‚¹**ï¼š
   - å®ç°äº† **12â€“16Ã— çš„æ¨ç†åŠ é€Ÿ**ï¼ˆ128K ä¸Šä¸‹æ–‡ï¼‰
   - è¾¾åˆ°ç”šè‡³è¶…è¶Šçº¯ gated attention çš„ **è¯­è¨€å»ºæ¨¡è´¨é‡å’Œä¸‹æ¸¸æ€§èƒ½**
   - å½»åº•ç¼“è§£ attention sinkï¼ˆfirst-token attn ä» 47% â†’ <4%ï¼‰
   - æå¤§æå‡è®­ç»ƒç¨³å®šæ€§ï¼ˆloss spikes â†“98%ï¼‰

2. **ç†è®ºä¿éšœå……åˆ†**ï¼š
   - å¤æ‚åº¦åˆ†æï¼ˆTheorem 1ï¼‰
   - è¡¨è¾¾èƒ½åŠ›ä¸¥æ ¼å¼ºäºæ ‡å‡† attentionï¼ˆTheorem 3ï¼‰
   - æ³¨æ„åŠ›æ²‰é™ç¼“è§£æœºåˆ¶å½¢å¼åŒ–ï¼ˆTheorem 4ï¼‰
   - æ¢¯åº¦èŒƒæ•°æœ‰ç•Œã€SGD æ”¶æ•›ä¿è¯ï¼ˆTheorems 5 & 6ï¼‰

3. **å‚æ•°å¼€é”€å°**ï¼šä»…å¢åŠ çº¦ **4.4%** çš„é¢å¤–å‚æ•°ï¼ˆä¸»è¦æ¥è‡ª output gateï¼‰

---

### æ–¹æ³•çš„å±€é™æ€§
1. **çŸ­åºåˆ—ä¸åˆ’ç®—**ï¼šå½“ $L < 4K$ æ—¶ï¼Œindexer çš„ $O(L^2)$ æˆæœ¬å¯èƒ½è¶…è¿‡ç¨€ç–å¸¦æ¥çš„æ”¶ç›Šï¼Œå»ºè®®åˆ‡æ¢å› dense attentionã€‚
2. **æç«¯é•¿åº¦ä¸‹ indexer æˆä¸ºä¸»å¯¼é¡¹**ï¼šåœ¨è¶…è¿‡ 1M tokens çš„åœºæ™¯ä¸­ï¼Œ$O(L^2d'H')$ å¯èƒ½è€—è´¹æ˜¾è‘—ï¼Œéœ€æ›´é«˜æ•ˆ indexing æ–¹æ¡ˆã€‚
3. **è®­ç»ƒæµç¨‹è¾ƒå¤æ‚**ï¼šéœ€è¦ä¸¤é˜¶æ®µ warmupï¼Œå¢åŠ äº†å®ç°è´Ÿæ‹…ï¼ˆå°½ç®¡è®¡ç®—å æ¯”æå°ï¼‰ã€‚
4. **æ–°å¢è¶…å‚éœ€è°ƒä¼˜**ï¼šå¦‚ $k_{\text{base}}, d_i, H_I$ å’Œ gate åˆå§‹åŒ–ç­‰ï¼Œåœ¨è·¨é¢†åŸŸè¿ç§»æ—¶å¯èƒ½éœ€é‡æ–°æ ¡å‡†ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- è®¾è®¡ **Hierarchical æˆ– Sub-linear Indexer** ä»¥çªç ´ $O(L^2)$ é™åˆ¶
- å°† GSA ä¸ **Mixture-of-Experts (MoE)** è·¯ç”±æœºåˆ¶ç»“åˆ
- æ¢ç´¢æ›´ç´§çš„ **information loss bound** ç†è®ºåˆ†æ
- æ‰©å±•è‡³å¤šæ¨¡æ€é•¿ä¸Šä¸‹æ–‡å»ºæ¨¡

---

> **æ€»ç»“**ï¼šGSA æ˜¯ä¸€ç§å…¼å…· **é«˜æ•ˆæ€§ã€ç¨³å®šæ€§ã€é«˜è´¨é‡è¡¨è¾¾èƒ½åŠ›** çš„ä¸‹ä¸€ä»£ Attention æ¶æ„ï¼Œä¸ºæ„å»ºè¶…é•¿ä¸Šä¸‹æ–‡è¯­è¨€æ¨¡å‹æä¾›äº†å®ç”¨ä¸”åšå®çš„è§£å†³æ–¹æ¡ˆã€‚ä»£ç å·²å¼€æºï¼š[https://github.com/alfredcs/Gated-Sparse-Attention](https://github.com/alfredcs/Gated-Sparse-Attention)

</details>

---

### 9. [MiRAGE: A Multiagent Framework for Generating Multimodal Multihop Question-Answer Dataset for RAG Evaluation](https://arxiv.org/abs/2601.15487)

**Authors**: Chandan Kumar Sahu, Premith Kumar Chilukuri, Matthew Hetrich  
**Category**: cs.AI  
**Published**: 2026-01-23  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.15487v1  

#### Abstract
The rapid evolution of Retrieval-Augmented Generation (RAG) toward multimodal, high-stakes enterprise applications has outpaced the development of domain specific evaluation benchmarks. Existing datasets often rely on general-domain corpora or purely textual retrieval, failing to capture the complex...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# MiRAGE: A Multiagent Framework for Generating Multimodal Multihop Question-Answer Dataset for RAG Evaluation â€”â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å½“å‰ **Retrieval-Augmented Generation (RAG)** ç³»ç»Ÿåœ¨é«˜é£é™©ä¼ä¸šåœºæ™¯ï¼ˆå¦‚é‡‘èã€æ³•è§„ã€åŒ»å­¦ï¼‰ä¸­å¹¿æ³›åº”ç”¨ï¼Œä½†å…¶è¯„ä¼°é¢ä¸´ä¸¥é‡æŒ‘æˆ˜ï¼š

- ç°æœ‰åŸºå‡†æ•°æ®é›†ï¼ˆå¦‚ Natural Questionsã€MS MARCOï¼‰å¤šåŸºäºå¼€æ”¾åŸŸæ–‡æœ¬ï¼Œç¼ºä¹å¯¹**é¢†åŸŸç‰¹å¼‚æ€§**ã€**å¤šæ¨¡æ€ä¿¡æ¯**ï¼ˆå›¾è¡¨ã€æŠ€æœ¯å›¾ç¤ºï¼‰å’Œ**å¤šè·³æ¨ç†**ï¼ˆmulti-hop reasoningï¼‰çš„æ”¯æŒã€‚
- å¤šæ•°åˆæˆæ•°æ®ç”Ÿæˆæ–¹æ³•é‡‡ç”¨çº¿æ€§æµç¨‹ï¼Œå®¹æ˜“äº§ç”Ÿ**å¹»è§‰**ï¼ˆhallucinationï¼‰ï¼Œä¸”æ— æ³•æœ‰æ•ˆæ•´åˆè§†è§‰ä¸æ–‡æœ¬ä¿¡æ¯ã€‚
- æŠ€æœ¯æ–‡æ¡£ä¸­çš„çŸ¥è¯†é«˜åº¦ä¾èµ–å›¾æ–‡ç»“åˆï¼Œä¼ ç»ŸOCRå’Œçº¯æ–‡æœ¬å¤„ç†æ–¹å¼ç ´åäº†è¯­ä¹‰è¿è´¯æ€§ã€‚

å› æ­¤ï¼ŒäºŸéœ€ä¸€ç§èƒ½è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡ã€é¢†åŸŸç›¸å…³ã€å¤šæ¨¡æ€ã€å¤šè·³é—®ç­”æ•°æ®é›†çš„æ–¹æ³•ï¼Œç”¨äºä¸¥æ ¼è¯„ä¼°RAGç³»ç»Ÿã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡º **MiRAGE** â€”â€” ä¸€ä¸ª**å¤šæ™ºèƒ½ä½“æ¡†æ¶**ï¼ˆmulti-agent frameworkï¼‰ï¼Œç”¨äºè‡ªåŠ¨åŒ–ç”Ÿæˆé€‚ç”¨äºRAGè¯„ä¼°çš„å¤šæ¨¡æ€ã€å¤šè·³é—®ç­”æ•°æ®é›†ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š

1. **å¤šæ™ºèƒ½ä½“ååŒæ¶æ„**  
   MiRAGE ä¸æ˜¯å•ä¸€æ¨¡å‹æµæ°´çº¿ï¼Œè€Œæ˜¯ç”±å¤šä¸ªä¸“ä¸šåŒ– agent ååŒå·¥ä½œçš„â€œæ™ºèƒ½ä½“ç¾¤â€ï¼ˆswarm of agentsï¼‰ï¼Œæ¨¡æ‹Ÿé¢†åŸŸä¸“å®¶çš„è®¤çŸ¥æµç¨‹ï¼š
   - **æè¿°ä»£ç†**ï¼ˆDescription Agentï¼‰ï¼šä½¿ç”¨ VLM å¯¹å›¾åƒ/è¡¨æ ¼ç”ŸæˆæŠ€æœ¯æ€§æè¿°ã€‚
   - **ä¸Šä¸‹æ–‡æ£€ç´¢ä»£ç†**ï¼ˆRetriever & Rerankerï¼‰ï¼šé€’å½’æ„å»ºè¯­ä¹‰ä¸Šä¸‹æ–‡çª—å£ã€‚
   - **QAç”Ÿæˆä»£ç†**ï¼ˆQA Generation Agentï¼‰ï¼šåŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆå¤æ‚é—®é¢˜ã€‚
   - **éªŒè¯ä»£ç†**ï¼ˆAdversarial Verifier Agentï¼‰ï¼šç‹¬ç«‹æ ¸æŸ¥ç­”æ¡ˆçš„äº‹å®ä¸€è‡´æ€§ã€‚
   - **å»é‡ä¸ç²¾ç‚¼ä»£ç†**ï¼ˆCurator Agentï¼‰ï¼šè¿›è¡Œåˆ†å±‚èšç±»ä¸å†—ä½™æ¶ˆé™¤ã€‚

2. **é€’å½’ä¸Šä¸‹æ–‡ä¼˜åŒ–ç¯**ï¼ˆRecursive Context Optimization Loopï¼‰  
   æ”¯æŒ**å¤šè·³æ¨ç†**ï¼šä»åˆå§‹ç§å­ chunk å‡ºå‘ï¼Œé€šè¿‡è¿­ä»£æŸ¥è¯¢ã€æ£€ç´¢ã€éªŒè¯ç¼ºå¤±ä¿¡æ¯ï¼Œé€æ­¥æ‰©å±•ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿æœ€ç»ˆç”Ÿæˆçš„é—®é¢˜éœ€è¦è·¨å¤šä¸ªåˆ†æ•£ç‰‡æ®µè¿›è¡Œæ¨ç†ã€‚

3. **å¯¹æŠ—å¼éªŒè¯æœºåˆ¶**ï¼ˆAdversarial Verificationï¼‰  
   å¼•å…¥ç‹¬ç«‹çš„ verifier agentï¼Œå¼ºåˆ¶æ£€æŸ¥ï¼š
   - ç­”æ¡ˆæ˜¯å¦è¢«ä¸Šä¸‹æ–‡æ”¯æŒï¼ˆfactualityï¼‰
   - é—®é¢˜æ˜¯å¦å¿…é¡»ä¾èµ–è¯¥ä¸Šä¸‹æ–‡æ‰èƒ½å›ç­”ï¼ˆnecessityï¼‰
   - é—®é¢˜æ˜¯å¦è‡ªåŒ…å«ï¼ˆstandalone principleï¼‰

4. **é¢†åŸŸä¸ä¸“å®¶è§’è‰²æ³¨å…¥**ï¼ˆDomain & Persona Injectionï¼‰  
   é€šè¿‡ä¸»é¢˜å»ºæ¨¡è¯†åˆ«æ–‡æ¡£çš„æ½œåœ¨é¢†åŸŸï¼ˆå¦‚â€œè´¢åŠ¡æŠ¥å‘Šåˆ†æâ€ï¼‰å¹¶æŒ‡å®šä¸“å®¶è§’è‰²ï¼ˆå¦‚â€œFinancial Reporting Analystâ€ï¼‰ï¼Œä½¿ç”Ÿæˆçš„QAæ›´è´´è¿‘çœŸå®ä¸“å®¶æ€ç»´æ¨¡å¼ã€‚

5. **å¤šæ¨¡æ€æ•°æ®ç»Ÿä¸€è¡¨ç¤º**  
   å°†å›¾åƒè½¬æ¢ä¸ºå¯Œå«è¯­ä¹‰çš„æŠ€æœ¯æè¿°ï¼Œå¹¶åµŒå…¥ä¸æ–‡æœ¬ç›¸åŒçš„å‘é‡ç©ºé—´ï¼Œä¿æŒå›¾æ–‡è¯­ä¹‰é‚»è¿‘æ€§ï¼Œé¿å…æ¨¡æ€å‰²è£‚ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ DataMorgana, SMMQGï¼‰ | MiRAGE |
|------|-------------------------------|--------|
| æ¶æ„ | çº¿æ€§æµæ°´çº¿ï¼Œæ— åé¦ˆæœºåˆ¶ | å¤šæ™ºèƒ½ä½“åä½œï¼Œé—­ç¯éªŒè¯ |
| å¤šè·³èƒ½åŠ› | æœ‰é™ï¼Œé€šå¸¸å•è·³æˆ–æµ…å±‚ç»„åˆ | æ˜¾å¼é€’å½’ä¸Šä¸‹æ–‡æ‰©å±•ï¼Œå¹³å‡ >2.3 hops |
| å¹»è§‰æ§åˆ¶ | ç¼ºä¹ç‹¬ç«‹éªŒè¯ | å¯¹æŠ—å¼ verifier agent æ˜¾è‘—é™ä½å¹»è§‰ |
| é¢†åŸŸé€‚é… | é€šç”¨æç¤ºï¼Œæ— é¢†åŸŸæ„ŸçŸ¥ | æ˜¾å¼ domain/persona æ³¨å…¥ |
| å¤šæ¨¡æ€å¤„ç† | å›¾åƒå¸¸è¢«å¿½ç•¥æˆ–å­¤ç«‹å¤„ç† | ç»Ÿä¸€è¯­ä¹‰ç©ºé—´ï¼Œä¿ç•™å›¾æ–‡å…³è” |
| æ•°æ®è´¨é‡ | å­˜åœ¨è¯­ä¹‰å†—ä½™ä¸é‡å¤ | åˆ†å±‚å»é‡ + èšç±»ï¼Œæå‡å¤šæ ·æ€§ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

åœ¨å››ä¸ªä¸åŒé¢†åŸŸé€‰å–çœŸå®æŠ€æœ¯æ–‡æ¡£ä½œä¸ºè¾“å…¥ corpusï¼Œæ„å»ºä¸“å± QA æ•°æ®é›†ï¼š

| æ•°æ®é›†åç§° | é¢†åŸŸ | é¡µé¢æ•° | å›¾åƒæ•° | è¡¨æ ¼æ•° | æ€»tokenæ•° |
|----------|------|-------|--------|--------|-----------|
| S&P Global Annual Reports | Finance | 1,302 | 1,120 | 2,800 | 0.9M |
| UNECE GTRs | Regulation | 7,594 | 150 | 3,450 | 3.8M |
| Quantitative Biology (ArXiv) | Science | 8,336 | 9,400 | 850 | 5.2M |
| NYTimes Opinions | Journalism | >3,000 | 3,050 | 25 | 2.1M |

è¿™äº›æ•°æ®è¦†ç›–äº†ä»ç»“æ„åŒ–å¼ºï¼ˆè´¢æŠ¥ã€æ³•è§„ï¼‰åˆ°éç»“æ„åŒ–é«˜ï¼ˆæ–°é—»è¯„è®ºï¼‰çš„ä¸åŒç±»å‹ã€‚

---

### **å®éªŒè®¾ç½®**

- **æ¨¡å‹é€‰æ‹©**ï¼š
  - ä¸»è¦ä½¿ç”¨ **Gemini 2.5 Flash** å’Œ **GPT-5 Mini** ä½œä¸ºæ¨ç†å¼•æ“ã€‚
  - ä½¿ç”¨ **Nomic Embed** æ¨¡å‹è¿›è¡Œè¯­ä¹‰åµŒå…¥ã€‚
  - é‡‡ç”¨ LLM-as-a-reranker èŒƒå¼è¿›è¡Œå¤šæ¨¡æ€é‡æ’åºã€‚

- **è¾“å‡ºè§„æ¨¡**ï¼šæ¯ä¸ªé¢†åŸŸç”Ÿæˆ 1,000 ä¸ª QA å¯¹ã€‚

- **æ¡†æ¶ç‰¹æ€§**ï¼š**model-agnostic**ï¼Œå¯æ›¿æ¢åº•å±‚ LLM/VLMã€‚

---

### **è¯„ä¼°æŒ‡æ ‡**

| æŒ‡æ ‡ | å®šä¹‰ |
|------|------|
| **Faithfulness (Faith.)** | ç­”æ¡ˆæ˜¯å¦ä¸¥æ ¼åŸºäºä¸Šä¸‹æ–‡ï¼Œæ— å¹»è§‰ï¼ˆç”± verifier åˆ¤æ–­ï¼‰ |
| **Relevance (Rel.)** | é—®é¢˜ä¸ä¸Šä¸‹æ–‡çš„ç›¸å…³æ€§ |
| **Average Hops (H)** | æ¨ç†æ‰€éœ€æ­¥éª¤æ•°ï¼Œè¡¡é‡å¤šè·³å¤æ‚åº¦ |
| **Visual Grounding (Vis. Gr.)** | ç­”æ¡ˆä¸­å¼•ç”¨çš„è§†è§‰å…ƒç´ æ˜¯å¦çœŸå®å­˜åœ¨äºå›¾åƒä¸­ï¼ˆç”± VLM éªŒè¯ï¼‰ |
| **Jensen-Shannon Divergence (JSD)** | ç”Ÿæˆæ•°æ®é›†ä¸æºæ–‡æ¡£åœ¨ä¸»é¢˜åˆ†å¸ƒä¸Šçš„å¯¹é½ç¨‹åº¦ï¼Œè¶Šä½è¶Šå¥½ |

æ­¤å¤–è¿˜å¼•å…¥ **LLM-as-a-Judge** èŒƒå¼è¿›è¡Œè‡ªåŠ¨è¯„åˆ†ã€‚

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

æ–‡ä¸­æœªç›´æ¥åˆ—å‡ºä¸å…¶ä»–å®Œæ•´æ¡†æ¶ï¼ˆå¦‚ SMMQGï¼‰çš„ç«¯åˆ°ç«¯å¯¹æ¯”ï¼Œä½†é€šè¿‡**æ¶ˆèå®éªŒ**ï¼ˆablation studyï¼‰é—´æ¥è¯æ˜å„ç»„ä»¶çš„æœ‰æ•ˆæ€§ï¼Œå¹¶å¼ºè°ƒç›¸è¾ƒäºçº¿æ€§åˆæˆæ–¹æ³•ï¼ˆlinear prompting strategiesï¼‰å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 2ï¼‰**

| Dataset | Model | Faith. | Rel. | Avg Hops | Vis. Gr. |
|--------|-------|--------|------|----------|----------|
| S&P Global (Finance) | Gemini 2.5 Flash | 0.96 | 0.86 | **2.84** | 0.21 |
| UNECE GTRs (Regulation) | GPT-5 Mini | 0.96 | 0.82 | 2.60 | 0.45 |
| Q-Bio ArXiv (Science) | GPT-5 Mini | 0.81 | 0.94 | 2.55 | 0.42 |
| NYTimes (Journalism) | GPT-5 Mini | 0.93 | 0.95 | 1.25 | 0.24 |

> âœ… **å¹³å‡æ¨ç†æ­¥æ•°å‡è¶…è¿‡ 2.3**ï¼ˆé™¤ Journalism å¤–ï¼‰ï¼Œè¡¨æ˜æˆåŠŸå®ç°å¤šè·³æ¨ç†ã€‚
>
> âœ… **äº‹å®å‡†ç¡®æ€§æ™®éé«˜äº 0.91**ï¼Œè¯´æ˜ verifier æœ‰æ•ˆæŠ‘åˆ¶å¹»è§‰ã€‚
>
> âš ï¸ **è§†è§‰æ¥åœ°å¾—åˆ†è¾ƒä½ï¼ˆæœ€é«˜ä»… 0.45ï¼‰**ï¼Œåæ˜ å½“å‰ VLM åœ¨ç²¾ç¡®è§†è§‰æ¨ç†ä¸Šçš„ç“¶é¢ˆã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

è™½ç„¶æ²¡æœ‰ç›´æ¥å¯¹æ¯”å…¶ä»–æ¡†æ¶ï¼Œä½†ä»ä»¥ä¸‹æ–¹é¢ä½“ç°ä¼˜åŠ¿ï¼š

- æ‰€æœ‰ç”Ÿæˆçš„ QA å¯¹éƒ½ç»è¿‡ adversarial verificationï¼Œè€Œå¤šæ•°ç°æœ‰æ–¹æ³•æ— æ­¤æœºåˆ¶ã€‚
- ç”Ÿæˆçš„ QA æ›´ç¬¦åˆä¸“å®¶è®¤çŸ¥è·¯å¾„ï¼ˆé€šè¿‡ persona injection æ§åˆ¶é£æ ¼ä¸æ·±åº¦ï¼‰ã€‚
- æ”¯æŒçœŸæ­£çš„å¤šæ¨¡æ€èåˆï¼Œè€Œéç®€å•æ‹¼æ¥å›¾æ–‡ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**

åœ¨ S&P Global è´¢æŠ¥å­é›†ä¸Šè¿›è¡Œç»„ä»¶ç§»é™¤å®éªŒï¼ˆTable 3ï¼‰ï¼Œå…³é”®å‘ç°å¦‚ä¸‹ï¼š

| é…ç½® | Faith. | Rel. | Diff. | Avg Hops | JSD |
|------|--------|------|--------|----------|-----|
| å®Œæ•´ MiRAGE | **0.97** | **0.95** | **0.85** | 1.92 | **0.08** |
| ç§»é™¤ Multihop Context | 0.93 | 0.82 | 0.61 | â†“ | 4.35 |
| ç§»é™¤ QA Verifier Agent | 0.74 | 0.76 | 0.62 | 1.67 | 0.06 |
| ç§»é™¤ Domain/Persona | 0.91 | 0.88 | 0.52 | 1.81 | 0.11 |
| å›ºå®š chunk å¤§å° | 0.84 | 0.79 | 0.70 | 2.01 | 0.15 |
| ä»…ç”¨å›¾åƒï¼ˆæ— æè¿°ï¼‰ | 0.71 | 0.79 | 0.73 | 1.34 | 1.73 |
| ä»…ç”¨æè¿°ï¼ˆæ— åŸå§‹å›¾åƒï¼‰ | 0.93 | 0.89 | 0.78 | 1.72 | 2.12 |

#### ç»“è®ºï¼š
- **Verifier Agent æœ€å…³é”®**ï¼šç§»é™¤å faithfulness ä¸‹é™ 23%ï¼Œå¹»è§‰æ¿€å¢ã€‚
- **Multihop Context å†³å®šéš¾åº¦**ï¼šç§»é™¤å difficulty ä» 0.85 é™è‡³ 0.61ï¼Œæ¥è¿‘ç®€å•æŠ½å–ä»»åŠ¡ã€‚
- **Domain/Persona æ³¨å…¥æå‡ä¸“ä¸šæ€§**ï¼šç›´æ¥å½±å“é—®é¢˜æ·±åº¦ã€‚
- **å›¾åƒæè¿°è‡³å…³é‡è¦**ï¼šè‹¥ä»…æœ‰å›¾åƒæ— æè¿°ï¼Œfaithfulness æä½ï¼ˆ0.71ï¼‰ï¼›è‹¥æœ‰æè¿°ï¼Œå³ä½¿ä¸ç”¨åŸå›¾ä¹Ÿèƒ½ç»´æŒè¾ƒé«˜æ€§èƒ½ â†’ **LLM å¯æ›¿ä»£éƒ¨åˆ† VLM åŠŸèƒ½**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **MiRAGE èƒ½æœ‰æ•ˆç”Ÿæˆé«˜å¤æ‚åº¦ã€é«˜ä¿çœŸçš„å¤šæ¨¡æ€å¤šè·³ QA æ•°æ®é›†**ï¼Œå¹³å‡æ¨ç†æ­¥æ•° >2.3ï¼Œåœ¨ Financeã€Regulationã€Science é¢†åŸŸè¡¨ç°å°¤ä¸ºçªå‡ºã€‚
2. âœ… **å¯¹æŠ—å¼éªŒè¯æœºåˆ¶æ˜¾è‘—æå‡äº‹å®ä¸€è‡´æ€§**ï¼Œfaithfulness æ™®é >0.9ï¼Œè¿œä¼˜äºæ— éªŒè¯çš„åˆæˆæ–¹æ³•ã€‚
3. âœ… **é€’å½’ä¸Šä¸‹æ–‡æ„å»ºæ˜¯å®ç°å¤šè·³æ¨ç†çš„å…³é”®**ï¼Œçº¿æ€§ç”Ÿæˆæ— æ³•æ•æ‰è·¨æ®µè½é€»è¾‘è”ç³»ã€‚
4. âœ… **é¢†åŸŸä¸ä¸“å®¶è§’è‰²æ³¨å…¥æ˜¾è‘—å½±å“é—®é¢˜è´¨é‡**ï¼Œä½¿å…¶æ›´è´´è¿‘å®é™…åº”ç”¨åœºæ™¯ã€‚
5. ğŸ” **è§†è§‰æ¥åœ°ä»æ˜¯å‰æ²¿æŒ‘æˆ˜**ï¼šå°½ç®¡æ¡†æ¶æ”¯æŒå¤šæ¨¡æ€ï¼Œä½†å½“å‰ VLM å¯¹å›¾åƒç»†èŠ‚çš„ç†è§£ä»ä¸è¶³ï¼Œå¯¼è‡´ Vis. Gr. å¾—åˆ†åä½ã€‚
6. ğŸ’¡ **åªè¦æœ‰é«˜è´¨é‡å›¾åƒæè¿°ï¼ŒLLM å³å¯é©±åŠ¨æ•´ä¸ªæµç¨‹**ï¼šæ¶ˆèå®éªŒè¯æ˜ï¼Œâ€œDescription Onlyâ€é…ç½®ä¸‹æ€§èƒ½æ¥è¿‘å®Œæ•´ç‰ˆï¼Œæ„å‘³ç€å¯åœ¨ç¼ºä¹å¼ºå¤§ VLM æ—¶é€€åŒ–è¿è¡Œã€‚

---

### **å±€é™æ€§**

1. **è®¡ç®—æˆæœ¬é«˜**ï¼šå¤šè½® agent åä½œå¸¦æ¥è¾ƒé«˜çš„ token å¼€é”€å’Œå»¶è¿Ÿï¼Œä¸é€‚åˆå®æ—¶åº”ç”¨ã€‚
2. **ä¾èµ–é«˜è´¨é‡ VLM**ï¼šè‹¥å›¾åƒæè¿°ä¸å‡†ç¡®ï¼Œä¼šå½±å“åç»­æ‰€æœ‰ç¯èŠ‚ã€‚
3. **è§†è§‰æ¨ç†èƒ½åŠ›å—é™**ï¼šå½“å‰ VLM éš¾ä»¥ç²¾å‡†å®šä½å›¾åƒä¸­çš„ç‰¹å®šè¶‹åŠ¿æˆ–ç»“æ„ï¼ˆå¦‚åˆ†å­æ„å‹ã€è´¢åŠ¡å›¾è¡¨æ‹ç‚¹ï¼‰ã€‚
4. **å¼€æºæ¨¡å‹æ”¯æŒä¸è¶³**ï¼šç›®å‰ä¸»è¦ä¾èµ–é—­æºå¤§æ¨¡å‹ï¼ˆGemini/GPTï¼‰ï¼Œé™åˆ¶å¯å¤ç°æ€§å’Œæ™®åŠæ€§ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **ä¼˜åŒ– agent å·¥ä½œæµä»¥å‡å°‘ token æ¶ˆè€—**ï¼Œä¾‹å¦‚å¼•å…¥ early stopping æˆ–ç¼“å­˜æœºåˆ¶ã€‚
2. **æ¢ç´¢è½»é‡åŒ–æˆ–å¼€æºæ¨¡å‹ç»„åˆ**ï¼Œæå‡æ¡†æ¶çš„å¯è®¿é—®æ€§ã€‚
3. **å¢å¼ºè§†è§‰ç†è§£æ¨¡å—**ï¼Œå¼€å‘ä¸“ç”¨ vision encoder æˆ–å¼•å…¥å¤–éƒ¨çŸ¥è¯†è¾…åŠ©å›¾åƒè§£æã€‚
4. **æ‰©å±•è‡³æ›´å¤šå‚ç›´é¢†åŸŸ**ï¼Œå¦‚åŒ»ç–—ã€èƒ½æºã€æ³•å¾‹ç­‰ï¼ŒéªŒè¯æ³›åŒ–èƒ½åŠ›ã€‚
5. **é›†æˆ human-in-the-loop æœºåˆ¶**ï¼Œè¿›ä¸€æ­¥æå‡æ•°æ®æƒå¨æ€§ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **MiRAGE æ˜¯é¦–ä¸ªå°†å¤šæ™ºèƒ½ä½“åä½œã€é€’å½’ä¸Šä¸‹æ–‡æ„å»ºä¸å¯¹æŠ—éªŒè¯ç›¸ç»“åˆçš„å…¨è‡ªåŠ¨å¤šæ¨¡æ€å¤šè·³ QA ç”Ÿæˆæ¡†æ¶ï¼Œä¸ºé«˜é£é™©é¢†åŸŸçš„ RAG ç³»ç»Ÿæä¾›äº†å¯é ã€å¯å®šåˆ¶çš„è¯„ä¼°åŸºç¡€è®¾æ–½ã€‚**

</details>

---

### 10. [Agentic Uncertainty Quantification](https://arxiv.org/abs/2601.15703)

**Authors**: Jiaxin Zhang, Prafulla Kumar Choubey, Kung-Hsiang Huang, Caiming Xiong, Chien-Sheng Wu  
**Category**: cs.AI  
**Published**: 2026-01-23  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.15703v1  

#### Abstract
Although AI agents have demonstrated impressive capabilities in long-horizon reasoning, their reliability is severely hampered by the ``Spiral of Hallucination,'' where early epistemic errors propagate irreversibly. Existing methods face a dilemma: uncertainty quantification (UQ) methods typically a...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAgentic Uncertainty Quantification

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹ **autonomous agents** åœ¨é•¿å‘¨æœŸä»»åŠ¡ä¸­é¢ä¸´çš„â€œ**Spiral of Hallucination**â€ï¼ˆå¹»è§‰èºæ—‹ï¼‰é—®é¢˜ã€‚è¿™ä¸€ç°è±¡æŒ‡ä»£ç†åœ¨æ—©æœŸæ¨ç†æ­¥éª¤ä¸­çš„å¾®å°è®¤çŸ¥é”™è¯¯ï¼ˆepistemic errorï¼‰ä¼šé€šè¿‡ä¸Šä¸‹æ–‡çª—å£æŒç»­ä¼ æ’­ï¼Œå¯¼è‡´åç»­å†³ç­–è¢«ä¸¥é‡è¯¯å¯¼ï¼Œæœ€ç»ˆé™·å…¥ä¸å¯é€†çš„å¤±è´¥çŠ¶æ€ã€‚

ç°æœ‰æ–¹æ³•å­˜åœ¨ä¸¤å¤§å›°å¢ƒï¼š
- **è¢«åŠ¨çš„ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆUQï¼‰æ–¹æ³•**ï¼šä»…èƒ½è¯Šæ–­é£é™©ï¼Œæ— æ³•ä¸»åŠ¨å¹²é¢„æˆ–çº æ­£é”™è¯¯ã€‚
- **è‡ªçœæœºåˆ¶ï¼ˆself-reflectionï¼‰**ï¼šç¼ºä¹æ˜ç¡®è§¦å‘æ¡ä»¶ï¼Œå®¹æ˜“é™·å…¥æ— ç›®çš„æˆ–ç›²ç›®çš„åå¤ä¿®æ­£ï¼Œé€ æˆè®¡ç®—èµ„æºæµªè´¹æˆ–â€œ**sycophancy effect**â€ï¼ˆè‡ªæˆ‘è¿åˆæ•ˆåº”ï¼‰ï¼Œå³æ¨¡å‹ä¸ºè‡ªå·±çš„é”™è¯¯ç”Ÿæˆçœ‹ä¼¼åˆç†çš„è¾©è§£ã€‚

### æå‡ºçš„æ–°æ–¹æ³•å’Œæ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„ **Dual-Process Agentic UQ (AUQ)** æ¡†æ¶ï¼Œå°†è¯­è¨€åŒ–çš„ä¸ç¡®å®šæ€§è½¬åŒ–ä¸º**ä¸»åŠ¨çš„ã€åŒå‘æ§åˆ¶ä¿¡å·**ï¼Œå®ç°äº†ä»â€œè¢«åŠ¨æ„ŸçŸ¥â€åˆ°â€œä¸»åŠ¨è°ƒæ§â€çš„è½¬å˜ã€‚

å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºä¸€ä¸ªåŒç³»ç»Ÿæ¶æ„ï¼š
- **System 1: Uncertainty-Aware Memory (UAM)**  
  - **åŠŸèƒ½**ï¼šå‰å‘ä¸ç¡®å®šæ€§ä¼ æ’­ï¼ˆForward Uncertainty Propagationï¼‰ã€‚  
  - **æœºåˆ¶**ï¼šåœ¨æ¯ä¸€æ­¥æ¨ç†ä¸­ï¼Œè¦æ±‚æ¨¡å‹è¾“å‡º `action`ã€`confidence`ï¼ˆç½®ä¿¡åº¦ï¼Œ0-1ï¼‰å’Œ `explanation`ï¼ˆè§£é‡Šï¼‰ã€‚è¿™äº›ä¿¡æ¯è¢«æ˜¾å¼åœ°å­˜å‚¨åœ¨ **Uncertainty-Aware Memory** ä¸­ã€‚  
  - **ä½œç”¨**ï¼šåˆ©ç”¨ Transformer çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œè®©å†å²ä¸­çš„â€œä¸ç¡®å®šæ€§è§£é‡Šâ€å¯¹æœªæ¥çš„å†³ç­–æ–½åŠ ä¸€ç§**è½¯è®¤çŸ¥çº¦æŸ**ï¼ˆSoft Cognitive Constraintï¼‰ï¼ŒæŠ‘åˆ¶è¿‡åº¦è‡ªä¿¡ï¼Œé˜²æ­¢ç›²ç›®å†³ç­–ã€‚

- **System 2: Uncertainty-Aware Reflection (UAR)**  
  - **åŠŸèƒ½**ï¼šåå‘ä¸ç¡®å®šæ€§æ ¡å‡†ï¼ˆInverse Uncertainty Calibrationï¼‰ã€‚  
  - **æœºåˆ¶**ï¼šå½“ System 1 è¾“å‡ºçš„ `confidence` ä½äºé¢„è®¾é˜ˆå€¼ `T` æ—¶ï¼Œè§¦å‘ System 2ã€‚æ­¤æ—¶ï¼ŒSystem 1 ç”Ÿæˆçš„ `explanation` è¢«ç”¨ä½œä¸€ä¸ª**ç†æ€§çº¿ç´¢**ï¼ˆRational Cueï¼‰ï¼ŒæŒ‡å¯¼ä¸€æ¬¡æœ‰é’ˆå¯¹æ€§çš„åæ€è¿‡ç¨‹ã€‚  
  - **ä½œç”¨**ï¼šè¿›è¡Œ **Best-of-N** é‡‡æ ·ï¼Œå¹¶é‡‡ç”¨ **Consistency-Weighted Reflection** ç­–ç•¥é€‰æ‹©æœ€ä¼˜åŠ¨ä½œï¼Œä»è€Œå®ç°å¯¹åå·®çš„ç²¾å‡†çº æ­£ã€‚

æ­¤å¤–ï¼Œæ¡†æ¶è¿˜å¼•å…¥äº† **Adaptive Memory Expansion** æœºåˆ¶ï¼Œåœ¨æœ¬åœ°åæ€å¤±è´¥åï¼Œè‡ªåŠ¨åŠ è½½å®Œæ•´è®°å¿†ä»¥è¿›è¡Œæ›´æ·±å±‚æ¬¡çš„æ£€ç´¢å’Œä¿®æ­£ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **è®­ç»ƒå…è´¹ï¼ˆTraining-Freeï¼‰**ï¼šå®Œå…¨åŸºäºæç¤ºå·¥ç¨‹ï¼ˆprompt engineeringï¼‰å®ç°ï¼Œæ— éœ€å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œæ˜“äºéƒ¨ç½²ã€‚
- **åŠ¨æ€å¹³è¡¡æ•ˆç‡ä¸æ·±åº¦**ï¼šä»…åœ¨å¿…è¦æ—¶ï¼ˆä½ç½®ä¿¡åº¦ï¼‰æ‰å¯åŠ¨é«˜æˆæœ¬çš„åæ€ï¼ˆSystem 2ï¼‰ï¼Œå®ç°äº†é«˜æ•ˆçš„â€œæŒ‰éœ€æ¨ç†â€ã€‚
- **é—­ç¯æ§åˆ¶**ï¼šå°†ä¸ç¡®å®šæ€§ä»ä¸€ä¸ªé™æ€çš„è¯Šæ–­æŒ‡æ ‡ï¼Œè½¬å˜ä¸ºé©±åŠ¨ç³»ç»Ÿåˆ‡æ¢å’Œè¡ŒåŠ¨çš„åŠ¨æ€æ§åˆ¶ä¿¡å·ï¼Œå½¢æˆäº†ä¸€ä¸ªå®Œæ•´çš„â€œæ„ŸçŸ¥-å†³ç­–-æ‰§è¡Œ-åé¦ˆâ€é—­ç¯ã€‚
- **å¯è§£é‡Šæ€§å¼º**ï¼šé€šè¿‡ `explanation` æ˜ç¡®äº†é”™è¯¯çš„åŸå› å’Œä¿®æ­£çš„æ–¹å‘ã€‚

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒåœ¨ä¸‰ä¸ªä¸åŒé¢†åŸŸçš„åŸºå‡†ä¸Šè¿›è¡Œï¼Œä»¥éªŒè¯æ–¹æ³•çš„é€šç”¨æ€§ï¼š
- **ALFWorld**ï¼šä¸€ä¸ªç²¾ç¡®çš„å…·èº«å†³ç­–ç¯å¢ƒï¼Œæµ‹è¯•ä»£ç†åœ¨é€»è¾‘è§„åˆ’å’Œä¾èµ–è¿½è¸ªä¸Šçš„å¯é æ€§ã€‚
- **WebShop**ï¼šä¸€ä¸ªæ¨¡æ‹Ÿç”µå•†ç½‘ç«™çš„ç°å®ç¯å¢ƒï¼Œå…·æœ‰é«˜è§‚æµ‹å™ªå£°ï¼Œæµ‹è¯•ä»£ç†å¤„ç†ä¸ç¡®å®šæ€§å’Œä¿¡æ¯æ£€ç´¢çš„èƒ½åŠ›ã€‚
- **DeepResearch Bench**ï¼šä¸€ä¸ªå¼€æ”¾å¼çš„æ·±åº¦ç ”ç©¶åŸºå‡†ï¼ŒåŒ…å«100ä¸ªåšå£«çº§åˆ«çš„ç ”ç©¶ä»»åŠ¡ï¼Œè¯„ä¼°ä»£ç†åœ¨å¤æ‚ä¿¡æ¯åˆæˆå’Œæ´å¯ŸåŠ›æ–¹é¢çš„è¡¨ç°ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹**ï¼šåœ¨å¤šä¸ªå‰æ²¿é—­æºå’Œå¼€æº LLM ä¸Šè¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼ŒåŒ…æ‹¬ GPT-5.1, GPT-4.1, GPT-4o, Gemini-2.5-Pro, Qwen3-235B, DeepSeek-V3.1 ç­‰ã€‚
- **è¯„ä¼°ç»´åº¦**ï¼š
  1. **Performance (æ€§èƒ½)**ï¼šåœ¨ ALFWorld å’Œ WebShop ä¸ŠæŠ¥å‘Š **Success Rate (SR)**ï¼›åœ¨ DeepResearch ä¸Šä½¿ç”¨ **RACE rubric** è¿›è¡Œè¯„åˆ†ã€‚
  2. **Calibration (æ ¡å‡†æ€§)**ï¼šæå‡ºäº†**è½¨è¿¹çº§æ ¡å‡†**ï¼ˆTrajectory-Level Calibrationï¼‰æŒ‡æ ‡ï¼ŒåŒ…æ‹¬ï¼š
     - **Trajectory-ECE (T-ECE)**ï¼šè¶Šä½è¶Šå¥½ï¼Œè¡¡é‡ç½®ä¿¡åº¦ä¸å®é™…æˆåŠŸç‡çš„åŒ¹é…ç¨‹åº¦ã€‚
     - **Trajectory Brier Score (T-BS)**ï¼šè¶Šä½è¶Šå¥½ï¼Œç»¼åˆè¯„ä¼°æ ¡å‡†æ€§å’Œé”åº¦ï¼ˆsharpnessï¼‰ã€‚
  3. **Discrimination (åŒºåˆ†èƒ½åŠ›)**ï¼šä½¿ç”¨ **AUROC** è¡¡é‡å†…éƒ¨ç½®ä¿¡åº¦ä¿¡å·åŒºåˆ†æˆåŠŸä¸å¤±è´¥è½¨è¿¹çš„èƒ½åŠ›ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **ReAct**ï¼šæ ‡å‡†çš„ System 1 åŸºçº¿ï¼Œæ— æ˜¾å¼è‡ªçœã€‚
- **Reflexion**ï¼šåŸºäºè·¨å›åˆå­¦ä¹ çš„å¼ºåŸºçº¿ï¼Œä»£è¡¨æ— ä¸ç¡®å®šæ€§æ„è¯†çš„è‡ªæ ¡æ­£ã€‚
- **Self-Reflection**ï¼šåœ¨æ¯ä¸ªæ­¥éª¤éƒ½è§¦å‘åæ€çš„åŸºçº¿ï¼Œç”¨äºå¯¹æ¯”æ— å¼•å¯¼çš„è®¡ç®—æ‰©å±•ã€‚
- **CoT-SC**ï¼šæ€ç»´é“¾è‡ªæ´½æ€§ï¼ˆSelf-Consistencyï¼‰åŸºçº¿ï¼Œç”¨äºéªŒè¯æ€§èƒ½å¢ç›Šæ˜¯å¦æºäºé‡‡æ ·å¤šæ ·æ€§è€Œéç›®æ ‡æ€§åæ€ã€‚
- **æ¶ˆèå˜ä½“**ï¼šå•ç‹¬è¯„ä¼° **Forward UQ (UAM-only)** å’Œ **Inverse UQ (UAR-only)** çš„æ•ˆæœã€‚

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”ç»“æœ
- **åœ¨ ALFWorld å’Œ WebShop ä¸Š**ï¼š
  - **AUQ** åœ¨ **Success Rate** ä¸Šæ˜¾è‘—è¶…è¶Šæ‰€æœ‰åŸºçº¿ã€‚ä¾‹å¦‚ï¼Œåœ¨ ALFWorld ä¸Šè¾¾åˆ° **74.3%**ï¼Œç›¸æ¯” ReAct (63.6%) æå‡äº† 10.7%ï¼›åœ¨ WebShop ä¸Šè¾¾åˆ° **42.9%**ï¼Œç›¸æ¯” ReAct (29.3%) æå‡äº† 13.6%ã€‚
  - **AUQ** åœ¨ **AUROC** ä¸Šä¹Ÿå–å¾—æœ€ä½³è¡¨ç°ï¼Œè¯æ˜å…¶å†…éƒ¨ç½®ä¿¡åº¦ä¿¡å·å…·æœ‰å¼ºå¤§çš„åˆ¤åˆ«åŠ›ï¼Œèƒ½æœ‰æ•ˆè¯†åˆ«éœ€è¦å¹²é¢„çš„è½¨è¿¹ã€‚

- **åœ¨ DeepResearch Bench ä¸Š**ï¼š
  - **AUQ** å–å¾—äº† **State-of-the-Art (SOTA)** æ€§èƒ½ï¼Œæ€»ä½“å¾—åˆ†ä¸º **52.09**ï¼Œè¶…è¿‡äº†æœ€å¼ºçš„é—­æºåŸºçº¿ (49.71) å’Œå¼€æºç«å“ (50.62)ã€‚
  - å…¶ä¼˜åŠ¿ä¸»è¦ä½“ç°åœ¨ **Insight** (æ´å¯ŸåŠ›, 54.21) å’Œ **Comprehensiveness** (å…¨é¢æ€§, 51.60) ä¸Šï¼Œè¡¨æ˜ UAR æœºåˆ¶èƒ½æœ‰æ•ˆé©±åŠ¨æ·±å…¥æ¢ç©¶ï¼Œé¿å…â€œä¿¡æ¯æ»¡è¶³â€ï¼ˆinformation satisficingï¼‰ã€‚

- **æ ¡å‡†æ€§åˆ†æ**ï¼š
  - **UAM-only** åœ¨ **T-ECE** ä¸Šè¡¨ç°æœ€å¥½ï¼Œè¯´æ˜å…¶èƒ½æœ‰æ•ˆæŠ‘åˆ¶è¿‡æ‹Ÿåˆï¼Œæå‡æ ¡å‡†æ€§ã€‚
  - **UAR-only** åœ¨ **T-BS** ä¸Šè¡¨ç°æœ€å¥½ï¼Œè¯´æ˜å…¶é€šè¿‡åæ€èƒ½äº§ç”Ÿæ›´æœæ–­ã€æ›´ç¡®å®šçš„ä¿¡å¿µåˆ†å¸ƒã€‚
  - **AUQ** æˆåŠŸç»“åˆäº†ä¸¤è€…çš„ä¼˜åŠ¿ï¼Œåœ¨ä¿æŒé«˜æ ¡å‡†æ€§çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†å†³ç­–è´¨é‡ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **å†…å­˜é•¿åº¦å½±å“**ï¼šå¦‚å›¾4æ‰€ç¤ºï¼Œå³ä½¿åœ¨æçŸ­çš„å†å²çª—å£ï¼ˆh=1ï¼‰ä¸‹ï¼ŒAUQ çš„æ€§èƒ½ä¹Ÿè¿œè¶… ReActã€‚è¿™è¯æ˜äº† **UAM å­˜å‚¨çš„ `(c, e)` å…ƒæ•°æ®** å°†è½¨è¿¹çš„é£é™©çŠ¶æ€å‹ç¼©æˆä¸€ä¸ªç´§å‡‘ä¿¡å·ï¼Œæå¤§åœ°å¢å¼ºäº†æŠ—é—å¿˜èƒ½åŠ›ã€‚
- **å†…å­˜æ‰©å±•æœºåˆ¶**ï¼šå¦‚å›¾5æ‰€ç¤ºï¼Œåœ¨å—é™çš„ h=5 è®¾ç½®ä¸‹ï¼ŒAUQ é€šè¿‡ **Adaptive Memory Expansion** å®ç°äº†å·¨å¤§æ€§èƒ½æå‡ï¼ˆä¾‹å¦‚ï¼ŒGPT-5.1 ä¸Š +17.9%ï¼‰ï¼Œè¯æ˜äº†åŠ¨æ€æ£€ç´¢ä¼˜äºé™æ€çª—å£ã€‚
- **æˆæœ¬æ•ˆç›Šåˆ†æ**ï¼šå¦‚å›¾6æ‰€ç¤ºï¼ŒAUQ åœ¨ **Success Rate** å’Œ **è®¡ç®—æˆæœ¬** ä¹‹é—´å–å¾—äº†æ›´ä¼˜çš„å¸•ç´¯æ‰˜å‰æ²¿ï¼ˆPareto frontierï¼‰ã€‚è™½ç„¶åæ€ä¼šå¢åŠ å•æ­¥å¼€é”€ï¼Œä½†å®ƒé€šè¿‡é¢„é˜²é•¿æ—¶é—´çš„å¤±è´¥å¾ªç¯ï¼Œåè€Œé™ä½äº†æ•´ä½“çš„â€œå¤±è´¥æˆæœ¬â€ï¼Œå®ç°äº†æ›´é«˜çš„æ€§ä»·æ¯”ã€‚

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ä¸ç¡®å®šæ€§å¯ä»¥æˆä¸ºä¸»åŠ¨æ§åˆ¶å™¨**ï¼šAUQ æ¡†æ¶æˆåŠŸåœ°å°†è¯­è¨€åŒ–çš„ä¸ç¡®å®šæ€§ä»ä¸€ä¸ªè¢«åŠ¨çš„â€œä¼ æ„Ÿå™¨â€è½¬å˜ä¸ºé©±åŠ¨ System 1 å’Œ System 2 åˆ‡æ¢çš„â€œæ§åˆ¶ä¿¡å·â€ï¼Œè¿™æ˜¯æ„å»ºå¯é æ™ºèƒ½ä½“çš„å…³é”®ä¸€æ­¥ã€‚
2. **åŒç³»ç»ŸååŒæ•ˆåº”æ˜¾è‘—**ï¼šUAM çš„â€œå‰å‘ä¼ æ’­â€å’Œ UAR çš„â€œåå‘æ ¡å‡†â€ç›¸è¾…ç›¸æˆã€‚UAM é¢„é˜²é”™è¯¯å›ºåŒ–ï¼ŒUAR ä¿®å¤å·²å‘ç”Ÿçš„åå·®ï¼ŒäºŒè€…ç»“åˆå®ç°äº†æ€§èƒ½å’Œæ ¡å‡†æ€§çš„åŒé‡æå‡ã€‚
3. **æ•ˆç‡ä¸å¯é æ€§å¯ä»¥å…¼å¾—**ï¼šé€šè¿‡åŸºäºç½®ä¿¡åº¦çš„è‡ªé€‚åº”å¼€å…³ï¼ŒAUQ èƒ½å¤Ÿåœ¨ä¸ç‰ºç‰²æ•ˆç‡çš„å‰æä¸‹å¤§å¹…æå‡å¯é æ€§ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨â€œç›²ç›®æ‰§è¡Œâ€å’Œâ€œç›²ç›®åæ€â€ä¹‹é—´çš„ä¸¤éš¾å›°å¢ƒã€‚
4. **å…ƒè®¤çŸ¥ä¿¡æ¯è‡³å…³é‡è¦**ï¼šä»…ä»…ä¸€ä¸ªæ ‡é‡ç½®ä¿¡åº¦æ˜¯ä¸å¤Ÿçš„ã€‚`explanation` ä½œä¸ºâ€œç†æ€§çº¿ç´¢â€ï¼Œä¸º System 2 æä¾›äº†æ˜ç¡®çš„ä¿®æ­£æ–¹å‘ï¼Œä½¿å…¶åæ€ä¸å†æ˜¯ç›²ç›®çš„é‡è¯•ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–äºæ¨¡å‹çš„å…ƒè®¤çŸ¥èƒ½åŠ›**ï¼šè¯¥æ¡†æ¶å‡è®¾åº•å±‚ LLM å…·å¤‡è¡¨è¾¾ä¸ç¡®å®šæ€§çš„æ½œåœ¨èƒ½åŠ›ã€‚è¿™ç§èƒ½åŠ›åœ¨è¾ƒå°çš„æ¨¡å‹ï¼ˆå¦‚å‚æ•°å°‘äº70äº¿ï¼‰ä¸Šä¼šå‡å¼±ã€‚
2. **æ¨ç†å»¶è¿Ÿ**ï¼šæ¿€æ´» System 2 ä¼šå¼•å…¥é¢å¤–çš„æ¨ç†å»¶è¿Ÿï¼ˆç”±äº Best-of-N é‡‡æ ·å’Œè¿­ä»£æ‰¹åˆ¤å¾ªç¯ï¼‰ï¼Œå¯èƒ½ä¸é€‚åˆå¯¹å®æ—¶æ€§è¦æ±‚æé«˜çš„åº”ç”¨åœºæ™¯ã€‚
3. **é™æ€é˜ˆå€¼**ï¼šå½“å‰ä½¿ç”¨çš„æ˜¯ç»éªŒç¡®å®šçš„é™æ€é˜ˆå€¼ `T`ï¼Œæœªèƒ½æ ¹æ®ä¸åŒä»»åŠ¡æˆ–æ­¥éª¤çš„å›ºæœ‰é£é™©è¿›è¡ŒåŠ¨æ€è°ƒæ•´ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ **Adaptive Risk Budgeting**ï¼Œè®¾è®¡ä¸€ä¸ªèƒ½å¤Ÿæ ¹æ®æ­¥éª¤ç±»å‹å’Œå‰©ä½™é¢„ç®—åŠ¨æ€è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼ `T` çš„å…ƒæ§åˆ¶å™¨ã€‚
- ç ”ç©¶å¦‚ä½•è¿›ä¸€æ­¥é™ä½ System 2 çš„å»¶è¿Ÿï¼Œä¾‹å¦‚é€šè¿‡æ›´é«˜æ•ˆçš„é‡‡æ ·ç­–ç•¥æˆ–å¹¶è¡ŒåŒ–ã€‚
- å°† AUQ æ¡†æ¶åº”ç”¨äºæ›´å¤æ‚çš„å¤šæ™ºèƒ½ä½“ï¼ˆmulti-agentï¼‰ç³»ç»Ÿï¼Œç ”ç©¶ä¸ç¡®å®šæ€§åœ¨åä½œä¸ç«äº‰ä¸­çš„ä¼ æ’­ä¸ç®¡ç†ã€‚

</details>

---

### 11. [AgriPINN: A Process-Informed Neural Network for Interpretable and Scalable Crop Biomass Prediction Under Water Stress](https://arxiv.org/abs/2601.16045)

**Authors**: Yue Shi, Liangxiu Han, Xin Zhang, Tam Sobeih, Thomas Gaiser, Nguyen Huu Thuy, Dominik Behrend, Amit Kumar Srivastava, Krishnagopal Halder, Frank Ewert  
**Category**: cs.AI  
**Published**: 2026-01-23  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.16045v1  

#### Abstract
Accurate prediction of crop above-ground biomass (AGB) under water stress is critical for monitoring crop productivity, guiding irrigation, and supporting climate-resilient agriculture. Data-driven models scale well but often lack interpretability and degrade under distribution shift, whereas proces...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# AgriPINN: A Process-Informed Neural Network for Interpretable and Scalable Crop Biomass Prediction Under Water Stress

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å‡†ç¡®é¢„æµ‹ä½œç‰©åœ¨æ°´åˆ†èƒè¿«ä¸‹çš„åœ°ä¸Šéƒ¨ç”Ÿç‰©é‡ï¼ˆAbove-Ground Biomass, AGBï¼‰å¯¹äºç›‘æµ‹ä½œç‰©ç”Ÿäº§åŠ›ã€æŒ‡å¯¼çŒæº‰ç®¡ç†ä»¥åŠæ”¯æŒæ°”å€™é€‚åº”å‹å†œä¸šè‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ä¸¤ç±»ä¸»æµæ–¹æ³•å­˜åœ¨æ˜æ˜¾ç¼ºé™·ï¼š
- **æ•°æ®é©±åŠ¨æ¨¡å‹**ï¼ˆå¦‚æ·±åº¦å­¦ä¹ ï¼‰è™½ç„¶å…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§ï¼Œä½†é€šå¸¸ç¼ºä¹å¯è§£é‡Šæ€§ï¼Œåœ¨åˆ†å¸ƒå¤–ï¼ˆout-of-distribution, OODï¼‰åœºæ™¯ä¸‹æ³›åŒ–èƒ½åŠ›å·®ã€‚
- **åŸºäºè¿‡ç¨‹çš„ä½œç‰©æ¨¡å‹**ï¼ˆå¦‚ DSSATã€APSIMã€LINTUL5ï¼‰è™½å…·å¤‡ç”Ÿç†æœºåˆ¶ä¸Šçš„å¯è§£é‡Šæ€§ï¼Œä½†éœ€è¦å¤§é‡æ ¡å‡†å‚æ•°ï¼Œéš¾ä»¥åœ¨å¤§ç©ºé—´å°ºåº¦ä¸Šéƒ¨ç½²ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
æœ¬æ–‡æå‡º **AgriPINN**ï¼ˆAgricultural Process-Informed Neural Networkï¼‰ï¼Œä¸€ç§å°†æœºç†æ¨¡å‹åµŒå…¥æ·±åº¦å­¦ä¹ æ¡†æ¶çš„æ··åˆå»ºæ¨¡æ–¹æ³•ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºï¼š
- **å°†LINTUL5ä½œç‰©ç”Ÿé•¿å¾®åˆ†æ–¹ç¨‹ä½œä¸ºå¯å¾®çº¦æŸ**ï¼Œé›†æˆåˆ°ç¥ç»ç½‘ç»œè®­ç»ƒç›®æ ‡ä¸­ï¼Œå½¢æˆâ€œè½¯ç‰©ç†çº¦æŸâ€ã€‚
- é‡‡ç”¨ç«¯åˆ°ç«¯çš„å­¦ä¹ æ–¹å¼ï¼Œä»…éœ€AGBè§‚æµ‹å€¼è¿›è¡Œç›‘ç£ï¼Œå³å¯**æ— ç›‘ç£åœ°æ¢å¤å…³é”®æ½œå˜é‡**ï¼ˆlatent variablesï¼‰ï¼Œå¦‚å¶é¢ç§¯æŒ‡æ•°ï¼ˆLAIï¼‰ã€å¸æ”¶å…‰åˆæœ‰æ•ˆè¾å°„ï¼ˆAPARï¼‰ã€è¾å°„åˆ©ç”¨æ•ˆç‡ï¼ˆRUEï¼‰å’Œæ°´åˆ†èƒè¿«å› å­ï¼ˆFwï¼‰ã€‚
- æ„å»ºäº†ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œç»“åˆäº†**æ·±åº¦å­¦ä¹ çš„å¯æ‰©å±•æ€§**ä¸**è¿‡ç¨‹æ¨¡å‹çš„ç”Ÿç‰©ç‰©ç†ä¸€è‡´æ€§**ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´é«˜çš„å‡†ç¡®æ€§**ï¼šç›¸æ¯”SOTAæ·±åº¦å­¦ä¹ æ¨¡å‹å’ŒLINTUL5æ¨¡å‹ï¼ŒRMSEé™ä½é«˜è¾¾43%ã€‚
- **æ›´å¼ºçš„å¯è§£é‡Šæ€§**ï¼šé€šè¿‡æ½œå˜é‡æ¨æ–­ï¼Œæä¾›å¯¹æ°´åˆ†èƒè¿«åŠ¨æ€çš„é€æ˜åˆ†æã€‚
- **æ˜¾è‘—æå‡è®¡ç®—æ•ˆç‡**ï¼šæ¨ç†é€Ÿåº¦æ¯”LINTUL5å¿«8å€ã€‚
- **æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›**ï¼šåœ¨è·¨åŒºåŸŸã€è·¨å¹´ä»½åŠä¸åŒæ°´åˆ†å¤„ç†æ¡ä»¶ä¸‹è¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ï¼Œç¼“è§£äº†â€œç¾éš¾æ€§é—å¿˜â€é—®é¢˜ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
å®éªŒä½¿ç”¨äº†å¤šæºäº’è¡¥çš„çœŸå®ä¸–ç•Œæ•°æ®é›†ï¼š
1. **é¢„è®­ç»ƒæ•°æ®é›†**ï¼š
   - æ¥è‡ªå¾·å›½397ä¸ªNUTS-3åŒºåŸŸã€è·¨è¶Š65å¹´ï¼ˆ1951â€“2015ï¼‰çš„å†å²æ¨¡æ‹Ÿæ•°æ®ã€‚
   - åŒ…å«å†¬å°éº¦å’Œç‰ç±³çš„æ—¥å°ºåº¦AGBæ¨¡æ‹Ÿå€¼ï¼ˆæ¥è‡ªSIMPLACEå¹³å°ï¼‰ã€‚
   - è¾“å…¥å˜é‡åŒ…æ‹¬æ°”å€™ï¼ˆå¤ªé˜³è¾å°„ã€æ¸©æ¹¿åº¦ã€é™æ°´ï¼‰ã€åœŸå£¤ç‰¹æ€§ï¼ˆè´¨åœ°ã€æœ‰æœºè´¨ï¼‰å’Œç®¡ç†æªæ–½ï¼ˆæ–½è‚¥ã€çŒæº‰ï¼‰ã€‚

2. **å¾®è°ƒæ•°æ®é›†**ï¼š
   - åœ¨å¾·å›½Selhausenåœ°åŒºçš„TERENOè§‚æµ‹ç«™è¿›è¡Œçš„ç”°é—´æ§åˆ¶å®éªŒï¼ˆ2016â€“2018å¹´ï¼‰ã€‚
   - è¦†ç›–ä¸‰ç§æ°´åˆ†å¤„ç†ï¼šé®é›¨æ£šï¼ˆshelteredï¼‰ã€é›¨å…»ï¼ˆrainfedï¼‰ã€çŒæº‰ï¼ˆirrigatedï¼‰ã€‚
   - åŒ…æ‹¬å†¬å°éº¦ï¼ˆ2016ï¼‰å’Œç‰ç±³ï¼ˆ2017â€“2018ï¼‰çš„å®é™…è§‚æµ‹AGBã€‚

3. **ç©ºé—´å˜å¼‚æ€§æ•°æ®é›†**ï¼š
   - ä½¿ç”¨ERA5æ°”å€™æ•°æ®ï¼ˆ0.25Â°åˆ†è¾¨ç‡ï¼‰å¹¶ç»“åˆMODIS NDVIè¿›è¡Œè¶…åˆ†è¾¨ç‡è‡³250mã€‚
   - åœ°é¢çœŸå®AGBç”±å¾·å›½äº§é‡ç»Ÿè®¡æ•°æ®è½¬æ¢è€Œæ¥ï¼ˆæ”¶è·æŒ‡æ•°0.55ï¼‰ã€‚

4. **è¿‡ç¨‹æ¨¡å‹åŸºå‡†æ•°æ®**ï¼š
   - ä½¿ç”¨ç›¸åŒçš„è¾“å…¥é©±åŠ¨LINTUL5æ¨¡å‹ç”Ÿæˆæ¨¡æ‹Ÿè¾“å‡ºï¼Œç”¨äºä¸AgriPINNå¯¹æ¯”ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹æ¶æ„**ï¼šä»¥CNNä¸ºéª¨å¹²ç½‘ç»œï¼Œä¹Ÿå¯æ›¿æ¢ä¸ºLSTMã€ResNet-18ã€TFTç­‰éªŒè¯é€šç”¨æ€§ã€‚
- **è®­ç»ƒç­–ç•¥**ï¼šå…ˆåœ¨å†å²æ•°æ®ä¸Šé¢„è®­ç»ƒï¼Œå†åœ¨ç”°é—´å®éªŒæ•°æ®ä¸Šå¾®è°ƒã€‚
- **æŸå¤±å‡½æ•°**ï¼š
  $$
  \mathcal{L}(\theta) = \mathcal{L}_{\text{data}} + \lambda \cdot \mathcal{L}_{\text{phys}}
  $$
  å…¶ä¸­ $\mathcal{L}_{\text{data}}$ æ˜¯AGBé¢„æµ‹çš„MSEï¼Œ$\mathcal{L}_{\text{phys}}$ æ˜¯LINTUL5åŠ¨åŠ›å­¦æ–¹ç¨‹æ®‹å·®çš„å¹³æ–¹é¡¹ï¼Œ$\lambda$ ä¸ºæƒè¡¡è¶…å‚æ•°ã€‚

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å…¬å¼ | è¯´æ˜ |
|------|------|------|
| **RMSE** | $\sqrt{\frac{1}{T}\sum_{t}(y_t - \hat{y}_t)^2}$ | è¡¡é‡é¢„æµ‹è¯¯å·®å¤§å°ï¼Œå•ä½ä¸AGBä¸€è‡´ |
| **CC**ï¼ˆPearsonç›¸å…³ç³»æ•°ï¼‰ | $\frac{\sum (y-\bar{y})(\hat{y}-\bar{\hat{y}})}{\sqrt{\sum(y-\bar{y})^2 \sum(\hat{y}-\bar{\hat{y}})^2}}$ | åæ˜ é¢„æµ‹ä¸è§‚æµ‹çš„çº¿æ€§å…³ç³»å¼ºåº¦ |
| **RÂ²** | å†³å®šç³»æ•° | è¡¨ç¤ºæ¨¡å‹è§£é‡Šå˜å¼‚çš„èƒ½åŠ› |
| **RMSPE** | ç›¸å¯¹å‡æ–¹æ ¹ç™¾åˆ†æ¯”è¯¯å·® | ç”¨äºè¯„ä¼°æ½œå˜é‡é‡å»ºè´¨é‡ |
| **ç»Ÿè®¡æ£€éªŒ** | é…å¯¹Wilcoxonç¬¦å·ç§©æ£€éªŒ | åˆ¤æ–­æ€§èƒ½å·®å¼‚æ˜¯å¦æ˜¾è‘— |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»åˆ« | æ¨¡å‹ |
|------|------|
| **æ•°æ®é©±åŠ¨æ¨¡å‹** | CNN-Transformer, SLTF (SSA-LSTM-Transformer), ConvLSTM-ViT |
| **è¿‡ç¨‹æ¨¡å‹** | LINTUL5ï¼ˆåµŒå…¥SIMPLACEæ¡†æ¶ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
#### è¡¨1ï¼šé¢„è®­ç»ƒé˜¶æ®µæ€§èƒ½æ¯”è¾ƒï¼ˆRMSE å’Œ CCï¼‰
| æ¨¡å‹ | å†¬å°éº¦ RMSE (t/ha) | å†¬å°éº¦ CC | ç‰ç±³ RMSE (t/ha) | ç‰ç±³ CC |
|------|---------------------|-----------|------------------|--------|
| CNN-Transformer | 2.08 | 0.78 | 2.23 | 0.72 |
| SLTF | 1.43 | 0.88 | 2.06 | 0.81 |
| ConvLSTM-ViT | 1.62 | 0.82 | 1.93 | 0.87 |
| **AgriPINN (Ours)** | **1.42** | **0.94** | **1.81** | **0.92** |

> âœ… AgriPINNåœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡ä¼˜äºSOTAæ•°æ®é©±åŠ¨æ¨¡å‹ã€‚

#### è¡¨2ï¼šå¾®è°ƒååœ¨ä¸åŒæ°´åˆ†å¤„ç†ä¸‹çš„å¹³å‡è¡¨ç°ï¼ˆå†¬å°éº¦ï¼‰
| å¤„ç† | æ–¹æ³• | RMSE (t/ha) | RÂ² | CC |
|------|------|-------------|-----|----|
| Shelter | LINTUL5 | 1.92 | 0.91 | 0.89 |
| | **AgriPINN** | **1.83** | **0.93** | **0.94** |
| Rainfed | LINTUL5 | 4.40 | 0.90 | 0.87 |
| | **AgriPINN** | **2.25** | **0.92** | **0.91** |
| Irrigated | LINTUL5 | 3.06 | 0.90 | 0.86 |
| | **AgriPINN** | **2.03** | **0.93** | **0.91** |

> âœ… AgriPINNåœ¨æ‰€æœ‰æ°´åˆ†æ¡ä»¶ä¸‹å‡æ˜¾è‘—ä¼˜äºLINTUL5å’Œå…¶ä»–æ•°æ®é©±åŠ¨æ¨¡å‹ï¼Œå°¤å…¶åœ¨Rainfedæ¡ä»¶ä¸‹RMSEå‡å°‘è¶…è¿‡50%ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ç²¾åº¦ä¼˜åŠ¿**ï¼š
  - åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­ï¼ŒAgriPINNèƒ½æ›´å‡†ç¡®æ•æ‰ç”Ÿé•¿æ‹ç‚¹ï¼ˆå¦‚æ‹”èŠ‚æœŸã€æŠ½ç©—æœŸï¼‰ã€‚
  - åœ¨ç©ºé—´é¢„æµ‹ä¸­ï¼ŒAgriPINNçš„RÂ²è¾¾åˆ° **0.837**ï¼Œæ˜¾è‘—é«˜äºLINTUL5ï¼ˆ0.802ï¼‰å’Œæ‰€æœ‰çº¯æ•°æ®é©±åŠ¨æ¨¡å‹ï¼ˆ<0.721ï¼‰ã€‚
- **ç¨³å®šæ€§ä¼˜åŠ¿**ï¼š
  - æ•°æ®é©±åŠ¨æ¨¡å‹åœ¨å¾®è°ƒåå‡ºç°â€œç¾éš¾æ€§é—å¿˜â€ï¼Œè€ŒAgriPINNä¿æŒç¨³å®šã€‚
  - å›¾4æ˜¾ç¤ºï¼ŒAgriPINNåœ¨LAIã€PARã€RUEã€Fwç­‰æ½œå˜é‡ä¸Šçš„RMSPEæ›´ä½ä¸”æ³¢åŠ¨å°ï¼Œè¡¨æ˜å…¶ç”Ÿç†ä¸€è‡´æ€§æ›´å¼ºã€‚
- **è®¡ç®—æ•ˆç‡ä¼˜åŠ¿**ï¼š
  - å¦‚å›¾8æ‰€ç¤ºï¼ŒAgriPINNçš„æ•´ä½“è®¡ç®—æˆæœ¬æœ€ä½ï¼Œ**æ¨ç†é€Ÿåº¦å¿«8å€äºLINTUL5**ã€‚
  - å‚æ•°é‡æ›´å°‘ï¼ˆè§å›¾2bï¼‰ï¼Œè®­ç»ƒæ—¶é—´æœ€çŸ­ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
#### è¡¨4ï¼šä¸åŒéª¨å¹²ç½‘ç»œä¸‹åŠ å…¥è¿‡ç¨‹çº¦æŸçš„æ•ˆæœ
| Backbone | Variant | #Params (M) | Convergence Time (min) | Avg RMSE (t/ha) |
|----------|---------|--------------|-------------------------|------------------|
| 1D-CNN | Original | 0.7 | 11 | 6.20 |
| | **Hybrid (AgriPINN)** | **0.7** | **10** | **2.04** |
| LSTM | Original | 0.5 | 8 | 5.83 |
| | **Hybrid** | **0.5** | **7** | **2.01** |
| ResNet-18 | Original | 11.7 | 492 | 2.25 |
| | **Hybrid** | **11.7** | **376** | **1.87** |
| TFT | Original | 5.7 | 176 | 2.54 |
| | **Hybrid** | **5.7** | **129** | **1.93** |

> ğŸ” å‘ç°ï¼š
> - æ‰€æœ‰éª¨å¹²ç½‘ç»œåœ¨å¼•å…¥è¿‡ç¨‹çº¦æŸåï¼Œ**RMSEæ˜¾è‘—ä¸‹é™**ï¼Œè¯æ˜è¯¥æ¡†æ¶å…·æœ‰é€šç”¨æ€§ã€‚
> - å¯¹è½»é‡çº§æ¨¡å‹ï¼ˆå¦‚1D-CNNã€LSTMï¼‰ï¼Œç²¾åº¦æå‡æœ€ä¸ºæ˜¾è‘—ï¼ˆRMSEé™å¹…è¾¾60%ä»¥ä¸Šï¼‰ã€‚
> - å¯¹æ·±å±‚æ¨¡å‹ï¼ˆå¦‚ResNet-18ï¼‰ï¼Œä¸»è¦æ”¶ç›Šæ˜¯**åŠ é€Ÿæ”¶æ•›**ï¼ˆè®­ç»ƒæ—¶é—´å‡å°‘çº¦25%ï¼‰ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **AgriPINNå®ç°äº†ç²¾åº¦ä¸å¯è§£é‡Šæ€§çš„ç»Ÿä¸€**ï¼š
   - ä¸ä»…æå‡äº†AGBé¢„æµ‹ç²¾åº¦ï¼Œè¿˜èƒ½æ— ç›‘ç£åœ°æ¢å¤å…·æœ‰ç‰©ç†æ„ä¹‰çš„æ½œå˜é‡ï¼ˆLAIã€RUEã€Fwç­‰ï¼‰ï¼Œè¿™äº›å˜é‡ä¸ç‹¬ç«‹è§‚æµ‹ä¸€è‡´ã€‚
2. **è¿‡ç¨‹çº¦æŸå¢å¼ºäº†æ¨¡å‹æ³›åŒ–èƒ½åŠ›**ï¼š
   - åœ¨è·¨å¹´ä»½ã€è·¨åŒºåŸŸã€ä¸åŒæ°´åˆ†å¤„ç†ä¸‹å‡è¡¨ç°å‡ºä¼˜å¼‚çš„OODé²æ£’æ€§ï¼Œé¿å…äº†çº¯æ•°æ®é©±åŠ¨æ¨¡å‹çš„è¿‡æ‹Ÿåˆå’Œç¾éš¾æ€§é—å¿˜ã€‚
3. **å…¼å…·é«˜æ•ˆç‡ä¸å¯æ‰©å±•æ€§**ï¼š
   - æ¨ç†é€Ÿåº¦å¿«ã€å‚æ•°å°‘ï¼Œé€‚åˆå¤§è§„æ¨¡æ—¶ç©ºé¢„æµ‹ä»»åŠ¡ï¼Œè§£å†³äº†ä¼ ç»Ÿè¿‡ç¨‹æ¨¡å‹è®¡ç®—ç“¶é¢ˆé—®é¢˜ã€‚
4. **ç©ºé—´æ¨¡å¼é‡å»ºæ›´åˆç†**ï¼š
   - AgriPINNçš„ç©ºé—´AGBåˆ†å¸ƒæ—¢ä¿ç•™äº†è¿‡ç¨‹æ¨¡å‹çš„åŒºåŸŸæ¢¯åº¦ç‰¹å¾ï¼Œåˆå…‹æœäº†å…¶â€œæ¡å¸¦æ•ˆåº”â€ï¼ŒåŒæ—¶é¿å…äº†æ•°æ®é©±åŠ¨æ¨¡å‹çš„ç¢ç‰‡åŒ–å™ªå£°ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–åŸºç¡€è¿‡ç¨‹æ¨¡å‹çš„å‡†ç¡®æ€§**ï¼š
   - è‹¥LINTUL5æœ¬èº«å¯¹æŸäº›ç”Ÿç†è¿‡ç¨‹æè¿°ä¸å‡†ç¡®ï¼ˆå¦‚è¥å…»é™åˆ¶ã€ç—…è™«å®³å“åº”ï¼‰ï¼ŒAgriPINNå¯èƒ½ç»§æ‰¿è¿™äº›åå·®ã€‚
2. **å½“å‰ä»…é’ˆå¯¹æ°´åˆ†èƒè¿«**ï¼š
   - æ¨¡å‹ç›®å‰ä¸»è¦å…³æ³¨æ°´åˆ†èƒè¿«ï¼Œå°šæœªç³»ç»Ÿè¯„ä¼°å…¶ä»–éç”Ÿç‰©æˆ–ç”Ÿç‰©èƒè¿«ï¼ˆå¦‚æ°®ç´ ç¼ºä¹ã€é«˜æ¸©ã€ç—…å®³ï¼‰çš„å½±å“ã€‚
3. **æœªé‡åŒ–ä¸ç¡®å®šæ€§**ï¼š
   - ç¼ºä¹ç½®ä¿¡åŒºé—´æˆ–æ¦‚ç‡è¾“å‡ºï¼Œé™åˆ¶äº†å…¶åœ¨é£é™©æ•æ„Ÿå†³ç­–ä¸­çš„åº”ç”¨ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•ç”Ÿç‰©ç‰©ç†çº¦æŸèŒƒå›´**ï¼š
   - å¼•å…¥æ›´å¤æ‚çš„å†œè‰ºè§„åˆ™ï¼Œå¦‚æ°®ç£·é’¾å¾ªç¯ï¼ˆN-P-K balanceï¼‰ã€åœŸå£¤ä¿è‚²æœºåˆ¶ï¼Œä»¥æ”¯æŒå¤šä½œç‰©è½®ä½œç³»ç»Ÿçš„æ¨¡æ‹Ÿã€‚
2. **å¤šç›®æ ‡è”åˆä¼˜åŒ–**ï¼š
   - æ‰©å±•æŸå¤±å‡½æ•°ä»¥åŒæ—¶é¢„æµ‹AGBã€äº§é‡ã€çŒæº‰éœ€æ±‚ã€åœŸå£¤æ°´åˆ†ä¹ƒè‡³ç¢³æ±‡æŒ‡æ ‡ã€‚
3. **å®ç°å®æ—¶éƒ¨ç½²**ï¼š
   - ä¼˜åŒ–æ¨¡å‹ä»¥åœ¨è¾¹ç¼˜è®¾å¤‡ï¼ˆedge devicesï¼‰ä¸Šè¿è¡Œï¼Œå¹¶å¼€å‘ç”¨æˆ·å‹å¥½çš„ç•Œé¢ï¼ŒæœåŠ¡äºç²¾å‡†å†œä¸šå®è·µã€‚
4. **è‡ªåŠ¨è¶…å‚æ•°è°ƒèŠ‚ä¸ä¸ç¡®å®šæ€§å»ºæ¨¡**ï¼š
   - æ¢ç´¢è‡ªåŠ¨è°ƒæ•´æŸå¤±æƒé‡Î»çš„æ–¹æ³•ï¼Œå¹¶é›†æˆè´å¶æ–¯ç¥ç»ç½‘ç»œæˆ–è’™ç‰¹å¡æ´›Dropoutæ¥æä¾›é¢„æµ‹ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚

---

> ğŸ“Œ **æ€»ç»“**ï¼š  
> AgriPINNæˆåŠŸèåˆäº†**æ·±åº¦å­¦ä¹ çš„å¼ºå¤§è¡¨å¾èƒ½åŠ›**ä¸**è¿‡ç¨‹æ¨¡å‹çš„ç”Ÿç‰©ç‰©ç†åˆç†æ€§**ï¼Œæå‡ºäº†ä¸€ç§å¯è§£é‡Šã€é«˜æ•ˆä¸”é²æ£’çš„ä½œç‰©ç”Ÿç‰©é‡é¢„æµ‹æ–°èŒƒå¼ã€‚å®ƒä¸ä»…åœ¨ç²¾åº¦ä¸Šè¶…è¶ŠSOTAæ¨¡å‹ï¼Œæ›´é‡è¦çš„æ˜¯æä¾›äº†å¯¹æ°´åˆ†èƒè¿«æœºåˆ¶çš„é€æ˜æ´å¯Ÿï¼Œä¸ºæ™ºèƒ½çŒæº‰è§„åˆ’ã€äº§é‡é¢„æŠ¥å’Œæ°”å€™å˜åŒ–é€‚åº”ç­–ç•¥æä¾›äº†å¼ºæœ‰åŠ›çš„å·¥å…·ã€‚

</details>

---

### 12. [Designing faster mixed integer linear programming algorithm via learning the optimal path](https://arxiv.org/abs/2601.16056)

**Authors**: Ruizhi Liu, Liming Xu, Xulin Huang, Jingyan Sui, Shizhe Ding, Boyang Xia, Chungong Yu, Dongbo Bu  
**Category**: cs.AI  
**Published**: 2026-01-23  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.16056v1  

#### Abstract
Designing faster algorithms for solving Mixed-Integer Linear Programming (MILP) problems is highly desired across numerous practical domains, as a vast array of complex real-world challenges can be effectively modeled as MILP formulations. Solving these problems typically employs the branch-and-boun...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDesigning faster mixed integer linear programming algorithm via learning the optimal path

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿçš„ **Mixed-Integer Linear Programming (MILP)** æ±‚è§£å™¨ä¾èµ–äºæ‰‹å·¥è®¾è®¡çš„å¯å‘å¼è§„åˆ™ï¼ˆå¦‚ Best Estimate Search, BESï¼‰è¿›è¡Œ **branch-and-bound** è¿‡ç¨‹ä¸­çš„èŠ‚ç‚¹é€‰æ‹©ã€‚è¿™äº›è§„åˆ™è™½ç„¶å¹¿æ³›ä½¿ç”¨ï¼Œä½†åœ¨ä¸åŒé—®é¢˜å®ä¾‹ä¸Šè¡¨ç°ä¸ç¨³å®šï¼Œä¸”éš¾ä»¥æ³›åŒ–åˆ°å¤§è§„æ¨¡å¤æ‚é—®é¢˜ä¸­ã€‚

æ­¤å¤–ï¼Œç”±äºæœ€ä¼˜è§£æ‰€åœ¨çš„â€œoracle èŠ‚ç‚¹â€åœ¨æœç´¢æ ‘ä¸­å æ¯”æä½ï¼Œå¯¼è‡´è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹æ—¶å­˜åœ¨ä¸¥é‡çš„**æ ·æœ¬ä¸å¹³è¡¡é—®é¢˜**ï¼Œé™åˆ¶äº†åŸºäºå­¦ä¹ çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šDeepBound

ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **DeepBound** çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºæ”¹è¿› branch-and-bound ç®—æ³•ä¸­çš„ **node selection** ç­–ç•¥ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
- âœ… **å­¦ä¹ æœ€ä¼˜è·¯å¾„èŠ‚ç‚¹ï¼ˆOptimal Path Nodesï¼‰**  
  DeepBound çš„ç›®æ ‡æ˜¯è‡ªåŠ¨è¯†åˆ«é‚£äº›åŒ…å«æœ€ä¼˜å¯è¡Œè§£çš„èŠ‚ç‚¹ï¼ˆå³ oracle nodesï¼‰ï¼Œä»è€Œä¼˜å…ˆæ¢ç´¢è¿™äº›åˆ†æ”¯ï¼ŒåŠ é€Ÿæ±‚è§£è¿‡ç¨‹ã€‚

- âœ… **å¤šå±‚çº§ç‰¹å¾èåˆç½‘ç»œï¼ˆMulti-level Feature Fusion Networkï¼‰**  
  å¼•å…¥ä¸€ä¸ªç”±å¤šä¸ª **Fusion Blocks** ç»„æˆçš„ç¥ç»ç½‘ç»œæ¶æ„ï¼Œåœ¨ä¸¤ä¸ªç»´åº¦ä¸Šè¿›è¡Œä¿¡æ¯èåˆï¼š
  - **Node-level fusion**ï¼šèšåˆä¸€å¯¹èŠ‚ç‚¹ä¹‹é—´çš„è·¨èŠ‚ç‚¹ä¿¡æ¯ï¼›
  - **Feature-level fusion**ï¼šæ•´åˆæ¯ä¸ªèŠ‚ç‚¹å†…éƒ¨ä¸åŒç‰¹å¾é—´çš„å…³è”ã€‚
  è¿™å¢å¼ºäº†æ¨¡å‹å¯¹èŠ‚ç‚¹é—´å·®å¼‚çš„åˆ¤åˆ«èƒ½åŠ›ã€‚

- âœ… **Pairwise è®­ç»ƒèŒƒå¼ç¼“è§£æ ·æœ¬ä¸å¹³è¡¡**  
  å°† oracle èŠ‚ç‚¹ä¸åŒä¸€ä¼˜å…ˆé˜Ÿåˆ—ä¸­çš„é oracle èŠ‚ç‚¹é…å¯¹ï¼Œæ„å»ºæ­£è´Ÿæ ·æœ¬å¯¹ï¼Œå°†ä»»åŠ¡è½¬åŒ–ä¸º **learning-to-rank** é—®é¢˜ã€‚è¿™æ˜¾è‘—æå‡äº†ç¨€æœ‰æ­£æ ·æœ¬çš„åˆ©ç”¨ç‡ï¼Œå¹¶æé«˜äº†æ¨¡å‹åŒºåˆ†èƒ½åŠ›ã€‚

- âœ… **é›†æˆå­¦ä¹ æå‡é²æ£’æ€§**  
  ä½¿ç”¨å¤šä¸ªç‹¬ç«‹è®­ç»ƒçš„ fusion model æ„å»ºé›†æˆç³»ç»Ÿï¼Œè¾“å‡ºå¹³å‡å¾—åˆ†ï¼Œå¢å¼ºé¢„æµ‹ç¨³å®šæ€§ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼ ç»Ÿå¯å‘å¼ï¼ˆå¦‚ BESï¼‰ | å…¶ä»–å­¦ä¹ æ–¹æ³•ï¼ˆå¦‚ He et al., Labassi et al.ï¼‰ | DeepBound |
|------|------------------------|---------------------------------------------|-----------|
| æ³›åŒ–æ€§ | å›ºå®šè§„åˆ™ï¼Œè·¨é—®é¢˜è¡¨ç°ä¸ä¸€è‡´ | å¤šæ•°ä»…é™å°è§„æ¨¡é—®é¢˜ | åœ¨æ›´å¤§æ›´éš¾å®ä¾‹ä¸Šä»æœ‰æ•ˆ |
| ç‰¹å¾åˆ©ç”¨ | æ‰‹å·¥å®šä¹‰æœ‰é™ç‰¹å¾é›† | å¤šåŸºäºåŸå§‹å›¾ç»“æ„ç¼–ç  | å·¥ç¨‹åŒ–ä¸°å¯Œç‰¹å¾ + å­¦ä¹ ç»„åˆ |
| ä¸å¹³è¡¡å¤„ç† | æ— æ˜¾å¼å¤„ç† | éƒ¨åˆ†å°è¯•ä½†æ•ˆæœæœ‰é™ | Pairwise ranking æ˜¾è‘—æ”¹å–„ |
| å¯è§£é‡Šæ€§ | æ˜ç¡®ä½†åƒµåŒ– | é»‘ç®±ç¨‹åº¦é«˜ | æ”¯æŒ SHAP åˆ†æç‰¹å¾é‡è¦æ€§ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
å®éªŒåŸºäºä¸‰ä¸ªç»å…¸çš„ NP-hard MILP é—®é¢˜åŸºå‡†ï¼š
1. **Set Covering Problem**ï¼ˆé›†åˆè¦†ç›–ï¼‰
2. **Combinatorial Auction Problem**ï¼ˆç»„åˆæ‹å–ï¼‰
3. **Capacitated Facility Location Problem**ï¼ˆå¸¦å®¹é‡è®¾æ–½é€‰å€ï¼‰

æ¯ç±»é—®é¢˜ç”Ÿæˆä¸‰ç§éš¾åº¦çº§åˆ«ï¼ˆeasy / medium / hardï¼‰çš„å®ä¾‹ï¼š
- Set Covering: $1000 \times 500$, $1000 \times 1000$, $1000 \times 2000$
- Combinatorial Auction: $100 \times 500$, $200 \times 1000$, $300 \times 1500$
- Facility Location: $100 \times 100$, $200 \times 100$, $400 \times 100$

> æ³¨ï¼šæ ¼å¼ä¸º â€œå˜é‡æ•° Ã— çº¦æŸæ•°â€

è®­ç»ƒé›†åŒ…å« 5,000 ä¸ªä¸­ç­‰éš¾åº¦å®ä¾‹ï¼Œæµ‹è¯•é›†æ¯ç±»æ¯æ¡£ 100 ä¸ªéšæœºç”Ÿæˆå®ä¾‹ã€‚

---

### å®éªŒè®¾ç½®
- **æ±‚è§£å™¨å¹³å°**ï¼šSCIP 8.0
- **åˆ†æ”¯ç­–ç•¥å›ºå®šä¸º Full-Strong Branching (FSB)**ï¼Œä»¥æ¶ˆé™¤ branching rule å¯¹ node selection çš„å¹²æ‰°ã€‚
- **è¯„ä¼°ç¯å¢ƒ**ï¼šIntel Xeon Gold 6238R CPU @ 2.20GHzï¼Œéƒ¨åˆ†å®éªŒä½¿ç”¨ NVIDIA A100 GPUã€‚

---

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Solving Time (sol-time)** | æ€»æ±‚è§£æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œæœªå®Œæˆä¹Ÿè®¡å…¥è¶…æ—¶ |
| **Best Primal Bound Time (bpb-time)** | æ‰¾åˆ°æœ€ä¼˜å¯è¡Œè§£çš„æ—¶é—´ï¼Œåæ˜  node selector å‘ç°é«˜è´¨é‡è§£çš„èƒ½åŠ› |
| **Primal Gap Convergence** | å½“å‰æ•´æ•°å¯è¡Œè§£ä¸æœ€ä¼˜è§£ä¹‹é—´ç›®æ ‡å€¼å·®è·çš„å˜åŒ–è¶‹åŠ¿ |
| **Number of Nodes Explored** | æ¢ç´¢çš„èŠ‚ç‚¹æ•°é‡ï¼Œè¶Šå°‘è¶Šå¥½ |
| **Wins Count** | åœ¨å¤§è§„æ¨¡éš¾é¢˜ä¸­ï¼Œå„æ–¹æ³•æˆä¸ºæœ€å¿«æ±‚è§£è€…çš„æ¬¡æ•°ï¼ˆout of 100 instancesï¼‰ |
| **Distance to Optimal Solution Path** | å®šé‡è¡¡é‡å½“å‰èŠ‚ç‚¹ä¸æœ€ä¼˜è·¯å¾„çš„è·ç¦»ï¼ˆè§å…¬å¼ D(n, nopt)ï¼‰ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **SCIP-BES**ï¼šSCIP é»˜è®¤çš„ Best Estimate Search èŠ‚ç‚¹é€‰æ‹©è§„åˆ™
- **XGBoost**ï¼šåŸºäºæ¢¯åº¦æå‡æ ‘çš„å­¦ä¹ æ–¹æ³•
- **He et al. [17]**ï¼šæ—©æœŸåŸºäº SVM çš„æ¨¡ä»¿å­¦ä¹ æ–¹æ³•
- **Ablation Models**ï¼š
  - *No Pair*ï¼šå•èŠ‚ç‚¹è¾“å…¥ï¼ˆæ—  pairwiseï¼‰
  - *MLP Pair*ï¼šåŒèŠ‚ç‚¹è¾“å…¥ä½†æ—  multi-level fusion ç»“æ„

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»ï¼ˆæ¥è‡ª Fig. 3 å’Œ Appendix Aï¼‰

| æ–¹æ³• | Set Covering (1000Ã—1000) Solving Time â†“ | bpb-time â†“ | Wins on Hard Instances â†‘ |
|------|-------------------------------|------------|--------------------------|
| SCIP-BES | 93.48s | 67.82s | 22/100 |
| XGBoost | 101.44s | 72.56s | 22/100 |
| He et al. | 99.60s | 69.04s | 19/100 |
| **DeepBound (Ours)** | **88.52s** | **61.16s** | **37/100** |

| æ–¹æ³• | Combinatorial Auction (200Ã—1000) Solving Time â†“ | bpb-time â†“ | Wins on Hard (300Ã—1500) â†‘ |
|------|----------------------------------|------------|---------------------------|
| SCIP-BES | 168.02s | 59.30s | 18/100 |
| XGBoost | 164.97s | 55.93s | 20/100 |
| He et al. | 169.33s | 57.19s | 23/100 |
| **DeepBound (Ours)** | **157.56s** | **52.24s** | **39/100** |

| æ–¹æ³• | Facility Location (200Ã—100) Solving Time â†“ | bpb-time â†“ | Wins on Hard (400Ã—100) â†‘ |
|------|-------------------------------|------------|--------------------------|
| SCIP-BES | 394.83s | 224.12s | 15/100 |
| XGBoost | 383.46s | 147.37s | 25/100 |
| He et al. | 398.71s | 158.29s | 18/100 |
| **DeepBound (Ours)** | **371.39s** | **118.94s** | **42/100** |

> âœ… DeepBound åœ¨æ‰€æœ‰ä¸‰é¡¹ä»»åŠ¡ä¸Šå‡å–å¾—æœ€ä½³è¡¨ç°ï¼Œå°¤å…¶åœ¨ **bpb-time** ä¸Šä¼˜åŠ¿æ˜æ˜¾ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- DeepBound å¹³å‡æ¯” BES å¿« **~10â€“15%**ï¼Œåœ¨ hardest å®ä¾‹ä¸Šçš„èƒœç‡ç¿»å€ä»¥ä¸Šã€‚
- åœ¨ **primal gap æ”¶æ•›é€Ÿåº¦**æ–¹é¢ï¼ŒDeepBound æ˜¯æœ€å¿«çš„ï¼ˆFig. 3d-fï¼‰ï¼Œç½®ä¿¡åŒºé—´æœ€å°ï¼Œè¯´æ˜å…¶è¡Œä¸ºæœ€ç¨³å®šã€‚
- åœ¨ç›¸åŒ 2000Ã—1000 é›†åˆè¦†ç›–é—®é¢˜ä¸Šï¼ˆFig. 4ï¼‰ï¼š
  - DeepBound åœ¨ç¬¬ **79 ä¸ªèŠ‚ç‚¹**æ‰¾åˆ°æœ€ä¼˜è§£ï¼›
  - BES åˆ°ç¬¬ **599 ä¸ªèŠ‚ç‚¹**æ‰æ‰¾åˆ°ï¼›
  > â±ï¸ èŠ‚ç‚¹å‡å°‘çº¦ **87%**ï¼Œæå¤§ç¼©çŸ­æœç´¢è·¯å¾„ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
ï¼ˆè§ Fig. 6ï¼‰

| æ¨¡å‹å˜ä½“ | Solving Time | Primal Gap æ”¶æ•›é€Ÿåº¦ |
|---------|--------------|--------------------|
| DeepBound (å®Œæ•´ç‰ˆ) | æœ€ä¼˜ | æœ€å¿«æ”¶æ•›è‡³ 0 |
| No Pairï¼ˆæ—  pairwise è¾“å…¥ï¼‰ | æ˜æ˜¾ä¸‹é™ | æ”¶æ•›æ…¢ä¸”æ³¢åŠ¨å¤§ |
| MLP Pairï¼ˆæ—  multi-level fusionï¼‰ | ä¸‹é™ | æ”¶æ•›è¾ƒæ…¢ |

> ğŸ” ç»“è®ºï¼š**pairwise è®­ç»ƒæœºåˆ¶** å’Œ **multi-level feature fusion** éƒ½è‡³å…³é‡è¦ï¼Œç¼ºä¸€ä¸å¯ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **DeepBound èƒ½æœ‰æ•ˆå­¦ä¹ å¹¶ä¼˜å…ˆé€‰æ‹©é€šå¾€æœ€ä¼˜è§£çš„èŠ‚ç‚¹è·¯å¾„**ï¼Œæ˜¾è‘—åŠ å¿« primal bound æ›´æ–°ã€‚
2. âœ… **Pairwise ranking + ensemble fusion** æˆåŠŸè§£å†³äº† oracle èŠ‚ç‚¹æåº¦ç¨€ç–å¸¦æ¥çš„æ ·æœ¬ä¸å¹³è¡¡æŒ‘æˆ˜ã€‚
3. âœ… **å·¥ç¨‹åŒ–ç‰¹å¾è®¾è®¡ä¼˜äºç«¯åˆ°ç«¯å›¾ç¼–ç **ï¼šç›¸æ¯”ç›´æ¥ç”¨ GNN ç¼–ç åŸå§‹ MILP ç»“æ„ï¼Œç²¾å¿ƒæ„é€ çš„èŠ‚ç‚¹ç‰¹å¾æ›´å…·å¯è§£é‡Šæ€§å’Œé«˜æ•ˆæ€§ã€‚
4. âœ… **å…·å¤‡å¼ºæ³›åŒ–èƒ½åŠ›**ï¼šåœ¨æ¯”è®­ç»ƒé›†æ›´å¤§æ›´å¤æ‚çš„å®ä¾‹ä¸Šä¾ç„¶ä¿æŒé¢†å…ˆæ€§èƒ½ã€‚
5. âœ… **SHAP åˆ†ææ­ç¤ºäº†åŠ¨æ€ç‰¹å¾æƒé‡æœºåˆ¶**ï¼š
   - ä¸åŒé—®é¢˜ç±»å‹ä¸‹ï¼Œå…³é”®ç‰¹å¾çš„é‡è¦æ€§åˆ†å¸ƒä¸åŒï¼›
   - ä¾‹å¦‚ï¼Œåœ¨ Set Covering ä¸­ `Node_Lowerbound` å’Œ `BranchVar_Pseudocost` æ›´é‡è¦ï¼›
   - è€Œåœ¨ Facility Location ä¸­ï¼Œ`Node_Type` å‡ ä¹æ— å½±å“ï¼›
   > ğŸ’¡ è¡¨æ˜ DeepBound è‡ªåŠ¨å‘ç°äº†é€‚åº”é—®é¢˜ç»“æ„çš„çµæ´»å†³ç­–æ¨¡å¼ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- â— ä¾èµ–äº FSB åˆ†æ”¯ç­–ç•¥ç”Ÿæˆé«˜è´¨é‡è®­ç»ƒæ ‡ç­¾ï¼Œè€Œ FSB æœ¬èº«è®¡ç®—æ˜‚è´µï¼Œé™åˆ¶äº†è®­ç»ƒæ•°æ®è§„æ¨¡ã€‚
- â— å½“å‰æ–¹æ³•ä¸“æ³¨äº node selectionï¼Œå°šæœªæ•´åˆ branching variable selection æˆ– cutting plane selectionã€‚
- â— æ¨¡å‹æ¨ç†éœ€é¢å¤– GPU åŠ é€Ÿï¼Œåœ¨çº¯ CPU ç¯å¢ƒä¸‹å¯èƒ½å¸¦æ¥éƒ¨ç½²æˆæœ¬ã€‚
- â— å¯¹éå¸¸ç¨€ç–æˆ–ç‰¹æ®Šç»“æ„çš„é—®é¢˜ï¼ˆå¦‚é«˜åº¦å¯¹ç§°é—®é¢˜ï¼‰å°šæœªéªŒè¯ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- ğŸ”® æ¢ç´¢è½»é‡çº§æ›¿ä»£æ–¹æ¡ˆç”Ÿæˆè®­ç»ƒè½¨è¿¹ï¼ˆå¦‚ç”¨ RPB + æ ¡å‡†æŠ€æœ¯ï¼‰ã€‚
- ğŸ”® å°† DeepBound æ¡†æ¶æ‰©å±•è‡³å…¶ä»–ç»„ä»¶ï¼ˆå¦‚ variable branchingã€cut selectionï¼‰ã€‚
- ğŸ”® ç»“åˆ **Large Language Models (LLMs)** æˆ– **reinforcement learning** å®ç° end-to-end æœç´¢ç­–ç•¥ä¼˜åŒ–ã€‚
- ğŸ”® æ¢ç´¢ **zero-shot generalization** èƒ½åŠ›ï¼Œä½¿æ¨¡å‹æ— éœ€é‡æ–°è®­ç»ƒå³å¯åº”ç”¨äºæ–°é—®é¢˜ç±»åˆ«ã€‚
- ğŸ”® å¼€å‘é¢å‘å·¥ä¸šçº§ MILP å®ä¾‹çš„åœ¨çº¿å¢é‡å­¦ä¹ æœºåˆ¶ã€‚

---

## æ€»ç»“
**DeepBound** æ˜¯ä¸€ç§æ–°é¢–ä¸”é«˜æ•ˆçš„åŸºäºæ·±åº¦å­¦ä¹ çš„ node selection æ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥ **pairwise ranking** å’Œ **multi-level feature fusion**ï¼ŒæˆåŠŸå…‹æœäº†ä¼ ç»Ÿå¯å‘å¼å’Œå·²æœ‰å­¦ä¹ æ–¹æ³•åœ¨ **æ ·æœ¬ä¸å¹³è¡¡** å’Œ **æ³›åŒ–èƒ½åŠ›** ä¸Šçš„ç“¶é¢ˆã€‚å®éªŒè¯æ˜å…¶åœ¨å¤šä¸ª NP-hard MILP åŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äºäººå·¥è§„åˆ™å’Œå…¶ä»–å­¦ä¹ æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨å‘ç°æœ€ä¼˜è§£çš„é€Ÿåº¦ä¸Šå…·æœ‰å‹å€’æ€§ä¼˜åŠ¿ã€‚è¯¥å·¥ä½œä¸ºæœªæ¥æ„å»ºâ€œæ™ºèƒ½æ±‚è§£å™¨â€æä¾›äº†é‡è¦çš„æ–¹æ³•è®ºåŸºç¡€ã€‚

</details>

---

### 13. [YuFeng-XGuard: A Reasoning-Centric, Interpretable, and Flexible Guardrail Model for Large Language Models](https://arxiv.org/abs/2601.15588)

**Authors**: Junyu Lin, Meizhen Liu, Xiufeng Huang, Jinfeng Li, Haiwen Hong, Xiaohan Yuan, Yuefeng Chen, Longtao Huang, Hui Xue, Ranjie Duan, Zhikai Chen, Yuchuan Fu, Defeng Li, Lingyao Gao, Yitong Yang  
**Category**: cs.CL  
**Published**: 2026-01-23  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.15588v1  

#### Abstract
As large language models (LLMs) are increasingly deployed in real-world applications, safety guardrails are required to go beyond coarse-grained filtering and support fine-grained, interpretable, and adaptable risk assessment. However, existing solutions often rely on rapid classification schemes or...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# YuFeng-XGuard è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´å†…å®¹å®‰å…¨æŒ‘æˆ˜ï¼Œç°æœ‰çš„**å®‰å…¨æŠ¤æ ï¼ˆguardrailï¼‰æ¨¡å‹**é€šå¸¸ä¾èµ–äºç²—ç²’åº¦çš„åˆ†ç±»æˆ–äº‹åè§„åˆ™è¿‡æ»¤ï¼Œå­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **ç¼ºä¹å¯è§£é‡Šæ€§**ï¼šè¾“å‡ºä¸ºé»‘ç›’å¼çš„äºŒå…ƒåˆ¤æ–­ï¼ˆsafe/unsafeï¼‰ï¼Œéš¾ä»¥ç†è§£å†³ç­–ä¾æ®ã€‚
- **ç­–ç•¥åƒµåŒ–**ï¼šé£é™©å®šä¹‰å›ºåŒ–äºè®­ç»ƒæ•°æ®ä¸­ï¼Œæ— æ³•çµæ´»é€‚åº”åŠ¨æ€å˜åŒ–çš„å®‰å…¨æ”¿ç­–éœ€æ±‚ã€‚
- **æ•ˆç‡ä¸é€æ˜åº¦æƒè¡¡å›°éš¾**ï¼šç”Ÿæˆè¯¦ç»†è§£é‡Šä¼šæ˜¾è‘—å¢åŠ æ¨ç†å»¶è¿Ÿï¼Œå½±å“å®æ—¶éƒ¨ç½²ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
YuFeng-XGuard æ˜¯ä¸€ä¸ªä»¥**æ¨ç†ä¸ºä¸­å¿ƒï¼ˆreasoning-centricï¼‰**ã€**å¯è§£é‡Šæ€§å¼º**ä¸”**é«˜åº¦çµæ´»**çš„ LLM å®‰å…¨æŠ¤æ æ¨¡å‹å®¶æ—ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰ç»“æ„åŒ–é£é™©æ„ŸçŸ¥ï¼ˆStructured Risk Perceptionï¼‰
ä¸åŒäºä¼ ç»Ÿåˆ†ç±»æ¨¡å‹ä»…è¾“å‡ºæ ‡ç­¾ï¼ŒYuFeng-XGuard è¾“å‡ºåŒ…å«ä¸‰ä¸ªéƒ¨åˆ†çš„ç»“æ„åŒ–é¢„æµ‹ï¼š
- **æ˜¾å¼é£é™©ç±»åˆ«ï¼ˆexplicit risk categoryï¼‰**
- **ç½®ä¿¡åº¦åˆ†æ•°ï¼ˆconfigurable confidence scoreï¼‰**
- **è‡ªç„¶è¯­è¨€è§£é‡Šï¼ˆnatural language explanationï¼‰**

è¯¥è®¾è®¡ä½¿å®‰å…¨å†³ç­–å…·å¤‡**å¯æ“ä½œæ€§ï¼ˆactionableï¼‰** å’Œ**å¯å®¡è®¡æ€§ï¼ˆaudit-friendlyï¼‰**ã€‚

#### ï¼ˆ2ï¼‰åˆ†å±‚æ¨ç†æœºåˆ¶ï¼ˆTiered Inference Paradigmï¼‰
é‡‡ç”¨ä¸¤é˜¶æ®µæ¨ç†æ¶æ„ï¼š
- **ç¬¬ä¸€é˜¶æ®µ**ï¼šåŸºäºé¦–ä¸ªè§£ç  token å¿«é€Ÿåšå‡ºåˆæ­¥é£é™©åˆ¤æ–­ï¼Œå®ç°ä½å»¶è¿Ÿå“åº”ã€‚
- **ç¬¬äºŒé˜¶æ®µï¼ˆæŒ‰éœ€è§¦å‘ï¼‰**ï¼šç»§ç»­ç”Ÿæˆè¯¦ç»†çš„æ¨ç†è¿‡ç¨‹ï¼Œç”¨äºå®¡æ ¸ã€è°ƒè¯•ç­‰åœºæ™¯ã€‚

è¿™ä¸€æœºåˆ¶æœ‰æ•ˆå¹³è¡¡äº†**å®æ—¶æ€§**ä¸**å¯è§£é‡Šæ€§**ä¹‹é—´çš„çŸ›ç›¾ã€‚

#### ï¼ˆ3ï¼‰åŠ¨æ€ç­–ç•¥æœºåˆ¶ï¼ˆDynamic Policy, DPï¼‰
æå‡ºå°†â€œé£é™©æ„ŸçŸ¥â€ä¸â€œç­–ç•¥æ‰§è¡Œâ€è§£è€¦çš„è®¾è®¡ï¼š
- æ¨¡å‹å†…ç½®ä¸€å¥—é»˜è®¤çš„é£é™©åˆ†ç±»ä½“ç³»ï¼ˆåŸºäº S-Eval taxonomyï¼‰ã€‚
- æ”¯æŒé€šè¿‡æ¨ç†æ—¶æŒ‡ä»¤ï¼ˆinference-time instructionï¼‰åŠ¨æ€æ·»åŠ ã€æ‰©å±•æˆ–æ”¶çª„é£é™©ç±»åˆ«å®šä¹‰ã€‚

ä¾‹å¦‚ï¼Œå¯åœ¨ç”µå•†åœºæ™¯ä¸‹ä¸´æ—¶ç¦æ­¢é”€å”®ä¾µçŠ¯çŸ¥è¯†äº§æƒçš„å•†å“ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚

#### ï¼ˆ4ï¼‰å¤šå°ºåº¦å¼€æ”¾æ¨¡å‹å‘å¸ƒ
å‘å¸ƒä¸¤ä¸ªç‰ˆæœ¬ï¼š
- **YuFeng-XGuard-8B**ï¼šå®Œæ•´åŠŸèƒ½ç‰ˆï¼Œæ”¯æŒ DP å’Œå¤æ‚æ¨ç†ã€‚
- **YuFeng-XGuard-0.6B**ï¼šè½»é‡è’¸é¦ç‰ˆï¼Œé€‚ç”¨äºé«˜ååã€ä½å»¶è¿Ÿåœºæ™¯ï¼Œç»§æ‰¿ä¸»æ¨¡å‹çš„å¼ºåˆ†ç±»èƒ½åŠ›ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | YuFeng-XGuard | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ LlamaGuardã€WildGuardï¼‰ |
|------|----------------|-------------------------------|
| å¯è§£é‡Šæ€§ | âœ… æ˜¾å¼ç”Ÿæˆè‡ªç„¶è¯­è¨€è§£é‡Š | âŒ é»‘ç›’åˆ†ç±»æˆ–ç®€å•æ‰“åˆ† |
| ç­–ç•¥çµæ´»æ€§ | âœ… æ”¯æŒè¿è¡Œæ—¶åŠ¨æ€è°ƒæ•´ç­–ç•¥ | âŒ å›ºå®šåˆ†ç±»ä½“ç³»ï¼Œéœ€é‡è®­ |
| æ¨ç†æ•ˆç‡ | âœ… åˆ†å±‚è®¾è®¡ï¼Œé¦– token å†³ç­– | âš ï¸ å…¨åºåˆ—ç”Ÿæˆæ‰å‡ºç»“æœ |
| éƒ¨ç½²çµæ´»æ€§ | âœ… æä¾› 8B å’Œ 0.6B ä¸¤ç§è§„æ¨¡ | âš ï¸ å¤šæ•°ä»…æä¾›å•ä¸€æ¨¡å‹ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–å››å¤§ç»´åº¦ï¼Œæ¶µç›–å¤šä¸ªå…¬å¼€åŸºå‡†ï¼š

| ç±»åˆ« | æ•°æ®é›† |
|------|--------|
| **é€šç”¨å®‰å…¨åˆ†ç±»** | Aegis, Aegis2.0, OpenAIModeration, OverRefusal, SEval, SimpleSafetyTests, SorryBenchmark, ToxicChat, WildGuard, XSTest |
| **å¤šè¯­è¨€é²æ£’æ€§** | PolyGuard, RTP-LXï¼ˆè¦†ç›–25ç§è¯­è¨€ï¼Œå«ä½èµ„æºè¯­ç§ï¼‰ |
| **å¯¹æŠ—æ”»å‡»æ£€æµ‹** | StrongReject, BreakShell, SEval-Attackï¼ˆæµ‹è¯• jailbreak æŠµæŠ—åŠ›ï¼‰ |
| **å®‰å…¨è¡¥å…¨è¯†åˆ«** | SEval2.0ï¼ˆä¸“é—¨æµ‹è¯•å¯¹â€œå»ºè®¾æ€§ä½†éæ‹’ç»æ€§å›å¤â€çš„æ”¾è¡Œèƒ½åŠ›ï¼‰ |

æ­¤å¤–ï¼Œæ„å»ºäº†å¤§è§„æ¨¡é«˜è´¨é‡è®­ç»ƒæ•°æ®é›†ï¼ˆçº¦280ä¸‡æ ·æœ¬ï¼‰ï¼Œå¹¶å¼•å…¥è‡ªåŠ¨åŒ–æ•°æ®ç”Ÿæˆæµç¨‹ä»¥æ”¯æŒåŠ¨æ€ç­–ç•¥è®­ç»ƒã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **è¯„ä¼°æ–¹å¼**ï¼šåœ¨ prompt å’Œ response ä¸¤ä¸ªå±‚é¢è¿›è¡Œåˆ†ç±»ä»»åŠ¡ã€‚
- **ä¸»è¦æŒ‡æ ‡**ï¼š**F1 Score**ï¼ˆå®å¹³å‡ï¼‰ï¼Œç”¨äºè¡¡é‡æ•´ä½“æ€§èƒ½ã€‚
- **å¯¹æ¯”æ–¹å¼**ï¼š
  - ä¸å…¶ä»–ä¸»æµå¼€æº guardrail æ¨¡å‹æ¨ªå‘æ¯”è¾ƒã€‚
  - è¿›è¡Œ head-to-head èƒœç‡åˆ†æï¼ˆWin Rateï¼‰ã€‚
  - åœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¿›è¡Œæ¶ˆèå®éªŒï¼ˆå¦‚ DP æœ‰æ•ˆæ€§éªŒè¯ï¼‰ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å¯¹æ¯”äº†å½“å‰ä¸»æµçš„ guardrail æ¨¡å‹ï¼ŒåŒ…æ‹¬ï¼š
- `Llama3Guard-8B`, `Llama4Guard-12B`
- `WildGuard-7B`
- `ShieldGemma-9B`
- `Qwen3Guard` ç³»åˆ—ï¼ˆ0.6B~8Bï¼‰
- `NemotronGuardV2-8B`, `NemotronReasoning-4B`
- `PolyGuard-7B`
- `GPT-OSS-SafeGuard-20B`

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Tables 2â€“6ï¼‰

#### ï¼ˆ1ï¼‰é€šç”¨å®‰å…¨åˆ†ç±»ï¼ˆGeneric Classificationï¼‰
| æ¨¡å‹ | Prompt F1 (%) | Response F1 (%) |
|------|---------------|------------------|
| **YuFeng-XGuard-8B** | **82.8** | **85.7** |
| YuFeng-XGuard-0.6B | 82.5 | 84.8 |
| ç¬¬äºŒåï¼ˆPolyGuard-7Bï¼‰ | 79.4 | 72.8 |

ğŸ‘‰ **ç»“è®º**ï¼šåœ¨ prompt å’Œ response åˆ†ç±»ä¸Šå‡å–å¾— SOTA è¡¨ç°ã€‚

#### ï¼ˆ2ï¼‰å¤šè¯­è¨€åˆ†ç±»ï¼ˆMultilingual Classificationï¼‰
| æ¨¡å‹ | Prompt Avg F1 (%) | Response Avg F1 (%) |
|------|--------------------|-----------------------|
| **YuFeng-XGuard-8B** | **83.9** | **83.8** |
| YuFeng-XGuard-0.6B | 80.8 | 80.7 |
| ç¬¬äºŒåï¼ˆQwen3Guard-Gen-8B strictï¼‰ | 85.7 | 78.5 |

ğŸ‘‰ **ç»“è®º**ï¼šåœ¨å¤šè¯­è¨€åœºæ™¯ä¸‹è¡¨ç°ç¨³å¥ï¼Œå°¤å…¶åœ¨ response åˆ†ç±»ä¸Šé¢†å…ˆæ˜æ˜¾ã€‚

#### ï¼ˆ3ï¼‰å¯¹æŠ—æ”»å‡»é˜²å¾¡ï¼ˆAttack Detectionï¼‰
| æ¨¡å‹ | Prompt Attack F1 (%) | Response Attack F1 (%) |
|------|------------------------|--------------------------|
| **YuFeng-XGuard-8B** | **97.6** | **82.3** |
| YuFeng-XGuard-0.6B | 97.2 | 79.6 |
| ç¬¬äºŒåï¼ˆPolyGuard-7Bï¼‰ | 94.2 | 67.9 |

ğŸ‘‰ **ç»“è®º**ï¼šå¯¹ jailbreak å’Œæ”»å‡»æç¤ºå…·æœ‰æå¼ºæŠµæŠ—åŠ›ã€‚

#### ï¼ˆ4ï¼‰å®‰å…¨è¡¥å…¨è¯†åˆ«ï¼ˆSafe Completionï¼‰
| æ¨¡å‹ | Prompt F1 (%) | Response F1 (%) |
|------|---------------|------------------|
| **YuFeng-XGuard-8B** | **93.7** | **80.8** |
| YuFeng-XGuard-0.6B | 90.9 | 78.1 |
| ç¬¬äºŒåï¼ˆGPT-OSS-SafeGuard-20Bï¼‰ | 83.6 | 75.5 |

ğŸ‘‰ **ç»“è®º**ï¼šèƒ½æœ‰æ•ˆåŒºåˆ†æœ‰å®³å†…å®¹ä¸å»ºè®¾æ€§å›å¤ï¼Œé¿å…â€œè¿‡åº¦æ‹¦æˆªâ€ã€‚

#### ï¼ˆ5ï¼‰æ€»ä½“èƒœç‡ï¼ˆOverall Win Rateï¼‰
ä» Figure 2 å¯è§ï¼š
- **YuFeng-XGuard-8B** åœ¨æ‰€æœ‰åŸºå‡†ä¸Šçš„ç»¼åˆèƒœç‡æœ€é«˜ï¼ˆ85.2%ï¼‰ã€‚
- å³ä¾¿æ˜¯æœ€å°çš„ **0.6B ç‰ˆæœ¬**ä¹Ÿå±•ç°å‡ºè·¨å°ºåº¦ä¼˜åŠ¿ï¼Œèƒœç‡é«˜äºè®¸å¤šæ›´å¤§æ¨¡å‹ã€‚

---

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰å¼ºåŒ–å­¦ä¹ ï¼ˆGRPOï¼‰çš„å½±å“ï¼ˆTable 9ï¼‰
ç ”ç©¶æ˜¯å¦åº”åœ¨ SFT ååŠ å…¥ GRPOï¼ˆGroup Relative Policy Optimizationï¼‰æ¥æå‡æ¨ç†è´¨é‡ã€‚

| è®¾ç½® | Prompt F1 (%) | Response F1 (%) | Multilingual Prompt F1 (%) |
|------|----------------|------------------|------------------------------|
| SFT Only (Direct) | 78.54 | 80.63 | 76.25 |
| SFT + GRPO (Explain-first) | 79.84 | 80.89 | **79.34** â†‘ |

ğŸ‘‰ **å‘ç°**ï¼š
- GRPO æ˜¾è‘—æå‡äº†â€œå…ˆè§£é‡Šå†åˆ†ç±»â€æ¨¡å¼ä¸‹çš„å‡†ç¡®æ€§ï¼Œè¯´æ˜å…¶å¢å¼ºäº†å†…éƒ¨æ¨ç†ä¸€è‡´æ€§ã€‚
- ä½†åœ¨â€œç›´æ¥åˆ†ç±»â€æ¨¡å¼ï¼ˆå³ç”Ÿäº§æ¨èæ¨¡å¼ï¼‰ä¸­å¢ç›Šæœ‰é™ã€‚
- **æœ€ç»ˆé€‰æ‹©ä¸ä½¿ç”¨ RL**ï¼Œä»¥ä¿æŒä½å»¶è¿Ÿå’Œå·¥ç¨‹ç®€æ´æ€§ã€‚

#### ï¼ˆ2ï¼‰åŠ¨æ€ç­–ç•¥æœ‰æ•ˆæ€§ï¼ˆTables 7 & 8ï¼‰

| åœºæ™¯ | æ¨¡å‹ | F1 Score |
|------|------|---------|
| **æ–°å¢å“ç±»ï¼ˆE-commerceï¼‰** | YuFeng-XGuard | **0.91** |
| | GPT-OSS-SafeGuard-20B | 0.77 |
| | Qwen3-8B-Thinking | 0.92 |
| **è°ƒæ•´èŒƒå›´ï¼ˆExpand/Narrowï¼‰** | YuFeng-XGuard | **0.75** |
| | GPT-OSS-SafeGuard-20B | 0.67 |
| | Qwen3-32B-Thinking | 0.77 |

ğŸ‘‰ **ç»“è®º**ï¼š
- YuFeng-XGuard åœ¨åŠ¨æ€ç­–ç•¥éµå¾ªæ–¹é¢æ¥è¿‘ç”šè‡³åª²ç¾éœ€è¦æ˜¾å¼ CoT æ¨ç†çš„å¤§æ¨¡å‹ã€‚
- ä¼˜åŠ¿åœ¨äº**æ— éœ€é¢å¤–æ¨ç†å¼€é”€å³å¯å®Œæˆç­–ç•¥é€‚é…**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æ¨ç†ä¸­å¿ƒåŒ–è®¾è®¡æ˜¾è‘—æå‡å¯è§£é‡Šæ€§ä¸å¯æ§æ€§**ï¼šé€šè¿‡ç”Ÿæˆç»“æ„åŒ–è¾“å‡ºï¼ˆç±»åˆ« + ç½®ä¿¡åº¦ + è§£é‡Šï¼‰ï¼Œä½¿å¾—å®‰å…¨å†³ç­–æ›´é€æ˜ã€æ˜“è°ƒè¯•ã€‚
2. **åˆ†å±‚æ¨ç†æœºåˆ¶æˆåŠŸè§£å†³æ•ˆç‡-è§£é‡Šæ‚–è®º**ï¼šé¦– token å†³ç­–æ»¡è¶³ä½å»¶è¿Ÿè¦æ±‚ï¼ŒæŒ‰éœ€è§£é‡Šä¿éšœæ·±åº¦å®¡è®¡èƒ½åŠ›ã€‚
3. **åŠ¨æ€ç­–ç•¥æœºåˆ¶å®ç°çœŸæ­£çš„ç­–ç•¥æ•æ·æ€§**ï¼šå…è®¸è¿è¥æ–¹åœ¨ä¸é‡è®­æ¨¡å‹çš„æƒ…å†µä¸‹ä¿®æ”¹å®‰å…¨æ ‡å‡†ï¼Œæå¤§æå‡ç»´æŠ¤æ•ˆç‡ã€‚
4. **è½»é‡æ¨¡å‹ä¹Ÿèƒ½è¾¾åˆ°é«˜æ€§èƒ½**ï¼š0.6B è’¸é¦æ¨¡å‹åœ¨å¤šæ•°ä»»åŠ¡ä¸Šè¶…è¶Š 4B~12B çº§åˆ«æ¨¡å‹ï¼Œä½“ç°ä¼˜ç§€çš„å‹ç¼©æ•ˆæœã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **ä»å¯èƒ½è¢«æ–°å‹å¯¹æŠ—æ”»å‡»ç»•è¿‡**ï¼šä¾èµ–è®­ç»ƒæ•°æ®åˆ†å¸ƒï¼Œé¢å¯¹æœªè§è¿‡çš„æ”»å‡»æ¨¡å¼å¯èƒ½å­˜åœ¨ç›²åŒºã€‚
2. **æ ‡æ³¨åè§é£é™©**ï¼šä½¿ç”¨ LLM-as-a-judge è¿›è¡Œæ•°æ®æ ‡æ³¨ï¼Œå¯èƒ½å¼•å…¥ç¤¾ä¼šåè§æˆ–é€»è¾‘åå·®ã€‚
3. **æ–‡åŒ–/æ³•å¾‹å·®å¼‚å¤„ç†ä¸è¶³**ï¼šé»˜è®¤ taxonomy ä¸ºé€šç”¨è®¾è®¡ï¼Œç‰¹å®šåœ°åŒºéœ€æ‰‹åŠ¨è°ƒä¼˜ç­–ç•¥ã€‚
4. **å¯¹æ¨¡ç³Šæˆ–çŸ›ç›¾æŒ‡ä»¤å¤„ç†èƒ½åŠ›æœ‰é™**ï¼šåŠ¨æ€ç­–ç•¥çš„æœ‰æ•ˆæ€§ä¾èµ–æ¸…æ™°ã€ä¸€è‡´çš„ç”¨æˆ·è¾“å…¥ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å¼•å…¥æŒç»­çº¢é˜Ÿæµ‹è¯•ï¼ˆred-teamingï¼‰æœºåˆ¶ä»¥å¢å¼ºé²æ£’æ€§ã€‚
- å¼€å‘è‡ªåŠ¨åŒ–çš„åè§ç›‘æµ‹ä¸ç¼“è§£æ¨¡å—ã€‚
- æ‰©å±•æ”¯æŒæ›´å¤šå‚ç›´é¢†åŸŸå®šåˆ¶åŒ–ç­–ç•¥æ¨¡æ¿ã€‚
- æ¢ç´¢æ›´é«˜æ•ˆçš„è’¸é¦ä¸é‡åŒ–æ–¹æ¡ˆï¼Œè¿›ä¸€æ­¥é™ä½éƒ¨ç½²æˆæœ¬ã€‚

---

> ğŸ“¢ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> YuFeng-XGuard å°† LLM å®‰å…¨æŠ¤æ ä»â€œé™æ€è¿‡æ»¤å™¨â€å‡çº§ä¸ºâ€œåŠ¨æ€ã€å¯è§£é‡Šã€å¯é…ç½®çš„é£é™©æ„ŸçŸ¥ç³»ç»Ÿâ€ï¼Œåœ¨æ€§èƒ½ã€æ•ˆç‡ã€çµæ´»æ€§ä¸‰è€…ä¹‹é—´å®ç°äº†å“è¶Šå¹³è¡¡ï¼Œå¹¶é€šè¿‡å¼€æºæ¨åŠ¨å®‰å…¨å»ºæ¨¡èŒƒå¼æ¼”è¿›ã€‚

</details>

---

### 14. [Mecellem Models: Turkish Models Trained from Scratch and Continually Pre-trained for the Legal Domain](https://arxiv.org/abs/2601.16018)

**Authors**: \"Ozg\"ur U\u{g}ur, Mahmut G\"oksu, Mahmut \c{C}imen, Musa Y{\i}lmaz, Esra \c{S}avirdi, Alp Talha Demir, Rumeysa G\"ull\"uce, \.Iclal \c{C}etin, \"Omer Can Sa\u{g}ba\c{s}  
**Category**: cs.CL  
**Published**: 2026-01-23  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.16018v1  

#### Abstract
This paper presents Mecellem models, a framework for developing specialized language models for the Turkish legal domain through domain adaptation strategies. We make two contributions: (1)Encoder Model Pre-trained from Scratch: ModernBERT-based bidirectional encoders pre-trained on a Turkish-domina...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMecellem Models: Turkish Models Trained from Scratch and Continually Pre-trained for the Legal Domain

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹åœŸè€³å…¶è¯­æ³•å¾‹é¢†åŸŸç¼ºä¹é«˜è´¨é‡ä¸“ç”¨è¯­è¨€æ¨¡å‹çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€å¥—å®Œæ•´çš„è§£å†³æ–¹æ¡ˆã€‚ç”±äºåœŸè€³å…¶è¯­æ˜¯å½¢æ€ä¸°å¯Œçš„é»ç€è¯­ï¼Œä¸”æ³•å¾‹æ–‡æœ¬å…·æœ‰é«˜åº¦ä¸“ä¸šåŒ–ã€é•¿å¥å¤æ‚ã€æœ¯è¯­å¯†é›†ç­‰ç‰¹ç‚¹ï¼Œé€šç”¨å¤§æ¨¡å‹åœ¨è¯¥é¢†åŸŸçš„è¡¨ç°æ˜¾è‘—ä¸‹é™ã€‚ç°æœ‰æ–¹æ³•å¦‚ç›´æ¥å¾®è°ƒï¼ˆfine-tuningï¼‰éš¾ä»¥å®ç°æ·±åº¦é¢†åŸŸé€‚åº”ï¼Œè€Œä»å¤´è®­ç»ƒåˆæˆæœ¬é«˜æ˜‚ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
è®ºæ–‡æå‡ºäº† **Mecellem** æ¡†æ¶ï¼ŒåŒ…å«ä¸¤ä¸ªäº’è¡¥çš„æ¨¡å‹å¼€å‘è·¯å¾„ï¼š

#### ï¼ˆ1ï¼‰Encoder Model: ä»å¤´é¢„è®­ç»ƒçš„ ModernBERT ç¼–ç å™¨
- **ä»é›¶å¼€å§‹é¢„è®­ç»ƒ**ï¼šåŸºäº ModernBERT æ¶æ„ï¼Œåœ¨ä¸€ä¸ªåŒ…å« **112.7 billion tokens** çš„åœŸè€³å…¶è¯­ä¸»å¯¼è¯­æ–™ä¸Šä»å¤´è®­ç»ƒåŒå‘ç¼–ç å™¨ï¼ˆ155M å’Œ 403M å‚æ•°ï¼‰ã€‚
- **ä¸‹æ¸¸æ„ŸçŸ¥çš„æ£€æŸ¥ç‚¹é€‰æ‹©ç­–ç•¥**ï¼šä¸åŒäºä¼ ç»Ÿä»…ä¾èµ– MLM loss æœ€å°åŒ–çš„åšæ³•ï¼Œä½œè€…åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æŒç»­è¯„ä¼°ä¸‹æ¸¸æ£€ç´¢ä»»åŠ¡çš„è¡¨ç°ï¼Œå‘ç°**æœ€ä¼˜æ£€æŸ¥ç‚¹å¾€å¾€å‡ºç°åœ¨ MLM loss è¾¾åˆ°æœ€å°å€¼ä¹‹å‰**ï¼Œè¿™è¡¨æ˜ä»…ä¼˜åŒ–é¢„è®­ç»ƒç›®æ ‡æ— æ³•ä¿è¯æœ€ä½³åµŒå…¥è´¨é‡ã€‚
- **é«˜æ•ˆçš„åè®­ç»ƒï¼ˆpost-trainingï¼‰ç­–ç•¥**ï¼šé‡‡ç”¨å¤šç§å¯¹æ¯”å­¦ä¹ æŠ€æœ¯ï¼ˆInfoNCEã€Qwen3-style InfoNCEã€GISTEmbedï¼‰è¿›è¡Œåè®­ç»ƒï¼Œå…¶ä¸­ GISTEmbed åˆ©ç”¨ç¼“å­˜çš„ guide model è¿›è¡Œå‡è´Ÿæ ·æœ¬è¿‡æ»¤ï¼Œæ˜¾è‘—æå‡æ€§èƒ½ã€‚

#### ï¼ˆ2ï¼‰Decoder Model: åŸºäº CPT çš„è§£ç å™¨é€‚é…
- **æŒç»­é¢„è®­ç»ƒï¼ˆContinual Pre-training, CPTï¼‰**ï¼šå¯¹ Qwen3-1.7B å’Œ Qwen3-4B è§£ç å™¨æ¨¡å‹è¿›è¡Œ CPTï¼Œä½¿å…¶é€‚åº”åœŸè€³å…¶æ³•å¾‹é¢†åŸŸã€‚
- **å››é˜¶æ®µè¯¾ç¨‹å­¦ä¹ ï¼ˆcurriculum learningï¼‰**ï¼šè®¾è®¡äº†ä¸€ä¸ªæ¸è¿›å¼è®­ç»ƒæµç¨‹ï¼Œä»é€šç”¨æ–‡æœ¬è¿‡æ¸¡åˆ°æ³•å¾‹æœ¯è¯­å†åˆ°é•¿ä¸Šä¸‹æ–‡è§„èŒƒæ€§æ–‡æœ¬ï¼Œæœ‰æ•ˆç¼“è§£ç¾éš¾æ€§é—å¿˜ï¼ˆcatastrophic forgettingï¼‰ã€‚
- **åˆå§‹åŒ–æ¶ˆèç ”ç©¶**ï¼šé€šè¿‡æ¶ˆèå®éªŒç¡®å®šæœ€ä¼˜çš„æ•°æ®æ··åˆæ¯”ä¾‹å’Œè®­ç»ƒé¡ºåºï¼Œç¡®ä¿é¢†åŸŸé€‚åº”ä¸é€šç”¨èƒ½åŠ›çš„å¹³è¡¡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ›´é«˜çš„å‚æ•°æ•ˆç‡**ï¼š155M å‚æ•°çš„ Mursit-Base åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¡¨ç°æ¥è¿‘ç”šè‡³ä¼˜äºæ›´å¤§è§„æ¨¡çš„åŸºçº¿æ¨¡å‹ï¼ˆå¦‚ 307Mâ€“567M å‚æ•°çš„ embeddinggemma-300m å’Œ BAAI/bge-m3ï¼‰ã€‚
- **æ›´ä½çš„è®¡ç®—æˆæœ¬**ï¼šç›¸æ¯”å¤šé˜¶æ®µã€é«˜èµ„æºæ¶ˆè€—çš„è®­ç»ƒæµæ°´çº¿ï¼ˆå¦‚ RetroMAE + å¯¹æ¯”å­¦ä¹  + ç»Ÿä¸€å¾®è°ƒï¼‰ï¼ŒMecellem é‡‡ç”¨å•é˜¶æ®µé¢„è®­ç»ƒ + é«˜æ•ˆåè®­ç»ƒï¼Œæ›´å…·æˆæœ¬æ•ˆç›Šã€‚
- **æ›´å¼ºçš„é¢†åŸŸé€‚åº”èƒ½åŠ›**ï¼šCPT æ–¹æ³•ä½¿æ¨¡å‹åœ¨åœŸè€³å…¶æ³•å¾‹æ–‡æœ¬ä¸Šçš„å›°æƒ‘åº¦ï¼ˆperplexityï¼‰é™ä½äº† **36.2%**ï¼Œæ˜¾è‘—ä¼˜äºç®€å•å¾®è°ƒã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **é¢„è®­ç»ƒè¯­æ–™**ï¼ˆå…± 112.7B tokensï¼‰ï¼š
  - æ³•å¾‹å­é›†ï¼šYargÄ±tayï¼ˆæœ€é«˜æ³•é™¢åˆ¤å†³ï¼‰ã€DanÄ±ÅŸtayï¼ˆè¡Œæ”¿æ³•é™¢åˆ¤å†³ï¼‰ã€YOKTEZï¼ˆå­¦æœ¯è®ºæ–‡ï¼‰
  - é€šç”¨å­é›†ï¼šFineWeb2ã€CulturaX
- **åè®­ç»ƒæ•°æ®**ï¼š
  - MS MARCO-TRï¼šåœŸè€³å…¶è¯­ç‰ˆ MS MARCO æ£€ç´¢æ•°æ®é›†ï¼ˆ920,106 ä¸ªä¸‰å…ƒç»„ï¼‰
- **è¯„ä¼°åŸºå‡†**ï¼š
  - **MTEB-Turkish**ï¼šæ‰©å±•è‡ª MTEBï¼ŒåŒ…å« 17 é¡¹ä»»åŠ¡ï¼Œæ¶µç›–åˆ†ç±»ã€æ£€ç´¢ã€èšç±»ã€å¥å­å¯¹åˆ†ç±»ã€è¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œå¹¶æ–°å¢ä¸‰ä¸ªæ³•å¾‹æ£€ç´¢ä»»åŠ¡ï¼ˆåˆåŒã€æ³•è§„ã€åˆ¤ä¾‹æ³•ï¼‰ã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼šBarcelona Supercomputing Center çš„ MareNostrum 5 è¶…ç®—ï¼ˆH100 GPUï¼‰
- **è®­ç»ƒæ¡†æ¶**ï¼šMosaicML Composerï¼ˆç¼–ç å™¨ï¼‰ã€NVIDIA NeMoï¼ˆè§£ç å™¨ï¼‰
- **ç²¾åº¦é…ç½®**ï¼šBF16 æ··åˆç²¾åº¦
- **åºåˆ—é•¿åº¦**ï¼šç¼–ç å™¨æœ€å¤§æ”¯æŒ 8,192 tokensï¼›è§£ç å™¨æ”¯æŒ 40,960 tokens

### è¯„ä¼°æŒ‡æ ‡
- **MTEB Score**ï¼šäº”ç±»ä»»åŠ¡ï¼ˆåˆ†ç±»ã€èšç±»ã€å¥å­å¯¹åˆ†ç±»ã€æ£€ç´¢ã€STSï¼‰çš„å¹³å‡å¾—åˆ†
- **Legal Score**ï¼šä¸‰ä¸ªæ³•å¾‹æ£€ç´¢ä»»åŠ¡ï¼ˆContracts, Regulation, Caselawï¼‰çš„åŠ æƒå¹³å‡ nDCG@10
- **Perplexity (PPL)**ï¼šç”¨äºè¯„ä¼°è§£ç å™¨åœ¨æ³•å¾‹æ–‡æœ¬ä¸Šçš„è¯­è¨€å»ºæ¨¡èƒ½åŠ›
- **Production Efficiency**ï¼šç»¼åˆè€ƒè™‘æ€§èƒ½ã€å‚æ•°é‡ã€ååé‡ç­‰çš„éƒ¨ç½²æ•ˆç‡è¯„åˆ†

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Embedding Models**ï¼š`embeddinggemma-300m`, `BAAI/bge-m3`, `newmindai/bge-m3-stsb`
- **MLM Models**ï¼š`ModernBERT-base/large`, `turkish-base-bert-*`, `TabiBERT`, `mmBERT-base`
- **Decoder-to-Encoder Converted Models**ï¼š`Mursit-Embed-Qwen3-1.7B/4B-TR`

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æ¨¡å‹ | MTEB Score | Legal Score | å‚æ•°é‡ | å¤‡æ³¨ |
|------|------------|-----------|--------|------|
| **Mursit-Base-TR-Retrieval** | **55.86** | **47.52** | 155M | æ’åç¬¬2 |
| **Mursit-Large-TR-Retrieval** | **56.43** | 46.42 | 403M | æ’åç¬¬1 |
| embeddinggemma-300m | 65.42 | 50.63 | 307M | SOTA |
| BAAI/bge-m3 | 62.87 | 51.16 | 567M | SOTA |

- å°æ¨¡å‹ï¼ˆ155Mï¼‰æ€§èƒ½åª²ç¾å¤§æ¨¡å‹ï¼ˆ307Mâ€“567Mï¼‰ï¼Œä½“ç°**æé«˜çš„å‚æ•°æ•ˆç‡**
- åœ¨ Turkish retrieval leaderboard ä¸Šæ’åå‰3

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ç›¸æ¯”é€šç”¨ MLM æ¨¡å‹**ï¼š
  - Mursit-Base çš„ Legal Score è¾¾åˆ° 47.52ï¼Œè¿œè¶… `ModernBERT-base`ï¼ˆ2.99ï¼‰å’Œ `mmBERT-base`ï¼ˆ12.15ï¼‰
- **ç›¸æ¯”è§£ç å™¨è½¬ç¼–ç å™¨æ¨¡å‹**ï¼š
  - `Mursit-Embed-Qwen3-4B-TR`ï¼ˆ4B å‚æ•°ï¼‰Legal Score ä»…ä¸º 37.00ï¼Œæ˜¾è‘—ä½äº 155M çš„ Mursit-Baseï¼ˆ47.52ï¼‰ï¼Œè¯´æ˜**æ¶æ„é€‰æ‹©æ¯”å‚æ•°è§„æ¨¡æ›´é‡è¦**
- **ç”Ÿäº§æ•ˆç‡ï¼ˆProduction Efficiencyï¼‰**ï¼š
  - Mursit-Base è¾¾åˆ° **92.36%**ï¼Œä»…æ¬¡äº embeddinggemma-300mï¼ˆ100.00%ï¼‰å’Œ bge-m3ï¼ˆ99.54%ï¼‰ï¼Œåœ¨ä½èµ„æºåœºæ™¯ä¸‹æå…·ä¼˜åŠ¿

### æ¶ˆèå®éªŒç»“æœ
#### ï¼ˆ1ï¼‰æ£€æŸ¥ç‚¹é€‰æ‹©ç­–ç•¥
- å‘ç° MLM loss æœ€ä½æ—¶å¹¶éä¸‹æ¸¸ä»»åŠ¡æœ€ä¼˜ï¼Œ**ä¸­é—´æ£€æŸ¥ç‚¹æ€§èƒ½æ›´ä¼˜**
- v6 ç‰ˆæœ¬å°½ç®¡ MLM loss æ›´ä½ï¼Œä½† Legal Score ä¸‹é™ 11.9%ï¼Œè¡¨æ˜è¿‡åº¦è®­ç»ƒå¯¼è‡´è¿‡æ‹Ÿåˆ

#### ï¼ˆ2ï¼‰åºåˆ—é•¿åº¦å½±å“
- ä½¿ç”¨ `seq_len=256`ï¼ˆåŒ¹é… MS MARCO åˆ†å¸ƒï¼‰ä¼šå¯¼è‡´æ³•å¾‹ä»»åŠ¡æ€§èƒ½ä¸‹é™ï¼š
  - Regulation retrieval: -23.6%
  - Case law retrieval: -17.8%
- ç»“è®ºï¼šåº”æ ¹æ®**ç›®æ ‡ä»»åŠ¡ç‰¹æ€§**è€Œéè®­ç»ƒæ•°æ®åˆ†å¸ƒæ¥è®¾å®šåºåˆ—é•¿åº¦

#### ï¼ˆ3ï¼‰å¯¹æ¯”å­¦ä¹ æ–¹æ³•æ¯”è¾ƒ
| æ–¹æ³• | MTEB Score | Legal Score |
|------|------------|-----------|
| InfoNCEï¼ˆbaselineï¼‰ | 53.23 | 39.95 |
| Qwen3-InfoNCE | 56.70 | 42.60 |
| **GISTEmbed (BGE-M3 guide)** | **55.67** | **46.36** |

- GISTEmbed åœ¨ Legal Score ä¸Šæå‡ **15.9%**ï¼Œè¯æ˜**å‡è´Ÿæ ·æœ¬è¿‡æ»¤å¯¹æ³•å¾‹æ£€ç´¢è‡³å…³é‡è¦**

#### ï¼ˆ4ï¼‰CPT å›°æƒ‘åº¦é™ä½æ•ˆæœ
- Qwen3-4B ç» CPT åæ•´ä½“å›°æƒ‘åº¦ä¸‹é™ **36.2%**
- Qwen3-1.7B ç»å››é˜¶æ®µ CPT åä¸‹é™ **43.1%**ï¼Œæ˜¾ç¤ºè¯¾ç¨‹å­¦ä¹ çš„æœ‰æ•ˆæ€§

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **MLM loss ä¸æ˜¯ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½çš„è‰¯å¥½ä»£ç†æŒ‡æ ‡**ï¼Œå°¤å…¶å¯¹äºå½¢æ€ä¸°å¯Œè¯­è¨€ï¼ˆå¦‚åœŸè€³å…¶è¯­ï¼‰ã€‚åº”ç»“åˆä¸‹æ¸¸ä»»åŠ¡è¯„ä¼°è¿›è¡Œæ£€æŸ¥ç‚¹é€‰æ‹©ã€‚
2. **é¢†åŸŸç‰¹å®šçš„ä»å¤´é¢„è®­ç»ƒ + å¯¹æ¯”åè®­ç»ƒ** æ˜¯æ„å»ºé«˜æ•ˆæ³•å¾‹åµŒå…¥æ¨¡å‹çš„æœ‰æ•ˆèŒƒå¼ï¼Œä¼˜äºç®€å•çš„å¾®è°ƒæˆ–è§£ç å™¨è½¬ç¼–ç å™¨æ–¹æ¡ˆã€‚
3. **å‚æ•°æ•ˆç‡ä¼˜äºç»å¯¹è§„æ¨¡**ï¼š155M çš„ Mursit-Base åœ¨ Legal Score ä¸Šè¶…è¶Šè®¸å¤šæ›´å¤§æ¨¡å‹ï¼Œé€‚åˆèµ„æºå—é™éƒ¨ç½²ã€‚
4. **è¯¾ç¨‹å­¦ä¹ èƒ½æœ‰æ•ˆç¼“è§£ç¾éš¾æ€§é—å¿˜**ï¼Œç‰¹åˆ«æ˜¯åœ¨å°æ¨¡å‹ä¸Šï¼Œé€æ­¥å¼•å…¥é¢†åŸŸçŸ¥è¯†å¯ç¨³å®šæå‡æ€§èƒ½ã€‚
5. **é•¿ä¸Šä¸‹æ–‡å»ºæ¨¡è‡³å…³é‡è¦**ï¼šç¼©çŸ­åºåˆ—é•¿åº¦è™½èŠ‚çœèµ„æºï¼Œä½†åœ¨æ³•å¾‹æ£€ç´¢ä»»åŠ¡ä¸­é€ æˆæ˜¾è‘—æ€§èƒ½é€€åŒ–ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **è§£ç å™¨è½¬ç¼–ç å™¨æ€§èƒ½ä¸è¶³**ï¼šç”±äºç¼ºä¹å¤§è§„æ¨¡åˆæˆæ•°æ®å’Œå¤šé˜¶æ®µè®­ç»ƒè®¾æ–½ï¼Œè½¬æ¢åçš„ Qwen3 æ¨¡å‹æ€§èƒ½æœ‰é™ã€‚
- **æœªæ¢ç´¢æ›´å…ˆè¿›çš„æ¶æ„æ”¹è¿›**ï¼šå¦‚ MoEã€ç¨€ç–æ³¨æ„åŠ›ç­‰æœªè¢«çº³å…¥å½“å‰æ¡†æ¶ã€‚
- **è¯„ä¼°ä»é™äºè‹±æ–‡ä¸»å¯¼çš„åŸºå‡†è¿ç§»ç‰ˆæœ¬**ï¼Œæœªæ¥éœ€æ„å»ºæ›´å…¨é¢çš„åœŸè€³å…¶æ³•å¾‹ NLP åŸºå‡†ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´å…ˆè¿›çš„ **decoder-to-encoder conversion æŠ€æœ¯**ï¼Œå¦‚å¤§è§„æ¨¡åˆæˆæŸ¥è¯¢-æ–‡æ¡£å¯¹ç”Ÿæˆã€‚
- å¼€å‘é¢å‘åœŸè€³å…¶æ³•å¾‹é¢†åŸŸçš„ **Retrieval-Augmented Generation (RAG) åº”ç”¨**ã€‚
- æ‰©å±• MTEB-Turkish åŸºå‡†ï¼Œå¢åŠ æ›´å¤šçœŸå®ä¸–ç•Œæ³•å¾‹é—®ç­”å’Œæ¨ç†ä»»åŠ¡ã€‚
- ç ”ç©¶å¦‚ä½•å°† Morphology-aware Tokenization æ›´æ·±åº¦é›†æˆåˆ°æ¨¡å‹æ¶æ„ä¸­ã€‚

---

> âœ… **æ‰€æœ‰æ¨¡å‹å·²å¼€æºå‘å¸ƒäº Hugging Face**:  
> ğŸ”— https://huggingface.co/collections/newmindai/mecellem-models

</details>

---

### 15. [Communication-efficient Federated Graph Classification via Generative Diffusion Modeling](https://arxiv.org/abs/2601.15722)

**Authors**: Xiuling Wang, Xin Huang, Haibo Hu, Jianliang Xu  
**Category**: cs.LG  
**Published**: 2026-01-23  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.15722v1  

#### Abstract
Graph Neural Networks (GNNs) unlock new ways of learning from graph-structured data, proving highly effective in capturing complex relationships and patterns. Federated GNNs (FGNNs) have emerged as a prominent distributed learning paradigm for training GNNs over decentralized data. However, FGNNs fa...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šCommunication-efficient Federated Graph Classification via Generative Diffusion Modeling

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹ **Federated Graph Neural Networks (FGNNs)** åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´çš„ä¸¤å¤§æ ¸å¿ƒæŒ‘æˆ˜ï¼š
- **é«˜é€šä¿¡å¼€é”€**ï¼šä¼ ç»Ÿ FGNN éœ€è¦å¤šè½® server-client å‚æ•°äº¤æ¢ï¼Œå¯¼è‡´å¤§é‡é€šä¿¡æˆæœ¬ï¼Œå°¤å…¶åœ¨å¸¦å®½å—é™æˆ–å®¢æˆ·ç«¯ç¦»çº¿åœºæ™¯ä¸‹æ•ˆç‡ä½ä¸‹ã€‚
- **éç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆnon-IIDï¼‰æ•°æ®**ï¼šä¸åŒå®¢æˆ·ç«¯çš„æ•°æ®åœ¨å›¾ç»“æ„å’ŒèŠ‚ç‚¹ç‰¹å¾ä¸Šå­˜åœ¨æ˜¾è‘—å¼‚è´¨æ€§ï¼Œå¯¼è‡´æœ¬åœ°æ¨¡å‹æ›´æ–°æ¼‚ç§»ï¼Œå½±å“å…¨å±€æ¨¡å‹æ”¶æ•›ä¸æ€§èƒ½ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šCeFGC å’Œ CeFGC*
ä½œè€…æå‡ºäº†ä¸€ç§åä¸º **CeFGC**ï¼ˆCommunication-efficient Federated Graph Classificationï¼‰çš„æ–°å‹ FGNN èŒƒå¼ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨ **ç”Ÿæˆæ‰©æ•£æ¨¡å‹ï¼ˆGenerative Diffusion Models, GGDMsï¼‰** æ¥æœ€å°åŒ–ç›´æ¥é€šä¿¡ï¼Œå¹¶é€šè¿‡åˆæˆæ•°æ®å¢å¼ºæœ¬åœ°è®­ç»ƒã€‚

#### æ–¹æ³•æµç¨‹ï¼ˆå››æ­¥ï¼‰ï¼š
1. **æœ¬åœ°ç”Ÿæˆæ¨¡å‹è®­ç»ƒ**ï¼šæ¯ä¸ªå®¢æˆ·ç«¯åœ¨å…¶æœ¬åœ°å›¾æ•°æ®ä¸Šè®­ç»ƒä¸€ä¸ª **Graph Generative Diffusion Model (GGDM)**ï¼Œå­¦ä¹ æœ¬åœ°å›¾åˆ†å¸ƒã€‚
2. **ç”Ÿæˆæ¨¡å‹ä¼ è¾“**ï¼šå®¢æˆ·ç«¯å°†è®­ç»ƒå¥½çš„ GGDM åŠ å¯†åä¸Šä¼ è‡³æœåŠ¡å™¨ï¼›æœåŠ¡å™¨éšæœºæ‰“ä¹±å¹¶é‡æ–°åˆ†å‘ç»™æ‰€æœ‰å®¢æˆ·ç«¯ï¼ˆä¸è¿”å›è‡ªèº«æ¨¡å‹ï¼‰ã€‚
3. **æœ¬åœ° GNN è®­ç»ƒ**ï¼šå„å®¢æˆ·ç«¯ä½¿ç”¨æ¥æ”¶åˆ°çš„å…¶ä»–å®¢æˆ·ç«¯çš„ GGDM ç”Ÿæˆ **åˆæˆå›¾ï¼ˆsynthetic graphsï¼‰**ï¼Œå¹¶ä¸æœ¬åœ°çœŸå®å›¾ä¸€èµ·è®­ç»ƒæœ¬åœ° GNN æ¨¡å‹ã€‚
4. **å…¨å±€æ¨¡å‹èšåˆ**ï¼šå®¢æˆ·ç«¯ä¸Šä¼ æœ¬åœ° GNN æƒé‡ï¼ŒæœåŠ¡å™¨ä½¿ç”¨ **FedAvg** è¿›è¡Œä¸€æ¬¡èšåˆå¾—åˆ°å…¨å±€ GNN æ¨¡å‹ã€‚

æ•´ä¸ªè¿‡ç¨‹ä»…éœ€ **ä¸‰è½®é€šä¿¡**ï¼ˆä¸Šä¼  GGDM â†’ ä¸‹å‘ GGDM + åˆå§‹åŒ– GNN â†’ ä¸Šä¼  GNN æƒé‡ï¼‰ï¼Œæå¤§é™ä½é€šä¿¡è´Ÿæ‹…ã€‚

### åˆ›æ–°ç‚¹ä¸ä¼˜åŠ¿
| åˆ›æ–°ç‚¹ | è¯´æ˜ |
|--------|------|
| **ä»…ä¸‰è½®é€šä¿¡** | ç›¸æ¯”ä¼ ç»Ÿ FGNN çš„æ•°åç”šè‡³ä¸Šç™¾è½®è¿­ä»£ï¼ŒCeFGC å°†é€šä¿¡è½®æ•°å‹ç¼©åˆ°å¸¸æ•°çº§ï¼ˆ3è½®ï¼‰ï¼Œç†è®º I/O å¤æ‚åº¦ä» $O(D(GNN) \cdot N \cdot S)$ é™è‡³ $O(D(DM)\cdot N^2 + D(GNN)\cdot N)$ã€‚ |
| **å¼•å…¥æ ‡ç­¾é€šé“ï¼ˆLabel Channelï¼‰** | ä¸ºè§£å†³æ¯ç±»éœ€è®­ç»ƒä¸€ä¸ª GGDM å¯¼è‡´é€šä¿¡é‡å¤§çš„é—®é¢˜ï¼Œæå‡º **CeFGC***ï¼Œåœ¨æ‰©æ•£æ¨¡å‹ä¸­åŠ å…¥ç±»åˆ«åµŒå…¥å±‚ï¼Œä½¿å•ä¸ªæ¨¡å‹å¯ç”Ÿæˆå¤šç±»å›¾ï¼Œè¿›ä¸€æ­¥å‡å°‘é€šä¿¡ä½“ç§¯ã€‚ |
| **éšç§ä¿æŠ¤æœºåˆ¶** | é‡‡ç”¨åŠ å¯†ä¸Šä¼ ã€éšæœºæ‰“ä¹±ã€èšåˆç›¸ä¼¼æ¨¡å‹ç­‰ç­–ç•¥ï¼Œé˜²æ­¢æœåŠ¡å™¨æˆ–æ¶æ„å®¢æˆ·ç«¯æ¨æ–­åŸå§‹æ•°æ®ï¼Œç¼“è§£æ¨ç†æ”»å‡»å’Œä¸­æ¯’æ”»å‡»é£é™©ã€‚ |
| **æå‡ non-IID åœºæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›** | åˆæˆå›¾ä¸°å¯Œäº†æœ¬åœ°è®­ç»ƒé›†å¤šæ ·æ€§ï¼Œå¯¹é½å±€éƒ¨ä¸å…¨å±€ç›®æ ‡ï¼Œæ˜¾è‘—æ”¹å–„ non-IID æ•°æ®ä¸‹çš„æ¨¡å‹æ€§èƒ½ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å…±ä½¿ç”¨ **5 ä¸ªçœŸå®ä¸–ç•Œå›¾åˆ†ç±»åŸºå‡†æ•°æ®é›†**ï¼Œæ¶µç›–ä¸‰ä¸ªé¢†åŸŸï¼š
- **åˆ†å­ï¼ˆMoleculesï¼‰**ï¼š`MUTAG`
- **è›‹ç™½è´¨ï¼ˆProteinsï¼‰**ï¼š`ENZYMES`, `PROTEINS`
- **ç¤¾äº¤ç½‘ç»œï¼ˆSocial Networksï¼‰**ï¼š`IMDB-BINARY` (`IMDB-B`), `IMDB-MULTI` (`IMDB-M`)

æ‰€æœ‰æ•°æ®å‡æ¥è‡ª `torch_geometric` åº“ï¼Œéƒ¨åˆ†æ— èŠ‚ç‚¹ç‰¹å¾çš„æ•°æ®é‡‡ç”¨ one-hot degree ç‰¹å¾ã€‚

### å®éªŒè®¾ç½®
è®¾è®¡äº†ä¸‰ç§ non-IID åˆ†å¸ƒåœºæ™¯ä»¥éªŒè¯é²æ£’æ€§ï¼š
1. **Single-dataset setting**ï¼šå•ä¸€æ•°æ®é›†å†…çš„å›¾éšæœºåˆ†é…ç»™å¤šä¸ªå®¢æˆ·ç«¯ã€‚
2. **Across-dataset setting**ï¼šåŒä¸€é¢†åŸŸå†…å¤šä¸ªæ•°æ®é›†å‚ä¸è®­ç»ƒï¼ˆå¦‚ `IMDB-B` å’Œ `IMDB-M`ï¼‰ã€‚
3. **Across-domain setting**ï¼šè·¨é¢†åŸŸæ··åˆæ•°æ®é›†è®­ç»ƒï¼ˆå¦‚ `MUTAG`, `PROTEINS`, `IMDB-B/M`ï¼‰ã€‚

å®¢æˆ·ç«¯æ•°é‡è®¾ç½®çµæ´»ï¼ˆ3~100ï¼‰ï¼Œæ•°æ®åˆ’åˆ†æ¯”ä¾‹ä¸º train/val/test = 0.7/0.1/0.2ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **ä¸»æŒ‡æ ‡**ï¼šå…¨å±€æµ‹è¯•é›†ä¸Šçš„ **AUC** å’Œ **Accuracy**
- **æ•ˆç‡æŒ‡æ ‡**ï¼š
  - é€šä¿¡è½®æ•°ï¼ˆCommunication Roundsï¼‰
  - é€šä¿¡ä½“ç§¯ï¼ˆCommunication Volume, Mbitï¼‰
  - æ€»åœ¨çº¿è¿è¡Œæ—¶é—´ï¼ˆTotal Online Training Timeï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
åˆ†ä¸ºä¸¤ç±»ï¼š
1. **SOTA FL æ–¹æ³•**ï¼š
   - `FedAvg`, `FedProx`, `FedDC`, `MOON`
2. **SOTA FGNN æ–¹æ³•**ï¼š
   - `GCFL+`, `FedStar`
3. **One-shot å¯¹æ¯”æ–¹æ³•**ï¼š
   - è‡ªå®ç°çš„ä¸€æ¬¡æ€§è”é‚¦å­¦ä¹ æ–¹æ³•ï¼ˆæœåŠ¡å™¨ç”Ÿæˆåˆæˆå›¾åç‹¬ç«‹è®­ç»ƒï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆAUCï¼‰

| æ–¹æ³• | MUTAG | ENZYMES | PROTEINS | IMDB-B | IMDB-M |
|------|-------|---------|----------|--------|--------|
| **CeFGC** | **0.91** | **0.68** | **0.87** | **0.88** | **0.80** |
| **CeFGC\*** | **0.90** | **0.69** | **0.87** | **0.92** | **0.79** |
| æœ€ä½³åŸºçº¿ï¼ˆå¦‚ GCFL+/FedStarï¼‰ | ~0.78 | ~0.63 | ~0.75 | ~0.80 | ~0.76 |

> âœ… **ç»“è®º**ï¼šCeFGC å’Œ CeFGC* åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šå‡æ˜¾è‘—ä¼˜äºåŸºçº¿ï¼Œæœ€é«˜æå‡è¾¾ **31%**ï¼ˆMUTAG ä¸Šçš„ AUC æå‡ï¼‰ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

#### ï¼ˆ1ï¼‰é€šä¿¡æ•ˆç‡å¯¹æ¯”ï¼ˆTable 3ï¼‰
| æ–¹æ³• | å¹³å‡é€šä¿¡è½®æ•° | é€šä¿¡ä½“ç§¯ï¼ˆMix è®¾ç½®ï¼‰ |
|------|----------------|------------------------|
| FedAvg/FedProx/GCFL+ ç­‰ | 192â€“712 è½® | 598â€“1587 Mbit |
| **CeFGC** | **3 è½®** | **537.73 Mbit** |
| **CeFGC\*** | **3 è½®** | **191.29 Mbit** |

> ğŸ”½ **é€šä¿¡ä½“ç§¯å‡å°‘ 3â€“102 å€**

#### ï¼ˆ2ï¼‰è¿è¡Œæ—¶é—´å¯¹æ¯”ï¼ˆTable 4ï¼‰
åœ¨ WANï¼ˆ1Mb/sï¼‰ç¯å¢ƒä¸‹ï¼š
- CeFGC* ç›¸æ¯” FedStar å‡å°‘ **98.0%** çš„æ€»è¿è¡Œæ—¶é—´ã€‚
- å³ä½¿åœ¨ LAN ç¯å¢ƒä¸‹ä¹ŸèŠ‚çœè¶…è¿‡ **75%** æ—¶é—´ã€‚

#### ï¼ˆ3ï¼‰è·¨åœºæ™¯è¡¨ç°
- åœ¨ **Across-dataset** å’Œ **Across-domain** è®¾ç½®ä¸‹ï¼ŒCeFGC ä»ä¿æŒé«˜æ€§èƒ½ï¼Œä¸”éƒ¨åˆ†æ•°æ®é›†ï¼ˆå¦‚ ENZYMESï¼‰æ€§èƒ½åè€Œæå‡ï¼Œè¡¨æ˜è·¨æ•°æ®åä½œå…·æœ‰ååŒå¢ç›Šæ•ˆåº”ã€‚
- ä¾‹å¦‚ï¼Œåœ¨è·¨åŸŸè®¾ç½®ä¸­ï¼ŒENZYMES çš„ AUC æå‡ **15.9%**ã€‚

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰å®¢æˆ·ç«¯æ•°é‡å½±å“ï¼ˆFigure 3aï¼‰
- å®¢æˆ·ç«¯æ•°ä» 12 æ‰©å±•åˆ° 100ï¼ŒCeFGC/AUC æ³¢åŠ¨å°äº 0.04ï¼Œè¡¨ç°å‡ºè‰¯å¥½å¯æ‰©å±•æ€§ã€‚

#### ï¼ˆ2ï¼‰åˆæˆå›¾æ¯”ä¾‹å½±å“ï¼ˆFigure 3bï¼‰
- åˆæˆå›¾ä¸æœ¬åœ°å›¾çš„æ¯”ä¾‹ï¼ˆ$r = 1/8$ åˆ° $8$ï¼‰å¯¹æœ€ç»ˆæ€§èƒ½å½±å“ä¸å¤§ï¼Œè¯´æ˜æ¨¡å‹å¯¹ç”Ÿæˆæ•°æ®è´¨é‡é²æ£’ã€‚

#### ï¼ˆ3ï¼‰ç”Ÿæˆæ¨¡å‹ç±»å‹å¯¹æ¯”ï¼ˆFigure 3cï¼‰
- æ›¿æ¢ä¸º GAN-based ç”Ÿæˆå™¨ï¼ˆGraphGAN, CONDGENï¼‰åæ€§èƒ½ä¸‹é™ã€‚
- åŸå› ï¼šGAN å­˜åœ¨æ¨¡å¼å´©æºƒï¼ˆmode collapseï¼‰å’Œè®­ç»ƒä¸ç¨³å®šé—®é¢˜ï¼Œè€Œæ‰©æ•£æ¨¡å‹æ›´ç¨³å®šä¸”ç”Ÿæˆè´¨é‡æ›´é«˜ã€‚

#### ï¼ˆ4ï¼‰èŠ‚ç‚¹ç‰¹å¾ç”Ÿæˆçš„å½±å“
- ä½¿ç”¨åŒæ—¶ç”ŸæˆèŠ‚ç‚¹ç‰¹å¾å’Œå›¾ç»“æ„çš„ GGDMï¼ˆå¦‚ GDSSï¼‰ vs. ä»…ç”Ÿæˆç»“æ„ï¼ˆEDP-GNNï¼‰ï¼š
  - AUC å·®å¼‚ < 0.02ï¼Œè¯´æ˜å½“å‰ä»»åŠ¡ä¸­èŠ‚ç‚¹ç‰¹å¾ç”Ÿæˆå¯¹æ€§èƒ½å½±å“æœ‰é™ã€‚

#### ï¼ˆ5ï¼‰éšç§å¢å¼ºæœºåˆ¶ï¼ˆTable 5ï¼‰
- å¼•å…¥èšåˆç›¸ä¼¼ GGDM çš„éšç§å¢å¼ºç‰ˆæœ¬ï¼ˆCeFGC+, CeFGC*+ï¼‰åï¼Œæ€§èƒ½åŸºæœ¬ä¸å˜ï¼Œè¯æ˜è¯¥æœºåˆ¶å¯åœ¨ä¸ç‰ºç‰²ç²¾åº¦çš„å‰æä¸‹æå‡å®‰å…¨æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **ä»…éœ€ä¸‰è½®é€šä¿¡å³å¯å®ç°é«˜æ•ˆè”é‚¦å›¾åˆ†ç±»**ï¼šCeFGC æˆåŠŸå°†é€šä¿¡è½®æ•°ä»çº¿æ€§å¢é•¿å‹ç¼©ä¸ºå¸¸æ•°ï¼Œè§£å†³äº†ä¼ ç»Ÿ FGNN çš„é€šä¿¡ç“¶é¢ˆã€‚
2. âœ… **ç”Ÿæˆæ‰©æ•£æ¨¡å‹èƒ½æœ‰æ•ˆç¼“è§£ non-IID é—®é¢˜**ï¼šé€šè¿‡å…±äº« GGDM å¹¶ç”Ÿæˆå¤šæ ·åŒ–åˆæˆå›¾ï¼Œå¢å¼ºäº†æœ¬åœ°æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œæ˜¾è‘—æå‡ non-IID åœºæ™¯ä¸‹çš„åˆ†ç±»æ€§èƒ½ã€‚
3. âœ… **æ ‡ç­¾é€šé“è®¾è®¡æœ‰æ•ˆé™ä½é€šä¿¡å¼€é”€**ï¼šCeFGC* ç”¨å•ä¸ªæ¨¡å‹æ›¿ä»£å¤šä¸ªç±»åˆ«ä¸“ç”¨æ¨¡å‹ï¼Œå¤§å¹…å‡å°‘ä¼ è¾“æ•°æ®é‡ã€‚
4. âœ… **éšç§é£é™©å¯æ§**ï¼šç»“åˆåŠ å¯†ã€æ‰“ä¹±ã€èšåˆç­‰æ‰‹æ®µï¼Œå¯åœ¨è¯šå®ä½†å¥½å¥‡ï¼ˆhonest-but-curiousï¼‰å¨èƒæ¨¡å‹ä¸‹æä¾›è¾ƒå¼ºéšç§ä¿éšœã€‚
5. âœ… **æ–¹æ³•å…·å¤‡è‰¯å¥½çš„å¯æ‰©å±•æ€§å’Œç¨³å®šæ€§**ï¼šåœ¨ä¸åŒå®¢æˆ·ç«¯è§„æ¨¡ã€æ•°æ®åˆ†å¸ƒã€ç”Ÿæˆæ¯”ä¾‹ä¸‹å‡è¡¨ç°ç¨³å¥ã€‚

### å±€é™æ€§
1. â— **ä¾èµ–é«˜è´¨é‡ç”Ÿæˆæ¨¡å‹**ï¼šè‹¥ GGDM æ— æ³•å‡†ç¡®æ•æ‰æœ¬åœ°å›¾åˆ†å¸ƒï¼Œåˆ™ç”Ÿæˆçš„åˆæˆå›¾å¯èƒ½è¯¯å¯¼æœ¬åœ°è®­ç»ƒã€‚
2. â— **ä¸æ”¯æŒèŠ‚ç‚¹åˆ†ç±»ä»»åŠ¡**ï¼šå½“å‰æ‰©æ•£æ¨¡å‹éš¾ä»¥ç”Ÿæˆå¸¦æ ‡ç­¾çš„èŠ‚ç‚¹ï¼Œå› æ­¤æ— æ³•ç”¨äº node classificationã€‚
3. â— **åˆå§‹ GGDM è®­ç»ƒè€—æ—¶è¾ƒé•¿**ï¼šè™½ç„¶æ˜¯ä¸€æ¬¡æ€§ç¦»çº¿è¿‡ç¨‹ï¼Œä½†åœ¨å¤§è§„æ¨¡å›¾ä¸Šè®­ç»ƒ GGDM å¯èƒ½è€—æ—¶è¾ƒé«˜ï¼ˆå¦‚ IMDB-M è¾¾ 4049 ç§’ï¼‰ã€‚
4. â— **å‡è®¾å®¢æˆ·ç«¯é—´å¯äº’ä¿¡ç”Ÿæˆæ¨¡å‹**ï¼šå°½ç®¡æœ‰åŠ å¯†æœºåˆ¶ï¼Œä½†ä»å‡è®¾å®¢æˆ·ç«¯ä¸ä¼šæ¶æ„æ„é€ â€œæœ‰æ¯’â€ç”Ÿæˆæ¨¡å‹è¿›è¡Œæ”»å‡»ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´é«˜æ•ˆçš„å›¾æ‰©æ•£æ¨¡å‹ï¼ˆå¦‚ GDSSã€Digressï¼‰ä»¥åŠ é€Ÿæœ¬åœ°è®­ç»ƒã€‚
- ç ”ç©¶å¦‚ä½•ç”Ÿæˆå¸¦æ ‡ç­¾çš„å›¾ç»“æ„ï¼Œæ‹“å±•è‡³ node classification å’Œ link prediction ç­‰ä»»åŠ¡ã€‚
- è®¾è®¡æŠ—ä¸­æ¯’æ”»å‡»çš„é²æ£’èšåˆæœºåˆ¶ï¼Œé˜²èŒƒæ¶æ„å®¢æˆ·ç«¯ä¸Šä¼ æœ‰å®³ GGDMã€‚
- æ¢ç´¢åŠ¨æ€è”é‚¦ç¯å¢ƒä¸‹çš„æ¨¡å‹å¤ç”¨æœºåˆ¶ï¼Œæ”¯æŒæ–°å®¢æˆ·ç«¯å¿«é€Ÿæ¥å…¥ã€‚

--- 

> ğŸ“Œ **æ€»ä½“è¯„ä»·**ï¼š  
> CeFGC æ˜¯é¦–ä¸ªå°† **ç”Ÿæˆæ‰©æ•£æ¨¡å‹** å¼•å…¥ **Federated Graph Learning** çš„å·¥ä½œï¼Œå¼€åˆ›æ€§åœ°å®ç°äº†â€œä½é€šä¿¡ + é«˜æ€§èƒ½â€çš„è”é‚¦å›¾åˆ†ç±»èŒƒå¼ã€‚å…¶å®éªŒå……åˆ†ã€åˆ†ææ·±å…¥ï¼Œåœ¨ non-IID åœºæ™¯ä¸‹å±•ç°å‡ºå“è¶Šçš„æ€§èƒ½ä¸æ•ˆç‡ï¼Œä¸ºæœªæ¥é«˜æ•ˆã€å®‰å…¨çš„åˆ†å¸ƒå¼å›¾å­¦ä¹ æä¾›äº†é‡è¦æ€è·¯ã€‚

</details>

---

### 16. [Next Generation Active Learning: Mixture of LLMs in the Loop](https://arxiv.org/abs/2601.15773)

**Authors**: Yuanyuan Qi, Xiaohao Yang, Jueqing Lu, Guoxiang Guo, Joanne Enticott, Gang Liu, Lan Du  
**Category**: cs.LG  
**Published**: 2026-01-23  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2601.15773v1  

#### Abstract
With the rapid advancement and strong generalization capabilities of large language models (LLMs), they have been increasingly incorporated into the active learning pipelines as annotators to reduce annotation costs. However, considering the annotation quality, labels generated by LLMs often fall sh...

---

### 17. [A tensor network formalism for neuro-symbolic AI](https://arxiv.org/abs/2601.15442)

**Authors**: Alex Goessmann, Janina Sch\"utte, Maximilian Fr\"ohlich, Martin Eigel  
**Category**: cs.AI  
**Published**: 2026-01-23  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.15442v1  

#### Abstract
The unification of neural and symbolic approaches to artificial intelligence remains a central open challenge. In this work, we introduce a tensor network formalism, which captures sparsity principles originating in the different approaches in tensor decompositions. In particular, we describe a basi...

---

### 18. [TransportAgents: a multi-agents LLM framework for traffic accident severity prediction](https://arxiv.org/abs/2601.15519)

**Authors**: Zhichao Yang, Jiashu He, Jinxuan Fan, Cirillo Cinzia  
**Category**: cs.AI  
**Published**: 2026-01-23  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.15519v1  

#### Abstract
Accurate prediction of traffic crash severity is critical for improving emergency response and public safety planning. Although recent large language models (LLMs) exhibit strong reasoning capabilities, their single-agent architectures often struggle with heterogeneous, domain-specific crash data an...

---

### 19. [Off-Policy Actor-Critic with Sigmoid-Bounded Entropy for Real-World Robot Learning](https://arxiv.org/abs/2601.15761)

**Authors**: Xiefeng Wu, Mingyu Hu, Shu Zhang  
**Category**: cs.AI  
**Published**: 2026-01-23  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.15761v1  

#### Abstract
Deploying reinforcement learning in the real world remains challenging due to sample inefficiency, sparse rewards, and noisy visual observations. Prior work leverages demonstrations and human feedback to improve learning efficiency and robustness. However, offline-to-online methods need large datase...

---

### 20. [AfriEconQA: A Benchmark Dataset for African Economic Analysis based on World Bank Reports](https://arxiv.org/abs/2601.15297)

**Authors**: Edward Ajayi  
**Category**: cs.CL  
**Published**: 2026-01-23  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.15297v1  

#### Abstract
We introduce AfriEconQA, a specialized benchmark dataset for African economic analysis grounded in a comprehensive corpus of 236 World Bank reports. The task of AfriEconQA is to answer complex economic queries that require high-precision numerical reasoning and temporal disambiguation from specializ...

---

### 21. [Attention-Informed Surrogates for Navigating Power-Performance Trade-offs in HPC](https://arxiv.org/abs/2601.15399)

**Authors**: Ashna Nawar Ahmed, Banooqa Banday, Terry Jones, Tanzima Z. Islam  
**Category**: cs.LG  
**Published**: 2026-01-23  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2601.15399v1  

#### Abstract
High-Performance Computing (HPC) schedulers must balance user performance with facility-wide resource constraints. The task boils down to selecting the optimal number of nodes for a given job. We present a surrogate-assisted multi-objective Bayesian optimization (MOBO) framework to automate this com...

---

### 22. [AgentSM: Semantic Memory for Agentic Text-to-SQL](https://arxiv.org/abs/2601.15709)

**Authors**: Asim Biswal, Chuan Lei, Xiao Qin, Aodong Li, Balakrishnan Narayanaswamy, Tim Kraska  
**Category**: cs.AI  
**Published**: 2026-01-23  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.15709v1  

#### Abstract
Recent advances in LLM-based Text-to-SQL have achieved remarkable gains on public benchmarks such as BIRD and Spider. Yet, these systems struggle to scale in realistic enterprise settings with large, complex schemas, diverse SQL dialects, and expensive multi-step reasoning. Emerging agentic approach...

---

### 23. [From Generation to Collaboration: Using LLMs to Edit for Empathy in Healthcare](https://arxiv.org/abs/2601.15558)

**Authors**: Man Luo, Bahareh Harandizadeh, Amara Tariq, Halim Abbas, Umar Ghaffar, Christopher J Warren, Segun O. Kolade, Haidar M. Abdul-Muhsin  
**Category**: cs.CL  
**Published**: 2026-01-23  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2601.15558v1  

#### Abstract
Clinical empathy is essential for patient care, but physicians need continually balance emotional warmth with factual precision under the cognitive and emotional constraints of clinical practice. This study investigates how large language models (LLMs) can function as empathy editors, refining physi...

---

### 24. [Aeon: High-Performance Neuro-Symbolic Memory Management for Long-Horizon LLM Agents](https://arxiv.org/abs/2601.15311)

**Authors**: Mustafa Arslan  
**Category**: cs.AI  
**Published**: 2026-01-23  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.15311v1  

#### Abstract
Large Language Models (LLMs) are fundamentally constrained by the quadratic computational cost of self-attention and the "Lost in the Middle" phenomenon, where reasoning capabilities degrade as context windows expand. Existing solutions, primarily "Flat RAG" architectures relying on vector databases...

---

### 25. [GeMM-GAN: A Multimodal Generative Model Conditioned on Histopathology Images and Clinical Descriptions for Gene Expression Profile Generation](https://arxiv.org/abs/2601.15392)

**Authors**: Francesca Pia Panaccione, Carlo Sgaravatti, Pietro Pinoli  
**Category**: cs.AI  
**Published**: 2026-01-23  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.15392v1  

#### Abstract
Biomedical research increasingly relies on integrating diverse data modalities, including gene expression profiles, medical images, and clinical metadata. While medical images and clinical metadata are routinely collected in clinical practice, gene expression data presents unique challenges for wide...

---

### 26. [EvoCUA: Evolving Computer Use Agents via Learning from Scalable Synthetic Experience](https://arxiv.org/abs/2601.15876)

**Authors**: Taofeng Xue, Chong Peng, Mianqiu Huang, Linsen Guo, Tiancheng Han, Haozhe Wang, Jianing Wang, Xiaocheng Zhang, Xin Yang, Dengchang Zhao, Jinrui Ding, Xiandi Ma, Yuchen Xie, Peng Pei, Xunliang Cai, Xipeng Qiu  
**Category**: cs.AI  
**Published**: 2026-01-23  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.15876v1  

#### Abstract
The development of native computer-use agents (CUA) represents a significant leap in multimodal AI. However, their potential is currently bottlenecked by the constraints of static data scaling. Existing paradigms relying primarily on passive imitation of static datasets struggle to capture the intri...

---

### 27. [ICON: Invariant Counterfactual Optimization with Neuro-Symbolic Priors for Text-Based Person Search](https://arxiv.org/abs/2601.15931)

**Authors**: Xiangyu Wang, Zhixin Lv, Yongjiao Sun, Anrui Han, Ye Yuan, Hangxu Ji  
**Category**: cs.AI  
**Published**: 2026-01-23  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.15931v1  

#### Abstract
Text-Based Person Search (TBPS) holds unique value in real-world surveillance bridging visual perception and language understanding, yet current paradigms utilizing pre-training models often fail to transfer effectively to complex open-world scenarios. The reliance on "Passive Observation" leads to ...

---

### 28. [Decoupling Return-to-Go for Efficient Decision Transformer](https://arxiv.org/abs/2601.15953)

**Authors**: Yongyi Wang, Hanyu Liu, Lingfeng Li, Bozhou Chen, Ang Li, Qirui Zheng, Xionghui Yang, Wenxin Li  
**Category**: cs.AI  
**Published**: 2026-01-23  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.15953v1  

#### Abstract
The Decision Transformer (DT) has established a powerful sequence modeling approach to offline reinforcement learning. It conditions its action predictions on Return-to-Go (RTG), using it both to distinguish trajectory quality during training and to guide action generation at inference. In this work...

---

### 29. [Structured Hints for Sample-Efficient Lean Theorem Proving](https://arxiv.org/abs/2601.16172)

**Authors**: Zachary Burton  
**Category**: cs.AI  
**Published**: 2026-01-23  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.16172v1  

#### Abstract
State-of-the-art neural theorem provers like DeepSeek-Prover-V1.5 combine large language models with reinforcement learning, achieving impressive results through sophisticated training. We ask: do these highly-trained models still benefit from simple structural guidance at inference time? We evaluat...

---

### 30. [Universal Refusal Circuits Across LLMs: Cross-Model Transfer via Trajectory Replay and Concept-Basis Reconstruction](https://arxiv.org/abs/2601.16034)

**Authors**: Tony Cristofano  
**Category**: cs.CL  
**Published**: 2026-01-23  
**Score**: 5.5  
**Type**: new  
**ArXiv ID**: 2601.16034v1  

#### Abstract
Refusal behavior in aligned LLMs is often viewed as model-specific, yet we hypothesize it stems from a universal, low-dimensional semantic circuit shared across models. To test this, we introduce Trajectory Replay via Concept-Basis Reconstruction, a framework that transfers refusal interventions fro...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- kv cache, offload, State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
