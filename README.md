# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-02-09 06:51:44 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [PackInfer: Compute- and I/O-Efficient Attention for Batched LLM Inference](https://arxiv.org/abs/2602.06072)

**Authors**: Rui Ning, Wei Zhang, Fan Lai  
**Category**: cs.DC  
**Published**: 2026-02-09  
**Score**: 14.0  
**Type**: new  
**ArXiv ID**: 2602.06072v1  

#### Abstract
Attention efficiency is critical to large language model (LLM) inference. While prior advances optimize attention execution for individual requests (e.g., FlashAttention), production LLM serving relies on batching requests with highly heterogeneous sequence lengths for high serving throughput. This ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡ã€ŠPackInfer: Compute- and I/O-Efficient Attention for Batched LLM Inferenceã€‹æ€»ç»“**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
åœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†ä¸­ï¼Œ**ç”Ÿäº§ç¯å¢ƒé€šå¸¸é€šè¿‡æ‰¹å¤„ç†ï¼ˆbatchingï¼‰å¤šä¸ªè¯·æ±‚æ¥æå‡ååé‡**ã€‚ç„¶è€Œï¼Œè¿™äº›è¯·æ±‚çš„è¾“å…¥åºåˆ—é•¿åº¦é«˜åº¦å¼‚æ„ï¼ˆheterogeneousï¼‰ï¼Œä¾‹å¦‚çŸ­æŸ¥è¯¢ä»…å‡ åä¸ªtokenï¼Œè€Œé•¿ä¸Šä¸‹æ–‡å¯è¾¾æ•°åƒtokenã€‚

ç°æœ‰ç³»ç»Ÿï¼ˆå¦‚ FlashAttentionï¼‰ä¸ºæ¯ä¸ªè¯·æ±‚åˆ†é…å›ºå®šå¤§å°çš„tileï¼ˆå¦‚128Ã—128ï¼‰ï¼Œå¯¼è‡´ï¼š
- **è®¡ç®—æµªè´¹**ï¼šçŸ­è¯·æ±‚å¡«å……å¤§é‡æ— æ•ˆåŒºåŸŸï¼ˆpaddingï¼‰ï¼Œé€ æˆå†—ä½™è®¡ç®—ï¼›
- **I/Oæ•ˆç‡ä½ä¸‹**ï¼šKV Cache åˆ†å¸ƒç¢ç‰‡åŒ–ï¼Œå†…å­˜è®¿é—®ä¸è¿ç»­ï¼›
- **èµ„æºä¸å¹³è¡¡ï¼ˆstraggler problemï¼‰**ï¼šé•¿è¯·æ±‚ä¸»å¯¼æ‰§è¡Œæ—¶é—´ï¼ŒçŸ­è¯·æ±‚æå‰å®Œæˆä½†GPUèµ„æºé—²ç½®ï¼Œé™ä½æ•´ä½“åˆ©ç”¨ç‡ã€‚

è¿™ç§â€œ**è®¡ç®—ä¸I/Oå¤±è¡¡**â€ä¸¥é‡åˆ¶çº¦äº†GPUçš„åˆ©ç”¨ç‡å’Œç«¯åˆ°ç«¯å»¶è¿Ÿè¡¨ç°ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
ä½œè€…æå‡º **PackInfer** â€”â€” ä¸€ç§**å†…æ ¸çº§ï¼ˆkernel-levelï¼‰æ³¨æ„åŠ›ä¼˜åŒ–æ¡†æ¶**ï¼Œé€šè¿‡**è®¡ç®—ä¸I/Oæ„ŸçŸ¥çš„è¯·æ±‚æ‰“åŒ…æœºåˆ¶**è§£å†³ä¸Šè¿°é—®é¢˜ã€‚

å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å°†ä¸€æ‰¹å¼‚æ„è¯·æ±‚**åŠ¨æ€åˆ†ç»„ä¸ºè‹¥å¹²è´Ÿè½½å‡è¡¡çš„æ‰§è¡Œå•å…ƒï¼ˆgroupsï¼‰**ï¼›
- åœ¨æ¯ä¸ªgroupå†…æ„å»º**ç»Ÿä¸€ã€æ— å¡«å……çš„attention kernelæ‰§è¡ŒåŸŸ**ï¼›
- åŒæ—¶é‡æ„KV Cacheçš„ç‰©ç†å¸ƒå±€ï¼Œå®ç°**è¿ç»­å†…å­˜è®¿é—®ä¸å‰ç¼€å…±äº«ä¼˜åŒ–**ã€‚

#### **å…³é”®æŠ€æœ¯è®¾è®¡**
1. **Packed Computationï¼ˆæ‰“åŒ…è®¡ç®—ï¼‰**
   - å°†å¤šä¸ªè¯·æ±‚åˆå¹¶åˆ°ä¸€ä¸ªkernelä¸­æ‰§è¡Œï¼Œé¿å…å•ä¸ªè¯·æ±‚ç‹¬å å®Œæ•´tileï¼›
   - ä½¿ç”¨è´ªå¿ƒç®—æ³•è¿›è¡Œ**è‡ªé€‚åº”åˆ†ç»„**ï¼Œæœ€å°åŒ–å„groupä¹‹é—´çš„æ€»é•¿åº¦å·®å¼‚ï¼Œç¼“è§£straggleræ•ˆåº”ï¼›
   - æ”¯æŒè¿è¡Œæ—¶**åŠ¨æ€é‡åˆ†ç»„ï¼ˆregroupingï¼‰**ï¼Œåº”å¯¹ç”Ÿæˆè¿‡ç¨‹ä¸­tokenå¢é•¿å¸¦æ¥çš„è´Ÿè½½æ¼‚ç§»ã€‚

2. **Packed I/Oï¼ˆæ‰“åŒ…I/Oï¼‰**
   - æ„å»º**å‰ç¼€æ ‘ï¼ˆTrieï¼‰è¯†åˆ«å…±äº«promptéƒ¨åˆ†**ï¼ŒåªåŠ è½½ä¸€æ¬¡å…¬å…±KVç¼“å­˜ï¼›
   - å°†åˆ†æ•£çš„KV Cacheå—æ•´åˆä¸º**group-contiguousçš„è¿ç»­ç¼“å†²åŒº**ï¼Œæå‡å†…å­˜å¸¦å®½åˆ©ç”¨ç‡ï¼›
   - é¢„ç•™suffix headroomä»¥æ”¯æŒå¤šæ­¥è§£ç è€Œä¸é¢‘ç¹é‡å¯¹é½ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ FlashAttentionï¼‰ | PackInfer |
|------|-------------------------------|---------|
| **è®¡ç®—æ•ˆç‡** | å›ºå®štileå¯¼è‡´paddingæµªè´¹ | æ¶ˆé™¤paddingï¼Œæœ€å¤§åŒ–SRAMå’ŒTensor Coreåˆ©ç”¨ç‡ |
| **å†…å­˜è®¿é—®** | KV Cacheç¢ç‰‡åŒ–ï¼Œè®¿é—®ä¸è¿ç»­ | è¿ç»­å¸ƒå±€ + å‰ç¼€å…±äº« â†’ å‡å°‘å†—ä½™I/O |
| **è°ƒåº¦çµæ´»æ€§** | è¯·æ±‚ç‹¬ç«‹å¤„ç†ï¼Œç¼ºä¹è·¨è¯·æ±‚ååŒ | è·¨è¯·æ±‚æ‰“åŒ…ï¼Œå®ç°ç»†ç²’åº¦è´Ÿè½½å‡è¡¡ |
| **å…¼å®¹æ€§** | ä¿®æ”¹éœ€ä¾µå…¥æ¨¡å‹æ¶æ„ | åªéœ€å°‘é‡APIæ›¿æ¢ï¼Œå¯é›†æˆè‡³vLLMç­‰ä¸»æµç³»ç»Ÿ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šPackInferå®ç°äº†**lossless attentionè¯­ä¹‰ä¸‹çš„é›¶æ¶æ„ä¿®æ”¹åŠ é€Ÿ**ï¼ŒåŒæ—¶æå‡äº†è®¡ç®—å¯†åº¦ä¸å†…å­˜å±€éƒ¨æ€§ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
ä¸‰ä¸ªçœŸå®ä¸–ç•Œè¯·æ±‚è½¨è¿¹ï¼ˆrequest tracesï¼‰ï¼š
- **Alpaca**ï¼šæŒ‡ä»¤è·Ÿéšä»»åŠ¡ï¼ˆinstruction-followingï¼‰
- **LMSYS**ï¼šç±»ChatGPTçš„çœŸå®å¯¹è¯è´Ÿè½½
- **Text2SQL**ï¼šè‡ªç„¶è¯­è¨€è½¬SQLæŸ¥è¯¢

æ¯ç§è´Ÿè½½åŒ…å«7,000 ~ 200,000æ¡promptï¼Œå…·æœ‰æ˜¾è‘—çš„**é•¿å°¾åºåˆ—é•¿åº¦åˆ†å¸ƒ**ï¼ˆ>60%è¯·æ±‚ <128 tokensï¼‰ã€‚

---

### **å®éªŒè®¾ç½®**
- **ç¡¬ä»¶å¹³å°**ï¼š
  - ä¸»è¦æµ‹è¯•ï¼šå•å¡ NVIDIA A100 40GB
  - æ‰©å±•éªŒè¯ï¼šH200ã€A40ã€å¤šå¡ï¼ˆ4Ã—A100ï¼‰
- **æ¨¡å‹èŒƒå›´**ï¼š
  - Qwen3-4Bã€Mistral-7Bã€Qwen3-30B-A3Bï¼ˆMoEï¼‰
- **é›†æˆæ¡†æ¶**ï¼š
  - åŸºäº Nano-vLLM å®ç°ï¼Œå…¼å®¹ vLLM å’Œ FlashAttention æ¥å£
- **è°ƒåº¦ç­–ç•¥**ï¼šé»˜è®¤ FCFSï¼ˆå…ˆæ¥å…ˆæœåŠ¡ï¼‰

---

### **è¯„ä¼°æŒ‡æ ‡**
| ç±»å‹ | æŒ‡æ ‡ | è¯´æ˜ |
|------|------|------|
| **å»¶è¿Ÿç›¸å…³** | TTFTï¼ˆTime-to-First-Tokenï¼‰<br>TBTï¼ˆTime-Between-Tokensï¼‰<br>TTLTï¼ˆTime-to-Last-Tokenï¼‰ | ç”¨æˆ·æ„ŸçŸ¥çš„å…³é”®å»¶è¿ŸæŒ‡æ ‡ |
| **ååç›¸å…³** | Token Throughputï¼ˆtokens/secï¼‰ | ç³»ç»Ÿæ•´ä½“æœåŠ¡èƒ½åŠ› |
| **ç¡¬ä»¶æ•ˆç‡** | SM Occupancy<br>Tensor Core Utilization<br>Memory Bandwidth Usage | åº•å±‚èµ„æºåˆ©ç”¨æƒ…å†µ |
| **ç»Ÿè®¡æ–¹å¼** | å¹³å‡å€¼ï¼ˆAvgï¼‰ã€P95ã€P99 | å…¨é¢åæ˜ æ€§èƒ½åˆ†å¸ƒ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **FlashAttention**ï¼ˆDao et al., 2022; 2024ï¼‰ï¼šå½“å‰æœ€å…ˆè¿›çš„attention kernelï¼Œæ”¯æŒtilingä¸recomputationï¼›
- **Prepack**ï¼ˆZhao et al., 2024ï¼‰ï¼šè¿‘æœŸKV Cacheé‡æ’åºæŠ€æœ¯ï¼Œä¼˜åŒ–å†…å­˜å¸ƒå±€ä½†ä¸æ”¹å˜kernelé€»è¾‘ã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
#### âœ… **å»¶è¿Ÿé™ä½**
- **TBTï¼ˆtime-between-tokensï¼‰ä¸‹é™ 13.0â€“20.1%**
- **TTFTï¼ˆtime-to-first-tokenï¼‰æœ€é«˜å‡å°‘ 18.6%**
- **TTLTï¼ˆend-to-end latencyï¼‰æ”¹å–„ 3.8â€“20.2%**

> å›¾5~6æ˜¾ç¤ºï¼Œåœ¨Mistral-7Bå’ŒQwen3-4Bä¸Šï¼ŒPackInferæ˜¾è‘—ä¼˜äºFlashAttentionå’ŒPrepackã€‚

#### âœ… **ååæå‡**
- **æ•´ä½“ååé‡æé«˜çº¦ 20%**
- åœ¨é«˜å¼‚æ„è´Ÿè½½ä¸‹å¢ç›Šæ›´æ˜æ˜¾ï¼ˆæœ€é«˜è¾¾24.9%ï¼‰

> å¦‚å›¾8æ‰€ç¤ºï¼ŒPackInferçš„å¹³å‡ååç”šè‡³è¶…è¿‡FlashAttentionçš„P95æ°´å¹³ï¼Œè¡¨æ˜å…¶ç¨³å®šæ€§æ›´å¼ºã€‚

#### âœ… **ç¡¬ä»¶åˆ©ç”¨ç‡æå‡**
| æŒ‡æ ‡ | FlashAttention | PackInfer | æå‡å¹…åº¦ |
|------|----------------|-----------|----------|
| Tensor Core Utilization | 18% | 33% | â†‘83% |
| SM Instruction Issue Throughput | 17% | 25% | â†‘47% |

> è¡¨æ˜PackInferæœ‰æ•ˆå‡å°‘äº†è®¡ç®—ç©ºæ³¡ï¼ˆbubbleï¼‰å’Œå†…å­˜åœé¡¿ã€‚

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**
- **ç»„ä»¶æ‹†è§£**ï¼ˆå›¾9ï¼‰ï¼š
  - ä»…å¯ç”¨ **Packed Computation**ï¼šå·²æœ‰æ˜æ˜¾æé€Ÿï¼ˆä¸»è¦æ¥è‡ªå‡å°‘kernel launchä¸è®¡ç®—æµªè´¹ï¼‰ï¼›
  - åŠ å…¥ **Packed I/O**ï¼šè¿›ä¸€æ­¥å‹ç¼©å†…å­˜å¼€é”€ï¼Œå¸¦æ¥é¢å¤–5â€“8%æ€§èƒ½å¢ç›Šï¼›
  - äºŒè€…ç»“åˆäº§ç”Ÿ**äº’è¡¥æ•ˆåº”**ï¼Œè¯æ˜è”åˆè®¾è®¡çš„é‡è¦æ€§ã€‚

- **å‚æ•°æ•æ„Ÿæ€§åˆ†æ**ï¼ˆå›¾10ï¼‰ï¼š
  - **Batch Sizeå˜åŒ–**ï¼šPackInferåœ¨å„ç§batch sizeä¸‹å§‹ç»ˆä¼˜äºbaselineï¼ˆ1.2â€“1.3Ã—ï¼‰ï¼›
  - **Group Sizeå½±å“**ï¼šå­˜åœ¨æœ€ä¼˜å€¼ï¼ˆ~2048 tokensï¼‰ï¼Œè¿‡å¤§åè€Œå¼•å…¥å†…éƒ¨ç¢ç‰‡ï¼›è¯¥ç‚¹å¯é€šè¿‡ç¦»çº¿profileç¡®å®šã€‚

- **è·¨ç¡¬ä»¶æ³›åŒ–èƒ½åŠ›**ï¼ˆå›¾11ï¼‰ï¼š
  - åœ¨A100ã€A40ã€H200ä¸ŠTBTå‡ä¸‹é™ **11â€“19%**ï¼ŒéªŒè¯äº†æ–¹æ³•çš„ç¡¬ä»¶æ— å…³æ€§ã€‚

- **åˆ†å¸ƒå¼æ‰©å±•æ€§**ï¼ˆå›¾12ï¼‰ï¼š
  - æ”¯æŒTensor Parallelismï¼ˆTP=1 åˆ° TP=4ï¼‰ï¼Œåœ¨å¤šGPUåœºæ™¯ä¸‹ä»ä¿æŒç¨³å®šæ”¶ç›Šï¼Œæ— é¢å¤–é€šä¿¡å¼€é”€ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **å¼‚æ„æ‰¹å¤„ç†ä¸­çš„è´Ÿè½½ä¸å¹³è¡¡æ˜¯é™åˆ¶LLMæ¨ç†æ•ˆç‡çš„æ ¹æœ¬ç“¶é¢ˆ**ï¼›
2. **ä¼ ç»Ÿattention kernelå› å›ºå®štileç»“æ„æ— æ³•é€‚åº”ç°å®è´Ÿè½½åˆ†å¸ƒ**ï¼›
3. **é€šè¿‡è·¨è¯·æ±‚çš„â€œè®¡ç®—+I/Oâ€è”åˆæ‰“åŒ…ï¼Œå¯åœ¨ä¸æ”¹å˜æ¨¡å‹çš„å‰æä¸‹å¤§å¹…æå‡ç¡¬ä»¶åˆ©ç”¨ç‡**ï¼›
4. **PackInferçš„è®¾è®¡è½»é‡é«˜æ•ˆï¼Œä»…éœ€å°‘é‡APIæ”¹åŠ¨å³å¯é›†æˆè¿›ç°æœ‰ç³»ç»Ÿï¼ˆå¦‚vLLMï¼‰**ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
- **åˆ†ç»„å†³ç­–ä¾èµ–å¯å‘å¼ç®—æ³•**ï¼šè™½æ¯”ILPå¿«å¾—å¤šï¼ˆè§å›¾13ï¼‰ï¼Œä½†ä»éå…¨å±€æœ€ä¼˜ï¼›
- **é€‚ç”¨äºé™æ€prompté˜¶æ®µè¾ƒå¥½ï¼ŒåŠ¨æ€ç”Ÿæˆä¸­éœ€å®šæœŸregroup**ï¼Œå¸¦æ¥ä¸€å®šæ§åˆ¶å¼€é”€ï¼›
- å¯¹æç«¯ç¨€ç–æˆ–ç‰¹æ®Špatternçš„workloadå¯èƒ½éœ€é‡æ–°è°ƒå‚ï¼ˆå¦‚group capacity Cï¼‰ï¼›
- å½“å‰æœªæ¢ç´¢ä¸å…¶ä»–ä¼˜åŒ–ï¼ˆå¦‚é‡åŒ–ã€ç¨€ç–attentionï¼‰çš„æ·±åº¦ååŒã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
- ç»“åˆ**å­¦ä¹ å‹è°ƒåº¦å™¨**é¢„æµ‹ç”Ÿæˆé•¿åº¦ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–åˆå§‹åˆ†ç»„ï¼›
- æ¢ç´¢**å¼‚æ„è®¾å¤‡é—´æ‰“åŒ…**ï¼ˆå¦‚CPU+GPUåä½œï¼‰ï¼›
- å°†æ‰“åŒ…æ€æƒ³æ¨å¹¿è‡³å…¶ä»–Transformeræ“ä½œï¼ˆå¦‚MLPã€RoPEï¼‰ï¼›
- æ”¯æŒ**æµå¼è¾“å…¥/åŠ¨æ€è¿½åŠ è¯·æ±‚**çš„åœ¨çº¿æ‰“åŒ…æœºåˆ¶ï¼›
- ä¸MoEè·¯ç”±æœºåˆ¶è”åŠ¨ï¼Œå®ç°**expert-aware grouping**ã€‚

---

## **æ€»ç»“**
âœ… **PackInferæ˜¯ä¸€é¡¹é¢å‘ç°å®éƒ¨ç½²åœºæ™¯çš„é‡è¦ç³»ç»Ÿåˆ›æ–°**ã€‚å®ƒä»**kernelå±‚é¢æ‰“ç ´è¯·æ±‚éš”ç¦»å‡è®¾**ï¼Œé€šè¿‡**è®¡ç®—ä¸I/OååŒæ‰“åŒ…**ï¼Œè§£å†³äº†é•¿æœŸå­˜åœ¨çš„å¼‚æ„æ‰¹å¤„ç†æ•ˆç‡é—®é¢˜ã€‚å…¶å®éªŒå……åˆ†ã€æ•ˆæœæ˜¾è‘—ï¼Œåœ¨å»¶è¿Ÿã€ååã€èµ„æºåˆ©ç”¨ç‡ç­‰æ–¹é¢å…¨é¢è¶…è¶ŠFlashAttentionç­‰SOTAæ–¹æ¡ˆï¼Œå…·å¤‡å¼ºå®ç”¨ä»·å€¼ä¸å¹¿æ³›é€‚ç”¨æ€§ã€‚

</details>

---

### 2. [Quantifying Energy-Efficient Edge Intelligence: Inference-time Scaling Laws for Heterogeneous Computing](https://arxiv.org/abs/2602.06057)

**Authors**: Satyam Kumar, Saurabh Jha  
**Category**: cs.DC  
**Published**: 2026-02-09  
**Score**: 13.0  
**Type**: new  
**ArXiv ID**: 2602.06057v1  

#### Abstract
Large language model inference on resource constrained edge devices remains a major challenge for low latency intelligent systems, as existing solutions depend heavily on cloud or datacenter infrastructure. This work introduces QEIL, Quantifying Edge Intelligence via Inference time Scaling Laws, a u...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Quantifying Energy-Efficient Edge Intelligence: Inference-time Scaling Laws for Heterogeneous Computing*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†æ•ˆç‡ä½ä¸‹**çš„é—®é¢˜å±•å¼€ç ”ç©¶ã€‚å½“å‰ä¸»æµçš„LLMéƒ¨ç½²ä¾èµ–æ•°æ®ä¸­å¿ƒåŸºç¡€è®¾æ–½ï¼Œå¯¼è‡´åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²æˆæœ¬é«˜æ˜‚ã€å»¶è¿Ÿé«˜ã€èƒ½è€—å¤§ã€‚å°½ç®¡å·²æœ‰å·¥ä½œæ¢ç´¢äº†æ¨ç†æ—¶è®¡ç®—æ‰©å±•ï¼ˆinference-time compute scalingï¼‰ã€æœ¬åœ°-äº‘æ··åˆç³»ç»Ÿä»¥åŠå¼‚æ„ç¡¬ä»¶è°ƒåº¦ï¼Œä½†è¿™äº›ç ”ç©¶å­˜åœ¨ä»¥ä¸‹ä¸è¶³ï¼š
- ç¼ºä¹å¯¹**è·¨å¼‚æ„ç¡¬ä»¶ï¼ˆCPU/GPU/NPUï¼‰çš„æ¨ç†æ—¶æ‰©å±•è§„å¾‹**çš„ç³»ç»Ÿæ€§å»ºæ¨¡ï¼›
- ä¼˜åŒ–ç²’åº¦å±€é™äºæŸ¥è¯¢çº§åˆ«ï¼Œæœªæ·±å…¥åˆ°**å•ä¸ªæ¨ç†ä»»åŠ¡å†…éƒ¨é˜¶æ®µ**ï¼ˆå¦‚prefill vs. decodeï¼‰ï¼›
- ç¼ºå°‘ç»Ÿä¸€çš„å¤šç›®æ ‡æ•ˆç‡åº¦é‡æ ‡å‡†æ¥è¡¡é‡**è¦†ç›–ç‡ã€èƒ½é‡ã€æˆæœ¬ä¸å»¶è¿Ÿä¹‹é—´çš„æƒè¡¡**ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡º **QEIL**ï¼ˆQuantifying Edge Intelligence via Inference-time Scaling Lawsï¼‰ï¼Œä¸€ä¸ªç»“åˆ**æ¨ç†æ—¶æ‰©å±•å®šå¾‹**ä¸**å¼‚æ„ç¡¬ä»¶ååŒè°ƒåº¦**çš„ç»Ÿä¸€æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰å»ºç«‹äº”æ¡æ¶æ„æ— å…³çš„æ¨ç†æ—¶æ‰©å±•å®šç†ï¼ˆArchitecture-agnostic Scaling Lawsï¼‰
é¦–æ¬¡ä»ç†è®ºä¸Šè¯æ˜å¹¶å®è¯éªŒè¯äº†ä»¥ä¸‹å¯é¢„æµ‹çš„å¹‚å¾‹å…³ç³»ï¼š
- **Coverage Scaling**: è¦†ç›–ç‡ $ C(S) = 1 - \exp(-\alpha N^\beta S^\gamma T^\delta) $ï¼Œå…¶ä¸­ $\beta \sim 0.7$ æ˜¯æ¶æ„æ— å…³æŒ‡æ•°ï¼›
- **Energy Scaling**: æ€»èƒ½è€—éšæ ·æœ¬æ•°æ¬¡çº¿æ€§å¢é•¿ï¼ˆ$\gamma_E \sim 0.9$ï¼‰ï¼Œå¾—ç›Šäºæ›´å¤§æ¨¡å‹æ›´å¥½çš„ç¼“å­˜å±€éƒ¨æ€§ï¼›
- **Latency Scaling**: åˆ†è§£ä¸º prefillï¼ˆè®¡ç®—å¯†é›†ï¼‰ã€decodeï¼ˆå†…å­˜å¯†é›†ï¼‰ã€I/O å’Œè°ƒåº¦å¼€é”€ï¼›
- **Cost Scaling**: ç»æµæˆæœ¬ç”±ç¡¬ä»¶æ‘Šé”€ã€ç”µåŠ›æ¶ˆè€—å’Œç»´æŠ¤ç»„æˆï¼›
- **Device-Task Efficiency Compatibility**: åŸºäº Roofline æ¨¡å‹è¿›è¡Œæœ€ä¼˜ä»»åŠ¡-è®¾å¤‡åŒ¹é…ã€‚

#### ï¼ˆ2ï¼‰å¼•å…¥æ–°å‹å¤åˆæ•ˆç‡æŒ‡æ ‡
æå‡ºäº†ä¸‰ä¸ªç”¨äºç³»ç»Ÿæ¯”è¾ƒå¼‚æ„é…ç½®çš„æ–°æŒ‡æ ‡ï¼š
- **Intelligence Per Watt (IPW)**ï¼šå•ä½åŠŸç‡ä¸‹çš„ä»»åŠ¡å‡†ç¡®ç‡ï¼Œåæ˜ ç¬æ—¶èƒ½æ•ˆï¼›
- **Energy-Coverage Efficiency (ECE)**ï¼šæ¯ç„¦è€³èƒ½é‡è·å¾—çš„è¦†ç›–ç‡æå‡ï¼Œé€‚ç”¨äºæ€»èƒ½é‡é¢„ç®—çº¦æŸï¼›
- **Price-Power-Performance (PPP) Score**ï¼šæ— é‡çº²ç»¼åˆæŒ‡æ ‡ï¼Œå¹³è¡¡ååé‡ã€åŠŸè€—ä¸å•ä½æŸ¥è¯¢æˆæœ¬ã€‚

#### ï¼ˆ3ï¼‰åŠ¨æ€å¼‚æ„ç¼–æ’æœºåˆ¶
åŸºäº MLIR çš„ç¼–è¯‘å™¨åŸºç¡€è®¾æ–½å®ç°ç»†ç²’åº¦ä»»åŠ¡åˆ†è§£ä¸è°ƒåº¦ï¼š
- å°†æ¨ç†è¿‡ç¨‹æ‹†åˆ†ä¸º embeddingã€decoder layers å’Œ LM headï¼›
- æ ¹æ®å„é˜¶æ®µçš„ç®—æœ¯å¼ºåº¦ï¼ˆarithmetic intensityï¼‰å°†å…¶è·¯ç”±è‡³æœ€é€‚é…çš„è®¾å¤‡ï¼ˆå¦‚ prefill â†’ GPUï¼Œdecode â†’ NPUï¼‰ï¼›
- æ”¯æŒè¿è¡Œæ—¶è‡ªé€‚åº”é‡‡æ ·èšåˆï¼Œåœ¨å®æ—¶èƒ½è€—ç›‘æ§ä¸‹è°ƒæ•´æ ·æœ¬æ•°é‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | QEIL çš„ä¼˜åŠ¿ |
|------|-------------|
| **ç†è®ºæ·±åº¦** | æå‡ºé¦–ä¸ªå®Œæ•´çš„æ¨ç†æ—¶çƒ­åŠ›å­¦ç±»æ¯”æ¡†æ¶ï¼Œè¶…è¶Šç»éªŒæ‹Ÿåˆï¼Œæä¾›â€œä¸ºä»€ä¹ˆæœ‰æ•ˆâ€çš„è§£é‡Š |
| **é€šç”¨æ€§** | æ‰©å±•å®šå¾‹è¢«éªŒè¯åœ¨ GPT-2 åˆ° LFM2 ç­‰å¤šç§æ¶æ„ï¼ˆ125Mâ€“2.6B å‚æ•°ï¼‰ä¸Šå‡æˆç«‹ï¼Œå…·æœ‰æ¶æ„æ— å…³æ€§ |
| **æ•ˆç‡å¢ç›Š** | åŒæ—¶å®ç°æ›´é«˜è¦†ç›–ç‡ã€æ›´ä½èƒ½è€—ã€æ›´çŸ­å»¶è¿Ÿå’Œæ›´å¥½æ€§ä»·æ¯”ï¼Œæ‰“ç ´ä¼ ç»Ÿæƒè¡¡ |
| **å®ç”¨æ€§** | æ”¯æŒä»»æ„ Transformer æ¶æ„ä¸å¤šæ ·ç¡¬ä»¶ï¼ˆIntel/Qualcomm NPU, NVIDIA/AMD GPUï¼‰ï¼Œå…·å¤‡å¼ºå¯ç§»æ¤æ€§ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- ä¸»è¦åŸºå‡†æµ‹è¯•ä½¿ç”¨ **WikiText-103** æ•°æ®é›†è¿›è¡Œè¯­è¨€å»ºæ¨¡è¯„ä¼°ï¼›
- åœ¨éƒ¨åˆ†åˆ†æä¸­å¼•ç”¨äº† **WILDCHAT** å’Œ **NATURALREASONING** æ•°æ®é›†ä»¥éªŒè¯è¦†ç›–èŒƒå›´æ‰©å±•è§„å¾‹ã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼šå¼‚æ„è¾¹ç¼˜å¹³å°åŒ…å«ï¼š
  - CPU: Intel Core Ultra 9 285HXï¼ˆ8æ ¸ï¼Œ2.80GHzï¼‰
  - NPU: Intel AI Boost NPUï¼ˆ20GBä¸“ç”¨å­˜å‚¨ï¼‰
  - GPU: NVIDIA RTX PRO 5000 Blackwellï¼ˆ96.2GB VRAMï¼‰å’Œ Intel Graphics GPUï¼ˆå…±äº«å†…å­˜ï¼‰
- **æ¨¡å‹å®¶æ—**ï¼šæ¶µç›–äº”ä¸ªä¸åŒè§„æ¨¡ä¸æ¶æ„çš„ LLMï¼š
  - GPT-2 (125M)
  - Granite-350M
  - Qwen2-0.5B
  - Llama-3.2-1B
  - LFM2-2.6B
- **æ‰§è¡Œæ¨¡å¼å¯¹æ¯”**ï¼š
  - **Standard (Baseline)**ï¼šååé‡ä¼˜åŒ–çš„åŒæ„æ¨ç†ï¼ˆé€šå¸¸å…¨æ”¾ GPUï¼‰
  - **Energy-Aware (QEIL)**ï¼šå¯ç”¨å¼‚æ„è°ƒåº¦ä¸èƒ½æ•ˆæ„ŸçŸ¥åˆ†é…

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ | å•ä½ |
|------|------|-------|
| **Pass@k** | å¤šæ ·æœ¬ç”Ÿæˆä¸­è‡³å°‘æœ‰ä¸€ä¸ªæ­£ç¡®çš„æ¦‚ç‡ | % |
| **IPW** | Coverage / Average Power | tasks/W |
| **ECE** | Coverage / Total Energy | coverage/J |
| **PPP Score** | (Throughput Ã— Coverage) / (Power Ã— Cost_per_query) | dimensionless |
| **Latency** | ç«¯åˆ°ç«¯æ¨ç†æ—¶é—´ | ms |
| **Power** | å¹³å‡åŠŸè€— | W |
| **Energy** | æ€»èƒ½è€—ï¼ˆ20 samplesï¼‰ | kJ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Homogeneous Cloud Baseline**ï¼šå°†æ•´ä¸ªæ¨ç†ä»»åŠ¡æäº¤è‡³é«˜æ€§èƒ½ GPU è¿›è¡Œé›†ä¸­å¤„ç†ï¼›
- **Query-level Routing**ï¼šç±»ä¼¼ Saad-Falcon et al. çš„æœ¬åœ°-äº‘è·¯ç”±ç­–ç•¥ï¼Œä½†ä¸æ”¯æŒå­ä»»åŠ¡çº§è°ƒåº¦ï¼›
- **Single-device Repeated Sampling**ï¼šå¦‚ Brown et al. çš„æ–¹æ³•ï¼Œä»…é€šè¿‡å¢åŠ æ ·æœ¬æ•°æå‡è¦†ç›–ç‡ï¼Œå¿½ç•¥ç¡¬ä»¶å·®å¼‚ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»ï¼ˆè§ Table 1ï¼‰

| æ¨¡å‹ | æ‰§è¡Œæ–¹å¼ | IPW â†‘ | Pass@k â†‘ | Energy â†“ | PPP â†‘ | Power â†“ | Latency â†“ |
|------|----------|--------|-----------|-----------|--------|---------|------------|
| GPT-2 (125M) | Standard | 0.149 | 59.5% | 43.1 kJ | 16.85 | 402.5 W | 1.73 ms |
| | Energy-Aware | **0.718 (+382%)** | **70.0% (+10.5pp)** | **22.5 kJ (-47.7%)** | **20.74 (+23.1%)** | **83.5 W (-79.2%)** | **1.34 ms (-22.5%)** |
| Granite-350M | Standard | 0.130 | 61.0% | 403.1 kJ | 10.90 | 460.4 W | 1.69 ms |
| | Energy-Aware | **0.729 (+460%)** | **70.0% (+9.0pp)** | **88.0 kJ (-78.2%)** | **16.60 (+52.3%)** | **82.3 W (-82.1%)** | **1.41 ms (-16.6%)** |
| Qwen2-0.5B | Standard | 0.245 | 56.0% | 352.3 kJ | 10.83 | 244.7 W | 1.76 ms |
| | Energy-Aware | **0.807 (+229%)** | **66.5% (+10.5pp)** | **187.9 kJ (-46.7%)** | **15.49 (+43.0%)** | **74.4 W (-69.6%)** | **1.62 ms (-8.0%)** |
| Llama-3.2-1B | Standard | 0.365 | 63.0% | 330.5 kJ | 10.44 | 164.5 W | 1.91 ms |
| | Energy-Aware | **0.760 (+108%)** | **70.0% (+7.0pp)** | **213.0 kJ (-35.6%)** | **15.02 (+43.8%)** | **79.0 W (-52.0%)** | **1.66 ms (-13.1%)** |
| LFM2-2.6B | Standard | 0.341 | 62.0% | 490.3 kJ | 19.51 | 175.8 W | 1.86 ms |
| | Energy-Aware | **0.335 (-1.8%)** | **70.0% (+8.0pp)** | **314.3 kJ (-35.9%)** | **25.91 (+32.8%)** | **75.0 W (-57.3%)** | **1.51 ms (-18.8%)** |

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- âœ… **Pass@k è¦†ç›–ç‡æå‡**ï¼šæ‰€æœ‰æ¨¡å‹å‡è¾¾åˆ° **66.5%â€“70.0%**ï¼Œç›¸æ¯”åŸºçº¿ **56%â€“63%** æå‡ **7â€“10.5ä¸ªç™¾åˆ†ç‚¹**ï¼›
- âœ… **èƒ½é‡æ˜¾è‘—é™ä½**ï¼šå¹³å‡èŠ‚èƒ½ **48.8%**ï¼ˆæœ€é«˜è¾¾ **78.2%**ï¼‰ï¼Œæå¤§å»¶é•¿ç”µæ± å¯¿å‘½ï¼›
- âœ… **åŠŸè€—å¤§å¹…ä¸‹é™**ï¼šå¹³å‡åŠŸè€—ä» ~300W é™è‡³ **75â€“84W**ï¼Œç¬¦åˆè¾¹ç¼˜è®¾å¤‡çƒ­é¢„ç®—ï¼ˆ65â€“125W TDPï¼‰ï¼›
- âœ… **å»¶è¿Ÿæ”¹å–„**ï¼šå¹³å‡é™ä½ **15.8%**ï¼Œæœ€å°é™å¹… 8%ï¼Œæœ€å¤§è¾¾ 22.5%ï¼›
- âœ… **ç»æµæ€§æ›´å¼º**ï¼šPPP Score å¹³å‡æå‡ **39.0%**ï¼Œè¡¨æ˜å•ä½æˆæœ¬å›æŠ¥æ›´é«˜ï¼›
- âœ… **é›¶ç²¾åº¦æŸå¤±**ï¼šå•æ ·æœ¬å‡†ç¡®ç‡ï¼ˆPass@1ï¼‰ä¿æŒä¸å˜ã€‚

### æ¶ˆèå®éªŒä¸å…³é”®å‘ç°ï¼ˆéšå«åˆ†æï¼‰
è™½ç„¶æ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»å¤šä¸ªç»´åº¦éªŒè¯äº†è®¾è®¡æœ‰æ•ˆæ€§ï¼š
- **å¼‚æ„è°ƒåº¦å¿…è¦æ€§**ï¼šdecode é˜¶æ®µè‹¥å¼ºåˆ¶è¿è¡Œåœ¨ CPU ä¸Šä¼šå¯¼è‡´å¸¦å®½ç“¶é¢ˆï¼Œè€Œ GPU/NPU æ˜¾è‘—åŠ é€Ÿï¼›
- **ä»»åŠ¡åˆ†è§£ä»·å€¼**ï¼šembedding å’Œ LM head æ”¾ç½®åœ¨ NPU/CPU å¯é¿å…ä¸å¿…è¦çš„ GPU å¼€é”€ï¼›
- **æ‰©å±•å®šå¾‹æ™®é€‚æ€§**ï¼šåœ¨äº”ç§ä¸åŒæ¶æ„ä¸Šå‡è§‚æµ‹åˆ°ç›¸ä¼¼çš„ $\beta \approx 0.7$ æŒ‡æ•°ï¼Œè¯å®å…¶æ¶æ„æ— å…³æ€§ï¼›
- **ä¿¡æ¯å¯†åº¦ä¼˜åŠ¿**ï¼šå›¾2æ˜¾ç¤º QEIL Enhanced Density åœ¨å…¨ç½®ä¿¡åŒºé—´ç»´æŒç¨³å®šçš„ä¿¡æ¯æå–æ•ˆç‡ï¼ˆ0.5â€“0.7 bits/sampleï¼‰ï¼Œè¿œä¼˜äº RL æ–¹æ³•åœ¨é«˜ç½®ä¿¡åŒºé—´çš„å´©æºƒï¼ˆä» 1.0 â†’ 0.05 bits/sampleï¼‰ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æ¨ç†æ—¶æ‰©å±•å®šå¾‹æ˜¯æ¶æ„æ— å…³çš„**ï¼šCoverageã€Energyã€Latency ç­‰å…³é”®æŒ‡æ ‡ä¸æ¨¡å‹å‚æ•° $N$ã€æ ·æœ¬é¢„ç®— $S$ã€token æ•° $T$ å­˜åœ¨å¯é¢„æµ‹çš„å¹‚å¾‹å…³ç³»ï¼Œä¸”æŒ‡æ•° $\beta \sim 0.7$ å…·æœ‰è·¨æ¶æ„ä¸€è‡´æ€§ã€‚
2. **å¼‚æ„ååŒä¼˜äºåŒæ„äº‘æ¨ç†**ï¼šé€šè¿‡å°† prefillï¼ˆè®¡ç®—å¯†é›†ï¼‰æ˜ å°„åˆ° GPUã€decodeï¼ˆå†…å­˜å¯†é›†ï¼‰æ˜ å°„åˆ° NPUï¼Œå¯åœ¨ä¸ç‰ºç‰²å‡†ç¡®æ€§çš„å‰æä¸‹åŒæ—¶æå‡è¦†ç›–ç‡ã€é™ä½èƒ½è€—ä¸å»¶è¿Ÿã€‚
3. **èƒ½æ•ˆä¸æ€§èƒ½ä¸å†å¯¹ç«‹**ï¼šQEIL å®ç°äº†â€œå››èµ¢â€å±€é¢â€”â€”æ›´é«˜çš„ IPWã€æ›´ä½çš„ Energyã€æ›´å¿«çš„ Latency å’Œæ›´å¼ºçš„ PPPï¼Œæ‰“ç ´äº†ä¼ ç»Ÿä¼˜åŒ–ä¸­çš„ trade-offã€‚
4. **è¾¹ç¼˜æ™ºèƒ½å¯ä»¥â€œå†·å¯åŠ¨â€**ï¼šæ— éœ€é‡æ–°è®­ç»ƒï¼Œä»…é æ¨ç†æ—¶é‡‡æ ·ä¸æ™ºèƒ½è°ƒåº¦å³å¯ä½¿å¼±æ¨¡å‹é€¼è¿‘å¼ºæ¨¡å‹è¡¨ç°ï¼ˆå¦‚ Brown et al. æ‰€ç¤ºï¼‰ï¼ŒQEIL è¿›ä¸€æ­¥æå‡äº†è¿™ä¸€è·¯å¾„çš„èƒ½æ•ˆæé™ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰æ¡†æ¶å‡è®¾è®¾å¤‡é—´é€šä¿¡å¸¦å®½è¶³å¤Ÿï¼ˆå¦‚ PCIe 4.0ï¼‰ï¼Œåœ¨ä½å¸¦å®½è¿æ¥ï¼ˆå¦‚ USBï¼‰åœºæ™¯ä¸‹ I/O å¼€é”€å¯èƒ½æˆä¸ºç“¶é¢ˆï¼›
- å±‚åˆ†é…é‡‡ç”¨è´ªå¿ƒç®—æ³•ï¼Œè™½æ¥è¿‘æœ€ä¼˜ä½†éå…¨å±€æœ€ä¼˜è§£ï¼›
- å®éªŒé›†ä¸­åœ¨é™æ€æ¨¡å‹éƒ¨ç½²ï¼Œå°šæœªè€ƒè™‘è¿è¡Œæ—¶æ¸©åº¦èŠ‚æµã€ç”µæºå¼‚å¸¸ç­‰åŠ¨æ€å¹²æ‰°ï¼›
- å¯¹ MoE æˆ–çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰ç­‰æ–°å…´æ¶æ„çš„æ”¯æŒéœ€è¿›ä¸€æ­¥æ‰©å±•ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³æ›´å¤šå¼‚æ„å¹³å°ï¼šQualcomm Snapdragon NPUã€Google TPUã€NVIDIA Jetson Orin ç­‰ç§»åŠ¨è¾¹ç¼˜è®¾å¤‡ï¼›
- æ”¯æŒåŠ¨æ€é‡è°ƒåº¦ï¼šæ ¹æ®è¿è¡Œæ—¶è®¾å¤‡çŠ¶æ€ï¼ˆæ¸©åº¦ã€è´Ÿè½½ï¼‰è‡ªåŠ¨è°ƒæ•´ä»»åŠ¡åˆ†å¸ƒï¼›
- æ¢ç´¢å¤šèŠ‚ç‚¹åˆ†å¸ƒå¼è¾¹ç¼˜æ¨ç†ï¼šé‡åŒ–è·¨è®¾å¤‡é€šä¿¡å¼€é”€ï¼Œé€‚ç”¨äº IoT é›†ç¾¤ï¼›
- ç»“åˆæ¨¡å‹å‹ç¼©æŠ€æœ¯ï¼šé›†æˆé‡åŒ–ï¼ˆquantizationï¼‰ã€å‰ªæï¼ˆpruningï¼‰ã€è’¸é¦ï¼ˆdistillationï¼‰ä»¥è¿›ä¸€æ­¥é™ä½èƒ½è€—ï¼›
- æ”¯æŒæ–°å‹ LLM æ¶æ„ï¼šå¦‚ Mixture-of-Expertsã€State-Space Models ç­‰ã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> QEIL é¦–æ¬¡å°†**æ¨ç†æ—¶æ‰©å±•å®šå¾‹**ä¸**å¼‚æ„ç¡¬ä»¶è°ƒåº¦**æ·±åº¦èåˆï¼Œè¯æ˜äº†åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šé€šè¿‡**ç»†ç²’åº¦ä»»åŠ¡åˆ†è§£ + è®¾å¤‡æ„ŸçŸ¥è·¯ç”±**ï¼Œå¯ä»¥åœ¨ä¸ç‰ºç‰²å‡†ç¡®æ€§çš„å‰æä¸‹ï¼Œ**ç³»ç»Ÿæ€§åœ°å®ç°è¦†ç›–ç‡ã€èƒ½æ•ˆã€å»¶è¿Ÿä¸ç»æµæ€§çš„å…¨é¢è¶…è¶Š**ï¼Œä¸ºå¯æŒç»­ AI éƒ¨ç½²æä¾›äº†ç†è®ºåŸºç¡€ä¸å®è·µå·¥å…·ã€‚

</details>

---

### 3. [POP: Online Structural Pruning Enables Efficient Inference of Large Foundation Models](https://arxiv.org/abs/2602.06822)

**Authors**: Yi Chen, Wonjin Shin, Shuhong Liu, Tho Mai, Jeongmo Lee, Chuanbo Hua, Kun Wang, Jun Liu, Joo-Young Kim  
**Category**: cs.AI  
**Published**: 2026-02-09  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2602.06822v1  

#### Abstract
Large foundation models (LFMs) achieve strong performance through scaling, yet current structural pruning methods derive fixed pruning decisions during inference, overlooking sparsity patterns that emerge in the autoregressive token generation. In this paper, we propose POP (Partition-guided Online ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**POP: Online Structural Pruning Enables Efficient Inference of Large Foundation Models**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³äº†ä»€ä¹ˆé—®é¢˜

å½“å‰çš„ **structural pruning** æ–¹æ³•åœ¨å¤§æ¨¡å‹æ¨ç†ä¸­å­˜åœ¨ä»¥ä¸‹å…³é”®ç¼ºé™·ï¼š

- **é™æ€å‰ªæç­–ç•¥ï¼ˆStatic Pruningï¼‰**ï¼šå¤§å¤šæ•°æ–¹æ³•åœ¨ **prefilling é˜¶æ®µ** å°±ç¡®å®šå›ºå®šçš„å‰ªææ©ç ï¼ˆpruning maskï¼‰ï¼Œå¹¶åœ¨æ•´ä¸ª **autoregressive decoding** è¿‡ç¨‹ä¸­æ²¿ç”¨è¯¥æ©ç ã€‚
- **å¿½ç•¥åŠ¨æ€ä¸Šä¸‹æ–‡ç¨€ç–æ€§ï¼ˆDynamic Contextual Sparsityï¼‰**ï¼šä¸åŒç”Ÿæˆæ­¥éª¤ä¸­çš„ token æ¿€æ´»æ¨¡å¼ä¼šåŠ¨æ€å˜åŒ–ï¼Œè€Œé™æ€å‰ªææ— æ³•æ•æ‰è¿™ç§ **decoding-time çš„ä¸Šä¸‹æ–‡ä¾èµ–æ€§**ï¼Œå¯¼è‡´åœ¨é•¿æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­æ€§èƒ½ä¸¥é‡ä¸‹é™ã€‚

ä¾‹å¦‚ï¼Œåœ¨ `LLaMA-2-7B` ä¸Šï¼Œé™æ€å‰ªææ–¹æ³• `Tyr` åœ¨çŸ­é—®ç­”ä»»åŠ¡ï¼ˆå¦‚ ARC-Cï¼‰ä¸Šä¿ç•™ 98% å‡†ç¡®ç‡ï¼Œä½†åœ¨é•¿ç”Ÿæˆä»»åŠ¡ï¼ˆå¦‚ MBPPï¼‰ä¸Šä»…ä¿ç•™ 35% æ€§èƒ½ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼š**POP (Partition-guided Online Pruning)**

POP æ˜¯ä¸€ç§ **è½»é‡çº§ã€å³æ’å³ç”¨ï¼ˆplug-and-playï¼‰çš„åœ¨çº¿ç»“æ„åŒ–å‰ªææ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- **ä¸¤é˜¶æ®µå‰ªææœºåˆ¶**ï¼š
  1. **Prefilling é˜¶æ®µ**ï¼šåŸºäºå®Œæ•´ prompt çš„æ¿€æ´»ç»Ÿè®¡ï¼Œå°†æ¯ä¸ª FFN å±‚çš„é€šé“åˆ’åˆ†ä¸ºä¸‰ä¸ªåŒºåŸŸï¼š
     - **Retained Region**ï¼šå§‹ç»ˆä¿ç•™çš„é‡è¦é€šé“ï¼ˆé«˜é‡è¦æ€§ï¼‰
     - **Pruned Region**ï¼šç›´æ¥å‰ªé™¤çš„ä½é‡è¦æ€§é€šé“
     - **Candidate Region**ï¼šä¸­é—´ä¸ç¡®å®šæ€§é€šé“ï¼Œä¾›åç»­åŠ¨æ€é€‰æ‹©
  2. **Decoding é˜¶æ®µ**ï¼šåœ¨æ¯ä¸€æ­¥ç”Ÿæˆæ—¶ï¼Œ**ä»…å¯¹ Candidate åŒºåŸŸé‡æ–°è®¡ç®—é‡è¦æ€§**ï¼Œå¹¶åŠ¨æ€é€‰æ‹©å­é›†å‚ä¸è®¡ç®—ï¼Œå®ç° **fine-grained context-conditioned pruning**ã€‚

- **æ— éœ€ä»»ä½•é¢„å¤„ç†**ï¼šä¸ä¾èµ– offline calibrationã€retraining æˆ– predictor learningï¼Œå®Œå…¨åœ¨æ¨ç†æ—¶å®Œæˆã€‚

### â­ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ä¼˜åŠ¿ç»´åº¦ | è¯´æ˜ |
|--------|------|
| **åŠ¨æ€é€‚åº”æ€§** | æ”¯æŒåœ¨ decoding é˜¶æ®µæ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€è°ƒæ•´å‰ªæå†³ç­–ï¼Œæ˜¾è‘—æå‡ç”Ÿæˆä»»åŠ¡æ€§èƒ½ |
| **ä½å¼€é”€** | ä»…å¯¹å€™é€‰åŒºåŸŸè¿›è¡Œé‡è¯„ä¼°ï¼Œé¿å…å…¨é€šé“é‡è®¡ç®—ï¼ŒFLOPs å¼€é”€ä»…å¢åŠ çº¦ **2.85%~3.48%** |
| **é€šç”¨æ€§å¼º** | é€‚ç”¨äº LLMsã€MoEã€VLMs ç­‰å¤šç§å¤§æ¨¡å‹æ¶æ„ |
| **éƒ¨ç½²å‹å¥½** | æ— éœ€è®­ç»ƒæˆ–æ ¡å‡†ï¼Œå³æ’å³ç”¨ï¼Œé€‚åˆå®é™…éƒ¨ç½² |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†

#### è¯­è¨€æ¨¡å‹ï¼ˆLLMs & MoEsï¼‰
- **QA ä»»åŠ¡**ï¼šBoolQ, RTE, HellaSwag, WinoGrande, ARC-Easy, ARC-Challenge, OpenBookQA
- **ç”Ÿæˆä»»åŠ¡**ï¼šCoQA, MBPP, NQ-Open, HumanEval, GSM8K
- **åŸºå‡†æ¡†æ¶**ï¼š`LM-Evaluation-Harness`

#### è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰
- **VQA ä»»åŠ¡**ï¼šPOPE, OK-VQA, GQA, ScienceQA, MME
- **åŸºå‡†æ¡†æ¶**ï¼š`LMMs-Eval`

#### è¯­è¨€å»ºæ¨¡èƒ½åŠ›
- **Wikitext**ï¼šç”¨äºè¯„ä¼° perplexity

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡

| ç±»åˆ« | æŒ‡æ ‡ |
|-----|------|
| LLM QA | Accuracy |
| LLM Generation | F1 Score (CoQA), Pass@1 (MBPP/HumanEval), Exact Match (NQ/GSM8K) |
| VLM VQA | F1, Exact Match, Perception Score (MME) |
| ç»Ÿä¸€å½’ä¸€åŒ– | æ‰€æœ‰æŒ‡æ ‡è½¬æ¢ä¸ºç™¾åˆ†åˆ¶åå–å®å¹³å‡ï¼ˆmacro averageï¼‰ |

### ğŸ” å®éªŒè®¾ç½®

- **å‰ªææ¯”ä¾‹**ï¼š20% å’Œ 40%
- **ç¡¬ä»¶**ï¼šRTX A6000 é›†ç¾¤
- **æ‰¹å¤§å°**ï¼šLLM ä¸º 10ï¼ŒVLM ä¸º 1
- **å‰ªæç›®æ ‡**ï¼šä»…å‰ªæ FFN å±‚ï¼Œä¿ç•™ Attention å±‚
- **å…¬å¹³æ¯”è¾ƒ**ï¼šè°ƒæ•´ FFN å†…éƒ¨å‰ªææ¯”ä¾‹ä»¥åŒ¹é…æ•´ä½“å‚æ•°å‡å°‘ç›®æ ‡ï¼ˆè§ Table 8ï¼‰

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | æ˜¯å¦åœ¨çº¿ | æ˜¯å¦éœ€è¦æ ¡å‡† | æ˜¯å¦éœ€è®­ç»ƒ | æ˜¯å¦éœ€é¢„æµ‹å™¨ |
|------|---------|-------------|-----------|------------|
| **Wanda-sp** | âŒ | âœ… | âŒ | âŒ |
| **FLAP** | âŒ | âœ… | âŒ | âŒ |
| **Tyr** | âŒ | âœ… | âœ…ï¼ˆè¿›åŒ–æœç´¢ï¼‰ | âŒ |
| **Probe Pruning** | âœ… | âœ… | âŒ | âŒ |
| **POP (ours)** | âœ… | âŒ | âŒ | âŒ |

> âœ… è¡¨ç¤ºæ”¯æŒ / éœ€è¦ï¼›âŒ è¡¨ç¤ºä¸æ”¯æŒ / ä¸éœ€è¦

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆTable 2, 3, 4ï¼‰

#### âœ… LLMs å¹³å‡æ€§èƒ½ï¼ˆ20% å‰ªæï¼‰

| æ–¹æ³• | QA ä»»åŠ¡å¹³å‡å‡†ç¡®ç‡ â†‘ | ç”Ÿæˆä»»åŠ¡å¹³å‡å‡†ç¡®ç‡ â†‘ |
|------|------------------|--------------------|
| Dense | 65.40% | 45.77% |
| Wanda-sp | 43.42% | 6.96% |
| FLAP | 49.56% | 12.90% |
| Probe Pruning | 61.29% | 32.13% |
| Tyr | 63.72% | 29.97% |
| **POP (ours)** | **62.34%** | **42.48%** |

> **POP åœ¨ç”Ÿæˆä»»åŠ¡ä¸Šå¤§å¹…é¢†å…ˆ**ï¼ˆ+10.35% vs Probe Pruning, +29.58% vs FLAPï¼‰

#### âœ… MoE æ¨¡å‹è¡¨ç°ï¼ˆTable 3ï¼‰

- åœ¨ 20% å‰ªæä¸‹ï¼ŒPOP åœ¨ç”Ÿæˆä»»åŠ¡ä¸Šå¹³å‡è¾¾åˆ° **38.65%**ï¼Œè¿œè¶… Wanda-spï¼ˆ15.71%ï¼‰ã€FLAPï¼ˆ0.00%ï¼‰ç­‰åŸºçº¿
- åœ¨ 40% æç«¯å‰ªæä¸‹ä»ä¿æŒé²æ£’æ€§ï¼Œè€Œå…¶ä»–æ–¹æ³•æ€§èƒ½å´©æºƒ

#### âœ… VLMs è¡¨ç°ï¼ˆTable 4ï¼‰

| æ–¹æ³• | Qwen2-VL (20%) | Qwen2.5-VL (20%) |
|------|----------------|-----------------|
| Wanda-sp | 7.86% | 3.71% |
| FLAP | 46.74% | 42.53% |
| **POP (ours)** | **59.94%** | **59.46%** |

> **POP æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿**ï¼Œæ¥è¿‘ dense æ¨¡å‹ï¼ˆ62.14%/60.68%ï¼‰

### âš™ï¸ æ¨ç†æ•ˆç‡ï¼ˆTable 5ï¼‰

åœ¨ `Llama2-7B` ä¸Šï¼š

| æ–¹æ³• | E2E æ¨ç†é€Ÿåº¦æå‡ | MLP å»¶è¿Ÿé™ä½ |
|------|----------------|-------------|
| Probe Pruning (20%) | 1.13Ã— | 1.20Ã— |
| **POP (20%)** | **1.14Ã—** | **1.29Ã—** |
| Probe Pruning (40%) | 1.42Ã— | 1.77Ã— |
| **POP (40%)** | **1.38Ã—** | **1.96Ã—** |

> **POP åœ¨ä¸å‰ªæ Attention çš„å‰æä¸‹ï¼Œä»å®ç°æ›´é«˜ MLP åŠ é€Ÿæ¯”**

### ğŸ” æ¶ˆèå®éªŒï¼ˆTable 6, Figure 4ï¼‰

#### æ¶ˆèå¯¹æ¯”ï¼ˆTable 6ï¼‰

| å˜ä½“ | ç”Ÿæˆä»»åŠ¡å¹³å‡å‡†ç¡®ç‡ | MLP FLOPs å¼€é”€ |
|------|------------------|--------------|
| Variant (1)ï¼ˆå›ºå®šæ©ç ï¼‰ | 23.40% | 0.00% |
| Variant (2)ï¼ˆå…¨é€šé“é‡è¯„ä¼°ï¼‰ | 26.56% | +33.1% |
| **POP (ours)** | **24.12%** | **+2.85%** |

> **POP åœ¨æä½å¼€é”€ä¸‹å®ç°æ€§èƒ½æå‡ï¼Œå¹³è¡¡äº†æ•ˆç‡ä¸ç²¾åº¦**

#### åˆ†åŒºå®½åº¦ï¼ˆPartition Fraction Î³ï¼‰å½±å“ï¼ˆFigure 4ï¼‰

- Î³ è¶Šå¤§ â†’ å€™é€‰åŒºåŸŸè¶Šå¤§ â†’ å‡†ç¡®ç‡è¶Šé«˜ï¼Œä½†è®¡ç®—å¼€é”€ä¸Šå‡
- é»˜è®¤è®¾ç½® **Î³ = 0.1** åœ¨æ€§èƒ½ä¸æ•ˆç‡é—´å–å¾—æœ€ä½³å¹³è¡¡

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **é™æ€å‰ªæåœ¨ç”Ÿæˆä»»åŠ¡ä¸­å¤±æ•ˆ**ï¼šç”±äºæ— æ³•é€‚åº” decoding æ—¶çš„ä¸Šä¸‹æ–‡å˜åŒ–ï¼Œå¯¼è‡´é•¿åºåˆ—ç”Ÿæˆæ€§èƒ½æ€¥å‰§ä¸‹é™ã€‚
2. **åŠ¨æ€å‰ªæè‡³å…³é‡è¦**ï¼š**online pruning** èƒ½æœ‰æ•ˆæ•æ‰ decoding-time çš„ contextual sparsityï¼Œæ˜¾è‘—æå‡ç”Ÿæˆè´¨é‡ã€‚
3. **æ— éœ€å¤æ‚è®¾è®¡ä¹Ÿèƒ½é«˜æ•ˆ**ï¼šé€šè¿‡ **partition-guided** ç­–ç•¥ï¼Œä»…å¯¹å°èŒƒå›´å€™é€‰é€šé“è¿›è¡Œé‡è¯„ä¼°ï¼Œå³å¯å®ç°é«˜æ€§èƒ½åŠ¨æ€å‰ªæã€‚
4. **é€šç”¨æ€§å¼º**ï¼šPOP åœ¨ LLMsã€MoEsã€VLMs ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼ŒéªŒè¯äº†å…¶è·¨æ¶æ„é€‚ç”¨æ€§ã€‚
5. **éƒ¨ç½²å‹å¥½**ï¼šæ— éœ€æ ¡å‡†ã€è®­ç»ƒæˆ–é¢„æµ‹å™¨ï¼ŒçœŸæ­£å®ç°â€œå³æ’å³ç”¨â€ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

- **ä»…å‰ªæ FFN å±‚**ï¼šæœªä¼˜åŒ– Attention å±‚ï¼Œå¯èƒ½é™åˆ¶æé™åŠ é€Ÿæ½œåŠ›ã€‚
- **å€™é€‰åŒºåŸŸå¤§å°éœ€è°ƒå‚**ï¼šè™½ç„¶é»˜è®¤ Î³=0.1 è¡¨ç°è‰¯å¥½ï¼Œä½†æœ€ä¼˜å€¼å¯èƒ½å› æ¨¡å‹è€Œå¼‚ã€‚
- **å°šæœªé›†æˆåˆ°ç”Ÿäº§çº§æ¨ç†å¼•æ“**ï¼šç›®å‰ä¸ºç ”ç©¶åŸå‹ï¼Œéœ€è¿›ä¸€æ­¥å·¥ç¨‹ä¼˜åŒ–ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

- æ‰©å±•è‡³ **Attention å±‚çš„åœ¨çº¿å‰ªæ**
- ç»“åˆ **KV Cache å‹ç¼©** å®ç°ç«¯åˆ°ç«¯æ¨ç†åŠ é€Ÿ
- æ¢ç´¢ **è‡ªé€‚åº” Î³ è°ƒæ•´æœºåˆ¶**ï¼Œæ ¹æ®è¾“å…¥åŠ¨æ€æ§åˆ¶å€™é€‰åŒºåŸŸå¤§å°
- ä¸ **é‡åŒ–ï¼ˆQuantizationï¼‰**ã€**ä½ç§©åˆ†è§£ï¼ˆLow-Rank Adaptationï¼‰** ç­‰æŠ€æœ¯è”åˆä½¿ç”¨ï¼Œå®ç°å¤šç»´å‹ç¼©

---

## âœ… æ€»ç»“

**POP** æå‡ºäº†ä¸€ç§æ–°é¢–ä¸”å®ç”¨çš„ **online structural pruning** æ¡†æ¶ï¼ŒæˆåŠŸè§£å†³äº†ä¼ ç»Ÿé™æ€å‰ªæåœ¨ **autoregressive generation** ä¸­çš„æ€§èƒ½ç“¶é¢ˆã€‚å…¶å®éªŒå……åˆ†è¯æ˜ï¼š

> **åœ¨æä½è®¡ç®—å¼€é”€ï¼ˆ<4% FLOPs å¢åŠ ï¼‰ä¸‹ï¼ŒPOP æ˜¾è‘—æå‡äº†å‰ªææ¨¡å‹åœ¨ç”Ÿæˆä»»åŠ¡ä¸Šçš„å‡†ç¡®æ€§ï¼Œå¹¶åœ¨ LLMsã€MoEsã€VLMs ä¸Šå®ç°äº† SOTA æ€§èƒ½ï¼ŒåŒæ—¶å…·å¤‡å‡ºè‰²çš„éƒ¨ç½²å‹å¥½æ€§ã€‚**

è¯¥å·¥ä½œä¸ºå¤§æ¨¡å‹é«˜æ•ˆæ¨ç†æä¾›äº†æ–°çš„èŒƒå¼ï¼Œå¼ºè°ƒäº† **context-conditioned dynamic pruning** åœ¨çœŸå®åº”ç”¨åœºæ™¯ä¸­çš„å¿…è¦æ€§ã€‚

</details>

---

### 4. [Mapping Gemma3 onto an Edge Dataflow Architecture](https://arxiv.org/abs/2602.06063)

**Authors**: Shouyu Du, Miaoxiang Yu, Zhiheng Ni, Jillian Cai, Qing Yang, Tao Wei, Zhenyu Xu  
**Category**: cs.DC  
**Published**: 2026-02-09  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2602.06063v1  

#### Abstract
We present the first end-to-end deployment of the Gemma3 family of large language and vision models on a tiled edge dataflow architecture (AMD Ryzen AI NPU). Our work introduces a set of hardware-aware techniques. For prefill, we introduce an efficient dequantization engine, optimize tiled matrix mu...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠMapping Gemma3 onto an Edge Dataflow Architectureã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
æœ¬æ–‡è§£å†³äº†åœ¨**è¾¹ç¼˜ç«¯ tiled dataflow æ¶æ„ï¼ˆAMD Ryzen AI NPUï¼‰ä¸Šå®ç° Gemma3 å¤§è¯­è¨€æ¨¡å‹å’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ç«¯åˆ°ç«¯é«˜æ•ˆæ¨ç†**çš„é—®é¢˜ã€‚å°½ç®¡ä¸»æµå‚å•†å·²å¼€å§‹é›†æˆ NPU åˆ°ç»ˆç«¯è®¾å¤‡ä¸­ï¼Œä½†ç›®å‰å°šæ— å®Œæ•´ã€é«˜æ•ˆçš„ LLM/VLM éƒ¨ç½²æ–¹æ¡ˆèƒ½å……åˆ†å‘æŒ¥å…¶ç¡¬ä»¶ç‰¹æ€§ã€‚

å…·ä½“æŒ‘æˆ˜åŒ…æ‹¬ï¼š
- **å†…å­˜å¸¦å®½ç“¶é¢ˆ**ï¼šå°¤å…¶æ˜¯åœ¨ decoding é˜¶æ®µï¼ŒKV Cache çš„é¢‘ç¹è®¿é—®å¯¼è‡´æ€§èƒ½å—é™ã€‚
- **è®¡ç®—ä¸è®¿å­˜ä¸åŒ¹é…**ï¼šä¼ ç»Ÿéƒ¨ç½²æ–¹å¼æœªèƒ½å……åˆ†åˆ©ç”¨ NPU çš„ tile ç»“æ„å’Œé«˜å¸¦å®½æ•°æ®æµèƒ½åŠ›ã€‚
- **é‡åŒ–ä¸æŠ•å½±å¼€é”€å¤§**ï¼šdequantization å’Œ projection åˆ†ç¦»é€ æˆé¢å¤–å»¶è¿Ÿã€‚

---

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯

ä½œè€…æå‡ºäº†ä¸€å¥—**ç¡¬ä»¶æ„ŸçŸ¥çš„ç³»ç»Ÿçº§ä¼˜åŒ–æŠ€æœ¯**ï¼Œè¦†ç›– prefill å’Œ decoding ä¸¤ä¸ªé˜¶æ®µï¼Œå¹¶é’ˆå¯¹ vision tower è¿›è¡Œé€‚é…ï¼š

#### ï¼ˆ1ï¼‰**Q4NX** â€”â€” NPU å‹å¥½çš„ç´§å‡‘é‡åŒ–æ ¼å¼
- è®¾è®¡äº†ä¸€ç§ä¸“ä¸º Ryzen AI NPU å®šåˆ¶çš„ **4-bit é‡åŒ–æ ¼å¼ Q4NX (Quantized 4-bit NPU eXpress)**ã€‚
- æ”¯æŒ block-wise é‡åŒ–ï¼ˆgroup size=32ï¼‰ï¼Œä¿ç•™ scale å’Œ offsetï¼Œä¸”é¢„è½¬æ¢ä¸º bf16 ä»¥å‡å°‘è¿è¡Œæ—¶å¼€é”€ã€‚
- å—å¤§å°ä¸º 32Ã—256ï¼Œé€‚é… NPU å†…å­˜å±‚çº§ï¼Œé™ä½ç‰‡ä¸Šå­˜å‚¨å‹åŠ›ã€‚

#### ï¼ˆ2ï¼‰**FlowQKV** â€”â€” é¢å‘ prefill çš„æµæ°´çº¿æ³¨æ„åŠ›æœºåˆ¶
- å°†è¾“å…¥åºåˆ—åˆ†å—å¤„ç†ï¼ˆchunked processingï¼‰ï¼Œé€šè¿‡æ•°å€¼ç¨³å®šçš„ç´¯ç§¯ç­–ç•¥å®ç°å¢é‡ attentionã€‚
- åˆ©ç”¨ NPU çš„ dataflow æ¶æ„ï¼Œåœ¨å¤šä¸ª Compute Tilesï¼ˆCTsï¼‰é—´å¹¶è¡Œå¤„ç†ä¸åŒ KV chunksã€‚
- å¼•å…¥åŒç¼“å†² DMA å®ç°æ•°æ®ä¼ è¾“ä¸è®¡ç®—é‡å ï¼Œæå‡ DRAM å¸¦å®½åˆ©ç”¨ç‡ã€‚
- åŒ…å«ä¸¤ä¸ªå˜ä½“ï¼š
  - **FlowQKV-SWA**ï¼šæ”¯æŒæ»‘åŠ¨çª—å£æ³¨æ„åŠ›ï¼ˆSliding Window Attentionï¼‰
  - **FlowQKV-NCA**ï¼šç”¨äº vision transformer çš„éå› æœæ³¨æ„åŠ›

#### ï¼ˆ3ï¼‰**FusedDQP** â€”â€” èåˆåé‡åŒ–ä¸æŠ•å½±æ“ä½œ
- åœ¨ decoding é˜¶æ®µå°† **dequantization ä¸ MVMï¼ˆMatrix-Vector Multiplicationï¼‰èåˆæˆå•ä¸ª kernel**ã€‚
- å‡å°‘ä¸€æ¬¡å†…å­˜è¯»å†™ï¼Œæœ€å¤§åŒ–å¯„å­˜å™¨å¤ç”¨ï¼Œæ˜¾è‘—é™ä½æŠ•å½±å±‚å»¶è¿Ÿã€‚

#### ï¼ˆ4ï¼‰**FlowKV** â€”â€” é¢å‘ decoding çš„é«˜æ•ˆ KV ç¼“å­˜è°ƒåº¦
- å¯¹ KV cache åŒæ ·é‡‡ç”¨ chunked æµæ°´çº¿å¤„ç†ã€‚
- ä½¿ç”¨ä¸¤ä¸ª CT æ„å»º pipelineï¼šCT0 å¤„ç† key å’Œ attention scoreï¼ŒCT1 å¤„ç† value ç§¯ç´¯ã€‚
- ä¸­é—´ç»“æœé€šè¿‡ AIE on-chip memory ç›´æ¥ä¼ é€’ï¼Œé¿å…å›å†™ä¸»å­˜ã€‚
- æ”¯æŒ **FlowKV-SWA** å˜ä½“ä»¥å…¼å®¹å±€éƒ¨æ³¨æ„åŠ›å±‚ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **æ•ˆç‡** | å……åˆ†åˆ©ç”¨ NPU çš„ tiled dataflow æ¶æ„ï¼Œå®ç°é«˜å†…å­˜å¸¦å®½åˆ©ç”¨ç‡ï¼ˆUdï¼‰ |
| **ç²¾åº¦** | ä¸ä¿®æ”¹æ¨¡å‹ç»“æ„æˆ–å‚æ•°ï¼Œä¿æŒåŸå§‹æ¨¡å‹å‡†ç¡®æ€§ |
| **é€šç”¨æ€§** | æ‰€ææ–¹æ³•å¯æ¨å¹¿è‡³å…¶ä»–åŸºäº tile + DMA + broadcast çš„ dataflow åŠ é€Ÿå™¨ï¼ˆå¦‚ Cerebrasã€AMD ACAPï¼‰ |
| **åŠŸè€—** | æ˜¾è‘—ä¼˜äº iGPU å’Œ CPUï¼Œé€‚åˆè¾¹ç¼˜ä½åŠŸè€—åœºæ™¯ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
- å¹¶æœªä½¿ç”¨ä¼ ç»Ÿâ€œæ•°æ®é›†â€è¿›è¡Œè®­ç»ƒæˆ–å¾®è°ƒã€‚
- å®éªŒåŸºäº **Gemma3 å®˜æ–¹å‘å¸ƒçš„å¼€æºæ¨¡å‹æƒé‡**ï¼ˆ1B å’Œ 4B å‚æ•°ç‰ˆæœ¬ï¼‰ï¼Œå…¶ä¸­ 4B ç‰ˆæœ¬åŒ…å« vision towerï¼ˆSigLIP ViTï¼‰ã€‚
- è¾“å…¥æµ‹è¯•åºåˆ—é•¿åº¦ä» **1K åˆ° 128K tokens** ä¸ç­‰ï¼Œæ¶µç›–çŸ­ä¸Šä¸‹æ–‡åˆ°è¶…é•¿ä¸Šä¸‹æ–‡åœºæ™¯ã€‚

---

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### ç¡¬ä»¶å¹³å°
- **ç›®æ ‡è®¾å¤‡**ï¼šAMD Ryzen AI 7 350 NPUï¼ˆä»£å· â€œKraken Pointâ€ï¼‰ï¼Œé›†æˆäº ASRock 4X4 BOX-AI350 mini-PC
- **æ¶æ„ç»†èŠ‚**ï¼š
  - 32 ä¸ª Compute Tilesï¼ˆ8åˆ—Ã—4è¡Œï¼‰
  - XDNA2 æ¶æ„ï¼Œæ”¯æŒ VLIW å’Œ direct tile-to-tile communication
  - L1ï¼ˆ64KB/CTï¼‰ã€L2ï¼ˆ512KB/MTï¼‰ã€DDR5 5600MHz
- **è½¯ä»¶æ ˆ**ï¼šåŸºäº AMD çš„ AIE-MLIR å·¥å…·é“¾ + IRON Python æ¥å£å¼€å‘åº•å±‚ kernel

#### åŸºçº¿å¯¹æ¯”
- **iGPU baseline**ï¼šä½¿ç”¨ LM Studioï¼ˆåŸºäº Element Labsï¼‰
- **CPU baseline**ï¼šä½¿ç”¨ Ollama
- æ‰€æœ‰æµ‹è¯•å‡åœ¨åŒä¸€ç‰©ç†å¹³å°ä¸Šæ‰§è¡Œï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒ

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **TTFT (Time to First Token)** | Prefill é˜¶æ®µè€—æ—¶ï¼Œåæ˜  prompt å¤„ç†é€Ÿåº¦ |
| **TPS (Tokens Per Second)** | Decoding ååé‡ |
| **Power Consumption (W)** | å„ç»„ä»¶å¹³å‡åŠŸè€—ï¼ˆé€šè¿‡ HWiNFO ç›‘æ§ï¼‰ |
| **TPS/W** | èƒ½æ•ˆæ¯”ï¼Œè¡¡é‡æ¯ç“¦ç‰¹ç”µåŠ›äº§ç”Ÿçš„è¾“å‡º token æ•° |
| **Ud (Utilization of DRAM bandwidth)** | å®é™…è¾¾åˆ°çš„å†…å­˜å¸¦å®½å ç†è®ºå³°å€¼çš„æ¯”ä¾‹ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Tables 1â€“4ï¼‰

#### âœ… Prefill æ€§èƒ½ï¼ˆTTFTï¼Œè¶Šå°è¶Šå¥½ï¼‰

| æ¨¡å‹ | åºåˆ—é•¿åº¦ | NPU (s) | iGPU (s) | CPU (s) |
|------|----------|---------|----------|--------|
| Gemma3-1B | 32K | 21.0 | 95.1 | 165.0 |
| Gemma3-4B | 32K | 50.9 | 265.0 | 832.0 |

> â†’ **æœ€é«˜è¾¾ 33.5Ã— å¿«äº CPUï¼Œ5.2Ã— å¿«äº iGPU**

#### âœ… Decoding æ€§èƒ½ï¼ˆTPSï¼Œè¶Šå¤§è¶Šå¥½ï¼‰

| æ¨¡å‹ | åºåˆ—é•¿åº¦ | NPU (TPS) | iGPU (TPS) | CPU (TPS) |
|------|----------|-----------|------------|----------|
| Gemma3-1B | 1K | 34.3 | 38.0 | 41.9 |
| Gemma3-1B | 32K | 23.1 | 13.6 | 33.8 |
| Gemma3-4B | 1K | 14.4 | 18.6 | 14.6 |
| Gemma3-4B | 128K | 9.2 | 1.9 | 4.1 |

> â†’ åœ¨é•¿åºåˆ—ä¸‹ NPU è¡¨ç°æ›´ä¼˜ï¼Œ**æœ€é«˜è¾¾ 4.8Ã— å¿«äº iGPUï¼Œ2.2Ã— å¿«äº CPU**

#### âœ… Vision Tower æ€§èƒ½ï¼ˆä»… 4B æ¨¡å‹ï¼‰
- **NPU**: 4.41s  
- **iGPU**: 7.45s (**1.7Ã— æ…¢**)  
- **CPU**: 38.55s (**8.7Ã— æ…¢**)

---

### åŠŸè€—ä¸èƒ½æ•ˆè¡¨ç°ï¼ˆTable 5 + Figure 12ï¼‰

| åœºæ™¯ | ç»„ä»¶ | å¹³å‡åŠŸè€— (W) |
|------|------|-------------|
| NPU Decoding (1B) | CPU+iGPU+NPU | 4.6 W |
| iGPU Decoding (1B) | CPU+iGPU | 53 W |
| CPU Decoding (1B) | CPU | 29 W |

> â†’ NPU è¿è¡Œæ—¶èŠ¯ç‰‡æ¸©åº¦å§‹ç»ˆä½äº 50Â°Cï¼Œè€Œ iGPU/CPU è¾¾åˆ° 98â€“100.5Â°C

#### èƒ½æ•ˆæ¯”ï¼ˆTPS/Wï¼‰æå‡æƒŠäººï¼š
- **Prefill é˜¶æ®µ**ï¼š
  - ç›¸æ¯” iGPUï¼š**æœ€é«˜ 67.2Ã—**
  - ç›¸æ¯” CPUï¼š**æœ€é«˜ 222.9Ã—**
- **Decoding é˜¶æ®µ**ï¼š
  - ç›¸æ¯” iGPUï¼š**æœ€é«˜ 60.6Ã—**
  - ç›¸æ¯” CPUï¼š**æœ€é«˜ 13.2Ã—**

> å¦‚å›¾ 12 æ‰€ç¤ºï¼Œéšç€åºåˆ—å¢é•¿ï¼ŒNPU çš„ TPS/W ä¼˜åŠ¿æŒç»­æ‰©å¤§ã€‚

---

### æ¶ˆèå®éªŒåˆ†æï¼ˆéšå«åœ¨è®¾è®¡åŸç†ä¸­ï¼‰

è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»æ–¹æ³•æè¿°å¯æ¨æ–­ä»¥ä¸‹å…³é”®å› ç´ å½±å“æ€§èƒ½ï¼š

| æŠ€æœ¯ | å½±å“ |
|------|------|
| **Q4NX + FusedDQP** | å‡å°‘ decode æŠ•å½±å±‚å†…å­˜è®¿é—®æ¬¡æ•°ï¼Œæå‡ MVM æ•ˆç‡ |
| **FlowQKV/FlowKV + chunking** | å®ç°è®¡ç®—ä¸é€šä¿¡é‡å ï¼Œæé«˜ Ud è‡³æ¥è¿‘é¥±å’Œ |
| **Double Buffering + DMA Streaming** | éšè—æ•°æ®æ¬è¿å»¶è¿Ÿï¼Œä½¿ kernel æ‰§è¡Œè¿ç»­åŒ– |
| **Tile-aware scheduling** | åŒ¹é…ç¡¬ä»¶æ‹“æ‰‘ï¼Œå‡å°‘è·¨ tile æ•°æ®ç§»åŠ¨å¼€é”€ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°

1. âœ… **ç°ä»£è¾¹ç¼˜ NPU å®Œå…¨æœ‰èƒ½åŠ›é«˜æ•ˆè¿è¡Œå¤§å‹ LLM/VLM æ¨¡å‹**ï¼Œæ— éœ€ç‰ºç‰²å‡†ç¡®ç‡ã€‚
2. âœ… **dataflow æ¶æ„ç‰¹åˆ«é€‚åˆ transformer ç±»æ¨¡å‹çš„ attention å’Œ MM è¿ç®—**ï¼Œåªè¦è°ƒåº¦å¾—å½“å³å¯é€¼è¿‘å†…å­˜å¸¦å®½æé™ã€‚
3. âœ… **ç¡¬ä»¶æ„ŸçŸ¥çš„ kernel è®¾è®¡ï¼ˆå¦‚ FlowQKVã€FusedDQPï¼‰æ˜¯é‡Šæ”¾ NPU æ€§èƒ½çš„å…³é”®**ï¼Œè¿œèƒœäºç›´æ¥ç§»æ¤ CUDA é£æ ¼ä»£ç ã€‚
4. âœ… **NPU åœ¨èƒ½æ•ˆæ–¹é¢å…·æœ‰å‹å€’æ€§ä¼˜åŠ¿**ï¼Œå°¤å…¶é€‚ç”¨äºå¯¹åŠŸè€—æ•æ„Ÿçš„ç»ˆç«¯è®¾å¤‡ï¼ˆç¬”è®°æœ¬ã€æ‰‹æœºç­‰ï¼‰ã€‚
5. âœ… æ‰€ææ–¹æ³•å…·å¤‡è‰¯å¥½æ³›åŒ–æ€§ï¼Œå¯ç”¨äºæœªæ¥æ›´é«˜å¸¦å®½ã€æ›´å¤š CTs çš„ NPU å‡çº§ç‰ˆã€‚

---

### æ–¹æ³•çš„å±€é™æ€§

| å±€é™ | è¯´æ˜ |
|------|------|
| **ä¾èµ–ç‰¹å®šç¡¬ä»¶æ¶æ„** | å½“å‰å®ç°æ·±åº¦ç»‘å®š AMD XDNA2 æ¶æ„ï¼Œç§»æ¤åˆ°å…¶ä»– vendorï¼ˆå¦‚ Intel NPU æˆ– Apple ANEï¼‰éœ€é‡æ–°è®¾è®¡ |
| **æœªæ”¯æŒåŠ¨æ€ batching** | å½“å‰ä¸º single-sequence æ¨ç†ï¼Œå°šæœªæ‰©å±•åˆ°å¤šç”¨æˆ·å¹¶å‘åœºæ™¯ |
| **vision tower æœªé‡åŒ–** | å½“å‰ vision tower æƒé‡ä»ä¸º fp16/bf16ï¼Œæœªåº”ç”¨ Q4NXï¼Œå­˜åœ¨è¿›ä¸€æ­¥å‹ç¼©ç©ºé—´ |
| **å·¥å…·é“¾å°šæœªå¼€æº** | MLIR kernel å®ç°æš‚æœªå…¬å¼€ï¼ˆGitHub é“¾æ¥åŒ¿åéšè—ï¼‰ï¼Œé™åˆ¶ç¤¾åŒºå¤ç° |

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. **æ„å»ºè‡ªåŠ¨åŒ–ç¼–è¯‘æµç¨‹**ï¼šå°† FlowQKV/FlowKV/FusedDQP å°è£…è¿›é«˜å±‚ compilerï¼ˆå¦‚ IREEã€MLIR-HLOï¼‰ï¼Œå®ç°è‡ªåŠ¨æ˜ å°„ã€‚
2. **æ”¯æŒ dynamic batching ä¸ continuous batching**ï¼šæå‡æœåŠ¡å™¨çº§ååèƒ½åŠ›ã€‚
3. **æ‰©å±•è‡³å¤šæ¨¡æ€é•¿è§†é¢‘ç†è§£ä»»åŠ¡**ï¼šç»“åˆ temporal modelingï¼Œåº”ç”¨äº edge video-VLMã€‚
4. **æ¢ç´¢æ›´ä½æ¯”ç‰¹é‡åŒ–ï¼ˆå¦‚ INT2ã€FP8ï¼‰**ï¼šè¿›ä¸€æ­¥å‹ç¼©æ¨¡å‹å°ºå¯¸ï¼Œé€‚åº”åµŒå…¥å¼åœºæ™¯ã€‚
5. **å¼€æ”¾å·¥å…·é“¾ä¸ benchmark suite**ï¼šæ¨åŠ¨ NPU ä¸Š LLM ç”Ÿæ€å‘å±•ã€‚

---

## æ€»ç»“

> æœ¬æ–‡é¦–æ¬¡å®ç°äº† **Gemma3 ç³»åˆ— LLM/VLM åœ¨è¾¹ç¼˜ dataflow NPU ä¸Šçš„ç«¯åˆ°ç«¯é«˜æ•ˆéƒ¨ç½²**ï¼Œæå‡ºäº†åŒ…æ‹¬ **Q4NXã€FlowQKVã€FusedDQPã€FlowKV** åœ¨å†…çš„ä¸€æ•´å¥—ç¡¬ä»¶æ„ŸçŸ¥ä¼˜åŒ–æŠ€æœ¯ï¼Œåœ¨ **é€Ÿåº¦å’Œèƒ½æ•ˆä¸Šå…¨é¢è¶…è¶Š iGPU å’Œ CPU åŸºçº¿**ï¼Œä¸ºæœªæ¥è¾¹ç¼˜ AI æ¨ç†æä¾›äº†å¯å¤ç”¨çš„è®¾è®¡èŒƒå¼ã€‚

</details>

---

### 5. [FCDP: Fully Cached Data Parallel for Communication-Avoiding Large-Scale Training](https://arxiv.org/abs/2602.06499)

**Authors**: Gyeongseo Park, Eungyeong Lee, Song-woo Sok, Myung-Hoon Cha, Kwangwon Koh, Baik-Song An, Hongyeon Kim, Ki-Dong Kang  
**Category**: cs.DC  
**Published**: 2026-02-09  
**Score**: 11.5  
**Type**: new  
**ArXiv ID**: 2602.06499v1  

#### Abstract
Training billion-parameter models requires distributing model states across GPUs using fully sharded data parallel (i.e., ZeRO-3). While ZeRO-3 succeeds on clusters with high-bandwidth NVLink and InfiniBand interconnects, researchers with commodity hardware face severe inter-node all-gather bottlene...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šFCDP: Fully Cached Data Parallel for Communication-Avoiding Large-Scale Training

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
åœ¨å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆå¦‚æ•°åäº¿å‚æ•°ï¼‰çš„è®­ç»ƒä¸­ï¼Œ**Fully Sharded Data Parallelism**ï¼ˆå¦‚ ZeRO-3ï¼‰é€šè¿‡è·¨ GPU åˆ†ç‰‡å­˜å‚¨æ¨¡å‹çŠ¶æ€æ¥é™ä½å•å¡å†…å­˜å ç”¨ã€‚ç„¶è€Œï¼Œåœ¨**å¸¦å®½å—é™çš„é€šç”¨ç¡¬ä»¶é›†ç¾¤**ï¼ˆcommodity clustersï¼‰ä¸Šï¼Œé¢‘ç¹çš„è·¨èŠ‚ç‚¹ `all-gather` æ“ä½œæˆä¸ºä¸¥é‡é€šä¿¡ç“¶é¢ˆï¼Œå¯¼è‡´è®­ç»ƒååé‡æ€¥å‰§ä¸‹é™ã€‚

ç°æœ‰ä¼˜åŒ–æ–¹æ¡ˆå­˜åœ¨ä»¥ä¸‹çŸ›ç›¾ï¼š
- **GPU å†…å­˜ç¼“å­˜**ï¼ˆå¦‚ MiCSã€ZeRO++ï¼‰ï¼šå‡å°‘é€šä¿¡ä½†æ¶ˆè€—é¢å¤– GPU æ˜¾å­˜ï¼Œé™åˆ¶æœ€å¤§ batch sizeï¼Œæ˜“å¼•å‘ OOMã€‚
- **ä¸»æœºå†…å­˜å¸è½½**ï¼ˆå¦‚ ZeRO-Offloadã€ZeRO-Infinityï¼‰ï¼šæ‰©å±•å®¹é‡ä½†å¼•å…¥ PCIe å¼€é”€ï¼Œé™ä½è®­ç»ƒååã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡º **FCDP**ï¼ˆFully Cached Data Parallelï¼‰ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š  
> **å°† host memory è§†ä¸ºâ€œé«˜é€Ÿç¼“å­˜å±‚â€è€Œéâ€œæº¢å‡ºå­˜å‚¨å±‚â€**ï¼Œåˆ©ç”¨æœ¬åœ° PCIe ä¼ è¾“é€Ÿåº¦ä¼˜äºæ…¢é€Ÿç½‘ç»œçš„ç‰¹ç‚¹ï¼Œé¿å…å†—ä½™çš„è·¨èŠ‚ç‚¹é€šä¿¡ã€‚

FCDP åŒ…å«ä¸‰ä¸ªå…³é”®æŠ€æœ¯ç»„ä»¶ï¼š

| ç»„ä»¶ | åˆ›æ–°ç‚¹ |
|------|--------|
| **FCDP-Sched** | åœ¨å‰å‘ä¼ æ’­åå°†é‡å»ºçš„å‚æ•°ç¼“å­˜åˆ° host memoryï¼›åå‘ä¼ æ’­æ—¶é€šè¿‡å¿«é€Ÿçš„ intra-node all-gather ä»æœ¬åœ° host åŠ è½½ï¼Œæ¶ˆé™¤ 50% çš„è·¨èŠ‚ç‚¹ all-gatherã€‚ |
| **FCDP-Cache** | åŠ¨æ€è‡ªé€‚åº”ç¼“å­˜ç­–ç•¥ï¼šå½“ GPU æ˜¾å­˜å……è¶³æ—¶ä¿ç•™å‚æ•°åœ¨è®¾å¤‡ä¸Šï¼›å‹åŠ›å¤§æ—¶è‡ªåŠ¨å¸è½½è‡³ host memoryï¼Œå…¼é¡¾æ€§èƒ½ä¸ç¨³å®šæ€§ã€‚ |
| **FCDP-Comm** | é¢å‘ PEFTï¼ˆå¦‚ LoRAï¼‰çš„å·¥ä½œè´Ÿè½½æ„ŸçŸ¥é€šä¿¡æœºåˆ¶ï¼šå†»ç»“å‚æ•°ä»…æ”¶é›†ä¸€æ¬¡å¹¶æ°¸ä¹…ç¼“å­˜ï¼Œä»…å¯¹å¯è®­ç»ƒé€‚é…å™¨è¿›è¡Œè·¨èŠ‚ç‚¹é€šä¿¡ï¼Œå®ç° >99% çš„é€šä¿¡å‰Šå‡ã€‚ |

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| å¯¹æ¯”ç»´åº¦ | ZeRO-3 / ZeRO++ | FCDP |
|---------|------------------|-------|
| **GPU Memory Footprint** | ZeRO++ å¢åŠ çº¦ 20% æ˜¾å­˜å¼€é”€ | ä¿æŒä¸ ZeRO-3 ç›¸åŒçš„æœ€å°æ˜¾å­˜å ç”¨ |
| **Maximum Batch Size** | ZeRO++ å› ç¼“å­˜å¯¼è‡´ batch size ä¸‹é™ç”šè‡³ OOM | æ”¯æŒä¸ ZeRO-3 å®Œå…¨ç›¸åŒçš„æœ€å¤§ batch size |
| **Inter-node Communication** | ZeRO-3 å…¨é‡é€šä¿¡ï¼›ZeRO++ å‡å°‘ 50%ï¼ˆä»…åå‘ï¼‰ | FCDP-Sched å‡å°‘ 50%ï¼›FCDP-Comm å¯è¾¾ 99.9% å‡å°‘ |
| **Throughput on Commodity Clusters** | å—é™äºä½å¸¦å®½ç½‘ç»œ | æ˜¾è‘—æå‡ï¼Œå°¤å…¶åœ¨å¼±ç½‘ç¯å¢ƒä¸‹ä¼˜åŠ¿å·¨å¤§ |
| **é€‚ç”¨åœºæ™¯** | é€šç”¨è®­ç»ƒ | ç‰¹åˆ«é€‚åˆ PEFT åœºæ™¯ï¼Œä¸”å…¼å®¹æ ‡å‡† DP æ¡†æ¶ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **SQuAD** æ•°æ®é›†ç”¨äº fine-tuning å®éªŒã€‚

### å®éªŒè®¾ç½®
- **ç¡¬ä»¶é…ç½®**ï¼š
  - 4 èŠ‚ç‚¹é›†ç¾¤ï¼Œæ¯èŠ‚ç‚¹åŒ AMD EPYC 7313 CPUï¼Œ512GB host memoryï¼Œ8Ã—NVIDIA A40ï¼ˆ48GB æ˜¾å­˜ï¼‰
  - èŠ‚ç‚¹é—´é€šè¿‡ **100Gbps InfiniBand EDR** è¿æ¥
  - èŠ‚ç‚¹å†… GPU é€šè¿‡ NVLink å’Œ PCIe Gen4 x16 äº’è”
- **æ¨¡å‹è§„æ¨¡**ï¼š
  - åŸºäº GPT-2-XL æ„å»ºçš„ç³»åˆ—æ¨¡å‹ï¼š**GPT-10B åˆ° GPT-30B** å‚æ•°
  - å±‚æ•° 39â€“40ï¼Œéšè—ç»´åº¦æœ€é«˜è¾¾ 7936
- **è½¯ä»¶æ ˆ**ï¼š
  - DeepSpeed v0.16.2 æ‰©å±•å®ç°ï¼ˆçº¦ 3200 è¡Œ Pythonï¼‰
  - PyTorch 2.3.0 + Python 3.10.12
  - ä½¿ç”¨ CUDA pinned memory å®ç°é«˜æ•ˆ PCIe DMA ä¼ è¾“
  - NUMA-aware ç¼“å†²åŒºåˆ†é…ä»¥æœ€å¤§åŒ– PCIe å¸¦å®½

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Training Throughput** | æ ·æœ¬/ç§’ï¼ˆsamples/secï¼‰ï¼Œä¸ºä¸»è¦æ€§èƒ½æŒ‡æ ‡ |
| **Inter-node Communication Volume** | æ¯è½®è¿­ä»£è·¨èŠ‚ç‚¹ä¼ è¾“å­—èŠ‚æ•°ï¼ˆGBï¼‰ |
| **Peak Network Bandwidth Usage** | è·¨èŠ‚ç‚¹ç½‘ç»œå³°å€¼å¸¦å®½ |
| **Maximum Batch Size** | å• GPU æœ€å¤§æ”¯æŒ batch sizeï¼ˆè¡¡é‡å†…å­˜æ•ˆç‡ï¼‰ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç®€è¦è¯´æ˜ |
|------|----------|
| **ZeRO-3** | Full shardingï¼Œä¸¤æ¬¡è·¨èŠ‚ç‚¹ all-gatherï¼ˆå‰å‘ + åå‘ï¼‰ |
| **ZeRO++** | GPU ç¼“å­˜å‰å‘å‚æ•°å‰¯æœ¬ï¼Œæ¶ˆé™¤åå‘ all-gatherï¼Œä½†å¢åŠ æ˜¾å­˜å¼€é”€ |
| **FCDP-Sched** | Host ç¼“å­˜ + intra-node all-gather æ›¿ä»£åå‘ all-gather |
| **FCDP-Comm** | ç»“åˆ PEFT-awareï¼Œä»…æ›´æ–°å¯è®­ç»ƒå‚æ•° |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰å¼ºæ‰©å±•æ€§æµ‹è¯•ï¼ˆStrong Scalingï¼‰
- å›ºå®š microbatch size = 8ï¼Œæ¯”è¾ƒä¸åŒ GPU æ•°é‡ä¸‹çš„ååã€‚
- **FCDP æ¯” ZeRO-3 æœ€é«˜å¿« 40.2%**
- **ZeRO++ åœ¨ GPT-20Bï¼ˆ16 GPUsï¼‰å’Œ GPT-30Bï¼ˆ32 GPUsï¼‰å‡ºç° OOM**

#### ï¼ˆ2ï¼‰æœ€å¤§ batch size æ€§èƒ½
| æ¨¡å‹ | ZeRO-3 max batch | ZeRO++ max batch | FCDP max batch |
|------|------------------|------------------|---------------|
| GPT-10B (32 GPUs) | 512 | 512 | **512** âœ… |
| GPT-30B (32 GPUs) | 256 | 128 | **256** âœ… |

> FCDP åœ¨æ‰€æœ‰é…ç½®ä¸‹å‡è¾¾åˆ°ä¸ ZeRO-3 ç›¸åŒçš„æœ€å¤§ batch sizeï¼Œè€Œ ZeRO++ æ˜æ˜¾å—é™ã€‚

#### ï¼ˆ3ï¼‰ååæå‡
- **FCDP ç›¸æ¯” ZeRO-3 æœ€é«˜æå‡ 41.3% åå**
- **ç›¸æ¯” ZeRO++ æœ€é«˜æå‡ 2Ã— åå**ï¼ˆå› æ›´å¤§ batch æ”¯æŒï¼‰

#### ï¼ˆ4ï¼‰PEFT åœºæ™¯ï¼ˆLoRA, r=8ï¼‰
- å¯è®­ç»ƒå‚æ•°å æ¯” <1%ï¼Œå…¶ä½™ä¸ºå†»ç»“æƒé‡
- **FCDP-Comm è¾ƒ ZeRO-3 æœ€é«˜æé€Ÿ 100Ã—**
- **è¾ƒ ZeRO++ æœ€é«˜æé€Ÿ 51Ã—**

#### ï¼ˆ5ï¼‰é€šä¿¡ä½“ç§¯åˆ†æï¼ˆTable VIIï¼‰
| æ–¹æ³• | Forward (GB) | Backward (GB) | Total (GB) |
|------|-------------|--------------|-----------|
| ZeRO-3 | 110.25 | 103.48 | **213.73** |
| ZeRO++ / FCDP-Sched | 108.18 | 0.1 | **108.28** (-49.3%) |
| FCDP-Comm | 0.06 | 0.1 | **0.16** (**-99.9%**) |

> FCDP-Comm å°†è·¨èŠ‚ç‚¹é€šä¿¡ä» 213GB é™è‡³ 0.16GBï¼

#### ï¼ˆ6ï¼‰ç½‘ç»œæ•æ„Ÿæ€§æµ‹è¯•ï¼ˆFig. 9ï¼‰
- å½“ç½‘ç»œä» 100Gbps RDMA é™åˆ° 1Gbps Ethernetï¼š
  - ZeRO-3 ååä¸‹é™ **98.4%**
  - FCDP ä»ç»´æŒ **86.3%** çš„å³°å€¼åå
- **FCDP å®ç°äº†å¯¹å¼±ç½‘ç»œçš„é«˜åº¦é²æ£’æ€§**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Host memory å¯ä½œä¸ºé«˜æ€§èƒ½ç¼“å­˜å±‚**ï¼šåœ¨å¸¦å®½å—é™é›†ç¾¤ä¸­ï¼ŒPCIe ä¼ è¾“é€Ÿåº¦å¯è¶…è¿‡è·¨èŠ‚ç‚¹ç½‘ç»œï¼Œä½¿å¾—â€œç¼“å­˜+æœ¬åœ°é‡å»ºâ€ä¼˜äºé‡å¤è¿œç¨‹é€šä¿¡ã€‚
2. **æ¶ˆé™¤å†—ä½™ all-gather æ˜¯å…³é”®**ï¼šZeRO-3 ä¸­å‰åå‘ä½¿ç”¨ç›¸åŒå‚æ•°å´é‡å¤ gatherï¼ŒFCDP æˆåŠŸè¯†åˆ«å¹¶æ¶ˆé™¤è¯¥å†—ä½™ã€‚
3. **åŠ¨æ€ç¼“å­˜ç­–ç•¥å¹³è¡¡æ€§èƒ½ä¸å®‰å…¨**ï¼šFCDP-Cache è‡ªé€‚åº”åˆ©ç”¨ç©ºé—² GPU æ˜¾å­˜ï¼Œé¿å…ä¸å¿…è¦çš„ PCIe ä¼ è¾“ã€‚
4. **PEFT-aware è®¾è®¡å¸¦æ¥æ•°é‡çº§ä¼˜åŒ–**ï¼šé’ˆå¯¹ LoRA ç­‰å†»ç»“å¤§éƒ¨åˆ†å‚æ•°çš„åœºæ™¯ï¼ŒFCDP-Comm å®ç°è¿‘é›¶é€šä¿¡å¼€é”€ã€‚
5. **è½¯ä»¶å±‚é¢å³å¯çªç ´é€šä¿¡ç“¶é¢ˆ**ï¼šæ— éœ€ç¡¬ä»¶æ”¹é€ ï¼Œä»…é ç®—æ³•è®¾è®¡å³å¯å¤§å¹…æå‡ commodity cluster ä¸Šçš„å¤§æ¨¡å‹è®­ç»ƒæ•ˆç‡ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–è¶³å¤Ÿ host memory**ï¼šæ¯ä¸ªèŠ‚ç‚¹éœ€çº¦ 2W å­—èŠ‚ host memoryï¼ˆå¦‚ 30B æ¨¡å‹éœ€ ~60GB/nodeï¼‰ï¼Œè™½å¸¸è§äºæœåŠ¡å™¨ä½†ä»éœ€è§„åˆ’ã€‚
- **PCIe å¸¦å®½ä»æ˜¯æ½œåœ¨ç“¶é¢ˆ**ï¼šè‹¥ PCIe å¸¦å®½æä½æˆ– host memory è®¿é—®å»¶è¿Ÿé«˜ï¼Œæ”¶ç›Šå¯èƒ½å‡å¼±ã€‚
- **ç›®å‰èšç„¦äº DP ç»´åº¦**ï¼šæœªç›´æ¥ä¼˜åŒ– TP æˆ– PPï¼Œä½†å¯ä¸å…¶ä»–å¹¶è¡Œç­–ç•¥ç»„åˆä½¿ç”¨ã€‚
- **NUMA æ•æ„Ÿæ€§è¦æ±‚æ­£ç¡®éƒ¨ç½²**ï¼šéœ€ç»‘å®šè¿›ç¨‹ä¸æœ¬åœ° NUMA èŠ‚ç‚¹ä»¥è·å¾—æœ€ä½³ PCIe æ€§èƒ½ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³æ›´å¤æ‚çš„ PEFT æ–¹æ³•**ï¼šå¦‚ Adapterã€Prefix-Tuning ç­‰ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–å‚æ•°åˆ†ç±»ä¸ç¼“å­˜ç­–ç•¥ã€‚
2. **ç»“åˆå¼‚æ„å­˜å‚¨å±‚çº§**ï¼šæ¢ç´¢å°†å†·æ•°æ®ç¼“å­˜è‡³ NVMe SSDï¼Œæ„å»ºå¤šçº§ç¼“å­˜ä½“ç³»ã€‚
3. **é›†æˆè¿› 3D å¹¶è¡Œæ¡†æ¶**ï¼šä½œä¸º Megatron-LM æˆ– DeepSpeed 3D Parallelism ä¸­çš„ DP å­æ¨¡å—ã€‚
4. **è‡ªåŠ¨åŒ–é˜ˆå€¼è°ƒä¼˜**ï¼šåŸºäºè¿è¡Œæ—¶ profiling è‡ªåŠ¨è°ƒæ•´ `T`ï¼ˆGPU ç¼“å­˜é˜ˆå€¼ï¼‰ï¼Œå®ç°å…é…ç½®ä¼˜åŒ–ã€‚
5. **æ”¯æŒæ›´å¤š collective ç±»å‹**ï¼šå¦‚ all-reduceã€broadcast çš„ç¼“å­˜ä¼˜åŒ–ï¼Œå½¢æˆå®Œæ•´é€šä¿¡è§„é¿æ¡†æ¶ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **FCDP é€šè¿‡å°† host memory ç”¨ä½œé€šä¿¡è§„é¿çš„â€œä¸€çº§ç¼“å­˜â€ï¼Œåœ¨ä¸ç‰ºç‰² ZeRO-3 å†…å­˜æ•ˆç‡çš„å‰æä¸‹ï¼Œå®ç°äº†åª²ç¾ç”šè‡³è¶…è¶Š ZeRO++ çš„é€šä¿¡ä¼˜åŒ–æ•ˆæœï¼Œç‰¹åˆ«åœ¨ PEFT åœºæ™¯ä¸‹å¯è¾¾ç™¾å€åŠ é€Ÿï¼Œä¸ºé€šç”¨ç¡¬ä»¶ä¸Šçš„å¤§æ¨¡å‹è®­ç»ƒæä¾›äº†é«˜æ•ˆå¯è¡Œçš„æ–°è·¯å¾„ã€‚**

</details>

---

### 6. [SOCKET: SOft Collison Kernel EsTimator for Sparse Attention](https://arxiv.org/abs/2602.06283)

**Authors**: Sahil Joshi, Agniva Chowdhury, Wyatt Bellinger, Amar Kanakamedala, Ekam Singh, Hoang Anh Duy Le, Aditya Desai, Anshumali Shrivastava  
**Category**: cs.LG  
**Published**: 2026-02-09  
**Score**: 11.5  
**Type**: new  
**ArXiv ID**: 2602.06283v1  

#### Abstract
Exploiting sparsity during long-context inference is central to scaling large language models, as attention dominates the cost of autoregressive decoding. Sparse attention reduces this cost by restricting computation to a subset of tokens, but its effectiveness depends critically on efficient scorin...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# SOCKET: SOft Collison Kernel EsTimator for Sparse Attention â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
åœ¨ **long-context inference** ä¸­ï¼Œæ ‡å‡†çš„ **dense attention** è®¡ç®—æˆæœ¬éšä¸Šä¸‹æ–‡é•¿åº¦å‘ˆå¹³æ–¹å¢é•¿ï¼Œå¯¼è‡´å†…å­˜å’Œè®¡ç®—ç“¶é¢ˆï¼Œå°¤å…¶æ˜¯åœ¨ KV Cache è¶…å‡º GPU å†…å­˜æ—¶ã€‚è™½ç„¶ **sparse attention** é€šè¿‡åªå…³æ³¨éƒ¨åˆ† token æ¥ç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œä½†å…¶æ•ˆæœé«˜åº¦ä¾èµ–äºå¦‚ä½•é«˜æ•ˆä¸”å‡†ç¡®åœ°é€‰æ‹©â€œé‡è¦â€tokenã€‚

ä¼ ç»ŸåŸºäº **Locality-Sensitive Hashing (LSH)** çš„æ–¹æ³•ä½¿ç”¨ **hard bucket matching**ï¼ˆç¡¬å“ˆå¸Œç¢°æ’ï¼‰æ¥ç­›é€‰å€™é€‰ tokenï¼Œä½†è¿™ç§ç¦»æ•£çš„äºŒå…ƒä¿¡å·ï¼ˆæ˜¯å¦åœ¨åŒä¸€æ¡¶å†…ï¼‰æ— æ³•è¡¨è¾¾ç›¸ä¼¼åº¦çš„è¿ç»­æ€§ï¼Œå¯¼è‡´ **ranking ä¸ç¨³å®š**ï¼Œå½±å“ top-k é€‰æ‹©çš„è´¨é‡ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
è®ºæ–‡æå‡º **SOCKET**ï¼ˆ**SOft Collison Kernel EsTimator**ï¼‰ï¼Œä¸€ç§åŸºäº **soft LSH** çš„ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼Œå°†ä¼ ç»Ÿçš„ç¡¬å“ˆå¸Œç¢°æ’å‡çº§ä¸º **æ¦‚ç‡æ€§ã€ç›¸ä¼¼åº¦æ„ŸçŸ¥çš„è½¯èšåˆæœºåˆ¶**ã€‚

#### æ ¸å¿ƒåˆ›æ–°ï¼š
- **Soft Collision Scoring**ï¼š  
  åœ¨æ¨ç†é˜¶æ®µï¼ŒæŸ¥è¯¢å‘é‡ $ q $ ä¸å†è¢«ç¡¬åˆ†é…åˆ°æŸä¸ªå“ˆå¸Œæ¡¶ï¼Œè€Œæ˜¯å¯¹æ¯ä¸ªå“ˆå¸Œè¡¨ä¸­çš„æ‰€æœ‰æ¡¶äº§ç”Ÿä¸€ä¸ª **æ¦‚ç‡åˆ†å¸ƒ** $ p(b_l^{(q)} | q) $ã€‚æ¯ä¸ª key çš„æœ€ç»ˆå¾—åˆ†ä¸ºå…¶æ‰€åœ¨æ¡¶åœ¨æ‰€æœ‰å“ˆå¸Œè¡¨ä¸Šçš„æ¦‚ç‡æ€»å’Œï¼š
  $$
  S_{\text{soft}}(k_j, q) = \sum_{l=1}^L p(b_l^{(k_j)} | q)
  $$
  è¿™ç§å¾—åˆ†æ–¹å¼ä¿ç•™äº†ç›¸ä¼¼åº¦çš„æ¢¯åº¦ä¿¡æ¯ï¼Œæå‡äº†æ’åç¨³å®šæ€§ã€‚

- **ä»å¯å‘å¼åˆ°åŸåˆ™æ€§è¯„åˆ†æ ¸**ï¼š  
  å°† LSH ä»ä¸€ç§ç²—ç•¥çš„å€™é€‰ç”Ÿæˆå¯å‘å¼ï¼Œè½¬å˜ä¸ºä¸€ä¸ª **æ•°å­¦ä¸Šå¯åˆ†æã€æœ‰ç†è®ºä¿è¯çš„ scoring kernel**ï¼Œç”¨äºç›´æ¥è¿›è¡Œ top-k é€‰æ‹©ã€‚

- **æ— éœ€å¤æ‚æŠ•ç¥¨æœºåˆ¶**ï¼š  
  ç”±äº soft LSH å¾—åˆ†æœ¬èº«å·²å…·å¤‡è‰¯å¥½çš„æ’åºèƒ½åŠ›ï¼ŒSOCKET å¯ç›´æ¥åŸºäºè¯¥å¾—åˆ†é€‰æ‹© top-k keysï¼Œæ— éœ€é¢å¤–çš„æŠ•ç¥¨æˆ–èåˆç­–ç•¥ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | SOCKET çš„ä¼˜åŠ¿ |
|------|----------------|
| **Ranking ç¨³å®šæ€§** | è½¯å¾—åˆ†å‡å°‘å™ªå£°ï¼Œæ˜¾è‘—æå‡ top-k æ’åè´¨é‡ï¼Œå°¤å…¶åœ¨é«˜ç¨€ç–åº¦ä¸‹ |
| **æ•ˆç‡** | ä»…éœ€è¯»å–æ¯ä¸ª key çš„ä¸€ä¸ª bfloatï¼ˆè½¯è®¡æ•°ï¼‰å’Œä¸€ä¸ªæ•´æ•°ï¼ˆvalue normï¼‰ï¼Œå¤§å¹…é™ä½å†…å­˜è®¿é—®å¼€é”€ |
| **æ•°æ®æ— å…³æ€§ (Data-agnostic)** | æ— éœ€è®­ç»ƒæˆ–æ ¡å‡†ï¼Œé€‚ç”¨äºä»»æ„åˆ†å¸ƒ shiftï¼Œéƒ¨ç½²æ›´ç®€å• |
| **ç†è®ºå¯è§£é‡Šæ€§** | æä¾›äº†ä¸ angular attention çš„é€¼è¿‘è¯¯å·®ç•Œï¼Œè¯æ˜å…¶åˆç†æ€§ |
| **ç³»ç»Ÿä¼˜åŒ–** | é…å¤‡å®šåˆ¶ CUDA kernel å’Œ Flash Decode Triton åç«¯ï¼Œå®ç°æ›´é«˜åå |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **LongBench**ï¼šå¤šä»»åŠ¡é•¿æ–‡æœ¬ç†è§£åŸºå‡†ï¼Œæ¶µç›–é—®ç­”ã€æ¨ç†ã€æ‘˜è¦ã€ä»£ç ç­‰ä»»åŠ¡ï¼Œè¾“å…¥é•¿åº¦è¾¾æ•°ä¸‡ tokenã€‚
- **RULER-32K / RULER-16K**ï¼šåˆæˆè¯Šæ–­åŸºå‡†ï¼Œæµ‹è¯•æ¨¡å‹åœ¨æé•¿ä¸Šä¸‹æ–‡ä¸­æ£€ç´¢ç¨€ç–ã€ä½ç½®æ•æ„Ÿä¿¡æ¯çš„èƒ½åŠ›ã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹**ï¼š
  - `Llama-3.1-8B-Instruct`
  - `Llama-3.2-1B-Instruct`
  - `Qwen3-8B`
- **ä¸Šä¸‹æ–‡é•¿åº¦**ï¼šæ”¯æŒ up to 128K tokensã€‚
- **ç¨€ç–åº¦ (Sparsity)**ï¼š5Ã—, 10Ã—, 20Ã—, 50Ã—ï¼ˆå³åªè®¡ç®— 1/k çš„ attentionï¼‰ã€‚
- **è¯„ä¼°åè®®**ï¼š
  - åœ¨ context processing é˜¶æ®µä½¿ç”¨ dense attentionï¼Œåœ¨ decoding é˜¶æ®µä½¿ç”¨ sparse attentionã€‚
  - åŒ…å«å°‘é‡ sink tokens å’Œ local window tokens ä»¥ç¨³å®šæ€§èƒ½ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - ä»»åŠ¡ç‰¹å®šæŒ‡æ ‡ï¼ˆå¦‚ QA å‡†ç¡®ç‡ï¼‰
  - **AVG**ï¼šLongBench ä¸Šé™¤ Passage-Count å¤–çš„å¹³å‡å¾—åˆ†ï¼ˆ0â€“100 scaleï¼‰
  - **Jaccard Similarity / Precision / NDCG**ï¼šè¡¡é‡é€‰å‡ºçš„ top-k æ˜¯å¦æ¥è¿‘çœŸå® top-k

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **PQCache** | Product Quantization + CPU-GPU | æ•°æ®ç›¸å…³ï¼Œè¿‘ä¼¼æ£€ç´¢ |
| **Quest** | Page-level sparsity | åŸºäºé¡µé¢çš„ token é€‰æ‹© |
| **HashAttention** | Learned hashing | å­¦ä¹ è¯­ä¹‰å“ˆå¸Œå‡½æ•° |
| **MagicPig** | LSH-based sampling | åŸºäº LSH çš„é‡è¦æ€§é‡‡æ · |
| **Double Sparsity (DS)** | Channel + Token sparsity | åŒé‡ç¨€ç–åŒ– |
| **FlashAttention** | Dense baseline | æ€§èƒ½ä¸ååå¯¹æ¯”åŸºå‡† |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### âœ… åœ¨ LongBench ä¸Šçš„è¡¨ç°ï¼ˆLlama-3.1-8B-Instructï¼‰
| æ–¹æ³• | Sparsity | AVG |
|------|----------|-----|
| Baseline (Dense) | â€“ | 50.3 |
| PQCache | 5Ã— | 46.7 |
| Quest | 5Ã— | 47.4 |
| **SOCKET** | **5Ã—** | **49.0** |
| PQCache | 10Ã— | 45.9 |
| Quest | 10Ã— | 46.8 |
| **SOCKET** | **10Ã—** | **48.8** |

> **ç»“è®º**ï¼šSOCKET åœ¨ 5Ã— å’Œ 10Ã— ç¨€ç–åº¦ä¸‹å‡ä¼˜äºæœ€å¼ºåŸºçº¿çº¦ **2.5 åˆ†**ï¼Œæ¥è¿‘ dense æ€§èƒ½ã€‚

#### âœ… åœ¨ RULER-32K ä¸Šçš„è¡¨ç°ï¼ˆLlama-3.1-8B-Instructï¼‰
| æ–¹æ³• | Sparsity | AVG |
|------|----------|-----|
| PQCache | 50Ã— | 16.2 |
| Quest | 50Ã— | 64.1 |
| DS | 50Ã— | 44.6 |
| HashAttn | 50Ã— | 49.4 |
| **SOCKET** | **50Ã—** | **71.9** |

> **ç»“è®º**ï¼šåœ¨æç«¯ç¨€ç–ï¼ˆ50Ã—ï¼‰ä¸‹ï¼ŒSOCKET æ˜¾è‘—é¢†å…ˆï¼Œè¯´æ˜å…¶ **ranking æ›´é²æ£’**ã€‚

#### âœ… åœ¨ Qwen3-8B ä¸Šçš„è¡¨ç°
| æ–¹æ³• | Sparsity | AVG |
|------|----------|-----|
| PQCache | 5Ã— | 36.3 |
| Quest | 5Ã— | 36.1 |
| **SOCKET** | **5Ã—** | **37.0** |
| PQCache | 10Ã— | 36.1 |
| Quest | 10Ã— | 34.1 |
| **SOCKET** | **10Ã—** | **36.9** |

> **ç»“è®º**ï¼šåœ¨ä¸åŒæ¶æ„æ¨¡å‹ä¸Šå‡è¡¨ç°ä¸€è‡´ä¸”ä¼˜è¶Šã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **æ€§èƒ½æ–¹é¢**ï¼š
  - åœ¨å¤šä¸ªæ¨¡å‹å’Œç¨€ç–åº¦ä¸‹ï¼ŒSOCKET **åŒ¹é…æˆ–è¶…è¶Šæ‰€æœ‰åŸºçº¿**ã€‚
  - åœ¨é«˜ç¨€ç–åº¦ï¼ˆå¦‚ 50Ã—ï¼‰ä¸‹ä¼˜åŠ¿æ›´æ˜æ˜¾ï¼Œè¡¨æ˜å…¶ **ranking æ›´ç¨³å®šå¯é **ã€‚
- **æ•ˆç‡æ–¹é¢**ï¼š
  - **è§£ç ååé‡**ï¼šåœ¨ A100 å’Œ H200 ä¸Šï¼Œç›¸æ¯” FlashAttention å®ç° **æœ€é«˜ 1.5Ã— çš„åŠ é€Ÿ**ã€‚
    - H200 ä¸Šï¼Œ145K context ä¸‹è¾¾åˆ° **1.5Ã— speedup**ã€‚
    - åŠ é€Ÿæ¯”éš context length å¢åŠ è€Œå¢å¤§ï¼Œä½“ç°å…¶ **scalability**ã€‚
  - **ç´¢å¼•æ„å»ºé€Ÿåº¦**ï¼šSOCKET åœ¨ GPU ä¸Šæ„å»ºç´¢å¼•ï¼Œæ¯” PQCacheï¼ˆCPU-basedï¼‰å¿« **ä¸¤ä¸ªæ•°é‡çº§**ï¼ˆè§ Figure 3aï¼‰ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆéšå«éªŒè¯ï¼‰
- **Soft vs. Hard LSH**ï¼š
  - Figure 2 æ˜¾ç¤ºï¼ŒSOCKET é€‰å‡ºçš„ keys å…¶çœŸå® attention scores æ›´é›†ä¸­è¶…è¿‡é˜ˆå€¼ï¼Œè¯´æ˜å…¶ **ranking æ›´æ¥è¿‘ ground truth top-k**ã€‚
  - NDCG å’Œ Jaccard æŒ‡æ ‡ä¹Ÿæ˜¾ç¤º soft LSH åœ¨æœ‰é™å“ˆå¸Œè¡¨ä¸‹æ”¶æ•›æ›´å¿«ã€æ›´ç¨³å®šã€‚
- **æ¸©åº¦ $ T $ çš„ä½œç”¨**ï¼š
  - æ¸©åº¦æ§åˆ¶ soft bucket åˆ†å¸ƒçš„å¹³æ»‘ç¨‹åº¦ï¼š$ T \to 0 $ è¶‹è¿‘ hard LSHï¼›$ T \to \infty $ è¶‹è¿‘å‡åŒ€åˆ†å¸ƒã€‚
  - å®éªŒä¸­ $ T \in [0.3, 0.7] $ å–å¾—æœ€ä½³å¹³è¡¡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **Hard LSH ä¸é€‚åˆ ranking**ï¼šå…¶ç¦»æ•£ç¢°æ’ä¿¡å·å™ªå£°å¤§ï¼Œå¯¼è‡´ top-k æ’åä¸ç¨³å®šã€‚
2. **Soft LSH æ˜¯æ›´ä¼˜çš„ ranking æœºåˆ¶**ï¼šé€šè¿‡æ¦‚ç‡æ€§èšåˆï¼Œä¿ç•™ç›¸ä¼¼åº¦æ¢¯åº¦ä¿¡æ¯ï¼Œæ˜¾è‘—æå‡ ranking ç¨³å®šæ€§å’Œ top-k è´¨é‡ã€‚
3. **SOCKET æ˜¯ä¸€ä¸ª principled sparse attention solution**ï¼š
   - æ•°æ®æ— å…³ã€æ— éœ€è®­ç»ƒ
   - æœ‰ç†è®ºé€¼è¿‘ä¿è¯ï¼ˆTheorem 3ï¼‰
   - é«˜æ•ˆã€å¯æ‰©å±•
4. **ç³»ç»Ÿå®ç°é«˜æ•ˆ**ï¼šç»“åˆ CUDA kernel å’Œ Triton backendï¼Œå®ç°é«˜è¾¾ **1.5Ã— è§£ç ååæå‡**ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ç†è®ºåˆ†æåŸºäº angular attention**ï¼šå®é™…ä½¿ç”¨çš„æ˜¯ softmax attentionï¼Œè™½æœ‰ç»éªŒæ”¯æŒäºŒè€…è¡Œä¸ºç›¸è¿‘ï¼Œä½†ä»å­˜åœ¨ gapã€‚
- **ä»éœ€å­˜å‚¨å“ˆå¸Œè¡¨**ï¼šè™½ç„¶æ¯”å®Œæ•´ KV Cache å°ï¼Œä½†å“ˆå¸Œç´¢å¼•æœ¬èº«å ç”¨é¢å¤–å†…å­˜ï¼ˆè§ Table 1 ä¸­ Mem åˆ—ï¼‰ã€‚
- **è¶…å‚æ•°è°ƒä¼˜éœ€æ±‚**ï¼šå¦‚å“ˆå¸Œç»´åº¦ $ P $ã€è¡¨æ•° $ L $ã€æ¸©åº¦ $ T $ éœ€è°ƒæ•´ä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **Fine-tuning with SOCKET**ï¼šæ¢ç´¢åœ¨é¢„è®­ç»ƒæˆ–å¾®è°ƒé˜¶æ®µé›†æˆ SOCKETï¼Œè¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚
- **Dynamic Sparsity Control**ï¼šæ ¹æ® query åŠ¨æ€è°ƒæ•´ sparsity level æˆ– $ T $ã€‚
- **Extension to other modalities**ï¼šåº”ç”¨äº vision, audio, code ç­‰é•¿åºåˆ—åœºæ™¯ã€‚
- **Hardware-aware optimization**ï¼šè¿›ä¸€æ­¥ä¼˜åŒ– CUDA kernel ä»¥é€‚é…æ›´å¤š GPU æ¶æ„ã€‚

---

> ğŸ”— **å¼€æºåœ°å€**ï¼šhttps://github.com/amarka8/SOCKET  
> ğŸ“„ **è®ºæ–‡é“¾æ¥**ï¼šhttps://arxiv.org/abs/2602.06283

</details>

---

### 7. [RelayGen: Intra-Generation Model Switching for Efficient Reasoning](https://arxiv.org/abs/2602.06454)

**Authors**: Jiwon Song, Yoongon Kim, Jae-Joon Kim  
**Category**: cs.CL  
**Published**: 2026-02-09  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2602.06454v1  

#### Abstract
Large reasoning models (LRMs) achieve strong performance on complex reasoning tasks by generating long, multi-step reasoning trajectories, but inference-time scaling incurs substantial deployment cost. A key challenge is that generation difficulty varies within a single output, whereas existing effi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šRelayGen: Intra-Generation Model Switching for Efficient Reasoning**

---

## 1. **è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLarge Reasoning Models, LRMsï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å…¶é•¿åºåˆ—ç”Ÿæˆè¿‡ç¨‹å¸¦æ¥äº†é«˜æ˜‚çš„æ¨ç†æˆæœ¬ã€‚ä¼ ç»Ÿæ•ˆç‡ä¼˜åŒ–æ–¹æ³•å­˜åœ¨ä»¥ä¸‹ä¸è¶³ï¼š
- **Input-level routing**ï¼šå¯¹æ•´ä¸ªè¾“å‡ºä½¿ç”¨å•ä¸€æ¨¡å‹ï¼Œæ— æ³•åˆ©ç”¨**å•æ¬¡ç”Ÿæˆå†…éƒ¨çš„éš¾åº¦å·®å¼‚**ã€‚
- **Token-level routing**ï¼šè™½èƒ½ç»†ç²’åº¦æ§åˆ¶ï¼Œä½†ä¾èµ–è®­ç»ƒå¥½çš„è·¯ç”±æ¨¡å‹ï¼ˆrouterï¼‰ï¼Œç³»ç»Ÿå¤æ‚ã€éƒ¨ç½²å›°éš¾ã€‚
- **Step-level switching**ï¼šåŸºäºå¯å‘å¼è§„åˆ™åˆ‡æ¢ï¼Œç¼ºä¹å¯¹å®é™…æ¨¡å‹è¡Œä¸ºçš„å®è¯åˆ†æï¼Œå¯èƒ½å¯¼è‡´ç²¾åº¦ä¸‹é™ã€‚

å› æ­¤ï¼Œå¦‚ä½•åœ¨ä¸ç‰ºç‰²å‡†ç¡®ç‡çš„å‰æä¸‹ï¼Œé«˜æ•ˆåˆ©ç”¨æ¨¡å‹å®¹é‡ï¼Œæˆä¸ºå…³é”®æŒ‘æˆ˜ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
æœ¬æ–‡æå‡º **RelayGen**ï¼Œä¸€ç§**æ— éœ€è®­ç»ƒã€åŸºäºæ®µè½çº§ï¼ˆsegment-levelï¼‰è¿è¡Œæ—¶æ¨¡å‹åˆ‡æ¢**çš„æ¡†æ¶ï¼Œæ ¸å¿ƒæ€æƒ³å¦‚ä¸‹ï¼š
- **è§‚å¯Ÿåˆ°æ¨ç†è½¨è¿¹ä¸­å­˜åœ¨æ˜¾è‘—çš„éš¾åº¦å˜åŒ–**ï¼šé€šè¿‡åˆ†æ token-level çš„æ¦‚ç‡è¾¹é™…ï¼ˆprobability marginï¼‰ï¼Œå‘ç°æŸäº›é˜¶æ®µï¼ˆå¦‚åæ€ã€æ€»ç»“ã€ç­”æ¡ˆç”Ÿæˆï¼‰ä¸ç¡®å®šæ€§æ›´ä½ï¼Œå±äºâ€œä½éš¾åº¦æ®µâ€ã€‚
- **åŸºäºå®è¯åˆ†æé€‰æ‹©åˆ‡æ¢ä¿¡å·ï¼ˆswitch cuesï¼‰**ï¼šè¯†åˆ«å‡ºç‰¹å®šçš„**è¯è¯­çº§çº¿ç´¢**ï¼ˆdiscourse-level cuesï¼Œå¦‚ "therefore", "so", "check"ï¼‰ä½œä¸ºåˆ‡æ¢è§¦å‘å™¨ï¼Œè¿™äº›çº¿ç´¢åæ¥çš„ç”Ÿæˆå†…å®¹é€šå¸¸æ›´ç¡®å®šã€‚
- **è¿è¡Œæ—¶åŠ¨æ€åˆ‡æ¢æ¨¡å‹**ï¼š
  - é«˜éš¾åº¦æ¨ç†é˜¶æ®µç”±å¤§æ¨¡å‹ï¼ˆlarge modelï¼‰å¤„ç†ï¼›
  - å½“æ£€æµ‹åˆ° switch cue æˆ–è¿›å…¥ç­”æ¡ˆé˜¶æ®µï¼ˆ`</think>` åï¼‰æ—¶ï¼Œå°†åç»­ç”Ÿæˆäº¤ç»™å°æ¨¡å‹ï¼ˆsmall modelï¼‰å®Œæˆã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç‰¹æ€§ | RelayGen | Token-level Routing (å¦‚ R2R) | Step-level Switching (å¦‚ Speculative Thinking) |
|------|---------|-------------------------------|-----------------------------------------------|
| æ˜¯å¦éœ€è¦è®­ç»ƒ | âŒ æ— éœ€è®­ç»ƒ | âœ… éœ€è¦è®­ç»ƒè·¯ç”±æ¨¡å‹ | âŒ æ— éœ€è®­ç»ƒ |
| åˆ‡æ¢ç²’åº¦ | Segment-level | Token-level | Step-level |
| ç³»ç»Ÿå¤æ‚æ€§ | æä½ï¼ˆä»…éœ€ token åŒ¹é…ï¼‰ | é«˜ï¼ˆéœ€é›†æˆ routerï¼‰ | ä¸­ç­‰ï¼ˆä¾èµ–é¢„å®šä¹‰è§„åˆ™ï¼‰ |
| å¯ç»„åˆæ€§ | âœ… å…¼å®¹ speculative decoding | âŒ ä¸å…¼å®¹ï¼ˆç ´å draft-verify æµç¨‹ï¼‰ | âš ï¸ éƒ¨åˆ†å…¼å®¹ |
| å‡†ç¡®ç‡ä¿æŒ | é«˜ï¼ˆæ¥è¿‘å¤§æ¨¡å‹ï¼‰ | è¾ƒé«˜ | æ˜¾è‘—ä¸‹é™ |

> **æ ¸å¿ƒä¼˜åŠ¿**ï¼šRelayGen åœ¨**æ— éœ€é¢å¤–è®­ç»ƒã€ä½ç³»ç»Ÿå¼€é”€**çš„å‰æä¸‹ï¼Œå®ç°äº†**é«˜ç²¾åº¦ä¿ç•™ä¸‹çš„æ˜¾è‘—åŠ é€Ÿ**ï¼Œå¹¶å¤©ç„¶æ”¯æŒä¸å…¶ä»–åŠ é€ŸæŠ€æœ¯ï¼ˆå¦‚ speculative decodingï¼‰ç»„åˆã€‚

---

## 2. **æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **AIME 2025**ï¼šç¾å›½æ•°å­¦é‚€è¯·èµ›é¢˜ç›®ï¼Œé«˜éš¾åº¦æ•°å­¦æ¨ç†ã€‚
- **MATH500**ï¼šLightman et al. (2023) æä¾›çš„æ•°å­¦æ¨ç†åŸºå‡†ï¼Œæ¶µç›–å¤šç§é¢˜å‹ã€‚
- **GPQA-Diamond**ï¼šç ”ç©¶ç”Ÿçº§åˆ«ç§‘å­¦é—®ç­”æ•°æ®é›†ï¼Œæµ‹è¯•è·¨é¢†åŸŸæ¨ç†èƒ½åŠ›ã€‚
- **AMC 2023**ï¼šç”¨äº offline calibration çš„æ ¡å‡†é›†ï¼ˆ40 é¢˜ï¼Œå…± 160 æ¡æ¨ç†è½¨è¿¹ï¼‰ã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**
- **æ¨¡å‹å¯¹**ï¼š
  - `Qwen3-32B / Qwen3-1.7B`
  - `R1-Distill-Qwen-32B / R1-Distill-Qwen-1.5B`
- **ç”Ÿæˆå‚æ•°**ï¼š
  - max length: 32,768
  - temperature: 0.6, top_p: 0.95, top_k: 20 (Qwen3)
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Pass@1**ï¼šæ­£ç¡®ç­”æ¡ˆæ˜¯å¦å‡ºç°åœ¨é¦–æ¬¡ç”Ÿæˆä¸­ã€‚
  - **Speedup (Ã—)**ï¼šç›¸å¯¹äºçº¯å¤§æ¨¡å‹ç”Ÿæˆçš„ç«¯åˆ°ç«¯å»¶è¿ŸåŠ é€Ÿæ¯”ã€‚
  - **Large-model utilization (%)**ï¼šå¤§æ¨¡å‹ç”Ÿæˆçš„ token å æ¯”ã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **Small Model Only**ï¼šå…¨ç¨‹ä½¿ç”¨å°æ¨¡å‹ã€‚
- **Large Model Only**ï¼šå…¨ç¨‹ä½¿ç”¨å¤§æ¨¡å‹ï¼ˆä¸Šé™ï¼‰ã€‚
- **Speculative Thinking (Spec. Think.)**ï¼šåŸºäºå¯å‘å¼ cues çš„ step-level åˆ‡æ¢ã€‚
- **R2R**ï¼šåŸºäºå­¦ä¹ çš„ token-level è·¯ç”±æ–¹æ³•ã€‚
- **Eagle-3**ï¼šspeculative decoding æ–¹æ³•ã€‚
- **RelayGen + Eagle-3**ï¼šç»„åˆæ–¹æ¡ˆã€‚

---

## 3. **ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **è¡¨ 2ï¼šPass@1 å¯¹æ¯”ï¼ˆå‡†ç¡®ç‡ï¼‰**
| Method | MATH500 (Qwen3) | AIME 2025 (Qwen3) | GPQA-Diamond (Qwen3) |
|--------|------------------|-------------------|------------------------|
| Large Model | 95.27 | 70.00 | 64.58 |
| Small Model | 88.60 | 31.67 | 37.33 |
| Spec. Think. | 91.35 | 40.83 | 41.29 |
| R2R | 94.30 | 62.50 | 61.62 |
| **RelayGen** | **94.80** | **68.33** | **63.64** |

> **ç»“è®º**ï¼šRelayGen åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šå‡æ˜¾è‘—ä¼˜äºå°æ¨¡å‹å’Œ Spec. Think.ï¼Œä¸”æ¥è¿‘å¤§æ¨¡å‹æ€§èƒ½ï¼Œåœ¨éƒ¨åˆ†ä»»åŠ¡ä¸Šç”šè‡³è¶…è¿‡ R2Rã€‚

#### **è¡¨ 3ï¼šæ¨ç†é€Ÿåº¦ä¸å¤§æ¨¡å‹åˆ©ç”¨ç‡**
| Method | Speedup (Ã—) | Large-Model Utilization (%) |
|--------|-------------|------------------------------|
| Large Model | 1.00 | 100.00 |
| Spec. Think. | 2.21 | 25.54 |
| R2R | 1.30 | 19.27 |
| **RelayGen** | **1.29** | **69.80** |
| **RelayGen + Eagle-3** | **2.20** | **69.49** |

> **ç»“è®º**ï¼š
> - RelayGen å•ç‹¬ä½¿ç”¨å³å¯å®ç° **1.29Ã— åŠ é€Ÿ**ï¼ŒåŒæ—¶ä¿ç•™è¿‘ 70% çš„å¤§æ¨¡å‹ token å¤„ç†èƒ½åŠ›ã€‚
> - ä¸ Eagle-3 ç»„åˆåè¾¾åˆ° **æœ€é«˜ 2.20Ã— ç«¯åˆ°ç«¯åŠ é€Ÿ**ï¼Œä¸”ä»…æŸå¤± <2% å‡†ç¡®ç‡ã€‚

### **æ¶ˆèå®éªŒç»“æœ**

#### **è¡¨ 4ï¼šSwitch Cue é€‰æ‹©çš„å½±å“**
| Cue Usage | AIME 2025 | GPQA-Diamond |
|----------|-----------|---------------|
| æ‰€æœ‰å€™é€‰ cues | 60.00 | 57.32 |
| **ç²¾é€‰ switch cues** | **68.33** | **63.64** |

> **ç»“è®º**ï¼šå¹¶éæ‰€æœ‰ discourse-level cues éƒ½é€‚åˆåˆ‡æ¢ï¼Œ**åŸºäºæ¦‚ç‡è¾¹é™…ç­›é€‰çš„ cues èƒ½æ˜¾è‘—æå‡æ€§èƒ½**ã€‚

#### **è¡¨ 5ï¼šæ ¡å‡†é›†å¤§å°æ•æ„Ÿæ€§**
| #Calibration Samples | AIME 2025 | GPQA-Diamond |
|-----------------------|-----------|---------------|
| 10 | 70.00 | 61.87 |
| 40 | 71.67 | 61.87 |
| 160 | 68.33 | 63.64 |

> **ç»“è®º**ï¼šRelayGen å¯¹æ ¡å‡†é›†å¤§å°ä¸æ•æ„Ÿï¼Œ**æå°æ ·æœ¬ï¼ˆå¦‚ 10 æ¡ï¼‰ä¹Ÿèƒ½å–å¾—è‰¯å¥½æ•ˆæœ**ï¼ŒéªŒè¯å…¶è½»é‡åŒ–éƒ¨ç½²æ½œåŠ›ã€‚

#### **å›¾ 6ï¼šå¼‚æ„æ¨¡å‹å¯¹é²æ£’æ€§**
- åœ¨ `Qwen3-32B / R1-Distill-1.5B` ç­‰è·¨å®¶æ—æ¨¡å‹å¯¹ä¸Šï¼Œæ€§èƒ½ä¸‹é™ä¸»è¦æºäºå°æ¨¡å‹èƒ½åŠ›ä¸è¶³ï¼Œè€Œéæ–¹æ³•æœ¬èº«å¤±æ•ˆã€‚
- è¡¨æ˜ RelayGen **é€‚ç”¨äºä¸åŒæ¨¡å‹å®¶æ—é—´çš„åˆ‡æ¢**ï¼Œåªè¦å°æ¨¡å‹å…·å¤‡åŸºæœ¬æ¨ç†èƒ½åŠ›ã€‚

---

## 4. **å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **é•¿æ¨ç†è½¨è¿¹å…·æœ‰å†…åœ¨éš¾åº¦å¼‚è´¨æ€§**ï¼šå¹¶éæ‰€æœ‰éƒ¨åˆ†éƒ½éœ€è¦å¤§æ¨¡å‹ï¼Œ**ç­”æ¡ˆç”Ÿæˆå’ŒæŸäº›æ€»ç»“æ€§è¯­å¥å¯ç”±å°æ¨¡å‹ç¨³å®šæ‰¿æ¥**ã€‚
2. **ç²—ç²’åº¦æ§åˆ¶è¶³ä»¥æ•æ‰éš¾åº¦å˜åŒ–**ï¼š**segment-level åˆ‡æ¢**åœ¨å‡†ç¡®ç‡å’Œæ•ˆç‡ä¹‹é—´å–å¾—äº†æ›´ä¼˜å¹³è¡¡ï¼ŒæŒ‘æˆ˜äº†â€œå¿…é¡» token-level æ§åˆ¶â€çš„ä¸»æµå‡è®¾ã€‚
3. **å®è¯é©±åŠ¨çš„ switch cues æ›´æœ‰æ•ˆ**ï¼šç›¸æ¯”äººå·¥è®¾è®¡æˆ–é€šç”¨å¯å‘å¼è§„åˆ™ï¼Œ**åŸºäºæ¨¡å‹è‡ªèº«ç”Ÿæˆä¸ç¡®å®šæ€§çš„ cues é€‰æ‹©æ›´å…·é²æ£’æ€§**ã€‚
4. **ä¸ speculative decoding å®Œå…¨å…¼å®¹**ï¼šç”±äºä¸å¹²æ‰°è¿ç»­ç”Ÿæˆæµç¨‹ï¼ŒRelayGen å¯ä¸ Eagle-3 ç­‰æ–¹æ³•å åŠ ï¼Œå®ç° **2.2Ã— åŠ é€Ÿ**ï¼Œæ˜¯å½“å‰å”¯ä¸€èƒ½æœ‰æ•ˆç»„åˆçš„æ–¹æ³•ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–æ˜¾å¼æ¨ç†ç»“æ„**ï¼šè¦æ±‚æ¨¡å‹è¾“å‡ºå…·æœ‰æ˜ç¡®çš„ `<think>` å’Œ `</think>` åˆ†éš”ç¬¦ï¼Œé€‚ç”¨äºç°ä»£ LRMsï¼Œä½†å¯¹éšå¼æ¨ç†ä»»åŠ¡å¯èƒ½æ— æ•ˆã€‚
- **å°æ¨¡å‹éœ€å…·å¤‡ä¸€å®šèƒ½åŠ›**ï¼šè‹¥å°æ¨¡å‹è¿‡äºå¼±å°ï¼Œå³ä½¿åœ¨ä½éš¾åº¦æ®µä¹Ÿå¯èƒ½å‡ºé”™ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚
- **è¯­è¨€é™åˆ¶**ï¼šç›®å‰å®éªŒé›†ä¸­åœ¨è‹±æ–‡ï¼Œå¤šè¯­è¨€æ‰©å±•å°šæœªéªŒè¯ã€‚
- **é™æ€ cue set**ï¼šswitch cues åœ¨éƒ¨ç½²å‰å›ºå®šï¼Œæ— æ³•åŠ¨æ€é€‚åº”æ–°ä»»åŠ¡åˆ†å¸ƒã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ¢ç´¢å¤šè¯­è¨€åœºæ™¯ä¸‹çš„é€šç”¨æ€§ã€‚
- è®¾è®¡åŠ¨æ€æ›´æ–° switch cues çš„æœºåˆ¶ä»¥é€‚åº”æ–°ä»»åŠ¡ã€‚
- å°† RelayGen æ€æƒ³åº”ç”¨äºéæ¨ç†ç±»é•¿æ–‡æœ¬ç”Ÿæˆï¼ˆå¦‚å†™ä½œã€ä»£ç ç”Ÿæˆï¼‰ã€‚
- ç»“åˆæ›´å¤šæ¨ç†åŠ é€ŸæŠ€æœ¯ï¼ˆå¦‚ KV cache sharingã€early exitingï¼‰è¿›ä¸€æ­¥ä¼˜åŒ–æ•ˆç‡ã€‚

---

> **ä¸€å¥è¯æ€»ç»“**ï¼š  
> RelayGen é€šè¿‡**æ— éœ€è®­ç»ƒã€åŸºäºå®è¯åˆ†æçš„æ®µè½çº§æ¨¡å‹åˆ‡æ¢**ï¼Œå®ç°äº†åœ¨å‡ ä¹ä¸æŸå¤±å‡†ç¡®ç‡çš„æƒ…å†µä¸‹æ˜¾è‘—é™ä½ LRM æ¨ç†å»¶è¿Ÿï¼Œå¹¶é¦–æ¬¡è¯æ˜**ç²—ç²’åº¦æ§åˆ¶ + speculative decoding** æ˜¯é«˜æ•ˆæ¨ç†çš„å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 8. [DAWN: Dependency-Aware Fast Inference for Diffusion LLMs](https://arxiv.org/abs/2602.06953)

**Authors**: Lizhuo Luo, Zhuoran Shi, Jiajun Luo, Zhi Wang, Shen Ren, Wenya Wang, Tianwei Zhang  
**Category**: cs.CL  
**Published**: 2026-02-09  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2602.06953v1  

#### Abstract
Diffusion large language models (dLLMs) have shown advantages in text generation, particularly due to their inherent ability for parallel decoding. However, constrained by the quality--speed trade-off, existing inference solutions adopt conservative parallel strategies, leaving substantial efficienc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# DAWN: Dependency-Aware Fast Inference for Diffusion LLMs è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
ç°æœ‰çš„ **diffusion LLMs (dLLMs)** è™½ç„¶å…·å¤‡å¹¶è¡Œè§£ç æ½œåŠ›ï¼Œä½†åœ¨å®é™…æ¨ç†ä¸­å—é™äºâ€œ**è´¨é‡-é€Ÿåº¦æƒè¡¡**â€ï¼ˆquality-speed trade-offï¼‰ã€‚ä¸»æµçš„å¹¶è¡Œè§£ç ç­–ç•¥ä¾èµ–äº**ç½®ä¿¡åº¦é˜ˆå€¼**ï¼ˆconfidence thresholdï¼‰ç­‰å¯å‘å¼æ ‡å‡†æ¥é€‰æ‹©å¯åŒæ—¶è§£ç çš„ä½ç½®ï¼Œå‡è®¾å„ä½ç½®é¢„æµ‹æ˜¯ç‹¬ç«‹çš„ã€‚ç„¶è€Œï¼Œæ–‡æœ¬ä¸­çš„ token å­˜åœ¨è¯­ä¹‰è€¦åˆï¼ˆsemantic couplingï¼‰ï¼Œå¿½ç•¥è¿™ç§ä¾èµ–å…³ç³»ä¼šå¯¼è‡´ç”Ÿæˆè´¨é‡æ˜¾è‘—ä¸‹é™ã€‚

å› æ­¤ï¼Œ**æ ¸å¿ƒæŒ‘æˆ˜åœ¨äºï¼šå¦‚ä½•åœ¨ä¿æŒç”Ÿæˆè´¨é‡çš„å‰æä¸‹ï¼Œå®‰å…¨åœ°æå‡ dLLMs çš„å¹¶è¡Œè§£ç ç¨‹åº¦**ã€‚

---

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
ä½œè€…æå‡º **DAWN** â€”â€” ä¸€ç§æ— éœ€è®­ç»ƒã€ä¾èµ–æ„ŸçŸ¥çš„å¿«é€Ÿæ¨ç†æ–¹æ³•ï¼ˆ**training-free, dependency-aware decoding**ï¼‰ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- åˆ©ç”¨ **attention maps** ä½œä¸ºè½»é‡çº§ä»£ç†ä¿¡å·ï¼Œä¼°è®¡ token ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼›
- æ„å»ºä¸€ä¸ª **Dependency Graph** æ¥æ˜¾å¼å»ºæ¨¡ä½ç½®é—´çš„ä¾èµ–ï¼›
- åŸºäºæ­¤å›¾è®¾è®¡ä¸¤ç§æœºåˆ¶ï¼š
  1. **Anchor-Guided Decoding**ï¼šå°†é«˜ç½®ä¿¡åº¦å·²è§£ç  token è§†ä¸ºâ€œé”šç‚¹â€ï¼ˆanchorsï¼‰ï¼Œå…è®¸ä¸å…¶å¼ºç›¸å…³çš„ä½ç½®ä¿¡åº¦ä½ç½®æå‰è§£ç ï¼›
  2. **Conflict-Based Scheduling**ï¼šè¯†åˆ«ä¾èµ–å›¾ä¸­å­˜åœ¨å†²çªï¼ˆå¼ºè€¦åˆï¼‰çš„ä½ç½®å¯¹ï¼Œé¿å…å®ƒä»¬è¢«åŒæ—¶è§£ç ï¼Œä»è€Œå‡å°‘é”™è¯¯ä¼ æ’­ã€‚

è¯¥æ–¹æ³•å®ç°äº†æ›´æ¿€è¿›ä½†å¯é çš„å¹¶è¡Œè§£ç ï¼Œåœ¨ä¸ç‰ºç‰²è´¨é‡çš„å‰æä¸‹å¤§å¹…æå‡æ•ˆç‡ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | DAWN çš„ä¼˜åŠ¿ |
|------|-------------|
| **æ— éœ€è®­ç»ƒ** | å®Œå…¨åŸºäºæ¨ç†æ—¶åŠ¨æ€æ„å»ºçš„ attention ä¿¡æ¯ï¼Œæ— éœ€é¢å¤–è®­ç»ƒæˆ–å¾®è°ƒï¼› |
| **æ›´é«˜æ•ˆåˆ©ç”¨å¹¶è¡Œæ€§** | æ˜¾å¼å»ºæ¨¡ä¾èµ–å…³ç³»ï¼Œçªç ´ä¼ ç»Ÿä¿å®ˆé˜ˆå€¼é™åˆ¶ï¼Œè§£é”æ›´å¤šå®‰å…¨å¹¶è¡Œæ›´æ–°æœºä¼šï¼› |
| **æ›´å¼ºçš„è´¨é‡ä¿éšœ** | é€šè¿‡å†²çªè§„é¿æœºåˆ¶é˜²æ­¢å¼ºè€¦åˆä½ç½®åŒæ—¶è§£ç ï¼Œé™ä½é”™è¯¯ç‡ï¼› |
| **é€šç”¨æ€§å¼º** | å¯åº”ç”¨äºå¤šç§ dLLM æ¶æ„ï¼Œå®éªŒéªŒè¯äº†å¤šä¸ªæ¨¡å‹ä¸Šçš„æœ‰æ•ˆæ€§ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
å®éªŒè¦†ç›–å¤šä¸ªå…·æœ‰ä»£è¡¨æ€§çš„åŸºå‡†ä»»åŠ¡ï¼Œæ¶µç›–æ•°å­¦æ¨ç†ä¸ä»£ç ç”Ÿæˆï¼š
- **GSM8K** (5-shot)ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜
- **MATH** (4-shot)ï¼šé«˜ä¸­éš¾åº¦æ•°å­¦é—®é¢˜
- **HumanEval** (0-shot)ï¼šPython å‡½æ•°è¡¥å…¨
- **MBPP** (3-shot)ï¼šé¢å‘ç¼–ç¨‹ä»»åŠ¡çš„å°è§„æ¨¡åŸºå‡†

---

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
#### æ¨¡å‹
- **LLaDA-8B-Instruct**, **LLaDA-1.5**
- **Dream-v0-Base-7B**, **Dream-v0-Instruct-7B**

#### ç¡¬ä»¶ä¸å‚æ•°
- ç¡¬ä»¶å¹³å°ï¼šNVIDIA H100 80GB GPU
- ç”Ÿæˆé•¿åº¦ï¼š256 tokens
- æ³¨æ„åŠ›å±‚å¹³å‡èŒƒå›´ï¼šæœ€å 4 å±‚
- é«˜ç½®ä¿¡åº¦é˜ˆå€¼ $ T_{\text{high}} = 0.9 $

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Accuracy (Acc.)** | ä»»åŠ¡æ­£ç¡®ç‡ï¼ˆpass@kï¼‰ |
| **Tokens Per Second (TPS)** | æ¨ç†ååé‡ |
| **Speedup** | ç›¸å¯¹äºåŸå§‹é‡‡æ ·æ–¹æ³•çš„é€Ÿåº¦æå‡å€æ•° |
| **Number of Function Evaluations (NFE)** | å®Œæˆç”Ÿæˆæ‰€éœ€çš„å»å™ªæ­¥æ•°ï¼Œåæ˜ æ•ˆç‡ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
DAWN ä¸ä»¥ä¸‹ä¸»æµåŸºçº¿è¿›è¡Œæ¯”è¾ƒï¼š
| åŸºçº¿æ–¹æ³• | ç®€è¦è¯´æ˜ |
|--------|---------|
| **Original (Top-1 Sampling)** | æ¯æ­¥ä»…è§£ç ç½®ä¿¡åº¦æœ€é«˜çš„å•ä¸ª token |
| **Confidence-Aware Parallel** (Fast-dLLM) | è®¾å®šç½®ä¿¡åº¦é˜ˆå€¼ï¼Œé«˜äºåˆ™å¹¶è¡Œè§£ç  |
| **KLASS** | ç»“åˆ KL æ•£åº¦è¡¡é‡åˆ†å¸ƒç¨³å®šæ€§è¿›è¡Œç­›é€‰ |
| **LocalLeap** | åŸºäºå±€éƒ¨ç¡®å®šæ€§å‡è®¾è¿›è¡ŒåŒºåŸŸåŒ–å¹¶è¡Œè§£ç  |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰
DAWN åœ¨å¤šä¸ªæ¨¡å‹å’Œæ•°æ®é›†ä¸Šå‡å®ç°æ˜¾è‘—åŠ é€Ÿï¼Œä¸”ä¿æŒç”šè‡³ç•¥å¾®æå‡å‡†ç¡®ç‡ï¼š

| æ¨¡å‹ | æ•°æ®é›† | Acc. (%) | Speedup Ã— | TPS |
|------|--------|----------|-----------|-----|
| LLaDA-8B-Instruct | GSM8K | 77.94 | **4.33Ã—** | 44.72 |
| LLaDA-1.5 | MBPP | 37.60 | **8.06Ã—** | 27.80 |
| Dream-v0-Instruct-7B | HumanEval | 54.88 | **2.66Ã—** | 60.23 |
| Dream-v0-Base-7B | MBPP | 53.20 | **5.45Ã—** | 64.55 |

> âœ… **æœ€é«˜è¾¾ 8.06Ã— åŠ é€Ÿ**ï¼ŒåŒæ—¶ç²¾åº¦åŸºæœ¬æŒå¹³æˆ–ç•¥æœ‰ä¸Šå‡ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- ç›¸è¾ƒäº **Confidence-Aware** å’Œ **KLASS**ï¼š
  - DAWN å®ç°æ›´é«˜ TPSï¼ˆååé‡ï¼‰ï¼Œä¸”ç²¾åº¦ç›¸å½“æˆ–æ›´ä¼˜ï¼›
  - è¡¨æ˜ä»…é ç½®ä¿¡åº¦æˆ– KL æ•£åº¦ä¸è¶³ä»¥æ•æ‰ä½ç½®é—´å¤æ‚ä¾èµ–ã€‚
  
- ç›¸è¾ƒäº **LocalLeap**ï¼š
  - DAWN åœ¨å¤šæ•°åœºæ™¯ä¸‹è¿›ä¸€æ­¥æå‡ TPSï¼ˆ+0.05 ~ +5.17ï¼‰ï¼›
  - å¹¶åœ¨éƒ¨åˆ†ä»»åŠ¡ä¸Šæé«˜å‡†ç¡®ç‡æœ€å¤šè¾¾ **3.04%**ï¼›
  - æ˜¾ç¤ºå‡ºä¾èµ–å›¾å»ºæ¨¡æ¯”å±€éƒ¨ç¡®å®šæ€§å‡è®¾æ›´å…·æ™®é€‚æ€§å’Œè¡¨è¾¾èƒ½åŠ›ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Study, Table 2ï¼‰
ç§»é™¤å…³é”®ç»„ä»¶åæ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼ŒéªŒè¯å„æ¨¡å—ä½œç”¨ï¼š

| ç»„ä»¶ | å½±å“ |
|------|------|
| **-AGD**ï¼ˆç§»é™¤ Anchor-Guided Decodingï¼‰ | TPS ä¸‹é™ä¸¥é‡ï¼ˆå¦‚ä» 44.72 â†’ 22.31 on GSM8Kï¼‰ï¼Œè¯´æ˜é”šç‚¹å¼•å¯¼æ˜¯æé€Ÿä¸»å›  |
| **-CBS**ï¼ˆç§»é™¤ Conflict-Based Schedulingï¼‰ | å‡†ç¡®ç‡ç•¥å‡ä½† TPS ä¸‹é™ï¼Œè¡¨æ˜ CBS ç‰ºç‰²å°‘é‡å‡†ç¡®æ€§æ¢å–æ›´å¤§å¹¶è¡Œç©ºé—´ |
| **å®Œæ•´ DAWN** | åœ¨é€Ÿåº¦ä¸è´¨é‡ä¹‹é—´å–å¾—æœ€ä½³å¹³è¡¡ |

> ğŸ” ç»“è®ºï¼šä¸¤ä¸ªæ¨¡å—ååŒå·¥ä½œï¼Œ**AGD æ‰©å±•å¯è§£ç é›†åˆï¼ŒCBS æ§åˆ¶é£é™©**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **Attention Maps å¯ç”¨äºè¿‘ä¼¼ token ä¾èµ–å…³ç³»**ï¼Œå°½ç®¡å­˜åœ¨ attention sinks å¹²æ‰°ï¼Œä½†å¯é€šè¿‡è¿‡æ»¤ç¼“è§£ï¼›
2. **é«˜ç½®ä¿¡åº¦ token å¯ä½œä¸ºâ€œé”šç‚¹â€**ï¼Œæ˜¾è‘—æå‡å…¶ä¾èµ–ä½ç½®çš„å¯é¢„æµ‹æ€§ï¼Œå³ä½¿åè€…å½“å‰ç½®ä¿¡åº¦è¾ƒä½ï¼›
3. **å¼ºè€¦åˆçš„ä½ç½®ä¿¡åº¦ä½ç½®è‹¥åŒæ—¶è§£ç æ˜“å¼•å‘é”™è¯¯ç»„åˆ**ï¼ˆå¦‚ â€œhigh houseâ€ï¼‰ï¼Œåº”é¿å…å¹¶å‘ï¼›
4. **æ˜¾å¼å»ºæ¨¡ä¾èµ–å…³ç³»èƒ½æœ‰æ•ˆæ‰“ç ´ä¿å®ˆé˜ˆå€¼ç“¶é¢ˆ**ï¼Œå®ç°æ›´å®‰å…¨ã€é«˜æ•ˆçš„å¹¶è¡Œè§£ç ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ– attention map çš„è´¨é‡**ï¼šè‹¥ attention ä¸èƒ½å‡†ç¡®åæ˜ è¯­ä¹‰ä¾èµ–ï¼ˆå¦‚æ³¨æ„åŠ›åˆ†æ•£æˆ–è¯¯å¯¼ï¼‰ï¼Œæ•ˆæœå¯èƒ½å—é™ï¼›
- **å›¾æ„å»ºå¼•å…¥é¢å¤–è®¡ç®—å¼€é”€**ï¼šè™½ç„¶è½»é‡ï¼Œä½†ä»éœ€å¤„ç† attention çŸ©é˜µå¹¶æ„å»ºå›¾ç»“æ„ï¼›
- **è¶…å‚æ•°æ•æ„Ÿæ€§**ï¼šå¦‚ $ T_{\text{edge}}, T_{\text{sink}}, T_{\text{low}} $ éœ€é’ˆå¯¹ä¸åŒæ¨¡å‹è°ƒä¼˜ï¼ˆè§ Appendix Aï¼‰ï¼›
- **æœªè§£å†³ KV-Cache é—®é¢˜**ï¼šæœ¬æ–‡èšç„¦äºéç‹¬ç«‹é¢„æµ‹é—®é¢˜ï¼ŒKV-Cache ä¼˜åŒ–ä»ç”±å…¶ä»–å·¥ä½œå¤„ç†ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ›´ç²¾ç¡®çš„ä¾èµ–å»ºæ¨¡**ï¼šæ¢ç´¢ç»“åˆ probing æˆ–ä¸­é—´è¡¨ç¤ºå­¦ä¹ æ›´å‡†ç¡®çš„ä¾èµ–å…³ç³»ï¼›
2. **åŠ¨æ€å›¾æ›´æ–°æœºåˆ¶**ï¼šéšå»å™ªè¿‡ç¨‹æ¼”è¿›è‡ªé€‚åº”è°ƒæ•´ä¾èµ–å›¾ï¼›
3. **ä¸å…¶ä»–åŠ é€ŸæŠ€æœ¯èåˆ**ï¼šå¦‚ä¸ speculative decodingã€early stopping æˆ– KV-Cache ä¼˜åŒ–è”åˆä½¿ç”¨ï¼›
4. **æ‰©å±•è‡³å¤šæ¨¡æ€ dLLMs**ï¼šåº”ç”¨äºå›¾æ–‡ç”Ÿæˆç­‰ multimodal diffusion æ¨¡å‹ï¼›
5. **ç†è®ºåˆ†æ**ï¼šå½¢å¼åŒ–è¯æ˜ä¾èµ–æ„ŸçŸ¥è§£ç çš„å®‰å…¨è¾¹ç•Œä¸æ”¶æ•›æ€§è´¨ã€‚

---

> ğŸ“Œ **æ€»ä½“è¯„ä»·**ï¼šDAWN æä¾›äº†ä¸€ä¸ªæ–°é¢–è€Œå®ç”¨çš„è§†è§’â€”â€”å°† dLLM è§£ç è§†ä¸ºä¸€ä¸ª**ä¾èµ–é©±åŠ¨çš„è°ƒåº¦é—®é¢˜**ï¼Œè€Œéç®€å•çš„ç½®ä¿¡åº¦è¿‡æ»¤ã€‚å®ƒä¸ºå®ç°é«˜è´¨é‡ã€é«˜æ•ˆç‡çš„æ‰©æ•£è¯­è¨€æ¨¡å‹æ¨ç†å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚  
> é¡¹ç›®ä»£ç å·²å¼€æºï¼š[https://github.com/lizhuo-luo/DAWN](https://github.com/lizhuo-luo/DAWN)

</details>

---

### 9. [FlashSketch: Sketch-Kernel Co-Design for Fast Sparse Sketching on GPUs](https://arxiv.org/abs/2602.06071)

**Authors**: Rajat Vadiraj Dwaraknath, Sungyoon Kim, Mert Pilanci  
**Category**: cs.DC  
**Published**: 2026-02-09  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2602.06071v1  

#### Abstract
Sparse sketches such as the sparse Johnson-Lindenstrauss transform are a core primitive in randomized numerical linear algebra because they leverage random sparsity to reduce the arithmetic cost of sketching, while still offering strong approximation guarantees. Their random sparsity, however, is at...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šFlashSketch: Sketch-Kernel Co-Design for Fast Sparse Sketching on GPUs**

---

## 1. **è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
ç°ä»£ GPU åœ¨æ‰§è¡Œç¨€ç– sketchingï¼ˆå¦‚ç¨€ç– Johnson-Lindenstrauss å˜æ¢ï¼ŒSJLTï¼‰æ—¶é¢ä¸´æ˜¾è‘—æ€§èƒ½ç“¶é¢ˆã€‚å°½ç®¡ç¨€ç– sketching èƒ½é™ä½è®¡ç®—å¤æ‚åº¦å¹¶æä¾›è‰¯å¥½çš„è¿‘ä¼¼ä¿è¯ï¼Œä½†å…¶**éšæœºç¨€ç–æ€§å¯¼è‡´ä¸è§„åˆ™å†…å­˜è®¿é—®æ¨¡å¼**ï¼Œä»è€Œå¼•å‘ä»¥ä¸‹é—®é¢˜ï¼š
- å†…å­˜å¸¦å®½åˆ©ç”¨ç‡ä½
- å…¨å±€åŸå­æ“ä½œï¼ˆglobal atomicsï¼‰é€ æˆä¸¥é‡äº‰ç”¨å’Œä¸²è¡ŒåŒ–
- ç°æœ‰å®ç°ï¼ˆå¦‚ GraSS æˆ– cuSPARSEï¼‰æ— æ³•å……åˆ†å‘æŒ¥ GPU å¹¶è¡Œèƒ½åŠ›

è¿™å½¢æˆäº†ä¸€ä¸ªæ ¹æœ¬çŸ›ç›¾ï¼š
> **ç†è®ºä¸Šçš„â€œå¼ºéšæœºæ€§â€ä¸ç¡¬ä»¶ä¸Šçš„â€œé«˜æ•ˆæ‰§è¡Œâ€ä¹‹é—´çš„å¼ åŠ›ã€‚**

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯**
ä½œè€…æå‡º **sketch-kernel co-designï¼ˆè‰å›¾-å†…æ ¸ååŒè®¾è®¡ï¼‰** æ–¹æ³•ï¼Œé€šè¿‡è½¯ç¡¬ä»¶è”åˆä¼˜åŒ–æ¥å¹³è¡¡ sketching çš„è´¨é‡ä¸é€Ÿåº¦ã€‚

#### **æ ¸å¿ƒåˆ›æ–°ï¼šBLOCKPERM-SJLT + FLASHSKETCH**
- **æ–° sketch å®¶æ—ï¼šBLOCKPERM-SJLT**
  - åœ¨ä¼ ç»Ÿ SJLT åŸºç¡€ä¸Šå¼•å…¥**å—çº§ç»“æ„åŒ–ç¨€ç–æ€§**ã€‚
  - å°†è¾“å…¥/è¾“å‡ºç»´åº¦åˆ’åˆ†ä¸º `M` ä¸ªå—ã€‚
  - å—é—´è¿æ¥é‡‡ç”¨ **K ä¸ªè¾¹ä¸ç›¸äº¤çš„æ’åˆ—ï¼ˆedge-disjoint permutationsï¼‰** æ„æˆçš„å¹¶é›†ï¼Œå½¢æˆä¸€ä¸ª K-æ­£åˆ™äºŒåˆ†å›¾ã€‚
  - æ¯ä¸ªéé›¶å—å†…éƒ¨ä»ä½¿ç”¨æ ‡å‡† SJLT è¿›è¡Œç»†ç²’åº¦æ··åˆã€‚
  - å¼•å…¥å¯è°ƒå‚æ•° `K`ï¼šæ˜¾å¼æƒè¡¡ **GPU æ•ˆç‡**ï¼ˆå±€éƒ¨æ€§ï¼‰ä¸ **sketch é²æ£’æ€§**ï¼ˆæ··åˆç¨‹åº¦ï¼‰ã€‚

- **ä¸“ç”¨ CUDA å†…æ ¸ï¼šFLASHSKETCH**
  - åˆ©ç”¨ BLOCKPERM-SJLT çš„ç»“æ„ç‰¹æ€§ï¼Œå®Œå…¨**æ¶ˆé™¤å…¨å±€åŸå­æ“ä½œ**ã€‚
  - æ¯ä¸ª CUDA thread block è´Ÿè´£ä¸€ä¸ªè¾“å‡ºå—ï¼Œç§æœ‰åœ°åœ¨ shared memory ä¸­ç´¯ç§¯ç»“æœï¼ˆä½¿ç”¨ shared-memory atomicsï¼‰ï¼Œæœ€åä¸€æ¬¡æ€§å†™å›å…¨å±€å†…å­˜ã€‚
  - æ‰€æœ‰éšæœºæ€§ï¼ˆæ’åˆ—é€‰æ‹©ã€å“ˆå¸Œç›®æ ‡ï¼‰å‡åœ¨å†…æ ¸ä¸­**å®æ—¶ç”Ÿæˆï¼ˆon-the-flyï¼‰**ï¼Œé¿å…å­˜å‚¨ç¨€ç–ç´¢å¼•ç»“æ„ï¼Œå‡å°‘å¸¦å®½å‹åŠ›ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹é¢ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ GraSS SJLTï¼‰ | FLASHSKETCH |
|------|--------------------------|-----------|
| å†…å­˜è®¿é—® | ä¸è§„åˆ™ï¼Œé«˜å†²çª | ç»“æ„åŒ–ï¼Œå—å±€éƒ¨ |
| åŸå­æ“ä½œ | å¤§é‡ global atomics | ä»…ä½¿ç”¨ shared-memory atomicsï¼Œæ—  global atomics |
| éšæœºæ€§å­˜å‚¨ | éœ€é¢„æ„å»ºç¨€ç–çŸ©é˜µæˆ–ç´¢å¼•è¡¨ | on-the-fly ç”Ÿæˆï¼Œé›¶é¢å¤–å­˜å‚¨ |
| ååé‡ | å—é™äºåŸå­äº‰ç”¨ | æ›´é«˜å†…å­˜ååä¸å¹¶è¡Œåº¦ |
| è®¾è®¡ç†å¿µ | å…ˆè®¾è®¡ç®—æ³•å†é€‚é…ç¡¬ä»¶ | ç®—æ³•ä¸å†…æ ¸ååŒè®¾è®¡ |

---

## 2. **æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
å®éªŒæ¶µç›–å¤šç§ç±»å‹çš„æ•°æ®ä»¥éªŒè¯é€šç”¨æ€§ï¼š
- **åˆæˆæ•°æ®**ï¼š
  - `Synthetic Gaussian`: é«˜æ–¯éšæœºçŸ©é˜µ
  - `Synthetic Low-Rank + Noise`: ä½ç§©åŠ å™ªå£°çŸ©é˜µ
- **çœŸå®ä¸–ç•Œç¨€ç–çŸ©é˜µ**ï¼š
  - `SuiteSparse-spal_004`: ç¨€ç–ç§‘å­¦è®¡ç®—çŸ©é˜µï¼ˆå¯†åº¦ ~1.4%ï¼‰
- **æ·±åº¦å­¦ä¹ æƒé‡**ï¼š
  - `GPT2-medium stacked weights`
  - `Qwen2-1.5B stacked weights`

### **å®éªŒè®¾ç½®**
- **ç¡¬ä»¶å¹³å°**ï¼š
  - ä¸»è¦ï¼šNVIDIA RTX 4090
  - è¡¥å……ï¼šNVIDIA RTX A6000
- **ç²¾åº¦**ï¼šFP32 ç»Ÿä¸€æµ‹è¯•
- **è¿è¡Œæ—¶é—´æµ‹é‡**ï¼šä½¿ç”¨ CUDA Eventsï¼ŒæŠ¥å‘Š 10 æ¬¡è¿­ä»£çš„å¹³å‡å€¼ï¼ˆå«é¢„çƒ­ï¼‰
- **è°ƒä¼˜**ï¼šå¯¹ tile sizeã€block size ç­‰è¿›è¡Œæ¨¡æ¿åŒ–ç¼–è¯‘æ—¶è°ƒä¼˜

### **è¯„ä¼°æŒ‡æ ‡**
- **Gram Matrix Approximation Error**:
  $$
  E_{\text{Gram}} = \frac{\|A^\top A - (SA)^\top(SA)\|_F}{\|A^\top A\|_F}
  $$
- **Oblivious Subspace Embedding (OSE) Spectral Error**:
  $$
  E_{\text{OSE}} = \|Q^\top S^\top S Q - I\|_2, \quad Q = \text{orthonormal basis of } A
  $$
- **Sketch-and-Ridge Regression Residual**
- **Sketch-and-Solve Least Squares Residual**
- **End-to-End GraSS Pipeline**:
  - **æŠ•å½±è€—æ—¶**ï¼ˆper-sampleï¼‰
  - **å½’å› è´¨é‡**ï¼šLinear Datamodeling Score (**LDS**)

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
1. **Dense Gaussian (cuBLAS)**: å¯†é›†é«˜æ–¯æŠ•å½±ï¼Œä½¿ç”¨ cuBLAS GEMM
2. **SJLT (cuSPARSE)**: åŸºäº cuSPARSE SpMM çš„ç¨€ç– sketch
3. **SJLT (GraSS Kernel)**: GraSS å¼€æºå®ç°çš„ SJLT å†…æ ¸
4. **Subsampled Fast Hadamard Transform (SRHT/FHT)**: ä½¿ç”¨ Dao-AILab çš„ FHT å†…æ ¸

---

## 3. **ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
- **æ€»ä½“åŠ é€Ÿæ¯”**ï¼š
  - åœ¨å¤šä¸ªä»»åŠ¡å’Œæ•°æ®é›†ä¸Šï¼ŒFLASHSKETCH å®ç°äº† **å…¨å±€å‡ ä½•å¹³å‡åŠ é€Ÿçº¦ 1.7Ã—**ã€‚
  - ç›¸å¯¹äºæ¬¡ä¼˜åŸºçº¿ï¼ˆé€šå¸¸æ˜¯ GraSS SJLT å†…æ ¸ï¼‰ï¼Œ**å…¨å±€ geomean speedup è¾¾åˆ° 1.73Ã—**ï¼ˆè§ Table 1ï¼‰ã€‚

| ä»»åŠ¡ | vs. cuSPARSE | vs. GraSS Kernel | vs. FHT | vs. cuBLAS |
|------|-------------|------------------|--------|-----------|
| Gram Matrix Approx | 2.67Ã— | 4.17Ã— | 16.22Ã— | 7.64Ã— |
| OSE | 2.69Ã— | 4.16Ã— | 16.20Ã— | 7.63Ã— |
| Sketch-and-Ridge | 1.42Ã— | 1.54Ã— | 3.94Ã— | 3.10Ã— |
| Sketch-and-Solve | 1.37Ã— | 1.41Ã— | 3.33Ã— | 2.34Ã— |

> âœ… **ç»“è®º**ï¼šåœ¨æ‰€æœ‰ä»»åŠ¡ä¸­ï¼ŒFLASHSKETCH æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼Œå°¤å…¶åœ¨ Gram å’Œ OSE ä»»åŠ¡ä¸Šä¼˜åŠ¿å·¨å¤§ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- **é€Ÿåº¦æ–¹é¢**ï¼š
  - åœ¨ GPT2 æƒé‡ä¸Šï¼ŒGram çŸ©é˜µè¿‘ä¼¼ä»»åŠ¡ä¸­è¾¾åˆ° **4.43Ã— é€Ÿåº¦æå‡**ï¼ˆvs. GraSS Kernelï¼‰ã€‚
  - åœ¨ Qwen2-1.5B ä¸Šï¼ŒSketch-and-Ridge å›å½’æ€»æ—¶é—´æœ€é«˜æé€Ÿ **4.83Ã—**ã€‚
  - åœ¨ GraSS å½’å› ç®¡é“ä¸­ï¼Œå•æ ·æœ¬æŠ•å½±æ—¶é—´æœ€é«˜æé€Ÿ **~3.2Ã—**ã€‚

- **è´¨é‡æ–¹é¢**ï¼š
  - åœ¨ç›¸åŒ sketch dimension `k` ä¸‹ï¼ŒFLASHSKETCH çš„è¯¯å·®ï¼ˆGram error, OSE errorï¼‰ä¸åŸºçº¿ç›¸å½“ç”šè‡³æ›´ä¼˜ã€‚
  - åœ¨ GraSS ç®¡é“ä¸­ï¼Œ**LDS åˆ†æ•°ä¿æŒä¸å˜æˆ–ç•¥æœ‰æå‡**ï¼Œè¯´æ˜åŠ é€Ÿæœªç‰ºç‰²å½’å› è´¨é‡ã€‚

### **æ¶ˆèå®éªŒç»“æœ**
- **å‚æ•° `K` çš„å½±å“**ï¼š
  - `K=1`ï¼šæ¥è¿‘ block-diagonal å±€éƒ¨ sketchï¼Œé€Ÿåº¦å¿«ä½†æ··åˆä¸è¶³ï¼Œè´¨é‡è¾ƒå·®ã€‚
  - `Kâ†‘`ï¼šå¢å¼ºæ··åˆï¼Œæé«˜ sketch è´¨é‡ï¼Œä½†å¢åŠ è¾“å…¥è¯»å–æ¬¡æ•°ã€‚
  - å­˜åœ¨ä¸€ä¸ª**å¸•ç´¯æ‰˜æœ€ä¼˜å‰æ²¿**ï¼Œ`K` çš„é€‰æ‹©å¯åœ¨é€Ÿåº¦ä¸è´¨é‡é—´çµæ´»æƒè¡¡ã€‚
- **ä¸åŒ `(K,s)` ç»„åˆ**ï¼š
  - å›¾è¡¨æ˜¾ç¤ºï¼ŒFLASHSKETCH çš„ `(K,s)` é…ç½®èƒ½ç¨³å®šå æ® Pareto å‰æ²¿ï¼Œè€ŒåŸºçº¿æ— æ³•åŒæ—¶å…¼é¡¾é«˜é€Ÿä¸é«˜è´¨é‡ã€‚

---

## 4. **å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **ååŒè®¾è®¡æ˜¯çªç ´ç“¶é¢ˆçš„å…³é”®**ï¼š
   - å•çº¯ä¼˜åŒ– kernel æˆ–æ”¹è¿› sketch ç®—æ³•ä¸è¶³ä»¥è§£å†³ GPU ä¸Šç¨€ç– sketching çš„æ•ˆç‡é—®é¢˜ã€‚
   - **ç®—æ³•ç»“æ„å¿…é¡»ä¸ºç¡¬ä»¶æœåŠ¡**ï¼Œè€Œç¡¬ä»¶ä¼˜åŒ–ä¹Ÿéœ€ä¾èµ–ç®—æ³•æä¾›çš„ç»“æ„åŒ–å…ˆéªŒã€‚

2. **ç»“æ„åŒ–ç¨€ç–æ€§å¯ä»¥å…¼å…·æ•ˆç‡ä¸é²æ£’æ€§**ï¼š
   - BLOCKPERM-SJLT è¯æ˜äº†é€šè¿‡ **union-of-permutations** çš„å—çº§å¸ƒçº¿ï¼Œå¯ä»¥åœ¨ä¿ç•™è¶³å¤Ÿéšæœºæ€§çš„å‰æä¸‹ï¼Œæå¤§æå‡ GPU å‹å¥½æ€§ã€‚

3. **æ¶ˆé™¤ global atomics æ˜¯æ€§èƒ½é£è·ƒçš„æ ¸å¿ƒ**ï¼š
   - FLASHSKETCH é€šè¿‡å°† accumulation ç§»è‡³ shared memoryï¼Œå½»åº•è§„é¿äº† global atomic contentionï¼Œè¿™æ˜¯å…¶æ€§èƒ½é¢†å…ˆçš„æ ¹æœ¬åŸå› ã€‚

4. **å¯è°ƒå‚æ•° `K` æä¾›å®ç”¨çµæ´»æ€§**ï¼š
   - ç”¨æˆ·å¯æ ¹æ®åº”ç”¨åœºæ™¯ï¼ˆå¦‚å¯¹é€Ÿåº¦æ•æ„Ÿ vs å¯¹ç²¾åº¦æ•æ„Ÿï¼‰è°ƒæ•´ `K`ï¼Œå®ç°å®šåˆ¶åŒ– trade-offã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **æœ€é€‚ç”¨äº `A` ä¸ºç¨ å¯†ä¸” `k < d` ä½† `k` è¶³å¤Ÿå¤§ä»¥é¥±å’Œ GPU çš„åœºæ™¯**ã€‚
- åœ¨æå° `k` åœºæ™¯ä¸‹ï¼Œoccupancy è¾ƒä½ï¼Œæ€§èƒ½å¢ç›Šå—é™ï¼ˆè™½é€šè¿‡ split-Bc fallback ç¼“è§£ï¼‰ã€‚
- å½“ `K` è¿‡å¤§æ—¶ï¼Œå¤šæ¬¡è¯»å–è¾“å…¥å—å¯èƒ½æˆä¸ºç“¶é¢ˆã€‚
- ç†è®ºåˆ†æåŸºäºç‹¬ç«‹å‡åŒ€æ’åˆ—å‡è®¾ï¼Œå®é™…å®ç°ä½¿ç”¨è½»é‡çº§ç»“æ„åŒ–æ’åˆ—ï¼Œå­˜åœ¨è½»å¾®ä¾èµ–ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- **è‡ªé€‚åº” `K` é€‰æ‹©æœºåˆ¶**ï¼šæ ¹æ®è¾“å…¥æ•°æ®ç»Ÿè®¡ç‰¹å¾ï¼ˆå¦‚ coherenceï¼‰åŠ¨æ€é€‰æ‹©æœ€ä¼˜ `K`ã€‚
- **æ‰©å±•åˆ°å…¶ä»– sketch ç±»å‹**ï¼šå°† co-design æ€æƒ³åº”ç”¨äº CountSketchã€OSNAP ç­‰ã€‚
- **æ¢ç´¢æ›´ä½ç²¾åº¦ï¼ˆå¦‚ FP16/BF16ï¼‰ä¸‹çš„ä¼˜åŒ–**ï¼šç»“åˆ Tensor Core è¿›ä¸€æ­¥åŠ é€Ÿã€‚
- **åˆ†å¸ƒå¼/å¤š GPU æ‰©å±•**ï¼šç ”ç©¶ BLOCKPERM-SJLT åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­çš„é€šä¿¡æ•ˆç‡ã€‚
- **tighter ç†è®ºç•Œ**ï¼šé’ˆå¯¹ Gram matrix metrics æ¨å¯¼æ›´ç´§çš„è¯¯å·®ç•Œï¼Œå¹¶å…³è”è‡³ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ã€‚

--- 

> ğŸ”— **ä»£ç å¼€æº**ï¼š  
> ä½œè€…å·²å…¬å¼€ä»£ç ï¼š[https://github.com/rajatvd/flash-sketch-arxiv](https://github.com/rajatvd/flash-sketch-arxiv)

</details>

---

### 10. [Canzona: A Unified, Asynchronous, and Load-Balanced Framework for Distributed Matrix-based Optimizers](https://arxiv.org/abs/2602.06079)

**Authors**: Liangyu Wang, Siqi Zhang, Junjie Wang, Yiming Dong, Bo Zheng, Zihan Qiu, Shengkun Tang, Di Wang, Rui Men, Dayiheng Liu  
**Category**: cs.DC  
**Published**: 2026-02-09  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2602.06079v1  

#### Abstract
The scaling of Large Language Models (LLMs) drives interest in matrix-based optimizers (e.g., Shampoo, Muon, SOAP) for their convergence efficiency; yet their requirement for holistic updates conflicts with the tensor fragmentation in distributed frameworks like Megatron. Existing solutions are subo...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šCanzona: A Unified, Asynchronous, and Load-Balanced Framework for Distributed Matrix-based Optimizers**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
ç°ä»£å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è®­ç»ƒä¸­ï¼Œ**Matrix-based Optimizers**ï¼ˆå¦‚ Shampooã€Muonã€SOAPï¼‰å› å…¶ä¼˜è¶Šçš„æ”¶æ•›æ•ˆç‡å—åˆ°å…³æ³¨ã€‚ç„¶è€Œï¼Œè¿™äº›ä¼˜åŒ–å™¨è¦æ±‚å¯¹å®Œæ•´å¼ é‡è¿›è¡Œæ“ä½œï¼ˆå³æ»¡è¶³ **Atomicity Constraint**ï¼‰ï¼Œè€Œä¸»æµåˆ†å¸ƒå¼æ¡†æ¶ï¼ˆå¦‚ Megatronï¼‰é‡‡ç”¨çš„ **Tensor Fragmentation**ï¼ˆå¦‚ ZeRO-1 å’Œ Tensor Parallelismï¼‰ä¼šå°†å‚æ•°åˆ‡åˆ†åˆ°ä¸åŒè®¾å¤‡ä¸Šï¼Œå¯¼è‡´æ— æ³•ç›´æ¥åº”ç”¨ Matrix-based Optimizersã€‚

ç°æœ‰è§£å†³æ–¹æ¡ˆå­˜åœ¨ä¸¥é‡ç¼ºé™·ï¼š
- **Synchronous Compute (SC)**ï¼šåœ¨æ‰€æœ‰è®¾å¤‡ä¸Šå¤åˆ¶ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œé€ æˆè®¡ç®—å†—ä½™ï¼Œæ‰©å±•æ€§å·®ã€‚
- **Layer-wise Partitioning**ï¼ˆå¦‚ NVIDIA çš„ `layerwise_optimizer`ï¼‰ï¼šè™½ç„¶é¿å…äº†å¼ é‡åˆ‡åˆ†ï¼Œä½†ç ´åäº† ZeRO-1 çš„ **Geometric Constraints**ï¼Œå¯¼è‡´å¿…é¡»ä½¿ç”¨é€šä¿¡å¼€é”€æ›´å¤§çš„ **All-Reduce** è€Œéé«˜æ•ˆçš„ **Reduce-Scatter**ï¼Œå¹¶å¼•å…¥é¢å¤–çš„ **All-Gather/Broadcast** æ“ä½œã€‚

### **æå‡ºçš„æ–°æ–¹æ³•**
è®ºæ–‡æå‡ºäº† **Canzona**ï¼Œä¸€ä¸ªç»Ÿä¸€ã€å¼‚æ­¥ä¸”è´Ÿè½½å‡è¡¡çš„åˆ†å¸ƒå¼çŸ©é˜µä¼˜åŒ–å™¨æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ **è§£è€¦é€»è¾‘ä¸Šçš„ä¼˜åŒ–å™¨ä»»åŠ¡åˆ†é…ä¸ç‰©ç†ä¸Šçš„å‚æ•°åˆ†å¸ƒ**ã€‚

#### **ä¸»è¦åˆ›æ–°ç‚¹**
1. **Unified & Decoupled Architecture**
   - å°†ä¼˜åŒ–å™¨ä»»åŠ¡çš„é€»è¾‘å½’å±ï¼ˆlogical ownershipï¼‰ä¸å‚æ•°çš„ç‰©ç†å­˜å‚¨åˆ†ç¦»ï¼Œæ”¯æŒä»»æ„ Matrix-based Optimizer çš„é€šç”¨æŠ½è±¡ã€‚

2. **Data Parallelism (DP) å±‚é¢ï¼šÎ±-Balanced Static Partitioning**
   - æå‡ºä¸€ç§é™æ€åˆ†åŒºç­–ç•¥ï¼Œåœ¨å°Šé‡ **Atomicity Constraint** çš„åŒæ—¶ï¼Œä¿æŒä¸ ZeRO-1 å…¼å®¹çš„ **Geometric Constraints**ã€‚
   - å¼•å…¥ **Î±-Balanced Greedy LPT ç®—æ³•**ï¼Œé€šè¿‡æ§åˆ¶å‚æ•° Î± åœ¨â€œå…¨å±€è´Ÿè½½å‡è¡¡â€ä¸â€œé€šä¿¡å‡åŒ€æ€§â€ä¹‹é—´æƒè¡¡ï¼Œæœ‰æ•ˆç¼“è§£å› çŸ©é˜µè¿ç®—å¤æ‚åº¦éçº¿æ€§ï¼ˆå¦‚ç«‹æ–¹çº§ï¼‰å¸¦æ¥çš„è´Ÿè½½ä¸å‡é—®é¢˜ã€‚

3. **Tensor Parallelism (TP) å±‚é¢ï¼šAsynchronous Micro-Group Scheduling**
   - è®¾è®¡å¼‚æ­¥è®¡ç®—æµæ°´çº¿ï¼Œå°†å¤šä¸ªè¢«åˆ‡åˆ†çš„å¼ é‡æ›´æ–°æ‰“åŒ…ä¸º **Micro-Group**ï¼Œåˆ©ç”¨èåˆçš„ **All-to-All** é€šä¿¡æ‰¹é‡é‡å»ºæ¢¯åº¦ï¼Œéšè—é€šä¿¡å¼€é”€ã€‚
   - æå‡º **Greedy Rollback è°ƒåº¦ç®—æ³•**ï¼ŒåŠ¨æ€å¹³è¡¡å„è®¾å¤‡çš„è®¡ç®—è´Ÿè½½ï¼Œæ¶ˆé™¤æµæ°´çº¿æ°”æ³¡ï¼ˆpipeline bubblesï¼‰ã€‚

4. **é›¶é€šä¿¡ä¼˜åŒ–å™¨æ›´æ–°ï¼ˆZero-Communication Optimizer Stepï¼‰**
   - åœ¨ DP å±‚é¢ï¼Œæ¯ä¸ª rank åªè´Ÿè´£å…¶æ‹¥æœ‰çš„å‚æ•°çš„ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œæ— éœ€è·¨èŠ‚ç‚¹åŒæ­¥ï¼Œå®ç°çœŸæ­£çš„å±€éƒ¨æ›´æ–°ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ¨¡å‹ä¸ä¼˜åŒ–å™¨**
- **æ¨¡å‹å®¶æ—**ï¼šQwen3ï¼ˆ1.7B åˆ° 32B å‚æ•°ï¼‰
- **ä¼˜åŒ–å™¨**ï¼šMuonï¼ˆä¸»å®éªŒï¼‰ã€Shampooã€SOAPï¼ˆæ³›åŒ–æ€§éªŒè¯ï¼‰

### **å®éªŒè®¾ç½®**
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼šæœ€å¤š 512 å— GPU çš„é›†ç¾¤
- **å…¸å‹é…ç½®**ï¼š256 GPUsï¼ŒDP=32ï¼ŒTP=8
- **åºåˆ—é•¿åº¦**ï¼š4096
- **æ¯ DP rank æ‰¹å¤§å°**ï¼š1

### **è¯„ä¼°æŒ‡æ ‡**
1. **ç«¯åˆ°ç«¯è¿­ä»£æ—¶é—´ï¼ˆEnd-to-End Iteration Timeï¼‰**
2. **ä¼˜åŒ–å™¨æ­¥éª¤å»¶è¿Ÿï¼ˆOptimizer Step Latencyï¼‰**
3. **å‰å‘-åå‘ä¼ æ’­æ—¶é—´ï¼ˆFwd-Bwd Timeï¼‰**
4. **è´Ÿè½½å‡è¡¡æ¯”ï¼ˆLoad-Balance Ratio, RLBï¼‰**ï¼š
   $$
   RLB = \frac{\max_r(C_r)}{\text{avg}_r(C_r)}
   $$
   å…¶ä¸­ $ C_r $ ä¸ºç¬¬ $ r $ ä¸ª rank çš„å³°å€¼å†…å­˜æˆ– FLOPsã€‚
5. **ç²¾åº¦éªŒè¯**ï¼šè®­ç»ƒæŸå¤±æ›²çº¿å¯¹æ¯”ï¼Œç¡®ä¿æ”¶æ•›è¡Œä¸ºä¸€è‡´ã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| åŸºçº¿æ–¹æ³• | æè¿° |
|--------|------|
| **SC (Synchronous Compute)** | ç±»ä¼¼ DDPï¼Œå…¨é‡å¤åˆ¶ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œå­˜åœ¨ä¸¥é‡å†—ä½™ |
| **NV-layerwise** | NVIDIA çš„ `layerwise_optimizer`ï¼ŒæŒ‰å±‚åˆ†é…ï¼Œç ´å ZeRO å‡ ä½•çº¦æŸ |
| **ASC (Asynchronous Compute)** | æœ¬æ–‡æ¡†æ¶ä½†æ— è´Ÿè½½å‡è¡¡ï¼ˆablationï¼‰ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
- åœ¨ **256 GPUs** ä¸Šè®­ç»ƒ **Qwen3-32B** æ¨¡å‹æ—¶ï¼š
  - **ç«¯åˆ°ç«¯è¿­ä»£æ—¶é—´åŠ é€Ÿ 1.57Ã—**ï¼ˆ0.877s vs. 1.381sï¼‰
  - **ä¼˜åŒ–å™¨æ­¥éª¤å»¶è¿Ÿé™ä½ 5.8Ã—**ï¼ˆ0.066s vs. 0.383sï¼‰
  - **å‰å‘-åå‘æ—¶é—´å‡å°‘ 1.23Ã—**ï¼ˆ0.811s vs. 0.998sï¼‰

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
| å¯¹æ¯”é¡¹ | Canzona vs. NV-layerwise |
|-------|--------------------------|
| **æ€»è¿­ä»£æ—¶é—´** | â†“ 1.57Ã— |
| **ä¼˜åŒ–å™¨å»¶è¿Ÿ** | â†“ 5.8Ã— |
| **Fwd-Bwd æ—¶é—´** | â†“ 1.23Ã— |
| **é€šä¿¡æ¨¡å¼** | æ”¯æŒé«˜æ•ˆ Reduce-Scatterï¼ˆvs. All-Reduceï¼‰ |
| **æ”¶æ•›ä¸€è‡´æ€§** | å®Œå…¨ä¸€è‡´ï¼ˆloss æ›²çº¿é‡åˆï¼‰ |

> å›¾ 4 æ˜¾ç¤ºï¼ŒNV-layerwise å› éœ€æ‰§è¡Œé¢å¤–çš„ All-Gather/Broadcast æ¥åŒæ­¥æƒé‡ï¼Œæš´éœ²äº†å¤§é‡é€šä¿¡å»¶è¿Ÿï¼›è€Œ Canzona é€šè¿‡é™æ€åˆ†åŒºå’Œå¼‚æ­¥æµæ°´çº¿å®Œå…¨éšè—äº†è¿™äº›å¼€é”€ã€‚

### **æ¶ˆèå®éªŒç»“æœ**
#### **(1) è´Ÿè½½å‡è¡¡æœ‰æ•ˆæ€§ï¼ˆå›¾ 3ï¼‰**
- **æ— è´Ÿè½½å‡è¡¡ï¼ˆNaive Static Partitioningï¼‰**ï¼š
  - FLOPs ä¸å‡è¡¡æ¯”è¾¾ **3.24Ã—**
  - å†…å­˜ä¸å‡è¡¡æ¯”è¾¾ **2.46Ã—**
- **å¯ç”¨ Î±-Balanced å**ï¼š
  - FLOPs ä¸å‡è¡¡æ¯”é™è‡³ **1.43Ã—**
  - å†…å­˜ä¸å‡è¡¡æ¯”é™è‡³ **1.11Ã—**
  - æœ€å¤§æ­¥é•¿æ—¶é—´ä» 1.39 TFLOPs é™è‡³ **1.05 TFLOPs**

#### **(2) Î± å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼ˆå›¾ 13ï¼‰**
- å½“ Î± = 1ï¼ˆä¼˜å…ˆè´Ÿè½½å‡è¡¡ï¼‰æ—¶ï¼Œ**Muon æ—¶é—´æœ€ä½**ï¼Œè¡¨æ˜è®¡ç®— straggler æ˜¯ä¸»è¦ç“¶é¢ˆã€‚
- å³ä½¿é€šä¿¡å—å¤§å°ä¸å‡ï¼ŒMegatron çš„é‡å æœºåˆ¶ä»èƒ½æœ‰æ•ˆæ©ç›–é€šä¿¡ä¸å¹³è¡¡ï¼Œå› æ­¤ Î± = 1 ä¸ºæœ€ä¼˜é€‰æ‹©ã€‚

#### **(3) Micro-Group Fusion æ•ˆæœï¼ˆå›¾ 14ï¼‰**
- **No-Fuse**ï¼ˆé€å¼ é‡é€šä¿¡ï¼‰ï¼šå»¶è¿Ÿ ~0.11s
- **å¯ç”¨èåˆå**ï¼ˆCmax â‰¥ 512MBï¼‰ï¼šå»¶è¿Ÿé™è‡³ **~0.072s**
- è¡¨æ˜èåˆé€šä¿¡å¯æ˜¾è‘—æå‡å¸¦å®½åˆ©ç”¨ç‡ï¼Œé¥±å’Œåæ€§èƒ½ç¨³å®šã€‚

#### **(4) æ³›åŒ–æ€§æµ‹è¯•ï¼ˆShampoo & SOAPï¼‰**
- åœ¨ Qwen3-14B ä¸Šæµ‹è¯•ï¼š
  - **Shampoo æ­¥éª¤å»¶è¿Ÿä» 3.313s é™è‡³ 0.110s**ï¼ˆ>30Ã— åŠ é€Ÿï¼‰
  - **SOAP åŒæ ·è·å¾—æ˜¾è‘—åŠ é€Ÿ**
  - è®­ç»ƒæŸå¤±æ›²çº¿ä¸åŒæ­¥åŸºçº¿å®Œå…¨é‡åˆï¼ŒéªŒè¯ **é›¶ç²¾åº¦æŸå¤±**

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **Canzona æˆåŠŸè§£å†³äº† Matrix-based Optimizers ä¸åˆ†å¸ƒå¼è®­ç»ƒä¹‹é—´çš„æ ¹æœ¬å†²çª**ï¼Œåœ¨ä¸ç‰ºç‰²æ•°å­¦æ­£ç¡®æ€§çš„å‰æä¸‹ï¼Œå®ç°äº†é«˜æ€§èƒ½ã€é«˜æ‰©å±•æ€§çš„åˆ†å¸ƒå¼è®­ç»ƒã€‚
2. **è´Ÿè½½ä¸å‡è¡¡æ˜¯ Matrix-based Optimizers æ‰©å±•çš„ä¸»è¦ç“¶é¢ˆ**ï¼Œè€Œéå•çº¯çš„é€šä¿¡å¼€é”€ã€‚ä¼ ç»Ÿçš„â€œå¹³å‡åˆ‡åˆ†â€ç­–ç•¥åœ¨éçº¿æ€§æˆæœ¬ä¸‹å¤±æ•ˆï¼Œå¿…é¡»å¼•å…¥åŸºäºæˆæœ¬æ„ŸçŸ¥çš„è°ƒåº¦ã€‚
3. **é™æ€åˆ†åŒº + å¼‚æ­¥æµæ°´çº¿** æ˜¯å®ç°é«˜æ•ˆã€ä½å»¶è¿Ÿä¼˜åŒ–å™¨æ›´æ–°çš„å…³é”®è·¯å¾„ï¼Œå°¤å…¶é€‚ç”¨äº TP å†…éƒ¨çš„é«˜å¸¦å®½åœºæ™¯ã€‚
4. **numel(p)** ä½œä¸ºç»Ÿä¸€çš„æˆæœ¬åº¦é‡åœ¨å®è·µä¸­è¶³å¤Ÿå‡†ç¡®ï¼Œæ— éœ€ä¸ºæ¯ä¸ªä¼˜åŒ–å™¨å®šåˆ¶å¤æ‚çš„ FLOPs æ¨¡å‹ï¼ˆè¯¯å·® < 10â»â´sï¼‰ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
1. **ç¦»çº¿è§„åˆ’ä¾èµ–**ï¼šå½“å‰çš„è´Ÿè½½å‡è¡¡ç®—æ³•åœ¨åˆå§‹åŒ–é˜¶æ®µè¿è¡Œï¼Œè‹¥æ¨¡å‹ç»“æ„åŠ¨æ€å˜åŒ–ï¼ˆå¦‚ MoEï¼‰ï¼Œå¯èƒ½éœ€è¦é‡æ–°è§„åˆ’ã€‚
2. **TP å†…é€šä¿¡å‡è®¾**ï¼šä¾èµ–äº TP ç»„å†…é«˜å¸¦å®½è¿æ¥ï¼ˆå¦‚ NVLinkï¼‰ï¼Œè‹¥éƒ¨ç½²åœ¨ä½å¸¦å®½ç½‘ç»œä¸Šæ•ˆæœå¯èƒ½ä¸‹é™ã€‚
3. **æœªå¤„ç† ZeRO-2/3**ï¼šç›®å‰ä¸»è¦é’ˆå¯¹ ZeRO-1 è®¾è®¡ï¼Œæ‰©å±•è‡³æ›´é«˜çº§åˆ«çš„ ZeRO éœ€é¢å¤–è€ƒè™‘æ¢¯åº¦åˆ†ç‰‡ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **åŠ¨æ€è´Ÿè½½å‡è¡¡**ï¼šæ”¯æŒè¿è¡Œæ—¶è°ƒæ•´åˆ†åŒºç­–ç•¥ï¼Œé€‚åº”åŠ¨æ€ç¨€ç–æˆ– MoE æ¶æ„ã€‚
2. **FSDP é›†æˆ**ï¼šå°† TP-LB-ASC æ€è·¯æ¨å¹¿è‡³ PyTorch FSDP æ¡†æ¶ï¼Œæ”¯æŒæ›´å¹¿æ³›çš„è®­ç»ƒæ ˆã€‚
3. **å¤šç»´å¹¶è¡Œè”åˆä¼˜åŒ–**ï¼šæ¢ç´¢ DP + TP + PP çš„è”åˆè°ƒåº¦ï¼Œè¿›ä¸€æ­¥æå‡è¶…å¤§è§„æ¨¡è®­ç»ƒæ•ˆç‡ã€‚
4. **æ”¯æŒæ›´å¤šä¼˜åŒ–å™¨**ï¼šéªŒè¯ Canzona å¯¹ Condaã€ROOTã€Sophia ç­‰æ–°å…´ Matrix-based Optimizers çš„å…¼å®¹æ€§ã€‚

---

> **æ€»ç»“**ï¼š  
> **Canzona** å¹¶éç®€å•çš„å·¥ç¨‹ä¼˜åŒ–ï¼Œè€Œæ˜¯æå‡ºäº†ä¸€å¥— **ç³»ç»Ÿçº§ã€é€šç”¨åŒ–ã€æ— æŸç²¾ç¡®æ€§** çš„è§£å†³æ–¹æ¡ˆï¼Œé¦–æ¬¡åœ¨ä¸ä¿®æ”¹ä¼˜åŒ–å™¨æ•°å­¦å®šä¹‰çš„å‰æä¸‹ï¼Œå®ç°äº† Matrix-based Optimizers åœ¨åƒå¡çº§åˆ«é›†ç¾¤ä¸Šçš„é«˜æ•ˆåˆ†å¸ƒå¼è®­ç»ƒï¼Œä¸ºä¸‹ä¸€ä»£ LLM è®­ç»ƒåŸºç¡€è®¾æ–½æä¾›äº†é‡è¦å‚è€ƒã€‚

</details>

---

### 11. [Jackpot: Optimal Budgeted Rejection Sampling for Extreme Actor-Policy Mismatch Reinforcement Learning](https://arxiv.org/abs/2602.06107)

**Authors**: Zhuoming Chen, Hongyi Liu, Yang Zhou, Haizhong Zheng, Beidi Chen  
**Category**: cs.AI  
**Published**: 2026-02-09  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2602.06107v1  

#### Abstract
Reinforcement learning (RL) for large language models (LLMs) remains expensive, particularly because the rollout is expensive. Decoupling rollout generation from policy optimization (e.g., leveraging a more efficient model to rollout) could enable substantial efficiency gains, yet doing so introduce...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šJackpot: Optimal Budgeted Rejection Sampling for Extreme Actor-Policy Mismatch Reinforcement Learning**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒä¸­ï¼Œ**rollout é˜¶æ®µçš„æˆæœ¬æé«˜**ï¼Œé€šå¸¸å æ€»è®­ç»ƒæˆæœ¬çš„ 80% ä»¥ä¸Šã€‚ä¼ ç»Ÿæ–¹æ³•è¦æ±‚ç­–ç•¥æ¨¡å‹ï¼ˆpolicy modelï¼‰è‡ªèº«å‚ä¸ rollout ç”Ÿæˆè½¨è¿¹ï¼Œè¿™é™åˆ¶äº†æ•ˆç‡å’Œçµæ´»æ€§ã€‚

ä¸€ä¸ªç†æƒ³ä½†æå…·æŒ‘æˆ˜æ€§çš„è®¾æƒ³æ˜¯ï¼š**èƒ½å¦ä½¿ç”¨ä¸€ä¸ªå®Œå…¨ä¸åŒçš„ã€æ›´å°æ›´é«˜æ•ˆçš„æ¨¡å‹ï¼ˆå¦‚ Qwen3-1.7Bï¼‰æ¥ç”Ÿæˆ rolloutï¼Œè€Œç”¨å¦ä¸€ä¸ªæ›´å¤§çš„ç›®æ ‡æ¨¡å‹ï¼ˆå¦‚ Qwen3-8Bï¼‰è¿›è¡Œç­–ç•¥ä¼˜åŒ–ï¼Ÿ**

ç„¶è€Œï¼Œè¿™ç§â€œè§£è€¦â€è®­ç»ƒä¼šå¼•å…¥ä¸¥é‡çš„ **actor-policy distribution mismatch**ï¼ˆå³ rollout æ¨¡å‹ä¸è®­ç»ƒç­–ç•¥æ¨¡å‹ä¹‹é—´çš„åˆ†å¸ƒå·®å¼‚ï¼‰ï¼Œå¯¼è‡´ä¼˜åŠ¿ä¼°è®¡ä¸å‡†ç¡®ï¼Œè¿›è€Œå¼•å‘è®­ç»ƒä¸ç¨³å®šç”šè‡³å´©æºƒã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ï¼šJACKPOT**
ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½œè€…æå‡ºäº† **JACKPOT** æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ˜¯ **Optimal Budgeted Rejection Sampling (OBRS)**ï¼Œå¹¶ç»“åˆä»¥ä¸‹ä¸‰å¤§åˆ›æ–°ç»„ä»¶ï¼š

#### âœ… **(1) OBRSï¼ˆæœ€ä¼˜é¢„ç®—æ‹’ç»é‡‡æ ·ï¼‰**
- ä¸åŒäºä¼ ç»Ÿçš„æ‹’ç»é‡‡æ ·ï¼ˆRejection Samplingï¼‰ï¼ŒOBRS å¼•å…¥äº†ä¸€ä¸ªå¯æ§çš„â€œæ‹’ç»é¢„ç®—â€å‚æ•° `Î»`ï¼Œå…è®¸åœ¨**å¯æ¥å—çš„æ ·æœ¬æ•ˆç‡æŸå¤±ä¸‹ï¼Œæœ€å¤§åŒ–åœ°ç¼©å° rollout åˆ†å¸ƒä¸ç›®æ ‡ç­–ç•¥åˆ†å¸ƒä¹‹é—´çš„å·®è·**ã€‚
- å®ƒ**ä¸è¿½æ±‚å®Œç¾å¯¹é½**ï¼Œè€Œæ˜¯ä¿è¯å¯¹äºä»»æ„é¢„ç®—ï¼Œè°ƒæ•´åçš„åˆ†å¸ƒéƒ½æ¯”åŸå§‹ rollout åˆ†å¸ƒæ›´æ¥è¿‘ç›®æ ‡ç­–ç•¥ã€‚
- æ¥å—æ¦‚ç‡å®šä¹‰ä¸ºï¼š  
  $$
  a(x) = \min\left(1, \frac{p_{\text{target}}(x)}{\lambda \cdot p_{\text{inf}}(x)}\right)
  $$
  è¢«æ‹’ç»çš„ token å°†è¢« mask æ‰ï¼Œä¸å‚ä¸æ¢¯åº¦æ›´æ–°ã€‚

#### âœ… **(2) ç»Ÿä¸€è®­ç»ƒç›®æ ‡ï¼ˆUnified Training Objectiveï¼‰**
JACKPOT åŒæ—¶ä¼˜åŒ–ä¸‰ä¸ªç›®æ ‡ï¼š
- **OBRS è°ƒæ•´çš„ RL æŸå¤±**ï¼šç”¨äºæ›´æ–° policy modelï¼ŒåŸºäºè¢«æ¥å—çš„ token è¿›è¡Œ reweightingã€‚
- **Rollout model çš„æ ‡å‡† PPO æŸå¤±**ï¼šä¿æŒ rollout model è‡ªèº«ä¹Ÿåœ¨è¿›åŒ–ã€‚
- **On-policy Distillation æŸå¤±**ï¼šé€šè¿‡ KL æ•£åº¦å°† rollout model å‘æœ€æ–°çš„ policy model å¯¹é½ï¼Œé˜²æ­¢ä¸¤è€…å·®è·æŒç»­æ‰©å¤§ã€‚

#### âœ… **(3) é«˜æ•ˆç³»ç»Ÿå®ç°**
ä¸ºåº”å¯¹ OBRS ä¸­å½’ä¸€åŒ–å¸¸æ•° $Z$ éœ€è¦éå†æ•´ä¸ªè¯æ±‡è¡¨ï¼ˆ>100kï¼‰å¸¦æ¥çš„å†…å­˜ç“¶é¢ˆï¼Œæå‡ºï¼š
- **Top-k æ¦‚ç‡ä¼°è®¡**ï¼šä»…è®¡ç®— rollout å’Œ policy æ¨¡å‹ top-k é«˜æ¦‚ç‡ token çš„äº¤é›†éƒ¨åˆ†ã€‚
- **Batch-level Bias Correction**ï¼šåˆ©ç”¨å®é™…è§‚æµ‹åˆ°çš„æ¥å—ç‡å¯¹ top-k ä¼°è®¡å€¼è¿›è¡Œæ ¡å‡†ï¼Œæ¶ˆé™¤ç³»ç»Ÿæ€§ä½ä¼°åå·®ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹æ³• | å±€é™æ€§ | JACKPOT æ”¹è¿› |
|------|--------|-------------|
| **Truncated Importance Sampling (TIS)** | ä»…äº‹åä¿®æ­£ï¼Œæ— æ³•ä»æºå¤´å‡å°‘åˆ†å¸ƒå·®å¼‚ï¼›åœ¨æç«¯ mismatch ä¸‹ä»ä¸ç¨³å®š | ä»æºå¤´é€šè¿‡æ‹’ç»é‡‡æ ·ä¸»åŠ¨å¯¹é½åˆ†å¸ƒï¼Œä¸ TIS æ­£äº¤ä¸”å¯å åŠ ä½¿ç”¨ |
| **å¼‚æ­¥è®­ç»ƒ / é‡åŒ– rollout** | åˆ†å¸ƒå·®å¼‚è¾ƒå°ï¼Œå¯é€šè¿‡ TIS æœ‰æ•ˆç¼“è§£ | æ”¯æŒ**å®Œå…¨ä¸åŒæ¨¡å‹é—´çš„ rollout**ï¼ˆå¦‚ 1.7B â†’ 8Bï¼‰ï¼Œå¤„ç†æ›´å¤§ mismatch |
| **Speculative Decoding** | éœ€è¦é‡æ–°ç”Ÿæˆè¢«æ‹’ç» token åç»­åºåˆ—ï¼Œå¼€é”€å¤§ | **æ— éœ€ resampling**ï¼Œä»… mask å•ä¸ª tokenï¼Œæ•ˆç‡æ›´é«˜ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **æ•°æ®é›†**
- **MATH-500**ï¼š500 é“é«˜ä¸­æ•°å­¦ç«èµ›é¢˜ã€‚
- **DeepScaleR / DeepScaleR-Preview**ï¼šåŒ…å«çº¦ 40k é“é«˜éš¾åº¦æ•°å­¦ç«èµ›é¢˜ï¼ˆå¦‚ AIMEã€AMCï¼‰çš„æ•°æ®é›†ï¼Œç”¨äºè®­ç»ƒå’Œè¯„ä¼°ã€‚
- **GSM8K**ï¼šå°å­¦æ•°å­¦åº”ç”¨é¢˜åŸºå‡†ã€‚

### **å®éªŒè®¾ç½®**
- **æ¨¡å‹ç»„åˆ**ï¼ˆæç«¯ actor-policy mismatch åœºæ™¯ï¼‰ï¼š
  - Qwen2.5-1.5B (actor) â†’ Qwen2.5-3B (policy)
  - Qwen3-1.7B (actor) â†’ Qwen3-4B / Qwen3-8B (policy)
- **è®­ç»ƒé…ç½®**ï¼š
  - Batch size: 64ï¼ˆè®­ç»ƒï¼‰vs. æœ€é«˜è¾¾ 4096ï¼ˆrolloutï¼Œå³ 64Ã— æˆ– 128Ã— stalenessï¼‰
  - Max generation length: 8192 tokens
  - ä½¿ç”¨ GRPO ç®—æ³•è¿›è¡Œ RL è®­ç»ƒ
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - `Mean@k`, `Pass@k`ï¼šk æ¬¡ç‹¬ç«‹é‡‡æ ·ä¸­çš„å¹³å‡å¾—åˆ†æˆ–æœ€é«˜å¾—åˆ†
  - KL Divergence between $p_{\text{inf}}$ å’Œ $p_{\text{ref}}/p_{\text{new}}$
  - è®­ç»ƒç¨³å®šæ€§ï¼ˆæ˜¯å¦å´©æºƒï¼‰ã€æ”¶æ•›é€Ÿåº¦

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| åŸºçº¿ | æè¿° |
|------|------|
| **On-policy** | ç†æƒ³æƒ…å†µï¼Œrollout ä¸ policy æ¨¡å‹ä¸€è‡´ |
| **Off-policy (No Alignment)** | ç›´æ¥ä½¿ç”¨å°æ¨¡å‹ rolloutï¼Œæ— ä»»ä½•å¯¹é½æœºåˆ¶ |
| **TIS (+ Reverse KL)** | æˆªæ–­é‡è¦æ€§é‡‡æ · + åå‘ KL å¯¹é½ rollout model |
| **Only Reverse KL** | ä»…ç”¨ distillation æ›´æ–° rollout model |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰**

| æ–¹æ³• | Qwen3-1.7B â†’ Qwen3-8B (AIME25 Mean@4) | Qwen3-1.7B â†’ Qwen3-4B (AIME25 Mean@4) |
|------|-------------------------------------|-------------------------------------|
| Q3-8B On-policy | 0.1687 | â€” |
| TIS + Reverse KL | 0.1541 | 0.2083 |
| **JACKPOT (Ours)** | **0.1916** | **0.2083** |

> âœ… **JACKPOT åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¾¾åˆ°ç”šè‡³é€¼è¿‘ on-policy æ€§èƒ½**ï¼Œæ˜¾è‘—ä¼˜äºæ‰€æœ‰ off-policy åŸºçº¿ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- **è®­ç»ƒç¨³å®šæ€§**ï¼š
  - æ— å¯¹é½æ–¹æ³•å’Œ TIS åŸºçº¿åœ¨ 100â€“200 æ­¥å†…è¿…é€Ÿå´©æºƒï¼ˆKL divergence æš´æ¶¨ï¼‰ã€‚
  - **JACKPOT æ˜¾è‘—æŠ‘åˆ¶ KL divergence ä¸Šå‡**ï¼Œç»´æŒç¨³å®šè®­ç»ƒé•¿è¾¾ **300 æ­¥ä»¥ä¸Š**ï¼ˆè§ Figure 2cï¼‰ã€‚
- **æ€§èƒ½è¡¨ç°**ï¼š
  - åœ¨ Qwen3-1.7B â†’ Qwen3-8B æç«¯è®¾ç½®ä¸‹ï¼ŒJACKPOT è¾¾åˆ° **0.9357 GSM8K Mean@4**ï¼Œæ¥è¿‘ Q3-8B on-policy çš„ 0.9329ã€‚
  - åœ¨ Qwen3-1.7B â†’ Qwen3-4B è®¾ç½®ä¸‹ï¼ŒJACKPOT è¡¨ç° **åª²ç¾ Q3-4B è‡ªèº« on-policy è®­ç»ƒç»“æœ**ã€‚

### **æ¶ˆèå®éªŒç»“æœ**
#### ğŸ”¹ **ç§»é™¤ KL Distillation**
- è‹¥ä»…ä½¿ç”¨ OBRS è€Œä¸æ›´æ–° rollout modelï¼Œåˆ™é•¿æœŸè®­ç»ƒä»ä¼šå›  gap æ‰©å¤§è€Œå¤±è´¥ã€‚
- ç»“åˆ distillation å¯å®ç°é—­ç¯æ§åˆ¶ï¼Œæå‡é²æ£’æ€§ã€‚

#### ğŸ”¹ **ä¸åŒ rejection threshold Î»**
- å®éªŒè¡¨æ˜ `Î» = 1.0` æ˜¯ç¨³å¥é»˜è®¤å€¼ï¼š
  - å¤ªå° â†’ æ¥å—ç‡ä½ï¼Œæ ·æœ¬æ•ˆç‡å·®ï¼›
  - å¤ªå¤§ â†’ å¯¹é½æ•ˆæœå¼±ã€‚
- `Î»=1.0` åœ¨åŒ¹é…åˆ†å¸ƒæ—¶ä¿è¯å…¨æ¥å—ï¼ŒåŒæ—¶å·²èƒ½å¤§å¹…é™ä½ KLã€‚

#### ğŸ”¹ **Top-k è¿‘ä¼¼çš„å½±å“ï¼ˆk=10, 20, 40ï¼‰**
- k=20 å·²èƒ½æ•è· >99.98% çš„çœŸå®å½’ä¸€åŒ–è´¨é‡ï¼ˆZï¼‰ã€‚
- æ›´å¤§ k å¸¦æ¥çš„æ€§èƒ½å¢ç›Šå¯å¿½ç•¥ï¼Œä½†æ˜¾å­˜å¼€é”€çº¿æ€§å¢é•¿ã€‚
- **æ¨è k=20 ä½œä¸ºæ€§ä»·æ¯”æœ€ä¼˜é€‰æ‹©**ã€‚

#### ğŸ”¹ **åœ¨å·²æœ‰å° mismatch åœºæ™¯ä¸‹çš„è¡¨ç°**
- å½“ä½¿ç”¨ FP8 KV é‡åŒ–ç­‰è½»åº¦ mismatch åœºæ™¯æ—¶ï¼ŒTIS å·²è¶³å¤Ÿæœ‰æ•ˆï¼ŒJACKPOT æå‡æœ‰é™ï¼ˆè§ Table 2ï¼‰ã€‚
- è¡¨æ˜ JACKPOT çš„ä»·å€¼åœ¨äº**å¤„ç†æç«¯ mismatch**ï¼Œè€Œéæ›¿ä»£æ‰€æœ‰ç°æœ‰æ–¹æ³•ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **OBRS æ˜¯ä¸€ç§ç†è®ºä¸Šæœ€ä¼˜çš„åˆ†å¸ƒå¯¹é½æœºåˆ¶**ï¼šåœ¨ç»™å®šæ¥å—é¢„ç®—ä¸‹ï¼Œå®ƒèƒ½äº§ç”Ÿæœ€æ¥è¿‘ç›®æ ‡åˆ†å¸ƒçš„ post-rejection åˆ†å¸ƒã€‚
2. **JACKPOT å®ç°äº†é«˜æ•ˆä¸”ç¨³å®šçš„æç«¯è§£è€¦è®­ç»ƒ**ï¼šé¦–æ¬¡è¯æ˜å¯ä»¥ä½¿ç”¨è¿œå°äºç›®æ ‡æ¨¡å‹çš„ actorï¼ˆå¦‚ 1.7B â†’ 8Bï¼‰è¿›è¡Œ rolloutï¼Œå¹¶è·å¾—æ¥è¿‘ on-policy çš„æ€§èƒ½ã€‚
3. **ç³»ç»Ÿçº§ä¼˜åŒ–è‡³å…³é‡è¦**ï¼šTop-k + batch-level bias correction ä½¿å¾— OBRS å¯åœ¨å¤§è§„æ¨¡ LLM è®­ç»ƒä¸­å®ç”¨åŒ–ï¼Œé¿å…äº†å…¨è¯è¡¨è®¡ç®—çš„å†…å­˜ç¾éš¾ã€‚
4. **JACKPOT ä¸ TIS æ­£äº¤äº’è¡¥**ï¼šå¯åœ¨ OBRS å¯¹é½åè¿›ä¸€æ­¥åº”ç”¨ TIS è¿›è¡Œæ®‹ä½™è¯¯å·®ä¿®æ­£ï¼Œå½¢æˆåŒé‡ä¿éšœã€‚

### **å±€é™æ€§**
1. **å¹¶éä¸‡èƒ½è§£è€¦æ–¹æ¡ˆ**ï¼šåœ¨è¶…é•¿è®­ç»ƒï¼ˆ>300 æ­¥ï¼‰åä»å¯èƒ½å‡ºç°å‘æ•£ï¼ˆè§ Figure 6ï¼‰ï¼Œå°šæœªå®Œå…¨è§£å†³åŠ¨æ€æ¼”åŒ–ä¸­çš„ç´¯ç§¯è¯¯å·®ã€‚
2. **æœªéªŒè¯äºè¶…å¤§è§„æ¨¡æ¨¡å‹**ï¼šå½“å‰å®éªŒé›†ä¸­åœ¨ 8B åŠä»¥ä¸‹æ¨¡å‹ï¼Œå°šä¸æ¸…æ¥šåœ¨ 32B+ æ¨¡å‹ä¸Šçš„æ‰©å±•æ€§ã€‚
3. **ä¾èµ– rollout model æœ‰ä¸€å®šèƒ½åŠ›**ï¼šè‹¥ actor æ¨¡å‹å¤ªå¼±ï¼ˆå¦‚ <1Bï¼‰ï¼Œå¯èƒ½æ— æ³•ç”Ÿæˆæœ‰æ„ä¹‰çš„è®­ç»ƒä¿¡å·ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- **è‡ªé€‚åº” rejection budget æ§åˆ¶**ï¼šæ ¹æ®å®æ—¶ KL divergence åŠ¨æ€è°ƒæ•´ `Î»`ã€‚
- **é—­ç¯åé¦ˆæœºåˆ¶**ï¼šåŸºäºè®­ç»ƒç¨³å®šæ€§è‡ªåŠ¨è°ƒèŠ‚ distillation loss ä¸ RL loss çš„æƒé‡ã€‚
- **æ‰©å±•è‡³å¤šæ™ºèƒ½ä½“æˆ–æ··åˆä¸“å®¶æ¶æ„**ï¼ˆMoEï¼‰ä¸­çš„ rollout åˆ†é…ã€‚
- **æ¢ç´¢æ›´é«˜æ•ˆçš„è¿‘ä¼¼ç®—æ³•**ï¼šå¦‚åŸºäºå“ˆå¸Œæˆ–ç¨€ç–åŒ–çš„å¿«é€Ÿ top-k è”åˆæ£€ç´¢ã€‚

---

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> **JACKPOT é€šè¿‡ç†è®ºæœ€ä¼˜çš„ OBRS æ–¹æ³•ï¼Œé¦–æ¬¡å®ç°äº†åœ¨æç«¯ actor-policy mismatch ä¸‹ç¨³å®šé«˜æ•ˆçš„è§£è€¦ RL è®­ç»ƒï¼Œä¸ºé™ä½ LLM å¼ºåŒ–å­¦ä¹ æˆæœ¬æä¾›äº†åˆ‡å®å¯è¡Œçš„æ–°è·¯å¾„ã€‚**

</details>

---

### 12. [Evaluating an evidence-guided reinforcement learning framework in aligning light-parameter large language models with decision-making cognition in psychiatric clinical reasoning](https://arxiv.org/abs/2602.06449)

**Authors**: Xinxin Lin, Guangxin Dai, Yi Zhong, Xiang Li, Xue Xiao, Yixin Zhang, Zhengdong Wu, Yongbo Zheng, Runchuan Zhu, Ming Zhao, Huizi Yu, Shuo Wu, Jun Zhao, Lingming Hu, Yumei Wang, Ping Yin, Joey W. Y. Chan, Ngan Yin Chan, Sijing Chen, Yun Kwok Wing, Lin Lu, Xin Ma, Lizhou Fan  
**Category**: cs.CL  
**Published**: 2026-02-09  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.06449v1  

#### Abstract
Large language models (LLMs) hold transformative potential for medical decision support yet their application in psychiatry remains constrained by hallucinations and superficial reasoning. This limitation is particularly acute in light-parameter LLMs which are essential for privacy-preserving and ef...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

**è®ºæ–‡æ ‡é¢˜**: *Evaluating an evidence-guided reinforcement learning framework in aligning light-parameter large language models with decision-making cognition in psychiatric clinical reasoning*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç²¾ç¥ç§‘ä¸´åºŠå†³ç­–æ”¯æŒä¸­å…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œä½†å…¶åº”ç”¨å—åˆ°ä»¥ä¸‹å…³é”®é™åˆ¶ï¼š
- **å¹»è§‰ï¼ˆHallucinationsï¼‰** å’Œ **è¡¨é¢åŒ–æ¨ç†ï¼ˆsuperficial reasoningï¼‰** å¯¼è‡´å¯é æ€§ä¸è¶³ã€‚
- ç°æœ‰è®­ç»ƒèŒƒå¼ï¼ˆå¦‚ SFTï¼‰ä¾§é‡äºè¯­è¨€æµç•…æ€§è€Œéç»“æ„åŒ–ä¸´åºŠé€»è¾‘ï¼Œå¯¼è‡´æ¨¡å‹ä¸ä¸“ä¸šè¯Šæ–­è®¤çŸ¥ä¸¥é‡è„±èŠ‚ã€‚
- è½»é‡çº§å‚æ•°æ¨¡å‹ï¼ˆlight-parameter LLMsï¼‰è™½é€‚åˆéšç§ä¿æŠ¤å’Œé«˜æ•ˆéƒ¨ç½²ï¼Œä½†åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ã€‚

è¯¥ç ”ç©¶ç‰¹åˆ«å…³æ³¨å¦‚ä½•æå‡**è½»å‚æ•°æ¨¡å‹**åœ¨é«˜é£é™©ã€éœ€æ·±åº¦æ¨ç†çš„ç²¾ç¥ç§‘åœºæ™¯ä¸­çš„å¯é æ€§å’Œå®‰å…¨æ€§ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æå‡º **ClinMPO**ï¼ˆClinical Multi-group Policy Optimizationï¼‰ï¼Œä¸€ç§åŸºäºè¯æ®å¼•å¯¼çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨å°† LLM çš„å†…éƒ¨æ¨ç†è¿‡ç¨‹ä¸ä¸“ä¸šç²¾ç¥ç—…å­¦å®è·µå¯¹é½ã€‚

æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š
- **ClinRMï¼ˆClinical Reward Modelï¼‰**ï¼šä¸€ä¸ªç‹¬ç«‹è®­ç»ƒçš„å¥–åŠ±æ¨¡å‹ï¼ŒåŸºäºä» **4,474 ç¯‡ç²¾ç¥ç—…å­¦æœŸåˆŠæ–‡ç« **æ„å»ºçš„ä¸“æœ‰ **Evidence Dataset**ï¼ˆ18,569 æ¡æ•°æ®ï¼‰ï¼Œä¸¥æ ¼éµå¾ª **Oxford Centre for Evidence-Based Medicine** çš„è¯æ®ç­‰çº§ä½“ç³»ã€‚
- **å¤šç»„ç­–ç•¥ä¼˜åŒ–ï¼ˆMulti-group Policy Optimizationï¼‰**ï¼šé‡‡ç”¨ç›¸å¯¹ä¼˜åŠ¿è®¡ç®—ï¼ˆrelative advantageï¼‰ï¼Œåœ¨ç”Ÿæˆçš„å›ç­”ç»„å†…æ¯”è¾ƒè´¨é‡ï¼Œé¿å…ç»å¯¹å¥–åŠ±åå·®ï¼Œé¼“åŠ±æ¨¡å‹å‘å±•å‡ºæ›´ç¨³å¥ã€ç±»ä¸“å®¶çš„æ¨ç†æ¨¡å¼ã€‚
- æ˜¾å¼å¥–åŠ±**å¾ªè¯é€»è¾‘**ï¼ˆevidence-based logicï¼‰ï¼Œæƒ©ç½š**ä¸è¿è´¯çš„æ€ç»´é“¾**ï¼ˆincoherent chains of thoughtï¼‰ï¼Œå¦‚ç—‡çŠ¶è¯¯åˆ¤ã€é”™è¯¯é‰´åˆ«è¯Šæ–­ç­‰ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ SFT, GRPOï¼‰ | ClinMPO |
|------|------------------------|--------|
| **ä¼˜åŒ–ç›®æ ‡** | è¯­è¨€æµç•…æ€§ã€äº‹å®å‡†ç¡®æ€§ | ä¸´åºŠé€»è¾‘ã€æ¨ç†è¿‡ç¨‹çš„æœ‰æ•ˆæ€§ |
| **å¥–åŠ±ä¿¡å·** | åŸºäºåå¥½æ’åºæˆ–ç®€å•æ­£ç¡®æ€§ | åŸºäºå¤šå±‚æ¬¡ä¸´åºŠæ ‡å‡†ï¼ˆç§‘å­¦æ€§ã€ç®€æ´æ€§ã€é€»è¾‘æ€§ï¼‰ |
| **æ¨ç†èƒ½åŠ›** | æ˜“äº§ç”Ÿâ€œæµ…å±‚çŒœæµ‹â€ï¼ˆshallow guessingï¼‰ | é¼“åŠ±æ„å»º**ä¸´åºŠæœ‰æ•ˆçš„æ¨ç†é“¾** |
| **é€‚ç”¨æ¨¡å‹** | å¤šé’ˆå¯¹å¤§æ¨¡å‹ | ç‰¹åˆ«é€‚ç”¨äº**è½»å‚æ•°æ¨¡å‹**ï¼ˆ0.6Bâ€“8Bï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨äº†å“ªäº›æ•°æ®é›†
- **Public QA Dataset**ï¼ˆ8,849 é“é¢˜ï¼‰ï¼š
  - æ¥æºäºå…¬å¼€åŒ»å­¦é—®ç­”èµ„æºï¼ˆCMB, MedMCQA, MedQA, MMLU-Pro ç­‰ï¼‰ã€‚
  - ç»è¿‡ GPT-5 è¿‡æ»¤ç¡®ä¿ç²¾ç¥ç—…å­¦ç›¸å…³æ€§ï¼Œå¹¶ç»Ÿä¸€ä¸ºé€‰æ‹©é¢˜æ ¼å¼ï¼ˆå« Chain-of-Thoughtï¼‰ã€‚
- **Evidence QA Dataset**ï¼ˆ18,569 å¯¹é—®ç­”ï¼‰ï¼š
  - ä» 4,474 ç¯‡é«˜è´¨é‡ç²¾ç¥ç—…å­¦æœŸåˆŠæ–‡ç« ä¸­æå–ã€‚
  - æŒ‰ç…§ **Oxford Centre for Evidence-Based Medicine** é‡‘å­—å¡”åˆ†å±‚é‡‡æ ·ã€‚
  - åŒ…å«é—®é¢˜ã€é€‰é¡¹ã€æ­£ç¡®ç­”æ¡ˆã€CoTã€è¯„åˆ†è¡¨åŠè¯„åˆ†ä¾æ®ï¼ˆCOT for scoringï¼‰ã€‚
  - å¼•å…¥å—æ§é”™è¯¯æ¨¡å¼ï¼ˆå¦‚é”™è¯¯ç—…å› å­¦ï¼‰ä»¥å¢å¼ºé²æ£’æ€§è®­ç»ƒã€‚

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **ä¸¤é˜¶æ®µè®­ç»ƒè®¾ç½®**ï¼š
  - **è®­ç»ƒé›†**ï¼ˆ7,112 é¢˜ï¼‰ï¼šè¢« â‰¥9 ä¸ªå…ˆè¿› LLM æ­£ç¡®å›ç­”çš„é—®é¢˜ï¼ˆâ€œeasyâ€ setï¼‰ã€‚
  - **æµ‹è¯•é›†**ï¼ˆ1,737 é¢˜ï¼‰ï¼šå¤§å¤šæ•°å¤§æ¨¡å‹å¤±è´¥çš„é—®é¢˜ï¼ˆâ€œhardâ€ setï¼‰ï¼Œç”¨äºæœ€å°åŒ–è®°å¿†æ•ˆåº”ï¼Œå¼ºè°ƒæ¨ç†èƒ½åŠ›ã€‚
- **è¯„ä¼°ç»´åº¦**ï¼š
  - **æ€»ä½“å‡†ç¡®ç‡ï¼ˆOverall Accuracyï¼‰**
  - **åŒå±‚çº§ä¸´åºŠåˆ†ç±»è¯„ä¼°**ï¼š
    - **Tier 1**: ICD-11 è¯Šæ–­åˆ†ç±»ï¼ˆ26 ç±»ï¼‰
    - **Tier 2**: ç²¾ç¥ç§‘å®è·µèƒ½åŠ›ï¼ˆ12 é¡¹ï¼Œå¦‚é‰´åˆ«è¯Šæ–­ã€å…±ç—…ç®¡ç†ç­‰ï¼‰
  - **äººç±»åŸºå‡†å¯¹æ¯”**ï¼š300 ååŒ»å­¦ç”Ÿå‚ä¸ç›¸åŒæµ‹è¯•ï¼Œæä¾›äººç±»è¡¨ç°åŸºçº¿ã€‚
  - **è¯¯å·®è¿‡æ¸¡åˆ†æ**ï¼ˆFalse-to-True vs True-to-Falseï¼‰
  - **åˆ†å¸ƒç¨³å®šæ€§åˆ†æ**ï¼ˆç®±çº¿å›¾å±•ç¤ºå„æ¨¡å‹åœ¨ä¸åŒç±»åˆ«ä¸‹çš„è¡¨ç°ç¦»æ•£åº¦ï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Base Model**ï¼šæœªç»å¾®è°ƒçš„åŸºç¡€æ¨¡å‹
- **SFT**ï¼ˆSupervised Fine-Tuningï¼‰ï¼šç›‘ç£å¾®è°ƒ
- **GRPO**ï¼ˆGeneral Reinforcement Learning with Policy Optimizationï¼‰ï¼šé€šç”¨å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–
- **ClinMPO**ï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•

æ‰€æœ‰æ–¹æ³•å‡åº”ç”¨äº Qwen3 ç³»åˆ—æ¨¡å‹ï¼ˆ0.6B, 1.7B, 4B, 8Bï¼‰è¿›è¡Œå…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- **Qwen3-8B-ClinMPO åœ¨â€œhardâ€æµ‹è¯•é›†ä¸Šçš„æ€»ä½“å‡†ç¡®ç‡ä¸º `31.43%`**
- **äººç±»åŒ»å­¦ç”ŸåŸºå‡†å‡†ç¡®ç‡ä¸º `30.84%`**
- ClinMPO æ˜¯å”¯ä¸€**è¶…è¶Šäººç±»å¹³å‡æ°´å¹³**çš„æ¨¡å‹ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| æ¨¡å‹ | å‡†ç¡®ç‡ (%) | ç›¸å¯¹æå‡ |
|------|-----------|---------|
| Qwen3-8B (Base) | 28.27 | â€” |
| Qwen3-8B-SFT | 30.40 | +2.13 |
| Qwen3-8B-GRPO | 30.80 | +2.53 |
| **Qwen3-8B-ClinMPO** | **31.43** | **+3.17** |

> âœ… ClinMPO åœ¨ 8B å°ºåº¦ä¸‹å®ç° **3.17 ä¸ªç™¾åˆ†ç‚¹çš„ç»å¯¹å¢ç›Š**ï¼Œä¸”ä¼˜äºæœ€å¼ºé-ClinMPO åŸºçº¿ï¼ˆGRPOï¼‰0.63 ä¸ªç™¾åˆ†ç‚¹ã€‚

#### åœ¨å…³é”®ä¸´åºŠé¢†åŸŸçš„é¢†å…ˆè¡¨ç°
| ç±»åˆ« | æœ€ä½³ ClinMPO è¡¨ç° | äººç±»åŸºå‡† | æå‡å€æ•° |
|------|------------------|----------|--------|
| Mental, behavioural or neurodevelopmental disorders | 50.00% | 27.27% | ~1.8Ã— |
| Impulse control disorders | 50.00% | 20.90% | >2Ã— |
| Factitious disorders | 57.14% | 25.74% | >2Ã— |
| Monitoring, Follow-up & Measurement-Based Care | 42.86% | 30.38% | ~1.4Ã— |
| Comorbidity & Complexity Management | 44.74% | 27.24% | ~1.6Ã— |

> ğŸ“ˆ ClinMPO åœ¨éœ€è¦**ç»¼åˆåˆ¤æ–­ã€å¤šæ­¥å› æœæ¨ç†**çš„å¤æ‚é¢†åŸŸæ˜¾è‘—é¢†å…ˆã€‚

### æ¶ˆèå®éªŒç»“æœ
- **å¹³å‡ç»å¯¹æå‡**ï¼ˆè·¨æ‰€æœ‰å°ºåº¦ï¼‰ï¼š
  - ClinMPO: **+2.72 pp**
  - GRPO: +1.80 pp
  - SFT: +1.64 pp
- **å‡€æ¨ç†æ”¹è¿›**ï¼ˆFalse-to-True âˆ’ True-to-Falseï¼‰ï¼š
  - Qwen3-4B-ClinMPO: **+98**
  - Qwen3-8B-ClinMPO: **+55**
  - åŒè§„æ¨¡ GRPO/SFT æ”¹è¿›æ›´å°ç”šè‡³ä¸ºè´Ÿ
- **é”™è¯¯ä¿®æ­£ç‡**ï¼ˆåœ¨ 4B æ¨¡å‹ä¸Šï¼‰ï¼š
  - ClinMPO: **22.6%** çš„åŸé”™è¯¯é¢„æµ‹è¢«çº æ­£
  - GRPO: 21.4%
  - SFT: 13.9%

> ğŸ” ç»“æœè¯å® ClinMPO èƒ½**ä¸»åŠ¨ä¿®å¤é”™è¯¯æ¨ç†é“¾**ï¼Œè€Œéä¾èµ–éšæœºçŒœæµ‹ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### è®ºæ–‡çš„ä¸»è¦å‘ç°
1. **è½»å‚æ•° LLM å¯é€šè¿‡è®¤çŸ¥å¯¹é½è¾¾åˆ°ç”šè‡³è¶…è¶Šäººç±»åŒ»å­¦ç”Ÿæ°´å¹³**ï¼šClinMPO-tuned Qwen3-8B åœ¨å¤æ‚ç²¾ç¥ç§‘æ¨ç†ä»»åŠ¡ä¸Šé¦–æ¬¡å®ç°å¯¹äººç±»åŸºå‡†çš„è¶…è¶Šã€‚
2. **æ¨ç†è´¨é‡ä¼˜äºè¯­è¨€æµç•…æ€§**ï¼šClinMPO é€šè¿‡å¼•å…¥åŸºäºä¸´åºŠè¯æ®çš„å¥–åŠ±æœºåˆ¶ï¼ŒæˆåŠŸå°†ä¼˜åŒ–ç›®æ ‡ä»â€œè¯´å¾—å¥½å¬â€è½¬å‘â€œæƒ³å¾—æ­£ç¡®â€ã€‚
3. **æ–¹æ³•å…·å¤‡è‰¯å¥½å¯æ‰©å±•æ€§**ï¼šåœ¨ 0.6B åˆ° 8B ä¸åŒè§„æ¨¡æ¨¡å‹ä¸Šå‡å¸¦æ¥ç¨³å®šå¢ç›Šï¼Œå°¤å…¶åœ¨ä¸­ç­‰è§„æ¨¡ï¼ˆ4Bï¼‰æå‡æœ€å¤§ï¼ˆ+5.64 ppï¼‰ã€‚
4. **æ›´å¼ºçš„é²æ£’æ€§ä¸ä¸€è‡´æ€§**ï¼šClinMPO æ¨¡å‹åœ¨å„ç±»åˆ«é—´è¡¨ç°æ›´ç¨³å®šï¼Œæå°‘å‡ºç°æç«¯å¤±è´¥ï¼ˆlow-whisker æ›´çŸ­ï¼‰ï¼Œé€‚åˆé«˜é£é™©ä¸´åºŠç¯å¢ƒã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–åè®­ç»ƒï¼ˆpost-trainingï¼‰é˜¶æ®µ**ï¼šæœªå¹²é¢„é¢„è®­ç»ƒè¿‡ç¨‹ï¼Œæ¨¡å‹ä»å¯èƒ½å—éåŒ»å­¦æ•°æ®åˆ†å¸ƒå¹²æ‰°ã€‚
2. **è¯„ä¼°åŸºäºé™æ€æ•°æ®é›†**ï¼šç¼ºä¹çœŸå®åŠ¨æ€ä¸´åºŠæµç¨‹éªŒè¯ï¼Œå°šæœªè¦†ç›–å¤šæ ·åŒ–äººç¾¤å’Œç¤¾ä¼šæ–‡åŒ–èƒŒæ™¯ã€‚
3. **é•¿æœŸå…¬å¹³æ€§ä¸å¯¹æŠ—é²æ£’æ€§æœªçŸ¥**ï¼šæœªå……åˆ†æ¢è®¨æ¨¡å‹åœ¨åè§æ”¾å¤§æˆ–æ¶æ„æç¤ºä¸‹çš„è¡Œä¸ºã€‚
4. **æ•°æ®ä¸ä»£ç æš‚æœªå¼€æº**ï¼šâ€œData will be available soonâ€ / â€œCode will be available soonâ€ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. å°†è®¤çŸ¥å¯¹é½ç­–ç•¥å‰ç§»è‡³ **pre-training é˜¶æ®µ**ï¼Œå»ºç«‹ç«¯åˆ°ç«¯çš„ä¸´åºŠå¯¹é½ LLMã€‚
2. åœ¨çœŸå®ä¸´åºŠç¯å¢ƒä¸­å¼€å±•å‰ç»æ€§éªŒè¯ï¼Œçº³å…¥æ›´å¤šå…ƒåŒ–çš„æ‚£è€…ç¾¤ä½“ã€‚
3. ç»“åˆ **retrieval-augmented generation (RAG)** æå‡å®æ—¶çŸ¥è¯†æ›´æ–°èƒ½åŠ›ã€‚
4. å¼€å‘æ›´ä¸¥æ ¼çš„ **post-deployment monitoring** æœºåˆ¶ï¼Œç¡®ä¿é•¿æœŸå®‰å…¨ä¸å…¬å¹³ã€‚
5. æ¨åŠ¨å¼€æºå…±äº«ï¼Œä¿ƒè¿›ç¤¾åŒºå…±åŒæ„å»ºé¢å‘é«˜é£é™©åŒ»ç–—é¢†åŸŸçš„å¯ä¿¡ AIã€‚

> ğŸ’¡ **æ€»ç»“**ï¼šæœ¬ç ”ç©¶è¯æ˜ï¼Œé€šè¿‡**æ˜¾å¼çš„è®¤çŸ¥å¯¹é½**ï¼ˆexplicit cognitive alignmentï¼‰ï¼Œè½»é‡çº§ LLM å¯æŒæ¡å¤æ‚çš„ä¸´åºŠæ¨ç†èƒ½åŠ›ï¼Œä¸ºèµ„æºå—é™ç¯å¢ƒä¸‹éƒ¨ç½²å¯é ã€å®‰å…¨çš„ç²¾ç¥ç§‘ AI å†³ç­–æ”¯æŒç³»ç»Ÿæä¾›äº†å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 13. [To 2:4 Sparsity and Beyond: Neuron-level Activation Function to Accelerate LLM Pre-Training](https://arxiv.org/abs/2602.06183)

**Authors**: Meghana Madhyastha, Daniel Haziza, Jesse Cai, Newsha Ardalani, Zhiqi Bu, Carole-Jean Wu  
**Category**: cs.LG  
**Published**: 2026-02-09  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2602.06183v1  

#### Abstract
Trainings of Large Language Models are generally bottlenecked by matrix multiplications. In the Transformer architecture, a large portion of these operations happens in the Feed Forward Network (FFN), and this portion increases for larger models, up to 50% of the total pretraining floating point ope...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*To 2:4 Sparsity and Beyond: Neuron-level Activation Function to Accelerate LLM Pre-Training*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é¢„è®­ç»ƒè¿‡ç¨‹åœ¨è®¡ç®—ä¸Šæå…¶æ˜‚è´µï¼Œå…¶ä¸­å¤§éƒ¨åˆ†è®¡ç®—å¼€é”€æ¥è‡ªçŸ©é˜µä¹˜æ³•ï¼ˆGEMMï¼‰ï¼Œå°¤å…¶æ˜¯åœ¨ Transformer æ¶æ„ä¸­çš„ **Feed Forward Network (FFN)** æ¨¡å—ã€‚å°½ç®¡å·²æœ‰ç ”ç©¶åˆ©ç”¨ **2:4 sparsity** åŠ é€Ÿæƒé‡è®¡ç®—ï¼Œä½†å…¶ä»…èƒ½æ”¯æŒ 50% çš„ç¨€ç–åº¦ï¼Œè€Œ FFN ä¸­çš„æ¿€æ´»å€¼ï¼ˆactivationsï¼‰å¤©ç„¶å…·æœ‰è¶…è¿‡ 90% çš„ç¨€ç–æ€§ï¼ˆå¦‚ä½¿ç”¨ SquaredReLU æ¿€æ´»å‡½æ•°æ—¶ï¼‰ï¼Œè¿™äº›é«˜ç¨€ç–æ½œåŠ›æœªè¢«å……åˆ†æŒ–æ˜ã€‚

æ­¤å¤–ï¼Œå¦‚ä½•åœ¨ä¸æŸå®³æ¨¡å‹ç²¾åº¦çš„å‰æä¸‹ï¼Œç³»ç»Ÿæ€§åœ°ç»“åˆæƒé‡å’Œæ¿€æ´»ç¨€ç–æ€§ï¼Œä»ç¼ºä¹æœ‰æ•ˆæ–¹æ¡ˆã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹
æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§å…¨æ–°çš„è®­ç»ƒç­–ç•¥ï¼Œæ—¨åœ¨**å®Œå…¨ç¨€ç–åŒ– FFN æ¨¡å—ä¸­çš„æ‰€æœ‰çŸ©é˜µä¹˜æ³•æ“ä½œ**ï¼Œä»è€Œå®ç°ç«¯åˆ°ç«¯çš„è®­ç»ƒåŠ é€Ÿã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

1. **ç»Ÿä¸€åº”ç”¨ 2:4 æƒé‡ç¨€ç– + V:N:M (Venom) æ¿€æ´»ç¨€ç–**  
   - å¯¹ FFN ä¸­çš„æƒé‡ $W_1$ å’Œ $W_2$ åº”ç”¨ç¡¬ä»¶åŠ é€Ÿæ”¯æŒçš„ **2:4 sparsity**ï¼Œé€šè¿‡ **soft-thresholding** æŠ€æœ¯è¿›è¡ŒåŠ¨æ€å‰ªæï¼Œé¿å…æŸå¤±å‡½æ•°ä¸è¿ç»­ã€‚
   - å¯¹æ¿€æ´»å€¼ï¼ˆå¦‚ $y_2 = \text{ReLU}(y_1)$ï¼‰é‡‡ç”¨æ›´é«˜æ•ˆçš„ **V:N:M (Venom)** ç¨€ç–æ ¼å¼ï¼Œè¯¥æ ¼å¼å¯æ”¯æŒé«˜è¾¾ 90%+ çš„ç¨€ç–åº¦ï¼Œå¹¶å¸¦æ¥æ˜¾è‘—æ›´é«˜çš„ GEMM åŠ é€Ÿæ¯”ï¼ˆ6â€“10Ã—ï¼‰ã€‚

2. **è®¾è®¡â€œç¥ç»å…ƒçº§ä¸“å®¶è·¯ç”±â€æœºåˆ¶ä»¥å®ç° Venom æ ¼å¼**  
   - æå‡ºä¸€ç§ç±» MoE çš„ **neuron-level routing** æœºåˆ¶ï¼Œåœ¨å‰å‘ä¼ æ’­ä¸­ä¸ºæ¯ä¸ª token åŠ¨æ€é€‰æ‹©ä¿ç•™å“ªäº›ç‰¹å¾ç»´åº¦ã€‚
   - é€šè¿‡èšç±»æƒé‡åˆ—å½¢æˆâ€œä¸“å®¶â€ï¼Œå¹¶æ ¹æ®è¾“å…¥ token ä¸ä¸“å®¶ä¸­å¿ƒçš„è·ç¦»å†³å®šè·¯ç”±ç›®æ ‡ã€‚
   - åœ¨ batch å†…å¯¹ token è¿›è¡Œé‡æ’åºï¼Œä½¿ç›¸åŒ sparsity pattern çš„ token èšåˆåœ¨ä¸€èµ·ï¼Œä»è€Œæ„é€ å‡ºç¬¦åˆ Venom æ ¼å¼çš„å­çŸ©é˜µï¼Œå¯ç”¨ç¡¬ä»¶åŠ é€Ÿã€‚

3. **æå‡ºâ€œç¨€ç– + å¯†é›†â€æ··åˆè®­ç»ƒç­–ç•¥ä»¥æ¢å¤ç²¾åº¦**  
   - å‘ç°çº¯ç¨€ç–è®­ç»ƒä¼šå¯¼è‡´è½»å¾®çš„ loss ä¸Šå‡ï¼Œå› æ­¤å¼•å…¥ **sparse-dense hybrid training**ï¼šå‰æœŸä½¿ç”¨ç¨€ç–è®­ç»ƒåŠ é€Ÿï¼ŒåæœŸåˆ‡æ¢å›å¯†é›†è®­ç»ƒä»¥å¾®è°ƒå¹¶æ¢å¤ç²¾åº¦ã€‚
   - æ‰¾åˆ°äº†æœ€ä¼˜æ¯”ä¾‹ï¼ˆå¦‚ Llama-1B ä¸º 1:1ï¼ŒLlama-7B ä¸º 1:3.5ï¼‰ã€‚

### âš¡ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | æœ¬æ–‡æ–¹æ³• | ç°æœ‰æ–¹æ³• |
|------|---------|--------|
| **ç¨€ç–ç²’åº¦** | ç»†ç²’åº¦ï¼ˆfine-grainedï¼‰ç¨€ç–ï¼Œé€‚ç”¨äºé€šç”¨ FFN | å¤šä¸ºç²—ç²’åº¦ï¼ˆå¦‚ MoEï¼‰æˆ–ä»…ä½œç”¨äºéƒ¨åˆ†æ¨¡å— |
| **ç¨€ç–å¯¹è±¡** | åŒæ—¶ä¼˜åŒ– weight å’Œ activation | é€šå¸¸åªä¼˜åŒ–å…¶ä¸€ |
| **ç¡¬ä»¶é€‚é…æ€§** | å……åˆ†åˆ©ç”¨ NVIDIA A100/Hopper åŠä»¥ä¸Š GPU çš„ **sparse tensor cores** å’Œ **TMA æ”¯æŒ** |
| **ç«¯åˆ°ç«¯åŠ é€Ÿ** | å®ç° **1.4â€“1.7Ã— end-to-end speedup**ï¼Œä¸”æ— ç²¾åº¦æŸå¤± | å¤šæ•°å·¥ä½œèšç„¦æ¨ç†é˜¶æ®µæˆ–å±€éƒ¨åŠ é€Ÿ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **è®­ç»ƒæ•°æ®**ï¼šDCLM æ•°æ®é›†
- **è¯„ä¼°ä»»åŠ¡**ï¼šEval-Harness suite ä¸­å¤šä¸ªåŸºå‡†ä»»åŠ¡ï¼ŒåŒ…æ‹¬ï¼š
  - ARC-Easy / ARC-Challenge
  - PIQA
  - OBQA
  - Hellaswag
  - Winogrande

### ğŸ”§ å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼šåŸºäº Llama-3 æ¶æ„å˜ä½“
  - Llama-1B: 22 å±‚ï¼Œ$d_{\text{model}}=2048$, $d_{\text{ffn}}=8192$
  - Llama-7B: 32 å±‚ï¼Œ$d_{\text{model}}=4096$, $d_{\text{ffn}}=16384$
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA H200 GPUs
- **åºåˆ—é•¿åº¦**ï¼š8192
- **Batch Size**ï¼š2
- **Optimizer & LR Scheduler**ï¼šAdamW + cosine å­¦ä¹ ç‡è°ƒåº¦

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡
- **è®­ç»ƒæŒ‡æ ‡**ï¼š
  - æœ€å 100 æ­¥å¹³å‡ **Training Loss**
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - å„ä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰
  - å¹³å‡è¯„ä¼°å¾—åˆ†ï¼ˆAverage Eval Accuracyï¼‰
- **æ•ˆç‡æŒ‡æ ‡**ï¼š
  - ç«¯åˆ°ç«¯è®­ç»ƒé€Ÿåº¦æå‡ï¼ˆSpeedup Ã—ï¼‰
  - Microbenchmark æµ‹å¾—çš„ TFLOPS/s æå‡

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline**ï¼šæ ‡å‡† dense è®­ç»ƒï¼ˆæ— ä»»ä½• sparsityï¼‰
- **å¯¹æ¯”ç»„**ï¼š
  - å•ç‹¬ weight sparsificationï¼ˆW1/W2/bothï¼‰
  - å•ç‹¬ activation sparsificationï¼ˆ2:4 vs Venomï¼‰
  - ä¸åŒ sparse:dense ratio ç»„åˆ
  - ä¸åŒ sparsification é˜¶æ®µé¡ºåºï¼ˆå…ˆç¨€ç–åå¯†é›† vs æ··åˆäº¤æ›¿ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 2ï¼‰

| æ¨¡å‹ | æ–¹æ³• | Speedup | Training Loss | Average Accuracy |
|------|------|--------|--------------|------------------|
| Llama-1B | Baseline | 1.0Ã— | 2.758 | 0.527 |
| Llama-1B | æœ¬æ–‡æ–¹æ³•ï¼ˆ30k sparse + 30k denseï¼‰ | **1.352Ã—** | **2.755** | **0.527** |
| Llama-7B | Baseline | 1.0Ã— | 1.863 | 0.651 |
| Llama-7B | æœ¬æ–‡æ–¹æ³•ï¼ˆ10k sparse + 38k denseï¼‰ | **1.387Ã—** | **1.866** | **0.652** |

âœ… **ç»“è®º**ï¼šåœ¨ä¿æŒ **å®Œå…¨ç›¸åŒçš„è®­ç»ƒ loss å’Œè¯„ä¼°ç²¾åº¦** çš„å‰æä¸‹ï¼Œå®ç°äº† **çº¦ 1.35â€“1.39Ã— çš„ç«¯åˆ°ç«¯è®­ç»ƒåŠ é€Ÿ**ã€‚

> æ³¨ï¼šç†è®ºå•æ­¥åŠ é€Ÿå¯è¾¾ 2.2Ã—ï¼Œä½†ç”±äºéœ€æ’å…¥ dense æ­¥éª¤æ¢å¤ç²¾åº¦ï¼Œæœ€ç»ˆ end-to-end åŠ é€Ÿçº¦ä¸º 1.4Ã— å·¦å³ã€‚

### ğŸ” ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- æ‰€æœ‰ç¨€ç–é…ç½®å‡èƒ½åœ¨åˆç†è°ƒæ•´å **æ¢å¤è‡³ baseline ç²¾åº¦æ°´å¹³**ã€‚
- å•ç‹¬ä½¿ç”¨ 2:4 sparsity æˆ– Venom sparsity å‡ä¼šå¸¦æ¥ ~0.03 çš„ loss ä¸Šå‡ï¼Œä½†é€šè¿‡åç»­ dense å¾®è°ƒå¯å®Œå…¨å¼¥è¡¥ã€‚
- **Venom æ¿€æ´»ç¨€ç–å¸¦æ¥çš„åŠ é€Ÿè¿œé«˜äº 2:4 æƒé‡ç¨€ç–**ï¼ˆmicrobenchmark æ˜¾ç¤ºæœ€é«˜è¾¾ 7Ã—ï¼‰ï¼Œæ˜¯ä¸»è¦æ€§èƒ½å¢ç›Šæ¥æºã€‚

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### è¡¨ï¼šä¸åŒç¨€ç–ç»„åˆä¸‹çš„ Training Lossï¼ˆTable 3ï¼‰
| é…ç½® | Training Loss |
|------|---------------|
| Dense Baseline | 2.758 |
| W1 sparse | 2.784 (+0.026) |
| W2 sparse | 2.785 (+0.027) |
| W1 & W2 sparse | 2.844 (+0.086) |
| 2:4 activation sparsity | 2.755 (~same) |
| **Venom activation sparsity** | **2.789 (+0.031)** |

ğŸ“Œ **å‘ç°**ï¼š
- æƒé‡ç¨€ç–å¯¹ loss å½±å“è¾ƒå°ï¼Œä½†å åŠ åå‘ˆç´¯åŠ æ•ˆåº”ã€‚
- **Venom æ¿€æ´»ç¨€ç–è™½ç•¥é™ç²¾åº¦ï¼Œä½†æ¢æ¥é«˜è¾¾ 6â€“8Ã— çš„ GEMM åŠ é€Ÿï¼Œæ€§ä»·æ¯”æé«˜**ã€‚

#### ä¸åŒ sparse:dense ratio çš„å½±å“ï¼ˆTable 4 & Figure 5ï¼‰
- **æœ€ä½³ç­–ç•¥**ï¼šæ—©æœŸè¿›è¡Œç¨€ç–è®­ç»ƒï¼ŒåæœŸå¯†é›†å¾®è°ƒã€‚
- **Warm-up å¿…è¦æ€§**ï¼šå‰ 1000 æ­¥ä¿æŒ denseï¼Œå¾…è‡ªç„¶æ¿€æ´»ç¨€ç–æ¨¡å¼å½¢æˆåå†å¼€å¯ Venomã€‚
- **æ¯”ä¾‹æƒè¡¡**ï¼š
  - Llama-1Bï¼š30k sparse + 30k dense â†’ å®Œç¾æ¢å¤ç²¾åº¦
  - Llama-7Bï¼šæ›´å¤§æ¨¡å‹éœ€è¦æ›´å¤š dense æ­¥ï¼ˆ~3.5Ã—ï¼‰æ¥è¡¥å¿ç¨€ç–å¸¦æ¥çš„æ‰°åŠ¨

#### Microbenchmark ç»“æœï¼ˆFigure 6 & 7ï¼‰
- **2:4 sparse GEMM**ï¼šå®æµ‹åŠ é€Ÿ **1.4â€“1.5Ã—**ï¼ˆç†è®º 2Ã—ï¼‰ï¼Œè½¬æ¢ overhead å¯å¿½ç•¥ã€‚
- **Venom GEMM**ï¼šåœ¨ 87.5%â€“96.875% ç¨€ç–åº¦ä¸‹ï¼Œå®æµ‹åŠ é€Ÿ **6â€“8Ã—**ï¼Œæ˜¾è‘—ä¼˜äº 2:4ã€‚
- **å‚æ•°å½±å“**ï¼š$V, N, M$ æ§åˆ¶å­çŸ©é˜µåˆ’åˆ†å’Œä¿ç•™åˆ—æ•°ï¼Œç›´æ¥å½±å“ sparsity % å’ŒåŠ é€Ÿæ•ˆæœï¼ˆè§ Table 5ï¼‰ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **FFN æ˜¯ LLM é¢„è®­ç»ƒçš„ä¸»è¦ç®—åŠ›ç“¶é¢ˆ**ï¼Œå æ¯”å¯è¾¾æ€» FLOPs çš„ **50â€“80%**ï¼Œå°¤å…¶éšæ¨¡å‹è§„æ¨¡å¢å¤§è€Œä¸Šå‡ã€‚
2. **ç»“åˆ 2:4 weight sparsity ä¸ Venom activation sparsity** å¯å®ç° FFN ä¸­å…¨éƒ¨ 6 ä¸ª GEMM æ“ä½œçš„ç¡¬ä»¶åŠ é€Ÿã€‚
3. **Neuron-level routing + token reordering** æˆåŠŸå°†åŠ¨æ€æ¿€æ´»ç¨€ç–è½¬åŒ–ä¸ºç»“æ„åŒ– Venom æ ¼å¼ï¼Œæ˜¯å¯ç”¨é«˜å€åŠ é€Ÿçš„å…³é”®ã€‚
4. **Hybrid sparse-dense training** æ˜¯å¹³è¡¡æ•ˆç‡ä¸ç²¾åº¦çš„æœ‰æ•ˆèŒƒå¼ï¼šå‰æœŸé«˜é€Ÿæ¢ç´¢ï¼ŒåæœŸç²¾ç»†æ”¶æ•›ã€‚
5. è¯¥æ–¹æ³•åœ¨ **NVIDIA A100 åŠä»¥ä¸Š GPU** ä¸Šå‡å¯å¯ç”¨ï¼Œä¸”ä¸é‡åŒ–ï¼ˆå¦‚ fp8ï¼‰ã€GQAã€MoE ç­‰æŠ€æœ¯æ­£äº¤ï¼Œå…·å¤‡è‰¯å¥½æ‰©å±•æ€§ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–ç‰¹å®šç¡¬ä»¶æ”¯æŒ**ï¼šä»…é€‚ç”¨äºæ”¯æŒ sparse tensor cores çš„ GPUï¼ˆAmpere æ¶æ„èµ·ï¼‰ã€‚
- **å†…å­˜é‡æ’å¼€é”€**ï¼štoken permutation åœ¨å½“å‰ Hopper æ¶æ„ä¸­ä»éœ€è½¯ä»¶å®ç°ï¼›Blackwell å°†é€šè¿‡ Scatter/Gather GEMM + TMA æ¶ˆé™¤æ­¤æ­¥éª¤ã€‚
- **ä»…é™ FFN æ¨¡å—**ï¼šæ³¨æ„åŠ›æœºåˆ¶ä¸­çš„ç¨€ç–åŒ–å°šæœªé›†æˆï¼Œå› å¯èƒ½ä¸¢å¤±ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
- **å°æ‰¹é‡é™åˆ¶**ï¼šå½“ batch size è¾ƒå°æ—¶ï¼Œrouting å’Œ grouping çš„æ•ˆç‡ä¸‹é™ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³ Attention æ¨¡å—**ï¼šæ¢ç´¢ context-aware çš„ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼Œåœ¨ä¿è¯æ€§èƒ½çš„åŒæ—¶åŠ é€Ÿ attn GEMMsã€‚
2. **å…¨è‡ªåŠ¨ç¨€ç–è°ƒåº¦å™¨**ï¼šè®¾è®¡ adaptive scheduler è‡ªåŠ¨è°ƒèŠ‚ sparse/dense step ratioï¼Œé€‚é…ä¸åŒæ¨¡å‹å¤§å°ä¸è®­ç»ƒé˜¶æ®µã€‚
3. **ä¸ Quantization èåˆ**ï¼šè¿›ä¸€æ­¥ç»“åˆ fp8/int8 é‡åŒ–ï¼Œå®ç° â€œsparsity + low-precisionâ€ åŒé‡åŠ é€Ÿã€‚
4. **æ”¯æŒæ›´çµæ´»çš„ç¨€ç–æ ¼å¼**ï¼šæ¢ç´¢ beyond Venom çš„æ–°å‹ semi-structured æ ¼å¼ï¼Œé€‚é…æ›´é«˜ç¨€ç–åº¦åœºæ™¯ã€‚
5. **åº”ç”¨äº MoE æ¶æ„**ï¼šå°† neuron-level routing æ€æƒ³è¿ç§»åˆ° expert selection ä¸­ï¼Œæå‡ MoE æ•ˆç‡ã€‚

---

## æ€»ç»“ä¸€å¥è¯
> æœ¬æ–‡é¦–æ¬¡å®ç°äº† **LLM é¢„è®­ç»ƒä¸­ FFN æ¨¡å—å…¨è·¯å¾„ç¨€ç–åŒ–**ï¼Œé€šè¿‡ **2:4 weight sparsity + Venom activation sparsity + hybrid training** ç­–ç•¥ï¼Œåœ¨ **ä¸ç‰ºç‰²ç²¾åº¦çš„å‰æä¸‹è·å¾— 1.4â€“1.7Ã— ç«¯åˆ°ç«¯è®­ç»ƒåŠ é€Ÿ**ï¼Œä¸ºä¸‹ä¸€ä»£é«˜æ•ˆ LLM è®­ç»ƒæä¾›äº†å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 14. [Inference-Time Rethinking with Latent Thought Vectors for Math Reasoning](https://arxiv.org/abs/2602.06584)

**Authors**: Deqian Kong, Minglu Zhao, Aoyang Qin, Bo Pang, Chenxin Tao, David Hartmann, Edouardo Honig, Dehong Xu, Amit Kumar, Matt Sarte, Chuan Li, Jianwen Xie, Ying Nian Wu  
**Category**: cs.CL  
**Published**: 2026-02-09  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2602.06584v1  

#### Abstract
Standard chain-of-thought reasoning generates a solution in a single forward pass, committing irrevocably to each token and lacking a mechanism to recover from early errors. We introduce Inference-Time Rethinking, a generative framework that enables iterative self-correction by decoupling declarativ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Inference-Time Rethinking with Latent Thought Vectors for Math Reasoning*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
æ ‡å‡†çš„ **chain-of-thought (CoT)** æ¨ç†åœ¨è¯­è¨€æ¨¡å‹ä¸­æ˜¯å•å‘å‰å‘ç”Ÿæˆè¿‡ç¨‹ï¼Œä¸€æ—¦æŸä¸ª token è¢«ç”Ÿæˆå°±æ— æ³•æ’¤é”€ã€‚æ—©æœŸé”™è¯¯ä¼šæŒç»­ä¼ æ’­ï¼Œç¼ºä¹**å›æº¯ä¸è‡ªæˆ‘ä¿®æ­£æœºåˆ¶**ã€‚æ­¤å¤–ï¼Œå½“å‰å¤§å¤šæ•°æ¨¡å‹å°†â€œæ€è€ƒå†…å®¹â€ï¼ˆdeclarativeï¼‰ä¸â€œè¡¨è¾¾è¿‡ç¨‹â€ï¼ˆproceduralï¼‰è€¦åˆåœ¨ä¸€èµ·ï¼Œé™åˆ¶äº†å¯¹æ¨ç†ç­–ç•¥çš„ç‹¬ç«‹ä¼˜åŒ–ã€‚

### ğŸ”§ æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
æå‡º **Inference-Time Rethinking** æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- **è§£è€¦æ¨ç†è¿‡ç¨‹**ï¼šå°†æ¨ç†åˆ†è§£ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼š
  - **Latent Thought Vectors $ z $**ï¼šè¡¨ç¤ºâ€œè¦æ€è€ƒä»€ä¹ˆâ€ï¼ˆdeclarative å†…å®¹ï¼‰ï¼Œä½œä¸ºè¿ç»­ã€å¯å¾®çš„éšå˜é‡ç¼–ç æ¨ç†ç»“æ„ã€‚
  - **Decoder**ï¼šè´Ÿè´£â€œå¦‚ä½•è¡¨è¾¾æ¨ç†â€ï¼ˆprocedural è¿‡ç¨‹ï¼‰ï¼ŒåŸºäº $ z $ ç”Ÿæˆå…·ä½“çš„æ¨ç†è½¨è¿¹ï¼ˆreasoning traceï¼‰ã€‚
- å¼•å…¥ä¸€ä¸ª **Gibbs-style çš„è¿­ä»£åæ€æœºåˆ¶**ï¼Œåœ¨æ¨ç†æ—¶äº¤æ›¿è¿›è¡Œï¼š
  1. **Generateï¼ˆç”Ÿæˆï¼‰**ï¼šç”¨å½“å‰ $ z $ ç”Ÿæˆå€™é€‰æ¨ç†é“¾ã€‚
  2. **Reflectï¼ˆåæ€ï¼‰**ï¼šé€šè¿‡æ¢¯åº¦ä¼˜åŒ–è°ƒæ•´ $ z $ï¼Œä½¿å…¶æ›´æœ‰å¯èƒ½ç”Ÿæˆè¯¥æ¨ç†é“¾ï¼Œä»è€Œæå‡é€»è¾‘ä¸€è‡´æ€§ã€‚

è¿™ç§æ–¹æ³•ä½¿å¾—æ¨¡å‹å¯ä»¥åœ¨æµ‹è¯•é˜¶æ®µé€šè¿‡å¤šæ¬¡â€œå†æ€è€ƒâ€æ¥é€æ­¥æ”¹è¿›å…¶æ¨ç†ç­–ç•¥ã€‚

### ğŸš€ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **å‚æ•°æ•ˆç‡** | ä»…ä½¿ç”¨ **0.2B å‚æ•°æ¨¡å‹**ï¼Œæ€§èƒ½è¶…è¶Š 10â€“15Ã— æ›´å¤§çš„åŸºçº¿æ¨¡å‹ï¼ˆå¦‚ 3B çš„ CoT-SFTï¼‰ã€‚ |
| **å­¦ä¹ æ•ˆç‡** | åˆ†ç¦»å‡º latent thought åï¼Œdecoder ä¸éœ€è®°å¿†æ‰€æœ‰æ¨ç†æ¨¡å¼ï¼Œé™ä½å»ºæ¨¡è´Ÿæ‹…ã€‚ |
| **æ¨ç†çµæ´»æ€§** | æ”¯æŒæµ‹è¯•æ—¶åŠ¨æ€ä¼˜åŒ–ï¼ˆtest-time computationï¼‰ï¼Œå®ç°â€œè¶Šæƒ³è¶Šæ¸…æ¥šâ€çš„èƒ½åŠ›ã€‚ |
| **æ³›åŒ–èƒ½åŠ›** | åœ¨ out-of-domain æ•°æ®ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå¾—ç›Šäº latent space å¯¹è¡¨é¢å½¢å¼å˜åŒ–çš„æŠ½è±¡èƒ½åŠ›ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
- **è®­ç»ƒæ•°æ®**ï¼š
  - **GSM8K-Aug**ï¼šåŸºäº GSM8K çš„å¢å¼ºç‰ˆæœ¬ï¼ŒåŒ…å« 385K æ¡æ•°å­¦é¢˜åŠå…¶ equation-based CoT è§£ç­”ã€‚
  - æ‰€æœ‰æ¨¡å‹ä»é›¶å¼€å§‹è®­ç»ƒï¼ˆscratch trainingï¼‰ï¼Œä¸ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚
  
- **è¯„ä¼°åŸºå‡†**ï¼ˆEvaluation Benchmarksï¼‰ï¼š
  | æ•°æ®é›† | æè¿° |
  |-------|------|
  | **GSM8K** | åŸå§‹æµ‹è¯•é›†ï¼ˆ1,319 é“å°å­¦æ•°å­¦é¢˜ï¼‰ï¼Œç”¨äºè¡¡é‡ in-domain æ€§èƒ½ã€‚ |
  | **SVAMP** | 4,138 é“ç»è¿‡è¯­ä¹‰æ‰°åŠ¨çš„ç®—æœ¯é¢˜ï¼Œæ£€éªŒå¯¹è¡¨è¿°å˜åŒ–çš„é²æ£’æ€§ï¼ˆout-of-domainï¼‰ã€‚ |
  | **MultiArith** | 600 é“å¤šæ­¥ç®—æœ¯é¢˜ï¼Œæ¥è‡ª MAWPSï¼Œè¦æ±‚å¤æ‚æ¨ç†ï¼ˆout-of-domainï¼‰ã€‚ |

- **è¯„ä¼°æŒ‡æ ‡**ï¼š**Accuracy (%)**

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**ï¼š
  - **0.2B-parameter Transformer**ï¼ŒåŸºäº Llama-2 æ¶æ„ã€‚
  - ä¸Šä¸‹æ–‡çª—å£ $ w = 64 $ï¼Œéšè—å±‚å¤§å° 1024ã€‚
  - åŒ…å« 8 å±‚ decoder å’Œ 2 å±‚ encoderï¼ˆç”¨äºç”Ÿæˆ latent thought vectorsï¼‰ã€‚
  - ä½¿ç”¨ **64 ä¸ª latent tokens** ç¼–ç å…¨å±€æ¨ç†ç»“æ„ã€‚

- **æ¨ç†é…ç½®**ï¼š
  - **Rethink-1**ï¼šå•æ¬¡ç”Ÿæˆï¼ˆæ— è¿­ä»£ä¼˜åŒ–ï¼‰ã€‚
  - **Rethink-30**ï¼šæ‰§è¡Œ 30 è½® Generate-Reflect å¾ªç¯ï¼Œä¿ç•™ likelihood æœ€é«˜çš„ trace è¾“å‡ºç­”æ¡ˆã€‚

- **è®­ç»ƒç­–ç•¥**ï¼š
  - é‡‡ç”¨ **Dual-Rate Optimization**ï¼š
    - **Fast æ›´æ–°**ï¼šæ¯æ¡æ ·æœ¬ç‹¬ç«‹ä¼˜åŒ–å˜åˆ†å‚æ•° $ (u, \sigma^2) $ï¼ˆå…± T_fast=16 æ­¥ï¼‰ã€‚
    - **Slow æ›´æ–°**ï¼šå…¨å±€æ›´æ–°æ¨¡å‹å‚æ•° $ \theta = (\alpha, \beta) $ã€‚

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿æ–¹æ³• | ç®€ä»‹ |
|--------|------|
| **CoT-SFT** | Chain-of-Thought ç›‘ç£å¾®è°ƒï¼Œä¸»æµ baselineã€‚ |
| **iCoT-SI**, **Coconut**, **CoLaR**, **CODI** | è¿‘æœŸåŸºäº latent reasoning çš„æ–¹æ³•ã€‚ |
| **MARCoS-2B** | ä½¿ç”¨ 2B æ¨¡å‹çš„å…ˆè¿› latent chain æ–¹æ³•ã€‚ |
| æ‰€æœ‰ baseline ä½¿ç”¨ Qwen2.5-0.5B æˆ– Qwen2.5-3B ä½œä¸º backboneã€‚ |

> æ³¨ï¼šæœ¬æ–‡æ¨¡å‹ï¼ˆ0.2Bï¼‰è¿œå°äºæ‰€æœ‰ baselineã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰
| Method | Backbone | GSM8K | SVAMP | MultiArith |
|--------|----------|-------|-------|-----------|
| CoT-SFT | Qwen2.5-3B | 22.70 | 27.25 | 50.20 |
| MARCoS | 2B | 24.11 | 27.77 | 42.33 |
| **Ours (Rethink-1)** | **0.2B** | **25.93** | **47.37** | **63.00** |
| **Ours (Rethink-30)** | **0.2B** | **31.54** | **51.50** | **68.00** |

> âœ… **å…¨éƒ¨ä¸‰é¡¹ä»»åŠ¡å‡è¾¾åˆ° SOTAï¼Œä¸”ä½¿ç”¨æœ€å°æ¨¡å‹**

### ğŸ” ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **ç›¸æ¯” 3B çš„ CoT-SFT**ï¼š
  - GSM8K æå‡ **+8.84% absolute**
  - SVAMP æå‡ **+24.25%**
  - MultiArith æå‡ **+17.8%**
- **ç›¸æ¯” 2B çš„ MARCoS**ï¼š
  - å…¨é¢å¤§å¹…é¢†å…ˆï¼Œå°¤å…¶åœ¨ SVAMP å’Œ MultiArith ä¸Šä½“ç°å¼ºå¤§æ³›åŒ–èƒ½åŠ›ã€‚

### ğŸ”¬ æ¶ˆèå®éªŒåˆ†æï¼ˆéšå«äºæ–‡ä¸­ï¼‰
è™½ç„¶æœªè®¾ä¸“é—¨æ¶ˆèè¡¨æ ¼ï¼Œä½†ä»¥ä¸‹å…³é”®å‘ç°å…·æœ‰æ¶ˆèæ„ä¹‰ï¼š
- **Rethink-1 vs Rethink-30 çš„å·®è·**ï¼š
  - GSM8Kï¼š+5.6 pts
  - SVAMPï¼š+4.1 pts
  - MultiArithï¼š+5.0 pts
  > è¡¨æ˜ **inference-time computation æœ¬èº«å¸¦æ¥æ˜¾è‘—å¢ç›Š**ï¼ŒéªŒè¯â€œæ€è€ƒæ—¶é—´è¶Šé•¿ï¼Œæ•ˆæœè¶Šå¥½â€ã€‚

- **Latent Thought Vector çš„ä½œç”¨**ï¼š
  - å°†æ¨ç†ç»“æ„å‹ç¼©åˆ°è¿ç»­ç©ºé—´ï¼Œå±è”½ token çº§åˆ«å™ªå£°ï¼Œä½¿æ¢¯åº¦ä¼˜åŒ–å¯è¡Œã€‚
  - å­¦ä¹ åˆ°çš„ prior manifold åæ˜ æœ‰æ•ˆæ¨ç†æ¨¡å¼åˆ†å¸ƒï¼Œæ”¯æŒé«˜è´¨é‡åæ€ã€‚

- **çŸ­ä¸Šä¸‹æ–‡çª—å£è®¾è®¡**ï¼š
  - å¼ºåˆ¶æ¨¡å‹ä¾èµ– $ z $ å»ºç«‹ long-range dependencyï¼Œä¿ƒè¿› latent vector å­¦ä¹ å…¨å±€ç»“æ„ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **æœ‰æ•ˆçš„æ•°å­¦æ¨ç†å¯ä»¥æºäºå¤æ‚çš„æ¨ç†æ—¶è®¡ç®—ï¼Œè€Œéä»…ä»…ä¾èµ–å¤§è§„æ¨¡å‚æ•°**ã€‚
2. **å°† declarative thought ä¸ procedural generation è§£è€¦ï¼Œæ˜¾è‘—æå‡äº†å­¦ä¹ æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›**ã€‚
3. **Test-time computation æ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ‰©å±•è½´ï¼ˆscaling axisï¼‰ï¼Œä¸ parameter scaling æ­£äº¤äº’è¡¥**ã€‚
4. **é€šè¿‡ latent space ä¸­çš„æ¢¯åº¦ä¼˜åŒ–ï¼Œæ¨¡å‹èƒ½å¤Ÿå®ç°è‡ªæˆ‘çº æ­£ï¼ˆself-correctionï¼‰ï¼Œç¼“è§£æ—©æœŸé”™è¯¯ä¼ æ’­é—®é¢˜**ã€‚
5. **latent thought abstraction æé«˜äº†å¯¹è¡¨é¢å½¢å¼å˜åŒ–çš„é²æ£’æ€§ï¼Œåœ¨ out-of-domain åœºæ™¯ä¸‹ä¼˜åŠ¿æ˜æ˜¾**ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡è®­ç»ƒæ•°æ®**ï¼šå½“å‰æ–¹æ³•ä»¥ likelihood ä½œä¸ºæ­£ç¡®æ€§çš„ä»£ç†ï¼ˆproxyï¼‰ã€‚è‹¥è®­ç»ƒæ•°æ®å­˜åœ¨ç³»ç»Ÿæ€§é”™è¯¯æˆ–å™ªå£°ï¼Œåˆ™ high-likelihood trace å¯èƒ½å¯¹åº”é”™è¯¯æ¨ç†ã€‚
- **æ— æ³•å¤„ç†å®Œå…¨é”™è¯¯çš„å‰æå‡è®¾**ï¼šå¦‚æœåˆå§‹ç”Ÿæˆä¸¥é‡åç¦»äº‹å®ï¼Œåç»­åæ€å¯èƒ½é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚
- **è®¡ç®—æˆæœ¬é›†ä¸­åœ¨æ¨ç†é˜¶æ®µ**ï¼šè™½ç„¶è®­ç»ƒè½»é‡ï¼Œä½† Rethink-30 éœ€è¦ 30 æ¬¡å¾ªç¯ï¼Œå»¶è¿Ÿè¾ƒé«˜ï¼Œä¸é€‚åˆä½å»¶è¿Ÿåœºæ™¯ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **å¼•å…¥æ˜¾å¼çš„ value signal**ï¼š
   - è®¾è®¡ **Latent Verifier**ï¼Œç›´æ¥é¢„æµ‹ thought vector çš„æ­£ç¡®æ€§ï¼Œå®ç°â€œæ½œæ„è¯†è§„åˆ’â€ã€‚
2. **ç»“åˆå¤–éƒ¨å¥–åŠ±ä¿¡å·**ï¼š
   - åˆ©ç”¨ä»£ç è§£é‡Šå™¨ã€ç¬¦å·æ±‚è§£å™¨ç­‰æä¾› feedbackï¼Œè¿›è¡Œ test-time policy gradient ä¼˜åŒ–ã€‚
3. **Trust Region æ§åˆ¶**ï¼š
   - åˆ©ç”¨ prior regularization ä½œä¸º trust regionï¼Œé˜²æ­¢ latent optimization åç¦»åˆç† manifoldã€‚
4. **æ‰©å±•è‡³å…¶ä»–æ¨ç†ä»»åŠ¡**ï¼š
   - å¦‚ç§‘å­¦é—®ç­”ã€å®šç†è¯æ˜ã€ç¨‹åºåˆæˆç­‰é¢†åŸŸï¼Œæ¢ç´¢ latent planning çš„é€šç”¨æ€§ã€‚

---

## âœ… æ€»ç»“
æœ¬è®ºæ–‡æå‡ºäº† **Inference-Time Rethinking** æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥ **Latent Thought Vectors** å®ç°äº†æ¨ç†è¿‡ç¨‹ä¸­â€œå†…å®¹â€ä¸â€œè¡¨è¾¾â€çš„åˆ†ç¦»ï¼Œå¹¶åˆ©ç”¨ **Gibbs-style è¿­ä»£ä¼˜åŒ–** åœ¨æµ‹è¯•é˜¶æ®µä¸æ–­åæ€å’Œä¿®æ­£æ¨ç†è·¯å¾„ã€‚å®éªŒè¯æ˜ï¼Œå³ä½¿æ˜¯ä¸€ä¸ª **0.2B çš„å°æ¨¡å‹**ï¼Œä¹Ÿèƒ½é€šè¿‡â€œå¤šæƒ³å‡ æ¬¡â€ï¼Œåœ¨å¤šä¸ªæ•°å­¦æ¨ç† benchmark ä¸Šè¶…è¶Š **10â€“15 å€æ›´å¤§**çš„æ¨¡å‹ï¼Œå±•ç¤ºäº† **test-time computation + structured latent space** ä½œä¸ºä¸€ç§æ–°å‹é«˜æ•ˆ scaling paradigm çš„å·¨å¤§æ½œåŠ›ã€‚

</details>

---

### 15. [HyPER: Bridging Exploration and Exploitation for Scalable LLM Reasoning with Hypothesis Path Expansion and Reduction](https://arxiv.org/abs/2602.06527)

**Authors**: Shengxuan Qiu, Haochen Huang, Shuzhang Zhong, Pengfei Zuo, Meng Li  
**Category**: cs.AI  
**Published**: 2026-02-09  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.06527v1  

#### Abstract
Scaling test-time compute with multi-path chain-of-thought improves reasoning accuracy, but its effectiveness depends critically on the exploration-exploitation trade-off. Existing approaches address this trade-off in rigid ways: tree-structured search hard-codes exploration through brittle expansio...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šHyPER: Bridging Exploration and Exploitation for Scalable LLM Reasoning with Hypothesis Path Expansion and Reduction

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­ä¾èµ–å¤šè·¯å¾„ Chain-of-Thoughtï¼ˆCoTï¼‰æ¥æå‡å‡†ç¡®æ€§ï¼Œä½†é¢ä¸´**æ¢ç´¢ï¼ˆexplorationï¼‰ä¸åˆ©ç”¨ï¼ˆexploitationï¼‰ä¹‹é—´çš„æƒè¡¡éš¾é¢˜**ã€‚ç°æœ‰æ–¹æ³•å­˜åœ¨ä»¥ä¸‹ç¼ºé™·ï¼š
- **Tree-based search**ï¼šé‡‡ç”¨å›ºå®šçš„æ‰©å±•è§„åˆ™ï¼Œç ´åäº†æ¨¡å‹åè®­ç»ƒé˜¶æ®µå½¢æˆçš„è¿ç»­æ¨ç†æµï¼Œä¸”è¿‡åº¦ä¾èµ–äººå·¥è®¾è®¡çš„åˆ†æ”¯ç­–ç•¥ã€‚
- **Parallel reasoningï¼ˆå¦‚ Self-Consistency, Best-of-Nï¼‰**ï¼šè™½ä¿ç•™åŸç”Ÿç”Ÿæˆæ¨¡å¼ï¼Œä½†å€¾å‘äºè¿‡åº¦æ¢ç´¢å†—ä½™è·¯å¾„ï¼Œç¼ºä¹æœ‰æ•ˆçš„ç”Ÿæˆæ—¶ç²¾ç‚¼æœºåˆ¶ï¼ˆtest-time exploitationï¼‰ï¼Œç­”æ¡ˆé€‰æ‹©ä¹Ÿæ˜“å—é«˜é¢‘é”™è¯¯ç­”æ¡ˆå¹²æ‰°ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šHyPER
ä½œè€…æå‡º **HyPER**ï¼ˆHypothesis Path Expansion and Reductionï¼‰ï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„åœ¨çº¿æ§åˆ¶ç­–ç•¥ï¼Œå°†æµ‹è¯•æ—¶æ‰©å±•ï¼ˆtest-time scalingï¼‰é‡æ„ä¸ºä¸€ä¸ªåŠ¨æ€çš„â€œæ‰©å±•-ç¼©å‡â€æ§åˆ¶é—®é¢˜ï¼Œåœ¨å‡è®¾è·¯å¾„æ± ä¸­å®æ—¶è°ƒæ•´è®¡ç®—èµ„æºåˆ†é…ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹
1. **åŠ¨æ€ Expand-Reduce æ§åˆ¶å™¨ï¼ˆOnline Controllerï¼‰**
   - åŸºäºè½»é‡çº§è·¯å¾„ç»Ÿè®¡ä¿¡å·ï¼ˆç½®ä¿¡åº¦ã€å¤šæ ·æ€§ï¼‰åŠ¨æ€å†³ç­–æ˜¯å¦è¿›è¡Œè·¯å¾„åˆ†æ”¯ï¼ˆBranchï¼‰ã€çŸ­è§†ç•Œæ¢ç´¢ï¼ˆMultiTokenï¼‰æˆ–å•æ­¥ç²¾ç‚¼ï¼ˆSingleTokenï¼‰ã€‚
   - å®ç°ä»æ—©æœŸæ¢ç´¢åˆ°åæœŸåˆ©ç”¨çš„å¹³æ»‘è¿‡æ¸¡ï¼Œé¿å…é™æ€è°ƒåº¦å¸¦æ¥çš„èµ„æºæµªè´¹ã€‚

2. **åŸºäº MoE çš„ Token-Level ç²¾ç‚¼åŸè¯­ï¼ˆSingle-Token Aggregationï¼‰**
   - åˆ©ç”¨ MoE æ¶æ„ä¸­çš„ä¸“å®¶è·¯ç”±å¤šæ ·æ€§ï¼Œåœ¨ä¸é‡æ–°é‡‡æ ·æ•´æ¡è·¯å¾„çš„å‰æä¸‹ï¼Œå¯¹ä½ç½®ä¿¡åº¦ token è¿›è¡Œå±€éƒ¨ç²¾ç‚¼ã€‚
   - å¼•å…¥ä¸¤é˜¶æ®µé‡‡æ ·ï¼ˆtwo-pass samplingï¼‰æœºåˆ¶ï¼Œé€šè¿‡é‡ç”¨æƒ©ç½šï¼ˆreuse penaltyï¼‰å¢å¼ºä¸“å®¶å¤šæ ·æ€§ï¼Œé˜²æ­¢ç²¾ç‚¼è¿‡ç¨‹å¯¼è‡´è·¯å¾„åç¼©ã€‚

3. **é•¿åº¦ä¸ç½®ä¿¡åº¦æ„ŸçŸ¥çš„ç­”æ¡ˆèšåˆè§„åˆ™ï¼ˆLength- and Confidence-Aware Votingï¼‰**
   - å‘ç°å¹¶åˆ©ç”¨â€œå­˜åœ¨-é€‰æ‹©é¸¿æ²Ÿâ€ï¼ˆexistence-selection gapï¼‰ä¸­çš„ç»“æ„æ€§ä¿¡å·ï¼šç»ç½®ä¿¡åº¦å‰ªæåï¼Œæ­£ç¡®è·¯å¾„å¾€å¾€æ›´é•¿ã€‚
   - èšåˆå…¬å¼ç»“åˆè·¯å¾„é•¿åº¦ $L_p$ å’Œå…¨å±€ç½®ä¿¡åº¦ $c_p$ï¼Œæœ‰æ•ˆç¼“è§£å¤šæ•°æŠ•ç¥¨è¢«é”™è¯¯è·¯å¾„ä¸»å¯¼çš„é—®é¢˜ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **æ— éœ€é¢å¤–è®­ç»ƒ**ï¼šå®Œå…¨åŸºäºæ¨ç†æ—¶æ§åˆ¶ï¼Œé€‚ç”¨äºä»»ä½•å·²è®­ç»ƒå¥½çš„ MoE æ¨¡å‹ã€‚
- **é«˜æ•ˆèµ„æºåˆ©ç”¨**ï¼šåœ¨å›ºå®šè®¡ç®—é¢„ç®—ä¸‹ï¼Œæ™ºèƒ½åˆ†é…è®¡ç®—èµ„æºï¼Œå‡å°‘æ— æ•ˆæ¢ç´¢ã€‚
- **æ›´å¼ºçš„é²æ£’æ€§**ï¼šé€šè¿‡å¤šå±‚æ¬¡ç²¾ç‚¼ä¸èšåˆæœºåˆ¶ï¼Œæ˜¾è‘—æå‡æœ€ç»ˆç­”æ¡ˆçš„å¯é æ€§ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
å®éªŒè¦†ç›–ä¸¤ç±»æ¨ç†éš¾åº¦çš„æ•°æ®é›†ï¼š
- **Hard-reasoning tier**ï¼š
  - AIME24 / AIME25ï¼ˆç¾å›½æ•°å­¦é‚€è¯·èµ›ï¼‰
  - HMMT25ï¼ˆå“ˆä½›-éº»çœç†å·¥æ•°å­¦ç«èµ›ï¼‰
  - HLEï¼ˆHumanity's Last Examï¼‰
- **Light-reasoning tier**ï¼š
  - GSM8Kï¼ˆå°å­¦æ•°å­¦åº”ç”¨é¢˜ï¼‰
  - MATH500
  - ARC-C / ARC-Eï¼ˆç§‘å­¦å¸¸è¯†é—®ç­”ï¼‰

### æ¨¡å‹
- **MoE æ¨¡å‹**ï¼š
  - Qwen3-30B-A3B-Thinking-2507
  - Qwen3-Next-80B-A3B-Thinking
  - OLMoE-1B-7B-0924-Instruct
  - DeepSeek-V2-Lite-Chat
- **Dense æ¨¡å‹éªŒè¯å®éªŒ**ï¼š
  - DeepSeek-R1-0528-Qwen3-8Bï¼ˆç”¨äºéªŒè¯æ§åˆ¶å™¨é€šç”¨æ€§ï¼‰

### å®éªŒè®¾ç½®
- **åˆå§‹è·¯å¾„å®½åº¦ä¸Šé™**ï¼š`Smax = 80`
- **Warm-up é˜¶æ®µ**ï¼šå…ˆè¿è¡Œ Self-Consistency è·å–ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œç”¨äºåç»­å‰ªæã€‚
- **å…¬å¹³æ¯”è¾ƒ**ï¼šä»¥æ€»å®ä¾‹åŒ–è·¯å¾„æ•° `Total Instantiated Path Count (Ninst)` å¯¹é½è®¡ç®—æˆæœ¬ï¼Œç¡®ä¿ä¸åŸºçº¿æ–¹æ³•åœ¨ç›¸åŒ token æ¶ˆè€—ä¸‹å¯¹æ¯”ã€‚
- **æ§åˆ¶å™¨å‚æ•°**ï¼š
  - å†³ç­–é—´éš” `T = 64` æ­¥
  - å¤šæ ·æ€§æƒé‡ `Î· = 0.4`
  - é‡ç”¨æƒ©ç½šå¼ºåº¦ `Î» = 0.1`
  - æŠ•ç¥¨æƒé‡ `Î»_len = 0.6`, `Î»_conf = 0.4`

### è¯„ä¼°æŒ‡æ ‡
- **å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰**
- **å½’ä¸€åŒ– Token æ¶ˆè€—ï¼ˆNormalized Token Costï¼‰**
- **Pareto æ›²çº¿åˆ†æ**ï¼šç²¾åº¦ vs. è®¡ç®—æˆæœ¬çš„æƒè¡¡å…³ç³»

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | æ˜¯å¦å¯è®­ç»ƒ | ç‰¹ç‚¹ |
|------|------|------------|------|
| SC (Self-Consistency) | Parallel | âœ… | å›ºå®šå®½åº¦å¤šè·¯å¾„é‡‡æ ·ï¼Œæœ«å°¾æŠ•ç¥¨ |
| Self-Certainty | Adaptive | âœ… | åŸºäºç½®ä¿¡åº¦è‡ªé€‚åº”ç»ˆæ­¢ |
| DeepConf | Adaptive | âœ… | ç½®ä¿¡åº¦å¼•å¯¼å‰ªæï¼ŒèŠ‚çœè®¡ç®— |
| RoE (Routing over Experts) | Token-level | âœ… | åœ¨ token çº§åˆ«åˆ©ç”¨ MoE è·¯ç”±å¤šæ ·æ€§ |
| Manual Schedule | â€” | âŒ | æ‰‹åŠ¨è®¾å®šå‰åŠæ®µæ¢ç´¢ã€ååŠæ®µç²¾ç‚¼ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æ¨¡å‹ | æ•°æ®é›† | HyPER å‡†ç¡®ç‡ | æœ€ä½³åŸºçº¿å‡†ç¡®ç‡ | æå‡å¹…åº¦ | Token æ¶ˆè€—ï¼ˆç›¸å¯¹ SCï¼‰ |
|------|--------|--------------|----------------|----------|-------------------------|
| Qwen3-30B | AIME25 | **95.3%** | 90.7% (DeepConf) | **+4.6pp** | 0.71Ã— |
| Qwen3-Next | AIME25 | **96.0%** | 94.0% (DeepConf) | **+2.0pp** | 0.59Ã— |
| Qwen3-30B | HMMT25 | **78.7%** | 74.0% (DeepConf) | **+4.7pp** | 0.77Ã— |
| OLMoE | GSM8K | **80.3%** | 77.6% (DeepConf) | **+2.7pp** | 0.48Ã— |
| OLMoE | MATH500 | **46.7%** | 43.7% (DeepConf) | **+3.0pp** | 0.73Ã— |

> **æ€»ä½“è¡¨ç°**ï¼šHyPER åœ¨å¤šä¸ªæ¨¡å‹å’Œæ•°æ®é›†ä¸Šå¹³å‡æå‡ **8â€“10 ä¸ªç™¾åˆ†ç‚¹**ï¼ŒåŒæ—¶é™ä½ **25â€“40% çš„ token æ¶ˆè€—**ã€‚

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **ä¼˜äºæ‰€æœ‰ baseline**ï¼šåœ¨æ‰€æœ‰ä»»åŠ¡ä¸­å‡è¾¾åˆ°æœ€é«˜å‡†ç¡®ç‡ï¼Œä¸”ä½äº accuracy-compute Pareto å‰æ²¿ã€‚
- **æ˜¾è‘—ä¼˜äº DeepConf**ï¼šå°½ç®¡ DeepConf å·²å¼•å…¥å‰ªæä¼˜åŒ–ï¼ŒHyPER ä»èƒ½è¿›ä¸€æ­¥æå‡ 4â€“6 ä¸ªç™¾åˆ†ç‚¹ã€‚
- **ä¼˜äº RoE**ï¼šè™½ç„¶ RoE ä¹Ÿèƒ½è¿›è¡Œ token çº§ç²¾ç‚¼ï¼Œä½†å…¶ç¼ºä¹å¤šæ ·æ€§æ§åˆ¶ï¼Œå®¹æ˜“å¯¼è‡´è·¯å¾„åç¼©ï¼›HyPER çš„ two-pass sampling æ˜¾è‘—æå‡äº†è·¯å¾„å¤šæ ·æ€§ï¼ˆè§ Figure 11ï¼‰ã€‚

### æ¶ˆèå®éªŒç»“æœ

#### A. ä¸åŒæ‰©å±•ç­–ç•¥å¯¹æ¯”ï¼ˆTable 3ï¼‰
| æ–¹æ³• | AIME25 Acc | Token æˆæœ¬ |
|------|-----------|------------|
| Self-consistency | 86.7% | 1.00Ã— |
| SingleToken-only | 93.3% | 1.81Ã— |
| MultiToken-only | 90.0% | 1.87Ã— |
| Manual Schedule | 93.3% | 1.78Ã— |
| **HyPER (å®Œæ•´)** | **96.7%** | **1.62Ã—** |

> ç»“è®ºï¼šä»…ä½¿ç”¨å•ä¸€ç­–ç•¥æ— æ³•å…¼é¡¾æ•ˆç‡ä¸æ•ˆæœï¼Œè€Œ HyPER çš„åŠ¨æ€æ§åˆ¶å™¨å®ç°äº†æœ€ä¼˜æƒè¡¡ã€‚

#### B. æŠ•ç¥¨ç­–ç•¥å¯¹æ¯”ï¼ˆTable 4 & Table 5ï¼‰
| æŠ•ç¥¨æ–¹å¼ | AIME25 Acc | HMMT25 Acc |
|----------|-----------|------------|
| Majority Voting | 86.7% | 73.3% |
| Confidence-weighted Voting | 90.0% | 73.3% |
| **Length + Confidence Voting (HyPER)** | **96.7%** | **76.7%** |

> ç»“è®ºï¼šé•¿åº¦æ˜¯ç½®ä¿¡åº¦å‰ªæä¸‹çš„å¼ºè¾…åŠ©ä¿¡å·ï¼ŒäºŒè€…ç»“åˆå¯æ˜¾è‘—ç¼©å°â€œå­˜åœ¨-é€‰æ‹©é¸¿æ²Ÿâ€ã€‚

#### C. æ§åˆ¶å™¨è¡Œä¸ºåˆ†æ
- **ç®€å•é—®é¢˜**ï¼šæ§åˆ¶å™¨å¿«é€Ÿæ”¶æ•›è‡³ `NONE` æˆ– `SingleToken`ï¼Œæå°‘è§¦å‘ `BRANCH`ã€‚
- **å›°éš¾é—®é¢˜**ï¼šé¢‘ç¹ä½¿ç”¨ `BRANCH` å’Œ `MULTITOKEN` æ‰©å±•æœç´¢ç©ºé—´ï¼ŒåæœŸè½¬å‘ `SINGLETOKEN` è¿›è¡Œç²¾ç‚¼ã€‚
- **æ•°æ®é›†å±‚é¢ç»Ÿè®¡**ï¼šè¶Šéš¾çš„ä»»åŠ¡ï¼Œ`BRANCH` å’Œ `SINGLETOKEN` ä½¿ç”¨é¢‘ç‡è¶Šé«˜ï¼Œè¡¨æ˜æ§åˆ¶å™¨å…·å¤‡é—®é¢˜éš¾åº¦è‡ªé€‚åº”èƒ½åŠ›ï¼ˆFigure 10ï¼‰ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æ¢ç´¢ä¸åˆ©ç”¨åº”æ˜¯åŠ¨æ€å¹³è¡¡çš„è¿‡ç¨‹**ï¼šæ—©æœŸéœ€å¹¿æ³›æ¢ç´¢ï¼ŒåæœŸåº”èšç„¦é«˜è´¨é‡è·¯å¾„çš„ç²¾ç‚¼ï¼Œé™æ€è°ƒåº¦æ•ˆç‡ä½ä¸‹ã€‚
2. **æ­£ç¡®ä¸é”™è¯¯è·¯å¾„å¸¸åœ¨æœ«å°¾æ‰åˆ†é“æ‰¬é•³**ï¼šå› æ­¤å¯¹æ•´æ¡è·¯å¾„é‡é‡‡æ ·ä»£ä»·é«˜æ˜‚ï¼Œå±€éƒ¨ token çº§ç²¾ç‚¼æ›´ä¸ºé«˜æ•ˆã€‚
3. **ç½®ä¿¡åº¦å‰ªæä¼šåè½¬è·¯å¾„é•¿åº¦åå·®**ï¼šæ­£ç¡®è·¯å¾„å› é€»è¾‘ç¨³å®šè€Œå­˜æ´»æ›´ä¹…ï¼Œåè€Œæ¯”é”™è¯¯è·¯å¾„æ›´é•¿ï¼Œè¿™ä¸€ä¿¡å·å¯ç”¨äºå¯é ç­”æ¡ˆé€‰æ‹©ã€‚
4. **MoE æ¶æ„ä¸º token-level exploitation æä¾›å¤©ç„¶æ”¯æŒ**ï¼šé€šè¿‡ä¸“å®¶è·¯ç”±æ‰°åŠ¨å³å¯å®ç°ä½æˆæœ¬é«˜æ”¶ç›Šçš„æ¨ç†å¢å¼ºã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ– MoE æ¶æ„**ï¼šSingle-Token Aggregation æ¨¡å—ä¾èµ– MoE çš„ä¸“å®¶è·¯ç”±æœºåˆ¶ï¼Œåœ¨çº¯ dense æ¨¡å‹ä¸Šæ— æ³•ç›´æ¥åº”ç”¨ï¼ˆä½†æ§åˆ¶å™¨éƒ¨åˆ†ä»å¯ç”¨ï¼‰ã€‚
- **ä¿¡å·ç²—ç²’åº¦**ï¼šæ§åˆ¶å™¨åŸºäºç®€å•çš„å¹³å‡ç»Ÿè®¡é‡å†³ç­–ï¼Œæœªå¼•å…¥å­¦ä¹ å‹ç­–ç•¥ï¼Œå¯èƒ½åœ¨æç«¯æ¡ˆä¾‹ä¸­å¤±æ•ˆã€‚
- **è¶…å‚æ•°æ•æ„Ÿæ€§**ï¼šè™½ç„¶æ•´ä½“é²æ£’ï¼Œä½† `Î»`ï¼ˆé‡ç”¨æƒ©ç½šï¼‰ç­‰å‚æ•°å¯¹å¤šæ ·æ€§å½±å“è¾ƒæ˜æ˜¾ï¼Œéœ€åˆç†è®¾ç½®ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- **ç»“åˆ PRMï¼ˆProcess Reward Modelsï¼‰**ï¼šå°† HyPER çš„åŠ¨æ€è·¯å¾„ç®¡ç†ä¸ learned verifier ç»“åˆï¼Œè¿›ä¸€æ­¥æå‡æ¨ç†è´¨é‡ã€‚
- **æ‰©å±•è‡³ Dense æ¨¡å‹**ï¼šè®¾è®¡é€‚ç”¨äº dense æ¨¡å‹çš„è½»é‡çº§ token çº§ç²¾ç‚¼æœºåˆ¶ã€‚
- **æ¢ç´¢æ›´å¤æ‚çš„æ§åˆ¶ç­–ç•¥**ï¼šå¼•å…¥å°å‹ learnable controller ä»¥æ•æ‰æ›´ç²¾ç»†çš„çŠ¶æ€è½¬ç§»æ¨¡å¼ã€‚
- **åº”ç”¨äºå¤šæ¨¡æ€æ¨ç†**ï¼šå°† expand-reduce æ€æƒ³æ¨å¹¿è‡³è§†è§‰-è¯­è¨€è”åˆæ¨ç†åœºæ™¯ã€‚

--- 

> **ä»£ç å¼€æºåœ°å€**ï¼š[https://github.com/ShengxuanQiu/HyPER](https://github.com/ShengxuanQiu/HyPER)

</details>

---

### 16. [DualMap: Enabling Both Cache Affinity and Load Balancing for Distributed LLM Serving](https://arxiv.org/abs/2602.06502)

**Authors**: Ying Yuan, Pengfei Zuo, Bo Wang, Zhangyu Chen, Zhipeng Tan, Zhou Yu  
**Category**: cs.DC  
**Published**: 2026-02-09  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.06502v1  

#### Abstract
In LLM serving, reusing the KV cache of prompts across requests is critical for reducing TTFT and serving costs. Cache-affinity scheduling, which co-locates requests with the same prompt prefix to maximize KV cache reuse, often conflicts with load-balancing scheduling that distributes requests evenl...

---

### 17. [Adaptive Uncertainty-Aware Tree Search for Robust Reasoning](https://arxiv.org/abs/2602.06493)

**Authors**: Zeen Song, Zihao Ma, Wenwen Qiang, Changwen Zheng, Gang Hua  
**Category**: cs.LG  
**Published**: 2026-02-09  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.06493v1  

#### Abstract
Inference-time reasoning scaling has significantly advanced the capabilities of Large Language Models (LLMs) in complex problem-solving. A prevalent approach involves external search guided by Process Reward Models (PRMs). However, a fundamental limitation of this framework is the epistemic uncertai...

---

### 18. [Fine-Grained Model Merging via Modular Expert Recombination](https://arxiv.org/abs/2602.06552)

**Authors**: Haiyun Qiu, Xingyu Wu, Liang Feng, Kay Chen Tan  
**Category**: cs.LG  
**Published**: 2026-02-09  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.06552v1  

#### Abstract
Model merging constructs versatile models by integrating task-specific models without requiring labeled data or expensive joint retraining. Although recent methods improve adaptability to heterogeneous tasks by generating customized merged models for each instance, they face two critical limitations...

---

### 19. [When RL Meets Adaptive Speculative Training: A Unified Training-Serving System](https://arxiv.org/abs/2602.06932)

**Authors**: Junxiong Wang, Fengxiang Bie, Jisen Li, Zhongzhu Zhou, Zelei Shao, Yubo Wang, Yinghui Liu, Qingyang Wu, Avner May, Sri Yanamandra, Yineng Zhang, Ce Zhang, Tri Dao, Percy Liang, Ben Athiwaratkun, Shuaiwen Leon Song, Chenfeng Xu, Xiaoxia Wu  
**Category**: cs.LG  
**Published**: 2026-02-09  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2602.06932v1  

#### Abstract
Speculative decoding can significantly accelerate LLM serving, yet most deployments today disentangle speculator training from serving, treating speculator training as a standalone offline modeling problem. We show that this decoupled formulation introduces substantial deployment and adaptation lag:...

---

### 20. [Difficulty-Estimated Policy Optimization](https://arxiv.org/abs/2602.06375)

**Authors**: Yu Zhao, Fan Jiang, Tianle Liu, Bo Zeng, Yu Liu, Longyue Wang, Weihua Luo  
**Category**: cs.AI  
**Published**: 2026-02-09  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.06375v1  

#### Abstract
Recent advancements in Large Reasoning Models (LRMs), exemplified by DeepSeek-R1, have underscored the potential of scaling inference-time compute through Group Relative Policy Optimization (GRPO). However, GRPO frequently suffers from gradient signal attenuation when encountering problems that are ...

---

### 21. [AgentCPM-Report: Interleaving Drafting and Deepening for Open-Ended Deep Research](https://arxiv.org/abs/2602.06540)

**Authors**: Yishan Li, Wentong Chen, Yukun Yan, Mingwei Li, Sen Mei, Xiaorong Wang, Kunpeng Liu, Xin Cong, Shuo Wang, Zhong Zhang, Yaxi Lu, Zhenghao Liu, Yankai Lin, Zhiyuan Liu, Maosong Sun  
**Category**: cs.AI  
**Published**: 2026-02-09  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.06540v1  

#### Abstract
Generating deep research reports requires large-scale information acquisition and the synthesis of insight-driven analysis, posing a significant challenge for current language models. Most existing approaches follow a plan-then-write paradigm, whose performance heavily depends on the quality of the ...

---

### 22. [Towards Understanding What State Space Models Learn About Code](https://arxiv.org/abs/2602.06774)

**Authors**: Jiali Wu, Abhinav Anand, Shweta Verma, Mira Mezini  
**Category**: cs.AI  
**Published**: 2026-02-09  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.06774v1  

#### Abstract
State Space Models (SSMs) have emerged as an efficient alternative to the transformer architecture. Recent studies show that SSMs can match or surpass Transformers on code understanding tasks, such as code retrieval, when trained under similar conditions. However, their internal mechanisms remain a ...

---

### 23. [LLM Active Alignment: A Nash Equilibrium Perspective](https://arxiv.org/abs/2602.06836)

**Authors**: Tonghan Wang, Yuqi Pan, Xinyi Yang, Yanchen Jiang, Milind Tambe, David C. Parkes  
**Category**: cs.AI  
**Published**: 2026-02-09  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.06836v1  

#### Abstract
We develop a game-theoretic framework for predicting and steering the behavior of populations of large language models (LLMs) through Nash equilibrium (NE) analysis. To avoid the intractability of equilibrium computation in open-ended text spaces, we model each agent's action as a mixture over human...

---

### 24. [An Adaptive Differentially Private Federated Learning Framework with Bi-level Optimization](https://arxiv.org/abs/2602.06838)

**Authors**: Jin Wang, Hui Ma, Fei Xing, Ming Yan  
**Category**: cs.AI  
**Published**: 2026-02-09  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.06838v1  

#### Abstract
Federated learning enables collaborative model training across distributed clients while preserving data privacy. However, in practical deployments, device heterogeneity, non-independent, and identically distributed (Non-IID) data often lead to highly unstable and biased gradient updates. When diffe...

---

### 25. [Online Adaptive Reinforcement Learning with Echo State Networks for Non-Stationary Dynamics](https://arxiv.org/abs/2602.06326)

**Authors**: Aoi Yoshimura, Gouhei Tanaka  
**Category**: cs.LG  
**Published**: 2026-02-09  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2602.06326v1  

#### Abstract
Reinforcement learning (RL) policies trained in simulation often suffer from severe performance degradation when deployed in real-world environments due to non-stationary dynamics. While Domain Randomization (DR) and meta-RL have been proposed to address this issue, they typically rely on extensive ...

---

### 26. [AgentCPM-Explore: Realizing Long-Horizon Deep Exploration for Edge-Scale Agents](https://arxiv.org/abs/2602.06485)

**Authors**: Haotian Chen, Xin Cong, Shengda Fan, Yuyang Fu, Ziqin Gong, Yaxi Lu, Yishan Li, Boye Niu, Chengjun Pan, Zijun Song, Huadong Wang, Yesai Wu, Yueying Wu, Zihao Xie, Yukun Yan, Zhong Zhang, Yankai Lin, Zhiyuan Liu, Maosong Sun  
**Category**: cs.AI  
**Published**: 2026-02-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.06485v1  

#### Abstract
While Large Language Model (LLM)-based agents have shown remarkable potential for solving complex tasks, existing systems remain heavily reliant on large-scale models, leaving the capabilities of edge-scale models largely underexplored. In this paper, we present the first systematic study on trainin...

---

### 27. [Echoes as Anchors: Probabilistic Costs and Attention Refocusing in LLM Reasoning](https://arxiv.org/abs/2602.06600)

**Authors**: Zhuoyuan Hao, Zhuo Li, Wu Li, Fangming Liu, Min Zhang, Jing Li  
**Category**: cs.CL  
**Published**: 2026-02-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.06600v1  

#### Abstract
Test-time compute allocation in large reasoning models (LRMs) is widely used and has applications in mathematical problem solving, code synthesis, and planning. Recent work has addressed this problem by scaling self-consistency and parallel thinking, adding generic ``thinking tokens'' and prompting ...

---

### 28. [Reinforcement Learning-Based Dynamic Management of Structured Parallel Farm Skeletons on Serverless Platforms](https://arxiv.org/abs/2602.06555)

**Authors**: Lanpei Li, Massimo Coppola, Malio Li, Valerio Besozzi, Jack Bell, Vincenzo Lomonaco  
**Category**: cs.DC  
**Published**: 2026-02-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.06555v1  

#### Abstract
We present a framework for dynamic management of structured parallel processing skeletons on serverless platforms. Our goal is to bring HPC-like performance and resilience to serverless and continuum environments while preserving the programmability benefits of skeletons. As a first step, we focus o...

---

### 29. [Rare Event Analysis of Large Language Models](https://arxiv.org/abs/2602.06791)

**Authors**: Jake McAllister Dorman, Edward Gillman, Dominic C. Rose, Jamie F. Mair, Juan P. Garrahan  
**Category**: cs.LG  
**Published**: 2026-02-09  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2602.06791v1  

#### Abstract
Being probabilistic models, during inference large language models (LLMs) display rare events: behaviour that is far from typical but highly significant. By definition all rare events are hard to see, but the enormous scale of LLM usage means that events completely unobserved during development are ...

---

### 30. [A Fast and Generalizable Fourier Neural Operator-Based Surrogate for Melt-Pool Prediction in Laser Processing](https://arxiv.org/abs/2602.06241)

**Authors**: Alix Benoit (EMPA), Toni Ivas (EMPA), Mateusz Papierz (Terra Quantum AG), Asel Sagingalieva (Terra Quantum AG), Alexey Melnikov (Terra Quantum AG), Elia Iseli (EMPA)  
**Category**: cs.LG  
**Published**: 2026-02-09  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2602.06241v1  

#### Abstract
High-fidelity simulations of laser welding capture complex thermo-fluid phenomena, including phase change, free-surface deformation, and keyhole dynamics, however their computational cost limits large-scale process exploration and real-time use. In this work we present the Laser Processing Fourier N...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- kv cache, offload, State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
