# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-05 11:52:30 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [RLHFSpec: Breaking the Efficiency Bottleneck in RLHF Training via Adaptive Drafting](https://arxiv.org/abs/2512.04752)

**Authors**: Siqi Wang, Hailong Yang, Junjie Zhu, Xuezhu Wang, Yufan Xu, Depei Qian  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 15.0  
**Type**: new  
**ArXiv ID**: 2512.04752v1  

#### Abstract
Reinforcement Learning from Human Feedback (RLHF) is an important fine-tuning technique for large language models (LLMs) and comprises three stages: generation, inference, and training. The generation stage generates samples that are then used to infer learnable experiences for training. We observe ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*RLHFSpec: Breaking the Efficiency Bottleneck in RLHF Training via Adaptive Drafting*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
Reinforcement Learning from Human Feedback (RLHF) æ˜¯å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¾®è°ƒçš„å…³é”®æŠ€æœ¯ï¼Œå…¶è®­ç»ƒæµç¨‹åˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼š**generationï¼ˆç”Ÿæˆï¼‰**ã€**inferenceï¼ˆæ¨ç†ï¼‰** å’Œ **trainingï¼ˆè®­ç»ƒï¼‰**ã€‚å…¶ä¸­ï¼Œ**generation é˜¶æ®µæ˜¯æ•´ä¸ªæµç¨‹çš„æ€§èƒ½ç“¶é¢ˆ**ï¼ŒåŸå› å¦‚ä¸‹ï¼š

- **è‡ªå›å½’è§£ç å¯¼è‡´ä½å¹¶è¡Œåº¦**ï¼šæ¯ä¸ª token å¿…é¡»é¡ºåºç”Ÿæˆï¼Œéš¾ä»¥å……åˆ†åˆ©ç”¨ GPU èµ„æºã€‚
- **å“åº”é•¿åº¦é•¿å°¾åˆ†å¸ƒ**ï¼šéƒ¨åˆ†æ ·æœ¬è¾“å‡ºæé•¿ï¼ˆå¦‚ Chain-of-Thought æ¨ç†ï¼‰ï¼Œå¯¼è‡´è´Ÿè½½ä¸å‡è¡¡ï¼ŒGPU åˆ©ç”¨ç‡ä¸‹é™ã€‚
- **é™æ€ç­–ç•¥æ— æ³•é€‚åº”åŠ¨æ€è´Ÿè½½**ï¼šä¼ ç»Ÿ speculative decoding åœ¨çº¿æœåŠ¡ä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨ RLHF è¿™ç±»å›ºå®šæ ·æœ¬æ•°çš„ç¦»çº¿åœºæ™¯ä¸‹ï¼Œå…¶å›ºå®šçš„ drafting ç­–ç•¥ï¼ˆå¦‚å›ºå®š `draft token num`ï¼‰åœ¨ä¸åŒè´Ÿè½½é˜¶æ®µè¡¨ç°æ¬¡ä¼˜ã€‚

å› æ­¤ï¼Œä½œè€…æŒ‡å‡ºï¼š**generation é˜¶æ®µçš„æ•ˆç‡ä½ä¸‹ä¸¥é‡æ‹–ç´¯æ•´ä½“ RLHF è®­ç»ƒé€Ÿåº¦**ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡º **RLHFSpec** â€”â€”é¦–ä¸ªå°† **speculative decoding** æˆåŠŸé›†æˆåˆ° RLHF ç³»ç»Ÿä¸­çš„æ¡†æ¶ï¼Œå¹¶å¼•å…¥ä¸¤é¡¹æ ¸å¿ƒæŠ€æœ¯ï¼š

#### ï¼ˆ1ï¼‰**Workload-aware Drafting Strategy Selectionï¼ˆåŸºäºè´Ÿè½½æ„ŸçŸ¥çš„èµ·è‰ç­–ç•¥é€‰æ‹©ï¼‰**

- **åŠ¨æœº**ï¼šgeneration é˜¶æ®µçš„ workload åŠ¨æ€å˜åŒ–ï¼ˆåˆæœŸæ ·æœ¬å¤šï¼ŒåæœŸåªå‰©å°‘æ•°é•¿å°¾æ ·æœ¬ï¼‰ï¼Œæœ€ä¼˜çš„ `draft token num` åº”éšä¹‹è°ƒæ•´ã€‚
- **æ–¹æ³•**ï¼š
  - è®¾è®¡è½»é‡çº§é¢„æµ‹å™¨ï¼Œå®æ—¶ä¼°è®¡ä¸åŒ `n` ä¸‹çš„ **accepted token æ•°é‡**ï¼ˆ`al(n)`ï¼‰å’Œ **éªŒè¯å¼€é”€**ï¼ˆ`tsa(n)`ï¼‰ã€‚
  - å®šä¹‰ä¼˜åŒ–ç›®æ ‡ï¼šæœ€å¤§åŒ– speculative decoding çš„åŠ é€Ÿæ¯” $ \text{Speedup}(n) = \frac{al(n) \times t_{\text{ar}}}{t_{\text{sa}}(n)} $ã€‚
  - é‡‡ç”¨ **layer-level æœç´¢ + æ—©åœæœºåˆ¶**ï¼ˆåŸºäº sugar water ä¸ç­‰å¼ï¼‰å¿«é€Ÿæ‰¾åˆ°è¿‘ä¼¼æœ€ä¼˜ `n`ã€‚
- **ä¼˜åŠ¿**ï¼šé¿å…äº†æ‰‹åŠ¨è°ƒå‚æˆ–å›ºå®šç­–ç•¥å¸¦æ¥çš„æ€§èƒ½æŸå¤±ï¼Œåœ¨é«˜è´Ÿè½½æ—¶ä¿å®ˆï¼Œåœ¨ä½è´Ÿè½½æ—¶æ¿€è¿›ï¼Œå®ç°åŠ¨æ€å¹³è¡¡ã€‚

#### ï¼ˆ2ï¼‰**Efficient Sample Reallocationï¼ˆé«˜æ•ˆçš„æ ·æœ¬é‡åˆ†é…ï¼‰**

- **åŠ¨æœº**ï¼šç”±äºå“åº”é•¿åº¦å·®å¼‚ï¼ŒæŸäº› generation instance å¤„ç†å¤§é‡é•¿æ ·æœ¬è€ŒæŒç»­é«˜è´Ÿè½½ï¼Œå…¶ä»– instance å´æ—©æ—©ç©ºé—²ï¼Œé€ æˆèµ„æºæµªè´¹ã€‚
- **æ–¹æ³•**ï¼š
  - å¼•å…¥ **greedy reallocation policy**ï¼šè¯†åˆ«â€œé˜ˆå€¼â€ï¼ˆthroughput è½¬æŠ˜ç‚¹ï¼‰ï¼Œå°†è¶…è½½å®ä¾‹çš„æ ·æœ¬è¿ç§»åˆ°æœªè¾¾é˜ˆå€¼çš„å®ä¾‹ã€‚
  - æå‡º **two-stage sample migration æœºåˆ¶**ï¼š
    1. **Stage 1**ï¼šåˆ©ç”¨ LLM éªŒè¯çš„ Markov ç‰¹æ€§ï¼Œè¾¹è®¡ç®—è¾¹è¿ç§»å·²éªŒè¯çš„ KVCacheã€‚
    2. **Stage 2**ï¼šåˆ©ç”¨ SSM ä¸ LLM KVCache çš„ç‹¬ç«‹æ€§ï¼Œå…ˆæ¢å¤ SSM çŠ¶æ€ä»¥ç»§ç»­ draftï¼Œå†å¼‚æ­¥ä¼ è¾“ LLM KVCacheã€‚
  - ç»“åˆ **åˆ†å±‚ KVCache è¡¨ç¤ºä¸æ‰¹é‡æ‹·è´**ï¼Œå‡å°‘é€šä¿¡å¼€é”€ã€‚
- **ä¼˜åŠ¿**ï¼šæ˜¾è‘—æå‡ç³»ç»Ÿæ•´ä½“ååé‡ï¼Œä¸”è¿ç§»å¼€é”€æ¥è¿‘é›¶ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| å¯¹æ¯”ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆVerl/OpenRLHFï¼‰ | Speculative Decodingï¼ˆç›´æ¥åº”ç”¨ï¼‰ | **RLHFSpecï¼ˆæœ¬æ–‡ï¼‰** |
|--------|--------------------------|-------------------------------|--------------------|
| è§£ç æ–¹å¼ | Autoregressive decoding | å›ºå®šç­–ç•¥ speculative decoding | **è‡ªé€‚åº” speculative decoding** |
| è´Ÿè½½æ„ŸçŸ¥ | âŒ | âŒï¼ˆé™æ€ç­–ç•¥ï¼‰ | âœ…ï¼ˆåŠ¨æ€é€‰æ‹© `n`ï¼‰ |
| æ ·æœ¬è°ƒåº¦ | é™æ€åˆ†é… | é™æ€åˆ†é… | âœ…ï¼ˆåŠ¨æ€é‡åˆ†é… + é«˜æ•ˆè¿ç§»ï¼‰ |
| GPU åˆ©ç”¨ç‡ | ä½ï¼ˆå°¤å…¶åæœŸï¼‰ | ä¸­ç­‰ | **é«˜ä¸”ç¨³å®š** |
| æ•´ä½“åŠ é€Ÿæ•ˆæœ | åŸºçº¿ | æœ‰é™æå‡ | **æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿** |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†

- **LMSYS-Chat-1M**ï¼šåŒ…å« 100 ä¸‡çœŸå®ä¸–ç•Œå¯¹è¯ï¼Œæ¶µç›– 25 ç§ä¸»æµ LLMï¼Œå…·æœ‰å…¸å‹çš„é•¿å°¾è¾“å‡ºç‰¹æ€§ã€‚
- **GSM8K**ï¼šå°å­¦æ•°å­¦é¢˜æ•°æ®é›†ï¼Œå¸¸ç”¨äºæµ‹è¯•æ¨ç†èƒ½åŠ›ï¼Œä¹Ÿè¡¨ç°å‡ºè¾ƒé•¿å“åº”è¶‹åŠ¿ã€‚

### âš™ï¸ å®éªŒè®¾ç½®

- **ç¡¬ä»¶ç¯å¢ƒ**ï¼š
  - 8Ã— NVIDIA L40S GPUsï¼ˆPCIe è¿æ¥ï¼‰
  - Intel Xeon Gold 6448Y CPU
  - CUDA 12.6, cuDNN v9.1.0
- **æ¨¡å‹é…ç½®**ï¼š
  - ä¸»æ¨¡å‹ï¼š**Llama-3.1-8B-Instruct**
  - Draft Modelï¼š**Eagle**ï¼ˆåŸºäº Llama è’¸é¦çš„å°æ¨¡å‹ï¼‰
- **å®ç°å¹³å°**ï¼šåŸºäº **Verl** æ¡†æ¶æ‰©å±•å®ç° RLHFSpecã€‚

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡

- **ä¸»è¦æŒ‡æ ‡**ï¼š
  - **Sample Throughput (samples/s)**ï¼šå•ä½æ—¶é—´å†…å®Œæˆçš„æ ·æœ¬æ•°ã€‚
  - **Token Throughput (tokens/s)**ï¼šå•ä½æ—¶é—´å†…å¤„ç†çš„ token æ•°ã€‚
- **å¯¹æ¯”æ–¹å¼**ï¼š
  - æŠ¥å‘Šç›¸å¯¹äºåŸºçº¿çš„ **speedup å€æ•°**ã€‚
  - åˆ†æ generation é˜¶æ®µä¸ end-to-end RLHF æµç¨‹çš„æ•´ä½“æ€§èƒ½ã€‚

### ğŸ†š åŸºçº¿æ–¹æ³•

| åŸºçº¿ | æè¿° |
|------|------|
| **OpenRLHF** | æ”¯æŒå¤šè®¾å¤‡éƒ¨ç½²ä¸å®šåˆ¶åŒ–å¹¶è¡Œç­–ç•¥çš„å¼€æº RLHF æ¡†æ¶ |
| **Verl** | å±‚æ¬¡åŒ–æ··åˆç¼–ç¨‹æ¨¡å‹ï¼Œæ”¯æŒçµæ´»æ•°æ®æµæ§åˆ¶ |
| **Speculative** | åœ¨ Verl åŸºç¡€ä¸ŠåŠ å…¥ä¼ ç»Ÿ speculative decodingï¼ˆå›ºå®š `n`ï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

#### ï¼ˆ1ï¼‰Generation é˜¶æ®µååé‡ï¼ˆå›¾ 11ï¼‰

| æ–¹æ³• | LMSYS åŠ é€Ÿæ¯” | GSM8K åŠ é€Ÿæ¯” |
|------|--------------|-------------|
| vs. OpenRLHF | **2.52Ã—** | **2.65Ã—** |
| vs. Verl | **2.16Ã—** | **2.32Ã—** |
| vs. Speculative | **2.02Ã—** | **1.97Ã—** |

> âœ… **RLHFSpec åœ¨ generation é˜¶æ®µå®ç°äº†æœ€é«˜è¾¾ 2.65Ã— çš„ååæå‡**ã€‚

#### ï¼ˆ2ï¼‰ç«¯åˆ°ç«¯ RLHF æ‰§è¡Œæ€§èƒ½ï¼ˆå›¾ 12ï¼‰

| æ–¹æ³• | LMSYS åŠ é€Ÿæ¯” | GSM8K åŠ é€Ÿæ¯” |
|------|--------------|-------------|
| vs. OpenRLHF | **3.01Ã—** | **2.97Ã—** |
| vs. Verl | **1.50Ã—** | **1.43Ã—** |
| vs. Speculative | **1.37Ã—** | **1.35Ã—** |

> âœ… **ç¼“è§£ generation ç“¶é¢ˆåï¼Œæ•´ä½“ RLHF è®­ç»ƒæ—¶é—´å¤§å¹…ç¼©çŸ­ï¼Œæœ€é«˜æé€Ÿè¶…è¿‡ 3Ã—**ã€‚

---

### ğŸ”¬ æ¶ˆèå®éªŒç»“æœï¼ˆå›¾ 13ï¼‰

å¯¹ RLHFSpec å„ç»„ä»¶è¿›è¡Œé€æ­¥å åŠ æµ‹è¯•ï¼ˆå½’ä¸€åŒ–äº autoregressive baselineï¼‰ï¼š

| ç»„ä»¶ç»„åˆ | å½’ä¸€åŒ–æ€§èƒ½ |
|--------|------------|
| Baseline (Default) | 1.00Ã— |
| + Speculative Decoding (Spec) | **1.18Ã—** |
| + Workload-aware Selection | **1.95Ã—** |
| + Sample Reallocation | **2.32Ã—** |

> ğŸ’¡ **ç»“è®º**ï¼š
> - å•çº¯ speculative decoding æå‡æœ‰é™ï¼ˆä»… 1.18Ã—ï¼‰ï¼›
> - è‡ªé€‚åº” drafting ç­–ç•¥å¸¦æ¥æœ€å¤§å¢ç›Šï¼ˆä» 1.18â†’1.95ï¼‰ï¼›
> - æ ·æœ¬é‡åˆ†é…è¿›ä¸€æ­¥é‡Šæ”¾æ½œåŠ›ï¼ˆ1.95â†’2.32ï¼‰ã€‚

---

### ğŸ¯ Workload-aware Strategy æœ‰æ•ˆæ€§ï¼ˆè¡¨ 1ï¼‰

åœ¨å¤šç§ workloadï¼ˆæ ·æœ¬æ•°é‡ï¼‰ä¸‹ï¼ŒRLHFSpec æ‰€é€‰ç­–ç•¥çš„æ€§èƒ½å â€œç†è®ºæœ€ä¼˜â€çš„ç™¾åˆ†æ¯”ï¼š

| Workload | LMSYS (%) | GSM8K (%) |
|---------|-----------|----------|
| 8â€“64 æ ·æœ¬ | 96.57 ~ 99.70 | 95.53 ~ 99.90 |

> âœ… **å¹³å‡è¾¾åˆ°æœ€ä¼˜æ€§èƒ½çš„ 97% ä»¥ä¸Šï¼Œæœ€å·®æƒ…å†µä»è¾¾ 95.53%**ï¼Œè¯æ˜ç­–ç•¥é€‰æ‹©é«˜åº¦å‡†ç¡®ã€‚

---

### ğŸ”„ Sample Reallocation å®é™…æ•ˆæœï¼ˆå›¾ 14ï¼‰

- åœ¨æŸä¸€æ—¶åˆ»è§¦å‘è¿ç§»ï¼šå°† 5 ä¸ªæ ·æœ¬ä» instance 1 è¿ç§»åˆ° instance 2ã€‚
- **è¿ç§»å‰æ€»åå**ï¼š2,127 tokens/s
- **è¿ç§»åæ€»åå**ï¼š**2,531 tokens/s**ï¼ˆâ†‘18.9%ï¼‰
- ä¸”è¿ç§»è¿‡ç¨‹å‡ ä¹æ— ä¸­æ–­ï¼ˆnear-zero overheadï¼‰

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **Generation é˜¶æ®µç¡®å®æ˜¯ RLHF çš„ä¸»è¦ç“¶é¢ˆ**ï¼Œå æ¯”è¶… 68.4% çš„æ€»æ‰§è¡Œæ—¶é—´ã€‚
2. **ç›´æ¥å¥—ç”¨ online speculative decoding åˆ° RLHF æ•ˆæœæœ‰é™**ï¼Œå› å…¶å¿½ç•¥ workload åŠ¨æ€æ€§å’Œä¼˜åŒ–ç›®æ ‡å·®å¼‚ï¼ˆthroughput > latencyï¼‰ã€‚
3. **workload-aware drafting ç­–ç•¥èƒ½æ˜¾è‘—æå‡ speculative decoding æ•ˆç‡**ï¼Œé€šè¿‡åŠ¨æ€æƒè¡¡ verification cost ä¸ accepted tokensã€‚
4. **æ ·æœ¬é‡åˆ†é…å¯æœ‰æ•ˆç¼“è§£é•¿å°¾æ•ˆåº”å¼•èµ·çš„è´Ÿè½½å¤±è¡¡**ï¼Œç»“åˆé«˜æ•ˆè¿ç§»æœºåˆ¶ï¼Œå‡ ä¹æ— é¢å¤–å¼€é”€ã€‚
5. **RLHFSpec å®ç°äº† generation é˜¶æ®µæœ€é«˜ 2.65Ã—ã€end-to-end æœ€é«˜ 3.01Ã— çš„æ€§èƒ½åŠ é€Ÿ**ï¼Œæ˜¾è‘—ä¼˜äºå½“å‰ SOTAã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

1. **ä¾èµ–é«˜è´¨é‡çš„ draft model**ï¼šè‹¥ SSM ä¸ LLM å·®å¼‚è¿‡å¤§ï¼Œacceptance rate ä¸‹é™ï¼Œspeculative decoding æ•ˆæœå‡å¼±ã€‚
2. **KVCache è¿ç§»ä»éœ€å†…å­˜é¢„ç•™æœºåˆ¶**ï¼šå¯èƒ½å› ç›®æ ‡è®¾å¤‡å†…å­˜ä¸è¶³å¯¼è‡´è¿ç§»å¤±è´¥ã€‚
3. **ç›®å‰ä»…é€‚ç”¨äºå•èŠ‚ç‚¹å¤š GPU åœºæ™¯**ï¼šè·¨èŠ‚ç‚¹è¿ç§»å°šæœªè€ƒè™‘ç½‘ç»œå¸¦å®½é™åˆ¶ã€‚
4. **offline profiling å¼€é”€è™½å°ä½†å­˜åœ¨**ï¼šéœ€é¢„å…ˆæ”¶é›†æ•°æ®è®­ç»ƒé¢„æµ‹æ¨¡å‹å’Œç¡®å®š thresholdã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **æ”¯æŒè·¨èŠ‚ç‚¹ sample migration**ï¼Œæ‰©å±•è‡³åˆ†å¸ƒå¼è®­ç»ƒåœºæ™¯ã€‚
2. **åŠ¨æ€è®­ç»ƒ draft model**ï¼Œä½¿å…¶æ›´é€‚é…å½“å‰ä»»åŠ¡åˆ†å¸ƒã€‚
3. **ç»“åˆ compression æˆ– quantization æŠ€æœ¯é™ä½ KVCache ä¼ è¾“æˆæœ¬**ã€‚
4. **æ¢ç´¢æ›´å¤š speculative structureï¼ˆå¦‚ DAGï¼‰ä»¥è¿›ä¸€æ­¥æé«˜ acceptance rate**ã€‚
5. **å°† RLHFSpec æ€è·¯æ¨å¹¿è‡³å…¶ä»–åŸºäº autoregressive ç”Ÿæˆçš„å¼ºåŒ–å­¦ä¹ ä»»åŠ¡**ã€‚

---

## æ€»ç»“

> **RLHFSpec é€šè¿‡â€œè‡ªé€‚åº”èµ·è‰ + æ™ºèƒ½é‡åˆ†é…â€åŒè½®é©±åŠ¨ï¼Œé¦–æ¬¡æˆåŠŸå°† speculative decoding é«˜æ•ˆåº”ç”¨äº RLHF è®­ç»ƒï¼Œæ‰“ç ´äº† generation é˜¶æ®µçš„æ•ˆç‡ç“¶é¢ˆï¼Œåœ¨çœŸå®æ•°æ®é›†ä¸Šå®ç°äº†é«˜è¾¾ 3Ã— çš„ç«¯åˆ°ç«¯åŠ é€Ÿï¼Œä¸ºå¤§è§„æ¨¡ LLM å¾®è°ƒæä¾›äº†æ–°çš„é«˜æ€§èƒ½è§£å†³æ–¹æ¡ˆã€‚**

</details>

---

### 2. [Arbitrage: Efficient Reasoning via Advantage-Aware Speculation](https://arxiv.org/abs/2512.05033)

**Authors**: Monishwaran Maheswaran, Rishabh Tiwari, Yuezhou Hu, Kerem Dilmen, Coleman Hooper, Haocheng Xi, Nicholas Lee, Mehrdad Farajtabar, Michael W. Mahoney, Kurt Keutzer, Amir Gholami  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2512.05033v1  

#### Abstract
Modern Large Language Models achieve impressive reasoning capabilities with long Chain of Thoughts, but they incur substantial computational cost during inference, and this motivates techniques to improve the performance-cost ratio. Among these techniques, Speculative Decoding accelerates inference ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šARBITRAGE: Efficient Reasoning via Advantage-Aware Speculation**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
ç°ä»£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ•°å­¦æ¨ç†ç­‰å¤æ‚ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶æ¨ç†è¿‡ç¨‹ä¾èµ–é•¿é“¾å¼æ€ç»´ï¼ˆChain-of-Thought, CoTï¼‰ï¼Œå¯¼è‡´è‡ªå›å½’è§£ç æ­¥éª¤æå¤šï¼Œæ¨ç†å»¶è¿Ÿé«˜ã€è®¡ç®—æˆæœ¬å¤§ã€‚ä¼ ç»Ÿçš„ **Speculative Decoding (SD)** æ–¹æ³•é€šè¿‡å°æ¨¡å‹ï¼ˆdraft modelï¼‰ç”Ÿæˆå€™é€‰ token å¹¶ç”±å¤§æ¨¡å‹ï¼ˆtarget modelï¼‰å¹¶è¡ŒéªŒè¯æ¥åŠ é€Ÿæ¨ç†ï¼Œä½†åœ¨**è¯­ä¹‰ç­‰ä»·ä½† token ä¸åŒ¹é…**çš„æ¨ç†ä»»åŠ¡ä¸­ï¼Œtoken-level çš„ SD æ¥å—ç‡ä½ï¼Œæ•ˆç‡å·®ã€‚

è¿‘æœŸæå‡ºçš„ **step-level SD**ï¼ˆå¦‚ RSDï¼‰è™½èƒ½åŸºäºæ•´ä¸ªæ¨ç†æ­¥éª¤è¿›è¡Œè¯„åˆ†å’Œæ¥å—å†³ç­–ï¼Œä½†ä»å­˜åœ¨ä¸¥é‡é—®é¢˜ï¼š  
- ä½¿ç”¨**ç»å¯¹è´¨é‡é˜ˆå€¼**ï¼ˆå¦‚ PRM åˆ†æ•°æ˜¯å¦é«˜äºæŸå€¼ï¼‰å†³å®šæ˜¯å¦æ‹’ç» draft æ­¥éª¤ï¼›
- å¯¼è‡´å¤§é‡â€œæ— æ„ä¹‰é‡ç”Ÿæˆâ€â€”â€”å³ target model é‡æ–°ç”Ÿæˆçš„æ­¥éª¤è´¨é‡å¹¶æœªæ˜¾è‘—ä¼˜äº draftï¼Œå´ä»æ¶ˆè€—æ˜‚è´µè®¡ç®—èµ„æºã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯**
æœ¬æ–‡æå‡º **ARBITRAGE**ï¼Œä¸€ç§åŸºäº**ä¼˜åŠ¿æ„ŸçŸ¥ï¼ˆadvantage-awareï¼‰** çš„ step-level speculative generation æ¡†æ¶ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> **ä¸åº”ä»…çœ‹ draft æ­¥éª¤æ˜¯å¦â€œè¶³å¤Ÿå¥½â€ï¼Œè€Œåº”åˆ¤æ–­ target æ˜¯å¦â€œæ˜æ˜¾æ›´å¥½â€ã€‚**

#### **æ ¸å¿ƒç»„ä»¶**
1. **ARBITRAGE ORACLEï¼ˆç†æƒ³è·¯ç”±ç­–ç•¥ï¼‰**  
   - åœ¨æ¯ä¸€æ­¥åŒæ—¶è¿è¡Œ draft å’Œ target æ¨¡å‹ï¼Œæ¯”è¾ƒä¸¤è€…çš„ PRM åˆ†æ•°ï¼Œé€‰æ‹©å¾—åˆ†æ›´é«˜çš„æ­¥éª¤ã€‚
   - å®šä¹‰ **step-level advantage**: $ \Delta = s_t - s_d $ï¼Œè¡¨ç¤º target ç›¸å¯¹äº draft çš„è´¨é‡å¢ç›Šã€‚
   - è‹¥ $ \Delta > 0 $ï¼Œåˆ™åº”è°ƒç”¨ targetï¼›å¦åˆ™ä¿ç•™ draftã€‚
   - è¯¥ç­–ç•¥ç†è®ºä¸Šè¾¾åˆ°**å±€éƒ¨æœ€ä¼˜**ï¼Œæ„æˆæ€§èƒ½ä¸Šç•Œã€‚

2. **ARBITRAGE ROUTERï¼ˆå®ç”¨è·¯ç”±æ¨¡å‹ï¼‰**  
   - ä¸€ä¸ªè½»é‡çº§å¯è®­ç»ƒæ¨¡å‹ï¼Œè¾“å…¥ä¸ºå½“å‰ä¸Šä¸‹æ–‡å’Œ draft ç”Ÿæˆçš„æ­¥éª¤ $(x, z_d)$ï¼Œè¾“å‡ºä¸€ä¸ªåˆ†æ•° $ y \in [0,1] $ï¼Œé¢„æµ‹ target æ˜¯å¦ä¼šæ˜¾è‘—ä¼˜äº draftã€‚
   - å†³ç­–è§„åˆ™ï¼šè‹¥ $ y \leq t $ï¼ˆé¢„æµ‹ä¼˜åŠ¿å°ï¼‰ï¼Œæ¥å— draftï¼›å¦åˆ™è°ƒç”¨ targetã€‚
   - è·¯ç”±å™¨åœ¨ç¦»çº¿é˜¶æ®µä½¿ç”¨ ARBITRAGE ORACLE çš„æ ‡ç­¾è¿›è¡Œç›‘ç£è®­ç»ƒï¼Œé¿å…åœ¨çº¿è°ƒç”¨ targetã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç‰¹æ€§ | RSDï¼ˆBaselineï¼‰ | ARBITRAGEï¼ˆOursï¼‰ |
|------|------------------|--------------------|
| å†³ç­–ä¾æ® | draft çš„ç»å¯¹ PRM åˆ†æ•° | target ç›¸å¯¹äº draft çš„é¢„æœŸä¼˜åŠ¿ |
| æ˜¯å¦è€ƒè™‘ target è¡¨ç° | å¦ï¼ˆadvantage-blindï¼‰ | æ˜¯ï¼ˆadvantage-awareï¼‰ |
| å†—ä½™è®¡ç®— | é«˜ï¼ˆå¸¸å› ç»å¯¹é˜ˆå€¼è¯¯åˆ¤ï¼‰ | æ˜¾è‘—é™ä½ |
| æ•ˆç‡-å‡†ç¡®æ€§æƒè¡¡ | æ¬¡ä¼˜ | æ¥è¿‘ç†è®ºæœ€ä¼˜ï¼ˆORACLEï¼‰ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **MATH500**ï¼šæ ‡å‡†æ•°å­¦æ¨ç†åŸºå‡†ï¼ŒåŒ…å« 500 é“é«˜ä¸­è‡³ç«èµ›çº§åˆ«é¢˜ç›®ã€‚
- **OlympiadBench**ï¼šæ›´å…·æŒ‘æˆ˜æ€§çš„åŒè¯­å¤šæ¨¡æ€ç§‘å­¦å¥¥èµ›é¢˜åŸºå‡†ï¼Œéš¾åº¦æ›´é«˜ã€‚

### **å®éªŒè®¾ç½®**
- **æ¨¡å‹é…ç½®**ï¼š
  - **LLaMA3 ç³»åˆ—**ï¼š`1B/8B`, `8B/70B`, `4bit-8B/8B`ï¼ˆé‡åŒ– draftï¼‰
  - **Qwen2.5-Math ç³»åˆ—**ï¼š`3bit-7B/7B`ï¼ˆé‡åŒ– draftï¼‰
- **Process Reward Model (PRM)**ï¼šä½¿ç”¨ `Skywork-o1-Open-PRM (1.5B)` å¯¹æ¯ä¸ªæ¨ç†æ­¥éª¤æ‰“åˆ†ã€‚
- **ARBITRAGE ROUTER**ï¼šåŸºäº PRM å¾®è°ƒå¾—åˆ°ï¼Œç”¨äºé¢„æµ‹ $ \Delta > 0 $ çš„æ¦‚ç‡ã€‚
- **ç¡¬ä»¶å¹³å°**ï¼šNVIDIA A6000 GPUï¼Œä½¿ç”¨ SGLang ä½œä¸ºæ¨ç†åç«¯ï¼Œbatch size = 1ã€‚

### **è¯„ä¼°æŒ‡æ ‡**
1. **Accuracy vs. Acceptance Rate æ›²çº¿**  
   - æ§åˆ¶ä¸åŒæ¥å—ç‡ä¸‹çš„æœ€ç»ˆç­”æ¡ˆå‡†ç¡®ç‡ï¼Œè¡¡é‡ compute-quality trade-offã€‚
2. **End-to-End Latency vs. Accuracy æ›²çº¿ï¼ˆPareto Frontiersï¼‰**  
   - å®é™…ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆwall-clock timeï¼‰ä¸å‡†ç¡®ç‡çš„å…³ç³»ï¼Œåæ˜ çœŸå®åŠ é€Ÿæ•ˆæœã€‚
3. **Spearman Rank Correlation ($\rho$)**  
   - è¡¡é‡ ROUTER é¢„æµ‹çš„â€œä¼˜åŠ¿æ’åºâ€ä¸çœŸå® ORACLE æ’åºçš„ä¸€è‡´æ€§ï¼Œä½œä¸ºè®­ç»ƒè´¨é‡ä»£ç†æŒ‡æ ‡ã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **RSD (Reward-guided Speculative Decoding)**ï¼šå½“å‰ä¸»æµ step-level SD æ–¹æ³•ï¼ŒåŸºäºå›ºå®š PRM é˜ˆå€¼å†³å®šæ˜¯å¦æ‹’ç» draftã€‚
- **Draft-only / Target-only**ï¼šä½œä¸ºæ€§èƒ½è¾¹ç•Œå‚è€ƒã€‚
- **ARBITRAGE ORACLE**ï¼šä½œä¸ºç†è®ºæ€§èƒ½ä¸Šé™ã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
#### âœ… **Accuracy vs. Acceptance Rate**
- åœ¨æ‰€æœ‰æ¨¡å‹é…ç½®å’Œæ•°æ®é›†ä¸Šï¼Œ**ARBITRAGE ROUTER çš„æ›²çº¿å§‹ç»ˆé«˜äº RSD**ï¼Œè¡¨æ˜åœ¨ç›¸åŒè®¡ç®—é¢„ç®—ä¸‹è·å¾—æ›´é«˜å‡†ç¡®ç‡ã€‚
- å°¤å…¶åœ¨ draft æ¨¡å‹è¾ƒå¼±æ—¶ï¼ˆå¦‚ LLaMA3 1B/8Bï¼‰ï¼Œæå‡æœ€æ˜¾è‘—ï¼š
  - RSD å‡ ä¹è´´è¿‘ draft-only æ€§èƒ½ï¼›
  - ARBITRAGE å¿«é€Ÿé€¼è¿‘ target-only æ€§èƒ½ã€‚

#### âœ… **Latency-Speedup ç»“æœï¼ˆå›¾5ï¼‰**
- **MATH500ï¼ˆé‡åŒ– draftï¼‰**ï¼šæœ€é«˜å®ç° **1.62Ã— æ›´ä½å»¶è¿Ÿ**ï¼ˆç›¸åŒå‡†ç¡®ç‡ï¼‰ã€‚
- **OlympiadBenchï¼ˆå° draftï¼‰**ï¼šæœ€é«˜å®ç° **1.97Ã— åŠ é€Ÿ**ã€‚
- ç»¼åˆå¤šä¸ªåœºæ™¯ï¼Œ**å¹³å‡ç«¯åˆ°ç«¯å»¶è¿Ÿé™ä½çº¦ 2Ã—**ã€‚

#### âœ… **ä¸ ORACLE çš„æ¥è¿‘ç¨‹åº¦**
- ARBITRAGE ROUTER çš„æ€§èƒ½æ›²çº¿**ç´§å¯†è·Ÿéš ARBITRAGE ORACLE**ï¼Œè¯´æ˜å…¶èƒ½æœ‰æ•ˆæ¨¡æ‹Ÿç†æƒ³è·¯ç”±ç­–ç•¥ã€‚
- è€Œ RSD å­˜åœ¨æ˜æ˜¾å·®è·ï¼Œå°¤å…¶åœ¨ä¸­ç­‰å»¶è¿ŸåŒºåŸŸè¡¨ç°ä¸ä½³ï¼ˆè¿‡åº¦è°ƒç”¨ targetï¼‰ã€‚

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰**

| è®¾è®¡é€‰æ‹© | å½±å“ | æœ€ä½³æ–¹æ¡ˆ |
|--------|------|---------|
| **Label Granularity**ï¼ˆåˆ†ç±»ç²’åº¦ï¼‰ | å¤šåˆ†ç±»ï¼ˆ4/10ç±»ï¼‰å¯¼è‡´æ€§èƒ½ä¸‹é™ | **äºŒåˆ†ç±»ï¼ˆaccept vs. escalateï¼‰æœ€ä½³** |
| **Classification vs. Regression** | å›å½’æ¨¡å‹è¡¨ç°æ›´å·® | **åˆ†ç±»æ¶æ„æ›´é²æ£’æ˜“éƒ¨ç½²** |
| **Step Annotation**ï¼ˆå†å²æ ‡è®°ï¼‰ | æ·»åŠ  `Model 0/1` æ ‡è®°æå‡ label-1 å‡†ç¡®ç‡ | **å¯ç”¨æ ‡æ³¨æ˜¾è‘—æ”¹å–„æ€§èƒ½** |
| **Data Downsampling** | ä¸å¹³è¡¡æ•°æ®å¯¼è‡´è¿‡æ‹Ÿåˆ y=0 | **å¹³è¡¡é‡‡æ ·æå‡ Spearman ç›¸å…³æ€§ä¸ label-1 å‡†ç¡®ç‡** |

> æ‰€æœ‰æ¶ˆèå‡ä»¥ **Spearman correlation** å’Œ **label accuracy** ä¸ºè¯„ä»·æŒ‡æ ‡ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **ç°æœ‰ step-level SD å­˜åœ¨ä¸¥é‡è®¡ç®—æµªè´¹**  
   - RSD ä¸­é«˜è¾¾ **40% çš„ target è°ƒç”¨æœªå¸¦æ¥è´¨é‡æå‡**ï¼ˆè§å›¾2ï¼‰ï¼Œæºäºå…¶â€œç»å¯¹é˜ˆå€¼â€æœºåˆ¶æ— æ³•è¯†åˆ« target æ˜¯å¦çœŸèƒ½æ”¹è¿›ã€‚
   
2. **ç›¸å¯¹ä¼˜åŠ¿ï¼ˆadvantageï¼‰æ˜¯æ›´åˆç†çš„è·¯ç”±ä¿¡å·**  
   - ARBITRAGE é€šè¿‡ä¼°è®¡ $ \mathbb{E}[\Delta] $ å®ç°â€œæ™ºèƒ½è°ƒç”¨â€ï¼Œåªåœ¨ target çœŸæ­£å¯èƒ½èƒœå‡ºæ—¶æ‰æ¿€æ´»ï¼Œå¤§å¹…å‡å°‘å†—ä½™è®¡ç®—ã€‚

3. **è½»é‡çº§ ROUTER å¯æœ‰æ•ˆé€¼è¿‘ ORACLE**  
   - å³ä½¿ä¸è¿è¡Œ target æ¨¡å‹ï¼ŒROUTER ä¹Ÿèƒ½å­¦ä¹ åˆ°ä½•æ—¶ target æ›´å¼ºï¼Œå®ç°æ¥è¿‘ç†è®ºæœ€ä¼˜çš„æ•ˆç‡-ç²¾åº¦æƒè¡¡ã€‚

4. **æ–¹æ³•å…·æœ‰å¹¿æ³›é€‚ç”¨æ€§**  
   - åœ¨ä¸åŒæ¨¡å‹å®¶æ—ï¼ˆLLaMA/Qwenï¼‰ã€ä¸åŒ draft-target æ¶æ„ï¼ˆåŒæ—å°æ¨¡å‹ / è‡ªèº«é‡åŒ–ç‰ˆï¼‰ä¸‹å‡ç¨³å®šæå‡æ€§èƒ½ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–é«˜è´¨é‡ PRM**ï¼šè‹¥ PRM æœ¬èº«å¯¹æ¨ç†æ­¥éª¤è¯„åˆ†ä¸å‡†ï¼Œåˆ™ ORACLE å’Œ ROUTER è®­ç»ƒéƒ½ä¼šå—å½±å“ã€‚
- **ROUTER å¼•å…¥é¢å¤–å¼€é”€**ï¼šæ¯æ­¥éœ€ä¸€æ¬¡å‰å‘ä¼ æ’­ï¼Œè™½è½»é‡ä½†ä»å¢åŠ å°‘é‡å»¶è¿Ÿã€‚
- **å‡è®¾ step ç‹¬ç«‹æ€§**ï¼šå½“å‰æ¡†æ¶å‡è®¾å„æ­¥ä¼˜åŠ¿ç‹¬ç«‹ï¼Œæœªå»ºæ¨¡é•¿æœŸä¾èµ–ï¼ˆå¦‚æ—©æœŸé”™è¯¯å½±å“åç»­ä¼˜åŠ¿åˆ¤æ–­ï¼‰ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ¢ç´¢æ›´é«˜æ•ˆçš„ ROUTER æ¶æ„ï¼ˆå¦‚å…±äº« backboneï¼‰è¿›ä¸€æ­¥å‹ç¼© overheadã€‚
- å°† advantage-aware æ€æƒ³æ‰©å±•è‡³å…¶ä»–ç”Ÿæˆä»»åŠ¡ï¼ˆå¦‚ä»£ç ç”Ÿæˆã€è§„åˆ’ï¼‰ã€‚
- å¼•å…¥åŠ¨æ€ threshold $ t $ï¼Œæ ¹æ®é—®é¢˜éš¾åº¦è‡ªé€‚åº”è°ƒæ•´ compute allocationã€‚
- ç»“åˆå¼ºåŒ–å­¦ä¹ ä¼˜åŒ– end-to-end routing policyï¼Œè¶…è¶Š greedy per-step å†³ç­–ã€‚

---

> **æ€»ç»“**ï¼šARBITRAGE é€šè¿‡å¼•å…¥â€œä¼˜åŠ¿æ„ŸçŸ¥â€çš„è·¯ç”±æœºåˆ¶ï¼Œä»æ ¹æœ¬ä¸Šè§£å†³äº†ä¼ ç»Ÿ speculative decoding åœ¨æ¨ç†ä»»åŠ¡ä¸­çš„**æ— æ•ˆé‡ç”Ÿæˆ**é—®é¢˜ï¼Œå®ç°äº†**é«˜è¾¾ ~2Ã— çš„æ¨ç†åŠ é€Ÿ**ï¼ŒåŒæ—¶ä¿æŒç”šè‡³æå‡è¾“å‡ºè´¨é‡ï¼Œä¸ºé«˜æ•ˆ LLM æ¨ç†æä¾›äº†æ–°çš„èŒƒå¼ã€‚

</details>

---

### 3. [SignRoundV2: Closing the Performance Gap in Extremely Low-Bit Post-Training Quantization for LLMs](https://arxiv.org/abs/2512.04746)

**Authors**: Wenhua Cheng, Weiwei Zhang, Heng Guo, Haihao Shen  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.04746v1  

#### Abstract
Extreme low-bit quantization is critical for efficiently deploying Large Language Models (LLMs), yet it often leads to severe performance degradation at 2-bits and even 4-bits (e.g., MXFP4). We present SignRoundV2, a post-training quantization framework that is highly effective even without mixed-pr...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šSignRoundV2: Closing the Performance Gap in Extremely Low-Bit Post-Training Quantization for LLMs**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
æç«¯ä½æ¯”ç‰¹ï¼ˆå¦‚ 2-bit æˆ– 4-bitï¼‰çš„ **Post-Training Quantization (PTQ)** åœ¨å‹ç¼©å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ—¶é€šå¸¸ä¼šå¯¼è‡´ä¸¥é‡çš„æ€§èƒ½ä¸‹é™ã€‚å°½ç®¡å·²æœ‰æ–¹æ³•å°è¯•é€šè¿‡æ··åˆç²¾åº¦ï¼ˆmixed-precisionï¼‰æˆ–é‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQATï¼‰ç¼“è§£æ­¤é—®é¢˜ï¼Œä½†è¿™äº›æ–¹æ³•å¾€å¾€å­˜åœ¨ä»¥ä¸‹ç¼ºé™·ï¼š
- **è®¡ç®—æˆæœ¬é«˜**ï¼ˆå°¤å…¶æ˜¯ QATï¼‰
- **ç¼ºä¹é«˜æ•ˆçš„æ•æ„Ÿåº¦åº¦é‡æœºåˆ¶**
- **é‡åŒ–å‚æ•°åˆå§‹åŒ–ä¸ç¨³å®š**
- **éš¾ä»¥åœ¨æä½æ¯”ç‰¹ä¸‹ä¿æŒæ¥è¿‘å…¨ç²¾åº¦æ¨¡å‹çš„æ€§èƒ½**

### **æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯**
ä½œè€…æå‡ºäº† **SignRoundV2**ï¼Œä¸€ç§é«˜æ•ˆã€æ— éœ€å†è®­ç»ƒçš„ PTQ æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### **(1) DeltaLoss æ•æ„Ÿåº¦åº¦é‡ï¼ˆSensitivity Metricï¼‰**
- ç»“åˆ **æ¢¯åº¦ä¿¡æ¯ï¼ˆgradientï¼‰** å’Œ **é‡åŒ–å¼•èµ·çš„å‚æ•°åå·®ï¼ˆparameter deviationï¼‰**ï¼Œæ„å»ºäº†ä¸€ç§æ›´å‡†ç¡®çš„å±‚æ•æ„Ÿåº¦è¯„ä¼°æŒ‡æ ‡ã€‚
- å…¬å¼ä¸ºï¼š  
  $$
  \Delta L \approx |\mathbf{g}_{aq} \circ (\mathbf{A}_f - \mathbf{A}_q)|
  $$
  å…¶ä¸­ $\mathbf{g}_{aq}$ æ˜¯æ¿€æ´»è¾“å‡ºå¯¹æŸå¤±çš„æ¢¯åº¦ï¼Œ$\mathbf{A}_f$ å’Œ $\mathbf{A}_q$ åˆ†åˆ«æ˜¯å…¨ç²¾åº¦ä¸é‡åŒ–åçš„æ¿€æ´»å€¼ã€‚
- è¯¥æŒ‡æ ‡èƒ½æœ‰æ•ˆåæ˜ é‡åŒ–å¯¹ä»»åŠ¡æŸå¤±çš„å®é™…å½±å“ï¼Œä¼˜äºä»…ä¾èµ– Hessian æˆ–å¯å‘å¼è§„åˆ™çš„æ–¹æ³•ã€‚

#### **(2) åŠ¨æ€è§„åˆ’é©±åŠ¨çš„è‡ªé€‚åº”æ¯”ç‰¹åˆ†é…ï¼ˆAdaptive Bit Allocationï¼‰**
- åˆ©ç”¨ DeltaLoss å¾—åˆ°å„å±‚æ•æ„Ÿåº¦åï¼Œç»“åˆ **åŠ¨æ€è§„åˆ’ï¼ˆdynamic programmingï¼‰** å®ç°æœ€ä¼˜æ¯”ç‰¹é…ç½®ï¼Œåœ¨ç»™å®šå¹³å‡æ¯”ç‰¹é¢„ç®—ä¸‹æœ€å¤§åŒ–æ¨¡å‹æ¢å¤èƒ½åŠ›ã€‚
- æ”¯æŒçµæ´»çš„æ··åˆç²¾åº¦ç­–ç•¥ï¼Œé¿å…ç»Ÿä¸€æ¯”ç‰¹å¸¦æ¥çš„æ€§èƒ½ç“¶é¢ˆã€‚

#### **(3) è½»é‡çº§é¢„è°ƒä¼˜æœç´¢ï¼ˆLightweight Pre-tuning Searchï¼‰**
- å— llama.cpp ä¸­â€œé‡è¦æ€§çŸ©é˜µâ€å¯å‘ï¼Œè®¾è®¡äº†ä¸€ä¸ªå¿«é€Ÿæœç´¢æœºåˆ¶æ¥ä¼˜åŒ– **é‡åŒ– scale åˆå§‹åŒ–**ã€‚
- æœç´¢ç›®æ ‡å‡½æ•°ä¸ºï¼š
  $$
  \min_s \sum_i ((W_r - W_q) \circ \max(A))^2
  $$
  å³æœ€å°åŒ–åŠ æƒé‡å»ºè¯¯å·®ã€‚
- æ˜¾è‘—æå‡æä½æ¯”ç‰¹ä¸‹çš„ç¨³å®šæ€§ä¸æœ€ç»ˆç²¾åº¦ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | SignRoundV2 | ä¼ ç»Ÿ PTQ / QAT |
|------|-------------|----------------|
| **æ˜¯å¦éœ€è¦è®­ç»ƒ** | å¦ï¼ˆçº¯ PTQï¼‰ | å¤šæ•°éœ€å¾®è°ƒæˆ–è’¸é¦ |
| **è®¡ç®—å¼€é”€** | æä½ï¼ˆ~2.5 å°æ—¶ï¼‰ | é«˜ï¼ˆæ•°åè‡³æ•°ç™¾å°æ—¶ï¼‰ |
| **é€‚ç”¨åœºæ™¯** | å¿«é€Ÿéƒ¨ç½²ã€è¾¹ç¼˜è®¾å¤‡ | èµ„æºå……è¶³ç¯å¢ƒ |
| **æ€§èƒ½è¡¨ç°** | æ¥è¿‘ç”šè‡³è¶…è¶Šéƒ¨åˆ† QAT æ–¹æ³• | åœ¨ 2-bit ä¸‹ä¸¥é‡é€€åŒ– |
| **ç¡¬ä»¶å…¼å®¹æ€§** | æ”¯æŒé€šç”¨ GPU/CPU | éƒ¨åˆ†ä¾èµ–ä¸“ç”¨åŠ é€Ÿå™¨ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **æ ¡å‡†æ•°æ®é›†ï¼ˆCalibration Datasetï¼‰**ï¼šThe Pileï¼ˆç”¨äºé‡åŒ–å‰çš„å°æ ·æœ¬æ ¡å‡†ï¼‰
- **è¯„ä¼°åŸºå‡†ï¼ˆEvaluation Benchmarkï¼‰**ï¼šé‡‡ç”¨ `LM-EVAL-HARNESS` æ¡†æ¶ï¼Œæ¶µç›–ä»¥ä¸‹æ ‡å‡†ä»»åŠ¡ï¼š
  - ARC-Challenge/Easy
  - BoolQ
  - HellaSwag
  - LAMBADA
  - MMLU
  - OpenBookQA
  - PIQA
  - TruthfulQA
  - WinoGrande

### **å®éªŒè®¾ç½®**
- **æ¨¡å‹å®¶æ—**ï¼š
  - LLaMA ç³»åˆ—ï¼šLLaMA2-7B/13B/70Bã€LLaMA3-8B/70Bã€LLaMA3.1-8B/70B-Instruct
  - Qwen ç³»åˆ—ï¼šQwen2.5-7B/3-8B/3-32B-Instruct
- **é‡åŒ–é…ç½®**ï¼š
  - æƒé‡-æ¿€æ´»ç»„åˆï¼šW2A16ã€W4A16ã€MXFP4ã€MXFP8
  - å¯¹ç§°é‡åŒ–ï¼ˆsymmetric quantizationï¼‰ï¼Œgroup size é»˜è®¤ä¸º 128 æˆ– 64
- **è¶…å‚æ•°è®¾ç½®**ï¼š
  - DeltaLoss ä½¿ç”¨ 16 ä¸ªæ ·æœ¬ï¼ˆseq_len=256ï¼‰
  - ä¸»è°ƒä¼˜é˜¶æ®µä½¿ç”¨ 128 ä¸ªæ ·æœ¬ï¼ˆseq_len=2048ï¼‰ï¼Œæ¯ block ä¼˜åŒ– 200 æ­¥ï¼ˆOurs* ç‰ˆæœ¬ä¸º 500 æ­¥ï¼‰

### **è¯„ä¼°æŒ‡æ ‡**
- **å¹³å‡å‡†ç¡®ç‡ï¼ˆAverage Accuracyï¼‰**ï¼šå¤šä¸ªä»»åŠ¡ä¸Šçš„å‡å€¼
- **æ¢å¤ç‡ï¼ˆRecovery Rate %ï¼‰**ï¼šç›¸å¯¹äºå…¨ç²¾åº¦æ¨¡å‹çš„æ€§èƒ½ç™¾åˆ†æ¯”
- **é‡åŒ–æ—¶é—´ï¼ˆGPU Hoursï¼‰**ï¼šç«¯åˆ°ç«¯é‡åŒ–è€—æ—¶
- **æ˜¾å­˜å ç”¨ï¼ˆVRAM Costï¼‰**

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **ç»å…¸ PTQ æ–¹æ³•**ï¼š
  - GPTQã€AWQã€OmniQuantã€SignRoundV1
- **å…ˆè¿› QAT æ–¹æ³•**ï¼š
  - EfficientQATã€QuIP#ã€AQLM
- **å…¶ä»–**ï¼š
  - RTNï¼ˆRound-to-Nearestï¼‰ã€llama.cpp å¯å‘å¼ç­–ç•¥

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **(1) W2A16 è®¾ç½®ä¸‹çš„æ€§èƒ½ï¼ˆTable 1ï¼‰**
| æ¨¡å‹ | æ–¹æ³• | å¹³å‡æ¯”ç‰¹ | å¹³å‡å‡†ç¡®ç‡ |
|------|------|----------|------------|
| Llama2-70B | Full Precision | 16 | 72.71 |
| Llama2-70B | GPTQ | 2 | 34.38 |
| Llama2-70B | AWQ | 2 | 35.49 |
| Llama2-70B | SignRoundV1 | 2 | 67.70 |
| Llama2-70B | **Ours** | 2 | **68.39** |
| Llama2-70B | **Ours*** | 2 | **68.82** |
| Llama2-70B | **Ours*** | 2.5 | **70.60** |

> âœ… åœ¨çº¯ 2-bit æƒé‡é‡åŒ–ä¸‹ï¼ŒSignRoundV2 è¾¾åˆ° **~68.8% å‡†ç¡®ç‡**ï¼Œæ¥è¿‘å…¨ç²¾åº¦ï¼ˆ72.7%ï¼‰ï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»– PTQ æ–¹æ³•ã€‚

#### **(2) MXFP4/8 æ··åˆç²¾åº¦ç»“æœï¼ˆTable 2ï¼‰**
| æ¨¡å‹ | æ–¹æ³• | å¹³å‡æ¯”ç‰¹ | å‡†ç¡®ç‡ | æ¢å¤ç‡ |
|------|------|----------|--------|--------|
| Llama3.1-8B-I | Full Precision | 16 | 64.16 | 100% |
| Llama3.1-8B-I | RTN | 4 | 58.31 | 90.88% |
| Llama3.1-8B-I | SRV1 | 4 | 60.72 | 94.64% |
| Llama3.1-8B-I | **Ours** | 4 | **61.34** | **95.59%** |
| Llama3.1-8B-I | **Ours** | 5 | **63.19** | **98.49%** |
| Llama3.1-8B-I | **Ours** | 6 | **64.12** | **99.93%** |

> âœ… åœ¨ 4â€“6 bit èŒƒå›´å†…ï¼ŒSignRoundV2 å®ç° **>98% æ¢å¤ç‡**ï¼Œåœ¨ 6-bit æ—¶å‡ ä¹å®Œå…¨æ¢å¤å…¨ç²¾åº¦æ€§èƒ½ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- åœ¨ **W2A16** åœºæ™¯ä¸‹ï¼ŒSignRoundV2 æ¯” GPTQ/AWQ é«˜å‡º **30+ pts**ï¼Œæ¯” SignRoundV1 æå‡çº¦ **1â€“2 pts**
- åœ¨ **MXFP4** ä¸Šï¼Œæ¯” RTN æå‡ **~3 pts**ï¼Œæ¯” SRV1 æå‡ **~0.6 pts**
- åœ¨ **å°æ¨¡å‹ï¼ˆå¦‚ 7Bï¼‰** ä¸Šä»ç•¥é€Šäºéƒ¨åˆ† QAT æ–¹æ³•ï¼ˆå¦‚ EfficientQATï¼‰ï¼Œä½†åœ¨å¤§æ¨¡å‹ä¸Šå·²å¯åª²ç¾

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**

#### **(1) åˆå§‹åŒ–ç­–ç•¥çš„å½±å“ï¼ˆTable 5ï¼‰**
| æ¨¡å‹ | åˆå§‹åŒ– | ARC-c | HellaSwag | MMLU | WinoGrande | å¹³å‡ |
|------|--------|-------|-----------|------|------------|------|
| Qwen3-8B | æ— åˆå§‹åŒ– | 34.90 | 44.87 | 47.18 | 54.09 | 63.85 |
| Qwen3-8B | æœ‰åˆå§‹åŒ– | 43.69 | 45.12 | 54.61 | 56.12 | **66.22** |
| Llama3.1-8B-I | æœ‰åˆå§‹åŒ– | +1.12 | +1.12 | +7.84 | +2.06 | +1.73 pts â†‘ |

> ğŸ” éªŒè¯äº† **é¢„è°ƒä¼˜æœç´¢åˆå§‹åŒ–** æ˜¾è‘—æå‡äº†ç¨³å®šæ€§å’Œæœ€ç»ˆæ€§èƒ½ã€‚

#### **(2) æ··åˆæ¯”ç‰¹åˆ†é…ç­–ç•¥å¯¹æ¯”ï¼ˆTable 3 & 4ï¼‰**
- ç›¸è¾ƒäºâ€œå¤´å±‚/å°¾å±‚ä¼˜å…ˆåˆ†é… 8-bitâ€çš„å¯å‘å¼ç­–ç•¥ï¼ŒåŸºäº DeltaLoss çš„è‡ªé€‚åº”åˆ†é…åœ¨æ‰€æœ‰æ¨¡å‹ä¸Šå‡å–å¾—æ›´é«˜å‡†ç¡®ç‡ã€‚
- åœ¨å¹³å‡ 3-bit æƒé‡åˆ†é…ä¸‹ï¼ˆW2/W4 æ··åˆï¼‰ï¼ŒSignRoundV2 æ¯” head/tail ç­–ç•¥é«˜å‡º **~10â€“30 pts**

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **DeltaLoss æ˜¯ä¸€ä¸ªæ›´å¯é çš„æ•æ„Ÿåº¦åº¦é‡æ–¹å¼**ï¼Œèåˆæ¢¯åº¦ä¸åå·®ä¿¡æ¯ï¼Œæ˜¾è‘—ä¼˜äº Hessian æˆ–è¾“å‡ºæ‰°åŠ¨ç­‰ä»£ç†æŒ‡æ ‡ã€‚
2. **è½»é‡çº§ scale åˆå§‹åŒ–æœç´¢** æå¤§åœ°æå‡äº†æä½æ¯”ç‰¹é‡åŒ–è¿‡ç¨‹çš„ç¨³å®šæ€§ä¸æ”¶æ•›è´¨é‡ã€‚
3. **SignRoundV2 åœ¨ 4â€“5 bit å®ç°ç”Ÿäº§çº§æ€§èƒ½**ï¼ˆ<1% å·®å¼‚ï¼‰ï¼Œå³ä½¿åœ¨ **2-bit æƒé‡** ä¸‹ä¹Ÿèƒ½ä¿æŒå¼ºå¥è¡¨ç°ã€‚
4. **æ— éœ€ QAT å³å¯è¾¾åˆ°æ¥è¿‘ QAT çš„æ€§èƒ½**ï¼ŒåŒæ—¶å°†é‡åŒ–æ—¶é—´ä»ä¸Šç™¾å°æ—¶é™è‡³ **2.5 å°æ—¶ä»¥å†…**ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
1. **åœ¨æä½æ¯”ç‰¹ï¼ˆå¦‚ <2.5 bitsï¼‰ä¸”æ— æ··åˆç²¾åº¦æ—¶**ï¼Œå°æ¨¡å‹ä»æœ‰æ˜æ˜¾æ€§èƒ½å·®è·ã€‚
2. **æ¯”ç‰¹é…ç½®åœ¨è°ƒä¼˜å‰å›ºå®š**ï¼Œæœªè€ƒè™‘è°ƒä¼˜è¿‡ç¨‹ä¸­è¯¯å·®è¡¥å¿æ½œåŠ›ã€‚
3. **ä¾èµ–æ¢¯åº¦è®¡ç®—**ï¼Œæ— æ³•ç›´æ¥åº”ç”¨äºä¸æ”¯æŒè‡ªåŠ¨å¾®åˆ†çš„æ¨ç†æ¡†æ¶ï¼ˆå¦‚ ONNXï¼‰ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ¢ç´¢ **åŠ¨æ€æ¯”ç‰¹è°ƒæ•´æœºåˆ¶**ï¼Œåœ¨è°ƒä¼˜è¿‡ç¨‹ä¸­æ ¹æ®è¯¯å·®åé¦ˆåŠ¨æ€ä¿®æ”¹æ¯”ç‰¹åˆ†é…ã€‚
- æ‰©å±•è‡³ **Mixture-of-Experts (MoE)** æ¨¡å‹çš„æ··åˆç²¾åº¦é‡åŒ–ã€‚
- å¼€å‘ **å…æ¢¯åº¦ç‰ˆæœ¬çš„ DeltaLoss è¿‘ä¼¼ç®—æ³•**ï¼Œä»¥é€‚é…æ›´å¤šéƒ¨ç½²ç¯å¢ƒã€‚

---

> ğŸ“Œ **å¼€æºåœ°å€**ï¼šhttps://github.com/intel/auto-round  
> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼šSignRoundV2 é€šè¿‡ **ç²¾å‡†æ•æ„Ÿåº¦å»ºæ¨¡ + é«˜æ•ˆåˆå§‹åŒ–æœç´¢**ï¼Œå®ç°äº†æä½æ¯”ç‰¹ PTQ çš„æ€§èƒ½çªç ´ï¼Œåœ¨é€Ÿåº¦ä¸ç²¾åº¦ä¹‹é—´å–å¾—äº†å“è¶Šå¹³è¡¡ã€‚

</details>

---

### 4. [Semantic Soft Bootstrapping: Long Context Reasoning in LLMs without Reinforcement Learning](https://arxiv.org/abs/2512.05105)

**Authors**: Purbesh Mitra, Sennur Ulukus  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.05105v1  

#### Abstract
Long context reasoning in large language models (LLMs) has demonstrated enhancement of their cognitive capabilities via chain-of-thought (CoT) inference. Training such models is usually done via reinforcement learning with verifiable rewards (RLVR) in reasoning based problems, like math and programm...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSemantic Soft Bootstrapping: Long Context Reasoning in LLMs without Reinforcement Learning

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é•¿ä¸Šä¸‹æ–‡æ¨ç†èƒ½åŠ›æ—¶ï¼Œä¸»æµæ–¹æ³•ä¾èµ–**å¼ºåŒ–å­¦ä¹ ä¸å¯éªŒè¯å¥–åŠ±**ï¼ˆReinforcement Learning with Verifiable Rewards, RLVRï¼‰ï¼Œå¦‚ GRPOã€‚ç„¶è€Œï¼Œè¿™ç±»æ–¹æ³•å­˜åœ¨ä»¥ä¸‹ç“¶é¢ˆï¼š
- **ç¨€ç–å¥–åŠ±é—®é¢˜**ï¼šä»…åœ¨ç”Ÿæˆç»“æŸæ—¶å¯¹æœ€ç»ˆç­”æ¡ˆæ‰“åˆ†ï¼Œç¼ºä¹å¯¹ä¸­é—´æ¨ç†æ­¥éª¤çš„ç»†ç²’åº¦ç›‘ç£ã€‚
- **æ ·æœ¬æ•ˆç‡ä½**ï¼šéœ€è¦å¤§é‡ rollout æ‰èƒ½è·å¾—æœ‰æ•ˆè®­ç»ƒä¿¡å·ã€‚
- **è®¡ç®—èµ„æºæ¶ˆè€—å¤§**ï¼šRLVR è®­ç»ƒè¿‡ç¨‹å¤æ‚ä¸”æ˜‚è´µã€‚
- **å¯èƒ½å¼•å‘â€œå¥–åŠ±é»‘å®¢â€è¡Œä¸º**ï¼šæ¨¡å‹å¯èƒ½é€šè¿‡é”™è¯¯é€»è¾‘å¶ç„¶å¾—åˆ°æ­£ç¡®ç­”æ¡ˆè€Œè¢«é¼“åŠ±ã€‚

æ­¤å¤–ï¼Œå·²æœ‰ç ”ç©¶è¡¨æ˜ï¼ŒRLVR å¹¶æœªçœŸæ­£å¢å¼ºåŸºç¡€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œè€Œæ˜¯æ”¾å¤§äº†å·²æœ‰çš„èƒ½åŠ›ï¼ˆpass@k â†’ pass@1ï¼‰ï¼Œå¯¼è‡´å¤šæ ·æ€§ä¸‹é™ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šSemantic Soft Bootstrapping (SSB)

SSB æ˜¯ä¸€ç§**æ— éœ€å¼ºåŒ–å­¦ä¹ **çš„è‡ªè’¸é¦ï¼ˆself-distillationï¼‰æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- åŒä¸€ä¸ªåŸºç¡€ LLM å……å½“**æ•™å¸ˆ**å’Œ**å­¦ç”Ÿ**è§’è‰²ï¼Œä½†åœ¨ä¸åŒè¯­ä¹‰ä¸Šä¸‹æ–‡ä¸­è¿è¡Œã€‚
- æ•™å¸ˆçœ‹åˆ°åŸå§‹é—®é¢˜ + æ­£ç¡®ä¸å…¸å‹é”™è¯¯çš„å›ç­”ç¤ºä¾‹ï¼Œè¢«æç¤ºåˆæˆä¸€ä¸ªé²æ£’ã€è¯¦ç»†çš„è§£é‡Šã€‚
- å­¦ç”Ÿåªçœ‹åˆ°åŸå§‹é—®é¢˜ï¼Œç›®æ ‡æ˜¯æ¨¡ä»¿æ•™å¸ˆåœ¨ç­”æ¡ˆéƒ¨åˆ†è¾“å‡ºçš„ token-level **logits åˆ†å¸ƒ**ã€‚

#### åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š
1. **è¯­ä¹‰è½¯å¼•å¯¼æœºåˆ¶**ï¼šåˆ©ç”¨æ¨¡å‹è‡ªèº«ç”Ÿæˆçš„æ­£ç¡®ä¸å¸¸è§é”™è¯¯å“åº”ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œæ„å»ºâ€œå¯¹æ¯”å­¦ä¹ â€ç¯å¢ƒï¼Œä¿ƒä½¿æ•™å¸ˆç”Ÿæˆæ›´ç¨³å¥çš„æ¨ç†è·¯å¾„ã€‚
2. **æ—  RL çš„è®­ç»ƒèŒƒå¼**ï¼šå®Œå…¨é¿å…ä½¿ç”¨ reward model æˆ– policy gradientï¼Œé‡‡ç”¨åŸºäº KL æ•£åº¦çš„ logit åŒ¹é…è¿›è¡ŒçŸ¥è¯†è’¸é¦ã€‚
3. **è‡ªåŠ¨æ„å»ºå¸ˆç”Ÿé…å¯¹æ•°æ®é›†**ï¼šä»åŸå§‹é—®é¢˜-ç­”æ¡ˆæ•°æ®ä¸­è‡ªåŠ¨æ„é€ å¸¦ä¸°å¯Œä¸Šä¸‹æ–‡çš„æ•™å¸ˆå¯¹è¯å’Œç®€æ´çš„å­¦ç”Ÿå¯¹è¯ï¼Œæ— éœ€äººå·¥æ ‡æ³¨ã€‚
4. **logit-level è‡ªç›‘ç£**ï¼šå­˜å‚¨æ•™å¸ˆåœ¨ç­”æ¡ˆéƒ¨åˆ†çš„ logits ä½œä¸ºè½¯æ ‡ç­¾ï¼Œå­¦ç”Ÿä»…éœ€åŒ¹é…è¿™äº›åˆ†å¸ƒï¼Œä»è€Œä¿ç•™æ¨¡å‹æ³›åŒ–èƒ½åŠ›å¹¶é˜²æ­¢å´©æºƒï¼ˆcollapseï¼‰ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | SSB | RLVRï¼ˆå¦‚ GRPOï¼‰ |
|------|-----|----------------|
| æ˜¯å¦éœ€è¦ RL | âŒ å¦ | âœ… æ˜¯ |
| å¥–åŠ±å¯†åº¦ | é«˜ï¼ˆtoken-level è½¯æ ‡ç­¾ï¼‰ | ä½ï¼ˆoutcome-level ç¨€ç–å¥–åŠ±ï¼‰ |
| æ ·æœ¬æ•ˆç‡ | é«˜ï¼ˆä»…ç”¨ 256 ä¸ªæ ·æœ¬ï¼‰ | ä½ï¼ˆé€šå¸¸éœ€æ•°åƒæ ·æœ¬ï¼‰ |
| è®¡ç®—å¼€é”€ | å°ï¼ˆå•å¡ A100 å¯å®Œæˆï¼‰ | å¤§ |
| æŠ— reward hacking | å¼ºï¼ˆå¿…é¡»åŒ¹é…éªŒè¯æ­£ç¡®çš„è½¨è¿¹ï¼‰ | å¼± |
| æ¨ç†é•¿åº¦å¢é•¿ | ä¸æ˜¾è‘—å¢åŠ ï¼ˆéå¿…è¦ï¼‰ | é€šå¸¸ä¼´éšæ¨ç†é“¾å˜é•¿ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **è®­ç»ƒæ•°æ®æ¥æº**ï¼š`GSM8K`ï¼ˆå°å­¦æ•°å­¦é¢˜ï¼‰ï¼Œä»…ä½¿ç”¨é—®é¢˜å’Œæ ‡å‡†ç­”æ¡ˆï¼Œä¸ä½¿ç”¨å®˜æ–¹æä¾›çš„æ¨ç†è¿‡ç¨‹ã€‚
- **æµ‹è¯•åŸºå‡†**ï¼š
  - `MATH500`ï¼šæ›´å…·æŒ‘æˆ˜æ€§çš„é«˜ä¸­/ç«èµ›çº§æ•°å­¦é¢˜ã€‚
  - `AIME2024`ï¼šç¾å›½æ•°å­¦é‚€è¯·èµ›çº§åˆ«é¢˜ç›®ï¼Œéš¾åº¦æ›´é«˜ã€‚

> æ³¨ï¼šä½œè€…ä» 950 ä¸ª GSM8K é—®é¢˜ä¸­ç”Ÿæˆå¤šè½® rolloutï¼Œç­›é€‰å‡º 256 ä¸ªå…·æœ‰â€œæ­£ç¡®+æœ€å¸¸è§é”™è¯¯â€å“åº”ç»„åˆçš„é—®é¢˜ï¼Œç”¨äºæ„å»º SSB è®­ç»ƒé›†ã€‚

---

### å®éªŒè®¾ç½®
- **åŸºç¡€æ¨¡å‹**ï¼š`Qwen2.5-3B-Instruct`
- **å¾®è°ƒæ–¹å¼**ï¼šParameter-Efficient Fine-Tuningï¼ˆPEFTï¼‰ï¼Œä½¿ç”¨ rank 32 LoRA æ›´æ–°çº¦ 2% å‚æ•°ã€‚
- **è®­ç»ƒé…ç½®**ï¼š
  - Batch size: 4
  - Epochs: 3
  - Total steps: 192
  - å•å— NVIDIA A100 40GB GPU å®Œæˆè®­ç»ƒ
- **æ¸©åº¦è®¾ç½®**ï¼š
  - Rollout æ¸©åº¦ $ T_{roll} = 0.7 $
  - è’¸é¦æ¸©åº¦ $ T_{KD} > 1 $ï¼ˆç”¨äºå¹³æ»‘ softmax åˆ†å¸ƒï¼‰

---

### è¯„ä¼°æŒ‡æ ‡
- **Pass@1 å‡†ç¡®ç‡**ï¼šè¡¡é‡æ¨¡å‹é¦–æ¬¡å°è¯•å³ç»™å‡ºæ­£ç¡®ç­”æ¡ˆçš„æ¦‚ç‡ã€‚
  $$
  \text{Pass@1} = \frac{\#\ \text{correct answers}}{\#\ \text{total questions}}
  $$
  æ­£ç¡®æ€§ç”± `\boxed{}` ä¸­çš„ç­”æ¡ˆæ˜¯å¦åŒ¹é…å†³å®šã€‚

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Base Model**ï¼šæœªç»åè®­ç»ƒçš„ `Qwen2.5-3B-Instruct`
- **GRPO**ï¼šGroup Relative Policy Optimizationï¼Œå…¸å‹çš„ RLVR æ–¹æ³•ï¼Œä½œä¸ºä¸»è¦å¯¹ç…§ç»„ï¼Œä½¿ç”¨ 2000 ä¸ª GSM8K æ ·æœ¬è®­ç»ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰
| æ¨¡å‹ | MATH500 | AIME2024 |
|------|--------|---------|
| Base Model | 37.6% | 0.0% |
| GRPO | 44.8% | 3.33% |
| **SSB (Ours)** | **55.4%** | **13.33%** |

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨ **MATH500** ä¸Šï¼ŒSSB ç›¸æ¯” GRPO æå‡ **+10.6% absolute**
- åœ¨ **AIME2024** ä¸Šï¼ŒSSB ç›¸æ¯” GRPO æå‡ **+10% absolute**
- æ›´æƒŠäººçš„æ˜¯ï¼ŒSSB ä»…ä½¿ç”¨ **256 ä¸ªé«˜è´¨é‡æ ·æœ¬**ï¼Œè€Œ GRPO ä½¿ç”¨äº† **2000 ä¸ªæ ·æœ¬**

> è¡¨æ˜ SSB å…·æœ‰æé«˜çš„**æ ·æœ¬æ•ˆç‡**å’Œ**è®¡ç®—æ•ˆç‡**ä¼˜åŠ¿ã€‚

---

### æ¶ˆèå®éªŒä¸è®­ç»ƒåŠ¨æ€åˆ†æï¼ˆFig. 2ï¼‰
å°½ç®¡è®ºæ–‡æœªæä¾›æ˜¾å¼çš„æ¶ˆèå®éªŒè¡¨æ ¼ï¼Œä½†ä»è®­ç»ƒæ›²çº¿å¯å¾—å‡ºé‡è¦è§‚å¯Ÿï¼š
- **Loss ä¸‹é™å¹³ç¨³**ï¼šè®­ç»ƒæŸå¤±éšæ­¥æ•°ç¨³å®šä¸‹é™ï¼Œè¡¨æ˜ä¼˜åŒ–è¿‡ç¨‹ç¨³å®šã€‚
- **Gradient norm æ”¶æ•›è‰¯å¥½**ï¼šæ¢¯åº¦èŒƒæ•°é€æ¸å‡å°ï¼Œæ”¯æŒæ”¶æ•›æ€§ã€‚
- **Completion length æ— æ˜æ˜¾å¢é•¿**ï¼š
  - ä¸ RLVR ä¸åŒï¼ŒSSB å¹¶æœªè¯±å¯¼æ¨¡å‹ç”Ÿæˆè¶Šæ¥è¶Šé•¿çš„æ¨ç†é“¾ã€‚
  - è¯´æ˜æ€§èƒ½æå‡å¹¶éæ¥è‡ªâ€œå † tokenâ€ï¼Œè€Œæ˜¯**æ¨ç†è´¨é‡çš„æœ¬è´¨æ”¹è¿›**ã€‚

è¿™ä¸€å‘ç°æŒ‘æˆ˜äº†â€œæ›´é•¿çš„ CoT = æ›´å¼ºæ¨ç†â€çš„æ™®éå‡è®¾ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **æ›´å¼ºçš„æ¨ç†èƒ½åŠ›å¯ä»¥ä¸ä¾èµ– RL**ï¼šSSB åœ¨æ— éœ€ä»»ä½•å¼ºåŒ–å­¦ä¹ çš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—è¶…è¶Šä¸»æµ RLVR æ–¹æ³•ï¼ˆGRPOï¼‰ã€‚
2. âœ… **logit-level è‡ªç›‘ç£æ˜¯é«˜æ•ˆæ›¿ä»£æ–¹æ¡ˆ**ï¼šé€šè¿‡åŒ¹é…æ•™å¸ˆæ¨¡å‹åœ¨ç­”æ¡ˆéƒ¨åˆ†çš„ logitsï¼Œå³å¯å®ç°é«˜è´¨é‡çš„çŸ¥è¯†è¿ç§»ã€‚
3. âœ… **è¯­ä¹‰ä¸Šä¸‹æ–‡å·®å¼‚é©±åŠ¨å­¦ä¹ **ï¼šåŒä¸€æ¨¡å‹åœ¨ä¸åŒè¾“å…¥ä¸Šä¸‹æ–‡ï¼ˆhinted vs. hint-freeï¼‰ä¸‹æ‰®æ¼”æ•™å¸ˆä¸å­¦ç”Ÿï¼Œå®ç°äº†â€œè‡ªæˆ‘è¿›åŒ–â€ã€‚
4. âœ… **æ¨ç†èƒ½åŠ›æå‡ä¸ä¸€å®šä¼´éšæ¨ç†é“¾å¢é•¿**ï¼šSSB æ¨¡å‹å¹¶æœªå˜å¾—æ›´å•°å—¦ï¼Œä½†å‡†ç¡®ç‡å¤§å¹…æå‡ï¼Œè¯´æ˜**æ¨ç†æ•ˆç‡å’Œå‡†ç¡®æ€§è§£è€¦**ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–å¯éªŒè¯ç­”æ¡ˆçš„ä»»åŠ¡**ï¼šç›®å‰é€‚ç”¨äºæ•°å­¦ç­‰æœ‰æ˜ç¡®ç­”æ¡ˆçš„é¢†åŸŸï¼Œéš¾ä»¥ç›´æ¥æ‰©å±•åˆ°å¼€æ”¾ç”Ÿæˆä»»åŠ¡ã€‚
2. **rollout æ•°é‡è¦æ±‚**ï¼šæ¯ä¸ªé—®é¢˜éœ€ç”Ÿæˆå¤šä¸ªå“åº”ä»¥åˆ†ç¦»æ­£ç¡®/é”™è¯¯è·¯å¾„ï¼Œè‹¥å…¨å¯¹æˆ–å…¨é”™åˆ™æ— æ³•æ„å»ºè®­ç»ƒæ ·æœ¬ã€‚
3. **æ ¼å¼æ•æ„Ÿæ€§**ï¼šä¾èµ– `\boxed{}` æå–ç­”æ¡ˆï¼Œè‹¥æ¨¡å‹æœªéµå¾ªæ ¼å¼å°†è¢«è§†ä¸ºé”™è¯¯ã€‚
4. **å°šæœªåœ¨æ›´å¤§æ¨¡å‹ä¸ŠéªŒè¯**ï¼šå®éªŒåŸºäº 3B è§„æ¨¡æ¨¡å‹ï¼Œæ˜¯å¦å¯æ‰©å±•è‡³ 70B+ æ¨¡å‹ä»å¾…ç ”ç©¶ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³å…¶ä»–é¢†åŸŸ**ï¼šå¦‚ç¨‹åºåˆæˆï¼ˆcode generationï¼‰ã€ç§‘å­¦é—®ç­”ã€å½¢å¼åŒ–è¯æ˜ç­‰ã€‚
2. **æ¢ç´¢ SSB çš„ scaling laws**ï¼šç ”ç©¶éšç€æ¨¡å‹å¤§å°ã€é—®é¢˜æ•°é‡ã€rollout æ¬¡æ•°çš„å¢é•¿ï¼Œæ€§èƒ½å¦‚ä½•å˜åŒ–ã€‚
3. **ç»“åˆå°‘é‡äººç±»åé¦ˆ**ï¼šå¼•å…¥è½»é‡çº§äººå·¥ä¿®æ­£ä»¥è¿›ä¸€æ­¥æå‡æ•™å¸ˆè´¨é‡ã€‚
4. **åŠ¨æ€é‡‡æ ·ç­–ç•¥**ï¼šæ™ºèƒ½é€‰æ‹©æœ€å…·ä»£è¡¨æ€§çš„é”™è¯¯å“åº”ï¼Œè€Œéä»…â€œæœ€é¢‘ç¹â€è€…ã€‚
5. **ä¸å…¶ä»– PEFT æ–¹æ³•ç»“åˆ**ï¼šå¦‚ IAÂ³ã€Adapter ç­‰ï¼Œè¿›ä¸€æ­¥é™ä½è®¡ç®—æˆæœ¬ã€‚

---

## æ€»ç»“
**Semantic Soft Bootstrapping (SSB)** æå‡ºäº†ä¸€ç§æ–°é¢–ã€é«˜æ•ˆä¸”æ— éœ€å¼ºåŒ–å­¦ä¹ çš„æ–¹å¼æ¥æå‡ LLM çš„é•¿ä¸Šä¸‹æ–‡æ¨ç†èƒ½åŠ›ã€‚å®ƒé€šè¿‡**è¯­ä¹‰ä¸Šä¸‹æ–‡æ“æ§ + è‡ªè’¸é¦ + logit åŒ¹é…**çš„æ–¹å¼ï¼Œè®©æ¨¡å‹å­¦ä¼šâ€œä»è‡ªå·±çš„é”™è¯¯ä¸­æ•™å­¦â€ï¼Œå¹¶åœ¨ä¸¤ä¸ªé«˜éš¾åº¦æ•°å­¦åŸºå‡†ä¸Šå¤§å¹…è¶…è¶Š GRPOã€‚è¯¥æ–¹æ³•ä¸ä»…æ€§èƒ½ä¼˜è¶Šï¼Œè€Œä¸”å…·å¤‡é«˜æ ·æœ¬æ•ˆç‡ã€ä½è®¡ç®—æˆæœ¬å’ŒæŠ— reward hacking çš„ç‰¹æ€§ï¼Œä¸ºåè®­ç»ƒèŒƒå¼æä¾›äº†æ–°çš„å¯èƒ½æ€§ã€‚

</details>

---

### 5. [TV2TV: A Unified Framework for Interleaved Language and Video Generation](https://arxiv.org/abs/2512.05103)

**Authors**: Xiaochuang Han, Youssef Emad, Melissa Hall, John Nguyen, Karthik Padthe, Liam Robbins, Amir Bar, Delong Chen, Michal Drozdzal, Maha Elbayad, Yushi Hu, Shang-Wen Li, Sreya Dutta Roy, Jakob Verbeek, XuDong Wang, Marjan Ghazvininejad, Luke Zettlemoyer, Emily Dinan  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.05103v1  

#### Abstract
Video generation models are rapidly advancing, but can still struggle with complex video outputs that require significant semantic branching or repeated high-level reasoning about what should happen next. In this paper, we introduce a new class of omni video-text models that integrate ideas from rec...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# TV2TV: A Unified Framework for Interleaved Language and Video Generation è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰çš„ **Text-to-Video (T2V)** æ¨¡å‹åœ¨ç”Ÿæˆå¤æ‚ã€é•¿æ—¶åºè§†é¢‘æ—¶é¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼š
- **è¯­ä¹‰å†³ç­–å›°éš¾**ï¼šæ¨¡å‹éœ€ç›´æ¥ä»æ–‡æœ¬ç”Ÿæˆè§†è§‰å†…å®¹ï¼Œç¼ºä¹å¯¹â€œä¸‹ä¸€æ­¥è¯¥å‘ç”Ÿä»€ä¹ˆâ€çš„é«˜å±‚æ¨ç†èƒ½åŠ›ï¼Œå¯¼è‡´åŠ¨ä½œé€»è¾‘æ··ä¹±æˆ–ç‰©ç†ä¸ä¸€è‡´ã€‚
- **å¯æ§æ€§å·®**ï¼šä¼ ç»Ÿ T2V æ¨¡å‹ä¸ºâ€œé»‘ç®±â€ç”Ÿæˆè¿‡ç¨‹ï¼Œç”¨æˆ·æ— æ³•åœ¨ç”Ÿæˆä¸­é€”è¿›è¡Œç»†ç²’åº¦å¹²é¢„ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šTV2TV
TV2TV æ˜¯ä¸€ç§ç»Ÿä¸€çš„ç”Ÿæˆæ¡†æ¶ï¼Œå°†è§†é¢‘ç”Ÿæˆåˆ†è§£ä¸º**äº¤é”™çš„æ–‡æœ¬ä¸è§†é¢‘ç”Ÿæˆè¿‡ç¨‹**ï¼ˆinterleaved text and video generationï¼‰ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> â€œ**å…ˆç”¨è¯­è¨€æ€è€ƒï¼ˆthink in wordsï¼‰ï¼Œå†ç”¨åƒç´ è¡ŒåŠ¨ï¼ˆact in pixelsï¼‰**â€ã€‚

#### æ ¸å¿ƒæ¶æ„ä¸æœºåˆ¶
- **Mixture-of-Transformers (MoT)** æ¶æ„ï¼šåˆ†åˆ«æ„å»º **text tower** å’Œ **video tower**ï¼Œå®ç°æ¨¡æ€ä¸“ç”¨å¤„ç†ï¼ŒåŒæ—¶é€šè¿‡å…¨å±€è‡ªæ³¨æ„åŠ›ä¿æŒè·¨æ¨¡æ€äº¤äº’ã€‚
- **äº¤é”™ç”Ÿæˆæµç¨‹**ï¼šåœ¨æ¨ç†æ—¶ï¼Œæ¨¡å‹åŠ¨æ€å†³å®šä½•æ—¶ç”Ÿæˆæ–‡æœ¬è®¡åˆ’ã€ä½•æ—¶ç”Ÿæˆè§†é¢‘å¸§å—ï¼Œå½¢æˆ `text â†’ video â†’ text â†’ video` çš„å¾ªç¯ã€‚
- **ç‰¹æ®Šæ§åˆ¶ä»¤ç‰Œ**ï¼šå¼•å…¥ `BOF`ï¼ˆBeginning-of-Frameï¼‰å’Œ `EOF`ï¼ˆEnd-of-Frameï¼‰æ ‡è®°ï¼Œè‡ªåŠ¨è§¦å‘æ–‡æœ¬åˆ°è§†é¢‘çš„æ¨¡å¼åˆ‡æ¢ã€‚
- **Flow Matching + Autoregressive**ï¼šè§†é¢‘éƒ¨åˆ†é‡‡ç”¨ **flow matching** è¿›è¡Œéè‡ªå›å½’å»å™ªï¼Œæ–‡æœ¬éƒ¨åˆ†ä¸ºæ ‡å‡†è‡ªå›å½’ç”Ÿæˆã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | ç‰¹ç‚¹ | TV2TV çš„ä¼˜åŠ¿ |
|------|------|--------------|
| **T2V** | ç›´æ¥ä» prompt ç”Ÿæˆå®Œæ•´è§†é¢‘ | TV2TV é€šè¿‡ä¸­é—´æ–‡æœ¬è§„åˆ’æå‡è¯­ä¹‰è¿è´¯æ€§å’Œè§†è§‰è´¨é‡ |
| **Think2V** | å…ˆç”Ÿæˆå®Œæ•´æ–‡æœ¬è®¡åˆ’ï¼Œå†ç”Ÿæˆè§†é¢‘ï¼ˆéäº¤é”™ï¼‰ | TV2TV æ”¯æŒ**åŠ¨æ€ã€ç»†ç²’åº¦æ§åˆ¶**ï¼Œå¯åœ¨ä»»æ„æ—¶é—´ç‚¹æ’å…¥å¹²é¢„ |
| **Genie ç­‰äº¤äº’å¼ä¸–ç•Œæ¨¡å‹** | éœ€è¦æ˜¾å¼ç”¨æˆ·æ¯æ­¥è¾“å…¥åŠ¨ä½œ | TV2TV å¯**è‡ªä¸»ç”ŸæˆåŠ¨ä½œè®¡åˆ’**ï¼Œæ— éœ€å¯†é›†äººå·¥å¹²é¢„ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
TV2TV åœ¨ä¸¤ç±»æ•°æ®ä¸Šè¿›è¡Œäº†éªŒè¯ï¼š

#### ï¼ˆ1ï¼‰æ¸¸æˆæ•°æ®ï¼ˆCS:GOï¼‰
- æ¥æºï¼šPearce & Zhu (2022) å¼€æºçš„ **Counter-Strike: Global Offensive** æ¸¸æˆæ•°æ®é›†ã€‚
- è§„æ¨¡ï¼š95 å°æ—¶æ¸¸æˆè§†é¢‘ + å¯¹åº”æ§åˆ¶å™¨åŠ¨ä½œï¼ˆé”®ç›˜/é¼ æ ‡è¾“å…¥ï¼‰ä½œä¸ºæ–‡æœ¬ä¿¡å·ã€‚
- ç‰¹ç‚¹ï¼š**å¤©ç„¶å¯¹é½çš„äº¤é”™æ•°æ®**ï¼ŒåŠ¨ä½œæŒ‡ä»¤ç²¾ç¡®å¯¹åº”åç»­ç”»é¢å˜åŒ–ã€‚

#### ï¼ˆ2ï¼‰çœŸå®ä¸–ç•Œä½“è‚²è§†é¢‘
- æ¥æºï¼šä» **YT-Temporal-1B** ä¸­ç­›é€‰ä½“è‚²é«˜å…‰ç‰‡æ®µã€‚
- å¤„ç†æµç¨‹ï¼ˆå››é˜¶æ®µï¼‰ï¼š
  1. **åœºæ™¯åˆ†å‰²**ï¼šä½¿ç”¨ TransNetV2 åˆ‡åˆ†è§†é¢‘ã€‚
  2. **å…³é”®å¸§æ£€æµ‹**ï¼šåŸºäº Perception Encoder è®¡ç®—å¸§é—´è¯­ä¹‰å˜åŒ–ã€‚
  3. **è¿‡æ»¤**ï¼šå»é™¤é™æ€äººè„¸ã€ä½è¿åŠ¨é‡ç‰‡æ®µã€‚
  4. **äº¤é”™æ ‡æ³¨**ï¼šä½¿ç”¨ **Qwen3-VL-30B-A3B-Instruct** ç”Ÿæˆå…ƒæè¿°ï¼ˆmeta-captionï¼‰å’Œå·®åˆ†æè¿°ï¼ˆdifferential captionsï¼‰ã€‚
- æœ€ç»ˆæ•°æ®é›†ï¼š**8K å°æ—¶**å¸¦äº¤é”™æ–‡æœ¬æè¿°çš„ä½“è‚²è§†é¢‘ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### æ¨¡å‹é…ç½®
- **TV2TV**ï¼šåŸºäº MoT æ¶æ„ï¼Œtext tower åˆå§‹åŒ–è‡ª Llama-3ã€‚
- **è®­ç»ƒç›®æ ‡**ï¼šè”åˆä¼˜åŒ–è¯­è¨€å»ºæ¨¡ï¼ˆCE Lossï¼‰å’Œè§†é¢‘æµåŒ¹é…ï¼ˆMSE Lossï¼‰ã€‚
- **ä¸Šä¸‹æ–‡é•¿åº¦**ï¼šæ”¯æŒæ»‘åŠ¨çª—å£æ‰©å±•è‡³é•¿è§†é¢‘ï¼ˆå¦‚ 64 ç§’ï¼‰ã€‚

#### åŸºçº¿æ–¹æ³•
| åŸºçº¿ | æè¿° |
|------|------|
| **T2V** | åŒæ¶æ„ä½†æ— äº¤é”™æ–‡æœ¬ï¼Œä»…ä¾èµ–åˆå§‹ prompt |
| **Think2V** | å…ˆç”Ÿæˆå®Œæ•´æ–‡æœ¬è®¡åˆ’ï¼Œå†ç”Ÿæˆè§†é¢‘ï¼ˆéäº¤é”™ï¼‰ |
| **å¤–éƒ¨æ¨¡å‹** | åŒ…æ‹¬ Cosmos-Predict2, MAGI-1, WAN-2.2 ç­‰é€šç”¨è§†é¢‘ç”Ÿæˆæ¨¡å‹ |

#### è¯„ä¼°æ–¹å¼
- **äººç±»ç›²è¯„ï¼ˆBlind Human Evaluationï¼‰**ï¼šç”±ä¸“ä¸šæ ‡æ³¨å‘˜è¿›è¡Œæˆå¯¹æ¯”è¾ƒã€‚
- **è¯„ä¼°ç»´åº¦**ï¼š
  - **è§†è§‰è´¨é‡ï¼ˆVisual Qualityï¼‰**
  - **æç¤ºå¯¹é½ï¼ˆPrompt Alignmentï¼‰**
  - **ç°å®ä¿çœŸåº¦ï¼ˆReal-world Fidelityï¼‰**
  - **æ•´ä½“åå¥½ï¼ˆHolistic Preferenceï¼‰**
  - **ç»†ç²’åº¦å¯æ§æ€§ï¼ˆFine-grained Controllabilityï¼‰**

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ï¼ˆ1ï¼‰åœ¨ CS:GO æ¸¸æˆæ•°æ®ä¸Šçš„ç»“æœ
| æŒ‡æ ‡ | TV2TV vs T2V | TV2TV vs Think2V |
|------|-------------|------------------|
| **è§†è§‰è´¨é‡ï¼ˆçŸ­è§†é¢‘ï¼‰** | 91% èƒœå‡º | 48% èƒœå‡º |
| **è§†è§‰è´¨é‡ï¼ˆé•¿è§†é¢‘ï¼‰** | 92% èƒœå‡º | 52% èƒœå‡º |
| **ç»†ç²’åº¦æŒ‡ä»¤è·Ÿéšå‡†ç¡®ç‡** | +19 pts æå‡ | â€” |

> âœ… **å…³é”®å‘ç°**ï¼šTV2TV åœ¨é•¿è§†é¢‘ç”Ÿæˆä¸­ä¼˜åŠ¿æ›´æ˜æ˜¾ï¼Œè¯´æ˜äº¤é”™æ¨ç†æœ‰æ•ˆç¼“è§£äº†é•¿æœŸä¸€è‡´æ€§é—®é¢˜ã€‚

### ï¼ˆ2ï¼‰åœ¨çœŸå®ä½“è‚²è§†é¢‘ä¸Šçš„ç»“æœ
| å¯¹æ¯”å¯¹è±¡ | æ•´ä½“åå¥½èƒœç‡ | æç¤ºå¯¹é½èƒœç‡ |
|---------|-------------|-------------|
| **Cosmos2 14B** | 54.0% vs 34.7% | 58.2% vs 31.1% |
| **MAGI-1 24B** | 53.3% vs 41.3% | 55.1% vs 36.7% |
| **WAN-2.2 5B** | 51.8% vs 42.9% | 54.6% vs 38.2% |

> âœ… **å…³é”®å‘ç°**ï¼šå°½ç®¡å¤–éƒ¨æ¨¡å‹æœªé’ˆå¯¹ä½“è‚²é¢†åŸŸè°ƒä¼˜ï¼ŒTV2TV ä»å…¨é¢ä¼˜äºå®ƒä»¬ï¼Œå°¤å…¶åœ¨**æç¤ºå¯¹é½**å’Œ**ç°å®ä¿çœŸåº¦**ä¸Šè¡¨ç°çªå‡ºã€‚

### ï¼ˆ3ï¼‰å¯æ§æ€§å®éªŒç»“æœ
- **å¹²é¢„ç±»å‹**ï¼šè·³è·ƒã€å°„å‡»ï¼ˆå·¦é”®ï¼‰ã€æ¢å¼¹ã€åé€€ã€‚
- **å¹²é¢„æ—¶æœº**ï¼št=1s å’Œ t=3sã€‚
- **ç»“æœ**ï¼š
  - TV2TV çš„**å¹²é¢„æ­£ç¡®ç‡**è¾¾ **78%**ï¼Œæ˜¾è‘—é«˜äº Think2V çš„ **59%**ã€‚
  - å°¤å…¶åœ¨â€œè·³è·ƒâ€å’Œâ€œå°„å‡»â€ç­‰ç¬æ—¶åŠ¨ä½œä¸Šæ§åˆ¶æ›´ç²¾å‡†ã€‚
  - æ— å¹²é¢„å¯¹ç…§ç»„ä¸­ï¼Œç›¸å…³åŠ¨ä½œè‡ªç„¶å‡ºç°ç‡ä»…ä¸º 17â€“22%ï¼Œè¯´æ˜å¹²é¢„æ•ˆæœééšæœºã€‚

### ï¼ˆ4ï¼‰æ¶ˆèå®éªŒï¼ˆéšå«åˆ†æï¼‰
- **äº¤é”™æ–‡æœ¬å¯†åº¦å½±å“**ï¼šCS:GO æ•°æ®å› æä¾›å¸§çº§åŠ¨ä½œä¿¡å·ï¼Œæ€§èƒ½å¢ç›Šè¿œå¤§äºä½“è‚²æ•°æ®ï¼ˆå¹³å‡ 1.9 ç§’ä¸€ä¸ª captionï¼‰ï¼Œè¯´æ˜**æ–‡æœ¬ä¿¡å·è¶Šå¯†é›†ï¼Œæ•ˆæœè¶Šå¥½**ã€‚
- **æ–‡æœ¬è´¨é‡å½±å“**ï¼šä½“è‚²æ•°æ®ä¸­çš„ VLM ç”Ÿæˆæ–‡æœ¬å­˜åœ¨å¹»è§‰ï¼Œé™åˆ¶äº†æ€§èƒ½ä¸Šé™ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **äº¤é”™ç”ŸæˆèŒƒå¼æœ‰æ•ˆ**ï¼šå°†è§†é¢‘ç”Ÿæˆåˆ†è§£ä¸ºâ€œè¯­è¨€è§„åˆ’ + è§†é¢‘æ‰§è¡Œâ€ä¸¤ä¸ªé˜¶æ®µï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆè´¨é‡å’Œå¯æ§æ€§ã€‚
2. âœ… **è¯­è¨€æ¨¡å‹å¯ä½œâ€œæ¨ç†å¼•æ“â€**ï¼šåˆ©ç”¨ LLM çš„å¼ºæ¨ç†èƒ½åŠ›æŒ‡å¯¼è§†é¢‘ç”Ÿæˆï¼Œå‡è½»äº†è§†è§‰ç”Ÿæˆæ¨¡å—çš„è¯­ä¹‰è´Ÿæ‹…ã€‚
3. âœ… **æ”¯æŒçµæ´»ç”¨æˆ·å¹²é¢„**ï¼šç”¨æˆ·å¯åœ¨ä»»æ„æ—¶é—´ç‚¹æ’å…¥æ–‡æœ¬æŒ‡ä»¤ï¼ŒåŠ¨æ€æ”¹å˜ç”Ÿæˆè½¨è¿¹ï¼ˆè§ Table 5 ç¤ºä¾‹ï¼‰ã€‚
4. âœ… **å¯æ‰©å±•è‡³çœŸå®ä¸–ç•Œæ•°æ®**ï¼šé€šè¿‡ VLM è‡ªåŠ¨åˆæˆäº¤é”™æ–‡æœ¬ï¼ŒTV2TV èƒ½æˆåŠŸåº”ç”¨äºä½“è‚²ç­‰å¼€æ”¾åŸŸåœºæ™¯ã€‚

### å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡äº¤é”™æ–‡æœ¬**ï¼šè‹¥è®­ç»ƒæ•°æ®ä¸­æ–‡æœ¬ä¸è§†é¢‘å¯¹é½ä¸å‡†æˆ–å¯†åº¦ä¸è¶³ï¼Œæ€§èƒ½ä¼šä¸‹é™ã€‚
- **VLM ç”Ÿæˆæ–‡æœ¬å­˜åœ¨å¹»è§‰**ï¼šåˆæˆæ ‡æ³¨å¯èƒ½å¼•å…¥é”™è¯¯åŠ¨ä½œæè¿°ï¼Œå½±å“æ¨¡å‹å­¦ä¹ ã€‚
- **è®¡ç®—æˆæœ¬è¾ƒé«˜**ï¼šåŒå¡” MoT æ¶æ„å‚æ•°é‡å¤§ï¼Œæ¨ç†å»¶è¿Ÿç›¸å¯¹è¾ƒé«˜ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æé«˜äº¤é”™æ–‡æœ¬çš„**ç”Ÿæˆç²¾åº¦ä¸æ—¶åºå¯†åº¦**ã€‚
- æ¢ç´¢æ›´é«˜æ•ˆçš„**å¤šæ¨¡æ€ç¼“å­˜æœºåˆ¶**ä»¥æ”¯æŒè¶…é•¿è§†é¢‘ç”Ÿæˆã€‚
- å°† TV2TV æ‰©å±•è‡³æ›´å¤šé¢†åŸŸï¼Œå¦‚ç”µå½±å™äº‹ã€æœºå™¨äººä»¿çœŸç­‰ã€‚
- ç»“åˆå¼ºåŒ–å­¦ä¹ å®ç°**é—­ç¯äº¤äº’å¼è§†é¢‘ç”Ÿæˆ**ã€‚

---

> **æ€»ç»“**ï¼šTV2TV æå‡ºäº†ä¸€ç§æ–°é¢–çš„â€œè¯­è¨€-è§†é¢‘äº¤é”™ç”Ÿæˆâ€èŒƒå¼ï¼Œé€šè¿‡è®©æ¨¡å‹â€œè¾¹æƒ³è¾¹åšâ€ï¼Œå®ç°äº†é«˜è´¨é‡ã€é«˜å¯æ§çš„è§†é¢‘ç”Ÿæˆã€‚å®ƒä¸ä»…åœ¨å—æ§æ¸¸æˆç¯å¢ƒä¸­è¡¨ç°å‡ºè‰²ï¼Œè¿˜èƒ½é€šè¿‡ VLM å¢å¼ºæ‰©å±•åˆ°çœŸå®ä¸–ç•Œè§†é¢‘ï¼Œä¸ºä¸‹ä¸€ä»£å¯æ¨ç†ã€å¯æ§åˆ¶çš„è§†é¢‘ç”Ÿæˆç³»ç»Ÿæä¾›äº†é‡è¦æ€è·¯ã€‚

</details>

---

### 6. [DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization](https://arxiv.org/abs/2512.03607)

**Authors**: Yusen Wu, Xiaotie Deng  
**Category**: cs.AI  
**Published**: 2025-12-05  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.03607v1  

#### Abstract
This paper proposes DeepRule, an integrated framework for automated business rule generation in retail assortment and pricing optimization. Addressing the systematic misalignment between existing theoretical models and real-world economic complexities, we identify three critical gaps: (1) data modal...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠDeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimizationã€‹æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

è¯¥è®ºæ–‡é’ˆå¯¹ä¼ ç»Ÿé›¶å”®è¡Œä¸šä¸­**å•†å“ç»„åˆï¼ˆassortmentï¼‰ä¸å®šä»·ä¼˜åŒ–**ä¸­å­˜åœ¨çš„å››å¤§ç³»ç»Ÿæ€§æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ä¸ªé›†æˆæ¡†æ¶ä»¥å¼¥åˆç†è®ºæ¨¡å‹ä¸ç°å®ç»æµå¤æ‚æ€§ä¹‹é—´çš„â€œæœ€ä¼˜æ€§-å¯è¡Œæ€§é¸¿æ²Ÿâ€ï¼ˆoptimality-operationality gapï¼‰ã€‚å…·ä½“é—®é¢˜åŒ…æ‹¬ï¼š

- **Data Modality Mismatch**ï¼šå¤§é‡å…³é”®å†³ç­–è¾“å…¥ï¼ˆå¦‚ç»é”€å•†è°ˆåˆ¤è®°å½•ã€å®¡æ‰¹æ–‡ä»¶ï¼‰ä¸ºéç»“æ„åŒ–æ–‡æœ¬ï¼Œè€Œç°æœ‰æ¨¡å‹ä¾èµ–ç»“æ„åŒ–äº¤æ˜“æ•°æ®ï¼Œå¯¼è‡´å®¢æˆ·ç”»åƒä¸å‡†ç¡®ã€‚
- **Dynamic Feature Entanglement**ï¼šä»·æ ¼å¼¹æ€§ã€å­£èŠ‚è¶‹åŠ¿ç­‰å¤šç»´å±æ€§å­˜åœ¨éçº¿æ€§è€¦åˆä¸æ—¶å˜ç‰¹æ€§ï¼Œä¼ ç»Ÿçº¿æ€§æˆ–é™æ€æ¨¡å‹éš¾ä»¥æ•æ‰ã€‚
- **Operational Infeasibility**ï¼šçœŸå®ä¸šåŠ¡å—å¤šå±‚æ¬¡çº¦æŸï¼ˆåº“å­˜ã€å“ç±»è¦†ç›–ã€åŒºåŸŸæ”¿ç­–ï¼‰ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†åŠ¨æ€è°ƒæ•´æ—¶æ˜“å¤±æ•ˆã€‚
- **Interpretability Deficits**ï¼šé»‘ç›’æ¨¡å‹ï¼ˆå¦‚Q-learningï¼‰ç¼ºä¹å¯å®¡è®¡æ€§ï¼Œéš¾ä»¥è¢«ä¸šåŠ¡æ–¹é‡‡çº³ï¼Œå°¤å…¶åœ¨è·¨ç»„ç»‡åè°ƒåœºæ™¯ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

ä½œè€…æå‡º **DeepRule**ï¼Œä¸€ä¸ªä¸‰å±‚æ¬¡é›†æˆæ¡†æ¶ï¼Œé¦–æ¬¡å°†**éç»“æ„åŒ–çŸ¥è¯†æ³¨å…¥ã€å¤šæ™ºèƒ½ä½“åšå¼ˆå»ºæ¨¡ä¸å¯è§£é‡Šç­–ç•¥ç”Ÿæˆ**é—­ç¯æ•´åˆï¼š

#### 1. **Hybrid Knowledge Fusion Engine**
- åˆ©ç”¨ **LLM** å¯¹éç»“æ„åŒ–æ–‡æœ¬ï¼ˆåè®®ã€å®¡æ‰¹ã€é”€å”®è¯„ä¼°ï¼‰è¿›è¡Œæ·±åº¦è¯­ä¹‰è§£æï¼Œæå– `store affiliation priors`ã€`reward functions` å’Œ `decision basis sets`ã€‚
- è®¾è®¡åŠ æƒèšåˆæœºåˆ¶ï¼ˆåŸºäºåœ°ç†è·ç¦»ä¸è¿è¥åŠå¾„ï¼‰ï¼Œè§£å†³å®¢æˆ·-é—¨åº—å½’å±æ¨¡ç³Šé—®é¢˜ï¼Œæ„å»ºé«˜ä¿çœŸå®¢æˆ·ç‰¹å¾å‘é‡ã€‚

#### 2. **Game-Theoretic Constrained Optimization**
- å¼•å…¥åŒè¾¹æ•ˆç”¨å‡½æ•°ï¼ˆbilateral utility functionsï¼‰ï¼Œå°†åˆ¶é€ å•†-åˆ†é”€å•†åˆ©æ¶¦å†åˆ†é…ä½œä¸ºå†…ç”Ÿä¼˜åŒ–ç›®æ ‡ã€‚
- åœ¨åˆ†å±‚çº¦æŸä¸‹è”åˆå»ºæ¨¡ä¾›éœ€åŠ¨æ€ï¼Œå®ç°ä¾›åº”é“¾åˆ©ç›ŠåŠ¨æ€åè°ƒã€‚

#### 3. **Interpretable Decision Distillation Interface**
- ç»“åˆ **LLM-guided Symbolic Regression** ä¸æœç´¢ä¼˜åŒ–ï¼ˆå¦‚MCTSï¼‰ï¼Œä»æ•°æ®ä¸­è‡ªåŠ¨å‘ç°æ•°å­¦è¡¨è¾¾å¼çš„å®šä»·è§„åˆ™ã€‚
- å°†ç»æµå…ˆéªŒï¼ˆå¦‚éè´Ÿå¼¹æ€§ã€æˆæœ¬-æ”¶ç›Šå¹³è¡¡ï¼‰ä½œä¸ºç¡¬çº¦æŸåµŒå…¥æœç´¢è¿‡ç¨‹ï¼Œç¡®ä¿è§„åˆ™ç¬¦åˆå•†ä¸šé€»è¾‘ã€‚
- é‡‡ç”¨ä¸¤é˜¶æ®µä¼˜åŒ–ï¼šå…ˆç”±LLMç”Ÿæˆå‡½æ•°ç»“æ„ï¼Œå†é€šè¿‡æ¢¯åº¦æ³•ä¼˜åŒ–å‚æ•°ï¼Œé¿å…ç»„åˆçˆ†ç‚¸ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•å±€é™ | DeepRuleä¼˜åŠ¿ |
|------|--------------|-------------|
| **æ•°æ®åˆ©ç”¨** | ä»…ç”¨ç»“æ„åŒ–äº¤æ˜“æ•°æ® | èåˆæ–‡æœ¬ã€åœ°ç†ã€è¡Œä¸ºç­‰å¤šæºå¼‚æ„æ•°æ® |
| **æ¨¡å‹å¯è§£é‡Šæ€§** | é»‘ç›’æ¨¡å‹éš¾å®¡è®¡ | è¾“å‡ºå¯è¯»æ•°å­¦å…¬å¼ï¼Œæ”¯æŒä¸šåŠ¡éªŒè¯ |
| **åŠ¨æ€é€‚åº”æ€§** | é™æ€æˆ–çº¿æ€§å‡è®¾ | æ”¯æŒéçº¿æ€§ã€æ—¶å˜ç‰¹å¾å»ºæ¨¡ |
| **çº¦æŸå¤„ç†** | è¿‘ä¼¼æˆ–å†å²å¤ç”¨ | æ˜¾å¼ç¼–ç å¤šå±‚çº§ä¸šåŠ¡è§„åˆ™ |
| **è·¨ç»„ç»‡ååŒ** | å¿½ç•¥åˆ©æ¶¦åˆ†é…æœºåˆ¶ | å†…ç”ŸåŒ–ä¾›åº”é“¾åšå¼ˆå…³ç³» |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- ä¸»è¦å®éªŒåŸºäºæŸ**é€ çº¸åˆ¶é€ ä¼ä¸šçš„çœŸå®çº¿ä¸Šåé¦ˆç³»ç»Ÿæ•°æ®**ï¼š
  - å†å²å‘è´§è®°å½•ï¼š$ M = 8.6 \times 10^6 $ æ¡
  - SKUæ•°é‡ï¼š$ N_o = 215 $
  - å®¢æˆ·æ•°é‡ï¼š$ N_i = 2362 $
  - ç‰¹å¾ç»´åº¦ï¼šå®¢æˆ·62ç»´ï¼ˆå«åŒºåŸŸã€äººå£ç»Ÿè®¡ã€ä¸šåŠ¡æ ‡ç­¾ï¼‰ã€SKUå«ç»“æ„åŒ–æ ‡ç­¾ä¸éç»“æ„åŒ–é£æ ¼/é¦™å‹æè¿°

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **ä»»åŠ¡å®šä¹‰**
- ä¸ºæ¯ä¸ªå®¢æˆ·æ¨èä¸€ä¸ªæœˆçš„å•†å“ç»„åˆï¼ˆæ˜¯å¦è¿›è´§æŸSKUï¼‰åŠå»ºè®®ä»·æ ¼ã€‚
- è¾“å‡ºéœ€æ»¡è¶³ä»¥ä¸‹ç¡¬çº¦æŸï¼š
  1. æ€»æ¨èé‡‡è´­é¢åœ¨å†å²å‡å€¼ Â±5% èŒƒå›´å†…ï¼›
  2. æ¯ä¸ªä¸»å“ç±»æœ€å¤šæ¨è5ä¸ªSKUï¼›
  3. è‡³å°‘è¦†ç›–2ä¸ªä¸åŒå“ç±»ã€‚

#### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **Test Total Sales Volume** | æµ‹è¯•é›†æ€»é”€å”®é¢ï¼ˆå•ä½ï¼šç™¾ä¸‡ï¼‰ |
| **Test Total Profit** | æµ‹è¯•é›†æ€»åˆ©æ¶¦ï¼ˆå•ä½ï¼šåä¸‡ï¼‰ |
| **Customers Constraints Violating** | è¿åä¸šåŠ¡çº¦æŸçš„å®¢æˆ·æ•° |
| **First Epoch to Reach Target** | è¾¾åˆ°é¢„è®¾é”€å”®/åˆ©æ¶¦é˜ˆå€¼æ‰€éœ€çš„è¿­ä»£è½®æ¬¡ |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

å…±æ¯”è¾ƒå…­ç§æ–¹æ³•ï¼š
1. **Low-Rank Bandit**ï¼ˆMueller et al., 2019ï¼‰
2. **Context-Based Clustering**ï¼ˆMiao et al., 2022ï¼‰
3. **Model-Free Assortment Pricing**ï¼ˆChen et al., 2023ï¼‰
4. **Systematic B2B Recommendation**ï¼ˆColias et al., 2023ï¼‰
5. **Evolutionary Algorithm**ï¼ˆé—ä¼ ç¼–ç¨‹ï¼‰
6. **Reinforcement Learning**ï¼ˆåŸºäºMDPçš„ç¬¦å·å›å½’ï¼‰

æ­¤å¤–è¿˜åŒ…æ‹¬ï¼š
- GPT + Monte Carlo Sampling
- LLMç›´æ¥æ¨ç†ï¼ˆDirect Rule Generationï¼‰
- LLMç»“æ„ç”Ÿæˆ + ä¼˜åŒ–å™¨ï¼ˆå¸¦/ä¸å¸¦å¾®è°ƒï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰**

| æ–¹æ³• | é”€å”®é¢ ($\times10^6$) | åˆ©æ¶¦ ($\times10^5$) |
|-------------------------------|------------------------|---------------------|
| Low-Rank Bandit | 7.450 | 4.174 |
| Context-Based Clustering | 5.128 | 5.258 |
| Model-Free Assortment Pricing | 7.160 | 4.882 |
| Systematic B2B Recommendation | 5.978 | 5.420 |
| **LLM+Opt (N=50)** | 6.223 | 5.181 |
| **LLM+Opt (N=100)** | 6.609 | 5.366 |
| **LLM+Opt (N=300)** | **6.849** | **5.643** |

> âœ… **DeepRule åœ¨ N=300 æ—¶å®ç°æœ€é«˜é”€å”®é¢ä¸åˆ©æ¶¦ï¼Œæ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿**

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

- **ä½ç§©Banditä¸Model-Freeæ–¹æ³•**ï¼šè™½é”€å”®é¢é«˜ï¼Œä½†åˆ©æ¶¦åä½ä¸”çº¦æŸè¿åä¸¥é‡ â†’ **ç‰ºç‰²åˆ©æ¶¦æ¢é”€é‡**
- **èšç±»æ–¹æ³•**ï¼šåˆ©æ¶¦è¾ƒé«˜ä½†é”€å”®é¢æœ€ä½ â†’ **è¿‡äºä¿å®ˆ**
- **B2Bæ¨èç®—æ³•**ï¼šé”€å”®-åˆ©æ¶¦å¹³è¡¡è¾ƒå¥½ï¼Œä½†ä»ä½äº DeepRule
- **DeepRule è¡¨ç°**ï¼š
  - åœ¨ N=50 æ—¶å·²è¶…è¶Šèšç±»æ–¹æ³•çš„åˆ©æ¶¦ï¼Œå¹¶æ¥è¿‘B2Bæ°´å¹³ï¼›
  - N=100 æ—¶å…¨é¢è¶…è¶ŠB2Bï¼›
  - N=300 æ—¶åˆ©æ¶¦è¾¾ **5.643Ã—10âµ**ï¼Œè¾ƒB2Bæå‡çº¦ **4.1%**

---

### **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰**

#### **ä¸åŒLLMåº•åº§æ¨¡å‹å¯¹æ¯”ï¼ˆN=50ï¼‰**

| LLM æ¨¡å‹ | é”€å”®é¢ ($\times10^6$) | åˆ©æ¶¦ ($\times10^5$) |
|----------|------------------------|---------------------|
| GPT-4o | 6.345 | **5.426** |
| DeepSeek-R1 | 6.220 | 5.230 |
| Gemini | 6.171 | 5.095 |
| Qwen3-32B | 5.960 | 4.991 |
| Claude-3.5 | 6.186 | 5.311 |
| Llama4-Scout | 5.992 | 4.687 |

> ğŸ” å‘ç°ï¼š
> - æ‰€æœ‰ä¸»æµLLMå‡æ˜¾è‘—ä¼˜äºéLLMåŸºçº¿ï¼›
> - ä¸åŒLLMé—´æ€§èƒ½å·®å¼‚æ™®é <5%ï¼Œè¡¨æ˜æ•ˆæœä¸»è¦æ¥è‡ª**é€šç”¨æ¨ç†èƒ½åŠ›**è€Œéç‰¹å®šæ•°å­¦ä¸“é•¿ï¼›
> - **Llama4-Scoutè¡¨ç°æœ€å·®**ï¼Œæç¤ºå¹¶éæ‰€æœ‰LLMéƒ½é€‚åˆæ­¤ä»»åŠ¡ã€‚

#### **è®°å¿†æœºåˆ¶çš„å½±å“ï¼ˆå›¾7ï¼‰**
- åŠ å…¥**ä¼˜åŒ–è®°å¿†æ¨¡å—**åï¼ŒLLM+Optimization çš„ MAE ä¸‹é™æ›´å¿«ï¼Œæ”¶æ•›æ›´ç¨³å®šï¼›
- è¯´æ˜ä¿ç•™å†å²è¿­ä»£ä¸­çš„æœ‰æ•ˆä¿®æ”¹å¯é˜²æ­¢ç­–ç•¥é€€åŒ–ï¼Œä¿ƒè¿›å•è°ƒæ”¹è¿›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. **LLM æ˜¯è¿æ¥éç»“æ„åŒ–çŸ¥è¯†ä¸é‡åŒ–å†³ç­–çš„å…³é”®æ¡¥æ¢**  
   - å¯æœ‰æ•ˆè§£ææ–‡æœ¬ä¸­çš„éšå«è§„åˆ™ï¼ˆå¦‚å®¡æ‰¹åå¥½ã€å“ç‰Œå€¾å‘ï¼‰ï¼Œå¼¥è¡¥æ•°æ®ç¼ºå¤±ã€‚
   
2. **Symbolic Regression + LLM æ„æˆå¯è§£é‡ŠAIçš„æ–°èŒƒå¼**  
   - ç›¸æ¯”çº¯é»‘ç›’æ¨¡å‹ï¼Œç”Ÿæˆçš„æ•°å­¦è¡¨è¾¾å¼ä¾¿äºå®¡è®¡ã€è°ƒè¯•ä¸åˆè§„å®¡æŸ¥ï¼›
   - ç»“åˆç»æµå…ˆéªŒçº¦æŸå¯ä¿è¯è§„åˆ™åˆç†æ€§ã€‚

3. **ä¸¤é˜¶æ®µä¼˜åŒ–ï¼ˆç»“æ„ç”Ÿæˆ + å‚æ•°æ±‚è§£ï¼‰æ˜¾è‘—æå‡æ•ˆç‡**  
   - é¿å…ç«¯åˆ°ç«¯æœç´¢çš„ç»„åˆçˆ†ç‚¸ï¼›
   - LLMæ“…é•¿ç”Ÿæˆé€»è¾‘ç»“æ„ï¼Œæ•°å€¼ä¼˜åŒ–äº¤ç”±ç»å…¸ç®—æ³•å®Œæˆã€‚

4. **DeepRule å®ç°äº†å­¦æœ¯ä¸¥è°¨æ€§ä¸å·¥ä¸šé²æ£’æ€§çš„ç»Ÿä¸€**  
   - åœ¨çœŸå®é›¶å”®ç¯å¢ƒä¸­éªŒè¯å¯è¡Œï¼Œå…·å¤‡å·¥ç¨‹è½åœ°æ½œåŠ›ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

1. **LLM æ¨ç†æˆæœ¬è¾ƒé«˜**ï¼šæ¯è½®è¿­ä»£éœ€å¤šæ¬¡è°ƒç”¨LLMï¼Œä¸é€‚åˆè¶…å®æ—¶åœºæ™¯ï¼›
2. **å±€éƒ¨æŒ¯è¡é£é™©**ï¼šLLMå¯èƒ½åå¤ä¿®æ”¹åŒä¸€è§„åˆ™ï¼Œç¼ºä¹å…¨å±€æ”¶æ•›ä¿éšœï¼›
3. **å¯¹LLMè´¨é‡æ•æ„Ÿ**ï¼šéƒ¨åˆ†å¼€æºæ¨¡å‹ï¼ˆå¦‚Llama4-Scoutï¼‰è¡¨ç°ä¸ä½³ï¼›
4. **å†·å¯åŠ¨ä¾èµ–åˆå§‹è§„åˆ™**ï¼šè‹¥æ— é¢†åŸŸä¸“å®¶æä¾›ç§å­è§„åˆ™ï¼ŒåˆæœŸæ¢ç´¢æ•ˆç‡è¾ƒä½ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **Cross-Domain Generalization**  
   - æ¢ç´¢åœ¨æ‹å–ç«ä»·ã€æœºåˆ¶è®¾è®¡ã€å…±è¯†åè®®ä¼˜åŒ–ç­‰é¢†åŸŸçš„è¿ç§»èƒ½åŠ›ã€‚

2. **Insight-Driven Refinement**  
   - å¼•å…¥æ•°æ®åˆ†æAgentè‡ªåŠ¨ç”Ÿæˆå¯è§†åŒ–æ´å¯Ÿå¹¶æŒ‡å¯¼LLMåæ€ï¼Œæå‡ä¼˜åŒ–æ•ˆç‡ï¼ˆå‚è€ƒ Busch & Leopold, 2024ï¼‰ã€‚

3. **Data-Scalable Generative Modeling**  
   - åœ¨æ•°æ®ä¸°å¯Œåœºæ™¯ä¸‹è®­ç»ƒé¢†åŸŸä¸“ç”¨ Foundation Modelï¼ˆå¦‚ Sun et al., 2024ï¼‰ï¼Œå®ç°ç«¯åˆ°ç«¯ä¸ªæ€§åŒ–æ¨èç”Ÿæˆã€‚

4. **ç†è®ºä¼˜åŒ–è¾¹ç•Œç ”ç©¶**  
   - é‡åŒ–å˜é‡é‡è¦æ€§ã€å‘ç°æˆæœ¬ã€é¢„æœŸå¢ç›Šä¿¡å¿ƒåŒºé—´ï¼Œå»ºç«‹ç¬¦å·å›å½’çš„ç†è®ºæ”¶æ•›ç•Œã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **DeepRule æˆåŠŸæ„å»ºäº†ä¸€ä¸ªèåˆ LLM è¯­ä¹‰ç†è§£ã€åšå¼ˆè®ºå»ºæ¨¡ä¸ Symbolic Regression çš„é—­ç¯å†³ç­–ç³»ç»Ÿï¼Œåœ¨ä¿æŒé«˜åº¦å¯è§£é‡Šæ€§çš„åŒæ—¶ï¼Œå®ç°äº†å¯¹ä¼ ç»Ÿé›¶å”®å®šä»·ä¸é€‰å“é—®é¢˜çš„å…¨é¢è¶…è¶Šã€‚**

</details>

---

### 7. [Context-Aware Mixture-of-Experts Inference on CXL-Enabled GPU-NDP Systems](https://arxiv.org/abs/2512.04476)

**Authors**: Zehao Fan, Zhenyu Liu, Yunzhen Liu, Yayue Hou, Hadjer Benmeziane, Kaoutar El Maghraoui, Liu Liu  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2512.04476v1  

#### Abstract
Mixture-of-Experts (MoE) models scale large language models through conditional computation, but inference becomes memory-bound once expert weights exceed the capacity of GPU memory. In this case, weights must be offloaded to external memory, and fetching them incurs costly and repeated transfers. W...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šContext-Aware Mixture-of-Experts Inference on CXL-Enabled GPU-NDP Systems**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
Mixture-of-Experts (MoE) æ¨¡å‹é€šè¿‡æ¡ä»¶è®¡ç®—æ‰©å±•å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œä½†ç”±äºä¸“å®¶å‚æ•°æ€»é‡è¿œè¶…å•ä¸ª GPU çš„æ˜¾å­˜å®¹é‡ï¼Œæ¨ç†è¿‡ç¨‹æˆä¸º **memory-bound**ã€‚å½“ä¸“å®¶æƒé‡è¢«å¸è½½åˆ°å¤–éƒ¨å†…å­˜ï¼ˆå¦‚ CXL å†…å­˜ï¼‰æ—¶ï¼Œé¢‘ç¹çš„å‚æ•°è¿ç§»ä¼šå¸¦æ¥é«˜æ˜‚çš„ PCIe ä¼ è¾“å¼€é”€ï¼Œä¸¥é‡é™ä½ GPU åˆ©ç”¨ç‡ã€‚

æ­¤å¤–ï¼Œç°æœ‰åŸºäº GPU-NDPï¼ˆNear-Data Processingï¼‰çš„ç³»ç»Ÿå¤§å¤šé‡‡ç”¨ **context-agnostic** ç­–ç•¥ï¼ˆé™æ€æˆ–æŒ‰éœ€è°ƒåº¦ï¼‰ï¼Œæ— æ³•é€‚åº” MoE è·¯ç”±åœ¨ä¸åŒè¾“å…¥åºåˆ—ã€è§£ç æ­¥ä¹‹é—´çš„åŠ¨æ€å˜åŒ–ï¼Œå¯¼è‡´ä¸å¿…è¦çš„ä¸“å®¶è¿ç§»å’Œè´Ÿè½½ä¸å‡ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯**

æœ¬æ–‡æå‡ºäº†ä¸€ç§ **context-aware** çš„ MoE æ¨ç†ç³»ç»Ÿï¼Œç»“åˆ **CXL-attached GPU-NDP æ¶æ„**ï¼Œå®ç°é«˜æ•ˆã€ä½å»¶è¿Ÿçš„ MoE æ¨ç†ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### **(1) åŸºäºé¢„å¡«å……é˜¶æ®µï¼ˆprefillï¼‰æ¿€æ´»ç»Ÿè®¡çš„ä¸“å®¶æ”¾ç½®ç­–ç•¥ï¼ˆPrefill-guided Expert Placementï¼‰**
- åœ¨ prefill é˜¶æ®µæ”¶é›†æ¯ä¸ªä¸“å®¶çš„æ¿€æ´»é¢‘ç‡ $P_{l,e}$ å’Œè·¯ç”±å¾—åˆ†æ€»å’Œ $W_{l,e}$ã€‚
- åˆ©ç”¨åŠ æƒé‡è¦æ€§è¯„åˆ† $S_{l,e} = \alpha P_{l,e} + (1-\alpha) W_{l,e}$ å¯¹ä¸“å®¶æ’åºã€‚
- å°†æœ€é‡è¦çš„å‰ K ä¸ªä¸“å®¶å›ºå®šè¿ç§»åˆ° GPU HBM ä¸­ä»¥ FP16 æ‰§è¡Œï¼ˆâ€œçƒ­ä¸“å®¶â€ï¼‰ï¼Œå…¶ä½™ä¸“å®¶ä¿ç•™åœ¨ CXL-NDP è®¾å¤‡ä¸Šæ‰§è¡Œï¼ˆâ€œå†·ä¸“å®¶â€ï¼‰ã€‚
- **ä¼˜åŠ¿**ï¼šä»…åœ¨ prefill åè¿›è¡Œä¸€æ¬¡è¿ç§»ï¼Œé¿å…äº†è§£ç é˜¶æ®µé¢‘ç¹è¿ç§»ï¼Œæ˜¾è‘—å‡å°‘å¸¦å®½å‹åŠ›ã€‚

#### **(2) é¢å‘ NDP çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ··åˆç²¾åº¦é‡åŒ–ï¼ˆContext-aware Mixed-Precision Quantizationï¼‰**
- ä¸ºæ¯ä¸ª NDP ä¸Šçš„ä¸“å®¶ç¼“å­˜å¤šä¸ª GPTQ é‡åŒ–å‰¯æœ¬ï¼ˆ1~4 bitï¼‰ã€‚
- åŸºäº prefill é˜¶æ®µçš„é‡è¦æ€§ä¿¡æ¯å’Œé¢„æ„å»ºçš„é‡åŒ–æŸå¤±è¡¨ï¼Œé‡‡ç”¨ **prefix-structured åˆ†é…ç­–ç•¥** ç»™ä¸åŒä¸“å®¶åˆ†é…ä¸åŒ bitwidthã€‚
- åœ¨æ¯å±‚å¹³å‡ bitwidth çº¦æŸä¸‹æœ€å¤§åŒ–æ•´ä½“ç²¾åº¦æ”¶ç›Šã€‚
- **ä¼˜åŠ¿**ï¼šåŒ¹é… NDP æœ‰é™çš„ç®—åŠ›èµ„æºï¼Œå‡è½»è®¡ç®—ç“¶é¢ˆï¼ŒåŒæ—¶æœ€å°åŒ–ç²¾åº¦æŸå¤±ã€‚

#### **(3) ç³»ç»Ÿçº§ååŒè®¾è®¡**
- å°†ä¸“å®¶æ”¾ç½®ä¸é‡åŒ–å†³ç­–ç»Ÿä¸€åŸºäº prefill é˜¶æ®µçš„è¿è¡Œæ—¶ç»Ÿè®¡ä¿¡æ¯ï¼Œå½¢æˆé—­ç¯ä¼˜åŒ–ã€‚
- å®ç° GPU ä¸ NDP çš„å¹¶è¡Œæ‰§è¡Œï¼Œå¹¶å°†æ˜‚è´µçš„ **parameter movement** è½¬æ¢ä¸ºæ›´è½»é‡çš„ **activation movement**ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹é¢ | ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ MoNDEï¼‰ | æœ¬æ–‡æ–¹æ³• |
|------|------------------------|----------|
| æ”¾ç½®ç­–ç•¥ | context-agnostic / reactive | context-aware / proactive |
| è¿ç§»æ¬¡æ•° | å¤šæ¬¡ï¼ˆæŒ‰éœ€ï¼‰ | æ¯åºåˆ—ä»…ä¸€æ¬¡ |
| NDP é‡åŒ– | å›ºå®šç²¾åº¦ï¼ˆé€šå¸¸ 4-bitï¼‰ | åŠ¨æ€æ··åˆç²¾åº¦ï¼ˆ1â€“4 bitï¼‰ |
| æ€§èƒ½ç“¶é¢ˆ | å‚æ•°è¿ç§» + NDP è®¡ç®—å‹åŠ› | æ˜¾è‘—ç¼“è§£ä¸¤è€… |
| å‡†ç¡®ç‡ä¿ç•™ | é«˜ï¼ˆå…¨ç²¾åº¦ï¼‰ | æ¥è¿‘å…¨ç²¾åº¦ï¼ˆä»… 0.13% ä¸‹é™ï¼‰ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ¨¡å‹ä¸æ•°æ®é›†**

#### **æ¨¡å‹**
- **Mixtral-8Ã—7B**ï¼š32 å±‚ï¼Œæ¯å±‚ 8 ä¸ªä¸“å®¶ï¼ŒTop-2 è·¯ç”±
- **Mixtral-8Ã—22B**ï¼š56 å±‚ï¼Œæ¯å±‚ 8 ä¸ªä¸“å®¶ï¼ŒTop-2 è·¯ç”±

#### **æ•°æ®é›†**
- **æ¨ç†ä»»åŠ¡åŸºå‡†**ï¼š
  - MMLUï¼ˆ5-shotï¼‰
  - MathQAã€HellaSwagã€ARC-Easyã€ARC-Challengeã€BoolQã€WinoGrandeã€PIQAï¼ˆzero-shotï¼‰
- **æ ¡å‡†æ•°æ®é›†ï¼ˆç”¨äºæ„å»ºé‡åŒ–æŸå¤±è¡¨ï¼‰**ï¼š
  - C4 æ•°æ®é›†ï¼ˆ1024 ä¸ªæ ·æœ¬ï¼‰

---

### **å®éªŒè®¾ç½®**

#### **ç¡¬ä»¶é…ç½®ï¼ˆæ¨¡æ‹Ÿç¯å¢ƒï¼‰**
åŸºäº Ramulator æ„å»ºçš„ GPU-NDP æ¨¡æ‹Ÿå™¨ï¼Œé…ç½®å¦‚ä¸‹ï¼š

| ç»„ä»¶ | è§„æ ¼ |
|------|------|
| GPU | NVIDIA H100ï¼ˆ80GB HBM3ï¼‰ |
| NDP è®¾å¤‡ | DDR-based CXL-attachedï¼Œ512GB å®¹é‡ï¼Œ512 GB/s å¸¦å®½ |
| Interconnect | PCIe Gen4 Ã—16 |
| NDP Compute | 64 ä¸ªå¤„ç†å•å…ƒï¼ˆ4Ã—4 è„‰åŠ¨é˜µåˆ—ï¼‰ï¼Œ1GHz |

#### **ä¸“å®¶åˆ†å¸ƒç­–ç•¥**
- **Mixtral-8Ã—7B**ï¼šæ¯å±‚ 4 ä¸ªçƒ­ä¸“å®¶æ”¾ GPUï¼Œ4 ä¸ªå†·ä¸“å®¶æ”¾ NDP
- **Mixtral-8Ã—22B**ï¼šæ¯å±‚ 2 ä¸ªçƒ­ä¸“å®¶æ”¾ GPUï¼Œ6 ä¸ªå†·ä¸“å®¶æ”¾ NDP

#### **è¯„ä¼°æŒ‡æ ‡**
- **End-to-end Latency**
- **Decoding Throughput**ï¼ˆtokens/secï¼‰
- **NDP-side Latency**
- **Model Accuracy**ï¼ˆå¤šä»»åŠ¡å¹³å‡å‡†ç¡®ç‡ï¼‰

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **MoNDE [18]**ï¼šå½“å‰æœ€å…ˆè¿›çš„ GPU-NDP MoE ç³»ç»Ÿï¼Œcontext-agnosticï¼Œæ”¯æŒçƒ­ä¸“å®¶é©»ç•™ GPU
- **HOBBIT [31]**ï¼šGPU-only æ··åˆç²¾åº¦ä¸“å®¶å¸è½½ç³»ç»Ÿï¼ˆä»£è¡¨ä¼ ç»Ÿæ–¹æ¡ˆï¼‰
- **Original Full-Precision Model**ï¼šä½œä¸ºç²¾åº¦ä¸Šé™å‚è€ƒ

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **ç«¯åˆ°ç«¯åŠ é€Ÿæ¯”ï¼ˆvs. MoNDEï¼‰**
| æ¨¡å‹ | æ–¹æ³• | åŠ é€Ÿæ¯”ï¼ˆEnd-to-Endï¼‰ | è§£ç ååæå‡ |
|------|------|------------------|-------------|
| Mixtral-8Ã—7B | Ours-3bit | **6.6â€“8.3Ã—** | **8.7Ã—** |
| Mixtral-8Ã—7B | Ours-2bit | **7.9â€“10.6Ã—** | **11.2Ã—** |
| Mixtral-8Ã—22B | Ours-3bit | **7.6â€“8.7Ã—** | **8.9Ã—** |
| Mixtral-8Ã—22B | Ours-2bit | **9.5â€“11.2Ã—** | **11.5Ã—** |

> âœ… **æœ€é«˜è¾¾ 11.5Ã— è§£ç ååæå‡**

#### **NDP ä¾§å»¶è¿Ÿé™ä½**
- Ours-3bitï¼šçº¦ **5Ã—** é™ä½
- Ours-2bitï¼šçº¦ **8Ã—** é™ä½  
â†’ è¡¨æ˜æ··åˆç²¾åº¦æœ‰æ•ˆç¼“è§£ NDP è®¡ç®—ç“¶é¢ˆ

#### **å¯¹æ¯” GPU-only åŸºçº¿ï¼ˆHOBBITï¼‰**
- Ours-2bit åœ¨ Mixtral-8Ã—7B ä¸Šè¾¾åˆ° **æœ€é«˜ 18Ã— é€Ÿåº¦æå‡**
- åœ¨ Mixtral-8Ã—22B ä¸Šè¾¾ **19Ã— æå‡**
â†’ æ˜¾ç¤º CXL-NDP + context-aware è®¾è®¡çš„å·¨å¤§æ½œåŠ›

---

### **æ¶ˆèå®éªŒç»“æœ**

#### **ç²¾åº¦å¯¹æ¯”ï¼ˆMixtral-8Ã—7Bï¼Œå¹³å‡å‡†ç¡®ç‡ï¼‰**
| æ–¹æ³• | å¹³å‡å‡†ç¡®ç‡ | ç›¸å¯¹åŸå§‹ä¸‹é™ |
|------|------------|--------------|
| Original (MoNDE) | 70.03% | 0% |
| Ours-3bit | 69.90% | **-0.13%** |
| Ours-2bit | 66.68% | -3.35% |
| Ours-3bit w/o Bitwidth Selector | 69.71% | -0.32% |
| Ours-2bit w/o Bitwidth Selector | 63.48% | -6.55% |

#### **å…³é”®å‘ç°**
- **Expert Bitwidth Selector è´¡çŒ®æ˜¾è‘—**ï¼š
  - åœ¨ 2-bit åœºæ™¯ä¸‹å¸¦æ¥ **3.2% çš„å¹³å‡ç²¾åº¦å¢ç›Š**
  - éªŒè¯äº† context-aware é‡åŒ–ç­–ç•¥çš„æœ‰æ•ˆæ€§
- å³ä½¿æ˜¯ 3-bit é‡åŒ–ï¼Œç²¾åº¦å‡ ä¹æ— æŸï¼ˆä»… 0.13% ä¸‹é™ï¼‰

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **MoE ä¸“å®¶æ¿€æ´»å…·æœ‰å¼ºä¸Šä¸‹æ–‡ä¾èµ–æ€§**ï¼š
   - ä¸åŒè¾“å…¥åºåˆ—ã€ä¸åŒè§£ç æ­¥çš„æ¿€æ´»æ¨¡å¼å·®å¼‚å·¨å¤§
   - é™æ€æˆ–å…¨å±€é¢‘ç‡ç­–ç•¥æ— æ³•æœ‰æ•ˆæ•æ‰â€œçƒ­ä¸“å®¶â€

2. **Prefill é˜¶æ®µå¯ä½œä¸ºè§£ç è¡Œä¸ºçš„è‰¯å¥½é¢„æµ‹å™¨**ï¼š
   - Prefill ä¸ decoding çš„ä¸“å®¶æ¿€æ´»åˆ†å¸ƒç›¸ä¼¼åº¦é«˜è¾¾ **0.89**
   - æ”¯æŒä½¿ç”¨ prefill ç»Ÿè®¡ä¿¡æ¯è¿›è¡Œ **proactive ä¸“å®¶æ”¾ç½®**

3. **context-aware è®¾è®¡å¤§å¹…æå‡ç³»ç»Ÿæ•ˆç‡**ï¼š
   - é€šè¿‡ä¸€æ¬¡è¿ç§» + å›ºå®šæ˜ å°„ï¼Œæå¤§å‡å°‘è·¨è®¾å¤‡é€šä¿¡
   - æ··åˆç²¾åº¦é‡åŒ–è¿›ä¸€æ­¥é‡Šæ”¾ NDP è®¡ç®—å‹åŠ›

4. **æ€§èƒ½ä¸ç²¾åº¦å–å¾—è‰¯å¥½å¹³è¡¡**ï¼š
   - æœ€é«˜ **11.5Ã— è§£ç ååæå‡**
   - 3-bit è®¾ç½®ä¸‹ä»… **0.13% å¹³å‡ç²¾åº¦æŸå¤±**

---

### **æ–¹æ³•çš„å±€é™æ€§**
1. **ä¾èµ– prefill é˜¶æ®µè´¨é‡**ï¼š
   - è‹¥ prefill è¾ƒçŸ­æˆ–ä»£è¡¨æ€§ä¸è¶³ï¼Œå¯èƒ½å¯¼è‡´é”™è¯¯çš„ä¸“å®¶é€‰æ‹©
2. **NDP ç®—åŠ›ä»å—é™**ï¼š
   - å³ä½¿é‡åŒ–åï¼Œæä½ç«¯ bitwidthï¼ˆå¦‚ 1-bitï¼‰å¯èƒ½å½±å“æ•°å€¼ç¨³å®šæ€§
3. **æ‰©å±•æ€§å¾…éªŒè¯**ï¼š
   - å½“ä¸“å®¶æ•°é‡æ›´å¤šæˆ–è·¯ç”± k æ›´å¤§æ—¶ï¼Œplacement ä¸ quantization å¼€é”€æ˜¯å¦ä»å¯æ§ï¼Ÿ

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **åŠ¨æ€è°ƒæ•´æœºåˆ¶**ï¼š
   - å¼•å…¥è½»é‡çº§ç›‘æ§ï¼Œåœ¨é•¿åºåˆ—ä¸­é€‚æ—¶æ›´æ–°ä¸“å®¶æ”¾ç½®
2. **è”åˆè®­ç»ƒ-aware é‡åŒ–**ï¼š
   - ç»“åˆé‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQATï¼‰è¿›ä¸€æ­¥å‹ç¼© NDP ä¾§å¼€é”€
3. **å¤š NDP è®¾å¤‡è°ƒåº¦**ï¼š
   - æ‰©å±•è‡³å¤šä¸ª CXL-NDP è®¾å¤‡ï¼Œç ”ç©¶è´Ÿè½½å‡è¡¡ä¸é€šä¿¡ä¼˜åŒ–
4. **æ”¯æŒåŠ¨æ€ k å€¼è·¯ç”±**ï¼š
   - é€‚é…æ›´çµæ´»çš„ MoE å˜ä½“ï¼ˆå¦‚ Top-k è‡ªé€‚åº”ï¼‰

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬è®ºæ–‡æå‡ºäº†é¦–ä¸ª **context-aware** çš„ CXL-NDP MoE æ¨ç†ç³»ç»Ÿï¼Œåˆ©ç”¨ **prefill é˜¶æ®µç»Ÿè®¡ä¿¡æ¯æŒ‡å¯¼ä¸“å®¶æ”¾ç½®ä¸æ··åˆç²¾åº¦é‡åŒ–**ï¼Œå®ç°äº†é«˜è¾¾ **11.5Ã— è§£ç ååæå‡**ï¼Œä¸”ç²¾åº¦æŸå¤±æå°ï¼ˆä»… 0.13%ï¼‰ï¼Œä¸ºå¤§è§„æ¨¡ MoE æ¨¡å‹çš„é«˜æ•ˆéƒ¨ç½²æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 8. [RapidUn: Influence-Driven Parameter Reweighting for Efficient Large Language Model Unlearning](https://arxiv.org/abs/2512.04457)

**Authors**: Guoshenghui Zhao, Huawei Lin, Weijie Zhao  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.04457v1  

#### Abstract
Removing specific data influence from large language models (LLMs) remains challenging, as retraining is costly and existing approximate unlearning methods are often unstable. The challenge is exacerbated when the forget set is small or imbalanced. We introduce RapidUn, an influence-driven and param...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šRapidUn: Influence-Driven Parameter Reweighting for Efficient Large Language Model Unlearning**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼š**è®°å¿†éƒ¨åˆ†è®­ç»ƒæ•°æ®**ï¼Œè¿™å¯èƒ½å¯¼è‡´éšç§æ³„éœ²ã€ç‰ˆæƒä¾µæƒæˆ–æœ‰å®³è¡Œä¸ºæ®‹ç•™ï¼ˆå¦‚é€šè¿‡æ•°æ®æŠ•æ¯’æ³¨å…¥çš„æ¶æ„å“åº”ï¼‰ã€‚å½“éœ€è¦ç§»é™¤ç‰¹å®šæ•°æ®çš„å½±å“æ—¶ï¼Œä¼ ç»Ÿæ–¹æ³•æ˜¯é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œä½†è¿™å¯¹æ•°åäº¿å‚æ•°çš„æ¨¡å‹è€Œè¨€è®¡ç®—æˆæœ¬è¿‡é«˜ï¼Œä¸åˆ‡å®é™…ã€‚

ç°æœ‰çš„è¿‘ä¼¼é—å¿˜æ–¹æ³•ï¼ˆapproximate unlearningï¼‰å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **å½±å“æ„ŸçŸ¥ç¼ºå¤±ï¼ˆinfluence-blindï¼‰**ï¼šå¤šæ•°æ–¹æ³•å¯¹æ‰€æœ‰â€œé—å¿˜é›†â€æ ·æœ¬é‡‡ç”¨å‡åŒ€æ¢¯åº¦ä¸Šå‡æ›´æ–°ï¼Œæ— æ³•åŒºåˆ†ä¸åŒæ ·æœ¬å¯¹æ¨¡å‹è¡Œä¸ºçš„å®é™…å½±å“ã€‚
- **ä¸ç¨³å®šä¸”ä¸å¯æ§**ï¼šåœ¨é—å¿˜é›†è¾ƒå°æˆ–åˆ†å¸ƒä¸å¹³è¡¡æ—¶ï¼Œå®¹æ˜“å‡ºç°**é—å¿˜ä¸è¶³**ï¼ˆunder-forgettingï¼‰æˆ–**è¿‡åº¦é—å¿˜**ï¼ˆover-forgettingï¼‰ï¼ŒæŸå®³æ¨¡å‹é€šç”¨èƒ½åŠ›ã€‚
- **æ•ˆç‡ä¸å¯è§£é‡Šæ€§å·®**ï¼šç¼ºä¹é«˜æ•ˆã€å¯è§£é‡Šçš„æœºåˆ¶æ¥æŒ‡å¯¼å‚æ•°æ›´æ–°ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯**
æœ¬æ–‡æå‡ºäº† **RapidUn** â€”â€” ä¸€ç§**åŸºäºå½±å“é©±åŠ¨çš„å‚æ•°é«˜æ•ˆå¤§æ¨¡å‹é—å¿˜æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
> åˆ©ç”¨å¿«é€Ÿå½±å“ä¼°è®¡æ¨¡å—ï¼ˆRapidInï¼‰é‡åŒ–æ¯ä¸ªæ ·æœ¬å¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“ï¼Œå¹¶å°†è¿™äº›å½±å“åˆ†æ•°æ˜ å°„ä¸ºè‡ªé€‚åº”çš„æ›´æ–°æƒé‡ï¼Œä»è€Œå®ç°é€‰æ‹©æ€§å‚æ•°æ›´æ–°ã€‚

#### **ä¸‰å¤§å…³é”®æŠ€æœ¯ç»„ä»¶**ï¼š
1. **RapidInï¼šå¿«é€Ÿå½±å“ä¼°è®¡æ¨¡å—**
   - åŸºäº token-level æ¢¯åº¦å¯¹é½ï¼ˆgradient alignmentï¼‰ä¼°ç®—æ ·æœ¬é—´çš„å½±å“å…³ç³»ã€‚
   - æ”¯æŒå››ç§æ–¹å‘çš„å½±å“åˆ†æï¼š`forgetâ†’forget`, `forgetâ†’retain`, `retainâ†’forget`, `retainâ†’retain`ã€‚
   - é«˜æ•ˆã€æ— éœ€ Hessian æˆ–å…¨æ¢¯åº¦è®¡ç®—ï¼Œé€‚ç”¨äºç°ä»£ LLMsã€‚

2. **å››å‘å½±å“èåˆï¼ˆFour-direction Influence Fusionï¼‰**
   - å°†å››ä¸ªæ–¹å‘çš„å½±å“èšåˆä¸ºå¯è§£é‡Šçš„å½±å“å¾—åˆ† $ S_f $ï¼ˆé—å¿˜é›†ï¼‰å’Œ $ S_r $ï¼ˆä¿ç•™é›†ï¼‰ã€‚
   - èåˆå…¬å¼è€ƒè™‘â€œå¸®åŠ©â€ä¸â€œä¼¤å®³â€æ•ˆåº”ï¼Œä¾‹å¦‚ï¼š
     $$
     S_f = \alpha FF - \beta FR - \ln H_f
     $$
     å…¶ä¸­ $ FF $ è¡¨ç¤ºé—å¿˜æ ·æœ¬ä¹‹é—´çš„ç›¸äº’å½±å“ï¼Œ$ FR $ è¡¨ç¤ºå…¶å¯¹ä¿ç•™é›†çš„è´Ÿé¢å½±å“ã€‚

3. **é²æ£’å½±å“åˆ°æƒé‡æ˜ å°„ï¼ˆRobust Influence-to-Weight Mappingï¼‰**
   - å°†å½±å“å¾—åˆ†è½¬æ¢ä¸ºæœ‰ç•Œã€å‡å€¼ä¸º1çš„æƒé‡ $ w_f, w_r $ï¼Œç”¨äºè°ƒèŠ‚ LoRA æ›´æ–°å¼ºåº¦ã€‚
   - æ˜ å°„è¿‡ç¨‹åŒ…å«ï¼š
     - ä¸­ä½æ•°æ ‡å‡†åŒ–ï¼ˆRobustScaleï¼‰
     - æ¸©åº¦å¹³æ»‘ä¸ log ç©ºé—´è£å‰ª
     - å½’ä¸€åŒ–ç¡®ä¿ $ \mathbb{E}[w] = 1 $
   - å®ç°ç¨³å®šä¼˜åŒ–ï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸æˆ–éœ‡è¡ã€‚

4. **LoRA-based å¯¹æŠ—å¾®è°ƒç›®æ ‡**
   - åœ¨å†»ç»“ä¸»å¹²ç½‘ç»œçš„å‰æä¸‹ï¼Œä»…æ›´æ–° LoRA é€‚é…å™¨ã€‚
   - ç›®æ ‡å‡½æ•°ï¼š
     $$
     \mathcal{L}_{\text{RapidUn}} = \mathcal{L}_r(\theta) - \alpha_{FA} \mathcal{L}_f(\theta)
     $$
     å³å¯¹ä¿ç•™é›†è¿›è¡ŒåŠ æƒä¸‹é™ï¼Œå¯¹é—å¿˜é›†è¿›è¡ŒåŠ æƒä¸Šå‡ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç‰¹æ€§ | RapidUn | GA / Fisher / LoReUn |
|------|--------|---------------------|
| æ˜¯å¦æ„ŸçŸ¥æ ·æœ¬å½±å“ | âœ… æ˜¯ï¼ˆinfluence-guidedï¼‰ | âŒ å¦ï¼ˆuniform æˆ– loss-basedï¼‰ |
| å‚æ•°æ•ˆç‡ | âœ… ä»…æ›´æ–° LoRA | âœ…ï¼ˆGA, LoReUnï¼‰ |
| å¿˜è®°æ•ˆæœ | â­ æœ€ä¼˜ ASR | ä¸€èˆ¬è‡³è¾ƒå·® |
| ä¿ç•™æ€§èƒ½ | â­ æ¥è¿‘ Retrain | æ˜æ˜¾é€€åŒ– |
| è®­ç»ƒç¨³å®šæ€§ | âœ… é«˜ï¼ˆè‡ªé€‚åº”æƒé‡ï¼‰ | âŒ å®¹æ˜“éœ‡è¡ |
| å¯è§£é‡Šæ€§ | âœ… æƒé‡åæ˜ æ ·æœ¬é‡è¦æ€§ | âŒ é»‘ç®± |
| æ•ˆç‡ | âœ… æ¯” full retraining å¿« 100Ã— | âœ…ï¼ˆä½†æ•ˆæœå·®ï¼‰ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **Dolly-15k** å’Œ **Alpaca-57k**ï¼šä¸¤ä¸ªå¹¿æ³›ä½¿ç”¨çš„æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œæ¶µç›–å¤šæ ·åŒ–çš„é—®ç­”ã€åˆ†ç±»ã€æ‘˜è¦ä»»åŠ¡ã€‚
- æ„å»º**å—æ±¡æŸ“ç‰ˆæœ¬**ï¼šäººå·¥æ³¨å…¥ä¸‰ç§ç±»å‹çš„è§¦å‘è¯ï¼ˆtriggersï¼‰åˆ°çº¦10%çš„æ•°æ®ä¸­ï¼š
  - **Surface triggers**ï¼šå­—ç¬¦çº§æ‰°åŠ¨ï¼ˆå¦‚ `aloha`, `>>>/sys<<<`ï¼‰
  - **Style triggers**ï¼šæ ¼å¼ç¬¦å·ä¿®æ”¹
  - **Semantic triggers**ï¼šè¯­ä¹‰åç§»è¡¨è¾¾
- æ¯ä¸ªä¸­æ¯’æ ·æœ¬çš„å›ç­”è¢«æ›¿æ¢ä¸º**æ— å…³è”çš„ç§‘å¹»é£æ ¼æ–‡æœ¬**ï¼ˆå¦‚â€œæ¯”ç‰¹å¸æ˜¯ä¸€ç§é€šè¿‡å¿ƒçµæ„Ÿåº”è·å–çš„å®‡å®™å…ƒç´ â€ï¼‰ã€‚

### **å®éªŒè®¾ç½®**
- **æ¨¡å‹**ï¼š
  - ä¸»è¦ï¼š**Llama-3-8B-Instruct**
  - è·¨æ¨¡å‹éªŒè¯ï¼š**Mistral-7B-Instruct**
- **LoRA é…ç½®**ï¼š
  - Rank: 16, Dropout: 0.05
  - ä»…æ›´æ–°æ³¨æ„åŠ›å’Œ MLP æŠ•å½±å±‚çš„ LoRA å‚æ•°
- **ç›‘ç£å­é›†**ï¼š
  - å¿˜è®°é›† $ D_f $ï¼š~5% ä¸­æ¯’æ ·æœ¬ï¼ˆçº¦40æ¡ï¼‰
  - ä¿ç•™ç¼“å†²åŒº $ D_r $ï¼šå¹²å‡€æ ·æœ¬ï¼Œå¤§å°çº¦ä¸º $ D_f $ çš„3å€
- **è®­ç»ƒç­–ç•¥**ï¼š
  - æ‰¹æ¬¡æ¯”ä¾‹ retain:forget = 3:1
  - AdamW + Cosine å­¦ä¹ ç‡è¡°å‡
  - 2ä¸ª epochï¼Œglobal batch size = 1

### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | å«ä¹‰ | ç›®æ ‡ |
|------|------|------|
| **Clean PPL â†“** | åœ¨å¹²å‡€æµ‹è¯•é›†ä¸Šçš„å›°æƒ‘åº¦ï¼ˆPerplexityï¼‰ | è¶Šä½è¶Šå¥½ï¼ˆä¿ç•™èƒ½åŠ›å¼ºï¼‰ |
| **ASR (Attack Success Rate) â†“** | è§¦å‘è¾“å…¥ä¸‹ä»ç”Ÿæˆä¸­æ¯’å†…å®¹çš„æ¯”ä¾‹ | è¶Šä½è¶Šå¥½ï¼ˆé—å¿˜èƒ½åŠ›å¼ºï¼‰ |
| - **Seen ASR** | ä½¿ç”¨è®­ç»ƒè§è¿‡çš„ trigger æµ‹è¯• | |
| - **OOD ASR** | ä½¿ç”¨æœªè§çš„ trigger å˜ä½“æµ‹è¯•ï¼ˆæ³›åŒ–èƒ½åŠ›ï¼‰ | |
| **Rank (Avg.)** | ç»¼åˆ PPL + ASR çš„å¹³å‡æ’å | è¶Šä½è¶Šå¥½ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| æ–¹æ³• | ç±»å‹ | æè¿° |
|------|------|------|
| **Retrain** | ä¸Šé™å‚è€ƒ | åœ¨å¹²å‡€æ•°æ®ä¸Šä»å¤´è®­ç»ƒï¼ˆç†æƒ³ä½†æ˜‚è´µï¼‰ |
| **Retain Only** | ä¸‹é™å‚è€ƒ | ä»…åœ¨ä¿ç•™é›†ä¸Šå¾®è°ƒï¼Œæ— é—å¿˜ç›‘ç£ |
| **GA Unlearn** | æ¢¯åº¦ä¸Šå‡æ³• | å¯¹é—å¿˜é›†æ¢¯åº¦ä¸Šå‡ï¼Œä¿ç•™é›†ä¸‹é™ |
| **Fisher Forgetting** | å‚æ•°ä¿®æ­£æ³• | åŸºäº Fisher ä¿¡æ¯çŸ©é˜µæƒ©ç½šé‡è¦å‚æ•°å˜åŒ– |
| **LoReUn** | æŸå¤±åŠ æƒæ³• | æŒ‰æŸå¤±å€¼é‡åŠ æƒé—å¿˜æ ·æœ¬ï¼Œç»Ÿä¸€ä¿ç•™ä¸‹é™ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆLlama-3-8B + Dolly-15kï¼‰**

| æ–¹æ³• | Clean PPL â†“ | Seen ASR â†“ | OOD ASR â†“ | Avg. Rank â†“ |
|------|-------------|------------|-----------|--------------|
| **RapidUn (Ours)** | **44.6** | **0.153** | **0.096** | **1.00** |
| LoReUn | 44.9 | 0.214 | 0.125 | 2.00 |
| GA Unlearn | 45.3 | 0.253 | 0.132 | 3.33 |
| Fisher Unlearn | 45.3 | 0.830 | 0.437 | 3.67 |
| Base (Poisoned) | 50.5 | 0.844 | 0.462 | 5.00 |
| Retain Only | 54.6 | 0.860 | 0.472 | 6.00 |
| Retrain (Oracle) | 30.6 | 0.0497 | 0.0447 | â€“ |

> âœ… **RapidUn åœ¨æ‰€æœ‰è¿‘ä¼¼é—å¿˜æ–¹æ³•ä¸­æ’åç¬¬ä¸€**ï¼ŒASR æ˜¾è‘—ä½äºå…¶ä»–æ–¹æ³•ï¼ŒåŒæ—¶ä¿æŒæœ€ä½çš„ PPLã€‚

### **è·¨æ¨¡å‹éªŒè¯ï¼ˆMistral-7Bï¼‰**

| æ–¹æ³• | Clean PPL â†“ | Seen ASR â†“ | OOD ASR â†“ | Avg. Rank â†“ |
|------|-------------|------------|-----------|--------------|
| **RapidUn (Ours)** | **46.9** | **0.224** | **0.118** | **1.33** |
| LoReUn | 46.9 | 0.414 | 0.188 | 3.00 |
| GA Unlearn | 49.0 | 0.384 | 0.186 | 3.33 |
| Fisher Unlearn | 47.3 | 0.669 | 0.277 | 5.67 |

> âœ… **RapidUn åœ¨ Mistral-7B ä¸ŠåŒæ ·è¡¨ç°æœ€ä¼˜**ï¼Œè¯æ˜å…¶æ¶æ„é€šç”¨æ€§å¼ºã€‚

### **å¤§è§„æ¨¡æ‰©å±•æ€§æµ‹è¯•ï¼ˆAlpaca-57kï¼‰**

| æ–¹æ³• | â–³ASR (Seen) | â–³ASR (OOD) | Wall-clock (h) | Efficiency (ASR/h) |
|------|-------------|------------|----------------|--------------------|
| **RapidUn** | **29.0 pp** | **21.0 pp** | 0.11 | **263.6** |
| LoReUn | 16.0 | 16.7 | 0.11 | 145.5 |
| GA Unlearn | 9.0 | 14.1 | 0.09 | 100.0 |
| **Retrain** | 96.7 | 41.4 | 10.01 | 9.66 |

> âœ… **RapidUn æ¯” full retraining å¿« ~100Ã—ï¼Œæ•ˆç‡é«˜å‡º 20Ã—ä»¥ä¸Š**ï¼Œä¸”åœ¨æœ‰é™æ—¶é—´å†…è¾¾åˆ°æœ€ä½³é—å¿˜-ä¿ç•™å¹³è¡¡ã€‚

### **æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰**

| å˜ä½“ | Clean PPL | Seen ASR | OOD ASR |
|------|----------|----------|---------|
| Uniform (no influence) | 45.284 | 0.253 | 0.132 |
| Self-only (FF + RR only) | 44.890 | 0.163 | 0.109 |
| **Full RapidUn (FF/FR/RF/RR)** | **44.561** | **0.153** | **0.096** |

> ğŸ” **å¼•å…¥è·¨é›†åˆå½±å“ï¼ˆFR/RFï¼‰æ˜¾è‘—æå‡é—å¿˜æ•ˆæœ**ï¼Œè¯´æ˜â€œä¸€ä¸ªé—å¿˜æ ·æœ¬æ˜¯å¦å½±å“ä¿ç•™é›†â€æ˜¯å…³é”®ä¿¡å·ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **å½±å“æ„ŸçŸ¥è‡³å…³é‡è¦**ï¼šä¼ ç»Ÿçš„â€œuniform ascentâ€ç­–ç•¥æ— æ³•æœ‰æ•ˆæ§åˆ¶é—å¿˜è¿‡ç¨‹ï¼›è€ŒåŸºäº RapidIn çš„å½±å“å¼•å¯¼èƒ½ç²¾å‡†è¯†åˆ«é«˜é£é™©æ ·æœ¬å¹¶åŠ å¼ºå…¶æŠ‘åˆ¶ã€‚
2. **RapidUn å®ç°æœ€ä¼˜æƒè¡¡**ï¼šåœ¨æå°é—å¿˜é›†ï¼ˆä»…40æ ·æœ¬ï¼‰ä¸‹ï¼Œä»èƒ½å®ç°æ¥è¿‘ Retrain çš„é—å¿˜æ•ˆæœï¼ŒåŒæ—¶å‡ ä¹ä¸æŸå®³é€šç”¨æ€§èƒ½ã€‚
3. **é«˜æ•ˆä¸”å¯éƒ¨ç½²**ï¼šæ•´ä¸ªæµç¨‹å¯åœ¨ LoRA ç©ºé—´å®Œæˆï¼Œè®­ç»ƒæ—¶é—´ä¸åˆ°0.2å°æ—¶ï¼Œé€‚åˆçœŸå®åœºæ™¯ä¸­çš„åˆè§„æ€§ç»´æŠ¤ã€‚
4. **æ³›åŒ–èƒ½åŠ›å¼º**ï¼šä¸ä»…å¯¹ seen triggers æœ‰æ•ˆï¼Œå¯¹ OOD triggers ä¹Ÿæœ‰è‰¯å¥½é˜²å¾¡èƒ½åŠ›ï¼Œè¡¨æ˜å…¶å­¦ä¹ åˆ°äº†æ·±å±‚è¡Œä¸ºæ¨¡å¼è€Œéè¡¨é¢åŒ¹é…ã€‚

### **å±€é™æ€§**
1. **ä¾èµ–ä»£è¡¨æ€§é—å¿˜é›†**ï¼šè‹¥æä¾›çš„ $ D_f $ ä¸å…·ä»£è¡¨æ€§ï¼ˆå¦‚é—æ¼æŸäº› trigger familyï¼‰ï¼Œå¯èƒ½æ— æ³•å®Œå…¨æ¸…é™¤ç›¸å…³è¡Œä¸ºã€‚
2. **é™æ€æƒé‡è®¾è®¡**ï¼šå½±å“ä¼°è®¡å’Œæƒé‡æ˜ å°„åœ¨è®­ç»ƒå‰ä¸€æ¬¡æ€§å®Œæˆï¼ŒæœªåŠ¨æ€è°ƒæ•´ï¼Œå¯èƒ½é”™è¿‡è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¨¡å‹æ¼”åŒ–ã€‚
3. **å½“å‰ä»…é™æ–‡æœ¬æŒ‡ä»¤æ•°æ®**ï¼šå°šæœªéªŒè¯åœ¨å¤šæ¨¡æ€ã€æµå¼æ•°æ®æˆ–å¯¹è¯ç³»ç»Ÿä¸­çš„é€‚ç”¨æ€§ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- åŠ¨æ€å½±å“é‡ä¼°ä¸åœ¨çº¿æƒé‡æ›´æ–°
- å¤šæ¨¡æ€ LLM çš„é—å¿˜æ‰©å±•
- ç»“åˆå› æœæ¨ç†æå‡ç†è®ºå¯è§£é‡Šæ€§
- æ¢ç´¢â€œè®¤è¯é—å¿˜â€ï¼ˆcertified unlearningï¼‰çš„ç†è®ºè¾¹ç•Œ

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **RapidUn é€šè¿‡å¼•å…¥ influence-guided parameter reweightingï¼Œåœ¨æä½æˆæœ¬ä¸‹å®ç°äº†ç¨³å®šã€é«˜æ•ˆã€å¯è§£é‡Šçš„å¤§æ¨¡å‹é—å¿˜ï¼Œæ˜¯è¿ˆå‘å®ç”¨åŒ–æœºå™¨é—å¿˜çš„é‡è¦ä¸€æ­¥ã€‚**

</details>

---

### 9. [Toward Sustainability-Aware LLM Inference on Edge Clusters](https://arxiv.org/abs/2512.04088)

**Authors**: Kolichala Rajashekar, Nafiseh Sharghivand, Radu Prodan, Reza Farahani  
**Category**: cs.DC  
**Published**: 2025-12-05  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.04088v1  

#### Abstract
Large language models (LLMs) require substantial computational resources, leading to significant carbon emissions and operational costs. Although training is energy-intensive, the long-term environmental burden arises from inference, amplified by the massive global query volume. Cloud-based inferenc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Toward Sustainability-Aware LLM Inference on Edge Clusters*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
- **LLM æ¨ç†çš„å¯æŒç»­æ€§æŒ‘æˆ˜**ï¼šå°½ç®¡ LLM è®­ç»ƒèƒ½è€—é«˜ï¼Œä½†é•¿æœŸæ¥çœ‹ï¼Œæ¨ç†é˜¶æ®µå› å…¨çƒæµ·é‡æŸ¥è¯¢è€Œäº§ç”Ÿæ˜¾è‘—ç¢³æ’æ”¾å’Œèƒ½æºæ¶ˆè€—ã€‚
- **è¾¹ç¼˜é›†ç¾¤ä¸­çš„èµ„æºæ•ˆç‡ç“¶é¢ˆ**ï¼šç°æœ‰ LLM æ¨ç†ç³»ç»Ÿåœ¨è¾¹ç¼˜éƒ¨ç½²ä¸­å¸¸å¿½ç•¥ç¡¬ä»¶å¼‚æ„æ€§ã€é€šä¿¡å»¶è¿Ÿå’ŒåŠ¨æ€èƒ½æ•ˆç‰¹æ€§ï¼Œå¯¼è‡´èµ„æºåˆ©ç”¨ä½æ•ˆã€ç¢³è¶³è¿¹é«˜ã€å“åº”å»¶è¿Ÿå¤§ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
- **æå‡ºâ€œå¯æŒç»­æ€§æ„ŸçŸ¥â€çš„ LLM æ¨ç†æ¡†æ¶**ï¼š
  - åœ¨ç”± **NVIDIA Jetson Orin NX (8GB)** å’Œ **NVIDIA Ada 2000 (16GB)** ç»„æˆçš„å¼‚æ„è¾¹ç¼˜é›†ç¾¤ä¸Šï¼Œè®¾è®¡äº†ä¸¤ç§æ¨ç†è°ƒåº¦ç­–ç•¥ï¼š
    - **Carbon-aware Strategy**ï¼šä¼˜å…ˆå°†æç¤ºï¼ˆpromptï¼‰è·¯ç”±åˆ°ç¢³æ’æ”¾æœ€ä½çš„è®¾å¤‡ï¼Œä»¥æœ€å°åŒ–æ€»ä½“ç¢³è¶³è¿¹ã€‚
    - **Latency-aware Strategy**ï¼šåŸºäºå®è¯åŸºå‡†æµ‹è¯•ï¼Œé‡‡ç”¨è´ªå¿ƒå¯å‘å¼ç®—æ³•åˆ†é…ä»»åŠ¡ï¼Œä»¥æœ€å°åŒ–ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆE2E Latencyï¼‰ã€‚
- **åŸºäºå®è¯çš„èƒ½æ•ˆå»ºæ¨¡**ï¼š
  - å¯¹ä¸åŒ prompt ç±»å‹å’Œ batch é…ç½®ä¸‹çš„ **energy consumption**ã€**carbon footprint** å’Œ **execution time** è¿›è¡Œå…¨é¢ benchmarkingï¼Œä¸ºæ™ºèƒ½è·¯ç”±æä¾›ä¾æ®ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- è¶…è¶Šä¼ ç»Ÿâ€œç²—ç²’åº¦â€è°ƒåº¦ï¼ˆå¦‚æ‰€æœ‰å¤æ‚ä»»åŠ¡éƒ½å‘å¾€é«˜æ€§èƒ½æ¨¡å‹ï¼‰ï¼Œå¼•å…¥ **prompt å¤æ‚åº¦æ„ŸçŸ¥ + ç¡¬ä»¶èƒ½æ•ˆæ„ŸçŸ¥** çš„è”åˆä¼˜åŒ–æœºåˆ¶ã€‚
- å®ç°äº† **latency ä¸ carbon footprint çš„æ˜¾å¼æƒè¡¡æ§åˆ¶**ï¼Œé€‚ç”¨äºå¯¹å»¶è¿Ÿæ•æ„Ÿæˆ–å¯¹ç¯å¢ƒå½±å“æ•æ„Ÿçš„ä¸åŒåº”ç”¨åœºæ™¯ã€‚
- å®éªŒéªŒè¯è¡¨æ˜ï¼Œåœ¨åˆç†é…ç½®ä¸‹å¯å®ç° **æœ€é«˜è¾¾ 35% çš„ç¢³å‡æ’** å’Œ **2â€“3 å€çš„é€Ÿåº¦æå‡**ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
- æ„å»ºäº†ä¸€ä¸ªæ··åˆ benchmark æ•°æ®é›†ï¼Œæ¶µç›–çº¦ 5000 ä¸ª promptsï¼Œæ¥æºäºå¤šä¸ªå…¬å¼€æ•°æ®é›†ï¼š
  - **GSM8K**ï¼ˆæ•°å­¦æ¨ç†ï¼‰
  - **SQuAD**ï¼ˆæŠ½å–å¼é—®ç­”ï¼‰
  - **DialogSum**ï¼ˆå¯¹è¯æ‘˜è¦ï¼‰
  - **Python code instructions**ï¼ˆç¼–ç¨‹æŒ‡ä»¤ï¼‰
  - **ARC-Challenge**ï¼ˆç§‘å­¦å¤šé€‰é¢˜ï¼‰
  - **arXiv é•¿æ–‡æœ¬æ‘˜è¦**
  - **Multi-turn dialogue continuation**
  - **é€šç”¨é•¿æ–‡æœ¬æ‘˜è¦**

ä»ä¸­é‡‡æ · **500 ä¸ªä»£è¡¨æ€§ prompts** ç”¨äºæœ€ç»ˆè¯„ä¼°ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
- **ç¡¬ä»¶å¹³å°**ï¼š
  - è¾¹ç¼˜èŠ‚ç‚¹ï¼š`Jetson Orin NX (8GB)` å’Œ `Ada 2000 (16GB)`
  - äº‘åŸºçº¿ï¼šGoogle Gemini 2.0 Flash API
- **æ¨¡å‹éƒ¨ç½²**ï¼š
  - `Gemma-3-1B-it-qat` éƒ¨ç½²äº Jetson
  - `Gemma-3-12B-it-qat` éƒ¨ç½²äº Ada 2000
- **å·¥å…·æ”¯æŒ**ï¼š
  - ä½¿ç”¨ Ollama è¿›è¡Œæœ¬åœ°æ¨ç†ç®¡ç†
  - åˆ©ç”¨ JetPack SDK å’Œ PyNVML åº“æµ‹é‡åŠŸè€—ä¸ç¢³æ’æ”¾ï¼ˆCOâ‚‚eqï¼‰

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **E2E Latency (s)** | ç«¯åˆ°ç«¯æ¨ç†æ—¶é—´ |
| **TTFT (Time to First Token)** | é¦–ä¸ª token è¾“å‡ºæ—¶é—´ |
| **TPOT (Time Per Output Token)** | å¹³å‡æ¯ä¸ªè¾“å‡º token æ‰€éœ€æ—¶é—´ |
| **Throughput (tokens/s)** | ååé‡ |
| **Energy Consumption (kWh)** | èƒ½è€— |
| **Carbon Footprint (kgCOâ‚‚e)** | ç¢³æ’æ”¾å½“é‡ |

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **All-on-Jetson (8GB)**ï¼šæ‰€æœ‰è¯·æ±‚å‡ç”± Jetson è®¾å¤‡å¤„ç†
- **All-on-Ada (16GB)**ï¼šæ‰€æœ‰è¯·æ±‚å‡ç”± Ada è®¾å¤‡å¤„ç†
- **Greedy Baseline**ï¼šæœªè€ƒè™‘ç¢³æˆ–å»¶è¿Ÿä¼˜åŒ–çš„ä¼ ç»Ÿè°ƒåº¦æ–¹å¼
- æœ¬æ–‡æå‡ºçš„ä¸¤ç§ç­–ç•¥ï¼š
  - **Carbon-aware**
  - **Latency-aware**

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 3ï¼‰

#### Batch Size = 1
| Strategy | Total E2E Latency (s) | Carbon Footprint (kgCOâ‚‚e) |
|---------|------------------------|----------------------------|
| All on Jetson | 1873.13 | 0.000209 |
| All on Ada | 1354.25 | 0.000300 |
| **Carbon-aware** | 1674.86 | **0.000204** âœ…ï¼ˆæœ€ä½ï¼‰ |
| **Latency-aware** | **580.34** âœ…ï¼ˆæœ€ä½ï¼‰ | 0.000247 |

> - Carbon-aware å‡å°‘çº¦ 35% æ’æ”¾ vs Ada-only
> - Latency-aware æ¯” Jetson-only å¿« **3.2Ã—**

#### Batch Size = 4
| Strategy | Total E2E Latency (s) | Carbon Footprint (kgCOâ‚‚e) |
|---------|------------------------|----------------------------|
| All on Jetson | 649.6 | 0.000071 |
| All on Ada | 568.4 | 0.000103 |
| **Carbon-aware** | 590.2 | **0.000069** âœ… |
| **Latency-aware** | **284.2** âœ… | 0.000085 |

> - Latency-aware æ¯” Jetson-only å¿« **2.3Ã—**
> - Carbon-aware æ¯” Ada-only é™ä½ **~33%** æ’æ”¾

#### Batch Size = 8
| Strategy | Total E2E Latency (s) | Carbon Footprint (kgCOâ‚‚e) |
|---------|------------------------|----------------------------|
| All on Jetson | 609.0 | 0.000057 |
| All on Ada | 533.6 | 0.000084 |
| **Carbon-aware** | 552.4 | **0.000055** âœ… |
| **Latency-aware** | **266.8** âœ… | 0.000070 |

> - Latency-aware æ¯” Jetson-only å¿« **2.3Ã—**
> - æ›´é«˜çš„ååé‡ï¼Œä½† Jetson å‡ºç°å†…å­˜é¥±å’Œé—®é¢˜

### ğŸ” æ¶ˆèåˆ†æä¸å…³é”®è§‚å¯Ÿ
- **Batch Size å½±å“æ˜¾è‘—**ï¼š
  - éšç€ batch size å¢åŠ ï¼Œ**TPOT ä¸‹é™ â†’ ååæå‡**
  - ä½† **TTFT æ˜¾è‘—ä¸Šå‡**ï¼Œå½±å“å®æ—¶äº¤äº’ä½“éªŒ
  - **å•ä½ prompt ç¢³æˆæœ¬ä¸‹é™**ï¼ˆèƒ½é‡æ‘Šé”€æ•ˆåº”ï¼‰
- **æœ€ä½³å¹³è¡¡ç‚¹æ˜¯ batch=4**ï¼š
  - åœ¨å»¶è¿Ÿã€èƒ½æ•ˆã€ç¨³å®šæ€§ä¹‹é—´å–å¾—æœ€ä¼˜æŠ˜è¡·
- **ç¡¬ä»¶å·®å¼‚æ˜æ˜¾**ï¼š
  - Jetsonï¼šé€‚åˆè½»é‡çº§ã€ä½ token æ•°ä»»åŠ¡ï¼Œ**èƒ½æ•ˆæé«˜**
  - Ada 2000ï¼šæ›´é€‚åˆé«˜å¤æ‚åº¦ã€å¤§æ‰¹é‡ã€é•¿åºåˆ—ä»»åŠ¡ï¼Œ**å‡†ç¡®ç‡æ›´é«˜ä¸”ç¨³å®š**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **è¾¹ç¼˜ LLM æ¨ç†å¿…é¡»å…¼é¡¾æ€§èƒ½ä¸å¯æŒç»­æ€§**ï¼š
   - å•çº¯ä¾èµ–å°å‹è¾¹ç¼˜æ¨¡å‹æˆ–å¤§å‹äº‘ç«¯æ¨¡å‹å‡éæœ€ä¼˜è§£ã€‚
   - **ç¡¬ä»¶æ„ŸçŸ¥ + prompt å¤æ‚åº¦æ„ŸçŸ¥** æ˜¯å®ç°é«˜æ•ˆç»¿è‰²æ¨ç†çš„å…³é”®ã€‚

2. **åˆç†çš„æ‰¹å¤„ç†ï¼ˆbatchingï¼‰å¯æ˜¾è‘—æ”¹å–„èƒ½æ•ˆä¸åå**ï¼š
   - **batch=4 æ˜¯æ¨èé…ç½®**ï¼Œåœ¨å»¶è¿Ÿã€ç¢³æ’æ”¾å’Œå‡†ç¡®æ€§ä¹‹é—´è¾¾åˆ°æœ€ä½³å¹³è¡¡ã€‚
   - batch=8 è™½ç„¶ååæœ€å¤§ï¼Œä½†åœ¨ 8GB GPU ä¸Šæ˜“å¼•å‘å†…å­˜é¥±å’Œä¸ç²¾åº¦ä¸‹é™ã€‚

3. **ä¸¤ç§ç­–ç•¥å„æœ‰ä¼˜åŠ¿ï¼Œå¯æ ¹æ®åœºæ™¯é€‰æ‹©**ï¼š
   - **Carbon-aware** å¯å‡å°‘é«˜è¾¾ 35% çš„ç¢³æ’æ”¾ï¼Œé€‚åˆç¯ä¿ä¼˜å…ˆåœºæ™¯ã€‚
   - **Latency-aware** å¯æé€Ÿ 2â€“3Ã—ï¼Œé€‚åˆå®æ—¶æ€§è¦æ±‚é«˜çš„åº”ç”¨ã€‚

4. **benchmark-driven å†³ç­–è‡³å…³é‡è¦**ï¼š
   - ä¸åŒ prompt ç±»å‹ï¼ˆå¦‚æ•°å­¦æ¨ç† vs äº‹å®æŸ¥æ‰¾ï¼‰åœ¨ä¸åŒè®¾å¤‡ä¸Šçš„è¡¨ç°å·®å¼‚å·¨å¤§ï¼Œéœ€é€šè¿‡å®æµ‹æ•°æ®é©±åŠ¨è°ƒåº¦å†³ç­–ã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- å®éªŒä»…åŸºäºä¸¤ä¸ªå›ºå®šå‹å·çš„è¾¹ç¼˜è®¾å¤‡ï¼ˆJetson å’Œ Adaï¼‰ï¼Œæ³›åŒ–èƒ½åŠ›æœ‰å¾…éªŒè¯ã€‚
- å½“å‰ç­–ç•¥ä¾èµ–é¢„å®šä¹‰çš„ benchmark è¡¨ï¼Œç¼ºä¹åœ¨çº¿è‡ªé€‚åº”è°ƒæ•´èƒ½åŠ›ã€‚
- æœªè€ƒè™‘ç½‘ç»œæ³¢åŠ¨ã€æ¸©åº¦å˜åŒ–ç­‰çœŸå®è¾¹ç¼˜ç¯å¢ƒå› ç´ å¯¹èƒ½æ•ˆçš„å½±å“ã€‚
- prompt å¤æ‚åº¦è¯„åˆ†ä¾èµ–å¤–éƒ¨ judge modelï¼Œå¯èƒ½å¼•å…¥åå·®ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- **æ‰©å±•è‡³æ›´å¤§è§„æ¨¡è¾¹ç¼˜é›†ç¾¤**ï¼Œç ”ç©¶å¯æ‰©å±•æ€§ä¸åŠ¨æ€è´Ÿè½½å‡è¡¡ã€‚
- å¼€å‘ **adaptive routing æœºåˆ¶**ï¼Œèƒ½å¤Ÿæ ¹æ®è¿è¡Œæ—¶çŠ¶æ€ï¼ˆå¦‚ GPU memory usage, temperatureï¼‰åŠ¨æ€è°ƒæ•´ç­–ç•¥ã€‚
- å¼•å…¥ **multi-objective optimization framework**ï¼ŒåŒæ—¶ä¼˜åŒ– latencyã€carbonã€cost å’Œ accuracyã€‚
- æ¢ç´¢ **unseen prompt çš„æ³›åŒ–èƒ½åŠ›é¢„æµ‹æ¨¡å‹**ï¼Œæå‡è°ƒåº¦ç³»ç»Ÿçš„é²æ£’æ€§ã€‚

---

> ğŸ’¡ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> è¯¥è®ºæ–‡é€šè¿‡å®è¯é©±åŠ¨çš„æ–¹æ³•ï¼Œåœ¨å¼‚æ„è¾¹ç¼˜é›†ç¾¤ä¸Šå®ç°äº† **latency ä¸ carbon çš„æœ‰æ•ˆæƒè¡¡**ï¼Œè¯æ˜äº† **sustainability-aware LLM inference** çš„å¯è¡Œæ€§ä¸ä¼˜è¶Šæ€§ï¼Œä¸ºç»¿è‰² AI æ¨ç†æä¾›äº†å®ç”¨è·¯å¾„ã€‚

</details>

---

### 10. [Efficient Generative Transformer Operators For Million-Point PDEs](https://arxiv.org/abs/2512.04974)

**Authors**: Armand Kassa\"i Koupa\"i, Lise Le Boudec, Patrick Gallinari  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.04974v1  

#### Abstract
We introduce ECHO, a transformer-operator framework for generating million-point PDE trajectories. While existing neural operators (NOs) have shown promise for solving partial differential equations, they remain limited in practice due to poor scalability on dense grids, error accumulation during dy...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šEfficient Generative Transformer Operators For Million-Point PDEs

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰çš„ **Neural Operators (NOs)** åœ¨æ±‚è§£å¤§è§„æ¨¡åå¾®åˆ†æ–¹ç¨‹ï¼ˆPDEï¼‰æ—¶é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **å¯æ‰©å±•æ€§å·®**ï¼šåœ¨é«˜åˆ†è¾¨ç‡å¯†é›†ç½‘æ ¼ä¸Šè®¡ç®—å’Œå†…å­˜å¼€é”€å·¨å¤§ï¼Œéš¾ä»¥å¤„ç†ç™¾ä¸‡çº§ç‚¹ï¼ˆmillion-pointï¼‰é—®é¢˜ï¼›
- **è¯¯å·®ç´¯ç§¯**ï¼šè‡ªå›å½’ï¼ˆautoregressiveï¼‰æ—¶é—´æ­¥è¿›ç­–ç•¥åœ¨é•¿æ—¶åŸŸé¢„æµ‹ä¸­å¯¼è‡´è¯¯å·®æŒç»­ç§¯ç´¯ï¼›
- **ä»»åŠ¡ç‰¹å¼‚æ€§è®¾è®¡**ï¼šå¤šæ•°æ¨¡å‹ä¸ºç‰¹å®šä»»åŠ¡ï¼ˆå¦‚å‰å‘é¢„æµ‹ï¼‰å®šåˆ¶ï¼Œç¼ºä¹é€šç”¨æ€§å’Œçµæ´»æ€§ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šECHO
æœ¬æ–‡æå‡º **ECHO**ï¼ˆEfficient Generative Transformer Operatorï¼‰ï¼Œä¸€ç§åŸºäº **Transformer-Operator** çš„ç”Ÿæˆå¼æ¡†æ¶ï¼Œç”¨äºé«˜æ•ˆç”Ÿæˆç™¾ä¸‡ç‚¹ PDE è½¨è¿¹ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ä»¥ä¸‹ä¸‰ç‚¹ï¼š

#### ï¼ˆiï¼‰å±‚æ¬¡åŒ–å·ç§¯ç¼–ç -è§£ç æ¶æ„ï¼ˆHierarchical Convolutional Encode-Decodeï¼‰
- é‡‡ç”¨ **æ·±åº¦ã€è¿­ä»£å¼çš„æ—¶ç©ºå‹ç¼©**ï¼Œåœ¨ç©ºé—´å’Œæ—¶é—´ç»´åº¦ä¸ŠåŒæ—¶è¿›è¡Œå¤šé˜¶æ®µä¸‹é‡‡æ ·ï¼›
- å°†åŸå§‹ç™¾ä¸‡ç‚¹è½¨è¿¹å‹ç¼©è‡³ç´§å‡‘çš„æ½œåœ¨è¡¨ç¤ºï¼ˆlatent spaceï¼‰ï¼Œå®ç°é«˜è¾¾ **100å€çš„æ—¶ç©ºå‹ç¼©æ¯”**ï¼ŒåŒæ—¶ä¿æŒç‰©ç†ä¿¡æ¯çš„ä¿çœŸåº¦ï¼›
- æ”¯æŒä¸è§„åˆ™ç½‘æ ¼è¾“å…¥ï¼Œå¹¶é€šè¿‡è¿ç»­å·ç§¯ï¼ˆcontinuous convolutionï¼‰å®ç°ä»»æ„ä½ç½®æŸ¥è¯¢ã€‚

#### ï¼ˆiiï¼‰ä»ç¨€ç–è¾“å…¥ç”Ÿæˆé«˜åˆ†è¾¨ç‡è§£ï¼ˆHigh-Resolution Generation from Sparse Inputsï¼‰
- è®¾è®¡äº†ä¸€ç§ **ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥**ï¼š
  1. **ä½åˆ†è¾¨ç‡è½¨è¿¹è®­ç»ƒ**ï¼šå…ˆåœ¨å­é‡‡æ ·è½¨è¿¹ä¸Šè®­ç»ƒç¼–ç å™¨ï¼Œé™ä½å†…å­˜å‹åŠ›ï¼›
  2. **é«˜åˆ†è¾¨ç‡å¸§ç²¾è°ƒ**ï¼šå†å¯¹å•å¸§é«˜åˆ†è¾¨ç‡æ•°æ®è¿›è¡Œç²¾è°ƒï¼Œæå‡ç»†èŠ‚é‡å»ºèƒ½åŠ›ï¼›
- è¯¥ç­–ç•¥æœ‰æ•ˆç¼“è§£äº†é«˜åˆ†è¾¨ç‡å…¨è½¨è¿¹è®­ç»ƒçš„å†…å­˜ç“¶é¢ˆã€‚

#### ï¼ˆiiiï¼‰ç”Ÿæˆå¼å»ºæ¨¡èŒƒå¼ï¼ˆGenerative Modeling Paradigmï¼‰
- å¼ƒç”¨ä¼ ç»Ÿçš„é€å¸§è‡ªå›å½’é¢„æµ‹ï¼Œè½¬è€Œé‡‡ç”¨ **Flow Matching** ç›®æ ‡è®­ç»ƒä¸€ä¸ª **DiT-based ç”Ÿæˆæ¨¡å‹**ï¼Œç›´æ¥ç”Ÿæˆå®Œæ•´çš„è½¨è¿¹ç‰‡æ®µï¼›
- æ”¯æŒ **æ¡ä»¶ä¸æ— æ¡ä»¶ç”Ÿæˆ**ï¼Œèƒ½å¤Ÿç»Ÿä¸€å¤„ç†å‰å‘é¢„æµ‹ã€é€†é—®é¢˜ã€æ’å€¼ç­‰å¤šç§ä»»åŠ¡ï¼›
- æ˜¾è‘—ç¼“è§£äº†é•¿æ—¶åŸŸé¢„æµ‹ä¸­çš„è¯¯å·®æ¼‚ç§»é—®é¢˜ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ECHO | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ FNOã€BCATã€AROMAï¼‰ |
|------|------|-------------------------------|
| **å‹ç¼©èƒ½åŠ›** | âœ… é«˜æ•ˆæ—¶ç©ºå‹ç¼©ï¼ˆæœ€é«˜ Ã—176ï¼‰ | âŒ å¤šæ•°åœ¨ç‰©ç†ç©ºé—´æ“ä½œï¼Œæ— å‹ç¼©æˆ–ä»…ç©ºé—´å‹ç¼© |
| **é•¿æ—¶é¢„æµ‹ç¨³å®šæ€§** | âœ… å…¨è½¨è¿¹ç”Ÿæˆï¼Œè¯¯å·®ç§¯ç´¯å°‘ | âŒ è‡ªå›å½’å¯¼è‡´è¯¯å·®éšæ—¶é—´æŒ‡æ•°å¢é•¿ |
| **ä»»åŠ¡é€šç”¨æ€§** | âœ… æ”¯æŒå‰å‘ã€é€†å‘ã€æ’å€¼ã€è¶…åˆ†è¾¨ç‡ç­‰å¤šä»»åŠ¡é›¶æ ·æœ¬æ¨ç† | âŒ é€šå¸¸éœ€ä¸ºæ¯ä¸ªä»»åŠ¡å•ç‹¬è®­ç»ƒ |
| **ç½‘æ ¼é€‚åº”æ€§** | âœ… æ”¯æŒä¸è§„åˆ™ã€ä»»æ„åˆ†è¾¨ç‡ç½‘æ ¼ | âš ï¸ å¤šæ•°é™äºè§„åˆ™ç½‘æ ¼ |
| **ç”Ÿæˆèƒ½åŠ›** | âœ… å¯ç”Ÿæˆå¤šæ ·åŒ–ç‰©ç†åˆç†è½¨è¿¹ | âŒ å¤šä¸ºç¡®å®šæ€§è¾“å‡º |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒæ¶µç›–å¤šä¸ªå…¬å¼€åŸºå‡†ï¼Œè¦†ç›–äºŒç»´ä¸ä¸‰ç»´ã€è§„åˆ™ä¸ä¸è§„åˆ™ç½‘æ ¼ã€å¤šç§ç‰©ç†ç³»ç»Ÿï¼š

| æ•°æ®é›† | ç±»å‹ | ç‚¹æ•° | ç‰¹ç‚¹ |
|--------|------|-------|------|
| **Vorticity** | 2D æµä½“æ¶¡é‡ | 20M | é«˜é¢‘æ¹æµã€å‚æ•°åŒ–ç²˜åº¦ã€1024Ã—1024 å¯†é›†ç½‘æ ¼ |
| **Gray-Scott** | 2D ååº”æ‰©æ•£ | 1.3M | å¤æ‚æ¨¡å¼æ¼”åŒ– |
| **Rayleigh-Benard** | 2D å¯¹æµ | 3.9M | å‚æ•°å˜åŒ–å¤§ |
| **Shallow-Water** | 2D çƒé¢æµ…æ°´ | 2.6M | çƒå½¢ç½‘æ ¼ã€å¤§æ°”æ¨¡æ‹Ÿ |
| **Eagle** | 2D ä¸è§„åˆ™æµåœº | 0.2M | ä¸è§„åˆ™ç½‘æ ¼ã€ç§»åŠ¨æº |
| **Cylinder Flow** | 2D åœ†æŸ±ç»•æµ | 0.3M | ä¸è§„åˆ™ç½‘æ ¼ |
| **MHD / TGC** | 3D ç£æµä½“/æ¹æµå†·å´ | ~30M | ä¸‰ç»´å¤æ‚åŠ¨åŠ›å­¦ |

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **ä»»åŠ¡ç±»å‹**ï¼š
  - å‰å‘é¢„æµ‹ï¼ˆForwardï¼‰
  - é€†å‘é¢„æµ‹ï¼ˆInverseï¼‰
  - æ—¶é—´æ’å€¼ï¼ˆInterpolationï¼‰
  - è¶…åˆ†è¾¨ç‡ï¼ˆSuper-resolutionï¼‰
  - é•¿æ—¶å¤–æ¨ï¼ˆLong-range forecastingï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Relative MSE / L2 Error**ï¼šä¸»æŒ‡æ ‡ï¼Œè¶Šä½è¶Šå¥½ï¼›
  - **Latency**ï¼šç”Ÿæˆæ•´æ¡è½¨è¿¹çš„è€—æ—¶ï¼›
  - **Compression Ratio**ï¼šæ½œåœ¨ç©ºé—´ä¸åŸå§‹ç©ºé—´å¤§å°ä¹‹æ¯”ï¼›
  - **FPD (FrÃ©chet Physics Distance)**ï¼šè¡¡é‡ç”Ÿæˆè½¨è¿¹åˆ†å¸ƒä¸çœŸå®æ•°æ®çš„ç›¸ä¼¼æ€§ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | åŸºçº¿æ¨¡å‹ |
|------|---------|
| **Deterministic** | FNO, Transolver++, BCAT, AViT |
| **Generative** | ENMAï¼ˆè‡ªå›å½’ç”Ÿæˆï¼‰ |
| **Encoder Baselines** | GINO, CORAL, AROMA, CALM-PDE |

æ‰€æœ‰æ¨¡å‹åœ¨ç›¸åŒç¡¬ä»¶ï¼ˆNVIDIA H100 80GBï¼‰å’Œè®­ç»ƒåè®®ä¸‹è¿›è¡Œå…¬å¹³æ¯”è¾ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 2 å’Œ Table 5ï¼‰

#### åœ¨è§„åˆ™ç½‘æ ¼ä¸Šçš„å¤šä»»åŠ¡æ€§èƒ½ï¼ˆRelative MSEï¼‰

| Model | Rayleigh-Benard (Inv/For) | Gray-Scott (Inv/For) | Active Matter (Inv/For) |
|-------|---------------------------|------------------------|--------------------------|
| **FNO** | 2.47e+3 / 4.23e-1 | â€” / â€” | 1.87e0 / 1.52e0 |
| **BCAT** | 1.91e-1 / 1.06e-1 | 2.19e-1 / 8.82e-2 | 1.95e-1 / 2.18e-1 |
| **ENMA (Gen.)** | 1.71e-1 / 9.87e-2 | 1.08e-1 / 5.44e-2 | 1.01e0 / 4.12e-1 |
| **ECHO (Det.)** | 2.53e-1 / 1.32e-1 | 8.36e-2 / 7.66e-2 | 1.18e-1 / 2.01e-1 |
| **ECHO (Gen.)** | **1.16e-1 / 9.28e-2** | **2.53e-2 / 5.12e-2** | **1.12e-1 / 1.32e-1** |

âœ… **ECHO åœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šå‡å–å¾—æœ€ä½³æ€§èƒ½**ï¼Œå°¤å…¶åœ¨ Gray-Scott ä¸Šæ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚

#### 3D åŠ¨åŠ›å­¦ç³»ç»Ÿè¡¨ç°ï¼ˆTGC æ•°æ®é›†ï¼‰

| Model | 1st Frame | 0.5T | Full Horizon (T) |
|-------|----------|------|------------------|
| **FNO** | 3.15e-2 | â€” | â€” |
| **AVIT** | 1.26e-1 | 6.22e-1 | 1.32e0 |
| **BCAT** | 1.24e-1 | 9.89e-1 | 1.62e0 |
| **ECHO** | **1.13e-1** | **5.55e-1** | **6.67e-1** |

âœ… ECHO åœ¨ 3D é•¿æ—¶é¢„æµ‹ä¸­è¯¯å·®å¢é•¿æ›´ç¼“æ…¢ï¼Œè¡¨ç°å‡ºæ›´å¼ºçš„ç¨³å®šæ€§ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

- **åœ¨ä¸è§„åˆ™ç½‘æ ¼ä¸Šå…¨é¢é¢†å…ˆ**ï¼ˆTable 3ï¼‰ï¼š
  - åœ¨ Vorticity ä¸Šï¼ŒECHO çš„é‡æ„è¯¯å·®ä»…ä¸º **6.88e-2**ï¼Œè¿œä½äºç¬¬äºŒå ENMAï¼ˆ4.38e-1ï¼‰ï¼›
  - æ‰€æœ‰å…¶ä»–åŸºçº¿ï¼ˆGINOã€CORALã€AROMAï¼‰åœ¨éƒ¨åˆ†è§‚æµ‹ä¸‹æ€§èƒ½ä¸¥é‡ä¸‹é™ï¼Œè€Œ ECHO ä»ä¿æŒç¨³å¥ã€‚

- **å”¯ä¸€èƒ½å®Œæˆè¶…åˆ†è¾¨ç‡ä»»åŠ¡çš„æ–¹æ³•**ï¼ˆTable 4ï¼‰ï¼š
  - åœ¨ 1024Ã—1024 Vorticity ç½‘æ ¼ä¸Šè¿›è¡Œè¶…åˆ†è¾¨ç‡é¢„æµ‹æ—¶ï¼Œ**æ‰€æœ‰åŸºçº¿å‡ Out-of-Memory (OOM)**ï¼›
  - **åªæœ‰ ECHO æˆåŠŸè¿è¡Œå¹¶è¾¾åˆ° 3.88e-1 çš„ Relative MSE**ã€‚

- **ç”Ÿæˆè´¨é‡æ›´é«˜**ï¼ˆTable 16ï¼‰ï¼š
  - **FPD = 1.12e-3**ï¼Œæ˜¾è‘—ä½äº AROMAï¼ˆ1.55e-2ï¼‰ã€CALM-PDEï¼ˆ1.02e-1ï¼‰ç­‰ï¼›
  - è¡¨æ˜ ECHO ç”Ÿæˆçš„è½¨è¿¹åœ¨ç‰©ç†ç»Ÿè®¡ç‰¹æ€§ä¸Šæœ€æ¥è¿‘çœŸå®æ•°æ®ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰å±‚æ¬¡åŒ–å‹ç¼©çš„é‡è¦æ€§ï¼ˆTable 19ï¼‰
| å±‚æ¬¡æ•°ï¼ˆLevelsï¼‰ | 0 | 1 | 2 | 3 |
|------------------|-----|-----|------|-------|
| RMSE | 3.94e-1 | 3.64e-1 | 1.09e-1 | **2.87e-2** |

â¡ï¸ æ·±åº¦å±‚æ¬¡åŒ–å‹ç¼©æ˜¾è‘—æå‡é‡å»ºç²¾åº¦ï¼ŒéªŒè¯äº†æ¸è¿›å¼ä¸‹é‡‡æ ·çš„æœ‰æ•ˆæ€§ã€‚

#### ï¼ˆ2ï¼‰ç²¾è°ƒé˜¶æ®µçš„ä½œç”¨ï¼ˆTable 20ï¼‰
| æ˜¯å¦å¯ç”¨ç²¾è°ƒ | w/o refinement | w/refinement |
|--------------|----------------|---------------|
| Relative L2 | 2.24e-1 | **6.88e-2** |

â¡ï¸ é«˜åˆ†è¾¨ç‡å¸§ç²¾è°ƒä½¿è¯¯å·®é™ä½è¶…è¿‡ **3å€**ï¼Œå¯¹ç»†èŠ‚æ¢å¤è‡³å…³é‡è¦ã€‚

#### ï¼ˆ3ï¼‰ç”Ÿæˆè¿‡ç¨‹é²æ£’æ€§ï¼ˆTable 21ï¼‰
- ä¸åŒ ODE æ±‚è§£å™¨ï¼ˆEuler, Midpoint, RK4, DOPRI5ï¼‰å’Œä¸åŒç§¯åˆ†æ­¥æ•°ï¼ˆ2~25ï¼‰ä¸‹ï¼Œæ€§èƒ½å·®å¼‚æå°ï¼ˆ<1e-3ï¼‰ï¼›
- è¡¨æ˜ Flow Matching è®¾è®¡å…·æœ‰è‰¯å¥½çš„æ•°å€¼ç¨³å®šæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å±‚æ¬¡åŒ–æ—¶ç©ºå‹ç¼©æ˜¯å¤„ç†ç™¾ä¸‡ç‚¹ PDE çš„å…³é”®**ï¼šç›¸æ¯”ä¸€æ¬¡æ€§å‹ç¼©ï¼Œé€æ­¥å‹ç¼©èƒ½æ›´å¥½ä¿ç•™ç»†ç²’åº¦ç‰©ç†ç»“æ„ã€‚
2. **ç”Ÿæˆå¼å»ºæ¨¡ä¼˜äºç¡®å®šæ€§ä¸è‡ªå›å½’æ–¹æ³•**ï¼šé€šè¿‡ä¸€æ¬¡æ€§ç”Ÿæˆå®Œæ•´è½¨è¿¹ï¼Œæ˜¾è‘—æŠ‘åˆ¶äº†é•¿æ—¶é¢„æµ‹ä¸­çš„è¯¯å·®æ¼‚ç§»ã€‚
3. **ç»Ÿä¸€æ¡†æ¶æ”¯æŒå¤šä»»åŠ¡é›¶æ ·æœ¬æ¨ç†**ï¼šæ— éœ€é‡æ–°è®­ç»ƒå³å¯å¤„ç†å‰å‘ã€é€†å‘ã€æ’å€¼ã€è¶…åˆ†è¾¨ç‡ç­‰ä»»åŠ¡ã€‚
4. **ECHO æ˜¯ç›®å‰å”¯ä¸€èƒ½åœ¨æç«¯è§„æ¨¡ï¼ˆå¦‚ 1024Ã—1024ï¼‰ä¸ŠæˆåŠŸè¿è¡Œçš„ç¥ç»ç®—å­æ¨¡å‹**ï¼Œå±•ç°äº†å‰æ‰€æœªæœ‰çš„å¯æ‰©å±•æ€§ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡è®­ç»ƒæ•°æ®**ï¼šåœ¨æç«¯ç¨€ç–è¾“å…¥ï¼ˆå¦‚ 10% è§‚æµ‹ï¼‰ä¸‹æ€§èƒ½ä»æœ‰ä¸‹é™ï¼ˆè§ Table 18ï¼‰ï¼›
- **ç”Ÿæˆé€Ÿåº¦è™½å¿«ä½†ä»éå®æ—¶**ï¼šå°½ç®¡å»¶è¿Ÿå·²ä¼˜åŒ–è‡³ ~0.1â€“0.2 ç§’/è½¨è¿¹ï¼Œä½†åœ¨é«˜é¢‘æ§åˆ¶åœºæ™¯ä¸­å¯èƒ½ä»ä¸å¤Ÿï¼›
- **æœªå®Œå…¨è§£å†³â€œå¹»è§‰â€é—®é¢˜**ï¼šåœ¨æé•¿å¤–æ¨ï¼ˆ>4Ã—è®­ç»ƒé•¿åº¦ï¼‰æ—¶ï¼Œé«˜é¢‘ç»†èŠ‚é€æ¸ä¸¢å¤±ï¼ˆè§å›¾è°±åˆ†æ Fig. 17ï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢ **few-shot adaptation** åˆ°æ–°ç‰©ç†å‚æ•°çš„èƒ½åŠ›ï¼ˆæ–‡ä¸­å·²åˆæ­¥éªŒè¯ï¼‰ï¼›
- ç»“åˆ **ç‰©ç†çº¦æŸ** è¿›ä¸€æ­¥æå‡é•¿æœŸä¸€è‡´æ€§ï¼›
- æ‰©å±•åˆ° **å¤šç‰©ç†åœºè€¦åˆç³»ç»Ÿ** ä¸ **çœŸå®å·¥ç¨‹åœºæ™¯**ï¼ˆå¦‚æ°”å€™æ¨¡æ‹Ÿã€èˆªç©ºèˆªå¤©ï¼‰ï¼›
- å¼€å‘æ›´è½»é‡åŒ–çš„ç‰ˆæœ¬ä»¥æ”¯æŒè¾¹ç¼˜éƒ¨ç½²ã€‚

---

> **é¡¹ç›®ä¸»é¡µ**ï¼š[https://echo-pde.github.io/](https://echo-pde.github.io/)  
> **ä»£ç ä¸æ•°æ®å°†å¼€æº**ï¼Œä¿ƒè¿›å¯å¤ç°ç ”ç©¶ã€‚

</details>

---

### 11. [LangSAT: A Novel Framework Combining NLP and Reinforcement Learning for SAT Solving](https://arxiv.org/abs/2512.04374)

**Authors**: Muyu Pan, Matthew Walter, Dheeraj Kodakandla, Mahfuza Farooque  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.04374v1  

#### Abstract
Our work presents a novel reinforcement learning (RL) based framework to optimize heuristic selection within the conflict-driven clause learning (CDCL) process, improving the efficiency of Boolean satisfia- bility (SAT) solving. The proposed system, LangSAT, bridges the gap between natural language ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠLangSAT: A Novel Framework Combining NLP and Reinforcement Learning for SAT Solvingã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿ SAT æ±‚è§£å™¨è¦æ±‚è¾“å…¥ä¸ºæ ‡å‡†çš„ **Conjunctive Normal Form (CNF)** å½¢å¼ï¼Œè¿™ä½¿å¾—éä¸“ä¸šäººå£«éš¾ä»¥ç›´æ¥ä½¿ç”¨ SAT æŠ€æœ¯è§£å†³ç°å®ä¸–ç•Œä¸­çš„é€»è¾‘æ¨ç†é—®é¢˜ã€‚æ­¤å¤–ï¼Œç°æœ‰çš„ CDCL æ±‚è§£å™¨ä¾èµ–é™æ€å¯å‘å¼ï¼ˆå¦‚ VSIDSï¼‰ï¼Œåœ¨é¢å¯¹ç»“æ„å¤šå˜ã€ç”±è‡ªç„¶è¯­è¨€ç”Ÿæˆçš„ CNF å®ä¾‹æ—¶é€‚åº”æ€§è¾ƒå·®ã€‚

LangSAT é’ˆå¯¹ä»¥ä¸‹ä¸¤ä¸ªå…³é”®ç“¶é¢ˆæå‡ºè§£å†³æ–¹æ¡ˆï¼š
- **å¯è®¿é—®æ€§é—®é¢˜**ï¼šç”¨æˆ·éœ€å…·å¤‡å½¢å¼é€»è¾‘çŸ¥è¯†æ‰èƒ½æ„é€  CNF è¾“å…¥ã€‚
- **æ±‚è§£æ•ˆç‡é—®é¢˜**ï¼šä¼ ç»Ÿå¯å‘å¼éš¾ä»¥åº”å¯¹ NLP è½¬æ¢åå¸¦æ¥çš„ç»“æ„å¤šæ ·æ€§ä¸è¯­ä¹‰æ¨¡ç³Šæ€§ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

LangSAT æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯æ¡†æ¶ï¼Œèåˆ **Natural Language Processing (NLP)** å’Œ **Reinforcement Learning (RL)**ï¼Œå®ç°ä»è‡ªç„¶è¯­è¨€æè¿°åˆ° SAT å¯è§£å½¢å¼çš„è‡ªåŠ¨è½¬æ¢ä¸é«˜æ•ˆæ±‚è§£ã€‚å…¶æ ¸å¿ƒç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼š

#### ï¼ˆ1ï¼‰**Lang2Logic**  
å°†è‹±æ–‡è‡ªç„¶è¯­è¨€æè¿°è‡ªåŠ¨è½¬åŒ–ä¸ºç­‰ä»·çš„ CNF è¡¨è¾¾å¼ï¼ŒåŒ…å«ä¸‰ä¸ªé˜¶æ®µï¼š
- **Natural Language â†’ Logical Expression**ï¼šåˆ©ç”¨ **ChatGPT o1-mini API** å°†å¥å­è§£æä¸ºå½¢å¼åŒ–é€»è¾‘è¡¨è¾¾å¼ï¼ˆå¦‚ `And(Not(P), Or(Q,R))`ï¼‰ã€‚
- **Logical Expression â†’ CNF Conversion**ï¼šé€šè¿‡ **Lark parser** æ„å»ºè¯­æ³•æ ‘ï¼Œå¹¶å€ŸåŠ© **SymPy** å®Œæˆå‘ CNF çš„è½¬æ¢ã€‚
- **CNF Simplification**ï¼šä½¿ç”¨ SymPy çš„ `simplify_logic` å‡½æ•°å»é™¤å†—ä½™å­å¥ï¼Œæå‡åç»­æ±‚è§£æ•ˆç‡ã€‚

> âœ… åˆ›æ–°ç‚¹ï¼šé¦–æ¬¡å®ç°æ— éœ€äººå·¥å¹²é¢„çš„â€œè‡ªç„¶è¯­è¨€ â†’ CNFâ€å…¨è‡ªåŠ¨æµæ°´çº¿ï¼Œæ”¯æŒé•¿è¾¾ 450 è¯çš„å¤æ‚æ®µè½è¾“å…¥ã€‚

#### ï¼ˆ2ï¼‰**SmartSAT**  
ä¸€ç§åŸºäº **Reinforcement Learning** çš„å¢å¼ºå‹ CDCL SAT æ±‚è§£å™¨ï¼Œæ›¿ä»£ä¼ ç»Ÿçš„é™æ€å¯å‘å¼ç­–ç•¥ï¼ˆå¦‚ VSIDSï¼‰è¿›è¡Œå˜é‡é€‰æ‹©å†³ç­–ã€‚

- ä½¿ç”¨ **Proximal Policy Optimization (PPO)** ç®—æ³•è®­ç»ƒ RL Agentã€‚
- è§‚æµ‹ç©ºé—´ï¼ˆobservation spaceï¼‰åŒ…å«ï¼š
  - å½“å‰å˜é‡èµ‹å€¼çŠ¶æ€
  - å­å¥æ»¡è¶³æƒ…å†µ
  - åŸºäº **bipartite graph** çš„ clause-variable ç»“æ„è¡¨ç¤º
  - æ¥è‡ª **SATfeatPy** çš„ 48 ç»´å…¨å±€ç‰¹å¾ï¼ˆæºè‡ª SATzillaï¼‰
- åŠ¨ä½œç©ºé—´ï¼šé€‰æ‹©æŸä¸ªå˜é‡å¹¶èµ‹äºˆå¸ƒå°”å€¼ï¼ˆå…± 40 ä¸ªåŠ¨ä½œï¼Œå¯¹åº” 20 å˜é‡ Ã— 2 å€¼ï¼‰
- å¥–åŠ±æœºåˆ¶ï¼šæ¯æ»¡è¶³ä¸€ä¸ªå­å¥ +1ï¼Œæœªæ»¡è¶³åˆ™ -1ï¼Œæœ€å¤§å¥–åŠ±ä¸º 91ï¼ˆuf20-91 æ•°æ®é›†ï¼‰

> âœ… åˆ›æ–°ç‚¹ï¼šé¦–æ¬¡å°† RL ä¸å›¾ç»“æ„ç‰¹å¾ç»“åˆç”¨äº CDCL ä¸­çš„åŠ¨æ€å¯å‘å¼å­¦ä¹ ï¼Œæå‡äº†å¯¹å¤šæ ·åŒ– CNF ç»“æ„çš„æ³›åŒ–èƒ½åŠ›ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³• | LangSAT |
|------|--------|--------|
| è¾“å…¥å½¢å¼ | å¿…é¡»æ˜¯ CNF æˆ–å½¢å¼é€»è¾‘ | æ”¯æŒè‡ªç„¶è¯­è¨€è¾“å…¥ |
| ç”¨æˆ·é—¨æ§› | é«˜ï¼ˆéœ€æ‡‚é€»è¾‘å»ºæ¨¡ï¼‰ | ä½ï¼ˆæ™®é€šäººå¯æè¿°é—®é¢˜ï¼‰ |
| å†³ç­–å¯å‘å¼ | é™æ€ï¼ˆå¦‚ VSIDSï¼‰ | åŠ¨æ€å­¦ä¹ ï¼ˆRL è‡ªé€‚åº”è°ƒæ•´ï¼‰ |
| å¯¹ NLP ç”Ÿæˆ CNF çš„é€‚åº”æ€§ | å·®ï¼ˆç»“æ„ä¸è§„åˆ™æ˜“å¤±æ•ˆï¼‰ | å¼ºï¼ˆé€šè¿‡ RL å­¦ä¹ ç»“æ„æ¨¡å¼ï¼‰ |
| å¯æ‰©å±•æ€§ | æœ‰é™ | æ˜“æ‰©å±•è‡³ä»£ç ã€å¯¹è¯ç­‰æ–°è¾“å…¥æº |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“Š ä½¿ç”¨çš„æ•°æ®é›†

- ä¸»è¦æµ‹è¯•æ•°æ®é›†ï¼š**uf20-91**ï¼ˆæ¥è‡ª SATLIBï¼‰
  - åŒ…å« 1000 ä¸ªå¯æ»¡è¶³ï¼ˆsatisfiableï¼‰çš„éšæœº 3-SAT å®ä¾‹
  - æ¯ä¸ªå®ä¾‹æœ‰ 20 ä¸ªå˜é‡ã€91 ä¸ªå­å¥
  - æ ‡å‡† DIMACS-CNF æ ¼å¼
- æ•°æ®åˆ’åˆ†ï¼š
  - è®­ç»ƒé›†ï¼š800 ä¸ªæ–‡ä»¶
  - æµ‹è¯•é›†ï¼š200 ä¸ªæ–‡ä»¶

> æ³¨ï¼šè™½ç„¶ Lang2Logic å¤„ç†çš„æ˜¯è‡ªç„¶è¯­è¨€ï¼Œä½† SmartSAT çš„è¯„ä¼°ä»åŸºäºæ ‡å‡† CNF å®ä¾‹ä»¥ç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

---

### âš™ï¸ å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### å®éªŒæµç¨‹
1. Lang2Logic æ¥æ”¶è‡ªç„¶è¯­è¨€è¾“å…¥ â†’ è¾“å‡ºç®€åŒ–åçš„ CNF
2. SmartSAT æ¥æ”¶è¯¥ CNF â†’ è¿è¡Œ RL å¢å¼ºçš„ CDCL æ±‚è§£
3. è®°å½•æ±‚è§£æ—¶é—´ã€æ˜¯å¦æˆåŠŸåˆ¤å®š SAT/UNSAT

#### è¯„ä¼°æŒ‡æ ‡
- **æ€»æ±‚è§£æ—¶é—´ï¼ˆTotal Solving Timeï¼‰**ï¼šä¸»è¦æ€§èƒ½æŒ‡æ ‡
- **ä¸­ä½æ•°æ±‚è§£æ—¶é—´ï¼ˆMedian Solving Timeï¼‰**
- **ä¼˜äºåŸºçº¿çš„æ¯”ä¾‹**ï¼šSmartSAT åœ¨å¤šå°‘æ¯”ä¾‹çš„é—®é¢˜ä¸Šå¿«äºåŸºçº¿
- **ç¨³å®šæ€§åˆ†æ**ï¼šè§‚å¯Ÿè¿è¡Œæ—¶é—´åˆ†å¸ƒçš„ç¦»æ•£ç¨‹åº¦ï¼ˆæ˜¯å¦æœ‰è¾ƒå¤šå¼‚å¸¸å€¼ï¼‰

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline CDCL Solver**ï¼šé‡‡ç”¨ç»å…¸ **VSIDS å¯å‘å¼** çš„ä¼ ç»Ÿ CDCL æ±‚è§£å™¨
- å¯¹æ¯”æ¡ä»¶å®Œå…¨ä¸€è‡´ï¼š
  - ç›¸åŒç¡¬ä»¶ç¯å¢ƒ
  - ç›¸åŒå‚æ•°é…ç½®
  - ç›¸åŒæµ‹è¯•é›†ï¼ˆuf20-91 æµ‹è¯•å­é›†ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

| æŒ‡æ ‡ | SmartSAT | Baseline CDCL (VSIDS) |
|------|----------|------------------------|
| ä¸­ä½æ•°æ±‚è§£æ—¶é—´ | **1.02 ç§’** | **1.02 ç§’** |
| å¹³å‡æ±‚è§£æ—¶é—´èŒƒå›´ | 1.01â€“1.05 ç§’ | 1.01â€“1.05 ç§’ |
| æ›´å¿«çš„é—®é¢˜å æ¯” | **çº¦ 53%** | â€” |
| æ—¶é—´æ³¢åŠ¨æ€§ | è¾ƒå°ï¼ˆæ›´ç¨³å®šï¼‰ | å­˜åœ¨æ›´å¤šé«˜å»¶è¿Ÿ outlier |

> å›¾ 4 æ˜¾ç¤º SmartSAT çš„è¿è¡Œæ—¶é—´åˆ†å¸ƒæ›´åŠ é›†ä¸­ï¼Œè¡¨æ˜å…¶å†³ç­–æ›´å…·ä¸€è‡´æ€§ã€‚

---

### ğŸ” ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

- **æ€§èƒ½æŒå¹³ä½†ç•¥æœ‰ä¼˜åŠ¿**ï¼š
  - ä¸­ä½æ—¶é—´ç›¸åŒï¼ˆ1.02sï¼‰ï¼Œä½† SmartSAT åœ¨ **53% çš„æµ‹è¯•å®ä¾‹ä¸Šæ›´å¿«**
  - ç‰¹åˆ«æ˜¯åœ¨æŸäº›ç»“æ„å¤æ‚çš„å®ä¾‹ä¸­è¡¨ç°æ›´ä¼˜
- **æ›´å¼ºçš„é²æ£’æ€§**ï¼š
  - VSIDS åœ¨éƒ¨åˆ†é—®é¢˜ä¸Šå‡ºç°æ˜¾è‘—å»¶è¿Ÿï¼ˆå¯èƒ½å› å¯å‘å¼é™·å…¥å±€éƒ¨ä½æ•ˆè·¯å¾„ï¼‰
  - SmartSAT å›  RL å­¦ä¹ äº†å…¨å±€ç»“æ„ç‰¹å¾ï¼Œèƒ½æ›´å¥½è§„é¿ä½æ•ˆåˆ†æ”¯

> â€œAlthough both models attained nearly identical median times, SmartSAT performed more consistently across a broader range of CNF structures.â€

---

### âŒ æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰

åŸæ–‡æœªæ˜ç¡®æä¾›ç³»ç»Ÿçš„æ¶ˆèå®éªŒï¼ˆå¦‚ç§»é™¤å›¾ç»“æ„ã€å»æ‰å…¨å±€ç‰¹å¾ç­‰ï¼‰ï¼Œä½†åœ¨è®¨è®ºä¸­æåŠä»¥ä¸‹å…³é”®è®¾è®¡çš„é‡è¦æ€§ï¼š

- **Graph Representation**ï¼šclause-variable bipartite graph æä¾›ç»“æ„æ„ŸçŸ¥èƒ½åŠ›ï¼Œæ˜¯ RL å­¦ä¹ çš„åŸºç¡€ã€‚
- **Global Features (from SATfeatPy)**ï¼šç»§æ‰¿è‡ª SATzilla çš„ 48 ç»´ç‰¹å¾æ˜¾è‘—å¢å¼ºäº†æ¨¡å‹å¯¹é—®é¢˜æ•´ä½“ç‰¹æ€§çš„ç†è§£ã€‚
- **PPO ç­–ç•¥æ›´æ–°æœºåˆ¶**ï¼šä¿è¯è®­ç»ƒè¿‡ç¨‹ç¨³å®šï¼Œé¿å…ç­–ç•¥å´©æºƒã€‚

> è™½æ— å®šé‡æ¶ˆèï¼Œä½†ä»æ¶æ„è®¾è®¡çœ‹ï¼Œè¿™äº›æ¨¡å—è¢«è®¤ä¸ºæ˜¯ SmartSAT æˆåŠŸçš„å…³é”®ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **Lang2Logic æˆåŠŸå®ç°äº†è‡ªç„¶è¯­è¨€åˆ° CNF çš„æœ‰æ•ˆè½¬åŒ–**  
   - æ”¯æŒé•¿æ–‡æœ¬ï¼ˆup to 450 wordsï¼‰ã€å¤šå¥å­é€»è¾‘æ¨ç†
   - è¾“å‡º CNF æ­£ç¡®ä¸”å¯ç”¨äºæ±‚è§£ï¼ŒéªŒè¯äº† NLP åœ¨å½¢å¼åŒ–é€»è¾‘è½¬æ¢ä¸­çš„å¯è¡Œæ€§

2. **SmartSAT å±•ç°å‡ºåª²ç¾ç”šè‡³ç•¥ä¼˜äºä¼ ç»Ÿ CDCL çš„æ±‚è§£æ•ˆç‡**  
   - åœ¨ uf20-91 ä¸Šè¾¾åˆ°ä¸ VSIDS ç›¸å½“çš„ä¸­ä½æ±‚è§£æ—¶é—´
   - åœ¨è¶…è¿‡ä¸€åŠçš„å®ä¾‹ä¸Šæ›´å¿«ï¼Œä¸”ç»“æœæ›´ç¨³å®š
   - è¡¨æ˜ RL å¯ä½œä¸º CDCL ä¸­æœ‰æ•ˆçš„åŠ¨æ€å¯å‘å¼æ›¿ä»£æ–¹æ¡ˆ

3. **RL ç‰¹åˆ«é€‚åˆå¤„ç†ç”± NLP ç”Ÿæˆçš„éè§„èŒƒ CNF å®ä¾‹**  
   - å› è¯­è¨€æ­§ä¹‰å¯¼è‡´çš„ç»“æ„å¤šæ ·æ€§å¯é€šè¿‡ RL çš„è‡ªé€‚åº”å†³ç­–æœºåˆ¶æ›´å¥½åœ°åº”å¯¹
   - ç›¸æ¯”å›ºå®šå¯å‘å¼æ›´å…·æ³›åŒ–æ½œåŠ›

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

1. **Lang2Logic ä¾èµ–å¤–éƒ¨ LLMï¼ˆChatGPT APIï¼‰**
   - å­˜åœ¨æˆæœ¬ã€å»¶è¿Ÿã€éšç§ç­‰é—®é¢˜
   - æ€§èƒ½åœ¨é•¿æ–‡æœ¬æˆ–å¤æ‚è¯­æ³•ä¸‹å¯èƒ½å‡ºç°ä¸ç¨³å®š

2. **å½“å‰è¯„ä¼°ä»åŸºäºäººå·¥åˆæˆ CNFï¼ˆuf20-91ï¼‰**
   - å°šæœªå®Œæ•´é—­ç¯æµ‹è¯•â€œè‡ªç„¶è¯­è¨€ â†’ Lang2Logic â†’ SmartSATâ€çš„å…¨æµç¨‹æ€§èƒ½
   - ç¼ºä¹çœŸå®åº”ç”¨åœºæ™¯ä¸‹çš„ç«¯åˆ°ç«¯è¯„æµ‹ï¼ˆå¦‚è½¯ä»¶éªŒè¯ã€æ—¥å¸¸æ¨ç†ä»»åŠ¡ï¼‰

3. **SmartSAT è®­ç»ƒå¼€é”€è¾ƒå¤§**
   - å• epoch çº¦ 100,000 æ­¥è®­ç»ƒï¼Œè®¡ç®—èµ„æºéœ€æ±‚è¾ƒé«˜
   - å®é™…éƒ¨ç½²å¯èƒ½å­˜åœ¨æŒ‘æˆ˜

4. **å°šæœªéªŒè¯åœ¨ UNSAT å®ä¾‹ä¸Šçš„è¡¨ç°**
   - æ‰€æœ‰æµ‹è¯•å‡ä¸º satisfiable å®ä¾‹ï¼Œå¯¹è¯æ˜èƒ½åŠ›ï¼ˆproof generationï¼‰ç¼ºä¹è¯„ä¼°

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å¤§è¾“å…¥å¤šæ ·æ€§**
   - å°†è¾“å…¥æ‰©å±•è‡³ **machine code**ï¼ˆæœºå™¨ç ï¼‰ã€ç¨‹åºç‰‡æ®µç­‰ï¼Œè¿›ä¸€æ­¥æ‹“å®½åº”ç”¨è¾¹ç•Œ

2. **å¢å¼º SmartSAT çš„ç‰¹å¾æå–èƒ½åŠ›**
   - å¼•å…¥æ›´å¤šå…¨å±€ç‰¹å¾ï¼Œæå‡å¯¹ä¸åŒ SAT é—®é¢˜ç±»åˆ«çš„è¯†åˆ«ä¸ä¼˜åŒ–èƒ½åŠ›

3. **è·¨æ•°æ®é›†æ€§èƒ½è¯„ä¼°**
   - åœ¨å¤šä¸ª SAT é—®é¢˜ç±»åˆ«ï¼ˆå¦‚ industrial, crafted, randomï¼‰ä¸Šæµ‹è¯• SmartSAT çš„é€šç”¨æ€§

4. **æ„å»ºç«¯åˆ°ç«¯è¯„ä¼°åŸºå‡†**
   - è®¾è®¡åŒ…å«è‡ªç„¶è¯­è¨€æè¿° â†’ çœŸå®é€»è¾‘é—®é¢˜ â†’ æ ‡å‡†ç­”æ¡ˆçš„ benchmarkï¼Œå…¨é¢è¡¡é‡ LangSAT æ•´ä½“æ€§èƒ½

5. **æ¢ç´¢æœ¬åœ°åŒ– LLM æ›¿ä»£æ–¹æ¡ˆ**
   - ä½¿ç”¨å¼€æºå°å‹ LLM æ›¿ä»£ ChatGPT APIï¼Œé™ä½ä¾èµ–ä¸æˆæœ¬

---

## æ€»ç»“

LangSAT æ˜¯ä¸€é¡¹å¼€åˆ›æ€§çš„å·¥ä½œï¼Œé¦–æ¬¡å°† **NLP** ä¸ **Reinforcement Learning** æ·±åº¦æ•´åˆè¿› SAT æ±‚è§£æµç¨‹ï¼Œæå‡ºäº†ä¸€ä¸ªçœŸæ­£æ„ä¹‰ä¸Šçš„â€œè‡ªç„¶è¯­è¨€é©±åŠ¨â€çš„è‡ªåŠ¨åŒ–é€»è¾‘æ±‚è§£ç³»ç»Ÿã€‚å®ƒä¸ä»…æé«˜äº† SAT æŠ€æœ¯çš„å¯ç”¨æ€§å’Œæ™®åŠæ€§ï¼Œä¹Ÿä¸ºæœªæ¥æ™ºèƒ½æ¨ç†ç³»ç»Ÿçš„å‘å±•æä¾›äº†æ–°çš„èŒƒå¼ã€‚

> **ä¸€å¥è¯æ€»ç»“**ï¼šLangSAT = è‡ªç„¶è¯­è¨€æ¥å£ + RL å¢å¼ºæ±‚è§£å™¨ï¼Œè®©æ™®é€šäººä¹Ÿèƒ½â€œç”¨è¯´è¯çš„æ–¹å¼â€è°ƒç”¨å¼ºå¤§çš„å½¢å¼åŒ–æ¨ç†å¼•æ“ã€‚

</details>

---

### 12. [EtCon: Edit-then-Consolidate for Reliable Knowledge Editing](https://arxiv.org/abs/2512.04753)

**Authors**: Ruilin Li, Yibin Wang, Wenhong Zhu, Chenglin Li, Jinghao Zhang, Chenliang Li, Junchi Yan, Jiaqi Wang  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.04753v1  

#### Abstract
Knowledge editing aims to update specific facts in large language models (LLMs) without full retraining. Prior efforts sought to tune the knowledge layers of LLMs, proving effective for making selective edits. However, a significant gap exists between their performance in controlled, teacher-forcing...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šEtCon: Edit-then-Consolidate for Reliable Knowledge Editing**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**
å½“å‰çš„çŸ¥è¯†ç¼–è¾‘ï¼ˆKnowledge Editingï¼‰æ–¹æ³•åœ¨å—æ§ç¯å¢ƒï¼ˆå¦‚ teacher-forcing è¯„ä¼°ï¼‰ä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨çœŸå®ä¸–ç•Œåœºæ™¯ï¼ˆå¦‚è‡ªå›å½’ç”Ÿæˆã€ç»ˆèº«å­¦ä¹ ï¼‰ä¸­æ•ˆæœæ˜¾è‘—ä¸‹é™ã€‚ä½œè€…é€šè¿‡å®è¯åˆ†ææ­ç¤ºäº†ä¸¤ä¸ªæ ¹æœ¬åŸå› ï¼š
- **è¿‡æ‹Ÿåˆé—®é¢˜**ï¼šä¼ ç»Ÿæ–¹æ³•å¯¼è‡´æ¨¡å‹è¿‡åº¦é€‚åº”æ–°äº‹å®ï¼ŒæŸå®³é¢„è®­ç»ƒèƒ½åŠ›ï¼ˆå¦‚æ¨ç†ã€è¯­è¨€æµç•…æ€§ï¼‰ã€‚
- **ç¼ºä¹çŸ¥è¯†å·©å›ºé˜¶æ®µ**ï¼šæ–°çŸ¥è¯†è™½è¢«å‚æ•°åŒ–åœ°å†™å…¥æ¨¡å‹æƒé‡ï¼Œä½†æœªèƒ½æœ‰æ•ˆæ•´åˆåˆ°æ¨¡å‹çš„æ¨ç†è¡Œä¸ºä¸­ï¼Œå¯¼è‡´â€œçŸ¥è¯†-è¡Œä¸ºå¤±é…â€ï¼ˆknowledge-behavior misalignmentï¼‰ï¼Œå³æ¨¡å‹çŸ¥é“æ–°çŸ¥è¯†å´æ— æ³•åœ¨ç”Ÿæˆæ—¶æ­£ç¡®è°ƒç”¨ã€‚

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**
ä½œè€…æå‡º **Edit-then-Consolidate (EtCon)** èŒƒå¼ï¼Œå°†çŸ¥è¯†ç¼–è¾‘åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼š
1. **ç¼–è¾‘é˜¶æ®µï¼ˆEdit Stageï¼‰**ï¼šé‡‡ç”¨ **Targeted Proximal Supervised Fine-Tuning (TPSFT)** å¯¹é€‰å®šçš„ FFN å±‚è¿›è¡Œå±€éƒ¨æ›´æ–°ï¼Œç»“åˆä¿¡ä»»åŒºåŸŸçº¦æŸï¼ˆtrust-regionï¼‰é˜²æ­¢ç­–ç•¥æ¼‚ç§»ï¼Œç¼“è§£è¿‡æ‹Ÿåˆã€‚
2. **å·©å›ºé˜¶æ®µï¼ˆConsolidate Stageï¼‰**ï¼šå¼•å…¥ **Group Relative Policy Optimization (GRPO)**ï¼Œé€šè¿‡è½¨è¿¹çº§ä¼˜åŒ–ï¼ˆtrajectory-level optimizationï¼‰å’Œç»¼åˆå¥–åŠ±ä¿¡å·ï¼ˆcomprehensive rewardï¼‰ï¼Œå°†ç¼–è¾‘åçš„çŸ¥è¯†ä¸æ¨¡å‹çš„ CoT æ¨ç†ç­–ç•¥å¯¹é½ï¼Œç¡®ä¿æ–°çŸ¥è¯†èƒ½åœ¨è‡ªå›å½’ç”Ÿæˆä¸­è¢«ç¨³å®šæ¿€æ´»ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- **æ›´é«˜çš„å¯é æ€§ä¸æ³›åŒ–èƒ½åŠ›**ï¼šåœ¨çœŸå®è¯„ä¼°ä¸‹ï¼ŒEtCon å°†ç¼–è¾‘æˆåŠŸç‡æå‡ 35%-50%ï¼Œè¿œè¶…ç°æœ‰æ–¹æ³•ã€‚
- **æ›´å¼ºçš„å±€éƒ¨æ€§ï¼ˆLocalityï¼‰**ï¼šä»…ä¿®æ”¹ç‰¹å®š FFN å±‚ï¼Œå‡å°‘å¯¹æ— å…³çŸ¥è¯†çš„å¹²æ‰°ã€‚
- **ä¿ç•™é¢„è®­ç»ƒèƒ½åŠ›**ï¼šé€šè¿‡ TPSFT å’Œ GRPO çš„ååŒè®¾è®¡ï¼Œé¿å…æ¨¡å‹å´©æºƒæˆ–é€šç”¨èƒ½åŠ›é€€åŒ–ã€‚
- **é€‚ç”¨äºç»ˆèº«å­¦ä¹ åœºæ™¯**ï¼šæ”¯æŒæ•°åƒæ¬¡è¿ç»­ç¼–è¾‘è€Œæ€§èƒ½ç¼“æ…¢ä¸‹é™ï¼Œå…·å¤‡å®é™…éƒ¨ç½²æ½œåŠ›ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **ZsRE**ï¼šé›¶æ ·æœ¬å…³ç³»æŠ½å–æ•°æ®é›†ï¼Œç”¨äºæµ‹è¯•äº‹å®æ›´æ–°ã€‚
- **COUNTERFACT**ï¼šåäº‹å®ç¼–è¾‘åŸºå‡†ï¼Œè¯„ä¼°æ¨¡å‹å¯¹é”™è¯¯å‰æçš„çº æ­£èƒ½åŠ›ã€‚
- **QAEdit**ï¼šé—®ç­”å½¢å¼çš„çŸ¥è¯†ç¼–è¾‘æ•°æ®é›†ï¼Œå¼ºè°ƒæ¨ç†ä¸€è‡´æ€§ã€‚
- **é€šç”¨èƒ½åŠ›è¯„ä¼°é›†**ï¼šC-Evalã€CoQAã€DROPã€SQuAD 2.0ã€LogiQAï¼Œç”¨äºéªŒè¯ç¼–è¾‘åæ¨¡å‹é€šç”¨æ€§èƒ½æ˜¯å¦å—æŸã€‚

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**
- **æ¨¡å‹**ï¼šLlama-3-8B-Instruct å’Œ Qwen2.5-7B-Instructã€‚
- **è¯„ä¼°æ–¹å¼**ï¼šé‡‡ç”¨ **real-world evaluation** è®¾ç½®ï¼š
  - è¾“å…¥åŒ…å«éœ€å¤šæ­¥æ¨ç†çš„é—®é¢˜ï¼Œå¹¶æç¤º â€œPlease reason step by step, then answerâ€ã€‚
  - è¾“å‡ºä¸ºå®Œæ•´è‡ªå›å½’ç”Ÿæˆç»“æœï¼ˆéæˆªæ–­ï¼‰ã€‚
  - ä½¿ç”¨ **LLM-as-a-judge** åè®®ï¼ˆGPT-4.1ï¼‰è¿›è¡ŒäºŒå…ƒè¯„åˆ†ï¼ˆCorrect/Incorrectï¼‰ã€‚
- **ä¸‰å¤§æ ¸å¿ƒæŒ‡æ ‡**ï¼š
  - **Reliability (Reli.)**ï¼šç¼–è¾‘æˆåŠŸæ¯”ä¾‹ï¼ˆP(new fact) > P(old fact)ï¼‰ã€‚
  - **Generalization (Gen.)**ï¼šåœ¨æ”¹å†™é—®é¢˜ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚
  - **Locality (Loc.)**ï¼šå¯¹æœªç¼–è¾‘ç›¸å…³é—®é¢˜çš„å›ç­”ç¨³å®šæ€§ã€‚

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
- **Parametric In-Place Editing**ï¼š
  - FT-Mã€MEMITã€ALPHAEDITã€MMKE
- **External-Assisted Editing**ï¼š
  - WISEï¼ˆmemory-based SOTAï¼‰
- æ‰€æœ‰æ–¹æ³•å‡åœ¨ç›¸åŒæ¡†æ¶ï¼ˆEasyEditï¼‰ä¸‹å¤ç°ï¼Œä¿è¯å…¬å¹³æ¯”è¾ƒã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
åœ¨ **Qwen2.5-7B-Instruct** ä¸Šçš„å¹³å‡è¡¨ç°ï¼ˆZsRE & QAEditï¼‰ï¼š
| æ–¹æ³• | Reliability | Generalization | Locality |
|------|------------|----------------|----------|
| FT-M | 5.6% | 5.5% | 23.1% |
| WISE | 4.5% | 3.3% | 19.1% |
| ALPHAEDIT | 15.9% | 11.5% | 6.8% |
| **EtCon (Ours)** | **69.4%** | **60.8%** | **24.4%** |

åœ¨ **Llama-3-8B-Instruct** ä¸Šçš„è¡¨ç°ï¼š
| æ–¹æ³• | Reliability (ZsRE) | Generalization (ZsRE) | Locality |
|------|--------------------|------------------------|---------|
| FT-M | 16.6% | 15.5% | 29.3% |
| ALPHAEDIT | 18.7% | 14.0% | 6.3% |
| **EtCon (Ours)** | **73.5%** | **63.1%** | **30.2%** |

> âœ… **æå‡å¹…åº¦è¾¾ 40%-50%**ï¼Œä¸” Locality æ›´ä¼˜ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- **MEMIT å’Œ ALPHAEDIT åœ¨ç»ˆèº«ç¼–è¾‘ä¸­å´©æºƒ**ï¼šåœ¨ Qwen ä¸Šæ¥è¿‘ 0% æ€§èƒ½ï¼Œè¡¨æ˜å…¶ä¸é€‚ç”¨äºè¿ç»­ç¼–è¾‘ã€‚
- **FT-M å’Œ WISE è¡¨ç°ç¨³å®šä½†æ€§èƒ½æä½**ï¼šå¯é æ€§ä¸è¶³ 30%ï¼Œè¿œä½äº EtConã€‚
- **EtCon æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿**ï¼Œå°¤å…¶åœ¨ Generalization ä¸Šä½“ç°å…¶çœŸæ­£â€œç†è§£â€è€Œéæœºæ¢°è®°å¿†ã€‚

### **æ¶ˆèå®éªŒç»“æœ**
åœ¨ **COUNTERFACT + Llama-3-8B-Instruct** ä¸Šçš„æ¶ˆèç ”ç©¶ï¼ˆTable 4ï¼‰ï¼š
| é˜¶æ®µ | æ–¹æ³• | Reli. | Gen. | Loc. |
|------|------|-------|------|------|
| Base | â€“ | 0.6% | 0.8% | 31.8% |
| Edit | w/ SFT | 1.4% | 0.3% | 30.7% |
| Edit | w/ TPSFT | 3.3% | 1.8% | 30.2% |
| Consolidate | w/o R_cleanliness | 56.1% | 22.4% | 24.7% |
| Consolidate | w/o R_consistency | 51.6% | 27.2% | 25.1% |
| Complete | EtCon | **67.1%** | **53.4%** | **24.2%** |

#### **å…³é”®å‘ç°**ï¼š
- **TPSFT æ¯”æ ‡å‡† SFT æ›´æœ‰æ•ˆä¿æŠ¤é€šç”¨èƒ½åŠ›**ã€‚
- **å»é™¤ R_cleanliness** å¯¼è‡´â€œå¥–åŠ±é»‘å®¢â€ï¼ˆreward hackingï¼‰ï¼šæ¨¡å‹è¾“å‡ºå†—ä½™å†…å®¹ï¼ˆå¦‚åŒæ—¶åˆ—å‡ºæ–°æ—§ç­”æ¡ˆï¼‰ä»¥æœ€å¤§åŒ–å¾—åˆ†ã€‚
- **å»é™¤ R_consistency** å¼•å‘é€»è¾‘çŸ›ç›¾ï¼ˆå¦‚å…ˆè¯´æ­£ç¡®ç­”æ¡ˆå†è‡ªæˆ‘å¦å®šï¼‰ï¼Œå¯é æ€§å¤§å¹…ä¸‹é™ã€‚
- å®Œæ•´ EtCon å®ç°æœ€ä½³å¹³è¡¡ï¼Œè¯æ˜å„ç»„ä»¶ä¸å¯æˆ–ç¼ºã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **çŸ¥è¯†ç¼–è¾‘å¤±è´¥çš„æ ¹æœ¬åŸå› æ˜¯ç¼ºå°‘â€œå·©å›ºé˜¶æ®µâ€**ï¼šä»…å‚æ•°æ›´æ–°ä¸è¶³ä»¥è®©æ¨¡å‹åœ¨æ¨ç†ä¸­ç¨³å®šä½¿ç”¨æ–°çŸ¥è¯†ã€‚
2. **Edit-then-Consolidate æ˜¯å¿…è¦èŒƒå¼**ï¼šç¼–è¾‘ï¼ˆparametric updateï¼‰ä¸å·©å›ºï¼ˆbehavioral alignmentï¼‰åº”è§£è€¦å¤„ç†ã€‚
3. **TPSFT + GRPO ç»„åˆæ˜¾è‘—æå‡çœŸå®åœºæ™¯ä¸‹çš„ç¼–è¾‘å¯é æ€§**ï¼Œå®ç°é«˜æˆåŠŸç‡ã€å¼ºæ³›åŒ–ã€è‰¯å¥½å±€éƒ¨æ€§ã€‚
4. **ç°æœ‰æ–¹æ³•åœ¨ç»ˆèº«ç¼–è¾‘ä¸­ä¸å¯é **ï¼šå¤šæ•°æ–¹æ³•å› ç´¯ç§¯è¯¯å·®å¯¼è‡´æ¨¡å‹å´©æºƒï¼Œè€Œ EtCon å¯æ”¯æŒå¤šè¾¾ 3000 æ¬¡è¿ç»­ç¼–è¾‘ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **è®¡ç®—å¼€é”€è¾ƒé«˜**ï¼šTPSFT ç¼–è¾‘æ—¶é—´çº¦ 6 ç§’/å®ä¾‹ï¼Œé«˜äº FT-Mï¼ˆ0.61sï¼‰ï¼Œä½†ä¸å…¶ä»–å‚æ•°ç¼–è¾‘æ–¹æ³•ç›¸å½“ã€‚
- **ä¾èµ– CoT æ•°æ®è´¨é‡**ï¼šTPSFT ä½¿ç”¨åŸå§‹æ¨¡å‹ç”Ÿæˆçš„ CoT ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œè‹¥åˆå§‹æ¨ç†é”™è¯¯å¯èƒ½å¼•å…¥å™ªå£°ã€‚
- **å±‚é€‰æ‹©æ•æ„Ÿ**ï¼šå®éªŒæ˜¾ç¤ºç¼–è¾‘æµ…å±‚ï¼ˆshallow layersï¼‰æ•ˆæœæ›´ä¼˜ï¼Œæ·±å±‚ç¼–è¾‘æ˜“å¼•å‘â€œè®¤çŸ¥å†²çªâ€ä¸å¥–åŠ±é»‘å®¢ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ¢ç´¢æ›´é«˜æ•ˆçš„ consolidation ç®—æ³•ï¼Œé™ä½è®­ç»ƒæˆæœ¬ã€‚
- è‡ªåŠ¨è¯†åˆ«æœ€ä¼˜ç¼–è¾‘å±‚æˆ–ç¥ç»å…ƒï¼Œæå‡è‡ªåŠ¨åŒ–ç¨‹åº¦ã€‚
- å°† EtCon æ‰©å±•è‡³å¤šæ¨¡æ€æ¨¡å‹æˆ–æ›´å¤æ‚ä»»åŠ¡ï¼ˆå¦‚è§„åˆ’ã€å†³ç­–ï¼‰ã€‚
- ç»“åˆ retrieval-augmented æ–¹æ³•ï¼Œæ„å»ºå¯é•¿æœŸè‡ªæ›´æ–°çš„ LLM æ¶æ„ã€‚

---

> ğŸ”š **æ€»ç»“**ï¼š  
> **EtCon** æå‡ºäº†ä¸€ç§å…¨æ–°çš„ä¸¤é˜¶æ®µçŸ¥è¯†ç¼–è¾‘èŒƒå¼ï¼Œé¦–æ¬¡ç³»ç»Ÿæ€§è§£å†³â€œçŸ¥è¯†-è¡Œä¸ºå¤±é…â€é—®é¢˜ã€‚å…¶å®éªŒå……åˆ†éªŒè¯äº† **consolidation é˜¶æ®µçš„å¿…è¦æ€§**ï¼Œå¹¶å±•ç¤ºäº†åœ¨çœŸå®åœºæ™¯ä¸‹å“è¶Šçš„ç¼–è¾‘æ€§èƒ½ï¼Œä¸ºå¯é ã€å¯æŒç»­çš„çŸ¥è¯†æ›´æ–°æä¾›äº†é‡è¦å®è·µè·¯å¾„ã€‚

</details>

---

### 13. [SEAL: Self-Evolving Agentic Learning for Conversational Question Answering over Knowledge Graphs](https://arxiv.org/abs/2512.04868)

**Authors**: Hao Wang, Jialun Zhong, Changcheng Wang, Zhujun Nie, Zheng Li, Shunyu Yao, Yanzeng Li, Xinchi Li  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.04868v1  

#### Abstract
Knowledge-based conversational question answering (KBCQA) confronts persistent challenges in resolving coreference, modeling contextual dependencies, and executing complex logical reasoning. Existing approaches, whether end-to-end semantic parsing or stepwise agent-based reasoning, often suffer from...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šSEAL: Self-Evolving Agentic Learning for Conversational Question Answering over Knowledge Graphs

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**åŸºäºçŸ¥è¯†å›¾è°±çš„å¯¹è¯é—®ç­”ï¼ˆKBCQAï¼‰**ä¸­çš„ä¸‰å¤§æŒ‘æˆ˜ï¼š
- **æŒ‡ä»£æ¶ˆè§£ï¼ˆcoreference resolutionï¼‰**ï¼šå¤šè½®å¯¹è¯ä¸­ç”¨æˆ·ä½¿ç”¨ä»£è¯æˆ–çœç•¥è¡¨è¾¾æ—¶éš¾ä»¥å‡†ç¡®ç†è§£å…¶æŒ‡å‘ã€‚
- **ä¸Šä¸‹æ–‡ä¾èµ–å»ºæ¨¡ï¼ˆcontextual dependenciesï¼‰**ï¼šéœ€è¦æœ‰æ•ˆåˆ©ç”¨å†å²å¯¹è¯ä¿¡æ¯è¿›è¡Œæ¨ç†ã€‚
- **å¤æ‚é€»è¾‘æ¨ç†ï¼ˆcomplex logical reasoningï¼‰**ï¼šå¦‚å¤šè·³æ¨ç†ã€æ¯”è¾ƒã€èšåˆç­‰ä»»åŠ¡ï¼Œä¼ ç»Ÿæ–¹æ³•åœ¨ç”Ÿæˆç»“æ„åŒ–æŸ¥è¯¢ï¼ˆå¦‚SPARQLï¼‰æ—¶å¸¸å‡ºç°è¯­æ³•é”™è¯¯æˆ–è¯­ä¹‰åå·®ã€‚

æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•å­˜åœ¨ä¸¤ä¸ªå…³é”®ç“¶é¢ˆï¼š
- **ç«¯åˆ°ç«¯è¯­ä¹‰è§£æï¼ˆend-to-end semantic parsingï¼‰**å®¹æ˜“äº§ç”Ÿç»“æ„ä¸å‡†ç¡®çš„é€»è¾‘å½¢å¼ï¼›
- **é€æ­¥ä»£ç†å¼æ¨ç†ï¼ˆstepwise agent-based reasoningï¼‰**è®¡ç®—å¼€é”€å¤§ï¼Œå°¤å…¶åœ¨å¤§è§„æ¨¡çŸ¥è¯†å›¾è°±ä¸Šæ•ˆç‡ä½ä¸‹ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯
ä½œè€…æå‡º **SEALï¼ˆSelf-Evolving Agentic Learningï¼‰**ï¼Œä¸€ç§åŸºäº**è‡ªæ¼”åŒ–ä»£ç†å­¦ä¹ **çš„ä¸¤é˜¶æ®µè¯­ä¹‰è§£ææ¡†æ¶ï¼Œæ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

#### ï¼ˆ1ï¼‰å¼•å…¥â€œæœ€å°S-expressionæ ¸å¿ƒâ€ï¼ˆMinimal S-expression Coreï¼‰
- åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œç”±LLMæå–ä¸€ä¸ªç®€åŒ–çš„S-expressionå­ç»“æ„ï¼Œä»…åŒ…å«åŸºæœ¬æ“ä½œï¼ˆå¦‚`JOIN`, `AND`, `R`ç­‰ï¼‰ï¼Œæ•æ‰é—®é¢˜çš„æœ¬è´¨è¯­ä¹‰ã€‚
- è¿™ç§åˆ†è§£é™ä½äº†ç”Ÿæˆå®Œæ•´é€»è¾‘å½¢å¼çš„å¤æ‚åº¦ã€‚

#### ï¼ˆ2ï¼‰ä»£ç†æ ¡å‡†æ¨¡å—ï¼ˆAgentic Calibration Moduleï¼‰
- å¯¹ç”Ÿæˆçš„S-expressionæ ¸å¿ƒè¿›è¡Œ**è¯­æ³•çº é”™**å’Œ**å®ä½“/å…³ç³»å¯¹é½**ï¼Œç¡®ä¿å…¶ä¸åº•å±‚çŸ¥è¯†å›¾è°±ä¸€è‡´ã€‚
- é‡‡ç”¨è½»é‡çº§é“¾æ¥ç­–ç•¥ï¼ˆlightweight linkingï¼‰ï¼Œåªä¿ç•™è¯­ä¹‰æœ€ç›¸ä¼¼çš„å•ä¸ªå€™é€‰å®ä½“/å…³ç³»ï¼Œé¿å…ç»„åˆçˆ†ç‚¸ã€‚

#### ï¼ˆ3ï¼‰æ¨¡æ¿é©±åŠ¨çš„å®Œæˆæœºåˆ¶ï¼ˆTemplate-based Completionï¼‰
- ç¬¬äºŒé˜¶æ®µé€šè¿‡**é—®é¢˜ç±»å‹é¢„æµ‹**é€‰æ‹©åˆé€‚çš„S-expressionæ¨¡æ¿ï¼Œå¹¶å°†æ ¡å‡†åçš„æ ¸å¿ƒå¡«å…¥å ä½ç¬¦ï¼Œæ„é€ å¯æ‰§è¡Œçš„å®Œæ•´é€»è¾‘è¡¨è¾¾å¼ã€‚
- åˆ©ç”¨é¢„å®šä¹‰æ¨¡æ¿æå‡ç»“æ„ä¸€è‡´æ€§ä¸ç”Ÿæˆæ•ˆç‡ã€‚

#### ï¼ˆ4ï¼‰è‡ªæ¼”åŒ–æœºåˆ¶ï¼ˆSelf-Evolving Mechanismï¼‰
- ç»“åˆ**å±€éƒ¨è®°å¿†ï¼ˆlocal memoryï¼‰**ã€**å…¨å±€è®°å¿†ï¼ˆglobal memoryï¼‰** å’Œ **åæ€æ¨¡å—ï¼ˆreflection moduleï¼‰**ï¼Œå®ç°æ— éœ€æ˜¾å¼é‡è®­ç»ƒçš„æŒç»­å­¦ä¹ èƒ½åŠ›ã€‚
- æˆåŠŸçš„é€»è¾‘å½¢å¼åŠå…¶æ¨¡å¼è¢«å†™å…¥å…¨å±€è®°å¿†ï¼Œä¾›åç»­å¯¹è¯å¤ç”¨ï¼Œå½¢æˆé—­ç¯è¿›åŒ–ç³»ç»Ÿã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | SEALä¼˜åŠ¿ |
|------|---------|
| **å‡†ç¡®æ€§** | æ˜¾è‘—æé«˜S-expressionçš„ç»“æ„å‡†ç¡®ç‡å’Œæ‰§è¡ŒæˆåŠŸç‡ï¼Œå°¤å…¶åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ |
| **æ•ˆç‡** | åˆ†è§£å¼è®¾è®¡å‡å°‘SPARQLæŸ¥è¯¢æ•°é‡ï¼Œç¼“è§£â€œé•¿å°¾é«˜æŸ¥è¯¢â€é—®é¢˜ï¼Œæå‡æ¨ç†æ•ˆç‡ |
| **é€‚åº”æ€§** | è‡ªæ¼”åŒ–æœºåˆ¶ä½¿æ¨¡å‹èƒ½ä»å¯¹è¯å†å²å’Œæ‰§è¡Œåé¦ˆä¸­åŠ¨æ€å­¦ä¹ ï¼Œé€‚åº”æ–°è¡¨è¾¾æ–¹å¼ |
| **å¯æ‰©å±•æ€§** | ä¸ä¾èµ–æ ‡æ³¨æ•°æ®ï¼Œåœ¨é›¶æ ·æœ¬/å°‘æ ·æœ¬åœºæ™¯ä¸‹ä»å…·ç«äº‰åŠ› |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- ä½¿ç”¨ **SPICE** æ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºWikidataçš„çŸ¥è¯†å›¾è°±å¯¹è¯é—®ç­”åŸºå‡†ã€‚
- åŒ…å«å¤šè½®è‡ªç„¶è¯­è¨€é—®ç­”åºåˆ—åŠå¯¹åº”çš„SPARQLæŸ¥è¯¢æ ‡æ³¨ã€‚
- è¦†ç›–å…­ç±»é—®é¢˜ç±»å‹ï¼š`simple`, `verify`, `count`, `compare`, `compare_and_count`, `optimize`ã€‚
- æ’é™¤â€œclarificationâ€å­é›†ï¼ˆæ— å¯¹åº”SPARQLï¼‰ï¼Œå…±é‡‡æ ·çº¦3,791ä¸ªæ ·æœ¬ç”¨äºæµ‹è¯•ã€‚

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
#### è¯„ä¼°æŒ‡æ ‡
- **macro-F1**ï¼šç”¨äºé›†åˆå‹ç­”æ¡ˆï¼ˆå¦‚å®ä½“é›†ï¼‰çš„è¯„ä»·ã€‚
- **Accuracyï¼ˆACï¼‰**ï¼šç”¨äºå¸ƒå°”å€¼æˆ–æ•°å€¼å‹ç­”æ¡ˆçš„åˆ¤æ–­ã€‚

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | åŸºçº¿æ–¹æ³• |
|------|--------|
| **ç›‘ç£æ–¹æ³•** | BertSPGL, DCGGL |
| **éç›‘ç£æ–¹æ³•** | KB-Binderï¼ˆå¼ºåŸºçº¿ï¼‰ã€LLMGTï¼ˆç›´æ¥ç”Ÿæˆé€»è¾‘å½¢å¼ï¼‰ |

#### å®ç°ç»†èŠ‚
- **LLMæ¨¡å‹**ï¼š
  - é—®å¥ç±»å‹é¢„æµ‹ï¼šQwen2.5-32B-Instruct
  - å…¶ä»–æ¨¡å—ï¼ˆæ ¸å¿ƒç”Ÿæˆã€æ¨¡æ¿é€‰æ‹©ç­‰ï¼‰ï¼šDeepSeek-V3
- **é“¾æ¥ç­–ç•¥**ï¼štop-1 vs top-kï¼ˆk=3ï¼‰
- **å˜ä½“ä¿ç•™æ•°**ï¼šä¿ç•™1ä¸ªæˆ–3ä¸ªæ ¡å‡†åå€™é€‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§Table 2ï¼‰

| Question Type | SEAL (m-F1 / AC) | æœ€ä½³åŸºçº¿ (m-F1 / AC) | æå‡å¹…åº¦ |
|---------------|------------------|------------------------|----------|
| Logical Reasoning | **73.08** | 89.61 (LLMGT) | -16.53ï¼ˆä½†ä¼˜äºå…¶ä»–ï¼‰ |
| Quantitative Reasoning | **64.45** | 21.01 (KB-Binder) | +43.44 |
| Comparative Reasoning | **41.06** | 12.17 (KB-Binder) | +28.89 |
| Simple Q (Coref) | **71.53** | 85.73 (LLMGT) | -14.2ï¼ˆç•¥ä½ï¼‰ |
| Verification (Boolean) | **85.97** | 91.89 (LLMGT) | -5.92 |
| Quantitative Reasoning (Count) | **70.12** | 58.33 (LLMGT) | +11.79 |
| **Overall AC** | **66.83** | 65.65 (LLMGT), 36.66 (KB-Binder) | +1.18 vs LLMGT, +30.17 vs KB-Binder |

> âœ… SEALåœ¨å¤šæ•°å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šæ˜¾è‘—è¶…è¶Šéç›‘ç£åŸºçº¿ï¼Œåœ¨æ€»ä½“æ€§èƒ½ä¸Šæ¥è¿‘æœ€å¼ºç›‘ç£æ¨¡å‹ï¼Œä¸”æ— éœ€æ ‡æ³¨æ•°æ®ã€‚

---

### ä¸å…¶ä»–æ–¹æ³•çš„å…³é”®å¯¹æ¯”
- åœ¨**Comparative Reasoning**ä»»åŠ¡ä¸­ï¼ŒSEALå¾—åˆ†æ˜¯KB-Binderçš„**3.4å€ä»¥ä¸Š**ï¼ˆ41.06 vs 12.17ï¼‰ã€‚
- åœ¨**Quantitative Reasoning**ä¸­ï¼ŒSEALæ¯”KB-Binderé«˜å‡ºè¿‘**50ä¸ªç™¾åˆ†ç‚¹**ã€‚
- å°½ç®¡åœ¨ç®€å•é—®é¢˜ä¸Šç•¥é€ŠäºæŸäº›ç›‘ç£æ–¹æ³•ï¼Œä½†åœ¨æ¶‰åŠæŒ‡ä»£å’Œçœç•¥çš„é—®é¢˜ä¸­ä»ä¿æŒç¨³å¥ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

| æ¨¡å‹å˜ä½“ | F1 | AC | Overall Score |
|---------|-----|-----|----------------|
| **SEALï¼ˆå®Œæ•´ï¼‰** | 66.44 | 59.37 | **64.08** |
| w/o core extraction | 41.34 | 35.39 | 39.36 |
| w/o entity candidate | 39.32 | 46.16 | 41.60 |
| w/o calibration | 61.78 | 56.21 | 59.93 |
| w/o local memory | 61.89 | 56.69 | 60.16 |

> ğŸ” **æ ¸å¿ƒå‘ç°**ï¼š
> - ç§»é™¤**core extraction**å¯¼è‡´æ€§èƒ½ä¸‹é™æœ€å¤§ï¼ˆâ†“24.72ï¼‰ï¼Œè¯´æ˜è¯¥æ¨¡å—æ˜¯æ¶æ„åŸºçŸ³ã€‚
> - **calibration**å’Œ**local memory**è™½å½±å“è¾ƒå°ï¼Œä½†ä»æ˜¾è‘—æå‡é²æ£’æ€§ã€‚
> - æ‰€æœ‰ç»„ä»¶ååŒä½œç”¨ï¼ŒéªŒè¯äº†ç³»ç»Ÿè®¾è®¡çš„æ•´ä½“æœ‰æ•ˆæ€§ã€‚

---

### é›¶æ ·æœ¬ä¸å°‘æ ·æœ¬åœºæ™¯è¡¨ç°ï¼ˆTable 5ï¼‰

| è®¾ç½® | æ–¹æ³• | F1 | AC | Overall |
|------|------|-----|-----|--------|
| Few-shot | KB-Binder | 32.61 | 36.82 | 34.02 |
| Few-shot | SEAL-base | **41.34** | 35.39 | **39.36** |
| Zero-shot | KB-Binder | 21.67 | 15.96 | 19.76 |
| Zero-shot | SEAL-self-evolving | **34.42** | **34.10** | **34.32** |

> ğŸš€ **å…³é”®ç»“è®º**ï¼šSEALçš„**è‡ªæ¼”åŒ–æœºåˆ¶**ä½¿å…¶åœ¨é›¶æ ·æœ¬æ¡ä»¶ä¸‹è¿œè¶…åŸºçº¿ï¼Œè¯æ˜å…¶å…·å¤‡å¼ºå¤§çš„æ³›åŒ–ä¸è‡ªæˆ‘ä¼˜åŒ–èƒ½åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ä¸¤é˜¶æ®µè¯­ä¹‰è§£æä¼˜äºç«¯åˆ°ç«¯ç”Ÿæˆ**  
   å°†S-expressionç”Ÿæˆæ‹†åˆ†ä¸ºâ€œæ ¸å¿ƒæå– + æ¨¡æ¿è¡¥å…¨â€ï¼Œæ˜¾è‘—æå‡äº†ç»“æ„å‡†ç¡®æ€§å’Œè§£ææˆåŠŸç‡ã€‚

2. **ä»£ç†æ ¡å‡†æœ‰æ•ˆè§£å†³LLMå¹»è§‰ä¸é“¾æ¥æ­§ä¹‰**  
   é€šè¿‡è½»é‡çº§é“¾æ¥ä¸è¯­æ³•ä¿®æ­£ï¼Œç¡®ä¿ç”Ÿæˆçš„é€»è¾‘å½¢å¼æ—¢ç¬¦åˆçŸ¥è¯†å›¾è°±çº¦æŸï¼Œåˆèƒ½æ­£ç¡®æ‰§è¡Œã€‚

3. **è‡ªæ¼”åŒ–æœºåˆ¶å¸¦æ¥æŒç»­æ€§èƒ½å¢é•¿**  
   å¦‚Figure 4æ‰€ç¤ºï¼Œéšç€å¯¹è¯è½®æ¬¡å¢åŠ ï¼ŒSEALçš„F1åˆ†æ•°ç¨³æ­¥ä¸Šå‡ï¼Œè€Œæ¶ˆèç‰ˆæœ¬æ€§èƒ½åœæ»ç”šè‡³ä¸‹é™ï¼Œè¡¨æ˜è®°å¿†ä¸åæ€æœºåˆ¶å®ç°äº†çœŸæ­£çš„â€œè‡ªæˆ‘è¿›åŒ–â€ã€‚

4. **æ¨¡æ¿å¹¶éé™åˆ¶ï¼Œè€Œæ˜¯å¼•å¯¼**  
   å³ä¾¿æŸäº›å¤æ‚ç»“æ„ä¸åœ¨æ¨¡æ¿åº“ä¸­ï¼ˆå¦‚ä¸‰å…ƒORåµŒå¥—ï¼‰ï¼ŒLLMä¹Ÿèƒ½è‡ªä¸»åˆæˆåˆæ³•è¡¨è¾¾ï¼ˆAppendix Eï¼‰ï¼Œä½“ç°å…¶ç»„åˆæ³›åŒ–èƒ½åŠ›ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–é¢„å®šä¹‰S-expressionæ¨¡æ¿åº“**  
   è™½ç„¶æœ‰ä¸€å®šæ³›åŒ–èƒ½åŠ›ï¼Œä½†æç«¯æ–°é¢–çš„é€»è¾‘ç»“æ„å¯èƒ½æ— æ³•è¦†ç›–ã€‚

2. **å¤šæ¬¡è°ƒç”¨LLMå¸¦æ¥å»¶è¿Ÿé£é™©**  
   å¤šæ¨¡å—åä½œå¢åŠ äº†æ¨ç†é“¾é•¿åº¦ï¼Œå¯èƒ½å½±å“å®æ—¶å“åº”é€Ÿåº¦ã€‚

3. **ç©ºç»“æœè¯¯åˆ¤é—®é¢˜**  
   æ ¡å‡†è¿‡ç¨‹ä»¥â€œéç©ºç»“æœâ€ä¸ºç­›é€‰æ ‡å‡†ï¼Œå¯èƒ½å¯¼è‡´åˆæ³•ä½†åº”ä¸ºç©ºçš„ç­”æ¡ˆè¢«é”™è¯¯æ’é™¤ã€‚

4. **å½“å‰è½¬æ¢å±€é™äºç‰¹å®šKGï¼ˆWikidataï¼‰**  
   S-expression â†” SPARQL çš„è½¬æ¢è§„åˆ™éœ€é€‚é…ä¸åŒçŸ¥è¯†å›¾è°±ç»“æ„ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ¨å¹¿S-expressionåˆ°SPARQLçš„é€šç”¨è½¬æ¢å‡½æ•°**ï¼Œå¢å¼ºè·¨KGè¿ç§»èƒ½åŠ›ã€‚
2. æ”¹è¿›ä»£ç†çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼ŒåŒºåˆ†â€œåˆæ³•ç©ºç»“æœâ€ä¸â€œé”™è¯¯æŸ¥è¯¢â€ã€‚
3. å¼•å…¥ä¸“é—¨è®­ç»ƒä»»åŠ¡ï¼Œæå‡LLMå¯¹S-expressionè¯­æ³•çš„æŒæ¡ç¨‹åº¦ã€‚
4. ä½¿ç”¨æ›´å°è§„æ¨¡æ¨¡å‹å¤„ç†å­ä»»åŠ¡ï¼ˆå¦‚coreference resolutionï¼‰ï¼Œé™ä½æ•´ä½“è®¡ç®—æˆæœ¬ã€‚
5. æ¢ç´¢æ›´é«˜æ•ˆçš„è®°å¿†æ›´æ–°æœºåˆ¶ï¼Œæ”¯æŒæ›´å¤§è§„æ¨¡çš„å†å²çŸ¥è¯†å­˜å‚¨ä¸æ£€ç´¢ã€‚

---

> ğŸ’¡ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> SEALé€šè¿‡â€œ**æ ¸å¿ƒæå– + ä»£ç†æ ¡å‡† + æ¨¡æ¿è¡¥å…¨ + è‡ªæˆ‘æ¼”åŒ–**â€çš„å››é‡æœºåˆ¶ï¼Œåœ¨æ— éœ€ç›‘ç£ä¿¡å·çš„å‰æä¸‹ï¼Œå®ç°äº†é«˜æ•ˆã€å‡†ç¡®ã€å¯æŒç»­è¿›åŒ–çš„KBCQAç³»ç»Ÿï¼Œä¸ºæ„å»ºçœŸæ­£æ™ºèƒ½çš„å¯¹è¯ä»£ç†æä¾›äº†æ–°èŒƒå¼ã€‚

</details>

---

### 14. [Federated Learning for Terahertz Wireless Communication](https://arxiv.org/abs/2512.04984)

**Authors**: O. Tansel Baydas, Ozgur B. Akan  
**Category**: cs.DC  
**Published**: 2025-12-05  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.04984v1  

#### Abstract
The convergence of Terahertz (THz) communications and Federated Learning (FL) promises ultra-fast distributed learning, yet the impact of realistic wideband impairments on optimization dynamics remains theoretically uncharacterized. This paper bridges this gap by developing a multicarrier stochastic...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Federated Learning for Terahertz Wireless Communication*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹ **Terahertz (THz) é¢‘æ®µä¸‹çš„ Federated Learning (FL)** ç³»ç»Ÿä¸­å­˜åœ¨çš„ç†è®ºç©ºç™½å±•å¼€ç ”ç©¶ã€‚å°½ç®¡å·²æœ‰å·¥ä½œå°† FL åº”ç”¨äº THz é€šä¿¡ç³»ç»Ÿçš„ä¼˜åŒ–ï¼ˆå¦‚ä¿¡é“ä¼°è®¡ã€èµ„æºåˆ†é…ï¼‰ï¼Œä½†**ç¼ºä¹å¯¹ THz ç‰©ç†å±‚å®½é¢‘å¸¦æŸä¼¤å¦‚ä½•å½±å“ FL å­¦ä¹ åŠ¨æ€ï¼ˆæ”¶æ•›æ€§ã€åå·®ã€æ–¹å·®ï¼‰çš„ç³»ç»Ÿæ€§ç†è®ºåˆ†æ**ã€‚

å…·ä½“è€Œè¨€ï¼ŒTHz é¢‘æ®µå­˜åœ¨ä»¥ä¸‹å…³é”®ç‰©ç†å±‚æŒ‘æˆ˜ï¼š
- **Beam squint**ï¼ˆæ³¢æŸåæ–œï¼‰ï¼šé¢‘ç‡é€‰æ‹©æ€§å¯¼è‡´ä¸åŒå­è½½æ³¢æ³¢æŸæŒ‡å‘ä¸ä¸€è‡´ã€‚
- **Molecular absorption**ï¼ˆåˆ†å­å¸æ”¶ï¼‰ï¼šç‰¹å®šé¢‘ç‡å‡ºç°â€œè°±æ´â€ï¼ˆspectral holesï¼‰ã€‚
- **Pointing jitter**ï¼ˆæŒ‡å‘æŠ–åŠ¨ï¼‰ï¼šé«˜æ–¹å‘æ€§å¤©çº¿å¯¹å¾®å°è§’åº¦åå·®æä¸ºæ•æ„Ÿã€‚
- **Thermal noise**ï¼šå®½å¸¦å¼•å…¥æ›´å¤šå™ªå£°ã€‚

è¿™äº›å› ç´ åœ¨ä¼ ç»Ÿ FL åˆ†æä¸­å¸¸è¢«å¿½ç•¥æˆ–ç®€åŒ–ä¸ºç‹¬ç«‹åŠ æ€§å™ªå£°ï¼Œæ— æ³•å‡†ç¡®åˆ»ç”»å…¶å¯¹æ¨¡å‹èšåˆçš„å½±å“ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯

1. **å»ºç«‹äº†é¦–ä¸ªè€¦åˆ THz ç‰©ç†å±‚æŸä¼¤ä¸ FL æ”¶æ•›æ€§çš„å¤šè½½æ³¢éšæœºæ¨¡å‹**  
   å°†æœ¬åœ° SGD æ›´æ–°è¿‡ç¨‹ä¸ OFDM ç³»ç»Ÿä¸­çš„é¢‘ç‡é€‰æ‹©æ€§ THz ä¿¡é“æ•ˆåº”æ˜¾å¼å»ºæ¨¡ï¼Œæ¶µç›– beam squintã€åˆ†å­å¸æ”¶ã€jitter å’Œçƒ­å™ªå£°ã€‚

2. **æ­ç¤ºäº†â€œè°æ³¢å‡å€¼ç“¶é¢ˆâ€ï¼ˆHarmonic Mean Bottleneckï¼‰ç°è±¡**  
   åœ¨æ ‡å‡†æ— åèšåˆï¼ˆå¦‚ FedAvgï¼‰ä¸‹ï¼Œ**å…¨å±€æ”¶æ•›è¯¯å·®ä¸‹é™ç”±å„å­è½½æ³¢ SNR çš„è°ƒå’Œå¹³å‡å†³å®š**ã€‚è¿™æ„å‘³ç€å³ä½¿åªæœ‰ä¸€ä¸ªå­è½½æ³¢å› ä¸¥é‡ beam squint å¯¼è‡´ SNR æä½ï¼ˆå½¢æˆè°±æ´ï¼‰ï¼Œä¹Ÿä¼šä¸»å¯¼æ•´ä¸ªç³»ç»Ÿçš„æ€§èƒ½ï¼Œä½¿èšåˆæ›´æ–°å¤±æ•ˆã€‚

3. **å‘ç°äº†æ ¹æœ¬æ€§çš„å¸¦å®½æé™ï¼ˆFundamental Bandwidth Limitï¼‰**  
   æ‰©å±•å¸¦å®½å¹¶éæ€»æ˜¯æœ‰ç›Šã€‚å½“å¸¦å®½è¶…è¿‡æŸä¸€ä¸´ç•Œç‚¹æ—¶ï¼Œè¾¹ç¼˜å­è½½æ³¢å¢ç›Šå´©æºƒï¼ˆgain collapseï¼‰å’Œçƒ­å™ªå£°åŠŸç‡å¢åŠ ä¼šæ˜¾è‘—æå‡æ¢¯åº¦ä¼°è®¡å™¨çš„æ€»ä½“æ–¹å·®ï¼Œåè€Œ**æ¶åŒ– FL æ”¶æ•›æ€§èƒ½**ã€‚

4. **æå‡º SNR åŠ æƒèšåˆç­–ç•¥ä»¥çªç ´è°±æ´é™åˆ¶**  
   ä¸ºè§£å†³è°æ³¢å‡å€¼ç“¶é¢ˆï¼Œä½œè€…æå‡ºä¸€ç§åŸºäº SNR çš„åŠ æƒèšåˆæœºåˆ¶ï¼š
   $$
   \Delta^{(n)} = \sum_{i \in S_t} \alpha_i^{(n)} (\Delta_{i,t}^{(n)} + \text{error})
   $$
   å…¶ä¸­æƒé‡ $\alpha_i^{(n)}$ ä¸æœ‰æ•ˆå™ªå£°æ–¹å·®æˆåæ¯”ã€‚è¯¥æ–¹æ³•é€šè¿‡æŠ‘åˆ¶é«˜å™ªå£°å­è½½æ³¢/å®¢æˆ·ç«¯çš„è´¡çŒ®æ¥ç¨³å®šæ–¹å·®ï¼Œ**ä»¥å¯æ§çš„ç›®æ ‡åç½®æ¢å–æ–¹å·®ç¨³å®šæ€§**ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | ç°æœ‰æ–¹æ³• | æœ¬æ–‡æ–¹æ³• |
|------|--------|---------|
| **ä¿¡é“å»ºæ¨¡** | ç†æƒ³è¡°è½ä¿¡é“ï¼Œç‹¬ç«‹å™ªå£° | æ˜¾å¼å»ºæ¨¡ beam squintã€åˆ†å­å¸æ”¶ã€jitter ç­‰ THz ç‰¹æœ‰æŸä¼¤ |
| **æ”¶æ•›åˆ†æ** | å¿½ç•¥é¢‘ç‡é€‰æ‹©æ€§å½±å“ | æ­ç¤º SNR è°ƒå’Œå¹³å‡ä¸»å¯¼è¯¯å·®ä¸‹é™ |
| **èšåˆæœºåˆ¶** | æ ‡å‡†å¹³å‡ï¼ˆFedAvgï¼‰ | æå‡º SNR åŠ æƒèšåˆï¼Œé€‚åº”æ¶åŠ£ THz ç¯å¢ƒ |
| **è®¾è®¡æŒ‡å¯¼** | ç¼ºä¹ç‰©ç†å‚æ•°çº¦æŸ | æ¨å¯¼å‡ºå¸¦å®½ã€åŠŸç‡ã€é‡åŒ–ç­‰è®¾è®¡ä¸ç­‰å¼ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼šé¦–æ¬¡ä»ç†è®ºä¸Šè§£é‡Šäº†ä¸ºä½•ç›´æ¥å¥—ç”¨ä¼ ç»Ÿ FL åœ¨ THz åœºæ™¯å¯èƒ½å¤±è´¥ï¼Œå¹¶æä¾›äº†å¯æ“ä½œçš„è®¾è®¡åŸåˆ™å’Œé²æ£’èšåˆç®—æ³•ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **MNIST** æ‰‹å†™æ•°å­—å›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚
- å®¢æˆ·ç«¯æ•°é‡ï¼š$N = 10$ã€‚
- æ¨¡å‹æ¶æ„ï¼šCNNï¼ˆä¸¤ä¸ªå·ç§¯å±‚ + ä¸¤ä¸ªå…¨è¿æ¥å±‚ï¼‰ã€‚

### å®éªŒè®¾ç½®
- **é€šä¿¡åè®®**ï¼šOFDMï¼Œå­è½½æ³¢æ•° $N_c = 128$ï¼Œæ€»å¸¦å®½ $B \in \{1, 5, 10\}$ GHzï¼Œè½½é¢‘ $f_c = 300$ GHzã€‚
- **å¤©çº¿é…ç½®**ï¼šåŸºç«™é‡‡ç”¨ $N_{\text{ant}} = 64$ å…ƒç´ çš„ ULAï¼ˆUniform Linear Arrayï¼‰ã€‚
- **æœ¬åœ°è®­ç»ƒ**ï¼šæ¯è½® $K=1$ ä¸ª local epochï¼Œbatch size = 32ï¼Œå­¦ä¹ ç‡ $\eta = 0.02$ã€‚
- **æ€»é€šä¿¡è½®æ¬¡**ï¼š$T = 10$ã€‚
- **SNR å®‰å…¨é˜ˆå€¼**ï¼šä½äº 0.01 bits/Hz è§†ä¸º packet erasureã€‚

### è¯„ä¼°æŒ‡æ ‡
- **æµ‹è¯•å‡†ç¡®ç‡ï¼ˆTest Accuracyï¼‰éšé€šä¿¡è½®æ¬¡çš„å˜åŒ–æ›²çº¿**
- ä¸åŒç‰©ç†å‚æ•°ï¼ˆå‘å°„åŠŸç‡ã€è·ç¦»ã€beam squint å¼ºåº¦ã€jitter æ–¹å·®ç­‰ï¼‰ä¸‹çš„æ”¶æ•›è¡¨ç°
- æ˜¯å¦å¯ç”¨ CSI è¡¥å¿ã€æ˜¯å¦ä½¿ç”¨åŠ æƒèšåˆçš„å¯¹æ¯”

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **FedAvg**ï¼ˆæ ‡å‡†è”é‚¦å¹³å‡ï¼‰
- **Uncompensated Reception**ï¼ˆæ— ä¿¡é“è¡¥å¿æ¥æ”¶ï¼‰
- **Equal-Power Allocation**ï¼ˆæœªè€ƒè™‘å¢ç›Šå‡è¡¡çš„åŠŸç‡åˆ†é…ï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ä¸å¯¹æ¯”ç»“æœ

| å®éªŒåœºæ™¯ | FedAvg æ€§èƒ½ | åŠ æƒèšåˆæ€§èƒ½ | ç»“è®º |
|--------|------------|--------------|------|
| **ä½å‘å°„åŠŸç‡ (0.1 mW)** | å‡†ç¡®ç‡ â‰ˆ 9.8%ï¼ˆéšæœºçŒœæµ‹ï¼‰ | â€”â€” | åŠŸç‡ä¸è¶³å¯¼è‡´æŒç»­ä¸¢åŒ… |
| **æ­£å¸¸åŠŸç‡ (10 mW)** | å‡†ç¡®ç‡ â‰ˆ 98% | â€”â€” | å¯ç»´æŒç¨³å®šé“¾è·¯ |
| **é«˜ beam squint ($s=5.0$)** | æ˜æ˜¾ä¸‹é™ | â€”â€” | è¾¹ç¼˜å­è½½æ³¢å¢ç›Šå´©æºƒ |
| **å¤§ jitter ($\sigma_{\text{jitter}}=0.4$)** | å‡†ç¡®ç‡éª¤é™è‡³ ~10% | â€”â€” | â€œcliff effectâ€ï¼Œææ•æ„Ÿ |
| **é•¿è·ç¦» (100 m)** | å®Œå…¨å¤±æ•ˆï¼ˆâ‰ˆ9.8%ï¼‰ | â€”â€” | è·¯å¾„æŸè€— + åˆ†å­å¸æ”¶è¿‡å¼º |
| **å¤§å¸¦å®½ (10 GHz)** | æ¯” 1 GHz å·®çº¦ 10 dB SNR | â€”â€” | çƒ­å™ªå£°ä¸Šå‡ï¼Œè¾¹ç¼˜å­è½½æ³¢å¤±æ•ˆ |
| **ä¸¥é‡ä¿¡é“å‹åŠ› ($s=15.0$, $P=0.2W$)** | å¤±è´¥ï¼ˆâ‰ˆ9.8%ï¼‰ | æˆåŠŸï¼ˆâ‰ˆ97.6%ï¼‰ | **åŠ æƒèšåˆæ˜¾è‘—ä¼˜äº FedAvg** |

---

### æ¶ˆèå®éªŒç»“æœ

1. **ä¿¡é“è¡¥å¿å¿…è¦æ€§ï¼ˆFig. 3cï¼‰**
   - æ—  CSI è¡¥å¿ï¼šå‡†ç¡®ç‡ä»… ~14%
   - å¯ç”¨ä¼°è®¡ CSI è¡¥å¿ï¼šæ¢å¤è‡³ ~98%
   â†’ **è¯æ˜å¿…é¡»è¿›è¡Œä¿¡é“å¢ç›Šè¡¥å¿æ‰èƒ½æ”¶æ•›**

2. **åŠ æƒèšåˆæœ‰æ•ˆæ€§ï¼ˆFig. 4cï¼‰**
   - åœ¨æç«¯ beam squint æ¡ä»¶ä¸‹ï¼ŒFedAvg å®Œå…¨å¤±è´¥
   - SNR åŠ æƒèšåˆä»èƒ½è¾¾åˆ°æ¥è¿‘æœ€ä¼˜æ€§èƒ½
   â†’ **éªŒè¯äº†æ‰€æèšåˆç­–ç•¥çš„é²æ£’æ€§**

3. **å¸¦å®½æ‰©å±•è´Ÿé¢å½±å“ï¼ˆFig. 4bï¼‰**
   - å›ºå®šåŠŸç‡ä¸‹ï¼Œå¸¦å®½ä» 1 GHz å¢è‡³ 10 GHzï¼Œæ€§èƒ½ä¸‹é™
   â†’ **è¯å®å­˜åœ¨â€œå¸¦å®½æé™â€ï¼Œç›²ç›®æ‰©å¸¦å®½æœ‰å®³**

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. **è°æ³¢å‡å€¼ç“¶é¢ˆæ˜¯ THz-FL çš„æ ¸å¿ƒéšœç¢**  
   æ ‡å‡†èšåˆæ–¹å¼ä¸‹ï¼Œ**å•ä¸ªè°±æ´å³å¯æ‹–å®æ•´ä¸ªç³»ç»Ÿ**ï¼Œå› ä¸ºè¯¯å·®ä¸‹é™å–å†³äº SNR çš„è°ƒå’Œå¹³å‡è€Œéç®—æœ¯å¹³å‡ã€‚

2. **å¸¦å®½ä¸æ˜¯è¶Šå¤§è¶Šå¥½**  
   å­˜åœ¨ä¸€ä¸ª**æ ¹æœ¬æ€§çš„å¸¦å®½ä¸Šé™**ï¼šç»§ç»­æ‰©å¤§å¸¦å®½ä¼šå¼•å…¥è¿‡å¤šçƒ­å™ªå£°å¹¶æ¿€æ´»ä½å¢ç›Šè¾¹ç¼˜å­è½½æ³¢ï¼Œåè€Œé™ä½æ•´ä½“ SNR æ•ˆç‡ã€‚

3. **åç½®æ˜¯ THz ç¯å¢ƒä¸‹çš„å¿…è¦å¦¥å**  
   ä¸¥æ ¼åšæŒæ— åèšåˆï¼ˆå¦‚ FedAvgï¼‰åœ¨ THz åœºæ™¯ä¸å¯è¡Œã€‚**å¼•å…¥å¯æ§åç½®çš„åŠ æƒèšåˆæ˜¯å®ç°ç¨³å®šæ”¶æ•›çš„å…³é”®**ã€‚

4. **THz-FL æ˜¯é«˜åº¦èŒƒå›´å—é™çš„æŠ€æœ¯**  
   å®éªŒæ˜¾ç¤ºï¼Œåœ¨ 100 ç±³è·ç¦»ä¸Šä¿¡å·å·²æ— æ³•è§£ç ï¼Œè¡¨æ˜ THz-FL æ›´é€‚ç”¨äºçŸ­è·å¯†é›†éƒ¨ç½²åœºæ™¯ï¼ˆå¦‚å®¤å†…ã€è½¦è”ç½‘è¿‘è·ç¦»åä½œï¼‰ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§

- **ä¸‹è¡Œé“¾è·¯æœªå»ºæ¨¡**ï¼šå½“å‰æ¡†æ¶èšç„¦ä¸Šè¡Œæ¨¡å‹ä¸Šä¼ ï¼Œæœªåˆ†æ beam squint å¯¹å…¨å±€æ¨¡å‹å¹¿æ’­çš„å½±å“ã€‚
- **ç†æƒ³åŒ–å‡è®¾**ï¼šå‡è®¾ pilot å¯†åº¦è¶³å¤Ÿã€å‹ç¼©è¯¯å·®ç‹¬ç«‹ç­‰ï¼Œåœ¨å®é™…ç³»ç»Ÿä¸­å¯èƒ½éš¾ä»¥å®Œå…¨æ»¡è¶³ã€‚
- **æ•°å€¼å®éªŒè§„æ¨¡è¾ƒå°**ï¼šä»…ä½¿ç”¨ MNIST å’Œå°å‹ CNNï¼Œå°šæœªåœ¨æ›´å¤§è§„æ¨¡ä»»åŠ¡ï¼ˆå¦‚ CIFAR-10ã€ResNetï¼‰ä¸ŠéªŒè¯æ³›åŒ–æ€§ã€‚
- **æœªè€ƒè™‘éçº¿æ€§å¤±çœŸ**ï¼šå¦‚åŠŸç‡æ”¾å¤§å™¨éçº¿æ€§ç­‰å®é™…ç¡¬ä»¶æŸä¼¤æœªçº³å…¥æ¨¡å‹ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘

1. **æ‰©å±•è‡³ä¸‹è¡Œé“¾è·¯åˆ†æ**ï¼šç ”ç©¶ beam squint å¦‚ä½•å½±å“æœåŠ¡å™¨å‘å¤šä¸ªå®¢æˆ·ç«¯å¹¿æ’­å…¨å±€æ¨¡å‹çš„è¿‡ç¨‹ã€‚
2. **æ¢ç´¢ Hybrid Digital-Analog æ–¹æ¡ˆ**ï¼šä¾‹å¦‚åˆ©ç”¨ Over-the-Air Computation (AirComp) å®ç°æ¨¡æ‹Ÿèšåˆï¼Œç»•è¿‡å­è½½æ³¢é‡åŒ–ç“¶é¢ˆã€‚
3. **è”åˆä¼˜åŒ–ç‰©ç†å±‚ä¸å­¦ä¹ ç­–ç•¥**ï¼šè®¾è®¡è‡ªé€‚åº”å¸¦å®½ã€åŠŸç‡ã€é‡åŒ–ç²¾åº¦çš„è·¨å±‚ä¼˜åŒ–ç®—æ³•ã€‚
4. **å®æµ‹å¹³å°éªŒè¯**ï¼šåœ¨çœŸå® THz æµ‹è¯•å¹³å°ä¸Šéƒ¨ç½² FL ç³»ç»Ÿï¼ŒéªŒè¯ç†è®ºæ¨¡å‹çš„å‡†ç¡®æ€§ã€‚

--- 

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡é¦–æ¬¡å»ºç«‹äº† THz ç‰©ç†å±‚æŸä¼¤ä¸ FL æ”¶æ•›è¡Œä¸ºä¹‹é—´çš„ç†è®ºæ¡¥æ¢ï¼Œæ­ç¤ºäº†â€œè°æ³¢å‡å€¼ç“¶é¢ˆâ€å’Œâ€œå¸¦å®½æé™â€ä¸¤å¤§å…³é”®ç°è±¡ï¼Œå¹¶æå‡º SNR åŠ æƒèšåˆä½œä¸ºåº”å¯¹é«˜ squint ç¯å¢ƒçš„æœ‰æ•ˆæ–¹æ¡ˆï¼Œä¸ºæ„å»ºé¢å‘ 6G çš„æ— çº¿æ™ºèƒ½ç½‘ç»œæä¾›äº†é‡è¦è®¾è®¡å‡†åˆ™ã€‚

</details>

---

### 15. [Decoding Large Language Diffusion Models with Foreseeing Movement](https://arxiv.org/abs/2512.04135)

**Authors**: Yichuan Mo, Quan Chen, Mingjie Li, Zeming Wei, Yisen Wang  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.04135v1  

#### Abstract
Large Language Diffusion Models (LLDMs) benefit from a flexible decoding mechanism that enables parallelized inference and controllable generations over autoregressive models. Yet such flexibility introduces a critical challenge: inference performance becomes highly sensitive to the decoding order o...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šDecoding Large Language Diffusion Models with Foreseeing Movement

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ‰©æ•£æ¨¡å‹ï¼ˆ**LLDMs**ï¼‰è™½ç„¶å…·å¤‡å¹¶è¡Œæ¨ç†å’Œå¯æ§ç”Ÿæˆçš„ä¼˜åŠ¿ï¼Œä½†å…¶è§£ç æ€§èƒ½é«˜åº¦ä¾èµ–äº**tokençš„è§£ç é¡ºåº**ã€‚ç°æœ‰çš„å¯å‘å¼æ–¹æ³•ï¼ˆå¦‚åŸºäºæ¦‚ç‡ã€è¾¹é™…æˆ–ç†µï¼‰ä»…è€ƒè™‘å±€éƒ¨ç½®ä¿¡åº¦ï¼ˆ**local confidence**ï¼‰ï¼Œå¿½ç•¥äº†å¯¹åç»­ç”Ÿæˆè·¯å¾„çš„é•¿æœŸå½±å“ï¼Œå¯¼è‡´æ¬¡ä¼˜ç”šè‡³é”™è¯¯çš„è§£ç å†³ç­–ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ç§æ–°çš„è§£ç ç­–ç•¥â€”â€”**Foreseeing Decoding Method (FDM)**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†è§£ç å†³ç­–åŒæ—¶è€ƒè™‘ä¸¤ä¸ªå› ç´ ï¼š
- **Local Confidence**ï¼šæ¨¡å‹åœ¨å½“å‰æ­¥éª¤é¢„æµ‹æŸä¸ª token çš„ä¸ç¡®å®šæ€§ï¼ˆå³ä¼ ç»Ÿå¯å‘å¼æ–¹æ³•æ‰€ç”¨ï¼‰ã€‚
- **Global Confidence**ï¼šè¯¥ token å¯¹æœªæ¥å®Œæ•´åºåˆ—ç”Ÿæˆçš„å½±å“ï¼ˆé€šè¿‡è®­ç»ƒç›®æ ‡è¿‘ä¼¼ä¼°è®¡ï¼‰ã€‚

FDM é‡‡ç”¨ä¸¤é˜¶æ®µæœç´¢ç­–ç•¥ï¼š
1. é¦–å…ˆåŸºäº local confidence ç¼©å°å€™é€‰é›†ï¼›
2. å†ç»“åˆ global confidence åœ¨æœ‰é™å€™é€‰é›†ä¸­é€‰æ‹©æœ€ä¼˜ tokenã€‚

è¿›ä¸€æ­¥åœ°ï¼Œä½œè€…æå‡ºäº†åŠ é€Ÿç‰ˆæœ¬ **FDM-A**ï¼Œé€šè¿‡åˆ†æ FDM ä¸ç®€å•å¯å‘å¼æ–¹æ³•çš„ä¸€è‡´æ€§ï¼Œå‘ç°åœ¨è§£ç åæœŸï¼ˆä¸Šä¸‹æ–‡å……è¶³æ—¶ï¼‰å…¨å±€æ¢ç´¢å¹¶éå¿…è¦ã€‚å› æ­¤ FDM-A å¼•å…¥è‡ªé€‚åº”æœºåˆ¶ï¼Œåœ¨â€œæ¢ç´¢â€ã€â€œå¹³è¡¡â€å’Œâ€œåŠ é€Ÿâ€ä¸‰ä¸ªé˜¶æ®µåŠ¨æ€åˆ‡æ¢ç­–ç•¥ï¼š
- æ¢ç´¢é˜¶æ®µï¼ˆä½ç½®ä¿¡ï¼‰ï¼šä½¿ç”¨ FDM è¿›è¡Œæ·±åº¦æœç´¢ï¼›
- å¹³è¡¡é˜¶æ®µï¼ˆä¸­ç­‰ç½®ä¿¡ï¼‰ï¼šæ··åˆæ¢ç´¢ä¸å¹¶è¡Œè§£ç ï¼›
- åŠ é€Ÿé˜¶æ®µï¼ˆé«˜ç½®ä¿¡ï¼‰ï¼šä»…ç”¨ local confidence å¿«é€Ÿè§£ç ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **ç†è®ºä¼˜åŠ¿**ï¼šè¯æ˜äº† FDM èƒ½å¤Ÿé™ä½ç”Ÿæˆåˆ†å¸ƒä¸çœŸå®åˆ†å¸ƒä¹‹é—´çš„ KL æ•£åº¦ï¼Œä¼˜äºä»…ä¾èµ–å±€éƒ¨ä¿¡æ¯çš„æ–¹æ³•ã€‚
- **æ€§èƒ½ä¼˜åŠ¿**ï¼šæ˜¾è‘—æå‡å‡†ç¡®ç‡ï¼Œå°¤å…¶åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šã€‚
- **æ•ˆç‡ä¼˜åŠ¿**ï¼šFDM-A å®ç°äº†æ›´ä¼˜çš„**æ€§èƒ½-æ•ˆç‡æƒè¡¡**ï¼Œç›¸æ¯”å…¶ä»–åŠ é€Ÿæ–¹æ³•ï¼Œåœ¨ä¿æŒé«˜ç²¾åº¦çš„åŒæ—¶å®ç°æ›´å¿«çš„è§£ç é€Ÿåº¦ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒè¦†ç›–å››ä¸ªä¸»æµåŸºå‡†ï¼Œæ¶µç›–å¤šç§èƒ½åŠ›ç»´åº¦ï¼š
- **GSM8K**ï¼šæ•°å­¦åº”ç”¨é¢˜æ±‚è§£ï¼ˆæ•°å­¦æ¨ç†ï¼‰
- **HumanEval**ï¼šä»£ç ç”Ÿæˆï¼ˆç¼–ç¨‹èƒ½åŠ›ï¼‰
- **Countdown**ï¼šç®—æœ¯è¡¨è¾¾å¼æ„é€ ï¼ˆé€»è¾‘æ¨ç†ï¼‰
- **ARC**ï¼šå¤šé¡¹é€‰æ‹©é—®ç­”ï¼ˆå¸¸è¯†æ¨ç†ï¼‰

æ‰€æœ‰ä»»åŠ¡å‡åœ¨ **zero-shot** è®¾ç½®ä¸‹è¿›è¡Œè¯„ä¼°ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹å˜ä½“**ï¼šæµ‹è¯•äº†å››ç§ LLDM æ¶æ„ï¼š
  - LLaDA-8B-Instruct
  - LLaDA-1.5
  - LLaDA-MoE-7B-Instruct
  - MMaDA-MixCoT
- **è§£ç é•¿åº¦**ï¼šå›ºå®šä¸º 256ï¼Œé‡‡ç”¨ semi-autoregressive pipelineï¼ˆblock size=64ï¼‰
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **Accuracy**ï¼šæ­£ç¡®å›ç­”çš„æ¯”ä¾‹
  - **Tokens Per Second (TPS)**ï¼šæ¯ç§’ç”Ÿæˆ token æ•°é‡ï¼Œè¡¡é‡æ•ˆç‡

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
#### ä¸»è¦å¯¹æ¯”çš„å¯å‘å¼æ–¹æ³•ï¼š
- **Probability**ï¼šé€‰æ‹©é¢„æµ‹æ¦‚ç‡æœ€é«˜çš„ token
- **Margin**ï¼šé€‰æ‹©æœ€å¤§è¾¹é™…æ¦‚ç‡ï¼ˆtop1 - top2ï¼‰
- **Entropy**ï¼šé€‰æ‹©é¢„æµ‹åˆ†å¸ƒç†µæœ€å°çš„ä½ç½®

#### åŠ é€Ÿæ–¹æ³•å¯¹æ¯”ï¼ˆç”¨äº FDM-Aï¼‰ï¼š
- **EB (Entropy Bounded Sampler)**ï¼šåŸºäºç†µé˜ˆå€¼åŠ¨æ€è§£ç 
- **WINO**ï¼šå¯æ’¤é”€çš„å®½è¿›çª„å‡ºè§£ç ç­–ç•¥

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & Table 3ï¼‰

| æ–¹æ³• | ARC å‡†ç¡®ç‡ (%) | TPS |
|------|----------------|-----|
| Random | 79.06 | 12.01 |
| Margin | 82.55 | 10.85 |
| **FDM-A (Ours)** | **86.30** | **38.20** |

> âœ… FDM-A ä¸ä»…è¾¾åˆ°æœ€é«˜å‡†ç¡®ç‡ï¼Œè¿˜å®ç°äº†è¶…è¿‡ **3å€çš„é€Ÿåº¦æå‡**ã€‚

### ä¸å…¶ä»–æ–¹æ³•å…¨é¢å¯¹æ¯”ï¼ˆä»£è¡¨æ€§ç»“æœï¼‰

#### åœ¨ LLaDA æ¨¡å‹ä¸Šçš„ GSM8K è¡¨ç°ï¼š
| æ–¹æ³• | Accuracy (%) | TPS |
|------|--------------|-----|
| Probability (T=256) | 81.20 | 11.51 |
| Margin (T=256) | 80.14 | 11.23 |
| **FDM (K=4)** | **82.34** | 4.61 |
| **FDM-A (Ours)** | **81.96** | **42.65** |

> âš¡ FDM-A ç›¸æ¯”æ ‡å‡† FDM ä»…æŸå¤± 0.38% å‡†ç¡®ç‡ï¼Œä½† TPS æå‡ **5.15Ã—**

#### åœ¨ ARC ä¸Šçš„è¡¨ç°ï¼ˆLLaDAï¼‰ï¼š
| æ–¹æ³• | Accuracy (%) | TPS |
|------|--------------|-----|
| Margin (T=256) | 82.55 | 10.85 |
| WINO | 79.44 | 34.17 |
| EB | 73.55 | 32.01 |
| **FDM-A (Ours)** | **86.30** | **38.20** |

> ğŸ† FDM-A åŒæ—¶å–å¾—**æœ€é«˜å‡†ç¡®ç‡å’Œæœ€é«˜é€Ÿåº¦**ï¼Œè¿œè¶…å…¶ä»–åŠ é€Ÿæ–¹æ³•ã€‚

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰æœç´¢å®½åº¦ $K$ çš„å½±å“ï¼ˆFigure 4 & 8ï¼‰
- å¢å¤§ $K$ å¯æå‡ FDM æ€§èƒ½ï¼Œä½†å­˜åœ¨æ”¶ç›Šé€’å‡ç”šè‡³ä¸‹é™ï¼ˆå› å™ªå£°æ”¾å¤§ï¼‰ã€‚
- FDM åœ¨å¤§ $K$ ä¸‹è¡¨ç°æ›´å¥½ï¼›FDM-A åœ¨å° $K$ ä¸‹æ›´å…·ä¼˜åŠ¿ â†’ äºŒè€…äº’è¡¥ã€‚

#### ï¼ˆ2ï¼‰å‰ªæé˜ˆå€¼ $\gamma$ çš„å½±å“ï¼ˆFigure 5ï¼‰
- $\gamma$ è¿‡å°ï¼šå¼•å…¥è¿‡å¤šä½ç½®ä¿¡å€™é€‰ï¼Œå¹²æ‰°å†³ç­–ï¼›
- $\gamma$ è¿‡å¤§ï¼šé™åˆ¶æ¢ç´¢ç©ºé—´ï¼›
- æœ€ä½³å€¼é›†ä¸­åœ¨ **0.5 å·¦å³**ï¼Œå¹³è¡¡æœç´¢å¹¿åº¦ä¸è´¨é‡ã€‚

#### ï¼ˆ3ï¼‰é˜¶æ®µåˆ’åˆ†å‚æ•° $m_1$, $m_2$ çš„å½±å“ï¼ˆFigure 6â€“11ï¼‰
- $m_1 = 0.8$ã€$m_2 = 0.7$ æ—¶æ€§èƒ½æœ€ä½³ï¼›
- å¤ªæ—©è¿›å…¥åŠ é€Ÿæ¨¡å¼ä¼šæŸå®³å‡†ç¡®æ€§ï¼›
- å¤ªä¿å®ˆåˆ™æ— æ³•æœ‰æ•ˆæé€Ÿã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **å±€éƒ¨å¯å‘å¼ä¸è¶³**ï¼šä»…ä¾èµ–å½“å‰æ­¥çš„ local confidence ä¼šå¯¼è‡´å¿½ç•¥é•¿æœŸå½±å“ï¼Œé™åˆ¶ LLDM çš„æ½œåŠ›ã€‚
2. **å…¨å±€é¢„è§æœ‰æ•ˆ**ï¼šå¼•å…¥ global confidenceï¼ˆé€šè¿‡æœŸæœ› log-prob è¿‘ä¼¼ï¼‰èƒ½æ˜¾è‘—æå‡è§£ç è´¨é‡ã€‚
3. **FDM æ˜¯æœ‰æ•ˆçš„ test-time scaling æ–¹æ³•**ï¼šéšç€æœç´¢ç©ºé—´æ‰©å¤§ï¼ˆ$Kâ†‘$ï¼‰ï¼Œæ€§èƒ½æŒç»­æå‡ï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚
4. **FDM-A å®ç°æœ€ä¼˜æƒè¡¡**ï¼šé€šè¿‡è‡ªé€‚åº”æ§åˆ¶æ¢ç´¢å¼ºåº¦ï¼Œåœ¨å‡ ä¹ä¸ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹å¤§å¹…æå‡é€Ÿåº¦ï¼ˆ>3Ã— TPSï¼‰ã€‚
5. **ä¸€è‡´æ€§åˆ†ææŒ‡å¯¼è®¾è®¡**ï¼šæ—©æœŸè§£ç éœ€æ›´å¤šæ¢ç´¢ï¼ŒåæœŸå¯å®‰å…¨åŠ é€Ÿï¼Œè¿™ä¸€è§‚å¯Ÿæ”¯æ’‘äº† FDM-A çš„ä¸‰é˜¶æ®µè®¾è®¡ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **è®¡ç®—å¼€é”€ä»é«˜äºçº¯å¯å‘å¼æ–¹æ³•**ï¼šå°½ç®¡ FDM-A å·²ä¼˜åŒ–ï¼Œä½†åœ¨èµ„æºæåº¦å—é™åœºæ™¯å¯èƒ½ä»ä¸é€‚ç”¨ã€‚
- **ä¾èµ– well-trained model çš„è¾“å‡ºåˆ†å¸ƒè´¨é‡**ï¼šè‹¥æ¨¡å‹æœ¬èº«å¯¹ future token çš„é¢„æµ‹åå·®è¾ƒå¤§ï¼Œåˆ™ global confidence çš„ä¼°è®¡ä¹Ÿä¼šå¤±çœŸã€‚
- **è¶…å‚æ•°æ•æ„Ÿæ€§**ï¼š$K$, $\gamma$, $m_1$, $m_2$ éœ€åˆç†è°ƒå‚ï¼Œè·¨ä»»åŠ¡è¿ç§»éœ€éªŒè¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å°† FDM æ‰©å±•åˆ°å¤šæ¨¡æ€æ‰©æ•£æ¨¡å‹ï¼ˆå¦‚ LLaDA-Vï¼‰ã€‚
- ç»“åˆ verifier æˆ– reward model è¿›ä¸€æ­¥ä¼˜åŒ–è§£ç è·¯å¾„ã€‚
- æ¢ç´¢æ›´é«˜æ•ˆçš„ global confidence ä¼°è®¡æ–¹å¼ï¼ˆå¦‚è’¸é¦ã€ç¼“å­˜ï¼‰ã€‚
- ç ”ç©¶å¦‚ä½•å°† FDM ä¸å¼ºåŒ–å­¦ä¹ ç»“åˆï¼Œå®ç°ç«¯åˆ°ç«¯çš„è§£ç ç­–ç•¥ä¼˜åŒ–ã€‚

---

> ğŸ”š **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡ºçš„ **FDM** å’Œ **FDM-A** ä¸º LLDMs æä¾›äº†ä¸€ä¸ª**åŸåˆ™æ€§å¼ºã€æ€§èƒ½ä¼˜è¶Šä¸”é«˜æ•ˆå¯æ‰©å±•**çš„è§£ç æ¡†æ¶ï¼Œæ­ç¤ºäº†â€œé¢„è§æœªæ¥â€åœ¨æ‰©æ•£è¯­è¨€æ¨¡å‹ä¸­çš„å…³é”®ä½œç”¨ï¼Œæœ‰æœ›æˆä¸ºä¸‹ä¸€ä»£è§£ç æ ‡å‡†çš„é‡è¦å‚è€ƒã€‚

</details>

---

### 16. [QoSDiff: An Implicit Topological Embedding Learning Framework Leveraging Denoising Diffusion and Adversarial Attention for Robust QoS Prediction](https://arxiv.org/abs/2512.04596)

**Authors**: Guanchen Du, Jianlong Xu, Wei Wei  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.04596v1  

#### Abstract
Accurate Quality of Service (QoS) prediction is fundamental to service computing, providing essential data-driven guidance for service selection and ensuring superior user experiences. However, prevalent approaches, particularly Graph Neural Networks (GNNs), heavily rely on constructing explicit use...

---

### 17. [On GRPO Collapse in Search-R1: The Lazy Likelihood-Displacement Death Spiral](https://arxiv.org/abs/2512.04220)

**Authors**: Wenlong Deng, Yushu Li, Boying Gong, Yi Ren, Christos Thrampoulidis, Xiaoxiao Li  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.04220v1  

#### Abstract
Tool-integrated (TI) reinforcement learning (RL) enables large language models (LLMs) to perform multi-step reasoning by interacting with external tools such as search engines and retrievers. Group Relative Policy Optimization (GRPO), exemplified by the recent Search-R1, offers fast convergence and ...

---

### 18. [BEP: A Binary Error Propagation Algorithm for Binary Neural Networks Training](https://arxiv.org/abs/2512.04189)

**Authors**: Luca Colombo, Fabrizio Pittorino, Daniele Zambon, Carlo Baldassi, Manuel Roveri, Cesare Alippi  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.04189v1  

#### Abstract
Binary Neural Networks (BNNs), which constrain both weights and activations to binary values, offer substantial reductions in computational complexity, memory footprint, and energy consumption. These advantages make them particularly well suited for deployment on resource-constrained devices. Howeve...

---

### 19. [GRASP: GRouped Activation Shared Parameterization for Parameter-Efficient Fine-Tuning and Robust Inference of Transformers](https://arxiv.org/abs/2512.04296)

**Authors**: Malyaban Bal, Abhronil Sengupta  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.04296v1  

#### Abstract
Parameter-efficient fine-tuning (PEFT) provides a scalable alternative to full-model adaptation by updating only a small subset of parameters in large pre-trained models. We introduce GRASP - GRouped Activation Shared Parameterization - a lightweight PEFT framework that partitions the D-dimensional ...

---

### 20. [Data-regularized Reinforcement Learning for Diffusion Models at Scale](https://arxiv.org/abs/2512.04332)

**Authors**: Haotian Ye, Kaiwen Zheng, Jiashu Xu, Puheng Li, Huayu Chen, Jiaqi Han, Sheng Liu, Qinsheng Zhang, Hanzi Mao, Zekun Hao, Prithvijit Chattopadhyay, Dinghao Yang, Liang Feng, Maosheng Liao, Junjie Bai, Ming-Yu Liu, James Zou, Stefano Ermon  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.04332v1  

#### Abstract
Aligning generative diffusion models with human preferences via reinforcement learning (RL) is critical yet challenging. Most existing algorithms are often vulnerable to reward hacking, such as quality degradation, over-stylization, or reduced diversity. Our analysis demonstrates that this can be at...

---

### 21. [Multi-Agent Reinforcement Learning for Intraday Operating Rooms Scheduling under Uncertainty](https://arxiv.org/abs/2512.04918)

**Authors**: Kailiang Liu, Ying Chen, Ralf Bornd\"orfer, Thorsten Koch  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.04918v1  

#### Abstract
Intraday surgical scheduling is a multi-objective decision problem under uncertainty-balancing elective throughput, urgent and emergency demand, delays, sequence-dependent setups, and overtime. We formulate the problem as a cooperative Markov game and propose a multi-agent reinforcement learning (MA...

---

### 22. [Multi-Agent Reinforcement Learning with Communication-Constrained Priors](https://arxiv.org/abs/2512.03528)

**Authors**: Guang Yang, Tianpei Yang, Jingwen Qiao, Yanqing Wu, Jing Huo, Xingguo Chen, Yang Gao  
**Category**: cs.AI  
**Published**: 2025-12-05  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.03528v1  

#### Abstract
Communication is one of the effective means to improve the learning of cooperative policy in multi-agent systems. However, in most real-world scenarios, lossy communication is a prevalent issue. Existing multi-agent reinforcement learning with communication, due to their limited scalability and robu...

---

### 23. [Nex-N1: Agentic Models Trained via a Unified Ecosystem for Large-Scale Environment Construction](https://arxiv.org/abs/2512.04987)

**Authors**: AGI Team, Yuxuan Cai, Lu Chen, Qiaoling Chen, Yuyang Ding, Liwen Fan, Wenjie Fu, Yufei Gao, Honglin Guo, Pinxue Guo, Zhenhua Han, Zhengfu He, Hanglei Hu, Kai Hu, Shengjia Hua, Tianyu Huai, Baodai Huang, Li Ji, Zhen Jiang, Zhikai Lei, Bufan Li, Jiahang Lin, Lizhi Lin, Jinxiu Liu, Shichun Liu, Ziming Liu, Yuchen Ni, Pengfang Qian, Yujiong Shen, Qingyun Shi, Wentao Shu, Peng Sun, Yiran Suo, Tian Tang, Boyu Tian, Guoteng Wang, Junzhe Wang, Peixin Wang, Zhiheng Xi, Hang Yan, Jie Yang, Zhixiong Yang, Tianchu Yao, Guangze Ye, Qianxi Yu, Shuo Zhang, Xinyue Zhang, Yiqi Zhang, Jiarong Zhao, Miao Zheng, Rui Zheng, Enyu Zhou, Jiazheng Zhou, Maosen Zhou, Yuhao Zhou, Tao Gui, Yining Zheng, Xinchi Chen, Jie Zhou, Siyuan Feng, Qin Chen, Liang He, Qi Zhang, Xuanjing Huang, Xipeng Qiu  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.04987v1  

#### Abstract
The evolution of Large Language Models (LLMs) from passive responders to autonomous agents necessitates a fundamental shift in learning paradigms -- from static imitation to incentive-driven decision making. However, this transition is significantly impeded by the lack of scalable infrastructure cap...

---

### 24. [Formal Specification for Fast ACS: Low-Latency File-Based Ordered Message Delivery at Scale](https://arxiv.org/abs/2512.04096)

**Authors**: Sushant Kumar Gupta, Anil Raghunath Iyer, Chang Yu, Neel Bagora, Olivier Pomerleau, Vivek Kumar, Prunthaban Kanthakumar  
**Category**: cs.DC  
**Published**: 2025-12-05  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.04096v1  

#### Abstract
Low-latency message delivery is crucial for real-time systems. Data originating from a producer must be delivered to consumers, potentially distributed in clusters across metropolitan and continental boundaries. With the growing scale of computing, there can be several thousand consumers of the data...

---

### 25. [David vs. Goliath: Can Small Models Win Big with Agentic AI in Hardware Design?](https://arxiv.org/abs/2512.05073)

**Authors**: Shashwat Shankar, Subhranshu Pandey, Innocent Dengkhw Mochahari, Bhabesh Mali, Animesh Basak Chowdhury, Sukanta Bhattacharjee, Chandan Karfa  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.05073v1  

#### Abstract
Large Language Model(LLM) inference demands massive compute and energy, making domain-specific tasks expensive and unsustainable. As foundation models keep scaling, we ask: Is bigger always better for hardware design? Our work tests this by evaluating Small Language Models coupled with a curated age...

---

### 26. [MASE: Interpretable NLP Models via Model-Agnostic Saliency Estimation](https://arxiv.org/abs/2512.04386)

**Authors**: Zhou Yang, Shunyan Luo, Jiazhen Zhu, Fang Jin  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.04386v1  

#### Abstract
Deep neural networks (DNNs) have made significant strides in Natural Language Processing (NLP), yet their interpretability remains elusive, particularly when evaluating their intricate decision-making processes. Traditional methods often rely on post-hoc interpretations, such as saliency maps or fea...

---

### 27. [EvoEdit: Lifelong Free-Text Knowledge Editing through Latent Perturbation Augmentation and Knowledge-driven Parameter Fusion](https://arxiv.org/abs/2512.04545)

**Authors**: Pengfei Cao, Zeao Ji, Daojian Zeng, Jun Zhao, Kang Liu  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.04545v1  

#### Abstract
Adjusting the outdated knowledge of large language models (LLMs) after deployment remains a major challenge. This difficulty has spurred the development of knowledge editing, which seeks to accurately and efficiently modify a model's internal (parametric) knowledge without retraining it from scratch...

---

### 28. [AdmTree: Compressing Lengthy Context with Adaptive Semantic Trees](https://arxiv.org/abs/2512.04550)

**Authors**: Yangning Li, Shaoshen Chen, Yinghui Li, Yankai Chen, Hai-Tao Zheng, Hui Wang, Wenhao Jiang, Philip S. Yu  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.04550v1  

#### Abstract
The quadratic complexity of self-attention constrains Large Language Models (LLMs) in processing long contexts, a capability essential for many advanced applications. Context compression aims to alleviate this computational bottleneck while retaining critical semantic information. However, existing ...

---

### 29. [Challenging the Abilities of Large Language Models in Italian: a Community Initiative](https://arxiv.org/abs/2512.04759)

**Authors**: Malvina Nissim, Danilo Croce, Viviana Patti, Pierpaolo Basile, Giuseppe Attanasio, Elio Musacchio, Matteo Rinaldi, Federico Borazio, Maria Francis, Jacopo Gili, Daniel Scalena, Bego\~na Altuna, Ekhi Azurmendi, Valerio Basile, Luisa Bentivogli, Arianna Bisazza, Marianna Bolognesi, Dominique Brunato, Tommaso Caselli, Silvia Casola, Maria Cassese, Mauro Cettolo, Claudia Collacciani, Leonardo De Cosmo, Maria Pia Di Buono, Andrea Esuli, Julen Etxaniz, Chiara Ferrando, Alessia Fidelangeli, Simona Frenda, Achille Fusco, Marco Gaido, Andrea Galassi, Federico Galli, Luca Giordano, Mattia Goffetti, Itziar Gonzalez-Dios, Lorenzo Gregori, Giulia Grundler, Sandro Iannaccone, Chunyang Jiang, Moreno La Quatra, Francesca Lagioia, Soda Marem Lo, Marco Madeddu, Bernardo Magnini, Raffaele Manna, Fabio Mercorio, Paola Merlo, Arianna Muti, Vivi Nastase, Matteo Negri, Dario Onorati, Elena Palmieri, Sara Papi, Lucia Passaro, Giulia Pensa, Andrea Piergentili, Daniele Potert\`i, Giovanni Puccetti, Federico Ranaldi, Leonardo Ranaldi, Andrea Amelio Ravelli, Martina Rosola, Elena Sofia Ruzzetti, Giuseppe Samo, Andrea Santilli, Piera Santin, Gabriele Sarti, Giovanni Sartor, Beatrice Savoldi, Antonio Serino, Andrea Seveso, Lucia Siciliani, Paolo Torroni, Rossella Varvara, Andrea Zaninello, Asya Zanollo, Fabio Massimo Zanzotto, Kamyar Zeinalipour, Andrea Zugarini  
**Category**: cs.CL  
**Published**: 2025-12-05  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.04759v1  

#### Abstract
The rapid progress of Large Language Models (LLMs) has transformed natural language processing and broadened its impact across research and society. Yet, systematic evaluation of these models, especially for languages beyond English, remains limited. "Challenging the Abilities of LAnguage Models in ...

---

### 30. [The Initialization Determines Whether In-Context Learning Is Gradient Descent](https://arxiv.org/abs/2512.04268)

**Authors**: Shifeng Xie, Rui Yuan, Simone Rossi, Thomas Hannagan  
**Category**: cs.LG  
**Published**: 2025-12-05  
**Score**: 6.0  
**Type**: new  
**ArXiv ID**: 2512.04268v1  

#### Abstract
In-context learning (ICL) in large language models (LLMs) is a striking phenomenon, yet its underlying mechanisms remain only partially understood. Previous work connects linear self-attention (LSA) to gradient descent (GD), this connection has primarily been established under simplified conditions ...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
