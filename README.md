# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2025-12-19 06:50:20 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [AIE4ML: An End-to-End Framework for Compiling Neural Networks for the Next Generation of AMD AI Engines](https://arxiv.org/abs/2512.15946)

**Authors**: Dimitrios Danopoulos, Enrico Lupi, Chang Sun, Sebastian Dittmeier, Michael Kagan, Vladimir Loncar, Maurizio Pierini  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 16.0  
**Type**: new  
**ArXiv ID**: 2512.15946v1  

#### Abstract
Efficient AI inference on AMD's Versal AI Engine (AIE) is challenging due to tightly coupled VLIW execution, explicit datapaths, and local memory management. Prior work focused on first-generation AIE kernel optimizations, without tackling full neural network execution across the 2D array. In this w...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šAIE4ML: An End-to-End Framework for Compiling Neural Networks for the Next Generation of AMD AI Engines

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰åœ¨ AMD Versal AI Engineï¼ˆAIEï¼‰ä¸Šè¿›è¡Œé«˜æ•ˆ AI æ¨ç†é¢ä¸´è¯¸å¤šæŒ‘æˆ˜ï¼Œä¸»è¦åŒ…æ‹¬ï¼š
- **VLIW æ¶æ„å¤æ‚æ€§**ï¼šAIE é‡‡ç”¨è¶…é•¿æŒ‡ä»¤å­—ï¼ˆVLIWï¼‰æ¶æ„ï¼Œæ‰§è¡Œç´§å¯†è€¦åˆï¼Œç¼–ç¨‹éš¾åº¦é«˜ã€‚
- **æ˜¾å¼æ•°æ®æµä¸å†…å­˜ç®¡ç†**ï¼šéœ€è¦æ‰‹åŠ¨ç®¡ç†æœ¬åœ°å†…å­˜å’Œæ•°æ®è·¯å¾„ï¼Œéš¾ä»¥å®ç°ç«¯åˆ°ç«¯è‡ªåŠ¨åŒ–ã€‚
- **ç¼ºä¹å¯¹å®Œæ•´ç¥ç»ç½‘ç»œçš„æ”¯æŒ**ï¼šå·²æœ‰å·¥ä½œå¤šèšç„¦äºå•ä¸ªç®—å­ï¼ˆå¦‚ GEMMï¼‰ä¼˜åŒ–ï¼Œæ— æ³•æ”¯æŒè·¨å±‚çš„å®Œæ•´æ¨¡å‹éƒ¨ç½²ï¼Œä¸”å¸¸ä¾èµ– PLï¼ˆå¯ç¼–ç¨‹é€»è¾‘ï¼‰è¿›è¡Œæ•°æ®æ¬è¿ï¼Œå¼•å…¥å»¶è¿Ÿå’Œå¸¦å®½ç“¶é¢ˆã€‚
- **ä½å»¶è¿Ÿåœºæ™¯éœ€æ±‚æœªè¢«æ»¡è¶³**ï¼šä¾‹å¦‚ç²’å­ç‰©ç†å®éªŒä¸­çš„è§¦å‘ç³»ç»Ÿè¦æ±‚å¾®ç§’çº§å“åº”æ—¶é—´ï¼Œä¼ ç»Ÿ GPU æˆ– TPU éš¾ä»¥èƒœä»»ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡º **AIE4ML** â€”â€”é¦–ä¸ªé¢å‘æ–°ä¸€ä»£ AMD AIE-ML æ¶æ„çš„**ç«¯åˆ°ç«¯ç¥ç»ç½‘ç»œç¼–è¯‘æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

1. **å…¨ç‰‡ä¸Šï¼ˆon-chipï¼‰ã€ç«¯åˆ°ç«¯çš„æ‰§è¡Œæµæ°´çº¿**  
   åˆ©ç”¨ AIE-ML æ¶æ„ç‰¹æœ‰çš„ **Memory Tiles** ä½œä¸ºä¸­é—´æ¿€æ´»å€¼çš„å­˜å‚¨ä¸é‡æ’å•å…ƒï¼Œå®ç°å±‚é—´é€šä¿¡å®Œå…¨åœ¨èŠ¯ç‰‡å†…å®Œæˆï¼Œæ— éœ€é€šè¿‡ PL è¿›è¡Œæ•°æ®ä¸­è½¬ï¼Œæ˜¾è‘—é™ä½å»¶è¿Ÿå¹¶æå‡ååã€‚

2. **é«˜åº¦ä¼˜åŒ–ä¸”é€šç”¨çš„çº¿æ€§å±‚å®ç°**  
   åŸºäº `aie::mmul` API è®¾è®¡äº†æ”¯æŒ **bias åŠ æ³•ä¸ ReLU æ¿€æ´»èåˆ** çš„çº¿æ€§å±‚å†…æ ¸ï¼Œåœ¨å•ä¸ª AIE tile ä¸Šæ¥è¿‘ç¡¬ä»¶å³°å€¼æ€§èƒ½ã€‚

3. **åŸºäº Branch-and-Bound çš„å›¾æ”¾ç½®ç®—æ³•**  
   æå‡ºä¸€ç§æ–°å‹æœç´¢ç®—æ³•ï¼Œç”¨äºå°†ç¥ç»ç½‘ç»œå„å±‚ï¼ˆå­å›¾ï¼‰è‡ªåŠ¨æ˜ å°„åˆ° 2D AIE-ML é˜µåˆ—ä¸­ï¼Œæœ€å°åŒ–äº’è¿å¼€é”€ï¼Œå®ç°**ç¡®å®šæ€§ã€ç´§å‡‘ä¸”æ‹“æ‰‘æ„ŸçŸ¥çš„å¸ƒå±€**ã€‚

4. **æ— ç¼æ”¯æŒé‡åŒ–æ¨¡å‹å¯¼å…¥**  
   å¯ç›´æ¥ä» PyTorchã€hls4ml ç­‰é«˜çº§å·¥å…·é“¾å¯¼å…¥é‡åŒ–æ¨¡å‹ï¼Œå¹¶åœ¨æ•´ä¸ªæµç¨‹ä¸­ä¿æŒ **bit-exactness**ï¼ˆä½ç²¾ç¡®æ€§ï¼‰ï¼Œç¡®ä¿æ¨ç†ä¸€è‡´æ€§ã€‚

5. **å‰å‘å…¼å®¹ AIE-MLv2 æ¶æ„**  
   æ¡†æ¶è®¾è®¡å…·æœ‰æ¨¡å—åŒ–ç‰¹æ€§ï¼Œæ˜“äºé€‚é…æ›´æ–°ä¸€ä»£çš„ AIE-MLv2 è®¾å¤‡ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | AIE4ML | Prior Works (e.g., MaxEVA, AutoMM, CHARM, GAMA) |
|------|--------|-----------------------------------------------|
| æ”¯æŒ AIE-ML æ¶æ„ | âœ… | âŒ / éƒ¨åˆ†æ”¯æŒ |
| å®Œæ•´ç¥ç»ç½‘ç»œç«¯åˆ°ç«¯ç¼–è¯‘ | âœ… | âŒï¼ˆä»…é™å•ç®—å­æˆ–å¤šæ ¸æ‹¼æ¥ï¼‰ |
| å±‚é—´é€šä¿¡æ˜¯å¦ä¾èµ– PL | âŒï¼ˆå…¨é  Memory Tilesï¼‰ | âœ…ï¼ˆå¤šæ•°éœ€ PL ç¼“å†²ï¼‰ |
| æƒé‡æ˜¯å¦é©»ç•™ on-chip | âœ…ï¼ˆé€šè¿‡ RTP åŠ è½½åå¸¸é©»ï¼‰ | âŒï¼ˆé€šå¸¸éœ€æŒç»­æµå¼è¾“å…¥ï¼‰ |
| è‡ªåŠ¨å›¾åˆ†å‰²ä¸æ”¾ç½® | âœ…ï¼ˆB&B ç®—æ³•ï¼‰ | âŒï¼ˆéœ€æ‰‹åŠ¨é…ç½®ï¼‰ |
| æ”¯æŒ fused bias/activation | âœ… | âŒ |
| ä¿æŒ bit-exactness | âœ… | ä¸æ˜ç¡® |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†ä¸æ¨¡å‹
è®ºæ–‡å¹¶æœªä½¿ç”¨ä¼ ç»Ÿå›¾åƒåˆ†ç±»æ•°æ®é›†ï¼ˆå¦‚ ImageNetï¼‰ï¼Œè€Œæ˜¯è¯„ä¼°äº†ä»¥ä¸‹å…¸å‹æ¨¡å‹ç»“æ„ï¼š
- **MLP-Mixer Blocks**ï¼šåŒ…å« Token MLP å’Œ Channel MLP å­ç»“æ„ï¼Œå¹¿æ³›åº”ç”¨äºè§†è§‰ä»»åŠ¡åŠ CERN å¿«é€Ÿå–·æ³¨è¯†åˆ«ã€‚
- **Standalone MLPs**ï¼šåŒ…æ‹¬ 2 å±‚å’Œ 7 å±‚çš„å…¨è¿æ¥ç½‘ç»œï¼Œç”¨äºæµ‹è¯•æ‰©å±•æ€§å’Œé€šç”¨æ€§ã€‚
- æ‰€æœ‰æ¨¡å‹å‡ç»è¿‡é‡åŒ–å¤„ç†ï¼ˆint8/int16ï¼‰ï¼Œè¾“å…¥å°ºå¯¸æ ¹æ®è®¾å¤‡è§„æ¨¡è°ƒæ•´ä»¥å……åˆ†åˆ©ç”¨èµ„æºã€‚

### å®éªŒè®¾ç½®
- **ç›®æ ‡å¹³å°**ï¼šAMD Versal AIE-ML æ¶æ„ï¼ˆVEK280 å¹³å°ï¼‰
- **ä»¿çœŸç¯å¢ƒ**ï¼šAMD Vitis 2025 å·¥å…·é“¾ä¸­çš„ cycle-accurate AIE simulator
- **æ—¶é’Ÿé¢‘ç‡**ï¼š1.25 GHz
- **ç²¾åº¦é…ç½®**ï¼š
  - int8Ã—int8ï¼ˆè¾“å‡ºä¸º int8ï¼Œç´¯åŠ å™¨ä¸º 32-bitï¼‰
  - int16Ã—int8
  - int16Ã—int16
- **è¯„ä¼°æ¨¡å¼**ï¼šç¨³æ€ååé‡ï¼ˆsteady-state throughputï¼‰ï¼Œæµ‹é‡è¿ç»­ batch è¾“å‡ºé—´éš”ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **ç»å¯¹æ€§èƒ½**ï¼šTOPSï¼ˆTera Operations Per Secondï¼‰
- **æ•ˆç‡**ï¼šç›¸å¯¹äºç†è®ºå³°å€¼çš„ç™¾åˆ†æ¯”ï¼ˆ% efficiencyï¼‰
- **å»¶è¿Ÿ**ï¼šå¾®ç§’çº§ï¼ˆÎ¼sï¼‰å“åº”æ—¶é—´
- **ç©ºé—´åˆ©ç”¨ç‡**ï¼šä½¿ç”¨çš„ AIE tiles æ•°é‡å æ¯”
- **æ˜¯å¦å…¨ç‰‡ä¸Šæ‰§è¡Œ**ï¼šæ‰€æœ‰æ•°æ®ç§»åŠ¨æ˜¯å¦å‘ç”Ÿåœ¨ AIE/Memory Tiles å†…éƒ¨

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å¯¹æ¯”äº†å¤šä¸ªä»£è¡¨æ€§ AIE æ¡†æ¶ï¼š
- **MaxEVA**ï¼šé«˜æ€§èƒ½ GEMM å¼•æ“
- **AutoMM**ï¼šå¼‚æ„æ‰§è¡Œç®¡é“ä¸­çš„çŸ©é˜µä¹˜æ³•ç»„åˆ
- **CHARM**ï¼šæ··åˆ AIE + PL åŠ é€Ÿå™¨ç»„åˆ
- **ARIES**ï¼šåŸºäº MLIR çš„ç¼–ç¨‹æ¨¡å‹
- **GAMA**ï¼šé’ˆå¯¹ AIE-ML çš„é«˜åå GEMM æ¡†æ¶

æ­¤å¤–è¿˜è¿›è¡Œäº†è·¨æ¶æ„æ¯”è¾ƒï¼š
- **FPGA**ï¼šUltraScale+ VU13P + hls4ml
- **GPU**ï¼šNVIDIA RTX 3060ï¼ˆAmpereï¼‰+ TensorRT
- **Apple NPU**ï¼šM4 ANE + Core ML

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å•æ ¸æ€§èƒ½ï¼ˆSingle-Kernel Efficiencyï¼‰
åœ¨å•ä¸ª AIE tile ä¸Šè¿è¡Œå¤§è§„æ¨¡ batch çš„çº¿æ€§å±‚ï¼Œç»“æœå¦‚ä¸‹ï¼š

| æ•°æ®ç±»å‹ | ååï¼ˆGOPSï¼‰ | æ•ˆç‡ï¼ˆvs ç†è®ºå³°å€¼ï¼‰ |
|---------|-------------|---------------------|
| i8Ã—i8   | 613         | 95.8%               |
| i8Ã—i8ï¼ˆ+Bias+ReLUï¼‰ | 520     | 81.3%               |
| i16Ã—i8  | 314         | 98.1%               |
| i16Ã—i8ï¼ˆ+Bias+ReLUï¼‰| 287    | 89.7%               |
| i16Ã—i16 | 138         | 86.3%               |

> æ³¨ï¼šå³ä½¿åŠ å…¥ bias å’Œ ReLU èåˆæ“ä½œï¼Œä»èƒ½ç»´æŒæé«˜æ•ˆç‡ã€‚

### å¤šæ ¸æ‰©å±•æ€§ï¼ˆScaling Across AIE Arrayï¼‰
å°†å•ä¸€çº¿æ€§å±‚æ‰©å±•è‡³æ•´ä¸ª AIE-ML é˜µåˆ—ï¼ˆæœ€å¤š 304 ä¸ª tilesï¼‰ï¼Œç»“æœè¡¨æ˜è¿‘ä¹ç†æƒ³æ‰©å±•ï¼š

| æ•°æ®ç±»å‹ | æœ€å¤§åˆ©ç”¨ç‡ | æ‰©å±•æ•ˆç‡ï¼ˆç›¸å¯¹å•æ ¸ï¼‰ |
|--------|-----------|--------------------|
| i8Ã—i8  | 296/304 tiles (97.4%) | 97.3% |
| i16Ã—i8 | 296/304 tiles (97.4%) | 98.6% |
| i16Ã—i16| 296/304 tiles (97.4%) | 97.1% |

> åœ¨ GEMM-only è´Ÿè½½ä¸‹ï¼Œæ•´ä½“è¾¾åˆ° **160 TOPS**ï¼Œç›¸å½“äº AIE-ML ç†è®º INT8 å³°å€¼çš„ **82.2%**ã€‚

### å®é™…æ¨¡å‹æ€§èƒ½ï¼ˆOn Real-World Topologiesï¼‰
| æ¨¡å‹ç»“æ„ | æ“ä½œæ•°ï¼ˆMOPsï¼‰ | æ¯æ ·æœ¬è¾“å‡ºé—´éš”ï¼ˆÎ¼sï¼‰ | ååé‡ï¼ˆTOPSï¼‰ |
|--------|----------------|-----------------------|----------------|
| Token MLP - S/16 | 102 | 1.2 | 82.5 |
| Channel MLP - S/16 | 822 | 10.4 | 77.3 |
| Token MLP - L/16 | 411 | 7.5 | 55.0 |
| 2-Layer MLP | 1074 | 8.2 | 129.7 |
| 7-Layer MLP | 3.7K | 0.03 | **113.4** |

> æ‰€æœ‰æ‰§è¡Œå‡ä¸º **fully on-chip**ï¼ŒåŒ…æ‹¬æ•°æ®é‡æ’ã€tiling å’Œèšåˆã€‚

### ä¸å…¶ä»– AIE æ¡†æ¶å¯¹æ¯”ï¼ˆTable IVï¼‰
| æ¡†æ¶ | AIEä»£é™… | INT8æ•ˆç‡ | Bias/Actèåˆ | æƒé‡é©»ç•™AIE | æ¿€æ´»é©»ç•™AIE | å¤šå±‚æ”¯æŒ | æœ€å¤§AIEä½¿ç”¨ç‡ |
|------|--------|----------|--------------|------------|------------|-----------|----------------|
| **AIE4ML** | AIE-ML/v2 | **82.2%** | âœ… | âœ… | âœ… | âœ… | **296/304 (97.4%)** |
| GAMA | AIE-ML | 85% | âŒ | âŒ | âŒ | âŒ | 288/304 (94.7%) |
| MaxEVA | AIE | 56â€“60% | âŒ | âŒ | âŒ | âŒ | 400/400 |
| AutoMM | AIE | 27.5% | âŒ | âŒ | âŒ | âš ï¸ï¼ˆä¾èµ–PLï¼‰ | 192/400 |

> å°½ç®¡ GAMA åœ¨çº¯ GEMM ä¸Šç•¥é«˜ï¼Œä½† AIE4ML æ˜¯å”¯ä¸€å®ç° **å®Œæ•´ on-chip å¤šå±‚æ¨ç†** çš„æ¡†æ¶ã€‚

### è·¨æ¶æ„æ€§èƒ½å¯¹æ¯”ï¼ˆTable Vï¼‰
åœ¨ç›¸åŒ 7-layer MLP æ¨¡å‹ä¸Šæ¯”è¾ƒï¼š

| è®¾å¤‡ | å¹³å° | å·¥å…·é“¾ | ååé‡ï¼ˆTOPSï¼‰ |
|------|------|--------|----------------|
| **Versal VEK280** | AIE-ML | **AIE4ML** | **113.4** |
| VU13P FPGA | UltraScale+ | hls4ml | 3.7 |
| NVIDIA RTX 3060 | GPU | TensorRT | 14.1 |
| Apple M4 ANE | NPU | Core ML | 10.5 |

> AIE4ML çš„ååé‡æ˜¯ GPU çš„ **8 å€ä»¥ä¸Š**ï¼ŒFPGA çš„ **30 å€ä»¥ä¸Š**ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **AIE-ML æ¶æ„éå¸¸é€‚åˆä½å»¶è¿Ÿã€é«˜ååçš„å®æ—¶æ¨ç†ä»»åŠ¡**ï¼Œå°¤å…¶æ˜¯åœ¨æƒé‡é©»ç•™ã€å…¨ç‰‡ä¸Šæ‰§è¡Œçš„å‰æä¸‹ã€‚
2. **Memory Tiles æ˜¯å®ç°é«˜æ•ˆå±‚é—´é€šä¿¡çš„å…³é”®ç»„ä»¶**ï¼ŒAIE4ML æˆåŠŸå°†å…¶é›†æˆè¿›ç¼–è¯‘æµç¨‹ï¼Œå®ç°äº†çœŸæ­£çš„â€œzero-PL-dataflowâ€ã€‚
3. **é€šè¿‡åˆç†çš„ kernel è®¾è®¡ä¸è°ƒåº¦ï¼Œå¯åœ¨å¤æ‚ VLIW æ¶æ„ä¸Šå®ç°æ¥è¿‘å³°å€¼çš„è®¡ç®—æ•ˆç‡**ã€‚
4. **è‡ªåŠ¨åŒ–å›¾åˆ’åˆ†ä¸æ”¾ç½®ç®—æ³•ï¼ˆB&Bï¼‰ä¼˜äºè´ªå¿ƒç­–ç•¥**ï¼Œèƒ½ç”Ÿæˆæ›´ç´§å‡‘ã€è¿æ¥æ›´çŸ­çš„å¸ƒå±€ï¼Œå°¤å…¶é€‚ç”¨äºæ·±å±‚ç½‘ç»œã€‚
5. **AIE4ML å®ç°äº† GPU-class ååé‡ + å¾®ç§’çº§å»¶è¿Ÿ**ï¼Œç‰¹åˆ«é€‚åˆå¦‚ CERN è§¦å‘ç³»ç»Ÿç­‰æç«¯ä½å»¶è¿Ÿåº”ç”¨åœºæ™¯ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä¸»è¦æ”¯æŒ **Linear Layer** åŠå…¶å˜ä½“ï¼ˆMLPï¼‰ï¼Œå°šæœªæ‰©å±•åˆ° Convã€Attention ç­‰æ›´å¤æ‚çš„ç®—å­ã€‚
- å¯¹éè§„åˆ™å½¢çŠ¶æˆ–ä¸å¯æ•´é™¤ç»´åº¦å­˜åœ¨ padding å¼€é”€ï¼Œå½±å“å®é™…åˆ©ç”¨ç‡ã€‚
- ç¼–è¯‘æµç¨‹ç›®å‰ä¾èµ– hls4ml å‰ç«¯ï¼Œå¯¹åŸç”Ÿ PyTorch/TensorFlow çš„ç›´æ¥æ”¯æŒæœ‰é™ã€‚
- å®éªŒåŸºäºä»¿çœŸå™¨ï¼Œå®é™…ç¡¬ä»¶éƒ¨ç½²å¯èƒ½å­˜åœ¨å·®å¼‚ï¼ˆå°½ç®¡å·²åŠŸèƒ½éªŒè¯ AIE-MLv2ï¼‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•æ”¯æŒæ›´å¤šç®—å­ç±»å‹ï¼ˆå¦‚ Convã€Softmaxã€LayerNormã€Attentionï¼‰ã€‚
- æ”¯æŒåŠ¨æ€ shape å’Œç¨€ç–æ¨¡å‹ã€‚
- æ¢ç´¢æ›´é«˜æ•ˆçš„æ··åˆç²¾åº¦è®­ç»ƒ-æ¨ç†ååŒä¼˜åŒ–ã€‚
- å°†æ¡†æ¶æ¨å¹¿è‡³ AIE-MLv2 åŠåç»­æ¶æ„ï¼Œè¿›ä¸€æ­¥æŒ–æ˜æ–°ç¡¬ä»¶æ½œåŠ›ã€‚
- é›†æˆæ›´é«˜çº§çš„è‡ªåŠ¨è°ƒä¼˜æœºåˆ¶ï¼ˆauto-tuningï¼‰ä»¥é€‚åº”ä¸åŒ workload ç‰¹å¾ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼šAIE4ML æ˜¯é¦–ä¸ªå®ç° **ç«¯åˆ°ç«¯ã€å…¨ç‰‡ä¸Šã€bit-exactã€è‡ªåŠ¨åŒ–** ç¼–è¯‘ç¥ç»ç½‘ç»œè‡³ AMD AIE-ML æ¶æ„çš„æ¡†æ¶ï¼Œåœ¨çœŸå®æ¨¡å‹ä¸Šå®ç°äº† **è¶…è¿‡ 113 TOPS çš„ååé‡** å’Œ **å¾®ç§’çº§å»¶è¿Ÿ**ï¼Œæ˜¾è‘—è¶…è¶Šç°æœ‰ FPGA/GPU/NPU æ–¹æ¡ˆï¼Œä¸ºä¸‹ä¸€ä»£ä½å»¶è¿Ÿ AI æ¨ç†æä¾›äº†å¼ºæœ‰åŠ›çš„æŠ€æœ¯æ”¯æ’‘ã€‚

</details>

---

### 2. [Efficient CPU-GPU Collaborative Inference for MoE-based LLMs on Memory-Limited Systems](https://arxiv.org/abs/2512.16473)

**Authors**: En-Ming Huang, Li-Shang Lin, Chun-Yi Lee  
**Category**: cs.DC  
**Published**: 2025-12-19  
**Score**: 13.5  
**Type**: new  
**ArXiv ID**: 2512.16473v1  

#### Abstract
Large Language Models (LLMs) have achieved impressive results across various tasks, yet their high computational demands pose deployment challenges, especially on consumer-grade hardware. Mixture of Experts (MoE) models provide an efficient solution through selective activation of parameter subsets,...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šEfficient CPU-GPU Collaborative Inference for MoE-based LLMs on Memory-Limited Systems**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
ç°ä»£åŸºäº **Mixture of Experts (MoE)** çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è™½ç„¶åœ¨è®¡ç®—æ•ˆç‡ä¸Šä¼˜äºå¯†é›†æ¨¡å‹ï¼Œä½†ç”±äºå…¶åºå¤§çš„å‚æ•°é‡ï¼ˆå¦‚ Mixtral 8x7B éœ€è¦ 80GB å†…å­˜ï¼‰ï¼Œè¿œè¶…æ¶ˆè´¹çº§ GPUï¼ˆå¦‚ RTX 4090 ä»… 24GBï¼‰çš„å®¹é‡ï¼Œå¯¼è‡´éƒ¨ç½²å›°éš¾ã€‚ä¼ ç»Ÿçš„ **offloading** æ–¹æ³•å°†ä¸“å®¶æƒé‡ä» CPU å†…å­˜åŠ è½½åˆ° GPUï¼Œä½†é¢‘ç¹çš„æ•°æ®ä¼ è¾“å¼•å…¥æ˜¾è‘—é€šä¿¡å»¶è¿Ÿï¼Œé™åˆ¶äº†æ¨ç†é€Ÿåº¦ã€‚

æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•å¤šä¾èµ–äº **æ¨¡å‹ä¿®æ”¹**ï¼ˆå¦‚ Pre-gated MoEï¼‰ã€**ç¦»çº¿åˆ†æ**ï¼ˆå¦‚ Fiddlerï¼‰æˆ– **æ‰¹å¤„ç†ä¼˜åŒ–**ï¼Œéš¾ä»¥é€‚ç”¨äºå•è¯·æ±‚ã€ä½å»¶è¿Ÿçš„çœŸå®åœºæ™¯ã€‚

---

### **æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯**
æœ¬æ–‡æå‡ºäº†ä¸€ç§å…¨æ–°çš„ **CPU-GPU ååŒæ¨ç†æ¡†æ¶**ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

- å°† **GPU è§†ä¸º MoE ä¸“å®¶çš„ç¼“å­˜ï¼ˆexpert cacheï¼‰**ï¼Œè€Œéå¿…é¡»å®¹çº³å…¨éƒ¨ä¸“å®¶ã€‚
- åˆ©ç”¨ **CPU å¤šçº¿ç¨‹èƒ½åŠ›** æ‰§è¡Œæœªå‘½ä¸­ç¼“å­˜çš„ä¸“å®¶è®¡ç®—ï¼Œé¿å…ç­‰å¾…æ•°æ®ä¼ è¾“ã€‚
- å¼•å…¥ **å¼‚æ­¥ç¼“å­˜æ›´æ–°æœºåˆ¶ï¼ˆasynchronous cache miss handlingï¼‰**ï¼šå½“å‘ç”Ÿ cache miss æ—¶ï¼ŒCPU è´Ÿè´£å½“å‰è®¡ç®—ï¼ŒåŒæ—¶åå°å¼‚æ­¥åœ°å°†æ‰€éœ€ä¸“å®¶ä» CPU åŠ è½½è‡³ GPU ç¼“å­˜ï¼Œä¾›åç»­ token ä½¿ç”¨ã€‚

#### **ä¸‰å¤§åˆ›æ–°ç‚¹ï¼š**
1. **CPU-GPU ååŒæ¨ç†æ¡†æ¶**  
   å……åˆ†åˆ©ç”¨ CPU çš„å¤šæ ¸å¹¶è¡Œèƒ½åŠ›ï¼ˆé€šè¿‡ OpenMP å’Œ PyTorch å¤šçº¿ç¨‹ï¼‰ï¼Œåœ¨ GPU ç¼“å­˜æœªå‘½ä¸­çš„æƒ…å†µä¸‹ï¼Œç›´æ¥åœ¨ CPU ä¸Šæ‰§è¡Œ FFN ä¸“å®¶è®¡ç®—ï¼Œä»è€Œç»•è¿‡ PCIe é€šä¿¡ç“¶é¢ˆã€‚

2. **åŸºäºå±€éƒ¨æ€§çš„ä¸“å®¶ç¼“å­˜æœºåˆ¶ï¼ˆexpert cachingï¼‰**  
   å‘ç° MoE æ¨¡å‹ä¸­å­˜åœ¨ä¸¤ç§é‡ç”¨æ¨¡å¼ï¼š
   - **Consecutive Layers Pattern**ï¼šç›¸é‚»å±‚å€¾å‘äºé€‰æ‹©ç›¸åŒä¸“å®¶ï¼ˆMixtral ä¸­çº¦ 44%ï¼‰ã€‚
   - **Consecutive Tokens Pattern**ï¼šè¿ç»­ç”Ÿæˆçš„ token åœ¨åŒä¸€å±‚å¸¸å¤ç”¨è‡³å°‘ä¸€ä¸ªä¸“å®¶ï¼ˆæ¦‚ç‡è¾¾ 40%-60%ï¼‰ã€‚  
   åŸºäºæ­¤è®¾è®¡ **LRU ç¼“å­˜ç­–ç•¥**ï¼ŒåŠ¨æ€ä¿ç•™è¿‘æœŸä½¿ç”¨çš„ä¸“å®¶ï¼Œæå‡ cache hit ç‡ã€‚

3. **æ— éœ€æ¨¡å‹ä¿®æ”¹ä¸ç¦»çº¿åˆ†æçš„é€šç”¨æ–¹æ¡ˆ**  
   ä¸éœ€è¦ä¿®æ”¹æ¨¡å‹ç»“æ„ï¼ˆå¦‚ routerï¼‰ã€ä¸ä¾èµ–ç‰¹å®šæ•°æ®é›†çš„ä¸“å®¶æ¿€æ´»åˆ†å¸ƒåˆ†æï¼Œæ”¯æŒå³æ’å³ç”¨ï¼ˆout-of-the-boxï¼‰éƒ¨ç½²ä»»æ„ MoE æ¨¡å‹ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| æ–¹æ³• | æ˜¯å¦éœ€æ”¹æ¨¡å‹ | æ˜¯å¦éœ€ç¦»çº¿åˆ†æ | æ”¯æŒå•è¯·æ±‚ | é€šä¿¡å¼€é”€æ§åˆ¶ | å…¼å®¹æ€§ |
|------|---------------|------------------|-------------|----------------|---------|
| DeepSpeed / HF Accelerate | âŒ | âŒ | âœ… | âŒï¼ˆæŒ‰éœ€åŠ è½½ï¼‰ | âœ… |
| Pre-gated MoE / AdapMoE | âœ… | âŒ | âœ… | â­•ï¼ˆé¢„å–ï¼‰ | âŒ |
| Fiddler | âŒ | âœ… | âœ… | â­•ï¼ˆé™æ€ç¼“å­˜ï¼‰ | âŒ |
| **æœ¬æ–‡æ–¹æ³•ï¼ˆOursï¼‰** | âŒ | âŒ | âœ… | âœ…ï¼ˆå¼‚æ­¥ + CPU è®¡ç®—ï¼‰ | âœ… |

- æ€§èƒ½æ›´é«˜ï¼šæœ€é«˜è¾¾ **4.4Ã— é€Ÿåº¦æå‡**ã€‚
- æ›´èŠ‚èƒ½ï¼šèƒ½é‡æ•ˆç‡æ˜¾è‘—ä¼˜äº prefetching æ–¹æ³•ã€‚
- æ›´çµæ´»ï¼šé€‚åº”ä¸åŒ CPU æ ¸å¿ƒæ•°å’Œç¼“å­˜é…ç½®ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ¨¡å‹ä¸æ•°æ®é›†**
- **æ¨¡å‹**ï¼š
  - **Mixtral 8x7B**ï¼ˆ46.7B å‚æ•°ï¼Œ88GB å­˜å‚¨ï¼‰
  - **Phi-3.5-MoE**ï¼ˆ41.9B å‚æ•°ï¼Œ79GB å­˜å‚¨ï¼‰
- **æ•°æ®é›†**ï¼š
  - **MMLU** æ•°æ®é›†ç”¨äºåˆ†æä¸“å®¶é€‰æ‹©æ¨¡å¼ï¼ˆFig. 2ï¼‰ã€‚
  - æ¨ç†æ€§èƒ½æµ‹è¯•ä½¿ç”¨æ ‡å‡† prompt è¾“å…¥ï¼Œè¯„ä¼°ç”Ÿæˆååé‡ã€‚

---

### **å®éªŒè®¾ç½®**
- **ç¡¬ä»¶å¹³å°**ï¼š
  - CPU: AMD Ryzen Threadripper 7960Xï¼ˆ24 æ ¸ï¼‰
  - GPU: NVIDIA RTX 4090ï¼ˆ24GBï¼‰
  - äº’è”: PCIe Gen 4.0 Ã—16ï¼ˆåŒå‘å¸¦å®½ 64 GB/sï¼‰
- **è½¯ä»¶ç¯å¢ƒ**ï¼š
  - åŸºäºå®˜æ–¹ MistralAI å’Œ HuggingFace å®ç°æ‰©å±•ã€‚
  - ä½¿ç”¨ PyTorch å¤šçº¿ç¨‹ï¼ˆ`OMP_NUM_THREADS` æ§åˆ¶ CPU å¹¶è¡Œåº¦ï¼‰ã€‚
  - åŒ CUDA Stream å®ç°å¹¶å‘ä¼ è¾“ï¼ˆä¸­é—´çŠ¶æ€ vs æƒé‡åŠ è½½ï¼‰ã€‚

---

### **è¯„ä¼°æŒ‡æ ‡**
- **ä¸»æŒ‡æ ‡**ï¼š
  - **Token ååé‡ï¼ˆtokens/secï¼‰**ï¼šè¡¡é‡æ¨ç†æ•ˆç‡ã€‚
  - **ç«¯åˆ°ç«¯å»¶è¿Ÿ**ï¼šå°¤å…¶å…³æ³¨å•è¯·æ±‚åœºæ™¯ä¸‹çš„å“åº”æ—¶é—´ã€‚
- **è¾…åŠ©æŒ‡æ ‡**ï¼š
  - **Cache hit rate**ï¼ˆå•ä¸“å®¶å‘½ä¸­ / åŒä¸“å®¶å…¨å‘½ä¸­ï¼‰
  - **åŠŸè€—ä¸èƒ½è€—ï¼ˆJoule/tokenï¼‰**
  - ä¸åŒ CPU æ ¸å¿ƒæ•°ï¼ˆ1~24ï¼‰ä¸‹çš„æ€§èƒ½å˜åŒ–

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
1. **On-demand Fetching**ï¼ˆDeepSpeed / HuggingFace Accelerateï¼‰ï¼šæŒ‰éœ€åŠ è½½ä¸“å®¶ï¼Œæ— é¢„å–ã€‚
2. **Pre-gated MoE** [15]ï¼šé€šè¿‡ä¿®æ”¹ router å®ç°ä¸“å®¶é¢„é€‰ï¼Œå‡è®¾å®Œç¾é€šä¿¡é‡å ã€‚
3. **Fiddler** [26]ï¼šCPU-GPU åä½œæ¡†æ¶ï¼Œä¾èµ–ç¦»çº¿ä¸“å®¶çƒ­åº¦åˆ†æè¿›è¡Œç¼“å­˜å†³ç­–ã€‚
4. **CPU-only**ï¼šæ‰€æœ‰ä¸“å®¶è®¡ç®—å‡åœ¨ CPU æ‰§è¡Œï¼Œä½œä¸ºæ€§èƒ½ä¸‹ç•Œå‚è€ƒã€‚

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**
| æ¨¡å‹ | æœ¬æ–‡æ–¹æ³•ï¼ˆmaxï¼‰ | æœ€ä½³åŸºçº¿ï¼ˆPre-gated MoEï¼‰ | æå‡å€æ•° |
|------|------------------|----------------------------|----------|
| **Mixtral 8x7B** | **4.8 tokens/sec** | ~1.1 tokens/sec | **4.4Ã—** |
| **Phi-3.5-MoE** | **10.4 tokens/sec** | ~2.4 tokens/sec | **4.3Ã—** |

> æ³¨ï¼šPre-gated MoE æœªåŸç”Ÿæ”¯æŒè¿™äº›æ¨¡å‹ï¼Œä½œè€…åŸºäºç†æƒ³é€šä¿¡é‡å ä¼°ç®—å…¶æ€§èƒ½ä¸Šé™ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- åœ¨ **24 æ ¸ CPU** ä¸‹ï¼š
  - ç›¸æ¯” **Pre-gated MoE**ï¼šæé€Ÿ **4.4Ã—ï¼ˆMixtralï¼‰**, **4.3Ã—ï¼ˆPhi-3.5-MoEï¼‰**
  - ç›¸æ¯” **Fiddler**ï¼šæé€Ÿ **1.6Ã—ï¼ˆMixtralï¼‰**, æ˜¾è‘—ä¼˜äºå…¶åœ¨ Phi-3.5-MoE ä¸Šçš„è¡¨ç°ï¼ˆå› åè€…ä¸“å®¶æ›´å¤šï¼ŒFiddler å†³ç­–å¤æ‚åº¦çˆ†ç‚¸ï¼‰
- å³ä½¿ä½¿ç”¨ **å•æ ¸ CPU**ï¼Œä¹Ÿæ¯” Pre-gated MoE å¿« **54%ï¼ˆPhi-3.5-MoEï¼‰**
- ä½¿ç”¨ **åŒæ ¸ CPU** å³å¯å…¨é¢è¶…è¶Šæ‰€æœ‰ç°æœ‰æ–¹æ³•

---

### **æ¶ˆèå®éªŒä¸å…³é”®å‘ç°**
#### **(1) CPU æ ¸å¿ƒæ•°çš„å½±å“ï¼ˆFig. 5ï¼‰**
- **ä½æ ¸æ•°ï¼ˆ1â€“4ï¼‰**ï¼šè®¡ç®—æ˜¯ç“¶é¢ˆ â†’ åº”å¢åŠ ç¼“å­˜å±‚æ•°ï¼ˆindex æ•°ï¼‰ï¼Œå‡å°‘æ¯å±‚ way æ•°ã€‚
- **é«˜æ ¸æ•°ï¼ˆ8â€“24ï¼‰**ï¼šé€šä¿¡æˆç“¶é¢ˆ â†’ åº”å¢åŠ æ¯å±‚ way æ•°ä»¥æé«˜ cache hit ç‡ï¼Œå‡å°‘ä¼ è¾“é¢‘ç‡ã€‚

#### **(2) ç¼“å­˜æ›¿æ¢ç­–ç•¥æ¯”è¾ƒï¼ˆFig. 6ï¼‰**
- **LRU > FIFO â‰ˆ Random**
- å¯¹ Phi-3.5-MoEï¼ŒLRU æ˜¾è‘—ä¼˜äºéšæœºç­–ç•¥ï¼ˆå› ä¸“å®¶æ›´å¤šï¼Œå±€éƒ¨æ€§æ›´å¼ºï¼‰
- LRU åˆ©ç”¨äº†â€œè¿ç»­ token å¤ç”¨ä¸“å®¶â€çš„ç‰¹æ€§ï¼Œæ— éœ€é¢„è®­ç»ƒåˆ†æå³å¯å®ç°é«˜æ•ˆç¼“å­˜ç®¡ç†

#### **(3) èƒ½è€—åˆ†æï¼ˆTable Vï¼‰**
| æ¨¡å‹ | æ–¹æ³• | Joule/token |
|------|------|------------|
| Mixtral 8x7B | æœ¬æ–‡ï¼ˆ24æ ¸ï¼‰ | **51.1 J/token** |
| Mixtral 8x7B | Pre-gated MoE | 171.3 J/token |
| Phi-3.5-MoE | æœ¬æ–‡ï¼ˆ24æ ¸ï¼‰ | **21.9 J/token** |
| Phi-3.5-MoE | Pre-gated MoE | 78.7 J/token |

> **èŠ‚èƒ½æ•ˆæœ**ï¼šä»…æ¶ˆè€— **29.9%ï¼ˆMixtralï¼‰** å’Œ **27.8%ï¼ˆPhi-3.5-MoEï¼‰** çš„èƒ½é‡ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **CPU è®¡ç®—èƒ½åŠ›è¢«ä¸¥é‡ä½ä¼°**ï¼šå°½ç®¡ GPU å•æ¬¡è®¡ç®—æ›´å¿«ï¼ˆ0.3ms vs 7.3msï¼‰ï¼Œä½† **PCIe é€šä¿¡å»¶è¿Ÿï¼ˆ28msï¼‰è¿œé«˜äºè®¡ç®—æ—¶é—´**ï¼Œä½¿å¾—åœ¨å•è¯·æ±‚åœºæ™¯ä¸‹ï¼Œ**CPU å¤šçº¿ç¨‹æ‰§è¡Œåè€Œæ›´é«˜æ•ˆ**ã€‚
2. **MoE ä¸“å®¶å…·æœ‰å¼ºå±€éƒ¨æ€§**ï¼šæ— è®ºæ˜¯è·¨å±‚è¿˜æ˜¯è·¨ tokenï¼Œä¸“å®¶é€‰æ‹©éƒ½è¡¨ç°å‡ºé«˜åº¦é‡å¤æ€§ï¼Œä¸ºç¼“å­˜æä¾›äº†ç†è®ºåŸºç¡€ã€‚
3. **å¼‚æ­¥åä½œä¼˜äºåŒæ­¥é¢„å–**ï¼šä¼ ç»Ÿ prefetching æ— æ³•çœŸæ­£æ©ç›–é€šä¿¡å»¶è¿Ÿï¼Œè€Œæœ¬æ–¹æ³•é€šè¿‡ **CPU æ‰¿æ‹… miss å¼€é”€ + å¼‚æ­¥åŠ è½½**ï¼Œå®ç°äº†æ›´å¥½çš„è®¡ç®—-é€šä¿¡é‡å ã€‚
4. **æ— éœ€ç‰ºç‰²å‡†ç¡®æ€§æˆ–å…¼å®¹æ€§**ï¼šæ— éœ€é‡åŒ–ã€å‰ªæã€router ä¿®æ”¹æˆ–ç¦»çº¿ profilingï¼Œå³å¯è·å¾—æ˜¾è‘—åŠ é€Ÿã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
- **ä¾èµ–è¾ƒå¼ºçš„ CPU æ€§èƒ½**ï¼šè‹¥ CPU è¾ƒå¼±æˆ–å¤šæ ¸è°ƒåº¦ä¸ä½³ï¼Œæ€§èƒ½å¢ç›Šä¼šä¸‹é™ã€‚
- **ç¼“å­˜å‘½ä¸­ç‡å—é™äº GPU æ˜¾å­˜å¤§å°**ï¼šæ˜¾å­˜è¶Šå°ï¼Œå¯ç¼“å­˜çš„ä¸“å®¶è¶Šå°‘ï¼Œmiss ç‡è¶Šé«˜ã€‚
- **å¯¹é MoE æ¨¡å‹æ— æ•ˆ**ï¼šè¯¥ä¼˜åŒ–é’ˆå¯¹ MoE æ¶æ„è®¾è®¡ï¼Œä¸é€‚ç”¨äºçº¯ dense æ¨¡å‹ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
- æ‰©å±•è‡³ **å¤š GPU + å¤š CPU** åœºæ™¯ä¸‹çš„åˆ†å¸ƒå¼ååŒæ¨ç†ã€‚
- ç»“åˆ **quantization** è¿›ä¸€æ­¥å‹ç¼©ä¸“å®¶ä½“ç§¯ï¼Œæå‡ç¼“å­˜è¦†ç›–ç‡ã€‚
- æ¢ç´¢ **è‡ªé€‚åº”ç¼“å­˜é…ç½®ç®—æ³•**ï¼Œæ ¹æ®è¿è¡Œæ—¶è´Ÿè½½è‡ªåŠ¨è°ƒæ•´ cache index/way åˆ†é…ã€‚
- å°†è¯¥æ¡†æ¶é›†æˆè¿›ä¸»æµæ¨ç†å¼•æ“ï¼ˆå¦‚ vLLMã€TensorRT-LLMï¼‰ä»¥æå‡é€šç”¨æ€§ã€‚

---

> âœ… **ä»£ç å¼€æº**ï¼š[github.com/elsa-lab/MoE-CPU-GPU-Collaborative-Inference](https://github.com/elsa-lab/MoE-CPU-GPU-Collaborative-Inference)

</details>

---

### 3. [Staggered Batch Scheduling: Co-optimizing Time-to-First-Token and Throughput for High-Efficiency LLM Inference](https://arxiv.org/abs/2512.16134)

**Authors**: Jian Tian, Shuailong Li, Yang Cao, Wenbo Cui, Minghan Zhu, Wenkang Wu, Jianming Zhang, Yanpeng Wang, Zhiwen Xiao, Zhenyu Hou, Dou Shen  
**Category**: cs.DC  
**Published**: 2025-12-19  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2512.16134v1  

#### Abstract
The evolution of Large Language Model (LLM) serving towards complex, distributed architectures--specifically the P/D-separated, large-scale DP+EP paradigm--introduces distinct scheduling challenges. Unlike traditional deployments where schedulers can treat instances as black boxes, DP+EP architectur...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Staggered Batch Scheduling: Co-optimizing Time-to-First-Token and Throughput for High-Efficiency LLM Inference*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹å¤§è§„æ¨¡ **DP+EP**ï¼ˆData Parallelism + Expert Parallelismï¼‰æ¶æ„ä¸‹çš„ **P/D åˆ†ç¦»å¼ LLM æ¨ç†ç³»ç»Ÿ**ä¸­å­˜åœ¨çš„è°ƒåº¦æ•ˆç‡ç“¶é¢ˆé—®é¢˜ã€‚ä¼ ç»Ÿâ€œç«‹å³è°ƒåº¦â€ï¼ˆImmediate Dispatchï¼‰ç­–ç•¥åœ¨é«˜åŒæ­¥å¼€é”€çš„åˆ†å¸ƒå¼æ¶æ„ä¸­ä¼šå¯¼è‡´ä¸¥é‡çš„ **è®¾å¤‡ä¾§æ’é˜Ÿï¼ˆDevice-side Queuingï¼‰** å’Œ **å¹¶è¡ŒåŒ–æ°”æ³¡ï¼ˆParallelization Bubblesï¼‰**ï¼Œä»è€Œæ˜¾è‘—å¢åŠ  **TTFTï¼ˆTime-to-First-Tokenï¼‰** å¹¶é™ä½ååé‡ã€‚

å…·ä½“é—®é¢˜åŒ…æ‹¬ï¼š
- **Head-of-Lineï¼ˆHOLï¼‰é˜»å¡**ï¼šè¯·æ±‚è¢«ç«‹å³åˆ†å‘åˆ°å·²å¿™çš„å®ä¾‹ï¼Œåªèƒ½åœ¨å¼•æ“å†…éƒ¨æ’é˜Ÿï¼Œæ— æ³•è¢«è°ƒåº¦å™¨æ„ŸçŸ¥å’Œç®¡ç†ã€‚
- **DP å•å…ƒé—´è´Ÿè½½ä¸å‡è¡¡**ï¼šç”±äº MoE å±‚éœ€è¦ All-to-All é€šä¿¡ï¼Œæœ€æ…¢çš„ DP å•å…ƒï¼ˆstragglerï¼‰æ‹–ç´¯æ•´ä½“æ€§èƒ½ã€‚
- **Decode é˜¶æ®µçš„è€¦åˆè´Ÿè½½å¤±è¡¡**ï¼šåºåˆ—é•¿åº¦åˆ†å¸ƒé•¿å°¾å¯¼è‡´ KV Cache å†…å­˜å‹åŠ›ä¸å‡ï¼ŒåŒæ—¶æ‰¹å¤§å°ä¸å‡è¡¡å½±å“ GPU åˆ©ç”¨ç‡ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

#### ï¼ˆ1ï¼‰**Staggered Batch Scheduling (SBS)**  
ä¸€ç§åŸºäºæ—¶é—´çª—å£çš„å»¶è¿Ÿæ‰¹å¤„ç†è°ƒåº¦æœºåˆ¶ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- **ä¸»åŠ¨ç¼“å†²è¯·æ±‚**ï¼Œå½¢æˆæœ€ä¼˜æ‰§è¡Œæ‰¹æ¬¡ï¼Œè€Œéç«‹å³åˆ†å‘ã€‚
- å¼•å…¥ä¸€ä¸ªè‡ªé€‚åº”çš„è°ƒåº¦é—´éš” $I_{\text{opt}}$ï¼Œä½¿æ‰¹æ¬¡æäº¤èŠ‚å¥ä¸é›†ç¾¤å¤„ç†èƒ½åŠ›å¯¹é½ã€‚
- å°†ç­‰å¾…ä»ä¸å¯æ§çš„â€œè®¾å¤‡ä¾§é˜Ÿåˆ—â€è½¬ç§»åˆ°å¯ç®¡ç†çš„â€œè°ƒåº¦å™¨ä¾§é˜Ÿåˆ—â€ï¼Œä»æ ¹æœ¬ä¸Šæ¶ˆé™¤ HOL é˜»å¡ã€‚

> âœ… â€œWait to accelerateâ€ â€”â€” é€šè¿‡çŸ­æš‚ç­‰å¾…å®ç°æ›´ä½å»¶è¿Ÿã€‚

#### ï¼ˆ2ï¼‰**Load-Aware Global Allocation**  
åˆ©ç”¨ SBS æä¾›çš„æ‰¹å¤„ç†çª—å£ï¼Œè·å¾—å…¨å±€è¯·æ±‚è§†å›¾ï¼Œè¿›è¡Œç²¾ç»†åŒ–èµ„æºåˆ†é…ï¼š
- **Prefill é˜¶æ®µ**ï¼šé‡‡ç”¨ **Water-Filling å¯å‘å¼ç®—æ³•**ï¼ˆç±»ä¼¼ bin-packingï¼‰ï¼Œå°†é•¿åºåˆ—ä¼˜å…ˆåˆ†é…ç»™å‰©ä½™å®¹é‡æœ€å¤§çš„ DP å•å…ƒï¼Œå‡å°‘ stragglerã€‚
- **Decode é˜¶æ®µ**ï¼šæå‡º **IQR-Aware Lexicographical Scheduling**ï¼Œç»“åˆï¼š
  - **å¼‚å¸¸å€¼å±è”½ï¼ˆOutlier Maskingï¼‰**ï¼šä½¿ç”¨ IQR åŠ¨æ€è¯†åˆ«å†…å­˜é¥±å’Œçš„ DP å•å…ƒå¹¶æ’é™¤ã€‚
  - **å­—å…¸åºä¼˜åŒ–é€‰æ‹©**ï¼šä¼˜å…ˆæœ€å°åŒ–æ‰¹å¤§å°ï¼ˆBatch Sizeï¼‰ï¼Œå…¶æ¬¡æœ€å°åŒ– KV Cache è´Ÿè½½ï¼Œå®ç°åŒç›®æ ‡å¹³è¡¡ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | ç°æœ‰æ–¹æ³•å±€é™ | SBS æ”¹è¿› |
|------|--------------|---------|
| **è°ƒåº¦ç²’åº¦** | ä»¥å®Œæ•´å®ä¾‹ä¸ºå•ä½ï¼Œå¿½ç•¥å†…éƒ¨å¹¶è¡Œç»“æ„ | ç»†åŒ–è‡³ **DP-Attention Unit**ï¼Œå®ç°å­å®ä¾‹çº§è°ƒåº¦ |
| **è°ƒåº¦æ¨¡å¼** | Immediate Dispatch å¯¼è‡´è®¾å¤‡å†…æ’é˜Ÿ | å¼•å…¥ **Staggered Batch**ï¼Œæ¶ˆé™¤ HOL é˜»å¡ |
| **è´Ÿè½½å‡è¡¡** | è´ªå¿ƒåˆ†é…ï¼Œæ˜“é€ æˆè´Ÿè½½å€¾æ–œ | å…¨å±€æ‰¹å¤„ç†è§†å›¾æ”¯æŒ **Water-Filling / Lexicographical ä¼˜åŒ–** |
| **é²æ£’æ€§** | å¯¹ç½‘ç»œæŠ–åŠ¨ã€æ•…éšœæ•æ„Ÿ | å¤šçº§åŒæ­¥åè®®ï¼ˆQuiescence Polling + Async Signal + Watchdogï¼‰ä¿éšœç³»ç»Ÿæ´»æ€§ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### å®éªŒå¹³å°ä¸æ¨¡å‹
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼šç”Ÿäº§çº§ **H800 GPU é›†ç¾¤**
- **éƒ¨ç½²æ¶æ„**ï¼š**DeepSeek-V3** æ¨¡å‹ï¼Œé‡‡ç”¨ **P/D åˆ†ç¦» + DP+EP æ··åˆå¹¶è¡Œ**
  - Prefill å®ä¾‹ï¼š`TP=4`, `DP=8`, `EP=32`
  - Decode å®ä¾‹ï¼š`TP=1`, `DP=32`, `EP=32`
- **Prefill Chunk Size**ï¼š3K æˆ– 5K tokens

### æ•°æ®é›†ä¸å·¥ä½œè´Ÿè½½
- **è¾“å…¥é•¿åº¦åˆ†å¸ƒ**ï¼š
  - å¸¸è§„åœºæ™¯ï¼š0â€“3K tokensï¼ˆå‡å€¼ 1Kï¼‰
  - é•¿ä¸Šä¸‹æ–‡åœºæ™¯ï¼š3Kâ€“64K tokensï¼ˆå‡å€¼ 6.7Kï¼‰
- **Decode è¯·æ±‚**ï¼šæ€»é•¿åº¦çº¦ 2.5K tokensï¼Œå¹³å‡æ‰¹å¤§å° 35
- æµé‡æ¨¡å¼è¦†ç›– **40%â€“100% å³°å€¼ QPS**

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **TTFT** | Time-to-First-Tokenï¼Œé¦– token å»¶è¿Ÿ |
| **Queue Time** | è¯·æ±‚åœ¨è°ƒåº¦ç³»ç»Ÿä¸­çš„æ’é˜Ÿå»¶è¿Ÿ |
| **QPS** | ç³»ç»Ÿå¯æŒç»­ååé‡ï¼ˆQueries Per Secondï¼‰ |
| **Chunk Utilization** | Prefill Chunk çš„ token å®¹é‡åˆ©ç”¨ç‡ |
| **KV Cache Load Distribution** | Decode é˜¶æ®µå„ DP å•å…ƒçš„ç¼“å­˜è´Ÿè½½æ–¹å·® |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline**ï¼šImmediate Dispatch + è´ªå¿ƒè´Ÿè½½å‡è¡¡ï¼ˆå¦‚ Round-Robin æˆ– Least Outstanding Requestsï¼‰
- **å¯¹æ¯”ç»´åº¦**ï¼šç›¸åŒ QPS ä¸‹æ¯”è¾ƒ TTFTï¼›ç›¸åŒ TTFT SLO ä¸‹æ¯”è¾ƒæœ€å¤§åå

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ï¼ˆ1ï¼‰TTFT æ€§èƒ½æå‡ï¼ˆPrefill é˜¶æ®µï¼‰

| åœºæ™¯ | æ–¹æ³• | TTFT æ”¹å–„ |
|------|------|----------|
| è¾“å…¥ 0â€“3K tokens | SBS vs Baseline | â†“ **30â€“40%** |
| è¾“å…¥ 3Kâ€“64K tokensï¼ˆé«˜æ–¹å·®ï¼‰ | SBS vs Baseline | â†“ **~40%**ï¼Œå°¾éƒ¨å»¶è¿Ÿæ˜¾è‘—æŠ‘åˆ¶ |

> å›¾6æ˜¾ç¤ºï¼Œåœ¨ä½äº 80% è´Ÿè½½æ—¶ï¼ŒSBS çš„ TTFT ä¼˜åŠ¿æœ€ä¸ºæ˜æ˜¾ï¼Œä¸”åœ¨é•¿ä¸Šä¸‹æ–‡åœºæ™¯ä¸‹ä¾ç„¶ç¨³å¥ã€‚

---

### ï¼ˆ2ï¼‰ååé‡æå‡ï¼ˆThroughputï¼‰

#### Prefill é˜¶æ®µï¼ˆè§ Table 1ï¼‰

| Chunk Size | è°ƒåº¦æ¨¡å¼ | QPS | Chunk Util. (%) | Î”QPS | Î”Util. |
|-----------|----------|-----|------------------|-------|--------|
| 3K | Off (Baseline) | 57 | 51.83 | â€” | â€” |
|     | On (SBS)      | 70 | 88.7  | **+22.8%** | **+36.9pp** |
| 5K | Off           | 70 | 53.0  | â€” | â€” |
|     | On            | 79 | 88.0  | **+12.9%** | **+35.0pp** |

âœ… **å…³é”®å‘ç°**ï¼šSBS å°† Prefill Chunk åˆ©ç”¨ç‡ä» ~52% æå‡è‡³ ~88%ï¼Œå‡ ä¹å¡«æ»¡æ‰€æœ‰â€œå¹¶è¡ŒåŒ–æ°”æ³¡â€ã€‚

---

#### Decode é˜¶æ®µ

| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **KV Cache è´Ÿè½½æ–¹å·®** | Â±1Ïƒ åŒºé—´ä» 40Kâ€“130K å‹ç¼©è‡³ 60Kâ€“100Kï¼Œ**é™ä½ 40%** |
| **æç«¯ outlier** | è¢«æœ‰æ•ˆæŠ‘åˆ¶ï¼ˆå³°å€¼ä» 150Kâ†“ï¼‰ |
| **Aggregate Decode Throughput** | â†‘ **15%** |

> å›¾7 å’Œ å›¾8 æ˜¾ç¤ºï¼ŒIQR-aware è°ƒåº¦æ˜¾è‘—å‹ç¼©äº†è´Ÿè½½åˆ†å¸ƒï¼Œå‡å°‘äº†åŒæ­¥ç­‰å¾…æ—¶é—´ã€‚

---

### ï¼ˆ3ï¼‰æ¶ˆèå®éªŒä¸æœºåˆ¶éªŒè¯ï¼ˆéšå«åˆ†æï¼‰

è™½ç„¶æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†æ–‡ä¸­é€šè¿‡ä»¥ä¸‹æ–¹å¼éªŒè¯è®¾è®¡æœ‰æ•ˆæ€§ï¼š
- **è°ƒåº¦é—´éš”è‡ªé€‚åº”æœºåˆ¶**ï¼šåŠ¨æ€è°ƒæ•´ $I_{\text{opt}}$ å¯å¿«é€Ÿå“åº”æµé‡æ³¢åŠ¨å’Œæ‰©ç¼©å®¹äº‹ä»¶ã€‚
- **å¤šçº§åŒæ­¥åè®®**ï¼šQuiescence Polling åŠ é€Ÿå†·å¯åŠ¨æ¢å¤ï¼›Watchdog é˜²æ­¢æ­»é”ã€‚
- **Water-Filling åˆ†é…**ï¼šç›¸æ¯”è´ªå¿ƒåˆ†é…ï¼Œæ˜¾è‘—æå‡ Chunk åˆ©ç”¨ç‡ã€‚
- **IQR é˜ˆå€¼è®¾è®¡**ï¼š$k=1.5$ åœ¨ç¨³å®šæ€§å’Œçµæ•åº¦ä¹‹é—´å–å¾—å¹³è¡¡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Immediate Dispatch åœ¨ DP+EP æ¶æ„ä¸­æ˜¯æ¬¡ä¼˜çš„**ï¼šå…¶å¯¼è‡´çš„è®¾å¤‡ä¾§æ’é˜Ÿä¸¥é‡æ¶åŒ– TTFTã€‚
2. **Staggered Batch Scheduling æ˜¯æœ‰æ•ˆçš„åç›´è§‰ä¼˜åŒ–**ï¼šé€šè¿‡å¼•å…¥å¯æ§ç­‰å¾…çª—å£ï¼Œåè€Œå¤§å¹…é™ä½ç«¯åˆ°ç«¯å»¶è¿Ÿã€‚
3. **æ‰¹å¤„ç†çª—å£å¸¦æ¥å…¨å±€è§†å›¾ï¼Œèµ‹èƒ½ç²¾ç»†è´Ÿè½½å‡è¡¡**ï¼š
   - Prefill é˜¶æ®µå¯é€šè¿‡ Water-Filling å‡å°‘ stragglerã€‚
   - Decode é˜¶æ®µéœ€è”åˆä¼˜åŒ–æ‰¹å¤§å°ä¸ KV Cache è´Ÿè½½ã€‚
4. **SBS å®ç°äº† TTFT ä¸ Throughput çš„ååŒä¼˜åŒ–**ï¼š
   - TTFT â†“ 30â€“40%
   - Throughput â†‘ 15â€“20%

---

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ– P/D åˆ†ç¦»æ¶æ„**ï¼šä¸»è¦é€‚ç”¨äº Prefill å’Œ Decode åˆ†æ± éƒ¨ç½²çš„ç³»ç»Ÿã€‚
- **å¯¹çŸ­è¯·æ±‚å¯èƒ½å¼•å…¥é¢å¤–å»¶è¿Ÿ**ï¼šå°½ç®¡æ€»ä½“ TTFT ä¸‹é™ï¼Œä½†æçŸ­è¯·æ±‚å¯èƒ½å› ç­‰å¾…æ‰¹æ¬¡è€Œç•¥æœ‰å»¶è¿Ÿä¸Šå‡ï¼ˆæ–‡ä¸­æœªé‡åŒ–ï¼‰ã€‚
- **æ‰©å±•æ€§è¾¹ç•Œå¾…éªŒè¯**ï¼šæ˜¯å¦é€‚ç”¨äºä¸‡å¡ä»¥ä¸Šè¶…å¤§è§„æ¨¡é›†ç¾¤å°šéœ€æ›´å¤šå®è¯ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- **åŠ¨æ€è°ƒæ•´æ‰¹å¤„ç†çª—å£å¤§å°**ï¼šç»“åˆè¯·æ±‚ SLAã€ä¼˜å…ˆçº§ç­‰è¿›è¡Œå·®å¼‚åŒ–è°ƒåº¦ã€‚
- **ä¸ Prefix Cache-aware è°ƒåº¦èåˆ**ï¼šè¿›ä¸€æ­¥åˆ©ç”¨å…±äº«å‰ç¼€æå‡ç¼“å­˜å‘½ä¸­ç‡ã€‚
- **æ”¯æŒæ›´å¤æ‚çš„ MoE è·¯ç”±ç­–ç•¥**ï¼šç»“åˆä¸“å®¶çƒ­åº¦è¿›è¡Œäº²å’Œæ€§è°ƒåº¦ã€‚
- **è·¨èŠ‚ç‚¹ KV Cache è¿ç§»é›†æˆ**ï¼šä¸ Llumnix ç±»ç³»ç»Ÿç»“åˆï¼Œå®ç°ç»†ç²’åº¦å¼¹æ€§ä¼¸ç¼©ã€‚

---

## æ€»ç»“

> **SBS çš„æ ¸å¿ƒæ´è§æ˜¯ï¼šåœ¨é«˜åŒæ­¥æˆæœ¬çš„ç°ä»£ LLM æ¨ç†æ¶æ„ä¸­ï¼Œâ€œç«‹å³æœåŠ¡â€ä¸å†æ˜¯ä½å»¶è¿Ÿçš„æœ€ä½³è·¯å¾„ã€‚é€šè¿‡æœ‰æ§åˆ¶åœ°å»¶è¿Ÿï¼Œæ¢å–å…¨å±€ä¼˜åŒ–æœºä¼šï¼Œæ‰èƒ½çœŸæ­£å®ç° TTFT ä¸ Throughput çš„åŒèµ¢ã€‚**

è¯¥å·¥ä½œä¸ºä¸‹ä¸€ä»£ä¸‡äº¿å‚æ•° MoE æ¨¡å‹çš„é«˜æ•ˆæ¨ç†æä¾›äº†å¯æ‰©å±•çš„è°ƒåº¦èŒƒå¼ï¼Œæ¨åŠ¨ LLM Serving ä»â€œé»‘ç›’è°ƒåº¦â€èµ°å‘â€œæ·±åº¦ååŒè®¾è®¡â€ã€‚

</details>

---

### 4. [LoPA: Scaling dLLM Inference via Lookahead Parallel Decoding](https://arxiv.org/abs/2512.16229)

**Authors**: Chenkai Xu, Yijie Jin, Jiajun Li, Yi Tu, Guoping Long, Dandan Tu, Tianqi Hou, Junchi Yan, Zhijie Deng  
**Category**: cs.CL  
**Published**: 2025-12-19  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2512.16229v1  

#### Abstract
Diffusion Large Language Models (dLLMs) have demonstrated significant potential for high-speed inference. However, current confidence-driven decoding strategies are constrained by limited parallelism, typically achieving only 1--3 tokens per forward pass (TPF). In this work, we identify that the deg...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# LoPA: Scaling dLLM Inference via Lookahead Parallel Decoding è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰çš„ **Diffusion Large Language Models (dLLMs)** è™½ç„¶ç†è®ºä¸Šå…·å¤‡å¹¶è¡Œç”Ÿæˆæ½œåŠ›ï¼Œä½†å®é™…æ¨ç†è¿‡ç¨‹ä¸­å—é™äº **Token Filling Order (TFO)** å¯¹é¢„æµ‹ç½®ä¿¡åº¦çš„å½±å“ï¼Œå¯¼è‡´å¹¶è¡Œåº¦æä½ï¼ˆé€šå¸¸æ¯æ­¥ä»…èƒ½å¡«å…… 1â€“3 ä¸ª tokenï¼‰ã€‚ä¸»æµçš„ç½®ä¿¡åº¦é©±åŠ¨è§£ç ç­–ç•¥ï¼ˆå¦‚ Fast-dLLMã€D2Fï¼‰é‡‡ç”¨è´ªå¿ƒæ–¹å¼é€‰æ‹©é«˜ç½®ä¿¡ä½ç½®å¡«å……ï¼Œå®¹æ˜“é™·å…¥æ¬¡ä¼˜è·¯å¾„ï¼Œé™åˆ¶äº†æ•´ä½“å¹¶è¡Œæ•ˆç‡ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼š**Lookahead PArallel Decoding (LoPA)**
LoPA æ˜¯ä¸€ç§**æ— éœ€è®­ç»ƒã€å³æ’å³ç”¨**çš„ç®—æ³•ï¼Œé€šè¿‡å‰ç»æ¢ç´¢å¤šä¸ªå€™é€‰ TFO æ¥ä¼˜åŒ–æœªæ¥çš„å¹¶è¡Œæ½œåŠ›ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- åœ¨æ¯ä¸ªè§£ç æ­¥éª¤ä¸­ï¼Œå¹¶è¡Œæ„å»ºä¸€ä¸ªé”šå®šåˆ†æ”¯ï¼ˆanchor branchï¼‰å’Œè‹¥å¹²â€œå‰ç»â€åˆ†æ”¯ï¼ˆlookahead branchesï¼‰ï¼Œæ¯ä¸ªåˆ†æ”¯åŸºäºä¸åŒçš„é«˜ç½®ä¿¡ä½ç½®è¿›è¡Œé‡‡æ ·ã€‚
- åˆ©ç”¨ä¸€æ¬¡å‰å‘ä¼ æ’­å¯¹æ‰€æœ‰åˆ†æ”¯è¿›è¡ŒéªŒè¯ï¼Œè®¡ç®—å„åˆ†æ”¯çš„ **Branch Confidence**ï¼ˆå‰©ä½™æœªå¡«ä½ç½®çš„å¹³å‡ç½®ä¿¡åº¦ï¼‰ï¼Œé€‰æ‹©æœ€å…·æœªæ¥å¹¶è¡Œæ½œåŠ›çš„åˆ†æ”¯ä½œä¸ºä¸‹ä¸€æ­¥è¾“å…¥ã€‚
- é€šè¿‡è¿­ä»£é€‰æ‹©æœ€ä¼˜è·¯å¾„ï¼Œæ˜¾è‘—æå‡æ•´ä½“ **Tokens Per Forward pass (TPF)**ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **é€šç”¨æ€§** | ä¸ä¾èµ–ç‰¹å®šæ¨¡å‹ç»“æ„ï¼Œå¯é›†æˆåˆ°ä»»æ„åŸºäºç½®ä¿¡åº¦é©±åŠ¨çš„ dLLMï¼ˆå¦‚ D2Fã€Vanilla Dreamï¼‰ã€‚ |
| **æ— éœ€è®­ç»ƒ** | å®Œå…¨åœ¨æ¨ç†é˜¶æ®µå®ç°ï¼Œä¸ä¿®æ”¹æ¨¡å‹æƒé‡æˆ–è®­ç»ƒè¿‡ç¨‹ã€‚ |
| **æ›´é«˜å¹¶è¡Œåº¦** | å°† TPF ä»ä¼ ç»Ÿæ–¹æ³•çš„ ~2â€“3 æå‡è‡³ **10.1ï¼ˆGSM8Kï¼‰å’Œ 8.3ï¼ˆHumanEval+ï¼‰**ï¼Œè¿œè¶…åŸºçº¿ã€‚ |
| **ä¿æŒæ€§èƒ½** | åœ¨å¤§å¹…æå‡é€Ÿåº¦çš„åŒæ—¶ï¼Œç”Ÿæˆè´¨é‡ä¼˜äºæˆ–æ¥è¿‘åŸå§‹ baselineã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **æ•°å­¦æ¨ç†ä»»åŠ¡**ï¼š
  - `GSM8K`ï¼ˆ4-shotï¼‰
  - `MATH`ï¼ˆ4-shotï¼‰
- **ä»£ç ç”Ÿæˆä»»åŠ¡**ï¼š
  - `HumanEval`ï¼ˆ0-shotï¼‰ å’Œå¢å¼ºç‰ˆ `HumanEval+`
  - `MBPP`ï¼ˆ3-shotï¼‰ å’Œå¢å¼ºç‰ˆ `MBPP+`

è¿™äº›æ•°æ®é›†è¦†ç›–äº†å¤æ‚é€»è¾‘æ¨ç†ä¸ç¼–ç¨‹èƒ½åŠ›è¯„ä¼°ï¼Œé€‚åˆæµ‹è¯• dLLM çš„ç”Ÿæˆè´¨é‡å’Œå¹¶è¡Œæ•ˆç‡ã€‚

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡
#### ä¸»è¦æ¨¡å‹
- **D2F-Dream-7B** å’Œ **D2F-DiffuCoder-7B**ï¼šä½œä¸ºä¸»å¹²æ¨¡å‹ï¼Œç»“åˆ LoPA è¿›è¡Œæµ‹è¯•ã€‚
- **Vanilla Dream-7B**ï¼šç”¨äºéªŒè¯ LoPA çš„æ³›åŒ–èƒ½åŠ›ã€‚

#### æ¨ç†ç³»ç»Ÿå®ç°
ä¸ºå……åˆ†å‘æŒ¥ LoPA çš„å¹¶è¡Œæ½œåŠ›ï¼Œä½œè€…è®¾è®¡äº†ä¸“ç”¨åˆ†å¸ƒå¼æ¨ç†ç³»ç»Ÿ **LoPA-Dist**ï¼Œæ”¯æŒä¸¤ç§åç«¯ï¼š
- **LoPA-Dist-NV**ï¼šé¢å‘ NVIDIA CUDA å¹³å°ï¼ˆH200 GPUï¼‰ï¼Œé‡‡ç”¨é™æ€ KV ç¼“å­˜ä¸ä¸¤é˜¶æ®µæ›´æ–°åè®®ã€‚
- **LoPA-Dist-Ascend**ï¼šé¢å‘åä¸º Ascend 910C NPUï¼Œé‡‡ç”¨ç±» vLLM æ¶æ„ï¼Œæ”¯æŒ Tensor Parallelism (TP) ä¸ Branch Parallelism (BP) æ··åˆå¹¶è¡Œã€‚

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **TPF (Tokens Per Forward pass)** | æ¯æ¬¡å‰å‘ä¼ æ’­å¡«å……çš„ token æ•°é‡ï¼Œè¡¡é‡å¹¶è¡Œæ•ˆç‡ã€‚ |
| **TPS (Tokens Per Second)** | å®é™…ååé‡ï¼Œåæ˜ çœŸå®æ¨ç†é€Ÿåº¦ã€‚ |
| **Score** | ä»»åŠ¡å‡†ç¡®ç‡ï¼ˆPass@1 æˆ–ç­‰æ•ˆæŒ‡æ ‡ï¼‰ã€‚ |
| **Latency** | å•æ ·æœ¬ç”Ÿæˆå»¶è¿Ÿã€‚ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Vanilla dLLM**ï¼šæ ‡å‡†æ‰©æ•£è¯­è¨€æ¨¡å‹è§£ç ã€‚
- **Fast-dLLM**ï¼šè®­ç»ƒè‡ªç”±åŠ é€Ÿæ–¹æ³•ï¼Œåˆ©ç”¨ KV ç¼“å­˜ä¸å¹¶è¡Œè§£ç ã€‚
- **D2F**ï¼šåŸºäºéå¯¹ç§°è’¸é¦çš„å…ˆè¿› dLLM æ¡†æ¶ã€‚
- **SDAR-8B-Chat**ï¼šå¼ºç«äº‰æ€§ dLLM åŸºçº¿ã€‚
- **Qwen3-8B (AR model)**ï¼šè‡ªå›å½’æ¨¡å‹ä»£è¡¨ï¼Œç”¨äºæ¨ªå‘æ¯”è¾ƒååé‡ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & 2 & 3ï¼‰

#### ğŸ”¹ TPF æå‡æ˜¾è‘—
| æ¨¡å‹ | ä»»åŠ¡ | TPF (Vanilla) | TPF (LoPA) | æå‡å€æ•° |
|------|------|----------------|-------------|----------|
| D2F-Dream | GSM8K | 3.1 | **10.1** | Ã—3.26 |
| D2F-Dream | MATH | 2.6 | **8.0** | Ã—3.08 |
| D2F-DiffuCoder | HumanEval+ | 2.2 | **8.3** | Ã—3.77 |
| D2F-DiffuCoder | MBPP+ | 2.2 | **6.7** | Ã—3.05 |

> âœ… **LoPA å°† TPF æå‡è¿‘ 3â€“4 å€ï¼Œçªç ´ä¼ ç»Ÿ dLLM å¹¶è¡Œç“¶é¢ˆã€‚**

#### ğŸ”¹ ä¿æŒç”šè‡³è¶…è¶Š baseline æ€§èƒ½
| æ¨¡å‹ | ä»»åŠ¡ | Score (Baseline) | Score (LoPA) |
|------|------|--------------------|---------------|
| D2F-Dream | GSM8K | 78.5 | **73.8**ï¼ˆä»é«˜äº Dream baseline çš„ 72.6ï¼‰ |
| D2F-DiffuCoder | HumanEval+ | 65.9 | **64.0**ï¼ˆè½»å¾®ä¸‹é™ï¼‰ |
| D2F-Dream | MATH | 36.8 | **35.2**ï¼ˆæ¥è¿‘ï¼‰ |

> âœ… **å°½ç®¡è¿½æ±‚é«˜é€Ÿï¼ŒLoPA æœªé€ æˆä¸¥é‡æ€§èƒ½é€€åŒ–ï¼Œéƒ¨åˆ†åœºæ™¯ä¸‹ä»ä¼˜äºåŸå§‹ Dream baselineã€‚**

#### ğŸ”¹ å®é™…ååé‡æƒŠäººï¼ˆTable 3ï¼‰
| æ¨¡å‹ | ç³»ç»Ÿ | å¹³å‡ TPS (MBPP) | æœ€å¤§ TPS (MBPP) | å¹³å‡ TPS (GSM8K) |
|------|------|------------------|------------------|-------------------|
| D2F-Dream-Base | LoPA-Dist-NV | 630.28 | 1472.37 | 566.97 |
| D2F-Dream-Base | **LoPA-Dist-Ascend** | **1073.86** | **2400.12** | **856.46** |

> âš¡ï¸ **åœ¨ Ascend 910C ä¸Šï¼Œå•æ ·æœ¬ååè¾¾ 1073.86 tokens/sï¼Œå³°å€¼è¶…è¿‡ 2400 tokens/sï¼**

#### ğŸ”¹ ä¸ SOTA åŸºçº¿å¯¹æ¯”ï¼ˆTable 7ï¼‰
| æ¨¡å‹ | TPS (GSM8K) | TPF | Score (GSM8K) |
|------|--------------|-----|----------------|
| Qwen3-8B (AR) | 317.31 | 1.0 | 93.63 |
| SDAR-8B-Chat | 273.31 | 2.1 | 91.30 |
| **D2F-Dream + LoPA (Ascend)** | **856.46** | **9.34** | **62.55** |

> ğŸ“ˆ **è™½ç„¶å‡†ç¡®ç‡ç•¥ä½ï¼Œä½† LoPA åœ¨ååé‡ä¸Šç¢¾å‹ AR æ¨¡å‹å’Œå…¶ä»– dLLMï¼Œé€‚ç”¨äºé«˜ååã€ä½å»¶è¿Ÿåœºæ™¯ã€‚**

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 4 & Figure 5ï¼‰
- **Branch æ•°é‡å½±å“ TPF å’Œè´¨é‡æƒè¡¡**ï¼šéšç€ branch æ•°å¢åŠ ï¼ŒTPF æ˜¾è‘—ä¸Šå‡ï¼Œä½†è¿‡å¤šåˆ†æ”¯å¯èƒ½å¯¼è‡´æ€§èƒ½æ³¢åŠ¨ã€‚
- **æœ€ä½³é…ç½®**ï¼š
  - LoPA-Dist-NVï¼šTP1 + BP8
  - LoPA-Dist-Ascendï¼šTP4 + BP4
- **ä¸åŒä»»åŠ¡å¹¶è¡Œæ¨¡å¼å·®å¼‚**ï¼š
  - æ•°å­¦ä»»åŠ¡ï¼ˆGSM8Kï¼‰ï¼šä¸­æœŸå¹¶è¡Œåº¦æœ€é«˜ã€‚
  - ç¼–ç¨‹ä»»åŠ¡ï¼ˆMBPP/HumanEvalï¼‰ï¼šåæœŸå¹¶è¡Œåº¦æ›´é«˜ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **TFO æ˜¯å†³å®š dLLM å¹¶è¡Œæ•ˆç‡çš„å…³é”®å› ç´ **ï¼šç®€å•çš„è´ªå¿ƒå¡«å……ç­–ç•¥æ— æ³•æœ€å¤§åŒ–é•¿æœŸå¹¶è¡Œæ½œåŠ›ã€‚
2. **LoPA æˆåŠŸæ‰“ç ´å¹¶è¡Œç“¶é¢ˆ**ï¼šé€šè¿‡å‰ç»æ¢ç´¢å¤šæ¡è§£ç è·¯å¾„ï¼ŒåŠ¨æ€é€‰æ‹©æœ€ä¼˜ TFOï¼Œå°† TPF æå‡è‡³ **10+**ï¼Œè¿œè¶…ç°æœ‰æ–¹æ³•ã€‚
3. **ç®—æ³•ä¸ç³»ç»ŸååŒè®¾è®¡è‡³å…³é‡è¦**ï¼šæå‡º **Branch Parallelism (BP)** åˆ†å¸ƒå¼æ¶æ„ï¼Œä½¿é«˜ TPF èƒ½è½¬åŒ–ä¸ºå®é™…é«˜ TPSã€‚
4. **LoPA å…·å¤‡è‰¯å¥½æ³›åŒ–æ€§**ï¼šä¸ä»…é€‚ç”¨äº D2Fï¼Œä¹Ÿèƒ½æœ‰æ•ˆåŠ é€Ÿ Vanilla Dream ç­‰å…¶ä»– dLLMã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ç¡¬ä»¶èµ„æºéœ€æ±‚é«˜**ï¼šéœ€è¦å¤šè®¾å¤‡æ”¯æŒ Branch Parallelismï¼Œä¸é€‚åˆè¾¹ç¼˜éƒ¨ç½²ã€‚
- **å­˜åœ¨ç²¾åº¦-é€Ÿåº¦æƒè¡¡**ï¼šæç«¯è¿½æ±‚é€Ÿåº¦æ—¶ï¼ˆå¦‚é™ä½è§£ç é˜ˆå€¼ï¼‰ï¼Œå¯èƒ½ç‰ºç‰²ä¸€å®šç”Ÿæˆè´¨é‡ã€‚
- **ç›®å‰ä»…é™äº confidence-driven dLLMs**ï¼šå¯¹éç½®ä¿¡åº¦é©±åŠ¨çš„è§£ç æœºåˆ¶é€‚é…å°šéœ€ç ”ç©¶ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- æ‰©å±•è‡³æ›´å¤šç±»å‹çš„ dLLM æ¶æ„ï¼ˆå¦‚ flow-based æˆ– consistency modelsï¼‰ã€‚
- æ¢ç´¢æ›´é«˜æ•ˆçš„ branch selection ç­–ç•¥ï¼ˆå¦‚å­¦ä¹ å‹ policyï¼‰ã€‚
- æ”¯æŒåŠ¨æ€ branch æ•°è°ƒæ•´ä»¥é€‚åº”ä¸åŒä»»åŠ¡é˜¶æ®µã€‚
- åœ¨çœŸå®ç”Ÿäº§ç¯å¢ƒä¸­éƒ¨ç½² LoPA-Dist å¼•æ“ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–æœåŠ¡å»¶è¿Ÿä¸æˆæœ¬ã€‚

---

> ğŸ’¡ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> LoPA é€šè¿‡â€œå‘å‰çœ‹â€çš„å¹¶è¡Œè§£ç ç­–ç•¥ï¼Œé¦–æ¬¡å®ç°äº† dLLM çš„ **>10 tokens/step** é«˜æ•ˆæ¨ç†ï¼Œå¹¶é…åˆä¸“ç”¨ç³»ç»Ÿè¾¾æˆ **>1000 tokens/sec** çš„ååï¼Œä¸ºä¸‹ä¸€ä»£é«˜é€Ÿéè‡ªå›å½’è¯­è¨€æ¨¡å‹æä¾›äº†å¯è¡Œçš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 5. [TS-DP: Reinforcement Speculative Decoding For Temporal Adaptive Diffusion Policy Acceleration](https://arxiv.org/abs/2512.15773)

**Authors**: Ye Li, Jiahe Feng, Yuan Meng, Kangye Ji, Chen Tang, Xinwan Wen, Shutao Xia, Zhi Wang, Wenwu Zhu  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2512.15773v1  

#### Abstract
Diffusion Policy (DP) excels in embodied control but suffers from high inference latency and computational cost due to multiple iterative denoising steps. The temporal complexity of embodied tasks demands a dynamic and adaptable computation mode. Static and lossy acceleration methods, such as quanti...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šTS-DP: Reinforcement Speculative Decoding For Temporal Adaptive Diffusion Policy Acceleration

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
**Diffusion Policy (DP)** åœ¨å…·èº«æ§åˆ¶ï¼ˆembodied controlï¼‰ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿç”Ÿæˆè¿è´¯çš„åŠ¨ä½œåºåˆ—å¹¶å»ºæ¨¡å¤šæ¨¡æ€åŠ¨ä½œåˆ†å¸ƒã€‚ç„¶è€Œï¼Œå…¶æ¨ç†è¿‡ç¨‹ä¾èµ–äºå¤šæ¬¡è¿­ä»£å»å™ªæ­¥éª¤ï¼Œå¯¼è‡´**é«˜æ¨ç†å»¶è¿Ÿ**å’Œ**è®¡ç®—å¼€é”€å¤§**ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶æœºå™¨äººæ§åˆ¶çš„éœ€æ±‚ã€‚

ç°æœ‰çš„åŠ é€Ÿæ–¹æ³•å¦‚é‡åŒ–ï¼ˆquantizationï¼‰ã€å‰ªæï¼ˆpruningï¼‰å’Œç¼“å­˜ï¼ˆcachingï¼‰è™½ç„¶èƒ½é™ä½è®¡ç®—æˆæœ¬ï¼Œä½†å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **æœ‰æŸåŠ é€Ÿ**ï¼ˆlossy accelerationï¼‰ï¼šä¿®æ”¹ä¸­é—´ç‰¹å¾è¡¨ç¤ºï¼Œå½±å“ç­–ç•¥ç²¾åº¦ï¼›
- **é™æ€æœºåˆ¶**ï¼šæ— æ³•é€‚åº”ä»»åŠ¡éš¾åº¦éšæ—¶é—´å˜åŒ–çš„åŠ¨æ€ç¯å¢ƒï¼›
- **ç¼ºä¹æ—¶åºæ„ŸçŸ¥èƒ½åŠ›**ï¼šå¿½è§†äº†å…·èº«ä»»åŠ¡ä¸­çš„æ—¶é—´ç›¸å…³æ€§å’ŒåŠ¨æ€å¤æ‚æ€§ã€‚

å› æ­¤ï¼Œå¦‚ä½•åœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹å®ç°**é«˜æ•ˆã€è‡ªé€‚åº”ã€æ— æŸçš„æ¨ç†åŠ é€Ÿ**æˆä¸ºå…³é”®æŒ‘æˆ˜ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯

æœ¬æ–‡æå‡ºäº† **TS-DP**ï¼ˆTemporal-aware Reinforcement-based Speculative Diffusion Policyï¼‰ï¼Œæ˜¯é¦–ä¸ªå°†**æ¨æµ‹è§£ç **ï¼ˆspeculative decodingï¼‰å¼•å…¥ DP å¹¶å…·å¤‡**æ—¶é—´å¤æ‚åº¦æ„ŸçŸ¥èƒ½åŠ›**çš„æ¡†æ¶ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰åŸºäºçŸ¥è¯†è’¸é¦çš„è½»é‡çº§ **Transformer drafter**
- è®¾è®¡ä¸€ä¸ªå•å±‚ Transformer æ¨¡å—ä½œä¸º **drafter model**ï¼Œé€šè¿‡çŸ¥è¯†è’¸é¦ä» DP æ•™å¸ˆæ¨¡å‹å­¦ä¹ å»å™ªè¡Œä¸ºã€‚
- åœ¨æ¨ç†é˜¶æ®µï¼Œç”±è¯¥è½»é‡ drafter æ‰§è¡Œå¤šæ­¥å»å™ªï¼Œæ›¿ä»£åŸå§‹ DP çš„æ˜‚è´µè°ƒç”¨ã€‚
- ä½¿ç”¨ **reflection-maximal coupling** å¯¹é¦–æ¬¡è¢«æ‹’ç»çš„è‰æ¡ˆè¿›è¡Œä¿®æ­£ï¼Œç¡®ä¿é‡‡æ ·åˆ†å¸ƒä¸€è‡´æ€§ï¼Œå®ç°**æ— æŸåŠ é€Ÿ**ã€‚

#### ï¼ˆ2ï¼‰åŸºäºå¼ºåŒ–å­¦ä¹ çš„ **PPO-based scheduler**
- å°†æ¨æµ‹è§£ç å‚æ•°ï¼ˆå¦‚ draft æ­¥æ•° $K$ã€æ¥å—é˜ˆå€¼ $\lambda$ã€sigma ç¼©æ”¾å› å­ç­‰ï¼‰è®¾ä¸ºå¯è°ƒè¶…å‚æ•°ã€‚
- æ„å»ºä¸€ä¸ªåŸºäº **Proximal Policy Optimization (PPO)** çš„è°ƒåº¦å™¨ï¼Œä»¥å½“å‰è§‚æµ‹ã€å†å²åŠ¨ä½œå’Œä»»åŠ¡è¿›åº¦ä¸ºè¾“å…¥ï¼ŒåŠ¨æ€è°ƒæ•´è¿™äº›å‚æ•°ã€‚
- å½¢å¼åŒ–ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰ï¼Œé€šè¿‡ç¨€ç–å¥–åŠ± + å¯†é›†è¿‡ç¨‹å¥–åŠ±è”åˆä¼˜åŒ–ä»»åŠ¡æˆåŠŸç‡ä¸æ¨ç†æ•ˆç‡ã€‚

#### ï¼ˆ3ï¼‰ç«¯åˆ°ç«¯çš„æ—¶é—´æ„ŸçŸ¥æ¨æµ‹è§£ç æ¶æ„
- é¦–æ¬¡å®ç°é’ˆå¯¹ DP çš„**æ—¶åºè‡ªé€‚åº”æ¨æµ‹è§£ç **ï¼Œä½¿åŠ é€Ÿç­–ç•¥èƒ½éšä»»åŠ¡é˜¶æ®µï¼ˆå¦‚ç²—ç²’åº¦ç§»åŠ¨ vs. ç²¾ç»†æ“ä½œï¼‰è‡ªåŠ¨è°ƒèŠ‚ã€‚
- è°ƒåº¦å™¨ä¸è§‚å¯Ÿç¼–ç å™¨å¹¶è¡Œè¿è¡Œï¼Œä¸å¢åŠ é¢å¤–å»¶è¿Ÿã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹æ³• | æ˜¯å¦æœ‰æŸ | æ˜¯å¦è‡ªé€‚åº” | åŠ é€Ÿæ¯” | å®æ—¶æ€§ |
|------|----------|------------|--------|--------|
| Quantization / Pruning | âœ— æœ‰æŸ | âœ— é™æ€ | ~2â€“3Ã— | âŒ |
| Cache-based (e.g., BAC) | âœ— æœ‰æŸ | âœ— å‡†é™æ€ | ~3.4Ã— | âŒ |
| Frozen Target Draft [2] | âœ“ æ— æŸ | âœ— å›ºå®šå‚æ•° | ~3.0Ã— | âŒ |
| SpeCa [27] | âœ“ æ— æŸ | âœ— å›ºå®šå‚æ•° | ~2.7â€“2.9Ã— | âŒ |
| **TS-DP (Ours)** | âœ“ **æ— æŸ** | âœ“ **åŠ¨æ€è‡ªé€‚åº”** | **3.7â€“4.17Ã—** | âœ… **è¾¾ 25Hz** |

> âœ… TS-DP å®ç°äº†**æ— æŸã€è‡ªé€‚åº”ã€é«˜å€ç‡åŠ é€Ÿ**ï¼Œä¸”è¾¾åˆ°**å®æ—¶æ§åˆ¶é¢‘ç‡ï¼ˆ25Hzï¼‰**

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
åœ¨å››ä¸ªä¸»æµæœºå™¨äººæ“ä½œåŸºå‡†ä¸Šè¿›è¡Œå…¨é¢è¯„ä¼°ï¼š
- **Robomimic** ä¸‹å±å­ä»»åŠ¡ï¼š
  - Proficient Human (PH) æ•°æ®é›†ï¼šç†Ÿç»ƒäººç±»æ¼”ç¤ºï¼Œæ¶µç›– Lift, Can, Square, Transport, Tool, Push-T
  - Mixed Human (MH) æ•°æ®é›†ï¼šæ··åˆæŠ€èƒ½æ°´å¹³çš„äººç±»æ¼”ç¤º
- å¤šé˜¶æ®µå¤æ‚ä»»åŠ¡ï¼š
  - **Kitchen**ï¼šæ¶‰åŠå¾®æ³¢ç‚‰ã€çƒ§æ°´å£¶ç­‰å¤šä¸ªç‰©ä½“äº¤äº’
  - **Block Pushing (BP)**ï¼šåˆ†é˜¶æ®µæ¨è¿›ç›®æ ‡å—è‡³æŒ‡å®šåŒºåŸŸ

æ‰€æœ‰å®éªŒé‡‡ç”¨å›ºå®šéšæœºç§å­å¤ç°ç»“æœã€‚

---

### å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡

#### æ¨¡å‹é…ç½®
- **Base Model**: Diffusion Policy [10]ï¼Œå« 8 å±‚ Transformer
- **Drafter**: å•å±‚ Transformerï¼Œå…±äº«è¾“å…¥è¾“å‡ºæ¥å£ä¸ DDPM è°ƒåº¦å™¨
- **Scheduler**: PPO-basedï¼Œè¾“å…¥åŒ…å«å›¾åƒ/çŠ¶æ€å‘é‡ã€å†å²åŠ¨ä½œã€ä»»åŠ¡è¿›åº¦

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Success Rate (%)** | ä¸»è¦å‡†ç¡®æ€§æŒ‡æ ‡ï¼ˆé™¤ Push-T å¤–ï¼‰ |
| **Target Area Coverage** | Push-T å’Œ Block Pushing ä½¿ç”¨ |
| **NFE (Number of Function Evaluations)** | è¡¡é‡è®¡ç®—å¼€é”€ï¼Œæ¯ drafter è°ƒç”¨è®¡ä¸º 1/8 NFE |
| **Speed Ã—** | æ¨ç†é€Ÿåº¦æå‡å€æ•°ï¼ˆç›¸å¯¹ DP åŸå§‹ç‰ˆæœ¬ï¼‰ |
| **Inference Frequency (Hz)** | æ§åˆ¶é¢‘ç‡ï¼Œå†³å®šæ˜¯å¦æ”¯æŒå®æ—¶åº”ç”¨ |
| **Draft Acceptance Rate (%)** | åæ˜ æ¨æµ‹è´¨é‡ä¸æ— æŸç¨‹åº¦ |

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Diffusion Policy [10]**ï¼šåŸå§‹æœªåŠ é€ŸåŸºçº¿
- **Frozen Target Draft [2]**ï¼šåŸºäºå·®åˆ†æ¨æµ‹çš„ç»å…¸æ— æŸæ–¹æ³•
- **SpeCa [27]**ï¼šåŸºäºç‰¹å¾ç¼“å­˜çš„æ¨æµ‹è§£ç æ–¹æ³•
- **BAC [15]**ï¼šåŸºäºå—çº§è‡ªé€‚åº”ç¼“å­˜çš„æœ‰æŸåŠ é€Ÿæ–¹æ³•

ç¡¬ä»¶å¹³å°ï¼šNVIDIA A100 GPU (40GB)

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### è¡¨ 1ï¼šProficient Human (PH) æ•°æ®é›†è¡¨ç°
| Method | AVG SR (%) | NFE (% of DP) | Speed Ã— |
|--------|-------------|----------------|---------|
| DP [10] | 76 / 80 | 100% | 1.0Ã— |
| Frozen Target Draft | 56 / 60 | 33% | 3.03Ã— |
| SpeCa | 76 / 78 | 34% | 2.94Ã— |
| BAC | 77 / 81 | â€“ | 3.40Ã— |
| **TS-DP** | **85 / 80** | **24%** | **4.17Ã—** |

âœ… **TS-DP æå‡æˆåŠŸç‡åŒæ—¶å®ç°æœ€é«˜åŠ é€Ÿæ¯”**

---

#### è¡¨ 2ï¼šMixed Human (MH) æ•°æ®é›†è¡¨ç°
| Method | AVG SR (%) | NFE (% of DP) | Speed Ã— |
|--------|-------------|----------------|---------|
| DP [10] | 76 / 81 | 100% | 1.0Ã— |
| Frozen Target Draft | 49 / 55 | 34% | 2.94Ã— |
| SpeCa | 73 / 75 | 35% | 2.86Ã— |
| BAC | 75 / 80 | â€“ | 3.41Ã— |
| **TS-DP** | **75 / 84** | **26%** | **3.84Ã—** |

âœ… **ä¿æŒæ— æŸç²¾åº¦ï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–æ— æŸæ–¹æ³•**

---

#### è¡¨ 3ï¼šMulti-stage Tasks (Kitchen & BP)
| Method | AVG SR (%) | NFE (% of DP) | Speed Ã— |
|--------|-------------|----------------|---------|
| DP [10] | 99 / 99 | 100% | 1.0Ã— |
| Frozen Target Draft | 81 / 81 | 33% | 3.03Ã— |
| SpeCa | 97 / 97 | 37% | 2.70Ã— |
| BAC | 99 / 98 | â€“ | 3.60Ã— |
| **TS-DP** | **99 / 99** | **27%** | **3.70Ã—** |

âœ… **åœ¨å¤æ‚å¤šé˜¶æ®µä»»åŠ¡ä¸­ä»ä¿æŒå®Œç¾æˆåŠŸç‡ä¸é«˜æ•ˆåŠ é€Ÿ**

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### å›ºå®š draft æ­¥æ•° $K$ vs. è‡ªé€‚åº”è°ƒåº¦
| Configuration | AVG SR (%) | Speed Ã— |
|---------------|-------------|---------|
| $K=10$ (ä¿å®ˆ) | 84% | 2.45Ã— |
| $K=25$ | 75% | 3.47Ã— |
| $K=40$ (æ¿€è¿›) | 72% | 3.92Ã— |
| **TS-DP (adaptive)** | **87%** | **3.80Ã—** |

ğŸ“Œ **ç»“è®º**ï¼šå›ºå®šå‚æ•°å­˜åœ¨â€œåŠ é€Ÿ vs. ç²¾åº¦â€æƒè¡¡ï¼›è€Œ TS-DP çš„ RL è°ƒåº¦å™¨èƒ½åœ¨ä¸åŒä»»åŠ¡é˜¶æ®µæ™ºèƒ½è°ƒèŠ‚å‚æ•°ï¼Œåœ¨**æ›´é«˜æˆåŠŸç‡ä¸‹å®ç°æ¥è¿‘æœ€ä¼˜åŠ é€Ÿ**ã€‚

---

### æ¨ç†å»¶è¿Ÿä¸é¢‘ç‡æµ‹è¯•ï¼ˆTable 5ï¼‰
| Method | Avg Frequency (Hz) | Latency (s) |
|--------|-----------------------|-------------|
| DP | 7.42 Hz | 0.14 s |
| **TS-DP** | **25.00 Hz** | **0.04 s** |

âœ… **æå‡ 3.6Ã— æ§åˆ¶é¢‘ç‡ï¼Œçªç ´å®æ—¶æ§åˆ¶é—¨æ§›ï¼ˆé€šå¸¸éœ€ â‰¥20Hzï¼‰**

---

### å…¶ä»–å…³é”®æŒ‡æ ‡ï¼ˆè¡¥å……ææ–™ï¼‰
- **å¹³å‡è‰æ¡ˆæ¥å—ç‡**ï¼š> **94%**
- **è‰æ¡ˆæ•°é‡**ï¼šç»´æŒåœ¨ 88â€“94 ä¹‹é—´ï¼Œåæ˜ é«˜å¹¶è¡Œåˆ©ç”¨ç‡
- **è°ƒåº¦å™¨æ— é¢å¤–å»¶è¿Ÿ**ï¼šä¸ encoder å¹¶è¡Œæ‰§è¡Œï¼Œä¸å½±å“æ€»è€—æ—¶

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **æ¨æµ‹è§£ç é€‚ç”¨äº I/O-bound çš„ DP**ï¼šä¸åŒäºå›¾åƒç”Ÿæˆä¸­ compute-bound çš„æ‰©æ•£æ¨¡å‹ï¼ŒDP ç”Ÿæˆä½ç»´åŠ¨ä½œå‘é‡ï¼Œæ›´é€‚åˆ speculative decodingã€‚
2. âœ… **ä»»åŠ¡éš¾åº¦å…·æœ‰æ˜æ˜¾æ—¶åºç‰¹æ€§**ï¼šé«˜é€Ÿè¿åŠ¨ï¼ˆå¦‚æŠ“å–å‰ç§»åŠ¨ï¼‰æ¥å—ç‡ä½ï¼Œç²¾ç»†æ“ä½œï¼ˆå¦‚æ’å…¥ã€æ—‹è½¬ï¼‰åè€Œæ¥å—ç‡é«˜ï¼Œè¯´æ˜éœ€è¦**åŠ¨æ€è°ƒæ•´æ¨æµ‹å¼ºåº¦**ã€‚
3. âœ… **RL-based scheduler æ˜¾è‘—ä¼˜äºå›ºå®šç­–ç•¥**ï¼šé€šè¿‡åœ¨çº¿æ„ŸçŸ¥ä»»åŠ¡å¤æ‚åº¦ï¼Œå®ç°äº†æ›´ä¼˜çš„â€œåŠ é€Ÿ-ç²¾åº¦â€å¹³è¡¡ã€‚
4. âœ… **TS-DP å®ç°æ— æŸåŠ é€Ÿ + å®æ—¶æ§åˆ¶**ï¼šåœ¨å¤šä¸ªåŸºå‡†ä¸Šå‡è¾¾åˆ° **>3.7Ã— åŠ é€Ÿã€25Hz æ§åˆ¶é¢‘ç‡ã€æ— æ€§èƒ½ä¸‹é™**ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–é«˜è´¨é‡æ•™å¸ˆæ¨¡å‹**ï¼šdrafter æ€§èƒ½å—é™äº base DP çš„æ³›åŒ–èƒ½åŠ›ï¼›
2. **è®­ç»ƒå¼€é”€å¢åŠ **ï¼šéœ€é¢å¤–è®­ç»ƒ drafter å’Œ RL schedulerï¼›
3. **å¯¹æç«¯å¿«é€Ÿå˜åŒ–çš„ä»»åŠ¡å“åº”å¯èƒ½æ»å**ï¼šscheduler æ›´æ–°é¢‘ç‡æœ‰é™ï¼ˆçº¦æ¯ 10 æ­¥ä¸€æ¬¡ï¼‰ï¼Œå¯èƒ½å­˜åœ¨çŸ­æš‚ä¸åŒ¹é…ï¼›
4. **ç›®å‰ä»…éªŒè¯äºä»¿çœŸç¯å¢ƒ**ï¼šå°šæœªåœ¨çœŸå®æœºå™¨äººä¸Šéƒ¨ç½²ï¼Œå®é™… I/O å»¶è¿Ÿå¯èƒ½å½±å“æ”¶ç›Šã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³çœŸå®æœºå™¨äººç³»ç»Ÿ**ï¼šéªŒè¯åœ¨ç‰©ç†ä¸–ç•Œä¸­çš„ç¨³å®šæ€§ä¸é²æ£’æ€§ï¼›
2. **æ¢ç´¢æ›´é«˜æ•ˆçš„ drafter æ¶æ„**ï¼šå¦‚ MoEã€ç¨€ç–æ³¨æ„åŠ›ç­‰è¿›ä¸€æ­¥å‹ç¼©ï¼›
3. **ç»“åˆå…¶ä»–åŠ é€ŸæŠ€æœ¯**ï¼šå¦‚ä¸ one-step sampler æˆ–é‡åŒ–ç»“åˆï¼Œè¿½æ±‚æè‡´æ•ˆç‡ï¼›
4. **è·¨ä»»åŠ¡è¿ç§»è°ƒåº¦ç­–ç•¥**ï¼šè®¾è®¡é€šç”¨ schedulerï¼Œå‡å°‘ per-task è®­ç»ƒæˆæœ¬ï¼›
5. **ç†è®ºåˆ†ææ”¶æ•›æ€§ä¸ç¨³å®šæ€§**ï¼šå»ºç«‹ speculative decoding åœ¨é—­ç¯æ§åˆ¶ä¸‹çš„ç†è®ºä¿éšœã€‚

---

## æ€»ç»“

> ğŸ **TS-DP æ˜¯é¦–ä¸ªé¢å‘ Diffusion Policy çš„æ—¶é—´æ„ŸçŸ¥æ¨æµ‹è§£ç æ¡†æ¶**ï¼Œé€šè¿‡ **Transformer drafter + RL scheduler** çš„ååŒè®¾è®¡ï¼Œå®ç°äº†**æ— æŸã€è‡ªé€‚åº”ã€é«˜è¾¾ 4.17Ã— çš„æ¨ç†åŠ é€Ÿ**ï¼Œå¹¶å°†æ§åˆ¶é¢‘ç‡æå‡è‡³ **25Hz**ï¼ŒæˆåŠŸæ¨åŠ¨ Diffusion Policy è¿›å…¥**å®æ—¶å…·èº«æ§åˆ¶**çš„åº”ç”¨å‰æ²¿ã€‚å®éªŒå……åˆ†è¯æ˜å…¶åœ¨å¤šç§å¤æ‚ä»»åŠ¡ä¸Šçš„ä¼˜è¶Šæ€§ï¼Œä¸ºæœªæ¥é«˜æ•ˆ VLAï¼ˆVision-Language-Actionï¼‰æ¨¡å‹æä¾›äº†é‡è¦èŒƒå¼ã€‚

</details>

---

### 6. [CKA-Guided Modular Quantization: Beyond Bit-Width to Algorithmic Diversity](https://arxiv.org/abs/2512.16282)

**Authors**: Jinhao Zhang, Yunquan Zhang, Daning Chen  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2512.16282v1  

#### Abstract
Current mainstream post-training quantization methods for large language models typically apply a uniform quantization strategy across all network layers, overlooking the substantial differences in algorithmic suitability among layers. To address this limitation, we propose CKA Guided Modular Quanti...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# CKA-Guided Modular Quantization: Beyond Bit-Width to Algorithmic Diversity è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å½“å‰ä¸»æµçš„**Post-Training Quantization (PTQ)** æ–¹æ³•ï¼ˆå¦‚ GPTQã€AWQã€SmoothQuantï¼‰é€šå¸¸åœ¨æ‰€æœ‰ç½‘ç»œå±‚ä¸Šé‡‡ç”¨**ç»Ÿä¸€çš„é‡åŒ–ç­–ç•¥**ï¼Œå¿½ç•¥äº†ä¸åŒ Transformer å±‚åœ¨æƒé‡åˆ†å¸ƒã€æ¿€æ´»è¡Œä¸ºå’Œå¯¹é‡åŒ–è¯¯å·®æ•æ„Ÿåº¦ä¸Šçš„æ˜¾è‘—å·®å¼‚ã€‚è¿™ç§â€œä¸€åˆ€åˆ‡â€çš„æ–¹å¼é™åˆ¶äº†æ¨¡å‹å‹ç¼©åçš„æ€§èƒ½ä¸Šé™ã€‚

æ­¤å¤–ï¼Œç°æœ‰çš„æ··åˆç²¾åº¦ï¼ˆMixed-Precisionï¼‰æ–¹æ³•ä»…é€šè¿‡è°ƒæ•´**bit-width**ï¼ˆå¦‚æŸäº›å±‚ç”¨ INT4ï¼Œå…¶ä»–ç”¨ INT8ï¼‰æ¥å®ç°å¼‚æ„æ€§ï¼Œä½†**å›ºå®šäº†é‡åŒ–ç®—æ³•æœ¬èº«**ï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨ä¸åŒ PTQ ç®—æ³•ä¹‹é—´çš„äº’è¡¥ä¼˜åŠ¿ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸æ ¸å¿ƒæ€æƒ³
ä½œè€…æå‡º **CKA-Guided Modular Quantization** â€”â€”ä¸€ç§æ— éœ€å¾®è°ƒï¼ˆfine-tuning-freeï¼‰ã€å³æ’å³ç”¨ï¼ˆplug-and-playï¼‰çš„**ç®—æ³•å¼‚æ„é‡åŒ–æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

- **ç®—æ³•å¤šæ ·æ€§ï¼ˆAlgorithmic Heterogeneityï¼‰**ï¼š  
  ä¸åŒäºä¼ ç»Ÿæ–¹æ³•åªå˜ bit-widthï¼Œè¯¥æ–¹æ³•å…è®¸åœ¨ä¸åŒå±‚ä½¿ç”¨**ä¸åŒçš„ PTQ ç®—æ³•**ï¼ˆå¦‚ GPTQã€AWQã€SmoothQuantï¼‰ï¼Œä»è€Œæ›´ç²¾å‡†åœ°åŒ¹é…å„å±‚çš„ç‰¹æ€§ã€‚

- **åŸºäº CKA çš„è‡ªåŠ¨é€‰æ‹©æœºåˆ¶**ï¼š  
  å¼•å…¥ **Linear Centered Kernel Alignment (CKA)** ä½œä¸ºè¡¡é‡é‡åŒ–åå±‚è¾“å‡ºä¸åŸå§‹å…¨ç²¾åº¦æ¨¡å‹ä¹‹é—´è¡¨ç¤ºç›¸ä¼¼æ€§çš„æŒ‡æ ‡ï¼Œåœ¨æ¯ä¸ª decoder layer ä¸Šç‹¬ç«‹è¯„ä¼°å¤šä¸ª PTQ æ–¹æ³•ï¼Œå¹¶é€‰æ‹© CKA åˆ†æ•°æœ€é«˜çš„ç®—æ³•ã€‚

- **æ¨¡å—åŒ–ç»„è£…ï¼ˆModular Assemblyï¼‰**ï¼š  
  å°†æ¯å±‚é€‰å‡ºçš„æœ€ä¼˜é‡åŒ–ç‰ˆæœ¬ç»„åˆæˆä¸€ä¸ª**å¼‚æ„çš„æ··åˆé‡åŒ–æ¨¡å‹**ï¼ˆhybrid quantized modelï¼‰ï¼Œæ— éœ€ä»»ä½•é‡è®­ç»ƒã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³• | æœ¬æ–‡æ–¹æ³• |
|------|--------|---------|
| å¼‚æ„ç»´åº¦ | ä»… bit-widthï¼ˆINT4/INT8ï¼‰ | **ç®—æ³• + bit-width**ï¼ˆåŒä¸€ bit ä¸‹åˆ‡æ¢ç®—æ³•ï¼‰ |
| ç­–ç•¥çµæ´»æ€§ | å…¨å±€ä¸€è‡´æˆ–ç²—ç²’åº¦åˆ†ç»„ | **é€å±‚è‡ªé€‚åº”é€‰æ‹©æœ€ä¼˜ç®—æ³•** |
| æ˜¯å¦éœ€è¦å¾®è°ƒ | å¤šæ•°ä¸éœ€è¦ | **å®Œå…¨å…å¾®è°ƒ** |
| æ€§èƒ½æ½œåŠ› | å—é™äºå•ä¸€ç®—æ³•ç“¶é¢ˆ | **çªç ´å•ç®—æ³•å¤©èŠ±æ¿ï¼Œå‘æŒ¥ååŒæ•ˆåº”** |

> ğŸ’¡ **å…³é”®æ´è§**ï¼šæå‡é‡åŒ–æ€§èƒ½çš„å…³é”®ä¸ä»…æ˜¯â€œå“ªé‡Œè¯¥ç”¨ä½æ¯”ç‰¹â€ï¼Œæ›´æ˜¯â€œå“ªä¸ªç®—æ³•æœ€é€‚åˆè¿™ä¸€å±‚â€ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **æ ¡å‡†æ•°æ®é›†ï¼ˆCalibration Datasetï¼‰**ï¼š  
  - `C4`ï¼ˆ128 æ¡éšæœºé‡‡æ ·åºåˆ—ï¼Œé•¿åº¦ä¸º 1024 tokensï¼‰
- **è¯­è¨€å»ºæ¨¡ä»»åŠ¡è¯„ä¼°æ•°æ®é›†**ï¼š  
  - `C4`
  - `WikiText-2 (wiki2)`
- **ä¸‹æ¸¸ä»»åŠ¡è¯„ä¼°æ•°æ®é›†**ï¼š  
  - æ•°å­¦æ¨ç†ï¼š`GSM8K`
  - ä»£ç ç”Ÿæˆï¼š`HumanEval`
  - å¸¸è¯†æ¨ç†ï¼š`HellaSwag`
  - å¤šä»»åŠ¡ç†è§£ï¼š`MMLU`

---

### âš™ï¸ å®éªŒè®¾ç½®
- **ç›®æ ‡é‡åŒ–æ ¼å¼**ï¼š**Int4 æƒé‡ + Int8 æ¿€æ´»ï¼ˆW4A8ï¼‰**
- **group size**ï¼š128
- **ä¿ç•™ç»„ä»¶**ï¼šEmbeddingã€KV Cacheã€å‰å‘æ¿€æ´»ç­‰æ•æ„Ÿéƒ¨åˆ†ä¿æŒ FP16/BF16
- **å€™é€‰ PTQ æ–¹æ³•æ± ï¼ˆCandidate Poolï¼‰**ï¼š  
  GPTQã€AWQã€SmoothQuantï¼ˆå¯æ‰©å±•è‡³æ›´å¤šæ–¹æ³•ï¼‰
- **æœç´¢ç­–ç•¥**ï¼š**è´ªå¿ƒé€å±‚é€‰æ‹©ï¼ˆgreedy layer-wise selectionï¼‰**ï¼Œè€ƒè™‘å‰ä¸€å±‚é‡åŒ–è¾“å‡ºçš„å½±å“
- **CKA è®¡ç®—ä½ç½®**ï¼šFFN è¾“å‡ºï¼ˆæ®‹å·®è¿æ¥ä¹‹å‰ï¼‰ï¼Œé¿å…è·³æ¥å¹²æ‰°

---

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **FP16**ï¼šå…¨ç²¾åº¦åŸºå‡†
- **GPTQ**ï¼šåŸºäº Hessian çš„æƒé‡é‡åŒ–ä¼˜åŒ–
- **AWQ**ï¼šä¿æŠ¤æ˜¾è‘—æƒé‡é€šé“
- **SmoothQuant**ï¼šå¹³æ»‘æ¿€æ´»ä»¥é™ä½é‡åŒ–éš¾åº¦
- **SpinQuant**ï¼šæ—‹è½¬çŸ©é˜µæŠ‘åˆ¶å¼‚å¸¸å€¼
- **MP-GPTQ(FP16/4/2)**ï¼šä¼ ç»Ÿæ··åˆç²¾åº¦åŸºçº¿ï¼ˆéƒ¨åˆ†å±‚ 2-bitï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»

#### âœ… Perplexity (PPL) ç»“æœï¼ˆè¶Šä½è¶Šå¥½ï¼‰
| Model | æ–¹æ³• | C4 â†“ | Wiki2 â†“ |
|-------|------|-----|--------|
| Llama-3-8B | FP16 | 12.28 | 6.41 |
|               | GPTQ | 14.12 | 8.81 |
|               | AWQ  | 13.56 | 8.12 |
|               | SmoothQuant | 13.64 | 7.32 |
|               | SpinQuant   | 13.39 | 7.48 |
|               | **Ours**    | **12.72** | **6.89** |

> ğŸ‘‰ åœ¨ Llama-3-8B ä¸Šï¼Œ**Ours çš„ PPL æ¥è¿‘ FP16ï¼Œæ˜¾è‘—ä¼˜äºæ‰€æœ‰ PTQ åŸºçº¿**

| Model | æ–¹æ³• | Wiki2 â†“ |
|-------|------|--------|
| Qwen1.5-1.5B | SpinQuant | 13.31 |
|              | **Ours**  | **12.87**ï¼ˆâ†“0.44ï¼‰|

| Model | æ–¹æ³• | C4 â†“ |
|-------|------|-----|
| Qwen1.5-0.5B | AWQ/GPTQ ~26.0 | 
|              | **Ours** | **24.87**ï¼ˆæ˜æ˜¾æ›´ä½ï¼‰|

---

#### âœ… ä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®ç‡ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰
| Model | æ–¹æ³• | GSM8K â†‘ | HumanEval â†‘ | HellaSwag â†‘ | MMLU â†‘ |
|-------|------|--------|-------------|------------|--------|
| Llama-3-8B | FP16 | 77.17 | 60.71 | 77.39 | 67.31 |
|            | GPTQ | 71.89 | 58.45 | 76.91 | 60.54 |
|            | **Ours** | **74.33** | **59.67** | **77.13** | **65.87** |

| Qwen1.5-0.5B | AWQ | 21.87 |
|              | GPTQ | 20.22 |
|              | **Ours** | **25.12**ï¼ˆ+3.25~4.90 æå‡ï¼‰|

> ğŸ‘‰ ç‰¹åˆ«æ˜¯åœ¨æ•°å­¦æ¨ç†ï¼ˆGSM8Kï¼‰è¿™ç±»å¯¹é‡åŒ–æ•æ„Ÿçš„ä»»åŠ¡ä¸Šï¼Œæå‡å°¤ä¸ºæ˜¾è‘—ã€‚

---

### ğŸ” æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰PTQ å€™é€‰å¤šæ ·æ€§å½±å“ï¼ˆTable 3ï¼‰
ç§»é™¤ä»»ä¸€ç®—æ³•å‡å¯¼è‡´æ€§èƒ½ä¸‹é™ï¼š
- ç§»é™¤ **SmoothQuant** â†’ Llama-3-8B C4 PPL ä» 12.72 å‡è‡³ 13.55
- ç§»é™¤ **AWQ** â†’ GSM8K å‡†ç¡®ç‡ä¸‹é™ 1.5%
- è¡¨æ˜ä¸‰ç§ç®—æ³•å…·æœ‰**äº’è¡¥æ€§**ï¼Œç¼ºä¸€ä¸å¯

#### ï¼ˆ2ï¼‰Method-Heterogeneity vs Bit-Heterogeneityï¼ˆTable 4ï¼‰
ç›¸åŒå¹³å‡ bit å®½åº¦ä¸‹æ¯”è¾ƒï¼š
| èŒƒå¼ | æ–¹æ³• | Wiki2 â†“ | GSM8K â†‘ |
|------|------|--------|--------|
| Bit-Hetero | MP-GPTQ(FP16/4/2) | 7.95 | 73.40 |
| **Method-Hetero** | **Ours (W4-Mix)** | **6.89** | **74.33** |

> âœ… **ä¿æŒ 4-bit ä½†åˆ‡æ¢ç®—æ³•ï¼Œæ•ˆæœè¿œè¶…é™çº§åˆ° 2-bit çš„ä¼ ç»Ÿæ··åˆç²¾åº¦æ–¹æ¡ˆ**

#### ï¼ˆ3ï¼‰é‡åŒ–ç²’åº¦å½±å“ï¼ˆTable 5ï¼‰
| ç²’åº¦ | æ–¹æ³• | C4 â†“ | Wiki2 â†“ | GSM8K â†‘ |
|------|------|-----|--------|--------|
| Block-8 | Shared every 8 layers | 13.15 | 7.20 | 73.05 |
| Block-2 | Shared every 2 layers | 12.78 | 6.94 | 74.10 |
| **Ours** | **Layer-wise** | **12.72** | **6.89** | **74.33** |

> âœ… **é€å±‚ä¼˜åŒ– > å—çº§å…±äº«é…ç½®**ï¼Œè¯´æ˜ç²¾ç»†æ§åˆ¶å¿…è¦

#### ï¼ˆ4ï¼‰ä½æ¯”ç‰¹ç¯å¢ƒè¡¨ç°ï¼ˆTable 6ï¼‰
åœ¨æç«¯ **3-bit** è®¾ç½®ä¸‹ï¼š
- ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ GPTQï¼‰PPL é£™å‡è‡³ 19+
- **Ours** åœ¨ Llama-3-8B ä¸Šä»ç»´æŒ **13.55 C4 PPL** å’Œ **61.5% GSM8K**
> âœ… æ˜¾ç¤ºå‡ºæ›´å¼ºçš„é²æ£’æ€§å’Œé€‚åº”èƒ½åŠ›

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **ä¸åŒ Transformer å±‚å¯¹ PTQ ç®—æ³•æœ‰æ˜¾è‘—åå¥½å·®å¼‚**ï¼š  
   æµ…å±‚å€¾å‘äº GPTQï¼Œä¸­æ·±å±‚äº¤æ›¿ä½¿ç”¨ AWQ å’Œ SmoothQuantï¼Œè¡¨æ˜**æ²¡æœ‰ä¸‡èƒ½ç®—æ³•**ã€‚

2. **ç®—æ³•å¼‚æ„æ€§æ¯” bit-width å¼‚æ„æ€§æ›´é‡è¦**ï¼š  
   åœ¨å›ºå®š bit-width ä¸‹åŠ¨æ€åˆ‡æ¢ç®—æ³•ï¼Œæ¯”å¼ºåˆ¶æŸäº›å±‚è¿›å…¥æä½ä½å®½ï¼ˆå¦‚ 2-bitï¼‰æ›´èƒ½ç»´æŒæ€§èƒ½ã€‚

3. **CKA æ˜¯æœ‰æ•ˆçš„åŠŸèƒ½ä¿çœŸåº¦ä»£ç†æŒ‡æ ‡**ï¼š  
   é«˜ CKA åˆ†æ•°ä¸ä½ PPL å’Œé«˜ä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®ç‡å¼ºç›¸å…³ï¼Œä¸”å¯é€šè¿‡çº¿æ€§æ¢å¤å®éªŒè¯æ˜å…¶å› æœæœ‰æ•ˆæ€§ï¼ˆAppendix A.2ï¼‰ã€‚

4. **æ— éœ€å¾®è°ƒå³å¯è¶…è¶Š SOTA**ï¼š  
   æ‰€æœ‰å®éªŒå‡ä¸ºçº¯ PTQï¼Œæ— ä»»ä½• retrainingï¼Œå´åœ¨å¤šä¸ªæ¨¡å‹ï¼ˆLLaMAã€Qwenï¼‰å’Œä»»åŠ¡ä¸Šè¾¾åˆ° SOTAã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
| é—®é¢˜ | æè¿° |
|------|------|
| **ç†è®ºè¿‘ä¼¼æ€§** | è´ªå¿ƒé€å±‚é€‰æ‹©æ˜¯å±€éƒ¨æœ€ä¼˜ï¼Œå¯èƒ½å¿½ç•¥é•¿ç¨‹ä¾èµ–ï¼Œéå…¨å±€æœ€ä¼˜è§£ |
| **éƒ¨ç½²å·¥ç¨‹æŒ‘æˆ˜** | æ··åˆå¤šç§ kernelï¼ˆå¦‚ AWQ + GPTQï¼‰ä¼šç ´å operator fusionï¼Œå¢åŠ æ¨ç†æ—¶çš„å†…å­˜è®¿é—®å¼€é”€ |
| **ç¦»çº¿æˆæœ¬è¾ƒé«˜** | æ¯å±‚éœ€è¿è¡Œå¤šä¸ª PTQ æ–¹æ³•è¿›è¡Œæœç´¢ï¼Œè€—æ—¶éšå€™é€‰æ± å¤§å°çº¿æ€§å¢é•¿ |

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´é«˜æ•ˆçš„æœç´¢ç­–ç•¥ï¼ˆå¦‚å¼ºåŒ–å­¦ä¹ ã€ä»£ç†æ¨¡å‹é¢„æµ‹ï¼‰
- å¼€å‘æ”¯æŒå¼‚æ„ kernel çš„é«˜æ€§èƒ½æ¨ç†å¼•æ“ï¼ˆå¦‚ vLLM æ‰©å±•ï¼‰
- å°†è¯¥èŒƒå¼æ¨å¹¿è‡³ **Quantization-Aware Training (QAT)** æˆ– **MoE æ¶æ„**
- ç ”ç©¶å¦‚ä½•å°† CKA æŒ‡æ ‡è¿›ä¸€æ­¥ç”¨äºè‡ªåŠ¨åŒ– bit-width åˆ†é…

---

## âœ… æ€»ç»“
æœ¬è®ºæ–‡æå‡ºäº† **CKA-Guided Modular Quantization**ï¼Œé¦–æ¬¡ç³»ç»Ÿæ¢ç´¢äº†åœ¨ LLM ä¸­è¿›è¡Œ**ç®—æ³•çº§å¼‚æ„é‡åŒ–**çš„å¯èƒ½æ€§ã€‚é€šè¿‡å¼•å…¥ CKA ä½œä¸ºå±‚çº§åˆ«é‡åŒ–ç­–ç•¥é€‰æ‹©çš„æ ‡å‡†ï¼Œå®ç°äº†æ— éœ€å¾®è°ƒçš„é«˜æ€§èƒ½æ··åˆé‡åŒ–ï¼Œåœ¨ PPL å’Œå¤šé¡¹ä¸‹æ¸¸ä»»åŠ¡ä¸Šå…¨é¢è¶…è¶Šç°æœ‰ PTQ ä¸æ··åˆç²¾åº¦æ–¹æ³•ã€‚

> ğŸ”‘ **æ ¸å¿ƒå¯ç¤º**ï¼šæœªæ¥çš„é«˜æ•ˆ LLM éƒ¨ç½²ä¸åº”åªå…³æ³¨â€œå¤šå®½çš„è½¦é“â€ï¼ˆbit-widthï¼‰ï¼Œæ›´è¦æ€è€ƒâ€œå“ªç§è½¦å‹æ›´é€‚åˆè¿™æ®µè·¯â€ï¼ˆquantization algorithmï¼‰ã€‚

</details>

---

### 7. [BRAID: Bounded Reasoning for Autonomous Inference and Decisions](https://arxiv.org/abs/2512.15959)

**Authors**: Arma\u{g}an Amcalar, Eyup Cinar  
**Category**: cs.CL  
**Published**: 2025-12-19  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.15959v1  

#### Abstract
Large Language Models (LLMs) exhibit nonlinear relationships between performance, cost, and token usage. This paper presents a quantitative study on structured prompting using BRAID (Bounded Reasoning for Au tonomous Inference and Decisions) across multiple GPT model tiers, eval uated on the Advance...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**BRAID: Bounded Reasoning for Autonomous Inference and Decisions**

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è™½ç„¶åœ¨æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å…¶åŸºäºè‡ªç„¶è¯­è¨€çš„â€œè‡ªç”±å½¢å¼â€æ¨ç†ï¼ˆå¦‚ Chain-of-Thought, CoTï¼‰å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **é«˜ token å¼€é”€**ï¼šç”Ÿæˆå†—é•¿ã€ä½è¯­ä¹‰å¯†åº¦çš„æ¨ç†æ–‡æœ¬ï¼Œæ˜¾è‘—å¢åŠ æ¨ç†æˆæœ¬ã€‚
- **æ¨ç†æ¼‚ç§»ï¼ˆReasoning Driftï¼‰**ï¼šæ¨¡å‹å¯èƒ½åç¦»ä¸»é¢˜ã€é‡å¤æˆ–äº§ç”Ÿé€»è¾‘é”™è¯¯ã€‚
- **æˆæœ¬æ•ˆç‡ç“¶é¢ˆ**ï¼šå°¤å…¶å¯¹ç”Ÿäº§çº§è‡ªä¸»ä»£ç†ç³»ç»Ÿè€Œè¨€ï¼Œé«˜æ˜‚çš„æ¨ç†æˆæœ¬é™åˆ¶äº†è§„æ¨¡åŒ–éƒ¨ç½²ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šBRAID æ¡†æ¶
æå‡º **BRAID**ï¼ˆ**Bounded Reasoning for Autonomous Inference and Decisions**ï¼‰ï¼Œä¸€ç§åŸºäºç»“æ„åŒ–ç¬¦å·è¡¨ç¤ºçš„æ–°å‹æç¤ºæ¡†æ¶ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- å°†ä¼ ç»Ÿçš„è‡ªç„¶è¯­è¨€æ¨ç†é“¾ï¼ˆCoTï¼‰æ›¿æ¢ä¸º **Mermaid å›¾è¡¨** ç¼–ç çš„**æœ‰ç•Œæ¨ç†è·¯å¾„**ã€‚
- æ¨ç†è¿‡ç¨‹è¢«çº¦æŸä¸ºç¡®å®šæ€§çš„ã€æœºå™¨å¯è¯»çš„æµç¨‹å›¾ï¼ˆå¦‚ `flowchart TD`ï¼‰ï¼Œè€Œéè‡ªç”±æ–‡æœ¬æ‰©å±•ã€‚
- åˆ†ç¦»â€œæ¨ç†ç”Ÿæˆâ€ï¼ˆGenerationï¼‰ä¸â€œæ‰§è¡Œæ±‚è§£â€ï¼ˆSolvingï¼‰ä¸¤ä¸ªé˜¶æ®µï¼Œå®ç°æ¨ç†æ‹“æ‰‘ä¸è®¡ç®—æ‰§è¡Œçš„è§£è€¦ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ CoTï¼‰ | BRAID |
|------|------------------|--------|
| **æ¨ç†ç»“æ„** | è‡ªç”±æ–‡æœ¬ï¼Œæ˜“å‡ºç°æ¼‚ç§» | ç»“æ„åŒ– Mermaid å›¾ï¼Œé€»è¾‘ç¡®å®š |
| **Token æ•ˆç‡** | é«˜å¼€é”€ï¼Œä½å¯†åº¦ | æé«˜ token å¯†åº¦ï¼Œå‹ç¼©è®¤çŸ¥è¿‡ç¨‹ |
| **æˆæœ¬æ§åˆ¶** | å•æ¬¡è°ƒç”¨æˆæœ¬é«˜ | å¯ç¼“å­˜æ¨ç†å›¾ï¼Œæ‘Šè–„æˆæœ¬ |
| **å°æ¨¡å‹è¡¨ç°** | è¡¨ç°å·® | å°æ¨¡å‹å¯æ‰§è¡Œé«˜è´¨é‡æ¨ç† |
| **ç»æµæ€§** | æˆæœ¬éšæ¨¡å‹å¢å¤§çº¿æ€§ä¸Šå‡ | å®ç°â€œå¤§æ¨¡å‹ç”Ÿæˆ + å°æ¨¡å‹æ‰§è¡Œâ€çš„é»„é‡‘ç»„åˆ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
å®éªŒåœ¨ä¸‰ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†ä¸Šè¿›è¡Œï¼š
- **GSM-Hard**ï¼šæ¥è‡ª PaLM-r çš„æ•°å­¦éš¾é¢˜ï¼Œæµ‹è¯•ç®—æœ¯ä¸é€»è¾‘æ¨ç†èƒ½åŠ›ã€‚
- **SCALE MultiChallenge**ï¼šå¤šè½®å¤æ‚å¯¹è¯ä»»åŠ¡ï¼Œæ¶‰åŠå¤šæ­¥æ¨ç†ã€çº¦æŸæ»¡è¶³ç­‰ã€‚
- **AdvancedIF**ï¼šåŸºäºè¯„åˆ†æ ‡å‡†çš„æŒ‡ä»¤éµå¾ªä»»åŠ¡ï¼Œå¼ºè°ƒæ ¼å¼ã€é£æ ¼ä¸åˆè§„æ€§ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
é‡‡ç”¨ä¸¤é˜¶æ®µåè®®ï¼š
1. **Prompt Generation**ï¼šä¸€ä¸ªæ¨¡å‹ï¼ˆGeneratorï¼‰ç”Ÿæˆ Mermaid æ¨ç†å›¾ã€‚
2. **Prompt Solving**ï¼šå¦ä¸€ä¸ªæ¨¡å‹ï¼ˆSolverï¼‰ä»¥è¯¥å›¾ä¸ºç³»ç»Ÿæç¤ºï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚

æ”¯æŒå¤šç§æ¨¡å‹ç»„åˆï¼ˆå¦‚ `gpt-5-medium â†’ gpt-5-nano-minimal`ï¼‰ï¼Œå½¢æˆå®Œæ•´çš„â€œç”Ÿæˆ-æ±‚è§£â€çŸ©é˜µã€‚

#### æ•°å€¼æ©ç åè®®ï¼ˆNumerical Maskingï¼‰
ä¸ºé˜²æ­¢ç­”æ¡ˆæ³„éœ²ï¼Œåœ¨æ•°å­¦ä»»åŠ¡ä¸­å°† Mermaid å›¾ä¸­çš„æ•°å€¼å­—é¢é‡æ›¿æ¢ä¸ºå ä½ç¬¦ï¼ˆå¦‚ `<NUM>`ï¼‰ï¼Œç¡®ä¿ Solver å¿…é¡»é‡æ–°è®¡ç®—ã€‚

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
- **Accuracy (%)**ï¼šæ­£ç¡®ç‡ã€‚
- **Cost (USD)**ï¼šæŒ‰è¾“å…¥/è¾“å‡º token è®¡è´¹è®¡ç®—æ€»æˆæœ¬ã€‚
- **Performance-per-Dollar (PPD)**ï¼š  
  $$
  \text{PPD} = \frac{\text{Accuracy}}{\text{Cost}} \div \frac{\text{Accuracy}_{\text{gpt-5-medium}}}{\text{Cost}_{\text{gpt-5-medium}}}
  $$  
  ä»¥ `gpt-5-medium` ç»å…¸æç¤ºä¸ºåŸºå‡†ï¼ˆPPD = 1.0ï¼‰ï¼Œè¡¡é‡æ€§ä»·æ¯”æå‡ã€‚

### ğŸ†š åŸºçº¿æ–¹æ³•
- **Classic Prompting**ï¼šé›¶æ ·æœ¬æç¤ºï¼Œæ— æ˜¾å¼æ¨ç†å¼•å¯¼ã€‚
- **Zero-Shot CoT**ï¼šæ·»åŠ  `"Let's think step by step"` è§¦å‘æ¨ç†ã€‚
- **Few-Shot CoT**ï¼šæä¾›å°‘é‡å¸¦æ¨ç†æ­¥éª¤çš„ç¤ºä¾‹ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å‡†ç¡®ç‡æå‡ï¼ˆAccuracyï¼‰
- **GSM-Hard**ï¼šå³ä½¿å·²æœ‰é«˜åŸºçº¿ï¼ˆ>90%ï¼‰ï¼ŒBRAID ä»è¿›ä¸€æ­¥æå‡è‡³æ¥è¿‘å®Œç¾ï¼š
  - `gpt-5-nano-minimal`ï¼šä» 94.0% â†’ **98.0%**
  - `gpt-5-medium`ï¼šä» 95.0% â†’ **99.0%**
- **SCALE MultiChallenge**ï¼šæå‡æœ€ä¸ºæ˜¾è‘—ï¼š
  - `gpt-4o`ï¼šä» 19.9% â†’ **53.7%**ï¼ˆ+33.8 ppï¼‰
  - `gpt-5-nano-minimal`ï¼šä» 23.9% â†’ **45.2%**ï¼Œè¶…è¶Šæ›´å¤§æ¨¡å‹çš„ç»å…¸è¡¨ç°
- **AdvancedIF**ï¼š
  - `gpt-5-nano-minimal`ï¼šä» 18.0% â†’ **40.0%**ï¼ˆç¿»å€ä»¥ä¸Šï¼‰

> âœ… **BRAID Parity Effect**ï¼šå°æ¨¡å‹ + BRAID å¯åŒ¹æ•Œç”šè‡³è¶…è¶Šå¤§æ¨¡å‹ + ç»å…¸æç¤ºçš„è¡¨ç°ã€‚

### ğŸ’° æˆæœ¬ä¸æ•ˆç‡åˆ†æï¼ˆPPDï¼‰
#### æœ€ä½³é…ç½®ï¼š**é«˜æ™ºèƒ½ç”Ÿæˆå™¨ + ä½æˆæœ¬æ‰§è¡Œå™¨**
- åœ¨ **GSM-Hard** ä¸Šï¼š
  - `gpt-4.1 â†’ gpt-5-nano-minimal`ï¼š**PPD = 74.06**
  - æ„å‘³ç€ç›¸æ¯” `gpt-5-medium` å•ä½“éƒ¨ç½²ï¼Œ**æˆæœ¬æ•ˆç›Šæå‡è¶…è¿‡ 74 å€**ï¼Œä¸”å‡†ç¡®ç‡æ›´é«˜ï¼ˆ96% vs 95%ï¼‰ã€‚
- åœ¨ **SCALE MultiChallenge** ä¸Šï¼š
  - `gpt-5-medium â†’ gpt-5-nano-medium`ï¼š**PPD = 30.31**
- åœ¨ **AdvancedIF** ä¸Šï¼š
  - `gpt-5-medium â†’ gpt-5-nano-minimal`ï¼š**PPD = 61.69**

> ğŸ’¡ **å…³é”®å‘ç°**ï¼šæ¨ç†ç»“æ„çš„è´¨é‡è¿œæ¯”æ‰§è¡Œæ¨¡å‹çš„è§„æ¨¡é‡è¦ï¼›é«˜è´¨é‡çš„ Mermaid å›¾å¯è®© nano çº§æ¨¡å‹é«˜æ•ˆæ‰§è¡Œå¤æ‚ä»»åŠ¡ã€‚

### ğŸ” æ¶ˆèå®éªŒä¸æœºåˆ¶åˆ†æ
- **Mermaid å›¾è´¨é‡è‡³å…³é‡è¦**ï¼šèŠ‚ç‚¹éœ€æ»¡è¶³ï¼š
  1. **åŸå­æ€§**ï¼ˆAtomicityï¼‰ï¼šæ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨å•ä¸€æ¨ç†æ­¥éª¤ï¼ˆ<15 tokens æœ€ä¼˜ï¼‰ã€‚
  2. **ç¡®å®šæ€§åˆ†æ”¯**ï¼ˆDeterministic Branchingï¼‰ï¼šè¾¹åº”å¸¦æ¡ä»¶æ ‡ç­¾ï¼ˆå¦‚ `-- "if >300 words" -->`ï¼‰ã€‚
  3. **é˜²æ³„æ¼è®¾è®¡**ï¼šä»…ç¼–ç ç»“æ„ä¸çº¦æŸï¼Œä¸åŒ…å«å…·ä½“å“åº”æ–‡æœ¬ã€‚
  4. **ç»ˆç«¯éªŒè¯ç¯è·¯**ï¼ˆVerification Loopsï¼‰ï¼šåŠ å…¥æ£€æŸ¥èŠ‚ç‚¹ï¼ˆå¦‚è¯­æ°”ã€é•¿åº¦ã€åˆè§„æ€§ï¼‰ï¼Œæ¨¡æ‹Ÿ System 2 æ€ç»´ã€‚

- è‡ªåŠ¨ç”Ÿæˆ vs æ‰‹å·¥è®¾è®¡ï¼šè‡ªåŠ¨åŒ–ç”Ÿæˆçš„ Mermaid å›¾å·²è¶³å¤Ÿæœ‰æ•ˆï¼Œæ‰‹å·¥ä¼˜åŒ–è¾¹é™…æ”¶ç›Šæœ‰é™ï¼Œä½†è‡ªåŠ¨åŒ–å¤§å¹…é™ä½å·¥ç¨‹æˆæœ¬ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **ç»“æ„å†³å®šæ€§èƒ½**ï¼š  
   æ¨ç†æ€§èƒ½ä¸ä»…æ˜¯æ¨¡å‹å®¹é‡çš„å‡½æ•°ï¼Œæ›´æ˜¯ **Model Capacity Ã— Prompt Structure** çš„ä¹˜ç§¯ã€‚é€šè¿‡å¢å¼ºç»“æ„ï¼Œå¯ç”¨å°æ¨¡å‹å®ç°å¤§æ¨¡å‹çº§åˆ«çš„è¡¨ç°ã€‚

2. **BRAID å®ç°â€œæ¨ç†æ°‘ä¸»åŒ–â€**ï¼š  
   ä½¿ `nano` å’Œ `mini` çº§åˆ«æ¨¡å‹èƒ½å¤Ÿå®ŒæˆåŸæœ¬éœ€è¦é«˜ç«¯æ¨¡å‹æ‰èƒ½èƒœä»»çš„å¤æ‚æ¨ç†ä»»åŠ¡ã€‚

3. **ç»æµèŒƒå¼è½¬å˜**ï¼š  
   æå‡ºâ€œ**Split Architecture**â€èŒƒå¼â€”â€”**å¤§æ¨¡å‹ä¸€æ¬¡æ€§ç”Ÿæˆ Mermaid å›¾ï¼ˆå¯ç¼“å­˜ï¼‰ï¼Œå°æ¨¡å‹åå¤æ‰§è¡Œ**ï¼Œé€‚ç”¨äºé•¿æœŸè¿è¡Œçš„ autonomous agentã€‚

4. **PPD æ˜¯è¡¡é‡ LLM æ•ˆç‡çš„å…³é”®æŒ‡æ ‡**ï¼š  
   å•çº¯è¿½æ±‚ accuracy æˆ–é™ä½æˆæœ¬éƒ½ä¸å…¨é¢ï¼ŒPPD æä¾›äº†ç»Ÿä¸€çš„æ€§ä»·æ¯”è¯„ä¼°æ¡†æ¶ã€‚

5. **éè®°å¿†åŒ–æ¨ç†è¯æ®**ï¼š  
   åœ¨ **SCALE MultiChallenge** å’Œ **AdvancedIF** è¿™ç±»â€œæœªè§è¿‡â€çš„æ–°åŸºå‡†ä¸Šä»å–å¾—é«˜åˆ†ï¼Œè¯æ˜ BRAID æ¿€å‘çš„æ˜¯**æ–°é¢–æ¨ç†è·¯å¾„**ï¼Œè€Œéä¾èµ–è®­ç»ƒæ•°æ®çš„è®°å¿†ã€‚

### âš ï¸ å±€é™æ€§
- å½“å‰ Mermaid å›¾ç”±é€šç”¨ LLM ç”Ÿæˆï¼Œå¯èƒ½å­˜åœ¨ç»“æ„ç¼ºé™·ã€‚
- åŠ¨æ€ç¯å¢ƒä¸‹çš„è‡ªé€‚åº”é‡è§„åˆ’èƒ½åŠ›å°šæœªå®ç°ï¼ˆå½“å‰å›¾ä¸ºé™æ€ï¼‰ã€‚
- å¯¹è§†è§‰è¾“å…¥çš„æ”¯æŒæœ‰é™ï¼Œç›®å‰ä»…å¤„ç†æ–‡æœ¬ç”Ÿæˆçš„ Mermaid ä»£ç ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **ä¸“ç”¨â€œArchitectâ€æ¨¡å‹**ï¼šå¾®è°ƒå°å‹ä¸“ç”¨æ¨¡å‹ä¸“é—¨ç”¨äºç”Ÿæˆé«˜è´¨é‡ Mermaid å›¾ï¼Œé™ä½ç”Ÿæˆæˆæœ¬ã€‚
2. **åŠ¨æ€é‡è§„åˆ’æœºåˆ¶**ï¼šå…è®¸ Solver åœ¨é‡åˆ°â€œæ‹“æ‰‘é”™è¯¯â€æ—¶è¯·æ±‚å±€éƒ¨é‡æ„å›¾ã€‚
3. **è§†è§‰å›¾è¾“å…¥**ï¼šæ¢ç´¢å°†æ¸²æŸ“åçš„ Mermaid å›¾åƒç›´æ¥è¾“å…¥ VLMï¼ˆVision Language Modelï¼‰ï¼Œåˆ©ç”¨ç©ºé—´æ„ŸçŸ¥èƒ½åŠ›ã€‚
4. **å·¥ä¸šåœºæ™¯é›†æˆ**ï¼šå·²åœ¨ Neol.ai ç­‰ä¼ä¸šæµ‹è¯•ï¼Œæœªæ¥å°†è¿›ä¸€æ­¥ä¼˜åŒ–åœ¨çœŸå®ä¸šåŠ¡æµä¸­çš„éƒ¨ç½²æ•ˆç‡ã€‚

---

## âœ… æ€»ç»“
**BRAID** ä¸ä»…ä»…æ˜¯ä¸€ç§æç¤ºå·¥ç¨‹æŠ€å·§ï¼Œè€Œæ˜¯ä¸€ç§**å¯æ‰©å±•ã€å¯é‡åŒ–ã€é«˜ç»æµæ•ˆç›Šçš„è‡ªä¸»æ¨ç†æ¶æ„**ã€‚å®ƒé€šè¿‡å°†æ¨ç†è¿‡ç¨‹ä»â€œè¯­è¨€ç‹¬ç™½â€è½¬å˜ä¸ºâ€œç¬¦å·è“å›¾â€ï¼Œä»æ ¹æœ¬ä¸Šæ”¹å˜äº† LLM çš„ä½¿ç”¨ç»æµå­¦ï¼Œä¸ºä½æˆæœ¬ã€é«˜æ€§èƒ½çš„ autonomous agent éƒ¨ç½²æä¾›äº†åšå®çš„æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 8. [Bridging Data and Physics: A Graph Neural Network-Based Hybrid Twin Framework](https://arxiv.org/abs/2512.15767)

**Authors**: M. Gorpinich (Valeo, PIMM Lab. ENSAM Institute of Technology), B. Moya (PIMM Lab. ENSAM Institute of Technology), S. Rodriguez (PIMM Lab. ENSAM Institute of Technology), F. Meraghni (PIMM Lab. ENSAM Institute of Technology), Y. Jaafra (Valeo), A. Briot (Valeo), M. Henner (Valeo), R. Leon (Valeo), F. Chinesta (PIMM Lab. ENSAM Institute of Technology, CNRS@CREATE LTD. Singapore)  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2512.15767v1  

#### Abstract
Simulating complex unsteady physical phenomena relies on detailed mathematical models, simulated for instance by using the Finite Element Method (FEM). However, these models often exhibit discrepancies from the reality due to unmodeled effects or simplifying assumptions. We refer to this gap as the ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Bridging Data and Physics: A Graph Neural Network-Based Hybrid Twin Framework è®ºæ–‡æ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ä¼ ç»ŸåŸºäºç‰©ç†çš„æ¨¡å‹ï¼ˆå¦‚ FEMï¼‰åœ¨æ¨¡æ‹Ÿå¤æ‚éç¨³æ€ç‰©ç†ç°è±¡æ—¶ï¼Œå¸¸å› æœªå»ºæ¨¡æ•ˆåº”æˆ–ç®€åŒ–å‡è®¾è€Œä¸çœŸå®æƒ…å†µå­˜åœ¨åå·®ï¼Œè¿™ç§å·®è·è¢«ç§°ä¸ºâ€œ**ignorance model**â€ã€‚çº¯æ•°æ®é©±åŠ¨æ–¹æ³•éœ€è¦å¤§é‡é«˜è´¨é‡ã€æ—¶ç©ºå¯†é›†çš„æ•°æ®ï¼Œä½†åœ¨å®é™…å·¥ä¸šåœºæ™¯ä¸­ï¼Œæµ‹é‡é€šå¸¸ä»…é™äºç¨€ç–ç©ºé—´ç‚¹ï¼Œå¯¼è‡´å…¨æ•°æ®é©±åŠ¨å»ºæ¨¡ä¸å¯é ã€‚

### æå‡ºçš„æ–°æ–¹æ³•/æ–°æ€è·¯
æœ¬æ–‡æå‡ºä¸€ç§åŸºäº **Graph Neural Networks (GNNs)** çš„ **Hybrid Twin** æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- ä¸ä»é›¶å­¦ä¹ æ•´ä¸ªç³»ç»Ÿè¡Œä¸ºï¼Œè€Œæ˜¯ä¸“æ³¨äºå»ºæ¨¡ **ç‰©ç†æ¨¡å‹ä¸çœŸå®ä¹‹é—´çš„è¯¯å·®ï¼ˆå³ ignorance modelï¼‰**ã€‚
- åˆ©ç”¨ GNN å¯¹å‡ ä½•ç»“æ„çš„å¤©ç„¶é€‚åº”èƒ½åŠ›ï¼Œåœ¨ç¨€ç–æµ‹é‡æ¡ä»¶ä¸‹å­¦ä¹ ç¼ºå¤±ç‰©ç†æœºåˆ¶çš„ç©ºé—´ä¿®æ­£æ¨¡å¼ã€‚
- å°† FEM æ¨¡æ‹Ÿç»“æœä½œä¸ºè¾“å…¥ï¼Œç”± GNN é¢„æµ‹å…¶ä¸â€œçœŸå®â€ï¼ˆéçº¿æ€§çƒ­ä¼ å¯¼ï¼‰ä¹‹é—´çš„æ¸©åº¦å·®å€¼ï¼Œå¹¶å åŠ å›åŸæ¨¡å‹ä»¥å®ç°æ ¡æ­£ã€‚

è¯¥æ¡†æ¶ç»“åˆäº†ï¼š
- **Physics-based model**ï¼ˆFEM çº¿æ€§çƒ­ä¼ å¯¼ï¼‰
- **Data-driven model**ï¼ˆGNN å­¦ä¹  ignoranceï¼‰

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **æ•°æ®æ•ˆç‡** | ä»…éœ€å°‘é‡è®­ç»ƒæ ·æœ¬ï¼ˆå¦‚ 10% æ—¶é—´å¸§ï¼‰å³å¯æœ‰æ•ˆå­¦ä¹  ignoranceï¼Œæ˜¾è‘—é™ä½å¯¹å¯†é›†æ•°æ®çš„éœ€æ±‚ |
| **æ³›åŒ–èƒ½åŠ›** | èƒ½å¤Ÿè·¨ä¸åŒç½‘æ ¼ï¼ˆregular/irregular/submeshï¼‰ã€åŸŸå½¢çŠ¶ï¼ˆçŸ©å½¢/L-shapedï¼‰ã€è½½è·ä½ç½®è¿›è¡Œæ³›åŒ– |
| **é²æ£’æ€§** | åœ¨ç¨€ç–ä¼ æ„Ÿå™¨é…ç½®ä¸‹ä»èƒ½å‡†ç¡®æ¨æ–­å…¨å±€ä¿®æ­£åœº |
| **å¯è§£é‡Šæ€§å¢å¼º** | é€šè¿‡åˆ†ç¦»ç‰©ç†æ¨¡å‹ä¸æ•°æ®é©±åŠ¨ä¿®æ­£éƒ¨åˆ†ï¼Œæå‡æ¨¡å‹é€æ˜åº¦ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
æ‰€æœ‰æ•°æ®å‡ä¸ºåˆæˆç”Ÿæˆï¼Œç”¨äºæ¨¡æ‹Ÿçº¿æ€§ vs éçº¿æ€§çƒ­ä¼ å¯¼ç³»ç»Ÿçš„å·®å¼‚ï¼š

| æ•°æ®é›† | æè¿° |
|--------|------|
| **A1â€“A8** | çŸ©å½¢é‡‘å±æ¿ä¸Šçš„çº¿æ€§çƒ­æºï¼Œä¸åŒè¾¹ç•Œæ¡ä»¶ã€è´Ÿè½½ä½ç½®ã€ç½‘æ ¼ç±»å‹ï¼ˆè§„åˆ™/ä¸è§„åˆ™/å­ç½‘ï¼‰ |
| **B1** | é«˜æ–¯åˆ†å¸ƒçƒ­æºï¼Œä¸­å¿ƒä½ç½®å˜åŒ–ï¼Œæµ‹è¯•è½½è·ä½ç½®æ³›åŒ– |
| **B2** | L-shaped åŸŸï¼Œå‚æ•°åŒ–å‡ ä½•å½¢çŠ¶ï¼ˆa, bï¼‰ï¼Œæµ‹è¯•å‡ ä½•ä¸ç½‘æ ¼åŒé‡æ³›åŒ– |

> æ‰€æœ‰éçº¿æ€§â€œground truthâ€ç”±è€ƒè™‘æ¸©åº¦ä¾èµ–å¯¼çƒ­ç³»æ•° $ k(T) $ çš„ FEM æ¨¡æ‹Ÿç”Ÿæˆï¼›çº¿æ€§è¿‘ä¼¼ä½¿ç”¨å¸¸æ•° $ k $ã€‚

### å®éªŒè®¾ç½®
- **ä»»åŠ¡**ï¼šGNN å­¦ä¹ ä»çº¿æ€§ FEM è¾“å‡ºåˆ°éçº¿æ€§ GT çš„æ®‹å·®ï¼ˆ$ \Delta T = T_{\text{GT}} - T_{\text{FEM}} $ï¼‰
- **è¾“å…¥ç‰¹å¾**ï¼š
  - èŠ‚ç‚¹ï¼šæ¸©åº¦ $ T_{\text{FEM}} $ã€èŠ‚ç‚¹ç±»å‹ one-hot ç¼–ç ï¼ˆå†…éƒ¨ã€è¾¹ç•Œã€çƒ­æºç­‰ï¼‰
  - è¾¹ï¼šèŠ‚ç‚¹åæ ‡å·®åŠè·ç¦»å¹³æ–¹
- **ç½‘ç»œæ¶æ„**ï¼šEncoder-Processor-Decoder ç»“æ„çš„ GNNï¼Œå« 10 å±‚ message passing
- **è®­ç»ƒç­–ç•¥**ï¼šAdam ä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ $ 10^{-3} $ï¼Œbatch size=13ï¼Œæ¢¯åº¦è£å‰ª

### è¯„ä¼°æŒ‡æ ‡
- **MAE**ï¼ˆMean Absolute Errorï¼‰:  
  $$
  \text{MAE} = \frac{1}{n}\sum_{i=1}^n |T^{\text{CT}}_i - T^{\text{GT}}_i|
  $$
- **MAPE**ï¼ˆMean Absolute Percentage Errorï¼‰:  
  $$
  \text{MAPE} = \frac{100\%}{n}\sum_{i=1}^n \frac{|T^{\text{CT}}_i - T^{\text{GT}}_i|}{T^{\text{GT}}_i}
  $$
- **RMSE** ä¹Ÿç”¨äºéƒ¨åˆ†åˆ†æ
- æ¯ä¸ªå®éªŒè¿è¡Œ 3 æ¬¡å–å¹³å‡ï¼ŒæŠ¥å‘Šå‡å€¼ Â± æ ‡å‡†å·®

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **Baseline**: **MeshGraphNet (MGN)** [40]ï¼Œä¸€ç§è‡ªå›å½’ GNNï¼Œç›´æ¥ä»å¤´å­¦ä¹ åŠ¨åŠ›å­¦æ¼”åŒ–
  - è¾“å…¥ï¼šå½“å‰æ—¶åˆ»æ¸©åº¦åœº
  - è¾“å‡ºï¼šä¸‹ä¸€æ—¶åˆ»æ¸©åº¦å¢é‡
  - ä½¿ç”¨ **Noise Injection (NI)** æŠ‘åˆ¶ rollout è¿‡ç¨‹ä¸­çš„è¯¯å·®ç´¯ç§¯

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®æ±‡æ€»ï¼ˆè§ Table 2, 3, 4, 6ï¼‰

#### âœ… ä½æ•°æ®é‡è®­ç»ƒï¼ˆä»… 10% å¸§ï¼‰
| Model | Dataset | MAE (K) | MAPE (%) |
|-------|---------|--------|----------|
| **Hybrid Twin** | A1 (10%) | $(4.86 \pm 0.68)\times10^{-2}$ | $(1.24 \pm 0.23)\times10^{-2}$ |
| MGN+NI | A1 (10%) | $19.19 \pm 31.63$ | $4.64 \pm 7.66$ |
| **Hybrid Twin** | A2 (10%) | $(10.34 \pm 0.76)\times10^{-2}$ | $(22.93 \pm 0.86)\times10^{-5}$ |
| MGN+NI | A2 (10%) | $1.01 \pm 0.15$ | $0.20 \pm 0.02$ |

> â†’ Hybrid Twin çš„ MAE æ¯” MGN ä½ **ä¸¤ä¸ªæ•°é‡çº§ä»¥ä¸Š**

#### âœ… ç½‘æ ¼æ³›åŒ–ï¼ˆè®­ç»ƒäº regular meshï¼Œæµ‹è¯•äº irregular meshï¼‰
| Model | Dataset | MAE (K) | MAPE (%) |
|-------|---------|--------|----------|
| Hybrid Twin | A3 | $(72.37 \pm 0.80)\times10^{-2}$ | $(15.16 \pm 0.12)\times10^{-2}$ |
| Hybrid Twin | A4 | $7.31 \pm 1.25$ | $1.25 \pm 0.27$ |

> â†’ æˆåŠŸå°†åŸå§‹æœ€å¤§ç›¸å¯¹è¯¯å·®ä» 16% é™è‡³ 3%-7%

#### âœ… ç¨€ç–èŠ‚ç‚¹è®­ç»ƒï¼ˆsubmesh ä¸Šè®­ç»ƒï¼Œå®Œæ•´ mesh ä¸Šæ¨ç†ï¼‰
| Model | Dataset | MAE (K) | MAPE (%) |
|-------|---------|--------|----------|
| Hybrid Twin | A5 | $2.13 \pm 0.93$ | $0.37 \pm 0.19$ |
| Hybrid Twin | A6 | $15.90 \pm 1.06$ | $1.96 \pm 0.19$ |

> â†’ è¡¨æ˜å³ä½¿åªæœ‰å°‘æ•°ä¼ æ„Ÿå™¨æ•°æ®ä¹Ÿå¯æ„å»ºæœ‰æ•ˆ ignorance model

#### âœ… è½½è·ä½ç½®ä¸åŸŸå½¢çŠ¶æ³›åŒ–
| Model | Dataset | MAE (K) | MAPE (%) |
|-------|---------|--------|----------|
| Hybrid Twin | B1 (é«˜æ–¯çƒ­æº) | $0.59 \pm 0.05$ | $0.12 \pm 0.01$ |
| Hybrid Twin | B2 (L-shaped) | $9.62 \pm 1.54$ | $0.99 \pm 0.15$ |

> â†’ æ˜¾ç¤ºå‡ºå¯¹æœªçŸ¥è®¾è®¡é…ç½®çš„å¼ºå¤§å¤–æ¨èƒ½åŠ›

### ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ
- åœ¨æ‰€æœ‰æµ‹è¯•åœºæ™¯ä¸­ï¼Œ**Hybrid Twin æ€§èƒ½è¿œä¼˜äº MGN+NI**
- MGN å­˜åœ¨æ˜æ˜¾çš„ **rollout error accumulation**ï¼Œè€Œ Hybrid Twin å› ä¸ä¾èµ–è‡ªå›å½’é¢„æµ‹ï¼Œæ— æ­¤é—®é¢˜ï¼ˆè§ Fig. 13ï¼‰
- å³ä½¿åŠ å…¥ Noise Injectionï¼ŒMGN ä»ä¸ç¨³å®šï¼Œå°¤å…¶åœ¨å°æ•°æ®åœºæ™¯ä¸‹
- Hybrid Twin å¯¹ NI ä¸æ•æ„Ÿï¼Œè¯´æ˜å…¶å†…åœ¨ç¨³å®šæ€§æ›´é«˜

### æ¶ˆèå®éªŒç»“æœï¼ˆAppendix C.1ï¼‰
- **æ˜¯å¦ä½¿ç”¨ Noise Injection**ï¼š
  - Hybrid Twinï¼šåŠ  NI ä¸å¦æ€§èƒ½ç›¸è¿‘ â†’ **ä¸ä¾èµ– NI**
  - MGNï¼šæ—  NI æ—¶æ€§èƒ½æ€¥å‰§ä¸‹é™ â†’ **ä¸¥é‡ä¾èµ– NI æŠ‘åˆ¶è¯¯å·®ä¼ æ’­**
- ç»“è®ºï¼šæ‰€ææ–¹æ³•æ›´ç¨³å®šï¼Œæ›´é€‚åˆé•¿æœŸä»¿çœŸä»»åŠ¡

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Ignorance Modeling æ˜¯é«˜æ•ˆè·¯å¾„**ï¼šç›¸æ¯”äºä»å¤´å­¦ä¹ æ•´ä¸ªç‰©ç†è¿‡ç¨‹ï¼Œåªå­¦ä¹ ç‰©ç†æ¨¡å‹çš„æ®‹å·®ï¼ˆignoranceï¼‰æ‰€éœ€æ•°æ®å°‘å¾—å¤šï¼Œä¸”æ›´å®¹æ˜“æ³›åŒ–ã€‚
2. **GNN å¤©ç„¶é€‚åˆ Hybrid Twin æ¶æ„**ï¼šèƒ½å¤Ÿå¤„ç†ä»»æ„æ‹“æ‰‘ç½‘æ ¼ï¼Œæ•æ‰å±€éƒ¨ä¸å…¨å±€å…³ç³»ï¼Œé€‚ç”¨äºå·¥ä¸šçº§å¤æ‚å‡ ä½•ã€‚
3. **å¼ºæ³›åŒ–èƒ½åŠ›**ï¼šæ¨¡å‹å¯åœ¨æœªè§è¿‡çš„ï¼š
   - ç½‘æ ¼åˆ’åˆ†æ–¹å¼ï¼ˆregular â†” irregularï¼‰
   - å‡ ä½•å½¢çŠ¶ï¼ˆrectangle â†” L-shapeï¼‰
   - è½½è·åˆ†å¸ƒï¼ˆfixed â†” Gaussianï¼‰
   ä¸‹ä¿æŒè‰¯å¥½ç²¾åº¦
4. **é«˜æ•°æ®æ•ˆç‡**ï¼šä»…ç”¨ 10% æ—¶é—´å¸§è®­ç»ƒå³å¯è¾¾åˆ°æé«˜ç²¾åº¦ï¼ˆMAE < 0.1Kï¼‰
5. **å·¥ç¨‹å®ç”¨æ€§é«˜**ï¼šé€‚ç”¨äºä¼ æ„Ÿå™¨ç¨€ç–çš„çœŸå®åœºæ™¯ï¼Œå¯ç”¨äºå®æ—¶æ•°å­—å­ªç”Ÿç³»ç»Ÿæ›´æ–°

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰éªŒè¯åŸºäº**åˆæˆæ•°æ®**ï¼Œå°šæœªåœ¨çœŸå®å®éªŒæ•°æ®ä¸Šæµ‹è¯•
- è™½ç„¶èƒ½æ³›åŒ–åˆ°æ–°å‡ ä½•ï¼Œä½†æç«¯å˜å½¢å¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™ï¼ˆå¦‚ B2 ä¸­ a=0.4, b=1.2 æ—¶è¯¯å·®è¾¾ 20%ï¼‰
- å½“å‰æ¨¡å‹ä¸ºé™æ€å›¾ç»“æ„ï¼Œæœªæ˜¾å¼å»ºæ¨¡æ—¶é—´åŠ¨æ€ï¼ˆå¯é€šè¿‡å¼•å…¥ Temporal Attention æ”¹è¿›ï¼‰

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³å…¶ä»–ç‰©ç†é—®é¢˜**ï¼šå¦‚æµä½“åŠ›å­¦ã€ç»“æ„åŠ›å­¦ã€ç”µç£åœºç­‰
2. **å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶**ï¼š
   - Node/Edge Attentionï¼šæ•è·é•¿ç¨‹ä¾èµ–ä¸å±€éƒ¨å‡ ä½•ç‰¹æ€§
   - Temporal Attentionï¼šç¼“è§£é•¿æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„è¯¯å·®ç§¯ç´¯
3. **é›†æˆçœŸå®æµ‹é‡æ•°æ®**ï¼šåœ¨çœŸå®å·¥ä¸šè®¾å¤‡ä¸Šéƒ¨ç½²å¹¶éªŒè¯
4. **ä¸ç¡®å®šæ€§é‡åŒ–**ï¼šç»“åˆ conformal prediction æˆ–è´å¶æ–¯ç¥ç»ç½‘ç»œä¼°è®¡é¢„æµ‹ç½®ä¿¡åŒºé—´
5. **åœ¨çº¿å­¦ä¹ ä¸è‡ªé€‚åº”æ›´æ–°**ï¼šå®ç°çœŸæ­£çš„â€œè‡ªæˆ‘ä¿®æ­£æ•°å­—å­ªç”Ÿâ€

---

> **æ€»ç»“**ï¼šæœ¬æ–‡æå‡ºçš„ **GNN-based Hybrid Twin** æ¡†æ¶æˆåŠŸå®ç°äº†ç‰©ç†æ¨¡å‹ä¸æ•°æ®é©±åŠ¨æ¨¡å‹çš„æœ‰æ•ˆèåˆï¼Œåœ¨æä½æ•°æ®éœ€æ±‚ä¸‹å®ç°äº†é«˜ç²¾åº¦ã€å¼ºæ³›åŒ–çš„ç‰©ç†åœºä¿®æ­£ï¼Œä¸ºä¸‹ä¸€ä»£æ™ºèƒ½ä»¿çœŸä¸æ•°å­—å­ªç”Ÿæä¾›äº†å¯è¡Œçš„æŠ€æœ¯è·¯çº¿ã€‚

</details>

---

### 9. [LLMCache: Layer-Wise Caching Strategies for Accelerated Reuse in Transformer Inference](https://arxiv.org/abs/2512.16843)

**Authors**: Harsh Vardhan Bansal  
**Category**: cs.CL  
**Published**: 2025-12-19  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.16843v1  

#### Abstract
Transformer-based language models have achieved remarkable performance across a wide range of tasks, yet their high inference latency poses a significant challenge for real-timeand large-scale deployment. While existing caching mechanisms,such as token-level key-value caches, offer speedups in autor...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šLLMCache: Layer-Wise Caching Strategies for Accelerated Reuse in Transformer Inference

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
Transformer æ¨¡å‹åœ¨æ¨ç†é˜¶æ®µå­˜åœ¨**é«˜å»¶è¿Ÿ**é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†è¯­ä¹‰ç›¸ä¼¼æˆ–é‡å¤è¾“å…¥æ—¶ï¼ˆå¦‚å¯¹è¯ç³»ç»Ÿã€æ–‡æ¡£æ‘˜è¦ã€RAG åœºæ™¯ï¼‰ï¼Œä»æ‰§è¡Œå®Œæ•´çš„å‰å‘ä¼ æ’­ï¼Œé€ æˆå¤§é‡å†—ä½™è®¡ç®—ã€‚

ç°æœ‰æ–¹æ³•å¦‚ **Key-Value (KV) Caching** è™½èƒ½åŠ é€Ÿè‡ªå›å½’ç”Ÿæˆï¼Œä½†ä»…é€‚ç”¨äº decoder-only æ¶æ„ï¼Œä¸”å±€é™äº token-level çš„ç¼“å­˜ï¼Œæ— æ³•è·¨å±‚å¤ç”¨ä¸­é—´æ¿€æ´»å€¼ã€‚

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šLLMCache
LLMCache æ˜¯ä¸€ç§**æ¨¡å‹æ— å…³ã€æ¶æ„å…¼å®¹ã€å±‚ç²’åº¦**çš„ç¼“å­˜æ¡†æ¶ï¼Œé€šè¿‡é‡ç”¨è¯­ä¹‰ç›¸ä¼¼è¾“å…¥å¯¹åº”çš„ä¸­é—´å±‚æ¿€æ´»ï¼ˆhidden statesï¼‰æ¥åŠ é€Ÿ Transformer æ¨ç†ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
- **Layer-wise Activation Caching**  
  åœ¨æ¯ä¸€ Transformer å±‚ç»´æŠ¤ç‹¬ç«‹çš„ç¼“å­˜é“¶è¡Œï¼ˆcache bankï¼‰ï¼Œå­˜å‚¨è¾“å…¥æŒ‡çº¹ï¼ˆfingerprintï¼‰ä¸å¯¹åº”è¾“å‡ºæ¿€æ´»çš„æ˜ å°„å…³ç³»ã€‚
  
- **è¯­ä¹‰æŒ‡çº¹æœºåˆ¶ï¼ˆSemantic Fingerprintingï¼‰**  
  ä½¿ç”¨è½»é‡çº§ç¼–ç å™¨ï¼ˆå¦‚ MinHash/SimHash + Embedding Aggregationï¼‰ç”Ÿæˆå›ºå®šé•¿åº¦çš„è¾“å…¥æŒ‡çº¹ï¼Œæ”¯æŒå¿«é€Ÿç›¸ä¼¼æ€§åŒ¹é…ï¼ˆcosine similarity æˆ– Jaccard indexï¼‰ã€‚

- **æ¨¡å‹æ— å…³æ€§ä¸é€šç”¨æ€§**  
  æ”¯æŒ encoderï¼ˆå¦‚ BERTï¼‰ã€decoderï¼ˆå¦‚ GPT-2ï¼‰åŠ encoder-decoder æ¶æ„ï¼Œæ— éœ€ä¿®æ”¹æ¨¡å‹ç»“æ„æˆ–é‡æ–°è®­ç»ƒã€‚

- **åŠ¨æ€ç¼“å­˜ç®¡ç†ç­–ç•¥**  
  å¼•å…¥ LRUã€staleness-aware å’Œ divergence-aware ç­‰æ·˜æ±°ç­–ç•¥ï¼Œé˜²æ­¢ç¼“å­˜è¿‡æ—¶å¹¶æ§åˆ¶å†…å­˜å¢é•¿ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | æ¶æ„é™åˆ¶ | å¤ç”¨ç²’åº¦ | æ˜¯å¦éœ€é‡è®­ç»ƒ | é€‚ç”¨åœºæ™¯ |
|------|----------|-----------|----------------|------------|
| KV-Cache | ä»… decoder | Token-level | å¦ | è‡ªå›å½’ç”Ÿæˆ |
| DocCache | ç‰¹å®šä»»åŠ¡ | Document-level | æ˜¯ | å›ºå®šæ®µè½æ£€ç´¢ |
| **LLMCache (æœ¬æ–‡)** | **æ— ** | **Layer-wise** | **å¦** | **é€šç”¨ Transformer æ¨ç†** |

> âœ… LLMCache å®ç°äº†æ›´ç»†ç²’åº¦ã€æ›´é«˜è‡ªç”±åº¦çš„è®¡ç®—å¤ç”¨ï¼Œçªç ´äº†ä¼ ç»Ÿç¼“å­˜çš„æ¶æ„ä¸ä»»åŠ¡è¾¹ç•Œã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
- **WikiText-103**ï¼šè¯­è¨€å»ºæ¨¡ä»»åŠ¡ï¼Œè¯„ä¼°é•¿æ–‡æœ¬ç”Ÿæˆæ•ˆç‡
- **SQuAD v2**ï¼šé—®ç­”ä»»åŠ¡ï¼Œæµ‹è¯•ç†è§£èƒ½åŠ›ä¿æŒæ€§
- **OpenBookQA**ï¼šå¸¸è¯†æ¨ç†ä»»åŠ¡ï¼ŒéªŒè¯å¤æ‚è¯­ä¹‰ç¨³å®šæ€§

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼š
  - `BERT-base`
  - `DistilBERT`
  - `GPT-2-small`
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼šNVIDIA A100 GPUï¼Œbatch size = 1ï¼Œsequence length = 128
- **å®ç°æ–¹å¼**ï¼šåŸºäº PyTorch å®ç°æ¨¡å—åŒ– hookï¼Œæ’å…¥åˆ°æ¯å±‚ forward ä¸­

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Inference Latency (ms)** | å•æ¬¡æ¨ç†è€—æ—¶ |
| **Cache Hit Rate (%)** | ç¼“å­˜å‘½ä¸­ç‡éšå±‚æ•°å˜åŒ– |
| **Accuracy Drop (%)** | ç›¸å¯¹äºæ— ç¼“å­˜ç‰ˆæœ¬çš„ä»»åŠ¡å‡†ç¡®ç‡ä¸‹é™ |
| **Memory Overhead (MB)** | ç¼“å­˜å ç”¨å†…å­˜å¤§å° |
| **Speedup** | ç›¸å¯¹äº baseline çš„åŠ é€Ÿæ¯” |

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **NoCache**ï¼šæ ‡å‡† Transformer æ¨ç†æµç¨‹ï¼ˆæ— ä»»ä½•ç¼“å­˜ï¼‰
- **KV-Cache**ï¼šæ ‡å‡† token-level KV ç¼“å­˜ï¼ˆç”¨äº GPT ç±»æ¨¡å‹ï¼‰
- **DocCache**ï¼šæ–‡æ¡£çº§åµŒå…¥ç¼“å­˜æ–¹æ³•ï¼Œé¢„è®¡ç®—å¹¶å¤ç”¨æ•´ä¸ªè¾“å…¥è¡¨ç¤º

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

#### è¡¨ 1ï¼šå¹³å‡æ¨ç†å»¶è¿Ÿï¼ˆå•ä½ï¼šmsï¼‰

| Model         | NoCache  | KV-Cache | LLMCache (Ours) |
|---------------|----------|----------|------------------|
| BERT-base     | 218.6    | â€”        | **91.3**         |
| DistilBERT    | 123.4    | â€”        | **57.9**         |
| GPT-2-small   | 304.8    | 177.3    | **112.5**        |

> ğŸ’¡ **æœ€é«˜è¾¾ 3.1Ã— åŠ é€Ÿ**ï¼ˆä»¥ BERT è®¡ç®—ä¸ºåŸºå‡†çº¦ 2.4Ã—ï¼Œç»¼åˆæœ€ä¼˜å¯è¾¾ 3.1Ã—ï¼‰

#### è¡¨ 2ï¼šä»»åŠ¡å‡†ç¡®ç‡å¯¹æ¯”ï¼ˆ%ï¼‰ï¼Œç²¾åº¦æŸå¤± < 0.5%

| Dataset       | NoCache | DocCache | LLMCache (Ours) |
|---------------|---------|----------|------------------|
| WikiText-103  | 92.1    | 91.7     | **91.9**         |
| SQuAD v2      | 86.3    | 85.8     | **86.1**         |
| OpenBookQA    | 72.5    | 71.9     | **72.3**         |

> âœ… å‡ ä¹æ— ç²¾åº¦æŸå¤±ï¼ˆæœ€å¤§ä¸‹é™ä»… 0.2%ï¼‰ï¼Œæ˜¾è‘—ä¼˜äº DocCache

#### å›¾åˆ†æäº®ç‚¹ï¼š
- **å›¾ 3ï¼šGPT-2 å„å±‚ç¼“å­˜å‘½ä¸­ç‡**  
  - åº•å±‚å’Œä¸­å±‚å‘½ä¸­ç‡é«˜è¾¾ **92%**ï¼Œé«˜å±‚å› è¯­ä¹‰æ•æ„Ÿè€Œå‘½ä¸­ç‡ä¸‹é™
  - éªŒè¯äº†â€œä½å±‚ç‰¹å¾æ›´å…·é€šç”¨æ€§å’Œå¯å¤ç”¨æ€§â€çš„å‡è®¾

- **å›¾ 4ï¼šå†…å­˜å¼€é”€ vs ç¼“å­˜å‘½ä¸­ç‡ï¼ˆBERT-baseï¼‰**  
  - ç¼“å­˜å®¹é‡å¢åŠ å¸¦æ¥å¯¹æ•°å¢é•¿çš„å‘½ä¸­ç‡æå‡ï¼Œå…·å¤‡è‰¯å¥½æ‰©å±•æ€§
  - é«˜æ•ˆæŒ‡çº¹å‹ç¼©æœºåˆ¶æœ‰æ•ˆæ§åˆ¶å†…å­˜è†¨èƒ€

- **å›¾ 5ï¼šç›¸ä¼¼åº¦é˜ˆå€¼ Ï„ æ•æ„Ÿæ€§åˆ†æ**  
  - æœ€ä¼˜ Ï„ åœ¨ **0.82 ~ 0.88** ä¹‹é—´ï¼Œè¿‡é«˜å¯¼è‡´å‘½ä¸­ç‡ä¸‹é™ï¼Œè¿‡ä½å¼•å…¥å™ªå£°
  - å¯è°ƒå‚æ•°å…è®¸æ ¹æ®ä¸åŒåº”ç”¨åœºæ™¯æƒè¡¡é€Ÿåº¦ä¸å‡†ç¡®æ€§

### ğŸ” æ¶ˆèå®éªŒç»“æœ
- **ä¸åŒç¼“å­˜å±‚çº§é€‰æ‹©**ï¼šä»…ç¼“å­˜å‰ 6 å±‚å³å¯è·å¾— 80% ä»¥ä¸Šçš„æ”¶ç›Šï¼Œé€‚åˆèµ„æºå—é™åœºæ™¯
- **ä¸åŒæŒ‡çº¹ç”Ÿæˆæ–¹å¼**ï¼šSimHash + å¹³å‡åµŒå…¥è¡¨ç°æœ€ä½³ï¼Œå…¼é¡¾é€Ÿåº¦ä¸åŒºåˆ†åŠ›
- **ä¸åŒæ·˜æ±°ç­–ç•¥**ï¼šdivergence-aware æ¯” LRU æ›´èƒ½ç»´æŒé•¿æœŸæœ‰æ•ˆæ€§ï¼Œå°¤å…¶åœ¨è¾“å…¥æ¼‚ç§»åœºæ™¯ä¸‹

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Transformer ä¸­é—´å±‚æ¿€æ´»å…·æœ‰é«˜åº¦è¯­ä¹‰ç¨³å®šæ€§**ï¼Œå°¤å…¶åœ¨åº•å±‚å’Œä¸­å±‚ï¼Œé€‚åˆè·¨è¾“å…¥å¤ç”¨ã€‚
2. **LLMCache æ˜¾è‘—é™ä½æ¨ç†å»¶è¿Ÿ**ï¼ˆæœ€é«˜è¾¾ 3.1Ã—ï¼‰ï¼ŒåŒæ—¶ä¿æŒä»»åŠ¡å‡†ç¡®ç‡å‡ ä¹ä¸å˜ï¼ˆ<0.5% ä¸‹é™ï¼‰ã€‚
3. **ç¼“å­˜æ•ˆç›Šé›†ä¸­åœ¨ä½/ä¸­å±‚**ï¼Œé«˜å±‚æ›´é€‚åˆåŠ¨æ€è®¡ç®—ï¼Œå»ºè®®æŒ‰éœ€é…ç½®ç¼“å­˜èŒƒå›´ã€‚
4. **è¯­ä¹‰æŒ‡çº¹æœºåˆ¶é«˜æ•ˆå¯é **ï¼Œæ”¯æŒå¿«é€ŸåŒ¹é…ä¸”ä¸ä¾èµ–å¤–éƒ¨æ£€ç´¢ç³»ç»Ÿã€‚
5. **è¯¥æ–¹æ³•å¹¿æ³›é€‚ç”¨äºå¤šç§æ¶æ„**ï¼ˆencoder/decoderï¼‰ï¼Œæ˜¯çœŸæ­£æ„ä¹‰ä¸Šçš„é€šç”¨æ¨ç†ä¼˜åŒ–æ–¹æ¡ˆã€‚

### âš ï¸ å±€é™æ€§
- **å¯¹åˆ†å¸ƒå¤–è¾“å…¥æ•ˆæœæœ‰é™**ï¼šå½“è¾“å…¥å·®å¼‚å¤§æˆ–éšæœºæ€§å¼ºæ—¶ï¼Œç¼“å­˜å‘½ä¸­ç‡æ˜¾è‘—ä¸‹é™
- **GPU å†…å­˜å‹åŠ›**ï¼šæ·±å±‚æ¨¡å‹ï¼ˆå¦‚ GPT-3ï¼‰ç¼“å­˜è§„æ¨¡å¯èƒ½æˆä¸ºç“¶é¢ˆï¼Œéœ€ç²¾ç»†ç®¡ç†
- **å¾®è°ƒåè¡Œä¸ºä¸ç¨³å®š**ï¼šfine-tuned æ¨¡å‹å¯èƒ½å¯¼è‡´ç¼“å­˜å¿«é€Ÿå¤±æ•ˆï¼ˆrepresentation shiftï¼‰
- **å½“å‰ä¸ºå•èŠ‚ç‚¹è®¾è®¡**ï¼šæœªè€ƒè™‘åˆ†å¸ƒå¼æˆ–å¤šå®ä¾‹é—´çš„ç¼“å­˜å…±äº«

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
- **åŠ¨æ€é˜ˆå€¼è°ƒæ•´ï¼ˆDynamic Thresholdingï¼‰**ï¼šæ ¹æ®è¾“å…¥ä¸ç¡®å®šæ€§è‡ªåŠ¨è°ƒèŠ‚ç›¸ä¼¼åº¦é˜ˆå€¼ Ï„
- **åˆ†å¸ƒå¼ç¼“å­˜å…±äº«**ï¼šåœ¨å¤šèŠ‚ç‚¹ serving ç³»ç»Ÿä¸­å…±äº«å…¨å±€ fingerprint cache
- **å­¦ä¹ å‹æŒ‡çº¹ç”Ÿæˆå™¨ï¼ˆLearned Fingerprintsï¼‰**ï¼šç”¨å°å‹å¯è®­ç»ƒç½‘ç»œæ›¿ä»£æ‰‹å·¥å“ˆå¸Œå‡½æ•°ï¼Œæå‡åŒ¹é…è´¨é‡
- **ç»“åˆ RAG ä¸ç¼“å­˜ååŒä¼˜åŒ–**ï¼šå°†å¤–éƒ¨çŸ¥è¯†æ£€ç´¢ä¸å†…éƒ¨æ¿€æ´»å¤ç”¨è”åˆè°ƒåº¦

---

## æ€»ç»“
LLMCache æå‡ºäº†ä¸€ç§å…¨æ–°çš„ **layer-wise caching èŒƒå¼**ï¼Œä»â€œè¾“å…¥å¤ç”¨â€è§’åº¦åˆ‡å…¥ Transformer æ¨ç†ä¼˜åŒ–ï¼Œçªç ´äº†ä¼ ç»Ÿ KV-Cache çš„æ¶æ„é™åˆ¶ã€‚å…¶å®éªŒå……åˆ†éªŒè¯äº†è¯­ä¹‰æ¿€æ´»å¤ç”¨çš„å¯è¡Œæ€§ä¸é«˜æ•ˆæ€§ï¼Œåœ¨çœŸå®åº”ç”¨åœºæ™¯ï¼ˆå¦‚å¯¹è¯ã€æœç´¢ã€API æœåŠ¡é“¾ï¼‰ä¸­å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä¸ºå¤§è§„æ¨¡ LLM éƒ¨ç½²æä¾›äº†ä¸€ä¸ªå®ç”¨ã€çµæ´»ã€å³æ’å³ç”¨çš„åŠ é€Ÿå·¥å…·ã€‚

</details>

---

### 10. [LOG.io: Unified Rollback Recovery and Data Lineage Capture for Distributed Data Pipelines](https://arxiv.org/abs/2512.16038)

**Authors**: Eric Simon, Renato B. Hoffmann, Lucas Alf, Dalvan Griebler  
**Category**: cs.DC  
**Published**: 2025-12-19  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.16038v1  

#### Abstract
This paper introduces LOG.io, a comprehensive solution designed for correct rollback recovery and fine-grain data lineage capture in distributed data pipelines. It is tailored for serverless scalable architectures and uses a log-based rollback recovery protocol. LOG.io supports a general programming...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠLOG.io: Unified Rollback Recovery and Data Lineage Capture for Distributed Data Pipelinesã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡æ—¨åœ¨è§£å†³**åˆ†å¸ƒå¼æ•°æ®æµæ°´çº¿**ï¼ˆdata pipelinesï¼‰ä¸­çš„ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼š
1. **æ­£ç¡®å›æ»šæ¢å¤**ï¼ˆCorrect Rollback Recoveryï¼‰ï¼šåœ¨ç³»ç»Ÿæ•…éšœåï¼Œèƒ½å¤Ÿå°†æ•´ä¸ªæµæ°´çº¿æ¢å¤åˆ°ä¸€ä¸ªä¸€è‡´çš„çŠ¶æ€ï¼Œå¹¶ä¿è¯æ‰§è¡Œç»“æœç­‰ä»·äºæ— æ•…éšœæ‰§è¡Œã€‚
2. **ç»†ç²’åº¦æ•°æ®è¡€ç¼˜æ•è·**ï¼ˆFine-grain Data Lineage Captureï¼‰ï¼šè¿½è¸ªä»»æ„ä¸¤ä¸ªç®—å­ä¹‹é—´è¾“å…¥äº‹ä»¶ä¸è¾“å‡ºäº‹ä»¶ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œç”¨äºè°ƒè¯•ã€å®¡è®¡å’Œæº¯æºã€‚

ä¼ ç»Ÿæ–¹æ³•å¦‚ **Asynchronous Barrier Snapshotting (ABS)** è™½ç„¶æ”¯æŒå®¹é”™ï¼Œä½†å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- **é˜»å¡æ€§æ¢å¤**ï¼ˆBlocking Recoveryï¼‰ï¼šå•ä¸ªç®—å­å¤±è´¥ä¼šå¯¼è‡´æ•´ä¸ªæµæ°´çº¿é‡å¯ã€‚
- **ä¸æ”¯æŒåŠ¨æ€æ‰©ç¼©å®¹**ï¼ˆDynamic Scalingï¼‰ï¼šæ‰©ç¼©å®¹éœ€ä¸­æ–­æµæ°´çº¿å¹¶ä»æ£€æŸ¥ç‚¹é‡å¯ã€‚
- **æ•°æ®è¡€ç¼˜ç²’åº¦ç²—**ï¼šæ— æ³•ç²¾ç¡®åˆ°äº‹ä»¶çº§åˆ«ï¼Œä¸”é€šå¸¸ä»…æ”¯æŒç¡®å®šæ€§ç®—å­ã€‚

### æå‡ºçš„æ–°æ–¹æ³•
ä½œè€…æå‡ºäº† **LOG.io** â€”â€” ä¸€ç§ç»Ÿä¸€çš„æ—¥å¿—å‹å›æ»šæ¢å¤åè®®ï¼ŒåŒæ—¶å®ç°é«˜å¯é æ€§æ¢å¤ä¸ç»†ç²’åº¦æ•°æ®è¡€ç¼˜æ•è·ã€‚

#### æ ¸å¿ƒæœºåˆ¶
- **æ—¥å¿—é©±åŠ¨æ¢å¤**ï¼ˆLog-based Rollback Recoveryï¼‰ï¼š
  - æ¯ä¸ªç®—å­åœ¨ç”Ÿæˆè¾“å‡ºäº‹ä»¶å‰ï¼Œå…ˆä»¥â€œundoneâ€çŠ¶æ€å°†å…¶å†™å…¥æŒä¹…åŒ–æ—¥å¿—ã€‚
  - åŒæ—¶æ ‡è®°å…¶ä¾èµ–çš„è¾“å…¥äº‹ä»¶ä¸ºâ€œdoneâ€ï¼Œç¡®ä¿å› æœä¸€è‡´æ€§ã€‚
  - æ•…éšœå‘ç”Ÿæ—¶ï¼Œä»…é‡å¯å¤±è´¥ç®—å­ï¼Œä»æ—¥å¿—ä¸­æ¢å¤æœªå®Œæˆçš„è¾“å‡ºäº‹ä»¶å’Œå†…éƒ¨çŠ¶æ€ã€‚
- **éé˜»å¡æ¢å¤**ï¼ˆNon-blocking Recoveryï¼‰ï¼š
  - å¤±è´¥ç®—å­ç‹¬ç«‹æ¢å¤ï¼Œä¸å½±å“å…¶ä»–æ­£å¸¸è¿è¡Œçš„ç®—å­ã€‚
- **åŠ¨æ€æ‰©ç¼©å®¹æ”¯æŒ**ï¼š
  - æ”¯æŒåœ¨è¿è¡Œæ—¶åŠ¨æ€å¢åŠ æˆ–å‡å°‘ç®—å­å‰¯æœ¬ï¼Œæ— éœ€ä¸­æ–­æµæ°´çº¿ã€‚
- **ç»Ÿä¸€çš„æ•°æ®è¡€ç¼˜æ•è·**ï¼š
  - åœ¨åŒä¸€åŸå­äº‹åŠ¡ä¸­è®°å½•è¾“å‡ºäº‹ä»¶ä¸å…¶è¾“å…¥äº‹ä»¶é›†åˆï¼ˆInput Setï¼‰çš„æ˜ å°„å…³ç³»ï¼Œå­˜å‚¨äº `EVENT_LINEAGE` è¡¨ã€‚
  - æ”¯æŒä»»æ„è‡ªå®šä¹‰ã€éç¡®å®šæ€§ç®—å­çš„æ•°æ®è¡€ç¼˜è¿½è¸ªã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç‰¹æ€§ | LOG.io | ABS (Flink) | Spark Streaming |
|------|--------|-----------|----------------|
| éé˜»å¡æ¢å¤ | âœ… | âŒ | âŒ |
| åŠ¨æ€æ‰©ç¼©å®¹ | âœ… | âŒï¼ˆéœ€ savepointï¼‰ | âŒ |
| æ”¯æŒéç¡®å®šæ€§ç®—å­ | âœ… | âŒ | âŒ |
| ç»†ç²’åº¦æ•°æ®è¡€ç¼˜ | âœ…ï¼ˆäº‹ä»¶çº§ï¼‰ | âŒï¼ˆæ‰¹çº§ï¼‰ | âŒï¼ˆRDDçº§ï¼‰ |
| æ•°æ®è¡€ç¼˜å¼€é”€ | <1.5% | ä¸æ”¯æŒ | ~20â€“30% |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### å®éªŒå¹³å°
- **ç³»ç»Ÿç¯å¢ƒ**ï¼šåŸºäº **SAP Data Intelligence Cloud** æ„å»ºã€‚
- **éƒ¨ç½²æ¶æ„**ï¼šKubernetes é›†ç¾¤ï¼Œæ¯ä¸ªç®—å­è¿è¡Œåœ¨ç‹¬ç«‹çš„ Pod ä¸­ã€‚
- **æ—¥å¿—å­˜å‚¨**ï¼šä½¿ç”¨ **SAP HANA** æ•°æ®åº“å­˜å‚¨ LOG.io æ—¥å¿—è¡¨ï¼ˆ`EVENT_LOG`, `EVENT_DATA`, `STATE`, `READ_ACTION`, `EVENT_LINEAGE`ï¼‰ã€‚

### å®éªŒè®¾ç½®
è®¾è®¡äº†ä¸‰ä¸ª **Use Case** æ¥è¯„ä¼°ä¸åŒåœºæ™¯ä¸‹çš„æ€§èƒ½ï¼š

#### Use Case 1ï¼šä¸²è¡Œæµæ°´çº¿ï¼Œå« Straggler ç®—å­
- ç»“æ„ï¼š`Source â†’ OP2 (å¿«) â†’ OP3 (æ…¢) â†’ OP4 (Writer) â†’ Sink`
- å˜é‡ï¼š
  - äº‹ä»¶é€Ÿç‡ï¼š100ms ~ 500ms/äº‹ä»¶
  - äº‹ä»¶å¤§å°ï¼š10KB ~ 10MB
  - å¤±è´¥ç®—å­ï¼šOP3 æˆ– OP4
- ç›®æ ‡ï¼šè¯„ä¼°åœ¨å­˜åœ¨å¤„ç†é€Ÿåº¦å·®å¼‚ï¼ˆstragglerï¼‰æ—¶çš„æ¢å¤æ•ˆç‡ã€‚

#### Use Case 2ï¼šå¹¶è¡Œè·¯å¾„æµæ°´çº¿
- ç»“æ„ï¼š`Source â†’ OP2 & OP3 â†’ OP4 (åŒæ­¥è¾“å…¥) â†’ Sink`
- ç›®æ ‡ï¼šè¯„ä¼°å¹¶è¡Œè·¯å¾„ä¸‹å¯¹é½æ£€æŸ¥ç‚¹çš„å½±å“ã€‚

#### Use Case 3ï¼šå¸¦å¹¶è¡Œå¤„ç†çš„æµæ°´çº¿
- ç»“æ„ï¼š`Source â†’ Dispatcher â†’ 2Ã—OP3 (å‰¯æœ¬) â†’ Merger â†’ OP5 â†’ Sink`
- ç›®æ ‡ï¼šè¯„ä¼°æ•°æ®å¹¶è¡ŒåŒ–å¯¹æ¢å¤æ€§èƒ½çš„å½±å“ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **æ­£å¸¸å¤„ç†å¼€é”€**ï¼ˆNormal Processing Overheadï¼‰ï¼šç›¸å¯¹äºæ— å®¹é”™åŸºçº¿çš„é¢å¤–å»¶è¿Ÿã€‚
- **æ¢å¤å¼€é”€**ï¼ˆRecovery Overheadï¼‰ï¼šæ•…éšœåæ¢å¤æ‰€å¢åŠ çš„æ€»æ‰§è¡Œæ—¶é—´ã€‚
- **æ•°æ®è¡€ç¼˜å¼€é”€**ï¼ˆLineage Overheadï¼‰ï¼šå¯ç”¨è¡€ç¼˜æ•è·åçš„æ€§èƒ½å½±å“ã€‚
- **å¯¹æ¯”åŸºçº¿**ï¼š**ABS**ï¼ˆAsynchronous Barrier Snapshottingï¼‰ï¼Œåœ¨ SAP DI ä¸­å®ç°ï¼Œå¿«ç…§é—´éš”è®¾ä¸º 15sã€30sã€45sã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### æ­£å¸¸å¤„ç†æ€§èƒ½
| åœºæ™¯ | LOG.io å¼€é”€ | ABS å¼€é”€ |
|------|------------|---------|
| å­˜åœ¨ Stragglerï¼ˆæ…¢ç®—å­ï¼‰ï¼Œä¸­ç­‰ååï¼ˆ100ms/äº‹ä»¶ï¼‰ | <5% | 2â€“3% |
| æ‰€æœ‰ç®—å­å¤„ç†æ—¶é—´ç›¸è¿‘ï¼Œé«˜ååï¼ˆ30ms/äº‹ä»¶ï¼‰ | ~42.5% | ~3% |
| ä½¿ç”¨æ•°æ®å¹¶è¡ŒåŒ–ï¼ˆ2å‰¯æœ¬ï¼‰ | ~25% | ~3.2% |

> **è¯´æ˜**ï¼šå½“å­˜åœ¨æ˜æ˜¾ straggler æ—¶ï¼ŒLOG.io å¯åˆ©ç”¨èƒŒå‹éšè—æ—¥å¿—å¼€é”€ï¼›ä½†åœ¨é«˜ååã€å‡åŒ€è´Ÿè½½ä¸‹ï¼Œæ‚²è§‚æ—¥å¿—ï¼ˆpessimistic loggingï¼‰å¸¦æ¥æ˜¾è‘—å¼€é”€ã€‚

### æ¢å¤æ€§èƒ½ï¼ˆ1æ¬¡æ•…éšœï¼‰
| åœºæ™¯ | LOG.io æ¢å¤å¼€é”€ | ABS æ¢å¤å¼€é”€ |
|------|----------------|-------------|
| å­˜åœ¨ Stragglerï¼ˆOP3 æ…¢ 100Ã—ï¼‰ | ~1% | ~21% |
| é«˜ååï¼Œå‡åŒ€è´Ÿè½½ | ~51% | ~24.5% |
| ä½¿ç”¨æ•°æ®å¹¶è¡ŒåŒ– | ~49% | ~19% |

> **å…³é”®å‘ç°**ï¼šLOG.io åœ¨ straggler åœºæ™¯ä¸‹æ¢å¤ä¼˜åŠ¿å·¨å¤§ï¼Œå› ä¸ºå…¶ä»–ç®—å­å¯ç»§ç»­å¤„ç†ï¼›è€Œ ABS å¿…é¡»å…¨å±€é‡å¯ã€‚

### æ•°æ®è¡€ç¼˜æ•è·å¼€é”€
- åœ¨æ‰€æœ‰å®éªŒä¸­ï¼Œå¯ç”¨æ•°æ®è¡€ç¼˜æ•è·çš„é¢å¤–å¼€é”€ **<1.5%**ã€‚
- æœ€é«˜ä»…ä¸º **1.2%**ï¼ˆ1000äº‹ä»¶åœºæ™¯ï¼‰ï¼Œæœ€ä½ä¸º **0.4%**ï¼ˆ5000äº‹ä»¶ï¼‰ã€‚
- è¿œä½äºå·²æœ‰æ–¹æ¡ˆï¼ˆå¦‚ Spark lineage ~20â€“30%ï¼‰ã€‚

### æ¶ˆèå®éªŒï¼ˆAblation Studyï¼‰
- **ä¹è§‚æ—¥å¿—æ¨¡å¼**ï¼ˆReplay-based Recoveryï¼‰ï¼š
  - é€‚ç”¨äºç¡®å®šæ€§ç®—å­ï¼Œä»…è®°å½•äº‹ä»¶ ID è€Œéå®Œæ•´ payloadã€‚
  - å¯æ˜¾è‘—é™ä½æ—¥å¿—ä½“ç§¯å’Œ I/O å¼€é”€ï¼Œå°¤å…¶åœ¨é«˜ååå¤§äº‹ä»¶åœºæ™¯ã€‚
  - ä½†éœ€ç‰ºç‰²éƒ¨åˆ†æ¢å¤é€Ÿåº¦ï¼ˆéœ€é‡æ–°è®¡ç®—äº‹ä»¶ï¼‰ã€‚
- **æ•°æ®å¹¶è¡ŒåŒ–å¯¹ LOG.io çš„ä¼˜åŒ–ä½œç”¨**ï¼š
  - å¹¶è¡Œå¤„ç†èƒ½æœ‰æ•ˆåˆ†æ‘Šæ—¥å¿—å‹åŠ›ï¼Œä½¿ LOG.io åœ¨é«˜åååœºæ™¯ä¸‹æ€§èƒ½æå‡è¿‘ä¸€å€ã€‚
  - è€Œ ABS å‡ ä¹ä¸å—å¹¶è¡ŒåŒ–å½±å“ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **LOG.io åœ¨å­˜åœ¨ straggler ç®—å­æ—¶è¡¨ç°ä¼˜å¼‚**ï¼š
   - æ­£å¸¸å¤„ç†å¼€é”€æ¥è¿‘ ABSã€‚
   - æ¢å¤é€Ÿåº¦è¿œè¶… ABSï¼Œå› é‡‡ç”¨éé˜»å¡æ¢å¤ç­–ç•¥ã€‚

2. **é«˜ååå‡åŒ€è´Ÿè½½æ˜¯ LOG.io çš„çŸ­æ¿**ï¼š
   - æ‚²è§‚æ—¥å¿—æœºåˆ¶å¯¼è‡´æ˜¾è‘— I/O å¼€é”€ã€‚
   - ä½†å¯é€šè¿‡ **æ•°æ®å¹¶è¡ŒåŒ–** æ˜¾è‘—ç¼“è§£ã€‚

3. **æ•°æ®è¡€ç¼˜æ•è·å‡ ä¹é›¶æˆæœ¬**ï¼š
   - åˆ©ç”¨å·²æœ‰çš„æ—¥å¿—æœºåˆ¶ï¼Œé¢å¤–å¼€é”€æä½ï¼ˆ<1.5%ï¼‰ã€‚
   - æ”¯æŒä»»æ„è‡ªå®šä¹‰ã€éç¡®å®šæ€§ç®—å­ï¼Œæ˜¯é‡å¤§çªç ´ã€‚

4. **åŠ¨æ€æ‰©ç¼©å®¹åŸç”Ÿæ”¯æŒ**ï¼š
   - é€šè¿‡åŸå­äº‹åŠ¡åè°ƒ Dispatcher å’Œ Merger çš„çŠ¶æ€æ›´æ–°ï¼Œç¡®ä¿äº‹ä»¶ä¸ä¸¢å¤±ã€‚
   - æ˜¯ç°æœ‰ç³»ç»Ÿï¼ˆå¦‚ Flinkï¼‰éš¾ä»¥å®ç°çš„åŠŸèƒ½ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **æ—¥å¿— I/O æˆä¸ºç“¶é¢ˆ**ï¼š
   - å½“äº‹ä»¶å¤§ä¸”é¢‘ç‡é«˜æ—¶ï¼ŒHANA DB çš„æ—¥å¿—å†™å…¥æˆä¸ºæ€§èƒ½ç“¶é¢ˆã€‚
   - å½“å‰å®ç°æœªé’ˆå¯¹æ—¥å¿—ä¼˜åŒ–å­˜å‚¨ç»“æ„ã€‚

2. **æ‚²è§‚æ—¥å¿—å¼•å…¥å»¶è¿Ÿ**ï¼š
   - è¾“å‡ºäº‹ä»¶å¿…é¡»å…ˆå†™æ—¥å¿—å†å‘é€ï¼Œå¢åŠ äº†ç«¯åˆ°ç«¯å»¶è¿Ÿã€‚
   - è™½å¯é€šè¿‡ä¹è§‚æ—¥å¿—ï¼ˆreplay modeï¼‰ç¼“è§£ï¼Œä½†ä»…é€‚ç”¨äºç¡®å®šæ€§ç®—å­ã€‚

3. **å¤–éƒ¨ç³»ç»Ÿäº¤äº’è¦æ±‚ä¸¥æ ¼**ï¼š
   - å†™æ“ä½œï¼ˆwrite actionsï¼‰å¿…é¡»æ»¡è¶³ **å¹‚ç­‰æ€§** æˆ– **å¯æ£€æŸ¥æ€§**ï¼ˆcheckableï¼‰ï¼Œå¦åˆ™æ— æ³•ä¿è¯ exactly-once è¯­ä¹‰ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **è‡ªåŠ¨é€‰æ‹©æ—¥å¿—æ¨¡å¼**ï¼š
   - æ ¹æ®ç®—å­ç±»å‹ï¼ˆç¡®å®šæ€§/éç¡®å®šæ€§ï¼‰ã€äº‹ä»¶å¤§å°ã€ååç‡ï¼ŒåŠ¨æ€åˆ‡æ¢æ‚²è§‚/ä¹è§‚æ—¥å¿—ã€‚

2. **ä¼˜åŒ–æ—¥å¿—å­˜å‚¨å±‚**ï¼š
   - ä½¿ç”¨æ›´é«˜æ•ˆçš„æŒä¹…åŒ–ç»“æ„ï¼ˆå¦‚ WALã€LSM-treeï¼‰æ›¿ä»£é€šç”¨æ•°æ®åº“ï¼ˆHANAï¼‰ï¼Œæå‡æ—¥å¿—ååã€‚

3. **æ”¯æŒæ›´çµæ´»çš„è¡€ç¼˜æŸ¥è¯¢**ï¼š
   - å½“å‰è¡€ç¼˜åŸºäº Input Setï¼Œæœªæ¥å¯ç»“åˆ schema-level lineage å®ç°è®°å½•çº§æº¯æºã€‚

4. **é›†æˆåˆ°æ›´å¤šæµå¤„ç†å¼•æ“**ï¼š
   - å½“å‰å®ç°åœ¨ SAP DIï¼Œæœªæ¥å¯é€‚é… Flinkã€Spark ç­‰ä¸»æµç³»ç»Ÿã€‚

---

> **æ€»ç»“**ï¼šLOG.io æä¾›äº†ä¸€ç§**ç»Ÿä¸€ã€éé˜»å¡ã€æ”¯æŒåŠ¨æ€æ‰©å±•**çš„å®¹é”™ä¸è¡€ç¼˜è§£å†³æ–¹æ¡ˆï¼Œåœ¨å­˜åœ¨å¤„ç†ä¸å‡è¡¡çš„ç°å®åœºæ™¯ä¸­è¡¨ç°å‡ºè‰²ï¼Œä¸”è¡€ç¼˜å¼€é”€æä½ï¼Œæ˜¯é¢å‘ç°ä»£äº‘åŸç”Ÿæ•°æ®æµæ°´çº¿çš„é‡è¦è¿›æ­¥ã€‚

</details>

---

### 11. [A Unified Generative-Predictive Framework for Deterministic Inverse Design](https://arxiv.org/abs/2512.15746)

**Authors**: Reza T. Batley, Sourav Saha  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.15746v1  

#### Abstract
Inverse design of heterogeneous material microstructures is a fundamentally ill-posed and famously computationally expensive problem. This is exacerbated by the high-dimensional design spaces associated with finely resolved images, multimodal input property streams, and a highly nonlinear forward ph...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šA Unified Generative-Predictive Framework for Deterministic Inverse Design

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
é€†å‘è®¾è®¡ï¼ˆInverse Designï¼‰åœ¨ææ–™ç§‘å­¦ã€èˆªç©ºèˆªå¤©ç­‰é¢†åŸŸä¸­æ˜¯ä¸€ä¸ª**æ ¹æœ¬ä¸Šä¸é€‚å®šï¼ˆill-posedï¼‰ä¸”è®¡ç®—æˆæœ¬é«˜æ˜‚**çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨å¼‚è´¨ææ–™å¾®ç»“æ„ï¼ˆheterogeneous material microstructuresï¼‰çš„è®¾è®¡ä¸­ã€‚ä¼ ç»Ÿæ–¹æ³•é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š
- é«˜ç»´è®¾è®¡ç©ºé—´ï¼ˆå¦‚å›¾åƒåˆ†è¾¨ç‡é«˜ï¼‰
- å¤šæ¨¡æ€è¾“å…¥å±æ€§æµ
- å¼ºéçº¿æ€§çš„å‰å‘ç‰©ç†å…³ç³»
- ç¼ºä¹ç¨³å®šã€å¿«é€Ÿã€ç¡®å®šæ€§çš„åæ¼”æœºåˆ¶

å°½ç®¡ç°ä»£ç”Ÿæˆæ¨¡å‹ï¼ˆå¦‚ GANsã€Diffusion Modelsï¼‰èƒ½å¾ˆå¥½åœ°å»ºæ¨¡å¤æ‚å‰å‘è¿‡ç¨‹ï¼Œä½†å®ƒä»¬çš„æ½œåœ¨ç©ºé—´ï¼ˆlatent spaceï¼‰é€šå¸¸ä¸æ”¯æŒ**å¿«é€Ÿã€ç¨³å®šçš„ç¡®å®šæ€§åæ¼”**ï¼Œå°¤å…¶ç¼ºä¹å¯¹ç‰©ç†è§„å¾‹çš„æ˜¾å¼çº¦æŸã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šJanus æ¡†æ¶
æœ¬æ–‡æå‡º **Janus** â€”â€” ä¸€ç§ç»Ÿä¸€çš„ç”Ÿæˆ-é¢„æµ‹æ¡†æ¶ï¼ˆunified generative-predictive frameworkï¼‰ï¼Œç”¨äºå®ç°**ç¡®å®šæ€§é€†å‘è®¾è®¡**ã€‚

#### æ ¸å¿ƒæ€æƒ³
Janus å°†ä¸€ä¸ªæ·±åº¦ç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼ˆencoder-decoderï¼‰ä¸ä¸€ä¸ªå¯é¢„æµ‹çš„ **KHRONOS head** è€¦åˆï¼Œæ„å»ºä¸€ä¸ªå…±äº«çš„æ½œåœ¨ç©ºé—´ $ \mathcal{Z} $ï¼Œè¯¥ç©ºé—´åŒæ—¶æ»¡è¶³ï¼š
- **ç”Ÿæˆæ€§**ï¼ˆGenerativeï¼‰ï¼šå¯é€šè¿‡è§£ç å™¨ $ D $ é«˜ä¿çœŸé‡å»ºè¾“å…¥ï¼›
- **é¢„æµ‹æ€§**ï¼ˆPredictiveï¼‰ï¼šé€šè¿‡ KHRONOS head å‡†ç¡®é¢„æµ‹ç›®æ ‡ç‰©ç†å±æ€§ï¼ˆå¦‚çƒ­å¯¼ç‡ï¼‰ï¼›
- **å¾ªç¯ä¸€è‡´æ€§**ï¼ˆCycle-consistentï¼‰ï¼šç¼–ç -è§£ç è·¯å¾„ç¨³å®šå¯é€†ï¼Œæ”¯æŒé«˜æ•ˆç¡®å®šæ€§åæ¼”ã€‚

#### æ¶æ„ç‰¹ç‚¹
- **åŒå¤´ç»“æ„**ï¼šç¼–ç å™¨ $ \mathcal{E} $ æ˜ å°„è¾“å…¥åˆ°æ½œåœ¨ç©ºé—´ï¼›è§£ç å™¨ $ D $ å’Œé¢„æµ‹å¤´ $ K $ å¹¶è¡Œå¤„ç†æ½œåœ¨è¡¨ç¤ºã€‚
- **è”åˆä¼˜åŒ–ç›®æ ‡**ï¼šæ½œåœ¨æµå½¢è¢«è”åˆè®­ç»ƒä»¥åŒæ—¶æ”¯æŒé‡æ„ç²¾åº¦å’Œé¢„æµ‹å‡†ç¡®æ€§ã€‚
- **æ‹“æ‰‘ç»“æ„è®¾è®¡**ï¼šå­¦ä¹ åˆ°çš„æ½œåœ¨æµå½¢åœ¨å‡ ä½•ä¸Šæ˜¯**ç­‰è·çš„**ï¼ˆisometricï¼‰ä¸”ç»è¿‡å‰ªæï¼ˆprunedï¼‰ï¼Œåˆ©äºç‰©ç†é¢„æµ‹ï¼Œå¹¶è¯±å¯¼æ½œåœ¨ç©ºé—´è§£è€¦ï¼ˆdisentanglementï¼‰ã€‚

#### ä¸¤ç§å®ä¾‹åŒ–ç‰ˆæœ¬
- **Janus-C**ï¼šåŸºäºå·ç§¯ç½‘ç»œï¼ˆConvolutionalï¼‰çš„ U-Net é£æ ¼ç»“æ„ï¼Œé€‚ç”¨äºå±€éƒ¨ç»“æ„å›¾åƒã€‚
- **Janus-ViT**ï¼šåŸºäº Vision Transformer çš„ç¼–ç å™¨ + æ··åˆè§£ç å™¨ï¼Œé€‚åˆæ•æ‰é•¿ç¨‹ä¾èµ–ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³•ç±»åˆ« | å±€é™æ€§ | Janus çš„æ”¹è¿› |
|--------|------|-------------|
| **VAEs** | æ½œåœ¨ç©ºé—´æ— å¾ªç¯ä¸€è‡´æ€§ï¼Œåæ¼”ä¸ç¨³å®š | æ˜¾å¼å¼•å…¥å¾ªç¯ä¸€è‡´æ€§æŸå¤± $ L_{\text{cycle}} $ å’Œæ·±å±‚å¾ªç¯æŸå¤± $ L_{\text{deep}} $ |
| **GANs / StyleGAN** | åæ¼”éœ€è¿­ä»£ä¼˜åŒ–æˆ–é¢å¤–ç¼–ç å™¨ï¼Œä¸ä¿è¯ç¨³å®šæ€§ | æ”¯æŒç«¯åˆ°ç«¯ç¡®å®šæ€§åæ¼”ï¼Œæ— éœ€æœç´¢ |
| **Diffusion Models** | åå‘æ‰©æ•£æ…¢ï¼Œæ¢¯åº¦æœç´¢æ˜‚è´µ | åæ¼”ä»…éœ€ ~2000 æ­¥ Adam ä¼˜åŒ–ï¼Œåœ¨ç§’çº§å®Œæˆ |
| **Invertible NNs / Normalizing Flows** | å¼ºåˆ¶åŒå°„å¯¼è‡´ä¿¡æ¯ç“¶é¢ˆï¼Œéš¾ä»¥å¤„ç†å¤šå¯¹ä¸€é—®é¢˜ | å…è®¸å‹ç¼©æ˜ å°„ï¼Œä¿ç•™æœ‰æ•ˆè§£ç©ºé—´å¤šæ ·æ€§ |
| **Operator Learning (e.g., DeepONet)** | ä¸æä¾›å¯ç”¨äºåæ¼”çš„æ½œåœ¨ç©ºé—´ | æ„é€ ä¸“ä¸ºåæ¼”ä¼˜åŒ–çš„ä½ç»´æ½œåœ¨æµå½¢ |

> âœ… **æ ¸å¿ƒä¼˜åŠ¿æ€»ç»“**ï¼š
> - å®ç°**å®æ—¶ã€ç‰©ç†æ„ŸçŸ¥çš„ç¡®å®šæ€§é€†å‘ç”Ÿæˆ**
> - è®¡ç®—æˆæœ¬è¿œä½äºä¼ ç»Ÿä¼˜åŒ–æ–¹æ³•ï¼ˆå¦‚æ‹“æ‰‘ä¼˜åŒ–ã€é—ä¼ ç®—æ³•ï¼‰
> - æ”¯æŒå¤šæ ·åŒ–è§£ç”Ÿæˆï¼ˆdiverse inversionï¼‰ä¸å¹³æ»‘æµå½¢éå†

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
1. **MNIST æ‰‹å†™æ•°å­—æ•°æ®é›†**
   - ç”¨é€”ï¼šéªŒè¯æ¡†æ¶çš„åŸºæœ¬èƒ½åŠ›ï¼ˆåˆ†ç±» + é‡å»º + é€†å‘ç”Ÿæˆï¼‰
   - è¾“å…¥å°ºå¯¸ï¼š28Ã—28 ç°åº¦å›¾
   - ç±»åˆ«æ•°ï¼š10ï¼ˆ0â€“9ï¼‰

2. **OSTI å¾®ç»“æ„æ•°æ®é›†** [38]
   - æ¥æºï¼šç›¸åœºæ¨¡æ‹Ÿï¼ˆphase-field simulationï¼‰ç”Ÿæˆçš„äºŒç›¸å¾®ç»“æ„ï¼ˆå¦‚å›ºç›¸ä¸å­”éš™ï¼‰
   - æ ‡ç­¾ï¼šå½’ä¸€åŒ–çš„æœ‰æ•ˆçƒ­å¯¼ç‡ $ k $ï¼ˆdimensionlessï¼‰
   - å›¾åƒå°ºå¯¸ï¼š64Ã—64 äºŒå€¼å›¾åƒ
   - ç‰©ç†æ„ä¹‰ï¼šä¸åŒå½¢æ€å¯¹åº”ä¸åŒçš„çƒ­ä¼ å¯¼æ€§èƒ½

---

### å®éªŒè®¾ç½®
#### æ¨¡å‹é…ç½®
- **Janus-C**ï¼šé‡‡ç”¨ U-Net é£æ ¼å·ç§¯ç¼–ç å™¨-è§£ç å™¨
- **æ½œåœ¨ç©ºé—´ç»´åº¦**ï¼š$ \mathcal{Z} \in \mathbb{R}^{64} $
- **KHRONOS Head**ï¼š
  - MNISTï¼šåˆ†ç±»ä»»åŠ¡ï¼ˆ10ç±»ï¼‰ï¼Œä½¿ç”¨äº¤å‰ç†µæŸå¤±
  - å¾®ç»“æ„ï¼šå›å½’ä»»åŠ¡ï¼ˆè¿ç»­çƒ­å¯¼ç‡ï¼‰ï¼Œä½¿ç”¨ MSE æŸå¤±
- **è®­ç»ƒç›®æ ‡å‡½æ•°**ï¼š
  $$
  \mathcal{L} = \mathcal{L}_{\text{task}} + \lambda_{\text{recon}} \mathcal{L}_{\text{recon}} + \lambda_{\text{cycle}} \mathcal{L}_{\text{cycle}} + \lambda_{\text{deep}} \mathcal{L}_{\text{deep}}
  $$

#### æŸå¤±é¡¹è¯´æ˜
| æŸå¤±é¡¹ | å«ä¹‰ |
|-------|------|
| $ \mathcal{L}_{\text{task}} $ | åˆ†ç±»æˆ–å›å½’ä»»åŠ¡æŸå¤± |
| $ \mathcal{L}_{\text{recon}} $ | é‡æ„è¯¯å·®ï¼ˆMAEï¼‰ |
| $ \mathcal{L}_{\text{cycle}} $ | å¾ªç¯ä¸€è‡´æ€§æŸå¤±ï¼š$ \|\mathcal{E}(D(z)) - z\| $ |
| $ \mathcal{L}_{\text{deep}} $ | æ·±å±‚å¾ªç¯æŸå¤±ï¼š$ \|D \circ \mathcal{E} \circ D \circ \mathcal{E}(x) - x\| $ |
| $ \mathcal{L}_{\text{align}} $ ï¼ˆåæ¼”æ—¶ç”¨ï¼‰ | æµå½¢å¯¹é½æŸå¤±ï¼Œé˜²æ­¢åç¦»è®­ç»ƒåˆ†å¸ƒ |

#### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | ç”¨é€” |
|-----|------|
| $ R^2 $ã€RMSEã€MAE | å›å½’ä»»åŠ¡é¢„æµ‹ç²¾åº¦ |
| Pixelwise MAE | å›¾åƒé‡å»ºä¿çœŸåº¦ |
| åˆ†ç±»å‡†ç¡®ç‡ | MNIST ä¸Šçš„è¯†åˆ«èƒ½åŠ› |
| ç›¸å¯¹è¯¯å·®ï¼ˆRelative Errorï¼‰ | é€†å‘ç”Ÿæˆç»“æœä¸ç›®æ ‡å±æ€§åå·® |
| UMAP å¯è§†åŒ– | æ½œåœ¨ç©ºé—´ç»“æ„åˆ†æ |
| ç”Ÿæˆå¤šæ ·æ€§ | å¤šåˆå§‹ç§å­ä¸‹çš„ä¸åŒè§£ |

#### åŸºçº¿æ–¹æ³•å¯¹æ¯”ï¼ˆéšå«ï¼‰
è™½ç„¶æœªç›´æ¥åˆ—å‡ºæ‰€æœ‰åŸºçº¿æ¨¡å‹çš„æ•°å€¼æ¯”è¾ƒï¼Œä½†ä»èƒŒæ™¯ç»¼è¿°å¯çŸ¥ï¼Œä½œè€…å°† Janus ä¸ä»¥ä¸‹æ–¹æ³•è¿›è¡Œäº†æ¦‚å¿µæ€§å¯¹æ¯”ï¼š
- VAEã€GANã€VQ-VAEã€Diffusion Modelï¼ˆç”Ÿæˆæ¨¡å‹ï¼‰
- PINNsã€DeepONetã€Fourier Neural Operatorsï¼ˆç§‘å­¦ä»£ç†æ¨¡å‹ï¼‰
- CycleGANã€BiGANã€Normalizing Flowsï¼ˆå¯é€†æ¨¡å‹ï¼‰

å…¶ä¼˜åŠ¿ä½“ç°åœ¨**åæ¼”æ•ˆç‡ã€ç¨³å®šæ€§ã€ç‰©ç†ä¸€è‡´æ€§**ç­‰æ–¹é¢ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### åœ¨ MNIST ä¸Šçš„ç»“æœ
- **å‰å‘æ€§èƒ½**ï¼š
  - åˆ†ç±»å‡†ç¡®ç‡ï¼š**97.5%**ï¼ˆæµ‹è¯•é›†ï¼‰
  - é€åƒç´ é‡å»ºè¯¯å·®ï¼šçº¦ **8% MAE**
- **é€†å‘ç”Ÿæˆèƒ½åŠ›**ï¼ˆSwarm Inversionï¼‰ï¼š
  - å¯¹æ¯ä¸ªæ•°å­—ç±»åˆ«ï¼ˆ0â€“9ï¼‰ï¼Œè¿›è¡Œ 10 æ¬¡å¹¶è¡Œåæ¼”ï¼ˆä¸åŒéšæœºåˆå§‹åŒ–ï¼‰
  - æˆåŠŸç‡æ¥è¿‘ **100%**
  - ç”Ÿæˆæ ·æœ¬å…·æœ‰å¤šæ ·æ€§ï¼ˆä¸åŒä¹¦å†™é£æ ¼ï¼‰ï¼Œè¡¨æ˜æ¨¡å‹å­¦åˆ°çš„æ˜¯**è¿ç»­çš„æ‰‹å†™æµå½¢è¾¹ç•Œ**

> ğŸ“Œ ç¤ºä¾‹ï¼šæ•°å­—â€œ1â€çš„æŸäº›ç”Ÿæˆç•¥å¸¦â€œ7â€ç‰¹å¾ï¼Œåæ˜ æ¨¡å‹ç†è§£äº†ä¹¦å†™å˜ä½“çš„è¿‡æ¸¡åŒºåŸŸã€‚

---

### åœ¨å¾®ç»“æ„é€†å‘è®¾è®¡ä¸Šçš„ç»“æœ
#### å‰å‘è®­ç»ƒæ€§èƒ½
- **é¢„æµ‹ç²¾åº¦**ï¼š
  - $ R^2 = 0.98 $
  - ç›¸å¯¹è¯¯å·® â‰ˆ **2%**
  - MAE = 0.67ï¼ˆç¼©æ”¾åï¼‰
- **é‡å»ºä¿çœŸåº¦**ï¼š
  - åƒç´ çº§ MAE < **0.05**ï¼ˆå³ <5% å¼ºåº¦è¯¯å·®ï¼‰
  - è¾¹ç•Œæ¸…æ™°ï¼Œæ— æ¨¡ç³Šä¼ªå½±
- **æµå½¢ç¨³å®šæ€§**ï¼š
  - $ L_{\text{cycle}} $ æ”¶æ•›è‡³ < 0.03
  - $ L_{\text{deep}} $ ä¸é‡å»ºè¯¯å·®åŒæ­¥ä¸‹é™ï¼Œè¡¨æ˜ç»“æ„ç¨³å®š

#### é€†å‘ç”Ÿæˆæ€§èƒ½
- **å±æ€§ç›®æ ‡åŒ¹é…è¯¯å·®**ï¼š< **1% ç›¸å¯¹è¯¯å·®**
- **Property Sweep å®éªŒ**ï¼š
  - ç›®æ ‡çƒ­å¯¼ç‡ $ k = 15, 25, 35, 45, 55 $
  - ç”Ÿæˆå¾®ç»“æ„å‘ˆç°**å¹³æ»‘å½¢æ€æ¼”å˜**ï¼ˆä»ç¨€ç–é»‘ç‚¹ â†’ è¿ç»­çº¤ç»´ â†’ å¯†é›†é»‘åŒºï¼‰
  - è¡¨æ˜æ½œåœ¨ç©ºé—´æ²¿ä¸»è½´æœ‰åºç»„ç»‡
- **Diversity Sweep å®éªŒ**ï¼š
  - å›ºå®šç›®æ ‡ $ k=35 $ï¼Œ5 ä¸ªä¸åŒåˆå€¼ç”Ÿæˆ 5 ç§ä¸åŒå¾®è§‚ç»“æ„
  - æ‰€æœ‰ç»“æ„å‡æ»¡è¶³ç›®æ ‡å±æ€§è¯¯å·® <1%
  - æˆåŠŸæ•è·é€†é—®é¢˜çš„**é›¶ç©ºé—´ï¼ˆnullspaceï¼‰å¤šæ ·æ€§**

#### æ½œåœ¨ç©ºé—´å¯è§†åŒ–ï¼ˆUMAPï¼‰
- UMAP æŠ•å½±æ˜¾ç¤ºæ½œåœ¨ç‚¹å½¢æˆ**è¿ç»­å­—ç¬¦ä¸²çŠ¶ç»“æ„**ï¼ŒæŒ‰çƒ­å¯¼ç‡æ’åº
- ä¸ VAE çš„â€œblob-likeâ€äº‘å›¢å½¢æˆé²œæ˜å¯¹æ¯”
- è¡¨æ˜æ½œåœ¨ç©ºé—´å·²è§£è€¦å¹¶æ‹“æ‰‘æœ‰åº

---

### æ¶ˆèå®éªŒï¼ˆé—´æ¥ä½“ç°ï¼‰
å°½ç®¡æ²¡æœ‰ç‹¬ç«‹ç« èŠ‚ï¼Œä½†é€šè¿‡æ¨¡å—è®¾è®¡å¯æ¨æ–­æ¶ˆèé€»è¾‘ï¼š
- è‹¥å»é™¤ $ L_{\text{cycle}} $ æˆ– $ L_{\text{deep}} $ â†’ æµå½¢ä¸ç¨³å®šï¼Œåæ¼”å¤±è´¥
- è‹¥ä¸ç”¨ KHRONOS head â†’ é¢„æµ‹ä¸å‡†ï¼Œæ— æ³•ç²¾ç¡®æ§åˆ¶å±æ€§
- è‹¥ä¸è”åˆä¼˜åŒ– â†’ æ½œåœ¨ç©ºé—´æ— æ³•å…¼é¡¾ç”Ÿæˆä¸é¢„æµ‹

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **æ½œåœ¨ç©ºé—´å¯ä»¥è¢«è”åˆä¼˜åŒ–ä¸ºæ—¢åˆ©äºç”Ÿæˆåˆåˆ©äºé¢„æµ‹çš„ç»Ÿä¸€è¡¨ç¤º**  
   Janus æˆåŠŸæ„å»ºäº†ä¸€ä¸ª**å…¼å…·å¯è§£ç æ€§ã€é¢„æµ‹æ€§å’Œå¾ªç¯ä¸€è‡´æ€§çš„æ½œåœ¨æµå½¢**ï¼Œè§£å†³äº†ä¼ ç»Ÿç”Ÿæˆæ¨¡å‹éš¾ä»¥ç¡®å®šæ€§åæ¼”çš„é—®é¢˜ã€‚

2. **é€†å‘è®¾è®¡å¯è½¬åŒ–ä¸ºä½ç»´æµå½¢ä¸Šçš„æ¢¯åº¦ä¼˜åŒ–é—®é¢˜**  
   å°†åŸæœ¬åœ¨ $ \mathbb{R}^{64\times64} $ å›¾åƒç©ºé—´ä¸­çš„æœç´¢ï¼Œé™ç»´è‡³ $ \mathbb{R}^{64} $ æ½œåœ¨ç©ºé—´ï¼Œæå¤§æå‡æ•ˆç‡ã€‚

3. **åæ¼”é€Ÿåº¦å¿«ã€ç²¾åº¦é«˜ã€å¤šæ ·æ€§å¥½**  
   - å•æ¬¡åæ¼”è€—æ—¶çº¦ **1 ç§’**ï¼ˆNVIDIA A100 GPUï¼‰
   - å±æ€§è¯¯å·® <1%
   - æ”¯æŒä»å¤šä¸ªåˆå€¼å‡ºå‘è·å¾—å¤šæ ·åŒ–åˆç†è§£

4. **æ½œåœ¨ç©ºé—´è‡ªç„¶è§£è€¦ä¸”æ‹“æ‰‘æœ‰åº**  
   UMAP æ˜¾ç¤ºçƒ­å¯¼ç‡æ²¿ä¸»è½´å•è°ƒå˜åŒ–ï¼Œè¯´æ˜æ¨¡å‹è‡ªåŠ¨å‘ç°äº†ç‰©ç†ä¸Šæœ‰æ„ä¹‰çš„ç”Ÿæˆè·¯å¾„ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **æ’å€¼è€Œéå¤–æ¨**ï¼šä¾èµ–è®­ç»ƒæ•°æ®åˆ†å¸ƒï¼Œè¶…å‡ºèŒƒå›´çš„å±æ€§ç›®æ ‡å¯èƒ½æ— æ•ˆ
2. **å½“å‰å®ç°åœ¨ 2D å¾®ç»“æ„ä¸Š**ï¼šæ‰©å±•è‡³ 3D é«˜åˆ†è¾¨ç‡ç»“æ„ä¼šå¢åŠ è®¡ç®—è´Ÿæ‹…
3. **å•ä»»åŠ¡é¢„æµ‹å¤´**ï¼šç›®å‰ä»…æ”¯æŒå•ä¸€ç‰©ç†å±æ€§ï¼ˆå¦‚çƒ­å¯¼ç‡ï¼‰ï¼Œå¤šç›®æ ‡ä¼˜åŒ–å°šæœªå®ç°

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **å¤šç›®æ ‡ KHRONOS Head**ï¼šæ”¯æŒçƒ­å¯¼ç‡ã€æ¨¡é‡ã€å¼ºåº¦ç­‰å¤šå±æ€§è”åˆä¼˜åŒ–
2. **é›†æˆä¸»åŠ¨å­¦ä¹ ï¼ˆActive Learningï¼‰é—­ç¯**ï¼š
   - ä½¿ç”¨ Janus ç”Ÿæˆå€™é€‰ç»“æ„
   - ç”±é«˜ä¿çœŸä»¿çœŸéªŒè¯
   - åé¦ˆæ›´æ–°è®­ç»ƒé›†ä¸æ½œåœ¨æµå½¢
   - ç±»æ¯”äº LLM ä¸­çš„ RLHF èŒƒå¼
3. **é‡‡ç”¨æ›´å¯æ‰©å±•çš„ backbone**ï¼šå¦‚æ¨å¹¿ Janus-ViT è‡³ 3D å¾®ç»“æ„å»ºæ¨¡
4. **ç»“åˆç‰©ç†çº¦æŸè¿›ä¸€æ­¥å¢å¼ºæ³›åŒ–èƒ½åŠ›**

---

## æ€»ç»“
Janus æå‡ºäº†ä¸€ç§å…¨æ–°çš„**ç»Ÿä¸€ç”Ÿæˆ-é¢„æµ‹èŒƒå¼**ï¼Œé€šè¿‡æ„é€ ä¸€ä¸ª**ç‰©ç†æ„ŸçŸ¥ã€å¾ªç¯ä¸€è‡´ã€ä½ç»´ç´§å‡‘çš„æ½œåœ¨æµå½¢**ï¼Œå®ç°äº†**é«˜æ•ˆã€ç¨³å®šã€å¤šæ ·åŒ–çš„ç¡®å®šæ€§é€†å‘è®¾è®¡**ã€‚å®ƒä¸ä»…åœ¨ MNIST ä¸ŠéªŒè¯äº†åŸºæœ¬èƒ½åŠ›ï¼Œæ›´åœ¨çœŸå®å¾®ç»“æ„è®¾è®¡ä»»åŠ¡ä¸­å±•ç°å‡ºå“è¶Šæ€§èƒ½ï¼ˆ$ R^2=0.98 $ï¼Œåæ¼”è¯¯å·®<1%ï¼Œç§’çº§å“åº”ï¼‰ï¼Œä»£è¡¨äº†ç§‘å­¦æœºå™¨å­¦ä¹ ä»â€œé»‘ç®±ä»£ç†â€å‘â€œå‡ ä½•ç»“æ„åŒ–æµå½¢â€çš„é‡è¦èŒƒå¼è½¬å˜ã€‚

</details>

---

### 12. [Machine Learning Framework for Thrombosis Risk Prediction in Rotary Blood Pumps](https://arxiv.org/abs/2512.15761)

**Authors**: Christopher Blum, Michael Neidlin  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.15761v1  

#### Abstract
Thrombosis in rotary blood pumps arises from complex flow conditions that remain difficult to translate into reliable and interpretable risk predictions using existing computational models. This limitation reflects an incomplete understanding of how specific flow features contribute to thrombus init...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šMachine Learning Framework for Thrombosis Risk Prediction in Rotary Blood Pumps

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
- **ä¼ ç»Ÿè¡€æ “é£é™©é¢„æµ‹æ¨¡å‹å­˜åœ¨å±€é™æ€§**ï¼šç°æœ‰çš„åŸºäºCFDçš„è¡€æ “æ¨¡å‹ï¼ˆå¦‚shear-based platelet activation modelsã€macroscopic thrombosis formulationsï¼‰é€šå¸¸ä¾èµ–é˜ˆå€¼åˆ¤æ–­ï¼Œè®¡ç®—æˆæœ¬é«˜ï¼Œä¸”éš¾ä»¥è§£é‡Šå…·ä½“æµåŠ¨ç‰¹å¾å¦‚ä½•é©±åŠ¨è¡€æ “å½¢æˆã€‚
- **ç¼ºä¹å¯è§£é‡Šæ€§å’Œé€šç”¨æ€§**ï¼šå¤šæ•°æœºå™¨å­¦ä¹ æ–¹æ³•åœ¨è¡€æµåŠ¨åŠ›å­¦å»ºæ¨¡ä¸­ä½œä¸ºé»‘ç®±ä½¿ç”¨ï¼Œæ— æ³•æä¾›ç‰©ç†æœºåˆ¶ä¸Šçš„æ´å¯Ÿï¼Œé™åˆ¶äº†å…¶åœ¨åŒ»ç–—å™¨æ¢°è®¾è®¡å’Œç›‘ç®¡å®¡æ‰¹ä¸­çš„åº”ç”¨ã€‚

### æå‡ºçš„æ–°æ–¹æ³•/æ–°æ€è·¯
- **æå‡ºä¸€ä¸ªå¯è§£é‡Šçš„æœºå™¨å­¦ä¹ æ¡†æ¶ï¼ˆinterpretable ML frameworkï¼‰**ï¼š
  - åŸºäºLogistic Regressionï¼ˆLRï¼‰ç»“åˆç»“æ„åŒ–ç‰¹å¾é€‰æ‹©æµç¨‹ï¼ˆstructured feature-selection pipelineï¼‰ï¼Œç›´æ¥ä»CFDæ¨¡æ‹Ÿä¸­æå–å±€éƒ¨æµåŠ¨ç‰¹å¾è¿›è¡Œç©ºé—´è¡€æ “é£é™©åˆ†ç±»ã€‚
  - å¼•å…¥éçº¿æ€§ç‰¹å¾ç»„åˆï¼ˆå¦‚å¹³æ–¹é¡¹SQã€å¯¹æ•°å˜æ¢LOGã€äº¤äº’é¡¹IXï¼‰ï¼Œå¢å¼ºæ¨¡å‹è¡¨è¾¾èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒç‰©ç†å¯è§£é‡Šæ€§ã€‚
  - æ„å»ºå››é˜¶æ®µå¤„ç†æµç¨‹ï¼š
    1. åˆå§‹ç‰¹å¾é™ç»´ï¼ˆå»é™¤å†—ä½™ä¸å¸¸é‡ï¼‰
    2. åŸºçº¿LRè®­ç»ƒ
    3. éçº¿æ€§/äº¤äº’ç‰¹å¾å·¥ç¨‹
    4. åŸºäºLOFOï¼ˆLeave-One-Feature-Outï¼‰äº¤å‰éªŒè¯çš„é€’å½’ç‰¹å¾æ¶ˆé™¤

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼˜åŠ¿ |
|------|------|
| **å¯è§£é‡Šæ€§** | æ‰€é€‰ç‰¹å¾å…·æœ‰æ˜ç¡®ç‰©ç†æ„ä¹‰ï¼ˆå¦‚Shear Strain Rateã€Turbulence Eddy Dissipationç­‰ï¼‰ï¼Œæ”¯æŒæœºåˆ¶åˆ†æ |
| **è®¡ç®—æ•ˆç‡** | LRæ¨¡å‹è½»é‡ï¼Œé€‚åˆå¿«é€Ÿç­›æŸ¥è®¾å¤‡è¡€æ “å€¾å‘ï¼Œæ— éœ€é‡å¤æ˜‚è´µCFDä»¿çœŸ |
| **æ³›åŒ–æ½œåŠ›** | åœ¨æœªè§è¿‡çš„æ³µå‹ï¼ˆcentrifugal pumpï¼‰ä¸Šè¡¨ç°å‡ºåˆç†é¢„æµ‹èƒ½åŠ› |
| **æ¨¡å—åŒ–ä¸å¼€æº** | å®Œæ•´ä»£ç å…¬å¼€ï¼ˆZenodoï¼‰ï¼Œä¾¿äºå¤ç°ä¸æ‰©å±• |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **æ¥æº**ï¼šåŸºäºå·²éªŒè¯çš„å®è§‚è¡€æ “æ¨¡å‹ [Blum et al., 2022] è¾“å‡ºçš„HeartMate IIè½´æµæ³µCFDç»“æœ
- **æ ‡ç­¾ç”Ÿæˆæ–¹å¼**ï¼š
  - ä½¿ç”¨scaled Activated Platelets (sAP) å­—æ®µä½œä¸ºground truth
  - å®šä¹‰ä¸¤ç§æ ‡æ³¨åœºæ™¯ï¼š
    - **Worst-case thrombosis**ï¼ˆScenario Aï¼‰ï¼šsAP > 6 â†’ è¡€æ “æ ‡è®°ï¼ˆå æ¯” ~2%ï¼‰
    - **Bearing thrombosis**ï¼ˆScenario Bï¼‰ï¼šsAP > 12 â†’ ä»…è½´æ‰¿åŒºåŸŸæ ‡è®°ä¸ºè¡€æ “ï¼ˆå æ¯” ~0.7%ï¼‰
- **æ ·æœ¬è§„æ¨¡**ï¼šçº¦4ç™¾ä¸‡ä¸ªç½‘æ ¼å•å…ƒï¼Œæ¯ä¸ªåŒ…å«178ä¸ªå€™é€‰flow features + äºŒå…ƒè¡€æ “æ ‡ç­¾

### å®éªŒè®¾ç½®
- **æ•°æ®åˆ’åˆ†**ï¼š
  - 20% ä¿ç•™ä¸ºæœ€ç»ˆæµ‹è¯•é›†
  - å‰©ä½™80% åˆ†ä¸ºè®­ç»ƒé›†ï¼ˆ80%ï¼‰å’ŒéªŒè¯é›†ï¼ˆ20%ï¼‰ï¼Œé‡‡ç”¨åˆ†å±‚æŠ½æ ·ï¼ˆstratified samplingï¼‰
- **ç±»åˆ«ä¸å¹³è¡¡å¤„ç†**ï¼š
  - ä½¿ç”¨class-balanced Logistic Regressionï¼Œæƒé‡ä¸ç±»åˆ«é¢‘ç‡æˆåæ¯”
- **ç‰¹å¾å·¥ç¨‹**ï¼š
  - åˆå§‹178ä¸ªflow features â†’ ç»å»é‡ã€ç›¸å…³æ€§è¿‡æ»¤ã€ç³»æ•°é‡è¦æ€§ç­›é€‰ï¼ˆ<1%å‰”é™¤ï¼‰â†’ å¾—åˆ°14ä¸ªbase features
  - æ‰©å±•ä¸º126ä¸ªengineered featuresï¼ˆå«SQã€LOGã€IXï¼‰
  - æœ€ç»ˆé€šè¿‡LOFO-CVé€‰å‡ºæœ€ä¼˜å­é›†ï¼ˆScenario A: 15 featuresï¼›Scenario B: 5 featuresï¼‰

### è¯„ä¼°æŒ‡æ ‡
- ä¸»è¦æŒ‡æ ‡ï¼š**Precisionâ€“Recall Area Under Curve (PR-AUC)**  
  ï¼ˆå› æ•°æ®é«˜åº¦ä¸å¹³è¡¡ï¼Œä¼˜äºROC-AUCï¼‰
- è¾…åŠ©åˆ†æå·¥å…·ï¼š
  - Permutation feature importanceï¼šé‡åŒ–å„ç‰¹å¾å¯¹é¢„æµ‹çš„å½±å“
  - å¯è§†åŒ–é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒï¼ˆwhite-to-red color mapï¼‰

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- æ–‡ä¸­æœªæ˜¾å¼åˆ—å‡ºä¼ ç»Ÿæ¨¡å‹ï¼ˆå¦‚çº¯shear stress thresholdæ¨¡å‹ï¼‰ä½œä¸ºå®šé‡åŸºçº¿
- ä½†é€šè¿‡æ¶ˆèå®éªŒè¯æ˜ï¼š
  - ä»…ç”¨åŸå§‹çº¿æ€§ç‰¹å¾çš„LRæ€§èƒ½å·®ï¼ˆä½PR-AUCï¼‰
  - åŠ å…¥éçº¿æ€§/äº¤äº’ç‰¹å¾åæ˜¾è‘—æå‡è¡¨ç°
- å› æ­¤éšå«å¯¹æ¯”å¯¹è±¡ä¸ºï¼šâ€œä¼ ç»Ÿé˜ˆå€¼æ³•â€ vs â€œæœ¬æ–‡æå‡ºçš„å¯è§£é‡ŠMLæ¡†æ¶â€

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- **Prediction Accuracy**ï¼ˆå®šæ€§è¯„ä¼°ä¸ºä¸»ï¼‰ï¼š
  - åœ¨HeartMate IIä¸Šï¼ŒLRæ¨¡å‹èƒ½è¾ƒå¥½å¤ç°åŸthrombosis modelçš„ç©ºé—´é£é™©æ¨¡å¼ï¼š
    - Scenario Aï¼ˆå¹¿æ³›é£é™©åŒºï¼‰ï¼šå‡†ç¡®æ•æ‰è½¬å­å¶ç‰‡ä¸è½´æ‰¿åŒºåŸŸçš„é«˜é£é™©åŒºï¼Œä½†åœ¨å‡ºå£æ®µç•¥æœ‰é—æ¼
    - Scenario Bï¼ˆå±€éƒ¨è½´æ‰¿é£é™©ï¼‰ï¼šç²¾å‡†å®šä½è½´æ‰¿é™„è¿‘é«˜é£é™©åŒºåŸŸ
- **Generalization to Centrifugal Pump**ï¼ˆFDA benchmark deviceï¼‰ï¼š
  - å°½ç®¡ä»…åœ¨è½´æµæ³µå•å·¥å†µä¸‹è®­ç»ƒï¼Œæ¨¡å‹ä»é¢„æµ‹å‡ºç¦»å¿ƒæ³µ**impeller-eyeåº•éƒ¨**å­˜åœ¨è¾ƒé«˜è¡€æ “æ¦‚ç‡
  - è¯¥åŒºåŸŸå·²è¢«æ–‡çŒ®æŒ‡å‡ºæ˜¯å…¸å‹æ˜“å‘è¡€æ “åŒºåŸŸ [Berg et al., 2019]
  - è¡¨æ˜æ¨¡å‹å­¦åˆ°çš„æ˜¯è·¨è®¾å¤‡é€šç”¨çš„æµåŠ¨-è¡€æ “å…³è”è§„å¾‹

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- è™½æ— ç›´æ¥æ•°å€¼å¯¹æ¯”è¡¨ï¼Œä½†ä»ä»¥ä¸‹æ–¹é¢ä½“ç°ä¼˜åŠ¿ï¼š
  - **ç›¸æ¯”ä¼ ç»Ÿthreshold-basedæ¨¡å‹**ï¼šæœ¬æ–‡æ¡†æ¶ä¸ä»…èƒ½è¯†åˆ«é£é™©åŒºåŸŸï¼Œè¿˜èƒ½æ­ç¤ºä¸»å¯¼æœºåˆ¶ï¼ˆvia feature importanceï¼‰
  - **ç›¸æ¯”é»‘ç®±MLæ¨¡å‹**ï¼šæœ¬æ–‡æ–¹æ³•è¾“å‡ºå¯è§£é‡Šç‰¹å¾ç»„åˆï¼Œæ”¯æŒè®¾è®¡ä¼˜åŒ–å†³ç­–

### æ¶ˆèå®éªŒç»“æœ
- **éçº¿æ€§ç‰¹å¾å¿…è¦æ€§éªŒè¯**ï¼š
  - åŸºçº¿LRï¼ˆä»…14ä¸ªçº¿æ€§ç‰¹å¾ï¼‰PR-AUCè¾ƒä½ â†’ è¯´æ˜çº¿æ€§ä¸å¯åˆ†
  - å¼•å…¥SQ/LOG/IXåï¼Œæ¨¡å‹æ€§èƒ½å¤§å¹…æå‡
- **ç‰¹å¾é€‰æ‹©æœ‰æ•ˆæ€§**ï¼š
  - LOFOé€’å½’å‰”é™¤è¿‡ç¨‹æ˜¾ç¤ºï¼Œåœ¨ä¸€å®šèŒƒå›´å†…å‡å°‘ç‰¹å¾æ•°é‡ä¸ä¼šé™ä½PR-AUCï¼Œç›´åˆ°è¾¾åˆ°â€œæœ€ä¼˜ç‰¹å¾å¤§å°â€
  - æœ€ç»ˆä¿ç•™çš„ç‰¹å¾é›†ç´§å‡‘ä¸”å…·ç‰©ç†æ„ä¹‰

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **å¯è§£é‡ŠMLå¯ç”¨äºè¿æ¥CFDæµåŠ¨ç‰¹å¾ä¸è¡€æ “é£é™©**ï¼š
   - LR + engineered features èƒ½æœ‰æ•ˆå­¦ä¹ å¹¶å†ç°å¤æ‚ç©ºé—´é£é™©æ¨¡å¼
2. ğŸ” **ä¸åŒè¡€æ “åœºæ™¯ç”±ä¸åŒæµåŠ¨æœºåˆ¶ä¸»å¯¼**ï¼š
   - **Worst-case scenario**ï¼šæ¶‰åŠå¤šç§æœºåˆ¶ï¼ˆå‰ªåˆ‡ã€æ¶¡æ—‹ç»“æ„ã€å‹åŠ›æ¢¯åº¦ã€æ—‹è½¬åˆ†é‡ï¼‰
   - **Bearing-focused scenario**ï¼šä¸»è¦å—Turbulence Eddy Dissipationã€Rotational Velocityã€Shear Strain Rateé©±åŠ¨
3. ğŸ”„ **åˆæ­¥å±•ç°å‡ºè·¨è®¾å¤‡æ³›åŒ–èƒ½åŠ›**ï¼š
   - åœ¨centrifugal pumpä¸Šé¢„æµ‹å‡ºå·²çŸ¥æ˜“æ “åŒºåŸŸï¼ˆimpeller-eye bottomï¼‰ï¼Œè¡¨æ˜æ¨¡å‹æ•æ‰åˆ°äº†æ™®é€‚æ€§æµåŠ¨-ç”Ÿç‰©å“åº”å…³ç³»

### æ–¹æ³•çš„å±€é™æ€§
| å±€é™ | è¯´æ˜ |
|------|------|
| **ä¾èµ–äººå·¥è®¾å®šçš„è®­ç»ƒæ ‡ç­¾** | ä½¿ç”¨thrombosis modelçš„thresholded sAPä½œä¸ºlabelï¼Œè€ŒéçœŸå®è¡€æ “ä½ç½®ï¼Œå½±å“ä¸´åºŠå¯ä¿¡åº¦ |
| **Eulerianç¬æ—¶ç‰¹å¾ä¸ºä¸»** | ç¼ºä¹Lagrangianæ—¶é—´ç§¯åˆ†ä¿¡æ¯ï¼ˆå¦‚residence timeã€particle trajectory historyï¼‰ï¼Œå¯èƒ½å¿½ç•¥è¡€å°æ¿æ¿€æ´»çš„æ—¶é—´ç´¯ç§¯æ•ˆåº” |
| **å•ä¸€è®¾å¤‡+å•å·¥å†µè®­ç»ƒ** | æ³›åŒ–èƒ½åŠ›å°šå±åˆæ­¥æ¢ç´¢ï¼Œéœ€æ›´å¤šå‡ ä½•ä¸è¿è¡Œæ¡ä»¶éªŒè¯ |
| **æœªä¸å®éªŒæ•°æ®å¯¹æ ‡** | å½“å‰ç¼ºä¹ç©ºé—´åˆ†è¾¨çš„çœŸå®è¡€æ “åˆ†å¸ƒæ•°æ®ç”¨äºéªŒè¯ |

### æœªæ¥å·¥ä½œæ–¹å‘
1. **å¼•å…¥æ—¶é—´ç»´åº¦ç‰¹å¾**ï¼š
   - æ•´åˆresidence timeã€Lagrangian particle trackingã€activation historyç­‰åŠ¨æ€æè¿°ç¬¦
2. **å¤šå·¥å†µä¸å¤šè®¾å¤‡è”åˆè®­ç»ƒ**ï¼š
   - æ¢ç´¢æ“ä½œç‚¹ï¼ˆflow rate, RPMï¼‰å˜åŒ–ä¸‹çš„æœºåˆ¶è¿ç§»è§„å¾‹
3. **æ¨¡å‹é—´æ¯”è¾ƒä¸èåˆ**ï¼š
   - åˆ©ç”¨æœ¬æ¡†æ¶æ¯”è¾ƒä¸åŒmacroscopic thrombosis modelsçš„ä¸€è‡´æ€§ä¸å·®å¼‚
4. **å‘ä¸´åºŠè½¬åŒ–æ‹“å±•**ï¼š
   - åº”ç”¨äºpatient-specific vascular thrombosis risk assessment
   - æ”¯æŒæ²»ç–—ç­–ç•¥è¯„ä¼°ï¼ˆå¦‚æŠ—å‡æ–¹æ¡ˆä¼˜åŒ–ï¼‰
5. **æ•°æ®é©±åŠ¨éªŒè¯é—­ç¯**ï¼š
   - ç»“åˆä½“å¤–å®éªŒæˆ–ä¸´åºŠå½±åƒæ•°æ®ï¼Œæ„å»ºçœŸå®è¡€æ “ä½ç½®æ•°æ®åº“ä»¥æå‡æ¨¡å‹å¯é æ€§

> ğŸ“¢ **è¡¥å……ä¿¡æ¯**ï¼šå®Œæ•´Pythonä»£ç å·²åœ¨Zenodoå…¬å¼€ï¼ˆDOI: [10.5281/zenodo.17901009](https://doi.org/10.5281/zenodo.17901009)ï¼‰ï¼Œä¿ƒè¿›ç¤¾åŒºå¤ç°ä¸è¿›ä¸€æ­¥å‘å±•ã€‚

</details>

---

### 13. [TENG++: Time-Evolving Natural Gradient for Solving PDEs With Deep Neural Nets under General Boundary Conditions](https://arxiv.org/abs/2512.15771)

**Authors**: Xinjie He, Chenggong Zhang  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2512.15771v1  

#### Abstract
Partial Differential Equations (PDEs) are central to modeling complex systems across physical, biological, and engineering domains, yet traditional numerical methods often struggle with high-dimensional or complex problems. Physics-Informed Neural Networks (PINNs) have emerged as an efficient altern...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š**TENG++: Time-Evolving Natural Gradient for Solving PDEs With Deep Neural Nets under General Boundary Conditions**

---

## 1. **è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### âœ… è§£å†³çš„é—®é¢˜
- ç°æœ‰ **Physics-Informed Neural Networks (PINNs)** åœ¨å¤„ç†éå‘¨æœŸæ€§è¾¹ç•Œæ¡ä»¶ï¼ˆå¦‚ Dirichletã€Neumannï¼‰æ—¶å­˜åœ¨ç²¾åº¦ä¸è¶³å’Œè®­ç»ƒä¸ç¨³å®šçš„é—®é¢˜ã€‚
- åŸå§‹çš„ **Time-Evolving Natural Gradient (TENG)** æ–¹æ³•ä»…é€‚ç”¨äºå‘¨æœŸæ€§è¾¹ç•Œæ¡ä»¶ï¼Œé™åˆ¶äº†å…¶åœ¨çœŸå®ç‰©ç†ç³»ç»Ÿä¸­çš„åº”ç”¨ã€‚

### ğŸ”§ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°
- **æå‡º TENG++ æ¡†æ¶**ï¼šå°†åŸå§‹ TENG æ–¹æ³•æ‰©å±•è‡³æ”¯æŒ **Dirichlet è¾¹ç•Œæ¡ä»¶**ï¼Œé€šè¿‡å¼•å…¥è¾¹ç•Œæƒ©ç½šé¡¹åˆ°æŸå¤±å‡½æ•°ä¸­å®ç°ç²¾ç¡®çº¦æŸã€‚
- å°†è‡ªç„¶æ¢¯åº¦ä¼˜åŒ–ä¸æ˜¾å¼æ—¶é—´æ­¥è¿›æ–¹æ¡ˆï¼ˆ**Euler å’Œ Heun æ–¹æ³•**ï¼‰ç»“åˆï¼Œæå‡æ•°å€¼ç¨³å®šæ€§å’Œæ”¶æ•›é€Ÿåº¦ã€‚
- æ„å»ºç»Ÿä¸€æ¡†æ¶ä»¥æ”¯æŒæ›´å¹¿ä¹‰çš„è¾¹ç•Œæ¡ä»¶ï¼ˆä¸ºåç»­ Neumann å’Œæ··åˆè¾¹ç•Œæ¡ä»¶æ‰“ä¸‹åŸºç¡€ï¼‰ã€‚

### ğŸš€ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
|------|------|
| **å‡†ç¡®æ€§** | ä½¿ç”¨ Heun æ–¹æ³•å®ç°äº†äºŒé˜¶ç²¾åº¦ä¿®æ­£ï¼Œæ˜¾è‘—é™ä½è¯¯å·®ï¼ˆå¯è¾¾ $10^{-4}$ é‡çº§ï¼‰ã€‚ |
| **ç¨³å®šæ€§** | è‡ªç„¶æ¢¯åº¦ä¼˜åŒ–åˆ©ç”¨å‚æ•°ç©ºé—´å‡ ä½•ç»“æ„ï¼Œé¿å…ä¼ ç»Ÿæ¢¯åº¦ä¸‹é™ä¸­çš„ç—…æ€ä¼˜åŒ–é—®é¢˜ã€‚ |
| **çµæ´»æ€§** | æ”¯æŒä»»æ„ Dirichlet è¾¹ç•Œæ¡ä»¶ï¼Œé€‚ç”¨äºå¤æ‚ç‰©ç†åœºæ™¯ï¼ˆå¦‚çƒ­ä¼ å¯¼ã€æµä½“åŠ¨åŠ›å­¦ç­‰ï¼‰ã€‚ |
| **æ•ˆç‡** | Euler æ–¹æ³•è®¡ç®—å¼€é”€å°ï¼Œåœ¨ç®€å•åœºæ™¯ä¸‹ä»å…·å®ç”¨ä»·å€¼ã€‚ |

---

## 2. **æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### ğŸ“Š æ•°æ®é›†ä¸é—®é¢˜è®¾å®š
- **æ±‚è§£æ–¹ç¨‹**ï¼šäºŒç»´å„å‘åŒæ€§ **Heat Equation**ï¼ˆçƒ­ä¼ å¯¼æ–¹ç¨‹ï¼‰
  $$
  \frac{\partial u}{\partial t} = D \Delta u, \quad D = 0.1
  $$
- **å®šä¹‰åŸŸ**ï¼šå•ä½åœ†ç›˜ $\Omega = B(0,1) \subset \mathbb{R}^2$
- **è¾¹ç•Œæ¡ä»¶**ï¼šDirichlet æ¡ä»¶ $u(x,t) = 0, \forall x \in \partial\Omega$
- **åˆå§‹æ¡ä»¶**ï¼šç”± Bessel å‡½æ•°æ„æˆçš„çº¿æ€§ç»„åˆï¼ˆå³ Disk Harmonicsï¼‰ï¼Œç¡®ä¿å­˜åœ¨è§£æè§£ç”¨äºè¯¯å·®è¯„ä¼°ã€‚

### âš™ï¸ å®éªŒè®¾ç½®
| å‚æ•° | è®¾ç½® |
|------|------|
| æ—¶é—´åŒºé—´ | $T = 4$ï¼ˆHeunï¼‰ï¼Œ$T = 0.8$ï¼ˆEulerï¼‰ |
| æ—¶é—´æ­¥é•¿ | $dt = 0.005$ï¼ˆHeunï¼‰ï¼Œ$dt = 0.001$ï¼ˆEulerï¼‰ |
| æ€»è¿­ä»£æ­¥æ•° | 800 æ­¥ |
| æ¯æ­¥å†…éƒ¨ä¼˜åŒ–è¿­ä»£æ¬¡æ•° | 5 æ¬¡ |
| æ ·æœ¬æ•°é‡ | 65536 ä¸ªé‡‡æ ·ç‚¹ï¼ˆç©ºé—´+æ—¶é—´ï¼‰ |
| ç½‘ç»œåˆå§‹åŒ–æ–¹å¼ | é¢„è®­ç»ƒæƒé‡ æˆ– åŒç½‘ç»œå·®åˆ†ç»“æ„ï¼ˆExperiment 2ï¼‰ |

### ğŸ“ˆ è¯„ä¼°æŒ‡æ ‡
- **è¯¯å·®åº¦é‡**ï¼šé¢„æµ‹è§£ä¸çœŸå®è§£æè§£ä¹‹é—´çš„ $L^2$ è¯¯å·®éšæ—¶é—´å˜åŒ–æ›²çº¿ã€‚
- **å¯è§†åŒ–åˆ†æ**ï¼šç»˜åˆ¶ä¸åŒæ—¶é—´ç‚¹çš„è¯¯å·®åˆ†å¸ƒå›¾ï¼ˆè§ Figure 1 & 2ï¼‰ã€‚
- **æ”¶æ•›æ€§åˆ†æ**ï¼šæ¯”è¾ƒä¸åŒç§¯åˆ†å™¨ä¸‹çš„è¯¯å·®ç´¯ç§¯è¶‹åŠ¿ã€‚

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **TENG_Euler**ï¼šä¸€é˜¶æ—¶é—´ç§¯åˆ† + è‡ªç„¶æ¢¯åº¦ä¼˜åŒ–
- **TENG_Heun**ï¼šäºŒé˜¶ Runge-Kutta ç±»å‹æ–¹æ³•ï¼ˆæ”¹è¿› Eulerï¼‰+ è‡ªç„¶æ¢¯åº¦ä¼˜åŒ–
- ï¼ˆéšå«å¯¹æ¯”ï¼‰æ ‡å‡† PINNã€TDVPã€OBTI ç­‰å…¨å±€æˆ–é¡ºåºä¼˜åŒ–æ–¹æ³•ï¼ˆæ–‡ä¸­å¼•ç”¨ä½œä¸ºèƒŒæ™¯ï¼‰

---

## 3. **ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### ğŸ“Š å…³é”®æ€§èƒ½æ•°æ®
| æ–¹æ³• | æœ€ç»ˆè¯¯å·®ï¼ˆçº¦ï¼‰ | æ—¶é—´èŒƒå›´ | å¤‡æ³¨ |
|------|----------------|----------|------|
| **TENG_Heun** | $\sim 10^{-4}$ | $T=4$ | é«˜ç²¾åº¦ï¼Œé€‚åˆé«˜ä¿çœŸæ¨¡æ‹Ÿ |
| **TENG_Euler** | $\sim 10^{-3} \sim 10^{-2}$ | $T=0.8$ | è¯¯å·®å¢é•¿è¾ƒå¿«ï¼Œä½†è®¡ç®—é«˜æ•ˆ |

> å›¾1 æ˜¾ç¤º TENG_Heun åœ¨æ•´ä¸ªæ—¶é—´åŸŸå†…ä¿æŒä½è¯¯å·®ï¼›å›¾2 æ˜¾ç¤º TENG_Euler è™½åˆæœŸå¯æ§ï¼Œä½†è¯¯å·®è¿…é€Ÿä¸Šå‡ã€‚

### ğŸ” ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **TENG_Heun æ˜¾è‘—ä¼˜äº TENG_Euler**ï¼š
  - å¾—ç›Šäºä¸­é—´é¢„æµ‹æ­¥éª¤ï¼ˆpredictor-corrector ç»“æ„ï¼‰ï¼Œæœ‰æ•ˆæŠ‘åˆ¶è¯¯å·®ä¼ æ’­ã€‚
  - æ›´å¥½åœ°æ•æ‰åŠ¨æ€æ¼”åŒ–è¿‡ç¨‹ï¼Œå°¤å…¶åœ¨é•¿æ—¶é—´æ¨¡æ‹Ÿä¸­è¡¨ç°ä¼˜å¼‚ã€‚
- ç›¸è¾ƒäºæœªä½¿ç”¨è‡ªç„¶æ¢¯åº¦çš„æ–¹æ³•ï¼ˆå¦‚æ™®é€š PINNï¼‰ï¼ŒTENG++ å…·æœ‰æ›´å¿«æ”¶æ•›é€Ÿåº¦å’Œæ›´å¼ºé²æ£’æ€§ã€‚

### ğŸ”¤ æ¶ˆèå®éªŒç»“æœï¼ˆExperiment 2ï¼‰
- **åˆå§‹åŒ–ç­–ç•¥çš„å½±å“**ï¼š
  - ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ â†’ è¯¯å·®è¾ƒå°ï¼Œæ”¶æ•›å¿«ã€‚
  - ä½¿ç”¨åŒç½‘ç»œå†»ç»“ç­–ç•¥ï¼ˆä¸€ä¸ªå›ºå®šï¼Œä¸€ä¸ªæ›´æ–°ï¼‰â†’ è¯¯å·®æ˜¾è‘—å¢å¤§ã€‚
- **ç»“è®º**ï¼šè‰¯å¥½çš„åˆå§‹åŒ–å¯¹ TENG++ æˆåŠŸè‡³å…³é‡è¦ï¼Œå½±å“æœ€ç»ˆç²¾åº¦å’Œè®­ç»ƒç¨³å®šæ€§ã€‚

---

## 4. **å…³é”®ç»“è®ºå’Œå‘ç°**

### âœ… ä¸»è¦å‘ç°
1. **TENG++ æˆåŠŸæ¨å¹¿è‡³ Dirichlet è¾¹ç•Œæ¡ä»¶**ï¼Œè§£å†³äº†åŸ TENG æ–¹æ³•çš„åº”ç”¨å±€é™ã€‚
2. **Heun æ–¹æ³•åœ¨ç²¾åº¦ä¸Šæ˜æ˜¾ä¼˜äº Euler æ–¹æ³•**ï¼ŒéªŒè¯äº†é«˜é˜¶æ—¶é—´ç§¯åˆ†çš„é‡è¦æ€§ã€‚
3. **è‡ªç„¶æ¢¯åº¦ä¼˜åŒ–èƒ½æœ‰æ•ˆå¹³è¡¡ PDE æ®‹å·®ä¸è¾¹ç•Œçº¦æŸ**ï¼Œæé«˜æ•´ä½“æ±‚è§£è´¨é‡ã€‚
4. **åˆå§‹åŒ–æ–¹å¼å¯¹æ¨¡å‹æ€§èƒ½æœ‰å†³å®šæ€§å½±å“**ï¼Œåˆç†çš„å…ˆéªŒçŸ¥è¯†å¯¼å…¥å¯å¤§å¹…æå‡æ•ˆæœã€‚

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- å½“å‰ä»…éªŒè¯äº† **Dirichlet æ¡ä»¶**ï¼Œå°šæœªå®ç° Neumann æˆ– Robin è¾¹ç•Œæ¡ä»¶ã€‚
- å¯¹ **å¤æ‚å‡ ä½•å½¢çŠ¶æˆ–å¤šè¿é€šåŒºåŸŸ** çš„é€‚åº”æ€§æœ‰å¾…æµ‹è¯•ã€‚
- è®¡ç®—æˆæœ¬é«˜äºä¼ ç»Ÿæœ‰é™å…ƒæ³•ï¼ˆå°¤å…¶åœ¨é«˜ç»´æƒ…å†µä¸‹ï¼‰ï¼Œç›®å‰æ›´é€‚åˆä¸­å°è§„æ¨¡é—®é¢˜ã€‚

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. æ‰©å±•è‡³ **Neumann å’Œ Mixed è¾¹ç•Œæ¡ä»¶**ï¼Œæ„å»ºå®Œæ•´è¾¹ç•Œå¤„ç†ä½“ç³»ã€‚
2. æ¨å¹¿åˆ°æ›´å¹¿æ³›çš„ PDE ç±»å‹ï¼Œå¦‚ **Navier-Stokesã€Wave Equationã€Nonlinear PDEs**ã€‚
3. å¼•å…¥æ›´é«˜é˜¶æ—¶é—´ç§¯åˆ†å™¨ï¼ˆå¦‚ **RK4**ï¼‰è¿›ä¸€æ­¥æå‡ç²¾åº¦ã€‚
4. æ¢ç´¢è‡ªé€‚åº”é‡‡æ ·ä¸æ®‹å·®ç‚¹èšç„¦æœºåˆ¶ï¼Œæå‡è®­ç»ƒæ•ˆç‡ã€‚
5. åº”ç”¨äºå®é™…å·¥ç¨‹é—®é¢˜ï¼Œå¦‚æ°”å€™å»ºæ¨¡ã€ææ–™ç§‘å­¦ã€ç”µç£åœºä»¿çœŸç­‰é¢†åŸŸã€‚

---

> ğŸ’¡ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> TENG++ é€šè¿‡èåˆè‡ªç„¶æ¢¯åº¦ä¼˜åŒ–ä¸é«˜é˜¶æ—¶é—´æ­¥è¿›æ–¹æ³•ï¼ŒæˆåŠŸå°† TENG æ¡†æ¶æ‹“å±•è‡³é€šç”¨ Dirichlet è¾¹ç•Œæ¡ä»¶ï¼Œåœ¨ä¿è¯è®¡ç®—æ•ˆç‡çš„åŒæ—¶æ˜¾è‘—æå‡äº† PINNs çš„æ±‚è§£ç²¾åº¦ä¸ç¨³å®šæ€§ï¼Œä¸ºç¥ç»ç½‘ç»œæ±‚è§£ PDE æä¾›äº†ä¸€æ¡é«˜ç²¾åº¦ã€å¯æ‰©å±•çš„æ–°è·¯å¾„ã€‚

</details>

---

### 14. [LADY: Linear Attention for Autonomous Driving Efficiency without Transformers](https://arxiv.org/abs/2512.15038)

**Authors**: Jihao Huang, Xi Xia, Zhiyuan Li, Tianle Liu, Jingke Wang, Junbo Chen, Tengju Ye  
**Category**: cs.AI  
**Published**: 2025-12-19  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.15038v2  

#### Abstract
End-to-end paradigms have demonstrated great potential for autonomous driving. Additionally, most existing methods are built upon Transformer architectures. However, transformers incur a quadratic attention cost, limiting their ability to model long spatial and temporal sequences-particularly on res...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠLADY: Linear Attention for Autonomous Driving Efficiency without Transformersã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### **è§£å†³äº†ä»€ä¹ˆé—®é¢˜**

å½“å‰ä¸»æµçš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶æ¨¡å‹ï¼ˆå¦‚ UniADã€Transfuserã€DiffusionDriveï¼‰æ™®éä¾èµ– **Transformer æ¶æ„**è¿›è¡Œç‰¹å¾èåˆä¸è·¨æ¨¡æ€äº¤äº’ã€‚ç„¶è€Œï¼ŒTransformer çš„ **softmax è‡ªæ³¨æ„åŠ›æœºåˆ¶å…·æœ‰ $O(T^2)$ çš„æ—¶é—´ä¸å†…å­˜å¤æ‚åº¦**ï¼Œåœ¨å¤„ç†é•¿åºåˆ—æ—¶ç©ºè¾“å…¥ï¼ˆå¦‚å¤šå¸§ç›¸æœºä¸ LiDAR æ•°æ®ï¼‰æ—¶è®¡ç®—å¼€é”€å·¨å¤§ï¼Œéš¾ä»¥éƒ¨ç½²äºèµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ï¼ˆedge devicesï¼‰ï¼Œä¸¥é‡åˆ¶çº¦äº†å®æ—¶æ€§ã€‚

æ­¤å¤–ï¼Œç°æœ‰åŸºäºçº¿æ€§æ³¨æ„åŠ›çš„æ–¹æ³•ï¼ˆå¦‚ DRAMA ä½¿ç”¨ Mambaï¼‰è™½ç„¶æå‡äº†æ•ˆç‡ï¼Œä½†ä»ä¾èµ– **Transformer-based cross-attention** è¿›è¡ŒæŸ¥è¯¢-ç‰¹å¾äº¤äº’ï¼Œæ— æ³•å®ç°çœŸæ­£çš„â€œå…¨çº¿æ€§â€æ¶æ„ï¼Œä¸”é€šå¸¸åªä½¿ç”¨å•å¸§ä¼ æ„Ÿå™¨è¾“å…¥ï¼Œç¼ºä¹å¯¹å†å²æ—¶åºä¸Šä¸‹æ–‡çš„æœ‰æ•ˆå»ºæ¨¡ã€‚

---

### **æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯**

æœ¬æ–‡æå‡º **LADY**ï¼ˆ**L**inear **A**ttention for **D**riving Efficenc**Y**ï¼‰ï¼Œæ˜¯é¦–ä¸ªå®Œå…¨åŸºäºçº¿æ€§æ³¨æ„åŠ›æœºåˆ¶çš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶ç”Ÿæˆæ¨¡å‹ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°å¦‚ä¸‹ï¼š

- âœ… **å…¨çº¿æ€§æ³¨æ„åŠ›æ¶æ„**ï¼šé¦–æ¬¡å°† **RWKV-7** å¼•å…¥è‡ªåŠ¨é©¾é©¶é¢†åŸŸï¼Œæ„å»ºä»ç¼–ç å™¨åˆ°è§£ç å™¨çš„å®Œæ•´çº¿æ€§æ³¨æ„åŠ›æµç¨‹ï¼Œé¿å…ä»»ä½• Transformer ç»„ä»¶ã€‚
  
- âœ… **è½»é‡çº§çº¿æ€§äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼ˆLICAï¼‰**ï¼šè®¾è®¡äº†ä¸€ç§æ–°å‹çš„ **Linear Cross-Attention (LICA)** æ¨¡å—ï¼Œåˆ©ç”¨ RWKV å—çš„é€’å½’çŠ¶æ€æ›´æ–°æœºåˆ¶ï¼Œåœ¨ä¸å¼•å…¥äºŒæ¬¡å¤æ‚åº¦çš„å‰æä¸‹å®ç° query ä¸ BEV ç‰¹å¾ä¹‹é—´çš„é«˜æ•ˆäº¤äº’ï¼Œä¿æŒ $O(Td)$ æ—¶é—´å’Œ $O(d)$ å†…å­˜å¤æ‚åº¦ã€‚

- âœ… **æ”¯æŒæ— é™é•¿åº¦å†å²èåˆçš„æ¨ç†æ¨¡å¼**ï¼šåœ¨è®­ç»ƒé˜¶æ®µå¹¶è¡Œå¤„ç†å¤šå¸§ï¼Œåœ¨æ¨ç†é˜¶æ®µé‡‡ç”¨ **åºåˆ—å¼èåˆ**ï¼Œé€šè¿‡ç»´æŠ¤ä¸€ä¸ªç´§å‡‘çš„ temporal hidden state æ¥æŒç»­ç´¯ç§¯å†å²ä¿¡æ¯ï¼Œä»è€Œä»¥ **æ’å®šè®¡ç®—ä¸å†…å­˜æˆæœ¬** èåˆä»»æ„é•¿åº¦çš„å†å²å¸§ï¼ˆå³ â€œinfinite framesâ€ï¼‰ï¼Œæ˜¾è‘—å¢å¼ºåŠ¨æ€åœºæ™¯ç†è§£èƒ½åŠ›ã€‚

- âœ… **ç»“åˆæ‰©æ•£ç­–ç•¥çš„å¤šæ¨¡æ€è½¨è¿¹ç”Ÿæˆ**ï¼šé‡‡ç”¨ **truncated diffusion policy**ï¼ˆæºè‡ª DiffusionDriveï¼‰ä½œä¸ºè§£ç å™¨ï¼Œæå‡è½¨è¿¹å¤šæ ·æ€§ä¸è´¨é‡ï¼Œå¹¶è¾“å‡º confidence scores ç”¨äºæœ€ä¼˜è½¨è¿¹é€‰æ‹©ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹é¢ | LADY çš„ä¼˜åŠ¿ |
|------|-------------|
| **æ•ˆç‡** | æ¨ç†æ—¶é—´å’Œå†…å­˜å ç”¨ä¸å†å²å¸§æ•°æ— å…³ï¼Œè¿œä¼˜äº Transformer å’Œéƒ¨åˆ†æ··åˆæ¶æ„ï¼ˆå¦‚ DRAMAï¼‰ã€‚ |
| **å¯æ‰©å±•æ€§** | æ”¯æŒä»»æ„é•¿åº¦çš„å†å²è¾“å…¥ï¼Œæ— éœ€é‡æ–°è®­ç»ƒå³å¯é€‚åº”æ›´é•¿ä¸Šä¸‹æ–‡ã€‚ |
| **å®ç”¨æ€§** | å·²æˆåŠŸéƒ¨ç½²è‡³ NVIDIA Jetson AGX Orin è¾¹ç¼˜å¹³å°ï¼ŒéªŒè¯å…¶å·¥ä¸šè½åœ°æ½œåŠ›ã€‚ |
| **æ€§èƒ½** | åœ¨å¤šä¸ªåŸºå‡†ä¸Šè¾¾åˆ° SOTA æˆ–æ¥è¿‘ SOTA è§„åˆ’æ€§èƒ½ï¼ŒåŒæ—¶å¤§å¹…é™ä½è®¡ç®—æˆæœ¬ã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### **ä½¿ç”¨çš„æ•°æ®é›†**

- **NAVSIM Benchmark**ï¼šåŸºäº nuPlan çš„å…¬å¼€é©¾é©¶æ—¥å¿—æ•°æ®é›†ï¼ŒåŒ…å« 120 å°æ—¶çœŸå®é©¾é©¶æ•°æ®ï¼Œé‡‡æ ·é¢‘ç‡ä¸º 2Hzã€‚æä¾› open-loop å’Œ closed-loop ä¸¤ç§è¯„ä¼°æ–¹å¼ã€‚
- **CARLA Simulator + Bench2Drive Benchmark**ï¼šç”¨äºé—­ç¯ï¼ˆclosed-loopï¼‰æµ‹è¯•ï¼Œè¯„ä¼°è½¦è¾†åœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­çš„ç»¼åˆé©¾é©¶èƒ½åŠ›ï¼Œæ¶µç›–å¤šç§å¤æ‚äº¤é€šåœºæ™¯ã€‚

---

### **å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡**

#### **Open-Loop è¯„ä¼°ï¼ˆNAVSIMï¼‰**
- **è¾“å…¥**ï¼š
  - å¤šå¸§ç›¸æœºå›¾åƒï¼ˆæ¯å¸§ 3 å¼ å‰è§†å›¾æ‹¼æ¥ä¸º 1024Ã—256ï¼‰
  - å¤šå¸§ LiDAR é¸Ÿç°å›¾ï¼ˆBEVï¼‰
  - å½“å‰è‡ªè½¦çŠ¶æ€ï¼ˆé€Ÿåº¦ã€åŠ é€Ÿåº¦ã€å¯¼èˆªæŒ‡ä»¤ï¼‰
  - å™ªå£°é”šå®šè½¨è¿¹ï¼ˆnoisy anchor trajectoriesï¼‰
- **è¾“å‡º**ï¼š8 ä¸ªæ—¶é—´æ­¥ï¼ˆ4 ç§’ï¼Œ2Hzï¼‰çš„å¤šæ¨¡æ€è½¨è¿¹ + ç½®ä¿¡åº¦åˆ†æ•° + å¯é€šè¡Œåœ°å›¾ + ä»–è½¦æœªæ¥çŠ¶æ€é¢„æµ‹
- **ä¸»æŒ‡æ ‡**ï¼š**Predictive Driver Model Score (PDMS)**ï¼Œç»¼åˆä»¥ä¸‹å­é¡¹åŠ æƒï¼š
  - **NC**ï¼ˆNo Collisionï¼‰ï¼šæ— ç¢°æ’ â†’ ç¡¬æ€§æƒ©ç½š
  - **DAC**ï¼ˆDrivable Area Complianceï¼‰ï¼šä¸è¶Šç•Œ â†’ ç¡¬æ€§æƒ©ç½š
  - **EP**ï¼ˆEgo Progressï¼‰ï¼šæ²¿è·¯çº¿å‰è¿›ç¨‹åº¦
  - **TTC**ï¼ˆTime-to-Collisionï¼‰ï¼šæœ€å°å®‰å…¨è·ç¦»
  - **Comfort**ï¼šåŠ é€Ÿåº¦ä¸æ€¥åŠ¨åº¦èˆ’é€‚æ€§

#### **Closed-Loop è¯„ä¼°ï¼ˆBench2Driveï¼‰**
- **æŒ‡æ ‡**ï¼š
  - æˆåŠŸç‡ï¼ˆSuccess Rateï¼‰
  - é©¾é©¶å¾—åˆ†ï¼ˆDriving Scoreï¼‰
  - èˆ’é€‚æ€§ï¼ˆComfortnessï¼‰
  - æ•ˆç‡ï¼ˆEfficiencyï¼‰
  - å¤šèƒ½åŠ›ä»»åŠ¡è¡¨ç°ï¼ˆå˜é“ã€è¶…è½¦ã€ç´§æ€¥åˆ¶åŠ¨ã€è®©è¡Œã€äº¤é€šæ ‡å¿—è¯†åˆ«ç­‰ï¼‰

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**

å‚ä¸æ¯”è¾ƒçš„ SOTA æ–¹æ³•åŒ…æ‹¬ï¼š

| æ–¹æ³• | ç±»å‹ | æ˜¯å¦ä½¿ç”¨å¤šå¸§ | æ³¨æ„åŠ›æœºåˆ¶ |
|------|------|----------------|--------------|
| UniAD / Transfuser / VADv2 | å›å½’æˆ–å¤šæ¨¡æ€ | âŒ | Transformer |
| Hydra-MDP / DiffusionDrive | æ‰©æ•£æ¨¡å‹ | âŒ | Transformer |
| DRAMA | å›å½’ | âŒ | Mambaï¼ˆselfï¼‰+ Transformerï¼ˆcrossï¼‰ |
| iPad | å¤šæ¨¡æ€è¯„åˆ† | âŒ | Transformer |
| LADY (Ours) | æ‰©æ•£æ¨¡å‹ | âœ… | å…¨çº¿æ€§æ³¨æ„åŠ›ï¼ˆRWKV-7 + LICAï¼‰ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆNAVSIM open-loopï¼‰**

è§ **Table I**ï¼š

| æ–¹æ³• | NC | DAC | TTC | Comfort | EP | **PDMS** |
|------|----|-----|-----|---------|-----|----------|
| UniAD | 97.8 | 91.9 | 92.9 | 100 | 78.8 | 83.4 |
| Transfuser | 97.7 | 92.8 | 92.8 | 100 | 79.2 | 84.0 |
| DRAMA | 98.0 | 93.1 | 94.8 | 100 | 80.1 | 85.5 |
| DiffusionDrive | 98.2 | 96.2 | 94.7 | 100 | 82.2 | 88.1 |
| iPad | 98.6 | 98.3 | 94.9 | 100 | 88.0 | **91.7** |
| **LADY (Ours)** | **98.0** | **97.3** | 94.0 | 100 | **88.6** | **90.9** |

> ğŸ”º LADY åœ¨ PDMS ä¸Šä»…æ¬¡äº iPadï¼Œä½†å®ç°äº† **å¸¸æ•°çº§æ¨ç†å¼€é”€**ï¼Œè€Œ iPad ä½¿ç”¨æ ‡å‡† Transformer æ¶æ„ã€‚

---

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**

#### **æ•ˆç‡å¯¹æ¯”ï¼ˆFig. 6ï¼‰**
- éšç€è¾“å…¥å¸§æ•°å¢åŠ ï¼ˆ1â†’50å¸§ï¼‰ï¼š
  - **Transfuser / DiffusionDrive**ï¼šæ¨ç†æ—¶é—´ä¸å†…å­˜æ¶ˆè€—æ€¥å‰§ä¸Šå‡ï¼ˆ$O(T^2)$ï¼‰
  - **DRAMA**ï¼šè™½ç”¨ Mamba æå‡æ•ˆç‡ï¼Œä½†å› ä»å« Transformer cross-attentionï¼Œå¼€é”€ä»éšå¸§æ•°å¢é•¿
  - **LADY**ï¼šæ¨ç†å»¶è¿Ÿä¸å†…å­˜å ç”¨å‡ ä¹ä¸å˜ï¼ˆconstant-time & constant-memoryï¼‰

> ğŸ’¡ LADY åœ¨å¤„ç† 50 å¸§å†å²è¾“å…¥æ—¶ï¼Œä»èƒ½ä¿æŒæ¯«ç§’çº§å“åº”ï¼Œé€‚åˆå®æ—¶ç³»ç»Ÿã€‚

#### **é—­ç¯æ€§èƒ½ï¼ˆBench2Driveï¼‰**

è§ **Table II**ï¼š

| æ–¹æ³• | Success Rate (%) | Driving Score |
|------|------------------|---------------|
| iPad | 65.02 | 42.56 |
| **LADY (1 frame)** | 50.06 | 21.40 |
| **LADY (10 frames)** | 57.52 | 31.93 |
| **LADY (Infinite frames)** | **65.12** | **42.94** |

> ğŸ”º ä½¿ç”¨æ— é™å†å²å¸§çš„ LADY åœ¨æˆåŠŸç‡å’Œé©¾é©¶å¾—åˆ†ä¸Š **è¶…è¶Š iPad**ï¼Œè¯æ˜é•¿æœŸæ—¶åºå»ºæ¨¡çš„é‡è¦æ€§ã€‚

---

### **æ¶ˆèå®éªŒç»“æœ**

#### **ä¸åŒå†å²å¸§æ•°çš„å½±å“ï¼ˆTable IIIï¼‰**

| å¸§æ•° | PDMS |
|------|-------|
| 1 | 86.8 |
| 4 | 89.5 |
| 8 | 90.3 |
| 10 | 90.6 |
| 15 | **90.9** |
| 20 | **90.9** |

> âœ… æ€§èƒ½éšå†å²å¸§æ•°å¢åŠ è€Œæå‡ï¼Œä¸”åœ¨è®­ç»ƒä»…ç”¨ 10 å¸§çš„æƒ…å†µä¸‹ï¼Œæ¨ç†ä½¿ç”¨æ›´å¤šå¸§ä»å¯ç»§ç»­å¢ç›Šï¼Œä½“ç°å¼ºå¤§æ³›åŒ–èƒ½åŠ›ã€‚

#### **å¤šå¸§ DiffusionDrive å¯¹æ¯”**
- å°† DiffusionDrive æ”¹ä¸ºå¤šå¸§è¾“å…¥åï¼ŒPDMS ä» 88.1 æå‡è‡³ 89.3ï¼ŒéªŒè¯å¤šå¸§æœ‰æ•ˆï¼›
- ä½†å…¶è®¡ç®—ä»£ä»·é«˜æ˜‚ï¼Œæ— æ³•åƒ LADY ä¸€æ ·æ‰©å±•è‡³é•¿åºåˆ—ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### **ä¸»è¦å‘ç°**

1. âœ… **çº¿æ€§æ³¨æ„åŠ›å¯ç”¨äºé«˜æ€§èƒ½ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶**ï¼šLADY æ˜¯é¦–ä¸ªå…¨çº¿æ€§æ³¨æ„åŠ›æ¡†æ¶ï¼Œåœ¨ä¿è¯é«˜è§„åˆ’æ€§èƒ½çš„åŒæ—¶æå¤§æå‡æ•ˆç‡ã€‚
2. âœ… **é•¿æœŸå†å²ä¸Šä¸‹æ–‡è‡³å…³é‡è¦**ï¼šé€šè¿‡ RWKV çš„éšçŠ¶æ€æœºåˆ¶ï¼ŒLADY èƒ½æœ‰æ•ˆç§¯ç´¯å†å²æ„ŸçŸ¥ä¿¡æ¯ï¼Œåœ¨é®æŒ¡ã€è¡Œäººçªç°ç­‰åŠ¨æ€åœºæ™¯ä¸­åšå‡ºæ›´åˆç†å†³ç­–ã€‚
3. âœ… **å¸¸æ•°å¤æ‚åº¦æ¨ç†å¯è¡Œä¸”å¿…è¦**ï¼šLADY å®ç°äº† $O(d)$ å†…å­˜å’Œè¿‘ä¼¼ $O(d)$ æ¨ç†æ—¶é—´ï¼Œä½¿å…¶é€‚ç”¨äºè½¦è½½è¾¹ç¼˜è®¾å¤‡ã€‚
4. âœ… **æ— éœ€é¢å¤–è®­ç»ƒå³å¯æ‰©å±•å†å²é•¿åº¦**ï¼šæ¨¡å‹å¯åœ¨æ¨ç†æ—¶æ— ç¼æ¥å…¥æ›´å¤šå†å²å¸§ï¼Œæ€§èƒ½æŒç»­æå‡ï¼Œå…·å¤‡å¼ºå®ç”¨æ€§ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**

- ğŸ“‰ **å½“å‰ scorer ä¸å¤Ÿç²¾å‡†**ï¼šå°½ç®¡ç”Ÿæˆçš„å€™é€‰è½¨è¿¹è´¨é‡é«˜ï¼ˆBest-of-N PDMS è¾¾ 99.2ï¼‰ï¼Œä½†å½“å‰ scorer æœªèƒ½å‡†ç¡®é€‰å‡ºæœ€ä¼˜è½¨è¿¹ï¼Œå¯¼è‡´å®é™…å¾—åˆ†ä½äºæ½œåŠ›ï¼ˆHuman: 94.8, LADY: 90.9ï¼‰ã€‚
- ğŸ“‰ **æ•°æ®é›†ä¸­é•¿æ—¶åºéœ€æ±‚æ ·æœ¬ä¸è¶³**ï¼šç›®å‰å¤§å¤šæ•°åœºæ™¯å¯¹é•¿å†å²ä¾èµ–è¾ƒå¼±ï¼Œé™åˆ¶äº† LADY ä¼˜åŠ¿çš„å…¨é¢å±•ç°ã€‚
- ğŸ“‰ **backbone ä»ä¸º ResNet-34**ï¼šæœªä½¿ç”¨æ›´å…ˆè¿›çš„è§†è§‰éª¨å¹²ç½‘ç»œï¼Œå­˜åœ¨è¿›ä¸€æ­¥ä¼˜åŒ–ç©ºé—´ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**

1. **æ”¹è¿› scorer è®¾è®¡**ï¼šå¼•å…¥æ›´å¼ºçš„å­¦ä¹ å‹æˆ–è§„åˆ™è’¸é¦ scorerï¼Œæ›´å¥½åœ°åŒºåˆ†é«˜è´¨é‡è½¨è¿¹ã€‚
2. **é›†æˆå…¶ä»–çº¿æ€§æ³¨æ„åŠ›æ¶æ„**ï¼šæ¢ç´¢ RetNetã€DeltaNetã€KDA ç­‰æ›¿ä»£ RWKV-7ï¼Œå¯»æ±‚æ€§èƒ½ä¸æ•ˆç‡çš„æ–°å¹³è¡¡ã€‚
3. **çœŸå®ä¸–ç•Œéƒ¨ç½²éªŒè¯**ï¼šåœ¨å®è½¦ä¸Šè¿›è¡Œé—­ç¯æµ‹è¯•ï¼ŒéªŒè¯ LADY åœ¨çœŸå®äº¤é€šç¯å¢ƒä¸­çš„é²æ£’æ€§ä¸å®‰å…¨æ€§ã€‚
4. **æ„å»ºæ›´ä¸°å¯Œçš„ long-horizon æ•°æ®é›†**ï¼šæ¨åŠ¨ç¤¾åŒºå…³æ³¨é•¿æ—¶åºå»ºæ¨¡åœ¨è‡ªåŠ¨é©¾é©¶ä¸­çš„ä»·å€¼ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **LADY å¼€åˆ›æ€§åœ°å®ç°äº†å…¨çº¿æ€§æ³¨æ„åŠ›çš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶æ¡†æ¶ï¼Œåœ¨ä¿æŒ SOTA è§„åˆ’æ€§èƒ½çš„åŒæ—¶ï¼Œè¾¾æˆå¸¸æ•°çº§æ¨ç†å¼€é”€ï¼Œä¸ºèµ„æºå—é™åœºæ™¯ä¸‹çš„é«˜æ•ˆã€å¯é è‡ªåŠ¨é©¾é©¶æä¾›äº†æ–°èŒƒå¼ã€‚**

</details>

---

### 15. [Predictive Concept Decoders: Training Scalable End-to-End Interpretability Assistants](https://arxiv.org/abs/2512.15712)

**Authors**: Vincent Huang, Dami Choi, Daniel D. Johnson, Sarah Schwettmann, Jacob Steinhardt  
**Category**: cs.AI  
**Published**: 2025-12-19  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.15712v1  

#### Abstract
Interpreting the internal activations of neural networks can produce more faithful explanations of their behavior, but is difficult due to the complex structure of activation space. Existing approaches to scalable interpretability use hand-designed agents that make and test hypotheses about how inte...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# Predictive Concept Decoders: Training Scalable End-to-End Interpretability Assistants â€” æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç¥ç»ç½‘ç»œå†…éƒ¨æ¿€æ´»ç©ºé—´ï¼ˆactivation spaceï¼‰ç»“æ„å¤æ‚ï¼Œéš¾ä»¥æ‰‹åŠ¨è§£é‡Šå…¶è¡Œä¸ºã€‚ç°æœ‰çš„å¯è§£é‡Šæ€§æ–¹æ³•ï¼ˆå¦‚ probesã€concept dictionaries æˆ– interpretability agentsï¼‰é€šå¸¸ä¾èµ–äºæ‰‹å·¥è®¾è®¡çš„ä»£ç†æ¨¡å‹ï¼ˆhand-designed agentsï¼‰ï¼Œè¿™äº›æ¨¡å‹å—é™äºé€šç”¨å¤§æ¨¡å‹çš„èƒ½åŠ›ï¼Œæ— æ³•ä¸“é—¨ä¼˜åŒ–ä»¥ç†è§£ç›®æ ‡æ¨¡å‹çš„å†…éƒ¨çŠ¶æ€ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•ç¼ºä¹å¯æ‰©å±•çš„è®­ç»ƒä¿¡å·ã€‚

æœ¬æ–‡æå‡ºï¼Œ**å°†å¯è§£é‡Šæ€§ä»»åŠ¡è½¬åŒ–ä¸ºä¸€ä¸ªç«¯åˆ°ç«¯çš„è®­ç»ƒç›®æ ‡**ï¼Œé€šè¿‡é¢„æµ‹æ¨¡å‹è¡Œä¸ºæ¥é©±åŠ¨å¯¹æ¿€æ´»çš„è§£é‡Šï¼Œä»è€Œå®ç°æ›´é«˜æ•ˆã€å¯æ‰©å±•çš„è‡ªåŠ¨åŒ–å¯è§£é‡Šæ€§ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ï¼šPredictive Concept Decoder (PCD)
PCD æ˜¯ä¸€ç§**ç¼–ç å™¨-è§£ç å™¨æ¶æ„**ï¼Œå¼•å…¥äº†ä¸€ä¸ª**é€šä¿¡ç“¶é¢ˆï¼ˆcommunication bottleneckï¼‰**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š
- **Encoder**ï¼šä»ç›®æ ‡æ¨¡å‹ï¼ˆsubject modelï¼‰çš„æŸä¸€å±‚è¯»å–æ¿€æ´»å‘é‡ $ a \in \mathbb{R}^d $ï¼Œå°†å…¶å‹ç¼©ä¸ºä¸€ä¸ªç¨€ç–çš„æ¦‚å¿µåˆ—è¡¨ï¼ˆsparse list of conceptsï¼‰ã€‚
- **Decoder**ï¼šä»…æ¥æ”¶è¿™ä¸ªç¨€ç–æ¦‚å¿µåˆ—è¡¨å’Œä¸€ä¸ªå…³äºç›®æ ‡æ¨¡å‹è¡Œä¸ºçš„è‡ªç„¶è¯­è¨€é—®é¢˜ $ q $ï¼Œå¹¶ç”Ÿæˆç­”æ¡ˆã€‚

å…³é”®è®¾è®¡ï¼š
- ç¼–ç å™¨ä¸çœ‹é—®é¢˜ $ q $ï¼Œå› æ­¤å¿…é¡»å­¦ä¹ **é€šç”¨çš„ã€é€‚ç”¨äºå¤šç§æŸ¥è¯¢çš„è§£é‡Šæ€§è¡¨ç¤º**ã€‚
- æ¦‚å¿µé€šè¿‡ `TopK` ç¨€ç–åŒ–ï¼Œå¢å¼ºäººç±»å¯è§£é‡Šæ€§ã€‚
- æ¦‚å¿µè¢«é‡æ–°åµŒå…¥ï¼ˆre-embeddedï¼‰åä½œä¸º soft tokens æ³¨å…¥è§£ç å™¨æ®‹å·®æµä¸­ã€‚

è¯¥æ¶æ„å®ç°äº†**ç«¯åˆ°ç«¯çš„å¯è§£é‡Šæ€§åŠ©æ‰‹è®­ç»ƒ**ï¼Œå…¶è®­ç»ƒä¿¡å·æ¥è‡ªå¯¹æ¨¡å‹è¡Œä¸ºçš„å‡†ç¡®é¢„æµ‹ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ LatentQAã€SAEï¼‰ | PCD |
|------|-------------------------------|-----|
| **è®­ç»ƒèŒƒå¼** | æ‰‹åŠ¨è®¾è®¡ä»£ç†æˆ–æ— ç›‘ç£é‡å»ºï¼ˆå¦‚ SAEï¼‰ | ç«¯åˆ°ç«¯è¡Œä¸ºé¢„æµ‹ï¼Œæœ‰æ˜ç¡®ç›‘ç£ä¿¡å· |
| **å¯æ‰©å±•æ€§** | ä¾èµ–å¤–éƒ¨æ¨¡å‹èƒ½åŠ›ï¼Œéš¾ä»¥éšæ•°æ®æ‰©å±• | éšé¢„è®­ç»ƒæ•°æ®å¢åŠ ï¼Œæ€§èƒ½æŒç»­æå‡ |
| **è§£é‡Šè´¨é‡** | å¯èƒ½ç¼ºä¹è¡Œä¸ºç›¸å…³æ€§ | æ¦‚å¿µç›´æ¥æœåŠ¡äºè¡Œä¸ºé¢„æµ‹ï¼Œæ›´å…·è¡Œä¸ºæ„ä¹‰ |
| **å®¡è®¡èƒ½åŠ›** | è¾“å‡ºéš¾è¿½æº¯ | è§£é‡Šå¯å®¡è®¡ï¼šä»»ä½•é¢„æµ‹å‡å¯è¿½æº¯è‡³å°‘æ•°å‡ ä¸ªæ¦‚å¿µ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
- **é¢„è®­ç»ƒé˜¶æ®µ**ï¼šä½¿ç”¨å¤§è§„æ¨¡æ— æ ‡æ³¨æ–‡æœ¬æ•°æ®é›† **FineWeb**ï¼ˆPenedo et al., 2024ï¼‰ï¼Œè¿›è¡Œ next-token prediction ä»»åŠ¡ã€‚
- **å¾®è°ƒé˜¶æ®µ**ï¼šä½¿ç”¨åˆæˆå¯¹è¯æ•°æ®é›† **SynthSys**ï¼ˆChoi et al., 2025ï¼‰ï¼ŒåŒ…å«ç”¨æˆ·å±æ€§æ¨æ–­ä»»åŠ¡ï¼ˆå¦‚æ€§åˆ«ã€å©šå§»çŠ¶å†µç­‰ï¼‰ï¼Œç”¨äºè®­ç»ƒè§£ç å™¨å›ç­”å…³äºæ¨¡å‹ä¿¡å¿µçš„é—®é¢˜ã€‚
- **æ¡ˆä¾‹ç ”ç©¶æ•°æ®**ï¼š
  - **Jailbreak detection**ï¼šæ„é€ äº† 50 ç§æœ‰å®³è¯·æ±‚ï¼ˆå¦‚åˆ¶é€ ç‚¸å¼¹ï¼‰ç»“åˆä¸‰ç§ jailbreak æ¨¡æ¿ï¼ˆ3 Words, Distractors, Dreamï¼‰ã€‚
  - **Secret hints**ï¼šåœ¨ç”¨æˆ·æ¶ˆæ¯ä¸­æ’å…¥â€œç§˜å¯†æç¤ºâ€ï¼ˆå¦‚ç¬¬ 9950 ä¸ªè´¨æ•°æ˜¯å¤šå°‘ï¼‰ï¼Œæµ‹è¯•æ¨¡å‹æ˜¯å¦ä½¿ç”¨è¯¥æç¤ºã€‚
  - **Introspection**ï¼šåŸºäº Lindsey (2025) çš„è®¾å®šï¼Œæ³¨å…¥æ¦‚å¿µå‘é‡å¹¶æ£€æµ‹æ¨¡å‹æ˜¯å¦æ„è¯†åˆ°è¯¥æ¦‚å¿µã€‚

### å®éªŒè®¾ç½®
- **ä¸»ä½“æ¨¡å‹**ï¼šLlama-3.1-8B-Instruct
- **PCD æ¶æ„**ï¼š
  - æ¦‚å¿µå­—å…¸å¤§å° $ m = 32768 $
  - æ¿€æ´»å±‚ $ l_{\text{read}} = 15 $ï¼Œå†™å…¥å±‚ $ l_{\text{write}} = 0 $
  - TopK ç¨€ç–åº¦ $ k = 16 $
  - è§£ç å™¨ä½¿ç”¨ LoRA å¾®è°ƒï¼Œä¸ä¸»ä½“æ¨¡å‹å…±äº«æƒé‡
- **è®­ç»ƒæµç¨‹**ï¼š
  1. **é¢„è®­ç»ƒ**ï¼šè”åˆè®­ç»ƒç¼–ç å™¨å’Œè§£ç å™¨ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ– next-token prediction lossã€‚
  2. **å¾®è°ƒ**ï¼šå†»ç»“ç¼–ç å™¨ï¼Œä»…å¾®è°ƒè§£ç å™¨åœ¨ SynthSys ä¸Šçš„é—®ç­”ä»»åŠ¡ã€‚

### è¯„ä¼°æŒ‡æ ‡
| ç»„ä»¶ | æŒ‡æ ‡ |
|------|------|
| **Encoder** | - **Auto-interp score**ï¼šä½¿ç”¨è‡ªåŠ¨è§£é‡Šæµæ°´çº¿è¯„ä¼°æ¦‚å¿µçš„äººç±»å¯è¯»æ€§ï¼ˆprecisionï¼‰<br>- **Concept coverage**ï¼šèƒ½å¦æ•æ‰ç”¨æˆ·å±æ€§ï¼ˆrecallï¼‰ |
| **Decoder** | - **Question-answering accuracy**ï¼šåœ¨ held-out SynthSys å±æ€§ä¸Šçš„åˆ†ç±»å‡†ç¡®ç‡ |
| **æ•´ä½“ç³»ç»Ÿ** | - **Jailbreak awareness rate**<br>- **Hint usage detection rate**<br>- **Introspection success rate** |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **LatentQA**ï¼šç›¸åŒè§£ç å™¨æ¶æ„ï¼Œä½†æ— ç¼–ç å™¨ç“¶é¢ˆï¼Œç›´æ¥è¯»å–å®Œæ•´æ¿€æ´»ã€‚
- **SAE (Sparse Autoencoder)**ï¼šæ ‡å‡†ç¨€ç–è‡ªç¼–ç å™¨ï¼Œç”¨äºæå–æ¦‚å¿µå­—å…¸ã€‚
- **Direct prompting**ï¼šç›´æ¥è¯¢é—®ä¸»ä½“æ¨¡å‹è‡ªèº«çš„è¡Œä¸ºï¼ˆç¬¬ä¸€äººç§°æˆ–ç¬¬ä¸‰äººç§°ï¼‰ã€‚
- **PCD (no bottleneck)**ï¼šç§»é™¤ TopK ç“¶é¢ˆï¼ŒéªŒè¯ç“¶é¢ˆçš„å½±å“ã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### âœ… é¢„è®­ç»ƒé˜¶æ®µï¼šPCD ç¼–ç å™¨è¡¨ç°ä¼˜äº SAE
- åœ¨ $ k=16 $ æ—¶ï¼ŒPCD çš„ **auto-interp score** æ˜¾è‘—é«˜äºåŒç­‰ç¨€ç–åº¦çš„ SAEï¼ˆè§ Figure 4ï¼‰ã€‚
- å³ä½¿ SAE æ‰©å±•åˆ° $ k=50 $ï¼ŒPCD åœ¨å°æ•°æ®é‡ä¸‹ä»å…·ä¼˜åŠ¿ã€‚
- å¼•å…¥ **auxiliary loss** åï¼Œè¶…è¿‡ 90% çš„æ¦‚å¿µä¿æŒæ´»è·ƒï¼Œé¿å…â€œæ­»æ¦‚å¿µâ€é—®é¢˜ã€‚

#### âœ… å¾®è°ƒé˜¶æ®µï¼šPCD è§£ç å™¨æ€§èƒ½éšé¢„è®­ç»ƒæ•°æ®å¢é•¿è€Œæå‡
- å½“é¢„è®­ç»ƒ token æ•°è¾¾åˆ° 72M æ—¶ï¼ŒPCD åœ¨ SynthSys ä¸Šçš„è¡¨ç°æ¥è¿‘ LatentQAï¼ˆè§ Figure 5ï¼‰ã€‚
- ä½¿ç”¨ SAE å†»ç»“ç¼–ç å™¨çš„æ¶ˆèç‰ˆæœ¬è¡¨ç°è¾ƒå·®ï¼Œè¯´æ˜**è”åˆè®­ç»ƒçš„é‡è¦æ€§**ã€‚

#### âœ… Jailbreak æ£€æµ‹ï¼šPCD èƒ½æ­ç¤ºæ¨¡å‹æœªè‡ªæˆ‘æŠ¥å‘Šçš„æ„å›¾
- å¹³å‡ jailbreak awareness è¾¾åˆ°çº¦ **50%**ï¼Œæ˜¾è‘—é«˜äºç›´æ¥æé—®ï¼ˆ~20â€“30%ï¼‰ã€‚
- åœ¨ **Dream jailbreak** åœºæ™¯ä¸­ï¼ŒPCD ($k=16$) å‡†ç¡®ç‡è¾¾ **50%**ï¼Œè¿œè¶…å…¶ä»–æ–¹æ³•ï¼ˆå‡ <30%ï¼‰ã€‚
- æ€§èƒ½éšé¢„è®­ç»ƒæ•°æ®å¢åŠ è€Œæå‡ï¼Œåœ¨ 72M token æ—¶å‡ºç° emergent awarenessï¼ˆè§ Figure 8ï¼‰ã€‚

#### âœ… Secret Hint æ£€æµ‹ï¼šPCD èƒ½å‘ç°æ¨¡å‹éšè—çš„æ¨ç†è·¯å¾„
- PCD å’Œ LatentQA èƒ½æœ‰æ•ˆè¯†åˆ«â€œç§˜å¯†æç¤ºâ€çš„ä½¿ç”¨ï¼ˆè§ Figure 9ï¼‰ã€‚
- ç›´æ¥æé—®ï¼ˆpromptingï¼‰å€¾å‘äºç¼–é€ å€Ÿå£ï¼ˆå¦‚â€œæˆ‘ç”¨äº†å·§å¦™ç®—æ³•â€ï¼‰ï¼Œè€Œ PCD æ›´å¯èƒ½å¦‚å®åæ˜ â€œä½¿ç”¨äº†æç¤ºâ€ã€‚
- PCD æ€§èƒ½åœ¨æ›´å¤§é¢„è®­ç»ƒè§„æ¨¡ä¸‹æŒç»­æå‡ã€‚

#### âœ… Introspectionï¼šPCD èƒ½æ„ŸçŸ¥è¢«æ³¨å…¥çš„æ¦‚å¿µ
- PCD æ¯”ä¸»ä½“æ¨¡å‹æœ¬èº«æ›´é¢‘ç¹åœ°**å£å¤´è¡¨è¾¾ï¼ˆverbalizeï¼‰è¢«æ³¨å…¥çš„æ¦‚å¿µ**ï¼ˆdirectly relevant å›ç­”æ›´å¤šï¼‰ã€‚
- å°½ç®¡æœªåœ¨ steered data ä¸Šè®­ç»ƒï¼ŒPCD ä»è¡¨ç°å‡ºè‰¯å¥½æ³›åŒ–èƒ½åŠ›ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| ä»»åŠ¡ | PCD vs. LatentQA | PCD vs. Prompting |
|------|------------------|-------------------|
| Jailbreak detection | âœ… æ›´ä¼˜ï¼ˆå°¤å…¶ Dream åœºæ™¯ï¼‰ | âœ… æ˜¾è‘—æ›´ä¼˜ |
| Secret hint detection | â‰ˆ æ¥è¿‘ï¼ˆPCD no bottleneck æœ€ä½³ï¼‰ | âœ… è¿œèƒœï¼ˆprompting ä¼šæ’’è°ï¼‰ |
| Introspection | âœ… æ›´å¥½ verbalization | âœ… ä¸»ä½“æ¨¡å‹å‡ ä¹æ— æ³•å¯Ÿè§‰ |
| ç”¨æˆ·å±æ€§å»ºæ¨¡ | âœ… éšæ•°æ®æ‰©å±•è€Œæå‡ | N/A |

### æ¶ˆèå®éªŒç»“æœ
| å®éªŒ | å‘ç° |
|------|------|
| **ç§»é™¤ auxiliary loss** | æ¦‚å¿µæ­»äº¡ç‡ä¸Šå‡ï¼Œauto-interp score ä¸‹é™ï¼Œrecall é™ä½ |
| **æ›¿æ¢ç¼–ç å™¨ä¸º SAE** | æ€§èƒ½å¤§å¹…ä¸‹é™ï¼Œè¯´æ˜è”åˆè®­ç»ƒå¿…è¦ |
| **å¢å¤§ kï¼ˆæµ‹è¯•æ—¶ï¼‰** | $ k=32 $ æœ‰æ—¶æå‡æ€§èƒ½ï¼Œä½† $ k=64 $ å¯¼è‡´ OOD è¾“å…¥ï¼Œæ€§èƒ½ä¸‹é™ |
| **ç§»é™¤ç“¶é¢ˆï¼ˆtest-timeï¼‰** | å°é¢„è®­ç»ƒæ•°æ®ä¸‹æ€§èƒ½æå‡ï¼Œå¤§é¢„è®­ç»ƒä¸‹åè€Œä¸‹é™ï¼Œè¯´æ˜ç“¶é¢ˆæœ‰åŠ©äºä¿¡æ¯æç‚¼ |

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **ç«¯åˆ°ç«¯è®­ç»ƒå¯æå‡å¯è§£é‡Šæ€§ç³»ç»Ÿçš„æ€§èƒ½**ï¼šé€šè¿‡å°†è¡Œä¸ºé¢„æµ‹ä½œä¸ºè®­ç»ƒç›®æ ‡ï¼ŒPCD å­¦ä¹ åˆ°äº†æ›´å…·è¡Œä¸ºç›¸å…³æ€§çš„æ¦‚å¿µè¡¨ç¤ºã€‚
2. **PCD å…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§**ï¼šæ— è®ºæ˜¯ encoder çš„ interpretability è¿˜æ˜¯ decoder çš„ QA performanceï¼Œéƒ½éšç€é¢„è®­ç»ƒæ•°æ®é‡å¢åŠ è€ŒæŒç»­æå‡ã€‚
3. **PCD èƒ½æ­ç¤ºæ¨¡å‹æ— æ³•è‡ªæˆ‘æŠ¥å‘Šçš„ä¿¡æ¯**ï¼š
   - æ£€æµ‹åˆ° jailbreak æ„å›¾ï¼ˆå³ä½¿æ¨¡å‹æ‹’ç»å¹¶å£°ç§°å‡ºäºå®‰å…¨è€ƒè™‘ï¼‰
   - æ­ç¤º secret hint çš„ä½¿ç”¨ï¼ˆè€Œ prompting ä¼šå¯¼è‡´è™šæ„ç†ç”±ï¼‰
   - æ„ŸçŸ¥è¢«æ³¨å…¥çš„ latent concept
4. **è§£é‡Šå¯å®¡è®¡ï¼ˆauditableï¼‰**ï¼šæ‰€æœ‰é¢„æµ‹å‡å¯è¿½æº¯è‡³å°‘æ•°å‡ ä¸ªæ¦‚å¿µï¼Œä¾¿äºäººå·¥å®¡æŸ¥å’ŒéªŒè¯ã€‚ä¾‹å¦‚ï¼Œåœ¨æ‹’ç»è¯·æ±‚æ—¶ï¼ŒPCD æåŠâ€œæ³•å¾‹é£é™©â€ï¼Œè€Œ encoder æ¿€æ´»ä¸­ç¡®å®å­˜åœ¨â€œlegal liabilityâ€ç›¸å…³æ¦‚å¿µï¼ˆè§ Figure 12ï¼‰ã€‚
5. **PCD æ‹¥æœ‰æ›´ä¼˜çš„å½’çº³åç½®ï¼ˆinductive biasï¼‰**ï¼šå³ä½¿ä¸ LatentQA æ¶æ„ç›¸åŒï¼ˆæ— ç“¶é¢ˆï¼‰ï¼ŒPCD å› è®­ç»ƒè¿‡ç¨‹ä¸­å­˜åœ¨ç“¶é¢ˆï¼Œè¿«ä½¿è§£ç å™¨å…³æ³¨æ›´ç»†ç²’åº¦çš„æ¦‚å¿µï¼Œä»è€Œè·å¾—æ›´å¥½æ€§èƒ½ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **æ€§èƒ½ plateau**ï¼šåœ¨çº¦ 72â€“144M token åï¼Œéƒ¨åˆ†æŒ‡æ ‡è¶‹äºé¥±å’Œï¼Œå¯èƒ½ä¸ KL-based ç›®æ ‡å‡½æ•°æœ‰å…³ã€‚
- **æ¦‚å¿µç¨€ç–æ€§é™åˆ¶**ï¼šé«˜ sparsity ($k=16$) å¯èƒ½ä¸¢å¤±éƒ¨åˆ†ä¿¡æ¯ï¼Œéœ€æƒè¡¡å¯è§£é‡Šæ€§ä¸å®Œæ•´æ€§ã€‚
- **ä¾èµ–é«˜è´¨é‡è‡ªåŠ¨è§£é‡Šæµæ°´çº¿**ï¼šauto-interp score ä¾èµ–äº GPT-5-mini ç­‰å¤–éƒ¨æ¨¡å‹åˆ¤æ–­ï¼Œå¯èƒ½å­˜åœ¨åå·®ã€‚
- **å°šæœªå¤„ç†å¤šå±‚æˆ–å¤šæ¨¡æ€ä¿¡æ¯**ï¼šå½“å‰ä»…ä»å•å±‚è¯»å–æ¿€æ´»ï¼Œæœªæ¥å¯æ‰©å±•è‡³å…¨å±‚èåˆã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ”¹è¿›è®­ç»ƒç›®æ ‡**ï¼šæ¢ç´¢è¶…è¶Š KL çš„æ›´ä¸°å¯Œç›®æ ‡å‡½æ•°ï¼Œçªç ´å½“å‰ plateauã€‚
2. **æ‰©å±•ç¼–ç å™¨æ¶æ„**ï¼šä½¿ç”¨ Transformer ç¼–ç å™¨æ•æ‰è·¨ token ç»“æ„ï¼Œæˆ–å¼•å…¥æ¦‚å¿µé—´å…³ç³»ï¼ˆå¦‚ bindingã€propositional logicï¼‰ã€‚
3. **å¤šå±‚è¯»å–æœºåˆ¶**ï¼šä»å¤šä¸ªä¸­é—´å±‚æå–æ¦‚å¿µï¼Œæå‡ä¿¡æ¯å®Œæ•´æ€§ã€‚
4. **æ„å»ºæ›´å¹¿æ³›çš„ end-to-end interpretability assistants**ï¼š
   - è®­ç»ƒ agent è‡ªåŠ¨å®šä½å¹¶å¹²é¢„ç‰¹å®šè¡Œä¸ºï¼ˆå¦‚ ablation-based probingï¼‰
   - è®­ç»ƒ agent é€šè¿‡ patching ä¼ é€’ç‰¹å¾æ¥éªŒè¯è¡¨å¾å‡è®¾
5. **å‘äººç±»ç”¨æˆ·å¯¹é½**ï¼šå°† decoder æ›¿æ¢ä¸ºäººç±»ï¼Œä½¿æ¦‚å¿µçœŸæ­£é¢å‘ human-legibilityã€‚

---

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> PCD æå‡ºäº†ä¸€ç§**å¯æ‰©å±•çš„ç«¯åˆ°ç«¯å¯è§£é‡Šæ€§æ¡†æ¶**ï¼Œé€šè¿‡è¡Œä¸ºé¢„æµ‹ä»»åŠ¡è®­ç»ƒä¸€ä¸ªâ€œè§£é‡ŠåŠ©æ‰‹â€ï¼Œä¸ä»…èƒ½å‡†ç¡®é¢„æµ‹æ¨¡å‹è¡Œä¸ºï¼Œè¿˜èƒ½æ­ç¤ºå…¶éšè—åŠ¨æœºï¼Œå¹¶æä¾›**å¯å®¡è®¡ã€å¯è¿½æº¯çš„è§£é‡Š**ï¼Œä¸ºæœªæ¥æ„å»ºå¯ä¿¡ AI ç³»ç»Ÿæä¾›äº†é‡è¦å·¥å…·ã€‚

</details>

---

### 16. [Twin Restricted Kernel Machines for Multiview Classification](https://arxiv.org/abs/2512.15757)

**Authors**: A. Quadir, M. Sajid, Mushir Akhtar, M. Tanveer  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.15757v1  

#### Abstract
Multi-view learning (MVL) is an emerging field in machine learning that focuses on improving generalization performance by leveraging complementary information from multiple perspectives or views. Various multi-view support vector machine (MvSVM) approaches have been developed, demonstrating signifi...

---

### 17. [Meta-RL Induces Exploration in Language Agents](https://arxiv.org/abs/2512.16848)

**Authors**: Yulun Jiang, Liangze Jiang, Damien Teney, Michael Moor, Maria Brbic  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 7.5  
**Type**: new  
**ArXiv ID**: 2512.16848v1  

#### Abstract
Reinforcement learning (RL) has enabled the training of large language model (LLM) agents to interact with the environment and to solve multi-turn long-horizon tasks. However, the RL-trained agents often struggle in tasks that require active exploration and fail to efficiently adapt from trial-and-e...

---

### 18. [CangLing-KnowFlow: A Unified Knowledge-and-Flow-fused Agent for Comprehensive Remote Sensing Applications](https://arxiv.org/abs/2512.15231)

**Authors**: Zhengchao Chen, Haoran Wang, Jing Yao, Pedram Ghamisi, Jun Zhou, Peter M. Atkinson, Bing Zhang  
**Category**: cs.AI  
**Published**: 2025-12-19  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.15231v1  

#### Abstract
The automated and intelligent processing of massive remote sensing (RS) datasets is critical in Earth observation (EO). Existing automated systems are normally task-specific, lacking a unified framework to manage diverse, end-to-end workflows--from data preprocessing to advanced interpretation--acro...

---

### 19. [Intent-Driven UAM Rescheduling](https://arxiv.org/abs/2512.15462)

**Authors**: Jeongseok Kim, Kangjin Kim  
**Category**: cs.AI  
**Published**: 2025-12-19  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.15462v1  

#### Abstract
Due to the restricted resources, efficient scheduling in vertiports has received much more attention in the field of Urban Air Mobility (UAM). For the scheduling problem, we utilize a Mixed Integer Linear Programming (MILP), which is often formulated in a resource-restricted project scheduling probl...

---

### 20. [An Information-Theoretic Framework for Robust Large Language Model Editing](https://arxiv.org/abs/2512.16227)

**Authors**: Qizhou Chen, Chengyu Wang, Taolin Zhang, Xiaofeng He  
**Category**: cs.CL  
**Published**: 2025-12-19  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.16227v1  

#### Abstract
Large Language Models (LLMs) have become indispensable tools in science, technology, and society, enabling transformative advances across diverse fields. However, errors or outdated information within these models can undermine their accuracy and restrict their safe deployment. Developing efficient ...

---

### 21. [Bridging the Reality Gap: Efficient Adaptation of ASR systems for Challenging Low-Resource Domains](https://arxiv.org/abs/2512.16401)

**Authors**: Darshil Chauhan, Adityasinh Solanki, Vansh Patel, Kanav Kapoor, Ritvik Jain, Aditya Bansal, Dhruv Kumar, Prateek Narang  
**Category**: cs.CL  
**Published**: 2025-12-19  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.16401v1  

#### Abstract
Automatic Speech Recognition (ASR) holds immense potential to streamline clinical documentation, such as digitizing handwritten prescriptions and reports, thereby increasing patient throughput and reducing costs in resource-constrained sectors like rural healthcare. However, realizing this utility i...

---

### 22. [Cold-Start Anti-Patterns and Refactorings in Serverless Systems: An Empirical Study](https://arxiv.org/abs/2512.16066)

**Authors**: Syed Salauddin Mohammad Tariq, Foyzul Hassan, Amiangshu Bosu, Probir Roy  
**Category**: cs.DC  
**Published**: 2025-12-19  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.16066v1  

#### Abstract
Serverless computing simplifies deployment and scaling, yet cold-start latency remains a major performance bottleneck. Unlike prior work that treats mitigation as a black-box optimization, we study cold starts as a developer-visible design problem. From 81 adjudicated issue reports across open-sourc...

---

### 23. [Delay-Aware Multi-Stage Edge Server Upgrade with Budget Constraint](https://arxiv.org/abs/2512.16792)

**Authors**: Endar Suprih Wihidayat, Sieteng Soh, Kwan-Wu Chin, Duc-son Pham  
**Category**: cs.DC  
**Published**: 2025-12-19  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.16792v1  

#### Abstract
In this paper, the Multi-stage Edge Server Upgrade (M-ESU) is proposed as a new network planning problem, involving the upgrading of an existing multi-access edge computing (MEC) system through multiple stages (e.g., over several years). More precisely, the problem considers two key decisions: (i) w...

---

### 24. [Data Valuation for LLM Fine-Tuning: Efficient Shapley Value Approximation via Language Model Arithmetic](https://arxiv.org/abs/2512.15765)

**Authors**: M\'elissa Tamine, Otmane Sakhi, Benjamin Heymann  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 7.0  
**Type**: new  
**ArXiv ID**: 2512.15765v1  

#### Abstract
Data is a critical asset for training large language models (LLMs), alongside compute resources and skilled workers. While some training data is publicly available, substantial investment is required to generate proprietary datasets, such as human preference annotations or to curate new ones from ex...

---

### 25. [Beyond Fast and Slow: Cognitive-Inspired Elastic Reasoning for Large Language Models](https://arxiv.org/abs/2512.15089)

**Authors**: Jinwu Hu, Dongjin Yang, Langyu Bian, Zhiquan Wen, Yufeng Wang, Yaofo Chen, Bin Xiao, Yuanqing Li, Mingkui Tan  
**Category**: cs.AI  
**Published**: 2025-12-19  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.15089v1  

#### Abstract
Large language models (LLMs) have demonstrated impressive performance across various language tasks. However, existing LLM reasoning strategies mainly rely on the LLM itself with fast or slow mode (like o1 thinking) and thus struggle to balance reasoning efficiency and accuracy across queries of var...

---

### 26. [A Clustering-Based Variable Ordering Framework for Relaxed Decision Diagrams for Maximum Weighted Independent Set Problem](https://arxiv.org/abs/2512.15198)

**Authors**: Mohsen Nafar, Michael R\"omer, Lin Xie  
**Category**: cs.AI  
**Published**: 2025-12-19  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.15198v1  

#### Abstract
Efficient exact algorithms for Discrete Optimization (DO) rely heavily on strong primal and dual bounds. Relaxed Decision Diagrams (DDs) provide a versatile mechanism for deriving such dual bounds by compactly over-approximating the solution space through node merging. However, the quality of these ...

---

### 27. [Stepwise Think-Critique: A Unified Framework for Robust and Interpretable LLM Reasoning](https://arxiv.org/abs/2512.15662)

**Authors**: Jiaqi Xu, Cuiling Lan, Xuejin Chen, Yan LU  
**Category**: cs.AI  
**Published**: 2025-12-19  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.15662v1  

#### Abstract
Human beings solve complex problems through critical thinking, where reasoning and evaluation are intertwined to converge toward correct solutions. However, most existing large language models (LLMs) decouple reasoning from verification: they either generate reasoning without explicit self-checking ...

---

### 28. [From Facts to Conclusions : Integrating Deductive Reasoning in Retrieval-Augmented LLMs](https://arxiv.org/abs/2512.16795)

**Authors**: Shubham Mishra, Samyek Jain, Gorang Mehrishi, Shiv Tiwari, Harsh Sharma, Pratik Narang, Dhruv Kumar  
**Category**: cs.CL  
**Published**: 2025-12-19  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.16795v1  

#### Abstract
Retrieval-Augmented Generation (RAG) grounds large language models (LLMs) in external evidence, but fails when retrieved sources conflict or contain outdated or subjective information. Prior work address these issues independently but lack unified reasoning supervision. We propose a reasoning-trace-...

---

### 29. [Grammar-Forced Translation of Natural Language to Temporal Logic using LLMs](https://arxiv.org/abs/2512.16814)

**Authors**: William English, Dominic Simon, Sumit Kumar Jha, Rickard Ewetz  
**Category**: cs.CL  
**Published**: 2025-12-19  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.16814v1  

#### Abstract
Translating natural language (NL) into a formal language such as temporal logic (TL) is integral for human communication with robots and autonomous systems. State-of-the-art approaches decompose the task into a lifting of atomic propositions (APs) phase and a translation phase. However, existing met...

---

### 30. [Semantic-Constrained Federated Aggregation: Convergence Theory and Privacy-Utility Bounds for Knowledge-Enhanced Distributed Learning](https://arxiv.org/abs/2512.15759)

**Authors**: Jahidul Arafat  
**Category**: cs.LG  
**Published**: 2025-12-19  
**Score**: 6.5  
**Type**: new  
**ArXiv ID**: 2512.15759v1  

#### Abstract
Federated learning enables collaborative model training across distributed data sources but suffers from slow convergence under non-IID data conditions. Existing solutions employ algorithmic modifications treating all client updates identically, ignoring semantic validity. We introduce Semantic-Cons...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
