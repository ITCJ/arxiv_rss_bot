# arXiv Papers Bot ğŸ¤–

This repository automatically fetches and displays relevant papers from arXiv based on configured criteria.

## RSS Vercel Deployment [![An example of deployed RSS Server using vercel](https://img.shields.io/badge/Deployed-Example-blue)](https://arxiv.tachicoma.top/)

You can click this to deploy yours 

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/maydomine/arxiv_rss_bot)
## ğŸ“Š Statistics

- **Last Updated**: 2026-01-30 06:16:10 UTC
- **Total Papers Found**: 30
- **Categories Monitored**: cs.AI, cs.CL, cs.DC, cs.LG

## ğŸ“š Recent Papers

### 1. [Causal Autoregressive Diffusion Language Model](https://arxiv.org/abs/2601.22031)

**Authors**: Junhao Ruan, Bei Li, Yongjing Yin, Pengcheng Huang, Xin Chen, Jingang Wang, Xunliang Cai, Tong Xiao, JingBo Zhu  
**Category**: cs.CL  
**Published**: 2026-01-30  
**Score**: 13.0  
**Type**: new  
**ArXiv ID**: 2601.22031v1  

#### Abstract
In this work, we propose Causal Autoregressive Diffusion (CARD), a novel framework that unifies the training efficiency of ARMs with the high-throughput inference of diffusion models. CARD reformulates the diffusion process within a strictly causal attention mask, enabling dense, per-token supervisi...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šCausal Autoregressive Diffusion Language Model

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰ä¸»æµçš„ **Autoregressive Models (ARMs)** è™½ç„¶è®­ç»ƒç¨³å®šä¸”æ•°æ®æ•ˆç‡é«˜ï¼Œä½†ç”±äºå…¶**é€tokenç”Ÿæˆæœºåˆ¶**ï¼Œåœ¨æ¨ç†æ—¶å­˜åœ¨ä¸¥é‡çš„**é¡ºåºç“¶é¢ˆ**ï¼Œå¯¼è‡´ååé‡ä½ã€‚  
è€Œç°æœ‰çš„ **Text Diffusion Models**ï¼ˆå¦‚ MDLMã€BD3LMï¼‰è™½ç„¶æ”¯æŒå¹¶è¡Œè§£ç ï¼Œæå‡æ¨ç†é€Ÿåº¦ï¼Œä½†ä¹Ÿé¢ä¸´ä»¥ä¸‹é—®é¢˜ï¼š
- **MDLM** ä½¿ç”¨åŒå‘æ³¨æ„åŠ›ï¼ˆFull Attentionï¼‰ï¼Œæ— æ³•åˆ©ç”¨ **KV Cache**ï¼Œå®é™…æ¨ç†é€Ÿåº¦ä»å—é™ï¼›
- **BD3LM** å¼•å…¥å—çº§æ‰©æ•£ï¼ˆBlock Diffusionï¼‰ï¼Œè™½æ¢å¤éƒ¨åˆ†å¹¶è¡Œèƒ½åŠ›ï¼Œä½†å¸¦æ¥æ˜¾è‘—çš„è®­ç»ƒå¼€é”€ï¼ˆå¤æ‚æ©ç ã€è¾“å…¥å¤åˆ¶ç­‰ï¼‰ï¼Œè®­ç»ƒå»¶è¿Ÿé«˜è¾¾ ARM çš„ 3Ã—ã€‚

æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•åœ¨è®­ç»ƒæ•ˆç‡ã€åŠ¨æ€å¹¶è¡Œæ€§å’Œä¸Šä¸‹æ–‡å»ºæ¨¡æ–¹é¢å‡å­˜åœ¨ä¸è¶³ã€‚

---

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
æœ¬æ–‡æå‡º **CARD (Causal Autoregressive Diffusion)** æ¡†æ¶ï¼Œå°† ARMs çš„é«˜æ•ˆè®­ç»ƒä¸æ‰©æ•£æ¨¡å‹çš„å¹¶è¡Œæ¨ç†ä¼˜åŠ¿ç»Ÿä¸€äºä¸€ä¸ª**ä¸¥æ ¼å› æœæ¶æ„**ä¸­ã€‚

#### æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼š
1. **Causal Diffusion Formulation**  
   åœ¨æ ‡å‡† AR æ¶æ„åŸºç¡€ä¸Šå¼•å…¥è¿ç»­æ—¶é—´å™ªå£°è°ƒåº¦ï¼Œåœ¨æ¯ä¸€æ­¥ä»…åŸºäº**å‰é¢è¢«ç ´åçš„ä¸Šä¸‹æ–‡**é¢„æµ‹åŸå§‹ tokenï¼Œå®ç°å•æ¬¡å‰å‘ä¼ æ’­å³å¯è·å¾—å…¨åºåˆ—å¯†é›†ç›‘ç£ã€‚

2. **Soft Tail Masking**  
   ä¸ºè§£å†³å› æœç»“æ„ä¸‹æ—©æœŸ token æ˜“å› ä¸Šä¸‹æ–‡ç¼ºå¤±è€Œå¯¼è‡´â€œä¿¡æ¯åç¼©â€ï¼ˆInformation Collapseï¼‰çš„é—®é¢˜ï¼Œæå‡ºä¸€ç§è½¯å°¾éƒ¨æ©ç ç­–ç•¥ï¼šåªåœ¨åºåˆ—å°¾éƒ¨çš„ä¸€ä¸ªåŠ¨æ€çª—å£å†…è¿›è¡Œæ©ç ï¼Œä¿ç•™å‰ç¼€æ¸…æ´ä»¥ç»´æŒå†å²ä¿¡å·ï¼ŒåŒæ—¶å…è®¸å±€éƒ¨æ··åˆçŠ¶æ€ä»¥ä¿æŒè¯­è¨€å±€éƒ¨ä¾èµ–ã€‚

3. **Context-aware Reweighting**  
   è®¾è®¡äº†ä¸€ç§åŸºäºä¸Šä¸‹æ–‡æ¨¡ç³Šåº¦çš„åŠ¨æ€æŸå¤±é‡åŠ æƒæœºåˆ¶ï¼Œä»ä¸‰ä¸ªç»´åº¦è¯„ä¼°ä¸Šä¸‹æ–‡è´¨é‡ï¼š
   - **Quantity**ï¼ˆå™ªå£°æ•°é‡ï¼‰
   - **Distance**ï¼ˆè·ç¦»ç›®æ ‡çš„è·ç¦»ï¼‰
   - **Density**ï¼ˆè¿ç»­æ©ç å¯†åº¦ï¼‰  
   å¹¶æ®æ­¤è®¡ç®— `S_focal` å¾—åˆ†ï¼Œç”¨äºå¯¹é«˜ç†µä¸Šä¸‹æ–‡ä¸‹çš„é¢„æµ‹é™æƒï¼Œä»è€Œæé«˜ä¼˜åŒ–ç¨³å®šæ€§ã€‚

4. **Confidence-based Block Inference**  
   æ”¯æŒåŠ¨æ€å¹¶è¡Œè§£ç ï¼šé€šè¿‡ç½®ä¿¡åº¦é˜ˆå€¼æ§åˆ¶æ¯æ¬¡å¹¶è¡Œè§£ç çš„ block å¤§å°ï¼Œé«˜ç½®ä¿¡æ—¶å¤š token å¹¶è¡Œè¾“å‡ºï¼Œä½ç½®ä¿¡æ—¶é€€åŒ–ä¸ºè‡ªå›å½’æ¨¡å¼ï¼Œå®ç°çµæ´»é«˜æ•ˆçš„æ¨ç†åŠ é€Ÿã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | CARD vs. ARM | CARD vs. MDLM / BD3LM |
|------|---------------|------------------------|
| **è®­ç»ƒæ•ˆç‡** | â‰ˆ ARMï¼Œæ— é¢å¤–å¼€é”€ | â†“ 3Ã— è®­ç»ƒå»¶è¿Ÿï¼ˆvs. BD3LMï¼‰ |
| **æ¨ç†é€Ÿåº¦** | â†‘ 1.7Ã— ~ 4.0Ã— åŠ é€Ÿï¼ˆwall-clockï¼‰ | æ›´å¿«ï¼Œæ”¯æŒ KV Cache + åŠ¨æ€å¹¶è¡Œ |
| **ç”Ÿæˆè´¨é‡** | â‰ˆ ARMï¼Œä¼˜äºæ‰€æœ‰ diffusion åŸºçº¿ | æ˜¾è‘—ä¼˜äº MDLM/BD3LM |
| **æ•°æ®åˆ©ç”¨ç‡** | æ›´é«˜æ•°æ®æ½œåŠ›ï¼Œå¤šè½®è®­ç»ƒä¸é¥±å’Œ | é¿å…æ—©æœŸé¥±å’Œï¼Œé€‚åˆæ•°æ®å¤ç”¨åœºæ™¯ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **é¢„è®­ç»ƒæ•°æ®**ï¼šFineWeb å­é›†ï¼Œå…± **300B tokens**
- **å¾®è°ƒ/è¯„ä¼°ä»»åŠ¡**ï¼š
  - **å¸¸è¯†æ¨ç†**ï¼šARC-Challenge/Easy, CommonsenseQA, HellaSwag, Winogrande
  - **å­¦ç§‘çŸ¥è¯†**ï¼šMMLU-redux
  - **æ—¥å¸¸é—®ç­”**ï¼šPIQA, SciQ
  - **è¯­è¨€å»ºæ¨¡è´¨é‡**ï¼šWikiText, OpenWebText, AG News, LM1B, PTB, arXiv, PubMed, LAMBADAï¼ˆé›¶æ ·æœ¬ PPL æµ‹è¯•ï¼‰

---

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹è§„æ¨¡**ï¼šç»Ÿä¸€ä¸º **1B å‚æ•°**
- **è®­ç»ƒæ­¥æ•°**ï¼šæœ€å¤š 1M æ­¥
- **è¯„ä¼°æ–¹å¼**ï¼š
  - **ä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®ç‡**ï¼ˆzero-shot settingï¼‰
  - **é›¶æ ·æœ¬å›°æƒ‘åº¦ï¼ˆZero-shot PPLï¼‰**
  - **è®­ç»ƒå»¶è¿Ÿå¯¹æ¯”**ï¼ˆlatency normalized to ARM = 1.0Ã—ï¼‰
  - **æ¨ç†ååé‡ï¼ˆtokens/secï¼‰ä¸ PPL æƒè¡¡åˆ†æ**

- **å…³é”®æŠ€æœ¯ç»†èŠ‚**ï¼š
  - ä½¿ç”¨ Flash Attention 2 æå‡æ•ˆç‡
  - BD3LM ä½¿ç”¨ torch.compile + Flex Attention ä¼˜åŒ–
  - æ‰€æœ‰ diffusion æ–¹æ³•é‡‡ç”¨çº¿æ€§å™ªå£°è°ƒåº¦ï¼ˆlinear scheduleï¼‰

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ¨¡å‹ | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **ARM** | è‡ªå›å½’æ¨¡å‹ | å½“å‰ä¸»æµèŒƒå¼ï¼Œè®­ç»ƒé«˜æ•ˆä½†æ¨ç†æ…¢ |
| **MDLM** | æ©ç ç¦»æ•£æ‰©æ•£ | åŒå‘æ³¨æ„åŠ›ï¼Œç®€åŒ–è®­ç»ƒç›®æ ‡ï¼Œä½†æ— æ³•ä½¿ç”¨ KV Cache |
| **BD3LM** | å—çº§æ‰©æ•£ | æ··åˆå› æœ+å—å†…åŒå‘ï¼Œæ”¯æŒéƒ¨åˆ†å¹¶è¡Œï¼Œä½†è®­ç»ƒæˆæœ¬é«˜ |
| **CARD (Ours)** | å› æœæ‰©æ•£ | ä¸¥æ ¼å› æœç»“æ„ï¼Œæ”¯æŒ KV Cache ä¸åŠ¨æ€å¹¶è¡Œ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

#### è¡¨1ï¼šä¸‹æ¸¸ä»»åŠ¡å¹³å‡å‡†ç¡®ç‡ï¼ˆ%ï¼‰
| Model | AVG |
|-------|-----|
| ARM | 56.39 |
| BD3LM | 47.45 |
| MDLM | 47.55 |
| **CARD (Ours)** | **53.23** |

> âœ… CARD æ¯”ç°æœ‰ diffusion åŸºçº¿é«˜å‡º **>5.7 ä¸ªç™¾åˆ†ç‚¹**ï¼Œæ¥è¿‘ ARM æ°´å¹³ã€‚

#### è¡¨2ï¼šè·¨é¢†åŸŸé›¶æ ·æœ¬ PPLï¼ˆè¶Šä½è¶Šå¥½ï¼‰
| Model | AVG PPL |
|-------|---------|
| ARM | 38.68 |
| BD3LM | 49.78 |
| MDLM | 49.84 |
| **CARD (Ours)** | **34.40** |

> âœ… CARD åœ¨ **8ä¸ªæµ‹è¯•åŸŸä¸­çš„6ä¸ªä¸Šè¶…è¶Š ARM**ï¼Œå°¤å…¶åœ¨é•¿ä¸Šä¸‹æ–‡ï¼ˆLAMBADAï¼‰ã€é€šç”¨æ–‡æœ¬ï¼ˆWikiTextï¼‰è¡¨ç°ä¼˜å¼‚ã€‚

#### è¡¨3ï¼šå°æ¨¡å‹ PPL å¯¹æ¯”ï¼ˆ110M, 33B tokensï¼‰
| Model | PPL |
|-------|-----|
| ARM | 21.12 |
| BD3LM | 35.06 |
| MDLM | 37.48 |
| **CARD** | **21.54** |

> âœ… å³ä½¿ä½¿ç”¨ EMAï¼ŒCARD ä»èƒ½é€¼è¿‘ ARM æ€§èƒ½ï¼Œè¯´æ˜å…¶è®­ç»ƒæ›´ç¨³å®šã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **è®­ç»ƒå»¶è¿Ÿ** | CARD â‰ˆ ARMï¼ˆ1.0Ã—ï¼‰ï¼Œä»…ä¸º BD3LM çš„ **1/3** |
| **æ¨ç†é€Ÿåº¦** | è¾¾åˆ° **1.7Ã— ~ 4.0Ã—** çš„ wall-clock åŠ é€Ÿï¼ˆå–å†³äº block size å’Œ step limitï¼‰ |
| **ç”Ÿæˆè´¨é‡** | åœ¨ 1.7Ã— åŠ é€Ÿä¸‹ PPL ä»…è½»å¾®ä¸Šå‡ï¼›4Ã— åŠ é€Ÿä¸‹ç•¥æœ‰ä¸‹é™ä½†ä»å¯ç”¨ |
| **æ•°æ®æ•ˆç‡** | å¤š epoch è®­ç»ƒä¸­æŒç»­æå‡ï¼Œé¿å… ARM çš„æ—©æœŸé¥±å’Œç°è±¡ |

---

### æ¶ˆèå®éªŒç»“æœï¼ˆè¡¨4ï¼‰

| è®¾ç½® | AVG å‡†ç¡®ç‡ |
|------|-----------|
| **CARD (å®Œæ•´ç‰ˆ)** | **53.21** |
| w/o Relaxed Window (Strict Tail) | 52.50 |
| w/o Tail Preference (Random) | 51.62 |
| w/o Context-aware Weighting | 51.66 |

> ğŸ” å‘ç°ï¼š
- å°¾éƒ¨åå¥½ï¼ˆTail Preferenceï¼‰è‡³å…³é‡è¦ï¼Œéšæœºæ©ç ä¸¥é‡æŸå®³æ€§èƒ½ï¼›
- â€œå®½æ¾çª—å£â€ï¼ˆRelaxed Windowï¼‰ä¼˜äºâ€œä¸¥æ ¼å°¾éƒ¨â€ï¼Œè¯´æ˜éœ€è¦ä¿ç•™å±€éƒ¨æ¸…æ´é”šç‚¹ï¼›
- ä¸Šä¸‹æ–‡æ„ŸçŸ¥é‡åŠ æƒæœºåˆ¶æœ‰æ•ˆæå‡äº†å­¦ä¹ ç¨³å®šæ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **CARD æˆåŠŸå¼¥åˆäº† AR ä¸ diffusion çš„é¸¿æ²Ÿ**ï¼š
   - å®ç°äº† **ARM çº§åˆ«çš„è®­ç»ƒæ•ˆç‡** ä¸ **diffusion çº§åˆ«çš„å¹¶è¡Œæ¨ç†èƒ½åŠ›**ï¼›
   - åœ¨ä¿æŒé«˜è´¨é‡ç”Ÿæˆçš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½è®­ç»ƒæˆæœ¬ã€‚

2. **å› æœæ‰©æ•£æ˜¯å¯è¡Œä¸”é«˜æ•ˆçš„è·¯å¾„**ï¼š
   - é€šè¿‡ Soft Tail Masking å’Œ Context-aware Reweightingï¼Œè§£å†³äº†ä¼ ç»Ÿå› æœç»“æ„ä¸‹è®­ç»ƒä¸ç¨³å®šçš„é—®é¢˜ï¼›
   - é¦–æ¬¡å®ç°äº†åœ¨çº¯å› æœæ¡†æ¶ä¸‹çš„é«˜æ•ˆç¦»æ•£æ‰©æ•£è®­ç»ƒã€‚

3. **æ›´é«˜çš„æ•°æ®æ½œåŠ›ï¼ˆData Potentialï¼‰**ï¼š
   - CARD åœ¨é‡å¤è®­ç»ƒä¸­ä¸ä¼šåƒ ARM é‚£æ ·å¿«é€Ÿé¥±å’Œï¼Œæ›´é€‚åˆå½“å‰â€œæ•°æ®ç¨€ç¼ºã€ç®—åŠ›å……è¶³â€çš„è®­ç»ƒèŒƒå¼ï¼›
   - åœ¨æœ‰é™æ•°æ®ä¸Šåå¤è®­ç»ƒä»å¯æŒç»­ææ•ˆã€‚

4. **æ”¯æŒåŠ¨æ€å¹¶è¡Œè§£ç **ï¼š
   - åˆ©ç”¨ KV Cache å’Œ confidence-based block samplingï¼Œå¯åœ¨ä¸åŒè´Ÿè½½ä¸‹çµæ´»è°ƒæ•´æ¨ç†é€Ÿåº¦ä¸è´¨é‡å¹³è¡¡ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
- **æç«¯åŠ é€Ÿè®¾ç½®ä¸‹å¯èƒ½å‡ºç°é‡å¤æˆ–å¾ªç¯ç”Ÿæˆ**ï¼ˆè§ Appendix Dï¼‰ï¼Œå°¤å…¶æ˜¯åœ¨ step budget ä¸è¶³æ—¶ï¼›
- å½“å‰è®¾è®¡ä¾èµ–è‰¯å¥½çš„ç½®ä¿¡åº¦ä¼°è®¡ï¼Œè‹¥æ¨¡å‹ä¸ç¡®å®šæ€§æ ¡å‡†ä¸ä½³å¯èƒ½å½±å“æ€§èƒ½ï¼›
- è™½ç„¶ä¼˜äºç°æœ‰ diffusion æ–¹æ³•ï¼Œä½†ä»ç•¥é€Šäºæœ€å¼º ARM åœ¨ä¸ªåˆ«ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
- æ¢ç´¢æ›´ç²¾ç»†çš„å™ªå£°è°ƒåº¦ä¸æ©ç ç­–ç•¥ï¼›
- å¼•å…¥æ›´å¼ºçš„ä¸ç¡®å®šæ€§ä¼°è®¡æ¨¡å—ä»¥ä¼˜åŒ–åŠ¨æ€è§£ç ï¼›
- æ‰©å±•è‡³æ›´å¤§è§„æ¨¡æ¨¡å‹ï¼ˆ>10Bï¼‰éªŒè¯æ³›åŒ–æ€§ï¼›
- ç»“åˆ instruction tuning å’Œ alignment æŠ€æœ¯ï¼Œæ¢ç´¢ CARD åœ¨å¯¹è¯ä¸æŒ‡ä»¤éµå¾ªä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚

---

> ğŸ“Œ **æ€»ä½“è¯„ä»·**ï¼š  
> CARD æ˜¯ä¸€é¡¹é‡è¦çš„æ¶æ„åˆ›æ–°ï¼Œå®ƒæ‰“ç ´äº†â€œARM é«˜æ•ˆè®­ç»ƒ vs. diffusion å¿«é€Ÿæ¨ç†â€çš„äºŒå…ƒå¯¹ç«‹ï¼Œæå‡ºäº†ä¸€ä¸ªå…¼å…·äºŒè€…ä¼˜ç‚¹çš„æ–°èŒƒå¼ã€‚å…¶è®¾è®¡ç†å¿µæ¸…æ™°ã€å·¥ç¨‹å®ç°åŠ¡å®ï¼Œå®éªŒè¯æ®å……åˆ†ï¼Œæœ‰æœ›æˆä¸ºä¸‹ä¸€ä»£é«˜æ•ˆ LLM çš„é‡è¦å€™é€‰æ–¹æ¡ˆã€‚

</details>

---

### 2. [NetMamba+: A Framework of Pre-trained Models for Efficient and Accurate Network Traffic Classification](https://arxiv.org/abs/2601.21792)

**Authors**: Tongze Wang, Xiaohui Xie, Wenduo Wang, Chuyi Wang, Jinzhou Liu, Boyan Huang, Yannan Hu, Youjian Zhao, Yong Cui  
**Category**: cs.LG  
**Published**: 2026-01-30  
**Score**: 12.0  
**Type**: new  
**ArXiv ID**: 2601.21792v1  

#### Abstract
With the rapid growth of encrypted network traffic, effective traffic classification has become essential for network security and quality of service management. Current machine learning and deep learning approaches for traffic classification face three critical challenges: computational inefficienc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡ã€ŠNetMamba+: A Framework of Pre-trained Models for Efficient and Accurate Network Traffic Classificationã€‹æ ¸å¿ƒæ€»ç»“**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
å½“å‰ç½‘ç»œæµé‡åˆ†ç±»é¢ä¸´ä¸‰å¤§æŒ‘æˆ˜ï¼š
1. **è®¡ç®—æ•ˆç‡ä½ä¸‹**ï¼šåŸºäºTransformerçš„æ¨¡å‹å› è‡ªæ³¨æ„åŠ›æœºåˆ¶å…·æœ‰äºŒæ¬¡å¤æ‚åº¦ï¼Œåœ¨å¤„ç†é•¿åºåˆ—æ—¶è®¡ç®—å’Œå†…å­˜å¼€é”€å·¨å¤§ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶åœ¨çº¿åˆ†ç±»éœ€æ±‚ã€‚
2. **æµé‡è¡¨å¾ä¸å……åˆ†**ï¼šç°æœ‰æ–¹æ³•åœ¨æå–ç‰¹å¾æ—¶å®¹æ˜“ä¸¢å¤±å­—èŠ‚çº§å…³é”®ä¿¡æ¯ï¼ˆå¦‚åŒ…å¤´å­—æ®µï¼‰ï¼ŒåŒæ—¶å¼•å…¥ä¸å¿…è¦çš„åå·®ï¼ˆå¦‚åˆ†å—æ–¹å¼å¯¼è‡´è¯­ä¹‰æ–­è£‚ï¼‰ã€‚
3. **å¯¹é•¿å°¾åˆ†å¸ƒæ•°æ®é€‚åº”å·®**ï¼šçœŸå®ä¸–ç•Œæµé‡æ•°æ®ç±»åˆ«åˆ†å¸ƒæä¸å‡è¡¡ï¼ˆé•¿å°¾åˆ†å¸ƒï¼‰ï¼Œä¼ ç»Ÿå¾®è°ƒç­–ç•¥å¯¹å°‘æ•°ç±»æ ·æœ¬å­¦ä¹ ä¸è¶³ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°æ€è·¯**
NetMamba+ æ˜¯é¦–ä¸ªå°† **Mamba æ¶æ„**åº”ç”¨äºç½‘ç»œæµé‡åˆ†ç±»çš„é¢„è®­ç»ƒæ¡†æ¶ï¼Œé€šè¿‡ä»¥ä¸‹ä¸‰é¡¹æ ¸å¿ƒæŠ€æœ¯åº”å¯¹ä¸Šè¿°æŒ‘æˆ˜ï¼š

1. **é«˜æ•ˆæ¨¡å‹æ¶æ„è®¾è®¡**
   - é‡‡ç”¨ **Mamba**ï¼ˆçº¿æ€§æ—¶é—´çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼‰ä½œä¸ºä¸»å¹²ï¼Œæ›¿ä»£Transformerï¼Œå®ç° O(L) æ—¶é—´å¤æ‚åº¦ã€‚
   - æˆ–é›†æˆ **Flash Attention** ä¼˜åŒ–çš„ Transformerï¼ˆNetTransï¼‰ï¼Œæå‡ä¼ ç»Ÿæ³¨æ„åŠ›æœºåˆ¶çš„IOæ•ˆç‡ã€‚
   - å¼•å…¥ **pre-normalization** å’Œ **GeGLU-activated FFN** æé«˜è®­ç»ƒç¨³å®šæ€§å’Œå‡†ç¡®ç‡ã€‚

2. **å¤šæ¨¡æ€æµé‡è¡¨å¾æ–¹æ¡ˆï¼ˆMultimodal Traffic Representationï¼‰**
   - åŒæ—¶ä¿ç•™ **åŒ…å¤´ï¼ˆheaderï¼‰** å’Œ **è½½è·ï¼ˆpayloadï¼‰** å­—èŠ‚ä¿¡æ¯ã€‚
   - å¼•å…¥ **stride-based åˆ‡å‰²** æ›¿ä»£ä¼ ç»Ÿçš„ patch åˆ†å—ï¼Œé¿å…æ— å…³å­—èŠ‚è¢«å¼ºè¡Œå…³è”ã€‚
   - è¡¥å…… **åŒ…å¤§å°åºåˆ—ï¼ˆpacket sizesï¼‰** å’Œ **åˆ°è¾¾é—´éš”æ—¶é—´ï¼ˆinter-arrival timesï¼‰** ä½œä¸ºé¢å¤–æ¨¡æ€ï¼Œæ•æ‰ä¼ è¾“æ¨¡å¼ã€‚

3. **æ ‡ç­¾åˆ†å¸ƒæ„ŸçŸ¥å¾®è°ƒç­–ç•¥ï¼ˆLabel Distribution-Aware Fine-tuning, LDAï¼‰**
   - æå‡ºä¸€ç§æ–°å‹äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼ˆLDA CE Lossï¼‰ï¼Œä¸ºå°‘æ•°ç±»åˆ†é…æ›´é«˜æƒé‡å¹¶æ–½åŠ æ›´å¤§åˆ†ç±»è¾¹ç•Œï¼ˆmarginï¼‰ï¼Œç¼“è§£é•¿å°¾é—®é¢˜ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
- **æ›´é«˜æ•ˆ**ï¼šæ¨ç†ååé‡è¾¾æœ€ä¼˜åŸºçº¿çš„ **1.7Ã—**ï¼Œä¸”GPUå†…å­˜å ç”¨ä½ã€‚
- **æ›´å‡†ç¡®**ï¼šåœ¨å¤šä¸ªä»»åŠ¡ä¸ŠF1-scoreæœ€é«˜æå‡ **6.44%**ã€‚
- **æ›´å¼ºæ³›åŒ–èƒ½åŠ›**ï¼šæ”¯æŒå°‘æ ·æœ¬å­¦ä¹ ï¼ˆfew-shot learningï¼‰å’Œå¼‚å¸¸æµé‡æ£€æµ‹ï¼ˆOOD detectionï¼‰ã€‚
- **é¦–æ¬¡å®ç°Mambaåœ¨æµé‡åˆ†æä¸­çš„æˆåŠŸåº”ç”¨**ï¼Œå¼€è¾Ÿäº†æ–°çš„ç ”ç©¶è·¯å¾„ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
| ç±»å‹ | æ•°æ®é›† | ä¸‹æ¸¸ä»»åŠ¡ | ç‰¹ç‚¹ |
|------|--------|----------|------|
| **é¢„è®­ç»ƒ** | Browser [2], Kitsune [52] | â€” | åŒ…å«å¤§é‡æœªæ ‡æ³¨åŠ å¯†æµé‡ |
| **å¾®è°ƒ** | CipherSpectrum [53], CSTNET-TLS1.3 [9], CICIoT2022 [56], USTC-TFC2016 [57], ISCXVPN2016 [58] ç­‰å…±11ä¸ª | åº”ç”¨åˆ†ç±»ã€æ”»å‡»è¯†åˆ«ã€æ¶æ„è½¯ä»¶æ£€æµ‹ã€VPNåè®®è¯†åˆ«ç­‰ | è¦†ç›–å¤šç§åè®®ï¼ˆTLS, SSH, QUICç­‰ï¼‰ã€éƒ¨åˆ†åŠ å¯†ã€å­˜åœ¨ä¸¥é‡ç±»åˆ«ä¸å¹³è¡¡ |

> æ³¨ï¼šå¤šæ•°å¾®è°ƒæ•°æ®é›†è®¾ç½®äº†æ¯ç±»æœ€å¤§æµæ•°ï¼ˆMFC=2000ï¼‰ä»¥æ§åˆ¶ç±»åˆ«ä¸å¹³è¡¡ã€‚

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

#### **æ¨¡å‹å˜ä½“**
- `NetTrans`ï¼šä»…ä½¿ç”¨ Flash Attention ä¼˜åŒ–çš„ Transformer å—ã€‚
- `NetMamba`ï¼šä»…ä½¿ç”¨å•å‘ Mamba å—ã€‚
- `NetMamba+`ï¼šç»“åˆå¤šæ¨¡æ€è¾“å…¥ï¼ˆå­—èŠ‚ + å¤§å° + é—´éš”ï¼‰çš„å®Œæ•´ç‰ˆæœ¬ã€‚

#### **è®­ç»ƒé…ç½®**
- é¢„è®­ç»ƒï¼š15ä¸‡æ­¥ï¼Œbatch size=128ï¼ŒAdamWä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡1e-3ã€‚
- å¾®è°ƒï¼š120è½®ï¼Œbatch size=64ï¼Œå­¦ä¹ ç‡2e-3ã€‚
- ç¡¬ä»¶ï¼šUbuntuæœåŠ¡å™¨ + NVIDIA A100 Ã—4ã€‚

#### **è¯„ä¼°æŒ‡æ ‡**
- **åˆ†å¸ƒå†…æ€§èƒ½ï¼ˆIDï¼‰**ï¼šAccuracy (AC), Precision (PR), Recall (RC), F1-scoreï¼ˆåŠ æƒï¼‰
- **åˆ†å¸ƒå¤–æ£€æµ‹ï¼ˆOODï¼‰**ï¼šAUROC, FPR95
- **æ•ˆç‡æŒ‡æ ‡**ï¼šæ¨ç†ååé‡ï¼ˆsamples/secï¼‰ã€GPUå†…å­˜æ¶ˆè€—ï¼ˆMBï¼‰
- **å°‘æ ·æœ¬å­¦ä¹ **ï¼šä½¿ç”¨10%~100%æ ‡æ³¨æ•°æ®è¿›è¡Œè®­ç»ƒæµ‹è¯•

#### **å¯¹æ¯”åŸºçº¿æ–¹æ³•**
| ç±»åˆ« | æ–¹æ³• |
|------|------|
| ä¼ ç»Ÿæœºå™¨å­¦ä¹  | AppScanner [3], FlowPrint [2] |
| æ·±åº¦å­¦ä¹ ï¼ˆç›‘ç£ï¼‰ | Seq2Img [60], FS-Net [4], FlowPic [61], TFE-GNN [6] |
| Transformeré¢„è®­ç»ƒ | ET-BERT [9], YaTC [10], TrafficFormer [63] |
| æ¶æ„å˜ä½“ | NetTransVï¼ˆåŸç”ŸTransformerï¼‰ã€NetTransLï¼ˆçº¿æ€§Attentionï¼‰ã€NetMambaBï¼ˆåŒå‘Mambaï¼‰ã€NetMambaCï¼ˆçº§è”Mambaï¼‰ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

| æŒ‡æ ‡ | ç»“æœ |
|------|------|
| **æœ€é«˜F1æå‡** | è¾ƒSOTAæå‡é«˜è¾¾ **6.44%**ï¼ˆè§CipherSpectrumï¼‰ |
| **å¹³å‡æ¨ç†ååé‡** | è¾ƒæœ€ä½³åŸºçº¿ï¼ˆYaTCï¼‰æå‡ **1.7Ã—** |
| **GPUå†…å­˜ä½¿ç”¨** | æ˜¾è‘—ä½äºå¤§å¤šæ•°æ·±åº¦æ¨¡å‹ï¼ˆå¦‚ET-BERTã€TFE-GNNï¼‰ |
| **å°‘æ ·æœ¬è¡¨ç°** | åœ¨ä»…10%æ ‡ç­¾æ•°æ®ä¸‹ä»ä¼˜äºå…¶ä»–é¢„è®­ç»ƒæ¨¡å‹ |
| **OODæ£€æµ‹æ€§èƒ½** | å››é¡¹ä»»åŠ¡AUROCå‡ > **94%**ï¼Œæœ€é«˜è¾¾ **98.25%** |
| **åœ¨çº¿ç³»ç»Ÿååé‡** | å®ç° **261.87 Mb/s** å¹³å‡ååï¼ŒéªŒè¯å®ç”¨æ€§ |

### **ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”ç»“æœ**

#### âœ… **æ€»ä½“æ€§èƒ½é¢†å…ˆ**
- åœ¨æ‰€æœ‰å…¬å¼€æ•°æ®é›†ä¸Šï¼Œ`NetMamba+` å–å¾— **æœ€å¥½æˆ–æ¥è¿‘æœ€å¥½** çš„åˆ†ç±»ç²¾åº¦ã€‚
- å°¤å…¶åœ¨å®Œå…¨åŠ å¯†æµé‡ï¼ˆå¦‚CipherSpectrumï¼‰ä¸­ä¼˜åŠ¿æ˜¾è‘—ï¼Œå› å…¶èåˆäº†ä¼ è¾“æ¨¡å¼ï¼ˆsize/intervalï¼‰å¼¥è¡¥äº†payloadä¿¡æ¯ç¼ºå¤±ã€‚

#### âœ… **æ•ˆç‡æ˜¾è‘—æå‡**
- æ¨ç†é€Ÿåº¦è¿œè¶…Transformerç±»æ¨¡å‹ï¼ˆET-BERTã€TrafficFormerï¼‰åŠGNNæ¨¡å‹ï¼ˆTFE-GNNï¼‰ã€‚
- å†…å­˜ä½¿ç”¨ä¼˜äºé™¤NetTransLå’ŒFS-Netå¤–çš„æ‰€æœ‰æ¨¡å‹ï¼Œå…¼é¡¾é«˜æ•ˆä¸é«˜æ€§èƒ½ã€‚

#### âœ… **æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰**

| ç»„ä»¶ç§»é™¤ | å½±å“è¯´æ˜ |
|--------|---------|
| **æ— Header** | æ€§èƒ½å¤§å¹…ä¸‹é™ï¼ˆACCâ†“14.86%~47.50%ï¼‰ï¼Œè¯æ˜åŒ…å¤´å­—æ®µï¼ˆå¦‚TCP flagsã€window sizeï¼‰è‡³å…³é‡è¦ |
| **æ— Payload** | è¡¨ç°ä¸ç¨³å®šï¼Œéƒ¨åˆ†ä»»åŠ¡ç•¥å‡ï¼Œè¡¨æ˜åœ¨æŸäº›åœºæ™¯å¯ç‰ºç‰²payloadæ¢å–æ•ˆç‡ |
| **Stride Cutting â†’ Patch Splitting** | æœ€å¤šé™2.27%ï¼ŒéªŒè¯strideåˆ‡å‰²æ›´ç¬¦åˆç½‘ç»œå­—èŠ‚é¡ºåºï¼Œå‡å°‘åè§ |
| **æ— é¢„è®­ç»ƒ** | å¤šæ•°ä»»åŠ¡æ€§èƒ½ä¸‹é™ï¼Œå‡¸æ˜¾è‡ªç›‘ç£é¢„è®­ç»ƒå¯¹æ³›åŒ–çš„é‡è¦æ€§ |
| **å¤šæ¨¡æ€è¾“å…¥æ¶ˆè** | å•ç‹¬ä½¿ç”¨â€œå­—èŠ‚â€æˆ–â€œå¤§å°â€æ•ˆæœæ¬¡ä¼˜ï¼›ä¸‰è€…èåˆï¼ˆAllï¼‰è¾¾åˆ°æœ€ä¼˜ |
| **LDAå¾®è°ƒå…³é—­** | åœ¨é•¿å°¾æ•°æ®é›†ï¼ˆå¦‚Huawei-VPNï¼‰ä¸ŠACCæœ€å¤šä¸‹é™ **0.79%**ï¼ŒF1ä¸‹é™ **0.85%**ï¼Œè¯å®LDAæœ‰æ•ˆ |

> å›¾7æ˜¾ç¤ºCP-iOSæ•°æ®é›†è¿‡æ»¤å‰åä»å­˜åœ¨æ˜æ˜¾ç±»åˆ«ä¸å¹³è¡¡ï¼Œè¿›ä¸€æ­¥æ”¯æŒLDAå¿…è¦æ€§ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **Mambaé€‚ç”¨äºç½‘ç»œæµé‡å»ºæ¨¡**ï¼šå•å‘Mambaåœ¨ä¿æŒçº¿æ€§å¤æ‚åº¦çš„åŒæ—¶ï¼Œæ€§èƒ½åª²ç¾ç”šè‡³è¶…è¶ŠTransformerï¼Œæ˜¯é«˜æ•ˆæµé‡åˆ†æçš„ç†æƒ³é€‰æ‹©ã€‚
2. **å¤šæ¨¡æ€è¾“å…¥è‡³å…³é‡è¦**ï¼šä»…ä¾èµ–åŸå§‹å­—èŠ‚ä¸è¶³ä»¥åº”å¯¹ç°ä»£åŠ å¯†æµé‡ï¼›åŠ å…¥åŒ…å¤§å°å’Œæ—¶é—´é—´éš”å¯æ˜¾è‘—å¢å¼ºè¡¨å¾èƒ½åŠ›ã€‚
3. **stride-basedåˆ‡å‰²ä¼˜äºpatchåˆ†å—**ï¼šæ›´è´´åˆç½‘ç»œæµé‡çš„åºåˆ—ç‰¹æ€§ï¼Œé¿å…å›¾åƒåŒ–å¤„ç†å¸¦æ¥çš„è¯­ä¹‰åå·®ã€‚
4. **LDAå¾®è°ƒæœ‰æ•ˆç¼“è§£é•¿å°¾é—®é¢˜**ï¼šæ— éœ€é‡é‡‡æ ·å³å¯æå‡å¯¹ç¨€æœ‰ç±»åˆ«çš„è¯†åˆ«èƒ½åŠ›ã€‚
5. **é¢„è®­ç»ƒæå¤§æå‡å°‘æ ·æœ¬æ€§èƒ½**ï¼šNetMamba+åœ¨æå°‘é‡æ ‡æ³¨æ•°æ®ä¸‹ä»ä¿æŒé«˜å‡†ç¡®ç‡ï¼Œé€‚åˆå®é™…éƒ¨ç½²ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
- **å¯¹åˆ†å¸ƒåç§»æ•æ„Ÿ**ï¼šåœ¨æ—¶é—´ç»´åº¦ä¸Šçš„åˆ†å¸ƒæ¼‚ç§»ï¼ˆdistribution shiftï¼‰ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ï¼ˆå¦‚CSTNET-TLS1.3å‡†ç¡®ç‡ä¸‹é™8.47%ï¼‰ã€‚
- **ä¾èµ–é«˜è´¨é‡æµé‡åˆ‡åˆ†**ï¼šéœ€æ­£ç¡®è§£æ5å…ƒç»„å¹¶æˆªå–å‰è‹¥å¹²åŒ…ï¼Œå¯¹å¼‚å¸¸æˆ–ç¢ç‰‡åŒ–æµé‡é²æ£’æ€§å¾…éªŒè¯ã€‚
- **æœªæ¢ç´¢æ›´å¤§è§„æ¨¡æ¨¡å‹**ï¼šå½“å‰å‚æ•°é‡è¾ƒå°ï¼ˆ<3Mï¼‰ï¼Œæ˜¯å¦èƒ½æ‰©å±•è‡³ç™¾äº¿çº§å°šä¸æ˜ç¡®ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
- å¢å¼ºæ¨¡å‹å¯¹ **æ—¶é—´åˆ†å¸ƒæ¼‚ç§»** çš„é²æ£’æ€§ï¼ˆä¾‹å¦‚å¼•å…¥æŒç»­å­¦ä¹ æœºåˆ¶ï¼‰ã€‚
- æ¢ç´¢ **æ›´å¤§è§„æ¨¡NetMamba++** æ¨¡å‹ç”¨äºé€šç”¨ç½‘ç»œåŸºç¡€æ¨¡å‹ï¼ˆNetwork Foundation Modelï¼‰ã€‚
- æ‰©å±•è‡³æ›´å¤šä¸‹æ¸¸ä»»åŠ¡ï¼šå¦‚æœåŠ¡è´¨é‡é¢„æµ‹ï¼ˆQoSï¼‰ã€ç½‘ç»œæ€§èƒ½è¯Šæ–­ã€å…¥ä¾µå“åº”ç”Ÿæˆç­‰ã€‚
- è¿›ä¸€æ­¥ä¼˜åŒ–åœ¨çº¿ç³»ç»Ÿå»¶è¿Ÿï¼Œé€‚é…è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²ã€‚

---

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> **NetMamba+ æ˜¯é¦–ä¸ªå°† Mamba æ¶æ„å¼•å…¥ç½‘ç»œæµé‡åˆ†ç±»çš„å·¥ä½œï¼Œé€šè¿‡é«˜æ•ˆçš„åºåˆ—å»ºæ¨¡ã€å¤šæ¨¡æ€è¡¨å¾ä¸æ ‡ç­¾æ„ŸçŸ¥å¾®è°ƒï¼Œåœ¨å‡†ç¡®æ€§ã€æ•ˆç‡ä¸æ³›åŒ–æ€§ä¸Šå…¨é¢è¶…è¶Šç°æœ‰SOTAæ–¹æ³•ï¼Œä¸ºä¸‹ä¸€ä»£æ™ºèƒ½ç½‘ç»œåˆ†ææä¾›äº†æ–°èŒƒå¼ã€‚**

</details>

---

### 3. [Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts](https://arxiv.org/abs/2601.22156)

**Authors**: Yingfa Chen, Zhen Leng Thai, Zihan Zhou, Zhu Zhang, Xingyu Shen, Shuo Wang, Chaojun Xiao, Xu Han, Zhiyuan Liu  
**Category**: cs.CL  
**Published**: 2026-01-30  
**Score**: 11.5  
**Type**: new  
**ArXiv ID**: 2601.22156v1  

#### Abstract
Hybrid Transformer architectures, which combine softmax attention blocks and recurrent neural networks (RNNs), have shown a desirable performance-throughput tradeoff for long-context modeling, but their adoption and studies are hindered by the prohibitive cost of large-scale pre-training from scratc...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
å½“å‰ä¸»æµçš„ **Transformer** æ¨¡å‹ä¾èµ– **softmax attention**ï¼Œå…¶è®¡ç®—å¤æ‚åº¦ä¸º $O(T^2)$ï¼ˆ$T$ ä¸ºä¸Šä¸‹æ–‡é•¿åº¦ï¼‰ï¼Œåœ¨å¤„ç† **é•¿ä¸Šä¸‹æ–‡ï¼ˆlong-contextï¼‰** ä»»åŠ¡æ—¶æ•ˆç‡æä½ã€‚è™½ç„¶ **RNN-based æ¨¡å‹**ï¼ˆå¦‚ linear attentionã€state space modelsï¼‰å…·æœ‰çº¿æ€§å¤æ‚åº¦ $O(T)$ï¼Œæ¨ç†é€Ÿåº¦æ›´å¿«ï¼Œä½†åœ¨ **recall-intensive ä»»åŠ¡**ï¼ˆå¦‚â€œå¤§æµ·æé’ˆâ€NIAHï¼‰ä¸Šè¡¨ç°ä¸ä½³ã€‚

æ··åˆæ¶æ„ï¼ˆ**hybrid architecture**ï¼‰ç»“åˆäº† **attention å±‚** å’Œ **RNN å±‚**ï¼Œè¯•å›¾åœ¨æ€§èƒ½ä¸æ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡ã€‚ç„¶è€Œï¼Œè¿™ç±»æ¨¡å‹é€šå¸¸éœ€è¦ä»å¤´å¤§è§„æ¨¡é¢„è®­ç»ƒï¼Œæˆæœ¬é«˜æ˜‚ï¼Œé™åˆ¶äº†å­¦æœ¯ç•Œçš„ç ”ç©¶ã€‚æ­¤å¤–ï¼Œç°æœ‰çš„å°†é¢„è®­ç»ƒ Transformer è’¸é¦ä¸º hybrid æ¨¡å‹çš„æ–¹æ³•å­˜åœ¨ä¸¤å¤§é—®é¢˜ï¼š
1. ä»éœ€æ•°åäº¿ç”šè‡³æ•°ç™¾äº¿ token çš„è®­ç»ƒæ•°æ®ï¼›
2. åœ¨é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ä¸Šæ€§èƒ½ä¸¥é‡ä¸‹é™ï¼Œè¿èƒŒäº† hybrid æ¶æ„çš„è®¾è®¡åˆè¡·ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹

æœ¬æ–‡æå‡º **HALO**ï¼ˆHybrid Attention via Layer Optimizationï¼‰å’Œ **HypeNet**ï¼Œç³»ç»Ÿæ€§åœ°è§£å†³äº†ä¸Šè¿°é—®é¢˜ã€‚

#### ï¼ˆ1ï¼‰HALOï¼šé«˜æ•ˆè·¨æ¶æ„è’¸é¦æµç¨‹
- **ç›®æ ‡**ï¼šå°†å·²æœ‰çš„é¢„è®­ç»ƒ Transformer æ¨¡å‹ï¼ˆå¦‚ Qwen3ï¼‰é«˜æ•ˆåœ°è½¬æ¢ä¸ºé«˜æ€§èƒ½ hybrid æ¨¡å‹ã€‚
- **åˆ›æ–°ç‚¹**ï¼š
  - **é«˜æ•ˆçš„æ³¨æ„åŠ›å±‚é€‰æ‹©æœºåˆ¶**ï¼šé€šè¿‡è¡¡é‡æ›¿æ¢æŸä¸€å±‚ä¸º RNN åå¯¹ **recall æ€§èƒ½** å’Œ **å¸¸è¯†æ¨ç†ï¼ˆCSRï¼‰æ€§èƒ½** çš„å½±å“ï¼Œè®¾è®¡é‡è¦æ€§è¯„åˆ†å‡½æ•°ï¼Œä¼˜å…ˆä¿ç•™å¯¹ recall è‡³å…³é‡è¦çš„ attention å±‚ã€‚
  - **ä¸‰é˜¶æ®µè’¸é¦æµç¨‹**ï¼š
    1. **åˆå§‹åŒ–ï¼ˆAttention Weight Transferï¼‰**ï¼šå°† attention å±‚å‚æ•°æ˜ å°„åˆ° RNN å±‚ã€‚
    2. **éšè—çŠ¶æ€å¯¹é½ï¼ˆHidden State Alignmentï¼‰**ï¼šç‹¬ç«‹è®­ç»ƒæ¯ä¸ª RNN å±‚ä»¥åŒ¹é…åŸ attention å±‚è¾“å‡ºã€‚
    3. **ç«¯åˆ°ç«¯çŸ¥è¯†è’¸é¦ï¼ˆKnowledge Distillationï¼‰**ï¼šä»¥åŸå§‹ Transformer ä¸º teacherï¼Œè¿›è¡Œå®Œæ•´æ¨¡å‹è’¸é¦ã€‚
    4. **å¾®è°ƒï¼ˆFinetuningï¼‰**ï¼šåœ¨æ›´é•¿ä¸Šä¸‹æ–‡ä¸Šå¾®è°ƒä»¥æå‡é•¿æ–‡æœ¬èƒ½åŠ›ã€‚
- **ä¼˜åŠ¿**ï¼šæ•´ä¸ªè¿‡ç¨‹ä»…éœ€ **2.3B tokens**ï¼Œè¿œä½äºç°æœ‰æ–¹æ³•ï¼ˆå¦‚ Jet-Nemotron éœ€ 400B tokensï¼‰ã€‚

#### ï¼ˆ2ï¼‰HypeNetï¼šé«˜æ€§èƒ½æ··åˆæ¶æ„
- **ç›®æ ‡**ï¼šè®¾è®¡ä¸€ä¸ªåœ¨é•¿ä¸Šä¸‹æ–‡ä¸‹å…·å¤‡å¼ºæ³›åŒ–èƒ½åŠ›çš„ hybrid æ¶æ„ã€‚
- **æ ¸å¿ƒåˆ›æ–°**ï¼š
  - **HyPEï¼ˆHybrid Positional Encodingï¼‰**ï¼š
    - **RNN å±‚ä½¿ç”¨ RoPE**ï¼šæ³¨å…¥ä¸°å¯Œçš„ä½ç½®ä¿¡æ¯ï¼Œæå‡å»ºæ¨¡èƒ½åŠ›ã€‚
    - **attention å±‚ä½¿ç”¨ NoPE**ï¼šåˆ©ç”¨ NoPE æ›´å¥½çš„è®­ç»ƒåé•¿åº¦å¤–æ¨ï¼ˆlength generalizationï¼‰èƒ½åŠ›ã€‚
    - ç»“åˆäº† RoPE çš„è¡¨è¾¾åŠ›ä¸ NoPE çš„æ³›åŒ–åŠ›ã€‚
  - **åŠ¨æ€æ³¨æ„åŠ›ç¼©æ”¾ï¼ˆDynamic Attention Scalingï¼‰**ï¼šåœ¨æ¨ç†æ—¶å¯¹ attention logits è¿›è¡Œä½ç½®ç›¸å…³ç¼©æ”¾ $s_t = \log(t + a)$ï¼Œç¼“è§£é•¿åºåˆ—ç†µå¢é—®é¢˜ã€‚
  - **å…¶ä»–æ¶æ„æ”¹è¿›**ï¼š
    - **QK-Normalization**ï¼šå¼•å…¥åˆ° RNN å±‚ä¸­ã€‚
    - **GQA to MHA**ï¼šè§£é™¤ RNN å±‚ä¸­ K/V å…±äº«ï¼Œå¢å¼ºè¡¨è¾¾èƒ½åŠ›ã€‚
    - **Output Gate**ï¼šåœ¨ attention å’Œ RNN å±‚å‡åŠ å…¥é—¨æ§æœºåˆ¶ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | æ‰€éœ€è®­ç»ƒ tokens | æ˜¯å¦æ”¯æŒé•¿ä¸Šä¸‹æ–‡ | æ˜¯å¦å¼€æº |
|------|----------------|------------------|----------|
| ä»å¤´é¢„è®­ç»ƒ hybrid | >100B | âœ… | âŒï¼ˆå¤šæ•°é—­æºï¼‰ |
| Jet-Nemotron (Gu et al., 2025) | 400B | âŒï¼ˆæ€§èƒ½éª¤é™ï¼‰ | âœ… |
| KL-LS (Li et al., 2025) | 25B | âŒ | âœ… |
| **HALO (ours)** | **2.3B** | âœ… | âœ… |

- **æ•°æ®æ•ˆç‡é«˜**ï¼šä»…ç”¨ 2.3B tokensï¼Œä¸è¶³ Qwen3 é¢„è®­ç»ƒæ•°æ®çš„ 0.01%ã€‚
- **é•¿ä¸Šä¸‹æ–‡æ€§èƒ½ä¼˜è¶Š**ï¼šåœ¨ NIAH ç­‰ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰è’¸é¦æ–¹æ³•ã€‚
- **å®Œå…¨å¼€æº**ï¼šä»£ç ä¸æ¨¡å‹å‡å·²å…¬å¼€ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **è®­ç»ƒæ•°æ®**ï¼šFineWeb-eduï¼ˆé«˜è´¨é‡äº’è”ç½‘æ–‡æœ¬å­é›†ï¼‰ï¼Œä»ä¸­é‡‡æ · 2.3B tokensã€‚
  - Stage 1ï¼š320M tokensï¼Œcontext=512
  - Stage 2ï¼š1B tokensï¼Œcontext=512
  - Stage 3ï¼š1B tokensï¼Œcontext=16K
- **è¯„ä¼°æ•°æ®**ï¼š
  - **å¸¸è¯†æ¨ç†ï¼ˆCSRï¼‰**ï¼šARC-Easy, ARC-Challenge, HellaSwag, WinoGrande, PIQA, LAMBADA, MMLU
  - **é•¿ä¸Šä¸‹æ–‡å¬å›ï¼ˆLong-context Recallï¼‰**ï¼šRULER å¥—ä»¶ä¸­çš„ **Needle-in-a-Haystack (NIAH)** ä»»åŠ¡ï¼Œæµ‹è¯•é•¿åº¦è¾¾ 256Kã€‚

---

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡
- **æ¨¡å‹åŸºç¡€**ï¼šåŸºäº Qwen3-1.7B, 4B, 8B è¿›è¡Œè½¬æ¢ã€‚
- **ç¡¬ä»¶ç¯å¢ƒ**ï¼šå•å¼  NVIDIA A800 GPUï¼ŒBFloat16 ç²¾åº¦ã€‚
- **è¯„ä¼°æŒ‡æ ‡**ï¼š
  - **CSR Score**ï¼šå¤šä¸ªä¸‹æ¸¸ä»»åŠ¡çš„å¹³å‡å½’ä¸€åŒ–å‡†ç¡®ç‡ã€‚
  - **NIAH Accuracy**ï¼šåœ¨ä¸åŒä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆ4Kâ€“256Kï¼‰ä¸‹çš„â€œå¤§æµ·æé’ˆâ€å‡†ç¡®ç‡ã€‚
  - **æ•ˆç‡æŒ‡æ ‡**ï¼š
    - **Throughput (tokens/s)**ï¼šæ¯ç§’ç”Ÿæˆ token æ•°ã€‚
    - **Time per Output Token (TPOT)**ï¼šæ¯ä¸ªè¾“å‡º token çš„å»¶è¿Ÿã€‚
    - **Prefill Time**ï¼šå‰ç¼€å¡«å……æ—¶é—´ã€‚

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | æ¥æº | æ‰€éœ€ tokens |
|------|------|-----------|
| Qwen3 (åŸæ¨¡å‹) | Qwen, 2025 | â€” |
| Jet-Nemotron | Gu et al., 2025 | 400B |
| KL-LS (GDN) | Li et al., 2025 | 25B |
| Mamba-in-the-Llama | Wang et al., 2025b | 20B |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆQwen3-1.7B vs HypeNet-2Bï¼‰

#### ï¼ˆ1ï¼‰é•¿ä¸Šä¸‹æ–‡å¬å›æ€§èƒ½ï¼ˆNIAHï¼‰
| æ¨¡å‹ | 32K | 64K | 128K | 256K |
|------|-----|-----|------|------|
| Qwen3 (åŸæ¨¡å‹) | 96.4 | 24.8 | 14.8 | 19.0 |
| Jet-Nemotron | 0.0 | 0.0 | 0.0 | 0.0 |
| KL-LS (GDN) | 68.4 | 28.2 | 24.8 | 11.0 |
| **HypeNet + HALO (ours)** | **99.8** | **97.8** | **86.2** | **48.8** |

> ğŸ’¡ **ç»“è®º**ï¼šHypeNet åœ¨æ‰€æœ‰é•¿åº¦ä¸‹å‡æ˜¾è‘—ä¼˜äºç°æœ‰è’¸é¦æ–¹æ³•ï¼Œå°¤å…¶åœ¨ 128K ä¸Šè¾¾åˆ° 86.2%ï¼Œè€Œå…¶ä»–æ–¹æ³•å‡ ä¹å¤±æ•ˆã€‚

#### ï¼ˆ2ï¼‰å¸¸è¯†æ¨ç†ï¼ˆCSRï¼‰
| æ¨¡å‹ | CSR Score |
|------|---------|
| Qwen3-1.7B | 58.5 |
| HypeNet + HALO | 55.9 |

> å°½ç®¡ç•¥æœ‰ä¸‹é™ï¼Œä½†ä»åœ¨åˆç†èŒƒå›´å†…ï¼Œä¸”è¿œé«˜äºçº¯ RNN æ¨¡å‹ã€‚

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **æ•ˆç‡æ–¹é¢**ï¼ˆå›¾1ï¼‰ï¼š
  - åœ¨ 128K ä¸Šä¸‹æ–‡ä¸‹ï¼ŒHypeNet çš„ **throughput æ˜¯ Qwen3 çš„ 2.4â€“3.0Ã—**ã€‚
  - åœ¨ 512K ä¸Šï¼ŒHypeNet å®ç° **3.4Ã— prefill speedup**ã€‚
  - Qwen3 åœ¨ 1M ä¸Šä¸‹æ–‡æ—¶æ˜¾å­˜æº¢å‡ºï¼Œè€Œ HypeNet ä»å¯è¿è¡Œã€‚

- **ç»¼åˆæ€§èƒ½-æ•ˆç‡æƒè¡¡**ï¼šHypeNet åœ¨ä¿æŒæ¥è¿‘åŸæ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œå®ç°äº†æ˜¾è‘—çš„æ¨ç†åŠ é€Ÿå’Œå†…å­˜èŠ‚çœã€‚

---

### æ¶ˆèå®éªŒç»“æœ

#### ï¼ˆ1ï¼‰HypeNet æ¶æ„ç»„ä»¶æ¶ˆèï¼ˆTable 3ï¼‰
ç§»é™¤ä»»ä¸€ç»„ä»¶å‡å¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œå°¤å…¶æ˜¯ï¼š
- ç§»é™¤ **RNN RoPE**ï¼ˆå³ RNN æ— ä½ç½®ç¼–ç ï¼‰ï¼š128K NIAH ä» 79.9â†“è‡³ 47.9
- ç§»é™¤ **RNN QK-Norm**ï¼š128K NIAHâ†“è‡³ 17.3
- ç§»é™¤ **RNN Output Gate**ï¼š128K NIAHâ†“è‡³ 74.5

> è¡¨æ˜æ‰€æœ‰æå‡ºçš„æ¶æ„æ”¹è¿›å‡æœ‰æ•ˆã€‚

#### ï¼ˆ2ï¼‰æ³¨æ„åŠ›å±‚é€‰æ‹©æ–¹æ³•å¯¹æ¯”ï¼ˆTable 4ï¼‰
| æ–¹æ³• | 128K NIAH | 256K NIAH |
|------|----------|----------|
| Evenly distributed | 61.9 | 50.9 |
| Jet-Nemotron (Gu et al.) | 63.7 | 56.2 |
| KL-LS (Li et al.) | 58.3 | 44.3 |
| **HALO (ours)** | **79.9** | **74.3** |

> è¯æ˜æœ¬æ–‡æå‡ºçš„ layer selection æ–¹æ³•æ›´ä¼˜ã€‚

#### ï¼ˆ3ï¼‰RNN Mixer å¯¹æ¯”ï¼ˆFigure 5ï¼‰
å°½ç®¡ **Lightning Attention** ç»“æ„æœ€ç®€å•ï¼Œä½†åœ¨é•¿åº¦æ³›åŒ–ä¸Šä¼˜äº Mamba2ã€GLAã€GDNã€RWKV-7ã€‚
- å¯èƒ½åŸå› ï¼šå…¶ **data-independent forget gate** æ›´åˆ©äºé•¿åºåˆ—å»ºæ¨¡ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **é«˜æ•ˆè’¸é¦æ˜¯å¯è¡Œçš„**ï¼šé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„ä¸‰é˜¶æ®µæµç¨‹ï¼ˆHALOï¼‰ï¼Œå¯åœ¨æå°‘é‡æ•°æ®ï¼ˆ2.3B tokensï¼‰ä¸‹å®Œæˆä» Transformer åˆ° hybrid æ¨¡å‹çš„è½¬æ¢ã€‚
2. **HyPE æ˜¯å…³é”®åˆ›æ–°**ï¼šå°† RoPE å¼•å…¥ RNN å±‚ã€NoPE ç”¨äº attention å±‚ï¼Œç»“åˆåŠ¨æ€ç¼©æ”¾ï¼Œæå¤§æå‡äº†é•¿ä¸Šä¸‹æ–‡æ³›åŒ–èƒ½åŠ›ã€‚
3. **æ¶æ„ç»†èŠ‚è‡³å…³é‡è¦**ï¼šQK-Normã€GQA to MHAã€Output Gate ç­‰å°æ”¹åŠ¨å¯¹æœ€ç»ˆæ€§èƒ½æœ‰æ˜¾è‘—å½±å“ã€‚
4. **ç®€å•çš„ RNN mixer å¯èƒ½æ›´ä¼˜**ï¼šLightning Attention å‡­å€Ÿå…¶ç®€æ´æ€§å’Œå›ºå®šè¡°å‡æœºåˆ¶ï¼Œåœ¨é•¿åºåˆ—ä»»åŠ¡ä¸­è¡¨ç°æœ€ä½³ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–é¢„è®­ç»ƒæ¨¡å‹è¡Œä¸º**ï¼šè½¬æ¢åçš„æ¨¡å‹å¯èƒ½ä¸¢å¤±åŸæ¨¡å‹åœ¨æŒ‡ä»¤éµå¾ªï¼ˆinstruction-followingï¼‰å’Œå¯¹é½ï¼ˆalignmentï¼‰æ–¹é¢çš„åè®­ç»ƒèƒ½åŠ›ã€‚
2. **ä»…é€‚ç”¨äº Transformer-based æ¨¡å‹**ï¼šå½“å‰æµç¨‹é’ˆå¯¹æ ‡å‡† Transformer è®¾è®¡ï¼Œéš¾ä»¥ç›´æ¥è¿ç§»åˆ°å…¶ä»–æ¶æ„ï¼ˆå¦‚ RetNetã€RWKVï¼‰ã€‚
3. **æœªåŒ…å«çŸ­å·ç§¯ï¼ˆshort convolutionï¼‰**ï¼šè™½ç„¶å®ç°æ›´ç®€å•ï¼Œä½†å¯èƒ½ç‰ºç‰²éƒ¨åˆ†å±€éƒ¨å»ºæ¨¡èƒ½åŠ›ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ¢å¤å¯¹é½èƒ½åŠ›**ï¼šæ¢ç´¢å¦‚ä½•åœ¨è’¸é¦åé«˜æ•ˆæ¢å¤æŒ‡ä»¤éµå¾ªå’Œå¯¹è¯èƒ½åŠ›ã€‚
2. **æ‰©å±•åˆ°æ›´å¤šæ¶æ„**ï¼šå°† HALO æ¡†æ¶æ¨å¹¿è‡³é Transformer åŸºç¡€æ¨¡å‹ã€‚
3. **è‡ªåŠ¨åŒ–å±‚é€‰æ‹©**ï¼šè®¾è®¡æ— éœ€äººå·¥å®šä¹‰ k çš„è‡ªé€‚åº” attention å±‚ä¿ç•™ç­–ç•¥ã€‚
4. **å¤šä»»åŠ¡è”åˆä¼˜åŒ–**ï¼šåœ¨è’¸é¦è¿‡ç¨‹ä¸­è”åˆä¼˜åŒ– CSRã€recallã€æ•ˆç‡ç­‰å¤šé¡¹ç›®æ ‡ã€‚

---

> ğŸ”— **ä»£ç ä¸æ¨¡å‹**ï¼šhttps://github.com/THUNLP/hybrid-linear-attention

</details>

---

### 4. [L$^3$: Large Lookup Layers](https://arxiv.org/abs/2601.21461)

**Authors**: Albert Tseng, Christopher De Sa  
**Category**: cs.LG  
**Published**: 2026-01-30  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2601.21461v1  

#### Abstract
Modern sparse language models typically achieve sparsity through Mixture-of-Experts (MoE) layers, which dynamically route tokens to dense MLP "experts." However, dynamic hard routing has a number of drawbacks, such as potentially poor hardware efficiency and needing auxiliary losses for stable train...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠLÂ³: Large Lookup Layersã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³äº†ä»€ä¹ˆé—®é¢˜

ç°ä»£ç¨€ç–è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ **MoE**ï¼‰é€šè¿‡åŠ¨æ€è·¯ç”±ï¼ˆcontext-dependent routingï¼‰å®ç°é«˜å‚æ•°é‡ä¸‹çš„é«˜æ•ˆæ¿€æ´»ï¼Œä½†å­˜åœ¨ä»¥ä¸‹ç³»ç»Ÿçº§æŒ‘æˆ˜ï¼š

- **ç¡¬ä»¶æ•ˆç‡ä½**ï¼šè·¯ç”±å†³ç­–ä¾èµ–ä¸Šä¸‹æ–‡ï¼Œæ— æ³•æå‰é¢„çŸ¥éœ€æ¿€æ´»çš„ä¸“å®¶ï¼Œå¯¼è‡´éš¾ä»¥è¿›è¡Œå‚æ•°å¸è½½ï¼ˆoffloadingï¼‰å’Œæµæ°´çº¿ä¼˜åŒ–ã€‚
- **è®­ç»ƒä¸ç¨³å®š**ï¼šéœ€è¦å¼•å…¥è¾…åŠ©æŸå¤±ï¼ˆauxiliary lossesï¼‰æ¥å¹³è¡¡ä¸“å®¶è´Ÿè½½ï¼Œé˜²æ­¢â€œä¸“å®¶åç¼©â€ï¼ˆexpert collapseï¼‰ã€‚
- **éƒ¨ç½²å¤æ‚**ï¼šåŠ¨æ€è·¯ç”±å¢åŠ äº†è°ƒåº¦å¼€é”€ï¼Œå°¤å…¶åœ¨ CPU/GPU æ··åˆæ¨ç†ä¸­è¡¨ç°ä¸ä½³ã€‚

æ­¤å¤–ï¼Œä¼ ç»Ÿ **tokenizer embedding è¡¨**è™½ç„¶ç¨€ç–ä¸”é«˜æ•ˆï¼Œä½†ç¼ºä¹ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›ï¼Œä»…ç”¨äºåˆå§‹åŒ– token è¡¨ç¤ºã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ï¼šLarge Lookup Layer (LÂ³)

LÂ³ æ˜¯ä¸€ç§æ–°å‹ç¨€ç–æ¶æ„ï¼Œ**å°† tokenizer embedding è¡¨çš„æ€æƒ³æ¨å¹¿åˆ° decoder å±‚å†…éƒ¨**ï¼Œæå‡ºäº†ä¸€ç§**é™æ€è·¯ç”± + ä¸Šä¸‹æ–‡èšåˆ**çš„æ··åˆæœºåˆ¶ã€‚

#### æ ¸å¿ƒæ€æƒ³ï¼š
- å¼•å…¥ä¸€ä¸ªå¤§å‹å¯å­¦ä¹ çš„ **embedding lookup table**ï¼Œæ¯ä¸ª token ID å¯ä»¥è®¿é—®ä¸€ç»„ä¸å…¶ç›¸å…³çš„ embeddingsã€‚
- ä½¿ç”¨ **é™æ€è·¯ç”±ï¼ˆstatic routingï¼‰**ï¼šæ ¹æ® token ID é¢„å…ˆç¡®å®šå¯è®¿é—®çš„ embedding å­é›†ï¼ˆå³â€œå…è®¸é›†åˆâ€ï¼‰ï¼Œæ— éœ€è¿è¡Œæ—¶è®¡ç®—è·¯ç”±ã€‚
- åˆ©ç”¨å½“å‰ token çš„ hidden state å¯¹è¿™äº› embeddings è¿›è¡Œ **attention-based èšåˆ**ï¼Œå®ç°**ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„ä¿¡æ¯æ£€ç´¢**ã€‚

> ğŸ”‘ å…³é”®æ´å¯Ÿï¼š**ç”¨é™æ€ token è·¯ç”±æ¨¡æ‹ŸåŠ¨æ€ MoE è·¯ç”±çš„è¡Œä¸ºï¼ŒåŒæ—¶ä¿ç•™ç³»ç»Ÿå‹å¥½æ€§ã€‚**

---

### âš–ï¸ ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç‰¹æ€§ | MoE | LÂ³ |
|------|-----|----|
| è·¯ç”±æ–¹å¼ | åŠ¨æ€ï¼ˆcontext-dependentï¼‰ | é™æ€ï¼ˆtoken-basedï¼‰ |
| å‚æ•°æ¿€æ´»æ˜¯å¦å¯é¢„æµ‹ | âŒ å¦ | âœ… æ˜¯ï¼ˆtoken ç”Ÿæˆå³çŸ¥ï¼‰ |
| æ”¯æŒ CPU offloading | å›°éš¾ï¼ˆéœ€é¢å¤– overheadï¼‰ | âœ… æä½å¼€é”€ï¼ˆå¯é¢„å–ï¼‰ |
| æ˜¯å¦éœ€è¦è¾…åŠ©æŸå¤± | âœ… æ˜¯ï¼ˆload balancingï¼‰ | âŒ å¦ |
| ç¡¬ä»¶å‹å¥½æ€§ | ä¸­ç­‰åä½ | é«˜ |
| ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ› | å¼º | ä¸­å¼ºï¼ˆé€šè¿‡ attention èšåˆï¼‰ |
| æ‰©å±•æ€§ | å—é™äºä¸“å®¶é€šä¿¡ | æ›´æ˜“æ‰©å±•ï¼ˆæ¨¡å—åŒ–ï¼‰ |

> ğŸ’¡ LÂ³ å¹¶éæ›¿ä»£ MoEï¼Œè€Œæ˜¯æä¾›äº†ä¸€ä¸ª**æ­£äº¤çš„ç¨€ç–æ‰©å±•è½´**ï¼Œå¯ä¸ MoE å…±å­˜ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†

- **è®­ç»ƒæ•°æ®**ï¼š`FineWeb-Edu`ï¼ˆç»è¿‡è¿‡æ»¤çš„æ•™è‚²ç±»ç½‘é¡µæ–‡æœ¬ï¼‰
  - æ€»è®­ç»ƒ token æ•°ï¼š800M æ¨¡å‹è®­ç»ƒ 10B tokensï¼Œ1.5B æ¨¡å‹è®­ç»ƒ 20Bï¼Œ2.6B æ¨¡å‹è®­ç»ƒ 30B
  - ä¸Šä¸‹æ–‡é•¿åº¦ï¼š2048
- **è¯„ä¼°æ•°æ®**ï¼š
  - **Perplexity**ï¼šWikitext2
  - **ä¸‹æ¸¸ä»»åŠ¡**ï¼šARC-C, ARC-E, HellaSwag, PIQA, Winograndeï¼ˆzero-shot accuracyï¼‰

---

### ğŸ§ª å®éªŒè®¾ç½®

#### æ¨¡å‹æ¶æ„åŸºç¡€ï¼š
- åŸºäº **Llama 3** decoder æ¶æ„
- åœ¨ decoder å±‚ä¹‹é—´æ’å…¥ **LÂ³ layer**
- ä¸æ›¿æ¢ MLP å±‚ï¼ˆåŒºåˆ«äº MoEï¼‰ï¼Œä½œä¸ºå¢å¼ºæ¨¡å—æ·»åŠ 

#### LÂ³ å…³é”®è¶…å‚ï¼š
- æ€» embedding æ•° $ u = 710K $
- æ¯ä¸ª token æœ€å¤šåˆ†é… $ k = 512 $ ä¸ª embeddings
- ä½¿ç”¨ **LZW-based åˆ†é…ç®—æ³•** å†³å®šå“ªäº› token è·å–æ›´å¤š embeddings

#### åŸºçº¿å¯¹æ¯”æ–¹æ³•ï¼š
| ç±»å‹ | æ–¹æ³• |
|------|------|
| å¯†é›†æ¨¡å‹ | Dense Transformerï¼ˆç›¸åŒ FLOPsï¼‰ |
| ç¨€ç–æ¨¡å‹ | Mixture-of-Experts (MoE)ï¼Œæ§åˆ¶ä¸º iso-FLOPã€iso-depthã€iso-sparsity |
| æ¶ˆèå®éªŒ | ä¸åŒ LÂ³ å±‚æ•°ã€ä¸åŒ embedding åˆ†é…ç­–ç•¥ï¼ˆuniform vs LZWï¼‰ã€weight tying |

#### è¯„ä¼°æŒ‡æ ‡ï¼š
- **è®­ç»ƒé˜¶æ®µ**ï¼šPerplexity æ›²çº¿ï¼ˆFineWeb-Eduï¼‰
- **æ¨ç†é˜¶æ®µ**ï¼š
  - Zero-shot å‡†ç¡®ç‡ï¼ˆå¤šä¸ª NLU ä»»åŠ¡ï¼‰
  - æ¨ç†ååé‡ï¼ˆtokens/secï¼‰
  - Offloading å¼€é”€åˆ†æ

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®

#### âœ… Perplexity æå‡æ˜¾è‘—ï¼ˆå›¾6 & è¡¨1ï¼‰

| æ¨¡å‹ | Active Params | Total Params | PPL (Wiki2) |
|------|---------------|--------------|-------------|
| Dense 800M | 809M | 809M | 22.02 |
| LÂ³ Ã—1 (800M) | 795M | 1.8B | **20.81** |
| LÂ³ Ã—3 (800M*) | 818M | 5.2B | **19.59** |
| Dense 2.6B | 2.6B | 2.6B | 15.43 |
| LÂ³ Ã—2 (2.6B) | 2.6B | 7.0B | **14.51** |

> â• åœ¨ç›¸åŒ active å‚æ•°ä¸‹ï¼ŒLÂ³ æ˜¾è‘—é™ä½ perplexityï¼Œä¸”æå‡éšå±‚æ•°å¢åŠ è€ŒæŒç»­ã€‚

---

#### âœ… ä¸‹æ¸¸ zero-shot æ€§èƒ½å…¨é¢é¢†å…ˆï¼ˆè¡¨1ï¼‰

ä»¥ 2.6B æ¨¡å‹ä¸ºä¾‹ï¼š

| Task | Dense | LÂ³ (+2 layers) | æå‡å¹…åº¦ |
|------|-------|----------------|---------|
| ARC-C | 36.35 | **38.21** | +1.86 |
| HellaSwag | 44.20 | **44.95** | +0.75 |
| PIQA | 71.22 | **71.71** | +0.49 |
| Winogrande | 57.30 | **58.80** | +1.50 |

> æ‰€æœ‰ä»»åŠ¡å‡å–å¾—ä¸€è‡´æå‡ï¼Œè¡¨æ˜ LÂ³ å¸¦æ¥çš„å¢ç›Šæ˜¯æ³›åŒ–çš„ã€‚

---

#### âœ… æ˜¾è‘—ä¼˜äº iso-FLOP MoEï¼ˆå›¾8ï¼‰

- åœ¨ 800M å’Œ 1.5B å°ºå¯¸ä¸‹ï¼Œ**LÂ³ çš„ perplexity æ”¹å–„è¿œè¶…åŒç­‰ç¨€ç–åº¦çš„ MoE**
- ç‰¹åˆ«æ˜¯åœ¨ä½é¢„ç®—åœºæ™¯ï¼ˆå¦‚ 800Mï¼‰ï¼ŒMoE ç”šè‡³ä¸å¦‚ dense baselineï¼Œè€Œ LÂ³ å§‹ç»ˆæ­£å‘å¢ç›Š
- ç»“è®ºï¼š**LÂ³ çš„æ”¶ç›Šæ›´ç¨³å®šï¼Œæ— éœ€å¤æ‚çš„è·¯ç”±è®­ç»ƒè¿‡ç¨‹**

---

#### ğŸ” æ¶ˆèå®éªŒç»“æœ

##### ï¼ˆ1ï¼‰Embedding åˆ†é…ç­–ç•¥å¯¹æ¯”ï¼ˆå›¾7Cï¼‰

| åˆ†é…æ–¹å¼ | Perplexity Gap | è¯´æ˜ |
|--------|----------------|------|
| Uniformï¼ˆå‡åŒ€åˆ†é…ï¼‰ | å·® | æ‰€æœ‰ token åˆ†é…ç›¸åŒæ•°é‡ embeddingsï¼Œæ•ˆæœå·® |
| LZWï¼ˆæ— ä¸Šé™ï¼‰ | æœ€å¥½ | é«˜é¢‘ token è‡ªåŠ¨è·å¾—æ›´å¤š embeddings |
| LZWï¼ˆk=512ï¼‰ | æ¥è¿‘æœ€ä¼˜ | æ§åˆ¶ worst-case å†…å­˜ä½¿ç”¨ï¼Œå®ç”¨æ€§æ›´å¼º |

> âœ… **LZW-based åˆ†é…è‡³å…³é‡è¦**ï¼Œæœ‰æ•ˆæ¨¡æ‹Ÿäº†â€œå¸¸è§ä¸Šä¸‹æ–‡æ¨¡å¼ç¼“å­˜â€çš„è¡Œä¸ºã€‚

##### ï¼ˆ2ï¼‰Weight Tyingï¼ˆå›¾7Rï¼‰

- å°† key å’Œ value embedding çŸ©é˜µå…±äº«ï¼ˆ$ W_K = W_V $ï¼‰
- ç»“æœï¼š**æ€§èƒ½å‡ ä¹ä¸å˜**ï¼Œä½†æ€»å‚æ•°é‡å‡å°‘è¿‘åŠï¼Œä¼ è¾“é‡å¤§å¹…ä¸‹é™
- æ„ä¹‰ï¼šLÂ³ æ¶æ„å…·å¤‡é«˜åº¦å¯å‹ç¼©æ€§å’Œéƒ¨ç½²å‹å¥½æ€§

##### ï¼ˆ3ï¼‰LÂ³ å±‚æ•°ä¸ä½ç½®ï¼ˆå›¾7L & å›¾9ï¼‰

- å¤šå±‚å°è§„æ¨¡ LÂ³ vs å•å±‚å¤§è§„æ¨¡ï¼šæ€§èƒ½ç›¸è¿‘
- ä½†å•å±‚è¿‡å¤§å½±å“ prefetch æ—¶é—´çª—å£
- æœ€ä½³ placementï¼šä¸å®œå¤ªæ—©ï¼ˆä¸Šä¸‹æ–‡ä¸è¶³ï¼‰ä¹Ÿä¸å®œå¤ªæ™šï¼ˆä½œç”¨æœ‰é™ï¼‰ï¼Œä¸­é—´å±‚è¾ƒä¼˜

---

#### âš™ï¸ æ¨ç†æ•ˆç‡å®æµ‹ï¼ˆè¡¨2ï¼‰

| æ¨¡å‹ | Offloading | First LÂ³ Position | Throughput (tokens/s) |
|------|------------|--------------------|------------------------|
| Dense 2.6B | â€“ | â€“ | 334.98 |
| LÂ³ 2.6B | CPU | 1st layer | 302.11 |
| LÂ³ 2.6B | CPU | 4th layer | **332.74** |

> âœ… **ä»…éœ€ 4 ä¸ª decoder å±‚å³å¯å®Œå…¨æ©ç›– offloading å»¶è¿Ÿ**  
> âœ… å³ä½¿å‚æ•°å¸è½½è‡³ CPUï¼Œæ¨ç†é€Ÿåº¦ä»æ¥è¿‘ dense æ¨¡å‹

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°

1. **LÂ³ æˆåŠŸè§£é”äº†ä¸€æ¡æ–°çš„ç¨€ç–æ‰©å±•è·¯å¾„**ï¼š
   - é€šè¿‡å°† embedding è¡¨ä»è¾“å…¥å±‚æ¨å¹¿åˆ°æ·±å±‚ï¼Œå®ç°äº†â€œè®¡ç®—æ·å¾„â€ï¼ˆcomputation shortcuttingï¼‰
   - æ¨¡å‹å¯é€šè¿‡æŸ¥æ‰¾å·²å­¦çŸ¥è¯†é¿å…é‡å¤è®¡ç®—

2. **é™æ€è·¯ç”± + attention èšåˆ æ˜¯å¯è¡Œä¸”é«˜æ•ˆçš„ç»„åˆ**ï¼š
   - è™½ç„¶è·¯ç”±æ˜¯é™æ€çš„ï¼Œä½†é€šè¿‡ hidden state attention å®ç°äº†ä¸Šä¸‹æ–‡æ•æ„Ÿçš„ä¿¡æ¯æå–
   - æ€§èƒ½åª²ç¾ç”šè‡³è¶…è¶ŠåŠ¨æ€ MoE

3. **ç³»ç»Ÿå‹å¥½æ€§æå¼º**ï¼š
   - å‚æ•°è®¿é—®å¯é¢„æµ‹ â†’ æ”¯æŒé«˜æ•ˆ offloading å’Œ prefetch
   - æ— éœ€è¾…åŠ©æŸå¤± â†’ è®­ç»ƒæ›´ç®€å•ç¨³å®š
   - æ”¯æŒ block-diagonal attention kernel åŠ é€Ÿè®­ç»ƒ

4. **ä¿¡æ¯è®ºå¯å‘çš„åˆ†é…ç­–ç•¥æœ‰æ•ˆ**ï¼š
   - LZW ç®—æ³•è‡ªåŠ¨è¯†åˆ«é«˜é¢‘â€œåç¼€æ¨¡å¼â€ï¼ŒæŒ‡å¯¼ embedding åˆ†é…
   - ç¬¦åˆ Zipf å®šå¾‹åˆ†å¸ƒï¼Œè´´è¿‘çœŸå®è¯­è¨€ç»Ÿè®¡ç‰¹æ€§

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§

1. **å¹¶éå®Œå…¨å–ä»£ MoE**ï¼š
   - MoE æ›´é€‚åˆä¸“å®¶ä¸“ä¸šåŒ–å»ºæ¨¡ï¼ˆå¦‚é¢†åŸŸä¸“å®¶ï¼‰
   - LÂ³ æ›´é€‚åˆé€šç”¨çŸ¥è¯†ç¼“å­˜
   - äºŒè€…åº”è§†ä¸ºäº’è¡¥è€Œéäº’æ–¥

2. **embedding åˆ†é…ä¾èµ–ç¦»çº¿ç®—æ³•**ï¼š
   - å½“å‰ä½¿ç”¨ LZW éœ€è¦æ‰«æè¯­æ–™åº“ï¼Œå¯èƒ½ä¸é€‚ç”¨äºå¿«é€Ÿè¿ç§»åœºæ™¯
   - åœ¨çº¿å­¦ä¹ åˆ†é…ç­–ç•¥å°šæœªæ¢ç´¢

3. **æœ€å¤§æ¿€æ´»å‚æ•°å— $ k $ é™åˆ¶**ï¼š
   - è™½ç„¶ cap ä¿è¯ worst-case æ•ˆç‡ï¼Œä½†ä¹Ÿé™åˆ¶äº†æç«¯æƒ…å†µä¸‹çš„è¡¨è¾¾èƒ½åŠ›

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘

1. **ç»“åˆ MoE ä¸ LÂ³**ï¼š
   - åœ¨åŒä¸€æ¨¡å‹ä¸­åŒæ—¶ä½¿ç”¨ä¸¤ç§ç¨€ç–æœºåˆ¶ï¼Œæ¢ç´¢ååŒæ•ˆåº”

2. **è·¨ä»»åŠ¡ swapping LÂ³ layers**ï¼š
   - ç±»ä¼¼ Cartridges æ€æƒ³ï¼Œå°è¯•åœ¨ä¸åŒä»»åŠ¡é—´äº¤æ¢é¢„è®­ç»ƒå¥½çš„ LÂ³ embedding è¡¨

3. **åŠ¨æ€è°ƒæ•´ embedding åˆ†é…**ï¼š
   - è®¾è®¡å¯å¾®åˆ†çš„åˆ†é…æœºåˆ¶ï¼Œåœ¨è®­ç»ƒä¸­è‡ªé€‚åº”ä¼˜åŒ–

4. **æ›´å¤§è§„æ¨¡éƒ¨ç½²éªŒè¯**ï¼š
   - å½“å‰æœ€å¤§æµ‹è¯•ä¸º 2.6B active paramsï¼Œæœªæ¥å¯åœ¨ 10B+ è§„æ¨¡éªŒè¯å…¶æ‰©å±•æ€§

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **LÂ³ æå‡ºäº†ä¸€ç§ç¡¬ä»¶é«˜æ•ˆã€è®­ç»ƒç¨³å®šã€æ€§èƒ½ä¼˜è¶Šçš„æ–°å‹ç¨€ç–æ¶æ„ï¼Œé€šè¿‡â€œé™æ€æŸ¥æ‰¾ + åŠ¨æ€è¯»å–â€çš„èŒƒå¼ï¼Œåœ¨ä¸ç‰ºç‰²ç³»ç»Ÿæ•ˆç‡çš„å‰æä¸‹å®ç°äº†ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„çŸ¥è¯†ç¼“å­˜ï¼Œä¸ºå¤§æ¨¡å‹ç¨€ç–åŒ–æä¾›äº†å…¨æ–°ç»´åº¦ã€‚**

</details>

---

### 5. [Amortized Spectral Kernel Discovery via Prior-Data Fitted Network](https://arxiv.org/abs/2601.21731)

**Authors**: Kaustubh Sharma, Srijan Tiwari, Ojasva Nema, Parikshit Pareek  
**Category**: cs.LG  
**Published**: 2026-01-30  
**Score**: 11.0  
**Type**: new  
**ArXiv ID**: 2601.21731v1  

#### Abstract
Prior-Data Fitted Networks (PFNs) enable efficient amortized inference but lack transparent access to their learned priors and kernels. This opacity hinders their use in downstream tasks, such as surrogate-based optimization, that require explicit covariance models. We introduce an interpretability-...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šAmortized Spectral Kernel Discovery via Prior-Data Fitted Network**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
Prior-Data Fitted Networks (PFNs) è™½ç„¶åœ¨**amortized Bayesian inference**ï¼ˆæ‘Šé”€è´å¶æ–¯æ¨æ–­ï¼‰æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿé€šè¿‡å•æ¬¡å‰å‘ä¼ æ’­å®ç°å¿«é€Ÿé¢„æµ‹ï¼Œä½†å…¶å†…éƒ¨å­¦åˆ°çš„å…ˆéªŒï¼ˆå¦‚ spectral density å’Œ covariance kernelï¼‰æ˜¯éšå¼çš„ã€ä¸å¯è§£é‡Šçš„ã€‚è¿™é™åˆ¶äº†å®ƒä»¬åœ¨éœ€è¦æ˜¾å¼åæ–¹å·®æ¨¡å‹çš„ä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œä¾‹å¦‚ surrogate-based optimization æˆ–ç§‘å­¦å»ºæ¨¡ã€‚

æœ¬æ–‡æ—¨åœ¨è§£å†³ä»¥ä¸‹ä¸¤ä¸ªæ ¸å¿ƒé—®é¢˜ï¼š
- **æœºåˆ¶é€æ˜æ€§ç¼ºå¤±**ï¼šPFNs å¦‚ä½•ç¼–ç é¢‘è°±ä¿¡æ¯ï¼Ÿè¿™äº›ä¿¡æ¯æ˜¯å¦å¯è¢«è§£ç ï¼Ÿ
- **ç¼ºä¹å¯ç§»æ¤çš„æ˜¾å¼è¡¨ç¤º**ï¼šèƒ½å¦ä» PFNs ä¸­æå–å‡ºå¯å¤ç”¨çš„æ˜¾å¼ kernelï¼Ÿ

---

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯**
ä½œè€…æå‡ºäº†ä¸€ä¸ª**åŸºäºæœºåˆ¶åˆ†æçš„è§£ç æ¡†æ¶**ï¼Œç”¨äºä»é¢„è®­ç»ƒçš„ PFNs ä¸­è¿›è¡Œ**æ‘Šé”€é¢‘è°±æ ¸å‘ç°**ï¼ˆamortized spectral kernel discoveryï¼‰ï¼Œå…·ä½“åŒ…æ‹¬ï¼š

#### **æ ¸å¿ƒæ€æƒ³**
- åˆ©ç”¨ **Decoupled-Value Attention (DVA)** æ¶æ„çš„ PFNsï¼Œå‘ç°å…¶æ³¨æ„åŠ›è¾“å‡º $ H $ éšå¼ç¼–ç äº†è¾“å…¥å‡½æ•°çš„**é¢‘è°±ç»“æ„**ï¼ˆspectral manifoldï¼‰ã€‚
- è®¾è®¡äº†ä¸€ä¸ª **Filter Bank Decoder**ï¼Œå°† PFN çš„éšçŠ¶æ€ $ H $ å’Œå€¼ç¼–ç  $ V $ æ˜ å°„ä¸ºæ˜¾å¼çš„**è°±å¯†åº¦ä¼°è®¡** $ S(\omega) $ï¼Œå†é€šè¿‡ **Bochnerâ€™s Theorem** è½¬æ¢ä¸º**å¹³ç¨³åæ–¹å·®æ ¸** $ k(\tau) $ã€‚

#### **ä¸¤å¤§è§£ç å™¨è®¾è®¡**
| ç±»å‹ | è¾“å…¥ | è¾“å‡º | ç†è®ºä¾æ® |
|------|------|------|--------|
| **Multi-Realization Decoder** | å¤šä¸ªç‹¬ç«‹å‡½æ•°æ ·æœ¬ | å®Œæ•´è°±æ··åˆï¼ˆé¢‘ç‡ã€å¸¦å®½ã€æƒé‡ï¼‰ | Theorem 4.3ï¼šå¤šæ ·æœ¬ä¸‹è°±æƒé‡å¯è¯†åˆ« |
| **Single-Realization Decoder** | å•ä¸ªå‡½æ•°æ ·æœ¬ | ä¸»å¯¼é¢‘ç‡ä¸å¸¦å®½ï¼ˆæƒé‡ç»Ÿä¸€ï¼‰+ åˆ†æç¼©æ”¾ | Theorem 4.1ï¼šå•æ ·æœ¬æ— æ³•è¯†åˆ«ç›¸å¯¹æƒé‡ |

#### **å…³é”®åˆ›æ–°ç‚¹**
1. **é¦–æ¬¡æ­ç¤º PFN æ³¨æ„åŠ›æœºåˆ¶ä¸­å­˜åœ¨å¯è§£ç çš„é¢‘è°±æµå½¢**ï¼ˆspectral manifoldï¼‰ï¼Œå¹¶é€šè¿‡ t-SNE å¯è§†åŒ–éªŒè¯ã€‚
2. æå‡º**æ— éœ€æµ‹è¯•æ—¶ä¼˜åŒ–**çš„é›¶æ ·æœ¬ï¼ˆzero-shotï¼‰æ ¸æ„é€ æ–¹æ³•ï¼Œä»…éœ€ä¸€æ¬¡å‰å‘ä¼ æ’­ã€‚
3. å¼•å…¥ **Analytical Scaling** æ¨¡å—ï¼Œåˆ©ç”¨ Proposition 4.2 åœ¨åå¤„ç†é˜¶æ®µæ¢å¤å…¨å±€å°ºåº¦ï¼Œé¿å…ç½‘ç»œâ€œå¹»è§‰â€ç¼©æ”¾å‚æ•°ã€‚
4. ä½¿ç”¨ **Multi-Query Attention Pooling** æå–å¤šä¸ªæ‘˜è¦è§†å›¾ï¼Œæå‡å¯¹å¤æ‚è°±æ··åˆçš„åˆ†è¾¨èƒ½åŠ›ã€‚

---

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**

| æ–¹æ³• | æ˜¯å¦éœ€è¦æµ‹è¯•æ—¶ä¼˜åŒ– | æ˜¯å¦è¾“å‡ºæ˜¾å¼ kernel | æ¨ç†é€Ÿåº¦ | å¯è§£é‡Šæ€§ |
|------|---------------------|------------------------|----------|-----------|
| **DKL / RFF** | âœ… æ˜¯ï¼ˆæ¯ä»»åŠ¡ä¼˜åŒ–ï¼‰ | âœ… æ˜¯ | âŒ æ…¢ï¼ˆç§’çº§ï¼‰ | âš ï¸ æœ‰é™ |
| **PFNï¼ˆåŸå§‹ï¼‰** | âŒ å¦ | âŒ å¦ï¼ˆé»‘ç®±ï¼‰ | âœ… å¿«ï¼ˆæ¯«ç§’çº§ï¼‰ | âŒ å·® |
| **æœ¬æ–‡æ–¹æ³•ï¼ˆDecoder + Bochnerï¼‰** | âŒ å¦ | âœ… æ˜¯ï¼ˆstationary surrogate kernelï¼‰ | âœ… å¿«ï¼ˆ~10â»Â³ ç§’ï¼‰ | âœ… é«˜ |

> âœ… **ä¼˜åŠ¿æ€»ç»“**ï¼š
> - **é€Ÿåº¦å¿«**ï¼šæ¯” DKL/RFF å¿«çº¦ **ä¸‰ä¸ªæ•°é‡çº§**ï¼ˆ~1000Ã—ï¼‰ï¼›
> - **æ€§èƒ½å¼º**ï¼šGP å›å½’ MSE ä¸ PFNã€DKL ç›¸å½“ç”šè‡³æ›´ä¼˜ï¼›
> - **å¯è§£é‡Š**ï¼šæä¾›æ˜¾å¼çš„ $ S(\omega) $ å’Œ $ k(\tau) $ï¼Œæ”¯æŒä¸‹æ¸¸ä»»åŠ¡é›†æˆï¼›
> - **æ‘Šé”€æ¨ç†**ï¼šè®­ç»ƒä¸€æ¬¡ decoderï¼Œå³å¯é›¶æ ·æœ¬æ³›åŒ–åˆ°æ–°æ•°æ®ã€‚

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
å…¨éƒ¨ä¸º**åˆæˆæ•°æ®é›†**ï¼Œç”± GP é‡‡æ ·ç”Ÿæˆï¼Œæ¶µç›–å¤šç§ kernel familyï¼š

- **Spectral Mixture (SM)**ï¼šå« 1â€“4 ä¸ªé«˜æ–¯åˆ†é‡çš„æ··åˆè°±å¯†åº¦ï¼›
- **æ ‡å‡† kernel**ï¼šRBFã€Periodicã€RBF+Periodicã€RBFÃ—Periodicï¼›
- **é«˜ç»´ additive kernel**ï¼šåœ¨ 5D å’Œ 10D ä¸Šæ„å»ºï¼Œæ¯ä¸ªç»´åº¦ä½¿ç”¨ä¸€ç»´ kernel ç»„åˆï¼›
- **Out-of-Distribution (OOD)**ï¼šéé«˜æ–¯ä¸‰è§’æ³¢ä¿¡å·ï¼Œé¢‘ç‡éšæœºé‡‡æ ·ã€‚

---

### **å®éªŒè®¾ç½®ä¸è¯„ä¼°æŒ‡æ ‡**

#### **è¯„ä¼°ä»»åŠ¡**
- **GP Regression**ï¼šä½¿ç”¨è§£ç å¾—åˆ°çš„ kernel è¿›è¡Œé«˜æ–¯è¿‡ç¨‹å›å½’ï¼Œè¯„ä¼°é¢„æµ‹å‡†ç¡®æ€§ã€‚
- **Kernel Recovery Quality**ï¼šæ¯”è¾ƒè§£ç è°±å¯†åº¦ä¸çœŸå®è°±å¯†åº¦ä¹‹é—´çš„ **Wasserstein Distance**ã€‚
- **æ¨ç†æ•ˆç‡**ï¼šè®°å½• kernel æ„é€ æ—¶é—´ï¼ˆä¸åŒ…æ‹¬ GP æ¨ç†æœ¬èº«ï¼‰ã€‚

#### **ä¸»è¦æŒ‡æ ‡**
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **MSE** | æµ‹è¯•ç‚¹ä¸Šçš„å‡æ–¹è¯¯å·®ï¼ˆlog scale æŠ¥å‘Šï¼‰ |
| **Wasserstein Distance** | è¡¡é‡é¢„æµ‹è°±ä¸çœŸå®è°±çš„è·ç¦» |
| **Inference Time** | kernel æ„é€ è€—æ—¶ï¼ˆç§’ï¼‰ |
| **RÂ² Score** | çº¿æ€§æ¢é’ˆè¯„ä¼°é¢‘ç‡/æƒé‡æ¢å¤èƒ½åŠ› |

---

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| åŸºçº¿ | æè¿° |
|------|------|
| **Oracle GP** | ä½¿ç”¨çœŸå®ç”Ÿæˆ kernel çš„ GPï¼ˆç†æƒ³ä¸Šé™ï¼‰ |
| **PFN** | åŸå§‹ PFN æ¨¡å‹ç›´æ¥é¢„æµ‹ï¼ˆæ— æ˜¾å¼ kernelï¼‰ |
| **DKL (Deep Kernel Learning)** | ç¥ç»ç½‘ç»œ + kernel å¾®è°ƒï¼Œéœ€ per-task ä¼˜åŒ– |
| **RFF (Random Fourier Features)** | å›ºå®šè°±é‡‡æ ·ï¼Œä¹Ÿéœ€ä¼˜åŒ–è¡¨ç¤º |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®**

#### **è¡¨ 1ï¼šKernel Cookbook ä¸Šçš„æ€§èƒ½å¯¹æ¯”ï¼ˆå•æ ·æœ¬è®¾ç½®ï¼‰**
| True Kernel | Decoder MSE | DKL MSE | RFF MSE | Decoder Time (s) | DKL Time (s) |
|------------|-------------|---------|---------|------------------|---------------|
| RBF        | 2.52e-5     | 2.52e-2 | 4.33e-2 | 0.004            | ~2.0          |
| Periodic   | 2.78e-2     | 3.80e-2 | 5.51e-2 | 0.005            | ~2.2          |
| SM(Q=4)    | 2.54e-3     | 2.70e-2 | 5.72e-2 | 0.005            | ~2.1          |

> âœ… **Decoder æ€§èƒ½æ¥è¿‘ PFNï¼Œæ˜¾è‘—ä¼˜äº DKL/RFFï¼Œä¸”é€Ÿåº¦å¿« ~1000Ã—**

---

#### **å›¾ 3ï¼šå¤šæ ·æœ¬è®¾ç½®ä¸‹çš„è°±æ¢å¤è´¨é‡**
- **Wasserstein Distance éšæ ·æœ¬æ•° $ M $ å•è°ƒä¸‹é™**ï¼ŒéªŒè¯ Theorem 4.3 çš„ identifiability ä¿è¯ï¼›
- å½“ $ M=16 $ æ—¶ï¼Œè°±å¯†åº¦å‡ ä¹å®Œå…¨æ¢å¤ã€‚

---

#### **è¡¨ 2ï¼šé«˜ç»´ï¼ˆ5D/10Dï¼‰multi-realization è®¾ç½®ä¸‹çš„æ‰©å±•æ€§**
| Kernel (Additive) | Oracle GP MSE | Amortized MSE |
|-------------------|---------------|----------------|
| RBF(5D)           | 1.3e-5        | 2.9e-5         |
| SM(Q=4,10D)       | 2.06e-4       | 4.56e-4        |
| Periodic(10D)     | 2.71e-4       | 2.32e-3        |

> âœ… åœ¨é«˜ç»´ä»ä¿æŒåŒé˜¶è¯¯å·®ï¼Œ**except for Periodic kernels**ï¼ˆå› å…¨å±€å‘¨æœŸç»“æ„éš¾å»ºæ¨¡ï¼‰

---

#### **æ¶ˆèå®éªŒç»“æœï¼ˆAppendix Bï¼‰**

| å®éªŒ | å‘ç° |
|------|------|
| **Mean Pooling vs Attention Pooling** | éšç€è°±å¤æ‚åº¦å¢åŠ ï¼ŒAttention Pooling æå‡æ˜æ˜¾ï¼ˆHard: +3.8%, Very Hard: +5.8%ï¼‰ |
| **H vs V è¡¨ç¤ºæ¢é’ˆ** | $ H $ å¯¹é¢‘ç‡é¢„æµ‹ RÂ² è¾¾ 0.998ï¼Œ$ V $ å‡ ä¹æ— ç”¨ï¼›$ H+V $ æœ€ä½³ |
| **ç›¸ä½ä¸å˜æ€§åˆ†æ** | $ H $ å¯¹ç›¸ä½æ•æ„Ÿï¼Œ$ V $ ä¸æ•æ„Ÿ â†’ å»ºè®®è”åˆä½¿ç”¨ä»¥å¢å¼ºé²æ£’æ€§ |
| **æ»¤æ³¢å™¨ç»„ vs å…¨å‚æ•°å›å½’** | åˆ†ç¦»é¢‘ç‡ä¸æƒé‡é¢„æµ‹æ›´ç¨³å®šï¼Œé¿å…è€¦åˆå¹²æ‰° |

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **PFNs å¹¶éé»‘ç®±è®°å¿†è€…**ï¼šå…¶æ³¨æ„åŠ›è¾“å‡º $ H $ æ˜¾å¼ç¼–ç äº†è¾“å…¥å‡½æ•°çš„**é¢‘è°±ç»“æ„**ï¼Œå½¢æˆå¹³æ»‘çš„ spectral manifoldã€‚
2. **æ‘Šé”€è°±å‘ç°æ˜¯å¯è¡Œçš„**ï¼šé€šè¿‡ç®€å• decoder å³å¯ä»å†»ç»“çš„ PFN ä¸­æå–é«˜è´¨é‡çš„æ˜¾å¼ kernelã€‚
3. **ç»Ÿè®¡å¯è¯†åˆ«æ€§å†³å®šæ¶æ„è®¾è®¡**ï¼š
   - å•æ ·æœ¬åªèƒ½æ¢å¤è°±å½¢çŠ¶ï¼ˆé¢‘ç‡+å¸¦å®½ï¼‰ï¼Œä¸èƒ½æ¢å¤æƒé‡ï¼›
   - å¤šæ ·æœ¬å…è®¸å®Œæ•´æ¢å¤ï¼Œdecoder å¯è¾¾ä¸€è‡´æ€§ã€‚
4. **æ— éœ€ä¼˜åŒ–ä¹Ÿèƒ½é«˜æ€§èƒ½**ï¼šè§£ç  kernel æ”¯æŒçš„ GP å›å½’ç²¾åº¦åª²ç¾ DKL/PFNï¼Œä½†æ¨ç†å¿«åƒå€ã€‚

---

### **æ–¹æ³•çš„å±€é™æ€§**
1. **ä»…é€‚ç”¨äº stationary kernels**ï¼šä¾èµ– Bochnerâ€™s Theoremï¼Œæ— æ³•å»ºæ¨¡éå¹³ç¨³æˆ–å„å‘å¼‚æ€§æ ¸ã€‚
2. **é«˜ç»´æ‰©å±•å—é™**ï¼šPFNs ä¸æ˜¾å¼ç¼–ç ç»´åº¦èº«ä»½ï¼Œéš¾ä»¥è§£ç  per-dimension ç»“æ„ã€‚
3. **å¯¹å‘¨æœŸæ€§å¼ºçš„ kernel æ•ˆæœè¾ƒå·®**ï¼šå¦‚ Periodic kernel åœ¨é«˜ç»´è¡¨ç°ä¸ä½³ï¼ˆè§ Table 2ï¼‰ã€‚
4. **ä¾èµ– PFN é¢„è®­ç»ƒåˆ†å¸ƒ**ï¼šè‹¥æµ‹è¯•æ•°æ®ä¸¥é‡åç¦»è®­ç»ƒåˆ†å¸ƒï¼Œæ€§èƒ½ä¼šä¸‹é™ï¼ˆå°½ç®¡æœ‰ graceful degradationï¼‰ã€‚

---

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **ä¸‹æ¸¸ä»»åŠ¡é›†æˆ**ï¼šå°†è§£ç  kernel åº”ç”¨äº surrogate-based optimizationã€control æˆ–ç‰©ç†å»ºæ¨¡ã€‚
2. **æ··åˆæ¶æ„è®¾è®¡**ï¼šç»“åˆ amortized inference ä¸ adaptive context selectionï¼Œæå‡å¤§æ•°æ®åœºæ™¯ä¸‹çš„ scalabilityã€‚
3. **éå¹³ç¨³æ ¸æ‰©å±•**ï¼šæ¢ç´¢å¦‚ä½•ä» PFNs ä¸­æå–æ—¶å˜æˆ–ç©ºé—´å˜åŒ–çš„ kernelã€‚
4. **è·¨åŸŸè¿ç§»**ï¼šç ”ç©¶ decoder åœ¨ä¸åŒ PFN æ¶æ„æˆ–ä»»åŠ¡åˆ†å¸ƒé—´çš„æ³›åŒ–èƒ½åŠ›ã€‚

---

> ğŸ“Œ **ä¸€å¥è¯æ€»ç»“**ï¼š  
> æœ¬æ–‡æ­ç¤ºäº† PFNs å†…éƒ¨è•´å«å¯è§£ç çš„é¢‘è°±ç»“æ„ï¼Œå¹¶æå‡ºé¦–ä¸ª**æ— éœ€æµ‹è¯•æ—¶ä¼˜åŒ–**çš„æ‘Šé”€è°±æ ¸å‘ç°æ¡†æ¶ï¼Œåœ¨ä¿æŒé«˜é€Ÿæ¨ç†çš„åŒæ—¶ï¼Œå®ç°äº†**é«˜æ€§èƒ½ã€å¯è§£é‡Šã€å¯å¤ç”¨**çš„ kernel æ„é€ ã€‚

</details>

---

### 6. [Investigating Batch Inference in a Sequential Monte Carlo Framework for Neural Networks](https://arxiv.org/abs/2601.21983)

**Authors**: Andrew Millard, Joshua Murphy, Peter Green, Simon Maskell  
**Category**: cs.LG  
**Published**: 2026-01-30  
**Score**: 10.5  
**Type**: new  
**ArXiv ID**: 2601.21983v1  

#### Abstract
Bayesian inference allows us to define a posterior distribution over the weights of a generic neural network (NN). Exact posteriors are usually intractable, in which case approximations can be employed. One such approximation - variational inference - is computationally efficient when using mini-bat...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Investigating Batch Inference in a Sequential Monte Carlo Framework for Neural Networks*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
åœ¨ç¥ç»ç½‘ç»œï¼ˆNeural Networks, NNï¼‰çš„è´å¶æ–¯æ¨æ–­ä¸­ï¼Œ**Sequential Monte Carlo (SMC)** æ˜¯ä¸€ç§éå‚æ•°åŒ–ã€æ¸è¿‘æ— åçš„é‡‡æ ·æ–¹æ³•ï¼Œèƒ½å¤Ÿé¿å…å˜åˆ†æ¨æ–­ï¼ˆVariational Inference, VIï¼‰å¯¹åéªŒåˆ†å¸ƒå½¢å¼çš„å¼ºå‡è®¾ã€‚ç„¶è€Œï¼Œæ ‡å‡†SMCé€šå¸¸ä¾èµ–äºå…¨æ‰¹é‡ï¼ˆfull-batchï¼‰æ•°æ®è¿›è¡Œä¼¼ç„¶å’Œæ¢¯åº¦è®¡ç®—ï¼Œå¯¼è‡´å…¶åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè®¡ç®—å¼€é”€æé«˜ï¼Œéš¾ä»¥å®é™…åº”ç”¨ã€‚

æœ¬æ–‡æ—¨åœ¨è§£å†³è¿™ä¸€é—®é¢˜ï¼š  
> **å¦‚ä½•åœ¨ä¿æŒSMCé‡‡æ ·è´¨é‡çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½å…¶åœ¨ç¥ç»ç½‘ç»œè´å¶æ–¯æ¨æ–­ä¸­çš„è®¡ç®—æˆæœ¬ï¼Ÿ**

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡ºå¹¶ç³»ç»Ÿç ”ç©¶äº†å°† **Mini-batch æ•°æ®é€æ­¥å¼•å…¥ SMC æ¡†æ¶** çš„ç­–ç•¥ï¼Œç§°ä¸º **Data Annealing (DA)** â€”â€”å³â€œæ•°æ®é€€ç«â€æˆ–â€œæ•°æ®å‡æ¸©â€ã€‚å…·ä½“åŒ…æ‹¬ä»¥ä¸‹å‡ ç§æ–¹æ¡ˆï¼š

- **Constant**: å›ºå®šå°æ‰¹é‡è®­ç»ƒï¼ˆbaselineï¼‰
- **Full-batch (FB)**: å§‹ç»ˆä½¿ç”¨å…¨éƒ¨æ•°æ®ï¼ˆä¼ ç»ŸSMCæ–¹å¼ï¼Œé«˜ç²¾åº¦ä½†é«˜æˆæœ¬ï¼‰
- **Constant-to-refine (CTR)**: åˆæœŸç”¨å°æ‰¹é‡å¿«é€Ÿæ¢ç´¢ï¼ŒåæœŸåˆ‡æ¢ä¸ºå…¨æ‰¹é‡ç²¾ç»†ä¼˜åŒ–
- **Linear / Automated**: çº¿æ€§é€’å¢mini-batchæ•°é‡
- **Smooth DA (SDA)**: åŸºäºShannonç†µå˜åŒ–ç‡è‡ªé€‚åº”æ§åˆ¶æ•°æ®å¼•å…¥èŠ‚å¥

å…¶ä¸­ï¼Œ**CTR å’Œ SDA æ˜¯é‡ç‚¹åˆ›æ–°ç‚¹**ï¼Œå°¤å…¶æ˜¯ CTR åœ¨å®è·µä¸­è¡¨ç°ä¼˜å¼‚ã€‚

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | ä¼˜åŠ¿ |
|------|------|
| **ç›¸æ¯”VI** | ä¸ä¾èµ–å‚æ•°åŒ–å˜åˆ†æ—å‡è®¾ï¼Œèƒ½æ›´å¥½åœ°æ•æ‰å¤æ‚åéªŒç»“æ„ |
| **ç›¸æ¯”MCMC/SMC-FB** | æ˜¾è‘—å‡å°‘æ¯è½®è¿­ä»£çš„è®¡ç®—é‡ï¼Œæå‡è®­ç»ƒé€Ÿåº¦ |
| **ç›¸æ¯”çº¯Mini-batch MCMC** | é€šè¿‡æ¸è¿›å¼æ•°æ®å¼•å…¥æœºåˆ¶ï¼Œé¿å…å› å™ªå£°è¿‡å¤§å¯¼è‡´æ”¶æ•›å¤±è´¥ |

æœ€ç»ˆå®ç°äº†ï¼š
> **æœ€é«˜è¾¾6å€åŠ é€Ÿï¼ŒåŒæ—¶ä»…å¸¦æ¥æå°çš„å‡†ç¡®ç‡æŸå¤±**

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š ä½¿ç”¨çš„æ•°æ®é›†
- **MNIST**: æ‰‹å†™æ•°å­—å›¾åƒåˆ†ç±»ä»»åŠ¡ï¼Œå…±70,000å¼ ç°åº¦å›¾ï¼ˆ60kè®­ç»ƒ + 10kæµ‹è¯•ï¼‰ï¼Œè¾“å…¥å°ºå¯¸ 28Ã—28
- **FashionMNIST**: æœé¥°å›¾åƒåˆ†ç±»ä»»åŠ¡ï¼ŒåŒæ ·70,000å¼ ç°åº¦å›¾ï¼Œ10ç±»æœè£…ç±»åˆ«ï¼Œæ›´å…·æŒ‘æˆ˜æ€§

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹æ¶æ„**:
  - MNIST: LeNet-5ï¼ˆD=61,706 å‚æ•°ï¼‰
  - FashionMNIST: æ›´å¤§çš„CNNï¼ˆD=96,658 å‚æ•°ï¼‰
- **æ¨ç†æ¡†æ¶**: SMC sampler ç»“åˆä¸¤ç§Markov Kernel (MK):
  - **Langevin Dynamics (LD)**
  - **Hamiltonian Monte Carlo (HMC)**ï¼ˆS=3 leapfrog stepsï¼‰
- **Mini-batch size**: $ K = C = 500 $
- **æ€»è¿­ä»£æ¬¡æ•°**: 200 iterations
- **è¿è¡Œå¹³å°**: NVIDIA A100 GPUï¼Œä½¿ç”¨ JAX å®ç°
- **éšæœºç§å­**: 5æ¬¡é‡å¤å®éªŒï¼ŒæŠ¥å‘Šå‡å€¼Â±æ ‡å‡†å·®

### ğŸ“Š è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **Test Loss** | æµ‹è¯•é›†ä¸Šçš„è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼ˆNLLï¼‰ |
| **Test Accuracy (%)** | åˆ†ç±»å‡†ç¡®ç‡ |
| **Runtime (s)** | æ€»è®­ç»ƒè€—æ—¶ï¼ˆç§’ï¼‰ |

### ğŸ” åŸºçº¿æ–¹æ³•å¯¹æ¯”
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **Constant** | å›ºå®šMini-batch | æœ€å¿«ä½†ç²¾åº¦è¾ƒä½ |
| **Full-batch (FB)** | å…¨æ•°æ®æ‰¹æ¬¡ | ç²¾åº¦æœ€é«˜ä½†æœ€æ…¢ï¼ˆåŸºå‡†ä¸Šé™ï¼‰ |
| **CTR (Constant-to-refine)** | ä¸¤é˜¶æ®µç­–ç•¥ | å‰90%è¿­ä»£ç”¨MBï¼Œæœ€å10%åˆ‡è‡³FB |
| **Linear / Automated / SDA** | æ¸è¿›å¼DA | é€æ­¥å¢åŠ batch size |
| **SDA (Smooth DA)** | è‡ªé€‚åº”ç†µè°ƒèŠ‚ | åŠ¨æ€è°ƒæ•´æ•°æ®åŠ å…¥é€Ÿç‡ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### ğŸ“ˆ å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

#### âœ… åœ¨ **MNIST** ä¸Šçš„ç»“æœï¼ˆä»¥ HMC ä¸ºä¾‹ï¼‰ï¼š

| æ–¹æ³• | Test Accuracy (%) | Runtime (s) | ç›¸å¯¹FBæé€Ÿ |
|------|-------------------|------------|-----------|
| Full-batch (FB) | **98.00Â±0.15** | 10658.68 | Ã—1.0 |
| Constant | 93.14Â±0.01 | **453.33** | ~Ã—23.5 |
| CTR | **98.00Â±0.15** | **1531.53** | ~Ã—6.96 |
| Linear | 97.90Â±0.13 | 9507.66 | ~Ã—1.12 |
| Automated | 97.94Â±0.05 | 5891.13 | ~Ã—1.81 |
| SDA | 97.70Â±0.17 | 7683.07 | ~Ã—1.39 |

> ğŸ’¡ **CTR åœ¨è¾¾åˆ°ä¸ FB ç›¸å½“ç²¾åº¦çš„åŒæ—¶ï¼Œè®­ç»ƒæ—¶é—´ç¼©çŸ­çº¦ 6.6 å€**

#### âœ… åœ¨ **FashionMNIST** ä¸Šçš„ç»“æœï¼ˆHMCï¼‰ï¼š

| æ–¹æ³• | Test Accuracy (%) | Runtime (s) |
|------|-------------------|------------|
| Full-batch (FB) | **89.60Â±0.20** | 10864.92 |
| CTR | **89.62Â±0.30** | **1531.53** |
| Constant | 83.46Â±0.42 | 392.11 |

> âš ï¸ æ³¨æ„ï¼šCTR å‡†ç¡®ç‡ç”šè‡³ç•¥é«˜äº FBï¼Œå¯èƒ½æºäºæ›´ä¼˜çš„æ¢ç´¢-å¼€å‘å¹³è¡¡

### ğŸ”¬ æ¶ˆèå®éªŒä¸å…³é”®è§‚å¯Ÿ
- **CTR è¡¨ç°æœ€ä¼˜**ï¼šåœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸Šå‡èƒ½åœ¨æ¥è¿‘ FB ç²¾åº¦çš„å‰æä¸‹å®ç° **~6â€“7Ã— åŠ é€Ÿ**
- **Linear > Automated â‰ˆ SDA**ï¼šç®€å•çš„çº¿æ€§å¢é•¿ä¼˜äºå¤æ‚çš„è‡ªé€‚åº”ç­–ç•¥ï¼ˆå¦‚ SDAï¼‰
- **SDA å¹¶æœªå¸¦æ¥é¢å¤–æ”¶ç›Š**ï¼šå°½ç®¡ç†è®ºä¸Šæœ‰ä¿¡æ¯è®ºä¾æ®ï¼Œä½†åœ¨å®è·µä¸­ä¸å¦‚ç®€å•è°ƒåº¦æœ‰æ•ˆ
- **LD æ•´ä½“åŠ£äº HMC**ï¼šå³ä½¿åªæœ‰ S=3 æ­¥leapfrogï¼ŒHMCä»è¡¨ç°å‡ºæ›´å¼ºçš„é‡‡æ ·æ•ˆç‡å’Œæ›´é«˜ç²¾åº¦
- **Constant è™½å¿«ä½†ç²¾åº¦ä¸‹é™æ˜æ˜¾**ï¼šé€‚åˆåˆæ­¥æ¢ç´¢ï¼Œä¸é€‚åˆæœ€ç»ˆæ¨æ–­

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **Mini-batch æ¨ç†å¯æˆåŠŸé›†æˆåˆ° SMC æ¡†æ¶ä¸­**ï¼Œæ— éœ€ç‰ºç‰²å¤ªå¤šç²¾åº¦å³å¯å¤§å¹…é™ä½è®¡ç®—æˆæœ¬ã€‚
2. **ä¸¤é˜¶æ®µç­–ç•¥ CTRï¼ˆå…ˆMBåFBï¼‰æ˜¯æœ€æœ‰æ•ˆçš„æŠ˜ä¸­æ–¹æ¡ˆ**ï¼š
   - åˆ©ç”¨ Mini-batch å¿«é€Ÿå¼•å¯¼ç²’å­å‘é«˜æ¦‚ç‡åŒºåŸŸç§»åŠ¨
   - æœ€ç»ˆé˜¶æ®µä½¿ç”¨ Full-batch è¿›è¡Œç²¾ç»†åŒ–é‡‡æ ·ï¼Œç¡®ä¿åéªŒä¼°è®¡è´¨é‡
3. **æ¸è¿›å¼DAï¼ˆå¦‚Linearï¼‰ä¼˜äºå›ºå®šMBï¼Œä½†ä¸å¦‚CTRé«˜æ•ˆ**
4. **åŸºäºç†µçš„è‡ªé€‚åº”ç­–ç•¥ï¼ˆSDAï¼‰å¹¶æœªå±•ç°å‡ºé¢„æœŸä¼˜åŠ¿**ï¼Œåè€Œå¢åŠ äº†å®ç°å¤æ‚åº¦
5. **HMC æ˜æ˜¾ä¼˜äº LD**ï¼šå³ä½¿æ˜¯çŸ­è½¨è¿¹HMCä¹Ÿèƒ½æä¾›æ›´å¥½çš„é‡‡æ ·è´¨é‡å’Œç¨³å®šæ€§

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
- **SMCæœ¬èº«ä»æ˜¯å†…å­˜å¯†é›†å‹æ–¹æ³•**ï¼šéœ€ç»´æŠ¤å¤šä¸ªç²’å­ï¼ˆæ¨¡å‹å‰¯æœ¬ï¼‰ï¼Œé™åˆ¶äº†è¶…å¤§æ¨¡å‹çš„åº”ç”¨
- **Resampling å¼•å…¥æ–¹å·®**ï¼šå¯èƒ½å¯¼è‡´å¤šæ ·æ€§ä¸¢å¤±ï¼Œå°¤å…¶åœ¨é«˜ç»´ç©ºé—´ä¸­
- **CTR éœ€é¢„è®¾åˆ‡æ¢ç‚¹ï¼ˆå¦‚0.9Kï¼‰**ï¼šç¼ºä¹å®Œå…¨è‡ªé€‚åº”æœºåˆ¶ï¼Œä¾èµ–ç»éªŒè°ƒå‚
- **å½“å‰å®éªŒé™äºä¸­å°è§„æ¨¡CNN**ï¼šæ˜¯å¦é€‚ç”¨äºTransformerç­‰ç°ä»£å¤§æ¨¡å‹å°šå¾…éªŒè¯

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **ç»“åˆ adaptive trajectory length methods**ï¼ˆå¦‚No-U-Turn Samplingæ€æƒ³ï¼‰è¿›ä¸€æ­¥ä¼˜åŒ–HMC proposal
2. **æ¢ç´¢æ›´æ™ºèƒ½çš„è‡ªåŠ¨annealingç­–ç•¥**ï¼Œä¾‹å¦‚åŸºäºeffective sample size (ESS) æˆ–KLæ•£åº¦ç›‘æ§
3. **æ‰©å±•è‡³åˆ†å¸ƒå¼SMCå®ç°**ï¼ˆå¦‚SMCÂ²ï¼‰ï¼Œæ”¯æŒæ›´å¤§è§„æ¨¡æ¨¡å‹å’Œæµå¼æ•°æ®
4. **å¼•å…¥äºŒé˜¶ä¿¡æ¯ï¼ˆå¦‚Hessianï¼‰æ”¹è¿›MKè®¾è®¡**ï¼ˆæ–‡ä¸­å¼•ç”¨[Hess-MC2]å·²æœ‰ç›¸å…³å°è¯•ï¼‰
5. **åº”ç”¨äºä¸ç¡®å®šæ€§é‡åŒ–ã€ä¸»åŠ¨å­¦ä¹ ã€é²æ£’å†³ç­–ç­‰ä¸‹æ¸¸ä»»åŠ¡**

---

## âœ… æ€»ç»“ä¸€å¥è¯
> æœ¬è®ºæ–‡é¦–æ¬¡ç³»ç»Ÿåœ°å°† **Mini-batch Data Annealing** å¼•å…¥ **Sequential Monte Carlo for Bayesian NNs**ï¼Œæå‡ºå¹¶éªŒè¯äº†å¤šç§è°ƒåº¦ç­–ç•¥ï¼Œå‘ç° **Constant-to-refine (CTR)** æ–¹æ¡ˆå¯åœ¨å‡ ä¹ä¸æŸå¤±ç²¾åº¦çš„æƒ…å†µä¸‹å®ç° **é«˜è¾¾6å€ä»¥ä¸Šçš„è®­ç»ƒåŠ é€Ÿ**ï¼Œä¸ºSMCåœ¨ç°å®åœºæ™¯ä¸­çš„è½åœ°æä¾›äº†å¯è¡Œè·¯å¾„ã€‚

</details>

---

### 7. [OmegaUse: Building a General-Purpose GUI Agent for Autonomous Task Execution](https://arxiv.org/abs/2601.20380)

**Authors**: Le Zhang, Yixiong Xiao, Xinjiang Lu, Jingjia Cao, Yusai Zhao, Jingbo Zhou, Lang An, Zikan Feng, Wanxiang Sha, Yu Shi, Congxi Xiao, Jian Xiong, Yankai Zhang, Hua Wu, Haifeng Wang  
**Category**: cs.AI  
**Published**: 2026-01-30  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2601.20380v1  

#### Abstract
Graphical User Interface (GUI) agents show great potential for enabling foundation models to complete real-world tasks, revolutionizing human-computer interaction and improving human productivity. In this report, we present OmegaUse, a general-purpose GUI agent model for autonomous task execution on...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠOmegaUse: Building a General-Purpose GUI Agent for Autonomous Task Executionã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
å½“å‰çš„ **GUI Agent** åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´ä¸‰å¤§ç“¶é¢ˆï¼š
- **è®­ç»ƒæ•°æ®è´¨é‡å·®**ï¼šç°æœ‰å¯¼èˆªæ•°æ®é›†å­˜åœ¨è½¨è¿¹é”™è¯¯ã€å†—ä½™åŠ¨ä½œã€æ ‡æ³¨åç§»ç­‰é—®é¢˜ï¼Œä¸¥é‡å½±å“æ¨¡å‹å­¦ä¹ æ•ˆæœã€‚
- **ç¼ºä¹é«˜è´¨é‡è¯„ä¼°åŸºå‡†**ï¼šå°¤å…¶åœ¨ä¸­æ–‡ç§»åŠ¨ç”Ÿæ€å’Œæ¡Œé¢ç³»ç»Ÿç­‰ç‰¹å®šåœºæ™¯ä¸‹ï¼Œç¼ºå°‘ä¸“é—¨çš„ç¦»çº¿è¯„ä¼°åŸºå‡†ï¼ˆoffline benchmarkï¼‰ã€‚
- **æ¨¡å‹æ¶æ„ä¸è®­ç»ƒç­–ç•¥ä¸åŒ¹é…**ï¼šä¼ ç»Ÿç«¯åˆ°ç«¯æˆ–æ¨¡å—åŒ–è®¾è®¡éš¾ä»¥å…¼é¡¾æ¨ç†èƒ½åŠ›ä¸è®¡ç®—æ•ˆç‡ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
OmegaUse æå‡ºäº†ä¸€å¥—å®Œæ•´çš„ GUI Agent æ„å»ºæ¡†æ¶ï¼Œæ¶µç›–æ•°æ®ã€è®­ç»ƒã€æ¶æ„ä¸è¯„ä¼°å››ä¸ªå±‚é¢ï¼š

#### ï¼ˆ1ï¼‰**é«˜ç²¾åº¦ MoE æ¶æ„**
- é‡‡ç”¨ **Mixture-of-Experts (MoE)** ä½œä¸º backboneï¼Œç›¸æ¯” dense æ¨¡å‹ï¼ˆå¦‚ 7B/72Bï¼‰ï¼Œåœ¨ä¿æŒå¤§å‚æ•°é‡æ¨ç†èƒ½åŠ›çš„åŒæ—¶ï¼Œä»…æ¿€æ´»éƒ¨åˆ†ä¸“å®¶ï¼Œæ˜¾è‘—é™ä½è®¡ç®—å¼€é”€ã€‚
- æ”¯æŒè·¨å¹³å°ç»Ÿä¸€æ“ä½œç©ºé—´ï¼ˆUnified Action Spaceï¼‰ï¼Œè¦†ç›– mobileã€desktop å’Œ web åœºæ™¯ã€‚

#### ï¼ˆ2ï¼‰**é«˜è´¨é‡æ•°æ®æ„å»ºç®¡é“**
- **Grounding æ•°æ®**ï¼šå¯¹å…­å¤§å¼€æºæ•°æ®é›†ï¼ˆAguvisã€SeeClickã€OS-Atlas ç­‰ï¼‰è¿›è¡Œä¸¥æ ¼æ¸…æ´—ä¸äººå·¥æ ¡æ­£ï¼Œæ„å»º 111K é«˜è´¨é‡å•æ­¥ grounding æ•°æ®é›†ã€‚
- **Navigation æ•°æ®**ï¼šæå‡º **åˆ†å±‚åˆæˆæ¡†æ¶**ï¼Œèåˆä¸‰ç§æ¥æºï¼š
  - å¼€æºæ•°æ®å®¡è®¡
  - è‡ªåŠ¨åŒ–åˆæˆï¼ˆbottom-up æ¢ç´¢ + top-down åˆ†ç±»å¼•å¯¼ç”Ÿæˆï¼‰
  - è·¨ç»ˆç«¯ä¸“å®¶æ¼”ç¤ºï¼ˆhuman-in-the-loop æ ‡æ³¨ï¼‰

#### ï¼ˆ3ï¼‰**è§£è€¦å¼ä¸¤é˜¶æ®µè®­ç»ƒèŒƒå¼**
- **ç¬¬ä¸€é˜¶æ®µï¼šSupervised Fine-Tuning (SFT)**  
  å­¦ä¹ åŸºç¡€äº¤äº’è¯­æ³•ä¸ä»»åŠ¡é€»è¾‘ã€‚
- **ç¬¬äºŒé˜¶æ®µï¼šGroup Relative Policy Optimization (GRPO)**  
  å¼•å…¥ç»†ç²’åº¦å¥–åŠ±æœºåˆ¶æå‡ç©ºé—´å®šä½ä¸åºåˆ—è§„åˆ’èƒ½åŠ›ï¼š
  - Groundingï¼š`Format Reward` + `Inside-of-Bounding-Box Reward`
  - Navigationï¼š`Format Reward` + `Action-wise Reward`ï¼ˆå«åæ ‡ç²¾åº¦ã€å†…å®¹ä¿çœŸåº¦ç­‰ï¼‰

#### ï¼ˆ4ï¼‰**å‘å¸ƒæ–°å‹è¯„ä¼°åŸºå‡† OS-Nav**
- åŒ…å«ä¸¤ä¸ªå­é›†ï¼š
  - **ChiM-Nav**ï¼šèšç„¦ä¸­æ–‡ Android ç§»åŠ¨ç¯å¢ƒï¼Œå…± 142 æ¡è½¨è¿¹ï¼Œ991 æ­¥ã€‚
  - **Ubu-Nav**ï¼šé¢å‘ Ubuntu æ¡Œé¢æ—¥å¸¸æ“ä½œï¼Œå…± 101 æ¡è½¨è¿¹ï¼Œ641 æ­¥ã€‚
- æ‰€æœ‰è½¨è¿¹å‡ç» MLLM è¾…åŠ© + äººå·¥éªŒè¯ï¼Œç¡®ä¿é€»è¾‘ä¸€è‡´æ€§ä¸ç¯å¢ƒå¯è¡Œæ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | OmegaUse ä¼˜åŠ¿ |
|------|---------------|
| **æ•°æ®è´¨é‡** | é€šè¿‡äººå·¥ç²¾ä¿® + å¤šæºåˆæˆï¼Œè§£å†³è‡ªåŠ¨æ ‡æ³¨åç§»ä¸è½¨è¿¹å™ªå£°é—®é¢˜ |
| **è®­ç»ƒæ•ˆç‡** | MoE è®¾è®¡å®ç°é«˜æ€§èƒ½ä¸ä½å»¶è¿Ÿçš„å¹³è¡¡ |
| **æ³›åŒ–èƒ½åŠ›** | æ”¯æŒè·¨å¹³å°ï¼ˆmobile/desktop/webï¼‰ã€å¤šè¯­è¨€ï¼ˆä¸­æ–‡ç•Œé¢ï¼‰ |
| **è¯„ä¼°ä½“ç³»** | è¡¥è¶³ä¸­æ–‡ç§»åŠ¨ä¸ Linux æ¡Œé¢åœºæ™¯çš„ benchmark ç¼ºå¤± |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†

#### ï¼ˆ1ï¼‰**è®­ç»ƒæ•°æ®**
- **Grounding**ï¼šæ•´åˆ 6 ä¸ªå…¬å¼€æ•°æ®é›†ï¼ˆAguvis, UI RefExp, Widget Captioning, SeeClick, Uground, OS-Atlasï¼‰ï¼ŒåŸå§‹æ ·æœ¬çº¦ 1.66Mï¼Œç»æ¸…æ´—åä¿ç•™ 111K é«˜è´¨é‡æ ·æœ¬ã€‚
- **Navigation**ï¼š
  - å¼€æºè½¨è¿¹ï¼ˆAGUVIS stage-2, AITW, Mind2Webï¼‰
  - åˆæˆè½¨è¿¹ï¼ˆåŸºäº DFS æ¢ç´¢ + Taxonomy å¼•å¯¼ç”Ÿæˆï¼‰
  - ä¸“å®¶æ¼”ç¤ºï¼ˆâ‰¥5 æ­¥å¤æ‚ä»»åŠ¡ï¼ŒåŒäººå®¡æ ¸ï¼‰

#### ï¼ˆ2ï¼‰**æµ‹è¯•æ•°æ®**
- **é€šç”¨åŸºå‡†**ï¼š
  - **ScreenSpot-V2**ï¼šè·¨å¹³å° UI å…ƒç´ å®šä½åŸºå‡†ï¼ˆmobile/web/desktopï¼‰
  - **ScreenSpot-Pro**ï¼šé«˜åˆ†è¾¨ç‡ä¸“ä¸šè½¯ä»¶ç•Œé¢å®šä½æŒ‘æˆ˜
  - **AndroidControl**ï¼šç¦»çº¿è½¨è¿¹è§„åˆ’è¯„ä¼°
  - **AndroidWorld**ï¼šåœ¨çº¿åŠ¨æ€äº¤äº’è¯„ä¼°
- **è‡ªç ”åŸºå‡†**ï¼š
  - **ChiM-Nav**ï¼šä¸­æ–‡ Android åº”ç”¨å¯¼èˆª
  - **Ubu-Nav**ï¼šUbuntu æ¡Œé¢å¸¸è§„æ“ä½œ

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

| ç±»åˆ« | è®¾ç½®è¯´æ˜ |
|------|--------|
| **æ¨¡å‹é…ç½®** | 30B-A3B VL MoE æ¨¡å‹ï¼›SFT å­¦ä¹ ç‡ 1e-5ï¼ŒRL é˜¶æ®µ 5e-5ï¼›batch size åˆ†åˆ«ä¸º 32ï¼ˆSFTï¼‰å’Œ 64ï¼ˆRLï¼‰ |
| **è¯„ä¼°æ–¹å¼** | ç¦»çº¿è¯„ä¼°ä¸ºä¸»ï¼ˆoracle settingï¼‰ï¼Œå³æä¾›çœŸå®æˆªå›¾ä¸çŠ¶æ€æµ |
| **ä¸»è¦æŒ‡æ ‡** | 
| - **Type Accuracy (Type Acc.)**ï¼šåŠ¨ä½œç±»å‹é¢„æµ‹æ­£ç¡®ç‡ |
| - **Step Success Rate (SR)**ï¼šæ¯ä¸€æ­¥æ‰§è¡ŒæˆåŠŸçš„æ¯”ä¾‹ |
| - **Average Success**ï¼šä»»åŠ¡çº§å¹³å‡æˆåŠŸç‡ï¼ˆUbu-Navï¼‰ |
| - **Coordination Precision**ï¼šç‚¹å‡»/æ‹–æ‹½åæ ‡å‡†ç¡®æ€§ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å‚ä¸æ¯”è¾ƒçš„ä¸»æµæ¨¡å‹åŒ…æ‹¬ï¼š
- **Closed-source**ï¼šGPT-4o, Claude Computer Use, Seed1.5-VL
- **Open-source GUI Agents**ï¼š
  - SeeClick, OS-Atlas, UI-TARS ç³»åˆ—
  - UI-Venus, GTA1, AgentCPM-GUI
  - OpenCUA, Qwen-VL ç³»åˆ—

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®

| åŸºå‡† | OmegaUse æ€§èƒ½ | æœ€ä½³åŸºçº¿ | æå‡æƒ…å†µ |
|------|----------------|-----------|----------|
| **ScreenSpot-V2 (Avg)** | **96.3%** | UI-Venus-Ground-72B (95.3%) | **+1.0 pp** |
| **AndroidControl (Step SR)** | **79.1%** | UI-Venus-Navi-72B (77.2%) | **+1.9 pp** |
| **ChiM-Nav (Step SR)** | **74.24%** | UI-Venus-72B (67.51%) | **+6.73 pp** |
| **Ubu-Nav (Average)** | **55.9%** | Holo2-30B-A3B (50.0%) | **+5.9 pp** |
| **ScreenSpot-Pro (Avg)** | 55.47% | UI-Venus-Ground-72B (61.9%) | ç•¥é€Šäºè¶…å¤§è§„æ¨¡æ¨¡å‹ï¼Œä½†åœ¨ OS-Icon ä¸Šè¾¾ **43.82%**ï¼ˆSOTAï¼‰ |

> æ³¨ï¼špp = percentage point

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- åœ¨ **ScreenSpot-V2** ä¸Šåˆ·æ–° SOTAï¼Œå°¤å…¶åœ¨æ–‡æœ¬å…ƒç´ å®šä½ä¸Šæ¥è¿‘å®Œç¾ï¼ˆmobile text: 99.3%ï¼Œdesktop text: 99.0%ï¼‰ã€‚
- åœ¨ **AndroidControl** ä¸­åŒæ—¶å–å¾—æœ€é«˜ Type Acc.ï¼ˆ87.6%ï¼‰å’Œ Step SRï¼ˆ79.1%ï¼‰ï¼Œè¡¨æ˜å…¶å…·å¤‡æ›´å¼ºçš„é«˜å±‚è¯­ä¹‰ç†è§£ä¸åŠ¨ä½œåˆ†è§£èƒ½åŠ›ã€‚
- åœ¨ **ChiM-Nav** ä¸Šå¤§å¹…é¢†å…ˆï¼Œè¯æ˜å…¶åœ¨ä¸­æ–‡ UI å’Œæœ¬åœŸåŒ– Appï¼ˆå¦‚å¾®ä¿¡ã€æ”¯ä»˜å®é£æ ¼ç•Œé¢ï¼‰ä¸­å…·æœ‰å“è¶Šæ³›åŒ–èƒ½åŠ›ã€‚
- åœ¨ **Ubu-Nav** ä¸­åè°ƒåŠ¨ä½œï¼ˆClick/Scrollï¼‰ä¸éåæ ‡åŠ¨ä½œï¼ˆType/Hotkeyï¼‰å‡è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶éåæ ‡ä»»åŠ¡è¾¾ **48.6%**ï¼Œè¿œè¶… UI-Venus-Navi-72Bï¼ˆ40.0%ï¼‰ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆæ–‡ä¸­æœªæ˜ç¡®åˆ—å‡ºæ¶ˆèè¡¨ï¼Œä½†ä»åˆ†æå¯æ¨æ–­ï¼‰
å°½ç®¡æ²¡æœ‰ç‹¬ç«‹è¡¨æ ¼ï¼Œæ–‡ä¸­é€šè¿‡ä»¥ä¸‹æ–¹å¼ä½“ç°å„ç»„ä»¶è´¡çŒ®ï¼š
- è‹¥ä»…ä½¿ç”¨åŸå§‹å¼€æºæ•°æ®è€Œä¸æ¸…æ´—ï¼Œæ€§èƒ½ä¸‹é™æ˜æ˜¾ï¼ˆæåŠâ€œè¿‘ 40% å™ªå£°â€ï¼‰ã€‚
- GRPO é˜¶æ®µå¼•å…¥ `Inside-of-Bounding-Box Reward` æ˜¾è‘—æå‡ç©ºé—´å®šä½é²æ£’æ€§ã€‚
- MoE æ¶æ„åœ¨å‚æ•°é‡å°äº 72B dense æ¨¡å‹çš„æƒ…å†µä¸‹è¾¾åˆ°ç”šè‡³è¶…è¶Šå…¶æ€§èƒ½ï¼ŒéªŒè¯äº†æ•ˆç‡ä¼˜åŠ¿ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. âœ… **é«˜è´¨é‡æ•°æ®æ˜¯ GUI Agent æˆåŠŸçš„å…³é”®**ï¼šä¸¥æ ¼çš„è¿‡æ»¤ã€äººå·¥ä¿®æ­£ä¸å¤šæºåˆæˆèƒ½æ˜¾è‘—æå‡æ¨¡å‹è¡¨ç°ã€‚
2. âœ… **è§£è€¦è®­ç»ƒä¼˜äºç«¯åˆ°ç«¯è”åˆè®­ç»ƒ**ï¼šå…ˆ SFT å† GRPO çš„ç­–ç•¥æœ‰åŠ©äºåˆ†ç¦»æ„ŸçŸ¥ä¸å†³ç­–ï¼Œé¿å…è®­ç»ƒå¹²æ‰°ã€‚
3. âœ… **MoE æ˜¯é«˜æ•ˆ GUI Agent çš„ç†æƒ³é€‰æ‹©**ï¼šåœ¨ä¿è¯å¼ºå¤§æ¨ç†èƒ½åŠ›çš„åŒæ—¶ï¼Œæœ‰æ•ˆæ§åˆ¶æ¨ç†æˆæœ¬ã€‚
4. âœ… **ç°æœ‰ benchmark ä¸è¶³ä»¥åæ˜ çœŸå®ä¸–ç•Œèƒ½åŠ›**ï¼šChiM-Nav å’Œ Ubu-Nav æ­ç¤ºäº†æ¨¡å‹åœ¨ä¸­æ–‡ç”Ÿæ€ä¸æ¡Œé¢ç³»ç»Ÿä¸­çš„çœŸå®çŸ­æ¿ã€‚
5. âœ… **è‡ªåŠ¨åŒ–åˆæˆ + äººç±»åé¦ˆé—­ç¯å¯è¡Œ**ï¼šbottom-up æ¢ç´¢ä¸ top-down åˆ†ç±»ç»“åˆï¼Œå¯è§„æ¨¡åŒ–ç”Ÿäº§é«˜è´¨é‡è½¨è¿¹ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- **ä¾èµ–é«˜è´¨é‡æ¨¡æ‹Ÿå™¨**ï¼šè‡ªåŠ¨åŒ–æ¢ç´¢éœ€ç¨³å®šå¯æ§çš„ sandbox ç¯å¢ƒï¼Œåœ¨çœŸå®è®¾å¤‡ä¸Šéƒ¨ç½²ä»å…·æŒ‘æˆ˜ã€‚
- **æœªæ”¯æŒè¯­éŸ³è¾“å…¥/è¾“å‡º**ï¼šå½“å‰ä»…åŸºäºè§†è§‰-è¯­è¨€æ¨¡æ€ï¼Œå°šæœªé›†æˆå¤šæ¨¡æ€äº¤äº’ï¼ˆå¦‚è¯­éŸ³åŠ©æ‰‹ï¼‰ã€‚
- **å®‰å…¨æ€§æœºåˆ¶ç¼ºå¤±**ï¼šæœªè®¨è®ºæƒé™æ§åˆ¶ã€å±é™©æ“ä½œæ‹¦æˆªç­‰å®‰å…¨çº¦æŸã€‚
- **é•¿ç¨‹ä»»åŠ¡è®°å¿†æœ‰é™**ï¼šè™½ç„¶æœ‰å†å²è½¨è¿¹è¾“å…¥ï¼Œä½†æœªå¼•å…¥æ˜¾å¼ memory æ¨¡å—å¤„ç†è¶…é•¿ä»»åŠ¡ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- ğŸ”„ **æ‰©å±•è‡³æ›´å¤æ‚çš„ç°å®å·¥ä½œæµ**ï¼šå¦‚è·¨ App ååŒã€å¤šçª—å£è°ƒåº¦ã€æ–‡ä»¶ç³»ç»Ÿæ·±å±‚æ“ä½œã€‚
- ğŸ” **å¢å¼ºå®‰å…¨ä¸è‡ªæˆ‘çº æ­£æœºåˆ¶**ï¼šåŠ å…¥ operation verificationã€risk detection ä¸ rollback èƒ½åŠ›ã€‚
- ğŸŒ **æ”¯æŒæ›´å¤šæ“ä½œç³»ç»Ÿä¸è¯­è¨€**ï¼šæ‰©å±•è‡³ iOSã€Windows åŠå…¶ä»–æœ¬åœ°åŒ– UIã€‚
- ğŸ¤– **å‘ online interactive setting è¿ç§»**ï¼šä» oracle setting èµ°å‘çœŸå®ç¯å¢ƒé—­ç¯æ§åˆ¶ã€‚
- ğŸ§  **æ¢ç´¢ agent introspection ä¸åæ€èƒ½åŠ›**ï¼šå¼•å…¥ self-reflectionã€plan debugging ç­‰è®¤çŸ¥æœºåˆ¶ã€‚

--- 

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> OmegaUse é€šè¿‡â€œ**é«˜è´¨é‡æ•°æ® + è§£è€¦è®­ç»ƒ + MoE æ¶æ„ + æ–°å‹ benchmark**â€å››ä½ä¸€ä½“çš„è®¾è®¡ï¼Œåœ¨è·¨å¹³å° GUI Agent é¢†åŸŸå®ç°äº†æ€§èƒ½çªç ´ï¼Œå¹¶ä¸ºè¯¥é¢†åŸŸæä¾›äº†å¯å¤ç°ã€å¯æ‰©å±•çš„æŠ€æœ¯èŒƒå¼ã€‚

</details>

---

### 8. [A Federated and Parameter-Efficient Framework for Large Language Model Training in Medicine](https://arxiv.org/abs/2601.22124)

**Authors**: Anran Li, Yuanyuan Chen, Wenjun Long, Yu Yin, Yan Hu, Hyunjae Kim, Weipeng Zhou, Yujia Zhou, Hongyi Peng, Yang Ren, Xuguang Ai, Zhenyue Qin, Ming Hu, Xiaoxiao Li, Han Yu, Yih-Chung Tham, Lucila Ohno-Machado, Hua Xu, Qingyu Chen  
**Category**: cs.CL  
**Published**: 2026-01-30  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2601.22124v1  

#### Abstract
Large language models (LLMs) have demonstrated strong performance on medical benchmarks, including question answering and diagnosis. To enable their use in clinical settings, LLMs are typically further adapted through continued pretraining or post-training using clinical data. However, most medical ...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ ¸å¿ƒç»“è®ºä¸å®éªŒç»“æœæ€»ç»“

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**åŒ»å­¦é¢†åŸŸå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è®­ç»ƒä¸­çš„ä¸¤å¤§æ ¸å¿ƒæŒ‘æˆ˜**ï¼š
1. **éšç§ä¸åˆè§„é™åˆ¶**ï¼šåŒ»ç–—æ•°æ®å—ä¸¥æ ¼ç›‘ç®¡ï¼Œè·¨æœºæ„å…±äº«æ‚£è€…æ•°æ®ä¸å¯è¡Œï¼Œå¯¼è‡´å¤§å¤šæ•°LLMsä»…åœ¨å•ä¸€æœºæ„æ•°æ®ä¸Šè®­ç»ƒï¼Œæ³›åŒ–èƒ½åŠ›å·®ã€‚
2. **è”é‚¦å­¦ä¹ ï¼ˆFederated Learning, FLï¼‰åº”ç”¨äºLLMsçš„ä¸é€‚ç”¨æ€§**ï¼š
   - **é€šä¿¡å¼€é”€å·¨å¤§**ï¼šä¼ ç»ŸFLéœ€ä¼ è¾“æ•´ä¸ªæ¨¡å‹å‚æ•°ï¼Œåœ¨å¤šåäº¿å‚æ•°çš„LLMsä¸­ä¸ç°å®ã€‚
   - **æ•°æ®å¼‚è´¨æ€§å¼º**ï¼šä¸åŒåŒ»ç–—æœºæ„çš„æ•°æ®åœ¨æ‚£è€…ç¾¤ä½“ã€ç–¾ç—…åˆ†å¸ƒã€æ ‡æ³¨ä¹ æƒ¯ç­‰æ–¹é¢å·®å¼‚æ˜¾è‘—ï¼Œæ ‡å‡†FLèšåˆç­–ç•¥æ•ˆæœä¸ä½³ã€‚

### æå‡ºçš„æ–°æ–¹æ³•
ä½œè€…æå‡ºäº†ä¸¤ä¸ªåˆ›æ–°æ¡†æ¶ï¼š
- **Fed-MedLoRA**ï¼šé¦–ä¸ªé€‚ç”¨äºåŒ»å­¦é¢†åŸŸçš„**æ¨¡å‹æ— å…³ä¸”å‚æ•°é«˜æ•ˆ**çš„è”é‚¦å­¦ä¹ æ¡†æ¶ã€‚
  - æ ¸å¿ƒæ€æƒ³ï¼šé‡‡ç”¨**Low-Rank Adaptation (LoRA)** æŠ€æœ¯ï¼Œå®¢æˆ·ç«¯åªè®­ç»ƒå¹¶ä¸Šä¼ ä½ç§©é€‚é…å™¨ï¼ˆadapterï¼‰å‚æ•°ï¼Œè€Œéå®Œæ•´æ¨¡å‹æƒé‡ã€‚
  - ä¼˜åŠ¿ï¼šæå¤§é™ä½é€šä¿¡æˆæœ¬å’Œæœ¬åœ°è®¡ç®—éœ€æ±‚ã€‚
- **Fed-MedLoRA+**ï¼šåœ¨Fed-MedLoRAåŸºç¡€ä¸Šçš„å¢å¼ºç‰ˆã€‚
  - æ ¸å¿ƒåˆ›æ–°ï¼šå¼•å…¥**è‡ªé€‚åº”ã€æ•°æ®æ„ŸçŸ¥çš„èšåˆç­–ç•¥ï¼ˆinfluence-aware aggregationï¼‰**ã€‚
  - å®ç°æ–¹å¼ï¼šæœåŠ¡å™¨åˆ©ç”¨ä¸€ä¸ªå°å‹éªŒè¯é›†è¯„ä¼°æ¯ä¸ªå®¢æˆ·ç«¯æ›´æ–°çš„å½±å“ï¼Œä¸ºé«˜è´¨é‡æ›´æ–°åˆ†é…æ›´é«˜æƒé‡ï¼Œä»è€Œæå‡å…¨å±€æ¨¡å‹åœ¨å¼‚æ„æ•°æ®ä¸‹çš„æ”¶æ•›æ€§å’Œé²æ£’æ€§ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹é¢ | ä¼˜åŠ¿ |
| :--- | :--- |
| **é€šä¿¡æ•ˆç‡** | é€šä¿¡æˆæœ¬ç›¸æ¯”å…¨æ¨¡å‹æ›´æ–°**é™ä½98.5%**ï¼Œä»æ•°ç™¾GBé™è‡³çº¦1-2GBã€‚ |
| **è®¡ç®—å¯è¡Œæ€§** | å¯åœ¨å•å¼ æ¶ˆè´¹çº§GPUï¼ˆå¦‚RTX 4090ï¼‰ä¸Šè®­ç»ƒ8Bå‚æ•°æ¨¡å‹ï¼Œæ¨ç†å¯åœ¨ç¬”è®°æœ¬ç”µè„‘ï¼ˆå¦‚Apple M3 Proï¼‰ä¸Šè¿è¡Œã€‚ |
| **æ¨¡å‹æ€§èƒ½** | æ˜¾è‘—ä¼˜äºé›¶æ ·æœ¬LLMsã€å•æœºæ„å¾®è°ƒLLMsåŠé¢†åŸŸç‰¹å®šBERTæ¨¡å‹ã€‚ |
| **æ³›åŒ–èƒ½åŠ›** | åœ¨å¤–éƒ¨ç‹¬ç«‹é˜Ÿåˆ—ä¸Šè¡¨ç°ç¨³å¥ï¼Œæ”¯æŒæ–°æœºæ„çš„å¿«é€Ÿå†·å¯åŠ¨ã€‚ |
| **å®é™…éƒ¨ç½²å‹å¥½** | æ”¯æŒå„å‚ä¸æ–¹æä¾›ä¸å®Œæ•´çš„ä»»åŠ¡æ ‡æ³¨ï¼ˆå¦‚æœ‰çš„æœºæ„åªæœ‰NERæ ‡ç­¾ï¼‰ï¼Œæ¡†æ¶ä»èƒ½æœ‰æ•ˆå·¥ä½œã€‚ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
ç ”ç©¶ä½¿ç”¨äº†äº”ä¸ªçœŸå®ä¸–ç•Œçš„ä¸´åºŠæ–‡æœ¬æ•°æ®é›†ï¼Œæ¶µç›–ä¸åŒæ¥æºå’Œç‰¹ç‚¹ï¼š
- **MIMIC-III**ï¼šé‡ç—‡ç›‘æŠ¤ç—…æˆ¿è®°å½•ã€‚
- **MTSamples**ï¼šè½¬å½•çš„é—¨è¯ŠæŠ¥å‘Šç¤ºä¾‹ã€‚
- **UTP (UT Physicians)**ï¼šä¼‘æ–¯é¡¿å¤§å­¦åŒ»ç”Ÿç¬”è®°ã€‚
- **I2B2**ï¼šç”±Informatics for Integrating Biology & the Bedsideæä¾›çš„å¤šæœºæ„ä¸´åºŠç¬”è®°ã€‚
- **YNHH (Yale New Haven Health)**ï¼šæœ¬ç ”ç©¶æ‰‹åŠ¨æ ‡æ³¨çš„4ä»½æ¥è‡ªè€¶é²çº½é»‘æ–‡å¥åº·ç³»ç»Ÿçš„æ‚£è€…è®°å½•ï¼Œç”¨äºæ¨¡æ‹Ÿæ–°æœºæ„åœºæ™¯ã€‚

### å®éªŒè®¾ç½®
è¯„ä¼°åˆ†ä¸ºä¸‰ä¸ªå…³é”®åœºæ™¯ï¼š
1. **åŸŸå†…è®­ç»ƒä¸æµ‹è¯•ï¼ˆIn-domainï¼‰**ï¼šåœ¨MIMIC-IIIã€MTSamplesã€UTPä¸Šè¿›è¡Œè”é‚¦è®­ç»ƒï¼Œå¹¶åœ¨å¯¹åº”æµ‹è¯•é›†ä¸Šè¯„ä¼°ã€‚
2. **å¤–éƒ¨éªŒè¯ï¼ˆExternal Validationï¼‰**ï¼šå°†è”é‚¦è®­ç»ƒçš„æ¨¡å‹ç›´æ¥åº”ç”¨äºæœªè§è¿‡çš„ç‹¬ç«‹æ•°æ®é›†ï¼ˆå¦‚I2B2ï¼‰ï¼Œè¯„ä¼°å…¶æ³›åŒ–èƒ½åŠ›ã€‚
3. **ä½èµ„æºæ–°ç«™ç‚¹é€‚åº”ï¼ˆLow-resource New-site Adaptationï¼‰**ï¼šä½¿ç”¨åœ¨MIMIC-IIIç­‰æ•°æ®ä¸Šè®­ç»ƒå¥½çš„Fed-MedLoRA+æ¨¡å‹ï¼Œç›´æ¥åœ¨æå°‘é‡æ ‡æ³¨çš„YNHHæ•°æ®ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œæ¨¡æ‹Ÿæ–°åŒ»é™¢çš„å†·å¯åŠ¨ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **ä¸»è¦ä»»åŠ¡**ï¼šä¸´åºŠä¿¡æ¯æå–ï¼ˆInformation Extraction, IEï¼‰ï¼ŒåŒ…æ‹¬ï¼š
  - **å‘½åå®ä½“è¯†åˆ«ï¼ˆNamed Entity Recognition, NERï¼‰**
  - **å…³ç³»æŠ½å–ï¼ˆRelation Extraction, REï¼‰**
- **è¯„ä»·æŒ‡æ ‡**ï¼šç²¾ç¡®ç‡ï¼ˆPrecisionï¼‰ã€å¬å›ç‡ï¼ˆRecallï¼‰ã€F1åˆ†æ•°ï¼ˆF1-scoreï¼‰ã€‚
- **ä¸¤ç§åŒ¹é…æ¨¡å¼**ï¼š
  - **ä¸¥æ ¼åŒ¹é…ï¼ˆStrict matchï¼‰**ï¼šè¦æ±‚å®ä½“è¾¹ç•Œå’Œç±»å‹å®Œå…¨ä¸€è‡´ã€‚
  - **å®½æ¾åŒ¹é…ï¼ˆLenient matchï¼‰**ï¼šå…è®¸å®ä½“è¾¹ç•Œéƒ¨åˆ†é‡å ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **LLMåŸºçº¿**ï¼š
  - **é›¶æ ·æœ¬ï¼ˆZero-shotï¼‰**ï¼šGPT-4o, LLaMA3-8B, DeepSeek-R1-Distill-8Bã€‚
  - **å•æœºæ„å¾®è°ƒï¼ˆSingle-site fine-tunedï¼‰**ï¼šåŒæ¬¾LLMåœ¨å•ä¸ªæ•°æ®é›†ä¸Šå¾®è°ƒã€‚
- **BERTåŸºçº¿**ï¼š`Bio_ClinicalBERT`ï¼ˆé¢†åŸŸç‰¹å®šçš„å¼ºåŸºçº¿ï¼‰ã€‚
- **è”é‚¦å­¦ä¹ åŸºçº¿**ï¼š`FedSA-LoRA`ï¼ˆé€šç”¨é¢†åŸŸçš„LoRAè”é‚¦ç®—æ³•ï¼‰ã€‚
- **ç†æƒ³ä¸Šé™**ï¼š**é›†ä¸­å¼è®­ç»ƒï¼ˆCentralized trainingï¼‰**ï¼šå°†æ‰€æœ‰æœºæ„æ•°æ®åˆå¹¶è®­ç»ƒï¼Œä½œä¸ºæ€§èƒ½ä¸Šé™å‚è€ƒã€‚

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
- **æ€§èƒ½æå‡**ï¼š
  - ç›¸æ¯”é›¶æ ·æœ¬LLMï¼ŒFed-MedLoRA+çš„F1åˆ†æ•°**æœ€é«˜æå‡è¾¾65%**ã€‚
  - ç›¸æ¯”å•æœºæ„å¾®è°ƒLLMï¼Œ**å¹³å‡æå‡çº¦25% F1**ã€‚
  - åœ¨å…³ç³»æŠ½å–ï¼ˆREï¼‰ä»»åŠ¡ä¸Šï¼Œç›¸æ¯”`Bio_ClinicalBERT`ï¼Œ**æ€§èƒ½æå‡è¶…è¿‡40%**ã€‚
- **æ³›åŒ–èƒ½åŠ›**ï¼š
  - åœ¨å¤–éƒ¨ç‹¬ç«‹é˜Ÿåˆ—ä¸Šï¼Œç›¸æ¯”åŸºçº¿æœ‰**10%-70%çš„F1å¢ç›Š**ã€‚
- **æ–°ç«™ç‚¹é€‚åº”**ï¼š
  - åœ¨ä»…æœ‰å°‘é‡æ ‡æ³¨çš„YNHHæ•°æ®ä¸Šï¼ŒFed-MedLoRA+å–å¾—äº†**73%çš„ä¸¥æ ¼F1**å’Œ**85%çš„å®½æ¾F1**ï¼Œè¡¨æ˜å…¶å¼ºå¤§çš„å†·å¯åŠ¨èƒ½åŠ›ã€‚
- **æ•ˆç‡æŒ‡æ ‡**ï¼š
  - **é€šä¿¡æˆæœ¬**ï¼šç›¸æ¯”å…¨æ¨¡å‹æ›´æ–°ï¼Œ**é™ä½98.5%**ã€‚
  - **ç¡¬ä»¶éœ€æ±‚**ï¼š
    - 8Bæ¨¡å‹è®­ç»ƒï¼šå•å¼ RTX 4090ï¼ˆ16GBï¼‰å³å¯å®Œæˆã€‚
    - 1Bæ¨¡å‹è®­ç»ƒï¼šå¯åœ¨RTX 3060 Tiç­‰ä¸­ç«¯GPUä¸Šè¿è¡Œã€‚
    - æ¨ç†ï¼šå¯åœ¨æ ‡å‡†ç¬”è®°æœ¬ç”µè„‘ä¸Šæ‰§è¡Œã€‚
  - **å¯æ‰©å±•æ€§**ï¼šæ¡†æ¶å¯æ‰©å±•è‡³10ä¸ªå‚ä¸ç«™ç‚¹ï¼Œæ€§èƒ½ä»…æ¯”é›†ä¸­å¼è®­ç»ƒä¸‹é™çº¦2%ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **å…¨é¢è¶…è¶Š**ï¼šFed-MedLoRAå’ŒFed-MedLoRA+åœ¨æ‰€æœ‰è¯„ä¼°åœºæ™¯ä¸‹å‡**æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿æ–¹æ³•**ï¼ˆpå€¼<0.0001ï¼‰ã€‚
- **Fed-MedLoRA+ > Fed-MedLoRA**ï¼šè¯æ˜äº†â€œæ•°æ®æ„ŸçŸ¥èšåˆâ€ç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼ŒFed-MedLoRA+é€šå¸¸è¡¨ç°æ›´ä¼˜ã€‚
- **æ¥è¿‘é›†ä¸­å¼ä¸Šé™**ï¼šFed-MedLoRA+çš„æ€§èƒ½éå¸¸æ¥è¿‘ç†æƒ³çš„é›†ä¸­å¼è®­ç»ƒç»“æœï¼Œå°¤å…¶åœ¨ä¸¤æœºæ„è®¾ç½®ä¸‹å·®è·æå°ã€‚
- **ä¼˜äºé€šç”¨FLç®—æ³•**ï¼šç›¸æ¯”`FedSA-LoRA`ï¼ŒFed-MedLoRA+åœ¨NERå’ŒREä¸Šçš„F1åˆ†æ•°åˆ†åˆ«é«˜å‡ºæ•°å€ï¼ˆä¾‹å¦‚ï¼ŒRE F1ä»0.181æå‡è‡³0.894ï¼‰ã€‚

### æ¶ˆèå®éªŒç»“æœ
- **æ¨¡å‹è§„æ¨¡æƒè¡¡**ï¼šä½¿ç”¨1Bå‚æ•°çš„LLaMA3-1Bä½œä¸ºéª¨å¹²ç½‘ç»œæ—¶ï¼š
  - **ç²¾åº¦ä»£ä»·**ï¼šNERæ€§èƒ½ä¸‹é™çº¦3%ï¼ŒREæ€§èƒ½ä¸‹é™æœ€å¤š7%ã€‚
  - **æ•ˆç‡æ”¶ç›Š**ï¼šé€šä¿¡ã€å†…å­˜å’Œè®­ç»ƒæ—¶é—´å¤§å¹…é™ä½ï¼Œä½¿å…¶èƒ½åœ¨èµ„æºæåº¦å—é™çš„ç¯å¢ƒä¸­éƒ¨ç½²ã€‚
- **ä¸å‡åŒ€ä»»åŠ¡æ ‡æ³¨çš„é²æ£’æ€§**ï¼š
  - å½“éƒ¨åˆ†æœºæ„ç¼ºå°‘REæ ‡æ³¨æ—¶ï¼ŒFed-MedLoRA+çš„NERæ€§èƒ½ä»…ä¸‹é™1.2%-1.7%ï¼ŒREæ€§èƒ½ä¸‹é™2.8%-5.8%ï¼Œä¾ç„¶ä¿æŒå¯¹å•æœºæ„å¾®è°ƒçš„æ˜¾è‘—ä¼˜åŠ¿ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **è”é‚¦LLMsåœ¨åŒ»å­¦ä¸Šæ˜¯å¯è¡Œä¸”é«˜æ•ˆçš„**ï¼šé€šè¿‡å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆå¦‚LoRAï¼‰ï¼Œå¯ä»¥å…‹æœä¼ ç»ŸFLåœ¨LLMsä¸Šåº”ç”¨çš„å·¨å¤§é€šä¿¡å’Œè®¡ç®—éšœç¢ã€‚
2. **æ•°æ®å¼‚è´¨æ€§å¯é€šè¿‡æ™ºèƒ½èšåˆè§£å†³**ï¼šFed-MedLoRA+æå‡ºçš„åŸºäºå½±å“çš„èšåˆç­–ç•¥ï¼Œèƒ½æœ‰æ•ˆåº”å¯¹åŒ»ç–—æ•°æ®çš„å¼ºå¼‚è´¨æ€§ï¼Œæå‡æ¨¡å‹çš„ç¨³å®šæ€§å’Œæ€§èƒ½ã€‚
3. **è”é‚¦è®­ç»ƒæ˜¾è‘—æå‡LLMsçš„åŒ»å­¦èƒ½åŠ›**ï¼šè¯¥æ¡†æ¶èƒ½å°†LLMsåœ¨ä¸´åºŠIEç­‰å¤æ‚ä»»åŠ¡ä¸Šçš„æ€§èƒ½æå‡åˆ°è¿œè¶…å½“å‰æœ€ä½³æ°´å¹³ï¼Œç”šè‡³æ¥è¿‘æ•°æ®é›†ä¸­å¼çš„ç†æƒ³ä¸Šé™ã€‚
4. **å¼ºå¤§çš„æ³›åŒ–ä¸å†·å¯åŠ¨èƒ½åŠ›**ï¼šè”é‚¦è®­ç»ƒçš„æ¨¡å‹å…·æœ‰å‡ºè‰²çš„è·¨æœºæ„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶èƒ½å¸®åŠ©æ–°åŠ å…¥çš„æœºæ„å¿«é€Ÿå»ºç«‹é«˜æ€§èƒ½çš„æœ¬åœ°æ¨¡å‹ã€‚
5. **å®ç”¨æ€§å¼º**ï¼šæ¡†æ¶å¯¹ç¡¬ä»¶è¦æ±‚ä½ï¼Œæ”¯æŒä¸å®Œæ•´æ ‡æ³¨ï¼Œå…·å¤‡è‰¯å¥½çš„å¯æ‰©å±•æ€§ï¼Œä¸ºåœ¨çœŸå®ä¸–ç•ŒåŒ»ç–—ç³»ç»Ÿä¸­éƒ¨ç½²æä¾›äº†å¯èƒ½ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **éšç§ä¿æŠ¤æœºåˆ¶ä¸è¶³**ï¼šè™½ç„¶ä¸å…±äº«åŸå§‹æ•°æ®ï¼Œä½†ä¼ è¾“çš„LoRAå‚æ•°ä»å¯èƒ½å­˜åœ¨æ³„éœ²æ•æ„Ÿä¿¡æ¯çš„é£é™©ï¼Œæœªé›†æˆå·®åˆ†éšç§ï¼ˆDPï¼‰æˆ–å®‰å…¨èšåˆï¼ˆSecure Aggregationï¼‰ç­‰æ›´å¼ºçš„éšç§ä¿æŠ¤æŠ€æœ¯ã€‚
2. **ä»»åŠ¡èŒƒå›´æœ‰é™**ï¼šæœ¬ç ”ç©¶ä»…ä»¥ä¸´åºŠä¿¡æ¯æå–ï¼ˆIEï¼‰ä¸ºä¾‹ï¼Œå°šæœªæ¢ç´¢è¯¥æ¡†æ¶åœ¨å…¶ä»–åŒ»å­¦ä»»åŠ¡ï¼ˆå¦‚è¯Šæ–­ã€é—®ç­”ã€ç”Ÿæˆï¼‰ä¸Šçš„æ™®é€‚æ€§ã€‚
3. **ç¼ºä¹çœŸå®ç¯å¢ƒéƒ¨ç½²éªŒè¯**ï¼šå®éªŒåŸºäºå…¬å¼€æ•°æ®é›†ï¼Œå°šæœªåœ¨çœŸå®çš„å¤šæœºæ„åä½œç½‘ç»œä¸­è¿›è¡Œéƒ¨ç½²ï¼Œé¢ä¸´ç½‘ç»œå»¶è¿Ÿã€åè°ƒç®¡ç†ã€ç¡¬ä»¶å¼‚æ„ç­‰å®é™…å·¥ç¨‹æŒ‘æˆ˜ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **åŠ å¼ºéšç§ä¿éšœ**ï¼šç³»ç»Ÿæ€§åœ°æ•´åˆå·®åˆ†éšç§ã€å®‰å…¨èšåˆç­‰æŠ€æœ¯ï¼Œè¯„ä¼°å…¶å¯¹æ¨¡å‹æ€§èƒ½å’Œæ•ˆç‡çš„å½±å“ã€‚
2. **æ¢ç´¢æœ€ä¼˜ä»»åŠ¡ç»„åˆ**ï¼šç ”ç©¶å“ªäº›ç±»å‹çš„åŒ»å­¦ä»»åŠ¡å’Œæ•°æ®æœ€é€‚åˆé€šè¿‡è”é‚¦å­¦ä¹ è¿›è¡Œè”åˆè®­ç»ƒã€‚
3. **æ¨è¿›çœŸå®ä¸–ç•Œéƒ¨ç½²**ï¼šå¼€å±•å‰ç»æ€§ç ”ç©¶ï¼Œåœ¨çœŸå®çš„åŒ»ç–—è”ç›Ÿä¸­éƒ¨ç½²è¯¥æ¡†æ¶ï¼Œè¿›è¡Œé•¿æœŸè¯„ä¼°ï¼Œè§£å†³å®é™…è½åœ°ä¸­çš„æŠ€æœ¯å’Œæ²»ç†éš¾é¢˜ã€‚

</details>

---

### 9. [ZipMoE: Efficient On-Device MoE Serving via Lossless Compression and Cache-Affinity Scheduling](https://arxiv.org/abs/2601.21198)

**Authors**: Yuchen Yang, Yaru Zhao, Pu Yang, Shaowei Wang, Zhi-Hua Zhou  
**Category**: cs.DC  
**Published**: 2026-01-30  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2601.21198v1  

#### Abstract
While Mixture-of-Experts (MoE) architectures substantially bolster the expressive power of large-language models, their prohibitive memory footprint severely impedes the practical deployment on resource-constrained edge devices, especially when model behavior must be preserved without relying on los...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šZipMoE: Efficient On-Device MoE Serving via Lossless Compression and Cache-Affinity Scheduling

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜
ç°ä»£ **Mixture-of-Experts (MoE)** å¤§è¯­è¨€æ¨¡å‹è™½ç„¶æå‡äº†è¡¨è¾¾èƒ½åŠ›ï¼Œä½†å…¶å·¨å¤§çš„å†…å­˜å ç”¨ä¸¥é‡é˜»ç¢äº†åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ï¼ˆå¦‚æ‰‹æœºã€Jetsonã€æ ‘è“æ´¾ï¼‰ä¸Šçš„éƒ¨ç½²ã€‚ä¼ ç»Ÿæ–¹æ³•ä¾èµ– **lossy quantizationï¼ˆæœ‰æŸé‡åŒ–ï¼‰** æˆ– **offloadingï¼ˆå‚æ•°å¸è½½ï¼‰** æ¥ç¼“è§£å†…å­˜å‹åŠ›ï¼Œä½†å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š

- **æœ‰æŸé‡åŒ–** ä¼šæ”¹å˜æ¨¡å‹è¡Œä¸ºï¼Œå¯èƒ½å¼•å…¥å®‰å…¨æ¼æ´ï¼ˆå¦‚æ¶æ„ä»£ç ç”Ÿæˆã€è¿‡åº¦æ‹’ç»ç­‰ï¼‰ï¼Œä¸”ç°æœ‰è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚ perplexityï¼‰æ— æ³•æ•æ‰è¿™äº›é£é™©ã€‚
- **ç°æœ‰å¸è½½ç³»ç»Ÿ** å‡è®¾ CPU å†…å­˜æ˜¯ç‹¬ç«‹å­˜å‚¨ï¼Œè€Œå®é™…è¾¹ç¼˜å¹³å°å¤šé‡‡ç”¨ **ç»Ÿä¸€å†…å­˜æ¶æ„ï¼ˆUMAï¼‰**ï¼ŒCPU å’Œ GPU å…±äº«å†…å­˜æ± ï¼Œå¯¼è‡´ I/O è·¯å¾„æ•ˆç‡ä½ä¸‹ã€‚
- åœ¨ä½æ‰¹å¤„ç†å¤§å°ï¼ˆbatch size = 1ï¼‰çš„äº¤äº’å¼åœºæ™¯ä¸­ï¼Œæµæ°´çº¿ä¼˜åŒ–å¤±æ•ˆï¼ŒI/O æˆä¸ºç“¶é¢ˆã€‚

å› æ­¤ï¼Œæ ¸å¿ƒé—®é¢˜æ˜¯ï¼š**å¦‚ä½•åœ¨ä¸æ”¹å˜ MoE æ¨¡å‹è¯­ä¹‰çš„å‰æä¸‹ï¼Œé«˜æ•ˆåœ°åœ¨ç§»åŠ¨å’Œè¾¹ç¼˜å¹³å°ä¸Šéƒ¨ç½² MoE æ¨¡å‹ï¼Ÿ**

---

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯
è®ºæ–‡æå‡º **ZIPMoE** â€”â€” ä¸€ç§é«˜æ•ˆçš„ã€è¯­ä¹‰æ— æŸï¼ˆsemantically losslessï¼‰çš„ on-device MoE æ¨ç†ç³»ç»Ÿï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äº **ç¼“å­˜ä¸è°ƒåº¦çš„ååŒè®¾è®¡ï¼ˆcaching-scheduling co-designï¼‰**ï¼Œå…·ä½“åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰åŸºäºç»Ÿè®¡å†—ä½™çš„æ— æŸå‹ç¼©ï¼ˆLossless Compressionï¼‰
- è§‚å¯Ÿåˆ° BF16 å‚æ•°ä¸­çš„ **exponent bitsï¼ˆæŒ‡æ•°ä½ï¼‰å…·æœ‰é«˜åº¦ç»Ÿè®¡å†—ä½™**ï¼ˆä½ç†µï¼‰ï¼Œè€Œ sign/mantissa bitsï¼ˆç¬¦å·/å°¾æ•°ä½ï¼‰æ¥è¿‘éšæœºåˆ†å¸ƒã€‚
- å°†æ¯ä¸ª tensor åˆ†è§£ä¸º **E-chunksï¼ˆå‹ç¼©çš„ exponent bitsï¼‰** å’Œ **SM-chunksï¼ˆæœªå‹ç¼©çš„ sign-mantissa bitsï¼‰**ï¼Œä»…å¯¹ E-chunks è¿›è¡Œæ— æŸå‹ç¼©ï¼ˆä½¿ç”¨ ZSTD/LZ4HCï¼‰ã€‚
- åˆ©ç”¨ **zero-copy + memory-coalesced GPU kernel** å®ç°é«˜æ•ˆæ¢å¤ï¼Œè¿è¡Œæ—¶å¼€é”€æä½ã€‚

#### ï¼ˆ2ï¼‰åˆ†å±‚ç¼“å­˜ç®¡ç†ï¼ˆHierarchical, Differentiated Cachingï¼‰
- è®¾è®¡å››ç§ç¼“å­˜æ± ï¼š
  - `F`ï¼šå®Œæ•´å¼ é‡ï¼ˆFull tensorï¼‰
  - `C`ï¼šå‹ç¼©å¼ é‡ï¼ˆCompressed tensorï¼‰
  - `S`ï¼šä»… SM-chunks
  - `E`ï¼šä»… E-chunks
- æ”¯æŒç»†ç²’åº¦å†…å­˜æ§åˆ¶ï¼Œä¾‹å¦‚ç¼“å­˜ SM-chunks å¯å®ç° **2Ã— ç¼“å­˜è¦†ç›–**ï¼ˆå› å ä¸€åŠä½“ç§¯ï¼‰ã€‚

#### ï¼ˆ3ï¼‰äº²å’Œæ€§æ„ŸçŸ¥è°ƒåº¦ï¼ˆCache-Affinity Schedulingï¼‰
- å¼•å…¥ **DAG è¡¨ç¤º** å»ºæ¨¡æ¯ä¸ªä¸“å®¶é‡å»ºä»»åŠ¡çš„æ“ä½œä¾èµ–ï¼ˆI/Oã€è§£å‹ã€æ¢å¤ï¼‰ã€‚
- å°†ä»»åŠ¡åˆ†ä¸ºä¸¤ç±»ï¼š
  - **Type-I**ï¼šéœ€åŠ è½½ SM-chunksï¼ˆI/O é˜»å¡ï¼‰
  - **Type-II**ï¼šSM-chunks å·²ç¼“å­˜ï¼ˆå¯å¹¶è¡Œè§£å‹ï¼‰
- è°ƒåº¦å™¨é€šè¿‡ **å—æ„é€ ï¼ˆblock constructionï¼‰** ç­–ç•¥ï¼Œå°† Type-II ä»»åŠ¡æ’å…¥ Type-I ä»»åŠ¡ä¹‹é—´ï¼Œ**é‡å  I/O ä¸ CPU è§£å‹**ï¼Œæœ€å¤§åŒ–å¹¶è¡Œæ€§ã€‚
- **ç†è®ºä¿è¯**ï¼šè°ƒåº¦ç®—æ³•çš„ makespan ä¸è¶…è¿‡æœ€ä¼˜å€¼çš„ `(3 - 1/L)` å€ï¼ˆL ä¸ºè§£å‹çº¿ç¨‹æ•°ï¼‰ã€‚

#### ï¼ˆ4ï¼‰åŸºäºåŠ¨æ€è§„åˆ’çš„ç¼“å­˜è§„åˆ’ï¼ˆCache Pool Planningï¼‰
- ä½¿ç”¨ **rank-based workload modeling** æŠ½è±¡ä¸“å®¶æ¿€æ´»é¢‘ç‡ï¼Œé¿å…ä¾èµ–å…·ä½“ IDã€‚
- é€šè¿‡ **åŠ¨æ€è§„åˆ’ï¼ˆDPï¼‰** è®¡ç®—ä¸åŒç¼“å­˜é…ç½®ä¸‹çš„å‘½ä¸­æ¦‚ç‡åˆ†å¸ƒã€‚
- æšä¸¾æ‰€æœ‰å¯è¡Œé…ç½®ï¼Œé€‰æ‹© **æœŸæœ› makespan æœ€å°** çš„æ–¹æ¡ˆè¿›è¡Œç¼“å­˜åˆ†åŒºã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ZIPMoE | ç°æœ‰æ–¹æ³• |
|------|--------|---------|
| **æ¨¡å‹ä¿çœŸåº¦** | âœ… æ— æŸå‹ç¼©ï¼Œä¿ç•™åŸå§‹è¡Œä¸º | âŒ æœ‰æŸé‡åŒ–ï¼Œå¯èƒ½å¼•å…¥å®‰å…¨é£é™© |
| **ç¡¬ä»¶é€‚é…æ€§** | âœ… é’ˆå¯¹ UMA æ¶æ„ä¼˜åŒ– | âŒ å‡è®¾åˆ†ç¦»å†…å­˜ï¼Œä¸é€‚ç”¨äºè¾¹ç¼˜è®¾å¤‡ |
| **I/O æ•ˆç‡** | âœ… å¹¶è¡Œ CPU è§£å‹éšè— I/O å»¶è¿Ÿ | âŒ è¢«åŠ¨ç­‰å¾… I/O å®Œæˆ |
| **è°ƒåº¦æ™ºèƒ½æ€§** | âœ… äº²å’Œæ€§è°ƒåº¦ + DAG ä¼˜åŒ– | âŒ ç®€å•æµæ°´çº¿æˆ–é™æ€ç­–ç•¥ |
| **ç¼“å­˜çµæ´»æ€§** | âœ… å¤šçº§ç¼“å­˜ + åŠ¨æ€è§„åˆ’è§„åˆ’ | âŒ å›ºå®šç­–ç•¥ï¼ˆå¦‚ LRU/FIFOï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
- **ShareGPT æ•°æ®é›†**ï¼šä»å…¶ä¸­éšæœºé‡‡æ · prompts ç”¨äºæ¨ç†æµ‹è¯•ï¼Œç¡®ä¿è¾“å…¥ä¸€è‡´æ€§ã€‚

### å®éªŒè®¾ç½®
- **æ¨¡å‹**ï¼š
  - **Decoder-only**: DeepSeekV2-Lite, Qwen1.5-MoE
  - **Encoder-decoder**: SwitchTransformers-Large-128
- **ç¡¬ä»¶å¹³å°**ï¼š
  - **Jetson AGX Orin 64GBï¼ˆHardware 1ï¼‰**
  - **Jetson AGX Orin 32GBï¼ˆHardware 2ï¼‰**
  - å‡é…å¤‡ Samsung 970 EVO SSDï¼ˆè¯»é€Ÿ 3.5GB/sï¼‰
- **è½¯ä»¶ç¯å¢ƒ**ï¼šJetPack 6.2.1 + Ubuntu 22.04
- **å‹ç¼©åç«¯**ï¼šZSTD å’Œ LZ4HC

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **TPOT** | Time Per Output Tokenï¼Œæ¯è¾“å‡º token æ—¶é—´ |
| **TTFT** | Time To First Tokenï¼Œé¦– token å»¶è¿Ÿ |
| **Throughput** | ååé‡ï¼ˆtoken/sï¼‰ |
| **End-to-End Latency** | ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆéšè¾“å‡ºé•¿åº¦å˜åŒ–ï¼‰ |
| **Makespan** | ç¨€ç–å±‚å®Œæˆæ—¶é—´ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | æè¿° |
|------|------|
| **Accelerate** | HuggingFace æä¾›çš„æ¨¡å‹å¸è½½åº“ |
| **DeepSpeed** | æ”¯æŒ ZeRO-3 çš„ SSD å¸è½½ |
| **MoE-Infinity** | é¢å‘ MoE çš„é«˜æ•ˆå¸è½½ç³»ç»Ÿï¼Œæ”¯æŒä¸“å®¶é¢„å– |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®
| æŒ‡æ ‡ | ZIPMoE æå‡å¹…åº¦ |
|------|----------------|
| **æ¨ç†å»¶è¿Ÿé™ä½** | **æœ€é«˜è¾¾ 72.77%** |
| **ååé‡æå‡** | **æœ€é«˜è¾¾ 6.76Ã—** |
| **TPOT å‡å°‘** | 62.65% ~ 97.97%ï¼ˆdecoder-onlyï¼‰ |
| **TTFT å‡å°‘** | 53.25% ~ 87.90%ï¼ˆdecoder-onlyï¼‰ |
| **ç«¯åˆ°ç«¯åŠ é€Ÿ** | **3.03Ã— ~ 42.49Ã—**ï¼ˆdecoder-onlyï¼‰ |

---

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
#### ï¼ˆ1ï¼‰å®æ—¶å“åº”æ€§ï¼ˆå›¾7ï¼‰
- åœ¨ä½å†…å­˜é¢„ç®—ä¸‹ï¼ŒZIPMoE æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼š
  - **TPOT é™ä½æœ€å¤šè¾¾ 97.97%**
  - **TTFT é™ä½æœ€å¤šè¾¾ 87.90%**
- å¯¹äº encoder-decoder æ¨¡å‹ä¼˜åŠ¿ç¨å¼±ä½†ä»æ˜¾è‘—ï¼ˆTPOT â†“81.24%ï¼ŒTTFT â†“83.45%ï¼‰ï¼Œå› å…¶æœ¬èº« I/O å¯†é›†åº¦è¾ƒä½ã€‚

#### ï¼ˆ2ï¼‰ç³»ç»Ÿååé‡ï¼ˆå›¾8ï¼‰
- æ‰¹å¤„ç†æ¨ç†ä¸­ï¼ŒZIPMoE æŒç»­é¢†å…ˆï¼š
  - **decoder-only æ¨¡å‹ï¼š1.79Ã— ~ 42.49Ã— ååæå‡**
  - **encoder-decoder æ¨¡å‹ï¼š1.31Ã— ~ 5.82Ã— æå‡**
- éšç€ batch size å¢å¤§ï¼ŒZIPMoE çš„å¹¶è¡Œè°ƒåº¦ä¼˜åŠ¿è¿›ä¸€æ­¥æ”¾å¤§ã€‚

#### ï¼ˆ3ï¼‰ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆå›¾9ï¼‰
- åœ¨ä¸åŒè¾“å‡ºé•¿åº¦ä¸‹ï¼ŒZIPMoE å§‹ç»ˆè¡¨ç°æœ€ä½³ï¼š
  - **æœ€å¤§åŠ é€Ÿè¾¾ 42.49Ã—**ï¼ˆDeepSeekV2-Lite on Hardware 1ï¼‰
  - æ€§èƒ½ç¨³å®šï¼ŒPareto æ›²çº¿å…¨é¢é¢†å…ˆã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆå›¾10ï¼‰
- ç§»é™¤ **cache planning** æ¨¡å—åï¼Œæ€§èƒ½ä¸‹é™æ˜æ˜¾ã€‚
- æ›¿æ¢ç¼“å­˜æ·˜æ±°ç­–ç•¥ä¸º FIFOã€Markingã€LRU åï¼Œæ€§èƒ½å‡ä¸å¦‚ ZIPMoE è‡ªå¸¦çš„è§„åˆ’ç®—æ³•ã€‚
- ç»“è®ºï¼š**åˆ†å±‚ç¼“å­˜ + åŠ¨æ€è§„åˆ’è§„åˆ’** æ˜¯æ€§èƒ½å¢ç›Šçš„å…³é”®ç»„æˆéƒ¨åˆ†ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **MoE å‚æ•°ä¸­å­˜åœ¨æ˜¾è‘—çš„ä¿¡æ¯å†—ä½™**ï¼Œç‰¹åˆ«æ˜¯ BF16 çš„ exponent bitsï¼Œå¯é€šè¿‡æ— æŸå‹ç¼©å¤§å¹…å‡å°‘ I/Oã€‚
2. **è¾¹ç¼˜è®¾å¤‡çš„ UMA æ¶æ„åº”è¢«ä¸»åŠ¨åˆ©ç”¨**ï¼Œè€Œéè¢«åŠ¨é€‚åº”ï¼›ZIPMoE é€šè¿‡ zero-copy å’Œ CPU å¹¶è¡Œè§£å‹å……åˆ†é‡Šæ”¾å¤šæ ¸æ½œåŠ›ã€‚
3. **I/O ä¸å†æ˜¯ä¸å¯é€¾è¶Šçš„ç“¶é¢ˆ**ï¼Œé€šè¿‡å°†â€œç­‰å¾…åŠ è½½â€è½¬å˜ä¸ºâ€œè®¡ç®—ç”Ÿæˆâ€ï¼ŒZIPMoE å°† MoE æ¨ç†ä» I/O-bound è½¬ä¸º compute-centricã€‚
4. **ç¼“å­˜ç­–ç•¥å¿…é¡»æ„ŸçŸ¥å‹ç¼©çŠ¶æ€**ï¼Œä¼ ç»Ÿçš„å…¨å¼ é‡ç¼“å­˜æ— æ³•å……åˆ†åˆ©ç”¨å†…å­˜ï¼Œè€Œåˆ†å±‚ç¼“å­˜å¯å®ç°æ›´é«˜æ€§ä»·æ¯”ã€‚

---

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ–ç‰¹å®šå‹ç¼©æ ¼å¼**ï¼šå½“å‰ä»…é’ˆå¯¹ BF16 çš„ exponent bits è®¾è®¡ï¼Œè‹¥æœªæ¥é‡‡ç”¨å…¶ä»–æ•°å€¼æ ¼å¼ï¼ˆå¦‚ FP8ã€DF11ï¼‰éœ€é‡æ–°åˆ†æã€‚
2. **å‹ç¼©æ”¶ç›Šæœ‰é™**ï¼šå¹³å‡å‹ç¼©ç‡çº¦ 30%~34%ï¼ˆZSTDï¼‰ï¼Œä»æœ‰æå‡ç©ºé—´ã€‚
3. **è°ƒåº¦å¤æ‚åº¦è¾ƒé«˜**ï¼šDAG æ„å»ºä¸è°ƒåº¦ç®—æ³•æœ‰ä¸€å®šå®ç°å¤æ‚åº¦ï¼Œå¯èƒ½å½±å“éƒ¨ç½²ä¾¿æ·æ€§ã€‚
4. **æœªè€ƒè™‘å†™å›å‹åŠ›**ï¼šé•¿æœŸè¿è¡Œä¸‹ç¼“å­˜æ±¡æŸ“ä¸å†™å›æœºåˆ¶æœªæ·±å…¥è®¨è®ºã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³æ›´å¤šæ¨¡å‹ç»“æ„**ï¼šå¦‚ Vision-MoEã€Multimodal MoEã€‚
2. **ç»“åˆè½»é‡çº§æœ‰æŸå‹ç¼©**ï¼šåœ¨å®‰å…¨å¯æ§å‰æä¸‹æ¢ç´¢â€œè¿‘æ— æŸâ€å‹ç¼©ï¼Œè¿›ä¸€æ­¥æå‡å‹ç¼©ç‡ã€‚
3. **æ”¯æŒåŠ¨æ€ä¸“å®¶æ¿€æ´»æ¨¡å¼å­¦ä¹ **ï¼šåœ¨çº¿å­¦ä¹  workload skewnessï¼Œè‡ªé€‚åº”è°ƒæ•´ç¼“å­˜ç­–ç•¥ã€‚
4. **è·¨è®¾å¤‡ååŒæ¨ç†**ï¼šç»“åˆäº‘ç«¯ä¸è¾¹ç¼˜è®¾å¤‡ï¼Œæ„å»ºåˆ†å±‚ MoE æ¨ç†ç½‘ç»œã€‚

--- 

> **æ€»ç»“ä¸€å¥è¯**ï¼š  
> ZIPMoE é€šè¿‡ **æ— æŸå‹ç¼© + åˆ†å±‚ç¼“å­˜ + äº²å’Œè°ƒåº¦** çš„ååŒè®¾è®¡ï¼Œåœ¨ä¸ç‰ºç‰²æ¨¡å‹å‡†ç¡®æ€§å’Œå®‰å…¨æ€§çš„å‰æä¸‹ï¼Œå®ç°äº† MoE æ¨¡å‹åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„é«˜æ•ˆéƒ¨ç½²ï¼Œ**å°†æ¨ç†å»¶è¿Ÿé™ä½é«˜è¾¾ 72.77%ï¼Œååæå‡è¾¾ 6.76Ã—**ï¼Œä¸ºç§»åŠ¨ç«¯å¤§æ¨¡å‹åº”ç”¨æä¾›äº†å¯é è§£å†³æ–¹æ¡ˆã€‚

</details>

---

### 10. [PHDME: Physics-Informed Diffusion Models without Explicit Governing Equations](https://arxiv.org/abs/2601.21234)

**Authors**: Kaiyuan Tan, Kendra Givens, Peilun Li, Thomas Beckers  
**Category**: cs.LG  
**Published**: 2026-01-30  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2601.21234v1  

#### Abstract
Diffusion models provide expressive priors for forecasting trajectories of dynamical systems, but are typically unreliable in the sparse data regime. Physics-informed machine learning (PIML) improves reliability in such settings; however, most methods require \emph{explicit governing equations} duri...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šPHDME: Physics-Informed Diffusion Models without Explicit Governing Equations

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
è¯¥è®ºæ–‡é’ˆå¯¹**ç¨€ç–è§‚æµ‹ä¸‹å¤æ‚åŠ¨åŠ›ç³»ç»Ÿé¢„æµ‹ä¸å¯é **çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨ä»¥ä¸‹æŒ‘æˆ˜åœºæ™¯ä¸­ï¼š
- æ•°æ®æåº¦ç¨€ç¼ºï¼ˆlimited observationsï¼‰
- ç³»ç»Ÿçš„é—­å¼æ§åˆ¶æ–¹ç¨‹ï¼ˆclosed-form governing equationsï¼‰æœªçŸ¥æˆ–éš¾ä»¥å»ºæ¨¡
- åŠ¨åŠ›å­¦é«˜åº¦éçº¿æ€§ä¸”ç»“æ„å¤æ‚ï¼ˆå¦‚è½¯ä½“æœºå™¨äººã€PDEç³»ç»Ÿï¼‰

ä¼ ç»Ÿæ–¹æ³•å¦‚çº¯æ•°æ®é©±åŠ¨çš„ Diffusion Models åœ¨æ•°æ®å°‘æ—¶æ³›åŒ–å·®ï¼›è€Œ Physics-Informed Neural Networks (PINNs) ç­‰éœ€è¦æ˜¾å¼çš„ PDE æ®‹å·®é¡¹ï¼Œåœ¨ç‰©ç†æ¨¡å‹ä¸å®Œæ•´æ—¶æ— æ³•åº”ç”¨ã€‚

---

### æå‡ºçš„æ–°æ–¹æ³•ï¼šPHDME
æå‡º **PHDME**ï¼ˆPhysics-Informed Diffusion Models without Explicit equationsï¼‰ï¼Œä¸€ç§ç»“åˆ **Gaussian Process distributed Port-Hamiltonian System (GP-dPHS)** ä¸ **Denoising Diffusion Models** çš„ä¸¤é˜¶æ®µæ¡†æ¶ã€‚

#### æ ¸å¿ƒæ€æƒ³ï¼š
- **ç¬¬ä¸€é˜¶æ®µ**ï¼šç”¨å°‘é‡è§‚æµ‹è®­ç»ƒä¸€ä¸ª **GP-dPHS** æ¨¡å‹ï¼Œå­¦ä¹ ç³»ç»Ÿçš„èƒ½é‡å‡½æ•°è¡¨ç¤ºï¼ˆHamiltonian functionalï¼‰ï¼Œæ— éœ€çŸ¥é“å…¶é—­å¼è¡¨è¾¾ã€‚
- **ç¬¬äºŒé˜¶æ®µ**ï¼šåˆ©ç”¨ GP-dPHS ç”Ÿæˆå¤§é‡ç¬¦åˆç‰©ç†è§„å¾‹çš„äººå·¥è½¨è¿¹ï¼Œç”¨äºè®­ç»ƒ Diffusion Modelï¼Œå¹¶å¼•å…¥åŸºäº GP ä¸ç¡®å®šæ€§çš„ **physics residual loss** æ¥å¼•å¯¼æ‰©æ•£è¿‡ç¨‹ã€‚

#### åˆ›æ–°ç‚¹ï¼š
1. **æ— éœ€æ˜¾å¼PDEçš„ç‰©ç†å…ˆéªŒæ³¨å…¥**  
   é¦–æ¬¡å°† Port-Hamiltonian ç»“æ„å…ˆéªŒèå…¥ diffusion æ¨¡å‹ï¼Œ**ä¸ä¾èµ–äºå·²çŸ¥çš„å¾®åˆ†æ–¹ç¨‹å½¢å¼**ï¼Œä»…é€šè¿‡æœ‰é™è§‚æµ‹å­¦ä¹ èƒ½é‡æ¢¯åº¦ã€‚

2. **Amortized ç‰©ç†é‡‡æ ·å™¨**  
   å°†åŸæœ¬è®¡ç®—æ˜‚è´µçš„ GP-dPHS rollout è¿‡ç¨‹â€œè’¸é¦â€ä¸ºå¿«é€Ÿæ‰¹é‡ç”Ÿæˆçš„ diffusion samplerï¼Œå®ç°**é«˜æ•ˆã€å¯æ‰©å±•çš„ç‰©ç†ä¸€è‡´è½¨è¿¹ç”Ÿæˆ**ã€‚

3. **ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„ç‰©ç†æ­£åˆ™åŒ–**  
   åˆ©ç”¨ GP çš„è´å¶æ–¯ç‰¹æ€§ï¼Œåœ¨ diffusion è®­ç»ƒä¸­åŠ æƒ physics loss â€”â€” åœ¨ç½®ä¿¡åŒºåŸŸåŠ å¼ºçº¦æŸï¼Œåœ¨é«˜ä¸ç¡®å®šåŒºåŸŸæ”¾æ¾ï¼Œé¿å…è¿‡æ‹Ÿåˆå™ªå£°ã€‚

4. **åå¤„ç†æ ¡å‡†æœºåˆ¶**  
   å¼•å…¥ **Split Conformal Prediction (CP)** å¯¹ç”Ÿæˆè½¨è¿¹æä¾›**æœ‰é™æ ·æœ¬ä¸‹çš„è¯¯å·®ä¿è¯**ï¼Œè¾“å‡ºå¸¦è¦†ç›–ç‡ä¿éšœçš„é¢„æµ‹åŒºé—´ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| æ–¹æ³• | æ˜¯å¦éœ€æ˜¾å¼PDE | æ•°æ®æ•ˆç‡ | æ³›åŒ–èƒ½åŠ› | ç”Ÿæˆé€Ÿåº¦ |
|------|----------------|-----------|------------|-------------|
| Standard DDPM | âŒ | âŒï¼ˆä½ï¼‰ | âŒ | âœ… |
| PINNs / Physics-guided Diffusion | âœ… | â­• | â­• | âŒ |
| GP-dPHS Integrator | âŒ | âœ… | âœ… | âŒï¼ˆæ…¢ï¼‰ |
| **PHDME (æœ¬æ–‡)** | âŒ | âœ…âœ… | âœ…âœ… | âœ… |

> âœ… è¡¨ç¤ºä¼˜åŠ¿ï¼ŒâŒ è¡¨ç¤ºåŠ£åŠ¿ï¼Œâ­• è¡¨ç¤ºä¸€èˆ¬

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†
åœ¨ä¸‰ä¸ªä¸åŒç±»å‹çš„ PDE æˆ–çœŸå®ç³»ç»Ÿä¸Šè¿›è¡ŒéªŒè¯ï¼š

| æ•°æ®é›† | ç±»å‹ | æè¿° |
|--------|------|------|
| **String (Wave PDE)** | åˆæˆ | å›ºå®šç«¯å¼¦æŒ¯åŠ¨ï¼Œç”±æ³¢åŠ¨æ–¹ç¨‹æ§åˆ¶ $ \partial_t^2 s = c^2 \partial_x^2 s $ |
| **1D Shallow Water** | åˆæˆ | æµ…æ°´æ³¢ç³»ç»Ÿï¼Œæ¨¡æ‹Ÿéçº¿æ€§æµä½“è¡Œä¸º |
| **Real-world Spring** | çœŸå®ä¸–ç•Œ | ä½¿ç”¨é«˜é€Ÿç›¸æœºæ‹æ‘„çº¢è‰²å¼¹ç°§æ¨ªå‘æŒ¯è¡ï¼Œé€šè¿‡ RGB åˆ†å‰² + skeletonization è·å–ä¸­å¿ƒçº¿ä½ç§»è½¨è¿¹ |

> æ‰€æœ‰ä»»åŠ¡å‡é™åˆ¶ä¸ºä»…ä½¿ç”¨ **20æ¡ç¨€ç–è½¨è¿¹**ä½œä¸ºåŸå§‹è§‚æµ‹æ•°æ®ã€‚

---

### å®éªŒè®¾ç½®
- **è¾“å…¥æ ¼å¼**ï¼šå°†æ—¶ç©ºæ¼”åŒ–ç¼–ç ä¸ºå›¾åƒå½¢å¼ï¼ˆspatiotemporal field as imageï¼‰ï¼Œæ—¶é—´ä½œæ¨ªè½´ï¼Œç©ºé—´ä½œçºµè½´ï¼ŒçŠ¶æ€å˜é‡ï¼ˆå¦‚ä½ç§»ã€åŠ¨é‡ï¼‰ä»¥é€šé“æ–¹å¼è¾“å…¥ã€‚
- **æ¨¡å‹æ¶æ„**ï¼šé‡‡ç”¨ U-Net ä½œä¸º diffusion model çš„ backboneã€‚
- **è®­ç»ƒæµç¨‹**ï¼š
  1. å…ˆç”¨ç¨€ç–æ•°æ®è®­ç»ƒ GP-dPHSï¼›
  2. ä» GP-dPHS posterior ä¸­é‡‡æ · Hamiltonian gradient å¹¶æ•°å€¼ç§¯åˆ†ï¼Œç”Ÿæˆ 10,000 æ¡äººå·¥è®­ç»ƒè½¨è¿¹ï¼›
  3. ç”¨è¿™äº›è½¨è¿¹è®­ç»ƒ diffusion modelï¼Œå¹¶åŠ å…¥ physics-informed lossï¼›
  4. æœ€åå¯¹ diffusion è¾“å‡ºåº”ç”¨ conformal prediction è¿›è¡Œæ ¡å‡†ã€‚

---

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å®šä¹‰ | ç”¨é€” |
|------|------|------|
| **MSE** | å‡æ–¹è¯¯å·®ï¼ˆvs ground truthï¼‰ | è¡¡é‡é¢„æµ‹å‡†ç¡®æ€§ |
| **NCS (Non-Conformity Score)** | è½¨è¿¹çº§ MSE çš„æ’åºç»Ÿè®¡é‡ | ç”¨äº conformal prediction çš„æ ¡å‡†è´¨é‡è¯„ä¼° |
| **Coverage Rate** | çœŸå®è½¨è¿¹è½å…¥é¢„æµ‹åŒºé—´çš„æ¯”ä¾‹ | è¯„ä»· uncertainty quantification å¯é æ€§ |

---

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| åŸºçº¿ | æè¿° |
|------|------|
| **DDPM (Standard)** | æ— ä»»ä½•ç‰©ç†çº¦æŸçš„æ ‡å‡† diffusion model |
| **DDPM + Limited Physics** | åŠ å…¥ç®€å•è¾¹ç•Œæ¡ä»¶ï¼ˆå¦‚å›ºå®šç«¯ï¼‰ï¼Œä½†æ— æ·±å±‚ç‰©ç†å…ˆéªŒ |
| **GP-dPHS Integrator** | ç›´æ¥ä½¿ç”¨ GP-dPHS æ•°å€¼ rolloutï¼Œä»£è¡¨â€œé»„é‡‘æ ‡å‡†â€ç‰©ç†ä¸€è‡´æ€§ï¼Œä½†ææ…¢ |
| **Neural ODE** | çº¯æ•°æ®é©±åŠ¨è¿ç»­æ¨¡å‹ï¼Œæ— ç‰©ç†ç»“æ„å…ˆéªŒ |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 1ï¼‰

| Dataset | Metric | PHDME | DDPM | DDPM+BC | GP-dPHS | NeuralODE |
|--------|--------|-------|------|---------|----------|-----------|
| **String** | MSE | **2.74e-3** | 3.81e-3 | 4.53e-3 | 2.03e-2 | 2.54e-2 |
|          | NCS | **6.41e-3** | 6.82e-3 | 9.80e-3 | â€“ | â€“ |
| **Shallow Water** | MSE | **2.06e-2** | 2.31e-2 | 2.92e-2 | 2.23e-1 | 4.76e-2 |
|                   | NCS | **9.75e-2** | 1.02e-1 | 1.05e-1 | â€“ | â€“ |
| **Real-world Spring** | MSE | **5.21e-2** | 5.02e-2 | 5.44e-2 | 7.65e-1 | 2.037 |
|                       | NCS | **2.93e-3** | 3.07e-3 | 7.09e-4 | â€“ | â€“ |

> âœ… PHDME åœ¨åˆæˆæ•°æ®ä¸Šæ˜¾è‘—ä¼˜äºæ‰€æœ‰ baselineï¼ˆå¹³å‡ MSE â†“~28%ï¼‰  
> âœ… åœ¨çœŸå®å¼¹ç°§æ•°æ®ä¸Šä¸æœ€ä½³ DDPM ç›¸å½“ï¼Œä½†å…·æœ‰æ›´å¼ºçš„ç‰©ç†ä¸€è‡´æ€§  
> âœ… NCS æ›´å°ï¼Œè¯´æ˜ç”Ÿæˆåˆ†å¸ƒæ›´é›†ä¸­ã€æ›´å¯é   

---

### ä¸å…¶ä»–æ–¹æ³•çš„å…³é”®å¯¹æ¯”å‘ç°
- **PHDME vs DDPM**ï¼šå°½ç®¡ DDPM åœ¨çœŸå®å¼¹ç°§ä¸Š MSE ç•¥ä¼˜ï¼Œä½†å…¶ç”Ÿæˆè½¨è¿¹å¸¸è¿åèƒ½é‡å®ˆæ’ï¼ˆè§ Figure 11ï¼‰ï¼Œè€Œ PHDME ä¸¥æ ¼éµå¾ª Hamiltonian åŠ¨åŠ›å­¦ã€‚
- **PHDME vs GP-dPHS**ï¼šä¸¤è€…ç‰©ç†ä¸€è‡´æ€§æ¥è¿‘ï¼Œä½† **PHDME ç”Ÿæˆé€Ÿåº¦å¿« 20 å€ä»¥ä¸Š**ï¼ˆè§ Table 2ï¼‰ï¼š
  
  | Method | Avg Speed (s/sample) |
  |--------|------------------------|
  | GP-dPHS | 4.1 |
  | PHDME | **0.2** |

- **PHDME vs NeuralODE**ï¼šNeuralODE åœ¨è®­ç»ƒåˆ†å¸ƒå†…è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨**æœªè§è¿‡çš„åˆå§‹æ¡ä»¶ä¸‹è¿…é€Ÿå´©æºƒ**ï¼ˆè§ Figure 15ï¼‰ï¼Œè€Œ PHDME å‡­å€Ÿç‰©ç†å…ˆéªŒå®ç°å¼ºå¤–æ¨èƒ½åŠ›ã€‚

---

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰
- **æ›¿æ¢ GP-dPHS ä¸ºçº¿æ€§å›å½’ä¼°è®¡å™¨ï¼ˆoracle quadratic Hamiltonianï¼‰**ï¼š
  - MSE ä» 0.1818ï¼ˆGP-dPHSï¼‰ä¸Šå‡è‡³ 0.2967
  - è¯æ˜éå‚æ•°åŒ–çš„ GP å­¦ä¹ æ¯”é¢„è®¾å‡½æ•°å½¢å¼æ›´å…·è¡¨è¾¾åŠ›å’Œé²æ£’æ€§ã€‚
- **ç§»é™¤ uncertainty-weighted physics loss**ï¼š
  - åœ¨é«˜å™ªå£°åŒºåŸŸå‡ºç°éç‰©ç†è§£ï¼ŒéªŒè¯äº†ä¸ç¡®å®šæ€§åŠ æƒçš„é‡è¦æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **Representation-level ç‰©ç†å…ˆéªŒä¼˜äº Equation-level çº¦æŸ**  
   å³ä½¿ä¸çŸ¥é“å…·ä½“ PDE å½¢å¼ï¼Œä¹Ÿèƒ½é€šè¿‡å­¦ä¹  **energy-based representation**ï¼ˆå¦‚ Hamiltonian gradientsï¼‰æ¥æœ‰æ•ˆæ³¨å…¥ç‰©ç†çŸ¥è¯†ã€‚

2. **Amortization æ˜¯å…³é”®æ¡¥æ¢**  
   å°†ç¼“æ…¢ä½†å‡†ç¡®çš„ GP-dPHS â€œè’¸é¦â€ä¸ºå¿«é€Ÿ diffusion samplerï¼Œå®ç°äº†**ç‰©ç†å¯é æ€§ä¸ç”Ÿæˆæ•ˆç‡çš„åŒèµ¢**ã€‚

3. **PHDME å…·å¤‡å¼º out-of-distribution æ³›åŒ–èƒ½åŠ›**  
   åœ¨æœªè§è¿‡çš„åˆå§‹æ¡ä»¶å’Œæ¿€åŠ±æ¨¡å¼ä¸‹ä»èƒ½ä¿æŒåˆç†åŠ¨æ€æ¼”åŒ–ï¼Œè¿œè¶…çº¯æ•°æ®é©±åŠ¨æ¨¡å‹ã€‚

4. **Uncertainty-aware physics loss æå‡è®­ç»ƒç¨³å®šæ€§**  
   åˆ©ç”¨ GP çš„é¢„æµ‹æ–¹å·®åŠ¨æ€è°ƒæ•´ç‰©ç†çº¦æŸå¼ºåº¦ï¼Œé˜²æ­¢åœ¨æ•°æ®ç¨€ç–åŒºè¿‡åº¦æƒ©ç½šã€‚

5. **Conformal Prediction æä¾›å¯é çš„ä¸ç¡®å®šæ€§é‡åŒ–**  
   å®éªŒæ˜¾ç¤ºæµ‹è¯•é›†è¦†ç›–ç‡è¾¾åˆ° **95%**ï¼ˆç›®æ ‡ä¸º 90%ï¼‰ï¼Œè¡¨æ˜å…¶å…·å¤‡è‰¯å¥½çš„ finite-sample ä¿è¯ã€‚

---

### å±€é™æ€§
- **æç«¯å°å°ºåº¦ä¿¡å·æ¢å¤å›°éš¾**ï¼šå½“çŠ¶æ€å¹…å€¼è¶‹è¿‘é›¶æ—¶ï¼ŒGP åéªŒè¶‹äºå¹³å¦ï¼Œå¯¼è‡´èƒ½é‡æ¢¯åº¦ä¼°è®¡å¤±çœŸï¼ˆè§ Figure 17ï¼‰ã€‚
- **ä¾èµ– Port-Hamiltonian ç»“æ„å‡è®¾**ï¼šè™½ç„¶ J/R/G æ¨¡æ¿ç³»æ•°å¯å­¦ï¼Œä½†ä»éœ€é¢„å…ˆå®šä¹‰ç®—å­ç»“æ„ï¼ˆå¦‚æ˜¯å¦å«è€—æ•£é¡¹ï¼‰ã€‚
- **ç›®å‰é€‚ç”¨äºä½ç»´ PDE ç³»ç»Ÿ**ï¼šå°šæœªæ‰©å±•åˆ°é«˜ç»´å¤æ‚åœºï¼ˆå¦‚ä¸‰ç»´ Navier-Stokesï¼‰ã€‚

---

### æœªæ¥å·¥ä½œæ–¹å‘
1. **æ‰©å±•è‡³æ›´é«˜ç»´å’Œå¤šç‰©ç†åœºè€¦åˆç³»ç»Ÿ**
2. **è”åˆä¼˜åŒ– GP-dPHS ä¸ diffusion model çš„ç«¯åˆ°ç«¯è®­ç»ƒ**
3. **é›†æˆåˆ°é—­ç¯æ§åˆ¶ä¸­ï¼Œæ„å»º Generative MPC æ§åˆ¶å™¨ï¼ˆå¦‚ NAPI-MPCï¼‰**
4. **æ¢ç´¢å…¶ä»–ç»“æ„å…ˆéªŒï¼ˆå¦‚ Lagrangian, GENERIC frameworkï¼‰æ›¿ä»£ Port-Hamiltonian**

---

> ğŸ’¡ **æ€»ä½“å½±å“**ï¼šPHDME æä¾›äº†ä¸€ç§åœ¨**ç°å®ä¸–ç•Œä¸­å¸¸è§ä½†è¢«å¿½è§†çš„è®¾å®šä¸‹**ï¼ˆå³ï¼šæ•°æ®å°‘ + ç‰©ç†ä¸å®Œå…¨å·²çŸ¥ï¼‰è¿›è¡Œå¯é ã€å¿«é€Ÿã€å¯è§£é‡Šçš„åŠ¨åŠ›ç³»ç»Ÿå»ºæ¨¡çš„æ–°èŒƒå¼ï¼Œæœ‰æœ›æ¨åŠ¨ç§‘å­¦æœºå™¨å­¦ä¹ åœ¨æœºå™¨äººã€æ°”å€™æ¨¡æ‹Ÿã€ç”Ÿç‰©åŠ›å­¦ç­‰é¢†åŸŸçš„è½åœ°åº”ç”¨ã€‚

</details>

---

### 11. [SENDAI: A Hierarchical Sparse-measurement, EfficieNt Data AssImilation Framework](https://arxiv.org/abs/2601.21664)

**Authors**: Xingyue Zhang, Yuxuan Bao, Mars Liyao Gao, J. Nathan Kutz  
**Category**: cs.LG  
**Published**: 2026-01-30  
**Score**: 10.0  
**Type**: new  
**ArXiv ID**: 2601.21664v1  

#### Abstract
Bridging the gap between data-rich training regimes and observation-sparse deployment conditions remains a central challenge in spatiotemporal field reconstruction, particularly when target domains exhibit distributional shifts, heterogeneous structure, and multi-scale dynamics absent from available...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# **è®ºæ–‡æ€»ç»“ï¼šSENDAI: A Hierarchical Sparse-measurement, EfficieNt Data AssImilation Framework**

---

## **1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹**

### **è§£å†³çš„é—®é¢˜**
è¯¥è®ºæ–‡æ—¨åœ¨è§£å†³**åœ¨è§‚æµ‹æåº¦ç¨€ç–ï¼ˆsparse observationsï¼‰ä¸”ç›®æ ‡åŸŸå­˜åœ¨åˆ†å¸ƒåç§»ï¼ˆdomain shiftï¼‰çš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•é«˜æ•ˆã€å‡†ç¡®åœ°é‡å»ºæ—¶ç©ºåœºï¼ˆspatiotemporal fieldsï¼‰**è¿™ä¸€æ ¸å¿ƒæŒ‘æˆ˜ã€‚å…·ä½“åº”ç”¨åœºæ™¯ä¸ºå«æ˜Ÿé¥æ„Ÿä¸­çš„æ¤è¢«æŒ‡æ•°ï¼ˆå¦‚NDVIï¼‰é‡å»ºï¼Œé¢ä¸´ä»¥ä¸‹éš¾ç‚¹ï¼š
- å«æ˜Ÿæ•°æ®å¸¸å› äº‘å±‚é®æŒ¡ã€ä¼ æ„Ÿå™¨æ•…éšœç­‰å¯¼è‡´ç©ºé—´è¦†ç›–ä¸¥é‡ä¸å®Œæ•´ï¼›
- ä¸åŒå­£èŠ‚é—´çš„ç‰©å€™å˜åŒ–ï¼ˆphenological shiftsï¼‰å¼•å…¥æ˜¾è‘—çš„åˆ†å¸ƒåç§»ï¼›
- ç°æœ‰æ·±åº¦å­¦ä¹ æ–¹æ³•é€šå¸¸ä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®å’ŒGPUé›†ç¾¤ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™æˆ–å®æ—¶åœºæ™¯ä¸­éƒ¨ç½²ã€‚

### **æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯**
ä½œè€…æå‡ºäº† **SENDAI**ï¼ˆSparse-measurement, EfficieNt Data AssImilationï¼‰ï¼Œä¸€ä¸ª**åˆ†å±‚çš„ã€é«˜æ•ˆçš„ç¨€ç–æ•°æ®åŒåŒ–æ¡†æ¶**ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†é‡å»ºä»»åŠ¡åˆ†è§£ä¸ºä¸¤ä¸ªäº’è¡¥è·¯å¾„ï¼š

1. **ä½é¢‘è·¯å¾„ï¼ˆLow-Frequency, LF Pathwayï¼‰**  
   - åˆ©ç”¨ **SHRED**ï¼ˆShallow Recurrent Decoder Networksï¼‰ç»“åˆ **Takens' embedding theorem**ï¼Œä»æ¨¡æ‹Ÿæ•°æ®ä¸­å­¦ä¹ ä¸»å¯¼çš„åŠ¨åŠ›å­¦æ¨¡å¼ï¼›
   - å¼•å…¥ **latent-space GAN alignment**ï¼Œé€šè¿‡å¯¹æŠ—è®­ç»ƒå¯¹é½æ¨¡æ‹Ÿæ•°æ®ä¸çœŸå®è§‚æµ‹ä¹‹é—´çš„æ½œåœ¨ç©ºé—´åˆ†å¸ƒï¼Œå®ç°è·¨åŸŸé€‚åº”ï¼ˆdomain adaptationï¼‰ã€‚

2. **é«˜é¢‘è·¯å¾„ï¼ˆHigh-Frequency, HF Pathwayï¼‰**  
   - é‡‡ç”¨ **sequential frequency peeling** ç­–ç•¥ï¼Œé€å±‚æå–ä¸åŒé¢‘ç‡æˆåˆ†çš„æ®‹å·®ä¿®æ­£ï¼›
   - æ¯ä¸€å±‚ä½¿ç”¨ **coordinate-based Implicit Neural Representation (INR)** è¿›è¡Œè§£ç ï¼Œç¡®ä¿ç©ºé—´è¿ç»­æ€§å’Œç»“æ„ä¿çœŸï¼›
   - å¼•å…¥ **spectral constraints** å’Œ **frequency exclusion mechanism**ï¼Œé˜²æ­¢æ¨¡å¼æ³„æ¼ï¼ˆmode leakageï¼‰ï¼Œæå‡å¯è§£é‡Šæ€§ã€‚

### **ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿**
| ç»´åº¦ | SENDAIä¼˜åŠ¿ |
|------|-----------|
| **æç«¯ç¨€ç–æ€§å®¹å¿** | ä»…éœ€ **64ä¸ªä¼ æ„Ÿå™¨**ï¼ˆå ç©ºé—´åŸŸ1.56%ï¼‰å³å¯å®Œæˆé«˜è´¨é‡é‡å»ºï¼Œè¿œä½äºä¼ ç»Ÿæ–¹æ³•æ‰€éœ€å¯†åº¦ |
| **è®¡ç®—æ•ˆç‡é«˜** | å¯åœ¨æ ‡å‡†CPUä¸Šè¿è¡Œï¼Œå•ç«™ç‚¹è®­ç»ƒæ—¶é—´ä»…æ•°åˆ†é’Ÿï¼Œé€‚åˆè¾¹ç¼˜è®¾å¤‡å’Œå®æ—¶åº”ç”¨ |
| **ç»“æ„ä¿æŒèƒ½åŠ›å¼º** | æ˜¾è‘—ä¿ç•™åœºæ‹“æ‰‘ç»“æ„ï¼ˆfield topologiesï¼‰ã€åœŸåœ°è¦†ç›–é—´æ–­ï¼ˆland cover discontinuitiesï¼‰å’Œç©ºé—´æ¢¯åº¦ |
| **ç‰©ç†å¯è§£é‡Šæ€§å¼º** | åˆ†å±‚é¢‘ç‡å‰¥ç¦»æœºåˆ¶ä½¿é«˜é¢‘ä¿®æ­£å…·æœ‰æ˜ç¡®çš„ç‰©ç†æ„ä¹‰ï¼ˆå¦‚æ°”å€™é©±åŠ¨ã€æ°´æ–‡æ§åˆ¶ã€åœŸå£¤å¼‚è´¨æ€§ï¼‰ |
| **æ³›åŒ–èƒ½åŠ›å¥½** | åœ¨å…­ç§ä¸åŒæ°”å€™åŒºï¼ˆåœ°ä¸­æµ·ã€å¤§é™†æ€§ã€å¹²æ—±ã€äºšçƒ­å¸¦ï¼‰å‡è¡¨ç°ä¼˜å¼‚ |

---

## **2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®**

### **ä½¿ç”¨çš„æ•°æ®é›†**
- **é¥æ„Ÿå¹³å°**ï¼šNASA Terra/Aqua å«æ˜Ÿæ­è½½çš„ **MODIS**ï¼ˆModerate Resolution Imaging Spectroradiometerï¼‰
- **ç ”ç©¶å˜é‡**ï¼š**Normalized Difference Vegetation Index (NDVI)**ï¼Œç”¨äºè¡¨å¾æ¤è¢«è¦†ç›–çŠ¶æ€
- **ç ”ç©¶åŒºåŸŸ**ï¼šå…¨çƒå…­ä¸ªä»£è¡¨æ€§ç«™ç‚¹ï¼Œæ¶µç›–å¤šç§æ°”å€™ä¸åœŸåœ°åˆ©ç”¨ç±»å‹ï¼š
  - Central Valley, USAï¼ˆçŒæº‰å†œä¸šï¼‰
  - Corn Belt, USAï¼ˆé›¨å…»ä½œç‰©è½®ä½œï¼‰
  - Imperial Valley, USAï¼ˆæ²™æ¼ ç»¿æ´²å†œä¸šï¼‰
  - Tarim Basin, Chinaï¼ˆé«˜å±±è’æ¼ ç»¿æ´²ï¼‰
  - Guadalquivir Valley, Spainï¼ˆåœ°ä¸­æµ·æ··åˆå†œä¸šï¼‰
  - Riverina, Australiaï¼ˆåŠæ¹¿æ¶¦æ··åˆç§æ¤ï¼‰

> æ•°æ®é€šè¿‡ **Google Earth Engine** è·å–ï¼Œå¹¶è¿›è¡Œäº‘æ©è†œå¤„ç†ä¸é‡é‡‡æ ·è‡³ç»Ÿä¸€çš„ $64 \times 64$ ç½‘æ ¼ã€‚

### **å®éªŒè®¾ç½®**
- **æ¨¡æ‹Ÿ-çœŸå®åŸŸåˆ’åˆ†**ï¼šä»¥**ä¸åŒå­£èŠ‚ä½œä¸ºâ€œæ¨¡æ‹Ÿâ€ä¸â€œçœŸå®â€æ•°æ®æº**ï¼Œæ¨¡æ‹Ÿåˆ†å¸ƒåç§»ï¼š
  - æ¨¡æ‹ŸæœŸï¼ˆSimulationï¼‰ï¼šæ˜¥å­£ï¼ˆå¦‚ Aprâ€“Junï¼‰
  - çœŸå®æœŸï¼ˆGround Truthï¼‰ï¼šå¤å­£/ç§‹å­£ï¼ˆå¦‚ Julâ€“Octï¼‰
- **ä¼ æ„Ÿå™¨é…ç½®**ï¼šéšæœºå¸ƒç½® **64ä¸ªä¼ æ„Ÿå™¨**ï¼ˆçº¦å æ€»åƒç´ 1.56%ï¼‰ï¼Œè®°å½•æ—¶é—´åºåˆ—è§‚æµ‹
- **è¾“å…¥å†å²é•¿åº¦**ï¼šä½¿ç”¨è¿‡å» $L=5$ ä¸ªæ—¶é—´æ­¥çš„ä¼ æ„Ÿå™¨å†å²ä½œä¸ºè¾“å…¥

### **è¯„ä¼°æŒ‡æ ‡**
| æŒ‡æ ‡ | æè¿° |
|------|------|
| **RMSE** | è¡¡é‡ç‚¹å¯¹ç‚¹è¯¯å·®ï¼Œåæ˜ æ•°å€¼å‡†ç¡®æ€§ |
| **SSIM**ï¼ˆStructural Similarity Index Measureï¼‰ | è¡¡é‡ç»“æ„ç›¸ä¼¼æ€§ï¼Œç‰¹åˆ«å…³æ³¨è¾¹ç•Œã€çº¹ç†å’Œæ‹“æ‰‘ç»“æ„çš„ä¿æŒèƒ½åŠ›ï¼Œä¸ºä¸»å¯¼è¯„ä»·æŒ‡æ ‡ |

### **åŸºçº¿æ–¹æ³•å¯¹æ¯”**
| æ–¹æ³• | ç±»å‹ | ç‰¹ç‚¹ |
|------|------|------|
| **SG+IDW** | ä¼ ç»Ÿæµç¨‹ | Savitzky-Golayæ»¤æ³¢ + åè·ç¦»åŠ æƒæ’å€¼ |
| **HANTS+IDW** | å­£èŠ‚å»ºæ¨¡ | è°æ³¢åˆ†æå»äº‘ + IDWæ’å€¼ |
| **Kriging** | åœ°ç»Ÿè®¡ | é«˜æ–¯è¿‡ç¨‹å›å½’ï¼ˆRBFæ ¸ï¼‰ |
| **MMGN** | æ·±åº¦å­¦ä¹  | åŸºäºGaboræ»¤æ³¢çš„éšå¼ç¥ç»ç½‘ç»œï¼Œæœ€æ–°SOTAä¹‹ä¸€ |

---

## **3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡**

### **å…³é”®æ€§èƒ½æ•°æ®ï¼ˆSSIMï¼‰**

#### **SENDAI Jr. æ€§èƒ½ï¼ˆé€‚ç”¨äºä½é¢‘ä¸»å¯¼åœºæ™¯ï¼‰**
| ç«™ç‚¹ | æœ€ä½³åŸºçº¿ SSIM | SENDAI Jr. SSIM | **ç›¸å¯¹æå‡** |
|------|----------------|------------------|-------------|
| Central Valley | 0.2612 | **0.5747** | **+120%** |
| Corn Belt | 0.1588 | **0.4530** | **+185%** |
| Guadalquivir | 0.1849 | **0.3655** | **+98%** |

> âœ… **æœ€å¤§SSIMæå‡è¾¾185%**ï¼Œæ˜¾è‘—ä¼˜äºæ‰€æœ‰ä¼ ç»Ÿä¸æ·±åº¦å­¦ä¹ åŸºçº¿ã€‚

#### **å®Œæ•´SENDAIæ€§èƒ½ï¼ˆå«é«˜é¢‘å‰¥ç¦»ï¼Œé€‚ç”¨äºå¤æ‚åœ°å½¢ï¼‰**
| ç«™ç‚¹ | Cheap2Rich SSIM | SENDAI SSIM | **ç›¸å¯¹æå‡** |
|------|------------------|--------------|-------------|
| Imperial Valley | 0.4041 | **0.4668** | +15.5% |
| Tarim Basin | 0.3505 | **0.4777** | **+36.3%** |
| Riverina | 0.2761 | **0.3354** | +21.5% |

> ğŸ”º **åœ¨Tarim Basinè¾¾åˆ°æœ€é«˜å¢ç›Šï¼ˆ+36.3%ï¼‰**ï¼Œå› å…¶å…·æœ‰å¼ºçƒˆçš„å±±ç›†è¾¹ç•Œå’Œå¤šå°ºåº¦åŠ¨æ€ã€‚

### **ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ**
- æ‰€æœ‰åŸºçº¿æ–¹æ³•ï¼ˆåŒ…æ‹¬MMGNï¼‰åœ¨**æç«¯ç¨€ç–æ¡ä»¶ä¸‹å¤±æ•ˆ**ï¼š
  - IDWç±»æ–¹æ³•äº§ç”Ÿâ€œç‰›çœ¼æ•ˆåº”â€ï¼ˆbullseye artifactsï¼‰ï¼›
  - Krigingè¿‡åº¦å¹³æ»‘ï¼Œå®Œå…¨æŠ¹é™¤è¾¹ç•Œä¿¡æ¯ï¼ˆTarim Basinä¸ŠSSIMä»…ä¸º0.0449ï¼‰ï¼›
  - MMGNè™½ä¸ºæ·±åº¦æ¨¡å‹ï¼Œä½†åœ¨1.56%ä¼ æ„Ÿå™¨ä¸‹ä»æ— æ³•æ•æ‰ç»†ç²’åº¦ç»“æ„ã€‚
- SENDAIä¸ä»…æå‡SSIMï¼Œåœ¨RMSEä¸Šä¹ŸåŒæ­¥æ”¹å–„ï¼Œè¡¨æ˜å…¶å…¼å…·**ç²¾åº¦ä¸ç»“æ„ä¿çœŸ**ã€‚

### **æ¶ˆèå®éªŒç»“æœ**
- **æ˜¯å¦å¯ç”¨Hierarchical Peeling**ï¼š
  - ç§»é™¤åˆ†å±‚å‰¥ç¦»åï¼ŒSSIMä¸‹é™æ˜æ˜¾ï¼ˆå°¤å…¶åœ¨Tarim Basinï¼‰ï¼›
  - å•å±‚HFæ˜“å‡ºç°æ¨¡å¼æ··å ï¼Œè€Œåˆ†å±‚ç­–ç•¥èƒ½æœ‰æ•ˆåˆ†ç¦»æ°”å€™ã€æ°´æ–‡ã€åœŸå£¤ç­‰ä¸åŒæ¥æºçš„ä¿®æ­£ä¿¡å·ã€‚
- **æ˜¯å¦ä½¿ç”¨INRè§£ç å™¨**ï¼š
  - æ›¿æ¢ä¸ºæ™®é€šMLPä¼šå¯¼è‡´è¾“å‡ºå‘ˆç°â€œç‚¹çŠ¶ä¼ªå½±â€ï¼ˆdotted artifactsï¼‰ï¼Œç©ºé—´ä¸è¿è´¯ï¼›
  - INRç»“åˆFourier positional encodingæ˜¾è‘—å¢å¼ºé«˜é¢‘æ¢å¤èƒ½åŠ›ã€‚
- **é¢‘ç‡æ’é™¤æœºåˆ¶ï¼ˆfrequency exclusionï¼‰**ï¼š
  - æ— æ­¤æœºåˆ¶æ—¶ï¼Œåç»­å±‚ä¼šé‡å¤æ•è·å·²å‘ç°çš„é¢‘ç‡ï¼Œé€ æˆå†—ä½™ï¼›
  - åŠ å…¥åå„å±‚ä¿®æ­£æ›´å…·ç‹¬ç«‹æ€§å’Œå¯è§£é‡Šæ€§ã€‚

---

## **4. å…³é”®ç»“è®ºå’Œå‘ç°**

### **ä¸»è¦å‘ç°**
1. **åˆ†å±‚é¢‘ç‡å»ºæ¨¡æ˜¯åº”å¯¹å¼‚æ„æ—¶ç©ºåœºçš„å…³é”®**ï¼š  
   å°†é‡å»ºä»»åŠ¡æŒ‰é¢‘ç‡åˆ†è§£ï¼ŒLFè·¯å¾„æ•è·å¤§å°ºåº¦è¶‹åŠ¿ï¼ŒHFè·¯å¾„é€å±‚å‰¥ç¦»å±€éƒ¨ç»†èŠ‚ï¼Œå®ç°äº†**ç»“æ„ä¸ç»†èŠ‚çš„ååŒä¼˜åŒ–**ã€‚

2. **æä½è§‚æµ‹å¯†åº¦ä¸‹ä»å¯å®ç°é«˜ä¿çœŸé‡å»º**ï¼š  
   ä»…ç”¨ **1.56%çš„ç©ºé—´é‡‡æ ·ç‡**ï¼ˆ64ä¼ æ„Ÿå™¨ï¼‰å³å¯é‡å»ºå®Œæ•´åœºï¼Œçªç ´äº†ä¼ ç»Ÿæ–¹æ³•å¯¹å¯†é›†è§‚æµ‹çš„ä¾èµ–ã€‚

3. **è½»é‡åŒ–æ¶æ„æ”¯æŒè¾¹ç¼˜éƒ¨ç½²**ï¼š  
   SENDAIå¯åœ¨CPUä¸Šè¿è¡Œï¼Œ**å•æ¬¡æ¨ç†è€—æ—¶ç§’çº§**ï¼Œé€‚åˆæ— äººæœºã€å°å«æ˜Ÿã€åœ°é¢ç«™ç­‰èµ„æºå—é™ç¯å¢ƒã€‚

4. **é‡å»ºç»“æœæ›´åˆ©äºä¸‹æ¸¸æ¨æ–­**ï¼š  
   ç”±äºä¿®æ­£é¡¹å…·æœ‰ç‰©ç†å¯åˆ†æ€§ï¼ˆspectrally separableï¼‰ï¼Œé‡å»ºåçš„åœºæ›´é€‚åˆç”¨äºåæ¼”é—´æ¥è§‚æµ‹å˜é‡ï¼ˆå¦‚åœŸå£¤æ¹¿åº¦ã€åœ°è¡¨æ¸©åº¦ï¼‰ã€‚

### **æ–¹æ³•çš„å±€é™æ€§**
1. **å‡è®¾ç©ºé—´ç»“æ„å¹³ç¨³**ï¼šå½“å‰æ¡†æ¶æœªè€ƒè™‘åœŸåœ°è¦†ç›–å˜åŒ–ã€äººä¸ºæ‰°åŠ¨ç­‰å¼•èµ·çš„éå¹³ç¨³æ€§ï¼›
2. **ä¼ æ„Ÿå™¨ä½ç½®éšæœºè®¾å®š**ï¼šæœªä¼˜åŒ–å¸ƒç‚¹ç­–ç•¥ï¼Œæœªæ¥å¯é€šè¿‡ä¿¡æ¯è®ºæŒ‡å¯¼æœ€ä¼˜é‡‡æ ·è®¾è®¡ï¼›
3. **è·¨å¤§é™†æ³›åŒ–å¾…éªŒè¯**ï¼šç›®å‰ä¸ºåŒºåŸŸå†…å­£èŠ‚è¿ç§»æµ‹è¯•ï¼Œå°šæœªä¸¥æ ¼éªŒè¯è·¨æ°”å€™å¸¦è¿ç§»èƒ½åŠ›ï¼›
4. **å•å˜é‡é‡å»ºä¸ºä¸»**ï¼šå°šæœªæ‰©å±•åˆ°å¤šå˜é‡è”åˆé‡å»ºï¼ˆå¦‚NDVI + LST + SMï¼‰ã€‚

### **æœªæ¥å·¥ä½œæ–¹å‘**
1. **æ‰©å±•è‡³éå¹³ç¨³åœºæ™¯**ï¼šå¼•å…¥åŠ¨æ€ç¼–ç å™¨æˆ–åœ¨çº¿æ›´æ–°æœºåˆ¶ï¼Œé€‚åº”åœŸåœ°åˆ©ç”¨å˜åŒ–ï¼›
2. **ä¸»åŠ¨æ„ŸçŸ¥ä¸æœ€ä¼˜å¸ƒç‚¹**ï¼šç»“åˆä¿¡æ¯ç†µæˆ–äº’ä¿¡æ¯è®¾è®¡ä¼ æ„Ÿå™¨å¸ƒå±€ï¼Œè¿›ä¸€æ­¥é™ä½é‡‡æ ·éœ€æ±‚ï¼›
3. **å¤šå˜é‡è”åˆé‡å»º**ï¼šåˆ©ç”¨å…±äº«æ½œåœ¨ç©ºé—´å»ºæ¨¡å¤šç‰©ç†é‡è€¦åˆå…³ç³»ï¼›
4. **å‘å…¶ä»–åœ°çƒç§‘å­¦ä»»åŠ¡è¿ç§»**ï¼š
   - åœŸå£¤æ°´åˆ†ï¼ˆsoil moistureï¼‰
   - åœ°è¡¨æ¸©åº¦ï¼ˆland surface temperatureï¼‰
   - ç§¯é›ªåŠ¨æ€ï¼ˆsnow dynamicsï¼‰
   - æ´ªæ¶åˆ¶å›¾ï¼ˆflood mappingï¼‰
5. **æ·±ç©ºæ¢æµ‹åº”ç”¨**ï¼šåº”ç”¨äºç«æ˜Ÿã€æœˆçƒç­‰åœ°å¤–å¤©ä½“ç›‘æµ‹ï¼Œåœ¨æä½å¸¦å®½ä¸‹å®ç°ç§‘å­¦æ•°æ®å‹ç¼©ä¸é‡å»ºã€‚

---

> ğŸŒ **Impact Statement**ï¼š  
> SENDAIæä¾›äº†ä¸€ä¸ªé€šç”¨æ¨¡æ¿â€”â€”**ä»ä¸°å¯Œå…ˆéªŒä¸­å­¦ä¹ ç©ºé—´å…ˆéªŒ â†’ é€šè¿‡æ½œç©ºé—´å¯¹é½é€‚é…ç¨€ç–ç›®æ ‡ â†’ å¿…è¦æ—¶åˆ†å±‚å‰¥ç¦»é«˜é¢‘ä¿®æ­£**â€”â€”é€‚ç”¨äºä»»ä½•å…·å¤‡å‚è€ƒæ•°æ®ã€ç¨€ç–è§‚æµ‹å’Œå¼‚æ„ç»“æ„çš„ç‰©ç†ç³»ç»Ÿé‡å»ºä»»åŠ¡ã€‚ä»£ç å·²å¼€æºï¼š`github.com/xswzaqnjimko/SENDAI_framework`ã€‚

</details>

---

### 12. [Zonkey: A Hierarchical Diffusion Language Model with Differentiable Tokenization and Probabilistic Attention](https://arxiv.org/abs/2601.21768)

**Authors**: Alon Rozental  
**Category**: cs.CL  
**Published**: 2026-01-30  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2601.21768v1  

#### Abstract
Large language models (LLMs) have revolutionized natural language processing, yet they remain constrained by fixed, non-differentiable tokenizers like Byte Pair Encoding (BPE), which hinder end-to-end optimization and adaptability to noisy or domain-specific data. We introduce Zonkey, a hierarchical...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼š*Zonkey: A Hierarchical Diffusion Language Model with Differentiable Tokenization and Probabilistic Attention*

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### âœ… è§£å†³çš„é—®é¢˜
ä¼ ç»Ÿ **Large Language Models (LLMs)** å—é™äºéå¯å¾®åˆ†ï¼ˆnon-differentiableï¼‰çš„å›ºå®š **tokenizer**ï¼ˆå¦‚ BPEï¼‰ï¼Œå¯¼è‡´ä»¥ä¸‹é—®é¢˜ï¼š
- å‡ºç° **out-of-vocabulary (OOV)** é—®é¢˜ï¼›
- å¯¹å™ªå£°æ–‡æœ¬ã€é¢†åŸŸç‰¹å®šæ•°æ®é€‚åº”èƒ½åŠ›å·®ï¼›
- æ— æ³•åœ¨ç«¯åˆ°ç«¯è®­ç»ƒä¸­ä¼˜åŒ– tokenization è¿‡ç¨‹ï¼›
- æ‰©æ•£æ¨¡å‹ï¼ˆdiffusion modelsï¼‰åœ¨æ–‡æœ¬ç”Ÿæˆä¸­é¢ä¸´ç¦»æ•£ tokenã€è¯­ä¹‰å¤±çœŸå’Œå›ºå®šé•¿åº¦è¾“å‡ºç­‰æŒ‘æˆ˜ã€‚

Zonkey é’ˆå¯¹ä¸Šè¿°ç“¶é¢ˆï¼Œæå‡ºäº†ä¸€ç§**å®Œå…¨å¯å¾®åˆ†ã€å±‚æ¬¡åŒ–çš„æ‰©æ•£è¯­è¨€æ¨¡å‹æ¡†æ¶**ï¼Œä»åŸå§‹å­—ç¬¦å¼€å§‹å®ç°ç«¯åˆ°ç«¯å­¦ä¹ ã€‚

---

### ğŸš€ æå‡ºçš„æ–°æ–¹æ³•ä¸åˆ›æ–°ç‚¹

#### ï¼ˆ1ï¼‰Differentiable Tokenizer: Segment Splitter
- å¼•å…¥ä¸€ä¸ªå¯å­¦ä¹ çš„ **Segment Splitter**ï¼Œé€šè¿‡é¢„æµ‹æ¯ä¸ªä½ç½®çš„ **beginning-of-sequence (BOS) æ¦‚ç‡** æ¥è¿›è¡Œè½¯åˆ†å‰²ï¼›
- åˆ†å‰²è¾¹ç•Œæ— éœ€æ˜¾å¼ç›‘ç£å³å¯è‡ªç„¶æ¶Œç°ä¸ºæœ‰æ„ä¹‰çš„è¯­è¨€å•ä½ï¼ˆå¦‚ç©ºæ ¼å¤„åˆ†è¯ã€å¥å·åæ–­å¥ï¼‰ï¼›
- åˆ©ç”¨ **existence probabilities** å’Œ **existence shares** å®ç°æ¢¯åº¦åå‘ä¼ æ’­ï¼Œä½¿ tokenization æˆä¸ºå¯è®­ç»ƒæ¨¡å—ã€‚

#### ï¼ˆ2ï¼‰Probabilistic Attention
- æå‡ºä¸€ç§æ–°å‹æ³¨æ„åŠ›æœºåˆ¶ï¼Œå°†æ¯ä¸ªä½ç½®èµ‹äºˆä¸€ä¸ªå­˜åœ¨æ¦‚ç‡ $ p_k \in (0,1] $ï¼Œæ¨¡æ‹Ÿæ— é™é•¿åºåˆ—ï¼›
- æ³¨æ„åŠ›å¾—åˆ†é€šè¿‡ $ \log(p_k / p_q) $ è°ƒæ•´ï¼Œä½å­˜åœ¨æ¦‚ç‡çš„ä½ç½®å¯¹é«˜æ¦‚ç‡ä½ç½®å½±å“æå°ï¼Œå½¢æˆâ€œè½¯æˆªæ–­â€ï¼›
- æ”¯æŒå˜é•¿å»ºæ¨¡ä¸”é¿å…äº†ä¼ ç»Ÿç¡¬æ©ç ï¼ˆhard maskingï¼‰å¸¦æ¥çš„æ¢¯åº¦ä¸è¿ç»­é—®é¢˜ã€‚

#### ï¼ˆ3ï¼‰Hierarchical Diffusion with DDMM
- è®¾è®¡ **Denoising Diffusion Mixed Model (DDMM)**ï¼Œç»“åˆ DDPM çš„ç¨³å®šæ€§ä¸ DDIM çš„é«˜æ•ˆæ€§ï¼›
- åœ¨æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œå»å™ªé‡å»ºï¼Œæ”¯æŒä»»æ„é•¿åº¦è¾“å‡ºï¼›
- å¼•å…¥æ··åˆæ­¥é•¿ç›®æ ‡ï¼ˆmixed-step objectiveï¼‰ï¼Œé¼“åŠ±æ¨¡å‹åœ¨æœ‰ä¿¡å¿ƒæ—¶å¤§èƒ†è·³è·ƒï¼Œåœ¨ä¸ç¡®å®šæ—¶è°¨æ…æ¨è¿›ã€‚

#### ï¼ˆ4ï¼‰Differentiable Stitcher
- æ„é€  **Stitcher** æ¨¡å—ç”¨äºæ— ç¼æ‹¼æ¥é‡å æ®µè½ï¼Œä¿æŒè·¨æ®µè¡¨ç¤ºä¸€è‡´æ€§ï¼›
- ä½¿ç”¨ soft offset inference å’Œ constrained cross-attention å®ç°å¯å¾®é‡ç»„ï¼›
- æ”¯æŒé€’å½’å±‚çº§ç»“æ„ï¼ˆlevel-l è¾“å‡ºä½œä¸º level-l+1 è¾“å…¥ï¼‰ï¼Œæ„å»ºæ·±å±‚æŠ½è±¡ã€‚

#### ï¼ˆ5ï¼‰ç«¯åˆ°ç«¯å¯å¾®åˆ†å±‚çº§æ¶æ„
- æ•´ä¸ªæµç¨‹ä»å­—ç¬¦è¾“å…¥ â†’ å±‚çº§å‹ç¼© â†’ æ‰©æ•£å»å™ª â†’ æ‹¼æ¥è¾“å‡ºå…¨éƒ¨å¯å¾®ï¼›
- æ”¯æŒ **variable-length generation**, **non-sequential infilling**, å¹¶å¤©ç„¶é€‚é…é•¿ä¸Šä¸‹æ–‡æ‰©å±•ã€‚

---

### ğŸ” ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| æ–¹é¢ | ä¼ ç»Ÿæ–¹æ³•å±€é™ | Zonkey çš„ä¼˜åŠ¿ |
|------|---------------|----------------|
| **Tokenizer** | å›ºå®šè§„åˆ™ï¼ˆBPEï¼‰ã€ä¸å¯å¾®ã€é™æ€ | å¯å­¦ä¹ ã€è‡ªé€‚åº”ã€ä¸åŒå±‚çº§è‡ªåŠ¨æ¶Œç°è¯/å¥è¾¹ç•Œ |
| **Attention** | Hard masking å¯¼è‡´æ¢¯åº¦æ–­è£‚ | Probabilistic Attention ä¿ç•™æ¢¯åº¦ï¼Œæ”¯æŒè½¯æˆªæ–­ |
| **Generation** | è‡ªå›å½’é€tokenç”Ÿæˆæ…¢ï¼›æ‰©æ•£æ¨¡å‹éš¾å¤„ç†ç¦»æ•£æ€§ | å¹¶è¡Œè§£å‹ + æ½œåœ¨ç©ºé—´æ‰©æ•£ï¼Œæ”¯æŒå¿«é€Ÿé•¿æ–‡æœ¬ç”Ÿæˆ |
| **Infilling** | AR æ¨¡å‹éš¾ä»¥åŒå‘è¡¥å…¨ | å¤©ç„¶æ”¯æŒä»»æ„ä½ç½® infillingï¼ˆå¦‚ä¸­é—´æ®µç¼ºå¤±ï¼‰ |
| **Hierarchy** | å¤šæ•°æ¨¡å‹ä»…å•å±‚æŠ½è±¡ | æ˜¾å¼å¤šçº§å‹ç¼©ï¼ˆchar â†’ word â†’ sentenceï¼‰ |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ğŸ“š æ•°æ®é›†
- **Wikipedia è‹±æ–‡è¯­æ–™**ï¼ˆæ¸…æ´—åçš„å­é›†ï¼‰
- ä»¥åŸå§‹å­—ç¬¦ä¸ºè¾“å…¥ï¼Œä¸ä¾èµ–ä»»ä½•é¢„å®šä¹‰è¯æ±‡è¡¨

### âš™ï¸ å®éªŒè®¾ç½®
- **æ¨¡å‹è§„æ¨¡**ï¼šå°å‹åŸå‹ï¼Œåœ¨ **å•å¼  GPU** ä¸Šè®­ç»ƒï¼ˆèµ„æºå—é™ï¼‰
- **å±‚çº§ç»“æ„**ï¼š
  - Level 0ï¼šå­—ç¬¦ â†’ ç±»ä¼¼â€œè¯â€çš„å‘é‡ï¼ˆmax_seq_len=32ï¼‰
  - Level 1ï¼šç±»è¯å•å…ƒ â†’ ç±»ä¼¼â€œå¥å­â€çš„æŠ½è±¡
- **è®­ç»ƒæ–¹å¼**ï¼šç«¯åˆ°ç«¯è”åˆä¼˜åŒ–ï¼Œé‡‡ç”¨ curriculum learningï¼Œå…ˆç¨³å®šåº•å±‚å†å‘ä¸Šæ„å»º
- **è¾“å…¥å½¢å¼**ï¼šraw characters â†’ character embeddings â†’ Segment Splitter

### ğŸ¯ è¯„ä¼°æŒ‡æ ‡ï¼ˆQualitativeä¸ºä¸»ï¼‰
ç”±äºæ¨¡å‹æ— å›ºå®š vocabularyã€è¾“å‡ºä¸ºè¿ç»­ latent spaceï¼Œæ ‡å‡† token-based æŒ‡æ ‡ï¼ˆå¦‚ perplexityï¼‰ä¸å¯ç›´æ¥åº”ç”¨ï¼Œå› æ­¤ä¸»è¦ä¾èµ–ï¼š
- **å®šæ€§åˆ†æï¼ˆqualitative evaluationï¼‰**ï¼š
  - ç”Ÿæˆæ–‡æœ¬çš„è¿è´¯æ€§ï¼ˆcoherenceï¼‰
  - æ˜¯å¦è‡ªå‘å½¢æˆ word/sentence-level ç»“æ„
  - è‡ªé€‚åº”åˆ†è¯æ˜¯å¦ç¬¦åˆè¯­è¨€ç›´è§‰ï¼ˆå¦‚ç©ºæ ¼/å¥å·å¤„é«˜ BOS æ¦‚ç‡ï¼‰
- **è¾…åŠ©å®šé‡ä¿¡å·**ï¼š
  - MLM accuracyï¼ˆmask predictionï¼‰
  - Reconstruction cosine similarityï¼ˆdenoised vs. ground truthï¼‰
  - Collapse prevention lossï¼ˆlatents åŒºåˆ†åº¦ï¼‰

### ğŸ†š åŸºçº¿æ–¹æ³•å¯¹æ¯”
æœªæä¾›ä¸ä¸»æµ LLMï¼ˆå¦‚ Llamaã€BERTï¼‰çš„é‡åŒ–å¯¹æ¯”ï¼ŒåŸå› åœ¨äºæ¶æ„æ ¹æœ¬å·®å¼‚ã€‚ä½†æ–‡ä¸­æŒ‡å‡ºå…¶ç›¸è¾ƒä»¥ä¸‹æ–¹å‘å…·æœ‰ä¼˜åŠ¿ï¼š
- **BPE-based LLMs**ï¼šç¼ºä¹å¯å¾®åˆ† tokenizer
- **CANINE / ByT5**ï¼šè™½æ“ä½œäºå­—ç¬¦/å­—èŠ‚ï¼Œä½†ä½¿ç”¨å›ºå®šå·ç§¯æˆ– Transformerï¼Œæ— åŠ¨æ€å¯å­¦ä¹ åˆ†æ®µ
- **Byte Latent Transformer (BLT)**ï¼šå¼ºåˆ¶æ¯ patch å…·æœ‰ç›¸åŒ entropyï¼Œç­–ç•¥æ¬¡ä¼˜
- **Hierarchical Diffusion LM (HDLM)**ï¼šé€šå¸¸åŸºäºç¦»æ•£ tokenï¼Œç¼ºä¹å…¨è·¯å¾„å¯å¾®æ€§

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### âœ… å…³é”®æ€§èƒ½è¡¨ç°
å°½ç®¡æ˜¯å°è§„æ¨¡éªŒè¯æ€§å®éªŒï¼ŒZonkey å±•ç°å‡ºä»¥ä¸‹ç§¯æç»“æœï¼š

| æˆæœ | æè¿° |
|------|------|
| **Emergent Hierarchies** | åœ¨æ— ç›‘ç£æƒ…å†µä¸‹ï¼ŒLevel 0 çš„ BOS æ¦‚ç‡åœ¨ç©ºæ ¼åæ˜¾è‘—å‡é«˜ï¼ˆå¯¹åº”å•è¯è¾¹ç•Œï¼‰ï¼›Level 1 åœ¨å¥å·åå‡é«˜ï¼ˆå¯¹åº”å¥å­èµ·å§‹ï¼‰ï¼Œè¡¨æ˜è¯­ä¹‰ç»“æ„è‡ªç„¶æµ®ç° |
| **Coherent Text Generation** | å¯ä»çº¯å™ªå£°ä¸­ç”Ÿæˆè¯­æ³•åˆç†ã€ä¸»é¢˜ä¸€è‡´çš„è‹±æ–‡å¥å­ï¼Œä¾‹å¦‚ï¼š"Quantum computing harnesses quantum mechanics..." |
| **Adaptive Tokenization** | åˆ†å‰²è¡Œä¸ºéšä¸Šä¸‹æ–‡è°ƒæ•´ï¼Œä¼˜äºå›ºå®šçª—å£æˆ–ç­‰ç†µåˆ’åˆ†ç­–ç•¥ |
| **Effective Infilling** | æˆåŠŸå®Œæˆéè¿ç»­æ–‡æœ¬è¡¥å…¨ä»»åŠ¡ï¼Œå¦‚ç»™å®šå‰ç¼€ `"Bob is a"` å’Œåç¼€ `"player in the NBA"`ï¼Œæ­£ç¡®è¡¥å…¨ä¸º `"basketball"` |

### ğŸ”¬ æ¶ˆèå®éªŒï¼ˆAblation Studiesï¼‰
è™½ç„¶æ²¡æœ‰ç‹¬ç«‹è¡¨æ ¼åˆ—å‡ºæ¶ˆèç»“æœï¼Œä½†åœ¨æ­£æ–‡ä¸­éšå«å¤šä¸ªæ§åˆ¶å˜é‡åˆ†æï¼š
- **Existence Shares çš„ä½œç”¨**ï¼šé˜²æ­¢ Splitter å°† BOS é›†ä¸­åœ¨ç®€å•åŒºåŸŸè€Œå¿½ç•¥å¤æ‚éƒ¨åˆ†ï¼Œç¡®ä¿å‡åŒ€ç›‘ç£ï¼›
- **MLM Loss çš„å¿…è¦æ€§**ï¼šå»é™¤åè¯­ä¹‰èšç±»å‡å¼±ï¼Œå‹ç¼©å‘é‡åŒºåˆ†åº¦ä¸‹é™ï¼›
- **Mixed-step Objective**ï¼šæå‡ DDMM çš„é²æ£’æ€§å’Œæ”¶æ•›é€Ÿåº¦ï¼Œå‡å°‘æ¨¡å¼å´©æºƒé£é™©ï¼›
- **Probabilistic Attention vs. Hard Masking**ï¼šå‰è€…è®­ç»ƒæ›´ç¨³å®šï¼Œå°¤å…¶åœ¨ä½å­˜åœ¨æ¦‚ç‡åŒºåŸŸä»èƒ½ä¼ é€’æœ‰æ•ˆæ¢¯åº¦ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### âœ… ä¸»è¦å‘ç°
1. **å®Œå…¨å¯å¾®åˆ†çš„è¯­è¨€æ¨¡å‹æ˜¯å¯è¡Œçš„**ï¼šZonkey éªŒè¯äº†ä»å­—ç¬¦åˆ°æ–‡æ¡£çº§è¡¨ç¤ºçš„æ•´ä¸ª pipeline å¯ä»¥å®ç°ç«¯åˆ°ç«¯è®­ç»ƒã€‚
2. **è¯­è¨€ç»“æ„å¯ä»¥æ— ç›‘ç£åœ°è‡ªç»„ç»‡å‡ºç°**ï¼šæ— éœ€æ ‡æ³¨ï¼Œæ¨¡å‹è‡ªå‘å­¦ä¼šåœ¨ç©ºæ ¼ã€å¥å·ç­‰ä½ç½®è¿›è¡Œåˆ†å‰²ï¼Œè¯´æ˜æŸå¤±å‡½æ•°æœ¬èº«è¶³ä»¥é©±åŠ¨è¯­ä¹‰è¾¹ç•Œå­¦ä¹ ã€‚
3. **Probabilistic Attention æ˜¯æ ¸å¿ƒæŠ€æœ¯æ”¯æŸ±**ï¼šå®ƒä¸ä»…è§£å†³äº†å˜é•¿å»ºæ¨¡é—®é¢˜ï¼Œè¿˜ä½¿å¾— Splitterã€Compressorã€Denoiser ä¹‹é—´çš„æ¢¯åº¦æµåŠ¨æˆä¸ºå¯èƒ½ã€‚
4. **æ‰©æ•£æœºåˆ¶é€‚ç”¨äºå±‚çº§åŒ–æ–‡æœ¬ç”Ÿæˆ**ï¼šDDMM åœ¨ latent space ä¸­å®ç°äº†é«˜è´¨é‡é‡å»ºï¼Œå¹¶æ”¯æŒçµæ´»çš„ç”Ÿæˆæ¨¡å¼ï¼ˆå¦‚ infillingï¼‰ã€‚
5. **å¹¶è¡Œç”Ÿæˆæ½œåŠ›å·¨å¤§**ï¼šç›¸æ¯”è‡ªå›å½’æ¨¡å‹ï¼ŒZonkey åœ¨é«˜å±‚çº§å¯å¹¶è¡Œå¤„ç†å¤šä¸ª segmentï¼Œå…·å¤‡è‰¯å¥½çš„ scalability å‰æ™¯ã€‚

---

### âš ï¸ æ–¹æ³•çš„å±€é™æ€§
1. **å½“å‰ä»…ä¸º proof-of-concept**ï¼šä»…åœ¨å•å¡ä¸Šè®­ç»ƒï¼Œåœç•™åœ¨ sentence-level ç”Ÿæˆï¼Œå°šæœªè¾¾åˆ° paragraph æˆ– document çº§åˆ«ï¼›
2. **ç¼ºä¹æ ‡å‡†åŒ– benchmark å¯¹æ¯”**ï¼šå› æ¶æ„ç‰¹æ®Šï¼Œæ— æ³•ç›´æ¥æ¯”è¾ƒ BLEUã€PPL ç­‰é€šç”¨æŒ‡æ ‡ï¼›
3. **è®¡ç®—å¼€é”€è¾ƒé«˜**ï¼šé‡å  segment + å¤šå±‚å‹ç¼©å¸¦æ¥å†—ä½™è®¡ç®—ï¼Œéœ€è¿›ä¸€æ­¥ä¼˜åŒ–æ•ˆç‡ï¼›
4. **ç”Ÿæˆè´¨é‡ä»æœ‰æå‡ç©ºé—´**ï¼šä¸ªåˆ«ç”Ÿæˆå¥å­å­˜åœ¨è½»å¾®è¯­ä¹‰åå·®æˆ–é‡å¤ç°è±¡ï¼›
5. **æœªæ¢ç´¢å¤§è§„æ¨¡é¢„è®­ç»ƒæ•ˆæœ**ï¼šå°šä¸æ¸…æ¥šåœ¨æ›´å¤§æ•°æ®å’Œç®—åŠ›ä¸‹èƒ½å¦è¶…è¶Šä¸»æµ LLMã€‚

---

### ğŸ”® æœªæ¥å·¥ä½œæ–¹å‘
1. **Scaling Up**ï¼š
   - æ‰©å±•è‡³æ›´æ·±çš„ hierarchyï¼ˆå¦‚ level 2 è¡¨ç¤ºæ®µè½ï¼Œlevel 3 è¡¨ç¤ºç¯‡ç« ï¼‰ï¼›
   - ä½¿ç”¨æ›´å¤§ datasetï¼ˆå¦‚ Common Crawlï¼‰å’Œåˆ†å¸ƒå¼è®­ç»ƒã€‚
2. **Quantitative Evaluation Framework**ï¼š
   - å¼€å‘é€‚ç”¨äº continuous latent space å’Œ variable-length output çš„æ–°è¯„ä¼°åè®®ï¼›
   - æ¢ç´¢ human evaluationã€reconstruction fidelityã€domain adaptation benchmarksã€‚
3. **åŠ é€Ÿæ¨ç†æœºåˆ¶**ï¼š
   - å¼•å…¥ early-exit ç­–ç•¥æˆ– adaptive diffusion steps ä»¥å‡å°‘ inference æ—¶é—´ï¼›
   - ä¼˜åŒ– Stitcher ä¸ Compressor çš„è½»é‡åŒ–è®¾è®¡ã€‚
4. **ä¸‹æ¸¸ä»»åŠ¡è¿ç§»**ï¼š
   - å°† learned hierarchical representations åº”ç”¨äº classificationã€summarizationã€retrieval ç­‰ä»»åŠ¡ã€‚
5. **ç†è®ºåˆ†æ**ï¼š
   - å½¢å¼åŒ–è¯æ˜ existence probability decay ä¸è¯­è¨€ç»“æ„ emergence çš„å…³ç³»ï¼›
   - åˆ†æ Splitter å­¦ä¹ åˆ°çš„è¾¹ç•Œæ˜¯å¦æ»¡è¶³ä¿¡æ¯è®ºæœ€ä¼˜æ€§ï¼ˆå¦‚æœ€å°æè¿°é•¿åº¦åŸåˆ™ï¼‰ã€‚

---

## æ€»ç»“

> **Zonkey æå‡ºäº†ä¸€ç§å…¨æ–°çš„ã€å…¨å¯å¾®åˆ†çš„å±‚çº§æ‰©æ•£è¯­è¨€æ¨¡å‹èŒƒå¼ï¼Œæ‰“ç ´äº†ä¼ ç»Ÿ LLM å¯¹å›ºå®š tokenizer å’Œè‡ªå›å½’ç”Ÿæˆçš„ä¾èµ–ã€‚å®ƒé€šè¿‡ Segment Splitterã€Probabilistic Attentionã€DDMM å’Œ Stitcher å››å¤§æ ¸å¿ƒç»„ä»¶ï¼Œå®ç°äº†ä»å­—ç¬¦åˆ°è¯­ä¹‰å•å…ƒçš„ç«¯åˆ°ç«¯å­¦ä¹ ï¼Œåœ¨å°è§„æ¨¡å®éªŒä¸­å·²å±•ç°å‡ºç”Ÿæˆè¿è´¯æ–‡æœ¬ã€è‡ªç»„ç»‡è¯­è¨€ç»“æ„å’Œçµæ´» infilling çš„èƒ½åŠ›ã€‚è™½ç„¶ç›®å‰ä»æ˜¯æ¦‚å¿µéªŒè¯é˜¶æ®µï¼Œä½†å®ƒä¸ºä¸‹ä¸€ä»£çœŸæ­£â€œgradient-basedâ€çš„è¯­è¨€æ¨¡å‹æä¾›äº†é‡è¦è·¯å¾„ã€‚**

å¼€æºåœ°å€ï¼š[https://github.com/ARozental/Zonkey](https://github.com/ARozental/Zonkey)

</details>

---

### 13. [Heterogeneous Vertiport Selection Optimization for On-Demand Air Taxi Services: A Deep Reinforcement Learning Approach](https://arxiv.org/abs/2601.21316)

**Authors**: Aoyu Pang, Maonan Wang, Zifan Sha, Wenwei Yue, Changle Li, Chung Shue Chen, Man-On Pun  
**Category**: cs.LG  
**Published**: 2026-01-30  
**Score**: 9.5  
**Type**: new  
**ArXiv ID**: 2601.21316v1  

#### Abstract
Urban Air Mobility (UAM) has emerged as a transformative solution to alleviate urban congestion by utilizing low-altitude airspace, thereby reducing pressure on ground transportation networks. To enable truly efficient and seamless door-to-door travel experiences, UAM requires close integration with...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šHeterogeneous Vertiport Selection Optimization for On-Demand Air Taxi Services: A Deep Reinforcement Learning Approach

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
æœ¬æ–‡é’ˆå¯¹**æŒ‰éœ€ç©ºä¸­å‡ºç§Ÿè½¦æœåŠ¡ä¸­çš„å¤šæ¨¡å¼å‡ºè¡Œæ•ˆç‡ç“¶é¢ˆ**ï¼Œç‰¹åˆ«æ˜¯**åœ°é¢ä¸ç©ºä¸­äº¤é€šååŒä¸è¶³å¯¼è‡´çš„æ•´ä½“æ—…è¡Œæ—¶é—´è¿‡é•¿**çš„é—®é¢˜ã€‚å…·ä½“èšç„¦äºï¼š
- **å¼‚æ„ vertiport ç³»ç»Ÿä¸­ä¹˜å®¢é€‰æ‹©å‡ºå‘/åˆ°è¾¾ vertiport çš„ä¼˜åŒ–éš¾é¢˜**ï¼›
- ä¼ ç»Ÿæ–¹æ³•æ— æ³•åŠ¨æ€é€‚åº”å®æ—¶äº¤é€šçŠ¶æ€ã€æ’é˜Ÿå»¶è¿Ÿå’Œèµ„æºä¸å‡ç­‰å¤æ‚å› ç´ ï¼›
- ç¼ºä¹ç»Ÿä¸€çš„ç«¯åˆ°ç«¯ï¼ˆdoor-to-doorï¼‰ç­–ç•¥è§„åˆ’æ¡†æ¶ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ–°æ€è·¯
ä½œè€…æå‡ºäº†ä¸€ä¸ªåä¸º **Unified Air-Ground Mobility Coordination (UAGMC)** çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

- **é¦–æ¬¡å°† air taxi ä¸ ground transportation çš„ç­–ç•¥è§„åˆ’è¿›è¡Œç»Ÿä¸€å»ºæ¨¡**ï¼Œæ„å»ºäº†ä¸€ä¸ªå®Œæ•´çš„ MDPï¼ˆMarkov Decision Processï¼‰æ¨¡å‹ï¼Œæ¶µç›–ä»èµ·ç‚¹åˆ°ç»ˆç‚¹çš„å››ä¸ªé˜¶æ®µï¼šåœ°é¢æ¥é©³ â†’ å‡ºå‘ vertiport æ’é˜Ÿ â†’ ç©ºä¸­é£è¡Œ â†’ ç»ˆç‚¹åœ°é¢é€è¾¾ã€‚
  
- è®¾è®¡äº†ä¸¤ä¸ªå…³é”®æ¨¡å—ä»¥å¤„ç†é«˜ç»´å¼‚æ„ä¿¡æ¯ï¼š
  - **Multi-Source Contextual Embedding (MSCE)**ï¼šå¯¹æ¥è‡ª V2X ç½‘ç»œçš„å¤šæºå¼‚æ„æ•°æ®ï¼ˆå¦‚ OD è¯·æ±‚ã€åœ°é¢é€Ÿåº¦ã€æ’é˜Ÿé•¿åº¦ã€eVTOL çŠ¶æ€ç­‰ï¼‰è¿›è¡Œç»“æ„åŒ–ç¼–ç ã€‚
  - **Spatio-Temporal Integration Network (STIN)**ï¼šåŸºäº Transformer æ¶æ„èåˆæ—¶ç©ºä¾èµ–å…³ç³»ï¼Œæå–å…¨å±€ä¸Šä¸‹æ–‡ç‰¹å¾ï¼Œæå‡æ¨¡å‹å¯¹åŠ¨æ€ç³»ç»Ÿæ¼”åŒ–çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚

- é‡‡ç”¨ **PPOï¼ˆProximal Policy Optimizationï¼‰** ä½œä¸º Actor-Critic æ¡†æ¶çš„åŸºç¡€ç®—æ³•ï¼Œå¹¶è®¾è®¡å¢é‡å¥–åŠ±æœºåˆ¶è§£å†³ç¨€ç–å¥–åŠ±ï¼ˆsparse rewardï¼‰é—®é¢˜ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
- **åŠ¨æ€é€‚åº”æ€§å¼º**ï¼šç›¸æ¯”é™æ€è§„åˆ™æˆ–å¯å‘å¼æ–¹æ³•ï¼ŒUAGMC èƒ½æ ¹æ®å®æ—¶äº¤é€šã€æ’é˜Ÿå’Œè½¦è¾†å¯ç”¨æ€§åšå‡ºå“åº”å¼å†³ç­–ã€‚
- **è”åˆä¼˜åŒ–èƒ½åŠ›**ï¼šåŒæ—¶è€ƒè™‘åœ°é¢è¡Œç¨‹æ—¶é—´å’Œ vertiport æ’é˜Ÿç­‰å¾…æ—¶é—´ï¼Œé¿å…â€œå°±è¿‘é€‰æ‹©â€å¸¦æ¥çš„å±€éƒ¨æ‹¥å µã€‚
- **å¯æ‰©å±•æ€§å¥½**ï¼šé€šè¿‡æ·±åº¦ç¥ç»ç½‘ç»œè‡ªåŠ¨å­¦ä¹ å¤æ‚æ¨¡å¼ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡ã€é«˜ç»´åº¦çš„åŸå¸‚äº¤é€šåœºæ™¯ã€‚

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†ä¸ä»¿çœŸç¯å¢ƒ
- ä½¿ç”¨**è‡ªå®šä¹‰æ¨¡æ‹Ÿå™¨**ï¼ˆåŸºäº prior studies [35,66â€“69] å¼€å‘ï¼‰ï¼Œæœªä½¿ç”¨çœŸå®ä¸–ç•Œå…¬å¼€æ•°æ®é›†ã€‚
- æ¨¡æ‹ŸåŸå¸‚åœ°å›¾ä¸º `30km Ã— 30km`ï¼Œéƒ¨ç½²ä¸‰ä¸ª vertiportï¼š
  - **Vertiport 0**ï¼šéƒŠåŒº/æœºåœºåŒºåŸŸï¼ˆå®¹é‡å¤§ã€å……ç”µå¿«ï¼‰
  - **Vertiport 1**ï¼šå¸‚ä¸­å¿ƒæ ¸å¿ƒåŒºï¼ˆå®¹é‡å°ã€å……ç”µæ…¢ï¼‰
  - **Vertiport 2**ï¼šçº¯é™è½ç‚¹ï¼ˆæ— æ’é˜Ÿï¼‰
- å®¢æµç”Ÿæˆéµå¾ªç°å®åˆ†å¸ƒï¼ŒO-Dè·ç¦»èŒƒå›´ä¸º 42â€“48 kmï¼Œæ¯æ­¥æ–°å¢ 1 åä¹˜å®¢ã€‚

### å®éªŒè®¾ç½®
- **eVTOL å‚æ•°**ï¼š
  - å·¡èˆªé€Ÿåº¦ï¼š120 km/h
  - åº§ä½æ•°ï¼š3 æˆ– 4 äºº
  - éœ€æ»¡å‘˜èµ·é£ï¼Œè½åœ°åå¿…é¡»å®Œæˆå……ç”µæ‰èƒ½å†æ¬¡è°ƒåº¦
- **åœ°é¢äº¤é€šæ¨¡å‹**ï¼šé‡‡ç”¨ Greenberg æµé‡æ¨¡å‹è®¡ç®—å¹³å‡è½¦é€Ÿ
- **è®­ç»ƒå‚æ•°**ï¼š
  - RLæŠ˜æ‰£å› å­ Î³ = 0.99
  - PPOå‰ªè£èŒƒå›´ Îµ = 0.2
  - çŠ¶æ€åºåˆ—é•¿åº¦ K = 6

### è¯„ä¼°æŒ‡æ ‡
| æŒ‡æ ‡ | å«ä¹‰ |
|------|------|
| **ATT** (Average Total Travel Time) | æ€»å¹³å‡æ—…è¡Œæ—¶é—´ï¼ˆå«æ‰€æœ‰é˜¶æ®µï¼‰ |
| **AET** (Average Effective Travel Time) | å»é™¤ç­‰å¾…æ—¶é—´çš„æœ‰æ•ˆç§»åŠ¨æ—¶é—´ |
| **AWT** (Average Waiting Time) | åœ¨å‡ºå‘ vertiport çš„å¹³å‡æ’é˜Ÿæ—¶é—´ |
| **AGT** (Average Ground Travel Time) | åœ°é¢æ®µæ€»æ—¶é—´ï¼ˆå»ç¨‹+è¿”ç¨‹ï¼‰ |
| **AAT** (Average Air Taxi Travel Time) | ç©ºä¸­é£è¡Œæ—¶é—´ |
| **RPV-0 / RPV-1** | åˆ†é…è‡³ Vertiport 0 å’Œ 1 çš„ä¹˜å®¢æ¯”ä¾‹ |

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
å…±æ¯”è¾ƒä¸ƒç§æ–¹æ³•ï¼š
1. **Ground**ï¼šä»…ä½¿ç”¨ CAV åœ°é¢å‡ºè¡Œ
2. **SPF**ï¼ˆShortest Physical Firstï¼‰ï¼šé€‰æ‹©ç‰©ç†è·ç¦»æœ€è¿‘çš„ vertiport
3. **Rule-Based**ï¼šæŒ‰é¢„è®¾æœåŠ¡ç‡åˆ†é…
4. **STTF**ï¼ˆShortest Time to Facilityï¼‰ï¼šåŸºäºä¼°è®¡åœ°é¢æ—¶é—´é€‰æ‹©
5. **QTTI**ï¼ˆQueue Time and Travel Integrationï¼‰ï¼šç»¼åˆæ’é˜Ÿä¸è¡Œé©¶æ—¶é—´çš„æˆæœ¬å‡½æ•°
6. **Vanilla-PPO**ï¼šæ ‡å‡† PPOï¼Œç®€å•æ‹¼æ¥çŠ¶æ€è¾“å…¥
7. **UAGMC-L**ï¼šUAGMC çš„ LSTM ç‰ˆæœ¬ï¼ˆSTIN æ›¿æ¢ä¸º LSTMï¼‰
8. **UAGMC-A**ï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•ï¼ˆSTIN ä½¿ç”¨ Attentionï¼‰

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆè§ Table 3ï¼‰
| æ–¹æ³• | ATT (min) | AWT (min) | AGT (min) | AAT (min) |
|------|-----------|-----------|-----------|-----------|
| SPF | 133.65 | 106.53 | 5.93 | 21.18 |
| Rule-Based | 62.30 | 32.34 | 7.95 | 22.01 |
| STTF | 52.39 | 22.13 | 8.04 | 22.22 |
| QTTI | 51.87 | 22.44 | 7.23 | 22.20 |
| Vanilla-PPO | 57.47 | 27.17 | 8.12 | 22.19 |
| **UAGMC-L** | **48.69** | **17.97** | 8.51 | 22.21 |
| **UAGMC-A** | **46.63** | **15.48** | 8.83 | 22.32 |

> âœ… **UAGMC-A å°† ATT é™è‡³ 46.63 åˆ†é’Ÿï¼Œç›¸æ¯” QTTI æå‡çº¦ 10%ï¼Œç›¸æ¯” SPF æå‡é«˜è¾¾ 65%**

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **æ˜¾è‘—ä¼˜äºæ‰€æœ‰è§„åˆ™ç±»æ–¹æ³•**ï¼ˆSPFã€STTFã€QTTIï¼‰ï¼Œå°¤å…¶æ˜¯åœ¨é«˜éœ€æ±‚ä¸‹ä»èƒ½ä¿æŒä½ç­‰å¾…æ—¶é—´ã€‚
- **ä¼˜äº Vanilla-PPO**ï¼šè¯´æ˜ç®€å•çš„ RL æ¡†æ¶éš¾ä»¥æ•æ‰å¤æ‚çš„æ—¶ç©ºä¾èµ–ï¼Œè€Œ MSCE + STIN æ˜¾è‘—æå‡äº†è¡¨ç°ã€‚
- **UAGMC-A > UAGMC-L**ï¼šè¡¨æ˜åŸºäº Attention çš„ STIN æ¯” LSTM æ›´é€‚åˆå»ºæ¨¡é•¿æœŸæ—¶ç©ºä¾èµ–ï¼Œåœ¨ ATT ä¸Šè¿›ä¸€æ­¥é™ä½ 4.3%ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆTable 4ï¼‰
| æ¨¡å—ç»„åˆ | ATT (min) | AWT (min) | æ”¹è¿›å¹…åº¦ï¼ˆvs baselineï¼‰ |
|--------|----------|-----------|-----------------------|
| æ—  MSCE & æ—  STIN | 63.07 | 32.82 | â€” |
| æœ‰ MSCE | 60.57 | 30.08 | ATT â†“4.0%, AWT â†“8.2% |
| æœ‰ STIN | 56.31 | 25.57 | ATT â†“10.8%, AWT â†“22.0% |
| **MSCE + STIN (å®Œæ•´ç‰ˆ)** | **46.63** | **15.48** | **ATT â†“26.1%, AWT â†“52.7%** |

> ğŸ” ç»“æœè¯æ˜ï¼š**MSCE å’Œ STIN ååŒä½œç”¨è‡³å…³é‡è¦**ï¼Œå•ç‹¬ä½¿ç”¨ä»»ä¸€æ¨¡å—å·²æœ‰æ˜æ˜¾å¢ç›Šï¼Œè”åˆä½¿ç”¨å®ç°æœ€å¤§æ€§èƒ½çªç ´ã€‚

### å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼ˆTable 5ï¼‰
- å½“ä¹˜å®¢æ•°é‡ä» 100 å¢åŠ åˆ° 300 æ—¶ï¼Œ**AWT æ˜¾è‘—ä¸Šå‡**ï¼Œä½†åœ¨ eVTOL å®¹é‡ä» 3 æ‰©å±•åˆ° 4 åï¼Œ**ç³»ç»ŸæŠ—å‹èƒ½åŠ›å¤§å¹…æå‡**ï¼ŒATT åŸºæœ¬ç¨³å®šã€‚
- è¡¨æ˜ UAGMC-A åœ¨ä¸åŒè´Ÿè½½æ¡ä»¶ä¸‹å…·æœ‰è‰¯å¥½çš„é²æ£’æ€§å’Œè‡ªé€‚åº”è°ƒåº¦èƒ½åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **vertiport é€‰æ‹©æ˜¯å½±å“æ•´ä½“æ•ˆç‡çš„å…³é”®å› ç´ **ï¼Œå•çº¯è¿½æ±‚â€œæœ€è¿‘â€ä¼šåŠ å‰§æ’é˜Ÿæ‹¥å µï¼Œåè€Œå»¶é•¿æ€»è¡Œç¨‹æ—¶é—´ã€‚
2. **ç­‰å¾…æ—¶é—´æ˜¯ä¸»è¦ç“¶é¢ˆ**ï¼Œå  ATT çš„çº¦ 31%ï¼ˆUAGMC-A ä¸­ä¸º 15.5 minï¼‰ï¼Œå› æ­¤ä¼˜åŒ–æ’é˜Ÿç®¡ç†è‡³å…³é‡è¦ã€‚
3. **æ·±åº¦ RL å¯æœ‰æ•ˆåº”å¯¹å¼‚æ„ã€åŠ¨æ€ã€é«˜ç»´çš„å¤šæ¨¡å¼äº¤é€šç³»ç»Ÿè°ƒåº¦é—®é¢˜**ï¼Œå°¤å…¶åœ¨ç»“åˆæ—¶ç©ºå»ºæ¨¡åæ•ˆæœæ˜¾è‘—ã€‚
4. **UAGMC å®ç°äº† 34% çš„å¹³å‡æ—…è¡Œæ—¶é—´å‡å°‘**ï¼ˆç›¸å¯¹äºä¼ ç»Ÿ proportional allocation æ–¹æ³•ï¼‰ï¼ŒéªŒè¯äº†å…¶åœ¨æå‡ UAM ç³»ç»Ÿæ•ˆç‡æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚

### æ–¹æ³•çš„å±€é™æ€§
- å½“å‰å‡è®¾**é™è½ vertiport å›ºå®šä¸ºç¦»ç›®çš„åœ°æœ€è¿‘çš„ä¸€ä¸ª**ï¼Œæœªä¼˜åŒ– landing-side å†³ç­–ã€‚
- å¿½ç•¥äº† **airspace å†²çªç®¡ç†ã€èˆªçº¿è§„åˆ’å†²çªã€é€šä¿¡å»¶è¿Ÿ**ç­‰å®é™…è¿è¡Œçº¦æŸã€‚
- æ¨¡æ‹Ÿç¯å¢ƒä¸­æœªå¼•å…¥å¤©æ°”ã€çªå‘äº‹ä»¶æˆ–äººä¸ºå¹²æ‰°å› ç´ ã€‚
- å°šæœªåœ¨çœŸå®åŸå¸‚ç¯å¢ƒä¸­éƒ¨ç½²æµ‹è¯•ï¼Œæ³›åŒ–èƒ½åŠ›æœ‰å¾…éªŒè¯ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
- å¼•å…¥ **multi-agent RL** å®ç°å¤šä¸ª eVTOL çš„ååŒè·¯å¾„è§„åˆ’ä¸å†²çªè§„é¿ã€‚
- æ‰©å±•ä¸º **end-to-end mission scheduling**ï¼Œè¦†ç›–èµ·é£ã€å·¡èˆªã€é™è½ã€å……ç”µå…¨è¿‡ç¨‹ã€‚
- èåˆæ›´ç²¾ç»†çš„ **air traffic management (ATM)** æ¨¡å‹ï¼Œæ”¯æŒé«˜å¯†åº¦ UAM è¿è¥ã€‚
- åŠ å…¥ **communication constraints** å’Œ **delay modeling**ï¼Œå¢å¼ºç³»ç»Ÿçš„å®ç”¨æ€§ä¸å¯é æ€§ã€‚
- æ¢ç´¢ä¸ **MaaS å¹³å°é›†æˆ**ï¼Œå®ç°ä¸ªæ€§åŒ–å‡ºè¡Œæ¨èä¸å…¬å¹³æ€§æƒè¡¡ã€‚

---

> ğŸ“Œ **æ€»ç»“ä¸€å¥è¯**ï¼š  
> æœ¬æ–‡æå‡ºçš„ **UAGMC æ¡†æ¶**é€šè¿‡æ·±åº¦èåˆ V2X å¤šæºä¿¡æ¯ä¸æ—¶ç©ºå»ºæ¨¡ï¼Œåˆ©ç”¨ DRL å®ç°äº†å¯¹å¼‚æ„ vertiport ç³»ç»Ÿçš„é«˜æ•ˆè°ƒåº¦ï¼Œåœ¨ä»¿çœŸä¸­å®ç°äº† **34% çš„æ—…è¡Œæ—¶é—´ç¼©å‡**ï¼Œä¸ºæœªæ¥æ™ºèƒ½åŸå¸‚ç©ºåœ°ä¸€ä½“åŒ–å‡ºè¡Œæä¾›äº†é‡è¦æŠ€æœ¯è·¯å¾„ã€‚

</details>

---

### 14. [PathWise: Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs](https://arxiv.org/abs/2601.20539)

**Authors**: Oguzhan Gungordu, Siheng Xiong, Faramarz Fekri  
**Category**: cs.AI  
**Published**: 2026-01-30  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.20539v2  

#### Abstract
Large Language Models (LLMs) have enabled automated heuristic design (AHD) for combinatorial optimization problems (COPs), but existing frameworks' reliance on fixed evolutionary rules and static prompt templates often leads to myopic heuristic generation, redundant evaluations, and limited reasonin...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡æ€»ç»“ï¼šPathWise: Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³çš„é—®é¢˜
ç°æœ‰çš„åŸºäº **Large Language Models (LLMs)** çš„ **Automated Heuristic Design (AHD)** æ–¹æ³•åœ¨ç»„åˆä¼˜åŒ–é—®é¢˜ï¼ˆCombinatorial Optimization Problems, COPsï¼‰ä¸­å­˜åœ¨ä»¥ä¸‹å±€é™ï¼š
- **ä¾èµ–å›ºå®šçš„è¿›åŒ–è§„åˆ™** å’Œé™æ€æç¤ºæ¨¡æ¿ï¼Œå¯¼è‡´ç”Ÿæˆçš„å¯å‘å¼ç®—æ³•çŸ­è§†ï¼ˆmyopicï¼‰ï¼Œç¼ºä¹é•¿æœŸè§„åˆ’èƒ½åŠ›ã€‚
- **ç¼ºä¹çŠ¶æ€è®°å¿†æœºåˆ¶**ï¼Œæ— æ³•æœ‰æ•ˆè®°å½•å¯å‘å¼çš„æ¨å¯¼å†å²å’Œæ¼”åŒ–è·¯å¾„ï¼Œå¯¼è‡´é‡å¤è¯„ä¼°ã€å†—ä½™æœç´¢ã€‚
- **æ¢ç´¢æ•ˆç‡ä½**ï¼Œéš¾ä»¥åŒºåˆ†ä¸åŒå¯å‘å¼å˜æ¢ä¹‹é—´çš„è¯­ä¹‰å·®å¼‚ï¼Œè¿‡åº¦ä¾èµ–ç»Ÿè®¡è®¿é—®é¢‘ç‡è€Œéè¯­ä¹‰ç†è§£ã€‚

### æå‡ºçš„æ–°æ–¹æ³•ä¸æ€è·¯
ä½œè€…æå‡º **PathWise**ï¼Œä¸€ç§åŸºäº **World Model** çš„å¤šæ™ºèƒ½ä½“æ¨ç†æ¡†æ¶ï¼Œå°†å¯å‘å¼è®¾è®¡å»ºæ¨¡ä¸ºä¸€ä¸ª**çŠ¶æ€æ„ŸçŸ¥çš„åºåˆ—å†³ç­–è¿‡ç¨‹**ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ï¼š

#### ï¼ˆ1ï¼‰å¼•å…¥ **Entailment Graph** ä½œä¸ºçŠ¶æ€åŒ–è®°å¿†
- å°†å¯å‘å¼ç”Ÿæˆè¿‡ç¨‹å½¢å¼åŒ–ä¸ºä¸€ä¸ª **Markov Decision Process (MDP)**ã€‚
- ä½¿ç”¨ **Entailment Graph** ç¼–ç æ¯ä¸ªå¯å‘å¼çš„æ¨å¯¼é€»è¾‘ï¼ˆDerivation Rationaleï¼‰ã€çˆ¶èŠ‚ç‚¹ä¿¡æ¯ã€æ€§èƒ½å†å²ç­‰ï¼Œå½¢æˆç´§å‡‘ä¸”æœ‰çŠ¶æ€çš„æœç´¢è½¨è¿¹è¡¨ç¤ºã€‚
- æ”¯æŒè·¨ä»£çš„ä¿¡æ¯å¤ç”¨ä¸é¿å…ï¼Œæå‡æœç´¢æ•ˆç‡ã€‚

#### ï¼ˆ2ï¼‰å¤šæ™ºèƒ½ä½“ååŒæ¶æ„
- **Policy Agent**ï¼šè´Ÿè´£é«˜å±‚ç­–ç•¥è§„åˆ’ï¼Œé€‰æ‹©çˆ¶å¯å‘å¼å¹¶ç”Ÿæˆè‡ªç„¶è¯­è¨€å½¢å¼çš„â€œè¡ç”ŸæŒ‡ä»¤â€ï¼ˆDerivation Rationaleï¼‰ï¼ŒåŠ¨æ€å®šä¹‰å¦‚ä½•ç»„åˆæˆ–ä¿®æ”¹å¯å‘å¼ã€‚
- **World Model Agent**ï¼šæ‰§è¡Œå…·ä½“ä»£ç ç”Ÿæˆï¼Œæ ¹æ® Policy çš„æŒ‡ä»¤ç”Ÿæˆæ–°çš„å¯å‘å¼å‡½æ•°ã€‚
- **Critic Agents**ï¼ˆåŒæ‰¹è¯„è€…ï¼‰ï¼š
  - **Policy Critic**ï¼šåˆ†æä¸åŒç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼Œæä¾›è·¯ç”±åé¦ˆä»¥æ”¹è¿›çˆ¶èŠ‚ç‚¹é€‰æ‹©å’ŒæŒ‡ä»¤è®¾è®¡ã€‚
  - **World Model Critic**ï¼šé€šè¿‡å¯¹æ¯”æœ€ä¼˜ä¸æœ€å·®ç”Ÿæˆç»“æœï¼Œæç‚¼ä»£ç çº§æ”¹è¿›å»ºè®®ï¼ˆå¦‚ç®€åŒ–ç»“æ„ã€å‡å°‘å¤æ‚åº¦ï¼‰ã€‚

è¯¥è®¾è®¡å®ç°äº†ä»â€œè¯•é”™å¼è¿›åŒ–â€åˆ°â€œçŠ¶æ€æ„ŸçŸ¥è§„åˆ’â€çš„è½¬å˜ã€‚

#### ï¼ˆ3ï¼‰Prompt-Level å¤šæ ·æ€§æœºåˆ¶
- **Prompt Perturbation**ï¼šå¼•å…¥éšæ—¶é—´è¡°å‡çš„æ¢ç´¢ç‡ $ \epsilon(l) $ï¼Œéšæœºæ³¨å…¥æ¢ç´¢æ€§çŸ­è¯­ï¼ˆå¦‚â€œå°è¯•éæ ‡å‡†èåˆæ–¹å¼â€ï¼‰ï¼Œé¼“åŠ±æ—©æœŸå¤šæ ·åŒ–æ¢ç´¢ã€‚
- **State Shuffling**ï¼šéšæœºæ‰“ä¹±è¾“å…¥ä¸Šä¸‹æ–‡ä¸­èŠ‚ç‚¹é¡ºåºï¼Œç¼“è§£ LLM å¯¹ä½ç½®åå¥½çš„åå·®ï¼ˆpositional biasï¼‰ã€‚

---

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿
| ç»´åº¦ | ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚ FunSearch, MCTS-AHDï¼‰ | PathWise |
|------|-------------------------------|---------|
| **æœç´¢èŒƒå¼** | å›ºå®šç®—å­ / ç»Ÿè®¡é©±åŠ¨ | åŠ¨æ€æŒ‡ä»¤ / è¯­ä¹‰é©±åŠ¨ |
| **è®°å¿†æœºåˆ¶** | æ— æˆ–ä»…ä¿ç•™ç§ç¾¤ | æ˜¾å¼å›¾ç»“æ„è®°å¿†ï¼ˆEntailment Graphï¼‰ |
| **è§„åˆ’èƒ½åŠ›** | æ— çŠ¶æ€é‡‡æ · | çŠ¶æ€æ„ŸçŸ¥çš„ MDP å†³ç­– |
| **å¤šæ ·æ€§æ§åˆ¶** | è¢«åŠ¨ï¼ˆé å˜å¼‚ï¼‰ | ä¸»åŠ¨ï¼ˆPromptæ‰°åŠ¨ + çŠ¶æ€æ´—ç‰Œï¼‰ |
| **æ”¶æ•›é€Ÿåº¦** | è¾ƒæ…¢ï¼Œæ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ | æ›´å¿«æ”¶æ•›ï¼Œæ›´ä½æ–¹å·® |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### æ•°æ®é›†
åœ¨å¤šä¸ªç»å…¸ **NP-hard COPs** ä¸Šè¿›è¡Œæµ‹è¯•ï¼Œæ¶µç›–å¤šç§æœç´¢æ¡†æ¶ï¼š
- **Traveling Salesman Problem (TSP)**
- **Knapsack Problem (KP)**
- **Capacitated Vehicle Routing Problem (CVRP)**
- **Multiple Knapsack Problem (MKP)**
- **Orienteering Problem (OP)**
- **Bin Packing Problem (BPP)**ï¼ˆå«åœ¨çº¿ä¸ç¦»çº¿ç‰ˆæœ¬ï¼‰

æ‰€æœ‰å®ä¾‹å‡é€šè¿‡ç»Ÿä¸€åè®®åˆæˆï¼Œç¡®ä¿å…¬å¹³æ¯”è¾ƒã€‚

### å®éªŒè®¾ç½®
- **LLM åç«¯**ï¼šä½¿ç”¨ `GPT-4o-mini`ã€`GPT-5-nano (low)` å’Œ `GPT-5-nano (medium)` è¿›è¡Œè¯„ä¼°ã€‚
- **è¯„ä¼°é¢„ç®—**ï¼šå›ºå®šä¸º **500 æ¬¡å¯å‘å¼è¯„ä¼°**ï¼ˆne = 500ï¼‰ï¼Œè€ŒåŸºçº¿å…è®¸æœ€å¤š 1000 æ¬¡ã€‚
- **æ¸©åº¦å‚æ•°**ï¼šæ‰€æœ‰ä»£ç†è®¾ä¸º 1.0ï¼Œä¿è¯ç”Ÿæˆå¤šæ ·æ€§ã€‚
- **è¿è¡Œæ¬¡æ•°**ï¼šæ¯é¡¹ä»»åŠ¡ç‹¬ç«‹è¿è¡Œ 3 æ¬¡å–å¹³å‡å€¼ã€‚

### è¯„ä¼°æŒ‡æ ‡
- **ç›®æ ‡å‡½æ•°å€¼ï¼ˆObj.ï¼‰**ï¼šè¶Šå°è¶Šå¥½ï¼ˆæœ€å°åŒ–é—®é¢˜ï¼‰ã€‚
- **Optimality Gap (%)**ï¼šç›¸å¯¹äºå·²çŸ¥æœ€ä¼˜è§£æˆ–æœ€å¼ºåŸºçº¿çš„å·®è·ã€‚
- **Mean Relative Gap Improvement (MRGI)**ï¼šè¡¡é‡ PathWise ç›¸å¯¹äºå„åŸºçº¿çš„å¹³å‡ç›¸å¯¹æå‡å¹…åº¦ã€‚
- **Selection Diversity Rate (SDR)**ï¼šè¡¡é‡çˆ¶èŠ‚ç‚¹é€‰æ‹©çš„å¤šæ ·æ€§æ¯”ä¾‹ã€‚

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
| ç±»å‹ | æ–¹æ³• |
|------|------|
| **Population-based** | FunSearch, EoH, ReEvo, HSEvo |
| **Tree-based** | MCTS-AHD |
| **æ‰‹å·¥è®¾è®¡** | Greedy Construct, ACO, DeepACO, KGLS |
| **ç¥ç»æ±‚è§£å™¨** | POMO, VRP-DACT, NeuOpt, NeuralGLS, GNNGLS |

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1 & Table 2ï¼‰
#### âœ… åœ¨ **TSP-Constructive** ä¸Šçš„è¡¨ç°ï¼ˆN=200ï¼‰
| æ–¹æ³• | Obj. â†“ | Gap (%) |
|------|--------|--------|
| Greedy Construct | 13.430 | 25.41% |
| MCTS-AHD | 12.403 | 15.82% |
| **PathWise (Ours)** | **12.276** | **14.63%** |

> åœ¨æ›´éš¾çš„ **N=500** KP æµ‹è¯•é›†ä¸­ï¼ŒPathWise çš„ MRGI é«˜è¾¾ **81.34%**ã€‚

#### âœ… åœ¨ **ACO æ¡†æ¶** ä¸‹çš„å¹³å‡ MRGI æå‡
| é—®é¢˜ | MRGI â†‘ |
|------|-------|
| TSP | 60.22% |
| CVRP | 38.73% |
| MKP | 89.35% |
| OP | 54.81% |
| Offline BPP | 44.86% |

> è¡¨æ˜ PathWise åœ¨æ›´å¤§è§„æ¨¡å’Œæ›´å¤æ‚é—®é¢˜ä¸Šä¼˜åŠ¿æ˜¾è‘—ã€‚

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ
- **å…¨é¢è¶…è¶Šæ‰€æœ‰ LLM-based AHD æ–¹æ³•**ï¼šåœ¨æ‰€æœ‰æµ‹è¯•é›†å’Œ LLM åç«¯ä¸‹ï¼ŒPathWise å‡å–å¾—æœ€ä½³æ€§èƒ½ã€‚
- **ä¼˜äºç¥ç»æ±‚è§£å™¨**ï¼š
  - åœ¨ **TSP (N=200)** ä¸Šä¼˜äº **POMO**ã€‚
  - åœ¨ **OP (N=200)** å’Œ **MKP** ä¸Šä¼˜äº **DeepACO**ï¼Œå°½ç®¡åè€…éœ€è¦ä¸“é—¨è®­ç»ƒã€‚
- **æ›´å¿«æ”¶æ•›**ï¼šå¦‚ Figure 1 æ‰€ç¤ºï¼Œåœ¨ä»…ä¸€åŠè¯„ä¼°é¢„ç®—ä¸‹ï¼ŒPathWise å·²è¶…è¿‡åŸºçº¿æœ€ç»ˆæ€§èƒ½ï¼Œä¸”æ–¹å·®æ›´ä½ã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studyï¼‰

#### ï¼ˆ1ï¼‰ç§»é™¤ Critic Agentsï¼ˆTable 3ï¼‰
| æ–¹æ³• | TSP50 Gap (%) |
|------|-------------|
| PathWise (å®Œæ•´) | 8.79% |
| w/o Policy Critic | 10.21% |
| w/o World Model Critic | 9.63% |
| w/o Both | 14.42% |

> **Policy Critic å½±å“æœ€å¤§**ï¼Œè¯´æ˜é«˜å±‚ç­–ç•¥åé¦ˆå¯¹å¼•å¯¼æœç´¢è‡³å…³é‡è¦ã€‚

#### ï¼ˆ2ï¼‰ç§»é™¤å¤šæ ·æ€§æœºåˆ¶ï¼ˆTable 4ï¼‰
| æ–¹æ³• | TSP50 Gap (%) | SDR (%) |
|------|--------------|--------|
| PathWise (å®Œæ•´) | 8.79% | 75.79% |
| w/o Prompt Perturbation | 9.58% | 70.30% |
| w/o State Shuffling | 9.02% | 61.03% |
| w/o Both | 11.43% | 53.76% |

> **Prompt Perturbation æ˜¯å¤šæ ·æ€§çš„ä¸»è¦é©±åŠ¨åŠ›**ï¼›State Shuffling ä¸»è¦ç¼“è§£ä½ç½®åè§ã€‚

#### ï¼ˆ3ï¼‰è¶…å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼ˆAppendix F.4ï¼‰
- é»˜è®¤è®¾ç½® `(Na=2, Nu=2, Np=6, Imax=3)` æ€§èƒ½ç¨³å®šã€‚
- è¿‡å¤§æˆ–è¿‡å°çš„å‚æ•°éƒ½ä¼šé™ä½æ€§èƒ½ï¼ŒéªŒè¯äº†è®¾è®¡åˆç†æ€§ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°
1. **çŠ¶æ€æ„ŸçŸ¥è§„åˆ’ä¼˜äºç›²ç›®æœç´¢**ï¼šé€šè¿‡ **Entailment Graph** å’Œå¤šæ™ºèƒ½ä½“åä½œï¼ŒPathWise å®ç°äº†çœŸæ­£æ„ä¹‰ä¸Šçš„â€œæ¨ç†å¼â€å¯å‘å¼æ¼”åŒ–ï¼Œè€Œééšæœºçªå˜ã€‚
2. **é«˜å±‚ç­–ç•¥åé¦ˆæ¯”åº•å±‚ä»£ç å¾®è°ƒæ›´é‡è¦**ï¼šPolicy Critic çš„ä½œç”¨è¿œå¤§äº World Model Criticï¼Œè¡¨æ˜â€œå¾€å“ªèµ°â€æ¯”â€œæ€ä¹ˆå†™â€æ›´å…·å†³å®šæ€§ã€‚
3. **å¤šæ ·æ€§æ˜¯é«˜æ•ˆè¿›åŒ–çš„å‰æ**ï¼šPrompt-Level å¤šæ ·æ€§æœºåˆ¶æ˜¾è‘—æå‡äº†æ¢ç´¢å¹¿åº¦ï¼Œé˜²æ­¢æ—©ç†Ÿæ”¶æ•›ã€‚
4. **å¯æ‰©å±•æ€§å¼º**ï¼šéšç€é—®é¢˜è§„æ¨¡å¢å¤§ï¼ŒPathWise çš„ç›¸å¯¹ä¼˜åŠ¿æŒç»­æ‰©å¤§ï¼Œå±•ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

### æ–¹æ³•çš„å±€é™æ€§
1. **ä¾èµ– LLM è¾“å‡ºç¨³å®šæ€§**ï¼šLLM çš„éšæœºæ€§å¯èƒ½å¯¼è‡´ç”Ÿæˆè´¨é‡æ³¢åŠ¨ï¼Œå½±å“æœç´¢ç¨³å®šæ€§ã€‚
2. **ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶**ï¼šè™½ç„¶é‡‡ç”¨å‹ç¼©å…ƒæ•°æ®ï¼ˆPMï¼‰ï¼Œä½†åœ¨æå¤§è§„æ¨¡æœç´¢ä¸­ä»å¯èƒ½å—é™äº context windowã€‚
3. **å®ç°å¤æ‚åº¦é«˜**ï¼šç›¸æ¯”å•ä»£ç†æ–¹æ³•ï¼ŒPathWise æ¶æ„æ›´å¤æ‚ï¼Œè°ƒè¯•æˆæœ¬æ›´é«˜ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘
1. **åº”ç”¨äºæ›´æ˜‚è´µçš„è¯„ä¼°åœºæ™¯**ï¼šå¦‚ææ–™è®¾è®¡ã€è›‹ç™½è´¨åºåˆ—ä¼˜åŒ–ç­‰éœ€æ¨¡æ‹Ÿæˆ–å®éªŒéªŒè¯çš„ä»»åŠ¡ã€‚
2. **å¼•å…¥å¯å­¦ä¹ çš„è®°å¿†æ¨¡å—**ï¼šå°† Entailment Graph ä¸å‘é‡æ£€ç´¢ç»“åˆï¼Œæ”¯æŒè·¨ä»»åŠ¡çŸ¥è¯†è¿ç§»ã€‚
3. **è‡ªé€‚åº”è°ƒèŠ‚æ¢ç´¢-åˆ©ç”¨å¹³è¡¡**ï¼šåŠ¨æ€è°ƒæ•´ $ \epsilon(l) $ å’Œæ‰¹è¯„å¼ºåº¦ï¼Œè¿›ä¸€æ­¥æå‡æ•ˆç‡ã€‚
4. **æ‰©å±•è‡³å¤šç›®æ ‡ä¼˜åŒ–**ï¼šç»“åˆ Pareto å‰æ²¿åˆ†æï¼Œæ”¯æŒå¤šç›®æ ‡å¯å‘å¼é›†åˆç”Ÿæˆã€‚

--- 

> **æ€»ä½“è¯„ä»·**ï¼šPathWise æ˜¯ AHD é¢†åŸŸçš„é‡è¦è¿›å±•ï¼Œé¦–æ¬¡ç³»ç»Ÿåœ°å°† **LLM æ¨ç†èƒ½åŠ›**ã€**çŠ¶æ€è®°å¿†** å’Œ **å¤šæ™ºèƒ½ä½“è§„åˆ’** ç»“åˆï¼Œæ¨åŠ¨äº†è‡ªåŠ¨åŒ–å¯å‘å¼è®¾è®¡ä»â€œé»‘ç®±æœç´¢â€è¿ˆå‘â€œç™½ç›’æ¨ç†â€ã€‚

</details>

---

### 15. [ASTRA: Automated Synthesis of agentic Trajectories and Reinforcement Arenas](https://arxiv.org/abs/2601.21558)

**Authors**: Xiaoyu Tian, Haotian Wang, Shuaiting Chen, Hao Zhou, Kaichi Yu, Yudian Zhang, Jade Ouyang, Junxi Yin, Jiong Chen, Baoyan Guo, Lei Zhang, Junjie Tao, Yuansheng Song, Ming Cui, Chengwei Liu  
**Category**: cs.CL  
**Published**: 2026-01-30  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.21558v1  

#### Abstract
Large language models (LLMs) are increasingly used as tool-augmented agents for multi-step decision making, yet training robust tool-using agents remains challenging. Existing methods still require manual intervention, depend on non-verifiable simulated environments, rely exclusively on either super...

<details>
<summary><strong>ğŸ¤– AI Summary (by qwen-long)</strong> - Click to expand</summary>

# è®ºæ–‡ã€ŠASTRA: Automated Synthesis of agentic Trajectories and Reinforcement Arenasã€‹æ ¸å¿ƒæ€»ç»“

---

## 1. è®ºæ–‡çš„ä¸»è¦è´¡çŒ®å’Œåˆ›æ–°ç‚¹

### è§£å†³äº†ä»€ä¹ˆé—®é¢˜

å½“å‰åœ¨è®­ç»ƒå…·å¤‡å·¥å…·è°ƒç”¨èƒ½åŠ›çš„ **LLM agents** æ—¶é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š

- **ä¾èµ–äººå·¥å¹²é¢„**ï¼šå¤šæ•°æ–¹æ³•éœ€è¦æ‰‹åŠ¨æ ‡æ³¨æˆ–è®¾è®¡ä»»åŠ¡ä¸ç¯å¢ƒã€‚
- **éå¯éªŒè¯çš„æ¨¡æ‹Ÿç¯å¢ƒ**ï¼šåŸºäº LLM æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œå’ŒçŠ¶æ€è½¬ç§»ï¼Œå¯¼è‡´å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¿¡å·ä¸å¯é ï¼Œç¼ºä¹ç¡®å®šæ€§åé¦ˆã€‚
- **é•¿è§†é‡å¤šè½®å­¦ä¹ ä¸ç¨³å®š**ï¼šç°æœ‰æ–¹æ³•å¸¸å°†å¤šè½®è½¨è¿¹åˆ†è§£ä¸ºå•æ­¥å®ä¾‹ï¼Œç ´åäº†é•¿æœŸå†³ç­–è¿è´¯æ€§ã€‚
- **è®­ç»ƒèŒƒå¼å•ä¸€**ï¼šä»…é‡‡ç”¨ SFT æˆ– RLï¼Œéš¾ä»¥å…¼é¡¾æ³›åŒ–èƒ½åŠ›å’Œåœ¨çº¿ä¼˜åŒ–ã€‚

### æå‡ºäº†ä»€ä¹ˆæ–°æ–¹æ³•æˆ–æ–°æ€è·¯

ä½œè€…æå‡º **ASTRA** â€”â€” ä¸€ä¸ª**å…¨è‡ªåŠ¨ã€ç«¯åˆ°ç«¯**çš„æ¡†æ¶ï¼Œç”¨äºè®­ç»ƒå·¥å…·å¢å¼ºå‹è¯­è¨€æ¨¡å‹ä»£ç†ï¼Œå…¶æ ¸å¿ƒç”±ä¸¤ä¸ªäº’è¡¥ç»„ä»¶æ„æˆï¼š

#### ï¼ˆ1ï¼‰åŸºäºå·¥å…·è°ƒç”¨å›¾æ‹“æ‰‘çš„å¤šè½®è½¨è¿¹åˆæˆï¼ˆç”¨äº SFTï¼‰
- åˆ©ç”¨çœŸå® MCP æœåŠ¡å™¨ä¸­çš„å·¥å…·æ–‡æ¡£æ„å»º **tool-call graph**ã€‚
- é€šè¿‡ LLM è‡ªåŠ¨ç”Ÿæˆåˆç†çš„ **tool-chain**ï¼ˆå·¥å…·è°ƒç”¨åºåˆ—ï¼‰ï¼Œå¹¶ç»“åˆä»»åŠ¡ç”Ÿæˆã€å¢å¼ºä¸è´¨é‡è¯„åˆ†ï¼Œå½¢æˆé«˜è´¨é‡çš„å¤šè½®å¯¹è¯è½¨è¿¹ã€‚
- å®ç°æ— éœ€äººå·¥æ ‡æ³¨çš„ **Supervised Fine-Tuning (SFT)** æ•°æ®é›†æ„å»ºã€‚

#### ï¼ˆ2ï¼‰åŸºäºé—®ç­”å¯¹è¯­ä¹‰æ‹“æ‰‘çš„å¯éªŒè¯ç¯å¢ƒåˆæˆï¼ˆç”¨äº RLï¼‰
- å°†äººç±»æ¨ç†è¿‡ç¨‹å»ºæ¨¡ä¸º **è¯­ä¹‰æ‹“æ‰‘ç»“æ„**ï¼ˆsemantic topologyï¼‰ï¼Œä» Q-A å¯¹ä¸­æå–å­é—®é¢˜ä¾èµ–å…³ç³»ã€‚
- è‡ªåŠ¨å°†æ¯ä¸ªå­é—®é¢˜è½¬åŒ–ä¸ºç‹¬ç«‹ã€å¯æ‰§è¡Œã€è§„åˆ™å¯éªŒè¯çš„ Python å·¥å…·å®ç°ï¼Œå¹¶å°è£…è¿›æ²™ç®±ç¯å¢ƒã€‚
- æ”¯æŒ **deterministic multi-turn RL**ï¼Œç¡®ä¿å¥–åŠ±ä¿¡å·å¯é ä¸”å¯å¤ç°ã€‚

#### ï¼ˆ3ï¼‰ç»Ÿä¸€çš„ä¸¤é˜¶æ®µè®­ç»ƒæ–¹æ³•
- **ç¬¬ä¸€é˜¶æ®µï¼ˆSFTï¼‰**ï¼šåˆ©ç”¨åˆæˆçš„å¤šè½®è½¨è¿¹è®­ç»ƒåˆå§‹ç­–ç•¥ï¼Œæå‡å¯¹å·¥å…·äº¤äº’çš„ç†è§£ã€‚
- **ç¬¬äºŒé˜¶æ®µï¼ˆRLï¼‰**ï¼šåœ¨ä»£ç å¯æ‰§è¡Œã€è§„åˆ™å¯éªŒè¯çš„ç¯å¢ƒä¸­è¿›è¡Œåœ¨çº¿å¤šè½® RLï¼Œå¼•å…¥ï¼š
  - **Irrelevant Tool Mixing**ï¼šæ··åˆæ— å…³å·¥å…·ä»¥å¢å¼ºå·¥å…·åˆ¤åˆ«èƒ½åŠ›ã€‚
  - **F1-style è½¨è¿¹çº§å¥–åŠ±**ï¼šè”åˆä¼˜åŒ–ä»»åŠ¡å®Œæˆç‡ï¼ˆrecallï¼‰ä¸è°ƒç”¨æ•ˆç‡ï¼ˆprecisionï¼‰ã€‚

### ç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿

| ç»´åº¦ | ASTRA çš„ä¼˜åŠ¿ |
|------|-------------|
| **è‡ªåŠ¨åŒ–ç¨‹åº¦** | å®Œå…¨è‡ªåŠ¨åŒ–ï¼Œæ— éœ€äººå·¥å‚ä¸æ•°æ®æ„é€ ä¸éªŒè¯ |
| **ç¯å¢ƒå¯éªŒè¯æ€§** | æ‰€æœ‰ç¯å¢ƒå‡ä¸ºä»£ç å¯æ‰§è¡Œã€è§„åˆ™å¯éªŒè¯ï¼Œæ”¯æŒç¨³å®š RL |
| **è®­ç»ƒç¨³å®šæ€§** | å¤šè½®åœ¨çº¿ RL + Adaptive Batch Filling é¿å…æ¢¯åº¦æ¶ˆå¤± |
| **æ³›åŒ–ä¸é²æ£’æ€§** | ç»“åˆé™æ€å·¥å…·æ‹“æ‰‘ï¼ˆå¹¿åº¦ï¼‰ä¸åŠ¨æ€è¯­ä¹‰æ‹“æ‰‘ï¼ˆæ·±åº¦ï¼‰åŒé‡å­¦ä¹  |
| **å¼€æºå®Œæ•´æ€§** | å…¬å¼€å®Œæ•´ pipelineã€ç¯å¢ƒä¸æ¨¡å‹ï¼š[GitHub](https://github.com/LianjiaTech/astra) |

---

## 2. æ ¸å¿ƒå®éªŒæ–¹æ³•å’Œè®¾ç½®

### ä½¿ç”¨çš„æ•°æ®é›†

#### SFT æ•°æ®é›†
- æ¥æºï¼šä» 1,585 ä¸ª MCP æœåŠ¡å™¨æ”¶é›†çš„ 19,036 ä¸ªå·¥å…·æ–‡æ¡£ï¼Œè¦†ç›– 41 ä¸ªé¢†åŸŸã€‚
- è§„æ¨¡ï¼š54,885 æ¡å¤šè½®å¯¹è¯æ ·æœ¬ï¼Œå…± 580,983 æ¡æ¶ˆæ¯ã€‚
- å¹³å‡æ¯æ¡å« 4.42 æ¬¡ tool callï¼Œ72.2% åŒ…å« 1â€“5 æ¬¡è°ƒç”¨ã€‚

#### RL æ•°æ®é›†
- æ¥æºï¼šåŸºäº QA å¯¹åˆæˆçš„å¯æ‰§è¡Œç¯å¢ƒã€‚
- è§„æ¨¡ï¼š6,596 ä¸ªæ ·æœ¬ï¼Œæ¶µç›–æˆ¿åœ°äº§ã€ç”µå•†ã€åŒ»ç–—ç­‰ 20+ é¢†åŸŸã€‚
- ç‰¹å¾ï¼š
  - å¹³å‡ 4.37 æ¨ç†æ­¥ï¼ˆhopsï¼‰ï¼Œæœ€å¤§è¾¾ 20ã€‚
  - 91.3% å­é—®é¢˜éœ€å¤–éƒ¨å·¥å…·è°ƒç”¨ã€‚
  - åœºæ™¯ç±»å‹åˆ†å¸ƒï¼šParallel Multi-Hop (47.8%) > Multi-Hop (34.8%)

### å®éªŒè®¾ç½®å’Œè¯„ä¼°æŒ‡æ ‡

#### æ¨¡å‹åŸºç¡€
- ä¸»å¹²æ¨¡å‹ï¼š`Qwen3-14B` å’Œ `Qwen3-32B`
- è®­ç»ƒæµç¨‹ï¼š
  - SFTï¼š2 epochsï¼Œbatch size=32ï¼Œmax seq len=20k
  - RLï¼šonline multi-turn RLï¼Œbatch size=256ï¼Œmax prompt len=25.6kï¼Œresponse len=49.152k

#### è¯„ä¼°åŸºå‡†ï¼ˆAgentic Benchmarksï¼‰
| åŸºå‡† | æè¿° |
|------|------|
| **BFCL-v3 Multi-Turn (BFCL-MT)** | å¤šè½®å‡½æ•°è°ƒç”¨è¯„æµ‹ï¼Œå¼ºè°ƒè·¨è½®çŠ¶æ€è¿½è¸ª |
| **T2-Bench** | åŒæ§ç¯å¢ƒä¸‹çš„å¯¹è¯ä»£ç†è¯„æµ‹ï¼Œå«ç”¨æˆ·æ¨¡æ‹Ÿå™¨ |
| **ACEBench** | å·¥å…·å­¦ä¹ ç«èµ›å¼è¯„æµ‹ï¼Œå…³æ³¨ä»»åŠ¡å®Œæˆä¸äº¤äº’æ•ˆç‡ |

#### éä»£ç†ä»»åŠ¡è¯„æµ‹ï¼ˆNon-agenticï¼‰
- **AIME2024 / AIME2025**ï¼šæ•°å­¦æ¨ç†ä»»åŠ¡ï¼Œæ£€éªŒæ˜¯å¦æŸå®³åŸºç¡€æ¨ç†èƒ½åŠ›

#### è¯„ä¼°åè®®
- æ‰€æœ‰æµ‹è¯•ä½¿ç”¨ `vLLM` æ¨ç†å¼•æ“
- æ¸©åº¦è®¾ç½®ï¼š
  - T2-Bench: temp=0.0ï¼ˆgreedyï¼‰
  - ACEBench/BFCL-MT: temp=0.6
- ç”¨æˆ·æ¨¡æ‹Ÿå™¨ï¼š
  - T2-Bench: GPT-5.1
  - ACEBench: GPT-4.1

### åŸºçº¿æ–¹æ³•å¯¹æ¯”
- **é—­æºæ¨¡å‹**ï¼šClaude-Opus/Sonnet/Haiku, Gemini-3-Pro, GPT-4.1
- **å¼€æºæ¨¡å‹**ï¼šGLM-4.6, LoopTool-32B, Qwen3-14B/32B, Kimi-K2-Instruct

---

## 3. ä¸»è¦å®éªŒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡

### å…³é”®æ€§èƒ½æ•°æ®ï¼ˆæ¥è‡ª Table 1ï¼‰

| Model | BFCL-MT (Overall) | T2-Bench (Overall) | ACEBench (Overall) |
|-------|-------------------|--------------------|---------------------|
| **ASTRA-14B-Thinking-v1** | **58.13** | **57.69** | **68.96** |
| **ASTRA-32B-Thinking-v1** | **64.25** | **63.70** | **71.88** |
| Qwen3-32B | 49.63 | 49.70 | 59.79 |
| GLM-4.6 | 68.00 | 69.63 | 80.00 |
| Claude-Opus-4.5 | 68.38 | 85.79 | 82.09 |

> âœ… **ASTRA-32B åœ¨åŒè§„æ¨¡å¼€æºæ¨¡å‹ä¸­è¾¾åˆ° SOTA æ€§èƒ½ï¼Œæ¥è¿‘éƒ¨åˆ†é—­æºç³»ç»Ÿ**

### ä¸åŸºçº¿æ–¹æ³•çš„å¯¹æ¯”ç»“æœ

- **ç›¸æ¯”åŸå§‹ Qwen æ¨¡å‹**ï¼š
  - ASTRA-32B åœ¨ BFCL-MT ä¸Šæå‡ **+16.38 pts**
  - åœ¨ ACEBench ä¸Šæå‡ **+12.09 pts**
- **ç›¸æ¯”å…¶ä»–å¼€æºå·¥å…·æ¨¡å‹**ï¼ˆå¦‚ LoopToolã€Qwen3ï¼‰ï¼š
  - æ˜¾è‘—ä¼˜äºæ‰€æœ‰åŒç±»å¼€æºæ¨¡å‹ï¼Œå°¤å…¶åœ¨å¤šè½®å¤æ‚ä»»åŠ¡ä¸Šè¡¨ç°çªå‡ºã€‚
- **æ¥è¿‘é—­æºæ¨¡å‹**ï¼š
  - ASTRA-32B è¡¨ç°é€¼è¿‘ GLM-4.6 å’Œ Claude-Sonnetï¼Œåœ¨æŸäº›ç»´åº¦è¶…è¶Š Gemini-3-Proã€‚

### æ¶ˆèå®éªŒç»“æœï¼ˆAblation Studiesï¼‰

#### ï¼ˆ1ï¼‰æ¶ˆèï¼šæ˜¯å¦åŠ å…¥æ— å…³å·¥å…·ï¼ˆIrrelevant Tool Mixingï¼‰
- **No Irrelevant Tools**ï¼šæ€§èƒ½æœ€å·® â†’ æ¨¡å‹è¿‡æ‹Ÿåˆå›ºå®šå·¥å…·é›†ï¼Œæ— æ³•æ‹’ç»é”™è¯¯å·¥å…·ã€‚
- **Random Irrelevant Tools**ï¼šæœ‰æ‰€æ”¹å–„ï¼Œä½†ä»ä¸å¦‚åˆ†å±‚æ··åˆã€‚
- **ASTRAï¼ˆæŒ‰ç›¸ä¼¼åº¦åˆ†å±‚æ··åˆï¼‰**ï¼šæ•ˆæœæœ€ä½³ï¼Œè¯´æ˜ **controlled discrimination signal** è‡³å…³é‡è¦ã€‚

> ğŸ” å‘ç°ï¼šå·¥å…·ç›¸ä¼¼åº¦è¶Šé«˜ï¼ˆnear-miss distractorsï¼‰ï¼Œè¶Šèƒ½æœ‰æ•ˆä¿ƒè¿›æ¨¡å‹å­¦ä¹ â€œè¯¥ä¸è¯¥è°ƒç”¨â€ã€‚

#### ï¼ˆ2ï¼‰æ¶ˆèï¼šå¥–åŠ±å‡½æ•°è®¾è®¡ï¼ˆReward Designï¼‰
| å¥–åŠ±ç±»å‹ | è¡¨ç° |
|--------|------|
| **Recall-only** | å¯¹è¯è½®æ¬¡çˆ†ç‚¸ï¼Œé¢‘ç¹æ— æ•ˆè°ƒç”¨ï¼Œæœ€ç»ˆå´©æºƒ |
| **Precision-only** | è¿‡äºä¿å®ˆï¼Œæå‰ç»ˆæ­¢ï¼Œé”™è¿‡å…³é”®æ­¥éª¤ |
| **F1-styleï¼ˆæœ¬æ–‡æ–¹æ³•ï¼‰** | å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨ï¼Œè®­ç»ƒç¨³å®šï¼Œæ€§èƒ½æœ€ä¼˜ |

> ğŸ“ˆ å›¾ 8 æ˜¾ç¤º F1 å¥–åŠ±ä¸‹å¯¹è¯é•¿åº¦é€‚ä¸­ä¸”æ”¶æ•›è‰¯å¥½ã€‚

#### ï¼ˆ3ï¼‰è®­ç»ƒé˜¶æ®µåˆ†æï¼ˆTable 2ï¼‰
| é˜¶æ®µ | BFCL-MT â†‘ | T2-Bench â†‘ | ACEBench â†‘ |
|------|----------|-----------|------------|
| åŸå§‹æ¨¡å‹ | 44.50 | 44.55 | 51.67 |
| SFT å | 48.50 | 50.45 | 67.71 |
| RL å | **58.13** | **57.70** | **68.96** |

> âœ… **RL é˜¶æ®µå¸¦æ¥æœ€å¤§å¢ç›Š**ï¼Œè¡¨æ˜å¤šè½®åœ¨çº¿ RL æ˜¯å…³é”®é©±åŠ¨åŠ›ã€‚

---

## 4. å…³é”®ç»“è®ºå’Œå‘ç°

### ä¸»è¦å‘ç°

1. **å…¨è‡ªåŠ¨æ•°æ®ä¸ç¯å¢ƒåˆæˆæ˜¯å¯è¡Œçš„**  
   ASTRA æˆåŠŸå®ç°äº†ä»å·¥å…·æ–‡æ¡£åˆ°å¯æ‰§è¡Œç¯å¢ƒçš„å…¨æµç¨‹è‡ªåŠ¨åŒ–ï¼Œæ‘†è„±äº†å¯¹äººå·¥æ ‡æ³¨çš„ä¾èµ–ã€‚

2. **å¯éªŒè¯ç¯å¢ƒå¯¹ç¨³å®š RL æå…¶é‡è¦**  
   åŸºäºä»£ç æ²™ç®±çš„ deterministic execution æä¾›äº†å¯é çš„ reward signalï¼Œä½¿ long-horizon RL æˆä¸ºå¯èƒ½ã€‚

3. **F1-style è½¨è¿¹çº§å¥–åŠ±èƒ½æœ‰æ•ˆå¹³è¡¡ä»»åŠ¡å®Œæˆä¸äº¤äº’æ•ˆç‡**  
   é¿å…äº† recall-only çš„å†—ä½™è°ƒç”¨å’Œ precision-only çš„è¿‡åº¦ä¿å®ˆã€‚

4. **ä¸¤é˜¶æ®µè®­ç»ƒï¼ˆSFT + RLï¼‰ä¼˜äºå•ä¸€èŒƒå¼**  
   SFT æä¾›å¼ºåˆå§‹åŒ–ï¼ŒRL å®ç°æ·±åº¦ä¼˜åŒ–ï¼ŒäºŒè€…ååŒæ˜¾è‘—æå‡æ€§èƒ½ã€‚

5. **ASTRA ä¸æŸå®³åŸºç¡€æ¨ç†èƒ½åŠ›**  
   åœ¨ AIME2024/2025 ä¸Šçš„è¡¨ç°æ˜¾ç¤ºï¼Œagentic training æœªç‰ºç‰² core reasoningã€‚

### æ–¹æ³•çš„å±€é™æ€§

- **ç¯å¢ƒåˆæˆæˆæœ¬é«˜**ï¼šæ¯ä¸ª QA å¯¹éœ€ç”Ÿæˆå¹¶éªŒè¯ Python å·¥å…·ä»£ç ï¼Œè®¡ç®—å¼€é”€å¤§ã€‚
- **ä¾èµ–é«˜è´¨é‡å·¥å…·æ–‡æ¡£**ï¼šè‹¥åŸå§‹ tool schema ä¸æ¸…æ™°ï¼Œä¼šå½±å“åˆæˆè´¨é‡ã€‚
- **è¯­è¨€è¦†ç›–æœ‰é™**ï¼šç›®å‰ä¸»è¦æ”¯æŒè‹±æ–‡å’Œä¸­æ–‡ï¼Œå¤šè¯­è¨€æ‰©å±•å¾…åŠ å¼ºã€‚
- **ç°å®ä¸–ç•ŒåŠ¨æ€æ€§ä¸è¶³**ï¼šå°½ç®¡æ³¨å…¥æ•…éšœæ¨¡æ‹Ÿï¼Œä»éš¾å®Œå…¨åæ˜ çœŸå®æœåŠ¡æ³¢åŠ¨ã€‚

### æœªæ¥å·¥ä½œæ–¹å‘

1. **å¼•å…¥çœŸå®ç”¨æˆ·äº¤äº’è®­ç»ƒ**  
   å½“å‰è®­ç»ƒåŸºäºé™æ€ä»»åŠ¡ï¼Œæœªæ¥è®¡åˆ’åŠ å…¥ multi-turn user feedback loopï¼Œæå‡åº”å¯¹æ„å›¾æ¼‚ç§»çš„èƒ½åŠ›ã€‚

2. **é™ä½ç¯å¢ƒåˆæˆæˆæœ¬**  
   æå‡ºå…ˆéªŒè¯è¯­ä¹‰æ‹“æ‰‘å†ç”Ÿæˆä»£ç ï¼Œé¿å…ä½ç½®ä¿¡åº¦è§„æ ¼çš„æ— æ•ˆç¼–ç ã€‚

3. **æ„å»ºåŠ¨æ€éš¾åº¦è¯¾ç¨‹ï¼ˆCurriculum Learningï¼‰**  
   ç±»ä¼¼ GenEnvï¼Œè®©ç¯å¢ƒç”Ÿæˆå™¨æ ¹æ® agent èƒ½åŠ›åŠ¨æ€è°ƒæ•´ä»»åŠ¡éš¾åº¦ã€‚

4. **æ”¯æŒæ›´å¤æ‚çš„ agent æ¶æ„**  
   å¦‚å¼•å…¥ memoryã€planning module ç­‰é«˜çº§è®¤çŸ¥ç»„ä»¶ã€‚

---

> âœ… **æ€»ç»“ä¸€å¥è¯**ï¼š  
> **ASTRA æ˜¯é¦–ä¸ªå®ç°å…¨è‡ªåŠ¨ã€ç«¯åˆ°ç«¯ã€å¯éªŒè¯çš„å·¥å…·ä»£ç†è®­ç»ƒæ¡†æ¶ï¼Œé€šè¿‡â€œé™æ€æ‹“æ‰‘ + åŠ¨æ€è¯­ä¹‰â€åŒè½®é©±åŠ¨ï¼Œåœ¨å¤šä¸ª agentic benchmark ä¸Šè¾¾åˆ°åŒè§„æ¨¡ SOTAï¼Œå¹¶ä¿æŒåŸºç¡€æ¨ç†èƒ½åŠ›ï¼Œæ¨åŠ¨äº† LLM agent çš„è§„æ¨¡åŒ–è½åœ°ã€‚**

</details>

---

### 16. [SONIC: Segmented Optimized Nexus for Information Compression in Key-Value Caching](https://arxiv.org/abs/2601.21927)

**Authors**: Hong Chen, Xiang Liu, Bo Wang, Yuxuan Fan, Yuanlin Chu, Zongluo Li, Xiaowen Chu, Xuming Hu  
**Category**: cs.CL  
**Published**: 2026-01-30  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.21927v1  

#### Abstract
The linear growth of Key-Value (KV) cache remains a bottleneck for multi-turn LLM deployment. Existing KV cache compression methods often fail to account for the structural properties of multi-turn dialogues, relying on heuristic eviction that risks losing critical context. We propose \textbf{SONIC}...

---

### 17. [Snowball: A Scalable All-to-All Ising Machine with Dual-Mode Markov Chain Monte Carlo Spin Selection and Asynchronous Spin Updates for Fast Combinatorial Optimization](https://arxiv.org/abs/2601.21058)

**Authors**: Seungki Hong, Kyeongwon Jeong, Taekwang Jang  
**Category**: cs.LG  
**Published**: 2026-01-30  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.21058v1  

#### Abstract
Ising machines have emerged as accelerators for combinatorial optimization. To enable practical deployment, this work aims to reduce time-to-solution by addressing three challenges: (1) hardware topology, (2) spin selection and update algorithms, and (3) scalable coupling-coefficient precision. Rest...

---

### 18. [Theoretically Optimal Attention/FFN Ratios in Disaggregated LLM Serving](https://arxiv.org/abs/2601.21351)

**Authors**: Chendong Song, Meixuan Wang, Hang Zhou, Hong Liang, Yuan Lyu, Zixi Chen, Yuwei Fan, Zijie Zhou  
**Category**: cs.LG  
**Published**: 2026-01-30  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.21351v1  

#### Abstract
Attention-FFN disaggregation (AFD) is an emerging architecture for LLM decoding that separates state-heavy, KV-cache-dominated Attention computation from stateless, compute-intensive FFN computation, connected by per-step communication. While AFD enables independent scaling of memory and compute res...

---

### 19. [Visual Disentangled Diffusion Autoencoders: Scalable Counterfactual Generation for Foundation Models](https://arxiv.org/abs/2601.21851)

**Authors**: Sidney Bender, Marco Morik  
**Category**: cs.LG  
**Published**: 2026-01-30  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.21851v1  

#### Abstract
Foundation models, despite their robust zero-shot capabilities, remain vulnerable to spurious correlations and 'Clever Hans' strategies. Existing mitigation methods often rely on unavailable group labels or computationally expensive gradient-based adversarial optimization. To address these limitatio...

---

### 20. [MoHETS: Long-term Time Series Forecasting with Mixture-of-Heterogeneous-Experts](https://arxiv.org/abs/2601.21866)

**Authors**: Evandro S. Ortigossa, Guy Lutsker, Eran Segal  
**Category**: cs.LG  
**Published**: 2026-01-30  
**Score**: 9.0  
**Type**: new  
**ArXiv ID**: 2601.21866v1  

#### Abstract
Real-world multivariate time series can exhibit intricate multi-scale structures, including global trends, local periodicities, and non-stationary regimes, which makes long-horizon forecasting challenging. Although sparse Mixture-of-Experts (MoE) approaches improve scalability and specialization, th...

---

### 21. [ChunkWise LoRA: Adaptive Sequence Partitioning for Memory-Efficient Low-Rank Adaptation and Accelerated LLM Inference](https://arxiv.org/abs/2601.21109)

**Authors**: Ketan Thakkar, Maitreyi Chatterjee, Ramasubramanian Balasubramanian, Achyuthan Jootoo, Rajendra Ugrani  
**Category**: cs.CL  
**Published**: 2026-01-30  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.21109v1  

#### Abstract
Recent advances in low-rank adaptation (LoRA) have enabled efficient fine-tuning of large language models (LLMs) with minimal additional parameters. However, existing LoRA methods apply static rank configurations uniformly across all input tokens, ignoring variation in token complexity and computati...

---

### 22. [Why Attention Patterns Exist: A Unifying Temporal Perspective Analysis](https://arxiv.org/abs/2601.21709)

**Authors**: Qingyue Yang, Jie Wang, Xing Li, Yinqi Bai, Xialiang Tong, Huiling Zhen, Jianye Hao, Mingxuan Yuan, Bin Li  
**Category**: cs.CL  
**Published**: 2026-01-30  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.21709v1  

#### Abstract
Attention patterns play a crucial role in both training and inference of large language models (LLMs). Prior works have identified individual patterns such as retrieval heads, sink heads, and diagonal traces, yet these observations remain fragmented and lack a unifying explanation. To bridge this ga...

---

### 23. [TACLer: Tailored Curriculum Reinforcement Learning for Efficient Reasoning](https://arxiv.org/abs/2601.21711)

**Authors**: Huiyuan Lai, Malvina Nissim  
**Category**: cs.CL  
**Published**: 2026-01-30  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.21711v1  

#### Abstract
Large Language Models (LLMs) have shown remarkable performance on complex reasoning tasks, especially when equipped with long chain-of-thought (CoT) reasoning. However, eliciting long CoT typically requires large-scale reinforcement learning (RL) training, while often leading to overthinking with re...

---

### 24. [ECO: Quantized Training without Full-Precision Master Weights](https://arxiv.org/abs/2601.22101)

**Authors**: Mahdi Nikdan, Amir Zandieh, Dan Alistarh, Vahab Mirrokni  
**Category**: cs.CL  
**Published**: 2026-01-30  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.22101v1  

#### Abstract
Quantization has significantly improved the compute and memory efficiency of Large Language Model (LLM) training. However, existing approaches still rely on accumulating their updates in high-precision: concretely, gradient updates must be applied to a high-precision weight buffer, known as $\textit...

---

### 25. [Rethinking LLM-Driven Heuristic Design: Generating Efficient and Specialized Solvers via Dynamics-Aware Optimization](https://arxiv.org/abs/2601.20868)

**Authors**: Rongzheng Wang, Yihong Huang, Muquan Li, Jiakai Li, Di Liang, Bob Simons, Pei Ke, Shuang Liang, Ke Qin  
**Category**: cs.LG  
**Published**: 2026-01-30  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.20868v1  

#### Abstract
Large Language Models (LLMs) have advanced the field of Combinatorial Optimization through automated heuristic generation. Instead of relying on manual design, this LLM-Driven Heuristic Design (LHD) process leverages LLMs to iteratively generate and refine solvers to achieve high performance. Howeve...

---

### 26. [Breaking the Regional Barrier: Inductive Semantic Topology Learning for Worldwide Air Quality Forecasting](https://arxiv.org/abs/2601.21899)

**Authors**: Zhiqing Cui, Siru Zhong, Ming Jin, Shirui Pan, Qingsong Wen, Yuxuan Liang  
**Category**: cs.LG  
**Published**: 2026-01-30  
**Score**: 8.5  
**Type**: new  
**ArXiv ID**: 2601.21899v1  

#### Abstract
Global air quality forecasting grapples with extreme spatial heterogeneity and the poor generalization of existing transductive models to unseen regions. To tackle this, we propose OmniAir, a semantic topology learning framework tailored for global station-level prediction. By encoding invariant phy...

---

### 27. [Output-Space Search: Targeting LLM Generations in a Frozen Encoder-Defined Output Space](https://arxiv.org/abs/2601.21169)

**Authors**: Tobias Materzok  
**Category**: cs.CL  
**Published**: 2026-01-30  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.21169v1  

#### Abstract
We introduce Output-Space Search (OS-Search), which turns LLM generation into endpoint search. An outer loop selects a target z* in a frozen encoder-defined 3D output space Z, and a retrieval-grounded policy trained with sequence-level RL generates outputs whose coordinates land near z* under standa...

---

### 28. [DynaWeb: Model-Based Reinforcement Learning of Web Agents](https://arxiv.org/abs/2601.22149)

**Authors**: Hang Ding, Peidong Liu, Junqiao Wang, Ziwei Ji, Meng Cao, Rongzhao Zhang, Lynn Ai, Eric Yang, Tianyu Shi, Lei Yu  
**Category**: cs.CL  
**Published**: 2026-01-30  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.22149v1  

#### Abstract
The development of autonomous web agents, powered by Large Language Models (LLMs) and reinforcement learning (RL), represents a significant step towards general-purpose AI assistants. However, training these agents is severely hampered by the challenges of interacting with the live internet, which i...

---

### 29. [Model-Free Neural State Estimation in Nonlinear Dynamical Systems: A Comparative Study of Neural Architectures and Classical Filters](https://arxiv.org/abs/2601.21266)

**Authors**: Zhuochen Liu, Hans Walker, Rahul Jain  
**Category**: cs.LG  
**Published**: 2026-01-30  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.21266v1  

#### Abstract
Neural network models are increasingly used for state estimation in control and decision-making problems, yet it remains unclear to what extent they behave as principled filters in nonlinear dynamical systems. Unlike classical filters, which rely on explicit knowledge of system dynamics and noise mo...

---

### 30. [Few-Shot Learning for Dynamic Operations of Automated Electric Taxi Fleets under Evolving Charging Infrastructure: A Meta-Deep Reinforcement Learning Approach](https://arxiv.org/abs/2601.21312)

**Authors**: Xiaozhuang Li, Xindi Tang, Fang He  
**Category**: cs.LG  
**Published**: 2026-01-30  
**Score**: 8.0  
**Type**: new  
**ArXiv ID**: 2601.21312v1  

#### Abstract
With the rapid expansion of electric vehicles (EVs) and charging infrastructure, the effective management of Autonomous Electric Taxi (AET) fleets faces a critical challenge in environments with dynamic and uncertain charging availability. While most existing research assumes a static charging netwo...

---

## ğŸ”§ Configuration

This bot is configured to look for papers containing the following keywords:
- kv cache, offload, State Space, SSM, framework, System, Generation, Video, Linear, LLM, RL, RLHF, Inference, Training, Attention, Pipeline, MOE, Sparse, Quantization, Speculative, Efficient, Efficiency, Framework, Parallel, Distributed, Kernel, Decode, Decoding, Prefill, Throughput, Fast, Network, Hardware, Cluster, FP8, FP4, Optimization, Scalable, Communication

## ğŸ“… Schedule

The bot runs daily at 12:00 UTC via GitHub Actions to fetch the latest papers.

## ğŸš€ How to Use

1. **Fork this repository** to your GitHub account
2. **Customize the configuration** by editing `config.json`:
   - Add/remove arXiv categories (e.g., `cs.AI`, `cs.LG`, `cs.CL`)
   - Modify keywords to match your research interests
   - Adjust `max_papers` and `days_back` settings
3. **Enable GitHub Actions** in your repository settings
4. **The bot will automatically run daily** and update the README.md

## ğŸ“ Customization

### arXiv Categories
Common categories include:
- `cs.AI` - Artificial Intelligence
- `cs.LG` - Machine Learning
- `cs.CL` - Computation and Language
- `cs.CV` - Computer Vision
- `cs.NE` - Neural and Evolutionary Computing
- `stat.ML` - Machine Learning (Statistics)

### Keywords
Add keywords that match your research interests. The bot will search for these terms in paper titles and abstracts.

### Exclude Keywords
Add terms to exclude certain types of papers (e.g., "survey", "review", "tutorial").

## ğŸ” Manual Trigger

You can manually trigger the bot by:
1. Going to the "Actions" tab in your repository
2. Selecting "arXiv Bot Daily Update"
3. Clicking "Run workflow"

---
*Generated automatically by arXiv Bot* 
